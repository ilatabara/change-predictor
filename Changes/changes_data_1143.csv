id,project,branch,change_id,subject,status,created,updated,submitted,reviewers,revisions,total_comment_count,number,current_revision,discussion_messages_count,reviewers_count,revisions_count,owner_account_id,owner_name,owner_username,is_owner_bot,commit_message,git_command,changed_files,files_count,commit_id,topic,added_lines,deleted_lines,insertions,deletions
openstack%2Fautomaton~master~Ia5ce6ebd96060eb2024564fab91a2a62ae2b9cc9,openstack/automaton,master,Ia5ce6ebd96060eb2024564fab91a2a62ae2b9cc9,Add history.rst that uses generated 'ChangeLog' file,MERGED,2015-06-23 23:06:38.000000000,2015-06-25 21:47:02.000000000,2015-06-25 21:47:02.000000000,"[{'_account_id': 3}, {'_account_id': 6618}, {'_account_id': 10584}]","[{'number': 1, 'created': '2015-06-23 23:06:38.000000000', 'files': ['doc/source/index.rst', 'doc/source/history.rst'], 'web_link': 'https://opendev.org/openstack/automaton/commit/9489002102b4b6b77f92a8dd6a4ac296ba6f9e56', 'message': ""Add history.rst that uses generated 'ChangeLog' file\n\nChange-Id: Ia5ce6ebd96060eb2024564fab91a2a62ae2b9cc9\n""}]",0,194855,9489002102b4b6b77f92a8dd6a4ac296ba6f9e56,7,3,1,1297,,,0,"Add history.rst that uses generated 'ChangeLog' file

Change-Id: Ia5ce6ebd96060eb2024564fab91a2a62ae2b9cc9
",git fetch https://review.opendev.org/openstack/automaton refs/changes/55/194855/1 && git format-patch -1 --stdout FETCH_HEAD,"['doc/source/index.rst', 'doc/source/history.rst']",2,9489002102b4b6b77f92a8dd6a4ac296ba6f9e56,,.. include:: ../../ChangeLog ,,10,0
openstack%2Fbifrost~master~Ia9783939efab0587a5b4c1340eaa1af8ba3c3c12,openstack/bifrost,master,Ia9783939efab0587a5b4c1340eaa1af8ba3c3c12,Fix white space in readme file.,MERGED,2015-06-25 17:52:04.000000000,2015-06-25 21:43:41.000000000,2015-06-25 21:43:40.000000000,"[{'_account_id': 3}, {'_account_id': 6618}, {'_account_id': 11655}]","[{'number': 1, 'created': '2015-06-25 17:52:04.000000000', 'files': ['playbooks/roles/bifrost-prepare-for-test-dynamic/README.md'], 'web_link': 'https://opendev.org/openstack/bifrost/commit/10cb40f4c2bc1a7140aa071d50f79ba430bb0505', 'message': 'Fix white space in readme file.\n\nFollow up patch to correct white space in a readme file.\n\nChange-Id: Ia9783939efab0587a5b4c1340eaa1af8ba3c3c12\n'}]",0,195687,10cb40f4c2bc1a7140aa071d50f79ba430bb0505,8,3,1,5805,,,0,"Fix white space in readme file.

Follow up patch to correct white space in a readme file.

Change-Id: Ia9783939efab0587a5b4c1340eaa1af8ba3c3c12
",git fetch https://review.opendev.org/openstack/bifrost refs/changes/87/195687/1 && git format-patch -1 --stdout FETCH_HEAD,['playbooks/roles/bifrost-prepare-for-test-dynamic/README.md'],1,10cb40f4c2bc1a7140aa071d50f79ba430bb0505,readme_update,coded into the role. The role expects to be executed after,coded into the role. The role expects to be executed after ,1,1
openstack%2Fkolla~master~I2788c1921eb82ad0d0524fc99a436c5fe9ff50d8,openstack/kolla,master,I2788c1921eb82ad0d0524fc99a436c5fe9ff50d8,Add missing dependency oslo policy,MERGED,2015-06-25 18:44:29.000000000,2015-06-25 21:41:51.000000000,2015-06-25 21:41:48.000000000,"[{'_account_id': 3}, {'_account_id': 2834}, {'_account_id': 10428}]","[{'number': 1, 'created': '2015-06-25 18:44:29.000000000', 'files': ['docker/centos/binary/neutron/neutron-base/Dockerfile'], 'web_link': 'https://opendev.org/openstack/kolla/commit/339efaa75c7502200618c4755b1b810f7aef272c', 'message': 'Add missing dependency oslo policy\n\nAffecting one ore more neutron containers\n\nChange-Id: I2788c1921eb82ad0d0524fc99a436c5fe9ff50d8\nCloses-bug: #1468863\n'}]",0,195700,339efaa75c7502200618c4755b1b810f7aef272c,7,3,1,3098,,,0,"Add missing dependency oslo policy

Affecting one ore more neutron containers

Change-Id: I2788c1921eb82ad0d0524fc99a436c5fe9ff50d8
Closes-bug: #1468863
",git fetch https://review.opendev.org/openstack/kolla refs/changes/00/195700/1 && git format-patch -1 --stdout FETCH_HEAD,['docker/centos/binary/neutron/neutron-base/Dockerfile'],1,339efaa75c7502200618c4755b1b810f7aef272c,bug/1468863, python-oslo-policy \,,1,0
openstack%2Fgrenade~master~I19fe1e422132a067e87c71984aeb796c184a236c,openstack/grenade,master,I19fe1e422132a067e87c71984aeb796c184a236c,Upgrade python-ironicclient with nova if necessary,ABANDONED,2015-04-08 22:33:27.000000000,2015-06-25 21:32:34.000000000,,"[{'_account_id': 3}, {'_account_id': 1420}, {'_account_id': 1849}, {'_account_id': 2750}]","[{'number': 1, 'created': '2015-04-08 22:33:27.000000000', 'files': ['projects/60_nova/upgrade.sh'], 'web_link': 'https://opendev.org/openstack/grenade/commit/e8b3140cc2622da20fe7e5c084786b274e63d0e3', 'message': ""Upgrade python-ironicclient with nova if necessary\n\nWhen configured to use the Ironic virt driver, ensure we upgrade\nto the latest client library with Nova. This library is not managed\nby nova's requirements and doesn't get upgraded with it, so we need\nto manually do it here.\n\nChange-Id: I19fe1e422132a067e87c71984aeb796c184a236c\n""}]",0,171846,e8b3140cc2622da20fe7e5c084786b274e63d0e3,7,4,1,1420,,,0,"Upgrade python-ironicclient with nova if necessary

When configured to use the Ironic virt driver, ensure we upgrade
to the latest client library with Nova. This library is not managed
by nova's requirements and doesn't get upgraded with it, so we need
to manually do it here.

Change-Id: I19fe1e422132a067e87c71984aeb796c184a236c
",git fetch https://review.opendev.org/openstack/grenade refs/changes/46/171846/1 && git format-patch -1 --stdout FETCH_HEAD,['projects/60_nova/upgrade.sh'],1,e8b3140cc2622da20fe7e5c084786b274e63d0e3,modular_grenade,"# Upgrade to newest python-ironicclient library if we're using it. if [[ ""$VIRT_DRIVER"" == ""ironic"" ]]; then pip_install_gr python-ironicclient fi ",,5,0
openstack%2Fdevstack~master~Ib5023f9dd681fbd363510a93166ec20bda7dc923,openstack/devstack,master,Ib5023f9dd681fbd363510a93166ec20bda7dc923,Skip cert related things in create_userrc.sh when n-crt absent,ABANDONED,2015-04-07 22:00:44.000000000,2015-06-25 21:32:18.000000000,,"[{'_account_id': 3}, {'_account_id': 6537}, {'_account_id': 10215}, {'_account_id': 10342}, {'_account_id': 10385}, {'_account_id': 12356}]","[{'number': 1, 'created': '2015-04-07 22:00:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack/commit/2a021f013bfa66164ed05543c8107b7f125c048b', 'message': 'Skip cert related things in create_userrc.sh when n-crt absent\n\n169709 removed n-crt from the default services, but missed the fact that\ncreate_userrc.sh is doing lots of cert things by default, some of which\nis dependent on that service being active.  To avoid errors and long RPC\ntimeouts trying to run nova x509-* commands, this adds a new flag to skip\ncert stuff that is passed when the service is missing.\n\nChange-Id: Ib5023f9dd681fbd363510a93166ec20bda7dc923\nCloses-bug: #1441348\n'}, {'number': 2, 'created': '2015-04-07 22:18:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack/commit/6167cf92ce073c305690d3bc4c8ab82efec61ab0', 'message': 'Skip cert related things in create_userrc.sh when n-crt absent\n\n169709 removed n-crt from the default services, but missed the fact that\ncreate_userrc.sh is doing lots of cert things by default, some of which\nis dependent on that service being active.  To avoid errors and long RPC\ntimeouts trying to run nova x509-* commands, this adds a new flag to skip\ncert stuff that is passed when the service is missing.\n\nChange-Id: Ib5023f9dd681fbd363510a93166ec20bda7dc923\nCloses-bug: #1441348\n'}, {'number': 3, 'created': '2015-04-07 22:20:27.000000000', 'files': ['tools/create_userrc.sh', 'stack.sh'], 'web_link': 'https://opendev.org/openstack/devstack/commit/b081d8aff321498208f6861afa9c161c53474954', 'message': 'Skip cert related things in create_userrc.sh when n-crt absent\n\n169709 removed n-crt from the default services, but missed the fact that\ncreate_userrc.sh is doing lots of cert things by default, some of which\nis dependent on that service being active.  To avoid errors and long RPC\ntimeouts trying to run nova x509-* commands, this adds a new flag to skip\ncert stuff that is passed when the service is missing.\n\nChange-Id: Ib5023f9dd681fbd363510a93166ec20bda7dc923\nCloses-bug: #1441348\n'}]",4,171406,b081d8aff321498208f6861afa9c161c53474954,12,6,3,1420,,,0,"Skip cert related things in create_userrc.sh when n-crt absent

169709 removed n-crt from the default services, but missed the fact that
create_userrc.sh is doing lots of cert things by default, some of which
is dependent on that service being active.  To avoid errors and long RPC
timeouts trying to run nova x509-* commands, this adds a new flag to skip
cert stuff that is passed when the service is missing.

Change-Id: Ib5023f9dd681fbd363510a93166ec20bda7dc923
Closes-bug: #1441348
",git fetch https://review.opendev.org/openstack/devstack refs/changes/06/171406/1 && git format-patch -1 --stdout FETCH_HEAD,"['tools/create_userrc.sh', 'stack.sh']",2,2a021f013bfa66164ed05543c8107b7f125c048b,," if ! is_service_enabled n-crt; then USERRC_PARAMS=""$USERRC_PARAMS --skip-certs"" fi ",,59,36
openstack%2Fnova~stable%2Fjuno~Id567ca3d5c30eed0ab8d249b0243c3056f1f8919,openstack/nova,stable/juno,Id567ca3d5c30eed0ab8d249b0243c3056f1f8919,Make Ironic driver explicitly request v1.1 of the Ironic API,ABANDONED,2015-03-23 23:18:44.000000000,2015-06-25 21:32:03.000000000,,"[{'_account_id': 3}, {'_account_id': 2889}, {'_account_id': 5805}, {'_account_id': 8871}]","[{'number': 1, 'created': '2015-03-23 23:18:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/a8f3b08ed7894c395d2f0c3c1b4a1df4764fed87', 'message': 'Make Ironic driver explicitly request v1.1 of the Ironic API\n\nIn Kilo, Ironic introduced API micro-versions.  Newer versions of\npython-ironicclient support specifying the desired API version and\nfuture versions of the client will default to the newest version.\nSince the juno nova driver existed prior to microversioning and\ndepends on an older API version, we need to explicitly request\nit here.  Setting this parameter will be ignored if using an older\nversion of the client or interfacing with an older version of the\nserver.\n\nChange-Id: Id567ca3d5c30eed0ab8d249b0243c3056f1f8919\nCloses-bug: #1433805\n'}, {'number': 2, 'created': '2015-03-24 01:19:27.000000000', 'files': ['nova/virt/ironic/client_wrapper.py', 'nova/tests/virt/ironic/test_client_wrapper.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/85f0c691e1ddd965dd425a73a242b6c0e326f10b', 'message': ""Make Ironic driver explicitly request v1.1 of the Ironic API\n\nIn Kilo, Ironic introduced API micro-versions.  Newer versions of\npython-ironicclient support specifying the desired API version and\nfuture versions of the client will default to the newest version.\nSince the juno nova driver existed prior to microversioning and\ndepends on an older API version, we need to explicitly request\nit here.  Setting this parameter will be ignored if using an older\nversion of the client or interfacing with an older version of the\nserver.\n\nNote this change is only relevant to stable/juno. Kilo's driver is\nalready updated to interface with both new and old Ironic clients\nand APIs.\n\nChange-Id: Id567ca3d5c30eed0ab8d249b0243c3056f1f8919\nCloses-bug: #1433805\n""}]",0,167038,85f0c691e1ddd965dd425a73a242b6c0e326f10b,11,4,2,1420,,,0,"Make Ironic driver explicitly request v1.1 of the Ironic API

In Kilo, Ironic introduced API micro-versions.  Newer versions of
python-ironicclient support specifying the desired API version and
future versions of the client will default to the newest version.
Since the juno nova driver existed prior to microversioning and
depends on an older API version, we need to explicitly request
it here.  Setting this parameter will be ignored if using an older
version of the client or interfacing with an older version of the
server.

Note this change is only relevant to stable/juno. Kilo's driver is
already updated to interface with both new and old Ironic clients
and APIs.

Change-Id: Id567ca3d5c30eed0ab8d249b0243c3056f1f8919
Closes-bug: #1433805
",git fetch https://review.opendev.org/openstack/nova refs/changes/38/167038/2 && git format-patch -1 --stdout FETCH_HEAD,['nova/virt/ironic/client_wrapper.py'],1,a8f3b08ed7894c395d2f0c3c1b4a1df4764fed87,167038," # In case the Ironic server offers microversions and we are running # with a newer version of the client, we need to explicitly request # the API microversion that this driver understands. kwargs['os_ironic_api_version'] = '1.1' ",,5,0
openstack%2Fpython-ironicclient~master~Iafa7ec9f3b1bfcd8c8826fc30e2944cd22dc8fe9,openstack/python-ironicclient,master,Iafa7ec9f3b1bfcd8c8826fc30e2944cd22dc8fe9,Add better framework for functionally testing verioned APIs,ABANDONED,2015-03-19 00:34:36.000000000,2015-06-25 21:31:42.000000000,,"[{'_account_id': 3}, {'_account_id': 1420}]","[{'number': 1, 'created': '2015-03-19 00:34:36.000000000', 'files': ['ironicclient/tests/functional/test_ironicclient.py', 'test-requirements.txt', 'tools/run_functional.sh'], 'web_link': 'https://opendev.org/openstack/python-ironicclient/commit/9238456d72e51c150c8365eb61157299af38ff9f', 'message': 'Add better framework for functionally testing verioned APIs\n\nThis adds the ability to tag API version ranges onto functional tests,\nso that they skip against servers that do not satisfy that range. This\ncurrently does not auto-discover server-side API versions, and instead\nrelies on that to be explictly set in the test.conf.\n\nThe test cases added are pretty blah, but can be improved with the\nrest of this patch.\n\nChange-Id: Iafa7ec9f3b1bfcd8c8826fc30e2944cd22dc8fe9\n'}]",0,165665,9238456d72e51c150c8365eb61157299af38ff9f,5,2,1,1420,,,0,"Add better framework for functionally testing verioned APIs

This adds the ability to tag API version ranges onto functional tests,
so that they skip against servers that do not satisfy that range. This
currently does not auto-discover server-side API versions, and instead
relies on that to be explictly set in the test.conf.

The test cases added are pretty blah, but can be improved with the
rest of this patch.

Change-Id: Iafa7ec9f3b1bfcd8c8826fc30e2944cd22dc8fe9
",git fetch https://review.opendev.org/openstack/python-ironicclient refs/changes/65/165665/1 && git format-patch -1 --stdout FETCH_HEAD,"['ironicclient/tests/functional/test_ironicclient.py', 'test-requirements.txt', 'tools/run_functional.sh']",3,9238456d72e51c150c8365eb61157299af38ff9f,,"function run_functional { IRONIC_API_VERSION=${1:-latest} os_ironic_api_verson=$IRONIC_API_VERSIONos_ironic_api_version=$IRONIC_API_VERSION # TODO(adam_g): Execute in venv via tox /w pretty output echo ""Running functional tests against API version $IRONIC_API_VERSION"" OS_TEST_PATH=./ironicclient/tests/functional python setup.py testr --testr-args=""--subunit"" | subunit-trace --no-failure-debug -f } API_VERSIONS=""1.1 1.2 1.3 1.4 1.5 1.6 latest"" FAILED="""" for vers in $API_VERSIONS; do run_functional $vers if [ $? != 0 ]; then FAILED+="" $vers "" fi done if [ -n ""$FAILED"" ]; then echo ""Test runs failed for the following API version(s): $FAILED"" exit 1 else echo ""Passed test runs for the following API versions: $API_VERSIONS"" fi",tox -e functional,154,15
openstack%2Fironic~master~Idda2f6c056e2c0651de17f9e7c42aa3fb9a05637,openstack/ironic,master,Idda2f6c056e2c0651de17f9e7c42aa3fb9a05637,Check-in Ironic's devstack code as in-tree plugin,ABANDONED,2015-03-04 23:54:03.000000000,2015-06-25 21:31:31.000000000,,"[{'_account_id': 3}, {'_account_id': 1420}, {'_account_id': 10239}, {'_account_id': 12081}]","[{'number': 1, 'created': '2015-03-04 23:54:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/34b0a745367421076c5cc396c535b3a43912d56b', 'message': ""Check-in Ironic's devstack code as in-tree plugin\n\nThis moves ironic's devstack code out of devstack proper and into\nthe Ironic tree as a plugin.\n\nChange-Id: Idda2f6c056e2c0651de17f9e7c42aa3fb9a05637\n""}, {'number': 2, 'created': '2015-03-05 19:20:00.000000000', 'files': ['devstack/tools/templates/vm.xml', 'devstack/tools/templates/brbm.xml', 'devstack/tools/scripts/setup-network', 'devstack/tools/scripts/create-node', 'devstack/plugin.sh', 'devstack/files/rpms/ironic', 'devstack/tools/scripts/cleanup-node', 'devstack/tools/scripts/configure-vm', 'devstack/files/debs/ironic', 'devstack/settings', 'devstack/tools/templates/tftpd-xinetd.template'], 'web_link': 'https://opendev.org/openstack/ironic/commit/1c7ca0afd490aa27ee7e22ac1bc627bdf3633b68', 'message': ""Check-in Ironic's devstack code as in-tree plugin\n\nThis moves ironic's devstack code out of devstack proper and into\nthe Ironic tree as a plugin.\n\nChange-Id: Idda2f6c056e2c0651de17f9e7c42aa3fb9a05637\n""}]",0,161485,1c7ca0afd490aa27ee7e22ac1bc627bdf3633b68,16,4,2,1420,,,0,"Check-in Ironic's devstack code as in-tree plugin

This moves ironic's devstack code out of devstack proper and into
the Ironic tree as a plugin.

Change-Id: Idda2f6c056e2c0651de17f9e7c42aa3fb9a05637
",git fetch https://review.opendev.org/openstack/ironic refs/changes/85/161485/2 && git format-patch -1 --stdout FETCH_HEAD,"['devstack/plugin.sh', 'devstack/settings']",2,34b0a745367421076c5cc396c535b3a43912d56b,ir_functional,"enable_service ir-api,ir-cond ",,890,0
openstack%2Ftempest~master~Ia24a5504b08b3c8baa2c54b3d53e8c927845427d,openstack/tempest,master,Ia24a5504b08b3c8baa2c54b3d53e8c927845427d,Tag compute hosts + hypervisor tests for baremetal,ABANDONED,2015-03-04 21:43:05.000000000,2015-06-25 21:31:18.000000000,,"[{'_account_id': 3}, {'_account_id': 1192}, {'_account_id': 1420}, {'_account_id': 2889}, {'_account_id': 5803}, {'_account_id': 6167}, {'_account_id': 7020}, {'_account_id': 8256}, {'_account_id': 8871}, {'_account_id': 10385}]","[{'number': 1, 'created': '2015-03-04 21:43:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/bd252fe1963c0b80a5f32e6ac290278f3838699e', 'message': ""Tag compute hosts + hypervisor tests for baremetal\n\nWe'd like to avoid using a tempest regex for running Ironic\ntests and instead use tags. This tags a subset of the compute\nAPI tests that we care about, and would allow us to run these when\nrunning Tempest /w the 'baremetal' tag.\n\nChange-Id: Ia24a5504b08b3c8baa2c54b3d53e8c927845427d\n""}, {'number': 2, 'created': '2015-03-04 21:49:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/e983784f2290ebb353fce3ba93d51f79e2085c0a', 'message': ""Tag compute hosts + hypervisor tests for baremetal\n\nWe'd like to avoid using a tempest regex for running Ironic\ntests and instead use tags. This tags a subset of the compute\nAPI tests that we care about, and would allow us to run these when\nrunning Tempest /w the 'baremetal' tag.\n\nChange-Id: Ia24a5504b08b3c8baa2c54b3d53e8c927845427d\n""}, {'number': 3, 'created': '2015-03-09 21:10:30.000000000', 'files': ['tempest/api/compute/admin/test_baremetal_nodes.py', 'tempest/api/compute/admin/test_hosts.py', 'tempest/api/compute/admin/test_hypervisor_negative.py', 'tempest/api/compute/admin/test_hypervisor.py', 'tempest/api/compute/admin/test_hosts_negative.py'], 'web_link': 'https://opendev.org/openstack/tempest/commit/d9436384cf3c000feb5c5a44e7d19061bf44b858', 'message': ""Tag compute hosts + hypervisor tests for baremetal\n\nWe'd like to avoid using a tempest regex for running Ironic\ntests and instead use tags. This tags a subset of the compute\nAPI tests that we care about, and would allow us to run these when\nrunning Tempest /w the 'baremetal' tag.\n\nChange-Id: Ia24a5504b08b3c8baa2c54b3d53e8c927845427d\n""}]",5,161429,d9436384cf3c000feb5c5a44e7d19061bf44b858,25,10,3,1420,,,0,"Tag compute hosts + hypervisor tests for baremetal

We'd like to avoid using a tempest regex for running Ironic
tests and instead use tags. This tags a subset of the compute
API tests that we care about, and would allow us to run these when
running Tempest /w the 'baremetal' tag.

Change-Id: Ia24a5504b08b3c8baa2c54b3d53e8c927845427d
",git fetch https://review.opendev.org/openstack/tempest refs/changes/29/161429/1 && git format-patch -1 --stdout FETCH_HEAD,"['tempest/api/compute/admin/test_hosts.py', 'tempest/api/compute/admin/test_hypervisor_negative.py', 'tempest/api/compute/admin/test_hypervisor.py', 'tempest/api/compute/admin/test_hosts_negative.py']",4,bd252fe1963c0b80a5f32e6ac290278f3838699e,161429," @test.attr(type=['negative', 'gate', 'baremetal']) @test.attr(type=['negative', 'gate', 'baremetal']) @test.attr(type=['negative', 'gate', 'baremetal']) @test.attr(type=['negative', 'gate', 'baremetal']) @test.attr(type=['negative', 'gate', 'baremetal']) @test.attr(type=['negative', 'gate', 'baremetal']) @test.attr(type=['negative', 'gate', 'baremetal']) @test.attr(type=['negative', 'gate', 'baremetal']) @test.attr(type=['negative', 'gate', 'baremetal']) @test.attr(type=['negative', 'gate', 'baremetal']) @test.attr(type=['negative', 'gate', 'baremetal']) @test.attr(type=['negative', 'gate', 'baremetal']) @test.attr(type=['negative', 'gate', 'baremetal']) @test.attr(type=['negative', 'gate', 'baremetal']) @test.attr(type=['negative', 'gate', 'baremetal'])"," @test.attr(type=['negative', 'gate']) @test.attr(type=['negative', 'gate']) @test.attr(type=['negative', 'gate']) @test.attr(type=['negative', 'gate']) @test.attr(type=['negative', 'gate']) @test.attr(type=['negative', 'gate']) @test.attr(type=['negative', 'gate']) @test.attr(type=['negative', 'gate']) @test.attr(type=['negative', 'gate']) @test.attr(type=['negative', 'gate']) @test.attr(type=['negative', 'gate']) @test.attr(type=['negative', 'gate']) @test.attr(type=['negative', 'gate']) @test.attr(type=['negative', 'gate']) @test.attr(type=['negative', 'gate'])",38,38
openstack%2Fironic~master~I4899f176bb2552cc2ef1bb4ee2d21faf47c40907,openstack/ironic,master,I4899f176bb2552cc2ef1bb4ee2d21faf47c40907,Testing forward grenade migration (Do not merge),ABANDONED,2014-09-26 17:21:23.000000000,2015-06-25 21:30:48.000000000,,"[{'_account_id': 3}, {'_account_id': 1420}, {'_account_id': 12081}]","[{'number': 1, 'created': '2014-09-26 17:21:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/e5e8c480809642a5f51b1818cc937a707a18f844', 'message': 'Testing sideways migration (Do not merge)\n\nDo not merge, just triggering an experimental check.\n\nChange-Id: I4899f176bb2552cc2ef1bb4ee2d21faf47c40907\n'}, {'number': 2, 'created': '2014-10-09 19:03:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/1213b825aed1362586d4c461caea17544f4645f2', 'message': 'Testing sideways migration (Do not merge)\n\nDo not merge, just triggering an experimental check.\n\nChange-Id: I4899f176bb2552cc2ef1bb4ee2d21faf47c40907\n'}, {'number': 3, 'created': '2014-10-09 19:04:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/a46ae73d52b3400c0d9e3b98025fc55845cef422', 'message': 'Testing sideways migration (Do not merge)\n\nDo not merge, just triggering an experimental check.\n\nChange-Id: I4899f176bb2552cc2ef1bb4ee2d21faf47c40907\n'}, {'number': 4, 'created': '2014-11-12 14:43:44.000000000', 'files': ['README.rst'], 'web_link': 'https://opendev.org/openstack/ironic/commit/fa857c959491c33365ba563960b1d8d6235662b6', 'message': 'Testing forward grenade migration (Do not merge)\n\nDo not merge, just triggering an experimental check.\n\nChange-Id: I4899f176bb2552cc2ef1bb4ee2d21faf47c40907\n'}]",0,124474,fa857c959491c33365ba563960b1d8d6235662b6,151,3,4,1420,,,0,"Testing forward grenade migration (Do not merge)

Do not merge, just triggering an experimental check.

Change-Id: I4899f176bb2552cc2ef1bb4ee2d21faf47c40907
",git fetch https://review.opendev.org/openstack/ironic refs/changes/74/124474/4 && git format-patch -1 --stdout FETCH_HEAD,['README.rst'],1,e5e8c480809642a5f51b1818cc937a707a18f844,124474,xIronic is an Incubated OpenStack project which aims to provision,Ironic is an Incubated OpenStack project which aims to provision,1,1
openstack%2Fdevstack~master~I1da8621d29d29a0146594792eb1a48acc936aa1f,openstack/devstack,master,I1da8621d29d29a0146594792eb1a48acc936aa1f,Bump Ironic api_max_retries,ABANDONED,2015-04-07 18:04:19.000000000,2015-06-25 21:30:38.000000000,,"[{'_account_id': 3}, {'_account_id': 1420}, {'_account_id': 5805}, {'_account_id': 6773}, {'_account_id': 7118}, {'_account_id': 10342}, {'_account_id': 10343}, {'_account_id': 10385}]","[{'number': 1, 'created': '2015-04-07 18:04:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack/commit/99fa9bbf4cb3f76417704f0bb65280d1bfdc4c72', 'message': ""Bump Ironic api_max_retries\n\nDuring deployment, devstack starts n-cpu, does some stuff and starts\nthe Ironic API server.  n-cpu immediately starts requesting node resources\nfrom Ironic assumming it will be up within its default 60 tries.  We've\nnoticed it taking a long time for devstack to do whatever its doing between\nstarting n-cpu and ir-api, this bumps the max retries to cope with this.\n\nChange-Id: I1da8621d29d29a0146594792eb1a48acc936aa1f\nCloses-bug: #1441007\n""}, {'number': 2, 'created': '2015-04-07 18:52:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack/commit/7374b767f9bb1222a7fe94c5e73e53d045beba36', 'message': ""Bump Ironic api_max_retries\n\nDuring deployment, devstack starts n-cpu, does some stuff and starts\nthe Ironic API server.  n-cpu immediately starts requesting node resources\nfrom Ironic assumming it will be up within its default 60 tries.  We've\nnoticed it taking a long time for devstack to do whatever its doing between\nstarting n-cpu and ir-api, this bumps the max retries to cope with this.\n\nChange-Id: I1da8621d29d29a0146594792eb1a48acc936aa1f\nCloses-bug: #1441007\n""}, {'number': 3, 'created': '2015-04-14 00:01:13.000000000', 'files': ['lib/nova_plugins/hypervisor-ironic'], 'web_link': 'https://opendev.org/openstack/devstack/commit/2331def41169ae7a972eea21cee29fc45a1068fb', 'message': ""Bump Ironic api_max_retries\n\nDuring deployment, devstack starts n-cpu, does some stuff and starts\nthe Ironic API server.  n-cpu immediately starts requesting node resources\nfrom Ironic assumming it will be up within its default 60 tries.  We've\nnoticed it taking a long time for devstack to do whatever its doing between\nstarting n-cpu and ir-api, this bumps the max retries to cope with this.\n\nChange-Id: I1da8621d29d29a0146594792eb1a48acc936aa1f\nPartial-bug: #1441007\n""}]",3,171313,2331def41169ae7a972eea21cee29fc45a1068fb,13,8,3,1420,,,0,"Bump Ironic api_max_retries

During deployment, devstack starts n-cpu, does some stuff and starts
the Ironic API server.  n-cpu immediately starts requesting node resources
from Ironic assumming it will be up within its default 60 tries.  We've
noticed it taking a long time for devstack to do whatever its doing between
starting n-cpu and ir-api, this bumps the max retries to cope with this.

Change-Id: I1da8621d29d29a0146594792eb1a48acc936aa1f
Partial-bug: #1441007
",git fetch https://review.opendev.org/openstack/devstack refs/changes/13/171313/3 && git format-patch -1 --stdout FETCH_HEAD,['lib/nova_plugins/hypervisor-ironic'],1,99fa9bbf4cb3f76417704f0bb65280d1bfdc4c72,api_max_retries, iniset $NOVA_CONF ironic api_max_retires 180,,1,0
openstack%2Fheat-translator~master~I4c25ecb64c6dd3396cb2ba52fc6da2f115f92e09,openstack/heat-translator,master,I4c25ecb64c6dd3396cb2ba52fc6da2f115f92e09,Prepare ELK TOSCA Template for Translation into HOT (4),MERGED,2015-06-24 19:48:40.000000000,2015-06-25 21:28:12.000000000,2015-06-25 21:28:10.000000000,"[{'_account_id': 3}, {'_account_id': 6456}, {'_account_id': 9498}]","[{'number': 1, 'created': '2015-06-24 19:48:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat-translator/commit/feb737cf6d5f386a56159f77ccf4cc4288dae652', 'message': 'Prepare ELK TOSCA Template for Translation into HOT (4)\n\nFix some further issues with the ELK scripts for proper deployment\nof the translated HOT template.\n\nPartially Implements: blueprint translate-tosca-monitoring-usecase\n\nChange-Id: I4c25ecb64c6dd3396cb2ba52fc6da2f115f92e09\n'}, {'number': 2, 'created': '2015-06-25 17:58:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat-translator/commit/01179760b968f1e40d96c55241e3609647a65d25', 'message': 'Prepare ELK TOSCA Template for Translation into HOT (4)\n\nFix some further issues with the ELK scripts for proper deployment\nof the translated HOT template. Also, switched all shell scripts\nto use bash.\n\nPartially Implements: blueprint translate-tosca-monitoring-usecase\n\nChange-Id: I4c25ecb64c6dd3396cb2ba52fc6da2f115f92e09\n'}, {'number': 3, 'created': '2015-06-25 17:59:56.000000000', 'files': ['translator/toscalib/tests/artifacts/rsyslog/create.sh', 'translator/toscalib/tests/artifacts/nodejs/config.sh', 'translator/toscalib/tests/data/CSAR/tosca_elk/Scripts/mongodb/start.sh', 'translator/toscalib/tests/data/CSAR/tosca_elk/Scripts/elasticsearch/start.sh', 'translator/toscalib/tests/artifacts/rsyslog/start.sh', 'translator/toscalib/tests/data/CSAR/tosca_elk/Scripts/collectd/create.sh', 'translator/toscalib/tests/artifacts/kibana/config.sh', 'translator/toscalib/tests/artifacts/logstash/start.sh', 'translator/toscalib/tests/data/CSAR/tosca_elk/Scripts/mongodb/config.sh', 'translator/toscalib/tests/artifacts/collectd/start.sh', 'translator/toscalib/tests/data/CSAR/tosca_elk/Scripts/rsyslog/create.sh', 'translator/toscalib/tests/data/CSAR/tosca_elk/Scripts/rsyslog/start.sh', 'translator/toscalib/tests/artifacts/mongodb/create.sh', 'translator/toscalib/tests/artifacts/nodejs/create.sh', 'translator/toscalib/tests/data/CSAR/tosca_elk/Definitions/tosca_elk.yaml', 'translator/toscalib/tests/artifacts/nodejs/start.sh', 'translator/toscalib/tests/data/CSAR/tosca_elk/Scripts/nodejs/create.sh', 'translator/toscalib/tests/artifacts/elasticsearch/create.sh', 'translator/toscalib/tests/artifacts/collectd/create.sh', 'translator/toscalib/tests/data/CSAR/tosca_elk/Scripts/kibana/config.sh', 'translator/toscalib/tests/data/CSAR/tosca_elk/Scripts/collectd/start.sh', 'translator/toscalib/tests/data/CSAR/tosca_elk/Scripts/kibana/start.sh', 'translator/toscalib/tests/artifacts/kibana/start.sh', 'translator/toscalib/tests/data/tosca_elk.yaml', 'translator/toscalib/tests/artifacts/logstash/create.sh', 'translator/toscalib/tests/data/CSAR/tosca_elk/Scripts/mongodb/create.sh', 'translator/toscalib/tests/artifacts/kibana/create.sh', 'translator/toscalib/tests/data/CSAR/tosca_elk/Scripts/kibana/create.sh', 'translator/toscalib/tests/data/CSAR/tosca_elk/Scripts/nodejs/start.sh', 'translator/toscalib/tests/artifacts/mongodb/start.sh', 'translator/toscalib/tests/data/CSAR/tosca_elk/Scripts/logstash/create.sh', 'translator/toscalib/tests/data/CSAR/tosca_elk/Scripts/logstash/start.sh', 'translator/toscalib/tests/data/CSAR/tosca_elk/Scripts/nodejs/config.sh', 'translator/toscalib/tests/artifacts/mongodb/config.sh', 'translator/toscalib/tests/data/CSAR/tosca_elk/Scripts/elasticsearch/create.sh', 'translator/toscalib/tests/artifacts/elasticsearch/start.sh'], 'web_link': 'https://opendev.org/openstack/heat-translator/commit/38910af64cfe3384315cf54c9127ae4d6e1710d1', 'message': 'Prepare ELK TOSCA Template for Translation into HOT (4)\n\nFix some further issues with the ELK scripts for proper deployment\nof the translated HOT template. Also, switch all shell scripts to\nuse bash.\n\nPartially Implements: blueprint translate-tosca-monitoring-usecase\n\nChange-Id: I4c25ecb64c6dd3396cb2ba52fc6da2f115f92e09\n'}]",0,195287,38910af64cfe3384315cf54c9127ae4d6e1710d1,11,3,3,9498,,,0,"Prepare ELK TOSCA Template for Translation into HOT (4)

Fix some further issues with the ELK scripts for proper deployment
of the translated HOT template. Also, switch all shell scripts to
use bash.

Partially Implements: blueprint translate-tosca-monitoring-usecase

Change-Id: I4c25ecb64c6dd3396cb2ba52fc6da2f115f92e09
",git fetch https://review.opendev.org/openstack/heat-translator refs/changes/87/195287/1 && git format-patch -1 --stdout FETCH_HEAD,"['translator/toscalib/tests/artifacts/nodejs/create.sh', 'translator/toscalib/tests/artifacts/rsyslog/create.sh', 'translator/toscalib/tests/data/CSAR/tosca_elk/Definitions/tosca_elk.yaml', 'translator/toscalib/tests/data/CSAR/tosca_elk/Scripts/nodejs/create.sh', 'translator/toscalib/tests/artifacts/elasticsearch/create.sh', 'translator/toscalib/tests/artifacts/collectd/create.sh', 'translator/toscalib/tests/data/CSAR/tosca_elk/Scripts/mongodb/start.sh', 'translator/toscalib/tests/data/tosca_elk.yaml', 'translator/toscalib/tests/artifacts/logstash/create.sh', 'translator/toscalib/tests/data/CSAR/tosca_elk/Scripts/mongodb/create.sh', 'translator/toscalib/tests/data/CSAR/tosca_elk/Scripts/collectd/create.sh', 'translator/toscalib/tests/data/CSAR/tosca_elk/Scripts/mongodb/config.sh', 'translator/toscalib/tests/artifacts/mongodb/start.sh', 'translator/toscalib/tests/data/CSAR/tosca_elk/Scripts/logstash/create.sh', 'translator/toscalib/tests/data/CSAR/tosca_elk/Scripts/rsyslog/create.sh', 'translator/toscalib/tests/artifacts/mongodb/config.sh', 'translator/toscalib/tests/artifacts/mongodb/create.sh', 'translator/toscalib/tests/data/CSAR/tosca_elk/Scripts/elasticsearch/create.sh']",18,feb737cf6d5f386a56159f77ccf4cc4288dae652,bp/translate-tosca-monitoring-usecase,"#!/bin/bash #Trying to avoid multiple apt-get's running simultaneously (in the #rare occasion that the apt-get command fails rerun the script). while [[ ""$(ps -A | grep apt-get | awk '{print $1}')"" != """" ]]; do echo ""Waiting for the other apt-get process to complete ..."" r=$RANDOM && let ""sec=$r/10000"" && let ""mil=($r%10000)/10"" sleep $sec.$mil done",#!/bin/sh -x,97,53
openstack%2Fmonasca-agent~master~Ifb1ef573925d7d86f140d7cd5d30ab79eb477093,openstack/monasca-agent,master,Ifb1ef573925d7d86f140d7cd5d30ab79eb477093,Allow hostname set by a plugin in dimensions to be used in a metric.,MERGED,2015-06-24 17:26:33.000000000,2015-06-25 21:18:11.000000000,2015-06-25 21:18:11.000000000,"[{'_account_id': 3}, {'_account_id': 2419}, {'_account_id': 7847}, {'_account_id': 14517}, {'_account_id': 15027}]","[{'number': 1, 'created': '2015-06-24 17:26:33.000000000', 'files': ['monasca_agent/common/aggregator.py'], 'web_link': 'https://opendev.org/openstack/monasca-agent/commit/facfd3b554005a40ffaa4335a0211d0547508a3c', 'message': 'Allow hostname set by a plugin in dimensions to be used in a metric.\n\nChange-Id: Ifb1ef573925d7d86f140d7cd5d30ab79eb477093\n'}]",0,195214,facfd3b554005a40ffaa4335a0211d0547508a3c,9,5,1,11094,,,0,"Allow hostname set by a plugin in dimensions to be used in a metric.

Change-Id: Ifb1ef573925d7d86f140d7cd5d30ab79eb477093
",git fetch https://review.opendev.org/openstack/monasca-agent refs/changes/14/195214/1 && git format-patch -1 --stdout FETCH_HEAD,['monasca_agent/common/aggregator.py'],1,facfd3b554005a40ffaa4335a0211d0547508a3c,feature/hostname, if 'hostname' not in dimensions and hostname:, if hostname:,1,1
openstack%2Fautomaton~master~I140cb188f58849ac5caea97ed5a422375b549f6f,openstack/automaton,master,I140cb188f58849ac5caea97ed5a422375b549f6f,Add base exception class for this library,MERGED,2015-06-23 19:33:32.000000000,2015-06-25 21:10:22.000000000,2015-06-25 21:10:17.000000000,"[{'_account_id': 3}, {'_account_id': 6618}, {'_account_id': 10239}, {'_account_id': 10584}]","[{'number': 1, 'created': '2015-06-23 19:33:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/automaton/commit/96c6cc74dc01b3682a58517a93fc1c19f575adee', 'message': 'Add base exception class for this library\n\nTo make it easier for users of this library to\ndifferentiate general exceptions from automaton\nexceptions it is quite common to have a root exception\nclass that libraries use (and derive there exceptions\nfrom); this adds that.\n\nChange-Id: I140cb188f58849ac5caea97ed5a422375b549f6f\n'}, {'number': 2, 'created': '2015-06-23 19:36:33.000000000', 'files': ['automaton/exceptions.py', 'doc/source/api.rst', 'doc/source/conf.py'], 'web_link': 'https://opendev.org/openstack/automaton/commit/fd1d81a90c64157b8bf163941dd141486c6ca648', 'message': 'Add base exception class for this library\n\nTo make it easier for users of this library to\ndifferentiate general exceptions from automaton\nexceptions it is quite common to have a root exception\nclass that libraries use (and derive there exceptions\nfrom); this adds that.\n\nChange-Id: I140cb188f58849ac5caea97ed5a422375b549f6f\n'}]",0,194793,fd1d81a90c64157b8bf163941dd141486c6ca648,9,4,2,1297,,,0,"Add base exception class for this library

To make it easier for users of this library to
differentiate general exceptions from automaton
exceptions it is quite common to have a root exception
class that libraries use (and derive there exceptions
from); this adds that.

Change-Id: I140cb188f58849ac5caea97ed5a422375b549f6f
",git fetch https://review.opendev.org/openstack/automaton refs/changes/93/194793/1 && git format-patch -1 --stdout FETCH_HEAD,['automaton/exceptions.py'],1,96c6cc74dc01b3682a58517a93fc1c19f575adee,,"class AutomatonException(Exception): """"""Base class for *most* exceptions emitted from this library."""""" class InvalidState(AutomatonException):class NotInitialized(AutomatonException):class NotFound(AutomatonException):class Duplicate(AutomatonException):class FrozenMachine(AutomatonException):",class InvalidState(Exception):class NotInitialized(Exception):class NotFound(Exception):class Duplicate(Exception):class FrozenMachine(Exception):,9,5
openstack%2Fproject-config~master~I19ca0901e81a547173bfae2ca508776b5bfbe592,openstack/project-config,master,I19ca0901e81a547173bfae2ca508776b5bfbe592,Make yaql py34 job voting,MERGED,2015-06-18 14:40:06.000000000,2015-06-25 21:02:31.000000000,2015-06-25 21:02:28.000000000,"[{'_account_id': 3}, {'_account_id': 2750}, {'_account_id': 4162}, {'_account_id': 6547}, {'_account_id': 7226}, {'_account_id': 7549}, {'_account_id': 7600}, {'_account_id': 8127}, {'_account_id': 16272}]","[{'number': 1, 'created': '2015-06-18 14:40:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/project-config/commit/fa723cecd04214b1b58ed348fdeb21b601613fad', 'message': 'Make yaql py34 job voting\n\nChange-Id: I19ca0901e81a547173bfae2ca508776b5bfbe592\n'}, {'number': 2, 'created': '2015-06-18 15:49:29.000000000', 'files': ['zuul/layout.yaml'], 'web_link': 'https://opendev.org/openstack/project-config/commit/8619b71c4f00095b69eea33a76369dadc47d4445', 'message': 'Make yaql py34 job voting\n\nre-use python3-jobs template for yaql.\n\nChange-Id: I19ca0901e81a547173bfae2ca508776b5bfbe592\n'}]",0,193156,8619b71c4f00095b69eea33a76369dadc47d4445,18,9,2,7600,,,0,"Make yaql py34 job voting

re-use python3-jobs template for yaql.

Change-Id: I19ca0901e81a547173bfae2ca508776b5bfbe592
",git fetch https://review.opendev.org/openstack/project-config refs/changes/56/193156/2 && git format-patch -1 --stdout FETCH_HEAD,['zuul/layout.yaml'],1,fa723cecd04214b1b58ed348fdeb21b601613fad,,, - name: gate-yaql-python34 voting: false ,0,3
openstack%2Fproject-config~master~I908da6d9a74fbb2c4ae93ae7b3f04e1e8514708a,openstack/project-config,master,I908da6d9a74fbb2c4ae93ae7b3f04e1e8514708a,Add non-voting Neutron fullstack check job,MERGED,2015-06-21 19:56:49.000000000,2015-06-25 21:02:21.000000000,2015-06-25 21:02:17.000000000,"[{'_account_id': 3}, {'_account_id': 105}, {'_account_id': 2035}, {'_account_id': 2750}, {'_account_id': 5263}, {'_account_id': 6316}, {'_account_id': 6524}, {'_account_id': 6547}, {'_account_id': 8124}, {'_account_id': 8873}, {'_account_id': 9656}, {'_account_id': 12444}]","[{'number': 1, 'created': '2015-06-21 19:56:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/project-config/commit/685bc1b438180f8ca0b39ab3b2e9a3489fa42371', 'message': ""Add non-voting Neutron fullstack check job\n\nWhat are Neutron fullstack tests?\nhttp://goo.gl/3lNUSP\n\nFor more context, please see:\nhttps://bugs.launchpad.net/neutron/+bug/1467275\n\nRequirements:\n* Neutron fullstack tests have exactly the same runtime requirements\n  as Neutron functional tests. I sent a Neutron patch here:\n  https://review.openstack.org/#/c/193905/\n  That sets up the host environment.\n* This new check job should be non-voting to start, but I'll want\n  to transition it to voting and add it to the gate pipline\n  once it bakes a bit. We currently have exactly one fullstack test,\n  with a bunch more coming: https://goo.gl/7mYgWv + stability fixes.\n* It should not run on any stable branch as fullstack tests were\n  added after stable/kilo was cut.\n\nChange-Id: I908da6d9a74fbb2c4ae93ae7b3f04e1e8514708a\n""}, {'number': 2, 'created': '2015-06-21 19:57:51.000000000', 'files': ['jenkins/jobs/projects.yaml', 'jenkins/jobs/neutron.yaml', 'zuul/layout.yaml'], 'web_link': 'https://opendev.org/openstack/project-config/commit/9de970526f7dd11e372f608e2428603888de9069', 'message': ""Add non-voting Neutron fullstack check job\n\nWhat are Neutron fullstack tests?\nhttp://goo.gl/3lNUSP\n\nFor more context, please see:\nhttps://bugs.launchpad.net/neutron/+bug/1467275\n\nRequirements:\n* Neutron fullstack tests have exactly the same runtime requirements\n  as Neutron functional tests. I sent a Neutron patch here:\n  https://review.openstack.org/#/c/193905/\n  That sets up the host environment.\n* This new check job should be non-voting to start, but I'll want\n  to transition it to voting and add it to the gate pipline\n  once it bakes a bit. We currently have exactly one fullstack test,\n  with a bunch more coming: https://goo.gl/7mYgWv + stability fixes.\n* It should not run on any stable branch as fullstack tests were\n  added after stable/kilo was cut.\n\nDepends-On: I90f4794f48ae151a888f37df26c087a7fdcd9d31\nChange-Id: I908da6d9a74fbb2c4ae93ae7b3f04e1e8514708a\n""}]",0,193906,9de970526f7dd11e372f608e2428603888de9069,11,12,2,8873,,,0,"Add non-voting Neutron fullstack check job

What are Neutron fullstack tests?
http://goo.gl/3lNUSP

For more context, please see:
https://bugs.launchpad.net/neutron/+bug/1467275

Requirements:
* Neutron fullstack tests have exactly the same runtime requirements
  as Neutron functional tests. I sent a Neutron patch here:
  https://review.openstack.org/#/c/193905/
  That sets up the host environment.
* This new check job should be non-voting to start, but I'll want
  to transition it to voting and add it to the gate pipline
  once it bakes a bit. We currently have exactly one fullstack test,
  with a bunch more coming: https://goo.gl/7mYgWv + stability fixes.
* It should not run on any stable branch as fullstack tests were
  added after stable/kilo was cut.

Depends-On: I90f4794f48ae151a888f37df26c087a7fdcd9d31
Change-Id: I908da6d9a74fbb2c4ae93ae7b3f04e1e8514708a
",git fetch https://review.opendev.org/openstack/project-config refs/changes/06/193906/1 && git format-patch -1 --stdout FETCH_HEAD,"['jenkins/jobs/projects.yaml', 'jenkins/jobs/neutron.yaml', 'zuul/layout.yaml']",3,685bc1b438180f8ca0b39ab3b2e9a3489fa42371,neutron_fullstack, - name: check-neutron-dsvm-fullstack branch: ^(?!stable/(icehouse|juno|kilo)).*$ voting: false - check-neutron-dsvm-fullstack,,55,0
openstack%2Fproject-config~master~If0c4fb6c3d4c9aa26f8fea128d70fc1792df1387,openstack/project-config,master,If0c4fb6c3d4c9aa26f8fea128d70fc1792df1387,Add puppet-manager-core to puppet-monasca,MERGED,2015-06-22 17:50:03.000000000,2015-06-25 20:57:45.000000000,2015-06-25 20:57:39.000000000,"[{'_account_id': 3}, {'_account_id': 2750}, {'_account_id': 3153}, {'_account_id': 6547}, {'_account_id': 8126}, {'_account_id': 8482}, {'_account_id': 9500}]","[{'number': 1, 'created': '2015-06-22 17:50:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/project-config/commit/9e480992e62ef50e273d226abb3fbfdb15c23554', 'message': 'Add puppet-manager-core to puppet-monasca\n\nPuppet-manager-core needs rights to the puppet-monasca repo\n\nChange-Id: If0c4fb6c3d4c9aa26f8fea128d70fc1792df1387\n'}, {'number': 2, 'created': '2015-06-22 18:50:55.000000000', 'files': ['gerrit/acls/openstack/puppet-monasca.config'], 'web_link': 'https://opendev.org/openstack/project-config/commit/23d5a18310caa8a8719bde4d0257099d3ceaa8fa', 'message': 'Add puppet-manager-core to puppet-monasca\n\nPuppet-manager-core needs rights to the puppet-monasca repo\n\nChange-Id: If0c4fb6c3d4c9aa26f8fea128d70fc1792df1387\n'}]",1,194263,23d5a18310caa8a8719bde4d0257099d3ceaa8fa,16,7,2,9500,,,0,"Add puppet-manager-core to puppet-monasca

Puppet-manager-core needs rights to the puppet-monasca repo

Change-Id: If0c4fb6c3d4c9aa26f8fea128d70fc1792df1387
",git fetch https://review.opendev.org/openstack/project-config refs/changes/63/194263/2 && git format-patch -1 --stdout FETCH_HEAD,['gerrit/acls/openstack/puppet-monasca.config'],1,9e480992e62ef50e273d226abb3fbfdb15c23554,,abandon = group puppet-manager-corelabel-Code-Review = -2..+2 group puppet-manager-corelabel-Workflow = -1..+1 group puppet-manager-corepushSignedTag = group puppet-manager-core,,4,0
openstack%2Fdiskimage-builder~master~I4f67ef0295af8f2ae783fe3aea347b41987c6a66,openstack/diskimage-builder,master,I4f67ef0295af8f2ae783fe3aea347b41987c6a66,Wait longer for root device to become available,MERGED,2015-06-17 16:55:30.000000000,2015-06-25 20:43:01.000000000,2015-06-25 20:43:00.000000000,"[{'_account_id': 3}, {'_account_id': 6488}, {'_account_id': 9176}, {'_account_id': 10035}, {'_account_id': 10115}]","[{'number': 1, 'created': '2015-06-17 16:55:30.000000000', 'files': ['elements/deploy-ironic/init.d/80-deploy-ironic'], 'web_link': 'https://opendev.org/openstack/diskimage-builder/commit/05764de6e7d786f1f096c4c17c81640d590653a4', 'message': ""Wait longer for root device to become available\n\nOn some systems, it can take longer than 10 seconds for the root\ndisk to be detected.  Because enterprise hardware.  Increase the\nwait time to 60 seconds so we don't incorrectly fail due to a\nmissing root device.\n\nChange-Id: I4f67ef0295af8f2ae783fe3aea347b41987c6a66\n""}]",0,192768,05764de6e7d786f1f096c4c17c81640d590653a4,10,5,1,6928,,,0,"Wait longer for root device to become available

On some systems, it can take longer than 10 seconds for the root
disk to be detected.  Because enterprise hardware.  Increase the
wait time to 60 seconds so we don't incorrectly fail due to a
missing root device.

Change-Id: I4f67ef0295af8f2ae783fe3aea347b41987c6a66
",git fetch https://review.opendev.org/openstack/diskimage-builder refs/changes/68/192768/1 && git format-patch -1 --stdout FETCH_HEAD,['elements/deploy-ironic/init.d/80-deploy-ironic'],1,05764de6e7d786f1f096c4c17c81640d590653a4,wait-longer, if [ $t -eq 60 ]; then, if [ $t -eq 10 ]; then,1,1
openstack%2Fdiskimage-builder~master~Iff075e25eeb091650ac85ca1e1af7a1fd3394d3e,openstack/diskimage-builder,master,Iff075e25eeb091650ac85ca1e1af7a1fd3394d3e,Updated from global requirements,MERGED,2015-06-16 17:19:24.000000000,2015-06-25 20:41:30.000000000,2015-06-25 20:41:28.000000000,"[{'_account_id': 3}, {'_account_id': 6488}, {'_account_id': 10035}, {'_account_id': 16272}]","[{'number': 1, 'created': '2015-06-16 17:19:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/diskimage-builder/commit/aa383f1af3a14f5190205fedaa775d08363f3c36', 'message': 'Updated from global requirements\n\nChange-Id: Iff075e25eeb091650ac85ca1e1af7a1fd3394d3e\n'}, {'number': 2, 'created': '2015-06-22 08:20:18.000000000', 'files': ['requirements.txt', 'test-requirements.txt', 'setup.py'], 'web_link': 'https://opendev.org/openstack/diskimage-builder/commit/c4ab25365304792e69079dd58b78ab34cd50ea00', 'message': 'Updated from global requirements\n\nChange-Id: Iff075e25eeb091650ac85ca1e1af7a1fd3394d3e\n'}]",0,192296,c4ab25365304792e69079dd58b78ab34cd50ea00,13,4,2,11131,,,0,"Updated from global requirements

Change-Id: Iff075e25eeb091650ac85ca1e1af7a1fd3394d3e
",git fetch https://review.opendev.org/openstack/diskimage-builder refs/changes/96/192296/1 && git format-patch -1 --stdout FETCH_HEAD,['setup.py'],1,aa383f1af3a14f5190205fedaa775d08363f3c36,openstack/requirements,,,0,0
openstack%2Fneutron-fwaas~master~I32757cbbdaaea0547f653bd9bbdb9ccd2a0780ac,openstack/neutron-fwaas,master,I32757cbbdaaea0547f653bd9bbdb9ccd2a0780ac,Fixes firewall going to error state on an update,MERGED,2015-06-10 20:24:06.000000000,2015-06-25 20:40:26.000000000,2015-06-25 20:40:19.000000000,"[{'_account_id': 3}, {'_account_id': 105}, {'_account_id': 490}, {'_account_id': 704}, {'_account_id': 841}, {'_account_id': 6659}, {'_account_id': 6995}, {'_account_id': 8976}, {'_account_id': 10692}, {'_account_id': 10980}, {'_account_id': 11753}, {'_account_id': 12525}, {'_account_id': 13702}, {'_account_id': 14081}, {'_account_id': 14605}, {'_account_id': 15444}, {'_account_id': 16920}]","[{'number': 1, 'created': '2015-06-10 20:24:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-fwaas/commit/7340d431b561abc9354fa7f4258dbbb9a2a2a69f', 'message': ""Fixes firewall going to error state on a update\n\nWhenever an attribute of firewall rule, firewall policy or the firewall\nis updated, the firewall state is set to 'error'. The current code in the\nupdate_firewall method handles only the cases where routers are either\nadded, removed or both from a firewall. This commit also handles setting\nthe status correctly when other attributes are updated.\n\nCo-Authored by: vikram.choudhary <vikram.choudhary@huawei.com>\nCloses-Bug: #1455863\n\nChange-Id: I32757cbbdaaea0547f653bd9bbdb9ccd2a0780ac\n""}, {'number': 2, 'created': '2015-06-10 20:28:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-fwaas/commit/380bf7ef1e5816b5692963f6cd8ab0df95861ff5', 'message': ""Fixes firewall going to error state on an update\n\nWhenever an attribute of firewall rule, firewall policy or the firewall\nis updated, the firewall state is set to 'error'. The current code in the\nupdate_firewall method handles only the cases where routers are either\nadded, removed or both from a firewall. This commit also handles setting\nthe status correctly when other attributes are updated.\n\nCo-Authored by: vikram.choudhary <vikram.choudhary@huawei.com>\nCloses-Bug: #1455863\n\nChange-Id: I32757cbbdaaea0547f653bd9bbdb9ccd2a0780ac\n""}, {'number': 3, 'created': '2015-06-12 21:52:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-fwaas/commit/59d4b3c72a4fb8b0626e6a6c02a0bc597f821041', 'message': ""Fixes firewall going to error state on an update\n\nWhenever an attribute of firewall rule, firewall policy or the firewall\nis updated, the firewall state is set to 'error'. The current code in the\nupdate_firewall method handles only the cases where routers are either\nadded, removed or both from a firewall. This commit also handles setting\nthe status correctly when other attributes are updated.\n\nCo-Authored by: vikram.choudhary <vikram.choudhary@huawei.com>\nCloses-Bug: #1455863\n\nChange-Id: I32757cbbdaaea0547f653bd9bbdb9ccd2a0780ac\n""}, {'number': 4, 'created': '2015-06-15 05:07:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-fwaas/commit/37c373b097133e9506215305fe9b69412873a978', 'message': ""Fixes firewall going to error state on an update\n\nWhenever an attribute of firewall rule, firewall policy or the firewall\nis updated, the firewall state is set to 'error'. The current code in the\nupdate_firewall method handles only the cases where routers are either\nadded, removed or both from a firewall. This commit also handles setting\nthe status correctly when other attributes are updated.\n\nCo-Authored by: vikram.choudhary <vikram.choudhary@huawei.com>\nCloses-Bug: #1455863\n\nChange-Id: I32757cbbdaaea0547f653bd9bbdb9ccd2a0780ac\n""}, {'number': 5, 'created': '2015-06-15 22:24:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-fwaas/commit/ad71c5d78dfe82b8c91b461a4c3979b4dbbea1df', 'message': ""Fixes firewall going to error state on an update\n\nWhenever an attribute of firewall rule, firewall policy or the firewall\nis updated, the firewall state is set to 'error'. The current code in the\nupdate_firewall method handles only the cases where routers are either\nadded, removed or both from a firewall. This commit also handles setting\nthe status correctly when other attributes are updated.\n\nCo-Authored by: vikram.choudhary <vikram.choudhary@huawei.com>\nCloses-Bug: #1455863\n\nChange-Id: I32757cbbdaaea0547f653bd9bbdb9ccd2a0780ac\n""}, {'number': 6, 'created': '2015-06-18 05:05:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-fwaas/commit/c826497ffd4df72c4e385ad0b4918db04279a28f', 'message': ""Fixes firewall going to error state on an update\n\nWhenever an attribute of firewall rule, firewall policy or the firewall\nis updated, the firewall state is set to 'error'. The current code in the\nupdate_firewall method handles only the cases where routers are either\nadded, removed or both from a firewall. This commit also handles setting\nthe status correctly when other attributes are updated.\n\nCo-Authored by: vikram.choudhary <vikram.choudhary@huawei.com>\nCloses-Bug: #1455863\n\nChange-Id: I32757cbbdaaea0547f653bd9bbdb9ccd2a0780ac\n""}, {'number': 7, 'created': '2015-06-18 05:34:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-fwaas/commit/ecfb32710112ccc1175921057abb4b9cdf693cc1', 'message': ""Fixes firewall going to error state on an update\n\nWhenever an attribute of firewall rule, firewall policy or the firewall\nis updated, the firewall state is set to 'error'. The current code in the\nupdate_firewall method handles only the cases where routers are either\nadded, removed or both from a firewall. This commit also handles setting\nthe status correctly when other attributes are updated.\n\nCo-Authored by: vikram.choudhary <vikram.choudhary@huawei.com>\nCloses-Bug: #1455863\n\nChange-Id: I32757cbbdaaea0547f653bd9bbdb9ccd2a0780ac\n""}, {'number': 8, 'created': '2015-06-19 16:26:14.000000000', 'files': ['neutron_fwaas/tests/unit/services/firewall/agents/l3reference/test_firewall_l3_agent.py', 'neutron_fwaas/services/firewall/agents/l3reference/firewall_l3_agent.py'], 'web_link': 'https://opendev.org/openstack/neutron-fwaas/commit/09f2a5e4bab6185607bdf35cd07c75803bee0629', 'message': ""Fixes firewall going to error state on an update\n\nWhenever an attribute of firewall rule, firewall policy or the firewall\nis updated, the firewall state is set to 'error'. The current code in the\nupdate_firewall method handles only the cases where routers are either\nadded, removed or both from a firewall. This commit also handles setting\nthe status correctly when other attributes are updated.\n\nCo-Authored by: vikram.choudhary <vikram.choudhary@huawei.com>\nCloses-Bug: #1455863\n\nChange-Id: I32757cbbdaaea0547f653bd9bbdb9ccd2a0780ac\n""}]",25,190336,09f2a5e4bab6185607bdf35cd07c75803bee0629,71,17,8,12525,,,0,"Fixes firewall going to error state on an update

Whenever an attribute of firewall rule, firewall policy or the firewall
is updated, the firewall state is set to 'error'. The current code in the
update_firewall method handles only the cases where routers are either
added, removed or both from a firewall. This commit also handles setting
the status correctly when other attributes are updated.

Co-Authored by: vikram.choudhary <vikram.choudhary@huawei.com>
Closes-Bug: #1455863

Change-Id: I32757cbbdaaea0547f653bd9bbdb9ccd2a0780ac
",git fetch https://review.opendev.org/openstack/neutron-fwaas refs/changes/36/190336/1 && git format-patch -1 --stdout FETCH_HEAD,['neutron_fwaas/services/firewall/agents/l3reference/firewall_l3_agent.py'],1,7340d431b561abc9354fa7f4258dbbb9a2a2a69f,bug/14455863," # handle the add router and/or rule, policy, firewall # attribute updates router_info_list = [] status = constants.INACTIVE if firewall['admin_state_up']: status = constants.ACTIVE else: status = constants.DOWN # call into the driver try: self.fwaas_driver.update_firewall( self.conf.agent_mode, router_info_list, firewall) except fw_ext.FirewallInternalDriverError: LOG.error(_LE(""Firewall Driver Error for "" ""update_firewall for firewall: "" ""%(fwid)s""), {'fwid': firewall['id']}) status = constants.ERROR"," # the add # call into the driver try: self.fwaas_driver.update_firewall( self.conf.agent_mode, router_info_list, firewall) if firewall['admin_state_up']: status = constants.ACTIVE else: status = constants.DOWN except fw_ext.FirewallInternalDriverError: LOG.error(_LE(""Firewall Driver Error for "" ""update_firewall for firewall: "" ""%(fwid)s""), {'fwid': firewall['id']}) status = constants.ERROR",21,17
openstack%2Fneutron-fwaas~master~I2df519965883b05d5d58cdc4785c850b0685dc2c,openstack/neutron-fwaas,master,I2df519965883b05d5d58cdc4785c850b0685dc2c,Switch to oslo_utils.uuidutils,MERGED,2015-06-19 23:27:42.000000000,2015-06-25 20:38:24.000000000,2015-06-25 20:38:23.000000000,"[{'_account_id': 3}, {'_account_id': 105}, {'_account_id': 841}, {'_account_id': 6524}, {'_account_id': 6854}, {'_account_id': 7293}, {'_account_id': 9796}, {'_account_id': 10692}, {'_account_id': 10980}]","[{'number': 1, 'created': '2015-06-19 23:27:42.000000000', 'files': ['neutron_fwaas/tests/unit/db/firewall/test_firewall_db.py', 'neutron_fwaas/tests/unit/extensions/test_firewall.py', 'neutron_fwaas/db/firewall/firewall_db.py', 'neutron_fwaas/tests/unit/services/firewall/drivers/varmour/test_varmour_fwaas.py', 'neutron_fwaas/tests/unit/services/firewall/agents/varmour/test_varmour_router.py', 'neutron_fwaas/tests/unit/services/firewall/drivers/vyatta/test_vyatta_fwaas.py'], 'web_link': 'https://opendev.org/openstack/neutron-fwaas/commit/4957923f75f8d42d0bbf77c359a64b5920c75aab', 'message': 'Switch to oslo_utils.uuidutils\n\nGet rid of oslo-incubator uuidutils\n\nPartial-Bug: #1467020\nChange-Id: I2df519965883b05d5d58cdc4785c850b0685dc2c\n'}]",0,193756,4957923f75f8d42d0bbf77c359a64b5920c75aab,13,9,1,8124,,,0,"Switch to oslo_utils.uuidutils

Get rid of oslo-incubator uuidutils

Partial-Bug: #1467020
Change-Id: I2df519965883b05d5d58cdc4785c850b0685dc2c
",git fetch https://review.opendev.org/openstack/neutron-fwaas refs/changes/56/193756/1 && git format-patch -1 --stdout FETCH_HEAD,"['neutron_fwaas/tests/unit/db/firewall/test_firewall_db.py', 'neutron_fwaas/tests/unit/extensions/test_firewall.py', 'neutron_fwaas/db/firewall/firewall_db.py', 'neutron_fwaas/tests/unit/services/firewall/drivers/varmour/test_varmour_fwaas.py', 'neutron_fwaas/tests/unit/services/firewall/agents/varmour/test_varmour_router.py', 'neutron_fwaas/tests/unit/services/firewall/drivers/vyatta/test_vyatta_fwaas.py']",6,4957923f75f8d42d0bbf77c359a64b5920c75aab,bug/1467020,from oslo_utils import uuidutils,from neutron.openstack.common import uuidutils,7,6
openstack%2Fkolla~master~Ie0fa318541e16d730b7007d3620c7873e898ed4a,openstack/kolla,master,Ie0fa318541e16d730b7007d3620c7873e898ed4a,Add neutron-openvswitch-agent contianer,MERGED,2015-05-10 14:48:41.000000000,2015-06-25 20:36:55.000000000,2015-06-25 20:36:54.000000000,"[{'_account_id': 3}, {'_account_id': 2834}, {'_account_id': 10419}, {'_account_id': 10787}, {'_account_id': 14119}, {'_account_id': 15697}]","[{'number': 1, 'created': '2015-05-10 14:48:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla/commit/1e4f4ba042c253fc0898013d2fc81b5d75846856', 'message': 'WIP Add openvswitch contianer\n\nAdd neutron-openvswitch-agent contianer,\nnext add compose yml and config neutron-server.\n\nPartially Implements blueprint: openvswitch-container\n\nChange-Id: Ie0fa318541e16d730b7007d3620c7873e898ed4a\n'}, {'number': 2, 'created': '2015-06-09 03:34:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla/commit/c1e0c47c9e59d945802d5c7a8b68b384b116f9ef', 'message': 'WIP Add neutron-openvswitch-agent contianer\n\nAdd neutron-openvswitch-agent contianer,\nnext add compose yml and config neutron-server.\n\nPartially Implements blueprint: openvswitch-container\n\nChange-Id: Ie0fa318541e16d730b7007d3620c7873e898ed4a\n'}, {'number': 3, 'created': '2015-06-25 06:48:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla/commit/bfdb208cf4d4addab3f12e5ecd7ff9797c025eda', 'message': 'Add neutron-openvswitch-agent contianer\n\nAdd neutron-openvswitch-agent contianer,\nnext add compose yml and config neutron-server.\n\nCo-Authored-By: Sam Yaple <sam@yaple.net>\nPartially Implements blueprint: openvswitch-container\n\nChange-Id: Ie0fa318541e16d730b7007d3620c7873e898ed4a\n'}, {'number': 4, 'created': '2015-06-25 07:58:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla/commit/2fb76d0391458267ffb597b3a8b773c04e54a5b1', 'message': 'Add neutron-openvswitch-agent contianer\n\nAdd neutron-openvswitch-agent contianer,\nnext add compose yml and config neutron-server.\n\nCo-Authored-By: Sam Yaple <sam@yaple.net>\nPartially Implements blueprint: openvswitch-container\n\nChange-Id: Ie0fa318541e16d730b7007d3620c7873e898ed4a\n'}, {'number': 5, 'created': '2015-06-25 17:03:58.000000000', 'files': ['docker/common/neutron/neutron-openvswitch-agent/check.sh', 'docker/common/neutron/neutron-openvswitch-agent/start.sh', 'docs/integration-guide.md', 'docker/centos/binary/neutron/neutron-openvswitch-agent/start.sh', 'docker/centos/binary/neutron/neutron-openvswitch-agent/Dockerfile', 'docker/centos/binary/neutron/neutron-openvswitch-agent/build', 'docker/centos/binary/neutron/neutron-openvswitch-agent/check.sh'], 'web_link': 'https://opendev.org/openstack/kolla/commit/74010ff9869cb6e1232a4aa1a3b8de971c929040', 'message': 'Add neutron-openvswitch-agent contianer\n\nImplements the neutron-openvswitch-agent plugin container.\n\nCo-Authored-By: Sam Yaple <sam@yaple.net>\nPartially Implements blueprint: openvswitch-container\n\nChange-Id: Ie0fa318541e16d730b7007d3620c7873e898ed4a\n'}]",8,181737,74010ff9869cb6e1232a4aa1a3b8de971c929040,27,6,5,15697,,,0,"Add neutron-openvswitch-agent contianer

Implements the neutron-openvswitch-agent plugin container.

Co-Authored-By: Sam Yaple <sam@yaple.net>
Partially Implements blueprint: openvswitch-container

Change-Id: Ie0fa318541e16d730b7007d3620c7873e898ed4a
",git fetch https://review.opendev.org/openstack/kolla refs/changes/37/181737/5 && git format-patch -1 --stdout FETCH_HEAD,"['docker/neutron/neutron-openvswitch-agent/start.sh', 'docker/neutron/neutron-openvswitch-agent/config-sudoers.sh', 'docker/neutron/neutron-openvswitch-agent/Dockerfile', 'docker/neutron/neutron-openvswitch-agent/check.sh', 'docker/neutron/neutron-openvswitch-agent/build']",5,1e4f4ba042c253fc0898013d2fc81b5d75846856,bp/openvswitch-container,"#!/bin/bash TOPDIR=$(git rev-parse --show-toplevel) IMGDIR=""$(cd ""$(dirname ""$0"")"" && pwd)"" RELEASE_NAMESPACE=kollaglue NAMESPACE=kollaglue PREFIX=centos-rdo- TAG=$(git rev-parse --short HEAD) RELEASE_TAG=kilo usage () { cat <<EOF Usage: $0 [options] Options: --namespace, -n <namespace> --tag, -t <tag> --push, -p --no-cache, -N --release --no-use-released-parent EOF } [ -f $TOPDIR/.buildconf ] && . $TOPDIR/.buildconf [ -f $IMGDIR/.buildconf ] && . $IMGDIR/.buildconf ARGS=$(getopt -o hn:t:pN -l help,namespace:,push,release,tag:,no-cache,no-use-released-parent -- ""$@"") || { usage >&2; exit 2; } eval set -- ""$ARGS"" while :; do case ""$1"" in (--help|-h) usage exit 0 ;; (--release) MODE=release NAMESPACE=$RELEASE_NAMESPACE TAG=$RELEASE_TAG ;; (--tag|-t) shift TAG=""$1"" ;; (--push|-p) PUSH=1 ;; (--no-cache|-N) BUILDFLAGS=""${BUILDFLAGS} --no-cache"" ;; (--namespace|-n) shift NAMESPACE=""$1"" ;; (--no-use-released-parent) USE_CURRENT_TAG=1 ;; (--) break ;; esac shift done if [[ $USE_CURRENT_TAG = 1 ]]; then PARENT_TAG=$TAG else PARENT_TAG=$RELEASE_TAG fi if [ ""$NAMESPACE"" = ""$RELEASE_NAMESPACE"" ] \ && [ ""$TAG"" = ""$RELEASE_TAG"" ] \ && ! [ ""$MODE"" = ""release"" ]; then echo ""ERROR: use --release to build a release image"" >&2 exit 1 fi IMAGE=""${PREFIX}${IMGDIR##*/}"" FULLIMAGE=""${NAMESPACE}/${IMAGE}${TAG:+:${TAG}}"" cat <<EOF ====================================================================== $FULLIMAGE ====================================================================== EOF if [ ""$MODE"" = ""release"" ]; then echo ""*** YOU ARE BUILDING A RELEASE IMAGE ***"" echo fi TMPDIR=$(mktemp -d /tmp/kolla-build.XXXXXXXXXX) cp -aL $IMGDIR/* $TMPDIR # Use an extension for in-place editing for portability, as GNU and BSD # versions of sed behave differently otherwise sed -i.bak ""s/%%KOLLA_NAMESPACE%%/${NAMESPACE}/g"" $TMPDIR/Dockerfile sed -i.bak ""s/%%KOLLA_PREFIX%%/${PREFIX}/g"" $TMPDIR/Dockerfile sed -i.bak ""s/%%KOLLA_TAG%%/${PARENT_TAG}/g"" $TMPDIR/Dockerfile if ! docker build ${BUILDFLAGS} -t ""$FULLIMAGE"" $TMPDIR; then echo ""ERROR: failed to build $FULLIMAGE"" exit 1 fi rm -rf $TMPDIR echo ""Built: $FULLIMAGE"" if [ ""$PUSH"" = 1 ]; then if ! docker push ""$FULLIMAGE""; then echo ""ERROR: failed to push $FULLIMAGE"" exit 1 fi echo ""Pushed: $FULLIMAGE"" fi ",,213,0
openstack%2Fnova-powervm~master~I956f2fa7148586543e7e05863f4c16964f5433a8,openstack/nova-powervm,master,I956f2fa7148586543e7e05863f4c16964f5433a8,Implement snapshot,MERGED,2015-06-24 21:06:10.000000000,2015-06-25 20:29:07.000000000,2015-06-25 20:29:06.000000000,"[{'_account_id': 3}, {'_account_id': 8190}, {'_account_id': 8662}, {'_account_id': 13883}, {'_account_id': 14070}]","[{'number': 1, 'created': '2015-06-24 21:06:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova-powervm/commit/a9f2f53f998316f0bd1aaf71a6a5c788d1f8af1f', 'message': 'WIP: Implement snapshot\n\nImplement the snapshot method in the powervm driver.\n\nChange-Id: I956f2fa7148586543e7e05863f4c16964f5433a8\n'}, {'number': 2, 'created': '2015-06-24 23:13:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova-powervm/commit/90770cb883186a9a3e33515d2561ceaeabc7cfcb', 'message': 'Implement snapshot\n\nImplement the snapshot method in the powervm driver.\n\nChange-Id: I956f2fa7148586543e7e05863f4c16964f5433a8\n'}, {'number': 3, 'created': '2015-06-24 23:42:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova-powervm/commit/da81086562bdb834166349b37cfbc1e0da969e50', 'message': 'Implement snapshot\n\nImplement the snapshot method in the powervm driver.\n\nChange-Id: I956f2fa7148586543e7e05863f4c16964f5433a8\n'}, {'number': 4, 'created': '2015-06-25 15:42:22.000000000', 'files': ['nova_powervm/virt/powervm/driver.py', 'nova_powervm/tests/virt/powervm/test_driver.py'], 'web_link': 'https://opendev.org/openstack/nova-powervm/commit/806e302c6270151e9f1b0eebd07bb2e9d40f8fd5', 'message': 'Implement snapshot\n\nImplement the snapshot method in the powervm driver.\n\nChange-Id: I956f2fa7148586543e7e05863f4c16964f5433a8\n'}]",7,195316,806e302c6270151e9f1b0eebd07bb2e9d40f8fd5,22,5,4,14070,,,0,"Implement snapshot

Implement the snapshot method in the powervm driver.

Change-Id: I956f2fa7148586543e7e05863f4c16964f5433a8
",git fetch https://review.opendev.org/openstack/nova-powervm refs/changes/16/195316/2 && git format-patch -1 --stdout FETCH_HEAD,['nova_powervm/virt/powervm/driver.py'],1,a9f2f53f998316f0bd1aaf71a6a5c788d1f8af1f,snapshot,"from nova_powervm.virt.powervm.tasks import image as tf_img # Define the flow flow = lf.Flow(""snapshot"") # Notify that we're starting the process flow.add(tf_img.UpdateTaskState(update_task_state, task_states.IMAGE_PENDING_UPLOAD)) # Connect the instance's boot disk to the management partition, and # scan the scsi bus and bring the device into the management partition. flow.add(tf_stg.InstanceDiskToMgmt(self.disk_dvr, instance)) # Notify that the upload is in progress flow.add(tf_img.UpdateTaskState( update_task_state, task_states .IMAGE_UPLOADING, expected_state=task_states.IMAGE_PENDING_UPLOAD)) # Stream the disk to glance flow.add(tf_img.StreamToGlance(context, self.image_api, image_id, instance)) # Disconnect the boot disk from the management partition and delete the # device flow.add(tf_stg.RemoveInstanceDiskFromMgmt(self.disk_dvr, instance)) # Build the engine & run taskflow.engines.load(flow).run()", # TODO(IBM): Implement snapshot,28,1
openstack%2Fneutron-vpnaas~master~I4823d344878fc97e66ddd8fdae25c13a34dede40,openstack/neutron-vpnaas,master,I4823d344878fc97e66ddd8fdae25c13a34dede40,Switch to oslo.service,MERGED,2015-06-19 08:26:26.000000000,2015-06-25 20:25:23.000000000,2015-06-25 20:25:17.000000000,"[{'_account_id': 3}, {'_account_id': 105}, {'_account_id': 841}, {'_account_id': 5948}, {'_account_id': 6659}, {'_account_id': 6854}, {'_account_id': 7293}, {'_account_id': 8911}, {'_account_id': 9656}, {'_account_id': 10692}]","[{'number': 1, 'created': '2015-06-19 08:26:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-vpnaas/commit/c8a59525c50564833ec84bb699725941f1d9c261', 'message': '[WIP] Switch to oslo.service\n\nChange-Id: I4823d344878fc97e66ddd8fdae25c13a34dede40\nDepends-On: I305cf53bad6213c151395e93d656b53a8a28e1db\n'}, {'number': 2, 'created': '2015-06-19 12:54:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-vpnaas/commit/208c0edb62b92dfea250ef4226159cf78e1d28c5', 'message': 'Switch to oslo.service\n\noslo.service has graduated, so neutron_vpnaas should consume it.\n\nPartial-Bug: #1466851\nChange-Id: I4823d344878fc97e66ddd8fdae25c13a34dede40\nDepends-On: I305cf53bad6213c151395e93d656b53a8a28e1db\n'}, {'number': 3, 'created': '2015-06-19 14:06:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-vpnaas/commit/72e75346947069e0ef467f91cec5a2c1b2f8ca1b', 'message': 'Switch to oslo.service\n\noslo.service has graduated, so neutron_vpnaas should consume it.\n\nRegrouped external imports in\nneutron_vpnaas.services.vpn.device_drivers.vyatta_ipsec\n\nPartial-Bug: #1466851\nChange-Id: I4823d344878fc97e66ddd8fdae25c13a34dede40\nDepends-On: I305cf53bad6213c151395e93d656b53a8a28e1db\n'}, {'number': 4, 'created': '2015-06-22 10:08:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-vpnaas/commit/45143f3ebb83d4f329d02cb14205e762e931ad8e', 'message': 'Switch to oslo.service\n\noslo.service has graduated, so neutron_vpnaas should consume it.\n\nRegrouped external imports in\nneutron_vpnaas.services.vpn.device_drivers.vyatta_ipsec\n\nPartial-Bug: #1466851\nChange-Id: I4823d344878fc97e66ddd8fdae25c13a34dede40\nDepends-On: I305cf53bad6213c151395e93d656b53a8a28e1db\n'}, {'number': 5, 'created': '2015-06-25 09:20:09.000000000', 'files': ['neutron_vpnaas/tests/functional/strongswan/test_strongswan_driver.py', 'requirements.txt', 'neutron_vpnaas/services/vpn/device_drivers/vyatta_ipsec.py', 'neutron_vpnaas/tests/unit/services/vpn/device_drivers/test_ipsec.py', 'neutron_vpnaas/tests/unit/services/vpn/device_drivers/test_vyatta_ipsec.py', 'neutron_vpnaas/services/vpn/device_drivers/cisco_ipsec.py', 'neutron_vpnaas/services/vpn/device_drivers/ipsec.py'], 'web_link': 'https://opendev.org/openstack/neutron-vpnaas/commit/d5d884beec5139dd6189421c690acc1a314c2add', 'message': 'Switch to oslo.service\n\noslo.service has graduated, so neutron_vpnaas should consume it.\n\nRegrouped external imports in\nneutron_vpnaas.services.vpn.device_drivers.vyatta_ipsec\n\nPartial-Bug: #1466851\nChange-Id: I4823d344878fc97e66ddd8fdae25c13a34dede40\nDepends-On: I305cf53bad6213c151395e93d656b53a8a28e1db\n'}]",9,193455,d5d884beec5139dd6189421c690acc1a314c2add,53,10,5,7293,,,0,"Switch to oslo.service

oslo.service has graduated, so neutron_vpnaas should consume it.

Regrouped external imports in
neutron_vpnaas.services.vpn.device_drivers.vyatta_ipsec

Partial-Bug: #1466851
Change-Id: I4823d344878fc97e66ddd8fdae25c13a34dede40
Depends-On: I305cf53bad6213c151395e93d656b53a8a28e1db
",git fetch https://review.opendev.org/openstack/neutron-vpnaas refs/changes/55/193455/4 && git format-patch -1 --stdout FETCH_HEAD,"['neutron_vpnaas/tests/functional/strongswan/test_strongswan_driver.py', 'requirements.txt', 'neutron_vpnaas/services/vpn/device_drivers/vyatta_ipsec.py', 'neutron_vpnaas/tests/unit/services/vpn/device_drivers/test_ipsec.py', 'neutron_vpnaas/tests/unit/services/vpn/device_drivers/test_vyatta_ipsec.py', 'neutron_vpnaas/services/vpn/device_drivers/cisco_ipsec.py', 'neutron_vpnaas/services/vpn/device_drivers/ipsec.py']",7,c8a59525c50564833ec84bb699725941f1d9c261,bug/1466851,from oslo_service import loopingcall,from neutron.openstack.common import loopingcall,10,8
openstack%2Fmonasca-agent~master~I51fc4f2c2a50a84e8d75cbc8f47c8a4e78b2e4d4,openstack/monasca-agent,master,I51fc4f2c2a50a84e8d75cbc8f47c8a4e78b2e4d4,Create dropwizard plugin for collecting metrics via http,MERGED,2015-06-15 22:43:14.000000000,2015-06-25 20:21:34.000000000,2015-06-25 20:21:32.000000000,"[{'_account_id': 3}, {'_account_id': 11094}, {'_account_id': 12149}, {'_account_id': 15027}]","[{'number': 1, 'created': '2015-06-15 22:43:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/monasca-agent/commit/a216fe38a0025cdc9df2813d4bd399ffecde3203', 'message': 'Create dropwizard plugin for collecting metrics via http\n\nChange-Id: I51fc4f2c2a50a84e8d75cbc8f47c8a4e78b2e4d4\n'}, {'number': 2, 'created': '2015-06-19 20:21:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/monasca-agent/commit/da6ebe8480e013571ac5fab1dfac2e2cbc3e823d', 'message': 'Create dropwizard plugin for collecting metrics via http\n\nChange-Id: I51fc4f2c2a50a84e8d75cbc8f47c8a4e78b2e4d4\n'}, {'number': 3, 'created': '2015-06-24 17:22:14.000000000', 'files': ['monasca_agent/collector/checks_d/http_check.py', 'monasca_agent/collector/checks_d/http_metrics.py', 'conf.d/http_metrics.yaml.example', 'docs/Plugins.md', 'monasca_setup/detection/plugins/mon.py'], 'web_link': 'https://opendev.org/openstack/monasca-agent/commit/38b5ca8384740bfc6f10333b835a3d01ea7cd7a7', 'message': 'Create dropwizard plugin for collecting metrics via http\n\nChange-Id: I51fc4f2c2a50a84e8d75cbc8f47c8a4e78b2e4d4\n'}]",7,191999,38b5ca8384740bfc6f10333b835a3d01ea7cd7a7,14,4,3,14517,,,0,"Create dropwizard plugin for collecting metrics via http

Change-Id: I51fc4f2c2a50a84e8d75cbc8f47c8a4e78b2e4d4
",git fetch https://review.opendev.org/openstack/monasca-agent refs/changes/99/191999/1 && git format-patch -1 --stdout FETCH_HEAD,"['monasca_agent/collector/checks_d/dropwizard.py', 'monasca_setup/detection/plugins/mon.py']",2,a216fe38a0025cdc9df2813d4bd399ffecde3203,jah1611," config = monasca_setup.agent_config.Plugins() config.merge(dropwizard_health_check('monitoring', 'api', 'http://localhost:8081/healthcheck')) log.info(""\tEnabling the Monasca api metrics"") whitelist = [ ""jvm.memory.total.max"", ""jvm.memory.total.used"", ""monasca.api.app.MetricService.metrics.published"", ""org.skife.jdbi.v2.DBI.raw-sql"" ] config.merge(dropwizard_metrics('monitoring', 'api', 'http://localhost:8081/metrics', whitelist)) return config config = monasca_setup.agent_config.Plugins() config.merge(dropwizard_health_check('monitoring', 'persister', 'http://localhost:8091/healthcheck')) log.info(""\tEnabling the Monasca persister metrics"") whitelist = [ ""jvm.memory.total.max"", ""jvm.memory.total.used"", ""monasca.persister.pipeline.event.AlarmStateTransitionHandler[alarm-state-transition-0].alarm-state-transitions-added-to-batch-counter"", ""monasca.persister.pipeline.event.AlarmStateTransitionHandler[alarm-state-transition-1].alarm-state-transitions-added-to-batch-counter"", ""monasca.persister.pipeline.event.MetricHandler[metric-0].metrics-added-to-batch-counter"", ""monasca.persister.pipeline.event.MetricHandler[metric-1].metrics-added-to-batch-counter"", ""monasca.persister.pipeline.event.MetricHandler[metric-2].metrics-added-to-batch-counter"", ""monasca.persister.pipeline.event.MetricHandler[metric-3].metrics-added-to-batch-counter"", ] config.merge(dropwizard_metrics('monitoring', 'persister', 'http://localhost:8091/metrics', whitelist)) return config def dropwizard_metrics(service, component, url, whitelist): """"""Setup a dropwizard metrics check"""""" config = monasca_setup.agent_config.Plugins() config['dropwizard'] = {'init_config': None, 'instances': [{'name': ""{0}-{1} healthcheck"".format(service, component), 'url': url, 'timeout': 1, 'dimensions': {'service': service, 'component': component}, 'whitelist': whitelist}]} return config"," return dropwizard_health_check('monitoring', 'api', 'http://localhost:{0}/healthcheck'.format(admin_port)) return dropwizard_health_check('monitoring', 'persister', 'http://localhost:8091/healthcheck')",241,2
openstack%2Fastara~master~I47f25a661c91e2c36680230968ba9339eb7c8b6f,openstack/astara,master,I47f25a661c91e2c36680230968ba9339eb7c8b6f,Sync requirements with stable/kilo GR for release,ABANDONED,2015-05-11 18:12:50.000000000,2015-06-25 20:17:48.000000000,,"[{'_account_id': 3}, {'_account_id': 1420}, {'_account_id': 6923}]","[{'number': 1, 'created': '2015-05-11 18:12:50.000000000', 'files': ['requirements.txt', 'test-requirements.txt', 'setup.py'], 'web_link': 'https://opendev.org/openstack/astara/commit/89ade0e673c1457ed1b68f3ceaefe8b3aa79f4ec', 'message': 'Sync requirements with stable/kilo GR for release\n\nThis syncs requirements.txt and test-requirements.txt with\nglobal requirements in preparation for cutting our kilo\nrelease.\n\nThis drops the blessed package from our requirements as its not\nincluded in GR currently and is instead being injected by devstakck.\n\nChange-Id: I47f25a661c91e2c36680230968ba9339eb7c8b6f\n'}]",0,182007,89ade0e673c1457ed1b68f3ceaefe8b3aa79f4ec,5,3,1,1420,,,0,"Sync requirements with stable/kilo GR for release

This syncs requirements.txt and test-requirements.txt with
global requirements in preparation for cutting our kilo
release.

This drops the blessed package from our requirements as its not
included in GR currently and is instead being injected by devstakck.

Change-Id: I47f25a661c91e2c36680230968ba9339eb7c8b6f
",git fetch https://review.opendev.org/openstack/astara refs/changes/07/182007/1 && git format-patch -1 --stdout FETCH_HEAD,"['requirements.txt', 'test-requirements.txt', 'setup.py']",3,89ade0e673c1457ed1b68f3ceaefe8b3aa79f4ec,req_sync,"#!/usr/bin/env python # Copyright (c) 2013 Hewlett-Packard Development Company, L.P.# Licensed under the Apache License, Version 2.0 (the ""License""); # you may not use this file except in compliance with the License. # You may obtain a copy of the License at# http://www.apache.org/licenses/LICENSE-2.0# distributed under the License is distributed on an ""AS IS"" BASIS, # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or # implied. # See the License for the specific language governing permissions and # limitations under the License. # THIS FILE IS MANAGED BY THE GLOBAL REQUIREMENTS REPO - DO NOT EDIT# In python < 2.7.4, a lazy loading of package `pbr` will break # setuptools if some other modules registered functions in `atexit`. # solution from: http://bugs.python.org/issue15881#msg170215 try: import multiprocessing # noqa except ImportError: pass ","# Copyright 2014 DreamHost, LLC # Copyright 2015 Akanda, Inc# Author: DreamHost, LLC# Licensed under the Apache License, Version 2.0 (the ""License""); you may # not use this file except in compliance with the License. You may obtain # a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0# distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT # WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the # License for the specific language governing permissions and limitations # under the License. ",42,30
openstack%2Fastara-appliance~master~I016c2ec7e5d5882def4923835f526c84999da8c2,openstack/astara-appliance,master,I016c2ec7e5d5882def4923835f526c84999da8c2,Test experimental devstack image build (DO NOT MERGE),ABANDONED,2015-06-08 17:44:54.000000000,2015-06-25 20:17:43.000000000,,"[{'_account_id': 3}, {'_account_id': 1420}, {'_account_id': 6923}]","[{'number': 1, 'created': '2015-06-08 17:44:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/astara-appliance/commit/bd7fc9cb0c87f5875ca0d04c66997445f58e6165', 'message': 'Test experimental devstack image build (DO NOT MERGE)\n\nChange-Id: I016c2ec7e5d5882def4923835f526c84999da8c2\n'}, {'number': 2, 'created': '2015-06-08 19:29:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/astara-appliance/commit/635836f8441f1ff55bee9acb3759b7745ffa0588', 'message': 'Test experimental devstack image build (DO NOT MERGE)\n\nChange-Id: I016c2ec7e5d5882def4923835f526c84999da8c2\nDepends-On: I140227cad770fadfd4d2157149da2c6c65c2d1a2\n'}, {'number': 3, 'created': '2015-06-08 22:15:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/astara-appliance/commit/0c3fff21154817e0cbca92b0c7a04a1beea4db1a', 'message': 'Test experimental devstack image build (DO NOT MERGE)\n\nChange-Id: I016c2ec7e5d5882def4923835f526c84999da8c2\nDepends-On: I2b54ddfcce8dab446ac7418cca61320b370bc999\n'}, {'number': 4, 'created': '2015-06-11 18:05:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/astara-appliance/commit/4c7de6671606e08f06132aa715593d14e76d7894', 'message': 'Test broken experimental devstack image build (DO NOT MERGE)\n\nThis shoulld fail.\n\nChange-Id: I016c2ec7e5d5882def4923835f526c84999da8c2\n'}, {'number': 5, 'created': '2015-06-12 00:30:42.000000000', 'files': ['setup.cfg'], 'web_link': 'https://opendev.org/openstack/astara-appliance/commit/44ad149163435cd5ba009d66103c59f1867b7410', 'message': 'Test experimental devstack image build (DO NOT MERGE)\n\nChange-Id: I016c2ec7e5d5882def4923835f526c84999da8c2\nDepends-On: I75491db540bb4877e0de1a904ee2536d5e7c09f6\n'}]",0,189380,44ad149163435cd5ba009d66103c59f1867b7410,28,3,5,1420,,,0,"Test experimental devstack image build (DO NOT MERGE)

Change-Id: I016c2ec7e5d5882def4923835f526c84999da8c2
Depends-On: I75491db540bb4877e0de1a904ee2536d5e7c09f6
",git fetch https://review.opendev.org/openstack/astara-appliance refs/changes/80/189380/2 && git format-patch -1 --stdout FETCH_HEAD,['setup.cfg'],1,bd7fc9cb0c87f5875ca0d04c66997445f58e6165,experimental,# FOO,,1,0
openstack%2Fastara-appliance~master~I74bf5de7d69f7ec6e4e0a3989178addd20aa0468,openstack/astara-appliance,master,I74bf5de7d69f7ec6e4e0a3989178addd20aa0468,Sync requirements with stable/kilo GR for release,ABANDONED,2015-05-11 18:41:47.000000000,2015-06-25 20:17:39.000000000,,"[{'_account_id': 3}, {'_account_id': 1420}, {'_account_id': 2592}, {'_account_id': 6923}]","[{'number': 1, 'created': '2015-05-11 18:41:47.000000000', 'files': ['requirements.txt', 'test-requirements.txt', 'test_requirements.txt', 'setup.py', 'tox.ini'], 'web_link': 'https://opendev.org/openstack/astara-appliance/commit/6a588503e0288399288aca9687f0a36ed862151f', 'message': 'Sync requirements with stable/kilo GR for release\n\nThis syncs requirements.txt and test-requirements.txt with\nglobal requirements in preparation for cutting our kilo\nrelease.\n\nThis renames test_requirements.txt -> test-requirements.txt so\nit can be managed by GR.\n\nAlso, this drops gunicorn as something we track in requirements.txt\nThis is really an external requirement and not a python requirement,\nas nothing actually imports it.  This can be installed externally via\nthe appliance builder glue or devstack.\n\nChange-Id: I74bf5de7d69f7ec6e4e0a3989178addd20aa0468\n'}]",1,182011,6a588503e0288399288aca9687f0a36ed862151f,8,4,1,1420,,,0,"Sync requirements with stable/kilo GR for release

This syncs requirements.txt and test-requirements.txt with
global requirements in preparation for cutting our kilo
release.

This renames test_requirements.txt -> test-requirements.txt so
it can be managed by GR.

Also, this drops gunicorn as something we track in requirements.txt
This is really an external requirement and not a python requirement,
as nothing actually imports it.  This can be installed externally via
the appliance builder glue or devstack.

Change-Id: I74bf5de7d69f7ec6e4e0a3989178addd20aa0468
",git fetch https://review.opendev.org/openstack/astara-appliance refs/changes/11/182011/1 && git format-patch -1 --stdout FETCH_HEAD,"['requirements.txt', 'test-requirements.txt', 'test_requirements.txt', 'setup.py', 'tox.ini']",5,6a588503e0288399288aca9687f0a36ed862151f,req_sync,deps = -r{toxinidir}/test-requirements.txt,deps = -r{toxinidir}/test_requirements.txt,37,23
openstack%2Fneutron~master~I1ddbdef772ad1cee749e9ba2b782175cfd68433a,openstack/neutron,master,I1ddbdef772ad1cee749e9ba2b782175cfd68433a,Check that new lbaas CI scripting fails properly,ABANDONED,2015-06-25 02:47:55.000000000,2015-06-25 20:17:26.000000000,,"[{'_account_id': 3}, {'_account_id': 5170}, {'_account_id': 8645}, {'_account_id': 9681}, {'_account_id': 9682}, {'_account_id': 9787}, {'_account_id': 9845}, {'_account_id': 10153}, {'_account_id': 10387}, {'_account_id': 10980}, {'_account_id': 14323}]","[{'number': 1, 'created': '2015-06-25 02:47:55.000000000', 'files': ['neutron/server/__init__.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/c1a336774dfc9bb0653da4942d170d672d7327b7', 'message': 'Check that new lbaas CI scripting fails properly\n\nChange-Id: I1ddbdef772ad1cee749e9ba2b782175cfd68433a\nDepends-On: Iee43c68b4cc954b9780de02625de7e053ebd27b3\n'}]",1,195389,c1a336774dfc9bb0653da4942d170d672d7327b7,15,11,1,10980,,,0,"Check that new lbaas CI scripting fails properly

Change-Id: I1ddbdef772ad1cee749e9ba2b782175cfd68433a
Depends-On: Iee43c68b4cc954b9780de02625de7e053ebd27b3
",git fetch https://review.opendev.org/openstack/neutron refs/changes/89/195389/1 && git format-patch -1 --stdout FETCH_HEAD,['neutron/server/__init__.py'],1,c1a336774dfc9bb0653da4942d170d672d7327b7,negative-ci-check,hjkls ,,2,0
openstack%2Fastara~master~I3a1aea5cc63c8152f38b39873e91f790e2d89cfd,openstack/astara,master,I3a1aea5cc63c8152f38b39873e91f790e2d89cfd,Naming convention change router to instance (wip),ABANDONED,2015-06-25 05:44:51.000000000,2015-06-25 20:15:20.000000000,,"[{'_account_id': 3}, {'_account_id': 6287}, {'_account_id': 6923}, {'_account_id': 8005}]","[{'number': 1, 'created': '2015-06-25 05:44:51.000000000', 'files': ['akanda/rug/instance_manager.py', 'akanda/rug/test/unit/test_instance_manager.py'], 'web_link': 'https://opendev.org/openstack/astara/commit/63702b1e8983b771844baf204587d0b9110cb6b2', 'message': ""Naming convention change router to instance (wip)\n\nLots of things in the code are refered to as a router. This won't make\nsense when you are actually trying to manage another higher level service\nsuch as load balancing.\n\nChange-Id: I3a1aea5cc63c8152f38b39873e91f790e2d89cfd\n""}]",0,195416,63702b1e8983b771844baf204587d0b9110cb6b2,7,4,1,6287,,,0,"Naming convention change router to instance (wip)

Lots of things in the code are refered to as a router. This won't make
sense when you are actually trying to manage another higher level service
such as load balancing.

Change-Id: I3a1aea5cc63c8152f38b39873e91f790e2d89cfd
",git fetch https://review.opendev.org/openstack/astara refs/changes/16/195416/1 && git format-patch -1 --stdout FETCH_HEAD,"['akanda/rug/instance_manager.py', 'akanda/rug/test/unit/test_instance_manager.py']",2,63702b1e8983b771844baf204587d0b9110cb6b2,(detached, @mock.patch('akanda.rug.instance_manager.instance_api') @mock.patch('akanda.rug.instance_manager.instance_api') @mock.patch('akanda.rug.instance_manager.instance_api') @mock.patch('akanda.rug.instance_manager.instance_api') @mock.patch('akanda.rug.instance_manager.instance_api') @mock.patch('akanda.rug.instance_manager.instance_api') @mock.patch('akanda.rug.instance_manager.instance_api') @mock.patch('akanda.rug.instance_manager.instance_api') @mock.patch('akanda.rug.instance_manager.instance_api') @mock.patch('akanda.rug.instance_manager.instance_api') @mock.patch('akanda.rug.instance_manager.instance_api') @mock.patch('akanda.rug.instance_manager.instance_api') @mock.patch('akanda.rug.instance_manager.instance_api') @mock.patch('akanda.rug.instance_manager.instance_api') @mock.patch('akanda.rug.instance_manager.instance_api') @mock.patch('akanda.rug.instance_manager.instance_api') v = instance_manager.synchronize_status( v = instance_manager.synchronize_status( v = instance_manager.synchronize_status(, @mock.patch('akanda.rug.instance_manager.router_api') @mock.patch('akanda.rug.instance_manager.router_api') @mock.patch('akanda.rug.instance_manager.router_api') @mock.patch('akanda.rug.instance_manager.router_api') @mock.patch('akanda.rug.instance_manager.router_api') @mock.patch('akanda.rug.instance_manager.router_api') @mock.patch('akanda.rug.instance_manager.router_api') @mock.patch('akanda.rug.instance_manager.router_api') @mock.patch('akanda.rug.instance_manager.router_api') @mock.patch('akanda.rug.instance_manager.router_api') @mock.patch('akanda.rug.instance_manager.router_api') @mock.patch('akanda.rug.instance_manager.router_api') @mock.patch('akanda.rug.instance_manager.router_api') @mock.patch('akanda.rug.instance_manager.router_api') @mock.patch('akanda.rug.instance_manager.router_api') @mock.patch('akanda.rug.instance_manager.router_api') v = instance_manager.synchronize_router_status( v = instance_manager.synchronize_router_status( v = instance_manager.synchronize_router_status(,107,104
openstack%2Fnova-powervm~master~Ic72b7f42a0f51ce56272de39206895d9986414c4,openstack/nova-powervm,master,Ic72b7f42a0f51ce56272de39206895d9986414c4,Task for disconnecting and removing instance disk,MERGED,2015-06-24 20:15:02.000000000,2015-06-25 20:04:13.000000000,2015-06-25 20:04:11.000000000,"[{'_account_id': 3}, {'_account_id': 8190}, {'_account_id': 8662}, {'_account_id': 13883}, {'_account_id': 14070}]","[{'number': 1, 'created': '2015-06-24 20:15:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova-powervm/commit/d4ae28e9d4f672e04dec13c0bc11b6f15dea49c6', 'message': ""Task for disconnecting and removing instance disk\n\nNew nova_powervm.virt.powervm.tasks.storage.RemoveInstanceDiskFromMgmt\nTask class encompassing a) disconnecting an instance's boot disk from\nthe management partition, and b) removing that disk from the management\npartition.\n\nChange-Id: Ic72b7f42a0f51ce56272de39206895d9986414c4\n""}, {'number': 2, 'created': '2015-06-24 20:46:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova-powervm/commit/c07711ce3a9b3f0e188153419d83f61f2e51d495', 'message': ""Task for disconnecting and removing instance disk\n\nNew nova_powervm.virt.powervm.tasks.storage.RemoveInstanceDiskFromMgmt\nTask class encompassing a) disconnecting an instance's boot disk from\nthe management partition, and b) removing that disk from the management\npartition.\n\nChange-Id: Ic72b7f42a0f51ce56272de39206895d9986414c4\n""}, {'number': 3, 'created': '2015-06-24 21:59:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova-powervm/commit/91a8837331a594461994b54717acde7240e75559', 'message': ""Task for disconnecting and removing instance disk\n\nNew nova_powervm.virt.powervm.tasks.storage.RemoveInstanceDiskFromMgmt\nTask class encompassing a) disconnecting an instance's boot disk from\nthe management partition, and b) removing that disk from the management\npartition.\n\nChange-Id: Ic72b7f42a0f51ce56272de39206895d9986414c4\n""}, {'number': 4, 'created': '2015-06-24 23:31:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova-powervm/commit/fa0e821f7cd8fbf90c6f36b78de62a6dd360a411', 'message': ""Task for disconnecting and removing instance disk\n\nNew nova_powervm.virt.powervm.tasks.storage.RemoveInstanceDiskFromMgmt\nTask class encompassing a) disconnecting an instance's boot disk from\nthe management partition, and b) removing that disk from the management\npartition.\n\nChange-Id: Ic72b7f42a0f51ce56272de39206895d9986414c4\n""}, {'number': 5, 'created': '2015-06-25 15:09:21.000000000', 'files': ['nova_powervm/virt/powervm/tasks/storage.py', 'nova_powervm/tests/virt/powervm/tasks/test_storage.py'], 'web_link': 'https://opendev.org/openstack/nova-powervm/commit/c65b7f5bf37294e2a78deada51613ae13f5009fb', 'message': ""Task for disconnecting and removing instance disk\n\nNew nova_powervm.virt.powervm.tasks.storage.RemoveInstanceDiskFromMgmt\nTask class encompassing a) disconnecting an instance's boot disk from\nthe management partition, and b) removing that disk from the management\npartition.\n\nChange-Id: Ic72b7f42a0f51ce56272de39206895d9986414c4\n""}]",13,195293,c65b7f5bf37294e2a78deada51613ae13f5009fb,23,5,5,14070,,,0,"Task for disconnecting and removing instance disk

New nova_powervm.virt.powervm.tasks.storage.RemoveInstanceDiskFromMgmt
Task class encompassing a) disconnecting an instance's boot disk from
the management partition, and b) removing that disk from the management
partition.

Change-Id: Ic72b7f42a0f51ce56272de39206895d9986414c4
",git fetch https://review.opendev.org/openstack/nova-powervm refs/changes/93/195293/1 && git format-patch -1 --stdout FETCH_HEAD,"['nova_powervm/virt/powervm/tasks/storage.py', 'nova_powervm/tests/virt/powervm/tasks/test_storage.py']",2,d4ae28e9d4f672e04dec13c0bc11b6f15dea49c6,task_disconnect," disk_dvr.connect_instance_disk_to_mgmt = mock.Mock( return_value=(mock_stg, mock_vwrap)) disk_dvr.disconnect_disk_from_mgmt = mock.Mock() def reset_mocks(): mock_find.reset_mock() mock_discover.reset_mock() mock_rm.reset_mock() disk_dvr.connect_instance_disk_to_mgmt.reset_mock() disk_dvr.disconnect_disk_from_mgmt.reset_mock() disk_dvr.connect_instance_disk_to_mgmt.assert_called_with( mock_instance) disk_dvr.disconnect_disk_from_mgmt.assert_called_with('vios_uuid', 'stg_name') reset_mocks() disk_dvr.connect_instance_disk_to_mgmt.assert_called_with( mock_instance) disk_dvr.disconnect_disk_from_mgmt.assert_called_with('vios_uuid', 'stg_name') reset_mocks() disk_dvr.connect_instance_disk_to_mgmt.assert_called_with( mock_instance) # disconnect_disk_from_mgmt got called disk_dvr.disconnect_disk_from_mgmt.assert_called_with('vios_uuid', 'stg_name') # ...but remove_block_dev did not. reset_mocks() disk_dvr.connect_instance_disk_to_mgmt.side_effect = ( npvmex.InstanceDiskMappingFailed(instance_name='inst_name')) disk_dvr.connect_instance_disk_to_mgmt.assert_called_with( mock_instance) self.assertEqual(0, disk_dvr.disconnect_disk_from_mgmt.call_count) @mock.patch('nova_powervm.virt.powervm.mgmt.remove_block_dev') def test_remove_instance_disk_from_mgmt(self, mock_rm): disk_dvr = mock.MagicMock() disk_dvr.disconnect_disk_from_mgmt = mock.Mock() mock_instance = mock.Mock() mock_instance.name = 'instance_name' mock_stg = mock.Mock() mock_stg.name = 'stg_name' mock_vwrap = mock.Mock() mock_vwrap.name = 'vios_name' mock_vwrap.uuid = 'vios_uuid' tf = tf_stg.RemoveInstanceDiskFromMgmt(disk_dvr, mock_instance) self.assertEqual('remove_inst_disk_from_mgmt', tf.name) tf.execute(mock_stg, mock_vwrap, '/dev/disk') disk_dvr.disconnect_disk_from_mgmt.assert_called_with('vios_uuid', 'stg_name') mock_rm.assert_called_with('/dev/disk')"," def verify_connect(inst): self.assertEqual(mock_instance, inst) return mock_stg, mock_vwrap def verify_disconnect(vios_uuid, stg_name): self.assertEqual('vios_uuid', vios_uuid) self.assertEqual('stg_name', stg_name) disk_dvr.connect_instance_disk_to_mgmt = verify_connect disk_dvr.disconnect_disk_from_mgmt = verify_disconnect mock_find.reset_mock() mock_discover.reset_mock() mock_rm.reset_mock() mock_find.reset_mock() mock_discover.reset_mock() mock_rm.reset_mock() # disconnect_disk_from_mgmt got called (still checked by # verify_disconnect above), but remove_block_dev did not. mock_find.reset_mock() mock_discover.reset_mock() mock_rm.reset_mock() disk_dvr.connect_instance_disk_to_mgmt = mock.Mock( side_effect=npvmex.InstanceDiskMappingFailed( instance_name='inst_name')) disk_dvr.disconnect_disk_from_mgmt = mock.Mock(side_effect=self.fail)",99,25
openstack%2Fkolla~master~I85c9a4698edbb350d5950bbe452cbf745f5e2b33,openstack/kolla,master,I85c9a4698edbb350d5950bbe452cbf745f5e2b33,Add warnings about running on F22 and later,MERGED,2015-06-25 16:05:00.000000000,2015-06-25 20:03:43.000000000,2015-06-25 20:03:40.000000000,"[{'_account_id': 3}, {'_account_id': 2834}, {'_account_id': 3098}, {'_account_id': 10428}, {'_account_id': 14119}]","[{'number': 1, 'created': '2015-06-25 16:05:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla/commit/f9f6cc8ad8ecfc7b1915660e5501a70de1626f03', 'message': 'Add warnings about running on F22 and later\n\nThe supermin tool in the centos container needs to be updated\nto supoprt reading kernel modules with the .zx format that\nFedora 22 introduces as a new feature.\n\nChange-Id: I85c9a4698edbb350d5950bbe452cbf745f5e2b33\nCloses-Bug: #1468056\n'}, {'number': 2, 'created': '2015-06-25 16:32:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla/commit/28ff9c4d4b5f00f74738ff0eb76bf050aae3b798', 'message': 'Add warnings about running on F22 and later\n\nThe supermin tool in the centos container needs to be updated\nto supoprt reading kernel modules with the .zx format that\nFedora 22 introduces as a new feature.\n\nChange-Id: I85c9a4698edbb350d5950bbe452cbf745f5e2b33\nCloses-Bug: #1468056\n'}, {'number': 3, 'created': '2015-06-25 16:38:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla/commit/5d6afd8709185fcc7558f985794e01f0cb4726ee', 'message': 'Add warnings about running on F22 and later\n\nThe supermin tool in the centos container needs to be updated\nto supoprt reading kernel modules with the .xz compressed format\nthat Fedora 22 introduces as a new feature.\n\nChange-Id: I85c9a4698edbb350d5950bbe452cbf745f5e2b33\nCloses-Bug: #1468056\n'}, {'number': 4, 'created': '2015-06-25 16:41:14.000000000', 'files': ['docs/dev-quickstart.md'], 'web_link': 'https://opendev.org/openstack/kolla/commit/d0403fcd675c6eedfc7b0a89a1fc7aca40713efb', 'message': 'Add warnings about running on F22 and later\n\nThe supermin tool in the centos container needs to be updated\nto supoprt reading kernel modules with the .xz compressed format\nthat Fedora 22 introduces as a new feature.\n\nChange-Id: I85c9a4698edbb350d5950bbe452cbf745f5e2b33\nCloses-Bug: #1468056\n'}]",4,195654,d0403fcd675c6eedfc7b0a89a1fc7aca40713efb,17,5,4,2834,,,0,"Add warnings about running on F22 and later

The supermin tool in the centos container needs to be updated
to supoprt reading kernel modules with the .xz compressed format
that Fedora 22 introduces as a new feature.

Change-Id: I85c9a4698edbb350d5950bbe452cbf745f5e2b33
Closes-Bug: #1468056
",git fetch https://review.opendev.org/openstack/kolla refs/changes/54/195654/4 && git format-patch -1 --stdout FETCH_HEAD,['docs/dev-quickstart.md'],1,f9f6cc8ad8ecfc7b1915660e5501a70de1626f03,bug/1468056,NB: Kolla will not run on Fedora 22 or later. Fedora 22 compresses kernel modules with the .zx format. THe guestfs system cannot read these images because a dependent package supermin in CentOS needs to be updated to add .zx format support. ,,5,0
openstack%2Fastara~master~I8ad2bc3f72888dfe43dd3a966cafee4ee2163131,openstack/astara,master,I8ad2bc3f72888dfe43dd3a966cafee4ee2163131,naming convention change vm to instance,MERGED,2015-06-25 04:00:08.000000000,2015-06-25 19:58:27.000000000,2015-06-25 19:58:27.000000000,"[{'_account_id': 3}, {'_account_id': 2592}, {'_account_id': 6923}]","[{'number': 1, 'created': '2015-06-25 04:00:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/astara/commit/7b7752c75bf393bb4101d6b7574b4780f95a3f0d', 'message': 'naming convention change vm to instance\n\nvm_manager = instance_manager\nVMManager = Instance_Manager\nvm = instance\n\nChange-Id: I8ad2bc3f72888dfe43dd3a966cafee4ee2163131\n'}, {'number': 2, 'created': '2015-06-25 04:22:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/astara/commit/4833d64e8a511a3db2c2560370e614d2cc058624', 'message': 'naming convention change vm to instance\n\nvm_manager = instance_manager\nVMManager = Instance_Manager\nvm = instance\n\nChange-Id: I8ad2bc3f72888dfe43dd3a966cafee4ee2163131\n'}, {'number': 3, 'created': '2015-06-25 04:55:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/astara/commit/26d9e3b85cc3fe0b471632dc7f91752b7f5e2908', 'message': 'naming convention change vm to instance\n\nvm_manager = instance_manager\nVMManager = Instance_Manager\nvm = instance\n\nChange-Id: I8ad2bc3f72888dfe43dd3a966cafee4ee2163131\n'}, {'number': 4, 'created': '2015-06-25 05:00:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/astara/commit/17b0d8d17b1b55a3ad41cd1e4377454bc898f5a3', 'message': 'naming convention change vm to instance\n\nvm_manager = instance_manager\nVMManager = Instance_Manager\nvm = instance\n\nChange-Id: I8ad2bc3f72888dfe43dd3a966cafee4ee2163131\n'}, {'number': 5, 'created': '2015-06-25 05:23:07.000000000', 'files': ['akanda/rug/api/nova.py', 'akanda/rug/test/unit/api/test_configuration.py', '.gitignore', 'akanda/rug/state.py', 'akanda/rug/instance_manager.py', 'akanda/rug/test/unit/test_tenant.py', 'akanda/rug/test/functional/test_service_vm.py', 'akanda/rug/test/functional/base.py', 'akanda/rug/test/functional/test_service_instance.py', 'akanda/rug/test/unit/test_instance_manager.py', 'akanda/rug/test/unit/test_state.py'], 'web_link': 'https://opendev.org/openstack/astara/commit/a227ab593b602549dbd3ec41d754193a3b463bc4', 'message': 'naming convention change vm to instance\n\nvm_manager = instance_manager\nVMManager = InstanceManager\nvm = instance\n\nChange-Id: I8ad2bc3f72888dfe43dd3a966cafee4ee2163131\n'}]",0,195404,a227ab593b602549dbd3ec41d754193a3b463bc4,16,3,5,6287,,,0,"naming convention change vm to instance

vm_manager = instance_manager
VMManager = InstanceManager
vm = instance

Change-Id: I8ad2bc3f72888dfe43dd3a966cafee4ee2163131
",git fetch https://review.opendev.org/openstack/astara refs/changes/04/195404/1 && git format-patch -1 --stdout FETCH_HEAD,"['akanda/rug/test/unit/api/test_configuration.py', '.gitignore', 'akanda/rug/state.py', 'akanda/rug/instance_manager.py', 'akanda/rug/test/functional/test_service_vm.py', 'akanda/rug/test/functional/base.py', 'akanda/rug/test/functional/test_service_instance.py', 'akanda/rug/test/unit/test_instance_manager.py', 'akanda/rug/api/nova.py', 'akanda/rug/test/unit/test_tenant.py', 'akanda/rug/test/unit/test_state.py', 'akanda/rug/openstack/common/log.py']",12,7b7752c75bf393bb4101d6b7574b4780f95a3f0d,(detached,"# Copyright 2014 DreamHost, LLC # # Author: DreamHost, LLC # # Licensed under the Apache License, Version 2.0 (the ""License""); you may # not use this file except in compliance with the License. You may obtain # a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT # WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the # License for the specific language governing permissions and limitations # under the License. # vim: tabstop=4 shiftwidth=4 softtabstop=4 # Copyright 2011 OpenStack Foundation. # Copyright 2010 United States Government as represented by the # Administrator of the National Aeronautics and Space Administration. # All Rights Reserved. # # Licensed under the Apache License, Version 2.0 (the ""License""); you may # not use this file except in compliance with the License. You may obtain # a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT # WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the # License for the specific language governing permissions and limitations # under the License. """"""Openstack logging handler. This module adds to logging functionality by adding the option to specify a context object when calling the various log methods. If the context object is not specified, default formatting is used. Additionally, an instance uuid may be passed as part of the log message, which is intended to make it easier for admins to find messages related to a specific instance. It also allows setting of formatting information through conf. """""" import cStringIO import inspect import itertools import logging import logging.config import logging.handlers import os import stat import sys import traceback from oslo.config import cfg from akanda.rug.openstack.common.gettextutils import _ from akanda.rug.openstack.common import jsonutils from akanda.rug.openstack.common import local from akanda.rug.openstack.common import notifier _DEFAULT_LOG_FORMAT = ""%(asctime)s %(levelname)8s [%(name)s] %(message)s"" _DEFAULT_LOG_DATE_FORMAT = ""%Y-%m-%d %H:%M:%S"" common_cli_opts = [ cfg.BoolOpt('debug', short='d', default=False, help='Print debugging output (set logging level to ' 'DEBUG instead of default WARNING level).'), cfg.BoolOpt('verbose', short='v', default=False, help='Print more verbose output (set logging level to ' 'INFO instead of default WARNING level).'), ] logging_cli_opts = [ cfg.StrOpt('log-config', metavar='PATH', help='If this option is specified, the logging configuration ' 'file specified is used and overrides any other logging ' 'options specified. Please see the Python logging module ' 'documentation for details on logging configuration ' 'files.'), cfg.StrOpt('log-format', default=_DEFAULT_LOG_FORMAT, metavar='FORMAT', help='A logging.Formatter log message format string which may ' 'use any of the available logging.LogRecord attributes. ' 'Default: %(default)s'), cfg.StrOpt('log-date-format', default=_DEFAULT_LOG_DATE_FORMAT, metavar='DATE_FORMAT', help='Format string for %%(asctime)s in log records. ' 'Default: %(default)s'), cfg.StrOpt('log-file', metavar='PATH', deprecated_name='logfile', help='(Optional) Name of log file to output to. ' 'If no default is set, logging will go to stdout.'), cfg.StrOpt('log-dir', deprecated_name='logdir', help='(Optional) The base directory used for relative ' '--log-file paths'), cfg.BoolOpt('use-syslog', default=False, help='Use syslog for logging.'), cfg.StrOpt('syslog-log-facility', default='LOG_USER', help='syslog facility to receive log lines') ] generic_log_opts = [ cfg.BoolOpt('use_stderr', default=True, help='Log output to standard error'), cfg.StrOpt('logfile_mode', default='0644', help='Default file mode used when creating log files'), ] log_opts = [ cfg.StrOpt('logging_context_format_string', default='%(asctime)s.%(msecs)03d %(levelname)s %(name)s ' '[%(request_id)s %(user)s %(tenant)s] %(instance)s' '%(message)s', help='format string to use for log messages with context'), cfg.StrOpt('logging_default_format_string', default='%(asctime)s.%(msecs)03d %(process)d %(levelname)s ' '%(name)s [-] %(instance)s%(message)s', help='format string to use for log messages without context'), cfg.StrOpt('logging_debug_format_suffix', default='%(funcName)s %(pathname)s:%(lineno)d', help='data to append to log format when level is DEBUG'), cfg.StrOpt('logging_exception_prefix', default='%(asctime)s.%(msecs)03d %(process)d TRACE %(name)s ' '%(instance)s', help='prefix each line of exception output with this format'), cfg.ListOpt('default_log_levels', default=[ 'amqplib=WARN', 'sqlalchemy=WARN', 'boto=WARN', 'suds=INFO', 'keystone=INFO', 'eventlet.wsgi.server=WARN' ], help='list of logger=LEVEL pairs'), cfg.BoolOpt('publish_errors', default=False, help='publish error events'), cfg.BoolOpt('fatal_deprecations', default=False, help='make deprecations fatal'), # NOTE(mikal): there are two options here because sometimes we are handed # a full instance (and could include more information), and other times we # are just handed a UUID for the instance. cfg.StrOpt('instance_format', default='[instance: %(uuid)s] ', help='If an instance is passed with the log message, format ' 'it like this'), cfg.StrOpt('instance_uuid_format', default='[instance: %(uuid)s] ', help='If an instance UUID is passed with the log message, ' 'format it like this'), ] CONF = cfg.CONF CONF.register_cli_opts(common_cli_opts) CONF.register_cli_opts(logging_cli_opts) CONF.register_opts(generic_log_opts) CONF.register_opts(log_opts) # our new audit level # NOTE(jkoelker) Since we synthesized an audit level, make the logging # module aware of it so it acts like other levels. logging.AUDIT = logging.INFO + 1 logging.addLevelName(logging.AUDIT, 'AUDIT') try: NullHandler = logging.NullHandler except AttributeError: # NOTE(jkoelker) NullHandler added in Python 2.7 class NullHandler(logging.Handler): def handle(self, record): pass def emit(self, record): pass def createLock(self): self.lock = None def _dictify_context(context): if context is None: return None if not isinstance(context, dict) and getattr(context, 'to_dict', None): context = context.to_dict() return context def _get_binary_name(): return os.path.basename(inspect.stack()[-1][1]) def _get_log_file_path(binary=None): logfile = CONF.log_file logdir = CONF.log_dir if logfile and not logdir: return logfile if logfile and logdir: return os.path.join(logdir, logfile) if logdir: binary = binary or _get_binary_name() return '%s.log' % (os.path.join(logdir, binary),) class ContextAdapter(logging.LoggerAdapter): warn = logging.LoggerAdapter.warning def __init__(self, logger, project_name, version_string): self.logger = logger self.project = project_name self.version = version_string def audit(self, msg, *args, **kwargs): self.log(logging.AUDIT, msg, *args, **kwargs) def deprecated(self, msg, *args, **kwargs): stdmsg = _(""Deprecated: %s"") % msg if CONF.fatal_deprecations: self.critical(stdmsg, *args, **kwargs) raise DeprecatedConfig(msg=stdmsg) else: self.warn(stdmsg, *args, **kwargs) def process(self, msg, kwargs): if 'extra' not in kwargs: kwargs['extra'] = {} extra = kwargs['extra'] context = kwargs.pop('context', None) if not context: context = getattr(local.store, 'context', None) if context: extra.update(_dictify_context(context)) instance = kwargs.pop('instance', None) instance_extra = '' if instance: instance_extra = CONF.instance_format % instance else: instance_uuid = kwargs.pop('instance_uuid', None) if instance_uuid: instance_extra = (CONF.instance_uuid_format % {'uuid': instance_uuid}) extra.update({'instance': instance_extra}) extra.update({""project"": self.project}) extra.update({""version"": self.version}) extra['extra'] = extra.copy() return msg, kwargs class JSONFormatter(logging.Formatter): def __init__(self, fmt=None, datefmt=None): # NOTE(jkoelker) we ignore the fmt argument, but its still there # since logging.config.fileConfig passes it. self.datefmt = datefmt def formatException(self, ei, strip_newlines=True): lines = traceback.format_exception(*ei) if strip_newlines: lines = [itertools.ifilter( lambda x: x, line.rstrip().splitlines()) for line in lines] lines = list(itertools.chain(*lines)) return lines def format(self, record): message = {'message': record.getMessage(), 'asctime': self.formatTime(record, self.datefmt), 'name': record.name, 'msg': record.msg, 'args': record.args, 'levelname': record.levelname, 'levelno': record.levelno, 'pathname': record.pathname, 'filename': record.filename, 'module': record.module, 'lineno': record.lineno, 'funcname': record.funcName, 'created': record.created, 'msecs': record.msecs, 'relative_created': record.relativeCreated, 'thread': record.thread, 'thread_name': record.threadName, 'process_name': record.processName, 'process': record.process, 'traceback': None} if hasattr(record, 'extra'): message['extra'] = record.extra if record.exc_info: message['traceback'] = self.formatException(record.exc_info) return jsonutils.dumps(message) class PublishErrorsHandler(logging.Handler): def emit(self, record): if ('akanda.rug.openstack.common.notifier.log_notifier' in CONF.notification_driver): return notifier.api.notify(None, 'error.publisher', 'error_notification', notifier.api.ERROR, dict(error=record.msg)) def _create_logging_excepthook(product_name): def logging_excepthook(type, value, tb): extra = {} if CONF.verbose: extra['exc_info'] = (type, value, tb) getLogger(product_name).critical(str(value), **extra) return logging_excepthook def setup(product_name): """"""Setup logging."""""" if CONF.log_config: logging.config.fileConfig(CONF.log_config) else: _setup_logging_from_conf() sys.excepthook = _create_logging_excepthook(product_name) def set_defaults(logging_context_format_string): cfg.set_defaults( log_opts, logging_context_format_string=logging_context_format_string, ) def _find_facility_from_conf(): facility_names = logging.handlers.SysLogHandler.facility_names facility = getattr(logging.handlers.SysLogHandler, CONF.syslog_log_facility, None) if facility is None and CONF.syslog_log_facility in facility_names: facility = facility_names.get(CONF.syslog_log_facility) if facility is None: valid_facilities = facility_names.keys() consts = ['LOG_AUTH', 'LOG_AUTHPRIV', 'LOG_CRON', 'LOG_DAEMON', 'LOG_FTP', 'LOG_KERN', 'LOG_LPR', 'LOG_MAIL', 'LOG_NEWS', 'LOG_AUTH', 'LOG_SYSLOG', 'LOG_USER', 'LOG_UUCP', 'LOG_LOCAL0', 'LOG_LOCAL1', 'LOG_LOCAL2', 'LOG_LOCAL3', 'LOG_LOCAL4', 'LOG_LOCAL5', 'LOG_LOCAL6', 'LOG_LOCAL7'] valid_facilities.extend(consts) raise TypeError(_('syslog facility must be one of: %s') % ', '.join(""'%s'"" % fac for fac in valid_facilities)) return facility def _setup_logging_from_conf(): log_root = getLogger(None).logger for handler in log_root.handlers: log_root.removeHandler(handler) if CONF.use_syslog: facility = _find_facility_from_conf() syslog = logging.handlers.SysLogHandler(address='/dev/log', facility=facility) log_root.addHandler(syslog) logpath = _get_log_file_path() if logpath: filelog = logging.handlers.WatchedFileHandler(logpath) log_root.addHandler(filelog) mode = int(CONF.logfile_mode, 8) st = os.stat(logpath) if st.st_mode != (stat.S_IFREG | mode): os.chmod(logpath, mode) if CONF.use_stderr: streamlog = ColorHandler() log_root.addHandler(streamlog) elif not CONF.log_file: # pass sys.stdout as a positional argument # python2.6 calls the argument strm, in 2.7 it's stream streamlog = logging.StreamHandler(sys.stdout) log_root.addHandler(streamlog) if CONF.publish_errors: log_root.addHandler(PublishErrorsHandler(logging.ERROR)) for handler in log_root.handlers: datefmt = CONF.log_date_format if CONF.log_format: handler.setFormatter(logging.Formatter(fmt=CONF.log_format, datefmt=datefmt)) else: handler.setFormatter(LegacyFormatter(datefmt=datefmt)) if CONF.debug: log_root.setLevel(logging.DEBUG) elif CONF.verbose: log_root.setLevel(logging.INFO) else: log_root.setLevel(logging.WARNING) level = logging.NOTSET for pair in CONF.default_log_levels: mod, _sep, level_name = pair.partition('=') level = logging.getLevelName(level_name) logger = logging.getLogger(mod) logger.setLevel(level) for handler in log_root.handlers: logger.addHandler(handler) _loggers = {} def getLogger(name='unknown', version='unknown'): if name not in _loggers: _loggers[name] = ContextAdapter(logging.getLogger(name), name, version) return _loggers[name] class WritableLogger(object): """"""A thin wrapper that responds to `write` and logs."""""" def __init__(self, logger, level=logging.INFO): self.logger = logger self.level = level def write(self, msg): self.logger.log(self.level, msg) class LegacyFormatter(logging.Formatter): """"""A context.RequestContext aware formatter configured through flags. The flags used to set format strings are: logging_context_format_string and logging_default_format_string. You can also specify logging_debug_format_suffix to append extra formatting if the log level is debug. For information about what variables are available for the formatter see: http://docs.python.org/library/logging.html#formatter """""" def format(self, record): """"""Uses contextstring if request_id is set, otherwise default."""""" # NOTE(sdague): default the fancier formating params # to an empty string so we don't throw an exception if # they get used for key in ('instance', 'color'): if key not in record.__dict__: record.__dict__[key] = '' if record.__dict__.get('request_id', None): self._fmt = CONF.logging_context_format_string else: self._fmt = CONF.logging_default_format_string if (record.levelno == logging.DEBUG and CONF.logging_debug_format_suffix): self._fmt += "" "" + CONF.logging_debug_format_suffix # Cache this on the record, Logger will respect our formated copy if record.exc_info: record.exc_text = self.formatException(record.exc_info, record) return logging.Formatter.format(self, record) def formatException(self, exc_info, record=None): """"""Format exception output with CONF.logging_exception_prefix."""""" if not record: return logging.Formatter.formatException(self, exc_info) stringbuffer = cStringIO.StringIO() traceback.print_exception(exc_info[0], exc_info[1], exc_info[2], None, stringbuffer) lines = stringbuffer.getvalue().split('\n') stringbuffer.close() if CONF.logging_exception_prefix.find('%(asctime)') != -1: record.asctime = self.formatTime(record, self.datefmt) formatted_lines = [] for line in lines: pl = CONF.logging_exception_prefix % record.__dict__ fl = '%s%s' % (pl, line) formatted_lines.append(fl) return '\n'.join(formatted_lines) class ColorHandler(logging.StreamHandler): LEVEL_COLORS = { logging.DEBUG: '\033[00;32m', # GREEN logging.INFO: '\033[00;36m', # CYAN logging.AUDIT: '\033[01;36m', # BOLD CYAN logging.WARN: '\033[01;33m', # BOLD YELLOW logging.ERROR: '\033[01;31m', # BOLD RED logging.CRITICAL: '\033[01;31m', # BOLD RED } def format(self, record): record.color = self.LEVEL_COLORS[record.levelno] return logging.StreamHandler.format(self, record) class DeprecatedConfig(Exception): message = _(""Fatal call to deprecated config: %(msg)s"") def __init__(self, msg): super(Exception, self).__init__(self.message % dict(msg=msg)) ",,996,429
openstack%2Fpython-openstackclient~master~I380941604d2e010451a103fc878c603031b14648,openstack/python-openstackclient,master,I380941604d2e010451a103fc878c603031b14648,Bump glanceclient min version,ABANDONED,2015-06-09 19:19:45.000000000,2015-06-25 19:20:28.000000000,,"[{'_account_id': 3}, {'_account_id': 6482}]","[{'number': 1, 'created': '2015-06-09 19:19:45.000000000', 'files': ['requirements.txt'], 'web_link': 'https://opendev.org/openstack/python-openstackclient/commit/3a3604a03ecdfe022fd2bfc2a885a976b71f8cbd', 'message': 'Bump glanceclient min version\n\nDepends-On: I332c12a60705770cd819f4ef3ef73bc24a209fa1\nChange-Id: I380941604d2e010451a103fc878c603031b14648\n'}]",0,189861,3a3604a03ecdfe022fd2bfc2a885a976b71f8cbd,4,2,1,970,,,0,"Bump glanceclient min version

Depends-On: I332c12a60705770cd819f4ef3ef73bc24a209fa1
Change-Id: I380941604d2e010451a103fc878c603031b14648
",git fetch https://review.opendev.org/openstack/python-openstackclient refs/changes/61/189861/1 && git format-patch -1 --stdout FETCH_HEAD,['requirements.txt'],1,3a3604a03ecdfe022fd2bfc2a885a976b71f8cbd,glanceclient-bump,python-glanceclient>=0.18.0,python-glanceclient>=0.17.1,1,1
openstack%2Fdesignate~master~I4e7c6ff309dfc8408b919fd7dd5e51644555d9b6,openstack/designate,master,I4e7c6ff309dfc8408b919fd7dd5e51644555d9b6,Ensure quotas ext doesn't mutate dict during iteration,MERGED,2015-06-25 14:46:27.000000000,2015-06-25 19:15:07.000000000,2015-06-25 19:15:04.000000000,"[{'_account_id': 3}, {'_account_id': 8099}, {'_account_id': 8174}]","[{'number': 1, 'created': '2015-06-25 14:46:27.000000000', 'files': ['designate/api/admin/views/extensions/quotas.py'], 'web_link': 'https://opendev.org/openstack/designate/commit/293392e5455e8bb54120e9c6af9b3f15f6c7aa62', 'message': ""Ensure quotas ext doesn't mutate dict during iteration\n\nThe quotas extenstion was mutating a dict while iterating it,\nwith the recent RANDOMHASHSEED change, this results in the\ndict ordering becoming random, changing the placement of the\nnewly inserted keys.\n\nChange-Id: I4e7c6ff309dfc8408b919fd7dd5e51644555d9b6\nCloses-Bug: 1468776\n""}]",0,195613,293392e5455e8bb54120e9c6af9b3f15f6c7aa62,7,3,1,741,,,0,"Ensure quotas ext doesn't mutate dict during iteration

The quotas extenstion was mutating a dict while iterating it,
with the recent RANDOMHASHSEED change, this results in the
dict ordering becoming random, changing the placement of the
newly inserted keys.

Change-Id: I4e7c6ff309dfc8408b919fd7dd5e51644555d9b6
Closes-Bug: 1468776
",git fetch https://review.opendev.org/openstack/designate refs/changes/13/195613/1 && git format-patch -1 --stdout FETCH_HEAD,['designate/api/admin/views/extensions/quotas.py'],1,293392e5455e8bb54120e9c6af9b3f15f6c7aa62,bug/1468776," mapping = { body[""quota""] = {mapping[k]: body[""quota""][k] for k in body[""quota""]}"," quota = body[""quota""] old_keys = { for key in quota: quota[old_keys[key]] = quota.pop(key)",2,5
openstack%2Fsahara~master~I92d72668d2c2a7f4f4a709f6cfea8f36310cc586,openstack/sahara,master,I92d72668d2c2a7f4f4a709f6cfea8f36310cc586,Fix problem with removing PID from list,MERGED,2015-06-01 09:51:55.000000000,2015-06-25 18:51:48.000000000,2015-06-04 14:42:38.000000000,"[{'_account_id': 3}, {'_account_id': 6116}, {'_account_id': 7213}, {'_account_id': 7710}, {'_account_id': 8411}, {'_account_id': 9740}, {'_account_id': 10670}, {'_account_id': 12038}, {'_account_id': 12039}, {'_account_id': 13919}, {'_account_id': 13953}]","[{'number': 1, 'created': '2015-06-01 09:51:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sahara/commit/85a2552cb8617840709f84bef02dc46d6b7ee97e', 'message': '[WIP] Fix problem with removing PID from list\n\nChange-Id: I92d72668d2c2a7f4f4a709f6cfea8f36310cc586\n'}, {'number': 2, 'created': '2015-06-01 14:27:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sahara/commit/b2e63065374c31bc34bfaffd29387bc290fb2bf3', 'message': 'Fix problem with removing PID from list\n\nPartial-bug: #1460651\n\nChange-Id: I92d72668d2c2a7f4f4a709f6cfea8f36310cc586\n'}, {'number': 3, 'created': '2015-06-03 17:09:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sahara/commit/a007494323edded48c4e13ec74c066593664baff', 'message': 'Fix problem with removing PID from list\n\nCloses-bug: #1460651\n\nChange-Id: I92d72668d2c2a7f4f4a709f6cfea8f36310cc586\n'}, {'number': 4, 'created': '2015-06-04 10:43:10.000000000', 'files': ['sahara/utils/wsgi.py'], 'web_link': 'https://opendev.org/openstack/sahara/commit/5d6cb33b384f92d00d66778e3b320581b3f124d3', 'message': 'Fix problem with removing PID from list\n\nCloses-bug: #1460651\n\nChange-Id: I92d72668d2c2a7f4f4a709f6cfea8f36310cc586\n'}]",8,187155,5d6cb33b384f92d00d66778e3b320581b3f124d3,38,11,4,7710,,,0,"Fix problem with removing PID from list

Closes-bug: #1460651

Change-Id: I92d72668d2c2a7f4f4a709f6cfea8f36310cc586
",git fetch https://review.opendev.org/openstack/sahara refs/changes/55/187155/4 && git format-patch -1 --stdout FETCH_HEAD,['sahara/utils/wsgi.py'],1,85a2552cb8617840709f84bef02dc46d6b7ee97e,bug/1460651," if pid in self.children: self.children.remove(pid) else: LOG.error(_LE(""PID %d not in child PID list""), pid)", self.children.remove(pid),4,1
openstack%2Fneutron~master~Ib2ed587670f206283d735191b3a2580bf3d1a04f,openstack/neutron,master,Ib2ed587670f206283d735191b3a2580bf3d1a04f,Move third-party CI policy under docs/policies,MERGED,2015-06-02 02:59:01.000000000,2015-06-25 18:51:18.000000000,2015-06-25 04:40:41.000000000,"[{'_account_id': 3}, {'_account_id': 105}, {'_account_id': 162}, {'_account_id': 748}, {'_account_id': 4395}, {'_account_id': 5170}, {'_account_id': 7016}, {'_account_id': 9681}, {'_account_id': 9682}, {'_account_id': 9751}, {'_account_id': 9787}, {'_account_id': 9845}, {'_account_id': 9846}, {'_account_id': 10121}, {'_account_id': 10153}, {'_account_id': 10184}, {'_account_id': 10387}, {'_account_id': 10980}, {'_account_id': 14208}, {'_account_id': 14212}, {'_account_id': 14213}, {'_account_id': 14214}, {'_account_id': 14215}, {'_account_id': 14216}, {'_account_id': 14323}, {'_account_id': 14571}, {'_account_id': 15296}, {'_account_id': 15444}, {'_account_id': 15752}]","[{'number': 1, 'created': '2015-06-02 02:59:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/1d4d9aa334a86a987c4f98b2e52fbb83d681b52c', 'message': 'WIP - Move third-party CI policy under docs/policies\n\nChange-Id: Ib2ed587670f206283d735191b3a2580bf3d1a04f\n'}, {'number': 2, 'created': '2015-06-24 21:35:18.000000000', 'files': ['doc/source/policies/thirdparty-ci.rst'], 'web_link': 'https://opendev.org/openstack/neutron/commit/668b12c2c8a60ce20ecdad2193ede9371d5cc391', 'message': 'Move third-party CI policy under docs/policies\n\nChange-Id: Ib2ed587670f206283d735191b3a2580bf3d1a04f\n'}]",5,187437,668b12c2c8a60ce20ecdad2193ede9371d5cc391,47,29,2,10980,,,0,"Move third-party CI policy under docs/policies

Change-Id: Ib2ed587670f206283d735191b3a2580bf3d1a04f
",git fetch https://review.opendev.org/openstack/neutron refs/changes/37/187437/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/source/policies/thirdparty-ci.rst'],1,1d4d9aa334a86a987c4f98b2e52fbb83d681b52c,thirdparty-ci,"Neutron Third-party CI ====================== What Is Expected of Third Party CI System for Neutron ----------------------------------------------------- As of the Liberty summit, Neutron no longer *requires* a third-party CI, but it is strongly encouraged, as internal neutron refactoring can break external plugins and drivers at any time. Neutron expects any Third Party CI system that interacts with gerrit to follow the requirements set by the Infrastructure team[1] as well as the Neutron Third Party CI guidelines below. Please ping the PTL in #openstack-neutron or send an email to the openstack-dev ML (with subject [neutron]) with any questions. Be aware that the Infrastructure documentation as well as this document are living documents and undergo changes. Track changes to the infrastructure documentation using this url[2] (and please review the patches) and check this doc on a regular basis for updates. [1] http://ci.openstack.org/third_party.html [2] https://review.openstack.org/#/q/status:open+project:openstack-infra/config+branch:master+topic:third-party,n,z What Changes to Run Against --------------------------- If your code is a neutron plugin or driver, you should run against every neutron change submitted, except for docs, tests, tools, and top-level setup files. You can see a programmatic example of the exceptions here[3]. [3] https://github.com/openstack-infra/project-config/blob/master/zuul/layout.yaml#L568 If your code is in a neutron-*aas repo, you should run against the tests for that repo. You may also run against every neutron change, if your service driver is using neutron interfaces that are not provided by your service plugin (e.g. loadbalancer/plugin.py). If you are using only plugin interfaces, it should be safe to test against only the service repo tests. What Tests To Run ----------------- Network API tests (git link). Network scenario tests (The test_network_* tests here). Any tests written specifically for your setup. http://git.openstack.org/cgit/openstack/tempest/tree/tempest/api/network Run with the test filter: 'network'. This will include all neutron specific tests as well as any other tests that are tagged as requiring networking. An example tempest setup for devstack-gate: export DEVSTACK_GATE_NEUTRON=1 export DEVSTACK_GATE_TEMPEST_REGEX='(?!.*\[.*\bslow\b.*\])((network)|(neutron))' ... an example setup for LBaaS: export DEVSTACK_GATE_NEUTRON=1 export DEVSTACK_GATE_TEMPEST_REGEX='(?!.*\[.*\bslow\b.*\])(alancer|SimpleReadOnlyNeutron|tempest.api.network)' Third Party CI Voting --------------------- The Neutron team encourages you to NOT vote -1 with a third-party CI. False negatives are noisy to the community, and have given -1 from third-party CIs a bad reputation. Really bad, to the point of people ignoring them all. Failure messages are useful to those doing refactors, and provide you feedback on the state of your plugin. If you insist on voting, by default, the infra team will not allow voting by new 3rd party CI systems. The way to get your 3rd party CI system to vote is to talk with the Neutron PTL, who will let infra know the system is ready to vote. The requirements for a new system to be given voting rights are as follows: * A new system must be up and running for a month, with a track record of voting on the sandbox system. * A new system must correctly run and pass tests on patches for the third party driver/plugin for a month. * A new system must have a logfile setup and retention setup similar to the below. Once the system has been running for a month, the owner of the third party CI system can contact the Neutron PTL to have a conversation about getting voting rights upstream. The general process to get these voting rights is outlined here. Please follow that, taking note of the guidelines Neutron also places on voting for it's CI systems. A third party system can have it's voting rights removed as well. If the system becomes unstable (stops running, voting, or start providing inaccurate results), the Neutron PTL will make an attempt to contact the owner and copy the openstack-dev mailing list. If no response is received within 2 days, the Neutron PTL will remove voting rights for the third party CI system. If a response is received, the owner will work to correct the issue. If the issue cannot be addressed in a reasonable amount of time, the voting rights will be temporarily removed. Log & Test Results Filesystem Layout ------------------------------------ Third-Party CI systems MUST provide logs and configuration data to help developers troubleshoot test failures. A third-party CI that DOES NOT post logs should be a candidate for removal, and new CI systems MUST post logs before they can be awarded voting privileges. Third party CI systems should follow the filesystem layout convention of the OpenStack CI system. Please store your logs as viewable in a web browser, in a directory structure. Requiring the user to download a giant tarball is not acceptable. At the root of the results - there should be the following: console.html.gz - contains the output of stdout of the test run local.conf / localrc - contains the setup used for this run logs/ Logs must be a directory, which contains the following: Log files for each screen session that DevStack creates and launches an OpenStack component in Test result files testr_results.html.gz tempest.txt.gz List of existing plugins and drivers ------------------------------------ https://wiki.openstack.org/wiki/Neutron_Plugins_and_Drivers#Existing_Plugin_and_Drivers ",,124,0
openstack%2Fnova-powervm~master~I77670ff970325781a69d96e24d5e69a23b6c195b,openstack/nova-powervm,master,I77670ff970325781a69d96e24d5e69a23b6c195b,Task for connecting and discovering instance disk,MERGED,2015-06-24 17:05:23.000000000,2015-06-25 18:46:51.000000000,2015-06-25 18:46:51.000000000,"[{'_account_id': 3}, {'_account_id': 8190}, {'_account_id': 8662}, {'_account_id': 13883}, {'_account_id': 14070}]","[{'number': 1, 'created': '2015-06-24 17:05:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova-powervm/commit/0c00bf3fc4ede0366d4ba0139cdef5cedb047340', 'message': ""Task for connecting and discovering instance disk\n\nNew nova_powervm.virt.powervm.tasks.storage.InstanceDiskToMgmt Task\nclass encompassing a) connecting an instance's boot disk to the\nmanagement partition, and b) discovering that disk and figuring out its\ndevice path.\n\nChange-Id: I77670ff970325781a69d96e24d5e69a23b6c195b\n""}, {'number': 2, 'created': '2015-06-24 17:39:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova-powervm/commit/7da624c46ea3ac346f65ad598dc7a610f2c84c8d', 'message': ""Task for connecting and discovering instance disk\n\nNew nova_powervm.virt.powervm.tasks.storage.InstanceDiskToMgmt Task\nclass encompassing a) connecting an instance's boot disk to the\nmanagement partition, and b) discovering that disk and figuring out its\ndevice path.\n\nChange-Id: I77670ff970325781a69d96e24d5e69a23b6c195b\n""}, {'number': 3, 'created': '2015-06-24 20:38:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova-powervm/commit/b9c99f2d08b91fa1aa272b327fe06f8879a9d4d7', 'message': ""Task for connecting and discovering instance disk\n\nNew nova_powervm.virt.powervm.tasks.storage.InstanceDiskToMgmt Task\nclass encompassing a) connecting an instance's boot disk to the\nmanagement partition, and b) discovering that disk and figuring out its\ndevice path.\n\nChange-Id: I77670ff970325781a69d96e24d5e69a23b6c195b\n""}, {'number': 4, 'created': '2015-06-24 21:53:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova-powervm/commit/ce47ca200f296dc2144beb4d0a4c41b2942a61ad', 'message': ""Task for connecting and discovering instance disk\n\nNew nova_powervm.virt.powervm.tasks.storage.InstanceDiskToMgmt Task\nclass encompassing a) connecting an instance's boot disk to the\nmanagement partition, and b) discovering that disk and figuring out its\ndevice path.\n\nChange-Id: I77670ff970325781a69d96e24d5e69a23b6c195b\n""}, {'number': 5, 'created': '2015-06-24 22:40:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova-powervm/commit/9a67b640602527841a2a60213112eacd5c3803be', 'message': ""Task for connecting and discovering instance disk\n\nNew nova_powervm.virt.powervm.tasks.storage.InstanceDiskToMgmt Task\nclass encompassing a) connecting an instance's boot disk to the\nmanagement partition, and b) discovering that disk and figuring out its\ndevice path.\n\nChange-Id: I77670ff970325781a69d96e24d5e69a23b6c195b\n""}, {'number': 6, 'created': '2015-06-25 15:03:08.000000000', 'files': ['nova_powervm/virt/powervm/tasks/storage.py', 'nova_powervm/virt/powervm/mgmt.py', 'nova_powervm/virt/powervm/exception.py', 'nova_powervm/tests/virt/powervm/tasks/test_storage.py'], 'web_link': 'https://opendev.org/openstack/nova-powervm/commit/91cf422ee2559809df4500df2b3cfef40c3dab62', 'message': ""Task for connecting and discovering instance disk\n\nNew nova_powervm.virt.powervm.tasks.storage.InstanceDiskToMgmt Task\nclass encompassing a) connecting an instance's boot disk to the\nmanagement partition, and b) discovering that disk and figuring out its\ndevice path.\n\nChange-Id: I77670ff970325781a69d96e24d5e69a23b6c195b\n""}]",14,195195,91cf422ee2559809df4500df2b3cfef40c3dab62,27,5,6,14070,,,0,"Task for connecting and discovering instance disk

New nova_powervm.virt.powervm.tasks.storage.InstanceDiskToMgmt Task
class encompassing a) connecting an instance's boot disk to the
management partition, and b) discovering that disk and figuring out its
device path.

Change-Id: I77670ff970325781a69d96e24d5e69a23b6c195b
",git fetch https://review.opendev.org/openstack/nova-powervm refs/changes/95/195195/1 && git format-patch -1 --stdout FETCH_HEAD,"['nova_powervm/virt/powervm/tasks/storage.py', 'nova_powervm/virt/powervm/mgmt.py', 'nova_powervm/virt/powervm/exception.py', 'nova_powervm/tests/virt/powervm/tasks/test_storage.py']",4,0c00bf3fc4ede0366d4ba0139cdef5cedb047340,task_connect,"# Copyright 2015 IBM Corp. # # All Rights Reserved. # # Licensed under the Apache License, Version 2.0 (the ""License""); you may # not use this file except in compliance with the License. You may obtain # a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT # WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the # License for the specific language governing permissions and limitations # under the License. import mock from nova import test from nova_powervm.virt.powervm import exception as npvmex from nova_powervm.virt.powervm.tasks import storage as tf_stg class TestStorage(test.TestCase): @mock.patch('pypowervm.tasks.scsi_mapper.find_maps') @mock.patch('nova_powervm.virt.powervm.mgmt.discover_vscsi_disk') @mock.patch('nova_powervm.virt.powervm.mgmt.remove_block_dev') def test_instance_disk_to_mgmt(self, mock_rm, mock_discover, mock_find): mock_discover.return_value = '/dev/disk' mock_instance = mock.Mock() mock_instance.name = 'instance_name' mock_stg = mock.Mock() mock_stg.name = 'stg_name' def verify_connect(inst): self.assertEqual(mock_instance, inst) mock_vwrap = mock.Mock() mock_vwrap.name = 'vios_name' mock_vwrap.uuid = 'vios_uuid' mock_vwrap.scsi_mappings = ['mapping1'] return mock_stg, mock_vwrap def verify_disconnect(vios_uuid, stg_name): self.assertEqual('vios_uuid', vios_uuid) self.assertEqual('stg_name', stg_name) disk_dvr = mock.MagicMock() disk_dvr.mp_uuid = 'mp_uuid' disk_dvr.connect_instance_disk_to_mgmt = verify_connect disk_dvr.disconnect_disk_from_mgmt = verify_disconnect # Good path - find_maps returns one result mock_find.return_value = ['one_mapping'] tf = tf_stg.InstanceDiskToMgmt(disk_dvr, 'context', mock_instance) self.assertEqual('connect_and_discover_instance_disk_to_mgmt', tf.name) self.assertEqual('/dev/disk', tf.execute()) mock_find.assert_called_with(['mapping1'], 'mp_uuid', stg_elem=mock_stg) mock_discover.assert_called_with('one_mapping') tf.revert('result', 'failures') mock_rm.assert_called_with('/dev/disk') # Good path - find_maps returns >1 result mock_find.reset_mock() mock_discover.reset_mock() mock_rm.reset_mock() mock_find.return_value = ['first_mapping', 'second_mapping'] tf = tf_stg.InstanceDiskToMgmt(disk_dvr, 'context', mock_instance) self.assertEqual('/dev/disk', tf.execute()) mock_find.assert_called_with(['mapping1'], 'mp_uuid', stg_elem=mock_stg) mock_discover.assert_called_with('first_mapping') tf.revert('result', 'failures') mock_rm.assert_called_with('/dev/disk') # Bad path - find_maps returns no results mock_find.reset_mock() mock_discover.reset_mock() mock_rm.reset_mock() mock_find.return_value = [] tf = tf_stg.InstanceDiskToMgmt(disk_dvr, 'context', mock_instance) self.assertRaises(npvmex.NewMappingNotFoundException, tf.execute) # find_maps was still called mock_find.assert_called_with(['mapping1'], 'mp_uuid', stg_elem=mock_stg) # discover_vscsi_disk didn't get called self.assertEqual(0, mock_discover.call_count) tf.revert('result', 'failures') # disconnect_disk_from_mgmt got called (still checked by # verify_disconnect above), but remove_block_dev did not. self.assertEqual(0, mock_rm.call_count) # Bad path - connect raises mock_find.reset_mock() mock_discover.reset_mock() mock_rm.reset_mock() disk_dvr.connect_instance_disk_to_mgmt = mock.Mock( side_effect=npvmex.InstanceDiskMappingFailed( instance_name='inst_name')) tf = tf_stg.InstanceDiskToMgmt(disk_dvr, 'context', mock_instance) self.assertRaises(npvmex.InstanceDiskMappingFailed, tf.execute) self.assertEqual(0, mock_find.call_count) self.assertEqual(0, mock_discover.call_count) # revert shouldn't call disconnect or remove disk_dvr.disconnect_disk_from_mgmt = mock.Mock(side_effect=self.fail) tf.revert('result', 'failures') self.assertEqual(0, mock_rm.call_count) ",,205,8
openstack%2Fdesignate~master~Ic8ecbcc3624cdbe77eb8cd7aa25e673ec2a98e0d,openstack/designate,master,Ic8ecbcc3624cdbe77eb8cd7aa25e673ec2a98e0d,Re-arrange default log levels and add iso8601,MERGED,2015-06-25 11:38:01.000000000,2015-06-25 18:41:24.000000000,2015-06-25 18:41:18.000000000,"[{'_account_id': 3}, {'_account_id': 741}, {'_account_id': 8099}]","[{'number': 1, 'created': '2015-06-25 11:38:01.000000000', 'files': ['designate/__init__.py'], 'web_link': 'https://opendev.org/openstack/designate/commit/0dfe70675dca076cca1ec6dbafa27e7e68f3878e', 'message': 'Re-arrange default log levels and add iso8601\n\nChange-Id: Ic8ecbcc3624cdbe77eb8cd7aa25e673ec2a98e0d\n'}]",0,195534,0dfe70675dca076cca1ec6dbafa27e7e68f3878e,9,3,1,395,,,0,"Re-arrange default log levels and add iso8601

Change-Id: Ic8ecbcc3624cdbe77eb8cd7aa25e673ec2a98e0d
",git fetch https://review.opendev.org/openstack/designate refs/changes/34/195534/1 && git format-patch -1 --stdout FETCH_HEAD,['designate/__init__.py'],1,0dfe70675dca076cca1ec6dbafa27e7e68f3878e,loglevels," 'iso8601=WARN', 'keystone=INFO', 'oslo.messaging=WARN', 'sqlalchemy=WARN', 'stevedore=WARN', 'suds=INFO', ])"," 'sqlalchemy=WARN', 'suds=INFO', 'keystone=INFO', 'stevedore=WARN', 'oslo.messaging=WARN'])",7,5
openstack%2Fswift~feature%2Fhummingbird~I0a0c9c4cf6450a1c837a3e893d5a89d0d0157b96,openstack/swift,feature/hummingbird,I0a0c9c4cf6450a1c837a3e893d5a89d0d0157b96,go: make use of filepath.Join() in objectserver main,MERGED,2015-06-24 19:01:15.000000000,2015-06-25 18:39:39.000000000,2015-06-25 18:39:35.000000000,"[{'_account_id': 3}, {'_account_id': 995}, {'_account_id': 2828}, {'_account_id': 16218}]","[{'number': 1, 'created': '2015-06-24 19:01:15.000000000', 'files': ['go/objectserver/main.go'], 'web_link': 'https://opendev.org/openstack/swift/commit/6db05edfeca75332428b9a96e7854af5f2d131d4', 'message': 'go: make use of filepath.Join() in objectserver main\n\nChange-Id: I0a0c9c4cf6450a1c837a3e893d5a89d0d0157b96\n'}]",0,195271,6db05edfeca75332428b9a96e7854af5f2d131d4,11,4,1,1009,,,0,"go: make use of filepath.Join() in objectserver main

Change-Id: I0a0c9c4cf6450a1c837a3e893d5a89d0d0157b96
",git fetch https://review.opendev.org/openstack/swift refs/changes/71/195271/1 && git format-patch -1 --stdout FETCH_HEAD,['go/objectserver/main.go'],1,6db05edfeca75332428b9a96e7854af5f2d131d4,objectserver_filepath_join," fileName := filepath.Join(hashDir, fmt.Sprintf(""%s.data"", requestTimestamp)) fileName := filepath.Join(hashDir, fmt.Sprintf(""%s.ts"", requestTimestamp)) devicePath := filepath.Join(server.driveRoot, vars[""device""])"," fileName := hashDir + ""/"" + requestTimestamp + "".data"" fileName := hashDir + ""/"" + requestTimestamp + "".ts"" devicePath := server.driveRoot + ""/"" + vars[""device""]",3,3
openstack%2Fkolla~master~I4a60e317ef1004649d2377f29b7f41b9c42c5212,openstack/kolla,master,I4a60e317ef1004649d2377f29b7f41b9c42c5212,Glance missing oslo.i18n,MERGED,2015-06-25 10:54:32.000000000,2015-06-25 18:38:36.000000000,2015-06-25 18:38:30.000000000,"[{'_account_id': 3}, {'_account_id': 2834}, {'_account_id': 10428}, {'_account_id': 12609}, {'_account_id': 14027}]","[{'number': 1, 'created': '2015-06-25 10:54:32.000000000', 'files': ['docker/centos/binary/glance/glance-base/Dockerfile'], 'web_link': 'https://opendev.org/openstack/kolla/commit/89d69ecea15ea5e867f92551397bfe45ac4df71b', 'message': ""Glance missing oslo.i18n\n\nGlance required this package but it's not in rpm dependencies\n\nChange-Id: I4a60e317ef1004649d2377f29b7f41b9c42c5212\nCloses: bug 1468729\n""}]",3,195516,89d69ecea15ea5e867f92551397bfe45ac4df71b,9,5,1,10787,,,0,"Glance missing oslo.i18n

Glance required this package but it's not in rpm dependencies

Change-Id: I4a60e317ef1004649d2377f29b7f41b9c42c5212
Closes: bug 1468729
",git fetch https://review.opendev.org/openstack/kolla refs/changes/16/195516/1 && git format-patch -1 --stdout FETCH_HEAD,['docker/centos/binary/glance/glance-base/Dockerfile'],1,89d69ecea15ea5e867f92551397bfe45ac4df71b,bug/1468729,RUN yum -y install openstack-glance python-oslo-i18n && yum clean all,RUN yum -y install openstack-glance && yum clean all,1,1
openstack%2Fos-client-config~master~I3e0aa9dc38bbafc3c3a205f08b65abbd4528e874,openstack/os-client-config,master,I3e0aa9dc38bbafc3c3a205f08b65abbd4528e874,Normalize project_name aliases,MERGED,2015-06-22 05:44:32.000000000,2015-06-25 18:36:17.000000000,2015-06-25 18:36:15.000000000,"[{'_account_id': 2}, {'_account_id': 3}, {'_account_id': 3099}]","[{'number': 1, 'created': '2015-06-22 05:44:32.000000000', 'files': ['os_client_config/config.py', 'os_client_config/tests/base.py', 'os_client_config/tests/test_config.py'], 'web_link': 'https://opendev.org/openstack/os-client-config/commit/b631da86fee360533111eb9993e215d6cb64f522', 'message': 'Normalize project_name aliases\n\nWe arent normalizing keys before we check for project_name aliases,\ntherefore using hyphenated versions of the aliases fail.\n\nChange-Id: I3e0aa9dc38bbafc3c3a205f08b65abbd4528e874\n'}]",0,193942,b631da86fee360533111eb9993e215d6cb64f522,7,3,1,10035,,,0,"Normalize project_name aliases

We arent normalizing keys before we check for project_name aliases,
therefore using hyphenated versions of the aliases fail.

Change-Id: I3e0aa9dc38bbafc3c3a205f08b65abbd4528e874
",git fetch https://review.opendev.org/openstack/os-client-config refs/changes/42/193942/1 && git format-patch -1 --stdout FETCH_HEAD,"['os_client_config/config.py', 'os_client_config/tests/base.py', 'os_client_config/tests/test_config.py']",3,b631da86fee360533111eb9993e215d6cb64f522,fix/accept-normalized-project-names," def test_get_one_cloud_with_hyphenated_project_id(self): c = config.OpenStackConfig(config_files=[self.cloud_yaml], vendor_files=[self.vendor_yaml]) cc = c.get_one_cloud('_test_cloud_hyphenated') self.assertEqual('12345', cc.auth['project_name']) '_test_cloud_hyphenated',",,19,2
openstack%2Fswift~feature%2Fhummingbird~Ic8d981cef147bd8fc9b99217211e0fc24434fb41,openstack/swift,feature/hummingbird,Ic8d981cef147bd8fc9b99217211e0fc24434fb41,go: check for empty path parts in object server,MERGED,2015-06-23 19:07:25.000000000,2015-06-25 18:34:29.000000000,2015-06-25 18:34:27.000000000,"[{'_account_id': 3}, {'_account_id': 995}, {'_account_id': 2828}, {'_account_id': 16218}]","[{'number': 1, 'created': '2015-06-23 19:07:25.000000000', 'files': ['go/objectserver/main.go', 'go/objectserver/main_test.go'], 'web_link': 'https://opendev.org/openstack/swift/commit/b9aa15290c3b84a94cca4ae17ebcabc0f549c33b', 'message': 'go: check for empty path parts in object server\n\nChange-Id: Ic8d981cef147bd8fc9b99217211e0fc24434fb41\n'}]",0,194789,b9aa15290c3b84a94cca4ae17ebcabc0f549c33b,9,4,1,1009,,,0,"go: check for empty path parts in object server

Change-Id: Ic8d981cef147bd8fc9b99217211e0fc24434fb41
",git fetch https://review.opendev.org/openstack/swift refs/changes/89/194789/1 && git format-patch -1 --stdout FETCH_HEAD,"['go/objectserver/main.go', 'go/objectserver/main_test.go']",2,b9aa15290c3b84a94cca4ae17ebcabc0f549c33b,empty_path," func TestEmptyDevice(t *testing.T) { ts, err := makeObjectServer() assert.Nil(t, err) defer ts.Close() req, err := http.NewRequest(""PUT"", fmt.Sprintf(""http://%s:%d//0/a/c/o"", ts.host, ts.port), bytes.NewBuffer([]byte(""ABCDEFGHIJKLMNOPQRSTUVWXYZ""))) assert.Nil(t, err) resp, err := http.DefaultClient.Do(req) assert.Nil(t, err) assert.Equal(t, 400, resp.StatusCode) } func TestEmptyPartition(t *testing.T) { ts, err := makeObjectServer() assert.Nil(t, err) defer ts.Close() req, err := http.NewRequest(""PUT"", fmt.Sprintf(""http://%s:%d/sda//a/c/o"", ts.host, ts.port), bytes.NewBuffer([]byte(""ABCDEFGHIJKLMNOPQRSTUVWXYZ""))) assert.Nil(t, err) resp, err := http.DefaultClient.Do(req) assert.Nil(t, err) assert.Equal(t, 400, resp.StatusCode) } func TestEmptyAccount(t *testing.T) { ts, err := makeObjectServer() assert.Nil(t, err) defer ts.Close() req, err := http.NewRequest(""PUT"", fmt.Sprintf(""http://%s:%d/sda/0//c/o"", ts.host, ts.port), bytes.NewBuffer([]byte(""ABCDEFGHIJKLMNOPQRSTUVWXYZ""))) assert.Nil(t, err) resp, err := http.DefaultClient.Do(req) assert.Nil(t, err) assert.Equal(t, 400, resp.StatusCode) } func TestEmptyContainer(t *testing.T) { ts, err := makeObjectServer() assert.Nil(t, err) defer ts.Close() req, err := http.NewRequest(""PUT"", fmt.Sprintf(""http://%s:%d/sda/0/a//o"", ts.host, ts.port), bytes.NewBuffer([]byte(""ABCDEFGHIJKLMNOPQRSTUVWXYZ""))) assert.Nil(t, err) resp, err := http.DefaultClient.Do(req) assert.Nil(t, err) assert.Equal(t, 400, resp.StatusCode) } func TestEmptyObject(t *testing.T) { ts, err := makeObjectServer() assert.Nil(t, err) defer ts.Close() req, err := http.NewRequest(""PUT"", fmt.Sprintf(""http://%s:%d/sda/0/a/c/"", ts.host, ts.port), bytes.NewBuffer([]byte(""ABCDEFGHIJKLMNOPQRSTUVWXYZ""))) assert.Nil(t, err) resp, err := http.DefaultClient.Do(req) assert.Nil(t, err) assert.Equal(t, 400, resp.StatusCode) }",,71,0
openstack%2Fshade~master~I04906e0fb35ffcac0d046ba37aa52c2a3cad8b1a,openstack/shade,master,I04906e0fb35ffcac0d046ba37aa52c2a3cad8b1a,Remove list_keypair_dicts method,MERGED,2015-06-25 14:49:51.000000000,2015-06-25 18:28:28.000000000,2015-06-25 18:28:23.000000000,"[{'_account_id': 2}, {'_account_id': 3}]","[{'number': 1, 'created': '2015-06-25 14:49:51.000000000', 'files': ['shade/__init__.py'], 'web_link': 'https://opendev.org/openstack/shade/commit/0b09988cba58a03cf7d351238621c8d4b37c2ece', 'message': 'Remove list_keypair_dicts method\n\nThis is unused and unnecessary now with the update to the\nkeypair API.\n\nChange-Id: I04906e0fb35ffcac0d046ba37aa52c2a3cad8b1a\n'}]",0,195616,0b09988cba58a03cf7d351238621c8d4b37c2ece,6,2,1,3099,,,0,"Remove list_keypair_dicts method

This is unused and unnecessary now with the update to the
keypair API.

Change-Id: I04906e0fb35ffcac0d046ba37aa52c2a3cad8b1a
",git fetch https://review.opendev.org/openstack/shade refs/changes/16/195616/1 && git format-patch -1 --stdout FETCH_HEAD,['shade/__init__.py'],1,0b09988cba58a03cf7d351238621c8d4b37c2ece,keypair_fix,, def list_keypair_dicts(self): return [meta.obj_to_dict(keypair) for keypair in self.list_keypairs()] ,0,4
openstack%2Fneutron~master~I2009ca3f102d0ca0db3f12af3012989f2a036c48,openstack/neutron,master,I2009ca3f102d0ca0db3f12af3012989f2a036c48,"Remove lbaas API tests, which are now in the lbaas repo",MERGED,2015-06-02 02:31:18.000000000,2015-06-25 18:20:22.000000000,2015-06-24 22:44:52.000000000,"[{'_account_id': 3}, {'_account_id': 105}, {'_account_id': 4395}, {'_account_id': 5170}, {'_account_id': 9681}, {'_account_id': 9682}, {'_account_id': 9751}, {'_account_id': 9787}, {'_account_id': 9845}, {'_account_id': 9846}, {'_account_id': 10121}, {'_account_id': 10153}, {'_account_id': 10184}, {'_account_id': 10387}, {'_account_id': 10980}, {'_account_id': 14208}, {'_account_id': 14212}, {'_account_id': 14213}, {'_account_id': 14214}, {'_account_id': 14215}, {'_account_id': 14216}, {'_account_id': 14323}, {'_account_id': 14571}, {'_account_id': 15444}, {'_account_id': 15752}]","[{'number': 1, 'created': '2015-06-02 02:31:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/e11f64cbdbba9560d0776f1254e2da79723ef8f4', 'message': 'Remove lbaas API tests, which are now in the lbaas repo\n\nChange-Id: I2009ca3f102d0ca0db3f12af3012989f2a036c48\n'}, {'number': 2, 'created': '2015-06-24 21:05:04.000000000', 'files': ['neutron/tests/api/test_load_balancer.py', 'neutron/tests/api/admin/test_lbaas_agent_scheduler.py', 'neutron/tests/api/admin/test_load_balancer_admin_actions.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/3bf62772d39d8b3b8b518ae88a6fcea7414d6884', 'message': 'Remove lbaas API tests, which are now in the lbaas repo\n\nChange-Id: I2009ca3f102d0ca0db3f12af3012989f2a036c48\n'}]",0,187430,3bf62772d39d8b3b8b518ae88a6fcea7414d6884,41,25,2,10980,,,0,"Remove lbaas API tests, which are now in the lbaas repo

Change-Id: I2009ca3f102d0ca0db3f12af3012989f2a036c48
",git fetch https://review.opendev.org/openstack/neutron refs/changes/30/187430/1 && git format-patch -1 --stdout FETCH_HEAD,"['neutron/tests/api/test_load_balancer.py', 'neutron/tests/api/admin/test_lbaas_agent_scheduler.py', 'neutron/tests/api/admin/test_load_balancer_admin_actions.py']",3,e11f64cbdbba9560d0776f1254e2da79723ef8f4,remove-lbaas-api-tests,,"# Copyright 2014 Mirantis.inc # All Rights Reserved. # # Licensed under the Apache License, Version 2.0 (the ""License""); you may # not use this file except in compliance with the License. You may obtain # a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT # WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the # License for the specific language governing permissions and limitations # under the License. from tempest_lib.common.utils import data_utils from neutron.tests.api import base from neutron.tests.tempest import test class LoadBalancerAdminTestJSON(base.BaseAdminNetworkTest): """""" Test admin actions for load balancer. Create VIP for another tenant Create health monitor for another tenant """""" @classmethod def resource_setup(cls): super(LoadBalancerAdminTestJSON, cls).resource_setup() if not test.is_extension_enabled('lbaas', 'network'): msg = ""lbaas extension not enabled."" raise cls.skipException(msg) cls.force_tenant_isolation = True manager = cls.get_client_manager() cls.client = manager.network_client cls.tenant_id = cls.isolated_creds.get_primary_creds().tenant_id cls.network = cls.create_network() cls.subnet = cls.create_subnet(cls.network) cls.pool = cls.create_pool(data_utils.rand_name('pool-'), ""ROUND_ROBIN"", ""HTTP"", cls.subnet) @test.attr(type='smoke') @test.idempotent_id('6b0a20d8-4fcd-455e-b54f-ec4db5199518') def test_create_vip_as_admin_for_another_tenant(self): name = data_utils.rand_name('vip-') body = self.admin_client.create_pool( name=data_utils.rand_name('pool-'), lb_method=""ROUND_ROBIN"", protocol=""HTTP"", subnet_id=self.subnet['id'], tenant_id=self.tenant_id) pool = body['pool'] self.addCleanup(self.admin_client.delete_pool, pool['id']) body = self.admin_client.create_vip(name=name, protocol=""HTTP"", protocol_port=80, subnet_id=self.subnet['id'], pool_id=pool['id'], tenant_id=self.tenant_id) vip = body['vip'] self.addCleanup(self.admin_client.delete_vip, vip['id']) self.assertIsNotNone(vip['id']) self.assertEqual(self.tenant_id, vip['tenant_id']) body = self.client.show_vip(vip['id']) show_vip = body['vip'] self.assertEqual(vip['id'], show_vip['id']) self.assertEqual(vip['name'], show_vip['name']) @test.attr(type='smoke') @test.idempotent_id('74552cfc-ab78-4fb6-825b-f67bca379921') def test_create_health_monitor_as_admin_for_another_tenant(self): body = ( self.admin_client.create_health_monitor(delay=4, max_retries=3, type=""TCP"", timeout=1, tenant_id=self.tenant_id)) health_monitor = body['health_monitor'] self.addCleanup(self.admin_client.delete_health_monitor, health_monitor['id']) self.assertIsNotNone(health_monitor['id']) self.assertEqual(self.tenant_id, health_monitor['tenant_id']) body = self.client.show_health_monitor(health_monitor['id']) show_health_monitor = body['health_monitor'] self.assertEqual(health_monitor['id'], show_health_monitor['id']) @test.attr(type='smoke') @test.idempotent_id('266a192d-3c22-46c4-a8fb-802450301e82') def test_create_pool_from_admin_user_other_tenant(self): body = self.admin_client.create_pool( name=data_utils.rand_name('pool-'), lb_method=""ROUND_ROBIN"", protocol=""HTTP"", subnet_id=self.subnet['id'], tenant_id=self.tenant_id) pool = body['pool'] self.addCleanup(self.admin_client.delete_pool, pool['id']) self.assertIsNotNone(pool['id']) self.assertEqual(self.tenant_id, pool['tenant_id']) @test.attr(type='smoke') @test.idempotent_id('158bb272-b9ed-4cfc-803c-661dac46f783') def test_create_member_from_admin_user_other_tenant(self): body = self.admin_client.create_member(address=""10.0.9.47"", protocol_port=80, pool_id=self.pool['id'], tenant_id=self.tenant_id) member = body['member'] self.addCleanup(self.admin_client.delete_member, member['id']) self.assertIsNotNone(member['id']) self.assertEqual(self.tenant_id, member['tenant_id']) ",0,641
openstack%2Fneutron-lbaas~master~Ibd4b763a46b9c511c1b511d787a7659376f47def,openstack/neutron-lbaas,master,Ibd4b763a46b9c511c1b511d787a7659376f47def,Test that new ci scripting fails properly,ABANDONED,2015-06-25 02:47:27.000000000,2015-06-25 18:03:24.000000000,,"[{'_account_id': 3}, {'_account_id': 9008}, {'_account_id': 9828}, {'_account_id': 12040}]","[{'number': 1, 'created': '2015-06-25 02:47:27.000000000', 'files': ['neutron_lbaas/services/loadbalancer/plugin.py'], 'web_link': 'https://opendev.org/openstack/neutron-lbaas/commit/44fe53a842f741c8c579abec9d33015f0649e036', 'message': 'Test that new ci scripting fails properly\n\nChange-Id: Ibd4b763a46b9c511c1b511d787a7659376f47def\n'}]",0,195388,44fe53a842f741c8c579abec9d33015f0649e036,6,4,1,10980,,,0,"Test that new ci scripting fails properly

Change-Id: Ibd4b763a46b9c511c1b511d787a7659376f47def
",git fetch https://review.opendev.org/openstack/neutron-lbaas refs/changes/88/195388/1 && git format-patch -1 --stdout FETCH_HEAD,['neutron_lbaas/services/loadbalancer/plugin.py'],1,44fe53a842f741c8c579abec9d33015f0649e036,negative-ci-check,hjkls ,,2,0
openstack%2Fmanila~master~I318a852740b3fb8c4361f5477757328e39fb8f67,openstack/manila,master,I318a852740b3fb8c4361f5477757328e39fb8f67,Remove unused manila/openstack/common/eventlet_backdoor.py,MERGED,2015-06-17 20:58:52.000000000,2015-06-25 17:53:16.000000000,2015-06-25 16:20:11.000000000,"[{'_account_id': 3}, {'_account_id': 2417}, {'_account_id': 7102}, {'_account_id': 7634}, {'_account_id': 8911}, {'_account_id': 10621}, {'_account_id': 11047}, {'_account_id': 11811}, {'_account_id': 11865}, {'_account_id': 14232}, {'_account_id': 15100}]","[{'number': 1, 'created': '2015-06-17 20:58:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/manila/commit/50f7f1d5b846596a941d58595278a1da3c2dfb11', 'message': 'Remove unused manila/openstack/common/eventlet_backdoor.py\n\nThis is from oslo-inclubator but is not used so remove it and also\nremove the configuration options for eventlet_backdoor.\n\nChange-Id: I318a852740b3fb8c4361f5477757328e39fb8f67\n'}, {'number': 2, 'created': '2015-06-25 09:48:51.000000000', 'files': ['openstack-common.conf', 'manila/openstack/common/eventlet_backdoor.py', 'manila/opts.py'], 'web_link': 'https://opendev.org/openstack/manila/commit/0b010e0f9c84bc7ef9d0d10a7b7d767dc617bcc5', 'message': 'Remove unused manila/openstack/common/eventlet_backdoor.py\n\nThis is from oslo-inclubator but is not used so remove it and also\nremove the configuration options for eventlet_backdoor.\n\nChange-Id: I318a852740b3fb8c4361f5477757328e39fb8f67\n'}]",0,192890,0b010e0f9c84bc7ef9d0d10a7b7d767dc617bcc5,24,11,2,7102,,,0,"Remove unused manila/openstack/common/eventlet_backdoor.py

This is from oslo-inclubator but is not used so remove it and also
remove the configuration options for eventlet_backdoor.

Change-Id: I318a852740b3fb8c4361f5477757328e39fb8f67
",git fetch https://review.opendev.org/openstack/manila refs/changes/90/192890/2 && git format-patch -1 --stdout FETCH_HEAD,"['openstack-common.conf', 'manila/openstack/common/eventlet_backdoor.py', 'manila/opts.py']",3,50f7f1d5b846596a941d58595278a1da3c2dfb11,192890,,"import manila.openstack.common.eventlet_backdoor manila.openstack.common.eventlet_backdoor.eventlet_backdoor_opts,",0,154
openstack%2Fpython-designateclient~master~I2ca31701af37ab9776e86aa7ce16f86f6edc8557,openstack/python-designateclient,master,I2ca31701af37ab9776e86aa7ce16f86f6edc8557,Removed peronal email address from example,MERGED,2015-06-25 13:31:55.000000000,2015-06-25 17:41:21.000000000,2015-06-25 17:41:20.000000000,"[{'_account_id': 3}, {'_account_id': 741}, {'_account_id': 8099}]","[{'number': 1, 'created': '2015-06-25 13:31:55.000000000', 'files': ['doc/source/shell-examples.rst'], 'web_link': 'https://opendev.org/openstack/python-designateclient/commit/f9e41ea81ecc1e1f0dd20f0f6b77ce3f017be350', 'message': 'Removed peronal email address from example\n\nChange-Id: I2ca31701af37ab9776e86aa7ce16f86f6edc8557\n'}]",0,195576,f9e41ea81ecc1e1f0dd20f0f6b77ce3f017be350,7,3,1,6494,,,0,"Removed peronal email address from example

Change-Id: I2ca31701af37ab9776e86aa7ce16f86f6edc8557
",git fetch https://review.opendev.org/openstack/python-designateclient refs/changes/76/195576/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/source/shell-examples.rst'],1,f9e41ea81ecc1e1f0dd20f0f6b77ce3f017be350,remove-personal-email-addresses, $ designate --os-endpoint http://127.0.0.1:9001/v1 domain-create --name testing123.net. --email me@mydomain.com | email | me@mydomain.com |, $ designate --os-endpoint http://127.0.0.1:9001/v1 domain-create --name testing123.net. --email simon@mccartney.ie | email | simon@mccartney.ie |,2,2
openstack%2Fshade~master~I997cb0edc4fd9160b6804a29d404190526303720,openstack/shade,master,I997cb0edc4fd9160b6804a29d404190526303720,Fix available_floating_ip when using Nova network,MERGED,2015-06-25 09:22:40.000000000,2015-06-25 17:41:13.000000000,2015-06-25 17:41:12.000000000,"[{'_account_id': 2}, {'_account_id': 3}, {'_account_id': 3099}, {'_account_id': 6133}]","[{'number': 1, 'created': '2015-06-25 09:22:40.000000000', 'files': ['shade/__init__.py', 'shade/tests/unit/test_floating_ip_nova.py'], 'web_link': 'https://opendev.org/openstack/shade/commit/5d666939ba35d539ab3e512ec0b165df9f9d0ccc', 'message': 'Fix available_floating_ip when using Nova network\n\nWhen neutron is not available and there are no floating IP already\nallocated to the project, available_floating_ip calls meta.obj_to_dict()\non a Bunch object.\n\nMoreover we can save an API call as we already know the pool name.\n\nChange-Id: I997cb0edc4fd9160b6804a29d404190526303720\n'}]",0,195476,5d666939ba35d539ab3e512ec0b165df9f9d0ccc,8,4,1,6550,,,0,"Fix available_floating_ip when using Nova network

When neutron is not available and there are no floating IP already
allocated to the project, available_floating_ip calls meta.obj_to_dict()
on a Bunch object.

Moreover we can save an API call as we already know the pool name.

Change-Id: I997cb0edc4fd9160b6804a29d404190526303720
",git fetch https://review.opendev.org/openstack/shade refs/changes/76/195476/1 && git format-patch -1 --stdout FETCH_HEAD,"['shade/__init__.py', 'shade/tests/unit/test_floating_ip_nova.py']",2,5d666939ba35d539ab3e512ec0b165df9f9d0ccc,floating-ips," @patch.object(OpenStackCloud, 'nova_client') mock_nova_client): mock_nova_client.floating_ips.create.return_value = \"," @patch.object(OpenStackCloud, '_nova_create_floating_ip') @patch.object(OpenStackCloud, 'list_floating_ip_pools') mock_list_floating_ip_pools, mock__nova_create_floating_ip): mock_list_floating_ip_pools.return_value = self.mock_floating_ip_pools mock__nova_create_floating_ip.return_value = \",5,8
openstack%2Fshade~master~I699d65ef3f9d917e14b4046d5ee4e6763e2ecc74,openstack/shade,master,I699d65ef3f9d917e14b4046d5ee4e6763e2ecc74,Add Neutron/Nova Floating IP delete (i.e. deallocate from project),MERGED,2015-05-15 18:16:10.000000000,2015-06-25 17:41:11.000000000,2015-06-25 17:41:07.000000000,"[{'_account_id': 2}, {'_account_id': 3}, {'_account_id': 3099}, {'_account_id': 6488}, {'_account_id': 6550}]","[{'number': 1, 'created': '2015-05-15 18:16:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/shade/commit/5f76e10ab51af364452047b781f5c841dc74e312', 'message': 'Add Neutron/Nova Floating IP delete (de-allocate from project)\n\nSome clouds out there are still running nova-network but we want to\nprovide support for neutron specific features and concepts like ports,\nnetworks, subnets, etc.\n\nThis change is part of a set that adds neutron support to existing\nfloating IP-related functions, hiding that behind resource-oriented\nmethods.\nFor instance, at high level, end-users can now request that a public IP\nis assigned to an instance without worrying about the specific service,\nprocedures and protocols used to provide that feature in the target\ncloud.\n\nChange-Id: I699d65ef3f9d917e14b4046d5ee4e6763e2ecc74\n'}, {'number': 2, 'created': '2015-06-04 10:36:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/shade/commit/4dcfcfb0eda8d4a9e0565bd9877e51208cece298', 'message': 'Add Neutron/Nova Floating IP delete (de-allocate from project)\n\nSome clouds out there are still running nova-network but we want to\nprovide support for neutron specific features and concepts like ports,\nnetworks, subnets, etc.\n\nThis change is part of a set that adds neutron support to existing\nfloating IP-related functions, hiding that behind resource-oriented\nmethods.\nFor instance, at high level, end-users can now request that a public IP\nis assigned to an instance without worrying about the specific service,\nprocedures and protocols used to provide that feature in the target\ncloud.\n\nChange-Id: I699d65ef3f9d917e14b4046d5ee4e6763e2ecc74\n'}, {'number': 3, 'created': '2015-06-22 15:53:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/shade/commit/a158e8cdef9664bb45597904ebfa13c7b77a72ec', 'message': 'Add Neutron/Nova Floating IP delete (de-allocate from project)\n\nSome clouds out there are still running nova-network but we want to\nprovide support for neutron specific features and concepts like ports,\nnetworks, subnets, etc.\n\nThis change is part of a set that adds neutron support to existing\nfloating IP-related functions, hiding that behind resource-oriented\nmethods.\nFor instance, at high level, end-users can now request that a public IP\nis assigned to an instance without worrying about the specific service,\nprocedures and protocols used to provide that feature in the target\ncloud.\n\nChange-Id: I699d65ef3f9d917e14b4046d5ee4e6763e2ecc74\n'}, {'number': 4, 'created': '2015-06-22 15:55:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/shade/commit/fee8392895fa07952b69e8cb51a31b307f9ba5c4', 'message': 'Add Neutron/Nova Floating IP delete (i.e. deallocate from project)\n\nSome clouds out there are still running nova-network but we want to\nprovide support for neutron specific features and concepts like ports,\nnetworks, subnets, etc.\n\nThis change is part of a set that adds neutron support to existing\nfloating IP-related functions, hiding that behind resource-oriented\nmethods.\nFor instance, at high level, end-users can now request that a public IP\nis assigned to an instance without worrying about the specific service,\nprocedures and protocols used to provide that feature in the target\ncloud.\n\nChange-Id: I699d65ef3f9d917e14b4046d5ee4e6763e2ecc74\n'}, {'number': 5, 'created': '2015-06-24 10:08:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/shade/commit/a5fce41b59e1ea85fa86b6ca630c0553d836f0f8', 'message': 'Add Neutron/Nova Floating IP delete (i.e. deallocate from project)\n\nSome clouds out there are still running nova-network but we want to\nprovide support for neutron specific features and concepts like ports,\nnetworks, subnets, etc.\n\nThis change is part of a set that adds neutron support to existing\nfloating IP-related functions, hiding that behind resource-oriented\nmethods.\nFor instance, at high level, end-users can now request that a public IP\nis assigned to an instance without worrying about the specific service,\nprocedures and protocols used to provide that feature in the target\ncloud.\n\nChange-Id: I699d65ef3f9d917e14b4046d5ee4e6763e2ecc74\n'}, {'number': 6, 'created': '2015-06-24 13:52:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/shade/commit/c2cb6a8026162d7662b2ee088df23e7a7fecfe3c', 'message': 'Add Neutron/Nova Floating IP delete (i.e. deallocate from project)\n\nSome clouds out there are still running nova-network but we want to\nprovide support for neutron specific features and concepts like ports,\nnetworks, subnets, etc.\n\nThis change is part of a set that adds neutron support to existing\nfloating IP-related functions, hiding that behind resource-oriented\nmethods.\nFor instance, at high level, end-users can now request that a public IP\nis assigned to an instance without worrying about the specific service,\nprocedures and protocols used to provide that feature in the target\ncloud.\n\nChange-Id: I699d65ef3f9d917e14b4046d5ee4e6763e2ecc74\n'}, {'number': 7, 'created': '2015-06-24 17:32:28.000000000', 'files': ['shade/tests/unit/test_floating_ip_neutron.py', 'shade/__init__.py', 'shade/_tasks.py', 'shade/tests/unit/test_floating_ip_nova.py'], 'web_link': 'https://opendev.org/openstack/shade/commit/f9c72e91a6284df3e6e520a968b554f29fd54cc9', 'message': 'Add Neutron/Nova Floating IP delete (i.e. deallocate from project)\n\nSome clouds out there are still running nova-network but we want to\nprovide support for neutron specific features and concepts like ports,\nnetworks, subnets, etc.\n\nThis change is part of a set that adds neutron support to existing\nfloating IP-related functions, hiding that behind resource-oriented\nmethods.\nFor instance, at high level, end-users can now request that a public IP\nis assigned to an instance without worrying about the specific service,\nprocedures and protocols used to provide that feature in the target\ncloud.\n\nChange-Id: I699d65ef3f9d917e14b4046d5ee4e6763e2ecc74\n'}]",3,183637,f9c72e91a6284df3e6e520a968b554f29fd54cc9,25,5,7,6550,,,0,"Add Neutron/Nova Floating IP delete (i.e. deallocate from project)

Some clouds out there are still running nova-network but we want to
provide support for neutron specific features and concepts like ports,
networks, subnets, etc.

This change is part of a set that adds neutron support to existing
floating IP-related functions, hiding that behind resource-oriented
methods.
For instance, at high level, end-users can now request that a public IP
is assigned to an instance without worrying about the specific service,
procedures and protocols used to provide that feature in the target
cloud.

Change-Id: I699d65ef3f9d917e14b4046d5ee4e6763e2ecc74
",git fetch https://review.opendev.org/openstack/shade refs/changes/37/183637/1 && git format-patch -1 --stdout FETCH_HEAD,"['shade/tests/unit/test_floating_ip_neutron.py', 'shade/__init__.py', 'shade/_tasks.py', 'shade/tests/unit/test_floating_ip_nova.py']",4,5f76e10ab51af364452047b781f5c841dc74e312,floating-ips," @patch.object(OpenStackCloud, 'get_floating_ip') @patch.object(OpenStackCloud, 'nova_client') @patch.object(OpenStackCloud, 'has_service') def test_deallocate_floating_ip( self, mock_has_service, mock_nova_client, mock_get_floating_ip): mock_has_service.side_effect = has_service_side_effect mock_get_floating_ip.return_value = self.mock_floating_ip_list_rep[2] self.client.deallocate_floating_ip(ip_address='29.29.29.29') mock_nova_client.floating_ips.delete.assert_called_with( floating_ip=self.mock_floating_ip_list_rep[2]['id'])",,93,1
openstack%2Fnova~master~I4249f38cd8b9c23c2cc320838c622e82aae54f16,openstack/nova,master,I4249f38cd8b9c23c2cc320838c622e82aae54f16,Add a TaskLog object,MERGED,2015-04-16 08:14:28.000000000,2015-06-25 17:40:41.000000000,2015-06-25 17:40:35.000000000,"[{'_account_id': 3}, {'_account_id': 642}, {'_account_id': 1653}, {'_account_id': 2271}, {'_account_id': 2750}, {'_account_id': 5170}, {'_account_id': 5754}, {'_account_id': 6062}, {'_account_id': 6450}, {'_account_id': 8276}, {'_account_id': 9008}, {'_account_id': 9578}, {'_account_id': 10118}, {'_account_id': 10385}, {'_account_id': 14358}, {'_account_id': 15286}, {'_account_id': 15751}]","[{'number': 1, 'created': '2015-04-16 08:14:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/fa70f33ad6866bcc03df976415e05e4f53d7fbdf', 'message': 'Add a TaskLog object\n\nThis change adds a TaskLog object to replace calls currently proxying\nthrough conductor.\n\nRelated to blueprint liberty-objects\n\nChange-Id: I4249f38cd8b9c23c2cc320838c622e82aae54f16\n'}, {'number': 2, 'created': '2015-04-16 09:03:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/09a1788a806ed8e84fb019248e62cfc21f051503', 'message': 'Add a TaskLog object\n\nThis change adds a TaskLog object to replace calls currently proxying\nthrough conductor.\n\nRelated to blueprint liberty-objects\n\nChange-Id: I4249f38cd8b9c23c2cc320838c622e82aae54f16\n'}, {'number': 3, 'created': '2015-04-20 11:43:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/e41c8fe13bbcdaf45bccf3593bef7e84dbe9e83b', 'message': 'Add a TaskLog object\n\nThis change adds a TaskLog object to replace calls currently proxying\nthrough conductor.\n\nRelated to blueprint liberty-objects\n\nChange-Id: I4249f38cd8b9c23c2cc320838c622e82aae54f16\n'}, {'number': 4, 'created': '2015-04-20 12:47:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/4bf39313522602d1a5d5db772ef7387249fcbeca', 'message': 'Add a TaskLog object\n\nThis change adds a TaskLog object to replace calls currently proxying\nthrough conductor.\n\nRelated to blueprint liberty-objects\n\nChange-Id: I4249f38cd8b9c23c2cc320838c622e82aae54f16\n'}, {'number': 5, 'created': '2015-04-27 10:06:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/5f5ea4973f12385c6f390c182809196e2247cb71', 'message': 'Add a TaskLog object\n\nThis change adds a TaskLog object to replace calls currently proxying\nthrough conductor.\n\nRelated to blueprint liberty-objects\n\nChange-Id: I4249f38cd8b9c23c2cc320838c622e82aae54f16\n'}, {'number': 6, 'created': '2015-05-10 14:13:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/70291a9840d44b2a55b001591935bc43d1396364', 'message': 'Add a TaskLog object\n\nThis change adds a TaskLog object to replace calls currently proxying\nthrough conductor.\n\nRelated to blueprint liberty-objects\n\nChange-Id: I4249f38cd8b9c23c2cc320838c622e82aae54f16\n'}, {'number': 7, 'created': '2015-05-12 06:42:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/2e851d6eb9c7f423d89c674a031c2d6b06ada81c', 'message': 'Add a TaskLog object\n\nThis change adds a TaskLog object to replace calls currently proxying\nthrough conductor.\n\nRelated to blueprint liberty-objects\n\nChange-Id: I4249f38cd8b9c23c2cc320838c622e82aae54f16\n'}, {'number': 8, 'created': '2015-06-04 07:04:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/0526df546253f8b51b5ee5d061bbdc954b4f44dd', 'message': 'Add a TaskLog object\n\nThis change adds a TaskLog object to replace calls currently proxying\nthrough conductor.\n\nRelated to blueprint liberty-objects\n\nChange-Id: I4249f38cd8b9c23c2cc320838c622e82aae54f16\n'}, {'number': 9, 'created': '2015-06-09 19:27:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/d203bdbd4c52f2dc254acf2907ddc23ce329fd66', 'message': 'Add a TaskLog object\n\nThis change adds a TaskLog object to replace calls currently proxying\nthrough conductor.\n\nRelated to blueprint liberty-objects\n\nChange-Id: I4249f38cd8b9c23c2cc320838c622e82aae54f16\n'}, {'number': 10, 'created': '2015-06-15 11:36:16.000000000', 'files': ['nova/tests/unit/objects/test_objects.py', 'nova/objects/__init__.py', 'nova/tests/unit/objects/test_task_log.py', 'nova/objects/task_log.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/5e92a2a106fdc58bad589ed166b0da99fbed2b4d', 'message': 'Add a TaskLog object\n\nThis change adds a TaskLog object to replace calls currently proxying\nthrough conductor.\n\nRelated to blueprint liberty-objects\n\nChange-Id: I4249f38cd8b9c23c2cc320838c622e82aae54f16\n'}]",4,174244,5e92a2a106fdc58bad589ed166b0da99fbed2b4d,91,17,10,6450,,,0,"Add a TaskLog object

This change adds a TaskLog object to replace calls currently proxying
through conductor.

Related to blueprint liberty-objects

Change-Id: I4249f38cd8b9c23c2cc320838c622e82aae54f16
",git fetch https://review.opendev.org/openstack/nova refs/changes/44/174244/4 && git format-patch -1 --stdout FETCH_HEAD,"['nova/tests/unit/objects/test_objects.py', 'nova/objects/__init__.py', 'nova/tests/unit/objects/test_task_log.py', 'nova/objects/task_log.py']",4,fa70f33ad6866bcc03df976415e05e4f53d7fbdf,instance-usage-audit-use-objects,"# Licensed under the Apache License, Version 2.0 (the ""License""); you may # not use this file except in compliance with the License. You may obtain # a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT # WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the # License for the specific language governing permissions and limitations # under the License. from nova import db from nova.objects import base from nova.objects import fields class TaskLog(base.NovaPersistentObject, base.NovaObject): # Version 1.0: Initial version VERSION = '1.0' fields = { 'id': fields.IntegerField(), 'task_name': fields.StringField(), 'state': fields.StringField(), 'host': fields.StringField(), 'period_beginning': fields.DateTimeField(), 'period_ending': fields.DateTimeField(), 'message': fields.StringField(), 'task_items': fields.IntegerField(), 'errors': fields.IntegerField(), } @staticmethod def _from_db_object(context, task_log, db_task_log): for field in task_log.fields: setattr(task_log, field, db_task_log[field]) task_log._context = context task_log.obj_reset_changes() return task_log @base.serialize_args @base.remotable_classmethod def get(cls, context, task_name, period_beginning, period_ending, host, state=None): db_task_log = db.task_log_get(context, task_name, period_beginning, period_ending, host, state=state) if db_task_log: return cls._from_db_object(context, cls(context), db_task_log) @base.serialize_args @base.remotable_classmethod def begin_task(cls, context, task_name, period_beginning, period_ending, host, task_items=None, message=None): db.task_log_begin_task(context, task_name, period_beginning, period_ending, host, task_items=task_items, message=message) @base.serialize_args @base.remotable_classmethod def end_task(cls, context, task_name, period_beginning, period_ending, host, errors, message=None): db.task_log_end_task(context, task_name, period_beginning, period_ending, host, errors=errors, message=message) class TaskLogList(base.ObjectListBase, base.NovaObject): # Version 1.0: Initial version VERSION = '1.0' fields = { 'objects': fields.ListOfObjectsField('TaskLog'), } child_versions = { '1.0': '1.0', } @base.serialize_args @base.remotable_classmethod def get_all(cls, context, task_name, period_beginning, period_ending, host=None, state=None): db_task_logs = db.task_log_get_all(context, task_name, period_beginning, period_ending, host=host, state=state) return base.obj_make_list(context, cls(context), TaskLog, db_task_logs) ",,228,0
openstack%2Fnova~master~I4ae54e1082b8cd73d2a09d321d71ada1d896eee6,openstack/nova,master,I4ae54e1082b8cd73d2a09d321d71ada1d896eee6,"Remove unused ""id"" and ""rules"" from secgroup body",MERGED,2015-06-16 01:25:10.000000000,2015-06-25 17:40:02.000000000,2015-06-25 17:39:55.000000000,"[{'_account_id': 3}, {'_account_id': 642}, {'_account_id': 1653}, {'_account_id': 2750}, {'_account_id': 5170}, {'_account_id': 6167}, {'_account_id': 8119}, {'_account_id': 8556}, {'_account_id': 9008}, {'_account_id': 9578}, {'_account_id': 10118}, {'_account_id': 10385}, {'_account_id': 14819}, {'_account_id': 15286}, {'_account_id': 16897}]","[{'number': 1, 'created': '2015-06-16 01:25:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/fa8c32fdc907788a97be1f733432e5b2c3025350', 'message': 'Remove unused ""id"" and ""rules"" from secgroup body\n\nIn test_delete_security_group_by_admin, security_group_template is\nused for getting a test request body. And current code specifies\nid and rules. However, ""create a security group"" API just doesn\'t\nuse them at all. So this patch removes them.\n\nChange-Id: I4ae54e1082b8cd73d2a09d321d71ada1d896eee6\n'}, {'number': 2, 'created': '2015-06-23 00:58:56.000000000', 'files': ['nova/tests/unit/api/openstack/compute/contrib/test_security_groups.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/de86db32c54772dabf303e692e31eb81f81cc562', 'message': 'Remove unused ""id"" and ""rules"" from secgroup body\n\nIn test_delete_security_group_by_admin, security_group_template is\nused for getting a test request body. And current code specifies\nid and rules. However, ""create a security group"" API just doesn\'t\nuse them at all.\nSo this patch removes them.\n\nChange-Id: I4ae54e1082b8cd73d2a09d321d71ada1d896eee6\n'}]",4,192029,de86db32c54772dabf303e692e31eb81f81cc562,35,15,2,6167,,,0,"Remove unused ""id"" and ""rules"" from secgroup body

In test_delete_security_group_by_admin, security_group_template is
used for getting a test request body. And current code specifies
id and rules. However, ""create a security group"" API just doesn't
use them at all.
So this patch removes them.

Change-Id: I4ae54e1082b8cd73d2a09d321d71ada1d896eee6
",git fetch https://review.opendev.org/openstack/nova refs/changes/29/192029/1 && git format-patch -1 --stdout FETCH_HEAD,['nova/tests/unit/api/openstack/compute/contrib/test_security_groups.py'],1,fa8c32fdc907788a97be1f733432e5b2c3025350,bug/1460875, sg = security_group_template()," sg = security_group_template(id=2, rules=[])",1,1
openstack%2Fneutron~master~I8c6a08e0cf3b5b5386fe03af9f2174c663b8ac73,openstack/neutron,master,I8c6a08e0cf3b5b5386fe03af9f2174c663b8ac73,Only create one netaddr.IPNetwork object,MERGED,2015-06-24 17:30:32.000000000,2015-06-25 17:39:14.000000000,2015-06-25 17:39:10.000000000,"[{'_account_id': 3}, {'_account_id': 2592}, {'_account_id': 5170}, {'_account_id': 5948}, {'_account_id': 9681}, {'_account_id': 9682}, {'_account_id': 9787}, {'_account_id': 9845}, {'_account_id': 10121}, {'_account_id': 10153}, {'_account_id': 10184}, {'_account_id': 10387}, {'_account_id': 10692}, {'_account_id': 14323}, {'_account_id': 14571}]","[{'number': 1, 'created': '2015-06-24 17:30:32.000000000', 'files': ['neutron/agent/linux/ipset_manager.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/1a480203b2531925d7520b62c94954064a26139d', 'message': 'Only create one netaddr.IPNetwork object\n\nChange-Id: I8c6a08e0cf3b5b5386fe03af9f2174c663b8ac73\n'}]",0,195218,1a480203b2531925d7520b62c94954064a26139d,19,15,1,4395,,,0,"Only create one netaddr.IPNetwork object

Change-Id: I8c6a08e0cf3b5b5386fe03af9f2174c663b8ac73
",git fetch https://review.opendev.org/openstack/neutron refs/changes/18/195218/1 && git format-patch -1 --stdout FETCH_HEAD,['neutron/agent/linux/ipset_manager.py'],1,1a480203b2531925d7520b62c94954064a26139d,, ip = netaddr.IPNetwork(ip) if (ip.prefixlen == 0): if(ip.version == 4): elif (ip.version == 6): sanitized_addresses.append(str(ip)), if (netaddr.IPNetwork(ip).prefixlen == 0): if(netaddr.IPNetwork(ip).version == 4): elif (netaddr.IPNetwork(ip).version == 6): sanitized_addresses.append(ip),5,4
openstack%2Fpuppet-keystone~stable%2Ficehouse~I2c39a6e682e3cff799b1072609c327bf338616d5,openstack/puppet-keystone,stable/icehouse,I2c39a6e682e3cff799b1072609c327bf338616d5,Updated wsgi file from openstack/keystone.,ABANDONED,2014-06-18 12:56:24.000000000,2015-06-25 17:29:16.000000000,,"[{'_account_id': 3}, {'_account_id': 3153}, {'_account_id': 7155}, {'_account_id': 8318}, {'_account_id': 8482}]","[{'number': 1, 'created': '2014-06-18 12:56:24.000000000', 'files': ['files/httpd/keystone.py'], 'web_link': 'https://opendev.org/openstack/puppet-keystone/commit/32c02e153f1b6523f0df2b67989b40ce168b7af1', 'message': 'Updated wsgi file from openstack/keystone.\n\nThe current wsgi file does not work with\nicehouse. The file has been updated from\nthe openstack keystone repository.\n\nChange-Id: I2c39a6e682e3cff799b1072609c327bf338616d5\n'}]",0,100892,32c02e153f1b6523f0df2b67989b40ce168b7af1,17,5,1,8318,,,0,"Updated wsgi file from openstack/keystone.

The current wsgi file does not work with
icehouse. The file has been updated from
the openstack keystone repository.

Change-Id: I2c39a6e682e3cff799b1072609c327bf338616d5
",git fetch https://review.opendev.org/openstack/puppet-keystone refs/changes/92/100892/1 && git format-patch -1 --stdout FETCH_HEAD,['files/httpd/keystone.py'],1,32c02e153f1b6523f0df2b67989b40ce168b7af1,update_wsgi_icehouse,"# NOTE(dstanek): gettextutils.enable_lazy() must be called before # gettextutils._() is called to ensure it has the desired lazy lookup # behavior. This includes cases, like keystone.exceptions, where # gettextutils._() is called at import time. gettextutils.enable_lazy() from keystone.common import dependencyfrom keystone.common import sqlfrom keystone import service config.configure() sql.initialize() config.set_default_for_default_log_levels() config.setup_logging() drivers = service.load_backends() dependency.resolve_future_dependencies()",# vim: tabstop=4 shiftwidth=4 softtabstop=4 # # This file was copied from https://github.com/openstack/keystone/raw/c3b92295b718a41c3136876eb39297081015a97c/httpd/keystone.py # It's only required for platforms on which it is not packaged yet. # It should be removed when available everywhere in a package. # # NOTE(blk-u): # gettextutils.install() must run to set _ before importing any modules that # contain static translated strings. gettextutils.install('keystone') config.setup_logging(CONF),19,14
openstack%2Fpuppet-keystone~master~I35187a857ae6e67b301d62e30525eaab75707161,openstack/puppet-keystone,master,I35187a857ae6e67b301d62e30525eaab75707161,Drop User resource dependency at all,ABANDONED,2015-06-09 20:01:17.000000000,2015-06-25 17:27:17.000000000,,"[{'_account_id': 3}, {'_account_id': 360}, {'_account_id': 3153}, {'_account_id': 9500}, {'_account_id': 14496}]","[{'number': 1, 'created': '2015-06-09 20:01:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-keystone/commit/599bb8fcac309cba9864d54bb42c1f875588d09e', 'message': 'Drop User resource dependency at all\n\nIn a previous patch [1], it has been attempted to drop User/Group\nmanagemement but some dependencies have been missed.\n\nThis patch aims to fix it.\n\n[1] 2abad789290be9f9b5f06e7eac40b438748de84e.\n\nChange-Id: I35187a857ae6e67b301d62e30525eaab75707161\nCloses-bug: #1463540\n'}, {'number': 2, 'created': '2015-06-10 15:55:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-keystone/commit/05a12d3ee26c9305e124a02cc0ec8cca16afa021', 'message': 'Drop User resource dependency at all\n\nIn a previous patch [1], it has been attempted to drop User/Group\nmanagemement but some dependencies have been missed.\n\nThis patch aims to fix it.\n\n[1] 2abad789290be9f9b5f06e7eac40b438748de84e.\n\nChange-Id: I35187a857ae6e67b301d62e30525eaab75707161\nCloses-bug: #1463540\n'}, {'number': 3, 'created': '2015-06-10 18:15:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-keystone/commit/ec2e2bb4238f294f29a901dfba092e11aea0a233', 'message': 'Drop User resource dependency at all\n\nIn a previous patch [1], it has been attempted to drop User/Group\nmanagemement but some dependencies have been missed.\n\nThis patch aims to:\n* Drop all dependencies on User/Group\n* Updating crontab to be able to configure the user\n* Make crontab creation idempotent at first Puppet run\n* Fix a unit test description to be coherent\n\n[1] 2abad789290be9f9b5f06e7eac40b438748de84e.\n\nChange-Id: I35187a857ae6e67b301d62e30525eaab75707161\nCloses-bug: #1463540\n'}, {'number': 4, 'created': '2015-06-10 18:15:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-keystone/commit/a449b927c59bd8f406b18d241864a416a4afa97c', 'message': 'Drop User resource dependency at all\n\nIn a previous patch [1], it has been attempted to drop User/Group\nmanagemement but some dependencies have been missed.\n\nThis patch aims to:\n* Drop all dependencies on User/Group\n* Updating crontab to be able to configure the user\n* Make crontab creation idempotent at first Puppet run\n* Fix a unit test description to be coherent\n\n[1] 2abad789290be9f9b5f06e7eac40b438748de84e.\n\nChange-Id: I35187a857ae6e67b301d62e30525eaab75707161\nCloses-bug: #1463540\n'}, {'number': 5, 'created': '2015-06-10 22:07:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-keystone/commit/fa7fc0fd41408fc451116fdf03d882b322bf5afa', 'message': 'Drop User resource dependency at all\n\nIn a previous patch [1], it has been attempted to drop User/Group\nmanagemement but some dependencies have been missed.\n\nThis patch aims to:\n* Drop all dependencies on User/Group\n* Updating crontab to be able to configure the user\n* Make crontab creation idempotent at first Puppet run\n* Fix a unit test description to be coherent\n\n[1] 2abad789290be9f9b5f06e7eac40b438748de84e.\n\nChange-Id: I35187a857ae6e67b301d62e30525eaab75707161\nCloses-bug: #1463540\n'}, {'number': 6, 'created': '2015-06-10 22:34:00.000000000', 'files': ['manifests/db/sync.pp', 'manifests/cron/token_flush.pp', 'spec/classes/keystone_spec.rb', 'manifests/init.pp', 'spec/classes/keystone_cron_token_flush_spec.rb'], 'web_link': 'https://opendev.org/openstack/puppet-keystone/commit/29636947c0794e1f68eec91c179cf79a42c063a8', 'message': 'Drop User resource dependency at all\n\nIn a previous patch [1], it has been attempted to drop User/Group\nmanagemement but some dependencies have been missed.\n\nThis patch aims to:\n* Drop all dependencies on User/Group\n* Updating crontab to be able to configure the user\n* Make crontab creation idempotent at first Puppet run\n* Fix a unit test description to be coherent\n\n[1] 2abad789290be9f9b5f06e7eac40b438748de84e.\n\nChange-Id: I35187a857ae6e67b301d62e30525eaab75707161\nCloses-bug: #1463540\n'}]",0,189908,29636947c0794e1f68eec91c179cf79a42c063a8,33,5,6,3153,,,0,"Drop User resource dependency at all

In a previous patch [1], it has been attempted to drop User/Group
managemement but some dependencies have been missed.

This patch aims to:
* Drop all dependencies on User/Group
* Updating crontab to be able to configure the user
* Make crontab creation idempotent at first Puppet run
* Fix a unit test description to be coherent

[1] 2abad789290be9f9b5f06e7eac40b438748de84e.

Change-Id: I35187a857ae6e67b301d62e30525eaab75707161
Closes-bug: #1463540
",git fetch https://review.opendev.org/openstack/puppet-keystone refs/changes/08/189908/2 && git format-patch -1 --stdout FETCH_HEAD,"['manifests/db/sync.pp', 'spec/classes/keystone_spec.rb', 'manifests/init.pp']",3,599bb8fcac309cba9864d54bb42c1f875588d09e,bug/1463540,," require => User['keystone'],",0,3
openstack%2Fpuppet-keystone~master~I0d1eba9b52fe9c4291af73d451b2caf9372f314e,openstack/puppet-keystone,master,I0d1eba9b52fe9c4291af73d451b2caf9372f314e,"Revert ""Revert ""remove POSIX users, groups and file modes""""",ABANDONED,2015-06-10 15:52:13.000000000,2015-06-25 17:26:53.000000000,,"[{'_account_id': 3}, {'_account_id': 3153}]","[{'number': 1, 'created': '2015-06-10 15:52:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-keystone/commit/6489221946d2da0f27fcca5f1ff783c06b90906b', 'message': 'Revert ""Revert ""remove POSIX users, groups and file modes""""\n\nThis reverts commit deaff0106014f042af835c279a05fa615e0a3d5d.\n\nChange-Id: I0d1eba9b52fe9c4291af73d451b2caf9372f314e\n'}, {'number': 2, 'created': '2015-06-10 18:04:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-keystone/commit/1b3363fa5eb7a830f30d1b4dcb3f3b219754d6f3', 'message': 'Revert ""Revert ""remove POSIX users, groups and file modes""""\n\nThis reverts commit deaff0106014f042af835c279a05fa615e0a3d5d.\n\nChange-Id: I0d1eba9b52fe9c4291af73d451b2caf9372f314e\n'}, {'number': 3, 'created': '2015-06-23 04:13:15.000000000', 'files': ['spec/classes/keystone_spec.rb', 'manifests/init.pp'], 'web_link': 'https://opendev.org/openstack/puppet-keystone/commit/2054795083ca1bf27a8520075e55da408f6f10ba', 'message': 'Revert ""Revert ""remove POSIX users, groups and file modes""""\n\nThis reverts commit deaff0106014f042af835c279a05fa615e0a3d5d.\n\nChange-Id: I0d1eba9b52fe9c4291af73d451b2caf9372f314e\n'}]",0,190237,2054795083ca1bf27a8520075e55da408f6f10ba,11,2,3,3153,,,0,"Revert ""Revert ""remove POSIX users, groups and file modes""""

This reverts commit deaff0106014f042af835c279a05fa615e0a3d5d.

Change-Id: I0d1eba9b52fe9c4291af73d451b2caf9372f314e
",git fetch https://review.opendev.org/openstack/puppet-keystone refs/changes/37/190237/1 && git format-patch -1 --stdout FETCH_HEAD,"['spec/classes/keystone_spec.rb', 'manifests/init.pp']",2,6489221946d2da0f27fcca5f1ff783c06b90906b,bug/1463540,," group { 'keystone': ensure => present, system => true, require => Package['keystone'], } user { 'keystone': ensure => 'present', gid => 'keystone', system => true, require => Package['keystone'], } mode => '0750', owner => 'keystone', group => 'keystone', mode => '0600', owner => 'keystone', group => 'keystone',",0,33
openstack%2Fneutron~master~I602e0d484c5e00eb48b86c4c8c4eff0be195c3a5,openstack/neutron,master,I602e0d484c5e00eb48b86c4c8c4eff0be195c3a5,Fix >80 char lines that pep8 failed to detect,MERGED,2015-06-24 18:06:26.000000000,2015-06-25 17:21:57.000000000,2015-06-25 17:21:45.000000000,"[{'_account_id': 3}, {'_account_id': 105}, {'_account_id': 2874}, {'_account_id': 5170}, {'_account_id': 5948}, {'_account_id': 6854}, {'_account_id': 7016}, {'_account_id': 8124}, {'_account_id': 9681}, {'_account_id': 9682}, {'_account_id': 9787}, {'_account_id': 9845}, {'_account_id': 10121}, {'_account_id': 10153}, {'_account_id': 10184}, {'_account_id': 10370}, {'_account_id': 10387}, {'_account_id': 10980}, {'_account_id': 12955}, {'_account_id': 14323}, {'_account_id': 14571}, {'_account_id': 14605}]","[{'number': 1, 'created': '2015-06-24 18:06:26.000000000', 'files': ['neutron/tests/unit/plugins/openvswitch/agent/test_ovs_neutron_agent.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/93d564223e8b76d10aa7b55f1b1d49f592d1c800', 'message': 'Fix >80 char lines that pep8 failed to detect\n\nChange-Id: I602e0d484c5e00eb48b86c4c8c4eff0be195c3a5\n'}]",0,195243,93d564223e8b76d10aa7b55f1b1d49f592d1c800,29,22,1,7787,,,0,"Fix >80 char lines that pep8 failed to detect

Change-Id: I602e0d484c5e00eb48b86c4c8c4eff0be195c3a5
",git fetch https://review.opendev.org/openstack/neutron refs/changes/43/195243/1 && git format-patch -1 --stdout FETCH_HEAD,['neutron/tests/unit/plugins/openvswitch/agent/test_ovs_neutron_agent.py'],1,93d564223e8b76d10aa7b55f1b1d49f592d1c800,cleanupline," mock.patch('neutron.openstack.common.loopingcall.' 'FixedIntervalLoopingCall', new=MockFixedIntervalLoopingCall),\ mock.patch('neutron.agent.common.ovs_lib.BaseOVS.' 'get_bridge_external_bridge_id', side_effect=pullup_side_effect),\ mock.patch('neutron.openstack.common.loopingcall.' 'FixedIntervalLoopingCall', new=MockFixedIntervalLoopingCall),\"," mock.patch('neutron.openstack.common.loopingcall.' 'FixedIntervalLoopingCall', new=MockFixedIntervalLoopingCall),\ mock.patch('neutron.agent.common.ovs_lib.BaseOVS.' 'get_bridge_external_bridge_id', side_effect=pullup_side_effect),\ mock.patch('neutron.openstack.common.loopingcall.' 'FixedIntervalLoopingCall', new=MockFixedIntervalLoopingCall),\",9,3
openstack%2Ftempest-lib~master~Ib7ee5ce85e14fffd28c70bb9da4fbea87a8a5903,openstack/tempest-lib,master,Ib7ee5ce85e14fffd28c70bb9da4fbea87a8a5903,Categorize rest client exceptions,MERGED,2015-05-21 05:17:25.000000000,2015-06-25 17:16:23.000000000,2015-06-25 17:16:20.000000000,"[{'_account_id': 3}, {'_account_id': 1192}, {'_account_id': 5689}, {'_account_id': 5803}]","[{'number': 1, 'created': '2015-05-21 05:17:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest-lib/commit/6dae1fd2e43deb1d76bd4b4514ce650cfb8b7606', 'message': 'Categorize rest client exceptions\n\nIn order to help to distinguish Client (4xx)\nand not client issues the Rest Client exceptions\nmoved to 3 Category:\n\n- Client 4xx\n- Server 5xx\n- Other Rest Client exceptions\n\nUnexpectedContentType exception added\nto distinguish the 415 case from the Other\nsituation.\n\nChange-Id: Ib7ee5ce85e14fffd28c70bb9da4fbea87a8a5903\n'}, {'number': 2, 'created': '2015-05-21 06:03:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest-lib/commit/959ce60b665c90827e13c86dfe9369968824a671', 'message': 'Categorize rest client exceptions\n\nIn order to help to distinguish Client (4xx)\nand not client issues the Rest Client exceptions\nmoved to 3 Category:\n\n- Client 4xx\n- Server 5xx\n- Other Rest Client exceptions\n\nUnexpectedContentType exception added\nto distinguish the 415 case from the Other\nsituation.\n\nChange-Id: Ib7ee5ce85e14fffd28c70bb9da4fbea87a8a5903\n'}, {'number': 3, 'created': '2015-06-22 07:37:20.000000000', 'files': ['tempest_lib/exceptions.py', 'tempest_lib/common/rest_client.py', 'tempest_lib/tests/test_rest_client.py'], 'web_link': 'https://opendev.org/openstack/tempest-lib/commit/b48f9feb47894549f2d2cdffb8149d1e9eef85a7', 'message': 'Categorize rest client exceptions\n\nIn order to help to distinguish Client (4xx)\nand not client issues the Rest Client exceptions\nmoved to 3 Category:\n\n- Client 4xx\n- Server 5xx\n- Other Rest Client exceptions\n\nUnexpectedContentType exception added\nto distinguish the 415 case from the Other\nsituation.\n\nChange-Id: Ib7ee5ce85e14fffd28c70bb9da4fbea87a8a5903\n'}]",1,184712,b48f9feb47894549f2d2cdffb8149d1e9eef85a7,16,4,3,5803,,,0,"Categorize rest client exceptions

In order to help to distinguish Client (4xx)
and not client issues the Rest Client exceptions
moved to 3 Category:

- Client 4xx
- Server 5xx
- Other Rest Client exceptions

UnexpectedContentType exception added
to distinguish the 415 case from the Other
situation.

Change-Id: Ib7ee5ce85e14fffd28c70bb9da4fbea87a8a5903
",git fetch https://review.opendev.org/openstack/tempest-lib refs/changes/12/184712/1 && git format-patch -1 --stdout FETCH_HEAD,"['tempest_lib/exceptions.py', 'tempest_lib/common/rest_client.py']",2,6dae1fd2e43deb1d76bd4b4514ce650cfb8b7606,rest-exp-cat, :raises UnexpectedContentType: If the content-type of the response isn't an expect type :raises InvalidContentType: If a 415 response code is received raise exceptions.UnexpectedContentType(str(resp.status)), :raises InvalidContentType: If the content-type of the response isn't an expect type or a 415 response code is received raise exceptions.InvalidContentType(str(resp.status)),38,22
openstack%2Fdragonflow~master~I6b9d751a0f1c87bc6918e9d304d131613c6b655f,openstack/dragonflow,master,I6b9d751a0f1c87bc6918e9d304d131613c6b655f,Fix properties naming for the PortData object,MERGED,2015-06-25 06:52:50.000000000,2015-06-25 17:07:46.000000000,2015-06-25 17:07:44.000000000,"[{'_account_id': 3}, {'_account_id': 2023}, {'_account_id': 11343}, {'_account_id': 13070}, {'_account_id': 14249}]","[{'number': 1, 'created': '2015-06-25 06:52:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/dragonflow/commit/29a4cddf84b5e073f2d27b0bfcbd92f5993d4b3b', 'message': 'Fix properties naming for the PortData object\n\nThis is part of the comments that were not merged in by mistake from\nprevious patches\n\nChange-Id: I6b9d751a0f1c87bc6918e9d304d131613c6b655f\n'}, {'number': 2, 'created': '2015-06-25 07:16:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/dragonflow/commit/9759eb738ecd8d5cc8051da4e8c46d953c2dd048', 'message': 'Fix properties naming for the PortData object\n\nThis is part of the comments that were not merged in by mistake from\nprevious patches\n\nChange-Id: I6b9d751a0f1c87bc6918e9d304d131613c6b655f\n'}, {'number': 3, 'created': '2015-06-25 09:53:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/dragonflow/commit/1fed71bf495744f22bb4e24e513d5d898af1c663', 'message': 'Fix properties naming for the PortData object\n\nThis is part of the comments that were not merged in by mistake from\nprevious patches\n\nChange-Id: I6b9d751a0f1c87bc6918e9d304d131613c6b655f\n'}, {'number': 4, 'created': '2015-06-25 11:15:07.000000000', 'files': ['dragonflow/controller/l3_openflow_app.py'], 'web_link': 'https://opendev.org/openstack/dragonflow/commit/8a0de6bed58f1a15eb12172b9f1a404a9d54021f', 'message': 'Fix properties naming for the PortData object\n\nThis is part of the comments that were not merged in by mistake from\nprevious patches\n\nChange-Id: I6b9d751a0f1c87bc6918e9d304d131613c6b655f\n'}]",0,195431,8a0de6bed58f1a15eb12172b9f1a404a9d54021f,18,5,4,13070,,,0,"Fix properties naming for the PortData object

This is part of the comments that were not merged in by mistake from
previous patches

Change-Id: I6b9d751a0f1c87bc6918e9d304d131613c6b655f
",git fetch https://review.opendev.org/openstack/dragonflow refs/changes/31/195431/4 && git format-patch -1 --stdout FETCH_HEAD,['dragonflow/controller/l3_openflow_app.py'],1,29a4cddf84b5e073f2d27b0bfcbd92f5993d4b3b,fix_subnet_list, def subnets(self): subnets = [] subnets.append(fixed_ip['subnet_id']) return subnets except KeyError: return subnets for subnet_id in port_data.subnets:, def get_subnets(self): subnet_l = [] subnet_l.append(fixed_ip['subnet_id']) return subnet_l except KeyError: return subnet_l for subnet_id in port_data.get_subnets:,6,6
openstack%2Fshade~master~I8006913ed2edf9b5019e83c8b958d48dfdf04cb2,openstack/shade,master,I8006913ed2edf9b5019e83c8b958d48dfdf04cb2,Do not use environment for Swift unit tests,MERGED,2015-06-25 09:21:54.000000000,2015-06-25 17:06:57.000000000,2015-06-25 17:06:54.000000000,"[{'_account_id': 2}, {'_account_id': 3}, {'_account_id': 3099}, {'_account_id': 6133}]","[{'number': 1, 'created': '2015-06-25 09:21:54.000000000', 'files': ['shade/tests/unit/test_object.py'], 'web_link': 'https://opendev.org/openstack/shade/commit/1e447b4e202de54c0026ae9ed2a2fa7f6d36f22e', 'message': 'Do not use environment for Swift unit tests\n\nSwift unit tests initialize the cloud object using\nshade::openstack_cloud(). That method uses os-cloud-config to load\ncloud parameters.\nAs a consequence, this test could use real clouds or just fail because\nof unexpected values in the cloud object settings.\n\nChange-Id: I8006913ed2edf9b5019e83c8b958d48dfdf04cb2\n'}]",0,195474,1e447b4e202de54c0026ae9ed2a2fa7f6d36f22e,8,4,1,6550,,,0,"Do not use environment for Swift unit tests

Swift unit tests initialize the cloud object using
shade::openstack_cloud(). That method uses os-cloud-config to load
cloud parameters.
As a consequence, this test could use real clouds or just fail because
of unexpected values in the cloud object settings.

Change-Id: I8006913ed2edf9b5019e83c8b958d48dfdf04cb2
",git fetch https://review.opendev.org/openstack/shade refs/changes/74/195474/1 && git format-patch -1 --stdout FETCH_HEAD,['shade/tests/unit/test_object.py'],1,1e447b4e202de54c0026ae9ed2a2fa7f6d36f22e,functional-tests,"from shade import OpenStackCloud self.cloud = OpenStackCloud('cloud', {})", self.cloud = shade.openstack_cloud(),2,1
openstack%2Fshade~master~Ie05d08c695f4d42d41d23d5e35e9caca03aaebb1,openstack/shade,master,Ie05d08c695f4d42d41d23d5e35e9caca03aaebb1,Skip Swift functional tests if needed,MERGED,2015-06-25 08:43:48.000000000,2015-06-25 17:05:43.000000000,2015-06-25 17:05:42.000000000,"[{'_account_id': 2}, {'_account_id': 3}, {'_account_id': 3099}, {'_account_id': 6133}]","[{'number': 1, 'created': '2015-06-25 08:43:48.000000000', 'files': ['shade/tests/functional/test_object.py'], 'web_link': 'https://opendev.org/openstack/shade/commit/fd36850b24ade1af62aa510850e34d473428e1f5', 'message': ""Skip Swift functional tests if needed\n\nNot all clouds have Swift, this patch skips functional tests for it if\nthe cloud used doesn't have the object service in its catalog.\n\nA warning message is printed to inform the user object service\nfunctional tests have been skipped.\n\nChange-Id: Ie05d08c695f4d42d41d23d5e35e9caca03aaebb1\n""}]",0,195452,fd36850b24ade1af62aa510850e34d473428e1f5,8,4,1,6550,,,0,"Skip Swift functional tests if needed

Not all clouds have Swift, this patch skips functional tests for it if
the cloud used doesn't have the object service in its catalog.

A warning message is printed to inform the user object service
functional tests have been skipped.

Change-Id: Ie05d08c695f4d42d41d23d5e35e9caca03aaebb1
",git fetch https://review.opendev.org/openstack/shade refs/changes/52/195452/1 && git format-patch -1 --stdout FETCH_HEAD,['shade/tests/functional/test_object.py'],1,fd36850b24ade1af62aa510850e34d473428e1f5,functional-tests, if not self.cloud.has_service('object'): self.skipTest('Object service not supported by cloud'),,2,0
openstack%2Fastara~master~If8353c96b0a6d5281aff2a226f54f5aa2233acb3,openstack/astara,master,If8353c96b0a6d5281aff2a226f54f5aa2233acb3,Migrate to oslo.log,ABANDONED,2015-06-12 22:49:55.000000000,2015-06-25 17:05:18.000000000,,"[{'_account_id': 3}, {'_account_id': 1420}, {'_account_id': 6287}, {'_account_id': 6923}]","[{'number': 1, 'created': '2015-06-12 22:49:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/astara/commit/1752564997ca1fe840561e7c753afe555c7ee252', 'message': 'Migrate to oslo.log\n\nThis updates logging to use olso.log.\n\nThis will likely need to be squashed into the oslo.messaging patch but pushing\nseperately for the sake of initial review.\n\nChange-Id: If8353c96b0a6d5281aff2a226f54f5aa2233acb3\n'}, {'number': 2, 'created': '2015-06-16 01:38:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/astara/commit/8bd9b206bb8c0cb7ae171bab48a7ebde77395169', 'message': 'Migrate to oslo.log\n\nThis updates logging to use olso.log.\n\nThis will likely need to be squashed into the oslo.messaging patch but pushing\nseperately for the sake of initial review.\n\nChange-Id: If8353c96b0a6d5281aff2a226f54f5aa2233acb3\n'}, {'number': 3, 'created': '2015-06-16 06:57:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/astara/commit/2b2db6a609aafabc596057b18f5704a277f2d56d', 'message': 'Migrate to oslo.log\n\nThis updates logging to use olso.log.\n\nThis will likely need to be squashed into the oslo.messaging patch but pushing\nseperately for the sake of initial review.\n\nChange-Id: If8353c96b0a6d5281aff2a226f54f5aa2233acb3\n'}, {'number': 4, 'created': '2015-06-16 18:07:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/astara/commit/b73c3b83903b01a25e98ef2c85819ed0a2145032', 'message': 'Migrate to oslo.log\n\nThis updates logging to use olso.log.\n\nThis will likely need to be squashed into the oslo.messaging patch but pushing\nseperately for the sake of initial review.\n\nChange-Id: If8353c96b0a6d5281aff2a226f54f5aa2233acb3\n'}, {'number': 5, 'created': '2015-06-16 21:39:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/astara/commit/9bf505c124ec6ae2eac2998ce940a5b7be836be1', 'message': 'Migrate to oslo.log\n\nThis updates logging to use olso.log.\n\nThis will likely need to be squashed into the oslo.messaging patch but pushing\nseperately for the sake of initial review.\n\nChange-Id: If8353c96b0a6d5281aff2a226f54f5aa2233acb3\n'}, {'number': 6, 'created': '2015-06-22 22:28:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/astara/commit/f7f3fb052ee0f3a1361f646eed4a74f8338519b0', 'message': 'Migrate to oslo.log\n\nThis updates logging to use olso.log. Also updates the default logging format\nto be a bit more standard, and sets up devstack to configure colorized logging\nin the screen session.\n\nThis will likely need to be squashed into the oslo.messaging patch but pushing\nseperately for the sake of initial review.\n\nChange-Id: If8353c96b0a6d5281aff2a226f54f5aa2233acb3\n'}, {'number': 7, 'created': '2015-06-25 00:38:20.000000000', 'files': ['akanda/rug/openstack/common/rpc/impl_fake.py', 'akanda/rug/notifications.py', 'akanda/rug/common/config.py', 'akanda/rug/openstack/common/rpc/dispatcher.py', 'akanda/rug/openstack/common/rpc/proxy.py', 'akanda/rug/openstack/common/rpc/impl_kombu.py', 'akanda/rug/worker.py', 'akanda/rug/common/linux/interface.py', 'akanda/rug/api/configuration.py', 'akanda/rug/api/neutron.py', 'akanda/rug/main.py', 'requirements.txt', 'akanda/rug/test/unit/test_main.py', 'akanda/rug/common/log_shim.py', 'akanda/rug/common/linux/utils.py', 'akanda/rug/test/unit/api/test_rug_api.py', 'akanda/rug/openstack/common/log.py', 'akanda/rug/state.py', 'akanda/rug/populate.py', 'akanda/rug/api/akanda_client.py', 'akanda/rug/service.py', 'akanda/rug/api/rug.py', 'akanda/rug/openstack/common/rpc/amqp.py', 'devstack/plugin.sh', 'akanda/rug/openstack/common/rpc/impl_qpid.py', 'akanda/rug/openstack/common/rpc/common.py', 'akanda/rug/scheduler.py', 'akanda/rug/common/rpc.py', 'akanda/rug/api/nova.py', 'akanda/rug/openstack/common/rpc/matchmaker.py', 'akanda/rug/openstack/common/rpc/__init__.py', 'akanda/rug/daemon.py', 'akanda/rug/openstack/common/rpc/service.py', 'akanda/rug/common/linux/ovs_lib.py', 'akanda/rug/tenant.py', 'akanda/rug/health.py', 'akanda/rug/metadata.py', 'akanda/rug/openstack/common/rpc/impl_zmq.py'], 'web_link': 'https://opendev.org/openstack/astara/commit/0f34cc917f4b8f0a4862aa0cce9ce0def2ba6974', 'message': 'Migrate to oslo.log\n\nThis updates logging to use olso.log. Also updates the default logging format\nto be a bit more standard, and sets up devstack to configure colorized logging\nin the screen session.\n\nThis will likely need to be squashed into the oslo.messaging patch but pushing\nseperately for the sake of initial review.\n\nChange-Id: If8353c96b0a6d5281aff2a226f54f5aa2233acb3\n'}]",0,191241,0f34cc917f4b8f0a4862aa0cce9ce0def2ba6974,28,4,7,1420,,,0,"Migrate to oslo.log

This updates logging to use olso.log. Also updates the default logging format
to be a bit more standard, and sets up devstack to configure colorized logging
in the screen session.

This will likely need to be squashed into the oslo.messaging patch but pushing
seperately for the sake of initial review.

Change-Id: If8353c96b0a6d5281aff2a226f54f5aa2233acb3
",git fetch https://review.opendev.org/openstack/astara refs/changes/41/191241/1 && git format-patch -1 --stdout FETCH_HEAD,"['akanda/rug/openstack/common/rpc/impl_fake.py', 'akanda/rug/notifications.py', 'akanda/rug/openstack/common/rpc/dispatcher.py', 'akanda/rug/openstack/common/rpc/proxy.py', 'akanda/rug/openstack/common/rpc/impl_kombu.py', 'akanda/rug/worker.py', 'akanda/rug/common/linux/interface.py', 'akanda/rug/api/configuration.py', 'akanda/rug/api/neutron.py', 'akanda/rug/main.py', 'requirements.txt', 'akanda/rug/common/linux/utils.py', 'akanda/rug/test/unit/api/test_rug_api.py', 'akanda/rug/openstack/common/log.py', 'akanda/rug/state.py', 'akanda/rug/populate.py', 'akanda/rug/api/akanda_client.py', 'akanda/rug/service.py', 'akanda/rug/api/rug.py', 'akanda/rug/openstack/common/rpc/amqp.py', 'akanda/rug/openstack/common/rpc/impl_qpid.py', 'akanda/rug/openstack/common/rpc/common.py', 'akanda/rug/scheduler.py', 'akanda/rug/common/rpc.py', 'akanda/rug/api/nova.py', 'akanda/rug/openstack/common/rpc/matchmaker.py', 'akanda/rug/openstack/common/rpc/__init__.py', 'akanda/rug/daemon.py', 'akanda/rug/openstack/common/rpc/service.py', 'akanda/rug/common/linux/ovs_lib.py', 'akanda/rug/tenant.py', 'akanda/rug/health.py', 'akanda/rug/metadata.py', 'akanda/rug/openstack/common/rpc/impl_zmq.py']",34,1752564997ca1fe840561e7c753afe555c7ee252,rpc,,"# Copyright 2014 DreamHost, LLC # # Author: DreamHost, LLC # # Licensed under the Apache License, Version 2.0 (the ""License""); you may # not use this file except in compliance with the License. You may obtain # a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT # WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the # License for the specific language governing permissions and limitations # under the License. # vim: tabstop=4 shiftwidth=4 softtabstop=4 # Copyright 2011 Cloudscaling Group, Inc # # Licensed under the Apache License, Version 2.0 (the ""License""); you may # not use this file except in compliance with the License. You may obtain # a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT # WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the # License for the specific language governing permissions and limitations # under the License. import os import pprint import re import socket import sys import types import uuid import eventlet import greenlet from oslo.config import cfg from akanda.rug.openstack.common import excutils from akanda.rug.openstack.common.gettextutils import _ from akanda.rug.openstack.common import importutils from akanda.rug.openstack.common import jsonutils from akanda.rug.openstack.common import processutils as utils from akanda.rug.openstack.common.rpc import common as rpc_common zmq = importutils.try_import('eventlet.green.zmq') # for convenience, are not modified. pformat = pprint.pformat Timeout = eventlet.timeout.Timeout LOG = rpc_common.LOG RemoteError = rpc_common.RemoteError RPCException = rpc_common.RPCException zmq_opts = [ cfg.StrOpt('rpc_zmq_bind_address', default='*', help='ZeroMQ bind address. Should be a wildcard (*), ' 'an ethernet interface, or IP. ' 'The ""host"" option should point or resolve to this ' 'address.'), # The module.Class to use for matchmaking. cfg.StrOpt( 'rpc_zmq_matchmaker', default=('akanda.rug.openstack.common.rpc.' 'matchmaker.MatchMakerLocalhost'), help='MatchMaker driver', ), # The following port is unassigned by IANA as of 2012-05-21 cfg.IntOpt('rpc_zmq_port', default=9501, help='ZeroMQ receiver listening port'), cfg.IntOpt('rpc_zmq_contexts', default=1, help='Number of ZeroMQ contexts, defaults to 1'), cfg.IntOpt('rpc_zmq_topic_backlog', default=None, help='Maximum number of ingress messages to locally buffer ' 'per topic. Default is unlimited.'), cfg.StrOpt('rpc_zmq_ipc_dir', default='/var/run/openstack', help='Directory for holding IPC sockets'), cfg.StrOpt('rpc_zmq_host', default=socket.gethostname(), help='Name of this node. Must be a valid hostname, FQDN, or ' 'IP address. Must match ""host"" option, if running Nova.') ] CONF = cfg.CONF CONF.register_opts(zmq_opts) ZMQ_CTX = None # ZeroMQ Context, must be global. matchmaker = None # memoized matchmaker object def _serialize(data): """""" Serialization wrapper We prefer using JSON, but it cannot encode all types. Error if a developer passes us bad data. """""" try: return jsonutils.dumps(data, ensure_ascii=True) except TypeError: with excutils.save_and_reraise_exception(): LOG.error(_(""JSON serialization failed."")) def _deserialize(data): """""" Deserialization wrapper """""" LOG.debug(_(""Deserializing: %s""), data) return jsonutils.loads(data) class ZmqSocket(object): """""" A tiny wrapper around ZeroMQ to simplify the send/recv protocol and connection management. Can be used as a Context (supports the 'with' statement). """""" def __init__(self, addr, zmq_type, bind=True, subscribe=None): self.sock = _get_ctxt().socket(zmq_type) self.addr = addr self.type = zmq_type self.subscriptions = [] # Support failures on sending/receiving on wrong socket type. self.can_recv = zmq_type in (zmq.PULL, zmq.SUB) self.can_send = zmq_type in (zmq.PUSH, zmq.PUB) self.can_sub = zmq_type in (zmq.SUB, ) # Support list, str, & None for subscribe arg (cast to list) do_sub = { list: subscribe, str: [subscribe], type(None): [] }[type(subscribe)] for f in do_sub: self.subscribe(f) str_data = {'addr': addr, 'type': self.socket_s(), 'subscribe': subscribe, 'bind': bind} LOG.debug(_(""Connecting to %(addr)s with %(type)s""), str_data) LOG.debug(_(""-> Subscribed to %(subscribe)s""), str_data) LOG.debug(_(""-> bind: %(bind)s""), str_data) try: if bind: self.sock.bind(addr) else: self.sock.connect(addr) except Exception: raise RPCException(_(""Could not open socket."")) def socket_s(self): """"""Get socket type as string."""""" t_enum = ('PUSH', 'PULL', 'PUB', 'SUB', 'REP', 'REQ', 'ROUTER', 'DEALER') return dict(map(lambda t: (getattr(zmq, t), t), t_enum))[self.type] def subscribe(self, msg_filter): """"""Subscribe."""""" if not self.can_sub: raise RPCException(""Cannot subscribe on this socket."") LOG.debug(_(""Subscribing to %s""), msg_filter) try: self.sock.setsockopt(zmq.SUBSCRIBE, msg_filter) except Exception: return self.subscriptions.append(msg_filter) def unsubscribe(self, msg_filter): """"""Unsubscribe."""""" if msg_filter not in self.subscriptions: return self.sock.setsockopt(zmq.UNSUBSCRIBE, msg_filter) self.subscriptions.remove(msg_filter) def close(self): if self.sock is None or self.sock.closed: return # We must unsubscribe, or we'll leak descriptors. if len(self.subscriptions) > 0: for f in self.subscriptions: try: self.sock.setsockopt(zmq.UNSUBSCRIBE, f) except Exception: pass self.subscriptions = [] try: # Default is to linger self.sock.close() except Exception: # While this is a bad thing to happen, # it would be much worse if some of the code calling this # were to fail. For now, lets log, and later evaluate # if we can safely raise here. LOG.error(""ZeroMQ socket could not be closed."") self.sock = None def recv(self): if not self.can_recv: raise RPCException(_(""You cannot recv on this socket."")) return self.sock.recv_multipart() def send(self, data): if not self.can_send: raise RPCException(_(""You cannot send on this socket."")) self.sock.send_multipart(data) class ZmqClient(object): """"""Client for ZMQ sockets."""""" def __init__(self, addr, socket_type=None, bind=False): if socket_type is None: socket_type = zmq.PUSH self.outq = ZmqSocket(addr, socket_type, bind=bind) def cast(self, msg_id, topic, data, envelope=False): msg_id = msg_id or 0 if not (envelope or rpc_common._SEND_RPC_ENVELOPE): self.outq.send(map(bytes, (msg_id, topic, 'cast', _serialize(data)))) return rpc_envelope = rpc_common.serialize_msg(data[1], envelope) zmq_msg = reduce(lambda x, y: x + y, rpc_envelope.items()) self.outq.send(map(bytes, (msg_id, topic, 'impl_zmq_v2', data[0]) + zmq_msg)) def close(self): self.outq.close() class RpcContext(rpc_common.CommonRpcContext): """"""Context that supports replying to a rpc.call."""""" def __init__(self, **kwargs): self.replies = [] super(RpcContext, self).__init__(**kwargs) def deepcopy(self): values = self.to_dict() values['replies'] = self.replies return self.__class__(**values) def reply(self, reply=None, failure=None, ending=False): if ending: return self.replies.append(reply) @classmethod def marshal(self, ctx): ctx_data = ctx.to_dict() return _serialize(ctx_data) @classmethod def unmarshal(self, data): return RpcContext.from_dict(_deserialize(data)) class InternalContext(object): """"""Used by ConsumerBase as a private context for - methods."""""" def __init__(self, proxy): self.proxy = proxy self.msg_waiter = None def _get_response(self, ctx, proxy, topic, data): """"""Process a curried message and cast the result to topic."""""" LOG.debug(_(""Running func with context: %s""), ctx.to_dict()) data.setdefault('version', None) data.setdefault('args', {}) try: result = proxy.dispatch( ctx, data['version'], data['method'], **data['args']) return ConsumerBase.normalize_reply(result, ctx.replies) except greenlet.GreenletExit: # ignore these since they are just from shutdowns pass except rpc_common.ClientException, e: LOG.debug(_(""Expected exception during message handling (%s)"") % e._exc_info[1]) return {'exc': rpc_common.serialize_remote_exception(e._exc_info, log_failure=False)} except Exception: LOG.error(_(""Exception during message handling"")) return {'exc': rpc_common.serialize_remote_exception(sys.exc_info())} def reply(self, ctx, proxy, msg_id=None, context=None, topic=None, msg=None): """"""Reply to a casted call."""""" # Our real method is curried into msg['args'] child_ctx = RpcContext.unmarshal(msg[0]) response = ConsumerBase.normalize_reply( self._get_response(child_ctx, proxy, topic, msg[1]), ctx.replies) LOG.debug(_(""Sending reply"")) _multi_send(_cast, ctx, topic, { 'method': '-process_reply', 'args': { 'msg_id': msg_id, # Include for Folsom compat. 'response': response } }, _msg_id=msg_id) class ConsumerBase(object): """"""Base Consumer."""""" def __init__(self): self.private_ctx = InternalContext(None) @classmethod def normalize_reply(self, result, replies): # TODO(ewindisch): re-evaluate and document this method. if isinstance(result, types.GeneratorType): return list(result) elif replies: return replies else: return [result] def process(self, proxy, ctx, data): data.setdefault('version', None) data.setdefault('args', {}) # Method starting with - are # processed internally. (non-valid method name) method = data.get('method') if not method: LOG.error(_(""RPC message did not include method."")) return # Internal method # uses internal context for safety. if method == '-reply': self.private_ctx.reply(ctx, proxy, **data['args']) return proxy.dispatch(ctx, data['version'], data['method'], **data['args']) class ZmqBaseReactor(ConsumerBase): """""" A consumer class implementing a centralized casting broker (PULL-PUSH) for RoundRobin requests. """""" def __init__(self, conf): super(ZmqBaseReactor, self).__init__() self.mapping = {} self.proxies = {} self.threads = [] self.sockets = [] self.subscribe = {} self.pool = eventlet.greenpool.GreenPool(conf.rpc_thread_pool_size) def register(self, proxy, in_addr, zmq_type_in, out_addr=None, zmq_type_out=None, in_bind=True, out_bind=True, subscribe=None): LOG.info(_(""Registering reactor"")) if zmq_type_in not in (zmq.PULL, zmq.SUB): raise RPCException(""Bad input socktype"") # Items push in. inq = ZmqSocket(in_addr, zmq_type_in, bind=in_bind, subscribe=subscribe) self.proxies[inq] = proxy self.sockets.append(inq) LOG.info(_(""In reactor registered"")) if not out_addr: return if zmq_type_out not in (zmq.PUSH, zmq.PUB): raise RPCException(""Bad output socktype"") # Items push out. outq = ZmqSocket(out_addr, zmq_type_out, bind=out_bind) self.mapping[inq] = outq self.mapping[outq] = inq self.sockets.append(outq) LOG.info(_(""Out reactor registered"")) def consume_in_thread(self): def _consume(sock): LOG.info(_(""Consuming socket"")) while True: self.consume(sock) for k in self.proxies.keys(): self.threads.append( self.pool.spawn(_consume, k) ) def wait(self): for t in self.threads: t.wait() def close(self): for s in self.sockets: s.close() for t in self.threads: t.kill() class ZmqProxy(ZmqBaseReactor): """""" A consumer class implementing a topic-based proxy, forwarding to IPC sockets. """""" def __init__(self, conf): super(ZmqProxy, self).__init__(conf) pathsep = set((os.path.sep or '', os.path.altsep or '', '/', '\\')) self.badchars = re.compile(r'[%s]' % re.escape(''.join(pathsep))) self.topic_proxy = {} def consume(self, sock): ipc_dir = CONF.rpc_zmq_ipc_dir # TODO(ewindisch): use zero-copy (i.e. references, not copying) data = sock.recv() topic = data[1] LOG.debug(_(""CONSUMER GOT %s""), ' '.join(map(pformat, data))) if topic.startswith('fanout~'): sock_type = zmq.PUB topic = topic.split('.', 1)[0] elif topic.startswith('zmq_replies'): sock_type = zmq.PUB else: sock_type = zmq.PUSH if topic not in self.topic_proxy: def publisher(waiter): LOG.info(_(""Creating proxy for topic: %s""), topic) try: # The topic is received over the network, # don't trust this input. if self.badchars.search(topic) is not None: emsg = _(""Topic contained dangerous characters."") LOG.warn(emsg) raise RPCException(emsg) out_sock = ZmqSocket(""ipc://%s/zmq_topic_%s"" % (ipc_dir, topic), sock_type, bind=True) except RPCException: waiter.send_exception(*sys.exc_info()) return self.topic_proxy[topic] = eventlet.queue.LightQueue( CONF.rpc_zmq_topic_backlog) self.sockets.append(out_sock) # It takes some time for a pub socket to open, # before we can have any faith in doing a send() to it. if sock_type == zmq.PUB: eventlet.sleep(.5) waiter.send(True) while(True): data = self.topic_proxy[topic].get() out_sock.send(data) LOG.debug(_(""ROUTER RELAY-OUT SUCCEEDED %(data)s"") % {'data': data}) wait_sock_creation = eventlet.event.Event() eventlet.spawn(publisher, wait_sock_creation) try: wait_sock_creation.wait() except RPCException: LOG.error(_(""Topic socket file creation failed."")) return try: self.topic_proxy[topic].put_nowait(data) LOG.debug(_(""ROUTER RELAY-OUT QUEUED %(data)s"") % {'data': data}) except eventlet.queue.Full: LOG.error(_(""Local per-topic backlog buffer full for topic "" ""%(topic)s. Dropping message."") % {'topic': topic}) def consume_in_thread(self): """"""Runs the ZmqProxy service"""""" ipc_dir = CONF.rpc_zmq_ipc_dir consume_in = ""tcp://%s:%s"" % \ (CONF.rpc_zmq_bind_address, CONF.rpc_zmq_port) consumption_proxy = InternalContext(None) if not os.path.isdir(ipc_dir): try: utils.execute('mkdir', '-p', ipc_dir, run_as_root=True) utils.execute('chown', ""%s:%s"" % (os.getuid(), os.getgid()), ipc_dir, run_as_root=True) utils.execute('chmod', '750', ipc_dir, run_as_root=True) except utils.ProcessExecutionError: with excutils.save_and_reraise_exception(): LOG.error(_(""Could not create IPC directory %s"") % (ipc_dir, )) try: self.register(consumption_proxy, consume_in, zmq.PULL, out_bind=True) except zmq.ZMQError: with excutils.save_and_reraise_exception(): LOG.error(_(""Could not create ZeroMQ receiver daemon. "" ""Socket may already be in use."")) super(ZmqProxy, self).consume_in_thread() def unflatten_envelope(packenv): """"""Unflattens the RPC envelope. Takes a list and returns a dictionary. i.e. [1,2,3,4] => {1: 2, 3: 4} """""" i = iter(packenv) h = {} try: while True: k = i.next() h[k] = i.next() except StopIteration: return h class ZmqReactor(ZmqBaseReactor): """""" A consumer class implementing a consumer for messages. Can also be used as a 1:1 proxy """""" def __init__(self, conf): super(ZmqReactor, self).__init__(conf) def consume(self, sock): # TODO(ewindisch): use zero-copy (i.e. references, not copying) data = sock.recv() LOG.debug(_(""CONSUMER RECEIVED DATA: %s""), data) if sock in self.mapping: LOG.debug(_(""ROUTER RELAY-OUT %(data)s"") % { 'data': data}) self.mapping[sock].send(data) return proxy = self.proxies[sock] if data[2] == 'cast': # Legacy protocol packenv = data[3] ctx, msg = _deserialize(packenv) request = rpc_common.deserialize_msg(msg) ctx = RpcContext.unmarshal(ctx) elif data[2] == 'impl_zmq_v2': packenv = data[4:] msg = unflatten_envelope(packenv) request = rpc_common.deserialize_msg(msg) # Unmarshal only after verifying the message. ctx = RpcContext.unmarshal(data[3]) else: LOG.error(_(""ZMQ Envelope version unsupported or unknown."")) return self.pool.spawn_n(self.process, proxy, ctx, request) class Connection(rpc_common.Connection): """"""Manages connections and threads."""""" def __init__(self, conf): self.topics = [] self.reactor = ZmqReactor(conf) def create_consumer(self, topic, proxy, fanout=False): # Register with matchmaker. _get_matchmaker().register(topic, CONF.rpc_zmq_host) # Subscription scenarios if fanout: sock_type = zmq.SUB subscribe = ('', fanout)[type(fanout) == str] topic = 'fanout~' + topic.split('.', 1)[0] else: sock_type = zmq.PULL subscribe = None topic = '.'.join((topic.split('.', 1)[0], CONF.rpc_zmq_host)) if topic in self.topics: LOG.info(_(""Skipping topic registration. Already registered."")) return # Receive messages from (local) proxy inaddr = ""ipc://%s/zmq_topic_%s"" % \ (CONF.rpc_zmq_ipc_dir, topic) LOG.debug(_(""Consumer is a zmq.%s""), ['PULL', 'SUB'][sock_type == zmq.SUB]) self.reactor.register(proxy, inaddr, sock_type, subscribe=subscribe, in_bind=False) self.topics.append(topic) def close(self): _get_matchmaker().stop_heartbeat() for topic in self.topics: _get_matchmaker().unregister(topic, CONF.rpc_zmq_host) self.reactor.close() self.topics = [] def wait(self): self.reactor.wait() def consume_in_thread(self): _get_matchmaker().start_heartbeat() self.reactor.consume_in_thread() def _cast(addr, context, topic, msg, timeout=None, envelope=False, _msg_id=None): timeout_cast = timeout or CONF.rpc_cast_timeout payload = [RpcContext.marshal(context), msg] with Timeout(timeout_cast, exception=rpc_common.Timeout): try: conn = ZmqClient(addr) # assumes cast can't return an exception conn.cast(_msg_id, topic, payload, envelope) except zmq.ZMQError: raise RPCException(""Cast failed. ZMQ Socket Exception"") finally: if 'conn' in vars(): conn.close() def _call(addr, context, topic, msg, timeout=None, envelope=False): # timeout_response is how long we wait for a response timeout = timeout or CONF.rpc_response_timeout # The msg_id is used to track replies. msg_id = uuid.uuid4().hex # Replies always come into the reply service. reply_topic = ""zmq_replies.%s"" % CONF.rpc_zmq_host LOG.debug(_(""Creating payload"")) # Curry the original request into a reply method. mcontext = RpcContext.marshal(context) payload = { 'method': '-reply', 'args': { 'msg_id': msg_id, 'context': mcontext, 'topic': reply_topic, 'msg': [mcontext, msg] } } LOG.debug(_(""Creating queue socket for reply waiter"")) # Messages arriving async. # TODO(ewindisch): have reply consumer with dynamic subscription mgmt with Timeout(timeout, exception=rpc_common.Timeout): try: msg_waiter = ZmqSocket( ""ipc://%s/zmq_topic_zmq_replies.%s"" % (CONF.rpc_zmq_ipc_dir, CONF.rpc_zmq_host), zmq.SUB, subscribe=msg_id, bind=False ) LOG.debug(_(""Sending cast"")) _cast(addr, context, topic, payload, envelope) LOG.debug(_(""Cast sent; Waiting reply"")) # Blocks until receives reply msg = msg_waiter.recv() LOG.debug(_(""Received message: %s""), msg) LOG.debug(_(""Unpacking response"")) if msg[2] == 'cast': # Legacy version raw_msg = _deserialize(msg[-1])[-1] elif msg[2] == 'impl_zmq_v2': rpc_envelope = unflatten_envelope(msg[4:]) raw_msg = rpc_common.deserialize_msg(rpc_envelope) else: raise rpc_common.UnsupportedRpcEnvelopeVersion( _(""Unsupported or unknown ZMQ envelope returned."")) responses = raw_msg['args']['response'] # ZMQError trumps the Timeout error. except zmq.ZMQError: raise RPCException(""ZMQ Socket Error"") except (IndexError, KeyError): raise RPCException(_(""RPC Message Invalid."")) finally: if 'msg_waiter' in vars(): msg_waiter.close() # It seems we don't need to do all of the following, # but perhaps it would be useful for multicall? # One effect of this is that we're checking all # responses for Exceptions. for resp in responses: if isinstance(resp, types.DictType) and 'exc' in resp: raise rpc_common.deserialize_remote_exception(CONF, resp['exc']) return responses[-1] def _multi_send(method, context, topic, msg, timeout=None, envelope=False, _msg_id=None): """""" Wraps the sending of messages, dispatches to the matchmaker and sends message to all relevant hosts. """""" conf = CONF LOG.debug(_(""%(msg)s"") % {'msg': ' '.join(map(pformat, (topic, msg)))}) queues = _get_matchmaker().queues(topic) LOG.debug(_(""Sending message(s) to: %s""), queues) # Don't stack if we have no matchmaker results if len(queues) == 0: LOG.warn(_(""No matchmaker results. Not casting."")) # While not strictly a timeout, callers know how to handle # this exception and a timeout isn't too big a lie. raise rpc_common.Timeout(_(""No match from matchmaker."")) # This supports brokerless fanout (addresses > 1) for queue in queues: (_topic, ip_addr) = queue _addr = ""tcp://%s:%s"" % (ip_addr, conf.rpc_zmq_port) if method.__name__ == '_cast': eventlet.spawn_n(method, _addr, context, _topic, msg, timeout, envelope, _msg_id) return return method(_addr, context, _topic, msg, timeout, envelope) def create_connection(conf, new=True): return Connection(conf) def multicall(conf, *args, **kwargs): """"""Multiple calls."""""" return _multi_send(_call, *args, **kwargs) def call(conf, *args, **kwargs): """"""Send a message, expect a response."""""" data = _multi_send(_call, *args, **kwargs) return data[-1] def cast(conf, *args, **kwargs): """"""Send a message expecting no reply."""""" _multi_send(_cast, *args, **kwargs) def fanout_cast(conf, context, topic, msg, **kwargs): """"""Send a message to all listening and expect no reply."""""" # NOTE(ewindisch): fanout~ is used because it avoid splitting on . # and acts as a non-subtle hint to the matchmaker and ZmqProxy. _multi_send(_cast, context, 'fanout~' + str(topic), msg, **kwargs) def notify(conf, context, topic, msg, envelope): """""" Send notification event. Notifications are sent to topic-priority. This differs from the AMQP drivers which send to topic.priority. """""" # NOTE(ewindisch): dot-priority in rpc notifier does not # work with our assumptions. topic = topic.replace('.', '-') cast(conf, context, topic, msg, envelope=envelope) def cleanup(): """"""Clean up resources in use by implementation."""""" global ZMQ_CTX if ZMQ_CTX: ZMQ_CTX.term() ZMQ_CTX = None global matchmaker matchmaker = None def _get_ctxt(): if not zmq: raise ImportError(""Failed to import eventlet.green.zmq"") global ZMQ_CTX if not ZMQ_CTX: ZMQ_CTX = zmq.Context(CONF.rpc_zmq_contexts) return ZMQ_CTX def _get_matchmaker(*args, **kwargs): global matchmaker if not matchmaker: matchmaker = importutils.import_object( CONF.rpc_zmq_matchmaker, *args, **kwargs) return matchmaker ",69,5584
openstack%2Fshade~master~Id6be1182a2226e3e53a10f6e29f674d777eae6c5,openstack/shade,master,Id6be1182a2226e3e53a10f6e29f674d777eae6c5,Fix AttributeError in keystone functional tests,MERGED,2015-06-25 08:43:48.000000000,2015-06-25 17:04:49.000000000,2015-06-25 17:04:48.000000000,"[{'_account_id': 2}, {'_account_id': 3}, {'_account_id': 3099}, {'_account_id': 6133}, {'_account_id': 6550}]","[{'number': 1, 'created': '2015-06-25 08:43:48.000000000', 'files': ['shade/tests/functional/test_endpoints.py', 'shade/tests/functional/test_services.py'], 'web_link': 'https://opendev.org/openstack/shade/commit/2b64bbc7d6e8e36c10ca86ae7cf7aed78c55c9d5', 'message': 'Fix AttributeError in keystone functional tests\n\nOpenStack allows omitting names for services. This patch adds a check\nto ensure we do not call startswith on None values.\n\nChange-Id: Id6be1182a2226e3e53a10f6e29f674d777eae6c5\n'}]",0,195451,2b64bbc7d6e8e36c10ca86ae7cf7aed78c55c9d5,9,5,1,6550,,,0,"Fix AttributeError in keystone functional tests

OpenStack allows omitting names for services. This patch adds a check
to ensure we do not call startswith on None values.

Change-Id: Id6be1182a2226e3e53a10f6e29f674d777eae6c5
",git fetch https://review.opendev.org/openstack/shade refs/changes/51/195451/1 && git format-patch -1 --stdout FETCH_HEAD,"['shade/tests/functional/test_endpoints.py', 'shade/tests/functional/test_services.py']",2,2b64bbc7d6e8e36c10ca86ae7cf7aed78c55c9d5,functional-tests, if s['name'] is not None and \ s['name'].startswith(self.new_service_name):, if s['name'].startswith(self.new_service_name):,4,2
openstack%2Fshade~master~I1d762898fc03765fc028943c2f792605b1ebcd1c,openstack/shade,master,I1d762898fc03765fc028943c2f792605b1ebcd1c,Update keypair APIs to latest standards,MERGED,2015-06-24 21:09:38.000000000,2015-06-25 17:04:14.000000000,2015-06-25 17:04:09.000000000,"[{'_account_id': 2}, {'_account_id': 3}, {'_account_id': 3099}, {'_account_id': 6133}, {'_account_id': 6488}, {'_account_id': 6550}]","[{'number': 1, 'created': '2015-06-24 21:09:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/shade/commit/b8840d1fb32deaac05b4c62214b43fc12a437153', 'message': 'Fix up keypair APIs\n\nThis brings the keypair API interface up to our current standards:\n\n   - Adheres to the new get/list/search interface.\n   - Catches client exceptions and rethrows as OpenStackCloudException\n   - Returns True/False in the delete API\n\nChange-Id: I1d762898fc03765fc028943c2f792605b1ebcd1c\n'}, {'number': 2, 'created': '2015-06-24 21:11:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/shade/commit/0c367d64b31771d069a66508a05ce6aacfb9c23b', 'message': 'Fix up keypair APIs\n\nThis brings the keypair API interface up to our current standards:\n\n   - Stop leaking keypair objects.\n   - Adheres to the new get/list/search interface.\n   - Catches client exceptions and rethrows as OpenStackCloudException\n   - Returns True/False in the delete API\n\nChange-Id: I1d762898fc03765fc028943c2f792605b1ebcd1c\n'}, {'number': 3, 'created': '2015-06-25 05:18:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/shade/commit/0d8f83be787e1f3f792d35a3d7d0078b574b7a36', 'message': 'Update keypair APIs to latest standards\n\nThis brings the keypair API interface up to our current standards:\n\n   - Stop leaking keypair objects.\n   - Adheres to the new get/list/search interface.\n   - Catches client exceptions and rethrows as OpenStackCloudException.\n   - Returns True/False in the delete API method.\n\nChange-Id: I1d762898fc03765fc028943c2f792605b1ebcd1c\n'}, {'number': 4, 'created': '2015-06-25 05:20:30.000000000', 'files': ['shade/tests/fakes.py', 'shade/__init__.py', 'shade/tests/unit/test_keypair.py'], 'web_link': 'https://opendev.org/openstack/shade/commit/6f93b3a253128191f35064f3d5e2a9d10086a99c', 'message': 'Update keypair APIs to latest standards\n\nThis brings the keypair API interface up to our current standards:\n\n   - Stop leaking keypair objects.\n   - Adheres to the new get/list/search interface.\n   - Catches client exceptions and rethrows as OpenStackCloudException.\n   - Returns True/False in the delete API method.\n\nChange-Id: I1d762898fc03765fc028943c2f792605b1ebcd1c\n'}]",0,195318,6f93b3a253128191f35064f3d5e2a9d10086a99c,14,6,4,3099,,,0,"Update keypair APIs to latest standards

This brings the keypair API interface up to our current standards:

   - Stop leaking keypair objects.
   - Adheres to the new get/list/search interface.
   - Catches client exceptions and rethrows as OpenStackCloudException.
   - Returns True/False in the delete API method.

Change-Id: I1d762898fc03765fc028943c2f792605b1ebcd1c
",git fetch https://review.opendev.org/openstack/shade refs/changes/18/195318/4 && git format-patch -1 --stdout FETCH_HEAD,['shade/__init__.py'],1,b8840d1fb32deaac05b4c62214b43fc12a437153,keypair_fix," def search_keypairs(self, name_or_id=None, filters=None): keypairs = self.list_keypairs() return _utils._filter_list(keypairs, name_or_id, filters) def list_keypairs(self): return meta.obj_list_to_dict( self.manager.submitTask(_tasks.KeypairList()) ) def get_keypair(self, name_or_id, filters=None): return _utils._get_entity(self.search_keypairs, name_or_id, filters) def create_keypair(self, name, public_key): """"""Create a new keypair. :param name: Name of the keypair being created. :param public_key: Public key for the new keypair. :raises: OpenStackCloudException on operation error. """""" try: return self.manager.submitTask(_tasks.KeypairCreate( name=name, public_key=public_key)) except Exception as e: self.log.debug(""Error creating keypair %s"" % name, exc_info=True) raise OpenStackCloudException( ""Unable to create keypair %s: %s"" % (name, e) ) def delete_keypair(self, name): """"""Delete a keypair :param name: Name of the keypair to delete. :returns: True if delete succeeded, False otherwise. :raises: OpenStackCloudException on operation error. """""" try: self.manager.submitTask(_tasks.KeypairDelete(key=name)) except nova_exceptions.NotFound: self.log.debug(""Keypair %s not found for deleting"" % name) return False except Exception as e: self.log.debug(""Error deleting keypair %s"" % name, exc_info=True) raise OpenStackCloudException( ""Unable to delete keypair %s: %s"" % (name, e) ) return True "," def list_keypairs(self): return self.manager.submitTask(_tasks.KeypairList()) def create_keypair(self, name, public_key): return self.manager.submitTask(_tasks.KeypairCreate( name=name, public_key=public_key)) def delete_keypair(self, name): return self.manager.submitTask(_tasks.KeypairDelete(key=name)) ",50,10
openstack%2Fbifrost~master~I6d7b71ed935c570ae9fe6ac57353260ee39539ed,openstack/bifrost,master,I6d7b71ed935c570ae9fe6ac57353260ee39539ed,Follow-up fix for H306 in bifrost_inventory.py,MERGED,2015-06-24 21:26:58.000000000,2015-06-25 16:53:16.000000000,2015-06-25 16:53:11.000000000,"[{'_account_id': 3}, {'_account_id': 5805}, {'_account_id': 11555}, {'_account_id': 12459}]","[{'number': 1, 'created': '2015-06-24 21:26:58.000000000', 'files': ['playbooks/inventory/bifrost_inventory.py'], 'web_link': 'https://opendev.org/openstack/bifrost/commit/67b867a42e02d3f1cae2efc3a290b9b08a15eb0e', 'message': 'Follow-up fix for H306 in bifrost_inventory.py\n\nChange-Id: I6d7b71ed935c570ae9fe6ac57353260ee39539ed\n'}]",0,195324,67b867a42e02d3f1cae2efc3a290b9b08a15eb0e,9,4,1,11655,,,0,"Follow-up fix for H306 in bifrost_inventory.py

Change-Id: I6d7b71ed935c570ae9fe6ac57353260ee39539ed
",git fetch https://review.opendev.org/openstack/bifrost refs/changes/24/195324/1 && git format-patch -1 --stdout FETCH_HEAD,['playbooks/inventory/bifrost_inventory.py'],1,67b867a42e02d3f1cae2efc3a290b9b08a15eb0e,194684,import yaml,import yaml,1,1
openstack%2Fbifrost~master~I6978ae4565890b5a9a8d75f064cfcc147e067843,openstack/bifrost,master,I6978ae4565890b5a9a8d75f064cfcc147e067843,Add example deploy all available playbook,MERGED,2015-06-24 14:21:40.000000000,2015-06-25 16:53:05.000000000,2015-06-25 16:53:05.000000000,"[{'_account_id': 3}, {'_account_id': 5805}]","[{'number': 1, 'created': '2015-06-24 14:21:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/bifrost/commit/7255d417df174ff1334b279413b6993638d0c5f1', 'message': 'Add example deploy all available playbook\n\nAdding an example playbook that utilizes the dynamic inventory\nto permit a user to deploy all available nodes in the inventory.\n\nChange-Id: I6978ae4565890b5a9a8d75f064cfcc147e067843\nDepends-On: I7155de8ec9a4123e16a9f9925a66ee12adfc9c28\n'}, {'number': 2, 'created': '2015-06-24 16:59:50.000000000', 'files': ['playbooks/example-deploy-all-available-nodes.yaml'], 'web_link': 'https://opendev.org/openstack/bifrost/commit/132657c5c0283f1c6914fbefce3b5bd1febd96e4', 'message': 'Add example deploy all available playbook\n\nAdding an example playbook that utilizes the dynamic inventory\nto permit a user to deploy all available nodes in the inventory.\n\nChange-Id: I6978ae4565890b5a9a8d75f064cfcc147e067843\nDepends-On: I7155de8ec9a4123e16a9f9925a66ee12adfc9c28\n'}]",0,195100,132657c5c0283f1c6914fbefce3b5bd1febd96e4,10,2,2,11655,,,0,"Add example deploy all available playbook

Adding an example playbook that utilizes the dynamic inventory
to permit a user to deploy all available nodes in the inventory.

Change-Id: I6978ae4565890b5a9a8d75f064cfcc147e067843
Depends-On: I7155de8ec9a4123e16a9f9925a66ee12adfc9c28
",git fetch https://review.opendev.org/openstack/bifrost refs/changes/00/195100/2 && git format-patch -1 --stdout FETCH_HEAD,['playbooks/example-deploy-all-available-nodes.yaml'],1,7255d417df174ff1334b279413b6993638d0c5f1,examples,"# This is an example playbook utilizing role conditionals to permit # deployment on available nodes. # # To utilize: # export BIFROST_INVENTORY_SOURCE=ironic # ansible-playbook -vvvv -i inventory/bifrost_inventory.py example-deploy-all-available-nodes.yaml # # NOTE(TheJulia): The format of this example will cause hosts to be deployed # utilizing DHCP on eth0 of Ubuntu/Debian hosts. It is advisable you build # your deployment image with the dhcp-all-interfaces element when deploying # other operating systems or if your target node has multiple ethernet # interfaces. --- - hosts: localhost connection: local name: ""Collect facts"" sudo: no gather_facts: yes - hosts: baremetal name: ""Create configuration drive files and deploy machines from inventory"" sudo: no connection: local roles: - { role: bifrost-configdrives-dynamic, when: provision_state == ""available"" and maintenance | bool != true } - { role: bifrost-deploy-nodes-dynamic, when: provision_state == ""available"" and maintenance | bool != true } ",,25,0
openstack%2Fbifrost~master~I7155de8ec9a4123e16a9f9925a66ee12adfc9c28,openstack/bifrost,master,I7155de8ec9a4123e16a9f9925a66ee12adfc9c28,Correct ipv4 networking config issue in dynamic path,MERGED,2015-06-19 19:14:15.000000000,2015-06-25 16:52:59.000000000,2015-06-25 16:52:59.000000000,"[{'_account_id': 3}, {'_account_id': 5805}, {'_account_id': 12459}]","[{'number': 1, 'created': '2015-06-19 19:14:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/bifrost/commit/473582da1c4af042c43b429c42ce40270873b9b7', 'message': 'Correct ipv4 networking config issue in dynamic path\n\nA syntax error in a template file coupled with the incorect\nipv4_gateway being set when testing resulted in Cirros being\nunable to get a working network interface online.\n\nThis corrects the template and addresses the ipv4_gateway default\nwhen using the test playbook.\n\nChange-Id: I7155de8ec9a4123e16a9f9925a66ee12adfc9c28\n'}, {'number': 2, 'created': '2015-06-22 11:15:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/bifrost/commit/acdf67949187b18a5629b814e2b8890ebc6ccc99', 'message': 'Correct ipv4 networking config issue in dynamic path\n\nA syntax error in a template file coupled with the incorect\nipv4_gateway being set when testing resulted in Cirros being\nunable to get a working network interface online.\n\nThis corrects the template and addresses the ipv4_gateway default\nwhen using the test playbook.\n\nChange-Id: I7155de8ec9a4123e16a9f9925a66ee12adfc9c28\n'}, {'number': 3, 'created': '2015-06-24 19:47:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/bifrost/commit/c02bd0a98cb2efd4ea5f1fc99b1ca256a331c32f', 'message': 'Correct ipv4 networking config issue in dynamic path\n\nA syntax error in a template file coupled with the incorect\nipv4_gateway being set when testing resulted in Cirros being\nunable to get a working network interface online.\n\nThis corrects the template and addresses the ipv4_gateway default\nwhen using the test playbook.\n\nChange-Id: I7155de8ec9a4123e16a9f9925a66ee12adfc9c28\n'}, {'number': 4, 'created': '2015-06-24 20:12:43.000000000', 'files': ['playbooks/test-bifrost-dynamic.yaml', 'playbooks/roles/bifrost-configdrives-dynamic/templates/interfaces.j2'], 'web_link': 'https://opendev.org/openstack/bifrost/commit/5bd90bab015df29d0cbda07f12ad77f1b06c44ef', 'message': 'Correct ipv4 networking config issue in dynamic path\n\nA syntax error in a template file coupled with the incorect\nipv4_gateway being set when testing resulted in Cirros being\nunable to get a working network interface online.\n\nThis corrects the template and addresses the ipv4_gateway default\nwhen using the test playbook.\n\nChange-Id: I7155de8ec9a4123e16a9f9925a66ee12adfc9c28\n'}]",1,193689,5bd90bab015df29d0cbda07f12ad77f1b06c44ef,14,3,4,11655,,,0,"Correct ipv4 networking config issue in dynamic path

A syntax error in a template file coupled with the incorect
ipv4_gateway being set when testing resulted in Cirros being
unable to get a working network interface online.

This corrects the template and addresses the ipv4_gateway default
when using the test playbook.

Change-Id: I7155de8ec9a4123e16a9f9925a66ee12adfc9c28
",git fetch https://review.opendev.org/openstack/bifrost refs/changes/89/193689/4 && git format-patch -1 --stdout FETCH_HEAD,"['playbooks/roles/bifrost-configdrives-dynamic/templates/interfaces.j2', 'playbooks/test-bifrost-dynamic.yaml']",2,473582da1c4af042c43b429c42ce40270873b9b7,feature/dynamic-inventory," - name: ""Override the ipv4_gateway setting"" set_fact: ipv4_gateway: ""192.168.122.1""",,3,2
openstack%2Fbifrost~master~Iec5b8e14af6e3f1ab3f48e40129d6f021b5e3338,openstack/bifrost,master,Iec5b8e14af6e3f1ab3f48e40129d6f021b5e3338,Add dynamic node unprovision role,MERGED,2015-06-19 19:14:15.000000000,2015-06-25 16:52:57.000000000,2015-06-25 16:52:55.000000000,"[{'_account_id': 3}, {'_account_id': 5805}, {'_account_id': 11655}, {'_account_id': 12459}]","[{'number': 1, 'created': '2015-06-19 19:14:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/bifrost/commit/7d3d86cb1c3f55725e729d98497e80fe708dcbf2', 'message': 'Add dynamic node unprovision role\n\nAddition of an node-unprovision role that leverages\ndynamic inventory style path.\n\nChange-Id: Iec5b8e14af6e3f1ab3f48e40129d6f021b5e3338\n'}, {'number': 2, 'created': '2015-06-22 11:14:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/bifrost/commit/e8f2b773afdb287658dc9b6da6b6651b339fab96', 'message': 'Add dynamic node unprovision role\n\nAddition of an node-unprovision role that leverages\ndynamic inventory style path.\n\nChange-Id: Iec5b8e14af6e3f1ab3f48e40129d6f021b5e3338\n'}, {'number': 3, 'created': '2015-06-24 19:47:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/bifrost/commit/9b72ddae0739a4b97e49b6f317b4cb3b6f0113af', 'message': 'Add dynamic node unprovision role\n\nAddition of an node-unprovision role that leverages\ndynamic inventory style path.\n\nChange-Id: Iec5b8e14af6e3f1ab3f48e40129d6f021b5e3338\n'}, {'number': 4, 'created': '2015-06-24 19:55:15.000000000', 'files': ['playbooks/roles/bifrost-unprovision-node-dynamic/vars/main.yml', 'playbooks/roles/bifrost-unprovision-node-dynamic/tasks/main.yml', 'playbooks/roles/bifrost-unprovision-node-dynamic/handlers/main.yml', 'playbooks/roles/bifrost-unprovision-node-dynamic/README.md', 'playbooks/roles/bifrost-unprovision-node-dynamic/defaults/main.yml', 'playbooks/test-bifrost-dynamic.yaml', 'playbooks/roles/bifrost-unprovision-node-dynamic/meta/main.yml'], 'web_link': 'https://opendev.org/openstack/bifrost/commit/7d6ba6a295c44d85b2ebf13ae7cab8fa85b38cd1', 'message': 'Add dynamic node unprovision role\n\nAddition of an node-unprovision role that leverages\ndynamic inventory style path.\n\nChange-Id: Iec5b8e14af6e3f1ab3f48e40129d6f021b5e3338\n'}]",5,193688,7d6ba6a295c44d85b2ebf13ae7cab8fa85b38cd1,16,4,4,11655,,,0,"Add dynamic node unprovision role

Addition of an node-unprovision role that leverages
dynamic inventory style path.

Change-Id: Iec5b8e14af6e3f1ab3f48e40129d6f021b5e3338
",git fetch https://review.opendev.org/openstack/bifrost refs/changes/88/193688/4 && git format-patch -1 --stdout FETCH_HEAD,"['playbooks/roles/bifrost-unprovision-node-dynamic/vars/main.yml', 'playbooks/roles/bifrost-unprovision-node-dynamic/tasks/main.yml', 'playbooks/roles/bifrost-unprovision-node-dynamic/handlers/main.yml', 'playbooks/roles/bifrost-unprovision-node-dynamic/README.md', 'playbooks/roles/bifrost-unprovision-node-dynamic/defaults/main.yml', 'playbooks/test-bifrost-dynamic.yaml', 'playbooks/roles/bifrost-unprovision-node-dynamic/meta/main.yml']",7,7d3d86cb1c3f55725e729d98497e80fe708dcbf2,feature/dynamic-inventory,"--- galaxy_info: author: Ironic Developers description: Unprovisions nodes in Ironic company: OpenStack license: Apache min_ansible_version: 2.0 # # Below are all platforms currently available. Just uncomment # the ones that apply to your role. If you don't see your # platform on this list, let us know and we'll get it added! # platforms: #- name: EL # versions: # - all # - 5 # - 6 # - 7 #- name: GenericUNIX # versions: # - all # - any #- name: Fedora # versions: # - all # - 16 # - 17 # - 18 # - 19 # - 20 #- name: SmartOS # versions: # - all # - any #- name: opensuse # versions: # - all # - 12.1 # - 12.2 # - 12.3 # - 13.1 # - 13.2 #- name: Amazon # versions: # - all # - 2013.03 # - 2013.09 #- name: GenericBSD # versions: # - all # - any #- name: FreeBSD # versions: # - all # - 8.0 # - 8.1 # - 8.2 # - 8.3 # - 8.4 # - 9.0 # - 9.1 # - 9.1 # - 9.2 #- name: Ubuntu # versions: # - all # - lucid # - maverick # - natty # - oneiric # - precise # - quantal # - raring # - saucy - trusty #- name: SLES # versions: # - all # - 10SP3 # - 10SP4 # - 11 # - 11SP1 # - 11SP2 # - 11SP3 #- name: GenericLinux # versions: # - all # - any #- name: Debian # versions: # - all # - etch # - lenny # - squeeze # - wheezy # # Below are all categories currently available. Just as with # the platforms above, uncomment those that apply to your role. # categories: - cloud - cloud:openstack #- cloud:gce #- cloud:rax #- clustering #- database #- database:nosql #- database:sql #- development #- monitoring #- networking #- packaging #- system #- web dependencies: [] ",,203,2
openstack%2Fbifrost~master~Id2bb814809e5f6c632c085a5eb75107a7ea126bb,openstack/bifrost,master,Id2bb814809e5f6c632c085a5eb75107a7ea126bb,Remove un-necessary checks from the dynamic test,MERGED,2015-06-19 19:14:15.000000000,2015-06-25 16:52:49.000000000,2015-06-25 16:52:49.000000000,"[{'_account_id': 3}, {'_account_id': 5805}, {'_account_id': 12459}]","[{'number': 1, 'created': '2015-06-19 19:14:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/bifrost/commit/fe73dfb8e5ecdd0029b0e5099ed25e0148890ea3', 'message': ""Remove un-necessary checks from the dynamic test\n\nThe direction bifrost roles are heading in may not make sense\nto have secondary validation steps outside of the initial steps.\n\ni.e. We should be attempting to validate we've completed x action\nbefore leaving x action's steps.  Separating them makes no sense.\n\nAs such, we're removing the un-necessary test step from the dynamic\ntest.  Additionally noted the un-necessary nature and possibilites\nin the node deployment given we can support users passing in their\nown pre-formatted instance_info.\n\nChange-Id: Id2bb814809e5f6c632c085a5eb75107a7ea126bb\n""}, {'number': 2, 'created': '2015-06-22 11:14:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/bifrost/commit/54b2b3e0885a2a2c016c01179d80ca61c0e6195f', 'message': ""Remove un-necessary checks from the dynamic test\n\nThe direction bifrost roles are heading in may not make sense\nto have secondary validation steps outside of the initial steps.\n\ni.e. We should be attempting to validate we've completed x action\nbefore leaving x action's steps.  Separating them makes no sense.\n\nAs such, we're removing the un-necessary test step from the dynamic\ntest.  Additionally noted the un-necessary nature and possibilites\nin the node deployment given we can support users passing in their\nown pre-formatted instance_info.\n\nChange-Id: Id2bb814809e5f6c632c085a5eb75107a7ea126bb\n""}, {'number': 3, 'created': '2015-06-24 17:12:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/bifrost/commit/e105249e1063f202d37531214672625685f552a8', 'message': ""Remove un-necessary checks from the dynamic test\n\nThe direction bifrost roles are heading it may not make sense\nto have secondary validation steps outside of the initial steps.\n\ni.e. We should be attempting to validate we've completed x action\nbefore leaving x action's steps.  Separating them makes no sense.\n\nAs such, we're removing the un-necessary test step from the dynamic\ntest.  Additionally noted the un-necessary nature and possibilites\nin the node deployment given we can support users passing in their\nown pre-formatted instance_info.\n\nChange-Id: Id2bb814809e5f6c632c085a5eb75107a7ea126bb\n""}, {'number': 4, 'created': '2015-06-24 19:47:18.000000000', 'files': ['playbooks/roles/bifrost-deploy-nodes-dynamic/tasks/main.yml', 'playbooks/test-bifrost-dynamic.yaml'], 'web_link': 'https://opendev.org/openstack/bifrost/commit/5cf7a66de7c26a2e350304ec00fcbd85d2ff0717', 'message': ""Remove un-necessary checks from the dynamic test\n\nThe direction bifrost roles are heading it may not make sense\nto have secondary validation steps outside of the initial steps.\n\ni.e. We should be attempting to validate we've completed x action\nbefore leaving x action's steps.  Separating them makes no sense.\n\nAs such, we're removing the un-necessary test step from the dynamic\ntest.  Additionally noted the un-necessary nature and possibilites\nin the node deployment given we can support users passing in their\nown pre-formatted instance_info.\n\nChange-Id: Id2bb814809e5f6c632c085a5eb75107a7ea126bb\n""}]",2,193687,5cf7a66de7c26a2e350304ec00fcbd85d2ff0717,16,3,4,11655,,,0,"Remove un-necessary checks from the dynamic test

The direction bifrost roles are heading it may not make sense
to have secondary validation steps outside of the initial steps.

i.e. We should be attempting to validate we've completed x action
before leaving x action's steps.  Separating them makes no sense.

As such, we're removing the un-necessary test step from the dynamic
test.  Additionally noted the un-necessary nature and possibilites
in the node deployment given we can support users passing in their
own pre-formatted instance_info.

Change-Id: Id2bb814809e5f6c632c085a5eb75107a7ea126bb
",git fetch https://review.opendev.org/openstack/bifrost refs/changes/87/193687/1 && git format-patch -1 --stdout FETCH_HEAD,"['playbooks/roles/bifrost-deploy-nodes-dynamic/tasks/main.yml', 'playbooks/test-bifrost-dynamic.yaml']",2,fe73dfb8e5ecdd0029b0e5099ed25e0148890ea3,feature/dynamic-inventory,,"- hosts: localhost connection: local name: ""Validates prior to deployment"" sudo: yes roles: - role: bifrost-validate-host-for-deploy",5,6
openstack%2Fironic~master~If8a4e9fda5e20bb2a49dc45bc3050eb63503d6de,openstack/ironic,master,If8a4e9fda5e20bb2a49dc45bc3050eb63503d6de,Refactor method to add or update capability string,MERGED,2015-03-08 07:41:02.000000000,2015-06-25 16:50:29.000000000,2015-06-24 10:25:32.000000000,"[{'_account_id': 3}, {'_account_id': 2889}, {'_account_id': 6618}, {'_account_id': 6773}, {'_account_id': 7711}, {'_account_id': 9315}, {'_account_id': 10239}, {'_account_id': 12081}, {'_account_id': 14760}]","[{'number': 1, 'created': '2015-03-08 07:41:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/3828fa6fdaac3a46440c6c0a6b9ec558b5b7a154', 'message': 'Refactor node capability methods to ironic/common\n\nThis commit refactors the methods handling node\ncapabilities to ironic/common. This helps to make\nuse of these methods for any other code that is\nin ironic/common.  This commit adds a new file\nironic/common/node_utils.py and puts these methods\nin there.\n\nChange-Id: If8a4e9fda5e20bb2a49dc45bc3050eb63503d6de\n'}, {'number': 2, 'created': '2015-03-12 14:19:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/ccae7a145cb068dde6c3b2d8dec7c2e071514097', 'message': 'Refactor node capability methods to ironic/common\n\nThis commit refactors the methods handling node\ncapabilities to ironic/common. This helps to make\nuse of these methods for any other code that is\nin ironic/common.  This commit adds a new file\nironic/common/node_utils.py and puts these methods\nin there.\n\nChange-Id: If8a4e9fda5e20bb2a49dc45bc3050eb63503d6de\n'}, {'number': 3, 'created': '2015-03-12 15:51:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/0daf793c4bdd8594cae2dde8b7c8af42b7e0078c', 'message': 'Refactor node capability methods to ironic/common\n\nThis commit refactors the methods handling node\ncapabilities to ironic/common. This helps to make\nuse of these methods for any other code that is\nin ironic/common.  This commit adds a new file\nironic/common/node_utils.py and puts these methods\nin there.\n\nChange-Id: If8a4e9fda5e20bb2a49dc45bc3050eb63503d6de\n'}, {'number': 4, 'created': '2015-06-12 09:18:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/ff414f266ff92d5598176153fe1403513d510cad', 'message': 'Refactor method to add or update capability string\n\nThis commit moves the method to add or update\ncapability present in ilo/inspect.py to\ncommon/utils.py so that it can be used in raid.py\nmodule.\n\nChange-Id: If8a4e9fda5e20bb2a49dc45bc3050eb63503d6de\n'}, {'number': 5, 'created': '2015-06-12 11:58:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/eca160e6699d88fa92f65ceb745710271179edb3', 'message': 'Refactor method to add or update capability string\n\nThis commit moves the method to add or update\ncapability present in ilo/inspect.py to\ncommon/utils.py so that it can be used in raid.py\nmodule.\n\nChange-Id: If8a4e9fda5e20bb2a49dc45bc3050eb63503d6de\n'}, {'number': 6, 'created': '2015-06-22 15:13:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/5c88d8df1fea4569cfb541b17e37e7732b063e80', 'message': 'Refactor method to add or update capability string\n\nThis commit moves the method to add or update\ncapability present in ilo/inspect.py to\ncommon/utils.py so that it can be used in raid.py\nmodule.\n\nChange-Id: If8a4e9fda5e20bb2a49dc45bc3050eb63503d6de\n'}, {'number': 7, 'created': '2015-06-23 10:07:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/cdd696548ade59a7e98d103a0ba7e51e29b420cf', 'message': 'Refactor method to add or update capability string\n\nThis commit moves the method to add or update\ncapability present in ilo/inspect.py to\ncommon/utils.py so that it can be used in raid.py\nmodule.\n\nImplements: blueprint ironic-generic-raid-interface\nChange-Id: If8a4e9fda5e20bb2a49dc45bc3050eb63503d6de\n'}, {'number': 8, 'created': '2015-06-23 14:01:22.000000000', 'files': ['ironic/tests/test_utils.py', 'ironic/tests/drivers/ilo/test_inspect.py', 'ironic/common/utils.py', 'ironic/drivers/modules/ilo/inspect.py'], 'web_link': 'https://opendev.org/openstack/ironic/commit/816f686805f4cbe1d11169c7714fc17c47c4b058', 'message': 'Refactor method to add or update capability string\n\nThis commit moves the method to add or update\ncapability present in ilo/inspect.py to\ncommon/utils.py so that it can be used in raid.py\nmodule.\n\nImplements: blueprint ironic-generic-raid-interface\nChange-Id: If8a4e9fda5e20bb2a49dc45bc3050eb63503d6de\n'}]",29,162451,816f686805f4cbe1d11169c7714fc17c47c4b058,54,9,8,9315,,,0,"Refactor method to add or update capability string

This commit moves the method to add or update
capability present in ilo/inspect.py to
common/utils.py so that it can be used in raid.py
module.

Implements: blueprint ironic-generic-raid-interface
Change-Id: If8a4e9fda5e20bb2a49dc45bc3050eb63503d6de
",git fetch https://review.opendev.org/openstack/ironic refs/changes/51/162451/5 && git format-patch -1 --stdout FETCH_HEAD,"['ironic/drivers/utils.py', 'ironic/tests/drivers/ilo/test_common.py', 'ironic/tests/test_node_utils.py', 'ironic/common/node_utils.py', 'ironic/tests/drivers/test_pxe.py', 'ironic/tests/drivers/test_utils.py', 'ironic/drivers/modules/irmc/management.py', 'ironic/drivers/modules/ilo/common.py', 'ironic/drivers/modules/ilo/deploy.py', 'ironic/drivers/modules/pxe.py', 'ironic/tests/drivers/irmc/test_management.py', 'ironic/common/pxe_utils.py', 'ironic/tests/drivers/ilo/test_deploy.py']",13,3828fa6fdaac3a46440c6c0a6b9ec558b5b7a154,bp/ironic-generic-raid-interface,"from ironic.common import node_utils @mock.patch.object(node_utils, 'get_node_capability') @mock.patch.object(node_utils, 'get_node_capability') @mock.patch.object(node_utils, 'get_node_capability')"," @mock.patch.object(driver_utils, 'get_node_capability') @mock.patch.object(driver_utils, 'get_node_capability') @mock.patch.object(driver_utils, 'get_node_capability')",214,176
openstack%2Fbarbican~master~I558a44f1006933c5abb61b749293a3aaf2a06622,openstack/barbican,master,I558a44f1006933c5abb61b749293a3aaf2a06622,Added unit test around bug related to who can modify ACL.,MERGED,2015-05-02 00:09:53.000000000,2015-06-25 16:45:13.000000000,2015-06-25 16:45:08.000000000,"[{'_account_id': 3}, {'_account_id': 1091}, {'_account_id': 7136}, {'_account_id': 8623}, {'_account_id': 9914}, {'_account_id': 10873}]","[{'number': 1, 'created': '2015-05-02 00:09:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/barbican/commit/5b6fc47977c2115dd3d67f3cd7c11eb2a85f3538', 'message': ""Addressing bug related to who can modify ACL.\n\nAs per the change, 'admin' project user can create/modify/delete ACL on\nsecrets/containers within same project.\nOtherwise only 'creator' of secret/container can create/modify/delete ACL\nand that user is expected to have 'creator' project role.\n\nChange-Id: I558a44f1006933c5abb61b749293a3aaf2a06622\nCloses-bug: #1450849\n""}, {'number': 2, 'created': '2015-05-02 00:11:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/barbican/commit/5e464273e0bb40bbc9239587f26f4b9f7a72738c', 'message': ""Addressing bug related to who can modify ACL.\n\nAs per the change, 'admin' project user can create/modify/delete ACL on\nsecrets/containers within same project.\nOtherwise only 'creator' of secret/container can create/modify/delete ACL\nand that user is expected to have 'creator' project role.\n\nChange-Id: I558a44f1006933c5abb61b749293a3aaf2a06622\nCloses-bug: #1450849\n""}, {'number': 3, 'created': '2015-06-18 02:54:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/barbican/commit/9673ecc2c6d1e5867a27ceab59ed5c6a526d4e9b', 'message': ""Addred unit test around bug related to who can modify ACL.\n\nAs per the change, 'admin' project user can create/modify/delete ACL on\nsecrets/containers within same project.\nOtherwise only 'creator' of secret/container can create/modify/delete ACL\nand that user is expected to have 'creator' project role.\n\nMost of needed code changes were made in earlier ACL refactoring effort.\nIn this patch, primarily adding unit test to verify policy enforcement.\n\nChange-Id: I558a44f1006933c5abb61b749293a3aaf2a06622\nCloses-bug: #1450849\n""}, {'number': 4, 'created': '2015-06-18 02:56:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/barbican/commit/fa28e075caffe443983edbb25a8979debbb625b1', 'message': ""Added unit test around bug related to who can modify ACL.\n\nAs per the change, 'admin' project user can create/modify/delete ACL on\nsecrets/containers within same project.\nOtherwise only 'creator' of secret/container can create/modify/delete ACL\nand that user is expected to have 'creator' project role.\n\nMost of needed code changes were made in earlier ACL refactoring effort.\nIn this patch, primarily adding unit test to verify policy enforcement.\n\nChange-Id: I558a44f1006933c5abb61b749293a3aaf2a06622\nCloses-bug: #1450849\n""}, {'number': 5, 'created': '2015-06-18 19:14:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/barbican/commit/2ab9aa1180cc41c846caee353da9497c75a91f77', 'message': ""Added unit test around bug related to who can modify ACL.\n\nAs per the change, 'admin' project user can create/modify/delete ACL on\nsecrets/containers within same project.\nOtherwise only 'creator' of secret/container can create/modify/delete ACL\nand that user is expected to have 'creator' project role.\n\nMost of needed code changes were made in earlier ACL refactoring effort.\nIn this patch, primarily adding parametrized unit test to verify policy\nenforcement.\n\nChange-Id: I558a44f1006933c5abb61b749293a3aaf2a06622\nCloses-bug: #1450849\n""}, {'number': 6, 'created': '2015-06-22 16:13:28.000000000', 'files': ['barbican/api/controllers/__init__.py', 'barbican/tests/api/controllers/test_acls.py'], 'web_link': 'https://opendev.org/openstack/barbican/commit/f4645001dc64907468700b5945db1889749c89a3', 'message': ""Added unit test around bug related to who can modify ACL.\n\nAs per the change, 'admin' project user can create/modify/delete ACL on\nsecrets/containers within same project.\nOtherwise only 'creator' of secret/container can create/modify/delete ACL\nand that user is expected to have 'creator' project role.\n\nMost of needed code changes were made in earlier ACL refactoring effort.\nIn this patch, primarily adding unit test to verify policy enforcement.\n\nChange-Id: I558a44f1006933c5abb61b749293a3aaf2a06622\nCloses-bug: #1450849\n""}]",4,179547,f4645001dc64907468700b5945db1889749c89a3,22,6,6,1091,,,0,"Added unit test around bug related to who can modify ACL.

As per the change, 'admin' project user can create/modify/delete ACL on
secrets/containers within same project.
Otherwise only 'creator' of secret/container can create/modify/delete ACL
and that user is expected to have 'creator' project role.

Most of needed code changes were made in earlier ACL refactoring effort.
In this patch, primarily adding unit test to verify policy enforcement.

Change-Id: I558a44f1006933c5abb61b749293a3aaf2a06622
Closes-bug: #1450849
",git fetch https://review.opendev.org/openstack/barbican refs/changes/47/179547/6 && git format-patch -1 --stdout FETCH_HEAD,"['barbican/api/controllers/acls.py', 'etc/barbican/policy.json', 'barbican/tests/utils.py', 'barbican/tests/api/controllers/test_acls.py']",4,5b6fc47977c2115dd3d67f3cd7c11eb2a85f3538,bug_1450849,"from barbican.tests.api import test_resources_policy as test_policyclass TestACLsWithContextMixin(test_policy.BaseTestCase): """"""Mixin for performing common acls operation used with policy logic."""""" def _create_secret_with_creator_user(self, app, creator_user_id): # define creator user for new secret entry. app.extra_environ = { 'barbican.context': self._build_context(self.project_id, user=creator_user_id) } secret_id, _ = create_secret(app) return secret_id def _create_container_with_creator_user(self, app, creator_user_id): # define creator user for new container entry. app.extra_environ = { 'barbican.context': self._build_context(self.project_id, user=creator_user_id) } container_id, _ = create_container(app) return container_id def _set_acls_with_context(self, app, entity_type=None, op_type=None, entity_id=None, roles=None, user=None, enforce_policy=True, expect_errors=False): """"""Perform acls create/updat/delete operation with policy logic. Before performing acls create/update/delete, provided input is used for setting custom barbican context. Operation is done under policy enforcement logic. """""" policy_enforcer = self.policy_enforcer if enforce_policy else None app.extra_environ = { 'barbican.context': self._build_context( self.project_id, roles=roles, user=user, is_admin=False, policy_enforcer=policy_enforcer) } resp = None if op_type == 'create': resp, _ = create_acls(app, entity_type, entity_id, read_user_ids=['u1', 'u2'], expect_errors=expect_errors) elif op_type == 'update': resp, _ = update_acls(app, entity_type, entity_id, read_user_ids=['u1', 'u2'], expect_errors=expect_errors) elif op_type == 'delete': resp = app.delete('/{0}/{1}/acls'.format(entity_type, entity_id), expect_errors=expect_errors) return resp def _set_an_acl_with_context(self, app, entity_type=None, op_type=None, entity_id=None, roles=None, user=None, enforce_policy=True, expect_errors=False, create_acls_needed=True): """"""Perform single acl update or delete operation with policy logic. Before performing single acl update/delete, provided input is used for setting custom barbican context. Operation is done under policy enforcement logic. """""" policy_enforcer = self.policy_enforcer if enforce_policy else None if create_acls_needed: # don't re-create if created in earlier check app.extra_environ = { 'barbican.context': self._build_context( self.project_id, policy_enforcer=None) } _, _ = create_acls(app, entity_type, entity_id, read_user_ids=['u1', 'u2'], read_creator_only=False) is_secret = entity_type == 'secrets' acl_map = _get_acl_map(entity_id, is_secret=is_secret) acl_id = acl_map['read']['id'] app.extra_environ = { 'barbican.context': self._build_context( self.project_id, roles=roles, user=user, is_admin=False, policy_enforcer=policy_enforcer) } resp = None if op_type == 'update': resp = update_acl(app, entity_type, entity_id, acl_id, read_creator_only=False, expect_errors=expect_errors) elif op_type == 'delete': resp = app.delete('/{0}/{1}/acls/{2}'.format(entity_type, entity_id, acl_id), expect_errors=expect_errors) return resp class WhenTestingSecretACLsResource(utils.BarbicanAPIBaseTestCase, TestACLsWithContextMixin): def test_who_can_create_new_secret_acls(self): """"""Test who can create new secret ACLs as per policy rules. New secret ACLs can be created by user who created the secret. Other user with 'creator' role in secret project cannot create ACL if user is not creator of the secret. User with 'admin' role in secret project can create ACL for that secret. """""" creator_user_id = 'creatorUserId' secret_uuid = self._create_secret_with_creator_user( self.app, creator_user_id) secret_uuid2 = self._create_secret_with_creator_user( self.app, creator_user_id) resp = self._set_acls_with_context( self.app, entity_type='secrets', op_type='create', entity_id=secret_uuid, roles=['creator'], user='NotSecretCreator', expect_errors=True) self.assertEqual(resp.status_int, 403) resp = self._set_acls_with_context( self.app, entity_type='secrets', op_type='create', entity_id=secret_uuid, roles=['creator'], user=creator_user_id, expect_errors=False) self.assertEqual(resp.status_int, 201) # test for user with 'admin' role in secret project resp = self._set_acls_with_context( self.app, entity_type='secrets', op_type='create', entity_id=secret_uuid2, roles=['admin'], user='AdminUser', expect_errors=False) self.assertEqual(resp.status_int, 201) def test_who_can_update_secret_acls(self): """"""Test who can update existing secret ACLs as per policy rules. Existing secret ACLs can be updated by user who created the secret. Other user with 'creator' role in secret project cannot update ACL if user is not creator of the secret. User with 'admin' role in secret project can update ACL for that secret. """""" creator_user_id = 'creatorUserId' secret_uuid = self._create_secret_with_creator_user( self.app, creator_user_id) self._set_acls_with_context( self.app, entity_type='secrets', op_type='create', entity_id=secret_uuid, enforce_policy=False) resp = self._set_acls_with_context( self.app, entity_type='secrets', op_type='update', entity_id=secret_uuid, roles=['creator'], user='NotSecretCreator', expect_errors=True) self.assertEqual(resp.status_int, 403) resp = self._set_acls_with_context( self.app, entity_type='secrets', op_type='update', entity_id=secret_uuid, roles=['creator'], user=creator_user_id) self.assertEqual(resp.status_int, 200) # test for user with 'admin' role in secret project resp = self._set_acls_with_context( self.app, entity_type='secrets', op_type='update', entity_id=secret_uuid, roles=['admin'], user='AdminUser') self.assertEqual(resp.status_int, 200) def test_who_can_delete_secret_acls(self): """"""Test who can delete existing secret ACLs as per policy rules. Existing secret ACLs can be deleted by user who created the secret. Other user with 'creator' role in secret project cannot delete ACL if user is not creator of the secret. User with 'admin' role in secret project can delete ACL for that secret. """""" creator_user_id = 'creatorUserId' secret_uuid = self._create_secret_with_creator_user( self.app, creator_user_id) self._set_acls_with_context( self.app, entity_type='secrets', op_type='create', entity_id=secret_uuid, enforce_policy=False) resp = self._set_acls_with_context( self.app, entity_type='secrets', op_type='delete', entity_id=secret_uuid, roles=['creator'], user='NotSecretCreator', expect_errors=True) self.assertEqual(resp.status_int, 403) resp = self._set_acls_with_context( self.app, entity_type='secrets', op_type='delete', entity_id=secret_uuid, roles=['creator'], user=creator_user_id) self.assertEqual(resp.status_int, 200) # Create new secret ACLs again. self._set_acls_with_context( self.app, entity_type='secrets', op_type='create', entity_id=secret_uuid, enforce_policy=False) # test for user with 'admin' role in secret project resp = self._set_acls_with_context( self.app, entity_type='secrets', op_type='delete', entity_id=secret_uuid, roles=['admin'], user='AdminUser') self.assertEqual(resp.status_int, 200) class WhenTestingSecretACLResource(utils.BarbicanAPIBaseTestCase, TestACLsWithContextMixin): def test_who_can_update_a_secret_acl(self): """"""Test who can update an existing secret ACL as per policy rules. Existing secret ACL can be updated by user who created the secret. Other user with 'creator' role in secret project cannot update ACL if user is not creator of the secret. User with 'admin' role in secret project can update ACL for that secret. """""" creator_user_id = 'creatorUserId' secret_uuid = self._create_secret_with_creator_user( self.app, creator_user_id) resp = self._set_an_acl_with_context( self.app, entity_type='secrets', op_type='update', entity_id=secret_uuid, roles=['creator'], user='NotCreator', expect_errors=True) self.assertEqual(resp.status_int, 403) resp = self._set_an_acl_with_context( self.app, entity_type='secrets', op_type='update', entity_id=secret_uuid, roles=['creator'], user=creator_user_id, create_acls_needed=False) self.assertEqual(resp.status_int, 200) # test for user with 'admin' role in secret project resp = self._set_an_acl_with_context( self.app, entity_type='secrets', op_type='update', entity_id=secret_uuid, roles=['admin'], user='AdminUser', create_acls_needed=False) self.assertEqual(resp.status_int, 200) def test_who_can_delete_a_secret_acl(self): """"""Test who can delete an existing secret ACL as per policy rules. Existing secret ACL can be deleted by user who created the secret. Other user with 'creator' role in secret project cannot delete ACL if user is not creator of the secret. User with 'admin' role in secret project can delete ACL for that secret. """""" creator_user_id = 'creatorUserId' secret_uuid = self._create_secret_with_creator_user( self.app, creator_user_id) resp = self._set_an_acl_with_context( self.app, entity_type='secrets', op_type='delete', entity_id=secret_uuid, roles=['creator'], user='NotCreator', expect_errors=True) self.assertEqual(resp.status_int, 403) resp = self._set_an_acl_with_context( self.app, entity_type='secrets', op_type='delete', entity_id=secret_uuid, roles=['creator'], user=creator_user_id, create_acls_needed=False) self.assertEqual(resp.status_int, 200) # test for user with 'admin' role in secret project resp = self._set_an_acl_with_context( self.app, entity_type='secrets', op_type='delete', entity_id=secret_uuid, roles=['admin'], user='AdminUser', create_acls_needed=True) self.assertEqual(resp.status_int, 200) class WhenTestingContainerAclsResource(utils.BarbicanAPIBaseTestCase, TestACLsWithContextMixin): def test_who_can_create_new_container_acls(self): """"""Test who can create new container ACLs as per policy rules. New container ACLs can be created by user who created the container. Other user with 'creator' role in container project cannot create ACL if user is not creator of the container. User with 'admin' role in container project can create ACL for that container. """""" creator_user_id = 'creatorUserId' container_id = self._create_container_with_creator_user( self.app, creator_user_id) container_id2 = self._create_container_with_creator_user( self.app, creator_user_id) resp = self._set_acls_with_context( self.app, entity_type='containers', op_type='create', entity_id=container_id, roles=['creator'], user='NotContainerCreator', expect_errors=True) self.assertEqual(resp.status_int, 403) resp = self._set_acls_with_context( self.app, entity_type='containers', op_type='create', entity_id=container_id, roles=['creator'], user=creator_user_id, expect_errors=False) self.assertEqual(resp.status_int, 201) # test for user with 'admin' role in container project resp = self._set_acls_with_context( self.app, entity_type='containers', op_type='create', entity_id=container_id2, roles=['admin'], user='AdminUser', expect_errors=False) self.assertEqual(resp.status_int, 201) def test_who_can_update_container_acls(self): """"""Test who can update existing container ACLs as per policy rules. Existing container ACLs can be updated by user who created the container. Other user with 'creator' role in container project cannot update ACL if user is not creator of the container. User with 'admin' role in container project can update ACL for that container. """""" creator_user_id = 'creatorUserId' container_id = self._create_container_with_creator_user( self.app, creator_user_id) self._set_acls_with_context( self.app, entity_type='containers', op_type='create', entity_id=container_id, enforce_policy=False) resp = self._set_acls_with_context( self.app, entity_type='containers', op_type='update', entity_id=container_id, roles=['creator'], user='NotCreator', expect_errors=True) self.assertEqual(resp.status_int, 403) resp = self._set_acls_with_context( self.app, entity_type='containers', op_type='update', entity_id=container_id, roles=['creator'], user=creator_user_id) self.assertEqual(resp.status_int, 200) # test for user with 'admin' role in container project resp = self._set_acls_with_context( self.app, entity_type='containers', op_type='update', entity_id=container_id, roles=['admin'], user='AdminUser') self.assertEqual(resp.status_int, 200) def test_who_can_delete_container_acls(self): """"""Test who can delete existing container ACLs as per policy rules. Existing container ACLs can be deleted by user who created the container. Other user with 'creator' role in container project cannot delete ACL if user is not creator of the container. User with 'admin' role in container project can delete ACL for that container. """""" creator_user_id = 'creatorUserId' container_id = self._create_container_with_creator_user( self.app, creator_user_id) self._set_acls_with_context( self.app, entity_type='containers', op_type='create', entity_id=container_id, enforce_policy=False) resp = self._set_acls_with_context( self.app, entity_type='containers', op_type='delete', entity_id=container_id, roles=['creator'], user='NotCreator', expect_errors=True) self.assertEqual(resp.status_int, 403) resp = self._set_acls_with_context( self.app, entity_type='containers', op_type='delete', entity_id=container_id, roles=['creator'], user=creator_user_id) self.assertEqual(resp.status_int, 200) # Create new container ACLs again. self._set_acls_with_context( self.app, entity_type='containers', op_type='create', entity_id=container_id, enforce_policy=False) # test for user with 'admin' role in container project resp = self._set_acls_with_context( self.app, entity_type='containers', op_type='delete', entity_id=container_id, roles=['admin'], user='AdminUser') self.assertEqual(resp.status_int, 200) class WhenTestingContainerAclResource(utils.BarbicanAPIBaseTestCase, TestACLsWithContextMixin): def test_who_can_update_a_container_acl(self): """"""Test who can update an existing container ACL as per policy rules. Existing container ACL can be updated by user who created the container. Other user with 'creator' role in container project cannot update ACL if user is not creator of the container. User with 'admin' role in container project can update ACL for that container. """""" creator_user_id = 'creatorUserId' container_id = self._create_container_with_creator_user( self.app, creator_user_id) resp = self._set_an_acl_with_context( self.app, entity_type='containers', op_type='update', entity_id=container_id, roles=['creator'], user='NotCreator', expect_errors=True) self.assertEqual(resp.status_int, 403) resp = self._set_an_acl_with_context( self.app, entity_type='containers', op_type='update', entity_id=container_id, roles=['creator'], user=creator_user_id, create_acls_needed=False) self.assertEqual(resp.status_int, 200) # test for user with 'admin' role in container project resp = self._set_an_acl_with_context( self.app, entity_type='containers', op_type='update', entity_id=container_id, roles=['admin'], user='AdminUser', create_acls_needed=False) self.assertEqual(resp.status_int, 200) def test_who_can_delete_a_container_acl(self): """"""Test who can delete an existing container ACL as per policy rules. Existing container ACL can be deleted by user who created the container. Other user with 'creator' role in container project cannot delete ACL if user is not container of the secret. User with 'admin' role in container project can delete ACL for that container. """""" creator_user_id = 'creatorUserId' container_id = self._create_container_with_creator_user( self.app, creator_user_id) resp = self._set_an_acl_with_context( self.app, entity_type='containers', op_type='delete', entity_id=container_id, roles=['creator'], user='NotCreator', expect_errors=True) self.assertEqual(resp.status_int, 403) resp = self._set_an_acl_with_context( self.app, entity_type='containers', op_type='delete', entity_id=container_id, roles=['creator'], user=creator_user_id, create_acls_needed=False) self.assertEqual(resp.status_int, 200) # test for user with 'admin' role in container project resp = self._set_an_acl_with_context( self.app, entity_type='containers', op_type='delete', entity_id=container_id, roles=['admin'], user='AdminUser', create_acls_needed=True) self.assertEqual(resp.status_int, 200) ",class WhenTestingSecretACLsResource(utils.BarbicanAPIBaseTestCase):class WhenTestingSecretACLResource(utils.BarbicanAPIBaseTestCase):class WhenTestingContainerAclsResource(utils.BarbicanAPIBaseTestCase):class WhenTestingContainerAclResource(utils.BarbicanAPIBaseTestCase):,485,23
openstack%2Fbifrost~master~I161f06ea2ebb26fe5cf5066713cfd12d33316fbb,openstack/bifrost,master,I161f06ea2ebb26fe5cf5066713cfd12d33316fbb,Addition of shade support to bifrost_inventory.py,MERGED,2015-06-23 14:46:50.000000000,2015-06-25 16:39:09.000000000,2015-06-25 16:39:09.000000000,"[{'_account_id': 3}, {'_account_id': 5805}]","[{'number': 1, 'created': '2015-06-23 14:46:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/bifrost/commit/5c2db9157761aba505a642de7e4acce08e41362f', 'message': 'Addition of shade support to bifrot_inventory.py\n\nAdding additional support to the dynamic inventory data source to\nallow a user to query ironic for the list of machines, which allows\na user to match on node state, and if sufficent information is\nalready present, deploy to the node.\n\nChange-Id: I161f06ea2ebb26fe5cf5066713cfd12d33316fbb\n'}, {'number': 2, 'created': '2015-06-24 13:37:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/bifrost/commit/00adc9b62155e5453e4e822a425df1fdc93b3967', 'message': 'Addition of shade support to bifrost_inventory.py\n\nAdding additional support to the dynamic inventory data source to\nallow a user to query ironic for the list of machines, which allows\na user to match on node state, and if sufficent information is\nalready present, deploy to the node.\n\nChange-Id: I161f06ea2ebb26fe5cf5066713cfd12d33316fbb\n'}, {'number': 3, 'created': '2015-06-24 16:34:00.000000000', 'files': ['playbooks/inventory/bifrost_inventory.py'], 'web_link': 'https://opendev.org/openstack/bifrost/commit/89fab210599f8327a91f2ea58520f1c270c2e415', 'message': 'Addition of shade support to bifrost_inventory.py\n\nAdding additional support to the dynamic inventory data source to\nallow a user to query ironic for the list of machines, which allows\na user to match on node state, and if sufficent information is\nalready present, deploy to the node.\n\nChange-Id: I161f06ea2ebb26fe5cf5066713cfd12d33316fbb\n'}]",1,194684,89fab210599f8327a91f2ea58520f1c270c2e415,12,2,3,11655,,,0,"Addition of shade support to bifrost_inventory.py

Adding additional support to the dynamic inventory data source to
allow a user to query ironic for the list of machines, which allows
a user to match on node state, and if sufficent information is
already present, deploy to the node.

Change-Id: I161f06ea2ebb26fe5cf5066713cfd12d33316fbb
",git fetch https://review.opendev.org/openstack/bifrost refs/changes/84/194684/3 && git format-patch -1 --stdout FETCH_HEAD,['playbooks/inventory/bifrost_inventory.py'],1,5c2db9157761aba505a642de7e4acce08e41362f,194684,"One can also just directly invoke bifrost_inventory.py in order to see theUtilizing ironic as the data source ----------------------------------- The functionality exists to allow a user to query an existing ironic installation for the inventory data. This is an advanced feature, as the node may not have sufficent information to allow for node deployment or automated testing, unless DHCP reservations are used. This setting can be invoked by setting the source to ""ironic"":: export BIFROST_INVENTORY_SOURCE=ironicimport yaml import six import shadedef _identify_shade_auth(): """"""Return shade credentials"""""" # Note(TheJulia): A logical progression is to support a user defining # an environment variable that triggers use of os-client-config to allow # environment variables or clouds.yaml auth configuration. This could # potentially be passed in as variables which could then be passed # to modules for authentication allowing the basic tooling to be # utilized in the context of a larger cloud supporting ironic. options = dict( auth_type=""None"", auth=dict(endpoint=""http://localhost:6385/"",) ) return options def _process_shade(groups, hostvars): """"""Retrieve inventory utilizing Shade"""""" options = _identify_shade_auth() cloud = shade.operator_cloud(**options) machines = cloud.list_machines() for machine in machines: if machine['name'] is None: name = machine['uuid'] else: name = machine['name'] new_machine = {} for key, value in six.iteritems(machine): if 'links' not in key: new_machine[key] = value new_machine['addressing_mode'] = ""dhcp"" groups['baremetal']['hosts'].append(name) hostvars.update({name: new_machine}) return (groups, hostvars) elif ""ironic"" in data_source: (groups, hostvars) = _process_shade(groups, hostvars)","One can also just direclty invoke bifrost_inventory.py in order to see theimport yaml # elif ""ironic"" in data_source.lower: # TODO(TheJulia) This would call shade's inventory and perform the # bare minimal manipulation to map things through. # if 'ironic' in os.environ['BIFROST_INVENTORY_SOURCE']:",53,6
openstack%2Fbifrost~master~I00c709698292120b7e668014dfcd6a8f35a55dda,openstack/bifrost,master,I00c709698292120b7e668014dfcd6a8f35a55dda,Correct license header on zuul change parsing code,MERGED,2015-06-24 13:16:44.000000000,2015-06-25 16:38:39.000000000,2015-06-25 16:38:33.000000000,"[{'_account_id': 3}, {'_account_id': 5805}, {'_account_id': 12459}]","[{'number': 1, 'created': '2015-06-24 13:16:44.000000000', 'files': ['playbooks/roles/ironic-install/files/parse_zuul_changes.py'], 'web_link': 'https://opendev.org/openstack/bifrost/commit/b6cf6bffcd572ef70fb436afec1f4852058ba5b9', 'message': ""Correct license header on zuul change parsing code\n\nWhen I originally stamped the license on to the code to parse\nchanges from zuul, I accidently stamped the incorrect license\non the file.  Since I'm the only person to have modified this\nfile, this change is to correct the license header.\n\nChange-Id: I00c709698292120b7e668014dfcd6a8f35a55dda\n""}]",0,195073,b6cf6bffcd572ef70fb436afec1f4852058ba5b9,8,3,1,11655,,,0,"Correct license header on zuul change parsing code

When I originally stamped the license on to the code to parse
changes from zuul, I accidently stamped the incorrect license
on the file.  Since I'm the only person to have modified this
file, this change is to correct the license header.

Change-Id: I00c709698292120b7e668014dfcd6a8f35a55dda
",git fetch https://review.opendev.org/openstack/bifrost refs/changes/73/195073/1 && git format-patch -1 --stdout FETCH_HEAD,['playbooks/roles/ironic-install/files/parse_zuul_changes.py'],1,b6cf6bffcd572ef70fb436afec1f4852058ba5b9,,"# Copyright (c) 2015 Hewlett-Packard Development Company, L.P.# Licensed under the Apache License, Version 2.0 (the ""License""); # you may not use this file except in compliance with the License. # You may obtain a copy of the License at# http://www.apache.org/licenses/LICENSE-2.0# Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or # implied. # See the License for the specific language governing permissions and # limitations under the License."," # (c) 2015, Hewlett-Packard Development Company, L.P.# This module is free software: you can redistribute it and/or modify # it under the terms of the GNU General Public License as published by # the Free Software Foundation, either version 3 of the License, or # (at your option) any later version.# This software is distributed in the hope that it will be useful, # but WITHOUT ANY WARRANTY; without even the implied warranty of # MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the # GNU General Public License for more details.# You should have received a copy of the GNU General Public License # along with this software. If not, see <http://www.gnu.org/licenses/>.",11,12
openstack%2Fbifrost~master~Ief657e06e781133dd53a58c1da11802d8d7d03c4,openstack/bifrost,master,Ief657e06e781133dd53a58c1da11802d8d7d03c4,Add os_ironic_facts module,MERGED,2015-06-12 14:27:20.000000000,2015-06-25 16:38:33.000000000,2015-06-25 16:38:26.000000000,"[{'_account_id': 3}, {'_account_id': 5805}, {'_account_id': 11655}, {'_account_id': 13997}]","[{'number': 1, 'created': '2015-06-12 14:27:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/bifrost/commit/d1fcebacde40c5dcdb8705721880d7050273faf6', 'message': 'Add os_ironic_facts module\n\nAdding a module that allows ironic to be queried for facts about the\nhost via a name, mac address, or uuid.  The returned facts include\nall node details with the exception of any passwords in driver_info.\n\nChange-Id: Ief657e06e781133dd53a58c1da11802d8d7d03c4\nDepends-On: I1c1b40f1827c9fafe8826f7b07942c2ed7c85228\n'}, {'number': 2, 'created': '2015-06-15 06:57:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/bifrost/commit/15e8633a562956998f954862bc6932d8e26fe66d', 'message': 'Add os_ironic_facts module\n\nAdding a module that allows ironic to be queried for facts about the\nhost via a name, mac address, or uuid.  The returned facts include\nall node details with the exception of any passwords in driver_info.\n\nChange-Id: Ief657e06e781133dd53a58c1da11802d8d7d03c4\nDepends-On: I1c1b40f1827c9fafe8826f7b07942c2ed7c85228\n'}, {'number': 3, 'created': '2015-06-17 17:03:28.000000000', 'files': ['playbooks/library/os_ironic_facts.py'], 'web_link': 'https://opendev.org/openstack/bifrost/commit/52a92078dc3c5aedf74254ec797ea448aab87262', 'message': 'Add os_ironic_facts module\n\nAdding a module that allows ironic to be queried for facts about the\nhost via a name, mac address, or uuid.  The returned facts include\nall node details with the exception of any passwords in driver_info.\n\nChange-Id: Ief657e06e781133dd53a58c1da11802d8d7d03c4\nDepends-On: I1c1b40f1827c9fafe8826f7b07942c2ed7c85228\n'}]",1,191093,52a92078dc3c5aedf74254ec797ea448aab87262,17,4,3,11655,,,0,"Add os_ironic_facts module

Adding a module that allows ironic to be queried for facts about the
host via a name, mac address, or uuid.  The returned facts include
all node details with the exception of any passwords in driver_info.

Change-Id: Ief657e06e781133dd53a58c1da11802d8d7d03c4
Depends-On: I1c1b40f1827c9fafe8826f7b07942c2ed7c85228
",git fetch https://review.opendev.org/openstack/bifrost refs/changes/93/191093/3 && git format-patch -1 --stdout FETCH_HEAD,['playbooks/library/os_ironic_facts.py'],1,d1fcebacde40c5dcdb8705721880d7050273faf6,191093,"#!/usr/bin/env python # coding: utf-8 -*- # (c) 2015, Hewlett-Packard Development Company, L.P. # # This module is free software: you can redistribute it and/or modify # it under the terms of the GNU General Public License as published by # the Free Software Foundation, either version 3 of the License, or # (at your option) any later version. # # This software is distributed in the hope that it will be useful, # but WITHOUT ANY WARRANTY; without even the implied warranty of # MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the # GNU General Public License for more details. # # You should have received a copy of the GNU General Public License # along with this software. If not, see <http://www.gnu.org/licenses/>. try: import shade HAS_SHADE = True except ImportError: HAS_SHADE = False DOCUMENTATION = ''' --- module: os_ironic_facts short_description: Searches Ironic and returns node facts. extends_documentation_fragment: openstack description: - Queries Ironic for a requested node and returns facts about the node, or fails if the node is not found. This module activly prevents any passwords in the node driver_info from being returned. options: mac: description: - unique mac address that is used to attempt to identify the host. required: false default: None uuid: description: - globally unique identifier (UUID) to identify the host. required: false default: None name: description: - unique name identifier to identify the host in Ironic. required: false default: None ironic_url: description: - If noauth mode is utilized, this is required to be set to the endpoint URL for the Ironic API. Use with ""auth"" and ""auth_type"" settings set to None. required: false default: None requirements: [""shade""] ''' EXAMPLES = ''' # Enroll a node with some basic properties and driver info - os_ironic_facts: name: ""testvm1"" ''' def _choose_id_value(module): if module.params['uuid']: return module.params['uuid'] if module.params['name']: return module.params['name'] return None def main(): argument_spec = openstack_full_argument_spec( auth_type=dict(required=False), uuid=dict(required=False), name=dict(required=False), mac=dict(required=False), ironic_url=dict(required=False), ) module_kwargs = openstack_module_kwargs() module = AnsibleModule(argument_spec, **module_kwargs) if not HAS_SHADE: module.fail_json(msg='shade is required for this module') if (module.params['auth_type'] in [None, 'None'] and module.params['ironic_url'] is None): module.fail_json(msg=""Authentication appears to be disabled, "" ""Please define an ironic_url parameter"") if (module.params['ironic_url'] and module.params['auth_type'] in [None, 'None']): module.params['auth'] = dict( endpoint=module.params['ironic_url'] ) try: cloud = shade.operator_cloud(**module.params) if module.params['name'] or module.params['uuid']: server = cloud.get_machine(_choose_id_value(module)) elif module.params['mac']: server = cloud.get_machine_by_mac(module.params['mac']) else: module.fail_json(msg=""The worlds did not align, "" ""the host was not found as "" ""no name, uuid, or mac was "" ""defined."") if server: facts = dict(server) new_driver_info = dict() # Rebuild driver_info to remove any password # fields as they can be masked. for key, value in facts['driver_info'].iteritems(): if 'password' not in key: new_driver_info[key] = value if new_driver_info: facts['driver_info'] = new_driver_info module.exit_json(changed=False, ansible_facts=facts) else: module.fail_json(msg=""node not found."") except shade.OpenStackCloudException as e: module.fail_json(msg=e.message) # this is magic, see lib/ansible/module_common.py from ansible.module_utils.basic import * from ansible.module_utils.openstack import * main() ",,134,0
openstack%2Fnova-powervm~master~I1faee7a630b6f0495ffde61e95095f1942b9464a,openstack/nova-powervm,master,I1faee7a630b6f0495ffde61e95095f1942b9464a,Task for streaming disk to glance,MERGED,2015-06-23 23:35:43.000000000,2015-06-25 16:33:58.000000000,2015-06-25 16:33:54.000000000,"[{'_account_id': 3}, {'_account_id': 8190}, {'_account_id': 8662}, {'_account_id': 13883}, {'_account_id': 14070}]","[{'number': 1, 'created': '2015-06-23 23:35:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova-powervm/commit/6583eba45194f0cf990ea6cbb62e635ddbe98b77', 'message': 'Task for streaming disk to glance\n\nAdd nova_powervm.virt.powervm.tasks.image.StreamToGlance, which\ngenerates metadata and uploads a disk to glance.\n\nChange-Id: I1faee7a630b6f0495ffde61e95095f1942b9464a\n'}, {'number': 2, 'created': '2015-06-24 14:15:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova-powervm/commit/cbd82c62bfec34454cb8d1e1020e1807dcc55de5', 'message': 'Task for streaming disk to glance\n\nAdd nova_powervm.virt.powervm.tasks.image.StreamToGlance, which\ngenerates metadata and uploads a disk to glance.\n\nChange-Id: I1faee7a630b6f0495ffde61e95095f1942b9464a\n'}, {'number': 3, 'created': '2015-06-24 20:37:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova-powervm/commit/63bd787bb7c0df1919e552bbe850ad2b02517cc1', 'message': 'Task for streaming disk to glance\n\nAdd nova_powervm.virt.powervm.tasks.image.StreamToGlance, which\ngenerates metadata and uploads a disk to glance.\n\nChange-Id: I1faee7a630b6f0495ffde61e95095f1942b9464a\n'}, {'number': 4, 'created': '2015-06-24 21:42:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova-powervm/commit/7f63e4f10a9f4148ce153fbfcf9749b6009d3158', 'message': 'Task for streaming disk to glance\n\nAdd nova_powervm.virt.powervm.tasks.image.StreamToGlance, which\ngenerates metadata and uploads a disk to glance.\n\nChange-Id: I1faee7a630b6f0495ffde61e95095f1942b9464a\n'}, {'number': 5, 'created': '2015-06-24 22:50:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova-powervm/commit/13bbf53b32c8f669186209da07447bc1674e1efc', 'message': 'Task for streaming disk to glance\n\nAdd nova_powervm.virt.powervm.tasks.image.StreamToGlance, which\ngenerates metadata and uploads a disk to glance.\n\nChange-Id: I1faee7a630b6f0495ffde61e95095f1942b9464a\n'}, {'number': 6, 'created': '2015-06-25 14:54:22.000000000', 'files': ['nova_powervm/virt/powervm/tasks/image.py', 'nova_powervm/tests/virt/powervm/tasks/test_image.py', 'nova_powervm/tests/virt/powervm/test_image.py'], 'web_link': 'https://opendev.org/openstack/nova-powervm/commit/5471cad97f51ad283e927425772e8c789f42dec5', 'message': 'Task for streaming disk to glance\n\nAdd nova_powervm.virt.powervm.tasks.image.StreamToGlance, which\ngenerates metadata and uploads a disk to glance.\n\nChange-Id: I1faee7a630b6f0495ffde61e95095f1942b9464a\n'}]",7,194871,5471cad97f51ad283e927425772e8c789f42dec5,25,5,6,14070,,,0,"Task for streaming disk to glance

Add nova_powervm.virt.powervm.tasks.image.StreamToGlance, which
generates metadata and uploads a disk to glance.

Change-Id: I1faee7a630b6f0495ffde61e95095f1942b9464a
",git fetch https://review.opendev.org/openstack/nova-powervm refs/changes/71/194871/5 && git format-patch -1 --stdout FETCH_HEAD,"['nova_powervm/virt/powervm/tasks/image.py', 'nova_powervm/tests/virt/powervm/tasks/test_image.py']",2,6583eba45194f0cf990ea6cbb62e635ddbe98b77,task_stream,"import mock expected_state='expected_state') @mock.patch('nova_powervm.virt.powervm.image.stream_disk_to_glance') @mock.patch('nova_powervm.virt.powervm.image.snapshot_metadata') def test_stream_to_glance(self, mock_metadata, mock_stream): mock_metadata.return_value = 'metadata' tf = tsk_img.StreamToGlance('context', 'image_api', 'image_id', 'instance') self.assertEqual('stream_to_glance', tf.name) tf.execute('disk_path') mock_metadata.assert_called_with('context', 'image_api', 'image_id', 'instance') mock_stream.assert_called_with('context', 'image_api', 'image_id', 'metadata', 'disk_path')", expected_state='expected_state'),34,1
openstack%2Ffuel-library~master~I995138a022e09f12b53abb560eaf1e6134504001,openstack/fuel-library,master,I995138a022e09f12b53abb560eaf1e6134504001,Rename clustercheck to galeracheck,MERGED,2015-06-24 21:07:36.000000000,2015-06-25 16:33:04.000000000,2015-06-25 16:31:27.000000000,"[{'_account_id': 3}, {'_account_id': 406}, {'_account_id': 7195}, {'_account_id': 8786}, {'_account_id': 8971}, {'_account_id': 11090}, {'_account_id': 13948}, {'_account_id': 14225}, {'_account_id': 14774}]","[{'number': 1, 'created': '2015-06-24 21:07:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/12b720f3e2b6c5260515026da863aec52b907705', 'message': 'Rename clustercheck to galeracheck\n\nThis change renames the clustercheck script to galeracheck as it\nconflicts with a similarly named script from the percona packages.\n\nChange-Id: I995138a022e09f12b53abb560eaf1e6134504001\nCloses-Bug: 1461304\n'}, {'number': 2, 'created': '2015-06-24 21:18:40.000000000', 'files': ['deployment/puppet/openstack/files/clustercheck', 'debian/fuel-ha-utils.install', 'specs/fuel-library7.0.spec', 'files/fuel-ha-utils/tools/galeracheck', 'deployment/puppet/openstack/manifests/galera/status.pp'], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/77d7b22c4c82e9f27e46bea743a480e18d4b4a80', 'message': 'Rename clustercheck to galeracheck\n\nThis change renames the clustercheck script to galeracheck as it\nconflicts with a similarly named script from the percona packages.\n\nChange-Id: I995138a022e09f12b53abb560eaf1e6134504001\nCloses-Bug: 1461304\n'}]",0,195317,77d7b22c4c82e9f27e46bea743a480e18d4b4a80,38,9,2,14985,,,0,"Rename clustercheck to galeracheck

This change renames the clustercheck script to galeracheck as it
conflicts with a similarly named script from the percona packages.

Change-Id: I995138a022e09f12b53abb560eaf1e6134504001
Closes-Bug: 1461304
",git fetch https://review.opendev.org/openstack/fuel-library refs/changes/17/195317/2 && git format-patch -1 --stdout FETCH_HEAD,"['deployment/puppet/openstack/files/clustercheck', 'specs/fuel-library7.0.spec', 'files/fuel-ha-utils/tools/galeracheck', 'deployment/puppet/openstack/manifests/galera/status.pp']",4,12b720f3e2b6c5260515026da863aec52b907705,bug/1461304," server => '/usr/bin/galeracheck',"," #file { '/usr/bin/clustercheck': # mode => '0755', # owner => root, # group => root, # source => ""puppet:///modules/openstack/clustercheck"", # require => File['/etc/wsrepclustercheckrc'], #} # require => File['/usr/bin/clustercheck'], server => '/usr/bin/clustercheck', #require => File['/usr/bin/clustercheck'],",3,89
openstack%2Fneutron-vpnaas~master~Ied0faac809a5b72b1cd466c8babc9ca5418692c3,openstack/neutron-vpnaas,master,Ied0faac809a5b72b1cd466c8babc9ca5418692c3,Switch to oslo_utils.uuidutils,MERGED,2015-06-19 23:27:23.000000000,2015-06-25 16:30:31.000000000,2015-06-25 16:30:27.000000000,"[{'_account_id': 3}, {'_account_id': 841}, {'_account_id': 6524}, {'_account_id': 6659}, {'_account_id': 6854}, {'_account_id': 7293}, {'_account_id': 8124}, {'_account_id': 10692}]","[{'number': 1, 'created': '2015-06-19 23:27:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-vpnaas/commit/a8d47902929d3dc6cc2ac9b5bcedcd7547916ade', 'message': 'Switch to oslo_utils.uuidutils\n\nGet rid of oslo-incubator uuidutils\n\nChange-Id: Ied0faac809a5b72b1cd466c8babc9ca5418692c3\nPartial-Bug: #1467020\n'}, {'number': 2, 'created': '2015-06-22 11:03:03.000000000', 'files': ['neutron_vpnaas/tests/unit/services/vpn/device_drivers/test_cisco_ipsec.py', 'neutron_vpnaas/tests/unit/services/vpn/test_vpn_service.py', 'neutron_vpnaas/tests/unit/services/vpn/service_drivers/test_ipsec.py', 'neutron_vpnaas/tests/unit/extensions/test_vpnaas.py', 'neutron_vpnaas/tests/unit/services/vpn/service_drivers/test_cisco_ipsec.py', 'neutron_vpnaas/tests/unit/services/vpn/service_drivers/test_vyatta_ipsec.py', 'neutron_vpnaas/tests/functional/strongswan/test_strongswan_driver.py', 'neutron_vpnaas/tests/unit/services/vpn/device_drivers/test_ipsec.py', 'neutron_vpnaas/tests/unit/services/vpn/test_vyatta_vpn_service.py', 'neutron_vpnaas/tests/unit/services/vpn/device_drivers/test_vyatta_ipsec.py', 'neutron_vpnaas/tests/unit/db/vpn/test_vpn_db.py', 'neutron_vpnaas/db/vpn/vpn_db.py'], 'web_link': 'https://opendev.org/openstack/neutron-vpnaas/commit/dd3c7853ca60ece7eb06f305003d2186e97f77d0', 'message': 'Switch to oslo_utils.uuidutils\n\nGet rid of oslo-incubator uuidutils\n\nChange-Id: Ied0faac809a5b72b1cd466c8babc9ca5418692c3\nPartial-Bug: #1467020\n'}]",2,193754,dd3c7853ca60ece7eb06f305003d2186e97f77d0,22,8,2,8124,,,0,"Switch to oslo_utils.uuidutils

Get rid of oslo-incubator uuidutils

Change-Id: Ied0faac809a5b72b1cd466c8babc9ca5418692c3
Partial-Bug: #1467020
",git fetch https://review.opendev.org/openstack/neutron-vpnaas refs/changes/54/193754/2 && git format-patch -1 --stdout FETCH_HEAD,"['neutron_vpnaas/tests/unit/services/vpn/device_drivers/test_cisco_ipsec.py', 'neutron_vpnaas/tests/unit/services/vpn/test_vpn_service.py', 'neutron_vpnaas/tests/unit/services/vpn/service_drivers/test_ipsec.py', 'neutron_vpnaas/tests/unit/extensions/test_vpnaas.py', 'neutron_vpnaas/tests/unit/services/vpn/service_drivers/test_cisco_ipsec.py', 'neutron_vpnaas/tests/unit/services/vpn/service_drivers/test_vyatta_ipsec.py', 'neutron_vpnaas/tests/functional/strongswan/test_strongswan_driver.py', 'neutron_vpnaas/tests/unit/services/vpn/device_drivers/test_ipsec.py', 'neutron_vpnaas/tests/unit/services/vpn/test_vyatta_vpn_service.py', 'neutron_vpnaas/tests/unit/services/vpn/device_drivers/test_vyatta_ipsec.py', 'neutron_vpnaas/tests/unit/db/vpn/test_vpn_db.py', 'neutron_vpnaas/db/vpn/vpn_db.py']",12,a8d47902929d3dc6cc2ac9b5bcedcd7547916ade,bug/1467020,from oslo_utils import uuidutils,from neutron.openstack.common import uuidutils,12,12
openstack%2Fbifrost~master~I196a8ee6e5aaeeb3cb5c4a43ae211a0056e464a2,openstack/bifrost,master,I196a8ee6e5aaeeb3cb5c4a43ae211a0056e464a2,Add README note about cleaning,MERGED,2015-06-23 18:57:25.000000000,2015-06-25 16:28:03.000000000,2015-06-25 16:27:56.000000000,"[{'_account_id': 3}, {'_account_id': 5805}]","[{'number': 1, 'created': '2015-06-23 18:57:25.000000000', 'files': ['README.rst'], 'web_link': 'https://opendev.org/openstack/bifrost/commit/5ac0362417b09c02fadcfe9fe20beb6725094075', 'message': 'Add README note about cleaning\n\nChange-Id: I196a8ee6e5aaeeb3cb5c4a43ae211a0056e464a2\n'}]",0,194783,5ac0362417b09c02fadcfe9fe20beb6725094075,7,2,1,11655,,,0,"Add README note about cleaning

Change-Id: I196a8ee6e5aaeeb3cb5c4a43ae211a0056e464a2
",git fetch https://review.opendev.org/openstack/bifrost refs/changes/83/194783/1 && git format-patch -1 --stdout FETCH_HEAD,['README.rst'],1,5ac0362417b09c02fadcfe9fe20beb6725094075,,"With regards to testing, you may wish to set your installation such that ironic node cleaning is disabled. You can achieve this by passing the option ""-e cleaning=false"" to the command line or executing the command below. This is because cleaning can take a substantial amount of time while disks are being wiped.:: ansible-playbook -K -vvvv -i inventory/localhost install.yaml -e cleaning=false After you have performed an installation, you can edit /etc/ironic/ironic.conf to enable or disable cleaning as desired.",,10,0
openstack%2Fbifrost~master~I82dea151e4a8c1335ba0869b0d1fcaea1304e128,openstack/bifrost,master,I82dea151e4a8c1335ba0869b0d1fcaea1304e128,Add a dynamic prepare for test role,MERGED,2015-06-15 22:46:37.000000000,2015-06-25 16:27:32.000000000,2015-06-25 16:27:28.000000000,"[{'_account_id': 3}, {'_account_id': 5805}, {'_account_id': 11655}, {'_account_id': 12459}, {'_account_id': 13997}]","[{'number': 1, 'created': '2015-06-15 22:46:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/bifrost/commit/666fead930ac3b4b484d1a6a589d8fdf18078aba', 'message': 'Add a dynamic prepare for test role\n\nThis role adds removes and re-adds hosts for testing and adds\nthe host to a test group.\n\nChange-Id: I82dea151e4a8c1335ba0869b0d1fcaea1304e128\n'}, {'number': 2, 'created': '2015-06-16 06:59:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/bifrost/commit/41497b10d1e9826e4a2f7d42d09fc309567ea276', 'message': 'Add a dynamic prepare for test role\n\nThis role adds removes and re-adds hosts for testing and adds\nthe host to a test group.\n\nChange-Id: I82dea151e4a8c1335ba0869b0d1fcaea1304e128\n'}, {'number': 3, 'created': '2015-06-16 11:58:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/bifrost/commit/0029a97715c4f224adc1ea3f2f249031ca3554f2', 'message': 'Add a dynamic prepare for test role\n\nThis role adds removes and re-adds hosts for testing and adds\nthe host to a test group.\n\nChange-Id: I82dea151e4a8c1335ba0869b0d1fcaea1304e128\n'}, {'number': 4, 'created': '2015-06-17 12:23:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/bifrost/commit/7b5f49dde19ed98fe77d3068a161a06656c26022', 'message': 'Add a dynamic prepare for test role\n\nThis role adds removes and re-adds hosts for testing and adds\nthe host to a test group.\n\nChange-Id: I82dea151e4a8c1335ba0869b0d1fcaea1304e128\n'}, {'number': 5, 'created': '2015-06-24 16:30:46.000000000', 'files': ['playbooks/roles/bifrost-prepare-for-test-dynamic/handlers/main.yml', 'playbooks/roles/bifrost-prepare-for-test-dynamic/README.md', 'playbooks/roles/bifrost-prepare-for-test-dynamic/defaults/main.yml', 'playbooks/roles/bifrost-prepare-for-test-dynamic/tasks/main.yml', 'playbooks/test-bifrost-dynamic.yaml', 'playbooks/roles/bifrost-prepare-for-test-dynamic/meta/main.yml', 'playbooks/roles/bifrost-prepare-for-test-dynamic/vars/main.yml'], 'web_link': 'https://opendev.org/openstack/bifrost/commit/aece574d3f8460873ca9dac1f29744a918ca0481', 'message': 'Add a dynamic prepare for test role\n\nThis role adds removes and re-adds hosts for testing and adds\nthe host to a test group.\n\nChange-Id: I82dea151e4a8c1335ba0869b0d1fcaea1304e128\n'}]",11,192001,aece574d3f8460873ca9dac1f29744a918ca0481,22,5,5,11655,,,0,"Add a dynamic prepare for test role

This role adds removes and re-adds hosts for testing and adds
the host to a test group.

Change-Id: I82dea151e4a8c1335ba0869b0d1fcaea1304e128
",git fetch https://review.opendev.org/openstack/bifrost refs/changes/01/192001/4 && git format-patch -1 --stdout FETCH_HEAD,"['playbooks/roles/bifrost-prepare-for-test-dynamic/handlers/main.yml', 'playbooks/roles/bifrost-prepare-for-test-dynamic/README.md', 'playbooks/roles/bifrost-prepare-for-test-dynamic/defaults/main.yml', 'playbooks/roles/bifrost-prepare-for-test-dynamic/tasks/main.yml', 'playbooks/test-bifrost-dynamic.yaml', 'playbooks/roles/bifrost-prepare-for-test-dynamic/meta/main.yml', 'playbooks/roles/bifrost-prepare-for-test-dynamic/vars/main.yml']",7,666fead930ac3b4b484d1a6a589d8fdf18078aba,feature/dynamic-inventory,--- # vars file for bifrost-prepare-for-test-dynamic ,,207,8
openstack%2Fbifrost~master~Iaabb0a5201ecdbfc3d2c126633f65cb3f70b0fd9,openstack/bifrost,master,Iaabb0a5201ecdbfc3d2c126633f65cb3f70b0fd9,Add the rest of the cookiecutter-generated files for testing,MERGED,2015-06-24 00:46:14.000000000,2015-06-25 16:27:22.000000000,2015-06-25 16:27:17.000000000,"[{'_account_id': 3}, {'_account_id': 5805}, {'_account_id': 8106}, {'_account_id': 11655}, {'_account_id': 12459}]","[{'number': 1, 'created': '2015-06-24 00:46:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/bifrost/commit/3de3bfaf6f3e1bf75269812811004e972364ca19', 'message': 'Add the rest of the cookiecutter-generated files for testing\n\nAdd the rest of the files generated by cookiecutter to the\nrepository with a view towards getting pep8 & docs in the gate\nand also eventual testing of the python code.\n\nChange-Id: Iaabb0a5201ecdbfc3d2c126633f65cb3f70b0fd9\n'}, {'number': 2, 'created': '2015-06-24 05:14:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/bifrost/commit/57544480bffdda0304b63e437e09b66c2ffe0e2c', 'message': 'Add the rest of the cookiecutter-generated files for testing\n\nAdd the rest of the files generated by cookiecutter to the\nrepository with a view towards getting pep8 & docs in the gate\nand also eventual testing of the python code.\n\nChange-Id: Iaabb0a5201ecdbfc3d2c126633f65cb3f70b0fd9\n'}, {'number': 3, 'created': '2015-06-24 23:09:17.000000000', 'files': ['bifrost/tests/base.py', '.testr.conf', 'bifrost/__init__.py', 'bifrost/tests/__init__.py', 'bifrost/tests/test_bifrost.py', 'tox.ini'], 'web_link': 'https://opendev.org/openstack/bifrost/commit/ae4597a239e0590955387517b84a78941ff68382', 'message': 'Add the rest of the cookiecutter-generated files for testing\n\nAdd the rest of the files generated by cookiecutter to the\nrepository with a view towards getting pep8 & docs in the gate\nand also eventual testing of the python code.\n\nChange-Id: Iaabb0a5201ecdbfc3d2c126633f65cb3f70b0fd9\n'}]",0,194893,ae4597a239e0590955387517b84a78941ff68382,17,5,3,12459,,,0,"Add the rest of the cookiecutter-generated files for testing

Add the rest of the files generated by cookiecutter to the
repository with a view towards getting pep8 & docs in the gate
and also eventual testing of the python code.

Change-Id: Iaabb0a5201ecdbfc3d2c126633f65cb3f70b0fd9
",git fetch https://review.opendev.org/openstack/bifrost refs/changes/93/194893/3 && git format-patch -1 --stdout FETCH_HEAD,"['bifrost/tests/base.py', '.testr.conf', 'bifrost/__init__.py', 'bifrost/tests/__init__.py', 'bifrost/tests/test_bifrost.py', 'tox.ini']",6,3de3bfaf6f3e1bf75269812811004e972364ca19,add-to-testing,"envlist = py33,py34,py26,py27,pep8","envlist = docs,pep8",78,1
openstack%2Fbandit~master~I8e48cf40b2ef200b53e259ecf9ae54973b1aa0fb,openstack/bandit,master,I8e48cf40b2ef200b53e259ecf9ae54973b1aa0fb,Actually rely on entry-points for formatters,MERGED,2015-06-25 00:49:02.000000000,2015-06-25 16:25:15.000000000,2015-06-25 16:25:11.000000000,"[{'_account_id': 3}, {'_account_id': 11029}, {'_account_id': 11861}]","[{'number': 1, 'created': '2015-06-25 00:49:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/bandit/commit/f68d9b72b6ba0354e73b207f290fc447b9419e44', 'message': 'Remove unnecessary code that should have been replaced by entry-points\n\nChange-Id: I8e48cf40b2ef200b53e259ecf9ae54973b1aa0fb\n'}, {'number': 2, 'created': '2015-06-25 00:50:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/bandit/commit/d37346fa29a0729b0308e4e4b1cf5595ca830098', 'message': 'Remove unnecessary code that should have been replaced by entry-points\n\nChange-Id: I8e48cf40b2ef200b53e259ecf9ae54973b1aa0fb\n'}, {'number': 3, 'created': '2015-06-25 00:56:44.000000000', 'files': ['bandit/core/result_store.py'], 'web_link': 'https://opendev.org/openstack/bandit/commit/059bd48cfb4c707acff2ebc0fef75caef82718de', 'message': ""Actually rely on entry-points for formatters\n\nThis should have been included in\nI102277dcd9481f2573028a436e910eda10011d91 but somehow the code was\nre-added in a later patchset. The way we picked our formatter function\nprior to this was a bit too clever. Checking if the report_func is\nself._report_text would not work and cause the format to always be 'txt'\neven when an output file was supplied. To reproduce this try the\nfollowing:\n\n    >>> class A(object):\n    ...     def foo(self, bar):\n    ...         pass\n    ...\n    >>> a = A()\n    >>> b = a.foo\n    >>> b is a.foo\n    False\n\nBy properly using our extension manager, we can more simply check the\nname of the formatter used and thus side-step this mess more easily.\n\nCloses-bug: 1468075\nChange-Id: I8e48cf40b2ef200b53e259ecf9ae54973b1aa0fb\n""}]",0,195367,059bd48cfb4c707acff2ebc0fef75caef82718de,10,3,3,12000,,,0,"Actually rely on entry-points for formatters

This should have been included in
I102277dcd9481f2573028a436e910eda10011d91 but somehow the code was
re-added in a later patchset. The way we picked our formatter function
prior to this was a bit too clever. Checking if the report_func is
self._report_text would not work and cause the format to always be 'txt'
even when an output file was supplied. To reproduce this try the
following:

    >>> class A(object):
    ...     def foo(self, bar):
    ...         pass
    ...
    >>> a = A()
    >>> b = a.foo
    >>> b is a.foo
    False

By properly using our extension manager, we can more simply check the
name of the formatter used and thus side-step this mess more easily.

Closes-bug: 1468075
Change-Id: I8e48cf40b2ef200b53e259ecf9ae54973b1aa0fb
",git fetch https://review.opendev.org/openstack/bandit refs/changes/67/195367/1 && git format-patch -1 --stdout FETCH_HEAD,['bandit/core/result_store.py'],1,f68d9b72b6ba0354e73b207f290fc447b9419e44,bug/1468075,"from bandit.core import extension_loader def _write_report(self, files_list, scores, excluded_files): formatters_mgr = extension_loader.MANAGER.formatters_mgr try: formatter = formatters_mgr[self.format] except KeyError: # Unrecognized format, so use text instead formatter = formatters_mgr['txt'] elif formatter.name == 'txt' and self.out_file: report_func = formatter.plugin","from collections import defaultdictimport csv from datetime import datetime import jsonfrom operator import itemgetter import six def _report_xml(self, file_list, scores, excluded_files): '''Prints/returns warnings in XML format (Xunit compatible) :param files_list: Which files were inspected :param scores: The scores awarded to each file in the scope :param excluded_files: Which files were excluded from the scope :return: A collection containing the XML data ''' import xml.etree.cElementTree as ET if self.out_file is None: self.out_file = 'bandit_results.xml' items = self.resstore.items() root = ET.Element('testsuite', name='bandit', tests=str(len(items))) for filename, issues in items: for issue in issues: test = issue['test'] testcase = ET.SubElement(root, 'testcase', classname=filename, name=test) if self._check_severity(issue['issue_severity']): text = 'Severity: %s Confidence: %s\n%s\nLocation %s:%s' text = text % ( issue['issue_severity'], issue['issue_confidence'], issue['issue_text'], issue['fname'], issue['lineno']) ET.SubElement(testcase, 'error', type=issue['issue_severity'], message=issue['issue_text']).text = text tree = ET.ElementTree(root) tree.write(self.out_file, encoding='utf-8', xml_declaration=True) print(""XML output written to file: %s"" % self.out_file) def _report_csv(self, file_list, scores, excluded_files): '''Prints/returns warnings in JSON format :param files_list: Which files were inspected :param scores: The scores awarded to each file in the scope :param excluded_files: Which files were excluded from the scope :return: A collection containing the CSV data ''' results = self._get_issue_list() # Remove the code from all the issues in the list, as we will not # be including it in the CSV data. def del_code(issue): del issue['code'] map(del_code, results) if self.out_file is None: self.out_file = 'bandit_results.csv' with open(self.out_file, 'w') as fout: fieldnames = ['filename', 'test_name', 'issue_severity', 'issue_confidence', 'issue_text', 'line_number', 'line_range'] writer = csv.DictWriter(fout, fieldnames=fieldnames, extrasaction='ignore') writer.writeheader() for result in results: writer.writerow(result) print(""CSV output written to file: %s"" % self.out_file) def _report_json(self, file_list, scores, excluded_files): '''Prints/returns warnings in JSON format :param files_list: Which files were inspected :param scores: The scores awarded to each file in the scope :param excluded_files: Which files were excluded from the scope :return: JSON string ''' stats = dict(zip(file_list, scores)) machine_output = dict({'results': [], 'errors': [], 'stats': []}) collector = list() for (fname, reason) in self.skipped: machine_output['errors'].append({'filename': fname, 'reason': reason}) for filer, score in six.iteritems(stats): totals = {} for i in range(self.level, len(constants.RANKING)): severity = constants.RANKING[i] severity_value = constants.RANKING_VALUES[severity] try: sc = score['SEVERITY'][i] / severity_value except ZeroDivisionError: sc = 0 totals[severity] = sc machine_output['stats'].append({'filename': filer, 'score': self._sum_scores(score), 'issue totals': totals}) collector = self._get_issue_list() if self.agg_type == 'vuln': machine_output['results'] = sorted(collector, key=itemgetter('error_type')) else: machine_output['results'] = sorted(collector, key=itemgetter('filename')) result = json.dumps(machine_output, sort_keys=True, indent=2, separators=(',', ': ')) if self.out_file: with open(self.out_file, 'w') as fout: fout.write(result) # XXX: Should this be log output? (ukbelch) print(""JSON output written to file: %s"" % self.out_file) else: print(result) def _report_text(self, files_list, scores, excluded_files): '''Prints the contents of the result store :param files_list: Which files were inspected :param scores: The scores awarded to each file in the scope :param excluded_files: List of files excluded from the scope :return: TXT string with appropriate TTY coloring for terminals ''' tmpstr_list = [] # use a defaultdict to default to an empty string color = defaultdict(str) if self.format == 'txt': # get text colors from settings for TTY output get_setting = self.config.get_setting color = {'HEADER': get_setting('color_HEADER'), 'DEFAULT': get_setting('color_DEFAULT'), 'LOW': get_setting('color_LOW'), 'MEDIUM': get_setting('color_MEDIUM'), 'HIGH': get_setting('color_HIGH') } # print header tmpstr_list.append(""%sRun started:%s\n\t%s\n"" % ( color['HEADER'], color['DEFAULT'], datetime.utcnow() )) if self.verbose: # print which files were inspected tmpstr_list.append(""\n%sFiles in scope (%s):%s\n"" % ( color['HEADER'], len(files_list), color['DEFAULT'] )) for item in zip(files_list, map(self._sum_scores, scores)): tmpstr_list.append(""\t%s (score: %i)\n"" % item) # print which files were excluded and why tmpstr_list.append(""\n%sFiles excluded (%s):%s\n"" % (color['HEADER'], len(excluded_files), color['DEFAULT'])) for fname in excluded_files: tmpstr_list.append(""\t%s\n"" % fname) # print which files were skipped and why tmpstr_list.append(""\n%sFiles skipped (%s):%s\n"" % ( color['HEADER'], len(self.skipped), color['DEFAULT'] )) for (fname, reason) in self.skipped: tmpstr_list.append(""\t%s (%s)\n"" % (fname, reason)) # print the results tmpstr_list.append(""\n%sTest results:%s\n"" % ( color['HEADER'], color['DEFAULT'] )) if self.count == 0: tmpstr_list.append(""\tNo issues identified.\n"") for filename, issues in self.resstore.items(): for issue in issues: # if the result isn't filtered out by severity if self._check_severity(issue['issue_severity']): tmpstr_list.append(""\n%s>> Issue: %s\n"" % ( color.get(issue['issue_severity'], color['DEFAULT']), issue['issue_text'] )) tmpstr_list.append("" Severity: %s Confidence: %s\n"" % ( issue['issue_severity'].capitalize(), issue['issue_confidence'].capitalize() )) tmpstr_list.append("" Location: %s:%s\n"" % ( issue['fname'], issue['lineno'] )) tmpstr_list.append(color['DEFAULT']) tmpstr_list.append( self._get_code(issue, True)) result = ''.join(tmpstr_list) if self.out_file: with open(self.out_file, 'w') as fout: fout.write(result) self.logger.info(""Text output written to file: %s"", self.out_file) else: print(result) def _write_report(self, files_list, scores, excluded_files): report_name = '_report_{}'.format(self.format) report_func = getattr(self, report_name, self._report_text) elif report_func is self._report_text and self.out_file:",8,230
openstack%2Fsahara~master~I587c416fbaacd36a48d99f9a629e5a213dbfcfe1,openstack/sahara,master,I587c416fbaacd36a48d99f9a629e5a213dbfcfe1,Fixed bug with volume type validation,MERGED,2015-05-13 15:40:34.000000000,2015-06-25 16:22:54.000000000,2015-05-15 08:59:13.000000000,"[{'_account_id': 3}, {'_account_id': 6116}, {'_account_id': 6786}, {'_account_id': 7213}, {'_account_id': 7710}, {'_account_id': 8411}, {'_account_id': 12038}, {'_account_id': 13953}]","[{'number': 1, 'created': '2015-05-13 15:40:34.000000000', 'files': ['sahara/service/validations/base.py'], 'web_link': 'https://opendev.org/openstack/sahara/commit/33874f03315f40ad8fe7889d552527a51cc7fcdd', 'message': 'Fixed bug with volume type validation\n\ncheck_volume_type_exists method in service.validations.base\nraised error even if volume type was valid.\n\nChange-Id: I587c416fbaacd36a48d99f9a629e5a213dbfcfe1\nCloses-bug: #1454753\n'}]",0,182726,33874f03315f40ad8fe7889d552527a51cc7fcdd,18,8,1,12039,,,0,"Fixed bug with volume type validation

check_volume_type_exists method in service.validations.base
raised error even if volume type was valid.

Change-Id: I587c416fbaacd36a48d99f9a629e5a213dbfcfe1
Closes-bug: #1454753
",git fetch https://review.opendev.org/openstack/sahara refs/changes/26/182726/1 && git format-patch -1 --stdout FETCH_HEAD,['sahara/service/validations/base.py'],1,33874f03315f40ad8fe7889d552527a51cc7fcdd,bug/1454753, if len(volume_types) == 1 and volume_types[0].name == volume_type:, if len(volume_types) == 1 and volume_types[0] == volume_type:,1,1
openstack%2Ffreezer~master~I2161ba429540e1be14d0914fca2a336c2db7b659,openstack/freezer,master,I2161ba429540e1be14d0914fca2a336c2db7b659,correct error message when backup path or file that does not exist,MERGED,2015-06-24 09:45:47.000000000,2015-06-25 16:19:56.000000000,2015-06-25 16:19:52.000000000,"[{'_account_id': 3}, {'_account_id': 12211}, {'_account_id': 14159}]","[{'number': 1, 'created': '2015-06-24 09:45:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/freezer/commit/7756375e775ce4bc537044d7ab980100eae58b61', 'message': 'correct error message when you try to backup path or file that does not exist\n\nChange-Id: I2161ba429540e1be14d0914fca2a336c2db7b659\nPartial-Bug: #1425591\n'}, {'number': 2, 'created': '2015-06-24 09:47:01.000000000', 'files': ['tests/commons.py', 'freezer/tar.py', 'tests/test_tar.py'], 'web_link': 'https://opendev.org/openstack/freezer/commit/24619b7b181913e267dd6b248a7ae54b20790b5f', 'message': 'correct error message when backup path or file that does not exist\n\nPartial-Bug: #1425591\n\nChange-Id: I2161ba429540e1be14d0914fca2a336c2db7b659\n'}]",0,195013,24619b7b181913e267dd6b248a7ae54b20790b5f,8,3,2,14030,,,0,"correct error message when backup path or file that does not exist

Partial-Bug: #1425591

Change-Id: I2161ba429540e1be14d0914fca2a336c2db7b659
",git fetch https://review.opendev.org/openstack/freezer refs/changes/13/195013/1 && git format-patch -1 --stdout FETCH_HEAD,"['freezer/tar.py', 'tests/commons.py', 'tests/test_tar.py']",3,7756375e775ce4bc537044d7ab980100eae58b61,bug/1425591," expanduser = Os() monkeypatch.setattr(os.path, 'exists', expanduser.notexists) with pytest.raises(Exception) as excinfo : gen_tar_command(backup_opt, meta_data_backup_file, time_stamp, remote_manifest_meta) assert excinfo.value.message == 'Error: path-to-backup does not exist' monkeypatch.setattr(os.path, 'exists', expanduser.exists) with pytest.raises(Exception) as excinfo : gen_tar_command(backup_opt, meta_data_backup_file, time_stamp, remote_manifest_meta) assert excinfo.value.message == ('Error: Please ALL the ' 'following options: ' '--path-to-backup, --backup-name')"," pytest.raises(Exception, gen_tar_command, backup_opt, meta_data_backup_file, time_stamp, remote_manifest_meta)",23,6
openstack%2Fpuppet-openstack_extras~master~I772d9929bcc379a7d1515a7a76658811720897dd,openstack/puppet-openstack_extras,master,I772d9929bcc379a7d1515a7a76658811720897dd,repo/apt: update to support apt 2.1.0 module,MERGED,2015-06-25 14:38:40.000000000,2015-06-25 16:19:36.000000000,2015-06-25 16:19:33.000000000,"[{'_account_id': 3}, {'_account_id': 7155}, {'_account_id': 8482}]","[{'number': 1, 'created': '2015-06-25 14:38:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-openstack_extras/commit/134bb124e26054fcd9e4b0384401afc9d446078f', 'message': ""repo/apt: update to support apt 2.1.0 module\n\n* Drop 'required_packages' deprecated parameter\n* Install UCA keyring package *before* adding the new repo and run\n  apt-get update\n* For backward compatibility when package_require is True, make sure to\n  not run `apt-get update` before the Package resource when manage_uca\n  is True; because it would lead to a Circular issue.\n\nChange-Id: I772d9929bcc379a7d1515a7a76658811720897dd\nCloses-bug: #1468761\n""}, {'number': 2, 'created': '2015-06-25 14:46:45.000000000', 'files': ['spec/classes/openstack_extras_repo_debian_debian_spec.rb', 'spec/classes/openstack_extras_repo_debian_ubuntu_spec.rb', 'manifests/repo/debian/ubuntu.pp', 'manifests/repo/debian/debian.pp'], 'web_link': 'https://opendev.org/openstack/puppet-openstack_extras/commit/6feda8b3e978a3b588d9f84d3e3776f0993c2623', 'message': ""repo/apt: update to support apt 2.1.0 module\n\nThis patcha affects how we use puppetlabs-apt on Debian & Ubuntu\nsystems.\n\nIt:\n* Drops 'required_packages' deprecated parameter\n* Installs UCA keyring package *before* adding the new repo and run\n  apt-get update\n* For backward compatibility when package_require is True, make sure to\n  not run `apt-get update` before the Package resource when manage_uca\n  is True; because it would lead to a Circular issue.\n\nChange-Id: I772d9929bcc379a7d1515a7a76658811720897dd\nCloses-bug: #1468761\n""}]",0,195611,6feda8b3e978a3b588d9f84d3e3776f0993c2623,8,3,2,3153,,,0,"repo/apt: update to support apt 2.1.0 module

This patcha affects how we use puppetlabs-apt on Debian & Ubuntu
systems.

It:
* Drops 'required_packages' deprecated parameter
* Installs UCA keyring package *before* adding the new repo and run
  apt-get update
* For backward compatibility when package_require is True, make sure to
  not run `apt-get update` before the Package resource when manage_uca
  is True; because it would lead to a Circular issue.

Change-Id: I772d9929bcc379a7d1515a7a76658811720897dd
Closes-bug: #1468761
",git fetch https://review.opendev.org/openstack/puppet-openstack_extras refs/changes/11/195611/2 && git format-patch -1 --stdout FETCH_HEAD,"['spec/classes/openstack_extras_repo_debian_ubuntu_spec.rb', 'manifests/repo/debian/ubuntu.pp']",2,134bb124e26054fcd9e4b0384401afc9d446078f,bug/1468761," package { 'ubuntu-cloud-keyring': ensure => 'present', name => $::openstack_extras::repo::debian::params::uca_required_packages, } apt::source { $::openstack_extras::repo::debian::params::uca_name: location => $::openstack_extras::repo::debian::params::uca_location, release => ""${::lsbdistcodename}-updates/${release}"", repos => $::openstack_extras::repo::debian::params::uca_repos, } Package[$::openstack_extras::repo::debian::params::uca_required_packages] -> Apt::Source[$::openstack_extras::repo::debian::params::uca_name] if $package_require and ! $manage_uca {"," apt::source { $::openstack_extras::repo::debian::params::uca_name: location => $::openstack_extras::repo::debian::params::uca_location, release => ""${::lsbdistcodename}-updates/${release}"", repos => $::openstack_extras::repo::debian::params::uca_repos, required_packages => $::openstack_extras::repo::debian::params::uca_required_packages } if $package_require {",22,9
openstack%2Fopenstackdocstheme~master~I8fa4d32a167aa7f5d773abc4bdb6e176e12d5d82,openstack/openstackdocstheme,master,I8fa4d32a167aa7f5d773abc4bdb6e176e12d5d82,Next release is 1.1.0,MERGED,2015-06-25 15:01:28.000000000,2015-06-25 16:19:10.000000000,2015-06-25 16:19:10.000000000,"[{'_account_id': 3}, {'_account_id': 6547}]","[{'number': 1, 'created': '2015-06-25 15:01:28.000000000', 'files': ['RELEASENOTES.rst'], 'web_link': 'https://opendev.org/openstack/openstackdocstheme/commit/9587cc5fbbe1d56ec5e1abf2f29dbfc759caba0a', 'message': 'Next release is 1.1.0\n\nadjust release note version number.\n\nChange-Id: I8fa4d32a167aa7f5d773abc4bdb6e176e12d5d82\n'}]",0,195620,9587cc5fbbe1d56ec5e1abf2f29dbfc759caba0a,6,2,1,6547,,,0,"Next release is 1.1.0

adjust release note version number.

Change-Id: I8fa4d32a167aa7f5d773abc4bdb6e176e12d5d82
",git fetch https://review.opendev.org/openstack/openstackdocstheme refs/changes/20/195620/1 && git format-patch -1 --stdout FETCH_HEAD,['RELEASENOTES.rst'],1,9587cc5fbbe1d56ec5e1abf2f29dbfc759caba0a,1_10,1.1.0,1.0.9,1,1
openstack%2Fneutron~master~I8c6a08e0cf3b5b5386fe03af9f2174c666b8ac75,openstack/neutron,master,I8c6a08e0cf3b5b5386fe03af9f2174c666b8ac75,Provide work around for 0.0.0.0/0 ::/0 for ipset,MERGED,2015-06-23 15:00:36.000000000,2015-06-25 16:09:50.000000000,2015-06-25 00:13:32.000000000,"[{'_account_id': 3}, {'_account_id': 1131}, {'_account_id': 2592}, {'_account_id': 4395}, {'_account_id': 5170}, {'_account_id': 7016}, {'_account_id': 7787}, {'_account_id': 8124}, {'_account_id': 9681}, {'_account_id': 9682}, {'_account_id': 9787}, {'_account_id': 9845}, {'_account_id': 10121}, {'_account_id': 10153}, {'_account_id': 10184}, {'_account_id': 10387}, {'_account_id': 10692}, {'_account_id': 14323}, {'_account_id': 14571}]","[{'number': 1, 'created': '2015-06-23 15:00:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/07b32d80a521f97bbb3dc60e07a460c27c68d415', 'message': ""Provide work around for 0.0.0.0/0 ::/0 for ipset\n\nPreviously, the ipset_manager would pass in 0.0.0.0/0 or ::/0 if\nthese addresses were inputted as allowed address pairs. This causes\nipset to raise an error as it does not work with zero prefix sizes.\nTo solve this problem we use two ipset rules to represent this:\n\nIpv4: 0.0.0.0/1 and 128.0.0.1/1\nIPv6: ::/1' and '8000::/1\n\nAll of this logic is handled via _sanitize_addresses() in the ipset_manager\nwhich is called to convert the input.\n\nChange-Id: I8c6a08e0cf3b5b5386fe03af9f2174c666b8ac75\nCloses-bug: 1461054\n""}, {'number': 2, 'created': '2015-06-24 17:30:32.000000000', 'files': ['neutron/tests/unit/agent/linux/test_ipset_manager.py', 'neutron/agent/linux/ipset_manager.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/d9a23f882f0d78aaca34c3607d9ca9ad54ac063b', 'message': ""Provide work around for 0.0.0.0/0 ::/0 for ipset\n\nPreviously, the ipset_manager would pass in 0.0.0.0/0 or ::/0 if\nthese addresses were inputted as allowed address pairs. This causes\nipset to raise an error as it does not work with zero prefix sizes.\nTo solve this problem we use two ipset rules to represent this:\n\nIpv4: 0.0.0.0/1 and 128.0.0.1/1\nIPv6: ::/1' and '8000::/1\n\nAll of this logic is handled via _sanitize_addresses() in the ipset_manager\nwhich is called to convert the input.\n\nChange-Id: I8c6a08e0cf3b5b5386fe03af9f2174c666b8ac75\nCloses-bug: 1461054\n""}]",3,194695,d9a23f882f0d78aaca34c3607d9ca9ad54ac063b,41,19,2,9311,,,0,"Provide work around for 0.0.0.0/0 ::/0 for ipset

Previously, the ipset_manager would pass in 0.0.0.0/0 or ::/0 if
these addresses were inputted as allowed address pairs. This causes
ipset to raise an error as it does not work with zero prefix sizes.
To solve this problem we use two ipset rules to represent this:

Ipv4: 0.0.0.0/1 and 128.0.0.1/1
IPv6: ::/1' and '8000::/1

All of this logic is handled via _sanitize_addresses() in the ipset_manager
which is called to convert the input.

Change-Id: I8c6a08e0cf3b5b5386fe03af9f2174c666b8ac75
Closes-bug: 1461054
",git fetch https://review.opendev.org/openstack/neutron refs/changes/95/194695/2 && git format-patch -1 --stdout FETCH_HEAD,"['neutron/tests/unit/agent/linux/test_ipset_manager.py', 'neutron/agent/linux/ipset_manager.py']",2,07b32d80a521f97bbb3dc60e07a460c27c68d415,bug/1461054,"import netaddr def _sanitize_addresses(self, addresses): """"""This method converts any address to ipset format. If an address has a mask of /0 we need to cover to it to a mask of /1 as ipset does not support /0 length addresses. Instead we use two /1's to represent the /0. """""" sanitized_addresses = [] for ip in addresses: if (netaddr.IPNetwork(ip).prefixlen == 0): if(netaddr.IPNetwork(ip).version == 4): sanitized_addresses.append('0.0.0.0/1') sanitized_addresses.append('128.0.0.0/1') elif (netaddr.IPNetwork(ip).version == 6): sanitized_addresses.append('::/1') sanitized_addresses.append('8000::/1') else: sanitized_addresses.append(ip) return sanitized_addresses member_ips = self._sanitize_addresses(member_ips)",,39,3
openstack%2Fpuppet-tripleo~master~I7199c7e5d759a76f58c0f48b40e9d460a3163886,openstack/puppet-tripleo,master,I7199c7e5d759a76f58c0f48b40e9d460a3163886,Introduce param to enable use of clustercheck,MERGED,2015-06-24 06:56:43.000000000,2015-06-25 16:06:11.000000000,2015-06-25 16:06:08.000000000,"[{'_account_id': 3}, {'_account_id': 3153}, {'_account_id': 4328}, {'_account_id': 6796}, {'_account_id': 7582}, {'_account_id': 8399}, {'_account_id': 8449}, {'_account_id': 9410}]","[{'number': 1, 'created': '2015-06-24 06:56:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-tripleo/commit/8c09c592911a45919ac4e8a9e6e3e0baf9e74b05', 'message': 'Use clustercheck to manage galera nodes membership\n\nChange-Id: I7199c7e5d759a76f58c0f48b40e9d460a3163886\nPartial-Bug: 1456701\n'}, {'number': 2, 'created': '2015-06-24 16:33:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-tripleo/commit/42986a6d9643df80c0fc346157f537d0c9cfc1bd', 'message': 'Use clustercheck to manage galera nodes membership in haproxy\n\nChange-Id: I7199c7e5d759a76f58c0f48b40e9d460a3163886\nPartial-Bug: 1456701\n'}, {'number': 3, 'created': '2015-06-24 18:15:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-tripleo/commit/e88d001ff58421dddce074bbb3030034f440a77d', 'message': 'Use clustercheck to manage galera nodes membership in haproxy\n\nChange-Id: I7199c7e5d759a76f58c0f48b40e9d460a3163886\nCloses-Bug: 1456701\n'}, {'number': 4, 'created': '2015-06-25 00:35:01.000000000', 'files': ['manifests/loadbalancer.pp'], 'web_link': 'https://opendev.org/openstack/puppet-tripleo/commit/ce548df370f06b0a74fe1f13f3e1b9af3818c6b2', 'message': 'Introduce param to enable use of clustercheck\n\nIn the pacemaker scenario we want to use the clustercheck script\nto evict galera nodes which are out of sync. This change adds a\nparameter meant to enable use of clustercheck for the mysql service.\n\nChange-Id: I7199c7e5d759a76f58c0f48b40e9d460a3163886\nCloses-Bug: 1456701\n'}]",0,194960,ce548df370f06b0a74fe1f13f3e1b9af3818c6b2,30,8,4,6796,,,0,"Introduce param to enable use of clustercheck

In the pacemaker scenario we want to use the clustercheck script
to evict galera nodes which are out of sync. This change adds a
parameter meant to enable use of clustercheck for the mysql service.

Change-Id: I7199c7e5d759a76f58c0f48b40e9d460a3163886
Closes-Bug: 1456701
",git fetch https://review.opendev.org/openstack/puppet-tripleo refs/changes/60/194960/4 && git format-patch -1 --stdout FETCH_HEAD,['manifests/loadbalancer.pp'],1,8c09c592911a45919ac4e8a9e6e3e0baf9e74b05,bug/1456701," options => ['check', 'port 9200', 'on-marked-down shutdown-sessions', 'inter 2000', 'rise 2', 'fall 5', 'backup'],"," options => ['check', 'inter 2000', 'rise 2', 'fall 5', 'backup'],",1,1
openstack%2Fcookbook-openstack-compute~master~I9dd7cdb6d444aaa9ba4f41db75b27655fb6ceb69,openstack/cookbook-openstack-compute,master,I9dd7cdb6d444aaa9ba4f41db75b27655fb6ceb69,Bump the retries for nova common package install,ABANDONED,2015-06-04 14:22:56.000000000,2015-06-25 16:04:22.000000000,,"[{'_account_id': 3}, {'_account_id': 7128}, {'_account_id': 8112}]","[{'number': 1, 'created': '2015-06-04 14:22:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cookbook-openstack-compute/commit/4f6138f15c38a331ecb7422468ce1c97875ab9e8', 'message': 'Bump the retries for nova common package install\n\nThe nova common package brings in many (100+) dependency\npackages and on some converges with a slower local disk\nenvironment the resource hits the 900 second timeout.\nBumping up the retries from zero to 3 should solve this\nissue for any case.\n\nChange-Id: I9dd7cdb6d444aaa9ba4f41db75b27655fb6ceb69\n'}, {'number': 2, 'created': '2015-06-08 01:59:36.000000000', 'files': ['spec/nova-common-redhat_spec.rb', 'spec/nova-common_spec.rb', 'recipes/nova-common.rb'], 'web_link': 'https://opendev.org/openstack/cookbook-openstack-compute/commit/604f6847e6af61c9629c6ea8054eab780a23cc51', 'message': 'Bump the retries for nova common package install\n\nThe nova common package brings in many (100+) dependency\npackages and on some converges with a slower local disk\nenvironment the resource hits the 900 second timeout.\nBumping up the retries from zero to 3 should solve this\nissue for any case.\n\nChange-Id: I9dd7cdb6d444aaa9ba4f41db75b27655fb6ceb69\n'}]",0,188416,604f6847e6af61c9629c6ea8054eab780a23cc51,10,3,2,7128,,,0,"Bump the retries for nova common package install

The nova common package brings in many (100+) dependency
packages and on some converges with a slower local disk
environment the resource hits the 900 second timeout.
Bumping up the retries from zero to 3 should solve this
issue for any case.

Change-Id: I9dd7cdb6d444aaa9ba4f41db75b27655fb6ceb69
",git fetch https://review.opendev.org/openstack/cookbook-openstack-compute refs/changes/16/188416/1 && git format-patch -1 --stdout FETCH_HEAD,"['spec/nova-common-redhat_spec.rb', 'spec/nova-common_spec.rb', 'recipes/nova-common.rb']",3,4f6138f15c38a331ecb7422468ce1c97875ab9e8,bug-1461974-package-retries, retries 3,,7,2
openstack%2Ffuel-library~master~Ie5728806a22c1022ac13091223475bd3c3d44c25,openstack/fuel-library,master,Ie5728806a22c1022ac13091223475bd3c3d44c25,"Revert ""Fix the problem with ceph deployment on scale lab""",MERGED,2015-06-25 09:11:33.000000000,2015-06-25 15:58:59.000000000,2015-06-25 15:58:05.000000000,"[{'_account_id': 3}, {'_account_id': 6926}, {'_account_id': 7468}, {'_account_id': 8786}, {'_account_id': 8787}, {'_account_id': 8971}, {'_account_id': 9037}, {'_account_id': 9387}, {'_account_id': 9546}, {'_account_id': 11090}, {'_account_id': 11827}, {'_account_id': 13343}, {'_account_id': 13344}, {'_account_id': 13948}, {'_account_id': 14774}]","[{'number': 1, 'created': '2015-06-25 09:11:33.000000000', 'files': ['deployment/puppet/ceph/manifests/init.pp', 'deployment/puppet/osnailyfacter/modular/ceph/compute.pp', 'deployment/puppet/osnailyfacter/modular/ceph/tasks.yaml', 'deployment/puppet/osnailyfacter/modular/astute/tasks.yaml', 'tests/noop/spec/hosts/ceph/compute_spec.rb', 'deployment/puppet/osnailyfacter/modular/astute/ceph_pools.pp', 'tests/noop/spec/hosts/astute/ceph_compute_spec.rb', 'deployment/puppet/osnailyfacter/modular/ceph/compute_post.rb'], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/b331e0cf9cff85bbf38092feb29efcd0f5b9daf0', 'message': 'Revert ""Fix the problem with ceph deployment on scale lab""\n\nThis reverts commit 0b0d8d8b1182c97276a32d0fb80d2f382ed79a78.\n\nChange-Id: Ie5728806a22c1022ac13091223475bd3c3d44c25\n'}]",0,195466,b331e0cf9cff85bbf38092feb29efcd0f5b9daf0,22,15,1,13343,,,0,"Revert ""Fix the problem with ceph deployment on scale lab""

This reverts commit 0b0d8d8b1182c97276a32d0fb80d2f382ed79a78.

Change-Id: Ie5728806a22c1022ac13091223475bd3c3d44c25
",git fetch https://review.opendev.org/openstack/fuel-library refs/changes/66/195466/1 && git format-patch -1 --stdout FETCH_HEAD,"['deployment/puppet/ceph/manifests/init.pp', 'deployment/puppet/osnailyfacter/modular/ceph/compute.pp', 'deployment/puppet/osnailyfacter/modular/ceph/tasks.yaml', 'deployment/puppet/osnailyfacter/modular/astute/tasks.yaml', 'tests/noop/spec/hosts/ceph/compute_spec.rb', 'deployment/puppet/osnailyfacter/modular/astute/ceph_pools.pp', 'tests/noop/spec/hosts/astute/ceph_compute_spec.rb', 'deployment/puppet/osnailyfacter/modular/ceph/compute_post.rb']",8,b331e0cf9cff85bbf38092feb29efcd0f5b9daf0,revert,,,55,146
openstack%2Fopenstack-manuals~master~I5eeda3b83c35ac199c5fbeeaa70c33f8a3dfd5dd,openstack/openstack-manuals,master,I5eeda3b83c35ac199c5fbeeaa70c33f8a3dfd5dd,Fixed typo in example script,MERGED,2015-06-25 12:16:14.000000000,2015-06-25 15:55:37.000000000,2015-06-25 15:55:26.000000000,"[{'_account_id': 3}, {'_account_id': 612}, {'_account_id': 10497}, {'_account_id': 14947}, {'_account_id': 14962}]","[{'number': 1, 'created': '2015-06-25 12:16:14.000000000', 'files': ['doc/user-guide-admin/source/cli_nova_migrate.rst'], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/b619242c9f1b298569afe0f6c2c2413476864791', 'message': 'Fixed typo in example script\n\nChange-Id: I5eeda3b83c35ac199c5fbeeaa70c33f8a3dfd5dd\nCloses-bug: #1468528\n'}]",0,195549,b619242c9f1b298569afe0f6c2c2413476864791,9,5,1,15299,,,0,"Fixed typo in example script

Change-Id: I5eeda3b83c35ac199c5fbeeaa70c33f8a3dfd5dd
Closes-bug: #1468528
",git fetch https://review.opendev.org/openstack/openstack-manuals refs/changes/49/195549/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/user-guide-admin/source/cli_nova_migrate.rst'],1,b619242c9f1b298569afe0f6c2c2413476864791,1468528, VM_ID=$1, $VM_ID=$1,1,1
openstack%2Ffuel-library~master~Ib44cf45fb90dca1c8512048d89ceba2b2d47c35b,openstack/fuel-library,master,Ib44cf45fb90dca1c8512048d89ceba2b2d47c35b,"Revert ""Fix the problem with ceph deployment on scale lab""",ABANDONED,2015-06-18 10:55:42.000000000,2015-06-25 15:55:06.000000000,,"[{'_account_id': 3}, {'_account_id': 6926}, {'_account_id': 8787}, {'_account_id': 8829}, {'_account_id': 8971}, {'_account_id': 14774}]","[{'number': 1, 'created': '2015-06-18 10:55:42.000000000', 'files': ['deployment/puppet/ceph/manifests/init.pp', 'deployment/puppet/osnailyfacter/modular/ceph/compute.pp', 'deployment/puppet/osnailyfacter/modular/ceph/tasks.yaml', 'deployment/puppet/osnailyfacter/modular/astute/tasks.yaml', 'tests/noop/spec/hosts/ceph/compute_spec.rb', 'deployment/puppet/osnailyfacter/modular/astute/ceph_pools.pp', 'tests/noop/spec/hosts/astute/ceph_compute_spec.rb', 'deployment/puppet/osnailyfacter/modular/ceph/compute_post.rb'], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/6ab5e33c2acc6f7ec85eb36a043bac28ff53c7be', 'message': 'Revert ""Fix the problem with ceph deployment on scale lab""\n\nThis reverts commit 43b25e4b200c5b994cde81439454d6e2e908a88f.\n\nCloses-bug: #1466075\n\nChange-Id: Ib44cf45fb90dca1c8512048d89ceba2b2d47c35b\n'}]",0,193065,6ab5e33c2acc6f7ec85eb36a043bac28ff53c7be,16,6,1,8786,,,0,"Revert ""Fix the problem with ceph deployment on scale lab""

This reverts commit 43b25e4b200c5b994cde81439454d6e2e908a88f.

Closes-bug: #1466075

Change-Id: Ib44cf45fb90dca1c8512048d89ceba2b2d47c35b
",git fetch https://review.opendev.org/openstack/fuel-library refs/changes/65/193065/1 && git format-patch -1 --stdout FETCH_HEAD,"['deployment/puppet/ceph/manifests/init.pp', 'deployment/puppet/osnailyfacter/modular/ceph/compute.pp', 'deployment/puppet/osnailyfacter/modular/ceph/tasks.yaml', 'deployment/puppet/osnailyfacter/modular/astute/tasks.yaml', 'tests/noop/spec/hosts/ceph/compute_spec.rb', 'deployment/puppet/osnailyfacter/modular/astute/ceph_pools.pp', 'tests/noop/spec/hosts/astute/ceph_compute_spec.rb', 'deployment/puppet/osnailyfacter/modular/ceph/compute_post.rb']",8,6ab5e33c2acc6f7ec85eb36a043bac28ff53c7be,,,,55,146
openstack%2Fpuppet-trove~master~Id27fd3637b59bf51d7b06b5065c597421dab513f,openstack/puppet-trove,master,Id27fd3637b59bf51d7b06b5065c597421dab513f,lint: Fix lint issues (missing documentation for define types),MERGED,2015-06-25 09:41:31.000000000,2015-06-25 15:49:29.000000000,2015-06-25 15:49:27.000000000,"[{'_account_id': 3}, {'_account_id': 1607}, {'_account_id': 3153}, {'_account_id': 9410}]","[{'number': 1, 'created': '2015-06-25 09:41:31.000000000', 'files': ['manifests/generic_service.pp'], 'web_link': 'https://opendev.org/openstack/puppet-trove/commit/51d4624f36016148c650081780f837e5720fad2b', 'message': ""lint: Fix lint issues (missing documentation for define types)\n\nThe gem 'puppet-lint-param-docs' was bumped to 1.2.0 and now handle\nclass and define type. This patch fix lint issues (missing documentation).\n\nChange-Id: Id27fd3637b59bf51d7b06b5065c597421dab513f\n""}]",0,195484,51d4624f36016148c650081780f837e5720fad2b,8,4,1,7155,,,0,"lint: Fix lint issues (missing documentation for define types)

The gem 'puppet-lint-param-docs' was bumped to 1.2.0 and now handle
class and define type. This patch fix lint issues (missing documentation).

Change-Id: Id27fd3637b59bf51d7b06b5065c597421dab513f
",git fetch https://review.opendev.org/openstack/puppet-trove refs/changes/84/195484/1 && git format-patch -1 --stdout FETCH_HEAD,['manifests/generic_service.pp'],1,51d4624f36016148c650081780f837e5720fad2b,lint,# === Parameters: # # [*package_name*] # (mandatory) The package name (for the generic_service) # # [*service_name*] # (mandatory) The service name (for the generic_service) # # [*enabled*] # (optional) Define if the service must be enabled or not # Defaults to false. # # [*manage_service*] # (optional) Manage or not the service (if a service_name is provided). # Defaults to true. # # [*ensure_package*] # (optional) Control the ensure parameter for the package ressource. # Defaults to 'present'. #,,20,0
openstack%2Fopenstack-ansible~master~I1037a7fce567e476f07a5d3c220379d656248160,openstack/openstack-ansible,master,I1037a7fce567e476f07a5d3c220379d656248160,Updated keystone to use fernet as the default,MERGED,2015-06-19 21:26:17.000000000,2015-06-25 15:35:45.000000000,2015-06-25 15:35:40.000000000,"[{'_account_id': 3}, {'_account_id': 4}, {'_account_id': 5046}, {'_account_id': 6816}, {'_account_id': 7353}, {'_account_id': 7725}, {'_account_id': 12000}]","[{'number': 1, 'created': '2015-06-19 21:26:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/16695f8b4a7687dc8f21006824a93d56d8a4e560', 'message': 'Updated keystone to use fernet as the default\n\nThis change simply enables fernet to be the default token backend and disables\nthe keystone memcached configuration for token storage.\n\nChange-Id: I1037a7fce567e476f07a5d3c220379d656248160\nRelated-Bug: #1463569\n'}, {'number': 2, 'created': '2015-06-19 23:16:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/91398afc34402fabf483100df12571cbc0b5196b', 'message': 'Updated keystone to use fernet as the default\n\nThis change simply enables fernet to be the default token backend and disables\nthe keystone memcached configuration for token storage.\n\nChange-Id: I1037a7fce567e476f07a5d3c220379d656248160\nRelated-Bug: #1463569\n'}, {'number': 3, 'created': '2015-06-20 22:32:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/167bcbb6672b7fd056a872de420ec448e55ff460', 'message': 'Updated keystone to use fernet as the default\n\nThis change simply enables fernet to be the default token backend and disables\nthe keystone memcached configuration for token storage.\n\nChange-Id: I1037a7fce567e476f07a5d3c220379d656248160\nRelated-Bug: #1463569\n'}, {'number': 4, 'created': '2015-06-21 00:52:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/a580549e279edcc8061b74ea04478a9932d01b3f', 'message': 'Updated keystone to use fernet as the default\n\nThis change simply enables fernet to be the default token backend and disables\nthe keystone memcached configuration for token storage.\n\nChange-Id: I1037a7fce567e476f07a5d3c220379d656248160\nRelated-Bug: #1463569\n'}, {'number': 5, 'created': '2015-06-21 02:01:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/c94cb0dbcb21ee74591b44bcfc6461cd7ee30f75', 'message': '[WIP] Updated keystone to use fernet as the default\n\nThis change simply enables fernet to be the default token backend and disables\nthe keystone memcached configuration for token storage.\n\nChange-Id: I1037a7fce567e476f07a5d3c220379d656248160\nRelated-Bug: #1463569\n'}, {'number': 6, 'created': '2015-06-22 13:55:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/030751773e0972573a3333be3287078609ca0837', 'message': '[WIP] Updated keystone to use fernet as the default\n\nThis change simply enables fernet to be the default token backend and disables\nthe keystone memcached configuration for token storage.\n\nChange-Id: I1037a7fce567e476f07a5d3c220379d656248160\nRelated-Bug: #1463569\n'}, {'number': 7, 'created': '2015-06-22 15:37:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/a735139c3883a581e92e09e3b6a692fcabd9fa6f', 'message': '[WIP] Updated keystone to use fernet as the default\n\nThis change simply enables fernet to be the default token backend and disables\nthe keystone memcached configuration for token storage.\n\nChange-Id: I1037a7fce567e476f07a5d3c220379d656248160\nRelated-Bug: #1463569\n'}, {'number': 8, 'created': '2015-06-22 17:03:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/39180305ad0c0c6b1981011b574848e4d948f779', 'message': '[WIP] Updated keystone to use fernet as the default\n\nThis change simply enables fernet to be the default token backend\nand disables the keystone memcached configuration for token storage.\n\nChange-Id: I1037a7fce567e476f07a5d3c220379d656248160\nRelated-Bug: #1463569\n'}, {'number': 9, 'created': '2015-06-22 20:10:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/74e9970526015d2d59dea191f77ac6de4eaa4a9c', 'message': '[WIP] Updated keystone to use fernet as the default\n\nThis change simply enables fernet to be the default token backend\nand disables the keystone memcached configuration for token storage.\n\nChange-Id: I1037a7fce567e476f07a5d3c220379d656248160\nRelated-Bug: #1463569\n'}, {'number': 10, 'created': '2015-06-22 20:35:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/5c239b0affcb600fb0be7fed9f00e1fa3a7452be', 'message': '[WIP] Updated keystone to use fernet as the default\n\nThis change simply enables fernet to be the default token backend\nand disables the keystone memcached configuration for token storage.\n\nChange-Id: I1037a7fce567e476f07a5d3c220379d656248160\nRelated-Bug: #1463569\n'}, {'number': 11, 'created': '2015-06-23 21:59:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/53bc94fac750970cd0346ce315f874c18a3d74b2', 'message': '[WIP] Updated keystone to use fernet as the default\n\nThis change simply enables fernet to be the default token backend\nand disables the keystone memcached configuration for token storage.\n\nChange-Id: I1037a7fce567e476f07a5d3c220379d656248160\nRelated-Bug: #1463569\n'}, {'number': 12, 'created': '2015-06-24 01:29:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/ed4e38eec9d48c4863717118afde494c16408337', 'message': 'Updated keystone to use fernet as the default\n\nThis change simply enables fernet to be the default token backend\nand disables the keystone memcached configuration for token storage.\n\nChange-Id: I1037a7fce567e476f07a5d3c220379d656248160\nRelated-Bug: #1463569\n'}, {'number': 13, 'created': '2015-06-24 14:34:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/200a1e81fd464ac17b47505c7b66b0a6fe59fe1c', 'message': 'Updated keystone to use fernet as the default\n\nThis change simply enables fernet to be the default token backend\nand disables the keystone memcached configuration for token storage.\n\nChange-Id: I1037a7fce567e476f07a5d3c220379d656248160\nRelated-Bug: #1463569\n'}, {'number': 14, 'created': '2015-06-24 15:50:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/cce191177b65cb6feadf20e70bfb89926eefc7fe', 'message': 'Updated keystone to use fernet as the default\n\nThis change simply enables fernet to be the default token backend\nand disables the keystone memcached configuration for token storage.\n\nChange-Id: I1037a7fce567e476f07a5d3c220379d656248160\nRelated-Bug: #1463569\n'}, {'number': 15, 'created': '2015-06-24 23:29:57.000000000', 'files': ['playbooks/roles/os_keystone/tasks/keystone_fernet_keys_create.yml', 'playbooks/roles/os_keystone/meta/main.yml', 'playbooks/roles/os_keystone/templates/keystone.conf.j2', 'playbooks/roles/os_keystone/tasks/keystone_fernet_cleanup.yml', 'playbooks/roles/os_keystone/defaults/main.yml'], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/4798dab6a232e8bd2ce9635c57b4bfd0f2351a57', 'message': 'Updated keystone to use fernet as the default\n\nThis change simply enables fernet to be the default token backend\nand disables the keystone memcached configuration for token storage.\n\nChange-Id: I1037a7fce567e476f07a5d3c220379d656248160\nRelated-Bug: #1463569\n'}]",1,193729,4798dab6a232e8bd2ce9635c57b4bfd0f2351a57,55,7,15,7353,,,0,"Updated keystone to use fernet as the default

This change simply enables fernet to be the default token backend
and disables the keystone memcached configuration for token storage.

Change-Id: I1037a7fce567e476f07a5d3c220379d656248160
Related-Bug: #1463569
",git fetch https://review.opendev.org/openstack/openstack-ansible refs/changes/29/193729/13 && git format-patch -1 --stdout FETCH_HEAD,"['playbooks/roles/os_keystone/meta/main.yml', 'playbooks/roles/os_keystone/templates/keystone.conf.j2', 'playbooks/roles/os_keystone/defaults/main.yml']",3,16695f8b4a7687dc8f21006824a93d56d8a4e560,bug/1463569,"keystone_token_provider: ""keystone.token.providers.fernet.Provider""","keystone_token_provider: ""keystone.token.providers.uuid.Provider""",9,4
openstack%2Fmagnum~master~Iea7a3e11e9bcf44bff510715b770a58a521e3e7a,openstack/magnum,master,Iea7a3e11e9bcf44bff510715b770a58a521e3e7a,Fix unit test case error,MERGED,2015-06-25 02:20:04.000000000,2015-06-25 15:21:20.000000000,2015-06-25 15:21:15.000000000,"[{'_account_id': 3}, {'_account_id': 7049}, {'_account_id': 7494}, {'_account_id': 11650}, {'_account_id': 12175}]","[{'number': 1, 'created': '2015-06-25 02:20:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/magnum/commit/1abbd10eaa03059816cab56c87a56608b2df4547', 'message': 'Fix unit test case error\n\nFor this assertion:\n`self.assertEqual(uuids.sort(), res_uuids.sort())`\nthis assertion is always true because sort() will return None instead of a\nsorted list.\n\nCloses-Bug: #1468580\nChange-Id: Iea7a3e11e9bcf44bff510715b770a58a521e3e7a\n'}, {'number': 2, 'created': '2015-06-25 09:17:30.000000000', 'files': ['magnum/tests/unit/db/test_bay.py'], 'web_link': 'https://opendev.org/openstack/magnum/commit/1241a33807f4dbf0e52071ca30326339d2e83fb1', 'message': 'Fix unit test case error\n\nFor this assertion:\n`self.assertEqual(uuids.sort(), res_uuids.sort())`\nthis assertion is always true because sort() will return None instead of a\nsorted list.\n\nCloses-Bug: #1468580\nChange-Id: Iea7a3e11e9bcf44bff510715b770a58a521e3e7a\n'}]",2,195381,1241a33807f4dbf0e52071ca30326339d2e83fb1,12,5,2,12175,,,0,"Fix unit test case error

For this assertion:
`self.assertEqual(uuids.sort(), res_uuids.sort())`
this assertion is always true because sort() will return None instead of a
sorted list.

Closes-Bug: #1468580
Change-Id: Iea7a3e11e9bcf44bff510715b770a58a521e3e7a
",git fetch https://review.opendev.org/openstack/magnum refs/changes/81/195381/1 && git format-patch -1 --stdout FETCH_HEAD,['magnum/tests/unit/db/test_bay.py'],1,1abbd10eaa03059816cab56c87a56608b2df4547,fix_get_list_unit_test," uuids.sort() res_uuids.sort() self.assertEqual(uuids, res_uuids)"," self.assertEqual(uuids.sort(), res_uuids.sort())",3,1
openstack%2Ffuturist~master~I385a8513e2a20ab05b2a089e4318141e1c5a198d,openstack/futurist,master,I385a8513e2a20ab05b2a089e4318141e1c5a198d,Updated from global requirements,MERGED,2015-06-22 08:20:22.000000000,2015-06-25 15:15:23.000000000,2015-06-25 15:15:21.000000000,"[{'_account_id': 3}, {'_account_id': 1297}, {'_account_id': 5638}]","[{'number': 1, 'created': '2015-06-22 08:20:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/futurist/commit/7258974dad2bdb5f54a1468c2d342f91d93ae8e2', 'message': 'Updated from global requirements\n\nChange-Id: I385a8513e2a20ab05b2a089e4318141e1c5a198d\n'}, {'number': 2, 'created': '2015-06-22 19:52:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/futurist/commit/50575bfe94dfd5f4a65a6a6ba713159aa232f556', 'message': 'Updated from global requirements\n\nChange-Id: I385a8513e2a20ab05b2a089e4318141e1c5a198d\n'}, {'number': 3, 'created': '2015-06-23 21:42:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/futurist/commit/f9eee565f05927011c4783beb7d5010c0f744b69', 'message': 'Updated from global requirements\n\nChange-Id: I385a8513e2a20ab05b2a089e4318141e1c5a198d\n'}, {'number': 4, 'created': '2015-06-24 14:38:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/futurist/commit/d4a0ce8ad48b4a63fbb8a55c0ef3303b20cd8772', 'message': 'Updated from global requirements\n\nChange-Id: I385a8513e2a20ab05b2a089e4318141e1c5a198d\n'}, {'number': 5, 'created': '2015-06-24 20:36:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/futurist/commit/da4a320ea0f770f8ad9a825ee683ac4bbdfa4802', 'message': 'Updated from global requirements\n\nChange-Id: I385a8513e2a20ab05b2a089e4318141e1c5a198d\n'}, {'number': 6, 'created': '2015-06-24 22:40:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/futurist/commit/b584dc91c83d8b18b9609320fee479d7158c00e9', 'message': 'Updated from global requirements\n\nChange-Id: I385a8513e2a20ab05b2a089e4318141e1c5a198d\n'}, {'number': 7, 'created': '2015-06-25 10:53:10.000000000', 'files': ['requirements.txt', 'test-requirements.txt', 'setup.py'], 'web_link': 'https://opendev.org/openstack/futurist/commit/e98692eb3d98b22688dd5cfab498fc5f9e322097', 'message': 'Updated from global requirements\n\nChange-Id: I385a8513e2a20ab05b2a089e4318141e1c5a198d\n'}]",0,193982,e98692eb3d98b22688dd5cfab498fc5f9e322097,28,3,7,11131,,,0,"Updated from global requirements

Change-Id: I385a8513e2a20ab05b2a089e4318141e1c5a198d
",git fetch https://review.opendev.org/openstack/futurist refs/changes/82/193982/1 && git format-patch -1 --stdout FETCH_HEAD,"['requirements.txt', 'test-requirements.txt', 'setup.py']",3,7258974dad2bdb5f54a1468c2d342f91d93ae8e2,openstack/requirements,,#!/usr/bin/env python,6,7
openstack%2Ffuel-specs~master~Icbe3fb433cc30eddb1ea82cbf3b74d32bfcd58ef,openstack/fuel-specs,master,Icbe3fb433cc30eddb1ea82cbf3b74d32bfcd58ef,Spec for migration to Twitter Bootstrap 3,MERGED,2015-06-24 18:35:11.000000000,2015-06-25 15:12:20.000000000,2015-06-25 15:12:17.000000000,"[{'_account_id': 3}, {'_account_id': 8735}, {'_account_id': 8766}, {'_account_id': 8782}, {'_account_id': 8970}, {'_account_id': 9091}, {'_account_id': 9730}, {'_account_id': 15315}]","[{'number': 1, 'created': '2015-06-24 18:35:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-specs/commit/c6e09cef4c9a99e8728937e0365ac283693a6676', 'message': 'Blueprint: tbs3\n\nChange-Id: Icbe3fb433cc30eddb1ea82cbf3b74d32bfcd58ef\n'}, {'number': 2, 'created': '2015-06-25 10:19:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-specs/commit/55c72be0c83bc5f87cc09ab620fef25d1712666a', 'message': 'Spec for migration to Twitter Bootstrap 3\n\nBlueprint tbs3\n\nChange-Id: Icbe3fb433cc30eddb1ea82cbf3b74d32bfcd58ef\n'}, {'number': 3, 'created': '2015-06-25 13:36:51.000000000', 'files': ['specs/7.0/tbs3.rst'], 'web_link': 'https://opendev.org/openstack/fuel-specs/commit/5c289a6bf881f56647ca12ca5d1e27e0769dd5c5', 'message': 'Spec for migration to Twitter Bootstrap 3\n\nBlueprint tbs3\n\nChange-Id: Icbe3fb433cc30eddb1ea82cbf3b74d32bfcd58ef\n'}]",1,195257,5c289a6bf881f56647ca12ca5d1e27e0769dd5c5,20,8,3,8735,,,0,"Spec for migration to Twitter Bootstrap 3

Blueprint tbs3

Change-Id: Icbe3fb433cc30eddb1ea82cbf3b74d32bfcd58ef
",git fetch https://review.opendev.org/openstack/fuel-specs refs/changes/57/195257/1 && git format-patch -1 --stdout FETCH_HEAD,['specs/7.0/tbs3.rst'],1,c6e09cef4c9a99e8728937e0365ac283693a6676,bp/tbs3,".. This work is licensed under a Creative Commons Attribution 3.0 Unported License. http://creativecommons.org/licenses/by/3.0/legalcode ================================ Migration to Twitter Bootstrap 3 ================================ https://blueprints.launchpad.net/fuel/+spec/tbs3 Migrate from Twitter Bootstrap 2 (TB2) to Twitter Bootstrap 3 (TB3). Problem description =================== Currently Fuel UI is based on TB2, which is not supported for more than a year. The current version of Twitter Bootstrap is 3.3.4. Also, our styles file (for TB2) is poorly structured as we haven't refactored it since the very beginning. Proposed change =============== We should migrate to TB3 and reimplement Fuel UI markup according to Twitter Bootstrap changelog. Migrating to a newer version of Twitter Bootstrap is a great chance to reduce technical debt: we'll also have to reimplement all the styles. Migration can be done in a few steps: * Base layout markup (navbar, footer, page wrapper) * Simple pages (support page, login page, releases page, etc.) * Cluster page markup * Cluster page tabs * Nodes tab screens (disks, interfaces) * Dialogs Alternatives ------------ Migrate to some other HTML framework, though it doesn't makes much sense. Data model impact ----------------- None. REST API impact --------------- None. Upgrade impact -------------- None. Security impact --------------- None. Notifications impact -------------------- None. Other end user impact --------------------- As we're changing markup, we also can alter look of some features to match the new style. Performance Impact ------------------ There could be slight impact to performance of Fuel UI in browser as we overhaul the styles and markup, not sure if it get worse or better. Plugin impact ------------- None. Other deployer impact --------------------- None. Developer impact ---------------- Fuel UI contributors should be aware of the changelog of TB3 to efficiently write new code. Infrastructure impact --------------------- None. Implementation ============== Assignees --------- Primary assignee: * Vitaly Kramskikh <vkramskikh@mirantis.com> Other contributors: * Alexandra Morozova <astepanchuk@mirantis.com> * Bogdan Dudko <bdudko@mirantis.com> * Julia Aranovich <jkirnosova@mirantis.com> * Kate Pimenova <kpimenova@mirantis.com> * Nikolay Bogdanov <nbogdanov@mirantis.com> Mandatory design review: * Vitaly Kramskikh <vkramskikh@mirantis.com> QA engineer: * Anastasia Palkina <apalkina@mirantis.com> Work Items ---------- As described in ``Proposed change`` section, though some changes could be more granular. Dependencies ============ None. Testing ======= Existing functional test suite should be modified to support new markup. Acceptance criteria ------------------- TBD Documentation Impact ==================== Screenshots of Fuel UI in the existing documentation should be updated. References ========== * #fuel-ui on freenode ",,161,0
openstack%2Fpuppet-keystone~master~Id7e5b5d5b9acc04907825fde1664a5b550674351,openstack/puppet-keystone,master,Id7e5b5d5b9acc04907825fde1664a5b550674351,support for keystone v3 api - update keystone::roles::admin,ABANDONED,2015-06-18 22:49:39.000000000,2015-06-25 15:11:09.000000000,,[{'_account_id': 3}],"[{'number': 1, 'created': '2015-06-18 22:49:39.000000000', 'files': ['manifests/roles/admin.pp'], 'web_link': 'https://opendev.org/openstack/puppet-keystone/commit/ff7384e98311af08802ff922a9cdfda44f4fbdf7', 'message': 'support for keystone v3 api - update keystone::roles::admin\n\nThis patch implements these parts of the blueprint:\n\n1) Use make_keystone_user_role_name in keystone::roles::admin\n\nChange-Id: Id7e5b5d5b9acc04907825fde1664a5b550674351\nImplements: blueprint api-v3-support\n'}]",0,193358,ff7384e98311af08802ff922a9cdfda44f4fbdf7,4,1,1,9983,,,0,"support for keystone v3 api - update keystone::roles::admin

This patch implements these parts of the blueprint:

1) Use make_keystone_user_role_name in keystone::roles::admin

Change-Id: Id7e5b5d5b9acc04907825fde1664a5b550674351
Implements: blueprint api-v3-support
",git fetch https://review.opendev.org/openstack/puppet-keystone refs/changes/58/193358/1 && git format-patch -1 --stdout FETCH_HEAD,['manifests/roles/admin.pp'],1,ff7384e98311af08802ff922a9cdfda44f4fbdf7,bp/api-v3-support," $role_name = make_keystone_user_role_name({ 'username' => $admin, 'project_name' => $admin_tenant, 'user_domain_name' => $admin_user_domain, 'project_domain_name' => $admin_tenant_domain }) keystone_user_role { $role_name:"," $admin_user_part = $admin_user_domain ? { undef => $admin, default => ""${admin}::${admin_user_domain}"", } $admin_tenant_part = $admin_tenant_domain ? { undef => $admin_tenant, default => ""${admin_tenant}::${admin_tenant_domain}"", } keystone_user_role { ""${admin_user_part}@${admin_tenant_part}"":",7,9
openstack%2Foslo.db~master~I143f30c41e788c7aa9887c0e994f49ee55c94651,openstack/oslo.db,master,I143f30c41e788c7aa9887c0e994f49ee55c94651,Remove implicit RequestContext decoration,MERGED,2015-06-25 10:02:52.000000000,2015-06-25 15:09:09.000000000,2015-06-25 15:09:05.000000000,"[{'_account_id': 3}, {'_account_id': 5638}, {'_account_id': 6849}, {'_account_id': 7491}, {'_account_id': 9555}, {'_account_id': 11816}, {'_account_id': 16986}]","[{'number': 1, 'created': '2015-06-25 10:02:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.db/commit/132ad27b26578e790c11bbe23e536c665033d7e7', 'message': ""Remove implicit RequestContext decoration\n\nThis change removes RequestContext implicit decoration as some\napplications have their own session management for the moment or don't\nneed this feature. Moreover this implicit decoration doesn't help\ndebugging.\n\nThis change doesn't disallow RequestContext decoration but applications\nshould require it explicitly:\n\n from oslo_db.sqlalchemy import enginefacade\n enginefacade.transaction_context_provider(oslo_context.RequestContext)\n\nCloses-Bug: #1468707\nChange-Id: I143f30c41e788c7aa9887c0e994f49ee55c94651\n""}, {'number': 2, 'created': '2015-06-25 10:04:46.000000000', 'files': ['oslo_db/tests/sqlalchemy/test_enginefacade.py', 'oslo_db/sqlalchemy/enginefacade.py'], 'web_link': 'https://opendev.org/openstack/oslo.db/commit/8811644c41715aac0968079ffb22b2300303947b', 'message': ""Remove implicit RequestContext decoration\n\nThis change removes RequestContext implicit decoration as some\napplications have their own session management for the moment or don't\nneed this feature. Moreover this implicit decoration doesn't help\ndebugging.\n\nThis change doesn't disallow RequestContext decoration but applications\nshould require it explicitly:\n\n from oslo_db.sqlalchemy import enginefacade\n enginefacade.transaction_context_provider(oslo_context.RequestContext)\n\nCloses-Bug: #1468707\nChange-Id: I143f30c41e788c7aa9887c0e994f49ee55c94651\n""}]",0,195494,8811644c41715aac0968079ffb22b2300303947b,10,7,2,8124,,,0,"Remove implicit RequestContext decoration

This change removes RequestContext implicit decoration as some
applications have their own session management for the moment or don't
need this feature. Moreover this implicit decoration doesn't help
debugging.

This change doesn't disallow RequestContext decoration but applications
should require it explicitly:

 from oslo_db.sqlalchemy import enginefacade
 enginefacade.transaction_context_provider(oslo_context.RequestContext)

Closes-Bug: #1468707
Change-Id: I143f30c41e788c7aa9887c0e994f49ee55c94651
",git fetch https://review.opendev.org/openstack/oslo.db refs/changes/94/195494/1 && git format-patch -1 --stdout FETCH_HEAD,['oslo_db/sqlalchemy/enginefacade.py'],1,132ad27b26578e790c11bbe23e536c665033d7e7,bug/1468707,,from oslo_context import context as oslo_context# apply the context descriptors to oslo.context.RequestContext transaction_context_provider(oslo_context.RequestContext) ,0,5
openstack%2Fpuppet-keystone~master~If790adbb1e5e9a59b52bd0de9188abd5b635dfe2,openstack/puppet-keystone,master,If790adbb1e5e9a59b52bd0de9188abd5b635dfe2,support for keystone v3 api - make_keystone_user_role_name,ABANDONED,2015-06-18 22:49:39.000000000,2015-06-25 15:04:43.000000000,,[{'_account_id': 3}],"[{'number': 1, 'created': '2015-06-18 22:49:39.000000000', 'files': ['lib/puppet/parser/functions/make_keystone_user_role_name.rb', 'spec/unit/parser/functions/make_keystone_user_role_name_spec.rb'], 'web_link': 'https://opendev.org/openstack/puppet-keystone/commit/b8111f1a5d459c1ecd3d4c2b54fd96626667e2c4', 'message': 'support for keystone v3 api - make_keystone_user_role_name\n\nThis patch implements these parts of the blueprint:\n\n1) Adds a make_keystone_user_role_name helper method which will construct a\nvalid domain aware user role name.  This is intended to be used in the other\npuppet modules (puppet-glance) that set notifications based on\nkeystone_user_role resources, in order to construct valid domain aware\nnames for these resources.\n\nChange-Id: If790adbb1e5e9a59b52bd0de9188abd5b635dfe2\nImplements: blueprint api-v3-support\n'}]",0,193355,b8111f1a5d459c1ecd3d4c2b54fd96626667e2c4,4,1,1,9983,,,0,"support for keystone v3 api - make_keystone_user_role_name

This patch implements these parts of the blueprint:

1) Adds a make_keystone_user_role_name helper method which will construct a
valid domain aware user role name.  This is intended to be used in the other
puppet modules (puppet-glance) that set notifications based on
keystone_user_role resources, in order to construct valid domain aware
names for these resources.

Change-Id: If790adbb1e5e9a59b52bd0de9188abd5b635dfe2
Implements: blueprint api-v3-support
",git fetch https://review.opendev.org/openstack/puppet-keystone refs/changes/55/193355/1 && git format-patch -1 --stdout FETCH_HEAD,"['lib/puppet/parser/functions/make_keystone_user_role_name.rb', 'spec/unit/parser/functions/make_keystone_user_role_name_spec.rb']",2,b8111f1a5d459c1ecd3d4c2b54fd96626667e2c4,bp/api-v3-support,"require 'puppet' require 'spec_helper' require 'puppet/parser/functions/make_keystone_user_role_name' describe 'the make_keystone_user_role_name function' do # NOTE: puppet undef is passed as '' def puppet_undef '' end before :all do Puppet::Parser::Functions.autoloader.loadall end before :each do node = Puppet::Node.new('localhost') compiler = Puppet::Parser::Compiler.new(node) @scope = Puppet::Parser::Scope.new(compiler) end it 'should exist' do expect(Puppet::Parser::Functions.function('make_keystone_user_role_name')).to eq('function_make_keystone_user_role_name') end it 'should raise an ArgumentError if no argument given' do expect { @scope.function_make_keystone_user_role_name([]) }.to raise_error(ArgumentError, 'a hash must be specified as the first and only argument') end it 'should raise an ArgumentError if too many arguments given' do expect { @scope.function_make_keystone_user_role_name([1, 2]) }.to raise_error(ArgumentError, 'a hash must be specified as the first and only argument') end it 'should raise an ArgumentError if argument is not a Hash' do expect { @scope.function_make_keystone_user_role_name(['not a hash']) }.to raise_error(ArgumentError, 'a hash must be specified as the first and only argument') end it 'should raise an ArgumentError if username not specified' do expect { @scope.function_make_keystone_user_role_name([{}]) }.to raise_error(ArgumentError, 'username must be specified') end it 'should raise an ArgumentError if username is empty' do expect { @scope.function_make_keystone_user_role_name([{'username' => puppet_undef}]) }.to raise_error(ArgumentError, 'username must be specified') end it 'should raise an ArgumentError if project or domain not specified' do expect { @scope.function_make_keystone_user_role_name([{'username' => 'foo'}]) }.to raise_error(ArgumentError, 'either project_name or domain_name must be specified') end it 'should raise an ArgumentError if project is empty' do expect { @scope.function_make_keystone_user_role_name([{'username' => 'foo', 'project_name' => puppet_undef}]) }.to raise_error(ArgumentError, 'either project_name or domain_name must be specified') end it 'should raise an ArgumentError if project and domain are empty' do expect { @scope.function_make_keystone_user_role_name([{'username' => 'foo', 'project_name' => puppet_undef, 'domain_name' => puppet_undef}]) }.to raise_error(ArgumentError, 'either project_name or domain_name must be specified') end it 'should raise an ArgumentError if project and domain are both specified' do expect { @scope.function_make_keystone_user_role_name([{'username' => 'foo', 'project_name' => 'proj', 'domain_name' => 'dom'}]) }.to raise_error(ArgumentError, 'either project_name or domain_name must be specified') end it 'should return name and project role' do expect(@scope.function_make_keystone_user_role_name([{'username' => 'foo', 'project_name' => 'bar'}])).to eq('foo@bar') end it 'should return name, user domain and project role' do arg = {'username' => 'foo', 'project_name' => 'bar', 'user_domain_name' => 'userdomain'} expect(@scope.function_make_keystone_user_role_name([arg])).to eq('foo::userdomain@bar') end it 'should return name, user domain, project and project domain role' do arg = {'username' => 'foo', 'project_name' => 'bar', 'user_domain_name' => 'userdomain', 'project_domain_name' => 'projectdomain'} expect(@scope.function_make_keystone_user_role_name([arg])).to eq('foo::userdomain@bar::projectdomain') end it 'should use default domain for missing user and project domain' do arg = {'username' => 'foo', 'project_name' => 'bar', 'user_domain_name' => puppet_undef, 'project_domain_name' => puppet_undef, 'default_domain_name' => 'defaultdomain'} expect(@scope.function_make_keystone_user_role_name([arg])).to eq('foo::defaultdomain@bar::defaultdomain') end it 'should use default domain for missing user domain' do arg = {'username' => 'foo', 'project_name' => 'bar', 'user_domain_name' => puppet_undef, 'project_domain_name' => 'projectdomain', 'default_domain_name' => 'defaultdomain'} expect(@scope.function_make_keystone_user_role_name([arg])).to eq('foo::defaultdomain@bar::projectdomain') end it 'should use default domain for missing project domain' do arg = {'username' => 'foo', 'project_name' => 'bar', 'user_domain_name' => 'userdomain', 'project_domain_name' => puppet_undef, 'default_domain_name' => 'defaultdomain'} expect(@scope.function_make_keystone_user_role_name([arg])).to eq('foo::userdomain@bar::defaultdomain') end it 'should make a domain role with given user domain and domain name' do arg = {'username' => 'foo', 'project_name' => puppet_undef, 'user_domain_name' => 'userdomain', 'project_domain_name' => puppet_undef, 'default_domain_name' => 'defaultdomain', 'domain_name' => 'domainname'} expect(@scope.function_make_keystone_user_role_name([arg])).to eq('foo::userdomain@::domainname') end it 'should make a domain role with given default domain and domain name' do arg = {'username' => 'foo', 'project_name' => puppet_undef, 'user_domain_name' => puppet_undef, 'project_domain_nam`e' => puppet_undef, 'default_domain_name' => 'defaultdomain', 'domain_name' => 'domainname'} expect(@scope.function_make_keystone_user_role_name([arg])).to eq('foo::defaultdomain@::domainname') end it 'should use domain given in username and project_name' do arg = {'username' => 'foo::userdomain', 'project_name' => 'foo::projectdomain', 'user_domain_name' => puppet_undef, 'project_domain_name' => puppet_undef, 'default_domain_name' => puppet_undef, 'domain_name' => puppet_undef} expect(@scope.function_make_keystone_user_role_name([arg])).to eq('foo::userdomain@foo::projectdomain') end it 'should use domain given in user_domain_name and project_domain_name instead of username and project_name' do arg = {'username' => 'foo::userdomain', 'project_name' => 'foo::projectdomain', 'user_domain_name' => 'override', 'project_domain_name' => 'override', 'default_domain_name' => 'defaultdomain', 'domain_name' => puppet_undef} expect(@scope.function_make_keystone_user_role_name([arg])).to eq('foo::override@foo::override') end it 'should use domain given in default_domain_name instead of username and project_name' do arg = {'username' => 'foo::userdomain', 'project_name' => 'foo::projectdomain', 'user_domain_name' => puppet_undef, 'project_domain_name' => puppet_undef, 'default_domain_name' => 'defaultdomain', 'domain_name' => puppet_undef} expect(@scope.function_make_keystone_user_role_name([arg])).to eq('foo::defaultdomain@foo::defaultdomain') end end ",,198,0
openstack%2Fpuppet-openstacklib~master~I4fe5bd457ca21fb7d2f72f69158f70f8c68af064,openstack/puppet-openstacklib,master,I4fe5bd457ca21fb7d2f72f69158f70f8c68af064,Fix Beaker CI according recent puppetlabs-rabbitmq change,MERGED,2015-06-25 12:08:03.000000000,2015-06-25 15:00:32.000000000,2015-06-25 15:00:32.000000000,"[{'_account_id': 3}, {'_account_id': 1607}, {'_account_id': 7155}, {'_account_id': 9983}]","[{'number': 1, 'created': '2015-06-25 12:08:03.000000000', 'files': ['spec/acceptance/rabbitmq_spec.rb'], 'web_link': 'https://opendev.org/openstack/puppet-openstacklib/commit/fd29cbdcee555892a4905d899b7624c5dd98aea5', 'message': ""Fix Beaker CI according recent puppetlabs-rabbitmq change\n\nThe puppetlabs-rabbitmq module introduce a new feature related to the\nerlang_cookie parameter change (the database must be wiped if the cookie\nis changed), the parameter wipe_db_on_cookie_change is configured to\nfalse by default. But we're not setting up a rabbitmq cluster and we're\nnot using pacemaker in beaker CI tests, so we just remove the erlang\ncookie parameter change.\n\nChange-Id: I4fe5bd457ca21fb7d2f72f69158f70f8c68af064\nCloses-Bug: #1468444\n""}]",0,195544,fd29cbdcee555892a4905d899b7624c5dd98aea5,10,4,1,3153,,,0,"Fix Beaker CI according recent puppetlabs-rabbitmq change

The puppetlabs-rabbitmq module introduce a new feature related to the
erlang_cookie parameter change (the database must be wiped if the cookie
is changed), the parameter wipe_db_on_cookie_change is configured to
false by default. But we're not setting up a rabbitmq cluster and we're
not using pacemaker in beaker CI tests, so we just remove the erlang
cookie parameter change.

Change-Id: I4fe5bd457ca21fb7d2f72f69158f70f8c68af064
Closes-Bug: #1468444
",git fetch https://review.opendev.org/openstack/puppet-openstacklib refs/changes/44/195544/1 && git format-patch -1 --stdout FETCH_HEAD,['spec/acceptance/rabbitmq_spec.rb'],1,fd29cbdcee555892a4905d899b7624c5dd98aea5,bug-1468444,," erlang_cookie => 'secrete',",0,1
openstack%2Fmagnum~master~I1ca2a7ca07b3393b06b78addb91443b9c427f733,openstack/magnum,master,I1ca2a7ca07b3393b06b78addb91443b9c427f733,Add Bay.list_all method to allow admin context to query all tenants bay,MERGED,2015-06-18 09:31:24.000000000,2015-06-25 14:59:57.000000000,2015-06-25 14:59:50.000000000,"[{'_account_id': 3}, {'_account_id': 7049}, {'_account_id': 7494}, {'_account_id': 9591}, {'_account_id': 10206}, {'_account_id': 11536}, {'_account_id': 11650}, {'_account_id': 12175}, {'_account_id': 12385}]","[{'number': 1, 'created': '2015-06-18 09:31:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/magnum/commit/648323d968ce1b14939e1841939d695d9991d142', 'message': 'Allow admin context to query all bay\n\nThis patch allows admin context to query all bays from db.\n\nPartial-Implements: blueprint add-periodic-task\nCo-Authored-By: ShaoHe Feng <shaohe.feng@intel.com>\nChange-Id: I1ca2a7ca07b3393b06b78addb91443b9c427f733\n'}, {'number': 2, 'created': '2015-06-23 06:33:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/magnum/commit/6198048be8950f4d7a1eba2d6479c7c52b29b7d4', 'message': 'Allow admin context to query all bay\n\nThis patch allows admin context to query all bays from db.\n\nIf use an admin context(context.is_admin=True), magnum will return all\nprojects/users bays.\n\nPartial-Implements: blueprint add-periodic-task\nCo-Authored-By: ShaoHe Feng <shaohe.feng@intel.com>\nChange-Id: I1ca2a7ca07b3393b06b78addb91443b9c427f733\n'}, {'number': 3, 'created': '2015-06-24 03:53:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/magnum/commit/f087e332800daea2af70b6a6ff14b2bda5c6375a', 'message': 'Allow admin context to query all bay\n\nThis patch allows admin context to query all bays from db.\n\nIf use an admin context(context.is_admin=True), magnum will return all\nprojects/users bays.\nA periodic task requires this function becuase we need to query all temporary\nstatus bays and sync their status from heat stack.\n\nPartial-Implements: blueprint add-periodic-task\nCo-Authored-By: ShaoHe Feng <shaohe.feng@intel.com>\nChange-Id: I1ca2a7ca07b3393b06b78addb91443b9c427f733\n'}, {'number': 4, 'created': '2015-06-24 08:19:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/magnum/commit/286865b1f030f8968c3471da18d1555640e085fd', 'message': 'Allow admin context to query all bay\n\nThis patch allows admin context to query all bays from db.\n\nIf use an admin context(context.is_admin=True), magnum will return all\nprojects/users bays.\nA periodic task requires this function becuase we need to query all temporary\nstatus bays and sync their status from heat stack.\n\nPartial-Implements: blueprint add-periodic-task\nCo-Authored-By: ShaoHe Feng <shaohe.feng@intel.com>\nChange-Id: I1ca2a7ca07b3393b06b78addb91443b9c427f733\n'}, {'number': 5, 'created': '2015-06-25 09:52:29.000000000', 'files': ['magnum/tests/unit/db/test_bay.py', 'magnum/db/sqlalchemy/api.py', 'magnum/objects/bay.py', 'magnum/tests/unit/objects/test_bay.py'], 'web_link': 'https://opendev.org/openstack/magnum/commit/c23ee12d306b07ff517233109a5fc06272613d21', 'message': 'Add Bay.list_all method to allow admin context to query all tenants bay\n\nThis patch adds a new method list_all to allows admin context to query all bays\nfrom db.\n\nA periodic task requires this function becuase we need to query all temporary\nstatus bays and sync their status from heat stack.\n\nPartial-Implements: blueprint add-periodic-task\nCo-Authored-By: ShaoHe Feng <shaohe.feng@intel.com>\nChange-Id: I1ca2a7ca07b3393b06b78addb91443b9c427f733\n'}]",2,193031,c23ee12d306b07ff517233109a5fc06272613d21,29,9,5,12175,,,0,"Add Bay.list_all method to allow admin context to query all tenants bay

This patch adds a new method list_all to allows admin context to query all bays
from db.

A periodic task requires this function becuase we need to query all temporary
status bays and sync their status from heat stack.

Partial-Implements: blueprint add-periodic-task
Co-Authored-By: ShaoHe Feng <shaohe.feng@intel.com>
Change-Id: I1ca2a7ca07b3393b06b78addb91443b9c427f733
",git fetch https://review.opendev.org/openstack/magnum refs/changes/31/193031/1 && git format-patch -1 --stdout FETCH_HEAD,['magnum/db/sqlalchemy/api.py'],1,648323d968ce1b14939e1841939d695d9991d142,bp/add-periodic-task, if context.is_admin: return query,,2,0
openstack%2Fpython-monascaclient~master~Ibf56fd10a3f163b9e5d612d3db3fbeafb6f776df,openstack/python-monascaclient,master,Ibf56fd10a3f163b9e5d612d3db3fbeafb6f776df,Moved pbr requirements to a newer constraint,MERGED,2015-06-24 21:47:54.000000000,2015-06-25 14:59:50.000000000,2015-06-25 14:59:48.000000000,"[{'_account_id': 3}, {'_account_id': 7847}, {'_account_id': 12133}]","[{'number': 1, 'created': '2015-06-24 21:47:54.000000000', 'files': ['requirements.txt'], 'web_link': 'https://opendev.org/openstack/python-monascaclient/commit/5bd42ca11e85190c392d07adea9535d59b47eb5d', 'message': 'Moved pbr requirements to a newer constraint\n\nChange-Id: Ibf56fd10a3f163b9e5d612d3db3fbeafb6f776df\n'}]",0,195332,5bd42ca11e85190c392d07adea9535d59b47eb5d,7,3,1,11094,,,0,"Moved pbr requirements to a newer constraint

Change-Id: Ibf56fd10a3f163b9e5d612d3db3fbeafb6f776df
",git fetch https://review.opendev.org/openstack/python-monascaclient refs/changes/32/195332/1 && git format-patch -1 --stdout FETCH_HEAD,['requirements.txt'],1,5bd42ca11e85190c392d07adea9535d59b47eb5d,feature/pbr,"pbr>=0.11,<2.0","pbr>=0.6,!=0.7,<1.0",1,1
openstack%2Fkolla~master~I15fd4926019590a150eb22dc885d0ef8cd31e7cc,openstack/kolla,master,I15fd4926019590a150eb22dc885d0ef8cd31e7cc,Have test retry building failed images,MERGED,2015-06-25 13:30:30.000000000,2015-06-25 14:59:43.000000000,2015-06-25 14:59:42.000000000,"[{'_account_id': 3}, {'_account_id': 2834}, {'_account_id': 3098}]","[{'number': 1, 'created': '2015-06-25 13:30:30.000000000', 'files': ['tests/test_images.py'], 'web_link': 'https://opendev.org/openstack/kolla/commit/091ef5a5cb7460e162eb66908df316b9bd790cf1', 'message': 'Have test retry building failed images\n\nThe image build test now retries 3 times before declaring an image as\nfailing. This should help the gate in case of unreliable network\nconnectivity to the mirrors.\n\nWe expect the penalty of retrying to build failed images to be low\nthanks to docker cache. Only the failing layer should be retried.\n\nChange-Id: I15fd4926019590a150eb22dc885d0ef8cd31e7cc\nCloses-Bug: #1466677\n'}]",0,195574,091ef5a5cb7460e162eb66908df316b9bd790cf1,7,3,1,13039,,,0,"Have test retry building failed images

The image build test now retries 3 times before declaring an image as
failing. This should help the gate in case of unreliable network
connectivity to the mirrors.

We expect the penalty of retrying to build failed images to be low
thanks to docker cache. Only the failing layer should be retried.

Change-Id: I15fd4926019590a150eb22dc885d0ef8cd31e7cc
Closes-Bug: #1466677
",git fetch https://review.opendev.org/openstack/kolla refs/changes/74/195574/1 && git format-patch -1 --stdout FETCH_HEAD,['tests/test_images.py'],1,091ef5a5cb7460e162eb66908df316b9bd790cf1,bug/1466677," '--testmode', '--retry 3'],"," '--testmode'],",2,1
openstack%2Frelease-tools~master~If2e13eaee230515d44cbd76fa3675ba0d8343cbf,openstack/release-tools,master,If2e13eaee230515d44cbd76fa3675ba0d8343cbf,Replace --dryrun with --target and --clean actions,MERGED,2015-06-23 14:55:10.000000000,2015-06-25 14:59:26.000000000,2015-06-25 14:59:26.000000000,"[{'_account_id': 3}, {'_account_id': 308}, {'_account_id': 2472}]","[{'number': 1, 'created': '2015-06-23 14:55:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/release-tools/commit/35e3b286466e19c54887d327b3c7275a5178c481', 'message': 'Add --no-clear flag to adjust_blueprints.py\n\nAdd a flag to skip clearing the milestones from incomplete blueprints.\n\nChange-Id: If2e13eaee230515d44cbd76fa3675ba0d8343cbf\n'}, {'number': 2, 'created': '2015-06-25 13:28:30.000000000', 'files': ['adjust_blueprints.py', 'README.rst'], 'web_link': 'https://opendev.org/openstack/release-tools/commit/f340cc2e3ed74502447529d9b3f268155ff940c1', 'message': 'Replace --dryrun with --target and --clean actions\n\nBy default do nothing, force user to specify --target to do the\ntargeting of completed blueprints and --clean to do the cleaning of\nincomplete blueprints.\n\nChange-Id: If2e13eaee230515d44cbd76fa3675ba0d8343cbf\n'}]",0,194689,f340cc2e3ed74502447529d9b3f268155ff940c1,9,3,2,2472,,,0,"Replace --dryrun with --target and --clean actions

By default do nothing, force user to specify --target to do the
targeting of completed blueprints and --clean to do the cleaning of
incomplete blueprints.

Change-Id: If2e13eaee230515d44cbd76fa3675ba0d8343cbf
",git fetch https://review.opendev.org/openstack/release-tools refs/changes/89/194689/1 && git format-patch -1 --stdout FETCH_HEAD,['adjust_blueprints.py'],1,35e3b286466e19c54887d327b3c7275a5178c481,bp/s,"parser.add_argument(""--no-clear"", action='store_true', help='Do not clear milestone from incomplete blueprints')if to_clear and not args.no_clear:else: print ""Not clearing incomplete blueprints""",if (to_clear):,5,1
openstack%2Frelease-tools~master~I20d252c0f33fa27f037f54a8a9761f9b2f315b85,openstack/release-tools,master,I20d252c0f33fa27f037f54a8a9761f9b2f315b85,adjust_blueprints: Only mention real modifications,MERGED,2015-06-25 12:22:39.000000000,2015-06-25 14:59:25.000000000,2015-06-25 14:59:24.000000000,"[{'_account_id': 3}, {'_account_id': 2472}]","[{'number': 1, 'created': '2015-06-25 12:22:39.000000000', 'files': ['adjust_blueprints.py'], 'web_link': 'https://opendev.org/openstack/release-tools/commit/10ffd1a4066ada253f1fb5eaab029e7efb210d80', 'message': ""adjust_blueprints: Only mention real modifications\n\nFirst version of adjust_blueprints.py was reporting all blueprints,\nincluding those that were already properly milestone-targeted and\nwith the series goal set.\n\nThis new version separates milestone-targeting from series-goal-\nsetting tasks, and only mention the real modifications about to be\ndone. Since you can't read the series goal field from the API, this\nis done by retrieving the series-targeted blueprints list and\ncomparing the sets.\n\nChange-Id: I20d252c0f33fa27f037f54a8a9761f9b2f315b85\n""}]",0,195550,10ffd1a4066ada253f1fb5eaab029e7efb210d80,6,2,1,308,,,0,"adjust_blueprints: Only mention real modifications

First version of adjust_blueprints.py was reporting all blueprints,
including those that were already properly milestone-targeted and
with the series goal set.

This new version separates milestone-targeting from series-goal-
setting tasks, and only mention the real modifications about to be
done. Since you can't read the series goal field from the API, this
is done by retrieving the series-targeted blueprints list and
comparing the sets.

Change-Id: I20d252c0f33fa27f037f54a8a9761f9b2f315b85
",git fetch https://review.opendev.org/openstack/release-tools refs/changes/50/195550/1 && git format-patch -1 --stdout FETCH_HEAD,['adjust_blueprints.py'],1,10ffd1a4066ada253f1fb5eaab029e7efb210d80,bp/s,"# Also get the series-targeted approved blueprints seriesbps = series.valid_specifications if bp not in seriesbps: to_series.append(bp) if bp.milestone != milestone: to_target.append(bp) print print ""Those are implemented: need milestone target added""if (to_series): print print ""Those are implemented: need series goal added/approved"" for bp in to_series: print bp.web_link if not args.dryrun: bp.proposeGoal(goal=series) if (to_clear): print"," to_target.append(bp) print ""Those are implemented: may need milestone or series target added"" bp.proposeGoal(goal=series)if (to_clear):",17,3
openstack%2Frelease-tools~master~Ie190213cb5a2b8e8f116d098a45977339e9851d9,openstack/release-tools,master,Ie190213cb5a2b8e8f116d098a45977339e9851d9,Fix adjust_blueprint.py milestone targeting fail,MERGED,2015-06-25 11:46:19.000000000,2015-06-25 14:59:18.000000000,2015-06-25 14:59:17.000000000,"[{'_account_id': 3}, {'_account_id': 2472}]","[{'number': 1, 'created': '2015-06-25 11:46:19.000000000', 'files': ['adjust_blueprints.py'], 'web_link': 'https://opendev.org/openstack/release-tools/commit/a99ad6524281f47a51d3be076aab324dd9f90ff6', 'message': 'Fix adjust_blueprint.py milestone targeting fail\n\nFix a case where adjust_blueprint.py was failing to properly target\na given blueprint to a milestone. This was due to Launchpad API fun,\nwith proposeGoal() reloading the bp object...\n\nChange-Id: Ie190213cb5a2b8e8f116d098a45977339e9851d9\n'}]",0,195537,a99ad6524281f47a51d3be076aab324dd9f90ff6,7,2,1,308,,,0,"Fix adjust_blueprint.py milestone targeting fail

Fix a case where adjust_blueprint.py was failing to properly target
a given blueprint to a milestone. This was due to Launchpad API fun,
with proposeGoal() reloading the bp object...

Change-Id: Ie190213cb5a2b8e8f116d098a45977339e9851d9
",git fetch https://review.opendev.org/openstack/release-tools refs/changes/37/195537/1 && git format-patch -1 --stdout FETCH_HEAD,['adjust_blueprints.py'],1,a99ad6524281f47a51d3be076aab324dd9f90ff6,bp/to," print ""Those are implemented: may need milestone or series target added"" bp.milestone = milestone"," print ""Those are implemented: need milestone and/or series target added"" bp.milestone = milestone",2,2
openstack%2Frelease-tools~master~I4b33f00f5edeeb915b10bdf47b0c02e8ee0ac745,openstack/release-tools,master,I4b33f00f5edeeb915b10bdf47b0c02e8ee0ac745,Optional include pypi package url link in release notes,MERGED,2015-06-23 22:44:36.000000000,2015-06-25 14:59:05.000000000,2015-06-25 14:59:00.000000000,"[{'_account_id': 3}, {'_account_id': 308}, {'_account_id': 2472}, {'_account_id': 16272}]","[{'number': 1, 'created': '2015-06-23 22:44:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/release-tools/commit/336c6f89a807fa6e5baa9d4b93e0da7a7c7b8bb1', 'message': 'Optional include pypi package url link in release notes\n\nChange-Id: I4b33f00f5edeeb915b10bdf47b0c02e8ee0ac745\n'}, {'number': 2, 'created': '2015-06-24 23:06:02.000000000', 'files': ['release_notes.py', 'release_postversion.sh'], 'web_link': 'https://opendev.org/openstack/release-tools/commit/0ba6479afa9e22f51ade30cbf7122dc8d2721905', 'message': 'Optional include pypi package url link in release notes\n\nChange-Id: I4b33f00f5edeeb915b10bdf47b0c02e8ee0ac745\n'}]",0,194850,0ba6479afa9e22f51ade30cbf7122dc8d2721905,11,4,2,1297,,,0,"Optional include pypi package url link in release notes

Change-Id: I4b33f00f5edeeb915b10bdf47b0c02e8ee0ac745
",git fetch https://review.opendev.org/openstack/release-tools refs/changes/50/194850/1 && git format-patch -1 --stdout FETCH_HEAD,"['release_notes.py', 'release_library.sh']",2,336c6f89a807fa6e5baa9d4b93e0da7a7c7b8bb1,, --include-pypi-link \,,18,0
openstack%2Fceilometermiddleware~master~Ibf3552c0f72f267ddd5a0a32a47427548d0b55c1,openstack/ceilometermiddleware,master,Ibf3552c0f72f267ddd5a0a32a47427548d0b55c1,Add test which asserts non-empty target_id,MERGED,2015-06-18 10:52:50.000000000,2015-06-25 14:54:22.000000000,2015-06-25 14:54:19.000000000,"[{'_account_id': 3}, {'_account_id': 6537}, {'_account_id': 7478}, {'_account_id': 9562}, {'_account_id': 10987}, {'_account_id': 11564}]","[{'number': 1, 'created': '2015-06-18 10:52:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometermiddleware/commit/19bb0cfaeefd75ec882797341c160a0a38d11fa6', 'message': 'Add test which asserts non-empty target_id\n\ntarget_id should not be empty because it is used as resource_id.\nRelated-Bug: #1464265\n\nChange-Id: Ibf3552c0f72f267ddd5a0a32a47427548d0b55c1\n'}, {'number': 2, 'created': '2015-06-23 07:22:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometermiddleware/commit/de8498dd61d79d03b8cbf8e32d14d23e681a5a42', 'message': 'Add test which asserts non-empty target_id\n\ntarget_id should not be empty because it is used as resource_id.\nRelated-Bug: #1464265\n\nChange-Id: Ibf3552c0f72f267ddd5a0a32a47427548d0b55c1\n'}, {'number': 3, 'created': '2015-06-24 14:11:42.000000000', 'files': ['ceilometermiddleware/tests/test_swift.py'], 'web_link': 'https://opendev.org/openstack/ceilometermiddleware/commit/cf9cb86be7b57e95ed3603924f721bbab6ba2816', 'message': 'Add test which asserts non-empty target_id\n\ntarget_id should not be empty because it is used as resource_id.\nRelated-Bug: #1464265\n\nChange-Id: Ibf3552c0f72f267ddd5a0a32a47427548d0b55c1\n'}]",4,193062,cf9cb86be7b57e95ed3603924f721bbab6ba2816,17,6,3,7478,,,0,"Add test which asserts non-empty target_id

target_id should not be empty because it is used as resource_id.
Related-Bug: #1464265

Change-Id: Ibf3552c0f72f267ddd5a0a32a47427548d0b55c1
",git fetch https://review.opendev.org/openstack/ceilometermiddleware refs/changes/62/193062/3 && git format-patch -1 --stdout FETCH_HEAD,"['ceilometermiddleware/swift.py', 'ceilometermiddleware/tests/test_swift.py']",2,19bb0cfaeefd75ec882797341c160a0a38d11fa6,bug/1464265," def test_empty_reseller_prefix(self): app = swift.Swift( FakeApp(), {'reseller_prefix': 'CUSTOM'}) req = FakeRequest('/1.0/CUSTOM/container/obj', environ={'REQUEST_METHOD': 'GET'}) with mock.patch('oslo.messaging.Notifier.info') as notify: list(app(req.environ, self.start_response)) data = notify.call_args_list[0][0] self.assertIsNot(0, len(data[2]['target']['id']))",,11,1
openstack%2Fnova~master~I3b27ba441c9c3e84c8f31b03ab630d6a1c49abb7,openstack/nova,master,I3b27ba441c9c3e84c8f31b03ab630d6a1c49abb7,WIP: Add support for VIF plugin script to Nova,ABANDONED,2015-03-08 13:21:45.000000000,2015-06-25 14:49:46.000000000,,"[{'_account_id': 3}, {'_account_id': 1779}, {'_account_id': 5170}, {'_account_id': 6598}, {'_account_id': 6681}, {'_account_id': 8871}, {'_account_id': 9008}, {'_account_id': 9578}, {'_account_id': 9732}, {'_account_id': 10118}, {'_account_id': 10385}, {'_account_id': 11103}, {'_account_id': 11604}, {'_account_id': 12171}, {'_account_id': 12340}, {'_account_id': 13734}, {'_account_id': 13869}, {'_account_id': 15286}, {'_account_id': 15751}]","[{'number': 1, 'created': '2015-03-08 13:21:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/493e2b42c52ce4e253f9669885f2591c743a4fae', 'message': 'WIP: Add support for VIF plugin script to Nova\n\nThis change introduces support for handling new VIF detail field,\nVIF_PLUGIN_SCRIPT. This field will be populated by Neutron and refer to\na back-end specific script that will be called from the virtualization\ndriver when the system is ready to connect the guest to a L2 network.\n\nChange-Id: I3b27ba441c9c3e84c8f31b03ab630d6a1c49abb7\n'}, {'number': 2, 'created': '2015-03-08 21:48:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/9f6315c7ba5104693663c122b63f88d959a795d6', 'message': 'WIP: Add support for VIF plugin script to Nova\n\nThis change introduces support for handling new VIF detail field,\nVIF_PLUGIN_SCRIPT. This field will be populated by Neutron and refer to\na back-end specific script that will be called from the virtualization\ndriver when the system is ready to connect the guest to a L2 network.\n\nChange-Id: I3b27ba441c9c3e84c8f31b03ab630d6a1c49abb7\n'}, {'number': 3, 'created': '2015-03-25 19:49:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/00c042b2a03a9b80f8de7deacbd1528da6fe1f3b', 'message': 'WIP: Add support for VIF plugin script to Nova\n\nThis change introduces support for handling new VIF detail field,\nVIF_PLUGIN_SCRIPT. This field will be populated by Neutron and refer to\na back-end specific script that will be called from the virtualization\ndriver when the system is ready to connect the guest to a L2 network.\n\nChange-Id: I3b27ba441c9c3e84c8f31b03ab630d6a1c49abb7\n'}, {'number': 4, 'created': '2015-03-25 19:55:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/42c359088f6c97972dd5ee8d897ac9dd00578246', 'message': 'WIP: Add support for VIF plugin script to Nova\n\nThis change introduces support for handling new VIF detail field,\nVIF_PLUGIN_SCRIPT. This field will be populated by Neutron and refer to\na back-end specific script that will be called from the virtualization\ndriver when the system is ready to connect the guest to a L2 network.\n\nChange-Id: I3b27ba441c9c3e84c8f31b03ab630d6a1c49abb7\n'}, {'number': 5, 'created': '2015-04-21 17:33:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/28dd7051f70e4c6cd97357272d7f360f42a84662', 'message': 'WIP: Add support for VIF plugin script to Nova\n\nThis change introduces support for handling new VIF detail field,\nVIF_PLUGIN_SCRIPT. This field will be populated by Neutron and refer to\na back-end specific script that will be called from the virtualization\ndriver when the system is ready to connect the guest to a L2 network.\n\nChange-Id: I3b27ba441c9c3e84c8f31b03ab630d6a1c49abb7\n'}, {'number': 6, 'created': '2015-04-21 17:49:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/25c9ac0f7e11bf34550cf5f0c71895a7d0463f95', 'message': 'WIP: Add support for VIF plugin script to Nova\n\nThis change introduces support for handling new VIF detail field,\nVIF_PLUGIN_SCRIPT. This field will be populated by Neutron and refer to\na back-end specific script that will be called from the virtualization\ndriver when the system is ready to connect the guest to a L2 network.\n\nChange-Id: I3b27ba441c9c3e84c8f31b03ab630d6a1c49abb7\n'}, {'number': 7, 'created': '2015-05-26 19:51:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/1d2de69cd0e069ab386569bafd94b93b67103d31', 'message': 'WIP: Add support for VIF plugin script to Nova\n\nThis change introduces support for handling new VIF detail field,\nVIF_PLUGIN_SCRIPT. This field will be populated by Neutron and refer to\na back-end specific script that will be called from the virtualization\ndriver when the system is ready to connect the guest to a L2 network.\n\nWIP TODO: Add configuration variable for script locations, validation\nfor path info, stderr logging and error code handling.\n\nChange-Id: I3b27ba441c9c3e84c8f31b03ab630d6a1c49abb7\n'}, {'number': 8, 'created': '2015-05-27 16:18:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/7d5877c013ec1b1970975814450c279d8691c26e', 'message': 'WIP: Add support for VIF plugin script to Nova\n\nThis change introduces support for handling new VIF detail field,\nVIF_PLUGIN_SCRIPT. This field will be populated by Neutron and refer to\na back-end specific script that will be called from the virtualization\ndriver when the system is ready to connect the guest to a L2 network.\n\nWIP note: this is a proof-of-concept that is tracking a spec proposal\nthat is not yet approved.\n\nChange-Id: I3b27ba441c9c3e84c8f31b03ab630d6a1c49abb7\n'}, {'number': 9, 'created': '2015-05-27 16:35:15.000000000', 'files': ['nova/virt/libvirt/vif.py', 'nova/tests/unit/virt/test_netutils.py', 'nova/network/model.py', 'nova/tests/unit/virt/libvirt/test_vif.py', 'nova/virt/netutils.py', 'nova/objects/network_info.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/487acfb343cda855169d37be126598459b36ec84', 'message': 'WIP: Add support for VIF plugin script to Nova\n\nThis change introduces support for handling new VIF detail field,\nVIF_PLUGIN_SCRIPT. This field will be populated by Neutron and refer to\na back-end specific script that will be called from the virtualization\ndriver when the system is ready to connect the guest to a L2 network.\n\nWIP note: this is a proof-of-concept that is tracking a spec proposal\nthat is not yet approved.\n\nChange-Id: I3b27ba441c9c3e84c8f31b03ab630d6a1c49abb7\n'}]",23,162470,487acfb343cda855169d37be126598459b36ec84,79,19,9,6681,,,0,"WIP: Add support for VIF plugin script to Nova

This change introduces support for handling new VIF detail field,
VIF_PLUGIN_SCRIPT. This field will be populated by Neutron and refer to
a back-end specific script that will be called from the virtualization
driver when the system is ready to connect the guest to a L2 network.

WIP note: this is a proof-of-concept that is tracking a spec proposal
that is not yet approved.

Change-Id: I3b27ba441c9c3e84c8f31b03ab630d6a1c49abb7
",git fetch https://review.opendev.org/openstack/nova refs/changes/70/162470/8 && git format-patch -1 --stdout FETCH_HEAD,"['nova/tests/unit/test_netutils.py', 'nova/virt/libvirt/vif.py', 'nova/network/model.py', 'nova/tests/unit/virt/libvirt/test_vif.py', 'nova/virt/netutils.py']",5,493e2b42c52ce4e253f9669885f2591c743a4fae,bp/vif-plugin-script," from oslo_concurrency import processutils from oslo_config import cfg from oslo_log import log as logging from oslo_serialization import jsonutils from nova import exception from nova.i18n import _from nova import utilsLOG = logging.getLogger(__name__) def create_vif_plug_env(instance, vif): if not instance: raise exception.VirtualInterfacePlugException( _(""Instance must have a valid value"")) result = {} result['VIF_INSTANCE_ID'] = instance.uuid # # XXX the ovs_interfaceid thing bugs me. Why put OVS in there at # all.... why not just interfaceid or something? Making a VIF have type # specific fields rots me! # # Format (prefix, vif key, required value). If a required value is not # present - throws an exception. NOTE(beagles): I'm currently undecided # on how that should all fit - right now the decision of whether # something is a required value is that I can't see there being any # sensible script processing without it. env_mappings = [ ('VIF_ID', 'id', True), ('VIF_MAC_ADDRESS', 'address', False), ('VIF_DEVNAME', 'devname', True), ('VIF_OVS_INTERFACEID', 'ovs_interfaceid', False), ('VIF_VNIC_TYPE', 'vnic_type', True) ] detail_prefix = 'VIF_DETAILS_' for env_var_name, vif_field, required in env_mappings: field_data = vif.get(vif_field) if field_data: result[env_var_name] = field_data continue if required: raise exception.VirtualInterfacePlugException( _(""%s must have a valid value"") % vif_field) # XXX - are we going to need to do a jsondumps on this? If would be # expecting a lot for script to handle properly. Not doing it and # expecting this to work puts the onus on the producer of the # VIF_DETAIL. I'm going to do the jsonutils thing for now - but maybe # that isn't sufficient either. for name, value in vif.get('details', {}).iteritems(): result['%s%s' % (detail_prefix, name)] = jsonutils.dumps(value) return result def run_plug_script(instance, vif, scriptpath, command): environment_vars = create_vif_plug_env(instance, vif) try: utils.execute(scriptpath, command, env_variables=environment_vars) except processutils.ProcessExecutionError as e: LOG.exception(e) error_msg = _('Failed to {command} VIF with {script} script, ' 'error {err_code:d} {error}').format( command=command, script=scriptpath, err_code=e.exit_code, error=e.stderr) raise exception.VirtualInterfacePlugException(error_msg)",from oslo_config import cfg ,326,14
openstack%2Fnova~master~Ia0f463e08dc03afef11332aa6d1c643415e49d93,openstack/nova,master,Ia0f463e08dc03afef11332aa6d1c643415e49d93,WIP: Refactor Nova VIF model,ABANDONED,2015-03-24 16:08:45.000000000,2015-06-25 14:49:08.000000000,,"[{'_account_id': 3}, {'_account_id': 1779}, {'_account_id': 4393}, {'_account_id': 5170}, {'_account_id': 6681}, {'_account_id': 8871}, {'_account_id': 9008}, {'_account_id': 9578}, {'_account_id': 9732}, {'_account_id': 10118}, {'_account_id': 10385}, {'_account_id': 11103}, {'_account_id': 11604}, {'_account_id': 12340}, {'_account_id': 13734}, {'_account_id': 13869}, {'_account_id': 15286}, {'_account_id': 15751}]","[{'number': 1, 'created': '2015-03-24 16:08:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/62b0be27cb0a28e12db19921fdf159436f9d8081', 'message': 'WIP: Refactor Nova VIF model\n\nCreating separate classes for VIF types defines a clearer relationship\nbetween VIF type specific data an the respective VIF driver. Refactoring\nalso facilitates publishing VIF appropriate environments for the related\nbp/vif-plugin-script effort.\n\nChange-Id: Ia0f463e08dc03afef11332aa6d1c643415e49d93\n'}, {'number': 2, 'created': '2015-03-25 18:13:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/cdad99ea4a14c9d34efed917628fd4e68634c8b9', 'message': 'WIP: Refactor Nova VIF model\n\nCreating separate classes for VIF types defines a clearer relationship\nbetween VIF type specific data an the respective VIF driver. Refactoring\nalso facilitates publishing VIF appropriate environments for the related\nbp/vif-plugin-script effort.\n\nChange-Id: Ia0f463e08dc03afef11332aa6d1c643415e49d93\n'}, {'number': 3, 'created': '2015-04-21 12:18:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/4f7d78da637cce8326c7f64522469ef95bee5695', 'message': 'WIP: Refactor Nova VIF model\n\nCreating separate classes for VIF types defines a clearer relationship\nbetween VIF type specific data an the respective VIF driver. Refactoring\nalso facilitates publishing VIF appropriate environments for the related\nbp/vif-plugin-script effort.\n\nChange-Id: Ia0f463e08dc03afef11332aa6d1c643415e49d93\n'}, {'number': 4, 'created': '2015-05-11 12:32:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/141481ac508e5b65614820efca3ccc9fd47abb26', 'message': 'WIP: Refactor Nova VIF model\n\nCreating separate classes for VIF types defines a clearer relationship\nbetween VIF type specific data an the respective VIF driver. Refactoring\nalso facilitates publishing VIF appropriate environments for the related\nbp/vif-plugin-script effort.\n\nNOTE: Still a WIP. There are some cleanups left, including moving some\nclass definitions from one file to another and a few tests still need\nupdating.\n\nChange-Id: Ia0f463e08dc03afef11332aa6d1c643415e49d93\n'}, {'number': 5, 'created': '2015-05-25 19:27:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/aba84dae6b9bacf9ae54196d8b090a8cb21c4f13', 'message': 'WIP: Refactor Nova VIF model\n\nCreating separate classes for VIF types defines a clearer relationship\nbetween VIF type specific data an the respective VIF driver. Refactoring\nalso facilitates publishing VIF appropriate environments for the related\nbp/vif-plugin-script effort.\n\nNOTE: Still a WIP. There are some cleanups left, including moving some\nclass definitions from one file to another and a few tests still need\nupdating.\n\nChange-Id: Ia0f463e08dc03afef11332aa6d1c643415e49d93\n'}, {'number': 6, 'created': '2015-05-25 19:29:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/97e95e4543c09a6ee6edbf3eb1c4530e03b2d9f2', 'message': ""WIP: Refactor Nova VIF model\n\nCreating separate classes for VIF types defines a clearer relationship\nbetween VIF type specific data an the respective VIF driver. Refactoring\nalso facilitates publishing VIF appropriate environments for the related\nbp/vif-plugin-script effort.\n\nNOTE: WIP. There are some cleanups left, including changing vif_type\nattribute back to 'type' (breaks backwards compatibility) and fixup\nfunctional tests. Unit tests should be all up-to-date now.\n\nChange-Id: Ia0f463e08dc03afef11332aa6d1c643415e49d93\n""}, {'number': 7, 'created': '2015-05-26 13:40:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/f95187ab0a459fe4f28115ccd03e36dbc4fa8ab1', 'message': ""WIP: Refactor Nova VIF model\n\nCreating separate classes for VIF types defines a clearer relationship\nbetween VIF type specific data an the respective VIF driver. Refactoring\nalso facilitates publishing VIF appropriate environments for the related\nbp/vif-plugin-script effort.\n\nNOTE: WIP. There are some cleanups left, including changing vif_type\nattribute back to 'type' (breaks backwards compatibility).  Functional\ntests and unit tests should be all up-to-date now.\n\nChange-Id: Ia0f463e08dc03afef11332aa6d1c643415e49d93\n""}, {'number': 8, 'created': '2015-05-26 14:20:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/cf10079293c6b9161deb36ef1989be92d25f0913', 'message': 'WIP: Refactor Nova VIF model\n\nCreating NovaObject based versions of the contents of\nnova/network/model.py to add support for versioning, etc. Also greating\nseparate classes for VIF types defines a clearer relationship between\nVIF type specific data an the respective VIF driver functionality.\n\nNOTE: WIP. There are some cleanups left. Functional\ntests and unit tests should be all up-to-date now.\n\nChange-Id: Ia0f463e08dc03afef11332aa6d1c643415e49d93\n'}, {'number': 9, 'created': '2015-05-26 16:49:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/0dabbccb46b090cc50b8d15d3da3753a0b216280', 'message': 'WIP: Refactor Nova VIF model\n\nCreating NovaObject based versions of the contents of\nnova/network/model.py to add support for versioning, etc. Also greating\nseparate classes for VIF types defines a clearer relationship between\nVIF type specific data an the respective VIF driver functionality.\n\nNOTE: WIP - one cleanup left involving an apparently test specific\nworkaround. Functional tests and unit tests should be all up-to-date\nnow.\n\nChange-Id: Ia0f463e08dc03afef11332aa6d1c643415e49d93\n'}, {'number': 10, 'created': '2015-05-28 14:44:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/e36aa7b5e0051929023016393083384a896ef50b', 'message': 'WIP: Refactor Nova VIF model\n\nCreating NovaObject based versions of the contents of\nnova/network/model.py to add support for versioning, etc. Also greating\nseparate classes for VIF types defines a clearer relationship between\nVIF type specific data an the respective VIF driver functionality.\n\nNOTE: WIP - one cleanup left involving an apparently test specific\nworkaround. Functional tests and unit tests should be all up-to-date\nnow.\n\nChange-Id: Ia0f463e08dc03afef11332aa6d1c643415e49d93\n'}, {'number': 11, 'created': '2015-05-28 16:12:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/531b35a2ab6f9b3dd5842c5ef2c379e813420e49', 'message': 'WIP: Refactor Nova VIF model\n\nCreating NovaObject based versions of the contents of\nnova/network/model.py to add support for versioning, etc. Also greating\nseparate classes for VIF types defines a clearer relationship between\nVIF type specific data an the respective VIF driver functionality.\n\nNOTE: WIP - one cleanup left involving an apparently test specific\nworkaround. Functional tests and unit tests should be all up-to-date\nnow.\n\nChange-Id: Ia0f463e08dc03afef11332aa6d1c643415e49d93\n'}, {'number': 12, 'created': '2015-05-28 18:20:50.000000000', 'files': ['nova/tests/unit/network/test_network_info.py', 'nova/tests/unit/virt/hyperv/test_hypervapi.py', 'nova/tests/unit/network/test_api.py', 'nova/network/manager.py', 'nova/network/api.py', 'nova/tests/unit/compute/test_shelve.py', 'nova/tests/unit/utils.py', 'nova/compute/manager.py', 'nova/tests/unit/objects/test_network_info.py', 'nova/virt/libvirt/vif.py', 'nova/tests/unit/compute/test_compute.py', 'nova/objects/__init__.py', 'nova/tests/unit/cells/test_cells_messaging.py', 'nova/tests/unit/objects/test_instance_info_cache.py', 'nova/tests/unit/virt/libvirt/test_driver.py', 'nova/tests/unit/compute/test_compute_mgr.py', 'nova/tests/unit/objects/test_fields.py', 'nova/tests/unit/virt/vmwareapi/test_vmops.py', 'nova/tests/unit/api/ec2/test_cloud.py', 'nova/objects/instance.py', 'nova/tests/unit/fake_network_cache_model.py', 'nova/tests/unit/objects/test_instance.py', 'nova/objects/network_info.py', 'nova/tests/unit/network/test_manager.py', 'nova/tests/unit/fake_network.py', 'nova/tests/unit/network/test_neutronv2.py', 'nova/tests/unit/api/ec2/test_cinder_cloud.py', 'nova/tests/unit/test_notifications.py', 'nova/tests/unit/virt/vmwareapi/test_driver_api.py', 'nova/tests/unit/api/openstack/compute/contrib/test_floating_ips.py', 'nova/api/ec2/ec2utils.py', 'nova/network/neutronv2/api.py', 'nova/tests/unit/test_metadata.py', 'nova/notifications.py', 'nova/network/base_api.py', 'nova/tests/unit/virt/vmwareapi/test_vif.py', 'nova/compute/api.py', 'nova/compute/utils.py', 'nova/virt/vmwareapi/vif.py', 'nova/objects/fields.py', 'nova/cells/messaging.py', 'nova/tests/unit/compute/test_compute_utils.py', 'nova/objects/instance_info_cache.py', 'nova/tests/unit/objects/test_objects.py', 'nova/exception.py', 'nova/tests/unit/virt/ironic/test_driver.py', 'nova/network/model.py', 'nova/tests/unit/virt/libvirt/test_vif.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/dba057227753f6a824220af5364930e4aa589694', 'message': 'WIP: Refactor Nova VIF model\n\nCreating NovaObject based versions of the contents of\nnova/network/model.py to add support for versioning, etc. Also greating\nseparate classes for VIF types defines a clearer relationship between\nVIF type specific data an the respective VIF driver functionality.\n\nChange-Id: Ia0f463e08dc03afef11332aa6d1c643415e49d93\n'}]",23,167287,dba057227753f6a824220af5364930e4aa589694,112,18,12,6681,,,0,"WIP: Refactor Nova VIF model

Creating NovaObject based versions of the contents of
nova/network/model.py to add support for versioning, etc. Also greating
separate classes for VIF types defines a clearer relationship between
VIF type specific data an the respective VIF driver functionality.

Change-Id: Ia0f463e08dc03afef11332aa6d1c643415e49d93
",git fetch https://review.opendev.org/openstack/nova refs/changes/87/167287/9 && git format-patch -1 --stdout FETCH_HEAD,"['nova/network/neutronv2/api.py', 'nova/tests/unit/network/test_network_info.py', 'nova/network/manager.py', 'nova/network/model.py']",4,62b0be27cb0a28e12db19921fdf159436f9d8081,net-model-to-novaobjects,"VIF_TYPE_DVS = 'dvs' # XXX - What is this?# XXX - these are accessed in neutronv2/api.py but really these could be # a factory element and hidden. # XXX WHY ARE THESE HERE? Isn't this only used by virtualization drivers # - virtio is libvirt centric and the other interface types probably are # as well. At the very least, these should be constants in the virt # subdirectory - not here. # # XXX ---- The following two classes don't seem to be used anywhere but # in tests! ## TODO(beagles): base off of nova Object instead of the Model/dict thing. class BaseVIF(Model): details=None, devname=None, active=False, ovs_interfaceid=None, preserve_on_delete=False, **kwargs): super(BaseVIF, self).__init__() # NOTE(beagles): Consider changing name from ""type"" to avoid # confusion with builtin type() method. self['ovs_interfaceid'] = ovs_interfaceid self.hybrid_plug = self['details'].get(VIF_DETAILS_OVS_HYBRID_PLUG, False) # XXX Move to an OVS specific VIF type # for some reason IVS, etc. need this. def is_hybrid_plug_enabled(self): return self.hybrid_plug class QbgVIF(BaseVIF): def __init__(self, **kwargs): self['qbg_params'] = kwargs.pop('qbg_params', None) super(QbgVIF, self).__init__(**kwargs) class QbhVIF(BaseVIF): def __init__(self, **kwargs): self['qph_params'] = kwargs.pop('qbh_params', None) super(QbhVIF, self).__init__(**kwargs) class MellanoxVIF(BaseVIF): def __init__(self, **kwargs): super(MellanoxVIF, self).__init__(**kwargs) self.physical_network = self['network']['meta'].get('physical_network') if self.physical_network: self.physical_network = self['details'][ VIF_DETAILS_PHYSICAL_NETWORK] class MidonetVIF(BaseVIF): def __init__(self, **kwargs): super(MidonetVIF, self).__init__(**kwargs) def create_vif(**kwargs): # Add type specific VIF classes here. factory_map = { VIF_TYPE_802_QBG: QbgVIF, VIF_TYPE_802_QBH: QbhVIF, VIF_TYPE_MLNX_DIRECT: MellanoxVIF, VIF_TYPE_MIDONET: MidonetVIF } # TODO(beagles): check to see if VHOSTUSER needs the ovs interface # id or if the Base VIF class will do. # Instantiate using the VIF class, or use the BaseVIF class if there # isn't a specific mapping. return factory_map.get(kwargs.get('type'), BaseVIF)(**kwargs) def hydrate_vif(vif): vif = create_vif(**ensure_string_keys(vif)) vif['network'] = Network.hydrate(vif['network']) return vif # XXX we can delegate VIF(**kwargs) to create_vif() for the moment def VIF(**kwargs): return create_vif(**kwargs) return cls([hydrate_vif(vif) for vif in network_info])","VIF_TYPE_DVS = 'dvs'class VIF(Model): """"""Represents a Virtual Interface in Nova."""""" details=None, devname=None, ovs_interfaceid=None, qbh_params=None, qbg_params=None, active=False, preserve_on_delete=False, **kwargs): super(VIF, self).__init__() self['ovs_interfaceid'] = ovs_interfaceid self['qbh_params'] = qbh_params self['qbg_params'] = qbg_params def __eq__(self, other): keys = ['id', 'address', 'network', 'vnic_type', 'type', 'profile', 'details', 'devname', 'ovs_interfaceid', 'qbh_params', 'qbg_params', 'active', 'preserve_on_delete'] return all(self[k] == other[k] for k in keys) def __ne__(self, other): return not self.__eq__(other) def labeled_ips(self): """"""Returns the list of all IPs The return value looks like this flat structure:: {'network_label': 'my_network', 'network_id': 'n8v29837fn234782f08fjxk3ofhb84', 'ips': [{'address': '123.123.123.123', 'version': 4, 'type: 'fixed', 'meta': {...}}, {'address': '124.124.124.124', 'version': 4, 'type': 'floating', 'meta': {...}}, {'address': 'fe80::4', 'version': 6, 'type': 'fixed', 'meta': {...}}] """""" if self['network']: # remove unnecessary fields on fixed_ips ips = [IP(**ensure_string_keys(ip)) for ip in self.fixed_ips()] for ip in ips: # remove floating ips from IP, since this is a flat structure # of all IPs del ip['meta']['floating_ips'] # add floating ips to list (if any) ips.extend(self.floating_ips()) return {'network_label': self['network']['label'], 'network_id': self['network']['id'], 'ips': ips} return [] def is_hybrid_plug_enabled(self): return self['details'].get(VIF_DETAILS_OVS_HYBRID_PLUG, False) @classmethod def hydrate(cls, vif): vif = cls(**ensure_string_keys(vif)) vif['network'] = Network.hydrate(vif['network']) return vif return cls([VIF.hydrate(vif) for vif in network_info])",94,81
openstack%2Fkolla~master~I2fc2ded47bb2ed34fb1e272d35b0758f098ce0ac,openstack/kolla,master,I2fc2ded47bb2ed34fb1e272d35b0758f098ce0ac,Add retry parameter to build-docker-image,MERGED,2015-06-25 03:49:40.000000000,2015-06-25 14:45:14.000000000,2015-06-25 14:45:11.000000000,"[{'_account_id': 3}, {'_account_id': 2834}, {'_account_id': 3098}, {'_account_id': 9488}]","[{'number': 1, 'created': '2015-06-25 03:49:40.000000000', 'files': ['tools/build-docker-image'], 'web_link': 'https://opendev.org/openstack/kolla/commit/f370edfb70d30de222e6abf48dda1ec91283bd39', 'message': 'Add retry parameter to build-docker-image\n\nPartial-Bug: #1466677\nChange-Id: I2fc2ded47bb2ed34fb1e272d35b0758f098ce0ac\n'}]",0,195402,f370edfb70d30de222e6abf48dda1ec91283bd39,8,4,1,13039,,,0,"Add retry parameter to build-docker-image

Partial-Bug: #1466677
Change-Id: I2fc2ded47bb2ed34fb1e272d35b0758f098ce0ac
",git fetch https://review.opendev.org/openstack/kolla refs/changes/02/195402/1 && git format-patch -1 --stdout FETCH_HEAD,['tools/build-docker-image'],1,f370edfb70d30de222e6abf48dda1ec91283bd39,bug/1466677,"MAX_TRIES=1--retry <number_of_retries>ARGS=$(getopt -o hr:n:t:pfuN -l help,prefix:,namespace:,push,pull,private-registry:,release,tag:,force-rm,no-cache,no-use-released-parent,retry: -- ""$@"") || { usage >&2; exit 2; } (--retry) shift MAX_TRIES=$((MAX_TRIES + $1)) ;; TRY=0 while [ $((MAX_TRIES - 1)) -gt $TRY ]; do if docker build ${BUILDFLAGS} -t ""$FULLIMAGE"" $TMPDIR; then break else echo ""WARNING: failed to build $FULLIMAGE, retrying..."" TRY=$((TRY + 1)) fi done ","ARGS=$(getopt -o hr:n:t:pfuN -l help,prefix:,namespace:,push,pull,private-registry:,release,tag:,force-rm,no-cache,no-use-released-parent -- ""$@"") || { usage >&2; exit 2; }",19,1
openstack%2Fsecurity-doc~master~I948890e188245d3b32ead599f1c219215b0e0364,openstack/security-doc,master,I948890e188245d3b32ead599f1c219215b0e0364,Conslidated many of the small sections.,MERGED,2015-06-01 02:18:07.000000000,2015-06-25 14:44:41.000000000,2015-06-25 14:44:37.000000000,"[{'_account_id': 3}, {'_account_id': 979}, {'_account_id': 6547}, {'_account_id': 9162}, {'_account_id': 10281}, {'_account_id': 10497}, {'_account_id': 10670}, {'_account_id': 10897}, {'_account_id': 12325}, {'_account_id': 12442}, {'_account_id': 12686}, {'_account_id': 15299}]","[{'number': 1, 'created': '2015-06-01 02:18:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/security-doc/commit/b6e64c174a101bda19d755306a3cb3d236a2dced', 'message': 'Conslidated many of the small sections.\n\nChange-Id: I948890e188245d3b32ead599f1c219215b0e0364\nCloses-Bug: #1459040\n'}, {'number': 2, 'created': '2015-06-03 01:56:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/security-doc/commit/9074f6014fd68a1820d19e341ef2ca8437abdd25', 'message': 'Conslidated many of the small sections.\n\nChange-Id: I948890e188245d3b32ead599f1c219215b0e0364\nCloses-Bug: #1459040\n'}, {'number': 3, 'created': '2015-06-05 04:54:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/security-doc/commit/869869d8564672baa517118ced012f64d41e84d5', 'message': 'Conslidated many of the small sections.\n\nChange-Id: I948890e188245d3b32ead599f1c219215b0e0364\nCloses-Bug: #1459040\n'}, {'number': 4, 'created': '2015-06-25 06:30:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/security-doc/commit/a01e7c9d6f59bc48a6eaa3bf90b7f9532a29db1b', 'message': 'Conslidated many of the small sections.\n\nChange-Id: I948890e188245d3b32ead599f1c219215b0e0364\nCloses-Bug: #1459040\n'}, {'number': 5, 'created': '2015-06-25 11:11:31.000000000', 'files': ['security-guide/section_dashboard-https-hsts-xss-ssrf.xml', 'security-guide/section_dashboard-basic-web-server-configuration.xml', 'security-guide/section_dashboard-domain-names.xml', 'security-guide/section_dashboard-domains-dashboard-upgrades-basic-web-server-configuration.xml', 'security-guide/section_dashboard-cross-site-scripting-xss.xml', 'security-guide/section_dashboard-front-end-caching-session-back-end.xml', 'security-guide/section_dashboard-horizon-image-upload.xml', 'security-guide/section_dashboard-https.xml', 'security-guide/ch_dashboard.xml', 'security-guide/section_dashboard-http-strict-transport-security-hsts.xml', 'security-guide/section_dashboard-session-back-end.xml', 'security-guide/section_dashboard-front-end-caching.xml', 'security-guide/section_dashboard-cross-site-request-forgery-csrf.xml', 'security-guide/section_dashboard-allowed-hosts.xml', 'security-guide/section_dashboard-upgrading.xml'], 'web_link': 'https://opendev.org/openstack/security-doc/commit/9bcdfaf2cb85c72baafc5f08046733ca0af62dbf', 'message': 'Conslidated many of the small sections.\n\nChange-Id: I948890e188245d3b32ead599f1c219215b0e0364\nCloses-Bug: #1459040\n'}]",6,187092,9bcdfaf2cb85c72baafc5f08046733ca0af62dbf,34,12,5,15299,,,0,"Conslidated many of the small sections.

Change-Id: I948890e188245d3b32ead599f1c219215b0e0364
Closes-Bug: #1459040
",git fetch https://review.opendev.org/openstack/security-doc refs/changes/92/187092/1 && git format-patch -1 --stdout FETCH_HEAD,"['security-guide/section_dashboard-https-hsts-xss-ssrf.xml', 'security-guide/section_dashboard-basic-web-server-configuration.xml', 'security-guide/section_dashboard-cross-site-scripting-xss.xml', 'security-guide/section_dashboard-front-end-caching-session-back-end.xml', 'security-guide/section_dashboard-https.xml', 'security-guide/ch_dashboard.xml', 'security-guide/section_dashboard-http-strict-transport-security-hsts.xml', 'security-guide/section_dashboard-session-back-end.xml', 'security-guide/section_dashboard-front-end-caching.xml', 'security-guide/section_dashboard-domain-names-upgrading-configuration.xml', 'security-guide/section_dashboard-cross-site-request-forgery-csrf.xml', 'security-guide/section_dashboard-upgrading.xml']",12,b6e64c174a101bda19d755306a3cb3d236a2dced,1459040,,"<?xml version=""1.0"" encoding=""UTF-8""?> <section xmlns=""http://docbook.org/ns/docbook"" xmlns:xi=""http://www.w3.org/2001/XInclude"" xmlns:xlink=""http://www.w3.org/1999/xlink"" version=""5.0"" xml:id=""dashboard-upgrading""> <?dbhtml stop-chunking?> <title>Upgrading</title> <para>Django security releases are generally well tested and aggressively backwards compatible. In almost all cases, new major releases of Django are also fully backwards compatible with previous releases. Dashboard implementers are strongly encouraged to run the latest stable release of Django with up-to-date security releases.</para> </section> ",139,171
openstack%2Fpuppet-neutron~master~I1ba95a680a70524e4fe7fb07449163b690149aa8,openstack/puppet-neutron,master,I1ba95a680a70524e4fe7fb07449163b690149aa8,Fix Beaker CI according recent puppetlabs-rabbitmq change.,MERGED,2015-06-24 17:15:04.000000000,2015-06-25 14:35:33.000000000,2015-06-25 14:35:31.000000000,"[{'_account_id': 3}, {'_account_id': 1607}, {'_account_id': 3153}, {'_account_id': 7155}, {'_account_id': 8482}, {'_account_id': 9500}]","[{'number': 1, 'created': '2015-06-24 17:15:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-neutron/commit/3ecf04e3409b95f6a8ee226bfc09b0acbe173951', 'message': 'Fix Beaker CI according recent puppetlabs-rabbitmq change.\n\nThe puppetlabs-rabbitmq module introduce a new feature related to the\nerlang_cookie parameter change (the database must be wiped if the cookie is\nchanged), the parameter wipe_db_on_cookie_change is configured to false by\ndefault.\n\nChange-Id: I1ba95a680a70524e4fe7fb07449163b690149aa8\nCloses-Bug: #1468444\n'}, {'number': 2, 'created': '2015-06-24 22:11:19.000000000', 'files': ['spec/acceptance/basic_neutron_spec.rb'], 'web_link': 'https://opendev.org/openstack/puppet-neutron/commit/25a4559bd656a1e45507eaf532f49ba151710560', 'message': ""Fix Beaker CI according recent puppetlabs-rabbitmq change.\n\nThe puppetlabs-rabbitmq module introduce a new feature related to the\nerlang_cookie parameter change (the database must be wiped if the cookie is\nchanged), the parameter wipe_db_on_cookie_change is configured to false by\ndefault.\n\nBut we're not setting up a rabbitmq cluster and we're not using pacemaker in\nbeaker CI tests, so we just remove the erlang cookie parameter change.\n\nChange-Id: I1ba95a680a70524e4fe7fb07449163b690149aa8\nCloses-Bug: #1468444\n""}]",0,195202,25a4559bd656a1e45507eaf532f49ba151710560,29,6,2,7155,,,0,"Fix Beaker CI according recent puppetlabs-rabbitmq change.

The puppetlabs-rabbitmq module introduce a new feature related to the
erlang_cookie parameter change (the database must be wiped if the cookie is
changed), the parameter wipe_db_on_cookie_change is configured to false by
default.

But we're not setting up a rabbitmq cluster and we're not using pacemaker in
beaker CI tests, so we just remove the erlang cookie parameter change.

Change-Id: I1ba95a680a70524e4fe7fb07449163b690149aa8
Closes-Bug: #1468444
",git fetch https://review.opendev.org/openstack/puppet-neutron refs/changes/02/195202/1 && git format-patch -1 --stdout FETCH_HEAD,['spec/acceptance/basic_neutron_spec.rb'],1,3ecf04e3409b95f6a8ee226bfc09b0acbe173951,bug-1468444," delete_guest_user => true, erlang_cookie => 'secrete', wipe_db_on_cookie_change => true, package_provider => $package_provider,"," delete_guest_user => true, erlang_cookie => 'secrete', package_provider => $package_provider,",4,3
openstack%2Ftelemetry-specs~master~I3482759bd54d31c0e6c707cb8a8e4bd742dfd6a6,openstack/telemetry-specs,master,I3482759bd54d31c0e6c707cb8a8e4bd742dfd6a6,Add log translation hints for ceilometer,ABANDONED,2014-07-09 12:43:18.000000000,2015-06-25 14:34:11.000000000,,"[{'_account_id': 3}, {'_account_id': 3012}, {'_account_id': 4491}, {'_account_id': 6537}, {'_account_id': 6676}, {'_account_id': 11564}]","[{'number': 1, 'created': '2014-07-09 12:43:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/telemetry-specs/commit/7e8d16cc4c618c46e3a8bbdfd719a6a521e8940f', 'message': 'Add log translation hints for ceilometer\n\nCurrent oslo libraries support translating log messages using different\ntranslation domains and oslo would like to see hints in all of our code\nby the end of juno. So ceilometer should handle the changes out over the\nrelease.Relate info about log translation hints as follows:\n    https://blueprints.launchpad.net/oslo/+spec/log-messages-translation-domain-rollout\n    https://review.openstack.org/#/c/70455\n\nblueprint support-log-translation-hints\n\nChange-Id: I3482759bd54d31c0e6c707cb8a8e4bd742dfd6a6\n'}, {'number': 2, 'created': '2014-07-09 12:51:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/telemetry-specs/commit/effba6f366fe00ee7f23d45adf16c2402aae6340', 'message': 'Add log translation hints for ceilometer\n\nCurrent oslo libraries support translating log messages using different\ntranslation domains and oslo would like to see hints in all of our code\nby the end of juno. So ceilometer should handle the changes out over the\nrelease.Relate info about log translation hints as follows:\n    https://blueprints.launchpad.net/oslo/+spec/log-messages-translation-domain-rollout\n    https://review.openstack.org/#/c/70455\n\nblueprint support-log-translation-hints\n\nChange-Id: I3482759bd54d31c0e6c707cb8a8e4bd742dfd6a6\n'}, {'number': 3, 'created': '2014-07-09 12:53:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/telemetry-specs/commit/4a7c1724517dbbd3f9ed77795167da1380384b9b', 'message': 'Add log translation hints for ceilometer\n\nCurrent oslo libraries support translating log messages using different\ntranslation domains and oslo would like to see hints in all of our code\nby the end of juno. So ceilometer should handle the changes out over the\nrelease.Relate info about log translation hints as follows:\n    https://blueprints.launchpad.net/oslo/+spec/log-messages-translation-domain-rollout\n    https://review.openstack.org/#/c/70455\n\nblueprint support-log-translation-hints\n\nChange-Id: I3482759bd54d31c0e6c707cb8a8e4bd742dfd6a6\n'}, {'number': 4, 'created': '2014-07-09 12:58:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/telemetry-specs/commit/783768c9b4409c65573aca7fa97075e973a81546', 'message': 'Add log translation hints for ceilometer\n\nCurrent oslo libraries support translating log messages using different\ntranslation domains and oslo would like to see hints in all of our code\nby the end of juno. So ceilometer should handle the changes out over the\nrelease.Relate info about log translation hints as follows:\n    https://blueprints.launchpad.net/oslo/+spec/log-messages-translation-domain-rollout\n    https://review.openstack.org/#/c/70455\n\nblueprint support-log-translation-hints\n\nChange-Id: I3482759bd54d31c0e6c707cb8a8e4bd742dfd6a6\n'}, {'number': 5, 'created': '2014-07-09 13:11:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/telemetry-specs/commit/f585c6a4a5abba186d5c76a83508c5f975ffcbd0', 'message': 'Add log translation hints for ceilometer\n\nCurrent oslo libraries support translating log messages using different\ntranslation domains and oslo would like to see hints in all of our code\nby the end of juno. So ceilometer should handle the changes out over the\nrelease.Relate info about log translation hints as follows:\n    https://blueprints.launchpad.net/oslo/+spec/log-messages-translation-domain-rollout\n    https://review.openstack.org/#/c/70455\n\nblueprint support-log-translation-hints\n\nChange-Id: I3482759bd54d31c0e6c707cb8a8e4bd742dfd6a6\n'}, {'number': 6, 'created': '2014-07-09 13:33:29.000000000', 'files': ['specs/juno/support-log-translation-hints.rst'], 'web_link': 'https://opendev.org/openstack/telemetry-specs/commit/cb179577db936dbfc9678ed72eeb7f54ffe6dfe0', 'message': 'Add log translation hints for ceilometer\n\nCurrent oslo libraries support translating log messages using different\ntranslation domains and oslo would like to see hints in all of our code\nby the end of juno. So ceilometer should handle the changes out over the\nrelease.Relate info about log translation hints as follows:\n    https://blueprints.launchpad.net/oslo/+spec/log-messages-translation-domain-rollout\n    https://review.openstack.org/#/c/70455\n\nblueprint support-log-translation-hints\n\nChange-Id: I3482759bd54d31c0e6c707cb8a8e4bd742dfd6a6\n'}]",0,105727,cb179577db936dbfc9678ed72eeb7f54ffe6dfe0,29,6,6,8874,,,0,"Add log translation hints for ceilometer

Current oslo libraries support translating log messages using different
translation domains and oslo would like to see hints in all of our code
by the end of juno. So ceilometer should handle the changes out over the
release.Relate info about log translation hints as follows:
    https://blueprints.launchpad.net/oslo/+spec/log-messages-translation-domain-rollout
    https://review.openstack.org/#/c/70455

blueprint support-log-translation-hints

Change-Id: I3482759bd54d31c0e6c707cb8a8e4bd742dfd6a6
",git fetch https://review.opendev.org/openstack/telemetry-specs refs/changes/27/105727/3 && git format-patch -1 --stdout FETCH_HEAD,['specs/juno/support-log-translation-hints.rst'],1,7e8d16cc4c618c46e3a8bbdfd719a6a521e8940f,bp/s,".. This work is licensed under a Creative Commons Attribution 3.0 Unported License. http://creativecommons.org/licenses/by/3.0/legalcode ==================================== Add log translation hints for ceilometer ==================================== https://blueprints.launchpad.net/ceilometer/+spec/support-log-translation-hints To update ceilometer log messages to take advantage of oslo's new feature of supporting translating log messages using different translation domains. Problem description =================== Current oslo libraries support translating log messages using different translation domains and oslo would like to see hints in all of our code by the end of juno. So ceilometer should handle the changes out over the release. Proposed change =============== Since there are too many files need to change, so divide this bp into 20 patches according to ceilometer directories. ceilometer  alarm  api  central  compute  dispatcher  energy  event  hardware  image  network  objectstore  openstack  orchestration  profiler  publisher  storage  tests  transformer  volume For each directory's files, we change all the log messages as follows. 1. Change ""LOG.exception(_("" to ""LOG.exception(_LE"". 2. Change ""LOG.warn(_("" to ""LOG.warn(_LW("". 3. Change ""LOG.info(_("" to ""LOG.info(_LI("". 4. Change ""LOG.critical(_("" to ""LOG.info(_LC("". Data model impact ----------------- None REST API impact --------------- None Security impact --------------- None Notifications impact -------------------- None Other end user impact --------------------- None Performance Impact ------------------ None Other deployer impact --------------------- Developer impact ---------------- None Implementation ============== Assignee(s) ----------- Primary assignee: Work Items ---------- For each directory's files, we change all the log messages as follows. 1. Change ""LOG.exception(_("" to ""LOG.exception(_LE"". 2. Change ""LOG.warn(_("" to ""LOG.warn(_LW("". 3. Change ""LOG.info(_("" to ""LOG.info(_LI("". 4. Change ""LOG.critical(_("" to ""LOG.info(_LC("". We handle these changes in the following order: ceilometer ceilometer/alarm ceilometer/api ceilometer/central ceilometer/compute ceilometer/dispatcher ceilometer/energy ceilometer/event ceilometer/hardware ceilometer/image ceilometer/network ceilometer/objectstore ceilometer/openstack ceilometer/orchestration ceilometer/profiler ceilometer/publisher ceilometer/storage ceilometer/tests ceilometer/transformer ceilometer/volume Add a HACKING check rule to ensure that log messages to relative domain. Using regular expression to check whether log messages with relative _L* function. log_translation_domain_error = re.compile( r""(.)*LOG\.error\(\s*_LE\(('|\"")"") log_translation_domain_info = re.compile( r""(.)*LOG\.info\(\s*_LI\(('|\"")"") log_translation_domain_warn = re.compile( r""(.)*LOG\.(warn|warning)\(\s*_LW\(('|\"")"") log_translation_domain_critical = re.compile( r""(.)*LOG\.critical\(\s*_LC\(('|\"")"") Dependencies ============ None Testing ======= None Documentation Impact ==================== None References ========== [1]https://blueprints.launchpad.net/oslo/+spec/log-messages-translation-domain-rollout [2]https://review.openstack.org/#/c/70455 [3]https://wiki.openstack.org/wiki/LoggingStandards",,167,0
openstack%2Ftelemetry-specs~master~I0a45a9743f56e411d510dc94708c761fde832c34,openstack/telemetry-specs,master,I0a45a9743f56e411d510dc94708c761fde832c34,Zabbix Metrics Collection in Ceilometer,ABANDONED,2014-06-26 04:03:05.000000000,2015-06-25 14:33:14.000000000,,"[{'_account_id': 3}, {'_account_id': 882}, {'_account_id': 1669}, {'_account_id': 2284}, {'_account_id': 7052}, {'_account_id': 9562}]","[{'number': 1, 'created': '2014-06-26 04:03:05.000000000', 'files': ['specs/juno/zabbix-metrics-collection.rst'], 'web_link': 'https://opendev.org/openstack/telemetry-specs/commit/7bc9313ca80e97801ba65090f12a3510ccd65410', 'message': 'Zabbix Metrics Collection in Ceilometer\n\nChange-Id: I0a45a9743f56e411d510dc94708c761fde832c34\n'}]",13,102713,7bc9313ca80e97801ba65090f12a3510ccd65410,14,6,1,882,,,0,"Zabbix Metrics Collection in Ceilometer

Change-Id: I0a45a9743f56e411d510dc94708c761fde832c34
",git fetch https://review.opendev.org/openstack/telemetry-specs refs/changes/13/102713/1 && git format-patch -1 --stdout FETCH_HEAD,['specs/juno/zabbix-metrics-collection.rst'],1,7bc9313ca80e97801ba65090f12a3510ccd65410,bp/zabbix-metrics-collection,".. This work is licensed under a Creative Commons Attribution 3.0 Unported License. http://creativecommons.org/licenses/by/3.0/legalcode ==================================== Collect Zabbix metrics in Ceilometer ==================================== This blueprint aims at taking advantage of customers' existing Zabbix deployment, getting the metrics collected by Zabbix to Ceilometer so that we have a single place - Ceilometer, storing all the measurements from top to bottom. Problem description =================== Currently, in Ceilometer, our metering data is collected via Openstack components and hypervisors on the compute nodes. This makes sure that the metrics above the hypervisor layer are covered. On the another hand, Zabbix, as an enterprise-class open source monitoring tool, has been widely deployed in many production environments to collect hardware level metrics, such as fan speed, power status, router up-time etc. In openstack environment, those metrics collected by Zabbix can be highly valuable from the system administration perspective. Out of the box, Zabbix supports SNMP, IPMI, JMX etc as well. The metrics from Zabbix can be a very good complement to the existing Ceilometer metrics. Proposed change =============== Since Zabbix has a set of Json-Rpc API over HTTP, The idea is to add a pollster in Ceilometer's central agent with a HTTP client periodically calling Zabbix API to get the latest monitoring items, then the corresponding Ceilometer samples can be generated based on them. Each Zabbix item corresponds to a Ceilometer meter, and the Zabbix item value corresponds to a Ceilometer sample volume. The relationship roughly looks like below:: ceilometer.sample.name = zabbix.item.key ceilometer.sample.volume = zabbix.item.lastvalue ceilometer.sample.resource_id = zabbix.item.hostid ceilometer.sample.timestamp = zabbix.item.lastclock ceilometer.sample.unit = zabbix.item.units ceilometer.sample.type = ""gauge"" ceilometer.sample.user_id = user_id ceilometer.sample.project_id = project_id ceilometer.sample.resource_meta = """" ceilometer.sample.source = ""zabbix"" Alternatives ------------ None Data model impact ----------------- None REST API impact --------------- None Security impact --------------- None Pipeline impact --------------- Pipeline.yaml needs to be updated if there is some specific changes need to be made against the Zabbix metrics in the pipeline. Other end user impact --------------------- None Performance/Scalability Impacts ------------------------------- None Other deployer impact --------------------- Dedicated sources and sinks for Zabbix metrics can be defined so that only desired items will be collected. An example below:: sources: - name: zabbix_meter interval: 600 meters: - ""system.fan"" - ""system.users.num"" sinks: - zabbix_sink sinks: - name: zabbix_sink transformers: publishers: - rpc:// Developer impact ---------------- None Implementation ============== Assignee(s) ----------- Primary assignee: * shengjie-min Other contributors: * dingyuan-rao Ongoing maintainer: * dingyuan-rao Work Items ---------- * Implement the Zabbix pollster * Register Zabbix pollster in the central agent * Finish the Deployment Configuration wiki Future lifecycle ================ None Dependencies ============ None Testing ======= None Documentation Impact ==================== None References ========== None ",,163,0
openstack%2Ftelemetry-specs~master~I819cbc2fa30e2ab6af2103ef188179a22e7e9e7d,openstack/telemetry-specs,master,I819cbc2fa30e2ab6af2103ef188179a22e7e9e7d,Central Agent High Availability in Active/Active State,ABANDONED,2014-06-19 18:16:50.000000000,2015-06-25 14:31:58.000000000,,"[{'_account_id': 3}, {'_account_id': 2284}, {'_account_id': 3012}, {'_account_id': 6537}, {'_account_id': 7052}, {'_account_id': 7336}, {'_account_id': 8052}, {'_account_id': 9562}, {'_account_id': 10987}, {'_account_id': 11549}, {'_account_id': 11564}]","[{'number': 1, 'created': '2014-06-19 18:16:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/telemetry-specs/commit/6c1b7ee0a33ca1c5d5583cddddc7f4d1c03db24e', 'message': 'Central Agent High Availability in Active/Active State\n\nThe central agent (a.k.a. pollster) is responsible of gathering data from a\nvariety of services and publish them to the queue infrastructure. This\ncomponent must be deployed and run as a single instance on all the cloud IaaS\nmaking it hard to achieve reliably high availability.\nThe current proposal modifies the central agent behavior allowing several to\nrun simultaneously sharing/competing for the resources to pull from.\nThis is achieved enabling the pipeline to be held in the database adding the\npotential benefit of dynamic changes without service interruption/restart.\n\nblueprint task-distribution-for-central-agents\n\nDocImpact\n\nChange-Id: I819cbc2fa30e2ab6af2103ef188179a22e7e9e7d\n'}, {'number': 2, 'created': '2014-06-20 04:01:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/telemetry-specs/commit/b27fe930cc64b48d349b34f4c3f98467c88c9182', 'message': 'Central Agent High Availability in Active/Active State\n\nThe central agent (a.k.a. pollster) is responsible of gathering data from a\nvariety of services and publish them to the queue infrastructure. This\ncomponent must be deployed and run as a single instance on all the cloud IaaS\nmaking it hard to achieve reliably high availability.\nThe current proposal modifies the central agent behavior allowing several to\nrun simultaneously sharing/competing for the resources to pull from.\nThis is achieved enabling the pipeline to be held in the database adding the\npotential benefit of dynamic changes without service interruption/restart.\n\nblueprint task-distribution-for-central-agents\n\nDocImpact\n\nChange-Id: I819cbc2fa30e2ab6af2103ef188179a22e7e9e7d\n'}, {'number': 3, 'created': '2014-06-21 00:05:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/telemetry-specs/commit/5f21762ccd87e2d294885abdd80fbc24c38d2511', 'message': 'Central Agent High Availability in Active/Active State\n\nThe central agent (a.k.a. pollster) is responsible of gathering data from a\nvariety of services and publish them to the queue infrastructure. This\ncomponent must be deployed and run as a single instance on all the cloud IaaS\nmaking it hard to achieve reliably high availability.\nThe current proposal modifies the central agent behavior allowing several to\nrun simultaneously sharing/competing for the resources to pull from.\nThis is achieved enabling the pipeline to be held in the database adding the\npotential benefit of dynamic changes without service interruption/restart.\n\nblueprint task-distribution-for-central-agents\n\nDocImpact\n\nChange-Id: I819cbc2fa30e2ab6af2103ef188179a22e7e9e7d\n'}, {'number': 4, 'created': '2014-06-24 16:06:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/telemetry-specs/commit/9b59232e397a626c9d6b427155f4472bbeece24a', 'message': 'Central Agent High Availability in Active/Active State\n\nThe central agent (a.k.a. pollster) is responsible of gathering data from a\nvariety of services and publish them to the queue infrastructure. This\ncomponent must be deployed and run as a single instance on all the cloud IaaS\nmaking it hard to achieve reliably high availability.\nThe current proposal modifies the central agent behavior allowing several to\nrun simultaneously sharing/competing for the resources to pull from.\nThis is achieved enabling the pipeline to be held in the database adding the\npotential benefit of dynamic changes without service interruption/restart.\n\nblueprint task-distribution-for-central-agents\n\nDocImpact\n\nChange-Id: I819cbc2fa30e2ab6af2103ef188179a22e7e9e7d\n'}, {'number': 5, 'created': '2014-06-26 14:44:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/telemetry-specs/commit/bcfae822789858bca96c2ae8684d22e2dbeb6441', 'message': ""Central Agent High Availability in Active/Active State\n\nThe Central Agent is responsible of gathering data from a variety of services\nand publish them to the queue infrastructure. It also coordinates and runs a\nset of polling tasks that collect the data from services' endpoints.\nThis component must be deployed and run as a single instance on all the cloud\nIaaS making it hard to achieve reliably high availability.\nThe current proposal modifies the central agent behavior allowing several\nAgents to run simultaneously sharing/competing for the resources to pull from.\nThis is achieved creating a resource-agent assignment table during the pipeline\ndata parsing and to be held in the database. The resource-agent table indicates\nwhich Agent is currently polling a given resource.\n\nblueprint task-distribution-for-central-agents\n\nDocImpact\n\nChange-Id: I819cbc2fa30e2ab6af2103ef188179a22e7e9e7d\n""}, {'number': 6, 'created': '2014-08-06 16:41:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/telemetry-specs/commit/37c1644829de38bf14eb4eff1cc43146b59ea093', 'message': ""Central Agent High Availability in Active/Active State\n\nThe Central Agent is responsible for gathering data from a variety of services\nand publishing them to the queue infrastructure. It also coordinates and runs\na set of polling tasks that collect the data from services' endpoints.\nThis component must be deployed and run as a single instance on all the cloud\nIaaS making it hard to achieve reliably high availability.\nThe current proposal modifies the central agent behavior allowing several\nAgents to run simultaneously sharing/competing for the resources to pull from.\nThis is achieved creating a resource-agent assignment table during the pipeline\ndata parsing and to be held in the database. The resource-agent table indicates\nwhich Agent is currently polling a given resource.\n\nDocImpact\n\nChange-Id: I819cbc2fa30e2ab6af2103ef188179a22e7e9e7d\n""}, {'number': 7, 'created': '2014-08-06 16:44:15.000000000', 'files': ['specs/juno/central_agent_ha_active_active.rst'], 'web_link': 'https://opendev.org/openstack/telemetry-specs/commit/51901de2ca075c19fde92eaebdc3cb8bbdd873e9', 'message': ""Central Agent High Availability in Active/Active State\n\nThe Central Agent is responsible for gathering data from a variety of services\nand publishing them to the queue infrastructure. It also coordinates and runs\na set of polling tasks that collect the data from services' endpoints.\nThis component must be deployed and run as a single instance on all the cloud\nIaaS making it hard to achieve reliably high availability.\nThe current proposal modifies the central agent behavior allowing several\nAgents to run simultaneously sharing/competing for the resources to pull from.\nThis is achieved creating a resource-agent assignment table during the pipeline\ndata parsing and to be held in the database. The resource-agent table indicates\nwhich Agent is currently polling a given resource.\n\nDocImpact\n\nChange-Id: I819cbc2fa30e2ab6af2103ef188179a22e7e9e7d\n""}]",16,101282,51901de2ca075c19fde92eaebdc3cb8bbdd873e9,60,11,7,7052,,,0,"Central Agent High Availability in Active/Active State

The Central Agent is responsible for gathering data from a variety of services
and publishing them to the queue infrastructure. It also coordinates and runs
a set of polling tasks that collect the data from services' endpoints.
This component must be deployed and run as a single instance on all the cloud
IaaS making it hard to achieve reliably high availability.
The current proposal modifies the central agent behavior allowing several
Agents to run simultaneously sharing/competing for the resources to pull from.
This is achieved creating a resource-agent assignment table during the pipeline
data parsing and to be held in the database. The resource-agent table indicates
which Agent is currently polling a given resource.

DocImpact

Change-Id: I819cbc2fa30e2ab6af2103ef188179a22e7e9e7d
",git fetch https://review.opendev.org/openstack/telemetry-specs refs/changes/82/101282/3 && git format-patch -1 --stdout FETCH_HEAD,['specs/juno/central_agent_ha_active_active.rst'],1,6c1b7ee0a33ca1c5d5583cddddc7f4d1c03db24e,central-agent-active-active-ha,".. This work is licensed under a Creative Commons Attribution 3.0 Unported License. http://creativecommons.org/licenses/by/3.0/legalcode ====================================================== Central Agent High Availability in Active/Active State ====================================================== https://blueprints.launchpad.net/ceilometer/+spec/task-distribution-for-central-agents https://blueprints.launchpad.net/ceilometer/+spec/high-availability The central agent (a.k.a. pollster) is responsible of gathering data from a variety of services and publish them to the queue infrastructure. This component must be deployed and run as a single instance on all the cloud IaaS making it hard to achieve reliably high availability. The current proposal modifies the central agent behavior allowing several to run simultaneously sharing/competing for the resources to pull from. This is achieved enabling the pipeline to be held in the database adding the potential benefit of dynamic changes without service interruption/restart. Problem description =================== Proposed change =============== There are several changes needed to move the Central Agent to support multiple instances running in parallel actively contributing in polling resources. These can be separated and implemented in steps: * Parse and store pipeline in the backend. The idea here is to set-up the configuration file to allow pipeline to be dynamic and stored on a specific driver that can be the same or different to where the other data is stored. This will add the benefit of potentially add API to dynamically change the pipeline without restarting the pollster. * Add pollster HA specific data to the pipeline table and have it populate at the start of polling. The pollster, for each source available in the pipeline table, will add its process id and server IP letting the other pollsters that it has ownership of that source. Every time the polling has been completed it will update the timestamp signaling its aliveness. The Central Agent will adopt this strategy creating de-facto a monitoring that can be leveraged. This could be, for instance, leveraged by the existing alert mechanisms. * Enable multiple pollsters competing for sources. When a pollster is started, it will check if there are sources that do not have a pollster associated. If that is the case it will add its pID and IP address and start polling at the source interval. Each pollster will take a source and if none are currently available will sleep for the shortest interval in the available sources set. Once a pollster is not updating the timestamp the other pollster will check the queue to see if the pollster is in a long data pulling process. If that is not the case, meaning: there is no activity for a given amount of time (which should be configurable), e.g. twice the longest interval in the associate source(s), one of the pollster will stop/kill the running compromised pollster and take over. Alternatives ------------ There are a few alternatives in reaching HA ensuring that only a single process is running: * Active/Passive cluster. A HA cluster is created and one node is set to active and the other node(s) are set to passive. When the active node is not responding anymore the passive nodes are trying to became active stopping the unreliable/unreachable previously active node. * Active/Passive cluster with election. It is similar to the simple Active/Passive but as soon as the active is not responsive the various passive are trying to be elected as active. The election can be done using priorities, regions (resource stickiness) or even using an arbiter. The advantage of using elections is that it is less common to enter in a split-brain situation. * Monitoring with alert. This is a manual approach where the process is monitored and if connection is lost an event is sent (e.g. e-mail to admin). The operator can then start the process in an alternative location whist manually removing/killing the former active process. Data model impact ----------------- SQL Databases New tables to support the pipeline storage are created: ====================================== ======== Sources Table Type ====================================== ======== sources.id varchar sources.name varchar sources.interval time ====================================== ======== The Resources and Meters tables are already available in the model. TODO: define structure for sinks, transformers and publishers or keep them as a wide columns in the source tables. No-SQL Databases In the No-SQL the data can be stored as directly as a JSON document. The sources document is: { ""id"": uuid, ""name"": source_1, ""interval"": interval_time, ""meters"" : [""meter_1"", ""meter_2""], ""resources"": [""resource_uri1"", ""resource_uri2""], ""sinks"" : [""sink_uuid_1"", ""sink_uuid_2""] } The sinks document is: { ""id"": uuid ""name"": sink_1, ""transformers"": [ {""name"": ""Transformer_1"", ""parameters"": {""p1"": ""value""}}, {""name"": ""Transformer_2"", ""parameters"": {""p1"": ""value""}}, ], ""publishers"": [""publisher_1"", ""publisher_2""] } For HA specific needs another table is created and supported only in transactional databases. The Pollster Activity Table has the following fields: =========================== ========== Field Name Field Type =========================== ========== source_id varchar last_successful_poll timestamp pollster_pid integer pollster_server_ip_address varchar =========================== ========== REST API impact --------------- None Security impact --------------- None Pipeline impact --------------- The pipeline configuration can still be expressed as a yaml file and loaded in the database when the pollster starts. Changes can be added through an API which is beyond the scope of this proposal. Other end user impact --------------------- None Performance/Scalability Impacts ------------------------------- Now the pollsters can run on several nodes concurrently and jointly polling data from sources. This has a positive impact both on scalability and performance. It also eliminates the current single point of failure. Other deployer impact --------------------- TODO Developer impact ---------------- TODO Implementation ============== Assignee(s) ----------- Primary assignee: fabgia Other contributors: <launchpad-id or None> Ongoing maintainer: <launchpad-id or None> Work Items ---------- TODO Future lifecycle ================ TODO Dependencies ============ TODO Testing ======= TODO Documentation Impact ==================== TODO References ========== TODO ",,234,0
openstack%2Ftelemetry-specs~master~Ib0709ad44ef49e4fb5ebb3cd3a54d7ebf008d072,openstack/telemetry-specs,master,Ib0709ad44ef49e4fb5ebb3cd3a54d7ebf008d072,Add the instance active intervals Meter,ABANDONED,2014-07-04 08:04:13.000000000,2015-06-25 14:31:02.000000000,,"[{'_account_id': 3}, {'_account_id': 882}, {'_account_id': 1669}, {'_account_id': 2284}, {'_account_id': 3012}, {'_account_id': 6537}, {'_account_id': 7052}, {'_account_id': 8052}, {'_account_id': 9320}, {'_account_id': 9562}, {'_account_id': 10987}, {'_account_id': 11564}, {'_account_id': 12260}]","[{'number': 1, 'created': '2014-07-04 08:04:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/telemetry-specs/commit/8daf6b85883a21d6fc693d3ed3fda7af45732b79', 'message': 'Add the instance uptime as a Ceilometer Meter\n\nChange-Id: Ib0709ad44ef49e4fb5ebb3cd3a54d7ebf008d072\n'}, {'number': 2, 'created': '2014-07-04 08:10:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/telemetry-specs/commit/cf187ca45e7fb6c92c0e753c4251bc48758e4229', 'message': 'Add the instance uptime as a Ceilometer Meter\n\nChange-Id: Ib0709ad44ef49e4fb5ebb3cd3a54d7ebf008d072\n'}, {'number': 3, 'created': '2014-07-15 06:30:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/telemetry-specs/commit/c51962cd5d7a6de8e63b22ada8995721f0ada5cf', 'message': 'Add the instance uptime as a Ceilometer Meter\n\nChange-Id: Ib0709ad44ef49e4fb5ebb3cd3a54d7ebf008d072\n'}, {'number': 4, 'created': '2014-07-16 01:30:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/telemetry-specs/commit/a581199cedd8e1b342ab7d0f40d7d02c07037652', 'message': 'Add the instance uptime as a Ceilometer Meter\n\nChange-Id: Ib0709ad44ef49e4fb5ebb3cd3a54d7ebf008d072\n'}, {'number': 5, 'created': '2014-07-16 01:36:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/telemetry-specs/commit/f329e95934b2743af238d2909dbce7bdd9129b99', 'message': 'Add the instance uptime as a Ceilometer Meter\n\nChange-Id: Ib0709ad44ef49e4fb5ebb3cd3a54d7ebf008d072\n'}, {'number': 6, 'created': '2014-07-23 08:09:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/telemetry-specs/commit/82c00cbbfc84e5606b0ed726146b4ea4e49baf37', 'message': 'Add the instance active intervals Meter\n\nChange-Id: Ib0709ad44ef49e4fb5ebb3cd3a54d7ebf008d072\n'}, {'number': 7, 'created': '2014-07-23 10:02:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/telemetry-specs/commit/d8b351db135b94df2188d1a1a6ff4c594e040823', 'message': 'Add the instance active intervals Meter\n\nChange-Id: Ib0709ad44ef49e4fb5ebb3cd3a54d7ebf008d072\n'}, {'number': 8, 'created': '2014-07-24 01:15:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/telemetry-specs/commit/d66927dbca58efa2f72aa6b08ca00896cc9ea323', 'message': 'Add the instance active intervals Meter\n\nChange-Id: Ib0709ad44ef49e4fb5ebb3cd3a54d7ebf008d072\n'}, {'number': 9, 'created': '2014-07-24 03:53:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/telemetry-specs/commit/477fddd12cf65751ef9ae082fd0672cc2100e7d5', 'message': 'Add the instance active intervals Meter\n\nChange-Id: Ib0709ad44ef49e4fb5ebb3cd3a54d7ebf008d072\n'}, {'number': 10, 'created': '2014-07-25 01:21:03.000000000', 'files': ['specs/juno/instance-active-intervals.rst'], 'web_link': 'https://opendev.org/openstack/telemetry-specs/commit/5c69be972f4a5d0d96a1ba088010c6fb3b55a6d1', 'message': 'Add the instance active intervals Meter\n\nChange-Id: Ib0709ad44ef49e4fb5ebb3cd3a54d7ebf008d072\n'}]",48,104784,5c69be972f4a5d0d96a1ba088010c6fb3b55a6d1,92,13,10,882,,,0,"Add the instance active intervals Meter

Change-Id: Ib0709ad44ef49e4fb5ebb3cd3a54d7ebf008d072
",git fetch https://review.opendev.org/openstack/telemetry-specs refs/changes/84/104784/1 && git format-patch -1 --stdout FETCH_HEAD,['specs/juno/instance-uptime.rst'],1,8daf6b85883a21d6fc693d3ed3fda7af45732b79,bp/instance-uptime,".. This work is licensed under a Creative Commons Attribution 3.0 Unported License. http://creativecommons.org/licenses/by/3.0/legalcode ==================================== Instance Uptime Meter ==================================== This blueprint aims at making instance uptime as an available billing metric in Ceilometer. Problem description =================== In Ceilometer, the cpu and memory utilisation are very well-known billing metrics while there is no meters available to allow the cloud provider to bill their customers based on the uptime of the instances they have. The instance uptime should be made available just as well as the other billable resource metrics. Proposed change =============== Since nova returns vm_state as an attribute of the instance, this piece of info exists in resource_metadata. The rough idea is to add a new transformer which caculates the delta(time) between two consequentive ""ACTIVE"" states. Alternatives ------------ None Data model impact ----------------- None REST API impact --------------- None Security impact --------------- None Pipeline impact --------------- The new transformer and instance_uptime meter needs to added in the pipeline.yaml Other end user impact --------------------- None Performance/Scalability Impacts ------------------------------- None Other deployer impact --------------------- Dedicated sources and sinks for the instance_uptime meter can be defined. An example below:: sources: - name: instance_source interval: 600 meters:* Register the transform in the setup.cfg - ""instance"" sinks: - instance_uptime_sink sinks: - name: instance_uptime_sink transformers: -name: ""up_time"" parameters: target: name:""vm_uptime"" unit:""sec"" type:""gauge"" publishers: - rpc:// Developer impact ---------------- None Implementation ============== Assignee(s) ----------- Primary assignee: * shengjie-min Other contributors: * dingyuan-rao Ongoing maintainer: * dingyuan-rao Work Items ---------- * Implement the Transformer * Add the new meter description to the wiki Future lifecycle ================ None Dependencies ============ None Testing ======= None Documentation Impact ==================== None References ========== None ",,145,0
openstack%2Ftelemetry-specs~master~Ie279b30e37836a678dcae91d83e3e88dea95a095,openstack/telemetry-specs,master,Ie279b30e37836a678dcae91d83e3e88dea95a095,Updated a new predictive failure metric proposal,ABANDONED,2014-08-21 19:08:35.000000000,2015-06-25 14:29:05.000000000,,"[{'_account_id': 3}, {'_account_id': 3012}, {'_account_id': 6537}]","[{'number': 1, 'created': '2014-08-21 19:08:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/telemetry-specs/commit/20c2ac3985484c37d023d70df063f94515be6e64', 'message': 'Added a new predictive failure metric proposal\n\nChange-Id: Ie279b30e37836a678dcae91d83e3e88dea95a095\n'}, {'number': 2, 'created': '2014-08-23 17:14:34.000000000', 'files': ['specs/juno/predictive-failure.txt'], 'web_link': 'https://opendev.org/openstack/telemetry-specs/commit/c1819b29767fd2d1b5299acd842f6a6aebeefe10', 'message': 'Updated a new predictive failure metric proposal\n\nChange-Id: Ie279b30e37836a678dcae91d83e3e88dea95a095\n'}]",5,116069,c1819b29767fd2d1b5299acd842f6a6aebeefe10,8,3,2,11624,,,0,"Updated a new predictive failure metric proposal

Change-Id: Ie279b30e37836a678dcae91d83e3e88dea95a095
",git fetch https://review.opendev.org/openstack/telemetry-specs refs/changes/69/116069/2 && git format-patch -1 --stdout FETCH_HEAD,['specs/juno/predictive-failure.txt'],1,20c2ac3985484c37d023d70df063f94515be6e64,predictive-failure-spec,".. This work is licensed under a Creative Commons Attribution 3.0 Unported License. http://creativecommons.org/licenses/by/3.0/legalcode ========================================== Metric for Predictive Failure of Host ========================================== Include the URL of your launchpad blueprint: https://blueprints.launchpad.net/ceilometer/+spec/predictive-failure-metric A host level metric is required that gives indications o h ost at risk for failure. A plug-in may run on the host and insert notifications for such a predictive failure (pfa). Problem description =================== Currently host level metrics are available in Ceilometer such as cpu and memory utilization among others. These take the form of notifications inserted based on host observation. A plugin that observes various hardware and software error rates and inserts notifications would require support of a host level Ceilometer metric. A policy service may query Ceilometerclient API to take responsive actions based on pre-defined policy. Use Case: A large number of a certain class of correctable DRAM errors ar fan errors are being noticed, and it is determined by some logic that the host is likely to fail. To prevent disruption in VM (and rstart), all VMs may be proactively live-migrated from the host. Proposed change =============== Add line to ceilometer entry_points.txt file: host_pfa = ceilometer.compute.notifications.cpu:HostPfa Add line to ./compute/notifications/cpu.py class HostPfa(ComputeMetricsNotificationBase): """"""Handle predictive failure alert message."""""" metric = 'host.pfa' sample_type = sample.TYPE_GAUGE unit = 'bool' Alternatives ------------ None Data model impact ----------------- None REST API impact --------------- None Security impact --------------- None Pipeline impact --------------- None Other end user impact --------------------- None Performance/Scalability Impacts ------------------------------- None Other deployer impact --------------------- None Developer impact ---------------- None Implementation ============== Code submitted Assignee(s) ----------- Primary assignee: Prabhakar Kudva Work Items ---------- Code Submitted Future lifecycle ================ None Dependencies ============ None Testing ======= A test to be added to enable the PFA metric Documentation Impact ==================== Documentation to be updated to indicated new metric available References ========== http://eavesdrop.openstack.org/meetings/ceilometer/2014/ceilometer.2014-08-21-15.00.log.html ",,137,0
openstack%2Ftelemetry-specs~master~I20f7cb327fe05f4f94217a8ab4b489e17ae00a95,openstack/telemetry-specs,master,I20f7cb327fe05f4f94217a8ab4b489e17ae00a95,PaaS Usage Event Collection,ABANDONED,2014-06-25 21:03:20.000000000,2015-06-25 14:28:38.000000000,,"[{'_account_id': 3}, {'_account_id': 6537}, {'_account_id': 7052}, {'_account_id': 7336}, {'_account_id': 10850}, {'_account_id': 10980}, {'_account_id': 10987}, {'_account_id': 11564}]","[{'number': 1, 'created': '2014-06-25 21:03:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/telemetry-specs/commit/d79c00d33f23cd1fa87aa1732f4c51d3aac7b765', 'message': 'PaaS Usage Event Collection\n\nProvides metering requirements, use cases and an architecture for\ncollection of usage information from Platform as a Service (PaaS)\nofferings.\n\nblueprint paas-usage-event-collection\n\nDocImpact\n\nChange-Id: I20f7cb327fe05f4f94217a8ab4b489e17ae00a95\n'}, {'number': 2, 'created': '2014-06-26 14:50:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/telemetry-specs/commit/ea0a91562022bb8552ed96493c4bcb2f1ca524b7', 'message': 'PaaS Usage Event Collection\n\nProvides metering requirements, use cases and an architecture for\ncollection of usage information from Platform as a Service (PaaS)\nofferings.\n\nblueprint paas-usage-event-collection\n\nDocImpact\n\nChange-Id: I20f7cb327fe05f4f94217a8ab4b489e17ae00a95\n'}, {'number': 3, 'created': '2014-06-26 14:56:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/telemetry-specs/commit/65abe1ecc38d157f8ac8dbdc7fca0c1e8ed727b7', 'message': 'PaaS Usage Event Collection\n\nProvides metering requirements, use cases and an architecture for\ncollection of usage information from Platform as a Service (PaaS)\nofferings.\n\nblueprint paas-usage-event-collection\n\nDocImpact\n\nChange-Id: I20f7cb327fe05f4f94217a8ab4b489e17ae00a95\n'}, {'number': 4, 'created': '2014-07-21 21:24:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/telemetry-specs/commit/33843e84ef3d06bee204599d704bbd8c02230bda', 'message': 'PaaS Usage Event Collection\n\nProvides metering requirements, use cases and an architecture for\ncollection of usage information from Platform as a Service (PaaS)\nofferings.\n\nDocImpact\n\nChange-Id: I20f7cb327fe05f4f94217a8ab4b489e17ae00a95\n'}, {'number': 5, 'created': '2014-07-21 21:53:21.000000000', 'files': ['specs/juno/paas-usage-event-collection.rst'], 'web_link': 'https://opendev.org/openstack/telemetry-specs/commit/2112d770f07a6ae5faa359a15b4b15317adc2af5', 'message': 'PaaS Usage Event Collection\n\nProvides metering requirements, use cases and an architecture for\ncollection of usage information from Platform as a Service (PaaS)\nofferings.\n\nDocImpact\n\nChange-Id: I20f7cb327fe05f4f94217a8ab4b489e17ae00a95\n'}]",6,102647,2112d770f07a6ae5faa359a15b4b15317adc2af5,23,8,5,7336,,,0,"PaaS Usage Event Collection

Provides metering requirements, use cases and an architecture for
collection of usage information from Platform as a Service (PaaS)
offerings.

DocImpact

Change-Id: I20f7cb327fe05f4f94217a8ab4b489e17ae00a95
",git fetch https://review.opendev.org/openstack/telemetry-specs refs/changes/47/102647/4 && git format-patch -1 --stdout FETCH_HEAD,['specs/juno/paas-usage-event-collection.rst'],1,d79c00d33f23cd1fa87aa1732f4c51d3aac7b765,bp/paas-event-collection,".. This work is licensed under a Creative Commons Attribution 3.0 Unported License. http://creativecommons.org/licenses/by/3.0/legalcode ========================================== PaaS Event Usage Collection ========================================== Include the URL of your launchpad blueprint: https://blueprints.launchpad.net/ceilometer/+spec/paas-usage-event-collection Ceilometer must be able to efficiently extract and process usage information from on-cloud PaaS services in order to properly generate usable data for post-processing. To make this as efficient as possible, and to allow the quickest integration of services, services to implement a consistent interface. Problem description =================== PaaS metering presents an issue in both the variety and complexity of models that need to be accomodated by the Ceilometer collection methods. While designing service-specific plugins has been sufficient to this point, following this approach for PaaS services is insufficient due to the fact that there are variations in ownership that we don't see for the infrastructure-type services. PaaS services are hosted within instances of Nova machines, which creates one of two scenarios: 1.PaaS Service owns the VM instance: VM instances are not visible to the end customer. The owner of the VM is the PaaS service. Usage records generated by Nova refer to the PaaS service controller's projectId. 2.End User owns the VM instances: VM instances are visible and can be controlled by the end user. Nova usage records refer to the actual end user projectId. Requires some mechanism to differentiate PaaS Nova instances from base Nova instances. The first scenario presents a distinct problem: how do we collect Example Use Cases ----------------- * Database as a Service Database as a Service (DBaaS), i.e. Trove, has an architecture where a service controller manages special Nova compute instances on behalf of the customer. From their perspective they are running instances of a database, not compute instances. Metering and billing will be based on hours that the database has been running, not necessarily how long the hosting instance has been run. This requires a unique set of metering records to be generated and stored to enable usage tracking and billing of the individual database instances. Ceilometer must be able to pull application specific records from the DBaaS service controller or an appropriate intermediary. * DNS as a Service DNS as a service runs on a similar service controller architecture to DBaaS. In this case, the meters that need to be measured are the existence of a DNS zone and the number of DNS queries that have been served. Once again these are application level meters that do not correlate directly to the host instances that are running. Queries could be served by a variety of hosts and a DNS zone's existence does not depend on a specific compute instance. Application level metrics must be tracked by the DNS service and reported out so that these systems can be tracked. Ceilometer must be able to pull application specific records from the DNSaaS service controller or an appropriate intermediary. * Load Balancing as a Service A load balancer is a logical system that consists of some number of compute instances that host the load balancing software. Meters that must be measured would be things like the existence of a load balancer instance and the amount of data that is being transferred through the system. Once again, this does not directly correlate to the underlying infrastructure but must be reported at the application level. Ceilometer must be able to pull application specific records from the LBSaaS service controller or an appropriate intermediary. Proposed change =============== Putting in place a centralized PaaS service controller on-cloud instance on Nova host node allows Ceilometer to collect PaaS-specific data and pass it to a unified plugin on the Ceilometer host. Implementing a PaaS-specific message queue supports the notification transport and provides a bridge across the overcloud/undercloud gap. Alternatives ------------ A derivative approach would be to set up direct communication from the Individual PaaS service instances on the Nova hosts directly to the PaaS messaging queue without passing through a centralized controller. That implies a greater footprint in each of the compute instances, however. Data model impact ----------------- The additional data collected from PaaS services should fit within the current data model. REST API impact --------------- No impact. Security impact --------------- One concern for security here is the potential for interception between the on-cloud messaging queue and the PaaS listener sitting on the Ceilometer node. The likely approach is to leverage a setup similar to the existing metering secret. Pipeline impact --------------- The addition of a PaaS-specific listener doesn't drastically change the pipeline architecture, but the fact that it will be listening to 1:N messaging queues hosted on-cloud implies that there is some configuration option to specify one or more queues separate from the current one used for infrastructure. The current message signature verification schema should be sufficient for the handoff from PaaS event listenter to Collector. This is fundamentally a new polling agent sitting on-cloud, though it will likely be more simplistic. The likely approach here is to rely on a separate pipeline configuration, in order to keep some separation from under-cloud metering and due to the fact that there is probably a different/simpler configur Other end user impact --------------------- None noted. Performance/Scalability Impacts ------------------------------- There will be impact to the volume of data on the messageing queues. Depending on implementation, there might also be an increase in exchanges and/or unique queues, which raises questions about cluster load and the overhead of mirroring. Also, considerations around multiple PaaS Service Controllers need to be addressed, as this is the likely approach to scaling to meet a growing number of on-cloud PaaS services. Other deployer impact --------------------- The PaaS service controller is, ultimately, an optional component for deployment. Deployers will need to explicitly enable it, similar to the effort needed to roll out the Compute agent. There a requirement for configuration of the PaaS controller instance, as well as the Ceilometer node, to enable the correct queue targeting and other setup options. For packaging purposes, there will be another daemon/service (the PaaS service controller) that needs to be available for deployment to each Nova node on which PaaS services will be hosted. Developer impact ---------------- There is some crossover into Nova development space. Implementation ============== Assignee(s) ----------- Who is leading the writing of the code? Or is this a blueprint where you're throwing it out there to see who picks it up? If more than one person is working on the implementation, please designate the primary author and contact. Primary assignee: nealph (phil.neal@hp.com) Other contributors: TBD Ongoing maintainer: nealph (phil.neal@hp.com) Work Items ---------- 1. PaaS Event Listener design and implementation: put together the Ceilometer component that will enable listening for PaaS notifications and passing them to the Ceilometer event bus. 2. PaaS queue setup and registration: enable a messaging queue for the PaaS controller to submit notifications to. 3. PaaS service controller: create a service controller node on-cloud that is responsible for generating PaaS usage records and pushing them onto the queue Future lifecycle ================ Targeting the late Juno or early K cycle to deliver the major components listed above. Additional iteration: Following the initial implementation of this and the PaaS event format BP, we'll need to circle back to the content of the published notifications and update as needed, as well as iterate on the service controller. Dependencies ============ At this point we anticipate no additional libraries will be required: this is really just an application of the current components onto the Nova hosts running on-cloud. This implementation is connected to https://blueprints.launchpad.net/ceilometer/+spec/paas-event-format-for-ceilometer Testing ======= Please discuss how the change will be tested. We especially want to know what Tempest tests will be added. It is assumed that unit and scenario test coverage will be added so that doesn't need to be mentioned explicitly, but discussion of why you think unit/scenario tests are sufficient and we don't need to add more tempest testcases would need to be included. Is this untestable in the upstream gate given current limitations (specific hardware / software configurations available)? If so, are there mitigation plans (3rd party testing, gate enhancements, etc.). Documentation Impact ==================== This new service controller and queue would need to be documented, along with the configuration items required to support them. References ========== Summit discussion notes: https://etherpad.openstack.org/p/Ceilometer_support_for_advanced_billing_models Original Blueprint https://wiki.openstack.org/wiki/Ceilometer/blueprints/PaaSEventUsageCollection ",,259,0
openstack%2Ftelemetry-specs~master~Ie0c8ee71dee008654e597b5bc1a2af3bbfa3ace6,openstack/telemetry-specs,master,Ie0c8ee71dee008654e597b5bc1a2af3bbfa3ace6,Add spec for graphite publisher,ABANDONED,2014-06-30 07:36:05.000000000,2015-06-25 14:27:47.000000000,,"[{'_account_id': 3}, {'_account_id': 136}, {'_account_id': 6537}, {'_account_id': 7537}, {'_account_id': 10068}, {'_account_id': 11564}]","[{'number': 1, 'created': '2014-06-30 07:36:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/telemetry-specs/commit/5554c426d93a7eb23ac3f2cfc7e10a27d39b53dd', 'message': 'Add spec for graphite publisher\n\nChange-Id: Ie0c8ee71dee008654e597b5bc1a2af3bbfa3ace6\n'}, {'number': 2, 'created': '2014-06-30 07:43:38.000000000', 'files': ['specs/juno/graphite-publisher.rst'], 'web_link': 'https://opendev.org/openstack/telemetry-specs/commit/139c80cd6da09a011309bc66fb416feb1e2d841c', 'message': 'Add spec for graphite publisher\n\nChange-Id: Ie0c8ee71dee008654e597b5bc1a2af3bbfa3ace6\n'}]",7,103479,139c80cd6da09a011309bc66fb416feb1e2d841c,24,6,2,12173,,,0,"Add spec for graphite publisher

Change-Id: Ie0c8ee71dee008654e597b5bc1a2af3bbfa3ace6
",git fetch https://review.opendev.org/openstack/telemetry-specs refs/changes/79/103479/1 && git format-patch -1 --stdout FETCH_HEAD,['specs/juno/graphite-publisher.rst'],1,5554c426d93a7eb23ac3f2cfc7e10a27d39b53dd,,".. This work is licensed under a Creative Commons Attribution 3.0 Unported License. http://creativecommons.org/licenses/by/3.0/legalcode ========================================== Graphite Publisher ========================================== https://blueprints.launchpad.net/ceilometer/+spec/graphite-publisher Problem description =================== As a large OpenStack based cloud operator, we want to monitor resource usage for all the instances grouped by tenants. We first tried with the full install of ceilometer components, but soon found out that there is a big performance penalty on the message-bus and the database. Therefore we require a solution that will still allow us to get the usage metrics easily. An analysis showed that we already have monitoring and metering implemented, and we are interested in only the data from ceilometer-compute agent. During the OpenStack summit in Atlanta, many of the other operators that we talked with were interested to implement this solution and looking forward to get the working code and provide feedback. We are talking about thousands of instances and multiple metrics per instance, which is necessary for us to record and graph, which is the purpose of this blueprint. Proposed change =============== When it comes to collection, aggregation and graphing of multiple thousands of metrics in realtime, graphite requires no introduction. This means we need one new publisher that will send metrics directly into graphite. This will allow all big cloud operators to still continue using the collection component of ceilometer but offload the metrics, aggregation, graphing part to graphite which is well suited for exactly this. Alternatives ------------ None Data model impact ----------------- None REST API impact --------------- None Security impact --------------- None Pipeline impact --------------- A new publisher for graphite needs to be created. Other end user impact --------------------- None Performance/Scalability Impacts ------------------------------- None Other deployer impact --------------------- None Developer impact ---------------- None Implementation ============== Assignee(s) ----------- Primary assignee: * admin0 Other contributors: Ongoing maintainer: * admin0 Work Items ---------- * Create a new publisher. * Create Implementation Documentation Future lifecycle ================ I am going to take care of it and given the interest in the idea and our working demo, I am positive that others will join to contribute and maintain. Dependencies ============ None Testing ======= This configuration will be tested in new unit tests. Documentation Impact ==================== Documentation needs to be created. References ========== * https://github.com/a1git/ceilograph * https://wiki.openstack.org/wiki/Ceilometer/blueprints/graphite-publisher ",,138,0
openstack%2Fmurano~master~Ic498ca67391ff7e4039ab47f13cc239c0c648ed9,openstack/murano,master,Ic498ca67391ff7e4039ab47f13cc239c0c648ed9,[Murano Docs] Adds ref links to manage_applications,MERGED,2015-06-20 13:22:22.000000000,2015-06-25 14:27:15.000000000,2015-06-25 14:27:11.000000000,"[{'_account_id': 3}, {'_account_id': 7535}, {'_account_id': 7549}, {'_account_id': 7821}, {'_account_id': 13149}, {'_account_id': 15168}]","[{'number': 1, 'created': '2015-06-20 13:22:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/murano/commit/f521936f786923faf1c94f19a9dbc396f87b8f90', 'message': '[Murano Docs] Adds ref links to manage_applications\n\nThis patch adds ref links to the Managing applications\n section. Thus, a reader can easily pick up the necessary\n parts of the HowTo.\n\nChange-Id: Ic498ca67391ff7e4039ab47f13cc239c0c648ed9\n'}, {'number': 2, 'created': '2015-06-24 06:49:27.000000000', 'files': ['doc/source/draft/enduser-guide/manage_applications.rst'], 'web_link': 'https://opendev.org/openstack/murano/commit/c1511a8febd9ae8d751895543dc449fb902c3aff', 'message': '[Murano Docs] Adds ref links to manage_applications\n\nThis patch adds ref links to the Managing applications \nsection. Thus, a reader can easily pick up the necessary \nparts of the HowTo.\n\nChange-Id: Ic498ca67391ff7e4039ab47f13cc239c0c648ed9\n'}]",2,193798,c1511a8febd9ae8d751895543dc449fb902c3aff,21,6,2,14947,,,0,"[Murano Docs] Adds ref links to manage_applications

This patch adds ref links to the Managing applications 
section. Thus, a reader can easily pick up the necessary 
parts of the HowTo.

Change-Id: Ic498ca67391ff7e4039ab47f13cc239c0c648ed9
",git fetch https://review.opendev.org/openstack/murano refs/changes/98/193798/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/source/draft/enduser-guide/manage_applications.rst'],1,f521936f786923faf1c94f19a9dbc396f87b8f90,minor-edits,* :ref:`from a zip file <ui_zip>` * :ref:`from murano applications repository <ui_repo>` * :ref:`from bundles of applications <ui_bundles>` .. _ui_zip:.. _ui_repo: .. _ui_bundles: ,* from a zip file * from murano applications repository * from bundles of applications,9,3
openstack%2Fcinder~master~I8796b299190d240acb84933e85acbd1743ccde1d,openstack/cinder,master,I8796b299190d240acb84933e85acbd1743ccde1d,tox: add a basic py34 venv running a single test,ABANDONED,2015-06-16 09:45:45.000000000,2015-06-25 14:22:37.000000000,,"[{'_account_id': 3}, {'_account_id': 2243}, {'_account_id': 8122}, {'_account_id': 9107}, {'_account_id': 9535}, {'_account_id': 9751}, {'_account_id': 10621}, {'_account_id': 10622}, {'_account_id': 11811}, {'_account_id': 11904}, {'_account_id': 12016}, {'_account_id': 12017}, {'_account_id': 12032}, {'_account_id': 12033}, {'_account_id': 12202}, {'_account_id': 12249}, {'_account_id': 12369}, {'_account_id': 12778}, {'_account_id': 12780}, {'_account_id': 13144}, {'_account_id': 13203}, {'_account_id': 13394}, {'_account_id': 13628}, {'_account_id': 13636}, {'_account_id': 14242}, {'_account_id': 14305}, {'_account_id': 14587}, {'_account_id': 15249}, {'_account_id': 15254}, {'_account_id': 15374}, {'_account_id': 15670}, {'_account_id': 15741}, {'_account_id': 15831}, {'_account_id': 15941}, {'_account_id': 16160}, {'_account_id': 16269}, {'_account_id': 16422}, {'_account_id': 16595}, {'_account_id': 16660}, {'_account_id': 16880}, {'_account_id': 16897}]","[{'number': 1, 'created': '2015-06-16 09:45:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/8dc52dc80b8f9053a7ab64d6ecfaa601639bf32b', 'message': 'tox: add a basic py34 venv running a single test\n\nWith this change, tox -e py34 now pass. Python 3 regressions can now be\ndetected more easily on code tested by the whitelist of tests executed\nby tox -e py34.\n\nMore tests will be added shortly when more Cinder modules will be\ncompatible with Python 3.\n\nThis change requires 3 other Python 3 fixes.\n\nBlueprint cinder-python3\nDepends-On: Ie1aedf1cbb9d3e54a996321cd586b875e69ac85a\nDepends-On: If7b8f50c6a8b0a5044c2c7108b2b0293dddafff3\nDepends-On: If618b4e810e444f7eb6592bb2398805e9d14d548\nChange-Id: I8796b299190d240acb84933e85acbd1743ccde1d\n'}, {'number': 2, 'created': '2015-06-17 20:46:07.000000000', 'files': ['tox.ini'], 'web_link': 'https://opendev.org/openstack/cinder/commit/d4ee0fd60d04b370bc9c58a01c237455c27896f7', 'message': 'tox: add a basic py34 venv running a single test\n\nWith this change, tox -e py34 now pass. Python 3 regressions can now be\ndetected more easily on code tested by the whitelist of tests executed\nby tox -e py34.\n\nMore tests will be added shortly when more Cinder modules will be\ncompatible with Python 3.\n\nBlueprint cinder-python3\nChange-Id: I8796b299190d240acb84933e85acbd1743ccde1d\n'}]",6,192118,d4ee0fd60d04b370bc9c58a01c237455c27896f7,85,41,2,9107,,,0,"tox: add a basic py34 venv running a single test

With this change, tox -e py34 now pass. Python 3 regressions can now be
detected more easily on code tested by the whitelist of tests executed
by tox -e py34.

More tests will be added shortly when more Cinder modules will be
compatible with Python 3.

Blueprint cinder-python3
Change-Id: I8796b299190d240acb84933e85acbd1743ccde1d
",git fetch https://review.opendev.org/openstack/cinder refs/changes/18/192118/2 && git format-patch -1 --stdout FETCH_HEAD,['tox.ini'],1,8dc52dc80b8f9053a7ab64d6ecfaa601639bf32b,bp/cinder-python3,"[testenv:py34] # Use a whitelist of tests which pass on Python 3.4 until Cinder is fully # ported to Python 3. Use testtools instead of testr, because testr loads # all tests which load all modules, whereas not all modules are compatible # with Python 3 yet. commands = python -m testtools.run \ cinder.tests.unit.test_utils.GenericUtilsTestCase ",,9,0
openstack%2Fcookbook-openstack-compute~master~I9e6c91bb67243b839bc10f7d906f8a3bf73ed791,openstack/cookbook-openstack-compute,master,I9e6c91bb67243b839bc10f7d906f8a3bf73ed791,Allow keymgr attributes to be configured.,MERGED,2015-06-24 09:31:33.000000000,2015-06-25 14:22:26.000000000,2015-06-25 14:22:25.000000000,"[{'_account_id': 3}, {'_account_id': 7128}, {'_account_id': 8112}, {'_account_id': 8989}, {'_account_id': 16986}]","[{'number': 1, 'created': '2015-06-24 09:31:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cookbook-openstack-compute/commit/15089c3d225d5fef23de4707775d119266fddb6d', 'message': 'Allow fixed_key to be configured in cookbook\n\nThe fixed_key should be configured.\n\nChange-Id: I9e6c91bb67243b839bc10f7d906f8a3bf73ed791\nCloses-Bug: 1468171\n'}, {'number': 2, 'created': '2015-06-25 06:22:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cookbook-openstack-compute/commit/a1670fb59d6f2680afa61658c0619bb8a73d4ac3', 'message': ""Allow keymgr attributes to be configured.\n\nThe keymgr section attributes 'api_class' 'fixed_key' should be configured to be used for encryption.\n\nChange-Id: I9e6c91bb67243b839bc10f7d906f8a3bf73ed791\nCloses-Bug: 1468171\n""}, {'number': 3, 'created': '2015-06-25 08:55:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cookbook-openstack-compute/commit/d64d49fe11a530d4f131b37d3e5711e70dfc9e78', 'message': ""Allow keymgr attributes to be configured.\n\nThe keymgr section attributes 'api_class' 'fixed_key' should be configured to be used for encryption.\n\nChange-Id: I9e6c91bb67243b839bc10f7d906f8a3bf73ed791\nCloses-Bug: 1468171\n""}, {'number': 4, 'created': '2015-06-25 08:58:29.000000000', 'files': ['attributes/default.rb', 'spec/nova-common_spec.rb', 'templates/default/nova.conf.erb', 'README.md'], 'web_link': 'https://opendev.org/openstack/cookbook-openstack-compute/commit/01678f7513323b36bc2affb821732021af815f99', 'message': ""Allow keymgr attributes to be configured.\n\nThe keymgr section attributes 'api_class' 'fixed_key' should be configured to be used for encryption.\n\nChange-Id: I9e6c91bb67243b839bc10f7d906f8a3bf73ed791\nCloses-Bug: 1468171\n""}]",6,195007,01678f7513323b36bc2affb821732021af815f99,15,5,4,8989,,,0,"Allow keymgr attributes to be configured.

The keymgr section attributes 'api_class' 'fixed_key' should be configured to be used for encryption.

Change-Id: I9e6c91bb67243b839bc10f7d906f8a3bf73ed791
Closes-Bug: 1468171
",git fetch https://review.opendev.org/openstack/cookbook-openstack-compute refs/changes/07/195007/4 && git format-patch -1 --stdout FETCH_HEAD,"['attributes/default.rb', 'spec/nova-common_spec.rb', 'templates/default/nova.conf.erb', 'README.md']",4,15089c3d225d5fef23de4707775d119266fddb6d,bug/1468171,"Keymgr Configuration Attributes ------------------------------- * `openstack[""compute""][""keymgr""][""fixed_key""] - the fixed key returned by key manager, specified in hex (string value). ",,28,0
openstack%2Fsenlin~master~Id78e72b5b1fd8382d89e204d3381944287c22f29,openstack/senlin,master,Id78e72b5b1fd8382d89e204d3381944287c22f29,Add vertical scaling into the pipeline,MERGED,2015-06-24 06:50:41.000000000,2015-06-25 14:21:53.000000000,2015-06-25 14:21:51.000000000,"[{'_account_id': 3}, {'_account_id': 8246}, {'_account_id': 11034}]","[{'number': 1, 'created': '2015-06-24 06:50:41.000000000', 'files': ['FEATURES.rst'], 'web_link': 'https://opendev.org/openstack/senlin/commit/bafcb9a316af6dc1c0d01f4abb83e2afda4cbf2e', 'message': 'Add vertical scaling into the pipeline\n\nVertical scaling is a different way of adding resources to an existing\npool. There are requirements on adding new resources to cluster nodes so\nthat the capability of the cluster is increased. We put this at a low\npriority at the moment.\n\nChange-Id: Id78e72b5b1fd8382d89e204d3381944287c22f29\n'}]",2,194958,bafcb9a316af6dc1c0d01f4abb83e2afda4cbf2e,8,3,1,8246,,,0,"Add vertical scaling into the pipeline

Vertical scaling is a different way of adding resources to an existing
pool. There are requirements on adding new resources to cluster nodes so
that the capability of the cluster is increased. We put this at a low
priority at the moment.

Change-Id: Id78e72b5b1fd8382d89e204d3381944287c22f29
",git fetch https://review.opendev.org/openstack/senlin refs/changes/58/194958/1 && git format-patch -1 --stdout FETCH_HEAD,['FEATURES.rst'],1,bafcb9a316af6dc1c0d01f4abb83e2afda4cbf2e,features,"Vertical Scaling ^^^^^^^^^^^^^^^^ Though Senlin is mainly concerns about the horizontal scaling in/out support, there are possibilities/requirements to scale nodes in the vertical direction. Vertical scaling means automatically adding compute/storage/network resources to cluster nodes. Depending on the support from corresponding services, this could be explored. ",,10,0
openstack%2Ffuel-qa~stable%2F6.1~I212a92a859f2f576b459a9d4b996c8f55a5dc5ff,openstack/fuel-qa,stable/6.1,I212a92a859f2f576b459a9d4b996c8f55a5dc5ff,Don't disable Ubuntu updates and security repos,MERGED,2015-06-25 13:39:37.000000000,2015-06-25 14:15:26.000000000,2015-06-25 14:15:23.000000000,"[{'_account_id': 3}, {'_account_id': 6719}, {'_account_id': 8882}, {'_account_id': 8971}, {'_account_id': 10136}, {'_account_id': 11969}, {'_account_id': 12867}, {'_account_id': 14057}, {'_account_id': 14708}, {'_account_id': 15943}, {'_account_id': 15984}, {'_account_id': 16106}]","[{'number': 1, 'created': '2015-06-25 13:39:37.000000000', 'files': ['fuelweb_test/models/fuel_web_client.py'], 'web_link': 'https://opendev.org/openstack/fuel-qa/commit/9c646a3df2d97fbe526e0d6232d83d86899a29c8', 'message': ""Don't disable Ubuntu updates and security repos\n\nChange-Id: I212a92a859f2f576b459a9d4b996c8f55a5dc5ff\nCloses-bug: #1468759\n""}]",0,195583,9c646a3df2d97fbe526e0d6232d83d86899a29c8,9,12,1,11081,,,0,"Don't disable Ubuntu updates and security repos

Change-Id: I212a92a859f2f576b459a9d4b996c8f55a5dc5ff
Closes-bug: #1468759
",git fetch https://review.opendev.org/openstack/fuel-qa refs/changes/83/195583/1 && git format-patch -1 --stdout FETCH_HEAD,['fuelweb_test/models/fuel_web_client.py'],1,9c646a3df2d97fbe526e0d6232d83d86899a29c8,," if repo['name'] in ('mos-updates', 'mos-security'):"," if repo['name'] in ('ubuntu-updates', 'ubuntu-security', 'mos-updates', 'mos-security', 'mos-holdback'):",1,3
openstack%2Ffuel-qa~master~I212a92a859f2f576b459a9d4b996c8f55a5dc5ff,openstack/fuel-qa,master,I212a92a859f2f576b459a9d4b996c8f55a5dc5ff,Don't disable Ubuntu updates and security repos,MERGED,2015-06-25 13:38:15.000000000,2015-06-25 14:14:19.000000000,2015-06-25 14:14:18.000000000,"[{'_account_id': 3}, {'_account_id': 6719}, {'_account_id': 8882}, {'_account_id': 8971}, {'_account_id': 10136}, {'_account_id': 11081}, {'_account_id': 11969}, {'_account_id': 12867}, {'_account_id': 14057}, {'_account_id': 14708}, {'_account_id': 15943}, {'_account_id': 15984}, {'_account_id': 16106}]","[{'number': 1, 'created': '2015-06-25 13:38:15.000000000', 'files': ['fuelweb_test/models/fuel_web_client.py'], 'web_link': 'https://opendev.org/openstack/fuel-qa/commit/3141ff22cbb05f92e6cc865d5190fe9df4dabd4f', 'message': ""Don't disable Ubuntu updates and security repos\n\nChange-Id: I212a92a859f2f576b459a9d4b996c8f55a5dc5ff\nCloses-bug: #1468759\n""}]",0,195581,3141ff22cbb05f92e6cc865d5190fe9df4dabd4f,13,13,1,11081,,,0,"Don't disable Ubuntu updates and security repos

Change-Id: I212a92a859f2f576b459a9d4b996c8f55a5dc5ff
Closes-bug: #1468759
",git fetch https://review.opendev.org/openstack/fuel-qa refs/changes/81/195581/1 && git format-patch -1 --stdout FETCH_HEAD,['fuelweb_test/models/fuel_web_client.py'],1,3141ff22cbb05f92e6cc865d5190fe9df4dabd4f,bug/1468759," if repo['name'] in ('mos-updates', 'mos-security'):"," if repo['name'] in ('ubuntu-updates', 'ubuntu-security', 'mos-updates', 'mos-security', 'mos-holdback'):",1,3
openstack%2Fheat-templates~master~Iec2de70bc34d31cd4483fab9077a4fe341c35d4c,openstack/heat-templates,master,Iec2de70bc34d31cd4483fab9077a4fe341c35d4c,Add support for zaqar in heat-config-notify,MERGED,2015-05-27 08:40:08.000000000,2015-06-25 14:12:51.000000000,2015-06-25 14:12:50.000000000,"[{'_account_id': 3}, {'_account_id': 4328}, {'_account_id': 4571}, {'_account_id': 6159}]","[{'number': 1, 'created': '2015-05-27 08:40:08.000000000', 'files': ['hot/software-config/elements/heat-config/bin/heat-config-notify', 'hot/software-config/elements/heat-config/install.d/heat-config-package-install/50-heat-config-package', 'hot/software-config/elements/heat-config/install.d/heat-config-source-install/50-heat-config-soure'], 'web_link': 'https://opendev.org/openstack/heat-templates/commit/6b28aba6605dbb6cecbc57884bcd592e3608949a', 'message': 'Add support for zaqar in heat-config-notify\n\nThis allows using a zaqar queue to push results of software deployments\nto heat.\n\nblueprint software-config-zaqar\nChange-Id: Iec2de70bc34d31cd4483fab9077a4fe341c35d4c\n'}]",0,185883,6b28aba6605dbb6cecbc57884bcd592e3608949a,7,4,1,7385,,,0,"Add support for zaqar in heat-config-notify

This allows using a zaqar queue to push results of software deployments
to heat.

blueprint software-config-zaqar
Change-Id: Iec2de70bc34d31cd4483fab9077a4fe341c35d4c
",git fetch https://review.opendev.org/openstack/heat-templates refs/changes/83/185883/1 && git format-patch -1 --stdout FETCH_HEAD,"['hot/software-config/elements/heat-config/bin/heat-config-notify', 'hot/software-config/elements/heat-config/install.d/heat-config-package-install/50-heat-config-package', 'hot/software-config/elements/heat-config/install.d/heat-config-source-install/50-heat-config-soure']",3,6b28aba6605dbb6cecbc57884bcd592e3608949a,bp/software-config-zaqar,pip install python-heatclient python-zaqarclient,pip install python-heatclient,34,3
openstack%2Fnova-powervm~master~I8574017ec392aaf181ec6f87ce18b4b4a75a9cf7,openstack/nova-powervm,master,I8574017ec392aaf181ec6f87ce18b4b4a75a9cf7,New 'image' module with glance upload and metadata,MERGED,2015-06-23 21:05:51.000000000,2015-06-25 14:11:50.000000000,2015-06-25 14:11:49.000000000,"[{'_account_id': 3}, {'_account_id': 8190}, {'_account_id': 8662}, {'_account_id': 13562}, {'_account_id': 13883}, {'_account_id': 14070}]","[{'number': 1, 'created': '2015-06-23 21:05:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova-powervm/commit/aaaa98dc97686386894f07eb94adff8d2b769b6f', 'message': ""New 'image' module with glance upload and metadata\n\nInaugurate the nova_powervm.virt.powervm.image module with methods\nstream_disk_to_glance, which opens a device special file and uploads it\nto the image API, and snapshot_metadata, which generates a metadata\ndictionary suitable for such an upload.\n\nChange-Id: I8574017ec392aaf181ec6f87ce18b4b4a75a9cf7\n""}, {'number': 2, 'created': '2015-06-23 23:35:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova-powervm/commit/f1519902c23c9265a6afeb682fd7e26e3ad3f08d', 'message': ""New 'image' module with glance upload and metadata\n\nInaugurate the nova_powervm.virt.powervm.image module with methods\nstream_disk_to_glance, which opens a device special file and uploads it\nto the image API, and snapshot_metadata, which generates a metadata\ndictionary suitable for such an upload.\n\nChange-Id: I8574017ec392aaf181ec6f87ce18b4b4a75a9cf7\n""}, {'number': 3, 'created': '2015-06-24 14:15:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova-powervm/commit/c154cd63214f4da1df0971a6ca403d96afbb1a59', 'message': ""New 'image' module with glance upload and metadata\n\nInaugurate the nova_powervm.virt.powervm.image module with methods\nstream_disk_to_glance, which opens a device special file and uploads it\nto the image API, and snapshot_metadata, which generates a metadata\ndictionary suitable for such an upload.\n\nChange-Id: I8574017ec392aaf181ec6f87ce18b4b4a75a9cf7\n""}, {'number': 4, 'created': '2015-06-24 20:32:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova-powervm/commit/2f03b0408bc3cf3448202bf3e29492f4a6400afa', 'message': ""New 'image' module with glance upload and metadata\n\nInaugurate the nova_powervm.virt.powervm.image module with methods\nstream_disk_to_glance, which opens a device special file and uploads it\nto the image API, and snapshot_metadata, which generates a metadata\ndictionary suitable for such an upload.\n\nChange-Id: I8574017ec392aaf181ec6f87ce18b4b4a75a9cf7\n""}, {'number': 5, 'created': '2015-06-24 21:20:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova-powervm/commit/0cdeaf6c35b0d41a97b019fd2572e1364e717100', 'message': ""New 'image' module with glance upload and metadata\n\nInaugurate the nova_powervm.virt.powervm.image module with methods\nstream_blockdev_to_glance, which opens a device special file and uploads\nit to the image API, and snapshot_metadata, which generates a metadata\ndictionary suitable for such an upload.\n\nChange-Id: I8574017ec392aaf181ec6f87ce18b4b4a75a9cf7\n""}, {'number': 6, 'created': '2015-06-24 21:23:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova-powervm/commit/2cbefebb1b853d7869b20887261f5bc1879b7514', 'message': ""New 'image' module with glance upload and metadata\n\nInaugurate the nova_powervm.virt.powervm.image module with methods\nstream_blockdev_to_glance, which opens a device special file and uploads\nit to the image API, and snapshot_metadata, which generates a metadata\ndictionary suitable for such an upload.\n\nChange-Id: I8574017ec392aaf181ec6f87ce18b4b4a75a9cf7\n""}, {'number': 7, 'created': '2015-06-24 23:24:24.000000000', 'files': ['nova_powervm/virt/powervm/image.py', 'nova_powervm/tests/virt/powervm/test_image.py'], 'web_link': 'https://opendev.org/openstack/nova-powervm/commit/cecd06a7e222f626ce3096f3afc93a0f32de2a34', 'message': ""New 'image' module with glance upload and metadata\n\nInaugurate the nova_powervm.virt.powervm.image module with methods\nstream_blockdev_to_glance, which opens a device special file and uploads\nit to the image API, and snapshot_metadata, which generates a metadata\ndictionary suitable for such an upload.\n\nChange-Id: I8574017ec392aaf181ec6f87ce18b4b4a75a9cf7\n""}]",15,194818,cecd06a7e222f626ce3096f3afc93a0f32de2a34,31,6,7,14070,,,0,"New 'image' module with glance upload and metadata

Inaugurate the nova_powervm.virt.powervm.image module with methods
stream_blockdev_to_glance, which opens a device special file and uploads
it to the image API, and snapshot_metadata, which generates a metadata
dictionary suitable for such an upload.

Change-Id: I8574017ec392aaf181ec6f87ce18b4b4a75a9cf7
",git fetch https://review.opendev.org/openstack/nova-powervm refs/changes/18/194818/1 && git format-patch -1 --stdout FETCH_HEAD,"['nova_powervm/virt/powervm/image.py', 'nova_powervm/tests/virt/powervm/test_image.py']",2,aaaa98dc97686386894f07eb94adff8d2b769b6f,image_module,"# Copyright 2015 IBM Corp. # # All Rights Reserved. # # Licensed under the Apache License, Version 2.0 (the ""License""); you may # not use this file except in compliance with the License. You may obtain # a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT # WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the # License for the specific language governing permissions and limitations # under the License. import mock from nova import test from nova_powervm.virt.powervm import image class TestImage(test.TestCase): @mock.patch('nova.utils.temporary_chown') @mock.patch('__builtin__.open') @mock.patch('nova.image.api.API') def test_stream_disk_to_glance(self, mock_api, mock_open, mock_chown): mock_api.update = mock.MagicMock() mock_stream = mock.MagicMock() mock_cm = mock.MagicMock() mock_cm.__enter__.return_value = mock_stream mock_open.return_value = mock_cm image.stream_disk_to_glance('context', mock_api, 'image_id', 'metadata', '/dev/disk') mock_chown.assert_called_with('/dev/disk') mock_open.assert_called_with('/dev/disk', 'rb') mock_api.update.assert_called_with('context', 'image_id', 'metadata', mock_stream) @mock.patch('nova.image.api.API') def test_snapshot_metadata(self, mock_api): mock_api.get = mock.MagicMock() mock_api.get.return_value = {'name': 'image_name'} mock_instance = mock.Mock() mock_instance.kernel_id = 'kernel_id' mock_instance.project_id = 'project_id' mock_instance.ramdisk_id = 'ramdisk_id' ret = image.snapshot_metadata('context', mock_api, 'image_id', mock_instance) mock_api.get.assert_called_with('context', 'image_id') self.assertEqual({ 'name': 'image_name', 'is_public': False, 'status': 'active', 'disk_format': 'raw', 'container_format': 'base', 'properties': { 'kernel_id': 'kernel_id', 'image_location': 'snapshot', 'image_state': 'available', 'owner_id': 'project_id', 'ramdisk_id': 'ramdisk_id' } }, ret) ",,130,0
openstack%2Fnova-powervm~master~I77e14301dfe32b857028a8f26b0a174901e934f0,openstack/nova-powervm,master,I77e14301dfe32b857028a8f26b0a174901e934f0,New Task module for image management,MERGED,2015-06-23 23:10:09.000000000,2015-06-25 14:11:44.000000000,2015-06-25 14:11:39.000000000,"[{'_account_id': 3}, {'_account_id': 8190}, {'_account_id': 8662}, {'_account_id': 13883}, {'_account_id': 14070}]","[{'number': 1, 'created': '2015-06-23 23:10:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova-powervm/commit/0c6ab69c55c05e2970663f0c9c7da9e4ddef7cce', 'message': 'New Task module for image management\n\nInaugurate nova_powervm.virt.powervm.tasks.image for Task classes\nrelated to glance images.  First class is UpdateTaskState, to wrap the\nupdate_task_state callable passed into the snapshot driver method.\n\nChange-Id: I77e14301dfe32b857028a8f26b0a174901e934f0\n'}, {'number': 2, 'created': '2015-06-24 14:11:07.000000000', 'files': ['nova_powervm/virt/powervm/tasks/image.py', 'nova_powervm/tests/virt/powervm/tasks/test_image.py'], 'web_link': 'https://opendev.org/openstack/nova-powervm/commit/75a9c2dbd8fa585f9694926a33a065b5fa3bc130', 'message': 'New Task module for image management\n\nInaugurate nova_powervm.virt.powervm.tasks.image for Task classes\nrelated to glance images.  First class is UpdateTaskState, to wrap the\nupdate_task_state callable passed into the snapshot driver method.\n\nChange-Id: I77e14301dfe32b857028a8f26b0a174901e934f0\n'}]",3,194858,75a9c2dbd8fa585f9694926a33a065b5fa3bc130,17,5,2,14070,,,0,"New Task module for image management

Inaugurate nova_powervm.virt.powervm.tasks.image for Task classes
related to glance images.  First class is UpdateTaskState, to wrap the
update_task_state callable passed into the snapshot driver method.

Change-Id: I77e14301dfe32b857028a8f26b0a174901e934f0
",git fetch https://review.opendev.org/openstack/nova-powervm refs/changes/58/194858/1 && git format-patch -1 --stdout FETCH_HEAD,"['nova_powervm/virt/powervm/tasks/image.py', 'nova_powervm/tests/virt/powervm/tasks/test_image.py']",2,0c6ab69c55c05e2970663f0c9c7da9e4ddef7cce,task_image,"# Copyright 2015 IBM Corp. # # All Rights Reserved. # # Licensed under the Apache License, Version 2.0 (the ""License""); you may # not use this file except in compliance with the License. You may obtain # a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT # WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the # License for the specific language governing permissions and limitations # under the License. from nova import test from nova_powervm.virt.powervm.tasks import image as tsk_img class TestImage(test.TestCase): def test_update_task_state(self): def func(task_state, expected_state): self.assertEqual('task_state', task_state) self.assertIsNone(expected_state) tf = tsk_img.UpdateTaskState(func, 'task_state') self.assertEqual('update_task_state_task_state', tf.name) tf.execute() def func2(task_state, expected_state): self.assertEqual('task_state', task_state) self.assertEqual('expected_state', expected_state) tf = tsk_img.UpdateTaskState(func2, 'task_state', expected_state='expected_state') tf.execute() ",,78,0
openstack%2Fproject-config~master~I6aa360b35dbabcde62df78a3b20862672514d62e,openstack/project-config,master,I6aa360b35dbabcde62df78a3b20862672514d62e,Grant keystone core pushMerge on keystoneclient feature branches,MERGED,2015-06-23 20:22:30.000000000,2015-06-25 14:07:03.000000000,2015-06-25 07:28:16.000000000,"[{'_account_id': 3}, {'_account_id': 2750}, {'_account_id': 2903}, {'_account_id': 4146}, {'_account_id': 6486}, {'_account_id': 6547}]","[{'number': 1, 'created': '2015-06-23 20:22:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/project-config/commit/29083b56908b9e3bc9f01aedab1e69f531e25f15', 'message': 'Grant keystone core pushMerge on keystoneauth feature branch\n\nNobody had authority to merge master to the keystoneauth feature\nbranch.\n\nChange-Id: I6aa360b35dbabcde62df78a3b20862672514d62e\n'}, {'number': 2, 'created': '2015-06-23 20:54:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/project-config/commit/56b77574cab01a18ffbacb24f694d175437a949b', 'message': 'Grant keystone core pushMerge on keystoneclient feature branches\n\nNobody had authority to merge master to the\nkeystoneauth_integration feature branch. Just give keystone core\npushMerge on any feature branches now and future.\n\nChange-Id: I6aa360b35dbabcde62df78a3b20862672514d62e\n'}, {'number': 3, 'created': '2015-06-23 20:59:42.000000000', 'files': ['gerrit/acls/openstack/python-keystoneclient.config'], 'web_link': 'https://opendev.org/openstack/project-config/commit/9a56ee55e5f020315dd2533cf6ea300d2a4fe6b6', 'message': 'Grant keystone core pushMerge on keystoneclient feature branches\n\nNobody had authority to merge master to the\nkeystoneauth_integration feature branch. Just give keystone core\npushMerge on any feature branches now and future.\n\nChange-Id: I6aa360b35dbabcde62df78a3b20862672514d62e\n'}]",1,194801,9a56ee55e5f020315dd2533cf6ea300d2a4fe6b6,14,6,3,6486,,,0,"Grant keystone core pushMerge on keystoneclient feature branches

Nobody had authority to merge master to the
keystoneauth_integration feature branch. Just give keystone core
pushMerge on any feature branches now and future.

Change-Id: I6aa360b35dbabcde62df78a3b20862672514d62e
",git fetch https://review.opendev.org/openstack/project-config refs/changes/01/194801/3 && git format-patch -1 --stdout FETCH_HEAD,['gerrit/acls/openstack/python-keystoneclient.config'],1,29083b56908b9e3bc9f01aedab1e69f531e25f15,keystoneauth_integration,"[access ""refs/heads/feature/keystoneauth_integration""] pushMerge = group keystone-core ",,3,0
openstack%2Ffuel-docs~master~If1cc7c4e2ae67275b042432932c634e1fd95d620,openstack/fuel-docs,master,If1cc7c4e2ae67275b042432932c634e1fd95d620,Update patching and repos configuration,MERGED,2015-06-25 11:58:53.000000000,2015-06-25 14:01:28.000000000,2015-06-25 14:01:27.000000000,"[{'_account_id': 3}, {'_account_id': 406}, {'_account_id': 8786}, {'_account_id': 8971}, {'_account_id': 13082}]","[{'number': 1, 'created': '2015-06-25 11:58:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-docs/commit/a93ece8221762ed1e80090da0fc37ca7c43e19ac', 'message': 'Update patching and repos configuration\n\nUpdate the patching description and repo\nconfiguration. Repo configuration is a separate\nchapter now crosslink with the patching and\nexternal Ubuntu.\n\nChange-Id: If1cc7c4e2ae67275b042432932c634e1fd95d620\n'}, {'number': 2, 'created': '2015-06-25 12:10:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-docs/commit/f944081c85ed733afb73c737a5b249a7b8b1fa59', 'message': 'Update patching and repos configuration\n\nUpdate the patching description and repo\nconfiguration. Repo configuration is a separate\nchapter now crosslink with the patching and\nexternal Ubuntu.\n\nChange-Id: If1cc7c4e2ae67275b042432932c634e1fd95d620\n'}, {'number': 3, 'created': '2015-06-25 12:18:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-docs/commit/17f18852cba509fa3f47fef6ebf43bbbd4dac847', 'message': 'Update patching and repos configuration\n\nUpdate the patching description and repo\nconfiguration. Repo configuration is a separate\nchapter now crosslink with the patching and\nexternal Ubuntu.\n\nChange-Id: If1cc7c4e2ae67275b042432932c634e1fd95d620\n'}, {'number': 4, 'created': '2015-06-25 12:22:28.000000000', 'files': ['pages/operations/configuring-repos-ops.rst', 'pages/operations/external-ubuntu-ops.rst', 'contents/contents-operations.rst'], 'web_link': 'https://opendev.org/openstack/fuel-docs/commit/22d4606e4b92a7e5891d987b7a6259fb9453a7e8', 'message': 'Update patching and repos configuration\n\nUpdate the patching description and repo\nconfiguration. Repo configuration is a separate\nchapter now crosslink with the patching and\nexternal Ubuntu.\n(!) These are asap temporary fixes.\n\nChange-Id: If1cc7c4e2ae67275b042432932c634e1fd95d620\n'}]",0,195542,22d4606e4b92a7e5891d987b7a6259fb9453a7e8,22,5,4,14342,,,0,"Update patching and repos configuration

Update the patching description and repo
configuration. Repo configuration is a separate
chapter now crosslink with the patching and
external Ubuntu.
(!) These are asap temporary fixes.

Change-Id: If1cc7c4e2ae67275b042432932c634e1fd95d620
",git fetch https://review.opendev.org/openstack/fuel-docs refs/changes/42/195542/4 && git format-patch -1 --stdout FETCH_HEAD,"['pages/operations/configuring-repos-ops.rst', 'pages/operations/external-ubuntu-ops.rst']",2,a93ece8221762ed1e80090da0fc37ca7c43e19ac,repoConfig,==================================See also :ref:`Configuring repositories<configuring-repos-ops>`. Setting up local mirrors ------------------------ You can create and update local mirrors of Mirantis OpenStack and/or Ubuntu packages using the ``fuel-createmirror`` script.,Configuring repositories ======================== Configuring repositories is not specific to the Mirantis OpenStack or Fuel products. The process of setting up repositories and repository priorities is the same one you normally do on your Linux distribution. Consult with your distribution's help if you are not sure: * `Ubuntu <https://help.ubuntu.com/community/Repositories/Ubuntu>`_ * `CentOS <http://wiki.centos.org/PackageManagement/Yum/Priorities>`_ ----------------------------------fuel-createmirror usage ----------------------- The ``fuel-createmirror`` script creates and updates local mirrors of Mirantis OpenStack and/or Ubuntu packages.,16,20
openstack%2Ffuel-docs~stable%2F6.1~If1cc7c4e2ae67275b042432932c634e1fd95d620,openstack/fuel-docs,stable/6.1,If1cc7c4e2ae67275b042432932c634e1fd95d620,Update patching and repos configuration,MERGED,2015-06-25 13:45:30.000000000,2015-06-25 13:59:46.000000000,2015-06-25 13:59:46.000000000,"[{'_account_id': 3}, {'_account_id': 8971}, {'_account_id': 13082}]","[{'number': 1, 'created': '2015-06-25 13:45:30.000000000', 'files': ['pages/operations/configuring-repos-ops.rst', 'pages/operations/external-ubuntu-ops.rst', 'contents/contents-operations.rst'], 'web_link': 'https://opendev.org/openstack/fuel-docs/commit/4d72b6816ec43b088f380caf0755834fa43bf704', 'message': 'Update patching and repos configuration\n\nUpdate the patching description and repo\nconfiguration. Repo configuration is a separate\nchapter now crosslink with the patching and\nexternal Ubuntu.\n(!) These are asap temporary fixes.\n\nChange-Id: If1cc7c4e2ae67275b042432932c634e1fd95d620\n'}]",0,195591,4d72b6816ec43b088f380caf0755834fa43bf704,7,3,1,14342,,,0,"Update patching and repos configuration

Update the patching description and repo
configuration. Repo configuration is a separate
chapter now crosslink with the patching and
external Ubuntu.
(!) These are asap temporary fixes.

Change-Id: If1cc7c4e2ae67275b042432932c634e1fd95d620
",git fetch https://review.opendev.org/openstack/fuel-docs refs/changes/91/195591/1 && git format-patch -1 --stdout FETCH_HEAD,"['pages/operations/configuring-repos-ops.rst', 'pages/operations/external-ubuntu-ops.rst', 'contents/contents-operations.rst']",3,4d72b6816ec43b088f380caf0755834fa43bf704,,.. include:: /pages/operations/external-ubuntu-ops.rst,.. include:: /pages/operations/external-ubuntu-ops.rst,17,22
openstack%2Ffuel-library~master~Id96aaf32fad8dc5e7bf14a4bedf3c795518dfd21,openstack/fuel-library,master,Id96aaf32fad8dc5e7bf14a4bedf3c795518dfd21,Looking only for eth* in rps_cpus (),MERGED,2015-06-22 16:02:47.000000000,2015-06-25 13:50:52.000000000,2015-06-25 13:50:02.000000000,"[{'_account_id': 3}, {'_account_id': 8786}, {'_account_id': 8971}, {'_account_id': 9037}, {'_account_id': 9387}, {'_account_id': 11090}, {'_account_id': 13344}, {'_account_id': 14774}]","[{'number': 1, 'created': '2015-06-22 16:02:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/aca2b31d2e9b8109ca93a4e5e718ef9f642d0a86', 'message': 'Reject vrouter-host in  rps_cpus ()\n\nProblem:\nnetconfig_post rb foolow checks failed on controller\n* test_rps_cpus_set\n* test_rps_cpus_config\n\nCaused by: we include vrouter-host interface in checks\nin function rps_cpu and ignore only lo.\nso add vrouter-host interface to rejected\nwhen we invoke rps_cpus for all data in /sys/class/net/\n\nFuel-CI: disable\n\nChange-Id: Id96aaf32fad8dc5e7bf14a4bedf3c795518dfd21\nCloses-Bug: #1433087\n'}, {'number': 2, 'created': '2015-06-22 16:05:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/a23f56b4a7ac19f22b540de6db1aabe9bd416c3a', 'message': 'Reject vrouter-host in  rps_cpus ()\n\nProblem:\nnetconfig_post rb flowing checks failed on controller\n* test_rps_cpus_set\n* test_rps_cpus_config\n\nCaused by: we include vrouter-host interface in checks\nin function rps_cpu and ignore only lo.\nso add vrouter-host interface to rejected\nwhen we invoke rps_cpus for all data in /sys/class/net/\n\nFuel-CI: disable\n\nChange-Id: Id96aaf32fad8dc5e7bf14a4bedf3c795518dfd21\nCloses-Bug: #1433087\n'}, {'number': 3, 'created': '2015-06-24 13:06:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/3d47f998a124255bf9b7ba8a21a9ee356c726483', 'message': 'Reject vrouter-host in  rps_cpus ()\n\nProblem:\nnetconfig_post rb checks listed bellow are failed on controller\n* test_rps_cpus_set\n* test_rps_cpus_config\n\nCaused by: we include vrouter-host interface in checks\nin function rps_cpu and ignore only lo.\nso add vrouter-host interface to rejected\nwhen we invoke rps_cpus for all data in /sys/class/net/\n\nFuel-CI: disable\n\nChange-Id: Id96aaf32fad8dc5e7bf14a4bedf3c795518dfd21\nCloses-Bug: #1433087\n'}, {'number': 4, 'created': '2015-06-24 14:53:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/35ecb2bb95da68c4b76ce5fb8fba3589004178aa', 'message': 'Reject vrouter-host in  rps_cpus ()\n\nProblem:\nnetconfig_post rb foolow checks failed on controller\n* test_rps_cpus_set\n* test_rps_cpus_config\n\nCaused by: we include vrouter-host interface in checks\nin function rps_cpu and ignore only lo.\nso add vrouter-host interface to rejected\nwhen we invoke rps_cpus for all data in /sys/class/net/\n\nFuel-CI: disable\n\nChange-Id: Id96aaf32fad8dc5e7bf14a4bedf3c795518dfd21\nCloses-Bug: #1433087\n'}, {'number': 5, 'created': '2015-06-24 15:13:06.000000000', 'files': ['deployment/puppet/osnailyfacter/modular/netconfig/netconfig_post.rb'], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/b7c47f74bd84524d3c81bc96255815a8a5ebce4c', 'message': 'Looking only for eth* in rps_cpus ()\n\nProblem:\nnetconfig_post rb foolow checks failed on controller\n* test_rps_cpus_set\n* test_rps_cpus_config\n\nCaused by: we include vrouter-host and other\nnot physical-interface in checks\nso start to look at eth* interfaces only\n\nFuel-CI: disable\n\nChange-Id: Id96aaf32fad8dc5e7bf14a4bedf3c795518dfd21\nCloses-Bug: #1433087\n'}]",0,194209,b7c47f74bd84524d3c81bc96255815a8a5ebce4c,74,8,5,6719,,,0,"Looking only for eth* in rps_cpus ()

Problem:
netconfig_post rb foolow checks failed on controller
* test_rps_cpus_set
* test_rps_cpus_config

Caused by: we include vrouter-host and other
not physical-interface in checks
so start to look at eth* interfaces only

Fuel-CI: disable

Change-Id: Id96aaf32fad8dc5e7bf14a4bedf3c795518dfd21
Closes-Bug: #1433087
",git fetch https://review.opendev.org/openstack/fuel-library refs/changes/09/194209/1 && git format-patch -1 --stdout FETCH_HEAD,['deployment/puppet/osnailyfacter/modular/netconfig/netconfig_post.rb'],1,aca2b31d2e9b8109ca93a4e5e718ef9f642d0a86,netconf_post," Dir.glob('/sys/class/net/*/queues/rx-*/rps_cpus').reject { |node| node.start_with? '/sys/class/net/lo' or '/sys/class/net/vrouter'} rps_cpus.each do |node| assert File.read(node).chomp.end_with?(hex_mask), ""Sysfs node: '#{node}' is not '#{hex_mask}'!"" assert File.exists?('/etc/sysfs.d/rps_cpus.conf'), 'RPS_CPUS sysfs config is missing!' rps_cpus.each do |line| line.gsub! %r(/sys/), '' line = ""#{line} = #{hex_mask}"" assert TestCommon::Config.has_line?('/etc/sysfs.d/rps_cpus.conf', line), ""Line '#{line}' is missing in the rps_cpus.conf!"""," Dir.glob('/sys/class/net/*/queues/rx-*/rps_cpus').reject { |node| node.start_with? '/sys/class/net/lo' } rps_cpus.each do |node| assert File.read(node).chomp.end_with?(hex_mask), ""Sysfs node: '#{node}' is not '#{hex_mask}'!"" assert File.exists?('/etc/sysfs.d/rps_cpus.conf'), 'RPS_CPUS sysfs config is missing!' rps_cpus.each do |line| line.gsub! %r(/sys/), '' line = ""#{line} = #{hex_mask}"" assert TestCommon::Config.has_line?('/etc/sysfs.d/rps_cpus.conf', line), ""Line '#{line}' is missing in the rps_cpus.conf!""",8,8
openstack%2Fdevstack~master~Iebe78925e5274a3466aaeee11b97c20162a8fb48,openstack/devstack,master,Iebe78925e5274a3466aaeee11b97c20162a8fb48,Set the notification_driver as messaging,ABANDONED,2015-06-25 11:24:38.000000000,2015-06-25 13:50:01.000000000,,"[{'_account_id': 6537}, {'_account_id': 10385}]","[{'number': 1, 'created': '2015-06-25 11:24:38.000000000', 'files': ['lib/ceilometer'], 'web_link': 'https://opendev.org/openstack/devstack/commit/638f00325a01a6b35b81b0180dcae883b274bc64', 'message': 'Set the notification_driver as messaging\n\nThe api-no-pipeline feature need configure notification_driver in\nceilometer.conf as default, the heat gate job has been broken for this\nissue (see the related bug).\n\nChange-Id: Iebe78925e5274a3466aaeee11b97c20162a8fb48\nRelated-bug: 1468697\n'}]",0,195530,638f00325a01a6b35b81b0180dcae883b274bc64,4,2,1,8290,,,0,"Set the notification_driver as messaging

The api-no-pipeline feature need configure notification_driver in
ceilometer.conf as default, the heat gate job has been broken for this
issue (see the related bug).

Change-Id: Iebe78925e5274a3466aaeee11b97c20162a8fb48
Related-bug: 1468697
",git fetch https://review.opendev.org/openstack/devstack refs/changes/30/195530/1 && git format-patch -1 --stdout FETCH_HEAD,['lib/ceilometer'],1,638f00325a01a6b35b81b0180dcae883b274bc64,bug/1468697," iniset $CEILOMETER_CONF DEFAULT notification_driver ""messaging""",,1,0
openstack%2Fkeystonemiddleware~stable%2Fkilo~I95a5192df12ec9ce540ee6397ceec8dbf3574d66,openstack/keystonemiddleware,stable/kilo,I95a5192df12ec9ce540ee6397ceec8dbf3574d66,Updated from global requirements,MERGED,2015-04-15 16:31:53.000000000,2015-06-25 13:44:26.000000000,2015-06-25 13:44:22.000000000,"[{'_account_id': 3}, {'_account_id': 741}, {'_account_id': 2472}, {'_account_id': 2903}, {'_account_id': 4190}, {'_account_id': 6486}]","[{'number': 1, 'created': '2015-04-15 16:31:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystonemiddleware/commit/3cc628c7593e7442c09e12d5401299f2f687715e', 'message': 'Updated from global requirements\n\nChange-Id: I95a5192df12ec9ce540ee6397ceec8dbf3574d66\n'}, {'number': 2, 'created': '2015-04-16 12:05:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystonemiddleware/commit/4085bc917260452f90a3ea30eb55734b9f8f5985', 'message': 'Updated from global requirements\n\nChange-Id: I95a5192df12ec9ce540ee6397ceec8dbf3574d66\n'}, {'number': 3, 'created': '2015-04-28 19:56:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystonemiddleware/commit/2e6e1e1432d2d3191a11769b617f0f942bc00e1e', 'message': 'Updated from global requirements\n\nChange-Id: I95a5192df12ec9ce540ee6397ceec8dbf3574d66\n'}, {'number': 4, 'created': '2015-05-04 20:12:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystonemiddleware/commit/5f73aa6a845aa59637d3ff0641d8e9ea7daec540', 'message': 'Updated from global requirements\n\nChange-Id: I95a5192df12ec9ce540ee6397ceec8dbf3574d66\n'}, {'number': 5, 'created': '2015-06-17 18:29:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystonemiddleware/commit/d30868795072b28ec827e7e114397fc8a4a48fd9', 'message': 'Updated from global requirements\n\nUpdated from stable/kilo requirements, keeping minimum\nversions unchanged while introducing necessary version\ncaps.\n\nCloses-Bug: 1463988\nChange-Id: I95a5192df12ec9ce540ee6397ceec8dbf3574d66\n'}, {'number': 6, 'created': '2015-06-24 17:53:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystonemiddleware/commit/6a3c3fe9b4c58a84c2d632bd2cfcc56cec9850b7', 'message': 'Updated from global requirements\n\nUpdated from stable/kilo requirements\n\nCloses-Bug: 1463988\nChange-Id: I95a5192df12ec9ce540ee6397ceec8dbf3574d66\n'}, {'number': 7, 'created': '2015-06-24 18:41:22.000000000', 'files': ['requirements.txt', 'test-requirements.txt', 'test-requirements-py3.txt'], 'web_link': 'https://opendev.org/openstack/keystonemiddleware/commit/fd12825acb92db08aea588522f9a91d7091f3a32', 'message': 'Updated from global requirements\n\nUpdated from stable/kilo requirements\n\nCloses-Bug: 1463988\nChange-Id: I95a5192df12ec9ce540ee6397ceec8dbf3574d66\n'}]",2,173972,fd12825acb92db08aea588522f9a91d7091f3a32,32,6,7,11131,,,0,"Updated from global requirements

Updated from stable/kilo requirements

Closes-Bug: 1463988
Change-Id: I95a5192df12ec9ce540ee6397ceec8dbf3574d66
",git fetch https://review.opendev.org/openstack/keystonemiddleware refs/changes/72/173972/6 && git format-patch -1 --stdout FETCH_HEAD,"['requirements.txt', 'test-requirements.txt', 'test-requirements-py3.txt']",3,3cc628c7593e7442c09e12d5401299f2f687715e,bug/1463988,"oslosphinx>=2.5.0,<2.6.0 # Apache-2.0 oslotest>=1.5.1,<1.6.0 # Apache-2.0 oslo.messaging>=1.8.0,<1.9.0 # Apache-2.0 requests-mock>=0.6.0 # Apache-2.0",oslosphinx>=2.2.0 # Apache-2.0 oslotest>=1.2.0 # Apache-2.0 oslo.messaging>=1.6.0 # Apache-2.0 requests-mock>=0.5.1 # Apache-2.0,13,13
openstack%2Fnetworking-ovn~master~I6c211eda8975c7283da5cc614c781f0e97f806c6,openstack/networking-ovn,master,I6c211eda8975c7283da5cc614c781f0e97f806c6,Remove random _ in code,MERGED,2015-06-24 20:53:44.000000000,2015-06-25 13:40:38.000000000,2015-06-25 13:40:37.000000000,"[{'_account_id': 3}, {'_account_id': 1561}, {'_account_id': 11343}]","[{'number': 1, 'created': '2015-06-24 20:53:44.000000000', 'files': ['networking_ovn/ml2/mech_driver.py'], 'web_link': 'https://opendev.org/openstack/networking-ovn/commit/f7e18d7957f2bbac1c63c84f6b6276e83ff68eb5', 'message': 'Remove random _ in code\n\nThis was introduced in 25c9eef4\n\nChange-Id: I6c211eda8975c7283da5cc614c781f0e97f806c6\n'}]",0,195312,f7e18d7957f2bbac1c63c84f6b6276e83ff68eb5,7,3,1,4395,,,0,"Remove random _ in code

This was introduced in 25c9eef4

Change-Id: I6c211eda8975c7283da5cc614c781f0e97f806c6
",git fetch https://review.opendev.org/openstack/networking-ovn refs/changes/12/195312/1 && git format-patch -1 --stdout FETCH_HEAD,['networking_ovn/ml2/mech_driver.py'],1,f7e18d7957f2bbac1c63c84f6b6276e83ff68eb5,,,_,1,1
openstack%2Fnetworking-ovn~master~I299b6da4e4ae225f2f348240c68bf8342ddfd0af,openstack/networking-ovn,master,I299b6da4e4ae225f2f348240c68bf8342ddfd0af,Add .sw? to .gitignore,MERGED,2015-06-24 20:55:25.000000000,2015-06-25 13:40:33.000000000,2015-06-25 13:40:29.000000000,"[{'_account_id': 3}, {'_account_id': 1561}, {'_account_id': 11343}]","[{'number': 1, 'created': '2015-06-24 20:55:25.000000000', 'files': ['.gitignore'], 'web_link': 'https://opendev.org/openstack/networking-ovn/commit/04ca2541fbe86b2b16520e7d688b4de5543f092c', 'message': 'Add .sw? to .gitignore\n\nChange-Id: I299b6da4e4ae225f2f348240c68bf8342ddfd0af\n'}]",0,195314,04ca2541fbe86b2b16520e7d688b4de5543f092c,7,3,1,4395,,,0,"Add .sw? to .gitignore

Change-Id: I299b6da4e4ae225f2f348240c68bf8342ddfd0af
",git fetch https://review.opendev.org/openstack/networking-ovn refs/changes/14/195314/1 && git format-patch -1 --stdout FETCH_HEAD,['.gitignore'],1,04ca2541fbe86b2b16520e7d688b4de5543f092c,,*.sw?,,1,0
openstack%2Foslo.service~master~I61170d3b8cebd6e3e381f33ddc52b6d0174efec4,openstack/oslo.service,master,I61170d3b8cebd6e3e381f33ddc52b6d0174efec4,Enforce H405 check,MERGED,2015-06-24 13:24:29.000000000,2015-06-25 13:38:46.000000000,2015-06-25 13:38:46.000000000,"[{'_account_id': 3}, {'_account_id': 1297}, {'_account_id': 5638}, {'_account_id': 14358}]","[{'number': 1, 'created': '2015-06-24 13:24:29.000000000', 'files': ['oslo_service/tests/test_periodic.py', 'tox.ini', 'oslo_service/threadgroup.py', 'oslo_service/periodic_task.py'], 'web_link': 'https://opendev.org/openstack/oslo.service/commit/eea13af6450ad162acf7d546a862386eafe40b5f', 'message': 'Enforce H405 check\n\nChange-Id: I61170d3b8cebd6e3e381f33ddc52b6d0174efec4\n'}]",0,195077,eea13af6450ad162acf7d546a862386eafe40b5f,8,4,1,7293,,,0,"Enforce H405 check

Change-Id: I61170d3b8cebd6e3e381f33ddc52b6d0174efec4
",git fetch https://review.opendev.org/openstack/oslo.service refs/changes/77/195077/1 && git format-patch -1 --stdout FETCH_HEAD,"['oslo_service/tests/test_periodic.py', 'tox.ini', 'oslo_service/threadgroup.py', 'oslo_service/periodic_task.py']",4,eea13af6450ad162acf7d546a862386eafe40b5f,pep8_checks," """"""Find the nearest boundary in the past. The boundary is a multiple of the spacing with the last run as an offset."," """"""Find nearest boundary which is in the past, which is a multiple of the spacing with the last run as an offset.",12,9
openstack%2Foslo.service~master~I7bf16a8cf317115d1d5f59c30db9d021ea0ad9b1,openstack/oslo.service,master,I7bf16a8cf317115d1d5f59c30db9d021ea0ad9b1,Enforce H301 check,MERGED,2015-06-24 13:24:29.000000000,2015-06-25 13:38:37.000000000,2015-06-25 13:38:34.000000000,"[{'_account_id': 3}, {'_account_id': 1297}, {'_account_id': 5638}]","[{'number': 1, 'created': '2015-06-24 13:24:29.000000000', 'files': ['tox.ini'], 'web_link': 'https://opendev.org/openstack/oslo.service/commit/f544d9b3f90d105718ed3660c67327eb08f4c423', 'message': 'Enforce H301 check\n\nRemoved H301 from excluded checks and added i18n integration\nmodule to hacking import_exceptions list according to [1].\n\n[1] http://docs.openstack.org/developer/oslo.i18n/usage.html\n\nChange-Id: I7bf16a8cf317115d1d5f59c30db9d021ea0ad9b1\n'}]",0,195076,f544d9b3f90d105718ed3660c67327eb08f4c423,7,3,1,7293,,,0,"Enforce H301 check

Removed H301 from excluded checks and added i18n integration
module to hacking import_exceptions list according to [1].

[1] http://docs.openstack.org/developer/oslo.i18n/usage.html

Change-Id: I7bf16a8cf317115d1d5f59c30db9d021ea0ad9b1
",git fetch https://review.opendev.org/openstack/oslo.service refs/changes/76/195076/1 && git format-patch -1 --stdout FETCH_HEAD,['tox.ini'],1,f544d9b3f90d105718ed3660c67327eb08f4c423,pep8_checks,"ignore = E123,E125,H405import_exceptions = oslo_service._i18n","ignore = E123,E125,H301,H405import_exceptions =",2,2
openstack%2Fopenstacksdk~master~I694e02b1607ecc2602b64a89a483aa70e864a8a0,openstack/openstacksdk,master,I694e02b1607ecc2602b64a89a483aa70e864a8a0,Docs for logging,MERGED,2015-06-22 23:09:00.000000000,2015-06-25 13:34:58.000000000,2015-06-25 13:34:33.000000000,"[{'_account_id': 3}, {'_account_id': 1112}, {'_account_id': 8257}, {'_account_id': 8736}]","[{'number': 1, 'created': '2015-06-22 23:09:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstacksdk/commit/cf7a744085958605973a3830a965415731a9ad37', 'message': 'Docs for logging\n\nChange-Id: I694e02b1607ecc2602b64a89a483aa70e864a8a0\nCloses-Bug: 1420060\n'}, {'number': 2, 'created': '2015-06-23 16:00:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstacksdk/commit/199f781a48ff56eeb3dec3ad95929036ab65b960', 'message': 'Docs for logging\n\nChange-Id: I694e02b1607ecc2602b64a89a483aa70e864a8a0\nCloses-Bug: 1420060\n'}, {'number': 3, 'created': '2015-06-23 17:33:12.000000000', 'files': ['doc/source/users/userguides/logging.rst', 'doc/source/conf.py', 'doc/source/users/index.rst'], 'web_link': 'https://opendev.org/openstack/openstacksdk/commit/439fb0c7fe75cf7a406d62e30d81e3bb4d664b4b', 'message': 'Docs for logging\n\nChange-Id: I694e02b1607ecc2602b64a89a483aa70e864a8a0\nCloses-Bug: 1420060\n'}]",2,194430,439fb0c7fe75cf7a406d62e30d81e3bb4d664b4b,14,4,3,1112,,,0,"Docs for logging

Change-Id: I694e02b1607ecc2602b64a89a483aa70e864a8a0
Closes-Bug: 1420060
",git fetch https://review.opendev.org/openstack/openstacksdk refs/changes/30/194430/1 && git format-patch -1 --stdout FETCH_HEAD,"['doc/source/users/userguides/logging.rst', 'doc/source/users/index.rst']",2,cf7a744085958605973a3830a965415731a9ad37,bug/1420060, Logging <userguides/logging>,,58,0
openstack%2Foslo.rootwrap~master~I7769e40c13e3bd740d5b8a949a61d1bcc127f137,openstack/oslo.rootwrap,master,I7769e40c13e3bd740d5b8a949a61d1bcc127f137,daemon: avoid raising UnboundLocalError to callers,MERGED,2015-06-15 17:02:48.000000000,2015-06-25 13:31:30.000000000,2015-06-25 13:31:25.000000000,"[{'_account_id': 3}, {'_account_id': 308}, {'_account_id': 708}, {'_account_id': 5638}, {'_account_id': 9656}]","[{'number': 1, 'created': '2015-06-15 17:02:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.rootwrap/commit/a3d1dc1a91de47cd95cce76f4db9b35c616c7ba7', 'message': ""daemon: avoid raising UnboundLocalError to callers\n\nIf something in the daemon_start() function fails before server variable\nis initialized, we get the following exception:\n\nUnboundLocalError: local variable 'server' referenced before assignment\n\nWe should not attempt to close connections or kill all threads for a\ndaemon that failed to start (or that hasn't even reached the moment of\nthe start).\n\nCloses-Bug: #1465350\nChange-Id: I7769e40c13e3bd740d5b8a949a61d1bcc127f137\n""}, {'number': 2, 'created': '2015-06-22 10:47:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.rootwrap/commit/1a04efe585a84b5fc9ce8550fb32648099404510', 'message': ""daemon: avoid raising UnboundLocalError to callers\n\nIf something in the daemon_start() function fails before server variable\nis initialized, we get the following exception:\n\nUnboundLocalError: local variable 'server' referenced before assignment\n\nWe should not attempt to close connections or kill all threads for a\ndaemon that failed to start (or that hasn't even reached the moment of\nthe start).\n\nCloses-Bug: #1465350\nChange-Id: I7769e40c13e3bd740d5b8a949a61d1bcc127f137\n""}, {'number': 3, 'created': '2015-06-22 10:50:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.rootwrap/commit/0d2ae6aad2303789ab9812d6e9b07954386cbea9', 'message': ""daemon: avoid raising UnboundLocalError to callers\n\nIf something in the daemon_start() function fails before server variable\nis initialized, we get the following exception:\n\nUnboundLocalError: local variable 'server' referenced before assignment\n\nWe should not attempt to close connections or kill all threads for a\ndaemon that failed to start (or that hasn't even reached the moment of\nthe start).\n\nCloses-Bug: #1465350\nChange-Id: I7769e40c13e3bd740d5b8a949a61d1bcc127f137\n""}, {'number': 4, 'created': '2015-06-22 10:51:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.rootwrap/commit/7cafcda05eccedbd0475e85f42bcac6048ad4d52', 'message': ""daemon: avoid raising UnboundLocalError to callers\n\nIf something in the daemon_start() function fails before server variable\nis initialized, we get the following exception:\n\nUnboundLocalError: local variable 'server' referenced before assignment\n\nWe should not attempt to close connections or kill all threads for a\ndaemon that failed to start (or that hasn't even reached the moment of\nthe start).\n\nCloses-Bug: #1465350\nChange-Id: I7769e40c13e3bd740d5b8a949a61d1bcc127f137\n""}, {'number': 5, 'created': '2015-06-23 11:21:30.000000000', 'files': ['oslo_rootwrap/daemon.py', 'oslo_rootwrap/tests/test_rootwrap.py'], 'web_link': 'https://opendev.org/openstack/oslo.rootwrap/commit/e0bf7767da36202747b6fc322f426bd2ca3fa041', 'message': ""daemon: avoid raising UnboundLocalError to callers\n\nIf something in the daemon_start() function fails before server variable\nis initialized, we get the following exception:\n\nUnboundLocalError: local variable 'server' referenced before assignment\n\nWe should not attempt to close connections or kill all threads for a\ndaemon that failed to start (or that hasn't even reached the moment of\nthe start).\n\nCloses-Bug: #1465350\nChange-Id: I7769e40c13e3bd740d5b8a949a61d1bcc127f137\n""}]",7,191895,e0bf7767da36202747b6fc322f426bd2ca3fa041,19,5,5,9656,,,0,"daemon: avoid raising UnboundLocalError to callers

If something in the daemon_start() function fails before server variable
is initialized, we get the following exception:

UnboundLocalError: local variable 'server' referenced before assignment

We should not attempt to close connections or kill all threads for a
daemon that failed to start (or that hasn't even reached the moment of
the start).

Closes-Bug: #1465350
Change-Id: I7769e40c13e3bd740d5b8a949a61d1bcc127f137
",git fetch https://review.opendev.org/openstack/oslo.rootwrap refs/changes/95/191895/3 && git format-patch -1 --stdout FETCH_HEAD,"['oslo_rootwrap/daemon.py', 'oslo_rootwrap/tests/test_rootwrap.py']",2,a3d1dc1a91de47cd95cce76f4db9b35c616c7ba7,bug/1465350,"from oslo_rootwrap import daemon class DaemonCleanupException(Exception): pass class DaemonCleanupTestCase(testtools.TestCase): @mock.patch('os.chmod') @mock.patch('shutil.rmtree') @mock.patch('tempfile.mkdtemp') @mock.patch.object(daemon.RootwrapManager, 'get_server', side_effect=DaemonCleanupException) def test_daemon_no_cleanup_for_uninitialized_server(self, gs, *args): self.assertRaises(DaemonCleanupException, daemon.daemon_start, config=None, filters=None)",,43,23
openstack%2Fmurano~master~I8794e56259bd9b1290987f2f0a8e63d0c9775c3f,openstack/murano,master,I8794e56259bd9b1290987f2f0a8e63d0c9775c3f,Document murano actions,MERGED,2015-06-16 09:17:04.000000000,2015-06-25 13:28:41.000000000,2015-06-25 13:28:38.000000000,"[{'_account_id': 3}, {'_account_id': 7225}, {'_account_id': 7535}, {'_account_id': 7549}, {'_account_id': 7821}, {'_account_id': 13149}, {'_account_id': 14265}, {'_account_id': 14947}, {'_account_id': 15168}]","[{'number': 1, 'created': '2015-06-16 09:17:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/murano/commit/2e8315c18700f412115cbbe41c3574b7a15b9db3', 'message': 'Document murano actions\n\n* API spec was updated\n* New content to the dev guide was added\n\nChange-Id: I8794e56259bd9b1290987f2f0a8e63d0c9775c3f\n'}, {'number': 2, 'created': '2015-06-16 13:50:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/murano/commit/28114d4709481ce05e90a3e2bd1428aeaa6ef120', 'message': 'Document murano actions\n\n* API spec was updated\n* New content to the dev guide was added\n\nChange-Id: I8794e56259bd9b1290987f2f0a8e63d0c9775c3f\n'}, {'number': 3, 'created': '2015-06-17 08:41:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/murano/commit/db164cf655d4bfb8104bcbad180daa1c112d75be', 'message': 'Document murano actions\n\n* API spec was updated\n* New content to the dev guide was added\n\nChange-Id: I8794e56259bd9b1290987f2f0a8e63d0c9775c3f\n'}, {'number': 4, 'created': '2015-06-18 09:46:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/murano/commit/c6b36e343a8f6e017920f3070e43114e2b692b54', 'message': 'Document murano actions\n\n* API spec was updated\n* New content to the dev guide was added\n\nChange-Id: I8794e56259bd9b1290987f2f0a8e63d0c9775c3f\n'}, {'number': 5, 'created': '2015-06-22 15:59:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/murano/commit/f5bea94f4e4c07eb91c1f36fbf852a26473699ec', 'message': 'Document murano actions\n\n* API spec was updated\n* New content to the dev guide was added\n\nChange-Id: I8794e56259bd9b1290987f2f0a8e63d0c9775c3f\n'}, {'number': 6, 'created': '2015-06-24 06:47:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/murano/commit/831d8953e2caa8608452c748075695682a832555', 'message': 'Document murano actions\n\n* API spec was updated\n* New content to the dev guide was added\n\nChange-Id: I8794e56259bd9b1290987f2f0a8e63d0c9775c3f\n'}, {'number': 7, 'created': '2015-06-24 15:03:32.000000000', 'files': ['doc/source/specification/murano-api.rst', 'doc/source/draft/appdev-guide/murano_pl.rst', 'doc/source/draft/appdev-guide/murano_pl/actions.rst'], 'web_link': 'https://opendev.org/openstack/murano/commit/815d69608103e56f98cf092f3fd0b88581e3462c', 'message': 'Document murano actions\n\n* API spec was updated\n* New content to the dev guide was added\n\nChange-Id: I8794e56259bd9b1290987f2f0a8e63d0c9775c3f\n'}]",24,192113,815d69608103e56f98cf092f3fd0b88581e3462c,48,9,7,7549,,,0,"Document murano actions

* API spec was updated
* New content to the dev guide was added

Change-Id: I8794e56259bd9b1290987f2f0a8e63d0c9775c3f
",git fetch https://review.opendev.org/openstack/murano refs/changes/13/192113/7 && git format-patch -1 --stdout FETCH_HEAD,"['doc/source/specification/murano-api.rst', 'doc/source/draft/appdev-guide/murano_pl.rst', 'doc/source/draft/appdev-guide/murano_pl/actions.rst']",3,2e8315c18700f412115cbbe41c3574b7a15b9db3,add-actions-doc,".. _actions: .. toctree:: :maxdepth: 2 ============== Murano Actions ============== Murano action is a type of MuranoPL method. The differences from regular MuranoPL method are: #. Action is executed on deployed objects. #. Action execution is initiated by API request, user do not have to call method manually. So murano action allows to perform any operations on objects: * getting information from the VM, like a config, that is generated during the deployment * VM rebooting * scaling List of available actions are formed during the environment deployment. Right after the deployment is finished, actions may be called asynchronously. Task id is generated on action execution request, so the action status can be tracked. .. note:: Actions may be called on any MuranoPL object, witch is ``Environment``, ``Application`` or any other. To indicate method as action ``Usage: Action`` is used. The example of action, that returns an archive, containing config file: :: exportConfig: Usage: Action Body: - $._environment.reporter.report($this, 'Action exportConfig called') - $resources: new(sys:Resources) - $template: $resources.yaml('ExportConfig.template') - $result: $.masterNode.instance.agent.call($template, $resources) - $._environment.reporter.report($this, 'Got archive from Kubernetes') - Return: new(std:File, base64Content => $result.content, filename => 'application.tar.gz') ",,129,0
openstack%2Fnova~master~Ieef59465547b2bb4a76a98712ed5325286b2e3d9,openstack/nova,master,Ieef59465547b2bb4a76a98712ed5325286b2e3d9,Merge SchedulerHints functional tests of v2 and v2.1,MERGED,2015-03-26 06:35:52.000000000,2015-06-25 13:27:50.000000000,2015-06-25 13:27:44.000000000,"[{'_account_id': 3}, {'_account_id': 2750}, {'_account_id': 5170}, {'_account_id': 6167}, {'_account_id': 8151}, {'_account_id': 8556}, {'_account_id': 9008}, {'_account_id': 9578}, {'_account_id': 10118}, {'_account_id': 10206}, {'_account_id': 10385}, {'_account_id': 13663}, {'_account_id': 15286}, {'_account_id': 15751}, {'_account_id': 16897}]","[{'number': 1, 'created': '2015-03-26 06:35:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/cd9466e804a41c1d1919b1240bbee082dc75a76f', 'message': 'Merge quota_classes functional tests of v2 and v2.1\n\nCurrently v2 and v2.1 have separate functional tests and their\ncorresponding sample files. As v2 and v2.1 are supposed to be identical,\nthere is overhead to maintain two set of functional tests and sample files.\nWe can have one set of tests which can run for both v2 and v2.1.\n\nThis commit merges scheduler_hints functional tests.\n\nPartially implements merge_sample_tests\n\nChange-Id: Ieef59465547b2bb4a76a98712ed5325286b2e3d9\n'}, {'number': 2, 'created': '2015-03-26 07:07:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/0acac67561e5d3bed699b5e9d7ee3816fb2fdf04', 'message': 'Merge SchedulerHints functional tests of v2 and v2.1\n\nCurrently v2 and v2.1 have separate functional tests and their\ncorresponding sample files. As v2 and v2.1 are supposed to be identical,\nthere is overhead to maintain two set of functional tests and sample files.\nWe can have one set of tests which can run for both v2 and v2.1.\n\nThis commit merges scheduler_hints functional tests.\n\nPartially implements merge_sample_tests\n\nChange-Id: Ieef59465547b2bb4a76a98712ed5325286b2e3d9\n'}, {'number': 3, 'created': '2015-04-10 04:21:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/bbad01c16af131ac47984e947477320ca05dfde2', 'message': 'Merge SchedulerHints functional tests of v2 and v2.1\n\nCurrently v2 and v2.1 have separate functional tests and their\ncorresponding sample files. As v2 and v2.1 are supposed to be identical,\nthere is overhead to maintain two set of functional tests and sample files.\nWe can have one set of tests which can run for both v2 and v2.1.\n\nThis commit merges scheduler_hints functional tests.\n\nPartially implements merge_sample_tests\n\nChange-Id: Ieef59465547b2bb4a76a98712ed5325286b2e3d9\n'}, {'number': 4, 'created': '2015-04-10 04:36:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/d568dc46a82ca1a81f4dc0c162f9cc0accfc45ff', 'message': 'Merge SchedulerHints functional tests of v2 and v2.1\n\nCurrently v2 and v2.1 have separate functional tests and their\ncorresponding sample files. As v2 and v2.1 are supposed to be identical,\nthere is overhead to maintain two set of functional tests and sample files.\nWe can have one set of tests which can run for both v2 and v2.1.\n\nThis commit merges scheduler_hints functional tests.\n\nPartially implements merge_sample_tests\n\nChange-Id: Ieef59465547b2bb4a76a98712ed5325286b2e3d9\n'}, {'number': 5, 'created': '2015-04-10 05:50:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/0a1dbb273dfef3cae3d406929f24241dbdb152b6', 'message': 'Merge SchedulerHints functional tests of v2 and v2.1\n\nCurrently v2 and v2.1 have separate functional tests and their\ncorresponding sample files. As v2 and v2.1 are supposed to be identical,\nthere is overhead to maintain two set of functional tests and sample files.\nWe can have one set of tests which can run for both v2 and v2.1.\n\nThis commit merges scheduler_hints functional tests.\n\nPartially implements merge_sample_tests\n\nChange-Id: Ieef59465547b2bb4a76a98712ed5325286b2e3d9\n'}, {'number': 6, 'created': '2015-06-15 08:08:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/abc4a2cee9b6981b718d3f59eee1cb07498d781c', 'message': 'Merge SchedulerHints functional tests of v2 and v2.1\n\nCurrently v2 and v2.1 have separate functional tests and their\ncorresponding sample files. As v2 and v2.1 are supposed to be identical,\nthere is overhead to maintain two set of functional tests and sample files.\nWe can have one set of tests which can run for both v2 and v2.1.\n\nThis commit merges scheduler_hints functional tests.\n\nChange-Id: Ieef59465547b2bb4a76a98712ed5325286b2e3d9\n'}, {'number': 7, 'created': '2015-06-15 09:19:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/72ccdf322c57c2ca1b36eced05708c8ec9e5151b', 'message': 'Merge SchedulerHints functional tests of v2 and v2.1\n\nCurrently v2 and v2.1 have separate functional tests and their\ncorresponding sample files. As v2 and v2.1 are supposed to be identical,\nthere is overhead to maintain two set of functional tests and sample files.\nWe can have one set of tests which can run for both v2 and v2.1.\n\nThis commit merges scheduler_hints functional tests.\n\nChange-Id: Ieef59465547b2bb4a76a98712ed5325286b2e3d9\n'}, {'number': 8, 'created': '2015-06-25 05:35:54.000000000', 'files': ['nova/tests/functional/v3/api_samples/os-scheduler-hints/scheduler-hints-post-resp.json.tpl', 'doc/api_samples/OS-SCH-HNT/scheduler-hints-post-resp.json', 'nova/tests/functional/test_api_samples.py', 'doc/api_samples/OS-SCH-HNT/scheduler-hints-post-req.json', 'nova/tests/functional/api_samples/OS-SCH-HNT/scheduler-hints-post-req.json.tpl', 'nova/tests/functional/api_samples/OS-SCH-HNT/scheduler-hints-post-resp.json.tpl', 'doc/v3/api_samples/os-scheduler-hints/scheduler-hints-post-resp.json', 'nova/tests/functional/v3/test_scheduler_hints.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/3f5043171202fca389e9bcfd3d0ba76a00306832', 'message': 'Merge SchedulerHints functional tests of v2 and v2.1\n\nCurrently v2 and v2.1 have separate functional tests and their\ncorresponding sample files. As v2 and v2.1 are supposed to be identical,\nthere is overhead to maintain two set of functional tests and sample files.\nWe can have one set of tests which can run for both v2 and v2.1.\n\nThis commit merges scheduler_hints functional tests.\n\nChange-Id: Ieef59465547b2bb4a76a98712ed5325286b2e3d9\n'}]",3,167903,3f5043171202fca389e9bcfd3d0ba76a00306832,69,15,8,10206,,,0,"Merge SchedulerHints functional tests of v2 and v2.1

Currently v2 and v2.1 have separate functional tests and their
corresponding sample files. As v2 and v2.1 are supposed to be identical,
there is overhead to maintain two set of functional tests and sample files.
We can have one set of tests which can run for both v2 and v2.1.

This commit merges scheduler_hints functional tests.

Change-Id: Ieef59465547b2bb4a76a98712ed5325286b2e3d9
",git fetch https://review.opendev.org/openstack/nova refs/changes/03/167903/8 && git format-patch -1 --stdout FETCH_HEAD,"['doc/api_samples/OS-SCH-HNT/scheduler-hints-post-resp.json', 'nova/tests/functional/test_api_samples.py', 'doc/api_samples/OS-SCH-HNT/scheduler-hints-post-req.json', 'nova/tests/functional/api_samples/OS-SCH-HNT/scheduler-hints-post-req.json.tpl', 'nova/tests/functional/api_samples/OS-SCH-HNT/scheduler-hints-post-resp.json.tpl', 'nova/tests/functional/v3/test_scheduler_hints.py']",6,cd9466e804a41c1d1919b1240bbee082dc75a76f,merge_sample_tests,"from oslo_config import cfg CONF = cfg.CONF CONF.import_opt('osapi_compute_extension', 'nova.api.openstack.compute.extensions') # TODO(gmann): Overriding '_api_version' till all functional tests # are merged between v2 and v2.1. After that base class variable # itself can be changed to 'v2' _api_version = 'v2' def _get_flags(self): f = super(SchedulerHintsJsonTest, self)._get_flags() f['osapi_compute_extension'] = CONF.osapi_compute_extension[:] f['osapi_compute_extension'].append( ""nova.api.openstack.compute.contrib.scheduler_hints."" ""Scheduler_hints"") return f ",,19,69
openstack%2Fnova~master~I683580f668158e8dea5714105946535ee6124e51,openstack/nova,master,I683580f668158e8dea5714105946535ee6124e51,Cells: Skip initial sync of block_device_mapping,MERGED,2015-04-14 20:24:04.000000000,2015-06-25 13:26:43.000000000,2015-06-25 13:26:37.000000000,"[{'_account_id': 3}, {'_account_id': 1653}, {'_account_id': 2750}, {'_account_id': 4690}, {'_account_id': 5170}, {'_account_id': 5441}, {'_account_id': 7166}, {'_account_id': 8119}, {'_account_id': 9008}, {'_account_id': 9578}, {'_account_id': 10118}, {'_account_id': 10385}, {'_account_id': 15286}, {'_account_id': 15751}, {'_account_id': 16897}]","[{'number': 1, 'created': '2015-04-14 20:24:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/8881a80399b5a74586a9f8ddfea9120125ed711c', 'message': 'Cells: Skip initial sync of block_device_mapping\n\nWhen initially creating the block device mapping in a child cell it is\nsynced up to the api without a device name. Since later syncs rely on\nthe device name to find and update the block device mapping versus\ncreating a new one we should skip this sync and wait for the later\nupdate.\n\nChange-Id: I683580f668158e8dea5714105946535ee6124e51\nCloses-Bug: 1444128\n'}, {'number': 2, 'created': '2015-06-11 21:00:26.000000000', 'files': ['nova/tests/unit/objects/test_block_device.py', 'nova/objects/block_device.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/0516f2165ea21a3962e7671b83b9bdda4064fb42', 'message': 'Cells: Skip initial sync of block_device_mapping\n\nWhen initially creating the block device mapping in a child cell it is\nsynced up to the api without a device name. Since later syncs rely on\nthe device name to find and update the block device mapping versus\ncreating a new one we should skip this sync and wait for the later\nupdate.\n\nChange-Id: I683580f668158e8dea5714105946535ee6124e51\nCloses-Bug: 1444128\n'}]",4,173502,0516f2165ea21a3962e7671b83b9bdda4064fb42,29,15,2,5441,,,0,"Cells: Skip initial sync of block_device_mapping

When initially creating the block device mapping in a child cell it is
synced up to the api without a device name. Since later syncs rely on
the device name to find and update the block device mapping versus
creating a new one we should skip this sync and wait for the later
update.

Change-Id: I683580f668158e8dea5714105946535ee6124e51
Closes-Bug: 1444128
",git fetch https://review.opendev.org/openstack/nova refs/changes/02/173502/1 && git format-patch -1 --stdout FETCH_HEAD,"['nova/tests/unit/objects/test_block_device.py', 'nova/objects/block_device.py']",2,8881a80399b5a74586a9f8ddfea9120125ed711c,bug/1444128," # NOTE(alaski): update_or_create is only True when first creating the # bdm. We don't want to sync that call as it may not have a # device_name yet, so when a later update comes it wouldn't find this # bdm and would create a second one. if cell_type == 'compute' and not update_or_create:", if cell_type == 'compute':,6,2
openstack%2Fheat~master~Ic4bac41683d2efc21d1f735ec51d3056caed049a,openstack/heat,master,Ic4bac41683d2efc21d1f735ec51d3056caed049a,DO NOT MERGE test bug,ABANDONED,2015-06-25 09:40:44.000000000,2015-06-25 13:25:55.000000000,,[{'_account_id': 3}],"[{'number': 1, 'created': '2015-06-25 09:40:44.000000000', 'files': ['README.rst'], 'web_link': 'https://opendev.org/openstack/heat/commit/d4f380784b71659c0ff9f237a768e4c08014cee6', 'message': 'DO NOT MERGE test bug\n\nChange-Id: Ic4bac41683d2efc21d1f735ec51d3056caed049a\nDepends-On: I6a1587e4aae055cc559286367632249865008654\n'}]",0,195483,d4f380784b71659c0ff9f237a768e4c08014cee6,4,1,1,7385,,,0,"DO NOT MERGE test bug

Change-Id: Ic4bac41683d2efc21d1f735ec51d3056caed049a
Depends-On: I6a1587e4aae055cc559286367632249865008654
",git fetch https://review.opendev.org/openstack/heat refs/changes/83/195483/1 && git format-patch -1 --stdout FETCH_HEAD,['README.rst'],1,d4f380784b71659c0ff9f237a768e4c08014cee6,test-ceilo-pb,,,1,0
openstack%2Fceilometer~master~I6a1587e4aae055cc559286367632249865008654,openstack/ceilometer,master,I6a1587e4aae055cc559286367632249865008654,"Revert ""Add support for posting samples..""",ABANDONED,2015-06-25 09:38:52.000000000,2015-06-25 13:25:51.000000000,,"[{'_account_id': 3}, {'_account_id': 9545}]","[{'number': 1, 'created': '2015-06-25 09:38:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/73d2e8b2515d4f1248ba9ad5c303e71574c6e8e0', 'message': 'WIP: test revert\n\nTest revert of 9d920e4de6b77bfcf17b7f1b3332d7779416b32d to see if it\nsolves heat test problem.\n\nChange-Id: I6a1587e4aae055cc559286367632249865008654\n'}, {'number': 2, 'created': '2015-06-25 13:20:58.000000000', 'files': ['ceilometer/tests/gabbi/gabbits/clean-samples.yaml', 'ceilometer/api/app.py', 'ceilometer/tests/gabbi/gabbits/meters.yaml', 'ceilometer/api/controllers/v2/meters.py', 'ceilometer/api/hooks.py', 'ceilometer/tests/api/test_app.py', 'ceilometer/tests/api/v2/test_post_samples_scenarios.py'], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/a448a3b35ab854dea0a95295940a6179f2055126', 'message': 'Revert ""Add support for posting samples..""\n\nRevert 9d920e4de6b77bfcf17b7f1b3332d7779416b32d as it\'s breaking default\nbehavior when posting samples, as discovered in Heat integration tests.\n\nCloses-Bug: #1468697\nChange-Id: I6a1587e4aae055cc559286367632249865008654\n'}]",0,195482,a448a3b35ab854dea0a95295940a6179f2055126,5,2,2,7385,,,0,"Revert ""Add support for posting samples..""

Revert 9d920e4de6b77bfcf17b7f1b3332d7779416b32d as it's breaking default
behavior when posting samples, as discovered in Heat integration tests.

Closes-Bug: #1468697
Change-Id: I6a1587e4aae055cc559286367632249865008654
",git fetch https://review.opendev.org/openstack/ceilometer refs/changes/82/195482/1 && git format-patch -1 --stdout FETCH_HEAD,"['ceilometer/tests/gabbi/gabbits/clean-samples.yaml', 'ceilometer/api/app.py', 'ceilometer/tests/gabbi/gabbits/meters.yaml', 'ceilometer/api/controllers/v2/meters.py', 'ceilometer/api/hooks.py', 'ceilometer/tests/api/test_app.py', 'ceilometer/tests/api/v2/test_post_samples_scenarios.py']",7,73d2e8b2515d4f1248ba9ad5c303e71574c6e8e0,bug/1468697,"from ceilometer import pipeline notifier.sample.side_effect = self.fake_notifier_sample self.useFixture(mockpatch.Patch('oslo_messaging.Notifier', @mock.patch.object(pipeline.SampleSource, ""support_meter"") def test_post_not_supported_sample(self, mocked): mocked.return_value = False s = [{'counter_name': 'apples', 'counter_type': 'gauge', 'counter_unit': 'instance', 'counter_volume': 1, 'resource_id': 'bd9431c1-8d69-4ad3-803a-8d4a6b89fd36', 'project_id': '35b17138-b364-4e6a-a131-8f3099c5be68', 'user_id': 'efd87807-12d2-4b38-9c70-5f5c2ac427ff', 'resource_metadata': {'name1': 'value1', 'name2': 'value2'}}] resp = self.post_json('/meters/apples/', s, expect_errors=True) self.assertEqual(409, resp.status_code) expected_msg = (""The metric apples is not supported by metering "" ""pipeline configuration."") self.assertEqual(expected_msg, resp.json['error_message']['faultstring']) "," notifier.info.side_effect = self.fake_notifier_sample self.useFixture(mockpatch.Patch('ceilometer.messaging.get_notifier',",65,55
openstack%2Fnova~master~I6b2c61f413707a3b01e316209877fc7cdd452cc9,openstack/nova,master,I6b2c61f413707a3b01e316209877fc7cdd452cc9,Logging corrected,MERGED,2015-06-24 21:15:27.000000000,2015-06-25 13:25:47.000000000,2015-06-25 13:25:37.000000000,"[{'_account_id': 3}, {'_account_id': 2750}, {'_account_id': 5170}, {'_account_id': 5441}, {'_account_id': 9578}, {'_account_id': 10118}, {'_account_id': 10385}, {'_account_id': 15286}, {'_account_id': 16897}]","[{'number': 1, 'created': '2015-06-24 21:15:27.000000000', 'files': ['nova/api/openstack/urlmap.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/5ed05b9ae0e2bdc0b60d9f51b07031f3769fe0a6', 'message': ""Logging corrected\n\nDict object environ doesn't have PATH_INFO attribute\nbut it has key 'PATH_INFO'.\n\nChange-Id: I6b2c61f413707a3b01e316209877fc7cdd452cc9\n""}]",0,195321,5ed05b9ae0e2bdc0b60d9f51b07031f3769fe0a6,13,9,1,14358,,,0,"Logging corrected

Dict object environ doesn't have PATH_INFO attribute
but it has key 'PATH_INFO'.

Change-Id: I6b2c61f413707a3b01e316209877fc7cdd452cc9
",git fetch https://review.opendev.org/openstack/nova refs/changes/21/195321/1 && git format-patch -1 --stdout FETCH_HEAD,['nova/api/openstack/urlmap.py'],1,5ed05b9ae0e2bdc0b60d9f51b07031f3769fe0a6,," LOG.debug('Could not find application for %s', environ['PATH_INFO'])"," LOG.debug('Could not find application for %s', environ.PATH_INFO)",1,1
openstack%2Fceilometer~master~Id02d31f790e60a367fab0cd76c98690c9ff431a3,openstack/ceilometer,master,Id02d31f790e60a367fab0cd76c98690c9ff431a3,Add support for posting samples to notification-agent via API,MERGED,2015-06-19 09:46:18.000000000,2015-06-25 13:25:15.000000000,2015-06-25 03:37:30.000000000,"[{'_account_id': 3}, {'_account_id': 4491}, {'_account_id': 6537}, {'_account_id': 7478}, {'_account_id': 8290}, {'_account_id': 10987}]","[{'number': 1, 'created': '2015-06-19 09:46:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/8cd61f1aec730f2074dab79aac291797af696e62', 'message': ""Add support for posting samples to notification-agent via API\n\nThis change make the ceilometer-api getting rid the pipline. samples will\nbe push to notification bus when creating via /v2/meters API.\n\nTo avoid the ceilometer-api's dependency of notification-agent, especially\nin some testing scenarios, this change also provide a optional parameter\nthat allow samples posted to storage directly.\n\nPartially implements: blueprint api-no-pipeline\n\nChange-Id: Id02d31f790e60a367fab0cd76c98690c9ff431a3\n""}, {'number': 2, 'created': '2015-06-19 09:50:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/e5f0af5c109367acadb742b95307895c69520306', 'message': ""Add support for posting samples to notification-agent via API\n\nThis change make the ceilometer-api getting rid the pipline. samples will\nbe push to notification bus when creating via /v2/meters API.\n\nTo avoid the ceilometer-api's dependency of notification-agent, especially\nin some testing scenarios, this change also provide a optional parameter\nthat allow samples posted to storage directly.\n\nPartially implements: blueprint api-no-pipeline\n\nChange-Id: Id02d31f790e60a367fab0cd76c98690c9ff431a3\n""}, {'number': 3, 'created': '2015-06-19 12:14:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/490c7a9fc86ca83bea18c85e2c0a59059d128e73', 'message': ""Add support for posting samples to notification-agent via API\n\nThis change make the ceilometer-api getting rid the pipline. samples will\nbe push to notification bus when creating via /v2/meters API.\n\nTo avoid the ceilometer-api's dependency of notification-agent, especially\nin some testing scenarios, this change also provide a optional parameter\nthat allow samples posted to storage directly.\n\nPartially implements: blueprint api-no-pipeline\n\nChange-Id: Id02d31f790e60a367fab0cd76c98690c9ff431a3\n""}, {'number': 4, 'created': '2015-06-19 12:15:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/84992bccd8069ecb019e9e04cc17a041334ab387', 'message': ""Add support for posting samples to notification-agent via API\n\nThis change make the ceilometer-api getting rid the pipline. samples will\nbe push to notification bus when creating via /v2/meters API.\n\nTo avoid the ceilometer-api's dependency of notification-agent, especially\nin some testing scenarios, this change also provide a optional parameter\nthat allow samples posted to storage directly.\n\nPartially implements: blueprint api-no-pipeline\n\nChange-Id: Id02d31f790e60a367fab0cd76c98690c9ff431a3\n""}, {'number': 5, 'created': '2015-06-23 06:29:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/cff53b62f26d3e0313f0be00f2cb6d7880e337e5', 'message': ""Add support for posting samples to notification-agent via API\n\nThis change make the ceilometer-api getting rid the pipline. samples will\nbe push to notification bus when creating via /v2/meters API.\n\nTo avoid the ceilometer-api's dependency of notification-agent, especially\nin some testing scenarios, this change also provide a optional parameter\nthat allow samples posted to storage directly.\n\nPartially implements: blueprint api-no-pipeline\n\nChange-Id: Id02d31f790e60a367fab0cd76c98690c9ff431a3\n""}, {'number': 6, 'created': '2015-06-23 07:38:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/aa1a252b233a5eda125327caa0a7ece1e3dd4026', 'message': ""Add support for posting samples to notification-agent via API\n\nThis change make the ceilometer-api getting rid the pipline. samples will\nbe push to notification bus when creating via /v2/meters API.\n\nTo avoid the ceilometer-api's dependency of notification-agent, especially\nin some testing scenarios, this change also provide a optional parameter\nthat allow samples posted to storage directly.\n\nPartially implements: blueprint api-no-pipeline\n\nChange-Id: Id02d31f790e60a367fab0cd76c98690c9ff431a3\n""}, {'number': 7, 'created': '2015-06-25 00:47:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/d3badc2f25a7e6eb8ac647eea51e2ab5d4c24775', 'message': ""Add support for posting samples to notification-agent via API\n\nThis change make the ceilometer-api getting rid the pipline. samples will\nbe push to notification bus when creating via /v2/meters API.\n\nTo avoid the ceilometer-api's dependency of notification-agent, especially\nin some testing scenarios, this change also provide a optional parameter\nthat allow samples posted to storage directly.\n\nPartially implements: blueprint api-no-pipeline\n\nChange-Id: Id02d31f790e60a367fab0cd76c98690c9ff431a3\n""}, {'number': 8, 'created': '2015-06-25 01:13:44.000000000', 'files': ['ceilometer/tests/gabbi/gabbits/clean-samples.yaml', 'ceilometer/api/app.py', 'ceilometer/tests/gabbi/gabbits/meters.yaml', 'ceilometer/api/controllers/v2/meters.py', 'ceilometer/api/hooks.py', 'ceilometer/tests/api/test_app.py', 'ceilometer/tests/api/v2/test_post_samples_scenarios.py'], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/9d920e4de6b77bfcf17b7f1b3332d7779416b32d', 'message': ""Add support for posting samples to notification-agent via API\n\nThis change make the ceilometer-api getting rid the pipline. samples will\nbe push to notification bus when creating via /v2/meters API.\n\nTo avoid the ceilometer-api's dependency of notification-agent, especially\nin some testing scenarios, this change also provide a optional parameter\nthat allow samples posted to storage directly.\n\nPartially implements: blueprint api-no-pipeline\n\nChange-Id: Id02d31f790e60a367fab0cd76c98690c9ff431a3\n""}]",17,193472,9d920e4de6b77bfcf17b7f1b3332d7779416b32d,32,6,8,8290,,,0,"Add support for posting samples to notification-agent via API

This change make the ceilometer-api getting rid the pipline. samples will
be push to notification bus when creating via /v2/meters API.

To avoid the ceilometer-api's dependency of notification-agent, especially
in some testing scenarios, this change also provide a optional parameter
that allow samples posted to storage directly.

Partially implements: blueprint api-no-pipeline

Change-Id: Id02d31f790e60a367fab0cd76c98690c9ff431a3
",git fetch https://review.opendev.org/openstack/ceilometer refs/changes/72/193472/8 && git format-patch -1 --stdout FETCH_HEAD,"['ceilometer/tests/gabbi/gabbits/clean-samples.yaml', 'ceilometer/api/app.py', 'ceilometer/tests/gabbi/gabbits/meters.yaml', 'ceilometer/api/controllers/v2/meters.py', 'ceilometer/api/hooks.py', 'ceilometer/tests/api/v2/test_post_samples_scenarios.py']",6,8cd61f1aec730f2074dab79aac291797af696e62,bp/api-no-pipeline," notifier.info.side_effect = self.fake_notifier_sample self.useFixture(mockpatch.Patch('ceilometer.messaging.get_notifier',"," notifier.sample.side_effect = self.fake_notifier_sample self.useFixture(mockpatch.Patch('oslo_messaging.Notifier', @mock.patch.object(pipeline.SampleSource, ""support_meter"") def test_post_not_supported_sample(self, mocked): mocked.return_value = False s = [{'counter_name': 'apples', 'counter_type': 'gauge', 'counter_unit': 'instance', 'counter_volume': 1, 'resource_id': 'bd9431c1-8d69-4ad3-803a-8d4a6b89fd36', 'project_id': '35b17138-b364-4e6a-a131-8f3099c5be68', 'user_id': 'efd87807-12d2-4b38-9c70-5f5c2ac427ff', 'resource_metadata': {'name1': 'value1', 'name2': 'value2'}}] resp = self.post_json('/meters/apples/', s, expect_errors=True) self.assertEqual(409, resp.status_code) expected_msg = (""The metric apples is not supported by metering "" ""pipeline configuration."") self.assertEqual(expected_msg, resp.json['error_message']['faultstring']) ",58,63
openstack%2Fnova~master~Ib8fb12a90f62f56f81530483d03f1c36cc5d56de,openstack/nova,master,Ib8fb12a90f62f56f81530483d03f1c36cc5d56de,VMware: convert driver to use nova.objects.ImageMeta,MERGED,2015-06-07 08:28:34.000000000,2015-06-25 13:24:40.000000000,2015-06-25 13:24:31.000000000,"[{'_account_id': 3}, {'_account_id': 1653}, {'_account_id': 1779}, {'_account_id': 2750}, {'_account_id': 5170}, {'_account_id': 7575}, {'_account_id': 8119}, {'_account_id': 9008}, {'_account_id': 9172}, {'_account_id': 9382}, {'_account_id': 9578}, {'_account_id': 10118}, {'_account_id': 10385}, {'_account_id': 15286}, {'_account_id': 15741}, {'_account_id': 15751}, {'_account_id': 15882}, {'_account_id': 16897}]","[{'number': 1, 'created': '2015-06-07 08:28:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/a70d0eff245cfc228460d43667cae5adc58500bd', 'message': 'VMware: convert driver to use nova.objects.ImageMeta\n\nThe patch also removes the test test_use_disk_format_none. This is no\nlonger relevant.\n\nChange-Id: Ib8fb12a90f62f56f81530483d03f1c36cc5d56de\n'}, {'number': 2, 'created': '2015-06-08 07:37:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/afe65d8228bce50c82328c6782cca1db5d2637f0', 'message': 'VMware: convert driver to use nova.objects.ImageMeta\n\nThe patch also removes the test test_use_disk_format_none. This is no\nlonger relevant.\n\nChange-Id: Ib8fb12a90f62f56f81530483d03f1c36cc5d56de\n'}, {'number': 3, 'created': '2015-06-08 09:05:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/6d7587734f13b63ce7027f63435163e9deda7af8', 'message': ""VMware: convert driver to use nova.objects.ImageMeta\n\nThe patch also removes the test test_use_disk_format_none. This is no\nlonger relevant.\n\nDocImpact\n\nThe purpose of the metadata object is to have common values across\ndrivers. Please note that the following are still supported but should\nuse the new keys:\n - 'vmware_ostype' => 'os_distro'\n - 'vmware_adaptertype' => 'hw_scsi_model'\n - 'vmware_disktype' => 'hw_disk_type'\n\nChange-Id: Ib8fb12a90f62f56f81530483d03f1c36cc5d56de\n""}, {'number': 4, 'created': '2015-06-08 09:45:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/c6b657d59b5af5e1c369e84e1be7372e9727cf67', 'message': ""VMware: convert driver to use nova.objects.ImageMeta\n\nThe patch also removes the test test_use_disk_format_none. This is no\nlonger relevant.\n\nDocImpact\n\nThe purpose of the metadata object is to have common values across\ndrivers. Please note that the following are still supported but should\nuse the new keys:\n - 'vmware_ostype' => 'os_distro'\n - 'vmware_adaptertype' => 'hw_scsi_model'\n - 'vmware_disktype' => 'hw_disk_type'\n\nChange-Id: Ib8fb12a90f62f56f81530483d03f1c36cc5d56de\n""}, {'number': 5, 'created': '2015-06-09 09:32:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/d40c0b114b9dff96241a398b8229718bcb3dfae4', 'message': ""VMware: convert driver to use nova.objects.ImageMeta\n\nThe patch also removes the test test_use_disk_format_none. This is no\nlonger relevant.\n\nDocImpact\n\nThe purpose of the metadata object is to have common values across\ndrivers. Please note that the following are still supported but should\nuse the new keys:\n - 'vmware_ostype' => 'os_distro'\n - 'vmware_adaptertype' => 'hw_disk_bus' and 'hw_scsi_model'\n - 'vmware_disktype' => 'hw_disk_type'\n\nChange-Id: Ib8fb12a90f62f56f81530483d03f1c36cc5d56de\n""}, {'number': 6, 'created': '2015-06-17 14:06:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/79e540a187118e6f00d6010ad59c11ca3b1d203c', 'message': ""VMware: convert driver to use nova.objects.ImageMeta\n\nThe patch also removes the test test_use_disk_format_none. This is no\nlonger relevant.\n\nDocImpact\n\nThe purpose of the metadata object is to have common values across\ndrivers. Please note that the following are still supported but should\nuse the new keys:\n - 'vmware_ostype' => 'os_distro'\n - 'vmware_adaptertype' => 'hw_disk_bus' and 'hw_scsi_model'\n - 'vmware_disktype' => 'hw_disk_type'\n\nChange-Id: Ib8fb12a90f62f56f81530483d03f1c36cc5d56de\n""}, {'number': 7, 'created': '2015-06-18 13:13:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/9108bbd568abc34eb67e3c6808eabfc30a217681', 'message': ""VMware: convert driver to use nova.objects.ImageMeta\n\nThe patch also removes the test test_use_disk_format_none. This is no\nlonger relevant.\n\nDocImpact\n\nThe purpose of the metadata object is to have common values across\ndrivers. Please note that the following are still supported but should\nuse the new keys:\n - 'vmware_ostype' => 'os_distro'\n - 'vmware_adaptertype' => 'hw_disk_bus' and 'hw_scsi_model'\n - 'vmware_disktype' => 'hw_disk_type'\n\nChange-Id: Ib8fb12a90f62f56f81530483d03f1c36cc5d56de\n""}, {'number': 8, 'created': '2015-06-23 04:39:01.000000000', 'files': ['nova/virt/vmwareapi/vmops.py', 'nova/virt/vmwareapi/driver.py', 'nova/tests/unit/virt/vmwareapi/test_vmops.py', 'nova/tests/unit/virt/vmwareapi/test_images.py', 'nova/virt/vmwareapi/images.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/bad76e6d0ad7d0127dde127ba0b4454d1a737b97', 'message': ""VMware: convert driver to use nova.objects.ImageMeta\n\nThe patch also removes the test test_use_disk_format_none. This is no\nlonger relevant.\n\nDocImpact\n\nThe purpose of the metadata object is to have common values across\ndrivers. Please note that the following are still supported but should\nuse the new keys:\n - 'vmware_ostype' => 'os_distro'\n - 'vmware_adaptertype' => 'hw_disk_bus' and 'hw_scsi_model'\n - 'vmware_disktype' => 'hw_disk_type'\n\nChange-Id: Ib8fb12a90f62f56f81530483d03f1c36cc5d56de\n""}]",25,189085,bad76e6d0ad7d0127dde127ba0b4454d1a737b97,103,18,8,1653,,,0,"VMware: convert driver to use nova.objects.ImageMeta

The patch also removes the test test_use_disk_format_none. This is no
longer relevant.

DocImpact

The purpose of the metadata object is to have common values across
drivers. Please note that the following are still supported but should
use the new keys:
 - 'vmware_ostype' => 'os_distro'
 - 'vmware_adaptertype' => 'hw_disk_bus' and 'hw_scsi_model'
 - 'vmware_disktype' => 'hw_disk_type'

Change-Id: Ib8fb12a90f62f56f81530483d03f1c36cc5d56de
",git fetch https://review.opendev.org/openstack/nova refs/changes/85/189085/7 && git format-patch -1 --stdout FETCH_HEAD,"['nova/virt/vmwareapi/vmops.py', 'nova/tests/unit/virt/vmwareapi/test_images.py', 'nova/virt/vmwareapi/images.py']",3,a70d0eff245cfc228460d43667cae5adc58500bd,use-image-meta-object,"from nova import objects image_meta = objects.ImageMeta.from_dict(image_meta) properties = image_meta.properties if hasattr(properties, 'img_linked_clone'): image_linked_clone = properties.img_linked_clone else: image_linked_clone = CONF.vmware.use_linked_clone container_format = hasattr(image_meta, 'container_format') if container_format: container_format = image_meta.container_format 'container_format': container_format } if hasattr(image_meta, 'size'): props['file_size'] = image_meta.size if hasattr(image_meta, 'disk_format'): props['file_type'] = image_meta.disk_format 'os_distro': 'os_type', 'hw_scsi_model': 'adapter_type', 'hw_disk_type': 'disk_type', if hasattr(properties, k): props[v] = getattr(properties, k)","LINKED_CLONE_PROPERTY = 'vmware_linked_clone' properties = image_meta.get(""properties"", {}) image_linked_clone = properties.get(LINKED_CLONE_PROPERTY, CONF.vmware.use_linked_clone) 'container_format': image_meta.get('container_format') } if 'size' in image_meta: props['file_size'] = image_meta['size'] if 'disk_format' in image_meta: props['file_type'] = image_meta['disk_format'] 'vmware_ostype': 'os_type', 'vmware_adaptertype': 'adapter_type', 'vmware_disktype': 'disk_type', if k in properties: props[v] = properties[k]",38,34
openstack%2Fnova~master~I3a38b1a6cf21a3e5774e5704303ba64979c04e56,openstack/nova,master,I3a38b1a6cf21a3e5774e5704303ba64979c04e56,Merge server rescue tests between v2 and v2.1,MERGED,2015-04-15 02:09:48.000000000,2015-06-25 13:23:58.000000000,2015-06-25 13:23:49.000000000,"[{'_account_id': 3}, {'_account_id': 2750}, {'_account_id': 5170}, {'_account_id': 6167}, {'_account_id': 9008}, {'_account_id': 9578}, {'_account_id': 10118}, {'_account_id': 10385}, {'_account_id': 13663}, {'_account_id': 15286}, {'_account_id': 15751}]","[{'number': 1, 'created': '2015-04-15 02:09:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/1e85ab451064177ececcdceaf6ee613bbc72f078', 'message': 'Merge server rescue tests between v2 and v2.1\n\nCurrently v2 and v2.1 have separate functional tests and their\ncorresponding sample files. As v2 and v2.1 are supposed to be identical,\nthere is overhead to maintain two set of functional tests and sample files.\nWe can have one set of tests which can run for both v2 and v2.1.\n\nThis commit merges servers rescue functional tests.\n\nV2 has two extensions\n- os-rescue\n- os-extended-rescue-with-image\nwhich are merged in single rescue plugins in v2.1\n\nIn rescue tests, enabling some more v2 extension which are required for\nPOST/GET sevrer.\n\nChange-Id: I3a38b1a6cf21a3e5774e5704303ba64979c04e56\n'}, {'number': 2, 'created': '2015-04-17 01:57:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/009ec797451573a0df27d64cd0db91e8d54c7c90', 'message': 'Merge server rescue tests between v2 and v2.1\n\nCurrently v2 and v2.1 have separate functional tests and their\ncorresponding sample files. As v2 and v2.1 are supposed to be identical,\nthere is overhead to maintain two set of functional tests and sample files.\nWe can have one set of tests which can run for both v2 and v2.1.\n\nThis commit merges servers rescue functional tests.\n\nV2 has two extensions\n- os-rescue\n- os-extended-rescue-with-image\nwhich are merged in single rescue plugins in v2.1\n\nIn rescue tests, enabling some more v2 extension which are required for\nPOST/GET sevrer.\n\nChange-Id: I3a38b1a6cf21a3e5774e5704303ba64979c04e56\n'}, {'number': 3, 'created': '2015-05-12 03:18:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/adafb3eab9fcc40cb5ee97d7e502144e52c47626', 'message': 'Merge server rescue tests between v2 and v2.1\n\nCurrently v2 and v2.1 have separate functional tests and their\ncorresponding sample files. As v2 and v2.1 are supposed to be identical,\nthere is overhead to maintain two set of functional tests and sample files.\nWe can have one set of tests which can run for both v2 and v2.1.\n\nThis commit merges servers rescue functional tests.\n\nV2 has two extensions\n- os-rescue\n- os-extended-rescue-with-image\nwhich are merged in single rescue plugins in v2.1\n\nIn rescue tests, enabling some more v2 extension which are required for\nPOST/GET sevrer.\n\nChange-Id: I3a38b1a6cf21a3e5774e5704303ba64979c04e56\n'}, {'number': 4, 'created': '2015-06-15 08:48:03.000000000', 'files': ['nova/tests/functional/api_samples/os-rescue/server-get-resp-unrescue.json.tpl', 'doc/v3/api_samples/os-rescue/server-get-resp-rescue.json', 'nova/tests/functional/v3/test_rescue.py', 'doc/api_samples/os-rescue/server-get-resp-rescue.json', 'nova/tests/functional/test_api_samples.py', 'doc/api_samples/os-rescue/server-rescue-req.json', 'nova/tests/functional/api_samples/os-rescue/server-rescue-req.json.tpl', 'nova/tests/functional/v3/api_samples/os-rescue/server-get-resp-unrescue.json.tpl', 'nova/tests/functional/v3/api_samples/os-rescue/server-get-resp-rescue.json.tpl', 'doc/api_samples/os-rescue/server-rescue.json', 'doc/api_samples/os-rescue/server-get-resp-unrescue.json', 'nova/tests/functional/api_samples/os-rescue/server-unrescue-req.json.tpl', 'nova/tests/functional/api_samples/os-rescue/server-rescue.json.tpl', 'doc/v3/api_samples/os-rescue/server-get-resp-unrescue.json', 'nova/tests/functional/api_samples/os-rescue/server-get-resp-rescue.json.tpl', 'doc/api_samples/os-rescue/server-unrescue-req.json'], 'web_link': 'https://opendev.org/openstack/nova/commit/3f2d390c3b27a0b01359fad5f703024a9cb1baa2', 'message': 'Merge server rescue tests between v2 and v2.1\n\nCurrently v2 and v2.1 have separate functional tests and their\ncorresponding sample files. As v2 and v2.1 are supposed to be identical,\nthere is overhead to maintain two set of functional tests and sample files.\nWe can have one set of tests which can run for both v2 and v2.1.\n\nThis commit merges servers rescue functional tests.\n\nV2 has two extensions\n- os-rescue\n- os-extended-rescue-with-image\nwhich are merged in single rescue plugins in v2.1\n\nIn rescue tests, enabling some more v2 extension which are required for\nPOST/GET sevrer.\n\nChange-Id: I3a38b1a6cf21a3e5774e5704303ba64979c04e56\n'}]",0,173651,3f2d390c3b27a0b01359fad5f703024a9cb1baa2,41,11,4,8556,,,0,"Merge server rescue tests between v2 and v2.1

Currently v2 and v2.1 have separate functional tests and their
corresponding sample files. As v2 and v2.1 are supposed to be identical,
there is overhead to maintain two set of functional tests and sample files.
We can have one set of tests which can run for both v2 and v2.1.

This commit merges servers rescue functional tests.

V2 has two extensions
- os-rescue
- os-extended-rescue-with-image
which are merged in single rescue plugins in v2.1

In rescue tests, enabling some more v2 extension which are required for
POST/GET sevrer.

Change-Id: I3a38b1a6cf21a3e5774e5704303ba64979c04e56
",git fetch https://review.opendev.org/openstack/nova refs/changes/51/173651/4 && git format-patch -1 --stdout FETCH_HEAD,"['nova/tests/functional/api_samples/os-rescue/server-get-resp-unrescue.json.tpl', 'doc/v3/api_samples/os-rescue/server-get-resp-rescue.json', 'nova/tests/functional/v3/test_rescue.py', 'doc/api_samples/os-rescue/server-get-resp-rescue.json', 'nova/tests/functional/test_api_samples.py', 'doc/api_samples/os-rescue/server-rescue-req.json', 'nova/tests/functional/api_samples/os-rescue/server-rescue-req.json.tpl', 'nova/tests/functional/v3/api_samples/os-rescue/server-get-resp-unrescue.json.tpl', 'nova/tests/functional/v3/api_samples/os-rescue/server-get-resp-rescue.json.tpl', 'doc/api_samples/os-rescue/server-rescue.json', 'doc/api_samples/os-rescue/server-get-resp-unrescue.json', 'nova/tests/functional/api_samples/os-rescue/server-unrescue-req.json.tpl', 'nova/tests/functional/api_samples/os-rescue/server-rescue.json.tpl', 'doc/v3/api_samples/os-rescue/server-get-resp-unrescue.json', 'nova/tests/functional/api_samples/os-rescue/server-get-resp-rescue.json.tpl', 'doc/api_samples/os-rescue/server-unrescue-req.json']",16,1e85ab451064177ececcdceaf6ee613bbc72f078,merge_sample_tests,,"{ ""unrescue"": null }",56,338
openstack%2Ffuel-library~master~I6eea00337c5cce2269c236b49305ba7085f68eb4,openstack/fuel-library,master,I6eea00337c5cce2269c236b49305ba7085f68eb4,Add openstacklib module,MERGED,2015-06-11 12:24:47.000000000,2015-06-25 13:19:41.000000000,2015-06-25 13:18:54.000000000,"[{'_account_id': 3}, {'_account_id': 6926}, {'_account_id': 7468}, {'_account_id': 7604}, {'_account_id': 7732}, {'_account_id': 7745}, {'_account_id': 8786}, {'_account_id': 8787}, {'_account_id': 8971}, {'_account_id': 9037}, {'_account_id': 9387}, {'_account_id': 9546}, {'_account_id': 11090}, {'_account_id': 11827}, {'_account_id': 13343}, {'_account_id': 13344}, {'_account_id': 13948}, {'_account_id': 14007}, {'_account_id': 14774}, {'_account_id': 14985}]","[{'number': 1, 'created': '2015-06-11 12:24:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/899c15c0b7335d5f414c14139620996eda647423', 'message': 'Add openstacklib module\n\n  v5.0.0 999f7849a3e0653f46f7336ee0fa9c2e38630b7b\n  source: https://github.com/stackforge/puppet-openstacklib\n\nRelated blueprint upgrade-openstack-puppet-modules\n\nChange-Id: I6eea00337c5cce2269c236b49305ba7085f68eb4\n'}, {'number': 2, 'created': '2015-06-12 12:54:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/424be3314ed79337a530cc723767dce137dff88b', 'message': 'Add openstacklib module\n\n  v5.0.0 999f7849a3e0653f46f7336ee0fa9c2e38630b7b\n  source: https://github.com/stackforge/puppet-openstacklib\n\nImplements: blueprint upgrade-openstack-puppet-modules\n                      \nChange-Id: I6eea00337c5cce2269c236b49305ba7085f68eb4'}, {'number': 3, 'created': '2015-06-22 15:05:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/abf6b6c4ff987237fdc472f47d23256e4018dec2', 'message': 'Add openstacklib module\n\n  master bcbe7aa35c03c83dd58842fdb0f72a332e660124\n  source: https://github.com/stackforge/puppet-openstacklib\n\nPartially Implements: blueprint upgrade-openstack-puppet-modules\n\nChange-Id: I6eea00337c5cce2269c236b49305ba7085f68eb4\n'}, {'number': 4, 'created': '2015-06-22 15:06:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/e2cd6e3086e670d58c63c764597e09a237d9aa76', 'message': 'Add openstacklib module\n\n  master bcbe7aa35c03c83dd58842fdb0f72a332e660124\n  source: https://github.com/stackforge/puppet-openstacklib\n\nPartially Implements: blueprint upgrade-openstack-puppet-modules\n\nChange-Id: I6eea00337c5cce2269c236b49305ba7085f68eb4\n'}, {'number': 5, 'created': '2015-06-25 11:30:41.000000000', 'files': ['deployment/puppet/openstacklib/lib/puppet/parser/functions/os_database_connection.rb', 'deployment/puppet/openstacklib/spec/functions/os_database_connection_spec.rb', 'deployment/puppet/openstacklib/README.md', 'deployment/puppet/openstacklib/spec/unit/provider/openstack_spec.rb', 'deployment/puppet/openstacklib/manifests/policy/base.pp', 'deployment/puppet/openstacklib/spec/spec_helper.rb', 'deployment/puppet/openstacklib/manifests/messaging/rabbitmq.pp', 'deployment/puppet/openstacklib/Gemfile', 'deployment/puppet/openstacklib/LICENSE', 'deployment/puppet/openstacklib/spec/defines/openstacklib_wsgi_apache_spec.rb', 'deployment/puppet/openstacklib/spec/defines/openstacklib_db_postgresql_spec.rb', 'deployment/puppet/openstacklib/.fixtures.yml', 'deployment/puppet/openstacklib/manifests/db/postgresql.pp', 'deployment/puppet/openstacklib/spec/defines/openstacklib_service_validation_spec.rb', 'deployment/puppet/openstacklib/lib/puppet/provider/openstack/credentials.rb', 'deployment/puppet/openstacklib/spec/classes/openstacklib_policy_spec.rb', 'deployment/puppet/openstacklib/spec/shared_examples.rb', 'deployment/puppet/openstacklib/manifests/wsgi/apache.pp', 'deployment/puppet/openstacklib/spec/acceptance/mysql_spec.rb', 'deployment/puppet/openstacklib/spec/defines/openstacklib_messaging_rabbitmq_spec.rb', 'deployment/puppet/openstacklib/spec/acceptance/nodesets/nodepool-centos7.yml', 'deployment/puppet/openstacklib/manifests/policy.pp', 'deployment/puppet/openstacklib/spec/unit/provider/openstack/auth_spec.rb', 'deployment/puppet/openstacklib/manifests/service_validation.pp', 'deployment/puppet/openstacklib/manifests/db/mysql/host_access.pp', 'deployment/puppet/openstacklib/Rakefile', 'deployment/puppet/openstacklib/spec/defines/openstacklib_db_mysql_host_access_spec.rb', 'deployment/puppet/openstacklib/spec/acceptance/nodesets/nodepool-trusty.yml', 'deployment/puppet/openstacklib/spec/defines/openstacklib_policy_spec.rb', 'deployment/puppet/openstacklib/spec/acceptance/rabbitmq_spec.rb', 'deployment/puppet/openstacklib/lib/puppet/provider/openstack.rb', 'deployment/puppet/openstacklib/metadata.json', 'deployment/puppet/openstacklib/spec/spec_helper_acceptance.rb', 'deployment/puppet/openstacklib/manifests/db/mysql.pp', 'deployment/puppet/openstacklib/lib/puppet/provider/openstack/auth.rb', 'deployment/puppet/openstacklib/spec/classes/init_spec.rb', 'deployment/puppet/openstacklib/spec/defines/openstacklib_db_mysql_spec.rb', 'deployment/puppet/openstacklib/spec/acceptance/nodesets/default.yml', 'deployment/puppet/openstacklib/manifests/openstackclient.pp', 'deployment/puppet/openstacklib/.gitignore', 'deployment/puppet/openstacklib/spec/unit/provider/openstack/credentials_spec.rb'], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/d3a5608583c5c9f4732b5fe607386f653782e281', 'message': 'Add openstacklib module\n\n  master bcbe7aa35c03c83dd58842fdb0f72a332e660124\n  source: https://github.com/stackforge/puppet-openstacklib\n\nPartially Implements: blueprint upgrade-openstack-puppet-modules\n\nChange-Id: I6eea00337c5cce2269c236b49305ba7085f68eb4\n'}]",0,190612,d3a5608583c5c9f4732b5fe607386f653782e281,89,20,5,14525,,,0,"Add openstacklib module

  master bcbe7aa35c03c83dd58842fdb0f72a332e660124
  source: https://github.com/stackforge/puppet-openstacklib

Partially Implements: blueprint upgrade-openstack-puppet-modules

Change-Id: I6eea00337c5cce2269c236b49305ba7085f68eb4
",git fetch https://review.opendev.org/openstack/fuel-library refs/changes/12/190612/1 && git format-patch -1 --stdout FETCH_HEAD,"['deployment/puppet/openstacklib/lib/puppet/parser/functions/os_database_connection.rb', 'deployment/puppet/openstacklib/spec/functions/os_database_connection_spec.rb', 'deployment/puppet/openstacklib/README.md', 'deployment/puppet/openstacklib/manifests/policy/base.pp', 'deployment/puppet/openstacklib/lib/puppet/util/aviator.rb', 'deployment/puppet/openstacklib/spec/spec_helper.rb', 'deployment/puppet/openstacklib/manifests/messaging/rabbitmq.pp', 'deployment/puppet/openstacklib/Gemfile', 'deployment/puppet/openstacklib/LICENSE', 'deployment/puppet/openstacklib/.fixtures.yml', 'deployment/puppet/openstacklib/spec/defines/openstacklib_service_validation_spec.rb', 'deployment/puppet/openstacklib/spec/classes/openstacklib_policy_spec.rb', 'deployment/puppet/openstacklib/spec/defines/openstacklib_messaging_rabbitmq_spec.rb', 'deployment/puppet/openstacklib/manifests/policy.pp', 'deployment/puppet/openstacklib/manifests/service_validation.pp', 'deployment/puppet/openstacklib/lib/puppet/provider/aviator.rb', 'deployment/puppet/openstacklib/manifests/db/mysql/host_access.pp', 'deployment/puppet/openstacklib/Rakefile', 'deployment/puppet/openstacklib/spec/defines/openstacklib_db_mysql_host_access_spec.rb', 'deployment/puppet/openstacklib/spec/unit/provider/aviator_spec.rb', 'deployment/puppet/openstacklib/spec/defines/openstacklib_policy_spec.rb', 'deployment/puppet/openstacklib/spec/fixtures/vcr/aviator/request/without_session.yml', 'deployment/puppet/openstacklib/metadata.json', 'deployment/puppet/openstacklib/manifests/db/mysql.pp', 'deployment/puppet/openstacklib/spec/fixtures/vcr/aviator/session/with_password.yml', 'deployment/puppet/openstacklib/spec/classes/init_spec.rb', 'deployment/puppet/openstacklib/spec/defines/openstacklib_db_mysql_spec.rb', 'deployment/puppet/openstacklib/spec/fixtures/vcr/aviator/session/with_token.yml', 'deployment/puppet/openstacklib/spec/fixtures/vcr/aviator/request/with_session.yml', 'deployment/puppet/openstacklib/.gitignore']",30,899c15c0b7335d5f414c14139620996eda647423,keystone,*.swp spec/fixtures/* !spec/fixtures/vcr/ pkg Gemfile.lock ,,2397,0
openstack%2Fneutron~master~I4e02a291738b16c7c9b7600f0bc9a47fb1318569,openstack/neutron,master,I4e02a291738b16c7c9b7600f0bc9a47fb1318569,"Deprecate ""router_delete_namespaces"" and ""dhcp_delete_namespaces""",MERGED,2015-06-08 04:04:52.000000000,2015-06-25 13:19:25.000000000,2015-06-24 22:28:42.000000000,"[{'_account_id': 3}, {'_account_id': 704}, {'_account_id': 4656}, {'_account_id': 5170}, {'_account_id': 5948}, {'_account_id': 6788}, {'_account_id': 6854}, {'_account_id': 7787}, {'_account_id': 8119}, {'_account_id': 8873}, {'_account_id': 8976}, {'_account_id': 9681}, {'_account_id': 9682}, {'_account_id': 9751}, {'_account_id': 9787}, {'_account_id': 9845}, {'_account_id': 10121}, {'_account_id': 10153}, {'_account_id': 10184}, {'_account_id': 10387}, {'_account_id': 10692}, {'_account_id': 11328}, {'_account_id': 12955}, {'_account_id': 14208}, {'_account_id': 14212}, {'_account_id': 14213}, {'_account_id': 14214}, {'_account_id': 14215}, {'_account_id': 14216}, {'_account_id': 14323}, {'_account_id': 14571}, {'_account_id': 15296}, {'_account_id': 15444}, {'_account_id': 15752}, {'_account_id': 15894}]","[{'number': 1, 'created': '2015-06-08 04:04:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/c9d59dd491526547666ca20b46cdaff18999c590', 'message': 'Remove confusing options router_delete_namespace and dhcp_delete_namespace in neutron/etc/l3_agent.ini and /etc/dhcp_agent.ini on option and description about deleting namespace.\n\nChange-Id: I4e02a291738b16c7c9b7600f0bc9a47fb1318569\nCloses-Bug: #1418079\n'}, {'number': 2, 'created': '2015-06-14 23:11:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/5629dde82708e9711f06b19c30bd00245f330eb3', 'message': 'Remove confusing options ""router_delete_namespaces"" and\n""dhcp_delete_namesapces"" are are not needed.\n\nIn neutron/etc/l3_agent.ini and /etc/dhcp_agent.ini the option and description\nabout deleting namespace is no longer necessary because of a previous fix.\n\nRemove references to ""router_delete_namespaes"" and ""dhcp_delete_namespaces"" in\nthe code as well as the associated unit test cases.\n\nChange-Id: I4e02a291738b16c7c9b7600f0bc9a47fb1318569\nCloses-Bug: #1418079\n'}, {'number': 3, 'created': '2015-06-24 05:16:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/efafc9731169f134a0333d3996350b423d12ff33', 'message': 'Deprecate ""router_delete_namespaces"" and ""dhcp_delete_namespaces""\n\nThese 2 configuration options are no longer be necessary.\n\nIt is marked as deprecated in this release and will be removed in the\nnext release.\n\nChange-Id: I4e02a291738b16c7c9b7600f0bc9a47fb1318569\nPartial-Bug: #1418079\n'}, {'number': 4, 'created': '2015-06-24 08:15:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/fead6b8e7623f54907aa9122b83d13d67a3b2f16', 'message': 'Deprecate ""router_delete_namespaces"" and ""dhcp_delete_namespaces""\n\nThese 2 configuration options are no longer be necessary.\n\nThey are marked as deprecated in this release and will be removed in the\nnext release.\n\nChange-Id: I4e02a291738b16c7c9b7600f0bc9a47fb1318569\nPartial-Bug: #1418079\n'}, {'number': 5, 'created': '2015-06-24 13:51:54.000000000', 'files': ['neutron/agent/l3/config.py', 'etc/l3_agent.ini', 'neutron/agent/dhcp/config.py', 'etc/dhcp_agent.ini'], 'web_link': 'https://opendev.org/openstack/neutron/commit/830e9114817765efc93c772dcbc735a6bb28a7ff', 'message': 'Deprecate ""router_delete_namespaces"" and ""dhcp_delete_namespaces""\n\nThese 2 configuration options are no longer be necessary.\n\nThey are marked as deprecated in this release and will be removed in the\nnext release.\n\nChange-Id: I4e02a291738b16c7c9b7600f0bc9a47fb1318569\nPartial-Bug: #1418079\n'}]",8,189184,830e9114817765efc93c772dcbc735a6bb28a7ff,95,35,5,11328,,,0,"Deprecate ""router_delete_namespaces"" and ""dhcp_delete_namespaces""

These 2 configuration options are no longer be necessary.

They are marked as deprecated in this release and will be removed in the
next release.

Change-Id: I4e02a291738b16c7c9b7600f0bc9a47fb1318569
Partial-Bug: #1418079
",git fetch https://review.opendev.org/openstack/neutron refs/changes/84/189184/5 && git format-patch -1 --stdout FETCH_HEAD,"['etc/l3_agent.ini', 'etc/dhcp_agent.ini']",2,c9d59dd491526547666ca20b46cdaff18999c590,master,,"# dhcp_delete_namespaces, which is True by default, can be set to False if # namespaces can't be deleted cleanly on the host running the DHCP agent. # Disable this if you hit the issue in # https://bugs.launchpad.net/neutron/+bug/1052535 or if # you are sure that your version of iproute suffers from the problem. # dhcp_delete_namespaces = True ",0,15
openstack%2Fproject-config~master~Iaf3fa42b2799c785963fe58397e2b80c394db46b,openstack/project-config,master,Iaf3fa42b2799c785963fe58397e2b80c394db46b,Add Ironic Inspector simple integration test job,MERGED,2015-06-22 05:41:45.000000000,2015-06-25 13:15:38.000000000,2015-06-25 13:15:32.000000000,"[{'_account_id': 3}, {'_account_id': 4162}, {'_account_id': 5263}, {'_account_id': 6167}, {'_account_id': 6547}, {'_account_id': 7882}, {'_account_id': 10239}]","[{'number': 1, 'created': '2015-06-22 05:41:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/project-config/commit/d7f30baaeec01c966cf734339c5824b619a2dcda', 'message': ""Add Ironic-inspector's jobs\n\nThis patch set add Ironic-inspector's job.\nAt first, I add just check job, as non-voting.\nIf this works well, I will change from non-voting to voting,\nand also I will add gate job.\n\nChange-Id: Iaf3fa42b2799c785963fe58397e2b80c394db46b\n""}, {'number': 2, 'created': '2015-06-22 06:24:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/project-config/commit/f708a1646659bd1cca0d59092bb5007a9bdc484c', 'message': ""Add Ironic-inspector's jobs\n\nThis patch set add Ironic-inspector's job.\nAt first, I add just check job, as non-voting.\nIf this works well, I will change from non-voting to voting,\nand also I will add gate job.\n\nChange-Id: Iaf3fa42b2799c785963fe58397e2b80c394db46b\n""}, {'number': 3, 'created': '2015-06-22 07:36:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/project-config/commit/c4145ee6b9df911d0f95296b2a7a44a3b1f2ca69', 'message': ""Add Ironic-inspector's jobs\n\nThis patch set add Ironic-inspector's integration test job.\nAt first, I add just check job, as non-voting.\nIf this works well, I will change from non-voting to voting,\nand also I will add gate job.\n\nChange-Id: Iaf3fa42b2799c785963fe58397e2b80c394db46b\n""}, {'number': 4, 'created': '2015-06-22 09:08:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/project-config/commit/2c31ade4d7b4ae3952177e5aabc6b7f0f7000e2d', 'message': ""Add Ironic Inspector simple integration test job\n\nThis patch set add Ironic Inspector's integration test job.\nAt first, I add just check job, as non-voting.\nIf this works well, I will change from non-voting to voting,\nand also I will add gate job.\n\nCo-Authored-By: Dmitry Tantsur <dtantsur@redhat.com>\nChange-Id: Iaf3fa42b2799c785963fe58397e2b80c394db46b\n""}, {'number': 5, 'created': '2015-06-22 09:12:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/project-config/commit/6557cabe8f2b51b4609d0fbdef68b8c5550bec95', 'message': ""Add Ironic Inspector simple integration test job\n\nThis patch set add Ironic Inspector's integration test job.\nAt first, I add just check job, as non-voting.\nIf this works well, I will change from non-voting to voting,\nand also I will add gate job.\n\nCo-Authored-By: Dmitry Tantsur <dtantsur@redhat.com>\nChange-Id: Iaf3fa42b2799c785963fe58397e2b80c394db46b\n""}, {'number': 6, 'created': '2015-06-22 18:33:49.000000000', 'files': ['jenkins/jobs/ironic.yaml', 'jenkins/jobs/projects.yaml', 'zuul/layout.yaml'], 'web_link': 'https://opendev.org/openstack/project-config/commit/b1a732017626d51622c4edd1aa493328c3e73dcf', 'message': ""Add Ironic Inspector simple integration test job\n\nThis patch set add Ironic Inspector's integration test job.\nAt first, I add just check job, as non-voting.\nIf this works well, I will change from non-voting to voting,\nand also I will add gate job.\n\nCo-Authored-By: Dmitry Tantsur <dtantsur@redhat.com>\nChange-Id: Iaf3fa42b2799c785963fe58397e2b80c394db46b\n""}]",17,193941,b1a732017626d51622c4edd1aa493328c3e73dcf,32,7,6,7882,,,0,"Add Ironic Inspector simple integration test job

This patch set add Ironic Inspector's integration test job.
At first, I add just check job, as non-voting.
If this works well, I will change from non-voting to voting,
and also I will add gate job.

Co-Authored-By: Dmitry Tantsur <dtantsur@redhat.com>
Change-Id: Iaf3fa42b2799c785963fe58397e2b80c394db46b
",git fetch https://review.opendev.org/openstack/project-config refs/changes/41/193941/6 && git format-patch -1 --stdout FETCH_HEAD,"['jenkins/jobs/ironic-inspector.yaml', 'zuul/layout.yaml']",2,d7f30baaeec01c966cf734339c5824b619a2dcda,ironic-inspector_gate_job, - name: gate-ironic-inspector-dsvm-functest voting: false - gate-ironic-inspector-dsvm-functest,,37,0
openstack%2Fmagnum~master~I9927b0ed4277e52a965478f83f95b9c47f6d95c4,openstack/magnum,master,I9927b0ed4277e52a965478f83f95b9c47f6d95c4,Not need to use bay uuid,MERGED,2015-06-24 05:53:26.000000000,2015-06-25 13:09:54.000000000,2015-06-25 13:09:50.000000000,"[{'_account_id': 3}, {'_account_id': 10206}, {'_account_id': 11536}, {'_account_id': 11650}, {'_account_id': 12175}]","[{'number': 1, 'created': '2015-06-24 05:53:26.000000000', 'files': ['doc/source/dev/dev-quickstart.rst'], 'web_link': 'https://opendev.org/openstack/magnum/commit/bf477f33058a772ee94c2eebfacfc5b070489a00', 'message': 'Not need to use bay uuid\n\nAs we alreasy support bay name, it is not needed to get bay uuid.\n\nChange-Id: I9927b0ed4277e52a965478f83f95b9c47f6d95c4\nCloses-Bug: #1468193\n'}]",0,194946,bf477f33058a772ee94c2eebfacfc5b070489a00,9,5,1,7049,,,0,"Not need to use bay uuid

As we alreasy support bay name, it is not needed to get bay uuid.

Change-Id: I9927b0ed4277e52a965478f83f95b9c47f6d95c4
Closes-Bug: #1468193
",git fetch https://review.opendev.org/openstack/magnum refs/changes/46/194946/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/source/dev/dev-quickstart.rst'],1,bf477f33058a772ee94c2eebfacfc5b070489a00,fixdoc, --bay swarmbay\, $ BAY_UUID=$(magnum bay-list | awk '/ swarmbay /{print $2}') --bay $BAY_UUID\,1,2
openstack%2Fmagnum~master~I5bd5c46d2577d5310a57e25e67dfd1f8c36a6ad0,openstack/magnum,master,I5bd5c46d2577d5310a57e25e67dfd1f8c36a6ad0,Fix the wrong number for minion node,MERGED,2015-06-24 08:51:15.000000000,2015-06-25 12:45:48.000000000,2015-06-25 12:45:37.000000000,"[{'_account_id': 3}, {'_account_id': 10206}, {'_account_id': 11536}]","[{'number': 1, 'created': '2015-06-24 08:51:15.000000000', 'files': ['doc/source/dev/dev-quickstart.rst'], 'web_link': 'https://opendev.org/openstack/magnum/commit/adcacd1ec1c3d6788ec74a475e83df990ad0f31f', 'message': 'Fix the wrong number for minion node\n\nCloses-Bug: #1468245\nChange-Id: I5bd5c46d2577d5310a57e25e67dfd1f8c36a6ad0\n'}]",0,194993,adcacd1ec1c3d6788ec74a475e83df990ad0f31f,7,3,1,7049,,,0,"Fix the wrong number for minion node

Closes-Bug: #1468245
Change-Id: I5bd5c46d2577d5310a57e25e67dfd1f8c36a6ad0
",git fetch https://review.opendev.org/openstack/magnum refs/changes/93/194993/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/source/dev/dev-quickstart.rst'],1,adcacd1ec1c3d6788ec74a475e83df990ad0f31f,fixdocminion,This bay will result in one master kubernetes node and one minion node.::,This bay will result in one master kubernetes node and two minion nodes.::,1,1
openstack%2Fanchor~master~Ia9d1030753f814f6adb0b3444a1fea7b3315e505,openstack/anchor,master,Ia9d1030753f814f6adb0b3444a1fea7b3315e505,Use range instead of xrange,MERGED,2015-06-24 00:20:57.000000000,2015-06-25 12:39:51.000000000,2015-06-25 12:39:48.000000000,"[{'_account_id': 3}, {'_account_id': 11397}, {'_account_id': 11716}]","[{'number': 1, 'created': '2015-06-24 00:20:57.000000000', 'files': ['anchor/X509/name.py'], 'web_link': 'https://opendev.org/openstack/anchor/commit/003ae0a0bd748ec177527e8e2fba47fde269ead5', 'message': ""Use range instead of xrange\n\nNeeded for py3 compatibility, but it's used in places where the number\nof iterations is very low. It doesn't matter if py2 constructs a list.\n\nChange-Id: Ia9d1030753f814f6adb0b3444a1fea7b3315e505\n""}]",0,194887,003ae0a0bd748ec177527e8e2fba47fde269ead5,7,3,1,1528,,,0,"Use range instead of xrange

Needed for py3 compatibility, but it's used in places where the number
of iterations is very low. It doesn't matter if py2 constructs a list.

Change-Id: Ia9d1030753f814f6adb0b3444a1fea7b3315e505
",git fetch https://review.opendev.org/openstack/anchor refs/changes/87/194887/1 && git format-patch -1 --stdout FETCH_HEAD,['anchor/X509/name.py'],1,003ae0a0bd748ec177527e8e2fba47fde269ead5,xrange, for i in range(self.entry_count()):, for i in xrange(self.entry_count()):,1,1
openstack%2Fdesignate~master~Ia33ad1a6e0d5776a0e4b10deca3d53eef3df7aca,openstack/designate,master,Ia33ad1a6e0d5776a0e4b10deca3d53eef3df7aca,Updated from global requirements,MERGED,2015-06-24 14:38:08.000000000,2015-06-25 12:35:12.000000000,2015-06-25 12:35:08.000000000,"[{'_account_id': 3}, {'_account_id': 741}, {'_account_id': 8099}]","[{'number': 1, 'created': '2015-06-24 14:38:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/designate/commit/bf9f700e57d36dd3d6017021f0ecac8a0eac4200', 'message': 'Updated from global requirements\n\nChange-Id: Ia33ad1a6e0d5776a0e4b10deca3d53eef3df7aca\n'}, {'number': 2, 'created': '2015-06-24 20:36:42.000000000', 'files': ['requirements.txt'], 'web_link': 'https://opendev.org/openstack/designate/commit/2e6e010d6cfc6780c7ae0b20edf55cc845d1c657', 'message': 'Updated from global requirements\n\nChange-Id: Ia33ad1a6e0d5776a0e4b10deca3d53eef3df7aca\n'}]",0,195106,2e6e010d6cfc6780c7ae0b20edf55cc845d1c657,9,3,2,11131,,,0,"Updated from global requirements

Change-Id: Ia33ad1a6e0d5776a0e4b10deca3d53eef3df7aca
",git fetch https://review.opendev.org/openstack/designate refs/changes/06/195106/1 && git format-patch -1 --stdout FETCH_HEAD,['requirements.txt'],1,bf9f700e57d36dd3d6017021f0ecac8a0eac4200,openstack/requirements,oslo.concurrency>=2.1.0 # Apache-2.0,oslo.concurrency>=2.0.0 # Apache-2.0,1,1
openstack%2Fpuppet-nova~master~I15ee384bf48ef21adaf7577216b3ad234988c615,openstack/puppet-nova,master,I15ee384bf48ef21adaf7577216b3ad234988c615,lint: Fix lint issues (missing documentation for define types),MERGED,2015-06-25 09:15:35.000000000,2015-06-25 12:24:25.000000000,2015-06-25 12:24:23.000000000,"[{'_account_id': 3}, {'_account_id': 1607}, {'_account_id': 3153}, {'_account_id': 6796}, {'_account_id': 9410}, {'_account_id': 11491}]","[{'number': 1, 'created': '2015-06-25 09:15:35.000000000', 'files': ['manifests/generic_service.pp', 'manifests/manage/network.pp', 'manifests/manage/floating.pp', 'manifests/network/bridge.pp'], 'web_link': 'https://opendev.org/openstack/puppet-nova/commit/7a4e067e9241a3fffec4b2d521f070f0bea1f50f', 'message': ""lint: Fix lint issues (missing documentation for define types)\n\nThe gem 'puppet-lint-param-docs' was bumped to 1.2.0 and now handle\nclass and define type. This patch fix lint issues (missing documentation).\n\nChange-Id: I15ee384bf48ef21adaf7577216b3ad234988c615\n""}]",0,195467,7a4e067e9241a3fffec4b2d521f070f0bea1f50f,11,6,1,7155,,,0,"lint: Fix lint issues (missing documentation for define types)

The gem 'puppet-lint-param-docs' was bumped to 1.2.0 and now handle
class and define type. This patch fix lint issues (missing documentation).

Change-Id: I15ee384bf48ef21adaf7577216b3ad234988c615
",git fetch https://review.opendev.org/openstack/puppet-nova refs/changes/67/195467/1 && git format-patch -1 --stdout FETCH_HEAD,"['manifests/generic_service.pp', 'manifests/manage/network.pp', 'manifests/manage/floating.pp', 'manifests/network/bridge.pp']",4,7a4e067e9241a3fffec4b2d521f070f0bea1f50f,lint,# # === Parameters: # # [*ip*] # (mandatory) IP address of the bridge interface. # # [*netmask*] # (optional) Netmask of the bridge interface. # Defaults to '255.255.255.0' (/24). #,,40,0
openstack%2Fpuppet-cinder~master~I25515b524b9dcce9356b18c422c4db5352a528f2,openstack/puppet-cinder,master,I25515b524b9dcce9356b18c422c4db5352a528f2,lint: Fix lint issues (missing documentation for define types),MERGED,2015-06-25 09:52:52.000000000,2015-06-25 12:23:44.000000000,2015-06-25 12:23:43.000000000,"[{'_account_id': 3}, {'_account_id': 1607}, {'_account_id': 3153}, {'_account_id': 11491}]","[{'number': 1, 'created': '2015-06-25 09:52:52.000000000', 'files': ['manifests/backend/hp3par_iscsi.pp', 'manifests/backend/iscsi.pp', 'manifests/backend/san.pp', 'manifests/backend/emc_vnx.pp', 'manifests/backend/vmdk.pp', 'manifests/backend/netapp.pp'], 'web_link': 'https://opendev.org/openstack/puppet-cinder/commit/c718627edb582400e43db14608bf2c82fd6af5c4', 'message': ""lint: Fix lint issues (missing documentation for define types)\n\nThe gem 'puppet-lint-param-docs' was bumped to 1.2.0 and now handle\nclass and define type. This patch fix lint issues (missing documentation).\n\nChange-Id: I25515b524b9dcce9356b18c422c4db5352a528f2\n""}]",0,195489,c718627edb582400e43db14608bf2c82fd6af5c4,9,4,1,7155,,,0,"lint: Fix lint issues (missing documentation for define types)

The gem 'puppet-lint-param-docs' was bumped to 1.2.0 and now handle
class and define type. This patch fix lint issues (missing documentation).

Change-Id: I25515b524b9dcce9356b18c422c4db5352a528f2
",git fetch https://review.opendev.org/openstack/puppet-cinder refs/changes/89/195489/1 && git format-patch -1 --stdout FETCH_HEAD,"['manifests/backend/hp3par_iscsi.pp', 'manifests/backend/iscsi.pp', 'manifests/backend/san.pp', 'manifests/backend/emc_vnx.pp', 'manifests/backend/vmdk.pp', 'manifests/backend/netapp.pp']",6,c718627edb582400e43db14608bf2c82fd6af5c4,lint,# [*volume_backend_name*] # (optional) The name of the cinder::backend::netapp ressource # Defaults to $name. #,,32,2
openstack%2Ffuel-web~master~Ie535f5c3f86789004dce619e92b50c82b187797a,openstack/fuel-web,master,Ie535f5c3f86789004dce619e92b50c82b187797a,Same height blocks on Actions Tab,ABANDONED,2015-06-24 18:22:54.000000000,2015-06-25 12:18:58.000000000,,"[{'_account_id': 3}, {'_account_id': 8735}, {'_account_id': 8766}, {'_account_id': 8970}, {'_account_id': 8971}, {'_account_id': 9091}, {'_account_id': 15315}]","[{'number': 1, 'created': '2015-06-24 18:22:54.000000000', 'files': ['nailgun/static/views/cluster_page_tabs/actions_tab.jsx'], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/a67965cf8997de35ee1fa20ac29823354293438c', 'message': 'Same height blocks on Actions Tab\n\nCloses-Bug:#1467986\n\nChange-Id: Ie535f5c3f86789004dce619e92b50c82b187797a\n'}]",0,195248,a67965cf8997de35ee1fa20ac29823354293438c,8,7,1,9730,,,0,"Same height blocks on Actions Tab

Closes-Bug:#1467986

Change-Id: Ie535f5c3f86789004dce619e92b50c82b187797a
",git fetch https://review.opendev.org/openstack/fuel-web refs/changes/48/195248/1 && git format-patch -1 --stdout FETCH_HEAD,['nailgun/static/views/cluster_page_tabs/actions_tab.jsx'],1,a67965cf8997de35ee1fa20ac29823354293438c,bug/1467986," 'jquery',function($, _, i18n, React, utils, models, dispatcher, dialogs, componentMixins) { componentDidMount: function() { var sameHightPanes = $(this.getDOMNode()).find('.panel'), maxHeight = _.max(sameHightPanes.map(function() { return $(this).height(); }).get()); sameHightPanes.height(maxHeight); },","function(_, i18n, React, utils, models, dispatcher, dialogs, componentMixins) {",9,1
openstack%2Fnova~stable%2Fkilo~I54a056d339d98bc4092af8cf9f4f5d24b882506b,openstack/nova,stable/kilo,I54a056d339d98bc4092af8cf9f4f5d24b882506b,Make nova-manage handle completely missing flavor information,MERGED,2015-06-02 19:32:22.000000000,2015-06-25 12:11:50.000000000,2015-06-25 12:11:45.000000000,"[{'_account_id': 3}, {'_account_id': 782}, {'_account_id': 979}, {'_account_id': 5170}, {'_account_id': 5441}, {'_account_id': 6873}, {'_account_id': 10118}]","[{'number': 1, 'created': '2015-06-02 19:32:22.000000000', 'files': ['nova/tests/unit/db/test_db_api.py', 'nova/db/sqlalchemy/api.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/22adc624666e5cc94fb533d95c998f59c70d5890', 'message': ""Make nova-manage handle completely missing flavor information\n\nIf you have a really (really) old instance without any flavor information\nstashed in sysmeta, then nova-manage will not be able to convert it to\na proper flavor object in extra. This patch makes it handle that case\nby looking up the flavor by id instead. Not only will this facilitate\nthe transition, but will also ensure that any such legacy instances are\nproperly brought up to date so that going forward we can just assume that\nthey have all been converted (and remove some other places where we\nhandle the has-no-flavor-info case).\n\nThis involves changing the flavor cache to contain flavor objects\ninstead of DB objects so that the two methods that use the cache can\ncoexist. It doesn't much affect the _augment_flavors_to_migrate() path,\nother than some mechanics and test changes.\n\nConflicts:\n\tnova/tests/unit/db/test_db_api.py\n\nChange-Id: I54a056d339d98bc4092af8cf9f4f5d24b882506b\nCloses-Bug: #1460673\n(cherry picked from commit 240fb9c5392f71e59e6ef2f8f917b098f1cf9960)\n""}]",1,187740,22adc624666e5cc94fb533d95c998f59c70d5890,10,7,1,4393,,,0,"Make nova-manage handle completely missing flavor information

If you have a really (really) old instance without any flavor information
stashed in sysmeta, then nova-manage will not be able to convert it to
a proper flavor object in extra. This patch makes it handle that case
by looking up the flavor by id instead. Not only will this facilitate
the transition, but will also ensure that any such legacy instances are
properly brought up to date so that going forward we can just assume that
they have all been converted (and remove some other places where we
handle the has-no-flavor-info case).

This involves changing the flavor cache to contain flavor objects
instead of DB objects so that the two methods that use the cache can
coexist. It doesn't much affect the _augment_flavors_to_migrate() path,
other than some mechanics and test changes.

Conflicts:
	nova/tests/unit/db/test_db_api.py

Change-Id: I54a056d339d98bc4092af8cf9f4f5d24b882506b
Closes-Bug: #1460673
(cherry picked from commit 240fb9c5392f71e59e6ef2f8f917b098f1cf9960)
",git fetch https://review.opendev.org/openstack/nova refs/changes/40/187740/1 && git format-patch -1 --stdout FETCH_HEAD,"['nova/tests/unit/db/test_db_api.py', 'nova/db/sqlalchemy/api.py']",2,22adc624666e5cc94fb533d95c998f59c70d5890,bug/1460673,"def _augment_flavor_to_migrate(flavor_to_migrate, full_flavor): for key in full_flavor['extra_specs']: if key not in flavor_to_migrate.extra_specs: flavor_to_migrate.extra_specs[key] = \ full_flavor.extra_specs[key] # NOTE(danms): Avoid circular import from nova import objects deleted_ctx = instance._context.elevated(read_deleted='yes') flavor_cache[flavorid] = objects.Flavor.get_by_flavor_id( deleted_ctx, flavorid)def _load_missing_flavor(instance, flavor_cache): # NOTE(danms): Avoid circular import from nova import objects deleted_ctx = instance._context.elevated(read_deleted='yes') flavor_cache_by_id = {flavor.id: flavor for flavor in flavor_cache.values()} if instance.instance_type_id in flavor_cache_by_id: instance.flavor = flavor_cache_by_id[instance.instance_type_id] else: instance.flavor = objects.Flavor.get_by_id(deleted_ctx, instance.instance_type_id) flavor_cache[instance.flavor.flavorid] = instance.flavor instance.old_flavor = None instance.new_flavor = None # NOTE(danms): If we have a really old instance with no flavor # information at all, flavor will not have been set during load. # If that's the case, look up the flavor by id (which implies that # old_ and new_flavor are None). No need to augment with extra_specs # since we're doing the lookup from scratch. if not instance.obj_attr_is_set('flavor'): try: _load_missing_flavor(instance, flavor_cache) except exception.FlavorNotFound: LOG.error(_LE('Unable to lookup flavor for legacy instance; ' 'migration is not possible without manual ' 'intervention'), instance=instance) continue else: _augment_flavors_to_migrate(instance, flavor_cache)","def _augment_flavor_to_migrate(flavor_to_migrate, db_flavor): for key in db_flavor['extra_specs']: if key not in flavor_to_migrate.extra_specs: flavor_to_migrate.extra_specs[key] = db_flavor['extra_specs'][key] flavor_cache[flavorid] = flavor_get_by_flavor_id( instance._context, flavorid, 'yes') _augment_flavors_to_migrate(instance, flavor_cache)",189,16
openstack%2Fdevstack~master~Ie0f1979c50901004418f8622d4ca79dc4bdadd8d,openstack/devstack,master,Ie0f1979c50901004418f8622d4ca79dc4bdadd8d,Add devstack-admin cloud to clouds.yaml,MERGED,2015-06-21 14:17:08.000000000,2015-06-25 12:11:41.000000000,2015-06-25 12:11:38.000000000,"[{'_account_id': 3}, {'_account_id': 2750}, {'_account_id': 6482}, {'_account_id': 7118}, {'_account_id': 10385}]","[{'number': 1, 'created': '2015-06-21 14:17:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack/commit/43974969914e349ac9ff58232b43990994787772', 'message': 'Add devstack-admin cloud to clouds.yaml\n\nA lot of commands developers use require admin by default, so add a\n""devstack-admin"" cloud to clouds.yaml that has admin authority.\n\n $ openstack --os-cloud devstack-admin user list\n\nChange-Id: Ie0f1979c50901004418f8622d4ca79dc4bdadd8d\n'}, {'number': 2, 'created': '2015-06-21 15:17:54.000000000', 'files': ['stack.sh'], 'web_link': 'https://opendev.org/openstack/devstack/commit/e123830c15a4bd07f7ea700a46ca1e158487cdd9', 'message': 'Add devstack-admin cloud to clouds.yaml\n\nA lot of commands developers use require admin by default, so add a\n""devstack-admin"" cloud to clouds.yaml that has admin authority.\n\n $ openstack --os-cloud devstack-admin user list\n\nChange-Id: Ie0f1979c50901004418f8622d4ca79dc4bdadd8d\n'}]",0,193888,e123830c15a4bd07f7ea700a46ca1e158487cdd9,11,5,2,6486,,,0,"Add devstack-admin cloud to clouds.yaml

A lot of commands developers use require admin by default, so add a
""devstack-admin"" cloud to clouds.yaml that has admin authority.

 $ openstack --os-cloud devstack-admin user list

Change-Id: Ie0f1979c50901004418f8622d4ca79dc4bdadd8d
",git fetch https://review.opendev.org/openstack/devstack refs/changes/88/193888/1 && git format-patch -1 --stdout FETCH_HEAD,['stack.sh'],1,43974969914e349ac9ff58232b43990994787772,clouds_yaml,# clouds.yaml will have # - A `devstack` entry for the `demo` user for the `demo` project. # - A `devstack-admin` entry for the `admin` user for the `admin` project.$TOP_DIR/tools/update_clouds_yaml.py \ --file $CLOUDS_YAML \ --os-cloud devstack-admin \ --os-region-name $REGION_NAME \ --os-identity-api-version $IDENTITY_API_VERSION \ $CA_CERT_ARG \ --os-auth-url $KEYSTONE_AUTH_URI/v$IDENTITY_API_VERSION \ --os-username admin \ --os-password $ADMIN_PASSWORD \ --os-project-name admin,# clouds.yaml will have a `devstack` entry for the `demo` user for the `demo` # project.,13,2
openstack%2Fpython-mistralclient~master~Iad86f805e8bb13027946a7da9b0d79dc220d44d6,openstack/python-mistralclient,master,Iad86f805e8bb13027946a7da9b0d79dc220d44d6,Implementing run-action command in client,MERGED,2015-06-11 13:30:18.000000000,2015-06-25 12:06:08.000000000,2015-06-25 12:06:04.000000000,"[{'_account_id': 3}, {'_account_id': 6732}, {'_account_id': 7700}, {'_account_id': 8731}, {'_account_id': 15881}]","[{'number': 1, 'created': '2015-06-11 13:30:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-mistralclient/commit/c79a0fc1f1eb443ae704ed976c7579a6223c9021', 'message': 'Implementing run-action command in client\n\nImplements blueprint mistral-run-individual-action\n\nTODO (in current commit):\n  - unit tests\n  - need to think about the convenient way to pass\n    the action input (currently --input \'{""arg"": ""val""}\'\n\nChange-Id: Iad86f805e8bb13027946a7da9b0d79dc220d44d6\n'}, {'number': 2, 'created': '2015-06-23 14:11:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-mistralclient/commit/3cf709a0916271946862d752c699cf119edc56d6', 'message': 'Implementing run-action command in client\n\nImplements blueprint mistral-run-individual-action\n\nTODO (in current commit):\n  - unit tests\n\nChange-Id: Iad86f805e8bb13027946a7da9b0d79dc220d44d6\n'}, {'number': 3, 'created': '2015-06-24 13:07:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-mistralclient/commit/d7ee96591006d50d54a37af3bf2da3f3bf144623', 'message': 'Implementing run-action command in client\n\nImplements blueprint mistral-run-individual-action\n\nTODO (in current commit):\n  - unit tests\n\nChange-Id: Iad86f805e8bb13027946a7da9b0d79dc220d44d6\n'}, {'number': 4, 'created': '2015-06-24 13:09:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-mistralclient/commit/31b2bc2f0dfd254c8791e82cd54f9c5111d82e24', 'message': 'Implementing run-action command in client\n\n * Introduced new command:\n mistral run-action <name> --input <input> [--save-result] [--target TARGET]\n\nImplements blueprint mistral-run-individual-action\n\nChange-Id: Iad86f805e8bb13027946a7da9b0d79dc220d44d6\n'}, {'number': 5, 'created': '2015-06-25 08:31:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-mistralclient/commit/72f07b7f8f75a00943332e9dfeec089364f36622', 'message': 'Implementing run-action command in client\n\n * Introduced new command:\n mistral run-action <name> <input> [--save-result] [--target TARGET]\n\n * Short options: -s (--save-result), -t (--target)\n\nImplements blueprint mistral-run-individual-action\n\nChange-Id: Iad86f805e8bb13027946a7da9b0d79dc220d44d6\n'}, {'number': 6, 'created': '2015-06-25 10:31:59.000000000', 'files': ['mistralclient/tests/unit/v2/test_action_executions.py', 'mistralclient/tests/unit/v2/test_cli_action_execs.py', 'mistralclient/shell.py', 'mistralclient/commands/v2/action_executions.py', 'mistralclient/api/v2/action_executions.py'], 'web_link': 'https://opendev.org/openstack/python-mistralclient/commit/1a0ccd1414a889ca5c52edc0b57e5194bba579bc', 'message': 'Implementing run-action command in client\n\n * Introduced new command:\n mistral run-action <name> <input> [--save-result] [--target TARGET]\n\n * Short options: -s (--save-result), -t (--target)\n\nImplements blueprint mistral-run-individual-action\n\nChange-Id: Iad86f805e8bb13027946a7da9b0d79dc220d44d6\n'}]",10,190636,1a0ccd1414a889ca5c52edc0b57e5194bba579bc,25,5,6,7700,,,0,"Implementing run-action command in client

 * Introduced new command:
 mistral run-action <name> <input> [--save-result] [--target TARGET]

 * Short options: -s (--save-result), -t (--target)

Implements blueprint mistral-run-individual-action

Change-Id: Iad86f805e8bb13027946a7da9b0d79dc220d44d6
",git fetch https://review.opendev.org/openstack/python-mistralclient refs/changes/36/190636/6 && git format-patch -1 --stdout FETCH_HEAD,"['mistralclient/shell.py', 'mistralclient/commands/v2/action_executions.py', 'mistralclient/api/v2/action_executions.py']",3,c79a0fc1f1eb443ae704ed976c7579a6223c9021,bp/mistral-run-individual-action,"import json def create(self, name, input=None, **params): self._ensure_not_empty(name=name) data = {'name': name} if input: data['input'] = json.dumps(input) if params: data['params'] = params resp = self.client.http_client.post( '/action_executions', json.dumps(data) ) if resp.status_code != 201: self._raise_api_exception(resp) if params.get('save_result'): return self.resource_class(self, base.get_json(resp)) else: return base.extract_json(resp, response_key='result') ",,107,1
openstack%2Ffuel-library~master~I1ba75c74a83f780d2b623b0ad1e17ee38fecc0af,openstack/fuel-library,master,I1ba75c74a83f780d2b623b0ad1e17ee38fecc0af,Possibility to detach heat from controllers,MERGED,2015-05-29 22:40:29.000000000,2015-06-25 12:04:30.000000000,2015-06-25 12:03:36.000000000,"[{'_account_id': 3}, {'_account_id': 7195}, {'_account_id': 8971}, {'_account_id': 11090}, {'_account_id': 11827}, {'_account_id': 13948}, {'_account_id': 14774}, {'_account_id': 14985}]","[{'number': 1, 'created': '2015-05-29 22:40:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/c716de513cb70e1d738592bc8d5e029fbea1e8ec', 'message': '(WIP) Possibility to detach heat from controllers\n\nWORK IN PROGRESS\n\nAdds the possibility to use external (non-controllers) keystone,\ndb, rabbitmq, etc for heat services.\n\nPartial blueprint: detach-components-from-controllers\n\nChange-Id: I1ba75c74a83f780d2b623b0ad1e17ee38fecc0af\n'}, {'number': 2, 'created': '2015-06-01 16:32:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/004bc8709e1cecfb56fc3482475aca9cc40fd15e', 'message': '(WIP) Possibility to detach heat from controllers\n\nWORK IN PROGRESS\n\nAdds the possibility to use external (non-controllers) keystone,\ndb, rabbitmq, etc for heat services.\n\nPartial blueprint: detach-components-from-controllers\n\nChange-Id: I1ba75c74a83f780d2b623b0ad1e17ee38fecc0af\n'}, {'number': 3, 'created': '2015-06-01 16:43:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/4b68e1ff1393a0f3da5b49871038eb6ce931839c', 'message': '(WIP) Possibility to detach heat from controllers\n\nWORK IN PROGRESS\n\nAdds the possibility to use external (non-controllers) keystone,\ndb, rabbitmq, etc for heat services.\n\nPartial blueprint: detach-components-from-controllers\n\nChange-Id: I1ba75c74a83f780d2b623b0ad1e17ee38fecc0af\n'}, {'number': 4, 'created': '2015-06-01 16:51:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/a62908fb9e6f5a75a7783768f04fd79e35582d48', 'message': '(WIP) Possibility to detach heat from controllers\n\nWORK IN PROGRESS\n\nAdds the possibility to use external (non-controllers) keystone,\ndb, rabbitmq, etc for heat services.\n\nPartial blueprint: detach-components-from-controllers\n\nChange-Id: I1ba75c74a83f780d2b623b0ad1e17ee38fecc0af\n'}, {'number': 5, 'created': '2015-06-02 15:13:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/ebdc10d5fde855f60a90e15e69e49ed062ae1434', 'message': '(WIP) Possibility to detach heat from controllers\n\nWORK IN PROGRESS\n\nAdds the possibility to use external (non-controllers) keystone,\ndb, rabbitmq, etc for heat services.\n\nPartial blueprint: detach-components-from-controllers\n\nChange-Id: I1ba75c74a83f780d2b623b0ad1e17ee38fecc0af\n'}, {'number': 6, 'created': '2015-06-04 00:34:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/477487910234e623c16a862dc087e0a32e5b8233', 'message': '(WIP) Possibility to detach heat from controllers\n\nWORK IN PROGRESS\n\nAdds the possibility to use external (non-controllers) keystone,\ndb, rabbitmq, etc for heat services.\n\nPartial blueprint: detach-components-from-controllers\n\nChange-Id: I1ba75c74a83f780d2b623b0ad1e17ee38fecc0af\n'}, {'number': 7, 'created': '2015-06-10 19:05:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/3d43b0975fe83ad5018031e1c3806aae997ecbe4', 'message': '(WIP) Possibility to detach heat from controllers\n\nWORK IN PROGRESS\n\nAdds the possibility to use external (non-controllers) keystone,\ndb, rabbitmq, etc for heat services.\n\nPartial blueprint: detach-components-from-controllers\n\nChange-Id: I1ba75c74a83f780d2b623b0ad1e17ee38fecc0af\n'}, {'number': 8, 'created': '2015-06-11 16:34:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/a43c3e343cb2ea38e84e3d6aa3b3d5abf3febc09', 'message': '(WIP) Possibility to detach heat from controllers\n\nWORK IN PROGRESS\n\nAdds the possibility to use external (non-controllers) keystone,\ndb, rabbitmq, etc for heat services.\n\nPartial blueprint: detach-components-from-controllers\n\nChange-Id: I1ba75c74a83f780d2b623b0ad1e17ee38fecc0af\n'}, {'number': 9, 'created': '2015-06-24 09:27:00.000000000', 'files': ['deployment/puppet/osnailyfacter/modular/heat/heat.pp', 'deployment/puppet/osnailyfacter/modular/globals/globals.pp', 'deployment/puppet/openstack/manifests/heat.pp'], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/6400e918244c98d78cd027278dbf8608064e5249', 'message': 'Possibility to detach heat from controllers\n\nAdds the possibility to use external (non-controllers) keystone,\ndb, rabbitmq, etc for heat services.\n\nPartial blueprint: detach-components-from-controllers\n\nChange-Id: I1ba75c74a83f780d2b623b0ad1e17ee38fecc0af\n'}]",1,186942,6400e918244c98d78cd027278dbf8608064e5249,152,8,9,9387,,,0,"Possibility to detach heat from controllers

Adds the possibility to use external (non-controllers) keystone,
db, rabbitmq, etc for heat services.

Partial blueprint: detach-components-from-controllers

Change-Id: I1ba75c74a83f780d2b623b0ad1e17ee38fecc0af
",git fetch https://review.opendev.org/openstack/fuel-library refs/changes/42/186942/9 && git format-patch -1 --stdout FETCH_HEAD,"['deployment/puppet/osnailyfacter/modular/heat/heat.pp', 'deployment/puppet/openstack/manifests/heat.pp']",2,c716de513cb70e1d738592bc8d5e029fbea1e8ec,bp/detach-components-from-controllers," $keystone_auth = true, $create_heat_db = true, } if ($create_heat_db){ class { 'heat::db::mysql': password => $db_password, dbname => $db_name, user => $db_user, host => $db_host, allowed_hosts => $db_allowed_hosts, require => Firewall['204 heat-api'], } } if ($keystone_auth){ # Auth class { 'heat::keystone::auth' : password => $keystone_password, auth_name => $keystone_user, public_address => $external_ip, admin_address => $keystone_host, internal_address => $keystone_host, port => '8004', version => 'v1', region => 'RegionOne', tenant => 'services', email => ""${keystone_user}@localhost"", public_protocol => 'http', admin_protocol => 'http', internal_protocol => 'http', configure_endpoint => true, } #TODO(bogdando) clarify this new to Fuel Heat auth cfn patterns class { 'heat::keystone::auth_cfn' : password => $keystone_password, auth_name => ""${keystone_user}-cfn"", service_type => 'cloudformation', public_address => $external_ip, admin_address => $keystone_host, internal_address => $keystone_host, port => '8000', version => 'v1', region => 'RegionOne', tenant => 'services', email => ""${keystone_user}-cfn@localhost"", public_protocol => 'http', admin_protocol => 'http', internal_protocol => 'http', configure_endpoint => true, } }"," } -> class { 'heat::db::mysql': password => $db_password, dbname => $db_name, user => $db_user, host => $db_host, allowed_hosts => $db_allowed_hosts, } # Auth class { 'heat::keystone::auth' : password => $keystone_password, auth_name => $keystone_user, public_address => $external_ip, admin_address => $keystone_host, internal_address => $keystone_host, port => '8004', version => 'v1', region => 'RegionOne', tenant => 'services', email => ""${keystone_user}@localhost"", public_protocol => 'http', admin_protocol => 'http', internal_protocol => 'http', configure_endpoint => true, } #TODO(bogdando) clarify this new to Fuel Heat auth cfn patterns class { 'heat::keystone::auth_cfn' : password => $keystone_password, auth_name => ""${keystone_user}-cfn"", service_type => 'cloudformation', public_address => $external_ip, admin_address => $keystone_host, internal_address => $keystone_host, port => '8000', version => 'v1', region => 'RegionOne', tenant => 'services', email => ""${keystone_user}-cfn@localhost"", public_protocol => 'http', admin_protocol => 'http', internal_protocol => 'http', configure_endpoint => true, } ",97,62
openstack%2Fdesignate-specs~master~Ie474d02c3cb3b610d1fad64e88f863f37d9c01fe,openstack/designate-specs,master,Ie474d02c3cb3b610d1fad64e88f863f37d9c01fe,Add Zone Exists Event Spec,MERGED,2015-06-03 14:22:13.000000000,2015-06-25 12:02:58.000000000,2015-06-25 12:02:57.000000000,"[{'_account_id': 3}, {'_account_id': 741}, {'_account_id': 8094}, {'_account_id': 8098}, {'_account_id': 8099}, {'_account_id': 8174}]","[{'number': 1, 'created': '2015-06-03 14:22:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/designate-specs/commit/759e3d2de953e312ad78b80649ffc0bc1b6e6275', 'message': 'Add Zone Exists Event Spec\n\nChange-Id: Ie474d02c3cb3b610d1fad64e88f863f37d9c01fe\n'}, {'number': 2, 'created': '2015-06-18 10:54:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/designate-specs/commit/4cb95b5cf8a7f87131fd05becb478e094b9652fc', 'message': 'Add Zone Exists Event Spec\n\nChange-Id: Ie474d02c3cb3b610d1fad64e88f863f37d9c01fe\n'}, {'number': 3, 'created': '2015-06-18 10:55:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/designate-specs/commit/45c91fd082778f0ced8272b5920a79ee8b749c0b', 'message': 'Add Zone Exists Event Spec\n\nChange-Id: Ie474d02c3cb3b610d1fad64e88f863f37d9c01fe\n'}, {'number': 4, 'created': '2015-06-24 11:18:42.000000000', 'files': ['specs/liberty/zone-exists-event.rst'], 'web_link': 'https://opendev.org/openstack/designate-specs/commit/661963a667fb6f10c415f653110437131d78981d', 'message': 'Add Zone Exists Event Spec\n\nChange-Id: Ie474d02c3cb3b610d1fad64e88f863f37d9c01fe\n'}]",2,188018,661963a667fb6f10c415f653110437131d78981d,15,6,4,741,,,0,"Add Zone Exists Event Spec

Change-Id: Ie474d02c3cb3b610d1fad64e88f863f37d9c01fe
",git fetch https://review.opendev.org/openstack/designate-specs refs/changes/18/188018/1 && git format-patch -1 --stdout FETCH_HEAD,['specs/liberty/zone-exists-event.rst'],1,759e3d2de953e312ad78b80649ffc0bc1b6e6275,188018,".. This work is licensed under a Creative Commons Attribution 3.0 Unported License. http://creativecommons.org/licenses/by/3.0/legalcode =================== Zone Exists Event =================== https://blueprints.launchpad.net/designate/+spec/zone-exists-event Problem description =================== Designate emits several events for use by Ceilometer for Metering & Billing purposes. Currently, these events are sent for zone/rrset/etc create, update and delete actions. As these events are emitted over RabbitMQ, we cannot guarantee delivery. In order to ensure accurate billing for customers, we need to provide a mechanism for identifying ""lost"" events. This is particularity important for Zone create/delete events, as per-Zone/per-Timeperiod is the most common billing unit. The accepted standard solution to the loss of create/delete events is for each service to emit a periodic ""exists"" event, this allows Ceilometer to, for example, identify that N exists events in a row were not received, surmising that a ""delete"" event was missed. In other services like Nova there is a clear ""owner"" for each core resource (e.g. an instance is owned by the compute node it resides on), this allows each nova-compute instance to periodically emit a `compute.instance.exists` event for a small number of instances. Designate has no such clear owner, and many thousands of zones may belong to a single pool (the smallest grouping we current;y have available). This poses a problem, in that emitting 100's of thousands of eventsm, or more, each hour may be too demaining for the active pool manager. Proposed change =============== We will introduce a new service `designate-zone-manager` which will handle all periodic tasks relating to the zones it is responsible for. Initially, this will only be the periodic `dns.domain.exists` event, but over time we will add additional tasks, for example, polling of Secondary zones at their refresh intervals. A concept of ""zone shards"" will be introduced, where every zone will be allocated to a shard based on the first three characters of the zones UUID. This will provide for 4,096 distinct shards to be distributed over the set of available `designate-zone-manager` processes, ensuring that no single `designate-zone-manager` is responsible for more zones than it can reasonably handle. With 5 million zones, each shard should contain approx 1.2k zones. Finally, distribution of shards to available `designate-zone-manager` processes will be handled by the `OpenStack Tooz <https://github.com/openstack/tooz>`_ library. Tooz provides the building blocks required to implement a ""Partitioner"", using it's Group Membership APIs to divvy up the available shards between active workers, including dynamically re-allocating based on membership changes. API Changes ----------- None Central Changes --------------- None Storage Changes --------------- A new column will be added to the domains, recordsets and records tables, this column will be populated by the storage driver with the integer representation of the first 3 characters of the UUID, giving a whole number with a value between 0 and 4095. We add the shard to the RecordSets/Records tables now, as we know it will be used in a future blueprint (ALIAS records). Domains Table Additions ^^^^^^^^^^^^^^^^^^^^^^^ +-------+--------+-----------+---------+ | Row | Type | Nullable? | Unique? | +=======+========+===========+=========+ | shard | int(2) | No | No | +-------+--------+-----------+---------+ RecordSets/Records Table Additions ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ +--------------+--------+-----------+---------+ | Row | Type | Nullable? | Unique? | +==============+========+===========+=========+ | domain_shard | int(2) | No | No | +--------------+--------+-----------+---------+ Other Changes ------------- A new service, `designate-zone-manager` will be introduced. This service will extend the Designate base `Service` class, but will not include the typical `RPCService` mixin. For this initial use case, there is no requirement for an RPC API. This service will use the existing oslo-incubator ThreadGroup.add_timer() methods for scheduling tasks, and the tooz library for group membership. The timer interval will be exposed as a configuration value, defaulting to 3600 seconds. Group membership will be implemented as a `Service` mixin, similar to `RPCService`, allowing for it's inclusion in other services such as `designate-pool-manager`. The `dns.domain.exists` event format will be identical to the domain create/update/delete event format, with the only difference being the event name. Finally, the list of Zones each `designate-zone-manager` is responsible for will be gathered at the start of each timer interval, in batches of a configurable size, based on the range of shard's allocated. Implementation ============== Assignee(s) ----------- Primary assignee: TBD Milestones ---------- Target Milestone for completion: Liberty-1 Work Items ---------- * Implement ""Partitioner"" based on Tooz * Implement `GroupMembership` mixin (Name TBD) * Create new `designate-zone-manager` service * Implement periodic exists event Dependencies ============ - Requires the OpenStack Tooz library be added to our requirements - Requires infrastructure for the the OpenStack Tooz library (memcache, redis, or zookeeper) ",,153,0
openstack%2Ffuel-library~master~I46582e9199bc9ed389f1b441306b8b109325c69a,openstack/fuel-library,master,I46582e9199bc9ed389f1b441306b8b109325c69a,Possibility to detach cinder from controllers,MERGED,2015-05-26 19:29:10.000000000,2015-06-25 12:00:52.000000000,2015-06-25 11:59:51.000000000,"[{'_account_id': 3}, {'_account_id': 7195}, {'_account_id': 8971}, {'_account_id': 11090}, {'_account_id': 13948}, {'_account_id': 14774}, {'_account_id': 14985}]","[{'number': 1, 'created': '2015-05-26 19:29:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/cac40cc518cf1d950524544f911d1bfecf30c5a1', 'message': '(WIP) Possibility to detach cinder from controllers\n\nWORK IN PROGRESS\n\nAdds the possibility to use external (non-controllers) keystone,\ndb, rabbitmq, etc for cinder services.\n\nPartial blueprint: detach-components-from-controllers\n\nChange-Id: I46582e9199bc9ed389f1b441306b8b109325c69a\n'}, {'number': 2, 'created': '2015-05-27 23:34:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/caf6dc8d91528fb2803648600c6d9b5f70b7e86e', 'message': '(WIP) Possibility to detach cinder from controllers\n\nWORK IN PROGRESS\n\nAdds the possibility to use external (non-controllers) keystone,\ndb, rabbitmq, etc for cinder services.\n\nPartial blueprint: detach-components-from-controllers\n\nChange-Id: I46582e9199bc9ed389f1b441306b8b109325c69a\n'}, {'number': 3, 'created': '2015-05-29 19:14:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/7922d7be5c571eba2af389f93bbdabd097b723e3', 'message': '(WIP) Possibility to detach cinder from controllers\n\nWORK IN PROGRESS\n\nAdds the possibility to use external (non-controllers) keystone,\ndb, rabbitmq, etc for cinder services.\n\nPartial blueprint: detach-components-from-controllers\n\nChange-Id: I46582e9199bc9ed389f1b441306b8b109325c69a\n'}, {'number': 4, 'created': '2015-06-01 17:11:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/6a0d7c82823294decb41b7f7c2a3c7022c45395f', 'message': '(WIP) Possibility to detach cinder from controllers\n\nWORK IN PROGRESS\n\nAdds the possibility to use external (non-controllers) keystone,\ndb, rabbitmq, etc for cinder services.\n\nPartial blueprint: detach-components-from-controllers\n\nChange-Id: I46582e9199bc9ed389f1b441306b8b109325c69a\n'}, {'number': 5, 'created': '2015-06-02 15:13:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/8e7755f1df92b05ead8ebaebcd5745d91f3e662d', 'message': '(WIP) Possibility to detach cinder from controllers\n\nWORK IN PROGRESS\n\nAdds the possibility to use external (non-controllers) keystone,\ndb, rabbitmq, etc for cinder services.\n\nPartial blueprint: detach-components-from-controllers\n\nChange-Id: I46582e9199bc9ed389f1b441306b8b109325c69a\n'}, {'number': 6, 'created': '2015-06-08 17:01:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/01c340ea59707b63bd1bd136e11b96f4a51c8b98', 'message': '(WIP) Possibility to detach cinder from controllers\n\nWORK IN PROGRESS\n\nAdds the possibility to use external (non-controllers) keystone,\ndb, rabbitmq, etc for cinder services.\n\nPartial blueprint: detach-components-from-controllers\n\nChange-Id: I46582e9199bc9ed389f1b441306b8b109325c69a\n'}, {'number': 7, 'created': '2015-06-10 18:27:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/a9d60a3562f256e28a8f7142209bc3d18fc90e42', 'message': '(WIP) Possibility to detach cinder from controllers\n\nWORK IN PROGRESS\n\nAdds the possibility to use external (non-controllers) keystone,\ndb, rabbitmq, etc for cinder services.\n\nPartial blueprint: detach-components-from-controllers\n\nChange-Id: I46582e9199bc9ed389f1b441306b8b109325c69a\n'}, {'number': 8, 'created': '2015-06-10 18:41:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/a04d9f116bb025f58ea459be39321ab2a46d2cba', 'message': '(WIP) Possibility to detach cinder from controllers\n\nWORK IN PROGRESS\n\nAdds the possibility to use external (non-controllers) keystone,\ndb, rabbitmq, etc for cinder services.\n\nPartial blueprint: detach-components-from-controllers\n\nChange-Id: I46582e9199bc9ed389f1b441306b8b109325c69a\n'}, {'number': 9, 'created': '2015-06-24 09:27:27.000000000', 'files': ['deployment/puppet/osnailyfacter/modular/openstack-cinder/openstack-cinder.pp', 'deployment/puppet/openstack/manifests/cinder.pp', 'deployment/puppet/osnailyfacter/modular/globals/globals.pp', 'deployment/puppet/osnailyfacter/modular/roles/cinder.pp'], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/e8ff3f01b460a1276f0452540081be9b3dddb2ba', 'message': 'Possibility to detach cinder from controllers\n\nAdds the possibility to use external (non-controllers) keystone,\ndb, rabbitmq, etc for cinder services.\n\nPartial blueprint: detach-components-from-controllers\n\nChange-Id: I46582e9199bc9ed389f1b441306b8b109325c69a\n'}]",4,185710,e8ff3f01b460a1276f0452540081be9b3dddb2ba,156,7,9,9387,,,0,"Possibility to detach cinder from controllers

Adds the possibility to use external (non-controllers) keystone,
db, rabbitmq, etc for cinder services.

Partial blueprint: detach-components-from-controllers

Change-Id: I46582e9199bc9ed389f1b441306b8b109325c69a
",git fetch https://review.opendev.org/openstack/fuel-library refs/changes/10/185710/8 && git format-patch -1 --stdout FETCH_HEAD,"['deployment/puppet/osnailyfacter/modular/openstack-cinder/openstack-cinder.pp', 'deployment/puppet/osnailyfacter/modular/roles/cinder.pp']",2,cac40cc518cf1d950524544f911d1bfecf30c5a1,bp/detach-components-from-controllers,"$cinder_hash = hiera_hash('cinder', {})$cinder_db_user = hiera('cinder_db_user', 'cinder') $cinder_db_dbname = hiera('cinder_db_dbname', 'cinder') $cinder_db_password = $cinder_hash[db_password] $db_host = hiera('db_host', $management_vip) $keystone_user = $cinder_hash['user'] ? { default => $cinder_hash['user'], undef => 'cinder', } $service_endpoint = hiera('service_endpoint', $management_vip) $glance_api_servers = hiera('glance_api_servers', ""${management_vip}:9292"") if hiera('amqp_nodes', false) { $amqp_nodes = hiera('amqp_nodes') } elsif $internal_address in $controller_nodes {$amqp_port = hiera('amqp_port', '5673') sql_connection => ""mysql://${cinder_db_user}:${cinder_db_password}@${db_host}/${cinder_db_dbname}?charset=utf8&read_timeout=60"", glance_api_servers => $glance_api_servers, auth_host => $service_endpoint, keystone_user => $keystone_user,","$cinder_hash = hiera('cinder', {})if $internal_address in $controller_nodes {$amqp_port = '5673' sql_connection => ""mysql://cinder:${cinder_hash[db_password]}@${management_vip}/cinder?charset=utf8&read_timeout=60"", glance_api_servers => ""${management_vip}:9292"", auth_host => $management_vip,",35,11
openstack%2Fdevstack~master~Id02378b6f3a86f9fee201d91688205705202c0a8,openstack/devstack,master,Id02378b6f3a86f9fee201d91688205705202c0a8,Update clouds.yaml,MERGED,2015-06-21 14:08:47.000000000,2015-06-25 11:58:35.000000000,2015-06-25 11:58:31.000000000,"[{'_account_id': 3}, {'_account_id': 2750}, {'_account_id': 6482}, {'_account_id': 7118}, {'_account_id': 10385}]","[{'number': 1, 'created': '2015-06-21 14:08:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack/commit/8bac8da2bf3814cf5a518b963f26ee04652e9c3e', 'message': 'Update clouds.yaml\n\nIf the user already has a clouds.yaml, update it with the ""devstack""\nentry.\n\nChange-Id: Id02378b6f3a86f9fee201d91688205705202c0a8\n'}, {'number': 2, 'created': '2015-06-21 15:17:54.000000000', 'files': ['tools/update_clouds_yaml.py', 'stack.sh'], 'web_link': 'https://opendev.org/openstack/devstack/commit/e1fa0701b3920932d40b031b08d19c6fd2e3397e', 'message': 'Update clouds.yaml\n\nIf the user already has a clouds.yaml, update it with the ""devstack""\nentry.\n\nChange-Id: Id02378b6f3a86f9fee201d91688205705202c0a8\n'}]",0,193886,e1fa0701b3920932d40b031b08d19c6fd2e3397e,12,5,2,6486,,,0,"Update clouds.yaml

If the user already has a clouds.yaml, update it with the ""devstack""
entry.

Change-Id: Id02378b6f3a86f9fee201d91688205705202c0a8
",git fetch https://review.opendev.org/openstack/devstack refs/changes/86/193886/1 && git format-patch -1 --stdout FETCH_HEAD,"['tools/update_clouds_yaml.py', 'stack.sh']",2,8bac8da2bf3814cf5a518b963f26ee04652e9c3e,clouds_yaml,"# Update/create user clouds.yaml file. # clouds.yaml will have a `devstack` entry for the `demo` user for the `demo` # project. # The location is a variable to allow for easier refactoring later to make it # overridable. There is currently no usecase where doing so makes sense, so # it's not currently configurable. mkdir -p $(dirname $CLOUDS_YAML) CA_CERT_ARG='' if [ -f ""$SSL_BUNDLE_FILE"" ]; then CA_CERT_ARG=""--os-cacert $SSL_BUNDLE_FILE""$TOP_DIR/tools/update_clouds_yaml.py \ --file $CLOUDS_YAML \ --os-cloud devstack \ --os-region-name $REGION_NAME \ --os-identity-api-version $IDENTITY_API_VERSION \ $CA_CERT_ARG \ --os-auth-url $KEYSTONE_AUTH_URI/v$IDENTITY_API_VERSION \ --os-username demo \ --os-password $ADMIN_PASSWORD \ --os-project-name demo","# Write out a clouds.yaml file # putting the location into a variable to allow for easier refactoring later # to make it overridable. There is current no usecase where doing so makes # sense, so I'm not actually doing it now.if [ ! -e $CLOUDS_YAML ]; then mkdir -p $(dirname $CLOUDS_YAML) cat >""$CLOUDS_YAML"" <<EOF clouds: devstack: auth: auth_url: $KEYSTONE_AUTH_URI/v$IDENTITY_API_VERSION username: demo project_name: demo password: $ADMIN_PASSWORD region_name: $REGION_NAME identity_api_version: $IDENTITY_API_VERSION EOF if [ -f ""$SSL_BUNDLE_FILE"" ]; then echo "" cacert: $SSL_BUNDLE_FILE"" >>""$CLOUDS_YAML"" fi",118,20
openstack%2Fdevstack~master~I9b5361ce6e1771781d7ae7226974604a7f9e5d00,openstack/devstack,master,I9b5361ce6e1771781d7ae7226974604a7f9e5d00,Use swift store config files in glance,MERGED,2015-06-19 03:11:19.000000000,2015-06-25 11:45:31.000000000,2015-06-25 11:45:28.000000000,"[{'_account_id': 3}, {'_account_id': 455}, {'_account_id': 2750}, {'_account_id': 7118}, {'_account_id': 7191}, {'_account_id': 7715}, {'_account_id': 10385}, {'_account_id': 14101}]","[{'number': 1, 'created': '2015-06-19 03:11:19.000000000', 'files': ['lib/glance'], 'web_link': 'https://opendev.org/openstack/devstack/commit/f4f01c63973246cbd7821fb28f0e8f9d74e4a131', 'message': 'Use swift store config files in glance\n\nUsing the swift_store_auth_address, swift_store_user and swift_store_key are\nmarked as deprecated in glance in favour of using a standalone config file that\nprovides multiple auth options.\n\nCreate and use a standalone authentication file for communicating with swift.\n\nChange-Id: I9b5361ce6e1771781d7ae7226974604a7f9e5d00\n'}]",1,193402,f4f01c63973246cbd7821fb28f0e8f9d74e4a131,12,8,1,7191,,,0,"Use swift store config files in glance

Using the swift_store_auth_address, swift_store_user and swift_store_key are
marked as deprecated in glance in favour of using a standalone config file that
provides multiple auth options.

Create and use a standalone authentication file for communicating with swift.

Change-Id: I9b5361ce6e1771781d7ae7226974604a7f9e5d00
",git fetch https://review.opendev.org/openstack/devstack refs/changes/02/193402/1 && git format-patch -1 --stdout FETCH_HEAD,['lib/glance'],1,f4f01c63973246cbd7821fb28f0e8f9d74e4a131,glance-swift-store,GLANCE_SWIFT_STORE_CONF=$GLANCE_CONF_DIR/glance-swift-store.conf iniset $GLANCE_API_CONF glance_store swift_store_config_file $GLANCE_SWIFT_STORE_CONF iniset $GLANCE_API_CONF glance_store default_swift_reference ref1 iniset $GLANCE_SWIFT_STORE_CONF ref1 user $SERVICE_TENANT_NAME:glance-swift iniset $GLANCE_SWIFT_STORE_CONF ref1 key $SERVICE_PASSWORD iniset $GLANCE_SWIFT_STORE_CONF ref1 auth_address $KEYSTONE_SERVICE_URI/v2.0/ # commenting is not strictly necessary but it's confusing to have bad values in conf inicomment $GLANCE_API_CONF glance_store swift_store_user inicomment $GLANCE_API_CONF glance_store swift_store_key inicomment $GLANCE_API_CONF glance_store swift_store_auth_address, iniset $GLANCE_API_CONF glance_store swift_store_auth_address $KEYSTONE_SERVICE_URI/v2.0/ iniset $GLANCE_API_CONF glance_store swift_store_user $SERVICE_TENANT_NAME:glance-swift iniset $GLANCE_API_CONF glance_store swift_store_key $SERVICE_PASSWORD,13,3
openstack%2Fanchor~master~I4d67c7c2adb88fe69236a97fd8d864f56b22d996,openstack/anchor,master,I4d67c7c2adb88fe69236a97fd8d864f56b22d996,Use the right class for open file,MERGED,2015-06-23 02:45:56.000000000,2015-06-25 11:45:03.000000000,2015-06-25 11:45:03.000000000,"[{'_account_id': 3}, {'_account_id': 11397}, {'_account_id': 11716}]","[{'number': 1, 'created': '2015-06-23 02:45:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/anchor/commit/b12598be7ff4ab0ce79eabc848e2633675a2383c', 'message': 'Use the right class for open file\n\nPython3 uses different class for open files. Use the appropriate mock\nbase in tests.\n\nChange-Id: I4d67c7c2adb88fe69236a97fd8d864f56b22d996\n'}, {'number': 2, 'created': '2015-06-23 23:09:21.000000000', 'files': ['tests/X509/test_x509_csr.py', 'tests/X509/test_x509_certificate.py'], 'web_link': 'https://opendev.org/openstack/anchor/commit/d3026642787c71f045bfba1666898d4fda3e1c9c', 'message': 'Use the right class for open file\n\nPython3 uses different class for open files. Use the appropriate mock\nbase in tests.\n\nChange-Id: I4d67c7c2adb88fe69236a97fd8d864f56b22d996\n'}]",0,194473,d3026642787c71f045bfba1666898d4fda3e1c9c,11,3,2,1528,,,0,"Use the right class for open file

Python3 uses different class for open files. Use the appropriate mock
base in tests.

Change-Id: I4d67c7c2adb88fe69236a97fd8d864f56b22d996
",git fetch https://review.opendev.org/openstack/anchor refs/changes/73/194473/1 && git format-patch -1 --stdout FETCH_HEAD,"['tests/X509/test_x509_csr.py', 'tests/X509/test_x509_certificate.py']",2,b12598be7ff4ab0ce79eabc848e2633675a2383c,py3_file,import sysif sys.version_info[0] < 3: file_class = file else: import _io file_class = _io.TextIOWrapper mock_open.return_value = mock.MagicMock(spec=file_class), mock_open.return_value = mock.MagicMock(spec=file),18,2
openstack%2Fanchor~master~Ie8949acf69dbf376044de357ba16da3fa4c95def,openstack/anchor,master,Ie8949acf69dbf376044de357ba16da3fa4c95def,"Use hex, not get_hex() in uuid",MERGED,2015-06-24 01:04:39.000000000,2015-06-25 11:44:35.000000000,2015-06-25 11:44:33.000000000,"[{'_account_id': 3}, {'_account_id': 11397}, {'_account_id': 11716}]","[{'number': 1, 'created': '2015-06-24 01:04:39.000000000', 'files': ['anchor/certificate_ops.py'], 'web_link': 'https://opendev.org/openstack/anchor/commit/4e6724c35ba11490fec834b50f00cb5337aa0ee4', 'message': 'Use hex, not get_hex() in uuid\n\nPython3 compatibility\n\nChange-Id: Ie8949acf69dbf376044de357ba16da3fa4c95def\n'}]",0,194901,4e6724c35ba11490fec834b50f00cb5337aa0ee4,7,3,1,1528,,,0,"Use hex, not get_hex() in uuid

Python3 compatibility

Change-Id: Ie8949acf69dbf376044de357ba16da3fa4c95def
",git fetch https://review.opendev.org/openstack/anchor refs/changes/01/194901/1 && git format-patch -1 --stdout FETCH_HEAD,['anchor/certificate_ops.py'],1,4e6724c35ba11490fec834b50f00cb5337aa0ee4,uuid_hex," serial = int(int(uuid.uuid4().hex, 16) % sys.maxsize)"," serial = int(int(uuid.uuid4().get_hex(), 16) % sys.maxsize)",1,1
openstack%2Ffuturist~master~Ia2f112e2ed6ec640c03bfa877a9e0b8e90324499,openstack/futurist,master,Ia2f112e2ed6ec640c03bfa877a9e0b8e90324499,Allow adding periodic callables at runtime,MERGED,2015-06-15 22:42:53.000000000,2015-06-25 11:39:13.000000000,2015-06-25 11:39:11.000000000,"[{'_account_id': 3}, {'_account_id': 1297}, {'_account_id': 5638}, {'_account_id': 10239}]","[{'number': 1, 'created': '2015-06-15 22:42:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/futurist/commit/26ad10680581af93f0b40d5c2777f2d986607be3', 'message': 'Allow adding periodic callables at runtime (WIP)\n\nChange-Id: Ia2f112e2ed6ec640c03bfa877a9e0b8e90324499\n'}, {'number': 2, 'created': '2015-06-16 19:21:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/futurist/commit/b29f3fc84ae208f6ffde6f530dcdeb331b205fff', 'message': 'Allow adding periodic callables at runtime\n\nChange-Id: Ia2f112e2ed6ec640c03bfa877a9e0b8e90324499\n'}, {'number': 3, 'created': '2015-06-24 23:01:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/futurist/commit/3b8168f1543ede52d9dc562b684e13f26ed2d203', 'message': 'Allow adding periodic callables at runtime\n\nChange-Id: Ia2f112e2ed6ec640c03bfa877a9e0b8e90324499\n'}, {'number': 4, 'created': '2015-06-25 01:53:25.000000000', 'files': ['futurist/periodics.py', 'futurist/tests/test_periodics.py'], 'web_link': 'https://opendev.org/openstack/futurist/commit/0b7d1e00926f70182f97b506d801284e13d1f3b3', 'message': 'Allow adding periodic callables at runtime\n\nChange-Id: Ia2f112e2ed6ec640c03bfa877a9e0b8e90324499\n'}]",4,191998,0b7d1e00926f70182f97b506d801284e13d1f3b3,20,4,4,1297,,,0,"Allow adding periodic callables at runtime

Change-Id: Ia2f112e2ed6ec640c03bfa877a9e0b8e90324499
",git fetch https://review.opendev.org/openstack/futurist refs/changes/98/191998/3 && git format-patch -1 --stdout FETCH_HEAD,['futurist/periodics.py'],1,26ad10680581af93f0b40d5c2777f2d986607be3,add-periodics-on-demand," def add(self, cb, *args, **kwargs): """"""Adds a new periodic callback to the current worker."""""" if not six.callable(cb): raise ValueError(""Periodic callback %r must be callable"" % cb) missing_attrs = _check_attrs(cb) if missing_attrs: raise ValueError(""Periodic callback %r missing required"" "" attributes %s"" % (cb, missing_attrs)) with self._waiter: index = len(self._callables) self._callables.append((cb, args, kwargs)) if cb._periodic_run_immediately: self._immediates.append(index) else: self._schedule.push_next(cb, index) self._waiter.notify_all() def start(self, allow_none=False): :param allow_none: instead of running with no callbacks raise when it has no contained callables (this can be set to true and :py:meth:`.add` can be used to add new callables on demand) :type allow_none: bool if not self._callables and not allow_none:", def start(self): NOTE(harlowja): If this worker has no contained callables this raises a runtime error and does not run since it is impossible to periodically run nothing. if not self._callables:,24,5
openstack%2Fopenstack-ansible~kilo~I1415e5822684af12e1a1dd8a306e708e8931fa38,openstack/openstack-ansible,kilo,I1415e5822684af12e1a1dd8a306e708e8931fa38,Fix errors when enabling SSL for apache,MERGED,2015-06-24 17:45:46.000000000,2015-06-25 11:34:20.000000000,2015-06-25 11:34:17.000000000,"[{'_account_id': 3}, {'_account_id': 6816}, {'_account_id': 7219}, {'_account_id': 12000}]","[{'number': 1, 'created': '2015-06-24 17:45:46.000000000', 'files': ['playbooks/roles/os_keystone/templates/keystone-httpd.conf.j2', 'playbooks/roles/os_keystone/tasks/keystone_apache.yml'], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/12ec305d09a5dd4689b01d26d3ab417b7259d528', 'message': 'Fix errors when enabling SSL for apache\n\nkeystone_ssl_enabled is used to determine whether or not to configure\napache to use SSL. Currently when this variable is set to true the\napache SSL module is not enabled.\n\nThis commit adds a task to enable/disable the SSL module based on the\nvariable keystone_ssl_enabled.\n\nThe keystone-httpd.conf template causes a formatting error. This commit\nfixes the error so that additional whitespace is no longer added before\nSSLEngine.\n\nChange-Id: I1415e5822684af12e1a1dd8a306e708e8931fa38\nCloses-bug: #1466827\n(cherry picked from commit 042771fd0713885ba26193c7a0708fccf187a744)\n'}]",0,195227,12ec305d09a5dd4689b01d26d3ab417b7259d528,6,4,1,7353,,,0,"Fix errors when enabling SSL for apache

keystone_ssl_enabled is used to determine whether or not to configure
apache to use SSL. Currently when this variable is set to true the
apache SSL module is not enabled.

This commit adds a task to enable/disable the SSL module based on the
variable keystone_ssl_enabled.

The keystone-httpd.conf template causes a formatting error. This commit
fixes the error so that additional whitespace is no longer added before
SSLEngine.

Change-Id: I1415e5822684af12e1a1dd8a306e708e8931fa38
Closes-bug: #1466827
(cherry picked from commit 042771fd0713885ba26193c7a0708fccf187a744)
",git fetch https://review.opendev.org/openstack/openstack-ansible refs/changes/27/195227/1 && git format-patch -1 --stdout FETCH_HEAD,"['playbooks/roles/os_keystone/templates/keystone-httpd.conf.j2', 'playbooks/roles/os_keystone/tasks/keystone_apache.yml']",2,12ec305d09a5dd4689b01d26d3ab417b7259d528,," - name: Enable/disable mod_ssl for apache2 apache2_module: name: ssl state: ""{{ (keystone_ssl_enabled | bool) | ternary('present', 'absent') }}"" tags: - keystone-httpd",,9,2
openstack%2Fopenstack-ansible~kilo~I87164926a4d6a65d3c9f733d625a2d4af91c2597,openstack/openstack-ansible,kilo,I87164926a4d6a65d3c9f733d625a2d4af91c2597,Clear expired Django sessions regularly from DB,MERGED,2015-06-24 17:36:09.000000000,2015-06-25 11:34:11.000000000,2015-06-25 11:34:08.000000000,"[{'_account_id': 3}, {'_account_id': 6816}, {'_account_id': 12000}, {'_account_id': 12807}]","[{'number': 1, 'created': '2015-06-24 17:36:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/4f42fb67f477b9cce65e09d19b1165de8ae7b44e', 'message': 'Clear expired Django sessions regularly from DB\n\nA random minute in the 21st hour of Sunday UTC was chosen arbitrarily.\nThat it is run on a single arbitrary host from the set was done to\nprevent unnecessary work being done until Bug #1424705 provides us with\na cleaner solution.\n\nThe bug as filed seems to indicate that this is not something that\nneeds to be done daily in high-use environments so a standard of once\nper week was chosen. Making this configurable or tunable does not seem\nto be necessary at this time.\n\nChange-Id: I87164926a4d6a65d3c9f733d625a2d4af91c2597\nCloses-Bug: #1466126\n(cherry picked from commit aba8b5c92a24232770697093c1dc55de87266ccb)\n'}, {'number': 2, 'created': '2015-06-24 18:26:38.000000000', 'files': ['playbooks/roles/os_horizon/tasks/horizon_db_setup.yml'], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/36378c5547a4c39db98994db61af68ee433ff943', 'message': ""Clear expired Django sessions regularly from DB\n\nA random minute in the 21st hour UTC, daily, was chosen arbitrarily.\nThat it is run on a single arbitrary host from the set was done to\nprevent unnecessary work being done until Bug #1424705 provides us with\na cleaner solution.\n\nAdjusted to run once per day just to be sure that the operation doesn't\nlock the table for a meaningful duration.\n\nMaking this configurable or tunable does not seem\nto be necessary at this time.\n\nChange-Id: I87164926a4d6a65d3c9f733d625a2d4af91c2597\nCloses-Bug: #1466126\n(cherry picked from commit 4ab949672428fda396d1d6a28149252dabc5655d)\n""}]",0,195220,36378c5547a4c39db98994db61af68ee433ff943,8,4,2,7353,,,0,"Clear expired Django sessions regularly from DB

A random minute in the 21st hour UTC, daily, was chosen arbitrarily.
That it is run on a single arbitrary host from the set was done to
prevent unnecessary work being done until Bug #1424705 provides us with
a cleaner solution.

Adjusted to run once per day just to be sure that the operation doesn't
lock the table for a meaningful duration.

Making this configurable or tunable does not seem
to be necessary at this time.

Change-Id: I87164926a4d6a65d3c9f733d625a2d4af91c2597
Closes-Bug: #1466126
(cherry picked from commit 4ab949672428fda396d1d6a28149252dabc5655d)
",git fetch https://review.opendev.org/openstack/openstack-ansible refs/changes/20/195220/1 && git format-patch -1 --stdout FETCH_HEAD,['playbooks/roles/os_horizon/tasks/horizon_db_setup.yml'],1,4f42fb67f477b9cce65e09d19b1165de8ae7b44e,bug/1424705," - name: Register DB session cleanup cron cron: name: ""Clear out expired sessions"" minute: ""{{ 58 | random(start=2) }}"" weekday: 0 hour: 21 job: ""/usr/local/bin/horizon-manage.py clearsessions"" user: ""{{ horizon_system_user_name }}"" state: present tags: - horizon-db-setup",,12,0
openstack%2Fopenstack-ansible~kilo~I4854216726491f6ea4e265694e702f980fddc5a6,openstack/openstack-ansible,kilo,I4854216726491f6ea4e265694e702f980fddc5a6,Add global endpoint_type_proto options,MERGED,2015-06-24 17:51:25.000000000,2015-06-25 11:34:02.000000000,2015-06-25 11:33:59.000000000,"[{'_account_id': 3}, {'_account_id': 2799}, {'_account_id': 6816}, {'_account_id': 12000}, {'_account_id': 12807}]","[{'number': 1, 'created': '2015-06-24 17:51:25.000000000', 'files': ['playbooks/roles/os_swift/defaults/main.yml', 'playbooks/roles/os_neutron/defaults/main.yml', 'playbooks/roles/os_cinder/defaults/main.yml', 'playbooks/roles/os_heat/defaults/main.yml', 'playbooks/roles/os_glance/defaults/main.yml', 'etc/openstack_deploy/user_group_vars.yml', 'playbooks/roles/os_glance/templates/glance-api.conf.j2', 'playbooks/roles/os_nova/defaults/main.yml', 'playbooks/roles/os_keystone/defaults/main.yml'], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/7765181cfd1a94c935129b3680730904ec7201c8', 'message': 'Add global endpoint_type_proto options\n\nThis allows you to set the endpoint-type protocol globally for all\nservices, e.g. internaluri can be http, and publicuri can be https.\n\nYou will no longer have to specify it per service, although those\nsettings already exist and have not changed.\n\nThis patch changes no functionality for existing installs or deployments\nand the values are defaulted to be the same as before, but allows these\nvalues to be adjusted on a per-endpoint type basis.\n\nChange-Id: I4854216726491f6ea4e265694e702f980fddc5a6\nCloses-Bug: #1399383\n(cherry picked from commit 2b6b896105c7d4cd3b615432da3c084fcc2bf29b)\n'}]",0,195233,7765181cfd1a94c935129b3680730904ec7201c8,7,5,1,7353,,,0,"Add global endpoint_type_proto options

This allows you to set the endpoint-type protocol globally for all
services, e.g. internaluri can be http, and publicuri can be https.

You will no longer have to specify it per service, although those
settings already exist and have not changed.

This patch changes no functionality for existing installs or deployments
and the values are defaulted to be the same as before, but allows these
values to be adjusted on a per-endpoint type basis.

Change-Id: I4854216726491f6ea4e265694e702f980fddc5a6
Closes-Bug: #1399383
(cherry picked from commit 2b6b896105c7d4cd3b615432da3c084fcc2bf29b)
",git fetch https://review.opendev.org/openstack/openstack-ansible refs/changes/33/195233/1 && git format-patch -1 --stdout FETCH_HEAD,"['playbooks/roles/os_swift/defaults/main.yml', 'playbooks/roles/os_neutron/defaults/main.yml', 'playbooks/roles/os_cinder/defaults/main.yml', 'playbooks/roles/os_heat/defaults/main.yml', 'etc/openstack_deploy/user_group_vars.yml', 'playbooks/roles/os_glance/defaults/main.yml', 'playbooks/roles/os_glance/templates/glance-api.conf.j2', 'playbooks/roles/os_nova/defaults/main.yml', 'playbooks/roles/os_keystone/defaults/main.yml']",9,7765181cfd1a94c935129b3680730904ec7201c8,,"keystone_service_publicuri_proto: ""{{ openstack_service_publicuri_proto | default(keystone_service_proto) }}"" keystone_service_adminuri_proto: ""{{ openstack_service_adminuri_proto | default(keystone_service_proto) }}"" keystone_service_internaluri_proto: ""{{ openstack_service_internaluri_proto | default(keystone_service_proto) }}""","keystone_service_publicuri_proto: ""{{ keystone_service_proto }}"" keystone_service_adminuri_proto: ""{{ keystone_service_proto }}"" keystone_service_internaluri_proto: ""{{ keystone_service_proto }}""",56,47
openstack%2Fopenstack-ansible~kilo~I2dfe3c9a9bf1c51c1f2530fc895ef3f4ba1f56c6,openstack/openstack-ansible,kilo,I2dfe3c9a9bf1c51c1f2530fc895ef3f4ba1f56c6,Rename group rpc to openstack,MERGED,2015-06-24 17:47:10.000000000,2015-06-25 11:33:53.000000000,2015-06-25 11:33:52.000000000,"[{'_account_id': 3}, {'_account_id': 6816}, {'_account_id': 12000}, {'_account_id': 12807}, {'_account_id': 16965}]","[{'number': 1, 'created': '2015-06-24 17:47:10.000000000', 'files': ['playbooks/roles/lxc_hosts/templates/lxc-openstack.conf.j2'], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/c0aea88168ff72d2dc947628e0fa39fccf622124', 'message': 'Rename group rpc to openstack\n\nRenamed the lxc group rpc to openstack to remove leftover rpc variable.\n\nCloses-Bug #1457609\n\nChange-Id: I2dfe3c9a9bf1c51c1f2530fc895ef3f4ba1f56c6\n(cherry picked from commit 1de9e33414834533727b5ddcfbd06b8182fb0778)\n'}]",0,195230,c0aea88168ff72d2dc947628e0fa39fccf622124,7,5,1,7353,,,0,"Rename group rpc to openstack

Renamed the lxc group rpc to openstack to remove leftover rpc variable.

Closes-Bug #1457609

Change-Id: I2dfe3c9a9bf1c51c1f2530fc895ef3f4ba1f56c6
(cherry picked from commit 1de9e33414834533727b5ddcfbd06b8182fb0778)
",git fetch https://review.opendev.org/openstack/openstack-ansible refs/changes/30/195230/1 && git format-patch -1 --stdout FETCH_HEAD,['playbooks/roles/lxc_hosts/templates/lxc-openstack.conf.j2'],1,c0aea88168ff72d2dc947628e0fa39fccf622124,,lxc.group = openstack,lxc.group = rpc,1,1
openstack%2Ffuel-web~master~I5ddd5e9027b9f06f4d493e1b70cabf27518406b1,openstack/fuel-web,master,I5ddd5e9027b9f06f4d493e1b70cabf27518406b1,Move volume manager into extensions directory,MERGED,2015-06-24 14:02:19.000000000,2015-06-25 11:32:48.000000000,2015-06-25 11:18:45.000000000,"[{'_account_id': 3}, {'_account_id': 3009}, {'_account_id': 8749}, {'_account_id': 8907}, {'_account_id': 8971}, {'_account_id': 12200}]","[{'number': 1, 'created': '2015-06-24 14:02:19.000000000', 'files': ['nailgun/nailgun/extensions/__init__.py', 'nailgun/nailgun/orchestrator/deployment_serializers.py', 'nailgun/nailgun/extensions/volume_manager/manager.py', 'nailgun/nailgun/test/unit/test_node_disks.py', 'nailgun/nailgun/test/integration/test_cluster_changes_handler.py', 'nailgun/nailgun/test/unit/test_task.py', 'nailgun/nailgun/test/integration/test_volume_manager.py', 'nailgun/nailgun/extensions/volume_manager/__init__.py', 'nailgun/nailgun/db/sqlalchemy/models/node.py', 'nailgun/nailgun/test/integration/test_orchestrator_serializer.py', 'nailgun/nailgun/api/v1/handlers/disks.py'], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/9ecd2645d8080f29e1b98403e0dcfc8ac3271a72', 'message': ""Move volume manager into extensions directory\n\nIt's a first step of extracting volume manager\nfrom the core and its refactoring.\n\nImplements blueprint: volume-manager-refactoring\n\nChange-Id: I5ddd5e9027b9f06f4d493e1b70cabf27518406b1\n""}]",0,195092,9ecd2645d8080f29e1b98403e0dcfc8ac3271a72,14,6,1,8749,,,0,"Move volume manager into extensions directory

It's a first step of extracting volume manager
from the core and its refactoring.

Implements blueprint: volume-manager-refactoring

Change-Id: I5ddd5e9027b9f06f4d493e1b70cabf27518406b1
",git fetch https://review.opendev.org/openstack/fuel-web refs/changes/92/195092/1 && git format-patch -1 --stdout FETCH_HEAD,"['nailgun/nailgun/extensions/__init__.py', 'nailgun/nailgun/extensions/volume_manager/manager.py', 'nailgun/nailgun/orchestrator/deployment_serializers.py', 'nailgun/nailgun/test/unit/test_node_disks.py', 'nailgun/nailgun/test/integration/test_cluster_changes_handler.py', 'nailgun/nailgun/test/unit/test_task.py', 'nailgun/nailgun/test/integration/test_volume_manager.py', 'nailgun/nailgun/db/sqlalchemy/models/node.py', 'nailgun/nailgun/extensions/volume_manager/__init__.py', 'nailgun/nailgun/test/integration/test_orchestrator_serializer.py', 'nailgun/nailgun/api/v1/handlers/disks.py']",11,9ecd2645d8080f29e1b98403e0dcfc8ac3271a72,bp/volume-manager-refactoring,from nailgun.extensions.volume_manager.manager import DisksFormatConvertor,from nailgun.volumes.manager import DisksFormatConvertor,11,11
openstack%2Fsenlin~master~I60eecdb9320b7238a27de47e2ad57dd74cb49629,openstack/senlin,master,I60eecdb9320b7238a27de47e2ad57dd74cb49629,Add pool_member related interfaces to neutron v2 driver,MERGED,2015-06-04 07:11:00.000000000,2015-06-25 11:24:13.000000000,2015-06-25 11:24:09.000000000,"[{'_account_id': 3}, {'_account_id': 8246}, {'_account_id': 11034}]","[{'number': 1, 'created': '2015-06-04 07:11:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/senlin/commit/d77eee7d584df65be096966f7408251ec2847fd1', 'message': 'Add pool_member related interfaces to neutron v2 driver\n\nThis patch added lbaas pool_member related interfaces to neutron v2\ndriver.\n\nChange-Id: I60eecdb9320b7238a27de47e2ad57dd74cb49629\n'}, {'number': 2, 'created': '2015-06-08 06:26:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/senlin/commit/40cd899b1a84789ecb3a819a74b1986329a043d6', 'message': 'Add pool_member related interfaces to neutron v2 driver\n\nThis patch added lbaas pool_member related interfaces to neutron v2\ndriver.\n\nChange-Id: I60eecdb9320b7238a27de47e2ad57dd74cb49629\n'}, {'number': 3, 'created': '2015-06-09 04:51:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/senlin/commit/78194cfaf5345567f4bc00da1b34e7834870351b', 'message': 'Add pool_member related interfaces to neutron v2 driver\n\nThis patch added lbaas pool_member related interfaces to neutron v2\ndriver.\n\nChange-Id: I60eecdb9320b7238a27de47e2ad57dd74cb49629\n'}, {'number': 4, 'created': '2015-06-09 09:42:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/senlin/commit/37553e4af4a7a93686f7561696e3b00d62e62b20', 'message': 'Add pool_member related interfaces to neutron v2 driver\n\nThis patch added lbaas pool_member related interfaces to neutron v2\ndriver.\n\nChange-Id: I60eecdb9320b7238a27de47e2ad57dd74cb49629\n'}, {'number': 5, 'created': '2015-06-11 04:35:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/senlin/commit/21757c43d85ac8d37c524824e930b749f8194eb1', 'message': 'Add pool_member related interfaces to neutron v2 driver\n\nThis patch added lbaas pool_member related interfaces to neutron v2\ndriver.\n\nChange-Id: I60eecdb9320b7238a27de47e2ad57dd74cb49629\n'}, {'number': 6, 'created': '2015-06-18 07:24:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/senlin/commit/f68156a05c1f3e30c91bb27d9a8b85aadc4b7a19', 'message': 'Add pool_member related interfaces to neutron v2 driver\n\nThis patch added lbaas pool_member related interfaces to neutron v2\ndriver.\n\nChange-Id: I60eecdb9320b7238a27de47e2ad57dd74cb49629\n'}, {'number': 7, 'created': '2015-06-23 09:01:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/senlin/commit/1e972d7c37503c458b3caefc56a2f1ed4f471e87', 'message': 'Add pool_member related interfaces to neutron v2 driver\n\nThis patch added lbaas pool_member related interfaces to neutron v2\ndriver.\n\nChange-Id: I60eecdb9320b7238a27de47e2ad57dd74cb49629\n'}, {'number': 8, 'created': '2015-06-25 08:42:30.000000000', 'files': ['senlin/drivers/openstack/neutron_v2.py'], 'web_link': 'https://opendev.org/openstack/senlin/commit/09b39d12da567c88c2ced6ff57f291a21e4cd568', 'message': 'Add pool_member related interfaces to neutron v2 driver\n\nThis patch added lbaas pool_member related interfaces to neutron v2\ndriver.\n\nChange-Id: I60eecdb9320b7238a27de47e2ad57dd74cb49629\n'}]",0,188282,09b39d12da567c88c2ced6ff57f291a21e4cd568,27,3,8,11034,,,0,"Add pool_member related interfaces to neutron v2 driver

This patch added lbaas pool_member related interfaces to neutron v2
driver.

Change-Id: I60eecdb9320b7238a27de47e2ad57dd74cb49629
",git fetch https://review.opendev.org/openstack/senlin refs/changes/82/188282/8 && git format-patch -1 --stdout FETCH_HEAD,['senlin/drivers/openstack/neutron_v2.py'],1,d77eee7d584df65be096966f7408251ec2847fd1,lb-policy," def pool_member_get(self, pool_id, member_identity): try: member = self.conn.network.find_pool_member(member_identity, pool_id) except sdk.exc.HttpException as ex: msg = _('Failed in getting lb pool_member %(value)s: %(ex)s' ) % {'value': member_identity, 'ex': six.text_type(ex)} raise exception.Error(msg=msg) return member def pool_member_list(self, pool_id): try: members = [m for m in self.conn.network.pool_members(pool_id)] except sdk.exc.HttpException as ex: msg = _('Failed in listing lb members of pool %(id)s: %(ex)s' ) % {'id': pool_id, 'ex': six.text_type(ex)} raise exception.Error(msg=msg) return members def pool_member_create(self, pool_id, address, protocol_port, subnet_id, weight=None, admin_state_up=True): kwargs = { 'pool_id': pool_id, 'address': address, 'protocol_port': protocol_port, 'admin_state_up': admin_state_up, 'subnet_id': subnet_id, } if weight is not None: kwargs['weight'] = weight try: res = self.conn.network.create_pool_member(**kwargs) except sdk.exc.HttpException as ex: msg = _('Failed in adding member to lb pool %(id)s: %(ex)s' ) % {'id': pool_id, 'ex': six.text_type(ex)} raise exception.Error(msg=msg) return res def pool_member_delete(self, pool_id, member_id): try: self.conn.network.delete_pool_member(member_id, pool_id) except sdk.exc.HttpException as ex: msg = _('Failed in deleting lb member %(id)s from pool %(pool)s: ' '%(ex)s') % {'id': member_id, 'pool': pool_id, 'ex': six.text_type(ex)} raise exception.Error(msg=msg) return ",,55,0
openstack%2Ffuel-qa~master~I4677d635198f5c12eb7e77df1d3953eea02e651f,openstack/fuel-qa,master,I4677d635198f5c12eb7e77df1d3953eea02e651f,Add test upgrade_fuel_after_rollback,MERGED,2015-06-24 13:00:19.000000000,2015-06-25 11:23:03.000000000,2015-06-25 11:19:05.000000000,"[{'_account_id': 3}, {'_account_id': 8971}, {'_account_id': 10068}, {'_account_id': 10136}, {'_account_id': 12867}, {'_account_id': 14057}, {'_account_id': 15943}]","[{'number': 1, 'created': '2015-06-24 13:00:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-qa/commit/2d654e86ccac52491ac2f6cea5ea41d842b3be03', 'message': 'Add test upgrade_fuel_after_rollback\n\nScenario:\n            1. Revert deploy_neutron_gre snapshot\n            2. Upgrade with rollback\n            3. Run OSTF\n            4. Run network verification\n            5. Upgrade fuel master\n            6. Check upgrading was successful\n            7. Deploy 6.1 cluster with 3 nodes and all default settings\n            8. Run OSTF for new cluster\n\nImplements: [System tests] Need to add case to upgrade fuel after rollback\nCloses-Bug: 1467062\n\nChange-Id: I4677d635198f5c12eb7e77df1d3953eea02e651f\n'}, {'number': 2, 'created': '2015-06-24 16:56:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-qa/commit/820c5549db047acb0312d765ff22b4bfe3857041', 'message': 'Add test upgrade_fuel_after_rollback\n\nScenario:\n            1. Revert deploy_neutron_gre snapshot\n            2. Upgrade with rollback\n            3. Run OSTF\n            4. Run network verification\n            5. Upgrade fuel master\n            6. Check upgrading was successful\n            7. Deploy 6.1 cluster with 3 nodes and all default settings\n            8. Run OSTF for new cluster\n\nImplements: [System tests] Need to add case to upgrade fuel after rollback\nCloses-Bug: 1467062\n\nChange-Id: I4677d635198f5c12eb7e77df1d3953eea02e651f\n'}, {'number': 3, 'created': '2015-06-25 09:55:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-qa/commit/7f595598f21f7d785fdae02c62065d2913caabf1', 'message': 'Add test upgrade_fuel_after_rollback\n\nScenario:\n            1. Revert deploy_neutron_gre snapshot\n            2. Upgrade with rollback\n            3. Run OSTF\n            4. Run network verification\n            5. Upgrade fuel master\n            6. Check upgrading was successful\n            7. Deploy 6.1 cluster with 3 nodes and all default settings\n            8. Run OSTF for new cluster\n\nImplements: [System tests] Need to add case to upgrade fuel after rollback\nCloses-Bug: 1467062\n\nChange-Id: I4677d635198f5c12eb7e77df1d3953eea02e651f\n'}, {'number': 4, 'created': '2015-06-25 10:46:44.000000000', 'files': ['fuelweb_test/tests/test_upgrade.py'], 'web_link': 'https://opendev.org/openstack/fuel-qa/commit/1a39511a9ef0ace3973dcffb4e7625e2cfef5f38', 'message': 'Add test upgrade_fuel_after_rollback\n\nScenario:\n            1. Revert deploy_neutron_gre snapshot\n            2. Upgrade with rollback\n            3. Run OSTF\n            4. Run network verification\n            5. Upgrade fuel master\n            6. Check upgrading was successful\n            7. Deploy 6.1 cluster with 3 nodes and all default settings\n            8. Run OSTF for new cluster\n\nImplements: [System tests] Need to add case to upgrade fuel after rollback\nCloses-Bug: 1467062\n\nChange-Id: I4677d635198f5c12eb7e77df1d3953eea02e651f\n'}]",24,195066,1a39511a9ef0ace3973dcffb4e7625e2cfef5f38,42,7,4,15943,,,0,"Add test upgrade_fuel_after_rollback

Scenario:
            1. Revert deploy_neutron_gre snapshot
            2. Upgrade with rollback
            3. Run OSTF
            4. Run network verification
            5. Upgrade fuel master
            6. Check upgrading was successful
            7. Deploy 6.1 cluster with 3 nodes and all default settings
            8. Run OSTF for new cluster

Implements: [System tests] Need to add case to upgrade fuel after rollback
Closes-Bug: 1467062

Change-Id: I4677d635198f5c12eb7e77df1d3953eea02e651f
",git fetch https://review.opendev.org/openstack/fuel-qa refs/changes/66/195066/1 && git format-patch -1 --stdout FETCH_HEAD,['fuelweb_test/tests/test_upgrade.py'],1,2d654e86ccac52491ac2f6cea5ea41d842b3be03,bug/1467062," @test(groups=[""upgrade_fuel_after_rollback""]) @log_snapshot_after_test def upgrade_fuel_after_rollback(self): """""" Scenario: 1. Revert deploy_neutron_gre snapshot 2. Upgrade with rollback 3. Run OSTF 4. Run network verification 5. Upgrade fuel master 6. Check upgrading was successful 7. Deploy 6.1 cluster with 3 nodes and all default settings 8. Run OSTF for new cluster """""" if not self.env.d_env.has_snapshot('deploy_neutron_gre'): raise SkipTest() self.env.revert_snapshot(""deploy_neutron_gre"") cluster_id = self.fuel_web.get_last_created_cluster() checkers.upload_tarball(self.env.d_env.get_admin_remote(), hlp_data.TARBALL_PATH, '/var') checkers.check_tarball_exists(self.env.d_env.get_admin_remote(), os.path.basename(hlp_data. TARBALL_PATH), '/var') checkers.untar(self.env.d_env.get_admin_remote(), os.path.basename(hlp_data. TARBALL_PATH), '/var') # Upgrade with rollback checkers.run_script(self.env.d_env.get_admin_remote(), '/var', 'upgrade.sh', password=hlp_data.KEYSTONE_CREDS['password'], rollback=True, exit_code=255) checkers.wait_rollback_is_done(self.env.d_env.get_admin_remote(), 3000) checkers.check_upgraded_containers(self.env.d_env.get_admin_remote(), hlp_data.UPGRADE_FUEL_TO, hlp_data.UPGRADE_FUEL_FROM) logger.debug(""all containers are ok"") _wait(lambda: self.fuel_web.get_nailgun_node_by_devops_node( self.env.d_env.nodes().slaves[0]), timeout=8 * 60) logger.debug(""all services are up now"") self.fuel_web.wait_nodes_get_online_state( self.env.d_env.nodes().slaves[:3]) self.fuel_web.assert_nodes_in_ready_state(cluster_id) self.fuel_web.assert_fuel_version(hlp_data.UPGRADE_FUEL_FROM) self.fuel_web.verify_network(cluster_id) self.fuel_web.run_ostf(cluster_id) # Upgrade fuel master checkers.run_script(self.env.d_env.get_admin_remote(), '/var', 'upgrade.sh', password=hlp_data.KEYSTONE_CREDS['password']) checkers.wait_upgrade_is_done(self.env.d_env.get_admin_remote(), 3000, phrase='*** UPGRADING MASTER NODE' ' DONE SUCCESSFULLY') checkers.check_upgraded_containers(self.env.d_env.get_admin_remote(), hlp_data.UPGRADE_FUEL_FROM, hlp_data.UPGRADE_FUEL_TO) self.fuel_web.assert_fuel_version(hlp_data.UPGRADE_FUEL_TO) self.fuel_web.assert_nodes_in_ready_state(cluster_id) self.fuel_web.wait_nodes_get_online_state( self.env.d_env.nodes().slaves[:3]) self.fuel_web.assert_nailgun_upgrade_migration() # Deploy new cluster self.env.bootstrap_nodes( self.env.d_env.nodes().slaves[3:6]) new_cluster_id = self.fuel_web.create_cluster( name=self.__class__.__name__, ) self.fuel_web.update_nodes( new_cluster_id, { 'slave-04': ['controller'], 'slave-05': ['compute'], 'slave-06': ['compute'] } ) self.fuel_web.run_network_verify(new_cluster_id) self.fuel_web.deploy_cluster_wait(new_cluster_id) self.fuel_web.run_ostf(new_cluster_id) self.env.make_snapshot(""upgrade_fuel_after_rollback"")",,86,0
openstack%2Fmagnum~master~I9c1f01e780aa4bd53e8d4465ff1d88498b614f78,openstack/magnum,master,I9c1f01e780aa4bd53e8d4465ff1d88498b614f78,[Work in Progress] Switch on concurrency to 1 for functional tests,ABANDONED,2015-06-25 10:11:47.000000000,2015-06-25 11:20:30.000000000,,[{'_account_id': 3}],"[{'number': 1, 'created': '2015-06-25 10:11:47.000000000', 'files': ['magnum/tests/contrib/post_test_hook.sh', '.testr.conf'], 'web_link': 'https://opendev.org/openstack/magnum/commit/8b559822914687441117696f637b4c4bac1d2cd4', 'message': '[Work in Progress] Switch on concurrency to 1 for functional tests\n\nChange-Id: I9c1f01e780aa4bd53e8d4465ff1d88498b614f78\n'}]",0,195499,8b559822914687441117696f637b4c4bac1d2cd4,3,1,1,5638,,,0,"[Work in Progress] Switch on concurrency to 1 for functional tests

Change-Id: I9c1f01e780aa4bd53e8d4465ff1d88498b614f78
",git fetch https://review.opendev.org/openstack/magnum refs/changes/99/195499/1 && git format-patch -1 --stdout FETCH_HEAD,"['magnum/tests/contrib/post_test_hook.sh', '.testr.conf']",2,8b559822914687441117696f637b4c4bac1d2cd4,," # NOTE(dims): If single-worker mode is wanted (e.g. for live tests) # the environment variable ``TEST_RUN_CONCURRENCY`` should be set to ``1``. If # a non-default (1 worker per available core) concurrency is desired, set # environment variable ``TEST_RUN_CONCURRENCY`` to the desired number of # workers. test_run_concurrency=echo ${TEST_RUN_CONCURRENCY:-0}",,8,1
openstack%2Fopenstack-ansible~master~I87164926a4d6a65d3c9f733d625a2d4af91c2597,openstack/openstack-ansible,master,I87164926a4d6a65d3c9f733d625a2d4af91c2597,Clear expired Django sessions regularly from DB,MERGED,2015-06-24 02:13:39.000000000,2015-06-25 11:20:04.000000000,2015-06-25 11:20:04.000000000,"[{'_account_id': 3}, {'_account_id': 6816}, {'_account_id': 7219}, {'_account_id': 7353}, {'_account_id': 12000}, {'_account_id': 12807}, {'_account_id': 14552}]","[{'number': 1, 'created': '2015-06-24 02:13:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/aba8b5c92a24232770697093c1dc55de87266ccb', 'message': 'Clear expired Django sessions regularly from DB\n\nA random minute in the 21st hour of Sunday UTC was chosen arbitrarily.\nThat it is run on a single arbitrary host from the set was done to\nprevent unnecessary work being done until Bug #1424705 provides us with\na cleaner solution.\n\nThe bug as filed seems to indicate that this is not something that\nneeds to be done daily in high-use environments so a standard of once\nper week was chosen. Making this configurable or tunable does not seem\nto be necessary at this time.\n\nChange-Id: I87164926a4d6a65d3c9f733d625a2d4af91c2597\nCloses-Bug: #1466126\n'}, {'number': 2, 'created': '2015-06-24 18:18:29.000000000', 'files': ['playbooks/roles/os_horizon/tasks/horizon_db_setup.yml'], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/4ab949672428fda396d1d6a28149252dabc5655d', 'message': ""Clear expired Django sessions regularly from DB\n\nA random minute in the 21st hour UTC, daily, was chosen arbitrarily.\nThat it is run on a single arbitrary host from the set was done to\nprevent unnecessary work being done until Bug #1424705 provides us with\na cleaner solution.\n\nAdjusted to run once per day just to be sure that the operation doesn't\nlock the table for a meaningful duration.\n\nMaking this configurable or tunable does not seem\nto be necessary at this time.\n\nChange-Id: I87164926a4d6a65d3c9f733d625a2d4af91c2597\nCloses-Bug: #1466126\n""}]",2,194910,4ab949672428fda396d1d6a28149252dabc5655d,19,7,2,12807,,,0,"Clear expired Django sessions regularly from DB

A random minute in the 21st hour UTC, daily, was chosen arbitrarily.
That it is run on a single arbitrary host from the set was done to
prevent unnecessary work being done until Bug #1424705 provides us with
a cleaner solution.

Adjusted to run once per day just to be sure that the operation doesn't
lock the table for a meaningful duration.

Making this configurable or tunable does not seem
to be necessary at this time.

Change-Id: I87164926a4d6a65d3c9f733d625a2d4af91c2597
Closes-Bug: #1466126
",git fetch https://review.opendev.org/openstack/openstack-ansible refs/changes/10/194910/1 && git format-patch -1 --stdout FETCH_HEAD,['playbooks/roles/os_horizon/tasks/horizon_db_setup.yml'],1,aba8b5c92a24232770697093c1dc55de87266ccb,bug/1424705," - name: Register DB session cleanup cron cron: name: ""Clear out expired sessions"" minute: ""{{ 58 | random(start=2) }}"" weekday: 0 hour: 21 job: ""/usr/local/bin/horizon-manage.py clearsessions"" user: ""{{ horizon_system_user_name }}"" state: present tags: - horizon-db-setup",,12,0
openstack%2Fmistral~master~I929c6b9f93c399e6022a1e8f04975230d5c7ab04,openstack/mistral,master,I929c6b9f93c399e6022a1e8f04975230d5c7ab04,Fixing devstack gate failure,MERGED,2015-06-25 10:22:04.000000000,2015-06-25 11:18:38.000000000,2015-06-25 11:18:37.000000000,"[{'_account_id': 3}, {'_account_id': 6732}, {'_account_id': 8731}]","[{'number': 1, 'created': '2015-06-25 10:22:04.000000000', 'files': ['mistral/engine/default_engine.py'], 'web_link': 'https://opendev.org/openstack/mistral/commit/8eab749392d1466e83732f929b7c044218c92f6f', 'message': ""Fixing devstack gate failure\n\n * Failure caused by engine returning a real object\n   instead of its clone in 'start_action'. That's\n   why 'output' field didn't load correctly.\n\nChange-Id: I929c6b9f93c399e6022a1e8f04975230d5c7ab04\n""}]",0,195501,8eab749392d1466e83732f929b7c044218c92f6f,7,3,1,7700,,,0,"Fixing devstack gate failure

 * Failure caused by engine returning a real object
   instead of its clone in 'start_action'. That's
   why 'output' field didn't load correctly.

Change-Id: I929c6b9f93c399e6022a1e8f04975230d5c7ab04
",git fetch https://review.opendev.org/openstack/mistral refs/changes/01/195501/1 && git format-patch -1 --stdout FETCH_HEAD,['mistral/engine/default_engine.py'],1,8eab749392d1466e83732f929b7c044218c92f6f,run_action, return action_ex.get_clone(), return action_ex,1,1
openstack%2Fcinder~master~Ifcaaf365aaab24c6fa2a6eca58f546860124f1fc,openstack/cinder,master,Ifcaaf365aaab24c6fa2a6eca58f546860124f1fc,Disable profiler for unit tests,MERGED,2015-06-18 17:17:01.000000000,2015-06-25 11:15:03.000000000,2015-06-18 22:52:13.000000000,"[{'_account_id': 3}, {'_account_id': 1736}, {'_account_id': 2759}, {'_account_id': 4523}, {'_account_id': 6172}, {'_account_id': 8247}, {'_account_id': 8871}, {'_account_id': 9003}, {'_account_id': 9008}, {'_account_id': 9535}, {'_account_id': 9751}, {'_account_id': 10621}, {'_account_id': 10622}, {'_account_id': 11811}, {'_account_id': 12017}, {'_account_id': 12202}, {'_account_id': 12249}, {'_account_id': 12369}, {'_account_id': 12778}, {'_account_id': 13144}, {'_account_id': 13394}, {'_account_id': 13636}, {'_account_id': 14587}, {'_account_id': 14797}, {'_account_id': 15239}, {'_account_id': 15249}, {'_account_id': 15374}, {'_account_id': 15386}, {'_account_id': 15670}, {'_account_id': 15764}, {'_account_id': 15941}, {'_account_id': 16160}, {'_account_id': 16269}, {'_account_id': 16422}, {'_account_id': 16595}, {'_account_id': 16660}, {'_account_id': 16880}, {'_account_id': 16897}]","[{'number': 1, 'created': '2015-06-18 17:17:01.000000000', 'files': ['cinder/test.py', 'cinder/tests/unit/test_backup.py'], 'web_link': 'https://opendev.org/openstack/cinder/commit/6cf63195fa5f0490746a89c65a42a379ced68d47', 'message': 'Disable profiler for unit tests\n\nosprofiler should not run for unit tests.  This makes stack\ntraces harder to debug, and generally complicates things, with\nno benefit.\n\nThe backup tests were already doing this, so port that\nmethod to the base Cinder test class.\n\nCloses-Bug: #1394785\nCloses-Bug: #1447400\n\nChange-Id: Ifcaaf365aaab24c6fa2a6eca58f546860124f1fc\n'}]",1,193222,6cf63195fa5f0490746a89c65a42a379ced68d47,49,38,1,4523,,,0,"Disable profiler for unit tests

osprofiler should not run for unit tests.  This makes stack
traces harder to debug, and generally complicates things, with
no benefit.

The backup tests were already doing this, so port that
method to the base Cinder test class.

Closes-Bug: #1394785
Closes-Bug: #1447400

Change-Id: Ifcaaf365aaab24c6fa2a6eca58f546860124f1fc
",git fetch https://review.opendev.org/openstack/cinder refs/changes/22/193222/1 && git format-patch -1 --stdout FETCH_HEAD,"['cinder/test.py', 'cinder/tests/unit/test_backup.py']",2,6cf63195fa5f0490746a89c65a42a379ced68d47,bug/1394785, self.backup_mgr = importutils.import_object(CONF.backup_manager)," with mock.patch(""osprofiler.profiler.trace_cls"") as mock_trace_cls: side_effect = lambda value: value mock_decorator = mock.MagicMock(side_effect=side_effect) mock_trace_cls.return_value = mock_decorator self.backup_mgr = \ importutils.import_object(CONF.backup_manager)",15,6
openstack%2Fironic~master~Ib986963bdc920b32a3d750b3f3a4b093152b5010,openstack/ironic,master,Ib986963bdc920b32a3d750b3f3a4b093152b5010,Add ENROLL and related states to the state machine,MERGED,2015-06-16 15:51:52.000000000,2015-06-25 11:09:12.000000000,2015-06-25 11:09:09.000000000,"[{'_account_id': 3}, {'_account_id': 6618}, {'_account_id': 9315}, {'_account_id': 10239}]","[{'number': 1, 'created': '2015-06-16 15:51:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/1b32da01cb0af59b85e72e2f701c881d9e74e4c8', 'message': 'Add ENROLL and related states to the state machine\n\nChange-Id: Ib986963bdc920b32a3d750b3f3a4b093152b5010\nImplements: blueprint enroll-node-state\n'}, {'number': 2, 'created': '2015-06-23 15:21:18.000000000', 'files': ['ironic/common/states.py'], 'web_link': 'https://opendev.org/openstack/ironic/commit/5db8c25f6d74141245d23e3445466401b431e368', 'message': 'Add ENROLL and related states to the state machine\n\nChange-Id: Ib986963bdc920b32a3d750b3f3a4b093152b5010\nImplements: blueprint enroll-node-state\n'}]",6,192269,5db8c25f6d74141245d23e3445466401b431e368,13,4,2,10239,,,0,"Add ENROLL and related states to the state machine

Change-Id: Ib986963bdc920b32a3d750b3f3a4b093152b5010
Implements: blueprint enroll-node-state
",git fetch https://review.opendev.org/openstack/ironic refs/changes/69/192269/2 && git format-patch -1 --stdout FETCH_HEAD,['ironic/common/states.py'],1,1b32da01cb0af59b85e72e2f701c881d9e74e4c8,bp/enroll-node-state,"ENROLL = 'enroll' """""" Node is just enrolled. This state indicates that Ironic is aware of a node, but is not managing yet. Node should be transitioned to MANAGEABLE before Ironic starts working with it. """""" VERIFYING = 'verifying' """""" Node power management credentials are being verified. """""" machine.add_state(ENROLL, stable=True, **watchers)machine.add_state(VERIFYING, target=MANAGEABLE, **watchers) # Start power credentials verification machine.add_transition(ENROLL, VERIFYING, 'manage') # Verification can succeed machine.add_transition(VERIFYING, MANAGEABLE, 'done') # Verification can fail with setting last_error and rolling back to ENROLL machine.add_transition(VERIFYING, ENROLL, 'fail')",,23,0
openstack%2Fopenstack-ansible~kilo~I95b456672f419fcc331d6739ce259b022d350472,openstack/openstack-ansible,kilo,I95b456672f419fcc331d6739ce259b022d350472,Add read/write_affinity settings for Swift,MERGED,2015-06-24 17:52:18.000000000,2015-06-25 11:08:04.000000000,2015-06-25 11:08:01.000000000,"[{'_account_id': 3}, {'_account_id': 2799}, {'_account_id': 6816}, {'_account_id': 12000}, {'_account_id': 12807}]","[{'number': 1, 'created': '2015-06-24 17:52:18.000000000', 'files': ['etc/openstack_deploy/conf.d/swift.yml.example', 'playbooks/roles/os_swift/templates/proxy-server.conf.j2', 'etc/openstack_deploy/conf.d/swift.yml.aio'], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/c1634b2e328af1bd5c535d750bd60d09d649d3c0', 'message': ""Add read/write_affinity settings for Swift\n\nAllow the setting of read/write_affinity and write_affinity_node_count\non a per proxy_host basis.\n\nThis allows the deployer to set preferences for which region to\nread/write to, which can increase the efficiency of a multi-region\nswift cluster.\n\nSample swift.yml has been updated, as well as the aio swift.yml to\nensure these settings are setup as part of the gate, but this shouldn't\nchange the functionality of swift at all (since there is only 1 region).\n\nChange-Id: I95b456672f419fcc331d6739ce259b022d350472\nCloses-Bug: #1415172\n(cherry picked from commit 5b9b49f52b12052f93c72f44a31a972f2e98620c)\n""}]",0,195234,c1634b2e328af1bd5c535d750bd60d09d649d3c0,7,5,1,7353,,,0,"Add read/write_affinity settings for Swift

Allow the setting of read/write_affinity and write_affinity_node_count
on a per proxy_host basis.

This allows the deployer to set preferences for which region to
read/write to, which can increase the efficiency of a multi-region
swift cluster.

Sample swift.yml has been updated, as well as the aio swift.yml to
ensure these settings are setup as part of the gate, but this shouldn't
change the functionality of swift at all (since there is only 1 region).

Change-Id: I95b456672f419fcc331d6739ce259b022d350472
Closes-Bug: #1415172
(cherry picked from commit 5b9b49f52b12052f93c72f44a31a972f2e98620c)
",git fetch https://review.opendev.org/openstack/openstack-ansible refs/changes/34/195234/1 && git format-patch -1 --stdout FETCH_HEAD,"['etc/openstack_deploy/conf.d/swift.yml.example', 'playbooks/roles/os_swift/templates/proxy-server.conf.j2', 'etc/openstack_deploy/conf.d/swift.yml.aio']",3,c1634b2e328af1bd5c535d750bd60d09d649d3c0,," container_vars: swift_proxy_vars: read_affinity: ""r1=100"" write_affinity: ""r1"" write_affinity_node_count: ""1 * replicas"" container_vars: swift_vars: zone: 0 region: 1",,63,0
openstack%2Fopenstack-ansible~kilo~Iec55db3b6e20b3661459c639e2a48ff755c001ef,openstack/openstack-ansible,kilo,Iec55db3b6e20b3661459c639e2a48ff755c001ef,Remove the adiscon/v8 ppa,MERGED,2015-06-24 17:46:23.000000000,2015-06-25 11:07:06.000000000,2015-06-25 11:07:04.000000000,"[{'_account_id': 3}, {'_account_id': 6816}, {'_account_id': 12000}, {'_account_id': 12807}]","[{'number': 1, 'created': '2015-06-24 17:46:23.000000000', 'files': ['playbooks/roles/rsyslog_client/defaults/main.yml', 'playbooks/roles/rsyslog_client/tasks/rsyslog_client_install.yml', 'playbooks/roles/rsyslog_server/defaults/main.yml', 'playbooks/roles/rsyslog_server/tasks/rsyslog_server_install.yml'], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/824ca03fef07e0dd898471bbec9799a22d74f385', 'message': 'Remove the adiscon/v8 ppa\n\nThe adiscon/v8 ppa has has occasional availability issues which\nhave resulted in failed deployments. This ppa can be removed\nwithout impacting the stack as the new features in rsyslog it\nprovides are not used by this project.\n\nChange-Id: Iec55db3b6e20b3661459c639e2a48ff755c001ef\nCloses-Bug: #1467118\n(cherry picked from commit 54dfd20c833c8ddf87bc899124673dbe387498fd)\n'}]",0,195229,824ca03fef07e0dd898471bbec9799a22d74f385,7,4,1,7353,,,0,"Remove the adiscon/v8 ppa

The adiscon/v8 ppa has has occasional availability issues which
have resulted in failed deployments. This ppa can be removed
without impacting the stack as the new features in rsyslog it
provides are not used by this project.

Change-Id: Iec55db3b6e20b3661459c639e2a48ff755c001ef
Closes-Bug: #1467118
(cherry picked from commit 54dfd20c833c8ddf87bc899124673dbe387498fd)
",git fetch https://review.opendev.org/openstack/openstack-ansible refs/changes/29/195229/1 && git format-patch -1 --stdout FETCH_HEAD,"['playbooks/roles/rsyslog_client/defaults/main.yml', 'playbooks/roles/rsyslog_client/tasks/rsyslog_client_install.yml', 'playbooks/roles/rsyslog_server/defaults/main.yml', 'playbooks/roles/rsyslog_server/tasks/rsyslog_server_install.yml']",4,824ca03fef07e0dd898471bbec9799a22d74f385,, when: rsyslog_server_apt_repos is defined,,6,4
openstack%2Fhorizon~master~Ib651a0e97e8e19b12b0a2735a7694d0234e378fc,openstack/horizon,master,Ib651a0e97e8e19b12b0a2735a7694d0234e378fc,Use gen_resource_name in create/delete user test,MERGED,2015-04-13 09:41:36.000000000,2015-06-25 10:59:16.000000000,2015-06-25 10:59:13.000000000,"[{'_account_id': 3}, {'_account_id': 5623}, {'_account_id': 6890}, {'_account_id': 9317}, {'_account_id': 9622}, {'_account_id': 9981}, {'_account_id': 10442}, {'_account_id': 10881}, {'_account_id': 12355}, {'_account_id': 12954}, {'_account_id': 14151}, {'_account_id': 15168}, {'_account_id': 16523}]","[{'number': 1, 'created': '2015-04-13 09:41:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/ffc85fb927ef300d06c11b5199bbe523a1ed5f3a', 'message': 'Use gen_resource_name in create/delete user test\n\nUsing uuid in every testcase is already overcome.\n\nChange-Id: Ib651a0e97e8e19b12b0a2735a7694d0234e378fc\n'}, {'number': 2, 'created': '2015-06-17 21:14:20.000000000', 'files': ['openstack_dashboard/test/integration_tests/tests/test_user_create_delete.py'], 'web_link': 'https://opendev.org/openstack/horizon/commit/31e189687e74cc7cb20d8f847a7dc63dfd535301', 'message': 'Use gen_resource_name in create/delete user test\n\nUsing uuid in every testcase is already overcome.\n\nChange-Id: Ib651a0e97e8e19b12b0a2735a7694d0234e378fc\n'}]",0,172858,31e189687e74cc7cb20d8f847a7dc63dfd535301,20,13,2,6890,,,0,"Use gen_resource_name in create/delete user test

Using uuid in every testcase is already overcome.

Change-Id: Ib651a0e97e8e19b12b0a2735a7694d0234e378fc
",git fetch https://review.opendev.org/openstack/horizon refs/changes/58/172858/1 && git format-patch -1 --stdout FETCH_HEAD,['openstack_dashboard/test/integration_tests/tests/test_user_create_delete.py'],1,ffc85fb927ef300d06c11b5199bbe523a1ed5f3a,bp/selenium-integration-testing," USER_NAME = helpers.gen_random_resource_name(""user"")","import uuid USER_NAME = ""user_"" + str(uuid.uuid4())",1,2
openstack%2Fanchor~master~I59f831a5b8bafdea1dc2faa2ecd9da99c59471e6,openstack/anchor,master,I59f831a5b8bafdea1dc2faa2ecd9da99c59471e6,Make bio operations work with str and bytes,MERGED,2015-06-24 01:06:46.000000000,2015-06-25 10:57:58.000000000,2015-06-25 10:57:58.000000000,"[{'_account_id': 3}, {'_account_id': 11397}, {'_account_id': 11716}]","[{'number': 1, 'created': '2015-06-24 01:06:46.000000000', 'files': ['anchor/X509/certificate.py', 'anchor/X509/signing_request.py', 'anchor/X509/utils.py'], 'web_link': 'https://opendev.org/openstack/anchor/commit/1b7762b60650e9ad6c9abb3bb19f3b4593e6c6c6', 'message': ""Make bio operations work with str and bytes\n\nPython3 compatibility - files read bytes, but tests include strings.\nIt's easier to just support both in this case.\n\nChange-Id: I59f831a5b8bafdea1dc2faa2ecd9da99c59471e6\n""}]",0,194902,1b7762b60650e9ad6c9abb3bb19f3b4593e6c6c6,7,3,1,1528,,,0,"Make bio operations work with str and bytes

Python3 compatibility - files read bytes, but tests include strings.
It's easier to just support both in this case.

Change-Id: I59f831a5b8bafdea1dc2faa2ecd9da99c59471e6
",git fetch https://review.opendev.org/openstack/anchor refs/changes/02/194902/1 && git format-patch -1 --stdout FETCH_HEAD,"['anchor/X509/certificate.py', 'anchor/X509/signing_request.py', 'anchor/X509/utils.py']",3,1b7762b60650e9ad6c9abb3bb19f3b4593e6c6c6,generalised_bio, if type(key_data) != bytes: key_data = key_data.encode('ascii'),,8,2
openstack%2Fanchor~master~Ia4681fd8b207d5caf1e0e482a17cac14267c8fa2,openstack/anchor,master,Ia4681fd8b207d5caf1e0e482a17cac14267c8fa2,Bio mode needs to be passed as bytes,MERGED,2015-06-24 01:09:28.000000000,2015-06-25 10:54:06.000000000,2015-06-25 10:54:03.000000000,"[{'_account_id': 3}, {'_account_id': 11397}, {'_account_id': 11716}]","[{'number': 1, 'created': '2015-06-24 01:09:28.000000000', 'files': ['anchor/X509/certificate.py'], 'web_link': 'https://opendev.org/openstack/anchor/commit/f92305c00b88e9c88c15c50a72e96dc836bfa6d6', 'message': 'Bio mode needs to be passed as bytes\n\nPython3 compatibility\n\nChange-Id: Ia4681fd8b207d5caf1e0e482a17cac14267c8fa2\n'}]",0,194903,f92305c00b88e9c88c15c50a72e96dc836bfa6d6,7,3,1,1528,,,0,"Bio mode needs to be passed as bytes

Python3 compatibility

Change-Id: Ia4681fd8b207d5caf1e0e482a17cac14267c8fa2
",git fetch https://review.opendev.org/openstack/anchor refs/changes/03/194903/1 && git format-patch -1 --stdout FETCH_HEAD,['anchor/X509/certificate.py'],1,f92305c00b88e9c88c15c50a72e96dc836bfa6d6,byte_filemode," bio = self._lib.BIO_new_file(path.encode('ascii', 'ignore'), b""w"")"," bio = self._lib.BIO_new_file(path.encode('ascii', 'ignore'), ""w"")",1,1
openstack%2Fcookbook-openstack-network~master~I364d902de5943c9bbf55eca6c5f76fb7fef64162,openstack/cookbook-openstack-network,master,I364d902de5943c9bbf55eca6c5f76fb7fef64162,Replace deprecated get_secret,MERGED,2015-06-22 20:41:36.000000000,2015-06-25 10:49:50.000000000,2015-06-25 10:49:48.000000000,"[{'_account_id': 3}, {'_account_id': 8112}, {'_account_id': 9488}]","[{'number': 1, 'created': '2015-06-22 20:41:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cookbook-openstack-network/commit/c6ae77c4ce8807c9923a82419571c407e883486f', 'message': ""Replace deprecated get_secret\n\nUse get_password 'token' instead.\n\nChange-Id: I364d902de5943c9bbf55eca6c5f76fb7fef64162\nPartial-Bug: #1467662\n""}, {'number': 2, 'created': '2015-06-22 20:53:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cookbook-openstack-network/commit/426da62beb141c274c95e8a27167bcc176a934e6', 'message': ""Replace deprecated get_secret\n\nUse get_password 'token' instead.\n\nChange-Id: I364d902de5943c9bbf55eca6c5f76fb7fef64162\nPartial-Bug: #1467662\n""}, {'number': 3, 'created': '2015-06-24 18:50:50.000000000', 'files': ['recipes/metadata_agent.rb', 'spec/spec_helper.rb', 'spec/metadata_agent_spec.rb', 'metadata.rb', 'recipes/identity_registration.rb'], 'web_link': 'https://opendev.org/openstack/cookbook-openstack-network/commit/b49df0cb25866c66bea2b868266b32684a4876c9', 'message': ""Replace deprecated get_secret\n\nUse get_password 'token' instead.\n\nChange-Id: I364d902de5943c9bbf55eca6c5f76fb7fef64162\nPartial-Bug: #1467662\n""}]",0,194361,b49df0cb25866c66bea2b868266b32684a4876c9,13,3,3,7128,,,0,"Replace deprecated get_secret

Use get_password 'token' instead.

Change-Id: I364d902de5943c9bbf55eca6c5f76fb7fef64162
Partial-Bug: #1467662
",git fetch https://review.opendev.org/openstack/cookbook-openstack-network refs/changes/61/194361/1 && git format-patch -1 --stdout FETCH_HEAD,"['recipes/metadata_agent.rb', 'spec/spec_helper.rb', 'recipes/identity_registration.rb']",3,c6ae77c4ce8807c9923a82419571c407e883486f,bug/1467662,"bootstrap_token = get_password 'token', 'openstack_identity_bootstrap_token'",bootstrap_token = get_secret 'openstack_identity_bootstrap_token',6,6
openstack%2Fironic~master~I0970bdfdd4d0eb3ce68f8fe17b99ef00554fda59,openstack/ironic,master,I0970bdfdd4d0eb3ce68f8fe17b99ef00554fda59,Add unit test for ilo_deploy _configure_vmedia_boot(),MERGED,2015-06-22 08:47:02.000000000,2015-06-25 10:46:09.000000000,2015-06-25 10:46:08.000000000,"[{'_account_id': 3}, {'_account_id': 6618}, {'_account_id': 10239}, {'_account_id': 12081}, {'_account_id': 13719}]","[{'number': 1, 'created': '2015-06-22 08:47:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/1496d9f383feacbd0e1cd7e721e4f16845d292c8', 'message': ""Add unit test for ilo_deploy _configure_vmedia_boot()\n\nThis patch adds unit test which is a reflection of iRMC virtual media\ncode review comment [1] to ilo virtual media reference source code.\nIt was advised that _configure_vmedia_boot could use it's own specific\nunit test.\n\nhttps://review.openstack.org/#/c/181807/7\n\nChange-Id: I0970bdfdd4d0eb3ce68f8fe17b99ef00554fda59\n""}, {'number': 2, 'created': '2015-06-24 06:11:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/67447862337e0b63b90370648de4824e359510d2', 'message': ""Add unit test for ilo_deploy _configure_vmedia_boot()\n\nThis patch adds unit test which is a reflection of iRMC virtual media\ncode review comment [1] to ilo virtual media reference source code.\nIt was advised that _configure_vmedia_boot could use it's own specific\nunit test.\n\nhttps://review.openstack.org/#/c/181807/7\n\nChange-Id: I0970bdfdd4d0eb3ce68f8fe17b99ef00554fda59\n""}, {'number': 3, 'created': '2015-06-24 14:59:03.000000000', 'files': ['ironic/tests/drivers/ilo/test_deploy.py'], 'web_link': 'https://opendev.org/openstack/ironic/commit/6a5b779d80246c4d2d32ef0398523573aea0b56a', 'message': ""Add unit test for ilo_deploy _configure_vmedia_boot()\n\nThis patch adds unit test which is a reflection of iRMC virtual media\ncode review comment [1] to ilo virtual media reference source code.\nIt was advised that _configure_vmedia_boot could use it's own specific\nunit test.\n\nhttps://review.openstack.org/#/c/181807/7\n\nChange-Id: I0970bdfdd4d0eb3ce68f8fe17b99ef00554fda59\n""}]",4,194047,6a5b779d80246c4d2d32ef0398523573aea0b56a,21,5,3,13719,,,0,"Add unit test for ilo_deploy _configure_vmedia_boot()

This patch adds unit test which is a reflection of iRMC virtual media
code review comment [1] to ilo virtual media reference source code.
It was advised that _configure_vmedia_boot could use it's own specific
unit test.

https://review.openstack.org/#/c/181807/7

Change-Id: I0970bdfdd4d0eb3ce68f8fe17b99ef00554fda59
",git fetch https://review.opendev.org/openstack/ironic refs/changes/47/194047/2 && git format-patch -1 --stdout FETCH_HEAD,['ironic/tests/drivers/ilo/test_deploy.py'],1,1496d9f383feacbd0e1cd7e721e4f16845d292c8,add-test-ilo_deploy-_configure_vmedia_boot," @mock.patch.object(manager_utils, 'node_set_boot_device', spec_set=True, autospec=True) @mock.patch.object(ilo_common, 'setup_vmedia_for_boot', spec_set=True, autospec=True) @mock.patch.object(ilo_deploy, '_get_boot_iso', spec_set=True, autospec=True) def test__configure_vmedia_boot_with_boot_iso( self, get_boot_iso_mock, setup_vmedia_mock, set_boot_device_mock): root_uuid = {'root uuid': 'root_uuid'} with task_manager.acquire(self.context, self.node.uuid, shared=False) as task: get_boot_iso_mock.return_value = 'boot.iso' task.driver.vendor._configure_vmedia_boot( task, root_uuid) get_boot_iso_mock.assert_called_once_with( task, root_uuid) setup_vmedia_mock.assert_called_once_with( task, 'boot.iso') set_boot_device_mock.assert_called_once_with( task, boot_devices.CDROM, persistent=True) @mock.patch.object(manager_utils, 'node_set_boot_device', spec_set=True, autospec=True) @mock.patch.object(ilo_common, 'setup_vmedia_for_boot', spec_set=True, autospec=True) @mock.patch.object(ilo_deploy, '_get_boot_iso', spec_set=True, autospec=True) def test__configure_vmedia_boot_without_boot_iso( self, get_boot_iso_mock, setup_vmedia_mock, set_boot_device_mock): root_uuid = {'root uuid': 'root_uuid'} with task_manager.acquire(self.context, self.node.uuid, shared=False) as task: get_boot_iso_mock.return_value = None task.driver.vendor._configure_vmedia_boot( task, root_uuid) get_boot_iso_mock.assert_called_once_with( task, root_uuid) self.assertFalse(setup_vmedia_mock.called) self.assertFalse(set_boot_device_mock.called) ",,46,0
openstack%2Ftripleo-heat-templates~master~I42462a6de2bf70ef71899833c3f27633f0f59493,openstack/tripleo-heat-templates,master,I42462a6de2bf70ef71899833c3f27633f0f59493,Ensure mysql/mariadb service is not enabled on boot,MERGED,2015-06-24 23:13:25.000000000,2015-06-25 10:44:07.000000000,2015-06-25 10:44:06.000000000,"[{'_account_id': 3}, {'_account_id': 4328}, {'_account_id': 6796}, {'_account_id': 7582}, {'_account_id': 8399}, {'_account_id': 8449}, {'_account_id': 9410}]","[{'number': 1, 'created': '2015-06-24 23:13:25.000000000', 'files': ['puppet/manifests/overcloud_controller_pacemaker.pp'], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/c8c0d149a1695293a1f237bce30eb908d2186084', 'message': 'Ensure mysql/mariadb service is not enabled on boot\n\nChange-Id: I42462a6de2bf70ef71899833c3f27633f0f59493\nCloses-Bug: 1468549\nCloses-Bug: https://bugzilla.redhat.com/show_bug.cgi?id=1235454\n'}]",0,195353,c8c0d149a1695293a1f237bce30eb908d2186084,12,7,1,6796,,,0,"Ensure mysql/mariadb service is not enabled on boot

Change-Id: I42462a6de2bf70ef71899833c3f27633f0f59493
Closes-Bug: 1468549
Closes-Bug: https://bugzilla.redhat.com/show_bug.cgi?id=1235454
",git fetch https://review.opendev.org/openstack/tripleo-heat-templates refs/changes/53/195353/1 && git format-patch -1 --stdout FETCH_HEAD,['puppet/manifests/overcloud_controller_pacemaker.pp'],1,c8c0d149a1695293a1f237bce30eb908d2186084,bug/1468549," service_enabled => false,",,1,0
openstack%2Ffuel-docs~master~I6e180e33dca2d3e970db171fc673ee4489c09a5a,openstack/fuel-docs,master,I6e180e33dca2d3e970db171fc673ee4489c09a5a,Fix links to Fuel-Dev,MERGED,2015-06-25 10:27:14.000000000,2015-06-25 10:42:52.000000000,2015-06-25 10:42:42.000000000,"[{'_account_id': 3}, {'_account_id': 8971}, {'_account_id': 13082}]","[{'number': 1, 'created': '2015-06-25 10:27:14.000000000', 'files': ['pages/terminology/c/cobbler.rst', 'pages/terminology/f/fuel-master-node.rst', 'pages/terminology/a/astute.rst', 'pages/planning-guide/0010-intro.rst', 'pages/terminology/n/nailgun.rst', 'pages/operations/2800-experimental.rst', 'pages/user-guide/0070-introduction.rst', 'pages/terminology/f/fuel.rst'], 'web_link': 'https://opendev.org/openstack/fuel-docs/commit/4f7c6ee1eb494b9a3d6be38eb911dbbb58c1395c', 'message': 'Fix links to Fuel-Dev\n\nFix links to the fuel dev guide.\n\nChange-Id: I6e180e33dca2d3e970db171fc673ee4489c09a5a\n'}]",0,195503,4f7c6ee1eb494b9a3d6be38eb911dbbb58c1395c,9,3,1,14342,,,0,"Fix links to Fuel-Dev

Fix links to the fuel dev guide.

Change-Id: I6e180e33dca2d3e970db171fc673ee4489c09a5a
",git fetch https://review.opendev.org/openstack/fuel-docs refs/changes/03/195503/1 && git format-patch -1 --stdout FETCH_HEAD,"['pages/terminology/c/cobbler.rst', 'pages/terminology/f/fuel-master-node.rst', 'pages/planning-guide/0010-intro.rst', 'pages/terminology/a/astute.rst', 'pages/terminology/n/nailgun.rst', 'pages/operations/2800-experimental.rst', 'pages/user-guide/0070-introduction.rst', 'pages/terminology/f/fuel.rst']",8,4f7c6ee1eb494b9a3d6be38eb911dbbb58c1395c,FixFuelDevLinks,- `Fuel Architecture <https://docs.fuel-infra.org/fuel-dev/develop/architecture.html>`_. - `Sequence diagrams <https://docs.fuel-infra.org/fuel-dev/develop/sequence.html#os-provisioning>`_,- `Fuel Architecture <http://docs.mirantis.com/fuel-dev/develop/architecture.html>`_. - `Sequence diagrams <http://docs.mirantis.com/fuel-dev/develop/sequence.html#os-provisioning>`_,9,9
openstack%2Fnetworking-midonet~stable%2Ficehouse~I0668c000bc88121a35a6548b46adf42267af7152,openstack/networking-midonet,stable/icehouse,I0668c000bc88121a35a6548b46adf42267af7152,Pin oslo.i18n to the version in global req,MERGED,2015-06-25 05:55:12.000000000,2015-06-25 10:41:52.000000000,2015-06-25 10:41:49.000000000,"[{'_account_id': 3}, {'_account_id': 156}]","[{'number': 1, 'created': '2015-06-25 05:55:12.000000000', 'files': ['requirements.txt'], 'web_link': 'https://opendev.org/openstack/networking-midonet/commit/901a4ff1bbc66a9ff5022a67d0fb58980beecedf', 'message': ""Pin oslo.i18n to the version in global req\n\nOslo.i18.n 2.0.0 that just came out is incompatible with the plugin.\n\nUpdate the requirements.txt temporarily to pin the version of oslo.i18n\nto match what's set in Icehouse's OpenStack global requirements until\nhow to handle library requirements is decided by the community.\n\nChange-Id: I0668c000bc88121a35a6548b46adf42267af7152\nFixes: MNP-160\n""}]",0,195419,901a4ff1bbc66a9ff5022a67d0fb58980beecedf,6,2,1,156,,,0,"Pin oslo.i18n to the version in global req

Oslo.i18.n 2.0.0 that just came out is incompatible with the plugin.

Update the requirements.txt temporarily to pin the version of oslo.i18n
to match what's set in Icehouse's OpenStack global requirements until
how to handle library requirements is decided by the community.

Change-Id: I0668c000bc88121a35a6548b46adf42267af7152
Fixes: MNP-160
",git fetch https://review.opendev.org/openstack/networking-midonet refs/changes/19/195419/1 && git format-patch -1 --stdout FETCH_HEAD,['requirements.txt'],1,901a4ff1bbc66a9ff5022a67d0fb58980beecedf,icehouse_to_ost," # Some components that the Icehouse plugin depends on are not compatible with # oslo.i18n 2.0.0 which is now available. Until the library requirements are # decided for the stable releases, pin these to the version matching the # version defined in Icehouse's OpenStack global requirements. oslo.i18n>=0.1.0,<1.1 # Apache-2.0",,6,0
openstack%2Fironic~master~I5326911d2fec6bab042a3afe28a748793aa4d1f6,openstack/ironic,master,I5326911d2fec6bab042a3afe28a748793aa4d1f6,Add iBoot driver documentation,MERGED,2015-06-19 13:35:02.000000000,2015-06-25 10:38:40.000000000,2015-06-25 10:38:37.000000000,"[{'_account_id': 3}, {'_account_id': 5805}, {'_account_id': 6618}, {'_account_id': 6773}, {'_account_id': 7711}, {'_account_id': 9382}, {'_account_id': 10239}, {'_account_id': 12081}, {'_account_id': 12459}]","[{'number': 1, 'created': '2015-06-19 13:35:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/78808721cb24c0a0c502326f2b89bd60ee4676f0', 'message': 'Add iBoot driver documentation\n\nThe iBoot driver have been in tree for a long time but it never had any\ndocumentation. This patch is adding one.\n\nChange-Id: I5326911d2fec6bab042a3afe28a748793aa4d1f6\n'}, {'number': 2, 'created': '2015-06-23 08:10:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/2ca660a907d01e45c0a29af41b0ed8cf0a91c3f9', 'message': 'Add iBoot driver documentation\n\nThe iBoot driver have been in tree for a long time but it never had any\ndocumentation. This patch is adding one.\n\nChange-Id: I5326911d2fec6bab042a3afe28a748793aa4d1f6\n'}, {'number': 3, 'created': '2015-06-23 13:31:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/927db1131703e2a0c4cb75293b1d44f33b3887e8', 'message': 'Add iBoot driver documentation\n\nThe iBoot driver have been in tree for a long time but it never had any\ndocumentation. This patch is adding one.\n\nChange-Id: I5326911d2fec6bab042a3afe28a748793aa4d1f6\n'}, {'number': 4, 'created': '2015-06-24 09:23:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/ac2da19386ad57b96a3c4b4aebf46e8f2906ade5', 'message': 'Add iBoot driver documentation\n\nThe iBoot driver have been in tree for a long time but it never had any\ndocumentation. This patch is adding one.\n\nChange-Id: I5326911d2fec6bab042a3afe28a748793aa4d1f6\n'}, {'number': 5, 'created': '2015-06-24 16:43:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/654601046e1417b8f7fe7a8bc8d3c0f0b836c200', 'message': 'Add iBoot driver documentation\n\nThe iBoot driver have been in tree for a long time but it never had any\ndocumentation. This patch is adding one.\n\nChange-Id: I5326911d2fec6bab042a3afe28a748793aa4d1f6\n'}, {'number': 6, 'created': '2015-06-25 08:37:27.000000000', 'files': ['doc/source/drivers/iboot.rst', 'doc/source/deploy/drivers.rst'], 'web_link': 'https://opendev.org/openstack/ironic/commit/0b778bba24acc6c90ab870eceffe122070706a2b', 'message': 'Add iBoot driver documentation\n\nThe iBoot driver have been in tree for a long time but it never had any\ndocumentation. This patch is adding one.\n\nChange-Id: I5326911d2fec6bab042a3afe28a748793aa4d1f6\n'}]",26,193546,0b778bba24acc6c90ab870eceffe122070706a2b,48,9,6,6773,,,0,"Add iBoot driver documentation

The iBoot driver have been in tree for a long time but it never had any
documentation. This patch is adding one.

Change-Id: I5326911d2fec6bab042a3afe28a748793aa4d1f6
",git fetch https://review.opendev.org/openstack/ironic refs/changes/46/193546/1 && git format-patch -1 --stdout FETCH_HEAD,"['doc/source/drivers/iboot.rst', 'doc/source/deploy/drivers.rst']",2,78808721cb24c0a0c502326f2b89bd60ee4676f0,iboot-docs, iBoot driver ------------ .. toctree:: :maxdepth: 1 ../drivers/iboot,,85,0
openstack%2Fkeystone~master~If1be9d798476f107644a2c430bb69a044387fd12,openstack/keystone,master,If1be9d798476f107644a2c430bb69a044387fd12,Update federation driver name in documentation,ABANDONED,2015-06-17 14:43:49.000000000,2015-06-25 10:35:36.000000000,,"[{'_account_id': 3}, {'_account_id': 6482}, {'_account_id': 6486}, {'_account_id': 7725}, {'_account_id': 8119}, {'_account_id': 11022}, {'_account_id': 13478}, {'_account_id': 16523}]","[{'number': 1, 'created': '2015-06-17 14:43:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/6f2eb7e30930c6a9cd58547fc41161fa648193b0', 'message': ""Update federation driver name in documentation\n\nWith stevedore  being used for loading keystone's drivers we use\ndifferent naming format.\nThis patch changes the configuration docs so they reflect default (and\ncorrect) values from the etc/keystone.conf file.\n\nChange-Id: If1be9d798476f107644a2c430bb69a044387fd12\n""}, {'number': 2, 'created': '2015-06-22 13:35:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/8d829fce66a7caabf3fe9dbd82932e4f0a6bd6f5', 'message': ""Update federation driver name in documentation\n\nWith stevedore  being used for loading keystone's drivers we use\ndifferent naming format.\nThis patch changes the configuration docs so they reflect default (and\ncorrect) values from the etc/keystone.conf file.\n\nChange-Id: If1be9d798476f107644a2c430bb69a044387fd12\n""}, {'number': 3, 'created': '2015-06-25 10:31:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/e00f2525e72f40a79c4434c47e6211362af8cb95', 'message': ""Update federation driver name in documentation\n\nWith stevedore  being used for loading keystone's drivers we use\ndifferent naming format.\nThis patch changes the configuration docs so they reflect default (and\ncorrect) values from the etc/keystone.conf file.\n\nChange-Id: If1be9d798476f107644a2c430bb69a044387fd12\n""}]",0,192706,e00f2525e72f40a79c4434c47e6211362af8cb95,14,8,3,8978,,,0,"Update federation driver name in documentation

With stevedore  being used for loading keystone's drivers we use
different naming format.
This patch changes the configuration docs so they reflect default (and
correct) values from the etc/keystone.conf file.

Change-Id: If1be9d798476f107644a2c430bb69a044387fd12
",git fetch https://review.opendev.org/openstack/keystone refs/changes/06/192706/3 && git format-patch -1 --stdout FETCH_HEAD,['doc/source/federation/federation.rst'],1,6f2eb7e30930c6a9cd58547fc41161fa648193b0,fix_docs, driver = sql, driver = keystone.contrib.federation.backends.sql.Federation,1,1
openstack%2Fdevstack~master~I09b1a7bee0785e5e1bb7dc96158a654bd3f15c83,openstack/devstack,master,I09b1a7bee0785e5e1bb7dc96158a654bd3f15c83,Check if cinder is enabled before doing anything lvm2 related,MERGED,2015-05-29 09:43:39.000000000,2015-06-25 10:35:12.000000000,2015-06-25 10:35:08.000000000,"[{'_account_id': 3}, {'_account_id': 970}, {'_account_id': 2750}, {'_account_id': 7118}, {'_account_id': 7350}, {'_account_id': 7715}, {'_account_id': 8871}, {'_account_id': 10385}, {'_account_id': 13252}]","[{'number': 1, 'created': '2015-05-29 09:43:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack/commit/84db574d8fa29cfe088731afa4acc7ddaa01f7d1', 'message': ""Check if /etc/lvm/lvm.conf exists before editing it with `sed`\n\nOn some system Cinder is not installed nor LVM, so lvm.conf doesn't\nexist. This patch prevents the warning 'sed: can't read /etc/lvm/lvm.conf:\nNo such file or directory' to appear on these systems.\n\nChange-Id: I09b1a7bee0785e5e1bb7dc96158a654bd3f15c83\n""}, {'number': 2, 'created': '2015-06-03 13:30:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack/commit/d3a84dd75fe9e4b543c87b2d8942ec02b511ffeb', 'message': 'Check if lvm2 is installed before doing anything lvm2 related\n\nOn some system Cinder is not installed nor LVM. Do not try to `sed`\n/etc/lvm.conf or clean LVM VG if lvm is not installed.\n\nChange-Id: I09b1a7bee0785e5e1bb7dc96158a654bd3f15c83\n'}, {'number': 3, 'created': '2015-06-03 13:34:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack/commit/90c7eaa3226a05378a98fcd393f631e594ec84e9', 'message': 'Check if lvm2 is installed before doing anything lvm2 related\n\nOn some system Cinder is not installed nor LVM. Do not try to `sed`\n/etc/lvm.conf or clean LVM VG if lvm is not installed.\n\nChange-Id: I09b1a7bee0785e5e1bb7dc96158a654bd3f15c83\n'}, {'number': 4, 'created': '2015-06-10 13:28:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack/commit/717733f738ed812be11c9d129de1411583865e49', 'message': 'Check if lvm2 is installed before doing anything lvm2 related\n\nOn some system Cinder is not installed nor LVM. Do not try to `sed`\n/etc/lvm.conf or clean LVM VG if lvm is not installed.\n\nChange-Id: I09b1a7bee0785e5e1bb7dc96158a654bd3f15c83\n'}, {'number': 5, 'created': '2015-06-18 08:17:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack/commit/70fe4b94a36ae05ed1bbb1c429ba8037b31e3f4c', 'message': 'Check if lvm2 is installed before doing anything lvm2 related\n\nOn some system Cinder is not installed nor LVM. Do not try to `sed`\n/etc/lvm.conf or clean LVM VG if lvm is not installed.\n\nChange-Id: I09b1a7bee0785e5e1bb7dc96158a654bd3f15c83\n'}, {'number': 6, 'created': '2015-06-19 08:17:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack/commit/cae35309c8de577ca7771da29aea794068c2e2bc', 'message': 'Check if lvm2 is installed before doing anything lvm2 related\n\nOn some system Cinder is not installed nor LVM. Do not try to `sed`\n/etc/lvm.conf or clean LVM VG if lvm is not installed.\n\nChange-Id: I09b1a7bee0785e5e1bb7dc96158a654bd3f15c83\n'}, {'number': 7, 'created': '2015-06-19 14:34:59.000000000', 'files': ['unstack.sh'], 'web_link': 'https://opendev.org/openstack/devstack/commit/23bf045c183f53762e7771fe0081b3d4ab09e107', 'message': ""Check if cinder is enabled before doing anything lvm2 related\n\nOn some system Cinder is not enabled so we can't assume LVM is installed. So\ndo not try to `sed` /etc/lvm/lvm.conf or clean LVM VG if cinder is not enabled\n\nChange-Id: I09b1a7bee0785e5e1bb7dc96158a654bd3f15c83""}]",9,186696,23bf045c183f53762e7771fe0081b3d4ab09e107,47,9,7,7350,,,0,"Check if cinder is enabled before doing anything lvm2 related

On some system Cinder is not enabled so we can't assume LVM is installed. So
do not try to `sed` /etc/lvm/lvm.conf or clean LVM VG if cinder is not enabled

Change-Id: I09b1a7bee0785e5e1bb7dc96158a654bd3f15c83",git fetch https://review.opendev.org/openstack/devstack refs/changes/96/186696/3 && git format-patch -1 --stdout FETCH_HEAD,['lib/lvm'],1,84db574d8fa29cfe088731afa4acc7ddaa01f7d1,," if [[ -f /etc/lvm/lvm.conf ]]; then sudo sed -i ""s/^.*# from devstack$//"" /etc/lvm/lvm.conf fi"," sudo sed -i ""s/^.*# from devstack$//"" /etc/lvm/lvm.conf",3,1
openstack%2Fmistral~master~I7c25e2962677ee022a00f8019c1b503d8a8461c1,openstack/mistral,master,I7c25e2962677ee022a00f8019c1b503d8a8461c1,Bug fix with-items tasks should always have result of list type,MERGED,2015-06-23 08:34:44.000000000,2015-06-25 10:34:53.000000000,2015-06-25 10:34:52.000000000,"[{'_account_id': 3}, {'_account_id': 5558}, {'_account_id': 6732}, {'_account_id': 7700}, {'_account_id': 8731}, {'_account_id': 9432}, {'_account_id': 15426}]","[{'number': 1, 'created': '2015-06-23 08:34:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/mistral/commit/3b5812f5b4bf665a9904e9f1bee8bc168c46ec58', 'message': 'Bug fix with-items tasks should always have result of list type\n\nChange-Id: I7c25e2962677ee022a00f8019c1b503d8a8461c1\nCloses-Bug: #1462189\n'}, {'number': 2, 'created': '2015-06-23 09:38:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/mistral/commit/c8a7cc424b2e4724d0b9117a48470f6f4b4c75ba', 'message': 'Bug fix with-items tasks should always have result of list type\n\nChange-Id: I7c25e2962677ee022a00f8019c1b503d8a8461c1\nCloses-Bug: #1462189\n'}, {'number': 3, 'created': '2015-06-23 10:56:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/mistral/commit/fbc63e936bd1cd4df40ef135f703651dc90a41f6', 'message': 'Bug fix with-items tasks should always have result of list type\n\nChange-Id: I7c25e2962677ee022a00f8019c1b503d8a8461c1\nCloses-Bug: #1462189\n'}, {'number': 4, 'created': '2015-06-24 08:49:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/mistral/commit/3c85d0b3bbd4f89079d4cf539eecbcf58d2a34c5', 'message': 'Bug fix with-items tasks should always have result of list type\n\nChange-Id: I7c25e2962677ee022a00f8019c1b503d8a8461c1\nCloses-Bug: #1462189\n'}, {'number': 5, 'created': '2015-06-25 08:28:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/mistral/commit/2bd48fcf08301ee8593f28da058bca1b1ba09ffa', 'message': 'Bug fix with-items tasks should always have result of list type\n\nChange-Id: I7c25e2962677ee022a00f8019c1b503d8a8461c1\nCloses-Bug: #1462189\n'}, {'number': 6, 'created': '2015-06-25 09:01:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/mistral/commit/60fbc079240332b7e6cc6711d456e6703162b11e', 'message': 'Bug fix with-items tasks should always have result of list type\n\nChange-Id: I7c25e2962677ee022a00f8019c1b503d8a8461c1\nCloses-Bug: #1462189\n'}, {'number': 7, 'created': '2015-06-25 09:59:10.000000000', 'files': ['mistral/workflow/data_flow.py', 'mistral/tests/unit/engine/test_with_items.py'], 'web_link': 'https://opendev.org/openstack/mistral/commit/7fb557adb5c65f649a8982d12e1d246cafcf4f09', 'message': 'Bug fix with-items tasks should always have result of list type\n\nChange-Id: I7c25e2962677ee022a00f8019c1b503d8a8461c1\nCloses-Bug: #1462189\n'}]",5,194547,7fb557adb5c65f649a8982d12e1d246cafcf4f09,30,7,7,15426,,,0,"Bug fix with-items tasks should always have result of list type

Change-Id: I7c25e2962677ee022a00f8019c1b503d8a8461c1
Closes-Bug: #1462189
",git fetch https://review.opendev.org/openstack/mistral refs/changes/47/194547/1 && git format-patch -1 --stdout FETCH_HEAD,"['mistral/workflow/data_flow.py', 'mistral/tests/unit/engine/test_with_items.py']",2,3b5812f5b4bf665a9904e9f1bee8bc168c46ec58,fd17823,"WORKFLOW_INPUT_ONE_ITEM = { 'names_info': [ {'name': 'Guy'} ] } def test_with_items_results_one_item_as_list(self): wb_service.create_workbook_v2(WORKBOOK) # Start workflow. wf_ex = self.engine.start_workflow('wb1.with_items', WORKFLOW_INPUT_ONE_ITEM) self._await( lambda: self.is_execution_success(wf_ex.id), ) # Note: We need to reread execution to access related tasks. wf_ex = db_api.get_workflow_execution(wf_ex.id) tasks = wf_ex.task_executions task1 = self._assert_single_item(tasks, name='task1') with_items_context = task1.runtime_context['with_items'] result = data_flow.get_task_execution_result(task1) self.assertEqual(1, with_items_context['count']) self.assertTrue(isinstance(result, list)) self.assertIn('Guy', result) published = task1.published self.assertIn(published['result'], ['Guy']) self.assertEqual(1, len(tasks)) self.assertEqual(states.SUCCESS, task1.state)",,45,1
openstack%2Frally~master~I496909e3f6fed962c8443d13453ef8e9382744ae,openstack/rally,master,I496909e3f6fed962c8443d13453ef8e9382744ae,Updated from global requirements,MERGED,2015-06-08 21:20:28.000000000,2015-06-25 10:30:49.000000000,2015-06-24 22:37:57.000000000,"[{'_account_id': 3}, {'_account_id': 6172}, {'_account_id': 7369}, {'_account_id': 9545}, {'_account_id': 14817}]","[{'number': 1, 'created': '2015-06-08 21:20:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/a9f9784a2969632b3473441e6f2c620afabaf487', 'message': 'Updated from global requirements\n\nChange-Id: I496909e3f6fed962c8443d13453ef8e9382744ae\n'}, {'number': 2, 'created': '2015-06-08 23:45:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/c34e6b1f88e300eb0295cbd19251098423851235', 'message': 'Updated from global requirements\n\nChange-Id: I496909e3f6fed962c8443d13453ef8e9382744ae\n'}, {'number': 3, 'created': '2015-06-09 20:05:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/92c5e4a0476bf3c19dc418c80f2b9034e0655593', 'message': 'Updated from global requirements\n\nChange-Id: I496909e3f6fed962c8443d13453ef8e9382744ae\n'}, {'number': 4, 'created': '2015-06-10 21:27:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/8811657062de0547aae116d9e90387b2f790209a', 'message': 'Updated from global requirements\n\nChange-Id: I496909e3f6fed962c8443d13453ef8e9382744ae\n'}, {'number': 5, 'created': '2015-06-10 23:50:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/b712dbe20b7266370768ea5c2a293f7aa6c47c57', 'message': 'Updated from global requirements\n\nChange-Id: I496909e3f6fed962c8443d13453ef8e9382744ae\n'}, {'number': 6, 'created': '2015-06-11 00:48:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/1c0cfa20b814041553017fc0b2b8a73116c3602e', 'message': 'Updated from global requirements\n\nChange-Id: I496909e3f6fed962c8443d13453ef8e9382744ae\n'}, {'number': 7, 'created': '2015-06-14 10:30:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/080352e78b27c00bce2a63972c049152176040d7', 'message': 'Updated from global requirements\n\nChange-Id: I496909e3f6fed962c8443d13453ef8e9382744ae\n'}, {'number': 8, 'created': '2015-06-15 03:47:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/95b1ac2b285291fac5a600cdd2aa9dcadcdaad58', 'message': 'Updated from global requirements\n\nChange-Id: I496909e3f6fed962c8443d13453ef8e9382744ae\n'}, {'number': 9, 'created': '2015-06-15 22:08:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/73371f04998ab6166cbce69c24227fcd29b233a2', 'message': 'Updated from global requirements\n\nChange-Id: I496909e3f6fed962c8443d13453ef8e9382744ae\n'}, {'number': 10, 'created': '2015-06-16 13:23:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/8fd1811909f46d169af79e50b28dcc23a407e120', 'message': 'Updated from global requirements\n\nChange-Id: I496909e3f6fed962c8443d13453ef8e9382744ae\n'}, {'number': 11, 'created': '2015-06-16 16:30:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/afa65259866bade832e9d9d99d5b2f877d960031', 'message': 'Updated from global requirements\n\nChange-Id: I496909e3f6fed962c8443d13453ef8e9382744ae\n'}, {'number': 12, 'created': '2015-06-16 16:50:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/4b4a36df8d3a02ba285d48e46a70dd1dee5db69f', 'message': 'Updated from global requirements\n\nChange-Id: I496909e3f6fed962c8443d13453ef8e9382744ae\n'}, {'number': 13, 'created': '2015-06-16 19:23:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/7d11187a78f0a994973ea75667e7d424ce815d69', 'message': 'Updated from global requirements\n\nChange-Id: I496909e3f6fed962c8443d13453ef8e9382744ae\n'}, {'number': 14, 'created': '2015-06-22 08:28:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/8111a34346618944de2dc7b4c149f43419674a19', 'message': 'Updated from global requirements\n\nChange-Id: I496909e3f6fed962c8443d13453ef8e9382744ae\n'}, {'number': 15, 'created': '2015-06-22 20:00:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/523ae229cba3a0cd73b863fbc9ecb24fa64e58a4', 'message': 'Updated from global requirements\n\nChange-Id: I496909e3f6fed962c8443d13453ef8e9382744ae\n'}, {'number': 16, 'created': '2015-06-22 20:50:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/167d4ae6eee2ad32be146628f3b72456cdb49775', 'message': 'Updated from global requirements\n\nChange-Id: I496909e3f6fed962c8443d13453ef8e9382744ae\n'}, {'number': 17, 'created': '2015-06-22 21:32:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/2ea885af78e3980f705ecf74aee6679efe4c5847', 'message': 'Updated from global requirements\n\nChange-Id: I496909e3f6fed962c8443d13453ef8e9382744ae\n'}, {'number': 18, 'created': '2015-06-22 22:04:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/b14d57643c5591882cb16cf04604db58ef93ca18', 'message': 'Updated from global requirements\n\nChange-Id: I496909e3f6fed962c8443d13453ef8e9382744ae\n'}, {'number': 19, 'created': '2015-06-23 21:50:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/42980d5f3f0a329ee5fdf08f7b41943976ee3a80', 'message': 'Updated from global requirements\n\nChange-Id: I496909e3f6fed962c8443d13453ef8e9382744ae\n'}, {'number': 20, 'created': '2015-06-24 14:46:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/3b2bbf50e6775a1bad24762c962ef01389d388b2', 'message': 'Updated from global requirements\n\nChange-Id: I496909e3f6fed962c8443d13453ef8e9382744ae\n'}, {'number': 21, 'created': '2015-06-24 19:38:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/3d1607e74130e50f8edaedfb3c18f4e87a80ca19', 'message': 'Updated from global requirements\n\nChange-Id: I496909e3f6fed962c8443d13453ef8e9382744ae\n'}, {'number': 22, 'created': '2015-06-24 20:22:40.000000000', 'files': ['requirements.txt', 'test-requirements.txt', 'setup.py'], 'web_link': 'https://opendev.org/openstack/rally/commit/f98b735cf56a51e80c36e40890563584095a89e3', 'message': 'Updated from global requirements\n\nChange-Id: I496909e3f6fed962c8443d13453ef8e9382744ae\n'}]",0,189463,f98b735cf56a51e80c36e40890563584095a89e3,75,5,22,11131,,,0,"Updated from global requirements

Change-Id: I496909e3f6fed962c8443d13453ef8e9382744ae
",git fetch https://review.opendev.org/openstack/rally refs/changes/63/189463/13 && git format-patch -1 --stdout FETCH_HEAD,"['requirements.txt', 'setup.py']",2,a9f9784a2969632b3473441e6f2c620afabaf487,fix_sqlalchemy,,"#import os if os.getuid() == 0: data_files = [ ('/etc/bash_completion.d', ['etc/rally.bash_completion']), ] else: data_files = [ ('etc/bash_completion.d', ['etc/rally.bash_completion']), ] data_files=data_files,",2,13
openstack%2Fkeystone~master~I9e40508304a964416edc771d75e470bf78ba35ac,openstack/keystone,master,I9e40508304a964416edc771d75e470bf78ba35ac,Update docs: xmlsec1 required for K2K,ABANDONED,2015-06-17 13:51:37.000000000,2015-06-25 10:29:35.000000000,,"[{'_account_id': 3}, {'_account_id': 6482}, {'_account_id': 7725}, {'_account_id': 8978}]","[{'number': 1, 'created': '2015-06-17 13:51:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/c52f8f357ed70093a98ff4cb777e789b4228b51b', 'message': 'Update docs: xmlsec1 requred for K2K\n\nWe should indicate, that xmlsec1 is required for Keystone Identity\nProvider only.\n\nChange-Id: I9e40508304a964416edc771d75e470bf78ba35ac\n'}, {'number': 2, 'created': '2015-06-17 13:52:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/9a45de8e208ad8e6a9c41c25397e5b1fc669047a', 'message': 'Update docs: xmlsec1 required for K2K\n\nWe should indicate, that xmlsec1 is required for Keystone Identity\nProvider only.\n\nChange-Id: I9e40508304a964416edc771d75e470bf78ba35ac\n'}, {'number': 3, 'created': '2015-06-22 13:38:58.000000000', 'files': ['doc/source/federation/federation.rst'], 'web_link': 'https://opendev.org/openstack/keystone/commit/5cddcff6c3d209075c8db51be9f62b7f4c3cb739', 'message': 'Update docs: xmlsec1 required for K2K\n\nWe should indicate, that xmlsec1 is required for Keystone Identity\nProvider only.\n\nChange-Id: I9e40508304a964416edc771d75e470bf78ba35ac\n'}]",3,192674,5cddcff6c3d209075c8db51be9f62b7f4c3cb739,12,4,3,8978,,,0,"Update docs: xmlsec1 required for K2K

We should indicate, that xmlsec1 is required for Keystone Identity
Provider only.

Change-Id: I9e40508304a964416edc771d75e470bf78ba35ac
",git fetch https://review.opendev.org/openstack/keystone refs/changes/74/192674/2 && git format-patch -1 --stdout FETCH_HEAD,['doc/source/federation/federation.rst'],1,c52f8f357ed70093a98ff4cb777e789b4228b51b,fix_docs, ============================ Keystone2Keystone Federation ============================ For keystone acting as an Identity Provider it is required to manually install ``xmlsec1`` binary. .. code-block:: bash $ apt-get install xmlsec1,,12,0
openstack%2Fneutron~master~I641ab092e0ea0aae67ec717b492118a2f8a6f4fd,openstack/neutron,master,I641ab092e0ea0aae67ec717b492118a2f8a6f4fd,Make DHCPv6 out of bounds API test deterministic,MERGED,2015-06-24 11:37:56.000000000,2015-06-25 10:29:15.000000000,2015-06-25 09:46:02.000000000,"[{'_account_id': 3}, {'_account_id': 5170}, {'_account_id': 5948}, {'_account_id': 6524}, {'_account_id': 7016}, {'_account_id': 7787}, {'_account_id': 9656}, {'_account_id': 9681}, {'_account_id': 9682}, {'_account_id': 9787}, {'_account_id': 9845}, {'_account_id': 10121}, {'_account_id': 10153}, {'_account_id': 10184}, {'_account_id': 10387}, {'_account_id': 10980}, {'_account_id': 14323}, {'_account_id': 14571}]","[{'number': 1, 'created': '2015-06-24 11:37:56.000000000', 'files': ['neutron/tests/api/test_dhcp_ipv6.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/a84ef9ae54a7dfe6d9dee54a01b189dd40bce423', 'message': 'Make DHCPv6 out of bounds API test deterministic\n\nThe test_dhcp_stateful_fixedips_outrange API test was randomly\npicking an IP from last + 1 up to last + 10 in the allocation\nrange. This made it fail randomly when there was an issue related\nto the subnet allocation having an off-by-one issue.\n\nThis adjusts the test to just always test last +1 and +2.\n\nRelated-Bug: #1468163\nChange-Id: I641ab092e0ea0aae67ec717b492118a2f8a6f4fd\n'}]",0,195045,a84ef9ae54a7dfe6d9dee54a01b189dd40bce423,29,18,1,7787,,,0,"Make DHCPv6 out of bounds API test deterministic

The test_dhcp_stateful_fixedips_outrange API test was randomly
picking an IP from last + 1 up to last + 10 in the allocation
range. This made it fail randomly when there was an issue related
to the subnet allocation having an off-by-one issue.

This adjusts the test to just always test last +1 and +2.

Related-Bug: #1468163
Change-Id: I641ab092e0ea0aae67ec717b492118a2f8a6f4fd
",git fetch https://review.opendev.org/openstack/neutron refs/changes/45/195045/1 && git format-patch -1 --stdout FETCH_HEAD,['neutron/tests/api/test_dhcp_ipv6.py'],1,a84ef9ae54a7dfe6d9dee54a01b189dd40bce423,bug/1468163," for i in range(1, 3): ip = netaddr.IPAddress(ip_range.last + i).format() self.assertRaises(lib_exc.BadRequest, self.create_port, self.network, fixed_ips=[{'subnet_id': subnet['id'], 'ip_address': ip}])"," ip = netaddr.IPAddress(random.randrange( ip_range.last + 1, ip_range.last + 10)).format() self.assertRaises(lib_exc.BadRequest, self.create_port, self.network, fixed_ips=[{'subnet_id': subnet['id'], 'ip_address': ip}])",7,7
openstack%2Fpuppet-gnocchi~master~I50e1776b32100cce557efc0042c15bf2db0e204d,openstack/puppet-gnocchi,master,I50e1776b32100cce557efc0042c15bf2db0e204d,lint: Fix lint issues (missing documentation for define types),ABANDONED,2015-06-25 09:42:12.000000000,2015-06-25 10:27:42.000000000,,"[{'_account_id': 3}, {'_account_id': 11491}]","[{'number': 1, 'created': '2015-06-25 09:42:12.000000000', 'files': ['manifests/generic_service.pp'], 'web_link': 'https://opendev.org/openstack/puppet-gnocchi/commit/669f2c90a0c62a20a9ac5b37766bda7e34eb5be4', 'message': ""lint: Fix lint issues (missing documentation for define types)\n\nThe gem 'puppet-lint-param-docs' was bumped to 1.2.0 and now handle\nclass and define type. This patch fix lint issues (missing documentation).\n\nChange-Id: I50e1776b32100cce557efc0042c15bf2db0e204d\n""}]",0,195486,669f2c90a0c62a20a9ac5b37766bda7e34eb5be4,3,2,1,7155,,,0,"lint: Fix lint issues (missing documentation for define types)

The gem 'puppet-lint-param-docs' was bumped to 1.2.0 and now handle
class and define type. This patch fix lint issues (missing documentation).

Change-Id: I50e1776b32100cce557efc0042c15bf2db0e204d
",git fetch https://review.opendev.org/openstack/puppet-gnocchi refs/changes/86/195486/1 && git format-patch -1 --stdout FETCH_HEAD,['manifests/generic_service.pp'],1,669f2c90a0c62a20a9ac5b37766bda7e34eb5be4,lint,# === Parameters: # # [*package_name*] # (mandatory) The package name (for the generic_service) # # [*service_name*] # (mandatory) The service name (for the generic_service) # # [*enabled*] # (optional) Define if the service must be enabled or not # Defaults to false. # # [*manage_service*] # (optional) Manage or not the service (if a service_name is provided). # Defaults to true. # # [*ensure_package*] # (optional) Control the ensure parameter for the package ressource. # Defaults to 'present'. #,,20,0
openstack%2Fceilometer~master~I50c8e97219da387362aef9d1ef4c53aea0c27142,openstack/ceilometer,master,I50c8e97219da387362aef9d1ef4c53aea0c27142,remove unused notifier,MERGED,2015-06-24 20:11:32.000000000,2015-06-25 10:10:29.000000000,2015-06-25 10:10:25.000000000,"[{'_account_id': 3}, {'_account_id': 1669}, {'_account_id': 4491}, {'_account_id': 8290}]","[{'number': 1, 'created': '2015-06-24 20:11:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/1fc8b5325836af048539b39778735f2b89b9cfcc', 'message': ""remove unused notifier\n\nthere's a notifier in our code. it doesn't seem to be connected to\nanything and is not accessible via setup.cfg. this appears to be\nresidual workaround from pre-oslo.messaging days\n\nChange-Id: I50c8e97219da387362aef9d1ef4c53aea0c27142\n""}, {'number': 2, 'created': '2015-06-25 02:43:57.000000000', 'files': ['ceilometer/notifier.py', 'tox.ini', 'ceilometer/tests/test_notifier.py'], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/965aca8a374ad36d2661b28cd6aec25e7d0e04d3', 'message': ""remove unused notifier\n\nthere's a notifier in our code. it doesn't seem to be connected to\nanything and is not accessible via setup.cfg. this appears to be\nresidual workaround from pre-oslo.messaging days\n\nChange-Id: I50c8e97219da387362aef9d1ef4c53aea0c27142\n""}]",0,195291,965aca8a374ad36d2661b28cd6aec25e7d0e04d3,13,4,2,6537,,,0,"remove unused notifier

there's a notifier in our code. it doesn't seem to be connected to
anything and is not accessible via setup.cfg. this appears to be
residual workaround from pre-oslo.messaging days

Change-Id: I50c8e97219da387362aef9d1ef4c53aea0c27142
",git fetch https://review.opendev.org/openstack/ceilometer refs/changes/91/195291/1 && git format-patch -1 --stdout FETCH_HEAD,"['ceilometer/notifier.py', 'ceilometer/tests/test_notifier.py']",2,1fc8b5325836af048539b39778735f2b89b9cfcc,remove-stuff,,"# # Copyright 2013 eNovance # # Licensed under the Apache License, Version 2.0 (the ""License""); you may # not use this file except in compliance with the License. You may obtain # a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT # WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the # License for the specific language governing permissions and limitations # under the License. """"""Tests for ceilometer/notifier.py """""" from oslotest import base from stevedore import extension from ceilometer import notifier from ceilometer import pipeline MESSAGE = { u'event_type': u'compute.instance.create.end', u'message_id': u'dae6f69c-00e0-41c0-b371-41ec3b7f4451', u'payload': {u'created_at': u'2012-05-08 20:23:41', u'deleted_at': u'', u'disk_gb': 0, u'display_name': u'testme', u'fixed_ips': [{u'address': u'10.0.0.2', u'floating_ips': [], u'meta': {}, u'type': u'fixed', u'version': 4}], u'image_ref_url': u'http://10.0.2.15:9292/images/UUID', u'instance_id': u'9f9d01b9-4a58-4271-9e27-398b21ab20d1', u'instance_type': u'm1.tiny', u'instance_type_id': 2, u'launched_at': u'2012-05-08 20:23:47.985999', u'memory_mb': 512, u'state': u'active', u'state_description': u'', u'tenant_id': u'7c150a59fe714e6f9263774af9688f0e', u'user_id': u'1e3ce043029547f1a61c1996d1a531a2', u'reservation_id': u'1e3ce043029547f1a61c1996d1a531a3', u'vcpus': 1, u'root_gb': 0, u'ephemeral_gb': 0, u'host': u'compute-host-name', u'availability_zone': u'1e3ce043029547f1a61c1996d1a531a4', u'os_type': u'linux?', u'architecture': u'x86', u'image_ref': u'UUID', u'kernel_id': u'1e3ce043029547f1a61c1996d1a531a5', u'ramdisk_id': u'1e3ce043029547f1a61c1996d1a531a6', }, u'priority': u'INFO', u'publisher_id': u'compute.vagrant-precise', u'timestamp': u'2012-05-08 20:23:48.028195', } class TestNotifier(base.BaseTestCase): def test_process_notification(self): transformer_manager = extension.ExtensionManager( 'ceilometer.transformer', ) notifier._pipeline_manager = pipeline.PipelineManager( [{ 'name': ""test_pipeline"", 'interval': 60, 'counters': ['*'], 'transformers': [], 'publishers': [""test""], }], transformer_manager) pub = notifier._pipeline_manager.pipelines[0].publishers[0] self.assertEqual(0, len(pub.samples)) notifier.notify(None, MESSAGE) self.assertTrue(len(pub.samples) > 0) self.assertIn('disk.ephemeral.size', [c.name for c in pub.samples]) ",0,153
openstack%2Fheat~stable%2Fkilo~If104037225905dc9c504972864270d6e68e08d73,openstack/heat,stable/kilo,If104037225905dc9c504972864270d6e68e08d73,Backup new resource as soon as possible,MERGED,2015-06-03 08:41:49.000000000,2015-06-25 10:02:28.000000000,2015-06-25 10:02:23.000000000,"[{'_account_id': 3}, {'_account_id': 4328}, {'_account_id': 4715}, {'_account_id': 6577}, {'_account_id': 9751}, {'_account_id': 10487}, {'_account_id': 14676}]","[{'number': 1, 'created': '2015-06-03 08:41:49.000000000', 'files': ['heat/engine/update.py', 'heat/tests/test_stack_update.py'], 'web_link': 'https://opendev.org/openstack/heat/commit/7148a964280a8518f9a6ecaed8c019306e81fb4a', 'message': 'Backup new resource as soon as possible\n\nThe root cause came discussion in\nhttps://review.openstack.org/#/c/175868/.\nIt is better to copy a new resources that appears during\nstack-update to backup stack as soon as possible because\nit reduces time when backup stack is not synchronized with\nthe existing stack.\n\nChange-Id: If104037225905dc9c504972864270d6e68e08d73\n(cherry picked from commit 3786262aed62d81ad35de3d4f703c38223907ffd)\n'}]",0,187909,7148a964280a8518f9a6ecaed8c019306e81fb4a,17,7,1,14676,,,0,"Backup new resource as soon as possible

The root cause came discussion in
https://review.openstack.org/#/c/175868/.
It is better to copy a new resources that appears during
stack-update to backup stack as soon as possible because
it reduces time when backup stack is not synchronized with
the existing stack.

Change-Id: If104037225905dc9c504972864270d6e68e08d73
(cherry picked from commit 3786262aed62d81ad35de3d4f703c38223907ffd)
",git fetch https://review.opendev.org/openstack/heat refs/changes/09/187909/1 && git format-patch -1 --stdout FETCH_HEAD,"['heat/engine/update.py', 'heat/tests/test_stack_update.py']",2,7148a964280a8518f9a6ecaed8c019306e81fb4a,kilo," def test_backup_stack_synchronized_after_update(self): """"""Test when backup stack updated correctly during stack update. Test checks the following scenario: 1. Create stack 2. Update stack (failed - so the backup should not be deleted) 3. Update stack (failed - so the backup from step 2 should be updated) The test checks that backup stack is synchronized with the main stack. """""" # create a stack tmpl_create = { 'heat_template_version': '2013-05-23', 'resources': { 'Ares': {'type': 'GenericResourceType'} } } self.stack = stack.Stack(self.ctx, 'test_update_stack_backup', template.Template(tmpl_create), disable_rollback=True) self.stack.store() self.stack.create() self.assertEqual((stack.Stack.CREATE, stack.Stack.COMPLETE), self.stack.state) # try to update a stack with a new resource that should be backed up tmpl_update = { 'heat_template_version': '2013-05-23', 'resources': { 'Ares': {'type': 'GenericResourceType'}, 'Bres': { 'type': 'ResWithComplexPropsAndAttrs', 'properties': { 'an_int': 0, } }, 'Cres': { 'type': 'ResourceWithPropsType', 'properties': { 'Foo': {'get_resource': 'Bres'}, } } } } self.patchobject(generic_rsrc.ResourceWithProps, 'handle_create', side_effect=[Exception, Exception]) stack_with_new_resource = stack.Stack( self.ctx, 'test_update_stack_backup', template.Template(tmpl_update)) self.stack.update(stack_with_new_resource) self.assertEqual((stack.Stack.UPDATE, stack.Stack.FAILED), self.stack.state) # assert that backup stack has been updated correctly self.assertIn('Bres', self.stack._backup_stack()) # update the stack with resource that updated in-place tmpl_update['resources']['Bres']['properties']['an_int'] = 1 updated_stack_second = stack.Stack(self.ctx, 'test_update_stack_backup', template.Template(tmpl_update)) self.stack.update(updated_stack_second) self.assertEqual((stack.Stack.UPDATE, stack.Stack.FAILED), self.stack.state) # assert that resource in backup stack also has been updated backup = self.stack._backup_stack() self.assertEqual(1, backup['Bres'].properties['an_int'])",,90,8
openstack%2Fheat~stable%2Fkilo~I436c44a579bb4df3031d1a17b9ca5b62da37afeb,openstack/heat,stable/kilo,I436c44a579bb4df3031d1a17b9ca5b62da37afeb,Save updated-in-place resources to backup stack,MERGED,2015-05-13 09:44:11.000000000,2015-06-25 10:00:01.000000000,2015-06-25 09:59:59.000000000,"[{'_account_id': 3}, {'_account_id': 4257}, {'_account_id': 4328}, {'_account_id': 4715}, {'_account_id': 6577}, {'_account_id': 8289}, {'_account_id': 9542}, {'_account_id': 9751}, {'_account_id': 10487}, {'_account_id': 14676}]","[{'number': 1, 'created': '2015-05-13 09:44:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/61040116a3ed98074f09cdef812708490cf4dd15', 'message': 'Save updated-in-place resources to backup stack\n\nThe patch changes the approach of resource backup during stack\nupdate. It stores the definition of resource that needs to be\nupdated in-place to backup stack(if it was not created before).\n\nWithout this functionality, InvalidTemplateReference will be thrown\nevery time when update-replaced resource has a reference to updated\nin-place resource and stack update was failed. In this case, backup\nstack has a resource that refers to not-presented another resource\nand backup stack deletion generates an exception.\n\nPlease also consider that some other components that use Heat\n(for example, Murano) are broken in some important cases\nwithout this fix.\n\nChange-Id: I436c44a579bb4df3031d1a17b9ca5b62da37afeb\nCloses-bug: #1446575\n(cherry picked from\n commit f2edd0d68ea84f8ca212df0ec1d6d92463a030aa)\n'}, {'number': 2, 'created': '2015-06-03 08:05:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/df2e84025146131a09a3181c704b25a94443701d', 'message': 'Save updated-in-place resources to backup stack\n\nThe patch changes the approach of resource backup during stack\nupdate. It stores the definition of resource that needs to be\nupdated in-place to backup stack(if it was not created before).\n\nWithout this functionality, InvalidTemplateReference will be thrown\nevery time when update-replaced resource has a reference to updated\nin-place resource and stack update was failed. In this case, backup\nstack has a resource that refers to not-presented another resource\nand backup stack deletion generates an exception.\n\nPlease also consider that some other components that use Heat\n(for example, Murano) are broken in some important cases\nwithout this fix.\n\nChange-Id: I436c44a579bb4df3031d1a17b9ca5b62da37afeb\nCloses-bug: #1446575\n(cherry picked from\n commit f2edd0d68ea84f8ca212df0ec1d6d92463a030aa\n commit 3786262aed62d81ad35de3d4f703c38223907ffd)\n'}, {'number': 3, 'created': '2015-06-03 08:41:49.000000000', 'files': ['heat/engine/update.py', 'heat/tests/test_stack_update.py'], 'web_link': 'https://opendev.org/openstack/heat/commit/da3777342a344a2dafb9244b7afca8722a398caa', 'message': 'Save updated-in-place resources to backup stack\n\nThe patch changes the approach of resource backup during stack\nupdate. It stores the definition of resource that needs to be\nupdated in-place to backup stack(if it was not created before).\n\nWithout this functionality, InvalidTemplateReference will be thrown\nevery time when update-replaced resource has a reference to updated\nin-place resource and stack update was failed. In this case, backup\nstack has a resource that refers to not-presented another resource\nand backup stack deletion generates an exception.\n\nChange-Id: I436c44a579bb4df3031d1a17b9ca5b62da37afeb\nCloses-bug: #1446575\n(cherry-picked from commit f2edd0d68ea84f8ca212df0ec1d6d92463a030aa)\n'}]",0,182599,da3777342a344a2dafb9244b7afca8722a398caa,37,10,3,14676,,,0,"Save updated-in-place resources to backup stack

The patch changes the approach of resource backup during stack
update. It stores the definition of resource that needs to be
updated in-place to backup stack(if it was not created before).

Without this functionality, InvalidTemplateReference will be thrown
every time when update-replaced resource has a reference to updated
in-place resource and stack update was failed. In this case, backup
stack has a resource that refers to not-presented another resource
and backup stack deletion generates an exception.

Change-Id: I436c44a579bb4df3031d1a17b9ca5b62da37afeb
Closes-bug: #1446575
(cherry-picked from commit f2edd0d68ea84f8ca212df0ec1d6d92463a030aa)
",git fetch https://review.opendev.org/openstack/heat refs/changes/99/182599/2 && git format-patch -1 --stdout FETCH_HEAD,"['heat/engine/update.py', 'heat/tests/test_stack_update.py']",2,61040116a3ed98074f09cdef812708490cf4dd15,kilo," def test_delete_stack_when_update_failed_twice(self): """"""Test when stack update failed twice and delete the stack. Test checks the following scenario: 1. Create stack 2. Update stack (failed) 3. Update stack (failed) 4. Delete stack The test checks the behavior of backup stack when update is failed. If some resources were not backed up correctly then test will fail. """""" tmpl_create = { 'heat_template_version': '2013-05-23', 'resources': { 'Ares': {'type': 'GenericResourceType'} } } # create a stack self.stack = stack.Stack(self.ctx, 'update_fail_test_stack', template.Template(tmpl_create), disable_rollback=True) self.stack.store() self.stack.create() self.assertEqual((stack.Stack.CREATE, stack.Stack.COMPLETE), self.stack.state) tmpl_update = { 'heat_template_version': '2013-05-23', 'resources': { 'Ares': {'type': 'GenericResourceType'}, 'Bres': {'type': 'GenericResourceType'}, 'Cres': { 'type': 'ResourceWithPropsType', 'properties': { 'Foo': {'get_resource': 'Bres'}, } } } } mock_create = self.patchobject( generic_rsrc.ResourceWithProps, 'handle_create', side_effect=[Exception, Exception]) updated_stack_first = stack.Stack(self.ctx, 'update_fail_test_stack', template.Template(tmpl_update)) self.stack.update(updated_stack_first) self.stack.resources['Cres'].resource_id_set('c_res') self.assertEqual((stack.Stack.UPDATE, stack.Stack.FAILED), self.stack.state) # try to update the stack again updated_stack_second = stack.Stack(self.ctx, 'update_fail_test_stack', template.Template(tmpl_update)) self.stack.update(updated_stack_second) self.assertEqual((stack.Stack.UPDATE, stack.Stack.FAILED), self.stack.state) self.assertEqual(mock_create.call_count, 2) # delete the failed stack self.stack.delete() self.assertEqual((stack.Stack.DELETE, stack.Stack.COMPLETE), self.stack.state)",,77,0
openstack%2Fcookbook-openstack-telemetry~master~Iab395042c34bceb1ce30e01d264276ef4cc8d251,openstack/cookbook-openstack-telemetry,master,Iab395042c34bceb1ce30e01d264276ef4cc8d251,Replace deprecated get_secret,MERGED,2015-06-22 20:46:26.000000000,2015-06-25 09:59:37.000000000,2015-06-25 09:59:37.000000000,"[{'_account_id': 3}, {'_account_id': 8112}, {'_account_id': 12323}]","[{'number': 1, 'created': '2015-06-22 20:46:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cookbook-openstack-telemetry/commit/a37a58931f558d516458f6455f0644b6d143209d', 'message': ""Replace deprecated get_secret\n\nUse get_password 'token' instead.\n\nChange-Id: Iab395042c34bceb1ce30e01d264276ef4cc8d251\nPartial-Bug: #1467662\n""}, {'number': 2, 'created': '2015-06-22 20:50:22.000000000', 'files': ['spec/spec_helper.rb', 'metadata.rb', 'recipes/common.rb', 'recipes/identity_registration.rb'], 'web_link': 'https://opendev.org/openstack/cookbook-openstack-telemetry/commit/7b4eed9eb593fce821dc007a1ad158166a5c94bd', 'message': ""Replace deprecated get_secret\n\nUse get_password 'token' instead.\n\nChange-Id: Iab395042c34bceb1ce30e01d264276ef4cc8d251\nPartial-Bug: #1467662\n""}]",0,194366,7b4eed9eb593fce821dc007a1ad158166a5c94bd,10,3,2,7128,,,0,"Replace deprecated get_secret

Use get_password 'token' instead.

Change-Id: Iab395042c34bceb1ce30e01d264276ef4cc8d251
Partial-Bug: #1467662
",git fetch https://review.opendev.org/openstack/cookbook-openstack-telemetry refs/changes/66/194366/1 && git format-patch -1 --stdout FETCH_HEAD,"['spec/spec_helper.rb', 'recipes/common.rb', 'recipes/identity_registration.rb']",3,a37a58931f558d516458f6455f0644b6d143209d,bug/1467662,"bootstrap_token = get_password 'token', 'openstack_identity_bootstrap_token'",bootstrap_token = get_secret 'openstack_identity_bootstrap_token',9,9
openstack%2Fcookbook-openstack-orchestration~master~I8a6a22751cfd3f262d44adaa7eb33ae0bcf9cffd,openstack/cookbook-openstack-orchestration,master,I8a6a22751cfd3f262d44adaa7eb33ae0bcf9cffd,Replace deprecated get_secret,MERGED,2015-06-22 20:44:14.000000000,2015-06-25 09:58:42.000000000,2015-06-25 09:58:40.000000000,"[{'_account_id': 3}, {'_account_id': 8112}, {'_account_id': 12323}]","[{'number': 1, 'created': '2015-06-22 20:44:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cookbook-openstack-orchestration/commit/5f240b677f6826ca3d964f511abd3ec3b1fc57ad', 'message': ""Replace deprecated get_secret\n\nUse get_password 'token' instead.\n\nChange-Id: I8a6a22751cfd3f262d44adaa7eb33ae0bcf9cffd\nPartial-Bug: #1467662\n""}, {'number': 2, 'created': '2015-06-22 20:53:44.000000000', 'files': ['spec/spec_helper.rb', 'metadata.rb', 'recipes/identity_registration.rb'], 'web_link': 'https://opendev.org/openstack/cookbook-openstack-orchestration/commit/b5fac0e02b5f5c541c6a16fe31ab8478c521db73', 'message': ""Replace deprecated get_secret\n\nUse get_password 'token' instead.\n\nChange-Id: I8a6a22751cfd3f262d44adaa7eb33ae0bcf9cffd\nPartial-Bug: #1467662\n""}]",0,194364,b5fac0e02b5f5c541c6a16fe31ab8478c521db73,11,3,2,7128,,,0,"Replace deprecated get_secret

Use get_password 'token' instead.

Change-Id: I8a6a22751cfd3f262d44adaa7eb33ae0bcf9cffd
Partial-Bug: #1467662
",git fetch https://review.opendev.org/openstack/cookbook-openstack-orchestration refs/changes/64/194364/1 && git format-patch -1 --stdout FETCH_HEAD,"['spec/spec_helper.rb', 'recipes/identity_registration.rb']",2,5f240b677f6826ca3d964f511abd3ec3b1fc57ad,bug/1467662,"token = get_password 'token', 'openstack_identity_bootstrap_token'",token = get_secret 'openstack_identity_bootstrap_token',3,3
openstack%2Fopenstack-manuals~master~I6b9a87c3ea3c6979d04f51eb082e14acc0334c5f,openstack/openstack-manuals,master,I6b9a87c3ea3c6979d04f51eb082e14acc0334c5f,Add Nova Scheduler IO Ops Weighter,MERGED,2015-06-25 03:07:05.000000000,2015-06-25 09:53:46.000000000,2015-06-25 09:29:02.000000000,"[{'_account_id': 3}, {'_account_id': 612}, {'_account_id': 7923}, {'_account_id': 13747}]","[{'number': 1, 'created': '2015-06-25 03:07:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/2e2feb1d65a0fd4548a9c4cd47441fb57dc6ad95', 'message': 'Add Nova Scheduler IO Ops Weighter\n\nAdd a new nova scheduler weighter, sort the filter\nhosts according to host io ops number, aims to\ninstances on light workload hosts.\n\nChange-Id: I6b9a87c3ea3c6979d04f51eb082e14acc0334c5f\nCloses-Bug: #1383178\n'}, {'number': 2, 'created': '2015-06-25 03:11:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/b95529853cb580d33413c91f4d0a4e2b01e208b0', 'message': 'Add Nova Scheduler IO Ops Weighter\n\nAdd a new nova scheduler weighter, sort the filter\nhosts according to host io ops number, aims to\ninstances on light workload hosts.\n\nChange-Id: I6b9a87c3ea3c6979d04f51eb082e14acc0334c5f\nCloses-Bug: #1383178\n'}, {'number': 3, 'created': '2015-06-25 03:28:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/dc50a392cdfa52873c2014c6ca172af9b444b470', 'message': 'Add Nova Scheduler IO Ops Weighter\n\nAdd a new nova scheduler weighter, sort the filter\nhosts according to host io ops number, aims to\ninstances on light workload hosts.\n\nChange-Id: I6b9a87c3ea3c6979d04f51eb082e14acc0334c5f\nCloses-Bug: #1383178\n'}, {'number': 4, 'created': '2015-06-25 06:05:01.000000000', 'files': ['doc/config-reference/compute/section_compute-scheduler.xml'], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/1a80a7173566cbd58086be880574b7d3261faff7', 'message': 'Add Nova Scheduler IO Ops Weighter\n\nAdd a new nova scheduler weighter, sort the filter\nhosts according to host io ops number, aims to\ninstances on light workload hosts.\n\nChange-Id: I6b9a87c3ea3c6979d04f51eb082e14acc0334c5f\nCloses-Bug: #1383178\n'}]",2,195393,1a80a7173566cbd58086be880574b7d3261faff7,14,4,4,13747,,,0,"Add Nova Scheduler IO Ops Weighter

Add a new nova scheduler weighter, sort the filter
hosts according to host io ops number, aims to
instances on light workload hosts.

Change-Id: I6b9a87c3ea3c6979d04f51eb082e14acc0334c5f
Closes-Bug: #1383178
",git fetch https://review.opendev.org/openstack/openstack-manuals refs/changes/93/195393/4 && git format-patch -1 --stdout FETCH_HEAD,['doc/config-reference/compute/section_compute-scheduler.xml'],1,2e2feb1d65a0fd4548a9c4cd47441fb57dc6ad95,bug/1383178," <tr valign=""top""> <td>[metrics]</td> <td><literal>io_ops_weight_multiplier</literal></td> <td>Multiplier used for weighing host io ops. Negative numbers mean a preference to choose light workload compute hosts. </td> </tr>io_ops_weight_multiplier = 2.0",,9,0
openstack%2Fcookbook-openstack-identity~master~I708e65d959fbe909b73df897bf1e150d231b7c8b,openstack/cookbook-openstack-identity,master,I708e65d959fbe909b73df897bf1e150d231b7c8b,Replace deprecated get_secret,MERGED,2015-06-22 20:35:04.000000000,2015-06-25 09:51:37.000000000,2015-06-25 09:51:35.000000000,"[{'_account_id': 3}, {'_account_id': 8112}, {'_account_id': 9488}]","[{'number': 1, 'created': '2015-06-22 20:35:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cookbook-openstack-identity/commit/0df037c390c157086d051e9d771b5cdaf9c08545', 'message': ""Replace deprecated get_secret\n\nUse get_password 'token' instead.\n\nChange-Id: I708e65d959fbe909b73df897bf1e150d231b7c8b\nPartial-Bug: #1467662\n""}, {'number': 2, 'created': '2015-06-22 20:52:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cookbook-openstack-identity/commit/ec0727619c3640dcb9f8a53ebbf95e5e415f9545', 'message': ""Replace deprecated get_secret\n\nUse get_password 'token' instead.\n\nChange-Id: I708e65d959fbe909b73df897bf1e150d231b7c8b\nPartial-Bug: #1467662\n""}, {'number': 3, 'created': '2015-06-24 18:54:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cookbook-openstack-identity/commit/53bf54202136edbe207b1ce5aeb18e83467f97a5', 'message': ""Replace deprecated get_secret\n\nUse get_password 'token' instead.\n\nChange-Id: I708e65d959fbe909b73df897bf1e150d231b7c8b\nPartial-Bug: #1467662\n""}, {'number': 4, 'created': '2015-06-24 19:08:43.000000000', 'files': ['recipes/server-apache.rb', 'recipes/registration.rb', 'spec/spec_helper.rb', 'metadata.rb', 'recipes/server.rb'], 'web_link': 'https://opendev.org/openstack/cookbook-openstack-identity/commit/b4d2d310e71d071ccc42d0f8431e3ce953e28b76', 'message': ""Replace deprecated get_secret\n\nUse get_password 'token' instead.\n\nChange-Id: I708e65d959fbe909b73df897bf1e150d231b7c8b\nPartial-Bug: #1467662\n""}]",0,194356,b4d2d310e71d071ccc42d0f8431e3ce953e28b76,14,3,4,7128,,,0,"Replace deprecated get_secret

Use get_password 'token' instead.

Change-Id: I708e65d959fbe909b73df897bf1e150d231b7c8b
Partial-Bug: #1467662
",git fetch https://review.opendev.org/openstack/cookbook-openstack-identity refs/changes/56/194356/2 && git format-patch -1 --stdout FETCH_HEAD,"['recipes/registration.rb', 'spec/spec_helper.rb', 'recipes/server.rb']",3,0df037c390c157086d051e9d771b5cdaf9c08545,bug/1467662,"bootstrap_token = get_password 'token', 'openstack_identity_bootstrap_token'",bootstrap_token = get_secret 'openstack_identity_bootstrap_token',4,4
openstack%2Fmistral~master~If13139910fcb58c03fce845b03af338f82f87af3,openstack/mistral,master,If13139910fcb58c03fce845b03af338f82f87af3,Set default log level of loopingcall module to 'INFO',MERGED,2015-06-25 09:10:35.000000000,2015-06-25 09:45:25.000000000,2015-06-25 09:45:18.000000000,"[{'_account_id': 3}, {'_account_id': 7700}, {'_account_id': 8731}]","[{'number': 1, 'created': '2015-06-25 09:10:35.000000000', 'files': ['mistral/config.py'], 'web_link': 'https://opendev.org/openstack/mistral/commit/3ba958ae2b9a7beb02faee8b2937bbf3043c69e8', 'message': ""Set default log level of loopingcall module to 'INFO'\n\nBecause we introduced oslo_service.loopingcall module in Mistral, just as\nthe oslo_service.periodic module, we should set the default log level to\n'INFO' to avoid annoying logs.\n\nChange-Id: If13139910fcb58c03fce845b03af338f82f87af3\n""}]",0,195464,3ba958ae2b9a7beb02faee8b2937bbf3043c69e8,7,3,1,6732,,,0,"Set default log level of loopingcall module to 'INFO'

Because we introduced oslo_service.loopingcall module in Mistral, just as
the oslo_service.periodic module, we should set the default log level to
'INFO' to avoid annoying logs.

Change-Id: If13139910fcb58c03fce845b03af338f82f87af3
",git fetch https://review.opendev.org/openstack/mistral refs/changes/64/195464/1 && git format-patch -1 --stdout FETCH_HEAD,['mistral/config.py'],1,3ba958ae2b9a7beb02faee8b2937bbf3043c69e8,bug/suppress-oslo-service-log," 'oslo_service.loopingcall=INFO',",,1,0
openstack%2Fdiskimage-builder~master~I8113563586fd0b29eeed4d7e3d083b0b4ff975cb,openstack/diskimage-builder,master,I8113563586fd0b29eeed4d7e3d083b0b4ff975cb,Fix partition table creation,ABANDONED,2015-04-16 09:22:00.000000000,2015-06-25 09:44:55.000000000,,"[{'_account_id': 3}, {'_account_id': 6488}, {'_account_id': 6796}, {'_account_id': 7102}, {'_account_id': 10035}]","[{'number': 1, 'created': '2015-04-16 09:22:00.000000000', 'files': ['elements/vm/block-device.d/10-partition'], 'web_link': 'https://opendev.org/openstack/diskimage-builder/commit/fed69f8d7ee1595dd28413816646114a50e3eaee', 'message': 'Fix partition table creation\n\nUsing sfdisk from util-linux 2.26.1 leads to a problem with the first\ngiven command.\nUse a format which works with util-linux 2.20 (tested on Ubuntu 14.04)\nand 2.26.1 (tested on openSUSE Tumbleweed).\n\nChange-Id: I8113563586fd0b29eeed4d7e3d083b0b4ff975cb\nCloses-Bug: #1444496\n'}]",2,174272,fed69f8d7ee1595dd28413816646114a50e3eaee,13,5,1,7102,,,0,"Fix partition table creation

Using sfdisk from util-linux 2.26.1 leads to a problem with the first
given command.
Use a format which works with util-linux 2.20 (tested on Ubuntu 14.04)
and 2.26.1 (tested on openSUSE Tumbleweed).

Change-Id: I8113563586fd0b29eeed4d7e3d083b0b4ff975cb
Closes-Bug: #1444496
",git fetch https://review.opendev.org/openstack/diskimage-builder refs/changes/72/174272/1 && git format-patch -1 --stdout FETCH_HEAD,['elements/vm/block-device.d/10-partition'],1,fed69f8d7ee1595dd28413816646114a50e3eaee,bug/1444496," sudo sfdisk -u S --force /dev/loop0 <<EOF 16065,,,*", sudo sfdisk $IMAGE_BLOCK_DEVICE << EOF 1 - - * 0 0; 0 0; 0 0;,2,5
openstack%2Ffuel-web~master~I62f230e07398b2ce8639e6e444b82c77a5c296b3,openstack/fuel-web,master,I62f230e07398b2ce8639e6e444b82c77a5c296b3,Prepare Alembic migrations for Fuel 7.0,MERGED,2015-06-24 09:26:28.000000000,2015-06-25 09:43:43.000000000,2015-06-25 09:25:01.000000000,"[{'_account_id': 3}, {'_account_id': 8392}, {'_account_id': 8749}, {'_account_id': 8829}, {'_account_id': 8907}, {'_account_id': 8971}, {'_account_id': 10391}, {'_account_id': 10959}, {'_account_id': 11577}, {'_account_id': 12200}, {'_account_id': 14167}]","[{'number': 1, 'created': '2015-06-24 09:26:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/8d25828fd861e68a77d2ff4e10c58c19dc2546e1', 'message': ""Prepare Alembic migrations for Fuel 7.0\n\nThere are two reasons why it's useful to prepare Fuel 7.0 migration file\nat the beginning of development. Here they are:\n\n1/ Having the fuel_7_0.py migration will protect us from mass merge\n   conflicts when we start merging various features into master. Why?\n   Because devs will extend already existing migration file, and\n   each one won't create fuel_7_0.py file.\n\n2/ We want to cover our migration mishits - apparently, database state\n   after migration doesn't fit state declared in ORM. The fuel_7_0.py\n   fixes this.\n\nCloses-Bug: #1468250\n\nChange-Id: I62f230e07398b2ce8639e6e444b82c77a5c296b3\nSigned-off-by: Igor Kalnitsky <igor@kalnitsky.org>\n""}, {'number': 2, 'created': '2015-06-24 14:20:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/bea33fea760321218e5f789f0e5e541e77c58f3e', 'message': ""Prepare Alembic migrations for Fuel 7.0\n\nThere are two reasons why it's useful to prepare Fuel 7.0 migration file\nat the beginning of development. Here they are:\n\n1/ Having the fuel_7_0.py migration will protect us from mass merge\n   conflicts when we start merging various features into master. Why?\n   Because devs will extend already existing migration file, and\n   each one won't create fuel_7_0.py file.\n\n2/ We want to cover our migration mishits - apparently, database state\n   after migration doesn't fit state declared in ORM. The fuel_7_0.py\n   fixes this.\n\nCloses-Bug: #1468250\n\nChange-Id: I62f230e07398b2ce8639e6e444b82c77a5c296b3\nSigned-off-by: Igor Kalnitsky <igor@kalnitsky.org>\n""}, {'number': 3, 'created': '2015-06-24 14:58:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/eb57e34a25459214661342b4e14dc59bc44f57a9', 'message': ""Prepare Alembic migrations for Fuel 7.0\n\nThere are two reasons why it's useful to prepare Fuel 7.0 migration file\nat the beginning of development. Here they are:\n\n1/ Having the fuel_7_0.py migration will protect us from mass merge\n   conflicts when we start merging various features into master. Why?\n   Because devs will extend already existing migration file, and\n   each one won't create fuel_7_0.py file.\n\n2/ We want to cover our migration mishits - apparently, database state\n   after migration doesn't fit state declared in ORM. The fuel_7_0.py\n   fixes this.\n\nCloses-Bug: #1468250\n\nChange-Id: I62f230e07398b2ce8639e6e444b82c77a5c296b3\nSigned-off-by: Igor Kalnitsky <igor@kalnitsky.org>\n""}, {'number': 4, 'created': '2015-06-24 16:05:56.000000000', 'files': ['nailgun/nailgun/db/migration/alembic_migrations/versions/fuel_7_0.py', 'nailgun/nailgun/db/sqlalchemy/models/__init__.py'], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/b132b59cff261c6db43a3d2fc1f72e82b1117c58', 'message': ""Prepare Alembic migrations for Fuel 7.0\n\nThere are two reasons why it's useful to prepare Fuel 7.0 migration file\nat the beginning of development. Here they are:\n\n1/ Having the fuel_7_0.py migration will protect us from mass merge\n   conflicts when we start merging various features into master. Why?\n   Because devs will extend already existing migration file, and\n   each one won't create fuel_7_0.py file.\n\n2/ We want to cover our migration mishits - apparently, database state\n   after migration doesn't fit state declared in ORM. The fuel_7_0.py\n   fixes this.\n\nCloses-Bug: #1468250\n\nChange-Id: I62f230e07398b2ce8639e6e444b82c77a5c296b3\nSigned-off-by: Igor Kalnitsky <igor@kalnitsky.org>\n""}]",0,195006,b132b59cff261c6db43a3d2fc1f72e82b1117c58,33,11,4,10391,,,0,"Prepare Alembic migrations for Fuel 7.0

There are two reasons why it's useful to prepare Fuel 7.0 migration file
at the beginning of development. Here they are:

1/ Having the fuel_7_0.py migration will protect us from mass merge
   conflicts when we start merging various features into master. Why?
   Because devs will extend already existing migration file, and
   each one won't create fuel_7_0.py file.

2/ We want to cover our migration mishits - apparently, database state
   after migration doesn't fit state declared in ORM. The fuel_7_0.py
   fixes this.

Closes-Bug: #1468250

Change-Id: I62f230e07398b2ce8639e6e444b82c77a5c296b3
Signed-off-by: Igor Kalnitsky <igor@kalnitsky.org>
",git fetch https://review.opendev.org/openstack/fuel-web refs/changes/06/195006/4 && git format-patch -1 --stdout FETCH_HEAD,"['nailgun/nailgun/db/migration/alembic_migrations/versions/fuel_7_0.py', 'nailgun/nailgun/db/sqlalchemy/models/__init__.py']",2,8d25828fd861e68a77d2ff4e10c58c19dc2546e1,fuel_7_0-migration, from nailgun.db.sqlalchemy.models.plugins import ClusterPlugins from nailgun.db.sqlalchemy.models.plugins import Plugin,,56,0
openstack%2Fswift~master~Ib7c298f0f6d666b1ecca25315b88539f45cf9f95,openstack/swift,master,Ib7c298f0f6d666b1ecca25315b88539f45cf9f95,Add policy support to dispersion tools,MERGED,2015-05-25 21:46:28.000000000,2015-06-25 09:42:02.000000000,2015-06-25 09:42:00.000000000,"[{'_account_id': 3}, {'_account_id': 4608}, {'_account_id': 7233}, {'_account_id': 7479}, {'_account_id': 7847}, {'_account_id': 15932}]","[{'number': 1, 'created': '2015-05-25 21:46:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/faff9e74e6ab7c9392b2ba6646c5e3ad676b5f3f', 'message': ""Add policy support to dispersion tools\n\nDoesn't work for anything other than policy 0. updated to allow user\nto specify policy name on cmd line (as with object-info) which\nthen makes populate/report work with 3x, 2x, or EC style policies\n\nChange-Id: Ib7c298f0f6d666b1ecca25315b88539f45cf9f95\nCloses-Bug: 1458688\n""}, {'number': 2, 'created': '2015-05-28 13:49:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/248e2aa237129dff3d8d7f78a221fd4a2b512646', 'message': ""Add policy support to dispersion tools\n\nDoesn't work for anything other than policy 0. updated to allow user\nto specify policy name on cmd line (as with object-info) which\nthen makes populate/report work with 3x, 2x, or EC style policies\n\nChange-Id: Ib7c298f0f6d666b1ecca25315b88539f45cf9f95\nCloses-Bug: 1458688\n""}, {'number': 3, 'created': '2015-06-13 19:52:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/ae26ebf4433b90cc7d07a27f90aef231f1fb4dcb', 'message': ""Add policy support to dispersion tools\n\nDoesn't work for anything other than policy 0. updated to allow user\nto specify policy name on cmd line (as with object-info) which\nthen makes populate/report work with 3x, 2x, or EC style policies\n\nChange-Id: Ib7c298f0f6d666b1ecca25315b88539f45cf9f95\nCloses-Bug: 1458688\n""}, {'number': 4, 'created': '2015-06-23 21:52:40.000000000', 'files': ['bin/swift-dispersion-report', 'bin/swift-dispersion-populate', 'doc/source/admin_guide.rst'], 'web_link': 'https://opendev.org/openstack/swift/commit/e6165a7879d796efd3992260ef23a7f95ceeab32', 'message': ""Add policy support to dispersion tools\n\nDoesn't work for anything other than policy 0. updated to allow user\nto specify policy name on cmd line (as with object-info) which\nthen makes populate/report work with 3x, 2x, or EC style policies\n\nChange-Id: Ib7c298f0f6d666b1ecca25315b88539f45cf9f95\nCloses-Bug: 1458688\n""}]",6,185459,e6165a7879d796efd3992260ef23a7f95ceeab32,23,6,4,7479,,,0,"Add policy support to dispersion tools

Doesn't work for anything other than policy 0. updated to allow user
to specify policy name on cmd line (as with object-info) which
then makes populate/report work with 3x, 2x, or EC style policies

Change-Id: Ib7c298f0f6d666b1ecca25315b88539f45cf9f95
Closes-Bug: 1458688
",git fetch https://review.opendev.org/openstack/swift refs/changes/59/185459/1 && git format-patch -1 --stdout FETCH_HEAD,"['bin/swift-dispersion-report', 'bin/swift-dispersion-populate']",2,faff9e74e6ab7c9392b2ba6646c5e3ad676b5f3f,bug/1458688,"from swift.common.storage_policy import POLICIESdef put_container(connpool, container, report, headers): conn.put_container(container, headers=headers) parser.add_option('-P', '--policy-name', dest='policy_name', help=""Specify storage policy name"") if options.policy_name is None: policy = POLICIES.legacy else: policy = POLICIES.get_by_name(options.policy_name) if policy is None: exit('Unable to find policy: %s' % options.policy_name) print 'Using storage policy: %s ' % policy.name headers = {} headers['X-Storage-Policy'] = policy.name coropool.spawn(put_container, connpool, container, report, headers) put_container(connpool, container, None, headers=headers) object_ring = Ring(swift_dir, ring_name=policy.ring_name)","def put_container(connpool, container, report): conn.put_container(container) coropool.spawn(put_container, connpool, container, report) put_container(connpool, container, None) object_ring = Ring(swift_dir, ring_name='object')",47,12
openstack%2Fopenstack-doc-tools~master~I821889967cbfe21694a21caa66408616e9fec861,openstack/openstack-doc-tools,master,I821889967cbfe21694a21caa66408616e9fec861,Support 'murano' in openstack-auto-commands,MERGED,2015-06-24 13:05:05.000000000,2015-06-25 09:38:12.000000000,2015-06-25 09:38:08.000000000,"[{'_account_id': 3}, {'_account_id': 612}, {'_account_id': 6547}, {'_account_id': 7549}]","[{'number': 1, 'created': '2015-06-24 13:05:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-doc-tools/commit/0a879f2b472defec1825e0b745e259a23bb0a8a4', 'message': ""Support 'murano' in openstack-auto-commands\n\nChange-Id: I821889967cbfe21694a21caa66408616e9fec861\n""}, {'number': 2, 'created': '2015-06-24 14:59:06.000000000', 'files': ['os_doc_tools/resources/clients.yaml', 'os_doc_tools/commands.py'], 'web_link': 'https://opendev.org/openstack/openstack-doc-tools/commit/17c1e9fa2665e7c66fa8a01df600cba8a1164729', 'message': ""Support 'murano' in openstack-auto-commands\n\nChange-Id: I821889967cbfe21694a21caa66408616e9fec861\n""}]",2,195067,17c1e9fa2665e7c66fa8a01df600cba8a1164729,11,4,2,7549,,,0,"Support 'murano' in openstack-auto-commands

Change-Id: I821889967cbfe21694a21caa66408616e9fec861
",git fetch https://review.opendev.org/openstack/openstack-doc-tools refs/changes/67/195067/2 && git format-patch -1 --stdout FETCH_HEAD,"['os_doc_tools/resources/clients.yaml', 'os_doc_tools/commands.py']",2,0a879f2b472defec1825e0b745e259a23bb0a8a4,add-murano," if os_command == 'murano': out_file.write("""""" <section xml:id=\""murano_cli_v1\""> <title>Application catalog API v1 commands</title>\n"""""")", generate_end(out_file) out_file.close() ,6,4
openstack%2Fcookbook-openstack-image~master~I8c9ff7cb17fa1d945e794ee386d24c393ef97a10,openstack/cookbook-openstack-image,master,I8c9ff7cb17fa1d945e794ee386d24c393ef97a10,Replace deprecated get_secret,MERGED,2015-06-22 20:37:32.000000000,2015-06-25 09:21:13.000000000,2015-06-25 09:21:12.000000000,"[{'_account_id': 3}, {'_account_id': 8112}, {'_account_id': 9488}]","[{'number': 1, 'created': '2015-06-22 20:37:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cookbook-openstack-image/commit/6b88aaae5279d616946a14557caa5e3946e1574a', 'message': ""Replace deprecated get_secret\n\nUse get_password 'token' instead.\n\nPartial-Bug: #1467662\n\nChange-Id: I8c9ff7cb17fa1d945e794ee386d24c393ef97a10\n""}, {'number': 2, 'created': '2015-06-22 20:52:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cookbook-openstack-image/commit/cf423eae64b68ac1cdd548c9b60680e8534c0ce1', 'message': ""Replace deprecated get_secret\n\nUse get_password 'token' instead.\n\nPartial-Bug: #1467662\n\nChange-Id: I8c9ff7cb17fa1d945e794ee386d24c393ef97a10\n""}, {'number': 3, 'created': '2015-06-24 03:49:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cookbook-openstack-image/commit/6146a90e45cc9a38f1c7a329694937c701cb40c7', 'message': ""Replace deprecated get_secret\n\nUse get_password 'token' instead.\n\nPartial-Bug: #1467662\n\nChange-Id: I8c9ff7cb17fa1d945e794ee386d24c393ef97a10\n""}, {'number': 4, 'created': '2015-06-24 18:52:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cookbook-openstack-image/commit/cf789fce25585d8ed7b060a9b858179e999b4521', 'message': ""Replace deprecated get_secret\n\nUse get_password 'token' instead.\n\nPartial-Bug: #1467662\n\nChange-Id: I8c9ff7cb17fa1d945e794ee386d24c393ef97a10\n""}, {'number': 5, 'created': '2015-06-25 01:26:27.000000000', 'files': ['spec/spec_helper.rb', 'spec/api_spec.rb', 'recipes/api.rb', 'metadata.rb', 'recipes/identity_registration.rb'], 'web_link': 'https://opendev.org/openstack/cookbook-openstack-image/commit/abc47a3bb55ea63d2136d5b2c391529a84ac0df0', 'message': ""Replace deprecated get_secret\n\nUse get_password 'token' instead.\n\nPartial-Bug: #1467662\n\nChange-Id: I8c9ff7cb17fa1d945e794ee386d24c393ef97a10\n""}]",0,194358,abc47a3bb55ea63d2136d5b2c391529a84ac0df0,16,3,5,7128,,,0,"Replace deprecated get_secret

Use get_password 'token' instead.

Partial-Bug: #1467662

Change-Id: I8c9ff7cb17fa1d945e794ee386d24c393ef97a10
",git fetch https://review.opendev.org/openstack/cookbook-openstack-image refs/changes/58/194358/4 && git format-patch -1 --stdout FETCH_HEAD,"['spec/spec_helper.rb', 'recipes/api.rb', 'recipes/identity_registration.rb']",3,6b88aaae5279d616946a14557caa5e3946e1574a,bug/1467662,"token = get_password 'token', 'openstack_identity_bootstrap_token'",token = get_secret 'openstack_identity_bootstrap_token',6,6
openstack%2Fnetworking-midonet~master~I37c5c058e55f62f00e982c33692d57f28270bd0f,openstack/networking-midonet,master,I37c5c058e55f62f00e982c33692d57f28270bd0f,Add epoch :1 on packaging,MERGED,2015-06-25 08:08:32.000000000,2015-06-25 09:16:02.000000000,2015-06-25 09:15:58.000000000,"[{'_account_id': 3}, {'_account_id': 156}, {'_account_id': 1935}]","[{'number': 1, 'created': '2015-06-25 08:08:32.000000000', 'files': ['packaging/deb/package_deb.sh', 'packaging/rpm/python-networking-midonet.spec'], 'web_link': 'https://opendev.org/openstack/networking-midonet/commit/88a95709e02010ad89a2b0ce1594e54ac4faf9b5', 'message': ""Add epoch :1 on packaging\n\nDue legacy 'fpm' package creation, we have to set the epoch of the\npackage as '1' for updates.\n\nChange-Id: I37c5c058e55f62f00e982c33692d57f28270bd0f\n""}]",1,195444,88a95709e02010ad89a2b0ce1594e54ac4faf9b5,9,3,1,7505,,,0,"Add epoch :1 on packaging

Due legacy 'fpm' package creation, we have to set the epoch of the
package as '1' for updates.

Change-Id: I37c5c058e55f62f00e982c33692d57f28270bd0f
",git fetch https://review.opendev.org/openstack/networking-midonet refs/changes/44/195444/1 && git format-patch -1 --stdout FETCH_HEAD,"['packaging/deb/package_deb.sh', 'packaging/rpm/python-networking-midonet.spec']",2,88a95709e02010ad89a2b0ce1594e54ac4faf9b5,,Epoch: 1,,2,1
openstack%2Ffuel-docs~stable%2F6.1~Ic0bc99a5d0af7c0e870509f77df17c311cf56b90,openstack/fuel-docs,stable/6.1,Ic0bc99a5d0af7c0e870509f77df17c311cf56b90,6.1 -- Consume External Ubuntu,ABANDONED,2015-06-19 10:35:51.000000000,2015-06-25 09:14:52.000000000,,"[{'_account_id': 3}, {'_account_id': 406}, {'_account_id': 1531}, {'_account_id': 7195}, {'_account_id': 8786}, {'_account_id': 8829}, {'_account_id': 8971}, {'_account_id': 9977}, {'_account_id': 10391}, {'_account_id': 10474}, {'_account_id': 12866}, {'_account_id': 13082}, {'_account_id': 13695}, {'_account_id': 14342}, {'_account_id': 15454}]","[{'number': 1, 'created': '2015-06-19 10:35:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-docs/commit/77f8b3a49412e40747a7abf578f9bce286c159fb', 'message': '6.1 -- Consume External Ubuntu\n\nAdd instructions on how change a path for\nUbuntu system packages.\nAdd to new features that the Ubuntu\nsystem packages can now be downloaded\nfrom official Ubuntu mirrors or\nfrom internal repos.\n\nChange-Id: Ic0bc99a5d0af7c0e870509f77df17c311cf56b90\n(cherry picked from commit 59116537e3bfdce1cddc537315e84b0b6ed088f3)\n'}, {'number': 2, 'created': '2015-06-19 10:38:54.000000000', 'files': ['_images/externalUbuntu.png', 'pages/release-notes/v6-1/new-features/ubuntu-downloadable.rst', 'pages/release-notes/v6-1/new-features/ubuntu-14-04.rst', 'contents/contents-refarch.rst', 'pages/operations/external-ubuntu-ops.rst', 'pages/reference-architecture/fuel-rep-mirror.rst', 'contents/contents-operations.rst'], 'web_link': 'https://opendev.org/openstack/fuel-docs/commit/86a98f821432c6bc14490f11f9c1434e8ea0f63d', 'message': '6.1 -- Consume External Ubuntu\n\nAdd instructions on how change a path for\nUbuntu system packages.\nAdd to new features that the Ubuntu\nsystem packages can now be downloaded\nfrom official Ubuntu mirrors or\nfrom internal repos.\n\nCloses-Bug:#1457949\nChange-Id: Ic0bc99a5d0af7c0e870509f77df17c311cf56b90\n(cherry picked from commit 59116537e3bfdce1cddc537315e84b0b6ed088f3)\n'}]",0,193490,86a98f821432c6bc14490f11f9c1434e8ea0f63d,13,15,2,11969,,,0,"6.1 -- Consume External Ubuntu

Add instructions on how change a path for
Ubuntu system packages.
Add to new features that the Ubuntu
system packages can now be downloaded
from official Ubuntu mirrors or
from internal repos.

Closes-Bug:#1457949
Change-Id: Ic0bc99a5d0af7c0e870509f77df17c311cf56b90
(cherry picked from commit 59116537e3bfdce1cddc537315e84b0b6ed088f3)
",git fetch https://review.opendev.org/openstack/fuel-docs refs/changes/90/193490/1 && git format-patch -1 --stdout FETCH_HEAD,"['_images/externalUbuntu.png', 'pages/release-notes/v6-1/new-features/ubuntu-downloadable.rst', 'pages/release-notes/v6-1/new-features/ubuntu-14-04.rst', 'contents/contents-refarch.rst', 'pages/operations/external-ubuntu-ops.rst', 'pages/reference-architecture/fuel-rep-mirror.rst', 'contents/contents-operations.rst']",7,77f8b3a49412e40747a7abf578f9bce286c159fb,,.. include:: /pages/operations/external-ubuntu-ops.rst,,327,7
openstack%2Fpython-keystoneclient~master~Idd3b7d730b70ecf4fa6be911078d02e8bdfc9f37,openstack/python-keystoneclient,master,Idd3b7d730b70ecf4fa6be911078d02e8bdfc9f37,Remove keystoneclient.middleware,ABANDONED,2015-06-17 16:15:13.000000000,2015-06-25 09:09:47.000000000,,"[{'_account_id': 3}, {'_account_id': 6486}, {'_account_id': 8122}, {'_account_id': 9107}]","[{'number': 1, 'created': '2015-06-17 16:15:13.000000000', 'files': ['requirements.txt', 'keystoneclient/middleware/memcache_crypt.py', 'test-requirements.txt', 'examples/pki/gen_pki.sh', 'keystoneclient/tests/unit/test_auth_token_middleware.py', 'keystoneclient/tests/unit/test_s3_token_middleware.py', 'keystoneclient/middleware/__init__.py', 'keystoneclient/tests/unit/test_memcache_crypt.py', 'keystoneclient/middleware/s3_token.py', 'examples/pki/run_all.sh', 'keystoneclient/middleware/auth_token.py'], 'web_link': 'https://opendev.org/openstack/python-keystoneclient/commit/96207228af4da1fbeb9b68f369b059155c787aba', 'message': ""Remove keystoneclient.middleware\n\nThe code has been moved to the new keystonemiddleware project and\nkeystone.middleware was deprecated since Juno. It's time to drop it in\nLiberty.\n\nRemove the directory keystoneclient/middleware/.\n\nRemove test_auth_token_middleware.py, test_memcache_crypt.py and\ntest_s3_token_middleware.py in keystoneclient/tests/unit/.\n\nRemove the create_middleware_cert shell function from\nexamples/pki/gen_pki.sh. And remove the call from\nexamples/pki/run_all.sh.\n\nRemove netaddr, pycrypto and WebOb test dependencies, only needed to\ntest the removed middleware.\n\nDocImpact: The keystoneclient.middleware module has been removed\n\nChange-Id: Idd3b7d730b70ecf4fa6be911078d02e8bdfc9f37\nCloses-Bug: #1449066\n""}]",0,192752,96207228af4da1fbeb9b68f369b059155c787aba,12,4,1,9107,,,0,"Remove keystoneclient.middleware

The code has been moved to the new keystonemiddleware project and
keystone.middleware was deprecated since Juno. It's time to drop it in
Liberty.

Remove the directory keystoneclient/middleware/.

Remove test_auth_token_middleware.py, test_memcache_crypt.py and
test_s3_token_middleware.py in keystoneclient/tests/unit/.

Remove the create_middleware_cert shell function from
examples/pki/gen_pki.sh. And remove the call from
examples/pki/run_all.sh.

Remove netaddr, pycrypto and WebOb test dependencies, only needed to
test the removed middleware.

DocImpact: The keystoneclient.middleware module has been removed

Change-Id: Idd3b7d730b70ecf4fa6be911078d02e8bdfc9f37
Closes-Bug: #1449066
",git fetch https://review.opendev.org/openstack/python-keystoneclient refs/changes/52/192752/1 && git format-patch -1 --stdout FETCH_HEAD,"['requirements.txt', 'keystoneclient/middleware/memcache_crypt.py', 'test-requirements.txt', 'examples/pki/gen_pki.sh', 'keystoneclient/tests/unit/test_auth_token_middleware.py', 'keystoneclient/tests/unit/test_s3_token_middleware.py', 'keystoneclient/middleware/__init__.py', 'keystoneclient/middleware/s3_token.py', 'keystoneclient/tests/unit/test_memcache_crypt.py', 'examples/pki/run_all.sh', 'keystoneclient/middleware/auth_token.py']",11,96207228af4da1fbeb9b68f369b059155c787aba,bug/1449066,,"# Copyright 2010-2012 OpenStack Foundation # # Licensed under the Apache License, Version 2.0 (the ""License""); # you may not use this file except in compliance with the License. # You may obtain a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or # implied. # See the License for the specific language governing permissions and # limitations under the License. """""" TOKEN-BASED AUTH MIDDLEWARE .. warning:: This module is DEPRECATED. The auth_token middleware has been moved to the `keystonemiddleware repository <http://docs.openstack.org/developer/keystonemiddleware/>`_. This WSGI component: * Verifies that incoming client requests have valid tokens by validating tokens with the auth service. * Rejects unauthenticated requests UNLESS it is in 'delay_auth_decision' mode, which means the final decision is delegated to the downstream WSGI component (usually the OpenStack service) * Collects and forwards identity information based on a valid token such as user name, tenant, etc HEADERS ------- * Headers starting with HTTP\_ is a standard http header * Headers starting with HTTP_X is an extended http header Coming in from initial call from client or customer ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ HTTP_X_AUTH_TOKEN The client token being passed in. HTTP_X_STORAGE_TOKEN The client token being passed in (legacy Rackspace use) to support swift/cloud files Used for communication between components ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ WWW-Authenticate HTTP header returned to a user indicating which endpoint to use to retrieve a new token What we add to the request for use by the OpenStack service ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ HTTP_X_IDENTITY_STATUS 'Confirmed' or 'Invalid' The underlying service will only see a value of 'Invalid' if the Middleware is configured to run in 'delay_auth_decision' mode HTTP_X_DOMAIN_ID Identity service managed unique identifier, string. Only present if this is a domain-scoped v3 token. HTTP_X_DOMAIN_NAME Unique domain name, string. Only present if this is a domain-scoped v3 token. HTTP_X_PROJECT_ID Identity service managed unique identifier, string. Only present if this is a project-scoped v3 token, or a tenant-scoped v2 token. HTTP_X_PROJECT_NAME Project name, unique within owning domain, string. Only present if this is a project-scoped v3 token, or a tenant-scoped v2 token. HTTP_X_PROJECT_DOMAIN_ID Identity service managed unique identifier of owning domain of project, string. Only present if this is a project-scoped v3 token. If this variable is set, this indicates that the PROJECT_NAME can only be assumed to be unique within this domain. HTTP_X_PROJECT_DOMAIN_NAME Name of owning domain of project, string. Only present if this is a project-scoped v3 token. If this variable is set, this indicates that the PROJECT_NAME can only be assumed to be unique within this domain. HTTP_X_USER_ID Identity-service managed unique identifier, string HTTP_X_USER_NAME User identifier, unique within owning domain, string HTTP_X_USER_DOMAIN_ID Identity service managed unique identifier of owning domain of user, string. If this variable is set, this indicates that the USER_NAME can only be assumed to be unique within this domain. HTTP_X_USER_DOMAIN_NAME Name of owning domain of user, string. If this variable is set, this indicates that the USER_NAME can only be assumed to be unique within this domain. HTTP_X_ROLES Comma delimited list of case-sensitive role names HTTP_X_SERVICE_CATALOG json encoded keystone service catalog (optional). For compatibility reasons this catalog will always be in the V2 catalog format even if it is a v3 token. HTTP_X_TENANT_ID *Deprecated* in favor of HTTP_X_PROJECT_ID Identity service managed unique identifier, string. For v3 tokens, this will be set to the same value as HTTP_X_PROJECT_ID HTTP_X_TENANT_NAME *Deprecated* in favor of HTTP_X_PROJECT_NAME Project identifier, unique within owning domain, string. For v3 tokens, this will be set to the same value as HTTP_X_PROJECT_NAME HTTP_X_TENANT *Deprecated* in favor of HTTP_X_TENANT_ID and HTTP_X_TENANT_NAME Keystone-assigned unique identifier, string. For v3 tokens, this will be set to the same value as HTTP_X_PROJECT_ID HTTP_X_USER *Deprecated* in favor of HTTP_X_USER_ID and HTTP_X_USER_NAME User name, unique within owning domain, string HTTP_X_ROLE *Deprecated* in favor of HTTP_X_ROLES Will contain the same values as HTTP_X_ROLES. OTHER ENVIRONMENT VARIABLES --------------------------- keystone.token_info Information about the token discovered in the process of validation. This may include extended information returned by the Keystone token validation call, as well as basic information about the tenant and user. """""" import contextlib import datetime import logging import os import stat import tempfile import time import netaddr from oslo_config import cfg from oslo_serialization import jsonutils from oslo_utils import timeutils import requests import six from six.moves import urllib from keystoneclient import access from keystoneclient.common import cms from keystoneclient import exceptions from keystoneclient.middleware import memcache_crypt from keystoneclient.openstack.common import memorycache # alternative middleware configuration in the main application's # configuration file e.g. in nova.conf # [keystone_authtoken] # auth_host = 127.0.0.1 # auth_port = 35357 # auth_protocol = http # admin_tenant_name = admin # admin_user = admin # admin_password = badpassword # when deploy Keystone auth_token middleware with Swift, user may elect # to use Swift memcache instead of the local Keystone memcache. Swift memcache # is passed in from the request environment and its identified by the # 'swift.cache' key. However it could be different, depending on deployment. # To use Swift memcache, you must set the 'cache' option to the environment # key where the Swift cache object is stored. # NOTE(jamielennox): A number of options below are deprecated however are left # in the list and only mentioned as deprecated in the help string. This is # because we have to provide the same deprecation functionality for arguments # passed in via the conf in __init__ (from paste) and there is no way to test # that the default value was set or not in CONF. # Also if we were to remove the options from the CONF list (as typical CONF # deprecation works) then other projects will not be able to override the # options via CONF. opts = [ cfg.StrOpt('auth_admin_prefix', default='', help='Prefix to prepend at the beginning of the path. ' 'Deprecated, use identity_uri.'), cfg.StrOpt('auth_host', default='127.0.0.1', help='Host providing the admin Identity API endpoint. ' 'Deprecated, use identity_uri.'), cfg.IntOpt('auth_port', default=35357, help='Port of the admin Identity API endpoint. ' 'Deprecated, use identity_uri.'), cfg.StrOpt('auth_protocol', default='https', help='Protocol of the admin Identity API endpoint ' '(http or https). Deprecated, use identity_uri.'), cfg.StrOpt('auth_uri', default=None, # FIXME(dolph): should be default='http://127.0.0.1:5000/v2.0/', # or (depending on client support) an unversioned, publicly # accessible identity endpoint (see bug 1207517) help='Complete public Identity API endpoint'), cfg.StrOpt('identity_uri', default=None, help='Complete admin Identity API endpoint. This should ' 'specify the unversioned root endpoint ' 'e.g. https://localhost:35357/'), cfg.StrOpt('auth_version', default=None, help='API version of the admin Identity API endpoint'), cfg.BoolOpt('delay_auth_decision', default=False, help='Do not handle authorization requests within the' ' middleware, but delegate the authorization decision to' ' downstream WSGI components'), cfg.BoolOpt('http_connect_timeout', default=None, help='Request timeout value for communicating with Identity' ' API server.'), cfg.IntOpt('http_request_max_retries', default=3, help='How many times are we trying to reconnect when' ' communicating with Identity API Server.'), cfg.StrOpt('admin_token', secret=True, help='This option is deprecated and may be removed in a future' ' release. Single shared secret with the Keystone configuration' ' used for bootstrapping a Keystone installation, or otherwise' ' bypassing the normal authentication process. This option' ' should not be used, use `admin_user` and `admin_password`' ' instead.'), cfg.StrOpt('admin_user', help='Keystone account username'), cfg.StrOpt('admin_password', secret=True, help='Keystone account password'), cfg.StrOpt('admin_tenant_name', default='admin', help='Keystone service account tenant name to validate' ' user tokens'), cfg.StrOpt('cache', default=None, help='Env key for the swift cache'), cfg.StrOpt('certfile', help='Required if Keystone server requires client certificate'), cfg.StrOpt('keyfile', help='Required if Keystone server requires client certificate'), cfg.StrOpt('cafile', default=None, help='A PEM encoded Certificate Authority to use when ' 'verifying HTTPs connections. Defaults to system CAs.'), cfg.BoolOpt('insecure', default=False, help='Verify HTTPS connections.'), cfg.StrOpt('signing_dir', help='Directory used to cache files related to PKI tokens'), cfg.ListOpt('memcached_servers', deprecated_name='memcache_servers', help='Optionally specify a list of memcached server(s) to' ' use for caching. If left undefined, tokens will instead be' ' cached in-process.'), cfg.IntOpt('token_cache_time', default=300, help='In order to prevent excessive effort spent validating' ' tokens, the middleware caches previously-seen tokens for a' ' configurable duration (in seconds). Set to -1 to disable' ' caching completely.'), cfg.IntOpt('revocation_cache_time', default=10, help='Determines the frequency at which the list of revoked' ' tokens is retrieved from the Identity service (in seconds). A' ' high number of revocation events combined with a low cache' ' duration may significantly reduce performance.'), cfg.StrOpt('memcache_security_strategy', default=None, help='(optional) if defined, indicate whether token data' ' should be authenticated or authenticated and encrypted.' ' Acceptable values are MAC or ENCRYPT. If MAC, token data is' ' authenticated (with HMAC) in the cache. If ENCRYPT, token' ' data is encrypted and authenticated in the cache. If the' ' value is not one of these options or empty, auth_token will' ' raise an exception on initialization.'), cfg.StrOpt('memcache_secret_key', default=None, secret=True, help='(optional, mandatory if memcache_security_strategy is' ' defined) this string is used for key derivation.'), cfg.BoolOpt('include_service_catalog', default=True, help='(optional) indicate whether to set the X-Service-Catalog' ' header. If False, middleware will not ask for service' ' catalog on token validation and will not set the' ' X-Service-Catalog header.'), cfg.StrOpt('enforce_token_bind', default='permissive', help='Used to control the use and type of token binding. Can' ' be set to: ""disabled"" to not check token binding.' ' ""permissive"" (default) to validate binding information if the' ' bind type is of a form known to the server and ignore it if' ' not. ""strict"" like ""permissive"" but if the bind type is' ' unknown the token will be rejected. ""required"" any form of' ' token binding is needed to be allowed. Finally the name of a' ' binding method that must be present in tokens.'), cfg.BoolOpt('check_revocations_for_cached', default=False, help='If true, the revocation list will be checked for cached' ' tokens. This requires that PKI tokens are configured on the' ' Keystone server.'), cfg.ListOpt('hash_algorithms', default=['md5'], help='Hash algorithms to use for hashing PKI tokens. This may' ' be a single algorithm or multiple. The algorithms are those' ' supported by Python standard hashlib.new(). The hashes will' ' be tried in the order given, so put the preferred one first' ' for performance. The result of the first hash will be stored' ' in the cache. This will typically be set to multiple values' ' only while migrating from a less secure algorithm to a more' ' secure one. Once all the old tokens are expired this option' ' should be set to a single value for better performance.'), ] CONF = cfg.CONF CONF.register_opts(opts, group='keystone_authtoken') LIST_OF_VERSIONS_TO_ATTEMPT = ['v2.0', 'v3.0'] CACHE_KEY_TEMPLATE = 'tokens/%s' class BIND_MODE(object): DISABLED = 'disabled' PERMISSIVE = 'permissive' STRICT = 'strict' REQUIRED = 'required' KERBEROS = 'kerberos' def will_expire_soon(expiry): """"""Determines if expiration is about to occur. :param expiry: a datetime of the expected expiration :returns: boolean : true if expiration is within 30 seconds """""" soon = (timeutils.utcnow() + datetime.timedelta(seconds=30)) return expiry < soon def _token_is_v2(token_info): return ('access' in token_info) def _token_is_v3(token_info): return ('token' in token_info) def confirm_token_not_expired(data): if not data: raise InvalidUserToken('Token authorization failed') if _token_is_v2(data): timestamp = data['access']['token']['expires'] elif _token_is_v3(data): timestamp = data['token']['expires_at'] else: raise InvalidUserToken('Token authorization failed') expires = timeutils.parse_isotime(timestamp) expires = timeutils.normalize_time(expires) utcnow = timeutils.utcnow() if utcnow >= expires: raise InvalidUserToken('Token authorization failed') return timeutils.isotime(at=expires, subsecond=True) def _v3_to_v2_catalog(catalog): """"""Convert a catalog to v2 format. X_SERVICE_CATALOG must be specified in v2 format. If you get a token that is in v3 convert it. """""" v2_services = [] for v3_service in catalog: # first copy over the entries we allow for the service v2_service = {'type': v3_service['type']} try: v2_service['name'] = v3_service['name'] except KeyError: pass # now convert the endpoints. Because in v3 we specify region per # URL not per group we have to collect all the entries of the same # region together before adding it to the new service. regions = {} for v3_endpoint in v3_service.get('endpoints', []): region_name = v3_endpoint.get('region') try: region = regions[region_name] except KeyError: region = {'region': region_name} if region_name else {} regions[region_name] = region interface_name = v3_endpoint['interface'].lower() + 'URL' region[interface_name] = v3_endpoint['url'] v2_service['endpoints'] = list(regions.values()) v2_services.append(v2_service) return v2_services def safe_quote(s): """"""URL-encode strings that are not already URL-encoded."""""" return urllib.parse.quote(s) if s == urllib.parse.unquote(s) else s def _conf_values_type_convert(conf): """"""Convert conf values into correct type."""""" if not conf: return {} _opts = {} opt_types = dict((o.dest, getattr(o, 'type', str)) for o in opts) for k, v in six.iteritems(conf): try: if v is None: _opts[k] = v else: _opts[k] = opt_types[k](v) except KeyError: _opts[k] = v except ValueError as e: raise ConfigurationError( 'Unable to convert the value of %s option into correct ' 'type: %s' % (k, e)) return _opts class InvalidUserToken(Exception): pass class ServiceError(Exception): pass class ConfigurationError(Exception): pass class NetworkError(Exception): pass class MiniResp(object): def __init__(self, error_message, env, headers=[]): # The HEAD method is unique: it must never return a body, even if # it reports an error (RFC-2616 clause 9.4). We relieve callers # from varying the error responses depending on the method. if env['REQUEST_METHOD'] == 'HEAD': self.body = [''] else: self.body = [error_message] self.headers = list(headers) self.headers.append(('Content-type', 'text/plain')) class AuthProtocol(object): """"""Auth Middleware that handles authenticating client calls."""""" def __init__(self, app, conf): self.LOG = logging.getLogger(conf.get('log_name', __name__)) self.LOG.info('Starting keystone auth_token middleware') self.LOG.warning( 'This middleware module is deprecated as of v0.10.0 in favor of ' 'keystonemiddleware.auth_token - please update your WSGI pipeline ' 'to reference the new middleware package.') # NOTE(wanghong): If options are set in paste file, all the option # values passed into conf are string type. So, we should convert the # conf value into correct type. self.conf = _conf_values_type_convert(conf) self.app = app # delay_auth_decision means we still allow unauthenticated requests # through and we let the downstream service make the final decision self.delay_auth_decision = (self._conf_get('delay_auth_decision') in (True, 'true', 't', '1', 'on', 'yes', 'y')) # where to find the auth service (we use this to validate tokens) self.identity_uri = self._conf_get('identity_uri') self.auth_uri = self._conf_get('auth_uri') # NOTE(jamielennox): it does appear here that our defaults arguments # are backwards. We need to do it this way so that we can handle the # same deprecation strategy for CONF and the conf variable. if not self.identity_uri: self.LOG.warning('Configuring admin URI using auth fragments. ' 'This is deprecated, use \'identity_uri\'' ' instead.') auth_host = self._conf_get('auth_host') auth_port = int(self._conf_get('auth_port')) auth_protocol = self._conf_get('auth_protocol') auth_admin_prefix = self._conf_get('auth_admin_prefix') if netaddr.valid_ipv6(auth_host): # Note(dzyu) it is an IPv6 address, so it needs to be wrapped # with '[]' to generate a valid IPv6 URL, based on # http://www.ietf.org/rfc/rfc2732.txt auth_host = '[%s]' % auth_host self.identity_uri = '%s://%s:%s' % (auth_protocol, auth_host, auth_port) if auth_admin_prefix: self.identity_uri = '%s/%s' % (self.identity_uri, auth_admin_prefix.strip('/')) else: self.identity_uri = self.identity_uri.rstrip('/') if self.auth_uri is None: self.LOG.warning( 'Configuring auth_uri to point to the public identity ' 'endpoint is required; clients may not be able to ' 'authenticate against an admin endpoint') # FIXME(dolph): drop support for this fallback behavior as # documented in bug 1207517. # NOTE(jamielennox): we urljoin '/' to get just the base URI as # this is the original behaviour. self.auth_uri = urllib.parse.urljoin(self.identity_uri, '/') self.auth_uri = self.auth_uri.rstrip('/') # SSL self.cert_file = self._conf_get('certfile') self.key_file = self._conf_get('keyfile') self.ssl_ca_file = self._conf_get('cafile') self.ssl_insecure = self._conf_get('insecure') # signing self.signing_dirname = self._conf_get('signing_dir') if self.signing_dirname is None: self.signing_dirname = tempfile.mkdtemp(prefix='keystone-signing-') self.LOG.info('Using %s as cache directory for signing certificate', self.signing_dirname) self.verify_signing_dir() val = '%s/signing_cert.pem' % self.signing_dirname self.signing_cert_file_name = val val = '%s/cacert.pem' % self.signing_dirname self.signing_ca_file_name = val val = '%s/revoked.pem' % self.signing_dirname self.revoked_file_name = val # Credentials used to verify this component with the Auth service since # validating tokens is a privileged call self.admin_token = self._conf_get('admin_token') if self.admin_token: self.LOG.warning( ""The admin_token option in the auth_token middleware is "" ""deprecated and should not be used. The admin_user and "" ""admin_password options should be used instead. The "" ""admin_token option may be removed in a future release."") self.admin_token_expiry = None self.admin_user = self._conf_get('admin_user') self.admin_password = self._conf_get('admin_password') self.admin_tenant_name = self._conf_get('admin_tenant_name') memcache_security_strategy = ( self._conf_get('memcache_security_strategy')) self._token_cache = TokenCache( self.LOG, cache_time=int(self._conf_get('token_cache_time')), hash_algorithms=self._conf_get('hash_algorithms'), env_cache_name=self._conf_get('cache'), memcached_servers=self._conf_get('memcached_servers'), memcache_security_strategy=memcache_security_strategy, memcache_secret_key=self._conf_get('memcache_secret_key')) self._token_revocation_list = None self._token_revocation_list_fetched_time = None self.token_revocation_list_cache_timeout = datetime.timedelta( seconds=self._conf_get('revocation_cache_time')) http_connect_timeout_cfg = self._conf_get('http_connect_timeout') self.http_connect_timeout = (http_connect_timeout_cfg and int(http_connect_timeout_cfg)) self.auth_version = None self.http_request_max_retries = ( self._conf_get('http_request_max_retries')) self.include_service_catalog = self._conf_get( 'include_service_catalog') self.check_revocations_for_cached = self._conf_get( 'check_revocations_for_cached') def _conf_get(self, name): # try config from paste-deploy first if name in self.conf: return self.conf[name] else: return CONF.keystone_authtoken[name] def _choose_api_version(self): """"""Determine the api version that we should use."""""" # If the configuration specifies an auth_version we will just # assume that is correct and use it. We could, of course, check # that this version is supported by the server, but in case # there are some problems in the field, we want as little code # as possible in the way of letting auth_token talk to the # server. if self._conf_get('auth_version'): version_to_use = self._conf_get('auth_version') self.LOG.info('Auth Token proceeding with requested %s apis', version_to_use) else: version_to_use = None versions_supported_by_server = self._get_supported_versions() if versions_supported_by_server: for version in LIST_OF_VERSIONS_TO_ATTEMPT: if version in versions_supported_by_server: version_to_use = version break if version_to_use: self.LOG.info('Auth Token confirmed use of %s apis', version_to_use) else: self.LOG.error( 'Attempted versions [%s] not in list supported by ' 'server [%s]', ', '.join(LIST_OF_VERSIONS_TO_ATTEMPT), ', '.join(versions_supported_by_server)) raise ServiceError('No compatible apis supported by server') return version_to_use def _get_supported_versions(self): versions = [] response, data = self._json_request('GET', '/') if response.status_code == 501: self.LOG.warning('Old keystone installation found...assuming v2.0') versions.append('v2.0') elif response.status_code != 300: self.LOG.error('Unable to get version info from keystone: %s', response.status_code) raise ServiceError('Unable to get version info from keystone') else: try: for version in data['versions']['values']: versions.append(version['id']) except KeyError: self.LOG.error( 'Invalid version response format from server') raise ServiceError('Unable to parse version response ' 'from keystone') self.LOG.debug('Server reports support for api versions: %s', ', '.join(versions)) return versions def __call__(self, env, start_response): """"""Handle incoming request. Authenticate send downstream on success. Reject request if we can't authenticate. """""" self.LOG.debug('Authenticating user token') self._token_cache.initialize(env) try: self._remove_auth_headers(env) user_token = self._get_user_token_from_header(env) token_info = self._validate_user_token(user_token, env) env['keystone.token_info'] = token_info user_headers = self._build_user_headers(token_info) self._add_headers(env, user_headers) return self.app(env, start_response) except InvalidUserToken: if self.delay_auth_decision: self.LOG.info( 'Invalid user token - deferring reject downstream') self._add_headers(env, {'X-Identity-Status': 'Invalid'}) return self.app(env, start_response) else: self.LOG.info('Invalid user token - rejecting request') return self._reject_request(env, start_response) except ServiceError as e: self.LOG.critical('Unable to obtain admin token: %s', e) resp = MiniResp('Service unavailable', env) start_response('503 Service Unavailable', resp.headers) return resp.body def _remove_auth_headers(self, env): """"""Remove headers so a user can't fake authentication. :param env: wsgi request environment """""" auth_headers = ( 'X-Identity-Status', 'X-Domain-Id', 'X-Domain-Name', 'X-Project-Id', 'X-Project-Name', 'X-Project-Domain-Id', 'X-Project-Domain-Name', 'X-User-Id', 'X-User-Name', 'X-User-Domain-Id', 'X-User-Domain-Name', 'X-Roles', 'X-Service-Catalog', # Deprecated 'X-User', 'X-Tenant-Id', 'X-Tenant-Name', 'X-Tenant', 'X-Role', ) self.LOG.debug('Removing headers from request environment: %s', ','.join(auth_headers)) self._remove_headers(env, auth_headers) def _get_user_token_from_header(self, env): """"""Get token id from request. :param env: wsgi request environment :return token id :raises InvalidUserToken if no token is provided in request """""" token = self._get_header(env, 'X-Auth-Token', self._get_header(env, 'X-Storage-Token')) if token: return token else: if not self.delay_auth_decision: self.LOG.warning('Unable to find authentication token' ' in headers') self.LOG.debug('Headers: %s', env) raise InvalidUserToken('Unable to find token in headers') def _reject_request(self, env, start_response): """"""Redirect client to auth server. :param env: wsgi request environment :param start_response: wsgi response callback :returns HTTPUnauthorized http response """""" headers = [('WWW-Authenticate', 'Keystone uri=\'%s\'' % self.auth_uri)] resp = MiniResp('Authentication required', env, headers) start_response('401 Unauthorized', resp.headers) return resp.body def get_admin_token(self): """"""Return admin token, possibly fetching a new one. if self.admin_token_expiry is set from fetching an admin token, check it for expiration, and request a new token is the existing token is about to expire. :return admin token id :raise ServiceError when unable to retrieve token from keystone """""" if self.admin_token_expiry: if will_expire_soon(self.admin_token_expiry): self.admin_token = None if not self.admin_token: (self.admin_token, self.admin_token_expiry) = self._request_admin_token() return self.admin_token def _http_request(self, method, path, **kwargs): """"""HTTP request helper used to make unspecified content type requests. :param method: http method :param path: relative request url :return (http response object, response body) :raise ServerError when unable to communicate with keystone """""" url = '%s/%s' % (self.identity_uri, path.lstrip('/')) kwargs.setdefault('timeout', self.http_connect_timeout) if self.cert_file and self.key_file: kwargs['cert'] = (self.cert_file, self.key_file) elif self.cert_file or self.key_file: self.LOG.warning('Cannot use only a cert or key file. ' 'Please provide both. Ignoring.') kwargs['verify'] = self.ssl_ca_file or True if self.ssl_insecure: kwargs['verify'] = False RETRIES = self.http_request_max_retries retry = 0 while True: try: response = requests.request(method, url, **kwargs) break except Exception as e: if retry >= RETRIES: self.LOG.error('HTTP connection exception: %s', e) raise NetworkError('Unable to communicate with keystone') # NOTE(vish): sleep 0.5, 1, 2 self.LOG.warning('Retrying on HTTP connection exception: %s', e) time.sleep(2.0 ** retry / 2) retry += 1 return response def _json_request(self, method, path, body=None, additional_headers=None): """"""HTTP request helper used to make json requests. :param method: http method :param path: relative request url :param body: dict to encode to json as request body. Optional. :param additional_headers: dict of additional headers to send with http request. Optional. :return (http response object, response body parsed as json) :raise ServerError when unable to communicate with keystone """""" kwargs = { 'headers': { 'Content-type': 'application/json', 'Accept': 'application/json', }, } if additional_headers: kwargs['headers'].update(additional_headers) if body: kwargs['data'] = jsonutils.dumps(body) response = self._http_request(method, path, **kwargs) try: data = jsonutils.loads(response.text) except ValueError: self.LOG.debug('Keystone did not return json-encoded body') data = {} return response, data def _request_admin_token(self): """"""Retrieve new token as admin user from keystone. :return token id upon success :raises ServerError when unable to communicate with keystone Irrespective of the auth version we are going to use for the user token, for simplicity we always use a v2 admin token to validate the user token. """""" params = { 'auth': { 'passwordCredentials': { 'username': self.admin_user, 'password': self.admin_password, }, 'tenantName': self.admin_tenant_name, } } response, data = self._json_request('POST', '/v2.0/tokens', body=params) try: token = data['access']['token']['id'] expiry = data['access']['token']['expires'] if not (token and expiry): raise AssertionError('invalid token or expire') datetime_expiry = timeutils.parse_isotime(expiry) return (token, timeutils.normalize_time(datetime_expiry)) except (AssertionError, KeyError): self.LOG.warning( 'Unexpected response from keystone service: %s', data) raise ServiceError('invalid json response') except (ValueError): data['access']['token']['id'] = '<SANITIZED>' self.LOG.warning( 'Unable to parse expiration time from token: %s', data) raise ServiceError('invalid json response') def _validate_user_token(self, user_token, env, retry=True): """"""Authenticate user token :param user_token: user's token id :param retry: Ignored, as it is not longer relevant :return uncrypted body of the token if the token is valid :raise InvalidUserToken if token is rejected :no longer raises ServiceError since it no longer makes RPC """""" token_id = None try: token_ids, cached = self._token_cache.get(user_token) token_id = token_ids[0] if cached: data = cached if self.check_revocations_for_cached: # A token stored in Memcached might have been revoked # regardless of initial mechanism used to validate it, # and needs to be checked. for tid in token_ids: is_revoked = self._is_token_id_in_revoked_list(tid) if is_revoked: self.LOG.debug( 'Token is marked as having been revoked') raise InvalidUserToken( 'Token authorization failed') elif cms.is_pkiz(user_token): verified = self.verify_pkiz_token(user_token, token_ids) data = jsonutils.loads(verified) elif cms.is_asn1_token(user_token): verified = self.verify_signed_token(user_token, token_ids) data = jsonutils.loads(verified) else: data = self.verify_uuid_token(user_token, retry) expires = confirm_token_not_expired(data) self._confirm_token_bind(data, env) self._token_cache.store(token_id, data, expires) return data except NetworkError: self.LOG.debug('Token validation failure.', exc_info=True) self.LOG.warning('Authorization failed for token') raise InvalidUserToken('Token authorization failed') except Exception: self.LOG.debug('Token validation failure.', exc_info=True) if token_id: self._token_cache.store_invalid(token_id) self.LOG.warning('Authorization failed for token') raise InvalidUserToken('Token authorization failed') def _build_user_headers(self, token_info): """"""Convert token object into headers. Build headers that represent authenticated user - see main doc info at start of file for details of headers to be defined. :param token_info: token object returned by keystone on authentication :raise InvalidUserToken when unable to parse token object """""" auth_ref = access.AccessInfo.factory(body=token_info) roles = ','.join(auth_ref.role_names) if _token_is_v2(token_info) and not auth_ref.project_id: raise InvalidUserToken('Unable to determine tenancy.') rval = { 'X-Identity-Status': 'Confirmed', 'X-Domain-Id': auth_ref.domain_id, 'X-Domain-Name': auth_ref.domain_name, 'X-Project-Id': auth_ref.project_id, 'X-Project-Name': auth_ref.project_name, 'X-Project-Domain-Id': auth_ref.project_domain_id, 'X-Project-Domain-Name': auth_ref.project_domain_name, 'X-User-Id': auth_ref.user_id, 'X-User-Name': auth_ref.username, 'X-User-Domain-Id': auth_ref.user_domain_id, 'X-User-Domain-Name': auth_ref.user_domain_name, 'X-Roles': roles, # Deprecated 'X-User': auth_ref.username, 'X-Tenant-Id': auth_ref.project_id, 'X-Tenant-Name': auth_ref.project_name, 'X-Tenant': auth_ref.project_name, 'X-Role': roles, } self.LOG.debug('Received request from user: %s with project_id : %s' ' and roles: %s ', auth_ref.user_id, auth_ref.project_id, roles) if self.include_service_catalog and auth_ref.has_service_catalog(): catalog = auth_ref.service_catalog.get_data() if _token_is_v3(token_info): catalog = _v3_to_v2_catalog(catalog) rval['X-Service-Catalog'] = jsonutils.dumps(catalog) return rval def _header_to_env_var(self, key): """"""Convert header to wsgi env variable. :param key: http header name (ex. 'X-Auth-Token') :return wsgi env variable name (ex. 'HTTP_X_AUTH_TOKEN') """""" return 'HTTP_%s' % key.replace('-', '_').upper() def _add_headers(self, env, headers): """"""Add http headers to environment."""""" for (k, v) in six.iteritems(headers): env_key = self._header_to_env_var(k) env[env_key] = v def _remove_headers(self, env, keys): """"""Remove http headers from environment."""""" for k in keys: env_key = self._header_to_env_var(k) try: del env[env_key] except KeyError: pass def _get_header(self, env, key, default=None): """"""Get http header from environment."""""" env_key = self._header_to_env_var(key) return env.get(env_key, default) def _invalid_user_token(self, msg=False): # NOTE(jamielennox): use False as the default so that None is valid if msg is False: msg = 'Token authorization failed' raise InvalidUserToken(msg) def _confirm_token_bind(self, data, env): bind_mode = self._conf_get('enforce_token_bind') if bind_mode == BIND_MODE.DISABLED: return try: if _token_is_v2(data): bind = data['access']['token']['bind'] elif _token_is_v3(data): bind = data['token']['bind'] else: self._invalid_user_token() except KeyError: bind = {} # permissive and strict modes don't require there to be a bind permissive = bind_mode in (BIND_MODE.PERMISSIVE, BIND_MODE.STRICT) if not bind: if permissive: # no bind provided and none required return else: self.LOG.info('No bind information present in token.') self._invalid_user_token() # get the named mode if bind_mode is not one of the predefined if permissive or bind_mode == BIND_MODE.REQUIRED: name = None else: name = bind_mode if name and name not in bind: self.LOG.info('Named bind mode %s not in bind information', name) self._invalid_user_token() for bind_type, identifier in six.iteritems(bind): if bind_type == BIND_MODE.KERBEROS: if not env.get('AUTH_TYPE', '').lower() == 'negotiate': self.LOG.info('Kerberos credentials required and ' 'not present.') self._invalid_user_token() if not env.get('REMOTE_USER') == identifier: self.LOG.info('Kerberos credentials do not match ' 'those in bind.') self._invalid_user_token() self.LOG.debug('Kerberos bind authentication successful.') elif bind_mode == BIND_MODE.PERMISSIVE: self.LOG.debug('Ignoring Unknown bind for permissive mode: ' '%(bind_type)s: %(identifier)s.', {'bind_type': bind_type, 'identifier': identifier}) else: self.LOG.info('Couldn`t verify unknown bind: %(bind_type)s: ' '%(identifier)s.', {'bind_type': bind_type, 'identifier': identifier}) self._invalid_user_token() def verify_uuid_token(self, user_token, retry=True): """"""Authenticate user token with keystone. :param user_token: user's token id :param retry: flag that forces the middleware to retry user authentication when an indeterminate response is received. Optional. :returns: token object received from keystone on success :raise InvalidUserToken: if token is rejected :raise ServiceError: if unable to authenticate token """""" # Determine the highest api version we can use. if not self.auth_version: self.auth_version = self._choose_api_version() if self.auth_version == 'v3.0': headers = {'X-Auth-Token': self.get_admin_token(), 'X-Subject-Token': safe_quote(user_token)} path = '/v3/auth/tokens' if not self.include_service_catalog: # NOTE(gyee): only v3 API support this option path = path + '?nocatalog' response, data = self._json_request( 'GET', path, additional_headers=headers) else: headers = {'X-Auth-Token': self.get_admin_token()} response, data = self._json_request( 'GET', '/v2.0/tokens/%s' % safe_quote(user_token), additional_headers=headers) if response.status_code == 200: return data if response.status_code == 404: self.LOG.warning('Authorization failed for token') raise InvalidUserToken('Token authorization failed') if response.status_code == 401: self.LOG.info( 'Keystone rejected admin token, resetting') self.admin_token = None else: self.LOG.error('Bad response code while validating token: %s', response.status_code) if retry: self.LOG.info('Retrying validation') return self.verify_uuid_token(user_token, False) else: self.LOG.warning('Invalid user token. Keystone response: %s', data) raise InvalidUserToken() def is_signed_token_revoked(self, token_ids): """"""Indicate whether the token appears in the revocation list."""""" for token_id in token_ids: if self._is_token_id_in_revoked_list(token_id): self.LOG.debug('Token is marked as having been revoked') return True return False def _is_token_id_in_revoked_list(self, token_id): """"""Indicate whether the token_id appears in the revocation list."""""" revocation_list = self.token_revocation_list revoked_tokens = revocation_list.get('revoked', None) if not revoked_tokens: return False revoked_ids = (x['id'] for x in revoked_tokens) return token_id in revoked_ids def cms_verify(self, data, inform=cms.PKI_ASN1_FORM): """"""Verifies the signature of the provided data's IAW CMS syntax. If either of the certificate files might be missing, fetch them and retry. """""" def verify(): try: return cms.cms_verify(data, self.signing_cert_file_name, self.signing_ca_file_name, inform=inform).decode('utf-8') except cms.subprocess.CalledProcessError as err: self.LOG.warning('Verify error: %s', err) raise try: return verify() except exceptions.CertificateConfigError: # the certs might be missing; unconditionally fetch to avoid racing self.fetch_signing_cert() self.fetch_ca_cert() try: # retry with certs in place return verify() except exceptions.CertificateConfigError as err: # if this is still occurring, something else is wrong and we # need err.output to identify the problem self.LOG.error('CMS Verify output: %s', err.output) raise def verify_signed_token(self, signed_text, token_ids): """"""Check that the token is unrevoked and has a valid signature."""""" if self.is_signed_token_revoked(token_ids): raise InvalidUserToken('Token has been revoked') formatted = cms.token_to_cms(signed_text) verified = self.cms_verify(formatted) return verified def verify_pkiz_token(self, signed_text, token_ids): if self.is_signed_token_revoked(token_ids): raise InvalidUserToken('Token has been revoked') try: uncompressed = cms.pkiz_uncompress(signed_text) verified = self.cms_verify(uncompressed, inform=cms.PKIZ_CMS_FORM) return verified # TypeError If the signed_text is not zlib compressed except TypeError: raise InvalidUserToken(signed_text) def verify_signing_dir(self): if os.path.exists(self.signing_dirname): if not os.access(self.signing_dirname, os.W_OK): raise ConfigurationError( 'unable to access signing_dir %s' % self.signing_dirname) uid = os.getuid() if os.stat(self.signing_dirname).st_uid != uid: self.LOG.warning( 'signing_dir is not owned by %s', uid) current_mode = stat.S_IMODE(os.stat(self.signing_dirname).st_mode) if current_mode != stat.S_IRWXU: self.LOG.warning( 'signing_dir mode is %s instead of %s', oct(current_mode), oct(stat.S_IRWXU)) else: os.makedirs(self.signing_dirname, stat.S_IRWXU) @property def token_revocation_list_fetched_time(self): if not self._token_revocation_list_fetched_time: # If the fetched list has been written to disk, use its # modification time. if os.path.exists(self.revoked_file_name): mtime = os.path.getmtime(self.revoked_file_name) fetched_time = datetime.datetime.utcfromtimestamp(mtime) # Otherwise the list will need to be fetched. else: fetched_time = datetime.datetime.min self._token_revocation_list_fetched_time = fetched_time return self._token_revocation_list_fetched_time @token_revocation_list_fetched_time.setter def token_revocation_list_fetched_time(self, value): self._token_revocation_list_fetched_time = value @property def token_revocation_list(self): timeout = (self.token_revocation_list_fetched_time + self.token_revocation_list_cache_timeout) list_is_current = timeutils.utcnow() < timeout if list_is_current: # Load the list from disk if required if not self._token_revocation_list: open_kwargs = {'encoding': 'utf-8'} if six.PY3 else {} with open(self.revoked_file_name, 'r', **open_kwargs) as f: self._token_revocation_list = jsonutils.loads(f.read()) else: self.token_revocation_list = self.fetch_revocation_list() return self._token_revocation_list def _atomic_write_to_signing_dir(self, file_name, value): # In Python2, encoding is slow so the following check avoids it if it # is not absolutely necessary. if isinstance(value, six.text_type): value = value.encode('utf-8') def _atomic_write(destination, data): with tempfile.NamedTemporaryFile(dir=self.signing_dirname, delete=False) as f: f.write(data) os.rename(f.name, destination) try: _atomic_write(file_name, value) except (OSError, IOError): self.verify_signing_dir() _atomic_write(file_name, value) @token_revocation_list.setter def token_revocation_list(self, value): """"""Save a revocation list to memory and to disk. :param value: A json-encoded revocation list """""" self._token_revocation_list = jsonutils.loads(value) self.token_revocation_list_fetched_time = timeutils.utcnow() self._atomic_write_to_signing_dir(self.revoked_file_name, value) def fetch_revocation_list(self, retry=True): headers = {'X-Auth-Token': self.get_admin_token()} response, data = self._json_request('GET', '/v2.0/tokens/revoked', additional_headers=headers) if response.status_code == 401: if retry: self.LOG.info( 'Keystone rejected admin token, resetting admin token') self.admin_token = None return self.fetch_revocation_list(retry=False) if response.status_code != 200: raise ServiceError('Unable to fetch token revocation list.') if 'signed' not in data: raise ServiceError('Revocation list improperly formatted.') return self.cms_verify(data['signed']) def _fetch_cert_file(self, cert_file_name, cert_type): if not self.auth_version: self.auth_version = self._choose_api_version() if self.auth_version == 'v3.0': if cert_type == 'signing': cert_type = 'certificates' path = '/v3/OS-SIMPLE-CERT/' + cert_type else: path = '/v2.0/certificates/' + cert_type response = self._http_request('GET', path) if response.status_code != 200: raise exceptions.CertificateConfigError(response.text) self._atomic_write_to_signing_dir(cert_file_name, response.text) def fetch_signing_cert(self): self._fetch_cert_file(self.signing_cert_file_name, 'signing') def fetch_ca_cert(self): self._fetch_cert_file(self.signing_ca_file_name, 'ca') class CachePool(list): """"""A lazy pool of cache references."""""" def __init__(self, cache, memcached_servers): self._environment_cache = cache self._memcached_servers = memcached_servers @contextlib.contextmanager def reserve(self): """"""Context manager to manage a pooled cache reference."""""" if self._environment_cache is not None: # skip pooling and just use the cache from the upstream filter yield self._environment_cache return # otherwise the context manager will continue! try: c = self.pop() except IndexError: # the pool is empty, so we need to create a new client c = memorycache.get_client(self._memcached_servers) try: yield c finally: self.append(c) class TokenCache(object): """"""Encapsulates the auth_token token cache functionality. auth_token caches tokens that it's seen so that when a token is re-used the middleware doesn't have to do a more expensive operation (like going to the identity server) to validate the token. initialize() must be called before calling the other methods. Store a valid token in the cache using store(); mark a token as invalid in the cache using store_invalid(). Check if a token is in the cache and retrieve it using get(). """""" _INVALID_INDICATOR = 'invalid' def __init__(self, log, cache_time=None, hash_algorithms=None, env_cache_name=None, memcached_servers=None, memcache_security_strategy=None, memcache_secret_key=None): self.LOG = log self._cache_time = cache_time self._hash_algorithms = hash_algorithms self._env_cache_name = env_cache_name self._memcached_servers = memcached_servers # memcache value treatment, ENCRYPT or MAC self._memcache_security_strategy = memcache_security_strategy if self._memcache_security_strategy is not None: self._memcache_security_strategy = ( self._memcache_security_strategy.upper()) self._memcache_secret_key = memcache_secret_key self._cache_pool = None self._initialized = False self._assert_valid_memcache_protection_config() def initialize(self, env): if self._initialized: return self._cache_pool = CachePool(env.get(self._env_cache_name), self._memcached_servers) self._initialized = True def get(self, user_token): """"""Check if the token is cached already. Returns a tuple. The first element is a list of token IDs, where the first one is the preferred hash. The second element is the token data from the cache if the token was cached, otherwise ``None``. :raises InvalidUserToken: if the token is invalid """""" if cms.is_asn1_token(user_token) or cms.is_pkiz(user_token): # user_token is a PKI token that's not hashed. token_hashes = list(cms.cms_hash_token(user_token, mode=algo) for algo in self._hash_algorithms) for token_hash in token_hashes: cached = self._cache_get(token_hash) if cached: return (token_hashes, cached) # The token wasn't found using any hash algorithm. return (token_hashes, None) # user_token is either a UUID token or a hashed PKI token. token_id = user_token cached = self._cache_get(token_id) return ([token_id], cached) def store(self, token_id, data, expires): """"""Put token data into the cache. Stores the parsed expire date in cache allowing quick check of token freshness on retrieval. """""" self.LOG.debug('Storing token in cache') self._cache_store(token_id, (data, expires)) def store_invalid(self, token_id): """"""Store invalid token in cache."""""" self.LOG.debug('Marking token as unauthorized in cache') self._cache_store(token_id, self._INVALID_INDICATOR) def _assert_valid_memcache_protection_config(self): if self._memcache_security_strategy: if self._memcache_security_strategy not in ('MAC', 'ENCRYPT'): raise ConfigurationError('memcache_security_strategy must be ' 'ENCRYPT or MAC') if not self._memcache_secret_key: raise ConfigurationError('memcache_secret_key must be defined ' 'when a memcache_security_strategy ' 'is defined') def _cache_get(self, token_id): """"""Return token information from cache. If token is invalid raise InvalidUserToken return token only if fresh (not expired). """""" if not token_id: # Nothing to do return if self._memcache_security_strategy is None: key = CACHE_KEY_TEMPLATE % token_id with self._cache_pool.reserve() as cache: serialized = cache.get(key) else: secret_key = self._memcache_secret_key if isinstance(secret_key, six.string_types): secret_key = secret_key.encode('utf-8') security_strategy = self._memcache_security_strategy if isinstance(security_strategy, six.string_types): security_strategy = security_strategy.encode('utf-8') keys = memcache_crypt.derive_keys( token_id, secret_key, security_strategy) cache_key = CACHE_KEY_TEMPLATE % ( memcache_crypt.get_cache_key(keys)) with self._cache_pool.reserve() as cache: raw_cached = cache.get(cache_key) try: # unprotect_data will return None if raw_cached is None serialized = memcache_crypt.unprotect_data(keys, raw_cached) except Exception: msg = 'Failed to decrypt/verify cache data' self.LOG.exception(msg) # this should have the same effect as data not # found in cache serialized = None if serialized is None: return None # Note that _INVALID_INDICATOR and (data, expires) are the only # valid types of serialized cache entries, so there is not # a collision with jsonutils.loads(serialized) == None. if not isinstance(serialized, six.string_types): serialized = serialized.decode('utf-8') cached = jsonutils.loads(serialized) if cached == self._INVALID_INDICATOR: self.LOG.debug('Cached Token is marked unauthorized') raise InvalidUserToken('Token authorization failed') data, expires = cached try: expires = timeutils.parse_isotime(expires) except ValueError: # Gracefully handle upgrade of expiration times from *nix # timestamps to ISO 8601 formatted dates by ignoring old cached # values. return expires = timeutils.normalize_time(expires) utcnow = timeutils.utcnow() if utcnow < expires: self.LOG.debug('Returning cached token') return data else: self.LOG.debug('Cached Token seems expired') raise InvalidUserToken('Token authorization failed') def _cache_store(self, token_id, data): """"""Store value into memcache. data may be _INVALID_INDICATOR or a tuple like (data, expires) """""" serialized_data = jsonutils.dumps(data) if isinstance(serialized_data, six.text_type): serialized_data = serialized_data.encode('utf-8') if self._memcache_security_strategy is None: cache_key = CACHE_KEY_TEMPLATE % token_id data_to_store = serialized_data else: secret_key = self._memcache_secret_key if isinstance(secret_key, six.string_types): secret_key = secret_key.encode('utf-8') security_strategy = self._memcache_security_strategy if isinstance(security_strategy, six.string_types): security_strategy = security_strategy.encode('utf-8') keys = memcache_crypt.derive_keys( token_id, secret_key, security_strategy) cache_key = CACHE_KEY_TEMPLATE % memcache_crypt.get_cache_key(keys) data_to_store = memcache_crypt.protect_data(keys, serialized_data) with self._cache_pool.reserve() as cache: cache.set(cache_key, data_to_store, time=self._cache_time) def filter_factory(global_conf, **local_conf): """"""Returns a WSGI filter app for use with paste.deploy."""""" conf = global_conf.copy() conf.update(local_conf) def auth_filter(app): return AuthProtocol(app, conf) return auth_filter def app_factory(global_conf, **local_conf): conf = global_conf.copy() conf.update(local_conf) return AuthProtocol(None, conf) if __name__ == '__main__': """"""Run this module directly to start a protected echo service:: $ python -m keystoneclient.middleware.auth_token When the ``auth_token`` module authenticates a request, the echo service will respond with all the environment variables presented to it by this module. """""" def echo_app(environ, start_response): """"""A WSGI application that echoes the CGI environment to the user."""""" start_response('200 OK', [('Content-Type', 'application/json')]) environment = dict((k, v) for k, v in six.iteritems(environ) if k.startswith('HTTP_X_')) yield jsonutils.dumps(environment) from wsgiref import simple_server # hardcode any non-default configuration here conf = {'auth_protocol': 'http', 'admin_token': 'ADMIN'} app = AuthProtocol(echo_app, conf) server = simple_server.make_server('', 8000, app) print('Serving on port 8000 (Ctrl+C to end)...') server.serve_forever() ",0,4410
openstack%2Fmistral~master~I365ec8b92e9bed72bb05c618323f18f5ca7b82e5,openstack/mistral,master,I365ec8b92e9bed72bb05c618323f18f5ca7b82e5,Implementing action_execution POST API,MERGED,2015-06-09 14:16:09.000000000,2015-06-25 09:02:45.000000000,2015-06-25 09:02:41.000000000,"[{'_account_id': 3}, {'_account_id': 6732}, {'_account_id': 7700}, {'_account_id': 8731}, {'_account_id': 15881}]","[{'number': 1, 'created': '2015-06-09 14:16:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/mistral/commit/d31269b260b65bf151aa459b3ff7044fc41486f3', 'message': ""Implementing action_execution POST API\n\n * Mistral API now enables POST on /action_executions\n * 2 ways of work - synchronous and asynchronous:\n     returns result immediately or saving action_execution\n     to the DB. it is controlled by 'save_result' option in\n     'params' key of the request.\n * fixed returning error back in executior\n\nTODO (next commit):\n  - Implementing 'run-action' cmd in python-mistralclient\n\nImplements blueprint mistral-run-individual-action\n\nChange-Id: I365ec8b92e9bed72bb05c618323f18f5ca7b82e5\n""}, {'number': 2, 'created': '2015-06-11 07:10:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/mistral/commit/b64014f356ab012931fcb8badd7245fc5b22aaad', 'message': ""Implementing action_execution POST API\n\n * Mistral API now enables POST on /action_executions\n * 2 ways of work - synchronous and asynchronous:\n     returns result immediately or saving action_execution\n     to the DB. it is controlled by 'save_result' option in\n     'params' key of the request.\n * fixed returning error back in executior\n\nTODO (next commit):\n  - Implementing 'run-action' cmd in python-mistralclient\n\nImplements blueprint mistral-run-individual-action\n\nChange-Id: I365ec8b92e9bed72bb05c618323f18f5ca7b82e5\n""}, {'number': 3, 'created': '2015-06-11 13:24:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/mistral/commit/33aff5e8e3f38b6323fde1fcf9a09928254cbca7', 'message': ""Implementing action_execution POST API\n\n * Mistral API now enables POST on /action_executions\n * 2 ways of work - synchronous and asynchronous:\n     returns result immediately or saving action_execution\n     to the DB. it is controlled by 'save_result' option in\n     'params' key of the request.\n * fixed returning error back in executior\n\nTODO (next commit):\n  - Implementing 'run-action' cmd in python-mistralclient\n\nImplements blueprint mistral-run-individual-action\n\nChange-Id: I365ec8b92e9bed72bb05c618323f18f5ca7b82e5\n""}, {'number': 4, 'created': '2015-06-17 09:00:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/mistral/commit/39aff0aec0f8b84859feb2cacd33600738ce5207', 'message': ""Implementing action_execution POST API\n\n * Mistral API now enables POST on /action_executions\n * 2 ways of work - synchronous and asynchronous:\n     returns result immediately or saving action_execution\n     to the DB. it is controlled by 'save_result' option in\n     'params' key of the request.\n * fixed returning error back in executior\n\nTODO (next commit):\n  - Implementing 'run-action' cmd in python-mistralclient\n\nImplements blueprint mistral-run-individual-action\n\nChange-Id: I365ec8b92e9bed72bb05c618323f18f5ca7b82e5\n""}, {'number': 5, 'created': '2015-06-22 12:42:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/mistral/commit/aaab47b1c7c068edb37ed3251ba8537ca0074ae7', 'message': ""Implementing action_execution POST API\n\n * Mistral API now enables POST on /action_executions\n * 2 ways of work - synchronous and asynchronous:\n     returns result immediately or saving action_execution\n     to the DB. it is controlled by 'save_result' option in\n     'params' key of the request.\n * fixed returning error back in executior\n\nTODO (next commit):\n  - Implementing 'run-action' cmd in python-mistralclient\n\nImplements blueprint mistral-run-individual-action\n\nChange-Id: I365ec8b92e9bed72bb05c618323f18f5ca7b82e5\n""}, {'number': 6, 'created': '2015-06-22 13:25:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/mistral/commit/30891fe9c95d7fecb16f9b22cf552f3cd13195e7', 'message': ""Implementing action_execution POST API\n\n * Mistral API now enables POST on /action_executions\n * 2 ways of work - synchronous and asynchronous:\n     returns result immediately or saving action_execution\n     to the DB. it is controlled by 'save_result' option in\n     'params' key of the request.\n * fixed returning error back in executior\n\nTODO (next commit):\n  - Implementing 'run-action' cmd in python-mistralclient\n\nImplements blueprint mistral-run-individual-action\n\nChange-Id: I365ec8b92e9bed72bb05c618323f18f5ca7b82e5\n""}, {'number': 7, 'created': '2015-06-23 12:34:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/mistral/commit/e825071838f9e720da6ec8e05d682f785cda6721', 'message': ""Implementing action_execution POST API\n\n * Mistral API now enables POST on /action_executions\n * 2 ways of work - synchronous and asynchronous:\n     returns result immediately or saving action_execution\n     to the DB. it is controlled by 'save_result' option in\n     'params' key of the request.\n * fixed returning error back in executior\n\nTODO (next commit):\n  - Implementing 'run-action' cmd in python-mistralclient\n\nImplements blueprint mistral-run-individual-action\n\nChange-Id: I365ec8b92e9bed72bb05c618323f18f5ca7b82e5\n""}, {'number': 8, 'created': '2015-06-24 12:50:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/mistral/commit/733b41a57513996e7434ffbb399cde9e064bf1fd', 'message': ""Implementing action_execution POST API\n\n * Mistral API now enables POST on /action_executions\n * 2 ways of work - synchronous and asynchronous:\n     returns result immediately or saving action_execution\n     to the DB. it is controlled by 'save_result' option in\n     'params' key of the request.\n * fixed returning error back in executior\n\nTODO (next commit):\n  - Implementing 'run-action' cmd in python-mistralclient\n\nImplements blueprint mistral-run-individual-action\n\nChange-Id: I365ec8b92e9bed72bb05c618323f18f5ca7b82e5\n""}, {'number': 9, 'created': '2015-06-24 14:05:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/mistral/commit/ad8dcb7fe600fe48dfae856d5061b0373883a800', 'message': ""Implementing action_execution POST API\n\n * Mistral API now enables POST on /action_executions\n * 2 ways of work - synchronous and asynchronous:\n     returns result immediately or saving action_execution\n     to the DB. it is controlled by 'save_result' option in\n     'params' key of the request.\n * fixed returning error back in executior\n\nTODO (next commit):\n  - Implementing 'run-action' cmd in python-mistralclient\n\nImplements blueprint mistral-run-individual-action\n\nChange-Id: I365ec8b92e9bed72bb05c618323f18f5ca7b82e5\n""}, {'number': 10, 'created': '2015-06-24 14:25:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/mistral/commit/492688e1ec26bbf24a1f17d5f5638962d7a8c792', 'message': ""Implementing action_execution POST API\n\n * Mistral API now enables POST on /action_executions\n * 2 ways of work - synchronous and asynchronous:\n     returns result immediately or saving action_execution\n     to the DB. it is controlled by 'save_result' option in\n     'params' key of the request.\n * fixed returning error back in executior\n\nTODO (next commit):\n  - Implementing 'run-action' cmd in python-mistralclient\n\nImplements blueprint mistral-run-individual-action\n\nChange-Id: I365ec8b92e9bed72bb05c618323f18f5ca7b82e5\n""}, {'number': 11, 'created': '2015-06-24 17:02:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/mistral/commit/6cd2d25439ee1ddd36d19b5d88e2e1d9c6b6daad', 'message': ""Implementing action_execution POST API\n\n * Mistral API now enables POST on /action_executions\n * 2 ways of work - synchronous and asynchronous:\n     returns result immediately or saving action_execution\n     to the DB. it is controlled by 'save_result' option in\n     'params' key of the request.\n * fixed returning error back in executior\n\nTODO (next commit):\n  - Implementing 'run-action' cmd in python-mistralclient\n\nImplements blueprint mistral-run-individual-action\n\nChange-Id: I365ec8b92e9bed72bb05c618323f18f5ca7b82e5\n""}, {'number': 12, 'created': '2015-06-25 06:46:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/mistral/commit/2c1fea9ea4a537c53ca7845aaca2cb0cf7694e0b', 'message': ""Implementing action_execution POST API\n\n * Mistral API now enables POST on /action_executions\n * 2 ways of work - synchronous and asynchronous:\n     returns result immediately or saving action_execution\n     to the DB. it is controlled by 'save_result' option in\n     'params' key of the request.\n * fixed returning error back in executior\n\nTODO (next commit):\n  - Implementing 'run-action' cmd in python-mistralclient\n\nImplements blueprint mistral-run-individual-action\n\nChange-Id: I365ec8b92e9bed72bb05c618323f18f5ca7b82e5\n""}, {'number': 13, 'created': '2015-06-25 06:49:56.000000000', 'files': ['mistral/engine/default_executor.py', 'mistral/api/controllers/v2/action_execution.py', 'mistral/tests/functional/base.py', 'mistral/tests/functional/api/v2/test_mistral_basic_v2.py', 'mistral/tests/unit/api/v2/test_action_executions.py'], 'web_link': 'https://opendev.org/openstack/mistral/commit/786b7adb4622720303d28a7103a95204356bbe86', 'message': ""Implementing action_execution POST API\n\n * Mistral API now enables POST on /action_executions\n * 2 ways of work - synchronous and asynchronous:\n     returns result immediately or saving action_execution\n     to the DB. it is controlled by 'save_result' option in\n     'params' key of the request.\n * fixed returning error back in executior\n\nTODO (next commit):\n  - Implementing 'run-action' cmd in python-mistralclient\n\nImplements blueprint mistral-run-individual-action\n\nChange-Id: I365ec8b92e9bed72bb05c618323f18f5ca7b82e5\n""}]",3,189736,786b7adb4622720303d28a7103a95204356bbe86,42,5,13,7700,,,0,"Implementing action_execution POST API

 * Mistral API now enables POST on /action_executions
 * 2 ways of work - synchronous and asynchronous:
     returns result immediately or saving action_execution
     to the DB. it is controlled by 'save_result' option in
     'params' key of the request.
 * fixed returning error back in executior

TODO (next commit):
  - Implementing 'run-action' cmd in python-mistralclient

Implements blueprint mistral-run-individual-action

Change-Id: I365ec8b92e9bed72bb05c618323f18f5ca7b82e5
",git fetch https://review.opendev.org/openstack/mistral refs/changes/36/189736/6 && git format-patch -1 --stdout FETCH_HEAD,"['mistral/engine/default_executor.py', 'mistral/api/controllers/v2/action_execution.py', 'mistral/tests/unit/api/v2/test_action_executions.py']",3,d31269b260b65bf151aa459b3ff7044fc41486f3,bp/mistral-run-individual-action,"import json @mock.patch.object(rpc.EngineClient, 'start_action') def test_post_sync(self, f): f.return_value = '123' resp = self.app.post_json( '/v2/action_executions', {'name': 'std.echo', 'input': '{}'} ) self.assertEqual(resp.status_int, 200) self.assertDictEqual({'result': '""123""'}, resp.json) f.assert_called_once_with( ACTION_EXEC['name'], json.loads(ACTION_EXEC['input']) ) @mock.patch.object(rpc.EngineClient, 'start_action') def test_post_async(self, f): f.return_value = action_ex.to_dict() resp = self.app.post_json( '/v2/action_executions', { 'name': 'std.echo', 'input': '{}', 'params': {'save_result': True} } ) self.assertEqual(resp.status_int, 200) action_exec = ACTION_EXEC del action_exec['task_name'] self.assertDictEqual(ACTION_EXEC, resp.json) f.assert_called_once_with( ACTION_EXEC['name'], json.loads(ACTION_EXEC['input']), save_result=True ) def test_post_bad_result(self): resp = self.app.post_json( '/v2/action_executions', {'input': 'null'}, expect_errors=True ) self.assertEqual(resp.status_int, 400) def test_post_bad_input(self): resp = self.app.post_json( '/v2/action_executions', {'input': None}, expect_errors=True ) self.assertEqual(resp.status_int, 400) ",,107,3
openstack%2Fpuppet-tripleo~master~Icdd80aa9cd56e5afd3707eb7fa38aaedb8535af6,openstack/puppet-tripleo,master,Icdd80aa9cd56e5afd3707eb7fa38aaedb8535af6,Use mode tcp for glance-registry balancing,MERGED,2015-06-25 01:24:26.000000000,2015-06-25 09:01:23.000000000,2015-06-25 09:01:19.000000000,"[{'_account_id': 3}, {'_account_id': 3153}, {'_account_id': 4328}, {'_account_id': 7582}, {'_account_id': 8041}, {'_account_id': 8399}, {'_account_id': 8449}, {'_account_id': 9410}]","[{'number': 1, 'created': '2015-06-25 01:24:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-tripleo/commit/a9851575a08d2413378467e9d07b2b38adf2d638', 'message': 'Use mode tcp for glance-registry balancing\n\nThe glance-registry service is returning 401 to httpchk, which\nmakes haproxy think it is down. This change switches the check\nmode to tcp.\n\nCloses-Bug: 1468566\nCloses-Bug: https://bugzilla.redhat.com/show_bug.cgi?id=1234637\n\nChange-Id: Icdd80aa9cd56e5afd3707eb7fa38aaedb8535af6\n'}, {'number': 2, 'created': '2015-06-25 01:25:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-tripleo/commit/e30acdcbbd06e9bb8e5f9e3ec01855955a06c354', 'message': 'Use mode tcp for glance-registry balancing\n\nThe glance-registry service is returning 401 to httpchk, which\nmakes haproxy think it is down. This change switches the check\nmode to tcp.\n\nCloses-Bug: 1468566\nCloses-Bug: https://bugzilla.redhat.com/show_bug.cgi?id=1234637\n\nChange-Id: Icdd80aa9cd56e5afd3707eb7fa38aaedb8535af6\n'}, {'number': 3, 'created': '2015-06-25 01:32:15.000000000', 'files': ['manifests/loadbalancer.pp'], 'web_link': 'https://opendev.org/openstack/puppet-tripleo/commit/2070d2d7cbd381a33bc0ad3a74d2713de0127e9f', 'message': 'Use mode tcp for glance-registry balancing\n\nThe glance-registry service is returning 401 to httpchk, which\nmakes haproxy think it is down. This change switches the check\nmode to tcp.\n\nCloses-Bug: https://bugzilla.redhat.com/show_bug.cgi?id=1234637\nCloses-Bug: 1468566\n\nChange-Id: Icdd80aa9cd56e5afd3707eb7fa38aaedb8535af6\n'}]",0,195370,2070d2d7cbd381a33bc0ad3a74d2713de0127e9f,12,8,3,6796,,,0,"Use mode tcp for glance-registry balancing

The glance-registry service is returning 401 to httpchk, which
makes haproxy think it is down. This change switches the check
mode to tcp.

Closes-Bug: https://bugzilla.redhat.com/show_bug.cgi?id=1234637
Closes-Bug: 1468566

Change-Id: Icdd80aa9cd56e5afd3707eb7fa38aaedb8535af6
",git fetch https://review.opendev.org/openstack/puppet-tripleo refs/changes/70/195370/1 && git format-patch -1 --stdout FETCH_HEAD,['manifests/loadbalancer.pp'],1,a9851575a08d2413378467e9d07b2b38adf2d638,bug/1468566," 'mode' => 'tcp', }"," 'option' => [ 'httpchk GET /' ], },",2,2
openstack%2Fglance~master~Id03f6fa9eb24ed0fd7a040f2abd14e815a49872e,openstack/glance,master,Id03f6fa9eb24ed0fd7a040f2abd14e815a49872e,Unsetting execution bit for metadefs definitions,ABANDONED,2015-06-01 08:59:52.000000000,2015-06-25 09:00:36.000000000,,"[{'_account_id': 3}, {'_account_id': 6159}, {'_account_id': 13161}]","[{'number': 1, 'created': '2015-06-01 08:59:52.000000000', 'files': ['etc/metadefs/software-runtimes.json', 'etc/metadefs/software-webservers.json', 'etc/metadefs/software-databases.json'], 'web_link': 'https://opendev.org/openstack/glance/commit/24afa6c07d65dc71d14aa1c3c52f2167277d1f51', 'message': 'Unsetting execution bit for metadefs definitions\n\nsoftware-*.json metadefs definitions in etc/metadefs had execution\nbit set (chmod 755). This is unnecessary and this commit sets their\npermissions to 644.\n\nChange-Id: Id03f6fa9eb24ed0fd7a040f2abd14e815a49872e\n'}]",0,187139,24afa6c07d65dc71d14aa1c3c52f2167277d1f51,5,3,1,11600,,,0,"Unsetting execution bit for metadefs definitions

software-*.json metadefs definitions in etc/metadefs had execution
bit set (chmod 755). This is unnecessary and this commit sets their
permissions to 644.

Change-Id: Id03f6fa9eb24ed0fd7a040f2abd14e815a49872e
",git fetch https://review.opendev.org/openstack/glance refs/changes/39/187139/1 && git format-patch -1 --stdout FETCH_HEAD,"['etc/metadefs/software-runtimes.json', 'etc/metadefs/software-webservers.json', 'etc/metadefs/software-databases.json']",3,24afa6c07d65dc71d14aa1c3c52f2167277d1f51,,,,0,0
openstack%2Fgnocchi~master~Ia60273ca73a351ba01f335ff79d5964ae3ddd6be,openstack/gnocchi,master,Ia60273ca73a351ba01f335ff79d5964ae3ddd6be,Don't reclone the repo we already did,MERGED,2015-06-24 13:36:48.000000000,2015-06-25 08:59:14.000000000,2015-06-25 08:59:14.000000000,"[{'_account_id': 3}, {'_account_id': 1669}, {'_account_id': 11564}]","[{'number': 1, 'created': '2015-06-24 13:36:48.000000000', 'files': ['devstack/plugin.sh'], 'web_link': 'https://opendev.org/openstack/gnocchi/commit/7d5f2d66dc6a86aaa07b58f805cd80ce39c2bf20', 'message': ""Don't reclone the repo we already did\n\nIn order to use a devstack plugin at all, we first must have cloned\nthe gnocchi repo pointed to in local.conf. This sets the remote and\nthe chosen branch. install_config then goes on to clone again,\nclobbering the thing that just got checked out, including and\ncustomizations that are being tested.\n\nSo, just get rid of the redundancy.\n\nChange-Id: Ia60273ca73a351ba01f335ff79d5964ae3ddd6be\n""}]",0,195080,7d5f2d66dc6a86aaa07b58f805cd80ce39c2bf20,7,3,1,11564,,,0,"Don't reclone the repo we already did

In order to use a devstack plugin at all, we first must have cloned
the gnocchi repo pointed to in local.conf. This sets the remote and
the chosen branch. install_config then goes on to clone again,
clobbering the thing that just got checked out, including and
customizations that are being tested.

So, just get rid of the redundancy.

Change-Id: Ia60273ca73a351ba01f335ff79d5964ae3ddd6be
",git fetch https://review.opendev.org/openstack/gnocchi refs/changes/80/195080/1 && git format-patch -1 --stdout FETCH_HEAD,['devstack/plugin.sh'],1,7d5f2d66dc6a86aaa07b58f805cd80ce39c2bf20,cd/no-dupe-clone,,# Setup repository GNOCCHI_REPO=${GNOCCHI_REPO:-${GIT_BASE}/openstack/gnocchi.git} GNOCCHI_BRANCH=${GNOCCHI_BRANCH:-master} git_clone $GNOCCHI_REPO $GNOCCHI_DIR $GNOCCHI_BRANCH ,0,6
openstack%2Fgnocchi~master~Ic68a09f12f2eadf07c7cdb5c28714d3b2768acb3,openstack/gnocchi,master,Ic68a09f12f2eadf07c7cdb5c28714d3b2768acb3,Ensure live gabbi tests run in gate,MERGED,2015-06-24 11:23:30.000000000,2015-06-25 08:58:52.000000000,2015-06-25 08:58:48.000000000,"[{'_account_id': 3}, {'_account_id': 1669}, {'_account_id': 8358}, {'_account_id': 10987}, {'_account_id': 11564}]","[{'number': 1, 'created': '2015-06-24 11:23:30.000000000', 'files': ['tox.ini'], 'web_link': 'https://opendev.org/openstack/gnocchi/commit/41a3ef2696393e1349e58c389995d64b4f4923d7', 'message': 'Ensure live gabbi tests run in gate\n\nWith tox 2.0 the environment is restricted. The gabbi live tests\nwill not run without GNOCCHI_SERVICE_HOST being in the environment.\nThis change ensures that GNOCCHI_SERVICE* is passed into the test\nrun.\n\nChange-Id: Ic68a09f12f2eadf07c7cdb5c28714d3b2768acb3\n'}]",0,195040,41a3ef2696393e1349e58c389995d64b4f4923d7,9,5,1,11564,,,0,"Ensure live gabbi tests run in gate

With tox 2.0 the environment is restricted. The gabbi live tests
will not run without GNOCCHI_SERVICE_HOST being in the environment.
This change ensures that GNOCCHI_SERVICE* is passed into the test
run.

Change-Id: Ic68a09f12f2eadf07c7cdb5c28714d3b2768acb3
",git fetch https://review.opendev.org/openstack/gnocchi refs/changes/40/195040/1 && git format-patch -1 --stdout FETCH_HEAD,['tox.ini'],1,41a3ef2696393e1349e58c389995d64b4f4923d7,cd/gate-live-gabbi,passenv = LANG GNOCCHI_SERVICE*,,1,0
openstack%2Ffuel-qa~stable%2F6.1~I57d03d68deb989ddb2fb97935a3d8ea264dce164,openstack/fuel-qa,stable/6.1,I57d03d68deb989ddb2fb97935a3d8ea264dce164,Upload files on target nodes using SFTP (patching),MERGED,2015-06-24 15:03:36.000000000,2015-06-25 08:55:13.000000000,2015-06-25 08:55:13.000000000,"[{'_account_id': 3}, {'_account_id': 6719}, {'_account_id': 8882}, {'_account_id': 8971}, {'_account_id': 10136}, {'_account_id': 11969}, {'_account_id': 12867}, {'_account_id': 14057}, {'_account_id': 14708}, {'_account_id': 15943}, {'_account_id': 15984}, {'_account_id': 16106}]","[{'number': 1, 'created': '2015-06-24 15:03:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-qa/commit/76f6a19f44e51bc87aa1e931f354f40caccbd718', 'message': 'Upload files on target nodes using SFTP (patching)\n\nChange-Id: I57d03d68deb989ddb2fb97935a3d8ea264dce164\nCloses-bug: #1468376\n'}, {'number': 2, 'created': '2015-06-24 20:17:48.000000000', 'files': ['fuelweb_test/helpers/patching.py'], 'web_link': 'https://opendev.org/openstack/fuel-qa/commit/ddd6e9a6f3d28bf412202c7b53d2c51a70242469', 'message': 'Upload files on target nodes using SFTP (patching)\n\nChange-Id: I57d03d68deb989ddb2fb97935a3d8ea264dce164\nCloses-bug: #1468376\n'}]",0,195136,ddd6e9a6f3d28bf412202c7b53d2c51a70242469,14,12,2,11081,,,0,"Upload files on target nodes using SFTP (patching)

Change-Id: I57d03d68deb989ddb2fb97935a3d8ea264dce164
Closes-bug: #1468376
",git fetch https://review.opendev.org/openstack/fuel-qa refs/changes/36/195136/2 && git format-patch -1 --stdout FETCH_HEAD,['fuelweb_test/helpers/patching.py'],1,76f6a19f44e51bc87aa1e931f354f40caccbd718,,"def get_package_test_info(package, pkg_type, tests_path, patch_target): assert_true(os.path.isdir(settings.PATCHING_PKGS_TESTS), ""Path for packages tests doesn't exist: '{0}'"".format( settings.PATCHING_PKGS_TESTS)) tests = get_package_test_info(package, pkg_type, settings.PATCHING_PKGS_TESTS, target) assert_true(os.path.exists(scenario_path), ""Erratum for bug #{0} is not found in '{0}' "" ""directory"".format(bug_id, settings.PATCHING_APPLY_TESTS)) with open(scenario_path) as f: return yaml.load(f.read()) source_path = '{0}/tests/{1}'.format(settings.PATCHING_APPLY_TESTS, file_name) for remote in remotes: remote.upload(source_path, upload_path) continue","from urllib2 import HTTPErrordef get_package_test_info_remote(package, pkg_type, tests_url, patch_target): packages_url = ""{0}/{1}/packages.yaml"".format(tests_url, pkg_type) tests = set() tests_file = 'test.yaml' all_packages = yaml.load(urlopen(packages_url).read()) assert_is_not_none(_get_target_and_project(package, all_packages), ""Package '{0}' doesn't belong to any installation "" ""target / project"".format(package)) target, project = _get_target_and_project(package, all_packages) if patch_target == 'master': if target not in ['master', 'bootstrap']: return set([None]) if patch_target == 'environment': if target not in ['deployment', 'provisioning']: return set([None]) target_tests_url = ""/"".join((tests_url, pkg_type, target, tests_file)) project_tests_url = ""/"".join((tests_url, pkg_type, target, project, tests_file)) package_tests_url = ""/"".join((tests_url, pkg_type, target, project, package, tests_file)) for url in (target_tests_url, project_tests_url, package_tests_url): try: test = yaml.load(urlopen(url).read()) if 'system_tests' in test.keys(): tests.update(test['system_tests']['tags']) except HTTPError: pass return tests def get_package_test_info_local(package, pkg_type, tests_path, patch_target): if 'http' in urlparse(settings.PATCHING_PKGS_TESTS): get_method = get_package_test_info_remote elif os.path.isdir(settings.PATCHING_PKGS_TESTS): get_method = get_package_test_info_local else: raise Exception(""Path for packages tests doesn't look like URL or loca"" ""l folder: '{0}'"".format(settings.PATCHING_PKGS_TESTS)) tests = get_method(package, pkg_type, settings.PATCHING_PKGS_TESTS, target) if 'http' in urlparse(settings.PATCHING_APPLY_TESTS): return yaml.load(urlopen(scenario_path).read()) elif os.path.isdir(settings.PATCHING_APPLY_TESTS): with open(scenario_path) as f: return yaml.load(f.read()) else: raise Exception(""Path to patching tests doesn't look like URL or local"" "" folder: '{0}'"".format(settings.PATCHING_APPLY_TESTS)) def get_script_content(path, bug_id, script): scripts_path = '{0}/bugs/{1}/tests/{2}'.format(path, bug_id, script) if 'http' in urlparse(settings.PATCHING_APPLY_TESTS): return urlopen(scripts_path).read() elif os.path.isdir(settings.PATCHING_APPLY_TESTS): with open(scripts_path) as f: return f.read() file_content = get_script_content( path=settings.PATCHING_APPLY_TESTS, bug_id=settings.PATCHING_BUG_ID, script=file_name) command = ""echo '{0}' > {1}/{2}"".format(file_content, upload_path, file_name)",18,64
openstack%2Ffuel-qa~master~I57d03d68deb989ddb2fb97935a3d8ea264dce164,openstack/fuel-qa,master,I57d03d68deb989ddb2fb97935a3d8ea264dce164,Upload files on target nodes using SFTP (patching),MERGED,2015-06-24 15:02:33.000000000,2015-06-25 08:54:08.000000000,2015-06-25 08:54:07.000000000,"[{'_account_id': 3}, {'_account_id': 6719}, {'_account_id': 8882}, {'_account_id': 8971}, {'_account_id': 10136}, {'_account_id': 11969}, {'_account_id': 12867}, {'_account_id': 14057}, {'_account_id': 14708}, {'_account_id': 15943}, {'_account_id': 15984}, {'_account_id': 16106}]","[{'number': 1, 'created': '2015-06-24 15:02:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-qa/commit/2f141541d2271fc3d2825b803a5d63ea131fbf7b', 'message': 'Upload files on target nodes using SFTP (patching)\n\nChange-Id: I57d03d68deb989ddb2fb97935a3d8ea264dce164\nCloses-bug: #1468376\n'}, {'number': 2, 'created': '2015-06-24 20:17:04.000000000', 'files': ['fuelweb_test/helpers/patching.py'], 'web_link': 'https://opendev.org/openstack/fuel-qa/commit/25a69197ea1d1856624e1dd1603eb11e1b4fe860', 'message': 'Upload files on target nodes using SFTP (patching)\n\nChange-Id: I57d03d68deb989ddb2fb97935a3d8ea264dce164\nCloses-bug: #1468376\n'}]",0,195133,25a69197ea1d1856624e1dd1603eb11e1b4fe860,16,12,2,11081,,,0,"Upload files on target nodes using SFTP (patching)

Change-Id: I57d03d68deb989ddb2fb97935a3d8ea264dce164
Closes-bug: #1468376
",git fetch https://review.opendev.org/openstack/fuel-qa refs/changes/33/195133/1 && git format-patch -1 --stdout FETCH_HEAD,['fuelweb_test/helpers/patching.py'],1,2f141541d2271fc3d2825b803a5d63ea131fbf7b,bug/1468376,"def get_package_test_info(package, pkg_type, tests_path, patch_target): assert_true(os.path.isdir(settings.PATCHING_PKGS_TESTS), ""Path for packages tests doesn't exist: '{0}'"".format( settings.PATCHING_PKGS_TESTS)) tests = get_package_test_info(package, pkg_type, settings.PATCHING_PKGS_TESTS, target) assert_true(os.path.exists(scenario_path), ""Erratum for bug #{0} is not found in '{0}' "" ""directory"".format(bug_id, settings.PATCHING_APPLY_TESTS)) with open(scenario_path) as f: return yaml.load(f.read()) source_path = '{0}/tests/{1}'.format(settings.PATCHING_APPLY_TESTS, file_name) for remote in remotes: remote.upload(source_path, upload_path) continue","from urllib2 import HTTPErrordef get_package_test_info_remote(package, pkg_type, tests_url, patch_target): packages_url = ""{0}/{1}/packages.yaml"".format(tests_url, pkg_type) tests = set() tests_file = 'test.yaml' all_packages = yaml.load(urlopen(packages_url).read()) assert_is_not_none(_get_target_and_project(package, all_packages), ""Package '{0}' doesn't belong to any installation "" ""target / project"".format(package)) target, project = _get_target_and_project(package, all_packages) if patch_target == 'master': if target not in ['master', 'bootstrap']: return set([None]) if patch_target == 'environment': if target not in ['deployment', 'provisioning']: return set([None]) target_tests_url = ""/"".join((tests_url, pkg_type, target, tests_file)) project_tests_url = ""/"".join((tests_url, pkg_type, target, project, tests_file)) package_tests_url = ""/"".join((tests_url, pkg_type, target, project, package, tests_file)) for url in (target_tests_url, project_tests_url, package_tests_url): try: test = yaml.load(urlopen(url).read()) if 'system_tests' in test.keys(): tests.update(test['system_tests']['tags']) except HTTPError: pass return tests def get_package_test_info_local(package, pkg_type, tests_path, patch_target): if 'http' in urlparse(settings.PATCHING_PKGS_TESTS): get_method = get_package_test_info_remote elif os.path.isdir(settings.PATCHING_PKGS_TESTS): get_method = get_package_test_info_local else: raise Exception(""Path for packages tests doesn't look like URL or loca"" ""l folder: '{0}'"".format(settings.PATCHING_PKGS_TESTS)) tests = get_method(package, pkg_type, settings.PATCHING_PKGS_TESTS, target) if 'http' in urlparse(settings.PATCHING_APPLY_TESTS): return yaml.load(urlopen(scenario_path).read()) elif os.path.isdir(settings.PATCHING_APPLY_TESTS): with open(scenario_path) as f: return yaml.load(f.read()) else: raise Exception(""Path to patching tests doesn't look like URL or local"" "" folder: '{0}'"".format(settings.PATCHING_APPLY_TESTS)) def get_script_content(path, bug_id, script): scripts_path = '{0}/bugs/{1}/tests/{2}'.format(path, bug_id, script) if 'http' in urlparse(settings.PATCHING_APPLY_TESTS): return urlopen(scripts_path).read() elif os.path.isdir(settings.PATCHING_APPLY_TESTS): with open(scripts_path) as f: return f.read() file_content = get_script_content( path=settings.PATCHING_APPLY_TESTS, bug_id=settings.PATCHING_BUG_ID, script=file_name) command = ""echo '{0}' > {1}/{2}"".format(file_content, upload_path, file_name)",18,64
openstack%2Fneutron-vpnaas~master~I7c8146d8044bce773255679d9975af2fab4fda46,openstack/neutron-vpnaas,master,I7c8146d8044bce773255679d9975af2fab4fda46,Updated from global requirements,MERGED,2015-06-22 08:23:55.000000000,2015-06-25 08:41:58.000000000,2015-06-25 08:41:58.000000000,"[{'_account_id': 3}, {'_account_id': 841}, {'_account_id': 6659}, {'_account_id': 10980}]","[{'number': 1, 'created': '2015-06-22 08:23:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-vpnaas/commit/b642842a5adf442dc64494bbb037c5812d4d0374', 'message': 'Updated from global requirements\n\nChange-Id: I7c8146d8044bce773255679d9975af2fab4fda46\n'}, {'number': 2, 'created': '2015-06-22 20:16:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-vpnaas/commit/d60371aadc935e7c7e68ed4b885833d1165db5d4', 'message': 'Updated from global requirements\n\nChange-Id: I7c8146d8044bce773255679d9975af2fab4fda46\n'}, {'number': 3, 'created': '2015-06-24 14:42:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-vpnaas/commit/ad7fc863ef1303df1fb8ba97e79e62c26123e912', 'message': 'Updated from global requirements\n\nChange-Id: I7c8146d8044bce773255679d9975af2fab4fda46\n'}, {'number': 4, 'created': '2015-06-24 20:40:29.000000000', 'files': ['requirements.txt', 'test-requirements.txt', 'setup.py'], 'web_link': 'https://opendev.org/openstack/neutron-vpnaas/commit/489515ca81b886207d6f018752cb46333875b40a', 'message': 'Updated from global requirements\n\nChange-Id: I7c8146d8044bce773255679d9975af2fab4fda46\n'}]",0,193992,489515ca81b886207d6f018752cb46333875b40a,21,4,4,11131,,,0,"Updated from global requirements

Change-Id: I7c8146d8044bce773255679d9975af2fab4fda46
",git fetch https://review.opendev.org/openstack/neutron-vpnaas refs/changes/92/193992/3 && git format-patch -1 --stdout FETCH_HEAD,"['requirements.txt', 'test-requirements.txt', 'setup.py']",3,b642842a5adf442dc64494bbb037c5812d4d0374,openstack/requirements,,#!/usr/bin/env python,16,17
openstack%2Fpuppet-tripleo~master~Ib6a36e9283b73133251fb9ff3f33e71c50edb3db,openstack/puppet-tripleo,master,Ib6a36e9283b73133251fb9ff3f33e71c50edb3db,Remove control over the galera_master_node,MERGED,2015-06-23 12:25:21.000000000,2015-06-25 08:34:43.000000000,2015-06-25 08:34:41.000000000,"[{'_account_id': 3}, {'_account_id': 3153}, {'_account_id': 4328}, {'_account_id': 6796}, {'_account_id': 7582}, {'_account_id': 8399}, {'_account_id': 8449}, {'_account_id': 9410}, {'_account_id': 16282}]","[{'number': 1, 'created': '2015-06-23 12:25:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-tripleo/commit/c192d7d4e4d2c6e1f5485b873655b5aba91835c6', 'message': 'Remove control over the galera_master_node\n\nWe do not want to give users control over the galera_master_node,\nthis should be gathered using the clustercheck script instead.\n\nChange-Id: Ib6a36e9283b73133251fb9ff3f33e71c50edb3db\nCloses-Bug: 1467918\nCloses-Bug: https://bugzilla.redhat.com/show_bug.cgi?id=1234817\n'}, {'number': 2, 'created': '2015-06-23 12:47:35.000000000', 'files': ['manifests/loadbalancer.pp'], 'web_link': 'https://opendev.org/openstack/puppet-tripleo/commit/bf5994053fe2cf2382813ffedf54d04771138f26', 'message': 'Remove control over the galera_master_node\n\nWe do not want to give users control over the galera_master_node,\nthis should be gathered using the clustercheck script instead.\n\nDepends-On: I56ebd2d8405ac35c707666d993b396f04aeb683e\nChange-Id: Ib6a36e9283b73133251fb9ff3f33e71c50edb3db\nCloses-Bug: 1467918\nCloses-Bug: https://bugzilla.redhat.com/show_bug.cgi?id=1234817\n'}]",0,194624,bf5994053fe2cf2382813ffedf54d04771138f26,28,9,2,6796,,,0,"Remove control over the galera_master_node

We do not want to give users control over the galera_master_node,
this should be gathered using the clustercheck script instead.

Depends-On: I56ebd2d8405ac35c707666d993b396f04aeb683e
Change-Id: Ib6a36e9283b73133251fb9ff3f33e71c50edb3db
Closes-Bug: 1467918
Closes-Bug: https://bugzilla.redhat.com/show_bug.cgi?id=1234817
",git fetch https://review.opendev.org/openstack/puppet-tripleo refs/changes/24/194624/2 && git format-patch -1 --stdout FETCH_HEAD,['manifests/loadbalancer.pp'],1,c192d7d4e4d2c6e1f5485b873655b5aba91835c6,bug/1467918," ipaddresses => hiera('mysql_node_ips', $controller_hosts_real), server_names => $controller_hosts_names_real,","# [*galera_master_hostname*] # FQDN of the Galera master node # Defaults to undef # # [*galera_master_ip*] # IP of the Galera master node # Defaults to undef # $galera_master_hostname = undef, $galera_master_ip = undef, haproxy::balancermember { 'mysql': listening_service => 'mysql', ports => '3306', ipaddresses => $galera_master_ip, server_names => $galera_master_hostname, options => ['check', 'inter 2000', 'rise 2', 'fall 5'], } $controller_hosts_without_galera_master = delete(hiera('mysql_node_ips', $controller_hosts_real), $galera_master_ip) $controller_hosts_names_without_galera_master = delete($controller_hosts_names_real, downcase($galera_master_hostname)) ipaddresses => $controller_hosts_without_galera_master, server_names => $controller_hosts_names_without_galera_master,",2,23
openstack%2Fmistral~master~I2fc1f3bb4382b72d6de7d7508c82d64e64ca656c,openstack/mistral,master,I2fc1f3bb4382b72d6de7d7508c82d64e64ca656c,Implementing 'start_action' on engine side,MERGED,2015-06-09 08:44:45.000000000,2015-06-25 08:32:42.000000000,2015-06-25 08:32:40.000000000,"[{'_account_id': 3}, {'_account_id': 5558}, {'_account_id': 6732}, {'_account_id': 7700}, {'_account_id': 8731}, {'_account_id': 9432}, {'_account_id': 15881}]","[{'number': 1, 'created': '2015-06-09 08:44:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/mistral/commit/ee57ba834ebe461e8aa22e22371992a20602b68b', 'message': ""Implementing 'start_action' on engine side\n\n  * new engine method (symmetrically to start_workflow) -\n    start_action;\n  * possibility to run action without saving the result\n    to the DB;\n  * adjusted model_base: updated_at indeed can be None\n    in set of cases;\n  * improved engine.utils.validate_input for checking\n    action_input (also adhoc action input); for this\n    new util method for getting input dict from input\n    string is introduced;\n  * executor client can call rpc method synchronously\n    for immediately returning result from action and\n    without callback to engine;\n  * fixed uploading actions from workbook;\n  * improved action_handler;\n  * improved inspect_utils for input validation needs.\n\nTODO (next patch set):\n - Implementing run action API side\n\nPartially implements blueprint mistral-run-individual-action\n\nChange-Id: I2fc1f3bb4382b72d6de7d7508c82d64e64ca656c\n""}, {'number': 2, 'created': '2015-06-09 08:51:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/mistral/commit/aae74404b9a2ace37fe18d064e1669f109907cb0', 'message': ""Implementing 'start_action' on engine side\n\n  * new engine method (symmetrically to start_workflow) -\n    start_action;\n  * possibility to run action without saving the result\n    to the DB;\n  * adjusted model_base: updated_at indeed can be None\n    in set of cases;\n  * improved engine.utils.validate_input for checking\n    action_input (also adhoc action input); for this\n    new util method for getting input dict from input\n    string is introduced;\n  * executor client can call rpc method synchronously\n    for immediately returning result from action and\n    without callback to engine;\n  * fixed uploading actions from workbook;\n  * improved action_handler;\n  * improved inspect_utils for input validation needs.\n\nTODO (next patch set):\n - Implementing run action API side\n\nPartially implements blueprint mistral-run-individual-action\n\nChange-Id: I2fc1f3bb4382b72d6de7d7508c82d64e64ca656c\n""}, {'number': 3, 'created': '2015-06-09 14:16:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/mistral/commit/b0dc440fb1a98b413bd0d25dddc1d30e23c16b0e', 'message': ""Implementing 'start_action' on engine side\n\n  * new engine method (symmetrically to start_workflow) -\n    start_action;\n  * possibility to run action without saving the result\n    to the DB;\n  * adjusted model_base: updated_at indeed can be None\n    in set of cases;\n  * improved engine.utils.validate_input for checking\n    action_input (also adhoc action input); for this\n    new util method for getting input dict from input\n    string is introduced;\n  * executor client can call rpc method synchronously\n    for immediately returning result from action and\n    without callback to engine;\n  * fixed uploading actions from workbook;\n  * improved action_handler;\n  * improved inspect_utils for input validation needs.\n\nTODO (next commit):\n - Implementing run action API side\n\nPartially implements blueprint mistral-run-individual-action\n\nChange-Id: I2fc1f3bb4382b72d6de7d7508c82d64e64ca656c\n""}, {'number': 4, 'created': '2015-06-17 09:00:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/mistral/commit/6fae5aaa0bf23a1cbcca28170719b08839c672f0', 'message': ""Implementing 'start_action' on engine side\n\n  * new engine method (symmetrically to start_workflow) -\n    start_action;\n  * possibility to run action without saving the result\n    to the DB;\n  * adjusted model_base: updated_at indeed can be None\n    in set of cases;\n  * improved engine.utils.validate_input for checking\n    action_input (also adhoc action input); for this\n    new util method for getting input dict from input\n    string is introduced;\n  * executor client can call rpc method synchronously\n    for immediately returning result from action and\n    without callback to engine;\n  * fixed uploading actions from workbook;\n  * improved action_handler;\n  * improved inspect_utils for input validation needs.\n\nTODO (next commit):\n - Implementing run action API side\n\nPartially implements blueprint mistral-run-individual-action\n\nChange-Id: I2fc1f3bb4382b72d6de7d7508c82d64e64ca656c\n""}, {'number': 5, 'created': '2015-06-22 12:42:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/mistral/commit/2f09d43029b174c870006137a6d7ab1cf215d4d7', 'message': ""Implementing 'start_action' on engine side\n\n  * new engine method (symmetrically to start_workflow) -\n    start_action;\n  * possibility to run action without saving the result\n    to the DB;\n  * adjusted model_base: updated_at indeed can be None\n    in set of cases;\n  * improved engine.utils.validate_input for checking\n    action_input (also adhoc action input); for this\n    new util method for getting input dict from input\n    string is introduced;\n  * executor client can call rpc method synchronously\n    for immediately returning result from action and\n    without callback to engine;\n  * fixed uploading actions from workbook;\n  * improved action_handler;\n  * improved inspect_utils for input validation needs.\n\nTODO (next commit):\n - Implementing run action API side\n\nPartially implements blueprint mistral-run-individual-action\n\nChange-Id: I2fc1f3bb4382b72d6de7d7508c82d64e64ca656c\n""}, {'number': 6, 'created': '2015-06-22 13:25:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/mistral/commit/7b0dc931e94ede9787d095a05c4c3b27d066f139', 'message': ""Implementing 'start_action' on engine side\n\n  * new engine method (symmetrically to start_workflow) -\n    start_action;\n  * possibility to run action without saving the result\n    to the DB;\n  * adjusted model_base: updated_at indeed can be None\n    in set of cases;\n  * improved engine.utils.validate_input for checking\n    action_input (also adhoc action input); for this\n    new util method for getting input dict from input\n    string is introduced;\n  * executor client can call rpc method synchronously\n    for immediately returning result from action and\n    without callback to engine;\n  * fixed uploading actions from workbook;\n  * improved action_handler;\n  * improved inspect_utils for input validation needs.\n\nTODO (next commit):\n - Implementing run action API side\n\nPartially implements blueprint mistral-run-individual-action\n\nChange-Id: I2fc1f3bb4382b72d6de7d7508c82d64e64ca656c\n""}, {'number': 7, 'created': '2015-06-23 12:34:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/mistral/commit/10f517437dd225586357d67e53f3173ddfacc7be', 'message': ""Implementing 'start_action' on engine side\n\n  * new engine method (symmetrically to start_workflow) -\n    start_action;\n  * possibility to run action without saving the result\n    to the DB;\n  * adjusted model_base: updated_at indeed can be None\n    in set of cases;\n  * improved engine.utils.validate_input for checking\n    action_input (also adhoc action input); for this\n    new util method for getting input dict from input\n    string is introduced;\n  * executor client can call rpc method synchronously\n    for immediately returning result from action and\n    without callback to engine;\n  * fixed uploading actions from workbook;\n  * improved action_handler;\n  * improved inspect_utils for input validation needs.\n\nTODO (next commit):\n - Implementing run action API side\n\nPartially implements blueprint mistral-run-individual-action\n\nChange-Id: I2fc1f3bb4382b72d6de7d7508c82d64e64ca656c\n""}, {'number': 8, 'created': '2015-06-24 12:50:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/mistral/commit/43ce633eee4bb14678a3764355b3e642c3d3b906', 'message': ""Implementing 'start_action' on engine side\n\n  * new engine method (symmetrically to start_workflow) -\n    start_action;\n  * possibility to run action without saving the result\n    to the DB;\n  * adjusted model_base: updated_at indeed can be None\n    in set of cases;\n  * improved engine.utils.validate_input for checking\n    action_input (also adhoc action input); for this\n    new util method for getting input dict from input\n    string is introduced;\n  * executor client can call rpc method synchronously\n    for immediately returning result from action and\n    without callback to engine;\n  * fixed uploading actions from workbook;\n  * improved action_handler;\n  * improved inspect_utils for input validation needs.\n\nTODO (next commit):\n - Implementing run action API side\n\nPartially implements blueprint mistral-run-individual-action\n\nChange-Id: I2fc1f3bb4382b72d6de7d7508c82d64e64ca656c\n""}, {'number': 9, 'created': '2015-06-24 14:05:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/mistral/commit/5f02cb0659615322ba98743549411d31e924ef5c', 'message': ""Implementing 'start_action' on engine side\n\n  * new engine method (symmetrically to start_workflow) -\n    start_action;\n  * possibility to run action without saving the result\n    to the DB;\n  * adjusted model_base: updated_at indeed can be None\n    in set of cases;\n  * improved engine.utils.validate_input for checking\n    action_input (also adhoc action input); for this\n    new util method for getting input dict from input\n    string is introduced;\n  * executor client can call rpc method synchronously\n    for immediately returning result from action and\n    without callback to engine;\n  * fixed uploading actions from workbook;\n  * improved action_handler;\n  * improved inspect_utils for input validation needs.\n\nTODO (next commit):\n - Implementing run action API side\n\nPartially implements blueprint mistral-run-individual-action\n\nChange-Id: I2fc1f3bb4382b72d6de7d7508c82d64e64ca656c\n""}, {'number': 10, 'created': '2015-06-24 14:25:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/mistral/commit/445f29e9a9e350c428ab35b7d41c881c124f8a60', 'message': ""Implementing 'start_action' on engine side\n\n  * new engine method (symmetrically to start_workflow) -\n    start_action;\n  * possibility to run action without saving the result\n    to the DB;\n  * adjusted model_base: updated_at indeed can be None\n    in set of cases;\n  * improved engine.utils.validate_input for checking\n    action_input (also adhoc action input); for this\n    new util method for getting input dict from input\n    string is introduced;\n  * executor client can call rpc method synchronously\n    for immediately returning result from action and\n    without callback to engine;\n  * fixed uploading actions from workbook;\n  * improved action_handler;\n  * improved inspect_utils for input validation needs.\n\nTODO (next commit):\n - Implementing run action API side\n\nPartially implements blueprint mistral-run-individual-action\n\nChange-Id: I2fc1f3bb4382b72d6de7d7508c82d64e64ca656c\n""}, {'number': 11, 'created': '2015-06-24 17:02:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/mistral/commit/0c7b26472ede5b46400a88789878f64a63591a8c', 'message': ""Implementing 'start_action' on engine side\n\n  * new engine method (symmetrically to start_workflow) -\n    start_action;\n  * possibility to run action without saving the result\n    to the DB;\n  * adjusted model_base: updated_at indeed can be None\n    in set of cases;\n  * improved engine.utils.validate_input for checking\n    action_input (also adhoc action input); for this\n    new util method for getting input dict from input\n    string is introduced;\n  * executor client can call rpc method synchronously\n    for immediately returning result from action and\n    without callback to engine;\n  * fixed uploading actions from workbook;\n  * improved action_handler;\n  * improved inspect_utils for input validation needs.\n\nTODO (next commit):\n - Implementing run action API side\n\nPartially implements blueprint mistral-run-individual-action\n\nChange-Id: I2fc1f3bb4382b72d6de7d7508c82d64e64ca656c\n""}, {'number': 12, 'created': '2015-06-25 06:46:49.000000000', 'files': ['mistral/tests/unit/engine/test_run_action.py', 'mistral/utils/inspect_utils.py', 'mistral/services/action_manager.py', 'mistral/engine/task_handler.py', 'mistral/engine/default_executor.py', 'mistral/tests/unit/engine/test_environment.py', 'mistral/engine/base.py', 'mistral/tests/unit/services/test_action_manager.py', 'mistral/services/actions.py', 'mistral/tests/unit/engine/test_race_condition.py', 'mistral/tests/unit/utils/test_inspect_utils.py', 'mistral/tests/unit/utils/test_utils.py', 'mistral/engine/action_handler.py', 'mistral/engine/utils.py', 'mistral/services/workbooks.py', 'mistral/utils/__init__.py', 'mistral/tests/unit/engine/test_direct_workflow.py', 'mistral/engine/rpc.py', 'mistral/services/triggers.py', 'mistral/db/sqlalchemy/model_base.py', 'mistral/tests/unit/engine/test_with_items.py', 'mistral/engine/default_engine.py'], 'web_link': 'https://opendev.org/openstack/mistral/commit/9d5f19786986dc5f25d75b341adbbc95a1f82689', 'message': ""Implementing 'start_action' on engine side\n\n  * new engine method (symmetrically to start_workflow) -\n    start_action;\n  * possibility to run action without saving the result\n    to the DB;\n  * adjusted model_base: updated_at indeed can be None\n    in set of cases;\n  * improved engine.utils.validate_input for checking\n    action_input (also adhoc action input); for this\n    new util method for getting input dict from input\n    string is introduced;\n  * executor client can call rpc method synchronously\n    for immediately returning result from action and\n    without callback to engine;\n  * fixed uploading actions from workbook;\n  * improved action_handler;\n  * improved inspect_utils for input validation needs.\n\nTODO (next commit):\n - Implementing run action API side\n\nPartially implements blueprint mistral-run-individual-action\n\nChange-Id: I2fc1f3bb4382b72d6de7d7508c82d64e64ca656c\n""}]",23,189596,9d5f19786986dc5f25d75b341adbbc95a1f82689,41,7,12,7700,,,0,"Implementing 'start_action' on engine side

  * new engine method (symmetrically to start_workflow) -
    start_action;
  * possibility to run action without saving the result
    to the DB;
  * adjusted model_base: updated_at indeed can be None
    in set of cases;
  * improved engine.utils.validate_input for checking
    action_input (also adhoc action input); for this
    new util method for getting input dict from input
    string is introduced;
  * executor client can call rpc method synchronously
    for immediately returning result from action and
    without callback to engine;
  * fixed uploading actions from workbook;
  * improved action_handler;
  * improved inspect_utils for input validation needs.

TODO (next commit):
 - Implementing run action API side

Partially implements blueprint mistral-run-individual-action

Change-Id: I2fc1f3bb4382b72d6de7d7508c82d64e64ca656c
",git fetch https://review.opendev.org/openstack/mistral refs/changes/96/189596/2 && git format-patch -1 --stdout FETCH_HEAD,"['mistral/tests/unit/engine/test_run_action.py', 'mistral/utils/inspect_utils.py', 'mistral/services/action_manager.py', 'mistral/engine/task_handler.py', 'mistral/engine/default_executor.py', 'mistral/tests/unit/engine/test_environment.py', 'mistral/tests/unit/services/test_action_manager.py', 'mistral/services/actions.py', 'mistral/tests/unit/engine/test_race_condition.py', 'mistral/tests/unit/utils/test_inspect_utils.py', 'mistral/tests/unit/utils/test_utils.py', 'mistral/engine/action_handler.py', 'mistral/engine/utils.py', 'mistral/services/workbooks.py', 'mistral/utils/__init__.py', 'mistral/tests/unit/engine/test_direct_workflow.py', 'mistral/engine/rpc.py', 'mistral/db/sqlalchemy/model_base.py', 'mistral/tests/unit/engine/test_with_items.py', 'mistral/engine/default_engine.py']",20,ee57ba834ebe461e8aa22e22371992a20602b68b,bp/mistral-run-individual-action,"from mistral.engine import action_handler eng_utils.validate_input(wf_def, wf_input, wf_spec) @u.log_exec(LOG) def start_action(self, action_name, action_input, **params): with db_api.transaction(): action_def = action_handler.resolve_definition(action_name) action_input = action_handler.get_action_input( action_name, action_input ) if params.get('save_result'): action_ex = action_handler.create_action_execution( action_def, action_input ) action_handler.run_action( action_def, action_input, action_ex.id, params.get('target') ) return action_ex else: return action_handler.run_action( action_def, action_input, target=params.get('target'), async=False ) # In case of single action execution there is no # assigned task execution. if not action_ex.task_execution: return action_handler.store_action_result( action_ex, result ).get_clone() "," eng_utils.validate_input(wf_def, wf_spec, wf_input)",407,130
openstack%2Ffuel-specs~master~I666c1d1de9e128147174abc0a178a41828ae5d93,openstack/fuel-specs,master,I666c1d1de9e128147174abc0a178a41828ae5d93,Spec for Neutron DVR support in Fuel,MERGED,2015-06-10 12:57:36.000000000,2015-06-25 08:29:21.000000000,2015-06-25 08:29:18.000000000,"[{'_account_id': 3}, {'_account_id': 4656}, {'_account_id': 5948}, {'_account_id': 5950}, {'_account_id': 6926}, {'_account_id': 7125}, {'_account_id': 7227}, {'_account_id': 7468}, {'_account_id': 7604}, {'_account_id': 7787}, {'_account_id': 8786}, {'_account_id': 8797}, {'_account_id': 11090}, {'_account_id': 13343}, {'_account_id': 13344}]","[{'number': 1, 'created': '2015-06-10 12:57:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-specs/commit/e30128a19a8ddb8998f2aef9a4ee2525b62484a0', 'message': 'Spec for Neutron DVR support in Fuel\n\nImplements blueprint neutron-dvr-deployment\n\nChange-Id: I666c1d1de9e128147174abc0a178a41828ae5d93\n'}, {'number': 2, 'created': '2015-06-10 12:58:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-specs/commit/c81e7e098c56107518cd7833c685eaeea57f8c52', 'message': 'Spec for Neutron DVR support in Fuel\n\nImplements blueprint neutron-dvr-deployment\n\nChange-Id: I666c1d1de9e128147174abc0a178a41828ae5d93\n'}, {'number': 3, 'created': '2015-06-10 13:08:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-specs/commit/4d90b6defb4883f1c2f00d5c5dcde8998053b685', 'message': 'Spec for Neutron DVR support in Fuel\n\nImplements blueprint neutron-dvr-deployment\n\nChange-Id: I666c1d1de9e128147174abc0a178a41828ae5d93\n'}, {'number': 4, 'created': '2015-06-10 13:59:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-specs/commit/cbaa13f9bad1c29e88c95bf07a13a26171695c3f', 'message': 'Spec for Neutron DVR support in Fuel\n\nImplements blueprint neutron-dvr-deployment\n\nChange-Id: I666c1d1de9e128147174abc0a178a41828ae5d93\n'}, {'number': 5, 'created': '2015-06-19 08:58:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-specs/commit/c57e9ada496756c44fff4fbf07660914218748bd', 'message': 'Spec for Neutron DVR support in Fuel\n\nImplements blueprint neutron-dvr-deployment\n\nChange-Id: I666c1d1de9e128147174abc0a178a41828ae5d93\n'}, {'number': 6, 'created': '2015-06-19 16:41:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-specs/commit/04a2a978d46990ba4532be2adc0f7cf3b78ea719', 'message': 'Spec for Neutron DVR support in Fuel\n\nImplements blueprint neutron-dvr-deployment\n\nChange-Id: I666c1d1de9e128147174abc0a178a41828ae5d93\n'}, {'number': 7, 'created': '2015-06-23 08:46:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-specs/commit/3482b9e5a9b98e1a0868931d072a33792b483502', 'message': 'Spec for Neutron DVR support in Fuel\n\nImplements blueprint neutron-dvr-deployment\n\nChange-Id: I666c1d1de9e128147174abc0a178a41828ae5d93\n'}, {'number': 8, 'created': '2015-06-23 12:05:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-specs/commit/44e8ae2735b6796c98fa2b17400299c84e6be518', 'message': 'Spec for Neutron DVR support in Fuel\n\nImplements blueprint neutron-dvr-deployment\n\nChange-Id: I666c1d1de9e128147174abc0a178a41828ae5d93\n'}, {'number': 9, 'created': '2015-06-23 15:21:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-specs/commit/416dad78873fe3ecd3ed8b7d79244ef05db53bd9', 'message': 'Spec for Neutron DVR support in Fuel\n\nImplements blueprint neutron-dvr-deployment\n\nChange-Id: I666c1d1de9e128147174abc0a178a41828ae5d93\n'}, {'number': 10, 'created': '2015-06-23 15:29:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-specs/commit/e2d5a1877644e3987591be71709d9a3dd32917b9', 'message': 'Spec for Neutron DVR support in Fuel\n\nImplements blueprint neutron-dvr-deployment\n\nChange-Id: I666c1d1de9e128147174abc0a178a41828ae5d93\n'}, {'number': 11, 'created': '2015-06-23 15:45:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-specs/commit/1be521e072c524dd6473fd130366b980f4737aa0', 'message': 'Spec for Neutron DVR support in Fuel\n\nImplements blueprint neutron-dvr-deployment\n\nChange-Id: I666c1d1de9e128147174abc0a178a41828ae5d93\n'}, {'number': 12, 'created': '2015-06-23 15:52:36.000000000', 'files': ['specs/7.0/neutron-dvr-deployment.rst'], 'web_link': 'https://opendev.org/openstack/fuel-specs/commit/af523046903cbf5eae406ad5eeefa7a2be590438', 'message': 'Spec for Neutron DVR support in Fuel\n\nImplements blueprint neutron-dvr-deployment\n\nChange-Id: I666c1d1de9e128147174abc0a178a41828ae5d93\n'}]",56,190172,af523046903cbf5eae406ad5eeefa7a2be590438,59,15,12,5948,,,0,"Spec for Neutron DVR support in Fuel

Implements blueprint neutron-dvr-deployment

Change-Id: I666c1d1de9e128147174abc0a178a41828ae5d93
",git fetch https://review.opendev.org/openstack/fuel-specs refs/changes/72/190172/12 && git format-patch -1 --stdout FETCH_HEAD,['specs/7.0/neutron-dvr-deployment.rst'],1,e30128a19a8ddb8998f2aef9a4ee2525b62484a0,bp/neutron-dvr-deployment,".. This work is licensed under a Creative Commons Attribution 3.0 Unported License. http://creativecommons.org/licenses/by/3.0/legalcode =================== Neutron DVR support =================== https://blueprints.launchpad.net/fuel/+spec/neutron-dvr-deployment Neutron Distributed Virtual Router implements the L3 Routers across the compute nodes, so that tenants intra VM communication will occur without hitting the controller node. (East-West Routing) Also Neutron Distributed Virtual Router implements the Floating IP namespace on every compute node where the VMs are located. In this case the VMs with FloatingIPs can forward the traffic to the external network without reaching the controller node. (North-South Routing) Neutron Distributed Virtual Router provides the legacy SNAT behavior for the default SNAT for all private VMs. SNAT service is not distributed, it is centralized and the service node will host the service. Problem description =================== Currently Neutron L3 Routers are deployed on specific Nodes (controller nodes) where all the compute traffic will flow through. * Problem 1: Intra VM traffic flows through the controller node In this case even VMs traffic that belong to the same tenant on a different subnet has to hit the controller node to get routed between the subnets. This would affect performance and scalability. * Problem 2: VMs with FloatingIP also receive and send packets through the controller node routers Today FloatingIP (DNAT) translation is done at the controller node and also the external network gateway port is available only at the controller So any traffic that is intended for the external network from the VM will have to go through the controller node. In this case the controller node becomes a single point of failure and also the traffic load will be heavy in the controller node. This would affect the performance and scalability. Proposed change =============== The proposal is to distribute L3 Routers across compute nodes when required by VMs. This implies having external network access on each compute node. In this case there will be enhanced L3 Agents running on each and every compute node (This is not a new agent, this is an updated version of the existing L3 Agent). Based on the configuration in the L3 Agent.ini file, the enhanced L3 Agent will behave in legacy (centralized router) mode or as a distributed router mode. Also the FloatingIP will have a new namespace created on the specific compute node where the VM is located (this is done by L3 agent itself). Each Compute Node will have one new namespace for FloatingIP per external network that will be shared among the tenants. An external gateway port will also be created on each compute node for the external traffic to flow through. This port will consume additional IP address from external network. The namespace with gateway port (and public IP) will be created on the compute node only in case there are VMs with Floating IP residing on this node. Default SNAT functionality will still be centralized and will be running on controller nodes. The Metadata agent will be distributed as well and will be hosted on all compute nodes and the Metadata Proxy will be hosted on all the distributed routers. This implementation is specific to ML2 with OVS driver. All three type of segmentation are supported: GRE, VXLAN, VLAN. Constraints and Limitations --------------------------- * No Distributed SNAT Neutron Distributed Virtual Router provides the legacy SNAT behavior for the default SNAT for all private VMs. SNAT service is not distributed, it is centralized and the service node will host the service. Thus current DVR architecture is not fully fault tolerant - outbound traffic for VMs without floating IPs is still going through one L3_agent node and is still prone to failures of a single node. * Only with ML2-OVS/L2-pop DVR feature is supported only by ML2 plugin with OVS mechanism driver. If using tunnel segmentation (VXLAN, GRE) L2 population mechanism should be enabled as well. * OVS and Kernel versions Proper operation of DVR requires OpenvSwitch 2.1 or newer and VXLAN requires kernel 3.13 or newer. Deployment impact ----------------- * Architecture changes * Neutron L3 and metadata agents will be deployed on all compute nodes and managed by Upstart. Agents deployment scheme on controller nodes is not changed. * All compute nodes require external bridge * Fuel Library related changes * Update Neutron Puppet module to support DVR-related options (L3 agent mode, L2 population, distributed router option) * Update Cloud Networking related Puppet modules to deploy Neutron L3 and metadata agents on compute nodes with appropriate configuration * update Horizon related Puppet modules to add an ability to enable Neutron DVR options * Fuel Web related changes * When Neutron DVR is enabled, a network scheme with external bridges on all compute nodes should be generated Alternatives ------------ None Data model impact ----------------- ""distributed"" flag will be added to the router object data model. This will enable the agent to take necessary action based on the router model. REST API impact --------------- Admin will be able to set ""distributed"" attribute on router create and update API calls. Users need not be aware about this attribute in the router table. So it is not visible to regular users. Upgrade impact -------------- The upgrade path from legacy to distributed router is supported. It's a 3 step process: * neutron router-update router1 --admin_state_up=False * neutron router-update router1 --distributed=True * neutron router-update router1 --admin_state_up=True distributed->legacy upgrade is not officially supported in Kilo but it may work, just needs to be tested. Security impact --------------- None Notifications impact -------------------- None Other end user impact --------------------- None Performance Impact ------------------ Inter VM traffic between the tenant subnets doesn't need to reach the router in the controller node to get routed and will be routed locally from the compute node. This would increase the performance substantially. Also the Floating IP traffic for a VM from a Compute Node will directly hit the external network from the compute node, instead of going through the router on the controller node. Dataplane testing results from 25 bare metal nodes env show significant performance improvement for both East-West and North-South (with floating IPs) scenarios. Plugin impact ------------- None Other deployer impact --------------------- None Developer impact ---------------- None Infrastructure impact --------------------- None Implementation ============== Assignee(s) ----------- Primary assignee: obondarev Other contributors: skolekonov Work Items ---------- * Patch fuel-lib to enable DVR by default * this will enable DVR testing at early stage * Scale testing * Rally scenarios * Shaker scenarios * debug * bug fixing/backport from upstream * Patch fuel-web to add ability to enable/disable DVR * disable DVR by default Dependencies ============ This will likely depend on enabling l2-population for tunneling which is a separate effort. However we will not wait but enable l2 pop as part of DVR effort if needed. Testing ======= Manual Acceptance Tests ----------------------- * On an environment with DVR enabled check that created router has distributed  attribute set to True via Horizon or CLI * Boot a VM on a subnet connected to DVR router. Check external connectivity. * Assign Floating IP to the VM. Check external connectivity. Ensure VM is reachable from external network. * Boot a second VM on a different subnet connected to the same router. Ensure inter-subnet connectivity (both VM can reach each other) Scale ----- * Environment with DVR enabled should pass all tests currently run on Scale Lab with no significant performance degradation * No additional Rally scenarios are needed to test specifics of DVR. HA/Destructive Tests -------------------- All existing HA/destructive tests should pass on env with DVR enabled. Additional scenarios should include: * East-West HA Test * Have several VM from different subnets running on different compute nodes. The subnets should be connected to each other and to an external network by a DVR router * Shutdown all controllers of the environment * Inter-subnet connectivity should be preserved: VMs from different subnets/compute nodes should still be able to reach each other * No dataplane downtime is expected * North-South HA Test * Have a VM with Floating IP running on a subnet connected to an external network by a DVR router * Shutdown all controllers of the environment. * External connectivity should be preserved: VMs should still be able to reach external network * No dataplane downtime is expected Data Plane Tests with Shaker ---------------------------- Shaker scenarios should be run on a bare-metal environment with DVR enabled. Significant increase in performance is expected for east-west and north-south (with Floating IPs) topologies. Some of the results were already obtained (see ""Performance Impact"" section of the this doc) Documentation Impact ==================== Ability to enable DVR support in Neutron should be documented in Fuel Deployment Guide. References ========== None ",,327,0
openstack%2Ftripleo-common~master~If204d0b74f5ed1fb63206b11642805e8f3d3c3a8,openstack/tripleo-common,master,If204d0b74f5ed1fb63206b11642805e8f3d3c3a8,Add a step-through heat stack update module,MERGED,2015-04-28 11:59:16.000000000,2015-06-25 08:28:44.000000000,2015-06-25 08:28:44.000000000,"[{'_account_id': 3}, {'_account_id': 4257}, {'_account_id': 4571}, {'_account_id': 6796}, {'_account_id': 7144}, {'_account_id': 7582}, {'_account_id': 9712}, {'_account_id': 12321}]","[{'number': 1, 'created': '2015-04-28 11:59:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-common/commit/e52e3936470b5f6f96f8a4a19a9c1817a1a8fe39', 'message': 'Add update overcloud method (WIP)\n\nStill just WIP, needs more testing.\nNext steps: move/re-use hook polling logic from heatclient\n(https://review.openstack.org/#/c/173969/)\n\nChange-Id: If204d0b74f5ed1fb63206b11642805e8f3d3c3a8\n'}, {'number': 2, 'created': '2015-04-28 14:50:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-common/commit/ba79796b538a4794143154b33b92345a9bc9f381', 'message': 'Add update overcloud method (WIP)\n\nStill just WIP, needs more testing.\nNext steps: move/re-use hook polling logic from heatclient\n(https://review.openstack.org/#/c/173969/)\n\nChange-Id: If204d0b74f5ed1fb63206b11642805e8f3d3c3a8\n'}, {'number': 3, 'created': '2015-04-30 13:16:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-common/commit/3597075ea03cca7273787f822dd175872d51cd78', 'message': 'Add update overcloud method (WIP)\n\nStep through update (WIP)\n\nChange-Id: If204d0b74f5ed1fb63206b11642805e8f3d3c3a8\n'}, {'number': 4, 'created': '2015-05-04 18:34:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-common/commit/ed5a59d322f5477ef19959c201a1de0aefcdfc16', 'message': 'Add a step-through heat stack update module\n\nThis module allows checking in what state is a stack,\nif there are some pending hooks, and allows removing\nhooks.\n\nIt includes also a simple interactive CLI method which\ncan be used to go through one-by-one hooks removal.\n\nChange-Id: If204d0b74f5ed1fb63206b11642805e8f3d3c3a8\n'}, {'number': 5, 'created': '2015-05-05 17:59:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-common/commit/e589413411ba3cc18de59644e252c1ab79d918e6', 'message': 'Add a step-through heat stack update module\n\nThis module allows checking in what state is a stack,\nif there are some pending hooks, and allows removing\nhooks.\n\nIt includes also a simple interactive CLI method which\ncan be used to go through one-by-one hooks removal.\n\nChange-Id: If204d0b74f5ed1fb63206b11642805e8f3d3c3a8\n'}, {'number': 6, 'created': '2015-05-05 19:44:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-common/commit/6f32aaac010837f2ad84818b623c81c47825f001', 'message': 'Add a step-through heat stack update module\n\nThis module allows checking in what state is a stack,\nif there are some pending hooks, and allows removing\nhooks.\n\nIt includes also a simple interactive CLI method which\ncan be used to go through one-by-one hooks removal.\n\nChange-Id: If204d0b74f5ed1fb63206b11642805e8f3d3c3a8\n'}, {'number': 7, 'created': '2015-05-07 20:17:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-common/commit/76223d9eb31c3df43b1dd1875fa1403b0749c7d7', 'message': 'Add a step-through heat stack update module\n\nThis module allows checking in what state is a stack,\nif there are some pending hooks, and allows removing\nhooks.\n\nIt includes also a simple interactive CLI method which\ncan be used to go through one-by-one hooks removal.\n\nChange-Id: If204d0b74f5ed1fb63206b11642805e8f3d3c3a8\n'}, {'number': 8, 'created': '2015-05-11 19:19:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-common/commit/00697ec644162caea2616f1444ad14f50f80440d', 'message': 'Add a step-through heat stack update module\n\nThis module allows checking in what state is a stack,\nif there are some pending hooks, and allows removing\nhooks.\n\nOnce I71b19202ab29f44e5c09b4ee04be4aeaea038c28 is merged\npython heatclient will support a general hook polling\nmethod which could be used in future. For now the general\npolling method is not ideal because it checks recursively\nall events on all nested stack, in step-through story\nwe know resource names we want to check so we can do\nsignificantly less requests and check only resources related\nto the step-through update.\n\nChange-Id: If204d0b74f5ed1fb63206b11642805e8f3d3c3a8\n'}, {'number': 9, 'created': '2015-05-12 11:11:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-common/commit/684debf08babce9928b8a7c948b0d092932e5f04', 'message': 'Add a step-through heat stack update module\n\nThis module allows checking in what state is a stack,\nif there are some pending hooks, and allows removing\nhooks.\n\nOnce I71b19202ab29f44e5c09b4ee04be4aeaea038c28 is merged\npython heatclient will support a general hook polling\nmethod which could be used in future. For now the general\npolling method is not ideal because it checks recursively\nall events on all nested stack, in step-through story\nwe know resource names we want to check so we can do\nsignificantly less requests and check only resources related\nto the step-through update.\n\nChange-Id: If204d0b74f5ed1fb63206b11642805e8f3d3c3a8\n'}, {'number': 10, 'created': '2015-05-12 15:00:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-common/commit/7e04fdacd29e36ef003ca26b5efbc8adca5338fa', 'message': 'Add a step-through heat stack update module\n\nThis module allows checking in what state is a stack,\nif there are some pending hooks, and allows removing\nhooks.\n\nOnce I71b19202ab29f44e5c09b4ee04be4aeaea038c28 is merged\npython heatclient will support a general hook polling\nmethod which could be used in future. For now the general\npolling method is not ideal because it checks recursively\nall events on all nested stack, in step-through story\nwe know resource names we want to check so we can do\nsignificantly less requests and check only resources related\nto the step-through update.\n\nChange-Id: If204d0b74f5ed1fb63206b11642805e8f3d3c3a8\n'}, {'number': 11, 'created': '2015-05-27 11:54:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-common/commit/512f1bcb45f9530ace1ab0c43a40b35c9eacf1f7', 'message': 'Add a step-through heat stack update module\n\nThis module allows checking in what state is a stack,\nif there are some pending hooks, and allows removing\nhooks.\n\nOnce I71b19202ab29f44e5c09b4ee04be4aeaea038c28 is merged\npython heatclient will support a general hook polling\nmethod which could be used in future. For now the general\npolling method is not ideal because it checks recursively\nall events on all nested stack, in step-through story\nwe know resource names we want to check so we can do\nsignificantly less requests and check only resources related\nto the step-through update.\n\nChange-Id: If204d0b74f5ed1fb63206b11642805e8f3d3c3a8\n'}, {'number': 12, 'created': '2015-05-27 20:10:38.000000000', 'files': ['tripleo_common/tests/test_stack_update.py', 'tripleo_common/stack_update.py'], 'web_link': 'https://opendev.org/openstack/tripleo-common/commit/4d778890cb42fdfd692775af026316c6b9c6f4c2', 'message': 'Add a step-through heat stack update module\n\nThis module allows checking in what state is a stack,\nif there are some pending hooks, and allows removing\nhooks.\n\nOnce I71b19202ab29f44e5c09b4ee04be4aeaea038c28 is merged\npython heatclient will support a general hook polling\nmethod which could be used in future. For now the general\npolling method is not ideal because it checks recursively\nall events on all nested stack, in step-through story\nwe know resource names we want to check so we can do\nsignificantly less requests and check only resources related\nto the step-through update.\n\nChange-Id: If204d0b74f5ed1fb63206b11642805e8f3d3c3a8\n'}]",0,178150,4d778890cb42fdfd692775af026316c6b9c6f4c2,39,8,12,7582,,,0,"Add a step-through heat stack update module

This module allows checking in what state is a stack,
if there are some pending hooks, and allows removing
hooks.

Once I71b19202ab29f44e5c09b4ee04be4aeaea038c28 is merged
python heatclient will support a general hook polling
method which could be used in future. For now the general
polling method is not ideal because it checks recursively
all events on all nested stack, in step-through story
we know resource names we want to check so we can do
significantly less requests and check only resources related
to the step-through update.

Change-Id: If204d0b74f5ed1fb63206b11642805e8f3d3c3a8
",git fetch https://review.opendev.org/openstack/tripleo-common refs/changes/50/178150/11 && git format-patch -1 --stdout FETCH_HEAD,"['tripleo_common/tests/test_stack_update.py', 'tripleo_common/stack_update.py', 'tripleo_common/tests/test_update.py', 'tripleo_common/update.py']",4,e52e3936470b5f6f96f8a4a19a9c1817a1a8fe39,updates,"# Copyright 2015 Red Hat, Inc. # All Rights Reserved. # # Licensed under the Apache License, Version 2.0 (the ""License""); you may # not use this file except in compliance with the License. You may obtain # a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT # WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the # License for the specific language governing permissions and limitations # under the License. import logging import time import yaml from heatclient.common import template_utils from tripleo_common import libutils from tripleo_common import stack_update from tuskarclient.common import utils as tuskarutils LOG = logging.getLogger(__name__) class PackageUpdateManager(stack_update.StackUpdateManager): def __init__(self, heatclient, tuskarclient, stack_id, plan_id): stack = heatclient.stacks.get(stack_id) self.tuskarclient = tuskarclient self.plan = tuskarutils.find_resource(self.tuskarclient.plans, plan_id) super(PackageUpdateManager, self).__init__( heatclient=heatclient, stack=stack, hook_type='pre-update', nested_depth=5, resource_name='update_deployment') def update(self): params = libutils.heat_params_from_templates( self.tuskarclient.plans.templates(self.plan.uuid)) timestamp = int(time.time()) params['parameters'] = { 'Controller-1::update_timestamp': timestamp, } env = yaml.load(params['environment']) template_utils.deep_update(env, { 'resource_registry': { 'resources': { '*': { '*': { 'update_deployment': {'hooks': 'pre-update'} } } } } }) params['environment'] = env LOG.info('updating stack: {0}', params) self.heatclient.stacks.update(self.stack.id, **params) ",,346,0
openstack%2Fneutron~feature%2Fqos~I7528d30b9d731c3b4d200c7d10454a819151eae4,openstack/neutron,feature/qos,I7528d30b9d731c3b4d200c7d10454a819151eae4,WIP: Agent extensions manager and SR-IOV agent for Qos,ABANDONED,2015-06-09 13:47:54.000000000,2015-06-25 08:24:33.000000000,,"[{'_account_id': 3}, {'_account_id': 2888}, {'_account_id': 4656}, {'_account_id': 5170}, {'_account_id': 6598}, {'_account_id': 8788}, {'_account_id': 9656}, {'_account_id': 9682}, {'_account_id': 9751}, {'_account_id': 9787}, {'_account_id': 10153}, {'_account_id': 10387}, {'_account_id': 10692}, {'_account_id': 11343}, {'_account_id': 12171}, {'_account_id': 14208}, {'_account_id': 14212}, {'_account_id': 14213}, {'_account_id': 14214}, {'_account_id': 14216}, {'_account_id': 14571}, {'_account_id': 14605}, {'_account_id': 15296}, {'_account_id': 15444}]","[{'number': 1, 'created': '2015-06-09 13:47:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/658227065f6c8d1f1d56b7b8f0a7fdd460bdee33', 'message': 'WIP: POC Agent mech driver\n\nThis patch POC the agent mech driver for better segregation\nbetween ML2 core and extention drivers. The POC in using the\nport security extension driver.\n\n* add rpc from agent to server on init to get the supported\n  extention drivers\n* in ml2 rpc segregate the neutron core from the extentions data.\n* add agent extension manager that load supported extension from server.\n* call handle_port_extensons on treat_devices_added_or_updated.\n\nChange-Id: I7528d30b9d731c3b4d200c7d10454a819151eae4\n'}, {'number': 2, 'created': '2015-06-09 15:43:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/812f76fcd70a477ecfdb304dd2eef183cbe6c209', 'message': 'WIP: POC Agent mech driver for Qos\n\nThis patch POC the agent mech driver for better segregation\nbetween ML2 core and extension drivers. The POC in using the\nport security extension driver, but in the future it should\nbe Qos extension driver.\n\n* add rpc from agent to server on init to get the supported\n  extension drivers\n* in ml2 rpc segregate the neutron core from the extensions data.\n* add agent extension manager that load supported extension from server.\n* call handle_port_extensions on treat_devices_added_or_updated.\n\nChange-Id: I7528d30b9d731c3b4d200c7d10454a819151eae4\n'}, {'number': 3, 'created': '2015-06-11 10:31:55.000000000', 'files': ['neutron/agent/l2/agent_extension.py', 'neutron/agent/l2/extensions/qos_agent.py', 'neutron/plugins/sriovnicagent/sriov_nic_agent.py', 'neutron/agent/l2/extensions/__init__.py', 'neutron/agent/l2/__init__.py', 'neutron/common/constants.py', 'neutron/api/rpc/handlers/extension_rpc.py', 'neutron/plugins/sriovnicagent/extension_drivers/qos_driver.py', 'neutron/agent/l2/agent_extensions_manager.py', 'neutron/agent/l2/l2_agent.py', 'setup.cfg', 'neutron/plugins/sriovnicagent/extension_drivers/__init__.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/5617eb65c32d93bd1e9d38a38d6c36e102c36229', 'message': 'WIP: Agent extensions manager and SR-IOV agent for Qos\n\nThis patch introdoce the following\n* Agent extensions manager and Agent extension - provides better\n  segregation between L2 Agent Core and L2 Agent Extensions.\n* QosAgentExtension - which will get the rules of the policy.\n* QosAgentDriver - abstact class\n* SriovAgentDriver - implement of  SR-IOV Qos functionality\n* L2Agent - abstact class\n* SR-IOV agent changes - support of Agent extensions manager\n\nChange-Id: I7528d30b9d731c3b4d200c7d10454a819151eae4\n'}]",32,189723,5617eb65c32d93bd1e9d38a38d6c36e102c36229,55,24,3,12171,,,0,"WIP: Agent extensions manager and SR-IOV agent for Qos

This patch introdoce the following
* Agent extensions manager and Agent extension - provides better
  segregation between L2 Agent Core and L2 Agent Extensions.
* QosAgentExtension - which will get the rules of the policy.
* QosAgentDriver - abstact class
* SriovAgentDriver - implement of  SR-IOV Qos functionality
* L2Agent - abstact class
* SR-IOV agent changes - support of Agent extensions manager

Change-Id: I7528d30b9d731c3b4d200c7d10454a819151eae4
",git fetch https://review.opendev.org/openstack/neutron refs/changes/23/189723/2 && git format-patch -1 --stdout FETCH_HEAD,"['neutron/plugins/ml2/rpc.py', 'neutron/agent/driver_api.py', 'neutron/api/rpc/handlers/extension_drivers_rpc.py', 'neutron/plugins/ml2/extensions/port_security.py', 'neutron/plugins/openvswitch/agent/ovs_neutron_agent.py', 'neutron/plugins/openvswitch/extentions/port_security.py', 'neutron/plugins/ml2/plugin.py', 'neutron/common/constants.py', 'neutron/plugins/ml2/managers.py', 'neutron/plugins/openvswitch/extentions/__init__.py', 'neutron/plugins/ml2/driver_api.py', 'neutron/agent/extension_manager.py', 'setup.cfg']",13,658227065f6c8d1f1d56b7b8f0a7fdd460bdee33,neutron-qos,neutron.agent.ovs.extension_drivers = port_security = neutron.plugins.openvswitch.extentions.port_security:PortSecurityExtensionDriver,,345,30
openstack%2Fopenstack-manuals~master~I133fa8e66c390b01000611bc8efc754fc47d6445,openstack/openstack-manuals,master,I133fa8e66c390b01000611bc8efc754fc47d6445,Convert Identity files to RST,MERGED,2015-06-22 06:57:17.000000000,2015-06-25 08:22:24.000000000,2015-06-25 08:22:22.000000000,"[{'_account_id': 3}, {'_account_id': 9382}, {'_account_id': 10497}, {'_account_id': 10607}, {'_account_id': 10705}, {'_account_id': 12686}, {'_account_id': 14643}, {'_account_id': 14947}, {'_account_id': 14962}]","[{'number': 1, 'created': '2015-06-22 06:57:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/fdc6eeffda2634b7e7f4ea2a282645b7b948f962', 'message': 'Convert Identity files to RST\n\nFiles converted:\n- Certificates for PKI\n- Configure the Identity Service with SSL\n- External authentication with Identity\n\nChange-Id: I133fa8e66c390b01000611bc8efc754fc47d6445\nImplements: blueprint reorganise-user-guide\n'}, {'number': 2, 'created': '2015-06-22 08:00:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/e3bf496129435be7f92e771e440955922a0475f7', 'message': 'Convert Identity files to RST\n\nFiles converted:\n- Certificates for PKI\n- Configure the Identity Service with SSL\n- External authentication with Identity\n\nChange-Id: I133fa8e66c390b01000611bc8efc754fc47d6445\nImplements: blueprint reorganise-user-guide\n'}, {'number': 3, 'created': '2015-06-23 02:54:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/efcd198dc92c7d6ffcfc0e82e905266718f36983', 'message': 'Convert Identity files to RST\n\nFiles converted:\n- Certificates for PKI\n- Configure the Identity Service with SSL\n- External authentication with Identity\n\nChange-Id: I133fa8e66c390b01000611bc8efc754fc47d6445\nImplements: blueprint reorganise-user-guide\n'}, {'number': 4, 'created': '2015-06-24 01:24:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/81efc87a0717cb1106306d36215156a9c24ced98', 'message': 'Convert Identity files to RST\n\nFiles converted:\n- Certificates for PKI\n- Configure the Identity Service with SSL\n- External authentication with Identity\n\nChange-Id: I133fa8e66c390b01000611bc8efc754fc47d6445\nImplements: blueprint reorganise-user-guide\n'}, {'number': 5, 'created': '2015-06-24 02:27:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/94c427bf9f3fad340c48670e690b97760ab6fb47', 'message': 'Convert Identity files to RST\n\nFiles converted:\n- Certificates for PKI\n- Configure the Identity Service with SSL\n- External authentication with Identity\n\nChange-Id: I133fa8e66c390b01000611bc8efc754fc47d6445\nImplements: blueprint reorganise-user-guide\n'}, {'number': 6, 'created': '2015-06-24 02:56:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/789788d451a0d89311bf4782a503b8dc52c0174c', 'message': 'Convert Identity files to RST\n\nFiles converted:\n- Certificates for PKI\n- Configure the Identity Service with SSL\n- External authentication with Identity\n\nChange-Id: I133fa8e66c390b01000611bc8efc754fc47d6445\nImplements: blueprint reorganise-user-guide\n'}, {'number': 7, 'created': '2015-06-25 02:15:01.000000000', 'files': ['doc/admin-guide-cloud-rst/source/keystone_certificates_for_pki.rst', 'doc/admin-guide-cloud-rst/source/identity_management.rst', 'doc/admin-guide-cloud-rst/source/keystone_external_authentication.rst', 'doc/admin-guide-cloud-rst/source/keystone_configure_with_SSL.rst'], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/3f23421ca5ebce0ca5deb05d84de7ad6316fc1b6', 'message': 'Convert Identity files to RST\n\nFiles converted:\n- Certificates for PKI\n- Configure the Identity Service with SSL\n- External authentication with Identity\n\nChange-Id: I133fa8e66c390b01000611bc8efc754fc47d6445\nImplements: blueprint reorganise-user-guide\n'}]",27,193958,3f23421ca5ebce0ca5deb05d84de7ad6316fc1b6,38,9,7,10705,,,0,"Convert Identity files to RST

Files converted:
- Certificates for PKI
- Configure the Identity Service with SSL
- External authentication with Identity

Change-Id: I133fa8e66c390b01000611bc8efc754fc47d6445
Implements: blueprint reorganise-user-guide
",git fetch https://review.opendev.org/openstack/openstack-manuals refs/changes/58/193958/7 && git format-patch -1 --stdout FETCH_HEAD,"['doc/admin-guide-cloud-rst/source/keystone_certificates_for_pki.rst', 'doc/admin-guide-cloud-rst/source/identity_management.rst', 'doc/admin-guide-cloud-rst/source/keystone_external_authentication.rst', 'doc/admin-guide-cloud-rst/source/keystone_configure_with_SSL.rst']",4,fdc6eeffda2634b7e7f4ea2a282645b7b948f962,bp/reorganise-user-guide,":orphan: ======================================= Configure the Identity service with SSL ======================================= You can configure the Identity service to support two-way SSL. You must obtain the x509 certificates externally and configure them. The Identity service provides a set of sample certificates in the ``examples/pki/certs`` and ``examples/pki/private`` directories: cacert.pem Certificate Authority chain to validate against. ssl\_cert.pem Public certificate for Identity service server. middleware.pem Public and private certificate for Identity service middleware/client. cakey.pem Private key for the CA. ssl\_key.pem Private key for the Identity service server. .. note:: You can choose names for these certificates. You can also combine public/private keys in the same file, if you wish. These certificates are provided as an example. Client authentication with keystone-all ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ When running ``keystone-all``, the server can be configured to enable SSL with client authentication using the following instructions. Modify the ``[eventlet_server_ssl]`` section in the :file:`etc/keystone.conf` file. The following SSL configuration example uses the included sample certificates: .. code-block:: ini :linenos: [eventlet_server_ssl] enable = True certfile = <path to keystone.pem> keyfile = <path to keystonekey.pem> ca_certs = <path to ca.pem> cert_required = True **Options** - ``enable`` True enables SSL. Default is False. - ``certfile`` Path to the Identity service public certificate file. - ``keyfile`` Path to the Identity service private certificate file. If you include the private key in the certfile, you can omit the keyfile. - ``ca_certs`` Path to the CA trust chain. - ``cert_required`` Requires client certificate. Default is False. When running the Identity service as a WSGI service in a web server such as Apache httpd, this configuration is done in the web server instead. In this case the options in the ``[eventlet_server_ssl]`` section are ignored. ",,361,0
openstack%2Ftripleo-heat-templates~master~I56ebd2d8405ac35c707666d993b396f04aeb683e,openstack/tripleo-heat-templates,master,I56ebd2d8405ac35c707666d993b396f04aeb683e,Do not set explicitly galera_master to any of the nodes,MERGED,2015-06-23 12:46:11.000000000,2015-06-25 08:21:34.000000000,2015-06-25 08:21:32.000000000,"[{'_account_id': 3}, {'_account_id': 4328}, {'_account_id': 6796}, {'_account_id': 7582}, {'_account_id': 8399}, {'_account_id': 8449}]","[{'number': 1, 'created': '2015-06-23 12:46:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/7cdc188bb5a09897ddced5db74910bfdf87e7eb3', 'message': 'Do not set explicitly galera_master to any of the nodes\n\nChange-Id: I56ebd2d8405ac35c707666d993b396f04aeb683e\n'}, {'number': 2, 'created': '2015-06-24 06:58:11.000000000', 'files': ['puppet/hieradata/controller.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/b3e17d52acde82718a2354a08d42e6f0aaa35ad0', 'message': 'Do not set explicitly galera_master to any of the nodes\n\nWe will manage nodes membership using the clustercheck script and\nmarking all backends as backup, see change:\nI7199c7e5d759a76f58c0f48b40e9d460a3163886\n\nRelated-Bug: 1467918\nChange-Id: I56ebd2d8405ac35c707666d993b396f04aeb683e\n'}]",1,194639,b3e17d52acde82718a2354a08d42e6f0aaa35ad0,22,6,2,6796,,,0,"Do not set explicitly galera_master to any of the nodes

We will manage nodes membership using the clustercheck script and
marking all backends as backup, see change:
I7199c7e5d759a76f58c0f48b40e9d460a3163886

Related-Bug: 1467918
Change-Id: I56ebd2d8405ac35c707666d993b396f04aeb683e
",git fetch https://review.opendev.org/openstack/tripleo-heat-templates refs/changes/39/194639/1 && git format-patch -1 --stdout FETCH_HEAD,['puppet/hieradata/controller.yaml'],1,7cdc188bb5a09897ddced5db74910bfdf87e7eb3,bug/1467918,# mysql,"tripleo::loadbalancer::galera_master_ip: ""%{hiera('bootstrap_nodeid_ip')}"" tripleo::loadbalancer::galera_master_hostname: ""%{hiera('bootstrap_nodeid')}"" ",1,4
openstack%2Fcinder~master~Ie8aeae63aca45d8082372ed0f1e5ce7be8dcbd5f,openstack/cinder,master,Ie8aeae63aca45d8082372ed0f1e5ce7be8dcbd5f,test,ABANDONED,2015-06-25 07:26:05.000000000,2015-06-25 08:21:21.000000000,,[{'_account_id': 12249}],"[{'number': 1, 'created': '2015-06-25 07:26:05.000000000', 'files': ['run_tests.sh'], 'web_link': 'https://opendev.org/openstack/cinder/commit/323194350c331ab760cacc22bbc9f1b0aba6eb14', 'message': 'test\n\nChange-Id: Ie8aeae63aca45d8082372ed0f1e5ce7be8dcbd5f\n'}]",0,195434,323194350c331ab760cacc22bbc9f1b0aba6eb14,3,1,1,11079,,,0,"test

Change-Id: Ie8aeae63aca45d8082372ed0f1e5ce7be8dcbd5f
",git fetch https://review.opendev.org/openstack/cinder refs/changes/34/195434/1 && git format-patch -1 --stdout FETCH_HEAD,['run_tests.sh'],1,323194350c331ab760cacc22bbc9f1b0aba6eb14,test,fdfdf#!/bin/bash,#!/bin/bash,1,1
openstack%2Fdjango_openstack_auth~master~I93ad3f410ac9a1ead8d3f6014f3a978596d8a59f,openstack/django_openstack_auth,master,I93ad3f410ac9a1ead8d3f6014f3a978596d8a59f,Imported Translations from Transifex,MERGED,2015-06-25 06:06:34.000000000,2015-06-25 08:13:47.000000000,2015-06-25 08:13:45.000000000,"[{'_account_id': 3}, {'_account_id': 1941}, {'_account_id': 6914}]","[{'number': 1, 'created': '2015-06-25 06:06:34.000000000', 'files': ['openstack_auth/locale/zh_CN/LC_MESSAGES/django.po'], 'web_link': 'https://opendev.org/openstack/django_openstack_auth/commit/a5bd6e6a284ba3cd2366319257bd3808beb7ccf3', 'message': 'Imported Translations from Transifex\n\nFor more information about this automatic import see:\nhttps://wiki.openstack.org/wiki/Translations/Infrastructure\n\nChange-Id: I93ad3f410ac9a1ead8d3f6014f3a978596d8a59f\n'}]",0,195426,a5bd6e6a284ba3cd2366319257bd3808beb7ccf3,7,3,1,11131,,,0,"Imported Translations from Transifex

For more information about this automatic import see:
https://wiki.openstack.org/wiki/Translations/Infrastructure

Change-Id: I93ad3f410ac9a1ead8d3f6014f3a978596d8a59f
",git fetch https://review.opendev.org/openstack/django_openstack_auth refs/changes/26/195426/1 && git format-patch -1 --stdout FETCH_HEAD,['openstack_auth/locale/zh_CN/LC_MESSAGES/django.po'],1,a5bd6e6a284ba3cd2366319257bd3808beb7ccf3,transifex/translations,"#  <liujunpeng@inspur.com>, 2015""POT-Creation-Date: 2015-06-25 06:06+0000\n"" ""PO-Revision-Date: 2015-06-24 07:30+0000\n"" ""Last-Translator:  <liujunpeng@inspur.com>\n""msgid ""Unable to establish connection to keystone endpoint."" msgstr ""keystone"" ","""POT-Creation-Date: 2015-05-29 06:02+0000\n"" ""PO-Revision-Date: 2015-05-28 07:03+0000\n"" ""Last-Translator: openstackjenkins <jenkins@openstack.org>\n""",7,3
openstack%2Fcinder~master~Ifb75bb47e1dbc07a50e188f01b403df24f4e4c05,openstack/cinder,master,Ifb75bb47e1dbc07a50e188f01b403df24f4e4c05,Override opportunistic database tests to PyMySQL,ABANDONED,2015-06-18 19:01:44.000000000,2015-06-25 08:01:32.000000000,,"[{'_account_id': 3}, {'_account_id': 1736}, {'_account_id': 5263}, {'_account_id': 9751}, {'_account_id': 10621}, {'_account_id': 10622}, {'_account_id': 11811}, {'_account_id': 12017}, {'_account_id': 12202}, {'_account_id': 12249}, {'_account_id': 12369}, {'_account_id': 12778}, {'_account_id': 13144}, {'_account_id': 13394}, {'_account_id': 14587}, {'_account_id': 14797}, {'_account_id': 15249}, {'_account_id': 15374}, {'_account_id': 15386}, {'_account_id': 15670}, {'_account_id': 15941}, {'_account_id': 16160}, {'_account_id': 16269}, {'_account_id': 16422}, {'_account_id': 16595}, {'_account_id': 16880}, {'_account_id': 16897}]","[{'number': 1, 'created': '2015-06-18 19:01:44.000000000', 'files': ['tox.ini'], 'web_link': 'https://opendev.org/openstack/cinder/commit/5b123a09dc3a9388b7544524e8d8bc5584ce4148', 'message': 'Override opportunistic database tests to PyMySQL\n\nSet the OS_TEST_DBAPI_ADMIN_CONNECTION override variable so that\noslo.db opportunistic detection will know to use PyMySQL until\nI12b32dc097a121bd43991bc38dd4d289b65e86c1 makes it the default\nbehavior.\n\nChange-Id: Ifb75bb47e1dbc07a50e188f01b403df24f4e4c05\nCo-Authored-By: Victor Sergeyev <vsergeyev@mirantis.com>\n'}]",0,193254,5b123a09dc3a9388b7544524e8d8bc5584ce4148,30,27,1,5263,,,0,"Override opportunistic database tests to PyMySQL

Set the OS_TEST_DBAPI_ADMIN_CONNECTION override variable so that
oslo.db opportunistic detection will know to use PyMySQL until
I12b32dc097a121bd43991bc38dd4d289b65e86c1 makes it the default
behavior.

Change-Id: Ifb75bb47e1dbc07a50e188f01b403df24f4e4c05
Co-Authored-By: Victor Sergeyev <vsergeyev@mirantis.com>
",git fetch https://review.opendev.org/openstack/cinder refs/changes/54/193254/1 && git format-patch -1 --stdout FETCH_HEAD,['tox.ini'],1,5b123a09dc3a9388b7544524e8d8bc5584ce4148,pymysql-switch, OS_TEST_DBAPI_ADMIN_CONNECTION=mysql+pymysql://openstack_citest:openstack_citest@localhost/;postgresql://openstack_citest:openstack_citest@localhost/postgres;sqlite://,,1,0
openstack%2Ftripleo-ci~master~I9cb2de5919a054b4895442b308d8958e741d51c1,openstack/tripleo-ci,master,I9cb2de5919a054b4895442b308d8958e741d51c1,Pin puppet-redis to known working version,ABANDONED,2015-06-24 10:35:07.000000000,2015-06-25 07:57:33.000000000,,"[{'_account_id': 3}, {'_account_id': 360}, {'_account_id': 1926}, {'_account_id': 9410}, {'_account_id': 13564}]","[{'number': 1, 'created': '2015-06-24 10:35:07.000000000', 'files': ['toci_devtest.sh'], 'web_link': 'https://opendev.org/openstack/tripleo-ci/commit/f29b6647145eec755ed54063b8e1d31e60275ba5', 'message': 'Pin puppet-redis to known working version\n\nThis is to avoid https://github.com/arioch/puppet-redis/issues/41\n\nChange-Id: I9cb2de5919a054b4895442b308d8958e741d51c1\n'}]",0,195028,f29b6647145eec755ed54063b8e1d31e60275ba5,6,5,1,6796,,,0,"Pin puppet-redis to known working version

This is to avoid https://github.com/arioch/puppet-redis/issues/41

Change-Id: I9cb2de5919a054b4895442b308d8958e741d51c1
",git fetch https://review.opendev.org/openstack/tripleo-ci refs/changes/28/195028/1 && git format-patch -1 --stdout FETCH_HEAD,['toci_devtest.sh'],1,f29b6647145eec755ed54063b8e1d31e60275ba5,puppet_redis_pinning,# Pin to an earlier puppet-redis # https://github.com/arioch/puppet-redis/issues/41 export DIB_REPOREF_puppet_redis=439fb695ed582b99430352cd7b15fefa6bb56989 ,,4,0
openstack%2Fdragonflow~master~I5d141b79f421494788be0fe1806037b7cfb565ea,openstack/dragonflow,master,I5d141b79f421494788be0fe1806037b7cfb565ea,Remove unused methods and members,MERGED,2015-06-22 14:50:23.000000000,2015-06-25 07:55:23.000000000,2015-06-25 07:55:22.000000000,"[{'_account_id': 3}, {'_account_id': 2023}, {'_account_id': 11343}, {'_account_id': 13070}, {'_account_id': 14249}]","[{'number': 1, 'created': '2015-06-22 14:50:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/dragonflow/commit/49734b214621b1a49e7c691ed8f26ee52b7a477b', 'message': 'Remove unnecessary methods and members\n\nChange-Id: I5d141b79f421494788be0fe1806037b7cfb565ea\n'}, {'number': 2, 'created': '2015-06-22 14:51:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/dragonflow/commit/b174a8c002e0438e76db81793361b29977a5055d', 'message': 'Remove unused methods and members\n\nChange-Id: I5d141b79f421494788be0fe1806037b7cfb565ea\n'}, {'number': 3, 'created': '2015-06-23 08:12:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/dragonflow/commit/e029d1fe63e940a8f00bdd69c42237d8778d6a44', 'message': 'Remove unused methods and members\n\nChange-Id: I5d141b79f421494788be0fe1806037b7cfb565ea\n'}, {'number': 4, 'created': '2015-06-25 07:22:34.000000000', 'files': ['dragonflow/controller/l3_openflow_app.py'], 'web_link': 'https://opendev.org/openstack/dragonflow/commit/1d95cdce63b628b7479d3e1d98844ec8b2845ef6', 'message': 'Remove unused methods and members\n\nChange-Id: I5d141b79f421494788be0fe1806037b7cfb565ea\n'}]",2,194173,1d95cdce63b628b7479d3e1d98844ec8b2845ef6,17,5,4,13070,,,0,"Remove unused methods and members

Change-Id: I5d141b79f421494788be0fe1806037b7cfb565ea
",git fetch https://review.opendev.org/openstack/dragonflow refs/changes/73/194173/2 && git format-patch -1 --stdout FETCH_HEAD,['dragonflow/controller/l3_openflow_app.py'],1,49734b214621b1a49e7c691ed8f26ee52b7a477b,remove_unused_func,," self.nodes = set() self.distances = {} def add_node(self, value): self.nodes.add(value) def del_node(self, value): self.nodes.remove(value) def add_edge(self, from_node, to_node, distance): self.edges[from_node].append(to_node) self.edges[to_node].append(from_node) self.distances[(from_node, to_node)] = distance def get_port_subnets(self, port): subnets_ids = [] if 'fixed_ips' in port: for fixed_ips in port['fixed_ips']: subnets_ids.append(fixed_ips['subnet_id']) return subnets_ids ",0,20
openstack%2Fsenlin~master~I8211687341658a133b57b9fd9c921e42b2931842,openstack/senlin,master,I8211687341658a133b57b9fd9c921e42b2931842,Redefine policy enforcement levels,MERGED,2015-06-22 14:07:29.000000000,2015-06-25 07:49:00.000000000,2015-06-25 07:48:58.000000000,"[{'_account_id': 3}, {'_account_id': 6348}, {'_account_id': 8246}, {'_account_id': 11034}]","[{'number': 1, 'created': '2015-06-22 14:07:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/senlin/commit/a369af46dc79725f7f3aff02dc142d69aa6c9e54', 'message': 'Redefine policy enforcement levels\n\nThe current set of enforcement levels is difficult to explain. We are\nswitching to a much simpler definition for levels.\n\nChange-Id: I8211687341658a133b57b9fd9c921e42b2931842\n'}, {'number': 2, 'created': '2015-06-23 03:32:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/senlin/commit/05577cf0763075d369560b01fb9c7494933b20d4', 'message': 'Redefine policy enforcement levels\n\nThe current set of enforcement levels is difficult to explain. We are\nswitching to a much simpler definition for levels.\n\nChange-Id: I8211687341658a133b57b9fd9c921e42b2931842\n'}, {'number': 3, 'created': '2015-06-23 03:49:55.000000000', 'files': ['TODO.rst', 'senlin/policies/__init__.py', 'senlin/policies/base.py'], 'web_link': 'https://opendev.org/openstack/senlin/commit/94f5539a15e039d55e3bdfb25569a0385ecc00cf', 'message': 'Redefine policy enforcement levels\n\nThe current set of enforcement levels is difficult to explain. We are\nswitching to a much simpler definition for levels.\n\nChange-Id: I8211687341658a133b57b9fd9c921e42b2931842\n'}]",5,194156,94f5539a15e039d55e3bdfb25569a0385ecc00cf,16,4,3,8246,,,0,"Redefine policy enforcement levels

The current set of enforcement levels is difficult to explain. We are
switching to a much simpler definition for levels.

Change-Id: I8211687341658a133b57b9fd9c921e42b2931842
",git fetch https://review.opendev.org/openstack/senlin refs/changes/56/194156/2 && git format-patch -1 --stdout FETCH_HEAD,"['TODO.rst', 'senlin/policies/__init__.py', 'senlin/policies/base.py']",3,a369af46dc79725f7f3aff02dc142d69aa6c9e54,enforcement-level," # TODO(Qiming): make this MIGHT self.level = kwargs.get('level', 0)"," ENFORCEMENT_LEVELS = ( CRITICAL, ERROR, WARNING, INFO, DEBUG, ) = ( 'CRITICAL', 'ERROR', 'WARNING', 'INFO', 'DEBUG', ) self.level = kwargs.get('level', self.DEBUG)",32,41
openstack%2Fsenlin~master~Ib846a196c07390ee5dfc3c6f29a1306cf8627170,openstack/senlin,master,Ib846a196c07390ee5dfc3c6f29a1306cf8627170,Add item about wiki page improvement,MERGED,2015-06-24 03:24:17.000000000,2015-06-25 07:48:39.000000000,2015-06-25 07:48:37.000000000,"[{'_account_id': 3}, {'_account_id': 11034}]","[{'number': 1, 'created': '2015-06-24 03:24:17.000000000', 'files': ['TODO.rst'], 'web_link': 'https://opendev.org/openstack/senlin/commit/ec37865b275231473a7ca81ed11e7e19d5661d0a', 'message': 'Add item about wiki page improvement\n\nThe wiki page will be the window for Senlin to tell its story. Need to\nstart working on it.\n\nChange-Id: Ib846a196c07390ee5dfc3c6f29a1306cf8627170\n'}]",0,194923,ec37865b275231473a7ca81ed11e7e19d5661d0a,6,2,1,8246,,,0,"Add item about wiki page improvement

The wiki page will be the window for Senlin to tell its story. Need to
start working on it.

Change-Id: Ib846a196c07390ee5dfc3c6f29a1306cf8627170
",git fetch https://review.opendev.org/openstack/senlin refs/changes/23/194923/1 && git format-patch -1 --stdout FETCH_HEAD,['TODO.rst'],1,ec37865b275231473a7ca81ed11e7e19d5661d0a,TODO,"WIKI ---- - add contents to https://wiki.openstack.org/wiki/Senlin, this is the first page for all newcomers. [Qiming] ",,5,0
openstack%2Fnetworking-midonet~master~Ia58870e3f56b7d6d5c576da129b729bd46254b98,openstack/networking-midonet,master,Ia58870e3f56b7d6d5c576da129b729bd46254b98,Call create_fake_uplink_l2.sh from devstack,MERGED,2015-06-24 18:04:45.000000000,2015-06-25 07:44:59.000000000,2015-06-25 07:44:59.000000000,"[{'_account_id': 3}, {'_account_id': 156}, {'_account_id': 6854}, {'_account_id': 8837}]","[{'number': 1, 'created': '2015-06-24 18:04:45.000000000', 'files': ['devstack/plugin.sh'], 'web_link': 'https://opendev.org/openstack/networking-midonet/commit/c0ef5d7a19a8772c3c02e4cb6b58c08a584abc2f', 'message': 'Call create_fake_uplink_l2.sh from devstack\n\nWith create_fake_uplink_l2.sh available in midonet, call it when ZOOM\nis specified.  This sets up the uplink network on the host.  This patch\nalso simplifies the plugin.sh script by callng the uplink scripts by\npassing arguments instead of setting environment variables.\n\nChange-Id: Ia58870e3f56b7d6d5c576da129b729bd46254b98\nImplements: MNP-161\n'}]",0,195241,c0ef5d7a19a8772c3c02e4cb6b58c08a584abc2f,8,4,1,156,,,0,"Call create_fake_uplink_l2.sh from devstack

With create_fake_uplink_l2.sh available in midonet, call it when ZOOM
is specified.  This sets up the uplink network on the host.  This patch
also simplifies the plugin.sh script by callng the uplink scripts by
passing arguments instead of setting environment variables.

Change-Id: Ia58870e3f56b7d6d5c576da129b729bd46254b98
Implements: MNP-161
",git fetch https://review.opendev.org/openstack/networking-midonet refs/changes/41/195241/1 && git format-patch -1 --stdout FETCH_HEAD,['devstack/plugin.sh'],1,c0ef5d7a19a8772c3c02e4cb6b58c08a584abc2f,MNP-161," if [[ ""$MIDONET_USE_ZOOM"" == ""True"" ]]; then $MIDONET_DIR/tools/devmido/create_fake_uplink_l2.sh \ $EXT_NET_ID $FLOATING_RANGE $PUBLIC_NETWORK_GATEWAY else $MIDONET_DIR/tools/devmido/create_fake_uplink.sh \ $FLOATING_RANGE fi if [[ ""$MIDONET_USE_ZOOM"" == ""True"" ]]; then $MIDONET_DIR/tools/devmido/delete_fake_uplink_l2.sh else $MIDONET_DIR/tools/devmido/delete_fake_uplink.sh fi", export CIDR=${FLOATING_RANGE:?Error \$FLOATING_RANGE is not set} $MIDONET_DIR/tools/devmido/create_fake_uplink.sh CIDR=${FLOATING_RANGE:?Error \$FLOATING_RANGE is not set} $MIDONET_DIR/tools/devmido/delete_fake_uplink.sh,12,5
openstack%2Fproject-config~master~I5bb261787f59650b71dbdf75bdd787bd2efb4f9f,openstack/project-config,master,I5bb261787f59650b71dbdf75bdd787bd2efb4f9f,Add temporary non voting multinode smoke jobs,MERGED,2015-06-24 18:37:05.000000000,2015-06-25 07:28:13.000000000,2015-06-25 07:28:11.000000000,"[{'_account_id': 3}, {'_account_id': 2750}, {'_account_id': 5263}, {'_account_id': 6547}]","[{'number': 1, 'created': '2015-06-24 18:37:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/project-config/commit/b86be37f9182d1ba26edc6907a03907989856ea5', 'message': ""Add temporary non voting multinode smoke jobs\n\nAs a first step in making grenade multinode, we need to figure out how\nreliable tempest smoke jobs are in multinode.  As it is tempest-full\nfails *roughly* 10% of the time with nova-network, and neutron (with\nDVR) fails every time. But we are turning off DVR for this job, as we\ndon't expect grenade to do DVR just yet, so I don't have any numbers on how\nreliable tempest-full is with non-dvr neutron.\n\nRunning these jobs as non-voting everywhere the full jobs were run and\nthen some in order to get a decent dataset in logstash.openstack.org and\ngraphite.\n\nWe cannot proceed with multinode grenade until these jobs are stable.\nOnce grenade is multinode, these jobs can be removed.\n\nChange-Id: I5bb261787f59650b71dbdf75bdd787bd2efb4f9f\n""}, {'number': 2, 'created': '2015-06-24 18:46:06.000000000', 'files': ['jenkins/jobs/projects.yaml', 'zuul/layout.yaml', 'jenkins/jobs/devstack-gate.yaml'], 'web_link': 'https://opendev.org/openstack/project-config/commit/fc12a7d5e2eef0c52cf8de9b1b02b522baf310ef', 'message': ""Add temporary non voting multinode smoke jobs\n\nAs a first step in making grenade multinode, we need to figure out how\nreliable tempest smoke jobs are in multinode.  As it is tempest-full\nfails *roughly* 10% of the time with nova-network, and neutron (with\nDVR) fails every time. But we are turning off DVR for this job, as we\ndon't expect grenade to do DVR just yet, so I don't have any numbers on how\nreliable tempest-full is with non-dvr neutron.\n\nRunning these jobs as non-voting everywhere the full jobs were run and\nthen some in order to get a decent dataset in logstash.openstack.org and\ngraphite.\n\nWe cannot proceed with multinode grenade until these jobs are stable.\nOnce grenade is multinode, these jobs can be removed.\n\nChange-Id: I5bb261787f59650b71dbdf75bdd787bd2efb4f9f\n""}]",0,195259,fc12a7d5e2eef0c52cf8de9b1b02b522baf310ef,8,4,2,1849,,,0,"Add temporary non voting multinode smoke jobs

As a first step in making grenade multinode, we need to figure out how
reliable tempest smoke jobs are in multinode.  As it is tempest-full
fails *roughly* 10% of the time with nova-network, and neutron (with
DVR) fails every time. But we are turning off DVR for this job, as we
don't expect grenade to do DVR just yet, so I don't have any numbers on how
reliable tempest-full is with non-dvr neutron.

Running these jobs as non-voting everywhere the full jobs were run and
then some in order to get a decent dataset in logstash.openstack.org and
graphite.

We cannot proceed with multinode grenade until these jobs are stable.
Once grenade is multinode, these jobs can be removed.

Change-Id: I5bb261787f59650b71dbdf75bdd787bd2efb4f9f
",git fetch https://review.opendev.org/openstack/project-config refs/changes/59/195259/1 && git format-patch -1 --stdout FETCH_HEAD,"['jenkins/jobs/projects.yaml', 'zuul/layout.yaml', 'jenkins/jobs/devstack-gate.yaml']",3,b86be37f9182d1ba26edc6907a03907989856ea5,smoke," name: '{pipeline}-tempest-dsvm-multinode-smoke{branch-designator}' node: '{node}' wrappers: - build-timeout: timeout: 125 - timestamps builders: - link-logs - net-info - devstack-checkout - shell: | #!/bin/bash -xe export PYTHONUNBUFFERED=true export DEVSTACK_GATE_TIMEOUT=120 export DEVSTACK_GATE_TEMPEST=1 export DEVSTACK_GATE_CONFIGDRIVE=0 export BRANCH_OVERRIDE={branch-override} if [ ""$BRANCH_OVERRIDE"" != ""default"" ] ; then export OVERRIDE_ZUUL_BRANCH=$BRANCH_OVERRIDE fi export DEVSTACK_GATE_TOPOLOGY=""multinode"" cp devstack-gate/devstack-vm-gate-wrap.sh ./safe-devstack-vm-gate-wrap.sh ./safe-devstack-vm-gate-wrap.sh publishers: - devstack-logs - console-log - job-template: name: '{pipeline}-tempest-dsvm-neutron-multinode-smoke{branch-designator}' node: '{node}' wrappers: - build-timeout: timeout: 125 - timestamps builders: - link-logs - net-info - devstack-checkout - shell: | #!/bin/bash -xe export PYTHONUNBUFFERED=true export DEVSTACK_GATE_TIMEOUT=120 export DEVSTACK_GATE_TEMPEST=1 export DEVSTACK_GATE_NEUTRON=1 export DEVSTACK_GATE_CONFIGDRIVE=0 export BRANCH_OVERRIDE={branch-override} if [ ""$BRANCH_OVERRIDE"" != ""default"" ] ; then export OVERRIDE_ZUUL_BRANCH=$BRANCH_OVERRIDE fi export DEVSTACK_GATE_TOPOLOGY=""multinode"" cp devstack-gate/devstack-vm-gate-wrap.sh ./safe-devstack-vm-gate-wrap.sh ./safe-devstack-vm-gate-wrap.sh publishers: - devstack-logs - console-log - job-template:",,94,0
openstack%2Fhorizon~master~I2975ca696949969eabd7213f99229ff4d139bec4,openstack/horizon,master,I2975ca696949969eabd7213f99229ff4d139bec4,Use default values in horizon.conf,MERGED,2015-03-17 15:14:50.000000000,2015-06-25 07:27:49.000000000,2015-06-25 07:27:47.000000000,"[{'_account_id': 3}, {'_account_id': 1941}, {'_account_id': 6610}, {'_account_id': 6890}, {'_account_id': 8577}, {'_account_id': 12355}, {'_account_id': 12954}]","[{'number': 1, 'created': '2015-03-17 15:14:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/21f52544cba8f39074fdada39089be683e694b80', 'message': 'Use default values in horizon.conf\n\nDefault values in horizon.conf and config.py differs.\n\nCloses-Bug: 1433123\nPartially implements blueprint: selenium-integration-testing\nChange-Id: I2975ca696949969eabd7213f99229ff4d139bec4\n'}, {'number': 2, 'created': '2015-03-18 09:36:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/3a2ed2c6e05fa1d1e42772799fb59c2359ce5b35', 'message': 'Use default values in horizon.conf\n\nDefault values in horizon.conf and config.py differs.\n\nCloses-Bug: 1433123\nPartially implements blueprint: selenium-integration-testing\nChange-Id: I2975ca696949969eabd7213f99229ff4d139bec4\n'}, {'number': 3, 'created': '2015-06-17 21:14:12.000000000', 'files': ['openstack_dashboard/test/integration_tests/config.py'], 'web_link': 'https://opendev.org/openstack/horizon/commit/81eb5113dfbed1970f120d482e7d7d071e3321fd', 'message': 'Use default values in horizon.conf\n\nDefault values in horizon.conf and config.py differs.\n\nCloses-Bug: 1433123\nPartially implements blueprint: selenium-integration-testing\nChange-Id: I2975ca696949969eabd7213f99229ff4d139bec4\n'}]",5,165102,81eb5113dfbed1970f120d482e7d7d071e3321fd,20,7,3,6890,,,0,"Use default values in horizon.conf

Default values in horizon.conf and config.py differs.

Closes-Bug: 1433123
Partially implements blueprint: selenium-integration-testing
Change-Id: I2975ca696949969eabd7213f99229ff4d139bec4
",git fetch https://review.opendev.org/openstack/horizon refs/changes/02/165102/2 && git format-patch -1 --stdout FETCH_HEAD,"['openstack_dashboard/test/integration_tests/config.py', 'openstack_dashboard/test/integration_tests/horizon.conf']",2,21f52544cba8f39074fdada39089be683e694b80,bp/selenium-integration-testing,sahara=False,sahara=True,6,5
openstack%2Fpython-mistralclient~master~Ie10339e5da486a4e2a3e5d31557016be8b3f4fc6,openstack/python-mistralclient,master,Ie10339e5da486a4e2a3e5d31557016be8b3f4fc6,Add description param for execution create/update,MERGED,2015-06-21 13:03:49.000000000,2015-06-25 07:25:35.000000000,2015-06-25 07:25:34.000000000,"[{'_account_id': 3}, {'_account_id': 5558}, {'_account_id': 6732}, {'_account_id': 7700}, {'_account_id': 8731}, {'_account_id': 9432}]","[{'number': 1, 'created': '2015-06-21 13:03:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-mistralclient/commit/b160fc0509e1838b85c73cef4b00619e88913bad', 'message': ""Add description param for execution create/update\n\nWith this patch, users could do the following:\n\nmistral exeuction-create wf -d my_first_execution mistral\nexecution-update d8922ca3-7908-4267-af03-bfad3d95fae2 -d\nmy_second_execution\n\nHowever, state and description can't be updated at the same time, since\nthere is no such scenario and avoid the implementation complexity.\n\nAdd some tests accordingly.\n\nChange-Id: Ie10339e5da486a4e2a3e5d31557016be8b3f4fc6\nImplements: blueprint workflow-execution-description-support\n""}, {'number': 2, 'created': '2015-06-21 15:05:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-mistralclient/commit/f92c38bd166584a0a4e32deb958d045cfc7f9c08', 'message': ""Add description param for execution create/update\n\nWith this patch, users could do the following:\n\nmistral exeuction-create wf -d my_first_executio\nmistral execution-update d8922ca3-7908-4267-af03-bfad3d95fae2 -d\nmy_second_execution\n\nHowever, state and description can't be updated at the same time, since\nthere is no such scenario and avoid the implementation complexity.\n\nAdd some tests accordingly.\n\nChange-Id: Ie10339e5da486a4e2a3e5d31557016be8b3f4fc6\nImplements: blueprint workflow-execution-description-support\n""}, {'number': 3, 'created': '2015-06-23 09:15:30.000000000', 'files': ['mistralclient/commands/v2/executions.py', 'mistralclient/tests/unit/v2/test_executions.py', 'mistralclient/api/v2/executions.py', 'mistralclient/tests/unit/v2/test_cli_executions.py', 'mistralclient/tests/functional/cli/v2/cli_tests_v2.py'], 'web_link': 'https://opendev.org/openstack/python-mistralclient/commit/66b3faabc04f55708b82f23a9d3eb6ddf34beb07', 'message': ""Add description param for execution create/update\n\nWith this patch, users could do the following:\n\nmistral exeuction-create wf -d my_first_executio\nmistral execution-update d8922ca3-7908-4267-af03-bfad3d95fae2 -d\nmy_second_execution\n\nHowever, state and description can't be updated at the same time, since\nthere is no such scenario and avoid the implementation complexity.\n\nAdd some tests accordingly.\n\nChange-Id: Ie10339e5da486a4e2a3e5d31557016be8b3f4fc6\nImplements: blueprint workflow-execution-description-support\n""}]",1,193880,66b3faabc04f55708b82f23a9d3eb6ddf34beb07,13,6,3,6732,,,0,"Add description param for execution create/update

With this patch, users could do the following:

mistral exeuction-create wf -d my_first_executio
mistral execution-update d8922ca3-7908-4267-af03-bfad3d95fae2 -d
my_second_execution

However, state and description can't be updated at the same time, since
there is no such scenario and avoid the implementation complexity.

Add some tests accordingly.

Change-Id: Ie10339e5da486a4e2a3e5d31557016be8b3f4fc6
Implements: blueprint workflow-execution-description-support
",git fetch https://review.opendev.org/openstack/python-mistralclient refs/changes/80/193880/2 && git format-patch -1 --stdout FETCH_HEAD,"['mistralclient/commands/v2/executions.py', 'mistralclient/api/v2/executions.py', 'mistralclient/tests/unit/v2/test_cli_executions.py', 'mistralclient/tests/functional/cli/v2/cli_tests_v2.py']",4,b160fc0509e1838b85c73cef4b00619e88913bad,bp/workflow-execution-description-support," 'execution-create', params='{0} -d ""execution test""'.format(self.direct_wf['Name']) ) description = self.get_value_of_field(execution, 'Description') self.assertEqual(description, ""execution test"") # update execution state 'execution-update', params='{0} -s PAUSED'.format(exec_id)) # update execution description execution = self.mistral_admin( 'execution-update', params='{0} -d ""execution update test""'.format(exec_id) ) description = self.get_value_of_field(execution, 'Description') self.assertEqual(description, ""execution update test"") params='%s -s ERROR' % exec_id) def test_ex_update_both_state_and_description(self): wf = self.workflow_create(self.wf_def) execution = self.execution_create(params=wf[0]['Name']) exec_id = self.get_value_of_field(execution, 'ID') self.assertRaises(exceptions.CommandFailed, self.mistral_admin, 'execution-update', params='%s -s ERROR -d update' % exec_id)"," 'execution-create', params=self.direct_wf['Name']) 'execution-update', params='{0} ""PAUSED""'.format(exec_id)) params='%s ERROR' % exec_id)",79,19
openstack%2Ffuel-qa~master~I79448e96d3ffef611a3f9004021218b8e3e13a83,openstack/fuel-qa,master,I79448e96d3ffef611a3f9004021218b8e3e13a83,Update version of glance client in requirements,MERGED,2015-06-24 11:48:40.000000000,2015-06-25 07:24:24.000000000,2015-06-25 07:24:23.000000000,"[{'_account_id': 3}, {'_account_id': 6719}, {'_account_id': 8882}, {'_account_id': 8971}, {'_account_id': 10136}, {'_account_id': 12867}, {'_account_id': 16106}]","[{'number': 1, 'created': '2015-06-24 11:48:40.000000000', 'files': ['fuelweb_test/requirements.txt'], 'web_link': 'https://opendev.org/openstack/fuel-qa/commit/94fbe87d49343e649b1243dcf5f2cbbe316dddfb', 'message': 'Update version of glance client in requirements\n\nUpdate version  in glance client in requirements.txt\n\nChange-Id: I79448e96d3ffef611a3f9004021218b8e3e13a83\nCloses-Bug: #1461173\n'}]",0,195047,94fbe87d49343e649b1243dcf5f2cbbe316dddfb,11,7,1,6719,,,0,"Update version of glance client in requirements

Update version  in glance client in requirements.txt

Change-Id: I79448e96d3ffef611a3f9004021218b8e3e13a83
Closes-Bug: #1461173
",git fetch https://review.opendev.org/openstack/fuel-qa refs/changes/47/195047/1 && git format-patch -1 --stdout FETCH_HEAD,['fuelweb_test/requirements.txt'],1,94fbe87d49343e649b1243dcf5f2cbbe316dddfb,fix_glance_verson,"python-glanceclient >=0.14.1,<=0.15.0",python-glanceclient>=0.9.0,1,1
openstack%2Fmurano-dashboard~master~I40f2a106f557ca69e3383c6e516db27358a82a0a,openstack/murano-dashboard,master,I40f2a106f557ca69e3383c6e516db27358a82a0a,Add ability to abandon environment,MERGED,2015-06-03 16:30:25.000000000,2015-06-25 07:23:43.000000000,2015-06-25 07:23:41.000000000,"[{'_account_id': 3}, {'_account_id': 7535}, {'_account_id': 7549}, {'_account_id': 7821}, {'_account_id': 8127}, {'_account_id': 13149}, {'_account_id': 13752}, {'_account_id': 13962}, {'_account_id': 14265}, {'_account_id': 15168}]","[{'number': 1, 'created': '2015-06-03 16:30:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/murano-dashboard/commit/ab7c9ab88dbc14fc9e81c135e49e53a806872c0e', 'message': 'Add ability to abandon environment\n\nChange-Id: I40f2a106f557ca69e3383c6e516db27358a82a0a\n'}, {'number': 2, 'created': '2015-06-03 16:33:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/murano-dashboard/commit/cfa7b87d130781d55810b7a9da9c43511058f163', 'message': 'Add ability to abandon environment\n\nChange-Id: I40f2a106f557ca69e3383c6e516db27358a82a0a\nDepends-On: I8bdbdfc3788893fd108d9e3d8b5cbd17f8192b85'}, {'number': 3, 'created': '2015-06-17 13:31:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/murano-dashboard/commit/e9199e93dc7ef111856d12f3e906510efc7464e1', 'message': 'Add ability to abandon environment\n\nImplements: blueprint environment-abandon\nCloses-Bug: #1438810\nChange-Id: I40f2a106f557ca69e3383c6e516db27358a82a0a\nDepends-On: I8bdbdfc3788893fd108d9e3d8b5cbd17f8192b85\n'}, {'number': 4, 'created': '2015-06-18 09:41:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/murano-dashboard/commit/dd8482b7bd952790237b895484ce796d4009f3db', 'message': 'Add ability to abandon environment\n\nImplements: blueprint environment-abandon\nCloses-Bug: #1438810\nChange-Id: I40f2a106f557ca69e3383c6e516db27358a82a0a\nDepends-On: I8bdbdfc3788893fd108d9e3d8b5cbd17f8192b85\n'}, {'number': 5, 'created': '2015-06-18 15:43:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/murano-dashboard/commit/42c7b6cdf3f5deb9e701a2d544ef6cd285860b78', 'message': 'Add ability to abandon environment\n\nImplements: blueprint environment-abandon\nCloses-Bug: #1438810\nChange-Id: I40f2a106f557ca69e3383c6e516db27358a82a0a\nDepends-On: I8bdbdfc3788893fd108d9e3d8b5cbd17f8192b85\n'}, {'number': 6, 'created': '2015-06-23 09:41:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/murano-dashboard/commit/254bb355ea93c4b5803ab4bf94ca43515046add7', 'message': 'Add ability to abandon environment\n\nImplements: blueprint environment-abandon\nCloses-Bug: #1438810\nChange-Id: I40f2a106f557ca69e3383c6e516db27358a82a0a\nDepends-On: I8bdbdfc3788893fd108d9e3d8b5cbd17f8192b85\n'}, {'number': 7, 'created': '2015-06-24 09:59:39.000000000', 'files': ['muranodashboard/environments/tables.py', 'muranodashboard/environments/api.py'], 'web_link': 'https://opendev.org/openstack/murano-dashboard/commit/f02722f7ba3472cebb60d07d180563c52fd6eb0b', 'message': 'Add ability to abandon environment\n\nImplements: blueprint environment-abandon\nCloses-Bug: #1438810\nChange-Id: I40f2a106f557ca69e3383c6e516db27358a82a0a\nDepends-On: I8bdbdfc3788893fd108d9e3d8b5cbd17f8192b85\n'}]",16,188069,f02722f7ba3472cebb60d07d180563c52fd6eb0b,70,10,7,13149,,,0,"Add ability to abandon environment

Implements: blueprint environment-abandon
Closes-Bug: #1438810
Change-Id: I40f2a106f557ca69e3383c6e516db27358a82a0a
Depends-On: I8bdbdfc3788893fd108d9e3d8b5cbd17f8192b85
",git fetch https://review.opendev.org/openstack/murano-dashboard refs/changes/69/188069/6 && git format-patch -1 --stdout FETCH_HEAD,"['muranodashboard/environments/tables.py', 'muranodashboard/environments/api.py']",2,ab7c9ab88dbc14fc9e81c135e49e53a806872c0e,bug/1438810,"def environment_abandon(request, environment_id): LOG.debug('Environment::Abandon <Id: {0}>'.format(environment_id)) return api.muranoclient(request).environments.abandon(environment_id) ",,32,1
openstack%2Fpuppet-sahara~master~Id24f65f5a7d7c610353d9ecbf51236c97c7e4cb4,openstack/puppet-sahara,master,Id24f65f5a7d7c610353d9ecbf51236c97c7e4cb4,Fix Beaker CI according recent puppetlabs-rabbitmq change.,MERGED,2015-06-24 17:13:52.000000000,2015-06-25 07:18:23.000000000,2015-06-25 07:18:22.000000000,"[{'_account_id': 3}, {'_account_id': 3153}, {'_account_id': 8482}, {'_account_id': 9500}]","[{'number': 1, 'created': '2015-06-24 17:13:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-sahara/commit/30a8a1f5c647452c7daf7c67e2f88c885df1c5df', 'message': 'Fix Beaker CI according recent puppetlabs-rabbitmq change.\n\nThe puppetlabs-rabbitmq module introduce a new feature related to the\nerlang_cookie parameter change (the database must be wiped if the cookie is\nchanged), the parameter wipe_db_on_cookie_change is configured to false by\ndefault.\n\nChange-Id: Id24f65f5a7d7c610353d9ecbf51236c97c7e4cb4\nCloses-Bug: #1468444\n'}, {'number': 2, 'created': '2015-06-24 22:08:35.000000000', 'files': ['spec/acceptance/basic_sahara_spec.rb'], 'web_link': 'https://opendev.org/openstack/puppet-sahara/commit/e7196c4d2ff0131ffb00a19a6715f104d761e46e', 'message': ""Fix Beaker CI according recent puppetlabs-rabbitmq change.\n\nThe puppetlabs-rabbitmq module introduce a new feature related to the\nerlang_cookie parameter change (the database must be wiped if the cookie is\nchanged), the parameter wipe_db_on_cookie_change is configured to false by\ndefault.\n\nBut we're not setting up a rabbitmq cluster and we're not using pacemaker in\nbeaker CI tests, so we just remove the erlang cookie parameter change.\n\nChange-Id: Id24f65f5a7d7c610353d9ecbf51236c97c7e4cb4\nCloses-Bug: #1468444\n""}]",0,195199,e7196c4d2ff0131ffb00a19a6715f104d761e46e,13,4,2,7155,,,0,"Fix Beaker CI according recent puppetlabs-rabbitmq change.

The puppetlabs-rabbitmq module introduce a new feature related to the
erlang_cookie parameter change (the database must be wiped if the cookie is
changed), the parameter wipe_db_on_cookie_change is configured to false by
default.

But we're not setting up a rabbitmq cluster and we're not using pacemaker in
beaker CI tests, so we just remove the erlang cookie parameter change.

Change-Id: Id24f65f5a7d7c610353d9ecbf51236c97c7e4cb4
Closes-Bug: #1468444
",git fetch https://review.opendev.org/openstack/puppet-sahara refs/changes/99/195199/1 && git format-patch -1 --stdout FETCH_HEAD,['spec/acceptance/basic_sahara_spec.rb'],1,30a8a1f5c647452c7daf7c67e2f88c885df1c5df,bug-1468444," delete_guest_user => true, erlang_cookie => 'secrete', wipe_db_on_cookie_change => true, package_provider => $package_provider,"," delete_guest_user => true, erlang_cookie => 'secrete', package_provider => $package_provider,",4,3
openstack%2Fpuppet-nova~master~I3381092f5503f4a50ab1636cef829145ef22d230,openstack/puppet-nova,master,I3381092f5503f4a50ab1636cef829145ef22d230,Fix Beaker CI according recent puppetlabs-rabbitmq change.,MERGED,2015-06-24 16:34:44.000000000,2015-06-25 07:13:11.000000000,2015-06-25 07:13:09.000000000,"[{'_account_id': 3}, {'_account_id': 1607}, {'_account_id': 3153}, {'_account_id': 7155}, {'_account_id': 8482}]","[{'number': 1, 'created': '2015-06-24 16:34:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-nova/commit/ab2ddd6939ec39f4ae35e6dbcd1b17c78817e504', 'message': 'acceptance: Fix CI according recent puppetlabs-rabbitmq change.\n\nThe puppetlabs-rabbitmq module introduce a new feature related to\nerlang_cookie change (the database must be wiped if the cookie\nchange), the parameter wipe_db_on_cookie_change is configured to false\nby default.\n\nChange-Id: I3381092f5503f4a50ab1636cef829145ef22d230\n'}, {'number': 2, 'created': '2015-06-24 17:14:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-nova/commit/5993a1336e59b42f54b6f3cef3e63a46e27f783d', 'message': 'Fix Beaker CI according recent puppetlabs-rabbitmq change.\n\nThe puppetlabs-rabbitmq module introduce a new feature related to the\nerlang_cookie parameter change (the database must be wiped if the cookie is\nchanged), the parameter wipe_db_on_cookie_change is configured to false by\ndefault.\n\nChange-Id: I3381092f5503f4a50ab1636cef829145ef22d230\nCloses-Bug: #1468444\n'}, {'number': 3, 'created': '2015-06-24 22:09:11.000000000', 'files': ['spec/acceptance/basic_nova_spec.rb'], 'web_link': 'https://opendev.org/openstack/puppet-nova/commit/b20f2fdc9726710efe5fe6adff97764949157551', 'message': ""Fix Beaker CI according recent puppetlabs-rabbitmq change.\n\nThe puppetlabs-rabbitmq module introduce a new feature related to the\nerlang_cookie parameter change (the database must be wiped if the cookie is\nchanged), the parameter wipe_db_on_cookie_change is configured to false by\ndefault.\n\nBut we're not setting up a rabbitmq cluster and we're not using pacemaker in\nbeaker CI tests, so we just remove the erlang cookie parameter change.\n\nChange-Id: I3381092f5503f4a50ab1636cef829145ef22d230\nCloses-Bug: #1468444\n""}]",1,195182,b20f2fdc9726710efe5fe6adff97764949157551,19,5,3,7155,,,0,"Fix Beaker CI according recent puppetlabs-rabbitmq change.

The puppetlabs-rabbitmq module introduce a new feature related to the
erlang_cookie parameter change (the database must be wiped if the cookie is
changed), the parameter wipe_db_on_cookie_change is configured to false by
default.

But we're not setting up a rabbitmq cluster and we're not using pacemaker in
beaker CI tests, so we just remove the erlang cookie parameter change.

Change-Id: I3381092f5503f4a50ab1636cef829145ef22d230
Closes-Bug: #1468444
",git fetch https://review.opendev.org/openstack/puppet-nova refs/changes/82/195182/3 && git format-patch -1 --stdout FETCH_HEAD,['spec/acceptance/basic_nova_spec.rb'],1,ab2ddd6939ec39f4ae35e6dbcd1b17c78817e504,bug-1468444," delete_guest_user => true, erlang_cookie => 'secrete', wipe_db_on_cookie_change => true, package_provider => $package_provider,"," delete_guest_user => true, erlang_cookie => 'secrete', package_provider => $package_provider,",4,3
openstack%2Fpython-muranoclient~master~I8bdbdfc3788893fd108d9e3d8b5cbd17f8192b85,openstack/python-muranoclient,master,I8bdbdfc3788893fd108d9e3d8b5cbd17f8192b85,Add abandon parameter to delete method,MERGED,2015-06-03 16:09:43.000000000,2015-06-25 07:11:25.000000000,2015-06-25 07:11:23.000000000,"[{'_account_id': 3}, {'_account_id': 7535}, {'_account_id': 7549}, {'_account_id': 7821}, {'_account_id': 8127}, {'_account_id': 13149}, {'_account_id': 14265}, {'_account_id': 15168}]","[{'number': 1, 'created': '2015-06-03 16:09:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-muranoclient/commit/59c2bb8fc49768777f13888c9ca4bb9890d3901d', 'message': 'Add CLI for abandon feature\n\nChange-Id: I8bdbdfc3788893fd108d9e3d8b5cbd17f8192b85\n'}, {'number': 2, 'created': '2015-06-03 16:32:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-muranoclient/commit/73a1f8d7053c27f98afc5c45503d25a3f1b23ecf', 'message': 'Add CLI for abandon feature\n\nChange-Id: I8bdbdfc3788893fd108d9e3d8b5cbd17f8192b85\nDepends-On: Iab47cf57a7147b4fd46d3320cffa625397c6c5a5'}, {'number': 3, 'created': '2015-06-17 13:33:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-muranoclient/commit/414d2e0811dd7f52f34b62017ef3f59c790e24f9', 'message': 'Add abandon parameter to delete method\n\nPartial-Bug: #1438810\nPartially implements bp environment-abandon\nDepends-On: Iab47cf57a7147b4fd46d3320cffa625397c6c5a5\nChange-Id: I8bdbdfc3788893fd108d9e3d8b5cbd17f8192b85\n'}, {'number': 4, 'created': '2015-06-18 15:24:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-muranoclient/commit/4f7a518c925d5a78e7b7505253433966f9dce5d4', 'message': 'Add abandon parameter to delete method\n\nPartial-Bug: #1438810\nPartially implements bp environment-abandon\nDepends-On: Iab47cf57a7147b4fd46d3320cffa625397c6c5a5\nChange-Id: I8bdbdfc3788893fd108d9e3d8b5cbd17f8192b85\n'}, {'number': 5, 'created': '2015-06-24 09:57:06.000000000', 'files': ['muranoclient/v1/environments.py', 'muranoclient/v1/shell.py', 'muranoclient/tests/unit/test_shell.py'], 'web_link': 'https://opendev.org/openstack/python-muranoclient/commit/fa1d106933155846a058b9833848d2b7e4452a53', 'message': 'Add abandon parameter to delete method\n\nPartial-Bug: #1438810\nPartially implements bp environment-abandon\nDepends-On: Iab47cf57a7147b4fd46d3320cffa625397c6c5a5\nChange-Id: I8bdbdfc3788893fd108d9e3d8b5cbd17f8192b85\n'}]",13,188063,fa1d106933155846a058b9833848d2b7e4452a53,43,8,5,13149,,,0,"Add abandon parameter to delete method

Partial-Bug: #1438810
Partially implements bp environment-abandon
Depends-On: Iab47cf57a7147b4fd46d3320cffa625397c6c5a5
Change-Id: I8bdbdfc3788893fd108d9e3d8b5cbd17f8192b85
",git fetch https://review.opendev.org/openstack/python-muranoclient refs/changes/63/188063/3 && git format-patch -1 --stdout FETCH_HEAD,"['muranoclient/v1/environments.py', 'muranoclient/v1/shell.py', 'muranoclient/tests/test_methods.py']",3,59c2bb8fc49768777f13888c9ca4bb9890d3901d,bug/1438810, def test_env_manager_abandon(self): manager = environments.EnvironmentManager(api) result = manager.abandon('test') self.assertIsNone(result) ,,31,0
openstack%2Fdragonflow~master~Id82c028e2161be90b5308755cd85497a34aa25eb,openstack/dragonflow,master,Id82c028e2161be90b5308755cd85497a34aa25eb,Refactoring the  port status event handler,MERGED,2015-06-22 14:23:01.000000000,2015-06-25 07:08:36.000000000,2015-06-25 07:08:34.000000000,"[{'_account_id': 3}, {'_account_id': 2023}, {'_account_id': 11343}, {'_account_id': 13070}, {'_account_id': 14249}]","[{'number': 1, 'created': '2015-06-22 14:23:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/dragonflow/commit/9db295370a3832788c13f6ec3841e285a0fbf44f', 'message': 'Refuctoring the  port status event handler\n\nChange-Id: Id82c028e2161be90b5308755cd85497a34aa25eb\n'}, {'number': 2, 'created': '2015-06-25 06:39:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/dragonflow/commit/a10a02f11e0c3131a1f4001b05f5029e592a882b', 'message': 'Refactoring the  port status event handler\n\nChange-Id: Id82c028e2161be90b5308755cd85497a34aa25eb\n'}, {'number': 3, 'created': '2015-06-25 06:56:54.000000000', 'files': ['dragonflow/controller/l3_openflow_app.py'], 'web_link': 'https://opendev.org/openstack/dragonflow/commit/3d9b70ad0909c1abd601ace4d4a4c2fa29a4ce21', 'message': 'Refactoring the  port status event handler\n\nChange-Id: Id82c028e2161be90b5308755cd85497a34aa25eb\n'}]",9,194160,3d9b70ad0909c1abd601ace4d4a4c2fa29a4ce21,16,5,3,13070,,,0,"Refactoring the  port status event handler

Change-Id: Id82c028e2161be90b5308755cd85497a34aa25eb
",git fetch https://review.opendev.org/openstack/dragonflow refs/changes/60/194160/3 && git format-patch -1 --stdout FETCH_HEAD,['dragonflow/controller/l3_openflow_app.py'],1,9db295370a3832788c13f6ec3841e285a0fbf44f,qr_port_handle," self._port_desc_handler_dhcp_server_port(datapath, port) elif port.name.startswith('qr'): self._port_desc_handler_legacy_router_port(datapath, port) elif port.name.startswith('qvo'): self._port_desc_handler_vm_port(datapath, port) elif ""patch-tun"" in port.name: self._port_desc_handler_patch_tun_port(datapath, switch, port) def _port_desc_handler_patch_tun_port(self, datapath, switch, port): LOG.debug(""Found br-tun patch port %s %s --> NORMAL path"", port.name, port.hw_addr) switch.patch_port_num = port.port_no self.add_flow_normal_by_port_num( datapath, 0, HIGH_PRIORITY_FLOW, port.port_no) def _port_desc_handler_dhcp_server_port(self, datapath, port): LOG.debug((""Found DHCPD port %s using MAC %s"" ""One machine install""), port.name, port.hw_addr) self.add_flow_normal_by_port_num( datapath, 0, HIGH_PRIORITY_FLOW, port.port_no) def _port_desc_handler_legacy_router_port(self, datapath, port): LOG.debug((""Found Legacy Router port %s using MAC %s"" ""One machine setup""), port.name, port.hw_addr) self.add_flow_normal_by_port_num( datapath, 0, HIGH_PRIORITY_FLOW, port.port_no) def _port_desc_handler_vm_port(self, datapath, port): # a VM port start with qvo<NET-ID[:11]> port_data, tenant_data = self.update_local_port_num( port.name, port.port_no, datapath) if not port_data or not tenant_data: LOG.warning(_LW(""No Port Data for port: <%s>""), port.name) return segmentation_id = port_data.segmentation_id if segmentation_id != 0: self.add_flow_metadata_by_port_num(datapath, 0, HIGH_PRIORITY_FLOW, port.port_no, segmentation_id, 0xffff, self.CLASSIFIER_TABLE) for subnet_id in port_data.get_subnets: subnet = tenant_data.subnets.get(subnet_id) router_ports = tenant_data.get_routers_ports_by_subnet( subnet) self._install_arp_responders_for_routers_ports(datapath, subnet, router_ports) if subnet.is_ipv4(): #Install Local flows for subnet cidr = subnet.cidr self.add_flow_normal_local_subnet( datapath, self.CLASSIFIER_TABLE, LOCAL_SUBNET_TRAFFIC_FLOW_PRIORITY, cidr.network.format(), str(cidr.prefixlen), subnet.segmentation_id) LOG.debug(""Found VM/router port %s using MAC %s,"" "" datapath: %d, port_no: %d, segmentation_id: %s"", port.name, port.hw_addr, datapath.id, port.port_no, segmentation_id) def _install_arp_responders_for_routers_ports(self, datapath, subnet, router_ports): for port in router_ports: self.add_subnet_binding(datapath, subnet, port) "," LOG.debug((""Found DHCPD port %s using MAC %s"" ""One machine install Special"" ""(One Machine set up ) test use case""), port.name, port.hw_addr) self.add_flow_normal_by_port_num( datapath, 0, HIGH_PRIORITY_FLOW, port.port_no) elif port.name.startswith('qr'): LOG.debug((""Found Legacy Router port %s using MAC %s"" ""One machine setup""), port.name, port.hw_addr) self.add_flow_normal_by_port_num( datapath, 0, HIGH_PRIORITY_FLOW, port.port_no) elif port.name.startswith('qvo'): # this is a VM/qrouter port start with qvo/qr<NET-ID[:11]> # update the port data with the port num and the switch dpid port_data, tenant_data = self.update_local_port_num( port.name, port.port_no, datapath) segmentation_id = port_data.segmentation_id if segmentation_id != 0: self.add_flow_metadata_by_port_num(datapath, 0, HIGH_PRIORITY_FLOW, port.port_no, segmentation_id, 0xffff, self.CLASSIFIER_TABLE) for subnet_id in port_data.get_subnets: subnet = tenant_data.subnets.get(subnet_id) router_ports = tenant_data.get_routers_ports_by_subnet( subnet) #Install ARP responders for Router Ports on Subnet for interface in router_ports: self.add_subnet_binding(datapath, subnet, interface) if subnet.is_ipv4(): #Install Local flows for subnet cidr = subnet.cidr self.add_flow_normal_local_subnet( datapath, self.CLASSIFIER_TABLE, LOCAL_SUBNET_TRAFFIC_FLOW_PRIORITY, cidr.network.format(), str(cidr.prefixlen), subnet.segmentation_id) LOG.debug(""Found VM/router port %s using MAC %s,"" "" datapath: %d, port_no: %d, segmentation_id: %s"", port.name, port.hw_addr, datapath.id, port.port_no, segmentation_id) elif ""patch-tun"" in port.name: LOG.debug(""Found br-tun patch port %s %s --> NORMAL path"", port.name, port.hw_addr) switch.patch_port_num = port.port_no self.add_flow_normal_by_port_num( datapath, 0, HIGH_PRIORITY_FLOW, port.port_no)",73,56
openstack%2Fopenstack-manuals~master~I90ef5587cb5ae0f1dc456019fc92d9d717ce71a8,openstack/openstack-manuals,master,I90ef5587cb5ae0f1dc456019fc92d9d717ce71a8,Imported Translations from Transifex,MERGED,2015-06-25 06:18:11.000000000,2015-06-25 07:08:12.000000000,2015-06-25 07:08:10.000000000,"[{'_account_id': 3}, {'_account_id': 6547}]","[{'number': 1, 'created': '2015-06-25 06:18:11.000000000', 'files': ['doc/admin-guide-cloud/locale/admin-guide-cloud.pot', 'doc/glossary/locale/vi_VN.po', 'doc/install-guide/locale/vi_VN.po', 'doc/install-guide/locale/ja.po', 'doc/common/locale/zh_CN.po'], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/bcde8ef774bc412f4a31ff783b9739b2ccab3d6f', 'message': 'Imported Translations from Transifex\n\nFor more information about this automatic import see:\nhttps://wiki.openstack.org/wiki/Translations/Infrastructure\n\nChange-Id: I90ef5587cb5ae0f1dc456019fc92d9d717ce71a8\n'}]",0,195428,bcde8ef774bc412f4a31ff783b9739b2ccab3d6f,6,2,1,11131,,,0,"Imported Translations from Transifex

For more information about this automatic import see:
https://wiki.openstack.org/wiki/Translations/Infrastructure

Change-Id: I90ef5587cb5ae0f1dc456019fc92d9d717ce71a8
",git fetch https://review.opendev.org/openstack/openstack-manuals refs/changes/28/195428/1 && git format-patch -1 --stdout FETCH_HEAD,"['doc/admin-guide-cloud/locale/admin-guide-cloud.pot', 'doc/glossary/locale/vi_VN.po', 'doc/install-guide/locale/vi_VN.po', 'doc/install-guide/locale/ja.po', 'doc/common/locale/zh_CN.po']",5,bcde8ef774bc412f4a31ff783b9739b2ccab3d6f,transifex/translations,"""POT-Creation-Date: 2015-06-25 01:02+0000\n"" ""PO-Revision-Date: 2015-06-24 08:39+0000\n""msgid ""m1.tiny"" msgstr ""m1.tiny"" ","""POT-Creation-Date: 2015-06-22 17:24+0000\n"" ""PO-Revision-Date: 2015-06-22 11:14+0000\n""",784,160
openstack%2Fbarbican~master~I3917acf5541c9ea43dcf895c6a85b97a1f9259bc,openstack/barbican,master,I3917acf5541c9ea43dcf895c6a85b97a1f9259bc,Remove left over reference to admin endpoint,MERGED,2015-06-24 18:32:13.000000000,2015-06-25 07:07:16.000000000,2015-06-25 07:07:13.000000000,"[{'_account_id': 3}, {'_account_id': 7136}, {'_account_id': 10873}, {'_account_id': 11970}]","[{'number': 1, 'created': '2015-06-24 18:32:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/barbican/commit/88489a745d0f590819b7a209f89aa811a9dfc72c', 'message': 'Remove left over reference to admin endpoint\n\nThis CR removes a missed reference to the admin endpoint that was missed\nwhen the admin endpoint was removed.\n\nChange-Id: I3917acf5541c9ea43dcf895c6a85b97a1f9259bc\nRelated-Bug: #1450277\n'}, {'number': 2, 'created': '2015-06-24 19:55:15.000000000', 'files': ['barbican/api/app.py'], 'web_link': 'https://opendev.org/openstack/barbican/commit/8627486c4e0a612f6da79d2fad2a081587851f3b', 'message': 'Remove left over reference to admin endpoint\n\nThis CR removes a missed reference to the admin endpoint that was missed\nwhen the admin endpoint was removed.\n\nChange-Id: I3917acf5541c9ea43dcf895c6a85b97a1f9259bc\nRelated-Bug: #1450277\n'}]",0,195251,8627486c4e0a612f6da79d2fad2a081587851f3b,11,4,2,7973,,,0,"Remove left over reference to admin endpoint

This CR removes a missed reference to the admin endpoint that was missed
when the admin endpoint was removed.

Change-Id: I3917acf5541c9ea43dcf895c6a85b97a1f9259bc
Related-Bug: #1450277
",git fetch https://review.opendev.org/openstack/barbican refs/changes/51/195251/2 && git format-patch -1 --stdout FETCH_HEAD,['barbican/api/app.py'],1,88489a745d0f590819b7a209f89aa811a9dfc72c,bug/1450277,"def create_version_app(global_config, **local_conf):","def create_admin_app(global_config, **local_conf): create_version_app = create_admin_app",1,4
openstack%2Ffuel-qa~master~I7a9b6871fac09fa97b8b01c66ce84176829f37d7,openstack/fuel-qa,master,I7a9b6871fac09fa97b8b01c66ce84176829f37d7,doc: Remove duplicate fuel-client section.,MERGED,2015-06-24 10:51:17.000000000,2015-06-25 07:05:28.000000000,2015-06-25 07:05:26.000000000,"[{'_account_id': 3}, {'_account_id': 8882}, {'_account_id': 8971}, {'_account_id': 9977}, {'_account_id': 12200}, {'_account_id': 12867}]","[{'number': 1, 'created': '2015-06-24 10:51:17.000000000', 'files': ['doc/models.rst'], 'web_link': 'https://opendev.org/openstack/fuel-qa/commit/75340a276b530c0848c25e5a331db9d7d0b8b633', 'message': 'doc: Remove duplicate fuel-client section.\n\nSecond fuel-client section has been added\nby mistake. Fixing it now.\n\nChange-Id: I7a9b6871fac09fa97b8b01c66ce84176829f37d7\nPartial-bug: #1321682\nRelated-bug: #1466048\n'}]",0,195032,75340a276b530c0848c25e5a331db9d7d0b8b633,11,6,1,16106,,,0,"doc: Remove duplicate fuel-client section.

Second fuel-client section has been added
by mistake. Fixing it now.

Change-Id: I7a9b6871fac09fa97b8b01c66ce84176829f37d7
Partial-bug: #1321682
Related-bug: #1466048
",git fetch https://review.opendev.org/openstack/fuel-qa refs/changes/32/195032/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/models.rst'],1,75340a276b530c0848c25e5a331db9d7d0b8b633,fix-duplicate-fuel,,Fuel Web Client --------------- .. automodule:: fuelweb_test.models.fuel_web_client :members: ,0,5
openstack%2Fproject-config~master~If8fc714c1e494f753bd21b2a28d95f21dd451291,openstack/project-config,master,If8fc714c1e494f753bd21b2a28d95f21dd451291,Normalize projects.yaml,MERGED,2015-06-25 06:01:19.000000000,2015-06-25 07:03:49.000000000,2015-06-25 07:03:47.000000000,"[{'_account_id': 3}, {'_account_id': 6547}]","[{'number': 1, 'created': '2015-06-25 06:01:19.000000000', 'files': ['gerrit/projects.yaml'], 'web_link': 'https://opendev.org/openstack/project-config/commit/fa3e9c00bf54194cb82eb74e81ba0eecd2604225', 'message': 'Normalize projects.yaml\n\nChange-Id: If8fc714c1e494f753bd21b2a28d95f21dd451291\n'}]",0,195423,fa3e9c00bf54194cb82eb74e81ba0eecd2604225,6,2,1,11131,,,0,"Normalize projects.yaml

Change-Id: If8fc714c1e494f753bd21b2a28d95f21dd451291
",git fetch https://review.opendev.org/openstack/project-config refs/changes/23/195423/1 && git format-patch -1 --stdout FETCH_HEAD,['gerrit/projects.yaml'],1,fa3e9c00bf54194cb82eb74e81ba0eecd2604225,project-yaml-normalization,, upstream: https://github.com/sdague/zmq-devstack.git,0,1
openstack%2Fopenstack-manuals~master~I8e20ed4dbc115d42d7d2cd7872e6e8ea82a6fe44,openstack/openstack-manuals,master,I8e20ed4dbc115d42d7d2cd7872e6e8ea82a6fe44,Invalid VMware options for glance metadata,MERGED,2015-06-17 12:46:41.000000000,2015-06-25 07:02:38.000000000,2015-06-25 07:02:36.000000000,"[{'_account_id': 3}, {'_account_id': 6547}, {'_account_id': 6772}, {'_account_id': 7923}, {'_account_id': 9162}, {'_account_id': 9382}, {'_account_id': 10607}]","[{'number': 1, 'created': '2015-06-17 12:46:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/887e57f7edf6e88d3eb64f153eac705e4b5e5337', 'message': 'Invalid VMware options for glance metadata\n\nThe folooiwng are flavor extra specs and not glance metadata:\n - quota:cpu_limit\n - quota:cpu_reservation\n - vmware:hw_version\n\nChange-Id: I8e20ed4dbc115d42d7d2cd7872e6e8ea82a6fe44\n'}, {'number': 2, 'created': '2015-06-24 04:27:12.000000000', 'files': ['doc/cli-reference/ch_cli_glance_property_keys.xml'], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/15acbd978631c17ec8b863b757b5cb4d0f9b9231', 'message': 'Invalid VMware options for glance metadata\n\nThe following are flavor extra specs and not glance metadata:\n - quota:cpu_limit\n - quota:cpu_reservation\n - vmware:hw_version\n\nChange-Id: I8e20ed4dbc115d42d7d2cd7872e6e8ea82a6fe44\n'}]",1,192644,15acbd978631c17ec8b863b757b5cb4d0f9b9231,14,7,2,1653,,,0,"Invalid VMware options for glance metadata

The following are flavor extra specs and not glance metadata:
 - quota:cpu_limit
 - quota:cpu_reservation
 - vmware:hw_version

Change-Id: I8e20ed4dbc115d42d7d2cd7872e6e8ea82a6fe44
",git fetch https://review.opendev.org/openstack/openstack-manuals refs/changes/44/192644/2 && git format-patch -1 --stdout FETCH_HEAD,['doc/cli-reference/ch_cli_glance_property_keys.xml'],1,887e57f7edf6e88d3eb64f153eac705e4b5e5337,image-meta,," <td>VMware API driver</td> <td>quota:cpu_limit</td> <td>Specifies the upper limit for CPU allocation in MHz. This parameter ensures that a machine never uses more than the defined amount of CPU time. It can be used to enforce a limit on the machine's CPU performance. </td> <td>A numerical value in MHz</td> </tr> <tr valign=""top""> <td>VMware API driver</td> <td>quota:cpu_reservation</td> <td>Specifies the guaranteed minimum CPU reservation in MHz. This means that if needed, the machine will definitely get allocated the reserved amount of CPU cycles. </td> <td>A numerical value in MHz</td> </tr> <tr valign=""top""> <td>VMware API driver</td> <td>vmware:hw_version</td> <td>Specifies the hardware version VMware uses to create images. If the hardware version needs to be compatible with a cluster version, for backward compatibility or other circumstances, the <literal>vmware:hw_version</literal> key specifies a virtual machine hardware version. In the event that a cluster has mixed host version types, the key will enable the VC to place the cluster on the correct host.</td> <td>See <link xlink:href=""https://pubs.vmware.com/vsphere-55/index.jsp# com.vmware.vsphere.hostclient.doc/GUID-68E5EDAE-66DE-43F8-9420-F424AFEADB1D.html"" >vmware.com</link>.</td> </tr> <tr valign=""top"">",0,33
openstack%2Fopenstack-manuals~master~I0cd5f01968625c42b17c31670b0fc8340fdb89e1,openstack/openstack-manuals,master,I0cd5f01968625c42b17c31670b0fc8340fdb89e1,Update back-end stores in image management,MERGED,2015-06-24 06:32:29.000000000,2015-06-25 07:02:34.000000000,2015-06-25 07:02:32.000000000,"[{'_account_id': 3}, {'_account_id': 6547}, {'_account_id': 7923}, {'_account_id': 10497}, {'_account_id': 10607}, {'_account_id': 10705}, {'_account_id': 14643}, {'_account_id': 14962}, {'_account_id': 15054}]","[{'number': 1, 'created': '2015-06-24 06:32:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/1e3eae0797bedf2ce6e4c396a8f3ff4576994e16', 'message': 'Update back-end stores in glance\n\nThis patch update the back-end stores in glance section\n\nChange-Id: I0cd5f01968625c42b17c31670b0fc8340fdb89e1\n'}, {'number': 2, 'created': '2015-06-24 06:51:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/e735754a60de760391a3d77468b7c26884d6f1fe', 'message': 'Update back-end stores in image management\n\nThis patch update the back-end stores in image management section\n\nChange-Id: I0cd5f01968625c42b17c31670b0fc8340fdb89e1\n'}, {'number': 3, 'created': '2015-06-24 07:43:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/d90b6b8ffd3727d42aeafde3232d1b9005c78fd6', 'message': 'Update back-end stores in image management\n\nThis patch update the back-end stores in image management section\n\nChange-Id: I0cd5f01968625c42b17c31670b0fc8340fdb89e1\n'}, {'number': 4, 'created': '2015-06-25 00:49:31.000000000', 'files': ['doc/admin-guide-cloud/compute/section_compute-image-mgt.xml'], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/dbfc676c245654d039f36d0d9fe4694d8ddc38b0', 'message': 'Update back-end stores in image management\n\nThis patch update the back-end stores in image management section\n\nChange-Id: I0cd5f01968625c42b17c31670b0fc8340fdb89e1\n'}]",6,194956,dbfc676c245654d039f36d0d9fe4694d8ddc38b0,22,9,4,15054,,,0,"Update back-end stores in image management

This patch update the back-end stores in image management section

Change-Id: I0cd5f01968625c42b17c31670b0fc8340fdb89e1
",git fetch https://review.opendev.org/openstack/openstack-manuals refs/changes/56/194956/4 && git format-patch -1 --stdout FETCH_HEAD,['doc/admin-guide-cloud/compute/section_compute-image-mgt.xml'],1,1e3eae0797bedf2ce6e4c396a8f3ff4576994e16,update_back-end_stores_in_image_management, <term>Swift</term> <term>Cinder</term> <listitem> <para>The OpenStack highly available service for storing blocks.</para> </listitem> </varlistentry> <varlistentry> <term>Vmware Datastore</term> <listitem> <para>ESX/ESXi or vCenter Server target system</para> </listitem> </varlistentry> <varlistentry> <term>Sheepdog</term> <listitem> <para>A distributed storage system for QEMU/KVM</para> </listitem> </varlistentry> <varlistentry>, <term>Object Storage service</term>,20,1
openstack%2Ffuel-devops~master~I6499d69f7fd8c81ccaa0f8bf8be6cc9d1438ec33,openstack/fuel-devops,master,I6499d69f7fd8c81ccaa0f8bf8be6cc9d1438ec33,Change dos.py slave naming to match environment expectations,MERGED,2015-05-29 15:37:30.000000000,2015-06-25 07:02:07.000000000,2015-06-25 07:02:06.000000000,"[{'_account_id': 3}, {'_account_id': 6719}, {'_account_id': 8882}, {'_account_id': 8971}, {'_account_id': 9439}, {'_account_id': 10136}, {'_account_id': 11081}, {'_account_id': 11969}, {'_account_id': 12867}, {'_account_id': 14708}]","[{'number': 1, 'created': '2015-05-29 15:37:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-devops/commit/a726af77054b547c6b690e6f749e109d34a046f7', 'message': 'Change dos.py slave naming to match environment expectations\n\nChange-Id: I6499d69f7fd8c81ccaa0f8bf8be6cc9d1438ec33\nCloses-bug: #1460118\n'}, {'number': 2, 'created': '2015-06-19 18:31:09.000000000', 'files': ['devops/shell.py'], 'web_link': 'https://opendev.org/openstack/fuel-devops/commit/b972701fdd0603938a92a731f759bdf85236d3c2', 'message': 'Change dos.py slave naming to match environment expectations\n\nChange-Id: I6499d69f7fd8c81ccaa0f8bf8be6cc9d1438ec33\nCloses-bug: #1460118\n'}]",0,186801,b972701fdd0603938a92a731f759bdf85236d3c2,15,10,2,8829,,,0,"Change dos.py slave naming to match environment expectations

Change-Id: I6499d69f7fd8c81ccaa0f8bf8be6cc9d1438ec33
Closes-bug: #1460118
",git fetch https://review.opendev.org/openstack/fuel-devops refs/changes/01/186801/2 && git format-patch -1 --stdout FETCH_HEAD,['devops/shell.py'],1,a726af77054b547c6b690e6f749e109d34a046f7,bug/1460118," node_name = ""slave-%02d"" % (node)"," node_name = ""slave-%i"" % (node)",1,1
openstack%2Ftricircle~master~I088977739394448e9ad8038480c1da52df2a8c24,openstack/tricircle,master,I088977739394448e9ad8038480c1da52df2a8c24,Remove code for image syncing which is not used now,MERGED,2015-06-25 06:48:07.000000000,2015-06-25 06:57:56.000000000,2015-06-25 06:50:10.000000000,"[{'_account_id': 3}, {'_account_id': 11819}, {'_account_id': 16911}]","[{'number': 1, 'created': '2015-06-25 06:48:07.000000000', 'files': ['image/sync/drivers/__init__.py', 'image/cascading.py', 'image/sync/__init__.py', 'image/exception.py', 'image/sync/drivers/filesystem.py'], 'web_link': 'https://opendev.org/openstack/tricircle/commit/812db07aa7f3058642ad156d21cda976914ae414', 'message': 'Remove code for image syncing which is not used now\n\nChange-Id: I088977739394448e9ad8038480c1da52df2a8c24\n'}]",0,195430,812db07aa7f3058642ad156d21cda976914ae414,7,3,1,12076,,,0,"Remove code for image syncing which is not used now

Change-Id: I088977739394448e9ad8038480c1da52df2a8c24
",git fetch https://review.opendev.org/openstack/tricircle refs/changes/30/195430/1 && git format-patch -1 --stdout FETCH_HEAD,"['image/sync/drivers/__init__.py', 'image/cascading.py', 'image/sync/__init__.py', 'image/exception.py', 'image/sync/drivers/filesystem.py']",5,812db07aa7f3058642ad156d21cda976914ae414,remove-image,,"import logging import sys from oslo.config import cfg import pxssh import pexpect from nova.i18n import _ from nova.image import exception LOG = logging.getLogger(__name__) CONF = cfg.CONF sync_opt = [ cfg.IntOpt('scp_copy_timeout', default=3600, help=_('when snapshot, max wait (second)time for snapshot ' 'status become active.'), deprecated_opts=[cfg.DeprecatedOpt('scp_copy_timeout', group='DEFAULT')]), ] CONF.register_opts(sync_opt, group='sync') def _get_ssh(hostname, username, password): s = pxssh.pxssh() s.login(hostname, username, password, original_prompt='[#$>]') s.logfile = sys.stdout return s class Store(object): def copy_to(self, from_location, to_location, candidate_path=None): from_store_loc = from_location to_store_loc = to_location LOG.debug(_('from_store_loc is: %s'), from_store_loc) if from_store_loc['host'] == to_store_loc['host'] and \ from_store_loc['path'] == to_store_loc['path']: LOG.info(_('The from_loc is same to to_loc, no need to copy. the ' 'host:path is %s:%s') % (from_store_loc['host'], from_store_loc['path'])) return 'file://%s' % to_store_loc['path'] to_host = r""""""{username}@{host}"""""".format( username=to_store_loc['login_user'], host=to_store_loc['host']) to_path = r""""""{to_host}:{path}"""""".format(to_host=to_host, path=to_store_loc['path']) copy_path = from_store_loc['path'] try: from_ssh = _get_ssh(from_store_loc['host'], from_store_loc['login_user'], from_store_loc['login_password']) except Exception: msg = _('ssh login failed to %(user)s:%(passwd)s %(host)s' % {'user': from_store_loc['login_user'], 'passwd': from_store_loc['login_password'], 'host': from_store_loc['host'] }) LOG.exception(msg) raise exception.GlanceSyncException(reason=msg) from_ssh.sendline('ls %s' % copy_path) from_ssh.prompt() if 'cannot access' in from_ssh.before or \ 'No such file' in from_ssh.before: if candidate_path: from_ssh.sendline('ls %s' % candidate_path) from_ssh.prompt() if 'cannot access' not in from_ssh.before and \ 'No such file' not in from_ssh.before: copy_path = candidate_path else: msg = _(""the image path for copy to is not exists, file copy"" ""failed: path is %s"" % copy_path) LOG.exception(msg) raise exception.GlanceSyncException(reason=msg) from_ssh.sendline('scp -P 22 %s %s' % (copy_path, to_path)) while True: scp_index = from_ssh.expect(['.yes/no.', '.assword:.', pexpect.TIMEOUT]) if scp_index == 0: from_ssh.sendline('yes') from_ssh.prompt() elif scp_index == 1: from_ssh.sendline(to_store_loc['login_password']) from_ssh.prompt(timeout=CONF.sync.scp_copy_timeout) break else: msg = _(""scp commond execute failed, with copy_path %s and "" ""to_path %s"" % (copy_path, to_path)) LOG.exception(msg) raise exception.GlanceSyncException(reason=msg) if from_ssh: from_ssh.logout() return 'file://%s' % to_store_loc['path'] ",0,310
openstack%2Fha-guide~master~Id3460d5c55894776c36beaf9019bddd0a6d4b01f,openstack/ha-guide,master,Id3460d5c55894776c36beaf9019bddd0a6d4b01f,Imported Translations from Transifex,MERGED,2015-06-25 06:00:09.000000000,2015-06-25 06:44:47.000000000,2015-06-25 06:44:46.000000000,"[{'_account_id': 3}, {'_account_id': 6547}]","[{'number': 1, 'created': '2015-06-25 06:00:09.000000000', 'files': ['doc/high-availability-guide/locale/ja.po', 'doc/high-availability-guide/locale/zh_CN.po'], 'web_link': 'https://opendev.org/openstack/ha-guide/commit/6ed6635f7b5a08583b37148434ae8a2d227e4a61', 'message': 'Imported Translations from Transifex\n\nFor more information about this automatic import see:\nhttps://wiki.openstack.org/wiki/Translations/Infrastructure\n\nChange-Id: Id3460d5c55894776c36beaf9019bddd0a6d4b01f\n'}]",0,195422,6ed6635f7b5a08583b37148434ae8a2d227e4a61,6,2,1,11131,,,0,"Imported Translations from Transifex

For more information about this automatic import see:
https://wiki.openstack.org/wiki/Translations/Infrastructure

Change-Id: Id3460d5c55894776c36beaf9019bddd0a6d4b01f
",git fetch https://review.opendev.org/openstack/ha-guide refs/changes/22/195422/1 && git format-patch -1 --stdout FETCH_HEAD,"['doc/high-availability-guide/locale/ja.po', 'doc/high-availability-guide/locale/zh_CN.po']",2,6ed6635f7b5a08583b37148434ae8a2d227e4a61,transifex/translations,"#  <liujunpeng@inspur.com>, 2015""POT-Creation-Date: 2015-06-23 11:29+0000\n"" ""PO-Revision-Date: 2015-06-24 08:40+0000\n"" ""Last-Translator:  <liujunpeng@inspur.com>\n""msgid ""2015-04-30"" msgstr ""2015-04-30"" msgid ""Conversion to DocBook."" msgstr ""DocBook"" ""Pacemaker interacts with applications through resource agents (RAs), of "" ""which it supports over 70 natively. Pacemaker can also easily use third-"" ""party RAs. An OpenStack high-availability configuration uses existing native "" ""Pacemaker RAs (such as those managing MySQL databases or virtual IP "" ""addresses), existing third-party RAs (such as for RabbitMQ), and native "" ""OpenStack RAs (such as those managing the OpenStack Identity and Image "" ""services)."" msgstr """" ""Pacemaker (RAs) 70  "" ""Pacemaker (RAs)OpenStack "" "" Pacemaker RAs MySQL  IP "" ""( RabbitMQ ) OpenStack "" ""RAs( OpenStack )"" msgid """"""This guide has various updates for the Kilo release, such as adding MariaDB, "" ""updates to the MySQL information, corosync and networking updates."" msgstr """" ""KiloMariaDBMySQLcorosync"" """" msgid """"","""POT-Creation-Date: 2015-06-17 09:52+0000\n"" ""PO-Revision-Date: 2015-06-17 14:47+0000\n"" ""Last-Translator: openstackjenkins <jenkins@openstack.org>\n""",96,6
openstack%2Fopenstackdocstheme~master~I4a45f6f76936eea0a95f10a827c5df8821ab677f,openstack/openstackdocstheme,master,I4a45f6f76936eea0a95f10a827c5df8821ab677f,Adds release notes entries for 1.0.8 and 1.0.9,MERGED,2015-06-24 17:22:17.000000000,2015-06-25 06:35:07.000000000,2015-06-25 06:35:07.000000000,"[{'_account_id': 3}, {'_account_id': 6547}]","[{'number': 1, 'created': '2015-06-24 17:22:17.000000000', 'files': ['RELEASENOTES.rst'], 'web_link': 'https://opendev.org/openstack/openstackdocstheme/commit/64d1132bb8634f270d02e41195e2d832089cb451', 'message': 'Adds release notes entries for 1.0.8 and 1.0.9\n\nChange-Id: I4a45f6f76936eea0a95f10a827c5df8821ab677f\n'}]",0,195211,64d1132bb8634f270d02e41195e2d832089cb451,6,2,1,964,,,0,"Adds release notes entries for 1.0.8 and 1.0.9

Change-Id: I4a45f6f76936eea0a95f10a827c5df8821ab677f
",git fetch https://review.opendev.org/openstack/openstackdocstheme refs/changes/11/195211/1 && git format-patch -1 --stdout FETCH_HEAD,['RELEASENOTES.rst'],1,64d1132bb8634f270d02e41195e2d832089cb451,relnotes,"1.0.9 * Make indentation on glossary definitions. * Adds original CSS/JS files to repository. * Improve navigation links. 1.0.8 * Enhancement to ""Report a bug"" link by adding URL to current page reported from. ",,10,0
openstack%2Fopenstack-ansible~master~Ia479610b9ab69d64d1de756099d840b2ab331378,openstack/openstack-ansible,master,Ia479610b9ab69d64d1de756099d840b2ab331378,Updated tempest isolation options,MERGED,2015-06-22 20:22:54.000000000,2015-06-25 06:24:37.000000000,2015-06-25 06:24:36.000000000,"[{'_account_id': 3}, {'_account_id': 4}, {'_account_id': 6816}, {'_account_id': 7353}, {'_account_id': 12000}]","[{'number': 1, 'created': '2015-06-22 20:22:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/a29ac1fdebb12418d14ad594cdfc7355518d9b8d', 'message': 'Updated tempest isolation options\n\nThis change updates the way that the packages are installed in an\nisolated deployment. This ensures that our build packages are used\nwithin the deployment while also allowing temptest to go online and\nconsume upstream packages from pypi. Additionally this updates\ntempest-lib which is needed to make keystone w/ fernet tokens go as\nthere is an upstream issues with date time-stampes with all versions\nof tempest-lib that will prohibit the use of fernet tokens.\n\nChange-Id: Ia479610b9ab69d64d1de756099d840b2ab331378\nRelated-Bug: #1466010\n'}, {'number': 2, 'created': '2015-06-23 21:59:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/5ade350968223256f509c9f22edd824530f08073', 'message': 'Updated tempest isolation options\n\nThis change updates the way that the packages are installed in an\nisolated deployment. This ensures that our build packages are used\nwithin the deployment while also allowing temptest to go online and\nconsume upstream packages from pypi. Additionally this updates\ntempest-lib which is needed to make keystone w/ fernet tokens go as\nthere is an upstream issues with date time-stampes with all versions\nof tempest-lib that will prohibit the use of fernet tokens.\n\nChange-Id: Ia479610b9ab69d64d1de756099d840b2ab331378\nRelated-Bug: #1466010\n'}, {'number': 3, 'created': '2015-06-24 14:31:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/5588e61ecf0403ed9117d04df2191e5e011bb690', 'message': 'Updated tempest isolation options\n\nThis change updates the way that the packages are installed in an\nisolated deployment. This ensures that our build packages are used\nwithin the deployment while also allowing temptest to go online and\nconsume upstream packages from pypi. Additionally this updates\ntempest-lib which is needed to make keystone w/ fernet tokens go as\nthere is an upstream issues with date timestamps with all versions\nof tempest-lib that will prohibit the use of fernet tokens.\n\nChange-Id: Ia479610b9ab69d64d1de756099d840b2ab331378\nRelated-Bug: #1466010\n'}, {'number': 4, 'created': '2015-06-24 14:34:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/944af81c53e724786e249eba485130f814fc660e', 'message': 'Updated tempest isolation options\n\nThis change updates the way that the packages are installed in an\nisolated deployment. This ensures that our build packages are used\nwithin the deployment while also allowing temptest to go online and\nconsume upstream packages from pypi. Additionally this updates\ntempest-lib which is needed to make keystone w/ fernet tokens go as\nthere is an upstream issues with date timestamps with all versions\nof tempest-lib that will prohibit the use of fernet tokens.\n\nChange-Id: Ia479610b9ab69d64d1de756099d840b2ab331378\nRelated-Bug: #1466010\n'}, {'number': 5, 'created': '2015-06-24 15:50:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/fa4982be4fb9f62e5564993fe4522f50175efff4', 'message': 'Updated tempest isolation options\n\nThis change updates the way that the packages are installed in an\nisolated deployment. This ensures that our build packages are used\nwithin the deployment while also allowing temptest to go online and\nconsume upstream packages from pypi. Additionally this updates\ntempest-lib which is needed to make keystone w/ fernet tokens go as\nthere is an upstream issues with date timestamps with all versions\nof tempest-lib that will prohibit the use of fernet tokens.\n\nChange-Id: Ia479610b9ab69d64d1de756099d840b2ab331378\nRelated-Bug: #1466010\n'}, {'number': 6, 'created': '2015-06-24 23:29:42.000000000', 'files': ['playbooks/roles/os_tempest/tasks/tempest_install.yml', 'playbooks/defaults/repo_packages/openstack_other.yml', 'etc/openstack_deploy/user_group_vars.yml', 'playbooks/roles/os_tempest/defaults/main.yml'], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/2086f6edb1a4c50dc0000804a510aa4da1af4f5f', 'message': 'Updated tempest isolation options\n\nThis change updates the way that the packages are installed in an\nisolated deployment. This ensures that our build packages are used\nwithin the deployment while also allowing temptest to go online and\nconsume upstream packages from pypi. Additionally this updates\ntempest-lib which is needed to make keystone w/ fernet tokens go as\nthere is an upstream issues with date timestamps with all versions\nof tempest-lib that will prohibit the use of fernet tokens.\n\nChange-Id: Ia479610b9ab69d64d1de756099d840b2ab331378\nRelated-Bug: #1466010\n'}]",2,194344,2086f6edb1a4c50dc0000804a510aa4da1af4f5f,32,5,6,7353,,,0,"Updated tempest isolation options

This change updates the way that the packages are installed in an
isolated deployment. This ensures that our build packages are used
within the deployment while also allowing temptest to go online and
consume upstream packages from pypi. Additionally this updates
tempest-lib which is needed to make keystone w/ fernet tokens go as
there is an upstream issues with date timestamps with all versions
of tempest-lib that will prohibit the use of fernet tokens.

Change-Id: Ia479610b9ab69d64d1de756099d840b2ab331378
Related-Bug: #1466010
",git fetch https://review.opendev.org/openstack/openstack-ansible refs/changes/44/194344/6 && git format-patch -1 --stdout FETCH_HEAD,"['playbooks/defaults/repo_packages/openstack_services.yml', 'playbooks/roles/os_tempest/tasks/tempest_install.yml', 'playbooks/defaults/repo_packages/openstack_other.yml', 'etc/openstack_deploy/user_group_vars.yml', 'playbooks/roles/os_tempest/defaults/main.yml']",5,a29ac1fdebb12418d14ad594cdfc7355518d9b8d,bug/1466010," tempest_pip_instructions: ""--isolated""", - python-memcached,18,4
openstack%2Ffuel-library~master~Ief0266d468bf127156db8c42c86b840436090ab8,openstack/fuel-library,master,Ief0266d468bf127156db8c42c86b840436090ab8,Fix amqp_hosts for heat,MERGED,2015-06-19 12:08:53.000000000,2015-06-25 06:20:52.000000000,2015-06-25 06:19:51.000000000,"[{'_account_id': 3}, {'_account_id': 6719}, {'_account_id': 6926}, {'_account_id': 7227}, {'_account_id': 8786}, {'_account_id': 8787}, {'_account_id': 8789}, {'_account_id': 8971}, {'_account_id': 9037}, {'_account_id': 10391}, {'_account_id': 11090}, {'_account_id': 11827}, {'_account_id': 13948}, {'_account_id': 14774}, {'_account_id': 14985}]","[{'number': 1, 'created': '2015-06-19 12:08:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/a819d19dde18b0c246b5d6f6367fa1e6ec69c2fc', 'message': 'Fix amqp_hosts for heat\n\nW/o this patch amqp_hosts is being passed\nto heat as array with single element containing\na string with all amqp hosts listed separeted by a comma.\nThis is wrong as by desgin, the heat module expects\nthem to be listed as array elements instead. This\nleads to ha_queues configured always to False\nbreaking Heat HA operations.\n\nThe fix is to split amql_hosts before to pass it\nto the heat class\n\nCloses-bug: #1465840\n\nChange-Id: Ief0266d468bf127156db8c42c86b840436090ab8\nSigned-off-by: Bogdan Dobrelya <bdobrelia@mirantis.com>\n'}, {'number': 2, 'created': '2015-06-19 12:21:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/a2828de305478200e174ab4f16c659aab116423d', 'message': 'Fix amqp_hosts for heat\n\nW/o this patch amqp_hosts is being passed\nto heat as array with single element containing\na string with all amqp hosts listed separeted by a comma.\nThis is wrong as by desgin, the heat module expects\nthem to be listed as array elements instead. This\nleads to ha_queues configured always to False\nbreaking Heat HA operations.\n\nThe fix is to split amql_hosts before to pass it\nto the heat class\n\nCloses-bug: #1465840\n\nChange-Id: Ief0266d468bf127156db8c42c86b840436090ab8\nSigned-off-by: Bogdan Dobrelya <bdobrelia@mirantis.com>\n'}, {'number': 3, 'created': '2015-06-19 13:04:08.000000000', 'files': ['deployment/puppet/osnailyfacter/modular/heat/heat.pp'], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/fb04fd58b067c54dc93d6c5998cd67aef4f30586', 'message': 'Fix amqp_hosts for heat\n\nW/o this patch amqp_hosts is being passed\nto heat as array with single element containing\na string with all amqp hosts listed separeted by a comma.\nThis is wrong as by desgin, the heat module expects\nthem to be listed as array elements instead. This\nleads to ha_queues configured always to False\nbreaking Heat HA operations\n\nThe fix is to split amql_hosts before to pass it\nto the heat class\n\nCloses-bug: #1465840\n\nChange-Id: Ief0266d468bf127156db8c42c86b840436090ab8\nSigned-off-by: Bogdan Dobrelya <bdobrelia@mirantis.com>\n'}]",0,193511,fb04fd58b067c54dc93d6c5998cd67aef4f30586,63,15,3,6926,,,0,"Fix amqp_hosts for heat

W/o this patch amqp_hosts is being passed
to heat as array with single element containing
a string with all amqp hosts listed separeted by a comma.
This is wrong as by desgin, the heat module expects
them to be listed as array elements instead. This
leads to ha_queues configured always to False
breaking Heat HA operations

The fix is to split amql_hosts before to pass it
to the heat class

Closes-bug: #1465840

Change-Id: Ief0266d468bf127156db8c42c86b840436090ab8
Signed-off-by: Bogdan Dobrelya <bdobrelia@mirantis.com>
",git fetch https://review.opendev.org/openstack/fuel-library refs/changes/11/193511/1 && git format-patch -1 --stdout FETCH_HEAD,['deployment/puppet/osnailyfacter/modular/heat/heat.pp'],1,a819d19dde18b0c246b5d6f6367fa1e6ec69c2fc,fix1465840," amqp_hosts => split($amqp_hosts, ',')"," amqp_hosts => [$amqp_hosts],",1,1
openstack%2Ftempest~master~Icb3404f18c24ff3a0ec1f34fde4f65811dce22a0,openstack/tempest,master,Icb3404f18c24ff3a0ec1f34fde4f65811dce22a0,Merge list_flavors_with_detail to list_flavors,MERGED,2015-06-17 03:14:40.000000000,2015-06-25 06:17:37.000000000,2015-06-25 06:17:35.000000000,"[{'_account_id': 3}, {'_account_id': 1192}, {'_account_id': 6167}, {'_account_id': 7020}, {'_account_id': 8556}, {'_account_id': 8871}, {'_account_id': 10300}, {'_account_id': 10385}, {'_account_id': 16986}]","[{'number': 1, 'created': '2015-06-17 03:14:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/3d09361f6cf8943e049dbac14f1bfd31854a038c', 'message': 'Merge list_flavors_with_detail to list_flavors\n\nThrough consistent-service-method-names dev, list_<resources>_detail\nmethods are merged into list_<resources> method. But I forgot to do\nit on I3fdfa1101b966015798a61aa6ba5acfdf4649831 .\nThis patch does it for consistent methods.\n\nPartially implements blueprint consistent-service-method-names\n\nChange-Id: Icb3404f18c24ff3a0ec1f34fde4f65811dce22a0\n'}, {'number': 2, 'created': '2015-06-17 03:48:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/36170381849db6e240e5373fa9c7b95b0ecd0a2c', 'message': 'Merge list_flavors_with_detail to list_flavors\n\nThrough consistent-service-method-names dev, list_<resources>_detail\nmethods are merged into list_<resources> method. But I forgot to do\nit on I3fdfa1101b966015798a61aa6ba5acfdf4649831 .\nThis patch does it for consistent methods.\n\nPartially implements blueprint consistent-service-method-names\n\nChange-Id: Icb3404f18c24ff3a0ec1f34fde4f65811dce22a0\n'}, {'number': 3, 'created': '2015-06-17 04:57:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/4c32306ce318a310b60adb28ef91c463cc83a52a', 'message': 'Merge list_flavors_with_detail to list_flavors\n\nThrough consistent-service-method-names dev, list_<resources>_detail\nmethods are merged into list_<resources> method. But I forgot to do\nit on I3fdfa1101b966015798a61aa6ba5acfdf4649831 .\nThis patch does it for consistent methods.\n\nPartially implements blueprint consistent-service-method-names\n\nChange-Id: Icb3404f18c24ff3a0ec1f34fde4f65811dce22a0\n'}, {'number': 4, 'created': '2015-06-17 15:42:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/9c9ce0b0485e922c9f43024ae64717a841854d16', 'message': 'Merge list_flavors_with_detail to list_flavors\n\nThrough consistent-service-method-names dev, list_<resources>_detail\nmethods are merged into list_<resources> method. But I forgot to do\nit on I3fdfa1101b966015798a61aa6ba5acfdf4649831 .\nThis patch does it for consistent methods.\n\nPartially implements blueprint consistent-service-method-names\n\nChange-Id: Icb3404f18c24ff3a0ec1f34fde4f65811dce22a0\n'}, {'number': 5, 'created': '2015-06-22 08:44:58.000000000', 'files': ['tempest/api/compute/admin/test_flavors_access.py', 'tempest/services/compute/json/flavors_client.py', 'tempest/api/database/flavors/test_flavors.py', 'tempest/api/compute/flavors/test_flavors.py', 'tempest/api/compute/admin/test_flavors.py'], 'web_link': 'https://opendev.org/openstack/tempest/commit/9150968a8c3b8e59706fe31ebaaa63e2492a6392', 'message': 'Merge list_flavors_with_detail to list_flavors\n\nThrough consistent-service-method-names dev, list_<resources>_detail\nmethods are merged into list_<resources> method. But I forgot to do\nit on I3fdfa1101b966015798a61aa6ba5acfdf4649831 .\nThis patch does it for consistent methods.\n\nPartially implements blueprint consistent-service-method-names\n\nChange-Id: Icb3404f18c24ff3a0ec1f34fde4f65811dce22a0\n'}]",0,192507,9150968a8c3b8e59706fe31ebaaa63e2492a6392,33,9,5,6167,,,0,"Merge list_flavors_with_detail to list_flavors

Through consistent-service-method-names dev, list_<resources>_detail
methods are merged into list_<resources> method. But I forgot to do
it on I3fdfa1101b966015798a61aa6ba5acfdf4649831 .
This patch does it for consistent methods.

Partially implements blueprint consistent-service-method-names

Change-Id: Icb3404f18c24ff3a0ec1f34fde4f65811dce22a0
",git fetch https://review.opendev.org/openstack/tempest refs/changes/07/192507/1 && git format-patch -1 --stdout FETCH_HEAD,"['tempest/api/compute/admin/test_flavors_access.py', 'tempest/services/compute/json/flavors_client.py', 'tempest/api/database/flavors/test_flavors.py', 'tempest/api/compute/admin/test_flavors.py', 'tempest/api/compute/flavors/test_flavors.py']",5,3d09361f6cf8943e049dbac14f1bfd31854a038c,bp/consistent-service-method-names," flavors = self.client.list_flavors(detail=True) flavors = self.client.list_flavors(detail=True, **params) flavors = self.client.list_flavors(detail=True, **params) flavors = self.client.list_flavors(detail=True, **params) flavors = self.client.list_flavors(detail=True, **params)", flavors = self.client.list_flavors_with_detail() flavors = self.client.list_flavors_with_detail(params) flavors = self.client.list_flavors_with_detail(params) flavors = self.client.list_flavors_with_detail(params) flavors = self.client.list_flavors_with_detail(params),22,27
openstack%2Fnetworking-midonet~stable%2Ficehouse~I1482b769d531ad2baf9f77f63636b11040f29c72,openstack/networking-midonet,stable/icehouse,I1482b769d531ad2baf9f77f63636b11040f29c72,Update .gitreview to point to openstack,MERGED,2015-06-25 05:45:10.000000000,2015-06-25 05:57:34.000000000,2015-06-25 05:57:33.000000000,"[{'_account_id': 3}, {'_account_id': 156}]","[{'number': 1, 'created': '2015-06-25 05:45:10.000000000', 'files': ['.gitreview'], 'web_link': 'https://opendev.org/openstack/networking-midonet/commit/89eb41efdecabbe1bda70b0702c151e5b0d37cfd', 'message': 'Update .gitreview to point to openstack\n\nPoint the repository in .gitreview to the correct one.\n\nChange-Id: I1482b769d531ad2baf9f77f63636b11040f29c72\n'}]",0,195417,89eb41efdecabbe1bda70b0702c151e5b0d37cfd,6,2,1,156,,,0,"Update .gitreview to point to openstack

Point the repository in .gitreview to the correct one.

Change-Id: I1482b769d531ad2baf9f77f63636b11040f29c72
",git fetch https://review.opendev.org/openstack/networking-midonet refs/changes/17/195417/1 && git format-patch -1 --stdout FETCH_HEAD,['.gitreview'],1,89eb41efdecabbe1bda70b0702c151e5b0d37cfd,icehouse_to_ost,host=review.openstack.orgproject=openstack/networking-midonet.git,host=review.gerrithub.ioproject=midonet/python-neutron-plugin-midonet.git,2,2
openstack%2Fnetworking-midonet~stable%2Fjuno~I441978ed7e585a3d21a6a474957c2ffc5cc6ff40,openstack/networking-midonet,stable/juno,I441978ed7e585a3d21a6a474957c2ffc5cc6ff40,Update .gitreview from stackforge to openstack,MERGED,2015-06-25 05:31:09.000000000,2015-06-25 05:51:21.000000000,2015-06-25 05:51:21.000000000,"[{'_account_id': 3}, {'_account_id': 156}]","[{'number': 1, 'created': '2015-06-25 05:31:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/networking-midonet/commit/e4c7ad114e298939b4c345c10105b3b496b98d3d', 'message': 'Update .gitreview from openstack to stackforge\n\n.gitreview must be updated to point to the new repository due to the recent\nchange that moved the project from stackforge to openstack.\n\nChange-Id: I441978ed7e585a3d21a6a474957c2ffc5cc6ff40\n'}, {'number': 2, 'created': '2015-06-25 05:41:48.000000000', 'files': ['.gitreview'], 'web_link': 'https://opendev.org/openstack/networking-midonet/commit/33e54f9080676c693f16ac8f33ed430ed463f535', 'message': 'Update .gitreview from stackforge to openstack\n\n.gitreview must be updated to point to the new repository due to the recent\nchange that moved the project from stackforge to openstack.\n\nChange-Id: I441978ed7e585a3d21a6a474957c2ffc5cc6ff40\n'}]",0,195414,33e54f9080676c693f16ac8f33ed430ed463f535,8,2,2,156,,,0,"Update .gitreview from stackforge to openstack

.gitreview must be updated to point to the new repository due to the recent
change that moved the project from stackforge to openstack.

Change-Id: I441978ed7e585a3d21a6a474957c2ffc5cc6ff40
",git fetch https://review.opendev.org/openstack/networking-midonet refs/changes/14/195414/2 && git format-patch -1 --stdout FETCH_HEAD,['.gitreview'],1,e4c7ad114e298939b4c345c10105b3b496b98d3d,(detached,project=openstack/networking-midonet.git,project=stackforge/networking-midonet.git,1,1
openstack%2Ftaskflow~master~I67fcfcb9e721d3293b60f04f7bebac3723b1a3ae,openstack/taskflow,master,I67fcfcb9e721d3293b60f04f7bebac3723b1a3ae,A few jobboard documentation tweaks,MERGED,2015-06-11 04:51:13.000000000,2015-06-25 05:40:49.000000000,2015-06-25 05:40:47.000000000,"[{'_account_id': 3}, {'_account_id': 1297}]","[{'number': 1, 'created': '2015-06-11 04:51:13.000000000', 'files': ['doc/source/jobs.rst'], 'web_link': 'https://opendev.org/openstack/taskflow/commit/2c9e2146bcf88349a54057d3d8bb8a732a0d4883', 'message': 'A few jobboard documentation tweaks\n\nChange-Id: I67fcfcb9e721d3293b60f04f7bebac3723b1a3ae\n'}]",0,190480,2c9e2146bcf88349a54057d3d8bb8a732a0d4883,6,2,1,1297,,,0,"A few jobboard documentation tweaks

Change-Id: I67fcfcb9e721d3293b60f04f7bebac3723b1a3ae
",git fetch https://review.opendev.org/openstack/taskflow refs/changes/80/190480/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/source/jobs.rst'],1,2c9e2146bcf88349a54057d3d8bb8a732a0d4883,," :doc:`atoms <atoms>` and completing their associated :doc:`states <states>` transitions).All jobboards are mere classes that implement same interface, and of course it is possible to import them and create instances of them just like with any other class in Python. But the easier (and recommended) way for creating jobboards is by using the :py:meth:`fetch() <taskflow.jobs.backends.fetch>` function which uses entrypoints (internally using `stevedore`_) to fetch and configure your backend."," :doc:`atoms <atoms>` and completing their associated state transitions).All engines are mere classes that implement same interface, and of course it is possible to import them and create their instances just like with any classes in Python. But the easier (and recommended) way for creating jobboards is by using the :py:meth:`fetch() <taskflow.jobs.backends.fetch>` function which uses entrypoints (internally using `stevedore`_) to fetch and configure your backend",8,6
openstack%2Ftaskflow~master~I5654b5db0db6b8e9884dae5cc285400edce2a698,openstack/taskflow,master,I5654b5db0db6b8e9884dae5cc285400edce2a698,"Executors come in via options config, not keyword arguments",MERGED,2015-05-12 06:01:56.000000000,2015-06-25 05:40:46.000000000,2015-06-25 05:40:43.000000000,"[{'_account_id': 3}, {'_account_id': 1297}]","[{'number': 1, 'created': '2015-05-12 06:01:56.000000000', 'files': ['taskflow/engines/action_engine/engine.py'], 'web_link': 'https://opendev.org/openstack/taskflow/commit/efd6d53aceb7de8723fe077c4a9f05a75f2875d7', 'message': 'Executors come in via options config, not keyword arguments\n\nChange-Id: I5654b5db0db6b8e9884dae5cc285400edce2a698\n'}]",0,182159,efd6d53aceb7de8723fe077c4a9f05a75f2875d7,6,2,1,1297,,,0,"Executors come in via options config, not keyword arguments

Change-Id: I5654b5db0db6b8e9884dae5cc285400edce2a698
",git fetch https://review.opendev.org/openstack/taskflow refs/changes/59/182159/1 && git format-patch -1 --stdout FETCH_HEAD,['taskflow/engines/action_engine/engine.py'],1,efd6d53aceb7de8723fe077c4a9f05a75f2875d7,, Supported option keys:, Supported keyword arguments:,1,1
openstack%2Ftaskflow~master~I8a1960731fd53434bf04d22cc6ff208998adb4f3,openstack/taskflow,master,I8a1960731fd53434bf04d22cc6ff208998adb4f3,Use sphinx deprecated docstring markup,MERGED,2015-06-11 03:13:08.000000000,2015-06-25 05:29:55.000000000,2015-06-25 05:29:53.000000000,"[{'_account_id': 3}, {'_account_id': 1297}]","[{'number': 1, 'created': '2015-06-11 03:13:08.000000000', 'files': ['taskflow/engines/base.py', 'taskflow/engines/helpers.py', 'taskflow/listeners/base.py', 'taskflow/conductors/backends/impl_blocking.py'], 'web_link': 'https://opendev.org/openstack/taskflow/commit/4707bd91b64d9f7cbee89db3fca4aa00a453419c', 'message': 'Use sphinx deprecated docstring markup\n\nAlong with using the `debtcollector` library we\nshould also be marking the docstrings of deprecated\nfunctions/methods/properties with the appropriate\ndeprecated information so that the generated docs also\nshow what is deprecated.\n\nChange-Id: I8a1960731fd53434bf04d22cc6ff208998adb4f3\n'}]",0,190467,4707bd91b64d9f7cbee89db3fca4aa00a453419c,6,2,1,1297,,,0,"Use sphinx deprecated docstring markup

Along with using the `debtcollector` library we
should also be marking the docstrings of deprecated
functions/methods/properties with the appropriate
deprecated information so that the generated docs also
show what is deprecated.

Change-Id: I8a1960731fd53434bf04d22cc6ff208998adb4f3
",git fetch https://review.opendev.org/openstack/taskflow refs/changes/67/190467/1 && git format-patch -1 --stdout FETCH_HEAD,"['taskflow/engines/base.py', 'taskflow/engines/helpers.py', 'taskflow/listeners/base.py', 'taskflow/conductors/backends/impl_blocking.py']",4,4707bd91b64d9f7cbee89db3fca4aa00a453419c,," .. deprecated:: 0.8 The ``timeout`` parameter is **deprecated** and is present for backward compatibility **only**. In order to wait for the conductor to gracefully shut down, :py:meth:`wait` should be used instead."," :param timeout: This parameter is **deprecated** and is present for backward compatibility **only**. In order to wait for the conductor to gracefully shut down, :meth:`wait` should be used instead.",52,5
openstack%2Ftaskflow~master~I74582e645ad883f33b08a460756b84a0a2d25b51,openstack/taskflow,master,I74582e645ad883f33b08a460756b84a0a2d25b51,Handy access to INFO level,MERGED,2015-06-12 16:05:43.000000000,2015-06-25 05:29:21.000000000,2015-06-25 05:29:19.000000000,"[{'_account_id': 3}, {'_account_id': 1297}, {'_account_id': 10584}]","[{'number': 1, 'created': '2015-06-12 16:05:43.000000000', 'files': ['taskflow/logging.py'], 'web_link': 'https://opendev.org/openstack/taskflow/commit/56ca3541236ee71d78d27ff4cefade7d05c21be0', 'message': 'Handy access to INFO level\n\nIt appears that the INFO log level does not have\nitself exposed for handy access, so fix that.\n\nChange-Id: I74582e645ad883f33b08a460756b84a0a2d25b51\n'}]",0,191132,56ca3541236ee71d78d27ff4cefade7d05c21be0,7,3,1,1297,,,0,"Handy access to INFO level

It appears that the INFO log level does not have
itself exposed for handy access, so fix that.

Change-Id: I74582e645ad883f33b08a460756b84a0a2d25b51
",git fetch https://review.opendev.org/openstack/taskflow refs/changes/32/191132/1 && git format-patch -1 --stdout FETCH_HEAD,['taskflow/logging.py'],1,56ca3541236ee71d78d27ff4cefade7d05c21be0,,INFO = logging.INFO,,1,0
openstack%2Fec2-api~master~Ic3157b98e8829cc0220e617eb27b552127eafe20,openstack/ec2-api,master,Ic3157b98e8829cc0220e617eb27b552127eafe20,update from oslo-incubator,MERGED,2015-06-22 11:51:44.000000000,2015-06-25 05:29:05.000000000,2015-06-25 05:29:03.000000000,"[{'_account_id': 3}, {'_account_id': 10224}, {'_account_id': 10234}]","[{'number': 1, 'created': '2015-06-22 11:51:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ec2-api/commit/65c1dcdb0be63372ff598a8b5662205d03999466', 'message': 'update from oslo-incubator\n\nChange-Id: Ic3157b98e8829cc0220e617eb27b552127eafe20\n'}, {'number': 2, 'created': '2015-06-22 12:10:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ec2-api/commit/2b06c0421ef23383188b3ace2a4be05cac246a49', 'message': 'update from oslo-incubator\n\nChange-Id: Ic3157b98e8829cc0220e617eb27b552127eafe20\n'}, {'number': 3, 'created': '2015-06-22 12:35:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ec2-api/commit/12a355a04d7652406521e7c15a78b4fc3fb02248', 'message': 'update from oslo-incubator\n\nChange-Id: Ic3157b98e8829cc0220e617eb27b552127eafe20\n'}, {'number': 4, 'created': '2015-06-23 13:50:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ec2-api/commit/8d9e1fa0fc48b1995201c91a440eb2375baab9ff', 'message': 'update from oslo-incubator\n\nChange-Id: Ic3157b98e8829cc0220e617eb27b552127eafe20\n'}, {'number': 5, 'created': '2015-06-24 18:33:23.000000000', 'files': ['ec2api/openstack/common/eventlet_backdoor.py', 'requirements.txt', 'ec2api/api/__init__.py', 'ec2api/openstack/common/service.py', 'ec2api/openstack/common/fileutils.py', 'openstack-common.conf', 'ec2api/openstack/common/threadgroup.py', 'ec2api/openstack/common/loopingcall.py', 'ec2api/context.py'], 'web_link': 'https://opendev.org/openstack/ec2-api/commit/1e591f5f63d8bee011d4818b840198cc846e3fb9', 'message': 'update from oslo-incubator\n\nChange-Id: Ic3157b98e8829cc0220e617eb27b552127eafe20\n'}]",0,194093,1e591f5f63d8bee011d4818b840198cc846e3fb9,23,3,5,10234,,,0,"update from oslo-incubator

Change-Id: Ic3157b98e8829cc0220e617eb27b552127eafe20
",git fetch https://review.opendev.org/openstack/ec2-api refs/changes/93/194093/4 && git format-patch -1 --stdout FETCH_HEAD,"['ec2api/openstack/common/eventlet_backdoor.py', 'requirements.txt', 'ec2api/api/__init__.py', 'ec2api/openstack/common/service.py', 'ec2api/openstack/common/fileutils.py', 'openstack-common.conf', 'ec2api/openstack/common/threadgroup.py', 'ec2api/openstack/common/loopingcall.py', 'ec2api/context.py']",9,65c1dcdb0be63372ff598a8b5662205d03999466,master-2,"from oslo_context import contextfrom ec2api.i18n import _, _LWclass RequestContext(context.RequestContext): def __init__(self, user_id, project_id, request_id=None, user = kwargs.pop('user', None) tenant = kwargs.pop('tenant', None) super(RequestContext, self).__init__( auth_token=auth_token, user=user_id or user, tenant=project_id or tenant, is_admin=is_admin, request_id=request_id, resource_uuid=kwargs.pop('resource_uuid', None), overwrite=overwrite) # oslo_context's RequestContext.to_dict() generates this field, we can # safely ignore this as we don't use it. kwargs.pop('user_identity', None) if kwargs: LOG.warning(_LW('Arguments dropped when creating context: %s') % str(kwargs)) values = super(RequestContext, self).to_dict() # FIXME(dims): defensive hasattr() checks need to be # removed once we figure out why we are seeing stack # traces values.update({ 'user_id': getattr(self, 'user_id', None), 'project_id': getattr(self, 'project_id', None), 'is_admin': getattr(self, 'is_admin', None), 'roles': getattr(self, 'roles', None), 'remote_address': getattr(self, 'remote_address', None), 'timestamp': timeutils.strtime(self.timestamp) if hasattr( self, 'timestamp') else None, 'request_id': getattr(self, 'request_id', None), 'quota_class': getattr(self, 'quota_class', None), 'user_name': getattr(self, 'user_name', None), 'service_catalog': getattr(self, 'service_catalog', None), 'project_name': getattr(self, 'project_name', None), 'is_os_admin': getattr(self, 'is_os_admin', None), 'api_version': getattr(self, 'api_version', None), }) return values current_context = context.get_current() if (current_context and current_context.is_os_admin): return current_context","from ec2api import exception from ec2api.i18n import _ from ec2api.openstack.common import localclass RequestContext(object): def __init__(self, user_id, project_id, if kwargs: LOG.warn(_('Arguments dropped when creating context: %s') % str(kwargs)) self.cached_secret_key = None self.request_id = generate_request_id() self.auth_token = auth_token if overwrite or not hasattr(local.store, 'context'): self.update_store() def update_store(self): local.store.context = self return {'user_id': self.user_id, 'project_id': self.project_id, 'is_admin': self.is_admin, 'roles': self.roles, 'remote_address': self.remote_address, 'timestamp': timeutils.strtime(self.timestamp), 'request_id': self.request_id, 'auth_token': self.auth_token, 'user_name': self.user_name, 'service_catalog': self.service_catalog, 'project_name': self.project_name, 'tenant': self.tenant, 'user': self.user} values.pop('user', None) values.pop('tenant', None) # NOTE(sirp): the openstack/common version of RequestContext uses # tenant/user whereas the ec2 version uses project_id/user_id. We need # this shim in order to use context-aware code from openstack/common, like # logging, until we make the switch to using openstack/common's version of # RequestContext. @property def tenant(self): return self.project_id @property def user(self): return self.user_id if (getattr(local.store, 'context', None) and local.store.context.is_os_admin): return local.store.context def require_context(ctxt): """"""Raise exception.AuthFailure() if context is not a user or an admin context. """""" if not ctxt.is_admin and not is_user_context(ctxt): raise exception.AuthFailure()",77,88
openstack%2Ftricircle~master~If3ec4713e0a05bbf0a425361f1a4cd4899766eba,openstack/tricircle,master,If3ec4713e0a05bbf0a425361f1a4cd4899766eba,Update project README file,MERGED,2015-06-24 04:17:18.000000000,2015-06-25 05:22:16.000000000,2015-06-25 05:22:16.000000000,"[{'_account_id': 3}, {'_account_id': 11819}, {'_account_id': 12076}, {'_account_id': 16911}]","[{'number': 1, 'created': '2015-06-24 04:17:18.000000000', 'files': ['README.md'], 'web_link': 'https://opendev.org/openstack/tricircle/commit/b7af1ad9c3b2d3f57bf0f67dbbc90b5e3a82a788', 'message': 'Update project README file\n\nChange-Id: If3ec4713e0a05bbf0a425361f1a4cd4899766eba\n'}]",0,194934,b7af1ad9c3b2d3f57bf0f67dbbc90b5e3a82a788,12,4,1,12076,,,0,"Update project README file

Change-Id: If3ec4713e0a05bbf0a425361f1a4cd4899766eba
",git fetch https://review.opendev.org/openstack/tricircle refs/changes/34/194934/1 && git format-patch -1 --stdout FETCH_HEAD,['README.md'],1,b7af1ad9c3b2d3f57bf0f67dbbc90b5e3a82a788,update-readme,"# Tricircle Tricircle is a stackforge project that aims to deal with OpenStack deployment across multiple sites. It provides users a single management view by having only one OpenStack instance on behalf of all the involved ones. It essentially serves as a communication bus between the central OpenStack instance and the other OpenStack instances that are called upon. ## Project Resources - Project status, bugs, and blueprints are tracked on [Launchpad](https://launchpad.net/tricircle) - Additional resources are linked from the project [Wiki](https://wiki.openstack.org/wiki/Tricircle) page","Tricircle =============================== Tricircle is a project for [Openstack cascading solution](https://wiki.openstack.org/wiki/OpenStack_cascading_solution), including the source code of Nova Proxy, Cinder Proxy, Neutron L2/L3 Proxy, Glance sync manager and Ceilometer Proxy(not implemented yet). The project name ""Tricircle"" comes from a fractal. See the blog [""OpenStack cascading and fractal""](https://www.linkedin.com/today/post/article/20140729022031-23841540-openstack-cascading-and-fractal) for more information. Important to know ----------- * Only about 15k code lines developed for OpenStack cascading. * The source code now based on Juno is for PoC only. Refactory will be done constantly to reach OpenStack acceptance standard. * The Neutron cascading using the feature of provider network. But horizon doen't support provider network very well. So you have to use Neutron CLI to create a network. * Support L2 networking(VxLAN) across cascaded OpenStack, but only point2point remote host IP tunneling supported now.L2 networking through L2GW to reduce population traffic and simplify networking topology will be developed in the near future. * The L3 networking across casacaded OpenStack will set up tunneling network for piggy data path, useing GRE tunneling over extra_route to brige the router in different cascaded OpenStack.Therefore, the loca L2 network (VLAN,VxLAN) in one cascaded OpenStack can reach L2 network(VLAN,VxLAN) located in another cascaded OpenStack. * Glance cascading using Glance V2 API. Only CLI/pythonclient support V2 API, the Horizon doesn't support that version. So image management should be done through CLI, and using V2 only. Otherwise, the glance cascading cannot work properly. * Glance cascading is not used by default, eg, useing global Glance by default. If Glance cascading is required, configuration is required. Key modules ----------- * Nova proxy The hypervisor driver for Nova running on Nova-Compute node. Transfer the VM operation to cascaded Nova. Also responsible for attach volume and network to the VM in the cascaded OpenStack. * Cinder proxy The Cinder-Volume driver for Cinder running on Cinder-Volume node.. Transfer the volume operation to cascaded Cinder. * Neuton proxy Including L2 proxy and L3 proxy, Similar role like OVS-Agent/L3-Agent. Finish L2/L3-networking in the cascaded OpenStack, including cross OpenStack networking. * Glance sync Synchronize image among the cascading and policy determined Cascaded OpenStacks Patches required ------------------ * Juno-Patches Pacthes for OpenStack Juno version, including patches for cascading level and cacscaded level. Feature Supported ------------------ * Nova cascading Launch/Reboot/Terminate/Resize/Rescue/Pause/Un-pause/Suspend/Resume/VNC Console/Attach Volume/Detach Volume/Snapshot/KeyPair/Flavor * Cinder cascading Create Volume/Delete Volume/Attach Volume/Detach Volume/Extend Volume/Create Snapshot/Delete Snapshot/List Snapshots/Create Volume from Snapshot/Create Volume from Image/Create Volume from Volume (Clone)/Create Image from Volume * Neutron cascading Network/Subnet/Port/Router. Including L2/L3 networking across cascaded OpenStacks * Glance cascading Only support V2 api. Create Image/Delete Image/List Image/Update Image/Upload Image/Patch Location/VM Snapshot/Image Synchronization Known Issues ------------------ * Launch VM only support ""boot from image"", ""boot from volume"", ""boot from snapshot"" * Flavor only support new created flavor synchronized to the cascaded OpenStack, does not support flavor update synchronization to cascaded OpenStack yet. Installation without Glance cascading ------------ * **Prerequisites** - the minimal installation requires three OpenStack Juno installated to experience across cascaded OpenStacks L2/L3 function. The minimal setup needs four nodes, see the following picture: ![minimal_setup](./minimal_setup.png?raw=true) - the cascading OpenStack needs two node, Node1 and Node 2. Add Node1 to AZ1, Node2 to AZ2 in the cascading OpenStack for both Nova and Cinder. - It's recommended to name the cascading Openstack region to ""Cascading"" or ""Region1"" - Node1 is all-in-one OpenStack installation with KeyStone and Glance, Node1 also function as Nova-Compute/Cinder-Volume/Neutron OVS-Agent/L3-Agent node, and will be replaced to be the proxy node for AZ1. - Node2 is general Nova-Compute node with Cinder-Volume, Neutron OVS-Agent/L3-Agent function installed. And will be replaced to be the proxy node for AZ2 - the all-in-one cascaded OpenStack installed in Node3 function as the AZ1. Node3 will also function as the Nova-Compute/Cinder-Volume/Neutron OVS-Agent/L3-Agent in order to be able to create VMs/Volume/Networking in this AZ1. Glance is only required to be installed if Glance cascading needed. Add Node3 to AZ1 in the cascaded OpenStack both for Nova and Cinder. It's recommended to name the cascaded Openstack region for Node3 to ""AZ1"" - the all-in-one cascaded OpenStack installed in Node4 function as the AZ2. Node3 will also function as the Nova-Compute/Cinder-Volume/Neutron OVS-Agent/L3-Agent in order to be able to create VMs/Volume/Networking in this AZ2. Glance is only required to be installed if Glance cascading needed.Add Node4 to AZ2 in the cascaded OpenStack both for Nova and Cinder.It's recommended to name the cascaded Openstack region for Node4 to ""AZ2"" Make sure the time of these four nodes are synchronized. Because the Nova Proxy/Cinder Proxy/Neutron L2/L3 Proxy will query the cascaded OpenStack using timestamp, incorrect time will lead to VM/Volume/Port status synchronization not work properly. Register all services endpoint in the global shared KeyStone. Make sure the 3 OpenStack can work independently before cascading introduced, eg. you can boot VM with network, create volume and attach volume in each OpenStack. After verify that 3 OpenStack can work independently, clean all created resources VM/Volume/Network. After all OpenStack installation is ready, it's time to install Juno pathces both for cascading OpenStack and cascaded OpenStack, and then replace the Nova-Compute/Cinder-Volume/Neutron OVS-Agent/L3-Agent to Nova Proxy / Cinder Proxy / Neutron l2/l3 Proxy. * **Juno pachtes installation step by step** 1. Node1 - Patches for Neutron - neutron_cascading_l3_patch This patch is to enable cross cascaded OpenStack L3 routing over extra route.The mapping between cascaded OpenStack and it's onlink external network which is used for GRE tunneling data path Navigate to the folder ``` cd ./tricircle/juno-patches/neutron/neutron_cascading_l3_patch ``` follow README.md instruction to install the patch 2. Node3 - Patches for Cinder - timestamp-query-patch This patch is to make the cascaded Cinder being able to execute query with timestamp filter, but not to return all objects. Navigate to the folder ``` cd ./tricircle/juno-patches/cinder/timestamp-query-patch ``` follow README.md instruction to install the patch - Patches for Neutron - neutron_timestamp_cascaded_patch This patch is to make Neutron being able to provide timestamp based port query. Navigate to the folder ``` cd ./tricircle/juno-patches/neutron/neutron_timestamp_cascaded_patch ``` follow README.md instruction to install the patch - Patches for Neutron - neutron_cascaded_l3_patch This patch is to enable cross cascaded OpenStack L3 routing over extra route.. Navigate to the folder ``` cd ./tricircle/juno-patches/neutron/neutron_cascaded_l3_patch ``` follow README.md instruction to install the patch 3. Node4 - Patches for Cinder - timestamp-query-patch This patch is to make the cascaded Cinder being able to execute query with timestamp filter, but not to return all objects. Navigate to the folder ``` cd ./tricircle/juno-patches/cinder/timestamp-query-patch ``` follow README.md instruction to install the patch - Patches for Neutron - neutron_timestamp_cascaded_patch This patch is to make Neutron being able to provide timestamp based port query. Navigate to the folder ``` cd ./tricircle/juno-patches/neutron/neutron_timestamp_cascaded_patch ``` follow README.md instruction to install the patch - Patches for Neutron - neutron_cascaded_l3_patch This patch is to enable cross cascaded OpenStack L3 routing over extra route.. Navigate to the folder ``` cd ./tricircle/juno-patches/neutron/neutron_cascaded_l3_patch ``` follow README.md instruction to install the patch * **Proxy installation step by step** 1. Node1 - Nova proxy Navigate to the folder ``` cd ./tricircle/novaproxy ``` follow README.md instruction to install the proxy. Please change the configuration value in the install.sh according to your environment setting - Cinder proxy Navigate to the folder ``` cd ./tricircle/cinderproxy ``` follow README.md instruction to install the proxy. Please change the configuration value in the install.sh according to your environment setting - L2 proxy Navigate to the folder ``` cd ./tricircle/neutronproxy/l2-proxy ``` follow README.md instruction to install the proxy. Please change the configuration value in the install.sh according to your environment setting - L3 proxy Navigate to the folder ``` cd ./tricircle/neutronproxy/l3-proxy ``` follow README.md instruction to install the proxy. Please change the configuration value in the install.sh according to your environment setting 2. Node2 - Nova proxy Navigate to the folder ``` cd ./tricircle/novaproxy ``` follow README.md instruction to install the proxy. Please change the configuration value in the install.sh according to your environment setting - Cinder proxy Navigate to the folder ``` cd ./tricircle/cinderproxy ``` follow README.md instruction to install the proxy. Please change the configuration value in the install.sh according to your environment setting - L2 proxy Navigate to the folder ``` cd ./tricircle/neutronproxy/l2-proxy ``` follow README.md instruction to install the proxy. Please change the configuration value in the install.sh according to your environment setting - L3 proxy Navigate to the folder ``` cd ./tricircle/neutronproxy/l3-proxy ``` follow README.md instruction to install the proxy. Please change the configuration value in the install.sh according to your environment setting Upgrade to Glance cascading ------------ * **Prerequisites** - To experience the glance cascading feature, you can simply upgrade the current installation with several step, see the following picture: ![minimal_setup_with_glance_cascading](./minimal_setup_with_glance_cascading.png?raw=true) 1. Node1 - Patches for Glance - glance_location_patch This patch is to make the glance being able to handle http url location. The patch also insert the sync manager to the chain of responsibility. Navigate to the folder ``` cd ./tricircle/juno-patches/glance/glance_location_patch ``` follow README.md instruction to install the patch - Patches for Glance - glance_store_patch This patch is to make the glance being able to handle http url location. Navigate to the folder ``` cd ./tricircle/juno-patches/glance_store/glance_store_patch ``` follow README.md instruction to install the patch - Sync Manager Navigate to the folder ``` cd ./tricircle/glancesync ``` modify the storage scheme configuration for cascading and cascaded level ``` vi ./tricircle/glancesync/etc/glance/glance_store.yaml ``` follow README.md instruction to install the sync manager. Please change the configuration value in the install.sh according to your environment setting, espeically for configuration: sync_enabled=True sync_server_port=9595 sync_server_host=127.0.0.1 2. Node3 - Glance Installation Please install Glance in the Node3 as the casacded Glance. Register the service endpoint in the KeyStone. Change the glance endpoint in nova.conf and cinder.conf to the Glance located in Node3 3. Node4 - Glance Installation Please install Glance in the Node4 as the casacded Glance. Register the service endpoint in the KeyStone Change the glance endpoint in nova.conf and cinder.conf to the Glance located in Node4 4. Configuration - Change Nova proxy configuration on Node1, setting the ""cascaded_glance_flag"" to True and add ""cascaded_glance_url"" of Node3 configurantion according to Nova-proxy README.MD instruction - Change Cinder proxy configuration on Node1, setting the ""glance_cascading_flag"" to True and add ""cascaded_glance_url"" of Node3 configurantion according to Nova-proxy README.MD instruction - Change Nova proxy configuration on Node2, setting the ""cascaded_glance_flag"" to True and add ""cascaded_glance_url"" of Node4 configurantion according to Nova-proxy README.MD instruction - Change Cinder proxy configuration on Node2, setting the ""glance_cascading_flag"" to True and add ""cascaded_glance_url"" of Node4 configurantion according to Nova-proxy README.MD instruction 5. Experience Glance cascading - Restart all related service - Use Glance V2 api to create Image, Upload Image or patch location for Image. Image should be able to sync to distributed Glance if sync_enabled is setting to True - Sync image only during first time usage but not uploading or patch location is still in testing phase, may not work properly. - Create VM/Volume/etc from Horizon",5,306
openstack%2Fglance~master~I84c754e51fb40ef1f9744bf85dbaa716b55cbb95,openstack/glance,master,I84c754e51fb40ef1f9744bf85dbaa716b55cbb95,Change generic NotFound to ImageNotFound exception,MERGED,2015-05-29 03:56:20.000000000,2015-06-25 05:20:14.000000000,2015-06-25 05:20:12.000000000,"[{'_account_id': 3}, {'_account_id': 2537}, {'_account_id': 6159}, {'_account_id': 6484}, {'_account_id': 7575}, {'_account_id': 9303}, {'_account_id': 11356}, {'_account_id': 12000}, {'_account_id': 13161}]","[{'number': 1, 'created': '2015-05-29 03:56:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/a9983abce7d8d38353ca0c8bcaa942176e09e646', 'message': 'Change generic NotFound exception to ImageNotFound exception\nWhen an image can not be found an ImageNotFound exception\nwill be raised instead of a generic NotFound exception.\nDoes not apply to Image Metadata, Image Members, Image Tags, Image Tasks\nCloses-Bug #1247633\n\nChange-Id: I84c754e51fb40ef1f9744bf85dbaa716b55cbb95\n'}, {'number': 2, 'created': '2015-05-29 13:21:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/4a32753e3856c99b0adf82ebde3ef81aff17bd6e', 'message': 'Change generic NotFound exception to ImageNotFound exception\nWhen an image can not be found an ImageNotFound exception\nwill be raised instead of a generic NotFound exception.\nDoes not apply to Image Metadata, Image Members, Image Tags, Image Tasks\nCloses-Bug #1247633\n\nChange-Id: I84c754e51fb40ef1f9744bf85dbaa716b55cbb95\n'}, {'number': 3, 'created': '2015-05-29 17:31:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/8933e612f9c837af73d8006bd1ce944eba95b075', 'message': 'Change generic NotFound exception to\nImageNotFound exception. When an image\ncan not be found an ImageNotFound exception\nwill be raised instead of a generic NotFound\nexception.  Does not apply to Image Metadata,\nImage Members, Image Tags, Image Tasks\n\nCloses-Bug #1247633\n\nChange-Id: I84c754e51fb40ef1f9744bf85dbaa716b55cbb95\n'}, {'number': 4, 'created': '2015-05-29 18:12:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/963104550bb800907b3c2dc041865b9cece2fdab', 'message': 'Change generic NotFound exception to\nImageNotFound exception. When an image\ncan not be found an ImageNotFound exception\nwill be raised instead of a generic NotFound\nexception.  Does not apply to Image Metadata,\nImage Members, Image Tags, Image Tasks\n\nCloses-Bug #1247633\n\nChange-Id: I84c754e51fb40ef1f9744bf85dbaa716b55cbb95\n'}, {'number': 5, 'created': '2015-05-29 18:14:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/e16823b8d51fe9bf4956f8009aac078aa7759f1b', 'message': 'Change generic NotFound to ImageNotFound exception\n\nWhen an image can not be found an ImageNotFound exception\nwill be raised instead of a generic NotFound\nexception.  Does not apply to Image Metadata,\nImage Members, Image Tags, Image Tasks\n\nCloses-Bug #1247633\n\nChange-Id: I84c754e51fb40ef1f9744bf85dbaa716b55cbb95\n'}, {'number': 6, 'created': '2015-05-30 02:16:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/7254adf0ee72e2d85a2875bc554b4acbc43777e1', 'message': 'Change generic NotFound to ImageNotFound exception\n\nWhen an image can not be found an ImageNotFound exception\nwill be raised instead of a generic NotFound\nexception.  Does not apply to Image Metadata,\nImage Members, Image Tags, Image Tasks\n\nCloses-Bug #1247633\n\nChange-Id: I84c754e51fb40ef1f9744bf85dbaa716b55cbb95\n'}, {'number': 7, 'created': '2015-05-30 15:18:42.000000000', 'files': ['glance/api/v2/image_data.py', 'glance/api/middleware/cache.py', 'glance/registry/api/v1/images.py', 'glance/common/exception.py', 'glance/db/simple/api.py', 'glance/tests/unit/test_cache_middleware.py', 'glance/tests/unit/v1/test_upload_utils.py', 'glance/db/__init__.py', 'glance/api/v1/upload_utils.py', 'glance/db/sqlalchemy/api.py', 'glance/tests/unit/v2/test_image_data_resource.py', 'glance/tests/unit/v2/test_registry_api.py', 'glance/tests/unit/test_db.py', 'glance/api/v1/images.py', 'glance/db/registry/api.py'], 'web_link': 'https://opendev.org/openstack/glance/commit/8a7086b9bfdc4da98f470fe6edd4fb1a6605ee1a', 'message': 'Change generic NotFound to ImageNotFound exception\n\nWhen an image can not be found an ImageNotFound exception\nwill be raised instead of a generic NotFound\nexception.  Does not apply to Image Metadata,\nImage Members, Image Tags, Image Tasks\n\nCloses-Bug #1247633\n\nChange-Id: I84c754e51fb40ef1f9744bf85dbaa716b55cbb95\n'}]",6,186646,8a7086b9bfdc4da98f470fe6edd4fb1a6605ee1a,26,9,7,16395,,,0,"Change generic NotFound to ImageNotFound exception

When an image can not be found an ImageNotFound exception
will be raised instead of a generic NotFound
exception.  Does not apply to Image Metadata,
Image Members, Image Tags, Image Tasks

Closes-Bug #1247633

Change-Id: I84c754e51fb40ef1f9744bf85dbaa716b55cbb95
",git fetch https://review.opendev.org/openstack/glance refs/changes/46/186646/2 && git format-patch -1 --stdout FETCH_HEAD,"['glance/api/v2/image_data.py', 'glance/api/middleware/cache.py', 'glance/registry/api/v1/images.py', 'glance/common/exception.py', 'glance/db/simple/api.py', 'glance/tests/unit/test_cache_middleware.py', 'glance/tests/unit/v1/test_upload_utils.py', 'glance/db/__init__.py', 'glance/api/v1/upload_utils.py', 'glance/db/sqlalchemy/api.py', 'glance/tests/unit/v2/test_image_data_resource.py', 'glance/tests/unit/v2/test_registry_api.py', 'glance/tests/unit/test_db.py', 'glance/api/v1/images.py', 'glance/db/registry/api.py']",15,a9983abce7d8d38353ca0c8bcaa942176e09e646,bug/1247633, :raises ImageNotFound if image does not exist., :raises NotFound if image does not exist.,36,34
openstack%2Fec2-api~master~Ibeeea1f5d92cc0aa08ac6c360c3e73fa67a45373,openstack/ec2-api,master,Ibeeea1f5d92cc0aa08ac6c360c3e73fa67a45373,Fix 0.0.0.0/0 route management,MERGED,2015-06-16 14:04:10.000000000,2015-06-25 05:15:25.000000000,2015-06-25 05:15:23.000000000,"[{'_account_id': 3}, {'_account_id': 9312}, {'_account_id': 10224}, {'_account_id': 10234}]","[{'number': 1, 'created': '2015-06-16 14:04:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ec2-api/commit/6e0773cff842b0e6b70e4dd4f2f8b362ec45eaa2', 'message': 'Fix gateway routes management\n\nChange-Id: Ibeeea1f5d92cc0aa08ac6c360c3e73fa67a45373\n'}, {'number': 2, 'created': '2015-06-16 14:55:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ec2-api/commit/7d7ee320b4fb7fda05f4a0e260740c6428980a49', 'message': ""Fix 0.0.0.0/0 route management\n\nIf subnet['gateway_ip'] is not None, Neutron prevents manual setting of\n0.0.0.0/0 route to host route table.\n\nSo we set gateway_ip to None during subnet creation. As a result Neutron\ndoesn't add its own 0.0.0.0/0 route, and we don't need to redirect it to\n172.0.0.1 if default route is not set for a subnet route table. It\nsimplifies mapping of VPC route table to Neutron subnet host routes.\n\nChange-Id: Ibeeea1f5d92cc0aa08ac6c360c3e73fa67a45373\n""}, {'number': 3, 'created': '2015-06-19 13:14:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ec2-api/commit/4c81515c8bdfc1f09ba4d9ccebdd90ab0e116955', 'message': ""Fix 0.0.0.0/0 route management\n\nIf subnet['gateway_ip'] is not None, Neutron prevents manual setting of\n0.0.0.0/0 route to host route table.\n\nSo we set gateway_ip to None during subnet creation if not internet\ngateway is used in an associated route table. As a result Neutron\ndoesn't add its own 0.0.0.0/0 route, and we don't need to redirect it to\n172.0.0.1 if default route is not set for a subnet route table. It\nsimplifies mapping of VPC route table to Neutron subnet host routes.\n\nChange-Id: Ibeeea1f5d92cc0aa08ac6c360c3e73fa67a45373\n""}, {'number': 4, 'created': '2015-06-22 09:25:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ec2-api/commit/7461fafbcdecfdd4e32ec35f1588f0413de10a1c', 'message': ""Fix 0.0.0.0/0 route management\n\nIf subnet['gateway_ip'] is not None, Neutron prevents manual setting of\n0.0.0.0/0 route to host route table.\n\nSo we set gateway_ip to None during subnet creation if not internet\ngateway is used in an associated route table. As a result Neutron\ndoesn't add its own 0.0.0.0/0 route, and we don't need to redirect it to\n172.0.0.1 if default route is not set for a subnet route table. It\nsimplifies mapping of VPC route table to Neutron subnet host routes.\n\nChange-Id: Ibeeea1f5d92cc0aa08ac6c360c3e73fa67a45373\n""}, {'number': 5, 'created': '2015-06-22 13:41:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ec2-api/commit/3466b8fb30f7b1eb0a99e7b5bcdb46c11be59d64', 'message': ""Fix 0.0.0.0/0 route management\n\nIf subnet['gateway_ip'] is not None, Neutron prevents manual setting of\n0.0.0.0/0 route to host route table.\n\nSo we set gateway_ip to None during subnet creation if not internet\ngateway is used in an associated route table. As a result Neutron\ndoesn't add its own 0.0.0.0/0 route, and we don't need to redirect it to\n172.0.0.1 if default route is not set for a subnet route table. It\nsimplifies mapping of VPC route table to Neutron subnet host routes.\n\nChange-Id: Ibeeea1f5d92cc0aa08ac6c360c3e73fa67a45373\n""}, {'number': 6, 'created': '2015-06-23 19:22:05.000000000', 'files': ['ec2api/tests/unit/test_subnet.py', 'ec2api/api/subnet.py', 'ec2api/tests/unit/fakes.py', 'ec2api/api/route_table.py', 'ec2api/tests/functional/api/test_addresses.py', 'ec2api/tests/functional/scenario/test_instances_in_vpc.py', 'ec2api/tests/unit/test_route_table.py'], 'web_link': 'https://opendev.org/openstack/ec2-api/commit/8ded70ab89392ce7a19a4fd1122efcf9059eead5', 'message': ""Fix 0.0.0.0/0 route management\n\nIf subnet['gateway_ip'] is not None, Neutron prevents manual setting of\n0.0.0.0/0 route to subnet host routes.\n\nSo we set gateway_ip to None during subnet creation if not internet\ngateway is used in an associated route table. As a result Neutron\ndoesn't add its own 0.0.0.0/0 route, and we don't need to redirect it to\n127.0.0.1 if default route is not set for a subnet route table. It\nsimplifies mapping of VPC route table to Neutron subnet host routes.\n\nDepends-On: I5c314d513922d8a21b3e63de632bb9cd3484b076\nChange-Id: Ibeeea1f5d92cc0aa08ac6c360c3e73fa67a45373\n""}]",0,192211,8ded70ab89392ce7a19a4fd1122efcf9059eead5,29,4,6,10224,,,0,"Fix 0.0.0.0/0 route management

If subnet['gateway_ip'] is not None, Neutron prevents manual setting of
0.0.0.0/0 route to subnet host routes.

So we set gateway_ip to None during subnet creation if not internet
gateway is used in an associated route table. As a result Neutron
doesn't add its own 0.0.0.0/0 route, and we don't need to redirect it to
127.0.0.1 if default route is not set for a subnet route table. It
simplifies mapping of VPC route table to Neutron subnet host routes.

Depends-On: I5c314d513922d8a21b3e63de632bb9cd3484b076
Change-Id: Ibeeea1f5d92cc0aa08ac6c360c3e73fa67a45373
",git fetch https://review.opendev.org/openstack/ec2-api refs/changes/11/192211/2 && git format-patch -1 --stdout FETCH_HEAD,"['ec2api/tests/unit/test_subnet.py', 'ec2api/api/subnet.py']",2,6e0773cff842b0e6b70e4dd4f2f8b362ec45eaa2,," # NOTE(ft): We need subnet['gateway_ip'] == None for gateway-like # host routes to be set correctly. But to prevent manually creation # of a port to attach subnet to vpc router, we use default # gateway_ip and set it to None at the end of vpc subnet creation. {'subnet': {'name': subnet['id'], 'gateway_ip': None}})", {'subnet': {'name': subnet['id']}}),8,2
openstack%2Fec2-api~master~If49390fbd27db51e396693c7d2970a3aab3f7970,openstack/ec2-api,master,If49390fbd27db51e396693c7d2970a3aab3f7970,Fix create/delete vpn connection route,MERGED,2015-06-23 13:57:49.000000000,2015-06-25 05:14:20.000000000,2015-06-25 05:14:18.000000000,"[{'_account_id': 3}, {'_account_id': 9312}, {'_account_id': 10234}]","[{'number': 1, 'created': '2015-06-23 13:57:49.000000000', 'files': ['ec2api/tests/unit/test_vpn_connection.py', 'ec2api/api/vpn_connection.py'], 'web_link': 'https://opendev.org/openstack/ec2-api/commit/6cb604f5b2ae640acad8380259ad4d480959b26e', 'message': 'Fix create/delete vpn connection route\n\nDepends-On: I75e1bbcd81678a56a0940b696cfa5dbc2c159cc6\nChange-Id: If49390fbd27db51e396693c7d2970a3aab3f7970\n'}]",0,194668,6cb604f5b2ae640acad8380259ad4d480959b26e,6,3,1,10224,,,0,"Fix create/delete vpn connection route

Depends-On: I75e1bbcd81678a56a0940b696cfa5dbc2c159cc6
Change-Id: If49390fbd27db51e396693c7d2970a3aab3f7970
",git fetch https://review.opendev.org/openstack/ec2-api refs/changes/68/194668/1 && git format-patch -1 --stdout FETCH_HEAD,"['ec2api/tests/unit/test_vpn_connection.py', 'ec2api/api/vpn_connection.py']",2,6cb604f5b2ae640acad8380259ad4d480959b26e,vpn," vpn_gateway = db_api.get_item_by_id(context, vpn_connection['vpn_gateway_id']) vpn_gateway, vpn_connections=[vpn_connection]) vpn_gateway = db_api.get_item_by_id(context, vpn_connection['vpn_gateway_id']) vpn_gateway, vpn_connections=[vpn_connection])"," vpn_gateway = db_api.get_item_by_id(context, vpn_connection_id) vpn_gateway, [vpn_connection]) vpn_gateway = db_api.get_item_by_id(context, vpn_connection_id) vpn_gateway, [vpn_connection])",18,6
openstack%2Fec2-api~master~I5c314d513922d8a21b3e63de632bb9cd3484b076,openstack/ec2-api,master,I5c314d513922d8a21b3e63de632bb9cd3484b076,Add a test scenario for establish of vpn connection,MERGED,2015-06-23 12:07:56.000000000,2015-06-25 05:14:06.000000000,2015-06-25 05:14:04.000000000,"[{'_account_id': 3}, {'_account_id': 9312}, {'_account_id': 10224}, {'_account_id': 10234}]","[{'number': 1, 'created': '2015-06-23 12:07:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ec2-api/commit/4637e8d2324dc5699105a9912c52595f3fd3e1ef', 'message': 'Add a test scenario for establish of vpn connection\n\nChange-Id: I5c314d513922d8a21b3e63de632bb9cd3484b076\n'}, {'number': 2, 'created': '2015-06-23 13:28:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ec2-api/commit/24d25207769aedb2582f0d19cc1efebbd39673f4', 'message': 'Add a test scenario for establish of vpn connection\n\nChange-Id: I5c314d513922d8a21b3e63de632bb9cd3484b076\n'}, {'number': 3, 'created': '2015-06-23 13:39:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ec2-api/commit/a56776254b10553bdde64b56165216e3a3fe3172', 'message': 'Add a test scenario for establish of vpn connection\n\nChange-Id: I5c314d513922d8a21b3e63de632bb9cd3484b076\n'}, {'number': 4, 'created': '2015-06-23 13:42:29.000000000', 'files': ['ec2api/tests/functional/scenario/test_vpn_routing.py'], 'web_link': 'https://opendev.org/openstack/ec2-api/commit/79e3931d1a89fc1423e098b108a78302349c3f04', 'message': 'Add a test scenario for establish of vpn connection\n\nChange-Id: I5c314d513922d8a21b3e63de632bb9cd3484b076\n'}]",0,194618,79e3931d1a89fc1423e098b108a78302349c3f04,22,4,4,10224,,,0,"Add a test scenario for establish of vpn connection

Change-Id: I5c314d513922d8a21b3e63de632bb9cd3484b076
",git fetch https://review.opendev.org/openstack/ec2-api refs/changes/18/194618/4 && git format-patch -1 --stdout FETCH_HEAD,['ec2api/tests/functional/scenario/test_vpn_routing.py'],1,4637e8d2324dc5699105a9912c52595f3fd3e1ef,vpn,"# Copyright 2014 OpenStack Foundation # All Rights Reserved. # # Licensed under the Apache License, Version 2.0 (the ""License""); you may # not use this file except in compliance with the License. You may obtain # a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT # WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the # License for the specific language governing permissions and limitations # under the License. from ec2api.tests.functional import base from ec2api.tests.functional import config CONF = config.CONF class VpnRoutingTest(base.EC2TestCase): VPC_CIDR = '10.4.0.0/20' CUSTOMER_GATEWAY_IP = '198.51.100.77' CUSTOMER_VPN_CIDR = '172.16.25.0/24' @classmethod @base.safe_setup def setUpClass(cls): super(VpnRoutingTest, cls).setUpClass() if not base.TesterStateHolder().get_vpc_enabled(): raise cls.skipException('VPC is disabled') def test_vpn_routing(self): vpc_id, _subnet_id = self.create_vpc_and_subnet(self.VPC_CIDR) data = self.client.create_customer_gateway( Type='ipsec.1', PublicIp=self.CUSTOMER_GATEWAY_IP, BgpAsn=65000) cgw_id = data['CustomerGateway']['CustomerGatewayId'] self.addResourceCleanUpStatic( self.client.delete_customer_gateway, CustomerGatewayId=cgw_id) data = self.client.create_vpn_gateway(Type='ipsec.1') vgw_id = data['VpnGateway']['VpnGatewayId'] self.addResourceCleanUpStatic( self.client.delete_vpn_gateway, VpnGatewayId=vgw_id) data = self.client.create_vpn_connection( CustomerGatewayId=cgw_id, VpnGatewayId=vgw_id, Options={'StaticRoutesOnly': True}, Type='ipsec.1') vpn_id = data['VpnConnection']['VpnConnectionId'] self.addResourceCleanUp(self.client.delete_vpn_connection, VpnConnectionId=vpn_id) data = self.client.attach_vpn_gateway(VpnGatewayId=vgw_id, VpcId=vpc_id) self.addResourceCleanUp(self.client.detach_vpn_gateway, VpnGatewayId=vgw_id, VpcId=vpc_id) vpn_waiter = self.get_vpn_connection_waiter() vpn_waiter.wait_available(vpn_id) attach_waiter = self.get_vpn_gateway_attachment_waiter() attach_waiter.wait_available(vgw_id, 'attached') data = self.client.describe_route_tables( Filters=[{'Name': 'vpc-id', 'Values': [vpc_id]}]) rtb_id = data['RouteTables'][0]['RouteTableId'] data = self.client.enable_vgw_route_propagation(RouteTableId=rtb_id, GatewayId=vgw_id) data = self.client.create_vpn_connection_route( VpnConnectionId=vpn_id, DestinationCidrBlock=self.CUSTOMER_VPN_CIDR) route_waiter = self.get_vpn_connection_route_waiter( self.CUSTOMER_VPN_CIDR) route_waiter.wait_available(vpn_id) data = self.client.describe_route_tables(RouteTableIds=[rtb_id]) route = next((r for r in data['RouteTables'][0]['Routes'] if r['DestinationCidrBlock'] == self.CUSTOMER_VPN_CIDR), None) self.assertIsNotNone(route) self.assertEqual('active', route['State']) self.assertEqual('EnableVgwRoutePropagation', route['Origin']) ",,86,0
openstack%2Fec2-api~master~I315e6a572e744eb989d600be0d307caa2ff74dca,openstack/ec2-api,master,I315e6a572e744eb989d600be0d307caa2ff74dca,Add basic functional tests for vpn connection,MERGED,2015-06-23 12:07:56.000000000,2015-06-25 05:12:51.000000000,2015-06-25 05:12:50.000000000,"[{'_account_id': 3}, {'_account_id': 9312}, {'_account_id': 10224}, {'_account_id': 10234}]","[{'number': 1, 'created': '2015-06-23 12:07:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ec2-api/commit/0327dd3b17155402899967b02861e4d7c1c0745b', 'message': 'Add basic functional tests for vpn connection\n\nChange-Id: I315e6a572e744eb989d600be0d307caa2ff74dca\n'}, {'number': 2, 'created': '2015-06-23 13:28:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ec2-api/commit/2390ff417ca481f350d3ab95d0353981cb68254b', 'message': 'Add basic functional tests for vpn connection\n\nChange-Id: I315e6a572e744eb989d600be0d307caa2ff74dca\n'}, {'number': 3, 'created': '2015-06-23 13:39:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ec2-api/commit/de3f57f0ef6c633249f69f052658469dfca02fbe', 'message': 'Add basic functional tests for vpn connection\n\nChange-Id: I315e6a572e744eb989d600be0d307caa2ff74dca\n'}, {'number': 4, 'created': '2015-06-23 13:42:29.000000000', 'files': ['ec2api/tests/functional/base.py', 'ec2api/tests/functional/api/test_vpn_connections.py'], 'web_link': 'https://opendev.org/openstack/ec2-api/commit/2ef5386c32fe6d96d225e66b9f55afb583e82326', 'message': 'Add basic functional tests for vpn connection\n\nChange-Id: I315e6a572e744eb989d600be0d307caa2ff74dca\n'}]",0,194617,2ef5386c32fe6d96d225e66b9f55afb583e82326,12,4,4,10224,,,0,"Add basic functional tests for vpn connection

Change-Id: I315e6a572e744eb989d600be0d307caa2ff74dca
",git fetch https://review.opendev.org/openstack/ec2-api refs/changes/17/194617/4 && git format-patch -1 --stdout FETCH_HEAD,"['ec2api/tests/functional/base.py', 'ec2api/tests/functional/api/test_vpn_connections.py']",2,0327dd3b17155402899967b02861e4d7c1c0745b,vpn,"# Copyright 2014 OpenStack Foundation # All Rights Reserved. # # Licensed under the Apache License, Version 2.0 (the ""License""); you may # not use this file except in compliance with the License. You may obtain # a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT # WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the # License for the specific language governing permissions and limitations # under the License. import botocore.exceptions from lxml import etree from ec2api.tests.functional import base from ec2api.tests.functional import config CONF = config.CONF class VpnConnectionTest(base.EC2TestCase): CUSTOMER_GATEWAY_IP = '198.51.100.77' CUSTOMER_VPN_CIDR = '172.16.25.0/24' cgw_id = None vgw_id = None @classmethod @base.safe_setup def setUpClass(cls): super(VpnConnectionTest, cls).setUpClass() if not base.TesterStateHolder().get_vpc_enabled(): raise cls.skipException('VPC is disabled') data = cls.client.create_customer_gateway( Type='ipsec.1', PublicIp=cls.CUSTOMER_GATEWAY_IP, BgpAsn=65000) cls.cgw_id = data['CustomerGateway']['CustomerGatewayId'] cls.addResourceCleanUpStatic( cls.client.delete_customer_gateway, CustomerGatewayId=cls.cgw_id) data = cls.client.create_vpn_gateway(Type='ipsec.1') cls.vgw_id = data['VpnGateway']['VpnGatewayId'] cls.addResourceCleanUpStatic( cls.client.delete_vpn_gateway, VpnGatewayId=cls.vgw_id) def test_create_delete_vpn_connection(self): data = self.client.create_vpn_connection( CustomerGatewayId=self.cgw_id, VpnGatewayId=self.vgw_id, Options={'StaticRoutesOnly': True}, Type='ipsec.1') vpn_id = data['VpnConnection']['VpnConnectionId'] vpn_clean = self.addResourceCleanUp( self.client.delete_vpn_connection, VpnConnectionId=vpn_id) vpn_config = etree.fromstring( data['VpnConnection']['CustomerGatewayConfiguration']) psks = vpn_config.xpath( '/vpn_connection/ipsec_tunnel/ike/pre_shared_key') self.assertNotEmpty(psks) self.assertTrue(psks[0].text) vpn_waiter = self.get_vpn_connection_waiter() vpn_waiter.wait_available(vpn_id) self.client.delete_vpn_connection(VpnConnectionId=vpn_id) self.cancelResourceCleanUp(vpn_clean) vpn_waiter.wait_delete(vpn_id) try: data = self.client.describe_vpn_connections( VpnConnectionIds=[vpn_id]) self.assertEqual(1, len(data['VpnConnections'])) self.assertEqual('deleted', data['VpnConnections'][0]['State']) except botocore.exceptions.ClientError as ex: self.assertEqual('InvalidVpnConnectionID.NotFound', ex.response['Error']['Code']) def test_create_delete_vpn_connection_route(self): data = self.client.create_vpn_connection( CustomerGatewayId=self.cgw_id, VpnGatewayId=self.vgw_id, Options={'StaticRoutesOnly': True}, Type='ipsec.1') vpn_id = data['VpnConnection']['VpnConnectionId'] self.addResourceCleanUp( self.client.delete_vpn_connection, VpnConnectionId=vpn_id) vpn_waiter = self.get_vpn_connection_waiter() vpn_waiter.wait_available(vpn_id) data = self.client.create_vpn_connection_route( VpnConnectionId=vpn_id, DestinationCidrBlock=self.CUSTOMER_VPN_CIDR) data = self.client.describe_vpn_connections(VpnConnectionIds=[vpn_id]) self.assertEqual(1, len(data['VpnConnections'][0]['Routes'])) self.assertEqual( self.CUSTOMER_VPN_CIDR, data['VpnConnections'][0]['Routes'][0]['DestinationCidrBlock']) route_waiter = self.get_vpn_connection_route_waiter( self.CUSTOMER_VPN_CIDR) route_waiter.wait_available(vpn_id) data = self.client.delete_vpn_connection_route( VpnConnectionId=vpn_id, DestinationCidrBlock=self.CUSTOMER_VPN_CIDR) data = self.client.describe_vpn_connections(VpnConnectionIds=[vpn_id]) route_waiter.wait_delete(vpn_id) ",,156,0
openstack%2Fec2-api~master~I6a281a75dd47e09edeed8a19cfcc41e36a032a0b,openstack/ec2-api,master,I6a281a75dd47e09edeed8a19cfcc41e36a032a0b,Add basic functional tests for customer and vpn gateways,MERGED,2015-06-22 16:49:51.000000000,2015-06-25 05:11:09.000000000,2015-06-25 05:11:07.000000000,"[{'_account_id': 3}, {'_account_id': 9312}, {'_account_id': 10224}, {'_account_id': 10234}]","[{'number': 1, 'created': '2015-06-22 16:49:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ec2-api/commit/572dc286dc16d43d9c26a4830d74ab9861b99961', 'message': 'Add basic tests for customer and vpn gateways\n\nChange-Id: I6a281a75dd47e09edeed8a19cfcc41e36a032a0b\n'}, {'number': 2, 'created': '2015-06-23 12:07:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ec2-api/commit/e7602cfb2064334c4453a6e6ef5050aab1e85ad6', 'message': 'Add basic functional tests for customer and vpn gateways\n\nChange-Id: I6a281a75dd47e09edeed8a19cfcc41e36a032a0b\n'}, {'number': 3, 'created': '2015-06-23 13:28:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ec2-api/commit/237b7230a6588ce376b56efe046dd3b6818d5ee8', 'message': 'Add basic functional tests for customer and vpn gateways\n\nDepends-On: Ia6ad0fdf0fbd8d62d2e4953b72a06f2f4a9863bf\nChange-Id: I6a281a75dd47e09edeed8a19cfcc41e36a032a0b\n'}, {'number': 4, 'created': '2015-06-23 13:39:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ec2-api/commit/42953ae59a4f6a62bbf30ad150f0f3fe9713b054', 'message': 'Add basic functional tests for customer and vpn gateways\n\nDepends-On: I61ec42ce09c05601b805f362b62d4a5abb76b937\nChange-Id: I6a281a75dd47e09edeed8a19cfcc41e36a032a0b\n'}, {'number': 5, 'created': '2015-06-23 13:42:29.000000000', 'files': ['ec2api/tests/functional/api/test_customer_gateways.py', 'ec2api/tests/functional/base.py', 'ec2api/tests/functional/api/test_vpn_gateways.py'], 'web_link': 'https://opendev.org/openstack/ec2-api/commit/e578087ed6781f93a8be440e0f8006fa09f08f34', 'message': 'Add basic functional tests for customer and vpn gateways\n\nDepends-On: I75e1bbcd81678a56a0940b696cfa5dbc2c159cc6\nChange-Id: I6a281a75dd47e09edeed8a19cfcc41e36a032a0b\n'}]",0,194231,e578087ed6781f93a8be440e0f8006fa09f08f34,15,4,5,10224,,,0,"Add basic functional tests for customer and vpn gateways

Depends-On: I75e1bbcd81678a56a0940b696cfa5dbc2c159cc6
Change-Id: I6a281a75dd47e09edeed8a19cfcc41e36a032a0b
",git fetch https://review.opendev.org/openstack/ec2-api refs/changes/31/194231/5 && git format-patch -1 --stdout FETCH_HEAD,"['ec2api/tests/functional/api/test_customer_gateways.py', 'ec2api/tests/functional/api/test_vpn_gateways.py']",2,572dc286dc16d43d9c26a4830d74ab9861b99961,vpn,"# Copyright 2014 OpenStack Foundation # All Rights Reserved. # # Licensed under the Apache License, Version 2.0 (the ""License""); you may # not use this file except in compliance with the License. You may obtain # a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT # WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the # License for the specific language governing permissions and limitations # under the License. import botocore.exceptions from tempest_lib import exceptions from ec2api.tests.functional import base from ec2api.tests.functional import config CONF = config.CONF class VpnGatewayTest(base.EC2TestCase): VPC_CIDR = '10.4.0.0/20' vpc_id = None @classmethod @base.safe_setup def setUpClass(cls): super(VpnGatewayTest, cls).setUpClass() if not base.TesterStateHolder().get_vpc_enabled(): raise cls.skipException('VPC is disabled') data = cls.client.create_vpc(CidrBlock=cls.VPC_CIDR) cls.vpc_id = data['Vpc']['VpcId'] cls.get_vpc_waiter().wait_available(cls.vpc_id) cls.addResourceCleanUpStatic(cls.client.delete_vpc, VpcId=cls.vpc_id) @classmethod def _vpn_gateway_get_attachment_state(cls, vpn_gateway_id): try: data = cls.client.describe_vpn_gateways( VpnGatewayIds=[vpn_gateway_id]) if not data['VpnGateways'][0].get('VpcAttachments'): return 'available' return data['VpnGateways'][0]['VpcAttachments'][0]['State'] except botocore.exceptions.ClientError as ex: error_code = ex.response['Error']['Code'] if error_code == 'InvalidVpnGatewayID.NotFound': raise exceptions.NotFound() raise def test_create_delete_vpn_gateway(self): data = self.client.create_vpn_gateway(Type='ipsec.1') vgw_id = data['VpnGateway']['VpnGatewayId'] vgw_clean = self.addResourceCleanUp( self.client.delete_vpn_gateway, VpnGatewayId=vgw_id) self.client.delete_vpn_gateway(VpnGatewayId=vgw_id) self.cancelResourceCleanUp(vgw_clean) try: data = self.client.describe_vpn_gateways( VpnGatewayIds=[vgw_id]) self.assertEqual(1, len(data['VpnGateways'])) self.assertEqual('deleted', data['VpnGateways'][0]['State']) except botocore.exceptions.ClientError as ex: self.assertEqual('InvalidVpnGatewayID.NotFound', ex.response['Error']['Code']) def test_attach_detach_vpn_gateway(self): data = self.client.create_vpn_gateway(Type='ipsec.1') vgw_id = data['VpnGateway']['VpnGatewayId'] self.addResourceCleanUp(self.client.delete_vpn_gateway, VpnGatewayId=vgw_id) data = self.client.attach_vpn_gateway(VpnGatewayId=vgw_id, VpcId=self.vpc_id) attach_clean = self.addResourceCleanUp( self.client.detach_vpn_gateway, VpnGatewayId=vgw_id, VpcId=self.vpc_id) self.assertIn('VpcAttachment', data) self.assertEqual(self.vpc_id, data['VpcAttachment']['VpcId']) attach_waiter = base.EC2Waiter(self._vpn_gateway_get_attachment_state) attach_waiter.wait_available(vgw_id, 'attached') data = self.client.detach_vpn_gateway(VpnGatewayId=vgw_id, VpcId=self.vpc_id) self.cancelResourceCleanUp(attach_clean) attach_waiter.wait_available(vgw_id, set(['available', 'detached'])) data = self.client.describe_vpn_gateways(VpnGatewayIds=[vgw_id]) self.assertEqual( 'detached', (data['VpnGateways'][0]['VpcAttachments'] or [{'State': 'detached'}])[0]['State']) ",,153,0
openstack%2Fneutron~master~I48d2deaa8cf3952917c854c92c1b934c03d104a5,openstack/neutron,master,I48d2deaa8cf3952917c854c92c1b934c03d104a5,Pluribus Networks decomposition plugin,ABANDONED,2015-02-02 05:56:37.000000000,2015-06-25 05:08:00.000000000,,"[{'_account_id': 3}, {'_account_id': 105}, {'_account_id': 261}, {'_account_id': 748}, {'_account_id': 2874}, {'_account_id': 5170}, {'_account_id': 6524}, {'_account_id': 7062}, {'_account_id': 8645}, {'_account_id': 9681}, {'_account_id': 9682}, {'_account_id': 9732}, {'_account_id': 9787}, {'_account_id': 9845}, {'_account_id': 10116}, {'_account_id': 10121}, {'_account_id': 10153}, {'_account_id': 10184}, {'_account_id': 10387}, {'_account_id': 12040}, {'_account_id': 12271}, {'_account_id': 14323}, {'_account_id': 14571}, {'_account_id': 14961}, {'_account_id': 15296}]","[{'number': 1, 'created': '2015-02-02 05:56:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/2592967af7741a27c9087cfae7c7fa4e98be0eca', 'message': 'Pluribus Networks decomposition plugin\n\nThis changeset adds the Pluribus Networks driver and\nthe associated requirements.txt file that points to the\nneutron-plugin-pluribus package on the PyPI server.\n\nThe Pluribus Networks plugin code is available at:\nhttps://github.com/PluribusNetworks/pluribus_neutron\n\nThe package is available on pypi at:\nhttps://pypi.python.org/pypi/neutron-plugin-pluribus/3.0\n\nDocImpact\nPartially-implements: blueprint core-vendor-decomposition\nImplements: blueprint pluribus-neutron-plugin\n\nChange-Id: I48d2deaa8cf3952917c854c92c1b934c03d104a5\n'}, {'number': 2, 'created': '2015-02-02 06:46:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/9c35299750907fd6f2fb25eb0dd737c8936bdc95', 'message': 'Pluribus Networks decomposition plugin\n\nThis changeset adds the Pluribus Networks driver and\nthe associated requirements.txt file that points to the\nneutron-plugin-pluribus package on the PyPI server.\n\nThe Pluribus Networks plugin code is available at:\nhttps://github.com/PluribusNetworks/pluribus_neutron\n\nThe package is available on pypi at:\nhttps://pypi.python.org/pypi/neutron-plugin-pluribus/3.0\n\nDocImpact\nPartially-implements: blueprint core-vendor-decomposition\nImplements: blueprint pluribus-neutron-plugin\n\nChange-Id: I48d2deaa8cf3952917c854c92c1b934c03d104a5\n'}, {'number': 3, 'created': '2015-02-05 08:45:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/20ddacf5e2934344a58efee7915fa02b05f0a948', 'message': 'Pluribus Networks decomposition plugin\n\nThis changeset adds the Pluribus Networks driver and\nthe associated requirements.txt file that points to the\nneutron-plugin-pluribus package on the PyPI server.\n\nThe Pluribus Networks plugin code is available at:\nhttps://github.com/PluribusNetworks/pluribus_neutron\n\nThe package is available on pypi at:\nhttps://pypi.python.org/pypi/neutron-plugin-pluribus/3.0\n\nDocImpact\nPartially-implements: blueprint core-vendor-decomposition\nImplements: blueprint pluribus-neutron-plugin\n\nChange-Id: I48d2deaa8cf3952917c854c92c1b934c03d104a5\n'}, {'number': 4, 'created': '2015-06-23 11:42:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/a78801b64cb6e8249c2ddb523a28ff8b89c9149c', 'message': 'Pluribus Networks decomposition plugin\n\nThis changeset adds the Pluribus Networks driver and\nthe associated requirements.txt file that points to the\nneutron-plugin-pluribus package on the PyPI server.\n\nThe Pluribus Networks plugin code is available at:\nhttps://github.com/PluribusNetworks/pluribus_neutron\n\nThe package is available on pypi at:\nhttps://pypi.python.org/pypi/neutron-plugin-pluribus/3.0\n\nDocImpact\nPartially-implements: blueprint core-vendor-decomposition\nImplements: blueprint pluribus-neutron-plugin\n\nChange-Id: I48d2deaa8cf3952917c854c92c1b934c03d104a5\n'}, {'number': 5, 'created': '2015-06-23 13:49:18.000000000', 'files': ['etc/neutron/plugins/pluribus/pluribus.ini', 'neutron/plugins/pluribus/requirements.txt', 'neutron/plugins/pluribus/plugin.py', 'neutron/plugins/pluribus/__init__.py', 'setup.cfg'], 'web_link': 'https://opendev.org/openstack/neutron/commit/30f2eb32dd484dde3dfa3bd04ec68a14e09e1a8d', 'message': 'Pluribus Networks decomposition plugin\n\nThis changeset adds the Pluribus Networks driver and\nthe associated requirements.txt file that points to the\nneutron-plugin-pluribus package on the PyPI server.\n\nThe Pluribus Networks plugin code is available at:\nhttps://github.com/PluribusNetworks/pluribus_neutron\n\nThe package is available on pypi at:\nhttps://pypi.python.org/pypi/neutron-plugin-pluribus/3.0\n\nDocImpact\nPartially-implements: blueprint core-vendor-decomposition\nImplements: blueprint pluribus-neutron-plugin\n\nChange-Id: I48d2deaa8cf3952917c854c92c1b934c03d104a5\n'}]",8,151992,30f2eb32dd484dde3dfa3bd04ec68a14e09e1a8d,80,25,5,12271,,,0,"Pluribus Networks decomposition plugin

This changeset adds the Pluribus Networks driver and
the associated requirements.txt file that points to the
neutron-plugin-pluribus package on the PyPI server.

The Pluribus Networks plugin code is available at:
https://github.com/PluribusNetworks/pluribus_neutron

The package is available on pypi at:
https://pypi.python.org/pypi/neutron-plugin-pluribus/3.0

DocImpact
Partially-implements: blueprint core-vendor-decomposition
Implements: blueprint pluribus-neutron-plugin

Change-Id: I48d2deaa8cf3952917c854c92c1b934c03d104a5
",git fetch https://review.opendev.org/openstack/neutron refs/changes/92/151992/4 && git format-patch -1 --stdout FETCH_HEAD,"['neutron/plugins/pluribus/requirements.txt', 'neutron/plugins/pluribus/plugin.py', 'neutron/plugins/pluribus/__init__.py']",3,2592967af7741a27c9087cfae7c7fa4e98be0eca,bp/core-vendor-decomposition,,,43,0
openstack%2Fkolla~master~I9c4c260ef14f9b367dc86ccfb1a66d764d58ae01,openstack/kolla,master,I9c4c260ef14f9b367dc86ccfb1a66d764d58ae01,Move glance-data container to the correct place,MERGED,2015-06-25 03:45:58.000000000,2015-06-25 04:26:27.000000000,2015-06-25 04:26:26.000000000,"[{'_account_id': 3}, {'_account_id': 2834}, {'_account_id': 3098}]","[{'number': 1, 'created': '2015-06-25 03:45:58.000000000', 'files': ['docker/centos/binary/glance/glance-data/Dockerfile', 'docker/glance/glance-data/build', 'docker/centos/binary/glance/glance-data/build'], 'web_link': 'https://opendev.org/openstack/kolla/commit/61a0bb6ce497c0835e1f0f79faa2d5e97c35e0fe', 'message': 'Move glance-data container to the correct place\n\nIt should be in docker/{centos,fedora,...}/binary/glance/glance-data\nand not directly at the root of docker directory.\n\nChange-Id: I9c4c260ef14f9b367dc86ccfb1a66d764d58ae01\nCloses-Bug: #1468596\n'}]",0,195400,61a0bb6ce497c0835e1f0f79faa2d5e97c35e0fe,7,3,1,13039,,,0,"Move glance-data container to the correct place

It should be in docker/{centos,fedora,...}/binary/glance/glance-data
and not directly at the root of docker directory.

Change-Id: I9c4c260ef14f9b367dc86ccfb1a66d764d58ae01
Closes-Bug: #1468596
",git fetch https://review.opendev.org/openstack/kolla refs/changes/00/195400/1 && git format-patch -1 --stdout FETCH_HEAD,"['docker/centos/binary/glance/glance-data/Dockerfile', 'docker/glance/glance-data/build', 'docker/centos/binary/glance/glance-data/build']",3,61a0bb6ce497c0835e1f0f79faa2d5e97c35e0fe,bug/1468596,../../../../../tools/build-docker-image,,1,1
openstack%2Fkolla~master~Ia296239bbf2d242403885d3ad5005479159c8aff,openstack/kolla,master,Ia296239bbf2d242403885d3ad5005479159c8aff,Fix build link for ovs container,MERGED,2015-06-25 03:30:34.000000000,2015-06-25 04:16:26.000000000,2015-06-25 04:16:25.000000000,"[{'_account_id': 3}, {'_account_id': 2834}, {'_account_id': 3098}]","[{'number': 1, 'created': '2015-06-25 03:30:34.000000000', 'files': ['docker/centos/binary/openvswitch/ovs-base/build'], 'web_link': 'https://opendev.org/openstack/kolla/commit/69e79b56d833a3adecec14aa70d243cf9e830445', 'message': 'Fix build link for ovs container\n\nChange-Id: Ia296239bbf2d242403885d3ad5005479159c8aff\nCloses-Bug: #1468591\n'}]",0,195398,69e79b56d833a3adecec14aa70d243cf9e830445,7,3,1,13039,,,0,"Fix build link for ovs container

Change-Id: Ia296239bbf2d242403885d3ad5005479159c8aff
Closes-Bug: #1468591
",git fetch https://review.opendev.org/openstack/kolla refs/changes/98/195398/1 && git format-patch -1 --stdout FETCH_HEAD,['docker/centos/binary/openvswitch/ovs-base/build'],1,69e79b56d833a3adecec14aa70d243cf9e830445,bug/1468591,../../../../../tools/build-docker-image,../../../../../../../tools/build-docker-image,1,1
openstack%2Fkolla~master~I7e7fbe9cab9f38d51807442d0f6a41a344779ba2,openstack/kolla,master,I7e7fbe9cab9f38d51807442d0f6a41a344779ba2,"Correct dev-quickstart installation directions kUse was using yum to install docker 1.7.0.  This wanted to install all of the fedora 23 dependencies.  Instead, simply use RPM to install via http with the --nodeps option.  This works because we don't really need selinux since we don't support an selinux operational model.",MERGED,2015-06-25 03:10:21.000000000,2015-06-25 04:13:46.000000000,2015-06-25 04:13:45.000000000,"[{'_account_id': 3}, {'_account_id': 3098}, {'_account_id': 13039}]","[{'number': 1, 'created': '2015-06-25 03:10:21.000000000', 'files': ['docs/dev-quickstart.md'], 'web_link': 'https://opendev.org/openstack/kolla/commit/4dac672cc84111f52af192282049a2d00f77735c', 'message': ""Correct dev-quickstart installation directions\nkUse was using yum to install docker 1.7.0.  This wanted to install\nall of the fedora 23 dependencies.  Instead, simply use RPM to install\nvia http with the --nodeps option.  This works because we don't really\nneed selinux since we don't support an selinux operational model.\n\nChange-Id: I7e7fbe9cab9f38d51807442d0f6a41a344779ba2\nCloses-Bug: #1468464\n""}]",0,195395,4dac672cc84111f52af192282049a2d00f77735c,7,3,1,2834,,,0,"Correct dev-quickstart installation directions
kUse was using yum to install docker 1.7.0.  This wanted to install
all of the fedora 23 dependencies.  Instead, simply use RPM to install
via http with the --nodeps option.  This works because we don't really
need selinux since we don't support an selinux operational model.

Change-Id: I7e7fbe9cab9f38d51807442d0f6a41a344779ba2
Closes-Bug: #1468464
",git fetch https://review.opendev.org/openstack/kolla refs/changes/95/195395/1 && git format-patch -1 --stdout FETCH_HEAD,['docs/dev-quickstart.md'],1,4dac672cc84111f52af192282049a2d00f77735c,bug/1468464, sudo rpm -Uvh --nodeps https://kojipkgs.fedoraproject.org//packages/docker/1.7.0/6.git56481a3.fc23/x86_64/docker-1.7.0-6.git56481a3.fc23.x86_64.rpm, sudo yum install https://kojipkgs.fedoraproject.org//packages/docker/1.7.0/6.git56481a3.fc23/x86_64/docker-1.7.0-6.git56481a3.fc23.x86_64.rpm,1,1
openstack%2Fheat-translator~master~I3bd9eb00b7eee7bda00e5f4768bd3a900576f447,openstack/heat-translator,master,I3bd9eb00b7eee7bda00e5f4768bd3a900576f447,Fix typos in ELK CSAR readme file,MERGED,2015-06-24 21:00:47.000000000,2015-06-25 04:11:48.000000000,2015-06-25 04:11:45.000000000,"[{'_account_id': 3}, {'_account_id': 6456}]","[{'number': 1, 'created': '2015-06-24 21:00:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat-translator/commit/1aef757cfd6d178179b3ee101ccc33407b9c8a56', 'message': 'Fix typos in ELK CSAR readme file\n\nChange-Id: I3bd9eb00b7eee7bda00e5f4768bd3a900576f447\n'}, {'number': 2, 'created': '2015-06-24 21:01:32.000000000', 'files': ['translator/toscalib/tests/data/CSAR/tosca_elk/README.txt'], 'web_link': 'https://opendev.org/openstack/heat-translator/commit/984510bff89e37604083d288f2acce0c6e92af97', 'message': 'Fix typos in ELK CSAR readme file\n\nChange-Id: I3bd9eb00b7eee7bda00e5f4768bd3a900576f447\n'}]",0,195315,984510bff89e37604083d288f2acce0c6e92af97,7,2,2,9498,,,0,"Fix typos in ELK CSAR readme file

Change-Id: I3bd9eb00b7eee7bda00e5f4768bd3a900576f447
",git fetch https://review.opendev.org/openstack/heat-translator refs/changes/15/195315/2 && git format-patch -1 --stdout FETCH_HEAD,['translator/toscalib/tests/data/CSAR/tosca_elk/README.txt'],1,1aef757cfd6d178179b3ee101ccc33407b9c8a56,bug/tosca_elk_csar_typo,"This TOSCA simple profile deploys nodejs, mongodb, elasticsearch, logstash and kibana each on a separate server with monitoring enabled for nodejs server where a sample nodejs application is running. The syslog and collectd are installed on a nodejs server. Entry information for processing through an orchestrator is contained in file TOSCA-Metadata/TOSCA.meta. This file provides high-level information such as CSAR version or creator of the CSAR. Furthermore, it provides pointers to the entry template under 'Entry-Definitions' key. The entry template itself may contain pointers to one or more files that are used to define TOSCA base type, unless provided by orchestrator as built-in TOSCA basetypes, and other non-normative types. These are typically provided under 'imports' section in the entry template file. Those type definitions will be read and processed by orchestrator or TOSCA parser to create an internal graph showing dependencies and relationships between various TOSCA types. The entry template may have references to various artifacts required for deployment and will be processed accordingly. ","This TOSCA simple profile deployes nodejs, mongodb, elasticsearch, logstash and kibana each on a separate server with monitoring enabled for nodejs server where a sample nodejs application is running. The syslog and collectd are insatlled on a nodejs server. Entry information for processing through an orchestrator is contained in file TOSCA-Metadata/TOSCA.meta. This file provides high-level information such as CSAR version or creator of the CSAR. Furthermore, it provides pointers to the entry template under 'Entry-Definitions' key. The entry template itself may contain pointer to one or more files that are used to define TOSCA base type, unless provided by Orchestrator as built-in TOSCA basetypes, and other non-normative types. These are typically provided under 'imports' section in the entry template file. Those type definitions will be read and processed by orchestrator or TOSCA parser to create an internal graph showing dependencies and relationship between various TOSCA types. The entry template may have reference to various artifacts required for deployment and will be processed accordingly. ",3,4
openstack%2Fastara~master~I12a7b0af323613c4353678f3873557f577097ea5,openstack/astara,master,I12a7b0af323613c4353678f3873557f577097ea5,Rework messaging layer for oslo.messaging,ABANDONED,2015-06-10 23:38:21.000000000,2015-06-25 04:02:16.000000000,,"[{'_account_id': 3}, {'_account_id': 1420}, {'_account_id': 6923}]","[{'number': 1, 'created': '2015-06-10 23:38:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/astara/commit/b950429cd994e95b1d47892e5b9221c85ef374fa', 'message': ""Rework messaging layer for oslo.messaging (WIP)\n\nInstead of setting up kombu connections directly this uses oslo.messaging.\noslo.messaging doesn't expose all the kombu/rabbit-isms that let us setup a\nsingle connectino to sniff the notifications and RPC buses.  Instead, we need\nto subscribe to each as different connectinos. The child process that listens\nfor notifications now spawns multiple threads, one for each consumer we setup.\n\nThe old code that created Events from messages is now split between a\nnotifications endpoint object and another for RPC messages.\n\nChange-Id: I12a7b0af323613c4353678f3873557f577097ea5\n""}, {'number': 2, 'created': '2015-06-11 22:52:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/astara/commit/4d03a82b6c127adc2a774daa42223daba7f1d4cd', 'message': ""Rework messaging layer for oslo.messaging (WIP)\n\nInstead of setting up kombu connections directly this uses oslo.messaging.\noslo.messaging doesn't expose all the kombu/rabbit-isms that let us setup a\nsingle connectino to sniff the notifications and RPC buses.  Instead, we need\nto subscribe to each as different connectinos. The child process that listens\nfor notifications now spawns multiple threads, one for each consumer we setup.\n\nThis also updates the Sender class to use an oslo.messaging notifier instead of\nsetting up notifications for commands directly with kombu. The ceilometer\nPublisher uses the same approach when sending its messages.\n\nThe old code that created Events from messages is now split between a\nnotifications endpoint object and another for RPC messages.\n\nChange-Id: I12a7b0af323613c4353678f3873557f577097ea5\n""}, {'number': 3, 'created': '2015-06-12 20:10:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/astara/commit/d5eba49f078ac426c3cba7830dcd08b5380d57b3', 'message': ""Rework messaging layer for oslo.messaging (WIP)\n\nInstead of setting up kombu connections directly this uses oslo.messaging.\noslo.messaging doesn't expose all the kombu/rabbit-isms that let us setup a\nsingle connectino to sniff the notifications and RPC buses.  Instead, we need\nto subscribe to each as different connectinos. The child process that listens\nfor notifications now spawns multiple threads, one for each consumer we setup.\n\nThis also updates the Sender class to use an oslo.messaging notifier instead of\nsetting up notifications for commands directly with kombu. The ceilometer\nPublisher uses the same approach when sending its messages.\n\nThe old code that created Events from messages is now split between a\nnotifications endpoint object and another for RPC messages.\n\nChange-Id: I12a7b0af323613c4353678f3873557f577097ea5\n""}, {'number': 4, 'created': '2015-06-16 01:38:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/astara/commit/3b9411dcce41954d494771332a796eac235f0723', 'message': ""Rework messaging layer for oslo.messaging (WIP)\n\nInstead of setting up kombu connections directly this uses oslo.messaging.\noslo.messaging doesn't expose all the kombu/rabbit-isms that let us setup a\nsingle connectino to sniff the notifications and RPC buses.  Instead, we need\nto subscribe to each as different connectinos. The child process that listens\nfor notifications now spawns multiple threads, one for each consumer we setup.\n\nThis also updates the Sender class to use an oslo.messaging notifier instead of\nsetting up notifications for commands directly with kombu. The ceilometer\nPublisher uses the same approach when sending its messages.\n\nThe old code that created Events from messages is now split between a\nnotifications endpoint object and another for RPC messages.\n\nChange-Id: I12a7b0af323613c4353678f3873557f577097ea5\n""}, {'number': 5, 'created': '2015-06-16 06:57:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/astara/commit/8358a1a3632bdc4da9b578a6831709d1573208c6', 'message': ""Rework messaging layer for oslo.messaging\n\nInstead of setting up kombu connections directly this uses oslo.messaging.\noslo.messaging doesn't expose all the kombu/rabbit-isms that let us setup a\nsingle connectino to sniff the notifications and RPC buses.  Instead, we need\nto subscribe to each as different connectinos. The child process that listens\nfor notifications now spawns multiple threads, one for each consumer we setup.\n\nThis also updates the Sender class to use an oslo.messaging notifier instead of\nsetting up notifications for commands directly with kombu. The ceilometer\nPublisher uses the same approach when sending its messages.\n\nThe old code that created Events from messages is now split between a\nnotifications endpoint object and another for RPC messages.\n\nChange-Id: I12a7b0af323613c4353678f3873557f577097ea5\n""}, {'number': 6, 'created': '2015-06-16 18:07:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/astara/commit/d20b1e2e969c68ac1ed8f7e972a57abdaaf7cfbe', 'message': ""Rework messaging layer for oslo.messaging\n\nInstead of setting up kombu connections directly this uses oslo.messaging.\noslo.messaging doesn't expose all the kombu/rabbit-isms that let us setup a\nsingle connectino to sniff the notifications and RPC buses.  Instead, we need\nto subscribe to each as different connectinos. The child process that listens\nfor notifications now spawns multiple threads, one for each consumer we setup.\n\nThis also updates the Sender class to use an oslo.messaging notifier instead of\nsetting up notifications for commands directly with kombu. The ceilometer\nPublisher uses the same approach when sending its messages.\n\nThe old code that created Events from messages is now split between a\nnotifications endpoint object and another for RPC messages.\n\nChange-Id: I12a7b0af323613c4353678f3873557f577097ea5\n""}, {'number': 7, 'created': '2015-06-16 21:39:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/astara/commit/7ce02df73d0475608478a0967af9ebc4db5f9c81', 'message': ""Rework messaging layer for oslo.messaging\n\nInstead of setting up kombu connections directly this uses oslo.messaging.\noslo.messaging doesn't expose all the kombu/rabbit-isms that let us setup a\nsingle connectino to sniff the notifications and RPC buses.  Instead, we need\nto subscribe to each as different connectinos. The child process that listens\nfor notifications now spawns multiple threads, one for each consumer we setup.\n\nThis also updates the Sender class to use an oslo.messaging notifier instead of\nsetting up notifications for commands directly with kombu. The ceilometer\nPublisher uses the same approach when sending its messages.\n\nThe old code that created Events from messages is now split between a\nnotifications endpoint object and another for RPC messages.\n\nChange-Id: I12a7b0af323613c4353678f3873557f577097ea5\n""}, {'number': 8, 'created': '2015-06-25 00:38:20.000000000', 'files': ['akanda/rug/main.py', 'requirements.txt', 'akanda/rug/test/unit/test_rpc.py', 'akanda/rug/test/unit/test_worker.py', 'akanda/rug/notifications.py', 'akanda/rug/test/unit/test_notifications.py', 'akanda/rug/cli/message.py', 'akanda/rug/worker.py', 'akanda/rug/api/neutron.py', 'akanda/rug/common/rpc.py'], 'web_link': 'https://opendev.org/openstack/astara/commit/d1798480d1f9a60a5c54f3e5d4d4372a96e5130e', 'message': ""Rework messaging layer for oslo.messaging\n\nInstead of setting up kombu connections directly this uses oslo.messaging.\noslo.messaging doesn't expose all the kombu/rabbit-isms that let us setup a\nsingle connectino to sniff the notifications and RPC buses.  Instead, we need\nto subscribe to each as different connectinos. The child process that listens\nfor notifications now spawns multiple threads, one for each consumer we setup.\n\nThis also updates the Sender class to use an oslo.messaging notifier instead of\nsetting up notifications for commands directly with kombu. The ceilometer\nPublisher uses the same approach when sending its messages.\n\nThe old code that created Events from messages is now split between a\nnotifications endpoint object and another for RPC messages.\n\nChange-Id: I12a7b0af323613c4353678f3873557f577097ea5\n""}]",0,190401,d1798480d1f9a60a5c54f3e5d4d4372a96e5130e,26,3,8,1420,,,0,"Rework messaging layer for oslo.messaging

Instead of setting up kombu connections directly this uses oslo.messaging.
oslo.messaging doesn't expose all the kombu/rabbit-isms that let us setup a
single connectino to sniff the notifications and RPC buses.  Instead, we need
to subscribe to each as different connectinos. The child process that listens
for notifications now spawns multiple threads, one for each consumer we setup.

This also updates the Sender class to use an oslo.messaging notifier instead of
setting up notifications for commands directly with kombu. The ceilometer
Publisher uses the same approach when sending its messages.

The old code that created Events from messages is now split between a
notifications endpoint object and another for RPC messages.

Change-Id: I12a7b0af323613c4353678f3873557f577097ea5
",git fetch https://review.opendev.org/openstack/astara refs/changes/01/190401/2 && git format-patch -1 --stdout FETCH_HEAD,"['akanda/rug/main.py', 'akanda/rug/notifications.py', 'akanda/rug/api/neutron.py', 'akanda/rug/common/rpc.py']",4,b950429cd994e95b1d47892e5b9221c85ef374fa,rpc," from akanda.rug.common import log_shim as logging import oslo_messaging from oslo_messaging.notify.filter import NotificationFilter import threading # XXX get this from the appropriate config settings. may need # to provide some mapping from the existing amqp_url to oslo.messaging # form, for backward comapt? amqp_url='rabbit://stackrabbit:secretrabbit@127.0.0.1:5672/' from oslo.config import cfg HOST='trusty' NOTIFICATIONS_EXCHANGE = 'neutron' LOG = logging.getLogger(__name__) def get_transport(): return oslo_messaging.get_transport(conf=cfg.CONF, url=amqp_url) def get_server(target, endpoints): return oslo_messaging.get_rpc_server( transport=get_transport(), target=target, endpoints=endpoints, ) def get_target(topic, fanout=True, exchange=None, version=None, server=None): return oslo_messaging.Target( topic=topic, fanout=fanout, exchange=exchange, version=None, server=server) class Connection(object): """"""Used to create objects that can manage multiple RPC connections"""""" def __init__(self): super(Connection, self).__init__() self._server_threads = {} def _add_server_thread(self, server): self._server_threads[server] = threading.Thread(target=server.start) def create_rpc_consumer(self, topic, endpoints): """"""Creates an RPC server for this host that will execute RPCs requested by clients. :param topic: Topic on which to listen for RPC requests :param endpoints: List of endpoint objects that define methods that the server will execute. """""" target = get_target(topic=topic, fanout=True, server=cfg.CONF.host) server = get_server(target, endpoints) LOG.debug('Created RPC server on topic %s' % topic) self._add_server_thread(server) def create_notification_listener(self, endpoints, exchange=None, topic='notifications'): """"""Creates an oslo.messaging notificatino listener associated with provided endpoints :param endpoints: list of endpoint objects that define methods for processing prioritized notifications :param exchange: Optional control exchange to listen on. If not specified, oslo_messaging defaults to 'openstack' :param topic: Topic on which to listen for notification events """""" transport = get_transport() target = get_target(topic='notifications', fanout=False, exchange=exchange) pool = 'akanda.' + topic server = oslo_messaging.get_notification_listener( transport, [target], endpoints, pool=pool) LOG.debug( 'Created RPC notification listener on topic:%s/exchange:%s.' % (topic, exchange)) self._add_server_thread(server) def consume_in_threads(self): """"""Start all RPC consumers in threads"""""" for server, thread in self._server_threads.items(): LOG.debug('Started RPC connection thread:%s/server:%s' % (thread, server)) thread.start() def close(self): for server, thread in self._server_threads.items(): thread.join() def get_rpc_client(topic, exchange, version='1.0'): """"""Creates an RPC client to be used to request methods be executed on remote RPC servers """""" target = get_target(topic=topic, exchange=exchange, version=version, fanout=False) return oslo_messaging.rpc.client.RPCClient( get_transport(), target ) ",,194,211
openstack%2Fastara~master~I4552bf17af1dfe8f945de4ba51d1d9682e014350,openstack/astara,master,I4552bf17af1dfe8f945de4ba51d1d9682e014350,Add a log shim to avoid a dependency on openstack.common.log,ABANDONED,2015-06-10 23:38:21.000000000,2015-06-25 04:02:03.000000000,,"[{'_account_id': 3}, {'_account_id': 1420}, {'_account_id': 6923}]","[{'number': 1, 'created': '2015-06-10 23:38:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/astara/commit/92fe3a2ea0e0a33c4f3dc97a5f9be09bc16771df', 'message': 'Add a log shim to avoid a dependency on openstack.common.log\n\nthere are all kinds of conflicts between openstack.common and oslo. This\njust mocks out a logging library to avoid them while migrating to oslo.messaging\nTemporary hack, to be replaced by migratno to oslo.log\n\nChange-Id: I4552bf17af1dfe8f945de4ba51d1d9682e014350\n'}, {'number': 2, 'created': '2015-06-11 22:52:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/astara/commit/776369697f5ff541886a559fee0e14dc79991ddc', 'message': 'Add a log shim to avoid a dependency on openstack.common.log\n\nthere are all kinds of conflicts between openstack.common and oslo. This\njust mocks out a logging library to avoid them while migrating to oslo.messaging\nTemporary hack, to be replaced by migratno to oslo.log\n\nChange-Id: I4552bf17af1dfe8f945de4ba51d1d9682e014350\n'}, {'number': 3, 'created': '2015-06-12 20:10:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/astara/commit/fe327f721f05132ae4053127b4d21bdeedb574e1', 'message': 'Add a log shim to avoid a dependency on openstack.common.log\n\nthere are all kinds of conflicts between openstack.common and oslo. This\njust mocks out a logging library to avoid them while migrating to oslo.messaging\nTemporary hack, to be replaced by migratno to oslo.log\n\nChange-Id: I4552bf17af1dfe8f945de4ba51d1d9682e014350\n'}, {'number': 4, 'created': '2015-06-16 01:38:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/astara/commit/ef72a16f1dd4d4af51816d2fc44844cf49461762', 'message': 'Add a log shim to avoid a dependency on openstack.common.log\n\nthere are all kinds of conflicts between openstack.common and oslo. This\njust mocks out a logging library to avoid them while migrating to oslo.messaging\nTemporary hack, to be replaced by migratno to oslo.log\n\nChange-Id: I4552bf17af1dfe8f945de4ba51d1d9682e014350\n'}, {'number': 5, 'created': '2015-06-25 00:38:20.000000000', 'files': ['akanda/rug/state.py', 'akanda/rug/populate.py', 'akanda/rug/api/akanda_client.py', 'akanda/rug/service.py', 'akanda/rug/notifications.py', 'akanda/rug/api/rug.py', 'akanda/rug/common/config.py', 'akanda/rug/worker.py', 'akanda/rug/common/linux/interface.py', 'akanda/rug/api/configuration.py', 'akanda/rug/api/neutron.py', 'akanda/rug/scheduler.py', 'akanda/rug/api/nova.py', 'akanda/rug/main.py', 'akanda/rug/daemon.py', 'akanda/rug/common/linux/ovs_lib.py', 'akanda/rug/common/log_shim.py', 'akanda/rug/common/linux/utils.py', 'akanda/rug/tenant.py', 'akanda/rug/test/unit/api/test_rug_api.py', 'akanda/rug/health.py', 'akanda/rug/metadata.py'], 'web_link': 'https://opendev.org/openstack/astara/commit/dbac06463e23c51f5ebfbe51bc750c15e9d8fe6a', 'message': 'Add a log shim to avoid a dependency on openstack.common.log\n\nthere are all kinds of conflicts between openstack.common and oslo. This\njust mocks out a logging library to avoid them while migrating to oslo.messaging\nTemporary hack, to be replaced by migratno to oslo.log\n\nChange-Id: I4552bf17af1dfe8f945de4ba51d1d9682e014350\n'}]",0,190400,dbac06463e23c51f5ebfbe51bc750c15e9d8fe6a,13,3,5,1420,,,0,"Add a log shim to avoid a dependency on openstack.common.log

there are all kinds of conflicts between openstack.common and oslo. This
just mocks out a logging library to avoid them while migrating to oslo.messaging
Temporary hack, to be replaced by migratno to oslo.log

Change-Id: I4552bf17af1dfe8f945de4ba51d1d9682e014350
",git fetch https://review.opendev.org/openstack/astara refs/changes/00/190400/2 && git format-patch -1 --stdout FETCH_HEAD,"['akanda/rug/state.py', 'akanda/rug/populate.py', 'akanda/rug/api/akanda_client.py', 'akanda/rug/service.py', 'akanda/rug/notifications.py', 'akanda/rug/api/rug.py', 'akanda/rug/worker.py', 'akanda/rug/common/linux/interface.py', 'akanda/rug/api/configuration.py', 'akanda/rug/api/neutron.py', 'akanda/rug/scheduler.py', 'akanda/rug/api/nova.py', 'akanda/rug/main.py', 'akanda/rug/daemon.py', 'akanda/rug/common/linux/ovs_lib.py', 'akanda/rug/common/log_shim.py', 'akanda/rug/common/linux/utils.py', 'akanda/rug/tenant.py', 'akanda/rug/health.py', 'akanda/rug/metadata.py']",20,92fe3a2ea0e0a33c4f3dc97a5f9be09bc16771df,rpc,from akanda.rug.common import log_shim as logging,from akanda.rug.openstack.common import log as logging,69,20
openstack%2Fdevstack~master~I674df4812d3edae46a9eba36cd7bd5b7b28eb6ae,openstack/devstack,master,I674df4812d3edae46a9eba36cd7bd5b7b28eb6ae,Ensure that instances can resolve external hosts,ABANDONED,2015-06-11 16:50:06.000000000,2015-06-25 03:59:40.000000000,,"[{'_account_id': 3}, {'_account_id': 105}, {'_account_id': 748}, {'_account_id': 1653}, {'_account_id': 2035}, {'_account_id': 2750}, {'_account_id': 4656}, {'_account_id': 7118}, {'_account_id': 8788}, {'_account_id': 8873}, {'_account_id': 10385}]","[{'number': 1, 'created': '2015-06-11 16:50:06.000000000', 'files': ['lib/neutron-legacy'], 'web_link': 'https://opendev.org/openstack/devstack/commit/43906cc21fdd422873a272f34a0a92747cb3467c', 'message': 'Ensure that instances can resolve external hosts\n\nWhen Neutron is used to manage networking, the default dhcp agent\nconfiguration does not include dns servers that would allow dnsmasq to\nresolve external hosts.  This change adds the google dns servers to the\ndhcp agent configuration to ensure that external resolution is possible\nby default.\n\nChange-Id: I674df4812d3edae46a9eba36cd7bd5b7b28eb6ae\n'}]",0,190716,43906cc21fdd422873a272f34a0a92747cb3467c,21,11,1,2035,,,0,"Ensure that instances can resolve external hosts

When Neutron is used to manage networking, the default dhcp agent
configuration does not include dns servers that would allow dnsmasq to
resolve external hosts.  This change adds the google dns servers to the
dhcp agent configuration to ensure that external resolution is possible
by default.

Change-Id: I674df4812d3edae46a9eba36cd7bd5b7b28eb6ae
",git fetch https://review.opendev.org/openstack/devstack refs/changes/16/190716/1 && git format-patch -1 --stdout FETCH_HEAD,['lib/neutron-legacy'],1,43906cc21fdd422873a272f34a0a92747cb3467c,," iniset $Q_DHCP_CONF_FILE DEFAULT dnsmasq_dns_servers ""8.8.4.4, 8.8.8.8""",,1,0
openstack%2Fneutron-lbaas~master~I1557e73d98d5b0afa91514e04929cb406d685de0,openstack/neutron-lbaas,master,I1557e73d98d5b0afa91514e04929cb406d685de0,Ignored several invalid tests,MERGED,2015-06-24 17:35:53.000000000,2015-06-25 03:37:29.000000000,2015-06-25 03:37:26.000000000,"[{'_account_id': 3}, {'_account_id': 6951}, {'_account_id': 9008}, {'_account_id': 9828}, {'_account_id': 10850}, {'_account_id': 10980}, {'_account_id': 11628}, {'_account_id': 12040}, {'_account_id': 12403}, {'_account_id': 14556}, {'_account_id': 14720}, {'_account_id': 16537}]","[{'number': 1, 'created': '2015-06-24 17:35:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-lbaas/commit/6663bb47fe54e3311b29ba507da69c476e8f7046', 'message': 'Ignored several invalid tests\n\nChange-Id: I1557e73d98d5b0afa91514e04929cb406d685de0\n'}, {'number': 2, 'created': '2015-06-24 19:50:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-lbaas/commit/5c694ad8fd6428a1987637cf422a5c12ec1c6c3a', 'message': 'Ignored several invalid tests\nFixed pep8 error\n\nChange-Id: I1557e73d98d5b0afa91514e04929cb406d685de0\n'}, {'number': 3, 'created': '2015-06-24 19:55:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-lbaas/commit/898541d2ba92225e5be03c7b75364fdb67f1b134', 'message': 'Ignored several invalid tests\nFixed pep8 error\nAdded missing decorator import\n\nChange-Id: I1557e73d98d5b0afa91514e04929cb406d685de0\n'}, {'number': 4, 'created': '2015-06-24 21:02:31.000000000', 'files': ['neutron_lbaas/tests/tempest/v2/api/test_pools_admin.py'], 'web_link': 'https://opendev.org/openstack/neutron-lbaas/commit/21a2e412e56ed3cdb0329f1c888048faa8ec8fde', 'message': 'Ignored several invalid tests\n\nFixed pep8 error\nAdded missing decorator import\n\nChange-Id: I1557e73d98d5b0afa91514e04929cb406d685de0\n'}]",0,195219,21a2e412e56ed3cdb0329f1c888048faa8ec8fde,37,12,4,16537,,,0,"Ignored several invalid tests

Fixed pep8 error
Added missing decorator import

Change-Id: I1557e73d98d5b0afa91514e04929cb406d685de0
",git fetch https://review.opendev.org/openstack/neutron-lbaas refs/changes/19/195219/4 && git format-patch -1 --stdout FETCH_HEAD,['neutron_lbaas/tests/tempest/v2/api/test_pools_admin.py'],1,6663bb47fe54e3311b29ba507da69c476e8f7046,test-skips," @decorators.skip_because(bug=""1468457"") @decorators.skip_because(bug=""1468457"") @decorators.skip_because(bug=""1468457"") @decorators.skip_because(bug=""1468457"")",,4,0
openstack%2Fkolla~master~I8fc730580f09ed3d4c54b8e94d011f0f924cae3e,openstack/kolla,master,I8fc730580f09ed3d4c54b8e94d011f0f924cae3e,Add more checks to the glance containers,MERGED,2015-06-24 16:55:21.000000000,2015-06-25 03:26:44.000000000,2015-06-25 03:26:42.000000000,"[{'_account_id': 3}, {'_account_id': 2834}, {'_account_id': 3098}, {'_account_id': 10428}, {'_account_id': 13039}]","[{'number': 1, 'created': '2015-06-24 16:55:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla/commit/3a9b59a78aa3ba50d149d22d2196788f14062783', 'message': 'Add more checks to glance container\n\nThe glance-base container needs to check for more required variable\nthan it was originally.\n\nChange-Id: I8fc730580f09ed3d4c54b8e94d011f0f924cae3e\nCloses-bug: #1432336\n'}, {'number': 2, 'created': '2015-06-24 17:00:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla/commit/482fdf6c472d234b26c3c15f280267da799e7c45', 'message': 'Add more checks to glance container\n\nThe glance-base container needs to check for more required variables\nthan it was originally.\n\nChange-Id: I8fc730580f09ed3d4c54b8e94d011f0f924cae3e\nCloses-bug: #1432336\n'}, {'number': 3, 'created': '2015-06-24 21:38:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla/commit/b7a855225afe880580d8a37ee821ace6ef069bc3', 'message': 'Add more checks to the glance containers\n\nThe glance containers need to check for more required variables\nthan they were originally.\n\nCloses-bug: #1432336\nCo-Authored-By: Paul Bourke <paul.bourke@oracle.com>\n\nChange-Id: I8fc730580f09ed3d4c54b8e94d011f0f924cae3e\n'}, {'number': 4, 'created': '2015-06-25 02:14:58.000000000', 'files': ['docs/minimal-environment-vars.md', 'docker/common/glance/glance-registry/start.sh', 'docker/common/glance/glance-api/start.sh', 'docker/common/glance/glance-base/config-glance.sh'], 'web_link': 'https://opendev.org/openstack/kolla/commit/29a9515365c4588c3bff2cb0535625c6da55f80e', 'message': 'Add more checks to the glance containers\n\nThe glance containers need to check for more required variables\nthan they were originally.\n\nCloses-bug: #1432336\nCo-Authored-By: Paul Bourke <paul.bourke@oracle.com>\n\nChange-Id: I8fc730580f09ed3d4c54b8e94d011f0f924cae3e\n'}]",8,195193,29a9515365c4588c3bff2cb0535625c6da55f80e,23,5,4,10419,,,0,"Add more checks to the glance containers

The glance containers need to check for more required variables
than they were originally.

Closes-bug: #1432336
Co-Authored-By: Paul Bourke <paul.bourke@oracle.com>

Change-Id: I8fc730580f09ed3d4c54b8e94d011f0f924cae3e
",git fetch https://review.opendev.org/openstack/kolla refs/changes/93/195193/2 && git format-patch -1 --stdout FETCH_HEAD,"['docs/minimal-environment-vars.md', 'docker/common/glance/glance-base/config-glance.sh']",2,3a9b59a78aa3ba50d149d22d2196788f14062783,bug/1432336, KEYSTONE_PUBLIC_SERVICE_HOST ADMIN_TENANT_NAME,,3,0
openstack%2Fneutron-specs~master~Ic51ad6eec9f5b01b4b70ed2e98a8109340cd02bd,openstack/neutron-specs,master,Ic51ad6eec9f5b01b4b70ed2e98a8109340cd02bd,blueprint virtual-network-performance-monitor,ABANDONED,2014-12-17 09:04:53.000000000,2015-06-25 03:14:44.000000000,,"[{'_account_id': 3}, {'_account_id': 105}, {'_account_id': 261}, {'_account_id': 333}, {'_account_id': 748}, {'_account_id': 4656}, {'_account_id': 8873}, {'_account_id': 9444}, {'_account_id': 10068}, {'_account_id': 14129}]","[{'number': 1, 'created': '2014-12-17 09:04:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-specs/commit/2832db13f2c3fec33c025c41ecace39d9a8b2e61', 'message': 'blueprint virtual-network-performance-monitor\n\nThe blueprint introduces a virtual network performance monitor service extension API\nand corresponding data model for the tenants to specify their requirements on monitoring virtual\nnetwork performance. Besides, this blueprint also describes the reference implementation of the\nextended API.\n\nChange-Id: Ic51ad6eec9f5b01b4b70ed2e98a8109340cd02bd\n'}, {'number': 2, 'created': '2014-12-18 14:38:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-specs/commit/22bbb85c2d276acff90372d88cd86da4b64acabb', 'message': 'blueprint virtual-network-performance-monitor(updated1)\n\nThe blueprint introduces a virtual network performance monitor service extension API\nand corresponding data model for the tenants to specify their requirements on monitoring virtual\nnetwork performance. Besides, this blueprint also describes the reference implementation of the\nextended API.\n\nChange-Id: Ic51ad6eec9f5b01b4b70ed2e98a8109340cd02bd\n'}, {'number': 3, 'created': '2014-12-23 16:49:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-specs/commit/6906818c141af9a736a9808d7b76c0377ac269c7', 'message': 'blueprint virtual-network-performance-monitor\n\nThe blueprint introduces a virtual network performance monitor service extension API\nand corresponding data model for the tenants to specify their requirements on monitoring virtual\nnetwork performance. Besides, this blueprint also describes the reference implementation of the\nextended API.\n\nChange-Id: Ic51ad6eec9f5b01b4b70ed2e98a8109340cd02bd\n'}, {'number': 4, 'created': '2014-12-23 16:53:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-specs/commit/7fd65a61d44775f36ceaabd71f213f3daaef66d1', 'message': 'blueprint virtual-network-performance-monitor\n\nThe blueprint introduces a virtual network performance monitor service extension API\nand corresponding data model for the tenants to specify their requirements on monitoring virtual\nnetwork performance. Besides, this blueprint also describes the reference implementation of the\nextended API.\n\nChange-Id: Ic51ad6eec9f5b01b4b70ed2e98a8109340cd02bd\n'}, {'number': 5, 'created': '2015-01-04 03:46:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-specs/commit/d5d5427bed3daf69f275cc7ee2dd3b0df07f56d0', 'message': 'blueprint virtual-network-performance-monitor\n\nThe blueprint introduces a virtual network performance monitor service extension API\nand corresponding data model for the tenants to specify their requirements on monitoring virtual\nnetwork performance. Besides, this blueprint also describes the reference implementation of the\nextended API.\n\nChange-Id: Ic51ad6eec9f5b01b4b70ed2e98a8109340cd02bd\n'}, {'number': 6, 'created': '2015-01-04 03:52:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-specs/commit/7f90563b6d18f0b35d35a74392504f9d012eccae', 'message': 'blueprint virtual-network-performance-monitor\n\nThe blueprint introduces a virtual network performance monitor service extension API\nand corresponding data model for the tenants to specify their requirements on monitoring virtual\nnetwork performance. Besides, this blueprint also describes the reference implementation of the\nextended API.\n\nChange-Id: Ic51ad6eec9f5b01b4b70ed2e98a8109340cd02bd\n'}, {'number': 7, 'created': '2015-02-04 14:21:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-specs/commit/5b1af30fc65197e2791fd453be73a8e4a70e7329', 'message': 'blueprint virtual-network-performance-monitor\n\nThe blueprint introduces a virtual network performance monitor service extension API\nand corresponding data model for the tenants to specify their requirements on monitoring virtual\nnetwork performance. Besides, this blueprint also describes the reference implementation of the\nextended API.\n\nChange-Id: Ic51ad6eec9f5b01b4b70ed2e98a8109340cd02bd\n'}, {'number': 8, 'created': '2015-02-12 14:19:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-specs/commit/25864adede34a26e9949509e1a657d84a34ea2fb', 'message': 'blueprint virtual-network-performance-monitor\n\nThe blueprint introduces a virtual network performance monitor service extension API\nand corresponding data model for the tenants to specify their requirements on monitoring virtual\nnetwork performance. Besides, this blueprint also describes the reference implementation of the\nextended API.\n\nChange-Id: Ic51ad6eec9f5b01b4b70ed2e98a8109340cd02bd\n'}, {'number': 9, 'created': '2015-03-15 14:18:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-specs/commit/315660b59532f7215b1bcd0315082312e02f4d5f', 'message': 'blueprint virtual-network-performance-monitor\n\nThe blueprint introduces a virtual network performance monitor service extension API\nand corresponding data model for the tenants to specify their requirements on monitoring virtual\nnetwork performance. Besides, this blueprint also describes the reference implementation of the\nextended API.\n\nChange-Id: Ic51ad6eec9f5b01b4b70ed2e98a8109340cd02bd\n'}, {'number': 10, 'created': '2015-03-15 14:22:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-specs/commit/5008b77cc33d9333ab330da92927ebad4ca5b920', 'message': 'blueprint virtual-network-performance-monitor\n\nThe blueprint introduces a virtual network performance monitor service extension API\nand corresponding data model for the tenants to specify their requirements on monitoring virtual\nnetwork performance. Besides, this blueprint also describes the reference implementation of the\nextended API.\n\nChange-Id: Ic51ad6eec9f5b01b4b70ed2e98a8109340cd02bd\n'}, {'number': 11, 'created': '2015-03-15 15:41:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-specs/commit/78b9aae0db0c0da5885ae109a1beb5d35e1012c9', 'message': 'blueprint virtual-network-performance-monitor\n\nThe blueprint introduces a virtual network performance monitor service extension API\nand corresponding data model for the tenants to specify their requirements on monitoring virtual\nnetwork performance. Besides, this blueprint also describes the reference implementation of the extended API.\n\nChange-Id: Ic51ad6eec9f5b01b4b70ed2e98a8109340cd02bd\n'}, {'number': 12, 'created': '2015-03-17 03:40:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-specs/commit/ffcad341d159f3565d9e0d31b8696044a14b4b72', 'message': 'blueprint virtual-network-performance-monitor\n\nThe blueprint introduces a virtual network performance monitor service extension API\nand corresponding data model for the tenants to specify their requirements on monitoring virtual\nnetwork performance. Besides, this blueprint also describes the reference implementation of the extended API.\n\nChange-Id: Ic51ad6eec9f5b01b4b70ed2e98a8109340cd02bd\n'}, {'number': 13, 'created': '2015-03-17 03:46:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-specs/commit/cc36906fffdb26a81853347a13991faa1da9e41f', 'message': 'blueprint virtual-network-performance-monitor\n\nThe blueprint introduces a virtual network performance monitor service extension API\nand corresponding data model for the tenants to specify their requirements on monitoring virtual\nnetwork performance. Besides, this blueprint also describes the reference implementation of the extended API.\n\nChange-Id: Ic51ad6eec9f5b01b4b70ed2e98a8109340cd02bd\n'}, {'number': 14, 'created': '2015-03-17 06:39:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-specs/commit/bf85830502d7fa481613569fa02bae3d8b1967e4', 'message': 'blueprint virtual-network-performance-monitor\n\nThe blueprint introduces a virtual network performance monitor service extension API\nand corresponding data model for the tenants to specify their requirements on monitoring virtual\nnetwork performance. Besides, this blueprint also describes the reference implementation of the extended API.\n\nChange-Id: Ic51ad6eec9f5b01b4b70ed2e98a8109340cd02bd\n'}, {'number': 15, 'created': '2015-03-17 07:03:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-specs/commit/530ab06cedf6c89fc53d739f14cece5aa2edb650', 'message': 'blueprint virtual-network-performance-monitor\n\nThe blueprint introduces a virtual network performance monitor service extension API\nand corresponding data model for the tenants to specify their requirements on monitoring virtual\nnetwork performance. Besides, this blueprint also describes the reference implementation of the extended API.\n\nChange-Id: Ic51ad6eec9f5b01b4b70ed2e98a8109340cd02bd\n'}, {'number': 16, 'created': '2015-03-17 08:15:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-specs/commit/5c4ee745e07067524e6b56e7644930859d8a7f29', 'message': 'blueprint virtual-network-performance-monitor\n\nThe blueprint introduces a virtual network performance monitor service extension API\nand corresponding data model for the tenants to specify their requirements on monitoring virtual\nnetwork performance. Besides, this blueprint also describes the reference implementation of the extended API.\n\nChange-Id: Ic51ad6eec9f5b01b4b70ed2e98a8109340cd02bd\n'}, {'number': 17, 'created': '2015-03-17 08:24:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-specs/commit/c36509d62aa7cdd2b94c6d85a0f32f28a7af009a', 'message': 'blueprint virtual-network-performance-monitor\n\nThe blueprint introduces a virtual network performance monitor service extension API\nand corresponding data model for the tenants to specify their requirements on monitoring virtual\nnetwork performance. Besides, this blueprint also describes the reference implementation of the extended API.\n\nChange-Id: Ic51ad6eec9f5b01b4b70ed2e98a8109340cd02bd\n'}, {'number': 18, 'created': '2015-03-17 08:37:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-specs/commit/0d527052cd3e442b1a3afee176512cde6b259f01', 'message': 'blueprint virtual-network-performance-monitor\n\nThe blueprint introduces a virtual network performance monitor service extension API\nand corresponding data model for the tenants to specify their requirements on monitoring virtual\nnetwork performance. Besides, this blueprint also describes the reference implementation of the extended API.\n\nChange-Id: Ic51ad6eec9f5b01b4b70ed2e98a8109340cd02bd\n'}, {'number': 19, 'created': '2015-03-17 09:07:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-specs/commit/90ff88cb384057ff1be621c84226997df5d13ade', 'message': 'blueprint virtual-network-performance-monitor\n\nThe blueprint introduces a virtual network performance monitor service extension API\nand corresponding data model for the tenants to specify their requirements on monitoring virtual\nnetwork performance. Besides, this blueprint also describes the reference implementation of the extended API.\n\nChange-Id: Ic51ad6eec9f5b01b4b70ed2e98a8109340cd02bd\n'}, {'number': 20, 'created': '2015-03-17 09:34:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-specs/commit/43e9106ef49116158bb3e40f907ac5f3973a5d56', 'message': 'blueprint virtual-network-performance-monitor\n\nThe blueprint introduces a virtual network performance monitor service extension API\nand corresponding data model for the tenants to specify their requirements on monitoring virtual\nnetwork performance. Besides, this blueprint also describes the reference implementation of the extended API.\n\nChange-Id: Ic51ad6eec9f5b01b4b70ed2e98a8109340cd02bd\n'}, {'number': 21, 'created': '2015-03-18 01:47:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-specs/commit/e8990fcd7910c7ba63ccfbdc7b1e3d93a4b26c8f', 'message': 'blueprint virtual-network-performance-monitor\n\nThe blueprint introduces a virtual network performance monitor service extension API\nand corresponding data model for the tenants to specify their requirements on monitoring virtual\nnetwork performance. Besides, this blueprint also describes the reference implementation of the extended API.\n\nChange-Id: Ic51ad6eec9f5b01b4b70ed2e98a8109340cd02bd\n'}, {'number': 22, 'created': '2015-03-18 15:20:59.000000000', 'files': ['specs/kilo/virtual-network-performance-monitor.rst'], 'web_link': 'https://opendev.org/openstack/neutron-specs/commit/73edd8826d1c1ccd5c2c5546e227369def1d3443', 'message': 'blueprint virtual-network-performance-monitor\n\nThe blueprint introduces a virtual network performance monitor service extension API\nand corresponding data model for the tenants to specify their requirements on monitoring virtual\nnetwork performance. Besides, this blueprint also describes the reference implementation of the extended API.\n\nChange-Id: Ic51ad6eec9f5b01b4b70ed2e98a8109340cd02bd\n'}]",5,142386,73edd8826d1c1ccd5c2c5546e227369def1d3443,53,10,22,13000,,,0,"blueprint virtual-network-performance-monitor

The blueprint introduces a virtual network performance monitor service extension API
and corresponding data model for the tenants to specify their requirements on monitoring virtual
network performance. Besides, this blueprint also describes the reference implementation of the extended API.

Change-Id: Ic51ad6eec9f5b01b4b70ed2e98a8109340cd02bd
",git fetch https://review.opendev.org/openstack/neutron-specs refs/changes/86/142386/18 && git format-patch -1 --stdout FETCH_HEAD,['specs/kilo/virtual-network-performance-monitor.rst'],1,2832db13f2c3fec33c025c41ecace39d9a8b2e61,bp/virtual-network-performance-monitor,".. This work is licensed under a Creative Commons Attribution 3.0 Unported License. http://creativecommons.org/licenses/by/3.0/legalcode ============================================================ Virtual Network Performance Monitor(VNPM) ============================================================ https://blueprints.launchpad.net/neutron/+spec/virtual-network-performance-monitor The tenants and operators need to be aware of the network performance, such as delay, delay jitter and packet loss ratio, but current Neutron APIs do not support such requirements. The blueprint introduces a virtual network performance monitor service extension API and corresponding data model for the tenants to specify their requirements on monitoring virtual network performance. Besides, this blueprint also describes the reference implementation of the extended API. Problem description =================== Currently neutron allows tenants to create virtual network services, but does not provide available API for the tenants to monitor the virtual network for alarming and performance optimization. So, VNPM API is necessary to be provided to monitor network performance indicators (KPIs), including delay, delay jitter, and packet loss. The tenants may obtain these network performance indicators (KPIs) information by running specific tools on VMs now. However, this self-implementation way is complex, special-purpose, error-prone and time consuming. Thus, it is valuable to provide a virtual network performance monitor API to provide that. Proposed change =============== This blueprint proposes 1) a North Bound Neutron API to represent the requirement of monitoring virtual network performance in the logical resources. 2) a reference architecture to implement the proposed API. Specifically, the virtual network performance parameters in this blueprint include: 1. Delay: the delay from one port to another port, the port refers to the virtual port in neutron. 2. Delay jitter: the variation of packet delay from one port to another port. 3. Packet loss: the ratio of lost packets to total transmitted packets from one port to another port. The introduced interface allows the tenants to express their requirements on virtual network performance monitoring, e.g., the source and destination of the port to monitor. The main advantage of the extensions described in this blueprint is that they provide a standard and flexible way for the tenants and operators to monitor virtual network performance, while current Neutron APIs do not support such requirements. The following diagram illustrates the overall workflows. +-------------------------+ | | | | | Neutron Server | +-------+ +-----+ | | | | | | | | | | | | | +-------------------------+ | | | | | +-------------------------+ +-------------------------+ | | | | | | | | | ML2 Plugin | | VNPM Plugin | | | | | | | | | | | | | | | | | | | | | +-------------------------+ +-------------------------+ | | | | | | | | | | | | +-------------------------+ | | | | | Compute Node | | | | | | +----------------------+ | +-----------+ | | | | |----| VNPM Agent | | | | | +----------------+ | | | | | | | | | vProbe | +-------+--------------+ | | | | +------------+ | | +-----------+ VNPM plugin is proposed to provide North Bound REST interface, which supports CRUD operation on VNPM resource. VNPM Agent and vProbe is proposed to implement the function of measuring network performance. Specifically, each compute node deploys VNPM agent and vProbe. The VNPM plugin transforms the Rest APIs into Neutron RPC messages. The RPC messages are sent to the proposed VNPM agents by the RabbitMQ bus. According to the received messages, the VNPM agent manages the vProbe, and the vProbe sends test packets to other vProbe to test the network performance. The vProbe then sends the test result to the VNPM agent, and the VNPM agent further populates the network performance information with the Oslo notification mechanism. The above architecture/method is only for reference implementation. The developers can also use other architecture/methods to implement the proposed interfaces. for supporting this VNPM API, vProbe and VNPM agent are proposed to use. Alternatives ------------ Since new data model and interface is being proposed here, a direct alternate does not exist. If ovs/linuxbridge has the vProbe function, VNPM plugin can directly communicate with ovs/linuxbridge. Data model impact ----------------- Add DB tables: * neutron.VNPMs New DB model introduced: 1.VNPM *vn_performance_monitors - the VNPM resource. Attributes: *id - unique identifier. *name - user readable name of the specified VNPM. *description - description of the VNPM. *tenant-id - the creator and owner of the VNPM. *source_id - the neutron port of the source of the network performance to be measured. *destination_id - the neutron port of the destination of the network performance to be measured. *test_type - once or periodic measurement. *period_time - the time duration of a measurement, only functions when the test type is set to periodic. *response_type - two options: {normal, only alarm}. If the value is set to ""normal"", every measurement results will be reported. If the value is set to ""only alarm"", only the measurement results that exceeds the specified threshold be reported. *reachability - indicates whether to test reachability or not. *delay - indicates whether to test delay or not. *delay_threhold - the threshold of the delay, only functions when delay is tested and the response_type is set to ""only alarm"". *jitter - indicates whether to test delay jitter or not. *jitter_threhold - the threshold of the delay jitter, only functions when delay jitter is tested and the response_type is set to ""only alarm"". *loss - indicates whether to test packet loss ratio or not. *loss_threhold- the threshold of the packet loss ratio, only functions when packet loss is tested and the response_type is set to ""only alarm"". REST API impact --------------- A separate extension will be created that will expose the VNPM resource. The VNPM resource property is presented as follows: RESOURCE_ATTRIBUTE_MAP = { 'vn_performance_monitors': { 'id': {'allow_post': False, 'allow_put': False, 'validate': {'type:uuid': None}, 'is_visible': True 'primary_key': True}, 'name': {'allow_post': True, 'allow_put': True, 'validate': {'type:string': None}, 'default': '', 'is_visible': True}, 'description': {'allow_post': True,'allow_put': True, 'validate': {'type:string': None}, 'is_visible': True, 'default': ''}, 'tenant_id': {'allow_post': True, 'allow_put': False, 'validate': {'type:string': None}, 'required_by_policy': True, 'is_visible': True}, 'source_id': {'allow_post': True, 'allow_put': False, 'validate': {'type:string': None}, 'required_by_policy': True, 'is_visible': True}, 'destination_id': {'allow_post': True, 'allow_put': False, 'validate': {'type:string': None}, 'required_by_policy': True, 'is_visible': True}, 'test_type': {'allow_post': True, 'allow_put': True, 'validate': {'type:values': ['once','periodic']}, 'is_visible': True, 'default': 'once'}, 'period_time': {'allow_post': True, 'allow_put': True, 'validate': {'type:float': None}, 'is_visible': True}, 'response_type': {'allow_post': True, 'allow_put': True, 'validate': {'type:values': ['normal','only_alarm']}, 'is_visible': True}, 'reachability': {'allow_post': True, 'allow_put': True, 'validate': {'type:bool':None}, 'default': False, 'is_visible': True}, 'delay': {'allow_post': True, 'allow_put': True, 'validate': {'type:bool':None}, 'default': False, 'is_visible': True}, 'jitter': {'allow_post': True, 'allow_put': True, 'validate': {'type:bool':None}, 'default': False, 'is_visible': True}, 'loss': {'allow_post': True, 'allow_put': True, 'validate': {'type:bool':None}, 'default': False, 'is_visible': True}, 'delay_threhold': {'allow_post': True, 'allow_put': True, 'validate': {'type:float':None}, 'default': '', 'is_visible': True}, 'jitter_threhold': {'allow_post': True, 'allow_put': True, 'validate': {'type:float':None}, 'default': '', 'is_visible': True}, 'loss_threhold': {'allow_post': True, 'allow_put': True, 'validate': {'type:float':None}, 'default': '', 'is_visible': True}, } } Security impact --------------- Standard Neutron tenant object ownership rules will apply. Notifications impact -------------------- New notifications will be added to report the virtual network performance. The format of the notification: +--------------+------------+--------------------------------------------------------+ |key |Value |Notes | +--------------+------------+--------------------------------------------------------+ |id |Integer |VNPM ID | +--------------+------------+--------------------------------------------------------+ |test_type |String |The value should be ""once"" or ""periodic"" | +--------------+------------+--------------------------------------------------------+ |period_time |Integer |Time duration for two tests if test_type is set to | | | |""periodic"" | +--------------+------------+--------------------------------------------------------+ |response_type |String |The value should be ""normal"" or ""only alarm"" | +------------------------------------------------------------------------------------+ |notification_ |Integer | | |time | |The time sending this notification | +--------------+------------+--------------------------------------------------------+ |reachability |Bool |True if reachable; False if not reachable | +--------------+------------+--------------------------------------------------------+ |delay(ms) |float |The packets delay from the source neutron port to the | | | |destination neutron port | +--------------+------------+--------------------------------------------------------+ |jitter(ms) |float |The delay jitter | +--------------+------------+--------------------------------------------------------+ |loss |float |packets loss ratio | +--------------+------------+--------------------------------------------------------+ Other end user impact --------------------- None. Performance Impact ------------------ The vProbes need to send test packets and therefore have impact on system performance. However, the administrator can configure how much resource the vProbe can use, including the percentage of CPU cycle, the total throughput, to minimize the impact. Other deployer impact --------------------- If vProbe is to be enabled, it is required to configure the vProbe plugin in neutron.conf. Developer impact ---------------- This API is a new resource extension, and will not affect existing API. Implementation ============== Assignee(s) ----------- Work Items ---------- 1. Implementing Rest API extension *Add a file under neutron/extensions to implement resource extension to and the base class of the plugin to process the API request. *Add a file under neutron/db to implement the data base operation. *Add a directory under neutron/services to implement the plugin. 2. Implementing vProbe *The function of vProbe includes sending test packets to specified IP, calculating the network performance parameter according to the received test packets. Besides, the vProbe should provide interfaces to communicate with VNPM agents. The implementation will be deployed on compute node as a system service. 3. Implementing VNPM agent *The function of VNPM agent includes interaction with the VNPM plugin through RPC, managing vProbes, populate the network performance information with Oslo notification mechanism. The implementation file of VNPM agent will be put under neutron/services/VNPM, and deployed on compute node. Dependencies ============ None Testing ======= Both, functional and, system tests will be added. Documentation Impact ==================== Virtual network performance monitor resource will be added in the documentation. References ========== None ",,345,0
openstack%2Fpython-senlinclient~master~Id9760abfda5197f52c5615890c7013f384d5ccc7,openstack/python-senlinclient,master,Id9760abfda5197f52c5615890c7013f384d5ccc7,Disable rollback by default,MERGED,2015-06-25 02:44:43.000000000,2015-06-25 03:13:22.000000000,2015-06-25 03:13:22.000000000,"[{'_account_id': 3}, {'_account_id': 8246}, {'_account_id': 11034}]","[{'number': 1, 'created': '2015-06-25 02:44:43.000000000', 'files': ['senlinclient/common/utils.py'], 'web_link': 'https://opendev.org/openstack/python-senlinclient/commit/608589c9161e0c06e3bd38d9839ba4c56f039530', 'message': 'Disable rollback by default\n\nCurrently heat disables rollback by default when create/update stack\nfails. Senlin should keep in consistence with heat.\n\nChange-Id: Id9760abfda5197f52c5615890c7013f384d5ccc7\nPartil-Bug: #1466352\n'}]",0,195386,608589c9161e0c06e3bd38d9839ba4c56f039530,7,3,1,6348,,,0,"Disable rollback by default

Currently heat disables rollback by default when create/update stack
fails. Senlin should keep in consistence with heat.

Change-Id: Id9760abfda5197f52c5615890c7013f384d5ccc7
Partil-Bug: #1466352
",git fetch https://review.opendev.org/openstack/python-senlinclient refs/changes/86/195386/1 && git format-patch -1 --stdout FETCH_HEAD,['senlinclient/common/utils.py'],1,608589c9161e0c06e3bd38d9839ba4c56f039530,disable_rollback," 'disable_rollback': spec.get('disable_rollback', True),"," 'disable_rollback': spec.get('disable_rollback', False),",1,1
openstack%2Fneutron-specs~master~I469af0248ec10d82b1fb6589d3f260dd2f3dd2e3,openstack/neutron-specs,master,I469af0248ec10d82b1fb6589d3f260dd2f3dd2e3,"Allow unaddressed port(without l3 address, subnet) and to boot VM with it",MERGED,2015-05-14 17:40:05.000000000,2015-06-25 03:12:25.000000000,2015-06-25 03:12:22.000000000,"[{'_account_id': 3}, {'_account_id': 105}, {'_account_id': 162}, {'_account_id': 333}, {'_account_id': 841}, {'_account_id': 6788}, {'_account_id': 6854}, {'_account_id': 8124}, {'_account_id': 9820}, {'_account_id': 11114}, {'_account_id': 11347}, {'_account_id': 11682}, {'_account_id': 12525}]","[{'number': 1, 'created': '2015-05-14 17:40:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-specs/commit/c5925cae7ad01550e18227051d422248a3d2daca', 'message': 'allow unaddressed port(without l3 address, subnet) and to boot VM with it\n\nChange-Id: I469af0248ec10d82b1fb6589d3f260dd2f3dd2e3\nDocImpact:\nBlueprint: vm-without-l3-address\n'}, {'number': 2, 'created': '2015-05-15 00:58:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-specs/commit/cb4bd897526249da3d77b68540808d8cfea15aea', 'message': 'allow unaddressed port(without l3 address, subnet) and to boot VM with it\n\nChange-Id: I469af0248ec10d82b1fb6589d3f260dd2f3dd2e3\nDocImpact:\nBlueprint: vm-without-l3-address\n'}, {'number': 3, 'created': '2015-06-12 09:03:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-specs/commit/d546a81af04805877c8f06efd9b12d0c2ca8ad3f', 'message': 'allow unaddressed port(without l3 address, subnet) and to boot VM with it\n\nChange-Id: I469af0248ec10d82b1fb6589d3f260dd2f3dd2e3\nDocImpact:\nBlueprint: vm-without-l3-address\n'}, {'number': 4, 'created': '2015-06-18 15:20:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-specs/commit/ea5a21e95e7fe3a6fa147ea884b4d8a5cde8f9cc', 'message': 'allow unaddressed port(without l3 address, subnet) and to boot VM with it\n\nChange-Id: I469af0248ec10d82b1fb6589d3f260dd2f3dd2e3\nDocImpact\nBlueprint: vm-without-l3-address\n'}, {'number': 5, 'created': '2015-06-24 03:10:31.000000000', 'files': ['specs/liberty/unaddressed-port.rst'], 'web_link': 'https://opendev.org/openstack/neutron-specs/commit/5ac8f10c22f1febf473c02f5633c13c469a9d3ff', 'message': 'Allow unaddressed port(without l3 address, subnet) and to boot VM with it\n\nAllow ports to be created and remove the filters based on MAC or IP for this\nport.\n\nChange-Id: I469af0248ec10d82b1fb6589d3f260dd2f3dd2e3\nDocImpact\nBlueprint: vm-without-l3-address\n'}]",48,183125,5ac8f10c22f1febf473c02f5633c13c469a9d3ff,41,13,5,333,,,0,"Allow unaddressed port(without l3 address, subnet) and to boot VM with it

Allow ports to be created and remove the filters based on MAC or IP for this
port.

Change-Id: I469af0248ec10d82b1fb6589d3f260dd2f3dd2e3
DocImpact
Blueprint: vm-without-l3-address
",git fetch https://review.opendev.org/openstack/neutron-specs refs/changes/25/183125/5 && git format-patch -1 --stdout FETCH_HEAD,['specs/liberty/unaddressed-port.rst'],1,c5925cae7ad01550e18227051d422248a3d2daca,bp/vm-without-l3-address,".. This work is licensed under a Creative Commons Attribution 3.0 Unported License. http://creativecommons.org/licenses/by/3.0/legalcode ========================================== Example Spec - The title of your blueprint ========================================== https://blueprints.launchpad.net/neutron/+spec/vm-without-l3-address Allow to create unaddressed port. i.e. port without l3-address, subnets and to boot with the port. Problem Description =================== Currently VM only with L2 address without ipv4/ip6 address can't be created. In fact, it is already possible to create a port with no v4 address, or with no v6 address. (Probably this effort should be done as bug fixes. But it requires user visible changes.) Neutron and nova create interfaces with the assumption that the interface's L2 and L3 assigned addresses are intrinsic attributes; that an L3 address is not optional, and that traffic should never be seen by that machine unless it is addressed to the recognised addresses. Network applications (for example, routers) often forward traffic that is not intended for them, and may actually have - interface without a primary L3 address, which may be receiving traffic for so many disparate addresses that configuring them all in Neutron itself is a pointless burden A typical use case is when a user wishes to deploy a VM which accepts traffic that is neither IPv4 nor IPv6 in nature, one that accepts is a superset of v4 and v6 traffic, or one that accepts traffic for a very wide address range (for either forwarding or termination) and where the port has no primary address. In such cases, the VM is not a conventional application VM. NOTE: many sentence are shamelessly stolen from [nova-l2-net-without-subnet]_ Proposed Change =============== Allow to boot VM with port without l3-address. Actually the current neutron allows to create a port without subnet. typical work flow is as follows (which doesn't work currently) # create neutron L2 network, but any subnets aren't associated to it # boot vm on the network or # create neutron L2 network. subnets may or may not be associated to it # create neutron port on the network without fixed ips. # boot vm with the created port Data Model Impact ----------------- None REST API Impact --------------- None. The current neutron api/implementation allows to create a port without any fixed ips. Security Impact --------------- None Notifications Impact -------------------- l2/l3 agent might be confused without fixed ip address since such a code path isn't tested. Other End User Impact --------------------- None Performance Impact ------------------ None IPv6 Impact ----------- None Other Deployer Impact --------------------- None Developer Impact ---------------- None Community Impact ---------------- None Alternatives ------------ None Implementation ============== Assignee(s) ----------- Primary assignee: Yalei Wang Zang Rui Isaku Yamahata(yamahata) Other contributors: to be added Work Items ---------- * python neutron client to specify that no fixed ip address is associated * python nova client to specify that no fixed ip address is associated * nova neutronv2 network driver * tests * if necessary, fix neutron components. especially l2/l3 agents, security group driver Dependencies ============ Nova neutronv2 network driver would need modification. Testing ======= Necessary api/functional tests will be added. Tempest Tests ------------- * create port without fixed ip address ** connection tests between ports * boot vm with such ports * attach/detach such ports to VMs Functional Tests ---------------- * create port without fixed ip address and tests connectivity between ports API Tests --------- None Documentation Impact ==================== The related part will be updated. User Documentation ------------------ * nova boot * neutron port creation Developer Documentation ----------------------- None References ========== .. [nfv-unaddressed-interface] NFV unaddressed interfaces https://review.openstack.org/#/c/97715/ .. [nova-l2-net-without-subnet] Creating Neutron L2 networks (without subnets) doesn't work as expected https://bugs.launchpad.net/nova/+bug/1039665 .. Make libvirt use the new network model datastructures https://review.openstack.org/#/c/11923/ ",,223,0
openstack%2Fpuppet-manila~master~I944b0288262648bccfab3d87a68da34a1e1e6cd5,openstack/puppet-manila,master,I944b0288262648bccfab3d87a68da34a1e1e6cd5,Fix Beaker CI according recent puppetlabs-rabbitmq change.,MERGED,2015-06-24 17:15:09.000000000,2015-06-25 03:10:34.000000000,2015-06-25 03:10:32.000000000,"[{'_account_id': 3}, {'_account_id': 3153}, {'_account_id': 9500}]","[{'number': 1, 'created': '2015-06-24 17:15:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-manila/commit/2cf8e61c326a97c68f58462db4ad6302a7869e0f', 'message': 'Fix Beaker CI according recent puppetlabs-rabbitmq change.\n\nThe puppetlabs-rabbitmq module introduce a new feature related to the\nerlang_cookie parameter change (the database must be wiped if the cookie is\nchanged), the parameter wipe_db_on_cookie_change is configured to false by\ndefault.\n\nChange-Id: I944b0288262648bccfab3d87a68da34a1e1e6cd5\nCloses-Bug: #1468444\n'}, {'number': 2, 'created': '2015-06-24 22:11:45.000000000', 'files': ['spec/acceptance/basic_manila_spec.rb'], 'web_link': 'https://opendev.org/openstack/puppet-manila/commit/2fb57a36b89e9e58d1a5b1190cf16f9e9d75d535', 'message': ""Fix Beaker CI according recent puppetlabs-rabbitmq change.\n\nThe puppetlabs-rabbitmq module introduce a new feature related to the\nerlang_cookie parameter change (the database must be wiped if the cookie is\nchanged), the parameter wipe_db_on_cookie_change is configured to false by\ndefault.\n\nBut we're not setting up a rabbitmq cluster and we're not using pacemaker in\nbeaker CI tests, so we just remove the erlang cookie parameter change.\n\nChange-Id: I944b0288262648bccfab3d87a68da34a1e1e6cd5\nCloses-Bug: #1468444\n""}]",0,195203,2fb57a36b89e9e58d1a5b1190cf16f9e9d75d535,9,3,2,7155,,,0,"Fix Beaker CI according recent puppetlabs-rabbitmq change.

The puppetlabs-rabbitmq module introduce a new feature related to the
erlang_cookie parameter change (the database must be wiped if the cookie is
changed), the parameter wipe_db_on_cookie_change is configured to false by
default.

But we're not setting up a rabbitmq cluster and we're not using pacemaker in
beaker CI tests, so we just remove the erlang cookie parameter change.

Change-Id: I944b0288262648bccfab3d87a68da34a1e1e6cd5
Closes-Bug: #1468444
",git fetch https://review.opendev.org/openstack/puppet-manila refs/changes/03/195203/2 && git format-patch -1 --stdout FETCH_HEAD,['spec/acceptance/basic_manila_spec.rb'],1,2cf8e61c326a97c68f58462db4ad6302a7869e0f,bug-1468444," delete_guest_user => true, erlang_cookie => 'secrete', wipe_db_on_cookie_change => true, package_provider => $package_provider,"," delete_guest_user => true, erlang_cookie => 'secrete', package_provider => $package_provider,",4,3
openstack%2Ffuturist~master~I7ad6ee6817a6b7387e6a11b50e3c1a73a5ac0f6e,openstack/futurist,master,I7ad6ee6817a6b7387e6a11b50e3c1a73a5ac0f6e,Show a prettier callback name,MERGED,2015-06-25 00:14:56.000000000,2015-06-25 03:09:57.000000000,2015-06-25 03:09:55.000000000,"[{'_account_id': 3}, {'_account_id': 1297}, {'_account_id': 5638}]","[{'number': 1, 'created': '2015-06-25 00:14:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/futurist/commit/0d4daf85156ad65f9775d091c25c641823aaf7b9', 'message': 'Show a prettier callback name\n\nInstead of just showing the repr(cb) of the callback\nattempt to show a nicely formatted callback name that\nuses attributes of the callback (and only falls back\nto using repr(cb) if none of those work out).\n\nChange-Id: I7ad6ee6817a6b7387e6a11b50e3c1a73a5ac0f6e\n'}, {'number': 2, 'created': '2015-06-25 00:27:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/futurist/commit/124a88ce7e857782df93da94cbec222286019de6', 'message': 'Show a prettier callback name\n\nInstead of just showing the repr(cb) of the callback\nattempt to show a nicely formatted callback name that\nuses attributes of the callback (and only falls back\nto using repr(cb) if none of those work out).\n\nChange-Id: I7ad6ee6817a6b7387e6a11b50e3c1a73a5ac0f6e\n'}, {'number': 3, 'created': '2015-06-25 00:34:56.000000000', 'files': ['futurist/periodics.py'], 'web_link': 'https://opendev.org/openstack/futurist/commit/ac43ca6698033f9e4dbaf925a82fbd21b134bd15', 'message': 'Show a prettier callback name\n\nInstead of just showing the repr(cb) of the callback\nattempt to show a nicely formatted callback name that\nuses attributes of the callback (and only falls back\nto using repr(cb) if none of those work out).\n\nChange-Id: I7ad6ee6817a6b7387e6a11b50e3c1a73a5ac0f6e\n'}]",0,195362,ac43ca6698033f9e4dbaf925a82fbd21b134bd15,11,3,3,1297,,,0,"Show a prettier callback name

Instead of just showing the repr(cb) of the callback
attempt to show a nicely formatted callback name that
uses attributes of the callback (and only falls back
to using repr(cb) if none of those work out).

Change-Id: I7ad6ee6817a6b7387e6a11b50e3c1a73a5ac0f6e
",git fetch https://review.opendev.org/openstack/futurist refs/changes/62/195362/2 && git format-patch -1 --stdout FETCH_HEAD,['futurist/periodics.py'],1,0d4daf85156ad65f9775d091c25c641823aaf7b9,,"def _get_callback_name(cb): segments = [] try: segments.append(cb.__qualname__) except AttributeError: try: segments.append(cb.__name__) if inspect.ismethod(cb): try: # This attribute doesn't exist on py3.x or newer, so # we optionally ignore it... (on those versions of # python `__qualname__` should have been found anyway). segments.insert(0, cb.im_class.__name__) except AttributeError: pass except AttributeError: pass if not segments: return repr(cb) else: try: segments.insert(0, cb.__module__) except AttributeError: pass return ""."".join(segments) if LOG.isEnabledFor(logging.DEBUG): LOG.debug(""Running periodic function '%s'"", _get_callback_name(cb)) started_at = _utils.now() self._log.error(""Failed to call %s '%s' (it runs every"" "" %0.2f seconds):\n%s"", kind, _get_callback_name(cb), how_often, pretty_tb) self._log.debug(""Stopped running callback[%s] '%s' periodically:"", index, _get_callback_name(cb))"," started_at = _utils.now() self._log.error(""Failed to call %s %r (it runs every"" "" %0.2f seconds):\n%s"", kind, cb, how_often, pretty_tb) self._log.debug(""Stopped running callback[%s] %r periodically:"", index, cb)",35,6
openstack%2Fpuppet-ironic~master~I8a994a5e4bce61a5700fe645db87889df8cd50b8,openstack/puppet-ironic,master,I8a994a5e4bce61a5700fe645db87889df8cd50b8,Fix Beaker CI according recent puppetlabs-rabbitmq change.,MERGED,2015-06-24 17:15:14.000000000,2015-06-25 03:09:32.000000000,2015-06-25 03:09:31.000000000,"[{'_account_id': 3}, {'_account_id': 3153}, {'_account_id': 9500}]","[{'number': 1, 'created': '2015-06-24 17:15:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-ironic/commit/cb944b21ec59ce981354fd389d39c0ce8359fda8', 'message': 'Fix Beaker CI according recent puppetlabs-rabbitmq change.\n\nThe puppetlabs-rabbitmq module introduce a new feature related to the\nerlang_cookie parameter change (the database must be wiped if the cookie is\nchanged), the parameter wipe_db_on_cookie_change is configured to false by\ndefault.\n\nChange-Id: I8a994a5e4bce61a5700fe645db87889df8cd50b8\nCloses-Bug: #1468444\n'}, {'number': 2, 'created': '2015-06-24 22:12:07.000000000', 'files': ['spec/acceptance/basic_ironic_spec.rb'], 'web_link': 'https://opendev.org/openstack/puppet-ironic/commit/00ed9a00ab0ccb9795b109fe3fc0c1dba82b0343', 'message': ""Fix Beaker CI according recent puppetlabs-rabbitmq change.\n\nThe puppetlabs-rabbitmq module introduce a new feature related to the\nerlang_cookie parameter change (the database must be wiped if the cookie is\nchanged), the parameter wipe_db_on_cookie_change is configured to false by\ndefault.\n\nBut we're not setting up a rabbitmq cluster and we're not using pacemaker in\nbeaker CI tests, so we just remove the erlang cookie parameter change.\n\nChange-Id: I8a994a5e4bce61a5700fe645db87889df8cd50b8\nCloses-Bug: #1468444\n""}]",0,195204,00ed9a00ab0ccb9795b109fe3fc0c1dba82b0343,9,3,2,7155,,,0,"Fix Beaker CI according recent puppetlabs-rabbitmq change.

The puppetlabs-rabbitmq module introduce a new feature related to the
erlang_cookie parameter change (the database must be wiped if the cookie is
changed), the parameter wipe_db_on_cookie_change is configured to false by
default.

But we're not setting up a rabbitmq cluster and we're not using pacemaker in
beaker CI tests, so we just remove the erlang cookie parameter change.

Change-Id: I8a994a5e4bce61a5700fe645db87889df8cd50b8
Closes-Bug: #1468444
",git fetch https://review.opendev.org/openstack/puppet-ironic refs/changes/04/195204/1 && git format-patch -1 --stdout FETCH_HEAD,['spec/acceptance/basic_ironic_spec.rb'],1,cb944b21ec59ce981354fd389d39c0ce8359fda8,bug-1468444," delete_guest_user => true, erlang_cookie => 'secrete', wipe_db_on_cookie_change => true, package_provider => $package_provider,"," delete_guest_user => true, erlang_cookie => 'secrete', package_provider => $package_provider,",4,3
openstack%2Fastara~master~Ia8abe17e5b88ba7994d8dd29763375f3eeb57ed6,openstack/astara,master,Ia8abe17e5b88ba7994d8dd29763375f3eeb57ed6,Migrate to oslo.i18n,MERGED,2015-06-16 19:30:12.000000000,2015-06-25 03:08:57.000000000,2015-06-25 03:08:56.000000000,"[{'_account_id': 3}, {'_account_id': 1420}, {'_account_id': 6287}, {'_account_id': 6923}]","[{'number': 1, 'created': '2015-06-16 19:30:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/astara/commit/f2a61c8f79d0e176ea8db1959a54a9b931e645e2', 'message': 'Migrate to oslo.i18n\n\nThis replaces use of openstack.common.gettextutils with oslo.i18n.\nIt switches to using the finer grained message catalogs and classifies\nlog msgs that are currently translated into their respective catalog.\n\nChange-Id: Ia8abe17e5b88ba7994d8dd29763375f3eeb57ed6\n'}, {'number': 2, 'created': '2015-06-16 19:31:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/astara/commit/4ce8094da82423d2789130e1cffbfdb5b8eff80b', 'message': 'Migrate to oslo.i18n\n\nThis replaces use of openstack.common.gettextutils with oslo.i18n.\nIt switches to using the finer grained message catalogs and classifies\nlog msgs that are currently translated into their respective catalog.\n\nChange-Id: Ia8abe17e5b88ba7994d8dd29763375f3eeb57ed6\n'}, {'number': 3, 'created': '2015-06-16 20:34:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/astara/commit/edc38bbaf951913d84cc5737db4ac49a4c6724f6', 'message': 'Migrate to oslo.i18n\n\nThis replaces use of openstack.common.gettextutils with oslo.i18n.\nIt switches to using the finer grained message catalogs and classifies\nlog msgs that are currently translated into their respective catalog.\n\nChange-Id: Ia8abe17e5b88ba7994d8dd29763375f3eeb57ed6\n'}, {'number': 4, 'created': '2015-06-16 21:39:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/astara/commit/21f9e4453f8d23814eee8365bcd363672353c469', 'message': 'Migrate to oslo.i18n\n\nThis replaces use of openstack.common.gettextutils with oslo.i18n.\nIt switches to using the finer grained message catalogs and classifies\nlog msgs that are currently translated into their respective catalog.\n\nChange-Id: Ia8abe17e5b88ba7994d8dd29763375f3eeb57ed6\n'}, {'number': 5, 'created': '2015-06-16 21:54:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/astara/commit/f68bf6963504285b8dbb9ad8b73d274fd53a5e1e', 'message': 'Migrate to oslo.i18n\n\nThis replaces use of openstack.common.gettextutils with oslo.i18n.\nIt switches to using the finer grained message catalogs and classifies\nlog msgs that are currently translated into their respective catalog.\n\nChange-Id: Ia8abe17e5b88ba7994d8dd29763375f3eeb57ed6\n'}, {'number': 6, 'created': '2015-06-22 22:28:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/astara/commit/167aa624d3fed803b05cfe79a309d0b2ad5f81ec', 'message': 'Migrate to oslo.i18n\n\nThis replaces use of openstack.common.gettextutils with oslo.i18n.\nIt switches to using the finer grained message catalogs and classifies\nlog msgs that are currently translated into their respective catalog.\n\nChange-Id: Ia8abe17e5b88ba7994d8dd29763375f3eeb57ed6\n'}, {'number': 7, 'created': '2015-06-25 00:38:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/astara/commit/a695ffa31670c7782b70877bf6f36aadec3565af', 'message': 'Migrate to oslo.i18n\n\nThis replaces use of openstack.common.gettextutils with oslo.i18n.\nIt switches to using the finer grained message catalogs and classifies\nlog msgs that are currently translated into their respective catalog.\n\nChange-Id: Ia8abe17e5b88ba7994d8dd29763375f3eeb57ed6\n'}, {'number': 8, 'created': '2015-06-25 01:49:18.000000000', 'files': ['akanda/rug/main.py', 'requirements.txt', 'akanda/rug/test/unit/common/test_linux_interface.py', 'akanda/rug/service.py', 'akanda/rug/common/linux/ovs_lib.py', 'akanda/rug/common/linux/utils.py', 'akanda/rug/common/linux/interface.py', 'akanda/rug/common/i18n.py', 'akanda/rug/common/linux/ip_lib.py'], 'web_link': 'https://opendev.org/openstack/astara/commit/dd401f7618d42bb5c0bc4db82bd7820012b399f5', 'message': 'Migrate to oslo.i18n\n\nThis replaces use of openstack.common.gettextutils with oslo.i18n.\nIt switches to using the finer grained message catalogs and classifies\nlog msgs that are currently translated into their respective catalog.\n\nChange-Id: Ia8abe17e5b88ba7994d8dd29763375f3eeb57ed6\n'}]",0,192395,dd401f7618d42bb5c0bc4db82bd7820012b399f5,29,4,8,1420,,,0,"Migrate to oslo.i18n

This replaces use of openstack.common.gettextutils with oslo.i18n.
It switches to using the finer grained message catalogs and classifies
log msgs that are currently translated into their respective catalog.

Change-Id: Ia8abe17e5b88ba7994d8dd29763375f3eeb57ed6
",git fetch https://review.opendev.org/openstack/astara refs/changes/95/192395/8 && git format-patch -1 --stdout FETCH_HEAD,"['akanda/rug/main.py', 'requirements.txt', 'akanda/rug/service.py', 'akanda/rug/common/linux/ovs_lib.py', 'akanda/rug/common/linux/utils.py', 'akanda/rug/common/linux/interface.py', 'akanda/rug/common/i18n.py', 'akanda/rug/common/linux/ip_lib.py']",8,f2a61c8f79d0e176ea8db1959a54a9b931e645e2,rpc,from akanda.rug.common.i18n import _ from oslo_log import logLOG = log.getLogger(__name__) m = _('sudo is required to run this command') LOG.error(m) raise Exception(m) elif not self._parent.namespace: m = _('No namespace defined for parent') LOG.error(m) raise Exception(m),from akanda.rug.openstack.common.gettextutils import _ raise Exception('Sudo is required to run this command') elif not self._parent.namespace: raise Exception(_('No namespace defined for parent')),66,32
openstack%2Fpuppet-trove~master~Ifb6baa23b0c3bec2eb592fad4224d172595f79ff,openstack/puppet-trove,master,Ifb6baa23b0c3bec2eb592fad4224d172595f79ff,Fix Beaker CI according recent puppetlabs-rabbitmq change.,MERGED,2015-06-24 17:14:48.000000000,2015-06-25 03:08:33.000000000,2015-06-25 03:08:32.000000000,"[{'_account_id': 3}, {'_account_id': 3153}, {'_account_id': 9500}]","[{'number': 1, 'created': '2015-06-24 17:14:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-trove/commit/18327f998949871a3c61f0e4a16e727dc1199db6', 'message': 'Fix Beaker CI according recent puppetlabs-rabbitmq change.\n\nThe puppetlabs-rabbitmq module introduce a new feature related to the\nerlang_cookie parameter change (the database must be wiped if the cookie is\nchanged), the parameter wipe_db_on_cookie_change is configured to false by\ndefault.\n\nChange-Id: Ifb6baa23b0c3bec2eb592fad4224d172595f79ff\nCloses-Bug: #1468444\n'}, {'number': 2, 'created': '2015-06-24 22:08:57.000000000', 'files': ['spec/acceptance/basic_trove_spec.rb'], 'web_link': 'https://opendev.org/openstack/puppet-trove/commit/abc81a8700d09ba4b3e9cfff1d58f4f55dc90e49', 'message': ""Fix Beaker CI according recent puppetlabs-rabbitmq change.\n\nThe puppetlabs-rabbitmq module introduce a new feature related to the\nerlang_cookie parameter change (the database must be wiped if the cookie is\nchanged), the parameter wipe_db_on_cookie_change is configured to false by\ndefault.\n\nBut we're not setting up a rabbitmq cluster and we're not using pacemaker in\nbeaker CI tests, so we just remove the erlang cookie parameter change.\n\nChange-Id: Ifb6baa23b0c3bec2eb592fad4224d172595f79ff\nCloses-Bug: #1468444\n""}]",0,195200,abc81a8700d09ba4b3e9cfff1d58f4f55dc90e49,9,3,2,7155,,,0,"Fix Beaker CI according recent puppetlabs-rabbitmq change.

The puppetlabs-rabbitmq module introduce a new feature related to the
erlang_cookie parameter change (the database must be wiped if the cookie is
changed), the parameter wipe_db_on_cookie_change is configured to false by
default.

But we're not setting up a rabbitmq cluster and we're not using pacemaker in
beaker CI tests, so we just remove the erlang cookie parameter change.

Change-Id: Ifb6baa23b0c3bec2eb592fad4224d172595f79ff
Closes-Bug: #1468444
",git fetch https://review.opendev.org/openstack/puppet-trove refs/changes/00/195200/1 && git format-patch -1 --stdout FETCH_HEAD,['spec/acceptance/basic_trove_spec.rb'],1,18327f998949871a3c61f0e4a16e727dc1199db6,bug-1468444," delete_guest_user => true, erlang_cookie => 'secrete', wipe_db_on_cookie_change => true, package_provider => $package_provider,"," delete_guest_user => true, erlang_cookie => 'secrete', package_provider => $package_provider,",4,3
openstack%2Fcinder~master~I2dbf57e03495e3e60f4674fce3fd0c54a8103c9d,openstack/cinder,master,I2dbf57e03495e3e60f4674fce3fd0c54a8103c9d,Split FC driver code into Common and FC,ABANDONED,2015-06-25 02:14:42.000000000,2015-06-25 03:08:09.000000000,,"[{'_account_id': 12249}, {'_account_id': 16595}]","[{'number': 1, 'created': '2015-06-25 02:14:42.000000000', 'files': ['cinder/volume/drivers/ibm/flashsystem_common.py', 'cinder/volume/drivers/ibm/flashsystem_iscsi.py', 'cinder/volume/drivers/ibm/flashsystem_fc.py'], 'web_link': 'https://opendev.org/openstack/cinder/commit/37dc033dfb0bc0906b66ea9ef0ed4f967da152e8', 'message': 'Split FC driver code into Common and FC\n\nThe patch is to split original FC driver code into common class and\nFC driver for IBM FlashSystem. iSCSI driver has been merged in L-1.\nIt will be inherited from common class as well. This meets community\nrequirement.\n\nImplements: blueprint ibm-flashsystem-iscsi-cleanup\nChange-Id: I2dbf57e03495e3e60f4674fce3fd0c54a8103c9d\n'}]",0,195379,37dc033dfb0bc0906b66ea9ef0ed4f967da152e8,4,2,1,13846,,,0,"Split FC driver code into Common and FC

The patch is to split original FC driver code into common class and
FC driver for IBM FlashSystem. iSCSI driver has been merged in L-1.
It will be inherited from common class as well. This meets community
requirement.

Implements: blueprint ibm-flashsystem-iscsi-cleanup
Change-Id: I2dbf57e03495e3e60f4674fce3fd0c54a8103c9d
",git fetch https://review.opendev.org/openstack/cinder refs/changes/79/195379/1 && git format-patch -1 --stdout FETCH_HEAD,"['cinder/volume/drivers/ibm/flashsystem_common.py', 'cinder/volume/drivers/ibm/flashsystem_iscsi.py', 'cinder/volume/drivers/ibm/flashsystem_fc.py']",3,37dc033dfb0bc0906b66ea9ef0ed4f967da152e8,bp/ibm-flashsystem-iscsi-cleanup,"# Copyright 2015 IBM Corp. # All Rights Reserved. # # Licensed under the Apache License, Version 2.0 (the ""License""); you may # not use this file except in compliance with the License. You may obtain # a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT # WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the # License for the specific language governing permissions and limitations # under the License. # """""" Volume driver for IBM FlashSystem storage systems with FC protocol. Limitations: 1. Cinder driver only works when open_access_enabled=off. """""" import random import threading from oslo_config import cfg from oslo_log import log as logging from oslo_utils import excutils import six from cinder import exception from cinder.i18n import _, _LE, _LI, _LW from cinder import utils import cinder.volume.driver from cinder.volume.drivers.ibm import flashsystem_common as fscommon from cinder.volume.drivers.san import san from cinder.zonemanager import utils as fczm_utils LOG = logging.getLogger(__name__) flashsystem_fc_opts = [ cfg.BoolOpt('flashsystem_multipath_enabled', default=False, help='Connect with multipath (FC only).' '(Default is false.)') ] CONF = cfg.CONF CONF.register_opts(flashsystem_fc_opts) class FlashSystemFCDriver(fscommon.FlashSystemDriver, cinder.volume.driver.FibreChannelDriver): """"""IBM FlashSystem FC volume driver. Version history: 1.0.0 - Initial driver 1.0.1 - Code clean up 1.0.2 - Add lock into vdisk map/unmap, connection initialize/terminate 1.0.3 - Initial driver for iSCSI 1.0.4 - Split Flashsystem driver into common and FC """""" VERSION = ""1.0.4"" def __init__(self, *args, **kwargs): super(FlashSystemFCDriver, self).__init__(*args, **kwargs) self.configuration.append_config_values(fscommon.flashsystem_opts) self.configuration.append_config_values(flashsystem_fc_opts) self.configuration.append_config_values(san.san_opts) def _check_vdisk_params(self, params): # Check that the requested protocol is enabled if params['protocol'] != self._protocol: msg = (_(""Illegal value '%(prot)s' specified for "" ""flashsystem_connection_protocol: "" ""valid value(s) are %(enabled)s."") % {'prot': params['protocol'], 'enabled': self._protocol}) raise exception.InvalidInput(reason=msg) def _create_host(self, connector): """"""Create a new host on the storage system. We create a host and associate it with the given connection information. """""" LOG.debug('enter: _create_host: host %s.', connector['host']) rand_id = six.text_type(random.randint(0, 99999999)).zfill(8) host_name = '%s-%s' % (self._connector_to_hostname_prefix(connector), rand_id) ports = [] if 'FC' == self._protocol and 'wwpns' in connector: for wwpn in connector['wwpns']: ports.append('-hbawwpn %s' % wwpn) self._driver_assert(ports, (_('_create_host: No connector ports.'))) port1 = ports.pop(0) arg_name, arg_val = port1.split() ssh_cmd = ['svctask', 'mkhost', '-force', arg_name, arg_val, '-name', '""%s""' % host_name] out, err = self._ssh(ssh_cmd) self._assert_ssh_return('successfully created' in out, '_create_host', ssh_cmd, out, err) for port in ports: arg_name, arg_val = port.split() ssh_cmd = ['svctask', 'addhostport', '-force', arg_name, arg_val, host_name] out, err = self._ssh(ssh_cmd) self._assert_ssh_return( (not out.strip()), '_create_host', ssh_cmd, out, err) LOG.debug( 'leave: _create_host: host %(host)s - %(host_name)s.', {'host': connector['host'], 'host_name': host_name}) return host_name def _find_host_exhaustive(self, connector, hosts): for host in hosts: ssh_cmd = ['svcinfo', 'lshost', '-delim', '!', host] out, err = self._ssh(ssh_cmd) self._assert_ssh_return( out.strip(), '_find_host_exhaustive', ssh_cmd, out, err) for attr_line in out.split('\n'): # If '!' not found, return the string and two empty strings attr_name, foo, attr_val = attr_line.partition('!') if (attr_name == 'WWPN' and 'wwpns' in connector and attr_val.lower() in map(str.lower, map(str, connector['wwpns']))): return host return None def _get_conn_fc_wwpns(self): wwpns = [] cmd = ['svcinfo', 'lsportfc'] generator = self._port_conf_generator(cmd) header = next(generator, None) if not header: return wwpns for port_data in generator: try: if port_data['status'] == 'active': wwpns.append(port_data['WWPN']) except KeyError: self._handle_keyerror('lsportfc', header) return wwpns def _get_fc_wwpns(self): for key in self._storage_nodes: node = self._storage_nodes[key] ssh_cmd = ['svcinfo', 'lsnode', '-delim', '!', node['id']] attributes = self._execute_command_and_parse_attributes(ssh_cmd) wwpns = set(node['WWPN']) for i, s in zip(attributes['port_id'], attributes['port_status']): if 'unconfigured' != s: wwpns.add(i) node['WWPN'] = list(wwpns) LOG.info(_LI('WWPN on node %(node)s: %(wwpn)s.'), {'node': node['id'], 'wwpn': node['WWPN']}) def _get_vdisk_map_properties( self, connector, lun_id, vdisk_name, vdisk_id, vdisk_params): """"""Get the map properties of vdisk."""""" LOG.debug( 'enter: _get_vdisk_map_properties: vdisk ' '%(vdisk_name)s.', {'vdisk_name': vdisk_name}) preferred_node = '0' IO_group = '0' # Get preferred node and other nodes in I/O group preferred_node_entry = None io_group_nodes = [] for k, node in self._storage_nodes.items(): if vdisk_params['protocol'] != node['protocol']: continue if node['id'] == preferred_node: preferred_node_entry = node if node['IO_group'] == IO_group: io_group_nodes.append(node) if not io_group_nodes: msg = (_('_get_vdisk_map_properties: No node found in ' 'I/O group %(gid)s for volume %(vol)s.') % {'gid': IO_group, 'vol': vdisk_name}) LOG.error(msg) raise exception.VolumeBackendAPIException(data=msg) if not preferred_node_entry and not vdisk_params['multipath']: # Get 1st node in I/O group preferred_node_entry = io_group_nodes[0] LOG.warning(_LW('_get_vdisk_map_properties: Did not find a ' 'preferred node for vdisk %s.'), vdisk_name) properties = {} properties['target_discovered'] = False properties['target_lun'] = lun_id properties['volume_id'] = vdisk_id type_str = 'fibre_channel' conn_wwpns = self._get_conn_fc_wwpns() if not conn_wwpns: msg = _('_get_vdisk_map_properties: Could not get FC ' 'connection information for the host-volume ' 'connection. Is the host configured properly ' 'for FC connections?') LOG.error(msg) raise exception.VolumeBackendAPIException(data=msg) properties['target_wwn'] = conn_wwpns if ""zvm_fcp"" in connector: properties['zvm_fcp'] = connector['zvm_fcp'] properties['initiator_target_map'] = self._build_initiator_target_map( connector['wwpns'], conn_wwpns) LOG.debug( 'leave: _get_vdisk_map_properties: vdisk ' '%(vdisk_name)s.', {'vdisk_name': vdisk_name}) return {'driver_volume_type': type_str, 'data': properties} @fczm_utils.AddFCZone @utils.synchronized('flashsystem-init-conn', external=True) def initialize_connection(self, volume, connector): """"""Perform the necessary work so that a FC connection can be made. To be able to create a FC connection from a given host to a volume, we must: 1. Translate the given WWNN to a host name 2. Create new host on the storage system if it does not yet exist 3. Map the volume to the host if it is not already done 4. Return the connection information for relevant nodes (in the proper I/O group) """""" LOG.debug( 'enter: initialize_connection: volume %(vol)s with ' 'connector %(conn)s.', {'vol': volume, 'conn': connector}) vdisk_name = volume['name'] vdisk_id = volume['id'] vdisk_params = self._get_vdisk_params(volume['volume_type_id']) self._wait_vdisk_copy_completed(vdisk_name) self._driver_assert( self._is_vdisk_defined(vdisk_name), (_('initialize_connection: vdisk %s is not defined.') % vdisk_name)) lun_id = self._map_vdisk_to_host(vdisk_name, connector) properties = {} try: properties = self._get_vdisk_map_properties( connector, lun_id, vdisk_name, vdisk_id, vdisk_params) except exception.VolumeBackendAPIException: with excutils.save_and_reraise_exception(): self.terminate_connection(volume, connector) LOG.error(_LE('initialize_connection: Failed to collect ' 'return properties for volume %(vol)s and ' 'connector %(conn)s.'), {'vol': volume, 'conn': connector}) LOG.debug( 'leave: initialize_connection:\n volume: %(vol)s\n connector ' '%(conn)s\n properties: %(prop)s.', {'vol': volume, 'conn': connector, 'prop': properties}) return properties @fczm_utils.RemoveFCZone @utils.synchronized('flashsystem-term-conn', external=True) def terminate_connection(self, volume, connector, **kwargs): """"""Cleanup after connection has been terminated. When we clean up a terminated connection between a given connector and volume, we: 1. Translate the given connector to a host name 2. Remove the volume-to-host mapping if it exists 3. Delete the host if it has no more mappings (hosts are created automatically by this driver when mappings are created) """""" LOG.debug( 'enter: terminate_connection: volume %(vol)s with ' 'connector %(conn)s.', {'vol': volume, 'conn': connector}) vdisk_name = volume['name'] self._wait_vdisk_copy_completed(vdisk_name) self._unmap_vdisk_from_host(vdisk_name, connector) properties = {} conn_wwpns = self._get_conn_fc_wwpns() properties['target_wwn'] = conn_wwpns properties['initiator_target_map'] = self._build_initiator_target_map( connector['wwpns'], conn_wwpns) LOG.debug( 'leave: terminate_connection: volume %(vol)s with ' 'connector %(conn)s.', {'vol': volume, 'conn': connector}) return { 'driver_volume_type': 'fibre_channel', 'data': properties } def do_setup(self, ctxt): """"""Check that we have all configuration details from the storage."""""" LOG.debug('enter: do_setup') self._context = ctxt # Get data of configured node self._get_node_data() # Get the WWPNs of the FlashSystem nodes self._get_fc_wwpns() # For each node, check what connection modes it supports. Delete any # nodes that do not support any types (may be partially configured). to_delete = [] for k, node in self._storage_nodes.items(): if not node['WWPN']: to_delete.append(k) for delkey in to_delete: del self._storage_nodes[delkey] # Make sure we have at least one node configured self._driver_assert(self._storage_nodes, 'do_setup: No configured nodes.') self._protocol = node['protocol'] = 'FC' # Set for vdisk synchronization self._vdisk_copy_in_progress = set() self._vdisk_copy_lock = threading.Lock() self._check_lock_interval = 5 LOG.debug('leave: do_setup') def validate_connector(self, connector): """"""Check connector."""""" if 'FC' == self._protocol and 'wwpns' not in connector: msg = _LE('The connector does not contain the ' 'required information: wwpns is missing') LOG.error(msg) raise exception.InvalidConnectorException(missing='wwpns') ",,498,475
openstack%2Fpuppet-designate~master~Ia0fc7ca568f9b0b25d96d25c3ee7b67da5bbfd45,openstack/puppet-designate,master,Ia0fc7ca568f9b0b25d96d25c3ee7b67da5bbfd45,Fix Beaker CI according recent puppetlabs-rabbitmq change.,MERGED,2015-06-24 17:15:25.000000000,2015-06-25 03:07:12.000000000,2015-06-25 03:07:10.000000000,"[{'_account_id': 3}, {'_account_id': 3153}, {'_account_id': 9500}]","[{'number': 1, 'created': '2015-06-24 17:15:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-designate/commit/a7d0aac1cdfb79a2079fff39f65ed7aee09305c8', 'message': 'Fix Beaker CI according recent puppetlabs-rabbitmq change.\n\nThe puppetlabs-rabbitmq module introduce a new feature related to the\nerlang_cookie parameter change (the database must be wiped if the cookie is\nchanged), the parameter wipe_db_on_cookie_change is configured to false by\ndefault.\n\nChange-Id: Ia0fc7ca568f9b0b25d96d25c3ee7b67da5bbfd45\nCloses-Bug: #1468444\n'}, {'number': 2, 'created': '2015-06-24 22:13:15.000000000', 'files': ['spec/acceptance/basic_designate_spec.rb'], 'web_link': 'https://opendev.org/openstack/puppet-designate/commit/c500d84a3a3a8aa2c018449ade90cf550b009835', 'message': ""Fix Beaker CI according recent puppetlabs-rabbitmq change.\n\nThe puppetlabs-rabbitmq module introduce a new feature related to the\nerlang_cookie parameter change (the database must be wiped if the cookie is\nchanged), the parameter wipe_db_on_cookie_change is configured to false by\ndefault.\n\nBut we're not setting up a rabbitmq cluster and we're not using pacemaker in\nbeaker CI tests, so we just remove the erlang cookie parameter change.\n\nChange-Id: Ia0fc7ca568f9b0b25d96d25c3ee7b67da5bbfd45\nCloses-Bug: #1468444\n""}]",0,195206,c500d84a3a3a8aa2c018449ade90cf550b009835,9,3,2,7155,,,0,"Fix Beaker CI according recent puppetlabs-rabbitmq change.

The puppetlabs-rabbitmq module introduce a new feature related to the
erlang_cookie parameter change (the database must be wiped if the cookie is
changed), the parameter wipe_db_on_cookie_change is configured to false by
default.

But we're not setting up a rabbitmq cluster and we're not using pacemaker in
beaker CI tests, so we just remove the erlang cookie parameter change.

Change-Id: Ia0fc7ca568f9b0b25d96d25c3ee7b67da5bbfd45
Closes-Bug: #1468444
",git fetch https://review.opendev.org/openstack/puppet-designate refs/changes/06/195206/2 && git format-patch -1 --stdout FETCH_HEAD,['spec/acceptance/basic_designate_spec.rb'],1,a7d0aac1cdfb79a2079fff39f65ed7aee09305c8,bug-1468444," delete_guest_user => true, erlang_cookie => 'secrete', wipe_db_on_cookie_change => true, package_provider => $package_provider,"," delete_guest_user => true, erlang_cookie => 'secrete', package_provider => $package_provider,",4,3
openstack%2Fpuppet-heat~master~Ib7917e16a4deb9a149b5ceca3c3176d8f04bb475,openstack/puppet-heat,master,Ib7917e16a4deb9a149b5ceca3c3176d8f04bb475,Fix Beaker CI according recent puppetlabs-rabbitmq change.,MERGED,2015-06-24 17:15:20.000000000,2015-06-25 03:06:46.000000000,2015-06-25 03:06:46.000000000,"[{'_account_id': 3}, {'_account_id': 3153}, {'_account_id': 9500}]","[{'number': 1, 'created': '2015-06-24 17:15:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-heat/commit/bf4edf008885dfebe125c00d479c89cbad65af7a', 'message': 'Fix Beaker CI according recent puppetlabs-rabbitmq change.\n\nThe puppetlabs-rabbitmq module introduce a new feature related to the\nerlang_cookie parameter change (the database must be wiped if the cookie is\nchanged), the parameter wipe_db_on_cookie_change is configured to false by\ndefault.\n\nChange-Id: Ib7917e16a4deb9a149b5ceca3c3176d8f04bb475\nCloses-Bug: #1468444\n'}, {'number': 2, 'created': '2015-06-24 22:12:37.000000000', 'files': ['spec/acceptance/basic_heat_spec.rb'], 'web_link': 'https://opendev.org/openstack/puppet-heat/commit/827ce8b1dc9a8e97589076681e32e1d188c9dfb9', 'message': ""Fix Beaker CI according recent puppetlabs-rabbitmq change.\n\nThe puppetlabs-rabbitmq module introduce a new feature related to the\nerlang_cookie parameter change (the database must be wiped if the cookie is\nchanged), the parameter wipe_db_on_cookie_change is configured to false by\ndefault.\n\nBut we're not setting up a rabbitmq cluster and we're not using pacemaker in\nbeaker CI tests, so we just remove the erlang cookie parameter change.\n\nChange-Id: Ib7917e16a4deb9a149b5ceca3c3176d8f04bb475\nCloses-Bug: #1468444\n""}]",0,195205,827ce8b1dc9a8e97589076681e32e1d188c9dfb9,11,3,2,7155,,,0,"Fix Beaker CI according recent puppetlabs-rabbitmq change.

The puppetlabs-rabbitmq module introduce a new feature related to the
erlang_cookie parameter change (the database must be wiped if the cookie is
changed), the parameter wipe_db_on_cookie_change is configured to false by
default.

But we're not setting up a rabbitmq cluster and we're not using pacemaker in
beaker CI tests, so we just remove the erlang cookie parameter change.

Change-Id: Ib7917e16a4deb9a149b5ceca3c3176d8f04bb475
Closes-Bug: #1468444
",git fetch https://review.opendev.org/openstack/puppet-heat refs/changes/05/195205/2 && git format-patch -1 --stdout FETCH_HEAD,['spec/acceptance/basic_heat_spec.rb'],1,bf4edf008885dfebe125c00d479c89cbad65af7a,bug-1468444," delete_guest_user => true, erlang_cookie => 'secrete', wipe_db_on_cookie_change => true, package_provider => $package_provider,"," delete_guest_user => true, erlang_cookie => 'secrete', package_provider => $package_provider,",4,3
openstack%2Fhorizon~master~Ibf0be2850669fbc8f6d963f70eb9b6c91281de68,openstack/horizon,master,Ibf0be2850669fbc8f6d963f70eb9b6c91281de68,ID Panels with long roles names should fit,MERGED,2015-06-16 01:24:28.000000000,2015-06-25 03:04:53.000000000,2015-06-25 03:04:50.000000000,"[{'_account_id': 3}, {'_account_id': 6162}, {'_account_id': 6610}, {'_account_id': 6650}, {'_account_id': 11098}, {'_account_id': 12826}, {'_account_id': 13785}, {'_account_id': 13805}, {'_account_id': 14107}, {'_account_id': 14151}, {'_account_id': 15168}]","[{'number': 1, 'created': '2015-06-16 01:24:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/aa4e680969ce512c9e6e068c4cc8018f13ff4606', 'message': 'ID Panels with long roles names/role lists should overflow with text ellipsis\n\nSee this screen shot: http://pasteboard.co/14TpE09S.png\nThe longer role names or having multiple roles is not working well beyond the\nmost basic _member_ admin type roles.\n\nChange-Id: Ibf0be2850669fbc8f6d963f70eb9b6c91281de68\nCloses-Bug: #1463181\n'}, {'number': 2, 'created': '2015-06-16 18:12:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/02fceee3dbadfffef19a8b62cd16dfe6bac7f5bc', 'message': 'ID Panels with long roles names/role lists should overflow with text ellipsis\n\nSee this screen shot: http://pasteboard.co/14TpE09S.png\nThe longer role names or having multiple roles is not working well beyond the\nmost basic _member_ admin type roles.\n\nChange-Id: Ibf0be2850669fbc8f6d963f70eb9b6c91281de68\nCloses-Bug: #1463181\n'}, {'number': 3, 'created': '2015-06-16 21:18:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/6589602a2cbe62b6bf39b8a20c0b6cd572648643', 'message': 'ID Panels with long roles names should fit\n\nSee this screen shot: http://pasteboard.co/14TpE09S.png\nThe longer role names or having multiple roles is not working well beyond the\nmost basic _member_ admin type roles.\n\nChange-Id: Ibf0be2850669fbc8f6d963f70eb9b6c91281de68\nCloses-Bug: #1463181\n'}, {'number': 4, 'created': '2015-06-22 16:41:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/def35b2af64e03d2ffa9edfa09da15d94e9feb10', 'message': 'ID Panels with long roles names should fit\n\nSee this screen shot: http://pasteboard.co/14TpE09S.png\nThe longer role names or having multiple roles is not working well beyond the\nmost basic _member_ admin type roles. It was also noticed while in the CSS\nfor the member roles list, that portions of the CSS could benefit from some\nvery simple refactoring to take advantage of the recent CSS Theme reorg.\n\nChange-Id: Ibf0be2850669fbc8f6d963f70eb9b6c91281de68\nCloses-Bug: #1463181\n'}, {'number': 5, 'created': '2015-06-24 05:21:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/8aa101485e8106d0168f1cce4e643e360eab6329', 'message': 'ID Panels with long roles names should fit\n\nSee this screen shot: http://pasteboard.co/14TpE09S.png\nThe longer role names or having multiple roles is not working well beyond the\nmost basic _member_ admin type roles. It was also noticed while in the CSS\nfor the member roles list, that portions of the CSS could benefit from some\nvery simple refactoring to take advantage of the recent CSS Theme reorg.\n\nChange-Id: Ibf0be2850669fbc8f6d963f70eb9b6c91281de68\nCloses-Bug: #1463181\n'}, {'number': 6, 'created': '2015-06-24 05:23:23.000000000', 'files': ['horizon/templates/horizon/client_side/_membership.html', 'horizon/static/horizon/js/horizon.membership.js', 'openstack_dashboard/static/dashboard/scss/horizon.scss', 'openstack_dashboard/static/dashboard/scss/_variables.scss'], 'web_link': 'https://opendev.org/openstack/horizon/commit/fd8fb3912a0368d8a1e77b516e38b9823d889d85', 'message': 'ID Panels with long roles names should fit\n\nSee this screen shot: http://pasteboard.co/14TpE09S.png\nThe longer role names or having multiple roles is not working well beyond the\nmost basic _member_ admin type roles. It was also noticed while in the CSS\nfor the member roles list, that portions of the CSS could benefit from some\nvery simple refactoring to take advantage of the recent CSS Theme reorg.\n\nChange-Id: Ibf0be2850669fbc8f6d963f70eb9b6c91281de68\nCloses-Bug: #1463181\n'}]",0,192028,fd8fb3912a0368d8a1e77b516e38b9823d889d85,31,11,6,11778,,,0,"ID Panels with long roles names should fit

See this screen shot: http://pasteboard.co/14TpE09S.png
The longer role names or having multiple roles is not working well beyond the
most basic _member_ admin type roles. It was also noticed while in the CSS
for the member roles list, that portions of the CSS could benefit from some
very simple refactoring to take advantage of the recent CSS Theme reorg.

Change-Id: Ibf0be2850669fbc8f6d963f70eb9b6c91281de68
Closes-Bug: #1463181
",git fetch https://review.opendev.org/openstack/horizon refs/changes/28/192028/6 && git format-patch -1 --stdout FETCH_HEAD,"['horizon/templates/horizon/client_side/_membership.html', 'horizon/static/horizon/js/horizon.membership.js', 'openstack_dashboard/static/dashboard/scss/horizon.scss', 'openstack_dashboard/static/dashboard/scss/_variables.scss']",4,aa4e680969ce512c9e6e068c4cc8018f13ff4606,bug/1463181,$table-bg-odd: $table-bg-accent !default; /* Member lists */ $members-list-padding: 3px !default; $members-list-border: 1px solid $gray-light !default; $members-list-item-width: 130px !default; $members-list-roles-width: 125px !default;,$table-bg-odd: #f9f9f9 !default;,37,15
openstack%2Fkolla~master~I97e8f52ea664ef80901deae9dea8acc93b6e1ca4,openstack/kolla,master,I97e8f52ea664ef80901deae9dea8acc93b6e1ca4,Check if tools/genenv binary dependencies are met.,MERGED,2015-06-14 17:53:37.000000000,2015-06-25 02:59:23.000000000,2015-06-25 02:59:21.000000000,"[{'_account_id': 3}, {'_account_id': 1390}, {'_account_id': 2834}, {'_account_id': 10419}, {'_account_id': 13039}, {'_account_id': 16270}]","[{'number': 1, 'created': '2015-06-14 17:53:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla/commit/a4d35b09fed0655b57bbd0b9e54ca3bf74f64423', 'message': ""Check if tools/kolla binary dependencies are met.\n\nThe check is using the bash-native 'type' instead of which, because which\nis not always available on all environments.\n\nCurrent implementation only checks for the availability of openssl but\nthis can be easily expanded.\n\nChange-Id: I97e8f52ea664ef80901deae9dea8acc93b6e1ca4\nCloses-Bug: #1463101\n""}, {'number': 2, 'created': '2015-06-15 17:10:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla/commit/f29048d6af5a5fb81de1eeae05a2488d10512e64', 'message': ""Check if tools/genenv binary dependencies are met.\n\nThe check is using the bash-native 'type' instead of which, because which\nis not always available on all environments.\n\nCurrent implementation only checks for the availability of openssl but\nthis can be easily expanded.\n\nChange-Id: I97e8f52ea664ef80901deae9dea8acc93b6e1ca4\nCloses-Bug: #1463101\n""}, {'number': 3, 'created': '2015-06-25 02:21:38.000000000', 'files': ['tools/genenv'], 'web_link': 'https://opendev.org/openstack/kolla/commit/24577bdeac6c598a8f4d549623af20da37624789', 'message': ""Check if tools/genenv binary dependencies are met.\n\nThe check is using the bash-native 'type' instead of which, because which\nis not always available on all environments.\n\nCurrent implementation only checks for the availability of openssl but\nthis can be easily expanded.\n\nChange-Id: I97e8f52ea664ef80901deae9dea8acc93b6e1ca4\nCloses-Bug: #1463101\n""}]",3,191580,24577bdeac6c598a8f4d549623af20da37624789,26,6,3,10428,,,0,"Check if tools/genenv binary dependencies are met.

The check is using the bash-native 'type' instead of which, because which
is not always available on all environments.

Current implementation only checks for the availability of openssl but
this can be easily expanded.

Change-Id: I97e8f52ea664ef80901deae9dea8acc93b6e1ca4
Closes-Bug: #1463101
",git fetch https://review.opendev.org/openstack/kolla refs/changes/80/191580/3 && git format-patch -1 --stdout FETCH_HEAD,['tools/kolla'],1,a4d35b09fed0655b57bbd0b9e54ca3bf74f64423,bug/1463101,"function check_binarydependencies { local binaries=""openssl"" for bin in $binaries; do if [[ ! $(type -t $bin) ]]; then echo Not found: $bin exit 1 fi done } check_binarydependencies",,11,0
openstack%2Fpuppet-cinder~master~Ie47809bd8c604179a9bfb7ac08a85b11dee283cd,openstack/puppet-cinder,master,Ie47809bd8c604179a9bfb7ac08a85b11dee283cd,Fix Beaker CI according recent puppetlabs-rabbitmq change.,MERGED,2015-06-24 17:15:31.000000000,2015-06-25 02:58:08.000000000,2015-06-25 02:58:08.000000000,"[{'_account_id': 3}, {'_account_id': 1607}, {'_account_id': 3153}, {'_account_id': 9500}]","[{'number': 1, 'created': '2015-06-24 17:15:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-cinder/commit/d1deeb43457c5458af44149fccf0281a04555f18', 'message': 'Fix Beaker CI according recent puppetlabs-rabbitmq change.\n\nThe puppetlabs-rabbitmq module introduce a new feature related to the\nerlang_cookie parameter change (the database must be wiped if the cookie is\nchanged), the parameter wipe_db_on_cookie_change is configured to false by\ndefault.\n\nChange-Id: Ie47809bd8c604179a9bfb7ac08a85b11dee283cd\nCloses-Bug: #1468444\n'}, {'number': 2, 'created': '2015-06-24 22:13:38.000000000', 'files': ['spec/acceptance/basic_cinder_spec.rb'], 'web_link': 'https://opendev.org/openstack/puppet-cinder/commit/6de585b7917a45b11072477291cfe410db91602b', 'message': ""Fix Beaker CI according recent puppetlabs-rabbitmq change.\n\nThe puppetlabs-rabbitmq module introduce a new feature related to the\nerlang_cookie parameter change (the database must be wiped if the cookie is\nchanged), the parameter wipe_db_on_cookie_change is configured to false by\ndefault.\n\nBut we're not setting up a rabbitmq cluster and we're not using pacemaker in\nbeaker CI tests, so we just remove the erlang cookie parameter change.\n\nChange-Id: Ie47809bd8c604179a9bfb7ac08a85b11dee283cd\nCloses-Bug: #1468444\n""}]",0,195207,6de585b7917a45b11072477291cfe410db91602b,12,4,2,7155,,,0,"Fix Beaker CI according recent puppetlabs-rabbitmq change.

The puppetlabs-rabbitmq module introduce a new feature related to the
erlang_cookie parameter change (the database must be wiped if the cookie is
changed), the parameter wipe_db_on_cookie_change is configured to false by
default.

But we're not setting up a rabbitmq cluster and we're not using pacemaker in
beaker CI tests, so we just remove the erlang cookie parameter change.

Change-Id: Ie47809bd8c604179a9bfb7ac08a85b11dee283cd
Closes-Bug: #1468444
",git fetch https://review.opendev.org/openstack/puppet-cinder refs/changes/07/195207/2 && git format-patch -1 --stdout FETCH_HEAD,['spec/acceptance/basic_cinder_spec.rb'],1,d1deeb43457c5458af44149fccf0281a04555f18,bug-1468444," delete_guest_user => true, erlang_cookie => 'secrete', wipe_db_on_cookie_change => true, package_provider => $package_provider,"," delete_guest_user => true, erlang_cookie => 'secrete', package_provider => $package_provider,",4,3
openstack%2Fsenlin~master~I69cb7d40f56a85f3191fb4b8333679fb5b3f5dcb,openstack/senlin,master,I69cb7d40f56a85f3191fb4b8333679fb5b3f5dcb,Implement the do_check method to check stack's status,MERGED,2015-06-04 06:11:56.000000000,2015-06-25 02:52:17.000000000,2015-06-25 02:52:14.000000000,"[{'_account_id': 3}, {'_account_id': 6348}, {'_account_id': 11034}]","[{'number': 1, 'created': '2015-06-04 06:11:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/senlin/commit/78eba7495900af7b45534f8c3b994e6625314fa4', 'message': ""Implement the do_check method to check stack's status\n\nChange-Id: I69cb7d40f56a85f3191fb4b8333679fb5b3f5dcb\n""}, {'number': 2, 'created': '2015-06-11 05:41:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/senlin/commit/92fcf9ca08b2d201d8031b57072c6a137157334e', 'message': ""Implement the do_check method to check stack's status\n\nCheck the stack's status to see whether it is ready to\ndo auto-scaling.\n\nChange-Id: I69cb7d40f56a85f3191fb4b8333679fb5b3f5dcb\n""}, {'number': 3, 'created': '2015-06-11 09:40:22.000000000', 'files': ['senlin/profiles/os/heat/stack.py', 'senlin/drivers/openstack/heat_v1.py'], 'web_link': 'https://opendev.org/openstack/senlin/commit/3dc29580ae17ea56eecffabea55f7f0b2b50a342', 'message': ""Implement the do_check method to check stack's status\n\nCheck the stack's status to see whether it is ready to\ndo auto-scaling.\n\nChange-Id: I69cb7d40f56a85f3191fb4b8333679fb5b3f5dcb\n""}]",2,188272,3dc29580ae17ea56eecffabea55f7f0b2b50a342,16,3,3,6348,,,0,"Implement the do_check method to check stack's status

Check the stack's status to see whether it is ready to
do auto-scaling.

Change-Id: I69cb7d40f56a85f3191fb4b8333679fb5b3f5dcb
",git fetch https://review.opendev.org/openstack/senlin refs/changes/72/188272/3 && git format-patch -1 --stdout FETCH_HEAD,['senlin/profiles/os/heat/stack.py'],1,78eba7495900af7b45534f8c3b994e6625314fa4,check_stack_status," """"""Check stack status."""""" self.stack_id = obj.physical_id try: stack = self.heat(obj).stack_get(self.stack_id) except Exception as ex: raise ex stack_status = stack.body['stack']['stack_status'] return stack_status", # TODO(anyone): Use heat client to query stack status return True,8,2
openstack%2Fsenlin~master~I4fcc58af13aabfa8ac6ef6a8b2cb2d22ad66d59c,openstack/senlin,master,I4fcc58af13aabfa8ac6ef6a8b2cb2d22ad66d59c,Tweak webhook middleware for optimization,MERGED,2015-06-10 03:15:27.000000000,2015-06-25 02:51:53.000000000,2015-06-25 02:51:51.000000000,"[{'_account_id': 3}, {'_account_id': 11034}]","[{'number': 1, 'created': '2015-06-10 03:15:27.000000000', 'files': ['senlin/api/middleware/webhook.py'], 'web_link': 'https://opendev.org/openstack/senlin/commit/5b3612ae71c86f759c9f6ba7b6fec1405de9a125', 'message': 'Tweak webhook middleware for optimization\n\nThis patch tweaks the webhook middleware, for code optimization.\n\nChange-Id: I4fcc58af13aabfa8ac6ef6a8b2cb2d22ad66d59c\n'}]",0,190002,5b3612ae71c86f759c9f6ba7b6fec1405de9a125,7,2,1,8246,,,0,"Tweak webhook middleware for optimization

This patch tweaks the webhook middleware, for code optimization.

Change-Id: I4fcc58af13aabfa8ac6ef6a8b2cb2d22ad66d59c
",git fetch https://review.opendev.org/openstack/senlin refs/changes/02/190002/1 && git format-patch -1 --stdout FETCH_HEAD,['senlin/api/middleware/webhook.py'],1,5b3612ae71c86f759c9f6ba7b6fec1405de9a125,tweak-webhook-mw,"import sixfrom senlin.common import exception as excfrom senlin.common.i18n import _LE """"""Middleware for authenticating webhook triggering requests. This middleware authenticates the webhook trigger requests and then rebuild the request header so that the request will successfully pass the verification of keystone auth_token middleware. """""" def process_request(self, req): # We only handle POST requests if req.method != 'POST': return # Extract webhook ID webhook_id = self._extract_webhook_id(req.url) if not webhook_id: return # The request must have a 'key' parameter if 'key' not in req.params: return key = req.params['key'] credential = self._get_credential(webhook_id, key) # Get token based on credential and fill it into the request header token = self._get_token(credential) req.headers['X-Auth-Token'] = token def _extract_webhook_id(self, url): """"""Extract webhook ID from the request URL. :param url: The URL from which the request is received. """""" if 'webhooks' not in url: url_bottom = url.split('webhooks')[1] if 'trigger' not in url_bottom: # /<webhook_id>/trigger?key=value parts = url_bottom.split('/') if len(parts) < 3: return webhook_id = parts[1] if not parts[2].startswith('trigger'): return return webhook_id def _get_credential(self, webhook_id, key): """"""Get credential for the given webhook using the provided key. :param webhook_id: ID of the webhook. :param key: The key string to be used for decryption. """""" # Build a RequestContext from service context for DB APIs ctx = context.RequestContext.from_dict(context.get_service_context()) # Default to auth_url from service context if not provided credential['auth_url'] = ctx.auth_url clear_text = utils.decrypt(credential['password'], key) credential['password'] = clear_text except Exception as ex: msg = _('Invalid key for webhook (%s) triggering.') % webhook_id LOG.error(six.text_type(ex)) raise exc.SenlinBadRequest(msg=msg) def _get_token(self, cred): """"""Get a valid token based on the credential provided. :param cred: Rebuilt credential dictionary for authentication. """""" try: access_info = sdk.authenticate(**cred) token = access_info.auth_token except Exception as ex: msg = _LE('Webhook trigger failed in getting token: %s' ) % six.text_type(ex) raise exc.WebhookCredentialInvalid(webhook=cred['webhook_id']) return token","from senlin.common import exception '''Middleware to do authentication for webhook triggering This middleware gets authentication for request to a webhook based on information embedded inside url and then rebuild the request header. ''' def process_request(self, req): self._authenticate(req) def _authenticate(self, req): LOG.debug(""Checking credentials of webhook request"") credential = self._get_credential(req) # Get a valid token based on credential # and fill into the request header token_id = self._get_token(credential) req.headers['X-Auth-Token'] = token_id def _get_credential(self, req): try: url_bottom = req.url.rsplit('webhooks')[1] webhook_id = url_bottom.rsplit('/')[1] trigger = url_bottom.rsplit('/')[2].startswith('trigger') if trigger is not True or 'key' not in req.params: raise Exception() except Exception: LOG.debug(_(""%(url)s is not a webhook trigger url,"" "" pass.""), {'url': req.url}) if req.method != 'POST': LOG.debug(_(""Not a post request to webhook trigger url"" "" %(url)s, pass.""), {'url': req.url}) # This is a webhook triggering, we need to fill in valid # credential info into the http headers to ensure this # request can pass keystone auth_token validation. # # Get the credential stored in DB based on webhook ID. # TODO(Anyone): Use Barbican to store these credential. LOG.debug(_(""Get credential of webhook %(id)s""), {'id': webhook_id}) senlin_context = context.get_service_context() # Build a RequestContext from senlin_context since DB API # needs the session parameter. # TODO(Anyone): This converting is not needed any more after # the context redesign is finally complete. ctx = context.RequestContext(**senlin_context) # If no auth_url is provided in credential, use # auth_url of senlin service context credential['auth_url'] = senlin_context['auth_url'] password = utils.decrypt(credential['password'], req.params['key']) credential['password'] = password except Exception: msg = 'Invalid key for webhook(%s) credential decryption' % \ webhook_id LOG.error(msg) raise exception.SenlinBadRequest(msg=msg) def _get_token(self, credential): '''Get a valid token based on credential''' try: access_info = sdk.authenticate(**credential) token_id = access_info.auth_token except Exception as ex: msg = 'Webhook get token failed: %s' % ex.message raise exception.WebhookCredentialInvalid( webhook=credential['webhook_id']) # Get token successfully! return token_id",70,60
openstack%2Fsenlin~master~I928c253950a8d10497237ebd920b08eb46623bbc,openstack/senlin,master,I928c253950a8d10497237ebd920b08eb46623bbc,Initial version of profile design doc,MERGED,2015-06-19 13:29:20.000000000,2015-06-25 02:51:02.000000000,2015-06-25 02:51:01.000000000,"[{'_account_id': 3}, {'_account_id': 6348}, {'_account_id': 11034}]","[{'number': 1, 'created': '2015-06-19 13:29:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/senlin/commit/b9a610a4d87734ab248e1972658d38e3d2a19563', 'message': 'WIP - Profile design doc\n\nThis patch provides an initial version of the design document for\nprofiles in Senlin.\n\nChange-Id: I928c253950a8d10497237ebd920b08eb46623bbc\n'}, {'number': 2, 'created': '2015-06-21 05:37:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/senlin/commit/aabe49cf5726bf204ffda468c2817866d7b1da24', 'message': 'Initial version of profile design doc\n\nThis patch provides an initial version of the design document for\nprofiles in Senlin.\n\nChange-Id: I928c253950a8d10497237ebd920b08eb46623bbc\n'}, {'number': 3, 'created': '2015-06-23 03:31:05.000000000', 'files': ['doc/source/index.rst', 'doc/source/developer/node.rst', 'doc/source/developer/profile.rst'], 'web_link': 'https://opendev.org/openstack/senlin/commit/dcea48d941a1315e4713a46fbd5873e288126f5d', 'message': 'Initial version of profile design doc\n\nThis patch provides an initial version of the design document for\nprofiles in Senlin.\n\nChange-Id: I928c253950a8d10497237ebd920b08eb46623bbc\n'}]",4,193541,dcea48d941a1315e4713a46fbd5873e288126f5d,11,3,3,8246,,,0,"Initial version of profile design doc

This patch provides an initial version of the design document for
profiles in Senlin.

Change-Id: I928c253950a8d10497237ebd920b08eb46623bbc
",git fetch https://review.opendev.org/openstack/senlin refs/changes/41/193541/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/source/developer/profile.rst'],1,b9a610a4d87734ab248e1972658d38e3d2a19563,profile-doc,".. Licensed under the Apache License, Version 2.0 (the ""License""); you may not use this file except in compliance with the License. You may obtain a copy of the License at http://www.apache.org/licenses/LICENSE-2.0 Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License. Profiles ======== A profile is an object instantiated from a ""profile type"" and it is used as the specification for creating a physical object to be managed by Senlin. The ""physical"" adjective here is used to differentiate such an object from its counterpart, the ""logical"" object, which is referred to as a node in Senlin. As the specification for physical object creation, a profile contains almost every piece of information needed for the underlying driver to create an object. After a physical object is created, its UUID will be assigned to the ``physical_id`` property of a node as reference. When a physical object is deleted, the ``physical_id`` property will be set to ``None``. Although not required, a profile may reference the node object's properties when creating a physical object. For example, a profile may use the node's ``index`` property value for generating a name for the object; a profile may customize an object's property based on the ``role`` property value of a node. It is up to the profile type author and the specific use case how a profile is making use of the properties of a node. ------------------ Profile Properties ------------------ A profile object has the following properties: - ``id``: a global unique ID assigned to the object after creation; - ``name``: a string representation of the profile name; - ``type``: a string referencing the profile type used; - ``context``: a map of key-value pairs that contains credentials and/or parameters for authentication with an identity service. When a profile is about to create an object, it will use data stored here to establish a connection to a service; - ``spec``: a map of key-value pairs that contains the specification for object creation. The content of this property is dictated by the corresponding profile type. - ``permission``: a string representing the access permissions assigned to different user and/or user groups. The supporting feature is still under design. - ``metadata``: a map of key-value pairs associated with the profile; - ``created_time``: the timestamp when the profile was created; - ``updated_time``: the timestamp when the profile was last updated; - ``deleted_time``: the timestamp when the profile was deleted. The ``spec`` property is the most important property for a profile. It is immutable, i.e. changing the ``spec`` property will result in a new profile being created. By restricting changes to this property, Senlin can do a better job in managing the object configurations. ------------------ Creating A Profile ------------------ When creating a profile using the ``profile_create`` API, a user must provide the ``name``, ``spec`` and the ``type`` parameters. In future, the ``type`` parameter may be provided as part of the ``spec`` map. All other parameters are optional. The provided ``spec`` map will be validated using the validation logic provided by the corresponding profile type. If the validation succeeds, the profile will be created and stored into the database. Senlin engine returns the details of the profile as a dict back to Senlin API and eventually to the requesting user. If the validation fails, Senlin engine returns an error message describing the reason of the failure. ",,80,0
openstack%2Fastara~master~Ia7cc26dc20ed57bdf21571e260d006669d6f3310,openstack/astara,master,Ia7cc26dc20ed57bdf21571e260d006669d6f3310,Migrate to oslo.log and oslo.messaging,MERGED,2015-06-25 01:49:18.000000000,2015-06-25 02:43:57.000000000,2015-06-25 02:43:56.000000000,"[{'_account_id': 3}, {'_account_id': 1420}, {'_account_id': 6287}, {'_account_id': 6923}]","[{'number': 1, 'created': '2015-06-25 01:49:18.000000000', 'files': ['akanda/rug/openstack/common/rpc/impl_fake.py', 'akanda/rug/test/unit/test_worker.py', 'akanda/rug/notifications.py', 'akanda/rug/common/config.py', 'akanda/rug/openstack/common/rpc/dispatcher.py', 'akanda/rug/openstack/common/rpc/proxy.py', 'akanda/rug/openstack/common/rpc/impl_kombu.py', 'akanda/rug/worker.py', 'akanda/rug/common/linux/interface.py', 'akanda/rug/api/configuration.py', 'akanda/rug/api/neutron.py', 'akanda/rug/main.py', 'requirements.txt', 'akanda/rug/test/unit/test_notifications.py', 'akanda/rug/test/unit/test_main.py', 'akanda/rug/cli/message.py', 'akanda/rug/common/linux/utils.py', 'akanda/rug/test/unit/api/test_rug_api.py', 'akanda/rug/openstack/common/log.py', 'akanda/rug/state.py', 'akanda/rug/test/unit/test_rpc.py', 'akanda/rug/populate.py', 'akanda/rug/api/akanda_client.py', 'akanda/rug/service.py', 'akanda/rug/api/rug.py', 'akanda/rug/openstack/common/rpc/amqp.py', 'devstack/plugin.sh', 'akanda/rug/openstack/common/rpc/impl_qpid.py', 'akanda/rug/openstack/common/rpc/common.py', 'akanda/rug/scheduler.py', 'akanda/rug/common/rpc.py', 'akanda/rug/api/nova.py', 'akanda/rug/openstack/common/rpc/matchmaker.py', 'akanda/rug/openstack/common/rpc/__init__.py', 'akanda/rug/daemon.py', 'akanda/rug/openstack/common/rpc/service.py', 'akanda/rug/common/linux/ovs_lib.py', 'akanda/rug/tenant.py', 'akanda/rug/health.py', 'akanda/rug/metadata.py', 'akanda/rug/openstack/common/rpc/impl_zmq.py'], 'web_link': 'https://opendev.org/openstack/astara/commit/1696da438ab5b172df652be83ac788635178b4b9', 'message': ""Migrate to oslo.log and oslo.messaging\n\nThis was originally proposed as two separate patches but a module dependency\nissue requires them to be squashed into one patch.\n\n* Migrate to oslo.log\n\nThis updates logging to use olso.log. Also updates the default logging format\nto be a bit more standard, and sets up devstack to configure colorized logging\nin the screen session.\n\nThis will likely need to be squashed into the oslo.messaging patch but pushing\nseperately for the sake of initial review.\n\n* Rework messaging layer for oslo.messaging\n\nInstead of setting up kombu connections directly this uses oslo.messaging.\noslo.messaging doesn't expose all the kombu/rabbit-isms that let us setup a\nsingle connectino to sniff the notifications and RPC buses.  Instead, we need\nto subscribe to each as different connectinos. The child process that listens\nfor notifications now spawns multiple threads, one for each consumer we setup.\n\nThis also updates the Sender class to use an oslo.messaging notifier instead of\nsetting up notifications for commands directly with kombu. The ceilometer\nPublisher uses the same approach when sending its messages.\n\nThe old code that created Events from messages is now split between a\nnotifications endpoint object and another for RPC messages.\n\nChange-Id: Ia7cc26dc20ed57bdf21571e260d006669d6f3310\n""}]",0,195373,1696da438ab5b172df652be83ac788635178b4b9,8,4,1,1420,,,0,"Migrate to oslo.log and oslo.messaging

This was originally proposed as two separate patches but a module dependency
issue requires them to be squashed into one patch.

* Migrate to oslo.log

This updates logging to use olso.log. Also updates the default logging format
to be a bit more standard, and sets up devstack to configure colorized logging
in the screen session.

This will likely need to be squashed into the oslo.messaging patch but pushing
seperately for the sake of initial review.

* Rework messaging layer for oslo.messaging

Instead of setting up kombu connections directly this uses oslo.messaging.
oslo.messaging doesn't expose all the kombu/rabbit-isms that let us setup a
single connectino to sniff the notifications and RPC buses.  Instead, we need
to subscribe to each as different connectinos. The child process that listens
for notifications now spawns multiple threads, one for each consumer we setup.

This also updates the Sender class to use an oslo.messaging notifier instead of
setting up notifications for commands directly with kombu. The ceilometer
Publisher uses the same approach when sending its messages.

The old code that created Events from messages is now split between a
notifications endpoint object and another for RPC messages.

Change-Id: Ia7cc26dc20ed57bdf21571e260d006669d6f3310
",git fetch https://review.opendev.org/openstack/astara refs/changes/73/195373/1 && git format-patch -1 --stdout FETCH_HEAD,"['akanda/rug/openstack/common/rpc/impl_fake.py', 'akanda/rug/test/unit/test_worker.py', 'akanda/rug/notifications.py', 'akanda/rug/common/config.py', 'akanda/rug/openstack/common/rpc/dispatcher.py', 'akanda/rug/openstack/common/rpc/proxy.py', 'akanda/rug/openstack/common/rpc/impl_kombu.py', 'akanda/rug/worker.py', 'akanda/rug/common/linux/interface.py', 'akanda/rug/api/configuration.py', 'akanda/rug/api/neutron.py', 'akanda/rug/main.py', 'requirements.txt', 'akanda/rug/test/unit/test_notifications.py', 'akanda/rug/test/unit/test_main.py', 'akanda/rug/cli/message.py', 'akanda/rug/common/linux/utils.py', 'akanda/rug/test/unit/api/test_rug_api.py', 'akanda/rug/openstack/common/log.py', 'akanda/rug/state.py', 'akanda/rug/test/unit/test_rpc.py', 'akanda/rug/populate.py', 'akanda/rug/api/akanda_client.py', 'akanda/rug/service.py', 'akanda/rug/api/rug.py', 'akanda/rug/openstack/common/rpc/amqp.py', 'devstack/plugin.sh', 'akanda/rug/openstack/common/rpc/impl_qpid.py', 'akanda/rug/openstack/common/rpc/common.py', 'akanda/rug/scheduler.py', 'akanda/rug/common/rpc.py', 'akanda/rug/api/nova.py', 'akanda/rug/openstack/common/rpc/matchmaker.py', 'akanda/rug/openstack/common/rpc/__init__.py', 'akanda/rug/daemon.py', 'akanda/rug/openstack/common/rpc/service.py', 'akanda/rug/common/linux/ovs_lib.py', 'akanda/rug/tenant.py', 'akanda/rug/health.py', 'akanda/rug/metadata.py', 'akanda/rug/openstack/common/rpc/impl_zmq.py']",41,1696da438ab5b172df652be83ac788635178b4b9,rpc,,"# Copyright 2014 DreamHost, LLC # # Author: DreamHost, LLC # # Licensed under the Apache License, Version 2.0 (the ""License""); you may # not use this file except in compliance with the License. You may obtain # a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT # WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the # License for the specific language governing permissions and limitations # under the License. # vim: tabstop=4 shiftwidth=4 softtabstop=4 # Copyright 2011 Cloudscaling Group, Inc # # Licensed under the Apache License, Version 2.0 (the ""License""); you may # not use this file except in compliance with the License. You may obtain # a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT # WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the # License for the specific language governing permissions and limitations # under the License. import os import pprint import re import socket import sys import types import uuid import eventlet import greenlet from oslo_config import cfg from akanda.rug.openstack.common import excutils from akanda.rug.openstack.common.gettextutils import _ from akanda.rug.openstack.common import importutils from akanda.rug.openstack.common import jsonutils from akanda.rug.openstack.common import processutils as utils from akanda.rug.openstack.common.rpc import common as rpc_common zmq = importutils.try_import('eventlet.green.zmq') # for convenience, are not modified. pformat = pprint.pformat Timeout = eventlet.timeout.Timeout LOG = rpc_common.LOG RemoteError = rpc_common.RemoteError RPCException = rpc_common.RPCException zmq_opts = [ cfg.StrOpt('rpc_zmq_bind_address', default='*', help='ZeroMQ bind address. Should be a wildcard (*), ' 'an ethernet interface, or IP. ' 'The ""host"" option should point or resolve to this ' 'address.'), # The module.Class to use for matchmaking. cfg.StrOpt( 'rpc_zmq_matchmaker', default=('akanda.rug.openstack.common.rpc.' 'matchmaker.MatchMakerLocalhost'), help='MatchMaker driver', ), # The following port is unassigned by IANA as of 2012-05-21 cfg.IntOpt('rpc_zmq_port', default=9501, help='ZeroMQ receiver listening port'), cfg.IntOpt('rpc_zmq_contexts', default=1, help='Number of ZeroMQ contexts, defaults to 1'), cfg.IntOpt('rpc_zmq_topic_backlog', default=None, help='Maximum number of ingress messages to locally buffer ' 'per topic. Default is unlimited.'), cfg.StrOpt('rpc_zmq_ipc_dir', default='/var/run/openstack', help='Directory for holding IPC sockets'), cfg.StrOpt('rpc_zmq_host', default=socket.gethostname(), help='Name of this node. Must be a valid hostname, FQDN, or ' 'IP address. Must match ""host"" option, if running Nova.') ] CONF = cfg.CONF CONF.register_opts(zmq_opts) ZMQ_CTX = None # ZeroMQ Context, must be global. matchmaker = None # memoized matchmaker object def _serialize(data): """""" Serialization wrapper We prefer using JSON, but it cannot encode all types. Error if a developer passes us bad data. """""" try: return jsonutils.dumps(data, ensure_ascii=True) except TypeError: with excutils.save_and_reraise_exception(): LOG.error(_(""JSON serialization failed."")) def _deserialize(data): """""" Deserialization wrapper """""" LOG.debug(_(""Deserializing: %s""), data) return jsonutils.loads(data) class ZmqSocket(object): """""" A tiny wrapper around ZeroMQ to simplify the send/recv protocol and connection management. Can be used as a Context (supports the 'with' statement). """""" def __init__(self, addr, zmq_type, bind=True, subscribe=None): self.sock = _get_ctxt().socket(zmq_type) self.addr = addr self.type = zmq_type self.subscriptions = [] # Support failures on sending/receiving on wrong socket type. self.can_recv = zmq_type in (zmq.PULL, zmq.SUB) self.can_send = zmq_type in (zmq.PUSH, zmq.PUB) self.can_sub = zmq_type in (zmq.SUB, ) # Support list, str, & None for subscribe arg (cast to list) do_sub = { list: subscribe, str: [subscribe], type(None): [] }[type(subscribe)] for f in do_sub: self.subscribe(f) str_data = {'addr': addr, 'type': self.socket_s(), 'subscribe': subscribe, 'bind': bind} LOG.debug(_(""Connecting to %(addr)s with %(type)s""), str_data) LOG.debug(_(""-> Subscribed to %(subscribe)s""), str_data) LOG.debug(_(""-> bind: %(bind)s""), str_data) try: if bind: self.sock.bind(addr) else: self.sock.connect(addr) except Exception: raise RPCException(_(""Could not open socket."")) def socket_s(self): """"""Get socket type as string."""""" t_enum = ('PUSH', 'PULL', 'PUB', 'SUB', 'REP', 'REQ', 'ROUTER', 'DEALER') return dict(map(lambda t: (getattr(zmq, t), t), t_enum))[self.type] def subscribe(self, msg_filter): """"""Subscribe."""""" if not self.can_sub: raise RPCException(""Cannot subscribe on this socket."") LOG.debug(_(""Subscribing to %s""), msg_filter) try: self.sock.setsockopt(zmq.SUBSCRIBE, msg_filter) except Exception: return self.subscriptions.append(msg_filter) def unsubscribe(self, msg_filter): """"""Unsubscribe."""""" if msg_filter not in self.subscriptions: return self.sock.setsockopt(zmq.UNSUBSCRIBE, msg_filter) self.subscriptions.remove(msg_filter) def close(self): if self.sock is None or self.sock.closed: return # We must unsubscribe, or we'll leak descriptors. if len(self.subscriptions) > 0: for f in self.subscriptions: try: self.sock.setsockopt(zmq.UNSUBSCRIBE, f) except Exception: pass self.subscriptions = [] try: # Default is to linger self.sock.close() except Exception: # While this is a bad thing to happen, # it would be much worse if some of the code calling this # were to fail. For now, lets log, and later evaluate # if we can safely raise here. LOG.error(""ZeroMQ socket could not be closed."") self.sock = None def recv(self): if not self.can_recv: raise RPCException(_(""You cannot recv on this socket."")) return self.sock.recv_multipart() def send(self, data): if not self.can_send: raise RPCException(_(""You cannot send on this socket."")) self.sock.send_multipart(data) class ZmqClient(object): """"""Client for ZMQ sockets."""""" def __init__(self, addr, socket_type=None, bind=False): if socket_type is None: socket_type = zmq.PUSH self.outq = ZmqSocket(addr, socket_type, bind=bind) def cast(self, msg_id, topic, data, envelope=False): msg_id = msg_id or 0 if not (envelope or rpc_common._SEND_RPC_ENVELOPE): self.outq.send(map(bytes, (msg_id, topic, 'cast', _serialize(data)))) return rpc_envelope = rpc_common.serialize_msg(data[1], envelope) zmq_msg = reduce(lambda x, y: x + y, rpc_envelope.items()) self.outq.send(map(bytes, (msg_id, topic, 'impl_zmq_v2', data[0]) + zmq_msg)) def close(self): self.outq.close() class RpcContext(rpc_common.CommonRpcContext): """"""Context that supports replying to a rpc.call."""""" def __init__(self, **kwargs): self.replies = [] super(RpcContext, self).__init__(**kwargs) def deepcopy(self): values = self.to_dict() values['replies'] = self.replies return self.__class__(**values) def reply(self, reply=None, failure=None, ending=False): if ending: return self.replies.append(reply) @classmethod def marshal(self, ctx): ctx_data = ctx.to_dict() return _serialize(ctx_data) @classmethod def unmarshal(self, data): return RpcContext.from_dict(_deserialize(data)) class InternalContext(object): """"""Used by ConsumerBase as a private context for - methods."""""" def __init__(self, proxy): self.proxy = proxy self.msg_waiter = None def _get_response(self, ctx, proxy, topic, data): """"""Process a curried message and cast the result to topic."""""" LOG.debug(_(""Running func with context: %s""), ctx.to_dict()) data.setdefault('version', None) data.setdefault('args', {}) try: result = proxy.dispatch( ctx, data['version'], data['method'], **data['args']) return ConsumerBase.normalize_reply(result, ctx.replies) except greenlet.GreenletExit: # ignore these since they are just from shutdowns pass except rpc_common.ClientException, e: LOG.debug(_(""Expected exception during message handling (%s)"") % e._exc_info[1]) return {'exc': rpc_common.serialize_remote_exception(e._exc_info, log_failure=False)} except Exception: LOG.error(_(""Exception during message handling"")) return {'exc': rpc_common.serialize_remote_exception(sys.exc_info())} def reply(self, ctx, proxy, msg_id=None, context=None, topic=None, msg=None): """"""Reply to a casted call."""""" # Our real method is curried into msg['args'] child_ctx = RpcContext.unmarshal(msg[0]) response = ConsumerBase.normalize_reply( self._get_response(child_ctx, proxy, topic, msg[1]), ctx.replies) LOG.debug(_(""Sending reply"")) _multi_send(_cast, ctx, topic, { 'method': '-process_reply', 'args': { 'msg_id': msg_id, # Include for Folsom compat. 'response': response } }, _msg_id=msg_id) class ConsumerBase(object): """"""Base Consumer."""""" def __init__(self): self.private_ctx = InternalContext(None) @classmethod def normalize_reply(self, result, replies): # TODO(ewindisch): re-evaluate and document this method. if isinstance(result, types.GeneratorType): return list(result) elif replies: return replies else: return [result] def process(self, proxy, ctx, data): data.setdefault('version', None) data.setdefault('args', {}) # Method starting with - are # processed internally. (non-valid method name) method = data.get('method') if not method: LOG.error(_(""RPC message did not include method."")) return # Internal method # uses internal context for safety. if method == '-reply': self.private_ctx.reply(ctx, proxy, **data['args']) return proxy.dispatch(ctx, data['version'], data['method'], **data['args']) class ZmqBaseReactor(ConsumerBase): """""" A consumer class implementing a centralized casting broker (PULL-PUSH) for RoundRobin requests. """""" def __init__(self, conf): super(ZmqBaseReactor, self).__init__() self.mapping = {} self.proxies = {} self.threads = [] self.sockets = [] self.subscribe = {} self.pool = eventlet.greenpool.GreenPool(conf.rpc_thread_pool_size) def register(self, proxy, in_addr, zmq_type_in, out_addr=None, zmq_type_out=None, in_bind=True, out_bind=True, subscribe=None): LOG.info(_(""Registering reactor"")) if zmq_type_in not in (zmq.PULL, zmq.SUB): raise RPCException(""Bad input socktype"") # Items push in. inq = ZmqSocket(in_addr, zmq_type_in, bind=in_bind, subscribe=subscribe) self.proxies[inq] = proxy self.sockets.append(inq) LOG.info(_(""In reactor registered"")) if not out_addr: return if zmq_type_out not in (zmq.PUSH, zmq.PUB): raise RPCException(""Bad output socktype"") # Items push out. outq = ZmqSocket(out_addr, zmq_type_out, bind=out_bind) self.mapping[inq] = outq self.mapping[outq] = inq self.sockets.append(outq) LOG.info(_(""Out reactor registered"")) def consume_in_thread(self): def _consume(sock): LOG.info(_(""Consuming socket"")) while True: self.consume(sock) for k in self.proxies.keys(): self.threads.append( self.pool.spawn(_consume, k) ) def wait(self): for t in self.threads: t.wait() def close(self): for s in self.sockets: s.close() for t in self.threads: t.kill() class ZmqProxy(ZmqBaseReactor): """""" A consumer class implementing a topic-based proxy, forwarding to IPC sockets. """""" def __init__(self, conf): super(ZmqProxy, self).__init__(conf) pathsep = set((os.path.sep or '', os.path.altsep or '', '/', '\\')) self.badchars = re.compile(r'[%s]' % re.escape(''.join(pathsep))) self.topic_proxy = {} def consume(self, sock): ipc_dir = CONF.rpc_zmq_ipc_dir # TODO(ewindisch): use zero-copy (i.e. references, not copying) data = sock.recv() topic = data[1] LOG.debug(_(""CONSUMER GOT %s""), ' '.join(map(pformat, data))) if topic.startswith('fanout~'): sock_type = zmq.PUB topic = topic.split('.', 1)[0] elif topic.startswith('zmq_replies'): sock_type = zmq.PUB else: sock_type = zmq.PUSH if topic not in self.topic_proxy: def publisher(waiter): LOG.info(_(""Creating proxy for topic: %s""), topic) try: # The topic is received over the network, # don't trust this input. if self.badchars.search(topic) is not None: emsg = _(""Topic contained dangerous characters."") LOG.warn(emsg) raise RPCException(emsg) out_sock = ZmqSocket(""ipc://%s/zmq_topic_%s"" % (ipc_dir, topic), sock_type, bind=True) except RPCException: waiter.send_exception(*sys.exc_info()) return self.topic_proxy[topic] = eventlet.queue.LightQueue( CONF.rpc_zmq_topic_backlog) self.sockets.append(out_sock) # It takes some time for a pub socket to open, # before we can have any faith in doing a send() to it. if sock_type == zmq.PUB: eventlet.sleep(.5) waiter.send(True) while(True): data = self.topic_proxy[topic].get() out_sock.send(data) LOG.debug(_(""ROUTER RELAY-OUT SUCCEEDED %(data)s"") % {'data': data}) wait_sock_creation = eventlet.event.Event() eventlet.spawn(publisher, wait_sock_creation) try: wait_sock_creation.wait() except RPCException: LOG.error(_(""Topic socket file creation failed."")) return try: self.topic_proxy[topic].put_nowait(data) LOG.debug(_(""ROUTER RELAY-OUT QUEUED %(data)s"") % {'data': data}) except eventlet.queue.Full: LOG.error(_(""Local per-topic backlog buffer full for topic "" ""%(topic)s. Dropping message."") % {'topic': topic}) def consume_in_thread(self): """"""Runs the ZmqProxy service"""""" ipc_dir = CONF.rpc_zmq_ipc_dir consume_in = ""tcp://%s:%s"" % \ (CONF.rpc_zmq_bind_address, CONF.rpc_zmq_port) consumption_proxy = InternalContext(None) if not os.path.isdir(ipc_dir): try: utils.execute('mkdir', '-p', ipc_dir, run_as_root=True) utils.execute('chown', ""%s:%s"" % (os.getuid(), os.getgid()), ipc_dir, run_as_root=True) utils.execute('chmod', '750', ipc_dir, run_as_root=True) except utils.ProcessExecutionError: with excutils.save_and_reraise_exception(): LOG.error(_(""Could not create IPC directory %s"") % (ipc_dir, )) try: self.register(consumption_proxy, consume_in, zmq.PULL, out_bind=True) except zmq.ZMQError: with excutils.save_and_reraise_exception(): LOG.error(_(""Could not create ZeroMQ receiver daemon. "" ""Socket may already be in use."")) super(ZmqProxy, self).consume_in_thread() def unflatten_envelope(packenv): """"""Unflattens the RPC envelope. Takes a list and returns a dictionary. i.e. [1,2,3,4] => {1: 2, 3: 4} """""" i = iter(packenv) h = {} try: while True: k = i.next() h[k] = i.next() except StopIteration: return h class ZmqReactor(ZmqBaseReactor): """""" A consumer class implementing a consumer for messages. Can also be used as a 1:1 proxy """""" def __init__(self, conf): super(ZmqReactor, self).__init__(conf) def consume(self, sock): # TODO(ewindisch): use zero-copy (i.e. references, not copying) data = sock.recv() LOG.debug(_(""CONSUMER RECEIVED DATA: %s""), data) if sock in self.mapping: LOG.debug(_(""ROUTER RELAY-OUT %(data)s"") % { 'data': data}) self.mapping[sock].send(data) return proxy = self.proxies[sock] if data[2] == 'cast': # Legacy protocol packenv = data[3] ctx, msg = _deserialize(packenv) request = rpc_common.deserialize_msg(msg) ctx = RpcContext.unmarshal(ctx) elif data[2] == 'impl_zmq_v2': packenv = data[4:] msg = unflatten_envelope(packenv) request = rpc_common.deserialize_msg(msg) # Unmarshal only after verifying the message. ctx = RpcContext.unmarshal(data[3]) else: LOG.error(_(""ZMQ Envelope version unsupported or unknown."")) return self.pool.spawn_n(self.process, proxy, ctx, request) class Connection(rpc_common.Connection): """"""Manages connections and threads."""""" def __init__(self, conf): self.topics = [] self.reactor = ZmqReactor(conf) def create_consumer(self, topic, proxy, fanout=False): # Register with matchmaker. _get_matchmaker().register(topic, CONF.rpc_zmq_host) # Subscription scenarios if fanout: sock_type = zmq.SUB subscribe = ('', fanout)[type(fanout) == str] topic = 'fanout~' + topic.split('.', 1)[0] else: sock_type = zmq.PULL subscribe = None topic = '.'.join((topic.split('.', 1)[0], CONF.rpc_zmq_host)) if topic in self.topics: LOG.info(_(""Skipping topic registration. Already registered."")) return # Receive messages from (local) proxy inaddr = ""ipc://%s/zmq_topic_%s"" % \ (CONF.rpc_zmq_ipc_dir, topic) LOG.debug(_(""Consumer is a zmq.%s""), ['PULL', 'SUB'][sock_type == zmq.SUB]) self.reactor.register(proxy, inaddr, sock_type, subscribe=subscribe, in_bind=False) self.topics.append(topic) def close(self): _get_matchmaker().stop_heartbeat() for topic in self.topics: _get_matchmaker().unregister(topic, CONF.rpc_zmq_host) self.reactor.close() self.topics = [] def wait(self): self.reactor.wait() def consume_in_thread(self): _get_matchmaker().start_heartbeat() self.reactor.consume_in_thread() def _cast(addr, context, topic, msg, timeout=None, envelope=False, _msg_id=None): timeout_cast = timeout or CONF.rpc_cast_timeout payload = [RpcContext.marshal(context), msg] with Timeout(timeout_cast, exception=rpc_common.Timeout): try: conn = ZmqClient(addr) # assumes cast can't return an exception conn.cast(_msg_id, topic, payload, envelope) except zmq.ZMQError: raise RPCException(""Cast failed. ZMQ Socket Exception"") finally: if 'conn' in vars(): conn.close() def _call(addr, context, topic, msg, timeout=None, envelope=False): # timeout_response is how long we wait for a response timeout = timeout or CONF.rpc_response_timeout # The msg_id is used to track replies. msg_id = uuid.uuid4().hex # Replies always come into the reply service. reply_topic = ""zmq_replies.%s"" % CONF.rpc_zmq_host LOG.debug(_(""Creating payload"")) # Curry the original request into a reply method. mcontext = RpcContext.marshal(context) payload = { 'method': '-reply', 'args': { 'msg_id': msg_id, 'context': mcontext, 'topic': reply_topic, 'msg': [mcontext, msg] } } LOG.debug(_(""Creating queue socket for reply waiter"")) # Messages arriving async. # TODO(ewindisch): have reply consumer with dynamic subscription mgmt with Timeout(timeout, exception=rpc_common.Timeout): try: msg_waiter = ZmqSocket( ""ipc://%s/zmq_topic_zmq_replies.%s"" % (CONF.rpc_zmq_ipc_dir, CONF.rpc_zmq_host), zmq.SUB, subscribe=msg_id, bind=False ) LOG.debug(_(""Sending cast"")) _cast(addr, context, topic, payload, envelope) LOG.debug(_(""Cast sent; Waiting reply"")) # Blocks until receives reply msg = msg_waiter.recv() LOG.debug(_(""Received message: %s""), msg) LOG.debug(_(""Unpacking response"")) if msg[2] == 'cast': # Legacy version raw_msg = _deserialize(msg[-1])[-1] elif msg[2] == 'impl_zmq_v2': rpc_envelope = unflatten_envelope(msg[4:]) raw_msg = rpc_common.deserialize_msg(rpc_envelope) else: raise rpc_common.UnsupportedRpcEnvelopeVersion( _(""Unsupported or unknown ZMQ envelope returned."")) responses = raw_msg['args']['response'] # ZMQError trumps the Timeout error. except zmq.ZMQError: raise RPCException(""ZMQ Socket Error"") except (IndexError, KeyError): raise RPCException(_(""RPC Message Invalid."")) finally: if 'msg_waiter' in vars(): msg_waiter.close() # It seems we don't need to do all of the following, # but perhaps it would be useful for multicall? # One effect of this is that we're checking all # responses for Exceptions. for resp in responses: if isinstance(resp, types.DictType) and 'exc' in resp: raise rpc_common.deserialize_remote_exception(CONF, resp['exc']) return responses[-1] def _multi_send(method, context, topic, msg, timeout=None, envelope=False, _msg_id=None): """""" Wraps the sending of messages, dispatches to the matchmaker and sends message to all relevant hosts. """""" conf = CONF LOG.debug(_(""%(msg)s"") % {'msg': ' '.join(map(pformat, (topic, msg)))}) queues = _get_matchmaker().queues(topic) LOG.debug(_(""Sending message(s) to: %s""), queues) # Don't stack if we have no matchmaker results if len(queues) == 0: LOG.warn(_(""No matchmaker results. Not casting."")) # While not strictly a timeout, callers know how to handle # this exception and a timeout isn't too big a lie. raise rpc_common.Timeout(_(""No match from matchmaker."")) # This supports brokerless fanout (addresses > 1) for queue in queues: (_topic, ip_addr) = queue _addr = ""tcp://%s:%s"" % (ip_addr, conf.rpc_zmq_port) if method.__name__ == '_cast': eventlet.spawn_n(method, _addr, context, _topic, msg, timeout, envelope, _msg_id) return return method(_addr, context, _topic, msg, timeout, envelope) def create_connection(conf, new=True): return Connection(conf) def multicall(conf, *args, **kwargs): """"""Multiple calls."""""" return _multi_send(_call, *args, **kwargs) def call(conf, *args, **kwargs): """"""Send a message, expect a response."""""" data = _multi_send(_call, *args, **kwargs) return data[-1] def cast(conf, *args, **kwargs): """"""Send a message expecting no reply."""""" _multi_send(_cast, *args, **kwargs) def fanout_cast(conf, context, topic, msg, **kwargs): """"""Send a message to all listening and expect no reply."""""" # NOTE(ewindisch): fanout~ is used because it avoid splitting on . # and acts as a non-subtle hint to the matchmaker and ZmqProxy. _multi_send(_cast, context, 'fanout~' + str(topic), msg, **kwargs) def notify(conf, context, topic, msg, envelope): """""" Send notification event. Notifications are sent to topic-priority. This differs from the AMQP drivers which send to topic.priority. """""" # NOTE(ewindisch): dot-priority in rpc notifier does not # work with our assumptions. topic = topic.replace('.', '-') cast(conf, context, topic, msg, envelope=envelope) def cleanup(): """"""Clean up resources in use by implementation."""""" global ZMQ_CTX if ZMQ_CTX: ZMQ_CTX.term() ZMQ_CTX = None global matchmaker matchmaker = None def _get_ctxt(): if not zmq: raise ImportError(""Failed to import eventlet.green.zmq"") global ZMQ_CTX if not ZMQ_CTX: ZMQ_CTX = zmq.Context(CONF.rpc_zmq_contexts) return ZMQ_CTX def _get_matchmaker(*args, **kwargs): global matchmaker if not matchmaker: matchmaker = importutils.import_object( CONF.rpc_zmq_matchmaker, *args, **kwargs) return matchmaker ",731,6232
openstack%2Fheat-translator~master~I9a0894d749ecf725dc3c805292f91d0e3fd9fe8a,openstack/heat-translator,master,I9a0894d749ecf725dc3c805292f91d0e3fd9fe8a,Added translation in dataentity module,MERGED,2015-06-18 21:38:37.000000000,2015-06-25 02:41:45.000000000,2015-06-25 02:41:43.000000000,"[{'_account_id': 3}, {'_account_id': 6456}, {'_account_id': 7514}, {'_account_id': 10068}, {'_account_id': 10295}]","[{'number': 1, 'created': '2015-06-18 21:38:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat-translator/commit/8791045223eee27b8b697567d8768b81dc95d368', 'message': 'Added translation for exceptions in dataentity.py\n\nAddded translation markers for exceptions in\n translator.toscalib.dataentity.py\n\nChange-Id: I9a0894d749ecf725dc3c805292f91d0e3fd9fe8a\nCloses-Bug: #1466655\n'}, {'number': 2, 'created': '2015-06-24 21:31:44.000000000', 'files': ['translator/toscalib/dataentity.py'], 'web_link': 'https://opendev.org/openstack/heat-translator/commit/00e6c8d0b152a29627856880ec85961aa8291837', 'message': 'Added translation in dataentity module\n\nAddressed translation needs for exceptions in dataentity\nmodule.\n\nChange-Id: I9a0894d749ecf725dc3c805292f91d0e3fd9fe8a\nCloses-Bug: #1466655\n'}]",1,193325,00e6c8d0b152a29627856880ec85961aa8291837,11,5,2,12974,,,0,"Added translation in dataentity module

Addressed translation needs for exceptions in dataentity
module.

Change-Id: I9a0894d749ecf725dc3c805292f91d0e3fd9fe8a
Closes-Bug: #1466655
",git fetch https://review.opendev.org/openstack/heat-translator refs/changes/25/193325/1 && git format-patch -1 --stdout FETCH_HEAD,['translator/toscalib/dataentity.py'],1,8791045223eee27b8b697567d8768b81dc95d368,newtests,from translator.toscalib.utils.gettextutils import _ raise UnknownFieldError(what=_('Data value of type %s') raise MissingRequiredFieldError(what=_('Data value of type %s'), raise UnknownFieldError(what='Data value of type %s' raise MissingRequiredFieldError(what='Data value of type %s',3,2
openstack%2Fkolla~master~If0223d18a2fbf12d2d6695f935aedfe4be517a15,openstack/kolla,master,If0223d18a2fbf12d2d6695f935aedfe4be517a15,Seperate check_required_vars one per line for Glance,ABANDONED,2015-06-22 14:02:06.000000000,2015-06-25 02:38:49.000000000,,"[{'_account_id': 3}, {'_account_id': 10428}]","[{'number': 1, 'created': '2015-06-22 14:02:06.000000000', 'files': ['docker/common/glance/glance-registry/start.sh', 'docker/common/glance/glance-api/start.sh', 'docker/common/glance/glance-base/config-glance.sh'], 'web_link': 'https://opendev.org/openstack/kolla/commit/03632974ecbdb8c6f21661c4085be9d50eba3a31', 'message': 'Seperate check_required_vars one per line for Glance\n\nThis layout along with sorting alphabetically makes it much easier to\nsee which vars are required and check for duplicates.\n\nChange-Id: If0223d18a2fbf12d2d6695f935aedfe4be517a15\nPartial-Bug: #1432336\n'}]",2,194152,03632974ecbdb8c6f21661c4085be9d50eba3a31,6,2,1,1390,,,0,"Seperate check_required_vars one per line for Glance

This layout along with sorting alphabetically makes it much easier to
see which vars are required and check for duplicates.

Change-Id: If0223d18a2fbf12d2d6695f935aedfe4be517a15
Partial-Bug: #1432336
",git fetch https://review.opendev.org/openstack/kolla refs/changes/52/194152/1 && git format-patch -1 --stdout FETCH_HEAD,"['docker/common/glance/glance-registry/start.sh', 'docker/common/glance/glance-api/start.sh', 'docker/common/glance/glance-base/config-glance.sh']",3,03632974ecbdb8c6f21661c4085be9d50eba3a31,bug/1432336,check_required_vars GLANCE_KEYSTONE_PASSWORD \ GLANCE_DB_PASSWORD,check_required_vars GLANCE_DB_PASSWORD GLANCE_KEYSTONE_PASSWORD,12,6
openstack%2Fkolla~master~Idfb93a91dbc6d8b9ecbc7a4bd8263b0306f2d3a4,openstack/kolla,master,Idfb93a91dbc6d8b9ecbc7a4bd8263b0306f2d3a4,Add all missing check_required_vars for Glance,ABANDONED,2015-06-22 14:37:43.000000000,2015-06-25 02:27:19.000000000,,"[{'_account_id': 3}, {'_account_id': 2834}, {'_account_id': 10419}, {'_account_id': 10428}]","[{'number': 1, 'created': '2015-06-22 14:37:43.000000000', 'files': ['docker/common/glance/glance-registry/start.sh', 'docker/common/glance/glance-api/start.sh', 'docker/common/glance/glance-base/config-glance.sh'], 'web_link': 'https://opendev.org/openstack/kolla/commit/ce5e15dd6b7c172820953d19b4068a16d401df4b', 'message': 'Add all missing check_required_vars for Glance\n\nChange-Id: Idfb93a91dbc6d8b9ecbc7a4bd8263b0306f2d3a4\nCloses-Bug: #1432336\n'}]",2,194166,ce5e15dd6b7c172820953d19b4068a16d401df4b,7,4,1,1390,,,0,"Add all missing check_required_vars for Glance

Change-Id: Idfb93a91dbc6d8b9ecbc7a4bd8263b0306f2d3a4
Closes-Bug: #1432336
",git fetch https://review.opendev.org/openstack/kolla refs/changes/66/194166/1 && git format-patch -1 --stdout FETCH_HEAD,"['docker/common/glance/glance-registry/start.sh', 'docker/common/glance/glance-api/start.sh', 'docker/common/glance/glance-base/config-glance.sh']",3,ce5e15dd6b7c172820953d19b4068a16d401df4b,bug/1432336,check_required_vars ADMIN_TENANT_NAME \ GLANCE_DB_NAME \ GLANCE_DB_PASSWORD \ GLANCE_DB_USER \ GLANCE_KEYSTONE_PASSWORD \ GLANCE_KEYSTONE_USER \ KEYSTONE_PUBLIC_SERVICE_HOST \ MARIADB_SERVICE_HOST,check_required_vars GLANCE_KEYSTONE_PASSWORD \ GLANCE_DB_PASSWORD,20,5
openstack%2Fkolla~master~I02d2aab2913356939d98b8c18f9e788ae6d901af,openstack/kolla,master,I02d2aab2913356939d98b8c18f9e788ae6d901af,Set up glance to use a data container.,MERGED,2015-06-15 21:03:36.000000000,2015-06-25 02:18:07.000000000,2015-06-25 02:18:06.000000000,"[{'_account_id': 3}, {'_account_id': 1390}, {'_account_id': 2011}, {'_account_id': 2834}, {'_account_id': 3098}, {'_account_id': 10419}, {'_account_id': 10428}, {'_account_id': 16520}]","[{'number': 1, 'created': '2015-06-15 21:03:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla/commit/8cf0583cbc257d23324b7fde97e80fc0f2042acb', 'message': 'Set up glance to use a data container.\n\nThe data was configured to be stored on the host but that was not\nworking well for our upgrades.  This change creates a data container\nto store images.\n\nCloses-bug: #1465401\n\nChange-Id: I02d2aab2913356939d98b8c18f9e788ae6d901af\nCo-Authored-By: Ryan Hallisey <rhallise@redhat.com>\n'}, {'number': 2, 'created': '2015-06-16 17:01:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla/commit/117c61ac11121245874837b9077427fc3e068894', 'message': 'Set up glance to use a data container.\n\nGlance images were originally intended to be stored on the host (see\ncontainer Dockerfile) but the compose file was not doing this.  The\nright thing is to use a data container for image content.\n\nCloses-bug: #1465401\n\nChange-Id: I02d2aab2913356939d98b8c18f9e788ae6d901af\nCo-Authored-By: Ryan Hallisey <rhallise@redhat.com>\n'}, {'number': 3, 'created': '2015-06-17 20:56:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla/commit/6090b61e6aa5941857d03fa1777c321833625574', 'message': 'Set up glance to use a data container.\n\nGlance images were originally intended to be stored on the host (see\ncontainer Dockerfile) but the compose file was not doing this.  The\nright thing is to use a data container for image content.\n\nCloses-bug: #1465401\n\nChange-Id: I02d2aab2913356939d98b8c18f9e788ae6d901af\nCo-Authored-By: Ryan Hallisey <rhallise@redhat.com>\n'}, {'number': 4, 'created': '2015-06-18 17:50:04.000000000', 'files': ['docker/centos/binary/glance/glance-api/Dockerfile', 'docker/glance/glance-data/build', 'compose/glance-api-registry.yml', 'docker/glance/glance-data/Dockerfile'], 'web_link': 'https://opendev.org/openstack/kolla/commit/2482f718f840dbea42f4c452238c5b096e1fd6b4', 'message': 'Set up glance to use a data container.\n\nGlance images were originally intended to be stored on the host (see\ncontainer Dockerfile) but the compose file was not doing this.  The\nright thing is to use a data container for image content.\n\nCloses-bug: #1465401\n\nChange-Id: I02d2aab2913356939d98b8c18f9e788ae6d901af\nCo-Authored-By: Ryan Hallisey <rhallise@redhat.com>\n'}]",16,191975,2482f718f840dbea42f4c452238c5b096e1fd6b4,31,8,4,2011,,,0,"Set up glance to use a data container.

Glance images were originally intended to be stored on the host (see
container Dockerfile) but the compose file was not doing this.  The
right thing is to use a data container for image content.

Closes-bug: #1465401

Change-Id: I02d2aab2913356939d98b8c18f9e788ae6d901af
Co-Authored-By: Ryan Hallisey <rhallise@redhat.com>
",git fetch https://review.opendev.org/openstack/kolla refs/changes/75/191975/4 && git format-patch -1 --stdout FETCH_HEAD,"['docker/centos/binary/glance/glance-api/Dockerfile', 'docker/glance/glance-data/build', 'compose/glance-api-registry.yml', 'docker/glance/glance-data/Dockerfile']",4,8cf0583cbc257d23324b7fde97e80fc0f2042acb,bug/1465401,"FROM %%KOLLA_NAMESPACE%%/%%KOLLA_PREFIX%%base:%%KOLLA_TAG%% MAINTAINER Kolla Project (https://launchpad.net/kolla) VOLUME [ ""/var/lib/glance"" ] # Command needed to start the data container. # Note: data containers do not need to be persistent. CMD [""/bin/true""] ",,16,2
openstack%2Fheat~master~I264e9e7ebe9de6aca116783a655a3efd9500c938,openstack/heat,master,I264e9e7ebe9de6aca116783a655a3efd9500c938,Fix heat-db-setup error on rhel7.1,MERGED,2015-06-24 07:46:04.000000000,2015-06-25 02:13:10.000000000,2015-06-24 23:50:46.000000000,"[{'_account_id': 3}, {'_account_id': 4715}, {'_account_id': 8246}]","[{'number': 1, 'created': '2015-06-24 07:46:04.000000000', 'files': ['bin/heat-db-setup'], 'web_link': 'https://opendev.org/openstack/heat/commit/7c5864ae37417b083de37b0f0b93ebc58c8580d6', 'message': ""Fix heat-db-setup error on rhel7.1\n\nIn bash, '-gt' can not work with flaot number.\n\nChange-Id: I264e9e7ebe9de6aca116783a655a3efd9500c938\nCloses-Bug: #1468217\n""}]",0,194973,7c5864ae37417b083de37b0f0b93ebc58c8580d6,9,3,1,7404,,,0,"Fix heat-db-setup error on rhel7.1

In bash, '-gt' can not work with flaot number.

Change-Id: I264e9e7ebe9de6aca116783a655a3efd9500c938
Closes-Bug: #1468217
",git fetch https://review.opendev.org/openstack/heat refs/changes/73/194973/1 && git format-patch -1 --stdout FETCH_HEAD,['bin/heat-db-setup'],1,7c5864ae37417b083de37b0f0b93ebc58c8580d6,bug/1468217, ver=`grep -E -o '[0-9]+' /etc/redhat-release| sed 1q`, ver=`grep -E -o '[0-9]+([.]?[0-9])*' /etc/redhat-release`,1,1
openstack%2Fastara~master~Icc424a67b63df5c730e8198fd04e30ecef00a6d6,openstack/astara,master,Icc424a67b63df5c730e8198fd04e30ecef00a6d6,Detangle config option registration,MERGED,2015-06-15 22:21:19.000000000,2015-06-25 01:51:36.000000000,2015-06-25 01:51:36.000000000,"[{'_account_id': 3}, {'_account_id': 6287}, {'_account_id': 6923}]","[{'number': 1, 'created': '2015-06-15 22:21:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/astara/commit/1c3549a0537180abb886f490b3cad8c92535beb0', 'message': 'Detangle config option registration\n\nConfig option registration currently happens in a big monolithic\nfunction register_and_load_opts().  This makes it really difficult to get\nsetup with a config test fixture, blocking some other work (ie: oslo.log)\n\nThis removes that and moves config option registration close to where the\nthings are actually used. In some places, this drops passing the config values\nto modules as function arguments, and instead relies on the cfg datastore\ninstead.\n\nChange-Id: Icc424a67b63df5c730e8198fd04e30ecef00a6d6\n'}, {'number': 2, 'created': '2015-06-15 22:23:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/astara/commit/8d4b0b30364d75bddf5b6eee467813e6e6ec4433', 'message': 'Detangle config option registration\n\nConfig option registration currently happens in a big monolithic\nfunction register_and_load_opts().  This makes it really difficult to get\nsetup with a config test fixture, blocking some other work (ie: oslo.log)\n\nThis removes that and moves config option registration close to where the\nthings are actually used. In some places, this drops passing the config values\nto modules as function arguments, and instead relies on the cfg datastore\ninstead.\n\nChange-Id: Icc424a67b63df5c730e8198fd04e30ecef00a6d6\n'}, {'number': 3, 'created': '2015-06-16 01:38:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/astara/commit/d35d5d0142b0a1f88a4437535bcf75b89d924d73', 'message': 'Detangle config option registration\n\nConfig option registration currently happens in a big monolithic\nfunction register_and_load_opts().  This makes it really difficult to get\nsetup with a config test fixture, blocking some other work (ie: oslo.log)\n\nThis removes that and moves config option registration close to where the\nthings are actually used. In some places, this drops passing the config values\nto modules as function arguments, and instead relies on the cfg datastore\ninstead.\n\nChange-Id: Icc424a67b63df5c730e8198fd04e30ecef00a6d6\n'}, {'number': 4, 'created': '2015-06-25 00:38:20.000000000', 'files': ['akanda/rug/test/unit/__init__.py', 'akanda/rug/test/unit/test_worker.py', 'akanda/rug/api/akanda_client.py', 'akanda/rug/notifications.py', 'akanda/rug/common/config.py', 'akanda/rug/test/unit/test_scheduler.py', 'akanda/rug/test/unit/test_debug.py', 'akanda/rug/worker.py', 'akanda/rug/cli/app.py', 'akanda/rug/common/linux/interface.py', 'akanda/rug/api/neutron.py', 'akanda/rug/debug.py', 'akanda/rug/scheduler.py', 'akanda/rug/api/__init__.py', 'akanda/rug/main.py', 'akanda/rug/test/unit/test_main.py', 'akanda/rug/vm_manager.py', 'akanda/rug/health.py', 'akanda/rug/metadata.py'], 'web_link': 'https://opendev.org/openstack/astara/commit/9625c93c45c0554400e9b562da002eec57449330', 'message': 'Detangle config option registration\n\nConfig option registration currently happens in a big monolithic\nfunction register_and_load_opts().  This makes it really difficult to get\nsetup with a config test fixture, blocking some other work (ie: oslo.log)\n\nThis removes that and moves config option registration close to where the\nthings are actually used. In some places, this drops passing the config values\nto modules as function arguments, and instead relies on the cfg datastore\ninstead.\n\nChange-Id: Icc424a67b63df5c730e8198fd04e30ecef00a6d6\n'}]",0,191993,9625c93c45c0554400e9b562da002eec57449330,13,3,4,1420,,,0,"Detangle config option registration

Config option registration currently happens in a big monolithic
function register_and_load_opts().  This makes it really difficult to get
setup with a config test fixture, blocking some other work (ie: oslo.log)

This removes that and moves config option registration close to where the
things are actually used. In some places, this drops passing the config values
to modules as function arguments, and instead relies on the cfg datastore
instead.

Change-Id: Icc424a67b63df5c730e8198fd04e30ecef00a6d6
",git fetch https://review.opendev.org/openstack/astara refs/changes/93/191993/4 && git format-patch -1 --stdout FETCH_HEAD,"['akanda/rug/test/unit/test_worker.py', 'akanda/rug/api/akanda_client.py', 'akanda/rug/notifications.py', 'akanda/rug/test/unit/test_scheduler.py', 'akanda/rug/worker.py', 'akanda/rug/common/linux/interface.py', 'akanda/rug/api/neutron.py', 'akanda/rug/scheduler.py', 'akanda/rug/api/__init__.py', 'akanda/rug/main.py', 'akanda/rug/vm_manager.py', 'akanda/rug/health.py', 'akanda/rug/metadata.py']",13,1c3549a0537180abb886f490b3cad8c92535beb0,rpc,CONF = cfg.CONF METADATA_OPTS = [CONF.register_opts(METADATA_OPTS),metadata_opts = [,230,281
openstack%2Fneutron~master~I0e3331f9a383fa2562706eeadb229f55593b888c,openstack/neutron,master,I0e3331f9a383fa2562706eeadb229f55593b888c,Support oslo_db 1.12,MERGED,2015-06-23 22:09:36.000000000,2015-06-25 01:51:12.000000000,2015-06-24 05:05:18.000000000,"[{'_account_id': 3}, {'_account_id': 5170}, {'_account_id': 6524}, {'_account_id': 6854}, {'_account_id': 7016}, {'_account_id': 7448}, {'_account_id': 9681}, {'_account_id': 9682}, {'_account_id': 9787}, {'_account_id': 9845}, {'_account_id': 10121}, {'_account_id': 10153}, {'_account_id': 10184}, {'_account_id': 10387}, {'_account_id': 14323}, {'_account_id': 14571}]","[{'number': 1, 'created': '2015-06-23 22:09:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/8b2efce67be90e4220536687ab0d28a78fe397aa', 'message': 'Use neutron context in brocade plugin\n\nChange-Id: I0e3331f9a383fa2562706eeadb229f55593b888c\n'}, {'number': 2, 'created': '2015-06-23 22:36:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/6f462bb3babee62b65e1a8a1567d5d0c3d27c3ac', 'message': 'Use neutron context in brocade plugin\n\nCurrently Brocade plugin tests are broken because Brocade plugin and its\nunittests try to set a read-only attribute (session). This change uses\nneutron.context instead of oslo_context.context in order to delegate\nsession management to the context and remove read-only attribute set.\n\nCloses-Bug: #1468128\nChange-Id: I0e3331f9a383fa2562706eeadb229f55593b888c\n'}, {'number': 3, 'created': '2015-06-23 23:34:03.000000000', 'files': ['neutron/tests/unit/plugins/brocade/test_brocade_vlan.py', 'neutron/plugins/brocade/NeutronPlugin.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/7eb9d9d316d35840706a767576ff083c9a04d781', 'message': ""Support oslo_db 1.12\n\noslo_db 1.12[1] decorates oslo_context.context.RequestContext with\nsession management[2][3] and add a read-only attribute 'session'. Such\nfeature breaks Brocade plugin and its unittests because they define\non RequestContext the 'session' attribute which now is a read-only\nproperty. This change uses neutron.context instead of\noslo_context.context in order to delegate session management to the\nneutron.context and remove read-only attribute set.\n\nA follow-up change will refactor neutron.context in order to use oslo_db\n1.12 session management instead of homemade one.\n\n[1] https://github.com/openstack/oslo.db/releases/tag/1.12.0\n[2] https://github.com/openstack/oslo.db/commit/\\\n    fdbd928b1fdf0334e1740e565ab8206fff54eaa6\n[3] https://github.com/openstack/oslo.db/blob/\\\n    fdbd928b1fdf0334e1740e565ab8206fff54eaa6/oslo_db/sqlalchemy/\\\n    enginefacade.py#L782\n\nCloses-Bug: #1468128\nChange-Id: I0e3331f9a383fa2562706eeadb229f55593b888c\n""}]",1,194844,7eb9d9d316d35840706a767576ff083c9a04d781,47,16,3,8124,,,0,"Support oslo_db 1.12

oslo_db 1.12[1] decorates oslo_context.context.RequestContext with
session management[2][3] and add a read-only attribute 'session'. Such
feature breaks Brocade plugin and its unittests because they define
on RequestContext the 'session' attribute which now is a read-only
property. This change uses neutron.context instead of
oslo_context.context in order to delegate session management to the
neutron.context and remove read-only attribute set.

A follow-up change will refactor neutron.context in order to use oslo_db
1.12 session management instead of homemade one.

[1] https://github.com/openstack/oslo.db/releases/tag/1.12.0
[2] https://github.com/openstack/oslo.db/commit/\
    fdbd928b1fdf0334e1740e565ab8206fff54eaa6
[3] https://github.com/openstack/oslo.db/blob/\
    fdbd928b1fdf0334e1740e565ab8206fff54eaa6/oslo_db/sqlalchemy/\
    enginefacade.py#L782

Closes-Bug: #1468128
Change-Id: I0e3331f9a383fa2562706eeadb229f55593b888c
",git fetch https://review.opendev.org/openstack/neutron refs/changes/44/194844/1 && git format-patch -1 --stdout FETCH_HEAD,"['neutron/tests/unit/plugins/brocade/test_brocade_vlan.py', 'neutron/plugins/brocade/NeutronPlugin.py']",2,8b2efce67be90e4220536687ab0d28a78fe397aa,bug/1468128,"from neutron import context as n_context self.ctxt = n_context.get_admin_context() self.rpc_context = n_context.ContextBase('neutron', 'neutron', is_admin=False)","from oslo_context import context as oslo_context self.ctxt = oslo_context.get_admin_context() self.ctxt.session = db.get_session() self.rpc_context = oslo_context.RequestContext('neutron', 'neutron', is_admin=False)",6,9
openstack%2Fkolla~master~I26acd90ca9f4a48673a95b0ab8e331f620058f6e,openstack/kolla,master,I26acd90ca9f4a48673a95b0ab8e331f620058f6e,Minor doc fixups in dev-quickstart.md,MERGED,2015-06-11 08:34:11.000000000,2015-06-25 01:39:13.000000000,2015-06-25 01:39:10.000000000,"[{'_account_id': 3}, {'_account_id': 2834}, {'_account_id': 3098}, {'_account_id': 10419}, {'_account_id': 16520}]","[{'number': 1, 'created': '2015-06-11 08:34:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla/commit/3a25d1778b68857e2fa84294f0b3795765e0d73c', 'message': 'Minor doc fixups in dev-quickstart.md\n\n* Capitalise all usages of ""Ansible"", ""Kolla"", and ""OpenStack""\n* Fix some typos\n\nChange-Id: I26acd90ca9f4a48673a95b0ab8e331f620058f6e\n'}, {'number': 2, 'created': '2015-06-19 09:56:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla/commit/682f6c1944c9dac75c0e4811421ef1207e772f4f', 'message': 'Minor doc fixups in dev-quickstart.md\n\n* Capitalise all usages of ""Ansible"", ""Kolla"", and ""OpenStack""\n* Fix some typos\n\nChange-Id: I26acd90ca9f4a48673a95b0ab8e331f620058f6e\n'}, {'number': 3, 'created': '2015-06-19 16:11:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla/commit/4ddfd5eb82c3dbcfc23f9bd7fcd8a38999297ee4', 'message': 'Minor doc fixups in dev-quickstart.md\n\n* Capitalise all usages of ""Ansible"", ""Kolla"", and ""OpenStack""\n* Fix some typos\n\nChange-Id: I26acd90ca9f4a48673a95b0ab8e331f620058f6e\n'}, {'number': 4, 'created': '2015-06-22 08:57:33.000000000', 'files': ['docs/dev-quickstart.md'], 'web_link': 'https://opendev.org/openstack/kolla/commit/247095a0d33406cd173ca591afaae6b20d36e129', 'message': 'Minor doc fixups in dev-quickstart.md\n\n* Capitalise all usages of ""Ansible"", ""Kolla"", and ""OpenStack""\n* Fix some typos\n\nChange-Id: I26acd90ca9f4a48673a95b0ab8e331f620058f6e\n'}]",0,190543,247095a0d33406cd173ca591afaae6b20d36e129,20,5,4,1390,,,0,"Minor doc fixups in dev-quickstart.md

* Capitalise all usages of ""Ansible"", ""Kolla"", and ""OpenStack""
* Fix some typos

Change-Id: I26acd90ca9f4a48673a95b0ab8e331f620058f6e
",git fetch https://review.opendev.org/openstack/kolla refs/changes/43/190543/4 && git format-patch -1 --stdout FETCH_HEAD,['docs/dev-quickstart.md'],1,3a25d1778b68857e2fa84294f0b3795765e0d73c,doc-fixups," sudo yum install python-keystoneclient python-glanceclient \ python-novaclient python-heatclient python-neutronclientThis environment will start up the OpenStack services listed in theexample with an Intel driver, the interface is enp1s0. The interface nameThe `start` command to Kolla is responsible for starting the containers"," sudo yum install python-keystoneclient python-glanceclient \ python-novaclient python-heatclient python-neutronclientThis environment will start up the openstack services listed in theexmaple with an Intel driver, the interface is enp1s0. The interface nameThe `start` command to kolla is responsible for starting the containers",5,5
openstack%2Fproject-config~master~I0c2402979432e86c7a3ba4ba705486db74ea4db9,openstack/project-config,master,I0c2402979432e86c7a3ba4ba705486db74ea4db9,Do not set ZUUL_REF to a valid value on devstack checkout,MERGED,2015-06-24 16:37:14.000000000,2015-06-25 01:20:46.000000000,2015-06-25 01:20:44.000000000,"[{'_account_id': 1}, {'_account_id': 3}, {'_account_id': 2750}, {'_account_id': 4146}, {'_account_id': 5263}]","[{'number': 1, 'created': '2015-06-24 16:37:14.000000000', 'files': ['jenkins/jobs/macros.yaml'], 'web_link': 'https://opendev.org/openstack/project-config/commit/b77cbc181c1efdfe5bdb5a4ae7ddf789b3a9c90e', 'message': 'Do not set ZUUL_REF to a valid value on devstack checkout\n\nZuul mergers do not keep all repository-branches up to date all of\nthe time.  Instead, they are current only under two conditions:\n\n1) if the zuul ref is refs/zuul/.* and they have that ref\n2) if the zuul ref is anything and the project matches zuul_project\n\nCondition 1 is true during tests on changes, condition 2 is true\nfor tags and timers.\n\nHowever, this job runs on the ""tempest"" project, meaning that\nneither of the conditions above hold, and therefore zuul mergers\nshould not be used to check out the repositories.  However, because\nwe gave zuul-cloner a ref that actually is in a merger repo\n(""master""), it behaved as if condition 1 were true and checked it\nout.  Instead, give it an invalid ref so that it falls back to the\ncanonical git repository to get the correct master branch-tip.\n\nChange-Id: I0c2402979432e86c7a3ba4ba705486db74ea4db9\n'}]",0,195185,b77cbc181c1efdfe5bdb5a4ae7ddf789b3a9c90e,18,5,1,1,,,0,"Do not set ZUUL_REF to a valid value on devstack checkout

Zuul mergers do not keep all repository-branches up to date all of
the time.  Instead, they are current only under two conditions:

1) if the zuul ref is refs/zuul/.* and they have that ref
2) if the zuul ref is anything and the project matches zuul_project

Condition 1 is true during tests on changes, condition 2 is true
for tags and timers.

However, this job runs on the ""tempest"" project, meaning that
neither of the conditions above hold, and therefore zuul mergers
should not be used to check out the repositories.  However, because
we gave zuul-cloner a ref that actually is in a merger repo
(""master""), it behaved as if condition 1 were true and checked it
out.  Instead, give it an invalid ref so that it falls back to the
canonical git repository to get the correct master branch-tip.

Change-Id: I0c2402979432e86c7a3ba4ba705486db74ea4db9
",git fetch https://review.opendev.org/openstack/project-config refs/changes/85/195185/1 && git format-patch -1 --stdout FETCH_HEAD,['jenkins/jobs/macros.yaml'],1,b77cbc181c1efdfe5bdb5a4ae7ddf789b3a9c90e,, export ZUUL_REF=${ZUUL_REF:-None}, export ZUUL_REF=${ZUUL_REF:-master},1,1
openstack%2Ffuturist~master~I0bee6912830b88de3d75e543689c54fd02801dd5,openstack/futurist,master,I0bee6912830b88de3d75e543689c54fd02801dd5,Allow providing customized scheduling strategies,MERGED,2015-06-12 17:42:54.000000000,2015-06-25 01:14:33.000000000,2015-06-25 01:14:31.000000000,"[{'_account_id': 3}, {'_account_id': 1297}, {'_account_id': 5638}]","[{'number': 1, 'created': '2015-06-12 17:42:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/futurist/commit/8f5a5a0cffd448dc44d20cb00267c5fe283b80e6', 'message': ""Allow providing customized scheduling strategies\n\nInstead of fixing on having a scheduling strategy that\nuses the last time the callback started + the callbacks\nduration as the next time the callback should run allow\nfor providing a customized callback 'strategy' that can\nbe used to provide different ways of determining when a\ncallback should run (given up-to 10 metrics about its\nprior runs).\n\nChange-Id: I0bee6912830b88de3d75e543689c54fd02801dd5\n""}, {'number': 2, 'created': '2015-06-12 18:11:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/futurist/commit/437e67210eef60c0e77a362afae5363713b05e4d', 'message': ""Allow providing customized scheduling strategies\n\nInstead of fixing on having a scheduling strategy that\nuses the last time the callback started + the callbacks\nperiodicity as the next time the callback should run allow\nfor providing a customized callback 'strategy' that can\nbe used to provide different ways of determining when a\ncallback should run (given up-to 10 metrics about its\nprior runs).\n\nChange-Id: I0bee6912830b88de3d75e543689c54fd02801dd5\n""}, {'number': 3, 'created': '2015-06-13 01:03:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/futurist/commit/23d3fd88cf5da3faad770fd5bde58bdc511ff22a', 'message': ""Allow providing customized scheduling strategies\n\nInstead of fixing on having a scheduling strategy that\nuses the last time the callback started + the callbacks\nperiodicity as the next time the callback should run allow\nfor providing a customized callback 'strategy' that can\nbe used to provide different ways of determining when a\ncallback should run (given up-to 10 metrics about its\nprior runs).\n\nChange-Id: I0bee6912830b88de3d75e543689c54fd02801dd5\n""}, {'number': 4, 'created': '2015-06-13 01:08:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/futurist/commit/30917b53c703d855ad324d56091ff14fc394139b', 'message': ""Allow providing customized scheduling strategies\n\nInstead of fixing on having a scheduling strategy that\nuses the last time the callback started + the callbacks\nperiodicity as the next time the callback should run allow\nfor providing a customized callback 'strategy' that can\nbe used to provide different ways of determining when a\ncallback should run (given up-to 10 metrics about its\nprior runs).\n\nChange-Id: I0bee6912830b88de3d75e543689c54fd02801dd5\n""}, {'number': 5, 'created': '2015-06-13 01:42:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/futurist/commit/a012d70c01c6dda42cd4c933b70e416bc1158a4b', 'message': ""Allow providing customized scheduling strategies\n\nInstead of fixing on having a scheduling strategy that\nuses the last time the callback started + the callbacks\nperiodicity as the next time the callback should run allow\nfor providing a customized callback 'strategy' that can\nbe used to provide different ways of determining when a\ncallback should run (given up-to 10 metrics about its\nprior runs).\n\nThis adds 4 built-in strategies that can be used to\naid in picking when next runs will happen.\n\nChange-Id: I0bee6912830b88de3d75e543689c54fd02801dd5\n""}, {'number': 6, 'created': '2015-06-13 01:56:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/futurist/commit/e548522ba9edb7f51c6967c73bb82b32ecfe8d05', 'message': ""Allow providing customized scheduling strategies\n\nInstead of fixing on having a scheduling strategy that\nuses the last time the callback started + the callbacks\nperiodicity as the next time the callback should run allow\nfor providing a customized callback 'strategy' that can\nbe used to provide different ways of determining when a\ncallback should run (given up-to 10 metrics about its\nprior runs).\n\nThis adds 4 built-in strategies that can be used to\naid in picking when next runs will happen.\n\nChange-Id: I0bee6912830b88de3d75e543689c54fd02801dd5\n""}, {'number': 7, 'created': '2015-06-13 03:15:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/futurist/commit/4887c1a5e227a0ee60342323eb0409869c64429d', 'message': ""Allow providing customized scheduling strategies\n\nInstead of fixing on having a scheduling strategy that\nuses the last time the callback started + the callbacks\nperiodicity as the next time the callback should run allow\nfor providing a customized callback 'strategy' that can\nbe used to provide different ways of determining when a\ncallback should run (given up-to 10 metrics about its\nprior runs).\n\nThis adds 4 built-in strategies that can be used to\naid in picking when next runs will happen.\n\nChange-Id: I0bee6912830b88de3d75e543689c54fd02801dd5\n""}, {'number': 8, 'created': '2015-06-13 18:28:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/futurist/commit/655806031f8d0ff7da4b8c4c6d2ff718b59114bf', 'message': ""Allow providing customized scheduling strategies\n\nInstead of fixing on having a scheduling strategy that\nuses the last time the callback started + the callbacks\nperiodicity as the next time the callback should run allow\nfor providing a customized callback 'strategy' that can\nbe used to provide different ways of determining when a\ncallback should run (given up-to 10 metrics about its\nprior runs).\n\nThis adds 4 built-in strategies that can be used to\naid in picking when next runs will happen.\n\nChange-Id: I0bee6912830b88de3d75e543689c54fd02801dd5\n""}, {'number': 9, 'created': '2015-06-14 17:35:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/futurist/commit/89b80ca2b6c232fe6d7c16fc6d2e971f7966030a', 'message': ""Allow providing customized scheduling strategies\n\nInstead of fixing on having a scheduling strategy that\nuses the last time the callback started + the callbacks\nperiodicity as the next time the callback should run allow\nfor providing a customized callback 'strategy' that can\nbe used to provide different ways of determining when a\ncallback should run (given up-to 10 metrics about its\nprior runs).\n\nThis adds 4 built-in strategies that can be used to\naid in picking when next runs will happen.\n\nChange-Id: I0bee6912830b88de3d75e543689c54fd02801dd5\n""}, {'number': 10, 'created': '2015-06-18 22:16:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/futurist/commit/3c92398c185e4180bfd30b4467dfadff3baf1432', 'message': ""Allow providing customized scheduling strategies\n\nInstead of fixing on having a scheduling strategy that\nuses the last time the callback started + the callbacks\nperiodicity as the next time the callback should run allow\nfor providing a customized callback 'strategy' that can\nbe used to provide different ways of determining when a\ncallback should run (given up-to 10 metrics about its\nprior runs).\n\nThis adds 4 built-in strategies that can be used to\naid in picking when next runs will happen.\n\nChange-Id: I0bee6912830b88de3d75e543689c54fd02801dd5\n""}, {'number': 11, 'created': '2015-06-19 00:09:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/futurist/commit/15ced609cba20eab0eadb7614ffc7be6af6f8de4', 'message': ""Allow providing customized scheduling strategies\n\nInstead of fixing on having a scheduling strategy that\nuses the last time the callback started + the callbacks\nperiodicity as the next time the callback should run allow\nfor providing a customized callback 'strategy' that can\nbe used to provide different ways of determining when a\ncallback should run (given metrics about prior runs).\n\nThis adds 4 built-in strategies that can be used to\naid in picking when next runs will happen.\n\nChange-Id: I0bee6912830b88de3d75e543689c54fd02801dd5\n""}, {'number': 12, 'created': '2015-06-19 00:10:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/futurist/commit/d089dbb1a747fcdc7d1f4b1af4f0dd39788df3ef', 'message': ""Allow providing customized scheduling strategies\n\nInstead of fixing on having a scheduling strategy that\nuses the last time the callback started + the callbacks\nperiodicity as the next time the callback should run allow\nfor providing a customized callback 'strategy' that can\nbe used to provide different ways of determining when a\ncallback should run (given metrics about prior runs).\n\nThis adds 4 built-in strategies that can be used to\naid in picking when next runs will happen.\n\nChange-Id: I0bee6912830b88de3d75e543689c54fd02801dd5\n""}, {'number': 13, 'created': '2015-06-19 01:03:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/futurist/commit/0ab752d510fccb84bab4960855312e5abec74f14', 'message': ""Allow providing customized scheduling strategies\n\nInstead of fixing on having a scheduling strategy that\nuses the last time the callback started + the callbacks\nperiodicity as the next time the callback should run allow\nfor providing a customized callback 'strategy' that can\nbe used to provide different ways of determining when a\ncallback should run (given metrics about prior runs).\n\nThis adds 4 built-in strategies that can be used to\naid in picking when next runs will happen.\n\nChange-Id: I0bee6912830b88de3d75e543689c54fd02801dd5\n""}, {'number': 14, 'created': '2015-06-19 01:08:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/futurist/commit/defe03423815c37db18ad181c3db21c7899b3f5d', 'message': ""Allow providing customized scheduling strategies\n\nInstead of fixing on having a scheduling strategy that\nuses the last time the callback started + the callbacks\nperiodicity as the next time the callback should run allow\nfor providing a customized callback 'strategy' that can\nbe used to provide different ways of determining when a\ncallback should run (given metrics about prior runs).\n\nThis adds 4 built-in strategies that can be used to\naid in picking when next runs will happen.\n\nChange-Id: I0bee6912830b88de3d75e543689c54fd02801dd5\n""}, {'number': 15, 'created': '2015-06-19 04:38:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/futurist/commit/01b2c09dbe480b2c9957cdf619b10e1367510d6c', 'message': ""Allow providing customized scheduling strategies\n\nInstead of fixing on having a scheduling strategy that\nuses the last time the callback started + the callbacks\nperiodicity as the next time the callback should run allow\nfor providing a customized callback 'strategy' that can\nbe used to provide different ways of determining when a\ncallback should run (given metrics about prior runs).\n\nThis adds 4 built-in strategies that can be used to\naid in picking when next runs will happen. It also adds\na enhanced metrics output that happens when the periodic\nworker finishes (using prettytable to dump the metrics\ndata).\n\nChange-Id: I0bee6912830b88de3d75e543689c54fd02801dd5\n""}, {'number': 16, 'created': '2015-06-19 18:04:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/futurist/commit/2c7d74a63d3192e363f499d826e6014339b044f7', 'message': ""Allow providing customized scheduling strategies\n\nInstead of fixing on having a scheduling strategy that\nuses the last time the callback started + the callbacks\nperiodicity as the next time the callback should run allow\nfor providing a customized callback 'strategy' that can\nbe used to provide different ways of determining when a\ncallback should run (given metrics about prior runs).\n\nThis adds 4 built-in strategies that can be used to\naid in picking when next runs will happen. It also adds\na enhanced metrics output that happens when the periodic\nworker finishes.\n\nChange-Id: I0bee6912830b88de3d75e543689c54fd02801dd5\n""}, {'number': 17, 'created': '2015-06-23 01:01:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/futurist/commit/d6f5b1193e51e7e4bb3ee0b8c6c2c09e61ccac17', 'message': ""Allow providing customized scheduling strategies\n\nInstead of fixing on having a scheduling strategy that\nuses the last time the callback started + the callbacks\nperiodicity as the next time the callback should run allow\nfor providing a customized callback 'strategy' that can\nbe used to provide different ways of determining when a\ncallback should run (given metrics about prior runs).\n\nThis adds 4 built-in strategies that can be used to\naid in picking when next runs will happen. It also adds\na enhanced metrics output that happens when the periodic\nworker finishes.\n\nChange-Id: I0bee6912830b88de3d75e543689c54fd02801dd5\n""}, {'number': 18, 'created': '2015-06-24 19:25:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/futurist/commit/22d32f2cbcb5525cc87e7b8c53a541bbc9e76a4b', 'message': ""Allow providing customized scheduling strategies\n\nInstead of fixing on having a scheduling strategy that\nuses the last time the callback started + the callbacks\nperiodicity as the next time the callback should run allow\nfor providing a customized callback 'strategy' that can\nbe used to provide different ways of determining when a\ncallback should run (given metrics about prior runs).\n\nThis adds 4 built-in strategies that can be used to\naid in picking when next runs will happen. It also adds\na enhanced metrics output that happens when the periodic\nworker finishes.\n\nChange-Id: I0bee6912830b88de3d75e543689c54fd02801dd5\n""}, {'number': 19, 'created': '2015-06-24 19:32:37.000000000', 'files': ['futurist/periodics.py', 'futurist/tests/test_periodics.py'], 'web_link': 'https://opendev.org/openstack/futurist/commit/bf31e28f2147c92f8b8df190f5efe1dfd1270ed4', 'message': ""Allow providing customized scheduling strategies\n\nInstead of fixing on having a scheduling strategy that\nuses the last time the callback started + the callbacks\nperiodicity as the next time the callback should run allow\nfor providing a customized callback 'strategy' that can\nbe used to provide different ways of determining when a\ncallback should run (given metrics about prior runs).\n\nThis adds 4 built-in strategies that can be used to\naid in picking when next runs will happen. It also adds\na enhanced metrics output that happens when the periodic\nworker finishes.\n\nChange-Id: I0bee6912830b88de3d75e543689c54fd02801dd5\n""}]",1,191163,bf31e28f2147c92f8b8df190f5efe1dfd1270ed4,47,3,19,1297,,,0,"Allow providing customized scheduling strategies

Instead of fixing on having a scheduling strategy that
uses the last time the callback started + the callbacks
periodicity as the next time the callback should run allow
for providing a customized callback 'strategy' that can
be used to provide different ways of determining when a
callback should run (given metrics about prior runs).

This adds 4 built-in strategies that can be used to
aid in picking when next runs will happen. It also adds
a enhanced metrics output that happens when the periodic
worker finishes.

Change-Id: I0bee6912830b88de3d75e543689c54fd02801dd5
",git fetch https://review.opendev.org/openstack/futurist refs/changes/63/191163/13 && git format-patch -1 --stdout FETCH_HEAD,['futurist/periodics.py'],1,8f5a5a0cffd448dc44d20cb00267c5fe283b80e6,customized-scheduling-strategies,"import collectionsdef _last_started_strategy(cb, metrics, now=None): # Determine when the callback should next run based on when it was # last started **only** given metrics about this information (or if no # metrics, then the current time as the last time it ran instead). how_often = cb._periodic_spacing try: started_at, _finished_at, _elapsed = metrics[-1] return started_at + how_often except IndexError: if now is None: now = _utils.now() return now + how_often def _build(callables, strategy): for index, (cb, args, kwargs) in _utils.reverse_enumerate(callables): if cb._periodic_run_immediately: immediates.append(index) next_run = strategy(cb, [], now=now) schedule.push(next_run, index) _CB_HISTORY_LIMIT = 10 cond_cls=threading.Condition, event_cls=threading.Event, schedule_strategy=None): :param schedule_strategy: callable object that can return the next time a callable should run given the callback, metrics about its prior runs and optionally the current time, by default if none is provided then a default strategy is selected that uses the callabacks last start time to determine when it should next run :type schedule_strategy: callable cond_cls=cond_cls, event_cls=event_cls, schedule_strategy=schedule_strategy) cond_cls=threading.Condition, event_cls=threading.Event, schedule_strategy=None): :param schedule_strategy: callable object that can return the next time a callable should run given the callback, metrics about its prior runs and optionally the current time, by default if none is provided then a default strategy is selected that uses the callabacks last start time to determine when it should next run :type schedule_strategy: callable self._metrics = [] self._metrics.append( collections.deque(maxlen=self._CB_HISTORY_LIMIT)) if schedule_strategy is None: schedule_strategy = _last_started_strategy self._schedule_strategy = schedule_strategy self._immediates, self._schedule = _build(self._callables, self._schedule_strategy) def _on_done(kind, cb, index, started_at, fut): finished_at = _utils.now() elapsed = max(0, finished_at - started_at) metrics = self._metrics[index] metrics.append((started_at, finished_at, elapsed)) next_run = self._schedule_strategy(cb, metrics, now=finished_at) with self._waiter: self._schedule.push(next_run, index) started_at = _utils.now() started_at)) started_at = _utils.now() when_next = next_run - started_at started_at))"," def push_next(self, cb, index, now=None): if now is None: now = _utils.now() next_run = now + cb._periodic_spacing self.push(next_run, index) def _build(callables): for i, (cb, args, kwargs) in _utils.reverse_enumerate(callables): if cb._periodic_run_immediately: immediates.append(i) schedule.push_next(cb, i, now=now) cond_cls=threading.Condition, event_cls=threading.Event): cond_cls=cond_cls, event_cls=event_cls) cond_cls=threading.Condition, event_cls=threading.Event): self._immediates, self._schedule = _build(self._callables) def _on_done(kind, cb, index, fut, now=None): with self._waiter: self._schedule.push_next(cb, index, now=now) now = _utils.now() # Note that we are providing the time that it started # at, so this implies that the rescheduling time will # *not* take into account how long it took to actually # run the callback... (for better or worse). now=now)) now = _utils.now() when_next = next_run - now # Note that we are providing the time that it started # at, so this implies that the rescheduling time will # *not* take into account how long it took to actually # run the callback... (for better or worse). now=now))",66,29
openstack%2Fcue~master~I621c86b954a2e99729b14bced7ad746725ed2148,openstack/cue,master,I621c86b954a2e99729b14bced7ad746725ed2148,DO NOT MERGE - Rally job CI Gate testing,ABANDONED,2015-06-15 20:09:10.000000000,2015-06-25 01:01:03.000000000,,"[{'_account_id': 3}, {'_account_id': 13771}]","[{'number': 1, 'created': '2015-06-15 20:09:10.000000000', 'files': ['rally-jobs/plugins/clusters.py'], 'web_link': 'https://opendev.org/openstack/cue/commit/9d1f5669c79bf60172cd5bd8013a636cb03fe87e', 'message': 'DO NOT MERGE - Rally job CI Gate testing\n\nChange-Id: I621c86b954a2e99729b14bced7ad746725ed2148\n'}]",0,191959,9d1f5669c79bf60172cd5bd8013a636cb03fe87e,8,2,1,13771,,,0,"DO NOT MERGE - Rally job CI Gate testing

Change-Id: I621c86b954a2e99729b14bced7ad746725ed2148
",git fetch https://review.opendev.org/openstack/cue refs/changes/59/191959/1 && git format-patch -1 --stdout FETCH_HEAD,['rally-jobs/plugins/clusters.py'],1,9d1f5669c79bf60172cd5bd8013a636cb03fe87e,rally_ci_test," """"""Creates a new cue cluster - testing rally job."," """"""Creates a new cue cluster.",1,1
openstack%2Fopenstack-manuals~master~Idb3b1a318b0f9b9d44875e60b7c42bb7021396ef,openstack/openstack-manuals,master,Idb3b1a318b0f9b9d44875e60b7c42bb7021396ef,Converts section_multi_backend.xml to RST,MERGED,2015-06-24 12:47:50.000000000,2015-06-25 01:01:02.000000000,2015-06-25 01:01:00.000000000,"[{'_account_id': 3}, {'_account_id': 6547}, {'_account_id': 10497}, {'_account_id': 10607}, {'_account_id': 10705}, {'_account_id': 12686}, {'_account_id': 14947}, {'_account_id': 14962}]","[{'number': 1, 'created': '2015-06-24 12:47:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/0f5bba0c73055171cf8e42006a4b244faf2d4bd8', 'message': 'Converts section_multi_backend.xml to RST\n\nThis patch converts blockstorage/section_multi_backend.xml\n to blockstorage_multi_backend.rst\n\nChange-Id: Idb3b1a318b0f9b9d44875e60b7c42bb7021396ef\nImplements: blueprint reorganise-user-guides\n'}, {'number': 2, 'created': '2015-06-24 14:17:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/271b8f67871c3396387a20b1536fdbf599c84c10', 'message': 'Converts section_multi_backend.xml to RST\n\nThis patch:\n- converts blockstorage/section_multi_backend.xml\n to blockstorage_multi_backend.rst\n- fixes :orphan: in blockstorage_glusterfs_backend.rst\n\nChange-Id: Idb3b1a318b0f9b9d44875e60b7c42bb7021396ef\nImplements: blueprint reorganise-user-guides\n'}, {'number': 3, 'created': '2015-06-24 14:35:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/bcb2b86b85539c6b38e9f444b0a678cb78b49b43', 'message': 'Converts section_multi_backend.xml to RST\n\nThis patch:\n- converts blockstorage/section_multi_backend.xml\n to blockstorage_multi_backend.rst\n- Deletes :orphan: in blockstorage_glusterfs_backend.rst\nas it works without it.\n\nChange-Id: Idb3b1a318b0f9b9d44875e60b7c42bb7021396ef\nImplements: blueprint reorganise-user-guides\n'}, {'number': 4, 'created': '2015-06-24 14:46:47.000000000', 'files': ['doc/admin-guide-cloud-rst/source/blockstorage.rst', 'doc/admin-guide-cloud-rst/source/blockstorage_multi_backend.rst', 'doc/admin-guide-cloud-rst/source/blockstorage_glusterfs_backend.rst'], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/23fa332bf448d9e6a3b87580b2ec8f9491b88f3c', 'message': 'Converts section_multi_backend.xml to RST\n\nThis patch:\n- converts blockstorage/section_multi_backend.xml\n to blockstorage_multi_backend.rst\n- Deletes :orphan: in blockstorage_glusterfs_backend.rst\nas it works without it.\n\nChange-Id: Idb3b1a318b0f9b9d44875e60b7c42bb7021396ef\nImplements: blueprint reorganise-user-guides\n'}]",7,195061,23fa332bf448d9e6a3b87580b2ec8f9491b88f3c,27,8,4,14947,,,0,"Converts section_multi_backend.xml to RST

This patch:
- converts blockstorage/section_multi_backend.xml
 to blockstorage_multi_backend.rst
- Deletes :orphan: in blockstorage_glusterfs_backend.rst
as it works without it.

Change-Id: Idb3b1a318b0f9b9d44875e60b7c42bb7021396ef
Implements: blueprint reorganise-user-guides
",git fetch https://review.opendev.org/openstack/openstack-manuals refs/changes/61/195061/4 && git format-patch -1 --stdout FETCH_HEAD,"['doc/admin-guide-cloud-rst/source/blockstorage.rst', 'doc/admin-guide-cloud-rst/source/blockstorage_multi_backend.rst']",2,0f5bba0c73055171cf8e42006a4b244faf2d4bd8,bp/reorganise-user-guides,".. _multi_backend: .. highlight: ini :linenothreshold: 5 .. orphan: Configure multiple-storage back ends ------------------------------------ When you configure multiple-storage back ends, you can create several back-end storage solutions that serve the same OpenStack Compute configuration and one ``cinder-volume`` is launched for each back-end storage or back-end storage pool. In a multiple-storage back-end configuration, each back end has a name (``volume_backend_name``). Several back ends can have the same name. In that case, the scheduler properly decides which back end the volume has to be created in. The name of the back end is declared as an extra-specification of a volume type (such as, ``volume_backend_name=LVM_iSCSI``). When a volume is created, the scheduler chooses an appropriate back end to handle the request, according to the volume type specified by the user. **Enable multiple-storage back ends** To enable a multiple-storage back ends, you must set the `enabled_backends` flag in the :file:`cinder.conf file`. This flag defines the names (separated by a comma) of the configuration groups for the different back ends: one name is associated to one configuration group for a back end (such as, ``[lvmdriver-1]``). .. note:: The configuration group name is not related to the ``volume_backend_name``. .. note:: After setting the :option:`enabled_backends` flag on an existing cinder service, and restarting the Block Storage services, the original ``host`` service is replaced with a new host service. The new service appears with a name like ``host@backend``. Use:: $ cinder-manage volume host --currentname CURRENTNAME --newname CURRENTNAME@BACKEND to convert current block devices to the new hostname. The options for a configuration group must be defined in the group (or default options are used). All the standard Block Storage configuration options (``volume_group``, ``volume_driver``, and so on) might be used in a configuration group. Configuration values in the ``[DEFAULT``] configuration group are not used. These examples show three back ends: .. code-block:: ini :linenos: enabled_backends=lvmdriver-1,lvmdriver-2,lvmdriver-3 [lvmdriver-1] volume_group=cinder-volumes-1 volume_driver=cinder.volume.drivers.lvm.LVMISCSIDriver volume_backend_name=LVM_iSCSI [lvmdriver-2] volume_group=cinder-volumes-2 volume_driver=cinder.volume.drivers.lvm.LVMISCSIDriver volume_backend_name=LVM_iSCSI [lvmdriver-3] volume_group=cinder-volumes-3 volume_driver=cinder.volume.drivers.lvm.LVMISCSIDriver volume_backend_name=LVM_iSCSI_b In this configuration, ``lvmdriver-1`` and ``lvmdriver-2`` have the same ``volume_backend_name``. If a volume creation requests the ``LVM_iSCSI`` back end name, the scheduler uses the capacity filter scheduler to choose the most suitable driver, which is either ``lvmdriver-1`` or ``lvmdriver-2``. The capacity filter scheduler is enabled by default. The next section provides more information. In addition, this example presents a ``lvmdriver-3`` back end. **Configure Block Storage scheduler multi back end** You must enable the `filter_scheduler` option to use multiple-storage back ends. The filter scheduler: #. Filters the available back ends. By default, ``AvailabilityZoneFilter``, ``CapacityFilter`` and ``CapabilitiesFilter`` are enabled. #. Weights the previously filtered back ends. By default, the :option:`CapacityWeigher` option is enabled. When this option is enabled, the filter scheduler assigns the highest weight to back ends with the most available capacity. The scheduler uses filters and weights to pick the best back end to handle the request. The scheduler uses volume types to explicitly create volumes on specific back ends. .. TODO: when filter/weighing scheduler documentation will be up, a ref should be added here **Volume type** Before using it, a volume type has to be declared to Block Storage. This can be done by the following command:: $ cinder --os-username admin --os-tenant-name admin type-create lvm Then, an extra-specification has to be created to link the volume type to a back end name. Run this command:: $ cinder --os-username admin --os-tenant-name admin type-key lvm set \ volume_backend_name=LVM_iSCSI This example creates a ``lvm`` volume type with ``volume_backend_name=LVM_iSCSI`` as extra-specifications. Create another volume type:: $ cinder --os-username admin --os-tenant-name admin type-create lvm_gold $ cinder --os-username admin --os-tenant-name admin type-key lvm_gold set \ volume_backend_name=LVM_iSCSI_b This second volume type is named ``lvm_gold`` and has ``LVM_iSCSI_b`` as back end name. .. note:: To list the extra-specifications, use this command:: $ cinder --os-username admin --os-tenant-name admin extra-specs-list .. note:: If a volume type points to a ``volume_backend_name`` that does not exist in the Block Storage configuration, the ``filter_scheduler`` returns an error that it cannot find a valid host with the suitable back end. **Usage** When you create a volume, you must specify the volume type. The extra-specifications of the volume type are used to determine which back end has to be used. :: $ cinder create --volume_type lvm --display_name test_multi_backend 1 Considering the :file:`cinder.conf` described previously, the scheduler creates this volume on ``lvmdriver-1`` or ``lvmdriver-2``. :: $ cinder create --volume_type lvm_gold --display_name test_multi_backend 1 This second volume is created on ``lvmdriver-3``. ",,160,1
openstack%2Fmagnum~master~Idbd19793838dbdd54aadc6cecc98b5a3d824879f,openstack/magnum,master,Idbd19793838dbdd54aadc6cecc98b5a3d824879f,Create new k8s_api instance on every calls,MERGED,2015-06-23 23:28:28.000000000,2015-06-25 00:39:04.000000000,2015-06-25 00:39:01.000000000,"[{'_account_id': 3}, {'_account_id': 7049}, {'_account_id': 10206}, {'_account_id': 11536}, {'_account_id': 11650}]","[{'number': 1, 'created': '2015-06-23 23:28:28.000000000', 'files': ['magnum/tests/unit/conductor/handlers/test_k8s_conductor.py', 'magnum/conductor/handlers/k8s_conductor.py'], 'web_link': 'https://opendev.org/openstack/magnum/commit/728039f6d255592db8abc28a24c8f832ba07510c', 'message': 'Create new k8s_api instance on every calls\n\nCurrently, conductor creates k8s_api instance on the first call and reuse\nthe same api instance after. This is incorrect because the api instance\nis binded to a bay while conductor could manage multiple bays.\n\nChange-Id: Idbd19793838dbdd54aadc6cecc98b5a3d824879f\nCloses-Bug: 1468067\n'}]",2,194866,728039f6d255592db8abc28a24c8f832ba07510c,10,5,1,11536,,,0,"Create new k8s_api instance on every calls

Currently, conductor creates k8s_api instance on the first call and reuse
the same api instance after. This is incorrect because the api instance
is binded to a bay while conductor could manage multiple bays.

Change-Id: Idbd19793838dbdd54aadc6cecc98b5a3d824879f
Closes-Bug: 1468067
",git fetch https://review.opendev.org/openstack/magnum refs/changes/66/194866/1 && git format-patch -1 --stdout FETCH_HEAD,"['magnum/tests/unit/conductor/handlers/test_k8s_conductor.py', 'magnum/conductor/handlers/k8s_conductor.py']",2,728039f6d255592db8abc28a24c8f832ba07510c,bug/1468067, # build a connection with Kubernetes master client = swagger.ApiClient(k8s_master_url) # create the ApivbetaApi class instance self._k8s_api = ApivbetaApi.ApivbetaApi(client), if self._k8s_api is None: # build a connection with Kubernetes master client = swagger.ApiClient(k8s_master_url) # create the ApivbetaApi class instance self._k8s_api = ApivbetaApi.ApivbetaApi(client),97,68
openstack%2Fcinder~master~I57f597a1bb2fdfeb24c17ac9020cc96f1ebf3fdd,openstack/cinder,master,I57f597a1bb2fdfeb24c17ac9020cc96f1ebf3fdd,Use a hard-coded project_id in racy cinder.tests.unit.test_volume tests,MERGED,2015-06-18 15:17:19.000000000,2015-06-25 00:38:16.000000000,2015-06-18 18:46:37.000000000,"[{'_account_id': 3}, {'_account_id': 2243}, {'_account_id': 2759}, {'_account_id': 4523}, {'_account_id': 9003}, {'_account_id': 9535}, {'_account_id': 9751}, {'_account_id': 10327}, {'_account_id': 10621}, {'_account_id': 10622}, {'_account_id': 11811}, {'_account_id': 12017}, {'_account_id': 12202}, {'_account_id': 12249}, {'_account_id': 12369}, {'_account_id': 12778}, {'_account_id': 13144}, {'_account_id': 13394}, {'_account_id': 14587}, {'_account_id': 14797}, {'_account_id': 15249}, {'_account_id': 15374}, {'_account_id': 15386}, {'_account_id': 15670}, {'_account_id': 15764}, {'_account_id': 15941}, {'_account_id': 16160}, {'_account_id': 16269}, {'_account_id': 16422}, {'_account_id': 16595}, {'_account_id': 16660}]","[{'number': 1, 'created': '2015-06-18 15:17:19.000000000', 'files': ['cinder/tests/unit/test_volume.py'], 'web_link': 'https://opendev.org/openstack/cinder/commit/bfcc27ea5c19e8aacce95cb56c10a95c5f1373b3', 'message': 'Use a hard-coded project_id in racy cinder.tests.unit.test_volume tests\n\nSince concurrent unit test runs have been turned on with ostestr there\nare races with the notifications causing the assertions in\ntest_volume.py tests to fail.\n\nA few attempts have been made at writing an elastic-recheck query to\nidentify the failures but they are too generic, e.g. querying for\n""fake_notifier.NOTIFICATIONS"" or ""MismatchError 0 != "", which could hit\non anything that fails with those, e.g. anything that uses\n""self.assertEqual(0, "" in the code could hit that kind of query - and we\nwant to avoid those types of queries running against changes in the\ncheck queue since they could mask legitimate test failures.\n\nSo we add something unique in these tests to identify them from other\ntest failures in Cinder by using a hard-coded uuid for the project_id so\nthat if we have an assertion failure with notifications, the\nnotification payload is dumped (due to commit\n4bbe1c87e26150c62e1dc8a2a5b8979896c1ddd9) and we can query on the\nassertion failure plus the hard-coded project_id used only in these\ntests.\n\nRelated-Bug: #1412513\n\nChange-Id: I57f597a1bb2fdfeb24c17ac9020cc96f1ebf3fdd\n'}]",0,193169,bfcc27ea5c19e8aacce95cb56c10a95c5f1373b3,36,31,1,6873,,,0,"Use a hard-coded project_id in racy cinder.tests.unit.test_volume tests

Since concurrent unit test runs have been turned on with ostestr there
are races with the notifications causing the assertions in
test_volume.py tests to fail.

A few attempts have been made at writing an elastic-recheck query to
identify the failures but they are too generic, e.g. querying for
""fake_notifier.NOTIFICATIONS"" or ""MismatchError 0 != "", which could hit
on anything that fails with those, e.g. anything that uses
""self.assertEqual(0, "" in the code could hit that kind of query - and we
want to avoid those types of queries running against changes in the
check queue since they could mask legitimate test failures.

So we add something unique in these tests to identify them from other
test failures in Cinder by using a hard-coded uuid for the project_id so
that if we have an assertion failure with notifications, the
notification payload is dumped (due to commit
4bbe1c87e26150c62e1dc8a2a5b8979896c1ddd9) and we can query on the
assertion failure plus the hard-coded project_id used only in these
tests.

Related-Bug: #1412513

Change-Id: I57f597a1bb2fdfeb24c17ac9020cc96f1ebf3fdd
",git fetch https://review.opendev.org/openstack/cinder refs/changes/69/193169/1 && git format-patch -1 --stdout FETCH_HEAD,['cinder/tests/unit/test_volume.py'],1,bfcc27ea5c19e8aacce95cb56c10a95c5f1373b3,bug/1412513," # NOTE(mriedem): The id is hard-coded here for tracking race fail # assertions with the notification code, it's part of an # elastic-recheck query so don't remove it or change it. self.project_id = '7f265bd4-3a85-465e-a899-5dc4854a86d3' self.context.project_id = self.project_id 'tenant_id': self.context.project_id, 'tenant_id': self.context.project_id, 'tenant_id': self.context.project_id, 'tenant_id': self.context.project_id,"," self.context.project_id = 'fake' 'tenant_id': 'fake', 'tenant_id': 'fake', 'tenant_id': 'fake', 'tenant_id': 'fake',",9,5
openstack%2Fnova~stable%2Fkilo~I8ac9be6b6d053895ace09d862f3da59d7456efd4,openstack/nova,stable/kilo,I8ac9be6b6d053895ace09d862f3da59d7456efd4,Updated from global requirements,MERGED,2015-04-28 20:00:42.000000000,2015-06-25 00:22:24.000000000,2015-06-25 00:04:31.000000000,"[{'_account_id': 3}, {'_account_id': 5170}, {'_account_id': 6873}, {'_account_id': 8213}, {'_account_id': 8871}, {'_account_id': 10118}, {'_account_id': 15741}]","[{'number': 1, 'created': '2015-04-28 20:00:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/74c6101a70f1c39639d536645feb95660fa1dde2', 'message': 'Updated from global requirements\n\nChange-Id: I8ac9be6b6d053895ace09d862f3da59d7456efd4\n'}, {'number': 2, 'created': '2015-05-04 20:16:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/78992a7d6eba0b2b98ed671afd7e4bcefc80c7e7', 'message': 'Updated from global requirements\n\nChange-Id: I8ac9be6b6d053895ace09d862f3da59d7456efd4\n'}, {'number': 3, 'created': '2015-05-07 15:23:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/3d37c9751f710910d0be7f42824a14f091f5f003', 'message': 'Updated from global requirements\n\nChange-Id: I8ac9be6b6d053895ace09d862f3da59d7456efd4\n'}, {'number': 4, 'created': '2015-06-04 16:02:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/7a2dd42330270f88ac6c8521f7564ddf365c6ae0', 'message': 'Updated from global requirements\n\nChange-Id: I8ac9be6b6d053895ace09d862f3da59d7456efd4\n'}, {'number': 5, 'created': '2015-06-05 01:17:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/6158d2623b7166a2e67f2a2d0f84cfdb66ce0e9f', 'message': 'Updated from global requirements\n\nChange-Id: I8ac9be6b6d053895ace09d862f3da59d7456efd4\n'}, {'number': 6, 'created': '2015-06-16 13:57:24.000000000', 'files': ['test-requirements.txt'], 'web_link': 'https://opendev.org/openstack/nova/commit/e1a62747b91368bfcc2dd3ce96f1519bb8416d20', 'message': 'Updated from global requirements\n\nChange-Id: I8ac9be6b6d053895ace09d862f3da59d7456efd4\n'}]",0,178376,e1a62747b91368bfcc2dd3ce96f1519bb8416d20,38,7,6,11131,,,0,"Updated from global requirements

Change-Id: I8ac9be6b6d053895ace09d862f3da59d7456efd4
",git fetch https://review.opendev.org/openstack/nova refs/changes/76/178376/1 && git format-patch -1 --stdout FETCH_HEAD,['test-requirements.txt'],1,74c6101a70f1c39639d536645feb95660fa1dde2,openstack/requirements,"tempest-lib>=0.4.0,<0.5.0",tempest-lib>=0.4.0,1,1
openstack%2Fheat~master~Ic5713e8c0c78c38ee1aaee8865346cb55228043f,openstack/heat,master,Ic5713e8c0c78c38ee1aaee8865346cb55228043f,Convergence: Handle resource failure,MERGED,2015-06-24 05:06:59.000000000,2015-06-25 00:15:37.000000000,2015-06-25 00:15:34.000000000,"[{'_account_id': 3}, {'_account_id': 4571}, {'_account_id': 4715}, {'_account_id': 6899}, {'_account_id': 11424}, {'_account_id': 12259}]","[{'number': 1, 'created': '2015-06-24 05:06:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/7e7a49ee933d93f65dc7f952ecad3283f1a6eb62', 'message': 'Convergence: Handle resource failure\n\nWhen a resource fails:\n1. Mark the stack as FAILED.\n2. If rollback is enabled, invoke rollback for the stack. Otherwise,\nclean-up database of stale entries.\n\nChange-Id: Ic5713e8c0c78c38ee1aaee8865346cb55228043f\n'}, {'number': 2, 'created': '2015-06-24 05:40:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/0eb65dca76366f5c471af1341f0b18ce1886bdd5', 'message': 'Convergence: Handle resource failure\n\nWhen a resource fails:\n1. Mark the stack as FAILED.\n2. If rollback is enabled, invoke rollback for the stack. Otherwise,\nclean-up database of stale entries.\n\nChange-Id: Ic5713e8c0c78c38ee1aaee8865346cb55228043f\n'}, {'number': 3, 'created': '2015-06-24 08:11:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/3c95aeacf06c13777ddf8c3cea8af98059931e3a', 'message': 'Convergence: Handle resource failure\n\nWhen a resource fails:\n1. Mark the stack as FAILED.\n2. If rollback is enabled, invoke rollback for the stack. Otherwise,\nclean-up database of stale entries.\n\nChange-Id: Ic5713e8c0c78c38ee1aaee8865346cb55228043f\n'}, {'number': 4, 'created': '2015-06-24 08:39:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/ea52ac5e1ccb62a189bfb1f24b7d9f059218c042', 'message': 'Convergence: Handle resource failure\n\nWhen a resource fails:\n1. Mark the stack as FAILED.\n2. If rollback is enabled, invoke rollback for the stack. Otherwise,\nclean-up database of stale entries.\n\nChange-Id: Ic5713e8c0c78c38ee1aaee8865346cb55228043f\n'}, {'number': 5, 'created': '2015-06-24 08:51:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/1a7248c2dba34d4d161e1c1dbbed557e22fc58f6', 'message': 'Convergence: Handle resource failure\n\nWhen a resource fails:\n1. Mark the stack as FAILED.\n2. If rollback is enabled, invoke rollback for the stack. Otherwise,\nclean-up database of stale entries.\n\nAfter the stack is completed (or failed), the database needs to be\ncleaned up.\n\nChange-Id: Ic5713e8c0c78c38ee1aaee8865346cb55228043f\n'}, {'number': 6, 'created': '2015-06-24 12:38:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/c6c29293874ec48a622402b73eba5ad7fa92e536', 'message': 'Convergence: Handle resource failure\n\nWhen a resource fails:\n1. Mark the stack as FAILED.\n2. If rollback is enabled, invoke rollback for the stack. Otherwise,\nclean-up database of stale entries.\n\nAfter the stack is completed (or failed), the database needs to be\ncleaned up.\n\nChange-Id: Ic5713e8c0c78c38ee1aaee8865346cb55228043f\n'}, {'number': 7, 'created': '2015-06-24 15:16:16.000000000', 'files': ['heat/tests/test_engine_service.py', 'heat/tests/test_engine_worker.py', 'heat/engine/worker.py', 'heat/engine/stack.py'], 'web_link': 'https://opendev.org/openstack/heat/commit/7abfcdee447e2fc22d03ace86958adc5e219064d', 'message': 'Convergence: Handle resource failure\n\nWhen a resource fails:\n1. Mark the stack as FAILED.\n2. If rollback is enabled, invoke rollback for the stack. Otherwise,\nclean-up database of stale entries.\n\nAfter the stack is completed (or failed), the database needs to be\ncleaned up.\n\nChange-Id: Ic5713e8c0c78c38ee1aaee8865346cb55228043f\n'}]",0,194937,7abfcdee447e2fc22d03ace86958adc5e219064d,26,6,7,12259,,,0,"Convergence: Handle resource failure

When a resource fails:
1. Mark the stack as FAILED.
2. If rollback is enabled, invoke rollback for the stack. Otherwise,
clean-up database of stale entries.

After the stack is completed (or failed), the database needs to be
cleaned up.

Change-Id: Ic5713e8c0c78c38ee1aaee8865346cb55228043f
",git fetch https://review.opendev.org/openstack/heat refs/changes/37/194937/4 && git format-patch -1 --stdout FETCH_HEAD,"['heat/tests/test_engine_worker.py', 'heat/engine/stack.py', 'heat/engine/worker.py']",3,7e7a49ee933d93f65dc7f952ecad3283f1a6eb62,handle-resource-failure,"from heat.engine import stack as parser def _trigger_rollback(self, cnxt, stack): # TODO(ananta) convergence-rollback implementation pass def _handle_resource_failure(self, cnxt, stack_id, traversal_id, failure_reason): stack = parser.Stack.load(cnxt, stack_id=stack_id) # make sure no new stack operation was triggered if stack.current_traversal != traversal_id: return stack = parser.Stack.load(cnxt, stack_id=stack_id) if (not stack.disable_rollback and stack.action in (stack.CREATE, stack.UPDATE)): self._trigger_rollback(cnxt, stack) else: stack.purge_db() except exception.ResourceFailure as e: reason = six.text_type(e) self._handle_resource_failure( cnxt, stack.id, current_traversal, reason) return except exception.ResourceFailure as e: reason = six.text_type(e) self._handle_resource_failure( cnxt, stack.id, current_traversal, reason) return",,170,0
openstack%2Fhorizon~master~I98978ddb271af9dc3cf18c73d2bd83948d723de7,openstack/horizon,master,I98978ddb271af9dc3cf18c73d2bd83948d723de7,JSCS cleanup - style guide cleanup for karma.config.js files,MERGED,2015-06-24 05:48:11.000000000,2015-06-25 00:15:21.000000000,2015-06-25 00:15:19.000000000,"[{'_account_id': 3}, {'_account_id': 9576}, {'_account_id': 9622}, {'_account_id': 10442}, {'_account_id': 11881}, {'_account_id': 12071}, {'_account_id': 13805}]","[{'number': 1, 'created': '2015-06-24 05:48:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/5f2ab7b0dfdf55828f34df4da550b4b366900ef2', 'message': 'Making farma.config.js files compliant to jscs rules\n\nkarma.config.js files are wirtten in node.js and therefore should\nbe compliant to the JavaScript code style applyed in Horizon. Also\nsome formatting inconsistency should be fixed.\n\nChange-Id: I98978ddb271af9dc3cf18c73d2bd83948d723de7\n'}, {'number': 2, 'created': '2015-06-24 06:25:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/404cb0fec4074e20eaa24889e2689f4f4e6c1982', 'message': 'Making karma.config.js files compliant to jscs rules\n\nkarma.config.js files are wirtten in node.js and therefore should\nbe compliant to the JavaScript code style applyed in Horizon. Also\nsome formatting inconsistency should be fixed.\n\nChange-Id: I98978ddb271af9dc3cf18c73d2bd83948d723de7'}, {'number': 3, 'created': '2015-06-24 17:21:56.000000000', 'files': ['openstack_dashboard/karma.conf.js', 'horizon/karma.conf.js'], 'web_link': 'https://opendev.org/openstack/horizon/commit/703353179090e82780b549401f2014f88ae99b5c', 'message': 'JSCS cleanup - style guide cleanup for karma.config.js files\n\nkarma.config.js files are wirtten in node.js and therefore should\nbe compliant to the JavaScript code style applyed in Horizon. Also\nsome formatting inconsistency should be fixed.\n\nChange-Id: I98978ddb271af9dc3cf18c73d2bd83948d723de7\nPartially-Implements: blueprint jscs-cleanup\n'}]",6,194944,703353179090e82780b549401f2014f88ae99b5c,16,7,3,13805,,,0,"JSCS cleanup - style guide cleanup for karma.config.js files

karma.config.js files are wirtten in node.js and therefore should
be compliant to the JavaScript code style applyed in Horizon. Also
some formatting inconsistency should be fixed.

Change-Id: I98978ddb271af9dc3cf18c73d2bd83948d723de7
Partially-Implements: blueprint jscs-cleanup
",git fetch https://review.opendev.org/openstack/horizon refs/changes/44/194944/2 && git format-patch -1 --stdout FETCH_HEAD,"['openstack_dashboard/karma.conf.js', 'horizon/karma.conf.js']",2,5f2ab7b0dfdf55828f34df4da550b4b366900ef2,better-format,"/* * (c) Copyright 2015 Hewlett-Packard Development Company, L.P. * * Licensed under the Apache License, Version 2.0 (the ""License""); * you may not use this file except in compliance with the License. * You may obtain a copy of the License at * * http://www.apache.org/licenses/LICENSE-2.0 * * Unless required by applicable law or agreed to in writing, software * distributed under the License is distributed on an ""AS IS"" BASIS, * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. * See the License for the specific language governing permissions and * limitations under the License. */ module.exports = function (config) { ]; console.error('xStatic libraries not found, please set up venv'); './**/!(*.spec).js': ['coverage'] basePath: './static/', files: [ autoWatch: true, browsers: ['PhantomJS'], reporters: ['progress', 'coverage'], plugins: [ type: 'html', dir: '../.coverage-karma/' }","module.exports = function(config) { ] console.error(""xStatic libraries not found, please set up venv""); './**/!(*spec).js': ['coverage'] basePath : './static/', files : [ autoWatch : true, browsers : ['PhantomJS'], reporters : [ 'progress', 'coverage' ], plugins : [ type : 'html', dir : '../.coverage-karma/' } ",58,31
openstack%2Fheat~master~Icc51b5ffd4b2256d2552cb00c0e51078049a96aa,openstack/heat,master,Icc51b5ffd4b2256d2552cb00c0e51078049a96aa,Add share network resource for manila,MERGED,2015-04-21 13:39:03.000000000,2015-06-25 00:15:11.000000000,2015-06-25 00:15:09.000000000,"[{'_account_id': 3}, {'_account_id': 4571}, {'_account_id': 4715}, {'_account_id': 6577}, {'_account_id': 7385}, {'_account_id': 7404}, {'_account_id': 8289}, {'_account_id': 8851}, {'_account_id': 9751}, {'_account_id': 10487}, {'_account_id': 12363}, {'_account_id': 13009}, {'_account_id': 13323}, {'_account_id': 14676}]","[{'number': 1, 'created': '2015-04-21 13:39:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/c06664adcc40193279740a267bfb6cc0b23b8a5b', 'message': 'Add share netwok resource for manila\n\nImplement create, delete, update methods for resource.\n\nChange-Id: Icc51b5ffd4b2256d2552cb00c0e51078049a96aa\n'}, {'number': 2, 'created': '2015-05-14 17:17:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/a5b754fd23769abd3816e8003e8b96bfe535fcd7', 'message': 'Add share netwok resource for manila\n\nImplement create, delete, update methods for resource.\n\nImplements: partial blueprint add-manila-resources\nChange-Id: Icc51b5ffd4b2256d2552cb00c0e51078049a96aa\n'}, {'number': 3, 'created': '2015-05-27 10:13:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/0c544ec2c600bff380e0bb1c34a26c94a8379e9e', 'message': 'Add share netwok resource for manila\n\nImplement create, delete, update methods for resource.\n\nImplements: partial blueprint add-manila-resources\nChange-Id: Icc51b5ffd4b2256d2552cb00c0e51078049a96aa\n'}, {'number': 4, 'created': '2015-05-27 10:38:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/2bfeb4f7578cd94eacb68745449ff9c10d2c8391', 'message': 'Add share netwok resource for manila\n\nImplement create, delete, update methods for resource.\n\nImplements: partial blueprint add-manila-resources\nChange-Id: Icc51b5ffd4b2256d2552cb00c0e51078049a96aa\n'}, {'number': 5, 'created': '2015-05-27 12:03:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/b65470a1d3e84dba6fee06498c9762e65225df49', 'message': 'Add share netwok resource for manila\n\nImplement create, delete, update methods for resource.\n\nImplements: partial blueprint add-manila-resources\nChange-Id: Icc51b5ffd4b2256d2552cb00c0e51078049a96aa\n'}, {'number': 6, 'created': '2015-06-03 12:57:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/e3ba4fa997180a842a002911f5ea841bae532521', 'message': 'Add share netwok resource for manila\n\nImplement create, delete, update methods for resource.\n\nImplements: partial blueprint add-manila-resources\nChange-Id: Icc51b5ffd4b2256d2552cb00c0e51078049a96aa\n'}, {'number': 7, 'created': '2015-06-03 13:56:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/efd01364101588f55029cf7bb785934f64ddac81', 'message': 'Add share netwok resource for manila\n\nImplement create, delete, update methods for resource.\n\nImplements: partial blueprint add-manila-resources\nChange-Id: Icc51b5ffd4b2256d2552cb00c0e51078049a96aa\n'}, {'number': 8, 'created': '2015-06-22 11:43:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/aea8facc8f04fcf4bbccbc27e512ec57173d1d01', 'message': 'Add share netwok resource for manila\n\nImplement create, delete, update methods for resource.\n\nImplements: partial blueprint add-manila-resources\nChange-Id: Icc51b5ffd4b2256d2552cb00c0e51078049a96aa\n'}, {'number': 9, 'created': '2015-06-22 11:48:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/5765fc3e907e9d81f1157d88dd62ce2c0d33ccab', 'message': 'Add share netwok resource for manila\n\nImplement create, delete, update methods for resource.\n\nImplements: partial blueprint add-manila-resources\nChange-Id: Icc51b5ffd4b2256d2552cb00c0e51078049a96aa\n'}, {'number': 10, 'created': '2015-06-22 12:03:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/c6b839cf74e0ba2802ee52a0937ddf1a4df84a20', 'message': 'Add share netwok resource for manila\n\nImplement create, delete, update methods for resource.\n\nImplements: partial blueprint add-manila-resources\nChange-Id: Icc51b5ffd4b2256d2552cb00c0e51078049a96aa\n'}, {'number': 11, 'created': '2015-06-22 12:35:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/c5272c406c9e1dc92e2ec199739ba4f0b2182ab5', 'message': 'Add share netwok resource for manila\n\nImplement create, delete, update methods for resource.\n\nImplements: partial blueprint add-manila-resources\nChange-Id: Icc51b5ffd4b2256d2552cb00c0e51078049a96aa\n'}, {'number': 12, 'created': '2015-06-23 10:34:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/182d82e03506a6ddbf1e758405838fb60e6b4993', 'message': 'Add share netwok resource for manila\n\nImplement create, delete, update methods for resource.\n\nImplements: partial blueprint add-manila-resources\nChange-Id: Icc51b5ffd4b2256d2552cb00c0e51078049a96aa\n'}, {'number': 13, 'created': '2015-06-23 11:52:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/37c2a0953afec962ea4a2d46963daf2b4aa55eea', 'message': 'Add share netwok resource for manila\n\nImplement create, delete, update methods for resource.\n\nImplements: partial blueprint add-manila-resources\nChange-Id: Icc51b5ffd4b2256d2552cb00c0e51078049a96aa\n'}, {'number': 14, 'created': '2015-06-23 17:03:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/33a98dfcd879da8efebd36762c9fd86c1b5d972c', 'message': 'Add share netwok resource for manila\n\nImplement create, delete, update methods for resource.\n\nImplements: partial blueprint add-manila-resources\nChange-Id: Icc51b5ffd4b2256d2552cb00c0e51078049a96aa\n'}, {'number': 15, 'created': '2015-06-24 11:48:12.000000000', 'files': ['heat/tests/test_manila_client.py', 'heat/tests/test_share_network.py', 'heat/engine/resources/openstack/manila/share_network.py', 'heat/engine/clients/os/manila.py'], 'web_link': 'https://opendev.org/openstack/heat/commit/d0b994858c5a22f488131074d497ba7544e1523a', 'message': 'Add share network resource for manila\n\nImplement create, delete, update methods for resource.\n\nImplements: partial blueprint add-manila-resources\nChange-Id: Icc51b5ffd4b2256d2552cb00c0e51078049a96aa\n'}]",101,175862,d0b994858c5a22f488131074d497ba7544e1523a,106,14,15,12363,,,0,"Add share network resource for manila

Implement create, delete, update methods for resource.

Implements: partial blueprint add-manila-resources
Change-Id: Icc51b5ffd4b2256d2552cb00c0e51078049a96aa
",git fetch https://review.opendev.org/openstack/heat refs/changes/62/175862/11 && git format-patch -1 --stdout FETCH_HEAD,"['contrib/heat_manila/heat_manila/tests/test_share_network.py', 'contrib/heat_manila/heat_manila/client.py', 'contrib/heat_manila/heat_manila/resources/share_network.py']",3,c06664adcc40193279740a267bfb6cc0b23b8a5b,bp/add-manila-resources,"# # Licensed under the Apache License, Version 2.0 (the ""License""); you may # not use this file except in compliance with the License. You may obtain # a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT # WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the # License for the specific language governing permissions and limitations # under the License. from oslo_log import log as logging from heat.common.i18n import _ from heat.engine import attributes from heat.engine import clients from heat.engine import properties from heat.engine import resource from heat.engine import support LOG = logging.getLogger(__name__) class ManilaShareNetwork(resource.Resource): """""" Stores network information that will be used by share servers, where shares are hosted. """""" support_status = support.SupportStatus(version='2015.2') PROPERTIES = ( NAME, NEUTRON_NETWORK, NEUTRON_SUBNET, NOVA_NETWORK, DESCRIPTION, SECURITY_SERVICES, ) = ( 'name', 'neutron_network', 'neutron_subnet', 'nova_network', 'description', 'security_services', ) ATTRIBUTES = ( SEGMENTATION_ID, CIDR, IP_VERSION, NETWORK_TYPE, ) = ( 'segmentation_id', 'cidr', 'ip_version', 'network_type', ) properties_schema = { NAME: properties.Schema( properties.Schema.STRING, _('Name of the share network.'), update_allowed=True ), NEUTRON_NETWORK: properties.Schema( properties.Schema.STRING, _('Neutron network id.'), update_allowed=True ), NEUTRON_SUBNET: properties.Schema( properties.Schema.STRING, _('Neutron subnet id.'), update_allowed=True ), NOVA_NETWORK: properties.Schema( properties.Schema.STRING, _('Nova network id.'), update_allowed=True ), DESCRIPTION: properties.Schema( properties.Schema.STRING, _('Share network description.'), update_allowed=True ), SECURITY_SERVICES: properties.Schema( properties.Schema.LIST, _('A list of security services IDs.'), schema=properties.Schema( properties.Schema.STRING ), update_allowed=True, default=[] ) } attributes_schema = { SEGMENTATION_ID: attributes.Schema( _('VLAN ID for VLAN networks or tunnel-id for GRE/VXLAN networks.') ), CIDR: attributes.Schema( _('CIDR of subnet.') ), IP_VERSION: attributes.Schema( _('Version of IP adress.') ), NETWORK_TYPE: attributes.Schema( _('The physical mechanism by which the virtual network is ' 'implemented.') ), } default_client_name = 'manila' default_client_plugin_name = 'manila' def _request_network(self): return self.client().share_netwoks.get(self.resource_id) def _resolve_attribute(self, name): network = self._request_network() return getattr(network, name) def handle_create(self): network = self.client().share_networks.create( name=self.properties[self.NAME], neutron_net_id=self.properties[self.NEUTRON_NETWORK], neutron_subnet_id=self.properties[self.NEUTRON_SUBNET], nova_net_id=self.properties[self.NOVA_NETWORK], description=self.properties[self.DESCRIPTION]) self.resource_id_set(network.id) for service in self.properties.get(self.SECURITY_SERVICES): self.client().share_networks.add_security_service( self.resource_id, self.client_plugin().get_security_service(service).id) def handle_update(self, json_snippet=None, tmpl_diff=None, prop_diff=None): if self.SECURITY_SERVICES in prop_diff: curr_services = [self.client_plugin().get_security_service(s).id for s in self.properties.get( self.SECURITY_SERVICES)] new_services = [self.client_plugin().get_security_service(s).id for s in prop_diff[self.SECURITY_SERVICES]] for service in curr_services: if service not in new_services: self.client().share_networks.remove_security_service( self.resource_id, service) for service in new_services: if service not in curr_services: self.client().share_networks.add_security_service( self.resource_id, service) if self.SECURITY_SERVICES in tmpl_diff['Properties']: del tmpl_diff['Properties'][self.SECURITY_SERVICES] self.client().share_networks.update(self.resource_id, **tmpl_diff['Properties']) def handle_delete(self): try: self.client().share_networks.delete(self.resource_id) except Exception as ex: self.client_plugin().ignore_not_found(ex) else: return True def resource_mapping(): return {'OS::Manila::ShareNetwork': ManilaShareNetwork} def available_resource_mapping(): if not clients.has_client('manila'): return {} return resource_mapping() ",,318,0
openstack%2Fnova~stable%2Fkilo~Ic389672d56eab4f11cffe0de306934188a18a5a4,openstack/nova,stable/kilo,Ic389672d56eab4f11cffe0de306934188a18a5a4,Fixes TypeError when libvirt version is BAD_LIBVIRT_CPU_POLICY_VERSIONS,MERGED,2015-06-18 20:02:16.000000000,2015-06-25 00:14:45.000000000,2015-06-25 00:14:42.000000000,"[{'_account_id': 3}, {'_account_id': 1420}, {'_account_id': 1653}, {'_account_id': 4428}, {'_account_id': 5170}, {'_account_id': 6873}, {'_account_id': 8151}, {'_account_id': 9732}, {'_account_id': 10118}]","[{'number': 1, 'created': '2015-06-18 20:02:16.000000000', 'files': ['nova/virt/libvirt/driver.py', 'nova/tests/unit/virt/libvirt/test_driver.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/199f0ab55abcd2ee3630c90cdc470be6a32c8387', 'message': 'Fixes TypeError when libvirt version is BAD_LIBVIRT_CPU_POLICY_VERSIONS\n\nAnd add unit test for _has_cpu_policy_support\n\nChange-Id: Ic389672d56eab4f11cffe0de306934188a18a5a4\nCloses-bug: #1465927\n(cherry picked from commit 68fd33799ed75023567ce06081cfcfd9a407ac23)\n'}]",0,193286,199f0ab55abcd2ee3630c90cdc470be6a32c8387,12,9,1,6873,,,0,"Fixes TypeError when libvirt version is BAD_LIBVIRT_CPU_POLICY_VERSIONS

And add unit test for _has_cpu_policy_support

Change-Id: Ic389672d56eab4f11cffe0de306934188a18a5a4
Closes-bug: #1465927
(cherry picked from commit 68fd33799ed75023567ce06081cfcfd9a407ac23)
",git fetch https://review.opendev.org/openstack/nova refs/changes/86/193286/1 && git format-patch -1 --stdout FETCH_HEAD,"['nova/virt/libvirt/driver.py', 'nova/tests/unit/virt/libvirt/test_driver.py']",2,199f0ab55abcd2ee3630c90cdc470be6a32c8387,," @mock.patch.object(host.Host, 'has_version', return_value=True) def test_has_cpu_policy_support(self, mock_has_version): drvr = libvirt_driver.LibvirtDriver(fake.FakeVirtAPI(), True) self.assertRaises(exception.CPUPinningNotSupported, drvr._has_cpu_policy_support) ",,7,1
openstack%2Ftripleo-heat-templates~master~I9832ee75eb1644a4646ca539bcdd4586739a42a4,openstack/tripleo-heat-templates,master,I9832ee75eb1644a4646ca539bcdd4586739a42a4,Fix tripleo::redis_notification::haproxy_monitor_ip,ABANDONED,2015-06-24 23:30:52.000000000,2015-06-25 00:07:06.000000000,,"[{'_account_id': 3}, {'_account_id': 360}, {'_account_id': 4328}, {'_account_id': 6796}, {'_account_id': 8399}, {'_account_id': 9410}]","[{'number': 1, 'created': '2015-06-24 23:30:52.000000000', 'files': ['puppet/vip-config.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/6289401ee69d55deea7d06ee487f50a224f3113f', 'message': 'Fix tripleo::redis_notification::haproxy_monitor_ip\n\nThis change fixes a mistake in vip-config.yaml for the Redis VIP.\nThe tripleo::redis_notification::haproxy_monitor_ip in the puppet\nhieradata is incorrect. It is hardcoded to point to the\nControlVirtualIP, when it should be poining at the redis_vip. This\nslipped through because when network isolation is not used, those\nvalues are equal.\n\nChange-Id: I9832ee75eb1644a4646ca539bcdd4586739a42a4\n'}]",0,195357,6289401ee69d55deea7d06ee487f50a224f3113f,4,6,1,12398,,,0,"Fix tripleo::redis_notification::haproxy_monitor_ip

This change fixes a mistake in vip-config.yaml for the Redis VIP.
The tripleo::redis_notification::haproxy_monitor_ip in the puppet
hieradata is incorrect. It is hardcoded to point to the
ControlVirtualIP, when it should be poining at the redis_vip. This
slipped through because when network isolation is not used, those
values are equal.

Change-Id: I9832ee75eb1644a4646ca539bcdd4586739a42a4
",git fetch https://review.opendev.org/openstack/tripleo-heat-templates refs/changes/57/195357/1 && git format-patch -1 --stdout FETCH_HEAD,['puppet/vip-config.yaml'],1,6289401ee69d55deea7d06ee487f50a224f3113f,redis_monitor_ip_fix, tripleo::redis_notification::haproxy_monitor_ip: {get_input: redis_vip}, tripleo::redis_notification::haproxy_monitor_ip: {get_input: control_virtual_ip},1,1
openstack%2Fheat~master~Ice5450761f52e7a2aeb873ceb7df49ed9bbe4a52,openstack/heat,master,Ice5450761f52e7a2aeb873ceb7df49ed9bbe4a52,Remove PROTOTYPE support status,MERGED,2015-05-29 10:34:27.000000000,2015-06-25 00:05:03.000000000,2015-06-25 00:05:01.000000000,"[{'_account_id': 3}, {'_account_id': 4257}, {'_account_id': 4328}, {'_account_id': 4571}, {'_account_id': 4715}, {'_account_id': 6498}, {'_account_id': 6577}, {'_account_id': 6899}, {'_account_id': 7404}, {'_account_id': 8246}, {'_account_id': 9751}, {'_account_id': 10487}, {'_account_id': 12363}, {'_account_id': 13009}, {'_account_id': 13323}, {'_account_id': 14676}]","[{'number': 1, 'created': '2015-05-29 10:34:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/6253a0862fba13b2787e6da0e874b9b9f7326da4', 'message': ""Remove PROTOTYPE support status\n\nIt's not used anywhere and is superseded by the UNSUPPORTED\nstatus\n\nChange-Id: Ice5450761f52e7a2aeb873ceb7df49ed9bbe4a52\n""}, {'number': 2, 'created': '2015-06-01 10:17:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/1c46ec6fa50688cff4018b7edab8a6a6bf195660', 'message': ""Remove PROTOTYPE support status\n\nIt's not used anywhere and is superseded by the UNSUPPORTED\nstatus\n\nChange-Id: Ice5450761f52e7a2aeb873ceb7df49ed9bbe4a52\n""}, {'number': 3, 'created': '2015-06-22 05:34:54.000000000', 'files': ['heat/engine/support.py'], 'web_link': 'https://opendev.org/openstack/heat/commit/2b1707fe6bc7514a99260f85f47c97ee2d0af31a', 'message': ""Remove PROTOTYPE support status\n\nIt's not used anywhere and is superseded by the UNSUPPORTED\nstatus\n\nCloses-Bug: #1467382\n\nChange-Id: Ice5450761f52e7a2aeb873ceb7df49ed9bbe4a52\n""}]",0,186705,2b1707fe6bc7514a99260f85f47c97ee2d0af31a,37,16,3,6899,,,0,"Remove PROTOTYPE support status

It's not used anywhere and is superseded by the UNSUPPORTED
status

Closes-Bug: #1467382

Change-Id: Ice5450761f52e7a2aeb873ceb7df49ed9bbe4a52
",git fetch https://review.opendev.org/openstack/heat refs/changes/05/186705/3 && git format-patch -1 --stdout FETCH_HEAD,['heat/engine/support.py'],1,6253a0862fba13b2787e6da0e874b9b9f7326da4,remove_prototype," UNSUPPORTED) = ('UNKNOWN', 'SUPPORTED', 'DEPRECATED', 'UNSUPPORTED')"," UNSUPPORTED) = ('UNKNOWN', 'SUPPORTED', 'PROTOTYPE', 'DEPRECATED', 'UNSUPPORTED')",2,2
openstack%2Fkeystonemiddleware~master~I1a487f51430ac918d21172a6e73b28534841ffc3,openstack/keystonemiddleware,master,I1a487f51430ac918d21172a6e73b28534841ffc3,Updated from global requirements,MERGED,2015-06-16 19:16:57.000000000,2015-06-25 00:03:15.000000000,2015-06-25 00:03:15.000000000,"[{'_account_id': 3}, {'_account_id': 4}, {'_account_id': 2903}, {'_account_id': 16272}]","[{'number': 1, 'created': '2015-06-16 19:16:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystonemiddleware/commit/62cdf048e3817c7354940e4ea737a6c15491b81a', 'message': 'Updated from global requirements\n\nChange-Id: I1a487f51430ac918d21172a6e73b28534841ffc3\n'}, {'number': 2, 'created': '2015-06-22 08:21:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystonemiddleware/commit/40ef5bc6ecf28b9f2bffe6d5db4e862e735dc614', 'message': 'Updated from global requirements\n\nChange-Id: I1a487f51430ac918d21172a6e73b28534841ffc3\n'}, {'number': 3, 'created': '2015-06-22 20:14:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystonemiddleware/commit/8952764a973fdf18e94eefd74eb42d0de9a1ae9a', 'message': 'Updated from global requirements\n\nChange-Id: I1a487f51430ac918d21172a6e73b28534841ffc3\n'}, {'number': 4, 'created': '2015-06-23 21:43:43.000000000', 'files': ['requirements.txt', 'test-requirements.txt', 'setup.py', 'test-requirements-py3.txt'], 'web_link': 'https://opendev.org/openstack/keystonemiddleware/commit/fd2a1b72f4c40a76fcfcfa00ee07aba4d58401a8', 'message': 'Updated from global requirements\n\nChange-Id: I1a487f51430ac918d21172a6e73b28534841ffc3\n'}]",0,192375,fd2a1b72f4c40a76fcfcfa00ee07aba4d58401a8,15,4,4,11131,,,0,"Updated from global requirements

Change-Id: I1a487f51430ac918d21172a6e73b28534841ffc3
",git fetch https://review.opendev.org/openstack/keystonemiddleware refs/changes/75/192375/4 && git format-patch -1 --stdout FETCH_HEAD,['requirements.txt'],1,62cdf048e3817c7354940e4ea737a6c15491b81a,openstack/requirements,oslo.utils>=1.6.0 # Apache-2.0,oslo.utils>=1.4.0 # Apache-2.0,1,1
openstack%2Fcue~master~I5293243d12fe6fbda0a9c816b734aa0d4fe1ed99,openstack/cue,master,I5293243d12fe6fbda0a9c816b734aa0d4fe1ed99,Adding ssl config to connect to Openstack HTTPS endpoint,MERGED,2015-06-22 03:22:47.000000000,2015-06-25 00:02:20.000000000,2015-06-25 00:02:19.000000000,"[{'_account_id': 3}, {'_account_id': 1925}, {'_account_id': 5390}, {'_account_id': 10584}]","[{'number': 1, 'created': '2015-06-22 03:22:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cue/commit/ab149b4e1447bfe9ddc674bbfeabe964d04a7666', 'message': 'Adding ssl config to connect to Openstack HTTPS endpoint\n\nChange-Id: I5293243d12fe6fbda0a9c816b734aa0d4fe1ed99\n'}, {'number': 2, 'created': '2015-06-24 16:45:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cue/commit/e0ea92fc0bdb5cac42e6166303d6ad192308bc2b', 'message': 'Adding ssl config to connect to Openstack HTTPS endpoint\n\nChange-Id: I5293243d12fe6fbda0a9c816b734aa0d4fe1ed99\n'}, {'number': 3, 'created': '2015-06-24 17:12:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cue/commit/c0c79dba4761b8e37fc69870031f4c2acf2fb925', 'message': 'Adding ssl config to connect to Openstack HTTPS endpoint\n\nChange-Id: I5293243d12fe6fbda0a9c816b734aa0d4fe1ed99\n'}, {'number': 4, 'created': '2015-06-24 21:55:39.000000000', 'files': ['cue/client.py'], 'web_link': 'https://opendev.org/openstack/cue/commit/0d760fdc19e05d992b2c7018665994c14a13d766', 'message': 'Adding ssl config to connect to Openstack HTTPS endpoint\n\nChange-Id: I5293243d12fe6fbda0a9c816b734aa0d4fe1ed99\n'}]",1,193925,0d760fdc19e05d992b2c7018665994c14a13d766,16,4,4,5390,,,0,"Adding ssl config to connect to Openstack HTTPS endpoint

Change-Id: I5293243d12fe6fbda0a9c816b734aa0d4fe1ed99
",git fetch https://review.opendev.org/openstack/cue refs/changes/25/193925/2 && git format-patch -1 --stdout FETCH_HEAD,['cue/client.py'],1,ab149b4e1447bfe9ddc674bbfeabe964d04a7666,cue-ssl," cfg.StrOpt('os_insecure', help='Openstack insecure', default=None), cfg.StrOpt('os_cacert', help='Openstack cacert', default=None), insecure=CONF.openstack.os_insecure, cacert=CONF.openstack.os_cacert, ) CONF.openstack.os_auth_url, CONF.openstack.os_insecure, cacert=CONF.openstack.os_cacert, ) insecure=CONF.openstack.os_insecure, ca_cert=CONF.openstack.os_cacert, )", ) CONF.openstack.os_auth_url ) ),16,4
openstack%2Fmagnum~master~I9b5cb3cf3e0470ce58f72bd9952b6b3856ebf94d,openstack/magnum,master,I9b5cb3cf3e0470ce58f72bd9952b6b3856ebf94d,"Backport ""docker group is no longer used""",MERGED,2015-06-17 10:28:58.000000000,2015-06-24 23:57:34.000000000,2015-06-24 23:57:33.000000000,"[{'_account_id': 3}, {'_account_id': 7049}, {'_account_id': 7494}, {'_account_id': 8143}, {'_account_id': 9591}, {'_account_id': 10206}, {'_account_id': 11536}]","[{'number': 1, 'created': '2015-06-17 10:28:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/magnum/commit/ba6231f97beacc14da9f48eaf184b99633f8da92', 'message': 'Backport ""docker group is no longer used""\n\nheat-coe-templates: I0eee1222e06d6c34761feb24b517972892dc8bbc\n\nChange-Id: I9b5cb3cf3e0470ce58f72bd9952b6b3856ebf94d\n'}, {'number': 2, 'created': '2015-06-24 15:16:10.000000000', 'files': ['magnum/templates/heat-kubernetes/fragments/add-to-docker-group.sh', 'magnum/templates/heat-kubernetes/kubeminion.yaml'], 'web_link': 'https://opendev.org/openstack/magnum/commit/e3b6ae71d50ec41f3c471e2c9572250f87c68614', 'message': 'Backport ""docker group is no longer used""\n\nRestrict docker api access to only the root user. This is so that someone\nwith access to the docker api cannot access arbitrary files on the host and\nmodify the host networking and kill/inspect host processes.\n\nChange-Id: I9b5cb3cf3e0470ce58f72bd9952b6b3856ebf94d\nheat-coe-templates: I0eee1222e06d6c34761feb24b517972892dc8bbc\n'}]",0,192587,e3b6ae71d50ec41f3c471e2c9572250f87c68614,13,7,2,11650,,,0,"Backport ""docker group is no longer used""

Restrict docker api access to only the root user. This is so that someone
with access to the docker api cannot access arbitrary files on the host and
modify the host networking and kill/inspect host processes.

Change-Id: I9b5cb3cf3e0470ce58f72bd9952b6b3856ebf94d
heat-coe-templates: I0eee1222e06d6c34761feb24b517972892dc8bbc
",git fetch https://review.opendev.org/openstack/magnum refs/changes/87/192587/1 && git format-patch -1 --stdout FETCH_HEAD,"['magnum/templates/heat-kubernetes/fragments/add-to-docker-group.sh', 'magnum/templates/heat-kubernetes/kubeminion.yaml']",2,ba6231f97beacc14da9f48eaf184b99633f8da92,backports,, add_to_docker_group: type: OS::Heat::SoftwareConfig properties: group: ungrouped config: {get_file: fragments/add-to-docker-group.sh} - config: {get_resource: add_to_docker_group},0,21
openstack%2Fmagnum~master~I509d8e8131aa8423cbec144e1f31796c51be6dd1,openstack/magnum,master,I509d8e8131aa8423cbec144e1f31796c51be6dd1,"Backport ""docker.socket is no longer used""",MERGED,2015-06-17 10:28:58.000000000,2015-06-24 23:57:07.000000000,2015-06-24 23:57:05.000000000,"[{'_account_id': 3}, {'_account_id': 7049}, {'_account_id': 7494}, {'_account_id': 10206}, {'_account_id': 11536}, {'_account_id': 11650}]","[{'number': 1, 'created': '2015-06-17 10:28:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/magnum/commit/e403eee8402b45b0674f8be06789ab133b1a57dd', 'message': 'Backport ""docker.socket is no longer used""\n\nChange-Id: I509d8e8131aa8423cbec144e1f31796c51be6dd1\nheat-coe-templates: I9a17a3c3f1a18545a014fe19dffeec7282a2e49b\n'}, {'number': 2, 'created': '2015-06-24 15:16:10.000000000', 'files': ['magnum/templates/heat-kubernetes/fragments/enable-services-minion.sh'], 'web_link': 'https://opendev.org/openstack/magnum/commit/fae860926298a8c532ee940a20f95582a46bce94', 'message': 'Backport ""docker.socket is no longer used""\n\nThe docker socket process is no longer necessary for setting up\nkubernetes because now the docker daemon starts up automatically, rather\nthan relying on socket activation. Docker is now running when the system\nboots even if there have not been any client connections.\n\nheat-coe-templates: I9a17a3c3f1a18545a014fe19dffeec7282a2e49b\n\nChange-Id: I509d8e8131aa8423cbec144e1f31796c51be6dd1\n'}]",6,192586,fae860926298a8c532ee940a20f95582a46bce94,13,6,2,11650,,,0,"Backport ""docker.socket is no longer used""

The docker socket process is no longer necessary for setting up
kubernetes because now the docker daemon starts up automatically, rather
than relying on socket activation. Docker is now running when the system
boots even if there have not been any client connections.

heat-coe-templates: I9a17a3c3f1a18545a014fe19dffeec7282a2e49b

Change-Id: I509d8e8131aa8423cbec144e1f31796c51be6dd1
",git fetch https://review.opendev.org/openstack/magnum refs/changes/86/192586/2 && git format-patch -1 --stdout FETCH_HEAD,['magnum/templates/heat-kubernetes/fragments/enable-services-minion.sh'],1,e403eee8402b45b0674f8be06789ab133b1a57dd,backports,for service in flanneld docker kubelet kube-proxy; do,for service in flanneld docker.socket docker kubelet kube-proxy; do,1,1
openstack%2Fpython-heatclient~master~If3a47e610264fe65d76b34c088a1ab3199d72438,openstack/python-heatclient,master,If3a47e610264fe65d76b34c088a1ab3199d72438,Fixed VerifyAll() when test case does ReplayAll(),MERGED,2015-06-09 18:09:32.000000000,2015-06-24 23:56:57.000000000,2015-06-24 23:56:55.000000000,"[{'_account_id': 3}, {'_account_id': 4328}, {'_account_id': 4715}, {'_account_id': 6577}, {'_account_id': 7385}, {'_account_id': 10487}, {'_account_id': 13009}, {'_account_id': 14676}]","[{'number': 1, 'created': '2015-06-09 18:09:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-heatclient/commit/2a80a654142ac83a282c4fd8733845d7baf96a8d', 'message': 'Fixed VerifyAll() when test case does ReplayAll()\n\nVerifyAll() methods moved to setUp into addCleanup method.\nRedundant VerifyAll() methods were removed.\n\n\tmodified:   heatclient/tests/unit/test_common_http.py\n\tmodified:   heatclient/tests/unit/test_events.py\n\tmodified:   heatclient/tests/unit/test_resources.py\n\tmodified:   heatclient/tests/unit/test_shell.py\n\tmodified:   heatclient/tests/unit/test_template_utils.py\n\nChange-Id: If3a47e610264fe65d76b34c088a1ab3199d72438\n'}, {'number': 2, 'created': '2015-06-09 19:05:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-heatclient/commit/2562e0c258e45f5885c4544edebed200592fe73d', 'message': 'Fixed VerifyAll() when test case does ReplayAll()\n\nVerifyAll() methods moved to setUp into addCleanup method.\nRedundant VerifyAll() methods were removed.\n\nCloses-Bug: #1419469\n\n\tmodified:   heatclient/tests/unit/test_common_http.py\n\tmodified:   heatclient/tests/unit/test_events.py\n\tmodified:   heatclient/tests/unit/test_resources.py\n\tmodified:   heatclient/tests/unit/test_shell.py\n\tmodified:   heatclient/tests/unit/test_template_utils.py\n\nChange-Id: If3a47e610264fe65d76b34c088a1ab3199d72438\n'}, {'number': 3, 'created': '2015-06-19 08:32:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-heatclient/commit/8506ae14074884c25d557b2c6c4e6d15f308769e', 'message': 'Fixed VerifyAll() when test case does ReplayAll()\n\nVerifyAll() methods moved to setUp into addCleanup method.\nRedundant VerifyAll() methods were removed.\n\nFixed after review\n- deleted redunant VerifyAll from file heatclient/tests/unit/test_utils.py\n- removed ResetAll\n- fixed some broken tests\n\nChange-Id: If3a47e610264fe65d76b34c088a1ab3199d72438\nCloses-Bug: #1419469\n'}, {'number': 4, 'created': '2015-06-19 08:39:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-heatclient/commit/3105f53278834b037fe3775faa2a605580f64d9c', 'message': 'Fixed VerifyAll() when test case does ReplayAll()\n\nVerifyAll() methods moved to setUp into addCleanup method.\nRedundant VerifyAll() methods were removed.\n\nFixed after review\n- deleted redunant VerifyAll from file heatclient/tests/unit/test_utils.py\n- removed ResetAll\n- fixed some broken tests\n\nChange-Id: If3a47e610264fe65d76b34c088a1ab3199d72438\nCloses-Bug: #1419469\n'}, {'number': 5, 'created': '2015-06-19 10:00:40.000000000', 'files': ['heatclient/tests/unit/test_events.py', 'heatclient/tests/unit/test_shell.py', 'heatclient/tests/unit/test_utils.py', 'heatclient/tests/unit/test_common_http.py', 'heatclient/tests/unit/test_template_utils.py', 'heatclient/tests/unit/test_resources.py'], 'web_link': 'https://opendev.org/openstack/python-heatclient/commit/868a116f178b5d3f2749f4b5b0c736b73d60e439', 'message': 'Fixed VerifyAll() when test case does ReplayAll()\n\n- VerifyAll() methods moved to setUp into addCleanup method for some tests\n- redundant VerifyAll() methods were removed\n- removed ResetAll() methods\n- fixed some broken tests\n\nChange-Id: If3a47e610264fe65d76b34c088a1ab3199d72438\nCloses-Bug: #1419469\n'}]",2,189842,868a116f178b5d3f2749f4b5b0c736b73d60e439,21,8,5,15985,,,0,"Fixed VerifyAll() when test case does ReplayAll()

- VerifyAll() methods moved to setUp into addCleanup method for some tests
- redundant VerifyAll() methods were removed
- removed ResetAll() methods
- fixed some broken tests

Change-Id: If3a47e610264fe65d76b34c088a1ab3199d72438
Closes-Bug: #1419469
",git fetch https://review.opendev.org/openstack/python-heatclient refs/changes/42/189842/1 && git format-patch -1 --stdout FETCH_HEAD,"['heatclient/tests/unit/test_events.py', 'heatclient/tests/unit/test_shell.py', 'heatclient/tests/unit/test_common_http.py', 'heatclient/tests/unit/test_template_utils.py', 'heatclient/tests/unit/test_resources.py']",5,2a80a654142ac83a282c4fd8733845d7baf96a8d,, self.addCleanup(self.m.VerifyAll),,3,33
openstack%2Fpycadf~master~I87720e35356a911b42fc89c64164a63358e5efc6,openstack/pycadf,master,I87720e35356a911b42fc89c64164a63358e5efc6,Updated from global requirements,MERGED,2015-06-22 08:27:29.000000000,2015-06-24 23:56:23.000000000,2015-06-24 23:56:23.000000000,"[{'_account_id': 3}, {'_account_id': 2903}, {'_account_id': 6482}, {'_account_id': 16272}]","[{'number': 1, 'created': '2015-06-22 08:27:29.000000000', 'files': ['requirements.txt', 'test-requirements.txt', 'setup.py'], 'web_link': 'https://opendev.org/openstack/pycadf/commit/f7d3f480cd4c3983ce2262315ed22591e177a0dc', 'message': 'Updated from global requirements\n\nChange-Id: I87720e35356a911b42fc89c64164a63358e5efc6\n'}]",0,194017,f7d3f480cd4c3983ce2262315ed22591e177a0dc,8,4,1,11131,,,0,"Updated from global requirements

Change-Id: I87720e35356a911b42fc89c64164a63358e5efc6
",git fetch https://review.opendev.org/openstack/pycadf refs/changes/17/194017/1 && git format-patch -1 --stdout FETCH_HEAD,"['requirements.txt', 'test-requirements.txt', 'setup.py']",3,f7d3f480cd4c3983ce2262315ed22591e177a0dc,openstack/requirements,,#!/usr/bin/env python,7,8
openstack%2Fglance~master~I3a54f9eb4e089dbbbc68a5b25fadd30502c92012,openstack/glance,master,I3a54f9eb4e089dbbbc68a5b25fadd30502c92012,Add an API call to discover the list of available artifact types,MERGED,2015-06-17 14:48:48.000000000,2015-06-24 23:51:53.000000000,2015-06-24 23:45:44.000000000,"[{'_account_id': 3}, {'_account_id': 2537}, {'_account_id': 6159}, {'_account_id': 8127}, {'_account_id': 9096}, {'_account_id': 9303}, {'_account_id': 11391}, {'_account_id': 12000}, {'_account_id': 16658}]","[{'number': 1, 'created': '2015-06-17 14:48:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/b8d106e479f746c4c2f9412c2a0f885805076214', 'message': 'Add action ""type_of_plugins""\n\nThis action show list of plugins\n\nChange-Id: I3a54f9eb4e089dbbbc68a5b25fadd30502c92012\n'}, {'number': 2, 'created': '2015-06-18 15:34:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/88889a620634c6e9bd2ed72ba901274aa3660f0e', 'message': 'Add action for show list of plugins\n\nThis code adds the ability to get a list of all\navailable artifact plugins in the system\n\nFastTrack\n\nCo-Authored-By: Mike Fedosin <mfedosin@mirantis.com>\n\nChange-Id: I3a54f9eb4e089dbbbc68a5b25fadd30502c92012\n'}, {'number': 3, 'created': '2015-06-19 10:51:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/aceee8ec80078526b6f901774d75e9c33eadab01', 'message': 'Add action for show list of plugins\n\nThis code adds the ability to get a list of all\navailable artifact plugins in the system\n\nFastTrack\n\nCo-Authored-By: Mike Fedosin <mfedosin@mirantis.com>\n\nChange-Id: I3a54f9eb4e089dbbbc68a5b25fadd30502c92012\n'}, {'number': 4, 'created': '2015-06-19 13:25:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/5bfac8df27efb7ff5da4b342c055af342cc4fc2c', 'message': 'Add action for show list of plugins\n\nThis code adds the ability to get a list of all\navailable artifact plugins in the system\n\nFastTrack\n\nCo-Authored-By: Mike Fedosin <mfedosin@mirantis.com>\n\nChange-Id: I3a54f9eb4e089dbbbc68a5b25fadd30502c92012\n'}, {'number': 5, 'created': '2015-06-22 12:32:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/b84740c3dcfa76d4427c20bc3bf55a2bb95511c3', 'message': 'Add an API call to discover the list of available artifact types\n\nThis code adds the ability to get a list of all\navailable artifact types in the system\n\nFastTrack\nApiImpact\n\nCo-Authored-By: Mike Fedosin <mfedosin@mirantis.com>\n\nChange-Id: I3a54f9eb4e089dbbbc68a5b25fadd30502c92012\n'}, {'number': 6, 'created': '2015-06-22 13:30:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/862b5e53e3c7f92424d151ebc1a42d9b4984ebd1', 'message': 'Add an API call to discover the list of available artifact types\n\nThis code adds the ability to get a list of all\navailable artifact types in the system\n\nFastTrack\nApiImpact\n\nCo-Authored-By: Mike Fedosin <mfedosin@mirantis.com>\n\nChange-Id: I3a54f9eb4e089dbbbc68a5b25fadd30502c92012\n'}, {'number': 7, 'created': '2015-06-23 14:41:21.000000000', 'files': ['glance/api/v3/artifacts.py', 'glance/tests/functional/artifacts/test_artifacts.py', 'glance/api/v3/router.py'], 'web_link': 'https://opendev.org/openstack/glance/commit/e7439208e34c61cb9eff7c76ef39e23c341a2fb5', 'message': 'Add an API call to discover the list of available artifact types\n\nThis code adds the ability to get a list of all\navailable artifact types in the system\n\nFastTrack\nApiImpact\n\nCo-Authored-By: Mike Fedosin <mfedosin@mirantis.com>\n\nChange-Id: I3a54f9eb4e089dbbbc68a5b25fadd30502c92012\n'}]",20,192713,e7439208e34c61cb9eff7c76ef39e23c341a2fb5,30,9,7,16658,,,0,"Add an API call to discover the list of available artifact types

This code adds the ability to get a list of all
available artifact types in the system

FastTrack
ApiImpact

Co-Authored-By: Mike Fedosin <mfedosin@mirantis.com>

Change-Id: I3a54f9eb4e089dbbbc68a5b25fadd30502c92012
",git fetch https://review.opendev.org/openstack/glance refs/changes/13/192713/4 && git format-patch -1 --stdout FETCH_HEAD,"['glance/api/v3/artifacts.py', 'glance/api/v3/router.py']",2,b8d106e479f746c4c2f9412c2a0f885805076214,(detached," mapper.connect('/artifacts', controller=artifacts_resource, action='type_of_plugins', conditions={'method': ['GET']}) ",,64,0
openstack%2Fheat~master~I8f8fec9959bd76dc4f768979d2c807c368ce7633,openstack/heat,master,I8f8fec9959bd76dc4f768979d2c807c368ce7633,Coverage: Full coverage for engine plugin manager,MERGED,2015-06-18 09:26:10.000000000,2015-06-24 23:50:57.000000000,2015-06-24 23:50:56.000000000,"[{'_account_id': 3}, {'_account_id': 4715}, {'_account_id': 6577}, {'_account_id': 13009}]","[{'number': 1, 'created': '2015-06-18 09:26:10.000000000', 'files': ['heat/tests/test_plugin_manager.py'], 'web_link': 'https://opendev.org/openstack/heat/commit/0815cf337b3444fac92f8bed52a9ac663767b93b', 'message': 'Coverage: Full coverage for engine plugin manager\n\nAdded unit tests to get 100% coverage for engine plugin manager\n\nChange-Id: I8f8fec9959bd76dc4f768979d2c807c368ce7633\n'}]",0,193026,0815cf337b3444fac92f8bed52a9ac663767b93b,9,4,1,6498,,,0,"Coverage: Full coverage for engine plugin manager

Added unit tests to get 100% coverage for engine plugin manager

Change-Id: I8f8fec9959bd76dc4f768979d2c807c368ce7633
",git fetch https://review.opendev.org/openstack/heat refs/changes/26/193026/1 && git format-patch -1 --stdout FETCH_HEAD,['heat/tests/test_plugin_manager.py'],1,0815cf337b3444fac92f8bed52a9ac663767b93b,coverpluginmgr,"def error_test_exception_mapping(): raise Exception(""exception"") def invalid_type_test_mapping(): return 'foo' def none_return_test_mapping(): return def test_load_mapping_exception(self): pm = plugin_manager.PluginMapping('error_test_exception') self.assertRaisesRegex(Exception, ""exception"", pm.load_from_module, self.module()) def test_load_mapping_invalidtype(self): pm = plugin_manager.PluginMapping('invalid_type_test') self.assertEqual({}, pm.load_from_module(self.module())) def test_load_mapping_nonereturn(self): pm = plugin_manager.PluginMapping('none_return_test') self.assertEqual({}, pm.load_from_module(self.module())) ",,26,0
openstack%2Fglance~master~I9e03b1c26d9ad311b8ff4330d19b0db93e6d1157,openstack/glance,master,I9e03b1c26d9ad311b8ff4330d19b0db93e6d1157,Provide extra parameter for FakeDB,MERGED,2015-05-25 08:43:47.000000000,2015-06-24 23:50:43.000000000,2015-06-24 23:50:41.000000000,"[{'_account_id': 3}, {'_account_id': 6159}, {'_account_id': 11391}, {'_account_id': 13161}]","[{'number': 1, 'created': '2015-05-25 08:43:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/e626830fabf807944507f4c92f9a9aaf9bf862ce', 'message': ""Provide extra parameter for FakeDB\n\nIn our codebase for tests we are often using same pattern to initialize\nFakeDB instance which by default resets the database state and puts\nsample data into it. After that we manually reset it's state, which\nmakes no sense. Here are the steps we are performing right now:\n\n1. Reset database state\n2. Puts data into database\n3. Reset database state\n\nIt would be cleaner (and slightly faster) if we can skip these redundant\nsteps (2,3) in case we need an empty database. Provided fix allows\ndevelopers who are writting tests to decide if sample data should be\ninitialized or not.\n\nChange-Id: I9e03b1c26d9ad311b8ff4330d19b0db93e6d1157\n""}, {'number': 2, 'created': '2015-06-23 06:22:27.000000000', 'files': ['glance/tests/unit/v2/test_image_members_resource.py', 'glance/tests/unit/test_db.py', 'glance/tests/unit/utils.py', 'glance/tests/unit/v2/test_metadef_resources.py', 'glance/tests/unit/v2/test_image_actions_resource.py', 'glance/tests/unit/test_search.py', 'glance/tests/unit/v2/test_images_resource.py', 'glance/tests/unit/v2/test_tasks_resource.py', 'glance/tests/unit/test_db_metadef.py'], 'web_link': 'https://opendev.org/openstack/glance/commit/6c435ca491ec8d0d632282216b32122f3797e43e', 'message': ""Provide extra parameter for FakeDB\n\nIn our codebase for tests we are often using same pattern to initialize\nFakeDB instance which by default resets the database state and puts\nsample data into it. After that we manually reset it's state, which\nmakes no sense. Here are the steps we are performing right now:\n\n1. Reset database state\n2. Puts data into database\n3. Reset database state\n\nIt would be cleaner (and slightly faster) if we can skip these redundant\nsteps (2,3) in case we need an empty database. Provided fix allows\ndevelopers who are writting tests to decide if sample data should be\ninitialized or not.\n\nChange-Id: I9e03b1c26d9ad311b8ff4330d19b0db93e6d1157\n""}]",0,185329,6c435ca491ec8d0d632282216b32122f3797e43e,11,4,2,13161,,,0,"Provide extra parameter for FakeDB

In our codebase for tests we are often using same pattern to initialize
FakeDB instance which by default resets the database state and puts
sample data into it. After that we manually reset it's state, which
makes no sense. Here are the steps we are performing right now:

1. Reset database state
2. Puts data into database
3. Reset database state

It would be cleaner (and slightly faster) if we can skip these redundant
steps (2,3) in case we need an empty database. Provided fix allows
developers who are writting tests to decide if sample data should be
initialized or not.

Change-Id: I9e03b1c26d9ad311b8ff4330d19b0db93e6d1157
",git fetch https://review.opendev.org/openstack/glance refs/changes/29/185329/2 && git format-patch -1 --stdout FETCH_HEAD,"['glance/tests/unit/v2/test_image_members_resource.py', 'glance/tests/unit/test_db.py', 'glance/tests/unit/utils.py', 'glance/tests/unit/v2/test_metadef_resources.py', 'glance/tests/unit/test_search.py', 'glance/tests/unit/v2/test_images_resource.py', 'glance/tests/unit/v2/test_tasks_resource.py', 'glance/tests/unit/test_db_metadef.py']",8,e626830fabf807944507f4c92f9a9aaf9bf862ce,cleanup, self.db = unit_test_utils.FakeDB(initialize=False), self.db = unit_test_utils.FakeDB() self.db.reset() self.db.reset(),14,27
openstack%2Fproject-config~master~I1615dbc4d946cd5587a2e017e1b1ce946d78d6e1,openstack/project-config,master,I1615dbc4d946cd5587a2e017e1b1ce946d78d6e1,Add server-publish and server-release to Congress,ABANDONED,2015-06-24 23:07:42.000000000,2015-06-24 23:48:34.000000000,,[{'_account_id': 3}],"[{'number': 1, 'created': '2015-06-24 23:07:42.000000000', 'files': ['zuul/layout.yaml'], 'web_link': 'https://opendev.org/openstack/project-config/commit/4280331f8b9a5d2fc2d00fc90d5d083dc1295efd', 'message': 'Add server-publish and server-release to Congress\n\nChange-Id: I1615dbc4d946cd5587a2e017e1b1ce946d78d6e1\n'}]",0,195352,4280331f8b9a5d2fc2d00fc90d5d083dc1295efd,3,1,1,8215,,,0,"Add server-publish and server-release to Congress

Change-Id: I1615dbc4d946cd5587a2e017e1b1ce946d78d6e1
",git fetch https://review.opendev.org/openstack/project-config refs/changes/52/195352/1 && git format-patch -1 --stdout FETCH_HEAD,['zuul/layout.yaml'],1,4280331f8b9a5d2fc2d00fc90d5d083dc1295efd,, - name: openstack-server-publish-jobs - name: openstack-server-release-jobs,,2,0
openstack%2Fpython-glanceclient~master~I19b9915bedacec60fc584a7437a9b46a80a26bdc,openstack/python-glanceclient,master,I19b9915bedacec60fc584a7437a9b46a80a26bdc,Updated from global requirements,MERGED,2015-06-22 08:27:41.000000000,2015-06-24 23:40:27.000000000,2015-06-24 23:40:25.000000000,"[{'_account_id': 3}, {'_account_id': 6159}, {'_account_id': 16272}, {'_account_id': 16658}]","[{'number': 1, 'created': '2015-06-22 08:27:41.000000000', 'files': ['requirements.txt', 'test-requirements.txt', 'setup.py'], 'web_link': 'https://opendev.org/openstack/python-glanceclient/commit/b10e8938f9d2df28b1194499265660ccb90d3d51', 'message': 'Updated from global requirements\n\nChange-Id: I19b9915bedacec60fc584a7437a9b46a80a26bdc\n'}]",0,194021,b10e8938f9d2df28b1194499265660ccb90d3d51,8,4,1,11131,,,0,"Updated from global requirements

Change-Id: I19b9915bedacec60fc584a7437a9b46a80a26bdc
",git fetch https://review.opendev.org/openstack/python-glanceclient refs/changes/21/194021/1 && git format-patch -1 --stdout FETCH_HEAD,"['requirements.txt', 'test-requirements.txt', 'setup.py']",3,b10e8938f9d2df28b1194499265660ccb90d3d51,openstack/requirements,,#!/usr/bin/env python,10,11
openstack%2Fglance~master~I668a35a8d0e2d763cb8fd0a07e671d189973cfe7,openstack/glance,master,I668a35a8d0e2d763cb8fd0a07e671d189973cfe7,Imported Translations from Transifex,MERGED,2015-06-20 06:07:58.000000000,2015-06-24 23:39:33.000000000,2015-06-24 23:39:31.000000000,"[{'_account_id': 3}, {'_account_id': 6159}, {'_account_id': 16272}]","[{'number': 1, 'created': '2015-06-20 06:07:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/4af61436ba8955034dacf53fef9373f6a9db371d', 'message': 'Imported Translations from Transifex\n\nFor more information about this automatic import see:\nhttps://wiki.openstack.org/wiki/Translations/Infrastructure\n\nChange-Id: I668a35a8d0e2d763cb8fd0a07e671d189973cfe7\n'}, {'number': 2, 'created': '2015-06-21 06:09:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/297f04421285784007243cf48a0f5822cfa15172', 'message': 'Imported Translations from Transifex\n\nFor more information about this automatic import see:\nhttps://wiki.openstack.org/wiki/Translations/Infrastructure\n\nChange-Id: I668a35a8d0e2d763cb8fd0a07e671d189973cfe7\n'}, {'number': 3, 'created': '2015-06-22 06:08:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/916cea7f84db244ac43de4fcfd12942ed4080e8b', 'message': 'Imported Translations from Transifex\n\nFor more information about this automatic import see:\nhttps://wiki.openstack.org/wiki/Translations/Infrastructure\n\nChange-Id: I668a35a8d0e2d763cb8fd0a07e671d189973cfe7\n'}, {'number': 4, 'created': '2015-06-23 06:08:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/251e4ca3fc1e64bfeadb008d0c2799deff2da5bb', 'message': 'Imported Translations from Transifex\n\nFor more information about this automatic import see:\nhttps://wiki.openstack.org/wiki/Translations/Infrastructure\n\nChange-Id: I668a35a8d0e2d763cb8fd0a07e671d189973cfe7\n'}, {'number': 5, 'created': '2015-06-24 06:11:07.000000000', 'files': ['glance/locale/es/LC_MESSAGES/glance-log-info.po', 'glance/locale/pt_BR/LC_MESSAGES/glance-log-info.po', 'glance/locale/glance-log-error.pot', 'glance/locale/ko_KR/LC_MESSAGES/glance-log-error.po', 'glance/locale/en_GB/LC_MESSAGES/glance-log-warning.po', 'glance/locale/glance-log-warning.pot', 'glance/locale/pt_BR/LC_MESSAGES/glance-log-warning.po', 'glance/locale/en_GB/LC_MESSAGES/glance-log-info.po', 'glance/locale/es/LC_MESSAGES/glance-log-error.po', 'glance/locale/fr/LC_MESSAGES/glance-log-error.po', 'glance/locale/glance-log-info.pot', 'glance/locale/es/LC_MESSAGES/glance.po', 'glance/locale/es/LC_MESSAGES/glance-log-warning.po'], 'web_link': 'https://opendev.org/openstack/glance/commit/0302a55ed9270633a3828554187b9fabc077e7ae', 'message': 'Imported Translations from Transifex\n\nFor more information about this automatic import see:\nhttps://wiki.openstack.org/wiki/Translations/Infrastructure\n\nChange-Id: I668a35a8d0e2d763cb8fd0a07e671d189973cfe7\n'}]",0,193780,0302a55ed9270633a3828554187b9fabc077e7ae,19,3,5,11131,,,0,"Imported Translations from Transifex

For more information about this automatic import see:
https://wiki.openstack.org/wiki/Translations/Infrastructure

Change-Id: I668a35a8d0e2d763cb8fd0a07e671d189973cfe7
",git fetch https://review.opendev.org/openstack/glance refs/changes/80/193780/5 && git format-patch -1 --stdout FETCH_HEAD,['glance/locale/es/LC_MESSAGES/glance-log-error.po'],1,4af61436ba8955034dacf53fef9373f6a9db371d,transifex/translations,"""POT-Creation-Date: 2015-06-20 06:07+0000\n"" ""PO-Revision-Date: 2015-06-19 13:50+0000\n""msgid """" ""Exception encountered while tee'ing image '%(image_id)s' into cache: "" ""%(error)s. Continuing with response."" msgstr """" ""Se ha encontrado una excepcin al colocar la imagen '%(image_id)s' en la "" ""memoria cach: %(error)s. Continuando con la respuesta. "" #, python-formatmsgid ""Failed to load the %s executor provided in the config."" msgstr ""Error al cargar el ejecutor %s en la configuracin."" #, python-format msgid ""Failed to retrieve RBAC filters from search plugin %(ext)s: %(e)s"" msgstr """" ""Error al recuperar filtros RBAC desde el complemento de bsqueda %(ext)s: "" ""%(e)s"" #, python-formatmsgid ""Forbidden to create resource type. Reason: %(reason)s"" msgstr ""Se olvid crear tipo de recurso. Razn: %(reason)s"" #, python-formatmsgid """" ""Task [%(task_id)s] status failed to change from %(cur_status)s to "" ""%(new_status)s"" msgstr """" ""Error al cambiar el estado de tarea [%(task_id)s] de %(cur_status)s a "" ""%(new_status)s"" #, python-formatmsgid ""Unable to create image %s"" msgstr ""No es posible crear imagen %s"" #, python-format msgid ""Unable to delete image %s"" msgstr ""No es posible eliminar imagen %s"" msgid ""Unable to get images"" msgstr ""No es posible obtener imgenes "" #, python-format#, python-format msgid ""Unable to show image %s"" msgstr ""No es posible mostrar imagen %s"" #, python-format msgid ""Unable to update image %s"" msgstr ""No ha sido posible actualizar la imagen %s"" ","""POT-Creation-Date: 2015-06-19 06:10+0000\n"" ""PO-Revision-Date: 2015-06-18 22:48+0000\n""",51,2
openstack%2Fglance_store~master~I3f4e3eb8d91edbfd10dc2233e3e83a3f90313cac,openstack/glance_store,master,I3f4e3eb8d91edbfd10dc2233e3e83a3f90313cac,Do not used named args when using swiftclient,MERGED,2015-06-24 21:59:10.000000000,2015-06-24 23:32:23.000000000,2015-06-24 23:32:22.000000000,"[{'_account_id': 3}, {'_account_id': 1179}, {'_account_id': 7233}, {'_account_id': 11356}, {'_account_id': 12000}]","[{'number': 1, 'created': '2015-06-24 21:59:10.000000000', 'files': ['glance_store/_drivers/swift/store.py'], 'web_link': 'https://opendev.org/openstack/glance_store/commit/01c8ccdcf5e9c8bacabf84930e802a8ebaf0448d', 'message': 'Do not used named args when using swiftclient\n\nThe arguments ""container"" and ""obj"" are not named arguments in swiftclient, and\na pending change to python-swiftclient [1] is thus always failing in the gate.\n\nCo-Authored-By: Clay Gerrard <clay.gerrard@gmail.com>\n\n[1]: https://review.openstack.org/#/c/189815/\n\nChange-Id: I3f4e3eb8d91edbfd10dc2233e3e83a3f90313cac\n'}]",0,195337,01c8ccdcf5e9c8bacabf84930e802a8ebaf0448d,10,5,1,6968,,,0,"Do not used named args when using swiftclient

The arguments ""container"" and ""obj"" are not named arguments in swiftclient, and
a pending change to python-swiftclient [1] is thus always failing in the gate.

Co-Authored-By: Clay Gerrard <clay.gerrard@gmail.com>

[1]: https://review.openstack.org/#/c/189815/

Change-Id: I3f4e3eb8d91edbfd10dc2233e3e83a3f90313cac
",git fetch https://review.opendev.org/openstack/glance_store refs/changes/37/195337/1 && git format-patch -1 --stdout FETCH_HEAD,['glance_store/_drivers/swift/store.py'],1,01c8ccdcf5e9c8bacabf84930e802a8ebaf0448d,," location.container, location.obj, location.container, location.obj)"," container=location.container, obj=location.obj, container=location.container, obj=location.obj)",2,2
openstack%2Fnetworking-ovn~master~I3b719779885385c15b623e2091c17b05460a6043,openstack/networking-ovn,master,I3b719779885385c15b623e2091c17b05460a6043,"DON""T REVIEW... test",ABANDONED,2015-06-24 19:56:41.000000000,2015-06-24 23:27:28.000000000,,"[{'_account_id': 3}, {'_account_id': 4395}]","[{'number': 1, 'created': '2015-06-24 19:56:41.000000000', 'files': ['README.rst'], 'web_link': 'https://opendev.org/openstack/networking-ovn/commit/4a9bd79429f44fe7c87aea4a0fa2e429a26d4182', 'message': 'DON""T REVIEW... test\n\nChange-Id: I3b719779885385c15b623e2091c17b05460a6043\n'}]",0,195289,4a9bd79429f44fe7c87aea4a0fa2e429a26d4182,4,2,1,4395,,,0,"DON""T REVIEW... test

Change-Id: I3b719779885385c15b623e2091c17b05460a6043
",git fetch https://review.opendev.org/openstack/networking-ovn refs/changes/89/195289/1 && git format-patch -1 --stdout FETCH_HEAD,['README.rst'],1,4a9bd79429f44fe7c87aea4a0fa2e429a26d4182,,,,1,0
openstack%2Fnova~stable%2Fkilo~I3b9f60a2c4aea904f39d6914c8f35c4d682a6b3a,openstack/nova,stable/kilo,I3b9f60a2c4aea904f39d6914c8f35c4d682a6b3a,network: fix instance cache refresh for empty list,MERGED,2015-06-08 15:54:50.000000000,2015-06-24 23:25:35.000000000,2015-06-24 23:25:32.000000000,"[{'_account_id': 3}, {'_account_id': 5170}, {'_account_id': 6873}, {'_account_id': 8213}, {'_account_id': 10118}, {'_account_id': 15741}]","[{'number': 1, 'created': '2015-06-08 15:54:50.000000000', 'files': ['nova/tests/unit/network/test_neutronv2.py', 'nova/network/neutronv2/api.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/4bb1e081bb87982f74c620b5b1f2376f8eb86640', 'message': 'network: fix instance cache refresh for empty list\n\nThe bug introduce a race condition makes network_info as an\nempty value. When trying to refresh cache we should use data\nreturned per Neutron.\n\nCo-Authored-By: Lee Yarwood <lyarwood@redhat.com>\n\nCloses-Bug: #1407664\nChange-Id: I3b9f60a2c4aea904f39d6914c8f35c4d682a6b3a\n(cherry picked from commit 3a850ac72d60b3823c5cb4a971eaf02c580a4a20)\n'}]",0,189350,4bb1e081bb87982f74c620b5b1f2376f8eb86640,9,6,1,7730,,,0,"network: fix instance cache refresh for empty list

The bug introduce a race condition makes network_info as an
empty value. When trying to refresh cache we should use data
returned per Neutron.

Co-Authored-By: Lee Yarwood <lyarwood@redhat.com>

Closes-Bug: #1407664
Change-Id: I3b9f60a2c4aea904f39d6914c8f35c4d682a6b3a
(cherry picked from commit 3a850ac72d60b3823c5cb4a971eaf02c580a4a20)
",git fetch https://review.opendev.org/openstack/nova refs/changes/50/189350/1 && git format-patch -1 --stdout FETCH_HEAD,"['nova/network/neutronv2/api.py', 'nova/tests/unit/network/test_neutronv2.py']",2,4bb1e081bb87982f74c620b5b1f2376f8eb86640,," @mock.patch('nova.network.neutronv2.api.API._nw_info_get_subnets') @mock.patch('nova.network.neutronv2.api.API._nw_info_get_ips') @mock.patch('nova.network.neutronv2.api.API._nw_info_build_network') @mock.patch('nova.network.neutronv2.api.API._get_preexisting_port_ids') @mock.patch('nova.network.neutronv2.api.API._gather_port_ids_and_networks') def test_build_network_info_model_empty( self, mock_gather_port_ids_and_networks, mock_get_preexisting_port_ids, mock_nw_info_build_network, mock_nw_info_get_ips, mock_nw_info_get_subnets): api = neutronapi.API() fake_inst = objects.Instance() fake_inst.project_id = 'fake' fake_inst.uuid = 'uuid' fake_inst.info_cache = objects.InstanceInfoCache() fake_inst.info_cache.network_info = model.NetworkInfo() fake_ports = [ # admin_state_up=True and status='ACTIVE' thus vif.active=True {'id': 'port1', 'network_id': 'net-id', 'admin_state_up': True, 'status': 'ACTIVE', 'fixed_ips': [{'ip_address': '1.1.1.1'}], 'mac_address': 'de:ad:be:ef:00:01', 'binding:vif_type': model.VIF_TYPE_BRIDGE, 'binding:vnic_type': model.VNIC_TYPE_NORMAL, 'binding:vif_details': {}, }, ] fake_subnets = [model.Subnet(cidr='1.0.0.0/8')] neutronapi.get_client(mox.IgnoreArg(), admin=True).MultipleTimes( ).AndReturn(self.moxed_client) self.moxed_client.list_ports( tenant_id='fake', device_id='uuid').AndReturn( {'ports': fake_ports}) mock_gather_port_ids_and_networks.return_value = (None, None) mock_get_preexisting_port_ids.return_value = [] mock_nw_info_build_network.return_value = (None, None) mock_nw_info_get_ips.return_value = [] mock_nw_info_get_subnets.return_value = fake_subnets self.mox.ReplayAll() neutronapi.get_client('fake') nw_infos = api._build_network_info_model( self.context, fake_inst) self.assertEqual(len(nw_infos), 1) ",,57,0
openstack%2Fopenstack-ansible~master~I1b15869e43bd082aa60f04707f389968eeb80d24,openstack/openstack-ansible,master,I1b15869e43bd082aa60f04707f389968eeb80d24,Updated master to the latest SHAs - 22.06.2015,MERGED,2015-06-21 00:54:34.000000000,2015-06-24 23:24:15.000000000,2015-06-24 23:24:13.000000000,"[{'_account_id': 3}, {'_account_id': 425}, {'_account_id': 6816}, {'_account_id': 7353}, {'_account_id': 12000}, {'_account_id': 12892}]","[{'number': 1, 'created': '2015-06-21 00:54:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/3252a16438f6fe3138c29a7502ed5ca5e2b75ee3', 'message': 'Updated master to the latest SHAs\n\nUpdates all of master to track the latest releases and changes coming in\nthe Librety cycle.\n\nChange-Id: I1b15869e43bd082aa60f04707f389968eeb80d24\n'}, {'number': 2, 'created': '2015-06-21 01:15:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/76e07462286ef79b3a0a9d8ab06ce614ce0d4686', 'message': 'Updated master to the latest SHAs\n\nUpdates all of master to track the latest releases and changes coming in\nthe Liberty cycle.\n\nChange-Id: I1b15869e43bd082aa60f04707f389968eeb80d24\n'}, {'number': 3, 'created': '2015-06-22 13:37:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/54bec161677f9856d9c7d225801b3f7790e1c176', 'message': 'Updated master to the latest SHAs - 06.20.2015\n\nUpdates all of master to track the latest releases and changes coming in\nthe Liberty cycle.\n\nChange-Id: I1b15869e43bd082aa60f04707f389968eeb80d24\n'}, {'number': 4, 'created': '2015-06-22 21:14:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/519b233d9dd5118b58859f33dc152761d72483df', 'message': 'Updated master to the latest SHAs - 06.20.2015\n\nUpdates all of master to track the latest releases and changes coming in\nthe Liberty cycle.\n\nChange-Id: I1b15869e43bd082aa60f04707f389968eeb80d24\n'}, {'number': 5, 'created': '2015-06-23 19:44:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/9f44419c51fde6df6af63c3702256776af3bffef', 'message': 'Updated master to the latest SHAs - 06.20.2015\n\nUpdates all of master to track the latest releases and changes coming in\nthe Liberty cycle.\n\nChange-Id: I1b15869e43bd082aa60f04707f389968eeb80d24\n'}, {'number': 6, 'created': '2015-06-24 14:28:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/00cf0f47b96255900b804bde5a8771c9c2136a48', 'message': 'Updated master to the latest SHAs - 06.20.2015\n\nUpdates all of master to track the latest releases and changes coming in\nthe Liberty cycle.\n\nChange-Id: I1b15869e43bd082aa60f04707f389968eeb80d24\n'}, {'number': 7, 'created': '2015-06-24 14:29:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/ab7fdaa52f58fb6d5e7aae4c0149e925a861b2bc', 'message': 'Updated master to the latest SHAs - 22.06.2015\n\nUpdates all of master to track the latest releases and changes coming in\nthe Liberty cycle.\n\nChange-Id: I1b15869e43bd082aa60f04707f389968eeb80d24\n'}, {'number': 8, 'created': '2015-06-24 15:50:42.000000000', 'files': ['playbooks/defaults/repo_packages/openstack_services.yml', 'scripts/update-revision.sh', '.gitignore', 'scripts/sources-branch-updater.sh', 'playbooks/defaults/repo_packages/openstack_other.yml', 'playbooks/defaults/repo_packages/openstack_clients.yml'], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/36a505bb68dccf560e67a1a95a4b977b265d990f', 'message': 'Updated master to the latest SHAs - 22.06.2015\n\nUpdates all of master to track the latest releases and changes coming in\nthe Liberty cycle.\n\nChange-Id: I1b15869e43bd082aa60f04707f389968eeb80d24\n'}]",7,193844,36a505bb68dccf560e67a1a95a4b977b265d990f,38,6,8,7353,,,0,"Updated master to the latest SHAs - 22.06.2015

Updates all of master to track the latest releases and changes coming in
the Liberty cycle.

Change-Id: I1b15869e43bd082aa60f04707f389968eeb80d24
",git fetch https://review.opendev.org/openstack/openstack-ansible refs/changes/44/193844/5 && git format-patch -1 --stdout FETCH_HEAD,"['playbooks/defaults/repo_packages/openstack_services.yml', 'playbooks/defaults/repo_packages/openstack_other.yml', 'playbooks/defaults/repo_packages/openstack_clients.yml']",3,3252a16438f6fe3138c29a7502ed5ca5e2b75ee3,,"barbicanclient_git_install_branch: 2f9dc5eb0d5124df41620c6f34202219687f5583 # HEAD of ""master"" as of 20.06.2015ceilometerclient_git_install_branch: 7e4d2edc970a555b982d7081a95c6a1ada6d58de # HEAD of ""master"" as of 20.06.2015cinderclient_git_install_branch: 79145aed9db9908be1d2bd8b6ea2ef142336ad16 # HEAD of ""master"" as of 20.06.2015designateclient_git_install_branch: 4eb1c541d66383522f806135abdc84c36239f08c # HEAD of ""master"" as of 20.06.2015glanceclient_git_install_branch: dc3dd87de925e165faa1d79fd457a2ffa53b801c # HEAD of ""master"" as of 20.06.2015heatclient_git_install_branch: 4b193e11712847e9b5a80a507124f5d22749ae8d # HEAD of ""master"" as of 20.06.2015ironicclient_git_install_branch: 3f4671a0b7eb5c300291c2e92082d16b96e6316c # HEAD of ""master"" as of 20.06.2015keystoneclient_git_install_branch: 56a7d0b52c2a9f6eeec345124c9da2d4faccc2f4 # HEAD of ""master"" as of 20.06.2015neutronclient_git_install_branch: dcb7401a04c96aeb7c00a456b1ba0c77134a0a25 # HEAD of ""master"" as of 20.06.2015novaclient_git_install_branch: 39020950d651b9601a136ca0b90e6b5085f373ca # HEAD of ""master"" as of 20.06.2015openstackclient_git_install_branch: 3120a0bd2ac2dd8cf918abfeae8357e20ac6b34e # HEAD of ""master"" as of 20.06.2015saharaclient_git_install_branch: 3260c2f66eb01c9519b3b8710b1a98ac40006bcf # HEAD of ""master"" as of 20.06.2015swiftclient_git_install_branch: 7c716997a8ede3f98741709b0594340df9849a76 # HEAD of ""master"" as of 20.06.2015troveclient_git_install_branch: dffbd6fc6ed9ea2e9a3fc94696cd217bd9762df5 # HEAD of ""master"" as of 20.06.2015tuskarclient_git_install_branch: 6fa19d5d106a353188cbccd286a710d1ada4d1d8 # HEAD of ""master"" as of 20.06.2015zaqarclient_git_install_branch: 09de9ee38127c4cea67553881fa71991df4d9e37 # HEAD of ""master"" as of 20.06.2015","barbicanclient_git_install_branch: e3431cd818de996f57528bb2f6127d192a886ec4 # HEAD of ""master"" as of 08.06.2015ceilometerclient_git_install_branch: 662a4642046ff86fefb56e89bfe269ff6b8bf100 # HEAD of ""master"" as of 08.06.2015cinderclient_git_install_branch: 91bf760989a6c992918d6eadb038d7265ea18287 # HEAD of ""master"" as of 08.06.2015designateclient_git_install_branch: 1548cb1af60f25c4a535251caa01089c80a0b416 # HEAD of ""master"" as of 08.06.2015glanceclient_git_install_branch: dfa98ab04c7fb7260b25e92af18caa2a016698c6 # HEAD of ""master"" as of 08.06.2015heatclient_git_install_branch: 296c8c2a73b936ce1cfc205f447ecc6a8183ebd3 # HEAD of ""master"" as of 08.06.2015ironicclient_git_install_branch: 01d2520788a1effb66fa6009fc8c8b4e38aace28 # HEAD of ""master"" as of 08.06.2015keystoneclient_git_install_branch: 7f407488cefd9668b31df6b4050209438675a95f # HEAD of ""master"" as of 08.06.2015neutronclient_git_install_branch: 7eb3241650ad87d2f6ca5aa45b3a2415eafe7207 # HEAD of ""master"" as of 08.06.2015novaclient_git_install_branch: 773eea811df7be3dcb73dc2ae16354b172f442c6 # HEAD of ""master"" as of 08.06.2015openstackclient_git_install_branch: 7cf779004e5e9eab9abee8d8a5bc2db3dfa8bd5d # HEAD of ""master"" as of 08.06.2015saharaclient_git_install_branch: 963d8ce6bbdfa151defe6702c8d0c31300607c03 # HEAD of ""master"" as of 08.06.2015swiftclient_git_install_branch: ec3e2ab3a099b1276ae5d87fda936567f64423dc # HEAD of ""master"" as of 08.06.2015troveclient_git_install_branch: e586689e0890da00f29a474b35a8e3537654b72e # HEAD of ""master"" as of 08.06.2015tuskarclient_git_install_branch: 47fdee09d06d80b523ab6e68fb7ebb93074b4659 # HEAD of ""master"" as of 08.06.2015zaqarclient_git_install_branch: 09de9ee38127c4cea67553881fa71991df4d9e37 # HEAD of ""master"" as of 08.06.2015",31,31
openstack%2Fkolla~master~I4a7ba1554bdcba3f2147eb4eaa628d1cc19f84fd,openstack/kolla,master,I4a7ba1554bdcba3f2147eb4eaa628d1cc19f84fd,centos-rdo-neutron-base fails to build,MERGED,2015-06-24 22:04:15.000000000,2015-06-24 23:22:09.000000000,2015-06-24 23:18:55.000000000,"[{'_account_id': 3}, {'_account_id': 2834}, {'_account_id': 3098}, {'_account_id': 10419}]","[{'number': 1, 'created': '2015-06-24 22:04:15.000000000', 'files': ['docker/centos/binary/neutron/neutron-base/Dockerfile'], 'web_link': 'https://opendev.org/openstack/kolla/commit/92e2f8555225b233a4b8023cd40ef729038ec1fb', 'message': 'centos-rdo-neutron-base fails to build\n\nAn ordering problem with the Dockerfile resultled in this\ncontainer and all thin containers failing to build.  This patch\nFixes that problem.\n\nChange-Id: I4a7ba1554bdcba3f2147eb4eaa628d1cc19f84fd\nCo-Authored-By: Jeff Peeler <jpeeler@redhat.com>\nCloses-Bug: #1468486\n'}]",0,195339,92e2f8555225b233a4b8023cd40ef729038ec1fb,8,4,1,2834,,,0,"centos-rdo-neutron-base fails to build

An ordering problem with the Dockerfile resultled in this
container and all thin containers failing to build.  This patch
Fixes that problem.

Change-Id: I4a7ba1554bdcba3f2147eb4eaa628d1cc19f84fd
Co-Authored-By: Jeff Peeler <jpeeler@redhat.com>
Closes-Bug: #1468486
",git fetch https://review.opendev.org/openstack/kolla refs/changes/39/195339/1 && git format-patch -1 --stdout FETCH_HEAD,['docker/centos/binary/neutron/neutron-base/Dockerfile'],1,92e2f8555225b233a4b8023cd40ef729038ec1fb,bug/1468486,RUN mkdir -p /opt/kolla/host_proc ,RUN mkdir -p /opt/kolla/host_proc,2,1
openstack%2Fdevstack~master~I7a2f3ee9c74b34fdf003f65f4936074a236784c2,openstack/devstack,master,I7a2f3ee9c74b34fdf003f65f4936074a236784c2,Start and stop n-net with n-cpu for partial upgrades,ABANDONED,2015-06-08 21:38:57.000000000,2015-06-24 23:20:53.000000000,,"[{'_account_id': 3}, {'_account_id': 1561}, {'_account_id': 1849}, {'_account_id': 2750}, {'_account_id': 4393}, {'_account_id': 8871}, {'_account_id': 10385}]","[{'number': 1, 'created': '2015-06-08 21:38:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack/commit/b7577a646732610b72fc590a1d41ac65f30e4894', 'message': 'Break out nova-network stop/start like nova-compute\n\nThis will allow us to bring n-net into the partial-ncpu job as\nan un-upgraded service for testing.\n\nChange-Id: I7a2f3ee9c74b34fdf003f65f4936074a236784c2\n'}, {'number': 2, 'created': '2015-06-09 00:00:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack/commit/a4fe564581c98845c1df40511247817c6ad2779e', 'message': 'Break out nova-network stop/start like nova-compute\n\nThis will allow us to bring n-net into the partial-ncpu job as\nan un-upgraded service for testing.\n\nChange-Id: I7a2f3ee9c74b34fdf003f65f4936074a236784c2\n'}, {'number': 3, 'created': '2015-06-09 14:12:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack/commit/8902b104a0b4f0bffcff542581055011c6d296ba', 'message': 'Start and stop n-net with n-cpu for partial upgrades\n\nIn a real environment, n-net will be co-located with n-cpu, and\nupgraded at the same time. For the sake of expediency, this patch\nmakes n-cpu and n-net be started and stopped at the same time as\n""the compute family of services."" Grenade\'s existing partial upgrade\nsupport will still apply, and we\'ll get a more realistic test.\n\nChange-Id: I7a2f3ee9c74b34fdf003f65f4936074a236784c2\n'}, {'number': 4, 'created': '2015-06-09 16:37:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack/commit/18e9151b03583ba2426e95fc74d1733633777eb0', 'message': 'Start and stop n-net with n-cpu for partial upgrades\n\nIn a real environment, n-net will be co-located with n-cpu, and\nupgraded at the same time. For the sake of expediency, this patch\nmakes n-cpu and n-net be started and stopped at the same time as\n""the compute family of services."" Grenade\'s existing partial upgrade\nsupport will still apply, and we\'ll get a more realistic test.\n\nDepends-On: I95b085fbb40ad07777cdac322908b6e6d31aa5b1\nChange-Id: I7a2f3ee9c74b34fdf003f65f4936074a236784c2\n'}, {'number': 5, 'created': '2015-06-10 09:43:18.000000000', 'files': ['lib/nova'], 'web_link': 'https://opendev.org/openstack/devstack/commit/308ea80bbdfa74e1b4f3851ed8c9d07fbb53ac1a', 'message': 'Start and stop n-net with n-cpu for partial upgrades\n\nIn a real environment, n-net will be co-located with n-cpu, and\nupgraded at the same time. For the sake of expediency, this patch\nmakes n-cpu and n-net be started and stopped at the same time as\n""the compute family of services."" Grenade\'s existing partial upgrade\nsupport will still apply, and we\'ll get a more realistic test.\n\nDepends-On: Ibf22143cb0a1bd56d8457eff6d2807307d264ae0\nChange-Id: I7a2f3ee9c74b34fdf003f65f4936074a236784c2'}]",0,189478,308ea80bbdfa74e1b4f3851ed8c9d07fbb53ac1a,33,7,5,4393,,,0,"Start and stop n-net with n-cpu for partial upgrades

In a real environment, n-net will be co-located with n-cpu, and
upgraded at the same time. For the sake of expediency, this patch
makes n-cpu and n-net be started and stopped at the same time as
""the compute family of services."" Grenade's existing partial upgrade
support will still apply, and we'll get a more realistic test.

Depends-On: Ibf22143cb0a1bd56d8457eff6d2807307d264ae0
Change-Id: I7a2f3ee9c74b34fdf003f65f4936074a236784c2",git fetch https://review.opendev.org/openstack/devstack refs/changes/78/189478/5 && git format-patch -1 --stdout FETCH_HEAD,['lib/nova'],1,b7577a646732610b72fc590a1d41ac65f30e4894,partial-n-cpu,"function start_nova_network() { local old_path=$PATH export PATH=$NOVA_BIN_DIR:$PATH run_process n-net ""$NOVA_BIN_DIR/nova-network --config-file $compute_cell_conf"" export PATH=$old_path } start_nova_networkfunction stop_nova_network { stop_process n-net } for serv in n-api n-crt n-sch n-novnc n-xvnc n-cauth n-spice n-cond n-cell n-cell n-api-meta n-obj n-sproxy; do stop_nova_network"," run_process n-net ""$NOVA_BIN_DIR/nova-network --config-file $compute_cell_conf"" for serv in n-api n-crt n-net n-sch n-novnc n-xvnc n-cauth n-spice n-cond n-cell n-cell n-api-meta n-obj n-sproxy; do",16,2
openstack%2Fkeystoneauth-saml2~master~Ia4e2e78bb8fbd9bf0c83383dd45ec5050977c6ac,openstack/keystoneauth-saml2,master,Ia4e2e78bb8fbd9bf0c83383dd45ec5050977c6ac,Updated from global requirements,MERGED,2015-06-16 17:26:32.000000000,2015-06-24 23:16:47.000000000,2015-06-24 23:16:45.000000000,"[{'_account_id': 3}, {'_account_id': 2903}, {'_account_id': 16272}]","[{'number': 1, 'created': '2015-06-16 17:26:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystoneauth-saml2/commit/e6a4da6af8cca0876799bf895a2e590ff99478e7', 'message': 'Updated from global requirements\n\nChange-Id: Ia4e2e78bb8fbd9bf0c83383dd45ec5050977c6ac\n'}, {'number': 2, 'created': '2015-06-22 08:27:52.000000000', 'files': ['requirements.txt', 'test-requirements.txt', 'setup.py'], 'web_link': 'https://opendev.org/openstack/keystoneauth-saml2/commit/841e186716b2ab01c415df1eec151f505aa68fcf', 'message': 'Updated from global requirements\n\nChange-Id: Ia4e2e78bb8fbd9bf0c83383dd45ec5050977c6ac\n'}]",0,192320,841e186716b2ab01c415df1eec151f505aa68fcf,9,3,2,11131,,,0,"Updated from global requirements

Change-Id: Ia4e2e78bb8fbd9bf0c83383dd45ec5050977c6ac
",git fetch https://review.opendev.org/openstack/keystoneauth-saml2 refs/changes/20/192320/2 && git format-patch -1 --stdout FETCH_HEAD,['setup.py'],1,e6a4da6af8cca0876799bf895a2e590ff99478e7,openstack/requirements,,,0,0
openstack%2Fheat~master~I0aff7a7805f5be474c661a726ab27bbbe0a9d2b8,openstack/heat,master,I0aff7a7805f5be474c661a726ab27bbbe0a9d2b8,Add preview option to stack abandon,ABANDONED,2014-04-02 08:45:30.000000000,2015-06-24 23:16:37.000000000,,"[{'_account_id': 3}, {'_account_id': 1633}, {'_account_id': 4328}, {'_account_id': 4571}, {'_account_id': 4715}, {'_account_id': 6498}, {'_account_id': 7230}, {'_account_id': 7233}, {'_account_id': 7253}, {'_account_id': 7404}, {'_account_id': 7761}, {'_account_id': 7896}, {'_account_id': 8289}, {'_account_id': 8505}, {'_account_id': 9542}, {'_account_id': 13009}]","[{'number': 1, 'created': '2014-04-02 08:45:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/2a96160471e3faf280a0ccc40472e4654c708700', 'message': ""Add dry_run option to stack abandon\n\ndry_run is used to just get abandon data without deleting the\nstack. It's very useful to perform dry_run abandon before stack update\nto get a copy of healthy data for later adopt if update failure found.\n\nCloses-Bug: #1300830\nChange-Id: I0aff7a7805f5be474c661a726ab27bbbe0a9d2b8\n""}, {'number': 2, 'created': '2014-04-02 10:09:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/950b3720a2fbee3180137497f9ac4ecbcd64dbe3', 'message': ""Add dry_run option to stack abandon\n\nOption dry_run is used to get abandon data without deleting the\nstack. It's useful to perform dry_run abandon before stack update to\nget a copy of healthy data for later adopt if update failure found.\n\nCloses-Bug: #1300830\nChange-Id: I0aff7a7805f5be474c661a726ab27bbbe0a9d2b8\n""}, {'number': 3, 'created': '2014-04-03 10:18:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/31f7f2aafc8353866daa6160b8c056ae7ec4e15f', 'message': ""Add dry_run option to stack abandon\n\nOption dry_run is used to get abandon data without deleting the\nstack. It's useful to perform dry_run abandon before stack update to\nget a copy of healthy data for later adopt if update failure found.\n\nCloses-Bug: #1300830\nChange-Id: I0aff7a7805f5be474c661a726ab27bbbe0a9d2b8\n""}, {'number': 4, 'created': '2014-04-03 14:24:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/44c6fbdbdda5b6f8d113605e96bb82228b1bc863', 'message': ""Add dry_run option to stack abandon\n\nOption dry_run is used to get abandon data without deleting the\nstack. It's useful to perform dry_run abandon before stack update to\nget a copy of healthy data for later adopt if update failure found.\n\nCloses-Bug: #1300830\nChange-Id: I0aff7a7805f5be474c661a726ab27bbbe0a9d2b8\n""}, {'number': 5, 'created': '2014-04-04 03:43:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/909bf18a30c6819905b25e7abac69710ad49f4b1', 'message': ""Add dry_run option to stack abandon\n\nOption dry_run is used to get abandon data without deleting the\nstack. It's useful to perform dry_run abandon before stack update to\nget a copy of healthy data for later adopt if update failure found.\n\nCloses-Bug: #1300830\nChange-Id: I0aff7a7805f5be474c661a726ab27bbbe0a9d2b8\n""}, {'number': 6, 'created': '2014-04-04 04:49:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/e4827e76ebc046e0274c6832600e0734d8c2aa5e', 'message': ""Add dry_run option to stack abandon\n\nOption dry_run is used to get abandon data without deleting the\nstack. It's useful to perform dry_run abandon before stack update to\nget a copy of healthy data for later adopt if update failure found.\n\nCloses-Bug: #1300830\nChange-Id: I0aff7a7805f5be474c661a726ab27bbbe0a9d2b8\n""}, {'number': 7, 'created': '2014-04-14 09:07:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/db098b4a9e2f40594fee5d9e8bbaebcb8292f295', 'message': ""Add dry_run option to stack abandon\n\nOption dry_run is used to get abandon data without deleting the\nstack. It's useful to perform dry_run abandon before stack update to\nget a copy of healthy data for later adopt if update failure found.\n\nCloses-Bug: #1300830\nChange-Id: I0aff7a7805f5be474c661a726ab27bbbe0a9d2b8\n""}, {'number': 8, 'created': '2014-04-15 04:07:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/ba703a021ad4387b053e5bf9fa110d0cac107f49', 'message': ""Add dry_run option to stack abandon\n\nOption dry_run is used to get abandon data without deleting the\nstack. It's useful to perform dry_run abandon before stack update to\nget a copy of healthy data for later adopt if update failure found.\n\nCloses-Bug: #1300830\nChange-Id: I0aff7a7805f5be474c661a726ab27bbbe0a9d2b8\n""}, {'number': 9, 'created': '2014-04-15 04:15:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/5a0f1a12035561bb915bd1c26c026c24efd198a2', 'message': ""Add dry_run option to stack abandon\n\nOption dry_run is used to get abandon data without deleting the\nstack. It's useful to perform dry_run abandon before stack update to\nget a copy of healthy data for later adopt if update failure found.\n\nCloses-Bug: #1300830\nChange-Id: I0aff7a7805f5be474c661a726ab27bbbe0a9d2b8\n""}, {'number': 10, 'created': '2014-04-15 09:28:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/07330849d7c54bf985cc783b3f36e0c5688b2273', 'message': ""Add preview option to stack abandon\n\nOption preview is used to get abandon data without deleting the\nstack. It's useful to perform dry_run abandon before stack update to\nget a copy of healthy data for later adopt if update failure found.\n\nCloses-Bug: #1300830\nChange-Id: I0aff7a7805f5be474c661a726ab27bbbe0a9d2b8\n""}, {'number': 11, 'created': '2014-04-15 10:10:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/2a32573a88566f827c437950b112e080c5a46d45', 'message': ""Add preview option to stack abandon\n\nOption preview is used to get abandon data without deleting the\nstack. It's useful to perform dry_run abandon before stack update to\nget a copy of healthy data for later adopt if update failure found.\n\nCloses-Bug: #1300830\nChange-Id: I0aff7a7805f5be474c661a726ab27bbbe0a9d2b8\n""}, {'number': 12, 'created': '2014-04-16 03:52:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/c3ba3c4e08badfa64a1727f2f6928a6eda0ca1b1', 'message': ""Add preview option to stack abandon\n\nOption preview is used to get abandon data without deleting the\nstack. It's useful to perform dry_run abandon before stack update to\nget a copy of healthy data for later adopt if update failure found.\n\nCloses-Bug: #1300830\nChange-Id: I0aff7a7805f5be474c661a726ab27bbbe0a9d2b8\n""}, {'number': 13, 'created': '2014-07-11 06:58:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/aa0d409dc5081b11f7e4b122a0141249ba01e3a3', 'message': ""Add preview option to stack abandon\n\nOption preview is used to get abandon data without deleting the\nstack. It's useful to perform dry_run abandon before stack update to\nget a copy of healthy data for later adopt if update failure found.\n\nCloses-Bug: #1300830\nChange-Id: I0aff7a7805f5be474c661a726ab27bbbe0a9d2b8\n""}, {'number': 14, 'created': '2014-07-29 02:36:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/e85477dc368b2b6ad4c0c6d91eab9098ea616b8d', 'message': ""Add preview option to stack abandon\n\nOption preview is used to get abandon data without deleting the\nstack. It's useful to perform dry_run abandon before stack update to\nget a copy of healthy data for later adopt if update failure found.\n\nPartial-Bug: #1300830\nChange-Id: I0aff7a7805f5be474c661a726ab27bbbe0a9d2b8\n""}, {'number': 15, 'created': '2014-07-29 13:32:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/bc88ce99716a198018130655e15282ce42601d09', 'message': ""Add preview option to stack abandon\n\nOption preview is used to get abandon data without deleting the\nstack. It's useful to perform dry_run abandon before stack update to\nget a copy of healthy data for later adopt if update failure found.\n\nPartial-Bug: #1300830\nChange-Id: I0aff7a7805f5be474c661a726ab27bbbe0a9d2b8\n""}, {'number': 16, 'created': '2014-08-25 02:23:32.000000000', 'files': ['heat/tests/test_engine_service.py', 'heat/rpc/client.py', 'heat/tests/test_api_openstack_v1.py', 'heat/api/openstack/v1/stacks.py', 'heat/engine/service.py', 'etc/heat/policy.json', 'heat/api/openstack/v1/__init__.py'], 'web_link': 'https://opendev.org/openstack/heat/commit/4cc87fc41510ee3d818bf6726814311045bfc40c', 'message': ""Add preview option to stack abandon\n\nOption preview is used to get abandon data without deleting the\nstack. It's useful to perform dry_run abandon before stack update to\nget a copy of healthy data for later adopt if update failure found.\n\nPartial-Bug: #1300830\nChange-Id: I0aff7a7805f5be474c661a726ab27bbbe0a9d2b8\n""}]",34,84664,4cc87fc41510ee3d818bf6726814311045bfc40c,100,16,16,7761,,,0,"Add preview option to stack abandon

Option preview is used to get abandon data without deleting the
stack. It's useful to perform dry_run abandon before stack update to
get a copy of healthy data for later adopt if update failure found.

Partial-Bug: #1300830
Change-Id: I0aff7a7805f5be474c661a726ab27bbbe0a9d2b8
",git fetch https://review.opendev.org/openstack/heat refs/changes/64/84664/9 && git format-patch -1 --stdout FETCH_HEAD,"['heat/tests/test_engine_service.py', 'heat/rpc/client.py', 'heat/tests/test_api_openstack_v1.py', 'heat/api/openstack/v1/stacks.py', 'heat/engine/service.py']",5,2a96160471e3faf280a0ccc40472e4654c708700,bugs/1300830," def abandon_stack(self, cnxt, stack_identity, dry_run=False): if not dry_run: # Set deletion policy to 'Retain' for all resources in the stack. stack.set_deletion_policy(resource.RETAIN) self.thread_group_mgr.start_with_lock(cnxt, stack, self.engine_id, stack.delete)"," def abandon_stack(self, cnxt, stack_identity): # Set deletion policy to 'Retain' for all resources in the stack. stack.set_deletion_policy(resource.RETAIN) self.thread_group_mgr.start_with_lock(cnxt, stack, self.engine_id, stack.delete)",31,14
openstack%2Fheat~master~I063ea5f5046679f72774f73fecc7082180609c94,openstack/heat,master,I063ea5f5046679f72774f73fecc7082180609c94,Move WritableLogger in-tree as it is deprecated in oslo_log,MERGED,2015-06-15 00:53:35.000000000,2015-06-24 23:14:58.000000000,2015-06-24 23:14:55.000000000,"[{'_account_id': 3}, {'_account_id': 4328}, {'_account_id': 4571}, {'_account_id': 4715}, {'_account_id': 6498}, {'_account_id': 8833}, {'_account_id': 16203}]","[{'number': 1, 'created': '2015-06-15 00:53:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/b092bcbe6e95e71dc8126277bc8daedbf20d4e9c', 'message': 'Move WritableLogger in-tree as it is deprecated in olso_log\n\nChange-Id: I063ea5f5046679f72774f73fecc7082180609c94\nCloses-bug: 1465077\n'}, {'number': 2, 'created': '2015-06-15 01:54:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/fa9e0984a7233dea6477fe17aa4b09ae9556b2fa', 'message': 'Move WritableLogger in-tree as it is deprecated in olso_log\n\nChange-Id: I063ea5f5046679f72774f73fecc7082180609c94\nCloses-bug: 1465077\n'}, {'number': 3, 'created': '2015-06-23 21:42:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/3aaeba3c801ec4a131d6227eed5fb2d4b01e5a41', 'message': 'Move WritableLogger in-tree as it is deprecated in oslo_log\n\nChange-Id: I063ea5f5046679f72774f73fecc7082180609c94\nCloses-bug: 1465077'}, {'number': 4, 'created': '2015-06-24 11:22:07.000000000', 'files': ['heat/common/wsgi.py'], 'web_link': 'https://opendev.org/openstack/heat/commit/1d46a7efcaeb594a193a14d606545ccc483a1702', 'message': 'Move WritableLogger in-tree as it is deprecated in oslo_log\n\nChange-Id: I063ea5f5046679f72774f73fecc7082180609c94\nCloses-bug: 1465077'}]",4,191597,1d46a7efcaeb594a193a14d606545ccc483a1702,22,7,4,4715,,,0,"Move WritableLogger in-tree as it is deprecated in oslo_log

Change-Id: I063ea5f5046679f72774f73fecc7082180609c94
Closes-bug: 1465077",git fetch https://review.opendev.org/openstack/heat refs/changes/97/191597/4 && git format-patch -1 --stdout FETCH_HEAD,['heat/common/wsgi.py'],1,b092bcbe6e95e71dc8126277bc8daedbf20d4e9c,bug/1465077,"import logging as std_loggingclass WritableLogger(object): """"""A thin wrapper that responds to `write` and logs."""""" def __init__(self, LOG, level=std_logging.DEBUG): self.LOG = LOG self.level = level def write(self, msg): self.LOG.log(self.level, msg.strip(""\n"")) self._wsgi_logger = WritableLogger(self._logger)",from oslo_log import loggers self._wsgi_logger = loggers.WritableLogger(self._logger),13,2
openstack%2Fkolla~master~I7770295271499275f937be3c2feab7216a30a388,openstack/kolla,master,I7770295271499275f937be3c2feab7216a30a388,Fix docker-1.7.0 binary download link,MERGED,2015-06-23 06:34:03.000000000,2015-06-24 23:13:18.000000000,2015-06-24 23:13:17.000000000,"[{'_account_id': 3}, {'_account_id': 2834}, {'_account_id': 10419}, {'_account_id': 10787}, {'_account_id': 14119}]","[{'number': 1, 'created': '2015-06-23 06:34:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla/commit/8db9f601c65ac5a2f793538e102d8bb3e3d7732f', 'message': 'Fix docker-1.7.0 binary download link\n\nThe download link is fixed and updated to use docker-1.7.0\nfrom https://get.docker.io instead of https://master.dockerproject.com\nbecause later one only holds latest docker bin which is 1.8.0,\nand get.docker.io is also the official way of getting docker binary\nas mentioned in docker install docs.\nCloses-bug: 1467767\n\nChange-Id: I7770295271499275f937be3c2feab7216a30a388\n'}, {'number': 2, 'created': '2015-06-23 07:02:58.000000000', 'files': ['devenv/kollanode.yaml', 'devenv/README.md'], 'web_link': 'https://opendev.org/openstack/kolla/commit/4f6a49769e3994d78844d702a70d10fd8fb9c15a', 'message': 'Fix docker-1.7.0 binary download link\n\nThe download link is fixed and updated to use docker-1.7.0\nfrom https://get.docker.com instead of https://master.dockerproject.com\nbecause later one only holds latest docker bin which is 1.8.0,\nand get.docker.io is also the official way of getting docker binary\nas mentioned in docker install docs.Also fixed the docs to point\nthat 1.7.0 is minimum version required for docker.\nCloses-bug: 1467767\n\nChange-Id: I7770295271499275f937be3c2feab7216a30a388\n'}]",0,194515,4f6a49769e3994d78844d702a70d10fd8fb9c15a,10,5,2,12609,,,0,"Fix docker-1.7.0 binary download link

The download link is fixed and updated to use docker-1.7.0
from https://get.docker.com instead of https://master.dockerproject.com
because later one only holds latest docker bin which is 1.8.0,
and get.docker.io is also the official way of getting docker binary
as mentioned in docker install docs.Also fixed the docs to point
that 1.7.0 is minimum version required for docker.
Closes-bug: 1467767

Change-Id: I7770295271499275f937be3c2feab7216a30a388
",git fetch https://review.opendev.org/openstack/kolla refs/changes/15/194515/1 && git format-patch -1 --stdout FETCH_HEAD,['devenv/kollanode.yaml'],1,8db9f601c65ac5a2f793538e102d8bb3e3d7732f,bug/1467767, curl -L https://get.docker.io/linux/amd64/docker-1.7.0 -o /usr/local/sbin/docker, curl -L https://master.dockerproject.com/linux/amd64/docker-1.7.0-dev -o /usr/local/sbin/docker,1,1
openstack%2Fcongress~master~I3aa5e1264ea292c0100099c800309daf35f5c494,openstack/congress,master,I3aa5e1264ea292c0100099c800309daf35f5c494,Change to semantic versioning,MERGED,2015-06-24 21:45:20.000000000,2015-06-24 23:02:11.000000000,2015-06-24 23:02:10.000000000,"[{'_account_id': 3}, {'_account_id': 8215}]","[{'number': 1, 'created': '2015-06-24 21:45:20.000000000', 'files': ['setup.cfg'], 'web_link': 'https://opendev.org/openstack/congress/commit/49020ad2ab549538a2e198268a58618c7fc98bff', 'message': 'Change to semantic versioning\n\nChange-Id: I3aa5e1264ea292c0100099c800309daf35f5c494\n'}]",0,195330,49020ad2ab549538a2e198268a58618c7fc98bff,9,2,1,8215,,,0,"Change to semantic versioning

Change-Id: I3aa5e1264ea292c0100099c800309daf35f5c494
",git fetch https://review.opendev.org/openstack/congress refs/changes/30/195330/1 && git format-patch -1 --stdout FETCH_HEAD,['setup.cfg'],1,49020ad2ab549538a2e198268a58618c7fc98bff,,version = 2.0.0,version = 2015.1,1,1
openstack%2Fautomaton~master~I4a699d72a0a7194c2c00fa870818e118b3a7fc41,openstack/automaton,master,I4a699d72a0a7194c2c00fa870818e118b3a7fc41,"Add code repo, mail list, and IRC to CONTRIBUTING",MERGED,2015-06-24 20:37:07.000000000,2015-06-24 22:55:51.000000000,2015-06-24 22:55:50.000000000,"[{'_account_id': 3}, {'_account_id': 1297}, {'_account_id': 10584}]","[{'number': 1, 'created': '2015-06-24 20:37:07.000000000', 'files': ['CONTRIBUTING.rst'], 'web_link': 'https://opendev.org/openstack/automaton/commit/3aaedf1879e8eff913cd448e3b75fee05a3b8b62', 'message': 'Add code repo, mail list, and IRC to CONTRIBUTING\n\nUpdate CONTRIBUTING information to include the location of the\ncode repository, the email list, and the IRC channel. So people\ncan find you :D\n\nChange-Id: I4a699d72a0a7194c2c00fa870818e118b3a7fc41\n'}]",0,195298,3aaedf1879e8eff913cd448e3b75fee05a3b8b62,7,3,1,6618,,,0,"Add code repo, mail list, and IRC to CONTRIBUTING

Update CONTRIBUTING information to include the location of the
code repository, the email list, and the IRC channel. So people
can find you :D

Change-Id: I4a699d72a0a7194c2c00fa870818e118b3a7fc41
",git fetch https://review.opendev.org/openstack/automaton refs/changes/98/195298/1 && git format-patch -1 --stdout FETCH_HEAD,['CONTRIBUTING.rst'],1,3aaedf1879e8eff913cd448e3b75fee05a3b8b62,contributing,"The code is hosted at: http://git.openstack.org/cgit/openstack/automaton. The mailing list is (prefix subjects with ""[Oslo][Automaton]""): http://lists.openstack.org/cgi-bin/mailman/listinfo/openstack-dev Questions and discussions take place in #openstack-state-management on irc.freenode.net.",,11,0
openstack%2Fglance~master~I342e4f2d7af3ba3b8089b3069fd55d727d373551,openstack/glance,master,I342e4f2d7af3ba3b8089b3069fd55d727d373551,(hyper-wip) Explicitly store visibility of image,ABANDONED,2014-11-21 14:55:22.000000000,2015-06-24 22:53:52.000000000,,"[{'_account_id': 3}, {'_account_id': 11356}, {'_account_id': 15732}]","[{'number': 1, 'created': '2014-11-21 14:55:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/f74d636735a965f0c7c2da9ad0af28286ca26757', 'message': '(hyper-wip) Explicitly store visibility of image\n\nRelated to bp community-level-v2-image-sharing\n\nChange-Id: I342e4f2d7af3ba3b8089b3069fd55d727d373551\n'}, {'number': 2, 'created': '2014-11-21 19:35:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/bd1e117b1104a11a47b55c2a858aec9ad3390a5b', 'message': '(hyper-wip) Explicitly store visibility of image\n\nRelated to bp community-level-v2-image-sharing\n\nChange-Id: I342e4f2d7af3ba3b8089b3069fd55d727d373551\n'}, {'number': 3, 'created': '2014-11-25 19:55:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/bd37f4b9b85907f9dee20343b698f3d280b67810', 'message': '(hyper-wip) Explicitly store visibility of image\n\nRelated to bp community-level-v2-image-sharing\n\nChange-Id: I342e4f2d7af3ba3b8089b3069fd55d727d373551\n'}, {'number': 4, 'created': '2014-11-25 22:17:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/bc4374e1c6cae479e27d9f591fcfea34325c1a1a', 'message': '(hyper-wip) Explicitly store visibility of image\n\nRelated to bp community-level-v2-image-sharing\n\nChange-Id: I342e4f2d7af3ba3b8089b3069fd55d727d373551\n'}, {'number': 5, 'created': '2014-12-02 18:25:58.000000000', 'files': ['glance/db/sqlalchemy/migrate_repo/versions/037_visibility.py', 'glance/db/sqlalchemy/api.py', 'glance/db/sqlalchemy/models.py'], 'web_link': 'https://opendev.org/openstack/glance/commit/167fa23f359f3f60456128429479520150ae9a22', 'message': '(hyper-wip) Explicitly store visibility of image\n\nRelated to bp community-level-v2-image-sharing\n\nChange-Id: I342e4f2d7af3ba3b8089b3069fd55d727d373551\n'}]",0,136374,167fa23f359f3f60456128429479520150ae9a22,14,3,5,11356,,,0,"(hyper-wip) Explicitly store visibility of image

Related to bp community-level-v2-image-sharing

Change-Id: I342e4f2d7af3ba3b8089b3069fd55d727d373551
",git fetch https://review.opendev.org/openstack/glance refs/changes/74/136374/4 && git format-patch -1 --stdout FETCH_HEAD,"['glance/db/sqlalchemy/migrate_repo/versions/037_visibility.py', 'glance/db/sqlalchemy/api.py', 'glance/db/sqlalchemy/models.py']",3,f74d636735a965f0c7c2da9ad0af28286ca26757,bp/community-level-v2-image-sharing," # TODO(kragniz) make this more fancy - probably use an enum visibility = Column(Integer, nullable=False, default=0) ",,43,2
openstack%2Fheat-specs~master~If67650f8e4a08849eadba97a3df9bb83278b660a,openstack/heat-specs,master,If67650f8e4a08849eadba97a3df9bb83278b660a,Uniform Resource Signals,MERGED,2015-05-06 03:03:00.000000000,2015-06-24 22:44:34.000000000,2015-06-24 22:44:32.000000000,"[{'_account_id': 3}, {'_account_id': 4328}, {'_account_id': 4571}, {'_account_id': 6804}, {'_account_id': 6899}, {'_account_id': 7193}, {'_account_id': 12259}, {'_account_id': 12321}, {'_account_id': 12606}]","[{'number': 1, 'created': '2015-05-06 03:03:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat-specs/commit/f8da8ed0c14ad7b50c92f761ec0681608c770d92', 'message': 'Better signals for hot resources\n\nThis spec proposes enhancements to the SignalResponder class to support\ndifferent types of signals.\n\nChange-Id: If67650f8e4a08849eadba97a3df9bb83278b660a\n'}, {'number': 2, 'created': '2015-05-06 14:20:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat-specs/commit/6cb27c8a017c5ff90dc02b65dbbb4b88f00e1375', 'message': 'Better signals for hot resources\n\nThis spec proposes enhancements to the SignalResponder class to support\ndifferent types of signals.\n\nChange-Id: If67650f8e4a08849eadba97a3df9bb83278b660a\n'}, {'number': 3, 'created': '2015-05-07 14:54:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat-specs/commit/1f9a71ab799788e76a475130ab6336d06ae7fb84', 'message': 'Better signals for HOT resources\n\nThis spec proposes enhancements to the SignalResponder class to support\ndifferent types of signals.\n\nbp hot-signals\n\nChange-Id: If67650f8e4a08849eadba97a3df9bb83278b660a\n'}, {'number': 4, 'created': '2015-05-07 18:20:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat-specs/commit/9947084fdfab5f3b9fc2430f5c1cef4c7c3c9b8f', 'message': 'Uniform Resource Signals\n\nThis spec proposes enhancements to the SignalResponder class to support\ndifferent types of signals.\n\nbp uniform-resource-signals\n\nChange-Id: If67650f8e4a08849eadba97a3df9bb83278b660a\n'}, {'number': 5, 'created': '2015-05-07 18:24:05.000000000', 'files': ['specs/liberty/uniform-resource-signals.rst'], 'web_link': 'https://opendev.org/openstack/heat-specs/commit/8659d4206f1588f4e7630ae66d51a52a0b97176b', 'message': 'Uniform Resource Signals\n\nThis spec proposes enhancements to the SignalResponder class to support\ndifferent types of signals.\n\nbp uniform-resource-signals\n\nChange-Id: If67650f8e4a08849eadba97a3df9bb83278b660a\n'}]",10,180387,8659d4206f1588f4e7630ae66d51a52a0b97176b,25,9,5,12606,,,0,"Uniform Resource Signals

This spec proposes enhancements to the SignalResponder class to support
different types of signals.

bp uniform-resource-signals

Change-Id: If67650f8e4a08849eadba97a3df9bb83278b660a
",git fetch https://review.opendev.org/openstack/heat-specs refs/changes/87/180387/4 && git format-patch -1 --stdout FETCH_HEAD,['specs/liberty/hot-signals.rst'],1,f8da8ed0c14ad7b50c92f761ec0681608c770d92,bp/uniform-resource-signals,".. This work is licensed under a Creative Commons Attribution 3.0 Unported License. http://creativecommons.org/licenses/by/3.0/legalcode .. ============= HOT Signals ============= https://blueprints.launchpad.net/heat/+spec/hot-signals This spec covers the implementation of a uniform signaling framework for heat resources. Problem description =================== The standard way to signal a resource is to do it through a request to heat-api. This works well for user generated signals, but when the signals are generated internally as a result of an event, the user credentials are not available. Heat resources implement a variety of mechanisms to make signals work in this context. For example, the ``OS::Heat::ScalingPolicy`` resource exposes a ``alarm_url`` attribute that is a EC2 signed URL, so the heat-api-cfn compatibility service must be available for these signals to work. The ``OS::Heat::WaitConditionHandle`` resource, on the other side, exposes a proper endpoint to heat-api and a token to authenticate against it, but that only allows signals to be sent before the token expires. Unfortunately there is no way to renew the token, so these resources cannot be used for long tasks. Other heat resources use swift temp URLs as signals, and yet some others expose a more traditional set of heat-owned keystone credentials that can be used to obtain a token to authenticate against heat-api. Out of all these authentication methods, the only one that is implemented in a base class accessible to all resources is EC2 signed URLs, the ones that are based on a heat-api-cfn endpoint. The others are implemented as ""one-offs"" by individual resources, making them hard to implement across resources without code duplication. Proposed change =============== The heat-engine service includes a ``SignalResponder`` base class, from which resources that can be signaled can inherit from. To make the different types of signals available to all resources, their implementations will be moved to this class, which already contains the support for EC2 signed URLs. With support for using all the different types of signals implemented in ``SignalResponder``, resources will be able to offer different choices of signals, without having to deal with the particulars of each implementation. Resources will have the option to expose a single signal type, or else implement a ``signal_transport`` property that gives the operator the option to select the signal type. The credentials necessary to trigger a signal will be exposed in the resource as an attribute called ``signal``, of type map. The items included in the map will depend on the selected signal type. The following signal types will be supported: - ``CFN_SIGNAL``: The currently available EC2 signed URL signals. The signals are triggered by sending a request to a URL. The request method and the URL are given in the ``signal`` attribute. The URL is based on the heat-api-cfn service. - ``TEMP_URL_SIGNAL``: Signals based on a swift temp URL. The signals are triggered by sending a request to a URL. The request method and the URL are given in the ``signal`` attribute. The URL is based on the swift service. - ``HEAT_SIGNAL``: Signals based on the standard heat-api signal endpoint. The process to trigger this signal involves requesting a keystone token, then sending the signal request to heat-api with this token. The keystone credentials necessary to obtain the token are given in the ``signal`` attribute. Alternatives ------------ Implement a webhook solution similar to EC2 signed URLs based on a heat-api endpoint. This is a less flexible approach, and it has the drawback that the authentication tokens are embedded in URLs, which are typically written to logfiles. The nice thing about the proposed solution is that nothing prevents a webhook signal to be added to the list of signal options in the future. Implementation ============== Assignee(s) ----------- Primary assignee: miguelgrinberg Milestones ---------- Target Milestone for completion: liberty-1 Work Items ---------- - Refactor EC2 signed URL support in ``SignalResponder`` class to allow other signal types to be defined. - Implement heat-api signals in the ``SignalResponder`` class. - Implement swift temp URL signals in the ``SignalResponder`` class. - Add support for all the signal types in wait conditions. - Add support for all the signal types in the scaling policy resource. - Base signals in SoftwareDeployment on the ``SignalResponder`` class. - Deprecate current signals in wait condition and scaling policy resources. - Deprecate the ``default_deployment_signal_transport`` configuration item and replace it with one that is generic for all resources, such as ``default_signal_transport``. - Documentation for the various affected resources. - Unit tests for the various affected resources. Dependencies ============ None ",,123,0
openstack%2Fbarbican~master~I89c4c7fdf7fee2dd73e40bdba6052dcd5213d932,openstack/barbican,master,I89c4c7fdf7fee2dd73e40bdba6052dcd5213d932,Change naming convention for Barbican config files,MERGED,2015-06-08 20:37:21.000000000,2015-06-24 22:42:17.000000000,2015-06-24 22:42:15.000000000,"[{'_account_id': 3}, {'_account_id': 7136}, {'_account_id': 7764}, {'_account_id': 7789}, {'_account_id': 7973}, {'_account_id': 10873}, {'_account_id': 11970}]","[{'number': 1, 'created': '2015-06-08 20:37:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/barbican/commit/390cc327774427ca43ab1b0d9ae73f266125acb0', 'message': 'Changes the naming convention for Barbican config files to be more consistent with other\nOpenStack projects.\n\nbarbican-api.conf files renamed to barbican.api\nUpdated references in code from barbican-api.conf to barbican.api\n\nChange-Id: I89c4c7fdf7fee2dd73e40bdba6052dcd5213d932\nCloses-bug: #1459682\n'}, {'number': 2, 'created': '2015-06-08 20:37:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/barbican/commit/61148c349a00fdcbadd7053d961b154bded8c0cb', 'message': 'Changes the naming convention for Barbican config files to be more consistent\nwith other OpenStack projects.\n\nbarbican-api.conf files renamed to barbican.api\nUpdated references in code from barbican-api.conf to barbican.api\n\nChange-Id: I89c4c7fdf7fee2dd73e40bdba6052dcd5213d932\nCloses-bug: #1459682\n'}, {'number': 3, 'created': '2015-06-08 20:38:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/barbican/commit/963374c2908969f711114bc7eed63146396a0811', 'message': 'Changes naming convention for Barbican config files to be more consistent\n\nbarbican-api.conf files renamed to barbican.api\nUpdated references in code from barbican-api.conf to barbican.api\n\nChange-Id: I89c4c7fdf7fee2dd73e40bdba6052dcd5213d932\nCloses-bug: #1459682\n'}, {'number': 4, 'created': '2015-06-08 20:41:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/barbican/commit/ace1675127bffa07c58eb8271463b69050f5ec7a', 'message': 'Changes naming convention for Barbican config files for consistency\n\nbarbican-api.conf files renamed to barbican.api\nUpdated references in code from barbican-api.conf to barbican.api\n\nChange-Id: I89c4c7fdf7fee2dd73e40bdba6052dcd5213d932\nCloses-bug: #1459682\n'}, {'number': 5, 'created': '2015-06-08 20:43:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/barbican/commit/21e40ab5da92d1e11fe0b62bdb137c20142b0179', 'message': 'Change naming convention for Barbican config files\n\nbarbican-api.conf files renamed to barbican.api\n\nUpdated references in code from barbican-api.conf to barbican.api\n\nChange-Id: I89c4c7fdf7fee2dd73e40bdba6052dcd5213d932\nCloses-bug: #1459682\n'}, {'number': 6, 'created': '2015-06-09 16:04:23.000000000', 'files': ['bin/barbican.sh', 'etc/barbican/barbican.conf', 'doc/source/setup/troubleshooting.rst', 'contrib/devstack/lib/barbican', 'doc/source/contribute/database_migrations.rst', 'rpmbuild/SPECS/barbican.spec', 'doc/source/setup/certificate.rst', 'bin/barbican-all', 'etc/init/barbican.conf'], 'web_link': 'https://opendev.org/openstack/barbican/commit/07d1a50de39e4bf724eda7254bee12fe4185742e', 'message': 'Change naming convention for Barbican config files\n\nbarbican-api.conf files renamed to barbican.conf\nUpdated references in code from barbican-api.conf to barbican.conf\nUpdated references in docs from barbican-api.conf to barbican.conf\n\nChange-Id: I89c4c7fdf7fee2dd73e40bdba6052dcd5213d932\nCloses-bug: #1459682\n'}]",1,189434,07d1a50de39e4bf724eda7254bee12fe4185742e,20,7,6,15993,,,0,"Change naming convention for Barbican config files

barbican-api.conf files renamed to barbican.conf
Updated references in code from barbican-api.conf to barbican.conf
Updated references in docs from barbican-api.conf to barbican.conf

Change-Id: I89c4c7fdf7fee2dd73e40bdba6052dcd5213d932
Closes-bug: #1459682
",git fetch https://review.opendev.org/openstack/barbican refs/changes/34/189434/1 && git format-patch -1 --stdout FETCH_HEAD,"['bin/barbican.sh', 'etc/barbican/barbican.conf', 'contrib/devstack/lib/barbican', 'rpmbuild/SPECS/barbican.spec', 'bin/barbican-all', 'etc/init/barbican.conf']",6,390cc327774427ca43ab1b0d9ae73f266125acb0,bug/1459682,,,9,9
openstack%2Fkeystone~master~Ieb1cfc5b482696a97da6cee041f8cdf87787c316,openstack/keystone,master,Ieb1cfc5b482696a97da6cee041f8cdf87787c316,StrictABC Implementation,ABANDONED,2015-01-19 20:27:44.000000000,2015-06-24 22:39:06.000000000,,"[{'_account_id': 3}, {'_account_id': 4}, {'_account_id': 1297}, {'_account_id': 1916}, {'_account_id': 1941}, {'_account_id': 2218}, {'_account_id': 2472}, {'_account_id': 2903}, {'_account_id': 5046}, {'_account_id': 5538}, {'_account_id': 5707}, {'_account_id': 6482}, {'_account_id': 7191}, {'_account_id': 7725}, {'_account_id': 9751}, {'_account_id': 11045}, {'_account_id': 11333}]","[{'number': 1, 'created': '2015-01-19 20:27:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/6d3d81976b5a2473de95aa1725d06b7ee29de3aa', 'message': 'DO NOT MERGE: StrictABC Prototype\n\nChange-Id: Ieb1cfc5b482696a97da6cee041f8cdf87787c316\n'}, {'number': 2, 'created': '2015-01-21 22:31:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/173c62cd819421e11679d85ab54436eb6a93dd94', 'message': 'DO NOT MERGE: StrictABC Prototype\n\nChange-Id: Ieb1cfc5b482696a97da6cee041f8cdf87787c316\n'}, {'number': 3, 'created': '2015-01-21 22:34:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/3f1b4ddf9f126d5470e2d9aa9cbfd3515d82767d', 'message': 'DO NOT MERGE: StrictABC Prototype\n\nChange-Id: Ieb1cfc5b482696a97da6cee041f8cdf87787c316\n'}, {'number': 4, 'created': '2015-01-21 22:36:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/b927dd22fe655aed71607649a3e29fb4c5ba0db3', 'message': 'DO NOT MERGE: StrictABC Prototype\n\nChange-Id: Ieb1cfc5b482696a97da6cee041f8cdf87787c316\n'}, {'number': 5, 'created': '2015-01-21 22:48:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/313fbeb5783e43d5b722734edb31fa826970cad5', 'message': 'DO NOT MERGE: StrictABC Prototype\n\nChange-Id: Ieb1cfc5b482696a97da6cee041f8cdf87787c316\n'}, {'number': 6, 'created': '2015-01-22 22:23:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/b21f291834cbb9ea4913182cba248b38f98f19f5', 'message': 'StrictABC Prototype\n\nThis allows us to enforce signature and property checking on extended and\ninherited classes.\n\npartially implements bp token-provider-cleanup\n\nChange-Id: Ieb1cfc5b482696a97da6cee041f8cdf87787c316\n'}, {'number': 7, 'created': '2015-01-22 22:27:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/0704a73659bb98a61f88dd612ab8ee808497c5f9', 'message': 'StrictABC Prototype\n\nThis allows us to enforce signature and property checking on extended and\ninherited classes.\n\npartially implements bp token-provider-cleanup\n\nChange-Id: Ieb1cfc5b482696a97da6cee041f8cdf87787c316\n'}, {'number': 8, 'created': '2015-01-25 23:11:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/9124df558d47c0691d65e6035b0707256d44499f', 'message': 'StrictABC Implementation\n\nThis allows us to enforce signature and property checking on extended and\ninherited classes.\n\npartially implements bp token-provider-cleanup\n\nChange-Id: Ieb1cfc5b482696a97da6cee041f8cdf87787c316\n'}, {'number': 9, 'created': '2015-02-08 01:09:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/18fc5d11421c1a16aa364930ccf0b8499439b644', 'message': 'StrictABC Implementation\n\nThis allows us to enforce signature and property checking on extended and\ninherited classes. This adds the ""decorator"" module dependency to support\nthe helper class-decorator to apply the StrictABCMeta class.\n\npartially implements bp token-provider-cleanup\n\nChange-Id: Ieb1cfc5b482696a97da6cee041f8cdf87787c316\n'}, {'number': 10, 'created': '2015-02-08 01:11:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/0c9d150fc3fd73a235ae9b20ffcb2900fe45525f', 'message': 'StrictABC Implementation\n\nThis allows us to enforce signature and property checking on extended and\ninherited classes. This adds the ""decorator"" module dependency to support\nthe helper class-decorator to apply the StrictABCMeta class.\n\npartially implements bp token-provider-cleanup\n\nChange-Id: Ieb1cfc5b482696a97da6cee041f8cdf87787c316\n'}, {'number': 11, 'created': '2015-02-09 22:13:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/f43f378e1729e67169cef43bb9580345a7fa7005', 'message': 'StrictABC Implementation\n\nThis allows us to enforce signature and property checking on extended and\ninherited classes.\n\npartially implements bp token-provider-cleanup\n\nChange-Id: Ieb1cfc5b482696a97da6cee041f8cdf87787c316\n'}, {'number': 12, 'created': '2015-05-01 13:03:16.000000000', 'files': ['keystone/common/strict_abc.py', 'keystone/tests/unit/common/test_strict_abc.py'], 'web_link': 'https://opendev.org/openstack/keystone/commit/ac1fbd0a3e1e3239169c576aed1367c7a930e826', 'message': 'StrictABC Implementation\n\nThis allows us to enforce signature and property checking on extended and\ninherited classes.\n\npartially implements bp token-provider-cleanup\n\nChange-Id: Ieb1cfc5b482696a97da6cee041f8cdf87787c316\n'}]",19,148354,ac1fbd0a3e1e3239169c576aed1367c7a930e826,42,17,12,2903,,,0,"StrictABC Implementation

This allows us to enforce signature and property checking on extended and
inherited classes.

partially implements bp token-provider-cleanup

Change-Id: Ieb1cfc5b482696a97da6cee041f8cdf87787c316
",git fetch https://review.opendev.org/openstack/keystone refs/changes/54/148354/11 && git format-patch -1 --stdout FETCH_HEAD,['keystone/common/strict_abc.py'],1,6d3d81976b5a2473de95aa1725d06b7ee29de3aa,148354,"# Licensed under the Apache License, Version 2.0 (the ""License""); you may # not use this file except in compliance with the License. You may obtain # a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT # WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the # License for the specific language governing permissions and limitations # under the License. import abc import inspect from keystone import exception from keystone.i18n import _ from keystone.openstack.common import log LOG = log.getLogger(__name__) _VALIDATED_CLASSES = set() def _assert_method_signature_match(name, cls, base_cls): cls_argspec = inspect.getargspec(getattr(cls, name)) base_argspec = inspect.getargspec(getattr(base_cls, name)) # TODO(morganfainberg): Support decorated methods. Right now this check # will not support decorated methods as they have the argspec of the # resulting wrapper. Not all wrapped callables will carry the original # argspec. if base_argspec != cls_argspec: raise MethodSignatureMismatch(method=name, cls_argspec=cls_argspec, cls=cls.__name__, base_cls=base_cls.__name__, base_argspec=base_argspec) class MethodSignatureMismatch(exception.Error): """"""Exception indicating there was a method signature mismatch."""""" message_format = _('Method signature mismatch for ""%(method)s"" with ' 'argspec ""%(cls_argspec)"" on ""%(cls)s"". Defined on ' '""%(base_cls)s"" as ""%(base_argspec)s""') class StrictABCMeta(abc.ABCMeta): def __new__(mcls, name, bases, namespace): """"""Raises if the abstractmethod sig is mismatched from the base."""""" cls = super(StrictABCMeta, mcls).__new__(mcls, name, bases, namespace) if cls not in _VALIDATED_CLASSES: for base in bases: for name in getattr(base, ""__abstractmethods__"", set()): value = getattr(cls, name, None) if getattr(value, ""__isabstractmethod__"", False): # This is not an abstract method and is abstract on the # current base. Ensure the signature matches. This will # traverse the entire tree. _assert_method_signature_match(name, cls, base) # This validation is only needed on the first attempt to # instantiate, add the class to the validated list for future # skipping of the validation step. _VALIDATED_CLASSES.add(cls) ",,64,0
openstack%2Fpython-keystoneclient~master~I5245437065635831c58d6e433d1c5dfe089f0dd0,openstack/python-keystoneclient,master,I5245437065635831c58d6e433d1c5dfe089f0dd0,Updated from global requirements,MERGED,2015-06-16 19:23:00.000000000,2015-06-24 22:38:26.000000000,2015-06-24 22:38:25.000000000,"[{'_account_id': 3}, {'_account_id': 2903}, {'_account_id': 6854}, {'_account_id': 16272}]","[{'number': 1, 'created': '2015-06-16 19:23:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-keystoneclient/commit/9ecda5d76f94bf445c5e0f55e60a8e897a44aaf3', 'message': 'Updated from global requirements\n\nChange-Id: I5245437065635831c58d6e433d1c5dfe089f0dd0\n'}, {'number': 2, 'created': '2015-06-22 08:27:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-keystoneclient/commit/9ff9a012796475340c988e1fa9c84b890fc55b67', 'message': 'Updated from global requirements\n\nChange-Id: I5245437065635831c58d6e433d1c5dfe089f0dd0\n'}, {'number': 3, 'created': '2015-06-22 20:00:21.000000000', 'files': ['requirements.txt', 'test-requirements.txt', 'setup.py'], 'web_link': 'https://opendev.org/openstack/python-keystoneclient/commit/2b058baf7be866df60d29cc13554f4715ba63554', 'message': 'Updated from global requirements\n\nChange-Id: I5245437065635831c58d6e433d1c5dfe089f0dd0\n'}]",0,192386,2b058baf7be866df60d29cc13554f4715ba63554,12,4,3,11131,,,0,"Updated from global requirements

Change-Id: I5245437065635831c58d6e433d1c5dfe089f0dd0
",git fetch https://review.opendev.org/openstack/python-keystoneclient refs/changes/86/192386/1 && git format-patch -1 --stdout FETCH_HEAD,['requirements.txt'],1,9ecda5d76f94bf445c5e0f55e60a8e897a44aaf3,openstack/requirements,oslo.utils>=1.6.0 # Apache-2.0,oslo.utils>=1.4.0 # Apache-2.0,1,1
openstack%2Frally~master~I8876ed8ad0e305a8f4fd6f744e1159bb5b70e17d,openstack/rally,master,I8876ed8ad0e305a8f4fd6f744e1159bb5b70e17d,Do not delete Constraints in case of sqlite,MERGED,2015-06-24 19:38:21.000000000,2015-06-24 22:37:54.000000000,2015-06-24 22:37:52.000000000,"[{'_account_id': 3}, {'_account_id': 6172}, {'_account_id': 9545}, {'_account_id': 14817}]","[{'number': 1, 'created': '2015-06-24 19:38:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/a608a53093e716cd119889354645440126688557', 'message': 'Do not delete Constraints in case of sqlite\n\nThis is not supported and should not be done.\n\nChange-Id: I8876ed8ad0e305a8f4fd6f744e1159bb5b70e17d\n'}, {'number': 2, 'created': '2015-06-24 20:22:40.000000000', 'files': ['rally/db/sqlalchemy/models.py'], 'web_link': 'https://opendev.org/openstack/rally/commit/1d48a5a73371c39dc9965603ae63b80f431dde9f', 'message': 'Do not delete Constraints in case of sqlite\n\nThis is not supported and should not be done.\n\nChange-Id: I8876ed8ad0e305a8f4fd6f744e1159bb5b70e17d\n'}]",0,195284,1d48a5a73371c39dc9965603ae63b80f431dde9f,11,4,2,6172,,,0,"Do not delete Constraints in case of sqlite

This is not supported and should not be done.

Change-Id: I8876ed8ad0e305a8f4fd6f744e1159bb5b70e17d
",git fetch https://review.opendev.org/openstack/rally refs/changes/84/195284/2 && git format-patch -1 --stdout FETCH_HEAD,['rally/db/sqlalchemy/models.py'],1,a608a53093e716cd119889354645440126688557,fix_sqlalchemy,"from sqlalchVemy import schema if engine.name != ""sqlite"": for fkc in all_fks: conn.execute(schema.DropConstraint(fkc))",from sqlalchemy import schema for fkc in all_fks: conn.execute(schema.DropConstraint(fkc)),4,3
openstack%2Frequirements~master~Iba7dd6a705ed5bdc8836bcfd0f511f6bf0e00ed7,openstack/requirements,master,Iba7dd6a705ed5bdc8836bcfd0f511f6bf0e00ed7,Remove swift from global-requirements.txt.,MERGED,2015-06-24 20:53:58.000000000,2015-06-24 22:37:50.000000000,2015-06-24 22:37:48.000000000,"[{'_account_id': 2}, {'_account_id': 3}, {'_account_id': 1849}, {'_account_id': 4146}]","[{'number': 1, 'created': '2015-06-24 20:53:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/requirements/commit/f29162e28fecd50874416c2f4ed91c55158a77ed', 'message': ""Remove swift from global-requirements.txt.\n\nswitft was added in 9b6a2b9050290bda548872cf444da6021f2aaeef as the\nresult of a mass script run over everything: we don't have any other\nservers in global-requirements, and as swift doesn't offer a library\ninterface (and isn't meant to be on PyPI) it doesn't make sense to\nhave it.\n\nChange-Id: Iba7dd6a705ed5bdc8836bcfd0f511f6bf0e00ed7\n""}, {'number': 2, 'created': '2015-06-24 20:58:03.000000000', 'files': ['global-requirements.txt', 'upper-constraints.txt'], 'web_link': 'https://opendev.org/openstack/requirements/commit/8e04f4a252b0101512c0571667dca78b05972ba6', 'message': ""Remove swift from global-requirements.txt.\n\nswift was added in 9b6a2b9050290bda548872cf444da6021f2aaeef as the\nresult of a mass script run over everything: we don't have any other\nservers in global-requirements, and as swift doesn't offer a library\ninterface (and isn't meant to be on PyPI) it doesn't make sense to\nhave it.\n\nChange-Id: Iba7dd6a705ed5bdc8836bcfd0f511f6bf0e00ed7\n""}]",1,195313,8e04f4a252b0101512c0571667dca78b05972ba6,11,4,2,4190,,,0,"Remove swift from global-requirements.txt.

swift was added in 9b6a2b9050290bda548872cf444da6021f2aaeef as the
result of a mass script run over everything: we don't have any other
servers in global-requirements, and as swift doesn't offer a library
interface (and isn't meant to be on PyPI) it doesn't make sense to
have it.

Change-Id: Iba7dd6a705ed5bdc8836bcfd0f511f6bf0e00ed7
",git fetch https://review.opendev.org/openstack/requirements refs/changes/13/195313/2 && git format-patch -1 --stdout FETCH_HEAD,"['global-requirements.txt', 'upper-constraints.txt']",2,f29162e28fecd50874416c2f4ed91c55158a77ed,,,swift===1.0.2,0,2
openstack%2Fnova~master~I3b9f60a2c4aea904f39d6914c8f35c4d682a6b3a,openstack/nova,master,I3b9f60a2c4aea904f39d6914c8f35c4d682a6b3a,network: fix instance cache refresh for empty list,MERGED,2015-05-28 08:35:49.000000000,2015-06-24 22:33:39.000000000,2015-06-03 04:23:05.000000000,"[{'_account_id': 3}, {'_account_id': 1653}, {'_account_id': 1849}, {'_account_id': 2271}, {'_account_id': 5170}, {'_account_id': 5511}, {'_account_id': 6873}, {'_account_id': 7166}, {'_account_id': 7730}, {'_account_id': 8276}, {'_account_id': 8587}, {'_account_id': 9008}, {'_account_id': 9578}, {'_account_id': 9732}, {'_account_id': 10118}, {'_account_id': 10135}, {'_account_id': 15286}, {'_account_id': 15524}, {'_account_id': 15751}]","[{'number': 1, 'created': '2015-05-28 08:35:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/b2171cd79a537d962fd61807c4c34f35ef9faa21', 'message': 'network: fix instance cache refresh for empty list\n\nThe bug introduced a race condition makes network_info as an\nempty value. When trying to refresh cache we should use data\nreturned per Neutron.\n\nCo-Authored-By: Lee Yarwood <lyarwood@redhat.com>\n\nRelated-Bug: #1407664\nChange-Id: I3b9f60a2c4aea904f39d6914c8f35c4d682a6b3a\n'}, {'number': 2, 'created': '2015-05-28 10:27:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/54d5ced9c7d696c2c9d60c949ba3b1e8fba94114', 'message': 'network: fix instance cache refresh for empty list\n\nThe bug introduce a race condition makes network_info as an\nempty value. When trying to refresh cache we should use data\nreturned per Neutron.\n\nCo-Authored-By: Lee Yarwood <lyarwood@redhat.com>\n\nCloses-Bug: #1407664\nChange-Id: I3b9f60a2c4aea904f39d6914c8f35c4d682a6b3a\n'}, {'number': 3, 'created': '2015-05-29 14:30:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/51bf2a37ed504bc592ab4a9cb2b6691f59078b13', 'message': 'network: fix instance cache refresh for empty list\n\nThe bug introduce a race condition makes network_info as an\nempty value. When trying to refresh cache we should use data\nreturned per Neutron.\n\nCo-Authored-By: Lee Yarwood <lyarwood@redhat.com>\n\nCloses-Bug: #1407664\nChange-Id: I3b9f60a2c4aea904f39d6914c8f35c4d682a6b3a\n'}, {'number': 4, 'created': '2015-05-29 14:34:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/662415b6a0173238d48edf41332c7bef6e740622', 'message': 'network: fix instance cache refresh for empty list\n\nThe bug introduce a race condition makes network_info as an\nempty value. When trying to refresh cache we should use data\nreturned per Neutron.\n\nCo-Authored-By: Lee Yarwood <lyarwood@redhat.com>\n\nCloses-Bug: #1407664\nChange-Id: I3b9f60a2c4aea904f39d6914c8f35c4d682a6b3a\n'}, {'number': 5, 'created': '2015-06-01 09:32:30.000000000', 'files': ['nova/tests/unit/network/test_neutronv2.py', 'nova/network/neutronv2/api.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/3a850ac72d60b3823c5cb4a971eaf02c580a4a20', 'message': 'network: fix instance cache refresh for empty list\n\nThe bug introduce a race condition makes network_info as an\nempty value. When trying to refresh cache we should use data\nreturned per Neutron.\n\nCo-Authored-By: Lee Yarwood <lyarwood@redhat.com>\n\nCloses-Bug: #1407664\nChange-Id: I3b9f60a2c4aea904f39d6914c8f35c4d682a6b3a\n'}]",12,186315,3a850ac72d60b3823c5cb4a971eaf02c580a4a20,59,19,5,7730,,,0,"network: fix instance cache refresh for empty list

The bug introduce a race condition makes network_info as an
empty value. When trying to refresh cache we should use data
returned per Neutron.

Co-Authored-By: Lee Yarwood <lyarwood@redhat.com>

Closes-Bug: #1407664
Change-Id: I3b9f60a2c4aea904f39d6914c8f35c4d682a6b3a
",git fetch https://review.opendev.org/openstack/nova refs/changes/15/186315/4 && git format-patch -1 --stdout FETCH_HEAD,"['nova/network/neutronv2/api.py', 'nova/tests/unit/network/test_neutronv2.py']",2,b2171cd79a537d962fd61807c4c34f35ef9faa21,bug/1407664," def test_build_network_info_model_empty(self): api = neutronapi.API() fake_inst = objects.Instance() fake_inst.project_id = 'fake' fake_inst.uuid = 'uuid' fake_inst.info_cache = objects.InstanceInfoCache() fake_inst.info_cache.network_info = model.NetworkInfo() fake_ports = [ # admin_state_up=True and status='ACTIVE' thus vif.active=True {'id': 'port1', 'network_id': 'net-id', 'admin_state_up': True, 'status': 'ACTIVE', 'fixed_ips': [{'ip_address': '1.1.1.1'}], 'mac_address': 'de:ad:be:ef:00:01', 'binding:vif_type': model.VIF_TYPE_BRIDGE, 'binding:vnic_type': model.VNIC_TYPE_NORMAL, 'binding:vif_details': {}, }, ] fake_subnets = [model.Subnet(cidr='1.0.0.0/8')] neutronapi.get_client(mox.IgnoreArg(), admin=True).MultipleTimes( ).AndReturn(self.moxed_client) self.moxed_client.list_ports( tenant_id='fake', device_id='uuid').AndReturn( {'ports': fake_ports}) self.mox.StubOutWithMock(api, '_gather_port_ids_and_networks') api._gather_port_ids_and_networks( self.context, fake_inst, None, None).AndReturn([None, None]) self.mox.StubOutWithMock(api, '_get_preexisting_port_ids') api._get_preexisting_port_ids(fake_inst).AndReturn([]) self.mox.StubOutWithMock(api, '_nw_info_build_network') self.mox.StubOutWithMock(api, '_nw_info_get_ips') self.mox.StubOutWithMock(api, '_nw_info_get_subnets') api._nw_info_get_ips( self.moxed_client, fake_ports[0]).AndReturn([]) api._nw_info_get_subnets( self.context, fake_ports[0], []).AndReturn(fake_subnets) api._nw_info_build_network( fake_ports[0], None, fake_subnets).AndReturn([None, None]) self.mox.ReplayAll() neutronapi.get_client('fake') fake_inst.info_cache = objects.InstanceInfoCache.new( self.context, 'fake-uuid') fake_inst.info_cache.network_info = model.NetworkInfo.hydrate([]) nw_infos = api._build_network_info_model( self.context, fake_inst) self.assertEqual(len(nw_infos), 1) ",,62,0
openstack%2Fkeystoneauth~master~Ib9e81773ab988ea05869bc27097d2b25e963e59c,openstack/keystoneauth,master,Ib9e81773ab988ea05869bc27097d2b25e963e59c,Add get_communication_params interface to plugins,MERGED,2015-06-15 05:02:48.000000000,2015-06-24 22:29:25.000000000,2015-06-24 22:29:24.000000000,"[{'_account_id': 3}, {'_account_id': 2903}]","[{'number': 1, 'created': '2015-06-15 05:02:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystoneauth/commit/ee504ca7a581fb1eed37dc7235ee775b46c8edd8', 'message': 'Add get_communication_params interface to plugins\n\nTo allow authentication plugins such as using client certificates or\ndoing kerberos authentication with every request we need a way for the\nplugins to manipulate the send parameters.\n\nChange-Id: Ib9e81773ab988ea05869bc27097d2b25e963e59c\nBlueprint: generic-plugins\n(cherry picked from commit 0ecf9b1ab5177fc42d16b4a57e8522769433b156)\n'}, {'number': 2, 'created': '2015-06-17 01:14:06.000000000', 'files': ['keystoneauth/session.py', 'keystoneauth/auth/base.py', 'keystoneauth/tests/unit/auth/test_identity_common.py', 'keystoneauth/exceptions/auth_plugins.py'], 'web_link': 'https://opendev.org/openstack/keystoneauth/commit/3e07bd2c40fcc05a6ad992aaa3668ced0471940b', 'message': 'Add get_communication_params interface to plugins\n\nTo allow authentication plugins such as using client certificates or\ndoing kerberos authentication with every request we need a way for the\nplugins to manipulate the send parameters.\n\nChange-Id: Ib9e81773ab988ea05869bc27097d2b25e963e59c\nBlueprint: generic-plugins\n(cherry picked from commit 0ecf9b1ab5177fc42d16b4a57e8522769433b156)\n'}]",0,191646,3e07bd2c40fcc05a6ad992aaa3668ced0471940b,8,2,2,7191,,,0,"Add get_communication_params interface to plugins

To allow authentication plugins such as using client certificates or
doing kerberos authentication with every request we need a way for the
plugins to manipulate the send parameters.

Change-Id: Ib9e81773ab988ea05869bc27097d2b25e963e59c
Blueprint: generic-plugins
(cherry picked from commit 0ecf9b1ab5177fc42d16b4a57e8522769433b156)
",git fetch https://review.opendev.org/openstack/keystoneauth refs/changes/46/191646/1 && git format-patch -1 --stdout FETCH_HEAD,"['keystoneauth/session.py', 'keystoneauth/auth/base.py', 'keystoneauth/tests/unit/auth/test_identity_common.py', 'keystoneauth/exceptions/auth_plugins.py']",4,ee504ca7a581fb1eed37dc7235ee775b46c8edd8,bp/generic-plugins," class UnsupportedParameters(AuthPluginException): """"""A parameter that was provided or returned is not supported. :param list(str) names: Names of the unsupported parameters. .. py:attribute:: names Names of the unsupported parameters. """""" def __init__(self, names): self.names = names m = 'The following parameters were given that are unsupported: %s' super(UnsupportedParameters, self).__init__(m % ', '.join(self.names))",,138,0
openstack%2Fkeystone~master~Id7652c2dd52facc01bf0144c71c21abc56ce25ea,openstack/keystone,master,Id7652c2dd52facc01bf0144c71c21abc56ce25ea,Document entrypoint namespaces,MERGED,2015-06-22 23:24:04.000000000,2015-06-24 22:28:34.000000000,2015-06-24 22:28:31.000000000,"[{'_account_id': 3}, {'_account_id': 2903}, {'_account_id': 6482}, {'_account_id': 11022}, {'_account_id': 13063}, {'_account_id': 16523}]","[{'number': 1, 'created': '2015-06-22 23:24:04.000000000', 'files': ['keystone/common/config.py'], 'web_link': 'https://opendev.org/openstack/keystone/commit/c3d339d43103ac8d1bd6def186c0664b26298822', 'message': 'Document entrypoint namespaces\n\nDocument the namespace for the entrypoints in the config options.\n\nbp stevedore\n\nChange-Id: Id7652c2dd52facc01bf0144c71c21abc56ce25ea\n'}]",1,194435,c3d339d43103ac8d1bd6def186c0664b26298822,10,6,1,6486,,,0,"Document entrypoint namespaces

Document the namespace for the entrypoints in the config options.

bp stevedore

Change-Id: Id7652c2dd52facc01bf0144c71c21abc56ce25ea
",git fetch https://review.opendev.org/openstack/keystone refs/changes/35/194435/1 && git format-patch -1 --stdout FETCH_HEAD,['keystone/common/config.py'],1,c3d339d43103ac8d1bd6def186c0664b26298822,bp/stevedore," help='Entrypoint for the identity backend driver in the ' 'keystone.identity namespace.'), help='Entrypoint for the identity mapping backend driver ' 'in the keystone.identity.id_mapping namespace.'), help='Entrypoint for the public ID generator for user and ' 'group entities in the keystone.identity.id_generator ' 'namespace. The Keystone identity mapper only ' 'supports generators that produce no more than 64 ' 'characters.'), help='Entrypoint for the trust backend driver in the ' 'keystone.trust namespace.')], 'revocation operations. Entrypoint in the ' 'keystone.token.provider namespace. Core providers ' 'are [fernet|pkiz|pki|uuid].'), help='Entrypoint for the token persistence backend driver ' 'in the keystone.token.persistence namespace.'), help='Entrypoint for an implementation of the backend for ' 'persisting revocation events in the keystone.revoke ' 'namespace.'), help='Entrypoint for the assignment backend driver in the ' 'keystone.assignment namespace.'), help='Entrypoint for the resource backend driver in the ' 'keystone.resource namespace. If a resource driver is ' help='Entrypoint for the domain config backend driver in ' 'the keystone.resource.domain_config namespace.'), help='Entrypoint for the role backend driver in the ' 'keystone.role namespace.'), help='Entrypoint for the credential backend driver in the ' 'keystone.credential namespace.'), help='Entrypoint for hte OAuth backend driver in the ' 'keystone.oauth1 namespace.'), help='Entrypoint for the federation backend driver in the ' 'keystone.federation namespace.'), help='Entrypoint for the policy backend driver in the ' 'keystone.policy namespace.'), help='Entrypoint for the endpoint filter backend driver in ' 'the keystone.endpoint_filter namespace.'), help='Entrypoint for the endpoint policy backend driver in ' 'the keystone.endpoint_policy namespace.'), help='Entrypoint for the password auth plugin module in ' 'the keystone.auth.password namespace.'), help='Entrypoint for the token auth plugin module in the ' 'keystone.auth.token namespace.'), 'plugin module in the keystone.auth.external ' 'namespace.'), help='Entrypoint for the oAuth1.0 auth plugin module in ' 'the keystone.auth.oauth1 namespace.'), help='Entrypoint for the catalog backend driver in the ' 'keystone.catalog namespace.'),"," help='Identity backend driver.'), help='Keystone Identity Mapping backend driver.'), help='Public ID generator for user and group entities. ' 'The Keystone identity mapper only supports ' 'generators that produce no more than 64 characters.'), help='Trust backend driver.')], 'revocation operations. Core providers are ' '[fernet|pkiz|pki|uuid].'), help='Token persistence backend driver.'), help='An implementation of the backend for persisting ' 'revocation events.'), help='Assignment backend driver.'), help='Resource backend driver. If a resource driver is ' help='Domain config backend driver.'), help='Role backend driver.'), help='Credential backend driver.'), help='OAuth backend driver.'), help='Federation backend driver.'), help='Policy backend driver.'), help='Endpoint Filter backend driver'), help='Endpoint policy backend driver'), help='Entrypoint for the password auth plugin module.'), help='Entrypoint for the token auth plugin module.'), 'plugin module.'), help='Entrypoint for the oAuth1.0 auth plugin module.'), help='Catalog backend driver.'),",49,26
openstack%2Fkeystoneauth~master~Id423a538c169264a81c5714e6a9eff9b33912a55,openstack/keystoneauth,master,Id423a538c169264a81c5714e6a9eff9b33912a55,Support discovery on the AUTH_INTERFACE,MERGED,2015-06-15 04:43:59.000000000,2015-06-24 22:28:02.000000000,2015-06-24 22:28:00.000000000,"[{'_account_id': 3}, {'_account_id': 2903}]","[{'number': 1, 'created': '2015-06-15 04:43:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystoneauth/commit/6c25b32c4c16144745b9de6ed5e55b7d88568867', 'message': 'Support discovery on the AUTH_INTERFACE\n\nWe need to allow get_endpoint(interface=auth.AUTH_INTERFACE, version=X)\nto support the same version negotiation that the service catalog goes\nthrough. This is required to support generic plugins where you often\nprovide an unversioned auth_url to the plugin but need a versioned URL\nto query for available projects.\n\nChange-Id: Id423a538c169264a81c5714e6a9eff9b33912a55\nCloses-Bug: #1438013\n(cherry picked from commit fd16240be482b4841dfafeee404f3a8e2678333e)\n'}, {'number': 2, 'created': '2015-06-18 01:47:17.000000000', 'files': ['keystoneauth/auth/identity/base.py', 'keystoneauth/tests/unit/auth/test_identity_common.py', 'keystoneauth/tests/unit/auth/test_identity_v3.py'], 'web_link': 'https://opendev.org/openstack/keystoneauth/commit/1a310f9fa54c9dc94b49c4446fdc344b0415c4bb', 'message': 'Support discovery on the AUTH_INTERFACE\n\nWe need to allow get_endpoint(interface=auth.AUTH_INTERFACE, version=X)\nto support the same version negotiation that the service catalog goes\nthrough. This is required to support generic plugins where you often\nprovide an unversioned auth_url to the plugin but need a versioned URL\nto query for available projects.\n\nChange-Id: Id423a538c169264a81c5714e6a9eff9b33912a55\nCloses-Bug: #1438013\n(cherry picked from commit fd16240be482b4841dfafeee404f3a8e2678333e)\n'}]",0,191641,1a310f9fa54c9dc94b49c4446fdc344b0415c4bb,9,2,2,7191,,,0,"Support discovery on the AUTH_INTERFACE

We need to allow get_endpoint(interface=auth.AUTH_INTERFACE, version=X)
to support the same version negotiation that the service catalog goes
through. This is required to support generic plugins where you often
provide an unversioned auth_url to the plugin but need a versioned URL
to query for available projects.

Change-Id: Id423a538c169264a81c5714e6a9eff9b33912a55
Closes-Bug: #1438013
(cherry picked from commit fd16240be482b4841dfafeee404f3a8e2678333e)
",git fetch https://review.opendev.org/openstack/keystoneauth refs/changes/41/191641/1 && git format-patch -1 --stdout FETCH_HEAD,"['keystoneauth/auth/identity/base.py', 'keystoneauth/tests/unit/auth/test_identity_common.py', 'keystoneauth/tests/unit/auth/test_identity_v3.py']",3,6c25b32c4c16144745b9de6ed5e55b7d88568867,bug/1438013, self.TEST_DISCOVERY_RESPONSE = { 'versions': {'values': [fixture.V3Discovery(self.TEST_URL)]}}," V3_URL = ""%sv3"" % self.TEST_URL self.TEST_DISCOVERY_RESPONSE = { 'versions': {'values': [fixture.V3Discovery(V3_URL)]}}",50,18
openstack%2Fkeystoneauth~master~I99b00df12c04517b5ffa1fe72e6b69d52d41d8a6,openstack/keystoneauth,master,I99b00df12c04517b5ffa1fe72e6b69d52d41d8a6,Keystone2KeystoneAuthPlugin scoping capabilities,MERGED,2015-06-05 18:04:59.000000000,2015-06-24 22:27:59.000000000,2015-06-24 22:27:58.000000000,"[{'_account_id': 3}, {'_account_id': 2903}, {'_account_id': 6482}, {'_account_id': 7191}, {'_account_id': 8978}, {'_account_id': 9981}, {'_account_id': 11022}]","[{'number': 1, 'created': '2015-06-05 18:04:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystoneauth/commit/0c6222bf6fadaaa7fb6b499c9e72ab13774870ab', 'message': 'Keystone2KeystoneAuthPLugin scoping capabilities\n\nThis enhancement takes care of scoping remote federated token in case\nscoping information were provided by a user. Otherwise it will return\nunscoped token wrapped with ``access.AccessInfoV3`` object.\n\nThis patch also introduces new options:\n- remote-domain-id\n- remote-domain-name\n- remote-project-id\n- remote-project-name\n- remote-project-domain-id\n- remote-project-domain-name\n- remote-trust-id\n\nwhere user will be able to specify scoping information for his remote\ncloud. Old non-remote corresponding values should be preserved for\ninteractions with his local cloud.\n\nChange-Id: I99b00df12c04517b5ffa1fe72e6b69d52d41d8a6\nImplements: bp k2k-auth-plugin\n'}, {'number': 2, 'created': '2015-06-05 18:15:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystoneauth/commit/2a6d9f83d41ff6e72f50f7d04ed763890f4a3f88', 'message': 'Keystone2KeystoneAuthPLugin scoping capabilities\n\nThis enhancement takes care of scoping remote federated token in case\nscoping information were provided by a user. Otherwise it will return\nunscoped token wrapped with ``access.AccessInfoV3`` object.\n\nThis patch also introduces new options:\n- remote-domain-id\n- remote-domain-name\n- remote-project-id\n- remote-project-name\n- remote-project-domain-id\n- remote-project-domain-name\n- remote-trust-id\n\nwhere user will be able to specify scoping information for his remote\ncloud. Old non-remote corresponding values should be preserved for\ninteractions with his local cloud.\n\nChange-Id: I99b00df12c04517b5ffa1fe72e6b69d52d41d8a6\nImplements: bp k2k-auth-plugin\n'}, {'number': 3, 'created': '2015-06-08 09:34:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystoneauth/commit/e5052a3e008bab27597bc877526625ff44f1b02b', 'message': 'Keystone2KeystoneAuthPlugin scoping capabilities\n\nThis enhancement takes care of scoping remote federated token in case\nscoping information were provided by a user. Otherwise it will return\nunscoped token wrapped with ``access.AccessInfoV3`` object.\n\nThis patch also introduces new options:\n- remote-domain-id\n- remote-domain-name\n- remote-project-id\n- remote-project-name\n- remote-project-domain-id\n- remote-project-domain-name\n- remote-trust-id\n\nwhere user will be able to specify scoping information for his remote\ncloud. Old non-remote corresponding values should be preserved for\ninteractions with his local cloud.\n\nChange-Id: I99b00df12c04517b5ffa1fe72e6b69d52d41d8a6\nImplements: bp k2k-auth-plugin\n'}, {'number': 4, 'created': '2015-06-08 11:49:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystoneauth/commit/a103a37dcb073d19f56d1943871450d0130197e7', 'message': 'Keystone2KeystoneAuthPlugin scoping capabilities\n\nThis enhancement takes care of scoping remote federated token in case\nscoping information were provided by a user. Otherwise it will return\nunscoped token wrapped with ``access.AccessInfoV3`` object.\n\nThis patch also introduces new options:\n- remote-domain-id\n- remote-domain-name\n- remote-project-id\n- remote-project-name\n- remote-project-domain-id\n- remote-project-domain-name\n- remote-trust-id\n\nwhere user will be able to specify scoping information for his remote\ncloud. Old non-remote corresponding values should be preserved for\ninteractions with his local cloud.\n\nChange-Id: I99b00df12c04517b5ffa1fe72e6b69d52d41d8a6\nImplements: bp k2k-auth-plugin\n'}, {'number': 5, 'created': '2015-06-08 13:57:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystoneauth/commit/ebddba405f2c37c44654b6fd02920edc66c42a2f', 'message': 'Keystone2KeystoneAuthPlugin scoping capabilities\n\nThis enhancement takes care of scoping remote federated token in case\nscoping information were provided by a user. Otherwise it will return\nunscoped token wrapped with ``access.AccessInfoV3`` object.\n\nThis patch also introduces new options:\n- remote-domain-id\n- remote-domain-name\n- remote-project-id\n- remote-project-name\n- remote-project-domain-id\n- remote-project-domain-name\n- remote-trust-id\n\nwhere user will be able to specify scoping information for his remote\ncloud. Old non-remote corresponding values should be preserved for\ninteractions with his local cloud.\n\nChange-Id: I99b00df12c04517b5ffa1fe72e6b69d52d41d8a6\nImplements: bp k2k-auth-plugin\n'}, {'number': 6, 'created': '2015-06-08 17:41:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystoneauth/commit/e02226c8dc0a16e4a9ea1af54f9440ad189fd29a', 'message': 'Keystone2KeystoneAuthPlugin scoping capabilities\n\nThis enhancement takes care of scoping remote federated token in case\nscoping information were provided by a user. Otherwise it will return\nunscoped token wrapped with ``access.AccessInfoV3`` object.\n\nThis patch also introduces new options:\n- remote-domain-id\n- remote-domain-name\n- remote-project-id\n- remote-project-name\n- remote-project-domain-id\n- remote-project-domain-name\n- remote-trust-id\n\nwhere user will be able to specify scoping information for his remote\ncloud. Old non-remote corresponding values should be preserved for\ninteractions with his local cloud.\n\nChange-Id: I99b00df12c04517b5ffa1fe72e6b69d52d41d8a6\nImplements: bp k2k-auth-plugin\n'}, {'number': 7, 'created': '2015-06-08 20:56:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystoneauth/commit/5a722784a62861be5306db216c0f1e94df58091c', 'message': 'Keystone2KeystoneAuthPlugin scoping capabilities\n\nThis enhancement takes care of scoping remote federated token in case\nscoping information were provided by a user. Otherwise it will return\nunscoped token wrapped with ``access.AccessInfoV3`` object.\n\nThis patch also introduces new options:\n- remote-domain-id\n- remote-domain-name\n- remote-project-id\n- remote-project-name\n- remote-project-domain-id\n- remote-project-domain-name\n- remote-trust-id\n\nwhere user will be able to specify scoping information for his remote\ncloud. Old non-remote corresponding values should be preserved for\ninteractions with his local cloud.\n\nChange-Id: I99b00df12c04517b5ffa1fe72e6b69d52d41d8a6\nImplements: bp k2k-auth-plugin\n'}, {'number': 8, 'created': '2015-06-11 12:02:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystoneauth/commit/ece46eff20d2b63a28bfa56fe61c01a9b949b1dc', 'message': 'Keystone2KeystoneAuthPlugin scoping capabilities\n\nThis enhancement takes care of scoping remote federated token in case\nscoping information were provided by a user. Otherwise it will return\nunscoped token wrapped with ``access.AccessInfoV3`` object.\n\nChange-Id: I99b00df12c04517b5ffa1fe72e6b69d52d41d8a6\nImplements: bp k2k-auth-plugin\n'}, {'number': 9, 'created': '2015-06-15 08:47:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystoneauth/commit/cab2876eb06a1e8de7e22462c6f93d1313ef8f65', 'message': 'Keystone2KeystoneAuthPlugin scoping capabilities\n\nThis enhancement takes care of scoping remote federated token in case\nscoping information were provided by a user. Otherwise it will return\nunscoped token wrapped with ``access.AccessInfoV3`` object.\n\nChange-Id: I99b00df12c04517b5ffa1fe72e6b69d52d41d8a6\nImplements: bp k2k-auth-plugin\n'}, {'number': 10, 'created': '2015-06-17 12:51:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystoneauth/commit/89583052e15d48f22d651af77ae422a901384094', 'message': 'Keystone2KeystoneAuthPlugin scoping capabilities\n\nThis enhancement takes care of scoping remote federated token in case\nscoping information were provided by a user. Otherwise it will return\nunscoped token wrapped with ``access.AccessInfoV3`` object.\n\nChange-Id: I99b00df12c04517b5ffa1fe72e6b69d52d41d8a6\nImplements: bp k2k-auth-plugin\n'}, {'number': 11, 'created': '2015-06-17 13:08:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystoneauth/commit/f1104053adec186102bf1e5ee31f935304565be2', 'message': 'Keystone2KeystoneAuthPlugin scoping capabilities\n\nThis enhancement takes care of scoping remote federated token in case\nscoping information were provided by a user. Otherwise it will return\nunscoped token wrapped with ``access.AccessInfoV3`` object.\n\nChange-Id: I99b00df12c04517b5ffa1fe72e6b69d52d41d8a6\nImplements: bp k2k-auth-plugin\n'}, {'number': 12, 'created': '2015-06-17 13:25:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystoneauth/commit/5eee7cdbb70f25db8465e507505ffcf0914ae2f5', 'message': 'Keystone2KeystoneAuthPlugin scoping capabilities\n\nThis enhancement takes care of scoping remote federated token in case\nscoping information were provided by a user. Otherwise it will return\nunscoped token wrapped with ``access.AccessInfoV3`` object.\n\nChange-Id: I99b00df12c04517b5ffa1fe72e6b69d52d41d8a6\nImplements: bp k2k-auth-plugin\n'}, {'number': 13, 'created': '2015-06-22 12:16:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystoneauth/commit/650480fff5e66520339dd8c169a33f8d61d61117', 'message': 'Keystone2KeystoneAuthPlugin scoping capabilities\n\nThis enhancement takes care of scoping remote federated token in case\nscoping information were provided by a user. Otherwise it will return\nunscoped token wrapped with ``access.AccessInfoV3`` object.\n\nChange-Id: I99b00df12c04517b5ffa1fe72e6b69d52d41d8a6\nImplements: bp k2k-auth-plugin\n'}, {'number': 14, 'created': '2015-06-22 13:54:05.000000000', 'files': ['keystoneauth/auth/identity/v3/k2k.py'], 'web_link': 'https://opendev.org/openstack/keystoneauth/commit/30f49dad9873a8a67c780b0e7a203d20c3f9c666', 'message': 'Keystone2KeystoneAuthPlugin scoping capabilities\n\nThis enhancement takes care of scoping remote federated token in case\nscoping information were provided by a user. Otherwise it will return\nunscoped token wrapped with ``access.AccessInfoV3`` object.\n\nChange-Id: I99b00df12c04517b5ffa1fe72e6b69d52d41d8a6\nImplements: bp k2k-auth-plugin\n'}]",6,188881,30f49dad9873a8a67c780b0e7a203d20c3f9c666,46,7,14,8978,,,0,"Keystone2KeystoneAuthPlugin scoping capabilities

This enhancement takes care of scoping remote federated token in case
scoping information were provided by a user. Otherwise it will return
unscoped token wrapped with ``access.AccessInfoV3`` object.

Change-Id: I99b00df12c04517b5ffa1fe72e6b69d52d41d8a6
Implements: bp k2k-auth-plugin
",git fetch https://review.opendev.org/openstack/keystoneauth refs/changes/81/188881/4 && git format-patch -1 --stdout FETCH_HEAD,['keystoneauth/auth/identity/v3/federation.py'],1,0c6222bf6fadaaa7fb6b499c9e72ab13774870ab,bp/k2k-auth-plugin," def __init__(self, base_plugin, service_provider, sp_url, sp_auth_url, remote_trust_id=None, remote_domain_id=None, remote_domain_name=None, remote_project_id=None, remote_project_name=None, remote_project_domain_id=None, remote_project_domain_name=None): auth_url=Keystone2KeystoneAuthPlugin.remote_auth_url( base_plugin.auth_url)) self.remote_trust_id = remote_trust_id self.remote_domain_id = remote_domain_id self.remote_domain_name = remote_domain_name self.remote_project_id = remote_project_id self.remote_project_name = remote_project_name self.remote_project_domain_id = remote_project_domain_id self.remote_project_domain_name = remote_project_domain_name @staticmethod def remote_auth_url(self, auth_url): """"""Return auth_url of the remote OpenStack cloud. Remote cloud's auth_url is an endpoint for getting federated unscoped token, typically that would be ``https://remote.example.com:5000/v3/OS-FEDERATION/identity_providers/ <idp>/protocols/<proto>/auth``. However we need to generate a real auth_url, used for token scoping. This function assumes there are static values today in the remote auth_url stored in the Service Provider attribute and those can be used as a delimiter. If the sp_auth_url doesn't comply with standard federation auth url the function will simply return whole string. :returns: auth_url of remote cloud where a token can be validated or scoped. :rtype: string """""" PATTERN = '/v3/OS-FEDERATION/' try: index = auth_url.index(PATTERN) except ValueError: return auth_url else: return auth_url[:index] def _get_scoping_remote_data(self): return {'trust_id': self.remote_trust_id, 'domain_id': self.remote_domain_id, 'domain_name': self.remote_domain_name, 'project_id': self.remote_project_id, 'project_name': self.remote_project_name, 'project_domain_id': self.remote_project_domain_id, 'project_domain_name': self.remote_project_domain_name} help='Service Provider\'s Authentication URL'), cfg.StrOpt('remote-domain-id', help='Remote domain ID to scope to'), cfg.StrOpt('remote-domain-name', help='Remote domain name to scope to'), cfg.StrOpt('remote-project-id', help='Remote project ID to scope to'), cfg.StrOpt('remote-project-name', help='Remote project name to scope to'), cfg.StrOpt('remote-project-domain-id', help='Remote domain ID containing project'), cfg.StrOpt('remote-project-domain-name', help='Remote domain name containing project'), cfg.StrOpt('remote-trust-id', help='Remote trust ID'), def _get_unscoped_auth_ref(self, session): token = self._sp_response.headers['X-Subject-Token'] token_json = self._sp_response.json()['token'] return access.AccessInfoV3(token, token_json) auth_ref = self._get_unscoped_token(session) scoping = self._get_scoping_remote_data() if any(scoping.values()): token_plugin = self.rescoping_plugin(self.token_url, token=auth_ref.auth_token, **scoping) auth_ref = token_plugin.get_auth_ref(session) return auth_ref"," def __init__(self, base_plugin, service_provider, sp_url, sp_auth_url): auth_url=base_plugin.auth_url) # TODO(rodrigods): this is not a regular plugin - it contains another # plugin. So we may use any AuthPlugin to authenticate and then pass # to this one in order to request a token from ta Service Provider. help='Service Provider\'s Authentication URL') def _get_unscoped_token(self, session): return (self._sp_response.headers['X-Subject-Token'], self._sp_response.json()['token']) token, token_json = self._get_unscoped_token(session) return access.AccessInfoV3(token, **token_json)",83,11
openstack%2Fkeystone~master~I2484af32e9eb3703869cf441e4f9851b54b0db2b,openstack/keystone,master,I2484af32e9eb3703869cf441e4f9851b54b0db2b,Short names for auth plugins,MERGED,2015-05-11 22:47:49.000000000,2015-06-24 22:24:47.000000000,2015-06-24 22:24:46.000000000,"[{'_account_id': 3}, {'_account_id': 2903}, {'_account_id': 6482}, {'_account_id': 6486}, {'_account_id': 8290}, {'_account_id': 8866}, {'_account_id': 13063}]","[{'number': 1, 'created': '2015-05-11 22:47:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/68fd17aac20641453bb34c012228cc4164a2400a', 'message': 'Default auth plugin\n\nDefine a ""default"" entrypoint for each auth plugin.\n\nbp stevedore\n\nChange-Id: I2484af32e9eb3703869cf441e4f9851b54b0db2b\n'}, {'number': 2, 'created': '2015-05-11 22:52:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/0295ad676f0f8ad708056d5d44df5ef37f11283e', 'message': 'Short names for auth plugins\n\nA ""default"" entrypoint is defined for each auth method. The\ndefault driver will be used if there\'s no config option for the\nmethod, or the config option is not set, or if the config option\nis set to ""default"".\n\nFor the external methods, since there\'s several of them, each gets\na short name that can be used rather than the qualified class.\n\nbp stevedore\n\nChange-Id: I2484af32e9eb3703869cf441e4f9851b54b0db2b\n'}, {'number': 3, 'created': '2015-05-12 01:52:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/11ca41ba84ac1dabc53aa377000d37d6afe3cf79', 'message': 'Short names for auth plugins\n\nA ""default"" entrypoint is defined for each auth method. The\ndefault driver will be used if there\'s no config option for the\nmethod, or the config option is not set, or if the config option\nis set to ""default"".\n\nFor the external methods, since there\'s several of them, each gets\na short name that can be used rather than the qualified class.\n\nbp stevedore\n\nChange-Id: I2484af32e9eb3703869cf441e4f9851b54b0db2b\n'}, {'number': 4, 'created': '2015-05-21 23:06:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/e0d93359afae5e592d8c5475c1e3ee574abafcbc', 'message': 'Short names for auth plugins\n\nA ""default"" entrypoint is defined for each auth method. The\ndefault driver will be used if there\'s no config option for the\nmethod, or the config option is not set, or if the config option\nis set to ""default"".\n\nFor the external methods, since there\'s several of them, each gets\na short name that can be used rather than the qualified class.\n\nbp stevedore\n\nChange-Id: I2484af32e9eb3703869cf441e4f9851b54b0db2b\n'}, {'number': 5, 'created': '2015-05-21 23:55:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/aa3459acad51d4ad4e2fa2a8fa20a7a888334f1b', 'message': 'Short names for auth plugins\n\nA ""default"" entrypoint is defined for each auth method. The\ndefault driver will be used if there\'s no config option for the\nmethod, or the config option is not set, or if the config option\nis set to ""default"".\n\nFor the external methods, since there\'s several of them, each gets\na short name that can be used rather than the qualified class.\n\nbp stevedore\n\nChange-Id: I2484af32e9eb3703869cf441e4f9851b54b0db2b\n'}, {'number': 6, 'created': '2015-05-22 18:55:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/b67c5b131b433695c086f2ed01ab36a4480f8c30', 'message': 'Short names for auth plugins\n\nA ""default"" entrypoint is defined for each auth method. The\ndefault driver will be used if there\'s no config option for the\nmethod, or the config option is not set, or if the config option\nis set to ""default"".\n\nFor the external methods, since there\'s several of them, each gets\na short name that can be used rather than the qualified class.\n\nbp stevedore\n\nChange-Id: I2484af32e9eb3703869cf441e4f9851b54b0db2b\n'}, {'number': 7, 'created': '2015-06-09 00:43:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/daefb07e709d836ce623821e5472db2e5b1df190', 'message': 'Short names for auth plugins\n\nA ""default"" entrypoint is defined for each auth method. The\ndefault driver will be used if there\'s no config option for the\nmethod, or the config option is not set, or if the config option\nis set to ""default"".\n\nFor the external methods, since there\'s several of them, each gets\na short name that can be used rather than the qualified class.\n\nbp stevedore\n\nDocImpact\n\nChange-Id: I2484af32e9eb3703869cf441e4f9851b54b0db2b\n'}, {'number': 8, 'created': '2015-06-09 01:01:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/209892a6a584cf29e3ae06cfee2577430cca0948', 'message': 'Short names for auth plugins\n\nA ""default"" entrypoint is defined for each auth method. The\ndefault driver will be used if there\'s no config option for the\nmethod, or the config option is not set, or if the config option\nis set to ""default"".\n\nFor the external methods, since there\'s several of them, each gets\na short name that can be used rather than the qualified class.\n\nbp stevedore\n\nDocImpact\n\nChange-Id: I2484af32e9eb3703869cf441e4f9851b54b0db2b\n'}, {'number': 9, 'created': '2015-06-19 02:15:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/fc91fa08eea62c01415c7e9619045a404689dd2b', 'message': 'Short names for auth plugins\n\nA ""default"" entrypoint is defined for each auth method. The\ndefault driver will be used if there\'s no config option for the\nmethod, or the config option is not set, or if the config option\nis set to ""default"".\n\nFor the external methods, since there\'s several of them, each gets\na short name that can be used rather than the qualified class.\n\nbp stevedore\n\nDocImpact\n\nChange-Id: I2484af32e9eb3703869cf441e4f9851b54b0db2b\n'}, {'number': 10, 'created': '2015-06-22 22:50:10.000000000', 'files': ['keystone/auth/controllers.py', 'keystone/tests/unit/test_config.py', 'keystone/tests/unit/test_v3_federation.py', 'keystone/common/config.py', 'keystone/tests/unit/test_v3_auth.py', 'doc/source/external-auth.rst', 'keystone/tests/unit/config_files/test_auth_plugin.conf', 'setup.cfg', 'doc/source/extensions/federation.rst', 'doc/source/extensions/oauth1.rst'], 'web_link': 'https://opendev.org/openstack/keystone/commit/04ff3541be021ab6e96829e47a33a0f6c7053a25', 'message': 'Short names for auth plugins\n\nA ""default"" entrypoint is defined for each auth method. The\ndefault driver will be used if there\'s no config option for the\nmethod, or the config option is not set, or if the config option\nis set to ""default"".\n\nFor the external methods, since there\'s several of them, each gets\na short name that can be used rather than the qualified class.\n\nbp stevedore\n\nDocImpact\n\nChange-Id: I2484af32e9eb3703869cf441e4f9851b54b0db2b\n'}]",13,182107,04ff3541be021ab6e96829e47a33a0f6c7053a25,32,7,10,6486,,,0,"Short names for auth plugins

A ""default"" entrypoint is defined for each auth method. The
default driver will be used if there's no config option for the
method, or the config option is not set, or if the config option
is set to ""default"".

For the external methods, since there's several of them, each gets
a short name that can be used rather than the qualified class.

bp stevedore

DocImpact

Change-Id: I2484af32e9eb3703869cf441e4f9851b54b0db2b
",git fetch https://review.opendev.org/openstack/keystone refs/changes/07/182107/5 && git format-patch -1 --stdout FETCH_HEAD,"['keystone/tests/unit/test_auth_plugin.py', 'keystone/auth/controllers.py', 'keystone/tests/unit/test_v3_federation.py', 'keystone/common/config.py', 'keystone/tests/unit/test_v3_oauth1.py', 'keystone/tests/unit/test_v3_auth.py', 'keystone/tests/unit/core.py', 'setup.cfg']",8,68fd17aac20641453bb34c012228cc4164a2400a,bp/stevedore, default = keystone.auth.plugins.external:DefaultDomain DefaultDomain = keystone.auth.plugins.external:DefaultDomain Domain = keystone.auth.plugins.external:Domain LegacyDefaultDomain = keystone.auth.plugins.external:LegacyDefaultDomain LegacyDomain = keystone.auth.plugins.external:LegacyDomain default = keystone.auth.plugins.external:KerberosDomain default = keystone.auth.plugins.oauth1:OAuth default = keystone.auth.plugins.mapped:Mapped default = keystone.auth.plugins.password:Password default = keystone.auth.plugins.mapped:Mapped default = keystone.auth.plugins.token:Token default = keystone.auth.plugins.mapped:Mapped, keystone.auth.plugins.external.DefaultDomain = keystone.auth.plugins.external:DefaultDomain keystone.auth.plugins.external.Domain = keystone.auth.plugins.external:Domain keystone.auth.plugins.external.LegacyDefaultDomain = keystone.auth.plugins.external:LegacyDefaultDomain keystone.auth.plugins.external.LegacyDomain = keystone.auth.plugins.external:LegacyDomain keystone.auth.plugins.external.KerberosDomain = keystone.auth.plugins.external:KerberosDomain keystone.auth.plugins.oauth1.OAuth = keystone.auth.plugins.oauth1:OAuth keystone.auth.plugins.mapped.Mapped = keystone.auth.plugins.mapped:Mapped keystone.auth.plugins.password.Password = keystone.auth.plugins.password:Password keystone.auth.plugins.mapped.Mapped = keystone.auth.plugins.mapped:Mapped keystone.auth.plugins.saml2.Saml2 = keystone.auth.plugins.saml2:Saml2 keystone.auth.plugins.token.Token = keystone.auth.plugins.token:Token keystone.auth.plugins.mapped.Mapped = keystone.auth.plugins.mapped:Mapped,41,45
openstack%2Fkeystoneauth~master~I91d95e3e2a5079d27575a66177c132ef20e00d63,openstack/keystoneauth,master,I91d95e3e2a5079d27575a66177c132ef20e00d63,Add Keystone2KeystoneAuthPlugin for K2K federation,MERGED,2015-06-04 20:41:36.000000000,2015-06-24 22:22:02.000000000,2015-06-24 22:22:00.000000000,"[{'_account_id': 2}, {'_account_id': 3}, {'_account_id': 4}, {'_account_id': 792}, {'_account_id': 1916}, {'_account_id': 1941}, {'_account_id': 2218}, {'_account_id': 2903}, {'_account_id': 5046}, {'_account_id': 5707}, {'_account_id': 6482}, {'_account_id': 6486}, {'_account_id': 7191}, {'_account_id': 7725}, {'_account_id': 8978}, {'_account_id': 9981}, {'_account_id': 11022}]","[{'number': 1, 'created': '2015-06-04 20:41:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystoneauth/commit/4022e013afb8a03de260feaa54db565dd084370f', 'message': 'Add Keystone2KeystoneAuthPlugin for K2K federation\n\nImplement the auth plugin to be used for keystone to keystone\nfederation.\n\nCo-Authored-By: Doug Fish <drfish@us.ibm.com>\n\nbp k2k-auth-plugin\n\nChange-Id: I91d95e3e2a5079d27575a66177c132ef20e00d63\n'}, {'number': 2, 'created': '2015-06-08 08:39:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystoneauth/commit/2ed59f61950a2e8c2969bced1b8b57c0c14d961e', 'message': 'Add Keystone2KeystoneAuthPlugin for K2K federation\n\nImplement the auth plugin to be used for keystone to keystone\nfederation.\n\nCo-Authored-By: Doug Fish <drfish@us.ibm.com>\n\nbp k2k-auth-plugin\n\nChange-Id: I91d95e3e2a5079d27575a66177c132ef20e00d63\n'}, {'number': 3, 'created': '2015-06-08 09:29:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystoneauth/commit/81bae89cc54f2ff5e165ffe52c0b790594375875', 'message': 'Add Keystone2KeystoneAuthPlugin for K2K federation\n\nImplement the auth plugin to be used for keystone to keystone\nfederation.\n\nCo-Authored-By: Doug Fish <drfish@us.ibm.com>\n\nbp k2k-auth-plugin\n\nChange-Id: I91d95e3e2a5079d27575a66177c132ef20e00d63\n'}, {'number': 4, 'created': '2015-06-08 11:44:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystoneauth/commit/5145b7a3cba6e72439c76d0c343481c43cb50d5c', 'message': 'Add Keystone2KeystoneAuthPlugin for K2K federation\n\nImplement the auth plugin to be used for keystone to keystone\nfederation.\n\nCo-Authored-By: Doug Fish <drfish@us.ibm.com>\n\nbp k2k-auth-plugin\n\nChange-Id: I91d95e3e2a5079d27575a66177c132ef20e00d63\n'}, {'number': 5, 'created': '2015-06-08 12:07:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystoneauth/commit/f786cc2effc162a02e8c81e68f883f1cc3537e09', 'message': 'Add Keystone2KeystoneAuthPlugin for K2K federation\n\nImplement the auth plugin to be used for keystone to keystone\nfederation.\n\nCo-Authored-By: Doug Fish <drfish@us.ibm.com>\n\nbp k2k-auth-plugin\n\nChange-Id: I91d95e3e2a5079d27575a66177c132ef20e00d63\n'}, {'number': 6, 'created': '2015-06-08 13:31:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystoneauth/commit/8541f08d6de36dfa388b6a220c9ab70c5efe280c', 'message': 'Add Keystone2KeystoneAuthPlugin for K2K federation\n\nImplement the auth plugin to be used for keystone to keystone\nfederation.\n\nCo-Authored-By: Doug Fish <drfish@us.ibm.com>\n\nbp k2k-auth-plugin\n\nChange-Id: I91d95e3e2a5079d27575a66177c132ef20e00d63\n'}, {'number': 7, 'created': '2015-06-08 13:34:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystoneauth/commit/f0afda34ae7c6f89b3e392bf6d2cbad6f2178684', 'message': 'Add Keystone2KeystoneAuthPlugin for K2K federation\n\nImplement the auth plugin to be used for keystone to keystone\nfederation.\n\nCo-Authored-By: Doug Fish <drfish@us.ibm.com>\nCo-Authored-By: Marek Denis <marek.denis@cern.ch>\n\nbp k2k-auth-plugin\n\nChange-Id: I91d95e3e2a5079d27575a66177c132ef20e00d63\n'}, {'number': 8, 'created': '2015-06-08 17:41:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystoneauth/commit/08f6e6c589963daa7e8f5906a4036bcdbc8d4347', 'message': 'Add Keystone2KeystoneAuthPlugin for K2K federation\n\nImplement the auth plugin to be used for keystone to keystone\nfederation.\n\nCo-Authored-By: Doug Fish <drfish@us.ibm.com>\nCo-Authored-By: Marek Denis <marek.denis@cern.ch>\n\nbp k2k-auth-plugin\n\nChange-Id: I91d95e3e2a5079d27575a66177c132ef20e00d63\n'}, {'number': 9, 'created': '2015-06-08 20:56:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystoneauth/commit/1c3c96c89fb9209b06aa0bddac95e7f06d208372', 'message': 'Add Keystone2KeystoneAuthPlugin for K2K federation\n\nImplement the auth plugin to be used for keystone to keystone\nfederation.\n\nCo-Authored-By: Doug Fish <drfish@us.ibm.com>\nCo-Authored-By: Marek Denis <marek.denis@cern.ch>\n\nbp k2k-auth-plugin\n\nChange-Id: I91d95e3e2a5079d27575a66177c132ef20e00d63\n'}, {'number': 10, 'created': '2015-06-09 09:55:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystoneauth/commit/69c36381acaad9eeadabf36d59cda7caf4239e83', 'message': 'Add Keystone2KeystoneAuthPlugin for K2K federation\n\nImplement the auth plugin to be used for keystone to keystone\nfederation.\n\nCo-Authored-By: Doug Fish <drfish@us.ibm.com>\nCo-Authored-By: Marek Denis <marek.denis@cern.ch>\n\nbp k2k-auth-plugin\n\nChange-Id: I91d95e3e2a5079d27575a66177c132ef20e00d63\n'}, {'number': 11, 'created': '2015-06-09 16:21:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystoneauth/commit/49f343ab60f740077873bb18155d039cb4e53a57', 'message': 'Add Keystone2KeystoneAuthPlugin for K2K federation\n\nImplement the auth plugin to be used for keystone to keystone\nfederation.\n\nCo-Authored-By: Doug Fish <drfish@us.ibm.com>\nCo-Authored-By: Marek Denis <marek.denis@cern.ch>\n\nbp k2k-auth-plugin\n\nChange-Id: I91d95e3e2a5079d27575a66177c132ef20e00d63\n'}, {'number': 12, 'created': '2015-06-09 16:44:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystoneauth/commit/d9039dc413ddb5d3fc8ae768cf1d651f9a20d5f9', 'message': 'Add Keystone2KeystoneAuthPlugin for K2K federation\n\nImplement the auth plugin to be used for keystone to keystone\nfederation.\n\nCo-Authored-By: Doug Fish <drfish@us.ibm.com>\nCo-Authored-By: Marek Denis <marek.denis@cern.ch>\n\nbp k2k-auth-plugin\n\nChange-Id: I91d95e3e2a5079d27575a66177c132ef20e00d63\n'}, {'number': 13, 'created': '2015-06-09 16:49:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystoneauth/commit/e2dbe638d06ea0b3de40690f757f928f7b0a491f', 'message': 'Add Keystone2KeystoneAuthPlugin for K2K federation\n\nImplement the auth plugin to be used for keystone to keystone\nfederation.\n\nCo-Authored-By: Doug Fish <drfish@us.ibm.com>\nCo-Authored-By: Marek Denis <marek.denis@cern.ch>\n\nbp k2k-auth-plugin\n\nChange-Id: I91d95e3e2a5079d27575a66177c132ef20e00d63\n'}, {'number': 14, 'created': '2015-06-10 07:14:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystoneauth/commit/64499b2fcce5199322206fdc8ebd604d1664d439', 'message': 'Add Keystone2KeystoneAuthPlugin for K2K federation\n\nImplement the auth plugin to be used for keystone to keystone\nfederation.\n\nCo-Authored-By: Doug Fish <drfish@us.ibm.com>\nCo-Authored-By: Marek Denis <marek.denis@cern.ch>\n\nbp k2k-auth-plugin\n\nChange-Id: I91d95e3e2a5079d27575a66177c132ef20e00d63\n'}, {'number': 15, 'created': '2015-06-10 14:25:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystoneauth/commit/37277d4bfe59e6c457c401475970358b355648e4', 'message': 'Add Keystone2KeystoneAuthPlugin for K2K federation\n\nImplement the auth plugin to be used for keystone to keystone\nfederation.\n\nCo-Authored-By: Doug Fish <drfish@us.ibm.com>\nCo-Authored-By: Marek Denis <marek.denis@cern.ch>\n\nbp k2k-auth-plugin\n\nChange-Id: I91d95e3e2a5079d27575a66177c132ef20e00d63\n'}, {'number': 16, 'created': '2015-06-10 14:31:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystoneauth/commit/aa24e0c0c84026a603a07575b528da416bd4351f', 'message': 'Add Keystone2KeystoneAuthPlugin for K2K federation\n\nImplement the auth plugin to be used for keystone to keystone\nfederation.\n\nCo-Authored-By: Doug Fish <drfish@us.ibm.com>\nCo-Authored-By: Marek Denis <marek.denis@cern.ch>\n\nbp k2k-auth-plugin\n\nChange-Id: I91d95e3e2a5079d27575a66177c132ef20e00d63\n'}, {'number': 17, 'created': '2015-06-11 09:43:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystoneauth/commit/f2a555f661e5609a50564c2f5fcf889faf51e619', 'message': 'Add Keystone2KeystoneAuthPlugin for K2K federation\n\nImplement the auth plugin to be used for keystone to keystone\nfederation.\n\nCo-Authored-By: Doug Fish <drfish@us.ibm.com>\nCo-Authored-By: Marek Denis <marek.denis@cern.ch>\n\nbp k2k-auth-plugin\n\nChange-Id: I91d95e3e2a5079d27575a66177c132ef20e00d63\n'}, {'number': 18, 'created': '2015-06-11 12:10:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystoneauth/commit/200a0c0c037868fd0d233b04776294bbd6e3f4a8', 'message': 'Add Keystone2KeystoneAuthPlugin for K2K federation\n\nImplement the auth plugin to be used for keystone to keystone\nfederation.\n\nCo-Authored-By: Doug Fish <drfish@us.ibm.com>\nCo-Authored-By: Marek Denis <marek.denis@cern.ch>\n\nbp k2k-auth-plugin\n\nChange-Id: I91d95e3e2a5079d27575a66177c132ef20e00d63\n'}, {'number': 19, 'created': '2015-06-12 14:38:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystoneauth/commit/705911411242b36947cc3af60d177391821926a6', 'message': 'Add Keystone2KeystoneAuthPlugin for K2K federation\n\nImplement the auth plugin to be used for keystone to keystone\nfederation.\n\nCo-Authored-By: Doug Fish <drfish@us.ibm.com>\nCo-Authored-By: Marek Denis <marek.denis@cern.ch>\n\nbp k2k-auth-plugin\n\nChange-Id: I91d95e3e2a5079d27575a66177c132ef20e00d63\n'}, {'number': 20, 'created': '2015-06-12 15:31:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystoneauth/commit/fb673803675b83a4c60d828ea4b54df38bba5af9', 'message': 'Add Keystone2KeystoneAuthPlugin for K2K federation\n\nImplement the auth plugin to be used for keystone to keystone\nfederation.\n\nCo-Authored-By: Doug Fish <drfish@us.ibm.com>\nCo-Authored-By: Marek Denis <marek.denis@cern.ch>\n\nbp k2k-auth-plugin\n\nChange-Id: I91d95e3e2a5079d27575a66177c132ef20e00d63\n'}, {'number': 21, 'created': '2015-06-12 20:09:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystoneauth/commit/0f3815d61ea90ce32ff0cc9ac4477ed44bedd2f2', 'message': 'Add Keystone2KeystoneAuthPlugin for K2K federation\n\nImplement the auth plugin to be used for keystone to keystone\nfederation.\n\nCo-Authored-By: Doug Fish <drfish@us.ibm.com>\nCo-Authored-By: Marek Denis <marek.denis@cern.ch>\n\nbp k2k-auth-plugin\n\nChange-Id: I91d95e3e2a5079d27575a66177c132ef20e00d63\n'}, {'number': 22, 'created': '2015-06-15 06:28:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystoneauth/commit/ad73346ba62beabe7385406ad24e40ed3b6327b8', 'message': 'Add Keystone2KeystoneAuthPlugin for K2K federation\n\nImplement the auth plugin to be used for keystone to keystone\nfederation.\n\nCo-Authored-By: Doug Fish <drfish@us.ibm.com>\nCo-Authored-By: Marek Denis <marek.denis@cern.ch>\n\nbp k2k-auth-plugin\n\nChange-Id: I91d95e3e2a5079d27575a66177c132ef20e00d63\n'}, {'number': 23, 'created': '2015-06-16 17:19:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystoneauth/commit/23db5a6934dae77a7f126d7519972fa214ad5ff9', 'message': 'Add Keystone2KeystoneAuthPlugin for K2K federation\n\nImplement the auth plugin to be used for keystone to keystone\nfederation.\n\nCo-Authored-By: Doug Fish <drfish@us.ibm.com>\nCo-Authored-By: Marek Denis <marek.denis@cern.ch>\n\nbp k2k-auth-plugin\n\nChange-Id: I91d95e3e2a5079d27575a66177c132ef20e00d63\n'}, {'number': 24, 'created': '2015-06-17 12:51:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystoneauth/commit/90dc445d17e8dfcc123f8c4bc5f1e214eb0e600b', 'message': 'Add Keystone2KeystoneAuthPlugin for K2K federation\n\nImplement the auth plugin to be used for keystone to keystone\nfederation.\n\nCo-Authored-By: Doug Fish <drfish@us.ibm.com>\nCo-Authored-By: Marek Denis <marek.denis@cern.ch>\n\nbp k2k-auth-plugin\n\nChange-Id: I91d95e3e2a5079d27575a66177c132ef20e00d63\n'}, {'number': 25, 'created': '2015-06-17 13:08:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystoneauth/commit/bbb5764d2554be4b7de58409c4c9a6f018cd8368', 'message': 'Add Keystone2KeystoneAuthPlugin for K2K federation\n\nImplement the auth plugin to be used for keystone to keystone\nfederation.\n\nCo-Authored-By: Doug Fish <drfish@us.ibm.com>\nCo-Authored-By: Marek Denis <marek.denis@cern.ch>\n\nbp k2k-auth-plugin\n\nChange-Id: I91d95e3e2a5079d27575a66177c132ef20e00d63\n'}, {'number': 26, 'created': '2015-06-17 13:25:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystoneauth/commit/78fb30838bb60acf5df1ed827000616b96c4f387', 'message': 'Add Keystone2KeystoneAuthPlugin for K2K federation\n\nImplement the auth plugin to be used for keystone to keystone\nfederation.\n\nCo-Authored-By: Doug Fish <drfish@us.ibm.com>\nCo-Authored-By: Marek Denis <marek.denis@cern.ch>\n\nbp k2k-auth-plugin\n\nChange-Id: I91d95e3e2a5079d27575a66177c132ef20e00d63\n'}, {'number': 27, 'created': '2015-06-22 13:53:17.000000000', 'files': ['keystoneauth/auth/identity/v3/k2k.py', 'keystoneauth/tests/unit/k2k_fixtures.py', 'keystoneauth/tests/unit/auth/test_identity_v3_federation.py', 'setup.cfg', 'keystoneauth/auth/identity/v3/__init__.py'], 'web_link': 'https://opendev.org/openstack/keystoneauth/commit/400a4d046d0048ca49d104f0051f5fbd4788f077', 'message': 'Add Keystone2KeystoneAuthPlugin for K2K federation\n\nImplement the auth plugin to be used for keystone to keystone\nfederation.\n\nCo-Authored-By: Doug Fish <drfish@us.ibm.com>\nCo-Authored-By: Marek Denis <marek.denis@cern.ch>\n\nbp k2k-auth-plugin\n\nChange-Id: I91d95e3e2a5079d27575a66177c132ef20e00d63\n'}]",57,188581,400a4d046d0048ca49d104f0051f5fbd4788f077,98,17,27,11022,,,0,"Add Keystone2KeystoneAuthPlugin for K2K federation

Implement the auth plugin to be used for keystone to keystone
federation.

Co-Authored-By: Doug Fish <drfish@us.ibm.com>
Co-Authored-By: Marek Denis <marek.denis@cern.ch>

bp k2k-auth-plugin

Change-Id: I91d95e3e2a5079d27575a66177c132ef20e00d63
",git fetch https://review.opendev.org/openstack/keystoneauth refs/changes/81/188581/25 && git format-patch -1 --stdout FETCH_HEAD,"['keystoneauth/tests/unit/auth/test_identity_v3_federation.py', 'keystoneauth/auth/identity/v3/__init__.py', 'keystoneauth/auth/identity/v3/federation.py']",3,4022e013afb8a03de260feaa54db565dd084370f,bp/k2k-auth-plugin,"from keystoneauth import access__all__ = ['FederationBaseAuth', 'Keystone2KeystoneAuthPlugin'] class Keystone2KeystoneAuthPlugin(base.BaseAuth): """"""Plugin to execute the keystone to keyestone authentication flow. In this plugin, an ECP wrapped SAML assertion provided by a keystone Identity Provider (IdP) is used to request an OpenStack unscoped token from a keystone Service Provider (SP). :param base_plugin: Auth plugin already authenticated against the keystone IdP. :type base_plugin: ``keystoneauth.auth.v3.base.BaseAuth`` :param service_provider: The Service Provider ID. :type sp_id: string :param sp_url: URL where the ECP wrapped SAML assertion will be presented to the keystone SP. Usually, something like: https://sp.com/Shibboleth.sso/SAML2/ECP :type sp_url: string :param sp_auth_url: Federated authentication URL of the keystone SP. It is specified by IdP, for example: https://sp.com/v3/OS-FEDERATION/identity_providers/idp_id/protocols/protocol_id/auth :type sp_auth_url: string """""" HTTP_MOVED_TEMPORARILY = 302 REQUEST_ECP_URL = '/auth/OS-FEDERATION/saml2/ecp' ECP_SP_SAML2_REQUEST_HEADERS = {'Content-Type': 'application/vnd.paos+xml'} def __init__(self, base_plugin, service_provider, sp_url, sp_auth_url): super(Keystone2KeystoneAuthPlugin, self).__init__( auth_url=base_plugin.auth_url) self._base_plugin = base_plugin self.sp_id = service_provider self.sp_url = sp_url self.sp_auth_url = sp_auth_url self._sp_response = None @classmethod def load_from_plugin(cls, auth_plugin, service_provider): """"""Class method used to extract the necessary data from the token. The parameters sp_auth_url and sp_url can be obtained from the token in the auth_plugin. """""" service_providers = auth_plugin.service_providers return cls(base_plugin=auth_plugin, service_provider=service_provider, sp_url=service_providers.get_sp_url(service_provider), sp_auth_url=( service_providers.get_auth_url(service_provider))) @classmethod def get_options(cls): # TODO(rodrigods): this is not a regular plugin - it contains another # plugin. So we may use any AuthPlugin to authenticate and then pass # to this one in order to request a token from ta Service Provider. options = super(Keystone2KeystoneAuthPlugin, cls).get_options() options.extend([ cfg.StrOpt('service-provider', help='Service Provider\'s ID'), cfg.StrOpt('sp-url', help='Service Provider\'s URL'), cfg.StrOpt('sp-auth-url', help='Service Provider\'s Authentication URL') ]) return options def _ecp_assertion_request_data(self, session): token_id = self._base_plugin.get_auth_ref(session).auth_token return { ""auth"": { ""identity"": { ""methods"": [ ""token"" ], ""token"": { ""id"": token_id } }, ""scope"": { ""service_provider"": { ""id"": self.sp_id } } } } def get_ecp_assertion(self, session): url = self._base_plugin.auth_url + self.REQUEST_ECP_URL r = session.post(url=url, data=self._ecp_assertion_request_data(session)) if not r.ok: raise Exception('Error while requesting ECP wrapped ' 'assertion, %s' % r) return str(r.text) def _send_service_provider_ecp_authn_response(self, session): """"""Present ECP wrapped SAML assertion to the keystone SP. The assertion is issued by the keystone IdP and it is targeted to the keystone that will serve as Service Provider. :param session: a session object to send out HTTP requests. """""" response = session.post( self.sp_url, headers=self.ECP_SP_SAML2_REQUEST_HEADERS, data=self.get_ecp_assertion(session), authenticated=False, redirect=False) # Don't follow HTTP specs - after the HTTP 302 response don't repeat # the call directed to the Location URL. In this case, this is an # indication that SAML2 session is now active and protected resource # can be accessed. if response.status_code == self.HTTP_MOVED_TEMPORARILY: response = session.request( self.sp_auth_url, 'GET', authenticated=False, headers=self.ECP_SP_SAML2_REQUEST_HEADERS) return response def _get_unscoped_token(self, session): """"""Get unscoped token after authenticating to the Service Provider. Send the ECP wrapped SAML assertion to the keystone SP to get a valid OpenStack unscoped token to be used against the keystone SP. :param session: a session object to send out HTTP requests. """""" if not self._sp_response or self._needs_reauthenticate(): # Store the Service Provider response to prevent re-posting the # ECP wrapped assertion a 2nd time self._sp_response = ( self._send_service_provider_ecp_authn_response(session)) return (self._sp_response.headers['X-Subject-Token'], self._sp_response.json()['token']) def get_auth_ref(self, session, **kwargs): token, token_json = self._get_unscoped_token(session) return access.AccessInfoV3(token, **token_json)",__all__ = ['FederationBaseAuth'],239,1
openstack%2Fswift~master~Ia1aa0bb1f93ee487e2f7ddf76a7a08efa8f3ba41,openstack/swift,master,Ia1aa0bb1f93ee487e2f7ddf76a7a08efa8f3ba41,Add note about updatedb to the docs,MERGED,2015-06-22 12:50:02.000000000,2015-06-24 22:19:15.000000000,2015-06-24 22:19:13.000000000,"[{'_account_id': 3}, {'_account_id': 1179}, {'_account_id': 7479}]","[{'number': 1, 'created': '2015-06-22 12:50:02.000000000', 'files': ['doc/source/deployment_guide.rst'], 'web_link': 'https://opendev.org/openstack/swift/commit/4a5b851207c98a380a32e27a183dd98022be9d16', 'message': 'Add note about updatedb to the docs\n\nChange-Id: Ia1aa0bb1f93ee487e2f7ddf76a7a08efa8f3ba41\n'}]",0,194126,4a5b851207c98a380a32e27a183dd98022be9d16,7,3,1,6968,,,0,"Add note about updatedb to the docs

Change-Id: Ia1aa0bb1f93ee487e2f7ddf76a7a08efa8f3ba41
",git fetch https://review.opendev.org/openstack/swift refs/changes/26/194126/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/source/deployment_guide.rst'],1,4a5b851207c98a380a32e27a183dd98022be9d16,doc-updatedb,"Most current Linux distributions ship with a default installation of updatedb. This tool runs periodically and updates the file name database that is used by the GNU locate tool. However, including Swift object and container database files is most likely not required and the periodic update affects the performance quite a bit. To disable the inclusion of these files add the path where Swift stores its data to the setting PRUNEPATHS in `/etc/updatedb.conf`:: PRUNEPATHS=""... /tmp ... /var/spool ... /srv/node"" ",,10,0
openstack%2Fswift~master~Id461129ef7f5b6412f94d36920c942a4181c0eb7,openstack/swift,master,Id461129ef7f5b6412f94d36920c942a4181c0eb7,Fixed Formatting Error in Swift -Form Post middleware section.,MERGED,2015-06-12 18:13:43.000000000,2015-06-24 22:10:37.000000000,2015-06-24 22:10:35.000000000,"[{'_account_id': 3}, {'_account_id': 2622}, {'_account_id': 6547}, {'_account_id': 6968}, {'_account_id': 7479}, {'_account_id': 12686}, {'_account_id': 14867}, {'_account_id': 16206}]","[{'number': 1, 'created': '2015-06-12 18:13:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/44d417c695ccde6e3222da2c397ac022d3b9f16c', 'message': 'Fixed Formatting Error in Swift -Form Post middleware section.\n\nFixed Formatting error in ``action=SWIFT_URL`` => action=``SWIFT_URL``\n\nChange-Id: Id461129ef7f5b6412f94d36920c942a4181c0eb7\nCloses-Bug: #1464740\n'}, {'number': 2, 'created': '2015-06-24 13:38:21.000000000', 'files': ['doc/source/api/form_post_middleware.rst'], 'web_link': 'https://opendev.org/openstack/swift/commit/514daea6317edc02587f7abfaae8770e1ef9cc4b', 'message': 'Fixed Formatting Error in Swift -Form Post middleware section.\n\nFixed Formatting error in ``action=SWIFT_URL`` => action=``SWIFT_URL``\n\nChange-Id: Id461129ef7f5b6412f94d36920c942a4181c0eb7\nCloses-Bug: #1464740\n'}]",17,191171,514daea6317edc02587f7abfaae8770e1ef9cc4b,16,8,2,14867,,,0,"Fixed Formatting Error in Swift -Form Post middleware section.

Fixed Formatting error in ``action=SWIFT_URL`` => action=``SWIFT_URL``

Change-Id: Id461129ef7f5b6412f94d36920c942a4181c0eb7
Closes-Bug: #1464740
",git fetch https://review.opendev.org/openstack/swift refs/changes/71/191171/2 && git format-patch -1 --stdout FETCH_HEAD,['doc/source/api/form_post_middleware.rst'],1,44d417c695ccde6e3222da2c397ac022d3b9f16c,bug/1464740,"**action=""``SWIFT_URL``""**","**``action=""SWIFT_URL``""**",1,1
openstack%2Fopenstack-ansible~master~Iec55db3b6e20b3661459c639e2a48ff755c001ef,openstack/openstack-ansible,master,Iec55db3b6e20b3661459c639e2a48ff755c001ef,Remove the adiscon/v8 ppa,MERGED,2015-06-23 19:12:51.000000000,2015-06-24 22:09:25.000000000,2015-06-24 22:09:24.000000000,"[{'_account_id': 3}, {'_account_id': 425}, {'_account_id': 6816}, {'_account_id': 12000}, {'_account_id': 12892}, {'_account_id': 14578}]","[{'number': 1, 'created': '2015-06-23 19:12:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/267979679407ec1fa321b378a558917fbd31fed4', 'message': ""Remove the v8 repos because they're not needed\n\nThe v8 repos are on launchpad and launchpad is not stable in terms of general\navailability. These repos can be removed without impacting the stack, we dont\nuse any of the new features in rsyslog that would require us to deal with this\nrepo and the problems that launchpad comes with.\n\nChange-Id: Iec55db3b6e20b3661459c639e2a48ff755c001ef\nCloses-Bug: #1467118\n""}, {'number': 2, 'created': '2015-06-23 21:12:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/f9cc1f72bddf2ff1f1ab1722b838b9e5ee089007', 'message': ""Remove the adiscon/v8 ppa because it's not needed\n\nThe adiscon/v8 ppa are on launchpad and launchpad is not stable in terms of\ngeneral availability. These repos can be removed without impacting the stack,\nwe dont use any of the new features in rsyslog that would require us to deal\nwith this ppa and the problems that launchpad comes with.\n\nChange-Id: Iec55db3b6e20b3661459c639e2a48ff755c001ef\nCloses-Bug: #1467118""}, {'number': 3, 'created': '2015-06-23 21:16:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/be1dd3663cc0b6534d1419e019af969f4608f013', 'message': 'Remove the adiscon/v8 ppa\n\nThe adiscon/v8 ppa has has occasional availability issues which have resulted in failed deployments. This ppa can be removed without impacting the stack as\nthe new features in rsyslog it provides are not used by this project.\n\nChange-Id: Iec55db3b6e20b3661459c639e2a48ff755c001ef\nCloses-Bug: #1467118'}, {'number': 4, 'created': '2015-06-23 21:17:34.000000000', 'files': ['playbooks/roles/rsyslog_client/defaults/main.yml', 'playbooks/roles/rsyslog_client/tasks/rsyslog_client_install.yml', 'playbooks/roles/rsyslog_server/defaults/main.yml', 'playbooks/roles/rsyslog_server/tasks/rsyslog_server_install.yml'], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/54dfd20c833c8ddf87bc899124673dbe387498fd', 'message': 'Remove the adiscon/v8 ppa\n\nThe adiscon/v8 ppa has has occasional availability issues which\nhave resulted in failed deployments. This ppa can be removed\nwithout impacting the stack as the new features in rsyslog it\nprovides are not used by this project.\n\nChange-Id: Iec55db3b6e20b3661459c639e2a48ff755c001ef\nCloses-Bug: #1467118\n'}]",0,194790,54dfd20c833c8ddf87bc899124673dbe387498fd,16,6,4,7353,,,0,"Remove the adiscon/v8 ppa

The adiscon/v8 ppa has has occasional availability issues which
have resulted in failed deployments. This ppa can be removed
without impacting the stack as the new features in rsyslog it
provides are not used by this project.

Change-Id: Iec55db3b6e20b3661459c639e2a48ff755c001ef
Closes-Bug: #1467118
",git fetch https://review.opendev.org/openstack/openstack-ansible refs/changes/90/194790/4 && git format-patch -1 --stdout FETCH_HEAD,"['playbooks/roles/rsyslog_client/defaults/main.yml', 'playbooks/roles/rsyslog_client/tasks/rsyslog_client_install.yml', 'playbooks/roles/rsyslog_server/defaults/main.yml', 'playbooks/roles/rsyslog_server/tasks/rsyslog_server_install.yml']",4,267979679407ec1fa321b378a558917fbd31fed4,bug/1467118, when: rsyslog_server_apt_repos is defined,,6,4
openstack%2Fpuppet-nova~master~Icb701244d5e560ad123c283e54a3c5aa693fc09c,openstack/puppet-nova,master,Icb701244d5e560ad123c283e54a3c5aa693fc09c,Fix Beaker CI according recent puppetlabs-rabbitmq change.,ABANDONED,2015-06-24 21:54:51.000000000,2015-06-24 22:07:31.000000000,,[{'_account_id': 3}],"[{'number': 1, 'created': '2015-06-24 21:54:51.000000000', 'files': ['spec/acceptance/basic_nova_spec.rb'], 'web_link': 'https://opendev.org/openstack/puppet-nova/commit/15557d6a28876645f616be8b976fb942d98a1bcd', 'message': ""Fix Beaker CI according recent puppetlabs-rabbitmq change.\n\nThe puppetlabs-rabbitmq module introduce a new feature related to the\nerlang_cookie parameter change (the database must be wiped if the cookie is\nchanged), the parameter wipe_db_on_cookie_change is configured to false by\ndefault.\n\nBut we're not setting up a rabbitmq cluster and we're not using pacemaker in\nbeaker CI tests, so we just remove the erlang cookie parameter change.\n\nChange-Id: Icb701244d5e560ad123c283e54a3c5aa693fc09c\nCloses-Bug: #1468444\n""}]",0,195334,15557d6a28876645f616be8b976fb942d98a1bcd,3,1,1,7155,,,0,"Fix Beaker CI according recent puppetlabs-rabbitmq change.

The puppetlabs-rabbitmq module introduce a new feature related to the
erlang_cookie parameter change (the database must be wiped if the cookie is
changed), the parameter wipe_db_on_cookie_change is configured to false by
default.

But we're not setting up a rabbitmq cluster and we're not using pacemaker in
beaker CI tests, so we just remove the erlang cookie parameter change.

Change-Id: Icb701244d5e560ad123c283e54a3c5aa693fc09c
Closes-Bug: #1468444
",git fetch https://review.opendev.org/openstack/puppet-nova refs/changes/34/195334/1 && git format-patch -1 --stdout FETCH_HEAD,['spec/acceptance/basic_nova_spec.rb'],1,15557d6a28876645f616be8b976fb942d98a1bcd,bug-1468444,," erlang_cookie => 'secrete',",0,1
openstack%2Fneutron-lbaas~master~Ib8abac4614f2b831ae5911ac4d5c06b3f6fb34f0,openstack/neutron-lbaas,master,Ib8abac4614f2b831ae5911ac4d5c06b3f6fb34f0,Modified tox.ini and post_test_hook.sh,MERGED,2015-06-19 19:43:16.000000000,2015-06-24 22:06:02.000000000,2015-06-24 22:05:59.000000000,"[{'_account_id': 3}, {'_account_id': 6951}, {'_account_id': 7812}, {'_account_id': 9008}, {'_account_id': 9828}, {'_account_id': 10850}, {'_account_id': 10980}, {'_account_id': 11302}, {'_account_id': 11628}, {'_account_id': 12040}, {'_account_id': 14556}]","[{'number': 1, 'created': '2015-06-19 19:43:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-lbaas/commit/7911050fdbe2b8c2fff218561c7dd8327ee363d0', 'message': 'Modified tox.ini\n\nUpdated tox.ini to inlude scenario tests and setting the right tempest.conf\nbefore running the tests\n\nChange-Id: Ib8abac4614f2b831ae5911ac4d5c06b3f6fb34f0\n'}, {'number': 2, 'created': '2015-06-22 22:04:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-lbaas/commit/41d78bb32cdaccc170314530b1f4b194cb09dc09', 'message': 'Modified tox.ini\n\nUpdated tox.ini to inlude scenario tests and setting the right tempest.conf\nbefore running the tests\n\nChange-Id: Ib8abac4614f2b831ae5911ac4d5c06b3f6fb34f0\n'}, {'number': 3, 'created': '2015-06-22 22:06:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-lbaas/commit/e9ccd38fd4ffa94f33123cc571592d983187a597', 'message': 'Modified tox.ini\n\nUpdated tox.ini to inlude scenario tests and setting the right tempest.conf\nbefore running the tests\n\nChange-Id: Ib8abac4614f2b831ae5911ac4d5c06b3f6fb34f0\n'}, {'number': 4, 'created': '2015-06-23 19:25:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-lbaas/commit/4440fa23326d7e6aae707046dc1ea0b5fbe0d8a1', 'message': 'WIP: Testing nodified tox.ini at gate\n\nUpdated tox.ini and post_test_hook.sh about setting the right tempest.conf\nbefore running any tests\n\nChange-Id: Ib8abac4614f2b831ae5911ac4d5c06b3f6fb34f0\n'}, {'number': 5, 'created': '2015-06-23 19:26:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-lbaas/commit/41dae9c777a01a7a735508756d7db5f131f12ae1', 'message': 'WIP: Testing tox.ini and post_test_hook.sh\n\nUpdated tox.ini and post_test_hook.sh about setting the right tempest.conf\nbefore running any tests\n\nChange-Id: Ib8abac4614f2b831ae5911ac4d5c06b3f6fb34f0\n'}, {'number': 6, 'created': '2015-06-23 21:27:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-lbaas/commit/603aac2964b18fdaca4b3370c09db491ebcce872', 'message': 'WIP: Testing tox.ini and post_test_hook.sh\n\nUpdated tox.ini and post_test_hook.sh about setting the right tempest.conf\nbefore running any tests\n\nChange-Id: Ib8abac4614f2b831ae5911ac4d5c06b3f6fb34f0\n'}, {'number': 7, 'created': '2015-06-23 22:17:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-lbaas/commit/b133561a6e1db152e21a67371291f70cc9b90457', 'message': 'WIP: Testing tox.ini and post_test_hook.sh\n\nUpdated tox.ini and post_test_hook.sh about setting the right tempest.conf\nbefore running any tests\n\nChange-Id: Ib8abac4614f2b831ae5911ac4d5c06b3f6fb34f0\n'}, {'number': 8, 'created': '2015-06-23 23:00:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-lbaas/commit/f6d5ed092be465edf7abd7c6581ed9e4b0a2f065', 'message': 'WIP: Testing tox.ini and post_test_hook.sh\n\nUpdated tox.ini and post_test_hook.sh about setting the right tempest.conf\nbefore running any tests\n\nChange-Id: Ib8abac4614f2b831ae5911ac4d5c06b3f6fb34f0\n'}, {'number': 9, 'created': '2015-06-23 23:30:39.000000000', 'files': ['neutron_lbaas/tests/contrib/post_test_hook.sh', 'tox.ini'], 'web_link': 'https://opendev.org/openstack/neutron-lbaas/commit/e89031cd61cec72c4abfd06c4d276eb7f746c164', 'message': 'Modified tox.ini and post_test_hook.sh\n\nUpdated tox.ini and post_test_hook.sh about setting the right tempest.conf\nbefore running any tests\n\nChange-Id: Ib8abac4614f2b831ae5911ac4d5c06b3f6fb34f0\n'}]",4,193706,e89031cd61cec72c4abfd06c4d276eb7f746c164,51,11,9,14556,,,0,"Modified tox.ini and post_test_hook.sh

Updated tox.ini and post_test_hook.sh about setting the right tempest.conf
before running any tests

Change-Id: Ib8abac4614f2b831ae5911ac4d5c06b3f6fb34f0
",git fetch https://review.opendev.org/openstack/neutron-lbaas refs/changes/06/193706/1 && git format-patch -1 --stdout FETCH_HEAD,['tox.ini'],1,7911050fdbe2b8c2fff218561c7dd8327ee363d0,tox.ini/updated,# E265 block comment should start with #  TEMPEST_CONFIG_DIR={env:TEMPEST_CONFIG_DIR:/opt/stack/tempest/etc} TEMPEST_CONFIG_DIR={env:TEMPEST_CONFIG_DIR:/opt/stack/tempest/etc} [testenv:scenario] deps = -r{toxinidir}/requirements.txt -r{toxinidir}/test-requirements.txt sitepackages = True setenv = OS_TEST_PATH={toxinidir}/neutron_lbaas/tests/tempest/v2/scenario OS_TESTR_CONCURRENCY=1 TEMPEST_CONFIG_DIR={env:TEMPEST_CONFIG_DIR:/opt/stack/tempest/etc} ,# E265 block comment should start with #  TEMPEST_CONFIG_DIR={toxinidir}/neutron_lbaas/tests/tempest/etc TEMPEST_CONFIG_DIR={toxinidir}/neutron_lbaas/tests/tempest/etc,14,3
openstack%2Fastara~master~I5004078c6c34e9d62aa6ca78e6f7a2abd6919b0c,openstack/astara,master,I5004078c6c34e9d62aa6ca78e6f7a2abd6919b0c,Drop use of 'oslo' namespace package,MERGED,2015-06-24 20:49:23.000000000,2015-06-24 22:05:22.000000000,2015-06-24 22:05:21.000000000,"[{'_account_id': 3}, {'_account_id': 1420}, {'_account_id': 6287}]","[{'number': 1, 'created': '2015-06-24 20:49:23.000000000', 'files': ['akanda/rug/test/unit/api/test_configuration.py', 'akanda/rug/openstack/common/notifier/api.py', 'akanda/rug/notifications.py', 'akanda/rug/openstack/common/rpc/impl_kombu.py', 'akanda/rug/worker.py', 'akanda/rug/common/linux/interface.py', 'akanda/rug/openstack/common/service.py', 'akanda/rug/api/configuration.py', 'akanda/rug/api/neutron.py', 'akanda/rug/debug.py', 'akanda/rug/main.py', 'akanda/rug/test/unit/common/test_linux_interface.py', 'akanda/rug/vm_manager.py', 'akanda/rug/openstack/common/notifier/log_notifier.py', 'akanda/rug/cli/router.py', 'akanda/rug/openstack/common/log.py', 'akanda/rug/state.py', 'akanda/rug/cli/browse.py', 'akanda/rug/populate.py', 'akanda/rug/api/akanda_client.py', 'akanda/rug/service.py', 'akanda/rug/api/rug.py', 'akanda/rug/openstack/common/eventlet_backdoor.py', 'akanda/rug/openstack/common/rpc/amqp.py', 'akanda/rug/openstack/common/rpc/impl_qpid.py', 'akanda/rug/openstack/common/rpc/common.py', 'akanda/rug/cli/app.py', 'akanda/rug/api/nova.py', 'akanda/rug/openstack/common/rpc/matchmaker.py', 'akanda/rug/openstack/common/rpc/__init__.py', 'akanda/rug/metadata.py', 'akanda/rug/openstack/common/rpc/impl_zmq.py'], 'web_link': 'https://opendev.org/openstack/astara/commit/09eac3eb8519498715e697c284999768aaa22f8c', 'message': ""Drop use of 'oslo' namespace package\n\nThe Oslo libraries have moved all of their code out of the 'oslo'\nnamespace package into per-library packages. The namespace package was\nretained during kilo for backwards compatibility, but will be removed by\nthe liberty-2 milestone. This change removes the use of the namespace\npackage, replacing it with the new package names.\n\nThe patches in the libraries will be put on hold until application\npatches have landed, or L2, whichever comes first. At that point, new\nversions of the libraries without namespace packages will be released as\na major version update.\n\nPlease merge this patch, or an equivalent, before L2 to avoid problems\nwith those library releases.\n\nBlueprint: remove-namespace-packages\nhttps://blueprints.launchpad.net/oslo-incubator/+spec/remove-namespace-packages\n\nChange-Id: I5004078c6c34e9d62aa6ca78e6f7a2abd6919b0c\n""}]",0,195304,09eac3eb8519498715e697c284999768aaa22f8c,7,3,1,2472,,,0,"Drop use of 'oslo' namespace package

The Oslo libraries have moved all of their code out of the 'oslo'
namespace package into per-library packages. The namespace package was
retained during kilo for backwards compatibility, but will be removed by
the liberty-2 milestone. This change removes the use of the namespace
package, replacing it with the new package names.

The patches in the libraries will be put on hold until application
patches have landed, or L2, whichever comes first. At that point, new
versions of the libraries without namespace packages will be released as
a major version update.

Please merge this patch, or an equivalent, before L2 to avoid problems
with those library releases.

Blueprint: remove-namespace-packages
https://blueprints.launchpad.net/oslo-incubator/+spec/remove-namespace-packages

Change-Id: I5004078c6c34e9d62aa6ca78e6f7a2abd6919b0c
",git fetch https://review.opendev.org/openstack/astara refs/changes/04/195304/1 && git format-patch -1 --stdout FETCH_HEAD,"['akanda/rug/test/unit/api/test_configuration.py', 'akanda/rug/openstack/common/notifier/api.py', 'akanda/rug/notifications.py', 'akanda/rug/openstack/common/rpc/impl_kombu.py', 'akanda/rug/worker.py', 'akanda/rug/common/linux/interface.py', 'akanda/rug/openstack/common/service.py', 'akanda/rug/api/configuration.py', 'akanda/rug/api/neutron.py', 'akanda/rug/debug.py', 'akanda/rug/main.py', 'akanda/rug/test/unit/common/test_linux_interface.py', 'akanda/rug/vm_manager.py', 'akanda/rug/openstack/common/notifier/log_notifier.py', 'akanda/rug/cli/router.py', 'akanda/rug/openstack/common/log.py', 'akanda/rug/state.py', 'akanda/rug/cli/browse.py', 'akanda/rug/populate.py', 'akanda/rug/api/akanda_client.py', 'akanda/rug/service.py', 'akanda/rug/api/rug.py', 'akanda/rug/openstack/common/eventlet_backdoor.py', 'akanda/rug/openstack/common/rpc/amqp.py', 'akanda/rug/openstack/common/rpc/impl_qpid.py', 'akanda/rug/openstack/common/rpc/common.py', 'akanda/rug/cli/app.py', 'akanda/rug/api/nova.py', 'akanda/rug/openstack/common/rpc/matchmaker.py', 'akanda/rug/openstack/common/rpc/__init__.py', 'akanda/rug/metadata.py', 'akanda/rug/openstack/common/rpc/impl_zmq.py']",32,09eac3eb8519498715e697c284999768aaa22f8c,bp/remove-namespace-packages,from oslo_config import cfg,from oslo.config import cfg,33,33
openstack%2Fmonasca-agent~master~I68e77f5a4df511e5d61d82f57f8b6b5a0beaca62,openstack/monasca-agent,master,I68e77f5a4df511e5d61d82f57f8b6b5a0beaca62,Update search pattern for Keystone setup plugin,MERGED,2015-06-24 20:47:12.000000000,2015-06-24 22:01:42.000000000,2015-06-24 22:01:41.000000000,"[{'_account_id': 3}, {'_account_id': 11094}, {'_account_id': 13348}]","[{'number': 1, 'created': '2015-06-24 20:47:12.000000000', 'files': ['monasca_setup/detection/plugins/keystone.py'], 'web_link': 'https://opendev.org/openstack/monasca-agent/commit/6b696435b83bd6e69c3fa1d7ba987f13952a574f', 'message': 'Update search pattern for Keystone setup plugin\n\nDevstack (and possibly elsewhere) is using a newer version of keystone,\nv3.4, so the match_pattern generated by the detection plugin (v3.0) was\nfailing.  This patch changes the patter to match any ""v3."" version.\n\nChange-Id: I68e77f5a4df511e5d61d82f57f8b6b5a0beaca62\n'}]",0,195302,6b696435b83bd6e69c3fa1d7ba987f13952a574f,7,3,1,12443,,,0,"Update search pattern for Keystone setup plugin

Devstack (and possibly elsewhere) is using a newer version of keystone,
v3.4, so the match_pattern generated by the detection plugin (v3.0) was
failing.  This patch changes the patter to match any ""v3."" version.

Change-Id: I68e77f5a4df511e5d61d82f57f8b6b5a0beaca62
",git fetch https://review.opendev.org/openstack/monasca-agent refs/changes/02/195302/1 && git format-patch -1 --stdout FETCH_HEAD,['monasca_setup/detection/plugins/keystone.py'],1,6b696435b83bd6e69c3fa1d7ba987f13952a574f,feature/update-keystone-search-pattern, 'search_pattern': '.*v3\..*', 'search_pattern': '.*v3.0.*',1,1
openstack%2Fnova~stable%2Fkilo~Ibb01f5227ded9b79816c064a06a1f6724f765e78,openstack/nova,stable/kilo,Ibb01f5227ded9b79816c064a06a1f6724f765e78,Replace ssh exec calls with paramiko lib,ABANDONED,2015-06-12 20:33:38.000000000,2015-06-24 22:00:53.000000000,,"[{'_account_id': 3}, {'_account_id': 1812}, {'_account_id': 6873}, {'_account_id': 7634}, {'_account_id': 8864}, {'_account_id': 9107}, {'_account_id': 10118}, {'_account_id': 11303}, {'_account_id': 15741}]","[{'number': 1, 'created': '2015-06-12 20:33:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/ddbe2d7ed0850f0fdbd7623ea38c4cdf3c2cbd92', 'message': 'Replace ssh exec calls with paramiko lib\n\nNova already has a dependency on paramiko and therefore should\ntake advantage of it for generating key pairs.  This will reduce\nthe code complexity and remove calls to exec.\n\nChange-Id: Ibb01f5227ded9b79816c064a06a1f6724f765e78\n(cherry picked from commit 3f3f9bf22efd2fb209d2a2fe0246f4857cd2d21a)\n'}, {'number': 2, 'created': '2015-06-12 20:38:04.000000000', 'files': ['nova/crypto.py', 'nova/tests/unit/test_crypto.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/6159f5d149f16ffa7bb96f56521f3ff6ca742186', 'message': 'Replace ssh exec calls with paramiko lib\n\nNova already has a dependency on paramiko and therefore should\ntake advantage of it for generating key pairs.  This will reduce\nthe code complexity and remove calls to exec.\n\nCloses-bug: 1464298\n\n(cherry picked from commit 3f3f9bf22efd2fb209d2a2fe0246f4857cd2d21a)\n\nChange-Id: Ibb01f5227ded9b79816c064a06a1f6724f765e78\n'}]",0,191206,6159f5d149f16ffa7bb96f56521f3ff6ca742186,11,9,2,8119,,,0,"Replace ssh exec calls with paramiko lib

Nova already has a dependency on paramiko and therefore should
take advantage of it for generating key pairs.  This will reduce
the code complexity and remove calls to exec.

Closes-bug: 1464298

(cherry picked from commit 3f3f9bf22efd2fb209d2a2fe0246f4857cd2d21a)

Change-Id: Ibb01f5227ded9b79816c064a06a1f6724f765e78
",git fetch https://review.opendev.org/openstack/nova refs/changes/06/191206/2 && git format-patch -1 --stdout FETCH_HEAD,"['nova/crypto.py', 'nova/tests/unit/test_crypto.py']",2,ddbe2d7ed0850f0fdbd7623ea38c4cdf3c2cbd92,,"import StringIOimport paramiko class KeyPairTest(test.TestCase): rsa_prv = ( ""-----BEGIN RSA PRIVATE KEY-----\n"" ""MIIEowIBAAKCAQEA5G44D6lEgMj6cRwCPydsMl1VRN2B9DVyV5lmwssGeJClywZM\n"" ""WcKlSZBaWPbwbt20/r74eMGZPlqtEi9Ro+EHj4/n5+3A2Mh11h0PGSt53PSPfWwo\n"" ""ZhEg9hQ1w1ZxfBMCx7eG2YdGFQocMgR0zQasJGjjt8hruCnWRB3pNH9DhEwKhgET\n"" ""H0/CFzxSh0eZWs/O4GSf4upwmRG/1Yu90vnVZq3AanwvvW5UBk6g4uWb6FTES867\n"" ""kAy4b5EcH6WR3lLE09omuG/NqtH+qkgIdQconDkmkuK3xf5go6GSwEod0erM1G1v\n"" ""e+C4w/MD98KZ4Zlon9hy7oE2rcqHXf58gZtOTQIDAQABAoIBAQCnkeM2Oemyv7xY\n"" ""dT+ArJ7GY4lFt2i5iOuUL0ge5Wid0R6OTNR9lDhEOszMLno6GhHIPrdvfjW4dDQ5\n"" ""/tRY757oRZzNmq+5V3R52V9WC3qeCBmq3EjWdwJDAphd72/YoOmNMKiPsphKntwI\n"" ""JRS5wodNPlSuYSwEMUypM3f7ttAEn5CASgYgribBDapm7EqkVa2AqSvpFzNvN3/e\n"" ""Sc36/XlxJin7AkKVOnRksuVOOj504VUQfXgVWZkfTeZqAROgA1FSnjUAffcubJmq\n"" ""pDL/JSgOqN4S+sJkkTrb19MuM9M/IdXteloynF+GUKZx6FdVQQc8xCiXgeupeeSD\n"" ""fNMAP7DRAoGBAP0JRFm3fCAavBREKVOyZm20DpeR6zMrVP7ht0SykkT/bw/kiRG+\n"" ""FH1tNioj9uyixt5SiKhH3ZVAunjsKvrwET8i3uz1M2Gk+ovWdLXurBogYNNWafjQ\n"" ""hRhFHpyExoZYRsn58bvYvjFXTO6JxuNS2b59DGBRkQ5mpsOhxarfbZnXAoGBAOcb\n"" ""K+qoPDeDicnQZ8+ygYYHxY3fy1nvm1F19jBiWd26bAUOHeZNPPKGvTSlrGWJgEyA\n"" ""FjZIlHJOY2s0dhukiytOiXzdA5iqK1NvlF+QTUI4tCeNMVejWC+n6sKR9ADZkX8D\n"" ""NOHaLkDzc/ukus59aKyjxP53I6SV6y6m5NeyvDx7AoGAaUji1MXA8wbMvU4DOB0h\n"" ""+4GRFMYVbEwaaJd4jzASJn12M9GuquBBXFMF15DxXFL6lmUXEZYdf83YCRqTY6hi\n"" ""NLgIs+XuxDFGQssv8sdletWAFE9/dpUk3A1eiFfC1wGCKuZCDBxKPvOJQjO3uryt\n"" ""d1JGxQkLZ0eVGg+E1O10iC8CgYB4w2QRfNPqllu8D6EPkVHJfeonltgmKOTajm+V\n"" ""HO+kw7OKeLP7EkVU3j+kcSZC8LUQRKZWu1qG2Jtu+7zz+OmYObPygXNNpS56rQW1\n"" ""Yixc/FB3knpEN2DvlilAfxAoGYjD/CL4GhCtdAoZZx0Opc262OEpr4v6hzSb7i4K\n"" ""4KUoXQKBgHfbiaSilxx9guUqvSaexpHmtiUwx05a05fD6tu8Cofl6AM9wGpw3xOT\n"" ""tfo4ehvS13tTz2RDE2xKuetMmkya7UgifcxUmBzqkOlgr0oOi2rp+eDKXnzUUqsH\n"" ""V7E96Dj36K8q2+gZIXcNqjN7PzfkF8pA0G+E1veTi8j5dnvIsy1x\n"" ""-----END RSA PRIVATE KEY-----\n"" ) rsa_pub = ( ""ssh-rsa AAAAB3NzaC1yc2EAAAADAQABAAABAQDkbjgPqUSAyPpxHAI/J2wyXVVE"" ""3YH0NXJXmWbCywZ4kKXLBkxZwqVJkFpY9vBu3bT+vvh4wZk+Wq0SL1Gj4QePj+fn"" ""7cDYyHXWHQ8ZK3nc9I99bChmESD2FDXDVnF8EwLHt4bZh0YVChwyBHTNBqwkaOO3"" ""yGu4KdZEHek0f0OETAqGARMfT8IXPFKHR5laz87gZJ/i6nCZEb/Vi73S+dVmrcBq"" ""fC+9blQGTqDi5ZvoVMRLzruQDLhvkRwfpZHeUsTT2ia4b82q0f6qSAh1ByicOSaS"" ""4rfF/mCjoZLASh3R6szUbW974LjD8wP3wpnhmWif2HLugTatyodd/nyBm05N Gen"" ""erated-by-Nova"" ) rsa_fp = ""e7:66:a1:2c:4f:90:6e:11:19:da:ac:c2:69:e1:ad:89"" dss_pub = ( ""ssh-dss AAAAB3NzaC1kc3MAAACBAKWFW2++pDxJWObkADbSXw8KfZ4VupkRKEXF"" ""SPN2kV0v+FgdnBEcrEJPExaOTMhmxIuc82ktTv76wHSEpbbsLuI7IDbB6KJJwHs2"" ""y356yB28Q9rin7X0VMYKkPxvAcbIUSrEbQtyPMihlOaaQ2dGSsEQGQSpjm3f3RU6"" ""OWux0w/NAAAAFQCgzWF2zxQmi/Obd11z9Im6gY02gwAAAIAHCDLjipVwMLXIqNKO"" ""MktiPex+ewRQxBi80dzZ3mJzARqzLPYI9hJFUU0LiMtLuypV/djpUWN0cQpmgTQf"" ""TfuZx9ipC6Mtiz66NQqjkQuoihzdk+9KlOTo03UsX5uBGwuZ09Dnf1VTF8ZsW5Hg"" ""HyOk6qD71QBajkcFJAKOT3rFfgAAAIAy8trIzqEps9/n37Nli1TvNPLbFQAXl1LN"" ""wUFmFDwBCGTLl8puVZv7VSu1FG8ko+mzqNebqcN4RMC26NxJqe+RRubn5KtmLoIa"" ""7tRe74hvQ1HTLLuGxugwa4CewNbwzzEDEs8U79WDhGKzDkJR4nLPVimj5WLAWV70"" ""RNnRX7zj5w== Generated-by-Nova"" ) dss_fp = ""b9:dc:ac:57:df:2a:2b:cf:65:a8:c3:4e:9d:4a:82:3c"" ecdsa_pub = ( ""ecdsa-sha2-nistp256 AAAAE2VjZHNhLXNoYTItbmlzdHAyNTYAAAAIbmlzdHAy"" ""NTYAAABBBG1r4wzPTIjSo78POCq+u/czb8gYK0KvqlmCvcRPrnDWxgLw7y6BX51t"" ""uYREz7iLRCP7BwUt8R+ZWzFZDeOLIWU= Generated-by-Nova"" ) ecdsa_fp = ""16:6a:c9:ec:80:4d:17:3e:d5:3b:6f:c0:d7:15:04:40"" def test_generate_fingerprint(self): fingerprint = crypto.generate_fingerprint(self.rsa_pub) self.assertEqual(self.rsa_fp, fingerprint) fingerprint = crypto.generate_fingerprint(self.dss_pub) self.assertEqual(self.dss_fp, fingerprint) fingerprint = crypto.generate_fingerprint(self.ecdsa_pub) self.assertEqual(self.ecdsa_fp, fingerprint) def test_generate_key_pair(self): (private_key, public_key, fingerprint) = crypto.generate_key_pair() raw_pub = public_key.split(' ')[1].decode('base64') pkey = paramiko.rsakey.RSAKey(None, raw_pub) self.assertEqual(2048, pkey.get_bits()) bits = 4096 (private_key, public_key, fingerprint) = crypto.generate_key_pair(bits) raw_pub = public_key.split(' ')[1].decode('base64') pkey = paramiko.rsakey.RSAKey(None, raw_pub) self.assertEqual(bits, pkey.get_bits()) keyin = StringIO.StringIO() keyin.write(self.rsa_prv) keyin.seek(0) key = paramiko.RSAKey.from_private_key(keyin) with mock.patch.object(paramiko.RSAKey, 'generate') as mock_generate: mock_generate.return_value = key (private_key, public_key, fingerprint) = crypto.generate_key_pair() self.assertEqual(self.rsa_pub, public_key) self.assertEqual(self.rsa_fp, fingerprint)",,130,33
openstack%2Fkolla~master~I869aa9f117c6fa959b1c6948dfc379f30a6bc1d7,openstack/kolla,master,I869aa9f117c6fa959b1c6948dfc379f30a6bc1d7,Fixes MariaDB to support Heat,MERGED,2015-06-15 23:10:37.000000000,2015-06-24 21:49:34.000000000,2015-06-24 21:49:34.000000000,"[{'_account_id': 3}, {'_account_id': 2834}, {'_account_id': 3098}, {'_account_id': 6836}, {'_account_id': 10428}]","[{'number': 1, 'created': '2015-06-15 23:10:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla/commit/ee084755629d55b65513f14e3bd7bf5a407345de', 'message': 'Fixes MariaDB to Support Heat\n\nWhen spawning Heat stacks, the DB reaches the max_connections\nlimit. This causes MariaDB to block all traffic by source IP,\nessentially blocking all services. This patch introduces the\nMARIADB_MAX_CONNECTIONS parameter to make the max_connections\nconfigurable. The default of 151 max_connections is maintained.\n\nCloses-Bug: #1465422\n\nChange-Id: I869aa9f117c6fa959b1c6948dfc379f30a6bc1d7\n'}, {'number': 2, 'created': '2015-06-17 17:00:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla/commit/fed3f4943c9235a46320441c947408daf7526c36', 'message': 'Fixes MariaDB to Support Heat\n\nWhen spawning Heat stacks, the DB reaches the max_connections\nlimit. This causes MariaDB to block all traffic by source IP,\nessentially blocking all services. This patch introduces the\nMARIADB_MAX_CONNECTIONS parameter to make the max_connections\nconfigurable. The default of 151 max_connections is maintained.\n\nCloses-Bug: #1465422\n\nChange-Id: I869aa9f117c6fa959b1c6948dfc379f30a6bc1d7\n'}, {'number': 3, 'created': '2015-06-24 16:47:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla/commit/63bec3ab3499a4735dd02eef5a42d7a35274eea6', 'message': 'Fixes MariaDB to Support Heat\n\nWhen spawning Heat stacks, the DB reaches the max_connections\nlimit. This causes MariaDB to block all traffic by source IP,\nessentially blocking all services. This patch introduces the\nMARIADB_MAX_CONNECTIONS parameter to make the max_connections\nconfigurable. The default of 151 max_connections is maintained.\n\nCloses-Bug: #1465422\n\nChange-Id: I869aa9f117c6fa959b1c6948dfc379f30a6bc1d7\n'}, {'number': 4, 'created': '2015-06-24 17:40:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla/commit/93b7acbc9a68f4a597c946c189c2a4c7b3754e0b', 'message': 'Fixes MariaDB to Support Heat\n\nWhen spawning Heat stacks, the DB reaches the max_connections\nlimit. This causes MariaDB to block all traffic by source IP,\nessentially blocking all services. This patch introduces the\nMARIADB_MAX_CONNECTIONS parameter to make the max_connections\nconfigurable. The default of 151 max_connections is maintained.\n\nCloses-Bug: #1465422\n\nChange-Id: I869aa9f117c6fa959b1c6948dfc379f30a6bc1d7\n'}, {'number': 5, 'created': '2015-06-24 20:00:19.000000000', 'files': ['tools/genenv', 'docker/common/mariadb-app/config-mysql.sh', 'docs/integration-guide.md'], 'web_link': 'https://opendev.org/openstack/kolla/commit/4a4cf92eb9c00f54b6e9f916070fe82454ae86c2', 'message': 'Fixes MariaDB to support Heat\n\nWhen spawning Heat stacks, the DB reaches the max_connections\nlimit. This causes MariaDB to block all traffic by source IP,\nessentially blocking all services. This patch introduces the\nMARIADB_MAX_CONNECTIONS parameter to make the max_connections\nconfigurable. The default of 151 max_connections is maintained.\n\nCloses-Bug: #1465422\n\nChange-Id: I869aa9f117c6fa959b1c6948dfc379f30a6bc1d7\n'}]",8,192011,4a4cf92eb9c00f54b6e9f916070fe82454ae86c2,26,5,5,6836,,,0,"Fixes MariaDB to support Heat

When spawning Heat stacks, the DB reaches the max_connections
limit. This causes MariaDB to block all traffic by source IP,
essentially blocking all services. This patch introduces the
MARIADB_MAX_CONNECTIONS parameter to make the max_connections
configurable. The default of 151 max_connections is maintained.

Closes-Bug: #1465422

Change-Id: I869aa9f117c6fa959b1c6948dfc379f30a6bc1d7
",git fetch https://review.opendev.org/openstack/kolla refs/changes/11/192011/1 && git format-patch -1 --stdout FETCH_HEAD,"['tools/genenv', 'docker/centos/binary/mariadb-app/config-mysql.sh', 'docs/integration-guide.md']",3,ee084755629d55b65513f14e3bd7bf5a407345de,bug/1465422, MARIADB_MAX_CONNECTIONS=<151> - The maximum number of connections to the MariaDB server,,4,0
openstack%2Frally~master~Id8d03249175006c13caea07a0b27effd893b79b4,openstack/rally,master,Id8d03249175006c13caea07a0b27effd893b79b4,Updated from global requirements,ABANDONED,2015-06-24 20:45:01.000000000,2015-06-24 21:43:25.000000000,,"[{'_account_id': 3}, {'_account_id': 14817}]","[{'number': 1, 'created': '2015-06-24 20:45:01.000000000', 'files': ['requirements.txt', 'test-requirements.txt', 'setup.py'], 'web_link': 'https://opendev.org/openstack/rally/commit/5349ca3c774ccd3bf5475007f9a6b73c1db8ac54', 'message': 'Updated from global requirements\n\nChange-Id: Id8d03249175006c13caea07a0b27effd893b79b4\n'}]",0,195301,5349ca3c774ccd3bf5475007f9a6b73c1db8ac54,4,2,1,11131,,,0,"Updated from global requirements

Change-Id: Id8d03249175006c13caea07a0b27effd893b79b4
",git fetch https://review.opendev.org/openstack/rally refs/changes/01/195301/1 && git format-patch -1 --stdout FETCH_HEAD,"['requirements.txt', 'test-requirements.txt', 'setup.py']",3,5349ca3c774ccd3bf5475007f9a6b73c1db8ac54,openstack/requirements,,#!/usr/bin/env python#,21,22
openstack%2Foslo.vmware~master~I6a61d719f692a104e86793925cf3dda569a2eead,openstack/oslo.vmware,master,I6a61d719f692a104e86793925cf3dda569a2eead,Updated from global requirements,MERGED,2015-06-24 14:45:49.000000000,2015-06-24 21:38:11.000000000,2015-06-24 21:38:10.000000000,"[{'_account_id': 3}, {'_account_id': 5638}, {'_account_id': 9008}]","[{'number': 1, 'created': '2015-06-24 14:45:49.000000000', 'files': ['requirements.txt'], 'web_link': 'https://opendev.org/openstack/oslo.vmware/commit/bbf6d0cc694ef891f91579a0cbb314acb98b080d', 'message': 'Updated from global requirements\n\nChange-Id: I6a61d719f692a104e86793925cf3dda569a2eead\n'}]",0,195121,bbf6d0cc694ef891f91579a0cbb314acb98b080d,7,3,1,11131,,,0,"Updated from global requirements

Change-Id: I6a61d719f692a104e86793925cf3dda569a2eead
",git fetch https://review.opendev.org/openstack/oslo.vmware refs/changes/21/195121/1 && git format-patch -1 --stdout FETCH_HEAD,['requirements.txt'],1,bbf6d0cc694ef891f91579a0cbb314acb98b080d,openstack/requirements,oslo.concurrency>=2.1.0 # Apache-2.0,oslo.concurrency>=2.0.0 # Apache-2.0,1,1
openstack%2Ffuturist~master~Ia909f2ed844a2ba39d4f73b1e6b349d950f6426a,openstack/futurist,master,Ia909f2ed844a2ba39d4f73b1e6b349d950f6426a,Add history.rst that uses generated 'ChangeLog' file,MERGED,2015-06-23 23:07:52.000000000,2015-06-24 21:35:48.000000000,2015-06-24 21:35:47.000000000,"[{'_account_id': 3}, {'_account_id': 5638}]","[{'number': 1, 'created': '2015-06-23 23:07:52.000000000', 'files': ['doc/source/index.rst', 'doc/source/history.rst'], 'web_link': 'https://opendev.org/openstack/futurist/commit/13b607785d5ba5e5babd10ba3951a77c24c15617', 'message': ""Add history.rst that uses generated 'ChangeLog' file\n\nChange-Id: Ia909f2ed844a2ba39d4f73b1e6b349d950f6426a\n""}]",0,194857,13b607785d5ba5e5babd10ba3951a77c24c15617,7,2,1,1297,,,0,"Add history.rst that uses generated 'ChangeLog' file

Change-Id: Ia909f2ed844a2ba39d4f73b1e6b349d950f6426a
",git fetch https://review.opendev.org/openstack/futurist refs/changes/57/194857/1 && git format-patch -1 --stdout FETCH_HEAD,"['doc/source/index.rst', 'doc/source/history.rst']",2,13b607785d5ba5e5babd10ba3951a77c24c15617,,.. include:: ../../ChangeLog ,,10,0
openstack%2Fmagnum~master~If58f14db7d7f5e46a797e841fbc36c4b010f1df8,openstack/magnum,master,If58f14db7d7f5e46a797e841fbc36c4b010f1df8,Updated from global requirements,MERGED,2015-06-24 14:39:55.000000000,2015-06-24 21:32:47.000000000,2015-06-24 21:32:46.000000000,"[{'_account_id': 3}, {'_account_id': 5638}, {'_account_id': 11536}, {'_account_id': 11650}]","[{'number': 1, 'created': '2015-06-24 14:39:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/magnum/commit/b591e92f986a8fe43fa6105e2101fc8f62ee4130', 'message': 'Updated from global requirements\n\nChange-Id: If58f14db7d7f5e46a797e841fbc36c4b010f1df8\n'}, {'number': 2, 'created': '2015-06-24 20:38:19.000000000', 'files': ['requirements.txt'], 'web_link': 'https://opendev.org/openstack/magnum/commit/deb2ce693b5c5425ef33b16723c975f9fc43901e', 'message': 'Updated from global requirements\n\nChange-Id: If58f14db7d7f5e46a797e841fbc36c4b010f1df8\n'}]",0,195113,deb2ce693b5c5425ef33b16723c975f9fc43901e,10,4,2,11131,,,0,"Updated from global requirements

Change-Id: If58f14db7d7f5e46a797e841fbc36c4b010f1df8
",git fetch https://review.opendev.org/openstack/magnum refs/changes/13/195113/2 && git format-patch -1 --stdout FETCH_HEAD,['requirements.txt'],1,b591e92f986a8fe43fa6105e2101fc8f62ee4130,openstack/requirements,oslo.concurrency>=2.1.0 # Apache-2.0,oslo.concurrency>=2.0.0 # Apache-2.0,1,1
openstack%2Fnova~master~I3623e60c49e442e2431cf017540422aa59bc285a,openstack/nova,master,I3623e60c49e442e2431cf017540422aa59bc285a,Ensure to store context in thread local after spawn/spawn_n,MERGED,2015-05-14 18:10:37.000000000,2015-06-24 21:28:35.000000000,2015-06-15 19:49:59.000000000,"[{'_account_id': 3}, {'_account_id': 4690}, {'_account_id': 5170}, {'_account_id': 5441}, {'_account_id': 6062}, {'_account_id': 6873}, {'_account_id': 8300}, {'_account_id': 8574}, {'_account_id': 8871}, {'_account_id': 9008}, {'_account_id': 9578}, {'_account_id': 10118}, {'_account_id': 12994}, {'_account_id': 15286}, {'_account_id': 15751}]","[{'number': 1, 'created': '2015-05-14 18:10:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/012874bd5f5147b29dabb1ed84157986a58a8aef', 'message': 'Ensure to store context in thread local after spawn/spawn_n\n\nhttps://review.openstack.org/#/c/171299/ introduces a wrapper for utils.spawn_n\nto update context in thread local store. However, there are other routines in\ndriver code which calls greenthread.spawn or greenthread.spawn_n, so that they\nwill not update context in thread local store. The commit adds utils.spawn as a\nnew wrapper, and also make those codes call spawn/spawn_n of utils, in order to\nensure the context of logging is correct.\n\nChange-Id: I3623e60c49e442e2431cf017540422aa59bc285a\nRelated-Bug: 1404268\n'}, {'number': 2, 'created': '2015-06-03 14:44:08.000000000', 'files': ['nova/virt/libvirt/driver.py', 'nova/tests/unit/test_utils.py', 'nova/virt/vmwareapi/io_util.py', 'nova/utils.py', 'nova/tests/unit/virt/libvirt/test_driver.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/7f293ec49ce87ec022798003470f5903dae603fa', 'message': 'Ensure to store context in thread local after spawn/spawn_n\n\nhttps://review.openstack.org/#/c/171299/ introduces a wrapper for utils.spawn_n\nto update context in thread local store. However, there are other routines in\ndriver code which calls greenthread.spawn or greenthread.spawn_n, so that they\nwill not update context in thread local store. The commit adds utils.spawn as a\nnew wrapper, and also make those codes call spawn/spawn_n of utils, in order to\nensure the context of logging is correct.\n\nChange-Id: I3623e60c49e442e2431cf017540422aa59bc285a\nRelated-Bug: 1404268\n'}]",0,183144,7f293ec49ce87ec022798003470f5903dae603fa,33,15,2,8574,,,0,"Ensure to store context in thread local after spawn/spawn_n

https://review.openstack.org/#/c/171299/ introduces a wrapper for utils.spawn_n
to update context in thread local store. However, there are other routines in
driver code which calls greenthread.spawn or greenthread.spawn_n, so that they
will not update context in thread local store. The commit adds utils.spawn as a
new wrapper, and also make those codes call spawn/spawn_n of utils, in order to
ensure the context of logging is correct.

Change-Id: I3623e60c49e442e2431cf017540422aa59bc285a
Related-Bug: 1404268
",git fetch https://review.opendev.org/openstack/nova refs/changes/44/183144/1 && git format-patch -1 --stdout FETCH_HEAD,"['nova/virt/libvirt/driver.py', 'nova/tests/unit/test_utils.py', 'nova/virt/vmwareapi/io_util.py', 'nova/utils.py', 'nova/tests/unit/virt/libvirt/test_driver.py']",5,012874bd5f5147b29dabb1ed84157986a58a8aef,bug/1404268," @mock.patch.object(utils, ""spawn"") @mock.patch.object(utils, ""spawn"") @mock.patch.object(utils, ""spawn"")"," @mock.patch.object(greenthread, ""spawn"") @mock.patch.object(greenthread, ""spawn"") @mock.patch.object(greenthread, ""spawn"")",44,13
openstack%2Fkolla~master~I70e3807be32c9a07346d316e7856421ecf468b9a,openstack/kolla,master,I70e3807be32c9a07346d316e7856421ecf468b9a,Add openvswitch container,MERGED,2015-06-14 00:16:48.000000000,2015-06-24 21:16:50.000000000,2015-06-24 21:16:50.000000000,"[{'_account_id': 3}, {'_account_id': 1390}, {'_account_id': 2834}, {'_account_id': 3098}, {'_account_id': 10428}, {'_account_id': 14119}]","[{'number': 1, 'created': '2015-06-14 00:16:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla/commit/60a186ff4037642844d5d56e2e073eb92a60f5ff', 'message': 'Add openvswitch contianer\n\nAdd openvswitch contianer, seperate openvswitch to:\n1) ovs-base\n2) ovs-dvserver-data, include the db info\n3) ovs-dbserver\n4) ovs-vswitchd\n\nit will bind the /run volume on the host.\n\nPartially Implements blueprint: openvswitch-container\n\nChange-Id: I70e3807be32c9a07346d316e7856421ecf468b9a\n'}, {'number': 2, 'created': '2015-06-14 00:35:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla/commit/cda0c2ad6ad6c5e9e168ab64fc3e93f6b8d37889', 'message': 'Add openvswitch contianer\n\nAdd openvswitch contianer, seperate openvswitch to:\n1) ovs-base\n2) ovs-dvserver-data, include the db info\n3) ovs-dbserver\n4) ovs-vswitchd\n\nit will bind the /run volume on the host.\n\nPartially Implements blueprint: openvswitch-container\n\nChange-Id: I70e3807be32c9a07346d316e7856421ecf468b9a\n'}, {'number': 3, 'created': '2015-06-15 06:13:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla/commit/2fc98950dcdc1a0fe9d9c5015e8b388e7ce41a76', 'message': 'Add openvswitch container\n\nAdd openvswitch containers. Openvswitch is seperated into two running\ncontainers:\n  ovs-db-server\n  ovs-vswitchd\n\nThe db container is what everything interacts with. Neutron tells the db\nits information, the vswitchd container reads this db and talks to the\nkernel module.\n\nThe db does not need to be persistent since the plugin agent will\nrepopulate all the information each time it is restarted and the plugin\nagent is required to be restarted when the ovs-vswitchd container is\nstopped/started to ensure the ports are setup properly.\n\nThis container requires /run for the socket and /lib/modules:ro to load\nthe appropriate host kernel module.\n\nThis userspace tools and the kernel module do _not_ have to match\nversions. Additionally, even though it is recommended that the userspace\ntool be newer than the kernel version to take advantage of all the\nfeatures, it is not required.\n\nPartially Implements blueprint: openvswitch-container\n\nCo-Authored-By: Sam Yaple <sam@yaple.net>\n\nChange-Id: I70e3807be32c9a07346d316e7856421ecf468b9a\n'}, {'number': 4, 'created': '2015-06-20 08:23:23.000000000', 'files': ['docker/centos/binary/openvswitch/ovs-base/Dockerfile', 'docker/centos/binary/openvswitch/ovs-vswitchd/build', 'docker/common/openvswitch/ovs-vswitchd/start.sh', 'docker/common/openvswitch/ovs-db-server/start.sh', 'docker/centos/binary/openvswitch/ovs-vswitchd/Dockerfile', 'docker/centos/binary/openvswitch/ovs-vswitchd/start.sh', 'docker/centos/binary/openvswitch/ovs-db-server/Dockerfile', 'docker/centos/binary/openvswitch/ovs-base/build', 'docker/centos/binary/openvswitch/ovs-db-server/start.sh', 'docker/centos/binary/openvswitch/ovs-db-server/build'], 'web_link': 'https://opendev.org/openstack/kolla/commit/0971e7eed66a252861b2a4617c4f82edcd838902', 'message': 'Add openvswitch container\n\nAdd openvswitch containers. Openvswitch is seperated into two running\ncontainers:\n  ovs-db-server\n  ovs-vswitchd\n\nThe db container is what everything interacts with. Neutron tells the db\nits information, the vswitchd container reads this db and talks to the\nkernel module.\n\nThe db does not need to be persistent since the plugin agent will\nrepopulate all the information each time it is restarted and the plugin\nagent is required to be restarted when the ovs-vswitchd container is\nstopped/started to ensure the ports are setup properly.\n\nThis container requires /run for the socket and /lib/modules:ro to load\nthe appropriate host kernel module.\n\nThis userspace tools and the kernel module do _not_ have to match\nversions. Additionally, even though it is recommended that the userspace\ntool be newer than the kernel version to take advantage of all the\nfeatures, it is not required.\n\nPartially Implements blueprint: openvswitch-container\n\nCo-Authored-By: Sam Yaple <sam@yaple.net>\n\nChange-Id: I70e3807be32c9a07346d316e7856421ecf468b9a\n'}]",12,191532,0971e7eed66a252861b2a4617c4f82edcd838902,16,6,4,15697,,,0,"Add openvswitch container

Add openvswitch containers. Openvswitch is seperated into two running
containers:
  ovs-db-server
  ovs-vswitchd

The db container is what everything interacts with. Neutron tells the db
its information, the vswitchd container reads this db and talks to the
kernel module.

The db does not need to be persistent since the plugin agent will
repopulate all the information each time it is restarted and the plugin
agent is required to be restarted when the ovs-vswitchd container is
stopped/started to ensure the ports are setup properly.

This container requires /run for the socket and /lib/modules:ro to load
the appropriate host kernel module.

This userspace tools and the kernel module do _not_ have to match
versions. Additionally, even though it is recommended that the userspace
tool be newer than the kernel version to take advantage of all the
features, it is not required.

Partially Implements blueprint: openvswitch-container

Co-Authored-By: Sam Yaple <sam@yaple.net>

Change-Id: I70e3807be32c9a07346d316e7856421ecf468b9a
",git fetch https://review.opendev.org/openstack/kolla refs/changes/32/191532/4 && git format-patch -1 --stdout FETCH_HEAD,"['docker/centos/binary/neutron/neutron-agents/openvswitch/ovs-base/Dockerfile', 'docker/centos/binary/neutron/neutron-agents/openvswitch/ovs-dbserver/build', 'docker/centos/binary/neutron/neutron-agents/openvswitch/ovs-dbserver-data/Dockerfile', 'docker/centos/binary/neutron/neutron-agents/openvswitch/ovs-base/build', 'docker/centos/binary/neutron/neutron-agents/openvswitch/ovs-dbserver/start.sh', 'docker/centos/binary/neutron/neutron-agents/openvswitch/ovs-vswitchd/start.sh', 'docker/centos/binary/neutron/neutron-agents/openvswitch/ovs-dbserver/Dockerfile', 'docker/centos/binary/neutron/neutron-agents/openvswitch/ovs-dbserver-data/build', 'docker/centos/binary/neutron/neutron-agents/openvswitch/ovs-vswitchd/build', 'docker/centos/binary/neutron/neutron-agents/openvswitch/ovs-vswitchd/Dockerfile']",10,60a186ff4037642844d5d56e2e073eb92a60f5ff,bp/openvswitch-container,"FROM %%KOLLA_NAMESPACE%%/%%KOLLA_PREFIX%%ovs-base:%%KOLLA_TAG%% MAINTAINER Kolla Project (https://launchpad.net/kolla) COPY ./start.sh /start.sh CMD [""/start.sh""] ",,677,0
openstack%2Frally~master~Ife538fcbdf3d4c8e8e079f6ceec1111c2f0ee0ec,openstack/rally,master,Ife538fcbdf3d4c8e8e079f6ceec1111c2f0ee0ec,Optimize task table order,MERGED,2015-06-23 08:25:16.000000000,2015-06-24 21:14:49.000000000,2015-06-24 21:14:47.000000000,"[{'_account_id': 3}, {'_account_id': 6172}, {'_account_id': 9545}, {'_account_id': 14817}]","[{'number': 1, 'created': '2015-06-23 08:25:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/25f629963cda2b62ff13eb4fa168fa185432a296', 'message': ""Optimize task table order\n\nOld style brings two wrong order case:\n    [1] http://paste.openstack.org/show/315958/ ('total' should be the\n    last one)\n    [2] http://paste.openstack.org/show/315986/ ('delete_user' should be\n    behind 'update_user_enabled')\n\nThis patch use OrderedDict instead of normal Dict in function\nget_atomic_actions_data and disable sort in print_list. Both these\nchanges keep the order from atomic actions correct and the 'total' last\none.\n\nChange-Id: Ife538fcbdf3d4c8e8e079f6ceec1111c2f0ee0ec\n""}, {'number': 2, 'created': '2015-06-23 08:27:30.000000000', 'files': ['rally/benchmark/processing/utils.py', 'rally/cli/commands/task.py'], 'web_link': 'https://opendev.org/openstack/rally/commit/7b82ecfafa626ea87aaf5dcc7ec324e3f3bf80cb', 'message': ""Optimize task table order\n\nOld style brings two wrong order case:\n\n[1] http://paste.openstack.org/show/315958/\n    ('total' should be the last one)\n[2] http://paste.openstack.org/show/315986/\n    ('delete_user' should be behind 'update_user_enabled')\n\nThis patch use OrderedDict instead of normal Dict in function\nget_atomic_actions_data and disable sort in print_list. Both these\nchanges keep the order from atomic actions correct and the 'total' last\none.\n\nChange-Id: Ife538fcbdf3d4c8e8e079f6ceec1111c2f0ee0ec\n""}]",0,194537,7b82ecfafa626ea87aaf5dcc7ec324e3f3bf80cb,10,4,2,6835,,,0,"Optimize task table order

Old style brings two wrong order case:

[1] http://paste.openstack.org/show/315958/
    ('total' should be the last one)
[2] http://paste.openstack.org/show/315986/
    ('delete_user' should be behind 'update_user_enabled')

This patch use OrderedDict instead of normal Dict in function
get_atomic_actions_data and disable sort in print_list. Both these
changes keep the order from atomic actions correct and the 'total' last
one.

Change-Id: Ife538fcbdf3d4c8e8e079f6ceec1111c2f0ee0ec
",git fetch https://review.opendev.org/openstack/rally refs/changes/37/194537/1 && git format-patch -1 --stdout FETCH_HEAD,"['rally/benchmark/processing/utils.py', 'rally/cli/commands/task.py']",2,25f629963cda2b62ff13eb4fa168fa185432a296,," table_label=""Response Times (sec)"", sortby_index=None)"," table_label=""Response Times (sec)"")",5,2
openstack%2Foslo.versionedobjects~master~Ie56b94e57a6e18292c10c926836592938540e515,openstack/oslo.versionedobjects,master,Ie56b94e57a6e18292c10c926836592938540e515,fields: allow subclasses in ObjectField/ListOfObjectsField,MERGED,2015-06-18 16:36:16.000000000,2015-06-24 21:11:17.000000000,2015-06-24 21:11:16.000000000,"[{'_account_id': 3}, {'_account_id': 1779}, {'_account_id': 4393}, {'_account_id': 5638}, {'_account_id': 8127}]","[{'number': 1, 'created': '2015-06-18 16:36:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.versionedobjects/commit/c3a0bc31638c28d981a1a998a41e03bcbdbd89b5', 'message': ""fields: allow subclasses in ObjectField/ListOfObjectsField\n\nThe Object class currently does a direct comparison of the\n'obj_name()' value of the thing being coerced, against the\ninternal _obj_name field it was initialized with.\n\nThis does not allow for creation of object fields which\nallow arbitrary subclasses - only the base class passes\nthe check.\n\nIntroduce a new 'allow_subclasses' parameter, defaulting\nto False, which traverses the python class hierarchy,\nchecking the obj_name() value on all parent classes\nof the value being coerced.\n\nChange-Id: Ie56b94e57a6e18292c10c926836592938540e515\n""}, {'number': 2, 'created': '2015-06-23 13:47:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.versionedobjects/commit/7718b9db981ecaa6127cd62a12d4ac2e76a190a5', 'message': ""fields: allow subclasses in ObjectField/ListOfObjectsField\n\nThe Object class currently does a direct comparison of the\n'obj_name()' value of the thing being coerced, against the\ninternal _obj_name field it was initialized with.\n\nThis does not allow for creation of object fields which\nallow arbitrary subclasses - only the base class passes\nthe check.\n\nIntroduce a new 'allow_subclasses' parameter, defaulting\nto False, which traverses the python class hierarchy,\nchecking the obj_name() value on all parent classes\nof the value being coerced.\n\nChange-Id: Ie56b94e57a6e18292c10c926836592938540e515\n""}, {'number': 3, 'created': '2015-06-23 13:58:44.000000000', 'files': ['oslo_versionedobjects/tests/test_fields.py', 'oslo_versionedobjects/fields.py'], 'web_link': 'https://opendev.org/openstack/oslo.versionedobjects/commit/28e2b4f004138ef49d4e88c7adf484a1634ad328', 'message': ""fields: allow subclasses in ObjectField/ListOfObjectsField\n\nThe Object class currently does a direct comparison of the\n'obj_name()' value of the thing being coerced, against the\ninternal _obj_name field it was initialized with.\n\nThis does not allow for creation of object fields which\nallow arbitrary subclasses - only the base class passes\nthe check.\n\nIntroduce a new 'subclasses' parameter, defaulting to\nFalse, which traverses the python class hierarchy,\nchecking the obj_name() value on all parent classes\nof the value being coerced.\n\nChange-Id: Ie56b94e57a6e18292c10c926836592938540e515\n""}]",5,193204,28e2b4f004138ef49d4e88c7adf484a1634ad328,15,5,3,1779,,,0,"fields: allow subclasses in ObjectField/ListOfObjectsField

The Object class currently does a direct comparison of the
'obj_name()' value of the thing being coerced, against the
internal _obj_name field it was initialized with.

This does not allow for creation of object fields which
allow arbitrary subclasses - only the base class passes
the check.

Introduce a new 'subclasses' parameter, defaulting to
False, which traverses the python class hierarchy,
checking the obj_name() value on all parent classes
of the value being coerced.

Change-Id: Ie56b94e57a6e18292c10c926836592938540e515
",git fetch https://review.opendev.org/openstack/oslo.versionedobjects refs/changes/04/193204/3 && git format-patch -1 --stdout FETCH_HEAD,['oslo_versionedobjects/fields.py'],1,c3a0bc31638c28d981a1a998a41e03bcbdbd89b5,devsupport," def __init__(self, obj_name, allow_subclasses=False, **kwargs): self._allow_subclasses = allow_subclasses @staticmethod def _get_obj_names(klass): if not hasattr(klass, ""obj_name""): return [] obj_names = [klass.obj_name()] for parent in klass.__bases__: obj_names.extend(Object._get_obj_names(parent)) return obj_names if self._allow_subclasses: obj_names = self._get_obj_names(value.__class__) else: obj_names = [obj_name] if self._obj_name not in obj_names: def __init__(self, objtype, allow_subclasses=False, **kwargs): self.AUTO_TYPE = Object(objtype, allow_subclasses) def __init__(self, objtype, allow_subclasses=False, **kwargs): self.AUTO_TYPE = List(Object(objtype, allow_subclasses))"," def __init__(self, obj_name, **kwargs): if obj_name != self._obj_name: def __init__(self, objtype, **kwargs): self.AUTO_TYPE = Object(objtype) def __init__(self, objtype, **kwargs): self.AUTO_TYPE = List(Object(objtype))",22,6
openstack%2Fnova-powervm~master~I888c74b17f1c9819e94cb6dad889d32f16f6bbcb,openstack/nova-powervm,master,I888c74b17f1c9819e94cb6dad889d32f16f6bbcb,Add/remove disk retry/timeout,MERGED,2015-06-22 17:00:15.000000000,2015-06-24 21:09:17.000000000,2015-06-24 21:09:16.000000000,"[{'_account_id': 3}, {'_account_id': 8190}, {'_account_id': 8662}, {'_account_id': 13883}, {'_account_id': 14070}]","[{'number': 1, 'created': '2015-06-22 17:00:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova-powervm/commit/e0e2c6c5c1c967fef7de00a988fe263aa4265e17', 'message': 'Add/remove disk retry/timeout\n\nRecently-added methods discover_vscsi_disk and remove_block_dev in\nnova_powervm.virt.powervm.mgmt performed SCSI bus scans followed by\nchecks for the existence of device special files.  Turns out the bus\nscan is asynchronous, meaning there may be a short delay between the\nreturn of the scan command and the (dis)appearance of the device special\nfile.  This change set builds a retry and timeout into those methods to\naccomodate.\n\nChange-Id: I888c74b17f1c9819e94cb6dad889d32f16f6bbcb\n'}, {'number': 2, 'created': '2015-06-24 17:15:48.000000000', 'files': ['nova_powervm/virt/powervm/mgmt.py', 'nova_powervm/virt/powervm/exception.py', 'nova_powervm/tests/virt/powervm/test_mgmt.py'], 'web_link': 'https://opendev.org/openstack/nova-powervm/commit/e0af19bc6f589df0855b5d2e93ed7bee2603c8b8', 'message': 'Add/remove disk retry/timeout\n\nRecently-added methods discover_vscsi_disk and remove_block_dev in\nnova_powervm.virt.powervm.mgmt performed SCSI bus scans followed by\nchecks for the existence of device special files.  Turns out the bus\nscan is asynchronous, meaning there may be a short delay between the\nreturn of the scan command and the (dis)appearance of the device special\nfile.  This change set builds a retry and timeout into those methods to\naccomodate.\n\nChange-Id: I888c74b17f1c9819e94cb6dad889d32f16f6bbcb\n'}]",2,194234,e0af19bc6f589df0855b5d2e93ed7bee2603c8b8,13,5,2,14070,,,0,"Add/remove disk retry/timeout

Recently-added methods discover_vscsi_disk and remove_block_dev in
nova_powervm.virt.powervm.mgmt performed SCSI bus scans followed by
checks for the existence of device special files.  Turns out the bus
scan is asynchronous, meaning there may be a short delay between the
return of the scan command and the (dis)appearance of the device special
file.  This change set builds a retry and timeout into those methods to
accomodate.

Change-Id: I888c74b17f1c9819e94cb6dad889d32f16f6bbcb
",git fetch https://review.opendev.org/openstack/nova-powervm refs/changes/34/194234/2 && git format-patch -1 --stdout FETCH_HEAD,"['nova_powervm/virt/powervm/mgmt.py', 'nova_powervm/virt/powervm/exception.py', 'nova_powervm/tests/virt/powervm/test_mgmt.py']",3,e0e2c6c5c1c967fef7de00a988fe263aa4265e17,nova_exception," @mock.patch('time.sleep') def test_discover_vscsi_disk_not_one_result(self, mock_exec, mock_glob, mock_sleep): mock_glob.side_effect = lambda path: [] self.assertRaises(npvmex.NoDiskDiscoveryException, self.assertTrue(mock_sleep.call_count) mock_sleep.reset_mock() self.assertEqual(0, mock_sleep.call_count) @mock.patch('time.sleep') def test_remove_block_dev(self, mock_exec, mock_stat, mock_realpath, mock_sleep): self.assertEqual(0, mock_sleep.call_count) mock_sleep.reset_mock() mock_stat.side_effect = lambda path: 1 # stat was called many times; exec was called once self.assertTrue(mock_stat.call_count > 4) # sleep was called many times self.assertTrue(mock_sleep.call_count)"," def test_discover_vscsi_disk_not_one_result(self, mock_exec, mock_glob): mock_glob.side_effect = [['path'], []] self.assertRaises(npvmex.UniqueDiskDiscoveryException, def test_remove_block_dev(self, mock_exec, mock_stat, mock_realpath): mock_stat.side_effect = (None, None, None) # stat was called thrice; exec was called once self.assertEqual(3, mock_stat.call_count)",77,20
openstack%2Fopenstack-ansible~master~I19f5da9820f2367b3d8dd0a7f215aa3f3ea5f611,openstack/openstack-ansible,master,I19f5da9820f2367b3d8dd0a7f215aa3f3ea5f611,Added options for enabling instance_passwords,MERGED,2015-06-23 19:42:24.000000000,2015-06-24 21:05:18.000000000,2015-06-24 21:05:16.000000000,"[{'_account_id': 3}, {'_account_id': 6816}, {'_account_id': 7353}, {'_account_id': 12000}, {'_account_id': 12892}, {'_account_id': 14578}]","[{'number': 1, 'created': '2015-06-23 19:42:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/3d9dea1f3bf33013debbbeb35783b6a5f8d9778f', 'message': 'Added a nova.conf option for instance_passwords\n\nThe nova.conf option for `enable_instance_password` has been added to as a\ndefault. This option has a default of True but that causes temptest to fail\nscheme validation on newer versions of temptest. To fix this issue the option\nbeing added with a default value of False which is perfectly acceptable as\npassword auth is geneerally disallowed in instance images in favor of using\nssh keys as provided through the nova keypair system.\n\nChange-Id: I19f5da9820f2367b3d8dd0a7f215aa3f3ea5f611\nPartial-Bug: #1468061\n'}, {'number': 2, 'created': '2015-06-24 14:25:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/c340347f4117540d35e6ef75926640283a0a737d', 'message': 'Added a nova.conf option for instance_passwords\n\nThe nova.conf option for `enable_instance_password` has been added to as a\ndefault. This option has a default of True but that causes temptest to fail\nscheme validation on newer versions of temptest. To fix this issue the option\nbeing added with a default value of False which is perfectly acceptable as\npassword auth is geneerally disallowed in instance images in favor of using\nssh keys as provided through the nova keypair system.\n\nChange-Id: I19f5da9820f2367b3d8dd0a7f215aa3f3ea5f611\nPartial-Bug: #1468061\n'}, {'number': 3, 'created': '2015-06-24 15:50:28.000000000', 'files': ['playbooks/roles/os_nova/templates/nova.conf.j2', 'playbooks/roles/os_tempest/templates/tempest.conf.j2', 'playbooks/roles/os_nova/defaults/main.yml', 'playbooks/roles/os_tempest/defaults/main.yml'], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/c068b965a11ad559aad0c6052ed7e58eff4dcd64', 'message': 'Added options for enabling instance_passwords\n\nThe nova.conf and tempest.conf option for `enable_instance_password` has been\nadded as a default. This option has a default of True in nova but false in tempest. \nThis causes temptest to fail scheme validation on newer versions of temptest. \nTo fix this issue the option being added with a default value of True for both\ntempest and nova.\n\nChange-Id: I19f5da9820f2367b3d8dd0a7f215aa3f3ea5f611\nPartial-Bug: #1468061\n'}]",0,194796,c068b965a11ad559aad0c6052ed7e58eff4dcd64,17,6,3,7353,,,0,"Added options for enabling instance_passwords

The nova.conf and tempest.conf option for `enable_instance_password` has been
added as a default. This option has a default of True in nova but false in tempest. 
This causes temptest to fail scheme validation on newer versions of temptest. 
To fix this issue the option being added with a default value of True for both
tempest and nova.

Change-Id: I19f5da9820f2367b3d8dd0a7f215aa3f3ea5f611
Partial-Bug: #1468061
",git fetch https://review.opendev.org/openstack/openstack-ansible refs/changes/96/194796/3 && git format-patch -1 --stdout FETCH_HEAD,"['playbooks/roles/os_nova/templates/nova.conf.j2', 'playbooks/roles/os_nova/defaults/main.yml']",2,3d9dea1f3bf33013debbbeb35783b6a5f8d9778f,bug/1468061,nova_enable_instance_password: False,,2,0
openstack%2Fnetworking-ovn~master~Ie8e538dafe6bcd2786cdc12a2e8ef7d0b9967a26,openstack/networking-ovn,master,Ie8e538dafe6bcd2786cdc12a2e8ef7d0b9967a26,Start disabling failing tests.,MERGED,2015-06-22 18:53:30.000000000,2015-06-24 21:02:04.000000000,2015-06-24 21:02:02.000000000,"[{'_account_id': 3}, {'_account_id': 1561}, {'_account_id': 4395}, {'_account_id': 11343}]","[{'number': 1, 'created': '2015-06-22 18:53:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/networking-ovn/commit/34b09a643bac2a3c843f6875a2b4134c13ae0493', 'message': 'Start disabling failing tests.\n\nI plan to revise this patch with a list of failing tests until we have\na passing tempest configuration.  This first revision is just to get\nan initial test run to get results from.\n\nChange-Id: Ie8e538dafe6bcd2786cdc12a2e8ef7d0b9967a26\nSigned-off-by: Russell Bryant <rbryant@redhat.com>\n'}, {'number': 2, 'created': '2015-06-22 20:16:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/networking-ovn/commit/0482c645d0a32a453190f6676dde66316b42eadb', 'message': 'Start disabling failing tests.\n\nI plan to revise this patch with a list of failing tests until we have\na passing tempest configuration.  This first revision is just to get\nan initial test run to get results from.\n\nChange-Id: Ie8e538dafe6bcd2786cdc12a2e8ef7d0b9967a26\nSigned-off-by: Russell Bryant <rbryant@redhat.com>\n'}, {'number': 3, 'created': '2015-06-22 20:18:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/networking-ovn/commit/f1fcc59e3e4be443ebe7f5c9e2a46f45a7b30743', 'message': 'Start disabling failing tests.\n\nI plan to revise this patch with a list of failing tests until we have\na passing tempest configuration.  This first revision is just to get\nan initial test run to get results from.\n\nChange-Id: Ie8e538dafe6bcd2786cdc12a2e8ef7d0b9967a26\nSigned-off-by: Russell Bryant <rbryant@redhat.com>\n'}, {'number': 4, 'created': '2015-06-22 21:10:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/networking-ovn/commit/2b11ed21dcaf55c27218cd2db0e76865718cf6e7', 'message': 'Start disabling failing tests.\n\nI plan to revise this patch with a list of failing tests until we have\na passing tempest configuration.  This first revision is just to get\nan initial test run to get results from.\n\nChange-Id: Ie8e538dafe6bcd2786cdc12a2e8ef7d0b9967a26\nSigned-off-by: Russell Bryant <rbryant@redhat.com>\n'}, {'number': 5, 'created': '2015-06-23 00:44:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/networking-ovn/commit/54210f7cfdc6be14a1dbf27fe35c59917f0c2e0f', 'message': 'Start disabling failing tests.\n\nI plan to revise this patch with a list of failing tests until we have\na passing tempest configuration.  This first revision is just to get\nan initial test run to get results from.\n\nChange-Id: Ie8e538dafe6bcd2786cdc12a2e8ef7d0b9967a26\nSigned-off-by: Russell Bryant <rbryant@redhat.com>\n'}, {'number': 6, 'created': '2015-06-23 01:11:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/networking-ovn/commit/97b4a5d791ed1dcce9f64d35700e78d8bf167e6b', 'message': 'Start disabling failing tests.\n\nI plan to revise this patch with a list of failing tests until we have\na passing tempest configuration.  This first revision is just to get\nan initial test run to get results from.\n\nChange-Id: Ie8e538dafe6bcd2786cdc12a2e8ef7d0b9967a26\nSigned-off-by: Russell Bryant <rbryant@redhat.com>\n'}, {'number': 7, 'created': '2015-06-23 14:39:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/networking-ovn/commit/663513f69008d705499975bcdef710fb9caa6866', 'message': 'Start disabling failing tests.\n\nI plan to revise this patch with a list of failing tests until we have\na passing tempest configuration.  This first revision is just to get\nan initial test run to get results from.\n\nChange-Id: Ie8e538dafe6bcd2786cdc12a2e8ef7d0b9967a26\nSigned-off-by: Russell Bryant <rbryant@redhat.com>\n'}, {'number': 8, 'created': '2015-06-23 15:07:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/networking-ovn/commit/6a69675828bf92eb99302bbf355290fe3f0a8698', 'message': 'Start disabling failing tests.\n\nI plan to revise this patch with a list of failing tests until we have\na passing tempest configuration.\n\nChange-Id: Ie8e538dafe6bcd2786cdc12a2e8ef7d0b9967a26\nSigned-off-by: Russell Bryant <rbryant@redhat.com>\n'}, {'number': 9, 'created': '2015-06-24 19:56:41.000000000', 'files': ['devstack/devstackgaterc'], 'web_link': 'https://opendev.org/openstack/networking-ovn/commit/cbbb634ba49f9c1bc69bf5fe039951b258ecdcf2', 'message': 'Start disabling failing tests.\n\nI plan to revise this patch with a list of failing tests until we have\na passing tempest configuration.\n\nChange-Id: Ie8e538dafe6bcd2786cdc12a2e8ef7d0b9967a26\nSigned-off-by: Russell Bryant <rbryant@redhat.com>\n'}]",0,194301,cbbb634ba49f9c1bc69bf5fe039951b258ecdcf2,28,4,9,1561,,,0,"Start disabling failing tests.

I plan to revise this patch with a list of failing tests until we have
a passing tempest configuration.

Change-Id: Ie8e538dafe6bcd2786cdc12a2e8ef7d0b9967a26
Signed-off-by: Russell Bryant <rbryant@redhat.com>
",git fetch https://review.opendev.org/openstack/networking-ovn refs/changes/01/194301/1 && git format-patch -1 --stdout FETCH_HEAD,['devstack/devstackgaterc'],1,34b09a643bac2a3c843f6875a2b4134c13ae0493,193330,"# Current list of failing tests that need to be triaged, have bugs filed, and # fixed as appropriate. # (none) ",,4,0
openstack%2Ftripleo-image-elements~master~Iac9f55e1d3ed75e8b4712812cba0242693ae2aac,openstack/tripleo-image-elements,master,Iac9f55e1d3ed75e8b4712812cba0242693ae2aac,Moving stack parameter defaults to Tuskar install,MERGED,2015-06-21 10:28:44.000000000,2015-06-24 20:59:00.000000000,2015-06-24 20:58:59.000000000,"[{'_account_id': 3}, {'_account_id': 6928}, {'_account_id': 7065}, {'_account_id': 7144}, {'_account_id': 9712}, {'_account_id': 11997}]","[{'number': 1, 'created': '2015-06-21 10:28:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-image-elements/commit/f5c7d01b347b6539d0cd27b77fa35fdb0a898e1c', 'message': 'Moving stack parameter defaults to Tuskar install\n\nWe don\'t want to overwrite parameters when deploying unless explicitly given.\nThis change moves the defaults to ""undercloud create"" and only sets parameters\nwhen given, enabling you to set Tuskar parameters through the GUI or with\nother CLI commands.\n\nSee also: https://bugzilla.redhat.com/show_bug.cgi?id=1227873\n\nChange-Id: Iac9f55e1d3ed75e8b4712812cba0242693ae2aac\n'}, {'number': 2, 'created': '2015-06-22 12:58:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-image-elements/commit/9a553b6e16daaa9aacf5cf39c17172919584f190', 'message': 'Moving stack parameter defaults to Tuskar install\n\nWe don\'t want to overwrite parameters when deploying unless explicitly given.\nThis change moves the defaults to ""undercloud create"" and only sets parameters\nwhen given, enabling you to set Tuskar parameters through the GUI or with\nother CLI commands.\n\nSee also: https://bugzilla.redhat.com/show_bug.cgi?id=1227873\n\nChange-Id: Iac9f55e1d3ed75e8b4712812cba0242693ae2aac\n'}, {'number': 3, 'created': '2015-06-23 15:45:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-image-elements/commit/70e1d07bdea234bac2849780b65bd4d070d08930', 'message': 'Moving stack parameter defaults to Tuskar install\n\nWe don\'t want to overwrite parameters when deploying unless explicitly given.\nThis change moves the defaults to ""undercloud create"" and only sets parameters\nwhen given, enabling you to set Tuskar parameters through the GUI or with\nother CLI commands.\n\nSee also: https://bugzilla.redhat.com/show_bug.cgi?id=1227873\n\nChange-Id: Iac9f55e1d3ed75e8b4712812cba0242693ae2aac\n'}, {'number': 4, 'created': '2015-06-23 15:50:46.000000000', 'files': ['elements/tuskar/os-refresh-config/post-configure.d/101-plan-add-roles'], 'web_link': 'https://opendev.org/openstack/tripleo-image-elements/commit/5b18bc5fbc48d51f6f331bf6914514df7a67c1f4', 'message': 'Moving stack parameter defaults to Tuskar install\n\nWe don\'t want to overwrite parameters when deploying unless explicitly given.\nThis change moves the defaults to ""undercloud create"" and only sets parameters\nwhen given, enabling you to set Tuskar parameters through the GUI or with\nother CLI commands.\n\nSee also: https://bugzilla.redhat.com/show_bug.cgi?id=1227873\n\nChange-Id: Iac9f55e1d3ed75e8b4712812cba0242693ae2aac\n'}]",1,193868,5b18bc5fbc48d51f6f331bf6914514df7a67c1f4,23,6,4,11997,,,0,"Moving stack parameter defaults to Tuskar install

We don't want to overwrite parameters when deploying unless explicitly given.
This change moves the defaults to ""undercloud create"" and only sets parameters
when given, enabling you to set Tuskar parameters through the GUI or with
other CLI commands.

See also: https://bugzilla.redhat.com/show_bug.cgi?id=1227873

Change-Id: Iac9f55e1d3ed75e8b4712812cba0242693ae2aac
",git fetch https://review.opendev.org/openstack/tripleo-image-elements refs/changes/68/193868/3 && git format-patch -1 --stdout FETCH_HEAD,['elements/tuskar/os-refresh-config/post-configure.d/102-plan-set-defaults'],1,f5c7d01b347b6539d0cd27b77fa35fdb0a898e1c,regebro/tuskar-plan-defaults,"#!/bin/bash set -x source /root/stackrc PLAN_ID=$(tuskar plan-show overcloud | awk '$2==""uuid"" {print $4}') tuskar plan-update -P Ceph-Storage-1::Flavor=baremetal \ -P Ceph-Storage-1::Image=overcloud-full \ -P Cinder-Storage-1::CinderISCSIHelper=lioadm \ -P Cinder-Storage-1::count=0 \ -P Cinder-Storage-1::Image=overcloud-full \ -P Cinder-Storage-1::Flavor=baremetal \ -P Compute-1::count=1 \ -P Compute-1::Flavor=baremetal \ -P Compute-1::Image=overcloud-full \ -P Compute-1::NeutronBridgeMappings=datacentre:br-ex \ -P Compute-1::NeutronEnableTunnelling=True \ -P Compute-1::NeutronFlatNetworks=datacentre \ -P Compute-1::NeutronNetworkType=gre \ -P Compute-1::NeutronNetworkVLANRanges=datacentre:1:1000 \ -P Compute-1::NeutronPhysicalBridge=br-ex \ -P Compute-1::NeutronPublicInterface=nic1 \ -P Compute-1::NeutronTunnelTypes=gre \ -P Compute-1::NovaComputeLibvirtType=qemu \ -P Compute-1::NtpServer= \ -P Controller-1::CinderISCSIHelper=lioadm \ -P Controller-1::CloudName=overcloud \ -P Controller-1::count=1 \ -P Controller-1::Flavor=baremetal \ -P Controller-1::Image=overcloud-full \ -P Controller-1::NeutronBridgeMappings=datacentre:br-ex \ -P Controller-1::NeutronEnableTunnelling=True \ -P Controller-1::NeutronFlatNetworks=datacentre \ -P Controller-1::NeutronNetworkType=gre \ -P Controller-1::NeutronNetworkVLANRanges=datacentre:1:1000 \ -P Controller-1::NeutronPublicInterface=nic1 \ -P Controller-1::NeutronTunnelTypes=gre \ -P Controller-1::NtpServer= \ -P Swift-Storage-1::count=0 \ -P Swift-Storage-1::Flavor=baremetal \ -P Swift-Storage-1::Image=overcloud-full \ $PLAN_ID ",,45,0
openstack%2Frally~master~Ia139db9c878b68c5c385c90291596602850f654b,openstack/rally,master,Ia139db9c878b68c5c385c90291596602850f654b,Testing that old lib for MySQL works better,ABANDONED,2015-06-12 00:45:04.000000000,2015-06-24 20:56:31.000000000,,"[{'_account_id': 3}, {'_account_id': 6172}, {'_account_id': 14817}]","[{'number': 1, 'created': '2015-06-12 00:45:04.000000000', 'files': ['README.rst'], 'web_link': 'https://opendev.org/openstack/rally/commit/2808979cad794481bc93f8a6ffc95ddb6dea14be', 'message': 'Testing that old lib for MySQL works better\n\nChange-Id: Ia139db9c878b68c5c385c90291596602850f654b\nDepends-on: I1d5a87a518fb67dd3ecba8d7a5d1b754c1a3a3bd\n'}]",0,190882,2808979cad794481bc93f8a6ffc95ddb6dea14be,6,3,1,6172,,,0,"Testing that old lib for MySQL works better

Change-Id: Ia139db9c878b68c5c385c90291596602850f654b
Depends-on: I1d5a87a518fb67dd3ecba8d7a5d1b754c1a3a3bd
",git fetch https://review.opendev.org/openstack/rally refs/changes/82/190882/1 && git format-patch -1 --stdout FETCH_HEAD,['README.rst'],1,2808979cad794481bc93f8a6ffc95ddb6dea14be,testing_that_new_mysql_lib_breaks_rally, ,,2,0
openstack%2Fpython-solumclient~master~I3d9c0f80e09dd62aba6e8599579305773a02afac,openstack/python-solumclient,master,I3d9c0f80e09dd62aba6e8599579305773a02afac,Updated from global requirements,MERGED,2015-06-22 08:29:28.000000000,2015-06-24 20:50:07.000000000,2015-06-24 20:50:05.000000000,"[{'_account_id': 3}, {'_account_id': 1375}, {'_account_id': 2506}, {'_account_id': 16272}]","[{'number': 1, 'created': '2015-06-22 08:29:28.000000000', 'files': ['requirements.txt', 'test-requirements.txt', 'setup.py'], 'web_link': 'https://opendev.org/openstack/python-solumclient/commit/b442452f1c8fd25c409394ad9cafcd23090684bd', 'message': 'Updated from global requirements\n\nChange-Id: I3d9c0f80e09dd62aba6e8599579305773a02afac\n'}]",0,194043,b442452f1c8fd25c409394ad9cafcd23090684bd,8,4,1,11131,,,0,"Updated from global requirements

Change-Id: I3d9c0f80e09dd62aba6e8599579305773a02afac
",git fetch https://review.opendev.org/openstack/python-solumclient refs/changes/43/194043/1 && git format-patch -1 --stdout FETCH_HEAD,"['requirements.txt', 'test-requirements.txt', 'setup.py']",3,b442452f1c8fd25c409394ad9cafcd23090684bd,openstack/requirements,,#!/usr/bin/env python,8,9
openstack%2Fheat-translator~master~I2dc7deea32588ac7a702ea7a0a3b2f1aee062cd1,openstack/heat-translator,master,I2dc7deea32588ac7a702ea7a0a3b2f1aee062cd1,Updated from global requirements,MERGED,2015-06-22 22:18:09.000000000,2015-06-24 20:46:32.000000000,2015-06-24 20:46:29.000000000,"[{'_account_id': 3}, {'_account_id': 6456}, {'_account_id': 6482}]","[{'number': 1, 'created': '2015-06-22 22:18:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat-translator/commit/48ca1f11671687cb8001f121bf6ca38bf243626d', 'message': 'Updated from global requirements\n\nChange-Id: I2dc7deea32588ac7a702ea7a0a3b2f1aee062cd1\n'}, {'number': 2, 'created': '2015-06-22 22:50:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat-translator/commit/7c9896fccdd122796e8560e3171d4e94d76ca0f1', 'message': 'Updated from global requirements\n\nChange-Id: I2dc7deea32588ac7a702ea7a0a3b2f1aee062cd1\n'}, {'number': 3, 'created': '2015-06-23 21:42:39.000000000', 'files': ['requirements.txt', 'test-requirements.txt', 'setup.py'], 'web_link': 'https://opendev.org/openstack/heat-translator/commit/c947875772bcc3d1a34c83aa262f4630363de4b7', 'message': 'Updated from global requirements\n\nChange-Id: I2dc7deea32588ac7a702ea7a0a3b2f1aee062cd1\n'}]",0,194418,c947875772bcc3d1a34c83aa262f4630363de4b7,12,3,3,11131,,,0,"Updated from global requirements

Change-Id: I2dc7deea32588ac7a702ea7a0a3b2f1aee062cd1
",git fetch https://review.opendev.org/openstack/heat-translator refs/changes/18/194418/2 && git format-patch -1 --stdout FETCH_HEAD,"['requirements.txt', 'test-requirements.txt', 'setup.py']",3,48ca1f11671687cb8001f121bf6ca38bf243626d,openstack/requirements,"# In python < 2.7.4, a lazy loading of package `pbr` will break # setuptools if some other modules registered functions in `atexit`. # solution from: http://bugs.python.org/issue15881#msg170215 try: import multiprocessing # noqa except ImportError: pass setup_requires=['pbr'],","#!/usr/bin/env python setup_requires=['pbr>=0.5.21,<1.0'],",23,10
openstack%2Fheat-translator~master~Id18b22963505300a09e0ec0b86c8d65397b7528b,openstack/heat-translator,master,Id18b22963505300a09e0ec0b86c8d65397b7528b,Added the missing testcases for Tosca translator,MERGED,2015-06-18 21:04:34.000000000,2015-06-24 20:42:32.000000000,2015-06-24 20:42:30.000000000,"[{'_account_id': 3}, {'_account_id': 6456}, {'_account_id': 7514}, {'_account_id': 10295}, {'_account_id': 12302}, {'_account_id': 16047}]","[{'number': 1, 'created': '2015-06-18 21:04:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat-translator/commit/4dd8a7c955da9955f06ce48d6254bb038219699a', 'message': 'Adding the missing testcases for Tosca translator Elasticsearch and Kibana software components\n\nThe testcases for Kibana and Elasticsearch software components were missing. Added those to improve test coverage to 100% for these components.\n\nChange-Id: Id18b22963505300a09e0ec0b86c8d65397b7528b\n'}, {'number': 2, 'created': '2015-06-18 21:29:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat-translator/commit/e6d73420cd8e530bfb5bcbf10165c2ad99107aa1', 'message': 'Adding the missing testcases for Tosca translator Elasticsearch and Kibana software components\n\nThe testcases for Kibana and Elasticsearch software components were missing. Added those to improve test coverage to 10% for these components.\nPatch set 2 fixes the PEP8 error where mock patch line in Elasticsearch testcase was 80 characters.\n\nChange-Id: Id18b22963505300a09e0ec0b86c8d65397b7528b\n'}, {'number': 3, 'created': '2015-06-18 21:43:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat-translator/commit/3b66873789cd3b00b59c1b8062319db0da9c6474', 'message': 'Adding the missing testcases for Tosca translator Elasticsearch and Kibana software components\n\nThe testcases for Kibana and Elasticsearch software components were missing. Added those to improve test coverage to 10% for these components.\nPatch set 2 fixes the PEP8 error where mock patch line in Elasticsearch testcase was 80 characters.\nPatch set 3 fixes the Python error related to PEP8 fix.\nChange-Id: Id18b22963505300a09e0ec0b86c8d65397b7528b\n'}, {'number': 4, 'created': '2015-06-18 23:25:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat-translator/commit/ba16d951455b15cfdad5d5501fb0c201df2f1478', 'message': 'Adding the missing testcases for Tosca translator Elasticsearch and Kibana software components\n\nThe testcases for Kibana and Elasticsearch software components were missing. Added those to improve test coverage to 10% for these components.\nPatch set 2 fixes the PEP8 error where mock patch line in Elasticsearch testcase was 80 characters.\nPatch set 3 fixes the Python error related to PEP8 fix.\nPatch set 4 Adding the check that handle_properties does not return anything\nChange-Id: Id18b22963505300a09e0ec0b86c8d65397b7528b\n'}, {'number': 5, 'created': '2015-06-19 20:13:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat-translator/commit/1e113211fa458292de2bde9ceb1aacefac98407d', 'message': 'Added the missing testcases for Tosca translator\n\nThe testcases for Kibana and Elasticsearch software components were missing. \nAdded those to improve test coverage to 100% for these components.\n\nChange-Id: Id18b22963505300a09e0ec0b86c8d65397b7528b\n'}, {'number': 6, 'created': '2015-06-19 20:14:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat-translator/commit/3d3b3b5b3251f66219bead20a6e1b39adc7079d3', 'message': 'Added the missing testcases for Tosca translator\n\nThe testcase for Kibana was added. \nThe testcase for Elasticsearch was added. \nImproved test coverage to 100% for these components.\n\nChange-Id: Id18b22963505300a09e0ec0b86c8d65397b7528b\n'}, {'number': 7, 'created': '2015-06-22 21:30:29.000000000', 'files': ['translator/hot/tosca/tests/test_tosca_kibana.py', 'translator/hot/tosca/tests/test_tosca_elasticsearch.py'], 'web_link': 'https://opendev.org/openstack/heat-translator/commit/48bb6d003d354f5b7709dcf70a218538874b057a', 'message': 'Added the missing testcases for Tosca translator\n\nThe testcase for Kibana was added.\nThe testcase for Elasticsearch was added.\nImproved test coverage to 100% for these components.\n\nChange-Id: Id18b22963505300a09e0ec0b86c8d65397b7528b\n'}]",9,193315,48bb6d003d354f5b7709dcf70a218538874b057a,27,6,7,12302,,,0,"Added the missing testcases for Tosca translator

The testcase for Kibana was added.
The testcase for Elasticsearch was added.
Improved test coverage to 100% for these components.

Change-Id: Id18b22963505300a09e0ec0b86c8d65397b7528b
",git fetch https://review.opendev.org/openstack/heat-translator refs/changes/15/193315/1 && git format-patch -1 --stdout FETCH_HEAD,"['translator/hot/tosca/tests/test_tosca_kibana.py', 'translator/hot/tosca/tests/test_tosca_elasticsearch.py']",2,4dd8a7c955da9955f06ce48d6254bb038219699a,newtests_merge,"# Licensed under the Apache License, Version 2.0 (the ""License""); you may # not use this file except in compliance with the License. You may obtain # a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT # WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the # License for the specific language governing permissions and limitations # under the License. import mock from translator.hot.tosca.tosca_elasticsearch import ToscaElasticsearch from translator.toscalib.tests.base import TestCase class ToscaElasticsearchTest(TestCase): @mock.patch('translator.toscalib.nodetemplate.NodeTemplate') @mock.patch('translator.hot.tosca.tosca_elasticsearch.HotResource.__init__') def test_init(self, mock_hotres_init, mock_node): ToscaElasticsearch(mock_node) # Make sure base class gets called mock_hotres_init.assert_called_once_with(mock_node) self.assertEqual(ToscaElasticsearch.toscatype, 'tosca.nodes.SoftwareComponent.Elasticsearch') @mock.patch('translator.toscalib.nodetemplate.NodeTemplate') @mock.patch('translator.hot.tosca.tosca_elasticsearch.HotResource.__init__') def test_handle_properties(self, mock_hotres_init, mock_node): p = ToscaElasticsearch(mock_node) p.handle_properties() ",,66,0
openstack%2Fbarbican~master~I319026abe885f46d98d9039aa4d3ac7eed06d161,openstack/barbican,master,I319026abe885f46d98d9039aa4d3ac7eed06d161,Remove ProjectSecret table-related code,MERGED,2015-06-22 18:19:02.000000000,2015-06-24 20:42:16.000000000,2015-06-24 20:42:14.000000000,"[{'_account_id': 3}, {'_account_id': 6783}, {'_account_id': 7136}, {'_account_id': 7262}, {'_account_id': 7789}, {'_account_id': 7973}, {'_account_id': 8004}, {'_account_id': 8623}, {'_account_id': 9234}, {'_account_id': 9237}, {'_account_id': 9914}, {'_account_id': 10873}, {'_account_id': 11970}]","[{'number': 1, 'created': '2015-06-22 18:19:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/barbican/commit/0045ca3a39dcccd2be24198f37dd0faa917ddd39', 'message': 'Remove ProjectSecret table-related code\n\nThis CR removes the code that was related to the ProjectSecret table, as\nwell as the transitional code that was added while that was phased out.\n\nblueprint data-remove-tenant-secret-assoc\n\nChange-Id: I319026abe885f46d98d9039aa4d3ac7eed06d161\n'}, {'number': 2, 'created': '2015-06-23 13:23:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/barbican/commit/defc41d8ed72d8878c2fd85d917617e58aa66d2f', 'message': 'Remove ProjectSecret table-related code\n\nThis CR removes the code that was related to the ProjectSecret table, as\nwell as the transitional code that was added while that was phased out.\n\nblueprint data-remove-tenant-secret-assoc\n\nChange-Id: I319026abe885f46d98d9039aa4d3ac7eed06d161\n'}, {'number': 3, 'created': '2015-06-24 11:22:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/barbican/commit/33499266557a67648da1d7400185a8ad7b92af18', 'message': 'Remove ProjectSecret table-related code\n\nThis CR removes the code that was related to the ProjectSecret table, as\nwell as the transitional code that was added while that was phased out.\n\nblueprint data-remove-tenant-secret-assoc\n\nChange-Id: I319026abe885f46d98d9039aa4d3ac7eed06d161\n'}, {'number': 4, 'created': '2015-06-24 12:55:19.000000000', 'files': ['barbican/api/controllers/acls.py', 'barbican/plugin/resources.py', 'barbican/tests/model/repositories/test_repositories_acls.py', 'barbican/tests/tasks/test_keystone_consumer.py', 'barbican/model/migration/alembic_migrations/versions/1bece815014f_remove_projectsecret_table.py', 'barbican/tests/tasks/test_resources.py', 'barbican/model/repositories.py', 'barbican/tests/model/repositories/test_repositories_secrets.py', 'barbican/tests/tasks/test_certificate_resources.py', 'barbican/api/controllers/secrets.py', 'barbican/plugin/store_crypto.py', 'barbican/tests/api/test_resources_policy.py', 'barbican/tests/plugin/test_resource.py', 'barbican/model/models.py', 'barbican/tests/utils.py', 'barbican/tests/plugin/test_store_crypto.py', 'barbican/tests/api/test_resources.py'], 'web_link': 'https://opendev.org/openstack/barbican/commit/910431319e715552622a02e8bc80c1d8ffd714d0', 'message': 'Remove ProjectSecret table-related code\n\nThis CR removes the code that was related to the ProjectSecret table, as\nwell as the transitional code that was added while that was phased out.\n\nblueprint data-remove-tenant-secret-assoc\n\nChange-Id: I319026abe885f46d98d9039aa4d3ac7eed06d161\n'}]",0,194283,910431319e715552622a02e8bc80c1d8ffd714d0,18,13,4,10873,,,0,"Remove ProjectSecret table-related code

This CR removes the code that was related to the ProjectSecret table, as
well as the transitional code that was added while that was phased out.

blueprint data-remove-tenant-secret-assoc

Change-Id: I319026abe885f46d98d9039aa4d3ac7eed06d161
",git fetch https://review.opendev.org/openstack/barbican refs/changes/83/194283/4 && git format-patch -1 --stdout FETCH_HEAD,"['barbican/api/controllers/acls.py', 'barbican/plugin/resources.py', 'barbican/tests/model/repositories/test_repositories_acls.py', 'barbican/tests/tasks/test_keystone_consumer.py', 'barbican/tests/tasks/test_resources.py', 'barbican/model/repositories.py', 'barbican/tests/model/repositories/test_repositories_secrets.py', 'barbican/tests/tasks/test_certificate_resources.py', 'barbican/api/controllers/secrets.py', 'barbican/plugin/store_crypto.py', 'barbican/tests/api/test_resources_policy.py', 'barbican/tests/plugin/test_resource.py', 'barbican/model/models.py', 'barbican/tests/utils.py', 'barbican/tests/plugin/test_store_crypto.py', 'barbican/tests/api/test_resources.py']",16,0045ca3a39dcccd2be24198f37dd0faa917ddd39,bp/data-remove-tenant-secret-assoc, self.secret.project = mock.MagicMock() self.secret.project.external_id = self.external_project_id, # Set up mocked project-secret repo self.project_secret_repo = mock.MagicMock() self.project_secret_repo.create_from.return_value = None self.setup_project_secret_repository_mock(self.project_secret_repo) self.secret.project_assocs = [mock.MagicMock()] secret_project = self.secret.project_assocs[0].projects secret_project.external_id = self.external_project_id # Set up mocked project-secret repo self.setup_project_secret_repository_mock() ,36,255
openstack%2Fproject-config~master~I5a4f24f50ff3d2463d6b4578861ae667122b9954,openstack/project-config,master,I5a4f24f50ff3d2463d6b4578861ae667122b9954,Copy rollcall votes on trivial rebase,MERGED,2015-06-24 16:15:45.000000000,2015-06-24 20:40:52.000000000,2015-06-24 20:40:50.000000000,"[{'_account_id': 1}, {'_account_id': 3}, {'_account_id': 308}, {'_account_id': 2750}, {'_account_id': 5263}, {'_account_id': 6547}]","[{'number': 1, 'created': '2015-06-24 16:15:45.000000000', 'files': ['gerrit/acls/openstack/governance.config', 'gerrit/acls/openstack-infra/infra-specs.config'], 'web_link': 'https://opendev.org/openstack/project-config/commit/92c83ed0265e416fe3fe14ad0019ed2c4f366e1d', 'message': 'Copy rollcall votes on trivial rebase\n\nChange-Id: I5a4f24f50ff3d2463d6b4578861ae667122b9954\n'}]",0,195179,92c83ed0265e416fe3fe14ad0019ed2c4f366e1d,14,6,1,1,,,0,"Copy rollcall votes on trivial rebase

Change-Id: I5a4f24f50ff3d2463d6b4578861ae667122b9954
",git fetch https://review.opendev.org/openstack/project-config refs/changes/79/195179/1 && git format-patch -1 --stdout FETCH_HEAD,"['gerrit/acls/openstack/governance.config', 'gerrit/acls/openstack-infra/infra-specs.config']",2,92c83ed0265e416fe3fe14ad0019ed2c4f366e1d,,copyAllScoresOnTrivialRebase = true,,2,0
openstack%2Fnova-powervm~master~Ideab10405a8897a2576d86f31e9ddb96aab2ff03,openstack/nova-powervm,master,Ideab10405a8897a2576d86f31e9ddb96aab2ff03,WIP: POC: snapshot upload,ABANDONED,2015-06-22 21:17:38.000000000,2015-06-24 20:39:00.000000000,,[{'_account_id': 3}],"[{'number': 1, 'created': '2015-06-22 21:17:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova-powervm/commit/7f814e7a210e0397c6cf3abd33c9f34c9529483e', 'message': 'WIP: POC: snapshot upload\n\nChange-Id: Ideab10405a8897a2576d86f31e9ddb96aab2ff03\n'}, {'number': 2, 'created': '2015-06-23 15:09:11.000000000', 'files': ['nova_powervm/virt/powervm/driver.py', 'nova_powervm/virt/powervm/image.py'], 'web_link': 'https://opendev.org/openstack/nova-powervm/commit/07cf8e348e2107f465e664aadaa5485f91839451', 'message': 'WIP: POC: snapshot upload\n\nChange-Id: Ideab10405a8897a2576d86f31e9ddb96aab2ff03\n'}]",0,194385,07cf8e348e2107f465e664aadaa5485f91839451,5,1,2,14070,,,0,"WIP: POC: snapshot upload

Change-Id: Ideab10405a8897a2576d86f31e9ddb96aab2ff03
",git fetch https://review.opendev.org/openstack/nova-powervm refs/changes/85/194385/2 && git format-patch -1 --stdout FETCH_HEAD,"['nova_powervm/virt/powervm/driver.py', 'nova_powervm/virt/powervm/image.py']",2,7f814e7a210e0397c6cf3abd33c9f34c9529483e,stream_to_glance,"# Copyright 2015 IBM Corp. # # All Rights Reserved. # # Licensed under the Apache License, Version 2.0 (the ""License""); you may # not use this file except in compliance with the License. You may obtain # a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT # WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the # License for the specific language governing permissions and limitations # under the License. """"""Utilities related to glance image management for the PowerVM driver."""""" from nova import utils def stream_disk_to_glance(context, image_api, image_id, metadata, diskpath): """"""Stream the entire contents of a block device to a glance image. :param context: Nova security context :param image_api: Handle to the glance image API. :param image_id: UUID of the prepared glance image. :param metadata: Dictionary of metadata for the image. :param diskpath: String path to device special file of disk to be uploaded, e.g. ""/dev/sde"". """""" # Make the device special file owned by the current user for the duration # of the operation. with utils.temporary_chown(diskpath): with open(diskpath, 'rb') as stream: # Stream it. This is synchronous. image_api.update(context, image_id, metadata, stream) def snapshot_metadata(context, image_api, image_id, instance): image = image_api.get(context, image_id) metadata = { 'name': image['name'], 'is_public': False, 'status': 'active', 'disk_format': 'ami', 'container_format': 'ami', 'properties': { 'kernel_id': instance.kernel_id, 'image_location': 'snapshot', 'image_state': 'available', 'owner_id': instance.project_id, 'ramdisk_id': instance.ramdisk_id } } return metadata ",,63,1
openstack%2Fdevstack~master~Ic0c6e01a6d7613d712ac9e7e4a378cc3a8ce75e6,openstack/devstack,master,Ic0c6e01a6d7613d712ac9e7e4a378cc3a8ce75e6,only soft enforce requirements not in projects.txt,MERGED,2015-06-24 09:55:11.000000000,2015-06-24 20:33:41.000000000,2015-06-24 20:33:39.000000000,"[{'_account_id': 3}, {'_account_id': 970}, {'_account_id': 2750}, {'_account_id': 5196}, {'_account_id': 8871}, {'_account_id': 10385}, {'_account_id': 16986}]","[{'number': 1, 'created': '2015-06-24 09:55:11.000000000', 'files': ['inc/python', 'stackrc'], 'web_link': 'https://opendev.org/openstack/devstack/commit/7af8a1b9b3180da54e2c9505228ad722db44ca27', 'message': ""only soft enforce requirements not in projects.txt\n\nWe're adding the ability to have devstack plugins, which should be\nmuch more free to require new things not in global requirements. Our\nold thinking of locking down all the requirements doesn't really work\nin a plugin model.\n\nInstead, if the project is in projects.txt, continue with the old\nbehavior. If it is not, do a soft update (update all the requirements\nwe know about, leave the ones we don't). This was previously the SOFT\nrequirements update mode, but now it will just be the default.\n\nChange-Id: Ic0c6e01a6d7613d712ac9e7e4a378cc3a8ce75e6\n""}]",0,195015,7af8a1b9b3180da54e2c9505228ad722db44ca27,17,7,1,2750,,,0,"only soft enforce requirements not in projects.txt

We're adding the ability to have devstack plugins, which should be
much more free to require new things not in global requirements. Our
old thinking of locking down all the requirements doesn't really work
in a plugin model.

Instead, if the project is in projects.txt, continue with the old
behavior. If it is not, do a soft update (update all the requirements
we know about, leave the ones we don't). This was previously the SOFT
requirements update mode, but now it will just be the default.

Change-Id: Ic0c6e01a6d7613d712ac9e7e4a378cc3a8ce75e6
",git fetch https://review.opendev.org/openstack/devstack refs/changes/15/195015/1 && git format-patch -1 --stdout FETCH_HEAD,"['inc/python', 'stackrc']",2,7af8a1b9b3180da54e2c9505228ad722db44ca27,soft_enforce,,"# Requirements enforcing mode # # - strict (default) : ensure all project requirements files match # what's in global requirements. # # - soft : enforce requirements on everything in # requirements/projects.txt, but do soft updates on all other # repositories (i.e. sync versions for requirements that are in g-r, # but pass through any extras) REQUIREMENTS_MODE=${REQUIREMENTS_MODE:-strict} ",6,21
openstack%2Frequirements~master~I9256563a6c2cc455043f0d61cd27b033d37302ef,openstack/requirements,master,I9256563a6c2cc455043f0d61cd27b033d37302ef,Enable 'python_version=='2.6' for futures and enum34,MERGED,2015-06-23 23:48:43.000000000,2015-06-24 20:33:18.000000000,2015-06-24 20:33:16.000000000,"[{'_account_id': 3}, {'_account_id': 2472}, {'_account_id': 2750}, {'_account_id': 4190}, {'_account_id': 5638}, {'_account_id': 9453}, {'_account_id': 16272}]","[{'number': 1, 'created': '2015-06-23 23:48:43.000000000', 'files': ['global-requirements.txt'], 'web_link': 'https://opendev.org/openstack/requirements/commit/c85fcb73a1e111929dae23dd8d62bd118d0661ae', 'message': ""Enable 'python_version=='2.6' for futures and enum34\n\nEnable futures for 2.6 this until the discussion around oslo.messaging\nneed for this (and its support for 2.6) and its planned usage of the futurist\nlibrary for the liberty release.\n\nAlso some of the current oslo libraries (taskflow) still support 2.6\nfor the short-term (until a few other reviews merge) so we need to enable\nits usage there still for enum34.\n\nThis is also breaking the futurist, automaton, gate and the taskflow check\ngates as those are still on 2.6 (this may change soon).\n\nSoon the following will make that less relevant (but these haven't merged\nyet):\n\n- https://review.openstack.org/#/c/193349/\n- https://review.openstack.org/#/c/193354/\n- https://review.openstack.org/#/c/194860/\n\nChange-Id: I9256563a6c2cc455043f0d61cd27b033d37302ef\n""}]",0,194877,c85fcb73a1e111929dae23dd8d62bd118d0661ae,10,7,1,1297,,,0,"Enable 'python_version=='2.6' for futures and enum34

Enable futures for 2.6 this until the discussion around oslo.messaging
need for this (and its support for 2.6) and its planned usage of the futurist
library for the liberty release.

Also some of the current oslo libraries (taskflow) still support 2.6
for the short-term (until a few other reviews merge) so we need to enable
its usage there still for enum34.

This is also breaking the futurist, automaton, gate and the taskflow check
gates as those are still on 2.6 (this may change soon).

Soon the following will make that less relevant (but these haven't merged
yet):

- https://review.openstack.org/#/c/193349/
- https://review.openstack.org/#/c/193354/
- https://review.openstack.org/#/c/194860/

Change-Id: I9256563a6c2cc455043f0d61cd27b033d37302ef
",git fetch https://review.opendev.org/openstack/requirements refs/changes/77/194877/1 && git format-patch -1 --stdout FETCH_HEAD,['global-requirements.txt'],1,c85fcb73a1e111929dae23dd8d62bd118d0661ae,,enum34;python_version=='2.7' or python_version=='2.6'futures>=3.0;python_version=='2.7' or python_version=='2.6',enum34;python_version=='2.7'futures>=3.0;python_version=='2.7',2,2
openstack%2Fneutron-specs~master~I2d2104f6fb78b8d52d033d8cc67e430d9097ca07,openstack/neutron-specs,master,I2d2104f6fb78b8d52d033d8cc67e430d9097ca07,Decompose vendor plugins/drivers for neutron-*aas,MERGED,2015-04-16 21:49:39.000000000,2015-06-24 20:26:41.000000000,2015-06-24 20:26:40.000000000,"[{'_account_id': 3}, {'_account_id': 105}, {'_account_id': 162}, {'_account_id': 6659}, {'_account_id': 6854}, {'_account_id': 6951}, {'_account_id': 7787}, {'_account_id': 10980}, {'_account_id': 12403}, {'_account_id': 12525}]","[{'number': 1, 'created': '2015-04-16 21:49:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-specs/commit/750a33a3d9fe733ab22640b4462bedf51305d5b6', 'message': 'Decompose vendor plugins/drivers for neutron-*aas\n\nChange-Id: I2d2104f6fb78b8d52d033d8cc67e430d9097ca07\n'}, {'number': 2, 'created': '2015-06-12 17:33:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-specs/commit/31519cc3ec23de09c59ff6b3f2533146e7bb8b9e', 'message': 'Decompose vendor plugins/drivers for neutron-*aas\n\nChange-Id: I2d2104f6fb78b8d52d033d8cc67e430d9097ca07\n'}, {'number': 3, 'created': '2015-06-24 19:19:08.000000000', 'files': ['specs/liberty/decompose-aas.rst'], 'web_link': 'https://opendev.org/openstack/neutron-specs/commit/2071a40261ceebadf9cdd99ec8dd8428af93ccb2', 'message': 'Decompose vendor plugins/drivers for neutron-*aas\n\nChange-Id: I2d2104f6fb78b8d52d033d8cc67e430d9097ca07\n'}]",12,174619,2071a40261ceebadf9cdd99ec8dd8428af93ccb2,24,10,3,10980,,,0,"Decompose vendor plugins/drivers for neutron-*aas

Change-Id: I2d2104f6fb78b8d52d033d8cc67e430d9097ca07
",git fetch https://review.opendev.org/openstack/neutron-specs refs/changes/19/174619/3 && git format-patch -1 --stdout FETCH_HEAD,['specs/liberty/decompose-aas.rst'],1,750a33a3d9fe733ab22640b4462bedf51305d5b6,bp/decompose-aas,".. This work is licensed under a Creative Commons Attribution 3.0 Unported License. http://creativecommons.org/licenses/by/3.0/legalcode ================================================ Decompose vendor plugins/drivers for neutron-aas ================================================ https://blueprints.launchpad.net/neutron/+spec/decompose-aas Move vendor service drivers out-of-tree, starting in Liberty, complete by the end of M. Includes ref implementations, if the Liberty summit decides to remove neutron ref implementations from in-tree. Problem Description =================== As part of Kilo, neutron undertook a major effort to decompose vendor code out-of-tree[1]. During discussion of this feature, it was decided to allow service drivers to remain in-tree, as those repos have a smaller community, but to eventually adopt the same model. This proposal attempts to outline the timeline for decomposing service drivers. This is not a purely Liberty focused spec, but instead attempts to communicate timelines and gather consensus around this topic for the next several cycles. Proposed Change =============== All new service drivers which are not in gerrit as of when this spec is approved, must be out-of-tree shim style drivers, as show in the neutron vendor decomp spec[1]. Existing drivers have until the end of the M cycle to convert themselves to out-of-tree shims. Data Model Impact ----------------- None. REST API Impact --------------- None. Security Impact --------------- None. Notifications Impact -------------------- None. Other End User Impact --------------------- Same as neutron decomp impact.[1] Performance Impact ------------------ None. IPv6 Impact ----------- None. Other Deployer Impact --------------------- Same as neutron decomp impact.[1] Developer Impact ---------------- Same as neutron decomp impact.[1] Community Impact ---------------- Same as neutron decomp impact.[1] Alternatives ------------ Continue having core teams review vendor code. Implementation ============== Assignee(s) ----------- Putting a name here as a starter. Anyone else, feel free. Primary assignee: https://launchpad.net/~dougwig Other contributors: <launchpad-id or None> Work Items ---------- - Communicate change for drivers in Liberty, deadlines for M. Dependencies ============ None. Testing ======= Tempest Tests ------------- Covered by third-party CI, as today. Functional Tests ---------------- Covered by third-party CI, as today. API Tests --------- Covered by third-party CI, as today. Documentation Impact ==================== User Documentation ------------------ None. Developer Documentation ----------------------- None. References ========== [1] https://github.com/openstack/neutron-specs/blob/master/specs/kilo/core-vendor-decomposition.rst ",,153,0
openstack%2Fhorizon~master~If6daee1fe949dc0d4524e35e0323a7f0cfd7c190,openstack/horizon,master,If6daee1fe949dc0d4524e35e0323a7f0cfd7c190,Add required to cidr field for 'Add Subnet',MERGED,2015-06-24 01:24:58.000000000,2015-06-24 19:54:33.000000000,2015-06-24 19:54:31.000000000,"[{'_account_id': 3}, {'_account_id': 2455}, {'_account_id': 4264}, {'_account_id': 4428}, {'_account_id': 10442}, {'_account_id': 14107}, {'_account_id': 16803}]","[{'number': 1, 'created': '2015-06-24 01:24:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/8732390e96ced4c661b140f67d91f19832e9bbbc', 'message': 'CIDR is required for creating subnet workflow\n\nChange-Id: If6daee1fe949dc0d4524e35e0323a7f0cfd7c190\nCloses-bug:# 1467810\n'}, {'number': 2, 'created': '2015-06-24 01:26:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/a10f2275e6e93bca63cef1aa5baaccac84d6a7aa', 'message': 'CIDR is required for creating subnet workflow\n\nChange-Id: If6daee1fe949dc0d4524e35e0323a7f0cfd7c190\nCloses-bug: #1467810\n'}, {'number': 3, 'created': '2015-06-24 06:40:54.000000000', 'files': ['openstack_dashboard/dashboards/project/networks/subnets/workflows.py'], 'web_link': 'https://opendev.org/openstack/horizon/commit/32f888fe638285aabc71bcc82a3f597701a53840', 'message': ""Add required to cidr field for 'Add Subnet'\n\nWhen adding subnet for a network, if no cidr is specified, the workflow\nwill not be able to process to next without any message to inform the\nuser that the cidr is required. This patch adds required attribute to\ncidr field.\n\nChange-Id: If6daee1fe949dc0d4524e35e0323a7f0cfd7c190\nCloses-bug: #1467810\n""}]",2,194904,32f888fe638285aabc71bcc82a3f597701a53840,16,7,3,4428,,,0,"Add required to cidr field for 'Add Subnet'

When adding subnet for a network, if no cidr is specified, the workflow
will not be able to process to next without any message to inform the
user that the cidr is required. This patch adds required attribute to
cidr field.

Change-Id: If6daee1fe949dc0d4524e35e0323a7f0cfd7c190
Closes-bug: #1467810
",git fetch https://review.opendev.org/openstack/horizon refs/changes/04/194904/3 && git format-patch -1 --stdout FETCH_HEAD,['openstack_dashboard/dashboards/project/networks/workflows.py'],1,8732390e96ced4c661b140f67d91f19832e9bbbc,add-subnet-cidr-required," required=True,"," required=False,",1,1
openstack%2Fneutron~master~Ia79f526aa973ece1145615d65349f860aa3fd465,openstack/neutron,master,Ia79f526aa973ece1145615d65349f860aa3fd465,Use string exception casting everywhere,MERGED,2015-06-18 18:35:08.000000000,2015-06-24 19:54:20.000000000,2015-06-24 19:54:18.000000000,"[{'_account_id': 3}, {'_account_id': 5170}, {'_account_id': 5948}, {'_account_id': 6524}, {'_account_id': 6788}, {'_account_id': 6854}, {'_account_id': 7293}, {'_account_id': 7787}, {'_account_id': 8124}, {'_account_id': 9008}, {'_account_id': 9423}, {'_account_id': 9681}, {'_account_id': 9682}, {'_account_id': 9787}, {'_account_id': 9845}, {'_account_id': 10068}, {'_account_id': 10121}, {'_account_id': 10153}, {'_account_id': 10184}, {'_account_id': 10692}, {'_account_id': 11279}, {'_account_id': 14323}, {'_account_id': 14571}, {'_account_id': 14605}, {'_account_id': 15296}, {'_account_id': 15894}, {'_account_id': 16934}]","[{'number': 1, 'created': '2015-06-18 18:35:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/45d390ca874ffab7d901b3ed209152d701371655', 'message': 'Use string exception casting\n\nInstead of the deprecated ""message"" member access, casting to a string invokes the __str__ method of the exception that is wired to return the message\n\nChange-Id: Ia79f526aa973ece1145615d65349f860aa3fd465\nCloses-Bug: 1466542\n'}, {'number': 2, 'created': '2015-06-19 17:09:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/0180f156550f7aa6fa11dd1b91818a16a0b428e8', 'message': 'Use string exception casting everywhere\n\nInstead of the deprecated ""message"" member access,\ncasting to a string invokes the __str__ method of the exception\nthat is wired to return the message\n\nFixed several places found by Henry Gessau <gessau@cisco.com>\nhttps://bugs.launchpad.net/neutron/+bug/1466542/comments/2\nSome of which were already fixed\n\nAdded a test of the failure cases of IpRouteCommand::delete_gateway\nbecause they were missing\n\nRunning the tests locally does not show this warning anymore\n\nChange-Id: Ia79f526aa973ece1145615d65349f860aa3fd465\nCloses-Bug: 1466542\n'}, {'number': 3, 'created': '2015-06-19 21:06:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/1e306dbd782f5188721c398576e1e6fa851f144b', 'message': 'Use string exception casting everywhere\n\nInstead of the deprecated ""message"" member access,\ncasting to a string invokes the __str__ method of the exception\nthat is wired to return the message\n\nAdded a test of the failure cases of IpRouteCommand::delete_gateway\nbecause they were missing\n\nRunning unit and functional tests locally no longer shows the warning\nreported in the bug.\n\nChange-Id: Ia79f526aa973ece1145615d65349f860aa3fd465\nCloses-Bug: #1466542\n'}, {'number': 4, 'created': '2015-06-22 13:13:30.000000000', 'files': ['neutron/plugins/embrane/agent/dispatcher.py', 'neutron/cmd/sanity/checks.py', 'neutron/plugins/embrane/agent/operations/router_operations.py', 'neutron/tests/unit/api/test_extensions.py', 'neutron/tests/tempest/common/accounts.py', 'neutron/agent/linux/ip_lib.py', 'neutron/api/v2/resource.py', 'neutron/tests/unit/agent/linux/test_ip_lib.py', 'neutron/tests/functional/agent/l3/test_namespace_manager.py', 'neutron/tests/unit/test_manager.py', 'neutron/agent/linux/utils.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/fe6654b25044de7d7d15573c689a0f003c018e99', 'message': 'Use string exception casting everywhere\n\nInstead of the deprecated ""message"" member access,\ncasting to a string invokes the __str__ method of the exception\nthat is wired to return the message\n\nAdded a test of the failure cases of IpRouteCommand::delete_gateway\nbecause they were missing\n\nRunning unit and functional tests locally no longer shows the warning\nreported in the bug.\n\nChange-Id: Ia79f526aa973ece1145615d65349f860aa3fd465\nCloses-Bug: #1466542\n'}]",17,193245,fe6654b25044de7d7d15573c689a0f003c018e99,80,27,4,16934,,,0,"Use string exception casting everywhere

Instead of the deprecated ""message"" member access,
casting to a string invokes the __str__ method of the exception
that is wired to return the message

Added a test of the failure cases of IpRouteCommand::delete_gateway
because they were missing

Running unit and functional tests locally no longer shows the warning
reported in the bug.

Change-Id: Ia79f526aa973ece1145615d65349f860aa3fd465
Closes-Bug: #1466542
",git fetch https://review.opendev.org/openstack/neutron refs/changes/45/193245/2 && git format-patch -1 --stdout FETCH_HEAD,['neutron/api/v2/resource.py'],1,45d390ca874ffab7d901b3ed209152d701371655,(detached," translatable.message = localize(str(translatable), locale)"," translatable.message = localize(translatable.message, locale)",1,1
openstack%2Fmanila~master~If0ce0ded60d40cad024eb90b85c160322b57b133,openstack/manila,master,If0ce0ded60d40cad024eb90b85c160322b57b133,Updated from global requirements,MERGED,2015-06-24 14:40:00.000000000,2015-06-24 19:52:11.000000000,2015-06-24 19:52:10.000000000,"[{'_account_id': 3}, {'_account_id': 2417}, {'_account_id': 10621}, {'_account_id': 11047}, {'_account_id': 11811}]","[{'number': 1, 'created': '2015-06-24 14:40:00.000000000', 'files': ['requirements.txt'], 'web_link': 'https://opendev.org/openstack/manila/commit/9d78f9ca36e4fc25a4ebe01c78781c126f7ea055', 'message': 'Updated from global requirements\n\nChange-Id: If0ce0ded60d40cad024eb90b85c160322b57b133\n'}]",0,195114,9d78f9ca36e4fc25a4ebe01c78781c126f7ea055,9,5,1,11131,,,0,"Updated from global requirements

Change-Id: If0ce0ded60d40cad024eb90b85c160322b57b133
",git fetch https://review.opendev.org/openstack/manila refs/changes/14/195114/1 && git format-patch -1 --stdout FETCH_HEAD,['requirements.txt'],1,9d78f9ca36e4fc25a4ebe01c78781c126f7ea055,openstack/requirements,oslo.service>=0.1.0 # Apache-2.0oslo.concurrency>=2.1.0 # Apache-2.0,oslo.service>=0.1.0oslo.concurrency>=2.0.0 # Apache-2.0,2,2
openstack%2Frally~master~Ief9485f4dd7f8d2becdb2ebfd78cf29b411aece7,openstack/rally,master,Ief9485f4dd7f8d2becdb2ebfd78cf29b411aece7,install_rally.sh: permit absolute paths for sqlite db name,MERGED,2015-06-24 13:58:48.000000000,2015-06-24 19:49:57.000000000,2015-06-24 19:35:43.000000000,"[{'_account_id': 3}, {'_account_id': 6172}, {'_account_id': 6835}, {'_account_id': 9545}, {'_account_id': 11748}, {'_account_id': 14817}]","[{'number': 1, 'created': '2015-06-24 13:58:48.000000000', 'files': ['install_rally.sh'], 'web_link': 'https://opendev.org/openstack/rally/commit/aa74b5a5ae5f93112a7f179b221196d45ed7ee9b', 'message': ""install_rally.sh: permit absolute paths for sqlite db name\n\nIf the SQLite database name (--db-name) starts with a /, assume that\nit's an absolute path, instead of being relative to\n$RALLY_DATABASE_DIR (which is not configurable).\n\nChange-Id: Ief9485f4dd7f8d2becdb2ebfd78cf29b411aece7\n""}]",0,195090,aa74b5a5ae5f93112a7f179b221196d45ed7ee9b,11,6,1,11748,,,0,"install_rally.sh: permit absolute paths for sqlite db name

If the SQLite database name (--db-name) starts with a /, assume that
it's an absolute path, instead of being relative to
$RALLY_DATABASE_DIR (which is not configurable).

Change-Id: Ief9485f4dd7f8d2becdb2ebfd78cf29b411aece7
",git fetch https://review.opendev.org/openstack/rally refs/changes/90/195090/1 && git format-patch -1 --stdout FETCH_HEAD,['install_rally.sh'],1,aa74b5a5ae5f93112a7f179b221196d45ed7ee9b,dockerfile-overhaul,"if [ ""$DBTYPE"" = 'sqlite' ]; then if [ ""${DBNAME:0:1}"" = '/' ]; then DBCONNSTRING=""$DBTYPE:///$DBNAME"" else DBCONNSTRING=""$DBTYPE:///${RALLY_DATABASE_DIR}/${DBNAME}"" fi else","if [ ""$DBTYPE"" != 'sqlite' ] thenelse DBCONNSTRING=""$DBTYPE:///${RALLY_DATABASE_DIR}/${DBNAME}""",7,4
openstack%2Fneutron-specs~master~Ib8faac4238f2e0c4f7af0b37495c76402a349a89,openstack/neutron-specs,master,Ib8faac4238f2e0c4f7af0b37495c76402a349a89,"Lbaas, use Octavia as reference implementation",MERGED,2015-04-16 21:32:56.000000000,2015-06-24 19:48:23.000000000,2015-06-24 19:48:21.000000000,"[{'_account_id': 3}, {'_account_id': 105}, {'_account_id': 7448}, {'_account_id': 7787}, {'_account_id': 8179}, {'_account_id': 8645}, {'_account_id': 10273}, {'_account_id': 10850}, {'_account_id': 10980}, {'_account_id': 11628}, {'_account_id': 12403}, {'_account_id': 12999}]","[{'number': 1, 'created': '2015-04-16 21:32:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-specs/commit/5c569684fd007a00d39c8e605155defc363fa75e', 'message': 'Lbaas, use Octavia as reference implementation\n\nChange-Id: Ib8faac4238f2e0c4f7af0b37495c76402a349a89\n'}, {'number': 2, 'created': '2015-06-24 19:24:53.000000000', 'files': ['specs/liberty/lbaas-ref-octavia.rst'], 'web_link': 'https://opendev.org/openstack/neutron-specs/commit/509c1aff5a5e36b1202c2f8dd972c2f05fe9c7ef', 'message': 'Lbaas, use Octavia as reference implementation\n\nChange-Id: Ib8faac4238f2e0c4f7af0b37495c76402a349a89\n'}]",11,174616,509c1aff5a5e36b1202c2f8dd972c2f05fe9c7ef,20,12,2,10980,,,0,"Lbaas, use Octavia as reference implementation

Change-Id: Ib8faac4238f2e0c4f7af0b37495c76402a349a89
",git fetch https://review.opendev.org/openstack/neutron-specs refs/changes/16/174616/1 && git format-patch -1 --stdout FETCH_HEAD,['specs/liberty/lbaas-ref-octavia.rst'],1,5c569684fd007a00d39c8e605155defc363fa75e,bp/lbaas-ref-octavia,".. This work is licensed under a Creative Commons Attribution 3.0 Unported License. http://creativecommons.org/licenses/by/3.0/legalcode ============================================== Lbaas, use Octavia as reference implementation ============================================== https://blueprints.launchpad.net/neutron/+spec/lbaas-ref-octavia The lbaas team intends to replace the reference implementation with the service-vm like implementation provided by project octavia[1], which uses nova compute to provide scalability and HA features. Problem Description =================== The existing reference implementation does not scale well, does not handle HA, is fragile in the face of underlying host failures. Proposed Change =============== A neutron-lbaas octavia driver (or shim) will be added to neutron-lbaas, which will reference the controller/framework implemented by the octavia project[1]. The existing reference implementation, the namespace haproxy driver, will remain in the neutron-lbaas tree for Liberty, for upgrades. The default driver enabled in the neutron-lbaas.conf file will be octavia, a dependency on octavia will be added to the project requirements file, and packager's will have to install/deploy octavia as part of an lbaas install. The neutron-lbaas devstack plugin will start installing octavia automatically. Data Model Impact ----------------- None. REST API Impact --------------- None. Security Impact --------------- None. Notifications Impact -------------------- None. Other End User Impact --------------------- None. Performance Impact ------------------ None. IPv6 Impact ----------- None. Other Deployer Impact --------------------- Upgrades will have to manually choose to switch to Octavia. The old driver will continue to function. New installs will need to pull in and start Octavia. Developer Impact ---------------- None. Community Impact ---------------- The existing reference implementation is not well liked. Hopefully, this starts to change that perception. Alternatives ------------ One alternative is to continue to maintain the existing reference/agent driver, and keep Octavia present as an option. The extra maintenance cycles of keeping both drivers prime-time is less desirable by the lbaas team. Implementation ============== Assignee(s) ----------- Primary assignee: https://launchpad.net/~dougwig Other contributors: <launchpad-id or None> I'll put myself as a placeholder here, but I expect this list needs tweaking. Work Items ---------- - Octavia neutron-lbaas driver. - Tweak requirements. - Convert tests to stably run with octavia. - Modify devstack plugin Dependencies ============ * A working Octavia implemention. Testing ======= Existing tests will exercise the Octavia backend. Additional jobs will be added to continue testing the namespace/haproxy backend, until it is removed (schedule TBD.) Tempest Tests ------------- Same as existing. Functional Tests ---------------- Same as existing. API Tests --------- Same as existing. Documentation Impact ==================== User Documentation ------------------ References to the driver/config settings will need to be updated, as will documentation on how to check if the right agents are running/troubleshooting. Developer Documentation ----------------------- None. References ========== [1] https://github.com/stackforge/octavia ",,168,0
openstack%2Fopenstacksdk~master~Id9b97d67ac6745fe962a76ccd9c0e4f7cbed4a89,openstack/openstacksdk,master,Id9b97d67ac6745fe962a76ccd9c0e4f7cbed4a89,Remove namespace from network ext test,MERGED,2015-06-24 19:00:13.000000000,2015-06-24 19:45:23.000000000,2015-06-24 19:45:22.000000000,"[{'_account_id': 3}, {'_account_id': 8736}]","[{'number': 1, 'created': '2015-06-24 19:00:13.000000000', 'files': ['openstack/tests/functional/network/v2/test_extension.py'], 'web_link': 'https://opendev.org/openstack/openstacksdk/commit/bfd8d1126e771702dfe4869923927b8f4fb81ef1', 'message': 'Remove namespace from network ext test\n\nChange-Id: Id9b97d67ac6745fe962a76ccd9c0e4f7cbed4a89\n'}]",0,195268,bfd8d1126e771702dfe4869923927b8f4fb81ef1,7,2,1,8736,,,0,"Remove namespace from network ext test

Change-Id: Id9b97d67ac6745fe962a76ccd9c0e4f7cbed4a89
",git fetch https://review.opendev.org/openstack/openstacksdk refs/changes/68/195268/1 && git format-patch -1 --stdout FETCH_HEAD,['openstack/tests/functional/network/v2/test_extension.py'],1,bfd8d1126e771702dfe4869923927b8f4fb81ef1,netext,," self.assertIsInstance(ext.namespace, six.string_types)",0,1
openstack%2Fosprofiler~master~I311f694d2e2e92468d3345d0da3f550fffa560ee,openstack/osprofiler,master,I311f694d2e2e92468d3345d0da3f550fffa560ee,Various cleanups,MERGED,2014-11-17 20:58:52.000000000,2015-06-24 19:45:16.000000000,2015-06-24 19:45:15.000000000,"[{'_account_id': 3}, {'_account_id': 6172}]","[{'number': 1, 'created': '2014-11-17 20:58:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/osprofiler/commit/81364bd4c101a863ed949a8a0fcc0bbe5a8a038e', 'message': 'Various cleanups\n\nChange-Id: I311f694d2e2e92468d3345d0da3f550fffa560ee\n'}, {'number': 2, 'created': '2015-06-24 19:18:33.000000000', 'files': ['osprofiler/profiler.py', 'osprofiler/_utils.py', 'osprofiler/cmd/template.html', 'osprofiler/web.py', 'tests/cmd/test_shell.py'], 'web_link': 'https://opendev.org/openstack/osprofiler/commit/c2e9a73b3f0ffac4ccc66b37086639dfe6a7d82b', 'message': 'Various cleanups\n\nChange-Id: I311f694d2e2e92468d3345d0da3f550fffa560ee\n'}]",0,135080,c2e9a73b3f0ffac4ccc66b37086639dfe6a7d82b,15,2,2,6172,,,0,"Various cleanups

Change-Id: I311f694d2e2e92468d3345d0da3f550fffa560ee
",git fetch https://review.opendev.org/openstack/osprofiler refs/changes/80/135080/2 && git format-patch -1 --stdout FETCH_HEAD,"['osprofiler/profiler.py', 'osprofiler/_utils.py', 'osprofiler/cmd/template.html', 'osprofiler/web.py', 'tests/cmd/test_shell.py']",5,81364bd4c101a863ed949a8a0fcc0bbe5a8a038e,various_cleanups," ""OS_USERNAME"": ""username"", ""OS_USER_ID"": ""user_id"", ""OS_PASSWORD"": ""password"", ""OS_USER_DOMAIN_ID"": ""user_domain_id"", ""OS_USER_DOMAIN_NAME"": ""user_domain_name"", ""OS_PROJECT_DOMAIN_ID"": ""project_domain_id"", ""OS_PROJECT_DOMAIN_NAME"": ""project_domain_name"", ""OS_PROJECT_ID"": ""project_id"", ""OS_PROJECT_NAME"": ""project_name"", ""OS_TENANT_ID"": ""tenant_id"", ""OS_TENANT_NAME"": ""tenant_name"", ""OS_AUTH_URL"": ""http://127.0.0.1:5000/v3/"", ""OS_AUTH_TOKEN"": ""pass"", ""OS_CACERT"": ""/path/to/cacert"", ""OS_SERVICE_TYPE"": ""service_type"", ""OS_ENDPOINT_TYPE"": ""public"", ""OS_REGION_NAME"": ""test"" sys.modules[""ceilometerclient""] = self.ceiloclient self.addCleanup(sys.modules.pop, ""ceilometerclient"", None) ceilo_modules = [""client"", ""exc"", ""shell""] for module in ceilo_modules: sys.modules[""ceilometerclient.%s"" % module] = getattr( sys.modules.pop, ""ceilometerclient.%s"" % module, None) mock_shell.side_effect = exc.CommandError(""some_message"") self.assertEqual(""some_message\n"", sys.stdout.getvalue()) ""Expected: `osprofiler.cmd.exc.CommandError` is raised with "" ""message: '%s'."" % expected_message) sys.modules[""ceilometerclient""] = None sys.modules[""ceilometerclient.client""] = None sys.modules[""ceilometerclient.exc""] = None sys.modules[""ceilometerclient.shell""] = None ""trace show fake_uuid"".split()) ""info"": { ""started"": 0, ""finished"": 0, ""name"": ""total""}, ""children"": []} ""info"": { ""started"": 0, ""finished"": 0, ""name"": ""total""}, ""children"": []} ""info"": { ""started"": 0, ""finished"": 0, ""name"": ""total""}, ""children"": []}"," 'OS_USERNAME': 'username', 'OS_USER_ID': 'user_id', 'OS_PASSWORD': 'password', 'OS_USER_DOMAIN_ID': 'user_domain_id', 'OS_USER_DOMAIN_NAME': 'user_domain_name', 'OS_PROJECT_DOMAIN_ID': 'project_domain_id', 'OS_PROJECT_DOMAIN_NAME': 'project_domain_name', 'OS_PROJECT_ID': 'project_id', 'OS_PROJECT_NAME': 'project_name', 'OS_TENANT_ID': 'tenant_id', 'OS_TENANT_NAME': 'tenant_name', 'OS_AUTH_URL': 'http://127.0.0.1:5000/v3/', 'OS_AUTH_TOKEN': 'pass', 'OS_CACERT': '/path/to/cacert', 'OS_SERVICE_TYPE': 'service_type', 'OS_ENDPOINT_TYPE': 'public', 'OS_REGION_NAME': 'test' sys.modules['ceilometerclient'] = self.ceiloclient self.addCleanup(sys.modules.pop, 'ceilometerclient', None) ceilo_modules = ['client', 'exc', 'shell'] for module in ceilo_modules: sys.modules['ceilometerclient.%s' % module] = getattr( sys.modules.pop, 'ceilometerclient.%s' % module, None) mock_shell.side_effect = exc.CommandError('some_message') self.assertEqual('some_message\n', sys.stdout.getvalue()) 'Expected: `osprofiler.cmd.exc.CommandError` is raised with ' 'message: ""%s"".' % expected_message) sys.modules['ceilometerclient'] = None sys.modules['ceilometerclient.client'] = None sys.modules['ceilometerclient.exc'] = None sys.modules['ceilometerclient.shell'] = None 'trace show fake_uuid'.split()) 'info': { 'started': 0, 'finished': 0, 'name': 'total'}, 'children': []} 'info': { 'started': 0, 'finished': 0, 'name': 'total'}, 'children': []} 'info': { 'started': 0, 'finished': 0, 'name': 'total'}, 'children': []}",52,69
openstack%2Fkolla~master~Iefc2dfea4bf4ce2fa9a5d1f013594929d218b9fc,openstack/kolla,master,Iefc2dfea4bf4ce2fa9a5d1f013594929d218b9fc,Configure Heat service domain,MERGED,2015-06-22 19:09:34.000000000,2015-06-24 19:44:51.000000000,2015-06-24 19:44:50.000000000,"[{'_account_id': 3}, {'_account_id': 2834}, {'_account_id': 3098}, {'_account_id': 10428}]","[{'number': 1, 'created': '2015-06-22 19:09:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla/commit/17d2ebaca4eecd335a0b6fcede9f8f276de51179', 'message': 'Configure Heat service domain\n\nChange-Id: Iefc2dfea4bf4ce2fa9a5d1f013594929d218b9fc\nCloses-Bug: #1463970\n'}, {'number': 2, 'created': '2015-06-24 17:28:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla/commit/31d8828bd320537f1b5802559e84e0e717c4335e', 'message': 'Configure Heat service domain\n\nChange-Id: Iefc2dfea4bf4ce2fa9a5d1f013594929d218b9fc\nCloses-Bug: #1463970\n'}, {'number': 3, 'created': '2015-06-24 18:39:14.000000000', 'files': ['tools/genenv', 'docs/integration-guide.md', 'docker/common/heat/heat-base/config-heat.sh', 'docker/common/heat/heat-engine/start.sh'], 'web_link': 'https://opendev.org/openstack/kolla/commit/f23a35651e7ccb7aec9bd3e83cd9783ff79b1942', 'message': 'Configure Heat service domain\n\nChange-Id: Iefc2dfea4bf4ce2fa9a5d1f013594929d218b9fc\nCloses-Bug: #1463970\n'}]",6,194308,f23a35651e7ccb7aec9bd3e83cd9783ff79b1942,14,4,3,10428,,,0,"Configure Heat service domain

Change-Id: Iefc2dfea4bf4ce2fa9a5d1f013594929d218b9fc
Closes-Bug: #1463970
",git fetch https://review.opendev.org/openstack/kolla refs/changes/08/194308/1 && git format-patch -1 --stdout FETCH_HEAD,"['tools/genenv', 'docs/integration-guide.md', 'docker/common/heat/heat-base/config-heat.sh', 'docker/common/heat/heat-engine/start.sh']",4,17d2ebaca4eecd335a0b6fcede9f8f276de51179,bug/1463970,check_required_vars HEAT_DB_NAME HEAT_DB_USER HEAT_DB_PASSWORD HEAT_DOMAIN_PASSheat-keystone-setup-domain \ --stack-user-domain-name heat_user_domain \ --stack-domain-admin heat_domain_admin \ --stack-domain-admin-password ${HEAT_DOMAIN_PASS} ,check_required_vars HEAT_DB_NAME HEAT_DB_USER HEAT_DB_PASSWORD,18,2
openstack%2Fcue~master~I99ca8682a3a6cc2558c61e512a52bdde21d1b32a,openstack/cue,master,I99ca8682a3a6cc2558c61e512a52bdde21d1b32a,Drop use of 'oslo' namespace package,MERGED,2015-06-24 18:35:44.000000000,2015-06-24 19:44:49.000000000,2015-06-24 19:44:48.000000000,"[{'_account_id': 3}, {'_account_id': 10584}]","[{'number': 1, 'created': '2015-06-24 18:35:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cue/commit/6d9a4eb8fc5b9621c1c1d3f7700216185c0f4811', 'message': ""Drop use of 'oslo' namespace package\n\nThe Oslo libraries have moved all of their code out of the 'oslo'\nnamespace package into per-library packages. The namespace package was\nretained during kilo for backwards compatibility, but will be removed by\nthe liberty-2 milestone. This change removes the use of the namespace\npackage, replacing it with the new package names.\n\nThe patches in the libraries will be put on hold until application\npatches have landed, or L2, whichever comes first. At that point, new\nversions of the libraries without namespace packages will be released as\na major version update.\n\nPlease merge this patch, or an equivalent, before L2 to avoid problems\nwith those library releases.\n\nBlueprint: remove-namespace-packages\nhttps://blueprints.launchpad.net/oslo-incubator/+spec/remove-namespace-packages\n\nChange-Id: I99ca8682a3a6cc2558c61e512a52bdde21d1b32a\n""}, {'number': 2, 'created': '2015-06-24 18:53:39.000000000', 'files': ['cue/tests/functional/taskflow/test_service.py', 'cue/tests/unit/objects/test_objects.py', 'cue/openstack/common/periodic_task.py', 'cue/cmd/manage.py', 'cue/taskflow/__init__.py', 'cue/tests/unit/common/test_service.py', 'cue/openstack/common/log.py', 'cue/manage/broker.py', 'cue/api/__init__.py', 'cue/openstack/common/service.py', 'cue/tests/unit/manage/database/test_migration.py', 'cue/db/sqlalchemy/base.py', 'cue/manage/database.py', 'cue/openstack/common/lockutils.py', 'cue/taskflow/service.py', 'cue/db/sqlalchemy/models.py', 'cue/db/api.py', 'cue/tests/functional/api/v1/test_cluster.py', 'cue/common/service.py', 'cue/manage/taskflow.py', 'cue/api/controllers/v1/cluster.py', 'cue/openstack/common/eventlet_backdoor.py', 'cue/tests/functional/fixtures/database.py', 'cue/cmd/worker.py', 'cue/common/exception.py', 'cue/taskflow/client.py', 'cue/tests/unit/cmd/test_worker.py', 'cue/client.py', 'cue/api/app.py', 'cue/api/hooks.py', 'cue/openstack/common/processutils.py', 'cue/tests/functional/api/__init__.py', 'cue/tests/unit/cmd/test_manage.py', 'cue/tests/functional/base.py', 'cue/tests/functional/objects/test_cluster.py', 'cue/tests/functional/db/manage/database/test_migration.py', 'cue/cmd/api.py', 'cue/db/sqlalchemy/api.py', 'cue/api/config.py', 'cue/__init__.py', 'cue/objects/utils.py', 'cue/tests/functional/db/test_models.py', 'cue/common/policy.py', 'cue/tests/functional/utils.py', 'cue/tests/functional/taskflow/test_client.py', 'cue/openstack/common/imageutils.py'], 'web_link': 'https://opendev.org/openstack/cue/commit/fcec80be55d2100b1ac76416f04106bdb0e1586d', 'message': ""Drop use of 'oslo' namespace package\n\nThe Oslo libraries have moved all of their code out of the 'oslo'\nnamespace package into per-library packages. The namespace package was\nretained during kilo for backwards compatibility, but will be removed by\nthe liberty-2 milestone. This change removes the use of the namespace\npackage, replacing it with the new package names.\n\nThe patches in the libraries will be put on hold until application\npatches have landed, or L2, whichever comes first. At that point, new\nversions of the libraries without namespace packages will be released as\na major version update.\n\nPlease merge this patch, or an equivalent, before L2 to avoid problems\nwith those library releases.\n\nBlueprint: remove-namespace-packages\nhttps://blueprints.launchpad.net/oslo-incubator/+spec/remove-namespace-packages\n\nChange-Id: I99ca8682a3a6cc2558c61e512a52bdde21d1b32a\n""}]",0,195258,fcec80be55d2100b1ac76416f04106bdb0e1586d,7,2,2,2472,,,0,"Drop use of 'oslo' namespace package

The Oslo libraries have moved all of their code out of the 'oslo'
namespace package into per-library packages. The namespace package was
retained during kilo for backwards compatibility, but will be removed by
the liberty-2 milestone. This change removes the use of the namespace
package, replacing it with the new package names.

The patches in the libraries will be put on hold until application
patches have landed, or L2, whichever comes first. At that point, new
versions of the libraries without namespace packages will be released as
a major version update.

Please merge this patch, or an equivalent, before L2 to avoid problems
with those library releases.

Blueprint: remove-namespace-packages
https://blueprints.launchpad.net/oslo-incubator/+spec/remove-namespace-packages

Change-Id: I99ca8682a3a6cc2558c61e512a52bdde21d1b32a
",git fetch https://review.opendev.org/openstack/cue refs/changes/58/195258/2 && git format-patch -1 --stdout FETCH_HEAD,"['cue/tests/functional/taskflow/test_service.py', 'cue/tests/unit/objects/test_objects.py', 'cue/openstack/common/periodic_task.py', 'cue/cmd/manage.py', 'cue/taskflow/__init__.py', 'cue/tests/unit/common/test_service.py', 'cue/openstack/common/log.py', 'cue/manage/broker.py', 'cue/api/__init__.py', 'cue/openstack/common/service.py', 'cue/tests/unit/manage/database/test_migration.py', 'cue/db/sqlalchemy/base.py', 'cue/manage/database.py', 'cue/openstack/common/lockutils.py', 'cue/taskflow/service.py', 'cue/db/sqlalchemy/models.py', 'cue/db/api.py', 'cue/tests/functional/api/v1/test_cluster.py', 'cue/common/service.py', 'cue/manage/taskflow.py', 'cue/api/controllers/v1/cluster.py', 'cue/openstack/common/eventlet_backdoor.py', 'cue/tests/functional/fixtures/database.py', 'cue/cmd/worker.py', 'cue/common/exception.py', 'cue/taskflow/client.py', 'cue/tests/unit/cmd/test_worker.py', 'cue/client.py', 'cue/api/app.py', 'cue/api/hooks.py', 'cue/openstack/common/processutils.py', 'cue/tests/functional/api/__init__.py', 'cue/tests/unit/cmd/test_manage.py', 'cue/tests/functional/base.py', 'cue/tests/functional/objects/test_cluster.py', 'cue/tests/functional/db/manage/database/test_migration.py', 'cue/cmd/api.py', 'cue/db/sqlalchemy/api.py', 'cue/api/config.py', 'cue/__init__.py', 'cue/objects/utils.py', 'cue/tests/functional/db/test_models.py', 'cue/common/policy.py', 'cue/tests/functional/utils.py', 'cue/tests/functional/taskflow/test_client.py', 'cue/openstack/common/imageutils.py']",46,6d9a4eb8fc5b9621c1c1d3f7700216185c0f4811,bp/remove-namespace-packages,from oslo_utils import strutils,from oslo.utils import strutils,69,69
openstack%2Fneutron~master~Ic39feee0248f2ffabdba26f3779ab40a8f3838e6,openstack/neutron,master,Ic39feee0248f2ffabdba26f3779ab40a8f3838e6,Override opportunistic database tests to PyMySQL,MERGED,2015-06-18 19:09:33.000000000,2015-06-24 19:39:08.000000000,2015-06-24 19:39:06.000000000,"[{'_account_id': 3}, {'_account_id': 5170}, {'_account_id': 5263}, {'_account_id': 6524}, {'_account_id': 7249}, {'_account_id': 8124}, {'_account_id': 9681}, {'_account_id': 9682}, {'_account_id': 9787}, {'_account_id': 9845}, {'_account_id': 10121}, {'_account_id': 10153}, {'_account_id': 10184}, {'_account_id': 10387}, {'_account_id': 14323}, {'_account_id': 14571}, {'_account_id': 15296}, {'_account_id': 15894}]","[{'number': 1, 'created': '2015-06-18 19:09:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/d6819785a9c4a54635e59e71578c0e138aa115e6', 'message': 'Override opportunistic database tests to PyMySQL\n\nSet the OS_TEST_DBAPI_ADMIN_CONNECTION override variable so that\noslo.db opportunistic detection will know to use PyMySQL until\nI12b32dc097a121bd43991bc38dd4d289b65e86c1 makes it the default\nbehavior.\n\nChange-Id: Ic39feee0248f2ffabdba26f3779ab40a8f3838e6\nCo-Authored-By: Victor Sergeyev <vsergeyev@mirantis.com>\n'}, {'number': 2, 'created': '2015-06-22 21:00:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/8343f9d3e578fa0050adaf5935eb759d33dc3a60', 'message': 'Override opportunistic database tests to PyMySQL\n\nSet the OS_TEST_DBAPI_ADMIN_CONNECTION override variable so that\noslo.db opportunistic detection will know to use PyMySQL until\nI12b32dc097a121bd43991bc38dd4d289b65e86c1 makes it the default\nbehavior.\n\nThis change removes previous code[1] enabling PyMySQL use.\n\n[1] Ic5c1d12ab75443e1cc290a7447eeb4b452b4a9dd\n\nChange-Id: Ic39feee0248f2ffabdba26f3779ab40a8f3838e6\nCo-Authored-By: Victor Sergeyev <vsergeyev@mirantis.com>\nCo-Authored-By: Cedric Brandily <zzelle@gmail.com>\n'}, {'number': 3, 'created': '2015-06-23 08:48:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/27262fd51934bb2c2133e94d8ece68a79c9e4e82', 'message': 'Override opportunistic database tests to PyMySQL\n\nSet the OS_TEST_DBAPI_ADMIN_CONNECTION override variable so that\noslo.db opportunistic detection will know to use PyMySQL until\nI12b32dc097a121bd43991bc38dd4d289b65e86c1 makes it the default\nbehavior.\n\nThis change removes previous code[1] enabling PyMySQL use.\n\n[1] Ic5c1d12ab75443e1cc290a7447eeb4b452b4a9dd\n\nChange-Id: Ic39feee0248f2ffabdba26f3779ab40a8f3838e6\nCo-Authored-By: Victor Sergeyev <vsergeyev@mirantis.com>\nCo-Authored-By: Cedric Brandily <zzelle@gmail.com>\n'}, {'number': 4, 'created': '2015-06-23 11:12:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/78c030cce7fe5d311add08a4f7a8a45ce624919b', 'message': 'Override opportunistic database tests to PyMySQL\n\nSet the OS_TEST_DBAPI_ADMIN_CONNECTION override variable so that\noslo.db opportunistic detection will know to use PyMySQL until\nI12b32dc097a121bd43991bc38dd4d289b65e86c1 makes it the default\nbehavior.\n\nThis change removes previous code[1] enabling PyMySQL use.\n\n[1] Ic5c1d12ab75443e1cc290a7447eeb4b452b4a9dd\n\nChange-Id: Ic39feee0248f2ffabdba26f3779ab40a8f3838e6\nCo-Authored-By: Victor Sergeyev <vsergeyev@mirantis.com>\nCo-Authored-By: Cedric Brandily <zzelle@gmail.com>\n'}, {'number': 5, 'created': '2015-06-23 19:02:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/b316c03645edd13a8fdac43c966acb71d1daa5b9', 'message': 'Override opportunistic database tests to PyMySQL\n\nSet the OS_TEST_DBAPI_ADMIN_CONNECTION override variable so that\noslo.db opportunistic detection will know to use PyMySQL until\nI12b32dc097a121bd43991bc38dd4d289b65e86c1 makes it the default\nbehavior.\n\nThis change removes previous code[1] enabling PyMySQL use.\n\n[1] Ic5c1d12ab75443e1cc290a7447eeb4b452b4a9dd\n\nChange-Id: Ic39feee0248f2ffabdba26f3779ab40a8f3838e6\nCo-Authored-By: Victor Sergeyev <vsergeyev@mirantis.com>\nCo-Authored-By: Cedric Brandily <zzelle@gmail.com>\n'}, {'number': 6, 'created': '2015-06-23 19:04:31.000000000', 'files': ['tox.ini', 'neutron/tests/common/base.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/d23a59f1c808c50575f49f9291bd70c6b3a5797a', 'message': 'Override opportunistic database tests to PyMySQL\n\nSet the OS_TEST_DBAPI_ADMIN_CONNECTION override variable so that\noslo.db opportunistic detection will know to use PyMySQL until\nI12b32dc097a121bd43991bc38dd4d289b65e86c1 makes it the default\nbehavior.\n\nThis change removes previous code[1] enabling PyMySQL use.\n\n[1] Ic5c1d12ab75443e1cc290a7447eeb4b452b4a9dd\n\nChange-Id: Ic39feee0248f2ffabdba26f3779ab40a8f3838e6\nCo-Authored-By: Victor Sergeyev <vsergeyev@mirantis.com>\nCo-Authored-By: Cedric Brandily <zzelle@gmail.com>\n'}]",8,193262,d23a59f1c808c50575f49f9291bd70c6b3a5797a,92,18,6,5263,,,0,"Override opportunistic database tests to PyMySQL

Set the OS_TEST_DBAPI_ADMIN_CONNECTION override variable so that
oslo.db opportunistic detection will know to use PyMySQL until
I12b32dc097a121bd43991bc38dd4d289b65e86c1 makes it the default
behavior.

This change removes previous code[1] enabling PyMySQL use.

[1] Ic5c1d12ab75443e1cc290a7447eeb4b452b4a9dd

Change-Id: Ic39feee0248f2ffabdba26f3779ab40a8f3838e6
Co-Authored-By: Victor Sergeyev <vsergeyev@mirantis.com>
Co-Authored-By: Cedric Brandily <zzelle@gmail.com>
",git fetch https://review.opendev.org/openstack/neutron refs/changes/62/193262/2 && git format-patch -1 --stdout FETCH_HEAD,['tox.ini'],1,d6819785a9c4a54635e59e71578c0e138aa115e6,pymysql-switch, OS_TEST_DBAPI_ADMIN_CONNECTION=mysql+pymysql://openstack_citest:openstack_citest@localhost/;postgresql://openstack_citest:openstack_citest@localhost/postgres;sqlite://,,1,0
openstack%2Frally~master~I5fb46be697c9ae1450b323a4e632ab13d7600998,openstack/rally,master,I5fb46be697c9ae1450b323a4e632ab13d7600998,[Heat] create-snapshot-restore-delete stack scenario,MERGED,2015-04-30 12:22:24.000000000,2015-06-24 19:37:28.000000000,2015-06-24 19:37:27.000000000,"[{'_account_id': 3}, {'_account_id': 6172}, {'_account_id': 8507}, {'_account_id': 10475}, {'_account_id': 11748}, {'_account_id': 13555}, {'_account_id': 13609}, {'_account_id': 14676}, {'_account_id': 14817}]","[{'number': 1, 'created': '2015-04-30 12:22:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/f8249e0a39633b7d43af95e1e3583a682609810f', 'message': 'Add create-snapshot-restore-delete stack scenario\n\nThe patch adds rally scenario that tests the following\nsequence of actions for Heat:\n1) create stack\n2) create stack snapshot\n3) restore stack from snapshot\n4) delete stack\n\nChange-Id: I5fb46be697c9ae1450b323a4e632ab13d7600998\n'}, {'number': 2, 'created': '2015-05-12 10:40:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/0b8ce974c063ac76c19b63f21b4b41a500f3a808', 'message': 'Add create-snapshot-restore-delete stack scenario\n\nThe patch adds rally scenario that tests the following\nsequence of actions for Heat:\n1) create stack\n2) create stack snapshot\n3) restore stack from snapshot\n4) delete stack\n\nChange-Id: I5fb46be697c9ae1450b323a4e632ab13d7600998\n'}, {'number': 3, 'created': '2015-05-12 11:21:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/381c2721d4e7702b509e291fd0ad45f43520c587', 'message': 'Add create-snapshot-restore-delete stack scenario\n\nThe patch adds rally scenario that tests the following\nsequence of actions for Heat:\n1) create stack\n2) create stack snapshot\n3) restore stack from snapshot\n4) delete stack\n\nChange-Id: I5fb46be697c9ae1450b323a4e632ab13d7600998\n'}, {'number': 4, 'created': '2015-05-13 09:09:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/1357fdc7cc16ec570a1da4503e653a35380d5c57', 'message': 'Add create-snapshot-restore-delete stack scenario\n\nThe patch adds rally scenario that tests the following\nsequence of actions for Heat:\n1) create stack\n2) create stack snapshot\n3) restore stack from snapshot\n4) delete stack\n\nChange-Id: I5fb46be697c9ae1450b323a4e632ab13d7600998\n'}, {'number': 5, 'created': '2015-05-27 09:33:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/612581d048603cd4dc732feeff3e3edae62739b8', 'message': 'Add create-snapshot-restore-delete stack scenario\n\nThe patch adds rally scenario that tests the following\nsequence of actions for Heat:\n1) create stack\n2) create stack snapshot\n3) restore stack from snapshot\n4) delete stack\n\nChange-Id: I5fb46be697c9ae1450b323a4e632ab13d7600998\n'}, {'number': 6, 'created': '2015-06-02 08:05:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/4786d6461264857239ff55f405e1179150718a9b', 'message': 'heat: create-snapshot-restore-delete stack scenario\n\nThe patch adds rally scenario that tests the following\nsequence of actions for Heat:\n1) create stack\n2) create stack snapshot\n3) restore stack from snapshot\n4) delete stack\n\nChange-Id: I5fb46be697c9ae1450b323a4e632ab13d7600998\n'}, {'number': 7, 'created': '2015-06-02 10:41:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/87bed5ac9955b8515e84e2c9a7077466a5a4c402', 'message': '[Heat] create-snapshot-restore-delete stack scenario\n\nThe patch adds rally scenario that tests the following\nsequence of actions for Heat:\n1) create stack\n2) create stack snapshot\n3) restore stack from snapshot\n4) delete stack\n\nChange-Id: I5fb46be697c9ae1450b323a4e632ab13d7600998\n'}, {'number': 8, 'created': '2015-06-03 08:10:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/58e729490491571cd35fc900aa25eb41fa7cce97', 'message': '[Heat] create-snapshot-restore-delete stack scenario\n\nThe patch adds rally scenario that tests the following\nsequence of actions for Heat:\n1) create stack\n2) create stack snapshot\n3) restore stack from snapshot\n4) delete stack\n\nChange-Id: I5fb46be697c9ae1450b323a4e632ab13d7600998\n'}, {'number': 9, 'created': '2015-06-04 09:53:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/e5e0f69d43837188bf52a61830e85c41d3391aa9', 'message': '[Heat] create-snapshot-restore-delete stack scenario\n\nThe patch adds rally scenario that tests the following\nsequence of actions for Heat:\n1) create stack\n2) create stack snapshot\n3) restore stack from snapshot\n4) delete stack\n\nChange-Id: I5fb46be697c9ae1450b323a4e632ab13d7600998\n'}, {'number': 10, 'created': '2015-06-04 10:05:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/b76edd5a12161b3a80f12118b7ece852377c6ab6', 'message': '[Heat] create-snapshot-restore-delete stack scenario\n\nThe patch adds rally scenario that tests the following\nsequence of actions for Heat:\n1) create stack\n2) create stack snapshot\n3) restore stack from snapshot\n4) delete stack\n\nChange-Id: I5fb46be697c9ae1450b323a4e632ab13d7600998\n'}, {'number': 11, 'created': '2015-06-05 08:04:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/74b396f19dc027119073fee5d6102dfae151502d', 'message': '[Heat] create-snapshot-restore-delete stack scenario\n\nThe patch adds rally scenario that tests the following\nsequence of actions for Heat:\n1) create stack\n2) create stack snapshot\n3) restore stack from snapshot\n4) delete stack\n\nChange-Id: I5fb46be697c9ae1450b323a4e632ab13d7600998\n'}, {'number': 12, 'created': '2015-06-05 09:52:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/ea9e8388818f99c2a65410bfe5a1d6ccdfc11af1', 'message': '[Heat] create-snapshot-restore-delete stack scenario\n\nThe patch adds rally scenario that tests the following\nsequence of actions for Heat:\n1) create stack\n2) create stack snapshot\n3) restore stack from snapshot\n4) delete stack\n\nChange-Id: I5fb46be697c9ae1450b323a4e632ab13d7600998\n'}, {'number': 13, 'created': '2015-06-08 12:14:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/64c7596ddbbee4bf7cde11541b0a94f2da14d4e9', 'message': '[Heat] create-snapshot-restore-delete stack scenario\n\nThe patch adds rally scenario that tests the following\nsequence of actions for Heat:\n1) create stack\n2) create stack snapshot\n3) restore stack from snapshot\n4) delete stack\n\nChange-Id: I5fb46be697c9ae1450b323a4e632ab13d7600998\n'}, {'number': 14, 'created': '2015-06-08 14:20:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/0dee568ba0cd07b34423fa6f08413e1c468732ed', 'message': '[Heat] create-snapshot-restore-delete stack scenario\n\nThe patch adds rally scenario that tests the following\nsequence of actions for Heat:\n1) create stack\n2) create stack snapshot\n3) restore stack from snapshot\n4) delete stack\n\nChange-Id: I5fb46be697c9ae1450b323a4e632ab13d7600998\n'}, {'number': 15, 'created': '2015-06-08 16:12:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/1fc6868a6150ba3493cacd391f335ec06c338bfd', 'message': '[Heat] create-snapshot-restore-delete stack scenario\n\nThe patch adds rally scenario that tests the following\nsequence of actions for Heat:\n1) create stack\n2) create stack snapshot\n3) restore stack from snapshot\n4) delete stack\n\nChange-Id: I5fb46be697c9ae1450b323a4e632ab13d7600998\n'}, {'number': 16, 'created': '2015-06-15 15:39:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/973af49b2ecd8cfa1698c9d4215781be6537192a', 'message': '[Heat] create-snapshot-restore-delete stack scenario\n\nThe patch adds rally scenario that tests the following\nsequence of actions for Heat:\n1) create stack\n2) create stack snapshot\n3) restore stack from snapshot\n4) delete stack\n\nChange-Id: I5fb46be697c9ae1450b323a4e632ab13d7600998\n'}, {'number': 17, 'created': '2015-06-17 12:50:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/cf439bd2a39e853df491432dcd8456f524346942', 'message': '[Heat] create-snapshot-restore-delete stack scenario\n\nThe patch adds rally scenario that tests the following\nsequence of actions for Heat:\n1) create stack\n2) create stack snapshot\n3) restore stack from snapshot\n4) delete stack\n\nChange-Id: I5fb46be697c9ae1450b323a4e632ab13d7600998\n'}, {'number': 18, 'created': '2015-06-17 17:03:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/7a20bdeafe0e95e12726c4a1671415d74dc054ff', 'message': '[Heat] create-snapshot-restore-delete stack scenario\n\nThe patch adds rally scenario that tests the following\nsequence of actions for Heat:\n1) create stack\n2) create stack snapshot\n3) restore stack from snapshot\n4) delete stack\n\nChange-Id: I5fb46be697c9ae1450b323a4e632ab13d7600998\n'}, {'number': 19, 'created': '2015-06-19 10:32:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/deb1622aff437eeac661b2344f455bc55b63ce68', 'message': '[Heat] create-snapshot-restore-delete stack scenario\n\nThe patch adds rally scenario that tests the following\nsequence of actions for Heat:\n1) create stack\n2) create stack snapshot\n3) restore stack from snapshot\n4) delete stack\n\nChange-Id: I5fb46be697c9ae1450b323a4e632ab13d7600998\n'}, {'number': 20, 'created': '2015-06-23 09:17:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/dc4bca9e97763ee5fc825ded0ed466d6c26a5e36', 'message': '[Heat] create-snapshot-restore-delete stack scenario\n\nThe patch adds rally scenario that tests the following\nsequence of actions for Heat:\n1) create stack\n2) create stack snapshot\n3) restore stack from snapshot\n4) delete stack\n\nChange-Id: I5fb46be697c9ae1450b323a4e632ab13d7600998\n'}, {'number': 21, 'created': '2015-06-23 13:15:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/cd56d90e91f0a52bbfeaebbe5b915f08a9803622', 'message': '[Heat] create-snapshot-restore-delete stack scenario\n\nThe patch adds rally scenario that tests the following\nsequence of actions for Heat:\n1) create stack\n2) create stack snapshot\n3) restore stack from snapshot\n4) delete stack\n\nChange-Id: I5fb46be697c9ae1450b323a4e632ab13d7600998\n'}, {'number': 22, 'created': '2015-06-23 16:16:56.000000000', 'files': ['etc/rally/rally.conf.sample', 'rally-jobs/heat.yaml', 'samples/tasks/scenarios/heat/create-snapshot-restore-delete-stack.yaml', 'tests/unit/plugins/openstack/scenarios/heat/test_utils.py', 'tests/unit/plugins/openstack/scenarios/heat/test_stacks.py', 'rally/plugins/openstack/scenarios/heat/utils.py', 'rally/plugins/openstack/scenarios/heat/stacks.py', 'samples/tasks/scenarios/heat/create-snapshot-restore-delete-stack.json', 'rally-jobs/rally.yaml'], 'web_link': 'https://opendev.org/openstack/rally/commit/35e0a5b8198fe3b42841a682ea8ef2bfb8452ca6', 'message': '[Heat] create-snapshot-restore-delete stack scenario\n\nThe patch adds rally scenario that tests the following\nsequence of actions for Heat:\n1) create stack\n2) create stack snapshot\n3) restore stack from snapshot\n4) delete stack\n\nChange-Id: I5fb46be697c9ae1450b323a4e632ab13d7600998\n'}]",36,179037,35e0a5b8198fe3b42841a682ea8ef2bfb8452ca6,103,9,22,14676,,,0,"[Heat] create-snapshot-restore-delete stack scenario

The patch adds rally scenario that tests the following
sequence of actions for Heat:
1) create stack
2) create stack snapshot
3) restore stack from snapshot
4) delete stack

Change-Id: I5fb46be697c9ae1450b323a4e632ab13d7600998
",git fetch https://review.opendev.org/openstack/rally refs/changes/37/179037/15 && git format-patch -1 --stdout FETCH_HEAD,"['rally/benchmark/scenarios/heat/utils.py', 'samples/tasks/scenarios/heat/create-snapshot-restore-delete-stack.yaml', 'tests/unit/benchmark/scenarios/heat/test_utils.py', 'rally-jobs/unstable-neutron.yaml', 'rally/benchmark/scenarios/heat/stacks.py', 'tests/unit/benchmark/scenarios/heat/test_stacks.py', 'samples/tasks/scenarios/heat/create-snapshot-restore-delete-stack.json']",7,f8249e0a39633b7d43af95e1e3583a682609810f,better-scenario-fixtures,"{ ""HeatStacks.create_snapshot_restore_delete_stack"": [ { ""args"": { ""template_path"": ""templates/random_strings.yaml.template"" }, ""runner"": { ""type"": ""constant"", ""times"": 10, ""concurrency"": 2 }, ""context"": { ""users"": { ""tenants"": 3, ""users_per_tenant"": 2 } } } ] } ",,187,0
openstack%2Fsahara~master~Icc2306b88e35bc95d0c9ce1169e3f96b148d9725,openstack/sahara,master,Icc2306b88e35bc95d0c9ce1169e3f96b148d9725,Switch to oslo.service,MERGED,2015-06-23 13:52:49.000000000,2015-06-24 19:35:11.000000000,2015-06-24 19:35:09.000000000,"[{'_account_id': 3}, {'_account_id': 6116}, {'_account_id': 6786}, {'_account_id': 7213}, {'_account_id': 7710}, {'_account_id': 8911}, {'_account_id': 9664}, {'_account_id': 12038}, {'_account_id': 13662}, {'_account_id': 13665}]","[{'number': 1, 'created': '2015-06-23 13:52:49.000000000', 'files': ['sahara/service/periodic.py', 'sahara/openstack/common/threadgroup.py', 'tools/config/config-generator.sahara.conf', 'requirements.txt', 'sahara/openstack/common/systemd.py', 'sahara/utils/wsgi.py', 'sahara/openstack/common/sslutils.py', 'openstack-common.conf', 'sahara/openstack/common/periodic_task.py', 'sahara/openstack/common/loopingcall.py', 'sahara/main.py'], 'web_link': 'https://opendev.org/openstack/sahara/commit/197d4a716bb6b8cd8e6bc584897d816d816b641b', 'message': 'Switch to oslo.service\n\noslo.service has graduated, so sahara should consume it.\n\nChange-Id: Icc2306b88e35bc95d0c9ce1169e3f96b148d9725\nCloses-Bug: #1466851\n'}]",0,194667,197d4a716bb6b8cd8e6bc584897d816d816b641b,17,10,1,8911,,,0,"Switch to oslo.service

oslo.service has graduated, so sahara should consume it.

Change-Id: Icc2306b88e35bc95d0c9ce1169e3f96b148d9725
Closes-Bug: #1466851
",git fetch https://review.opendev.org/openstack/sahara refs/changes/67/194667/1 && git format-patch -1 --stdout FETCH_HEAD,"['sahara/openstack/common/threadgroup.py', 'sahara/service/periodic.py', 'requirements.txt', 'tools/config/config-generator.sahara.conf', 'sahara/openstack/common/systemd.py', 'sahara/utils/wsgi.py', 'sahara/openstack/common/sslutils.py', 'openstack-common.conf', 'sahara/openstack/common/periodic_task.py', 'sahara/openstack/common/loopingcall.py', 'sahara/main.py']",11,197d4a716bb6b8cd8e6bc584897d816d816b641b,bug/1466851,from oslo_service import systemd,from sahara.openstack.common import systemd,12,728
openstack%2Fneutron~master~I99184f7375571fb8569a24ba04ae267108f5da08,openstack/neutron,master,I99184f7375571fb8569a24ba04ae267108f5da08,Extend default setenv instead of replacing it in tox.ini,MERGED,2015-06-23 19:02:33.000000000,2015-06-24 19:34:59.000000000,2015-06-24 19:34:57.000000000,"[{'_account_id': 3}, {'_account_id': 2035}, {'_account_id': 2874}, {'_account_id': 5170}, {'_account_id': 6524}, {'_account_id': 7016}, {'_account_id': 7249}, {'_account_id': 8124}, {'_account_id': 8645}, {'_account_id': 9681}, {'_account_id': 9682}, {'_account_id': 9787}, {'_account_id': 9845}, {'_account_id': 10153}, {'_account_id': 10184}, {'_account_id': 10387}, {'_account_id': 14323}, {'_account_id': 14571}, {'_account_id': 14605}]","[{'number': 1, 'created': '2015-06-23 19:02:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/f753be322a05b1223497f53f40ab78d679914d12', 'message': 'Extend default setenv instead of replacing it in tox.ini\n\nSome tox jobs[1] define their own setenv without extending/referencing\ndefault setenv, it disallows to define environment variables shared by\nall jobs. This change updates previous jobs[1] in order to extend\ninstead of replacing default setenv and enable global environement\nvariables (used in daughter change).\n\nOne remark, this change sets VIRTUAL_ENV environment variable in updated\njobs[1] but it has no effect on them.\n\n[1] (dsvm-)functional, (dsvm-)fullstack and api jobs\n\nCloses-Bug: #1468059\nChange-Id: I99184f7375571fb8569a24ba04ae267108f5da08\n'}, {'number': 2, 'created': '2015-06-23 19:04:31.000000000', 'files': ['tox.ini'], 'web_link': 'https://opendev.org/openstack/neutron/commit/04d44cee63f3fbba45956abd28f325d5ac3ca2d9', 'message': 'Extend default setenv instead of replacing it in tox.ini\n\nSome tox jobs[1] define their own setenv without extending/referencing\ndefault setenv, it disallows to define environment variables shared by\nall jobs. This change updates previous jobs[1] in order to extend\ninstead of replacing default setenv and enable global environement\nvariables (used in daughter change).\n\nOne remark, this change sets VIRTUAL_ENV environment variable in updated\njobs[1] but it has no effect on them.\n\n[1] (dsvm-)functional, (dsvm-)fullstack and api jobs\n\nCloses-Bug: #1468059\nChange-Id: I99184f7375571fb8569a24ba04ae267108f5da08\n'}]",2,194785,04d44cee63f3fbba45956abd28f325d5ac3ca2d9,37,19,2,8124,,,0,"Extend default setenv instead of replacing it in tox.ini

Some tox jobs[1] define their own setenv without extending/referencing
default setenv, it disallows to define environment variables shared by
all jobs. This change updates previous jobs[1] in order to extend
instead of replacing default setenv and enable global environement
variables (used in daughter change).

One remark, this change sets VIRTUAL_ENV environment variable in updated
jobs[1] but it has no effect on them.

[1] (dsvm-)functional, (dsvm-)fullstack and api jobs

Closes-Bug: #1468059
Change-Id: I99184f7375571fb8569a24ba04ae267108f5da08
",git fetch https://review.opendev.org/openstack/neutron refs/changes/85/194785/2 && git format-patch -1 --stdout FETCH_HEAD,['tox.ini'],1,f753be322a05b1223497f53f40ab78d679914d12,bug/1468059,setenv = {[testenv]setenv} OS_TEST_PATH=./neutron/tests/apisetenv = {[testenv]setenv} OS_TEST_PATH=./neutron/tests/functionalsetenv = {[testenv]setenv} OS_TEST_PATH=./neutron/tests/functionalsetenv = {[testenv]setenv} OS_TEST_PATH=./neutron/tests/fullstacksetenv = {[testenv]setenv} OS_TEST_PATH=./neutron/tests/fullstack,setenv = OS_TEST_PATH=./neutron/tests/apisetenv = OS_TEST_PATH=./neutron/tests/functionalsetenv = OS_TEST_PATH=./neutron/tests/functionalsetenv = OS_TEST_PATH=./neutron/tests/fullstacksetenv = OS_TEST_PATH=./neutron/tests/fullstack,10,5
openstack%2Fneutron~master~I1ec786754467fc9039d2276f084f1bceaab15635,openstack/neutron,master,I1ec786754467fc9039d2276f084f1bceaab15635,Bulk move methods to ipam_backend_mixin.py,MERGED,2015-06-23 09:28:20.000000000,2015-06-24 19:34:46.000000000,2015-06-24 19:34:43.000000000,"[{'_account_id': 3}, {'_account_id': 2874}, {'_account_id': 5170}, {'_account_id': 5948}, {'_account_id': 7448}, {'_account_id': 7715}, {'_account_id': 8976}, {'_account_id': 9008}, {'_account_id': 9681}, {'_account_id': 9682}, {'_account_id': 9787}, {'_account_id': 9845}, {'_account_id': 10121}, {'_account_id': 10153}, {'_account_id': 10184}, {'_account_id': 10386}, {'_account_id': 10387}, {'_account_id': 10692}, {'_account_id': 12912}, {'_account_id': 13768}, {'_account_id': 14323}, {'_account_id': 14571}, {'_account_id': 15296}]","[{'number': 1, 'created': '2015-06-23 09:28:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/bd24ed604afe1e22b98a653facc4bc3e9fb7c779', 'message': 'Bulk move methods to ipam_backend_mixin.py\n\nipam_backend_mixin contains methods common for both backends:\npluggable and non-pluggable, so moving methods to make them accessible\nby backends.\nNext methods were moved from db_base_plugin_v2.py to\nipam_backend_mixin.py:\n- _validate_subnet_cidr\n- _validate_network_subnetpools\n- _allocate_pools_for_subnet\n- _save_subnet\n\nThis commit moves methods without any internal changes.\nAll future changes and decomposition of these methods will be handled in\nnext commits.\n\nPartially-Implements: blueprint neutron-ipam\n\nChange-Id: I1ec786754467fc9039d2276f084f1bceaab15635\n'}, {'number': 2, 'created': '2015-06-23 10:49:01.000000000', 'files': ['neutron/db/ipam_backend_mixin.py', 'neutron/db/db_base_plugin_v2.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/277d89b67a6a8ea4f6a7bc216014d55ace5c1d2d', 'message': 'Bulk move methods to ipam_backend_mixin.py\n\nipam_backend_mixin contains methods common for both backends:\npluggable and non-pluggable, so moving methods to make them accessible\nby backends.\nNext methods were moved from db_base_plugin_v2.py to\nipam_backend_mixin.py:\n- _validate_subnet_cidr\n- _validate_network_subnetpools\n- _allocate_pools_for_subnet\n- _save_subnet\n\nThis commit moves methods without any internal changes.\nAll future changes and decomposition of these methods will be handled in\nnext commits.\n\nPartially-Implements: blueprint neutron-ipam\n\nChange-Id: I1ec786754467fc9039d2276f084f1bceaab15635\n'}]",4,194566,277d89b67a6a8ea4f6a7bc216014d55ace5c1d2d,61,23,2,13768,,,0,"Bulk move methods to ipam_backend_mixin.py

ipam_backend_mixin contains methods common for both backends:
pluggable and non-pluggable, so moving methods to make them accessible
by backends.
Next methods were moved from db_base_plugin_v2.py to
ipam_backend_mixin.py:
- _validate_subnet_cidr
- _validate_network_subnetpools
- _allocate_pools_for_subnet
- _save_subnet

This commit moves methods without any internal changes.
All future changes and decomposition of these methods will be handled in
next commits.

Partially-Implements: blueprint neutron-ipam

Change-Id: I1ec786754467fc9039d2276f084f1bceaab15635
",git fetch https://review.opendev.org/openstack/neutron refs/changes/66/194566/1 && git format-patch -1 --stdout FETCH_HEAD,"['neutron/db/ipam_backend_mixin.py', 'neutron/db/db_base_plugin_v2.py']",2,bd24ed604afe1e22b98a653facc4bc3e9fb7c779,bp/neutron-ipam,," def _validate_subnet_cidr(self, context, network, new_subnet_cidr): """"""Validate the CIDR for a subnet. Verifies the specified CIDR does not overlap with the ones defined for the other subnets specified for this network, or with any other CIDR if overlapping IPs are disabled. """""" new_subnet_ipset = netaddr.IPSet([new_subnet_cidr]) # Disallow subnets with prefix length 0 as they will lead to # dnsmasq failures (see bug 1362651). # This is not a discrimination against /0 subnets. # A /0 subnet is conceptually possible but hardly a practical # scenario for neutron's use cases. for cidr in new_subnet_ipset.iter_cidrs(): if cidr.prefixlen == 0: err_msg = _(""0 is not allowed as CIDR prefix length"") raise n_exc.InvalidInput(error_message=err_msg) if cfg.CONF.allow_overlapping_ips: subnet_list = network.subnets else: subnet_list = self._get_all_subnets(context) for subnet in subnet_list: if (netaddr.IPSet([subnet.cidr]) & new_subnet_ipset): # don't give out details of the overlapping subnet err_msg = (_(""Requested subnet with cidr: %(cidr)s for "" ""network: %(network_id)s overlaps with another "" ""subnet"") % {'cidr': new_subnet_cidr, 'network_id': network.id}) LOG.info(_LI(""Validation for CIDR: %(new_cidr)s failed - "" ""overlaps with subnet %(subnet_id)s "" ""(CIDR: %(cidr)s)""), {'new_cidr': new_subnet_cidr, 'subnet_id': subnet.id, 'cidr': subnet.cidr}) raise n_exc.InvalidInput(error_message=err_msg) def _validate_network_subnetpools(self, network, new_subnetpool_id, ip_version): """"""Validate all subnets on the given network have been allocated from the same subnet pool as new_subnetpool_id """""" for subnet in network.subnets: if (subnet.ip_version == ip_version and new_subnetpool_id != subnet.subnetpool_id): raise n_exc.NetworkSubnetPoolAffinityError() def _allocate_pools_for_subnet(self, context, subnet): """"""Create IP allocation pools for a given subnet Pools are defined by the 'allocation_pools' attribute, a list of dict objects with 'start' and 'end' keys for defining the pool range. """""" pools = [] # Auto allocate the pool around gateway_ip net = netaddr.IPNetwork(subnet['cidr']) first_ip = net.first + 1 last_ip = net.last - 1 gw_ip = int(netaddr.IPAddress(subnet['gateway_ip'] or net.last)) # Use the gw_ip to find a point for splitting allocation pools # for this subnet split_ip = min(max(gw_ip, net.first), net.last) if split_ip > first_ip: pools.append({'start': str(netaddr.IPAddress(first_ip)), 'end': str(netaddr.IPAddress(split_ip - 1))}) if split_ip < last_ip: pools.append({'start': str(netaddr.IPAddress(split_ip + 1)), 'end': str(netaddr.IPAddress(last_ip))}) # return auto-generated pools # no need to check for their validity return pools def _save_subnet(self, context, network, subnet_args, dns_nameservers, host_routes, allocation_pools): if not attributes.is_attr_set(allocation_pools): allocation_pools = self._allocate_pools_for_subnet(context, subnet_args) else: self._validate_allocation_pools(allocation_pools, subnet_args['cidr']) if subnet_args['gateway_ip']: self._validate_gw_out_of_pools(subnet_args['gateway_ip'], allocation_pools) self._validate_subnet_cidr(context, network, subnet_args['cidr']) self._validate_network_subnetpools(network, subnet_args['subnetpool_id'], subnet_args['ip_version']) subnet = models_v2.Subnet(**subnet_args) context.session.add(subnet) if attributes.is_attr_set(dns_nameservers): for addr in dns_nameservers: ns = models_v2.DNSNameServer(address=addr, subnet_id=subnet.id) context.session.add(ns) if attributes.is_attr_set(host_routes): for rt in host_routes: route = models_v2.SubnetRoute( subnet_id=subnet.id, destination=rt['destination'], nexthop=rt['nexthop']) context.session.add(route) self._save_allocation_pools(context, subnet, allocation_pools) return subnet ",116,116
openstack%2Fneutron~master~Ibd9b31b4f2393b8732253d5cbfd36e8b5614860d,openstack/neutron,master,Ibd9b31b4f2393b8732253d5cbfd36e8b5614860d,Fix SR-IOV mech driver to set port status to down when agent is required,MERGED,2015-06-11 09:41:45.000000000,2015-06-24 19:34:31.000000000,2015-06-24 19:34:27.000000000,"[{'_account_id': 3}, {'_account_id': 1653}, {'_account_id': 5170}, {'_account_id': 6509}, {'_account_id': 6598}, {'_account_id': 6685}, {'_account_id': 6788}, {'_account_id': 7715}, {'_account_id': 7787}, {'_account_id': 8788}, {'_account_id': 8976}, {'_account_id': 9681}, {'_account_id': 9682}, {'_account_id': 9751}, {'_account_id': 9787}, {'_account_id': 9845}, {'_account_id': 10121}, {'_account_id': 10153}, {'_account_id': 10184}, {'_account_id': 10386}, {'_account_id': 11343}, {'_account_id': 12171}, {'_account_id': 14208}, {'_account_id': 14212}, {'_account_id': 14213}, {'_account_id': 14214}, {'_account_id': 14216}, {'_account_id': 14323}, {'_account_id': 14571}, {'_account_id': 15296}, {'_account_id': 15444}, {'_account_id': 15894}]","[{'number': 1, 'created': '2015-06-11 09:41:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/949ef91ace7e46d90ff8af8fb8d693f58f116031', 'message': ""SR-IOV mech driver doesn't send port update when launching vm\nand agent required is true.\n\nSR-IOV mech driver has 2 modes agent and agent-less. Currently in boths\nmodes port status are active. This patch update the port status to down\nwhen using agent mode. This will allow the SR-IOV agent to get port\nupdate notification and  apply its additinal functionality\nwhen launching vm.\n\nCloses-Bug: #1464186\n\nChange-Id: Ibd9b31b4f2393b8732253d5cbfd36e8b5614860d\n""}, {'number': 2, 'created': '2015-06-11 16:25:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/5317d2854fed8779183a8626e51d4340fe72883c', 'message': ""SR-IOV mech driver doesn't send port update when launching vm\nand agent required is true.\n\nSR-IOV mech driver has 2 modes agent and agent-less. Currently in both\nmodes port status are active. This patch update the port status to down\nwhen using agent mode. This will allow the SR-IOV agent to get port\nupdate notification and  apply its additional functionality\nwhen launching vm.\n\nCloses-Bug: #1464186\n\nChange-Id: Ibd9b31b4f2393b8732253d5cbfd36e8b5614860d\n""}, {'number': 3, 'created': '2015-06-18 11:17:55.000000000', 'files': ['neutron/plugins/ml2/drivers/mech_sriov/mech_driver.py', 'neutron/tests/unit/plugins/ml2/drivers/mech_sriov/test_mech_sriov_nic_switch.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/63e318f5f8159f108cf1e7a82c952fa5f882870f', 'message': 'Fix SR-IOV mech driver to set port status to down when agent is required\n\nSR-IOV mech driver has 2 modes agent and agent-less. Currently in both\nmodes port status are active. This patch update the port status to down\nwhen using agent mode. This will allow the SR-IOV agent to get port\nupdate notification and apply its additional functionality\nwhen launching vm.\n\nCo-Authored-By: Berezovsky Irena <irenab.dev@gmail.com>\n\nCloses-Bug: #1464186\n\nChange-Id: Ibd9b31b4f2393b8732253d5cbfd36e8b5614860d\n'}]",6,190562,63e318f5f8159f108cf1e7a82c952fa5f882870f,74,32,3,12171,,,0,"Fix SR-IOV mech driver to set port status to down when agent is required

SR-IOV mech driver has 2 modes agent and agent-less. Currently in both
modes port status are active. This patch update the port status to down
when using agent mode. This will allow the SR-IOV agent to get port
update notification and apply its additional functionality
when launching vm.

Co-Authored-By: Berezovsky Irena <irenab.dev@gmail.com>

Closes-Bug: #1464186

Change-Id: Ibd9b31b4f2393b8732253d5cbfd36e8b5614860d
",git fetch https://review.opendev.org/openstack/neutron refs/changes/62/190562/1 && git format-patch -1 --stdout FETCH_HEAD,['neutron/plugins/ml2/drivers/mech_sriov/mech_driver.py'],1,949ef91ace7e46d90ff8af8fb8d693f58f116031,bug/1464186, port_status = constants.PORT_STATUS_DOWN if agent is None: port_status = constants.PORT_STATUS_ACTIVE port_status), constants.PORT_STATUS_ACTIVE),4,1
openstack%2Fneutron~master~Ia9ff79c34bd4c9124ec8663a8f616ded4f389f62,openstack/neutron,master,Ia9ff79c34bd4c9124ec8663a8f616ded4f389f62,Add IPset cleanup script,MERGED,2015-04-16 20:26:21.000000000,2015-06-24 19:31:25.000000000,2015-06-24 19:31:22.000000000,"[{'_account_id': 3}, {'_account_id': 1131}, {'_account_id': 1653}, {'_account_id': 4395}, {'_account_id': 5170}, {'_account_id': 6788}, {'_account_id': 7787}, {'_account_id': 8124}, {'_account_id': 8788}, {'_account_id': 8976}, {'_account_id': 9681}, {'_account_id': 9682}, {'_account_id': 9732}, {'_account_id': 9751}, {'_account_id': 9787}, {'_account_id': 9845}, {'_account_id': 10117}, {'_account_id': 10121}, {'_account_id': 10153}, {'_account_id': 10184}, {'_account_id': 10387}, {'_account_id': 12040}, {'_account_id': 14208}, {'_account_id': 14212}, {'_account_id': 14213}, {'_account_id': 14214}, {'_account_id': 14215}, {'_account_id': 14216}, {'_account_id': 14323}, {'_account_id': 14571}, {'_account_id': 14605}, {'_account_id': 15296}, {'_account_id': 15444}, {'_account_id': 15752}, {'_account_id': 15894}]","[{'number': 1, 'created': '2015-04-16 20:26:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/c7a0b3080fcd15b0d0cfe1928eb01d8f9db7d378', 'message': 'Add IPset cleanup script\n\nThis will aid in removing stale IPsets when we change the prefix\nused in creating IPset names.\n\nChange-Id: Ia9ff79c34bd4c9124ec8663a8f616ded4f389f62\nPartial-Bug: #1444201\n'}, {'number': 2, 'created': '2015-04-17 19:10:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/731e1f54d54c067e21fb06a81e786da10ead92d0', 'message': 'Add IPset cleanup script\n\nThis will aid in removing stale IPsets when we change the prefix\nused in creating IPset names.\n\nChange-Id: Ia9ff79c34bd4c9124ec8663a8f616ded4f389f62\nPartial-Bug: #1444201\n'}, {'number': 3, 'created': '2015-04-17 19:25:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/6c6ca191e7546f253b5cb1e67d8148e01c23e3e6', 'message': 'Add IPset cleanup script\n\nThis will aid in removing stale IPsets when we change the prefix\nused in creating IPset names.\n\nChange-Id: Ia9ff79c34bd4c9124ec8663a8f616ded4f389f62\nPartial-Bug: #1444201\n'}, {'number': 4, 'created': '2015-05-04 21:30:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/99edbb35de923ee6b3cdff63b23ac58f27e4ee0d', 'message': 'Add IPset cleanup script\n\nThis will aid in removing stale IPsets when we change the prefix\nused in creating IPset names.\n\nChange-Id: Ia9ff79c34bd4c9124ec8663a8f616ded4f389f62\nPartial-Bug: #1444201\n'}, {'number': 5, 'created': '2015-06-22 23:36:43.000000000', 'files': ['neutron/cmd/ipset_cleanup.py', 'setup.cfg'], 'web_link': 'https://opendev.org/openstack/neutron/commit/c384b13ae6b83a8bad944972c60bdcbe6f4fa050', 'message': 'Add IPset cleanup script\n\nThis will aid in removing stale IPsets when we change the prefix\nused in creating IPset names.\n\nChange-Id: Ia9ff79c34bd4c9124ec8663a8f616ded4f389f62\nPartial-Bug: #1444201\n'}]",17,174590,c384b13ae6b83a8bad944972c60bdcbe6f4fa050,144,35,5,1131,,,0,"Add IPset cleanup script

This will aid in removing stale IPsets when we change the prefix
used in creating IPset names.

Change-Id: Ia9ff79c34bd4c9124ec8663a8f616ded4f389f62
Partial-Bug: #1444201
",git fetch https://review.opendev.org/openstack/neutron refs/changes/90/174590/5 && git format-patch -1 --stdout FETCH_HEAD,"['neutron/cmd/ipset_cleanup.py', 'setup.cfg']",2,c7a0b3080fcd15b0d0cfe1928eb01d8f9db7d378,ipset-cleanup, neutron-ipset-cleanup = neutron.cmd.ipset_cleanup:main,,85,0
openstack%2Fproject-config~master~I3448927decc636503b7ce9e0d454ed3b4b29f2b3,openstack/project-config,master,I3448927decc636503b7ce9e0d454ed3b4b29f2b3,Set tag ACLs for more networking libraries,MERGED,2015-06-18 20:45:21.000000000,2015-06-24 19:30:41.000000000,2015-06-24 15:35:11.000000000,"[{'_account_id': 3}, {'_account_id': 105}, {'_account_id': 2750}, {'_account_id': 4162}, {'_account_id': 6530}, {'_account_id': 6547}, {'_account_id': 10980}, {'_account_id': 11685}, {'_account_id': 13070}, {'_account_id': 16272}]","[{'number': 1, 'created': '2015-06-18 20:45:21.000000000', 'files': ['gerrit/acls/openstack/octavia.config', 'gerrit/acls/openstack/dragonflow.config'], 'web_link': 'https://opendev.org/openstack/project-config/commit/78baa87237d2c37ca68f0726e52d0e3270eaee7f', 'message': 'Set tag ACLs for more networking libraries\n\nBoth octavia and dragonflow are libraries used by neutron, so set their\nACLs to let the library-release team manage tagging.\n\nChange-Id: I3448927decc636503b7ce9e0d454ed3b4b29f2b3\n'}]",0,193305,78baa87237d2c37ca68f0726e52d0e3270eaee7f,12,10,1,2472,,,0,"Set tag ACLs for more networking libraries

Both octavia and dragonflow are libraries used by neutron, so set their
ACLs to let the library-release team manage tagging.

Change-Id: I3448927decc636503b7ce9e0d454ed3b4b29f2b3
",git fetch https://review.opendev.org/openstack/project-config refs/changes/05/193305/1 && git format-patch -1 --stdout FETCH_HEAD,"['gerrit/acls/openstack/octavia.config', 'gerrit/acls/openstack/dragonflow.config']",2,78baa87237d2c37ca68f0726e52d0e3270eaee7f,centralize-library-releases-2,pushSignedTag = group library-release,pushSignedTag = group dragonflow-release,2,2
openstack%2Fnova~stable%2Fkilo~I8cf5483982085da57ee470fa2753b0d0aebc12b3,openstack/nova,stable/kilo,I8cf5483982085da57ee470fa2753b0d0aebc12b3,Reduce window for allocate_fixed_ip / release_fixed_ip race in nova-net,MERGED,2015-06-24 16:46:59.000000000,2015-06-24 19:23:28.000000000,2015-06-24 19:23:25.000000000,"[{'_account_id': 3}, {'_account_id': 979}, {'_account_id': 2750}, {'_account_id': 10118}]","[{'number': 1, 'created': '2015-06-24 16:46:59.000000000', 'files': ['nova/network/manager.py', 'nova/tests/unit/db/test_db_api.py', 'nova/tests/unit/network/test_manager.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/2b5fe5db0da7356527f076a2db9822506299ecfe', 'message': ""Reduce window for allocate_fixed_ip / release_fixed_ip race in nova-net\n\nThere is a race during allocate_fixed_ip where a new instance, B, is\nassociated with a fixed IP, X, which was previously associated with\ninstance A that is being deallocated.\n\nBetween the time that instance A is associated with fixed IP X and the\ntime that it's VIF is allocated, and fip.allocated = True in the DB, the\ndhcpagent callback hits release_fixed_ip for the fixed IP X from when\ninstance A was deallocating.\n\nrelease_fixed_ip checks to see if the instance is allocated and if not\nit disassociates the instance, which was associated with new instance B.\n\nThis leads to get_instance_nw_info() not building anything since there\nare no fixed IPs associated with instance A in the database, so\neventually anything needing to do networking with instance A, like\nassocating a floating IP, fails.\n\nTo narrow the race, we do the VIF allocation before associating the\nfixed IP to the new instance. This does not completely fix the bug, but\nit's a tactical change that we can backport to stable branches while\nworking on the longer-term fix which is going to involve network RPC API\nchanges to release_fixed_ip().\n\nNote that test_vpn_allocate_fixed_ip_no_network_id is removed since it\nno longer works and arguably was testing the DB API in the wrong place,\nso a new test is added to test_db_api for the same coverage.\n\nPartial-Bug: #1249065\n\nChange-Id: I8cf5483982085da57ee470fa2753b0d0aebc12b3\n(cherry picked from commit 3736c120cbeacbc4349efbda99e279cddfb5f09e)\n""}]",0,195190,2b5fe5db0da7356527f076a2db9822506299ecfe,7,4,1,6873,,,0,"Reduce window for allocate_fixed_ip / release_fixed_ip race in nova-net

There is a race during allocate_fixed_ip where a new instance, B, is
associated with a fixed IP, X, which was previously associated with
instance A that is being deallocated.

Between the time that instance A is associated with fixed IP X and the
time that it's VIF is allocated, and fip.allocated = True in the DB, the
dhcpagent callback hits release_fixed_ip for the fixed IP X from when
instance A was deallocating.

release_fixed_ip checks to see if the instance is allocated and if not
it disassociates the instance, which was associated with new instance B.

This leads to get_instance_nw_info() not building anything since there
are no fixed IPs associated with instance A in the database, so
eventually anything needing to do networking with instance A, like
assocating a floating IP, fails.

To narrow the race, we do the VIF allocation before associating the
fixed IP to the new instance. This does not completely fix the bug, but
it's a tactical change that we can backport to stable branches while
working on the longer-term fix which is going to involve network RPC API
changes to release_fixed_ip().

Note that test_vpn_allocate_fixed_ip_no_network_id is removed since it
no longer works and arguably was testing the DB API in the wrong place,
so a new test is added to test_db_api for the same coverage.

Partial-Bug: #1249065

Change-Id: I8cf5483982085da57ee470fa2753b0d0aebc12b3
(cherry picked from commit 3736c120cbeacbc4349efbda99e279cddfb5f09e)
",git fetch https://review.opendev.org/openstack/nova refs/changes/90/195190/1 && git format-patch -1 --stdout FETCH_HEAD,"['nova/network/manager.py', 'nova/tests/unit/db/test_db_api.py', 'nova/tests/unit/network/test_manager.py']",3,2b5fe5db0da7356527f076a2db9822506299ecfe,," @mock.patch('nova.objects.instance.Instance.get_by_uuid') @mock.patch.object(db, 'virtual_interface_get_by_instance_and_network', return_value=None) @mock.patch('nova.objects.fixed_ip.FixedIP') def test_allocate_fixed_ip_add_vif_fails(self, mock_fixedip, mock_get_vif, mock_instance_get): # Tests that we don't try to do anything with fixed IPs if # _add_virtual_interface fails. instance = fake_instance.fake_instance_obj(self.context) mock_instance_get.return_value = instance network = {'cidr': '24', 'id': 1, 'uuid': '398399b3-f696-4859-8695-a6560e14cb02'} vif_error = exception.VirtualInterfaceMacAddressException() # mock out quotas because we don't care in this test with mock.patch.object(self.network, 'quotas_cls', objects.QuotasNoOp): with mock.patch.object(self.network, '_add_virtual_interface', side_effect=vif_error): self.assertRaises( exception.VirtualInterfaceMacAddressException, self.network.allocate_fixed_ip, self.context, '9d2ee1e3-ffad-4e5f-81ff-c96dd97b0ee0', network) self.assertFalse(mock_fixedip.called, str(mock_fixedip.mock_calls)) @mock.patch.object(db, 'virtual_interface_get_by_instance_and_network', return_value=None) @mock.patch('nova.objects.fixed_ip.FixedIP') def test_allocate_fixed_ip_add_vif_fails(self, mock_fixedip, mock_get_vif): # Tests that we don't try to do anything with fixed IPs if # _add_virtual_interface fails. vif_error = exception.VirtualInterfaceMacAddressException() with mock.patch.object(self.network, '_add_virtual_interface', side_effect=vif_error): self.assertRaises(exception.VirtualInterfaceMacAddressException, self.network.allocate_fixed_ip, self.context, '9d2ee1e3-ffad-4e5f-81ff-c96dd97b0ee0', networks[0]) self.assertFalse(mock_fixedip.called, str(mock_fixedip.mock_calls)) "," def test_vpn_allocate_fixed_ip_no_network_id(self): network = dict(networks[0]) network['vpn_private_address'] = '192.168.0.2' network['id'] = None instance = db.instance_create(self.context, {}) self.assertRaises(exception.FixedIpNotFoundForNetwork, self.network.allocate_fixed_ip, self.context_admin, instance['uuid'], network, vpn=True) ",85,32
openstack%2Fosprofiler~master~Ia5b4859b662d98facf3c211ae813962bd07feef0,openstack/osprofiler,master,Ia5b4859b662d98facf3c211ae813962bd07feef0,Remove version from setup.cfg,MERGED,2015-06-24 18:59:39.000000000,2015-06-24 19:18:15.000000000,2015-06-24 19:18:15.000000000,"[{'_account_id': 3}, {'_account_id': 6172}]","[{'number': 1, 'created': '2015-06-24 18:59:39.000000000', 'files': ['setup.cfg'], 'web_link': 'https://opendev.org/openstack/osprofiler/commit/bc78823f299747ba1ff660953775a008d3581df0', 'message': ""Remove version from setup.cfg\n\nPbr is calculating versions on it's own based on git tags.\nSo we don't need to specify by hands in setup.cfg version\n\nChange-Id: Ia5b4859b662d98facf3c211ae813962bd07feef0\n""}]",0,195267,bc78823f299747ba1ff660953775a008d3581df0,6,2,1,6172,,,0,"Remove version from setup.cfg

Pbr is calculating versions on it's own based on git tags.
So we don't need to specify by hands in setup.cfg version

Change-Id: Ia5b4859b662d98facf3c211ae813962bd07feef0
",git fetch https://review.opendev.org/openstack/osprofiler refs/changes/67/195267/1 && git format-patch -1 --stdout FETCH_HEAD,['setup.cfg'],1,bc78823f299747ba1ff660953775a008d3581df0,,,version = 0.3.0,0,1
openstack%2Fbarbican~master~Ie7e706adcf1b5d74f64776b888a06638247b4e87,openstack/barbican,master,Ie7e706adcf1b5d74f64776b888a06638247b4e87,Display all versions info in versions controller,MERGED,2015-04-29 10:38:09.000000000,2015-06-24 19:07:33.000000000,2015-06-24 19:07:32.000000000,"[{'_account_id': 3}, {'_account_id': 1091}, {'_account_id': 6783}, {'_account_id': 7136}, {'_account_id': 7262}, {'_account_id': 7789}, {'_account_id': 7973}, {'_account_id': 8004}, {'_account_id': 8623}, {'_account_id': 9234}, {'_account_id': 9914}, {'_account_id': 10873}, {'_account_id': 11970}]","[{'number': 1, 'created': '2015-04-29 10:38:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/barbican/commit/bbe955851f53865d1eac2f914633c762a7a6e505', 'message': 'Display all versions info in versions controller\n\nThis patch enables the ""versions controller"" or ""/"" resource to display\ninformation relevant to all the versions of the Barbican API (which is\nonly v1 at the moment). This is done in the same fashion Keystone\ndisplays it, and it has the purpose of enabling more automatic discovery\nas described in the blueprint.\n\nOn the other hand, this introduces the V1Controller, which is now the\nroot controller (which requires authentication) for Barbican. At the\nmoment it only displays what the legacy versions controllers did, which\nis the version and the build number; But this will be changed into a\nproper json-home response in a subsequent patch.\n\nPartially implements blueprint fix-version-api\nChange-Id: Ie7e706adcf1b5d74f64776b888a06638247b4e87\n'}, {'number': 2, 'created': '2015-04-29 20:01:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/barbican/commit/63c14b0512b0cb46cfb8671a7fec9b18865338ea', 'message': 'Display all versions info in versions controller\n\nThis patch enables the ""versions controller"" or ""/"" resource to display\ninformation relevant to all the versions of the Barbican API (which is\nonly v1 at the moment). This is done in the same fashion Keystone\ndisplays it, and it has the purpose of enabling more automatic discovery\nas described in the blueprint.\n\nOn the other hand, this introduces the V1Controller, which is now the\nroot controller (which requires authentication) for Barbican. At the\nmoment it only displays what the legacy versions controllers did, which\nis the version and the build number; But this will be changed into a\nproper json-home response in a subsequent patch.\n\nPartially implements blueprint fix-version-api\nChange-Id: Ie7e706adcf1b5d74f64776b888a06638247b4e87\n'}, {'number': 3, 'created': '2015-04-29 21:18:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/barbican/commit/77d891d8cbfa7994ee4ca04b8382c3fe27228d1d', 'message': 'Display all versions info in versions controller\n\nThis patch enables the ""versions controller"" or ""/"" resource to display\ninformation relevant to all the versions of the Barbican API (which is\nonly v1 at the moment). This is done in the same fashion Keystone\ndisplays it, and it has the purpose of enabling more automatic discovery\nas described in the blueprint.\n\nOn the other hand, this introduces the V1Controller, which is now the\nroot controller (which requires authentication) for Barbican. At the\nmoment it only displays what the legacy versions controllers did, which\nis the version and the build number; But this will be changed into a\nproper json-home response in a subsequent patch.\n\nPartially implements blueprint fix-version-api\nChange-Id: Ie7e706adcf1b5d74f64776b888a06638247b4e87\n'}, {'number': 4, 'created': '2015-05-01 08:28:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/barbican/commit/8c9d9b038d0501534537dc348e1103df8e7763f1', 'message': 'Display all versions info in versions controller\n\nThis patch enables the ""versions controller"" or ""/"" resource to display\ninformation relevant to all the versions of the Barbican API (which is\nonly v1 at the moment). This is done in the same fashion Keystone\ndisplays it, and it has the purpose of enabling more automatic discovery\nas described in the blueprint.\n\nOn the other hand, this introduces the V1Controller, which is now the\nroot controller (which requires authentication) for Barbican. At the\nmoment it only displays what the legacy versions controllers did, which\nis the version and the build number; But this will be changed into a\nproper json-home response in a subsequent patch.\n\nPartially implements blueprint fix-version-api\nChange-Id: Ie7e706adcf1b5d74f64776b888a06638247b4e87\n'}, {'number': 5, 'created': '2015-05-20 16:38:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/barbican/commit/58edbfd161797f621a35cb400ddb7fa2f684f8f8', 'message': 'Display all versions info in versions controller\n\nThis patch enables the ""versions controller"" or ""/"" resource to display\ninformation relevant to all the versions of the Barbican API (which is\nonly v1 at the moment). This is done in the same fashion Keystone\ndisplays it, and it has the purpose of enabling more automatic discovery\nas described in the blueprint.\n\nOn the other hand, this introduces the V1Controller, which is now the\nroot controller (which requires authentication) for Barbican. At the\nmoment it only displays what the legacy versions controllers did, which\nis the version and the build number; But this will be changed into a\nproper json-home response in a subsequent patch.\n\nPartially implements blueprint fix-version-api\nChange-Id: Ie7e706adcf1b5d74f64776b888a06638247b4e87\n'}, {'number': 6, 'created': '2015-05-26 12:45:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/barbican/commit/0905978f5232adfa013d4553ac89e5068b37cc16', 'message': 'Display all versions info in versions controller\n\nThis patch enables the ""versions controller"" or ""/"" resource to display\ninformation relevant to all the versions of the Barbican API (which is\nonly v1 at the moment). This is done in the same fashion Keystone\ndisplays it, and it has the purpose of enabling more automatic discovery\nas described in the blueprint.\n\nOn the other hand, this introduces the V1Controller, which is now the\nroot controller (which requires authentication) for Barbican. At the\nmoment it only displays what the legacy versions controllers did, which\nis the version and the build number; But this will be changed into a\nproper json-home response in a subsequent patch.\n\nPartially implements blueprint fix-version-api\nChange-Id: Ie7e706adcf1b5d74f64776b888a06638247b4e87\n'}, {'number': 7, 'created': '2015-06-04 07:37:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/barbican/commit/59acfde742afe5e1dbb678f7d795a513baf043e0', 'message': 'Display all versions info in versions controller\n\nThis patch enables the ""versions controller"" or ""/"" resource to display\ninformation relevant to all the versions of the Barbican API (which is\nonly v1 at the moment). This is done in the same fashion Keystone\ndisplays it, and it has the purpose of enabling more automatic discovery\nas described in the blueprint.\n\nOn the other hand, this introduces the V1Controller, which is now the\nroot controller (which requires authentication) for Barbican. At the\nmoment it only displays what the legacy versions controllers did, which\nis the version and the build number; But this will be changed into a\nproper json-home response in a subsequent patch.\n\nPartially implements blueprint fix-version-api\nChange-Id: Ie7e706adcf1b5d74f64776b888a06638247b4e87\n'}, {'number': 8, 'created': '2015-06-04 09:36:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/barbican/commit/6a8b20bfd760fe1312c1c517d88ae97d1eb6c485', 'message': 'Display all versions info in versions controller\n\nThis patch enables the ""versions controller"" or ""/"" resource to display\ninformation relevant to all the versions of the Barbican API (which is\nonly v1 at the moment). This is done in the same fashion Keystone\ndisplays it, and it has the purpose of enabling more automatic discovery\nas described in the blueprint.\n\nAccessing the root resource with the ""build"" query parameter, such as:\n\n    $ curl http://localhost:9311/?build\n\nwill display the build information.\n\nOn the other hand, this introduces the V1Controller, which is now the\nroot controller (which requires authentication) for Barbican.\n\nAccessing the ""/v1"" resource will display the version information in the\nway it\'s required by keystone.\n\nThe json-home implementation is left for a subsequent CR.\n\nPartially implements blueprint fix-version-api\nChange-Id: Ie7e706adcf1b5d74f64776b888a06638247b4e87\n'}, {'number': 9, 'created': '2015-06-04 10:18:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/barbican/commit/3d43c16c00969ed9b9902555e3cfab7960696f9f', 'message': 'Display all versions info in versions controller\n\nThis patch enables the ""versions controller"" or ""/"" resource to display\ninformation relevant to all the versions of the Barbican API (which is\nonly v1 at the moment). This is done in the same fashion Keystone\ndisplays it, and it has the purpose of enabling more automatic discovery\nas described in the blueprint.\n\nAccessing the root resource with the ""build"" query parameter, such as:\n\n    $ curl http://localhost:9311/?build\n\nwill display the build information.\n\nOn the other hand, this introduces the V1Controller, which is now the\nroot controller (which requires authentication) for Barbican.\n\nAccessing the ""/v1"" resource will display the version information in the\nway it\'s required by keystone.\n\nThe json-home implementation is left for a subsequent CR.\n\nPartially implements blueprint fix-version-api\nChange-Id: Ie7e706adcf1b5d74f64776b888a06638247b4e87\n'}, {'number': 10, 'created': '2015-06-18 02:21:36.000000000', 'files': ['etc/barbican/barbican-api-paste.ini', 'contrib/devstack/lib/barbican', 'barbican/tests/api/test_resources_policy.py', 'barbican/common/utils.py', 'barbican/api/controllers/versions.py', 'barbican/tests/api/controllers/test_versions.py', 'barbican/api/app.py', 'doc/source/setup/keystone.rst', 'functionaltests/api/v1/smoke/test_versions.py'], 'web_link': 'https://opendev.org/openstack/barbican/commit/3b20d84312b6870557a5b1db346de75e928ddbe8', 'message': 'Display all versions info in versions controller\n\nThis patch enables the ""versions controller"" or ""/"" resource to display\ninformation relevant to all the versions of the Barbican API (which is\nonly v1 at the moment). This is done in the same fashion Keystone\ndisplays it, and it has the purpose of enabling more automatic discovery\nas described in the blueprint.\n\nAccessing the root resource with the ""build"" query parameter, such as:\n\n    $ curl http://localhost:9311/?build\n\nwill display the build information.\n\nOn the other hand, this introduces the V1Controller, which is now the\nroot controller (which requires authentication) for Barbican.\n\nAccessing the ""/v1"" resource will display the version information in the\nway it\'s required by keystone.\n\nThe json-home implementation is left for a subsequent CR.\n\nPartially implements blueprint fix-version-api\nChange-Id: Ie7e706adcf1b5d74f64776b888a06638247b4e87\n'}]",17,178601,3b20d84312b6870557a5b1db346de75e928ddbe8,47,13,10,10873,,,0,"Display all versions info in versions controller

This patch enables the ""versions controller"" or ""/"" resource to display
information relevant to all the versions of the Barbican API (which is
only v1 at the moment). This is done in the same fashion Keystone
displays it, and it has the purpose of enabling more automatic discovery
as described in the blueprint.

Accessing the root resource with the ""build"" query parameter, such as:

    $ curl http://localhost:9311/?build

will display the build information.

On the other hand, this introduces the V1Controller, which is now the
root controller (which requires authentication) for Barbican.

Accessing the ""/v1"" resource will display the version information in the
way it's required by keystone.

The json-home implementation is left for a subsequent CR.

Partially implements blueprint fix-version-api
Change-Id: Ie7e706adcf1b5d74f64776b888a06638247b4e87
",git fetch https://review.opendev.org/openstack/barbican refs/changes/01/178601/1 && git format-patch -1 --stdout FETCH_HEAD,"['etc/barbican/barbican-api-paste.ini', 'barbican/tests/api/test_resources_policy.py', 'barbican/common/utils.py', 'barbican/api/controllers/versions.py', 'barbican/tests/api/controllers/test_versions.py', 'barbican/api/app.py', 'functionaltests/api/v1/smoke/test_versions.py']",7,bbe955851f53865d1eac2f914633c762a7a6e505,bp/fix-version-api," self.assertEqual(resp.status_code, 300) versions_response = body['versions']['values'] v1_info = versions_response[0] # NOTE(jaosorior): I used assertIn instead of assertEqual because we # might start using decimal numbers in the future. So when that happens # this test will still be valid. self.assertIn('v1', v1_info['id']) self.assertEqual(len(v1_info['media-types']), 1) self.assertEqual(v1_info['media-types'][0]['base'], 'application/json')"," self.assertEqual(resp.status_code, 200) self.assertEqual(body.get('v1'), 'current') self.assertGreater(len(body.get('build')), 1)",210,69
openstack%2Fcookbook-openstack-common~master~I3779458498a98d08816a5a4d57ee490515c40222,openstack/cookbook-openstack-common,master,I3779458498a98d08816a5a4d57ee490515c40222,Gate TEST - ChefDK 0.6.0,ABANDONED,2015-06-01 19:54:24.000000000,2015-06-24 19:05:41.000000000,,"[{'_account_id': 3}, {'_account_id': 7128}, {'_account_id': 11915}, {'_account_id': 12323}, {'_account_id': 15068}]","[{'number': 1, 'created': '2015-06-01 19:54:24.000000000', 'files': ['bootstrap.sh'], 'web_link': 'https://opendev.org/openstack/cookbook-openstack-common/commit/1fda54dc49a13cc5c1528ef4fd4b23943ba03005', 'message': ""Gate TEST - ChefDK 0.6.0\n\nLet's see how the new version works for gates\n\nChange-Id: I3779458498a98d08816a5a4d57ee490515c40222\n""}]",0,187309,1fda54dc49a13cc5c1528ef4fd4b23943ba03005,11,5,1,7128,,,0,"Gate TEST - ChefDK 0.6.0

Let's see how the new version works for gates

Change-Id: I3779458498a98d08816a5a4d57ee490515c40222
",git fetch https://review.opendev.org/openstack/cookbook-openstack-common refs/changes/09/187309/1 && git format-patch -1 --stdout FETCH_HEAD,['bootstrap.sh'],1,1fda54dc49a13cc5c1528ef4fd4b23943ba03005,chefdk-6,chefdk=chefdk_0.6.0-1_amd64.deb,chefdk=chefdk_0.4.0-1_amd64.deb,1,1
openstack%2Fproject-config~master~Id7a2c82e979d1f878022b4982f51ef4ef06ecf4b,openstack/project-config,master,Id7a2c82e979d1f878022b4982f51ef4ef06ecf4b,Sprinkle in Horizon translations for Zanata,MERGED,2015-06-23 07:25:16.000000000,2015-06-24 19:05:34.000000000,2015-06-24 19:05:33.000000000,"[{'_account_id': 3}, {'_account_id': 6547}, {'_account_id': 6609}, {'_account_id': 9369}]","[{'number': 1, 'created': '2015-06-23 07:25:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/project-config/commit/bc11c7f2395ec7febd84fccd1bcc3fdeb047f281', 'message': 'Sprinke in Horizon translations for Zanata\n\nBuilding on work landed in II3bfb188c8b0c0e65f22d7edc30721b163f084fff,\nadd support for pushing source documents of Horizon into Zanata.\nThis has also necessitated adding support for parsing and adding\nrules for create-zanata-xml.py. As a drive-by correct some incorrect\ndocstrings in ZanataUtils.\n\nChange-Id: Id7a2c82e979d1f878022b4982f51ef4ef06ecf4b\n'}, {'number': 2, 'created': '2015-06-23 07:26:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/project-config/commit/36969ccd5d0ed13eeff7e71e243d93ed229faeb2', 'message': 'Sprinkle in Horizon translations for Zanata\n\nBuilding on work landed in II3bfb188c8b0c0e65f22d7edc30721b163f084fff,\nadd support for pushing source documents of Horizon into Zanata.\nThis has also necessitated adding support for parsing and adding\nrules for create-zanata-xml.py. As a drive-by correct some incorrect\ndocstrings in ZanataUtils.\n\nChange-Id: Id7a2c82e979d1f878022b4982f51ef4ef06ecf4b\n'}, {'number': 3, 'created': '2015-06-23 08:51:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/project-config/commit/3535497220947fa014f1d00643a1a371a7cc7e7e', 'message': 'Sprinkle in Horizon translations for Zanata\n\nBuilding on work landed in II3bfb188c8b0c0e65f22d7edc30721b163f084fff,\nadd support for pushing source documents of Horizon into Zanata.\nThis has also necessitated adding support for parsing and adding\nrules for create-zanata-xml.py. As a drive-by correct some incorrect\ndocstrings in ZanataUtils.\n\nChange-Id: Id7a2c82e979d1f878022b4982f51ef4ef06ecf4b\n'}, {'number': 4, 'created': '2015-06-23 10:31:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/project-config/commit/0bc95e4defceb27ee7706800c314f1e72e2496db', 'message': 'Sprinkle in Horizon translations for Zanata\n\nBuilding on work landed in II3bfb188c8b0c0e65f22d7edc30721b163f084fff,\nadd support for pushing source documents of Horizon into Zanata.\nThis has also necessitated adding support for parsing and adding\nrules for create-zanata-xml.py. As a drive-by correct some incorrect\ndocstrings in ZanataUtils.\n\nChange-Id: Id7a2c82e979d1f878022b4982f51ef4ef06ecf4b\n'}, {'number': 5, 'created': '2015-06-24 05:39:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/project-config/commit/0c14ac93ee957ab255e2c73a3c888b27b4a704fb', 'message': 'Sprinkle in Horizon translations for Zanata\n\nBuilding on work landed in II3bfb188c8b0c0e65f22d7edc30721b163f084fff,\nadd support for pushing source documents of Horizon into Zanata.\nThis has also necessitated adding support for parsing and adding\nrules for create-zanata-xml.py. As a drive-by correct some incorrect\ndocstrings in ZanataUtils.\n\nChange-Id: Id7a2c82e979d1f878022b4982f51ef4ef06ecf4b\n'}, {'number': 6, 'created': '2015-06-24 05:40:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/project-config/commit/d8630d192b55a2d77d0fe563f78c26570e76c048', 'message': 'Sprinkle in Horizon translations for Zanata\n\nBuilding on work landed in II3bfb188c8b0c0e65f22d7edc30721b163f084fff,\nadd support for pushing source documents of Horizon into Zanata.\nThis has also necessitated adding support for parsing and adding\nrules for create-zanata-xml.py. As a drive-by correct some incorrect\ndocstrings in ZanataUtils.\n\nChange-Id: Id7a2c82e979d1f878022b4982f51ef4ef06ecf4b\n'}, {'number': 7, 'created': '2015-06-24 06:15:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/project-config/commit/dae4845dd9e2b2ef9aa73f07f7830613edea9f4d', 'message': 'Sprinkle in Horizon translations for Zanata\n\nBuilding on work landed in II3bfb188c8b0c0e65f22d7edc30721b163f084fff,\nadd support for pushing source documents of Horizon into Zanata.\nThis has also necessitated adding support for parsing and adding\nrules for create-zanata-xml.py.\n\nAs a drive-by correct some incorrect docstrings in ZanataUtils, split\nsome ludicrously long lines calling create-zanata-xml.py, and correct\nusage of an undefined variable in setup_django_openstack_auth.\n\nChange-Id: Id7a2c82e979d1f878022b4982f51ef4ef06ecf4b\n'}, {'number': 8, 'created': '2015-06-24 08:47:26.000000000', 'files': ['jenkins/scripts/ZanataUtils.py', 'jenkins/scripts/upstream_translation_horizon.sh', 'jenkins/scripts/create-zanata-xml.py', 'jenkins/scripts/common_translation_update.sh'], 'web_link': 'https://opendev.org/openstack/project-config/commit/544eb51c73482ab5fa257f9a0d04a6d2b1713512', 'message': 'Sprinkle in Horizon translations for Zanata\n\nBuilding on work landed in II3bfb188c8b0c0e65f22d7edc30721b163f084fff,\nadd support for pushing source documents of Horizon into Zanata.\nThis has also necessitated adding support for parsing and adding\nrules for create-zanata-xml.py.\n\nAs a drive-by correct some incorrect docstrings in ZanataUtils, split\nsome ludicrously long lines calling create-zanata-xml.py, and correct\nusage of an undefined variable in setup_django_openstack_auth.\n\nChange-Id: Id7a2c82e979d1f878022b4982f51ef4ef06ecf4b\n'}]",11,194525,544eb51c73482ab5fa257f9a0d04a6d2b1713512,25,4,8,9369,,,0,"Sprinkle in Horizon translations for Zanata

Building on work landed in II3bfb188c8b0c0e65f22d7edc30721b163f084fff,
add support for pushing source documents of Horizon into Zanata.
This has also necessitated adding support for parsing and adding
rules for create-zanata-xml.py.

As a drive-by correct some incorrect docstrings in ZanataUtils, split
some ludicrously long lines calling create-zanata-xml.py, and correct
usage of an undefined variable in setup_django_openstack_auth.

Change-Id: Id7a2c82e979d1f878022b4982f51ef4ef06ecf4b
",git fetch https://review.opendev.org/openstack/project-config refs/changes/25/194525/7 && git format-patch -1 --stdout FETCH_HEAD,"['jenkins/scripts/ZanataUtils.py', 'jenkins/scripts/upstream_translation_horizon.sh', 'jenkins/scripts/create-zanata-xml.py', 'jenkins/scripts/common_translation_update.sh']",4,bc11c7f2395ec7febd84fccd1bcc3fdeb047f281,zanata," # While we spin up, we want to not error out if we can't generate the # zanata.xml file. if ! /usr/local/jenkins/slave_scripts/create-zanata-xml.py -p $project -v master --srcdir . --txdir . -r 'horizon/*.pot' 'horizon/locale/{locale}/LC_MESSAGES}/{filename}.pot' -r 'openstack_dashboard/*.pot' 'openstack_dashboard/locale/{locale}/LC_MESSAGES/{filename}.pot' -f zanata.xml; then echo ""Failed to generate zanata.xml"" fi ",,37,17
openstack%2Fpython-designateclient~master~Id3e3da54a0ccd9a1bb521eca1390b626d1cb71cc,openstack/python-designateclient,master,Id3e3da54a0ccd9a1bb521eca1390b626d1cb71cc,Add .eggs to gitignore,MERGED,2015-06-22 18:30:27.000000000,2015-06-24 18:55:26.000000000,2015-06-24 18:55:23.000000000,"[{'_account_id': 3}, {'_account_id': 741}, {'_account_id': 8094}, {'_account_id': 8099}, {'_account_id': 8174}]","[{'number': 1, 'created': '2015-06-22 18:30:27.000000000', 'files': ['.gitignore'], 'web_link': 'https://opendev.org/openstack/python-designateclient/commit/07bbd7e517462b2d82d39bdbc608902efe4a34fd', 'message': 'Add .eggs to gitignore\n\nChange-Id: Id3e3da54a0ccd9a1bb521eca1390b626d1cb71cc\n'}]",0,194288,07bbd7e517462b2d82d39bdbc608902efe4a34fd,7,5,1,741,,,0,"Add .eggs to gitignore

Change-Id: Id3e3da54a0ccd9a1bb521eca1390b626d1cb71cc
",git fetch https://review.opendev.org/openstack/python-designateclient refs/changes/88/194288/1 && git format-patch -1 --stdout FETCH_HEAD,['.gitignore'],1,07bbd7e517462b2d82d39bdbc608902efe4a34fd,,.eggs,,1,0
openstack%2Fopenstack-ansible~master~I2dfe3c9a9bf1c51c1f2530fc895ef3f4ba1f56c6,openstack/openstack-ansible,master,I2dfe3c9a9bf1c51c1f2530fc895ef3f4ba1f56c6,Rename group rpc to openstack,MERGED,2015-06-23 17:13:00.000000000,2015-06-24 18:55:12.000000000,2015-06-24 18:55:11.000000000,"[{'_account_id': 3}, {'_account_id': 425}, {'_account_id': 6816}, {'_account_id': 7219}, {'_account_id': 7353}, {'_account_id': 10068}]","[{'number': 1, 'created': '2015-06-23 17:13:00.000000000', 'files': ['playbooks/roles/lxc_hosts/templates/lxc-openstack.conf.j2'], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/1de9e33414834533727b5ddcfbd06b8182fb0778', 'message': 'Rename group rpc to openstack\n\nRenamed the lxc group rpc to openstack to remove leftover rpc variable.\n\nCloses-Bug #1457609\n\nChange-Id: I2dfe3c9a9bf1c51c1f2530fc895ef3f4ba1f56c6\n'}]",0,194749,1de9e33414834533727b5ddcfbd06b8182fb0778,11,6,1,16965,,,0,"Rename group rpc to openstack

Renamed the lxc group rpc to openstack to remove leftover rpc variable.

Closes-Bug #1457609

Change-Id: I2dfe3c9a9bf1c51c1f2530fc895ef3f4ba1f56c6
",git fetch https://review.opendev.org/openstack/openstack-ansible refs/changes/49/194749/1 && git format-patch -1 --stdout FETCH_HEAD,['playbooks/roles/lxc_hosts/templates/lxc-openstack.conf.j2'],1,1de9e33414834533727b5ddcfbd06b8182fb0778,bug/1457609,lxc.group = openstack,lxc.group = rpc,1,1
openstack%2Fopenstack-ansible~master~I1415e5822684af12e1a1dd8a306e708e8931fa38,openstack/openstack-ansible,master,I1415e5822684af12e1a1dd8a306e708e8931fa38,Fix errors when enabling SSL for apache,MERGED,2015-06-23 14:14:05.000000000,2015-06-24 18:54:55.000000000,2015-06-24 18:54:53.000000000,"[{'_account_id': 3}, {'_account_id': 425}, {'_account_id': 6816}, {'_account_id': 7353}, {'_account_id': 12000}]","[{'number': 1, 'created': '2015-06-23 14:14:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/280ed20d0196cffcee1fd35ad0c9b53d2228083f', 'message': 'Fix errors when enabling SSL for apache\n\nkeystone_ssl_enabled is used to determine whether or not to configure\napache to use SSL. Currently when this variable is set to true the\napache SSL module is not enabled.\n\nThis commit adds a task to enable/disable the SSL module based on the\nvariable keystone_ssl_enabled.\n\nThe keystone-httpd.conf template causes a formatting error. This commit\nfixes the error so that additional whitespace is no longer added before\nSSLEngine.\n\nChange-Id: I1415e5822684af12e1a1dd8a306e708e8931fa38\nCloses-bug: #1466827\n'}, {'number': 2, 'created': '2015-06-24 12:33:46.000000000', 'files': ['playbooks/roles/os_keystone/templates/keystone-httpd.conf.j2', 'playbooks/roles/os_keystone/tasks/keystone_apache.yml'], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/042771fd0713885ba26193c7a0708fccf187a744', 'message': 'Fix errors when enabling SSL for apache\n\nkeystone_ssl_enabled is used to determine whether or not to configure\napache to use SSL. Currently when this variable is set to true the\napache SSL module is not enabled.\n\nThis commit adds a task to enable/disable the SSL module based on the\nvariable keystone_ssl_enabled.\n\nThe keystone-httpd.conf template causes a formatting error. This commit\nfixes the error so that additional whitespace is no longer added before\nSSLEngine.\n\nChange-Id: I1415e5822684af12e1a1dd8a306e708e8931fa38\nCloses-bug: #1466827\n'}]",0,194672,042771fd0713885ba26193c7a0708fccf187a744,13,5,2,7219,,,0,"Fix errors when enabling SSL for apache

keystone_ssl_enabled is used to determine whether or not to configure
apache to use SSL. Currently when this variable is set to true the
apache SSL module is not enabled.

This commit adds a task to enable/disable the SSL module based on the
variable keystone_ssl_enabled.

The keystone-httpd.conf template causes a formatting error. This commit
fixes the error so that additional whitespace is no longer added before
SSLEngine.

Change-Id: I1415e5822684af12e1a1dd8a306e708e8931fa38
Closes-bug: #1466827
",git fetch https://review.opendev.org/openstack/openstack-ansible refs/changes/72/194672/2 && git format-patch -1 --stdout FETCH_HEAD,"['playbooks/roles/os_keystone/templates/keystone-httpd.conf.j2', 'playbooks/roles/os_keystone/tasks/keystone_apache.yml']",2,280ed20d0196cffcee1fd35ad0c9b53d2228083f,bug/1466827," - name: Enable/disable mod_ssl for apache2 apache2_module: name: ssl state: ""{{ (keystone_ssl_enabled | bool) | ternary('present', 'absent') }}""",,7,2
openstack%2Fkeystone~master~Ib2a11bb3802c1df6fd11569d6de22bea5b893ca5,openstack/keystone,master,Ib2a11bb3802c1df6fd11569d6de22bea5b893ca5,WIP: make keystone-wsgi-public a console entry point,ABANDONED,2015-06-24 11:36:05.000000000,2015-06-24 18:53:05.000000000,,"[{'_account_id': 3}, {'_account_id': 2903}, {'_account_id': 6486}]","[{'number': 1, 'created': '2015-06-24 11:36:05.000000000', 'files': ['setup.cfg', 'keystone/httpd/public.py'], 'web_link': 'https://opendev.org/openstack/keystone/commit/6227bf124ae892da49a63e571ab401cc64d27596', 'message': ""WIP: make keystone-wsgi-public a console entry point\n\nThis is a half baked sketch on what I think would be great to get to,\nit's untested, but it seemed a better way to explain things.\n\nChange-Id: Ib2a11bb3802c1df6fd11569d6de22bea5b893ca5\n""}]",0,195044,6227bf124ae892da49a63e571ab401cc64d27596,5,3,1,2750,,,0,"WIP: make keystone-wsgi-public a console entry point

This is a half baked sketch on what I think would be great to get to,
it's untested, but it seemed a better way to explain things.

Change-Id: Ib2a11bb3802c1df6fd11569d6de22bea5b893ca5
",git fetch https://review.opendev.org/openstack/keystone refs/changes/44/195044/1 && git format-patch -1 --stdout FETCH_HEAD,"['setup.cfg', 'keystone/httpd/public.py']",2,6227bf124ae892da49a63e571ab401cc64d27596,httpd," application = None def main(): if not __name__.startswith('_mod_wsgi'): raise Exception( ""This is designed to be run under mod_wsgi, not directly"") global application",if __name__.startswith('_mod_wsgi'): ,10,1
openstack%2Fcue~master~I58f09dd6fa3057af1ff55766e4f67e1a4604ea38,openstack/cue,master,I58f09dd6fa3057af1ff55766e4f67e1a4604ea38,Use fixture to register command line option,MERGED,2015-06-24 17:48:28.000000000,2015-06-24 18:47:06.000000000,2015-06-24 18:47:05.000000000,"[{'_account_id': 3}, {'_account_id': 10584}]","[{'number': 1, 'created': '2015-06-24 17:48:28.000000000', 'files': ['cue/tests/unit/cmd/test_manage.py'], 'web_link': 'https://opendev.org/openstack/cue/commit/4d3706e7db238cb611b900fb5ce486138d76090a', 'message': 'Use fixture to register command line option\n\nUse the config fixture to register the command line option in\ntest_fetch_func_args_database instead of registering it directly. This\nensures that the option is de-registered at the end of the test, and\nshould help with the intermittent failure in\nunit.common.test_service.TestCommonService.test_prepare_service.\n\nChange-Id: I58f09dd6fa3057af1ff55766e4f67e1a4604ea38\n'}]",0,195231,4d3706e7db238cb611b900fb5ce486138d76090a,6,2,1,2472,,,0,"Use fixture to register command line option

Use the config fixture to register the command line option in
test_fetch_func_args_database instead of registering it directly. This
ensures that the option is de-registered at the end of the test, and
should help with the intermittent failure in
unit.common.test_service.TestCommonService.test_prepare_service.

Change-Id: I58f09dd6fa3057af1ff55766e4f67e1a4604ea38
",git fetch https://review.opendev.org/openstack/cue refs/changes/31/195231/1 && git format-patch -1 --stdout FETCH_HEAD,['cue/tests/unit/cmd/test_manage.py'],1,4d3706e7db238cb611b900fb5ce486138d76090a,use-fixture-to-register-opt, self.CONF.register_cli_opt(category_opt), cfg.CONF.register_cli_opt(category_opt),1,1
openstack%2Ftrove-integration~master~If6bf4cea056cd9f865811966c8428eaf4c5c2cfe,openstack/trove-integration,master,If6bf4cea056cd9f865811966c8428eaf4c5c2cfe,Disable THP in MongoDB elements.,MERGED,2015-06-15 15:38:45.000000000,2015-06-24 18:38:41.000000000,2015-06-24 18:38:39.000000000,"[{'_account_id': 3}, {'_account_id': 4240}, {'_account_id': 5293}, {'_account_id': 7806}, {'_account_id': 10215}, {'_account_id': 10440}, {'_account_id': 15321}]","[{'number': 1, 'created': '2015-06-15 15:38:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/trove-integration/commit/f24f96665ec1d14e3a25c0b6843622fb4c08668d', 'message': 'Disable THP in MongoDB elements.\n\nMake sure to disable Linux kernel feature transparent huge pages,\nit will affect greatly both memory usage and latency in a negative way.\nSee: http://docs.mongodb.org/manual/tutorial/transparent-huge-pages/\n\nChange-Id: If6bf4cea056cd9f865811966c8428eaf4c5c2cfe\n'}, {'number': 2, 'created': '2015-06-15 16:50:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/trove-integration/commit/56e0347369e27c8ee193a5b7e4bd0191db334f1d', 'message': 'Disable THP in MongoDB elements\n\nMake sure to disable Linux kernel feature transparent huge pages,\nit will affect greatly both memory usage and latency in a negative way.\nSee: http://docs.mongodb.org/manual/tutorial/transparent-huge-pages/\n\nChange-Id: If6bf4cea056cd9f865811966c8428eaf4c5c2cfe'}, {'number': 3, 'created': '2015-06-15 17:42:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/trove-integration/commit/b81745cf22f3ed14757ff7c6d600c82533358127', 'message': 'Disable THP in MongoDB elements\n\nMake sure to disable Linux kernel feature transparent huge pages,\nit will affect greatly both memory usage and latency in a negative way.\nSee: http://docs.mongodb.org/manual/tutorial/transparent-huge-pages/\n\nChange-Id: If6bf4cea056cd9f865811966c8428eaf4c5c2cfe\nPartially Implements: blueprint mongodb-database'}, {'number': 4, 'created': '2015-06-17 15:29:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/trove-integration/commit/1a03d895937969a8f5c7a9263dd131eebaf984aa', 'message': 'Disable THP in MongoDB elements.\n\nMake sure to disable Linux kernel feature transparent huge pages,\nit will affect greatly both memory usage and latency in a negative way.\nSee: http://docs.mongodb.org/manual/tutorial/transparent-huge-pages/\n\nChange-Id: If6bf4cea056cd9f865811966c8428eaf4c5c2cfe\n'}, {'number': 5, 'created': '2015-06-17 15:35:32.000000000', 'files': ['scripts/files/elements/fedora-mongodb/install.d/10-mongodb', 'scripts/files/elements/ubuntu-mongodb/install.d/10-mongodb'], 'web_link': 'https://opendev.org/openstack/trove-integration/commit/967cf7f113ea605b33cffdecadd0810a000dd2cd', 'message': 'Disable THP in MongoDB elements.\n\nMake sure to disable Linux kernel feature transparent huge pages,\nit will affect greatly both memory usage and latency in a negative way.\nSee: http://docs.mongodb.org/manual/tutorial/transparent-huge-pages/\n\nPartially Implements: blueprint mongodb-database\nChange-Id: If6bf4cea056cd9f865811966c8428eaf4c5c2cfe'}]",3,191863,967cf7f113ea605b33cffdecadd0810a000dd2cd,22,7,5,14576,,,0,"Disable THP in MongoDB elements.

Make sure to disable Linux kernel feature transparent huge pages,
it will affect greatly both memory usage and latency in a negative way.
See: http://docs.mongodb.org/manual/tutorial/transparent-huge-pages/

Partially Implements: blueprint mongodb-database
Change-Id: If6bf4cea056cd9f865811966c8428eaf4c5c2cfe",git fetch https://review.opendev.org/openstack/trove-integration refs/changes/63/191863/1 && git format-patch -1 --stdout FETCH_HEAD,"['scripts/files/elements/fedora-mongodb/install.d/10-mongodb', 'scripts/files/elements/ubuntu-mongodb/install.d/10-mongodb']",2,f24f96665ec1d14e3a25c0b6843622fb4c08668d,mongodb-elements-fixes,"cat > ""/etc/rc.local"" << _EOF_ # Make sure to disable Linux kernel feature transparent huge pages, # it will affect greatly both memory usage and latency in a negative way. # See: http://docs.mongodb.org/manual/tutorial/transparent-huge-pages/ echo never > /sys/kernel/mm/transparent_hugepage/enabled echo never > /sys/kernel/mm/transparent_hugepage/defrag exit \$? _EOF_ ",,20,0
openstack%2Fneutron-lbaas~master~I678638fa0128621dd4bb2b2008b1ce98f6ba041d,openstack/neutron-lbaas,master,I678638fa0128621dd4bb2b2008b1ce98f6ba041d,Neutron_LBaaS: Update README.rst for Tests,MERGED,2015-03-04 18:06:10.000000000,2015-06-24 18:38:13.000000000,2015-06-24 18:38:11.000000000,"[{'_account_id': 3}, {'_account_id': 6951}, {'_account_id': 7812}, {'_account_id': 8179}, {'_account_id': 9008}, {'_account_id': 9828}, {'_account_id': 9897}, {'_account_id': 10850}, {'_account_id': 10980}, {'_account_id': 11302}, {'_account_id': 11343}, {'_account_id': 12040}, {'_account_id': 12417}, {'_account_id': 14556}]","[{'number': 1, 'created': '2015-03-04 18:06:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-lbaas/commit/e1146712b0711dff87c54f1a4a52a44159edc4ea', 'message': 'Initial Tempest Directory\n\nTempest test directory with api and scenario directory.\nTo be used for creating  neutron-lbaas tests.\n\nChange-Id: Ie22a8792942ef9c582f0804133077c048c047d6e\nCo-Author-By: Trevor Vardemon  <trevor.vardeman@RACKSPACE.COM>\nCo-Author-By: Carlos Garza  <carlos.garza@RACKSPACE.COM>\n\nNeutron_LBaaS: Update README for Tests\n\n* Updated the README file with information on installing and\n  running tests using Tempest\n* Also, mentioned future plans with fully using tempest-lib.\n\nChange-Id: I678638fa0128621dd4bb2b2008b1ce98f6ba041d\n'}, {'number': 2, 'created': '2015-03-04 20:15:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-lbaas/commit/74b03aa26580333ee258b10c4165fd0c2656f086', 'message': 'Neutron_LBaaS: Update README for Tests\n\n* Updated the README file with information on installing and\n  running tests using Tempest\n* Also, mentioned future plans with fully using tempest-lib.\n\nChange-Id: I678638fa0128621dd4bb2b2008b1ce98f6ba041d\n'}, {'number': 3, 'created': '2015-03-04 20:19:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-lbaas/commit/a86f2b2e168bf579021d3444f09886ca0f7c5220', 'message': 'Neutron_LBaaS: Update README for Tests\n\n* Updated the README file with information on installing and\n  running tests using Tempest\n* Also, mentioned future plans with fully using tempest-lib.\n\nChange-Id: I678638fa0128621dd4bb2b2008b1ce98f6ba041d\n'}, {'number': 4, 'created': '2015-03-05 17:07:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-lbaas/commit/e449a1091fafbd59a0f60da4d6d754a7e4d19441', 'message': 'Neutron_LBaaS: Update README for Tests\n\n* Added README file with information on installing and\n  running tests using Tempest\n* Also, mentioned future plans with fully using tempest-lib.\n\nChange-Id: I678638fa0128621dd4bb2b2008b1ce98f6ba041d\n'}, {'number': 5, 'created': '2015-03-05 17:08:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-lbaas/commit/af9b1f0bbff4c7ff5aee3b6f70a8aa0bd0cea9be', 'message': 'Neutron_LBaaS: Update README for Tests\n\n* Added README file with information on installing and\n  running tests using Tempest\n* Also, mentioned future plans with fully using tempest-lib.\n\nChange-Id: I678638fa0128621dd4bb2b2008b1ce98f6ba041d\n'}, {'number': 6, 'created': '2015-03-06 20:26:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-lbaas/commit/1cfdff05c0e26a2de95938cd611669df9cf7edad', 'message': 'Neutron_LBaaS: Update README for Tests\n\n* Added README file with information on installing and\n  running tests using Tempest\n* Also, mentioned future plans with fully using tempest-lib.\n\nChange-Id: I678638fa0128621dd4bb2b2008b1ce98f6ba041d\n'}, {'number': 7, 'created': '2015-03-11 16:18:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-lbaas/commit/04f220a7c698e9eca796adcf0dfab3918822c3e0', 'message': 'Neutron_LBaaS: Update README for Tests\n\n* Added README file with information on installing and\n  running tests using Tempest\n* Also, mentioned future plans with fully using tempest-lib.\n\nChange-Id: I678638fa0128621dd4bb2b2008b1ce98f6ba041d\n'}, {'number': 8, 'created': '2015-04-08 19:25:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-lbaas/commit/79ea3597caf2edcc46da1cc299fe1ddf2ef5fdac', 'message': 'Neutron_LBaaS: Update README for Tests\n\n* Added README file with information on installing and\n  running tests using Tempest\n* Also, mentioned future plans with fully using tempest-lib.\n\nChange-Id: I678638fa0128621dd4bb2b2008b1ce98f6ba041d\n'}, {'number': 9, 'created': '2015-04-08 19:59:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-lbaas/commit/c2f70bb95158b223915760b50cab1e1b14b3b500', 'message': 'Neutron_LBaaS: Update README for Tests\n\n* Added README file with information on installing and\n  running tests using Tempest\n* Also, mentioned future plans with fully using tempest-lib.\n\nChange-Id: I678638fa0128621dd4bb2b2008b1ce98f6ba041d\n'}, {'number': 10, 'created': '2015-06-19 00:08:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-lbaas/commit/b98ef4b95f0b28065c9e39742dbf1b07a2c44032', 'message': 'Neutron_LBaaS: Update README for Tests\n\n* Added README.rst file with information on installing and\n  running tests\n* Edited README to reflect the latest change\n\nChange-Id: I678638fa0128621dd4bb2b2008b1ce98f6ba041d\nCo-Authored-By: Madhusudhan Kandadai  <madhusudhan.kandadai@hp.com>\n'}, {'number': 11, 'created': '2015-06-19 00:13:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-lbaas/commit/63067efc5ead9058f0e531ff6b83514dd603d1d8', 'message': 'Neutron_LBaaS: Update README for Tests\n\n* Added README.rst file with information on installing and\n  running tests\n* Edited README to reflect the latest change\n\nChange-Id: I678638fa0128621dd4bb2b2008b1ce98f6ba041d\nCo-Authored-By: Madhusudhan Kandadai  <madhusudhan.kandadai@hp.com>\n'}, {'number': 12, 'created': '2015-06-19 18:58:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-lbaas/commit/c6974f51a68677f0ae3b1622d01f26e1bc457eaa', 'message': 'Neutron_LBaaS: Update README for Tests\n\n* Added README.rst file with information on installing and\n  running tests\n* Removed README to avoid confusion in picking the right README file\n\nChange-Id: I678638fa0128621dd4bb2b2008b1ce98f6ba041d\nCo-Authored-By: Madhusudhan Kandadai  <madhusudhan.kandadai@hp.com>\n'}, {'number': 13, 'created': '2015-06-24 03:47:33.000000000', 'files': ['neutron_lbaas/tests/tempest/README', 'neutron_lbaas/tests/tempest/README.rst'], 'web_link': 'https://opendev.org/openstack/neutron-lbaas/commit/285991d443c880bd810d6731af0542af7259f1e5', 'message': 'Neutron_LBaaS: Update README.rst for Tests\n\n* Updated README.rst file with information on installing and\n  running tests\n* Removed README to avoid confusion in having two README files\n\nChange-Id: I678638fa0128621dd4bb2b2008b1ce98f6ba041d\nCo-Authored-By: Madhusudhan Kandadai  <madhusudhan.kandadai@hp.com>\n'}]",18,161346,285991d443c880bd810d6731af0542af7259f1e5,71,14,13,7812,,,0,"Neutron_LBaaS: Update README.rst for Tests

* Updated README.rst file with information on installing and
  running tests
* Removed README to avoid confusion in having two README files

Change-Id: I678638fa0128621dd4bb2b2008b1ce98f6ba041d
Co-Authored-By: Madhusudhan Kandadai  <madhusudhan.kandadai@hp.com>
",git fetch https://review.opendev.org/openstack/neutron-lbaas refs/changes/46/161346/9 && git format-patch -1 --stdout FETCH_HEAD,"['neutron_lbaas/tests/tempest/api/__init__.py', 'neutron_lbaas/tests/tempest/scenario/__init__.py', 'README.rst']",3,e1146712b0711dff87c54f1a4a52a44159edc4ea,neutron_lbaas_readme_tempest_v2," API Testing with Tempest: ------------------------- Included in the repo are Tempest tests. If you're familiar with the Tempest Testing Framework continue on, otherwise please see the Tempest README : https://github.com/openstack/tempest/blob/master/README.rst 1. Using Devstack ^^^^^^^^^^^^^^^^^ If you have a running devstack environment, tempest will be automatically configured and placed in ``/opt/stack/tempest``. It will have a configuration file already set up to work with your devstack installation. You will need to install tempest to run the tests. You can do this by running inside ``/opt/stack/tempest`` :: $> sudo python setup.py install Once installed, you can run the tests by using ``nosetests`` :: $> nosetests . 2. Not using Devstack ^^^^^^^^^^^^^^^^^^^^^ 3/4/2015 - As we do not have an external Openstack environment with Neutron_LBaaS V2 to test with, this is TBD 3. Packages tempest vs. tempest-lib ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ Currently you will need to install the tempest directory for running the API tests that are located in the ``/neutron_lbaas/tests/tests/tempest`` directory. This is because the dependent neutron packages used to set up the tests are required. These packages have not yet been migrated over to tempest-lib. As of 3/4/2015, the migration of neutron test libraries to tempest-lib is still on-going. Once fully merged and tested to be working, we will submit a change to transition the API tests over to using tempest-lib. You will still need, however, tempest-lib, installed for running the basic unit tests. For more information on the Tempest testing framework see: <https://github.com/openstack/tempest>",,50,0
openstack%2Fec2-api~master~Ia6ad0fdf0fbd8d62d2e4953b72a06f2f4a9863bf,openstack/ec2-api,master,Ia6ad0fdf0fbd8d62d2e4953b72a06f2f4a9863bf,Restrict botocore version for functional testing,ABANDONED,2015-06-23 12:52:18.000000000,2015-06-24 18:35:13.000000000,,"[{'_account_id': 3}, {'_account_id': 10224}, {'_account_id': 10234}]","[{'number': 1, 'created': '2015-06-23 12:52:18.000000000', 'files': ['ec2api/tests/contrib/post_test_hook.sh'], 'web_link': 'https://opendev.org/openstack/ec2-api/commit/6b6baae392c48ef7e630313002256c9f00a3752d', 'message': 'Restrict botocore version for functional testing\n\nChange-Id: Ia6ad0fdf0fbd8d62d2e4953b72a06f2f4a9863bf\n'}]",0,194644,6b6baae392c48ef7e630313002256c9f00a3752d,5,3,1,10224,,,0,"Restrict botocore version for functional testing

Change-Id: Ia6ad0fdf0fbd8d62d2e4953b72a06f2f4a9863bf
",git fetch https://review.opendev.org/openstack/ec2-api refs/changes/44/194644/1 && git format-patch -1 --stdout FETCH_HEAD,['ec2api/tests/contrib/post_test_hook.sh'],1,6b6baae392c48ef7e630313002256c9f00a3752d,,"sudo pip install 'botocore>=0.85,<1.0.0'",sudo pip install botocore,1,1
openstack%2Fec2-api~master~I75e1bbcd81678a56a0940b696cfa5dbc2c159cc6,openstack/ec2-api,master,I75e1bbcd81678a56a0940b696cfa5dbc2c159cc6,Update botocore client and use cloned novaclient for functional tests,MERGED,2015-06-22 12:47:32.000000000,2015-06-24 18:32:55.000000000,2015-06-24 18:32:53.000000000,"[{'_account_id': 3}, {'_account_id': 10224}, {'_account_id': 10234}]","[{'number': 1, 'created': '2015-06-22 12:47:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ec2-api/commit/21f0636819ebc58d70c21a08a1869c6f006208d6', 'message': 'update botocore client for functional tests\n\nChange-Id: I75e1bbcd81678a56a0940b696cfa5dbc2c159cc6\n'}, {'number': 2, 'created': '2015-06-23 13:50:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ec2-api/commit/0804133c1ba00705a80846d7eac868168dc69e33', 'message': 'update botocore client for functional tests\n\nChange-Id: I75e1bbcd81678a56a0940b696cfa5dbc2c159cc6\n'}, {'number': 3, 'created': '2015-06-24 05:49:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ec2-api/commit/c0fee27250db26cc339b92bf667ceae4649503d6', 'message': 'Update botocore client and use cloned novaclient for functional tests\n\nSince botocore 1.0.0 is released we make ec2api functional tests\nto be compatible with it.\n\nPreviously used novaclient modification (v14 of\nhttps://review.openstack.org/#/c/152569/) is too obsolete. It is not\ncompatible with modern oslo libraries. Current version of this\nmodification (v34) is obsolete as well.\n\nThe proposed solution is to use a separate novaclient repository, which\ncan be maintained independently of community. Until microversions are\nnot supported by novaclient upstream.\n\nChange-Id: I75e1bbcd81678a56a0940b696cfa5dbc2c159cc6\n'}, {'number': 4, 'created': '2015-06-24 10:20:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ec2-api/commit/ca2e5b1acb11e91485cd9e478537cc3413f07c4b', 'message': 'Update botocore client and use cloned novaclient for functional tests\n\nSince botocore 1.0.0 is released we make ec2api functional tests\nto be compatible with it.\n\nPreviously used novaclient modification (v14 of\nhttps://review.openstack.org/#/c/152569/) is too obsolete. It is not\ncompatible with modern oslo libraries. Current version of this\nmodification (v34) is obsolete as well.\n\nThe proposed solution is to use a separate novaclient repository, which\ncan be maintained independently of community. Until microversions are\nnot supported by novaclient upstream.\n\nChange-Id: I75e1bbcd81678a56a0940b696cfa5dbc2c159cc6\n'}, {'number': 5, 'created': '2015-06-24 11:09:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ec2-api/commit/699a3c65c095df8441a64cf1e4eb880f736d1083', 'message': 'Update botocore client and use cloned novaclient for functional tests\n\nSince botocore 1.0.0 is released we make ec2api functional tests\nto be compatible with it.\n\nPreviously used novaclient modification (v14 of\nhttps://review.openstack.org/#/c/152569/) is too obsolete. It is not\ncompatible with modern oslo libraries. Current version of this\nmodification (v34) is obsolete as well.\n\nThe proposed solution is to use a separate novaclient repository, which\ncan be maintained independently of community. Until microversions are\nnot supported by novaclient upstream.\n\nChange-Id: I75e1bbcd81678a56a0940b696cfa5dbc2c159cc6\n'}, {'number': 6, 'created': '2015-06-24 12:08:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ec2-api/commit/feff012811323d18cbadb68a5e5329c5a3573082', 'message': 'Update botocore client and use cloned novaclient for functional tests\n\nSince botocore 1.0.0 is released we make ec2api functional tests\nto be compatible with it.\n\nPreviously used novaclient modification (v14 of\nhttps://review.openstack.org/#/c/152569/) is too obsolete. It is not\ncompatible with modern oslo libraries. Current version of this\nmodification (v34) is obsolete as well.\n\nThe proposed solution is to use a separate novaclient repository, which\ncan be maintained independently of community. Until microversions are\nnot supported by novaclient upstream.\n\nChange-Id: I75e1bbcd81678a56a0940b696cfa5dbc2c159cc6\n'}, {'number': 7, 'created': '2015-06-24 12:26:16.000000000', 'files': ['ec2api/tests/functional/botocoreclient.py', 'devstack/settings'], 'web_link': 'https://opendev.org/openstack/ec2-api/commit/45bde55bbb2626715da518260a62dba0fd63db44', 'message': 'Update botocore client and use cloned novaclient for functional tests\n\nSince botocore 1.0.0 is released we make ec2api functional tests\nto be compatible with it.\n\nPreviously used novaclient modification (v14 of\nhttps://review.openstack.org/#/c/152569/) is too obsolete. It is not\ncompatible with modern oslo libraries. Current version of this\nmodification (v34) is obsolete as well.\n\nThe proposed solution is to use a separate novaclient repository, which\ncan be maintained independently of community. Until microversions are\nnot supported by novaclient upstream.\n\nChange-Id: I75e1bbcd81678a56a0940b696cfa5dbc2c159cc6\n'}]",0,194125,45bde55bbb2626715da518260a62dba0fd63db44,41,3,7,10234,,,0,"Update botocore client and use cloned novaclient for functional tests

Since botocore 1.0.0 is released we make ec2api functional tests
to be compatible with it.

Previously used novaclient modification (v14 of
https://review.openstack.org/#/c/152569/) is too obsolete. It is not
compatible with modern oslo libraries. Current version of this
modification (v34) is obsolete as well.

The proposed solution is to use a separate novaclient repository, which
can be maintained independently of community. Until microversions are
not supported by novaclient upstream.

Change-Id: I75e1bbcd81678a56a0940b696cfa5dbc2c159cc6
",git fetch https://review.opendev.org/openstack/ec2-api refs/changes/25/194125/6 && git format-patch -1 --stdout FETCH_HEAD,['ec2api/tests/functional/botocoreclient.py'],1,21f0636819ebc58d70c21a08a1869c6f006208d6,master-2," 'config_file': (None, 'AWS_CONFIG_FILE', None, None), 'region': ('region', 'BOTO_DEFAULT_REGION', region, None),"," 'config_file': (None, 'AWS_CONFIG_FILE', None), 'region': ('region', 'BOTO_DEFAULT_REGION', region),",2,2
openstack%2Fos-testr~master~I88af9104352163f2412c2a3cbaf6c88d0a937988,openstack/os-testr,master,I88af9104352163f2412c2a3cbaf6c88d0a937988,Dogfood things for unit tests,MERGED,2015-06-23 23:34:19.000000000,2015-06-24 18:29:41.000000000,2015-06-24 18:29:40.000000000,"[{'_account_id': 3}, {'_account_id': 5196}]","[{'number': 1, 'created': '2015-06-23 23:34:19.000000000', 'files': ['tox.ini'], 'web_link': 'https://opendev.org/openstack/os-testr/commit/0abbeeac4b280a6157e3e89d456aa17c27c61414', 'message': ""Dogfood things for unit tests\n\nSo it turns out we weren't actually using ostestr for running the\nos-testr unit tests. We probably should use the test runner runner\nwrapper we're developing to run the unit tests for the test runner\nrunner wrapper and the other utilities in the package.\n\nChange-Id: I88af9104352163f2412c2a3cbaf6c88d0a937988\n""}]",0,194870,0abbeeac4b280a6157e3e89d456aa17c27c61414,6,2,1,5196,,,0,"Dogfood things for unit tests

So it turns out we weren't actually using ostestr for running the
os-testr unit tests. We probably should use the test runner runner
wrapper we're developing to run the unit tests for the test runner
runner wrapper and the other utilities in the package.

Change-Id: I88af9104352163f2412c2a3cbaf6c88d0a937988
",git fetch https://review.opendev.org/openstack/os-testr refs/changes/70/194870/1 && git format-patch -1 --stdout FETCH_HEAD,['tox.ini'],1,0abbeeac4b280a6157e3e89d456aa17c27c61414,(HEAD,commands = ostestr {posargs},commands = python setup.py testr --slowest --testr-args='{posargs}',1,1
openstack%2Fopenstacksdk~master~If643f27eb443dd5b1abeae67c826cde95167ff27,openstack/openstacksdk,master,If643f27eb443dd5b1abeae67c826cde95167ff27,Add functional tests for floating IP.,MERGED,2015-06-24 17:20:26.000000000,2015-06-24 18:16:16.000000000,2015-06-24 18:16:15.000000000,"[{'_account_id': 3}, {'_account_id': 8736}]","[{'number': 1, 'created': '2015-06-24 17:20:26.000000000', 'files': ['openstack/tests/functional/network/v2/test_floating_ip.py'], 'web_link': 'https://opendev.org/openstack/openstacksdk/commit/5bb154f41f25d8c9bbd9067b29a03a5fc2dff371', 'message': 'Add functional tests for floating IP.\n\nChange-Id: If643f27eb443dd5b1abeae67c826cde95167ff27\n'}]",0,195209,5bb154f41f25d8c9bbd9067b29a03a5fc2dff371,6,2,1,15739,,,0,"Add functional tests for floating IP.

Change-Id: If643f27eb443dd5b1abeae67c826cde95167ff27
",git fetch https://review.opendev.org/openstack/openstacksdk refs/changes/09/195209/1 && git format-patch -1 --stdout FETCH_HEAD,['openstack/tests/functional/network/v2/test_floating_ip.py'],1,5bb154f41f25d8c9bbd9067b29a03a5fc2dff371,test_floating_ip,"# Licensed under the Apache License, Version 2.0 (the ""License""); you may # not use this file except in compliance with the License. You may obtain # a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT # WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the # License for the specific language governing permissions and limitations # under the License. import uuid from openstack.network.v2 import floating_ip from openstack.network.v2 import network from openstack.network.v2 import subnet from openstack.tests.functional import base class TestFloatingIP(base.BaseFunctionalTest): NET_NAME = uuid.uuid4().hex SUB_NAME = uuid.uuid4().hex IPV4 = 4 CIDR = ""10.100.0.0/24"" NET_ID = None SUB_ID = None FIP_ID = None @classmethod def setUpClass(cls): super(TestFloatingIP, cls).setUpClass() args = {'router:external': True} net = cls.conn.network.create_network(name=cls.NET_NAME, **args) assert isinstance(net, network.Network) cls.assertIs(cls.NET_NAME, net.name) cls.NET_ID = net.id sub = cls.conn.network.create_subnet(name=cls.SUB_NAME, ip_version=cls.IPV4, network_id=cls.NET_ID, cidr=cls.CIDR) assert isinstance(sub, subnet.Subnet) cls.assertIs(cls.SUB_NAME, sub.name) cls.SUB_ID = sub.id fip = cls.conn.network.create_ip(floating_network_id=cls.NET_ID) assert isinstance(fip, floating_ip.FloatingIP) cls.FIP_ID = fip.id @classmethod def tearDownClass(cls): sot = cls.conn.network.delete_ip(cls.FIP_ID, ignore_missing=False) cls.assertIs(None, sot) sot = cls.conn.network.delete_subnet(cls.SUB_ID, ignore_missing=False) cls.assertIs(None, sot) sot = cls.conn.network.delete_network(cls.NET_ID, ignore_missing=False) cls.assertIs(None, sot) def test_find(self): sot = self.conn.network.find_ip(self.FIP_ID) self.assertEqual(self.FIP_ID, sot.id) def test_get(self): sot = self.conn.network.get_ip(self.FIP_ID) self.assertEqual(self.NET_ID, sot.floating_network_id) self.assertEqual('10.100.0.2', sot.floating_ip_address) self.assertIn('floating_ip_address', sot) self.assertIn('fixed_ip_address', sot) self.assertIn('port_id', sot) self.assertIn('router_id', sot) def test_list(self): ids = [o.id for o in self.conn.network.ips()] self.assertIn(self.FIP_ID, ids) ",,74,0
openstack%2Fironic-specs~master~I51f061aabd59b894cd8935fbaf417e3c7455d804,openstack/ironic-specs,master,I51f061aabd59b894cd8935fbaf417e3c7455d804,Allow all printable unicode and horizontal spaces in logical names,ABANDONED,2015-06-24 15:12:29.000000000,2015-06-24 18:10:32.000000000,,"[{'_account_id': 3}, {'_account_id': 2889}, {'_account_id': 6618}]","[{'number': 1, 'created': '2015-06-24 15:12:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic-specs/commit/c191d15326b34a7937ca39ef18d2406985621823', 'message': 'Allow all printable unicode and horizontal spaces in logical names\n\nUpdate the logical names spec to permit freeform strings as logical\nnames, rather than restricting it to an RFC 952 hostname.\n\nChange-Id: I51f061aabd59b894cd8935fbaf417e3c7455d804\nPartial-Bug: 1434376\n'}, {'number': 2, 'created': '2015-06-24 16:29:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic-specs/commit/5932005646d1d16b45ad4669a112a234ff091f4f', 'message': 'Allow all printable unicode and horizontal spaces in logical names\n\nPermit freeform strings as logical names, rather than restricting it\nto an RFC 952 hostname.\n\nPartial-Bug: 1434376\nChange-Id: I51f061aabd59b894cd8935fbaf417e3c7455d804\n'}, {'number': 3, 'created': '2015-06-24 16:40:05.000000000', 'files': ['specs/liberty/freeform-logical-names.rst'], 'web_link': 'https://opendev.org/openstack/ironic-specs/commit/20c0e0e68cd8a0dbe5ca6bb54b3110d6b7a66ea0', 'message': 'Allow all printable unicode and horizontal spaces in logical names\n\nPermit freeform strings as logical names, rather than restricting it\nto an RFC 952 hostname.\n\nPartial-Bug: 1434376\nChange-Id: I51f061aabd59b894cd8935fbaf417e3c7455d804\n'}]",4,195138,20c0e0e68cd8a0dbe5ca6bb54b3110d6b7a66ea0,11,3,3,11748,,,0,"Allow all printable unicode and horizontal spaces in logical names

Permit freeform strings as logical names, rather than restricting it
to an RFC 952 hostname.

Partial-Bug: 1434376
Change-Id: I51f061aabd59b894cd8935fbaf417e3c7455d804
",git fetch https://review.opendev.org/openstack/ironic-specs refs/changes/38/195138/1 && git format-patch -1 --stdout FETCH_HEAD,['specs/kilo/logical-names.rst'],1,c191d15326b34a7937ca39ef18d2406985621823,bug/1434376," This change introduces the concept of a <logical name> to ironic so that a human readable name can be associated with nodes. The <logical name> is only intended for human consumption, so may contain all printable Unicode characters and horizontal spaces. The maximum length of a <logical name> is 255 characters, although database implementations may limit this further depending on their handling of Unicode. else if is_valid_logical_name(value):","This change introduces the concept of a <logical name> to ironic so that a human readable name can be associated with nodes. This <logical name> should be hostname safe, that is, the node logical name should also be usable as the hostname for the instance. For this to be true, the following references should be used to define what is a valid <logical name>: [wikipedia:hostname], [RFC952] and [RFC1123]. In simple english, what this means is that <logical names>s can be between 1 and 63 characters long, with the valid characters being [a-z0-9] and '-', except that a <logical name> cannot begin or end with a '-'. As a regular expression, this can be represented as: <logical name> == [a-z0-9]([a-z0-9\-]{0,61}[a-z0-9]|[a-z0-9]{0,62})? else if is_hostname_like(value): * [wikipedia:hostname] - http://en.wikipedia.org/wiki/Hostname * [RFC952] - http://tools.ietf.org/html/rfc952 * [RFC1123] - http://tools.ietf.org/html/rfc1123 ",8,20
openstack%2Fpython-novaclient~master~I8948bdd08ea55200ce7899ee8704651eb08a359a,openstack/python-novaclient,master,I8948bdd08ea55200ce7899ee8704651eb08a359a,Updated from global requirements,MERGED,2015-06-24 00:21:39.000000000,2015-06-24 18:01:02.000000000,2015-06-24 18:01:01.000000000,"[{'_account_id': 3}, {'_account_id': 679}, {'_account_id': 1849}]","[{'number': 1, 'created': '2015-06-24 00:21:39.000000000', 'files': ['test-requirements.txt'], 'web_link': 'https://opendev.org/openstack/python-novaclient/commit/916993a1f654948a65ee0916ceae2df253a78a59', 'message': 'Updated from global requirements\n\nChange-Id: I8948bdd08ea55200ce7899ee8704651eb08a359a\n'}]",0,194889,916993a1f654948a65ee0916ceae2df253a78a59,7,3,1,11131,,,0,"Updated from global requirements

Change-Id: I8948bdd08ea55200ce7899ee8704651eb08a359a
",git fetch https://review.opendev.org/openstack/python-novaclient refs/changes/89/194889/1 && git format-patch -1 --stdout FETCH_HEAD,['test-requirements.txt'],1,916993a1f654948a65ee0916ceae2df253a78a59,openstack/requirements,os-client-config>=1.4.0,os-client-config>=1.2.0,1,1
openstack%2Fastara~master~Ic49cd21376d024f4834523dabc5c320946dbd012,openstack/astara,master,Ic49cd21376d024f4834523dabc5c320946dbd012,Capture and gracefully handle failed interface attach/detach API calls.,MERGED,2015-06-18 20:16:37.000000000,2015-06-24 17:53:01.000000000,2015-06-24 17:52:59.000000000,"[{'_account_id': 3}, {'_account_id': 1420}, {'_account_id': 2592}, {'_account_id': 6287}, {'_account_id': 6923}, {'_account_id': 8005}]","[{'number': 1, 'created': '2015-06-18 20:16:37.000000000', 'files': ['akanda/rug/vm_manager.py'], 'web_link': 'https://opendev.org/openstack/astara/commit/dc6336f965c46da2249da7f804b3c88bbf983e31', 'message': 'Capture and gracefully handle failed interface attach/detach API calls.\n\nWhen the rug notices a discrepancy between the interfaces on a router VM and\nthe ports that neutron knows about, it attempts to resolve them via Nova\n`interface-attach` and `interface-detach` API calls.  If these calls fail,\nhowever, the state machine falls into an endless loop of -> Configure -> Replug\n-> Configure -> Replug.  In the event that VM hot plugging/unplugging fails, we\nshould fall back to recreating the VM.\n\nChange-Id: Ic49cd21376d024f4834523dabc5c320946dbd012\nFixes-bug: #1466623\n'}]",0,193292,dc6336f965c46da2249da7f804b3c88bbf983e31,7,6,1,8005,,,0,"Capture and gracefully handle failed interface attach/detach API calls.

When the rug notices a discrepancy between the interfaces on a router VM and
the ports that neutron knows about, it attempts to resolve them via Nova
`interface-attach` and `interface-detach` API calls.  If these calls fail,
however, the state machine falls into an endless loop of -> Configure -> Replug
-> Configure -> Replug.  In the event that VM hot plugging/unplugging fails, we
should fall back to recreating the VM.

Change-Id: Ic49cd21376d024f4834523dabc5c320946dbd012
Fixes-bug: #1466623
",git fetch https://review.opendev.org/openstack/astara refs/changes/92/193292/1 && git format-patch -1 --stdout FETCH_HEAD,['akanda/rug/vm_manager.py'],1,dc6336f965c46da2249da7f804b3c88bbf983e31,bug/1466623," try: instance.interface_attach(port.id, None, None) except: self.log.exception('Interface attach failed') self.state = RESTART return try: instance.interface_detach(port.id) except: self.log.exception('Interface detach failed') self.state = RESTART return"," instance.interface_attach(port.id, None, None) instance.interface_detach(port.id)",12,2
openstack%2Fopenstack-ansible~master~I95b456672f419fcc331d6739ce259b022d350472,openstack/openstack-ansible,master,I95b456672f419fcc331d6739ce259b022d350472,Add read/write_affinity settings for Swift,MERGED,2015-06-12 11:50:47.000000000,2015-06-24 17:52:18.000000000,2015-06-21 01:34:51.000000000,"[{'_account_id': 3}, {'_account_id': 7353}, {'_account_id': 9884}, {'_account_id': 12892}]","[{'number': 1, 'created': '2015-06-12 11:50:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/bacb8734744a88acf8f1361ecb88ed720b60cbf2', 'message': ""Add read/write_affinity settings for Swift\n\nAllow the setting of read/write_affinity and write_affinity_node_count\non a per proxy_host basis.\n\nThis allows the deployer to set preferences for which region to\nread/write to, which can increase the efficiency of a multi-region\nswift cluster.\n\nSample swift.yml has been updated, as well as the aio swift.yml to\nensure these settings are setup as part of the gate, but this shouldn't\nchange the functionality of swift at all (since there is only 1 region).\n\nChange-Id: I95b456672f419fcc331d6739ce259b022d350472\nCloses-Bug: #1415172\n""}, {'number': 2, 'created': '2015-06-12 21:53:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/57026a2c31c570bf58250975601adee4cb4fb3e6', 'message': ""Add read/write_affinity settings for Swift\n\nAllow the setting of read/write_affinity and write_affinity_node_count\non a per proxy_host basis.\n\nThis allows the deployer to set preferences for which region to\nread/write to, which can increase the efficiency of a multi-region\nswift cluster.\n\nSample swift.yml has been updated, as well as the aio swift.yml to\nensure these settings are setup as part of the gate, but this shouldn't\nchange the functionality of swift at all (since there is only 1 region).\n\nChange-Id: I95b456672f419fcc331d6739ce259b022d350472\nCloses-Bug: #1415172\n""}, {'number': 3, 'created': '2015-06-13 06:12:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/f7b73d52fff9ab3bb7891acdc789caa562a03b4c', 'message': ""Add read/write_affinity settings for Swift\n\nAllow the setting of read/write_affinity and write_affinity_node_count\non a per proxy_host basis.\n\nThis allows the deployer to set preferences for which region to\nread/write to, which can increase the efficiency of a multi-region\nswift cluster.\n\nSample swift.yml has been updated, as well as the aio swift.yml to\nensure these settings are setup as part of the gate, but this shouldn't\nchange the functionality of swift at all (since there is only 1 region).\n\nChange-Id: I95b456672f419fcc331d6739ce259b022d350472\nCloses-Bug: #1415172\n""}, {'number': 4, 'created': '2015-06-13 06:27:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/4a87fcba1b466bf4a9d045c4ec54842f64050732', 'message': ""Add read/write_affinity settings for Swift\n\nAllow the setting of read/write_affinity and write_affinity_node_count\non a per proxy_host basis.\n\nThis allows the deployer to set preferences for which region to\nread/write to, which can increase the efficiency of a multi-region\nswift cluster.\n\nSample swift.yml has been updated, as well as the aio swift.yml to\nensure these settings are setup as part of the gate, but this shouldn't\nchange the functionality of swift at all (since there is only 1 region).\n\nChange-Id: I95b456672f419fcc331d6739ce259b022d350472\nCloses-Bug: #1415172\n""}, {'number': 5, 'created': '2015-06-13 14:52:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/392f8e69041bf43ee0e85e04798327ca6d8e4b6e', 'message': ""Add read/write_affinity settings for Swift\n\nAllow the setting of read/write_affinity and write_affinity_node_count\non a per proxy_host basis.\n\nThis allows the deployer to set preferences for which region to\nread/write to, which can increase the efficiency of a multi-region\nswift cluster.\n\nSample swift.yml has been updated, as well as the aio swift.yml to\nensure these settings are setup as part of the gate, but this shouldn't\nchange the functionality of swift at all (since there is only 1 region).\n\nChange-Id: I95b456672f419fcc331d6739ce259b022d350472\nCloses-Bug: #1415172\n""}, {'number': 6, 'created': '2015-06-13 20:02:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/66fcb1eff2496f6b77306487b43c9d92b06f0fd4', 'message': ""Add read/write_affinity settings for Swift\n\nAllow the setting of read/write_affinity and write_affinity_node_count\non a per proxy_host basis.\n\nThis allows the deployer to set preferences for which region to\nread/write to, which can increase the efficiency of a multi-region\nswift cluster.\n\nSample swift.yml has been updated, as well as the aio swift.yml to\nensure these settings are setup as part of the gate, but this shouldn't\nchange the functionality of swift at all (since there is only 1 region).\n\nChange-Id: I95b456672f419fcc331d6739ce259b022d350472\nCloses-Bug: #1415172\n""}, {'number': 7, 'created': '2015-06-15 20:55:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/93c932dbdad242fb2090ee4096952f37c53b3b8e', 'message': ""Add read/write_affinity settings for Swift\n\nAllow the setting of read/write_affinity and write_affinity_node_count\non a per proxy_host basis.\n\nThis allows the deployer to set preferences for which region to\nread/write to, which can increase the efficiency of a multi-region\nswift cluster.\n\nSample swift.yml has been updated, as well as the aio swift.yml to\nensure these settings are setup as part of the gate, but this shouldn't\nchange the functionality of swift at all (since there is only 1 region).\n\nChange-Id: I95b456672f419fcc331d6739ce259b022d350472\nCloses-Bug: #1415172\n""}, {'number': 8, 'created': '2015-06-16 22:27:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/3019852bef99b62f70bb721961322cfb5754d42d', 'message': ""Add read/write_affinity settings for Swift\n\nAllow the setting of read/write_affinity and write_affinity_node_count\non a per proxy_host basis.\n\nThis allows the deployer to set preferences for which region to\nread/write to, which can increase the efficiency of a multi-region\nswift cluster.\n\nSample swift.yml has been updated, as well as the aio swift.yml to\nensure these settings are setup as part of the gate, but this shouldn't\nchange the functionality of swift at all (since there is only 1 region).\n\nChange-Id: I95b456672f419fcc331d6739ce259b022d350472\nCloses-Bug: #1415172\n""}, {'number': 9, 'created': '2015-06-19 09:08:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/3b72c47d785f701a4b63bf79825f730181544f27', 'message': ""Add read/write_affinity settings for Swift\n\nAllow the setting of read/write_affinity and write_affinity_node_count\non a per proxy_host basis.\n\nThis allows the deployer to set preferences for which region to\nread/write to, which can increase the efficiency of a multi-region\nswift cluster.\n\nSample swift.yml has been updated, as well as the aio swift.yml to\nensure these settings are setup as part of the gate, but this shouldn't\nchange the functionality of swift at all (since there is only 1 region).\n\nChange-Id: I95b456672f419fcc331d6739ce259b022d350472\nCloses-Bug: #1415172\n""}, {'number': 10, 'created': '2015-06-19 11:30:45.000000000', 'files': ['etc/openstack_deploy/conf.d/swift.yml.example', 'playbooks/roles/os_swift/templates/proxy-server.conf.j2', 'etc/openstack_deploy/conf.d/swift.yml.aio'], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/5b9b49f52b12052f93c72f44a31a972f2e98620c', 'message': ""Add read/write_affinity settings for Swift\n\nAllow the setting of read/write_affinity and write_affinity_node_count\non a per proxy_host basis.\n\nThis allows the deployer to set preferences for which region to\nread/write to, which can increase the efficiency of a multi-region\nswift cluster.\n\nSample swift.yml has been updated, as well as the aio swift.yml to\nensure these settings are setup as part of the gate, but this shouldn't\nchange the functionality of swift at all (since there is only 1 region).\n\nChange-Id: I95b456672f419fcc331d6739ce259b022d350472\nCloses-Bug: #1415172\n""}]",0,191023,5b9b49f52b12052f93c72f44a31a972f2e98620c,38,4,10,2799,,,0,"Add read/write_affinity settings for Swift

Allow the setting of read/write_affinity and write_affinity_node_count
on a per proxy_host basis.

This allows the deployer to set preferences for which region to
read/write to, which can increase the efficiency of a multi-region
swift cluster.

Sample swift.yml has been updated, as well as the aio swift.yml to
ensure these settings are setup as part of the gate, but this shouldn't
change the functionality of swift at all (since there is only 1 region).

Change-Id: I95b456672f419fcc331d6739ce259b022d350472
Closes-Bug: #1415172
",git fetch https://review.opendev.org/openstack/openstack-ansible refs/changes/23/191023/9 && git format-patch -1 --stdout FETCH_HEAD,"['etc/openstack_deploy/conf.d/swift.yml.example', 'playbooks/roles/os_swift/templates/proxy-server.conf.j2', 'etc/openstack_deploy/conf.d/swift.yml.aio']",3,bacb8734744a88acf8f1361ecb88ed720b60cbf2,bug/1415172," container_vars: swift_proxy_vars: read_affinity: ""r1=100"" write_affinity: ""r1"" write_affinity_node_count: ""replicas * 1"" container_vars: swift_vars: zone: 0 region: 1",,63,0
openstack%2Fnetworking-ovn~master~Ie9669381f0a1d5a695d998ab8453eb2427d39926,openstack/networking-ovn,master,Ie9669381f0a1d5a695d998ab8453eb2427d39926,Control list of enabled services for tempest job.,MERGED,2015-06-23 14:39:44.000000000,2015-06-24 17:52:03.000000000,2015-06-24 17:52:02.000000000,"[{'_account_id': 3}, {'_account_id': 4395}, {'_account_id': 11343}]","[{'number': 1, 'created': '2015-06-23 14:39:44.000000000', 'files': ['devstack/devstackgaterc'], 'web_link': 'https://opendev.org/openstack/networking-ovn/commit/0543de34554b0379057e93fb45f102e657ddc16e', 'message': 'Control list of enabled services for tempest job.\n\nThis patch moves the list of enabled services into the local job\nconfig so that we can more easily update it.  This list is the same as\nwhat was in project-config with ""n-obj"" added.  One of the test\nfailures was\ntempest.thirdparty.boto.test_ec2_instance_run.InstanceRunTest failing\nwhen trying to create an S3 bucket, so I think turning this service\non will resolve that.\n\nChange-Id: Ie9669381f0a1d5a695d998ab8453eb2427d39926\nSigned-off-by: Russell Bryant <rbryant@redhat.com>\n'}]",0,194680,0543de34554b0379057e93fb45f102e657ddc16e,7,3,1,1561,,,0,"Control list of enabled services for tempest job.

This patch moves the list of enabled services into the local job
config so that we can more easily update it.  This list is the same as
what was in project-config with ""n-obj"" added.  One of the test
failures was
tempest.thirdparty.boto.test_ec2_instance_run.InstanceRunTest failing
when trying to create an S3 bucket, so I think turning this service
on will resolve that.

Change-Id: Ie9669381f0a1d5a695d998ab8453eb2427d39926
Signed-off-by: Russell Bryant <rbryant@redhat.com>
",git fetch https://review.opendev.org/openstack/networking-ovn refs/changes/80/194680/1 && git format-patch -1 --stdout FETCH_HEAD,['devstack/devstackgaterc'],1,0543de34554b0379057e93fb45f102e657ddc16e,193330,"# You can find the CI job configuration here:export OVERRIDE_ENABLED_SERVICES=key,n-api,n-cpu,n-cond,n-sch,n-crt,n-cauth,n-obj,g-api,g-reg,c-sch,c-api,c-vol,horizon,rabbit,tempest,mysql,dstat,ovn-northd,ovn-controller,q-svc,q-dhcp,q-l3 ",# It's used to configure which tempest tests actually get run. You can find # the CI job configuration here:,3,2
openstack%2Fopenstack-ansible~master~I4854216726491f6ea4e265694e702f980fddc5a6,openstack/openstack-ansible,master,I4854216726491f6ea4e265694e702f980fddc5a6,Add global endpoint_type_proto options,MERGED,2015-06-19 14:31:24.000000000,2015-06-24 17:51:25.000000000,2015-06-22 15:02:08.000000000,"[{'_account_id': 3}, {'_account_id': 2799}, {'_account_id': 6816}, {'_account_id': 7353}, {'_account_id': 12000}]","[{'number': 1, 'created': '2015-06-19 14:31:24.000000000', 'files': ['playbooks/roles/os_swift/defaults/main.yml', 'playbooks/roles/os_neutron/defaults/main.yml', 'playbooks/roles/os_cinder/defaults/main.yml', 'playbooks/roles/os_heat/defaults/main.yml', 'playbooks/roles/os_glance/defaults/main.yml', 'etc/openstack_deploy/user_group_vars.yml', 'playbooks/roles/os_glance/templates/glance-api.conf.j2', 'playbooks/roles/os_nova/defaults/main.yml', 'playbooks/roles/os_keystone/defaults/main.yml'], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/2b6b896105c7d4cd3b615432da3c084fcc2bf29b', 'message': 'Add global endpoint_type_proto options\n\nThis allows you to set the endpoint-type protocol globally for all\nservices, e.g. internaluri can be http, and publicuri can be https.\n\nYou will no longer have to specify it per service, although those\nsettings already exist and have not changed.\n\nThis patch changes no functionality for existing installs or deployments\nand the values are defaulted to be the same as before, but allows these\nvalues to be adjusted on a per-endpoint type basis.\n\nChange-Id: I4854216726491f6ea4e265694e702f980fddc5a6\nCloses-Bug: #1399383\n'}]",7,193573,2b6b896105c7d4cd3b615432da3c084fcc2bf29b,12,5,1,2799,,,0,"Add global endpoint_type_proto options

This allows you to set the endpoint-type protocol globally for all
services, e.g. internaluri can be http, and publicuri can be https.

You will no longer have to specify it per service, although those
settings already exist and have not changed.

This patch changes no functionality for existing installs or deployments
and the values are defaulted to be the same as before, but allows these
values to be adjusted on a per-endpoint type basis.

Change-Id: I4854216726491f6ea4e265694e702f980fddc5a6
Closes-Bug: #1399383
",git fetch https://review.opendev.org/openstack/openstack-ansible refs/changes/73/193573/1 && git format-patch -1 --stdout FETCH_HEAD,"['playbooks/roles/os_swift/defaults/main.yml', 'playbooks/roles/os_neutron/defaults/main.yml', 'playbooks/roles/os_cinder/defaults/main.yml', 'playbooks/roles/os_heat/defaults/main.yml', 'etc/openstack_deploy/user_group_vars.yml', 'playbooks/roles/os_glance/defaults/main.yml', 'playbooks/roles/os_glance/templates/glance-api.conf.j2', 'playbooks/roles/os_nova/defaults/main.yml', 'playbooks/roles/os_keystone/defaults/main.yml']",9,2b6b896105c7d4cd3b615432da3c084fcc2bf29b,bug/1399383,"keystone_service_publicuri_proto: ""{{ openstack_service_publicuri_proto | default(keystone_service_proto) }}"" keystone_service_adminuri_proto: ""{{ openstack_service_adminuri_proto | default(keystone_service_proto) }}"" keystone_service_internaluri_proto: ""{{ openstack_service_internaluri_proto | default(keystone_service_proto) }}""","keystone_service_publicuri_proto: ""{{ keystone_service_proto }}"" keystone_service_adminuri_proto: ""{{ keystone_service_proto }}"" keystone_service_internaluri_proto: ""{{ keystone_service_proto }}""",56,47
openstack%2Foslo.versionedobjects~master~I8bb0f9d8f162058027e4b80fa2373dfb3cbd7624,openstack/oslo.versionedobjects,master,I8bb0f9d8f162058027e4b80fa2373dfb3cbd7624,Updated from global requirements,MERGED,2015-06-24 14:45:47.000000000,2015-06-24 17:50:02.000000000,2015-06-24 17:50:01.000000000,"[{'_account_id': 3}, {'_account_id': 5638}]","[{'number': 1, 'created': '2015-06-24 14:45:47.000000000', 'files': ['requirements.txt', 'requirements-py3.txt'], 'web_link': 'https://opendev.org/openstack/oslo.versionedobjects/commit/0907e25d8ebf3ad18201863f60cfeb07df438937', 'message': 'Updated from global requirements\n\nChange-Id: I8bb0f9d8f162058027e4b80fa2373dfb3cbd7624\n'}]",0,195120,0907e25d8ebf3ad18201863f60cfeb07df438937,6,2,1,11131,,,0,"Updated from global requirements

Change-Id: I8bb0f9d8f162058027e4b80fa2373dfb3cbd7624
",git fetch https://review.opendev.org/openstack/oslo.versionedobjects refs/changes/20/195120/1 && git format-patch -1 --stdout FETCH_HEAD,"['requirements.txt', 'requirements-py3.txt']",2,0907e25d8ebf3ad18201863f60cfeb07df438937,openstack/requirements,oslo.concurrency>=2.1.0 # Apache-2.0,oslo.concurrency>=2.0.0 # Apache-2.0,2,2
openstack%2Fproject-config~master~I5dcbab958f7dd2fe4c675e48620919d9b84e69ca,openstack/project-config,master,I5dcbab958f7dd2fe4c675e48620919d9b84e69ca,Do not run requirements check on keystonemiddleware kilo branch,ABANDONED,2015-06-23 22:42:16.000000000,2015-06-24 17:46:32.000000000,,"[{'_account_id': 3}, {'_account_id': 2472}, {'_account_id': 4190}, {'_account_id': 6316}]","[{'number': 1, 'created': '2015-06-23 22:42:16.000000000', 'files': ['zuul/layout.yaml'], 'web_link': 'https://opendev.org/openstack/project-config/commit/489effd6bd7c47aa538d0714ea71d60b7208d020', 'message': 'Do not run requirements check on keystonemiddleware kilo branch\n\nDue to a mismatch in requirements that prevents us from increasing the\nminimums, keystonemiddleware for kilo cannot have the requirements check\nrun against it or it fails. See: https://review.openstack.org/#/c/173972/\nfor more info.\n\nChange-Id: I5dcbab958f7dd2fe4c675e48620919d9b84e69ca\nrelated-bug: #1463988\n'}]",0,194849,489effd6bd7c47aa538d0714ea71d60b7208d020,6,4,1,2903,,,0,"Do not run requirements check on keystonemiddleware kilo branch

Due to a mismatch in requirements that prevents us from increasing the
minimums, keystonemiddleware for kilo cannot have the requirements check
run against it or it fails. See: https://review.openstack.org/#/c/173972/
for more info.

Change-Id: I5dcbab958f7dd2fe4c675e48620919d9b84e69ca
related-bug: #1463988
",git fetch https://review.opendev.org/openstack/project-config refs/changes/49/194849/1 && git format-patch -1 --stdout FETCH_HEAD,['zuul/layout.yaml'],1,489effd6bd7c47aa538d0714ea71d60b7208d020,bug/1463988, - name: gate-keystonemiddleware-requirements branch: ^(!?stable/kilo).*$ ,,3,0
openstack%2Ftrove-specs~master~I56fe640a7f81f9a7a6906580e6484ddfbf84e677,openstack/trove-specs,master,I56fe640a7f81f9a7a6906580e6484ddfbf84e677,MySQL manager refactor,MERGED,2015-03-26 17:17:40.000000000,2015-06-24 17:26:27.000000000,2015-06-24 17:26:25.000000000,"[{'_account_id': 3}, {'_account_id': 4240}, {'_account_id': 6413}, {'_account_id': 7806}, {'_account_id': 9664}, {'_account_id': 9782}, {'_account_id': 10215}, {'_account_id': 10295}, {'_account_id': 10440}, {'_account_id': 14912}, {'_account_id': 14966}, {'_account_id': 15321}]","[{'number': 1, 'created': '2015-03-26 17:17:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/trove-specs/commit/4020067230f445b5885eabdc1abf51e2ed84888e', 'message': 'MySQL manager refactor blueprint\n\nThere are a number of forks of MySQL that differ to varying degrees.\nThis blueprint proposes the creation of a class structure for\nMySQL-derived datastores to avoid duplication of code dealing with\nfeatures and capabilities shared in common.\n\nIt is expected that the lessons learned from this effort will be\napplicable to future efforts to provide differentiation for systems\nsuch as MongoDB and PostgreSQL.\n\nChange-Id: I56fe640a7f81f9a7a6906580e6484ddfbf84e677\nImplements: blueprint mysql-manager-refactor\n'}, {'number': 2, 'created': '2015-04-13 20:38:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/trove-specs/commit/089d29143461638a96e8c83b1a1e795f70ce5c86', 'message': 'MySQL manager refactor blueprint\n\nThere are a number of forks of MySQL that differ to varying degrees.\nThis blueprint proposes the creation of a class structure for\nMySQL-derived datastores to avoid duplication of code dealing with\nfeatures and capabilities shared in common.\n\nIt is expected that the lessons learned from this effort will be\napplicable to future efforts to provide differentiation for systems\nsuch as MongoDB and PostgreSQL.\n\nChange-Id: I56fe640a7f81f9a7a6906580e6484ddfbf84e677\nImplements: blueprint mysql-manager-refactor\n'}, {'number': 3, 'created': '2015-04-23 18:34:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/trove-specs/commit/3a361b04ffa07890f3b2da1fe3fe267b5600f437', 'message': 'MySQL manager refactor blueprint\n\nThere are a number of forks of MySQL that differ to varying degrees.\nThis blueprint proposes the creation of a class structure for\nMySQL-derived datastores to avoid duplication of code dealing with\nfeatures and capabilities shared in common.\n\nIt is expected that the lessons learned from this effort will be\napplicable to future efforts to provide differentiation for systems\nsuch as MongoDB and PostgreSQL.\n\nChange-Id: I56fe640a7f81f9a7a6906580e6484ddfbf84e677\nImplements: blueprint mysql-manager-refactor\n'}, {'number': 4, 'created': '2015-06-15 21:21:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/trove-specs/commit/11546788d01fd8b850588457932cbb89c6db7a7a', 'message': 'MySQL manager refactor blueprint\n\nThere are a number of forks of MySQL that differ to varying degrees.\nThis blueprint proposes the creation of a class structure for\nMySQL-derived datastores to avoid duplication of code dealing with\nfeatures and capabilities shared in common.\n\nIt is expected that the lessons learned from this effort will be\napplicable to future efforts to provide differentiation for systems\nsuch as MongoDB and PostgreSQL.\n\nChange-Id: I56fe640a7f81f9a7a6906580e6484ddfbf84e677\nImplements: blueprint mysql-manager-refactor\n'}, {'number': 5, 'created': '2015-06-17 20:36:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/trove-specs/commit/3e1cfca41280c077132b9a21d986b32e7b7c9170', 'message': 'MySQL manager refactor blueprint\n\nThere are a number of forks of MySQL that differ to varying degrees.\nThis blueprint proposes the creation of a class structure for\nMySQL-derived datastores to avoid duplication of code dealing with\nfeatures and capabilities shared in common.\n\nIt is expected that the lessons learned from this effort will be\napplicable to future efforts to provide differentiation for systems\nsuch as MongoDB and PostgreSQL.\n\nChange-Id: I56fe640a7f81f9a7a6906580e6484ddfbf84e677\nImplements: blueprint mysql-manager-refactor\n'}, {'number': 6, 'created': '2015-06-17 20:59:44.000000000', 'files': ['specs/liberty/mysql-manager-refactor.rst'], 'web_link': 'https://opendev.org/openstack/trove-specs/commit/b539a0742e894c3e8575ba7c30a9d45ba6b32aab', 'message': 'MySQL manager refactor\n\nThere are a number of forks of MySQL that differ to varying degrees.\nWe propose to create a class structure for MySQL-derived\ndatastores to avoid duplication of code dealing with features\nand capabilities shared in common.\n\nIt is expected that the lessons learned from this effort will be\napplicable to future efforts to provide differentiation for systems\nsuch as MongoDB and PostgreSQL.\n\nChange-Id: I56fe640a7f81f9a7a6906580e6484ddfbf84e677\nImplements: blueprint mysql-manager-refactor\n'}]",23,168083,b539a0742e894c3e8575ba7c30a9d45ba6b32aab,48,12,6,10440,,,0,"MySQL manager refactor

There are a number of forks of MySQL that differ to varying degrees.
We propose to create a class structure for MySQL-derived
datastores to avoid duplication of code dealing with features
and capabilities shared in common.

It is expected that the lessons learned from this effort will be
applicable to future efforts to provide differentiation for systems
such as MongoDB and PostgreSQL.

Change-Id: I56fe640a7f81f9a7a6906580e6484ddfbf84e677
Implements: blueprint mysql-manager-refactor
",git fetch https://review.opendev.org/openstack/trove-specs refs/changes/83/168083/6 && git format-patch -1 --stdout FETCH_HEAD,"['specs/liberty/mysql-manager-refactor.rst', 'doc/source/index.rst']",2,4020067230f445b5885eabdc1abf51e2ed84888e,bp/mysql-manager-refactor,Liberty approved specs: .. toctree:: :glob: :maxdepth: 1 specs/liberty/* ,,218,0
openstack%2Fsecurity-doc~master~I165d5cc6bf29a3eafdaedf4d9434af70d609f6a3,openstack/security-doc,master,I165d5cc6bf29a3eafdaedf4d9434af70d609f6a3,Identity Management Case studies merged in identity-section.,ABANDONED,2015-06-21 09:28:57.000000000,2015-06-24 17:25:10.000000000,,"[{'_account_id': 3}, {'_account_id': 964}, {'_account_id': 10670}, {'_account_id': 12325}, {'_account_id': 14867}]","[{'number': 1, 'created': '2015-06-21 09:28:57.000000000', 'files': ['security-guide/ch_identity.xml', 'security-guide/section_case-studies-identity-management.xml', 'security-guide/bk-openstack-security-guide.xml'], 'web_link': 'https://opendev.org/openstack/security-doc/commit/a3bd184055444e8055faa1d67ae8c9ba7844deef', 'message': 'Identity Management Case studies merged in identity-section.\n\nSub chapter was marked as a new chapter.\n\nChange-Id: I165d5cc6bf29a3eafdaedf4d9434af70d609f6a3\nCloses-Bug: #1465037\n'}]",0,193864,a3bd184055444e8055faa1d67ae8c9ba7844deef,8,5,1,14867,,,0,"Identity Management Case studies merged in identity-section.

Sub chapter was marked as a new chapter.

Change-Id: I165d5cc6bf29a3eafdaedf4d9434af70d609f6a3
Closes-Bug: #1465037
",git fetch https://review.opendev.org/openstack/security-doc refs/changes/64/193864/1 && git format-patch -1 --stdout FETCH_HEAD,"['security-guide/ch_identity.xml', 'security-guide/section_case-studies-identity-management.xml', 'security-guide/bk-openstack-security-guide.xml']",3,a3bd184055444e8055faa1d67ae8c9ba7844deef,bug/1465037,," <xi:include href=""ch_case-studies-identity-management.xml""/>",4,4
openstack%2Fcue~master~Ib70fd37a0349c5cf89f73a2ca2334400b87bff56,openstack/cue,master,Ib70fd37a0349c5cf89f73a2ca2334400b87bff56,Fix revert on ERROR/Exception,MERGED,2015-06-10 09:22:59.000000000,2015-06-24 17:18:51.000000000,2015-06-24 17:18:49.000000000,"[{'_account_id': 3}, {'_account_id': 1925}, {'_account_id': 10584}]","[{'number': 1, 'created': '2015-06-10 09:22:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cue/commit/6c172261c01896eac0956a8112d2348d1417ab8f', 'message': ""Fix revert on ERROR/Exception\n\nFailure on a sub flow that is being Retry'd is not forcing the\nsurrounding flow to also REVERT.  This is because the Retry controller\nis returning REVERT rather than REVERT_ALL.\n\nChange-Id: Ib70fd37a0349c5cf89f73a2ca2334400b87bff56\nCloses-Bug: 1452958\n""}, {'number': 2, 'created': '2015-06-16 18:27:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cue/commit/21fec652e7f50b8ab0ed04a5e6152e9e74b34ace', 'message': ""Fix revert on ERROR/Exception\n\nFailure on a sub flow that is being Retry'd is not forcing the\nsurrounding flow to also REVERT.  This is because the Retry controller\nis returning REVERT rather than REVERT_ALL.\n\nChange-Id: Ib70fd37a0349c5cf89f73a2ca2334400b87bff56\nCloses-Bug: 1452958\n""}, {'number': 3, 'created': '2015-06-16 18:30:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cue/commit/0c7579a296442df5ec368be04de16c3ad2ac7ef7', 'message': ""Fix revert on ERROR/Exception\n\nFailure on a sub flow that is being Retry'd is not forcing the\nsurrounding flow to also REVERT.  This is because the Retry controller\nis returning REVERT rather than REVERT_ALL.\n\nChange-Id: Ib70fd37a0349c5cf89f73a2ca2334400b87bff56\nCloses-Bug: 1452958\n""}, {'number': 4, 'created': '2015-06-24 06:36:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cue/commit/afd8e2fa2665f15d699c535f17da4a2a8a1d81f8', 'message': ""Fix revert on ERROR/Exception\n\nFailure on a sub flow that is being Retry'd is not forcing the\nsurrounding flow to also REVERT.  This is because the Retry controller\nis returning REVERT rather than REVERT_ALL.\n\nChange-Id: Ib70fd37a0349c5cf89f73a2ca2334400b87bff56\nCloses-Bug: 1452958\n""}, {'number': 5, 'created': '2015-06-24 13:29:41.000000000', 'files': ['requirements.txt', 'cue/taskflow/flow/create_cluster_node.py'], 'web_link': 'https://opendev.org/openstack/cue/commit/c88eebaafa8ffb6bbc010f2e586bdb40f543dde4', 'message': ""Fix revert on ERROR/Exception\n\nFailure on a sub flow that is being Retry'd is not forcing the\nsurrounding flow to also REVERT.  This is because the Retry controller\nis returning REVERT rather than REVERT_ALL.\n\nChange-Id: Ib70fd37a0349c5cf89f73a2ca2334400b87bff56\nCloses-Bug: 1452958\n""}]",0,190081,c88eebaafa8ffb6bbc010f2e586bdb40f543dde4,25,3,5,10584,,,0,"Fix revert on ERROR/Exception

Failure on a sub flow that is being Retry'd is not forcing the
surrounding flow to also REVERT.  This is because the Retry controller
is returning REVERT rather than REVERT_ALL.

Change-Id: Ib70fd37a0349c5cf89f73a2ca2334400b87bff56
Closes-Bug: 1452958
",git fetch https://review.opendev.org/openstack/cue refs/changes/81/190081/5 && git format-patch -1 --stdout FETCH_HEAD,['cue/taskflow/flow/create_cluster_node.py'],1,6c172261c01896eac0956a8112d2348d1417ab8f,bug/1452958," retry=retry.Times(12, revert_all=True)) retry=retry.Times(node_check_max_count, revert_all=True))", retry=retry.Times(12)) retry=retry.Times(node_check_max_count)),2,2
openstack%2Foslo.concurrency~master~I37e3170b58627dee93513ec222f9a55001389dad,openstack/oslo.concurrency,master,I37e3170b58627dee93513ec222f9a55001389dad,Ensure we 'join' on the timer watchdog thread,MERGED,2015-06-20 00:29:37.000000000,2015-06-24 17:17:22.000000000,2015-06-24 17:17:20.000000000,"[{'_account_id': 3}, {'_account_id': 708}, {'_account_id': 1297}, {'_account_id': 5638}]","[{'number': 1, 'created': '2015-06-20 00:29:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.concurrency/commit/9f97f9103b8d3d28fbd10d53c9ca032104269ecb', 'message': ""Ensure we 'join' on the timer watchdog thread\n\nThis object is just another thread and its cancel method\ndoes not join on itself, so we should make sure that we do\nto avoid leaving threads lying around.\n\nChange-Id: I37e3170b58627dee93513ec222f9a55001389dad\n""}, {'number': 2, 'created': '2015-06-21 16:55:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.concurrency/commit/1ec58b9526ad980ddfc7d51b1dea650e113256fb', 'message': ""Ensure we 'join' on the timer watchdog thread\n\nThis object is just another thread and its cancel method\ndoes not join on itself, so we should make sure that we do\nto avoid leaving threads lying around.\n\nChange-Id: I37e3170b58627dee93513ec222f9a55001389dad\n""}, {'number': 3, 'created': '2015-06-22 17:35:14.000000000', 'files': ['oslo_concurrency/watchdog.py'], 'web_link': 'https://opendev.org/openstack/oslo.concurrency/commit/68a82f29f1f74bac99ebc9d9264fcf39801ef453', 'message': ""Ensure we 'join' on the timer watchdog thread\n\nThis object is just another thread and its cancel method\ndoes not join on itself, so we should make sure that we do\nto avoid leaving threads lying around.\n\nChange-Id: I37e3170b58627dee93513ec222f9a55001389dad\n""}]",0,193763,68a82f29f1f74bac99ebc9d9264fcf39801ef453,17,4,3,1297,,,0,"Ensure we 'join' on the timer watchdog thread

This object is just another thread and its cancel method
does not join on itself, so we should make sure that we do
to avoid leaving threads lying around.

Change-Id: I37e3170b58627dee93513ec222f9a55001389dad
",git fetch https://review.opendev.org/openstack/oslo.concurrency refs/changes/63/193763/1 && git format-patch -1 --stdout FETCH_HEAD,['oslo_concurrency/watchdog.py'],1,9f97f9103b8d3d28fbd10d53c9ca032104269ecb,, timer.join(),,1,0
openstack%2Foslo.middleware~master~Id86fa35bc81d9d24211d8553ac2ef9e91949ba7a,openstack/oslo.middleware,master,Id86fa35bc81d9d24211d8553ac2ef9e91949ba7a,Drop use of 'oslo' namespace package,MERGED,2015-06-24 15:32:26.000000000,2015-06-24 17:14:47.000000000,2015-06-24 17:14:45.000000000,"[{'_account_id': 3}, {'_account_id': 5638}, {'_account_id': 9107}]","[{'number': 1, 'created': '2015-06-24 15:32:26.000000000', 'files': ['oslo_middleware/ssl.py'], 'web_link': 'https://opendev.org/openstack/oslo.middleware/commit/159121e468ffa9789a97cd15f6f097217771566d', 'message': ""Drop use of 'oslo' namespace package\n\nThe Oslo libraries have moved all of their code out of the 'oslo'\nnamespace package into per-library packages. The namespace package was\nretained during kilo for backwards compatibility, but will be removed by\nthe liberty-2 milestone. This change removes the use of the namespace\npackage, replacing it with the new package names.\n\nThe patches in the libraries will be put on hold until application\npatches have landed, or L2, whichever comes first. At that point, new\nversions of the libraries without namespace packages will be released as\na major version update.\n\nPlease merge this patch, or an equivalent, before L2 to avoid problems\nwith those library releases.\n\nBlueprint: remove-namespace-packages\nhttps://blueprints.launchpad.net/oslo-incubator/+spec/remove-namespace-packages\n\nChange-Id: Id86fa35bc81d9d24211d8553ac2ef9e91949ba7a\n""}]",0,195148,159121e468ffa9789a97cd15f6f097217771566d,8,3,1,2472,,,0,"Drop use of 'oslo' namespace package

The Oslo libraries have moved all of their code out of the 'oslo'
namespace package into per-library packages. The namespace package was
retained during kilo for backwards compatibility, but will be removed by
the liberty-2 milestone. This change removes the use of the namespace
package, replacing it with the new package names.

The patches in the libraries will be put on hold until application
patches have landed, or L2, whichever comes first. At that point, new
versions of the libraries without namespace packages will be released as
a major version update.

Please merge this patch, or an equivalent, before L2 to avoid problems
with those library releases.

Blueprint: remove-namespace-packages
https://blueprints.launchpad.net/oslo-incubator/+spec/remove-namespace-packages

Change-Id: Id86fa35bc81d9d24211d8553ac2ef9e91949ba7a
",git fetch https://review.opendev.org/openstack/oslo.middleware refs/changes/48/195148/1 && git format-patch -1 --stdout FETCH_HEAD,['oslo_middleware/ssl.py'],1,159121e468ffa9789a97cd15f6f097217771566d,bp/remove-namespace-packages,from oslo_config import cfg,from oslo.config import cfg,1,1
openstack%2Fproject-config~master~Id6ebf86308536046135ad25070faee5143ad545a,openstack/project-config,master,Id6ebf86308536046135ad25070faee5143ad545a,Oslo to adopt sdague's zmq plugin,MERGED,2015-06-24 15:02:51.000000000,2015-06-24 17:12:56.000000000,2015-06-24 17:12:52.000000000,"[{'_account_id': 3}, {'_account_id': 2750}, {'_account_id': 5638}, {'_account_id': 6159}, {'_account_id': 6547}, {'_account_id': 8770}, {'_account_id': 13290}]","[{'number': 1, 'created': '2015-06-24 15:02:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/project-config/commit/c827da5705838da4fce5439d264c29a0427b4a4a', 'message': ""Oslo to adopt sdague's zmq plugin\n\nChange-Id: Id6ebf86308536046135ad25070faee5143ad545a\n""}, {'number': 2, 'created': '2015-06-24 15:54:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/project-config/commit/274f3568a38cf7630c48dad1a3a4f0243a9ef35e', 'message': ""Oslo to adopt sdague's zmq plugin\n\nChange-Id: Id6ebf86308536046135ad25070faee5143ad545a\n""}, {'number': 3, 'created': '2015-06-24 16:06:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/project-config/commit/66b7cf8c0513536e0715be64c9df509a893842a9', 'message': ""Oslo to adopt sdague's zmq plugin\n\nChange-Id: Id6ebf86308536046135ad25070faee5143ad545a\n""}, {'number': 4, 'created': '2015-06-24 16:14:26.000000000', 'files': ['gerritbot/channels.yaml', 'jenkins/jobs/projects.yaml', 'gerrit/projects.yaml', 'zuul/layout.yaml'], 'web_link': 'https://opendev.org/openstack/project-config/commit/0b7bfc1d77ba03e454fe8107f3fd4c122ac5cb51', 'message': ""Oslo to adopt sdague's zmq plugin\n\nChange-Id: Id6ebf86308536046135ad25070faee5143ad545a\n""}]",3,195134,0b7bfc1d77ba03e454fe8107f3fd4c122ac5cb51,18,7,4,5638,,,0,"Oslo to adopt sdague's zmq plugin

Change-Id: Id6ebf86308536046135ad25070faee5143ad545a
",git fetch https://review.opendev.org/openstack/project-config refs/changes/34/195134/4 && git format-patch -1 --stdout FETCH_HEAD,"['gerritbot/channels.yaml', 'gerrit/acls/openstack/devstack-plugin-zmq.config', 'jenkins/jobs/projects.yaml', 'gerrit/projects.yaml', 'zuul/layout.yaml']",5,c827da5705838da4fce5439d264c29a0427b4a4a,, - name: openstack/devstack-plugin-zmq template: - name: merge-check check: - gate-devstack-plugin-zmq-bashate gate: - gate-devstack-plugin-zmq-bashate ,,40,0
openstack%2Fhorizon~master~Iea74e4f3763f83a6fa3043a3824b523003686dc3,openstack/horizon,master,Iea74e4f3763f83a6fa3043a3824b523003686dc3,Updated from global requirements,MERGED,2015-06-24 14:39:21.000000000,2015-06-24 17:11:35.000000000,2015-06-24 17:11:35.000000000,"[{'_account_id': 3}, {'_account_id': 6914}, {'_account_id': 9576}]","[{'number': 1, 'created': '2015-06-24 14:39:21.000000000', 'files': ['requirements.txt'], 'web_link': 'https://opendev.org/openstack/horizon/commit/536b6d6d6716dcc8f98d2fc51ada890cfe6ad0f0', 'message': 'Updated from global requirements\n\nChange-Id: Iea74e4f3763f83a6fa3043a3824b523003686dc3\n'}]",0,195110,536b6d6d6716dcc8f98d2fc51ada890cfe6ad0f0,7,3,1,11131,,,0,"Updated from global requirements

Change-Id: Iea74e4f3763f83a6fa3043a3824b523003686dc3
",git fetch https://review.opendev.org/openstack/horizon refs/changes/10/195110/1 && git format-patch -1 --stdout FETCH_HEAD,['requirements.txt'],1,536b6d6d6716dcc8f98d2fc51ada890cfe6ad0f0,openstack/requirements,oslo.concurrency>=2.1.0 # Apache-2.0,oslo.concurrency>=2.0.0 # Apache-2.0,1,1
openstack%2Fopenstackdocstheme~master~I2d52750600703432e82ab41c3bac9a3764743fd4,openstack/openstackdocstheme,master,I2d52750600703432e82ab41c3bac9a3764743fd4,Cleanup css/styles.css,MERGED,2015-06-02 18:17:20.000000000,2015-06-24 17:11:27.000000000,2015-06-24 17:11:27.000000000,"[{'_account_id': 3}, {'_account_id': 167}, {'_account_id': 964}, {'_account_id': 6547}, {'_account_id': 7923}]","[{'number': 1, 'created': '2015-06-02 18:17:20.000000000', 'files': ['openstackdocstheme/theme/openstackdocs/static/css/styles.css'], 'web_link': 'https://opendev.org/openstack/openstackdocstheme/commit/48627df7b566ce96b0e662c59fc6121b925c52be', 'message': 'Cleanup css/styles.css\n\nRemove extra whitespace, convert to normal line endings.\n\nChange-Id: I2d52750600703432e82ab41c3bac9a3764743fd4\n'}]",0,187712,48627df7b566ce96b0e662c59fc6121b925c52be,8,5,1,6547,,,0,"Cleanup css/styles.css

Remove extra whitespace, convert to normal line endings.

Change-Id: I2d52750600703432e82ab41c3bac9a3764743fd4
",git fetch https://review.opendev.org/openstack/openstackdocstheme refs/changes/12/187712/1 && git format-patch -1 --stdout FETCH_HEAD,['openstackdocstheme/theme/openstackdocs/static/css/styles.css'],1,48627df7b566ce96b0e662c59fc6121b925c52be,rm-dos-endings,"/*! * Start Bootstrap - Landing Page Bootstrap Theme (http://startbootstrap.com) * Code licensed under the Apache License v2.0. * For details, see http://www.apache.org/licenses/LICENSE-2.0. */ body, html { width: 100%; height: 100%; } body, h1, h2, h3, h4, h5, h6 { font-family: ""Open Sans"", Helvetica, Arial, sans-serif; font-weight: 400; } h2 { color: #284d68; font-size: 34; font-weight: 300; margin-bottom: 25px; } h5 { color: #da3d27; margin-bottom: 0; } dd { margin-left: 20px } .lead { font-size: 18px; font-weight: 400; } /*Header Navigation*/ .brand-wrapper { margin: 10px 0; padding-right: 20px; float: left; border-right: 1px solid #eee; min-width: 135px; } @media (max-width: 767px) { .brand-wrapper { border-right: none; } } a.navbar-brand { background: url('../images/openstack-logo-full.png') left no-repeat; height: 35px; width: 135px; } @media (min-width: 768px) and (max-width: 1025px) { .brand-wrapper { width: 75px; min-width: 75px; margin-top: 0; } a.navbar-brand { background: url('../images/openstack-logo-vert.png') left no-repeat; margin-left: 0px !important; height: 54px; width: 59px; } } @media (max-width: 767px) { a.navbar-brand { margin-left: 15px; } } .navbar-default { border: none; border-radius: 0px; background: #fff; margin-bottom: 0; padding: 20px 0; } .navbar-default .container { background-color: white; } @media (min-width: 768px) and (max-width: 1200px) { .navbar-default .container { width: 100%; } } ul.navbar-main { display: none; float: right; } @media (min-width: 768px) and (max-width: 1097px) { ul.navbar-main { display: block; } } @media (max-width:767px) { ul.navbar-main { display: block; margin-right: 30px; width: 90%; } } .navbar-default ul.navbar-main>li>a { color: #8a959e; font-size: 12px; font-weight: 400; text-transform: uppercase; } @media (min-width: 768px) and (max-width: 1025px) { ul.navbar-main { margin-top: 1px; } .navbar-default ul.navbar-main>li>a { font-size: 11px; padding: 15px 8px; } } .navbar-default ul.navbar-main>li>a.sign-in-btn { background: #2e729a; padding: 7px 25px; border-radius: 2px; color: #fff; margin-top: 7px; } .navbar-default ul.navbar-main>li>a.sign-in-btn:hover { background: #286A9D; color: #fff; } @media (max-width: 1025px) { .navbar-default ul.navbar-main>li>a.sign-in-btn { padding: 5px 10px; margin-top: 9px; } } @media (max-width: 767px) { .navbar-default ul.navbar-main>li>a.sign-in-btn { margin: 0; padding: 10px 15px; background: transparent; border: none; color: #2e729a; font-size: 12px; font-weight: 700; text-transform: uppercase; } .navbar-default ul.navbar-main>li>a.sign-in-btn:hover { background: #fff; color: #286A9D; } } .navbar-default .navbar-nav>.open>a, .navbar-default .navbar-nav>.open>a:hover, .navbar-default .navbar-nav>.open>a:focus { background: #fff; } .navbar-nav>li>.dropdown-menu { margin-top: 10px; padding: 10px 0; min-width: 230px; border-top-left-radius: 4px; border-top-right-radius: 4px; } .navbar-nav>li>.dropdown-menu:after, .navbar-nav>li>.dropdown-menu:before { bottom: 100%; left: 25%; border: solid transparent; content: "" ""; height: 0; width: 0; position: absolute; pointer-events: none; } .navbar-nav>li>.dropdown-menu:after { border-color: rgba(255, 255, 255, 0); border-bottom-color: #ffffff; border-width: 15px; margin-left: -15px; } .navbar-nav>li>.dropdown-menu:before { border-color: rgba(170, 170, 170, 0); border-bottom-color: #aaaaaa; border-width: 16px; margin-left: -16px; } @media (max-width: 767px) { .navbar-nav>li>.dropdown-menu:after, .navbar-nav>li>.dropdown-menu:before { display: none; } .navbar-nav>li>.dropdown-menu:after { display: none; } .navbar-nav>li>.dropdown-menu:before { display: none; } } i.fa-caret-right { margin-left: 8px; } .navbar-nav>li>.dropdown-menu li a{ text-transform: uppercase; padding: 13px 20px; font-size: 12px; color: #8a959e; } .navbar-nav>li>.dropdown-menu li a:hover { color: #333; } .navbar-nav>li>.dropdown-menu li a:focus { outline: none; } @media (max-width: 767px) { .navbar-default ul.navbar-main>li>a i.fa-caret-down { display: none; } } .navbar-default .navbar-toggle { border: none; } .navbar-default .navbar-toggle:hover, .navbar-default .navbar-toggle:focus { background: transparent; } .navbar-default .navbar-toggle .icon-bar { background-color: #5A5A5A; height: 3px; border-radius: 3px; } .search-container { position: relative; display: none; float: left; width: 84%; } @media (min-width: 768px) and (max-width: 1200px) { .search-container { width: 80%; } } @media (max-width:767px) { .search-container { display: none; } } .search-icon { display: none; padding: 17px 20px 16px; float: left; text-transform: uppercase; color: #8a959e; font-size: 12px; font-weight: 400; } .search-icon:hover { cursor: pointer; color: #8a959e; } .search-icon i { margin-right: 5px; color: #8a959e; } @media (max-width: 767px) { .search-icon { display: none !important; } } .header-search-form { position: absolute; z-index: 1000; left: 20px; width: 100%; -webkit-transition-property: width; -webkit-transition-duration: 1s; -webkit-transition-timing-function: linear; /* Standard syntax */ transition-property: width; transition-duration: 1s; transition-timing-function: linear; } @media (max-width:767px) { .header-search-form { display: none; } } .mobile-search-form { display: none; position: relative; width: 100%; } @media (max-width: 767px) { .mobile-search-form { display: block; } } .header-search { border: 2px solid #dae5ee; border-radius: 4px; height: 35px; margin: 7px 0 0 0; background: #fff; width: 100%; -webkit-transition: width 4s; -moz-transition: width 4s; -ms-transition: width 4s; -o-transition: width 4s; transition: width 4s; } .header-search::-webkit-input-placeholder { color: #8a959e; font-size: 12px; text-transform: lowercase; font-weight: 400; } .header-search:-moz-placeholder { /* Firefox 18- */ color: #8a959e; font-size: 12px; text-transform: lowercase; font-weight: 400; } .header-search::-moz-placeholder { /* Firefox 19+ */ color: #8a959e; font-size: 12px; text-transform: lowercase; font-weight: 400; } .header-search:-ms-input-placeholder { color: #8a959e; font-size: 12px; text-transform: lowercase; font-weight: 400; } .header-search:focus { border-radius: 4px; outline: none; border: 2px solid #3D84B6; } .close-search { position: absolute; top: 17px; right: 0px; color: #dae5ee; z-index: 1001; font-size: 16px } .close-search:hover { color: #3D84B6; cursor: pointer; } @media (max-width:767px) { .close-search { display: none !important; } } .show { display: block; } @media (max-width:767px) { .show { display: none; } } /*End Header Navigation*/ /*Hero*/ .intro-header { padding-top: 0px; padding-bottom: 0; text-align: center; color: #f8f8f8; background: url(/images/hero-bkgd1.jpg) no-repeat center center; background-size: cover; position: relative; } .intro-message { position: relative; padding-top: 110px; padding-bottom: 110px; } @media(max-width:1199px) { .intro-message { padding-bottom: 50px; } } .intro-message > h1 { margin: 0; font-size: 3em; font-weight: 300; text-align: center; font-family: ""Open Sans"", Helvetica, Arial, sans-serif; width: 100%; } @media(max-width:767px) { .intro-message > h1 { font-size: 3em; } } .intro-divider { width: 400px; border-top: 1px solid #f8f8f8; border-bottom: 1px solid rgba(0,0,0,0.2); } .intro-message > h3 { text-shadow: none; text-align: left; font-weight: 300; font-size: 24px; margin-top: 10px; } .hero-credit { position: absolute; bottom: 30px; right: 30px; color: #fff; opacity: 0.5; } .hero-credit:hover { opacity: 1; } /*Hero Promo, add .featured to .intro-header*/ .intro-header.featured { text-align: center; background: url(/images/summit-promo-bkgd1.jpg) no-repeat center center; min-height: 420px; background-size: cover; position: relative; } .intro-header.featured .intro-message { padding-bottom: 50px; } .promo-btn-wrapper { } a.promo-btn { color: #fff; font-size: 24px; font-weight: 300; background: transparent; border: 2px solid #fff; border-radius: 4px; padding: 20px 35px; margin: 0 auto; text-align: center; min-width: 370px; display: inline-block; } a.promo-btn:hover { text-decoration: none; background: rgba(255, 255, 255, 0.2); } a.promo-btn i.fa-chevron-right { background: transparent; border: 2px solid #fff; border-radius: 100px; padding: 0; font-size: 14px; margin-left: 10px; width: 30px; height: 30px; line-height: 2.1; } p.promo-dates { display: inline-block; margin-top: 10px; font-weight: 400; } /*End Hero*/ /*Overview Section*/ .overview-section { padding: 80px 0; } @media (max-width: 767px) { .overview-section { padding-top: 40px; } } .overview-section h2 { color: #284d68; font-size: 34px; font-weight: 300; margin-bottom: 25px; } .overview-section p { color: #888; font-size: 16px; font-weight: 300px; line-height: 1.4; } .overview-section a { color: #4c97c3; text-decoration: underline; } .btn-wrapper { float: left; width: 100%; text-align: center; } @media (max-width: 980px) { .overview-left { margin-bottom: 50px; } } a.overview-btn { float: left; background: #4c97c3; color: #fff; text-transform: uppercase; border-radius: 4px; padding: 15px 25px; text-decoration: none; margin-top: 5px; margin-bottom: 5px; } a.overview-btn:hover { background: #2e729a; } a.overview-btn.left-btn { border-top-right-radius: 0; border-bottom-right-radius: 0; border-right: 1px solid #3f81a7; margin-right: 0; } a.overview-btn.right-btn { border-top-left-radius: 0; border-bottom-left-radius: 0; border-left: 1px solid #73b8e1; margin-left: 0; } .release-text { display: block; text-align: left; color: #636568; font-size: 13px; } .overview-section .img-responsive { max-width: 550px; } .overview-right { text-align: center; } .control-cloud-graphic { max-width: 600px; margin: 0 auto 15px; } a.demo-link { font-size: 13px; font-weight: 400; text-decoration: none; color: #34789A; background: #F0F9FE; padding: 10px 25px; border-radius: 4px; } a.demo-link:hover { color: #34789A; background: #CDD9E2; } a.demo-link i { margin-left: 5px; font-size: 14px; } /*When Featured, Add Class .featured to .overview-section*/ .overview-section.featured .overview-right { background: #E8EEF5; border-radius: 4px; text-align: center; padding: 20px; margin-top: 50px; } @media (max-width: 1200px) { .overview-section.featured .overview-right { margin-top: 50px; } } .overview-section.featured .overview-right h3 { color: #3D84B6; text-align: center; } .overview-section.featured .overview-right p { color: #333; font-size: 13px; } .overview-section.featured .overview-right img.promo-graphic { max-width: 350px; margin: 20px auto; } /*End Overview Section*/ /*Customers Section*/ .customers-row { padding: 80px 0; text-align: center; background: #edf2f7; } .customers-row h2 { text-transform: capitalize; margin-bottom: 0; } .customer-logos-wrapper { margin: 15px 0; } .customer-logos { position: relative; padding: 20px 0; } @media (max-width: 767px) { .customer-logos { position: relative; padding: 20px 0; width: 80%; margin: 0 auto; } } .logo-hover { background: #dee2e8; border-radius: 3px; } .logo-hover:after { content: ' '; height: 0; position: absolute; width: 0; border: 10px solid transparent; border-top-color: #dee2e8; top: 100%; left: 50%; margin-left: -10px; } .customers-description { margin: 40px 0; color: #284d68; text-align: center; } .customers-description p { padding: 20px 50px; border-top: 1px solid #dee2e8; border-bottom: 1px solid #dee2e8; display: inline; } @media (max-width: 767px) { .customers-description p { display: block; } } .customers-action { margin-top: 40px; text-align: center; } a.customer-btn { background: #2e729a; color: #fff; text-transform: uppercase; border-radius: 4px; padding: 15px 25px; text-decoration: none; border-style: none; } a.customer-btn:hover { background: #173D5B; color: #fff; } /*When Featured, Add Class .featured to .customers-row*/ .customers-row.featured .customer-logos-wrapper { width: 50%; max-width: 1000px; margin: 40px 25% 0; border-top: 1px solid #DDE3E8; padding-top: 20px; } .customers-row.featured .customer-logos-wrapper hr { color: #333; } .customers-row.featured .customer-logos img { width: 90%; max-width: 100px; } .customers-row.featured .customer-logos:hover { background: none; } .customers-row.featured .customer-logos:hover:after { display: none; } .customers-row.featured .customers-action { margin-top: 0; } .customers-row.featured button.customer-btn { background: none; border-radius: 0; padding: 0; text-decoration: underline; color: #2e729a; text-transform: capitalize; } .featured-description { width: 85%; margin: 40px auto; } @media (max-width: 767px) { iframe { width: 90%; } } /*End Customers Section*/ /*Community Section*/ .community-section { padding: 75px 0; background: url('../images/community-bkgd.jpg') no-repeat center center; background-size: cover; min-height: 350px; } .community-section.featured { background: url('../images/community-bkgd2.jpg') no-repeat center center; background-size: cover; } .community-graphic { max-width: 650px; margin: 0 auto; } @media (max-width: 1200px) { .community-graphic { margin-bottom: 20px; } } .community-section h2 { color: #fff; } .community-section p { color: #fff; } @media (max-width: 1200px) { .community-section h2 { text-align: center; } .community-section p { text-align: center; } } a.community-btn { font-size: 16px; font-weight: 400; background: transparent; border: 1px solid #fff; border-radius: 3px; margin-top: 10px; padding: 8px 30px 8px 40px; color: white; float: left; } a.community-btn i { margin-left: 10px; } a.community-btn:hover { text-decoration: none; background: rgba(255, 255, 255, 0.2); } /*When Featured, add .featured to .community-section*/ .community-section.featured h3 { color: #fff; } @media (max-width: 1200px) { .community-section.featured h3 { text-align: center; } } .designate-logo { max-width: 302px; margin: 50px 0 20px; } @media (max-width: 1200px) { .designate-logo { margin: 50px auto 20px; } } .default-community { background-color: rgba(5, 54, 86, 0.7); border-radius: 4px; padding: 30px; text-align: center; } @media (max-width: 1200px) { .default-community { margin-top: 50px; } } .default-community h2 { margin-top: 0; } .community-graphic.small { max-width: 450px; margin: 20px auto; } a.featured-link { display: block; background: #b9301d; padding: 10px 20px; border-radius: 2px; width: 80%; text-decoration: none; margin: 10px auto 0; color: #fff; font-weight: 600; } a.featured-link:hover { text-decoration: none; background: #831917; } /*End Community Section*/ /*News and Events Section*/ .news-section { padding: 70px 0; } .news-section h2 a { font-size: 14px; color: #559bc4; font-weight: 400; margin-left: 30px; } .news-section h2 a:hover { color: #28709a; text-decoration: none; } .event-ad, .news-ad { width: 100%; max-width: 560px; margin-bottom: 20px; } .news-wrapper { /*float: left;*/ } .news-section .news-wrapper ul { margin: 30px 0; padding-start: 0; -webkit-padding-start: 0; } .news-section .news-wrapper ul li { list-style: none; } .single-event, .eventBlock .event { float: left; width: 100%; padding: 15px 10px; border-bottom: 1px solid #ebeff4; } .single-event:hover, .eventBlock .event:hover { background: #f9f9f9; } .single-event.last, .eventBlock .event.last { border-bottom: none; } .left-event { float: left; width: 20%; } @media (min-width: 768px) and (max-width: 981px) { .left-event { width: 25%; } } @media (max-width: 767px) { .left-event { width: 15%; } } .event-details { float: left; margin-left: 3%; width: 62%; } @media (min-width: 768px) and (max-width: 981px) { .event-details { width: 72%; } } .right-event { float: right; width: 13%; } @media (min-width: 768px) and (max-width: 981px) { .right-event { display: none; } } .date, .news-type, .planet-type { background: #fff; border: 2px solid #b9301d; border-radius: 4px; padding: 5px 15px; color: #b9301d; font-size: 10px; width: 100%; text-align: center; float: left; margin-top: 5px; } .event-name, .news-title { display: block; font-size: 14px; font-weight: 600; color: #333; width: 100%; white-space: nowrap; overflow: hidden; text-overflow: ellipsis; } .location, .news-date { display: block; float: left; font-style: italic; color: #333; font-weight: 300; } .right-arrow { float: right; background: #d9dfe5; border-radius: 100px; width: 30px; height: 30px; padding: 6px 10px; color: #fff; margin-right: 10px; margin-top: 5px; display: none; } .single-event:hover .right-arrow { display: block; } .news-type { border: 2px solid #2a4d67; color: #2a4d67; } .planet-type { border: 2px solid #74c99f; color: #74c99f; } .see-more-bottom { width: 100%; float: left; text-align: center; margin-top: 40px; } .see-more-bottom a { color: #2e729a; text-decoration: none; padding: 5px 15px; border-radius: 4px; background: ; font-size: 12px; font-weight: 400; border: 2px solid #2e729a; } .see-more-bottom a i { margin-left: 10px; font-size: 11px; } /*End News and Events Section*/ /*Photo Row*/ .photo-row-wrapper { width: 100%; color: #eee; max-height: 240px; margin: 80px 0 10px; overflow: hidden; } @media (max-width: 765px) { .photo-row-wrapper { display: none; } } .photo-container { width: 4000px; max-height: 240px; margin-left: -30px; } .photo-container img { margin: 0 10px 0 0; max-width: 22%; max-height: 240px; } /*End Photo Row*/ /*Footer*/ footer { background: #333333; padding: 70px 0; } .footer-links h3 { color: #fff; font-size: 14px; font-weight: 400; } .footer-links ul { margin-left: 0; padding-start: 0; -webkit-padding-start: 0; } .footer-links ul li a { color: #aaa; font-size: 12px; font-weight: 400; list-style: none; margin-left: 0; } .social-icons { width: 40px; min-height: 40px; display: inline-block; margin-right: 10px; } .footer-twitter { background: url('../images/footer-twitter.png') no-repeat; } .footer-twitter:hover { background: url('../images/footer-twitter-hover.png') no-repeat; } .footer-facebook { background: url('../images/footer-facebook.png') no-repeat; } .footer-facebook:hover { background: url('../images/footer-facebook-hover.png') no-repeat; } .footer-linkedin { background: url('../images/footer-linkedin.png') no-repeat; } .footer-linkedin:hover { background: url('../images/footer-linkedin-hover.png') no-repeat; } .footer-youtube { background: url('../images/footer-youtube.png') no-repeat; } .footer-youtube:hover { background: url('../images/footer-youtube-hover.png') no-repeat; } .newsletter-form { margin: 10px 0 30px; width: 100%; } .newsletter-form label { color: #aaa; font-size: 12px; font-weight: 300; display: block; } .newsletter-input { display: inline-block; background: transparent; border: 2px solid #888; border-radius: 4px; color: #888; font-size: 12px; font-weight: 400; padding: 10px 15px; width: 70%; } @media (max-width: 767px) { .newsletter-input { width: 70%; } } .newsletter-input::-webkit-input-placeholder { color: #888; font-size: 12px; font-weight: 400; text-transform: uppercase; } .newsletter-input:-moz-placeholder { /* Firefox 18- */ color: #888; font-size: 12px; font-weight: 400; text-transform: uppercase; } .newsletter-input::-moz-placeholder { /* Firefox 19+ */ color: #888; font-size: 12px; font-weight: 400; text-transform: uppercase; } .newsletter-input:-ms-input-placeholder { color: #888; font-size: 12px; font-weight: 400; text-transform: uppercase; } .newsletter-input:focus { outline: none; border: 2px solid #666; } .newsletter-btn { margin-left: 1%; display: inline-block; background: transparent; border: 2px solid #4c97c3; border-radius: 4px; color: #4c97c3; font-size: 12px; font-weight: 400; padding: 10px 15px; text-transform: uppercase; width: 27%; } @media (max-width: 767px) { .newsletter-btn { width: 18%; margin-left: 2%; padding: 10px; } } .newsletter-btn:hover { border: 2px solid #888; color: #999; } .fine-print { margin-top: 20px; color: #aaa; font-size: 12px; } .fine-print a { color: #aaa; text-decoration: underline; } .fine-print a:hover { color: #fff; } .footer-bottom { background: #222; padding: 15px 0; text-align: center; width: 100%; } .feedback-input { display: inline-block; background: #222; border: 2px solid #444; border-radius: 4px; color: #777; font-size: 12px; font-weight: 400; padding: 10px 20px; width: 310px; } @media (max-width: 767px) { .feedback-input { width: 70%; } } .feedback-input::-webkit-input-placeholder { color: #555; font-size: 12px; font-weight: 400; } .feedback-input:-moz-placeholder { /* Firefox 18- */ color: #555; font-size: 12px; font-weight: 400; } .feedback-input::-moz-placeholder { /* Firefox 19+ */ color: #555; font-size: 12px; font-weight: 400; } .feedback-input:-ms-input-placeholder { color: #555; font-size: 12px; font-weight: 400; } .feedback-input:focus { outline: none; border: 2px solid #666; } .feedback-btn { margin-left: 11px; display: inline-block; background: #222; border: 2px solid #666; border-radius: 4px; color: #777; font-size: 12px; font-weight: 400; padding: 10px 30px; } @media (max-width: 767px) { .feedback-btn { width: 18%; margin-left: 2%; padding: 10px; } } .feedback-btn:hover { border: 2px solid #888; color: #999; } /*End Footer*/ /*General Inner Page Styles*/ .navbar-default.inner { border-bottom: 1px solid #ddd; } /*End General Inner Page Styles*/ /*Events Page*/ .eventsBanner { height: 150px; padding: 20px } .eventsPhotoCaption { background: rgba(0,0,0,0.3); border-radius: 4px; padding: 10px; color: white; } .news-section.full { padding: 20px 0; } .eventTitleArea { text-align: center; margin: 40px 0; } .eventTitleArea h1 { color: #333; font-weight: 300; } .postEvent { float: left; width: 100%; height: 130px; padding: 30px 5%; background: #F4F5F8; margin: 20px 0 10px; text-align: center; } .postEvent p { margin-bottom: 20px; } .postEvent a { background: #2e729a; padding: 10px 25px; border-radius: 4px; color: #fff; } .eventBlock { float: left; width: 100%; } .eventBlock.summit .date { border-color: #255E88; color: #255E88 ; } .eventBlock.past h2 { margin-top: 50px; } .eventBlock.past .date { border-color: #555; color: #555; } .eventButton a { } /*End Events Page*/ /*Community Page*/ .communityBoxes { margin: 30px 0 10px; font-size: 13px; } .communityBoxes h2 { font-size: 20px; font-weight: 400; margin-bottom: 15px; } .communityBoxes h2 a { color: #CD281E; } .developersRow { border-top: 1px solid #eee; border-bottom: 1px solid #eee; padding: 20px 30px; margin-bottom: 30px; } .devLabel { float: left; margin-right: 30px; font-weight: 700; } ul#developerActivity { float: left; padding-left: 0; margin: 0; } ul#developerActivity li { list-style: none; display: inline-block; } ul#developerActivity li a { font-weight: 700; color: #222; } ul#developerActivity li span { background: #E8EEF5; padding: 5px 10px; border-radius: 4px; margin-right: 5px; color: #255E88; font-size: 11px; font-weight: 400; } /*End Community Page*/ ","/*! * Start Bootstrap - Landing Page Bootstrap Theme (http://startbootstrap.com) * Code licensed under the Apache License v2.0. * For details, see http://www.apache.org/licenses/LICENSE-2.0. */ body, html { width: 100%; height: 100%; } body, h1, h2, h3, h4, h5, h6 { font-family: ""Open Sans"", Helvetica, Arial, sans-serif; font-weight: 400; } h2 { color: #284d68; font-size: 34; font-weight: 300; margin-bottom: 25px; } h5 { color: #da3d27; margin-bottom: 0; } dd { margin-left: 20px } .lead { font-size: 18px; font-weight: 400; } /*Header Navigation*/ .brand-wrapper { margin: 10px 0; padding-right: 20px; float: left; border-right: 1px solid #eee; min-width: 135px; } @media (max-width: 767px) { .brand-wrapper { border-right: none; } } a.navbar-brand { background: url('../images/openstack-logo-full.png') left no-repeat; height: 35px; width: 135px; } @media (min-width: 768px) and (max-width: 1025px) { .brand-wrapper { width: 75px; min-width: 75px; margin-top: 0; } a.navbar-brand { background: url('../images/openstack-logo-vert.png') left no-repeat; margin-left: 0px !important; height: 54px; width: 59px; } } @media (max-width: 767px) { a.navbar-brand { margin-left: 15px; } } .navbar-default { border: none; border-radius: 0px; background: #fff; margin-bottom: 0; padding: 20px 0; } .navbar-default .container { background-color: white; } @media (min-width: 768px) and (max-width: 1200px) { .navbar-default .container { width: 100%; } } ul.navbar-main { display: none; float: right; } @media (min-width: 768px) and (max-width: 1097px) { ul.navbar-main { display: block; } } @media (max-width:767px) { ul.navbar-main { display: block; margin-right: 30px; width: 90%; } } .navbar-default ul.navbar-main>li>a { color: #8a959e; font-size: 12px; font-weight: 400; text-transform: uppercase; } @media (min-width: 768px) and (max-width: 1025px) { ul.navbar-main { margin-top: 1px; } .navbar-default ul.navbar-main>li>a { font-size: 11px; padding: 15px 8px; } } .navbar-default ul.navbar-main>li>a.sign-in-btn { background: #2e729a; padding: 7px 25px; border-radius: 2px; color: #fff; margin-top: 7px; } .navbar-default ul.navbar-main>li>a.sign-in-btn:hover { background: #286A9D; color: #fff; } @media (max-width: 1025px) { .navbar-default ul.navbar-main>li>a.sign-in-btn { padding: 5px 10px; margin-top: 9px; } } @media (max-width: 767px) { .navbar-default ul.navbar-main>li>a.sign-in-btn { margin: 0; padding: 10px 15px; background: transparent; border: none; color: #2e729a; font-size: 12px; font-weight: 700; text-transform: uppercase; } .navbar-default ul.navbar-main>li>a.sign-in-btn:hover { background: #fff; color: #286A9D; } } .navbar-default .navbar-nav>.open>a, .navbar-default .navbar-nav>.open>a:hover, .navbar-default .navbar-nav>.open>a:focus { background: #fff; } .navbar-nav>li>.dropdown-menu { margin-top: 10px; padding: 10px 0; min-width: 230px; border-top-left-radius: 4px; border-top-right-radius: 4px; } .navbar-nav>li>.dropdown-menu:after, .navbar-nav>li>.dropdown-menu:before { bottom: 100%; left: 25%; border: solid transparent; content: "" ""; height: 0; width: 0; position: absolute; pointer-events: none; } .navbar-nav>li>.dropdown-menu:after { border-color: rgba(255, 255, 255, 0); border-bottom-color: #ffffff; border-width: 15px; margin-left: -15px; } .navbar-nav>li>.dropdown-menu:before { border-color: rgba(170, 170, 170, 0); border-bottom-color: #aaaaaa; border-width: 16px; margin-left: -16px; } @media (max-width: 767px) { .navbar-nav>li>.dropdown-menu:after, .navbar-nav>li>.dropdown-menu:before { display: none; } .navbar-nav>li>.dropdown-menu:after { display: none; } .navbar-nav>li>.dropdown-menu:before { display: none; } } i.fa-caret-right { margin-left: 8px; } .navbar-nav>li>.dropdown-menu li a{ text-transform: uppercase; padding: 13px 20px; font-size: 12px; color: #8a959e; } .navbar-nav>li>.dropdown-menu li a:hover { color: #333; } .navbar-nav>li>.dropdown-menu li a:focus { outline: none; } @media (max-width: 767px) { .navbar-default ul.navbar-main>li>a i.fa-caret-down { display: none; } } .navbar-default .navbar-toggle { border: none; } .navbar-default .navbar-toggle:hover, .navbar-default .navbar-toggle:focus { background: transparent; } .navbar-default .navbar-toggle .icon-bar { background-color: #5A5A5A; height: 3px; border-radius: 3px; } .search-container { position: relative; display: none; float: left; width: 84%; } @media (min-width: 768px) and (max-width: 1200px) { .search-container { width: 80%; } } @media (max-width:767px) { .search-container { display: none; } } .search-icon { display: none; padding: 17px 20px 16px; float: left; text-transform: uppercase; color: #8a959e; font-size: 12px; font-weight: 400; } .search-icon:hover { cursor: pointer; color: #8a959e; } .search-icon i { margin-right: 5px; color: #8a959e; } @media (max-width: 767px) { .search-icon { display: none !important; } } .header-search-form { position: absolute; z-index: 1000; left: 20px; width: 100%; -webkit-transition-property: width; -webkit-transition-duration: 1s; -webkit-transition-timing-function: linear; /* Standard syntax */ transition-property: width; transition-duration: 1s; transition-timing-function: linear; } @media (max-width:767px) { .header-search-form { display: none; } } .mobile-search-form { display: none; position: relative; width: 100%; } @media (max-width: 767px) { .mobile-search-form { display: block; } } .header-search { border: 2px solid #dae5ee; border-radius: 4px; height: 35px; margin: 7px 0 0 0; background: #fff; width: 100%; -webkit-transition: width 4s; -moz-transition: width 4s; -ms-transition: width 4s; -o-transition: width 4s; transition: width 4s; } .header-search::-webkit-input-placeholder { color: #8a959e; font-size: 12px; text-transform: lowercase; font-weight: 400; } .header-search:-moz-placeholder { /* Firefox 18- */ color: #8a959e; font-size: 12px; text-transform: lowercase; font-weight: 400; } .header-search::-moz-placeholder { /* Firefox 19+ */ color: #8a959e; font-size: 12px; text-transform: lowercase; font-weight: 400; } .header-search:-ms-input-placeholder { color: #8a959e; font-size: 12px; text-transform: lowercase; font-weight: 400; } .header-search:focus { border-radius: 4px; outline: none; border: 2px solid #3D84B6; } .close-search { position: absolute; top: 17px; right: 0px; color: #dae5ee; z-index: 1001; font-size: 16px } .close-search:hover { color: #3D84B6; cursor: pointer; } @media (max-width:767px) { .close-search { display: none !important; } } .show { display: block; } @media (max-width:767px) { .show { display: none; } } /*End Header Navigation*/ /*Hero*/ .intro-header { padding-top: 0px; padding-bottom: 0; text-align: center; color: #f8f8f8; background: url(/images/hero-bkgd1.jpg) no-repeat center center; background-size: cover; position: relative; } .intro-message { position: relative; padding-top: 110px; padding-bottom: 110px; } @media(max-width:1199px) { .intro-message { padding-bottom: 50px; } } .intro-message > h1 { margin: 0; font-size: 3em; font-weight: 300; text-align: center; font-family: ""Open Sans"", Helvetica, Arial, sans-serif; width: 100%; } @media(max-width:767px) { .intro-message > h1 { font-size: 3em; } } .intro-divider { width: 400px; border-top: 1px solid #f8f8f8; border-bottom: 1px solid rgba(0,0,0,0.2); } .intro-message > h3 { text-shadow: none; text-align: left; font-weight: 300; font-size: 24px; margin-top: 10px; } .hero-credit { position: absolute; bottom: 30px; right: 30px; color: #fff; opacity: 0.5; } .hero-credit:hover { opacity: 1; } /*Hero Promo, add .featured to .intro-header*/ .intro-header.featured { text-align: center; background: url(/images/summit-promo-bkgd1.jpg) no-repeat center center; min-height: 420px; background-size: cover; position: relative; } .intro-header.featured .intro-message { padding-bottom: 50px; } .promo-btn-wrapper { } a.promo-btn { color: #fff; font-size: 24px; font-weight: 300; background: transparent; border: 2px solid #fff; border-radius: 4px; padding: 20px 35px; margin: 0 auto; text-align: center; min-width: 370px; display: inline-block; } a.promo-btn:hover { text-decoration: none; background: rgba(255, 255, 255, 0.2); } a.promo-btn i.fa-chevron-right { background: transparent; border: 2px solid #fff; border-radius: 100px; padding: 0; font-size: 14px; margin-left: 10px; width: 30px; height: 30px; line-height: 2.1; } p.promo-dates { display: inline-block; margin-top: 10px; font-weight: 400; } /*End Hero*/ /*Overview Section*/ .overview-section { padding: 80px 0; } @media (max-width: 767px) { .overview-section { padding-top: 40px; } } .overview-section h2 { color: #284d68; font-size: 34px; font-weight: 300; margin-bottom: 25px; } .overview-section p { color: #888; font-size: 16px; font-weight: 300px; line-height: 1.4; } .overview-section a { color: #4c97c3; text-decoration: underline; } .btn-wrapper { float: left; width: 100%; text-align: center; } @media (max-width: 980px) { .overview-left { margin-bottom: 50px; } } a.overview-btn { float: left; background: #4c97c3; color: #fff; text-transform: uppercase; border-radius: 4px; padding: 15px 25px; text-decoration: none; margin-top: 5px; margin-bottom: 5px; } a.overview-btn:hover { background: #2e729a; } a.overview-btn.left-btn { border-top-right-radius: 0; border-bottom-right-radius: 0; border-right: 1px solid #3f81a7; margin-right: 0; } a.overview-btn.right-btn { border-top-left-radius: 0; border-bottom-left-radius: 0; border-left: 1px solid #73b8e1; margin-left: 0; } .release-text { display: block; text-align: left; color: #636568; font-size: 13px; } .overview-section .img-responsive { max-width: 550px; } .overview-right { text-align: center; } .control-cloud-graphic { max-width: 600px; margin: 0 auto 15px; } a.demo-link { font-size: 13px; font-weight: 400; text-decoration: none; color: #34789A; background: #F0F9FE; padding: 10px 25px; border-radius: 4px; } a.demo-link:hover { color: #34789A; background: #CDD9E2; } a.demo-link i { margin-left: 5px; font-size: 14px; } /*When Featured, Add Class .featured to .overview-section*/ .overview-section.featured .overview-right { background: #E8EEF5; border-radius: 4px; text-align: center; padding: 20px; margin-top: 50px; } @media (max-width: 1200px) { .overview-section.featured .overview-right { margin-top: 50px; } } .overview-section.featured .overview-right h3 { color: #3D84B6; text-align: center; } .overview-section.featured .overview-right p { color: #333; font-size: 13px; } .overview-section.featured .overview-right img.promo-graphic { max-width: 350px; margin: 20px auto; } /*End Overview Section*/ /*Customers Section*/ .customers-row { padding: 80px 0; text-align: center; background: #edf2f7; } .customers-row h2 { text-transform: capitalize; margin-bottom: 0; } .customer-logos-wrapper { margin: 15px 0; } .customer-logos { position: relative; padding: 20px 0; } @media (max-width: 767px) { .customer-logos { position: relative; padding: 20px 0; width: 80%; margin: 0 auto; } } .logo-hover { background: #dee2e8; border-radius: 3px; } .logo-hover:after { content: ' '; height: 0; position: absolute; width: 0; border: 10px solid transparent; border-top-color: #dee2e8; top: 100%; left: 50%; margin-left: -10px; } .customers-description { margin: 40px 0; color: #284d68; text-align: center; } .customers-description p { padding: 20px 50px; border-top: 1px solid #dee2e8; border-bottom: 1px solid #dee2e8; display: inline; } @media (max-width: 767px) { .customers-description p { display: block; } } .customers-action { margin-top: 40px; text-align: center; } a.customer-btn { background: #2e729a; color: #fff; text-transform: uppercase; border-radius: 4px; padding: 15px 25px; text-decoration: none; border-style: none; } a.customer-btn:hover { background: #173D5B; color: #fff; } /*When Featured, Add Class .featured to .customers-row*/ .customers-row.featured .customer-logos-wrapper { width: 50%; max-width: 1000px; margin: 40px 25% 0; border-top: 1px solid #DDE3E8; padding-top: 20px; } .customers-row.featured .customer-logos-wrapper hr { color: #333; } .customers-row.featured .customer-logos img { width: 90%; max-width: 100px; } .customers-row.featured .customer-logos:hover { background: none; } .customers-row.featured .customer-logos:hover:after { display: none; } .customers-row.featured .customers-action { margin-top: 0; } .customers-row.featured button.customer-btn { background: none; border-radius: 0; padding: 0; text-decoration: underline; color: #2e729a; text-transform: capitalize; } .featured-description { width: 85%; margin: 40px auto; } @media (max-width: 767px) { iframe { width: 90%; } } /*End Customers Section*/ /*Community Section*/ .community-section { padding: 75px 0; background: url('../images/community-bkgd.jpg') no-repeat center center; background-size: cover; min-height: 350px; } .community-section.featured { background: url('../images/community-bkgd2.jpg') no-repeat center center; background-size: cover; } .community-graphic { max-width: 650px; margin: 0 auto; } @media (max-width: 1200px) { .community-graphic { margin-bottom: 20px; } } .community-section h2 { color: #fff; } .community-section p { color: #fff; } @media (max-width: 1200px) { .community-section h2 { text-align: center; } .community-section p { text-align: center; } } a.community-btn { font-size: 16px; font-weight: 400; background: transparent; border: 1px solid #fff; border-radius: 3px; margin-top: 10px; padding: 8px 30px 8px 40px; color: white; float: left; } a.community-btn i { margin-left: 10px; } a.community-btn:hover { text-decoration: none; background: rgba(255, 255, 255, 0.2); } /*When Featured, add .featured to .community-section*/ .community-section.featured h3 { color: #fff; } @media (max-width: 1200px) { .community-section.featured h3 { text-align: center; } } .designate-logo { max-width: 302px; margin: 50px 0 20px; } @media (max-width: 1200px) { .designate-logo { margin: 50px auto 20px; } } .default-community { background-color: rgba(5, 54, 86, 0.7); border-radius: 4px; padding: 30px; text-align: center; } @media (max-width: 1200px) { .default-community { margin-top: 50px; } } .default-community h2 { margin-top: 0; } .community-graphic.small { max-width: 450px; margin: 20px auto; } a.featured-link { display: block; background: #b9301d; padding: 10px 20px; border-radius: 2px; width: 80%; text-decoration: none; margin: 10px auto 0; color: #fff; font-weight: 600; } a.featured-link:hover { text-decoration: none; background: #831917; } /*End Community Section*/ /*News and Events Section*/ .news-section { padding: 70px 0; } .news-section h2 a { font-size: 14px; color: #559bc4; font-weight: 400; margin-left: 30px; } .news-section h2 a:hover { color: #28709a; text-decoration: none; } .event-ad, .news-ad { width: 100%; max-width: 560px; margin-bottom: 20px; } .news-wrapper { /*float: left;*/ } .news-section .news-wrapper ul { margin: 30px 0; padding-start: 0; -webkit-padding-start: 0; } .news-section .news-wrapper ul li { list-style: none; } .single-event, .eventBlock .event { float: left; width: 100%; padding: 15px 10px; border-bottom: 1px solid #ebeff4; } .single-event:hover, .eventBlock .event:hover { background: #f9f9f9; } .single-event.last, .eventBlock .event.last { border-bottom: none; } .left-event { float: left; width: 20%; } @media (min-width: 768px) and (max-width: 981px) { .left-event { width: 25%; } } @media (max-width: 767px) { .left-event { width: 15%; } } .event-details { float: left; margin-left: 3%; width: 62%; } @media (min-width: 768px) and (max-width: 981px) { .event-details { width: 72%; } } .right-event { float: right; width: 13%; } @media (min-width: 768px) and (max-width: 981px) { .right-event { display: none; } } .date, .news-type, .planet-type { background: #fff; border: 2px solid #b9301d; border-radius: 4px; padding: 5px 15px; color: #b9301d; font-size: 10px; width: 100%; text-align: center; float: left; margin-top: 5px; } .event-name, .news-title { display: block; font-size: 14px; font-weight: 600; color: #333; width: 100%; white-space: nowrap; overflow: hidden; text-overflow: ellipsis; } .location, .news-date { display: block; float: left; font-style: italic; color: #333; font-weight: 300; } .right-arrow { float: right; background: #d9dfe5; border-radius: 100px; width: 30px; height: 30px; padding: 6px 10px; color: #fff; margin-right: 10px; margin-top: 5px; display: none; } .single-event:hover .right-arrow { display: block; } .news-type { border: 2px solid #2a4d67; color: #2a4d67; } .planet-type { border: 2px solid #74c99f; color: #74c99f; } .see-more-bottom { width: 100%; float: left; text-align: center; margin-top: 40px; } .see-more-bottom a { color: #2e729a; text-decoration: none; padding: 5px 15px; border-radius: 4px; background: ; font-size: 12px; font-weight: 400; border: 2px solid #2e729a; } .see-more-bottom a i { margin-left: 10px; font-size: 11px; } /*End News and Events Section*/ /*Photo Row*/ .photo-row-wrapper { width: 100%; color: #eee; max-height: 240px; margin: 80px 0 10px; overflow: hidden; } @media (max-width: 765px) { .photo-row-wrapper { display: none; } } .photo-container { width: 4000px; max-height: 240px; margin-left: -30px; } .photo-container img { margin: 0 10px 0 0; max-width: 22%; max-height: 240px; } /*End Photo Row*/ /*Footer*/ footer { background: #333333; padding: 70px 0; } .footer-links h3 { color: #fff; font-size: 14px; font-weight: 400; } .footer-links ul { margin-left: 0; padding-start: 0; -webkit-padding-start: 0; } .footer-links ul li a { color: #aaa; font-size: 12px; font-weight: 400; list-style: none; margin-left: 0; } .social-icons { width: 40px; min-height: 40px; display: inline-block; margin-right: 10px; } .footer-twitter { background: url('../images/footer-twitter.png') no-repeat; } .footer-twitter:hover { background: url('../images/footer-twitter-hover.png') no-repeat; } .footer-facebook { background: url('../images/footer-facebook.png') no-repeat; } .footer-facebook:hover { background: url('../images/footer-facebook-hover.png') no-repeat; } .footer-linkedin { background: url('../images/footer-linkedin.png') no-repeat; } .footer-linkedin:hover { background: url('../images/footer-linkedin-hover.png') no-repeat; } .footer-youtube { background: url('../images/footer-youtube.png') no-repeat; } .footer-youtube:hover { background: url('../images/footer-youtube-hover.png') no-repeat; } .newsletter-form { margin: 10px 0 30px; width: 100%; } .newsletter-form label { color: #aaa; font-size: 12px; font-weight: 300; display: block; } .newsletter-input { display: inline-block; background: transparent; border: 2px solid #888; border-radius: 4px; color: #888; font-size: 12px; font-weight: 400; padding: 10px 15px; width: 70%; } @media (max-width: 767px) { .newsletter-input { width: 70%; } } .newsletter-input::-webkit-input-placeholder { color: #888; font-size: 12px; font-weight: 400; text-transform: uppercase; } .newsletter-input:-moz-placeholder { /* Firefox 18- */ color: #888; font-size: 12px; font-weight: 400; text-transform: uppercase; } .newsletter-input::-moz-placeholder { /* Firefox 19+ */ color: #888; font-size: 12px; font-weight: 400; text-transform: uppercase; } .newsletter-input:-ms-input-placeholder { color: #888; font-size: 12px; font-weight: 400; text-transform: uppercase; } .newsletter-input:focus { outline: none; border: 2px solid #666; } .newsletter-btn { margin-left: 1%; display: inline-block; background: transparent; border: 2px solid #4c97c3; border-radius: 4px; color: #4c97c3; font-size: 12px; font-weight: 400; padding: 10px 15px; text-transform: uppercase; width: 27%; } @media (max-width: 767px) { .newsletter-btn { width: 18%; margin-left: 2%; padding: 10px; } } .newsletter-btn:hover { border: 2px solid #888; color: #999; } .fine-print { margin-top: 20px; color: #aaa; font-size: 12px; } .fine-print a { color: #aaa; text-decoration: underline; } .fine-print a:hover { color: #fff; } .footer-bottom { background: #222; padding: 15px 0; text-align: center; width: 100%; } .feedback-input { display: inline-block; background: #222; border: 2px solid #444; border-radius: 4px; color: #777; font-size: 12px; font-weight: 400; padding: 10px 20px; width: 310px; } @media (max-width: 767px) { .feedback-input { width: 70%; } } .feedback-input::-webkit-input-placeholder { color: #555; font-size: 12px; font-weight: 400; } .feedback-input:-moz-placeholder { /* Firefox 18- */ color: #555; font-size: 12px; font-weight: 400; } .feedback-input::-moz-placeholder { /* Firefox 19+ */ color: #555; font-size: 12px; font-weight: 400; } .feedback-input:-ms-input-placeholder { color: #555; font-size: 12px; font-weight: 400; } .feedback-input:focus { outline: none; border: 2px solid #666; } .feedback-btn { margin-left: 11px; display: inline-block; background: #222; border: 2px solid #666; border-radius: 4px; color: #777; font-size: 12px; font-weight: 400; padding: 10px 30px; } @media (max-width: 767px) { .feedback-btn { width: 18%; margin-left: 2%; padding: 10px; } } .feedback-btn:hover { border: 2px solid #888; color: #999; } /*End Footer*/ /*General Inner Page Styles*/ .navbar-default.inner { border-bottom: 1px solid #ddd; } /*End General Inner Page Styles*/ /*Events Page*/ .eventsBanner { height: 150px; padding: 20px } .eventsPhotoCaption { background: rgba(0,0,0,0.3); border-radius: 4px; padding: 10px; color: white; } .news-section.full { padding: 20px 0; } .eventTitleArea { text-align: center; margin: 40px 0; } .eventTitleArea h1 { color: #333; font-weight: 300; } .postEvent { float: left; width: 100%; height: 130px; padding: 30px 5%; background: #F4F5F8; margin: 20px 0 10px; text-align: center; } .postEvent p { margin-bottom: 20px; } .postEvent a { background: #2e729a; padding: 10px 25px; border-radius: 4px; color: #fff; } .eventBlock { float: left; width: 100%; } .eventBlock.summit .date { border-color: #255E88; color: #255E88 ; } .eventBlock.past h2 { margin-top: 50px; } .eventBlock.past .date { border-color: #555; color: #555; } .eventButton a { } /*End Events Page*/ /*Community Page*/ .communityBoxes { margin: 30px 0 10px; font-size: 13px; } .communityBoxes h2 { font-size: 20px; font-weight: 400; margin-bottom: 15px; } .communityBoxes h2 a { color: #CD281E; } .developersRow { border-top: 1px solid #eee; border-bottom: 1px solid #eee; padding: 20px 30px; margin-bottom: 30px; } .devLabel { float: left; margin-right: 30px; font-weight: 700; } ul#developerActivity { float: left; padding-left: 0; margin: 0; } ul#developerActivity li { list-style: none; display: inline-block; } ul#developerActivity li a { font-weight: 700; color: #222; } ul#developerActivity li span { background: #E8EEF5; padding: 5px 10px; border-radius: 4px; margin-right: 5px; color: #255E88; font-size: 11px; font-weight: 400; } /*End Community Page*/",1337,1337
openstack%2Fastara~master~I8bf4832ea5e96c0a4a2221c3a04d1fb52376e387,openstack/astara,master,I8bf4832ea5e96c0a4a2221c3a04d1fb52376e387,Expose RUG API port as a config option,MERGED,2015-06-22 23:53:12.000000000,2015-06-24 17:11:11.000000000,2015-06-24 17:11:08.000000000,"[{'_account_id': 3}, {'_account_id': 1420}, {'_account_id': 2592}, {'_account_id': 8005}]","[{'number': 1, 'created': '2015-06-22 23:53:12.000000000', 'files': ['akanda/rug/api/rug.py', 'devstack/plugin.sh'], 'web_link': 'https://opendev.org/openstack/astara/commit/17a1c23f36c8b8a20aba9672af5afe7a267346c4', 'message': 'Expose RUG API port as a config option\n\nThis removes the hard-coding of the RUG REST API port and exposes\nit as a new config option.  The devstack code is updated to set this\nand point horizon at the correct port.\n\nChange-Id: I8bf4832ea5e96c0a4a2221c3a04d1fb52376e387\n'}]",0,194444,17a1c23f36c8b8a20aba9672af5afe7a267346c4,9,4,1,1420,,,0,"Expose RUG API port as a config option

This removes the hard-coding of the RUG REST API port and exposes
it as a new config option.  The devstack code is updated to set this
and point horizon at the correct port.

Change-Id: I8bf4832ea5e96c0a4a2221c3a04d1fb52376e387
",git fetch https://review.opendev.org/openstack/astara refs/changes/44/194444/1 && git format-patch -1 --stdout FETCH_HEAD,"['akanda/rug/api/rug.py', 'devstack/plugin.sh']",2,17a1c23f36c8b8a20aba9672af5afe7a267346c4,api_port,"AKANDA_RUG_API_PORT=${AKANDA_RUG_API_PORT:-44250} iniset $AKANDA_RUG_CONF DEFAULT rug_api_port $AKANDA_RUG_API_PORT _horizon_config_set $HORIZON_LOCAL_SETTINGS """" RUG_API_PORT \""$AKANDA_RUG_API_PORT\"""," _horizon_config_set $HORIZON_LOCAL_SETTINGS """" RUG_API_PORT \""$AKANDA_RUG_MANAGEMENT_PORT\""",12,3
openstack%2Fmurano~master~I9603c13d5ce170d516acea208c33f92570f04c96,openstack/murano,master,I9603c13d5ce170d516acea208c33f92570f04c96,Do not store session db in tmp directory,MERGED,2015-06-15 11:04:01.000000000,2015-06-24 17:05:37.000000000,2015-06-24 17:05:35.000000000,"[{'_account_id': 3}, {'_account_id': 7535}, {'_account_id': 7549}, {'_account_id': 7821}, {'_account_id': 8127}, {'_account_id': 13752}, {'_account_id': 13962}, {'_account_id': 14265}, {'_account_id': 15168}]","[{'number': 1, 'created': '2015-06-15 11:04:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/murano/commit/04e5f20b1a325458f952dbcf736974458ced9278', 'message': 'Do not store session db in tmp directory\n\nThis commit prevents situation, when after machine reboot manage.py syncdb is needed\nto recreate a database.\n\nThe db location changed to $HOME to prevent error with rights.\n\nChange was made to devstack script and murano documnetation.\n\nChange-Id: I9603c13d5ce170d516acea208c33f92570f04c96\nCloses-Bug: #1464215\n'}, {'number': 2, 'created': '2015-06-16 13:14:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/murano/commit/14ab0914acbdd109357fcc7fec31ede3648694fc', 'message': 'Do not store session db in tmp directory\n\nThis commit prevents situation, when after machine reboot manage.py syncdb is needed\nto recreate a database.\n\nThe db location changed to murano /opt/stack/murano-dashboard in murano devstack script.\nDocumentation also was updated.\n\nChange-Id: I9603c13d5ce170d516acea208c33f92570f04c96\nCloses-Bug: #1464215\n'}, {'number': 3, 'created': '2015-06-16 13:17:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/murano/commit/04a8c7a778329aba47c908770e805485e5e531ee', 'message': 'Do not store session db in tmp directory\n\nThis commit prevents situation, when after machine reboot manage.py syncdb is needed\nto recreate a database.\n\nThe db location changed to murano /opt/stack/murano-dashboard in murano devstack script.\nDocumentation also was updated.\n\nChange-Id: I9603c13d5ce170d516acea208c33f92570f04c96\nCloses-Bug: #1464215\n'}, {'number': 4, 'created': '2015-06-22 15:59:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/murano/commit/0daf51aa368ac19070418d9a4455c55188da6bce', 'message': 'Do not store session db in tmp directory\n\nThis commit prevents situation, when after machine reboot manage.py syncdb is needed\nto recreate a database.\n\nThe db location changed to murano /opt/stack/murano-dashboard in murano devstack script.\nDocumentation also was updated.\n\nChange-Id: I9603c13d5ce170d516acea208c33f92570f04c96\nCloses-Bug: #1464215\n'}, {'number': 5, 'created': '2015-06-24 06:47:16.000000000', 'files': ['doc/source/install/manual.rst', 'contrib/devstack/lib/murano-dashboard'], 'web_link': 'https://opendev.org/openstack/murano/commit/4e3ade1b5b2b1064946c7b57c8c105f39ab2354c', 'message': 'Do not store session db in tmp directory\n\nThis commit prevents situation, when after machine reboot manage.py syncdb is needed\nto recreate a database.\n\nThe db location changed to murano /opt/stack/murano-dashboard in murano devstack script.\nDocumentation also was updated.\n\nChange-Id: I9603c13d5ce170d516acea208c33f92570f04c96\nCloses-Bug: #1464215\n'}]",2,191757,4e3ade1b5b2b1064946c7b57c8c105f39ab2354c,41,9,5,7549,,,0,"Do not store session db in tmp directory

This commit prevents situation, when after machine reboot manage.py syncdb is needed
to recreate a database.

The db location changed to murano /opt/stack/murano-dashboard in murano devstack script.
Documentation also was updated.

Change-Id: I9603c13d5ce170d516acea208c33f92570f04c96
Closes-Bug: #1464215
",git fetch https://review.opendev.org/openstack/murano refs/changes/57/191757/3 && git format-patch -1 --stdout FETCH_HEAD,"['doc/source/install/manual.rst', 'contrib/devstack/lib/murano-dashboard']",2,04e5f20b1a325458f952dbcf736974458ced9278,bug/1464215,"HOME=$HOME 'NAME': os.path.join(HOME, 'openstack-dashboard.sqlite')"," 'NAME': os.path.join(METADATA_CACHE_DIR, 'openstack-dashboard.sqlite')",3,2
openstack%2Foslo-incubator~master~I82dcb11ed962956976bf8f6ecf0248b9895da0d3,openstack/oslo-incubator,master,I82dcb11ed962956976bf8f6ecf0248b9895da0d3,Updated from global requirements,MERGED,2015-06-22 19:59:33.000000000,2015-06-24 17:05:27.000000000,2015-06-24 17:05:25.000000000,"[{'_account_id': 3}, {'_account_id': 5638}]","[{'number': 1, 'created': '2015-06-22 19:59:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo-incubator/commit/66c386fbb6ae2dd6c200ff8422289781863612ee', 'message': 'Updated from global requirements\n\nChange-Id: I82dcb11ed962956976bf8f6ecf0248b9895da0d3\n'}, {'number': 2, 'created': '2015-06-24 14:45:26.000000000', 'files': ['requirements.txt'], 'web_link': 'https://opendev.org/openstack/oslo-incubator/commit/2e41adeb4c19114fd3504eb69891e9149dba7072', 'message': 'Updated from global requirements\n\nChange-Id: I82dcb11ed962956976bf8f6ecf0248b9895da0d3\n'}]",0,194326,2e41adeb4c19114fd3504eb69891e9149dba7072,9,2,2,11131,,,0,"Updated from global requirements

Change-Id: I82dcb11ed962956976bf8f6ecf0248b9895da0d3
",git fetch https://review.opendev.org/openstack/oslo-incubator refs/changes/26/194326/2 && git format-patch -1 --stdout FETCH_HEAD,['requirements.txt'],1,66c386fbb6ae2dd6c200ff8422289781863612ee,openstack/requirements,eventlet>=0.17.4,eventlet>=0.17.3,1,1
openstack%2Fgrenade~master~I8b0ad682203f77f68a03b9b7f56624df6d15ac50,openstack/grenade,master,I8b0ad682203f77f68a03b9b7f56624df6d15ac50,Source target functions before calling build_wheels,MERGED,2015-05-13 03:16:47.000000000,2015-06-24 17:02:50.000000000,2015-06-24 17:02:47.000000000,"[{'_account_id': 3}, {'_account_id': 1849}, {'_account_id': 2750}, {'_account_id': 6873}]","[{'number': 1, 'created': '2015-05-13 03:16:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/grenade/commit/942e38a05ab0c8bccf55910ec5372219c9b54b74', 'message': 'Source target functions before calling build_wheels\n\nOtherwise we get the error:\n  build_wheels.sh: line 61: pip_install: command not found\n\nSince the grenade functions do not have pip_install\n\nChange-Id: I8b0ad682203f77f68a03b9b7f56624df6d15ac50\n'}, {'number': 2, 'created': '2015-05-13 18:29:56.000000000', 'files': ['prep-target'], 'web_link': 'https://opendev.org/openstack/grenade/commit/2f0fd969ff6b6aae654fc038695f8736f7b877a6', 'message': 'Source target functions before calling build_wheels\n\nOtherwise we get the error:\n  build_wheels.sh: line 61: pip_install: command not found\n\nSince the grenade functions do not have pip_install\n\nChange-Id: I8b0ad682203f77f68a03b9b7f56624df6d15ac50\n'}]",0,182526,2f0fd969ff6b6aae654fc038695f8736f7b877a6,16,4,2,1849,,,0,"Source target functions before calling build_wheels

Otherwise we get the error:
  build_wheels.sh: line 61: pip_install: command not found

Since the grenade functions do not have pip_install

Change-Id: I8b0ad682203f77f68a03b9b7f56624df6d15ac50
",git fetch https://review.opendev.org/openstack/grenade refs/changes/26/182526/1 && git format-patch -1 --stdout FETCH_HEAD,['prep-target'],1,942e38a05ab0c8bccf55910ec5372219c9b54b74,wheel,# Get target config source $TARGET_DEVSTACK_DIR/functions source $TARGET_DEVSTACK_DIR/stackrc ,# Get target config source $TARGET_DEVSTACK_DIR/functions source $TARGET_DEVSTACK_DIR/stackrc ,4,4
openstack%2Fdebtcollector~master~I76cc9a6a9f46e218c98b7657404c55d526ed15c0,openstack/debtcollector,master,I76cc9a6a9f46e218c98b7657404c55d526ed15c0,Fix quoting of examples,MERGED,2015-06-24 06:06:54.000000000,2015-06-24 17:02:45.000000000,2015-06-24 17:02:43.000000000,"[{'_account_id': 3}, {'_account_id': 1297}, {'_account_id': 1669}]","[{'number': 1, 'created': '2015-06-24 06:06:54.000000000', 'files': ['doc/source/examples.rst'], 'web_link': 'https://opendev.org/openstack/debtcollector/commit/fc4f2854803e7707c48ceac51594d52c75f04370', 'message': 'Fix quoting of examples\n\nThe removal output was updated to be in quotes, so the examples\nshould reflect this.\n\nChange-Id: I76cc9a6a9f46e218c98b7657404c55d526ed15c0\n'}]",0,194950,fc4f2854803e7707c48ceac51594d52c75f04370,10,3,1,1297,,,0,"Fix quoting of examples

The removal output was updated to be in quotes, so the examples
should reflect this.

Change-Id: I76cc9a6a9f46e218c98b7657404c55d526ed15c0
",git fetch https://review.opendev.org/openstack/debtcollector refs/changes/50/194950/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/source/examples.rst'],1,fc4f2854803e7707c48ceac51594d52c75f04370,, __main__:1: DeprecationWarning: Using function/method 'Car.start()' is deprecated __main__:1: DeprecationWarning: Using class 'Pinto' is deprecated, __main__:1: DeprecationWarning: Using function/method Car.start is deprecated __main__:1: DeprecationWarning: Using class Pinto is deprecated,2,2
openstack%2Ftripleo-image-elements~master~Ic62b6303795f70f3b9ace46731a21d1c0e7fe6c7,openstack/tripleo-image-elements,master,Ic62b6303795f70f3b9ace46731a21d1c0e7fe6c7,Return derived config id when signalling deployments,MERGED,2015-06-10 17:56:11.000000000,2015-06-24 17:01:07.000000000,2015-06-24 17:01:05.000000000,"[{'_account_id': 3}, {'_account_id': 360}, {'_account_id': 4328}, {'_account_id': 4571}, {'_account_id': 6796}, {'_account_id': 8399}]","[{'number': 1, 'created': '2015-06-10 17:56:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-image-elements/commit/dc4dba9924bd8938ff0ff0903b760379ff3eebeb', 'message': 'Add orc-hiera-datafiles signalling\n\nCurrently signalling via 99-refresh-completed only uses the legacy\ncurl data payload (e.g that for CFN compatible WaitConditions),\nbut now we\'re using it exclusively for signalling SoftwareDeployment\nresources, which support a different payload, including deploy_stdout\nwhich is accessible via a resource attribute.\n\nSo add support a new orc-hiera-datafiles group, which calculates\na hash of the hieradata files and sends it back as part of the\ndeploy_stdout.  Also send a better stdout than ""null"" for the existing\nos-apply-config deployment group.\n\nThis means we can derive a hash of the hieradata files deployed via e.g:\n\nget_attr: [ControllerDeployment, deploy_stdout]\n\nPartial-Bug: #1463092\nChange-Id: Ic62b6303795f70f3b9ace46731a21d1c0e7fe6c7\n'}, {'number': 2, 'created': '2015-06-11 12:14:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-image-elements/commit/7a03b9fa7ad789874c63cdbfe2eed7217163a247', 'message': ""Return derived config id when signalling deployments\n\nCurrently signalling via 99-refresh-completed only uses the legacy\ncurl data payload (e.g that for CFN compatible WaitConditions),\nbut now we're using it exclusively for signalling SoftwareDeployment\nresources, which support a different payload, including deploy_stdout\nwhich is accessible via a resource attribute.\n\nReturning a payload for deploy_stdout containing the derived config ID\nis potentially useful as it changes whenever the SoftwareConfig or any\ninputs change, thus can be used as a unique identifier for dependent\nresources which need to be re-triggered when some config is reapplied,\nfor example puppet manifests with a dependency on hieradata applied\nvia a SoftwareDeployment.\n\nget_attr: [ControllerDeployment, deploy_stdout]\n\nPartial-Bug: #1463092\nChange-Id: Ic62b6303795f70f3b9ace46731a21d1c0e7fe6c7\n""}, {'number': 3, 'created': '2015-06-16 14:06:51.000000000', 'files': ['elements/os-refresh-config/os-refresh-config/post-configure.d/99-refresh-completed'], 'web_link': 'https://opendev.org/openstack/tripleo-image-elements/commit/e6b9609473a4852b5b3af21c10b2ff3ad885715a', 'message': ""Return derived config id when signalling deployments\n\nCurrently signalling via 99-refresh-completed only uses the legacy\ncurl data payload (e.g that for CFN compatible WaitConditions),\nbut now we're using it exclusively for signalling SoftwareDeployment\nresources, which support a different payload, including deploy_stdout\nwhich is accessible via a resource attribute.\n\nReturning a payload for deploy_stdout containing the derived config ID\nis potentially useful as it changes whenever the SoftwareConfig or any\ninputs change, thus can be used as a unique identifier for dependent\nresources which need to be re-triggered when some config is reapplied,\nfor example puppet manifests with a dependency on hieradata applied\nvia a SoftwareDeployment.\n\nget_attr: [ControllerDeployment, deploy_stdout]\n\nPartial-Bug: #1463092\nChange-Id: Ic62b6303795f70f3b9ace46731a21d1c0e7fe6c7\n""}]",1,190282,e6b9609473a4852b5b3af21c10b2ff3ad885715a,32,6,3,4328,,,0,"Return derived config id when signalling deployments

Currently signalling via 99-refresh-completed only uses the legacy
curl data payload (e.g that for CFN compatible WaitConditions),
but now we're using it exclusively for signalling SoftwareDeployment
resources, which support a different payload, including deploy_stdout
which is accessible via a resource attribute.

Returning a payload for deploy_stdout containing the derived config ID
is potentially useful as it changes whenever the SoftwareConfig or any
inputs change, thus can be used as a unique identifier for dependent
resources which need to be re-triggered when some config is reapplied,
for example puppet manifests with a dependency on hieradata applied
via a SoftwareDeployment.

get_attr: [ControllerDeployment, deploy_stdout]

Partial-Bug: #1463092
Change-Id: Ic62b6303795f70f3b9ace46731a21d1c0e7fe6c7
",git fetch https://review.opendev.org/openstack/tripleo-image-elements refs/changes/82/190282/3 && git format-patch -1 --stdout FETCH_HEAD,['elements/os-refresh-config/os-refresh-config/post-configure.d/99-refresh-completed'],1,dc4dba9924bd8938ff0ff0903b760379ff3eebeb,bug/1463092,"call_curl_deployment() { local method=$1 local url=$2 local stdout=$3 local output=$(mktemp) status=$(curl -s -w %{http_code} -X $method -H 'Content-Type:' -o $output --data-binary ""{\""deploy_stdout\"": \""$stdout\"", \""deploy_status_code\"": \""0\""}"" $url) cat $output rm $output if [ ""$status"" != ""200"" ]; then exit 1 fi } echo ""Signalling os-apply-config deploy_signal_handle=$url"" call_curl_deployment POST $url ""os-apply-config deployment completed"" done # This extracts ""deploy_signal_id"" from any deployments of group ""orc-hiera-datafiles"" # This calculates the hash of the hieradata and includes it in the stdout returned to # heat, so it's accessible via the SoftwareDeployment resource deploy_stdout attribute DEPLOYMENT_HANDLES=$(os-apply-config --key deployments --type raw --key-default """" | \ jq -r ""map(select(.group == \""orc-hiera-datafiles\"") | .inputs | \ map(select(.name == \""deploy_signal_id\""))) | .[][].value"") for url in ${DEPLOYMENT_HANDLES} do echo ""Signalling orc-hiera-datafiles deploy_signal_handle=$url"" HIERA_HASH=$(cat /etc/puppet/hieradata/* | sha256sum | awk '{print $1}') call_curl_deployment POST $url ""orc-hiera-datafiles deployment completed $HIERA_HASH"""," echo ""Signalling deploy_signal_handle=$url"" call_curl POST $url",28,2
openstack%2Ftripleo-heat-templates~master~I1175248c3236d0c42e37d062afce550efce8aadc,openstack/tripleo-heat-templates,master,I1175248c3236d0c42e37d062afce550efce8aadc,Make puppet-applying *Post resources depend on hieradata,MERGED,2015-06-12 16:39:34.000000000,2015-06-24 17:00:18.000000000,2015-06-24 17:00:17.000000000,"[{'_account_id': 3}, {'_account_id': 360}, {'_account_id': 4328}, {'_account_id': 4571}, {'_account_id': 6796}, {'_account_id': 8399}]","[{'number': 1, 'created': '2015-06-12 16:39:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/d25d5d646d8509e0108cc6d8000843252fab1363', 'message': 'Make puppet-applying *Post resources depend on hieradata\n\nWhen you do a stack-update which affects, e.g ControllerDeployment\nsuch that some value in hieradata is updated (for example changing\nthe ""Debug"" parameter to True), we only write the hieradata file and\ndon\'t reapply the manifests.\n\nSo we introduce a dependency on the deploy_stdout values from all\nhieradata applying configs, such that the manifests will be re-applied\non update if the data is changed.\n\nThis requires https://review.openstack.org/#/c/190282/ so that\n99-refresh-completed will return the derived config ID as part of the\ndeploy_stdout payload.\n\nCloses-Bug: #1463092\nChange-Id: I1175248c3236d0c42e37d062afce550efce8aadc\n'}, {'number': 2, 'created': '2015-06-12 16:48:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/6e6e84ff2c8c6fbafa6d75b0540ec5a894336989', 'message': 'Make puppet-applying *Post resources depend on hieradata\n\nWhen you do a stack-update which affects, e.g ControllerDeployment\nsuch that some value in hieradata is updated (for example changing\nthe ""Debug"" parameter to True), we only write the hieradata file and\ndon\'t reapply the manifests.\n\nSo we introduce a dependency on the deploy_stdout values from all\nhieradata applying configs, such that the manifests will be re-applied\non update if the data is changed.\n\nThis requires https://review.openstack.org/#/c/190282/ so that\n99-refresh-completed will return the derived config ID as part of the\ndeploy_stdout payload.\n\nCloses-Bug: #1463092\nChange-Id: I1175248c3236d0c42e37d062afce550efce8aadc\n'}, {'number': 3, 'created': '2015-06-16 08:12:46.000000000', 'files': ['swift-storage.yaml', 'cinder-storage.yaml', 'compute-post.yaml', 'controller.yaml', 'ceph-storage.yaml', 'puppet/swift-storage-post.yaml', 'swift-storage-post.yaml', 'ceph-storage-post.yaml', 'puppet/controller-post-puppet.yaml', 'overcloud-without-mergepy.yaml', 'puppet/ceph-storage-puppet.yaml', 'controller-post.yaml', 'puppet/ceph-storage-post-puppet.yaml', 'cinder-storage-post.yaml', 'compute.yaml', 'puppet/cinder-storage-puppet.yaml', 'puppet/compute-post-puppet.yaml', 'puppet/swift-storage-puppet.yaml', 'puppet/compute-puppet.yaml', 'puppet/controller-puppet.yaml', 'puppet/cinder-storage-post.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/ec3137dc6ec6ff4871125ac2802aefe3c2089805', 'message': 'Make puppet-applying *Post resources depend on hieradata\n\nWhen you do a stack-update which affects, e.g ControllerDeployment\nsuch that some value in hieradata is updated (for example changing\nthe ""Debug"" parameter to True), we only write the hieradata file and\ndon\'t reapply the manifests.\n\nSo we introduce a dependency on the deploy_stdout values from all\nhieradata applying configs, such that the manifests will be re-applied\non update if the data is changed.\n\nThis requires https://review.openstack.org/#/c/190282/ so that\n99-refresh-completed will return the derived config ID as part of the\ndeploy_stdout payload.\n\nCloses-Bug: #1463092\nChange-Id: I1175248c3236d0c42e37d062afce550efce8aadc\n'}]",0,191146,ec3137dc6ec6ff4871125ac2802aefe3c2089805,20,6,3,4328,,,0,"Make puppet-applying *Post resources depend on hieradata

When you do a stack-update which affects, e.g ControllerDeployment
such that some value in hieradata is updated (for example changing
the ""Debug"" parameter to True), we only write the hieradata file and
don't reapply the manifests.

So we introduce a dependency on the deploy_stdout values from all
hieradata applying configs, such that the manifests will be re-applied
on update if the data is changed.

This requires https://review.openstack.org/#/c/190282/ so that
99-refresh-completed will return the derived config ID as part of the
deploy_stdout payload.

Closes-Bug: #1463092
Change-Id: I1175248c3236d0c42e37d062afce550efce8aadc
",git fetch https://review.opendev.org/openstack/tripleo-heat-templates refs/changes/46/191146/3 && git format-patch -1 --stdout FETCH_HEAD,"['overcloud-without-mergepy.yaml', 'puppet/ceph-storage-puppet.yaml', 'puppet/ceph-storage-post-puppet.yaml', 'puppet/cinder-storage-puppet.yaml', 'puppet/compute-post-puppet.yaml', 'puppet/swift-storage-post.yaml', 'puppet/swift-storage-puppet.yaml', 'puppet/compute-puppet.yaml', 'puppet/controller-puppet.yaml', 'puppet/cinder-storage-post.yaml', 'puppet/controller-post-puppet.yaml']",11,d25d5d646d8509e0108cc6d8000843252fab1363,bug/1463092, NodeConfigIdentifiers: type: json description: Value which changes if the node configuration may need to be re-applied update_identifier: {get_param: NodeConfigIdentifiers} update_identifier: {get_param: NodeConfigIdentifiers} input_values: update_identifier: {get_param: NodeConfigIdentifiers} update_identifier: {get_param: NodeConfigIdentifiers} update_identifier: {get_param: NodeConfigIdentifiers},,57,0
openstack%2Fproject-config~master~If839729efdb0537f685b9686497582e85fefd6ab,openstack/project-config,master,If839729efdb0537f685b9686497582e85fefd6ab,Make lbaas API test jobs voting again,MERGED,2015-06-24 01:55:40.000000000,2015-06-24 16:55:03.000000000,2015-06-24 16:55:01.000000000,"[{'_account_id': 3}, {'_account_id': 105}, {'_account_id': 6316}, {'_account_id': 6547}]","[{'number': 1, 'created': '2015-06-24 01:55:40.000000000', 'files': ['zuul/layout.yaml'], 'web_link': 'https://opendev.org/openstack/project-config/commit/9214e6816b229b8e882ed1cd2f42d4f41c2a21f7', 'message': 'Make lbaas API test jobs voting again\n\nThe lbaas api job was made non-voting because it was testing the wrong\nneutron, which has been fixed. Both jobs have been running experimental and\nthen check queue stably, and tested that they are testing the expected repo:\n\nhttps://review.openstack.org/#/c/188166/\n\nChange-Id: If839729efdb0537f685b9686497582e85fefd6ab\n'}]",0,194908,9214e6816b229b8e882ed1cd2f42d4f41c2a21f7,8,4,1,10980,,,0,"Make lbaas API test jobs voting again

The lbaas api job was made non-voting because it was testing the wrong
neutron, which has been fixed. Both jobs have been running experimental and
then check queue stably, and tested that they are testing the expected repo:

https://review.openstack.org/#/c/188166/

Change-Id: If839729efdb0537f685b9686497582e85fefd6ab
",git fetch https://review.opendev.org/openstack/project-config refs/changes/08/194908/1 && git format-patch -1 --stdout FETCH_HEAD,['zuul/layout.yaml'],1,9214e6816b229b8e882ed1cd2f42d4f41c2a21f7,, - gate-neutron-lbaasv1-dsvm-api - gate-neutron-lbaasv2-dsvm-api gate: - gate-neutron-lbaasv1-dsvm-api - gate-neutron-lbaasv2-dsvm-api, - name: ^(check|gate)-neutron-lbaasv1-dsvm-api$ voting: false voting: false,5,4
openstack%2Fdragonflow~master~I86afceea09bbc8dfe297453a51fc3bc8067ded13,openstack/dragonflow,master,I86afceea09bbc8dfe297453a51fc3bc8067ded13,legacy router port offloaded to the NORMAL path,MERGED,2015-06-22 10:10:53.000000000,2015-06-24 16:52:18.000000000,2015-06-24 16:52:17.000000000,"[{'_account_id': 3}, {'_account_id': 2023}, {'_account_id': 11343}, {'_account_id': 14249}]","[{'number': 1, 'created': '2015-06-22 10:10:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/dragonflow/commit/a214701e7f50e26b54c1d7f3cb539bf2bf0b26e4', 'message': 'The legacy router port should not go into our pipeline it should be\noffloaded to the NORMAL path.\nUntil now In one machine devstack install the legacy router port was\ninjected into the dragonflow pipeline.\n\nChange-Id: I86afceea09bbc8dfe297453a51fc3bc8067ded13\n'}, {'number': 2, 'created': '2015-06-24 15:27:40.000000000', 'files': ['dragonflow/controller/l3_openflow_app.py'], 'web_link': 'https://opendev.org/openstack/dragonflow/commit/0e003a7e8f55e5e97b5b3aa648be673e9f732742', 'message': 'legacy router port offloaded to the NORMAL path\n\nThe legacy router port should not go into our\npipeline it should be offloaded to the NORMAL path.\nUntil now In one machine devstack install the legacy\nrouter port was injected into the dragonflow pipeline.\n\nChange-Id: I86afceea09bbc8dfe297453a51fc3bc8067ded13\n'}]",1,194069,0e003a7e8f55e5e97b5b3aa648be673e9f732742,13,4,2,13070,,,0,"legacy router port offloaded to the NORMAL path

The legacy router port should not go into our
pipeline it should be offloaded to the NORMAL path.
Until now In one machine devstack install the legacy
router port was injected into the dragonflow pipeline.

Change-Id: I86afceea09bbc8dfe297453a51fc3bc8067ded13
",git fetch https://review.opendev.org/openstack/dragonflow refs/changes/69/194069/1 && git format-patch -1 --stdout FETCH_HEAD,['dragonflow/controller/l3_openflow_app.py'],1,a214701e7f50e26b54c1d7f3cb539bf2bf0b26e4,qr_port_handle," elif port.name.startswith('qr'): LOG.debug((""Found Legacy Router port %s using MAC %s"" ""One machine setup""), port.name, port.hw_addr) self.add_flow_normal_by_port_num( datapath, 0, HIGH_PRIORITY_FLOW, port.port_no) elif port.name.startswith('qvo'):", elif port.name.startswith('qvo') or port.name.startswith('qr'):,8,1
openstack%2Fhorizon~stable%2Ficehouse~Ib63c6a0e7bb5661d4a60d10a1722fdad978b50bb,openstack/horizon,stable/icehouse,Ib63c6a0e7bb5661d4a60d10a1722fdad978b50bb,Disable Floating IP features if Neutron router is disabled,ABANDONED,2015-06-08 21:17:06.000000000,2015-06-24 16:51:24.000000000,,"[{'_account_id': 3}, {'_account_id': 841}, {'_account_id': 1941}, {'_account_id': 1955}]","[{'number': 1, 'created': '2015-06-08 21:17:06.000000000', 'files': ['openstack_dashboard/dashboards/project/access_and_security/floating_ips/tests.py', 'openstack_dashboard/api/neutron.py', 'openstack_dashboard/dashboards/admin/overview/tests.py', 'openstack_dashboard/dashboards/project/access_and_security/tabs.py', 'openstack_dashboard/dashboards/project/instances/tests.py', 'openstack_dashboard/dashboards/project/instances/tables.py', 'openstack_dashboard/dashboards/project/overview/tests.py', 'openstack_dashboard/dashboards/admin/projects/tests.py', 'openstack_dashboard/usage/base.py', 'openstack_dashboard/api/network_base.py', 'openstack_dashboard/dashboards/project/access_and_security/keypairs/tests.py', 'openstack_dashboard/dashboards/project/access_and_security/tests.py', 'openstack_dashboard/test/api_tests/network_tests.py', 'openstack_dashboard/test/tests/quotas.py', 'openstack_dashboard/api/network.py', 'openstack_dashboard/usage/quotas.py', 'openstack_dashboard/api/nova.py'], 'web_link': 'https://opendev.org/openstack/horizon/commit/84735c909179057278590c36b88db1745cf2dd70', 'message': ""Disable Floating IP features if Neutron router is disabled\n\nIf the config option 'enable_router' is set to False,\nFloating IP features are disabled when Neutron is enabled.\nIt does not affect when Neutron is disabled.\n\nIt also adds unit tests for api.network.servers_update_addresses\nwhich is affected by this change.\n\nCompletes blueprint hide-router-panel-by-config\nCloses-Bug: #1292022\n\nConflicts:\n\tdoc/source/topics/settings.rst\n\topenstack_dashboard/api/neutron.py\n\topenstack_dashboard/dashboards/project/access_and_security/tests.py\n\topenstack_dashboard/dashboards/project/instances/tests.py\n\topenstack_dashboard/dashboards/project/overview/tests.py\n\topenstack_dashboard/usage/base.py\n\topenstack_dashboard/usage/quotas.py\n\nChange-Id: Ib63c6a0e7bb5661d4a60d10a1722fdad978b50bb\n""}]",0,189459,84735c909179057278590c36b88db1745cf2dd70,7,4,1,7400,,,0,"Disable Floating IP features if Neutron router is disabled

If the config option 'enable_router' is set to False,
Floating IP features are disabled when Neutron is enabled.
It does not affect when Neutron is disabled.

It also adds unit tests for api.network.servers_update_addresses
which is affected by this change.

Completes blueprint hide-router-panel-by-config
Closes-Bug: #1292022

Conflicts:
	doc/source/topics/settings.rst
	openstack_dashboard/api/neutron.py
	openstack_dashboard/dashboards/project/access_and_security/tests.py
	openstack_dashboard/dashboards/project/instances/tests.py
	openstack_dashboard/dashboards/project/overview/tests.py
	openstack_dashboard/usage/base.py
	openstack_dashboard/usage/quotas.py

Change-Id: Ib63c6a0e7bb5661d4a60d10a1722fdad978b50bb
",git fetch https://review.opendev.org/openstack/horizon refs/changes/59/189459/1 && git format-patch -1 --stdout FETCH_HEAD,"['openstack_dashboard/dashboards/project/access_and_security/floating_ips/tests.py', 'openstack_dashboard/api/neutron.py', 'openstack_dashboard/dashboards/admin/overview/tests.py', 'openstack_dashboard/dashboards/project/access_and_security/tabs.py', 'openstack_dashboard/dashboards/project/instances/tests.py', 'openstack_dashboard/dashboards/project/instances/tables.py', 'openstack_dashboard/dashboards/project/overview/tests.py', 'openstack_dashboard/dashboards/admin/projects/tests.py', 'openstack_dashboard/usage/base.py', 'openstack_dashboard/api/network_base.py', 'openstack_dashboard/dashboards/project/access_and_security/keypairs/tests.py', 'openstack_dashboard/dashboards/project/access_and_security/tests.py', 'openstack_dashboard/test/api_tests/network_tests.py', 'openstack_dashboard/test/tests/quotas.py', 'openstack_dashboard/api/network.py', 'openstack_dashboard/usage/quotas.py', 'openstack_dashboard/api/nova.py']",17,84735c909179057278590c36b88db1745cf2dd70,bug/1292022, def is_supported(self): return True ,,470,106
openstack%2Foslo.db~master~Ibd4f454183c2bd3465539c3e572fa23208975bdb,openstack/oslo.db,master,Ibd4f454183c2bd3465539c3e572fa23208975bdb,Add a new ModelBase.items() method,MERGED,2015-06-24 14:19:55.000000000,2015-06-24 16:49:25.000000000,2015-06-24 16:49:23.000000000,"[{'_account_id': 3}, {'_account_id': 5638}, {'_account_id': 6849}, {'_account_id': 7491}, {'_account_id': 9107}]","[{'number': 1, 'created': '2015-06-24 14:19:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.db/commit/e5ed75128b44b960f56f37b8230c1e4bfdad5f57', 'message': 'Add a new ModelBase.items() method\n\nThe ModelBase.iteritems() method now returns an iterator instead of a\nlist.\n\nChange-Id: Ibd4f454183c2bd3465539c3e572fa23208975bdb\n'}, {'number': 2, 'created': '2015-06-24 14:35:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.db/commit/631df388ec04b2f03e71897312a4d092bb11b59e', 'message': ""Add a new ModelBase.items() method\n\nThis change is required to port applications using oslo.db to Python 3.\nThe iteritems() method of Python 2 dictionaries was removed in Python 3\n(renamed to items()). Currently, it's not possible to replace\nobj.iteritems() with six.iteritems(obj) or obj.items() for oslo.db\nobjects.\n\nNova has a function calling obj.iteritems(), the function gets oslo.db\nobjects and dictionaries. On Python 3, dictionaries have no iteritems()\nmethod, whereas oslo.db objects have no items() method. This change\nallows to write obj.items() which works on Python 2 and Python 3, on\ndictionaries and oslo.db objects.\n\nOn Python 3, the ModelBase.iteritems() method now returns an iterator\ninstead of a list. The behaviour on Python 2 is unchanged to not break\nbackward compatibility.\n\nChange-Id: Ibd4f454183c2bd3465539c3e572fa23208975bdb\n""}, {'number': 3, 'created': '2015-06-24 15:16:20.000000000', 'files': ['oslo_db/tests/sqlalchemy/test_models.py', 'oslo_db/sqlalchemy/models.py'], 'web_link': 'https://opendev.org/openstack/oslo.db/commit/9c646eaf5a835f68247c64e6d1899912004a4dd7', 'message': ""Add a new ModelBase.items() method\n\nThis change is required to port applications using oslo.db to Python 3.\nThe iteritems() method of Python 2 dictionaries was removed in Python 3\n(renamed to items()). Currently, it's not possible to replace\nobj.iteritems() with six.iteritems(obj) or obj.items() for oslo.db\nobjects.\n\nNova has a function calling obj.iteritems(), the function gets oslo.db\nobjects and dictionaries. On Python 3, dictionaries have no iteritems()\nmethod, whereas oslo.db objects have no items() method. This change\nallows to write obj.items() which works on Python 2 and Python 3, on\ndictionaries and oslo.db objects.\n\nChange-Id: Ibd4f454183c2bd3465539c3e572fa23208975bdb\n""}]",0,195099,9c646eaf5a835f68247c64e6d1899912004a4dd7,11,5,3,9107,,,0,"Add a new ModelBase.items() method

This change is required to port applications using oslo.db to Python 3.
The iteritems() method of Python 2 dictionaries was removed in Python 3
(renamed to items()). Currently, it's not possible to replace
obj.iteritems() with six.iteritems(obj) or obj.items() for oslo.db
objects.

Nova has a function calling obj.iteritems(), the function gets oslo.db
objects and dictionaries. On Python 3, dictionaries have no iteritems()
method, whereas oslo.db objects have no items() method. This change
allows to write obj.items() which works on Python 2 and Python 3, on
dictionaries and oslo.db objects.

Change-Id: Ibd4f454183c2bd3465539c3e572fa23208975bdb
",git fetch https://review.opendev.org/openstack/oslo.db refs/changes/99/195099/2 && git format-patch -1 --stdout FETCH_HEAD,"['oslo_db/tests/sqlalchemy/test_models.py', 'oslo_db/sqlalchemy/models.py']",2,e5ed75128b44b960f56f37b8230c1e4bfdad5f57,items," def _as_dict(self): return local def iteritems(self): """"""Make the model object behave like a dict."""""" return six.iteritems(self._as_dict()) def items(self): """"""Make the model object behave like a dict."""""" return self._as_dict().items()", def iteritems(self): return six.iteritems(local),13,3
openstack%2Fnova~master~I8cf5483982085da57ee470fa2753b0d0aebc12b3,openstack/nova,master,I8cf5483982085da57ee470fa2753b0d0aebc12b3,Reduce window for allocate_fixed_ip / release_fixed_ip race in nova-net,MERGED,2015-06-23 20:58:24.000000000,2015-06-24 16:47:00.000000000,2015-06-24 16:38:16.000000000,"[{'_account_id': 3}, {'_account_id': 2750}, {'_account_id': 4393}, {'_account_id': 5170}, {'_account_id': 6873}, {'_account_id': 9578}, {'_account_id': 10118}, {'_account_id': 10385}, {'_account_id': 11803}, {'_account_id': 15286}, {'_account_id': 16839}, {'_account_id': 16897}]","[{'number': 1, 'created': '2015-06-23 20:58:24.000000000', 'files': ['nova/network/manager.py', 'nova/tests/unit/db/test_db_api.py', 'nova/tests/unit/network/test_manager.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/3736c120cbeacbc4349efbda99e279cddfb5f09e', 'message': ""Reduce window for allocate_fixed_ip / release_fixed_ip race in nova-net\n\nThere is a race during allocate_fixed_ip where a new instance, B, is\nassociated with a fixed IP, X, which was previously associated with\ninstance A that is being deallocated.\n\nBetween the time that instance A is associated with fixed IP X and the\ntime that it's VIF is allocated, and fip.allocated = True in the DB, the\ndhcpagent callback hits release_fixed_ip for the fixed IP X from when\ninstance A was deallocating.\n\nrelease_fixed_ip checks to see if the instance is allocated and if not\nit disassociates the instance, which was associated with new instance B.\n\nThis leads to get_instance_nw_info() not building anything since there\nare no fixed IPs associated with instance A in the database, so\neventually anything needing to do networking with instance A, like\nassocating a floating IP, fails.\n\nTo narrow the race, we do the VIF allocation before associating the\nfixed IP to the new instance. This does not completely fix the bug, but\nit's a tactical change that we can backport to stable branches while\nworking on the longer-term fix which is going to involve network RPC API\nchanges to release_fixed_ip().\n\nNote that test_vpn_allocate_fixed_ip_no_network_id is removed since it\nno longer works and arguably was testing the DB API in the wrong place,\nso a new test is added to test_db_api for the same coverage.\n\nPartial-Bug: #1249065\n\nChange-Id: I8cf5483982085da57ee470fa2753b0d0aebc12b3\n""}]",0,194815,3736c120cbeacbc4349efbda99e279cddfb5f09e,24,12,1,6873,,,0,"Reduce window for allocate_fixed_ip / release_fixed_ip race in nova-net

There is a race during allocate_fixed_ip where a new instance, B, is
associated with a fixed IP, X, which was previously associated with
instance A that is being deallocated.

Between the time that instance A is associated with fixed IP X and the
time that it's VIF is allocated, and fip.allocated = True in the DB, the
dhcpagent callback hits release_fixed_ip for the fixed IP X from when
instance A was deallocating.

release_fixed_ip checks to see if the instance is allocated and if not
it disassociates the instance, which was associated with new instance B.

This leads to get_instance_nw_info() not building anything since there
are no fixed IPs associated with instance A in the database, so
eventually anything needing to do networking with instance A, like
assocating a floating IP, fails.

To narrow the race, we do the VIF allocation before associating the
fixed IP to the new instance. This does not completely fix the bug, but
it's a tactical change that we can backport to stable branches while
working on the longer-term fix which is going to involve network RPC API
changes to release_fixed_ip().

Note that test_vpn_allocate_fixed_ip_no_network_id is removed since it
no longer works and arguably was testing the DB API in the wrong place,
so a new test is added to test_db_api for the same coverage.

Partial-Bug: #1249065

Change-Id: I8cf5483982085da57ee470fa2753b0d0aebc12b3
",git fetch https://review.opendev.org/openstack/nova refs/changes/15/194815/1 && git format-patch -1 --stdout FETCH_HEAD,"['nova/network/manager.py', 'nova/tests/unit/db/test_db_api.py', 'nova/tests/unit/network/test_manager.py']",3,3736c120cbeacbc4349efbda99e279cddfb5f09e,bug/1249065," @mock.patch('nova.objects.instance.Instance.get_by_uuid') @mock.patch.object(db, 'virtual_interface_get_by_instance_and_network', return_value=None) @mock.patch('nova.objects.fixed_ip.FixedIP') def test_allocate_fixed_ip_add_vif_fails(self, mock_fixedip, mock_get_vif, mock_instance_get): # Tests that we don't try to do anything with fixed IPs if # _add_virtual_interface fails. instance = fake_instance.fake_instance_obj(self.context) mock_instance_get.return_value = instance network = {'cidr': '24', 'id': 1, 'uuid': '398399b3-f696-4859-8695-a6560e14cb02'} vif_error = exception.VirtualInterfaceMacAddressException() # mock out quotas because we don't care in this test with mock.patch.object(self.network, 'quotas_cls', objects.QuotasNoOp): with mock.patch.object(self.network, '_add_virtual_interface', side_effect=vif_error): self.assertRaises( exception.VirtualInterfaceMacAddressException, self.network.allocate_fixed_ip, self.context, '9d2ee1e3-ffad-4e5f-81ff-c96dd97b0ee0', network) self.assertFalse(mock_fixedip.called, str(mock_fixedip.mock_calls)) @mock.patch.object(db, 'virtual_interface_get_by_instance_and_network', return_value=None) @mock.patch('nova.objects.fixed_ip.FixedIP') def test_allocate_fixed_ip_add_vif_fails(self, mock_fixedip, mock_get_vif): # Tests that we don't try to do anything with fixed IPs if # _add_virtual_interface fails. vif_error = exception.VirtualInterfaceMacAddressException() with mock.patch.object(self.network, '_add_virtual_interface', side_effect=vif_error): self.assertRaises(exception.VirtualInterfaceMacAddressException, self.network.allocate_fixed_ip, self.context, '9d2ee1e3-ffad-4e5f-81ff-c96dd97b0ee0', networks[0]) self.assertFalse(mock_fixedip.called, str(mock_fixedip.mock_calls)) "," def test_vpn_allocate_fixed_ip_no_network_id(self): network = dict(networks[0]) network['vpn_private_address'] = '192.168.0.2' network['id'] = None instance = db.instance_create(self.context, {}) self.assertRaises(exception.FixedIpNotFoundForNetwork, self.network.allocate_fixed_ip, self.context_admin, instance['uuid'], network, vpn=True) ",85,32
openstack%2Foslo.db~master~I33be8f511059665fd029bd784b974cc54457676a,openstack/oslo.db,master,I33be8f511059665fd029bd784b974cc54457676a,Updated from global requirements,MERGED,2015-06-24 14:45:33.000000000,2015-06-24 16:46:52.000000000,2015-06-24 16:46:51.000000000,"[{'_account_id': 3}, {'_account_id': 7491}]","[{'number': 1, 'created': '2015-06-24 14:45:33.000000000', 'files': ['requirements.txt'], 'web_link': 'https://opendev.org/openstack/oslo.db/commit/28ec7b87072019bc9c9adeecdd1f7a3c16bacb99', 'message': 'Updated from global requirements\n\nChange-Id: I33be8f511059665fd029bd784b974cc54457676a\n'}]",0,195119,28ec7b87072019bc9c9adeecdd1f7a3c16bacb99,7,2,1,11131,,,0,"Updated from global requirements

Change-Id: I33be8f511059665fd029bd784b974cc54457676a
",git fetch https://review.opendev.org/openstack/oslo.db refs/changes/19/195119/1 && git format-patch -1 --stdout FETCH_HEAD,['requirements.txt'],1,28ec7b87072019bc9c9adeecdd1f7a3c16bacb99,openstack/requirements,oslo.context>=0.2.0 # Apache-2.0,oslo.context>=0.2.0 # Apache-2.0,1,1
openstack%2Fastara-appliance~master~I636cd5c37884c5bf9bfe1051716e6c3790ed0165,openstack/astara-appliance,master,I636cd5c37884c5bf9bfe1051716e6c3790ed0165,Add a build script + build_image tox env,MERGED,2015-06-17 22:22:35.000000000,2015-06-24 16:43:50.000000000,2015-06-24 16:43:49.000000000,"[{'_account_id': 3}, {'_account_id': 2592}, {'_account_id': 8005}]","[{'number': 1, 'created': '2015-06-17 22:22:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/astara-appliance/commit/ac45db64ab7f7ac63aaf6c310e505d4a2485e582', 'message': ""Add a build script + build_image tox env\n\nThis adds a little script to call DIB to build an appliance with the\ncurrently checked out code, and adds a tox target to call that.\nThis'll mostly be used by the jenkins bot when doing image builds as\na post build job.\n\nChange-Id: I636cd5c37884c5bf9bfe1051716e6c3790ed0165\n""}, {'number': 2, 'created': '2015-06-17 22:36:37.000000000', 'files': ['tox.ini', 'scripts/build_dib_appliance.sh'], 'web_link': 'https://opendev.org/openstack/astara-appliance/commit/cf844cf55a759cfd1444568854bc89edbc75ea38', 'message': ""Add a build script + build_image tox env\n\nThis adds a little script to call DIB to build an appliance with the\ncurrently checked out code, and adds a tox target to call that.\nThis'll mostly be used by the jenkins bot when doing image builds as\na post build job.\n\nChange-Id: I636cd5c37884c5bf9bfe1051716e6c3790ed0165\n""}]",0,192915,cf844cf55a759cfd1444568854bc89edbc75ea38,8,3,2,1420,,,0,"Add a build script + build_image tox env

This adds a little script to call DIB to build an appliance with the
currently checked out code, and adds a tox target to call that.
This'll mostly be used by the jenkins bot when doing image builds as
a post build job.

Change-Id: I636cd5c37884c5bf9bfe1051716e6c3790ed0165
",git fetch https://review.opendev.org/openstack/astara-appliance refs/changes/15/192915/2 && git format-patch -1 --stdout FETCH_HEAD,"['tox.ini', 'scripts/build_dib_appliance.sh']",2,ac45db64ab7f7ac63aaf6c310e505d4a2485e582,,"#!/bin/bash -xe # Copyright 2015 Akanda, Inc. # # Author: Akanda, Inc. # # Licensed under the Apache License, Version 2.0 (the ""License""); you may # not use this file except in compliance with the License. You may obtain # a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT # WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the # License for the specific language governing permissions and limitations # under the License. # This builds an akanda appliance VM image at $SRC_ROOT/build/akanda.qcow2, # containing the akanda-appliance code as it is currently checked out # in this local repository. SRC_ROOT=""$(dirname $0)/.."" IMG_OUT=$SRC_ROOT/build/akanda AKANDA_DEBIAN_RELEASE=${AKANDA_DEBIAN_RELEASE:-""jessie""} BASE_ELEMENTS=""vm debian akanda"" EXTRA_ELEMENTS=""$@"" GIT_HEAD=""$(cd $SRC_ROOT && git rev-parse HEAD^)"" DIB_REPOLOCATION_akanda=$SRC_ROOT \ DIB_REPOREF_akanda=$GIT_HEAD \ ELEMENTS_PATH=$SRC_ROOT/diskimage-builder/elements \ DIB_RELEASE=$AKANDA_DEBIAN_RELEASE DIB_EXTLINUX=1 \ disk-image-create $BASE_ELEMENTS $EXTRA_ELEMENTS -o $IMG_OUT ",,39,0
openstack-attic%2Fakanda-appliance-builder~master~I88782acad59ecff1ae262a76b8bfa896abad4604,openstack-attic/akanda-appliance-builder,master,I88782acad59ecff1ae262a76b8bfa896abad4604,remove stale appliance-builder content,MERGED,2015-06-23 21:16:50.000000000,2015-06-24 16:43:48.000000000,2015-06-24 16:43:48.000000000,"[{'_account_id': 3}, {'_account_id': 1420}, {'_account_id': 8005}]","[{'number': 1, 'created': '2015-06-23 21:16:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack-attic/akanda-appliance-builder/commit/d89c07f1f6bd63011efd03018ab0c6c63d9305df', 'message': 'remove stale appliance-builder content\n\nthe function of this repo has been moved to\nthe akanda-appliance repo.\n\nPartially Implements: blueprint liberty-ci-updates\n\nChange-Id: I88782acad59ecff1ae262a76b8bfa896abad4604\n'}, {'number': 2, 'created': '2015-06-23 23:20:48.000000000', 'files': ['nocloud/meta-data', 'diskimage-builder/README.md', 'diskimage-builder/elements/akanda/source-repository-akanda', 'diskimage-builder/elements/akanda/environment.d/10-cloudinit-akanda', 'diskimage-builder/elements/debug-user/README.md', 'diskimage-builder/elements/pip-and-virtualenv/install.d/get-pip-py-source-install/01-install-pip', 'diskimage-builder/elements/ansible/README.md', 'diskimage-builder/elements/ansible/install.d/ansible-package-install/30-ansible-package', 'diskimage-builder/elements/pip-and-virtualenv/install.d/get-pip-py-package-install/package-installs-pip-and-virtualenv', 'nocloud/user-data', 'diskimage-builder/elements/ansible/environment.d/10-ansible-venv-dir.bash', 'diskimage-builder/elements/akanda/element-deps', 'diskimage-builder/elements/nginx-plus/README.rst', 'diskimage-builder/elements/ansible/element-deps', 'diskimage-builder/elements/ansible/install.d/ansible-source-install/30-ansible-source', 'diskimage-builder/elements/nginx/element-deps', 'diskimage-builder/elements/nginx/README.rst', 'diskimage-builder/elements/pip-and-virtualenv/element-deps', 'nocloud/README.md', 'README.md', 'diskimage-builder/elements/akanda/README.rst', 'diskimage-builder/elements/nginx-plus/pre-install.d/01-nginx-plus', 'diskimage-builder/elements/akanda/install.d/akanda-source-install/70-akanda', 'diskimage-builder/elements/pip-and-virtualenv/source-repository-pip-and-virtualenv', 'diskimage-builder/elements/akanda/post-install.d/90-fix-locale', 'diskimage-builder/elements/nginx/install.d/package-installs-nginx', 'diskimage-builder/elements/ansible/cleanup.d/50-remove-source-ansible', 'diskimage-builder/elements/nginx-plus/element-deps', 'diskimage-builder/elements/pip-and-virtualenv/README.md', 'diskimage-builder/elements/debug-user/install.d/50-debug-user'], 'web_link': 'https://opendev.org/openstack-attic/akanda-appliance-builder/commit/9b9a58b572b7fbe7c2b63b3ad8f719c889a55214', 'message': 'remove stale appliance-builder content\n\nthe function of this repo has been moved to\nthe akanda-appliance repo.\n\nPartially Implements: blueprint liberty-ci-updates\n\nChange-Id: I88782acad59ecff1ae262a76b8bfa896abad4604\n'}]",1,194825,9b9a58b572b7fbe7c2b63b3ad8f719c889a55214,11,3,2,6923,,,0,"remove stale appliance-builder content

the function of this repo has been moved to
the akanda-appliance repo.

Partially Implements: blueprint liberty-ci-updates

Change-Id: I88782acad59ecff1ae262a76b8bfa896abad4604
",git fetch https://review.opendev.org/openstack-attic/akanda-appliance-builder refs/changes/25/194825/1 && git format-patch -1 --stdout FETCH_HEAD,"['nocloud/meta-data', 'diskimage-builder/README.md', 'diskimage-builder/elements/akanda/source-repository-akanda', 'diskimage-builder/elements/akanda/environment.d/10-cloudinit-akanda', 'diskimage-builder/elements/debug-user/README.md', 'diskimage-builder/elements/pip-and-virtualenv/install.d/get-pip-py-source-install/01-install-pip', 'diskimage-builder/elements/ansible/README.md', 'diskimage-builder/elements/ansible/install.d/ansible-package-install/30-ansible-package', 'diskimage-builder/elements/pip-and-virtualenv/install.d/get-pip-py-package-install/package-installs-pip-and-virtualenv', 'nocloud/user-data', 'diskimage-builder/elements/ansible/environment.d/10-ansible-venv-dir.bash', 'diskimage-builder/elements/akanda/element-deps', 'diskimage-builder/elements/nginx-plus/README.rst', 'diskimage-builder/elements/ansible/element-deps', 'diskimage-builder/elements/ansible/install.d/ansible-source-install/30-ansible-source', 'diskimage-builder/elements/nginx/element-deps', 'diskimage-builder/elements/nginx/README.rst', 'diskimage-builder/elements/pip-and-virtualenv/element-deps', 'nocloud/README.md', 'README.md', 'diskimage-builder/elements/akanda/README.rst', 'diskimage-builder/elements/nginx-plus/pre-install.d/01-nginx-plus', 'diskimage-builder/elements/akanda/install.d/akanda-source-install/70-akanda', 'diskimage-builder/elements/pip-and-virtualenv/source-repository-pip-and-virtualenv', 'diskimage-builder/elements/akanda/post-install.d/90-fix-locale', 'diskimage-builder/elements/nginx/install.d/package-installs-nginx', 'diskimage-builder/elements/ansible/cleanup.d/50-remove-source-ansible', 'diskimage-builder/elements/nginx-plus/element-deps', 'diskimage-builder/elements/pip-and-virtualenv/README.md', 'tox.ini', 'diskimage-builder/elements/debug-user/install.d/50-debug-user']",31,d89c07f1f6bd63011efd03018ab0c6c63d9305df,bp/liberty-ci-updates,,#!/bin/bash DIB_AKANDA_APPLIANCE_DEBUG_USER=${DIB_AKANDA_APPLIANCE_DEBUG_USER:-akanda-debug} DIB_AKANDA_APPLIANCE_DEBUG_PASSWORD=${DIB_AKANDA_APPLIANCE_DEBUG_PASSWORD:-akanda} set -eu set -o xtrace useradd -m $DIB_AKANDA_APPLIANCE_DEBUG_USER -s /bin/bash passwd $DIB_AKANDA_APPLIANCE_DEBUG_USER <<EOF $DIB_AKANDA_APPLIANCE_DEBUG_PASSWORD $DIB_AKANDA_APPLIANCE_DEBUG_PASSWORD EOF cat > /etc/sudoers.d/akanda-debug-user <<eof $DIB_AKANDA_APPLIANCE_DEBUG_USER ALL=(ALL) NOPASSWD:ALL eof chmod 0440 /etc/sudoers.d/akanda-debug-user visudo -c ,4,258
openstack%2Fironic~master~Icab13ef5c48ab7a84e44bc1e4b30fe10de9d530e,openstack/ironic,master,Icab13ef5c48ab7a84e44bc1e4b30fe10de9d530e,Updated from global requirements,MERGED,2015-06-22 19:53:58.000000000,2015-06-24 16:43:45.000000000,2015-06-24 16:43:43.000000000,"[{'_account_id': 3}, {'_account_id': 6618}, {'_account_id': 10239}, {'_account_id': 12081}]","[{'number': 1, 'created': '2015-06-22 19:53:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/f1d8bf5678956954483ef618364383ed5c53e0b3', 'message': 'Updated from global requirements\n\nChange-Id: Icab13ef5c48ab7a84e44bc1e4b30fe10de9d530e\n'}, {'number': 2, 'created': '2015-06-22 20:13:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/52b5eaa3b392d433abeb155ac9b86cd753d57f86', 'message': 'Updated from global requirements\n\nChange-Id: Icab13ef5c48ab7a84e44bc1e4b30fe10de9d530e\n'}, {'number': 3, 'created': '2015-06-23 21:43:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/e06ded6756506461a22ce18646e139082eed42a8', 'message': 'Updated from global requirements\n\nChange-Id: Icab13ef5c48ab7a84e44bc1e4b30fe10de9d530e\n'}, {'number': 4, 'created': '2015-06-23 22:04:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/7d3b7b791a3236de2a6d30898e01d531285a63c4', 'message': 'Updated from global requirements\n\nChange-Id: Icab13ef5c48ab7a84e44bc1e4b30fe10de9d530e\n'}, {'number': 5, 'created': '2015-06-24 14:39:29.000000000', 'files': ['requirements.txt', 'test-requirements.txt'], 'web_link': 'https://opendev.org/openstack/ironic/commit/e84be558a9d9fa12e48fd9bd96a66326de9cb9ce', 'message': 'Updated from global requirements\n\nChange-Id: Icab13ef5c48ab7a84e44bc1e4b30fe10de9d530e\n'}]",0,194320,e84be558a9d9fa12e48fd9bd96a66326de9cb9ce,23,4,5,11131,,,0,"Updated from global requirements

Change-Id: Icab13ef5c48ab7a84e44bc1e4b30fe10de9d530e
",git fetch https://review.opendev.org/openstack/ironic refs/changes/20/194320/1 && git format-patch -1 --stdout FETCH_HEAD,['requirements.txt'],1,f1d8bf5678956954483ef618364383ed5c53e0b3,openstack/requirements,eventlet>=0.17.4,eventlet>=0.17.3,1,1
openstack%2Fneutron-vpnaas~master~If8a61cf71075d86b9491e0498a603ae1597c6c7f,openstack/neutron-vpnaas,master,If8a61cf71075d86b9491e0498a603ae1597c6c7f,Use DvrEdgeRouter instead of decomposed DvrRouter in test_ipsec,MERGED,2015-06-22 12:01:27.000000000,2015-06-24 16:43:39.000000000,2015-06-24 16:43:38.000000000,"[{'_account_id': 3}, {'_account_id': 6659}, {'_account_id': 7293}, {'_account_id': 7448}]","[{'number': 1, 'created': '2015-06-22 12:01:27.000000000', 'files': ['neutron_vpnaas/tests/unit/services/vpn/device_drivers/test_ipsec.py'], 'web_link': 'https://opendev.org/openstack/neutron-vpnaas/commit/e9cd3f81039da3096f8eba4135c2b3c984090895', 'message': 'Use DvrEdgeRouter instead of decomposed DvrRouter in test_ipsec\n\nChange-Id: If8a61cf71075d86b9491e0498a603ae1597c6c7f\nCloses-Bug: #1467466\n'}]",2,194100,e9cd3f81039da3096f8eba4135c2b3c984090895,12,4,1,7293,,,0,"Use DvrEdgeRouter instead of decomposed DvrRouter in test_ipsec

Change-Id: If8a61cf71075d86b9491e0498a603ae1597c6c7f
Closes-Bug: #1467466
",git fetch https://review.opendev.org/openstack/neutron-vpnaas refs/changes/00/194100/1 && git format-patch -1 --stdout FETCH_HEAD,['neutron_vpnaas/tests/unit/services/vpn/device_drivers/test_ipsec.py'],1,e9cd3f81039da3096f8eba4135c2b3c984090895,bug/1467466,"from neutron.agent.l3 import dvr_edge_router self._make_dvr_edge_router_info_for_test() def _make_dvr_edge_router_info_for_test(self): router = dvr_edge_router.DvrEdgeRouter(mock.sentinel.agent, mock.sentinel.myhost, FAKE_ROUTER_ID, **self.ri_kwargs) def test_get_namespace_for_dvr_edge_router(self): def test_add_nat_rule_with_dvr_edge_router(self): def test_iptables_apply_with_dvr_edge_router(self): def test_remove_rule_with_dvr_edge_router(self):","from neutron.agent.l3 import dvr_router self._make_dvr_router_info_for_test() def _make_dvr_router_info_for_test(self): router = dvr_router.DvrRouter(mock.sentinel.agent, mock.sentinel.myhost, FAKE_ROUTER_ID, **self.ri_kwargs) def test_get_namespace_for_dvr_router(self): def test_add_nat_rule_with_dvr_router(self): def test_iptables_apply_with_dvr_router(self): def test_remove_rule_with_dvr_router(self):",11,11
openstack%2Fgrenade~master~Id65c7d0ba332d89cfca3a4f9671877e52b990f32,openstack/grenade,master,Id65c7d0ba332d89cfca3a4f9671877e52b990f32,Update a misguided comment about pbr and newness.,MERGED,2015-06-22 21:42:11.000000000,2015-06-24 16:43:25.000000000,2015-06-24 16:43:22.000000000,"[{'_account_id': 3}, {'_account_id': 970}, {'_account_id': 2750}]","[{'number': 1, 'created': '2015-06-22 21:42:11.000000000', 'files': ['prep-target'], 'web_link': 'https://opendev.org/openstack/grenade/commit/23be267630a3dc41cba09b8bc08819f5ec0095fd', 'message': 'Update a misguided comment about pbr and newness.\n\nChange-Id: Id65c7d0ba332d89cfca3a4f9671877e52b990f32\n'}]",0,194400,23be267630a3dc41cba09b8bc08819f5ec0095fd,8,3,1,4190,,,0,"Update a misguided comment about pbr and newness.

Change-Id: Id65c7d0ba332d89cfca3a4f9671877e52b990f32
",git fetch https://review.opendev.org/openstack/grenade refs/changes/00/194400/1 && git format-patch -1 --stdout FETCH_HEAD,['prep-target'],1,23be267630a3dc41cba09b8bc08819f5ec0095fd,,"# this also pulls in new pbr which is needed because older # releases of various libraries trigger downgrades which then # would break, and pbr as a setup_requires can't be sanely # minimum-versioned.","# FIXME: this also pulls in new pbr which is not really needed, we # should separate that in the future.",4,2
openstack%2Fnova~master~Ib356aa9df0a3b85580ea2869ce4d043a6850967a,openstack/nova,master,Ib356aa9df0a3b85580ea2869ce4d043a6850967a,Add the rule of separate plugin for Nova REST API in devref,MERGED,2015-03-10 08:39:15.000000000,2015-06-24 16:42:49.000000000,2015-06-24 16:42:45.000000000,"[{'_account_id': 3}, {'_account_id': 7}, {'_account_id': 782}, {'_account_id': 1653}, {'_account_id': 2750}, {'_account_id': 5170}, {'_account_id': 5754}, {'_account_id': 6062}, {'_account_id': 6167}, {'_account_id': 8556}, {'_account_id': 9172}, {'_account_id': 9420}, {'_account_id': 9578}, {'_account_id': 9732}, {'_account_id': 10118}, {'_account_id': 10385}, {'_account_id': 11103}, {'_account_id': 13663}, {'_account_id': 14320}, {'_account_id': 15286}, {'_account_id': 15751}, {'_account_id': 16897}, {'_account_id': 17023}]","[{'number': 1, 'created': '2015-03-10 08:39:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/7be39c36ec2b3b24c9b89df74d3efa6980200715', 'message': 'Add the rule of separate plugin for Nova REST API in devref\n\nThis patch adds the describe how to separate plugin when add new\nresource or some extended for existed resource.\n\nChange-Id: Ib356aa9df0a3b85580ea2869ce4d043a6850967a\n'}, {'number': 2, 'created': '2015-04-28 09:54:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/6a5ed04e467a6636957f08127d064be958d71c28', 'message': 'Add the rule of separate plugin for Nova REST API in devref\n\nThis patch adds the describe how to separate plugin when add new\nresource or some extended for existed resource.\n\nChange-Id: Ib356aa9df0a3b85580ea2869ce4d043a6850967a\n'}, {'number': 3, 'created': '2015-04-28 11:30:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/218ffe377e4b7294dd6458f4a94e15c142126317', 'message': 'Add the rule of separate plugin for Nova REST API in devref\n\nThis patch adds the describe how to separate plugin when add new\nresource or some extended for existed resource.\n\nChange-Id: Ib356aa9df0a3b85580ea2869ce4d043a6850967a\n'}, {'number': 4, 'created': '2015-04-29 08:18:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/099e7d24709744a779f3edaadd7a50ccfc46cdd2', 'message': 'Add the rule of separate plugin for Nova REST API in devref\n\nThis patch adds the describe how to separate plugin when add new\nresource or some extended for existed resource.\n\nChange-Id: Ib356aa9df0a3b85580ea2869ce4d043a6850967a\n'}, {'number': 5, 'created': '2015-04-30 23:34:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/0ee1e17aa54cff0ea1df339833765a8d94568c6c', 'message': 'Add the rule of separate plugin for Nova REST API in devref\n\nThis patch adds the describe how to separate plugin when add new\nresource or some extended for existed resource.\n\nChange-Id: Ib356aa9df0a3b85580ea2869ce4d043a6850967a\n'}, {'number': 6, 'created': '2015-05-30 14:20:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/0a0a9dc6b0a4277b3f4cd67e4d25384e940f64e4', 'message': 'Add the rule of separate plugin for Nova REST API in devref\n\nThis patch adds the describe how to separate plugin when add new\nresource or some extended for existed resource.\n\nChange-Id: Ib356aa9df0a3b85580ea2869ce4d043a6850967a\n'}, {'number': 7, 'created': '2015-06-03 02:59:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/13ea008554aed10d647ca85039f590bf87d1d3e0', 'message': 'Add the rule of separate plugin for Nova REST API in devref\n\nThis patch adds the describe how to separate plugin when add new\nresource or some extended for existed resource.\n\nChange-Id: Ib356aa9df0a3b85580ea2869ce4d043a6850967a\n'}, {'number': 8, 'created': '2015-06-03 05:15:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/f0bf4e7fae99061f7b7156e6115490ac98a159ba', 'message': 'Add the rule of separate plugin for Nova REST API in devref\n\nThis patch adds the describe how to separate plugin when add new\nresource or some extended for existed resource.\n\nChange-Id: Ib356aa9df0a3b85580ea2869ce4d043a6850967a\n'}, {'number': 9, 'created': '2015-06-03 08:08:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/df4b8dd688f6eb23f2e8571fafa1137aba356741', 'message': 'Add the rule of separate plugin for Nova REST API in devref\n\nThis patch adds the describe how to separate plugin when add new\nresource or some extended for existed resource.\n\nChange-Id: Ib356aa9df0a3b85580ea2869ce4d043a6850967a\n'}, {'number': 10, 'created': '2015-06-11 14:12:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/33405e00b1af624b1e7b7a402ea142e83c6d7879', 'message': 'Add the rule of separate plugin for Nova REST API in devref\n\nThis patch adds the describe how to separate plugin when add new\nresource or some extended for existed resource.\n\nChange-Id: Ib356aa9df0a3b85580ea2869ce4d043a6850967a\n'}, {'number': 11, 'created': '2015-06-18 08:38:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/5acf113d1cf0a738ffea102e348f95c7e9b07191', 'message': 'Add the rule of separate plugin for Nova REST API in devref\n\nThis patch adds the describe how to separate plugin when add new\nresource or some extended for existed resource.\n\nChange-Id: Ib356aa9df0a3b85580ea2869ce4d043a6850967a\n'}, {'number': 12, 'created': '2015-06-18 09:26:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/25904d4f5c2b67282fe7fb224db48a4b1bb8a9d4', 'message': 'Add the rule of separate plugin for Nova REST API in devref\n\nThis patch adds the describe how to separate plugin when add new\nresource or some extended for existed resource.\n\nChange-Id: Ib356aa9df0a3b85580ea2869ce4d043a6850967a\n'}, {'number': 13, 'created': '2015-06-19 07:18:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/8c91bd5ccb6c971629992f52fcfa0606c6ed6e7e', 'message': 'Add the rule of separate plugin for Nova REST API in devref\n\nThis patch adds the describe how to separate plugin when add new\nresource or some extended for existed resource.\n\nChange-Id: Ib356aa9df0a3b85580ea2869ce4d043a6850967a\n'}, {'number': 14, 'created': '2015-06-24 13:25:05.000000000', 'files': ['doc/source/api_plugins.rst'], 'web_link': 'https://opendev.org/openstack/nova/commit/b5b86ae0901a0a74142022500821fd5dfa445961', 'message': 'Add the rule of separate plugin for Nova REST API in devref\n\nThis patch adds the describe how to separate plugin when adding new\nresource or some extended for existed resource.\n\nChange-Id: Ib356aa9df0a3b85580ea2869ce4d043a6850967a\n'}]",58,162913,b5b86ae0901a0a74142022500821fd5dfa445961,122,23,14,5754,,,0,"Add the rule of separate plugin for Nova REST API in devref

This patch adds the describe how to separate plugin when adding new
resource or some extended for existed resource.

Change-Id: Ib356aa9df0a3b85580ea2869ce4d043a6850967a
",git fetch https://review.opendev.org/openstack/nova refs/changes/13/162913/5 && git format-patch -1 --stdout FETCH_HEAD,['doc/source/devref/api_plugins.rst'],1,7be39c36ec2b3b24c9b89df74d3efa6980200715,(detached,"Modularity ~~~~~~~~~~ All the Nova REST API are separated into different plugins in the directory 'plugins/v3/' Although Nova REST API support micro-version for now, the API can be extended without any new plugin. But for code readability, the Nova REST API code still need modularity. There is the rule for how to separate plugin: * Add new resource The new resource should be in standalone plugin. There isn't any reason to put different resources in a single plugin. * Add sub-resource for existed resource For prevent the existed resource plugin over inflated, the sub-resource's action and extended attributes of existed resource. * Add extended attributes for existed resource In normally, the extended attributes is part of existed resource's data model also. So this can be added into existed resource plugin directly and lightly. If there is more appropriately extended plugin for the existed resource, it also good choice. The spec of the API change should describe whether need new plugin for the change and the reason. That can be reviewed by Nova team. ",,28,0
openstack%2Fceilometer~stable%2Fkilo~I5c5b263f0160726034dfca59d70d2a6a32585cb5,openstack/ceilometer,stable/kilo,I5c5b263f0160726034dfca59d70d2a6a32585cb5,[elasticsearch] default trait type to string,MERGED,2015-06-12 09:05:26.000000000,2015-06-24 16:42:36.000000000,2015-06-24 16:42:34.000000000,"[{'_account_id': 3}, {'_account_id': 4491}, {'_account_id': 6676}, {'_account_id': 6873}, {'_account_id': 6924}, {'_account_id': 7729}, {'_account_id': 8290}, {'_account_id': 8358}, {'_account_id': 10987}, {'_account_id': 11564}, {'_account_id': 14107}]","[{'number': 1, 'created': '2015-06-12 09:05:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/1865780f0ea883e8561144fcb77edb0326a06b2c', 'message': '[elasticsearch] default trait type to string\n\nwhen trait mapping is not found, get_events for es backend will\nassume the last known type that was mapped. this patch changes that\nso it will default to text type if a mapping is not found.\n\nChange-Id: I5c5b263f0160726034dfca59d70d2a6a32585cb5\nCloses-Bug: #1453919\n'}, {'number': 4, 'created': '2015-06-16 00:05:23.000000000', 'files': ['ceilometer/event/storage/impl_elasticsearch.py'], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/349be3da3e724f9ae15f1c23be76eeaf64792100', 'message': '[elasticsearch] default trait type to string\n\nwhen trait mapping is not found, get_events for es backend will\nassume the last known type that was mapped. this patch changes that\nso it will default to text type if a mapping is not found.\n\nChange-Id: I5c5b263f0160726034dfca59d70d2a6a32585cb5\nCloses-Bug: #1453919\n(cherry picked from commit 906c72fc216a108cd949faf94fc2a2adda014a9b)'}]",0,190983,349be3da3e724f9ae15f1c23be76eeaf64792100,17,11,2,6537,,,0,"[elasticsearch] default trait type to string

when trait mapping is not found, get_events for es backend will
assume the last known type that was mapped. this patch changes that
so it will default to text type if a mapping is not found.

Change-Id: I5c5b263f0160726034dfca59d70d2a6a32585cb5
Closes-Bug: #1453919
(cherry picked from commit 906c72fc216a108cd949faf94fc2a2adda014a9b)",git fetch https://review.opendev.org/openstack/ceilometer refs/changes/83/190983/1 && git format-patch -1 --stdout FETCH_HEAD,['ceilometer/event/storage/impl_elasticsearch.py'],1,1865780f0ea883e8561144fcb77edb0326a06b2c,, else: dtype = models.Trait.TEXT_TYPE,,2,0
openstack%2Fmistral~master~I80610cbfe7fd54263c8a2d9178ec9a2498c91899,openstack/mistral,master,I80610cbfe7fd54263c8a2d9178ec9a2498c91899,Get rid of openstack/common package,MERGED,2015-06-24 07:44:36.000000000,2015-06-24 16:36:38.000000000,2015-06-24 16:36:37.000000000,"[{'_account_id': 3}, {'_account_id': 5558}, {'_account_id': 6732}, {'_account_id': 7700}, {'_account_id': 8731}, {'_account_id': 9432}, {'_account_id': 15881}]","[{'number': 1, 'created': '2015-06-24 07:44:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/mistral/commit/b74e25ea498692e42245e297ba68ecc3b2480faa', 'message': 'Get rid of openstack/common package\n\n* use oslo graduated modules, delete openstack/common package since there\n  is no dependency on oslo-incubator modules.\n* delete openstack-common.conf for the reason above.\n* update project requirements automatically.\n\nChange-Id: I80610cbfe7fd54263c8a2d9178ec9a2498c91899\nCloses-Bug: #1459188\n'}, {'number': 2, 'created': '2015-06-24 08:53:20.000000000', 'files': ['mistral/utils/javascript.py', 'test-requirements.txt', 'mistral/config.py', 'mistral/openstack/common/jsonutils.py', 'mistral/services/scheduler.py', 'requirements.txt', 'mistral/openstack/common/__init__.py', 'mistral/db/sqlalchemy/migration/cli.py', 'mistral/openstack/common/loopingcall.py', 'mistral/actions/action_factory.py', 'mistral/openstack/common/strutils.py', 'openstack-common.conf', 'mistral/services/periodic.py', 'mistral/openstack/common/excutils.py', 'mistral/openstack/common/test.py', 'mistral/openstack/common/importutils.py', 'mistral/openstack/common/timeutils.py', 'mistral/openstack/common/threadgroup.py', 'mistral/openstack/common/config/__init__.py', 'mistral/openstack/__init__.py', 'run_tests.sh', 'mistral/context.py', 'mistral/openstack/common/context.py', 'mistral/db/sqlalchemy/types.py', 'mistral/openstack/common/config/generator.py', 'mistral/openstack/common/gettextutils.py', 'mistral/openstack/common/periodic_task.py', 'mistral/tests/unit/api/test_auth.py', 'mistral/openstack/common/fileutils.py', 'mistral/openstack/common/uuidutils.py', 'mistral/openstack/common/lockutils.py', 'tox.ini', 'mistral/openstack/common/local.py', 'mistral/tests/unit/api/v2/test_root.py'], 'web_link': 'https://opendev.org/openstack/mistral/commit/645576e2f09fa1b3a315a23e61328e6d867a51d8', 'message': 'Get rid of openstack/common package\n\n* use oslo graduated modules, delete openstack/common package since there\n  is no dependency on oslo-incubator modules now.\n* delete openstack-common.conf for the reason above.\n* update project requirements automatically.\n\nChange-Id: I80610cbfe7fd54263c8a2d9178ec9a2498c91899\nCloses-Bug: #1459188\n'}]",0,194972,645576e2f09fa1b3a315a23e61328e6d867a51d8,12,7,2,6732,,,0,"Get rid of openstack/common package

* use oslo graduated modules, delete openstack/common package since there
  is no dependency on oslo-incubator modules now.
* delete openstack-common.conf for the reason above.
* update project requirements automatically.

Change-Id: I80610cbfe7fd54263c8a2d9178ec9a2498c91899
Closes-Bug: #1459188
",git fetch https://review.opendev.org/openstack/mistral refs/changes/72/194972/1 && git format-patch -1 --stdout FETCH_HEAD,"['mistral/utils/javascript.py', 'test-requirements.txt', 'mistral/config.py', 'mistral/openstack/common/jsonutils.py', 'mistral/services/scheduler.py', 'requirements.txt', 'mistral/openstack/common/__init__.py', 'mistral/db/sqlalchemy/migration/cli.py', 'mistral/openstack/common/loopingcall.py', 'mistral/actions/action_factory.py', 'mistral/openstack/common/strutils.py', 'openstack-common.conf', 'mistral/services/periodic.py', 'mistral/openstack/common/excutils.py', 'mistral/openstack/common/test.py', 'mistral/openstack/common/importutils.py', 'mistral/openstack/common/timeutils.py', 'mistral/openstack/common/threadgroup.py', 'mistral/openstack/common/config/__init__.py', 'mistral/openstack/__init__.py', 'run_tests.sh', 'mistral/context.py', 'mistral/openstack/common/context.py', 'mistral/db/sqlalchemy/types.py', 'mistral/openstack/common/config/generator.py', 'mistral/openstack/common/gettextutils.py', 'mistral/openstack/common/periodic_task.py', 'mistral/tests/unit/api/test_auth.py', 'mistral/openstack/common/fileutils.py', 'mistral/openstack/common/uuidutils.py', 'mistral/openstack/common/lockutils.py', 'mistral/openstack/common/local.py', 'mistral/tests/unit/api/v2/test_root.py']",33,b74e25ea498692e42245e297ba68ecc3b2480faa,bug/1459188,from oslo_serialization import jsonutils , from mistral.openstack.common import jsonutils,55,2985
openstack%2Fdesignate~master~I9343852b2834affd0fe6c1e3f85c0f25002a0ee7,openstack/designate,master,I9343852b2834affd0fe6c1e3f85c0f25002a0ee7,"Edits to dev guide, juno guide, and kilo guide",MERGED,2015-06-11 19:55:23.000000000,2015-06-24 16:32:01.000000000,2015-06-24 16:31:59.000000000,"[{'_account_id': 3}, {'_account_id': 741}, {'_account_id': 8174}, {'_account_id': 10068}, {'_account_id': 11662}]","[{'number': 1, 'created': '2015-06-11 19:55:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/designate/commit/8ce94dd3a1a3531d336e6fdb219467b1ef67989e', 'message': 'Edits to getting started guide and dev guides\n\n-Added notes to assist whoever is using the guide for when they run into an error\nthat I previously encountered (repeatedly). Also changed the basic-config-sample.conf\nto clean up the commented lines and added a sample pool configuration.\n-Corrected a few typos in the guide for juno, and added clarification on how to\nuse the mysql command line.\n\nChange-Id: I9343852b2834affd0fe6c1e3f85c0f25002a0ee7\n'}, {'number': 2, 'created': '2015-06-12 15:43:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/designate/commit/bccaaa9e1f31f769e66685ded9563493e366f65f', 'message': ""Edits to getting started guide and dev guides\n\n-Added notes to assist whoever is using the guide for when they run into an error\nthat I previously encountered (repeatedly). Also changed the basic-config-sample.conf\nto clean up the commented lines and added a sample pool configuration.\n-Corrected a few typos in the guide for juno, and added clarification on how to\nuse the mysql command line.\n\n--update--\nMade changes according to Tim's comments.\n-Added back the commented lines to config sample file\n-Removed Pool Backend Configs\n-Added apt-get update to steps\n-Updated mysql commands\n\nChange-Id: I9343852b2834affd0fe6c1e3f85c0f25002a0ee7\n""}, {'number': 3, 'created': '2015-06-12 15:45:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/designate/commit/d6c709588fbe53bc9def0773edaf674602d553a3', 'message': ""Edits to getting started guide and dev guides\n\n-Added notes to assist whoever is using the guide for when they run into an error\nthat I previously encountered (repeatedly). Also changed the basic-config-sample.conf\nto clean up the commented lines and added a sample pool configuration.\n-Corrected a few typos in the guide for juno, and added clarification on how to\nuse the mysql command line.\n\n--update--\nMade changes according to Tim's comments.\n-Added back the commented lines to config sample file\n-Removed Pool Backend Configs\n-Added apt-get update to steps\n-Updated mysql commands\n\nChange-Id: I9343852b2834affd0fe6c1e3f85c0f25002a0ee7\n""}, {'number': 4, 'created': '2015-06-12 15:48:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/designate/commit/16658e90feb3cd3e4df0bee1156591930efd74f0', 'message': ""Edits to getting started guide and dev guides\n\n-Added notes to assist whoever is using the guide for when they run into an error\nthat I previously encountered (repeatedly). Also changed the basic-config-sample.conf\nto clean up the commented lines and added a sample pool configuration.\n-Corrected a few typos in the guide for juno, and added clarification on how to\nuse the mysql command line.\n\n--update--\nMade changes according to Tim's comments.\n-Added back the commented lines to config sample file\n-Removed Pool Backend Configs\n-Added apt-get update to steps\n-Updated mysql commands\n\n--update--\nMinor change: deleted repeat in basic-config-sample.conf\n\nChange-Id: I9343852b2834affd0fe6c1e3f85c0f25002a0ee7\n""}, {'number': 5, 'created': '2015-06-22 21:35:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/designate/commit/dc4d42c615ec2a44180e4bb1c860715bbf25f672', 'message': ""Edits to getting started guide and juno guide, and addition of kilo guide\n\n-Added notes to assist whoever is using the guide for when they run into an error\nthat I previously encountered (repeatedly). Also changed the basic-config-sample.conf\nto clean up the commented lines and added a sample pool configuration.\n-Corrected a few typos in the guide for juno, and added clarification on how to\nuse the mysql command line.\n\n--update--\nMade changes according to Tim's comments.\n-Added back the commented lines to config sample file\n-Removed Pool Backend Configs\n-Added apt-get update to steps\n-Updated mysql commands\n\n--update--\nMinor change: deleted repeat in basic-config-sample.conf\n\n--update--\nAdded guide for Kilo using the ubuntu-dev guide with modifications as fit for the Kilo branch.\n\nChange-Id: I9343852b2834affd0fe6c1e3f85c0f25002a0ee7\n""}, {'number': 6, 'created': '2015-06-22 21:57:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/designate/commit/6a3b7c84fabc221c36cde41816592296e52677dc', 'message': ""Edits to getting started guide and juno guide, and addition of kilo guide\n\n-Added notes to assist whoever is using the guide for when they run into an error\nthat I previously encountered (repeatedly). Also changed the basic-config-sample.conf\nto clean up the commented lines and added a sample pool configuration.\n-Corrected a few typos in the guide for juno, and added clarification on how to\nuse the mysql command line.\n\n--update2--\nMade changes according to Tim's comments.\n-Added back the commented lines to config sample file\n-Removed Pool Backend Configs\n-Added apt-get update to steps\n-Updated mysql commands\n\n--update4--\nMinor change: deleted repeat in basic-config-sample.conf\n\n--update5--\nAdded guide for Kilo using the ubuntu-dev guide with modifications as fit for the Kilo branch.\n\nChange-Id: I9343852b2834affd0fe6c1e3f85c0f25002a0ee7\n""}, {'number': 7, 'created': '2015-06-23 14:43:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/designate/commit/a3afbdfbf5bd3889ba48d948404bfcb9c6ecf474', 'message': ""Edits to dev guide, juno guide, and kilo guide\n\n-Added notes to assist whoever is using the guide for when they run into an error\nthat I previously encountered (repeatedly). Also changed the basic-config-sample.conf\nto clean up the commented lines and added a sample pool configuration.\n-Corrected a few typos in the guide for juno, and added clarification on how to\nuse the mysql command line.\n\n--update2--\nMade changes according to Tim's comments.\n-Added back the commented lines to config sample file\n-Removed Pool Backend Configs\n-Added apt-get update to steps\n-Updated mysql commands\n\n--update4--\nMinor change: deleted repeat in basic-config-sample.conf\n\n--update5--\nAdded guide for Kilo using the ubuntu-dev guide with modifications as fit for the Kilo branch.\n\n--update7--\n-Shortened title\n-removed random spacesx\n\nChange-Id: I9343852b2834affd0fe6c1e3f85c0f25002a0ee7\n""}, {'number': 8, 'created': '2015-06-23 16:29:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/designate/commit/cb72eca0d9be186ebb8ee08b6945e0acc4b53b2a', 'message': ""Edits to dev guide, juno guide, and kilo guide\n\n-Added notes to assist whoever is using the guide for when they run into an error\nthat I previously encountered (repeatedly). Also changed the basic-config-sample.conf\nto clean up the commented lines and added a sample pool configuration.\n-Corrected a few typos in the guide for juno, and added clarification on how to\nuse the mysql command line.\n\n--update2--\nMade changes according to Tim's comments.\n-Added back the commented lines to config sample file\n-Removed Pool Backend Configs\n-Added apt-get update to steps\n-Updated mysql commands\n\n--update4--\nMinor change: deleted repeat in basic-config-sample.conf\n\n--update5--\nAdded guide for Kilo using the ubuntu-dev guide with modifications as fit for the Kilo branch.\n\n--update7--\n-Shortened title\n-removed random spacesx\n\n--update8--\n-removed line from basic-config file\n-created config file specific to kilo\n-renamed config file specific to juno\n-edited doc with correct config file names\n\nChange-Id: I9343852b2834affd0fe6c1e3f85c0f25002a0ee7\n""}, {'number': 9, 'created': '2015-06-23 21:47:51.000000000', 'files': ['doc/source/install/ubuntu-juno.rst', 'doc/source/examples/basic-config-sample.conf', 'doc/source/examples/basic-config-sample-kilo.conf', 'doc/source/install/ubuntu-dev.rst', 'doc/source/examples/basic-config-sample-juno.conf', 'doc/source/install/ubuntu-kilo.rst'], 'web_link': 'https://opendev.org/openstack/designate/commit/d96a382ef34b8cad5b295d998357154e41c8d06c', 'message': 'Edits to dev guide, juno guide, and kilo guide\n\nDev Guide:\n- Added notes to assist whoever is using the guide for when they run into an error\nthat I previously encountered (repeatedly). \n- Added apt-get update as first step\n\nSample Config File:\n- Added a sample pool configuration\n- Removed pool backend configs\n- Created config file specific to kilo and juno\n- Removed backends=bind9\n\n\nJuno Guide:\n- Corrected a few typos in the guide for juno\n- Updated mysql commands\n- Changed config file name\n\nKilo Guide:\n- Created a duplicate of the ubuntu-dev guide and modified it to work specifically for the kilo branch\n\nChange-Id: I9343852b2834affd0fe6c1e3f85c0f25002a0ee7\n'}]",6,190787,d96a382ef34b8cad5b295d998357154e41c8d06c,37,5,9,16561,,,0,"Edits to dev guide, juno guide, and kilo guide

Dev Guide:
- Added notes to assist whoever is using the guide for when they run into an error
that I previously encountered (repeatedly). 
- Added apt-get update as first step

Sample Config File:
- Added a sample pool configuration
- Removed pool backend configs
- Created config file specific to kilo and juno
- Removed backends=bind9


Juno Guide:
- Corrected a few typos in the guide for juno
- Updated mysql commands
- Changed config file name

Kilo Guide:
- Created a duplicate of the ubuntu-dev guide and modified it to work specifically for the kilo branch

Change-Id: I9343852b2834affd0fe6c1e3f85c0f25002a0ee7
",git fetch https://review.opendev.org/openstack/designate refs/changes/87/190787/8 && git format-patch -1 --stdout FETCH_HEAD,"['doc/source/install/ubuntu-juno.rst', 'doc/source/examples/basic-config-sample.conf', 'doc/source/install/ubuntu-dev.rst']",3,8ce94dd3a1a3531d336e6fdb219467b1ef67989e,ubuntu-dev-guide,".. note:: If you run into an error such as ""unable to locate package python-pip"", try apt-get update.. note:: If you run into the error: Installed distribution pbr 1.1.1 conflicts with requirement pbr>=0.6,!=0.7,<1.0, try doing pip install pbr==0.11.0 ",,46,92
openstack%2Fnetworking-ovn~master~I6c67b9b0a3cf29c4693cbfa85e4d34934767d78e,openstack/networking-ovn,master,I6c67b9b0a3cf29c4693cbfa85e4d34934767d78e,Updated from global requirements,MERGED,2015-06-24 00:15:45.000000000,2015-06-24 16:30:40.000000000,2015-06-24 16:30:39.000000000,"[{'_account_id': 3}, {'_account_id': 1561}, {'_account_id': 11343}]","[{'number': 1, 'created': '2015-06-24 00:15:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/networking-ovn/commit/c360ee0790d87f0bee09e68f45be266b65e412c7', 'message': 'Updated from global requirements\n\nChange-Id: I6c67b9b0a3cf29c4693cbfa85e4d34934767d78e\n'}, {'number': 2, 'created': '2015-06-24 14:40:20.000000000', 'files': ['requirements.txt'], 'web_link': 'https://opendev.org/openstack/networking-ovn/commit/78eac4aa7d1356aa2981604adda4f924b68a3dd2', 'message': 'Updated from global requirements\n\nChange-Id: I6c67b9b0a3cf29c4693cbfa85e4d34934767d78e\n'}]",0,194885,78eac4aa7d1356aa2981604adda4f924b68a3dd2,11,3,2,11131,,,0,"Updated from global requirements

Change-Id: I6c67b9b0a3cf29c4693cbfa85e4d34934767d78e
",git fetch https://review.opendev.org/openstack/networking-ovn refs/changes/85/194885/1 && git format-patch -1 --stdout FETCH_HEAD,['requirements.txt'],1,c360ee0790d87f0bee09e68f45be266b65e412c7,openstack/requirements,,,1,0
openstack%2Fopenstack-manuals~master~I992606a55e765ba84fe7182e1c933937ca3451e1,openstack/openstack-manuals,master,I992606a55e765ba84fe7182e1c933937ca3451e1,telemetry-system-architecture to RST,MERGED,2015-06-24 12:52:03.000000000,2015-06-24 16:29:28.000000000,2015-06-24 16:29:23.000000000,"[{'_account_id': 3}, {'_account_id': 6547}, {'_account_id': 10497}, {'_account_id': 14947}, {'_account_id': 15293}]","[{'number': 1, 'created': '2015-06-24 12:52:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/281f257fead6af0fbaa8a7b483238dabf8f4d5c1', 'message': 'telemetry-system-architecture to RST\n\nConverts section_telemetry-sytem-architecture.xml\nto RST.\nImplements: blueprint reorganise-user-guides\n\nChange-Id: I992606a55e765ba84fe7182e1c933937ca3451e1\n'}, {'number': 2, 'created': '2015-06-24 12:53:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/15ec7aa881b4f16fb333d3e56b7163befee60f6e', 'message': 'telemetry-system-architecture to RST\n\nConverts section_telemetry-system-architecture.xml\nto RST.\nImplements: blueprint reorganise-user-guides\n\nChange-Id: I992606a55e765ba84fe7182e1c933937ca3451e1\n'}, {'number': 3, 'created': '2015-06-24 16:09:45.000000000', 'files': ['doc/admin-guide-cloud-rst/source/telemetry.rst', 'doc/admin-guide-cloud-rst/source/telemetry-system-architecture.rst'], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/d3d4ebf6afbc3cc22411ce24514632c75f2dc287', 'message': 'telemetry-system-architecture to RST\n\nConverts section_telemetry-system-architecture.xml\nto RST.\nImplements: blueprint reorganise-user-guides\n\nChange-Id: I992606a55e765ba84fe7182e1c933937ca3451e1\n'}]",3,195063,d3d4ebf6afbc3cc22411ce24514632c75f2dc287,14,5,3,15293,,,0,"telemetry-system-architecture to RST

Converts section_telemetry-system-architecture.xml
to RST.
Implements: blueprint reorganise-user-guides

Change-Id: I992606a55e765ba84fe7182e1c933937ca3451e1
",git fetch https://review.opendev.org/openstack/openstack-manuals refs/changes/63/195063/3 && git format-patch -1 --stdout FETCH_HEAD,"['doc/admin-guide-cloud-rst/source/telemetry.rst', 'doc/admin-guide-cloud-rst/source/telemetry-system-architecture.rst']",2,281f257fead6af0fbaa8a7b483238dabf8f4d5c1,bp/reorganise-user-guides,"System architecture ~~~~~~~~~~~~~~~~~~~ The Telemetry module uses an agent-based architecture. Several modules combine their responsibilities to collect data, store samples in a database, or provide an API service for handling incoming requests. The Telemetry module is built from the following agents and services: ceilometer-api Presents aggregated metering data to consumers (such as billing engines, analytics tools and so forth). ceilometer-polling Polls for different kinds of meter data by using the polling plug-ins (pollsters) registered in different namespaces. ceilometer-agent-central Polls the public RESTful APIs of other OpenStack services such as Compute service and Image service, in order to keep tabs on resource existence, by using the polling plug-ins (pollsters) registered in the central polling namespace. ceilometer-agent-compute Polls the local hypervisor or libvirt daemon to acquire performance data for the local instances, messages and emits the data as AMQP messages, by using the polling plug-ins (pollsters) registered in the compute polling namespace. ceilometer-agent-ipmi Polls the local node with IPMI support, in order to acquire IPMI sensor data and Intel Node Manager data, by using the polling plug-ins (pollsters) registered in the IPMI polling namespace. ceilometer-agent-notification Consumes AMQP messages from other OpenStack services. ceilometer-collector Consumes AMQP notifications from the agents, then dispatches these data to the appropriate data store. ceilometer-alarm-evaluator Determines when alarms fire due to the associated statistic trend crossing a threshold over a sliding time window. ceilometer-alarm-notifier Initiates alarm actions, for example calling out to a webhook with a description of the alarm state transition. .. note:: The ceilometer-polling service is available since the Kilo release. Besides the ceilometer-agent-compute and the ceilometer-agent-ipmi service, all the other services are placed on one or more controller nodes. The Telemetry architecture highly depends on the AMQP service both for consuming notifications coming from OpenStack services and internal communication. | Supported databases ------------------- The other key external component of Telemetry is the database, where events, samples, alarm definitions and alarms are stored. .. note:: Multiple database back ends can be configured in order to store events, samples and alarms separately. The list of supported database back ends: - `ElasticSearch (events only) <http://www.elasticsearch.org/>`__ - `MongoDB <http://www.mongodb.org/>`__ - `MySQL <http://www.mysql.com/>`__ - `PostgreSQL <http://www.postgresql.org/>`__ - `HBase <http://hbase.apache.org/>`__ - `DB2 <http://www-01.ibm.com/software/data/db2/>`__ | Supported hypervisors --------------------- The Telemetry module collects information about the virtual machines, which requires close connection to the hypervisor that runs on the compute hosts. The list of supported hypervisors is: - The following hypervisors are supported via `Libvirt <http://libvirt.org/>`__: - `Kernel-based Virtual Machine (KVM) <http://www.linux-kvm.org/page/Main_Page>`__ - `Quick Emulator (QEMU) <http://wiki.qemu.org/Main_Page>`__ - `Linux Containers (LXC) <https://linuxcontainers.org/>`__ - `User-mode Linux (UML) <http://user-mode-linux.sourceforge.net/>`__ .. note:: For details about hypervisor support in libvirt please check the `Libvirt API support matrix <http://libvirt.org/hvsupport.html>`__. - `Hyper-V <http://www.microsoft.com/en-us/server-cloud/hyper-v-server/default.aspx>`__ - `XEN <http://www.xenproject.org/help/documentation.html>`__ - `VMWare vSphere <http://www.vmware.com/products/vsphere-hypervisor/support.html>`__ | Supported networking services ----------------------------- Telemetry is able to retrieve information from OpenStack Networking and external networking services: - OpenStack Networking: - Basic network meters - Firewall-as-a-Service (FWaaS) meters - Loadbalancer-as-a-Service (LBaaS) meters - VPN-as-a-Service (VPNaaS) meters - SDN controller meters: - `OpenDaylight <http://www.opendaylight.org/software>`__ - `OpenContrail <http://opencontrail.org/>`__ | Users, roles and tenants ------------------------ This module of OpenStack uses OpenStack Identity for authenticating and authorizing users. The required configuration options are listed in the `Telemetry section <http://docs.openstack.org/kilo/config-reference/content/ch_configuring-openstack-telemetry.html>`__ in the *OpenStack Configuration Reference*. Two roles are used in the system basically, which are the 'admin' and 'non-admin'. The authorization happens before processing each API request. The amount of returned data depends on the role the requestor owns. The creation of alarm definitions also highly depends on the role of the user, who initiated the action. Further details about alarm handling can be found in this guide. .. TODO (karenb) Add reference to telemetry-alarms. ",,171,1
openstack%2Fmagnum~master~I06146435eacff514b10fcc110eb7116f13690046,openstack/magnum,master,I06146435eacff514b10fcc110eb7116f13690046,Support use admin creds in KeystoneClientV3,MERGED,2015-06-18 09:31:24.000000000,2015-06-24 16:28:35.000000000,2015-06-24 16:28:35.000000000,"[{'_account_id': 3}, {'_account_id': 5638}, {'_account_id': 7049}, {'_account_id': 10206}, {'_account_id': 11536}, {'_account_id': 11650}, {'_account_id': 12175}, {'_account_id': 17023}]","[{'number': 1, 'created': '2015-06-18 09:31:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/magnum/commit/ca52f6050853b6543aa286983c4b04a930f669ae', 'message': 'Support use admin creds in KeystoneClientV3\n\nBy passing an admin_context to KeystoneClientV3, we can not use admin creds\nwhich configures in magnum.conf\n\nPartial-Implements: blueprint add-periodic-task\nCo-Authored-By: ShaoHe Feng <shaohe.feng@intel.com>\nChange-Id: I06146435eacff514b10fcc110eb7116f13690046\n'}, {'number': 2, 'created': '2015-06-23 06:33:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/magnum/commit/de56fe31284f5f3ae6bc99b20143b8506bf61398', 'message': 'Support use admin creds in KeystoneClientV3\n\nBy passing an admin_context to KeystoneClientV3, we can now use admin creds\nwhich configures in magnum.conf\n\nPartial-Implements: blueprint add-periodic-task\nCo-Authored-By: ShaoHe Feng <shaohe.feng@intel.com>\nChange-Id: I06146435eacff514b10fcc110eb7116f13690046\n'}, {'number': 3, 'created': '2015-06-24 03:53:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/magnum/commit/b410500bdaed3bcb7d519caaebb2fa04e9d025ea', 'message': 'Support use admin creds in KeystoneClientV3\n\nBy passing an admin_context to KeystoneClientV3, we can now use admin creds\nwhich configures in magnum.conf\n\nPartial-Implements: blueprint add-periodic-task\nCo-Authored-By: ShaoHe Feng <shaohe.feng@intel.com>\nChange-Id: I06146435eacff514b10fcc110eb7116f13690046\n'}, {'number': 4, 'created': '2015-06-24 08:19:10.000000000', 'files': ['magnum/tests/unit/common/test_magnum_keystoneclient.py', 'magnum/common/magnum_keystoneclient.py'], 'web_link': 'https://opendev.org/openstack/magnum/commit/e22d38b3aec9693c651c38ffc2fb5b2cfe88a059', 'message': 'Support use admin creds in KeystoneClientV3\n\nBy passing an admin_context to KeystoneClientV3, we can now use admin creds\nwhich configures in magnum.conf\n\nPartial-Implements: blueprint add-periodic-task\nCo-Authored-By: ShaoHe Feng <shaohe.feng@intel.com>\nChange-Id: I06146435eacff514b10fcc110eb7116f13690046\n'}]",6,193030,e22d38b3aec9693c651c38ffc2fb5b2cfe88a059,25,8,4,12175,,,0,"Support use admin creds in KeystoneClientV3

By passing an admin_context to KeystoneClientV3, we can now use admin creds
which configures in magnum.conf

Partial-Implements: blueprint add-periodic-task
Co-Authored-By: ShaoHe Feng <shaohe.feng@intel.com>
Change-Id: I06146435eacff514b10fcc110eb7116f13690046
",git fetch https://review.opendev.org/openstack/magnum refs/changes/30/193030/4 && git format-patch -1 --stdout FETCH_HEAD,"['magnum/tests/unit/common/test_magnum_keystoneclient.py', 'magnum/common/magnum_keystoneclient.py']",2,ca52f6050853b6543aa286983c4b04a930f669ae,bp/add-periodic-task, self._is_admin = context.is_admin if self._is_admin: return self.admin_client else: if not self._client: # Create connection to v3 API self._client = self._v3_client_init() return self._client, if not self._client: # Create connection to v3 API self._client = self._v3_client_init() return self._client,17,4
openstack%2Fastara-appliance~master~Iad2076beecb86dd27fe2630d4c2fbe9e8a0a97a4,openstack/astara-appliance,master,Iad2076beecb86dd27fe2630d4c2fbe9e8a0a97a4,Properly establish SNAT rules for VMs that have no Floating IP.,MERGED,2015-06-18 20:46:43.000000000,2015-06-24 16:14:36.000000000,2015-06-23 18:21:44.000000000,"[{'_account_id': 3}, {'_account_id': 986}, {'_account_id': 1420}, {'_account_id': 2592}, {'_account_id': 3208}, {'_account_id': 6287}, {'_account_id': 6923}, {'_account_id': 7878}, {'_account_id': 8005}]","[{'number': 1, 'created': '2015-06-18 20:46:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/astara-appliance/commit/d497db2d164911f66a917be458a2cc8d13db1893', 'message': 'Properly establish SNAT rules for VMs that have no Floating IP.\n\nThis fixes a bug whereby VMs *without* a Floating IP can not reach other VMs\nvia *their* Floating IP.\n\nChange-Id: Iad2076beecb86dd27fe2630d4c2fbe9e8a0a97a4\n'}, {'number': 2, 'created': '2015-06-22 15:08:20.000000000', 'files': ['test/unit/drivers/test_iptables.py', 'akanda/router/drivers/iptables.py'], 'web_link': 'https://opendev.org/openstack/astara-appliance/commit/047702d740145836ab8f09a111334b41717b6351', 'message': 'Properly establish SNAT rules for VMs that have no Floating IP.\n\nThis fixes a bug whereby VMs *without* a Floating IP can not reach other VMs\nvia *their* Floating IP.\n\nFixes-bug: #1467562\nChange-Id: Iad2076beecb86dd27fe2630d4c2fbe9e8a0a97a4\n'}]",0,193306,047702d740145836ab8f09a111334b41717b6351,17,9,2,8005,,,0,"Properly establish SNAT rules for VMs that have no Floating IP.

This fixes a bug whereby VMs *without* a Floating IP can not reach other VMs
via *their* Floating IP.

Fixes-bug: #1467562
Change-Id: Iad2076beecb86dd27fe2630d4c2fbe9e8a0a97a4
",git fetch https://review.opendev.org/openstack/astara-appliance refs/changes/06/193306/2 && git format-patch -1 --stdout FETCH_HEAD,"['test/unit/drivers/test_iptables.py', 'akanda/router/drivers/iptables.py']",2,d497db2d164911f66a917be458a2cc8d13db1893,193306," :rtype: akanda.router.models.Network :rtype: akanda.router.models.Network def get_internal_networks(self, config): ''' Returns the internal networks :rtype: [akanda.router.models.Network] ''' return self.networks_by_type(config, Network.TYPE_INTERNAL) for network in self.get_internal_networks(config): for network in self.get_internal_networks(config): for network in self.get_internal_networks(config): if rules: for network in self.get_internal_networks(config): for subnet in network.subnets: if subnet.cidr.version == 4: rules.append( Rule('-A POSTROUTING -s %s -j PUBLIC_SNAT' % ( subnet.cidr ), ip_version=4) ) external_network = self.get_external_network(config) for fip in external_network.floating_ips: # Add source NAT for VMs without floating IPs '-A PUBLIC_SNAT ! -o %s -j SNAT --to %s' % ( mgt_if.ifname, str(external_network.interface.first_v4) ),"," :rtype: akanda.router.models.Interface :rtype: akanda.router.models.Interface for network in self.networks_by_type(config, Network.TYPE_INTERNAL): for network in self.networks_by_type(config, Network.TYPE_INTERNAL): rules.append( Rule('-A POSTROUTING -s %s -j PUBLIC_SNAT' % ( fip.fixed_ip ), ip_version=4) ) for network in self.networks_by_type( config, Network.TYPE_INTERNAL ): for fip in self.get_external_network(config).floating_ips: # Add a masquerade catch-all for VMs without floating IPs '-A PUBLIC_SNAT ! -o %s -j MASQUERADE' % mgt_if.ifname,",35,19
openstack%2Fbifrost~master~I3c0c969c388c19bce85336ba304f42b5df181652,openstack/bifrost,master,I3c0c969c388c19bce85336ba304f42b5df181652,Drop use of 'oslo' namespace package,MERGED,2015-06-24 15:20:55.000000000,2015-06-24 16:12:09.000000000,2015-06-24 16:12:06.000000000,"[{'_account_id': 3}, {'_account_id': 5805}, {'_account_id': 11655}]","[{'number': 1, 'created': '2015-06-24 15:20:55.000000000', 'files': ['playbooks/inventory/bifrost_inventory.py'], 'web_link': 'https://opendev.org/openstack/bifrost/commit/6edb10eff6c1edae811425204f961009bbd67685', 'message': ""Drop use of 'oslo' namespace package\n\nThe Oslo libraries have moved all of their code out of the 'oslo'\nnamespace package into per-library packages. The namespace package was\nretained during kilo for backwards compatibility, but will be removed by\nthe liberty-2 milestone. This change removes the use of the namespace\npackage, replacing it with the new package names.\n\nThe patches in the libraries will be put on hold until application\npatches have landed, or L2, whichever comes first. At that point, new\nversions of the libraries without namespace packages will be released as\na major version update.\n\nPlease merge this patch, or an equivalent, before L2 to avoid problems\nwith those library releases.\n\nBlueprint: remove-namespace-packages\nhttps://blueprints.launchpad.net/oslo-incubator/+spec/remove-namespace-packages\n\nChange-Id: I3c0c969c388c19bce85336ba304f42b5df181652\n""}]",0,195143,6edb10eff6c1edae811425204f961009bbd67685,7,3,1,2472,,,0,"Drop use of 'oslo' namespace package

The Oslo libraries have moved all of their code out of the 'oslo'
namespace package into per-library packages. The namespace package was
retained during kilo for backwards compatibility, but will be removed by
the liberty-2 milestone. This change removes the use of the namespace
package, replacing it with the new package names.

The patches in the libraries will be put on hold until application
patches have landed, or L2, whichever comes first. At that point, new
versions of the libraries without namespace packages will be released as
a major version update.

Please merge this patch, or an equivalent, before L2 to avoid problems
with those library releases.

Blueprint: remove-namespace-packages
https://blueprints.launchpad.net/oslo-incubator/+spec/remove-namespace-packages

Change-Id: I3c0c969c388c19bce85336ba304f42b5df181652
",git fetch https://review.opendev.org/openstack/bifrost refs/changes/43/195143/1 && git format-patch -1 --stdout FETCH_HEAD,['playbooks/inventory/bifrost_inventory.py'],1,6edb10eff6c1edae811425204f961009bbd67685,bp/remove-namespace-packages,from oslo_config import cfg,from oslo.config import cfg,1,1
openstack-attic%2Fakanda~master~I5a5d8dadecc18055c343d341896d15afe4dc804f,openstack-attic/akanda,master,I5a5d8dadecc18055c343d341896d15afe4dc804f,update root readme,MERGED,2015-06-24 00:50:23.000000000,2015-06-24 16:11:36.000000000,2015-06-24 16:11:35.000000000,"[{'_account_id': 3}, {'_account_id': 1420}, {'_account_id': 8005}]","[{'number': 1, 'created': '2015-06-24 00:50:23.000000000', 'files': ['README.md'], 'web_link': 'https://opendev.org/openstack-attic/akanda/commit/389df3db50f099399849cecda35e0ea60422aa96', 'message': 'update root readme\n\nremoves reference to akanda-appliance-builder\nrepo whose function has been merged into\nakanda-appliance\n\nPartially Implements: blueprint liberty-doc-updates\n\nChange-Id: I5a5d8dadecc18055c343d341896d15afe4dc804f\n'}]",0,194895,389df3db50f099399849cecda35e0ea60422aa96,7,3,1,6923,,,0,"update root readme

removes reference to akanda-appliance-builder
repo whose function has been merged into
akanda-appliance

Partially Implements: blueprint liberty-doc-updates

Change-Id: I5a5d8dadecc18055c343d341896d15afe4dc804f
",git fetch https://review.opendev.org/openstack-attic/akanda refs/changes/95/194895/1 && git format-patch -1 --stdout FETCH_HEAD,['README.md'],1,389df3db50f099399849cecda35e0ea60422aa96,bp/liberty-doc-updates,, * [Akanda Appliance Builder] (https://github.com/stackforge/akanda-appliance-builder) - Various methods to build an Akanda appliance. ,0,3
openstack-attic%2Fakanda~master~I896c0a1e4ff1515a9acb61d2f9455e57087e468c,openstack-attic/akanda,master,I896c0a1e4ff1515a9acb61d2f9455e57087e468c,Updates outdated repo reference,MERGED,2015-06-24 01:01:43.000000000,2015-06-24 16:11:26.000000000,2015-06-24 16:11:26.000000000,"[{'_account_id': 3}, {'_account_id': 1420}, {'_account_id': 8005}]","[{'number': 1, 'created': '2015-06-24 01:01:43.000000000', 'files': ['docs/source/operation.rst'], 'web_link': 'https://opendev.org/openstack-attic/akanda/commit/7f8cd18fd12eea9f580689f3bc2a7348fcd3e0de', 'message': 'Updates outdated repo reference\n\nmodified reference to old akanda repo for\nsource based installation\n\nChange-Id: I896c0a1e4ff1515a9acb61d2f9455e57087e468c\nFixes-Bug: #1468151\n'}]",0,194900,7f8cd18fd12eea9f580689f3bc2a7348fcd3e0de,7,3,1,6923,,,0,"Updates outdated repo reference

modified reference to old akanda repo for
source based installation

Change-Id: I896c0a1e4ff1515a9acb61d2f9455e57087e468c
Fixes-Bug: #1468151
",git fetch https://review.opendev.org/openstack-attic/akanda refs/changes/00/194900/1 && git format-patch -1 --stdout FETCH_HEAD,['docs/source/operation.rst'],1,7f8cd18fd12eea9f580689f3bc2a7348fcd3e0de,bug/1468151, $ pip install -e git://github.com/stackforge/akanda-rug.git@stable/kilo#egg=akanda-rug, $ pip install -e git://github.com/akanda/akanda-rug.git@stable/juno#egg=akanda-rug,1,1
openstack%2Fbifrost~master~Ia0c69931e026e4939d75d6cf3aa446a592d66550,openstack/bifrost,master,Ia0c69931e026e4939d75d6cf3aa446a592d66550,Adding agent_ucs driver to the driver list,MERGED,2015-06-12 21:14:22.000000000,2015-06-24 16:08:33.000000000,2015-06-24 16:08:30.000000000,"[{'_account_id': 3}, {'_account_id': 5805}, {'_account_id': 11655}, {'_account_id': 12459}, {'_account_id': 13997}]","[{'number': 1, 'created': '2015-06-12 21:14:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/bifrost/commit/ece78932ce5b3fe23d71b91e3918472b0832cd76', 'message': 'Adding agent_ucs driver to the driver list\n\nChange-Id: Ia0c69931e026e4939d75d6cf3aa446a592d66550\n'}, {'number': 2, 'created': '2015-06-15 11:08:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/bifrost/commit/3c73bf455e65e916680ad46fab2e4b95957b0a81', 'message': 'Adding agent_ucs driver to the driver list\n\nDepends-On: Ic77c7c318888ffbda268610b71363a74e7f98d85\nChange-Id: Ia0c69931e026e4939d75d6cf3aa446a592d66550\n'}, {'number': 3, 'created': '2015-06-16 11:58:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/bifrost/commit/1341cb30ab9d40e6a7022f32a045c21587216f00', 'message': 'Adding agent_ucs driver to the driver list\n\nDepends-On: Ic77c7c318888ffbda268610b71363a74e7f98d85\nChange-Id: Ia0c69931e026e4939d75d6cf3aa446a592d66550\n'}, {'number': 4, 'created': '2015-06-17 15:25:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/bifrost/commit/4f4a430e7d66c710421da810916e799b83a43906', 'message': 'Adding agent_ucs driver to the driver list\n\nDepends-On: Ic77c7c318888ffbda268610b71363a74e7f98d85\nChange-Id: Ia0c69931e026e4939d75d6cf3aa446a592d66550\n'}, {'number': 5, 'created': '2015-06-17 17:31:51.000000000', 'files': ['requirements.txt', 'playbooks/roles/ironic-install/templates/ironic.conf.j2'], 'web_link': 'https://opendev.org/openstack/bifrost/commit/e8371af99647e11d7af4233222cf3b1f5f180a4d', 'message': 'Adding agent_ucs driver to the driver list\n\nDepends-On: Ic77c7c318888ffbda268610b71363a74e7f98d85\nChange-Id: Ia0c69931e026e4939d75d6cf3aa446a592d66550\n'}]",0,191219,e8371af99647e11d7af4233222cf3b1f5f180a4d,23,5,5,11655,,,0,"Adding agent_ucs driver to the driver list

Depends-On: Ic77c7c318888ffbda268610b71363a74e7f98d85
Change-Id: Ia0c69931e026e4939d75d6cf3aa446a592d66550
",git fetch https://review.opendev.org/openstack/bifrost refs/changes/19/191219/2 && git format-patch -1 --stdout FETCH_HEAD,"['requirements.txt', 'playbooks/roles/ironic-install/templates/ironic.conf.j2']",2,ece78932ce5b3fe23d71b91e3918472b0832cd76,feature/drivers,"enabled_drivers=agent_ssh,agent_ipmitool,pxe_amt,agent_ilo,agent_ucsenabled_drivers=agent_ipmitool,pxe_amt,agent_ilo,agent_ucs","enabled_drivers=agent_ssh,agent_ipmitool,pxe_amt,agent_iloenabled_drivers=agent_ipmitool,pxe_amt,agent_ilo",3,2
openstack%2Fzaqar~master~I547bc7b2a013eded3dcdfa332079404d228545d0,openstack/zaqar,master,I547bc7b2a013eded3dcdfa332079404d228545d0,Initial commit of swift backend,ABANDONED,2015-06-10 16:56:13.000000000,2015-06-24 16:03:31.000000000,,"[{'_account_id': 3}, {'_account_id': 12321}]","[{'number': 1, 'created': '2015-06-10 16:56:13.000000000', 'files': ['zaqar/storage/swift/options.py', 'zaqar/storage/swift/messages.py', 'zaqar/storage/swift/controllers.py', 'zaqar/storage/swift/driver.py', 'etc/oslo-config-generator/zaqar.conf', 'setup.cfg', 'zaqar/storage/swift/__init__.py'], 'web_link': 'https://opendev.org/openstack/zaqar/commit/f8bf37a53c2fcf81396e56bf733de6eed13d41e9', 'message': 'Initial commit of swift backend\n\nEnables:\n* Message expiry\n* Message listing\n* Batch operations by message ID\n* queue creation\n\nTodo:\n\n* Claims\n* Sharding queues\n* Use swift vendor prefixes to enable multitenancy\n\nChange-Id: I547bc7b2a013eded3dcdfa332079404d228545d0\nDepends-On: I692c35dcf217bede557ac463b2388f9a60d96c79\n'}]",0,190261,f8bf37a53c2fcf81396e56bf733de6eed13d41e9,4,2,1,12321,,,0,"Initial commit of swift backend

Enables:
* Message expiry
* Message listing
* Batch operations by message ID
* queue creation

Todo:

* Claims
* Sharding queues
* Use swift vendor prefixes to enable multitenancy

Change-Id: I547bc7b2a013eded3dcdfa332079404d228545d0
Depends-On: I692c35dcf217bede557ac463b2388f9a60d96c79
",git fetch https://review.opendev.org/openstack/zaqar refs/changes/61/190261/1 && git format-patch -1 --stdout FETCH_HEAD,"['zaqar/storage/swift/options.py', 'zaqar/storage/swift/messages.py', 'zaqar/storage/swift/controllers.py', 'zaqar/storage/swift/driver.py', 'etc/oslo-config-generator/zaqar.conf', 'setup.cfg', 'zaqar/storage/swift/__init__.py']",7,f8bf37a53c2fcf81396e56bf733de6eed13d41e9,,,,462,1
openstack%2Fbifrost~master~I3724d89d801930086234e3eea9720bac94210d53,openstack/bifrost,master,I3724d89d801930086234e3eea9720bac94210d53,Make git URLs consistent with each other,MERGED,2015-06-23 23:55:34.000000000,2015-06-24 16:01:39.000000000,2015-06-24 16:01:37.000000000,"[{'_account_id': 3}, {'_account_id': 5805}, {'_account_id': 11555}, {'_account_id': 11655}]","[{'number': 1, 'created': '2015-06-23 23:55:34.000000000', 'files': ['playbooks/roles/ironic-install/defaults/main.yml'], 'web_link': 'https://opendev.org/openstack/bifrost/commit/9c045c3dab133e1e440e0fd7999bfb77d7ddd973', 'message': 'Make git URLs consistent with each other\n\nFix shade and ironicclient URLs to match the other git URLs provided\nin bifrost for installation from source.\n\nChange-Id: I3724d89d801930086234e3eea9720bac94210d53\n'}]",0,194881,9c045c3dab133e1e440e0fd7999bfb77d7ddd973,8,4,1,12459,,,0,"Make git URLs consistent with each other

Fix shade and ironicclient URLs to match the other git URLs provided
in bifrost for installation from source.

Change-Id: I3724d89d801930086234e3eea9720bac94210d53
",git fetch https://review.opendev.org/openstack/bifrost refs/changes/81/194881/1 && git format-patch -1 --stdout FETCH_HEAD,['playbooks/roles/ironic-install/defaults/main.yml'],1,9c045c3dab133e1e440e0fd7999bfb77d7ddd973,repo-urls,ironicclient_git_url: https://git.openstack.org/openstack/python-ironicclient shade_git_url: https://git.openstack.org/openstack-infra/shade,ironicclient_git_url: https://review.openstack.org/openstack/python-ironicclient shade_git_url: https://review.openstack.org/openstack-infra/shade,2,2
openstack%2Fnetworking-ovn~master~I23827eeb2acc8ec22071094dd21fa6807806769c,openstack/networking-ovn,master,I23827eeb2acc8ec22071094dd21fa6807806769c,Disable apparmor for libvirtd.,MERGED,2015-06-18 21:57:26.000000000,2015-06-24 15:54:55.000000000,2015-06-24 15:54:53.000000000,"[{'_account_id': 3}, {'_account_id': 1561}, {'_account_id': 4395}, {'_account_id': 11343}]","[{'number': 1, 'created': '2015-06-18 21:57:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/networking-ovn/commit/741781ff922d094372bfddd1e032e4d8c8d52fa4', 'message': 'TEST\n\nChange-Id: I23827eeb2acc8ec22071094dd21fa6807806769c\n'}, {'number': 2, 'created': '2015-06-22 20:15:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/networking-ovn/commit/aa154b85779cec188bcb76105a99dea63bfd05de', 'message': 'Disable apparmor for libvirtd.\n\nOur devstack integration currently installs ovs from source and breaks\napparmor.  Disable apparmor for libvirtd, which is where we see the\nproblems.\n\nChange-Id: I23827eeb2acc8ec22071094dd21fa6807806769c\nCo-authored-by: Russell Bryant <rbryant@redhat.com>\n'}, {'number': 3, 'created': '2015-06-22 20:16:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/networking-ovn/commit/3452b58d5338f73c1e4ed79b41cac7c028f402d3', 'message': 'Disable apparmor for libvirtd.\n\nOur devstack integration currently installs ovs from source and breaks\napparmor.  Disable apparmor for libvirtd, which is where we see the\nproblems.\n\nChange-Id: I23827eeb2acc8ec22071094dd21fa6807806769c\nCo-authored-by: Russell Bryant <rbryant@redhat.com>\n'}, {'number': 4, 'created': '2015-06-22 20:18:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/networking-ovn/commit/2cc826ca48b489e0208ed820c1ed5a59d90ecc01', 'message': 'Disable apparmor for libvirtd.\n\nOur devstack integration currently installs ovs from source and breaks\napparmor.  Disable apparmor for libvirtd, which is where we see the\nproblems.\n\nChange-Id: I23827eeb2acc8ec22071094dd21fa6807806769c\nCo-authored-by: Russell Bryant <rbryant@redhat.com>\nCloses-bug: #1466631\n'}, {'number': 5, 'created': '2015-06-22 21:10:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/networking-ovn/commit/b69470280f5c6f875eaa2e4eaecccf6f15861667', 'message': 'Disable apparmor for libvirtd.\n\nOur devstack integration currently installs ovs from source and breaks\napparmor.  Disable apparmor for libvirtd, which is where we see the\nproblems.\n\nChange-Id: I23827eeb2acc8ec22071094dd21fa6807806769c\nCo-authored-by: Russell Bryant <rbryant@redhat.com>\nCloses-bug: #1466631\n'}, {'number': 6, 'created': '2015-06-23 00:44:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/networking-ovn/commit/335dfbef4e7954d20e88fb9f4817d718629cb819', 'message': 'Disable apparmor for libvirtd.\n\nOur devstack integration currently installs ovs from source and breaks\napparmor.  Disable apparmor for libvirtd, which is where we see the\nproblems.\n\nChange-Id: I23827eeb2acc8ec22071094dd21fa6807806769c\nCo-authored-by: Russell Bryant <rbryant@redhat.com>\nCloses-bug: #1466631\n'}, {'number': 7, 'created': '2015-06-23 01:11:16.000000000', 'files': ['devstack/plugin.sh'], 'web_link': 'https://opendev.org/openstack/networking-ovn/commit/3ce863affbc98582932f32a1cc62309bb40805a1', 'message': 'Disable apparmor for libvirtd.\n\nOur devstack integration currently installs ovs from source and breaks\napparmor.  Disable apparmor for libvirtd, which is where we see the\nproblems.\n\nChange-Id: I23827eeb2acc8ec22071094dd21fa6807806769c\nCo-authored-by: Russell Bryant <rbryant@redhat.com>\nCloses-bug: #1466631\n'}]",0,193330,3ce863affbc98582932f32a1cc62309bb40805a1,23,4,7,4395,,,0,"Disable apparmor for libvirtd.

Our devstack integration currently installs ovs from source and breaks
apparmor.  Disable apparmor for libvirtd, which is where we see the
problems.

Change-Id: I23827eeb2acc8ec22071094dd21fa6807806769c
Co-authored-by: Russell Bryant <rbryant@redhat.com>
Closes-bug: #1466631
",git fetch https://review.opendev.org/openstack/networking-ovn refs/changes/30/193330/1 && git format-patch -1 --stdout FETCH_HEAD,['devstack/plugin.sh'],1,741781ff922d094372bfddd1e032e4d8c8d52fa4,193330,function disable_libvirt_apparmor { # NOTE(arosen): This is used as a work around to allow newer versions # of libvirt to work with ovs configured ports. See LP#1466631. # requires the apparmor-utils install_package apparmor-utils # disables apparmor for libvirtd sudo aa-complain /etc/apparmor.d/usr.sbin.libvirtd } disable_libvirt_apparmor,,10,0
openstack%2Ftempest~master~Iccc827c6a50ea79de26cc0e8e00d83fe2498c858,openstack/tempest,master,Iccc827c6a50ea79de26cc0e8e00d83fe2498c858,More javelin unit tests,MERGED,2015-06-01 13:55:51.000000000,2015-06-24 15:53:52.000000000,2015-06-24 15:53:49.000000000,"[{'_account_id': 3}, {'_account_id': 5196}, {'_account_id': 5689}, {'_account_id': 5803}, {'_account_id': 7020}, {'_account_id': 8871}, {'_account_id': 10385}]","[{'number': 1, 'created': '2015-06-01 13:55:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/785ad5560c3f119c9e11ccd2fa68bcaf9a57f46d', 'message': 'More javelin unit tests\n\nImproving test coverage of Javelin by covering more resources:\n\n* routers: create/destroy\n* secgroups: create/destroy\n* subnets: destroy\n\nChange-Id: Iccc827c6a50ea79de26cc0e8e00d83fe2498c858\n'}, {'number': 2, 'created': '2015-06-15 15:22:19.000000000', 'files': ['tempest/tests/cmd/test_javelin.py'], 'web_link': 'https://opendev.org/openstack/tempest/commit/94fd9699f8557afd790e9708b09dbf0da537dfd0', 'message': 'More javelin unit tests\n\nImproving test coverage of Javelin by covering more resources:\n\n* routers: create/destroy\n* secgroups: create/destroy\n* subnets: destroy\n\nChange-Id: Iccc827c6a50ea79de26cc0e8e00d83fe2498c858\n'}]",0,187198,94fd9699f8557afd790e9708b09dbf0da537dfd0,14,7,2,7020,,,0,"More javelin unit tests

Improving test coverage of Javelin by covering more resources:

* routers: create/destroy
* secgroups: create/destroy
* subnets: destroy

Change-Id: Iccc827c6a50ea79de26cc0e8e00d83fe2498c858
",git fetch https://review.opendev.org/openstack/tempest refs/changes/98/187198/1 && git format-patch -1 --stdout FETCH_HEAD,['tempest/tests/cmd/test_javelin.py'],1,785ad5560c3f119c9e11ccd2fa68bcaf9a57f46d,javunittest_routsecgroup," def test_create_router(self): self.fake_client.networks.list_routers.return_value = {'routers': []} self.useFixture(mockpatch.PatchObject(javelin, ""client_for_user"", return_value=self.fake_client)) javelin.create_routers([self.fake_object]) mocked_function = self.fake_client.networks.create_router mocked_function.assert_called_once_with(self.fake_object['name']) def test_create_router_existing(self): self.fake_client.networks.list_routers.return_value = { 'routers': [self.fake_object]} self.useFixture(mockpatch.PatchObject(javelin, ""client_for_user"", return_value=self.fake_client)) javelin.create_routers([self.fake_object]) mocked_function = self.fake_client.networks.create_router self.assertFalse(mocked_function.called) def test_create_secgroup(self): self.useFixture(mockpatch.PatchObject(javelin, ""client_for_user"", return_value=self.fake_client)) self.fake_client.secgroups.list_security_groups.return_value = [] self.fake_client.secgroups.create_security_group.return_value = \ {'id': self.fake_object['secgroup_id']} javelin.create_secgroups([self.fake_object]) mocked_function = self.fake_client.secgroups.create_security_group mocked_function.assert_called_once_with( self.fake_object['name'], self.fake_object['description']) fake_auth = self.fake_client fake_auth = self.fake_client self.fake_client.objects.delete_object.return_value = \ {'status': ""200""}, """" return_value=self.fake_client)) mocked_function = self.fake_client.objects.delete_object return_value=self.fake_client)) mocked_function = self.fake_client.images.delete_image return_value=self.fake_client)) mocked_function = self.fake_client.networks.delete_network def test_destroy_subnets(self): self.useFixture(mockpatch.PatchObject(javelin, ""client_for_user"", return_value=self.fake_client)) fake_subnet_id = self.fake_object['subnet_id'] self.useFixture(mockpatch.PatchObject(javelin, ""_get_resource_by_name"", return_value={ 'id': fake_subnet_id})) javelin.destroy_subnets([self.fake_object]) mocked_function = self.fake_client.networks.delete_subnet mocked_function.assert_called_once_with(fake_subnet_id) def test_destroy_routers(self): self.useFixture(mockpatch.PatchObject(javelin, ""client_for_user"", return_value=self.fake_client)) # this function is used on 2 different occasions in the code def _fake_get_resource_by_name(*args): if args[1] == ""routers"": return {""id"": self.fake_object['router_id']} elif args[1] == ""subnets"": return {""id"": self.fake_object['subnet_id']} javelin._get_resource_by_name = _fake_get_resource_by_name javelin.destroy_routers([self.fake_object]) mocked_function = self.fake_client.networks.delete_router mocked_function.assert_called_once_with( self.fake_object['router_id']) def test_destroy_secgroup(self): self.useFixture(mockpatch.PatchObject(javelin, ""client_for_user"", return_value=self.fake_client)) fake_secgroup = {'id': self.fake_object['id']} self.useFixture(mockpatch.PatchObject(javelin, ""_get_resource_by_name"", return_value=fake_secgroup)) javelin.destroy_secgroups([self.fake_object]) mocked_function = self.fake_client.secgroups.delete_security_group mocked_function.assert_called_once_with(self.fake_object['id'])"," fake_auth = mock.MagicMock() fake_auth = mock.MagicMock() fake_client = mock.MagicMock() fake_client.objects.delete_object.return_value = {'status': ""200""}, """" return_value=fake_client)) mocked_function = fake_client.objects.delete_object fake_client = mock.MagicMock() return_value=fake_client)) mocked_function = fake_client.images.delete_image fake_client = mock.MagicMock() return_value=fake_client)) mocked_function = fake_client.networks.delete_network",90,13
openstack%2Ffuel-specs~master~I5c828db86287dc7ca440e2b51596333d862d0008,openstack/fuel-specs,master,I5c828db86287dc7ca440e2b51596333d862d0008,Spec for Openstack Environment Dashboard,MERGED,2015-05-05 14:50:03.000000000,2015-06-24 15:51:13.000000000,2015-06-24 15:51:12.000000000,"[{'_account_id': 3}, {'_account_id': 6794}, {'_account_id': 8735}, {'_account_id': 8749}, {'_account_id': 8766}, {'_account_id': 8782}, {'_account_id': 8954}, {'_account_id': 8970}, {'_account_id': 9091}, {'_account_id': 9147}, {'_account_id': 9730}, {'_account_id': 12847}, {'_account_id': 15315}]","[{'number': 1, 'created': '2015-05-05 14:50:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-specs/commit/a94697fda23cf8033a55b93f5eb20b823fe4ff06', 'message': 'Post Deployment Dashboard specification\n\nChange-Id: I5c828db86287dc7ca440e2b51596333d862d0008\n'}, {'number': 2, 'created': '2015-05-06 12:15:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-specs/commit/bec00ce7f57435d69778ad1bca22bd0dd94d15b5', 'message': 'Post Deployment Dashboard specification\n\nBlueprint post-deployment-dashboard\n\nChange-Id: I5c828db86287dc7ca440e2b51596333d862d0008\n'}, {'number': 3, 'created': '2015-05-06 15:27:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-specs/commit/25e2b8ba78c02f17cb7af7e13e454067a0d02b70', 'message': 'Post Deployment Dashboard specification\n\nBlueprint post-deployment-dashboard\n\nChange-Id: I5c828db86287dc7ca440e2b51596333d862d0008\n'}, {'number': 4, 'created': '2015-05-07 13:00:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-specs/commit/2605799f450fad8958104764d2fc729c035d15d2', 'message': 'Post Deployment Dashboard specification\n\nBlueprint post-deployment-dashboard\n\nChange-Id: I5c828db86287dc7ca440e2b51596333d862d0008\n'}, {'number': 5, 'created': '2015-05-13 10:56:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-specs/commit/99aec5eda8bb3d159415b35e997fc11450faf38e', 'message': 'Post Deployment Dashboard specification\n\nBlueprint post-deployment-dashboard\n\nChange-Id: I5c828db86287dc7ca440e2b51596333d862d0008\n'}, {'number': 6, 'created': '2015-05-13 11:33:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-specs/commit/91eb490ec6617c0729b5318c831f0880863f79e4', 'message': 'Cluster Dashboard specification\n\nBlueprint post-deployment-dashboard\n\nChange-Id: I5c828db86287dc7ca440e2b51596333d862d0008\n'}, {'number': 7, 'created': '2015-05-13 12:55:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-specs/commit/0f7fc05337bfc69e3e91f65fc683deb2b4f086df', 'message': 'Cluster Dashboard specification\n\nBlueprint post-deployment-dashboard\n\nChange-Id: I5c828db86287dc7ca440e2b51596333d862d0008\n'}, {'number': 8, 'created': '2015-05-19 14:22:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-specs/commit/33ad7a9075b37e19d92ab093fa5a7f2b21d814d9', 'message': 'Cluster Dashboard specification\n\nBlueprint post-deployment-dashboard\n\nChange-Id: I5c828db86287dc7ca440e2b51596333d862d0008\n'}, {'number': 9, 'created': '2015-05-21 12:44:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-specs/commit/eb1a0934e93636115be7bc74d08cd3c7f7521b35', 'message': 'Cluster Dashboard specification\n\nBlueprint post-deployment-dashboard\n\nChange-Id: I5c828db86287dc7ca440e2b51596333d862d0008\n'}, {'number': 10, 'created': '2015-06-03 10:07:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-specs/commit/de5768a2f78067d880307eb203772752c51c7f57', 'message': 'Openstack Environment Dashboard specification\n\nBlueprint post-deployment-dashboard\n\nChange-Id: I5c828db86287dc7ca440e2b51596333d862d0008\n'}, {'number': 11, 'created': '2015-06-15 17:07:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-specs/commit/4a29dd68a38db828711333d9bcd457ca899dd31f', 'message': 'Spec for Openstack Environment Dashboard\n\n - without mockups for now\n\n addin a new tab on Fuel UI - an entry point for plugins and a\n place with cluster cummulated information, proposed actions,\n documentation links\n\nBlueprint post-deployment-dashboard\n\nChange-Id: I5c828db86287dc7ca440e2b51596333d862d0008\n'}, {'number': 12, 'created': '2015-06-16 15:44:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-specs/commit/492884039929f1e970e7281ef3c083bde0b783f0', 'message': 'Spec for Openstack Environment Dashboard\n\n - without mockups for now\n\n addin a new tab on Fuel UI - an entry point for plugins and a\n place with OpenStack environment cumulated information,\n proposed actions, documentation links\n\nBlueprint post-deployment-dashboard\n\nChange-Id: I5c828db86287dc7ca440e2b51596333d862d0008\n'}, {'number': 13, 'created': '2015-06-17 14:09:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-specs/commit/6d5181ae61201c9de35b22c834c043e431b17d31', 'message': 'Spec for Openstack Environment Dashboard\n\n - without mockups for now\n\n addin a new tab on Fuel UI - an entry point for plugins and a\n place with OpenStack environment cumulated information,\n proposed actions, documentation links\n\nBlueprint post-deployment-dashboard\n\nChange-Id: I5c828db86287dc7ca440e2b51596333d862d0008\n'}, {'number': 14, 'created': '2015-06-18 13:52:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-specs/commit/7fd2e4264c1a3a8a19a02f9c0ffd5da1f00534e6', 'message': 'Spec for Openstack Environment Dashboard\n\n - without mockups for now\n\n addin a new tab on Fuel UI - an entry point for plugins and a\n place with OpenStack environment cumulated information,\n proposed actions, documentation links\n\nBlueprint post-deployment-dashboard\n\nChange-Id: I5c828db86287dc7ca440e2b51596333d862d0008\n'}, {'number': 15, 'created': '2015-06-19 11:23:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-specs/commit/b405fffe6cfe6071935d6611d70a77a426d716e3', 'message': 'Spec for Openstack Environment Dashboard\n\n adding a new tab on Fuel UI - an entry point for plugins and a\n place with OpenStack environment cumulated information,\n proposed actions, documentation links\n\nBlueprint post-deployment-dashboard\n\nChange-Id: I5c828db86287dc7ca440e2b51596333d862d0008\n'}, {'number': 16, 'created': '2015-06-19 14:50:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-specs/commit/6805bd8c42f610445a93163ab6d41eb14f5e93a1', 'message': 'Spec for Openstack Environment Dashboard\n\n adding a new tab on Fuel UI - an entry point for plugins and a\n place with OpenStack environment cumulated information,\n proposed actions, documentation links\n\nBlueprint post-deployment-dashboard\n\nChange-Id: I5c828db86287dc7ca440e2b51596333d862d0008\n'}, {'number': 17, 'created': '2015-06-23 10:57:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-specs/commit/39095c2dda4606827c422adde6693676e6d8e697', 'message': 'Spec for Openstack Environment Dashboard\n\n adding a new tab on Fuel UI - an entry point for plugins and a\n place with OpenStack environment cumulated information,\n proposed actions, documentation links\n\nBlueprint post-deployment-dashboard\n\nChange-Id: I5c828db86287dc7ca440e2b51596333d862d0008\n\nPost Deployment Dashboard specification\n\nBlueprint post-deployment-dashboard\n\nChange-Id: I5c828db86287dc7ca440e2b51596333d862d0008\n\nSpec for Openstack Environment Dashboard\n\n adding a new tab on Fuel UI - an entry point for plugins and a\n place with OpenStack environment cumulated information,\n proposed actions, documentation links\n\nBlueprint post-deployment-dashboard\n\nChange-Id: I5c828db86287dc7ca440e2b51596333d862d0008\n'}, {'number': 18, 'created': '2015-06-23 10:58:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-specs/commit/d8c99f92ab69d16b266625e7255590d2b34f4536', 'message': 'Spec for Openstack Environment Dashboard\n\n adding a new tab on Fuel UI - an entry point for plugins and a\n place with OpenStack environment cumulated information,\n proposed actions, documentation links\n\nBlueprint post-deployment-dashboard\n\nChange-Id: I5c828db86287dc7ca440e2b51596333d862d0008\n'}, {'number': 19, 'created': '2015-06-24 12:24:49.000000000', 'files': ['specs/7.0/fuel-ui-dashboard.rst', 'images/7.0/fuel-ui-dashboard/deployment_in_progress.png', 'images/7.0/fuel-ui-dashboard/deployment_warnings.png', 'images/7.0/fuel-ui-dashboard/new_cluster.png', 'images/7.0/fuel-ui-dashboard/deployment_success.jpg'], 'web_link': 'https://opendev.org/openstack/fuel-specs/commit/cd6524b8ea48896a36b11eca0dbcd777d8cb3267', 'message': 'Spec for Openstack Environment Dashboard\n\n adding a new tab on Fuel UI - an entry point for plugins and a\n place with OpenStack environment cumulated information,\n proposed actions, documentation links\n\nBlueprint post-deployment-dashboard\n\nChange-Id: I5c828db86287dc7ca440e2b51596333d862d0008\n'}]",190,180181,cd6524b8ea48896a36b11eca0dbcd777d8cb3267,89,13,19,9091,,,0,"Spec for Openstack Environment Dashboard

 adding a new tab on Fuel UI - an entry point for plugins and a
 place with OpenStack environment cumulated information,
 proposed actions, documentation links

Blueprint post-deployment-dashboard

Change-Id: I5c828db86287dc7ca440e2b51596333d862d0008
",git fetch https://review.opendev.org/openstack/fuel-specs refs/changes/81/180181/19 && git format-patch -1 --stdout FETCH_HEAD,['specs/7.0/post-deployment-dashboard.rst'],1,a94697fda23cf8033a55b93f5eb20b823fe4ff06,bp/post-deployment-dashboard,".. This work is licensed under a Creative Commons Attribution 3.0 Unported License. http://creativecommons.org/licenses/by/3.0/legalcode ========================================== Post Deployment Support ========================================== https://blueprints.launchpad.net/fuel/+spec/post-deployment-dashboard Create a single entry point for user to have access to all the necessary information after deployment. Problem description =================== After deployment is done typical Fuel user doesn't know what to do next. So, with this new tab he will get the basic instructions on what to do next. It should become visible and default only after cluster deployment. This would be a simple dashboard on tab with plugin information after deployment - with links to Horizon, any plugins. Should be extensible for future plugins. Proposed change =============== For nailgun ----------- Provide API with links to all possible necessary resources after cluster deployment (list of them to be discussed). Should be pluggable. For UI developers - Implement design and layout with the data provided from nailgun and short useful descriptions. Alternatives ------------ As one of the alternatives can be considered `global` dashboard, not only with after-deployment tasks, but this approach appears to be not as agile and versatile as post-deployment dashboard. Also, it rises a lot of unanswered questions about contents of this tab and its neccessity in terms of not repeating your self with already existing tabs functionality. Data model impact ----------------- None. REST API impact --------------- Might require some changes, but to be discussed. All optimization have to be backward compatible. Should support GET - request providing the list of entry point for further usage. e.g. GET /post_deployment_tasks POST/PUT/DELETE are unlikely to be supported. Ok code 200, server error code starting from 500. No parameters expected. JSON format, something like: http://paste.openstack.org/show/214983/ Upgrade impact -------------- Only if database is changed, but unlikely. Security impact --------------- None Notifications impact -------------------- Unlikely. Other end user impact --------------------- Will improve user experience for after deployment scenarios. Unlikely to impact python-fuelclient. Performance Impact ------------------ None. Plugin impact --------------------- Will provide an entry point for plugins to access post-deployment dashboard. Other deployer impact --------------------- Better UX. Developer impact ---------------- None. Implementation ============== Assignee(s) ----------- Primary assignee: astepanchuk@mirantis.com Other contributors (design): * Bogdan Dudko <bdudko@mirantis.com> * Steve Doll <sdoll@mirantis.com> Approver: * Nathan Trueblood <ntrueblood@mirantis.com> Reviewer: * Vitaly Kramskikh <vkramskikh@mirantis.com> Work Items ---------- Blueprint will be implemented in several stages: * Initial design and logic approval * Markup implementation with logic Dependencies ============ None Testing ======= Probably test should be created for new APi items. UI side should also be covered with tests. Aceptance criteria ------------------ After my OpenStack deployment has successfully completed, the default tab displayed shows links out to all relevant dashboards (Horizon, Murano, plugin UIs). If plugins were included, links should include plugin-relevant UIs. Changing plugin settings and/or removing plugins is not a part of this page. Documentation Impact ==================== Part about post-deployment should be updated. References ========== 1. https://blueprints.launchpad.net/fuel/+spec/post-deployment-dashboard ",,175,0
openstack%2Ffuel-library~stable%2F6.0~Ibbbfa3a5331f865e48160c37e9ba558af19dc680,openstack/fuel-library,stable/6.0,Ibbbfa3a5331f865e48160c37e9ba558af19dc680,Fix the way q-agent-cleanup executes shell processes,MERGED,2015-06-16 10:04:04.000000000,2015-06-24 15:45:03.000000000,2015-06-24 15:45:01.000000000,"[{'_account_id': 3}, {'_account_id': 5950}, {'_account_id': 8786}, {'_account_id': 8971}, {'_account_id': 14168}]","[{'number': 1, 'created': '2015-06-16 10:04:04.000000000', 'files': ['deployment/puppet/cluster/files/q-agent-cleanup.py'], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/01d3498ab1cb26cee606ecada8906f218d838c26', 'message': 'Fix the way q-agent-cleanup executes shell processes\n\nShell commands are executed via subprocess.Popen(). Currently the\nstatus of process is tracked by wait() method which results in deadlocks\nwhen output is large enough (tens of kB). The correct way is to use\ncommunicate() method.\n\nPartial-bug 1436414\n\nChange-Id: Ibbbfa3a5331f865e48160c37e9ba558af19dc680\n'}]",0,192128,01d3498ab1cb26cee606ecada8906f218d838c26,12,5,1,7604,,,0,"Fix the way q-agent-cleanup executes shell processes

Shell commands are executed via subprocess.Popen(). Currently the
status of process is tracked by wait() method which results in deadlocks
when output is large enough (tens of kB). The correct way is to use
communicate() method.

Partial-bug 1436414

Change-Id: Ibbbfa3a5331f865e48160c37e9ba558af19dc680
",git fetch https://review.opendev.org/openstack/fuel-library refs/changes/28/192128/1 && git format-patch -1 --stdout FETCH_HEAD,['deployment/puppet/cluster/files/q-agent-cleanup.py'],1,01d3498ab1cb26cee606ecada8906f218d838c26,bug/1436414," def _execute(self, cmd): (stdout, stderr) = process.communicate() ret_code = process.returncode if ret_code != 0: ""ERROR (rc={0}) while execution {1}, stderr: {2}"".format( ret_code, ' '.join(cmd), stderr)) return None return ret_code, stdout def __collect_namespaces_for_agent(self, agent): cmd = self.CMD__ip_netns_list[:] self.log.debug(""Execute command '{0}'"".format(' '.join(cmd))) ret_code, stdout = self._execute(cmd) if ret_code != 0: ret_code, stdout = self._execute(cmd) if ret_code != 0: self._execute(cmd)"," def __collect_namespaces_for_agent(self, agent): cmd = self.CMD__ip_netns_list[:] self.log.debug(""Execute command '{0}'"".format(' '.join(cmd))) rc = process.wait() if rc != 0: ""ERROR (rc={0}) while execution {1}"".format( rc, ' '.join(cmd))) stdout = process.communicate()[0] process = subprocess.Popen( cmd, shell=False, stdout=subprocess.PIPE, stderr=subprocess.PIPE ) rc = process.wait() if rc != 0: self.log.error( ""ERROR (rc={0}) while execution {1}"".format( rc, ' '.join(cmd))) stdout = process.communicate()[0] process = subprocess.Popen( cmd, shell=False, stdout=subprocess.PIPE, stderr=subprocess.PIPE ) rc = process.wait() if rc != 0: self.log.error( ""ERROR (rc={0}) while execution {1}"".format( rc, ' '.join(cmd)))",17,31
openstack%2Ffuel-library~stable%2F6.0~Iee0968a079deacef24b56f34e9314b0ebecad0ae,openstack/fuel-library,stable/6.0,Iee0968a079deacef24b56f34e9314b0ebecad0ae,Remove openrc/admin-token usage in q-agent-cleanup.py,MERGED,2015-06-16 10:04:04.000000000,2015-06-24 15:44:45.000000000,2015-06-24 15:44:45.000000000,"[{'_account_id': 3}, {'_account_id': 6072}, {'_account_id': 8786}, {'_account_id': 8797}, {'_account_id': 8971}]","[{'number': 1, 'created': '2015-06-16 10:04:04.000000000', 'files': ['deployment/puppet/cluster/files/test_q_agent_cleanup.py', 'deployment/puppet/cluster/files/q-agent-cleanup.py'], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/fa790193cbe218539ba341080815c4ead5a7fd12', 'message': 'Remove openrc/admin-token usage in q-agent-cleanup.py\n\nRemoves the openrc/admin-token deps in q-agent-cleanup.py. Instead it will\nread the neutron service credentials out of neutron.conf. This has the\nadvantage that it must be up to date for neutron to function so if the\ncredential is modified it will have to be updated by the administrator.\n\nRelated-bug: #1347542\nCloses-bug: #1396594\n\nConflicts:\n\tdeployment/puppet/cluster/files/q-agent-cleanup.py\n\tutils/jenkins/python-test-requirements.txt\n\nChange-Id: Iee0968a079deacef24b56f34e9314b0ebecad0ae\n'}]",0,192127,fa790193cbe218539ba341080815c4ead5a7fd12,11,5,1,7604,,,0,"Remove openrc/admin-token usage in q-agent-cleanup.py

Removes the openrc/admin-token deps in q-agent-cleanup.py. Instead it will
read the neutron service credentials out of neutron.conf. This has the
advantage that it must be up to date for neutron to function so if the
credential is modified it will have to be updated by the administrator.

Related-bug: #1347542
Closes-bug: #1396594

Conflicts:
	deployment/puppet/cluster/files/q-agent-cleanup.py
	utils/jenkins/python-test-requirements.txt

Change-Id: Iee0968a079deacef24b56f34e9314b0ebecad0ae
",git fetch https://review.opendev.org/openstack/fuel-library refs/changes/27/192127/1 && git format-patch -1 --stdout FETCH_HEAD,"['deployment/puppet/cluster/files/test_q_agent_cleanup.py', 'deployment/puppet/cluster/files/q-agent-cleanup.py']",2,fa790193cbe218539ba341080815c4ead5a7fd12,bug/1436414,"# Copyright 2013 - 2015 Mirantis, Inc. # # Licensed under the Apache License, Version 2.0 (the ""License""); you may # not use this file except in compliance with the License. You may obtain # a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT # WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the # License for the specific language governing permissions and limitations # under the License. from ConfigParser import SafeConfigParser import functools import jsonimport logging.configimport reimport StringIO import subprocess import sys from time import sleep from neutronclient.neutron import client as n_client def make_logger(handler=logging.StreamHandler(sys.stdout), level=logging.INFO): format = logging.Formatter(""%(asctime)s - %(levelname)s - %(message)s"") handler.setFormatter(format) logger = logging.getLogger(LOG_NAME) logger.addHandler(handler) logger.setLevel(level) return logger LOG = make_logger() AUTH_KEYS = { 'tenant_name': 'admin_tenant_name', 'username': 'admin_user', 'password': 'admin_password', 'auth_url': 'auth_uri', } def get_auth_data(cfg_file, section='keystone_authtoken', keys=AUTH_KEYS): cfg = SafeConfigParser() with open(cfg_file) as f: cfg.readfp(f) auth_data = {} for key, value in keys.iteritems(): auth_data[key] = cfg.get(section, value) return auth_data # Note(xarses): be careful not to inject \n's into the regex pattern # or it will case the maching to fail RECOVERABLE = re.compile(( '(HTTP\s+400\))|' '(400-\{\'message\'\:\s+\'\'\})|' '(\[Errno 111\]\s+Connection\s+refused)|' '(503\s+Service\s+Unavailable)|' '(504\s+Gateway\s+Time-out)|' '(\:\s+Maximum\s+attempts\s+reached)|' '(Unauthorized\:\s+bad\s+credentials)|' '(Max\s+retries\s+exceeded)|' """"""('*NoneType'*\s+object\s+ha'\s+no\s+attribute\s+'*__getitem__'*$)|"""""" '(No\s+route\s+to\s+host$)|' '(Lost\s+connection\s+to\s+MySQL\s+server)'), flags=re.M) RETRY_COUNT = 50 RETRY_DELAY = 2 def retry(func, pattern=RECOVERABLE): @functools.wraps(func) def wrapper(*args, **kwargs): i = 0 while True: try: return func(*args, **kwargs) except Exception as e: if pattern and not pattern.match(e.message): raise e i += 1 if i >= RETRY_COUNT: raise e print(""retry request {0}: {1}"".format(i, e)) sleep(RETRY_DELAY) return wrapper BRIDGES_FOR_PORTS_BY_AGENT = { # 14: tap-xxxyyyzzz: RE__port_in_portlist = re.compile(r""^\s*\d+\:\s+([\w-]+)\:"") def __init__(self, options, log=None): self.auth_data = get_auth_data(cfg_file=options.get('authconf')) @retry self._client = n_client.Client(API_VER, **self.auth_data) @retry def _get_agents(self, use_cache=True): return self.client.list_agents()['agents'] @retry def _get_routers(self, use_cache=True): return self.client.list_routers()['routers'] @retry def _get_networks(self, use_cache=True): return self.client.list_networks()['networks'] @retry def _list_networks_on_dhcp_agent(self, agent_id): return self.client.list_networks_on_dhcp_agent( agent_id)['networks'] @retry def _list_routers_on_l3_agent(self, agent_id): return self.client.list_routers_on_l3_agent( agent_id)['routers'] @retry def _list_l3_agents_on_router(self, router_id): return self.client.list_l3_agent_hosting_routers( router_id)['agents'] @retry def _list_dhcp_agents_on_network(self, network_id): return self.client.list_dhcp_agent_hosting_networks( network_id)['agents'] self.log.debug( ""_list_orphaned_networks:, got list of networks {0}"".format( json.dumps(networks, indent=4))) self.log.debug( ""_list_orphaned_networks:, got list of orphaned networks {0}"". format(orphaned_networks)) self.log.debug( ""_list_orphaned_routers:, got list of routers {0}"".format( json.dumps(routers, indent=4))) self.log.debug( ""_list_orphaned_routers:, got list of orphaned routers {0}"".format( orphaned_routers)) @retry def _add_network_to_dhcp_agent(self, agent_id, net_id): return self.client.add_network_to_dhcp_agent( agent_id, {""network_id"": net_id}) @retry def _add_router_to_l3_agent(self, agent_id, router_id): return self.client.add_router_to_l3_agent( agent_id, {""router_id"": router_id}) @retry def _remove_router_from_l3_agent(self, agent_id, router_id): return self.client.remove_router_from_l3_agent( agent_id, router_id) @retry def _delete_agent(self, agent_id): return self.client.delete_agent(agent_id) self.log.debug( ""_get_agents_by_type: end, {0} rv: {1}"".format( from_cache, json.dumps(rv, indent=4))) self.log.error( ""ERROR (rc={0}) while execution {1}"".format( rc, ' '.join(cmd))) if ns.startswith(self.NS_NAME_PREFIXES[agent]): self.log.error( ""ERROR (rc={0}) while execution {1}"".format( rc, ' '.join(cmd))) self.log.error( ""ERROR (rc={0}) while execution {1}"".format( rc, ' '.join(cmd))) self.log.info( ""found alive DHCP agent: {0}"".format(agent['id'])) self.log.info( ""found dead DHCP agent: {0}"".format(agent['id'])) self.log.info( ""attach network {net} to DHCP agent {agent}"".format( net=net['id'], agent=agents['alive'][0]['id'])) if not self.options.get('noop'): self._add_network_to_dhcp_agent( agents['alive'][0]['id'], net['id']) self.log.info( ""remove dead DHCP agent: {0}"".format(agent['id'])) if not self.options.get('noop'): self._delete_agent(agent['id']) orphaned_networks = self._list_orphaned_networks() self.log.info( ""_reschedule_agent_dhcp: rescheduling {0} to {1}"".format( network, agents['alive'][0]['id'])) if not self.options.get('noop'): self._add_network_to_dhcp_agent( agents['alive'][0]['id'], network) self.log.info( ""_reschedule_agent_dhcp: ended rescheduling of orphaned networks"") self.log.debug( ""L3 agents in cluster: {0}"".format( json.dumps(agents, indent=4))) self.log.debug(""Routers, attached to dead L3 agents: {0}"".format( json.dumps(dead_routers, indent=4))) self._delete_agent(agent['id']) for rou in filter( lambda rr: not(rr[0]['id'] in lucky_ids), dead_routers): self.log.info( ""schedule router {0} to L3 agent {1}"".format( rou[0]['id'], agents['alive'][0]['id'])) if not self.options.get('noop'): self._add_router_to_l3_agent( agents['alive'][0]['id'], rou[0]['id']) orphaned_routers = self._list_orphaned_routers() self.log.info( ""_reschedule_agent_l3: rescheduling {0} to {1}"".format( router, agents['alive'][0]['id'])) if not self.options.get('noop'): self._add_router_to_l3_agent( agents['alive'][0]['id'], router) self.log.info( ""_reschedule_agent_l3: ended rescheduling of orphaned routers"") def _remove_self(self, agent_type): self.log.info( ""_remove_self: deleting our own agent {0} of type {1}"". format(agent['id'], agent_type)) if not self.options.get('noop'): self._delete_agent(agent['id']) task(agent) # OCF_FAILED_MASTER, # http://www.linux-ha.org/doc/dev-guides/_literal_ocf_failed_master_literal_9.html rc = 9if __name__ == '__main__': parser = argparse.ArgumentParser( description='Neutron network node cleaning tool.') parser.add_argument( ""-c"", ""--auth-config"", dest=""authconf"", default=""/etc/neutron/neutron.conf"", help=""Read authconfig from service file"", metavar=""FILE"") parser.add_argument( ""-t"", ""--auth-token"", dest=""auth-token"", default=None, help=""Authenticating token (instead username/passwd)"", metavar=""TOKEN"") parser.add_argument( ""-u"", ""--admin-auth-url"", dest=""admin-auth-url"", default=None, help=""Authenticating URL (admin)"", metavar=""URL"") parser.add_argument( ""--retries"", dest=""retries"", type=int, default=50, help=""try NN retries for API call"", metavar=""NN"") parser.add_argument( ""--sleep"", dest=""sleep"", type=int, default=2, help=""sleep seconds between retries"", metavar=""SEC"") parser.add_argument( ""-a"", ""--agent"", dest=""agent"", action=""append"", help=""specyfy agents for cleaning"", required=True) parser.add_argument( ""--cleanup-ports"", dest=""cleanup-ports"", action=""store_true"", default=False, help=""cleanup ports for given agents on this node"") parser.add_argument( ""--remove-self"", dest=""remove-self"", action=""store_true"", default=False, help=""remove ourselves from agent list"") parser.add_argument( ""--activeonly"", dest=""activeonly"", action=""store_true"", default=False, help=""cleanup only active ports"") parser.add_argument( ""--reschedule"", dest=""reschedule"", action=""store_true"", default=False, help=""reschedule given agents"") parser.add_argument( ""--remove-dead"", dest=""remove-dead"", action=""store_true"", default=False, help=""remove dead agents while rescheduling"") parser.add_argument( ""--test-alive-for-hostname"", dest=""test-hostnames"", action=""append"", help=""testing agent's healthy for given hostname"") parser.add_argument( ""--external-bridge"", dest=""external-bridge"", default=""br-ex"", help=""external bridge name"", metavar=""IFACE"") parser.add_argument( ""--integration-bridge"", dest=""integration-bridge"", default=""br-int"", help=""integration bridge name"", metavar=""IFACE"") parser.add_argument( ""-l"", ""--log"", dest=""log"", action=""store"", help=""log to file instead of STDOUT"") parser.add_argument( ""--noop"", dest=""noop"", action=""store_true"", default=False, help=""do not execute, print to log instead"") parser.add_argument( ""--debug"", dest=""debug"", action=""store_true"", default=False, help=""debug"") RETRY_COUNT = args.retries RETRY_DELAY = args.sleep # setup logging if args.log: LOG = make_logger( handler=logging.handlers.WatchedFileHandler(args.log)) if args.debug: LOG.setLevel(logging.DEBUG) cleaner = NeutronCleaner(options=vars(args), log=LOG)","import re import time import os import sys import random import string import jsonimport shlex import subprocess import StringIOfrom neutronclient.neutron import client as q_client from keystoneclient.v2_0 import client as ks_client from keystoneclient.apiclient.exceptions import NotFound as ks_NotFoundTMP_USER_NAME = 'tmp_neutron_admin' def get_authconfig(cfg_file): # Read OS auth config file rv = {} stripchars="" \'\"""" with open(cfg_file) as f: for line in f: rg = re.match(r'\s*export\s+(\w+)\s*=\s*(.*)',line) if rg : #Use shlex to unescape bash shell escape characters value = """".join(x for x in shlex.split(rg.group(2).strip(stripchars))) rv[rg.group(1).strip(stripchars)] = value return rv BRIDGES_FOR_PORTS_BY_AGENT ={ RE__port_in_portlist = re.compile(r""^\s*\d+\:\s+([\w-]+)\:"") # 14: tap-xxxyyyzzz: def __init__(self, openrc, options, log=None): self.auth_config = openrc self._token = None self._keystone = None self._need_cleanup_tmp_admin = False def __del__(self): if self._need_cleanup_tmp_admin and self._keystone and self._keystone.username: try: self._keystone.users.delete(self._keystone.users.find(username=self._keystone.username)) except: # if we get exception while cleaning temporary account -- nothing harm pass def generate_random_passwd(self, length=13): chars = string.ascii_letters + string.digits + '!@#$%^&*()' random.seed = (os.urandom(1024)) return ''.join(random.choice(chars) for i in range(length)) def keystone(self): if self._keystone is None: ret_count = self.options.get('retries', 1) tmp_passwd = self.generate_random_passwd() while True: if ret_count <= 0: self.log.error("">>> Keystone error: no more retries for connect to keystone server."") sys.exit(1) try: a_token = self.options.get('auth-token') a_url = self.options.get('admin-auth-url') if a_token and a_url: self.log.debug(""Authentication by predefined token."") # create keystone instance, authorized by service token ks = ks_client.Client( token=a_token, endpoint=a_url, ) service_tenant = ks.tenants.find(name='services') auth_url = ks.endpoints.find( service_id=ks.services.find(type='identity').id ).internalurl # find and re-create temporary rescheduling-admin user with random password try: user = ks.users.find(username=TMP_USER_NAME) ks.users.delete(user) except ks_NotFound: # user not found, it's OK pass user = ks.users.create(TMP_USER_NAME, tmp_passwd, tenant_id=service_tenant.id) ks.roles.add_user_role(user, ks.roles.find(name='admin'), service_tenant) # authenticate newly-created tmp neutron admin self._keystone = ks_client.Client( username=user.username, password=tmp_passwd, tenant_id=user.tenantId, auth_url=auth_url, ) self._need_cleanup_tmp_admin = True else: self.log.debug(""Authentication by given credentionals."") self._keystone = ks_client.Client( username=self.auth_config['OS_USERNAME'], password=self.auth_config['OS_PASSWORD'], tenant_name=self.auth_config['OS_TENANT_NAME'], auth_url=self.auth_config['OS_AUTH_URL'], ) break except Exception as e: errmsg = str(e.message).strip() # str() need, because keystone may use int as message in exception if re.search(r""Connection\s+refused$"", errmsg, re.I) or \ re.search(r""Connection\s+timed\s+out$"", errmsg, re.I) or\ re.search(r""Lost\s+connection\s+to\s+MySQL\s+server"", errmsg, re.I) or\ re.search(r""Service\s+Unavailable$"", errmsg, re.I) or\ re.search(r""'*NoneType'*\s+object\s+has\s+no\s+attribute\s+'*__getitem__'*$"", errmsg, re.I) or \ re.search(r""No\s+route\s+to\s+host$"", errmsg, re.I): self.log.info("">>> Can't connect to {0}, wait for server ready..."".format(self.auth_config['OS_AUTH_URL'])) time.sleep(self.options.sleep) else: self.log.error("">>> Keystone error:\n{0}"".format(e.message)) raise e ret_count -= 1 return self._keystone @property def token(self): if self._token is None: self._token = self._keystone.auth_token #self.log.debug(""Auth_token: '{0}'"".format(self._token)) #todo: Validate existing token return self._token @property self._client = q_client.Client( API_VER, endpoint_url=self.keystone.endpoints.find( service_id=self.keystone.services.find(type='network').id ).adminurl, token=self.token, ) def _neutron_API_call(self, method, *args): ret_count = self.options.get('retries') while True: if ret_count <= 0: self.log.error(""Q-server error: no more retries for connect to server."") return [] try: rv = method (*args) break except Exception as e: errmsg = str(e.message).strip() if re.search(r""Connection\s+refused"", errmsg, re.I) or\ re.search(r""Connection\s+timed\s+out"", errmsg, re.I) or\ re.search(r""Lost\s+connection\s+to\s+MySQL\s+server"", errmsg, re.I) or\ re.search(r""503\s+Service\s+Unavailable"", errmsg, re.I) or\ re.search(r""No\s+route\s+to\s+host"", errmsg, re.I): self.log.info(""Can't connect to {0}, wait for server ready..."".format(self.keystone.service_catalog.url_for(service_type='network'))) time.sleep(self.options.sleep) else: self.log.error(""Neutron error:\n{0}"".format(e.message)) raise e ret_count -= 1 return rv def _get_agents(self,use_cache=True): return self._neutron_API_call(self.client.list_agents)['agents'] def _get_routers(self, use_cache=True): return self._neutron_API_call(self.client.list_routers)['routers'] def _get_networks(self, use_cache=True): return self._neutron_API_call(self.client.list_networks)['networks'] def _list_networks_on_dhcp_agent(self, agent_id): return self._neutron_API_call(self.client.list_networks_on_dhcp_agent, agent_id)['networks'] def _list_routers_on_l3_agent(self, agent_id): return self._neutron_API_call(self.client.list_routers_on_l3_agent, agent_id)['routers'] def _list_l3_agents_on_router(self, router_id): return self._neutron_API_call(self.client.list_l3_agent_hosting_routers, router_id)['agents'] def _list_dhcp_agents_on_network(self, network_id): return self._neutron_API_call(self.client.list_dhcp_agent_hosting_networks, network_id)['agents'] self.log.debug(""_list_orphaned_networks:, got list of networks {0}"".format(json.dumps(networks,indent=4))) self.log.debug(""_list_orphaned_networks:, got list of orphaned networks {0}"".format(orphaned_networks)) self.log.debug(""_list_orphaned_routers:, got list of routers {0}"".format(json.dumps(routers,indent=4))) self.log.debug(""_list_orphaned_routers:, got list of orphaned routers {0}"".format(orphaned_routers)) def _add_network_to_dhcp_agent(self, agent_id, net_id): return self._neutron_API_call(self.client.add_network_to_dhcp_agent, agent_id, {""network_id"": net_id}) def _add_router_to_l3_agent(self, agent_id, router_id): return self._neutron_API_call(self.client.add_router_to_l3_agent, agent_id, {""router_id"": router_id}) def _remove_router_from_l3_agent(self, agent_id, router_id): return self._neutron_API_call(self.client.remove_router_from_l3_agent, agent_id, router_id) self.log.debug(""_get_agents_by_type: end, {0} rv: {1}"".format(from_cache, json.dumps(rv, indent=4))) self.log.error(""ERROR (rc={0}) while execution {1}"".format(rc, ' '.join(cmd))) if ns.startswith(""{0}-"".format(self.NS_NAME_PREFIXES[agent])): self.log.error(""ERROR (rc={0}) while execution {1}"".format(rc, ' '.join(cmd))) self.log.error(""ERROR (rc={0}) while execution {1}"".format(rc, ' '.join(cmd))) self.log.info(""found alive DHCP agent: {0}"".format(agent['id'])) self.log.info(""found dead DHCP agent: {0}"".format(agent['id'])) self.log.info(""attach network {net} to DHCP agent {agent}"".format( net=net['id'], agent=agents['alive'][0]['id'] )) if not self.options.get('noop'): self._add_network_to_dhcp_agent(agents['alive'][0]['id'], net['id']) #if error: # return self.log.info(""remove dead DHCP agent: {0}"".format(agent['id'])) if not self.options.get('noop'): self._neutron_API_call(self.client.delete_agent, agent['id']) orphaned_networks=self._list_orphaned_networks() self.log.info(""_reschedule_agent_dhcp: rescheduling {0} to {1}"".format(network,agents['alive'][0]['id'])) if not self.options.get('noop'): self._add_network_to_dhcp_agent(agents['alive'][0]['id'], network) self.log.info(""_reschedule_agent_dhcp: ended rescheduling of orphaned networks"") self.log.debug(""L3 agents in cluster: {ags}"".format(ags=json.dumps(agents, indent=4))) self.log.debug(""Routers, attached to dead L3 agents: {rr}"".format(rr=json.dumps(dead_routers, indent=4))) self._neutron_API_call(self.client.delete_agent, agent['id']) for rou in filter(lambda rr: not(rr[0]['id'] in lucky_ids), dead_routers): # self.log.info(""unschedule router {rou} from L3 agent {agent}"".format( # rou=rou[0]['id'], # agent=rou[1] # )) # if not self.options.get('noop'): # self._remove_router_from_l3_agent(rou[1], rou[0]['id']) # #todo: if error: # # self.log.info(""schedule router {rou} to L3 agent {agent}"".format( rou=rou[0]['id'], agent=agents['alive'][0]['id'] )) if not self.options.get('noop'): self._add_router_to_l3_agent(agents['alive'][0]['id'], rou[0]['id']) orphaned_routers=self._list_orphaned_routers() self.log.info(""_reschedule_agent_l3: rescheduling {0} to {1}"".format(router,agents['alive'][0]['id'])) if not self.options.get('noop'): self._add_router_to_l3_agent(agents['alive'][0]['id'], router) self.log.info(""_reschedule_agent_l3: ended rescheduling of orphaned routers"") def _remove_self(self,agent_type): self.log.info(""_remove_self: deleting our own agent {0} of type {1}"".format(agent['id'],agent_type)) if not self.options.get('noop'): self._neutron_API_call(self.client.delete_agent, agent['id']) task (agent) # if self.options.get('remove-agent'): # self._cleanup_agents(agent) rc = 9 # OCF_FAILED_MASTER, http://www.linux-ha.org/doc/dev-guides/_literal_ocf_failed_master_literal_9.html if __name__ == '__main__': parser = argparse.ArgumentParser(description='Neutron network node cleaning tool.') parser.add_argument(""-c"", ""--auth-config"", dest=""authconf"", default=""/root/openrc"", help=""Authenticating config FILE"", metavar=""FILE"") parser.add_argument(""-t"", ""--auth-token"", dest=""auth-token"", default=None, help=""Authenticating token (instead username/passwd)"", metavar=""TOKEN"") parser.add_argument(""-u"", ""--admin-auth-url"", dest=""admin-auth-url"", default=None, help=""Authenticating URL (admin)"", metavar=""URL"") parser.add_argument(""--retries"", dest=""retries"", type=int, default=50, help=""try NN retries for API call"", metavar=""NN"") parser.add_argument(""--sleep"", dest=""sleep"", type=int, default=2, help=""sleep seconds between retries"", metavar=""SEC"") parser.add_argument(""-a"", ""--agent"", dest=""agent"", action=""append"", help=""specyfy agents for cleaning"", required=True) parser.add_argument(""--cleanup-ports"", dest=""cleanup-ports"", action=""store_true"", default=False, help=""cleanup ports for given agents on this node"") parser.add_argument(""--remove-self"", dest=""remove-self"", action=""store_true"", default=False, help=""remove ourselves from agent list"") parser.add_argument(""--activeonly"", dest=""activeonly"", action=""store_true"", default=False, help=""cleanup only active ports"") parser.add_argument(""--reschedule"", dest=""reschedule"", action=""store_true"", default=False, help=""reschedule given agents"") parser.add_argument(""--remove-dead"", dest=""remove-dead"", action=""store_true"", default=False, help=""remove dead agents while rescheduling"") parser.add_argument(""--test-alive-for-hostname"", dest=""test-hostnames"", action=""append"", help=""testing agent's healthy for given hostname"") parser.add_argument(""--external-bridge"", dest=""external-bridge"", default=""br-ex"", help=""external bridge name"", metavar=""IFACE"") parser.add_argument(""--integration-bridge"", dest=""integration-bridge"", default=""br-int"", help=""integration bridge name"", metavar=""IFACE"") parser.add_argument(""-l"", ""--log"", dest=""log"", action=""store"", help=""log file or logging.conf location"") parser.add_argument(""--noop"", dest=""noop"", action=""store_true"", default=False, help=""do not execute, print to log instead"") parser.add_argument(""--debug"", dest=""debug"", action=""store_true"", default=False, help=""debug"") # if len(args) != 1: # parser.error(""incorrect number of arguments"") # parser.print_help() args = parser.parse_args() #setup logging if args.debug: _log_level = logging.DEBUG else: _log_level = logging.INFO if not args.log: # log config or file not given -- log to console LOG = logging.getLogger(LOG_NAME) # do not move to UP of file _log_handler = logging.StreamHandler(sys.stdout) _log_handler.setFormatter(logging.Formatter(""%(asctime)s - %(levelname)s - %(message)s"")) LOG.addHandler(_log_handler) LOG.setLevel(_log_level) elif args.log.split(os.sep)[-1] == 'logging.conf': # setup logging by external file import logging.config logging.config.fileConfig(args.log) LOG = logging.getLogger(LOG_NAME) # do not move to UP of file else: # log to given file LOG = logging.getLogger(LOG_NAME) # do not move to UP of file LOG.addHandler(logging.handlers.WatchedFileHandler(args.log)) LOG.setLevel(_log_level) cleaner = NeutronCleaner(get_authconfig(args.authconf), options=vars(args), log=LOG)# ###",408,280
openstack%2Ffuel-library~stable%2F6.0~I511a23b8a8523a811cd2d2b6a418977ae9e979ba,openstack/fuel-library,stable/6.0,I511a23b8a8523a811cd2d2b6a418977ae9e979ba,Backport packaging of OCF scripts from 6.1 to 6.0-updates,MERGED,2015-06-18 14:32:54.000000000,2015-06-24 15:44:32.000000000,2015-06-24 15:44:30.000000000,"[{'_account_id': 3}, {'_account_id': 8786}, {'_account_id': 8971}, {'_account_id': 11090}, {'_account_id': 13194}, {'_account_id': 14168}]","[{'number': 1, 'created': '2015-06-18 14:32:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/fc53adb64267d35c8176b38d89de6fd3a00d98ff', 'message': '[DO NOT MERGE | WORK IN PROGRESS] Backport packaging of OCF scripts from 6.1 to 6.0-updates\n\nWe need a way to deliver fixes for OCF scripts in MOS 6.0 deployments as a part of maintenance updates.\nTo achieve that OCF scripts should be packaged in the same way as they are in 6.1.\n\nChange-Id: I511a23b8a8523a811cd2d2b6a418977ae9e979ba\nCloses-bug: #1465771\n'}, {'number': 2, 'created': '2015-06-22 15:49:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/d7edc6a94a412798f510de9bf836d5632b2362c8', 'message': '[DO NOT MERGE | WORK IN PROGRESS] Backport packaging of OCF scripts from 6.1 to 6.0-updates\n\nWe need a way to deliver fixes for OCF scripts in MOS 6.0 deployments as a part of maintenance updates.\nTo achieve that OCF scripts should be packaged in the same way as they are in 6.1.\n\nChange-Id: I511a23b8a8523a811cd2d2b6a418977ae9e979ba\nCloses-bug: #1465771\n'}, {'number': 3, 'created': '2015-06-22 15:50:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/893caf6e13ebdb519f01446bd844e6fd0449b559', 'message': '[WIP] Backport packaging of OCF scripts from 6.1 to 6.0-updates\n\nWe need a way to deliver fixes for OCF scripts in MOS 6.0 deployments as a part of maintenance updates.\nTo achieve that OCF scripts should be packaged in the same way as they are in 6.1.\n\nChange-Id: I511a23b8a8523a811cd2d2b6a418977ae9e979ba\nCloses-bug: #1465771\n'}, {'number': 4, 'created': '2015-06-22 16:00:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/624be352499edf24749a8312b90c0145e58452e1', 'message': '[WIP] Backport packaging of OCF scripts from 6.1 to 6.0-updates\n\nWe need a way to deliver fixes for OCF scripts in MOS 6.0 deployments as a part of maintenance updates.\nTo achieve that OCF scripts should be packaged in the same way as they are in 6.1.\n\nChange-Id: I511a23b8a8523a811cd2d2b6a418977ae9e979ba\nCloses-bug: #1465771\n'}, {'number': 5, 'created': '2015-06-23 12:20:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/d90e5e0c3d036b0c8346a1876f8b24ed7487769e', 'message': '[WIP] Backport packaging of OCF scripts from 6.1 to 6.0-updates\n\nWe need a way to deliver fixes for OCF scripts in MOS 6.0 deployments as a part of maintenance updates.\nTo achieve that OCF scripts should be packaged in the same way as they are in 6.1.\n\nChange-Id: I511a23b8a8523a811cd2d2b6a418977ae9e979ba\nCloses-bug: #1465771\n'}, {'number': 6, 'created': '2015-06-23 12:34:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/9f1b02257a9da7e248798ef453a9a258858415bd', 'message': '[WIP] Backport packaging of OCF scripts from 6.1 to 6.0-updates\n\nWe need a way to deliver fixes for OCF scripts in MOS 6.0 deployments as a part of maintenance updates.\nTo achieve that OCF scripts should be packaged in the same way as they are in 6.1.\n\nChange-Id: I511a23b8a8523a811cd2d2b6a418977ae9e979ba\nCloses-bug: #1465771\n'}, {'number': 7, 'created': '2015-06-23 12:55:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/cd59e63abd9ae6f46a257e65e3872a11ecceffdf', 'message': '[WIP] Backport packaging of OCF scripts from 6.1 to 6.0-updates\n\nWe need a way to deliver fixes for OCF scripts in MOS 6.0 deployments as a part of maintenance updates.\nTo achieve that OCF scripts should be packaged in the same way as they are in 6.1.\n\nChange-Id: I511a23b8a8523a811cd2d2b6a418977ae9e979ba\nCloses-bug: #1465771\n'}, {'number': 8, 'created': '2015-06-23 13:09:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/12fb22959cd5947d646d27b5618da66260232b4a', 'message': '[WIP] Backport packaging of OCF scripts from 6.1 to 6.0-updates\n\nWe need a way to deliver fixes for OCF scripts in MOS 6.0 deployments as a part of maintenance updates.\nTo achieve that OCF scripts should be packaged in the same way as they are in 6.1.\n\nChange-Id: I511a23b8a8523a811cd2d2b6a418977ae9e979ba\nCloses-bug: #1465771\n'}, {'number': 9, 'created': '2015-06-23 13:15:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/6ae096f5692aaf2543a6c5f8574ebc0c6203874e', 'message': '[WIP] Backport packaging of OCF scripts from 6.1 to 6.0-updates\n\nWe need a way to deliver fixes for OCF scripts in MOS 6.0 deployments as a part of maintenance updates.\nTo achieve that OCF scripts should be packaged in the same way as they are in 6.1.\n\nChange-Id: I511a23b8a8523a811cd2d2b6a418977ae9e979ba\nCloses-bug: #1465771\n'}, {'number': 10, 'created': '2015-06-23 13:19:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/d42b011a35feb1c59901d5c44ff0f08ce6552d2f', 'message': '[WIP] Backport packaging of OCF scripts from 6.1 to 6.0-updates\n\nWe need a way to deliver fixes for OCF scripts in MOS 6.0 deployments as a part of maintenance updates.\nTo achieve that OCF scripts should be packaged in the same way as they are in 6.1.\n\nChange-Id: I511a23b8a8523a811cd2d2b6a418977ae9e979ba\nCloses-bug: #1465771\n'}, {'number': 11, 'created': '2015-06-23 13:56:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/a684521977231dae71c10abdaa03266cd7715bad', 'message': '[WIP] Backport packaging of OCF scripts from 6.1 to 6.0-updates\n\nWe need a way to deliver fixes for OCF scripts in MOS 6.0 deployments as a part of maintenance updates.\nTo achieve that OCF scripts should be packaged in the same way as they are in 6.1.\n\nChange-Id: I511a23b8a8523a811cd2d2b6a418977ae9e979ba\nCloses-bug: #1465771\n'}, {'number': 12, 'created': '2015-06-23 14:35:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/8c6dea4f18686ba9a59668056c3d31ffb173924a', 'message': '[WIP] Backport packaging of OCF scripts from 6.1 to 6.0-updates\n\nWe need a way to deliver fixes for OCF scripts in MOS 6.0 deployments as a part of maintenance updates.\nTo achieve that OCF scripts should be packaged in the same way as they are in 6.1.\n\nChange-Id: I511a23b8a8523a811cd2d2b6a418977ae9e979ba\nCloses-bug: #1465771\n'}, {'number': 13, 'created': '2015-06-23 15:33:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/c413a4436bf72a9cc196dd15d9a60d4ac25ac752', 'message': '[WIP] Backport packaging of OCF scripts from 6.1 to 6.0-updates\n\nWe need a way to deliver fixes for OCF scripts in MOS 6.0 deployments as a part of maintenance updates.\nTo achieve that OCF scripts should be packaged in the same way as they are in 6.1.\n\nChange-Id: I511a23b8a8523a811cd2d2b6a418977ae9e979ba\nCloses-bug: #1465771\n'}, {'number': 14, 'created': '2015-06-23 15:41:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/2d757aeaa1f9ed3f37c6b036cd546285cf08a911', 'message': '[WIP] Backport packaging of OCF scripts from 6.1 to 6.0-updates\n\nWe need a way to deliver fixes for OCF scripts in MOS 6.0 deployments as a part of maintenance updates.\nTo achieve that OCF scripts should be packaged in the same way as they are in 6.1.\n\nChange-Id: I511a23b8a8523a811cd2d2b6a418977ae9e979ba\nCloses-bug: #1465771\n'}, {'number': 15, 'created': '2015-06-23 15:46:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/64d6615ad257204cc93eee92b0e6e6323c9379aa', 'message': '[WIP] Backport packaging of OCF scripts from 6.1 to 6.0-updates\n\nWe need a way to deliver fixes for OCF scripts in MOS 6.0 deployments as a part of maintenance updates.\nTo achieve that OCF scripts should be packaged in the same way as they are in 6.1.\n\nChange-Id: I511a23b8a8523a811cd2d2b6a418977ae9e979ba\nCloses-bug: #1465771\n'}, {'number': 16, 'created': '2015-06-23 16:04:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/71ef3ec06a7a068e6054c1de44bdc6eca9c70dd3', 'message': '[WIP] Backport packaging of OCF scripts from 6.1 to 6.0-updates\n\nWe need a way to deliver fixes for OCF scripts in MOS 6.0 deployments as a part of maintenance updates.\nTo achieve that OCF scripts should be packaged in the same way as they are in 6.1.\n\nChange-Id: I511a23b8a8523a811cd2d2b6a418977ae9e979ba\nCloses-bug: #1465771\n'}, {'number': 17, 'created': '2015-06-23 17:08:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/67c12b15be043a639d90eb7621f57aef7e610ab8', 'message': 'Backport packaging of OCF scripts from 6.1 to 6.0-updates\n\nWe need a way to deliver fixes for OCF scripts in MOS 6.0 deployments as a part of maintenance updates.\nTo achieve that OCF scripts should be packaged in the same way as they are in 6.1.\n\nChange-Id: I511a23b8a8523a811cd2d2b6a418977ae9e979ba\nCloses-bug: #1465771\n'}, {'number': 18, 'created': '2015-06-24 14:12:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/c8c0efcda8c9878c5a5d79c2eeae28ae99b53906', 'message': 'Backport packaging of OCF scripts from 6.1 to 6.0-updates\n\nWe need a way to deliver fixes for OCF scripts in MOS 6.0 deployments as a part of maintenance updates.\nTo achieve that OCF scripts should be packaged in the same way as they are in 6.1.\n\nChange-Id: I511a23b8a8523a811cd2d2b6a418977ae9e979ba\nCloses-bug: #1465771\n'}, {'number': 19, 'created': '2015-06-24 14:51:07.000000000', 'files': ['debian/rules', 'debian/changelog', 'debian/fuel-ha-utils6.0.install', 'debian/compat', 'debian/source/format', 'debian/copyright', 'specs/fuel-library6.0.spec', 'debian/control', 'debian/fuel-library6.0.install'], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/24c7fb0b75e339d63bf569d88144c16db699f531', 'message': 'Backport packaging of OCF scripts from 6.1 to 6.0-updates\n\nWe need a way to deliver fixes for OCF scripts in MOS 6.0 deployments as a part of maintenance updates.\nTo achieve that OCF scripts should be packaged in the same way as they are in 6.1.\n\nChange-Id: I511a23b8a8523a811cd2d2b6a418977ae9e979ba\nCloses-bug: #1465771\n'}]",4,193155,24c7fb0b75e339d63bf569d88144c16db699f531,130,6,19,14168,,,0,"Backport packaging of OCF scripts from 6.1 to 6.0-updates

We need a way to deliver fixes for OCF scripts in MOS 6.0 deployments as a part of maintenance updates.
To achieve that OCF scripts should be packaged in the same way as they are in 6.1.

Change-Id: I511a23b8a8523a811cd2d2b6a418977ae9e979ba
Closes-bug: #1465771
",git fetch https://review.opendev.org/openstack/fuel-library refs/changes/55/193155/17 && git format-patch -1 --stdout FETCH_HEAD,['specs/fuel-library6.0.spec'],1,fc53adb64267d35c8176b38d89de6fd3a00d98ff,bug/1465771,"%define name fuel-library6.0 %{!?version: %define version 6.0.0} %{!?release: %define release 1} Summary: Fuel-Library: a set of deployment manifests of Fuel for OpenStack Name: %{name} Version: %{version} Release: %{release} Group: System Environment/Libraries License: GPLv2 URL: http://github.com/stackforge/fuel-library Source0: %{name}-%{version}.tar.gz Provides: fuel-library BuildArch: noarch BuildRoot: %{_tmppath}/fuel-library-%{version}-%{release} %define files_source %{_builddir}/%{name}-%{version} %define openstack_version 2014.2-6.0 %description Fuel is the Ultimate Do-it-Yourself Kit for OpenStack Purpose built to assimilate the hard-won experience of our services team, it contains the tooling, information, and support you need to accelerate time to production with OpenStack cloud. OpenStack is a very versatile and flexible cloud management platform. By exposing its portfolio of cloud infrastructure services  compute, storage, networking and other core resources  through ReST APIs, it enables a wide range of control over these services, both from the perspective of an integrated Infrastructure as a Service (IaaS) controlled by applications, as well as automated manipulation of the infrastructure itself. This architectural flexibility doesnt set itself up magically; it asks you, the user and cloud administrator, to organize and manage a large array of configuration options. Consequently, getting the most out of your OpenStack cloud over time  in terms of flexibility, scalability, and manageability  requires a thoughtful combination of automation and configuration choices. This package contains deployment manifests and code to execute provisioning of master and slave nodes. %prep %setup -cq %install mkdir -p %{buildroot}/etc/puppet/%{openstack_version}/modules/ mkdir -p %{buildroot}/etc/puppet/%{openstack_version}/manifests/ mkdir -p %{buildroot}/usr/bin/ mkdir -p %{buildroot}/usr/lib/ cp -fr %{_builddir}/%{name}-%{version}/deployment/puppet/* %{buildroot}/etc/puppet/%{openstack_version}/modules/ #fuel-ha-utils install -d -m 0755 %{buildroot}/usr/lib/ocf/resource.d/mirantis install -m 0755 %{files_source}/cluster/files/ns_haproxy %{buildroot}/usr/lib/ocf/resource.d/mirantis/ns_haproxy install -m 0755 %{files_source}/cluster/files/ns_IPaddr2 %{buildroot}/usr/lib/ocf/resource.d/mirantis/ns_IPaddr2 install -m 0755 %{files_source}/cluster/files/ocf/neutron-agent-ovs %{buildroot}/usr/lib/ocf/resource.d/mirantis/neutron-agent-ovs install -m 0755 %{files_source}/cluster/files/ocf/neutron-agent-metadata %{buildroot}/usr/lib/ocf/resource.d/mirantis/neutron-agent-metadata install -m 0755 %{files_source}/cluster/files/ocf/neutron-agent-dhcp %{buildroot}/usr/lib/ocf/resource.d/mirantis/neutron-agent-dhcp install -m 0755 %{files_source}/cluster/files/ocf/neutron-agent-l3 %{buildroot}/usr/lib/ocf/resource.d/mirantis/neutron-agent-l3 install -m 0755 %{files_source}/cluster/files/q-agent-cleanup.py %{buildroot}/usr/bin/q-agent-cleanup.py install -m 0755 %{files_source}/galera/files/ocf/mysql-wss %{buildroot}/usr/lib/ocf/resource.d/mirantis/mysql-wss install -m 0755 %{files_source}/heat/templates/heat_engine_centos.ocf.erb %{buildroot}/usr/lib/ocf/resource.d/mirantis/heat-engine install -m 0755 %{files_source}/nova/files/ocf/rabbitmq %{buildroot}/usr/lib/ocf/resource.d/mirantis/rabbitmq-server install -m 0755 %{files_source}/ceilometer/files/ocf/ceilometer-agent-central %{buildroot}/usr/lib/ocf/resource.d/mirantis/ceilometer-agent-central install -m 0755 %{files_source}/ceilometer/files/ocf/ceilometer-alarm-evaluator %{buildroot}/usr/lib/ocf/resource.d/mirantis/ceilometer-alarm-evaluator %files /etc/puppet/%{openstack_version}/modules/ /etc/puppet/%{openstack_version}/manifests/ %package -n fuel-ha-utils Summary: Fuel project HA utilities Version: %{version} Release: %{release} Group: System Environment/Libraries # FIXME(aglarendil): mixed license actually - need to figure out the best option License: GPLv2 Requires: python-keystoneclient Requires: python-neutronclient URL: http://github.com/stackforge/fuel-library BuildArch: noarch BuildRoot: %{_tmppath}/fuel-library-%{version}-%{release} %description -n fuel-ha-utils A set of scripts for Fuel deployment utility HA deployment For further information go to http://wiki.openstack.org/Fuel %files -n fuel-ha-utils %defattr(-,root,root) /usr/lib/ocf/resource.d/mirantis /usr/bin/q-agent-cleanup.py %clean rm -rf ${buildroot} %changelog * Wed Jun 17 2015 Alexander Nevenchannyy <anevenchannyy@mirantis.com> - 6.0 - Create spec ",,89,0
openstack%2Ffuel-docs~stable%2F6.1~I91cdd350d806c6da447b661601d29094d4d07179,openstack/fuel-docs,stable/6.1,I91cdd350d806c6da447b661601d29094d4d07179,Update Patching docs,MERGED,2015-06-24 15:38:18.000000000,2015-06-24 15:44:00.000000000,2015-06-24 15:43:57.000000000,"[{'_account_id': 3}, {'_account_id': 8971}, {'_account_id': 13082}]","[{'number': 1, 'created': '2015-06-24 15:38:18.000000000', 'files': ['pages/operations/configuring-repos-ops.rst', 'pages/user-guide/patching-ug.rst', 'pages/operations/patching-ops.rst', '_images/errataPatching.png', 'pages/user-guide/streamlined-patching-ug.rst', 'pages/release-notes/v6-1/new-features/patch-openstack.rst', '_images/patchingRepos.png', 'contents/contents-user.rst', 'contents/contents-operations.rst', 'pages/operations/streamlined-patching.rst'], 'web_link': 'https://opendev.org/openstack/fuel-docs/commit/a441690c99abe077027a31cc018e49df8041ded2', 'message': 'Update Patching docs\n\nUpdate patching docs.\nMake repos configuration a separate chapter\nin the ops guide.\n\nChange-Id: I91cdd350d806c6da447b661601d29094d4d07179\n'}]",0,195152,a441690c99abe077027a31cc018e49df8041ded2,7,3,1,14342,,,0,"Update Patching docs

Update patching docs.
Make repos configuration a separate chapter
in the ops guide.

Change-Id: I91cdd350d806c6da447b661601d29094d4d07179
",git fetch https://review.opendev.org/openstack/fuel-docs refs/changes/52/195152/1 && git format-patch -1 --stdout FETCH_HEAD,"['pages/operations/configuring-repos-ops.rst', 'pages/operations/patching-ops.rst', 'pages/user-guide/patching-ug.rst', '_images/errataPatching.png', 'pages/user-guide/streamlined-patching-ug.rst', 'pages/release-notes/v6-1/new-features/patch-openstack.rst', '_images/patchingRepos.png', 'contents/contents-user.rst', 'contents/contents-operations.rst', 'pages/operations/streamlined-patching.rst']",10,a441690c99abe077027a31cc018e49df8041ded2,,,".. _streamlined-patching-ops: Applying streamlined patching ============================= .. note:: The primary user of the the streamlined patching feature is the Linux system administrator. If you are not confident enough, you may want to skip this. With the streamlined patching feature in Mirantis OpenStack 6.1 you can now keep your environment up-to-date in a customized fashion without the need to upgrade to the latest version. .. note:: The streamlined patching feature is introduced in Mirantis OpenStack 6.1 and will not work in older releases. There are two types of officially supported updates: 1. Bugfix updates -- These are released in an aggregated form and consist of bug fixes and security updates. The bugfix updates are run through our internal testing to ensure that they work without breaking each other. 2. Security updates -- These are released as soon as they are available. Streamlined patching prerequisites ---------------------------------- * Make sure you are registered at at the `official Mirantis website <https://software.mirantis.com/openstack-download-form/>`_. Once you are registered, you will receive regular email notifications on the available patches in an aggregate form. Once you receive the email, you can click on the patching items listed there. This will lead you to the `errata portal <http://errata.mirantis.com/>`_. * At the portal you will see a list of all the available patches. Each patching item will have detailed instructions on how to download and apply each of them. * Make sure you have the repositories configured correctly as described below. Configuring repositories ------------------------ By default, your environments will have the configuration of the repositories that point to the Mirantis update and security repository mirrors. There is also an 'Auxiliary' repository configured on the Fuel Master node which can be used to deliver packages to the nodes. To change the list of repositories, you will need to amend the three fields which contain the required information for the repositories configuration depending on the distribution you install. For CentOS ++++++++++ :: |repo-name|repo-baseurl|repo-priority| e.g :: my-repo http://my-domain.local/repo 10 For Ubuntu ++++++++++ :: |repo-name|apt-sources-list-string|repo-priority| my-repo deb http://my-domain.local/repo trusty main 1200 Additional information ++++++++++++++++++++++ For additional information read the following: * Ubuntu: `PinningHowto <https://help.ubuntu.com/community/PinningHowto>`_ * CentOS: `yum-plugin-priorities <http://wiki.centos.org/PackageManagement/Yum/Priorities>`_ Applying the patches -------------------- Each patch item listed at the the `errata portal <http://errata.mirantis.com/>`_ will have the exact commands you need to run to download and apply the patch -- usually ``yum`` or ``apt-get``. The listed commands need to be executed on every node that you need to patch. ",120,109
openstack%2Ffuel-docs~stable%2F6.1~I675c7766084e011bba69c0106f1208f4056c1ef2,openstack/fuel-docs,stable/6.1,I675c7766084e011bba69c0106f1208f4056c1ef2,Update the upgrade text,MERGED,2015-06-24 15:37:51.000000000,2015-06-24 15:43:30.000000000,2015-06-24 15:43:29.000000000,"[{'_account_id': 3}, {'_account_id': 8971}, {'_account_id': 13082}]","[{'number': 1, 'created': '2015-06-24 15:37:51.000000000', 'files': ['pages/user-guide/8000-upgrade.rst'], 'web_link': 'https://opendev.org/openstack/fuel-docs/commit/f850a3531be5bb3ea86fce569d8d68fbae89b748', 'message': 'Update the upgrade text\n\nUpdate the upgrade text to make it clear\n\nChange-Id: I675c7766084e011bba69c0106f1208f4056c1ef2\n'}]",0,195151,f850a3531be5bb3ea86fce569d8d68fbae89b748,7,3,1,14342,,,0,"Update the upgrade text

Update the upgrade text to make it clear

Change-Id: I675c7766084e011bba69c0106f1208f4056c1ef2
",git fetch https://review.opendev.org/openstack/fuel-docs refs/changes/51/195151/1 && git format-patch -1 --stdout FETCH_HEAD,['pages/user-guide/8000-upgrade.rst'],1,f850a3531be5bb3ea86fce569d8d68fbae89b748,,"* If you are running Fuel 4.x or earlier, you cannot upgrade to 6.1. * If you are running Fuel 5.x, you cannot upgrade *directly* to 6.1. You will need to upgrade from 5.x to 6.0 first, and then you can upgrade to 6.1. * If you are running Fuel 6.0, you can upgrade to Fuel 6.1 Fuel 6.1 console can manage your existing 6.x OpenStack environment(s)","You can upgrade a Fuel Master node to 6.1 from an earlier version of Mirantis OpenStack Release 5.x. After you do this, your new Fuel 6.1 console can manage your existing 6.x OpenStack environment(s)",7,4
openstack%2Ffuel-docs~stable%2F6.1~I8f4f56d3ea246bfe85332ed716de4f6495942283,openstack/fuel-docs,stable/6.1,I8f4f56d3ea246bfe85332ed716de4f6495942283,Add Murano features,MERGED,2015-06-24 15:28:10.000000000,2015-06-24 15:40:41.000000000,2015-06-24 15:40:39.000000000,"[{'_account_id': 3}, {'_account_id': 8971}, {'_account_id': 13082}]","[{'number': 1, 'created': '2015-06-24 15:28:10.000000000', 'files': ['pages/release-notes/v6-1/0020-new-features.rst', 'pages/release-notes/v6-1/new-features/murano.rst'], 'web_link': 'https://opendev.org/openstack/fuel-docs/commit/8a8e659db57ae52af4d0579bb922019bfff44149', 'message': 'Add Murano features\n\nAdd Murano features to the 6.1 relnotes\n\nChange-Id: I8f4f56d3ea246bfe85332ed716de4f6495942283\n(cherry picked from commit bc1c888ab2f418b3b5b08d728a8be49431fb6ef6)\n'}]",0,195147,8a8e659db57ae52af4d0579bb922019bfff44149,7,3,1,14342,,,0,"Add Murano features

Add Murano features to the 6.1 relnotes

Change-Id: I8f4f56d3ea246bfe85332ed716de4f6495942283
(cherry picked from commit bc1c888ab2f418b3b5b08d728a8be49431fb6ef6)
",git fetch https://review.opendev.org/openstack/fuel-docs refs/changes/47/195147/1 && git format-patch -1 --stdout FETCH_HEAD,"['pages/release-notes/v6-1/0020-new-features.rst', 'pages/release-notes/v6-1/new-features/murano.rst']",2,8a8e659db57ae52af4d0579bb922019bfff44149,," Murano-related features ----------------------- * New OpenStack application catalog was published to `Communtiy App Catalog <http://apps.openstack.org/>`_, enabling users to select Murano packages, Heat templates, and Glance images they would like to add to their cloud. * Users can source Murano packages and their dependencies using a URL (package name) from `Communtiy App Catalog <http://apps.openstack.org/>`_ instead of using a zip file, simplifying Murano workflow. See `the related blueprint <https://blueprints.launchpad.net/murano/+spec/muraniclient-url-download>`__. * Support for Docker applications in Murano. See `the related blueprint <https://blueprints.launchpad.net/murano/+spec/docker-registry-in-murano>`__. ",,17,0
openstack%2Ffuel-docs~stable%2F6.1~I6ebd7f0425c6a93c895e0eb19bfc699347c3dc64,openstack/fuel-docs,stable/6.1,I6ebd7f0425c6a93c895e0eb19bfc699347c3dc64,change LBaas wording and remove Contrail,MERGED,2015-06-24 15:27:20.000000000,2015-06-24 15:40:20.000000000,2015-06-24 15:40:20.000000000,"[{'_account_id': 3}, {'_account_id': 8971}, {'_account_id': 13082}]","[{'number': 1, 'created': '2015-06-24 15:27:20.000000000', 'files': ['pages/release-notes/v6-1/new-features/plugins.rst'], 'web_link': 'https://opendev.org/openstack/fuel-docs/commit/566c5c30afd50e1b4984eb85e6278ac07a4809ed', 'message': 'change LBaas wording and remove Contrail\n\nChange LBaaS plugin description and\nremove Contrail as it is not supported yet.\n\nChange-Id: I6ebd7f0425c6a93c895e0eb19bfc699347c3dc64\n(cherry picked from commit 73200a84c7915bd2cf61b687335ea05bc29874e7)\n'}]",0,195146,566c5c30afd50e1b4984eb85e6278ac07a4809ed,7,3,1,14342,,,0,"change LBaas wording and remove Contrail

Change LBaaS plugin description and
remove Contrail as it is not supported yet.

Change-Id: I6ebd7f0425c6a93c895e0eb19bfc699347c3dc64
(cherry picked from commit 73200a84c7915bd2cf61b687335ea05bc29874e7)
",git fetch https://review.opendev.org/openstack/fuel-docs refs/changes/46/195146/1 && git format-patch -1 --stdout FETCH_HEAD,['pages/release-notes/v6-1/new-features/plugins.rst'],1,566c5c30afd50e1b4984eb85e6278ac07a4809ed,,"LBaaS plugin compatible with controllers in HA mode +++++++++++++++++++++++++++++++++++++++++++++++++++ The 6.1 compatible LBaaS plugin has been modified so that it can be deployed on controllers in HA mode. Please note that this enables the new LBaaS plugin to work with 6.1, but does not make the plugin itself HA.| Zabbix | Mellanox | | || InfluxDB-Grafana | Cisco ACI | | |","LBaaS is supported in HA ++++++++++++++++++++++++ LBaaS Fuel plugin, previously available in multi-node mode only, is now supported in HA. Please, note that HA works for the Controllers only, but not for the plugin itself.| Zabbix | Contrail | | || InfluxDB-Grafana | Mellanox | | | +----------------------+------------+---------+-----------+ | | Cisco ACI | | |",8,10
openstack%2Ffuel-docs~stable%2F6.1~I411f6d67d251bc48281150e8c9e87b4ad904dca3,openstack/fuel-docs,stable/6.1,I411f6d67d251bc48281150e8c9e87b4ad904dca3,Update OpenStack version support,MERGED,2015-06-24 15:25:56.000000000,2015-06-24 15:40:00.000000000,2015-06-24 15:39:59.000000000,"[{'_account_id': 3}, {'_account_id': 8971}, {'_account_id': 13082}]","[{'number': 1, 'created': '2015-06-24 15:25:56.000000000', 'files': ['pages/release-notes/v6-1-juno-full.rst'], 'web_link': 'https://opendev.org/openstack/fuel-docs/commit/1b9be9d9dc9660398f3d223ee029da74a4e52576', 'message': 'Update OpenStack version support\n\nUpdate OpenStack version support.\n\nChange-Id: I411f6d67d251bc48281150e8c9e87b4ad904dca3\n(cherry picked from commit 8bb65792a50598235551d274364beebfb7da9dc4)\n'}]",0,195145,1b9be9d9dc9660398f3d223ee029da74a4e52576,7,3,1,14342,,,0,"Update OpenStack version support

Update OpenStack version support.

Change-Id: I411f6d67d251bc48281150e8c9e87b4ad904dca3
(cherry picked from commit 8bb65792a50598235551d274364beebfb7da9dc4)
",git fetch https://review.opendev.org/openstack/fuel-docs refs/changes/45/195145/1 && git format-patch -1 --stdout FETCH_HEAD,['pages/release-notes/v6-1-juno-full.rst'],1,1b9be9d9dc9660398f3d223ee029da74a4e52576,,This generally available version of Mirantis OpenStack is based on Juno release 2014.2.2 of OpenStack.,This generally available version of Mirantis OpenStack is based on the latest stable Juno release of OpenStack.,2,2
openstack%2Ffuel-docs~master~I675c7766084e011bba69c0106f1208f4056c1ef2,openstack/fuel-docs,master,I675c7766084e011bba69c0106f1208f4056c1ef2,Update the upgrade text,MERGED,2015-06-24 14:54:16.000000000,2015-06-24 15:39:51.000000000,2015-06-24 15:39:51.000000000,"[{'_account_id': 3}, {'_account_id': 8971}, {'_account_id': 13082}]","[{'number': 1, 'created': '2015-06-24 14:54:16.000000000', 'files': ['pages/user-guide/8000-upgrade.rst'], 'web_link': 'https://opendev.org/openstack/fuel-docs/commit/a0d2fd17332ea7b0dff3885fb11a0d2fb1615630', 'message': 'Update the upgrade text\n\nUpdate the upgrade text to make it clear\n\nChange-Id: I675c7766084e011bba69c0106f1208f4056c1ef2\n'}]",0,195127,a0d2fd17332ea7b0dff3885fb11a0d2fb1615630,9,3,1,14342,,,0,"Update the upgrade text

Update the upgrade text to make it clear

Change-Id: I675c7766084e011bba69c0106f1208f4056c1ef2
",git fetch https://review.opendev.org/openstack/fuel-docs refs/changes/27/195127/1 && git format-patch -1 --stdout FETCH_HEAD,['pages/user-guide/8000-upgrade.rst'],1,a0d2fd17332ea7b0dff3885fb11a0d2fb1615630,UpgradeProcedure,"* If you are running Fuel 4.x or earlier, you cannot upgrade to 6.1. * If you are running Fuel 5.x, you cannot upgrade *directly* to 6.1. You will need to upgrade from 5.x to 6.0 first, and then you can upgrade to 6.1. * If you are running Fuel 6.0, you can upgrade to Fuel 6.1 Fuel 6.1 console can manage your existing 6.x OpenStack environment(s)","You can upgrade a Fuel Master node to 6.1 from an earlier version of Mirantis OpenStack Release 5.x. After you do this, your new Fuel 6.1 console can manage your existing 6.x OpenStack environment(s)",7,4
openstack%2Ffuel-docs~master~I91cdd350d806c6da447b661601d29094d4d07179,openstack/fuel-docs,master,I91cdd350d806c6da447b661601d29094d4d07179,Update Patching docs,MERGED,2015-06-24 12:35:52.000000000,2015-06-24 15:39:35.000000000,2015-06-24 15:39:35.000000000,"[{'_account_id': 3}, {'_account_id': 8971}, {'_account_id': 13082}]","[{'number': 1, 'created': '2015-06-24 12:35:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-docs/commit/8ed95318031043f23e9b38eedd62a41d64c2dd8f', 'message': 'Update Patching docs\n\nUpdate patching docs.\nMake repos configuration a separate chapter\nin the ops guide.\n\nChange-Id: I91cdd350d806c6da447b661601d29094d4d07179\n'}, {'number': 2, 'created': '2015-06-24 12:50:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-docs/commit/5d5274c4d99fe8ceffc4b4a20bc30f85a39c6b03', 'message': 'Update Patching docs\n\nUpdate patching docs.\nMake repos configuration a separate chapter\nin the ops guide.\n\nChange-Id: I91cdd350d806c6da447b661601d29094d4d07179\n'}, {'number': 3, 'created': '2015-06-24 12:54:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-docs/commit/63f1fb2bf2d09b2a785865eadf61b36f47504b71', 'message': 'Update Patching docs\n\nUpdate patching docs.\nMake repos configuration a separate chapter\nin the ops guide.\n\nChange-Id: I91cdd350d806c6da447b661601d29094d4d07179\n'}, {'number': 4, 'created': '2015-06-24 13:00:57.000000000', 'files': ['pages/operations/configuring-repos-ops.rst', 'pages/user-guide/patching-ug.rst', 'pages/operations/patching-ops.rst', '_images/errataPatching.png', 'pages/user-guide/streamlined-patching-ug.rst', 'pages/release-notes/v6-1/new-features/patch-openstack.rst', '_images/patchingRepos.png', 'contents/contents-user.rst', 'contents/contents-operations.rst', 'pages/operations/streamlined-patching.rst'], 'web_link': 'https://opendev.org/openstack/fuel-docs/commit/fdda81e6f8343057ae0bad0b1769da29e2d56f8a', 'message': 'Update Patching docs\n\nUpdate patching docs.\nMake repos configuration a separate chapter\nin the ops guide.\n\nChange-Id: I91cdd350d806c6da447b661601d29094d4d07179\n'}]",0,195057,fdda81e6f8343057ae0bad0b1769da29e2d56f8a,21,3,4,14342,,,0,"Update Patching docs

Update patching docs.
Make repos configuration a separate chapter
in the ops guide.

Change-Id: I91cdd350d806c6da447b661601d29094d4d07179
",git fetch https://review.opendev.org/openstack/fuel-docs refs/changes/57/195057/4 && git format-patch -1 --stdout FETCH_HEAD,"['pages/operations/configuring-repos-ops.rst', '_images/errataPatching.png', '_images/patchingRepos.png', 'contents/contents-operations.rst', 'pages/operations/streamlined-patching.rst']",5,8ed95318031043f23e9b38eedd62a41d64c2dd8f,editPatching,"Applying streamlined patches ============================Patching prerequisites ----------------------* Make sure you have the repositories configured correctly as described in :ref:`Configuring repositories<configuring-repos-ops>`. the patch -- usually ``yum`` or ``apt-get``, followed by restarting the associated service. The listed commands need to be executed on every node that you need to patch. In addition to the patch itself, Mirantis will also provide steps to verify that the patch was applied successfully. See below for an example. .. image:: /_images/errataPatching.png","Applying streamlined patching =============================Streamlined patching prerequisites ----------------------------------* Make sure you have the repositories configured correctly as described below. Configuring repositories ------------------------ By default, your environments will have the configuration of the repositories that point to the Mirantis update and security repository mirrors. There is also an 'Auxiliary' repository configured on the Fuel Master node which can be used to deliver packages to the nodes. To change the list of repositories, you will need to amend the three fields which contain the required information for the repositories configuration depending on the distribution you install. For CentOS ++++++++++ :: |repo-name|repo-baseurl|repo-priority| e.g :: my-repo http://my-domain.local/repo 10 For Ubuntu ++++++++++ :: |repo-name|apt-sources-list-string|repo-priority| my-repo deb http://my-domain.local/repo trusty main 1200 Additional information ++++++++++++++++++++++ For additional information read the following: * Ubuntu: `PinningHowto <https://help.ubuntu.com/community/PinningHowto>`_ * CentOS: `yum-plugin-priorities <http://wiki.centos.org/PackageManagement/Yum/Priorities>`_ the patch -- usually ``yum`` or ``apt-get``. The listed commands need to be executed on every node that you need to patch.",64,53
openstack%2Fautomaton~master~I218740910163a1ca2587d706edc55852af1c0c74,openstack/automaton,master,I218740910163a1ca2587d706edc55852af1c0c74,Add optional machine conversion into a pydot graph,MERGED,2015-06-13 20:12:33.000000000,2015-06-24 15:39:33.000000000,2015-06-24 15:39:31.000000000,"[{'_account_id': 3}, {'_account_id': 1297}, {'_account_id': 6618}, {'_account_id': 9453}, {'_account_id': 10584}]","[{'number': 1, 'created': '2015-06-13 20:12:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/automaton/commit/8a290713cbd7c25a2eb5e39c6f304c8b126fd6e1', 'message': 'Add optional machine conversion into a pydot graph\n\nBoth ironic and taskflow share this same code to convert\nthere state machines into a pydot graph which then gets\nconverted into SVG to form:\n\n- http://docs.openstack.org/developer/taskflow/states.html\n- http://docs.openstack.org/developer/ironic/dev/states.html\n\nSo instead of duplicating it, provide a useful helper function\nthat both (and others) can share to produce a dot/graphviz pretty\ndiagram from a state machine.\n\nChange-Id: I218740910163a1ca2587d706edc55852af1c0c74\n'}, {'number': 2, 'created': '2015-06-13 20:21:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/automaton/commit/502c7ed0c5a35f69621d96ebf7a995ebde85cb61', 'message': 'Add optional machine conversion into a pydot graph\n\nBoth ironic and taskflow share this same code to convert\nthere state machines into a pydot graph which then gets\nconverted into SVG to form:\n\n- http://docs.openstack.org/developer/taskflow/states.html\n- http://docs.openstack.org/developer/ironic/dev/states.html\n\nSo instead of duplicating it, provide a useful helper function\nthat both (and others) can share to produce a dot/graphviz pretty\ndiagram from a state machine.\n\nChange-Id: I218740910163a1ca2587d706edc55852af1c0c74\n'}, {'number': 3, 'created': '2015-06-16 03:27:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/automaton/commit/4180e288a67814148fbfcd9fcaa597fc77e9874f', 'message': 'Add optional machine conversion into a pydot graph\n\nBoth ironic and taskflow share this same code to convert\ntheir state machines into a pydot graph which then gets\nconverted into SVG to form:\n\n- http://docs.openstack.org/developer/taskflow/states.html\n- http://docs.openstack.org/developer/ironic/dev/states.html\n\nSo instead of duplicating it, provide a useful helper function\nthat both (and others) can share to produce a dot/graphviz pretty\ndiagram from a state machine.\n\nChange-Id: I218740910163a1ca2587d706edc55852af1c0c74\n'}, {'number': 4, 'created': '2015-06-16 03:28:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/automaton/commit/58626519ff022345d2f8cd1c83a36f6bae519dff', 'message': 'Add optional machine conversion into a pydot graph\n\nBoth ironic and taskflow share this same code to convert\ntheir state machines into a pydot graph which then gets\nconverted into SVG to form:\n\n- http://docs.openstack.org/developer/taskflow/states.html\n- http://docs.openstack.org/developer/ironic/dev/states.html\n\nSo instead of duplicating it, provide a useful helper function\nthat both (and others) can share to produce a dot/graphviz pretty\ndiagram from a state machine.\n\nChange-Id: I218740910163a1ca2587d706edc55852af1c0c74\n'}, {'number': 5, 'created': '2015-06-16 05:29:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/automaton/commit/b2d71a49fdc0b0c8ab0903a591721993dcc5438a', 'message': 'Add optional machine conversion into a pydot graph\n\nBoth ironic and taskflow share this same code to convert\ntheir state machines into a pydot graph which then gets\nconverted into SVG to form:\n\n- http://docs.openstack.org/developer/taskflow/states.html\n- http://docs.openstack.org/developer/ironic/dev/states.html\n\nSo instead of duplicating it, provide a useful helper function\nthat both (and others) can share to produce a dot/graphviz pretty\ndiagram from a state machine.\n\nChange-Id: I218740910163a1ca2587d706edc55852af1c0c74\n'}, {'number': 6, 'created': '2015-06-18 17:41:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/automaton/commit/94b8cba3a7d77128ed0a55647fbe5532ce555122', 'message': 'Add optional machine conversion into a pydot graph\n\nBoth ironic and taskflow share this same code to convert\ntheir state machines into a pydot graph which then gets\nconverted into SVG to form:\n\n- http://docs.openstack.org/developer/taskflow/states.html\n- http://docs.openstack.org/developer/ironic/dev/states.html\n\nSo instead of duplicating it, provide a useful helper function\nthat both (and others) can share to produce a dot/graphviz pretty\ndiagram from a state machine.\n\nChange-Id: I218740910163a1ca2587d706edc55852af1c0c74\n'}, {'number': 7, 'created': '2015-06-18 17:44:55.000000000', 'files': ['doc/source/api.rst', 'automaton/converters/__init__.py', 'automaton/converters/pydot.py'], 'web_link': 'https://opendev.org/openstack/automaton/commit/3898b1d803738aa811d4c88add2c75cec3dad00a', 'message': 'Add optional machine conversion into a pydot graph\n\nBoth ironic and taskflow share this same code to convert\ntheir state machines into a pydot graph which then gets\nconverted into SVG to form:\n\n- http://docs.openstack.org/developer/taskflow/states.html\n- http://docs.openstack.org/developer/ironic/dev/states.html\n\nSo instead of duplicating it, provide a useful helper function\nthat both (and others) can share to produce a dot/graphviz pretty\ndiagram from a state machine.\n\nChange-Id: I218740910163a1ca2587d706edc55852af1c0c74\n'}]",8,191526,3898b1d803738aa811d4c88add2c75cec3dad00a,25,5,7,1297,,,0,"Add optional machine conversion into a pydot graph

Both ironic and taskflow share this same code to convert
their state machines into a pydot graph which then gets
converted into SVG to form:

- http://docs.openstack.org/developer/taskflow/states.html
- http://docs.openstack.org/developer/ironic/dev/states.html

So instead of duplicating it, provide a useful helper function
that both (and others) can share to produce a dot/graphviz pretty
diagram from a state machine.

Change-Id: I218740910163a1ca2587d706edc55852af1c0c74
",git fetch https://review.opendev.org/openstack/automaton refs/changes/26/191526/5 && git format-patch -1 --stdout FETCH_HEAD,"['test-requirements.txt', 'automaton/machines.py']",2,8a290713cbd7c25a2eb5e39c6f304c8b126fd6e1,add-pydot-formatter," import pydot PYDOT_AVAILABLE = True except ImportError: PYDOT_AVAILABLE = False try: def to_dot(self, graph_name, graph_attrs_cb=None, node_attrs_cb=None, edge_attrs_cb=None, add_start_state=True): """"""Translates the state machine into a pydot graph."""""" if not PYDOT_AVAILABLE: raise RuntimeError(""pydot (or pydot2 or equivalent) is required"" "" to convert a state machine into a pydot"" "" graph"") graph_attrs = { 'graph_name': graph_name, 'rankdir': 'LR', 'nodesep': '0.25', 'overlap': 'false', 'ranksep': '0.5', 'size': ""11x8.5"", 'splines': 'true', 'ordering': 'in', } if graph_attrs_cb is not None: graph_attrs.update(graph_attrs_cb(graph_name)) g = pydot.Dot(**graph_attrs) node_attrs = { 'fontsize': '11', } nodes = {} for (start_state, event, end_state) in self: if start_state not in nodes: start_node_attrs = node_attrs.copy() if node_attrs_cb is not None: start_node_attrs.update(node_attrs_cb(start_state)) nodes[start_state] = pydot.Node(start_state, **start_node_attrs) g.add_node(nodes[start_state]) if end_state not in nodes: end_node_attrs = node_attrs.copy() if node_attrs_cb is not None: end_node_attrs.update(node_attrs_cb(end_state)) nodes[end_state] = pydot.Node(end_state, **end_node_attrs) g.add_node(nodes[end_state]) edge_attrs = {} if edge_attrs_cb is not None: edge_attrs.update(edge_attrs_cb(start_state, end_state)) g.add_edge(pydot.Edge(nodes[start_state], nodes[end_state], **edge_attrs)) if add_start_state and self.default_start_state: start = pydot.Node(""__start__"", shape=""point"", width=""0.1"", xlabel='start', fontcolor='green', **node_attrs) g.add_node(start) g.add_edge(pydot.Edge(start, nodes[self.default_start_state], style='dotted')) return g ",,60,0
openstack%2Fopenstack-manuals~master~I30686737c6cac1452bb7e826f4a8f6785182ae7e,openstack/openstack-manuals,master,I30686737c6cac1452bb7e826f4a8f6785182ae7e,fwaas/lbaas: create the required DB tables,MERGED,2015-06-22 16:07:32.000000000,2015-06-24 15:37:50.000000000,2015-06-24 15:37:49.000000000,"[{'_account_id': 3}, {'_account_id': 6547}, {'_account_id': 7923}, {'_account_id': 10897}, {'_account_id': 14643}, {'_account_id': 14947}]","[{'number': 1, 'created': '2015-06-22 16:07:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/3605e5071415b8fd244cf08e571df32b50100068', 'message': 'fwaas/lbaas: create the required DB tables\n\nFWaaS and LBaaS require additional tables in the neutron DB to be\nentirely functional.\n\nChange-Id: I30686737c6cac1452bb7e826f4a8f6785182ae7e\n'}, {'number': 2, 'created': '2015-06-24 03:31:44.000000000', 'files': ['doc/admin-guide-cloud/networking/section_networking_config-agents.xml', 'doc/admin-guide-cloud/networking/section_networking_introduction.xml'], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/a2f1fd8e4424a2adb9a9031bd6c0cabca5b8a187', 'message': 'fwaas/lbaas: create the required DB tables\n\nFWaaS and LBaaS require additional tables in the neutron DB to be\nentirely functional.\n\nChange-Id: I30686737c6cac1452bb7e826f4a8f6785182ae7e\nCloses-Bug: #1468161\n'}]",0,194214,a2f1fd8e4424a2adb9a9031bd6c0cabca5b8a187,15,6,2,7923,,,0,"fwaas/lbaas: create the required DB tables

FWaaS and LBaaS require additional tables in the neutron DB to be
entirely functional.

Change-Id: I30686737c6cac1452bb7e826f4a8f6785182ae7e
Closes-Bug: #1468161
",git fetch https://review.opendev.org/openstack/openstack-manuals refs/changes/14/194214/1 && git format-patch -1 --stdout FETCH_HEAD,"['doc/admin-guide-cloud/networking/section_networking_config-agents.xml', 'doc/admin-guide-cloud/networking/section_networking_introduction.xml']",2,3605e5071415b8fd244cf08e571df32b50100068,, <para>Create the required tables in the database:</para> <screen><prompt>#</prompt> <userinput>neutron-db-manage --service fwaas upgrade head</userinput></screen> </step> <step>,,10,0
openstack%2Fnova-specs~master~Iec6635bd0e24716bbc366c3faabf888d09700b56,openstack/nova-specs,master,Iec6635bd0e24716bbc366c3faabf888d09700b56,Add virt-driver CPU thread pinning,MERGED,2015-06-22 16:15:51.000000000,2015-06-24 15:37:36.000000000,2015-06-24 15:37:36.000000000,"[{'_account_id': 3}, {'_account_id': 782}, {'_account_id': 1779}, {'_account_id': 5511}, {'_account_id': 7730}, {'_account_id': 15334}]","[{'number': 1, 'created': '2015-06-22 16:15:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/a498a876f4d339d39c2aaeb6584c2f8f2ef5dae1', 'message': ""Add virt-driver CPU thread pinning\n\nhttps://blueprints.launchpad.net/nova/+spec/virt-driver-cpu-pinning\n\nResubmit the thread policy aspect of the 'virt-driver-cpu-pinning'\nspec, which was not implemented in Kilo.\n\nChange-Id: Iec6635bd0e24716bbc366c3faabf888d09700b56\nBlueprint: virt-driver-cpu-pinning\n""}, {'number': 2, 'created': '2015-06-23 09:12:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/61c2e18d8a4d0385bc081b0535068eae60025497', 'message': ""Add virt-driver CPU thread pinning\n\nhttps://blueprints.launchpad.net/nova/+spec/virt-driver-cpu-pinning\n\nResubmit the thread policy aspect of the 'virt-driver-cpu-pinning'\nspec, which was not implemented in Kilo.\n\nChange-Id: Iec6635bd0e24716bbc366c3faabf888d09700b56\nBlueprint: virt-driver-cpu-pinning\n""}, {'number': 3, 'created': '2015-06-23 09:18:53.000000000', 'files': ['specs/liberty/approved/virt-driver-cpu-pinning.rst'], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/390417ee0a8b309b5b06f0cae8959851854dd071', 'message': ""Add virt-driver CPU thread pinning\n\nhttps://blueprints.launchpad.net/nova/+spec/virt-driver-cpu-pinning\n\nResubmit the thread policy aspect of the 'virt-driver-cpu-pinning'\nspec, which was not implemented in Kilo.\n\nChange-Id: Iec6635bd0e24716bbc366c3faabf888d09700b56\nBlueprint: virt-driver-cpu-pinning\n""}]",0,194221,390417ee0a8b309b5b06f0cae8959851854dd071,14,6,3,15334,,,0,"Add virt-driver CPU thread pinning

https://blueprints.launchpad.net/nova/+spec/virt-driver-cpu-pinning

Resubmit the thread policy aspect of the 'virt-driver-cpu-pinning'
spec, which was not implemented in Kilo.

Change-Id: Iec6635bd0e24716bbc366c3faabf888d09700b56
Blueprint: virt-driver-cpu-pinning
",git fetch https://review.opendev.org/openstack/nova-specs refs/changes/21/194221/1 && git format-patch -1 --stdout FETCH_HEAD,"['specs/liberty/approved/virt-driver-cpu-pinning.rst', 'specs/liberty/approved/vif-driver-ib-passthrough.rst']",2,a498a876f4d339d39c2aaeb6584c2f8f2ef5dae1,bp/virt-driver-cpu-pinning,,,204,0
openstack%2Fkolla~master~I1ba6bd5148af12cacfd872591b3c7b84a8dccba2,openstack/kolla,master,I1ba6bd5148af12cacfd872591b3c7b84a8dccba2,Auto generate minimal environment variables doc,MERGED,2015-05-27 01:48:02.000000000,2015-06-24 15:35:06.000000000,2015-06-24 15:35:01.000000000,"[{'_account_id': 3}, {'_account_id': 2834}, {'_account_id': 3098}, {'_account_id': 10419}, {'_account_id': 10787}, {'_account_id': 13039}, {'_account_id': 14119}]","[{'number': 1, 'created': '2015-05-27 01:48:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla/commit/4f426a31af6487032e735cda9f5e895e89c65fee', 'message': 'Auto generate minimal environment variables doc\n\nThis script will generate the minimal-environment-variables doc\nbased on the what each services has in the check_required_var field.\nAnytime that field is changed run this script and commit the changes.\n\nChange-Id: I1ba6bd5148af12cacfd872591b3c7b84a8dccba2\n'}, {'number': 2, 'created': '2015-05-27 01:50:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla/commit/30fc0fc19d446ebbaf9c35fb18f6c4bcc7f3f2c4', 'message': 'Auto generate minimal environment variables doc\n\nThis script will generate the minimal-environment-variables doc\nbased on the what each services has in the check_required_var field.\nAnytime that field is changed run this script and commit the changes.\n\nChange-Id: I1ba6bd5148af12cacfd872591b3c7b84a8dccba2\n'}, {'number': 3, 'created': '2015-05-27 11:07:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla/commit/6750d4b6204210a07053447eaeb4e1f466a69869', 'message': 'Auto generate minimal environment variables doc\n\nThis script will generate the minimal-environment-variables doc\nbased on the what each services has in the check_required_var field.\nAnytime that field is changed run this script and commit the changes.\n\nCo-Authored-By: Lon Hohberger <lhh@redhat.com>\nChange-Id: I1ba6bd5148af12cacfd872591b3c7b84a8dccba2\n'}, {'number': 4, 'created': '2015-05-27 16:49:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla/commit/7c2c6c148de0792dc9ab1f672c14a5fec5db8c1c', 'message': 'Auto generate minimal environment variables doc\n\nThis script will generate the minimal-environment-variables doc\nbased on the what each services has in the check_required_var field.\nAnytime that field is changed run this script and commit the changes.\n\nFixes bug 1459347\n\nCo-Authored-By: Lon Hohberger <lhh@redhat.com>\nChange-Id: I1ba6bd5148af12cacfd872591b3c7b84a8dccba2\n'}, {'number': 5, 'created': '2015-05-28 12:58:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla/commit/b1334b22912d9a2031c9497ba6c3a703182f918f', 'message': 'Auto generate minimal environment variables doc\n\nThis script will generate the minimal-environment-variables doc\nbased on the what each services has in the check_required_var field.\nAnytime that field is changed run this script and commit the changes.\n\nCloses-bug: #1459347\n\nCo-Authored-By: Lon Hohberger <lhh@redhat.com>\nChange-Id: I1ba6bd5148af12cacfd872591b3c7b84a8dccba2\n'}, {'number': 6, 'created': '2015-06-22 15:03:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla/commit/4a8de8bea82235cad7f39b91663cb1ac9b6dee21', 'message': 'Auto generate minimal environment variables doc\n\nThis script will generate the minimal-environment-variables doc\nbased on the what each services has in the check_required_var field.\nAnytime that field is changed run this script and commit the changes.\n\nCloses-bug: #1459347\n\nCo-Authored-By: Lon Hohberger <lhh@redhat.com>\nChange-Id: I1ba6bd5148af12cacfd872591b3c7b84a8dccba2\n'}, {'number': 7, 'created': '2015-06-22 15:06:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla/commit/167026b5d8b6405b73253d234129caeaa3390bc6', 'message': 'Auto generate minimal environment variables doc\n\nThis script will generate the minimal-environment-variables doc\nbased on the what each services has in the check_required_var field.\nAnytime that field is changed run this script and commit the changes.\n\nCloses-bug: #1459347\n\nCo-Authored-By: Lon Hohberger <lhh@redhat.com>\nChange-Id: I1ba6bd5148af12cacfd872591b3c7b84a8dccba2\n'}, {'number': 8, 'created': '2015-06-22 15:08:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla/commit/af702bdfcbe07f7e32d2fbba9ec06a7fcc045951', 'message': 'Auto generate minimal environment variables doc\n\nThis script will generate the minimal-environment-variables doc\nbased on the what each services has in the check_required_var field.\nAnytime that field is changed run this script and commit the changes.\n\nCloses-bug: #1459347\n\nCo-Authored-By: Lon Hohberger <lhh@redhat.com>\nChange-Id: I1ba6bd5148af12cacfd872591b3c7b84a8dccba2\n'}, {'number': 9, 'created': '2015-06-24 14:48:57.000000000', 'files': ['tools/min-env.sh', 'docs/minimal-environment-vars.md'], 'web_link': 'https://opendev.org/openstack/kolla/commit/01e90ec2e575e4545037cb9c2953fd5347bfb875', 'message': 'Auto generate minimal environment variables doc\n\nThis script will generate the minimal-environment-variables doc\nbased on the what each services has in the check_required_var field.\nAnytime that field is changed run this script and commit the changes.\nSince Neutron is a thick container, the script will get a few duplicates\nin the neutron-agents field.  When Neutron is thinned out, this script\nwill function normally.\n\nCloses-bug: #1459347\n\nCo-Authored-By: Lon Hohberger <lhh@redhat.com>\nChange-Id: I1ba6bd5148af12cacfd872591b3c7b84a8dccba2\n'}]",13,185814,01e90ec2e575e4545037cb9c2953fd5347bfb875,36,7,9,10419,,,0,"Auto generate minimal environment variables doc

This script will generate the minimal-environment-variables doc
based on the what each services has in the check_required_var field.
Anytime that field is changed run this script and commit the changes.
Since Neutron is a thick container, the script will get a few duplicates
in the neutron-agents field.  When Neutron is thinned out, this script
will function normally.

Closes-bug: #1459347

Co-Authored-By: Lon Hohberger <lhh@redhat.com>
Change-Id: I1ba6bd5148af12cacfd872591b3c7b84a8dccba2
",git fetch https://review.opendev.org/openstack/kolla refs/changes/14/185814/9 && git format-patch -1 --stdout FETCH_HEAD,"['tools/min-env.sh', 'docs/minimal-environment-vars.md']",2,4f426a31af6487032e735cda9f5e895e89c65fee,bug/1459347,# Barbican KEYSTONE_ADMIN_SERVICE_PORT BARBICAN_ADMIN_PASSWORD GLANCE_KEYSTONE_USER GLANCE_KEYSTONE_PASSWORD ADMIN_TENANT_NAME GLANCE_DB_USER GLANCE_DB_PASSWORD # Rabbitmq None # Swift-account SWIFT_ADMIN_PASSWORD # Swift-proxy-server None # Swift-object KEYSTONE_ADMIN_TOKEN KEYSTONE_ADMIN_SERVICE_HOST SWIFT_ADMIN_PASSWORD # Swift-container KEYSTONE_ADMIN_TOKEN KEYSTONE_ADMIN_SERVICE_HOST SWIFT_ADMIN_PASSWORD # Heat-api-cfn KEYSTONE_ADMIN_TOKEN KEYSTONE_ADMIN_SERVICE_HOST HEAT_CFN_KEYSTONE_USER HEAT_CFN_KEYSTONE_PASSWORD KEYSTONE_AUTH_PROTOCOL KEYSTONE_ADMIN_SERVICE_PORT ADMIN_TENANT_NAME HEAT_API_CFN_SERVICE_HOST HEAT_API_CFN_SERVICE_PORT # Heat-api KEYSTONE_ADMIN_TOKEN KEYSTONE_ADMIN_SERVICE_HOST HEAT_KEYSTONE_USER HEAT_KEYSTONE_PASSWORD KEYSTONE_AUTH_PROTOCOL ADMIN_TENANT_NAME HEAT_API_SERVICE_HOST# Heat-engine HEAT_DB_NAME HEAT_DB_USER HEAT_DB_PASSWORD # Ceilometer-central KEYSTONE_ADMIN_SERVICE_PORT # Ceilometer-alarm None # Ceilometer-api CEILOMETER_DB_USER CEILOMETER_DB_NAME CEILOMETER_DB_PASSWORD KEYSTONE_ADMIN_TOKEN KEYSTONE_AUTH_PROTOCOL KEYSTONE_ADMIN_SERVICE_HOST KEYSTONE_ADMIN_SERVICE_PORT ADMIN_TENANT_NAME CEILOMETER_KEYSTONE_USER CEILOMETER_ADMIN_PASSWORD CEILOMETER_API_SERVICE_HOST PUBLIC_IP # Ceilometer-collector None # Ceilometer-notification None # Ceilometer-compute KEYSTONE_ADMIN_TOKEN RABBIT_PASSWORD None # Nova-compute None # Cinder CINDER_ADMIN_PASSWORD # Zaqar ZAQAR_KEYSTONE_PASSWORD ZAQAR_SERVER_SERVICE_HOST KEYSTONE_ADMIN_SERVICE_HOST KEYSTONE_ADMIN_TOKEN# Horizon None # Neutron-server KEYSTONE_ADMIN_TOKEN KEYSTONE_ADMIN_SERVICE_HOST KEYSTONE_AUTH_PROTOCOL NOVA_API_SERVICE_HOST NOVA_KEYSTONE_USER NOVA_KEYSTONE_PASSWORD ADMIN_TENANT_NAME PUBLIC_IP NEUTRON_DB_PASSWORD # Magnum-conductor MAGNUM_DB_NAME MAGNUM_DB_USER MAGNUM_DB_PASSWORD # Magnum-api KEYSTONE_ADMIN_TOKEN KEYSTONE_ADMIN_SERVICE_HOST MAGNUM_KEYSTONE_USER MAGNUM_KEYSTONE_PASSWORD KEYSTONE_AUTH_PROTOCOL ADMIN_TENANT_NAME MAGNUM_API_SERVICE_HOST KEYSTONE_ADMIN_SERVICE_PORT MAGNUM_API_SERVICE_PORT # Nova-conductor NOVA_DB_NAME NOVA_DB_USER NOVA_DB_PASSWORD # Nova-novncproxy PUBLIC_IP NOVA_NOVNC_PROXY_SERVICE_HOST NOVA_NOVNC_PROXY_PORT NOVA_NOVNC_BASE_ADDRESS NOVA_VNCSERVER_LISTEN_ADDRESS NOVA_VNCSERVER_PROXYCLIENT_ADDRESS # Nova-consoleauth None # Nova-api KEYSTONE_ADMIN_TOKEN KEYSTONE_ADMIN_SERVICE_HOST NOVA_KEYSTONE_USER NOVA_KEYSTONE_PASSWORD ADMIN_TENANT_NAME NOVA_API_SERVICE_HOST NOVA_EC2_API_SERVICE_HOST PUBLIC_IP NOVA_DB_NAME # Nova-scheduler NOVA_DB_NAME # Keystone KEYSTONE_ADMIN_TOKEN KEYSTONE_DB_PASSWORD KEYSTONE_ADMIN_PASSWORD ADMIN_TENANT_NAME KEYSTONE_PUBLIC_SERVICE_HOST KEYSTONE_ADMIN_SERVICE_HOST PUBLIC_IP,# Logging DEBUG_LOGGING VERBOSE_LOGGING NOVA_LOG_DIR NEUTRON_LOG_DIR NOVA_API_LOG_FILE NOVA_CONDUCTOR_LOG_FILE NOVA_SCHEDULER_LOG_FILE NOVA_COMPUTE_LOG_FILE NEUTRON_SERVER_LOG_FILE NEUTRON_L3_AGENT_LOG_FILE NEUTRON_LINUXBRIDGE_AGENT_LOG_FILE NEUTRON_METADATA_AGENT_LOG_FILE # Mariadb MARIADB_SERVICE_HOST MYSQL_ROOT_PASSWORD # Keystone MYSQL_ROOT_PASSWORD GLANCE_KEYSTONE_PASSWORD GLANCE_KEYSTONE_USER KEYSTONE_ADMIN_PASSWORD KEYSTONE_ADMIN_SERVICE_PORT KEYSTONE_AUTH_PROTOCOL KEYSTONE_DB_PASSWORD NOVA_KEYSTONE_PASSWORD NOVA_KEYSTONE_USER ADMIN_TENANT_NAME DB_ROOT_PASSWORD KEYSTONE_PUBLIC_SERVICE_HOST MARIADB_SERVICE_HOST MYSQL_ROOT_PASSWORD GLANCE_KEYSTONE_PASSWORD GLANCE_KEYSTONE_USER GLANCE_DB_USER GLANCE_DB_NAME KEYSTONE_ADMIN_PASSWORD KEYSTONE_ADMIN_SERVICE_PORT KEYSTONE_AUTH_PROTOCOL KEYSTONE_DB_PASSWORD NOVA_KEYSTONE_PASSWORD NOVA_KEYSTONE_USER ADMIN_TENANT_NAME DB_ROOT_PASSWORD KEYSTONE_PUBLIC_SERVICE_HOST MARIADB_SERVICE_HOST GLANCE_REGISTRY_SERVICE_HOST MYSQL_ROOT_PASSWORD GLANCE_KEYSTONE_PASSWORD GLANCE_KEYSTONE_USER GLANCE_DB_USER KEYSTONE_ADMIN_PASSWORD KEYSTONE_ADMIN_SERVICE_PORT KEYSTONE_AUTH_PROTOCOL KEYSTONE_DB_PASSWORD NOVA_KEYSTONE_PASSWORD NOVA_KEYSTONE_USER ADMIN_TENANT_NAME DB_ROOT_PASSWORD KEYSTONE_PUBLIC_SERVICE_HOST MARIADB_SERVICE_HOST GLANCE_REGISTRY_SERVICE_HOST GLANCE_API_SERVICE_HOST# Nova-conductor MYSQL_ROOT_PASSWORD NOVA_KEYSTONE_PASSWORD NOVA_KEYSTONE_USER NOVA_DB_USER NOVA_DB_NAME KEYSTONE_ADMIN_PASSWORD KEYSTONE_ADMIN_SERVICE_PORT KEYSTONE_DB_PASSWORD ADMIN_TENANT_NAME DB_ROOT_PASSWORD MYSQL_ROOT_PASSWORD NOVA_KEYSTONE_PASSWORD NOVA_KEYSTONE_USER NOVA_DB_USER NOVA_DB_NAME KEYSTONE_ADMIN_PASSWORD KEYSTONE_ADMIN_SERVICE_PORT KEYSTONE_ADMIN_TOKEN KEYSTONE_AUTH_PROTOCOL KEYSTONE_DB_PASSWORD ADMIN_TENANT_NAME DB_ROOT_PASSWORD PUBLIC_INTERFACE FLAT_INTERFACE KEYSTONE_PUBLIC_SERVICE_HOST MARIADB_SERVICE_HOST GLANCE_API_SERVICE_HOST NOVA_CONDUCTOR_SERVICE_HOST NOVA_EC2_API_SERVICE_HOST NOVA_EC2_SERVICE_HOST PUBLIC_IP # Nova-api MYSQL_ROOT_PASSWORD NOVA_KEYSTONE_PASSWORD NOVA_KEYSTONE_USER NOVA_DB_USER NOVA_DB_NAME KEYSTONE_ADMIN_PASSWORD KEYSTONE_ADMIN_SERVICE_PORT KEYSTONE_ADMIN_TOKEN KEYSTONE_AUTH_PROTOCOL KEYSTONE_DB_PASSWORD ADMIN_TENANT_NAME DB_ROOT_PASSWORD PUBLIC_INTERFACE FLAT_INTERFACE KEYSTONE_ADMIN_SERVICE_HOST KEYSTONE_PUBLIC_SERVICE_HOST MARIADB_SERVICE_HOST RABBITMQ_SERVICE_HOST GLANCE_API_SERVICE_HOST NOVA_API_SERVICE_HOST NOVA_EC2_API_SERVICE_HOST NOVA_EC2_SERVICE_HOST NOVA_METADATA_API_SERVICE_HOST PUBLIC_IP # Nova-compute MYSQL_ROOT_PASSWORD NOVA_KEYSTONE_PASSWORD NOVA_KEYSTONE_USER NOVA_DB_USER NOVA_DB_NAME KEYSTONE_ADMIN_PASSWORD KEYSTONE_ADMIN_SERVICE_PORT KEYSTONE_ADMIN_TOKEN KEYSTONE_AUTH_PROTOCOL KEYSTONE_DB_PASSWORD ADMIN_TENANT_NAME DB_ROOT_PASSWORD PUBLIC_INTERFACE FLAT_INTERFACE KEYSTONE_ADMIN_SERVICE_HOST KEYSTONE_PUBLIC_SERVICE_HOST MARIADB_SERVICE_HOST RABBITMQ_SERVICE_HOST GLANCE_API_SERVICE_HOST NOVA_COMPUTE_SERVICE_HOST NOVA_EC2_COMPUTE_SERVICE_HOST NOVA_EC2_SERVICE_HOST NOVA_NOVNC_BASE_ADDRESS NOVA_NOVNC_PROXY_PORT PUBLIC_IP# Nova-scheduler MYSQL_ROOT_PASSWORD NOVA_KEYSTONE_PASSWORD NOVA_KEYSTONE_USER NOVA_DB_USER NOVA_DB_NAME KEYSTONE_ADMIN_PASSWORD KEYSTONE_ADMIN_SERVICE_PORT KEYSTONE_ADMIN_TOKEN KEYSTONE_AUTH_PROTOCOL KEYSTONE_DB_PASSWORD ADMIN_TENANT_NAME DB_ROOT_PASSWORD PUBLIC_INTERFACE FLAT_INTERFACE KEYSTONE_ADMIN_SERVICE_HOST KEYSTONE_PUBLIC_SERVICE_HOST MARIADB_SERVICE_HOST RABBITMQ_SERVICE_HOST GLANCE_API_SERVICE_HOST NOVA_SCHEDULER_SERVICE_HOST NOVA_EC2_SCHEDULER_SERVICE_HOST NOVA_EC2_SERVICE_HOST PUBLIC_IP MYSQL_ROOT_PASSWORD NOVA_KEYSTONE_PASSWORD NOVA_KEYSTONE_USER NOVA_DB_USER NOVA_DB_NAME KEYSTONE_ADMIN_PASSWORD KEYSTONE_ADMIN_SERVICE_PORT KEYSTONE_AUTH_PROTOCOL KEYSTONE_DB_PASSWORD ADMIN_TENANT_NAME DB_ROOT_PASSWORD PUBLIC_INTERFACE FLAT_INTERFACE KEYSTONE_PUBLIC_SERVICE_HOST MARIADB_SERVICE_HOST RABBITMQ_SERVICE_HOST GLANCE_API_SERVICE_HOST NOVA_NETWORK_SERVICE_HOST NOVA_EC2_NETWORK_SERVICE_HOST NOVA_EC2_SERVICE_HOST# Nova NoVNC NOVA_VNCSERVER_LISTEN_ADDRESS NOVA_VNCSERVER_PROXYCLIENT_ADDRESS # Neutron/Nova NEUTRON_SHARED_SECRET # Neutron Server NEUTRON_API_PASTE_CONFIG # Neutron ML2 PLugin TYPE_DRIVERS TENANT_NETWORK_TYPES MECHANISM_DRIVERS # Neutron Linux Bridge Plugin NEUTRON_FLAT_NETWORK_NAME NEUTRON_FLAT_NETWORK_INTERFACE,238,215
openstack%2Fopenstacksdk~master~Ibc553b0927e019cd03dc49ec16b5e41e4526bde3,openstack/openstacksdk,master,Ibc553b0927e019cd03dc49ec16b5e41e4526bde3,Add Heat resource support,MERGED,2015-05-07 16:33:28.000000000,2015-06-24 15:29:56.000000000,2015-06-24 15:29:51.000000000,"[{'_account_id': 3}, {'_account_id': 1112}, {'_account_id': 8246}, {'_account_id': 8257}, {'_account_id': 8736}, {'_account_id': 12807}]","[{'number': 1, 'created': '2015-05-07 16:33:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstacksdk/commit/136c6855858caab71d855af0f0d60c2bef080096', 'message': 'Add Heat resource support\n\nThis patch adds support to listing resources in a Heat stack. To make\nthe test case happy, test_proxy_base is slightly modified. Also, when\ntesting proxy, some mock calls are introduced.\n\nChange-Id: Ibc553b0927e019cd03dc49ec16b5e41e4526bde3\n'}, {'number': 2, 'created': '2015-05-26 08:14:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstacksdk/commit/2d86ee1a0fd7adf385632f0c0c2b31dcc8c07356', 'message': 'Add Heat resource support\n\nThis patch adds support to listing resources in a Heat stack. To make\nthe test case happy, test_proxy_base is slightly modified. Also, when\ntesting proxy, some mock calls are introduced.\n\nChange-Id: Ibc553b0927e019cd03dc49ec16b5e41e4526bde3\n'}, {'number': 3, 'created': '2015-05-26 23:21:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstacksdk/commit/9770be43d5a20fa5abb46c7d9e2f3374dd2f996a', 'message': 'Add Heat resource support\n\nThis patch adds support to listing resources from a Heat stack. To the\nmake the test case happy, test_proxy_base is slightly modified. Also,\nwhen testing proxy methods, some mock calls (decorators) are introduced.\n\nChange-Id: Ibc553b0927e019cd03dc49ec16b5e41e4526bde3\n'}, {'number': 4, 'created': '2015-05-28 01:02:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstacksdk/commit/3e218db42d26d5f4cb70d1a89bb4024d2c83456e', 'message': 'Add Heat resource support\n\nThis patch adds support to listing resources from a Heat stack. To the\nmake the test case happy, test_proxy_base is slightly modified. Also,\nwhen testing proxy methods, some mock calls (decorators) are introduced.\n\nChange-Id: Ibc553b0927e019cd03dc49ec16b5e41e4526bde3\n'}, {'number': 5, 'created': '2015-06-02 03:10:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstacksdk/commit/d161dbd9c7dd0643a22b253ca67b1337edd573b9', 'message': 'Add Heat resource support\n\nThis patch adds support to listing resources from a Heat stack. To the\nmake the test case happy, test_proxy_base is slightly modified. Also,\nwhen testing proxy methods, some mock calls (decorators) are introduced.\n\nChange-Id: Ibc553b0927e019cd03dc49ec16b5e41e4526bde3\n'}, {'number': 6, 'created': '2015-06-03 02:56:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstacksdk/commit/fbdfa912a0ae9ec65b8a9f62e7b95e380df45e25', 'message': 'Add Heat resource support\n\nThis patch adds support to listing resources from a Heat stack. To the\nmake the test case happy, test_proxy_base is slightly modified. Also,\nwhen testing proxy methods, some mock calls (decorators) are introduced.\n\nChange-Id: Ibc553b0927e019cd03dc49ec16b5e41e4526bde3\n'}, {'number': 7, 'created': '2015-06-03 03:38:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstacksdk/commit/775625200157a1e039a0b4af4fd8c739ad1ffbe2', 'message': 'Add Heat resource support\n\nThis patch adds support to listing resources from a Heat stack. To the\nmake the test case happy, test_proxy_base is slightly modified. Also,\nwhen testing proxy methods, some mock calls (decorators) are introduced.\n\nChange-Id: Ibc553b0927e019cd03dc49ec16b5e41e4526bde3\n'}, {'number': 8, 'created': '2015-06-03 05:55:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstacksdk/commit/c5264904b9cac4d5c913805e491c31c874bed96a', 'message': 'Add Heat resource support\n\nThis patch adds support to listing resources from a Heat stack. To the\nmake the test case happy, test_proxy_base is slightly modified. Also,\nwhen testing proxy methods, some mock calls (decorators) are introduced.\n\nTo ease functional tests, the patch also revised the functional test\nused.\n\nChange-Id: Ibc553b0927e019cd03dc49ec16b5e41e4526bde3\n'}, {'number': 9, 'created': '2015-06-04 06:43:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstacksdk/commit/1c98a77d50e78409a1a22a2164e3a9fcdb2d0359', 'message': 'Add Heat resource support\n\nThis patch adds support to listing resources from a Heat stack. To the\nmake the test case happy, test_proxy_base is slightly modified. Also,\nwhen testing proxy methods, some mock calls (decorators) are introduced.\n\nThe functional test in previous patchsets is pulled out and left as a\nTODO item. Will need to fix some related resource.find() logic before\nmaking functional tests work.\n\nChange-Id: Ibc553b0927e019cd03dc49ec16b5e41e4526bde3\n'}, {'number': 10, 'created': '2015-06-18 04:49:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstacksdk/commit/8e1b88870bcf4526b2208d00c4a66c6f866863f5', 'message': 'Add Heat resource support\n\nThis patch adds support to listing resources from a Heat stack. To the\nmake the test case happy, test_proxy_base is slightly modified. Also,\nwhen testing proxy methods, some mock calls (decorators) are introduced.\n\nThe functional test in previous patchsets is pulled out and left as a\nTODO item. Will need to fix some related resource.find() logic before\nmaking functional tests work.\n\nChange-Id: Ibc553b0927e019cd03dc49ec16b5e41e4526bde3\n'}, {'number': 11, 'created': '2015-06-23 03:27:55.000000000', 'files': ['openstack/tests/unit/orchestration/v1/test_proxy.py', 'openstack/tests/unit/orchestration/v1/test_resource.py', 'openstack/orchestration/v1/_proxy.py', 'openstack/orchestration/v1/resource.py'], 'web_link': 'https://opendev.org/openstack/openstacksdk/commit/631faeb44665573700d795a0934d40c275b8bac2', 'message': 'Add Heat resource support\n\nThis patch adds support to listing resources from a Heat stack. To the\nmake the test case happy, test_proxy_base is slightly modified. Also,\nwhen testing proxy methods, some mock calls (decorators) are introduced.\n\nThe functional test in previous patchsets is pulled out and left as a\nTODO item. Will need to fix some related resource.find() logic before\nmaking functional tests work.\n\nChange-Id: Ibc553b0927e019cd03dc49ec16b5e41e4526bde3\n'}]",31,181063,631faeb44665573700d795a0934d40c275b8bac2,63,6,11,8246,,,0,"Add Heat resource support

This patch adds support to listing resources from a Heat stack. To the
make the test case happy, test_proxy_base is slightly modified. Also,
when testing proxy methods, some mock calls (decorators) are introduced.

The functional test in previous patchsets is pulled out and left as a
TODO item. Will need to fix some related resource.find() logic before
making functional tests work.

Change-Id: Ibc553b0927e019cd03dc49ec16b5e41e4526bde3
",git fetch https://review.opendev.org/openstack/openstacksdk refs/changes/63/181063/11 && git format-patch -1 --stdout FETCH_HEAD,"['openstack/tests/unit/orchestration/v1/test_proxy.py', 'openstack/tests/unit/orchestration/v1/test_resource.py', 'openstack/orchestration/v1/_proxy.py', 'openstack/orchestration/v1/resource.py', 'openstack/tests/unit/test_proxy_base.py']",5,136c6855858caab71d855af0f0d60c2bef080096,heat-res," def verify_list(self, mock_method, test_method, expected_result=[""result""], **kwargs): self._verify(mock_method, test_method, expected_result=expected_result,"," def verify_list(self, mock_method, test_method, **kwargs): self._verify(mock_method, test_method, expected_result=[""result""],",144,2
openstack%2Fkolla~master~I73bcd1c97bbaf742af883dbf281a8d76aff8aebf,openstack/kolla,master,I73bcd1c97bbaf742af883dbf281a8d76aff8aebf,Change fat neutron container into thin containers,MERGED,2015-06-19 10:02:52.000000000,2015-06-24 15:29:02.000000000,2015-06-24 15:28:59.000000000,"[{'_account_id': 3}, {'_account_id': 1390}, {'_account_id': 2834}, {'_account_id': 3098}, {'_account_id': 10428}, {'_account_id': 14119}]","[{'number': 1, 'created': '2015-06-19 10:02:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla/commit/ac1529c7ad06d446360757810f17f1e95ad381ba', 'message': 'WIP Change fat neutron container into thin contianers\n\nKeep difference here is the ip_wrapper.py file. This file and docker 1.7\nallow for the network namespaces to be created in the host mount\nnamespace and propogated into the containers.\n\nChange-Id: I73bcd1c97bbaf742af883dbf281a8d76aff8aebf\n'}, {'number': 2, 'created': '2015-06-20 08:06:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla/commit/05137359c40019c4c097c2f1086e4d76e5ccf9b3', 'message': 'WIP Change fat neutron container into thin contianers\n\nKeep difference here is the ip_wrapper.py file. This file and docker 1.7\nallow for the network namespaces to be created in the host mount\nnamespace and propogated into the containers.\n\nChange-Id: I73bcd1c97bbaf742af883dbf281a8d76aff8aebf\n'}, {'number': 3, 'created': '2015-06-24 08:25:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla/commit/8a4a3c17c274d50e1d281610c1999669268850e1', 'message': 'Change fat neutron container into thin containers\n\nKey difference here is the ip_wrapper.py file. This file and docker 1.7\nallow for the network namespaces to be created in the host mount\nnamespace and propogated into the containers.\n\nChange-Id: I73bcd1c97bbaf742af883dbf281a8d76aff8aebf\n'}, {'number': 4, 'created': '2015-06-24 08:30:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla/commit/6642b1ebce6dac083265a38e795b468bfef0ea23', 'message': 'Change fat neutron container into thin containers\n\nKey difference here is the ip_wrapper.py file. This file and docker 1.7\nallow for the network namespaces to be created in the host mount\nnamespace and propogated into the containers.\n\nCo-Authored-By: Paul Bourke <paul.bourke@oracle.com>\nChange-Id: I73bcd1c97bbaf742af883dbf281a8d76aff8aebf\n'}, {'number': 5, 'created': '2015-06-24 09:01:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla/commit/7a80c32a72431c5c576e60a90af2f173285af9ee', 'message': 'Change fat neutron container into thin containers\n\nKey difference here is the ip_wrapper.py file. This file and docker 1.7\nallow for the network namespaces to be created in the host mount\nnamespace and propogated into the containers.\n\nCo-Authored-By: Paul Bourke <paul.bourke@oracle.com>\nChange-Id: I73bcd1c97bbaf742af883dbf281a8d76aff8aebf\n'}, {'number': 6, 'created': '2015-06-24 14:15:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla/commit/cce0a437899420ba9b90b7915d52f1becc890011', 'message': 'Change fat neutron container into thin containers\n\nKey difference here is the ip_wrapper.py file. This file and docker 1.7\nallow for the network namespaces to be created in the host mount\nnamespace and propogated into the containers.\n\nCo-Authored-By: Paul Bourke <paul.bourke@oracle.com>\nChange-Id: I73bcd1c97bbaf742af883dbf281a8d76aff8aebf\n'}, {'number': 7, 'created': '2015-06-24 14:41:38.000000000', 'files': ['docker/centos/binary/neutron/neutron-agents/supervisord.conf', 'docker/common/neutron/neutron-l3-agent/fwaas_driver.ini', 'docker/centos/binary/neutron/neutron-l3-agent/Dockerfile', 'docker/centos/binary/neutron/neutron-agents/check-scripts/check-l3-agent.sh', 'docker/common/neutron/neutron-agents/supervisord.conf', 'compose/neutron-metadata-agent.yml', 'tools/kolla', 'docker/centos/binary/neutron/neutron-metadata-agent/Dockerfile', 'docker/common/neutron/neutron-metadata-agent/check.sh', 'docker/centos/binary/neutron/neutron-agents/Dockerfile', 'docker/centos/binary/neutron/neutron-dhcp-agent/start.sh', 'docker/centos/binary/neutron/neutron-metadata-agent/check.sh', 'compose/neutron-dhcp-agent.yml', 'compose/neutron-agents.yml', 'docker/common/neutron/neutron-linuxbridge-agent/check.sh', 'docker/centos/binary/neutron/neutron-l3-agent/start.sh', 'docker/centos/binary/neutron/neutron-dhcp-agent/build', 'docker/centos/binary/neutron/neutron-l3-agent/fwaas_driver.ini', 'docker/centos/binary/neutron/neutron-linuxbridge-agent/check.sh', 'docker/centos/binary/neutron/neutron-linuxbridge-agent/start.sh', 'docker/centos/binary/neutron/neutron-agents/check-scripts/check-linuxbridge-agent.sh', 'docker/centos/binary/neutron/neutron-dhcp-agent/Dockerfile', 'docker/centos/binary/neutron/neutron-agents/config-scripts/config-sudoers.sh', 'compose/neutron-linuxbridge-agent.yml', 'docker/common/neutron/neutron-dhcp-agent/start.sh', 'docker/common/neutron/neutron-l3-agent/check.sh', 'docker/common/neutron/neutron-l3-agent/start.sh', 'docker/centos/binary/neutron/neutron-agents/check-scripts/check-dhcp-agent.sh', 'docker/centos/binary/neutron/neutron-agents/config-scripts/config-metadata-agent.sh', 'docker/centos/binary/neutron/neutron-base/Dockerfile', 'docker/common/neutron/neutron-dhcp-agent/check.sh', 'docker/centos/binary/neutron/neutron-l3-agent/check.sh', 'docker/centos/binary/neutron/neutron-metadata-agent/build', 'compose/neutron-l3-agent.yml', 'docker/centos/binary/neutron/neutron-agents/fwaas_driver.ini', 'docker/centos/binary/neutron/neutron-agents/config-scripts/config-l3-agent.sh', 'docker/centos/binary/neutron/neutron-base/config-sudoers.sh', 'docker/centos/binary/neutron/neutron-agents/check-scripts/check-metadata-agent.sh', 'docker/centos/binary/neutron/neutron-dhcp-agent/check.sh', 'docker/centos/binary/neutron/neutron-linuxbridge-agent/build', 'docker/centos/binary/neutron/neutron-agents/config-scripts/config-dhcp-agent.sh', 'docker/centos/binary/neutron/neutron-base/ip_wrapper.py', 'docker/centos/binary/neutron/neutron-agents/config-scripts/config-linuxbridge-agent.sh', 'docker/centos/binary/neutron/neutron-l3-agent/build', 'docker/centos/binary/neutron/neutron-server/Dockerfile', 'docker/centos/binary/neutron/neutron-metadata-agent/start.sh', 'docker/centos/binary/neutron/neutron-linuxbridge-agent/Dockerfile', 'docker/common/neutron/neutron-linuxbridge-agent/start.sh', 'docker/common/neutron/neutron-metadata-agent/start.sh'], 'web_link': 'https://opendev.org/openstack/kolla/commit/98460af04d626907f44ea1b13289769979ed4f7b', 'message': 'Change fat neutron container into thin containers\n\nKey difference here is the ip_wrapper.py file. This file and docker 1.7\nallow for the network namespaces to be created in the host mount\nnamespace and propogated into the containers.\n\nCo-Authored-By: Paul Bourke <paul.bourke@oracle.com>\nChange-Id: I73bcd1c97bbaf742af883dbf281a8d76aff8aebf\n'}]",38,193480,98460af04d626907f44ea1b13289769979ed4f7b,31,6,7,14119,,,0,"Change fat neutron container into thin containers

Key difference here is the ip_wrapper.py file. This file and docker 1.7
allow for the network namespaces to be created in the host mount
namespace and propogated into the containers.

Co-Authored-By: Paul Bourke <paul.bourke@oracle.com>
Change-Id: I73bcd1c97bbaf742af883dbf281a8d76aff8aebf
",git fetch https://review.opendev.org/openstack/kolla refs/changes/80/193480/7 && git format-patch -1 --stdout FETCH_HEAD,"['docker/centos/binary/neutron/neutron-agents/supervisord.conf', 'docker/centos/binary/neutron/neutron-dhcp-agent/build', 'docker/centos/binary/neutron/neutron-l3-agent/check.sh', 'docker/centos/binary/neutron/neutron-l3-agent/fwaas_driver.ini', 'docker/centos/binary/neutron/neutron-linuxbridge-agent/check.sh', 'docker/centos/binary/neutron/neutron-metadata-agent/build', 'docker/centos/binary/neutron/neutron-linuxbridge-agent/start.sh', 'docker/centos/binary/neutron/neutron-base/config-sudoers.sh', 'docker/centos/binary/neutron/neutron-dhcp-agent/Dockerfile', 'docker/centos/binary/neutron/neutron-l3-agent/Dockerfile', 'docker/centos/binary/neutron/neutron-dhcp-agent/check.sh', 'docker/centos/binary/neutron/neutron-agents/Dockerfile', 'docker/centos/binary/neutron/neutron-dhcp-agent/start.sh', 'docker/centos/binary/neutron/neutron-linuxbridge-agent/build', 'docker/centos/binary/neutron/neutron-metadata-agent/check.sh', 'docker/centos/binary/neutron/neutron-base/ip_wrapper.py', 'docker/centos/binary/neutron/neutron-base/Dockerfile', 'docker/centos/binary/neutron/neutron-l3-agent/build', 'docker/centos/binary/neutron/neutron-l3-agent/start.sh', 'docker/centos/binary/neutron/neutron-metadata-agent/Dockerfile', 'docker/centos/binary/neutron/neutron-server/Dockerfile', 'docker/centos/binary/neutron/neutron-metadata-agent/start.sh', 'docker/centos/binary/neutron/neutron-linuxbridge-agent/Dockerfile']",23,ac1529c7ad06d446360757810f17f1e95ad381ba,bp/thin-neutron-agents,"FROM %%KOLLA_NAMESPACE%%/%%KOLLA_PREFIX%%neutron-base:%%KOLLA_TAG%% MAINTAINER Kolla Project (https://launchpad.net/kolla) # Install required packages RUN yum install -y openstack-neutron-linuxbridge && \ yum clean all COPY check.sh start.sh / CMD [""/start.sh""] ",,82,110
openstack%2Ffuel-docs~master~I8f4f56d3ea246bfe85332ed716de4f6495942283,openstack/fuel-docs,master,I8f4f56d3ea246bfe85332ed716de4f6495942283,Add Murano features,MERGED,2015-06-24 13:43:09.000000000,2015-06-24 15:28:10.000000000,2015-06-24 14:36:43.000000000,"[{'_account_id': 3}, {'_account_id': 8971}, {'_account_id': 13082}]","[{'number': 1, 'created': '2015-06-24 13:43:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-docs/commit/7ad65edbfe9f06c50ed2f8497c6fe75e3581f7c3', 'message': 'Add Murano features\n\nAdd Murano features to the 6.1 relnotes\n\nChange-Id: I8f4f56d3ea246bfe85332ed716de4f6495942283\n'}, {'number': 2, 'created': '2015-06-24 14:28:09.000000000', 'files': ['pages/release-notes/v6-1/0020-new-features.rst', 'pages/release-notes/v6-1/new-features/murano.rst'], 'web_link': 'https://opendev.org/openstack/fuel-docs/commit/bc1c888ab2f418b3b5b08d728a8be49431fb6ef6', 'message': 'Add Murano features\n\nAdd Murano features to the 6.1 relnotes\n\nChange-Id: I8f4f56d3ea246bfe85332ed716de4f6495942283\n'}]",0,195083,bc1c888ab2f418b3b5b08d728a8be49431fb6ef6,13,3,2,14342,,,0,"Add Murano features

Add Murano features to the 6.1 relnotes

Change-Id: I8f4f56d3ea246bfe85332ed716de4f6495942283
",git fetch https://review.opendev.org/openstack/fuel-docs refs/changes/83/195083/2 && git format-patch -1 --stdout FETCH_HEAD,"['pages/release-notes/v6-1/0020-new-features.rst', 'pages/release-notes/v6-1/new-features/murano.rst']",2,7ad65edbfe9f06c50ed2f8497c6fe75e3581f7c3,MuranoFeatures," Murano-related features ----------------------- * New OpenStack application catalog was published to `Communtiy App Catalog <http://apps.openstack.org/>`_, enabling users to select Murano packages, Heat templates, and Glance images they would like to add to their cloud. * Users can source Murano packages and their dependencies using a URL (package name) from `Communtiy App Catalog <http://apps.openstack.org/>`_ instead of using a zip file, simplifying Murano workflow. See `the related blueprint <https://blueprints.launchpad.net/murano/+spec/muraniclient-url-download>`_. * Support for Docker applications in Murano. See `the related blueprint <https://blueprints.launchpad.net/murano/+spec/docker-registry-in-murano>`_. ",,17,0
openstack%2Ffuel-docs~master~I6ebd7f0425c6a93c895e0eb19bfc699347c3dc64,openstack/fuel-docs,master,I6ebd7f0425c6a93c895e0eb19bfc699347c3dc64,change LBaas wording and remove Contrail,MERGED,2015-06-24 10:17:16.000000000,2015-06-24 15:27:20.000000000,2015-06-24 10:22:44.000000000,"[{'_account_id': 3}, {'_account_id': 8971}, {'_account_id': 13082}]","[{'number': 1, 'created': '2015-06-24 10:17:16.000000000', 'files': ['pages/release-notes/v6-1/new-features/plugins.rst'], 'web_link': 'https://opendev.org/openstack/fuel-docs/commit/73200a84c7915bd2cf61b687335ea05bc29874e7', 'message': 'change LBaas wording and remove Contrail\n\nChange LBaaS plugin description and\nremove Contrail as it is not supported yet.\n\nChange-Id: I6ebd7f0425c6a93c895e0eb19bfc699347c3dc64\n'}]",0,195022,73200a84c7915bd2cf61b687335ea05bc29874e7,9,3,1,14342,,,0,"change LBaas wording and remove Contrail

Change LBaaS plugin description and
remove Contrail as it is not supported yet.

Change-Id: I6ebd7f0425c6a93c895e0eb19bfc699347c3dc64
",git fetch https://review.opendev.org/openstack/fuel-docs refs/changes/22/195022/1 && git format-patch -1 --stdout FETCH_HEAD,['pages/release-notes/v6-1/new-features/plugins.rst'],1,73200a84c7915bd2cf61b687335ea05bc29874e7,LBaaSreword,"LBaaS plugin compatible with controllers in HA mode +++++++++++++++++++++++++++++++++++++++++++++++++++ The 6.1 compatible LBaaS plugin has been modified so that it can be deployed on controllers in HA mode. Please note that this enables the new LBaaS plugin to work with 6.1, but does not make the plugin itself HA.| Zabbix | Mellanox | | || InfluxDB-Grafana | Cisco ACI | | |","LBaaS is supported in HA ++++++++++++++++++++++++ LBaaS Fuel plugin, previously available in multi-node mode only, is now supported in HA. Please, note that HA works for the Controllers only, but not for the plugin itself.| Zabbix | Contrail | | || InfluxDB-Grafana | Mellanox | | | +----------------------+------------+---------+-----------+ | | Cisco ACI | | |",8,10
openstack%2Fpython-openstackclient~master~Id72670be8640e5c6e2490a6ef849e9ec3493b1a9,openstack/python-openstackclient,master,Id72670be8640e5c6e2490a6ef849e9ec3493b1a9,Add support to inherited project role grant calls,MERGED,2014-09-19 15:32:19.000000000,2015-06-24 15:26:19.000000000,2015-06-24 15:26:18.000000000,"[{'_account_id': 3}, {'_account_id': 1941}, {'_account_id': 6482}, {'_account_id': 8736}, {'_account_id': 8866}, {'_account_id': 9142}, {'_account_id': 10873}]","[{'number': 1, 'created': '2014-09-19 15:32:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-openstackclient/commit/bb85ddd438e7354c6508322683b32b1acda9d8ed', 'message': 'Add support to inherited project role grant calls\n\nOnce inherited project role grant calls are\nimplemented on python-keystoneclient,\npython-openstackclient also should support such\ncalls.\nThis patch add such support as well as its\nrelated tests.\n\nChange-Id: Id72670be8640e5c6e2490a6ef849e9ec3493b1a9\nImplements: blueprint hierarchical-multitenancy\n'}, {'number': 2, 'created': '2015-06-10 17:23:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-openstackclient/commit/181d9c547cdd415e825c6272fbecf2f9eff02ff3', 'message': 'Add support to inherited project role grant calls\n\nOnce inherited project role grant calls are\nimplemented on python-keystoneclient,\npython-openstackclient also should support such\ncalls.\nThis patch add such support as well as its\nrelated tests.\n\nCo-Authored-By: Raildo Mascena <raildo@lsd.ufcg.edu.br>\n\nChange-Id: Id72670be8640e5c6e2490a6ef849e9ec3493b1a9\nImplements: blueprint hierarchical-multitenancy\n'}, {'number': 3, 'created': '2015-06-22 14:05:29.000000000', 'files': ['openstackclient/identity/v3/role.py', 'openstackclient/identity/common.py', 'openstackclient/tests/identity/v3/test_role.py', 'doc/source/command-objects/role_assignment.rst'], 'web_link': 'https://opendev.org/openstack/python-openstackclient/commit/ed241ef9bc4e36137ecf835c545fdd44dddc426f', 'message': 'Add support to inherited project role grant calls\n\nOnce inherited project role grant calls are\nimplemented on python-keystoneclient,\npython-openstackclient also should support such\ncalls.\nThis patch add such support as well as its\nrelated tests.\n\nCo-Authored-By: Raildo Mascena <raildo@lsd.ufcg.edu.br>\n\nChange-Id: Id72670be8640e5c6e2490a6ef849e9ec3493b1a9\nImplements: blueprint hierarchical-multitenancy\n'}]",3,122775,ed241ef9bc4e36137ecf835c545fdd44dddc426f,21,7,3,9142,,,0,"Add support to inherited project role grant calls

Once inherited project role grant calls are
implemented on python-keystoneclient,
python-openstackclient also should support such
calls.
This patch add such support as well as its
related tests.

Co-Authored-By: Raildo Mascena <raildo@lsd.ufcg.edu.br>

Change-Id: Id72670be8640e5c6e2490a6ef849e9ec3493b1a9
Implements: blueprint hierarchical-multitenancy
",git fetch https://review.opendev.org/openstack/python-openstackclient refs/changes/75/122775/2 && git format-patch -1 --stdout FETCH_HEAD,"['openstackclient/identity/v3/role.py', 'openstackclient/tests/identity/v3/test_role.py']",2,bb85ddd438e7354c6508322683b32b1acda9d8ed,bp/hierarchical-multitenancy," if self._is_inheritance_testcase(): arglist.append('--inherited') ('inherited', self._is_inheritance_testcase()), 'inherited': self._is_inheritance_testcase(), if self._is_inheritance_testcase(): arglist.append('--inherited') ('inherited', self._is_inheritance_testcase()), 'inherited': self._is_inheritance_testcase(), if self._is_inheritance_testcase(): arglist.append('--inherited') ('inherited', self._is_inheritance_testcase()), 'inherited': self._is_inheritance_testcase(), if self._is_inheritance_testcase(): arglist.append('--inherited') ('inherited', self._is_inheritance_testcase()), 'inherited': self._is_inheritance_testcase(),",,20,0
openstack%2Ffuel-docs~master~I411f6d67d251bc48281150e8c9e87b4ad904dca3,openstack/fuel-docs,master,I411f6d67d251bc48281150e8c9e87b4ad904dca3,Update OpenStack version support,MERGED,2015-06-24 09:40:29.000000000,2015-06-24 15:25:56.000000000,2015-06-24 10:22:26.000000000,"[{'_account_id': 3}, {'_account_id': 8971}, {'_account_id': 13082}]","[{'number': 1, 'created': '2015-06-24 09:40:29.000000000', 'files': ['pages/release-notes/v6-1-juno-full.rst'], 'web_link': 'https://opendev.org/openstack/fuel-docs/commit/8bb65792a50598235551d274364beebfb7da9dc4', 'message': 'Update OpenStack version support\n\nUpdate OpenStack version support.\n\nChange-Id: I411f6d67d251bc48281150e8c9e87b4ad904dca3\n'}]",0,195011,8bb65792a50598235551d274364beebfb7da9dc4,9,3,1,14342,,,0,"Update OpenStack version support

Update OpenStack version support.

Change-Id: I411f6d67d251bc48281150e8c9e87b4ad904dca3
",git fetch https://review.opendev.org/openstack/fuel-docs refs/changes/11/195011/1 && git format-patch -1 --stdout FETCH_HEAD,['pages/release-notes/v6-1-juno-full.rst'],1,8bb65792a50598235551d274364beebfb7da9dc4,,This generally available version of Mirantis OpenStack is based on Juno release 2014.2.2 of OpenStack.,This generally available version of Mirantis OpenStack is based on the latest stable Juno release of OpenStack.,2,2
openstack%2Fmurano-dashboard~master~I660d174493cade75fcab6a8f5b7f6214dd188589,openstack/murano-dashboard,master,I660d174493cade75fcab6a8f5b7f6214dd188589,Remove attempts to close success message in tests,MERGED,2015-06-24 08:40:26.000000000,2015-06-24 15:25:14.000000000,2015-06-24 15:25:13.000000000,"[{'_account_id': 3}, {'_account_id': 7226}, {'_account_id': 7535}, {'_account_id': 7549}, {'_account_id': 7821}, {'_account_id': 8127}, {'_account_id': 13149}, {'_account_id': 13752}, {'_account_id': 15168}]","[{'number': 1, 'created': '2015-06-24 08:40:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/murano-dashboard/commit/c6d9ba0fa51c69277bf1a461186513cd6150ccaa', 'message': ""Remove attempts to close success message in tests\n\nThis commit removes attempts to close a success message, because horizon code\nmay hide and remove the message before tests are able to close it. This\ncould trigger false negatives from time to time.\nIt's harmless to ignore success the message as long as it is present on the page.\n\nChange-Id: I660d174493cade75fcab6a8f5b7f6214dd188589\nRelated-Bug: #1466332\n""}, {'number': 2, 'created': '2015-06-24 13:44:31.000000000', 'files': ['muranodashboard/tests/functional/base.py'], 'web_link': 'https://opendev.org/openstack/murano-dashboard/commit/af4d28eaf49a307a9708b39929a165ea77f7c775', 'message': ""Remove attempts to close success message in tests\n\nThis commit removes attempts to close a success message, because horizon code\nmay hide and remove the message before tests are able to close it. This\ncould trigger false negatives from time to time.\nIt's harmless to ignore success the message as long as it is present on the page.\n\nChange-Id: I660d174493cade75fcab6a8f5b7f6214dd188589\nRelated-Bug: #1466332\n""}]",0,194988,af4d28eaf49a307a9708b39929a165ea77f7c775,19,9,2,15168,,,0,"Remove attempts to close success message in tests

This commit removes attempts to close a success message, because horizon code
may hide and remove the message before tests are able to close it. This
could trigger false negatives from time to time.
It's harmless to ignore success the message as long as it is present on the page.

Change-Id: I660d174493cade75fcab6a8f5b7f6214dd188589
Related-Bug: #1466332
",git fetch https://review.opendev.org/openstack/murano-dashboard refs/changes/88/194988/1 && git format-patch -1 --stdout FETCH_HEAD,['muranodashboard/tests/functional/base.py'],1,c6d9ba0fa51c69277bf1a461186513cd6150ccaa,bug/1466332,," is_open = self.driver.find_elements(by.By.CSS_SELECTOR, 'a.close') if is_open: log.debug(""Hide success message"") is_open[0].click()",0,5
openstack%2Fmurano-dashboard~master~I94972726129c256d53377320b8b632afb56b8906,openstack/murano-dashboard,master,I94972726129c256d53377320b8b632afb56b8906,Remove openstack.common modules,MERGED,2015-06-22 16:06:11.000000000,2015-06-24 15:25:12.000000000,2015-06-24 15:25:10.000000000,"[{'_account_id': 3}, {'_account_id': 7226}, {'_account_id': 7535}, {'_account_id': 7549}, {'_account_id': 7821}, {'_account_id': 8127}, {'_account_id': 13149}, {'_account_id': 13752}, {'_account_id': 13962}, {'_account_id': 15168}]","[{'number': 1, 'created': '2015-06-22 16:06:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/murano-dashboard/commit/4b51f2c006a2fcd1a0c6edb4016f2341a7ed7752', 'message': 'Remove openstack.common libs in favor of oslo_* modules\n\nThis pathc removes unused log and gettextutils and replaces versionutils\nwith oslo_log.versionutils.\n\nChange-Id: I94972726129c256d53377320b8b632afb56b8906\nCloses-Bug: #1466332\n'}, {'number': 2, 'created': '2015-06-22 20:03:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/murano-dashboard/commit/2c2970d490c3eb84aa7fdc597eb63f3f64852bd5', 'message': 'Remove openstack.common libs in favor of oslo_* modules\n\nThis patch removes unused log and gettextutils and replaces versionutils\nwith oslo_log.versionutils.\n\nChange-Id: I94972726129c256d53377320b8b632afb56b8906\nCloses-Bug: #1466332\n'}, {'number': 3, 'created': '2015-06-22 20:50:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/murano-dashboard/commit/f47726f6d04deb538f4496644360e0faa91c7a8d', 'message': ""Remove openstack.common libs and fix tests\n\nThis patch removes unused log and gettextutils and replaces versionutils\nwith oslo_log.versionutils.\nIt also removes attempts to close a success message, since horizon code\nmay hide and remove the message before we're able to close it. This\ncould trigger false positives from time to time. It's harmless to ignore\nsuccess the message as long as it is present on the page.\n\nChange-Id: I94972726129c256d53377320b8b632afb56b8906\nCloses-Bug: #1466332\n""}, {'number': 4, 'created': '2015-06-23 10:43:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/murano-dashboard/commit/ab72929218aa4d6f976330cf771d8d319ef09dcc', 'message': ""Remove openstack.common libs and fix tests\n\nThis patch removes unused openstack.common modules and replaces\nversionutils with oslo_log.versionutils.\nIt also removes attempts to close a success message, because horizon code\nmay hide and remove the message before we're able to close it. This\ncould trigger false positives from time to time. It's harmless to ignore\nsuccess the message as long as it is present on the page.\n\nChange-Id: I94972726129c256d53377320b8b632afb56b8906\nCloses-Bug: #1466332\n""}, {'number': 5, 'created': '2015-06-23 10:47:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/murano-dashboard/commit/2252753ba502e504d92a14705558f0f9eea3b9d6', 'message': ""Remove openstack.common libs and fix tests\n\nThis patch removes unused openstack.common modules and replaces\nversionutils with oslo_log.versionutils.\nIt also removes attempts to close a success message, because horizon code\nmay hide and remove the message before we're able to close it. This\ncould trigger false positives from time to time. It's harmless to ignore\nsuccess the message as long as it is present on the page.\n\nChange-Id: I94972726129c256d53377320b8b632afb56b8906\nCloses-Bug: #1466332\n""}, {'number': 6, 'created': '2015-06-24 08:37:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/murano-dashboard/commit/b34b6b48b97e7d77248060b4886746af63a9d5a2', 'message': 'Remove openstack.common libs and fix tests\n\nThis patch removes unused openstack.common modules and replaces\nversionutils with oslo_log.versionutils.\nThis fixes the gate issue partly, by removing openstack.common.log which\nin some cases could override CONF object in horizon.\n\nChange-Id: I94972726129c256d53377320b8b632afb56b8906\nCloses-Bug: #1466332\n'}, {'number': 7, 'created': '2015-06-24 13:44:23.000000000', 'files': ['muranodashboard/openstack/common/gettextutils.py', 'muranodashboard/dynamic_ui/fields.py', 'muranodashboard/openstack/common/_i18n.py', 'muranodashboard/openstack/common/versionutils.py', 'muranodashboard/openstack/common/timeutils.py', 'muranodashboard/openstack/__init__.py', 'requirements.txt', 'muranodashboard/openstack/common/local.py', 'muranodashboard/openstack/common/log.py', 'openstack-common.conf', 'muranodashboard/openstack/common/__init__.py', 'tox.ini'], 'web_link': 'https://opendev.org/openstack/murano-dashboard/commit/7f1069c1188f6832468eaa89b4bdb40f658f7a92', 'message': 'Remove openstack.common modules\n\nThis patch removes unused openstack.common modules and replaces\nversionutils with oslo_log.versionutils.\nThis fixes the gate issue partly, by removing openstack.common.log which\nin some cases could override CONF object in horizon.\n\nChange-Id: I94972726129c256d53377320b8b632afb56b8906\nCloses-Bug: #1466332\n'}]",1,194211,7f1069c1188f6832468eaa89b4bdb40f658f7a92,65,10,7,15168,,,0,"Remove openstack.common modules

This patch removes unused openstack.common modules and replaces
versionutils with oslo_log.versionutils.
This fixes the gate issue partly, by removing openstack.common.log which
in some cases could override CONF object in horizon.

Change-Id: I94972726129c256d53377320b8b632afb56b8906
Closes-Bug: #1466332
",git fetch https://review.opendev.org/openstack/murano-dashboard refs/changes/11/194211/1 && git format-patch -1 --stdout FETCH_HEAD,"['requirements.txt', 'muranodashboard/openstack/common/gettextutils.py', 'muranodashboard/dynamic_ui/fields.py', 'muranodashboard/openstack/common/log.py', 'openstack-common.conf', 'muranodashboard/openstack/common/versionutils.py']",6,4b51f2c006a2fcd1a0c6edb4016f2341a7ed7752,bug/1466332,,"# Copyright (c) 2013 OpenStack Foundation # All Rights Reserved. # # Licensed under the Apache License, Version 2.0 (the ""License""); you may # not use this file except in compliance with the License. You may obtain # a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT # WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the # License for the specific language governing permissions and limitations # under the License. """""" Helpers for comparing version strings. """""" import functools import inspect import pkg_resources import six from muranodashboard.openstack.common._i18n import _ from muranodashboard.openstack.common import log as logging LOG = logging.getLogger(__name__) class deprecated(object): """"""A decorator to mark callables as deprecated. This decorator logs a deprecation message when the callable it decorates is used. The message will include the release where the callable was deprecated, the release where it may be removed and possibly an optional replacement. Examples: 1. Specifying the required deprecated release >>> @deprecated(as_of=deprecated.ICEHOUSE) ... def a(): pass 2. Specifying a replacement: >>> @deprecated(as_of=deprecated.ICEHOUSE, in_favor_of='f()') ... def b(): pass 3. Specifying the release where the functionality may be removed: >>> @deprecated(as_of=deprecated.ICEHOUSE, remove_in=+1) ... def c(): pass 4. Specifying the deprecated functionality will not be removed: >>> @deprecated(as_of=deprecated.ICEHOUSE, remove_in=0) ... def d(): pass 5. Specifying a replacement, deprecated functionality will not be removed: >>> @deprecated(as_of=deprecated.ICEHOUSE, in_favor_of='f()', remove_in=0) ... def e(): pass """""" # NOTE(morganfainberg): Bexar is used for unit test purposes, it is # expected we maintain a gap between Bexar and Folsom in this list. BEXAR = 'B' FOLSOM = 'F' GRIZZLY = 'G' HAVANA = 'H' ICEHOUSE = 'I' JUNO = 'J' KILO = 'K' _RELEASES = { # NOTE(morganfainberg): Bexar is used for unit test purposes, it is # expected we maintain a gap between Bexar and Folsom in this list. 'B': 'Bexar', 'F': 'Folsom', 'G': 'Grizzly', 'H': 'Havana', 'I': 'Icehouse', 'J': 'Juno', 'K': 'Kilo', } _deprecated_msg_with_alternative = _( '%(what)s is deprecated as of %(as_of)s in favor of ' '%(in_favor_of)s and may be removed in %(remove_in)s.') _deprecated_msg_no_alternative = _( '%(what)s is deprecated as of %(as_of)s and may be ' 'removed in %(remove_in)s. It will not be superseded.') _deprecated_msg_with_alternative_no_removal = _( '%(what)s is deprecated as of %(as_of)s in favor of %(in_favor_of)s.') _deprecated_msg_with_no_alternative_no_removal = _( '%(what)s is deprecated as of %(as_of)s. It will not be superseded.') def __init__(self, as_of, in_favor_of=None, remove_in=2, what=None): """"""Initialize decorator :param as_of: the release deprecating the callable. Constants are define in this class for convenience. :param in_favor_of: the replacement for the callable (optional) :param remove_in: an integer specifying how many releases to wait before removing (default: 2) :param what: name of the thing being deprecated (default: the callable's name) """""" self.as_of = as_of self.in_favor_of = in_favor_of self.remove_in = remove_in self.what = what def __call__(self, func_or_cls): if not self.what: self.what = func_or_cls.__name__ + '()' msg, details = self._build_message() if inspect.isfunction(func_or_cls): @six.wraps(func_or_cls) def wrapped(*args, **kwargs): LOG.deprecated(msg, details) return func_or_cls(*args, **kwargs) return wrapped elif inspect.isclass(func_or_cls): orig_init = func_or_cls.__init__ # TODO(tsufiev): change `functools` module to `six` as # soon as six 1.7.4 (with fix for passing `assigned` # argument to underlying `functools.wraps`) is released # and added to the muranodashboard-incubator requrements @functools.wraps(orig_init, assigned=('__name__', '__doc__')) def new_init(self, *args, **kwargs): LOG.deprecated(msg, details) orig_init(self, *args, **kwargs) func_or_cls.__init__ = new_init return func_or_cls else: raise TypeError('deprecated can be used only with functions or ' 'classes') def _get_safe_to_remove_release(self, release): # TODO(dstanek): this method will have to be reimplemented once # when we get to the X release because once we get to the Y # release, what is Y+2? new_release = chr(ord(release) + self.remove_in) if new_release in self._RELEASES: return self._RELEASES[new_release] else: return new_release def _build_message(self): details = dict(what=self.what, as_of=self._RELEASES[self.as_of], remove_in=self._get_safe_to_remove_release(self.as_of)) if self.in_favor_of: details['in_favor_of'] = self.in_favor_of if self.remove_in > 0: msg = self._deprecated_msg_with_alternative else: # There are no plans to remove this function, but it is # now deprecated. msg = self._deprecated_msg_with_alternative_no_removal else: if self.remove_in > 0: msg = self._deprecated_msg_no_alternative else: # There are no plans to remove this function, but it is # now deprecated. msg = self._deprecated_msg_with_no_alternative_no_removal return msg, details def is_compatible(requested_version, current_version, same_major=True): """"""Determine whether `requested_version` is satisfied by `current_version`; in other words, `current_version` is >= `requested_version`. :param requested_version: version to check for compatibility :param current_version: version to check against :param same_major: if True, the major version must be identical between `requested_version` and `current_version`. This is used when a major-version difference indicates incompatibility between the two versions. Since this is the common-case in practice, the default is True. :returns: True if compatible, False if not """""" requested_parts = pkg_resources.parse_version(requested_version) current_parts = pkg_resources.parse_version(current_version) if same_major and (requested_parts[0] != current_parts[0]): return False return current_parts >= requested_parts ",6,1403
