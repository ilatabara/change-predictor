id,project,branch,change_id,subject,status,created,updated,submitted,reviewers,revisions,total_comment_count,number,current_revision,discussion_messages_count,reviewers_count,revisions_count,owner_account_id,owner_name,owner_username,is_owner_bot,commit_message,git_command,changed_files,files_count,commit_id,topic,added_lines,deleted_lines,insertions,deletions
openstack%2Freleases~master~Id26705da343b30c1f5a23eda85581aff501c00d3,openstack/releases,master,Id26705da343b30c1f5a23eda85581aff501c00d3,Release osc-placement for wallaby-1 milestone,ABANDONED,2020-11-30 13:22:56.000000000,2020-12-03 15:38:59.000000000,,"[{'_account_id': 11904}, {'_account_id': 22348}]","[{'number': 1, 'created': '2020-11-30 13:22:56.000000000', 'files': ['deliverables/wallaby/osc-placement.yaml'], 'web_link': 'https://opendev.org/openstack/releases/commit/a4834d3517fbc123e3c9fb4eb63927ec42eae3b9', 'message': 'Release osc-placement for wallaby-1 milestone\n\nThis is a library release for osc-placement for the wallaby-1\nmilestone. This repo includes commits that have not been releases for\nthis cycle yet.\n\nIf the team is ready to process with this release, please leave a +1\nto indicate we should go ahead with the release.\n\nIf the team needs more time for things about to merge, or if there is\nsome other reason a release should not be done at this time, please\nleave a -1 with a comment indicating the status. Then update the patch\nwith the new commit hash to use once the team is ready to do the\nrelease.\n\nChange-Id: Id26705da343b30c1f5a23eda85581aff501c00d3\n'}]",0,764705,a4834d3517fbc123e3c9fb4eb63927ec42eae3b9,4,2,1,28522,,,0,"Release osc-placement for wallaby-1 milestone

This is a library release for osc-placement for the wallaby-1
milestone. This repo includes commits that have not been releases for
this cycle yet.

If the team is ready to process with this release, please leave a +1
to indicate we should go ahead with the release.

If the team needs more time for things about to merge, or if there is
some other reason a release should not be done at this time, please
leave a -1 with a comment indicating the status. Then update the patch
with the new commit hash to use once the team is ready to do the
release.

Change-Id: Id26705da343b30c1f5a23eda85581aff501c00d3
",git fetch https://review.opendev.org/openstack/releases refs/changes/05/764705/1 && git format-patch -1 --stdout FETCH_HEAD,['deliverables/wallaby/osc-placement.yaml'],1,a4834d3517fbc123e3c9fb4eb63927ec42eae3b9,w1-c-w-i,releases: - version: 2.2.0 projects: - repo: openstack/osc-placement hash: e662e51f23d1c20ebbdd331a23ce05e04ead2e3a,,5,0
openstack%2Freleases~master~I9f82b451c9e495d0a8e7d58b827a82ddecee2eb4,openstack/releases,master,I9f82b451c9e495d0a8e7d58b827a82ddecee2eb4,Release monasca-statsd for wallaby-1 milestone,ABANDONED,2020-11-30 13:18:01.000000000,2020-12-03 15:38:26.000000000,,"[{'_account_id': 11904}, {'_account_id': 22348}, {'_account_id': 28062}]","[{'number': 1, 'created': '2020-11-30 13:18:01.000000000', 'files': ['deliverables/wallaby/monasca-statsd.yaml'], 'web_link': 'https://opendev.org/openstack/releases/commit/90946f45f2e98de0e903346ac36ff4d711bcec73', 'message': 'Release monasca-statsd for wallaby-1 milestone\n\nThis is a library release for monasca-statsd for the wallaby-1\nmilestone. This repo includes commits that have not been releases for\nthis cycle yet.\n\nIf the team is ready to process with this release, please leave a +1\nto indicate we should go ahead with the release.\n\nIf the team needs more time for things about to merge, or if there is\nsome other reason a release should not be done at this time, please\nleave a -1 with a comment indicating the status. Then update the patch\nwith the new commit hash to use once the team is ready to do the\nrelease.\n\nChange-Id: I9f82b451c9e495d0a8e7d58b827a82ddecee2eb4\n'}]",0,764698,90946f45f2e98de0e903346ac36ff4d711bcec73,4,3,1,28522,,,0,"Release monasca-statsd for wallaby-1 milestone

This is a library release for monasca-statsd for the wallaby-1
milestone. This repo includes commits that have not been releases for
this cycle yet.

If the team is ready to process with this release, please leave a +1
to indicate we should go ahead with the release.

If the team needs more time for things about to merge, or if there is
some other reason a release should not be done at this time, please
leave a -1 with a comment indicating the status. Then update the patch
with the new commit hash to use once the team is ready to do the
release.

Change-Id: I9f82b451c9e495d0a8e7d58b827a82ddecee2eb4
",git fetch https://review.opendev.org/openstack/releases refs/changes/98/764698/1 && git format-patch -1 --stdout FETCH_HEAD,['deliverables/wallaby/monasca-statsd.yaml'],1,90946f45f2e98de0e903346ac36ff4d711bcec73,w1-c-w-i,releases: - version: 2.2.0 projects: - repo: openstack/monasca-statsd hash: 298394511e160a436849773e1ab2c080ded231e7,,5,0
openstack%2Freleases~master~I7f31ece9b022c09d4b5ba238000d20e01db92602,openstack/releases,master,I7f31ece9b022c09d4b5ba238000d20e01db92602,Release monasca-common for wallaby-1 milestone,ABANDONED,2020-11-30 13:17:29.000000000,2020-12-03 15:37:23.000000000,,"[{'_account_id': 11904}, {'_account_id': 22348}, {'_account_id': 28062}]","[{'number': 1, 'created': '2020-11-30 13:17:29.000000000', 'files': ['deliverables/wallaby/monasca-common.yaml'], 'web_link': 'https://opendev.org/openstack/releases/commit/12171188e743566184d1cda2051c8704f86a733f', 'message': 'Release monasca-common for wallaby-1 milestone\n\nThis is a library release for monasca-common for the wallaby-1\nmilestone. This repo includes commits that have not been releases for\nthis cycle yet.\n\nIf the team is ready to process with this release, please leave a +1\nto indicate we should go ahead with the release.\n\nIf the team needs more time for things about to merge, or if there is\nsome other reason a release should not be done at this time, please\nleave a -1 with a comment indicating the status. Then update the patch\nwith the new commit hash to use once the team is ready to do the\nrelease.\n\nChange-Id: I7f31ece9b022c09d4b5ba238000d20e01db92602\n'}]",0,764697,12171188e743566184d1cda2051c8704f86a733f,4,3,1,28522,,,0,"Release monasca-common for wallaby-1 milestone

This is a library release for monasca-common for the wallaby-1
milestone. This repo includes commits that have not been releases for
this cycle yet.

If the team is ready to process with this release, please leave a +1
to indicate we should go ahead with the release.

If the team needs more time for things about to merge, or if there is
some other reason a release should not be done at this time, please
leave a -1 with a comment indicating the status. Then update the patch
with the new commit hash to use once the team is ready to do the
release.

Change-Id: I7f31ece9b022c09d4b5ba238000d20e01db92602
",git fetch https://review.opendev.org/openstack/releases refs/changes/97/764697/1 && git format-patch -1 --stdout FETCH_HEAD,['deliverables/wallaby/monasca-common.yaml'],1,12171188e743566184d1cda2051c8704f86a733f,w1-c-w-i,releases: - version: 3.3.0 projects: - repo: openstack/monasca-common hash: fd7c3bf7073b7afec3408de3c1d32ff137e82e37,,5,0
openstack%2Fproject-config~master~I090095b052f363a4f6e1f4f0fedea87e959fa69a,openstack/project-config,master,I090095b052f363a4f6e1f4f0fedea87e959fa69a,End project gating for retiring Searchlight project,MERGED,2020-11-28 02:23:12.000000000,2020-12-03 15:36:52.000000000,2020-12-03 15:36:52.000000000,"[{'_account_id': 1004}, {'_account_id': 6547}, {'_account_id': 22348}]","[{'number': 1, 'created': '2020-11-28 02:23:12.000000000', 'files': ['zuul.d/projects.yaml'], 'web_link': 'https://opendev.org/openstack/project-config/commit/62a262062bf384b2a24ef9fe6067280e42693b38', 'message': 'End project gating for retiring Searchlight project\n\nSearchlight is going to be retired in Wallaby cycle[1],\nas first step this commit end the project gating for\nall the deliverables under Searchlight project.\n\n[1] http://lists.openstack.org/pipermail/openstack-discuss/2020-November/018637.html\n\nChange-Id: I090095b052f363a4f6e1f4f0fedea87e959fa69a\n'}]",0,764519,62a262062bf384b2a24ef9fe6067280e42693b38,7,3,1,8556,,,0,"End project gating for retiring Searchlight project

Searchlight is going to be retired in Wallaby cycle[1],
as first step this commit end the project gating for
all the deliverables under Searchlight project.

[1] http://lists.openstack.org/pipermail/openstack-discuss/2020-November/018637.html

Change-Id: I090095b052f363a4f6e1f4f0fedea87e959fa69a
",git fetch https://review.opendev.org/openstack/project-config refs/changes/19/764519/1 && git format-patch -1 --stdout FETCH_HEAD,['zuul.d/projects.yaml'],1,62a262062bf384b2a24ef9fe6067280e42693b38,retire-searchlight, - noop-jobs - noop-jobs - noop-jobs - noop-jobs, - publish-to-pypi - translation-jobs-master-only - api-ref-jobs - publish-to-pypi - translation-jobs-master-stable - publish-to-pypi,4,6
openstack%2Freleases~master~If28866e25221db8dbc779e344d107d9924179aab,openstack/releases,master,If28866e25221db8dbc779e344d107d9924179aab,Release python-manilaclient for wallaby-1 milestone,MERGED,2020-11-30 13:45:41.000000000,2020-12-03 15:35:19.000000000,2020-12-03 15:35:19.000000000,"[{'_account_id': 308}, {'_account_id': 9003}, {'_account_id': 16643}, {'_account_id': 22348}, {'_account_id': 28522}]","[{'number': 1, 'created': '2020-11-30 13:45:41.000000000', 'files': ['deliverables/wallaby/python-manilaclient.yaml'], 'web_link': 'https://opendev.org/openstack/releases/commit/4b06c296d25ee30875a3cf61b2f4b9bf50f47ecc', 'message': 'Release python-manilaclient for wallaby-1 milestone\n\nThis is a library release for python-manilaclient for the wallaby-1\nmilestone. This repo includes commits that have not been releases for\nthis cycle yet.\n\nIf the team is ready to process with this release, please leave a +1\nto indicate we should go ahead with the release.\n\nIf the team needs more time for things about to merge, or if there is\nsome other reason a release should not be done at this time, please\nleave a -1 with a comment indicating the status. Then update the patch\nwith the new commit hash to use once the team is ready to do the\nrelease.\n\nChange-Id: If28866e25221db8dbc779e344d107d9924179aab\n'}]",0,764735,4b06c296d25ee30875a3cf61b2f4b9bf50f47ecc,9,5,1,28522,,,0,"Release python-manilaclient for wallaby-1 milestone

This is a library release for python-manilaclient for the wallaby-1
milestone. This repo includes commits that have not been releases for
this cycle yet.

If the team is ready to process with this release, please leave a +1
to indicate we should go ahead with the release.

If the team needs more time for things about to merge, or if there is
some other reason a release should not be done at this time, please
leave a -1 with a comment indicating the status. Then update the patch
with the new commit hash to use once the team is ready to do the
release.

Change-Id: If28866e25221db8dbc779e344d107d9924179aab
",git fetch https://review.opendev.org/openstack/releases refs/changes/35/764735/1 && git format-patch -1 --stdout FETCH_HEAD,['deliverables/wallaby/python-manilaclient.yaml'],1,4b06c296d25ee30875a3cf61b2f4b9bf50f47ecc,w1-c-w-i,releases: - version: 2.4.0 projects: - repo: openstack/python-manilaclient hash: 3cc12ce444feaf069f3953788a3d9f9c425bd768,,5,0
openstack%2Freleases~master~Ib7d236a44819bee5cbbb7f4963bd6a6f43512b49,openstack/releases,master,Ib7d236a44819bee5cbbb7f4963bd6a6f43512b49,Release python-octaviaclient for wallaby-1 milestone,ABANDONED,2020-11-30 13:49:08.000000000,2020-12-03 15:34:57.000000000,,"[{'_account_id': 6469}, {'_account_id': 10273}, {'_account_id': 11628}, {'_account_id': 22348}]","[{'number': 1, 'created': '2020-11-30 13:49:08.000000000', 'files': ['deliverables/wallaby/python-octaviaclient.yaml'], 'web_link': 'https://opendev.org/openstack/releases/commit/5ea7f858a773b4ad2366e4570bf2376428744b70', 'message': 'Release python-octaviaclient for wallaby-1 milestone\n\nThis is a library release for python-octaviaclient for the wallaby-1\nmilestone. This repo includes commits that have not been releases for\nthis cycle yet.\n\nIf the team is ready to process with this release, please leave a +1\nto indicate we should go ahead with the release.\n\nIf the team needs more time for things about to merge, or if there is\nsome other reason a release should not be done at this time, please\nleave a -1 with a comment indicating the status. Then update the patch\nwith the new commit hash to use once the team is ready to do the\nrelease.\n\nChange-Id: Ib7d236a44819bee5cbbb7f4963bd6a6f43512b49\n'}]",0,764742,5ea7f858a773b4ad2366e4570bf2376428744b70,4,4,1,28522,,,0,"Release python-octaviaclient for wallaby-1 milestone

This is a library release for python-octaviaclient for the wallaby-1
milestone. This repo includes commits that have not been releases for
this cycle yet.

If the team is ready to process with this release, please leave a +1
to indicate we should go ahead with the release.

If the team needs more time for things about to merge, or if there is
some other reason a release should not be done at this time, please
leave a -1 with a comment indicating the status. Then update the patch
with the new commit hash to use once the team is ready to do the
release.

Change-Id: Ib7d236a44819bee5cbbb7f4963bd6a6f43512b49
",git fetch https://review.opendev.org/openstack/releases refs/changes/42/764742/1 && git format-patch -1 --stdout FETCH_HEAD,['deliverables/wallaby/python-octaviaclient.yaml'],1,5ea7f858a773b4ad2366e4570bf2376428744b70,w1-c-w-i,releases: - version: 2.3.0 projects: - repo: openstack/python-octaviaclient hash: 1a133a3320568cbc14a1eb9d7938b7e174b12c08,,5,0
openstack%2Fgovernance~master~If449b175a8e7dababf8242ccdd4a692b0d60dd42,openstack/governance,master,If449b175a8e7dababf8242ccdd4a692b0d60dd42,Generate the TC liaisons assignments,MERGED,2020-11-23 17:19:30.000000000,2020-12-03 15:31:49.000000000,2020-12-03 15:28:42.000000000,"[{'_account_id': 1004}, {'_account_id': 7198}, {'_account_id': 22348}]","[{'number': 1, 'created': '2020-11-23 17:19:30.000000000', 'files': ['reference/projects.yaml'], 'web_link': 'https://opendev.org/openstack/governance/commit/e156a96e7dd846c6116939d3d05ffd17bc570154', 'message': 'Generate the TC liaisons assignments\n\nGenerating the TC liaisons assignments using\n./tools/assign_liaisons.py on top of already\nassigned one.\n\nChange-Id: If449b175a8e7dababf8242ccdd4a692b0d60dd42\n'}]",0,763810,e156a96e7dd846c6116939d3d05ffd17bc570154,12,3,1,8556,,,0,"Generate the TC liaisons assignments

Generating the TC liaisons assignments using
./tools/assign_liaisons.py on top of already
assigned one.

Change-Id: If449b175a8e7dababf8242ccdd4a692b0d60dd42
",git fetch https://review.opendev.org/openstack/governance refs/changes/10/763810/1 && git format-patch -1 --stdout FETCH_HEAD,['reference/projects.yaml'],1,e156a96e7dd846c6116939d3d05ffd17bc570154,documentation-change," tc_members: - mnaser - dansmith tc_members: - mnaser - mugsie tc_members: [gmann, knikolla] tc_members: - jungleboyj - belmoreira tc_members: - dansmith - jungleboyj tc_members: - diablo_rojo - jungleboyj tc_members: - jungleboyj - mugsie tc_members: - mnaser - ricolin tc_members: [dansmith, jungleboyj] tc_members: [ricolin, mugsie] tc_members: - mnaser - mugsie tc_members: [dansmith, diablo_rojo] tc_members: - diablo_rojo - knikolla tc_members: - mnaser - mugsie tc_members: - gmann - dansmith tc_members: - diablo_rojo - jungleboyj tc_members: [ricolin, diablo_rojo] tc_members: [gmann, knikolla] tc_members: - mnaser - mugsie tc_members: - mugsie - diablo_rojo tc_members: [ricolin, mugsie] tc_members: - belmoreira - ricolin tc_members: - mnaser - mugsie tc_members: - mugsie - jungleboyj tc_members: - belmoreira - knikolla tc_members: - knikolla - mugsie tc_members: - jungleboyj - knikolla tc_members: - knikolla - jungleboyj tc_members: [dansmith, belmoreira] tc_members: [ricolin, knikolla] tc_members: - mnaser - belmoreira tc_members: - mnaser - gmann tc_members: [gmann, jungleboyj] tc_members: - diablo_rojo - belmoreira tc_members: [diablo_rojo, knikolla] tc_members: - mnaser - belmoreira tc_members: - ricolin - mugsie tc_members: - belmoreira - mnaser tc_members: [ricolin, diablo_rojo] tc_members: - mnaser - knikolla tc_members: - belmoreira - diablo_rojo tc_members: [diablo_rojo, jungleboyj] tc_members: [gmann, diablo_rojo] tc_members: [ricolin, dansmith] tc_members: - gmann - ricolin tc_members: [gmann, belmoreira] tc_members: - ricolin - knikolla tc_members: [gmann, knikolla] tc_members: - ricolin - mnaser tc_members: - jungleboyj - belmoreira tc_members: - belmoreira - dansmith", tc_members: [] tc_members: [] tc_members: [gmann] tc_members: [] tc_members: [] tc_members: [] tc_members: [] tc_members: [] tc_members: [dansmith] tc_members: [ricolin] tc_members: [] tc_members: [dansmith] tc_members: [] tc_members: [] tc_members: [] tc_members: [] tc_members: [ricolin] tc_members: [gmann] tc_members: [] tc_members: [] tc_members: [ricolin] tc_members: [] tc_members: [] tc_members: [] tc_members: [] tc_members: [] tc_members: [] tc_members: [] tc_members: [dansmith] tc_members: [ricolin] tc_members: [] tc_members: [] tc_members: [gmann] tc_members: [] tc_members: [diablo_rojo] tc_members: [] tc_members: [] tc_members: [] tc_members: [ricolin] tc_members: [] tc_members: [] tc_members: [diablo_rojo] tc_members: [gmann] tc_members: [ricolin] tc_members: [] tc_members: [gmann] tc_members: [] tc_members: [gmann] tc_members: [] tc_members: [] tc_members: [],119,51
openstack%2Fironic-specs~master~I3b8832a945183ce3ed41ea79838fc9f682bfc547,openstack/ironic-specs,master,I3b8832a945183ce3ed41ea79838fc9f682bfc547,Support node history,MERGED,2019-04-16 02:02:18.000000000,2020-12-03 15:31:29.000000000,2020-12-03 15:29:38.000000000,"[{'_account_id': 136}, {'_account_id': 2889}, {'_account_id': 6618}, {'_account_id': 10206}, {'_account_id': 10239}, {'_account_id': 11292}, {'_account_id': 11655}, {'_account_id': 22348}, {'_account_id': 23851}, {'_account_id': 24828}]","[{'number': 1, 'created': '2019-04-16 02:02:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic-specs/commit/e4fd0b3484ffab6980645a9021cfb2007645f3a0', 'message': 'Support error log history\n\nCurrently ironic uses one last_error field to record error information\nwhen something goes wrong. Sometimes, an error is caused by another\nerror within a single operation, we even have the case the root cause\ncould be overwritten alone the code path, care must be taken to prevent\nlast_error from being overwritten which make things complicated, it\nwould be easier with error log history.\n\nOn the other hand, an error history reflects node status during a\nperiod of time, it helps to monitor or diagnose the node, especially\nwe now have some fault autorecovery mechanism like power fault recovery.\n\nThe proposal is to introduce a new table named errors, and record\nnode failure events that make sense.\n\nChange-Id: I3b8832a945183ce3ed41ea79838fc9f682bfc547\nStory: 2002980\nTask: 22989\n'}, {'number': 2, 'created': '2020-06-28 06:51:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic-specs/commit/b58dd2e8571b3abc91117ca412e219747b008091', 'message': ""Support node history\n\nCurrently ironic uses one last_error field to record error information\nwhen an operation failed. The field is easily overwritten and we don't\nhave a traceback on what happened in the past, the only way is to check\nservice logs.\n\nThe proposal is to introduce a new table named node_history, and record\nimportant node events that helps bare metal maintenance and troubleshooting.\n\nChange-Id: I3b8832a945183ce3ed41ea79838fc9f682bfc547\nStory: 2002980\nTask: 22989\n""}, {'number': 3, 'created': '2020-08-19 12:33:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic-specs/commit/03b7f81e0af23db4952beb4b6c28dcd5007f5423', 'message': ""Support node history\n\nCurrently ironic uses one last_error field to record error information\nwhen an operation failed. The field is easily overwritten and we don't\nhave a traceback on what happened in the past, the only way is to check\nservice logs.\n\nThe proposal is to introduce a new table named node_history, and record\nimportant node events that helps bare metal maintenance and troubleshooting.\n\nChange-Id: I3b8832a945183ce3ed41ea79838fc9f682bfc547\nStory: 2002980\nTask: 22989\n""}, {'number': 4, 'created': '2020-11-24 11:15:33.000000000', 'files': ['specs/approved/node-history.rst', 'specs/not-implemented/node-history.rst'], 'web_link': 'https://opendev.org/openstack/ironic-specs/commit/30b1bd844f4947345d305fe58aca5486f25339ea', 'message': ""Support node history\n\nCurrently ironic uses one last_error field to record error information\nwhen an operation failed. The field is easily overwritten and we don't\nhave a traceback on what happened in the past, the only way is to check\nservice logs.\n\nThe proposal is to introduce a new table named node_history, and record\nimportant node events that helps bare metal maintenance and troubleshooting.\n\nChange-Id: I3b8832a945183ce3ed41ea79838fc9f682bfc547\nStory: 2002980\nTask: 22989\n""}]",108,652811,30b1bd844f4947345d305fe58aca5486f25339ea,58,10,4,24828,,,0,"Support node history

Currently ironic uses one last_error field to record error information
when an operation failed. The field is easily overwritten and we don't
have a traceback on what happened in the past, the only way is to check
service logs.

The proposal is to introduce a new table named node_history, and record
important node events that helps bare metal maintenance and troubleshooting.

Change-Id: I3b8832a945183ce3ed41ea79838fc9f682bfc547
Story: 2002980
Task: 22989
",git fetch https://review.opendev.org/openstack/ironic-specs refs/changes/11/652811/4 && git format-patch -1 --stdout FETCH_HEAD,"['specs/approved/error-log-history.rst', 'specs/not-implemented/error-log-history.rst']",2,e4fd0b3484ffab6980645a9021cfb2007645f3a0,node-history,../approved/error-log-history.rst,,237,0
openstack%2Fgovernance~master~I962a1a0e610f65a4192d071e744db068885f293a,openstack/governance,master,I962a1a0e610f65a4192d071e744db068885f293a,Update example and oslo code usage in JSON->YAML goal,MERGED,2020-11-26 01:25:23.000000000,2020-12-03 15:30:47.000000000,2020-12-03 15:27:44.000000000,"[{'_account_id': 1004}, {'_account_id': 7198}, {'_account_id': 13995}, {'_account_id': 22348}]","[{'number': 1, 'created': '2020-11-26 01:25:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/governance/commit/e920d08c3ce73060f389ff4ca08b1f7bd4e206ac', 'message': 'Update example and oslo code usage in JSON->YAML goal\n\nChange-Id: I962a1a0e610f65a4192d071e744db068885f293a\n'}, {'number': 2, 'created': '2020-11-26 17:30:43.000000000', 'files': ['goals/selected/wallaby/migrate-policy-format-from-json-to-yaml.rst'], 'web_link': 'https://opendev.org/openstack/governance/commit/0a8d633169d039f2be465f6db9f31d2db8fbe4fd', 'message': 'Update example and oslo code usage in JSON->YAML goal\n\nChange-Id: I962a1a0e610f65a4192d071e744db068885f293a\n'}]",2,764261,0a8d633169d039f2be465f6db9f31d2db8fbe4fd,14,4,2,8556,,,0,"Update example and oslo code usage in JSON->YAML goal

Change-Id: I962a1a0e610f65a4192d071e744db068885f293a
",git fetch https://review.opendev.org/openstack/governance refs/changes/61/764261/2 && git format-patch -1 --stdout FETCH_HEAD,['goals/selected/wallaby/migrate-policy-format-from-json-to-yaml.rst'],1,e920d08c3ce73060f389ff4ca08b1f7bd4e206ac,documentation-change,"#. Enable upgrade checks to detect the JSON format file which is defined in oslo.upgradecheck 1.2.0 and warn about it. `Example <https://review.opendev.org/c/openstack/keystone/+/764240/2/keystone/cmd/status.py>`_ #. Change the default for config ``policy_file`` via ``set_defaults``. To avoid breaking the deployment, a fallback logic to use the existing ``policy.json`` is added in oslo.policy 3.6.0. upgrade: - | The default value of ``[oslo_policy] policy_file`` config option has been changed from ``policy.json`` to ``policy.yaml``. Operators who are utilizing customized or previously generated static policy JSON files (which are not needed by default), should generate new policy files or convert them in YAML format. Use the `oslopolicy-convert-json-to-yaml <https://docs.openstack.org/oslo.policy/latest/cli/oslopolicy-convert-json-to-yaml.html>`_ tool to convert a JSON to YAML formatted policy file in backward compatible way. Use of JSON policy files was deprecated by the ``oslo.policy`` library during the Victoria development cycle. As a result, this deprecation is being noted in the Wallaby with an anticipated future removal of support by ``oslo.policy``. As such operators will need to convert to YAML policy files. Please see the upgrade notes for details on migration of any custom policy files.* Keystone: https://review.opendev.org/c/openstack/keystone/+/764240 * Nova (common code is moved from nova to oslo side): https://review.opendev.org/#/c/748059/ * Work done till now: https://review.opendev.org/#/q/topic:bp/policy-json-to-yaml+(status:open+OR+status:merged) Tracking for this work will be done in `this etherpad <https://etherpad.opendev.org/p/migrate-policy-format-from-json-to-yaml>`_ ",#. Add upgrade checks to detect the JSON format file and warn about it. `Example <https://review.opendev.org/#/c/748059/16/nova/cmd/status.py>`_ #. Change the default for config ``policy_file`` via ``set_defaults``. The default value of the ``[oslo_policy] policy_file`` config option has been changed from ``policy.json`` to ``policy.yaml``. The current default value of the ``[oslo_policy] policy_file`` config option (``policy.json``) does not work for deprecated policy rules when ``policy.json`` is generated by the `oslopolicy-sample-generator <https://docs.openstack.org/oslo.policy/latest/cli/oslopolicy-sample-generator.html>`_ tool. Use the `oslopolicy-convert-json-to-yaml <https://docs.openstack.org/oslo.policy/latest/cli/oslopolicy-convert-json-to-yaml.html>`_ tool to convert the existing JSON formatted policy file to YAML in a backward compatible way.Nova: https://review.opendev.org/#/c/748059/ Work done till now: https://review.opendev.org/#/q/topic:bp/policy-json-to-yaml+(status:open+OR+status:merged) ,28,16
openstack%2Freleases~master~I0bae49ff501bb348b024ba412cade23c5b6afd52,openstack/releases,master,I0bae49ff501bb348b024ba412cade23c5b6afd52,Release python-designateclient for wallaby-1 milestone,ABANDONED,2020-11-30 13:39:43.000000000,2020-12-03 15:29:22.000000000,,"[{'_account_id': 8099}, {'_account_id': 11628}, {'_account_id': 22348}]","[{'number': 1, 'created': '2020-11-30 13:39:43.000000000', 'files': ['deliverables/wallaby/python-designateclient.yaml'], 'web_link': 'https://opendev.org/openstack/releases/commit/d72c16b4ac3e3e89dc09aa88f7858fe63cf57002', 'message': 'Release python-designateclient for wallaby-1 milestone\n\nThis is a library release for python-designateclient for the wallaby-1\nmilestone. This repo includes commits that have not been releases for\nthis cycle yet.\n\nIf the team is ready to process with this release, please leave a +1\nto indicate we should go ahead with the release.\n\nIf the team needs more time for things about to merge, or if there is\nsome other reason a release should not be done at this time, please\nleave a -1 with a comment indicating the status. Then update the patch\nwith the new commit hash to use once the team is ready to do the\nrelease.\n\nChange-Id: I0bae49ff501bb348b024ba412cade23c5b6afd52\n'}]",0,764727,d72c16b4ac3e3e89dc09aa88f7858fe63cf57002,5,3,1,28522,,,0,"Release python-designateclient for wallaby-1 milestone

This is a library release for python-designateclient for the wallaby-1
milestone. This repo includes commits that have not been releases for
this cycle yet.

If the team is ready to process with this release, please leave a +1
to indicate we should go ahead with the release.

If the team needs more time for things about to merge, or if there is
some other reason a release should not be done at this time, please
leave a -1 with a comment indicating the status. Then update the patch
with the new commit hash to use once the team is ready to do the
release.

Change-Id: I0bae49ff501bb348b024ba412cade23c5b6afd52
",git fetch https://review.opendev.org/openstack/releases refs/changes/27/764727/1 && git format-patch -1 --stdout FETCH_HEAD,['deliverables/wallaby/python-designateclient.yaml'],1,d72c16b4ac3e3e89dc09aa88f7858fe63cf57002,w1-c-w-i,releases: - version: 4.2.0 projects: - repo: openstack/python-designateclient hash: 5b8068818dba6b20475aeb89fe02613f99978365,,5,0
openstack%2Fgovernance~master~Icc1e837c1de964caba505c1d7cfe0467ef88808e,openstack/governance,master,Icc1e837c1de964caba505c1d7cfe0467ef88808e,Remove already done use-builtin-mock from goal,MERGED,2020-11-26 01:31:37.000000000,2020-12-03 15:28:36.000000000,2020-12-03 15:28:36.000000000,"[{'_account_id': 308}, {'_account_id': 1004}, {'_account_id': 7198}, {'_account_id': 22348}]","[{'number': 1, 'created': '2020-11-26 01:31:37.000000000', 'files': ['goals/proposed/use-builtin-mock.rst'], 'web_link': 'https://opendev.org/openstack/governance/commit/8239004a7b49aeefceca9ba4b16f4f1b93ee22f9', 'message': 'Remove already done use-builtin-mock from goal\n\nuse-builtin-mock work is already done under:\nhttps://review.opendev.org/q/topic:%22unittest.mock%22+(status:open%20OR%20status:merged)\n\nWe do not need to keep it in proposal goal doc.\n\nChange-Id: Icc1e837c1de964caba505c1d7cfe0467ef88808e\n'}]",0,764262,8239004a7b49aeefceca9ba4b16f4f1b93ee22f9,10,4,1,8556,,,0,"Remove already done use-builtin-mock from goal

use-builtin-mock work is already done under:
https://review.opendev.org/q/topic:%22unittest.mock%22+(status:open%20OR%20status:merged)

We do not need to keep it in proposal goal doc.

Change-Id: Icc1e837c1de964caba505c1d7cfe0467ef88808e
",git fetch https://review.opendev.org/openstack/governance refs/changes/62/764262/1 && git format-patch -1 --stdout FETCH_HEAD,['goals/proposed/use-builtin-mock.rst'],1,8239004a7b49aeefceca9ba4b16f4f1b93ee22f9,,,"========================================= Migrate from mock to bultin unittest.mock ========================================= The external mock library was necessary in python versions less than 3.3. The built in unittest.mock provides the functionality of the old mock library and also provides a more stable interface vs the constantly updating external mock library. Champion ======== * Matthew Thode <mthode@mthode.org> (prometheanfire) * Sean McGinnis <sean.mcginnis@gmail.com> (smcginnis) Gerrit Topic ============ To facilitate tracking, commits related to this goal should use the gerrit topic:: unittest.mock A new Story in https://storyboard.openstack.org/ will be created to track any related patch. Completion Criteria =================== #. All projects with managed constraints do not use the mock library but use the built in unittest.mock. References ========== The main refrence is upstream documentation located at [1]_ An example review can be found in [2]_ Current progress is tracked in [3]_ Current State / Anticipated Impact ================================== There are over 100 repositories needing this change, a short selection is listed below. * openstack/ironic * openstack/ironic * openstack/ironic-ui * openstack/karbor-dashboard * openstack/keystoneauth * openstack/keystoneauth * openstack/keystoneauth * openstack/keystonemiddleware * openstack/keystonemiddleware * openstack/kuryr-tempest-plugin * openstack/magnum * openstack/manila * openstack/mistral-dashboard * openstack/mistral-tempest-plugin * openstack/monasca-analytics * openstack/monasca-analytics * openstack/monasca-ceilometer * openstack/monasca-events-api * openstack/monasca-log-api * openstack/monasca-statsd * openstack/monasca-tempest-plugin * openstack/monasca-transform * openstack/monasca-transform * openstack/monasca-ui * openstack/networking-l2gw * openstack/networking-l2gw-tempest-plugin * openstack/networking-midonet * openstack/networking-powervm * openstack/networking-sfc * openstack/neutron * openstack/neutron-dynamic-routing * openstack/neutron-fwaas * openstack/neutron-fwaas-dashboard * openstack/neutron-vpnaas-dashboard * openstack/nova * openstack/nova-powervm * openstack/openstack-ansible * openstack/openstack-doc-tools * openstack/openstack-doc-tools * openstack/openstack-health * openstack/openstacksdk * openstack/os-brick * openstack/os-collect-config Links ===== .. [1] https://docs.python.org/3/library/unittest.mock.html .. [2] https://review.opendev.org/#/c/720914/ .. [3] https://review.opendev.org/#/q/branch:master+topic:unittest.mock ",0,100
openstack%2Freleases~master~I828fe08e65689bf32aa67b1a164dce2a3c21a188,openstack/releases,master,I828fe08e65689bf32aa67b1a164dce2a3c21a188,Release python-zunclient for wallaby-1 milestone,ABANDONED,2020-11-30 13:53:49.000000000,2020-12-03 15:26:45.000000000,,"[{'_account_id': 11536}, {'_account_id': 11904}, {'_account_id': 22348}, {'_account_id': 23365}, {'_account_id': 27654}, {'_account_id': 31245}]","[{'number': 1, 'created': '2020-11-30 13:53:49.000000000', 'files': ['deliverables/wallaby/python-zunclient.yaml'], 'web_link': 'https://opendev.org/openstack/releases/commit/6b621e8d3b8e699a19404ad24ac1f9fa9935e2cd', 'message': 'Release python-zunclient for wallaby-1 milestone\n\nThis is a library release for python-zunclient for the wallaby-1\nmilestone. This repo includes commits that have not been releases for\nthis cycle yet.\n\nIf the team is ready to process with this release, please leave a +1\nto indicate we should go ahead with the release.\n\nIf the team needs more time for things about to merge, or if there is\nsome other reason a release should not be done at this time, please\nleave a -1 with a comment indicating the status. Then update the patch\nwith the new commit hash to use once the team is ready to do the\nrelease.\n\nChange-Id: I828fe08e65689bf32aa67b1a164dce2a3c21a188\n'}]",0,764752,6b621e8d3b8e699a19404ad24ac1f9fa9935e2cd,8,6,1,28522,,,0,"Release python-zunclient for wallaby-1 milestone

This is a library release for python-zunclient for the wallaby-1
milestone. This repo includes commits that have not been releases for
this cycle yet.

If the team is ready to process with this release, please leave a +1
to indicate we should go ahead with the release.

If the team needs more time for things about to merge, or if there is
some other reason a release should not be done at this time, please
leave a -1 with a comment indicating the status. Then update the patch
with the new commit hash to use once the team is ready to do the
release.

Change-Id: I828fe08e65689bf32aa67b1a164dce2a3c21a188
",git fetch https://review.opendev.org/openstack/releases refs/changes/52/764752/1 && git format-patch -1 --stdout FETCH_HEAD,['deliverables/wallaby/python-zunclient.yaml'],1,6b621e8d3b8e699a19404ad24ac1f9fa9935e2cd,w1-c-w-i,releases: - version: 4.2.0 projects: - repo: openstack/python-zunclient hash: 751df7101f66da07b7c2366d20c2af06a91de3d6,,5,0
openstack%2Freleases~master~I6b8323fe4344005afb1a17d561cb93eb07ec324e,openstack/releases,master,I6b8323fe4344005afb1a17d561cb93eb07ec324e,Release python-watcherclient for wallaby-1 milestone,ABANDONED,2020-11-30 13:53:11.000000000,2020-12-03 15:25:11.000000000,,"[{'_account_id': 11904}, {'_account_id': 21692}, {'_account_id': 22348}]","[{'number': 1, 'created': '2020-11-30 13:53:11.000000000', 'files': ['deliverables/wallaby/python-watcherclient.yaml'], 'web_link': 'https://opendev.org/openstack/releases/commit/a0206a7f660ebb2169661b8ae191a5f9aec7b4af', 'message': 'Release python-watcherclient for wallaby-1 milestone\n\nThis is a library release for python-watcherclient for the wallaby-1\nmilestone. This repo includes commits that have not been releases for\nthis cycle yet.\n\nIf the team is ready to process with this release, please leave a +1\nto indicate we should go ahead with the release.\n\nIf the team needs more time for things about to merge, or if there is\nsome other reason a release should not be done at this time, please\nleave a -1 with a comment indicating the status. Then update the patch\nwith the new commit hash to use once the team is ready to do the\nrelease.\n\nChange-Id: I6b8323fe4344005afb1a17d561cb93eb07ec324e\n'}]",0,764750,a0206a7f660ebb2169661b8ae191a5f9aec7b4af,6,3,1,28522,,,0,"Release python-watcherclient for wallaby-1 milestone

This is a library release for python-watcherclient for the wallaby-1
milestone. This repo includes commits that have not been releases for
this cycle yet.

If the team is ready to process with this release, please leave a +1
to indicate we should go ahead with the release.

If the team needs more time for things about to merge, or if there is
some other reason a release should not be done at this time, please
leave a -1 with a comment indicating the status. Then update the patch
with the new commit hash to use once the team is ready to do the
release.

Change-Id: I6b8323fe4344005afb1a17d561cb93eb07ec324e
",git fetch https://review.opendev.org/openstack/releases refs/changes/50/764750/1 && git format-patch -1 --stdout FETCH_HEAD,['deliverables/wallaby/python-watcherclient.yaml'],1,a0206a7f660ebb2169661b8ae191a5f9aec7b4af,w1-c-w-i,releases: - version: 3.2.0 projects: - repo: openstack/python-watcherclient hash: 6a33b44d7f989043e448030c518210744b35a08e,,5,0
openstack%2Freleases~master~Ieac436e4353f08b2e7b6a5a536d2bb9983d1408d,openstack/releases,master,Ieac436e4353f08b2e7b6a5a536d2bb9983d1408d,Release python-neutronclient for wallaby-1 milestone,ABANDONED,2020-11-30 13:48:13.000000000,2020-12-03 15:24:39.000000000,,"[{'_account_id': 841}, {'_account_id': 11904}, {'_account_id': 11975}, {'_account_id': 22348}]","[{'number': 1, 'created': '2020-11-30 13:48:13.000000000', 'files': ['deliverables/wallaby/python-neutronclient.yaml'], 'web_link': 'https://opendev.org/openstack/releases/commit/a98221b592a08a6a81d9e1a4bc1f5893121a9046', 'message': 'Release python-neutronclient for wallaby-1 milestone\n\nThis is a library release for python-neutronclient for the wallaby-1\nmilestone. This repo includes commits that have not been releases for\nthis cycle yet.\n\nIf the team is ready to process with this release, please leave a +1\nto indicate we should go ahead with the release.\n\nIf the team needs more time for things about to merge, or if there is\nsome other reason a release should not be done at this time, please\nleave a -1 with a comment indicating the status. Then update the patch\nwith the new commit hash to use once the team is ready to do the\nrelease.\n\nChange-Id: Ieac436e4353f08b2e7b6a5a536d2bb9983d1408d\n'}]",0,764740,a98221b592a08a6a81d9e1a4bc1f5893121a9046,6,4,1,28522,,,0,"Release python-neutronclient for wallaby-1 milestone

This is a library release for python-neutronclient for the wallaby-1
milestone. This repo includes commits that have not been releases for
this cycle yet.

If the team is ready to process with this release, please leave a +1
to indicate we should go ahead with the release.

If the team needs more time for things about to merge, or if there is
some other reason a release should not be done at this time, please
leave a -1 with a comment indicating the status. Then update the patch
with the new commit hash to use once the team is ready to do the
release.

Change-Id: Ieac436e4353f08b2e7b6a5a536d2bb9983d1408d
",git fetch https://review.opendev.org/openstack/releases refs/changes/40/764740/1 && git format-patch -1 --stdout FETCH_HEAD,['deliverables/wallaby/python-neutronclient.yaml'],1,a98221b592a08a6a81d9e1a4bc1f5893121a9046,w1-c-w-i,releases: - version: 7.3.0 projects: - repo: openstack/python-neutronclient hash: 1a1ee061e8d6d3a9c825819ed426e4f1b2eba80e,,5,0
openstack%2Freleases~master~I8664b8f465c00fe2ce3b880f37ea150d0e9c0a92,openstack/releases,master,I8664b8f465c00fe2ce3b880f37ea150d0e9c0a92,Release python-zaqarclient for wallaby-1 milestone,ABANDONED,2020-11-30 13:53:31.000000000,2020-12-03 15:16:33.000000000,,"[{'_account_id': 6484}, {'_account_id': 8846}, {'_account_id': 11904}, {'_account_id': 22348}]","[{'number': 1, 'created': '2020-11-30 13:53:31.000000000', 'files': ['deliverables/wallaby/python-zaqarclient.yaml'], 'web_link': 'https://opendev.org/openstack/releases/commit/6a46d9e06728c6ffcdbd313f09459636215de641', 'message': 'Release python-zaqarclient for wallaby-1 milestone\n\nThis is a library release for python-zaqarclient for the wallaby-1\nmilestone. This repo includes commits that have not been releases for\nthis cycle yet.\n\nIf the team is ready to process with this release, please leave a +1\nto indicate we should go ahead with the release.\n\nIf the team needs more time for things about to merge, or if there is\nsome other reason a release should not be done at this time, please\nleave a -1 with a comment indicating the status. Then update the patch\nwith the new commit hash to use once the team is ready to do the\nrelease.\n\nChange-Id: I8664b8f465c00fe2ce3b880f37ea150d0e9c0a92\n'}]",0,764751,6a46d9e06728c6ffcdbd313f09459636215de641,6,4,1,28522,,,0,"Release python-zaqarclient for wallaby-1 milestone

This is a library release for python-zaqarclient for the wallaby-1
milestone. This repo includes commits that have not been releases for
this cycle yet.

If the team is ready to process with this release, please leave a +1
to indicate we should go ahead with the release.

If the team needs more time for things about to merge, or if there is
some other reason a release should not be done at this time, please
leave a -1 with a comment indicating the status. Then update the patch
with the new commit hash to use once the team is ready to do the
release.

Change-Id: I8664b8f465c00fe2ce3b880f37ea150d0e9c0a92
",git fetch https://review.opendev.org/openstack/releases refs/changes/51/764751/1 && git format-patch -1 --stdout FETCH_HEAD,['deliverables/wallaby/python-zaqarclient.yaml'],1,6a46d9e06728c6ffcdbd313f09459636215de641,w1-c-w-i,releases: - version: 2.1.0 projects: - repo: openstack/python-zaqarclient hash: e388947aae2c1440ffc8c635d9dc2f702dc2cb27,,5,0
openstack%2Fpuppet-barbican~master~Ifaa3da741778f3f2af00e82934235f44dd0cf24e,openstack/puppet-barbican,master,Ifaa3da741778f3f2af00e82934235f44dd0cf24e,Missing supported_os fact,MERGED,2020-12-02 01:51:26.000000000,2020-12-03 15:13:06.000000000,2020-12-03 15:13:06.000000000,"[{'_account_id': 9816}, {'_account_id': 16137}, {'_account_id': 22348}]","[{'number': 1, 'created': '2020-12-02 01:51:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-barbican/commit/a6acb8413dade47da09012e72e861334ea1c2f85', 'message': 'Missing supported_os fact\n\nChange-Id: Ifaa3da741778f3f2af00e82934235f44dd0cf24e\n'}, {'number': 2, 'created': '2020-12-02 01:59:04.000000000', 'files': ['spec/classes/barbican_wsgi_apache_spec.rb'], 'web_link': 'https://opendev.org/openstack/puppet-barbican/commit/e48bc4d9a4e059dd4f1651465c3cecc6b30d6ab6', 'message': 'Missing supported_os fact\n\nIf the supported_os fact is missing, the test will not run on the\ndefault supported systems (debian, ubuntu, centos).\n\nChange-Id: Ifaa3da741778f3f2af00e82934235f44dd0cf24e\n'}]",0,765032,e48bc4d9a4e059dd4f1651465c3cecc6b30d6ab6,8,3,2,9414,,,0,"Missing supported_os fact

If the supported_os fact is missing, the test will not run on the
default supported systems (debian, ubuntu, centos).

Change-Id: Ifaa3da741778f3f2af00e82934235f44dd0cf24e
",git fetch https://review.opendev.org/openstack/puppet-barbican refs/changes/32/765032/1 && git format-patch -1 --stdout FETCH_HEAD,['spec/classes/barbican_wsgi_apache_spec.rb'],1,a6acb8413dade47da09012e72e861334ea1c2f85,missing-supported_os, :supported_os => OSDefaults.get_supported_os,,1,0
openstack%2Freleases~master~I72385fcef188ca50bd3babaec5ae57c173c9fa5c,openstack/releases,master,I72385fcef188ca50bd3babaec5ae57c173c9fa5c,Release castellan for wallaby-1 milestone,MERGED,2020-11-30 13:12:25.000000000,2020-12-03 15:11:28.000000000,2020-12-03 15:11:28.000000000,"[{'_account_id': 11904}, {'_account_id': 22348}, {'_account_id': 28522}]","[{'number': 1, 'created': '2020-11-30 13:12:25.000000000', 'files': ['deliverables/wallaby/castellan.yaml'], 'web_link': 'https://opendev.org/openstack/releases/commit/5832db900f33828a415deee7710356bb32d4bba1', 'message': 'Release castellan for wallaby-1 milestone\n\nThis is a library release for castellan for the wallaby-1\nmilestone. This repo includes commits that have not been releases for\nthis cycle yet.\n\nIf the team is ready to process with this release, please leave a +1\nto indicate we should go ahead with the release.\n\nIf the team needs more time for things about to merge, or if there is\nsome other reason a release should not be done at this time, please\nleave a -1 with a comment indicating the status. Then update the patch\nwith the new commit hash to use once the team is ready to do the\nrelease.\n\nChange-Id: I72385fcef188ca50bd3babaec5ae57c173c9fa5c\n'}]",0,764665,5832db900f33828a415deee7710356bb32d4bba1,8,3,1,28522,,,0,"Release castellan for wallaby-1 milestone

This is a library release for castellan for the wallaby-1
milestone. This repo includes commits that have not been releases for
this cycle yet.

If the team is ready to process with this release, please leave a +1
to indicate we should go ahead with the release.

If the team needs more time for things about to merge, or if there is
some other reason a release should not be done at this time, please
leave a -1 with a comment indicating the status. Then update the patch
with the new commit hash to use once the team is ready to do the
release.

Change-Id: I72385fcef188ca50bd3babaec5ae57c173c9fa5c
",git fetch https://review.opendev.org/openstack/releases refs/changes/65/764665/1 && git format-patch -1 --stdout FETCH_HEAD,['deliverables/wallaby/castellan.yaml'],1,5832db900f33828a415deee7710356bb32d4bba1,w1-c-w-i,releases: - version: 3.7.0 projects: - repo: openstack/castellan hash: aede0861dee800c0e9fb8a0ee79b91795941bdce,,5,0
openstack%2Fopenstackdocstheme~master~I1e1e39f39c6b0bb957d48d0f9a6cf7753a8d1258,openstack/openstackdocstheme,master,I1e1e39f39c6b0bb957d48d0f9a6cf7753a8d1258,Use TOX_CONSTRAINTS_FILE,MERGED,2020-11-04 09:54:38.000000000,2020-12-03 14:51:02.000000000,2020-12-03 14:48:27.000000000,"[{'_account_id': 11904}, {'_account_id': 22348}]","[{'number': 1, 'created': '2020-11-04 09:54:38.000000000', 'files': ['tox.ini'], 'web_link': 'https://opendev.org/openstack/openstackdocstheme/commit/3020abdfb87941d670616e3ee64441dc320b676a', 'message': 'Use TOX_CONSTRAINTS_FILE\n\nUPPER_CONSTRAINTS_FILE is old name and deprecated\nThis allows to use upper-constraints file as more\nreadable way instead of UPPER_CONSTRAINTS_FILE=<lower-constraints file>.\n\n[1] https://review.opendev.org/#/c/722814/\n[2] https://zuul-ci.org/docs/zuul-jobs/python-roles.html#rolevar-tox.tox_constraints_file\n\nChange-Id: I1e1e39f39c6b0bb957d48d0f9a6cf7753a8d1258\n'}]",0,761366,3020abdfb87941d670616e3ee64441dc320b676a,7,2,1,28522,,,0,"Use TOX_CONSTRAINTS_FILE

UPPER_CONSTRAINTS_FILE is old name and deprecated
This allows to use upper-constraints file as more
readable way instead of UPPER_CONSTRAINTS_FILE=<lower-constraints file>.

[1] https://review.opendev.org/#/c/722814/
[2] https://zuul-ci.org/docs/zuul-jobs/python-roles.html#rolevar-tox.tox_constraints_file

Change-Id: I1e1e39f39c6b0bb957d48d0f9a6cf7753a8d1258
",git fetch https://review.opendev.org/openstack/openstackdocstheme refs/changes/66/761366/1 && git format-patch -1 --stdout FETCH_HEAD,['tox.ini'],1,3020abdfb87941d670616e3ee64441dc320b676a,tox_constraints_file, -c{env:TOX_CONSTRAINTS_FILE:https://opendev.org/openstack/requirements/raw/upper-constraints.txt}, -c{env:UPPER_CONSTRAINTS_FILE:https://opendev.org/openstack/requirements/raw/upper-constraints.txt},1,1
openstack%2Fcinder~stable%2Fvictoria~I8c2c58092da4d5801642036a96079da45eafb290,openstack/cinder,stable/victoria,I8c2c58092da4d5801642036a96079da45eafb290,Fix volume rekey during clone,MERGED,2020-11-29 22:25:43.000000000,2020-12-03 14:50:46.000000000,2020-12-03 14:38:27.000000000,"[{'_account_id': 4523}, {'_account_id': 5314}, {'_account_id': 5997}, {'_account_id': 7198}, {'_account_id': 10459}, {'_account_id': 11904}, {'_account_id': 22348}]","[{'number': 1, 'created': '2020-11-29 22:25:43.000000000', 'files': ['cinder/volume/flows/manager/create_volume.py', 'cinder/tests/unit/volume/test_volume.py', 'releasenotes/notes/bug-1904440-clone-rekey-fd57a2b5f6224e0f.yaml'], 'web_link': 'https://opendev.org/openstack/cinder/commit/cdc586631586dc9782794a90f129ce3f34118193', 'message': 'Fix volume rekey during clone\n\nApply the correct encryption key to the\nnew volume during clone.\n\nCloses-Bug: #1904440\nChange-Id: I8c2c58092da4d5801642036a96079da45eafb290\n(cherry picked from commit 25cded9d106ea3c4d23b87d594451dc7fb9e0484)\n'}]",0,764503,cdc586631586dc9782794a90f129ce3f34118193,37,7,1,21129,,,0,"Fix volume rekey during clone

Apply the correct encryption key to the
new volume during clone.

Closes-Bug: #1904440
Change-Id: I8c2c58092da4d5801642036a96079da45eafb290
(cherry picked from commit 25cded9d106ea3c4d23b87d594451dc7fb9e0484)
",git fetch https://review.opendev.org/openstack/cinder refs/changes/03/764503/1 && git format-patch -1 --stdout FETCH_HEAD,"['cinder/volume/flows/manager/create_volume.py', 'cinder/tests/unit/volume/test_volume.py', 'releasenotes/notes/bug-1904440-clone-rekey-fd57a2b5f6224e0f.yaml']",3,cdc586631586dc9782794a90f129ce3f34118193,,"--- fixes: - | `Bug #1904440 <https://bugs.launchpad.net/cinder/+bug/1904440>`_: When an iSCSI/FC encrypted volume was cloned, the rekey operation would stamp the wrong encryption key on the newly cloned volume. This resulted in a volume that could not be attached. It does not present a security problem. ",,54,1
openstack%2Fneutron~master~I693c03622b047f126b5031a01f7f7ebbb002b22e,openstack/neutron,master,I693c03622b047f126b5031a01f7f7ebbb002b22e,Implement secure RBAC for address scopes,ABANDONED,2020-12-03 02:45:16.000000000,2020-12-03 14:44:50.000000000,,[],"[{'number': 1, 'created': '2020-12-03 02:45:16.000000000', 'files': ['neutron/conf/policies/address_scope.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/99a3ad428e46962d977997983a5f8b8932b9e501', 'message': 'Implement secure RBAC for address scopes\n\nThis commit updates the policies for address scopes to account for\nsystem-scope and default roles provided in keystone. This is part of a\nbroader set of changes across OpenStack APIs to provide a more secure\nand consistent authorization experience for end-users and operators.\n\nChange-Id: I693c03622b047f126b5031a01f7f7ebbb002b22e\n'}]",0,765232,99a3ad428e46962d977997983a5f8b8932b9e501,3,0,1,5046,,,0,"Implement secure RBAC for address scopes

This commit updates the policies for address scopes to account for
system-scope and default roles provided in keystone. This is part of a
broader set of changes across OpenStack APIs to provide a more secure
and consistent authorization experience for end-users and operators.

Change-Id: I693c03622b047f126b5031a01f7f7ebbb002b22e
",git fetch https://review.opendev.org/openstack/neutron refs/changes/32/765232/1 && git format-patch -1 --stdout FETCH_HEAD,['neutron/conf/policies/address_scope.py'],1,99a3ad428e46962d977997983a5f8b8932b9e501,secure-rbac,"from oslo_log import versionutilsDEPRECATED_REASON = """""" The address scope API now supports system scope and default roles. """""" deprecated_create_address_scope = policy.DeprecatedRule( name='create_address_scope', check_str=base.RULE_ANY ) deprecated_create_address_scope_shared = policy.DeprecatedRule( name='create_address_scope:shared', check_str=base.RULE_ADMIN_ONLY ) deprecated_get_address_scope = policy.DeprecatedRule( name='get_address_scope', check_str=base.policy_or( base.RULE_ADMIN_OR_OWNER, 'rule:shared_address_scopes' ) ) deprecated_update_address_scope = policy.DeprecatedRule( name='update_address_scope', check_str=base.RULE_ADMIN_OR_OWNER ) deprecated_update_address_scope_shared = policy.DeprecatedRule( name='update_address_scope:shared', check_str=base.RULE_ADMIN_ONLY ) deprecated_delete_address_scope = policy.DeprecatedRule( name='delete_address_scope', check_str=base.RULE_ADMIN_OR_OWNER ) name='shared_address_scopes', check_str='field:address_scopes:shared=True', description='Definition of a shared address scope' name='create_address_scope', check_str=base.SYSTEM_ADMIN_OR_PROJECT_MEMBER, scope_types=['system', 'project'], description='Create an address scope', operations=[ ], deprecated_rule=deprecated_create_address_scope, deprecated_reason=DEPRECATED_REASON, deprecated_since=versionutils.deprecated.WALLABY name='create_address_scope:shared', check_str=base.SYSTEM_ADMIN, scope_types=['system'], description='Create a shared address scope', operations=[ ], deprecated_rule=deprecated_create_address_scope_shared, deprecated_reason=DEPRECATED_REASON, deprecated_since=versionutils.deprecated.WALLABY name='get_address_scope', check_str=base.SYSTEM_OR_PROJECT_READER, scope_types=['system', 'project'], description='Get an address scope', operations=[ ], deprecated_rule=deprecated_get_address_scope, deprecated_reason=DEPRECATED_REASON, deprecated_since=versionutils.deprecated.WALLABY name='update_address_scope', check_str=base.SYSTEM_ADMIN_OR_PROJECT_MEMBER, scope_types=['system', 'project'], description='Update an address scope', operations=[ ], deprecated_rule=deprecated_update_address_scope, deprecated_reason=DEPRECATED_REASON, deprecated_since=versionutils.deprecated.WALLABY name='update_address_scope:shared', check_str=base.SYSTEM_ADMIN, scope_types=['system'], description='Update ``shared`` attribute of an address scope', operations=[ ], deprecated_rule=deprecated_update_address_scope_shared, deprecated_reason=DEPRECATED_REASON, deprecated_since=versionutils.deprecated.WALLABY name='delete_address_scope', check_str=base.SYSTEM_ADMIN_OR_PROJECT_MEMBER, scope_types=['system', 'project'], description='Delete an address scope', operations=[ ], deprecated_rule=deprecated_delete_address_scope, deprecated_reason=DEPRECATED_REASON, deprecated_since=versionutils.deprecated.WALLABY"," 'shared_address_scopes', 'field:address_scopes:shared=True', 'Definition of a shared address scope' 'create_address_scope', base.RULE_ANY, 'Create an address scope', [ ] 'create_address_scope:shared', base.RULE_ADMIN_ONLY, 'Create a shared address scope', [ ] 'get_address_scope', base.policy_or(base.RULE_ADMIN_OR_OWNER, 'rule:shared_address_scopes'), 'Get an address scope', [ ] 'update_address_scope', base.RULE_ADMIN_OR_OWNER, 'Update an address scope', [ ] 'update_address_scope:shared', base.RULE_ADMIN_ONLY, 'Update ``shared`` attribute of an address scope', [ ] 'delete_address_scope', base.RULE_ADMIN_OR_OWNER, 'Delete an address scope', [ ]",90,34
openstack%2Fopenstack-ansible~master~Ib18788ffc318b43d78e154295d027f9ed0dccf38,openstack/openstack-ansible,master,Ib18788ffc318b43d78e154295d027f9ed0dccf38,Decrease amphora image RAM for CI,MERGED,2020-12-02 13:10:20.000000000,2020-12-03 14:42:26.000000000,2020-12-03 14:33:51.000000000,"[{'_account_id': 22348}, {'_account_id': 25023}, {'_account_id': 31542}]","[{'number': 1, 'created': '2020-12-02 13:10:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/edae7206b0fb780308687847ec410b70d61340fb', 'message': 'Decrease amphora image RAM for CI\n\nDefault value for amphora image is 1024MB which is the way too much for\nCI gates that overall has 8Gb of RAM.\n\nChange-Id: Ib18788ffc318b43d78e154295d027f9ed0dccf38\n'}, {'number': 2, 'created': '2020-12-02 16:38:23.000000000', 'files': ['tests/roles/bootstrap-host/templates/user_variables_octavia.yml.j2'], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/0f352559f5db3727b6c4117df345b888e11486b0', 'message': 'Decrease amphora image RAM for CI\n\nDefault value for amphora image is 1024MB which is the way too much for\nCI gates that overall has 8Gb of RAM. We also limit threads number for\noctavia health manager.\n\nChange-Id: Ib18788ffc318b43d78e154295d027f9ed0dccf38\n'}]",0,765134,0f352559f5db3727b6c4117df345b888e11486b0,9,3,2,28619,,,0,"Decrease amphora image RAM for CI

Default value for amphora image is 1024MB which is the way too much for
CI gates that overall has 8Gb of RAM. We also limit threads number for
octavia health manager.

Change-Id: Ib18788ffc318b43d78e154295d027f9ed0dccf38
",git fetch https://review.opendev.org/openstack/openstack-ansible refs/changes/34/765134/2 && git format-patch -1 --stdout FETCH_HEAD,['tests/roles/bootstrap-host/templates/user_variables_octavia.yml.j2'],1,edae7206b0fb780308687847ec410b70d61340fb,,octavia_amp_ram: 512,,1,0
openstack%2Fopenstack-ansible~master~Ia97fc6a75b64d52075fbd5b20361d8bc3472a15c,openstack/openstack-ansible,master,Ia97fc6a75b64d52075fbd5b20361d8bc3472a15c,Add Zun CI requirement to Zuul required projects,MERGED,2020-11-18 13:22:41.000000000,2020-12-03 14:41:03.000000000,2020-12-03 14:33:41.000000000,"[{'_account_id': 22348}, {'_account_id': 25023}, {'_account_id': 28619}]","[{'number': 1, 'created': '2020-11-18 13:22:41.000000000', 'files': ['zuul.d/jobs.yaml'], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/427d5f2ec428b5adeea087224bad0970ee417554', 'message': 'Add Zun CI requirement to Zuul required projects\n\nkuryr-libnetwork is required by the Zun role. Cloning from this\nrepo currently fails in Zun CI\n\nChange-Id: Ia97fc6a75b64d52075fbd5b20361d8bc3472a15c\n'}]",0,763177,427d5f2ec428b5adeea087224bad0970ee417554,24,3,1,31542,,,0,"Add Zun CI requirement to Zuul required projects

kuryr-libnetwork is required by the Zun role. Cloning from this
repo currently fails in Zun CI

Change-Id: Ia97fc6a75b64d52075fbd5b20361d8bc3472a15c
",git fetch https://review.opendev.org/openstack/openstack-ansible refs/changes/77/763177/1 && git format-patch -1 --stdout FETCH_HEAD,['zuul.d/jobs.yaml'],1,427d5f2ec428b5adeea087224bad0970ee417554,, - name: openstack/kuryr-libnetwork,,1,0
openstack%2Fopenstack-doc-tools~master~I9a48a44a1cc32c3ab9393b97ea9014dc95cfd4de,openstack/openstack-doc-tools,master,I9a48a44a1cc32c3ab9393b97ea9014dc95cfd4de,Use TOX_CONSTRAINTS_FILE,MERGED,2020-11-04 09:54:17.000000000,2020-12-03 14:40:48.000000000,2020-12-03 14:38:45.000000000,"[{'_account_id': 11904}, {'_account_id': 22348}]","[{'number': 1, 'created': '2020-11-04 09:54:17.000000000', 'files': ['tox.ini'], 'web_link': 'https://opendev.org/openstack/openstack-doc-tools/commit/3c9dac518639ea57d2641b0cc13dd8989b2f4179', 'message': 'Use TOX_CONSTRAINTS_FILE\n\nUPPER_CONSTRAINTS_FILE is old name and deprecated\nThis allows to use upper-constraints file as more\nreadable way instead of UPPER_CONSTRAINTS_FILE=<lower-constraints file>.\n\n[1] https://review.opendev.org/#/c/722814/\n[2] https://zuul-ci.org/docs/zuul-jobs/python-roles.html#rolevar-tox.tox_constraints_file\n\nChange-Id: I9a48a44a1cc32c3ab9393b97ea9014dc95cfd4de\n'}]",0,761365,3c9dac518639ea57d2641b0cc13dd8989b2f4179,7,2,1,28522,,,0,"Use TOX_CONSTRAINTS_FILE

UPPER_CONSTRAINTS_FILE is old name and deprecated
This allows to use upper-constraints file as more
readable way instead of UPPER_CONSTRAINTS_FILE=<lower-constraints file>.

[1] https://review.opendev.org/#/c/722814/
[2] https://zuul-ci.org/docs/zuul-jobs/python-roles.html#rolevar-tox.tox_constraints_file

Change-Id: I9a48a44a1cc32c3ab9393b97ea9014dc95cfd4de
",git fetch https://review.opendev.org/openstack/openstack-doc-tools refs/changes/65/761365/1 && git format-patch -1 --stdout FETCH_HEAD,['tox.ini'],1,3c9dac518639ea57d2641b0cc13dd8989b2f4179,tox_constraints_file, -c{env:TOX_CONSTRAINTS_FILE:https://releases.openstack.org/constraints/upper/master}, -c{env:UPPER_CONSTRAINTS_FILE:https://releases.openstack.org/constraints/upper/master},1,1
openstack%2Fcharms.openstack~master~I42574654bc1f314b49049e80861d4039f8484dff,openstack/charms.openstack,master,I42574654bc1f314b49049e80861d4039f8484dff,Allow bespoke get_charm_instance method to be used,MERGED,2020-12-03 10:59:46.000000000,2020-12-03 14:38:22.000000000,2020-12-03 14:38:22.000000000,"[{'_account_id': 20870}, {'_account_id': 22348}]","[{'number': 1, 'created': '2020-12-03 10:59:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charms.openstack/commit/5bd0e7ab57471897cc166aea7ec0a7c258de8a82', 'message': 'Allow bespoke get_charm_instance method to be used\n\nAllow a charm to use the new register_get_charm_instance decorator\nto register the method to be used when getting a charm instance.\nCurrently get_charm_instance expects standard OpenStack\nversioning, this change allows are a charm to register an\nalternative get_charm_instance method that can handle an\nalternative versioning system.\n\nPerhaps controversially the default method is not defined in\ncharms_openstack.charm.defaults. I have kept it in core\nbecause it felt a more natural fit there given it relies on\ncore._releases but I am open to moving it if that is\npreferable.\n\nChange-Id: I42574654bc1f314b49049e80861d4039f8484dff\n'}, {'number': 2, 'created': '2020-12-03 13:22:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charms.openstack/commit/418595b638b14c166948f207e79082599e38a47b', 'message': 'Allow bespoke get_charm_instance method to be used\n\nAllow a charm to use the new register_get_charm_instance decorator\nto register the method to be used when getting a charm instance.\nCurrently get_charm_instance expects standard OpenStack\nversioning, this change allows are a charm to register an\nalternative get_charm_instance method that can handle an\nalternative versioning system.\n\nPerhaps controversially the default method is not defined in\ncharms_openstack.charm.defaults. I have kept it in core\nbecause it felt a more natural fit there given it relies on\ncore._releases but I am open to moving it if that is\npreferable.\n\nChange-Id: I42574654bc1f314b49049e80861d4039f8484dff\n'}, {'number': 3, 'created': '2020-12-03 13:46:13.000000000', 'files': ['charms_openstack/charm/core.py', 'unit_tests/charms_openstack/charm/test_core.py'], 'web_link': 'https://opendev.org/openstack/charms.openstack/commit/38de241ce669dbc4c9c956cf94fbfc9dbbbbe17f', 'message': 'Allow bespoke get_charm_instance method to be used\n\nAllow a charm to use the new register_get_charm_instance decorator\nto register the method to be used when getting a charm instance.\nCurrently get_charm_instance expects standard OpenStack\nversioning, this change allows are a charm to register an\nalternative get_charm_instance method that can handle an\nalternative versioning system.\n\nPerhaps controversially the default method is not defined in\ncharms_openstack.charm.defaults. I have kept it in core\nbecause it felt a more natural fit there given it relies on\ncore._releases but I am open to moving it if that is\npreferable.\n\nChange-Id: I42574654bc1f314b49049e80861d4039f8484dff\n'}]",1,765310,38de241ce669dbc4c9c956cf94fbfc9dbbbbe17f,11,2,3,12549,,,0,"Allow bespoke get_charm_instance method to be used

Allow a charm to use the new register_get_charm_instance decorator
to register the method to be used when getting a charm instance.
Currently get_charm_instance expects standard OpenStack
versioning, this change allows are a charm to register an
alternative get_charm_instance method that can handle an
alternative versioning system.

Perhaps controversially the default method is not defined in
charms_openstack.charm.defaults. I have kept it in core
because it felt a more natural fit there given it relies on
core._releases but I am open to moving it if that is
preferable.

Change-Id: I42574654bc1f314b49049e80861d4039f8484dff
",git fetch https://review.opendev.org/openstack/charms.openstack refs/changes/10/765310/1 && git format-patch -1 --stdout FETCH_HEAD,"['charms_openstack/charm/core.py', 'unit_tests/charms_openstack/charm/test_core.py']",2,5bd0e7ab57471897cc166aea7ec0a7c258de8a82,register-get-charm-instance,"class TestRegisterGetCharmInstance(unittest.TestCase): def test_register(self): save_rsf = chm_core._get_charm_instance_function chm_core._get_charm_instance_function = None @chm_core.register_get_charm_instance def test_func(): pass self.assertEqual(chm_core._get_charm_instance_function, test_func) chm_core._get_charm_instance_function = save_rsf def test_cant_register_more_than_once(self): save_rsf = chm_core._get_charm_instance_function chm_core._get_charm_instance_function = None @chm_core.register_get_charm_instance def test_func1(): pass with self.assertRaises(RuntimeError): @chm_core.register_get_charm_instance def test_func2(): pass self.assertEqual(chm_core._get_charm_instance_function, test_func1) chm_core._get_charm_instance_function = save_rsf chm_core._get_charm_instance_function = None",,87,3
openstack%2Fneutron~master~Id060a9df49d9f4a87e7a8d1037ad47f6da080211,openstack/neutron,master,Id060a9df49d9f4a87e7a8d1037ad47f6da080211,Add common persona check strings to base policies,ABANDONED,2020-12-03 02:31:36.000000000,2020-12-03 14:20:57.000000000,,[],"[{'number': 1, 'created': '2020-12-03 02:31:36.000000000', 'files': ['neutron/conf/policies/base.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/cf209fdaeadd9e7c57935de21e9aca5e0803e0e4', 'message': 'Add common persona check strings to base policies\n\nThis commit introduces several new common check strings as constants in\nbase.py. Subsequent patches will use these check strings when updating\npolicies.\n\nChange-Id: Id060a9df49d9f4a87e7a8d1037ad47f6da080211\n'}]",0,765231,cf209fdaeadd9e7c57935de21e9aca5e0803e0e4,3,0,1,5046,,,0,"Add common persona check strings to base policies

This commit introduces several new common check strings as constants in
base.py. Subsequent patches will use these check strings when updating
policies.

Change-Id: Id060a9df49d9f4a87e7a8d1037ad47f6da080211
",git fetch https://review.opendev.org/openstack/neutron refs/changes/31/765231/1 && git format-patch -1 --stdout FETCH_HEAD,['neutron/conf/policies/base.py'],1,cf209fdaeadd9e7c57935de21e9aca5e0803e0e4,secure-rbac,SYSTEM_ADMIN = 'role:admin and system_scope:all' SYSTEM_READER = 'role:reader and system_scope:all' PROJECT_MEMBER = 'role:member and project_id:%(project_id)s' PROJECT_READER = 'role:reader and project_id:%(project_id)s' # Composite check strings build for policies that are designed to operate # across multiple scopes. SYSTEM_ADMIN_OR_PROJECT_MEMBER = ( '(' + SYSTEM_ADMIN + ')' ' or (' + PROJECT_MEMBER + ')' ) SYSTEM_OR_PROJECT_READER = ( '(' + SYSTEM_READER + ')' ' or (' + PROJECT_READER + ')' ),,15,0
openstack%2Frpm-packaging~master~I0c6a291f9a53350cab9cab1f4b8f93cfa66a4fb7,openstack/rpm-packaging,master,I0c6a291f9a53350cab9cab1f4b8f93cfa66a4fb7,update python-tackerclient to 1.4.0,MERGED,2020-12-01 10:26:00.000000000,2020-12-03 14:04:16.000000000,2020-12-03 14:04:16.000000000,"[{'_account_id': 6593}, {'_account_id': 13294}, {'_account_id': 19648}, {'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2020-12-01 10:26:00.000000000', 'files': ['openstack/python-tackerclient/python-tackerclient.spec.j2'], 'web_link': 'https://opendev.org/openstack/rpm-packaging/commit/7c101da272e2aa60ce2527197f170246ffc906f8', 'message': 'update python-tackerclient to 1.4.0\n\nChange-Id: I0c6a291f9a53350cab9cab1f4b8f93cfa66a4fb7\n'}]",0,764923,7c101da272e2aa60ce2527197f170246ffc906f8,10,5,1,30533,,,0,"update python-tackerclient to 1.4.0

Change-Id: I0c6a291f9a53350cab9cab1f4b8f93cfa66a4fb7
",git fetch https://review.opendev.org/openstack/rpm-packaging refs/changes/23/764923/1 && git format-patch -1 --stdout FETCH_HEAD,['openstack/python-tackerclient/python-tackerclient.spec.j2'],1,7c101da272e2aa60ce2527197f170246ffc906f8,bug/python-tackerclient,{% set upstream_version = upstream_version('1.4.0') %},{% set upstream_version = upstream_version('1.3.0') %},1,1
openstack%2Fopenstack-ansible-os_sahara~master~Ie4384375f65d6ec262a3f5b71ab7cd62ed5e210a,openstack/openstack-ansible-os_sahara,master,Ie4384375f65d6ec262a3f5b71ab7cd62ed5e210a,Reduce number of processes on small systems,MERGED,2020-11-30 11:59:17.000000000,2020-12-03 13:58:27.000000000,2020-12-03 13:57:05.000000000,"[{'_account_id': 22348}, {'_account_id': 25023}, {'_account_id': 31542}]","[{'number': 1, 'created': '2020-11-30 11:59:17.000000000', 'files': ['defaults/main.yml'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_sahara/commit/0f9e76292461a5532f6d43927b71ab9fff692dd5', 'message': 'Reduce number of processes on small systems\n\nEven the most modest 4C/8T system would run with the maximum 16 processes\ndue to the calculation being VCPU*2.\n\nWe devide amount of CPUs to number of threads for hyperthreaded CPUs\n\nChange-Id: Ie4384375f65d6ec262a3f5b71ab7cd62ed5e210a\n'}]",0,764651,0f9e76292461a5532f6d43927b71ab9fff692dd5,10,3,1,28619,,,0,"Reduce number of processes on small systems

Even the most modest 4C/8T system would run with the maximum 16 processes
due to the calculation being VCPU*2.

We devide amount of CPUs to number of threads for hyperthreaded CPUs

Change-Id: Ie4384375f65d6ec262a3f5b71ab7cd62ed5e210a
",git fetch https://review.opendev.org/openstack/openstack-ansible-os_sahara refs/changes/51/764651/1 && git format-patch -1 --stdout FETCH_HEAD,['defaults/main.yml'],1,0f9e76292461a5532f6d43927b71ab9fff692dd5,api_threads,"sahara_api_workers: ""{{ [[(ansible_processor_vcpus//ansible_processor_threads_per_core)|default(1), 1] | max * 2, sahara_api_workers_max] | min }}""","sahara_api_workers: ""{{ [[ansible_processor_vcpus|default(2) // 2, 1] | max, sahara_api_workers_max] | min }}""",1,1
openstack%2Fpython-troveclient~master~I8f561325780a95173501f42e10b6fce617bb17f4,openstack/python-troveclient,master,I8f561325780a95173501f42e10b6fce617bb17f4,Add support for python 3.8,MERGED,2020-12-03 01:03:27.000000000,2020-12-03 13:51:45.000000000,2020-12-03 13:49:20.000000000,"[{'_account_id': 3031}, {'_account_id': 6732}, {'_account_id': 22348}]","[{'number': 1, 'created': '2020-12-03 01:03:27.000000000', 'files': ['lower-constraints.txt'], 'web_link': 'https://opendev.org/openstack/python-troveclient/commit/61d36db2d5dbe2cb5f8a014ca755f4af62fd5041', 'message': 'Add support for python 3.8\n\nIntroduce support of python 3.8 [1] and move tox and jobs to py38.\n\njsonschema 3.2.0 [2] support python 3.8\npyOpenSSL 19.1.0 [3] support python 3.8\n\n[1] https://governance.openstack.org/tc/reference/runtimes/victoria.html#python-runtimes-for-victoria\n[2] https://github.com/Julian/jsonschema/pull/627\n[3] https://pypi.org/project/pyOpenSSL/19.1.0/\n\nChange-Id: I8f561325780a95173501f42e10b6fce617bb17f4\n'}]",0,765225,61d36db2d5dbe2cb5f8a014ca755f4af62fd5041,8,3,1,32029,,,0,"Add support for python 3.8

Introduce support of python 3.8 [1] and move tox and jobs to py38.

jsonschema 3.2.0 [2] support python 3.8
pyOpenSSL 19.1.0 [3] support python 3.8

[1] https://governance.openstack.org/tc/reference/runtimes/victoria.html#python-runtimes-for-victoria
[2] https://github.com/Julian/jsonschema/pull/627
[3] https://pypi.org/project/pyOpenSSL/19.1.0/

Change-Id: I8f561325780a95173501f42e10b6fce617bb17f4
",git fetch https://review.opendev.org/openstack/python-troveclient refs/changes/25/765225/1 && git format-patch -1 --stdout FETCH_HEAD,['lower-constraints.txt'],1,61d36db2d5dbe2cb5f8a014ca755f4af62fd5041,py38,jsonschema==3.2.0pyOpenSSL==19.1.0,jsonschema==2.6.0pyOpenSSL==17.1.0,2,2
openstack%2Ftrove~master~I2be70b395877ede3f594232a19cab4b83835dcc5,openstack/trove,master,I2be70b395877ede3f594232a19cab4b83835dcc5,use HTTPStatus instead of http.client,MERGED,2020-11-11 01:31:20.000000000,2020-12-03 13:50:38.000000000,2020-12-03 13:49:13.000000000,"[{'_account_id': 3031}, {'_account_id': 6732}, {'_account_id': 22348}, {'_account_id': 32238}]","[{'number': 1, 'created': '2020-11-11 01:31:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/trove/commit/302a2624855fdaa32f5313e9a351d7ea51363c13', 'message': ""use HTTPStatus instead of http.client\n\nWe don't need an HTTP client for this, we only\nneed status codes.  Just load that instead.\n\nhttps://docs.python.org/3/library/http.html\n\nChange-Id: I2be70b395877ede3f594232a19cab4b83835dcc5\n""}, {'number': 2, 'created': '2020-11-11 05:53:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/trove/commit/cb2918ca584c21af0269387d4247e7b72570d685', 'message': ""use HTTPStatus instead of http.client\n\nWe don't need an HTTP client for this, we only\nneed status codes.  Just load that instead.\n\nhttps://docs.python.org/3/library/http.html\n\nChange-Id: I2be70b395877ede3f594232a19cab4b83835dcc5\n""}, {'number': 3, 'created': '2020-12-03 02:08:23.000000000', 'files': ['trove/tests/fakes/swift.py'], 'web_link': 'https://opendev.org/openstack/trove/commit/c1a722d771ad107de57abf4de76bc8bc18c346f7', 'message': ""use HTTPStatus instead of http.client\n\nWe don't need an HTTP client for this, we only\nneed status codes.  Just load that instead.\n\nhttps://docs.python.org/3/library/http.html\n\nChange-Id: I2be70b395877ede3f594232a19cab4b83835dcc5\n""}]",1,762269,c1a722d771ad107de57abf4de76bc8bc18c346f7,15,4,3,32029,,,0,"use HTTPStatus instead of http.client

We don't need an HTTP client for this, we only
need status codes.  Just load that instead.

https://docs.python.org/3/library/http.html

Change-Id: I2be70b395877ede3f594232a19cab4b83835dcc5
",git fetch https://review.opendev.org/openstack/trove refs/changes/69/762269/3 && git format-patch -1 --stdout FETCH_HEAD,"['trove/common/limits.py', 'trove/tests/fakes/swift.py', 'trove/tests/unittests/api/common/test_limits.py']",3,302a2624855fdaa32f5313e9a351d7ea51363c13,http_client,from http import HTTPStatus as http_client,from http import client as http_client,3,3
openstack%2Fopenstack-ansible-os_adjutant~master~I41d331fdb5ee95e0c9b9edbb3c7ee19ccd40d98c,openstack/openstack-ansible-os_adjutant,master,I41d331fdb5ee95e0c9b9edbb3c7ee19ccd40d98c,Define condition for the first play host one time,MERGED,2020-11-30 12:17:41.000000000,2020-12-03 13:40:31.000000000,2020-12-03 13:39:11.000000000,"[{'_account_id': 22348}, {'_account_id': 25023}, {'_account_id': 31542}]","[{'number': 1, 'created': '2020-11-30 12:17:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_adjutant/commit/3bdd38a0a6bf4c4a286f83dcc0c7685c8b2b4f02', 'message': 'Define condition for the first play host one time\n\nWe use the same condition, which defines against what host some ""service""\ntasks should run against, several times. It\'s hard to keep it the same\nacross the role and ansible spending additional resources to evaluate\nit each time, so it\'s simpler and better for the maintenance to set\na boolean variable which will say for all tasks, that we want to run\nonly against signle host, if they should run or not now.\n\nDepends-On: https://review.opendev.org/c/openstack/openstack-ansible/+/756310\nChange-Id: I41d331fdb5ee95e0c9b9edbb3c7ee19ccd40d98c\n'}, {'number': 2, 'created': '2020-12-01 14:47:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_adjutant/commit/9e2afb40f01215ff17da646e95c4f8dcec69f879', 'message': 'Define condition for the first play host one time\n\nWe use the same condition, which defines against what host some ""service""\ntasks should run against, several times. It\'s hard to keep it the same\nacross the role and ansible spending additional resources to evaluate\nit each time, so it\'s simpler and better for the maintenance to set\na boolean variable which will say for all tasks, that we want to run\nonly against signle host, if they should run or not now.\n\nDepends-On: https://review.opendev.org/c/openstack/openstack-ansible/+/756310\nChange-Id: I41d331fdb5ee95e0c9b9edbb3c7ee19ccd40d98c\n'}, {'number': 3, 'created': '2020-12-02 07:53:58.000000000', 'files': ['tasks/main.yml', 'vars/main.yml'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_adjutant/commit/a202a34981870e524665d2b19232b313507307a6', 'message': 'Define condition for the first play host one time\n\nWe use the same condition, which defines against what host some ""service""\ntasks should run against, several times. It\'s hard to keep it the same\nacross the role and ansible spending additional resources to evaluate\nit each time, so it\'s simpler and better for the maintenance to set\na boolean variable which will say for all tasks, that we want to run\nonly against signle host, if they should run or not now.\n\nDepends-On: https://review.opendev.org/c/openstack/openstack-ansible/+/756310\nChange-Id: I41d331fdb5ee95e0c9b9edbb3c7ee19ccd40d98c\n'}]",1,764656,a202a34981870e524665d2b19232b313507307a6,14,3,3,28619,,,0,"Define condition for the first play host one time

We use the same condition, which defines against what host some ""service""
tasks should run against, several times. It's hard to keep it the same
across the role and ansible spending additional resources to evaluate
it each time, so it's simpler and better for the maintenance to set
a boolean variable which will say for all tasks, that we want to run
only against signle host, if they should run or not now.

Depends-On: https://review.opendev.org/c/openstack/openstack-ansible/+/756310
Change-Id: I41d331fdb5ee95e0c9b9edbb3c7ee19ccd40d98c
",git fetch https://review.opendev.org/openstack/openstack-ansible-os_adjutant refs/changes/56/764656/3 && git format-patch -1 --stdout FETCH_HEAD,"['tasks/main.yml', 'vars/main.yml']",2,3bdd38a0a6bf4c4a286f83dcc0c7685c8b2b4f02,run_condition,"_adjuant_is_first_play_host: ""{{ (adjutant_services['adjutant-api']['group'] in group_names and inventory_hostname == (groups[adjutant_services['adjutant-api']['group']] | intersect(ansible_play_hosts)) | first) | bool }}"" ",,5,3
openstack%2Fpuppet-swift~stable%2Fussuri~Ibad1132193b08dcb2846ab7d7bf305fa77e17bbb,openstack/puppet-swift,stable/ussuri,Ibad1132193b08dcb2846ab7d7bf305fa77e17bbb,Test https://review.opendev.org/c/openstack/puppet-swift/+/765295,ABANDONED,2020-12-03 13:39:42.000000000,2020-12-03 13:40:18.000000000,,[],"[{'number': 1, 'created': '2020-12-03 13:39:42.000000000', 'files': ['.dnm'], 'web_link': 'https://opendev.org/openstack/puppet-swift/commit/3a0aad1d7462d6225fd183e079b37d6c4333f1b4', 'message': 'Test https://review.opendev.org/c/openstack/puppet-swift/+/765295\n\nDepends-on: https://review.opendev.org/c/765295\nChange-Id: Ibad1132193b08dcb2846ab7d7bf305fa77e17bbb\n'}]",0,765330,3a0aad1d7462d6225fd183e079b37d6c4333f1b4,2,0,1,9816,,,0,"Test https://review.opendev.org/c/openstack/puppet-swift/+/765295

Depends-on: https://review.opendev.org/c/765295
Change-Id: Ibad1132193b08dcb2846ab7d7bf305fa77e17bbb
",git fetch https://review.opendev.org/openstack/puppet-swift refs/changes/30/765330/1 && git format-patch -1 --stdout FETCH_HEAD,['.dnm'],1,3a0aad1d7462d6225fd183e079b37d6c4333f1b4,dnm,,,0,0
openstack%2Ftacker~master~I71b333dc05f2195dacb478f3f0bc442dac9c5691,openstack/tacker,master,I71b333dc05f2195dacb478f3f0bc442dac9c5691,Fix `ProblemDetails.detail` from `.details`,MERGED,2020-12-03 00:19:44.000000000,2020-12-03 13:12:23.000000000,2020-12-03 13:10:51.000000000,"[{'_account_id': 17255}, {'_account_id': 22348}, {'_account_id': 25701}, {'_account_id': 26222}, {'_account_id': 27880}, {'_account_id': 31730}, {'_account_id': 31821}, {'_account_id': 32102}]","[{'number': 1, 'created': '2020-12-03 00:19:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tacker/commit/206d9718db984cde78e1f5bb7c5031884000e411', 'message': ""Field name `details` is used in ProblemDetails Object, but it should be `detail`.\nThis field missmatch cause NotImplemntError when failing to instantiate VNF.\n\nThis patch fixes the filed 'details' to 'detail' in ProblemDetails Object.\n\nCloses-Bug: 1905680\nChange-Id: I71b333dc05f2195dacb478f3f0bc442dac9c5691\n""}, {'number': 2, 'created': '2020-12-03 05:25:02.000000000', 'files': ['tacker/conductor/conductor_server.py'], 'web_link': 'https://opendev.org/openstack/tacker/commit/8c6a1cb179608d02bc4b7b82c6147dd92e0676e0', 'message': ""Fix `ProblemDetails.detail` from `.details`\n\nField name `details` is used in ProblemDetails Object, but\nit should be `detail`. This field missmatch cause\nNotImplemntError when failing to instantiate VNF.\n\nThis patch fixes the filed 'details' to 'detail' in\nProblemDetails Object.\n\nCloses-Bug: 1905680\nChange-Id: I71b333dc05f2195dacb478f3f0bc442dac9c5691\n""}]",0,765222,8c6a1cb179608d02bc4b7b82c6147dd92e0676e0,14,8,2,32707,,,0,"Fix `ProblemDetails.detail` from `.details`

Field name `details` is used in ProblemDetails Object, but
it should be `detail`. This field missmatch cause
NotImplemntError when failing to instantiate VNF.

This patch fixes the filed 'details' to 'detail' in
ProblemDetails Object.

Closes-Bug: 1905680
Change-Id: I71b333dc05f2195dacb478f3f0bc442dac9c5691
",git fetch https://review.opendev.org/openstack/tacker refs/changes/22/765222/2 && git format-patch -1 --stdout FETCH_HEAD,['tacker/conductor/conductor_server.py'],1,206d9718db984cde78e1f5bb7c5031884000e411,bug/1905680, detail=error, details=error,1,1
openstack%2Fopenstack-ansible-os_neutron~master~Id4d7c4527bdcecd63b6cf86e64fe131c439ccec1,openstack/openstack-ansible-os_neutron,master,Id4d7c4527bdcecd63b6cf86e64fe131c439ccec1,Updated from OpenStack Ansible Tests,MERGED,2020-10-19 09:20:36.000000000,2020-12-03 12:46:26.000000000,2020-12-03 12:45:06.000000000,"[{'_account_id': 22348}, {'_account_id': 25023}, {'_account_id': 28619}, {'_account_id': 31542}]","[{'number': 1, 'created': '2020-10-19 09:20:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_neutron/commit/24d07f05d66ca5d0ba32c57e4f78fcc75338ceb9', 'message': 'Updated from OpenStack Ansible Tests\n\nChange-Id: Id4d7c4527bdcecd63b6cf86e64fe131c439ccec1\n'}, {'number': 2, 'created': '2020-11-24 09:15:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_neutron/commit/3d7aa53ee3f574833273ebf6bf772d81d9bd66d9', 'message': 'Updated from OpenStack Ansible Tests\n\nChange-Id: Id4d7c4527bdcecd63b6cf86e64fe131c439ccec1\n'}, {'number': 3, 'created': '2020-11-25 13:21:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_neutron/commit/5ea224c20a1106414fc9754461fe6ed7ea6c0bb9', 'message': 'Updated from OpenStack Ansible Tests\n\nChange-Id: Id4d7c4527bdcecd63b6cf86e64fe131c439ccec1\n'}, {'number': 4, 'created': '2020-11-30 20:27:41.000000000', 'files': ['tasks/service_setup.yml'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_neutron/commit/ca7a48c2a9d9b64947aa24a63818773aa4253350', 'message': 'Updated from OpenStack Ansible Tests\n\nDepends-On: Ice2bd1408f65ff4979c9c5244f0ca026e8c246e4\nChange-Id: Id4d7c4527bdcecd63b6cf86e64fe131c439ccec1\n'}]",0,758751,ca7a48c2a9d9b64947aa24a63818773aa4253350,52,4,4,11131,,,0,"Updated from OpenStack Ansible Tests

Depends-On: Ice2bd1408f65ff4979c9c5244f0ca026e8c246e4
Change-Id: Id4d7c4527bdcecd63b6cf86e64fe131c439ccec1
",git fetch https://review.opendev.org/openstack/openstack-ansible-os_neutron refs/changes/51/758751/4 && git format-patch -1 --stdout FETCH_HEAD,['tasks/service_setup.yml'],1,24d07f05d66ca5d0ba32c57e4f78fcc75338ceb9,openstack/openstack-ansible-tests/sync-tests, openstack.cloud.identity_domain: openstack.cloud.project: openstack.cloud.catalog_service: openstack.cloud.identity_role: openstack.cloud.identity_user: openstack.cloud.role_assignment: openstack.cloud.endpoint:, openstack.cloud.os_keystone_domain: openstack.cloud.os_project: openstack.cloud.os_keystone_service: openstack.cloud.os_keystone_role: openstack.cloud.os_user: openstack.cloud.os_user_role: openstack.cloud.os_keystone_endpoint:,7,7
openstack%2Frequirements~master~I43fb7f7c192b860fbf07ba535b1189a4b436f0c7,openstack/requirements,master,I43fb7f7c192b860fbf07ba535b1189a4b436f0c7,update constraint for mistral-lib to new release 2.4.0,MERGED,2020-12-02 10:46:16.000000000,2020-12-03 12:29:35.000000000,2020-12-03 12:27:20.000000000,"[{'_account_id': 14288}, {'_account_id': 22348}, {'_account_id': 28522}]","[{'number': 1, 'created': '2020-12-02 10:46:16.000000000', 'files': ['upper-constraints.txt'], 'web_link': 'https://opendev.org/openstack/requirements/commit/7355da19c0a1168d9c0319ec36d1d7c04fa09eec', 'message': 'update constraint for mistral-lib to new release 2.4.0\n\nmeta: version: 2.4.0\nmeta: diff-start: -\nmeta: series: wallaby\nmeta: release-type: release\nmeta: pypi: yes\nmeta: first: yes\nmeta: release:Author: Herv Beraud <hberaud@redhat.com>\nmeta: release:Commit: Herv Beraud <hberaud@redhat.com>\nmeta: release:Change-Id: Iebd9f6116b7fdd1d0c61a1d442203b87decf00ce\nmeta: release:Code-Review+2: Sean McGinnis <sean.mcginnis@gmail.com>\nmeta: release:Code-Review+2: Herv Beraud <hberaud@redhat.com>\nmeta: release:Workflow+1: Herv Beraud <hberaud@redhat.com>\nChange-Id: I43fb7f7c192b860fbf07ba535b1189a4b436f0c7\n'}]",0,765104,7355da19c0a1168d9c0319ec36d1d7c04fa09eec,14,3,1,11131,,,0,"update constraint for mistral-lib to new release 2.4.0

meta: version: 2.4.0
meta: diff-start: -
meta: series: wallaby
meta: release-type: release
meta: pypi: yes
meta: first: yes
meta: release:Author: Herv Beraud <hberaud@redhat.com>
meta: release:Commit: Herv Beraud <hberaud@redhat.com>
meta: release:Change-Id: Iebd9f6116b7fdd1d0c61a1d442203b87decf00ce
meta: release:Code-Review+2: Sean McGinnis <sean.mcginnis@gmail.com>
meta: release:Code-Review+2: Herv Beraud <hberaud@redhat.com>
meta: release:Workflow+1: Herv Beraud <hberaud@redhat.com>
Change-Id: I43fb7f7c192b860fbf07ba535b1189a4b436f0c7
",git fetch https://review.opendev.org/openstack/requirements refs/changes/04/765104/1 && git format-patch -1 --stdout FETCH_HEAD,['upper-constraints.txt'],1,7355da19c0a1168d9c0319ec36d1d7c04fa09eec,new-release,mistral-lib===2.4.0,mistral-lib===2.3.0,1,1
openstack%2Frequirements~master~I4d2dcbc6dc47773129026a9f718b1c0196d0ce88,openstack/requirements,master,I4d2dcbc6dc47773129026a9f718b1c0196d0ce88,update constraint for python-vitrageclient to new release 4.2.0,MERGED,2020-12-02 10:46:29.000000000,2020-12-03 12:23:11.000000000,2020-12-03 12:21:24.000000000,"[{'_account_id': 14288}, {'_account_id': 22348}, {'_account_id': 28522}]","[{'number': 1, 'created': '2020-12-02 10:46:29.000000000', 'files': ['upper-constraints.txt'], 'web_link': 'https://opendev.org/openstack/requirements/commit/0a95c5e84d08452578283fb2fbde9a9cab6e9d9b', 'message': 'update constraint for python-vitrageclient to new release 4.2.0\n\nmeta: version: 4.2.0\nmeta: diff-start: -\nmeta: series: wallaby\nmeta: release-type: release\nmeta: pypi: yes\nmeta: first: yes\nmeta: release:Author: Herv Beraud <hberaud@redhat.com>\nmeta: release:Commit: Herv Beraud <hberaud@redhat.com>\nmeta: release:Change-Id: I39c87eec9a1f52adb97a0e844b952dfee356b014\nmeta: release:Code-Review+1: Eyal <eyal.bar-ilan@nokia.com>\nmeta: release:Code-Review+2: Herv Beraud <hberaud@redhat.com>\nmeta: release:Code-Review+2: Thierry Carrez <thierry@openstack.org>\nmeta: release:Workflow+1: Thierry Carrez <thierry@openstack.org>\nChange-Id: I4d2dcbc6dc47773129026a9f718b1c0196d0ce88\n'}]",0,765106,0a95c5e84d08452578283fb2fbde9a9cab6e9d9b,14,3,1,11131,,,0,"update constraint for python-vitrageclient to new release 4.2.0

meta: version: 4.2.0
meta: diff-start: -
meta: series: wallaby
meta: release-type: release
meta: pypi: yes
meta: first: yes
meta: release:Author: Herv Beraud <hberaud@redhat.com>
meta: release:Commit: Herv Beraud <hberaud@redhat.com>
meta: release:Change-Id: I39c87eec9a1f52adb97a0e844b952dfee356b014
meta: release:Code-Review+1: Eyal <eyal.bar-ilan@nokia.com>
meta: release:Code-Review+2: Herv Beraud <hberaud@redhat.com>
meta: release:Code-Review+2: Thierry Carrez <thierry@openstack.org>
meta: release:Workflow+1: Thierry Carrez <thierry@openstack.org>
Change-Id: I4d2dcbc6dc47773129026a9f718b1c0196d0ce88
",git fetch https://review.opendev.org/openstack/requirements refs/changes/06/765106/1 && git format-patch -1 --stdout FETCH_HEAD,['upper-constraints.txt'],1,0a95c5e84d08452578283fb2fbde9a9cab6e9d9b,new-release,python-vitrageclient===4.2.0,python-vitrageclient===4.1.1,1,1
openstack%2Ftripleo-quickstart~master~I04100ba2c3cee861aaebda5121375f34242c8e92,openstack/tripleo-quickstart,master,I04100ba2c3cee861aaebda5121375f34242c8e92,Modify 2ctlr for multiple overclouds ci job ,MERGED,2020-11-03 07:01:03.000000000,2020-12-03 12:00:27.000000000,2020-12-03 11:58:19.000000000,"[{'_account_id': 9976}, {'_account_id': 12393}, {'_account_id': 13861}, {'_account_id': 18846}, {'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2020-11-03 07:01:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-quickstart/commit/c7b5395dec7a31c3341c54960642d0b018305b90', 'message': '[wip] Test installing older openjdk package\n\nWith this patch we trying to install older openjdk package\nto avoid bug/1902478\n\nChange-Id: I04100ba2c3cee861aaebda5121375f34242c8e92\n'}, {'number': 2, 'created': '2020-11-26 09:56:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-quickstart/commit/c70254190c6c2c90c81d3e4ea19f1973af914f28', 'message': '[dnm] test patch remove overcloud name hardcoding\n\n\nChange-Id: I04100ba2c3cee861aaebda5121375f34242c8e92\n'}, {'number': 3, 'created': '2020-11-26 09:56:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-quickstart/commit/2be9590913164aae42ef6bac656565d1261945b5', 'message': '[dnm] test patch remove overcloud name hardcoding\n\n\nChange-Id: I04100ba2c3cee861aaebda5121375f34242c8e92\n'}, {'number': 4, 'created': '2020-11-26 10:04:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-quickstart/commit/f545c970aa63f2ddbb465f5764975a6e7c72a704', 'message': '[dnm] test patch remove overcloud name hardcoding\n\nChange-Id: I04100ba2c3cee861aaebda5121375f34242c8e92\n'}, {'number': 5, 'created': '2020-11-29 12:05:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-quickstart/commit/e03c914c2236d3bd62d332f1f53aa5f29be48936', 'message': '[dnm] test 2ctlr nodeset\n\nChange-Id: I04100ba2c3cee861aaebda5121375f34242c8e92\n'}, {'number': 6, 'created': '2020-11-30 04:46:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-quickstart/commit/1c4050b803b8e1f7b999e4d603c9a4efff3d6c24', 'message': '[dnm] test 2ctlr nodeset\n\nChange-Id: I04100ba2c3cee861aaebda5121375f34242c8e92\n'}, {'number': 7, 'created': '2020-12-01 13:10:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-quickstart/commit/d61b03c5331b8d06153e9391e8e956cb0c9aa51a', 'message': 'Modify 2ctlr for multiple overclouds ci job \n\n2ctlr nodes is currently not utilized by any ci job[1], With this patch\nwe are modifying 2ctlr for a new ci job which test multiple overcloud \nstacks deployment using a single undercloud.\n\ncontrol_0 will be utilized by first overcloud stack and control_1 will be\nutilized by second overcloud stack.\n\n[1] https://codesearch.opendev.org/?q=2ctlr&i=nope&files=&excludeFiles=&repos=\n\nChange-Id: I04100ba2c3cee861aaebda5121375f34242c8e92\n'}, {'number': 8, 'created': '2020-12-01 13:10:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-quickstart/commit/867e079ae33f70dc1ed37a954b85a6b1b1eafbbd', 'message': 'Modify 2ctlr for multiple overclouds ci job \n\n2ctlr nodes is currently not utilized by any ci job[1], With this patch\nwe are modifying 2ctlr for a new ci job which test multiple overcloud \nstacks deployment using a single undercloud.\n\ncontrol_0 will be utilized by first overcloud stack and control_1 will be\nutilized by second overcloud stack.\n\n[1] https://codesearch.opendev.org/?q=2ctlr&i=nope&files=&excludeFiles=&repos=\n\nChange-Id: I04100ba2c3cee861aaebda5121375f34242c8e92\n'}, {'number': 9, 'created': '2020-12-01 13:11:14.000000000', 'files': ['config/nodes/2ctlr.yml'], 'web_link': 'https://opendev.org/openstack/tripleo-quickstart/commit/3c92ce31334f14236c4c2158dc9599576c4855b3', 'message': 'Modify 2ctlr for multiple overclouds ci job \n\n2ctlr nodes is currently not utilized by any ci job[1], With this patch\nwe are modifying 2ctlr for a new ci job which test multiple overcloud \nstacks deployment using a single undercloud.\n\ncontrol_0 will be utilized by first overcloud stack and control_1 will\nbe utilized by second overcloud stack.\n\n[1] https://codesearch.opendev.org/?q=2ctlr&i=nope&files=&excludeFiles=&repos=\n\nChange-Id: I04100ba2c3cee861aaebda5121375f34242c8e92\n'}]",1,761061,3c92ce31334f14236c4c2158dc9599576c4855b3,31,6,9,29775,,,0,"Modify 2ctlr for multiple overclouds ci job 

2ctlr nodes is currently not utilized by any ci job[1], With this patch
we are modifying 2ctlr for a new ci job which test multiple overcloud 
stacks deployment using a single undercloud.

control_0 will be utilized by first overcloud stack and control_1 will
be utilized by second overcloud stack.

[1] https://codesearch.opendev.org/?q=2ctlr&i=nope&files=&excludeFiles=&repos=

Change-Id: I04100ba2c3cee861aaebda5121375f34242c8e92
",git fetch https://review.opendev.org/openstack/tripleo-quickstart refs/changes/61/761061/7 && git format-patch -1 --stdout FETCH_HEAD,"['zuul.d/layout.yaml', 'config/release/tripleo-ci/CentOS-8/master.yml']",2,c7b5395dec7a31c3341c54960642d0b018305b90,multiple_overcloud_stacks, exclude: - java-1.8.0-openjdk-*272*,,2,21
openstack%2Ftripleo-heat-templates~master~I973e1364e5f3d0e03658acdd37e316a59504825e,openstack/tripleo-heat-templates,master,I973e1364e5f3d0e03658acdd37e316a59504825e,Adding Ceph Dashboard to the Edge roles,MERGED,2020-11-04 16:01:21.000000000,2020-12-03 11:58:26.000000000,2020-12-03 11:58:26.000000000,"[{'_account_id': 3153}, {'_account_id': 6796}, {'_account_id': 14985}, {'_account_id': 18002}, {'_account_id': 21129}, {'_account_id': 22348}, {'_account_id': 23181}, {'_account_id': 25402}]","[{'number': 1, 'created': '2020-11-04 16:01:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/6ab6544e0cd3895b33496be3123d47b69d571bb8', 'message': 'WIP -  Adding Ceph Dashboard to the Edge roles\n\nChange-Id: I973e1364e5f3d0e03658acdd37e316a59504825e\n'}, {'number': 2, 'created': '2020-11-12 12:55:51.000000000', 'files': ['roles/DistributedComputeHCI.yaml', 'roles/DistributedComputeHCIDashboard.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/0b41751786e8c170afa73ec17853dc4a77f0b38d', 'message': 'Adding Ceph Dashboard to the Edge roles\n\nThis change adds the CephGrafana Service for the\nEdge roles.\nAlso, a new DistributedComputeHCIDashboard is\nintroduced: the purpose of this role is to support\nthe StorageDashboard network on the edge site when\nthat network is defined and used in central site.\n\nChange-Id: I973e1364e5f3d0e03658acdd37e316a59504825e\n'}]",2,761437,0b41751786e8c170afa73ec17853dc4a77f0b38d,27,8,2,25402,,,0,"Adding Ceph Dashboard to the Edge roles

This change adds the CephGrafana Service for the
Edge roles.
Also, a new DistributedComputeHCIDashboard is
introduced: the purpose of this role is to support
the StorageDashboard network on the edge site when
that network is defined and used in central site.

Change-Id: I973e1364e5f3d0e03658acdd37e316a59504825e
",git fetch https://review.opendev.org/openstack/tripleo-heat-templates refs/changes/37/761437/2 && git format-patch -1 --stdout FETCH_HEAD,['roles/DistributedComputeHCI.yaml'],1,6ab6544e0cd3895b33496be3123d47b69d571bb8,, - OS::TripleO::Services::CephGrafana,,1,0
openstack%2Ftripleo-heat-templates~stable%2Fussuri~If81477ad2c6048b7103810e519083a0870897fa3,openstack/tripleo-heat-templates,stable/ussuri,If81477ad2c6048b7103810e519083a0870897fa3,Refresh ceph-ansible group_vars values,MERGED,2020-11-20 13:28:54.000000000,2020-12-03 11:43:09.000000000,2020-12-03 11:43:09.000000000,"[{'_account_id': 6796}, {'_account_id': 14985}, {'_account_id': 18002}, {'_account_id': 22348}, {'_account_id': 22865}, {'_account_id': 23181}]","[{'number': 1, 'created': '2020-11-20 13:28:54.000000000', 'files': ['deployment/ceph-ansible/ceph-rgw.yaml', 'deployment/ceph-ansible/ceph-base.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/23718b21c886237647604bd1027f4c6769268d89', 'message': 'Refresh ceph-ansible group_vars values\n\nThe purpose of this change is having a mechanism to refresh the\nceph-ansible group_vars/ when a Ceph related service, that defines a\nspecific set of variables, is included in the overcloud.\n\nFor this reason, this patch:\n\n1. Adds the ""prepare"" tasks (including tripleo-ceph-work-dir) at the\n   beginning of Step2. By doing this we can make sure that all the\n   variables needed by ceph-ansible are properly collected at Step1,\n   and persisted (in group_vars/*) at Step2, before the ceph-ansible\n   playbook execution.\n   This approach is valid for all the services that define additional\n   ConfigOverrides variables\n\n2. Removes the ""prepare"" (including tripleo-ceph-work-dir) in the rgw\n   service: having the ""prepare"" tasks included ""per role"" creates the\n   risk of executing it multiple times.\n   For example, including ""prepare"" in clients and rgw results in three\n   execution of the same thing!\n   Adding it at the beginning of Step 2 ensures that it\'s executed at\n   least two times.\n\nChange-Id: If81477ad2c6048b7103810e519083a0870897fa3\n(cherry picked from commit 1fafca733c995dc835cbe040c12d766e8ac02cd4)\n'}]",1,763558,23718b21c886237647604bd1027f4c6769268d89,16,6,1,25402,,,0,"Refresh ceph-ansible group_vars values

The purpose of this change is having a mechanism to refresh the
ceph-ansible group_vars/ when a Ceph related service, that defines a
specific set of variables, is included in the overcloud.

For this reason, this patch:

1. Adds the ""prepare"" tasks (including tripleo-ceph-work-dir) at the
   beginning of Step2. By doing this we can make sure that all the
   variables needed by ceph-ansible are properly collected at Step1,
   and persisted (in group_vars/*) at Step2, before the ceph-ansible
   playbook execution.
   This approach is valid for all the services that define additional
   ConfigOverrides variables

2. Removes the ""prepare"" (including tripleo-ceph-work-dir) in the rgw
   service: having the ""prepare"" tasks included ""per role"" creates the
   risk of executing it multiple times.
   For example, including ""prepare"" in clients and rgw results in three
   execution of the same thing!
   Adding it at the beginning of Step 2 ensures that it's executed at
   least two times.

Change-Id: If81477ad2c6048b7103810e519083a0870897fa3
(cherry picked from commit 1fafca733c995dc835cbe040c12d766e8ac02cd4)
",git fetch https://review.opendev.org/openstack/tripleo-heat-templates refs/changes/58/763558/1 && git format-patch -1 --stdout FETCH_HEAD,"['deployment/ceph-ansible/ceph-base.yaml', 'deployment/ceph-ansible/ceph-rgw.yaml']",2,23718b21c886237647604bd1027f4c6769268d89,,, - name: create ceph-ansible working directory include_role: name: tripleo_ceph_work_dir tasks_from: prepare,4,4
openstack%2Fkolla-ansible~master~I0caceecc487e160ec65060b26c15a83ab98d4fd0,openstack/kolla-ansible,master,I0caceecc487e160ec65060b26c15a83ab98d4fd0,Add prometheus node-exporter support collect systemd,ABANDONED,2020-10-31 06:56:57.000000000,2020-12-03 11:25:48.000000000,,[{'_account_id': 22348}],"[{'number': 1, 'created': '2020-10-31 06:56:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/59aadf429ec133fd2c82d49b89296350e247f1f1', 'message': 'Add prometheus node-exporter support collect systemd\n\nChange-Id: I0caceecc487e160ec65060b26c15a83ab98d4fd0\n'}, {'number': 2, 'created': '2020-10-31 06:58:49.000000000', 'files': ['releasenotes/notes/add-prometheus-node-exporter-support-systemd-8847d265b4f92838.yaml', 'ansible/roles/prometheus/templates/prometheus-node-exporter.json.j2', 'ansible/roles/prometheus/defaults/main.yml'], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/bd87f1db32954162d8de748403e42e2d0e49179c', 'message': 'Add prometheus node-exporter support collect systemd\n\nChange-Id: I0caceecc487e160ec65060b26c15a83ab98d4fd0\n'}]",0,760682,bd87f1db32954162d8de748403e42e2d0e49179c,5,1,2,31310,,,0,"Add prometheus node-exporter support collect systemd

Change-Id: I0caceecc487e160ec65060b26c15a83ab98d4fd0
",git fetch https://review.opendev.org/openstack/kolla-ansible refs/changes/82/760682/2 && git format-patch -1 --stdout FETCH_HEAD,"['ansible/roles/prometheus/templates/prometheus-node-exporter.json.j2', 'ansible/roles/prometheus/defaults/main.yml']",2,59aadf429ec133fd2c82d49b89296350e247f1f1,prometheus_node_exporter_systemd," - ""/run/dbus/system_bus_socket:/var/run/dbus/system_bus_socket""",,2,1
openstack%2Fdesignate-dashboard~master~I97e34dd80743ff387e230b226394489f0ede812e,openstack/designate-dashboard,master,I97e34dd80743ff387e230b226394489f0ede812e,Add default index URL to resource modules,MERGED,2020-11-30 21:47:05.000000000,2020-12-03 11:08:39.000000000,2020-12-03 11:07:08.000000000,"[{'_account_id': 19298}, {'_account_id': 22348}, {'_account_id': 29313}]","[{'number': 1, 'created': '2020-11-30 21:47:05.000000000', 'files': ['designatedashboard/static/designatedashboard/resources/os-designate-zone/os-designate-zone.module.js', 'designatedashboard/static/designatedashboard/resources/os-designate-floatingip/os-designate-floatingip.module.js', 'designatedashboard/static/designatedashboard/resources/os-designate-recordset/os-designate-recordset.module.js'], 'web_link': 'https://opendev.org/openstack/designate-dashboard/commit/0fb4e2e99e4dbf2859790d4a627c04f136a0bafc', 'message': 'Add default index URL to resource modules\n\nDefault Index Url is missing for resource modules which causes\nimproper redirect to details page opened in a new tab.\n\nCloses-Bug: #1905707\nChange-Id: I97e34dd80743ff387e230b226394489f0ede812e\n'}]",0,764829,0fb4e2e99e4dbf2859790d4a627c04f136a0bafc,8,3,1,6914,,,0,"Add default index URL to resource modules

Default Index Url is missing for resource modules which causes
improper redirect to details page opened in a new tab.

Closes-Bug: #1905707
Change-Id: I97e34dd80743ff387e230b226394489f0ede812e
",git fetch https://review.opendev.org/openstack/designate-dashboard refs/changes/29/764829/1 && git format-patch -1 --stdout FETCH_HEAD,"['designatedashboard/static/designatedashboard/resources/os-designate-zone/os-designate-zone.module.js', 'designatedashboard/static/designatedashboard/resources/os-designate-floatingip/os-designate-floatingip.module.js', 'designatedashboard/static/designatedashboard/resources/os-designate-recordset/os-designate-recordset.module.js']",3,0fb4e2e99e4dbf2859790d4a627c04f136a0bafc,bug/1905707, .setDefaultIndexUrl('/resources/recordsets/'),,3,0
openstack%2Faodh~master~Iecaf623e413c514d0a7cf42557576fa0e6fd4ba1,openstack/aodh,master,Iecaf623e413c514d0a7cf42557576fa0e6fd4ba1,Fix pygments style,MERGED,2020-05-20 00:48:36.000000000,2020-12-03 10:53:19.000000000,2020-12-03 10:51:41.000000000,"[{'_account_id': 4264}, {'_account_id': 22348}]","[{'number': 1, 'created': '2020-05-20 00:48:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/aodh/commit/6e944a25343e7e5b79f0b7ad24532661348bc75d', 'message': 'Fix pygments style\n\nChange-Id: Iecaf623e413c514d0a7cf42557576fa0e6fd4ba1\n'}, {'number': 2, 'created': '2020-05-20 00:55:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/aodh/commit/438a22abf505dbd563ff44ffc71aa5dc3a965311', 'message': 'Fix pygments style\n\nNew theme of docs (Victoria+) respects pygments_style.\nSince we starts using Victoria reqs while being on Ussuri,\nthis patch ensures proper rendering both in Ussuri and Victoria.\n\nChange-Id: Iecaf623e413c514d0a7cf42557576fa0e6fd4ba1\n'}, {'number': 3, 'created': '2020-05-21 01:22:08.000000000', 'files': ['doc/source/conf.py', 'releasenotes/source/conf.py'], 'web_link': 'https://opendev.org/openstack/aodh/commit/31777297e905399fbbd1f401b956dc7120c15f3c', 'message': 'Fix pygments style\n\nNew theme of docs respects pygments_style.\n\nmore info: http://lists.openstack.org/pipermail/openstack-discuss/2020-May/014971.html\n\nChange-Id: Iecaf623e413c514d0a7cf42557576fa0e6fd4ba1\n'}]",0,729451,31777297e905399fbbd1f401b956dc7120c15f3c,11,2,3,30356,,,0,"Fix pygments style

New theme of docs respects pygments_style.

more info: http://lists.openstack.org/pipermail/openstack-discuss/2020-May/014971.html

Change-Id: Iecaf623e413c514d0a7cf42557576fa0e6fd4ba1
",git fetch https://review.opendev.org/openstack/aodh refs/changes/51/729451/1 && git format-patch -1 --stdout FETCH_HEAD,"['doc/source/conf.py', 'releasenotes/source/conf.py']",2,6e944a25343e7e5b79f0b7ad24532661348bc75d,,pygments_style = 'native',pygments_style = 'sphinx',2,2
openstack%2Ftripleo-heat-templates~master~I354bb6a13ac4d53c75aa22a39b1977a0074466ad,openstack/tripleo-heat-templates,master,I354bb6a13ac4d53c75aa22a39b1977a0074466ad,OvS HW Offload support for FFU with leapp,ABANDONED,2020-08-19 07:01:55.000000000,2020-12-03 10:46:37.000000000,,"[{'_account_id': 18575}, {'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2020-08-19 07:01:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/022b6a6a6b76f6882e0436c2a7aa96bb148fdac4', 'message': 'WIP: OvS Offload support with FFU with leapp\n\nChange-Id: I354bb6a13ac4d53c75aa22a39b1977a0074466ad\n'}, {'number': 2, 'created': '2020-11-11 10:18:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/3086174a7fc95b22e9d9a1a7861d3a238fd6e61c', 'message': 'WIP: OvS Offload support with FFU with leapp\n\nChange-Id: I354bb6a13ac4d53c75aa22a39b1977a0074466ad\n'}, {'number': 3, 'created': '2020-11-18 08:54:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/6041a572129f0801ed386d6ac57ffa5109e6d28e', 'message': 'WIP: OvS HW Offload support with FFU with leapp\n\nOn leapp upgrade (7 to 8), the os-net-config package\nwill not be present initiall on rhel8, which contins the\nexecutable os-net-config-sriov. This executable is used\nby sriov_config.service on each reboot to configure the\nVFs and switchdev mode based on stored configuration.\nSince this executable is not available, sriov_config\nservice will fail to setup VFs.\n\nRemove the sriov_config service explicitly\n\nChange-Id: I354bb6a13ac4d53c75aa22a39b1977a0074466ad\n'}, {'number': 4, 'created': '2020-11-25 08:40:51.000000000', 'files': ['deployment/neutron/neutron-ovs-agent-container-puppet.yaml', 'deployment/neutron/neutron-sriov-agent-container-puppet.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/373992a4af3475c6b1c91ec06b33c8c40b0ec1c4', 'message': 'OvS HW Offload support for FFU with leapp\n\nOn leapp upgrade (7 to 8), the os-net-config package\nwill not be present initiall on rhel8, which contains the\nexecutable os-net-config-sriov. This executable is used\nby sriov_config.service on each reboot to configure the\nVFs and switchdev mode based on stored configuration.\nSince this executable is not available, sriov_config\nservice will fail to setup VFs.\n\nRemove sriov_config service explicitly as it will fail\non reboot and remove all the VFs (as leapp will fail\nif upgraded with VF). This tasks will be performed\nbefore starting leapp upgrade and after upgrade\nos-net-config run (with --no-activate) will configure\nthe service and VFs as per the existing configuration.\n\nChange-Id: I354bb6a13ac4d53c75aa22a39b1977a0074466ad\n'}]",0,746843,373992a4af3475c6b1c91ec06b33c8c40b0ec1c4,16,3,4,18575,,,0,"OvS HW Offload support for FFU with leapp

On leapp upgrade (7 to 8), the os-net-config package
will not be present initiall on rhel8, which contains the
executable os-net-config-sriov. This executable is used
by sriov_config.service on each reboot to configure the
VFs and switchdev mode based on stored configuration.
Since this executable is not available, sriov_config
service will fail to setup VFs.

Remove sriov_config service explicitly as it will fail
on reboot and remove all the VFs (as leapp will fail
if upgraded with VF). This tasks will be performed
before starting leapp upgrade and after upgrade
os-net-config run (with --no-activate) will configure
the service and VFs as per the existing configuration.

Change-Id: I354bb6a13ac4d53c75aa22a39b1977a0074466ad
",git fetch https://review.opendev.org/openstack/tripleo-heat-templates refs/changes/43/746843/1 && git format-patch -1 --stdout FETCH_HEAD,"['deployment/neutron/neutron-ovs-agent-container-puppet.yaml', 'deployment/neutron/neutron-sriov-agent-container-puppet.yaml']",2,022b6a6a6b76f6882e0436c2a7aa96bb148fdac4,ffu_offload, when: sriov_config_remove_result is changed, when: sriov_config_remove_result['changed'],36,1
openstack%2Fpuppet-openstack-integration~master~Ie25a35422a0ca5e00d2085bf37e521106b2c11c2,openstack/puppet-openstack-integration,master,Ie25a35422a0ca5e00d2085bf37e521106b2c11c2,Handle opendev.org sources in copy_logs.sh,MERGED,2020-12-02 13:15:36.000000000,2020-12-03 10:32:42.000000000,2020-12-03 10:32:42.000000000,"[{'_account_id': 16137}, {'_account_id': 16312}, {'_account_id': 22348}]","[{'number': 1, 'created': '2020-12-02 13:15:36.000000000', 'files': ['copy_logs.sh'], 'web_link': 'https://opendev.org/openstack/puppet-openstack-integration/commit/7be46c1a525f9ac48e554d693803033de19cea63', 'message': ""Handle opendev.org sources in copy_logs.sh\n\n[1] updated sources to use opendev.org instead of\ngithub.com, let's handle opendev.org sources too\nin copy_logs.sh. Without this services logs are not\ncollected.\n\n[1] https://review.opendev.org/q/topic:fix-source-metadata\n\nChange-Id: Ie25a35422a0ca5e00d2085bf37e521106b2c11c2\n""}]",0,765135,7be46c1a525f9ac48e554d693803033de19cea63,10,3,1,13861,,,0,"Handle opendev.org sources in copy_logs.sh

[1] updated sources to use opendev.org instead of
github.com, let's handle opendev.org sources too
in copy_logs.sh. Without this services logs are not
collected.

[1] https://review.opendev.org/q/topic:fix-source-metadata

Change-Id: Ie25a35422a0ca5e00d2085bf37e521106b2c11c2
",git fetch https://review.opendev.org/openstack/puppet-openstack-integration refs/changes/35/765135/1 && git format-patch -1 --stdout FETCH_HEAD,['copy_logs.sh'],1,7be46c1a525f9ac48e554d693803033de19cea63,," if egrep -q ""(github.com|opendev.org)/(stackforge|openstack)/puppet"" $project/metadata.json; then"," if egrep -q ""github.com/(stackforge|openstack)/puppet"" $project/metadata.json; then",1,1
openstack%2Frequirements~master~I8fb6d76d327fe39101f38833f8653c0280af2a4b,openstack/requirements,master,I8fb6d76d327fe39101f38833f8653c0280af2a4b,update constraint for python-masakariclient to new release 6.2.0,MERGED,2020-12-02 10:43:08.000000000,2020-12-03 10:12:52.000000000,2020-12-03 10:11:23.000000000,"[{'_account_id': 14288}, {'_account_id': 22348}, {'_account_id': 28522}, {'_account_id': 30491}]","[{'number': 1, 'created': '2020-12-02 10:43:08.000000000', 'files': ['upper-constraints.txt'], 'web_link': 'https://opendev.org/openstack/requirements/commit/659488e01d25f5969f16a354c8897c5e417b1b02', 'message': 'update constraint for python-masakariclient to new release 6.2.0\n\nmeta: version: 6.2.0\nmeta: diff-start: -\nmeta: series: wallaby\nmeta: release-type: release\nmeta: pypi: no\nmeta: first: yes\nmeta: release:Author: Herv Beraud <hberaud@redhat.com>\nmeta: release:Commit: Herv Beraud <hberaud@redhat.com>\nmeta: release:Change-Id: I125f0286d21481ea071454ba3fff85ec13ba0451\nmeta: release:Code-Review+1: Radosaw Piliszek <radoslaw.piliszek@gmail.com>\nmeta: release:Code-Review+2: Herv Beraud <hberaud@redhat.com>\nmeta: release:Code-Review+2: Thierry Carrez <thierry@openstack.org>\nmeta: release:Workflow+1: Thierry Carrez <thierry@openstack.org>\nChange-Id: I8fb6d76d327fe39101f38833f8653c0280af2a4b\n'}]",0,765102,659488e01d25f5969f16a354c8897c5e417b1b02,13,4,1,11131,,,0,"update constraint for python-masakariclient to new release 6.2.0

meta: version: 6.2.0
meta: diff-start: -
meta: series: wallaby
meta: release-type: release
meta: pypi: no
meta: first: yes
meta: release:Author: Herv Beraud <hberaud@redhat.com>
meta: release:Commit: Herv Beraud <hberaud@redhat.com>
meta: release:Change-Id: I125f0286d21481ea071454ba3fff85ec13ba0451
meta: release:Code-Review+1: Radosaw Piliszek <radoslaw.piliszek@gmail.com>
meta: release:Code-Review+2: Herv Beraud <hberaud@redhat.com>
meta: release:Code-Review+2: Thierry Carrez <thierry@openstack.org>
meta: release:Workflow+1: Thierry Carrez <thierry@openstack.org>
Change-Id: I8fb6d76d327fe39101f38833f8653c0280af2a4b
",git fetch https://review.opendev.org/openstack/requirements refs/changes/02/765102/1 && git format-patch -1 --stdout FETCH_HEAD,['upper-constraints.txt'],1,659488e01d25f5969f16a354c8897c5e417b1b02,new-release,python-masakariclient===6.2.0,python-masakariclient===6.1.1,1,1
openstack%2Fcharms.openstack~master~I9a7dcc6ad3da8860dc650f956e5c6eec8ff51660,openstack/charms.openstack,master,I9a7dcc6ad3da8860dc650f956e5c6eec8ff51660,Separate pkg version collection from release calc,MERGED,2020-12-03 09:37:22.000000000,2020-12-03 10:10:45.000000000,2020-12-03 10:10:45.000000000,"[{'_account_id': 20870}, {'_account_id': 22348}]","[{'number': 1, 'created': '2020-12-03 09:37:22.000000000', 'files': ['charms_openstack/charm/core.py'], 'web_link': 'https://opendev.org/openstack/charms.openstack/commit/4907569ebc2c71bb065842460778f3146084ed83', 'message': 'Separate pkg version collection from release calc\n\nBreak out the collection of a packages version information from\nderiving the corresponding OpenStack release. This allows the package\nversion code to be used with charms which have their own\nidiosyncratic versioning system.\n\nChange-Id: I9a7dcc6ad3da8860dc650f956e5c6eec8ff51660\n'}]",0,765305,4907569ebc2c71bb065842460778f3146084ed83,6,2,1,12549,,,0,"Separate pkg version collection from release calc

Break out the collection of a packages version information from
deriving the corresponding OpenStack release. This allows the package
version code to be used with charms which have their own
idiosyncratic versioning system.

Change-Id: I9a7dcc6ad3da8860dc650f956e5c6eec8ff51660
",git fetch https://review.opendev.org/openstack/charms.openstack refs/changes/05/765305/1 && git format-patch -1 --stdout FETCH_HEAD,['charms_openstack/charm/core.py'],1,4907569ebc2c71bb065842460778f3146084ed83,refactor-package-version-calc," def get_package_version(package, apt_cache_sufficient=False): """"""Derive OpenStack release codename from a package. :param package: Package name to lookup (ie. in apt cache) :type package: str :param apt_cache_sufficient: When False (the default) version from an installed package will be used, when True version from the systems APT cache will be used. This is useful for subordinate charms who need working release selection prior to package installation and has no way of using fall back to version of a package the principle charm has installed nor package source configuration option. :type apt_cache_sufficient: bool :returns: OpenStack version name corresponding to package :rtype: Optional[str] :raises: AttributeError, ValueError """""" cache = fetch.apt_cache() try: pkg = cache[package] except KeyError: # the package is unknown to the current apt cache. e = ValueError( 'Could not determine version of package with no installation ' 'candidate: {}'.format(package)) raise e if apt_cache_sufficient: vers = fetch.apt_pkg.upstream_version(pkg.version) else: vers = fetch.apt_pkg.upstream_version(pkg.current_ver.ver_str) # x.y match only for 20XX.X # and ignore patch level for other packages match = re.match(r'^(\d+)\.(\d+)', vers) if match: vers = match.group(0) return vers @staticmethod try: vers = BaseOpenStackCharm.get_package_version( package, apt_cache_sufficient=apt_cache_sufficient) # Generate a major version number for newer semantic # versions of openstack projects major_vers = vers.split('.')[0] except Exception: if fatal: raise else:"," cache = fetch.apt_cache() try: pkg = cache[package] except KeyError: if not fatal: # the package is unknown to the current apt cache. e = ValueError( 'Could not determine version of package with no installation ' 'candidate: {}'.format(package)) raise e if apt_cache_sufficient: vers = fetch.apt_pkg.upstream_version(pkg.version) else: if not pkg.current_ver: if not fatal: return None vers = fetch.apt_pkg.upstream_version(pkg.current_ver.ver_str) # x.y match only for 20XX.X # and ignore patch level for other packages match = re.match(r'^(\d+)\.(\d+)', vers) if match: vers = match.group(0) # Generate a major version number for newer semantic # versions of openstack projects major_vers = vers.split('.')[0]",52,29
openstack%2Fkuryr-kubernetes~master~I214c08c197483c00a5caecc47ef117cdd07a7652,openstack/kuryr-kubernetes,master,I214c08c197483c00a5caecc47ef117cdd07a7652,Add urllib3's SSLError to expected Watcher exc,MERGED,2020-12-01 12:18:41.000000000,2020-12-03 10:09:57.000000000,2020-12-03 10:08:40.000000000,"[{'_account_id': 13692}, {'_account_id': 22348}, {'_account_id': 23567}, {'_account_id': 27032}, {'_account_id': 30963}]","[{'number': 1, 'created': '2020-12-01 12:18:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kuryr-kubernetes/commit/2e67cfed68a875ddb66996f3ad6c4c703f5ba366', 'message': ""Add urllib3's SSLError to expected Watcher exc\n\nSeems like new requests lib is somehow raising\nurllib3.exceptions.SSLError more often. This commit adds it to the\nexceptions expected by the Watcher and silenced with a retry.\n\nChange-Id: I214c08c197483c00a5caecc47ef117cdd07a7652\n""}, {'number': 2, 'created': '2020-12-02 10:18:01.000000000', 'files': ['kuryr_kubernetes/k8s_client.py'], 'web_link': 'https://opendev.org/openstack/kuryr-kubernetes/commit/f5e8e9c3b0045ce8e7805500730c0f478d5d21fc', 'message': ""Add urllib3's SSLError to expected Watcher exc\n\nSeems like new requests lib is somehow raising\nurllib3.exceptions.SSLError more often. This commit adds it to the\nexceptions expected by the Watcher and silenced with a retry.\n\nCloses-Bug: 1906498\nChange-Id: I214c08c197483c00a5caecc47ef117cdd07a7652\n""}]",0,764934,f5e8e9c3b0045ce8e7805500730c0f478d5d21fc,16,5,2,11600,,,0,"Add urllib3's SSLError to expected Watcher exc

Seems like new requests lib is somehow raising
urllib3.exceptions.SSLError more often. This commit adds it to the
exceptions expected by the Watcher and silenced with a retry.

Closes-Bug: 1906498
Change-Id: I214c08c197483c00a5caecc47ef117cdd07a7652
",git fetch https://review.opendev.org/openstack/kuryr-kubernetes refs/changes/34/764934/2 && git format-patch -1 --stdout FETCH_HEAD,['kuryr_kubernetes/k8s_client.py'],1,2e67cfed68a875ddb66996f3ad6c4c703f5ba366,hide-ssl-error,"import urllib3 ssl.SSLError, requests.exceptions.ChunkedEncodingError, urllib3.exceptions.SSLError):"," ssl.SSLError, requests.exceptions.ChunkedEncodingError):",3,1
openstack%2Fmasakari~master~I5cbe5609ff3de717b624f89b76d999fb58ce3390,openstack/masakari,master,I5cbe5609ff3de717b624f89b76d999fb58ce3390,Replace deprecated UPPER_CONSTRAINTS_FILE variable,MERGED,2020-12-03 06:34:09.000000000,2020-12-03 09:58:32.000000000,2020-12-03 09:56:31.000000000,"[{'_account_id': 22348}, {'_account_id': 30491}]","[{'number': 1, 'created': '2020-12-03 06:34:09.000000000', 'files': ['tox.ini'], 'web_link': 'https://opendev.org/openstack/masakari/commit/329b9fedd1c6630077bb04196d00b73f5359ead5', 'message': 'Replace deprecated UPPER_CONSTRAINTS_FILE variable\n\nChange-Id: I5cbe5609ff3de717b624f89b76d999fb58ce3390\n'}]",0,765245,329b9fedd1c6630077bb04196d00b73f5359ead5,8,2,1,30384,,,0,"Replace deprecated UPPER_CONSTRAINTS_FILE variable

Change-Id: I5cbe5609ff3de717b624f89b76d999fb58ce3390
",git fetch https://review.opendev.org/openstack/masakari refs/changes/45/765245/1 && git format-patch -1 --stdout FETCH_HEAD,['tox.ini'],1,329b9fedd1c6630077bb04196d00b73f5359ead5,, -c{env:TOX_CONSTRAINTS_FILE:https://releases.openstack.org/constraints/upper/master}, -c{env:UPPER_CONSTRAINTS_FILE:https://releases.openstack.org/constraints/upper/master},1,1
openstack%2Fkolla~master~I68e0cde16bf84ca5743c8c8dd6b6460752587e92,openstack/kolla,master,I68e0cde16bf84ca5743c8c8dd6b6460752587e92,Introduce curl macro - fetch_url,ABANDONED,2020-06-19 17:19:07.000000000,2020-12-03 09:56:09.000000000,,"[{'_account_id': 22348}, {'_account_id': 22629}, {'_account_id': 23181}, {'_account_id': 24072}, {'_account_id': 30491}]","[{'number': 1, 'created': '2020-06-19 17:19:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla/commit/66b9ab4c49e5203431d24f848b1a8fe351ba3782', 'message': 'WIP: Introduce curl macro - fetch_url\n\nChange-Id: I68e0cde16bf84ca5743c8c8dd6b6460752587e92\n'}, {'number': 2, 'created': '2020-06-22 18:09:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla/commit/49f9d27b1e91e6ad5ca384e48fdd047d5eda43f8', 'message': 'WIP: Introduce curl macro - fetch_url\n\nChange-Id: I68e0cde16bf84ca5743c8c8dd6b6460752587e92\n'}, {'number': 3, 'created': '2020-06-23 07:59:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla/commit/e0b0fcade42e36149db4fb9c28723c3a1ee2512d', 'message': 'WIP: Introduce curl macro - fetch_url\n\nChange-Id: I68e0cde16bf84ca5743c8c8dd6b6460752587e92\n'}, {'number': 4, 'created': '2020-06-23 09:49:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla/commit/4740cff46b264d41e134d4f959d8b56e6aab6b1c', 'message': 'WIP: Introduce curl macro - fetch_url\n\nChange-Id: I68e0cde16bf84ca5743c8c8dd6b6460752587e92\n'}, {'number': 5, 'created': '2020-06-25 09:49:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla/commit/7f3aaa0458232990a3af8a53ba2d24767f1ac17a', 'message': 'WIP: Introduce curl macro - fetch_url\n\nChange-Id: I68e0cde16bf84ca5743c8c8dd6b6460752587e92\n'}, {'number': 6, 'created': '2020-07-03 11:15:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla/commit/2b5df23c050b2b4a6f06f873260fb44f99c7c4ff', 'message': 'WIP: Introduce curl macro - fetch_url\n\nChange-Id: I68e0cde16bf84ca5743c8c8dd6b6460752587e92\n'}, {'number': 7, 'created': '2020-11-05 16:39:18.000000000', 'files': ['docker/mariadb/mariadb-clustercheck/Dockerfile.j2', 'docker/monasca/monasca-grafana/Dockerfile.j2', 'docker/zun/zun-cni-daemon/Dockerfile.j2', 'docker/kafka/Dockerfile.j2', 'docker/macros.j2', 'docker/prometheus/prometheus-blackbox-exporter/Dockerfile.j2', 'docker/storm/Dockerfile.j2', 'docker/kolla-toolbox/Dockerfile.j2', 'docker/prometheus/prometheus-haproxy-exporter/Dockerfile.j2', 'docker/prometheus/prometheus-mysqld-exporter/Dockerfile.j2', 'docker/logstash/Dockerfile.j2', 'docker/prometheus/prometheus-node-exporter/Dockerfile.j2', 'docker/zookeeper/Dockerfile.j2', 'docker/prometheus/prometheus-memcached-exporter/Dockerfile.j2', 'docker/prometheus/prometheus-elasticsearch-exporter/Dockerfile.j2', 'docker/prometheus/prometheus-server/Dockerfile.j2', 'docker/prometheus/prometheus-alertmanager/Dockerfile.j2', 'docker/skydive/skydive-base/Dockerfile.j2', 'docker/prometheus/prometheus-cadvisor/Dockerfile.j2', 'docker/base/Dockerfile.j2', 'docker/fluentd/Dockerfile.j2', 'docker/prometheus/prometheus-mtail/Dockerfile.j2', 'docker/prometheus/prometheus-openstack-exporter/Dockerfile.j2'], 'web_link': 'https://opendev.org/openstack/kolla/commit/4c8eb33fd41c2915838c3f33fb71fae814a94a2b', 'message': 'Introduce curl macro - fetch_url\n\nChange-Id: I68e0cde16bf84ca5743c8c8dd6b6460752587e92\n'}]",1,737051,4c8eb33fd41c2915838c3f33fb71fae814a94a2b,30,5,7,22629,,,0,"Introduce curl macro - fetch_url

Change-Id: I68e0cde16bf84ca5743c8c8dd6b6460752587e92
",git fetch https://review.opendev.org/openstack/kolla refs/changes/51/737051/2 && git format-patch -1 --stdout FETCH_HEAD,"['docker/mariadb/mariadb-clustercheck/Dockerfile.j2', 'docker/monasca/monasca-grafana/Dockerfile.j2', 'docker/zun/zun-cni-daemon/Dockerfile.j2', 'docker/kafka/Dockerfile.j2', 'docker/macros.j2', 'docker/prometheus/prometheus-blackbox-exporter/Dockerfile.j2', 'docker/storm/Dockerfile.j2', 'docker/kolla-toolbox/Dockerfile.j2', 'docker/prometheus/prometheus-haproxy-exporter/Dockerfile.j2', 'docker/prometheus/prometheus-mysqld-exporter/Dockerfile.j2', 'docker/logstash/Dockerfile.j2', 'docker/prometheus/prometheus-node-exporter/Dockerfile.j2', 'docker/zookeeper/Dockerfile.j2', 'docker/prometheus/prometheus-memcached-exporter/Dockerfile.j2', 'docker/prometheus/prometheus-elasticsearch-exporter/Dockerfile.j2', 'docker/prometheus/prometheus-server/Dockerfile.j2', 'docker/prometheus/prometheus-alertmanager/Dockerfile.j2', 'docker/skydive/skydive-base/Dockerfile.j2', 'docker/prometheus/prometheus-cadvisor/Dockerfile.j2', 'docker/base/Dockerfile.j2', 'docker/fluentd/Dockerfile.j2', 'docker/prometheus/prometheus-mtail/Dockerfile.j2', 'docker/prometheus/prometheus-openstack-exporter/Dockerfile.j2']",23,66b9ab4c49e5203431d24f848b1a8fe351ba3782,curl_macro,"{{ macros.fetch_url(""https://github.com/openstack-exporter/openstack-exporter/releases/download/v${prometheus_openstack_exporter_version}/openstack-exporter-${prometheus_openstack_exporter_version}.linux-{{debian_arch}}.tar.gz"", ""/tmp/prometheus_openstack_exporter.tar.gz"") }} \",RUN curl -sSL -o /tmp/prometheus_openstack_exporter.tar.gz https://github.com/openstack-exporter/openstack-exporter/releases/download/v${prometheus_openstack_exporter_version}/openstack-exporter-${prometheus_openstack_exporter_version}.linux-{{debian_arch}}.tar.gz \,29,23
openstack%2Fcharm-ceph-osd~master~I4ced679e814c3b58595a9bc123ce0d402b1c1811,openstack/charm-ceph-osd,master,I4ced679e814c3b58595a9bc123ce0d402b1c1811,Sync charm-helpers to pick up the commit: https://github.com/juju/charm-helpers/commit/09208c2a2c691435e178b2b481d043f687b7e61b,MERGED,2020-11-12 14:13:01.000000000,2020-12-03 09:45:11.000000000,2020-12-03 09:45:11.000000000,"[{'_account_id': 14567}, {'_account_id': 20634}, {'_account_id': 20648}, {'_account_id': 22348}, {'_account_id': 32438}]","[{'number': 1, 'created': '2020-11-12 14:13:01.000000000', 'files': ['hooks/charmhelpers/core/host.py'], 'web_link': 'https://opendev.org/openstack/charm-ceph-osd/commit/f749de225d63f4e68d8cd7fc78647a24069d0571', 'message': 'Sync charm-helpers to pick up the commit:\nhttps://github.com/juju/charm-helpers/commit/09208c2a2c691435e178b2b481d043f687b7e61b\n\nChange-Id: I4ced679e814c3b58595a9bc123ce0d402b1c1811\nSigned-off-by: Ponnuvel Palaniyappan <ponnuvel.palaniyappan@canonical.com>\n'}]",0,762523,f749de225d63f4e68d8cd7fc78647a24069d0571,10,5,1,31959,,,0,"Sync charm-helpers to pick up the commit:
https://github.com/juju/charm-helpers/commit/09208c2a2c691435e178b2b481d043f687b7e61b

Change-Id: I4ced679e814c3b58595a9bc123ce0d402b1c1811
Signed-off-by: Ponnuvel Palaniyappan <ponnuvel.palaniyappan@canonical.com>
",git fetch https://review.opendev.org/openstack/charm-ceph-osd refs/changes/23/762523/1 && git format-patch -1 --stdout FETCH_HEAD,['hooks/charmhelpers/core/host.py'],1,f749de225d63f4e68d8cd7fc78647a24069d0571,bug/1898605,"import errno Can be any hash algorithm supported by :mod:`hashlib`, run commands from a specified directory. try: except (IOError, OSError) as e: # Intended to ignore ""file not found"". Catching both to be # compatible with both Python 2.7 and 3.x. if e.errno == errno.ENOENT: pass"," Can be any hash alrgorithm supported by :mod:`hashlib`, run commands from a specificed directory. broken_symlink = os.path.lexists(full) and not os.path.exists(full) if not broken_symlink:",9,4
openstack%2Frequirements~master~Id7e9f5b04a58c323bce22463a465a4001d32e24d,openstack/requirements,master,Id7e9f5b04a58c323bce22463a465a4001d32e24d,update constraint for openstackdocstheme to new release 2.2.7,MERGED,2020-12-02 21:02:09.000000000,2020-12-03 09:43:42.000000000,2020-12-03 09:42:17.000000000,"[{'_account_id': 14288}, {'_account_id': 22348}]","[{'number': 1, 'created': '2020-12-02 21:02:09.000000000', 'files': ['upper-constraints.txt'], 'web_link': 'https://opendev.org/openstack/requirements/commit/b7050412988306ed395051718b5cadf884ae4323', 'message': 'update constraint for openstackdocstheme to new release 2.2.7\n\nmeta: version: 2.2.7\nmeta: diff-start: -\nmeta: series: independent\nmeta: release-type: release\nmeta: pypi: no\nmeta: first: no\nmeta: release:Author: Jeremy Stanley <fungi@yuggoth.org>\nmeta: release:Commit: Jeremy Stanley <fungi@yuggoth.org>\nmeta: release:Change-Id: Ib9affcca4f4ac08118e3de11c52210dd89731966\nmeta: release:Code-Review+2: Sean McGinnis <sean.mcginnis@gmail.com>\nmeta: release:Code-Review+2: Herv Beraud <hberaud@redhat.com>\nmeta: release:Workflow+1: Herv Beraud <hberaud@redhat.com>\nChange-Id: Id7e9f5b04a58c323bce22463a465a4001d32e24d\n'}]",0,765207,b7050412988306ed395051718b5cadf884ae4323,8,2,1,11131,,,0,"update constraint for openstackdocstheme to new release 2.2.7

meta: version: 2.2.7
meta: diff-start: -
meta: series: independent
meta: release-type: release
meta: pypi: no
meta: first: no
meta: release:Author: Jeremy Stanley <fungi@yuggoth.org>
meta: release:Commit: Jeremy Stanley <fungi@yuggoth.org>
meta: release:Change-Id: Ib9affcca4f4ac08118e3de11c52210dd89731966
meta: release:Code-Review+2: Sean McGinnis <sean.mcginnis@gmail.com>
meta: release:Code-Review+2: Herv Beraud <hberaud@redhat.com>
meta: release:Workflow+1: Herv Beraud <hberaud@redhat.com>
Change-Id: Id7e9f5b04a58c323bce22463a465a4001d32e24d
",git fetch https://review.opendev.org/openstack/requirements refs/changes/07/765207/1 && git format-patch -1 --stdout FETCH_HEAD,['upper-constraints.txt'],1,b7050412988306ed395051718b5cadf884ae4323,new-release,openstackdocstheme===2.2.7,openstackdocstheme===2.2.6,1,1
openstack%2Fkuryr-kubernetes~master~Id3149e3ee1899d99a6496b90c28033c930ce8232,openstack/kuryr-kubernetes,master,Id3149e3ee1899d99a6496b90c28033c930ce8232,Add basic docs about nested mode,MERGED,2020-11-17 13:45:53.000000000,2020-12-03 09:28:20.000000000,2020-12-03 09:25:44.000000000,"[{'_account_id': 11600}, {'_account_id': 13692}, {'_account_id': 22348}, {'_account_id': 23567}, {'_account_id': 27032}]","[{'number': 1, 'created': '2020-11-17 13:45:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kuryr-kubernetes/commit/42bf0543caf22c9b4d6db384ba5950061361dce5', 'message': 'Add basic docs about nested mode\n\nRelated-Bug: 1904488\nChange-Id: Id3149e3ee1899d99a6496b90c28033c930ce8232\n'}, {'number': 2, 'created': '2020-11-18 13:45:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kuryr-kubernetes/commit/01cf5fe415d23f9de2d4d096de59d79a81060e56', 'message': 'Add basic docs about nested mode\n\nRelated-Bug: 1904488\nChange-Id: Id3149e3ee1899d99a6496b90c28033c930ce8232\n'}, {'number': 3, 'created': '2020-11-24 14:35:42.000000000', 'files': ['doc/source/index.rst', 'doc/source/installation/containerized.rst', 'doc/source/nested_vlan_mode.rst'], 'web_link': 'https://opendev.org/openstack/kuryr-kubernetes/commit/775a4c9ef2fe39c61367114520d199ba47417cfb', 'message': 'Add basic docs about nested mode\n\nRelated-Bug: 1904488\nChange-Id: Id3149e3ee1899d99a6496b90c28033c930ce8232\n'}]",16,763012,775a4c9ef2fe39c61367114520d199ba47417cfb,18,5,3,11600,,,0,"Add basic docs about nested mode

Related-Bug: 1904488
Change-Id: Id3149e3ee1899d99a6496b90c28033c930ce8232
",git fetch https://review.opendev.org/openstack/kuryr-kubernetes refs/changes/12/763012/2 && git format-patch -1 --stdout FETCH_HEAD,"['doc/source/index.rst', 'doc/source/installation/containerized.rst', 'doc/source/nested_mode.rst']",3,42bf0543caf22c9b4d6db384ba5950061361dce5,nested-docs,"============================ Kuryr-Kubernetes nested mode ============================ Kuryr-Kubernetes can work in two basic modes - nested and standalone. The main use case of the project, which is to support Kubernetes running on OpenStack VMs is implemented with nested mode. The standalone mode is mostly used for testing. Requirements ============ Nested mode requires Neutron to have `trunk` extension enabled, which adds trunk port functionality to Neutron API. Principle ========= This mode aims at use case of kuryr-kubernetes providing networking for a Kubernetes cluster running in VMs on OpenStack. .. note:: A natural consideration here is running kuryr-kubernetes in containers on that K8s cluster. For more see :ref:`containerized` section. The principle is that Kuryr-Kubernetes will require that main interface of the K8s worker VMs is a trunk port. Then each of the pods will get a subport of that attached into its network namespace. Both VLAN and macvlan modes are supported. How to configure ================ You need to set several options in the kuryr.conf: .. code-block:: ini [binding] default_driver = kuryr.lib.binding.drivers.vlan link_iface = ens3 # Name of the trunk port interface on VMs. If not provided Kuryr will try to autodetect it. [kubernetes] pod_vif_driver = nested-vlan # Or nested-macvlan. vif_pool_driver = nested # If using port pools. [pod_vif_nested] worker_nodes_subnet = <id> # ID of the subnet in which worker node VMs are running. Also if you want to run several Kubernetes cluster in one OpenStack tenant you need to make sure Kuryr-Kubernetes instances are able to distinguish their own resources from resources created by other instances. In order to do that you need to configure Kuryr-Kubernetes to tag resources with unique ID: .. code-block:: ini [neutron_defaults] resource_tags = <unique-id-of-the-K8s-cluster> ",,61,0
openstack%2Fkuryr-kubernetes~master~I5b712ba97e030192d1d24cce2585724a78408e23,openstack/kuryr-kubernetes,master,I5b712ba97e030192d1d24cce2585724a78408e23,Skip unscheduled pods when deleting NPs,MERGED,2020-11-12 17:07:02.000000000,2020-12-03 09:27:11.000000000,2020-12-03 09:25:40.000000000,"[{'_account_id': 11600}, {'_account_id': 13692}, {'_account_id': 22348}, {'_account_id': 23567}, {'_account_id': 27032}]","[{'number': 1, 'created': '2020-11-12 17:07:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kuryr-kubernetes/commit/106a40594266d988a8983fff4ebe6ddd3e34b2dd', 'message': ""Skip unscheduled pods when deleting NPs\n\nIt may happen that there's an unscheduled pod matching a policy when NP\nis getting deleted. In that case we'll get a traceback as pod has no\nnodeName set. This commit fixes that by making sure we skip unscheduled\npods when detaching SGs from ports on NP deletion.\n\nChange-Id: I5b712ba97e030192d1d24cce2585724a78408e23\nCloses-Bug: 1904040\n""}, {'number': 2, 'created': '2020-11-13 10:21:25.000000000', 'files': ['kuryr_kubernetes/controller/drivers/utils.py', 'kuryr_kubernetes/controller/handlers/kuryrnetworkpolicy.py'], 'web_link': 'https://opendev.org/openstack/kuryr-kubernetes/commit/dce5939c242d44417b74e00382fd0a08a8c34f7b', 'message': ""Skip unscheduled pods when deleting NPs\n\nIt may happen that there's an unscheduled pod matching a policy when NP\nis getting deleted. In that case we'll get a traceback as pod has no\nnodeName set. This commit fixes that by making sure we skip unscheduled\npods when detaching SGs from ports on NP deletion.\n\nChange-Id: I5b712ba97e030192d1d24cce2585724a78408e23\nCloses-Bug: 1904040\n""}]",3,762551,dce5939c242d44417b74e00382fd0a08a8c34f7b,24,5,2,11600,,,0,"Skip unscheduled pods when deleting NPs

It may happen that there's an unscheduled pod matching a policy when NP
is getting deleted. In that case we'll get a traceback as pod has no
nodeName set. This commit fixes that by making sure we skip unscheduled
pods when detaching SGs from ports on NP deletion.

Change-Id: I5b712ba97e030192d1d24cce2585724a78408e23
Closes-Bug: 1904040
",git fetch https://review.opendev.org/openstack/kuryr-kubernetes refs/changes/51/762551/2 && git format-patch -1 --stdout FETCH_HEAD,"['kuryr_kubernetes/controller/drivers/utils.py', 'kuryr_kubernetes/controller/handlers/kuryrnetworkpolicy.py', 'kuryr_kubernetes/tests/unit/controller/handlers/test_vif.py', 'kuryr_kubernetes/controller/handlers/vif.py', 'kuryr_kubernetes/tests/unit/controller/drivers/test_utils.py']",5,106a40594266d988a8983fff4ebe6ddd3e34b2dd,bug/1904040," def setUp(self): super(TestUtils, self).setUp() self._pod_version = mock.sentinel.pod_version self._pod_link = mock.sentinel.pod_link self._pod_namespace = mock.sentinel.namespace self._pod_name = 'pod1' self._pod = { 'metadata': {'resourceVersion': self._pod_version, 'selfLink': self._pod_link, 'name': self._pod_name, 'namespace': self._pod_namespace}, 'status': {'phase': constants.K8S_POD_STATUS_PENDING}, 'spec': {'hostNetwork': False, 'nodeName': 'hostname'} } def test_is_pod_scheduled(self): self.assertTrue(utils.is_pod_scheduled(self._pod)) def test_is_not_pending(self): self._pod['status']['phase'] = 'Unknown' self.assertFalse(utils.is_pod_scheduled(self._pod)) def test_is_pending_no_node(self): self._pod['spec']['nodeName'] = None self.assertFalse(utils.is_pod_scheduled(self._pod)) def test_unset_pending(self): self.assertFalse(utils.is_pod_scheduled({'spec': {}, 'status': {}}))",,45,30
openstack%2Frequirements~master~Ib7e0568c5ea454c014d836b694db2345635d45eb,openstack/requirements,master,Ib7e0568c5ea454c014d836b694db2345635d45eb,update constraint for os-win to new release 5.3.0,MERGED,2020-12-02 18:19:47.000000000,2020-12-03 09:26:16.000000000,2020-12-03 09:24:35.000000000,"[{'_account_id': 14288}, {'_account_id': 22348}, {'_account_id': 28522}]","[{'number': 1, 'created': '2020-12-02 18:19:47.000000000', 'files': ['upper-constraints.txt'], 'web_link': 'https://opendev.org/openstack/requirements/commit/32bfd7c8da5c582e5eab114d043fb33c4762e535', 'message': 'update constraint for os-win to new release 5.3.0\n\nmeta: version: 5.3.0\nmeta: diff-start: -\nmeta: series: wallaby\nmeta: release-type: release\nmeta: pypi: yes\nmeta: first: yes\nmeta: release:Author: Herv Beraud <hberaud@redhat.com>\nmeta: release:Commit: Herv Beraud <hberaud@redhat.com>\nmeta: release:Change-Id: I9a6d8bbf4972694e29cff65be684cdd3ce057af9\nmeta: release:Code-Review+1: Lucian Petrut <lpetrut@cloudbasesolutions.com>\nmeta: release:Code-Review+2: Herv Beraud <hberaud@redhat.com>\nmeta: release:Code-Review+2: Thierry Carrez <thierry@openstack.org>\nmeta: release:Workflow+1: Thierry Carrez <thierry@openstack.org>\nChange-Id: Ib7e0568c5ea454c014d836b694db2345635d45eb\n'}]",0,765189,32bfd7c8da5c582e5eab114d043fb33c4762e535,9,3,1,11131,,,0,"update constraint for os-win to new release 5.3.0

meta: version: 5.3.0
meta: diff-start: -
meta: series: wallaby
meta: release-type: release
meta: pypi: yes
meta: first: yes
meta: release:Author: Herv Beraud <hberaud@redhat.com>
meta: release:Commit: Herv Beraud <hberaud@redhat.com>
meta: release:Change-Id: I9a6d8bbf4972694e29cff65be684cdd3ce057af9
meta: release:Code-Review+1: Lucian Petrut <lpetrut@cloudbasesolutions.com>
meta: release:Code-Review+2: Herv Beraud <hberaud@redhat.com>
meta: release:Code-Review+2: Thierry Carrez <thierry@openstack.org>
meta: release:Workflow+1: Thierry Carrez <thierry@openstack.org>
Change-Id: Ib7e0568c5ea454c014d836b694db2345635d45eb
",git fetch https://review.opendev.org/openstack/requirements refs/changes/89/765189/1 && git format-patch -1 --stdout FETCH_HEAD,['upper-constraints.txt'],1,32bfd7c8da5c582e5eab114d043fb33c4762e535,new-release,os-win===5.3.0,os-win===5.2.0,1,1
openstack%2Fpython-ironicclient~master~I5ad491575145af8f249c3b3d9fea6c1843b8a8b4,openstack/python-ironicclient,master,I5ad491575145af8f249c3b3d9fea6c1843b8a8b4,Add support for python 3.8,ABANDONED,2020-12-03 01:34:39.000000000,2020-12-03 09:15:31.000000000,,"[{'_account_id': 22348}, {'_account_id': 23851}]","[{'number': 1, 'created': '2020-12-03 01:34:39.000000000', 'files': ['lower-constraints.txt'], 'web_link': 'https://opendev.org/openstack/python-ironicclient/commit/a60a23a8f2d69f0430796746200a4895e9715b9f', 'message': 'Add support for python 3.8\n\nIntroduce support of python 3.8 [1] and move tox and jobs to py38.\n\npyOpenSSL 19.1.0 [2] support python 3.8\n\n[1] https://governance.openstack.org/tc/reference/runtimes/victoria.html#python-runtimes-for-victoria\n[2] https://pypi.org/project/pyOpenSSL/19.1.0/\n\nChange-Id: I5ad491575145af8f249c3b3d9fea6c1843b8a8b4\n'}]",0,765226,a60a23a8f2d69f0430796746200a4895e9715b9f,4,2,1,32029,,,0,"Add support for python 3.8

Introduce support of python 3.8 [1] and move tox and jobs to py38.

pyOpenSSL 19.1.0 [2] support python 3.8

[1] https://governance.openstack.org/tc/reference/runtimes/victoria.html#python-runtimes-for-victoria
[2] https://pypi.org/project/pyOpenSSL/19.1.0/

Change-Id: I5ad491575145af8f249c3b3d9fea6c1843b8a8b4
",git fetch https://review.opendev.org/openstack/python-ironicclient refs/changes/26/765226/1 && git format-patch -1 --stdout FETCH_HEAD,['lower-constraints.txt'],1,a60a23a8f2d69f0430796746200a4895e9715b9f,py38,pyOpenSSL==19.1.0,pyOpenSSL==17.1.0,1,1
openstack%2Ftrove-tempest-plugin~master~Ic138e03434e286645bb73daf6c5744f4c26f296a,openstack/trove-tempest-plugin,master,Ic138e03434e286645bb73daf6c5744f4c26f296a,bump py36 to py38 in tox.ini,ABANDONED,2020-09-19 14:50:58.000000000,2020-12-03 09:01:19.000000000,,[{'_account_id': 22348}],"[{'number': 1, 'created': '2020-09-19 14:50:58.000000000', 'files': ['tox.ini'], 'web_link': 'https://opendev.org/openstack/trove-tempest-plugin/commit/db4edc48de522445fb39b3f534b9127f3d8507a8', 'message': ""bump py36 to py38 in tox.ini\n\nin 'victoria' cycle, we should test py38 by default.\nalso remove pypy from default env\nTrivial change\n\nChange-Id: Ic138e03434e286645bb73daf6c5744f4c26f296a\n""}]",0,752800,db4edc48de522445fb39b3f534b9127f3d8507a8,3,1,1,26285,,,0,"bump py36 to py38 in tox.ini

in 'victoria' cycle, we should test py38 by default.
also remove pypy from default env
Trivial change

Change-Id: Ic138e03434e286645bb73daf6c5744f4c26f296a
",git fetch https://review.opendev.org/openstack/trove-tempest-plugin refs/changes/00/752800/1 && git format-patch -1 --stdout FETCH_HEAD,['tox.ini'],1,db4edc48de522445fb39b3f534b9127f3d8507a8,,"envlist = py38,pep8","envlist = py36,py35,pypy,pep8",1,1
openstack%2Fyaql~master~I5e2f563d6b6841fc6ca025a5c8b45fb1d01883da,openstack/yaql,master,I5e2f563d6b6841fc6ca025a5c8b45fb1d01883da,Remove pypy,ABANDONED,2020-07-03 14:57:27.000000000,2020-12-03 08:45:58.000000000,,[{'_account_id': 22348}],"[{'number': 1, 'created': '2020-07-03 14:57:27.000000000', 'files': ['tox.ini'], 'web_link': 'https://opendev.org/openstack/yaql/commit/08eaece6f541dcdfcd5aa13498d30d0b49f54c41', 'message': 'Remove pypy\n\nPypy is not tested in OpenStack anymore, remove the job.\n\nChange-Id: I5e2f563d6b6841fc6ca025a5c8b45fb1d01883da\n'}]",0,739248,08eaece6f541dcdfcd5aa13498d30d0b49f54c41,3,1,1,26285,,,0,"Remove pypy

Pypy is not tested in OpenStack anymore, remove the job.

Change-Id: I5e2f563d6b6841fc6ca025a5c8b45fb1d01883da
",git fetch https://review.opendev.org/openstack/yaql refs/changes/48/739248/1 && git format-patch -1 --stdout FETCH_HEAD,['tox.ini'],1,08eaece6f541dcdfcd5aa13498d30d0b49f54c41,,"envlist = py37,pep8","envlist = py37,pypy,pep8",1,1
openstack%2Fpython-freezerclient~stable%2Fussuri~I1458a61f5b0d70e1d4ebe3b8ba88bc4826b7a363,openstack/python-freezerclient,stable/ussuri,I1458a61f5b0d70e1d4ebe3b8ba88bc4826b7a363,Remove keystone v2 related code,ABANDONED,2020-08-05 13:45:47.000000000,2020-12-03 08:45:35.000000000,,"[{'_account_id': 11904}, {'_account_id': 21069}, {'_account_id': 22348}, {'_account_id': 26285}]","[{'number': 1, 'created': '2020-08-05 13:45:47.000000000', 'files': ['freezerclient/tests/unit/v2/test_client.py', 'freezerclient/tests/unit/v1/test_client.py', 'freezerclient/v2/client.py', 'freezerclient/shell.py', 'freezerclient/v1/client.py', 'freezerclient/tests/unit/test_shell.py'], 'web_link': 'https://opendev.org/openstack/python-freezerclient/commit/437892271f920185c633d24516f6cf4596b76667', 'message': 'Remove keystone v2 related code\n\nKyestone V2 support was removed in Train, so it\'s safe to remove ""tenant"" param.\n\nChange-Id: I1458a61f5b0d70e1d4ebe3b8ba88bc4826b7a363\n(cherry picked from commit 0df8a1da22145b06c30234b9f289d0ce55dd12f8)\n'}]",0,744907,437892271f920185c633d24516f6cf4596b76667,6,4,1,26285,,,0,"Remove keystone v2 related code

Kyestone V2 support was removed in Train, so it's safe to remove ""tenant"" param.

Change-Id: I1458a61f5b0d70e1d4ebe3b8ba88bc4826b7a363
(cherry picked from commit 0df8a1da22145b06c30234b9f289d0ce55dd12f8)
",git fetch https://review.opendev.org/openstack/python-freezerclient refs/changes/07/744907/1 && git format-patch -1 --stdout FETCH_HEAD,"['freezerclient/tests/unit/v2/test_client.py', 'freezerclient/tests/unit/v1/test_client.py', 'freezerclient/v2/client.py', 'freezerclient/shell.py', 'freezerclient/v1/client.py', 'freezerclient/tests/unit/test_shell.py']",6,437892271f920185c633d24516f6cf4596b76667,remove-keystone-v2-stable/ussuri,," 'OS_TENANT_ID': DEFAULT_PROJECT_ID, 'OS_TENANT_NAME': DEFAULT_PROJECT_NAME,",6,24
openstack%2Ffreezer-dr~master~Ie92d519836d6c25e80a6fc6f41f300d9cf17c941,openstack/freezer-dr,master,Ie92d519836d6c25e80a6fc6f41f300d9cf17c941,Add py38 in tox and setup.cfg,ABANDONED,2020-07-20 14:38:30.000000000,2020-12-03 08:44:57.000000000,,"[{'_account_id': 11904}, {'_account_id': 22348}]","[{'number': 1, 'created': '2020-07-20 14:38:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/freezer-dr/commit/429baffb8f49c41db2156d4924c0aaff52a72852', 'message': 'Add py38 in tox and setup.cfg\n\nChange-Id: Ie92d519836d6c25e80a6fc6f41f300d9cf17c941\n'}, {'number': 2, 'created': '2020-07-21 01:40:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/freezer-dr/commit/f5977a7c2c11e2f6703a9b7c3af54268cf15a7e7', 'message': 'Add py38 in tox and setup.cfg\n\nfix CI too\nChange-Id: Ie92d519836d6c25e80a6fc6f41f300d9cf17c941\n'}, {'number': 3, 'created': '2020-09-11 16:03:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/freezer-dr/commit/585b09c2503aaec5550e4871b07139bbfa38cb4f', 'message': 'Add py38 in tox and setup.cfg\n\nfix CI too\nChange-Id: Ie92d519836d6c25e80a6fc6f41f300d9cf17c941\n'}, {'number': 4, 'created': '2020-09-18 13:18:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/freezer-dr/commit/eca38b6a43c9aeffebfc7a176b64d88b6d63d337', 'message': 'Add py38 in tox and setup.cfg\n\nremove redundant py env from tox.\n\nChange-Id: Ie92d519836d6c25e80a6fc6f41f300d9cf17c941\n'}, {'number': 5, 'created': '2020-09-18 13:19:10.000000000', 'files': ['setup.cfg', 'tox.ini'], 'web_link': 'https://opendev.org/openstack/freezer-dr/commit/6da0d72729a960e8f3bf4974bd6256baddb465a3', 'message': 'Add py38 in tox and setup.cfg\n\nremove redundant py env from tox.\n\nChange-Id: Ie92d519836d6c25e80a6fc6f41f300d9cf17c941\n'}]",1,741958,6da0d72729a960e8f3bf4974bd6256baddb465a3,12,2,5,26285,,,0,"Add py38 in tox and setup.cfg

remove redundant py env from tox.

Change-Id: Ie92d519836d6c25e80a6fc6f41f300d9cf17c941
",git fetch https://review.opendev.org/openstack/freezer-dr refs/changes/58/741958/4 && git format-patch -1 --stdout FETCH_HEAD,"['setup.cfg', 'tox.ini']",2,429baffb8f49c41db2156d4924c0aaff52a72852,,"envlist =py36,py38,pep8,pylint,docs[testenv:py38] basepython = python3.8","envlist =py36,py37,pep8,pylint,docs[testenv:py37] basepython = python3.7",4,3
openstack%2Ftrove~master~I2b385acf8bf4e135cfe48b0c75c2fcce0b1c0a02,openstack/trove,master,I2b385acf8bf4e135cfe48b0c75c2fcce0b1c0a02,bump py37 to py38 in tox.ini,ABANDONED,2020-09-19 14:45:30.000000000,2020-12-03 08:43:47.000000000,,[{'_account_id': 22348}],"[{'number': 1, 'created': '2020-09-19 14:45:30.000000000', 'files': ['tox.ini'], 'web_link': 'https://opendev.org/openstack/trove/commit/ee852031508182118640c1d9f24dacf599431cba', 'message': ""bump py37 to py38 in tox.ini\n\nin 'victoria' cycle, we should test py38 by default.\nTrivial change\n\nChange-Id: I2b385acf8bf4e135cfe48b0c75c2fcce0b1c0a02\n""}]",0,752798,ee852031508182118640c1d9f24dacf599431cba,3,1,1,26285,,,0,"bump py37 to py38 in tox.ini

in 'victoria' cycle, we should test py38 by default.
Trivial change

Change-Id: I2b385acf8bf4e135cfe48b0c75c2fcce0b1c0a02
",git fetch https://review.opendev.org/openstack/trove refs/changes/98/752798/1 && git format-patch -1 --stdout FETCH_HEAD,['tox.ini'],1,ee852031508182118640c1d9f24dacf599431cba,,"envlist = py38,pep8,cover,api-ref,releasenotes,bandit,fakemodetests","envlist = py37,pep8,cover,api-ref,releasenotes,bandit,fakemodetests",1,1
openstack%2Fqinling-dashboard~master~I3561e8fd7c9df32fdf9ce80fc1d2c7a7bd3e89b5,openstack/qinling-dashboard,master,I3561e8fd7c9df32fdf9ce80fc1d2c7a7bd3e89b5,bump py37 to py38 in tox.ini,ABANDONED,2020-09-19 15:33:52.000000000,2020-12-03 08:43:05.000000000,,"[{'_account_id': 22348}, {'_account_id': 29313}]","[{'number': 1, 'created': '2020-09-19 15:33:52.000000000', 'files': ['tox.ini'], 'web_link': 'https://opendev.org/openstack/qinling-dashboard/commit/57347b763dbf1ba5103d7a06ee82ffcb14602e0d', 'message': ""bump py37 to py38 in tox.ini\n\nin 'victoria' cycle, we should test py38 by default.\nTrivial change\n\nChange-Id: I3561e8fd7c9df32fdf9ce80fc1d2c7a7bd3e89b5\n""}]",0,752802,57347b763dbf1ba5103d7a06ee82ffcb14602e0d,4,2,1,26285,,,0,"bump py37 to py38 in tox.ini

in 'victoria' cycle, we should test py38 by default.
Trivial change

Change-Id: I3561e8fd7c9df32fdf9ce80fc1d2c7a7bd3e89b5
",git fetch https://review.opendev.org/openstack/qinling-dashboard refs/changes/02/752802/1 && git format-patch -1 --stdout FETCH_HEAD,['tox.ini'],1,57347b763dbf1ba5103d7a06ee82ffcb14602e0d,,"envlist = py38,pep8,docs","envlist = py37,pep8,docs",1,1
openstack%2Foctavia-tempest-plugin~master~I162bc85c4cdb9b779338444c777c620f97db57e8,openstack/octavia-tempest-plugin,master,I162bc85c4cdb9b779338444c777c620f97db57e8,Set provider to amphora,ABANDONED,2020-11-19 08:46:47.000000000,2020-12-03 07:05:31.000000000,,"[{'_account_id': 1131}, {'_account_id': 22348}]","[{'number': 1, 'created': '2020-11-19 08:46:47.000000000', 'files': ['octavia_tempest_plugin/config.py'], 'web_link': 'https://opendev.org/openstack/octavia-tempest-plugin/commit/38b8eb72a243082aa4da6e8502db5aace6444884', 'message': 'Set provider to amphora\n\nRequired for testing amphorav2 transition to amphora.\n\nChange-Id: I162bc85c4cdb9b779338444c777c620f97db57e8\n'}]",0,763319,38b8eb72a243082aa4da6e8502db5aace6444884,3,2,1,7249,,,0,"Set provider to amphora

Required for testing amphorav2 transition to amphora.

Change-Id: I162bc85c4cdb9b779338444c777c620f97db57e8
",git fetch https://review.opendev.org/openstack/octavia-tempest-plugin refs/changes/19/763319/1 && git format-patch -1 --stdout FETCH_HEAD,['octavia_tempest_plugin/config.py'],1,38b8eb72a243082aa4da6e8502db5aace6444884,," default='amphora',"," default='octavia',",1,1
openstack%2Fcyborg~master~Ie88409118a0546e81056ad8d040adf589f49c04e,openstack/cyborg,master,Ie88409118a0546e81056ad8d040adf589f49c04e,refresh device profile link in API doc,MERGED,2020-11-26 07:27:11.000000000,2020-12-03 06:58:26.000000000,2020-12-03 06:56:40.000000000,"[{'_account_id': 22348}, {'_account_id': 23168}, {'_account_id': 26458}, {'_account_id': 28748}, {'_account_id': 31412}]","[{'number': 1, 'created': '2020-11-26 07:27:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cyborg/commit/1c9ad8d838ea2bd520b2d487d5275f8f8c9ad875', 'message': 'refresh device profile link in API doc\n\nChange-Id: Ie88409118a0546e81056ad8d040adf589f49c04e\n'}, {'number': 2, 'created': '2020-11-26 08:20:03.000000000', 'files': ['api-ref/source/v2/device_profile.inc', 'api-ref/source/v2/arqs.inc'], 'web_link': 'https://opendev.org/openstack/cyborg/commit/0e5b3708de8f8c3b4bc499331c59e938e5f4c35f', 'message': 'refresh device profile link in API doc\n\nChange-Id: Ie88409118a0546e81056ad8d040adf589f49c04e\n'}]",0,764281,0e5b3708de8f8c3b4bc499331c59e938e5f4c35f,10,5,2,25738,,,0,"refresh device profile link in API doc

Change-Id: Ie88409118a0546e81056ad8d040adf589f49c04e
",git fetch https://review.opendev.org/openstack/cyborg refs/changes/81/764281/2 && git format-patch -1 --stdout FETCH_HEAD,['api-ref/source/v2/device_profile.inc'],1,1c9ad8d838ea2bd520b2d487d5275f8f8c9ad875,docs,<https://specs.openstack.org/openstack/cyborg-specs/specs/train/implemented/device-profiles.html>`_ ,<http://specs.openstack.org/openstack/cyborg-specs/specs/train/approved/device-profiles.html>`_ ,1,1
openstack%2Frequirements~master~Iad6885265ab3b16821d0145cfd774f092a774272,openstack/requirements,master,Iad6885265ab3b16821d0145cfd774f092a774272,Updated from generate-constraints,ABANDONED,2020-12-03 06:30:36.000000000,2020-12-03 06:53:56.000000000,,[],"[{'number': 1, 'created': '2020-12-03 06:30:36.000000000', 'files': ['upper-constraints.txt'], 'web_link': 'https://opendev.org/openstack/requirements/commit/364429a7325338f69bca8f48318e21dbb511290c', 'message': 'Updated from generate-constraints\n\nChange-Id: Iad6885265ab3b16821d0145cfd774f092a774272\n'}]",0,765244,364429a7325338f69bca8f48318e21dbb511290c,3,0,1,11131,,,0,"Updated from generate-constraints

Change-Id: Iad6885265ab3b16821d0145cfd774f092a774272
",git fetch https://review.opendev.org/openstack/requirements refs/changes/44/765244/1 && git format-patch -1 --stdout FETCH_HEAD,['upper-constraints.txt'],1,364429a7325338f69bca8f48318e21dbb511290c,openstack/requirements/constraints,python-saharaclient===3.3.0grpcio===1.34.0neutron-lib===2.7.0python-vitrageclient===4.2.0pyOpenSSL===20.0.0pymongo===3.11.2sphinxcontrib.datatemplates===0.7.1mock===4.0.2libvirt-python===6.10.0importlib-metadata===3.1.1;python_version=='3.6'docutils===0.16mistral-lib===2.4.0os-win===5.3.0boto3===1.16.28packaging===20.7python-qpid-proton===0.33.0sympy===1.7openstackdocstheme===2.2.7botocore===1.19.28jsonpatch===1.28pkg-resources===0.0.0python-masakariclient===6.2.0aniso8601===8.1.0sphinxcontrib-runcmd===0.2.0,python-saharaclient===3.2.1grpcio===1.33.2neutron-lib===2.6.1python-vitrageclient===4.1.1pyOpenSSL===19.1.0;python_version=='3.6' pyOpenSSL===20.0.0;python_version=='3.8'pymongo===3.11.1sphinxcontrib.datatemplates===0.6.1mock===3.0.5libvirt-python===6.9.0importlib-metadata===3.1.0;python_version=='3.6'docutils===0.15.2mistral-lib===2.3.0os-win===5.2.0boto3===1.16.25packaging===20.4python-qpid-proton===0.32.0sympy===1.6.2openstackdocstheme===2.2.6botocore===1.19.25jsonpatch===1.27python-masakariclient===6.1.1aniso8601===8.0.0setuptools===50.3.2,24,24
openstack%2Ftripleo-common~stable%2Ftrain~Iff8eec43bd73bc6486f56e741e740869d1b8acbb,openstack/tripleo-common,stable/train,Iff8eec43bd73bc6486f56e741e740869d1b8acbb,Switch to tripleo_dense,MERGED,2020-07-06 18:52:56.000000000,2020-12-03 06:50:34.000000000,2020-12-03 06:47:55.000000000,"[{'_account_id': 3153}, {'_account_id': 7353}, {'_account_id': 14985}, {'_account_id': 22348}, {'_account_id': 23181}, {'_account_id': 29775}]","[{'number': 1, 'created': '2020-07-06 18:52:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-common/commit/6d06eab254f4c2e23f4c861cc7fb65de97c18b99', 'message': 'Switch to tripleo_dense\n\nChange-Id: Iff8eec43bd73bc6486f56e741e740869d1b8acbb\n(cherry picked from commit 0186702a41c8a917013931a4dd2a1164777380fb)\n'}, {'number': 2, 'created': '2020-07-13 01:32:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-common/commit/493bcc6458bd58ba5444fa0c4d56a5ec63c4ec84', 'message': 'Switch to tripleo_dense\n\nChange-Id: Iff8eec43bd73bc6486f56e741e740869d1b8acbb\n(cherry picked from commit 0186702a41c8a917013931a4dd2a1164777380fb)\n'}, {'number': 3, 'created': '2020-08-27 00:46:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-common/commit/3896ef8703bd1dc70d87581b54489ea90ec62e60', 'message': 'Switch to tripleo_dense\n\nChange-Id: Iff8eec43bd73bc6486f56e741e740869d1b8acbb\n(cherry picked from commit 0186702a41c8a917013931a4dd2a1164777380fb)\n'}, {'number': 4, 'created': '2020-09-10 12:47:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-common/commit/a6bbb4e922d37e4aaf2cb89e4eda25e83c1906fb', 'message': 'Switch to tripleo_dense\n\nChange-Id: Iff8eec43bd73bc6486f56e741e740869d1b8acbb\n(cherry picked from commit 0186702a41c8a917013931a4dd2a1164777380fb)\n'}, {'number': 5, 'created': '2020-09-10 17:40:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-common/commit/40d74b4381b201ae7135f90019beeb247e7654e9', 'message': 'Switch to tripleo_dense\n\nChange-Id: Iff8eec43bd73bc6486f56e741e740869d1b8acbb\n(cherry picked from commit 0186702a41c8a917013931a4dd2a1164777380fb)\n'}, {'number': 6, 'created': '2020-09-14 20:18:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-common/commit/d47c54f76d78ea186d78e7c7046af17487fe577a', 'message': 'Switch to tripleo_dense\n\nDepends-On: https://review.opendev.org/#/c/751895/\nChange-Id: Iff8eec43bd73bc6486f56e741e740869d1b8acbb\n(cherry picked from commit 0186702a41c8a917013931a4dd2a1164777380fb)\n'}, {'number': 7, 'created': '2020-09-22 11:44:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-common/commit/2af56839d1fcf76b03f99490bbcab2216e4b4761', 'message': 'Switch to tripleo_dense\n\nDepends-On: https://review.opendev.org/#/c/751895/\nChange-Id: Iff8eec43bd73bc6486f56e741e740869d1b8acbb\n(cherry picked from commit 0186702a41c8a917013931a4dd2a1164777380fb)\n'}, {'number': 8, 'created': '2020-09-22 11:44:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-common/commit/a4be2577fc079e0bd46a322879464cce946ef937', 'message': 'Switch to tripleo_dense\n\nChange-Id: Iff8eec43bd73bc6486f56e741e740869d1b8acbb\n(cherry picked from commit 0186702a41c8a917013931a4dd2a1164777380fb)\n'}, {'number': 9, 'created': '2020-10-13 12:42:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-common/commit/3b5d66e9f94dc4252567ed701af2a5f5e168a3a3', 'message': 'Switch to tripleo_dense\n\nChange-Id: Iff8eec43bd73bc6486f56e741e740869d1b8acbb\n(cherry picked from commit 0186702a41c8a917013931a4dd2a1164777380fb)\n'}, {'number': 10, 'created': '2020-11-16 16:15:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-common/commit/fe6bae1f3a7f2ba276993406c38630c19727af8a', 'message': 'Switch to tripleo_dense\n\nChange-Id: Iff8eec43bd73bc6486f56e741e740869d1b8acbb\nDepends-On: https://review.opendev.org/#/c/726479/\n(cherry picked from commit 0186702a41c8a917013931a4dd2a1164777380fb)\n'}, {'number': 11, 'created': '2020-11-16 20:01:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-common/commit/a59847704b037d40127f5ccea138c9baa2b488e0', 'message': 'Switch to tripleo_dense\n\nChange-Id: Iff8eec43bd73bc6486f56e741e740869d1b8acbb\nDepends-On: https://review.opendev.org/#/c/726479/\n(cherry picked from commit 0186702a41c8a917013931a4dd2a1164777380fb)\n'}, {'number': 12, 'created': '2020-11-16 20:02:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-common/commit/800c30afe5061fcee750ce143a95c133fadd1578', 'message': 'Switch to tripleo_dense\n\nChange-Id: Iff8eec43bd73bc6486f56e741e740869d1b8acbb\nDepends-On: https://review.opendev.org/#/c/726479/\n(cherry picked from commit 0186702a41c8a917013931a4dd2a1164777380fb)\n'}, {'number': 13, 'created': '2020-11-16 20:04:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-common/commit/c54323d2f4a3cc60d25b5135bab60a5a95c2c02c', 'message': 'Switch to tripleo_dense\n\nChange-Id: Iff8eec43bd73bc6486f56e741e740869d1b8acbb\nDepends-On: https://review.opendev.org/#/c/726479/\n(cherry picked from commit 0186702a41c8a917013931a4dd2a1164777380fb)\n'}, {'number': 14, 'created': '2020-11-19 16:11:59.000000000', 'files': ['tripleo_common/actions/ansible.py', 'tripleo_common/tests/actions/test_ansible.py'], 'web_link': 'https://opendev.org/openstack/tripleo-common/commit/8bae698dcc110f3ded9b9e35eb9d0b8e1f7594b0', 'message': 'Switch to tripleo_dense\n\nChange-Id: Iff8eec43bd73bc6486f56e741e740869d1b8acbb\nDepends-On: https://review.opendev.org/#/c/726479/\n(cherry picked from commit 0186702a41c8a917013931a4dd2a1164777380fb)\n'}]",0,739578,8bae698dcc110f3ded9b9e35eb9d0b8e1f7594b0,123,6,14,3153,,,0,"Switch to tripleo_dense

Change-Id: Iff8eec43bd73bc6486f56e741e740869d1b8acbb
Depends-On: https://review.opendev.org/#/c/726479/
(cherry picked from commit 0186702a41c8a917013931a4dd2a1164777380fb)
",git fetch https://review.opendev.org/openstack/tripleo-common refs/changes/78/739578/4 && git format-patch -1 --stdout FETCH_HEAD,"['tripleo_common/actions/ansible.py', 'tripleo_common/tests/actions/test_ansible.py']",2,6d06eab254f4c2e23f4c861cc7fb65de97c18b99,callback-improvements," 'ANSIBLE_CALLBACK_WHITELIST': 'tripleo_dense,tripleo_profile_tasks', 'ANSIBLE_STDOUT_CALLBACK': 'tripleo_dense',"," 'ANSIBLE_CALLBACK_WHITELIST': 'tripleo,profile_tasks', 'ANSIBLE_STDOUT_CALLBACK': 'tripleo',",7,5
openstack%2Ftripleo-heat-templates~stable%2Ftrain~Ib4a02a192377aafab5970647d74977cb1189bcae,openstack/tripleo-heat-templates,stable/train,Ib4a02a192377aafab5970647d74977cb1189bcae,Switch deploy steps to tripleo_free,MERGED,2020-07-21 18:23:05.000000000,2020-12-03 06:47:59.000000000,2020-12-03 06:47:59.000000000,"[{'_account_id': 6926}, {'_account_id': 7353}, {'_account_id': 14985}, {'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2020-07-21 18:23:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/e3102ca349d9687052b90349d054e8a276f36715', 'message': ""Switch deploy steps to tripleo_free\n\nThe tripleo_free strategy should allow the tasks to run freely for a\ngiven playbook that defines using the tripleo_free strategy. The defaul\nstrategy is a linear one that will execute each task across all servers\nprior to moving to the next task. The tripleo_free strategy will execute\nthe tasks on servers without syncryonizing the tasks within a given\nplaybook. Because TripleO uses step concepts in our deployment, we\nalready have the syncronization points in the main playbook. The outer\nplaybook should be done linearly but the deployment steps themselves\nshould be done freely.\n\nThe tripleo_free playbook won't stop execution on all hosts if one host\nfails or becomes unreachable. It will however end the play exeuction if\nany error occurs on any host. This is similar to the deployment failures\nwe used to have with Heat where a failure on any single node would stop\nthe deployment at a given deployment step.  A future improvement of this\nwill be to add logic to handle a failure percentage on a given TripleO\nrole to only stop the playbook if the failure percentage exceeds a\ndefined amount. Currently any failure will stop a playbook but may not\nstop later tasks from executing on the rest of the hosts. We will likely\nneed to implement a tripleo_linear strategy based on the upstream linear\nstrategy to understand these failure percentages as well.\n\nNOTE: During the testing of this, we identified two issues with the free\nstrategy in ansible itself. We will need those fixes landed in the\nversion of ansible prior to being able to land this.\n\nDepends-On: https://github.com/ansible/ansible/pull/69730\nDepends-On: https://github.com/ansible/ansible/pull/69524\nChange-Id: Ib4a02a192377aafab5970647d74977cb1189bcae\n(cherry picked from commit a5f9740759461434177d6590cc8c99bb5e48365b)\n""}, {'number': 2, 'created': '2020-07-21 18:25:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/d4d4d283d10815fa9ff11ff15c55a498e1585d5a', 'message': ""Switch deploy steps to tripleo_free\n\nThe tripleo_free strategy should allow the tasks to run freely for a\ngiven playbook that defines using the tripleo_free strategy. The defaul\nstrategy is a linear one that will execute each task across all servers\nprior to moving to the next task. The tripleo_free strategy will execute\nthe tasks on servers without syncryonizing the tasks within a given\nplaybook. Because TripleO uses step concepts in our deployment, we\nalready have the syncronization points in the main playbook. The outer\nplaybook should be done linearly but the deployment steps themselves\nshould be done freely.\n\nThe tripleo_free playbook won't stop execution on all hosts if one host\nfails or becomes unreachable. It will however end the play exeuction if\nany error occurs on any host. This is similar to the deployment failures\nwe used to have with Heat where a failure on any single node would stop\nthe deployment at a given deployment step.  A future improvement of this\nwill be to add logic to handle a failure percentage on a given TripleO\nrole to only stop the playbook if the failure percentage exceeds a\ndefined amount. Currently any failure will stop a playbook but may not\nstop later tasks from executing on the rest of the hosts. We will likely\nneed to implement a tripleo_linear strategy based on the upstream linear\nstrategy to understand these failure percentages as well.\n\nNOTE: During the testing of this, we identified two issues with the free\nstrategy in ansible itself. We will need those fixes landed in the\nversion of ansible prior to being able to land this.\n\nChange-Id: Ib4a02a192377aafab5970647d74977cb1189bcae\n(cherry picked from commit a5f9740759461434177d6590cc8c99bb5e48365b)\n""}, {'number': 3, 'created': '2020-11-11 17:36:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/1323a7c1078ce944043377cb250a4a37ab747290', 'message': ""Switch deploy steps to tripleo_free\n\nThe tripleo_free strategy should allow the tasks to run freely for a\ngiven playbook that defines using the tripleo_free strategy. The defaul\nstrategy is a linear one that will execute each task across all servers\nprior to moving to the next task. The tripleo_free strategy will execute\nthe tasks on servers without syncryonizing the tasks within a given\nplaybook. Because TripleO uses step concepts in our deployment, we\nalready have the syncronization points in the main playbook. The outer\nplaybook should be done linearly but the deployment steps themselves\nshould be done freely.\n\nThe tripleo_free playbook won't stop execution on all hosts if one host\nfails or becomes unreachable. It will however end the play exeuction if\nany error occurs on any host. This is similar to the deployment failures\nwe used to have with Heat where a failure on any single node would stop\nthe deployment at a given deployment step.  A future improvement of this\nwill be to add logic to handle a failure percentage on a given TripleO\nrole to only stop the playbook if the failure percentage exceeds a\ndefined amount. Currently any failure will stop a playbook but may not\nstop later tasks from executing on the rest of the hosts. We will likely\nneed to implement a tripleo_linear strategy based on the upstream linear\nstrategy to understand these failure percentages as well.\n\nNOTE: During the testing of this, we identified two issues with the free\nstrategy in ansible itself. We will need those fixes landed in the\nversion of ansible prior to being able to land this.\n\nChange-Id: Ib4a02a192377aafab5970647d74977cb1189bcae\n(cherry picked from commit a5f9740759461434177d6590cc8c99bb5e48365b)\n""}, {'number': 4, 'created': '2020-11-16 15:15:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/5eaec82290391febff4d24f1caf3d3140bc48b9d', 'message': ""Switch deploy steps to tripleo_free\n\nThe tripleo_free strategy should allow the tasks to run freely for a\ngiven playbook that defines using the tripleo_free strategy. The defaul\nstrategy is a linear one that will execute each task across all servers\nprior to moving to the next task. The tripleo_free strategy will execute\nthe tasks on servers without syncryonizing the tasks within a given\nplaybook. Because TripleO uses step concepts in our deployment, we\nalready have the syncronization points in the main playbook. The outer\nplaybook should be done linearly but the deployment steps themselves\nshould be done freely.\n\nThe tripleo_free playbook won't stop execution on all hosts if one host\nfails or becomes unreachable. It will however end the play exeuction if\nany error occurs on any host. This is similar to the deployment failures\nwe used to have with Heat where a failure on any single node would stop\nthe deployment at a given deployment step.  A future improvement of this\nwill be to add logic to handle a failure percentage on a given TripleO\nrole to only stop the playbook if the failure percentage exceeds a\ndefined amount. Currently any failure will stop a playbook but may not\nstop later tasks from executing on the rest of the hosts. We will likely\nneed to implement a tripleo_linear strategy based on the upstream linear\nstrategy to understand these failure percentages as well.\n\nNOTE: During the testing of this, we identified two issues with the free\nstrategy in ansible itself. We will need those fixes landed in the\nversion of ansible prior to being able to land this.\n\nChange-Id: Ib4a02a192377aafab5970647d74977cb1189bcae\n(cherry picked from commit a5f9740759461434177d6590cc8c99bb5e48365b)\n""}, {'number': 5, 'created': '2020-11-16 20:20:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/887b7c0e1b3b4748632fcad3794e6167e852dbca', 'message': ""Switch deploy steps to tripleo_free\n\nThe tripleo_free strategy should allow the tasks to run freely for a\ngiven playbook that defines using the tripleo_free strategy. The defaul\nstrategy is a linear one that will execute each task across all servers\nprior to moving to the next task. The tripleo_free strategy will execute\nthe tasks on servers without syncryonizing the tasks within a given\nplaybook. Because TripleO uses step concepts in our deployment, we\nalready have the syncronization points in the main playbook. The outer\nplaybook should be done linearly but the deployment steps themselves\nshould be done freely.\n\nThe tripleo_free playbook won't stop execution on all hosts if one host\nfails or becomes unreachable. It will however end the play exeuction if\nany error occurs on any host. This is similar to the deployment failures\nwe used to have with Heat where a failure on any single node would stop\nthe deployment at a given deployment step.  A future improvement of this\nwill be to add logic to handle a failure percentage on a given TripleO\nrole to only stop the playbook if the failure percentage exceeds a\ndefined amount. Currently any failure will stop a playbook but may not\nstop later tasks from executing on the rest of the hosts. We will likely\nneed to implement a tripleo_linear strategy based on the upstream linear\nstrategy to understand these failure percentages as well.\n\nNOTE: During the testing of this, we identified two issues with the free\nstrategy in ansible itself. We will need those fixes landed in the\nversion of ansible prior to being able to land this.\n\nDepends-On: https://review.opendev.org/#/c/739578/\nChange-Id: Ib4a02a192377aafab5970647d74977cb1189bcae\n(cherry picked from commit a5f9740759461434177d6590cc8c99bb5e48365b)\n""}, {'number': 6, 'created': '2020-11-18 18:16:15.000000000', 'files': ['common/deploy-steps.j2'], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/ca5860b4ff6e2014236659daac8b531ee2f3364f', 'message': ""Switch deploy steps to tripleo_free\n\nThe tripleo_free strategy should allow the tasks to run freely for a\ngiven playbook that defines using the tripleo_free strategy. The defaul\nstrategy is a linear one that will execute each task across all servers\nprior to moving to the next task. The tripleo_free strategy will execute\nthe tasks on servers without syncryonizing the tasks within a given\nplaybook. Because TripleO uses step concepts in our deployment, we\nalready have the syncronization points in the main playbook. The outer\nplaybook should be done linearly but the deployment steps themselves\nshould be done freely.\n\nThe tripleo_free playbook won't stop execution on all hosts if one host\nfails or becomes unreachable. It will however end the play exeuction if\nany error occurs on any host. This is similar to the deployment failures\nwe used to have with Heat where a failure on any single node would stop\nthe deployment at a given deployment step.  A future improvement of this\nwill be to add logic to handle a failure percentage on a given TripleO\nrole to only stop the playbook if the failure percentage exceeds a\ndefined amount. Currently any failure will stop a playbook but may not\nstop later tasks from executing on the rest of the hosts. We will likely\nneed to implement a tripleo_linear strategy based on the upstream linear\nstrategy to understand these failure percentages as well.\n\nNOTE: During the testing of this, we identified two issues with the free\nstrategy in ansible itself. We will need those fixes landed in the\nversion of ansible prior to being able to land this.\n\nDepends-On: https://review.opendev.org/#/c/739578/\nChange-Id: Ib4a02a192377aafab5970647d74977cb1189bcae\n(cherry picked from commit a5f9740759461434177d6590cc8c99bb5e48365b)\n""}]",0,742263,ca5860b4ff6e2014236659daac8b531ee2f3364f,38,5,6,14985,,,0,"Switch deploy steps to tripleo_free

The tripleo_free strategy should allow the tasks to run freely for a
given playbook that defines using the tripleo_free strategy. The defaul
strategy is a linear one that will execute each task across all servers
prior to moving to the next task. The tripleo_free strategy will execute
the tasks on servers without syncryonizing the tasks within a given
playbook. Because TripleO uses step concepts in our deployment, we
already have the syncronization points in the main playbook. The outer
playbook should be done linearly but the deployment steps themselves
should be done freely.

The tripleo_free playbook won't stop execution on all hosts if one host
fails or becomes unreachable. It will however end the play exeuction if
any error occurs on any host. This is similar to the deployment failures
we used to have with Heat where a failure on any single node would stop
the deployment at a given deployment step.  A future improvement of this
will be to add logic to handle a failure percentage on a given TripleO
role to only stop the playbook if the failure percentage exceeds a
defined amount. Currently any failure will stop a playbook but may not
stop later tasks from executing on the rest of the hosts. We will likely
need to implement a tripleo_linear strategy based on the upstream linear
strategy to understand these failure percentages as well.

NOTE: During the testing of this, we identified two issues with the free
strategy in ansible itself. We will need those fixes landed in the
version of ansible prior to being able to land this.

Depends-On: https://review.opendev.org/#/c/739578/
Change-Id: Ib4a02a192377aafab5970647d74977cb1189bcae
(cherry picked from commit a5f9740759461434177d6590cc8c99bb5e48365b)
",git fetch https://review.opendev.org/openstack/tripleo-heat-templates refs/changes/63/742263/1 && git format-patch -1 --stdout FETCH_HEAD,['common/deploy-steps.j2'],1,e3102ca349d9687052b90349d054e8a276f36715,maxfail/train, strategy: tripleo_free strategy: tripleo_free strategy: tripleo_free strategy: tripleo_free strategy: tripleo_free strategy: tripleo_free strategy: tripleo_free,,7,0
openstack%2Ftripleo-heat-templates~stable%2Fussuri~Ib5478e53eb1f216bf6924ff30ea8502cb8529d00,openstack/tripleo-heat-templates,stable/ussuri,Ib5478e53eb1f216bf6924ff30ea8502cb8529d00,Add NovaDisableImageDownloadToRbd parameter,MERGED,2020-10-28 15:00:55.000000000,2020-12-03 06:47:50.000000000,2020-12-03 06:47:50.000000000,"[{'_account_id': 14985}, {'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2020-10-28 15:00:55.000000000', 'files': ['environments/dcn-hci.yaml', 'environments/dcn.yaml', 'deployment/nova/nova-compute-container-puppet.yaml', 'sample-env-generator/dcn.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/815af694a8065179f4602a67b744a91ceea6d61b', 'message': 'Add NovaDisableImageDownloadToRbd parameter\n\nThis exposes the nova workaround to disable downloading images from glance to\nrbd (vs a cheap COW clone) when nova-compute and glance are not backed by the\nsame ceph cluster.\n\nRelated nova change: I069b6b1d28eaf1eee5c7fb8d0fdef9c0c229a1bf\nDepends-On: I8329810d6c047c0d94e7b123e7cdc1263a7856cd\n\nChange-Id: Ib5478e53eb1f216bf6924ff30ea8502cb8529d00\n(cherry picked from commit b756944d454299ad908bddd0fe2ba679c166ec6e)\n'}]",0,760159,815af694a8065179f4602a67b744a91ceea6d61b,13,3,1,23811,,,0,"Add NovaDisableImageDownloadToRbd parameter

This exposes the nova workaround to disable downloading images from glance to
rbd (vs a cheap COW clone) when nova-compute and glance are not backed by the
same ceph cluster.

Related nova change: I069b6b1d28eaf1eee5c7fb8d0fdef9c0c229a1bf
Depends-On: I8329810d6c047c0d94e7b123e7cdc1263a7856cd

Change-Id: Ib5478e53eb1f216bf6924ff30ea8502cb8529d00
(cherry picked from commit b756944d454299ad908bddd0fe2ba679c166ec6e)
",git fetch https://review.opendev.org/openstack/tripleo-heat-templates refs/changes/59/760159/1 && git format-patch -1 --stdout FETCH_HEAD,"['environments/dcn-hci.yaml', 'environments/dcn.yaml', 'deployment/nova/nova-compute-container-puppet.yaml', 'sample-env-generator/dcn.yaml']",4,815af694a8065179f4602a67b744a91ceea6d61b,, deployment/nova/nova-compute-container-puppet.yaml: parameters: - NovaDisableImageDownloadToRbd NovaDisableImageDownloadToRbd: true,,23,0
openstack%2Foctavia~master~I5ed6288b2776bd7f1c9b67e9cfd9a8f05b1196be,openstack/octavia,master,I5ed6288b2776bd7f1c9b67e9cfd9a8f05b1196be,Add amphora_id in store params for failover_amphora,MERGED,2020-10-29 14:54:15.000000000,2020-12-03 06:46:54.000000000,2020-12-03 06:45:11.000000000,"[{'_account_id': 1131}, {'_account_id': 6469}, {'_account_id': 7249}, {'_account_id': 11628}, {'_account_id': 22348}]","[{'number': 1, 'created': '2020-10-29 14:54:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/octavia/commit/cc8082235b7edb891f13ef81725c8a038bcac601', 'message': ""Add amphora_id in store params for failover_amphora\n\nSeveral tasks require amphora_id parameter to be passed in\nget_amphora_for_lb_failover_subflow.\nExecution passed results in error:\n\ntaskflow.exceptions.NotFound: Mapped argument 'amphora_id' <=\n'amphora_id' was not produced by any accessible provider\n(1 possible providers were scanned).\n\nChange-Id: I5ed6288b2776bd7f1c9b67e9cfd9a8f05b1196be\n""}, {'number': 2, 'created': '2020-10-30 10:44:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/octavia/commit/14246048d117102f24dcc6155169dd730401b413', 'message': ""Add amphora_id in store params for failover_amphora\n\nSeveral tasks require amphora_id parameter to be passed in\nget_amphora_for_lb_failover_subflow.\nExecution passed results in error:\n\ntaskflow.exceptions.NotFound: Mapped argument 'amphora_id' <=\n'amphora_id' was not produced by any accessible provider\n(1 possible providers were scanned).\n\nChange-Id: I5ed6288b2776bd7f1c9b67e9cfd9a8f05b1196be\n""}, {'number': 3, 'created': '2020-11-03 08:59:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/octavia/commit/4d639f803e79f6cc68ff13bdf90091a81bf3c207', 'message': ""Add amphora_id in store params for failover_amphora\n\nSeveral tasks require amphora_id parameter to be passed in\nget_amphora_for_lb_failover_subflow.\nExecution passed results in error:\n\ntaskflow.exceptions.NotFound: Mapped argument 'amphora_id' <=\n'amphora_id' was not produced by any accessible provider\n(1 possible providers were scanned).\n\nAlso fix getting ID parameter from amphora dict in\nAmphoraIndexListenersReload.\n\nChange-Id: I5ed6288b2776bd7f1c9b67e9cfd9a8f05b1196be\n""}, {'number': 4, 'created': '2020-11-17 07:28:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/octavia/commit/bb1ad104d21ca34d4bbc2cfbc248614de381773a', 'message': ""Add amphora_id in store params for failover_amphora\n\nSeveral tasks require amphora_id parameter to be passed in\nget_amphora_for_lb_failover_subflow.\nExecution passed results in error:\n\ntaskflow.exceptions.NotFound: Mapped argument 'amphora_id' <=\n'amphora_id' was not produced by any accessible provider\n(1 possible providers were scanned).\n\nAlso fix getting ID parameter from amphora dict in\nAmphoraIndexListenersReload.\n\nChange-Id: I5ed6288b2776bd7f1c9b67e9cfd9a8f05b1196be\n""}, {'number': 5, 'created': '2020-11-25 10:07:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/octavia/commit/9d5de15642719e04d7f7a91eb9913a5e614ca1f2', 'message': ""Add amphora_id in store params for failover_amphora\n\nSeveral tasks require amphora_id parameter to be passed in\nget_amphora_for_lb_failover_subflow.\nExecution passed results in error:\n\ntaskflow.exceptions.NotFound: Mapped argument 'amphora_id' <=\n'amphora_id' was not produced by any accessible provider\n(1 possible providers were scanned).\n\nAlso fix getting ID parameter from amphora dict in\nAmphoraIndexListenersReload.\n\nChange-Id: I5ed6288b2776bd7f1c9b67e9cfd9a8f05b1196be\n""}, {'number': 6, 'created': '2020-11-25 15:08:36.000000000', 'files': ['octavia/tests/unit/controller/worker/v2/test_controller_worker.py', 'octavia/controller/worker/v2/tasks/amphora_driver_tasks.py', 'octavia/controller/worker/v2/controller_worker.py', 'octavia/tests/unit/controller/worker/v2/tasks/test_amphora_driver_tasks.py'], 'web_link': 'https://opendev.org/openstack/octavia/commit/1a154839c2dfb5a9c89963b27a96f0adef1038ee', 'message': ""Add amphora_id in store params for failover_amphora\n\nSeveral tasks require amphora_id parameter to be passed in\nget_amphora_for_lb_failover_subflow.\nExecution passed results in error:\n\ntaskflow.exceptions.NotFound: Mapped argument 'amphora_id' <=\n'amphora_id' was not produced by any accessible provider\n(1 possible providers were scanned).\n\nAlso fix getting ID parameter from amphora dict in\nAmphoraIndexListenersReload and add missing retries for create_*\nresources in v2 worker.\n\nChange-Id: I5ed6288b2776bd7f1c9b67e9cfd9a8f05b1196be\n""}]",1,760380,1a154839c2dfb5a9c89963b27a96f0adef1038ee,34,5,6,7249,,,0,"Add amphora_id in store params for failover_amphora

Several tasks require amphora_id parameter to be passed in
get_amphora_for_lb_failover_subflow.
Execution passed results in error:

taskflow.exceptions.NotFound: Mapped argument 'amphora_id' <=
'amphora_id' was not produced by any accessible provider
(1 possible providers were scanned).

Also fix getting ID parameter from amphora dict in
AmphoraIndexListenersReload and add missing retries for create_*
resources in v2 worker.

Change-Id: I5ed6288b2776bd7f1c9b67e9cfd9a8f05b1196be
",git fetch https://review.opendev.org/openstack/octavia refs/changes/80/760380/4 && git format-patch -1 --stdout FETCH_HEAD,"['octavia/tests/unit/controller/worker/v2/test_controller_worker.py', 'octavia/controller/worker/v2/controller_worker.py']",2,cc8082235b7edb891f13ef81725c8a038bcac601,," constants.VIP: vip_dict, constants.AMPHORA_ID: amphora_id}", constants.VIP: vip_dict},16,8
openstack%2Foctavia-tempest-plugin~master~I75c2d4e78ad56a6338f63073f13655a290353ec2,openstack/octavia-tempest-plugin,master,I75c2d4e78ad56a6338f63073f13655a290353ec2,Add HTTP/2 support to the Go test server,MERGED,2020-10-16 19:15:16.000000000,2020-12-03 06:40:35.000000000,2020-12-03 06:38:47.000000000,"[{'_account_id': 1131}, {'_account_id': 6469}, {'_account_id': 7249}, {'_account_id': 11628}, {'_account_id': 13995}, {'_account_id': 19298}, {'_account_id': 22348}, {'_account_id': 29244}]","[{'number': 1, 'created': '2020-10-16 19:15:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/octavia-tempest-plugin/commit/7df2a41211dc9c17d8118129e49281396e76cb40', 'message': 'Add HTTP/2 support to the Go test server\n\nThe HTTPS listener will now also serve HTTP/2 requests.\n\nChange-Id: I75c2d4e78ad56a6338f63073f13655a290353ec2\n'}, {'number': 2, 'created': '2020-10-27 20:48:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/octavia-tempest-plugin/commit/809e7badbeb8e4ef3f63e94e3985d11d77946ff4', 'message': 'Add HTTP/2 support to the Go test server\n\nThe HTTPS listener will now also serve HTTP/2 requests.\n\nChange-Id: I75c2d4e78ad56a6338f63073f13655a290353ec2\n'}, {'number': 3, 'created': '2020-10-28 14:11:49.000000000', 'files': ['octavia_tempest_plugin/contrib/test_server/test_server.go'], 'web_link': 'https://opendev.org/openstack/octavia-tempest-plugin/commit/7a47c372cacda1f11dad62d163782b3c912f809b', 'message': 'Add HTTP/2 support to the Go test server\n\nThe HTTPS listener will now also serve HTTP/2 requests.\n\nChange-Id: I75c2d4e78ad56a6338f63073f13655a290353ec2\n'}]",0,758617,7a47c372cacda1f11dad62d163782b3c912f809b,86,8,3,6469,,,0,"Add HTTP/2 support to the Go test server

The HTTPS listener will now also serve HTTP/2 requests.

Change-Id: I75c2d4e78ad56a6338f63073f13655a290353ec2
",git fetch https://review.opendev.org/openstack/octavia-tempest-plugin refs/changes/17/758617/1 && git format-patch -1 --stdout FETCH_HEAD,"['octavia_tempest_plugin/contrib/test_server/test_server.go', 'octavia_tempest_plugin/contrib/test_server/test_server.bin']",2,7df2a41211dc9c17d8118129e49281396e76cb40,http2,,,1,0
openstack%2Fwhitebox-tempest-plugin~master~I14dddb5846b2330811c496aa7c134d020781edb8,openstack/whitebox-tempest-plugin,master,I14dddb5846b2330811c496aa7c134d020781edb8,Remove restart_command config option,MERGED,2020-12-02 21:58:07.000000000,2020-12-03 06:38:12.000000000,2020-12-03 06:38:12.000000000,"[{'_account_id': 8864}, {'_account_id': 11604}, {'_account_id': 22348}, {'_account_id': 28006}]","[{'number': 1, 'created': '2020-12-02 21:58:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/whitebox-tempest-plugin/commit/d4657d70a8aa1420309f82347436100671cea0a0', 'message': 'Remove restart_command config option\n\nIn real life, nothin actually uses that config option. We currently\nsupport nova-compute and libvirt as services, and both only use\nstart_command and stop_command. Libvirt only uses those because it\nneeds to be a stopped for a destructive test, and nova-compute only\nuses those because it implements restart() as a sequence of stop/start\noperations and waits for the service to appear down/up in the services\nAPI at each step.\n\nThis patch removes the restart_command config option entirely, and\nmoves the stop()/start() implementation of restart() into the base\nServiceManager class.\n\nIf we ever actually need to restart a service, we can re-add this\nconfig option in the future.\n\nChange-Id: I14dddb5846b2330811c496aa7c134d020781edb8\n'}, {'number': 2, 'created': '2020-12-03 01:11:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/whitebox-tempest-plugin/commit/9110076605eafc0f85c1f0feda2159b11d339a94', 'message': 'Remove restart_command config option\n\nIn real life, nothing actually uses that config option. We currently\nsupport nova-compute and libvirt as services, and both only use\nstart_command and stop_command. Libvirt only uses those because it\nneeds to be a stopped for a destructive test, and nova-compute only\nuses those because it implements restart() as a sequence of stop/start\noperations and waits for the service to appear down/up in the services\nAPI at each step.\n\nThis patch removes the restart_command config option entirely, and\nmoves the stop()/start() implementation of restart() into the base\nServiceManager class.\n\nIf we ever actually need to restart a service, we can re-add this\nconfig option in the future.\n\nChange-Id: I14dddb5846b2330811c496aa7c134d020781edb8\n'}, {'number': 3, 'created': '2020-12-03 01:12:50.000000000', 'files': ['whitebox_tempest_plugin/services/clients.py', 'whitebox_tempest_plugin/tests/test_clients.py'], 'web_link': 'https://opendev.org/openstack/whitebox-tempest-plugin/commit/4a4d0c6d639681c8224dbed3508acad1748f4d26', 'message': 'Remove restart_command config option\n\nIn real life, nothing actually uses that config option. We currently\nsupport nova-compute and libvirt as services, and both only use\nstart_command and stop_command. Libvirt only uses those because it\nneeds to be stopped for a destructive test, and nova-compute only\nuses those because it implements restart() as a sequence of stop/start\noperations and waits for the service to appear down/up in the services\nAPI at each step.\n\nThis patch removes the restart_command config option entirely, and\nmoves the stop()/start() implementation of restart() into the base\nServiceManager class.\n\nIf we ever actually need to restart a service, we can re-add this\nconfig option in the future.\n\nChange-Id: I14dddb5846b2330811c496aa7c134d020781edb8\n'}]",1,765211,4a4d0c6d639681c8224dbed3508acad1748f4d26,21,4,3,8864,,,0,"Remove restart_command config option

In real life, nothing actually uses that config option. We currently
support nova-compute and libvirt as services, and both only use
start_command and stop_command. Libvirt only uses those because it
needs to be stopped for a destructive test, and nova-compute only
uses those because it implements restart() as a sequence of stop/start
operations and waits for the service to appear down/up in the services
API at each step.

This patch removes the restart_command config option entirely, and
moves the stop()/start() implementation of restart() into the base
ServiceManager class.

If we ever actually need to restart a service, we can re-add this
config option in the future.

Change-Id: I14dddb5846b2330811c496aa7c134d020781edb8
",git fetch https://review.opendev.org/openstack/whitebox-tempest-plugin refs/changes/11/765211/1 && git format-patch -1 --stdout FETCH_HEAD,"['whitebox_tempest_plugin/services/clients.py', 'whitebox_tempest_plugin/tests/test_clients.py']",2,d4657d70a8aa1420309f82347436100671cea0a0,selinux_labels,," # NOTE(artom) There is currently no service that has all 3 start, stop # and restart, so we set up a fake one for testing. CONF.register_opt(cfg.StrOpt('restart_command'), group='whitebox-fake-service') self.flags(restart_command='fake restart command', group='whitebox-fake-service') # Restart service.restart() mock_exec.assert_called_with('fake restart command', sudo=True)",2,15
openstack%2Fdevstack~master~I25dd99d724668ef14f939c65bfc8309f4162fcfc,openstack/devstack,master,I25dd99d724668ef14f939c65bfc8309f4162fcfc,Enabling python3.5 for swift and ironic,ABANDONED,2017-05-16 05:28:01.000000000,2020-12-03 06:10:23.000000000,,"[{'_account_id': 3}, {'_account_id': 10118}, {'_account_id': 10385}, {'_account_id': 12033}, {'_account_id': 16376}]","[{'number': 1, 'created': '2017-05-16 05:28:01.000000000', 'files': ['stackrc'], 'web_link': 'https://opendev.org/openstack/devstack/commit/5fb581856b7e218728e6338295de83bcffd72ca4', 'message': 'Enabling python3.5 for swift and ironic\n\nThis commits enables python3.5 for swift and ironic\nby adding them in ""ENABLED_PYTHON3_PACKAGES""\n\nChange-Id: I25dd99d724668ef14f939c65bfc8309f4162fcfc\n'}]",0,464932,5fb581856b7e218728e6338295de83bcffd72ca4,9,5,1,19604,,,0,"Enabling python3.5 for swift and ironic

This commits enables python3.5 for swift and ironic
by adding them in ""ENABLED_PYTHON3_PACKAGES""

Change-Id: I25dd99d724668ef14f939c65bfc8309f4162fcfc
",git fetch https://review.opendev.org/openstack/devstack refs/changes/32/464932/1 && git format-patch -1 --stdout FETCH_HEAD,['stackrc'],1,5fb581856b7e218728e6338295de83bcffd72ca4,python3.5,"export ENABLED_PYTHON3_PACKAGES=""nova,glance,cinder,uwsgi,python-openstackclient,swift,ironic""","export ENABLED_PYTHON3_PACKAGES=""nova,glance,cinder,uwsgi,python-openstackclient""",1,1
openstack%2Fneutron~master~I0db516b184cf621e4539d11726fe1bd47b53ba05,openstack/neutron,master,I0db516b184cf621e4539d11726fe1bd47b53ba05,Disable not used services in the tempest and rally jobs,MERGED,2020-11-12 21:23:28.000000000,2020-12-03 05:12:23.000000000,2020-12-03 05:06:35.000000000,"[{'_account_id': 8313}, {'_account_id': 11975}, {'_account_id': 13995}, {'_account_id': 15752}, {'_account_id': 16688}, {'_account_id': 22348}, {'_account_id': 26622}]","[{'number': 1, 'created': '2020-11-12 21:23:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/a0364a4af93c0cb053ec86e364fb352cac76fb2e', 'message': ""Disable not used services in the tempest and rally jobs\n\nWe don't need to run Swift, Cinder and etcd services in the\nNeutron jobs so this patch disables those services on all\nsuch jobs defined in the Neutron repository.\nIt will skip some tests which aren't really related to Neutron\nand will safe some resources on test nodes.\n\nThis patch also enables br-ex-tcpdump and br-int-flows services\nin the jobs where it was missing.\nIt may be useful during debugging some failures of those jobs\nin the future.\n\nChange-Id: I0db516b184cf621e4539d11726fe1bd47b53ba05\n""}, {'number': 2, 'created': '2020-11-12 21:31:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/275c59d7bffda89de4398a3dacd869000106ea4f', 'message': ""Disable not used services in the tempest and rally jobs\n\nWe don't need to run Swift, Cinder and etcd services in the\nNeutron jobs so this patch disables those services on all\nsuch jobs defined in the Neutron repository.\nIt will skip some tests which aren't really related to Neutron\nand will safe some resources on test nodes.\n\nThis patch also enables br-ex-tcpdump and br-int-flows services\nin the jobs where it was missing.\nIt may be useful during debugging some failures of those jobs\nin the future.\n\nChange-Id: I0db516b184cf621e4539d11726fe1bd47b53ba05\n""}, {'number': 3, 'created': '2020-11-13 09:13:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/a3dae72720656b9b41040b8bc9947fdb011dc323', 'message': ""Disable not used services in the tempest and rally jobs\n\nWe don't need to run Swift, Cinder and etcd services in the\nNeutron jobs so this patch disables those services on all\nsuch jobs defined in the Neutron repository.\nIt will skip some tests which aren't really related to Neutron\nand will safe some resources on test nodes.\n\nThis patch also enables br-ex-tcpdump and br-int-flows services\nin the jobs where it was missing.\nIt may be useful during debugging some failures of those jobs\nin the future.\n\nDepends-On: https://review.opendev.org/762622\n\nChange-Id: I0db516b184cf621e4539d11726fe1bd47b53ba05\n""}, {'number': 4, 'created': '2020-11-19 22:03:50.000000000', 'files': ['zuul.d/tempest-multinode.yaml', 'zuul.d/rally.yaml', 'zuul.d/tempest-singlenode.yaml'], 'web_link': 'https://opendev.org/openstack/neutron/commit/747ac575249c57fe9fe70413e3a75fe81f18c946', 'message': ""Disable not used services in the tempest and rally jobs\n\nWe don't need to run Swift, Cinder and etcd services in the\nNeutron jobs so this patch disables those services on all\nsuch jobs defined in the Neutron repository.\nIt will skip some tests which aren't really related to Neutron\nand will safe some resources on test nodes.\n\nThis patch also enables br-ex-tcpdump and br-int-flows services\nin the jobs where it was missing.\nIt may be useful during debugging some failures of those jobs\nin the future.\n\nDepends-On: https://review.opendev.org/762622\n\nChange-Id: I0db516b184cf621e4539d11726fe1bd47b53ba05\n""}]",0,762582,747ac575249c57fe9fe70413e3a75fe81f18c946,64,7,4,11975,,,0,"Disable not used services in the tempest and rally jobs

We don't need to run Swift, Cinder and etcd services in the
Neutron jobs so this patch disables those services on all
such jobs defined in the Neutron repository.
It will skip some tests which aren't really related to Neutron
and will safe some resources on test nodes.

This patch also enables br-ex-tcpdump and br-int-flows services
in the jobs where it was missing.
It may be useful during debugging some failures of those jobs
in the future.

Depends-On: https://review.opendev.org/762622

Change-Id: I0db516b184cf621e4539d11726fe1bd47b53ba05
",git fetch https://review.opendev.org/openstack/neutron refs/changes/82/762582/2 && git format-patch -1 --stdout FETCH_HEAD,"['zuul.d/tempest-multinode.yaml', 'zuul.d/rally.yaml', 'zuul.d/tempest-singlenode.yaml']",3,a0364a4af93c0cb053ec86e364fb352cac76fb2e,improve-neutron-ci, # Cinder services c-api: false c-bak: false c-sch: false c-vol: false cinder: false # Swift services s-account: false s-container: false s-object: false s-proxy: false # Cinder services c-api: false c-bak: false c-sch: false c-vol: false cinder: false # Swift services s-account: false s-container: false s-object: false s-proxy: false # Cinder services c-api: false c-bak: false c-sch: false c-vol: false cinder: false # Swift services s-account: false s-container: false s-object: false s-proxy: false devstack_services: br-ex-tcpdump: true br-int-flows: true # Cinder services c-api: false c-bak: false c-sch: false c-vol: false cinder: false # Swift services s-account: false s-container: false s-object: false s-proxy: false devstack_services: br-ex-tcpdump: true br-int-flows: true # Cinder services c-api: false c-bak: false c-sch: false c-vol: false cinder: false # Swift services s-account: false s-container: false s-object: false s-proxy: false # Cinder services c-api: false c-bak: false c-sch: false c-vol: false cinder: false # Swift services s-account: false s-container: false s-object: false s-proxy: false # Cinder services c-api: false c-bak: false c-sch: false c-vol: false cinder: false devstack_services: etcd: false br-ex-tcpdump: true br-int-flows: true # Cinder services c-api: false c-bak: false c-sch: false c-vol: false cinder: false # Swift services s-account: false s-container: false s-object: false s-proxy: false, c-api: true c-sch: true c-vol: true,160,4
openstack%2Ftripleo-heat-templates~master~I4c28c6c90c52f22d4fa81d13e85842ce876ec2b9,openstack/tripleo-heat-templates,master,I4c28c6c90c52f22d4fa81d13e85842ce876ec2b9,Add NovaApiMaxLimit configure max_limit for nova,MERGED,2020-11-13 05:53:09.000000000,2020-12-03 04:10:19.000000000,2020-12-03 04:08:49.000000000,"[{'_account_id': 8833}, {'_account_id': 9816}, {'_account_id': 14985}, {'_account_id': 22348}, {'_account_id': 23181}, {'_account_id': 28223}, {'_account_id': 29268}, {'_account_id': 30073}]","[{'number': 1, 'created': '2020-11-13 05:53:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/e4ab5b3dd556b849de11a57efd4dd0a24004fac6', 'message': ""Add NovaApiMaxLimit configure max_limit for nova\n\nCurrently, we can't set Nova [api]/max_limit\nusing a supplied Heat parameter. This change\nadds a Heat parameter that will make it easier\nfor users to configure max_limit in nova.conf.\n\nChange-Id: I4c28c6c90c52f22d4fa81d13e85842ce876ec2b9\ncloses-bug: 1904096\n""}, {'number': 2, 'created': '2020-11-13 06:21:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/1c0a7ca06c1c9447a722433b85f1f2d5911fa05e', 'message': ""Add NovaApiMaxLimit configure max_limit for nova\n\nCurrently, we can't set Nova [api]/max_limit\nusing a supplied Heat parameter. This change\nadds a Heat parameter that will make it easier\nfor users to configure max_limit in nova.conf.\n\nChange-Id: I4c28c6c90c52f22d4fa81d13e85842ce876ec2b9\ncloses-bug: 1904096\n""}, {'number': 3, 'created': '2020-11-13 06:22:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/0d91e50e8a9cbb60c8b18a08619e5cad4e6154a5', 'message': ""Add NovaApiMaxLimit configure max_limit for nova\n\nCurrently, we can't set Nova [api]/max_limit\nusing a supplied Heat parameter. This change\nadds a Heat parameter that will make it easier\nfor users to configure max_limit in nova.conf.\n\nChange-Id: I4c28c6c90c52f22d4fa81d13e85842ce876ec2b9\ncloses-bug: 1904096\n""}, {'number': 4, 'created': '2020-11-13 07:09:40.000000000', 'files': ['deployment/nova/nova-api-container-puppet.yaml', 'releasenotes/notes/nova_api_max_limit-support-43fe9792eca63599.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/603530c711323d09b68b1a73a5fc7c61cfb6b42a', 'message': ""Add NovaApiMaxLimit configure max_limit for nova\n\nCurrently, we can't set Nova [api]/max_limit\nusing a supplied Heat parameter. This change\nadds a Heat parameter that will make it easier\nfor users to configure max_limit in nova.conf.\n\nChange-Id: I4c28c6c90c52f22d4fa81d13e85842ce876ec2b9\ncloses-bug: 1904096\n""}]",1,762614,603530c711323d09b68b1a73a5fc7c61cfb6b42a,34,8,4,30073,,,0,"Add NovaApiMaxLimit configure max_limit for nova

Currently, we can't set Nova [api]/max_limit
using a supplied Heat parameter. This change
adds a Heat parameter that will make it easier
for users to configure max_limit in nova.conf.

Change-Id: I4c28c6c90c52f22d4fa81d13e85842ce876ec2b9
closes-bug: 1904096
",git fetch https://review.opendev.org/openstack/tripleo-heat-templates refs/changes/14/762614/3 && git format-patch -1 --stdout FETCH_HEAD,['deployment/nova/nova-api-container-puppet.yaml'],1,e4ab5b3dd556b849de11a57efd4dd0a24004fac6,bug/1904096, NovaApiMaxLimit: default: 1000 description: Max number of objects returned per API query type: number nova::api::max_limit: {get_param: NovaApiMaxLimit},,5,0
openstack%2Foctavia~stable%2Fstein~Ic72459dbfe66c86b865526ad239f95d1b1984bc4,openstack/octavia,stable/stein,Ic72459dbfe66c86b865526ad239f95d1b1984bc4,repair the HealthMonitor operating_status,ABANDONED,2020-11-18 10:35:58.000000000,2020-12-03 03:06:30.000000000,,"[{'_account_id': 11628}, {'_account_id': 22348}, {'_account_id': 32644}]","[{'number': 1, 'created': '2020-11-18 10:35:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/octavia/commit/958c474d9f9a1c07e06f0e67a5459f83433ccea6', 'message': 'When the loadbalancer and its subcomponents are successfully created,\nthe HealthMonitor operator_status is OFFLINE.\nI know this is a wrong solution, but I can not find where to deal with it.\n\nChange-Id: Ic72459dbfe66c86b865526ad239f95d1b1984bc4\n'}, {'number': 2, 'created': '2020-11-18 10:40:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/octavia/commit/56a30228fe060f525d48b50f3d2509ba74969186', 'message': 'repair the HealthMonitor operating_status\n\nWhen the loadbalancer and its subcomponents are successfully created,\nthe HealthMonitor operator_status is OFFLINE.\nI know this is a wrong solution, but I can not find where to deal with it.\n\nChange-Id: Ic72459dbfe66c86b865526ad239f95d1b1984bc4\n'}, {'number': 3, 'created': '2020-11-18 10:41:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/octavia/commit/b2235666edc1f1c620920d00e97e909f3a891a8f', 'message': 'repair the HealthMonitor operating_status\n\nWhen the loadbalancer and its subcomponents are successfully created,\nthe HealthMonitor operator_status is OFFLINE.\nI know this is a wrong solution, but I can not find where to deal with it.\n\nChange-Id: Ic72459dbfe66c86b865526ad239f95d1b1984bc4\n'}, {'number': 4, 'created': '2020-11-18 10:47:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/octavia/commit/e923ba31ae57a3545ab30406e47ffd2bc1d52f63', 'message': 'repair the HealthMonitor operating_status\n\nWhen the loadbalancer and its subcomponents are successfully created,\nthe HealthMonitor operator_status is OFFLINE.\nI know this is a wrong solution, but I can not find where to deal with it.\n\nChange-Id: Ic72459dbfe66c86b865526ad239f95d1b1984bc4\n'}, {'number': 5, 'created': '2020-11-19 00:37:35.000000000', 'files': ['octavia/controller/worker/tasks/database_tasks.py'], 'web_link': 'https://opendev.org/openstack/octavia/commit/b677fd6253f1c9fa22db5bc4a3a856eba04c211d', 'message': 'repair the HealthMonitor operating_status\n\nWhen the loadbalancer and its subcomponents are successfully created,\nthe HealthMonitor operator_status is OFFLINE.\nI know this is a wrong solution, but I can not find where to deal with it.\n\nChange-Id: Ic72459dbfe66c86b865526ad239f95d1b1984bc4\n'}]",2,763153,b677fd6253f1c9fa22db5bc4a3a856eba04c211d,12,3,5,32644,,,0,"repair the HealthMonitor operating_status

When the loadbalancer and its subcomponents are successfully created,
the HealthMonitor operator_status is OFFLINE.
I know this is a wrong solution, but I can not find where to deal with it.

Change-Id: Ic72459dbfe66c86b865526ad239f95d1b1984bc4
",git fetch https://review.opendev.org/openstack/octavia refs/changes/53/763153/2 && git format-patch -1 --stdout FETCH_HEAD,['octavia/controller/worker/tasks/database_tasks.py'],1,958c474d9f9a1c07e06f0e67a5459f83433ccea6,s," """""" When the loadbalancer and its subcomponents are created, the health monitor operating_status is office, I know this is a wrong solution, but I can't find where to deal with it. """""" op_status = (constants.ONLINE if hm.enabled else constants.OFFLINE) provisioning_status=status, operating_status=op_status)", provisioning_status=status),8,1
openstack%2Fneutron~master~I53cf2cb73b6569c3eccc7cf6bb14b6711f5b5ef9,openstack/neutron,master,I53cf2cb73b6569c3eccc7cf6bb14b6711f5b5ef9,Bump minimum versions of libraries for secure RBAC,ABANDONED,2020-12-03 02:25:12.000000000,2020-12-03 02:46:36.000000000,,[],"[{'number': 1, 'created': '2020-12-03 02:25:12.000000000', 'files': ['requirements.txt', 'lower-constraints.txt'], 'web_link': 'https://opendev.org/openstack/neutron/commit/ddf3e2d12c1835376f6406b6f82faa9c7feabf40', 'message': ""Bump minimum versions of libraries for secure RBAC\n\nIn order to support more consistent and secure RBAC defaults, we're\nproposing common personas across OpenStack projects for secure RBAC.\nThese personas fulfill the most common usecases for custom policy\nrequests in OpenStack deployments, while making the code more consistent\nacross OpenStack, easier to understand, easier to maintain, and easier\nto modify.\n\nThis commit bumps the minimum requirements needed for libraries to\nunderstand enhanced scope checks. Subsequent patches leverage these\nlibraries in updated policies.\n\nChange-Id: I53cf2cb73b6569c3eccc7cf6bb14b6711f5b5ef9\n""}]",0,765230,ddf3e2d12c1835376f6406b6f82faa9c7feabf40,3,0,1,5046,,,0,"Bump minimum versions of libraries for secure RBAC

In order to support more consistent and secure RBAC defaults, we're
proposing common personas across OpenStack projects for secure RBAC.
These personas fulfill the most common usecases for custom policy
requests in OpenStack deployments, while making the code more consistent
across OpenStack, easier to understand, easier to maintain, and easier
to modify.

This commit bumps the minimum requirements needed for libraries to
understand enhanced scope checks. Subsequent patches leverage these
libraries in updated policies.

Change-Id: I53cf2cb73b6569c3eccc7cf6bb14b6711f5b5ef9
",git fetch https://review.opendev.org/openstack/neutron refs/changes/30/765230/1 && git format-patch -1 --stdout FETCH_HEAD,"['requirements.txt', 'lower-constraints.txt']",2,ddf3e2d12c1835376f6406b6f82faa9c7feabf40,secure-rbac,keystonemiddleware==5.1.0oslo.log==4.3.0oslo.policy==3.6.0,keystonemiddleware==4.17.0oslo.log==4.2.1oslo.policy==1.30.0,6,6
openstack%2Ftempest~master~I30e5446b4afe33d8b60a50813d590c0a91649ad2,openstack/tempest,master,I30e5446b4afe33d8b60a50813d590c0a91649ad2,Change help string to use openstack instead of neutron,MERGED,2020-11-23 19:05:25.000000000,2020-12-03 01:28:11.000000000,2020-12-03 01:26:41.000000000,"[{'_account_id': 8556}, {'_account_id': 20190}, {'_account_id': 22348}, {'_account_id': 22873}]","[{'number': 1, 'created': '2020-11-23 19:05:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/1fa38aa15f7e0873183d10707198ca15f3b1e015', 'message': ""Change help string to use openstack instead of neutron\n\nThe openstack version of 'neutron ext-list' is\n'openstack extension list --network', changed the help\nstring accordingly.  Also changed some minor grammar\nissues in the network section.\n\nTrivialfix\n\nChange-Id: I30e5446b4afe33d8b60a50813d590c0a91649ad2\n""}, {'number': 2, 'created': '2020-11-25 03:28:25.000000000', 'files': ['tempest/config.py'], 'web_link': 'https://opendev.org/openstack/tempest/commit/3d701091463a4e69d9f7135c8a4f9fab0c01390e', 'message': ""Change help string to use openstack instead of neutron\n\nThe openstack version of 'neutron ext-list' is\n'openstack extension list --network', changed the help\nstring accordingly.  Also changed some minor grammar\nissues in the network section.\n\nTrivialfix\n\nChange-Id: I30e5446b4afe33d8b60a50813d590c0a91649ad2\n""}]",0,763833,3d701091463a4e69d9f7135c8a4f9fab0c01390e,36,4,2,1131,,,0,"Change help string to use openstack instead of neutron

The openstack version of 'neutron ext-list' is
'openstack extension list --network', changed the help
string accordingly.  Also changed some minor grammar
issues in the network section.

Trivialfix

Change-Id: I30e5446b4afe33d8b60a50813d590c0a91649ad2
",git fetch https://review.opendev.org/openstack/tempest refs/changes/33/763833/2 && git format-patch -1 --stdout FETCH_HEAD,['tempest/config.py'],1,1fa38aa15f7e0873183d10707198ca15f3b1e015,network-ext-list," help=""Allow the execution of IPv6 tests.""), ""To get the list of extensions run: "" ""'openstack extension list --network'""), ""Empty list indicates all features are disabled. "" ""discoverable through the API.""), ""and ipv6_address_mode."" help=""Does the test environment support changing "" ""port admin state?""), help='Does the test environment support floating_ips?'),"," help=""Allow the execution of IPv6 tests""), ""To get the list of extensions run: 'neutron ext-list'""), ""Empty list indicates all features are disabled."" ""discoverable through API.""), ""and ipv6_address_mode"" help=""Does the test environment support changing"" "" port admin state""), help='Does the test environment support floating_ips'),",9,8
openstack%2Fneutron~master~Idae12136e043031485694b95f8102e9f301094cc,openstack/neutron,master,Idae12136e043031485694b95f8102e9f301094cc,Migrate to new engine facade in the L3 extension UT module,MERGED,2020-12-01 10:27:35.000000000,2020-12-03 01:27:18.000000000,2020-12-01 21:02:01.000000000,"[{'_account_id': 1131}, {'_account_id': 16688}, {'_account_id': 22348}]","[{'number': 1, 'created': '2020-12-01 10:27:35.000000000', 'files': ['neutron/tests/unit/extensions/test_l3.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/23738d0df76862256ef0596f7e59d95f0d6ab06a', 'message': 'Migrate to new engine facade in the L3 extension UT module\n\nPartially-Implements blueprint: enginefacade-switch\n\nChange-Id: Idae12136e043031485694b95f8102e9f301094cc\n'}]",0,764924,23738d0df76862256ef0596f7e59d95f0d6ab06a,10,3,1,11975,,,0,"Migrate to new engine facade in the L3 extension UT module

Partially-Implements blueprint: enginefacade-switch

Change-Id: Idae12136e043031485694b95f8102e9f301094cc
",git fetch https://review.opendev.org/openstack/neutron refs/changes/24/764924/1 && git format-patch -1 --stdout FETCH_HEAD,['neutron/tests/unit/extensions/test_l3.py'],1,23738d0df76862256ef0596f7e59d95f0d6ab06a,bp/enginefacade-switch, with db_api.CONTEXT_WRITER.using(context):, session = context.session with session.begin(subtransactions=True):,1,2
openstack%2Ftrove~master~I3d8cfd57278ba426067f0631d63c02f2b73dcbf4,openstack/trove,master,I3d8cfd57278ba426067f0631d63c02f2b73dcbf4,Fixup zuul nodetype for nested,MERGED,2020-12-02 01:12:00.000000000,2020-12-03 01:08:01.000000000,2020-12-03 01:03:26.000000000,"[{'_account_id': 6732}, {'_account_id': 22348}]","[{'number': 1, 'created': '2020-12-02 01:12:00.000000000', 'files': ['.zuul.yaml'], 'web_link': 'https://opendev.org/openstack/trove/commit/25abf125ef1d751a34793ea7bcc92c03f926c152', 'message': 'Fixup zuul nodetype for nested\n\nNeed tempest group to get tempest jobs to work\n\nChange-Id: I3d8cfd57278ba426067f0631d63c02f2b73dcbf4\n'}]",0,765029,25abf125ef1d751a34793ea7bcc92c03f926c152,7,2,1,3031,,,0,"Fixup zuul nodetype for nested

Need tempest group to get tempest jobs to work

Change-Id: I3d8cfd57278ba426067f0631d63c02f2b73dcbf4
",git fetch https://review.opendev.org/openstack/trove refs/changes/29/765029/1 && git format-patch -1 --stdout FETCH_HEAD,['.zuul.yaml'],1,25abf125ef1d751a34793ea7bcc92c03f926c152,, - name: tempest, - name: controller,1,1
openstack%2Fmagnum~master~I789fac4a3e273d10c58963aa92b8490f5c67bfe0,openstack/magnum,master,I789fac4a3e273d10c58963aa92b8490f5c67bfe0,Update helm charts origin repository,MERGED,2020-11-09 12:09:02.000000000,2020-12-03 00:03:33.000000000,2020-12-03 00:02:11.000000000,"[{'_account_id': 6484}, {'_account_id': 20498}, {'_account_id': 22348}, {'_account_id': 29425}]","[{'number': 1, 'created': '2020-11-09 12:09:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/magnum/commit/b0f74df368da7944619739cbef694f8de9444078', 'message': 'Update helm charts origin repository\n\nTask: 41233\nStory: 2008332\nChange-Id: I789fac4a3e273d10c58963aa92b8490f5c67bfe0\nSigned-off-by: Diogo Guerra <diogo.filipe.tomas.guerra@cern.ch>\n'}, {'number': 2, 'created': '2020-11-09 12:15:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/magnum/commit/fc72bc9469a97fdbd0d6819051870f2734e5025e', 'message': 'Update helm charts origin repository\n\nUpdated helm chart origins for:\nnginx, prometheus-operator, metrics-server, prometheus-adapter\nTriggered by:\nhttps://helm.sh/blog/2019-10-22-helm-2150-released/#helm-2-support-plan\nhttps://github.com/helm/charts#status-of-the-project\n\nTask: 41233\nStory: 2008332\nChange-Id: I789fac4a3e273d10c58963aa92b8490f5c67bfe0\nSigned-off-by: Diogo Guerra <diogo.filipe.tomas.guerra@cern.ch>\n'}, {'number': 3, 'created': '2020-11-09 16:40:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/magnum/commit/0c4f62af65ea66b6deaf4dd62ba5dded630a0787', 'message': 'Update helm charts origin repository\n\nUpdated helm chart origins for:\nnginx, prometheus-operator, metrics-server, prometheus-adapter\nTriggered by:\nhttps://helm.sh/blog/2019-10-22-helm-2150-released/#helm-2-support-plan\nhttps://github.com/helm/charts#status-of-the-project\n\nTask: 41233\nStory: 2008332\nChange-Id: I789fac4a3e273d10c58963aa92b8490f5c67bfe0\nSigned-off-by: Diogo Guerra <diogo.filipe.tomas.guerra@cern.ch>\n'}, {'number': 4, 'created': '2020-11-30 08:45:20.000000000', 'files': ['magnum/drivers/common/templates/kubernetes/helm/prometheus-operator.sh', 'magnum/drivers/common/templates/kubernetes/helm/metrics-server.sh', 'magnum/drivers/common/templates/kubernetes/helm/ingress-nginx.sh', 'magnum/drivers/common/templates/kubernetes/helm/prometheus-adapter.sh'], 'web_link': 'https://opendev.org/openstack/magnum/commit/333331b743c5ee8fba9d3530af7ef641c3219643', 'message': 'Update helm charts origin repository\n\nUpdated helm chart origins for:\nnginx, prometheus-operator, metrics-server, prometheus-adapter\nTriggered by:\nhttps://helm.sh/blog/2019-10-22-helm-2150-released/#helm-2-support-plan\nhttps://github.com/helm/charts#status-of-the-project\n\nTask: 41233\nStory: 2008332\nChange-Id: I789fac4a3e273d10c58963aa92b8490f5c67bfe0\nSigned-off-by: Diogo Guerra <diogo.filipe.tomas.guerra@cern.ch>\n'}]",1,761899,333331b743c5ee8fba9d3530af7ef641c3219643,23,4,4,29425,,,0,"Update helm charts origin repository

Updated helm chart origins for:
nginx, prometheus-operator, metrics-server, prometheus-adapter
Triggered by:
https://helm.sh/blog/2019-10-22-helm-2150-released/#helm-2-support-plan
https://github.com/helm/charts#status-of-the-project

Task: 41233
Story: 2008332
Change-Id: I789fac4a3e273d10c58963aa92b8490f5c67bfe0
Signed-off-by: Diogo Guerra <diogo.filipe.tomas.guerra@cern.ch>
",git fetch https://review.opendev.org/openstack/magnum refs/changes/99/761899/2 && git format-patch -1 --stdout FETCH_HEAD,"['magnum/drivers/common/templates/kubernetes/helm/prometheus-operator.sh', 'magnum/drivers/common/templates/kubernetes/helm/ingress-nginx.sh', 'magnum/drivers/common/templates/kubernetes/helm/prometheus-adapter.sh']",3,b0f74df368da7944619739cbef694f8de9444078,helm, repository: https://prometheus-community.github.io/helm-charts, repository: https://kubernetes-charts.storage.googleapis.com/,3,3
openstack%2Fironic~master~I01608004ce90facadb73e252203900a1e62cbea1,openstack/ironic,master,I01608004ce90facadb73e252203900a1e62cbea1,JSON conversion followup change,MERGED,2020-11-18 22:06:55.000000000,2020-12-02 23:40:42.000000000,2020-12-02 23:38:09.000000000,"[{'_account_id': 4571}, {'_account_id': 10239}, {'_account_id': 11076}, {'_account_id': 19339}, {'_account_id': 22348}]","[{'number': 1, 'created': '2020-11-18 22:06:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/9a3a0ba32183d09add3085d80f6df7067f91dd0b', 'message': 'JSON conversion followup change\n\nThis change addresses nit-level review comments from this task.\n\nStory: 1651346\nTask: 10551\nChange-Id: I01608004ce90facadb73e252203900a1e62cbea1\n'}, {'number': 2, 'created': '2020-11-23 04:11:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/a8b5413d45bd61bb711699f117987fe3b5869c43', 'message': 'JSON conversion followup change\n\nThis change addresses nit-level review comments from this task.\n\nStory: 1651346\nTask: 10551\nChange-Id: I01608004ce90facadb73e252203900a1e62cbea1\n'}, {'number': 3, 'created': '2020-11-24 02:05:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/617ab4ae3872f221a47bd385bffb041c189a3f0d', 'message': 'JSON conversion followup change\n\nThis change addresses nit-level review comments from this task.\n\nStory: 1651346\nTask: 10551\nChange-Id: I01608004ce90facadb73e252203900a1e62cbea1\n'}, {'number': 4, 'created': '2020-11-25 22:15:05.000000000', 'files': ['ironic/tests/unit/api/controllers/v1/test_utils.py', 'ironic/api/controllers/v1/collection.py', 'ironic/api/controllers/v1/driver.py', 'ironic/api/controllers/v1/event.py', 'ironic/tests/unit/common/test_args.py', 'ironic/common/args.py', 'ironic/tests/unit/api/controllers/v1/test_node.py', 'ironic/tests/unit/api/controllers/v1/test_driver.py', 'ironic/api/controllers/v1/allocation.py', 'ironic/api/method.py', 'ironic/common/exception.py', 'ironic/api/controllers/v1/deploy_template.py', 'ironic/api/controllers/v1/utils.py', 'ironic/api/controllers/v1/node.py'], 'web_link': 'https://opendev.org/openstack/ironic/commit/e41893c9d085b4883366db65b9a74104f1949e1d', 'message': 'JSON conversion followup change\n\nThis change addresses nit-level review comments from this task.\n\nStory: 1651346\nTask: 10551\nChange-Id: I01608004ce90facadb73e252203900a1e62cbea1\n'}]",7,763279,e41893c9d085b4883366db65b9a74104f1949e1d,25,5,4,4571,,,0,"JSON conversion followup change

This change addresses nit-level review comments from this task.

Story: 1651346
Task: 10551
Change-Id: I01608004ce90facadb73e252203900a1e62cbea1
",git fetch https://review.opendev.org/openstack/ironic refs/changes/79/763279/1 && git format-patch -1 --stdout FETCH_HEAD,"['ironic/tests/unit/api/controllers/v1/test_utils.py', 'ironic/api/controllers/v1/collection.py', 'ironic/api/controllers/v1/driver.py', 'ironic/api/controllers/v1/event.py', 'ironic/common/args.py', 'ironic/tests/unit/api/controllers/v1/test_node.py', 'ironic/tests/unit/api/controllers/v1/test_driver.py', 'ironic/api/controllers/v1/allocation.py', 'ironic/api/method.py', 'ironic/common/exception.py', 'ironic/api/controllers/v1/deploy_template.py', 'ironic/api/controllers/v1/utils.py', 'ironic/api/controllers/v1/node.py']",13,9a3a0ba32183d09add3085d80f6df7067f91dd0b,story/1651346,," # NOTE(derekh): mask ssh keys for the ssh power driver. # As this driver is deprecated masking here (opposed to strutils) # is simpler, and easier to backport. This can be removed along # with support for the ssh power driver. if node['driver_info'].get('ssh_key_contents'): node['driver_info']['ssh_key_contents'] = ""******"" ",26,70
openstack%2Fpython-designateclient~master~I8244e13303646e6686e4233e1edbd2bbc788e054,openstack/python-designateclient,master,I8244e13303646e6686e4233e1edbd2bbc788e054,Add choices to `--type` command line argument,MERGED,2020-09-25 14:51:23.000000000,2020-12-02 23:26:46.000000000,2020-12-02 23:25:25.000000000,"[{'_account_id': 11628}, {'_account_id': 19298}, {'_account_id': 22348}, {'_account_id': 22623}, {'_account_id': 32438}]","[{'number': 1, 'created': '2020-09-25 14:51:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-designateclient/commit/3830e83a3b089e34a4bd2a4a5f2f24b008202628', 'message': 'Add choices to `--type` command line argument\n\nWe only allow `PRIMARY` and `SECONDARY` zones. Instead of testing for\neither one of those two choices later in the code, we can offload this\ntest to the parser.\n\nChange-Id: I8244e13303646e6686e4233e1edbd2bbc788e054\nSigned-off-by: Nicolas Bock <nicolas.bock@canonical.com>\n'}, {'number': 2, 'created': '2020-10-03 13:37:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-designateclient/commit/cc5de037eb6fb039cc3721063dc7c8c284d8c1e3', 'message': 'Add choices to `--type` command line argument\n\nWe only allow `PRIMARY` and `SECONDARY` zones. Instead of testing for\neither one of those two choices later in the code, we can offload this\ntest to the parser.\n\nChange-Id: I8244e13303646e6686e4233e1edbd2bbc788e054\nSigned-off-by: Nicolas Bock <nicolas.bock@canonical.com>\n'}, {'number': 3, 'created': '2020-10-03 13:44:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-designateclient/commit/88d6f09810720cd8cf6bbb888c21e835d3c3f190', 'message': 'Add choices to `--type` command line argument\n\nWe only allow `PRIMARY` and `SECONDARY` zones. Instead of testing for\neither one of those two choices later in the code, we can offload this\ntest to the parser.\n\nChange-Id: I8244e13303646e6686e4233e1edbd2bbc788e054\nDepends-On: If7afefde0f33161016a27774021d27239c642eb5\nSigned-off-by: Nicolas Bock <nicolas.bock@canonical.com>\n'}, {'number': 4, 'created': '2020-10-06 18:32:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-designateclient/commit/c5bcb83aff088cfa257065173ec18747e7417468', 'message': 'Add choices to `--type` command line argument\n\nWe only allow `PRIMARY` and `SECONDARY` zones. Instead of testing for\neither one of those two choices later in the code, we can offload this\ntest to the parser.\n\nChange-Id: I8244e13303646e6686e4233e1edbd2bbc788e054\nDepends-On: If7afefde0f33161016a27774021d27239c642eb5\nDepends-On: Ie075e8d214e0131cf6c004875dde9b9490f6e19b\nSigned-off-by: Nicolas Bock <nicolas.bock@canonical.com>\n'}, {'number': 5, 'created': '2020-10-12 22:04:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-designateclient/commit/8b5fa7dc559857ba818142d471e701f0fbcd159f', 'message': 'Add choices to `--type` command line argument\n\nWe only allow `PRIMARY` and `SECONDARY` zones. Instead of testing for\neither one of those two choices later in the code, we can offload this\ntest to the parser.\n\nChange-Id: I8244e13303646e6686e4233e1edbd2bbc788e054\nDepends-On: If7afefde0f33161016a27774021d27239c642eb5\nDepends-On: Ie075e8d214e0131cf6c004875dde9b9490f6e19b\nSigned-off-by: Nicolas Bock <nicolas.bock@canonical.com>\n'}, {'number': 6, 'created': '2020-10-13 12:34:14.000000000', 'files': ['designateclient/v2/cli/zones.py'], 'web_link': 'https://opendev.org/openstack/python-designateclient/commit/b68b70a097fd9b968407f253c8eaf91c76ff0fd1', 'message': 'Add choices to `--type` command line argument\n\nWe only allow `PRIMARY` and `SECONDARY` zones. Instead of testing for\neither one of those two choices later in the code, we can offload this\ntest to the parser.\n\nChange-Id: I8244e13303646e6686e4233e1edbd2bbc788e054\nSigned-off-by: Nicolas Bock <nicolas.bock@canonical.com>\n'}]",0,754415,b68b70a097fd9b968407f253c8eaf91c76ff0fd1,29,5,6,19298,,,0,"Add choices to `--type` command line argument

We only allow `PRIMARY` and `SECONDARY` zones. Instead of testing for
either one of those two choices later in the code, we can offload this
test to the parser.

Change-Id: I8244e13303646e6686e4233e1edbd2bbc788e054
Signed-off-by: Nicolas Bock <nicolas.bock@canonical.com>
",git fetch https://review.opendev.org/openstack/python-designateclient refs/changes/15/754415/1 && git format-patch -1 --stdout FETCH_HEAD,['designateclient/v2/cli/zones.py'],1,3830e83a3b089e34a4bd2a4a5f2f24b008202628,zone_type," parser.add_argument('--type', help=""Zone Type"", choices=[""PRIMARY"", ""SECONDARY""], required=False) parser.add_argument('--type', help=""Zone Type"", choices=[""PRIMARY"", ""SECONDARY""], default='PRIMARY')"," parser.add_argument('--type', help=""Zone Type"", required=False) parser.add_argument('--type', help=""Zone Type"", default='PRIMARY')",6,2
openstack%2Ftrove~master~I4ead112d337d393034db1f080938a8d4942e2d73,openstack/trove,master,I4ead112d337d393034db1f080938a8d4942e2d73,Add support for python 3.8,MERGED,2020-12-02 11:40:26.000000000,2020-12-02 23:08:04.000000000,2020-12-02 23:06:38.000000000,"[{'_account_id': 3031}, {'_account_id': 6732}, {'_account_id': 22348}]","[{'number': 1, 'created': '2020-12-02 11:40:26.000000000', 'files': ['lower-constraints.txt'], 'web_link': 'https://opendev.org/openstack/trove/commit/7a5e94f63c26e02e175af6b4470fa3bac230626d', 'message': 'Add support for python 3.8\n\nIntroduce support of python 3.8 [1] and move tox and jobs to py38.\npyopenssl 19.1.0 [2] support python 3.8\n\n[1] https://governance.openstack.org/tc/reference/runtimes/victoria.html#python-runtimes-for-victoria\n[2] https://pypi.org/project/pyOpenSSL/19.1.0/\n\nChange-Id: I4ead112d337d393034db1f080938a8d4942e2d73\n'}]",0,765123,7a5e94f63c26e02e175af6b4470fa3bac230626d,8,3,1,32029,,,0,"Add support for python 3.8

Introduce support of python 3.8 [1] and move tox and jobs to py38.
pyopenssl 19.1.0 [2] support python 3.8

[1] https://governance.openstack.org/tc/reference/runtimes/victoria.html#python-runtimes-for-victoria
[2] https://pypi.org/project/pyOpenSSL/19.1.0/

Change-Id: I4ead112d337d393034db1f080938a8d4942e2d73
",git fetch https://review.opendev.org/openstack/trove refs/changes/23/765123/1 && git format-patch -1 --stdout FETCH_HEAD,['lower-constraints.txt'],1,7a5e94f63c26e02e175af6b4470fa3bac230626d,py38,pyOpenSSL==19.1.0,pyOpenSSL==17.5.0,1,1
openstack%2Fpython-openstackclient~master~Iae3b6d0b56ebd2bbbb94f9f3637b5086e75559a7,openstack/python-openstackclient,master,Iae3b6d0b56ebd2bbbb94f9f3637b5086e75559a7,Add documentation about login with federation,MERGED,2019-11-06 19:10:30.000000000,2020-12-02 22:57:40.000000000,2020-12-02 22:55:55.000000000,"[{'_account_id': 841}, {'_account_id': 11904}, {'_account_id': 15334}, {'_account_id': 22348}, {'_account_id': 27900}, {'_account_id': 28356}, {'_account_id': 30695}]","[{'number': 1, 'created': '2019-11-06 19:10:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-openstackclient/commit/115a9b9fed5e44793859e22b9b28b028f8488056', 'message': 'Add documentation about login with federation\n\nThe documentation presents the parameters necessary\nto authenticate via federation (using password) and do\na brief description of each parameter used in the process.\n\nDepends-On: https://review.opendev.org/#/c/692140/\nChange-Id: Iae3b6d0b56ebd2bbbb94f9f3637b5086e75559a7\n'}, {'number': 2, 'created': '2019-12-27 13:29:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-openstackclient/commit/cd7d18a89f4be3629cc76342fb2b082721cab5d2', 'message': 'Add documentation about login with federation\n\nThe documentation presents the parameters necessary\nto authenticate via federation (using password) and do\na brief description of each parameter used in the process.\n\nChange-Id: Iae3b6d0b56ebd2bbbb94f9f3637b5086e75559a7\n'}, {'number': 3, 'created': '2020-01-20 19:55:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-openstackclient/commit/72276e26629411379998f795f3efef8f2896ec9f', 'message': 'Add documentation about login with federation\n\nThe documentation presents the parameters necessary\nto authenticate via federation (using password) and do\na brief description of each parameter used in the process.\n\nChange-Id: Iae3b6d0b56ebd2bbbb94f9f3637b5086e75559a7\n'}, {'number': 4, 'created': '2020-06-16 21:07:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-openstackclient/commit/40c3cf6a90203fd425cfa7464857527484645ff5', 'message': 'Add documentation about login with federation\n\nThe documentation presents the parameters necessary\nto authenticate via federation (using password) and do\na brief description of each parameter used in the process.\n\nChange-Id: Iae3b6d0b56ebd2bbbb94f9f3637b5086e75559a7\n'}, {'number': 5, 'created': '2020-06-16 21:18:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-openstackclient/commit/43c5e29006e840b928691a7ed58f20f9076cfb27', 'message': 'Add documentation about login with federation\n\nThe documentation presents the parameters necessary\nto authenticate via federation (using password) and do\na brief description of each parameter used in the process.\n\nChange-Id: Iae3b6d0b56ebd2bbbb94f9f3637b5086e75559a7\n'}, {'number': 6, 'created': '2020-06-16 22:37:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-openstackclient/commit/2393283e878ca7dcf968d35403ab425588b3594d', 'message': 'Add documentation about login with federation\n\nThe documentation presents the parameters necessary\nto authenticate via federation (using password) and do\na brief description of each parameter used in the process.\n\nDepends-On: https://review.opendev.org/#/c/736032/\nChange-Id: Iae3b6d0b56ebd2bbbb94f9f3637b5086e75559a7\n'}, {'number': 7, 'created': '2020-12-01 13:00:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-openstackclient/commit/ea68583fba9242cfdd436bb2676b1d400ce8a880', 'message': 'Add documentation about login with federation\n\nThe documentation presents the parameters necessary\nto authenticate via federation (using password) and do\na brief description of each parameter used in the process.\n\nDepends-On: https://review.opendev.org/#/c/736032/\nChange-Id: Iae3b6d0b56ebd2bbbb94f9f3637b5086e75559a7\n'}, {'number': 8, 'created': '2020-12-01 16:23:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-openstackclient/commit/99859069c94d022cf25edf9b276d9b153fde355e', 'message': 'Add documentation about login with federation\n\nThe documentation presents the parameters necessary\nto authenticate via federation (using password) and do\na brief description of each parameter used in the process.\n\nDepends-On: https://review.opendev.org/#/c/736032/\nChange-Id: Iae3b6d0b56ebd2bbbb94f9f3637b5086e75559a7\n'}, {'number': 9, 'created': '2020-12-01 18:36:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-openstackclient/commit/f80d0aed9c6ca814b8dcd673ae3e7a07afab9226', 'message': 'Add documentation about login with federation\n\nThe documentation presents the parameters necessary\nto authenticate via federation (using password) and do\na brief description of each parameter used in the process.\n\nDepends-On: https://review.opendev.org/#/c/736032/\nChange-Id: Iae3b6d0b56ebd2bbbb94f9f3637b5086e75559a7\n'}, {'number': 10, 'created': '2020-12-02 11:43:02.000000000', 'files': ['doc/source/cli/man/openstack.rst', 'doc/source/cli/authentication.rst', 'README.rst'], 'web_link': 'https://opendev.org/openstack/python-openstackclient/commit/d688cb58a3a21ce5fbb5edf4e4feaae9998cb21c', 'message': 'Add documentation about login with federation\n\nThe documentation presents the parameters necessary\nto authenticate via federation (using password) and do\na brief description of each parameter used in the process.\n\nChange-Id: Iae3b6d0b56ebd2bbbb94f9f3637b5086e75559a7\n'}]",70,693232,d688cb58a3a21ce5fbb5edf4e4feaae9998cb21c,44,7,10,30695,,,0,"Add documentation about login with federation

The documentation presents the parameters necessary
to authenticate via federation (using password) and do
a brief description of each parameter used in the process.

Change-Id: Iae3b6d0b56ebd2bbbb94f9f3637b5086e75559a7
",git fetch https://review.opendev.org/openstack/python-openstackclient refs/changes/32/693232/8 && git format-patch -1 --stdout FETCH_HEAD,"['doc/source/configuration/federation/parameters.rst', 'README.rst']",2,115a9b9fed5e44793859e22b9b28b028f8488056,upstream/doc/add-documentation-about-login-using-federation,"Authentication using username/password is most commonly used: - For a local user, your configuration will looks like the below:: export OS_AUTH_URL=<url-to-openstack-identity> export OS_IDENTITY_API_VERSION=3 export OS_PROJECT_NAME=<project-name> export OS_PROJECT_DOMAIN_NAME=<project-domain-name> export OS_USERNAME=<username> export OS_USER_DOMAIN_NAME=<user-domain-name> export OS_PASSWORD=<password> # (optional) The corresponding command-line options look very similar:: --os-auth-url <url> --os-identity-api-version 3 --os-project-name <project-name> --os-project-domain-name <project-domain-name> --os-username <username> --os-user-domain-name <user-domain-name> [--os-password <password>] - For a federated user, please check the federation user `documentation. <doc/source/configuration/federation/parameters.rst>`_",Authentication using username/password is most commonly used:: export OS_AUTH_URL=<url-to-openstack-identity> export OS_IDENTITY_API_VERSION=3 export OS_PROJECT_NAME=<project-name> export OS_PROJECT_DOMAIN_NAME=<project-domain-name> export OS_USERNAME=<username> export OS_USER_DOMAIN_NAME=<user-domain-name> export OS_PASSWORD=<password> # (optional) The corresponding command-line options look very similar:: --os-auth-url <url> --os-identity-api-version 3 --os-project-name <project-name> --os-project-domain-name <project-domain-name> --os-username <username> --os-user-domain-name <user-domain-name> [--os-password <password>],197,16
openstack%2Fglance~master~I78ec79f97bfdcc39772448296140f8d8f35adea1,openstack/glance,master,I78ec79f97bfdcc39772448296140f8d8f35adea1,Remove 'admin_role' option,MERGED,2020-11-25 01:35:47.000000000,2020-12-02 22:57:39.000000000,2020-12-02 22:55:50.000000000,"[{'_account_id': 5046}, {'_account_id': 9303}, {'_account_id': 11904}, {'_account_id': 22348}, {'_account_id': 32171}]","[{'number': 1, 'created': '2020-11-25 01:35:47.000000000', 'files': ['releasenotes/notes/remove-admin_role-f508754e98331fc4.yaml', 'glance/tests/functional/__init__.py', 'glance/api/middleware/context.py', 'doc/source/admin/authentication.rst', 'glance/tests/unit/test_context_middleware.py'], 'web_link': 'https://opendev.org/openstack/glance/commit/f102b74a285ad7de90c99ee7f5d6bef6e0d46161', 'message': ""Remove 'admin_role' option\n\nThis option was deprecated in the Ussuri release by change\nI0f61f85a0aaa4f68e345fa08fbb6b039d3d32587 and it is now eligible\nfor removal following the standard OpenStack deprecation policy.\n\nChange-Id: I78ec79f97bfdcc39772448296140f8d8f35adea1\n""}]",5,764107,f102b74a285ad7de90c99ee7f5d6bef6e0d46161,15,5,1,5314,,,0,"Remove 'admin_role' option

This option was deprecated in the Ussuri release by change
I0f61f85a0aaa4f68e345fa08fbb6b039d3d32587 and it is now eligible
for removal following the standard OpenStack deprecation policy.

Change-Id: I78ec79f97bfdcc39772448296140f8d8f35adea1
",git fetch https://review.opendev.org/openstack/glance refs/changes/07/764107/1 && git format-patch -1 --stdout FETCH_HEAD,"['releasenotes/notes/remove-admin_role-f508754e98331fc4.yaml', 'glance/tests/functional/__init__.py', 'glance/api/middleware/context.py', 'doc/source/admin/authentication.rst', 'glance/tests/unit/test_context_middleware.py']",5,f102b74a285ad7de90c99ee7f5d6bef6e0d46161,remove_admin_role_opt," # the admin_role config option was removed in Wallaby from oslo_config.cfg import NoSuchOptError self.assertRaises(NoSuchOptError, self.config, admin_role='role1') self.assertIn('role1', req.context.roles)"," # if we change the admin_role attribute, we should be able to use it req = self._build_request() self.config(admin_role='role1') self._build_middleware().process_request(req) self.assertTrue(req.context.is_admin) # accept role from config req = self._build_request(roles=['role1']) self.config(admin_role='rOLe1') self._build_middleware().process_request(req) self.assertTrue(req.context.is_admin) self.config(admin_role='role1') self.assertTrue(req.context.is_admin) # stripping extra spaces in config req = self._build_request(roles=['\trole1\n']) self.config(admin_role=' role1\t') self._build_middleware().process_request(req) self.assertTrue(req.context.is_admin)",12,64
openstack%2Ftrove-dashboard~master~I1b692d7765bfd92dd255e0545b10e7325758935b,openstack/trove-dashboard,master,I1b692d7765bfd92dd255e0545b10e7325758935b,Add Backup Strategies table,MERGED,2020-12-02 20:00:21.000000000,2020-12-02 22:31:51.000000000,2020-12-02 22:31:51.000000000,"[{'_account_id': 6732}, {'_account_id': 22348}]","[{'number': 1, 'created': '2020-12-02 20:00:21.000000000', 'files': ['trove_dashboard/content/backup_strategies/tables.py', 'trove_dashboard/content/backup_strategies/urls.py', 'trove_dashboard/content/backup_strategies/templates/backup_strategies/index.html', 'trove_dashboard/content/backup_strategies/panel.py', 'trove_dashboard/content/backup_strategies/views.py'], 'web_link': 'https://opendev.org/openstack/trove-dashboard/commit/a266b4bed558d9da71f371eb88c2d356dbdff70e', 'message': 'Add Backup Strategies table\n\nCommit 2c13af259a39c15e749580ee83598d90cd7f193c has missed files\nwich are added now.\n\nChange-Id: I1b692d7765bfd92dd255e0545b10e7325758935b\n'}]",0,765200,a266b4bed558d9da71f371eb88c2d356dbdff70e,6,2,1,1736,,,0,"Add Backup Strategies table

Commit 2c13af259a39c15e749580ee83598d90cd7f193c has missed files
wich are added now.

Change-Id: I1b692d7765bfd92dd255e0545b10e7325758935b
",git fetch https://review.opendev.org/openstack/trove-dashboard refs/changes/00/765200/1 && git format-patch -1 --stdout FETCH_HEAD,"['trove_dashboard/content/backup_strategies/tables.py', 'trove_dashboard/content/backup_strategies/urls.py', 'trove_dashboard/content/backup_strategies/templates/backup_strategies/index.html', 'trove_dashboard/content/backup_strategies/panel.py', 'trove_dashboard/content/backup_strategies/views.py']",5,a266b4bed558d9da71f371eb88c2d356dbdff70e,bak-strategy,"# Copyright 2013 Rackspace Hosting # # Licensed under the Apache License, Version 2.0 (the ""License""); you may # not use this file except in compliance with the License. You may obtain # a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT # WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the # License for the specific language governing permissions and limitations # under the License. """""" Views for displaying database backups. """""" from django.utils.translation import ugettext_lazy as _ from horizon import exceptions from horizon import tables as horizon_tables from trove_dashboard import api from trove_dashboard.content.backup_strategies import tables class IndexView(horizon_tables.DataTableView): table_class = tables.BackupStrategiesTable template_name = 'project/backup_strategies/index.html' page_title = _(""Backup Strategies"") def get_data(self): try: backups = api.trove.backup_strategy_list(self.request) except Exception: backups = [] msg = _('Error getting backup strategies list.') exceptions.handle(self.request, msg) return backups ",,154,0
openstack%2Fcinder~stable%2Ftrain~I6c7c94528ee94183c1df21c25388505b28f1781a,openstack/cinder,stable/train,I6c7c94528ee94183c1df21c25388505b28f1781a,PowerMax Driver - Safeguarding retype to some in-use replicated modes,MERGED,2020-10-09 09:14:15.000000000,2020-12-02 21:32:34.000000000,2020-11-19 21:03:20.000000000,"[{'_account_id': 1736}, {'_account_id': 7198}, {'_account_id': 10118}, {'_account_id': 11904}, {'_account_id': 12032}, {'_account_id': 12369}, {'_account_id': 12670}, {'_account_id': 15386}, {'_account_id': 22348}, {'_account_id': 22510}, {'_account_id': 23613}, {'_account_id': 24921}, {'_account_id': 25243}, {'_account_id': 26077}, {'_account_id': 26537}, {'_account_id': 27615}, {'_account_id': 28801}, {'_account_id': 31939}, {'_account_id': 31981}]","[{'number': 1, 'created': '2020-10-09 09:14:15.000000000', 'files': ['cinder/volume/drivers/dell_emc/powermax/iscsi.py', 'cinder/volume/drivers/dell_emc/powermax/provision.py', 'cinder/volume/drivers/dell_emc/powermax/common.py', 'cinder/volume/drivers/dell_emc/powermax/metadata.py', 'cinder/tests/unit/volume/drivers/dell_emc/powermax/test_powermax_utils.py', 'cinder/tests/unit/volume/drivers/dell_emc/powermax/test_powermax_provision.py', 'cinder/volume/drivers/dell_emc/powermax/rest.py', 'cinder/tests/unit/volume/drivers/dell_emc/powermax/test_powermax_common.py', 'releasenotes/notes/powermax-disable-inuse-metro-89e9f398ec9e2672.yaml', 'cinder/volume/drivers/dell_emc/powermax/utils.py', 'cinder/tests/unit/volume/drivers/dell_emc/powermax/test_powermax_replication.py', 'cinder/volume/drivers/dell_emc/powermax/fc.py', 'cinder/tests/unit/volume/drivers/dell_emc/powermax/powermax_data.py'], 'web_link': 'https://opendev.org/openstack/cinder/commit/fa48c21fba30c6d44ee9b96b8d657575e207e15c', 'message': 'PowerMax Driver - Safeguarding retype to some in-use replicated modes\n\nHost assisted migration is a better option for retyping from a non-replicated\nto a replicated (Asynchronous and Metro) modes.\n\n1. Block in-use non-replicated to replicated(Metro and Asynchronous)\n2. Remove any unused code\n3. Differentiate between the production and the management storage groups\n4. Remove rollback code on a cleanup_lun, its not necessary on delete and\n    will not always work\n5. Allow for a target device not to exist on the target array\n6. Fix minor issue on metadata on a retype\n\nCloses-Bug: #1899137\nChange-Id: I6c7c94528ee94183c1df21c25388505b28f1781a\n(cherry picked from commit 92aeec3ad9dbb0482c2531a0b42c06326ae945fd)\n'}]",0,757035,fa48c21fba30c6d44ee9b96b8d657575e207e15c,96,19,1,12670,,,0,"PowerMax Driver - Safeguarding retype to some in-use replicated modes

Host assisted migration is a better option for retyping from a non-replicated
to a replicated (Asynchronous and Metro) modes.

1. Block in-use non-replicated to replicated(Metro and Asynchronous)
2. Remove any unused code
3. Differentiate between the production and the management storage groups
4. Remove rollback code on a cleanup_lun, its not necessary on delete and
    will not always work
5. Allow for a target device not to exist on the target array
6. Fix minor issue on metadata on a retype

Closes-Bug: #1899137
Change-Id: I6c7c94528ee94183c1df21c25388505b28f1781a
(cherry picked from commit 92aeec3ad9dbb0482c2531a0b42c06326ae945fd)
",git fetch https://review.opendev.org/openstack/cinder refs/changes/35/757035/1 && git format-patch -1 --stdout FETCH_HEAD,"['cinder/volume/drivers/dell_emc/powermax/iscsi.py', 'cinder/volume/drivers/dell_emc/powermax/provision.py', 'cinder/volume/drivers/dell_emc/powermax/common.py', 'cinder/volume/drivers/dell_emc/powermax/metadata.py', 'cinder/tests/unit/volume/drivers/dell_emc/powermax/test_powermax_utils.py', 'cinder/tests/unit/volume/drivers/dell_emc/powermax/test_powermax_provision.py', 'cinder/volume/drivers/dell_emc/powermax/rest.py', 'cinder/tests/unit/volume/drivers/dell_emc/powermax/test_powermax_common.py', 'releasenotes/notes/powermax-disable-inuse-metro-89e9f398ec9e2672.yaml', 'cinder/volume/drivers/dell_emc/powermax/utils.py', 'cinder/tests/unit/volume/drivers/dell_emc/powermax/test_powermax_replication.py', 'cinder/volume/drivers/dell_emc/powermax/fc.py', 'cinder/tests/unit/volume/drivers/dell_emc/powermax/powermax_data.py']",13,fa48c21fba30c6d44ee9b96b8d657575e207e15c,," connector=connector, attached_host='HostX') volume_details_attached_async = ( {'cap_gb': 2, 'num_of_storage_groups': 1, 'volumeId': device_id, 'volume_identifier': 'OS-%s' % test_volume.id, 'wwn': volume_wwn, 'snapvx_target': 'false', 'snapvx_source': 'false', 'storageGroupId': [ rdf_managed_async_grp, storagegroup_name_f + '-RA']}) # retype metadata dict retype_metadata_dict = { 'device_id': device_id, 'rdf_group_no': '10', 'remote_array': remote_array, 'target_device_id': device_id, 'rep_mode': 'Asynchronous', 'replication_status': 'enabled', 'target_array_model': array_model} retype_metadata_dict2 = { 'default_sg_name': 'default-sg', 'service_level': 'Diamond' }", connector=connector),393,94
openstack%2Ftripleo-heat-templates~stable%2Fussuri~Ide6d464be4a13457debfeceb61e5255c06b67808,openstack/tripleo-heat-templates,stable/ussuri,Ide6d464be4a13457debfeceb61e5255c06b67808,Add CinderBackupOptVolumes parameter,MERGED,2020-11-13 15:17:01.000000000,2020-12-02 21:04:17.000000000,2020-12-02 21:04:17.000000000,"[{'_account_id': 7160}, {'_account_id': 8833}, {'_account_id': 14624}, {'_account_id': 17558}, {'_account_id': 21129}, {'_account_id': 22348}, {'_account_id': 23181}, {'_account_id': 31016}, {'_account_id': 31779}]","[{'number': 1, 'created': '2020-11-13 15:17:01.000000000', 'files': ['deployment/cinder/cinder-common-container-puppet.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/a1058dbe71bf0f4945223e75a41789e95d0f005b', 'message': ""Add CinderBackupOptVolumes parameter\n\nThis adds a new parameter 'CinderBackupOptVolumes' to allow\ncinder-backup to mount extra volumes.\n\nChange-Id: Ide6d464be4a13457debfeceb61e5255c06b67808\n(cherry picked from commit 3f8decf175fe79223b78d2153c752a6f368a2275)\n""}]",0,762671,a1058dbe71bf0f4945223e75a41789e95d0f005b,33,9,1,13671,,,0,"Add CinderBackupOptVolumes parameter

This adds a new parameter 'CinderBackupOptVolumes' to allow
cinder-backup to mount extra volumes.

Change-Id: Ide6d464be4a13457debfeceb61e5255c06b67808
(cherry picked from commit 3f8decf175fe79223b78d2153c752a6f368a2275)
",git fetch https://review.opendev.org/openstack/tripleo-heat-templates refs/changes/71/762671/1 && git format-patch -1 --stdout FETCH_HEAD,['deployment/cinder/cinder-common-container-puppet.yaml'],1,a1058dbe71bf0f4945223e75a41789e95d0f005b,add-CinderBackupOptVolumes-stable/ussuri, CinderBackupOptVolumes: default: [] description: list of optional volumes to be mounted type: comma_delimited_list - {get_param: CinderBackupOptVolumes},,5,0
openstack%2Freleases~master~Ib9affcca4f4ac08118e3de11c52210dd89731966,openstack/releases,master,Ib9affcca4f4ac08118e3de11c52210dd89731966,Release openstackdocstheme 2.2.7,MERGED,2020-12-02 18:47:19.000000000,2020-12-02 20:38:59.000000000,2020-12-02 20:38:59.000000000,"[{'_account_id': 11904}, {'_account_id': 22348}, {'_account_id': 28522}]","[{'number': 1, 'created': '2020-12-02 18:47:19.000000000', 'files': ['deliverables/_independent/openstackdocstheme.yaml'], 'web_link': 'https://opendev.org/openstack/releases/commit/4cdc072d2500a1ceca383891dcc5d61c68e1a7de', 'message': 'Release openstackdocstheme 2.2.7\n\nThe StarlingX docs site utilizes a theme variant within the\nopenstackdocstheme repo, but consumes packaged releases. A recent\nchange merged to add a rubric paragraph class to the combined\nstylesheet, and the StarlingX community would appreciate a new\nopenstackdocstheme release to make use of it.\n\nChange-Id: Ib9affcca4f4ac08118e3de11c52210dd89731966\n'}]",0,765192,4cdc072d2500a1ceca383891dcc5d61c68e1a7de,7,3,1,5263,,,0,"Release openstackdocstheme 2.2.7

The StarlingX docs site utilizes a theme variant within the
openstackdocstheme repo, but consumes packaged releases. A recent
change merged to add a rubric paragraph class to the combined
stylesheet, and the StarlingX community would appreciate a new
openstackdocstheme release to make use of it.

Change-Id: Ib9affcca4f4ac08118e3de11c52210dd89731966
",git fetch https://review.opendev.org/openstack/releases refs/changes/92/765192/1 && git format-patch -1 --stdout FETCH_HEAD,['deliverables/_independent/openstackdocstheme.yaml'],1,4cdc072d2500a1ceca383891dcc5d61c68e1a7de,openstackdocstheme, - version: 2.2.7 projects: - repo: openstack/openstackdocstheme hash: c7f7eec234a63dc2c7662ce5036bcda17cbf24de,,4,0
openstack%2Frequirements~master~Ib6dff04e0743bb72b7296121c3065126a3cdca89,openstack/requirements,master,Ib6dff04e0743bb72b7296121c3065126a3cdca89,update constraint for keystonemiddleware to new release 9.2.0,MERGED,2020-12-02 10:34:54.000000000,2020-12-02 20:23:35.000000000,2020-12-02 20:20:42.000000000,"[{'_account_id': 14288}, {'_account_id': 22348}, {'_account_id': 28522}]","[{'number': 1, 'created': '2020-12-02 10:34:54.000000000', 'files': ['upper-constraints.txt'], 'web_link': 'https://opendev.org/openstack/requirements/commit/184a2817458fe12f48315210722f082e7d999200', 'message': 'update constraint for keystonemiddleware to new release 9.2.0\n\nmeta: version: 9.2.0\nmeta: diff-start: -\nmeta: series: wallaby\nmeta: release-type: release\nmeta: pypi: yes\nmeta: first: yes\nmeta: release:Author: Herv Beraud <hberaud@redhat.com>\nmeta: release:Commit: Herv Beraud <hberaud@redhat.com>\nmeta: release:Change-Id: I10e2fac4fdef97e95d4d10a2da9bb0dd0ad483af\nmeta: release:Code-Review+2: Sean McGinnis <sean.mcginnis@gmail.com>\nmeta: release:Code-Review+2: Herv Beraud <hberaud@redhat.com>\nmeta: release:Workflow+1: Herv Beraud <hberaud@redhat.com>\nChange-Id: Ib6dff04e0743bb72b7296121c3065126a3cdca89\n'}]",0,765099,184a2817458fe12f48315210722f082e7d999200,9,3,1,11131,,,0,"update constraint for keystonemiddleware to new release 9.2.0

meta: version: 9.2.0
meta: diff-start: -
meta: series: wallaby
meta: release-type: release
meta: pypi: yes
meta: first: yes
meta: release:Author: Herv Beraud <hberaud@redhat.com>
meta: release:Commit: Herv Beraud <hberaud@redhat.com>
meta: release:Change-Id: I10e2fac4fdef97e95d4d10a2da9bb0dd0ad483af
meta: release:Code-Review+2: Sean McGinnis <sean.mcginnis@gmail.com>
meta: release:Code-Review+2: Herv Beraud <hberaud@redhat.com>
meta: release:Workflow+1: Herv Beraud <hberaud@redhat.com>
Change-Id: Ib6dff04e0743bb72b7296121c3065126a3cdca89
",git fetch https://review.opendev.org/openstack/requirements refs/changes/99/765099/1 && git format-patch -1 --stdout FETCH_HEAD,['upper-constraints.txt'],1,184a2817458fe12f48315210722f082e7d999200,new-release,keystonemiddleware===9.2.0,keystonemiddleware===9.1.0,1,1
openstack%2Frequirements~master~I97eb8c526d371f011ac9ef7d548a3b1232cce27e,openstack/requirements,master,I97eb8c526d371f011ac9ef7d548a3b1232cce27e,update constraint for metalsmith to new release 1.3.0,MERGED,2020-12-02 10:32:48.000000000,2020-12-02 20:22:21.000000000,2020-12-02 20:20:38.000000000,"[{'_account_id': 14288}, {'_account_id': 22348}, {'_account_id': 28522}]","[{'number': 1, 'created': '2020-12-02 10:32:48.000000000', 'files': ['upper-constraints.txt'], 'web_link': 'https://opendev.org/openstack/requirements/commit/8cb9b0c14e4f9d36fd0eb2f535c5d036690a1ab9', 'message': 'update constraint for metalsmith to new release 1.3.0\n\nmeta: version: 1.3.0\nmeta: diff-start: -\nmeta: series: wallaby\nmeta: release-type: release\nmeta: pypi: no\nmeta: first: yes\nmeta: release:Author: Herv Beraud <hberaud@redhat.com>\nmeta: release:Commit: Herv Beraud <hberaud@redhat.com>\nmeta: release:Change-Id: I1ed118e982d7f4075b83377b2fd3d4945e013568\nmeta: release:Code-Review+2: Sean McGinnis <sean.mcginnis@gmail.com>\nmeta: release:Code-Review+2: Herv Beraud <hberaud@redhat.com>\nmeta: release:Workflow+1: Herv Beraud <hberaud@redhat.com>\nChange-Id: I97eb8c526d371f011ac9ef7d548a3b1232cce27e\n'}]",0,765098,8cb9b0c14e4f9d36fd0eb2f535c5d036690a1ab9,9,3,1,11131,,,0,"update constraint for metalsmith to new release 1.3.0

meta: version: 1.3.0
meta: diff-start: -
meta: series: wallaby
meta: release-type: release
meta: pypi: no
meta: first: yes
meta: release:Author: Herv Beraud <hberaud@redhat.com>
meta: release:Commit: Herv Beraud <hberaud@redhat.com>
meta: release:Change-Id: I1ed118e982d7f4075b83377b2fd3d4945e013568
meta: release:Code-Review+2: Sean McGinnis <sean.mcginnis@gmail.com>
meta: release:Code-Review+2: Herv Beraud <hberaud@redhat.com>
meta: release:Workflow+1: Herv Beraud <hberaud@redhat.com>
Change-Id: I97eb8c526d371f011ac9ef7d548a3b1232cce27e
",git fetch https://review.opendev.org/openstack/requirements refs/changes/98/765098/1 && git format-patch -1 --stdout FETCH_HEAD,['upper-constraints.txt'],1,8cb9b0c14e4f9d36fd0eb2f535c5d036690a1ab9,new-release,metalsmith===1.3.0,metalsmith===1.2.0,1,1
openstack%2Fopenstack-helm-infra~master~I2651c2f81191802a8f30314c4eebffdf0c2a53af,openstack/openstack-helm-infra,master,I2651c2f81191802a8f30314c4eebffdf0c2a53af,Make publish jobs more generic,MERGED,2020-11-12 00:23:02.000000000,2020-12-02 19:54:11.000000000,2020-12-02 19:51:46.000000000,"[{'_account_id': 20466}, {'_account_id': 21420}, {'_account_id': 22348}]","[{'number': 1, 'created': '2020-11-12 00:23:02.000000000', 'files': ['playbooks/publish/post.yaml'], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/ca60e1d875d7c3554629dad49a7373c5074374cd', 'message': 'Make publish jobs more generic\n\nThis will help in allowing the openstack-helm repo cleanly\npublish to the seperate folder.\n\nChange-Id: I2651c2f81191802a8f30314c4eebffdf0c2a53af\n'}]",0,762442,ca60e1d875d7c3554629dad49a7373c5074374cd,10,3,1,1004,,,0,"Make publish jobs more generic

This will help in allowing the openstack-helm repo cleanly
publish to the seperate folder.

Change-Id: I2651c2f81191802a8f30314c4eebffdf0c2a53af
",git fetch https://review.opendev.org/openstack/openstack-helm-infra refs/changes/42/762442/1 && git format-patch -1 --stdout FETCH_HEAD,['playbooks/publish/post.yaml'],1,ca60e1d875d7c3554629dad49a7373c5074374cd,," url: ""https://tarballs.opendev.org/{{ zuul.project.name }}/index.yaml"" shell: helm repo index {{ zuul.project.src_dir }} --url https://tarballs.opendev.org/{{ zuul.project.name }} shell: helm repo index {{ zuul.project.src_dir }} --merge {{ zuul.project.src_dir }}/index.yaml --url https://tarballs.opendev.org/{{ zuul.project.name }}", url: https://tarballs.opendev.org/openstack/openstack-helm-infra/index.yaml shell: helm repo index {{ zuul.project.src_dir }} --url https://tarballs.opendev.org/openstack/openstack-helm-infra shell: helm repo index {{ zuul.project.src_dir }} --merge {{ zuul.project.src_dir }}/index.yaml --url https://tarballs.opendev.org/openstack/openstack-helm-infra,3,3
openstack%2Fkolla-ansible~stable%2Ftrain~I1ff4cbdf3f60cb7fd5fe5d3c5d498e05fe2df79a,openstack/kolla-ansible,stable/train,I1ff4cbdf3f60cb7fd5fe5d3c5d498e05fe2df79a,RabbitMQ handler refactored to restart services in serial,MERGED,2020-12-01 18:43:23.000000000,2020-12-02 19:43:48.000000000,2020-12-02 19:41:39.000000000,"[{'_account_id': 22348}, {'_account_id': 22629}, {'_account_id': 30491}, {'_account_id': 32688}]","[{'number': 1, 'created': '2020-12-01 18:43:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/24e943c5980fd588bd6dfbb9d58e976f008dd402', 'message': 'RabbitMQ handler refactored to restart services in serial\n\nAdapted for Ussuri and below due to no RMQ TLS (different notifies).\n\nChange-Id: I1ff4cbdf3f60cb7fd5fe5d3c5d498e05fe2df79a\nCloses-Bug: #1904702\n(cherry picked from commit 4cc4ba59dac8d0835d7eaa1cfc9df5dd481e60c9)\n'}, {'number': 2, 'created': '2020-12-01 19:00:08.000000000', 'files': ['ansible/roles/rabbitmq/tasks/config.yml', 'ansible/roles/rabbitmq/handlers/main.yml', 'ansible/roles/rabbitmq/tasks/restart_services.yml', 'releasenotes/notes/bug-1904702-7451dd8c4caa309b.yaml', 'ansible/roles/rabbitmq/tasks/check-containers.yml'], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/6323f8096284819463823144596920164002052d', 'message': 'RabbitMQ handler refactored to restart services in serial\n\nAdapted for Ussuri and below due to no RMQ TLS (different notifies).\n\nChange-Id: I1ff4cbdf3f60cb7fd5fe5d3c5d498e05fe2df79a\nCloses-Bug: #1904702\n(cherry picked from commit 4cc4ba59dac8d0835d7eaa1cfc9df5dd481e60c9)\n'}]",0,764959,6323f8096284819463823144596920164002052d,14,4,2,30491,,,0,"RabbitMQ handler refactored to restart services in serial

Adapted for Ussuri and below due to no RMQ TLS (different notifies).

Change-Id: I1ff4cbdf3f60cb7fd5fe5d3c5d498e05fe2df79a
Closes-Bug: #1904702
(cherry picked from commit 4cc4ba59dac8d0835d7eaa1cfc9df5dd481e60c9)
",git fetch https://review.opendev.org/openstack/kolla-ansible refs/changes/59/764959/2 && git format-patch -1 --stdout FETCH_HEAD,"['ansible/roles/rabbitmq/tasks/config.yml', 'ansible/roles/rabbitmq/handlers/main.yml', 'ansible/roles/rabbitmq/tasks/restart_services.yml', 'releasenotes/notes/bug-1904702-7451dd8c4caa309b.yaml', 'ansible/roles/rabbitmq/tasks/check-containers.yml']",5,24e943c5980fd588bd6dfbb9d58e976f008dd402,rmq-handler-1904702-stable/victoria-stable/ussuri-stable/train, - Restart rabbitmq container, - Restart rabbitmq container (first node) - Restart rabbitmq container (rest of nodes),39,22
openstack%2Fkolla-ansible~stable%2Fussuri~I1ff4cbdf3f60cb7fd5fe5d3c5d498e05fe2df79a,openstack/kolla-ansible,stable/ussuri,I1ff4cbdf3f60cb7fd5fe5d3c5d498e05fe2df79a,RabbitMQ handler refactored to restart services in serial,MERGED,2020-12-01 16:08:22.000000000,2020-12-02 19:43:29.000000000,2020-12-02 19:41:35.000000000,"[{'_account_id': 22348}, {'_account_id': 22629}, {'_account_id': 30491}, {'_account_id': 32688}]","[{'number': 1, 'created': '2020-12-01 16:08:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/63adb75408cd86aa72d7ac795d4a60b66b03892a', 'message': 'RabbitMQ handler refactored to restart services in serial\n\nChange-Id: I1ff4cbdf3f60cb7fd5fe5d3c5d498e05fe2df79a\nCloses-Bug: #1904702\n(cherry picked from commit 4cc4ba59dac8d0835d7eaa1cfc9df5dd481e60c9)\n'}, {'number': 2, 'created': '2020-12-01 16:16:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/a5ffbb90b681032eccf05ccf49357740327394ff', 'message': 'RabbitMQ handler refactored to restart services in serial\n\nChange-Id: I1ff4cbdf3f60cb7fd5fe5d3c5d498e05fe2df79a\nCloses-Bug: #1904702\n(cherry picked from commit 4cc4ba59dac8d0835d7eaa1cfc9df5dd481e60c9)\n'}, {'number': 3, 'created': '2020-12-01 18:05:42.000000000', 'files': ['ansible/roles/rabbitmq/tasks/config.yml', 'ansible/roles/rabbitmq/handlers/main.yml', 'ansible/roles/rabbitmq/tasks/restart_services.yml', 'releasenotes/notes/bug-1904702-7451dd8c4caa309b.yaml', 'ansible/roles/rabbitmq/tasks/check-containers.yml'], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/aa3fa8d828a2cf26673d6667315f7afdb1b101a7', 'message': 'RabbitMQ handler refactored to restart services in serial\n\nAdapted for Ussuri and below due to no RMQ TLS (different notifies).\n\nChange-Id: I1ff4cbdf3f60cb7fd5fe5d3c5d498e05fe2df79a\nCloses-Bug: #1904702\n(cherry picked from commit 4cc4ba59dac8d0835d7eaa1cfc9df5dd481e60c9)\n'}]",0,764957,aa3fa8d828a2cf26673d6667315f7afdb1b101a7,14,4,3,30491,,,0,"RabbitMQ handler refactored to restart services in serial

Adapted for Ussuri and below due to no RMQ TLS (different notifies).

Change-Id: I1ff4cbdf3f60cb7fd5fe5d3c5d498e05fe2df79a
Closes-Bug: #1904702
(cherry picked from commit 4cc4ba59dac8d0835d7eaa1cfc9df5dd481e60c9)
",git fetch https://review.opendev.org/openstack/kolla-ansible refs/changes/57/764957/3 && git format-patch -1 --stdout FETCH_HEAD,"['ansible/roles/rabbitmq/handlers/main.yml', 'ansible/roles/rabbitmq/tasks/restart_services.yml', 'releasenotes/notes/bug-1904702-7451dd8c4caa309b.yaml']",3,63adb75408cd86aa72d7ac795d4a60b66b03892a,rmq-handler-1904702-stable/victoria-stable/ussuri,--- fixes: - | RabbitMQ services are now restarted serially to avoid a split brain. `LP#1904702 <https://launchpad.net/bugs/1904702>`__ ,,33,10
openstack%2Fkolla-ansible~stable%2Fvictoria~I1ff4cbdf3f60cb7fd5fe5d3c5d498e05fe2df79a,openstack/kolla-ansible,stable/victoria,I1ff4cbdf3f60cb7fd5fe5d3c5d498e05fe2df79a,RabbitMQ handler refactored to restart services in serial,MERGED,2020-12-01 16:07:07.000000000,2020-12-02 19:25:52.000000000,2020-12-02 19:24:27.000000000,"[{'_account_id': 22348}, {'_account_id': 22629}, {'_account_id': 30491}, {'_account_id': 32688}]","[{'number': 1, 'created': '2020-12-01 16:07:07.000000000', 'files': ['ansible/roles/rabbitmq/handlers/main.yml', 'ansible/roles/rabbitmq/tasks/restart_services.yml', 'releasenotes/notes/bug-1904702-7451dd8c4caa309b.yaml'], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/1a7478d2febc683e265d0da3758267113192d6e8', 'message': 'RabbitMQ handler refactored to restart services in serial\n\nChange-Id: I1ff4cbdf3f60cb7fd5fe5d3c5d498e05fe2df79a\nCloses-Bug: #1904702\n(cherry picked from commit 4cc4ba59dac8d0835d7eaa1cfc9df5dd481e60c9)\n'}]",0,764956,1a7478d2febc683e265d0da3758267113192d6e8,9,4,1,30491,,,0,"RabbitMQ handler refactored to restart services in serial

Change-Id: I1ff4cbdf3f60cb7fd5fe5d3c5d498e05fe2df79a
Closes-Bug: #1904702
(cherry picked from commit 4cc4ba59dac8d0835d7eaa1cfc9df5dd481e60c9)
",git fetch https://review.opendev.org/openstack/kolla-ansible refs/changes/56/764956/1 && git format-patch -1 --stdout FETCH_HEAD,"['ansible/roles/rabbitmq/handlers/main.yml', 'ansible/roles/rabbitmq/tasks/restart_services.yml', 'releasenotes/notes/bug-1904702-7451dd8c4caa309b.yaml']",3,1a7478d2febc683e265d0da3758267113192d6e8,rmq-handler-1904702-stable/victoria,--- fixes: - | RabbitMQ services are now restarted serially to avoid a split brain. `LP#1904702 <https://launchpad.net/bugs/1904702>`__ ,,30,41
openstack%2Fcharm-swift-storage~master~I2fbd0194a64943f536fff25ff05934a8ec4c74c7,openstack/charm-swift-storage,master,I2fbd0194a64943f536fff25ff05934a8ec4c74c7,Adding debugs and understanting charms,ABANDONED,2020-12-02 15:32:44.000000000,2020-12-02 19:16:39.000000000,,"[{'_account_id': 20648}, {'_account_id': 22348}]","[{'number': 1, 'created': '2020-12-02 15:32:44.000000000', 'files': ['lib/swift_storage_context.py', 'templates/object-server-replicator.conf', 'hooks/swift_storage_hooks.py', 'lib/swift_storage_utils.py'], 'web_link': 'https://opendev.org/openstack/charm-swift-storage/commit/88a7cc4cc50cbea1c7573ad3f35d95776e39ccf4', 'message': 'Adding debugs and understanting charms\n\nChange-Id: I2fbd0194a64943f536fff25ff05934a8ec4c74c7\n'}]",0,765157,88a7cc4cc50cbea1c7573ad3f35d95776e39ccf4,4,2,1,10058,,,0,"Adding debugs and understanting charms

Change-Id: I2fbd0194a64943f536fff25ff05934a8ec4c74c7
",git fetch https://review.opendev.org/openstack/charm-swift-storage refs/changes/57/765157/1 && git format-patch -1 --stdout FETCH_HEAD,"['lib/swift_storage_context.py', 'templates/object-server-replicator.conf', 'hooks/swift_storage_hooks.py', 'lib/swift_storage_utils.py']",4,88a7cc4cc50cbea1c7573ad3f35d95776e39ccf4,fix-swift-rep-port,# TODO(erlon): Re-test and think about the map,,24,2
openstack%2Fopenstack-ansible~master~Ie41c08f3e8c8c06a8bd334f7d8ec9bf03586ec2b,openstack/openstack-ansible,master,Ie41c08f3e8c8c06a8bd334f7d8ec9bf03586ec2b,Update variables for default Zun deployments and AIO,MERGED,2020-11-20 13:41:10.000000000,2020-12-02 19:14:01.000000000,2020-12-02 19:11:08.000000000,"[{'_account_id': 22348}, {'_account_id': 25023}, {'_account_id': 28619}, {'_account_id': 31542}]","[{'number': 1, 'created': '2020-11-20 13:41:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/8d0f29319788631ec697d5db81f96e7a1a3482f2', 'message': 'Bump API microversion required for Zun AIO\n\nThe Zun API added the ability to delete networks in this version\nwhich means that tempest tests can be run without the need to\nbind the Docker daemon to a wider set of addresses than localhost.\n\nChange-Id: Ie41c08f3e8c8c06a8bd334f7d8ec9bf03586ec2b\n'}, {'number': 2, 'created': '2020-11-23 15:18:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/8eb69561bc1d559dcf6e0f51a9fecca6c54f9234', 'message': 'Update variables for default Zun AIO\n\nThe Zun API added the ability to delete networks in this\nmicroversion which means that tempest tests can be run without the\nneed to bind the Docker daemon to a wider set of addresses than\nlocalhost.\n\nFor the same reason, one tempest test is skipped as this assumes\nthe Docker daemon is accessible on localhost.\n\nChange-Id: Ie41c08f3e8c8c06a8bd334f7d8ec9bf03586ec2b\n'}, {'number': 3, 'created': '2020-11-27 15:24:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/8b4833da920596e57486035f53483ce3dcf5f0ec', 'message': 'Update variables for default Zun deployments and AIO\n\nThe Zun API added the ability to delete networks in this\nmicroversion which means that tempest tests can be run without the\nneed to bind the Docker daemon to a wider set of addresses than\nlocalhost.\n\nFor the same reason, one tempest test is skipped as this assumes\nthe Docker daemon is accessible on localhost.\n\nThis commit also enables the Zun Horizon UI when Zun is used\n\nChange-Id: Ie41c08f3e8c8c06a8bd334f7d8ec9bf03586ec2b\n'}, {'number': 4, 'created': '2020-12-02 12:54:30.000000000', 'files': ['tests/roles/bootstrap-host/templates/user_variables_zun.yml.j2', 'inventory/group_vars/horizon_all.yml'], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/ce593d8252e871e62181e0f7eaaca982e8e19707', 'message': 'Update variables for default Zun deployments and AIO\n\nThe Zun API added the ability to delete networks in this\nmicroversion which means that tempest tests can be run without the\nneed to bind the Docker daemon to a wider set of addresses than\nlocalhost.\n\nFor the same reason, one tempest test is skipped as this assumes\nthe Docker daemon is accessible on localhost.\n\nThis commit also enables the Zun Horizon UI when Zun is used\n\nChange-Id: Ie41c08f3e8c8c06a8bd334f7d8ec9bf03586ec2b\n'}]",0,763562,ce593d8252e871e62181e0f7eaaca982e8e19707,22,4,4,31542,,,0,"Update variables for default Zun deployments and AIO

The Zun API added the ability to delete networks in this
microversion which means that tempest tests can be run without the
need to bind the Docker daemon to a wider set of addresses than
localhost.

For the same reason, one tempest test is skipped as this assumes
the Docker daemon is accessible on localhost.

This commit also enables the Zun Horizon UI when Zun is used

Change-Id: Ie41c08f3e8c8c06a8bd334f7d8ec9bf03586ec2b
",git fetch https://review.opendev.org/openstack/openstack-ansible refs/changes/62/763562/4 && git format-patch -1 --stdout FETCH_HEAD,['tests/roles/bootstrap-host/templates/user_variables_zun.yml.j2'],1,8d0f29319788631ec697d5db81f96e7a1a3482f2,, min_microversion: 1.27, min_microversion: 1.12,1,1
openstack%2Fcharm-deployment-guide~stable%2Fvictoria~I00675dbc236a735b96d575e4d44a208f8a6acc87,openstack/charm-deployment-guide,stable/victoria,I00675dbc236a735b96d575e4d44a208f8a6acc87,app-ovn: Fix mis-alignments in the numbered list,MERGED,2020-12-02 18:25:20.000000000,2020-12-02 18:39:46.000000000,2020-12-02 18:37:22.000000000,"[{'_account_id': 22348}, {'_account_id': 30561}]","[{'number': 1, 'created': '2020-12-02 18:25:20.000000000', 'files': ['deploy-guide/source/app-ovn.rst'], 'web_link': 'https://opendev.org/openstack/charm-deployment-guide/commit/7bf2971698086ee176ee7ebe3702125e8c9edd87', 'message': 'app-ovn: Fix mis-alignments in the numbered list\n\nChange-Id: I00675dbc236a735b96d575e4d44a208f8a6acc87\n(cherry picked from commit 0393fdf90cb9342b382fff8249e777e97a78c06d)\n'}]",0,765089,7bf2971698086ee176ee7ebe3702125e8c9edd87,7,2,1,13686,,,0,"app-ovn: Fix mis-alignments in the numbered list

Change-Id: I00675dbc236a735b96d575e4d44a208f8a6acc87
(cherry picked from commit 0393fdf90cb9342b382fff8249e777e97a78c06d)
",git fetch https://review.opendev.org/openstack/charm-deployment-guide refs/changes/89/765089/1 && git format-patch -1 --stdout FETCH_HEAD,['deploy-guide/source/app-ovn.rst'],1,7bf2971698086ee176ee7ebe3702125e8c9edd87,, .. code-block:: none juju config neutron-api manage-neutron-plugin-legacy-mode=false Wait for the deployment to settle. .. code-block:: none juju run-action neutron-api/0 pause juju run-action neutron-api/1 pause juju run-action neutron-api/2 pause Wait for the deployment to settle. Wait for the deployment to settle., .. code-block:: none juju config neutron-api manage-neutron-plugin-legacy-mode=false Wait for the deployment to settle. .. code-block:: none juju run-action neutron-api/0 pause juju run-action neutron-api/1 pause juju run-action neutron-api/2 pause Wait for the deployment to settle. Wait for the deployment to settle.,9,9
openstack%2Fcharm-deployment-guide~stable%2Fvictoria~I3e7d9ee5076375c04df2ef7edc87e18fd0617c7c,openstack/charm-deployment-guide,stable/victoria,I3e7d9ee5076375c04df2ef7edc87e18fd0617c7c,Add steps for confirming IP address allocations and firewall driver,MERGED,2020-12-02 17:13:14.000000000,2020-12-02 18:38:40.000000000,2020-12-02 18:37:20.000000000,"[{'_account_id': 22348}, {'_account_id': 30561}]","[{'number': 1, 'created': '2020-12-02 17:13:14.000000000', 'files': ['deploy-guide/source/app-ovn.rst'], 'web_link': 'https://opendev.org/openstack/charm-deployment-guide/commit/f1c4aa32c5fd176d90d48fb5042df342e767c6c9', 'message': ""Add steps for confirming IP address allocations and firewall driver\n\nOVN will allocate new ports/IP addresses during the migration, if\nany subnets do not have IPs free for allocation the migration will\nfail.\n\nWe have omitted a step for change of firewall driver to\n'openvswtich'.\n\nChange-Id: I3e7d9ee5076375c04df2ef7edc87e18fd0617c7c\nCloses-Bug: #1905554\n(cherry picked from commit 57d609fa74dd87d3b680bcdc10ca164dda06e026)\n""}]",3,765088,f1c4aa32c5fd176d90d48fb5042df342e767c6c9,9,2,1,13686,,,0,"Add steps for confirming IP address allocations and firewall driver

OVN will allocate new ports/IP addresses during the migration, if
any subnets do not have IPs free for allocation the migration will
fail.

We have omitted a step for change of firewall driver to
'openvswtich'.

Change-Id: I3e7d9ee5076375c04df2ef7edc87e18fd0617c7c
Closes-Bug: #1905554
(cherry picked from commit 57d609fa74dd87d3b680bcdc10ca164dda06e026)
",git fetch https://review.opendev.org/openstack/charm-deployment-guide refs/changes/88/765088/1 && git format-patch -1 --stdout FETCH_HEAD,['deploy-guide/source/app-ovn.rst'],1,f1c4aa32c5fd176d90d48fb5042df342e767c6c9,bug/1905554-stable/victoria,"If this can be done then steps #1 and #9 below can be skipped, where it is2. Confirm cloud subnet configuration * Confirm that all subnets have IP addresses available for allocation. During the migration OVN may create a new port in subnets and allocate an IP address to it. Depending on the type of network, this port will be used for either the OVN metadata service or for the SNAT address assigned to an external router interface. .. warning:: If a subnet has no free IP addresses for allocation the migration will fail. * Confirm that all subnets have a valid DNS server configuration. OVN handles instance access to DNS differently to how ML2+OVS does. Please refer to the Internal DNS resolution paragraph in this document for details. When the subnet ``dns_nameservers`` attribute is empty the OVN DHCP server will provide instances with the DNS addresses specified in the neutron-api-plugin-ovn ``dns-servers`` configuration option. If any of your subnets have the ``dns_nameservers`` attribute set to the IP address ML2+OVS used for instance DNS (usually the .2 address of the project subnet) you will need to remove this configuration. 3. Make a fresh backup copy of the Neutron database 4. Deploy the OVN components and Vault5. Unseal `Vault`_, enable `Certificate Lifecycle Management`_ and6. Change firewall driver to 'openvswitch' To be able to successfully clean up after the Neutron agents on hypervisors we need to instruct the neutron-openvswitch charm to use the 'openvswitch' firewall driver. This is accomplished by setting the ``firewall-driver`` configuration option to 'openvswitch'. .. code-block:: none juju config neutron-openvswitch firewall-driver=openvswitch 7. Pause neutron-openvswitch and/or neutron-gateway units.8. Deploy the Neutron OVN plugin application9. Adjust MTU on overlay networks (if required)10. Enable the Neutron OVN plugin11. Pause the Neutron API units12. Perform initial synchronization of the Neutron and OVN databases13. (Optional) Perform Neutron database surgery to update ``network_type`` of14. Resume the Neutron API units15. Migrate hypervisors and gateways16. Post migration tasks","If this can be done then steps #1 and #7 below can be skipped, where it is2. Make a fresh backup copy of the Neutron database 3. Deploy the OVN components and Vault4. Unseal `Vault`_, enable `Certificate Lifecycle Management`_ and5. Pause neutron-openvswitch and/or neutron-gateway units.6. Deploy the Neutron OVN plugin application7. Adjust MTU on overlay networks (if required)8. Enable the Neutron OVN plugin9. Pause the Neutron API units10. Perform initial synchronization of the Neutron and OVN databases11. (Optional) Perform Neutron database surgery to update ``network_type`` of12. Resume the Neutron API units13. Migrate hypervisors and gateways14. Post migration tasks",52,14
openstack%2Fpython-openstackclient~stable%2Ftrain~I102b41677736bbe37a82abaa3c5b3e1faf2475d5,openstack/python-openstackclient,stable/train,I102b41677736bbe37a82abaa3c5b3e1faf2475d5,Bypass user and group verification in RemoveRole,MERGED,2020-08-19 15:52:20.000000000,2020-12-02 18:24:33.000000000,2020-12-02 18:21:58.000000000,"[{'_account_id': 9954}, {'_account_id': 22348}, {'_account_id': 27900}, {'_account_id': 28522}]","[{'number': 1, 'created': '2020-08-19 15:52:20.000000000', 'files': ['releasenotes/notes/bug-2006635-3110f7a87a186e62.yaml', 'openstackclient/identity/v3/role.py', 'openstackclient/tests/unit/identity/v3/test_role.py'], 'web_link': 'https://opendev.org/openstack/python-openstackclient/commit/2e0a0f15cf50e200925aebd9659d903c79b5b68e', 'message': ""Bypass user and group verification in RemoveRole\n\nKeystone let's users remove role assignments that reference non-existent\nusers and groups. This is nice when keystone backs to an identity store\nlike LDAP and users or groups are removed.\n\nPreviously, openstackclient would validate the user and group existed in\nkeystone before sending the request to delete the role assignment. This\ncommit updates the code to bypass that validation so that users can use\nIDs to forcibly cleanup role assignments.\n\nChange-Id: I102b41677736bbe37a82abaa3c5b3e1faf2475d5\nStory: 2006635\nTask: 36848\n(cherry picked from commit e24673267093de85beee753860cda1fb224ce4bc)\n""}]",0,746970,2e0a0f15cf50e200925aebd9659d903c79b5b68e,10,4,1,5046,,,0,"Bypass user and group verification in RemoveRole

Keystone let's users remove role assignments that reference non-existent
users and groups. This is nice when keystone backs to an identity store
like LDAP and users or groups are removed.

Previously, openstackclient would validate the user and group existed in
keystone before sending the request to delete the role assignment. This
commit updates the code to bypass that validation so that users can use
IDs to forcibly cleanup role assignments.

Change-Id: I102b41677736bbe37a82abaa3c5b3e1faf2475d5
Story: 2006635
Task: 36848
(cherry picked from commit e24673267093de85beee753860cda1fb224ce4bc)
",git fetch https://review.opendev.org/openstack/python-openstackclient refs/changes/70/746970/1 && git format-patch -1 --stdout FETCH_HEAD,"['releasenotes/notes/bug-2006635-3110f7a87a186e62.yaml', 'openstackclient/identity/v3/role.py', 'openstackclient/tests/unit/identity/v3/test_role.py']",3,2e0a0f15cf50e200925aebd9659d903c79b5b68e,,"from openstackclient.identity import common @mock.patch.object(common, 'find_user') def test_role_remove_non_existent_user_system(self, find_mock): # Simulate the user not being in keystone, the client should gracefully # handle this exception and send the request to remove the role since # keystone supports removing role assignments with non-existent actors # (e.g., users or groups). find_mock.side_effect = exceptions.CommandError arglist = [ '--user', identity_fakes.user_id, '--system', 'all', identity_fakes.role_name ] if self._is_inheritance_testcase(): arglist.append('--inherited') verifylist = [ ('user', identity_fakes.user_id), ('group', None), ('system', 'all'), ('domain', None), ('project', None), ('role', identity_fakes.role_name), ('inherited', self._is_inheritance_testcase()), ] parsed_args = self.check_parser(self.cmd, arglist, verifylist) result = self.cmd.take_action(parsed_args) # Set expected values kwargs = { 'user': identity_fakes.user_id, 'system': 'all', 'os_inherit_extension_inherited': self._is_inheritance_testcase(), } # RoleManager.revoke(role, user=, group=, domain=, project=) self.roles_mock.revoke.assert_called_with( identity_fakes.role_id, **kwargs ) self.assertIsNone(result) @mock.patch.object(common, 'find_user') def test_role_remove_non_existent_user_domain(self, find_mock): # Simulate the user not being in keystone, the client the gracefully # handle this exception and send the request to remove the role since # keystone will validate. find_mock.side_effect = exceptions.CommandError arglist = [ '--user', identity_fakes.user_id, '--domain', identity_fakes.domain_name, identity_fakes.role_name ] if self._is_inheritance_testcase(): arglist.append('--inherited') verifylist = [ ('user', identity_fakes.user_id), ('group', None), ('system', None), ('domain', identity_fakes.domain_name), ('project', None), ('role', identity_fakes.role_name), ('inherited', self._is_inheritance_testcase()), ] parsed_args = self.check_parser(self.cmd, arglist, verifylist) result = self.cmd.take_action(parsed_args) # Set expected values kwargs = { 'user': identity_fakes.user_id, 'domain': identity_fakes.domain_id, 'os_inherit_extension_inherited': self._is_inheritance_testcase(), } # RoleManager.revoke(role, user=, group=, domain=, project=) self.roles_mock.revoke.assert_called_with( identity_fakes.role_id, **kwargs ) self.assertIsNone(result) @mock.patch.object(common, 'find_user') def test_role_remove_non_existent_user_project(self, find_mock): # Simulate the user not being in keystone, the client the gracefully # handle this exception and send the request to remove the role since # keystone will validate. find_mock.side_effect = exceptions.CommandError arglist = [ '--user', identity_fakes.user_id, '--project', identity_fakes.project_name, identity_fakes.role_name ] if self._is_inheritance_testcase(): arglist.append('--inherited') verifylist = [ ('user', identity_fakes.user_id), ('group', None), ('system', None), ('domain', None), ('project', identity_fakes.project_name), ('role', identity_fakes.role_name), ('inherited', self._is_inheritance_testcase()), ] parsed_args = self.check_parser(self.cmd, arglist, verifylist) result = self.cmd.take_action(parsed_args) # Set expected values kwargs = { 'user': identity_fakes.user_id, 'project': identity_fakes.project_id, 'os_inherit_extension_inherited': self._is_inheritance_testcase(), } # RoleManager.revoke(role, user=, group=, domain=, project=) self.roles_mock.revoke.assert_called_with( identity_fakes.role_id, **kwargs ) self.assertIsNone(result) @mock.patch.object(common, 'find_group') def test_role_remove_non_existent_group_system(self, find_mock): # Simulate the user not being in keystone, the client the gracefully # handle this exception and send the request to remove the role since # keystone will validate. find_mock.side_effect = exceptions.CommandError arglist = [ '--group', identity_fakes.group_id, '--system', 'all', identity_fakes.role_name ] if self._is_inheritance_testcase(): arglist.append('--inherited') verifylist = [ ('user', None), ('group', identity_fakes.group_id), ('system', 'all'), ('domain', None), ('project', None), ('role', identity_fakes.role_name), ('inherited', self._is_inheritance_testcase()), ] parsed_args = self.check_parser(self.cmd, arglist, verifylist) result = self.cmd.take_action(parsed_args) # Set expected values kwargs = { 'group': identity_fakes.group_id, 'system': 'all', 'os_inherit_extension_inherited': self._is_inheritance_testcase(), } # RoleManager.revoke(role, user=, group=, domain=, project=) self.roles_mock.revoke.assert_called_with( identity_fakes.role_id, **kwargs ) self.assertIsNone(result) @mock.patch.object(common, 'find_group') def test_role_remove_non_existent_group_domain(self, find_mock): # Simulate the user not being in keystone, the client the gracefully # handle this exception and send the request to remove the role since # keystone will validate. find_mock.side_effect = exceptions.CommandError arglist = [ '--group', identity_fakes.group_id, '--domain', identity_fakes.domain_name, identity_fakes.role_name ] if self._is_inheritance_testcase(): arglist.append('--inherited') verifylist = [ ('user', None), ('group', identity_fakes.group_id), ('system', None), ('domain', identity_fakes.domain_name), ('project', None), ('role', identity_fakes.role_name), ('inherited', self._is_inheritance_testcase()), ] parsed_args = self.check_parser(self.cmd, arglist, verifylist) result = self.cmd.take_action(parsed_args) # Set expected values kwargs = { 'group': identity_fakes.group_id, 'domain': identity_fakes.domain_id, 'os_inherit_extension_inherited': self._is_inheritance_testcase(), } # RoleManager.revoke(role, user=, group=, domain=, project=) self.roles_mock.revoke.assert_called_with( identity_fakes.role_id, **kwargs ) self.assertIsNone(result) @mock.patch.object(common, 'find_group') def test_role_remove_non_existent_group_project(self, find_mock): # Simulate the user not being in keystone, the client the gracefully # handle this exception and send the request to remove the role since # keystone will validate. find_mock.side_effect = exceptions.CommandError arglist = [ '--group', identity_fakes.group_id, '--project', identity_fakes.project_name, identity_fakes.role_name ] if self._is_inheritance_testcase(): arglist.append('--inherited') verifylist = [ ('user', None), ('group', identity_fakes.group_id), ('system', None), ('domain', None), ('project', identity_fakes.project_name), ('role', identity_fakes.role_name), ('inherited', self._is_inheritance_testcase()), ] parsed_args = self.check_parser(self.cmd, arglist, verifylist) result = self.cmd.take_action(parsed_args) # Set expected values kwargs = { 'group': identity_fakes.group_id, 'project': identity_fakes.project_id, 'os_inherit_extension_inherited': self._is_inheritance_testcase(), } # RoleManager.revoke(role, user=, group=, domain=, project=) self.roles_mock.revoke.assert_called_with( identity_fakes.role_id, **kwargs ) self.assertIsNone(result) ",,285,32
openstack%2Fpython-openstackclient~stable%2Ftrain~I30fdc6ec55e1eb1cfa55f4cbf92c3f001d89865f,openstack/python-openstackclient,stable/train,I30fdc6ec55e1eb1cfa55f4cbf92c3f001d89865f,Add system role assignment tests for users and groups,MERGED,2020-08-19 15:52:20.000000000,2020-12-02 18:23:25.000000000,2020-12-02 18:21:54.000000000,"[{'_account_id': 9954}, {'_account_id': 22348}, {'_account_id': 27900}, {'_account_id': 28522}]","[{'number': 1, 'created': '2020-08-19 15:52:20.000000000', 'files': ['openstackclient/tests/unit/identity/v3/test_role.py'], 'web_link': 'https://opendev.org/openstack/python-openstackclient/commit/3934fe8d0a53593d6fcbed8ea8867e22282d60aa', 'message': 'Add system role assignment tests for users and groups\n\nI was writing some additional functionality and noticed these tests were\nmissing. This commit adds tests for adding and removing system role\nassignments for users and groups.\n\nChange-Id: I30fdc6ec55e1eb1cfa55f4cbf92c3f001d89865f\n(cherry picked from commit a8aad9fec80bcb6c9917d2dd076373f06467849f)\n'}]",0,746969,3934fe8d0a53593d6fcbed8ea8867e22282d60aa,9,4,1,5046,,,0,"Add system role assignment tests for users and groups

I was writing some additional functionality and noticed these tests were
missing. This commit adds tests for adding and removing system role
assignments for users and groups.

Change-Id: I30fdc6ec55e1eb1cfa55f4cbf92c3f001d89865f
(cherry picked from commit a8aad9fec80bcb6c9917d2dd076373f06467849f)
",git fetch https://review.opendev.org/openstack/python-openstackclient refs/changes/69/746969/1 && git format-patch -1 --stdout FETCH_HEAD,['openstackclient/tests/unit/identity/v3/test_role.py'],1,3934fe8d0a53593d6fcbed8ea8867e22282d60aa,," def test_role_add_user_system(self): arglist = [ '--user', identity_fakes.user_name, '--system', 'all', identity_fakes.role_name, ] if self._is_inheritance_testcase(): arglist.append('--inherited') verifylist = [ ('user', identity_fakes.user_name), ('group', None), ('system', 'all'), ('domain', None), ('project', None), ('role', identity_fakes.role_name), ('inherited', self._is_inheritance_testcase()), ] parsed_args = self.check_parser(self.cmd, arglist, verifylist) result = self.cmd.take_action(parsed_args) # Set expected values kwargs = { 'user': identity_fakes.user_id, 'system': 'all', 'os_inherit_extension_inherited': self._is_inheritance_testcase(), } # RoleManager.grant(role, user=, group=, domain=, project=) self.roles_mock.grant.assert_called_with( identity_fakes.role_id, **kwargs ) self.assertIsNone(result) def test_role_add_group_system(self): arglist = [ '--group', identity_fakes.group_name, '--system', 'all', identity_fakes.role_name, ] if self._is_inheritance_testcase(): arglist.append('--inherited') verifylist = [ ('user', None), ('group', identity_fakes.group_name), ('system', 'all'), ('domain', None), ('project', None), ('role', identity_fakes.role_name), ('inherited', self._is_inheritance_testcase()), ] parsed_args = self.check_parser(self.cmd, arglist, verifylist) result = self.cmd.take_action(parsed_args) # Set expected values kwargs = { 'group': identity_fakes.group_id, 'system': 'all', 'os_inherit_extension_inherited': self._is_inheritance_testcase(), } # RoleManager.grant(role, user=, group=, domain=, project=) self.roles_mock.grant.assert_called_with( identity_fakes.role_id, **kwargs ) self.assertIsNone(result) def test_role_remove_user_system(self): arglist = [ '--user', identity_fakes.user_name, '--system', 'all', identity_fakes.role_name ] if self._is_inheritance_testcase(): arglist.append('--inherited') verifylist = [ ('user', identity_fakes.user_name), ('group', None), ('system', 'all'), ('domain', None), ('project', None), ('role', identity_fakes.role_name), ('inherited', self._is_inheritance_testcase()), ] parsed_args = self.check_parser(self.cmd, arglist, verifylist) result = self.cmd.take_action(parsed_args) # Set expected values kwargs = { 'user': identity_fakes.user_id, 'system': 'all', 'os_inherit_extension_inherited': self._is_inheritance_testcase(), } # RoleManager.revoke(role, user=, group=, domain=, project=) self.roles_mock.revoke.assert_called_with( identity_fakes.role_id, **kwargs ) self.assertIsNone(result) def test_role_remove_group_system(self): arglist = [ '--group', identity_fakes.group_name, '--system', 'all', identity_fakes.role_name, ] if self._is_inheritance_testcase(): arglist.append('--inherited') verifylist = [ ('user', None), ('group', identity_fakes.group_name), ('system', 'all'), ('domain', None), ('project', None), ('role', identity_fakes.role_name), ('role', identity_fakes.role_name), ('inherited', self._is_inheritance_testcase()), ] parsed_args = self.check_parser(self.cmd, arglist, verifylist) result = self.cmd.take_action(parsed_args) # Set expected values kwargs = { 'group': identity_fakes.group_id, 'system': 'all', 'os_inherit_extension_inherited': self._is_inheritance_testcase(), } # RoleManager.revoke(role, user=, group=, domain=, project=) self.roles_mock.revoke.assert_called_with( identity_fakes.role_id, **kwargs ) self.assertIsNone(result) ",,137,0
openstack%2Fneutron~master~Iae86705f1d30c89dc5482261d852b45787bd8782,openstack/neutron,master,Iae86705f1d30c89dc5482261d852b45787bd8782,Fix calling of add_tunnel_port method from sanity checks module,MERGED,2020-11-25 14:02:32.000000000,2020-12-02 18:13:16.000000000,2020-12-02 18:11:15.000000000,"[{'_account_id': 5948}, {'_account_id': 8313}, {'_account_id': 9845}, {'_account_id': 16688}, {'_account_id': 22348}]","[{'number': 1, 'created': '2020-11-25 14:02:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/e3b590f1eb0ab67256efc4553dee98d2090cd3b4', 'message': 'Fix calling of add_tunnel_port method from sanity checks module\n\nSanity checks functions which are checking if vxlan and geneve tunnels\nare available in openvswitch are now passing all mandatory parameters\nto the ovs_lib.OVSBridge.add_tunnel_port method.\nPreviously port_name was missing.\n\nCloses-Bug: #1905568\nChange-Id: Iae86705f1d30c89dc5482261d852b45787bd8782\n'}, {'number': 2, 'created': '2020-11-25 14:40:41.000000000', 'files': ['neutron/cmd/sanity/checks.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/ab6c59b57e732def62e3817a80d081b8392d669a', 'message': 'Fix calling of add_tunnel_port method from sanity checks module\n\nSanity checks functions which are checking if vxlan and geneve tunnels\nare available in openvswitch are now passing all mandatory parameters\nto the ovs_lib.OVSBridge.add_tunnel_port method.\nPreviously port_name was missing.\n\nCloses-Bug: #1905568\nChange-Id: Iae86705f1d30c89dc5482261d852b45787bd8782\n'}]",3,764171,ab6c59b57e732def62e3817a80d081b8392d669a,41,5,2,11975,,,0,"Fix calling of add_tunnel_port method from sanity checks module

Sanity checks functions which are checking if vxlan and geneve tunnels
are available in openvswitch are now passing all mandatory parameters
to the ovs_lib.OVSBridge.add_tunnel_port method.
Previously port_name was missing.

Closes-Bug: #1905568
Change-Id: Iae86705f1d30c89dc5482261d852b45787bd8782
",git fetch https://review.opendev.org/openstack/neutron refs/changes/71/764171/2 && git format-patch -1 --stdout FETCH_HEAD,['neutron/cmd/sanity/checks.py'],1,e3b590f1eb0ab67256efc4553dee98d2090cd3b4,bug/1905568," port_name = common_utils.get_rand_device_name(prefix='vxlantest-') with ovs_lib.OVSBridge(name) as br: port = br.add_tunnel_port( port_name=port_name, remote_ip=from_ip, local_ip=to_ip, tunnel_type=n_consts.TYPE_VXLAN) port_name = common_utils.get_rand_device_name(prefix='genevetest-') with ovs_lib.OVSBridge(name) as br: port = br.add_tunnel_port( port_name=port_name, remote_ip=from_ip, local_ip=to_ip, tunnel_type=n_consts.TYPE_GENEVE)"," with ovs_lib.OVSBridge(name) as br: port = br.add_tunnel_port(from_ip, to_ip, n_consts.TYPE_VXLAN) with ovs_lib.OVSBridge(name) as br: port = br.add_tunnel_port(from_ip, to_ip, n_consts.TYPE_GENEVE)",12,2
openstack%2Freleases~master~I9a6d8bbf4972694e29cff65be684cdd3ce057af9,openstack/releases,master,I9a6d8bbf4972694e29cff65be684cdd3ce057af9,Release os-win for wallaby-1 milestone,MERGED,2020-11-30 13:21:53.000000000,2020-12-02 17:52:54.000000000,2020-12-02 17:52:54.000000000,"[{'_account_id': 308}, {'_account_id': 8213}, {'_account_id': 8543}, {'_account_id': 22348}, {'_account_id': 28522}]","[{'number': 1, 'created': '2020-11-30 13:21:53.000000000', 'files': ['deliverables/wallaby/os-win.yaml'], 'web_link': 'https://opendev.org/openstack/releases/commit/21a0265ff4a3e3dc9cd3c9335c57eee20f2469f3', 'message': 'Release os-win for wallaby-1 milestone\n\nThis is a library release for os-win for the wallaby-1\nmilestone. This repo includes commits that have not been releases for\nthis cycle yet.\n\nIf the team is ready to process with this release, please leave a +1\nto indicate we should go ahead with the release.\n\nIf the team needs more time for things about to merge, or if there is\nsome other reason a release should not be done at this time, please\nleave a -1 with a comment indicating the status. Then update the patch\nwith the new commit hash to use once the team is ready to do the\nrelease.\n\nChange-Id: I9a6d8bbf4972694e29cff65be684cdd3ce057af9\n'}]",0,764704,21a0265ff4a3e3dc9cd3c9335c57eee20f2469f3,9,5,1,28522,,,0,"Release os-win for wallaby-1 milestone

This is a library release for os-win for the wallaby-1
milestone. This repo includes commits that have not been releases for
this cycle yet.

If the team is ready to process with this release, please leave a +1
to indicate we should go ahead with the release.

If the team needs more time for things about to merge, or if there is
some other reason a release should not be done at this time, please
leave a -1 with a comment indicating the status. Then update the patch
with the new commit hash to use once the team is ready to do the
release.

Change-Id: I9a6d8bbf4972694e29cff65be684cdd3ce057af9
",git fetch https://review.opendev.org/openstack/releases refs/changes/04/764704/1 && git format-patch -1 --stdout FETCH_HEAD,['deliverables/wallaby/os-win.yaml'],1,21a0265ff4a3e3dc9cd3c9335c57eee20f2469f3,w1-c-w-i,releases: - version: 5.3.0 projects: - repo: openstack/os-win hash: 78414e71606b37ff2147ee886ee1fd962ef3a911,,5,0
openstack%2Fcharm-deployment-guide~master~I00675dbc236a735b96d575e4d44a208f8a6acc87,openstack/charm-deployment-guide,master,I00675dbc236a735b96d575e4d44a208f8a6acc87,app-ovn: Fix mis-alignments in the numbered list,MERGED,2020-12-02 17:33:46.000000000,2020-12-02 17:51:57.000000000,2020-12-02 17:50:46.000000000,"[{'_account_id': 22348}, {'_account_id': 30561}]","[{'number': 1, 'created': '2020-12-02 17:33:46.000000000', 'files': ['deploy-guide/source/app-ovn.rst'], 'web_link': 'https://opendev.org/openstack/charm-deployment-guide/commit/0393fdf90cb9342b382fff8249e777e97a78c06d', 'message': 'app-ovn: Fix mis-alignments in the numbered list\n\nChange-Id: I00675dbc236a735b96d575e4d44a208f8a6acc87\n'}]",0,765181,0393fdf90cb9342b382fff8249e777e97a78c06d,7,2,1,13686,,,0,"app-ovn: Fix mis-alignments in the numbered list

Change-Id: I00675dbc236a735b96d575e4d44a208f8a6acc87
",git fetch https://review.opendev.org/openstack/charm-deployment-guide refs/changes/81/765181/1 && git format-patch -1 --stdout FETCH_HEAD,['deploy-guide/source/app-ovn.rst'],1,0393fdf90cb9342b382fff8249e777e97a78c06d,, .. code-block:: none juju config neutron-api manage-neutron-plugin-legacy-mode=false Wait for the deployment to settle. .. code-block:: none juju run-action neutron-api/0 pause juju run-action neutron-api/1 pause juju run-action neutron-api/2 pause Wait for the deployment to settle. Wait for the deployment to settle., .. code-block:: none juju config neutron-api manage-neutron-plugin-legacy-mode=false Wait for the deployment to settle. .. code-block:: none juju run-action neutron-api/0 pause juju run-action neutron-api/1 pause juju run-action neutron-api/2 pause Wait for the deployment to settle. Wait for the deployment to settle.,9,9
openstack%2Fansible-collections-openstack~master~I5590976964543188518200f2b31a1603eb30f39b,openstack/ansible-collections-openstack,master,I5590976964543188518200f2b31a1603eb30f39b,Migrating subnets_info from AnsibleModule to OpenStackModule,MERGED,2020-11-23 14:12:08.000000000,2020-12-02 17:49:20.000000000,2020-12-02 17:49:20.000000000,"[{'_account_id': 10969}, {'_account_id': 22348}]","[{'number': 1, 'created': '2020-11-23 14:12:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ansible-collections-openstack/commit/427188210fceecf005763c4bb2bf8dea29d29941', 'message': 'Migrating subnets_info from AnsibleModule to OpenStackModule\n\nChange-Id: I5590976964543188518200f2b31a1603eb30f39b\n'}, {'number': 2, 'created': '2020-11-23 17:10:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ansible-collections-openstack/commit/83bdfcbcb414b52ed139f36ceaa4a0ce211f77d7', 'message': 'Migrating subnets_info from AnsibleModule to OpenStackModule\n\nRemoved ""ansible-deprecated-no-collection-name"" for subnets_info for ansible 2.10\n\nChange-Id: I5590976964543188518200f2b31a1603eb30f39b\n'}, {'number': 3, 'created': '2020-11-23 17:22:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ansible-collections-openstack/commit/a390aededc01a346f83c77576d106df9fbeee3ed', 'message': 'Migrating subnets_info from AnsibleModule to OpenStackModule\n\nUpdated module, added ""deprecated_names"", Removed ""ansible-deprecated-no-collection-name"" for subnets_info for ansible 2.10\n\nChange-Id: I5590976964543188518200f2b31a1603eb30f39b\n'}, {'number': 4, 'created': '2020-12-01 22:42:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ansible-collections-openstack/commit/88432d34f9b8db2582ab04ca3aabc625e716cb81', 'message': 'Migrating subnets_info from AnsibleModule to OpenStackModule\n\nUpdated module, added ""deprecated_names"", Removed ""ansible-deprecated-no-collection-name"" for subnets_info for ansible 2.10\n\nChange-Id: I5590976964543188518200f2b31a1603eb30f39b\n'}, {'number': 5, 'created': '2020-12-02 12:27:25.000000000', 'files': ['tests/sanity/ignore-2.10.txt', 'plugins/modules/subnets_info.py', 'tests/sanity/ignore-2.11.txt'], 'web_link': 'https://opendev.org/openstack/ansible-collections-openstack/commit/d5c403cded8d9ff2d35f22416daecc3b3ec565cd', 'message': 'Migrating subnets_info from AnsibleModule to OpenStackModule\n\nUpdated module, added ""deprecated_names"", Removed ""ansible-deprecated-no-collection-name"" for subnets_info for ansible 2.10, 2.11\n\nChange-Id: I5590976964543188518200f2b31a1603eb30f39b\n'}]",5,763785,d5c403cded8d9ff2d35f22416daecc3b3ec565cd,21,2,5,32458,,,0,"Migrating subnets_info from AnsibleModule to OpenStackModule

Updated module, added ""deprecated_names"", Removed ""ansible-deprecated-no-collection-name"" for subnets_info for ansible 2.10, 2.11

Change-Id: I5590976964543188518200f2b31a1603eb30f39b
",git fetch https://review.opendev.org/openstack/ansible-collections-openstack refs/changes/85/763785/4 && git format-patch -1 --stdout FETCH_HEAD,['plugins/modules/subnets_info.py'],1,427188210fceecf005763c4bb2bf8dea29d29941,update_subnets_info,"from ansible_collections.openstack.cloud.plugins.module_utils.openstack import OpenStackModule class SubnetInfoModule(OpenStackModule): argument_spec = dict( def run(self): kwargs = self.check_versioned( filters=self.params['filters'] ) if self.params['name']: kwargs['name_or_id'] = self.params['name'] subnets = self.conn.search_subnets(**kwargs) self.exit(changed=False, openstack_subnets=subnets) def main(): module = SubnetInfoModule() module()","from ansible.module_utils.basic import AnsibleModule from ansible_collections.openstack.cloud.plugins.module_utils.openstack import openstack_full_argument_spec, openstack_cloud_from_module def main(): argument_spec = openstack_full_argument_spec( module = AnsibleModule(argument_spec) is_old_facts = module._name == 'openstack.cloud.subnets_facts' if is_old_facts: module.deprecate(""The 'openstack.cloud.subnets_facts' module has been renamed to 'openstack.cloud.subnets_info', "" ""and the renamed one no longer returns ansible_facts"", version='2.13') sdk, cloud = openstack_cloud_from_module(module) try: subnets = cloud.search_subnets(module.params['name'], module.params['filters']) if is_old_facts: module.exit_json(changed=False, ansible_facts=dict( openstack_subnets=subnets)) else: module.exit_json(changed=False, openstack_subnets=subnets) except sdk.exceptions.OpenStackCloudException as e: module.fail_json(msg=str(e))",16,20
openstack%2Fansible-collections-openstack~master~I85e19f0db8b4ee549137249477d0b7f5d82e9865,openstack/ansible-collections-openstack,master,I85e19f0db8b4ee549137249477d0b7f5d82e9865,Migrating networks_info from AnsibleModule to OpenStackModule,MERGED,2020-11-20 10:49:02.000000000,2020-12-02 17:31:27.000000000,2020-12-02 17:31:27.000000000,"[{'_account_id': 10969}, {'_account_id': 22348}, {'_account_id': 32458}]","[{'number': 1, 'created': '2020-11-20 10:49:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ansible-collections-openstack/commit/fdbf31618ab8d3bacf1d7d7ded0bfece69334d4a', 'message': 'Migrating networks_info from AnsibleModule to OpenStackModule\n\nChange-Id: I85e19f0db8b4ee549137249477d0b7f5d82e9865\n'}, {'number': 2, 'created': '2020-11-23 08:46:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ansible-collections-openstack/commit/f6020808e8766890a017f81a7d4608d09f0879d6', 'message': 'Migrating networks_info from AnsibleModule to OpenStackModule\n\nMigrated networks_info module to OpenStackModule and updated playbook to test the module in CI jobs.\n\nChange-Id: I85e19f0db8b4ee549137249477d0b7f5d82e9865\n'}, {'number': 3, 'created': '2020-11-23 08:53:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ansible-collections-openstack/commit/eb378f379cc933a8ecde015922b023b8c25543b1', 'message': 'Migrating networks_info from AnsibleModule to OpenStackModule\n\nMigrated networks_info module to OpenStackModule and updated playbook to test the module in CI jobs.\n\nChange-Id: I85e19f0db8b4ee549137249477d0b7f5d82e9865\n'}, {'number': 4, 'created': '2020-11-23 13:50:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ansible-collections-openstack/commit/0e2303adc79abee3bfa6c1b4cf4f6dec60887588', 'message': 'Migrating networks_info from AnsibleModule to OpenStackModule\n\nMigrated networks_info module to OpenStackModule and updated playbook to test the module in CI jobs.\nRemoved ""ansible-deprecated-no-collection-name"" exception for networks_info for ansible 2.10 and 2.11\n\nChange-Id: I85e19f0db8b4ee549137249477d0b7f5d82e9865\n'}, {'number': 5, 'created': '2020-11-23 17:38:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ansible-collections-openstack/commit/b89bb49d7f33a44958c88b94b80b5ecf9b9b1c6a', 'message': 'Migrating networks_info from AnsibleModule to OpenStackModule\n\nMigrated networks_info module to OpenStackModule and updated playbook to test the module in CI jobs. Added deprecated_names tyo module.\nRemoved ""ansible-deprecated-no-collection-name"" exception for networks_info for ansible 2.10 and 2.11\n\nChange-Id: I85e19f0db8b4ee549137249477d0b7f5d82e9865\n'}, {'number': 6, 'created': '2020-11-24 21:01:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ansible-collections-openstack/commit/39de863c3792fd863f91b871d62855265e1fddbc', 'message': 'Migrating networks_info from AnsibleModule to OpenStackModule\n\nMigrated networks_info module to OpenStackModule and updated playbook to test the module in CI jobs. Added deprecated_names tyo module.\nRemoved ""ansible-deprecated-no-collection-name"" exception for networks_info for ansible 2.10 and 2.11. Reverted \'False\' to \'false\' and updated filters (case sensitive) to check for \'False\' instead\n\nChange-Id: I85e19f0db8b4ee549137249477d0b7f5d82e9865\n'}, {'number': 7, 'created': '2020-11-25 11:13:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ansible-collections-openstack/commit/3a14cbdbb934ccf79ca037ce9b1dccc34d3c60b8', 'message': 'Migrating networks_info from AnsibleModule to OpenStackModule\n\nMigrated networks_info module to OpenStackModule and updated playbook to test the module in CI jobs. Added deprecated_names tyo module.\nRemoved ""ansible-deprecated-no-collection-name"" exception for networks_info for ansible 2.10 and 2.11. Reverted \'False\' to \'false\' and updated filters (case sensitive) to check for \'False\' instead\n\nChange-Id: I85e19f0db8b4ee549137249477d0b7f5d82e9865\n'}, {'number': 8, 'created': '2020-12-01 22:35:03.000000000', 'files': ['plugins/modules/networks_info.py', 'tests/sanity/ignore-2.10.txt', 'ci/roles/network/tasks/main.yml', 'tests/sanity/ignore-2.11.txt'], 'web_link': 'https://opendev.org/openstack/ansible-collections-openstack/commit/d36ac1f1255b2712911865ce3e27deef1933abe4', 'message': 'Migrating networks_info from AnsibleModule to OpenStackModule\n\nMigrated networks_info module to OpenStackModule and updated playbook to test the module in CI jobs. Added deprecated_names tyo module.\nRemoved ""ansible-deprecated-no-collection-name"" exception for networks_info for ansible 2.10 and 2.11. Reverted \'False\' to \'false\' and updated filters (case sensitive) to check for \'False\' instead\n\nChange-Id: I85e19f0db8b4ee549137249477d0b7f5d82e9865\n'}]",3,763543,d36ac1f1255b2712911865ce3e27deef1933abe4,24,3,8,32458,,,0,"Migrating networks_info from AnsibleModule to OpenStackModule

Migrated networks_info module to OpenStackModule and updated playbook to test the module in CI jobs. Added deprecated_names tyo module.
Removed ""ansible-deprecated-no-collection-name"" exception for networks_info for ansible 2.10 and 2.11. Reverted 'False' to 'false' and updated filters (case sensitive) to check for 'False' instead

Change-Id: I85e19f0db8b4ee549137249477d0b7f5d82e9865
",git fetch https://review.opendev.org/openstack/ansible-collections-openstack refs/changes/43/763543/8 && git format-patch -1 --stdout FETCH_HEAD,['plugins/modules/networks_info.py'],1,fdbf31618ab8d3bacf1d7d7ded0bfece69334d4a,,"from ansible_collections.openstack.cloud.plugins.module_utils.openstack import OpenStackModule class NetworkInfoModule(OpenStackModule): argument_spec = dict( def run(self): kwargs = self.check_versioned( filters=self.params['filters'] ) if self.params['name']: kwargs['name_or_id'] = self.params['name'] networks = self.conn.search_networks(**kwargs) self.exit(changed=False, openstack_networks=networks) def main(): module = NetworkInfoModule() module()","from ansible.module_utils.basic import AnsibleModule from ansible_collections.openstack.cloud.plugins.module_utils.openstack import ( openstack_full_argument_spec, openstack_cloud_from_module, ) def main(): argument_spec = openstack_full_argument_spec( module = AnsibleModule(argument_spec) is_old_facts = module._name == 'openstack.cloud.networks_facts' if is_old_facts: module.deprecate(""The 'openstack.cloud.networks_facts' module has been renamed to 'openstack.cloud.networks_info', "" ""and the renamed one no longer returns ansible_facts"", version='2.13') sdk, cloud = openstack_cloud_from_module(module) try: networks = cloud.search_networks(module.params['name'], module.params['filters']) if is_old_facts: module.exit_json(changed=False, ansible_facts=dict( openstack_networks=networks)) else: module.exit_json(changed=False, openstack_networks=networks) except sdk.exceptions.OpenStackCloudException as e: module.fail_json(msg=str(e))",17,23
openstack%2Ftripleo-ansible~master~Ifc3bd9cfcfcf77ba5d6355d28b79e5d05209a511,openstack/tripleo-ansible,master,Ifc3bd9cfcfcf77ba5d6355d28b79e5d05209a511,tripleo_config_download: make it work without Swift,MERGED,2020-09-22 16:06:30.000000000,2020-12-02 17:17:25.000000000,2020-12-02 17:17:25.000000000,"[{'_account_id': 7144}, {'_account_id': 7353}, {'_account_id': 14985}, {'_account_id': 22348}, {'_account_id': 23181}, {'_account_id': 25877}]","[{'number': 1, 'created': '2020-09-22 16:06:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ansible/commit/6669e5972e7b7a14b0c158b0403f04510d200841', 'message': 'WIP - tripleo_config_download: make it work without Swift\n\nThis patch will make the tripleo_config_download module to work without\nSwift.\n\nDepends-On: https://review.opendev.org/753394\nChange-Id: Ifc3bd9cfcfcf77ba5d6355d28b79e5d05209a511\n'}, {'number': 2, 'created': '2020-09-24 14:18:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ansible/commit/7c940300bc8ee816ae5d999ebc84c6b4e6e9c415', 'message': 'tripleo_config_download: make it work without Swift\n\nThis patch will make the tripleo_config_download module to work without\nSwift.\n\nDepends-On: https://review.opendev.org/753394\nChange-Id: Ifc3bd9cfcfcf77ba5d6355d28b79e5d05209a511\n'}, {'number': 3, 'created': '2020-09-24 14:18:52.000000000', 'files': ['tripleo_ansible/ansible_plugins/modules/tripleo_config_download.py'], 'web_link': 'https://opendev.org/openstack/tripleo-ansible/commit/b125689ce301eef98b4b9865f2013132f99b6b07', 'message': 'tripleo_config_download: make it work without Swift\n\nThis patch will make the tripleo_config_download module to work without\nSwift.\n\nDepends-On: https://review.opendev.org/753394\nChange-Id: Ifc3bd9cfcfcf77ba5d6355d28b79e5d05209a511\n'}]",0,753395,b125689ce301eef98b4b9865f2013132f99b6b07,17,6,3,3153,,,0,"tripleo_config_download: make it work without Swift

This patch will make the tripleo_config_download module to work without
Swift.

Depends-On: https://review.opendev.org/753394
Change-Id: Ifc3bd9cfcfcf77ba5d6355d28b79e5d05209a511
",git fetch https://review.opendev.org/openstack/tripleo-ansible refs/changes/95/753395/1 && git format-patch -1 --stdout FETCH_HEAD,['tripleo_ansible/ansible_plugins/modules/tripleo_config_download.py'],1,6669e5972e7b7a14b0c158b0403f04510d200841,config-download/swift," swift=False, heat=heat, container=plan, container_config=config_container, config_dir=work_dir, config_type=config_type, preserve_config=download)"," swift = tripleo.get_object_client() swift, heat, plan, config_container, config_type) if download: ooo_config.download_overcloud_config( swift, config_container, work_dir)",7,11
openstack%2Fopenstack-ansible-os_senlin~master~I2e3191559c5aab37aa655d7a8831b0ae66e5f71d,openstack/openstack-ansible-os_senlin,master,I2e3191559c5aab37aa655d7a8831b0ae66e5f71d,Fix senlin health manager group name,MERGED,2020-12-01 17:52:14.000000000,2020-12-02 17:11:19.000000000,2020-12-02 17:08:56.000000000,"[{'_account_id': 22348}, {'_account_id': 25023}, {'_account_id': 28752}, {'_account_id': 31542}]","[{'number': 1, 'created': '2020-12-01 17:52:14.000000000', 'files': ['defaults/main.yml'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_senlin/commit/c1d9d9978ba99550b071ac401aeed8cb167e629a', 'message': 'Fix senlin health manager group name\n\nChange-Id: I2e3191559c5aab37aa655d7a8831b0ae66e5f71d\n'}]",0,764989,c1d9d9978ba99550b071ac401aeed8cb167e629a,9,4,1,28619,,,0,"Fix senlin health manager group name

Change-Id: I2e3191559c5aab37aa655d7a8831b0ae66e5f71d
",git fetch https://review.opendev.org/openstack/openstack-ansible-os_senlin refs/changes/89/764989/1 && git format-patch -1 --stdout FETCH_HEAD,['defaults/main.yml'],1,c1d9d9978ba99550b071ac401aeed8cb167e629a,, group: senlin_health_manager, group: senlin_health-manager,1,1
openstack%2Ftripleo-specs~master~Ic74a9a6b1014e3a3a4b5e08bd99ad8bdb8f5211f,openstack/tripleo-specs,master,Ic74a9a6b1014e3a3a4b5e08bd99ad8bdb8f5211f,Introduce tripleo-ceph spec,MERGED,2020-04-25 16:31:20.000000000,2020-12-02 17:09:55.000000000,2020-12-02 17:07:48.000000000,"[{'_account_id': 6413}, {'_account_id': 6796}, {'_account_id': 6926}, {'_account_id': 7160}, {'_account_id': 8449}, {'_account_id': 9003}, {'_account_id': 14270}, {'_account_id': 14985}, {'_account_id': 15205}, {'_account_id': 16643}, {'_account_id': 18002}, {'_account_id': 20172}, {'_account_id': 20182}, {'_account_id': 22348}, {'_account_id': 24245}, {'_account_id': 25402}]","[{'number': 1, 'created': '2020-04-25 16:31:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-specs/commit/7218afdfedfe9f63d9e66c8fa5f19e84d1830ea0', 'message': 'WIP/DNM Introduce tripleo-cephadm spec\n\nChange-Id: Ic74a9a6b1014e3a3a4b5e08bd99ad8bdb8f5211f\n'}, {'number': 2, 'created': '2020-04-25 16:43:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-specs/commit/456c1d9d2acc0ed42cfa2977c2c1cd03e096f663', 'message': 'WIP/DNM Introduce tripleo-cephadm spec\n\nChange-Id: Ic74a9a6b1014e3a3a4b5e08bd99ad8bdb8f5211f\n'}, {'number': 3, 'created': '2020-04-29 09:55:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-specs/commit/9c165ef5ce7c6774569e31a2e886d1b1215cd0d7', 'message': 'WIP/DNM Introduce tripleo-cephadm spec\n\nChange-Id: Ic74a9a6b1014e3a3a4b5e08bd99ad8bdb8f5211f\n'}, {'number': 4, 'created': '2020-05-05 07:48:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-specs/commit/fb154e7750eb62f7286005e311f70799ed12cd71', 'message': 'WIP/DNM Introduce tripleo-cephadm spec\n\nCo-Authored-By: Francesco Pantano <fpantano@redhat.com>\nChange-Id: Ic74a9a6b1014e3a3a4b5e08bd99ad8bdb8f5211f\n'}, {'number': 5, 'created': '2020-05-05 08:02:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-specs/commit/a95122db8174d4ef8916ed21259a614bfa902157', 'message': 'WIP/DNM Introduce tripleo-cephadm spec\n\nCo-Authored-By: Francesco Pantano <fpantano@redhat.com>\nChange-Id: Ic74a9a6b1014e3a3a4b5e08bd99ad8bdb8f5211f\n'}, {'number': 6, 'created': '2020-05-05 10:50:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-specs/commit/f53dc177c72853f43ec64c4871a1851705738410', 'message': 'WIP/DNM Introduce tripleo-cephadm spec\n\nCo-Authored-By: Francesco Pantano <fpantano@redhat.com>\nChange-Id: Ic74a9a6b1014e3a3a4b5e08bd99ad8bdb8f5211f\n'}, {'number': 7, 'created': '2020-05-05 15:42:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-specs/commit/7b549e3e0fe3cceafd8d78e7bac0b391e4605b54', 'message': 'WIP/DNM Introduce tripleo-cephadm spec\n\nCo-Authored-By: Francesco Pantano <fpantano@redhat.com>\nChange-Id: Ic74a9a6b1014e3a3a4b5e08bd99ad8bdb8f5211f\n'}, {'number': 8, 'created': '2020-05-05 15:46:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-specs/commit/decd726f43bda0164fbf852ae4e0c1ceda8087f9', 'message': 'WIP/DNM Introduce tripleo-cephadm spec\n\nCo-Authored-By: Francesco Pantano <fpantano@redhat.com>\nChange-Id: Ic74a9a6b1014e3a3a4b5e08bd99ad8bdb8f5211f\n'}, {'number': 9, 'created': '2020-05-11 10:18:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-specs/commit/9d958843edc6959f0020ee2b7579d19e2dc94858', 'message': 'WIP/DNM Introduce tripleo-cephadm spec\n\nCo-Authored-By: Francesco Pantano <fpantano@redhat.com>\nChange-Id: Ic74a9a6b1014e3a3a4b5e08bd99ad8bdb8f5211f\n'}, {'number': 10, 'created': '2020-05-11 10:59:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-specs/commit/21f6ad4e4dfcfb6b2a3ee7c0c8494a68f27e46fa', 'message': 'WIP/DNM Introduce tripleo-cephadm spec\n\nCo-Authored-By: Francesco Pantano <fpantano@redhat.com>\nChange-Id: Ic74a9a6b1014e3a3a4b5e08bd99ad8bdb8f5211f\n'}, {'number': 11, 'created': '2020-05-11 14:50:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-specs/commit/74ea4b52a8e05d50b7e28d3873d47dbaf50308a6', 'message': 'WIP/DNM Introduce tripleo-cephadm spec\n\nCo-Authored-By: Francesco Pantano <fpantano@redhat.com>\nChange-Id: Ic74a9a6b1014e3a3a4b5e08bd99ad8bdb8f5211f\n'}, {'number': 12, 'created': '2020-05-11 15:38:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-specs/commit/cb80b45763eb0b21935bb2851ad26d2942a04064', 'message': 'WIP/DNM Introduce tripleo-cephadm spec\n\nCo-Authored-By: Francesco Pantano <fpantano@redhat.com>\nChange-Id: Ic74a9a6b1014e3a3a4b5e08bd99ad8bdb8f5211f\n'}, {'number': 13, 'created': '2020-05-11 15:58:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-specs/commit/4f369247f2d4959a9b7da7c7a90d2ec19ccc3dae', 'message': 'WIP/DNM Introduce tripleo-cephadm spec\n\nCo-Authored-By: Francesco Pantano <fpantano@redhat.com>\nChange-Id: Ic74a9a6b1014e3a3a4b5e08bd99ad8bdb8f5211f\n'}, {'number': 14, 'created': '2020-05-28 02:29:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-specs/commit/9fc35108000b23417d1d3c23b51fa0486e68d6a4', 'message': 'WIP/DNM Introduce tripleo-cephadm spec\n\nCo-Authored-By: Francesco Pantano <fpantano@redhat.com>\nChange-Id: Ic74a9a6b1014e3a3a4b5e08bd99ad8bdb8f5211f\n'}, {'number': 15, 'created': '2020-05-28 02:30:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-specs/commit/a2163c70390d87b13b054fadad107820949e33ef', 'message': 'Introduce tripleo-cephadm spec\n\nCo-Authored-By: Francesco Pantano <fpantano@redhat.com>\nChange-Id: Ic74a9a6b1014e3a3a4b5e08bd99ad8bdb8f5211f\n'}, {'number': 16, 'created': '2020-05-28 11:56:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-specs/commit/f78f3694a48be115e2635ef8e39552c32fad6cda', 'message': 'Introduce tripleo-ceph spec\n\nCo-Authored-By: Francesco Pantano <fpantano@redhat.com>\nChange-Id: Ic74a9a6b1014e3a3a4b5e08bd99ad8bdb8f5211f\n'}, {'number': 17, 'created': '2020-05-28 18:11:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-specs/commit/2b03fff68612c9a53a2147e56576db25d8fb5757', 'message': 'Introduce tripleo-ceph spec\n\nCo-Authored-By: Francesco Pantano <fpantano@redhat.com>\nChange-Id: Ic74a9a6b1014e3a3a4b5e08bd99ad8bdb8f5211f\n'}, {'number': 18, 'created': '2020-05-31 18:25:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-specs/commit/7e87330dcf55e30e70c87d005a0c2d420d48c823', 'message': 'Introduce tripleo-ceph spec\n\nCo-Authored-By: Francesco Pantano <fpantano@redhat.com>\nChange-Id: Ic74a9a6b1014e3a3a4b5e08bd99ad8bdb8f5211f\n'}, {'number': 19, 'created': '2020-05-31 21:12:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-specs/commit/e711998169e3d213191c35c37eb80821186c91a0', 'message': 'Introduce tripleo-ceph spec\n\nCo-Authored-By: Francesco Pantano <fpantano@redhat.com>\nChange-Id: Ic74a9a6b1014e3a3a4b5e08bd99ad8bdb8f5211f\n'}, {'number': 20, 'created': '2020-10-01 19:22:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-specs/commit/97362cc4b37970d5c5e85462a9ed3995c58af942', 'message': 'Introduce tripleo-ceph spec\n\nCo-Authored-By: Francesco Pantano <fpantano@redhat.com>\nChange-Id: Ic74a9a6b1014e3a3a4b5e08bd99ad8bdb8f5211f\n'}, {'number': 21, 'created': '2020-10-12 20:08:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-specs/commit/9e866afdca7d251e1fc2bf518c7a4e052afd5b52', 'message': 'Introduce tripleo-ceph spec\n\nCo-Authored-By: Francesco Pantano <fpantano@redhat.com>\nChange-Id: Ic74a9a6b1014e3a3a4b5e08bd99ad8bdb8f5211f\n'}, {'number': 22, 'created': '2020-10-12 20:19:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-specs/commit/f19b773a8511b52beab96452604ede723db71bf6', 'message': 'Introduce tripleo-ceph spec\n\nCo-Authored-By: Francesco Pantano <fpantano@redhat.com>\nChange-Id: Ic74a9a6b1014e3a3a4b5e08bd99ad8bdb8f5211f\n'}, {'number': 23, 'created': '2020-10-12 20:22:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-specs/commit/cce395082f6c9dd962fe1b81817734b1ac0b8a7f', 'message': 'Introduce tripleo-ceph spec\n\nCo-Authored-By: Francesco Pantano <fpantano@redhat.com>\nChange-Id: Ic74a9a6b1014e3a3a4b5e08bd99ad8bdb8f5211f\n'}, {'number': 24, 'created': '2020-10-13 07:54:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-specs/commit/75ff829c723baf6b7c1a30aa1bfee9234c39e461', 'message': 'Introduce tripleo-ceph spec\n\nCo-Authored-By: Francesco Pantano <fpantano@redhat.com>\nChange-Id: Ic74a9a6b1014e3a3a4b5e08bd99ad8bdb8f5211f\n'}, {'number': 25, 'created': '2020-10-13 09:38:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-specs/commit/3d9fe49dd65c349badc48f8c6a9044ba650356fa', 'message': 'Introduce tripleo-ceph spec\n\nCo-Authored-By: Francesco Pantano <fpantano@redhat.com>\nChange-Id: Ic74a9a6b1014e3a3a4b5e08bd99ad8bdb8f5211f\n'}, {'number': 26, 'created': '2020-10-27 02:37:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-specs/commit/cccc7698913c88c962284b773726b3807d8de823', 'message': 'Introduce tripleo-ceph spec\n\nCo-Authored-By: Francesco Pantano <fpantano@redhat.com>\nChange-Id: Ic74a9a6b1014e3a3a4b5e08bd99ad8bdb8f5211f\n'}, {'number': 27, 'created': '2020-10-27 03:09:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-specs/commit/f27a8a9065600b3597e47776e5c7ada6d9438b09', 'message': 'Introduce tripleo-ceph spec\n\nCo-Authored-By: Francesco Pantano <fpantano@redhat.com>\nChange-Id: Ic74a9a6b1014e3a3a4b5e08bd99ad8bdb8f5211f\n'}, {'number': 28, 'created': '2020-10-27 15:17:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-specs/commit/4e3ebb95d8293ee9c5ef4cb0dd0b3de5d44cfe8b', 'message': 'Introduce tripleo-ceph spec\n\nCo-Authored-By: Francesco Pantano <fpantano@redhat.com>\nChange-Id: Ic74a9a6b1014e3a3a4b5e08bd99ad8bdb8f5211f\n'}, {'number': 29, 'created': '2020-10-29 22:19:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-specs/commit/71631f87eb487a5646631caecc3d4c39ea436492', 'message': 'Introduce tripleo-ceph spec\n\nCo-Authored-By: Francesco Pantano <fpantano@redhat.com>\nChange-Id: Ic74a9a6b1014e3a3a4b5e08bd99ad8bdb8f5211f\n'}, {'number': 30, 'created': '2020-10-30 15:59:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-specs/commit/fa7109dedb9aa20299ac02de5a18e0639d1780c5', 'message': 'Introduce tripleo-ceph spec\n\nCo-Authored-By: Francesco Pantano <fpantano@redhat.com>\nChange-Id: Ic74a9a6b1014e3a3a4b5e08bd99ad8bdb8f5211f\n'}, {'number': 31, 'created': '2020-10-30 18:38:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-specs/commit/61d7f1cca9f6a0e7b5ce574f284cad190a3a7122', 'message': 'Introduce tripleo-ceph spec\n\nCo-Authored-By: Francesco Pantano <fpantano@redhat.com>\nChange-Id: Ic74a9a6b1014e3a3a4b5e08bd99ad8bdb8f5211f\n'}, {'number': 32, 'created': '2020-11-03 14:26:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-specs/commit/f8641f5c0f8204214cb79b7a115417b9fc5fe052', 'message': 'Introduce tripleo-ceph spec\n\nCo-Authored-By: Francesco Pantano <fpantano@redhat.com>\nChange-Id: Ic74a9a6b1014e3a3a4b5e08bd99ad8bdb8f5211f\n'}, {'number': 33, 'created': '2020-11-03 15:40:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-specs/commit/e2efac9b2300257b6ea23680cef36dc6e39bd86e', 'message': 'Introduce tripleo-ceph spec\n\nCo-Authored-By: Francesco Pantano <fpantano@redhat.com>\nChange-Id: Ic74a9a6b1014e3a3a4b5e08bd99ad8bdb8f5211f\n'}, {'number': 34, 'created': '2020-11-04 13:16:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-specs/commit/524eef2b837286a79fc129f947a832a75863672c', 'message': 'Introduce tripleo-ceph spec\n\nCo-Authored-By: Francesco Pantano <fpantano@redhat.com>\nChange-Id: Ic74a9a6b1014e3a3a4b5e08bd99ad8bdb8f5211f\n'}, {'number': 35, 'created': '2020-11-04 23:32:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-specs/commit/5c01e50f7e1683056c1fc8f9852477137a0e312e', 'message': 'Introduce tripleo-ceph spec\n\nCo-Authored-By: Francesco Pantano <fpantano@redhat.com>\nChange-Id: Ic74a9a6b1014e3a3a4b5e08bd99ad8bdb8f5211f\n'}, {'number': 36, 'created': '2020-11-05 23:15:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-specs/commit/15a88a74cb2adf19f0e8b5055027cad74c8da176', 'message': 'Introduce tripleo-ceph spec\n\nCo-Authored-By: Francesco Pantano <fpantano@redhat.com>\nChange-Id: Ic74a9a6b1014e3a3a4b5e08bd99ad8bdb8f5211f\n'}, {'number': 37, 'created': '2020-11-06 23:05:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-specs/commit/9dcd466b8de410ce9c39226daeaf49ffaa391ed0', 'message': 'Introduce tripleo-ceph spec\n\nCo-Authored-By: Francesco Pantano <fpantano@redhat.com>\nChange-Id: Ic74a9a6b1014e3a3a4b5e08bd99ad8bdb8f5211f\n'}, {'number': 38, 'created': '2020-11-09 13:56:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-specs/commit/f84116a1a80220485ccb8182aa305705ff40e86c', 'message': 'Introduce tripleo-ceph spec\n\nCo-Authored-By: Francesco Pantano <fpantano@redhat.com>\nChange-Id: Ic74a9a6b1014e3a3a4b5e08bd99ad8bdb8f5211f\n'}, {'number': 39, 'created': '2020-11-10 19:04:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-specs/commit/778d562654e86ad54e28656db1fd0d35360a98dd', 'message': 'Introduce tripleo-ceph spec\n\nCo-Authored-By: Francesco Pantano <fpantano@redhat.com>\nChange-Id: Ic74a9a6b1014e3a3a4b5e08bd99ad8bdb8f5211f\n'}, {'number': 40, 'created': '2020-11-25 16:36:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-specs/commit/d0347489cef0e1b8999b42b2da6c05378935aae9', 'message': 'Introduce tripleo-ceph spec\n\nCo-Authored-By: Francesco Pantano <fpantano@redhat.com>\nChange-Id: Ic74a9a6b1014e3a3a4b5e08bd99ad8bdb8f5211f\n'}, {'number': 41, 'created': '2020-12-01 16:20:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-specs/commit/0f6a041d904483c2ae5a8a1d384b0c166c255f16', 'message': 'Introduce tripleo-ceph spec\n\nCo-Authored-By: Francesco Pantano <fpantano@redhat.com>\nChange-Id: Ic74a9a6b1014e3a3a4b5e08bd99ad8bdb8f5211f\n'}, {'number': 42, 'created': '2020-12-02 15:59:02.000000000', 'files': ['specs/wallaby/tripleo-ceph.rst'], 'web_link': 'https://opendev.org/openstack/tripleo-specs/commit/2fda7fdcfa87cc1b7c0ff531186db93e17e00b2f', 'message': 'Introduce tripleo-ceph spec\n\nCo-Authored-By: Francesco Pantano <fpantano@redhat.com>\nChange-Id: Ic74a9a6b1014e3a3a4b5e08bd99ad8bdb8f5211f\n'}]",132,723108,2fda7fdcfa87cc1b7c0ff531186db93e17e00b2f,170,16,42,18002,,,0,"Introduce tripleo-ceph spec

Co-Authored-By: Francesco Pantano <fpantano@redhat.com>
Change-Id: Ic74a9a6b1014e3a3a4b5e08bd99ad8bdb8f5211f
",git fetch https://review.opendev.org/openstack/tripleo-specs refs/changes/08/723108/21 && git format-patch -1 --stdout FETCH_HEAD,['specs/victoria/tripleo-cephadm.rst'],1,7218afdfedfe9f63d9e66c8fa5f19e84d1830ea0,tripleo-cephadm,".. This work is licensed under a Creative Commons Attribution 3.0 Unported License. http://creativecommons.org/licenses/by/3.0/legalcode =============== TripleO cephadm =============== https://blueprints.launchpad.net/tripleo/+spec/tripleo-cephadm A light Ansible framework for TripleO integration with Ceph clusters deployed with cephadm and managed with Ceph orchestrator. Problem Description =================== Starting in the Octopus release, Ceph has its own day1 tool called cephadm [1]_ and it's own day2 tool called orchestrator [2]_ which will replace ceph-ansible [3]_. What should TripleO's Ceph integration do about this? We currently provide the following user experience: Describe an OpenStack deployment, which includes Ceph, and TripleO will ""make it so"" The above has been true for TripleO since Kilo and should continue. TripleO should also continue hyper-converged support (collocation of OpenStack and Ceph containers). There's sufficient value in both of these (one tool and hyper-convergence) to justify this project. At the same time we want to deploy Ceph in a way consistent with the way the Ceph project is moving and decouple the complexity of day2 management of Ceph from TripleO. Proposed Change =============== Overview -------- Create a new OpenStack repository called tripleo-cephadm for Ceph server deployment and some Ceph server configuration and introduce a new role into tripleo-ansible for Ceph client configuration. These two projects will have the following goals. tripleo-cephadm project goals: - Provide Ansible roles which TripleO can use to deploy Ceph using cephadm - Focus on the day1 problem for Ceph RBD, RGW, CephFS, and Dashboard deployment - For day2 Ceph operations use cephadm, orchestrator, or Dashboard directly unless the day2 Ceph change involves adding hardware and other exceptions as needed - TripleO stack updates do not trigger tripleo-cephadm by default - Provide an opinionated Ceph installation based on parameters from TripleO and Ironic - Provide Ceph integration but maximize orthogonality between OpenStack and Ceph - Configure cephx keyrings and pools for OpenStack on deployed Ceph cluster - Support collocation (hyperconvergence) of OpenStack/Ceph containers on same host - cephadm reconciliation loop must not break OpenStack configuration - TripleO configuration updates must not break Ceph configuration tripleo-ansible/roles/ceph_client goals: - Configure OpenStack services as clients of an external Ceph cluster (in the case of collocation, the ceph cluster is still logically external) - Provide Ceph configuration files and cephx keys for OpenStack clients of RBD, RGW, CephFS (Nova, Cinder, Glance, Manila) - Full multiclient support, e.g. one OpenStack deployment may use multiple Ceph clusters, e.g. multibackend Glance - Configure clients quickly, e.g. generate the key in one place, without a container, and copy it efficiently Why propose openstack/tripleo-cephadm as a separate repository instead of a set of roles within tripleo-ansible? This is similar to how openstack/puppet-tripleo used to call openstack/puppet-ceph and follows the same pattern as openstack/tripleo-validations. We also hope it makes things easier for openstack/tripleo-ansible maintainers. Alternatives ------------ We could ask deployers to do this: - Deploy hardware with metalsmith - Use cephadm and orchestrator directly to configure that hardware with Ceph and create OpenStack pools accessible by CephX clients - Use TripleO to configure OpenStack We want the above to be possible for all who choose it, but also offer an option to automate step two. The TripleO project has already ensured that the move from one to three is automated and requires only two commands (see first paragraph of Provisioning Baremetal Before Overcloud Deploy [4]_). The alternative is to not automate step two, but that is user unfriendly. Another alternative is to continue using ceph-ansible as we do today. However, even though ceph-ansible can deploy Octopus today and will continue to support deployment of Luminous and Nautilus, the project is in the process of adding a playbook for converting Ceph clusters that it has deployed to cephadm [5]_ so seems to be moving away from true Octopus support. Ceph-ansible has lot of code and day2 support; porting it to cephadm or orechstrator is more work than starting a project with a smaller scope. Security Impact --------------- Describe any potential security impact on the system. Some of the items to consider include: * Does this change touch sensitive data such as tokens, keys, or user data? * Does this change involve cryptography or hashing? * Does this change require the use of sudo or any elevated privileges? * Does this change involve using or parsing user-provided data? This could be directly at the API level or indirectly such as changes to a cache layer. * Can this change enable a resource exhaustion attack, such as allowing a single API interaction to consume significant server resources? Some examples of this include launching subprocesses for each connection, or entity expansion attacks in XML. For more detailed guidance, please see the OpenStack Security Guidelines as a reference (https://wiki.openstack.org/wiki/Security/Guidelines). These guidelines are a work in progress and are designed to help you identify security best practices. For further information, feel free to reach out to the OpenStack Security Group at openstack-security@lists.openstack.org. Upgrade Impact -------------- Describe potential upgrade impact on the system. * Is this change meant to become the default for deployments at some point in the future? How do we migrate existing deployments to that feature? * Can the system be upgraded to this feature using the upgrade hooks provided by the composable services framework? * Describe any plans to deprecate configuration values or features. (For example, if we change the directory name that instances are stored in, how do we handle instance directories created before the change landed? Do we move them? Do we have a special case in the code? Do we assume that the operator will recreate all the instances in their cloud?) * Please state anything that operators upgrading from the previous release need to be aware of. Do they need to perform extra manual operations? Other End User Impact --------------------- Are there ways a user will interact with this feature? Performance Impact ------------------ Describe any potential performance impact on the system, for example how often will new code be called, and is there a major change to the calling pattern of existing code. Examples of things to consider here include: * A small change in a utility function or a commonly used decorator can have a large impacts on performance. Other Deployer Impact --------------------- Discuss things that will affect how you deploy and configure OpenStack that have not already been mentioned, such as: * What config options are being added? Should they be more generic than proposed (for example a flag that other hypervisor drivers might want to implement as well)? Are the default values ones which will work well in real deployments? * Is this a change that takes immediate effect after its merged, or is it something that has to be explicitly enabled? Developer Impact ---------------- Discuss things that will affect other developers working on OpenStack. Implementation ============== In general we will defer as much as possible to the following pattern (though the order might vary for scaling up or down). - Provision Baremetal [4]_ - Ceph orchestrator [2]_ - Stack updates In the past stack updates did everything, but the split for Metalsmith (described in Provisioning Baremetal Before Overcloud Deploy [4]_) gives an opening in the deployment steps for Ceph's new native tools to be run independently for day2 operations. The tripleo-cephadm project wishes to automate for day1 and ensure (by CI, documentation, and code only if necessary) that day2 can be done with Cephs native tools. Assignee(s) ----------- Contributors: fmount fultonj gfidente jmolmo Work Items ---------- Proposed Schedule ----------------- - OpenStack V: start tripleo-cephadm and tripleo-ansible/roles/ceph_client as experimental and then default (only if it is stable). If tripleo-cephadm is not yet stable, then Victoria will release with Nautilus support as deployed by ceph-ansible just like Ussuri. - OpenStack W: tripleo-cephadm default, tripleo-ansible/roles/ceph_* deprecated except ceph_client Work items or tasks -- break the feature up into the things that need to be done to implement it. Those parts might end up being done by different people, but we're mostly trying to understand the timeline for implementation. Dependencies ============ * Include specific references to specs and/or blueprints in tripleo, or in other projects, that this one either depends on or is related to. * If this requires functionality of another project that is not currently used by Tripleo (such as the glance v2 API when we previously only required v1), document that fact. * Does this feature require any new library dependencies or code otherwise not included in OpenStack? Or does it depend on a specific version of library? Testing ======= Please discuss how the change will be tested. Is this untestable in CI given current limitations (specific hardware / software configurations available)? If so, are there mitigation plans (3rd party testing, gate enhancements, etc). Documentation Impact ==================== What is the impact on the docs? Don't repeat details discussed above, but please reference them here. References ========== .. [1] `cephadm <https://github.com/ceph/ceph-ansible>`_ .. [2] `orchestrator <https://docs.ceph.com/docs/octopus/mgr/orchestrator/>`_ .. [3] `ceph-ansible <https://github.com/ceph/ceph-ansible>`_ .. [4] `Provisioning Baremetal Before Overcloud Deploy <https://docs.openstack.org/project-deploy-guide/tripleo-docs/latest/provisioning/baremetal_provision.html>`_ .. [5] `Add playbook for converting cluster to cephadm <https://github.com/ceph/ceph-ansible/pull/5269>`_ ",,287,0
openstack%2Fopenstack-ansible~master~I347bd6bafceca1040eb39ce948b195dc4f64f748,openstack/openstack-ansible,master,I347bd6bafceca1040eb39ce948b195dc4f64f748,[DNM] Remove magnum tempest blacklists,ABANDONED,2020-12-01 16:41:48.000000000,2020-12-02 17:08:01.000000000,,[{'_account_id': 22348}],"[{'number': 1, 'created': '2020-12-01 16:41:48.000000000', 'files': ['tests/roles/bootstrap-host/templates/user_variables_magnum.yml.j2'], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/746307fae5914209101c233c810067523e687e37', 'message': '[DNM] Remove magnum tempest blacklists\n\nChange-Id: I347bd6bafceca1040eb39ce948b195dc4f64f748\n'}]",0,764986,746307fae5914209101c233c810067523e687e37,3,1,1,28619,,,0,"[DNM] Remove magnum tempest blacklists

Change-Id: I347bd6bafceca1040eb39ce948b195dc4f64f748
",git fetch https://review.opendev.org/openstack/openstack-ansible refs/changes/86/764986/1 && git format-patch -1 --stdout FETCH_HEAD,['tests/roles/bootstrap-host/templates/user_variables_magnum.yml.j2'],1,746307fae5914209101c233c810067523e687e37,,," # NOTE(noonedeadpunk): We comment these tests out because of weird magnum things happening like # http://paste.openstack.org/show/790131/ # But when ""b''"" around auth toke is dropped, everything is fine. tempest_test_blacklist: - magnum_tempest_plugin.tests.api.v1.test_cluster.ClusterTest.test_create_list_sign_delete_clusters - magnum_tempest_plugin.tests.api.v1.test_cluster.ClusterTest.test_create_cluster_with_nonexisting_flavor ",0,8
openstack%2Fopenstack-ansible-os_magnum~master~Ibf36a1fcf0cca49f77eb3bad91fd887b903f26ef,openstack/openstack-ansible-os_magnum,master,Ibf36a1fcf0cca49f77eb3bad91fd887b903f26ef,[DNM] Test CI,ABANDONED,2020-12-01 16:48:18.000000000,2020-12-02 17:07:54.000000000,,[{'_account_id': 22348}],"[{'number': 1, 'created': '2020-12-01 16:48:18.000000000', 'files': ['noop'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_magnum/commit/2a055976944a61b4207028ff6d887771329e422a', 'message': '[DNM] Test CI\n\nDepends-On: https://review.opendev.org/c/openstack/openstack-ansible/+/764986\nChange-Id: Ibf36a1fcf0cca49f77eb3bad91fd887b903f26ef\n'}]",0,764987,2a055976944a61b4207028ff6d887771329e422a,3,1,1,28619,,,0,"[DNM] Test CI

Depends-On: https://review.opendev.org/c/openstack/openstack-ansible/+/764986
Change-Id: Ibf36a1fcf0cca49f77eb3bad91fd887b903f26ef
",git fetch https://review.opendev.org/openstack/openstack-ansible-os_magnum refs/changes/87/764987/1 && git format-patch -1 --stdout FETCH_HEAD,['noop'],1,2a055976944a61b4207028ff6d887771329e422a,,,,0,0
openstack%2Fcinder~stable%2Fussuri~I18b4b0b1b71904b766f7b89df49f5539e3c7662a,openstack/cinder,stable/ussuri,I18b4b0b1b71904b766f7b89df49f5539e3c7662a,Fix: listing volumes with filters,MERGED,2020-10-21 13:46:36.000000000,2020-12-02 17:02:06.000000000,2020-11-25 23:00:03.000000000,"[{'_account_id': 5314}, {'_account_id': 7198}, {'_account_id': 10118}, {'_account_id': 10459}, {'_account_id': 12032}, {'_account_id': 12369}, {'_account_id': 15386}, {'_account_id': 22248}, {'_account_id': 22348}, {'_account_id': 22510}, {'_account_id': 23613}, {'_account_id': 24921}, {'_account_id': 25243}, {'_account_id': 26077}, {'_account_id': 26537}, {'_account_id': 27615}, {'_account_id': 28801}]","[{'number': 1, 'created': '2020-10-21 13:46:36.000000000', 'files': ['cinder/tests/unit/api/v3/test_volumes.py', 'releasenotes/notes/fix-list-volume-filtering-3f2bf93ab9b98974.yaml', 'cinder/volume/api.py'], 'web_link': 'https://opendev.org/openstack/cinder/commit/f94fc87e4d659ef1f59802d05b4f87a5a8c1bab2', 'message': ""Fix: listing volumes with filters\n\nThis patch includes 2 fix for the following issues:\n\n1) ast.literal_eval() doesn't work with int and float values\nSee comment inline\n\n2) Do not traverse and modify the same dict:\nwhile traversing filters dict, we're modifying it inside the loop\nwhich distorts the order of elements (adding modified elements in the\nend). to fix this, i've used a temp dict that will be used to traverse\nand modification will be done in the filters dict.\n\nCloses-Bug: #1883490\n\nChange-Id: I18b4b0b1b71904b766f7b89df49f5539e3c7662a\n(cherry picked from commit aed94a76cf62fdaedff793c7a9d998920b56c072)\n""}]",0,759056,f94fc87e4d659ef1f59802d05b4f87a5a8c1bab2,68,17,1,27615,,,0,"Fix: listing volumes with filters

This patch includes 2 fix for the following issues:

1) ast.literal_eval() doesn't work with int and float values
See comment inline

2) Do not traverse and modify the same dict:
while traversing filters dict, we're modifying it inside the loop
which distorts the order of elements (adding modified elements in the
end). to fix this, i've used a temp dict that will be used to traverse
and modification will be done in the filters dict.

Closes-Bug: #1883490

Change-Id: I18b4b0b1b71904b766f7b89df49f5539e3c7662a
(cherry picked from commit aed94a76cf62fdaedff793c7a9d998920b56c072)
",git fetch https://review.opendev.org/openstack/cinder refs/changes/56/759056/1 && git format-patch -1 --stdout FETCH_HEAD,"['cinder/tests/unit/api/v3/test_volumes.py', 'releasenotes/notes/fix-list-volume-filtering-3f2bf93ab9b98974.yaml', 'cinder/volume/api.py']",3,f94fc87e4d659ef1f59802d05b4f87a5a8c1bab2,bug/1883490-stable/ussuri," temp_dict = filters.copy() for key, val in temp_dict.items(): # this is required as ast.literal_eval(<int>/<float>) # raises exception. Eg: ast.literal_eval(5) generates # ValueError: malformed node or string: 5 if not isinstance(val, str): val = str(val)"," for key, val in filters.items():",29,2
openstack%2Fcharm-deployment-guide~master~I3e7d9ee5076375c04df2ef7edc87e18fd0617c7c,openstack/charm-deployment-guide,master,I3e7d9ee5076375c04df2ef7edc87e18fd0617c7c,Add steps for confirming IP address allocations and firewall driver,MERGED,2020-11-26 10:41:32.000000000,2020-12-02 16:51:30.000000000,2020-12-02 16:49:59.000000000,"[{'_account_id': 22348}, {'_account_id': 30561}]","[{'number': 1, 'created': '2020-11-26 10:41:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-deployment-guide/commit/f713c65204d4278da9e4bcdc685757a64e6a0fd5', 'message': ""Add steps for confirming IP address allocations and firewall driver\n\nOVN will allocate new ports/IP addresses during the migration, if\nany subnets do not have IPs free for allocation the migration will\nfail.\n\nWe have omitted a step for change of firewall driver to\n'openvswtich'.\n\nChange-Id: I3e7d9ee5076375c04df2ef7edc87e18fd0617c7c\nCloses-Bug: #1905554\n""}, {'number': 2, 'created': '2020-11-26 11:02:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-deployment-guide/commit/8776cafbeed5f3500de4a6fbb7affd09cab088a7', 'message': ""Add steps for confirming IP address allocations and firewall driver\n\nOVN will allocate new ports/IP addresses during the migration, if\nany subnets do not have IPs free for allocation the migration will\nfail.\n\nWe have omitted a step for change of firewall driver to\n'openvswtich'.\n\nChange-Id: I3e7d9ee5076375c04df2ef7edc87e18fd0617c7c\nCloses-Bug: #1905554\n""}, {'number': 3, 'created': '2020-11-26 11:04:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-deployment-guide/commit/54355ff205d5671ca20d2869f2b11210c6ed8fc2', 'message': ""Add steps for confirming IP address allocations and firewall driver\n\nOVN will allocate new ports/IP addresses during the migration, if\nany subnets do not have IPs free for allocation the migration will\nfail.\n\nWe have omitted a step for change of firewall driver to\n'openvswtich'.\n\nChange-Id: I3e7d9ee5076375c04df2ef7edc87e18fd0617c7c\nCloses-Bug: #1905554\n""}, {'number': 4, 'created': '2020-12-02 07:31:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-deployment-guide/commit/63050821f9885ba22f571ebca7c00f214f40d3b0', 'message': ""Add steps for confirming IP address allocations and firewall driver\n\nOVN will allocate new ports/IP addresses during the migration, if\nany subnets do not have IPs free for allocation the migration will\nfail.\n\nWe have omitted a step for change of firewall driver to\n'openvswtich'.\n\nChange-Id: I3e7d9ee5076375c04df2ef7edc87e18fd0617c7c\nCloses-Bug: #1905554\n""}, {'number': 5, 'created': '2020-12-02 16:13:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-deployment-guide/commit/698b4f839adece4bb645afdd6bee631aec370c9d', 'message': ""Add steps for confirming IP address allocations and firewall driver\n\nOVN will allocate new ports/IP addresses during the migration, if\nany subnets do not have IPs free for allocation the migration will\nfail.\n\nWe have omitted a step for change of firewall driver to\n'openvswtich'.\n\nChange-Id: I3e7d9ee5076375c04df2ef7edc87e18fd0617c7c\nCloses-Bug: #1905554\n""}, {'number': 6, 'created': '2020-12-02 16:37:35.000000000', 'files': ['deploy-guide/source/app-ovn.rst'], 'web_link': 'https://opendev.org/openstack/charm-deployment-guide/commit/57d609fa74dd87d3b680bcdc10ca164dda06e026', 'message': ""Add steps for confirming IP address allocations and firewall driver\n\nOVN will allocate new ports/IP addresses during the migration, if\nany subnets do not have IPs free for allocation the migration will\nfail.\n\nWe have omitted a step for change of firewall driver to\n'openvswtich'.\n\nChange-Id: I3e7d9ee5076375c04df2ef7edc87e18fd0617c7c\nCloses-Bug: #1905554\n""}]",15,764319,57d609fa74dd87d3b680bcdc10ca164dda06e026,20,2,6,13686,,,0,"Add steps for confirming IP address allocations and firewall driver

OVN will allocate new ports/IP addresses during the migration, if
any subnets do not have IPs free for allocation the migration will
fail.

We have omitted a step for change of firewall driver to
'openvswtich'.

Change-Id: I3e7d9ee5076375c04df2ef7edc87e18fd0617c7c
Closes-Bug: #1905554
",git fetch https://review.opendev.org/openstack/charm-deployment-guide refs/changes/19/764319/4 && git format-patch -1 --stdout FETCH_HEAD,['deploy-guide/source/app-ovn.rst'],1,f713c65204d4278da9e4bcdc685757a64e6a0fd5,bug/1905554,"If this can be done then steps #1 and #9 below can be skipped, where it is2. Confirm that all subnets have IP addresses available for allocation During the migration OVN may create a new port in subnets and allocate an IP address to it. Depending on type of network this port will be used for the OVN metadata service or as SNAT address for an external router interface. If a subnet has no free IP addresses for allocation the migration will fail. 3. Make a fresh backup copy of the Neutron database 4. Deploy the OVN components and Vault5. Unseal `Vault`_, enable `Certificate Lifecycle Management`_ and6. Change firewall driver to 'openvswitch' To be able to successfully clean up after the Neutron agents on hypervisors we need to instruct the neutron-openvswitch charm to use the 'openvswitch' firewall driver. This is accomplished by setting the ``firewall-driver`` configuration option to 'openvswitch'. .. code-block:: none juju config neutron-openvswitch firewall-driver=openvswitch 7. Pause neutron-openvswitch and/or neutron-gateway units.8. Deploy the Neutron OVN plugin application9. Adjust MTU on overlay networks (if required)10. Enable the Neutron OVN plugin11. Pause the Neutron API units12. Perform initial synchronization of the Neutron and OVN databases13. (Optional) Perform Neutron database surgery to update ``network_type`` of14. Resume the Neutron API units15. Migrate hypervisors and gateways16. Post migration tasks","If this can be done then steps #1 and #7 below can be skipped, where it is2. Make a fresh backup copy of the Neutron database 3. Deploy the OVN components and Vault4. Unseal `Vault`_, enable `Certificate Lifecycle Management`_ and5. Pause neutron-openvswitch and/or neutron-gateway units.6. Deploy the Neutron OVN plugin application7. Adjust MTU on overlay networks (if required)8. Enable the Neutron OVN plugin9. Pause the Neutron API units10. Perform initial synchronization of the Neutron and OVN databases11. (Optional) Perform Neutron database surgery to update ``network_type`` of12. Resume the Neutron API units13. Migrate hypervisors and gateways14. Post migration tasks",33,14
openstack%2Fnova~stable%2Ftrain~Id6e2be2b407eb08e269c35e0f89d235c67a1ab99,openstack/nova,stable/train,Id6e2be2b407eb08e269c35e0f89d235c67a1ab99,Retry on vmware create_vm when it fails,NEW,2020-11-30 10:28:41.000000000,2020-12-02 16:40:15.000000000,,"[{'_account_id': 17685}, {'_account_id': 20363}, {'_account_id': 22348}]","[{'number': 1, 'created': '2020-11-30 10:28:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/edf5028d5afb361847c43121313153334f52a37c', 'message': 'Retry on vmware create_vm when it fails\n\nIn some cases the logical switch is not ready when the VM is booted,\nso retry can help avoid the error.\n\nChange-Id: Id6e2be2b407eb08e269c35e0f89d235c67a1ab99\n'}, {'number': 2, 'created': '2020-12-01 06:25:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/263231205ed3104e1a9c55c3814582ad83238f06', 'message': 'Retry on vmware create_vm when it fails\n\nIn some cases the logical switch is not ready when the VM is booted,\nso retry can help avoid the error.\n\nChange-Id: Id6e2be2b407eb08e269c35e0f89d235c67a1ab99\n(Cherry picked from commit: Id6e2be2b407eb08e269c35e0f89d235c67a1ab99)\n'}, {'number': 3, 'created': '2020-12-02 08:45:33.000000000', 'files': ['nova/virt/vmwareapi/vm_util.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/b42bc2aa5e89e4cc62a9a7692a591af83a86e284', 'message': 'Retry on vmware create_vm when it fails\n\nIn some cases the logical switch is not ready when the VM is booted,\nso retry can help avoid the error.\n\nChange-Id: Id6e2be2b407eb08e269c35e0f89d235c67a1ab99\n(Cherry picked from commit: Id6e2be2b407eb08e269c35e0f89d235c67a1ab99)\n'}]",1,764515,b42bc2aa5e89e4cc62a9a7692a591af83a86e284,16,3,3,20363,,,0,"Retry on vmware create_vm when it fails

In some cases the logical switch is not ready when the VM is booted,
so retry can help avoid the error.

Change-Id: Id6e2be2b407eb08e269c35e0f89d235c67a1ab99
(Cherry picked from commit: Id6e2be2b407eb08e269c35e0f89d235c67a1ab99)
",git fetch https://review.opendev.org/openstack/nova refs/changes/15/764515/1 && git format-patch -1 --stdout FETCH_HEAD,['nova/virt/vmwareapi/vm_util.py'],1,edf5028d5afb361847c43121313153334f52a37c,,"from oslo_service import loopingcall@loopingcall.RetryDecorator( max_retry_count=5, inc_sleep_time=2, max_sleep_time=10, exceptions=(vexc.VimFaultException,))",,4,0
openstack%2Fpuppet-pacemaker~master~I3a9b852da78426ae45d99987022b630d833a84dc,openstack/puppet-pacemaker,master,I3a9b852da78426ae45d99987022b630d833a84dc,Add fence_crosslink support,MERGED,2020-11-30 10:56:29.000000000,2020-12-02 16:35:09.000000000,2020-12-02 16:35:09.000000000,"[{'_account_id': 14985}, {'_account_id': 20172}, {'_account_id': 20778}, {'_account_id': 22348}]","[{'number': 1, 'created': '2020-11-30 10:56:29.000000000', 'files': ['manifests/stonith/fence_crosslink.pp', 'agent_generator/src_xml/fence_crosslink.xml', 'agent_generator/variables.sh'], 'web_link': 'https://opendev.org/openstack/puppet-pacemaker/commit/2f4b6fafcb265c81072d072f4fac489f24c647dd', 'message': 'Add fence_crosslink support\n\nThis adds support for the newly introduced fence_crosslink\ntwo-node fence agents pushed upstream:\nhttps://github.com/ClusterLabs/fence-agents/pull/360\n\nChange-Id: I3a9b852da78426ae45d99987022b630d833a84dc\n'}]",1,764633,2f4b6fafcb265c81072d072f4fac489f24c647dd,8,4,1,20172,,,0,"Add fence_crosslink support

This adds support for the newly introduced fence_crosslink
two-node fence agents pushed upstream:
https://github.com/ClusterLabs/fence-agents/pull/360

Change-Id: I3a9b852da78426ae45d99987022b630d833a84dc
",git fetch https://review.opendev.org/openstack/puppet-pacemaker refs/changes/33/764633/1 && git format-patch -1 --stdout FETCH_HEAD,"['manifests/stonith/fence_crosslink.pp', 'agent_generator/src_xml/fence_crosslink.xml', 'agent_generator/variables.sh']",3,2f4b6fafcb265c81072d072f4fac489f24c647dd,crosslink," ""fence_crosslink:None""",,344,0
openstack%2Ftripleo-heat-templates~master~Ibba61afbeb3957a955aa6d75e8258279a60fd141,openstack/tripleo-heat-templates,master,Ibba61afbeb3957a955aa6d75e8258279a60fd141,Add qemu metadata to compute node when tls for live migration,MERGED,2020-12-01 13:52:27.000000000,2020-12-02 16:35:02.000000000,2020-12-02 16:35:02.000000000,"[{'_account_id': 14985}, {'_account_id': 20172}, {'_account_id': 20733}, {'_account_id': 22348}, {'_account_id': 23181}, {'_account_id': 24245}, {'_account_id': 27419}]","[{'number': 1, 'created': '2020-12-01 13:52:27.000000000', 'files': ['deployment/nova/nova-libvirt-container-puppet.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/83e6f9a6c5c6559134cbaeadab1b998bdfef86ad', 'message': 'Add qemu metadata to compute node when tls for live migration\n\nWith I7f583d18e558b95922a66eb539cc91de74409c96 certificates are\nmoved to use bind mounts and in case of UseTLSTransportForNbd\nto create the required certificates even if UseTLSTransportForNbd\nis set to False. In case of UseTLSTransportForNbd is False the\ncompute node still need the qemu metadata to have permissions\nto request the certificates for the nbd tls use case.\n\nChange-Id: Ibba61afbeb3957a955aa6d75e8258279a60fd141\n'}]",0,764941,83e6f9a6c5c6559134cbaeadab1b998bdfef86ad,9,7,1,17216,,,0,"Add qemu metadata to compute node when tls for live migration

With I7f583d18e558b95922a66eb539cc91de74409c96 certificates are
moved to use bind mounts and in case of UseTLSTransportForNbd
to create the required certificates even if UseTLSTransportForNbd
is set to False. In case of UseTLSTransportForNbd is False the
compute node still need the qemu metadata to have permissions
to request the certificates for the nbd tls use case.

Change-Id: Ibba61afbeb3957a955aa6d75e8258279a60fd141
",git fetch https://review.opendev.org/openstack/tripleo-heat-templates refs/changes/41/764941/1 && git format-patch -1 --stdout FETCH_HEAD,['deployment/nova/nova-libvirt-container-puppet.yaml'],1,83e6f9a6c5c6559134cbaeadab1b998bdfef86ad,compute_metadata," - service: qemu network: {get_param: [ServiceNetMap, NovaLibvirtNetwork]} type: node"," - if: - use_tls_for_nbd - - service: qemu network: {get_param: [ServiceNetMap, NovaLibvirtNetwork]} type: node - null",3,7
openstack%2Fkuryr-kubernetes~master~Id53f321ef94d2ed1802c28cebefd7040c9944526,openstack/kuryr-kubernetes,master,Id53f321ef94d2ed1802c28cebefd7040c9944526,Fix spelling errors.,MERGED,2020-12-02 15:18:42.000000000,2020-12-02 16:28:03.000000000,2020-12-02 16:26:32.000000000,"[{'_account_id': 13692}, {'_account_id': 22348}, {'_account_id': 27032}]","[{'number': 1, 'created': '2020-12-02 15:18:42.000000000', 'files': ['doc/source/devref/port_manager.rst', 'doc/source/specs/pike/contrail_support.rst', 'doc/source/devref/network_policy.rst', 'doc/source/devref/vif_handler_drivers_design.rst'], 'web_link': 'https://opendev.org/openstack/kuryr-kubernetes/commit/643468ae681560d9f32c701d4a000b0b5177dc61', 'message': 'Fix spelling errors.\n\nCorrects typos in kuryr-kubernetes documentation.\n\nChange-Id: Id53f321ef94d2ed1802c28cebefd7040c9944526\nCloses-Bug: #1906521\n'}]",0,765153,643468ae681560d9f32c701d4a000b0b5177dc61,9,3,1,32533,,,0,"Fix spelling errors.

Corrects typos in kuryr-kubernetes documentation.

Change-Id: Id53f321ef94d2ed1802c28cebefd7040c9944526
Closes-Bug: #1906521
",git fetch https://review.opendev.org/openstack/kuryr-kubernetes refs/changes/53/765153/1 && git format-patch -1 --stdout FETCH_HEAD,"['doc/source/devref/port_manager.rst', 'doc/source/specs/pike/contrail_support.rst', 'doc/source/devref/network_policy.rst', 'doc/source/devref/vif_handler_drivers_design.rst']",4,643468ae681560d9f32c701d4a000b0b5177dc61,bug/1906521,VIF-handler was intended to handle VIFs. Currently it is responsible forto implement it. It is possible to have manually precreated specific ports in,VIV-handler was intended to handle VIFs. Currently it is responsible forto implement it. It is possile to have manually precreated specific ports in,5,5
openstack%2Fcharm-swift-proxy~master~I87eb23de94e3f2f5b06d44df1f8bd9d2324c3585,openstack/charm-swift-proxy,master,I87eb23de94e3f2f5b06d44df1f8bd9d2324c3585,Adding debug messages,ABANDONED,2020-12-02 15:35:37.000000000,2020-12-02 15:57:01.000000000,,"[{'_account_id': 20648}, {'_account_id': 22348}]","[{'number': 1, 'created': '2020-12-02 15:35:37.000000000', 'files': ['hooks/swift_hooks.py', '.juju-charm', 'lib/swift_utils.py'], 'web_link': 'https://opendev.org/openstack/charm-swift-proxy/commit/69a6d9c8d01ca5a9570e5c94a9e32714ef0a72d2', 'message': 'Adding debug messages\n\nChange-Id: I87eb23de94e3f2f5b06d44df1f8bd9d2324c3585\n'}]",1,765160,69a6d9c8d01ca5a9570e5c94a9e32714ef0a72d2,4,2,1,10058,,,0,"Adding debug messages

Change-Id: I87eb23de94e3f2f5b06d44df1f8bd9d2324c3585
",git fetch https://review.opendev.org/openstack/charm-swift-proxy refs/changes/60/765160/1 && git format-patch -1 --stdout FETCH_HEAD,"['hooks/swift_hooks.py', '.juju-charm', 'lib/swift_utils.py']",3,69a6d9c8d01ca5a9570e5c94a9e32714ef0a72d2,fix-swift-rep-port," log(""ERLON: update_rings: nodes={}"".format(nodes))",,10,0
openstack%2Fcharm-swift-storage~master~I25d4a123811fa3da96821c9da28c72dded47fdc7,openstack/charm-swift-storage,master,I25d4a123811fa3da96821c9da28c72dded47fdc7,Add .juju-charm file to test mounts,ABANDONED,2020-12-02 15:32:44.000000000,2020-12-02 15:56:19.000000000,,"[{'_account_id': 20648}, {'_account_id': 22348}]","[{'number': 1, 'created': '2020-12-02 15:32:44.000000000', 'files': ['.juju-charm'], 'web_link': 'https://opendev.org/openstack/charm-swift-storage/commit/2e635f516cbf698e1a9c8a673d60def8eea42d27', 'message': 'Add .juju-charm file to test mounts\n\nChange-Id: I25d4a123811fa3da96821c9da28c72dded47fdc7\n'}]",0,765156,2e635f516cbf698e1a9c8a673d60def8eea42d27,4,2,1,10058,,,0,"Add .juju-charm file to test mounts

Change-Id: I25d4a123811fa3da96821c9da28c72dded47fdc7
",git fetch https://review.opendev.org/openstack/charm-swift-storage refs/changes/56/765156/1 && git format-patch -1 --stdout FETCH_HEAD,['.juju-charm'],1,2e635f516cbf698e1a9c8a673d60def8eea42d27,fix-swift-rep-port,cs:swift-storage-272,,1,0
openstack%2Ftripleo-quickstart~master~If035ac781ee12706e5400e72d214e824bc7d2a63,openstack/tripleo-quickstart,master,If035ac781ee12706e5400e72d214e824bc7d2a63,ensure dlrn current is actually pulling current,MERGED,2020-12-01 05:22:01.000000000,2020-12-02 15:50:16.000000000,2020-12-02 07:11:08.000000000,"[{'_account_id': 8449}, {'_account_id': 9592}, {'_account_id': 9976}, {'_account_id': 12393}, {'_account_id': 14985}, {'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2020-12-01 05:22:01.000000000', 'files': ['config/release/tripleo-ci/CentOS-8/master.yml'], 'web_link': 'https://opendev.org/openstack/tripleo-quickstart/commit/dc25776f630bfc9e90965a6d3c7e8d23aec8232c', 'message': 'ensure dlrn current is actually pulling current\n\ndlrn-current was pulling current-tripleo content\nand thus the lastest merged patches were not entering\nthe workflow properly as seen here:\n\n+ DLRN_PATH_TAG_NEWEST=current/82/ee/82ee84379d1c07bc4c41616006b4c225\n2020-11-29 13:02:48 | + export DLRN_PATH_TAG=current-tripleo/82/ee/82ee84379d1c07bc4c41616006b4c225\n2020-11-29 13:02:48 | + DLRN_PATH_TAG=current-tripleo/82/ee/82ee84379d1c07bc4c41616006b4c225\n2020-11-29 13:02:48 | ++ curl --silent https://trunk.rdoproject.org/centos8-master/current/82/ee/82ee84379d1c07bc4c41616006b4c225/delorean.repo -S\n\nhttps://logserver.rdoproject.org/00/763500/2/openstack-check/tripleo-ci-centos-8-ovb-3ctlr_1comp-featureset001/9db879b/logs/undercloud/home/zuul/repo_setup.log.gz\n\nThis is not a permanent fix, however should fix\nthe issue for now.\n\nRelated-Bug: #1906347\nChange-Id: If035ac781ee12706e5400e72d214e824bc7d2a63\n'}]",5,764898,dc25776f630bfc9e90965a6d3c7e8d23aec8232c,19,7,1,9592,,,0,"ensure dlrn current is actually pulling current

dlrn-current was pulling current-tripleo content
and thus the lastest merged patches were not entering
the workflow properly as seen here:

+ DLRN_PATH_TAG_NEWEST=current/82/ee/82ee84379d1c07bc4c41616006b4c225
2020-11-29 13:02:48 | + export DLRN_PATH_TAG=current-tripleo/82/ee/82ee84379d1c07bc4c41616006b4c225
2020-11-29 13:02:48 | + DLRN_PATH_TAG=current-tripleo/82/ee/82ee84379d1c07bc4c41616006b4c225
2020-11-29 13:02:48 | ++ curl --silent https://trunk.rdoproject.org/centos8-master/current/82/ee/82ee84379d1c07bc4c41616006b4c225/delorean.repo -S

https://logserver.rdoproject.org/00/763500/2/openstack-check/tripleo-ci-centos-8-ovb-3ctlr_1comp-featureset001/9db879b/logs/undercloud/home/zuul/repo_setup.log.gz

This is not a permanent fix, however should fix
the issue for now.

Related-Bug: #1906347
Change-Id: If035ac781ee12706e5400e72d214e824bc7d2a63
",git fetch https://review.opendev.org/openstack/tripleo-quickstart refs/changes/98/764898/1 && git format-patch -1 --stdout FETCH_HEAD,['config/release/tripleo-ci/CentOS-8/master.yml'],1,dc25776f630bfc9e90965a6d3c7e8d23aec8232c,,"# IF you need to RECREATE or RERUN on a SPECIFIC HASH, to pin current override ""current_url"" # To override current-tripleo, use ""dlrn_hash_tag"" dlrn_baseurl: ""https://trunk.rdoproject.org/{{ distro_ver }}-{{ release }}"" current_url: ""{{ dlrn_baseurl }}/component/tripleo/current/delorean.repo"" # get the baseurl with hash for ""current"" CURRENT_URL=`curl --silent {{ current_url }} -S 2>>~/current_curl_errors.log | grep baseurl | cut -d= -f2` if [[ -z ""$CURRENT_URL"" ]]; then echo ""Failed to parse dlrn hash for current"" exit 1 fi # this routine is for current-tripleo only. export CURRENT_TRIPLEO_URL=""{{ dlrn_baseurl }}/${DLRN_PATH_TAG}"" # sub in the mirror $NODEPOOL_RDO_PROXY export CURRENT_URL_MIRROR=${CURRENT_URL/https:\/\/trunk.rdoproject.org/$NODEPOOL_RDO_PROXY} export CURRENT_TRIPLEO_URL_MIRROR=${CURRENT_TRIPLEO_URL/https:\/\/trunk.rdoproject.org/$NODEPOOL_RDO_PROXY} down_url: ""${CURRENT_TRIPLEO_URL_MIRROR}/delorean.repo"" baseurl: $CURRENT_URL_MIRROR","dlrn_baseurl: ""https://trunk.rdoproject.org/{{ distro_ver }}-{{ release }}"" {% if dlrn_hash_path_newest is defined and dlrn_hash_path_newest %} export DLRN_PATH_TAG_NEWEST=""current/{{ dlrn_hash_path_newest }}"" {% elif dlrn_hash_tag_newest is match(""^[a-zA-Z0-9]{32}$"") %} export DLRN_PATH_TAG_NEWEST=""current/{{ dlrn_hash_tag_newest[:2] }}/{{ dlrn_hash_tag_newest[2:4] }}/{{ dlrn_hash_tag_newest }}"" {% else %} export DLRN_PATH_TAG_NEWEST=""{{ dlrn_hash_tag_newest }}"" {% endif %} rdo_dlrn=`curl --silent https://trunk.rdoproject.org/{{ distro_ver }}-{{ release }}/${DLRN_PATH_TAG_NEWEST}/delorean.repo -S 2>>~/dlrn_repo_curl_errors.log | grep baseurl | grep ""component/tripleo"" | cut -d= -f2` if [[ -z ""$rdo_dlrn"" ]]; then echo ""Failed to parse dlrn hash"" exit 1 fi export RDO_DLRN_REPO=${rdo_dlrn/https:\/\/trunk.rdoproject.org/$NODEPOOL_RDO_PROXY} down_url: ""https://trunk.rdoproject.org/{{ distro_ver }}-{{ release }}/${DLRN_PATH_TAG}/delorean.repo"" baseurl: $RDO_DLRN_REPO",21,16
openstack%2Foctavia~master~Ie6ccc4bf0017587df8e8e29d8ee3bf5c19e6d615,openstack/octavia,master,Ie6ccc4bf0017587df8e8e29d8ee3bf5c19e6d615,Fix nf_conntrack_buckets sysctl in Amphora,MERGED,2020-08-28 19:39:11.000000000,2020-12-02 15:41:35.000000000,2020-12-02 15:39:30.000000000,"[{'_account_id': 1131}, {'_account_id': 6469}, {'_account_id': 7249}, {'_account_id': 22348}, {'_account_id': 29244}]","[{'number': 1, 'created': '2020-08-28 19:39:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/octavia/commit/ee4acdefa740426f44481c42b78d21a4ea8ee2d7', 'message': ""Fix nf_conntrack_buckets sysctl in Amphora\n\nSetting nf_conntrack_buckets in the amphora namespace fails because this\nsysctl can only be set in the initial namespace (cf kernel doc at\nhttps://www.kernel.org/doc/Documentation/networking/nf_conntrack-sysctl.txt)\n\nThis commit allows to set nf_conntrack_buckets in the initial namespace,\nthe value is then inherited by other namespaces.\n\nConntrack is not enabled in the main namespace, the new default value\ndoesn't affect this namespace behavior.\n\nStory: 2008028\nTask: 40682\n\nChange-Id: Ie6ccc4bf0017587df8e8e29d8ee3bf5c19e6d615\n""}, {'number': 2, 'created': '2020-09-10 11:51:32.000000000', 'files': ['releasenotes/notes/fix-nf_conntrack_buckets-sysctl-75ae6dbb9d052863.yaml', 'elements/haproxy-octavia/post-install.d/20-haproxy-tune-kernel', 'octavia/amphorae/backends/agent/api_server/templates/amphora-netns.systemd.j2'], 'web_link': 'https://opendev.org/openstack/octavia/commit/64a301d4ec85a1bc9b208e60d7958a89e6972976', 'message': ""Fix nf_conntrack_buckets sysctl in Amphora\n\nSetting nf_conntrack_buckets in the amphora namespace fails because this\nsysctl can only be set in the initial namespace (cf kernel doc at\nhttps://www.kernel.org/doc/Documentation/networking/nf_conntrack-sysctl.txt)\n\nThis commit allows to set nf_conntrack_buckets in the initial namespace,\nthe value is then inherited by other namespaces.\n\nConntrack is not enabled in the main namespace, the new default value\ndoesn't affect this namespace behavior.\n\nStory: 2008028\nTask: 40682\n\nChange-Id: Ie6ccc4bf0017587df8e8e29d8ee3bf5c19e6d615\n""}]",0,748749,64a301d4ec85a1bc9b208e60d7958a89e6972976,14,5,2,29244,,,0,"Fix nf_conntrack_buckets sysctl in Amphora

Setting nf_conntrack_buckets in the amphora namespace fails because this
sysctl can only be set in the initial namespace (cf kernel doc at
https://www.kernel.org/doc/Documentation/networking/nf_conntrack-sysctl.txt)

This commit allows to set nf_conntrack_buckets in the initial namespace,
the value is then inherited by other namespaces.

Conntrack is not enabled in the main namespace, the new default value
doesn't affect this namespace behavior.

Story: 2008028
Task: 40682

Change-Id: Ie6ccc4bf0017587df8e8e29d8ee3bf5c19e6d615
",git fetch https://review.opendev.org/openstack/octavia refs/changes/49/748749/2 && git format-patch -1 --stdout FETCH_HEAD,"['releasenotes/notes/fix-nf_conntrack_buckets-sysctl-75ae6dbb9d052863.yaml', 'elements/haproxy-octavia/post-install.d/20-haproxy-tune-kernel', 'octavia/amphorae/backends/agent/api_server/templates/amphora-netns.systemd.j2']",3,ee4acdefa740426f44481c42b78d21a4ea8ee2d7,,"# Set nf_conntrack_buckets sysctl in the main namespace (nf_conntrack_buckets # cannot be set in another net namespace, but its value is inherited from the # main namespace) ExecStart=-/sbin/sysctl -w net.netfilter.nf_conntrack_buckets=125000",,9,1
openstack%2Ftripleo-heat-templates~stable%2Fussuri~Iea8cccd77caac4b84764d84a213918ed57bd4e3e,openstack/tripleo-heat-templates,stable/ussuri,Iea8cccd77caac4b84764d84a213918ed57bd4e3e,Set correct default NovaLibvirtCPUMode,MERGED,2020-11-27 17:02:28.000000000,2020-12-02 15:05:50.000000000,2020-12-02 15:02:44.000000000,"[{'_account_id': 14985}, {'_account_id': 20172}, {'_account_id': 20733}, {'_account_id': 22348}, {'_account_id': 23181}, {'_account_id': 23811}]","[{'number': 1, 'created': '2020-11-27 17:02:28.000000000', 'files': ['deployment/nova/nova-compute-container-puppet.yaml', 'releasenotes/notes/nova_compute_default_cpu_mode-cda2bb3e56463b3a.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/e511431347a61ada0b9046a6ceaee9ccf5839e58', 'message': ""Set correct default NovaLibvirtCPUMode\n\nhttps://review.opendev.org/q/I8df21d5d171976cbb8670dc5aef744b5fae657b2\nintroduced THT parameters to set libvirt/cpu_mode. The patch sets the\nNovaLibvirtCPUMode wrong to 'none' string which results in puppet-nova\nnot to handle the default cases correct and sets libvirt/cpu_mode to\nnone which results in 'qemu64' CPU model, which is highly buggy and\nundesirable for production usage.  This changes the default to the\nrecommended CPU mode 'host-model', for various benefits documented\nelsewhere.\n\nCloses-Bug: #1905544\n\nChange-Id: Iea8cccd77caac4b84764d84a213918ed57bd4e3e\n(cherry picked from commit c290a5e3a10b2ca6599b09f813da875d6aaa4f9f)\n""}]",0,764313,e511431347a61ada0b9046a6ceaee9ccf5839e58,17,6,1,17216,,,0,"Set correct default NovaLibvirtCPUMode

https://review.opendev.org/q/I8df21d5d171976cbb8670dc5aef744b5fae657b2
introduced THT parameters to set libvirt/cpu_mode. The patch sets the
NovaLibvirtCPUMode wrong to 'none' string which results in puppet-nova
not to handle the default cases correct and sets libvirt/cpu_mode to
none which results in 'qemu64' CPU model, which is highly buggy and
undesirable for production usage.  This changes the default to the
recommended CPU mode 'host-model', for various benefits documented
elsewhere.

Closes-Bug: #1905544

Change-Id: Iea8cccd77caac4b84764d84a213918ed57bd4e3e
(cherry picked from commit c290a5e3a10b2ca6599b09f813da875d6aaa4f9f)
",git fetch https://review.opendev.org/openstack/tripleo-heat-templates refs/changes/13/764313/1 && git format-patch -1 --stdout FETCH_HEAD,"['deployment/nova/nova-compute-container-puppet.yaml', 'releasenotes/notes/nova_compute_default_cpu_mode-cda2bb3e56463b3a.yaml']",2,e511431347a61ada0b9046a6ceaee9ccf5839e58,fix_default_cpu_mode-stable/ussuri,"--- fixes: - | https://review.opendev.org/q/I8df21d5d171976cbb8670dc5aef744b5fae657b2 introduced THT parameters to set libvirt/cpu_mode. The patch sets the NovaLibvirtCPUMode wrong to 'none' string which results in puppet-nova not to handle the default cases correct and sets libvirt/cpu_mode to none which results in 'qemu64' CPU model, which is highly buggy and undesirable for production usage. This changes the default to the recommended CPU mode 'host-model', for various benefits documented elsewhere. ",,12,1
openstack%2Fpython-brick-cinderclient-ext~master~I51b7a7a36c1478d261eb0eba948803f3f614b4f0,openstack/python-brick-cinderclient-ext,master,I51b7a7a36c1478d261eb0eba948803f3f614b4f0,Update tox.ini for wallaby supported pythons,MERGED,2020-11-23 15:47:50.000000000,2020-12-02 14:31:23.000000000,2020-12-02 14:25:33.000000000,"[{'_account_id': 5997}, {'_account_id': 22348}, {'_account_id': 27615}]","[{'number': 1, 'created': '2020-11-23 15:47:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-brick-cinderclient-ext/commit/20eeea46564f3e06cafe7ab73b3646387eea1b6c', 'message': 'Update tox.ini for wallaby supported pythons\n\nThe wallaby PTI specifies python 3.6 and 3.8 as the supported\nwallaby versions.\n\nChange-Id: I51b7a7a36c1478d261eb0eba948803f3f614b4f0\n'}, {'number': 2, 'created': '2020-11-24 02:01:28.000000000', 'files': ['.zuul.yaml', 'tox.ini'], 'web_link': 'https://opendev.org/openstack/python-brick-cinderclient-ext/commit/6b6bbd670971f58faa2509dbd3195e24cc1882dc', 'message': 'Update tox.ini for wallaby supported pythons\n\nThe wallaby PTI specifies python 3.6 and 3.8 as the supported\nwallaby versions.\n\nChange-Id: I51b7a7a36c1478d261eb0eba948803f3f614b4f0\n'}]",0,763802,6b6bbd670971f58faa2509dbd3195e24cc1882dc,10,3,2,5314,,,0,"Update tox.ini for wallaby supported pythons

The wallaby PTI specifies python 3.6 and 3.8 as the supported
wallaby versions.

Change-Id: I51b7a7a36c1478d261eb0eba948803f3f614b4f0
",git fetch https://review.opendev.org/openstack/python-brick-cinderclient-ext refs/changes/02/763802/2 && git format-patch -1 --stdout FETCH_HEAD,['tox.ini'],1,20eeea46564f3e06cafe7ab73b3646387eea1b6c,wallaby-pti,# python runtimes: https://governance.openstack.org/tc/reference/project-testing-interface.html#tested-runtimes[testenv:functional-py38],# python runtimes: https://governance.openstack.org/tc/reference/runtimes/ussuri.html[testenv:functional-py37],2,2
openstack%2Fcinder~master~Ib198372bf3e125a88d607c71377c95a24ab584ad,openstack/cinder,master,Ib198372bf3e125a88d607c71377c95a24ab584ad,Fixed an issue with creating a backup from snapshot with NFS volume driver.,MERGED,2020-07-25 18:19:32.000000000,2020-12-02 14:15:02.000000000,2020-11-14 19:42:23.000000000,"[{'_account_id': 4523}, {'_account_id': 9008}, {'_account_id': 9535}, {'_account_id': 10118}, {'_account_id': 11611}, {'_account_id': 11904}, {'_account_id': 12016}, {'_account_id': 12017}, {'_account_id': 12032}, {'_account_id': 12033}, {'_account_id': 12369}, {'_account_id': 14384}, {'_account_id': 15386}, {'_account_id': 15941}, {'_account_id': 19933}, {'_account_id': 22248}, {'_account_id': 22348}, {'_account_id': 22510}, {'_account_id': 23613}, {'_account_id': 24814}, {'_account_id': 24815}, {'_account_id': 24921}, {'_account_id': 25243}, {'_account_id': 25678}, {'_account_id': 26077}, {'_account_id': 26537}, {'_account_id': 28801}, {'_account_id': 29705}, {'_account_id': 30688}, {'_account_id': 32159}]","[{'number': 1, 'created': '2020-07-25 18:19:32.000000000', 'files': ['cinder/tests/unit/volume/drivers/test_nfs.py', 'releasenotes/notes/bug-1888951-backup-from-nfs-snapshot-2e06235eb318b852.yaml', 'cinder/volume/drivers/remotefs.py'], 'web_link': 'https://opendev.org/openstack/cinder/commit/a21bf41413b8e5b56c1a61460039ec7609f45042', 'message': 'Fixed an issue with creating a backup from snapshot with NFS volume driver.\n\nChange-Id: Ib198372bf3e125a88d607c71377c95a24ab584ad\nCloses-Bug: 1888951\n'}]",2,743040,a21bf41413b8e5b56c1a61460039ec7609f45042,41,30,1,29568,,,0,"Fixed an issue with creating a backup from snapshot with NFS volume driver.

Change-Id: Ib198372bf3e125a88d607c71377c95a24ab584ad
Closes-Bug: 1888951
",git fetch https://review.opendev.org/openstack/cinder refs/changes/40/743040/1 && git format-patch -1 --stdout FETCH_HEAD,"['cinder/tests/unit/volume/drivers/test_nfs.py', 'releasenotes/notes/bug-1888951-backup-from-nfs-snapshot-2e06235eb318b852.yaml', 'cinder/volume/drivers/remotefs.py']",3,a21bf41413b8e5b56c1a61460039ec7609f45042,bug/1888951," status = snapshot.status acceptable_states = ['available', 'backing-up'] self._validate_state(status, acceptable_states, obj_description='snapshot', invalid_exc=exception.InvalidSnapshot)"," if snapshot.status != 'available': msg = _('Snapshot status must be ""available"" to clone. ' 'But is: %(status)s') % {'status': snapshot.status} raise exception.InvalidSnapshot(msg)",22,12
openstack%2Ftempest~master~Ie4d4aba15d626d24c56280521aae5be33529bab4,openstack/tempest,master,Ie4d4aba15d626d24c56280521aae5be33529bab4,"Revert ""Add related test to Bug #1732428""",ABANDONED,2020-12-02 10:52:42.000000000,2020-12-02 14:04:48.000000000,,"[{'_account_id': 5689}, {'_account_id': 5803}, {'_account_id': 8556}, {'_account_id': 9708}, {'_account_id': 15334}, {'_account_id': 22348}, {'_account_id': 22873}, {'_account_id': 23181}, {'_account_id': 28332}, {'_account_id': 28627}]","[{'number': 1, 'created': '2020-12-02 10:52:42.000000000', 'files': ['releasenotes/notes/add-compute-feature-shelve-migrate-fdbd3633abe65c4e.yaml', 'tempest/config.py', 'tempest/scenario/test_shelve_instance.py'], 'web_link': 'https://opendev.org/openstack/tempest/commit/42616e3869ba2a8445f372cd7209b026be6c1896', 'message': 'Revert ""Add related test to Bug #1732428""\n\nThis reverts commit 0a9b8235b6a3222b3b0ef721c1651d0cf1f5f906.\n\nThis is currently failing and blocking the Nova gate.\n\nChange-Id: Ie4d4aba15d626d24c56280521aae5be33529bab4\nCloses-Bug: #1906428\n'}]",0,765079,42616e3869ba2a8445f372cd7209b026be6c1896,4,10,1,10135,,,0,"Revert ""Add related test to Bug #1732428""

This reverts commit 0a9b8235b6a3222b3b0ef721c1651d0cf1f5f906.

This is currently failing and blocking the Nova gate.

Change-Id: Ie4d4aba15d626d24c56280521aae5be33529bab4
Closes-Bug: #1906428
",git fetch https://review.opendev.org/openstack/tempest refs/changes/79/765079/1 && git format-patch -1 --stdout FETCH_HEAD,"['releasenotes/notes/add-compute-feature-shelve-migrate-fdbd3633abe65c4e.yaml', 'tempest/config.py', 'tempest/scenario/test_shelve_instance.py']",3,42616e3869ba2a8445f372cd7209b026be6c1896,bug/1732428," def _create_server_then_shelve_and_unshelve(self, boot_from_volume=False):"," * check the existence of the timestamp file in the unshelved instance, after a cold migrate credentials = ['primary', 'admin'] @classmethod def setup_clients(cls): super(TestShelveInstance, cls).setup_clients() cls.admin_servers_client = cls.os_admin.servers_client def _cold_migrate_server(self, server): src_host = self.get_host_for_server(server['id']) self.admin_servers_client.migrate_server(server['id']) waiters.wait_for_server_status(self.servers_client, server['id'], 'VERIFY_RESIZE') self.servers_client.confirm_resize_server(server['id']) waiters.wait_for_server_status(self.servers_client, server['id'], 'ACTIVE') dst_host = self.get_host_for_server(server['id']) self.assertNotEqual(src_host, dst_host) def _create_server_then_shelve_and_unshelve(self, boot_from_volume=False, cold_migrate=False): if cold_migrate: # Prevent bug #1732428 from coming back self._cold_migrate_server(server) @decorators.attr(type='slow') @decorators.idempotent_id('1295fd9e-193a-4cf8-b211-55358e021bae') @testtools.skipUnless(CONF.network.public_network_id, 'The public_network_id option must be specified.') @testtools.skipUnless(CONF.compute_feature_enabled.cold_migration, 'Cold migration not available.') @testtools.skipUnless(CONF.compute_feature_enabled.shelve_migrate, 'Shelve migrate not available.') @testtools.skipUnless(CONF.compute.min_compute_nodes > 1, 'Less than 2 compute nodes, skipping multinode ' 'tests.') @utils.services('compute', 'network', 'image') def test_cold_migrate_unshelved_instance(self): self._create_server_then_shelve_and_unshelve(cold_migrate=True)",1,53
openstack%2Fironic-python-agent~master~Icb4f66a02b298b4d165ebb58134cd31029e535cc,openstack/ironic-python-agent,master,Icb4f66a02b298b4d165ebb58134cd31029e535cc,Bring up VLAN interfaces and include in introspection report,MERGED,2020-10-30 14:40:59.000000000,2020-12-02 14:00:59.000000000,2020-12-02 13:59:28.000000000,"[{'_account_id': 1926}, {'_account_id': 4571}, {'_account_id': 10239}, {'_account_id': 21909}, {'_account_id': 22348}, {'_account_id': 23181}, {'_account_id': 23851}]","[{'number': 1, 'created': '2020-10-30 14:40:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic-python-agent/commit/767da2d2a30e2f1bb06ee1291c492f49124ec9af', 'message': ""[WIP] Bring up VLAN interfaces and include in introspection report\n\nAdd the ability to bring up VLAN interfaces and include them in the\nintrospection report.  A new configuration field is added -\n``ipa-vlan-interfaces``, which defines either the VLAN interface to\nenable, the interface to use, or 'all' - which indicates all\ninterfaces.  If the particular VLAN is not provided, IPA will\nuse the lldp info for the interface to determine which VLANs should\nbe enabled.\n\nChange-Id: Icb4f66a02b298b4d165ebb58134cd31029e535cc\nStory: 2008298\nTask: 41183\n""}, {'number': 2, 'created': '2020-11-04 02:26:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic-python-agent/commit/395cdb0530b698f3e613cf876c17f53732f49df5', 'message': ""Bring up VLAN interfaces and include in introspection report\n\nAdd the ability to bring up VLAN interfaces and include them in the\nintrospection report.  A new configuration field is added -\n``ipa-vlan-interfaces``, which defines either the VLAN interface to\nenable, the interface to use, or 'all' - which indicates all\ninterfaces.  If the particular VLAN is not provided, IPA will\nuse the lldp info for the interface to determine which VLANs should\nbe enabled.\n\nChange-Id: Icb4f66a02b298b4d165ebb58134cd31029e535cc\nStory: 2008298\nTask: 41183\n""}, {'number': 3, 'created': '2020-11-04 02:28:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic-python-agent/commit/41499fde8abf3f32e81830f441fc761143c1297d', 'message': ""Bring up VLAN interfaces and include in introspection report\n\nAdd the ability to bring up VLAN interfaces and include them in the\nintrospection report.  A new configuration field is added -\n``ipa-vlan-interfaces``, which defines either the VLAN interface to\nenable, the interface to use, or 'all' - which indicates all\ninterfaces.  If the particular VLAN is not provided, IPA will\nuse the lldp info for the interface to determine which VLANs should\nbe enabled.\n\nChange-Id: Icb4f66a02b298b4d165ebb58134cd31029e535cc\nStory: 2008298\nTask: 41183\n""}, {'number': 4, 'created': '2020-11-04 12:41:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic-python-agent/commit/703ab8909f11012b3e539470edd3a8d22ab31f30', 'message': ""Bring up VLAN interfaces and include in introspection report\n\nAdd the ability to bring up VLAN interfaces and include them in the\nintrospection report.  A new configuration field is added -\n``ipa-vlan-interfaces``, which defines either the VLAN interface to\nenable, the interface to use, or 'all' - which indicates all\ninterfaces.  If the particular VLAN is not provided, IPA will\nuse the lldp info for the interface to determine which VLANs should\nbe enabled.\n\nChange-Id: Icb4f66a02b298b4d165ebb58134cd31029e535cc\nStory: 2008298\nTask: 41183\n""}, {'number': 5, 'created': '2020-11-05 17:12:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic-python-agent/commit/121bdd8f8a4d30c2465ac55959e3dc2fc44c2dd3', 'message': ""Bring up VLAN interfaces and include in introspection report\n\nAdd the ability to bring up VLAN interfaces and include them in the\nintrospection report.  A new configuration field is added -\n``ipa-vlan-interfaces``, which defines either the VLAN interface to\nenable, the interface to use, or 'all' - which indicates all\ninterfaces.  If the particular VLAN is not provided, IPA will\nuse the lldp info for the interface to determine which VLANs should\nbe enabled.\n\nChange-Id: Icb4f66a02b298b4d165ebb58134cd31029e535cc\nStory: 2008298\nTask: 41183\n""}, {'number': 6, 'created': '2020-11-05 18:32:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic-python-agent/commit/319d5849834a3dcf7209f46cdad62b3d3694ee43', 'message': ""Bring up VLAN interfaces and include in introspection report\n\nAdd the ability to bring up VLAN interfaces and include them in the\nintrospection report.  A new configuration field is added -\n``ipa-vlan-interfaces``, which defines either the VLAN interface to\nenable, the interface to use, or 'all' - which indicates all\ninterfaces.  If the particular VLAN is not provided, IPA will\nuse the lldp info for the interface to determine which VLANs should\nbe enabled.\n\nChange-Id: Icb4f66a02b298b4d165ebb58134cd31029e535cc\nStory: 2008298\nTask: 41183\n""}, {'number': 7, 'created': '2020-11-10 15:18:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic-python-agent/commit/2e491e9c9b6cf283f76c422625f5c0673d16be79', 'message': ""Bring up VLAN interfaces and include in introspection report\n\nAdd the ability to bring up VLAN interfaces and include them in the\nintrospection report.  A new configuration field is added -\n``ipa-enable-vlan-interfaces``, which defines either the VLAN interface\nto enable, the interface to use, or 'all' - which indicates all\ninterfaces.  If the particular VLAN is not provided, IPA will\nuse the lldp info for the interface to determine which VLANs should\nbe enabled.\n\nChange-Id: Icb4f66a02b298b4d165ebb58134cd31029e535cc\nStory: 2008298\nTask: 41183\n""}, {'number': 8, 'created': '2020-11-23 13:13:19.000000000', 'files': ['ironic_python_agent/hardware.py', 'ironic_python_agent/netutils.py', 'ironic_python_agent/config.py', 'ironic_python_agent/tests/unit/test_hardware.py', 'releasenotes/notes/add-vlan-interfaces-cdfeb39d0f3d444d.yaml'], 'web_link': 'https://opendev.org/openstack/ironic-python-agent/commit/6e3f28d720c838b66a570babeb3f36f36c48bf1f', 'message': ""Bring up VLAN interfaces and include in introspection report\n\nAdd the ability to bring up VLAN interfaces and include them in the\nintrospection report.  A new configuration field is added -\n``ipa-enable-vlan-interfaces``, which defines either the VLAN interface\nto enable, the interface to use, or 'all' - which indicates all\ninterfaces.  If the particular VLAN is not provided, IPA will\nuse the lldp info for the interface to determine which VLANs should\nbe enabled.\n\nChange-Id: Icb4f66a02b298b4d165ebb58134cd31029e535cc\nStory: 2008298\nTask: 41183\n""}]",38,760570,6e3f28d720c838b66a570babeb3f36f36c48bf1f,34,7,8,21909,,,0,"Bring up VLAN interfaces and include in introspection report

Add the ability to bring up VLAN interfaces and include them in the
introspection report.  A new configuration field is added -
``ipa-enable-vlan-interfaces``, which defines either the VLAN interface
to enable, the interface to use, or 'all' - which indicates all
interfaces.  If the particular VLAN is not provided, IPA will
use the lldp info for the interface to determine which VLANs should
be enabled.

Change-Id: Icb4f66a02b298b4d165ebb58134cd31029e535cc
Story: 2008298
Task: 41183
",git fetch https://review.opendev.org/openstack/ironic-python-agent refs/changes/70/760570/8 && git format-patch -1 --stdout FETCH_HEAD,"['ironic_python_agent/hardware.py', 'ironic_python_agent/config.py']",2,767da2d2a30e2f1bb06ee1291c492f49124ec9af,vlan-interfaces," 'configuration.'), cfg.StrOpt('inspection_vlan_interfaces', default=APARAMS.get('ipa-vlan-interfaces', ''), help='Comma-separated list of vlan interfaces to enable, ' 'in the format ""interface.vlan"". If only an ' 'interface is provided, then IPA should attempt to ' 'bring up all vlans on that interface detected ' 'via lldp. If ""all"" is set then IPA should attempt ' 'to bring up all vlans from lldp on all interfaces. ' 'By default, no vlans will be brought up'),", 'configuration.'),112,1
openstack%2Foctavia~stable%2Ftrain~I923accd73e0c9cadc91c115157c576432f428622,openstack/octavia,stable/train,I923accd73e0c9cadc91c115157c576432f428622,Fix load balancers with failed amphora failover,MERGED,2020-11-23 14:13:08.000000000,2020-12-02 13:34:34.000000000,2020-12-02 13:32:59.000000000,"[{'_account_id': 7249}, {'_account_id': 11628}, {'_account_id': 22348}, {'_account_id': 28008}]","[{'number': 1, 'created': '2020-11-23 14:13:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/octavia/commit/0d9a744854e76f9bc70227fb8173dc29f9e2a2c0', 'message': 'Fix load balancers with failed amphora failover\n\nThis patch is a complement of [1] which we ensure\na fresh lb object, but only for AmpListenersUpdate\nclass.\n\nIt was observed, at least on train and ussuri\ndeployments that multiple failed amphoras were still\nhappening when using session persistence.\n\nThat is fixed and failover works flawless with session\npersistence when we also ensure a fresh lb object on\nAmphoraIndexListenerUpdate class.\n\n[1] https://review.opendev.org/#/c/756597/\n\nChange-Id: I923accd73e0c9cadc91c115157c576432f428622\nStory: 2008099\nTask: 40802\n(cherry picked from commit f96251c74275ac44a8ac20ff23a0f6c850af44f5)\n'}, {'number': 2, 'created': '2020-12-02 00:14:28.000000000', 'files': ['octavia/controller/worker/v1/tasks/amphora_driver_tasks.py', 'octavia/tests/unit/controller/worker/v1/tasks/test_amphora_driver_tasks.py'], 'web_link': 'https://opendev.org/openstack/octavia/commit/a455eacf2852fa8732ac01ed483f62350d19d2c1', 'message': 'Fix load balancers with failed amphora failover\n\nThis patch is a complement of [1] which we ensure\na fresh lb object, but only for AmpListenersUpdate\nclass.\n\nIt was observed, at least on train and ussuri\ndeployments that multiple failed amphoras were still\nhappening when using session persistence.\n\nThat is fixed and failover works flawless with session\npersistence when we also ensure a fresh lb object on\nAmphoraIndexListenerUpdate class.\n\n[1] https://review.opendev.org/#/c/756597/\n\nChange-Id: I923accd73e0c9cadc91c115157c576432f428622\nStory: 2008099\nTask: 40802\n(cherry picked from commit f96251c74275ac44a8ac20ff23a0f6c850af44f5)\n'}]",0,763733,a455eacf2852fa8732ac01ed483f62350d19d2c1,24,4,2,28619,,,0,"Fix load balancers with failed amphora failover

This patch is a complement of [1] which we ensure
a fresh lb object, but only for AmpListenersUpdate
class.

It was observed, at least on train and ussuri
deployments that multiple failed amphoras were still
happening when using session persistence.

That is fixed and failover works flawless with session
persistence when we also ensure a fresh lb object on
AmphoraIndexListenerUpdate class.

[1] https://review.opendev.org/#/c/756597/

Change-Id: I923accd73e0c9cadc91c115157c576432f428622
Story: 2008099
Task: 40802
(cherry picked from commit f96251c74275ac44a8ac20ff23a0f6c850af44f5)
",git fetch https://review.opendev.org/openstack/octavia refs/changes/33/763733/1 && git format-patch -1 --stdout FETCH_HEAD,"['octavia/controller/worker/v1/tasks/amphora_driver_tasks.py', 'octavia/tests/unit/controller/worker/v1/tasks/test_amphora_driver_tasks.py']",2,0d9a744854e76f9bc70227fb8173dc29f9e2a2c0,," @mock.patch('octavia.db.repositories.LoadBalancerRepository.get') def test_amphorae_listeners_update(self, mock_lb_repo_get, mock_driver, mock_generate_uuid, mock_log, mock_get_session, mock_listener_repo_get, mock_listener_repo_update, mock_amphora_repo_update): mock_lb_repo_get.return_value = _LB_mock _LB_mock, _amphora_mock, self.timeout_dict)"," def test_amphorae_listeners_update( self, mock_driver, mock_generate_uuid, mock_log, mock_get_session, mock_listener_repo_get, mock_listener_repo_update, mock_amphora_repo_update): _load_balancer_mock, _amphora_mock, self.timeout_dict)",15,5
openstack%2Fopenstack-ansible-os_nova~stable%2Fussuri~I152d9d4d161f18336d9b412d578846f749a0162b,openstack/openstack-ansible-os_nova,stable/ussuri,I152d9d4d161f18336d9b412d578846f749a0162b,Set Bridge Information for NSX Integration,MERGED,2020-09-08 12:08:47.000000000,2020-12-02 13:29:07.000000000,2020-12-02 13:27:42.000000000,"[{'_account_id': 16011}, {'_account_id': 22093}, {'_account_id': 22348}, {'_account_id': 25023}]","[{'number': 1, 'created': '2020-09-08 12:08:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_nova/commit/8978289b49d7064233b915d940142235f73aa185', 'message': 'Set Bridge Information for NSX Integration\n\nVM interfaces need to connect to a nsx-specific bridge vs the default\nof br-int in order for NSX integration to be successful.\n\nChange-Id: I152d9d4d161f18336d9b412d578846f749a0162b\n(cherry picked from commit c05a843ef0f0e7d0b28abb292c05ef9b4080e4fa)\n'}, {'number': 2, 'created': '2020-10-19 16:52:32.000000000', 'files': ['defaults/main.yml'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_nova/commit/d5c9074a373e3cd540ea8d824ddf3d11b50b6d33', 'message': 'Set Bridge Information for NSX Integration\n\nVM interfaces need to connect to a nsx-specific bridge vs the default\nof br-int in order for NSX integration to be successful.\n\nChange-Id: I152d9d4d161f18336d9b412d578846f749a0162b\n(cherry picked from commit c05a843ef0f0e7d0b28abb292c05ef9b4080e4fa)\n'}]",0,750330,d5c9074a373e3cd540ea8d824ddf3d11b50b6d33,26,4,2,22093,,,0,"Set Bridge Information for NSX Integration

VM interfaces need to connect to a nsx-specific bridge vs the default
of br-int in order for NSX integration to be successful.

Change-Id: I152d9d4d161f18336d9b412d578846f749a0162b
(cherry picked from commit c05a843ef0f0e7d0b28abb292c05ef9b4080e4fa)
",git fetch https://review.opendev.org/openstack/openstack-ansible-os_nova refs/changes/30/750330/2 && git format-patch -1 --stdout FETCH_HEAD,['defaults/main.yml'],1,8978289b49d7064233b915d940142235f73aa185,vmware-nsx-integration-stable/ussuri, nsx: use_forwarded_for: True metadata_proxy_enabled: True ovs_bridge: nsx-managed,,4,0
openstack%2Frequirements~master~I6580092f6f61e60e743fef18bc6e6ded08b97ae3,openstack/requirements,master,I6580092f6f61e60e743fef18bc6e6ded08b97ae3,Add rbd-iscsi-client to global-reqs,MERGED,2020-07-30 15:00:34.000000000,2020-12-02 13:15:35.000000000,2020-08-01 16:50:19.000000000,"[{'_account_id': 11904}, {'_account_id': 14288}, {'_account_id': 22348}, {'_account_id': 28522}]","[{'number': 1, 'created': '2020-07-30 15:00:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/requirements/commit/3bb5f5dc33296f2ad0d94e0204362fb851705679', 'message': 'Add rbd-iscsi-client to global-reqs\n\nThis patch adds the new rbd-iscsi-client to global-requirements.\nThis client lib is used for cinder ceph iscsi driver.\n\nChange-Id: I6580092f6f61e60e743fef18bc6e6ded08b97ae3\n'}, {'number': 2, 'created': '2020-07-30 16:56:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/requirements/commit/0a0857a2914332afa010e5857a05a068af477eda', 'message': ""Add rbd-iscsi-client to global-reqs\n\nThis patch adds the new rbd-iscsi-client to global-requirements.\nThis client lib is used for cinder ceph iscsi driver.\n\nCurrently, the library is maintained by me, but have plans to\npossible add it under cinder's umbrella.\n\nThe library is python3 compatible.\n\nApaache 2 license.\n\nThe library is currently not packaged by a distro yet as far\nas I know.\n\nThe function of this library is not already covered by other\nlibraries.\n\nThe library is required by the new cinder ceph iscsi driver.\nhttps://review.opendev.org/#/c/662829/\n\nChange-Id: I6580092f6f61e60e743fef18bc6e6ded08b97ae3\n""}, {'number': 3, 'created': '2020-07-31 13:00:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/requirements/commit/1609b315b0e08ea5761d10f52dfbb3f512e8ddcd', 'message': ""Add rbd-iscsi-client to global-reqs\n\nThis patch adds the new rbd-iscsi-client to global-requirements.\nThis client lib is used for cinder ceph iscsi driver.\n\nCurrently, the library is maintained by me, but have plans to\npossible add it under cinder's umbrella.\n\nThe library is python3 compatible.\n\nApaache 2 license.\n\nThe library is currently not packaged by a distro yet as far\nas I know.\n\nThe function of this library is not already covered by other\nlibraries.\n\nThe library is required by the new cinder ceph iscsi driver.\nhttps://review.opendev.org/#/c/662829/\n\nChange-Id: I6580092f6f61e60e743fef18bc6e6ded08b97ae3\n""}, {'number': 4, 'created': '2020-07-31 19:39:32.000000000', 'files': ['global-requirements.txt', 'upper-constraints.txt'], 'web_link': 'https://opendev.org/openstack/requirements/commit/2ce1a5eaabe492bafe92604bcbcbb3a148f874de', 'message': ""Add rbd-iscsi-client to global-reqs\n\nThis patch adds the new rbd-iscsi-client to global-requirements.\nThis client lib is used for cinder ceph iscsi driver.\n\nCurrently, the library is maintained by me, but have plans to\npossible add it under cinder's umbrella.\n\nThe library is python3 compatible.\n\nApaache 2 license.\n\nThe library is currently not packaged by a distro yet as far\nas I know.\n\nThe function of this library is not already covered by other\nlibraries.\n\nThe library is required by the new cinder ceph iscsi driver.\nhttps://review.opendev.org/#/c/662829/\n\nChange-Id: I6580092f6f61e60e743fef18bc6e6ded08b97ae3\n""}]",1,743995,2ce1a5eaabe492bafe92604bcbcbb3a148f874de,28,4,4,5997,,,0,"Add rbd-iscsi-client to global-reqs

This patch adds the new rbd-iscsi-client to global-requirements.
This client lib is used for cinder ceph iscsi driver.

Currently, the library is maintained by me, but have plans to
possible add it under cinder's umbrella.

The library is python3 compatible.

Apaache 2 license.

The library is currently not packaged by a distro yet as far
as I know.

The function of this library is not already covered by other
libraries.

The library is required by the new cinder ceph iscsi driver.
https://review.opendev.org/#/c/662829/

Change-Id: I6580092f6f61e60e743fef18bc6e6ded08b97ae3
",git fetch https://review.opendev.org/openstack/requirements refs/changes/95/743995/1 && git format-patch -1 --stdout FETCH_HEAD,['global-requirements.txt'],1,3bb5f5dc33296f2ad0d94e0204362fb851705679,ceph-iscsi,rbd-iscsi-client>=0.1.7 # Apache-2.0,,1,0
openstack%2Fcharm-designate~master~I7cc1a74e608edaf72b9a9e062adf897b07bdb6a9,openstack/charm-designate,master,I7cc1a74e608edaf72b9a9e062adf897b07bdb6a9,Rebuild charm to pick up revised memcache interface,MERGED,2020-11-28 10:22:37.000000000,2020-12-02 13:00:12.000000000,2020-12-02 13:00:12.000000000,"[{'_account_id': 19298}, {'_account_id': 20634}, {'_account_id': 20648}, {'_account_id': 22348}]","[{'number': 1, 'created': '2020-11-28 10:22:37.000000000', 'files': ['rebuild'], 'web_link': 'https://opendev.org/openstack/charm-designate/commit/42dc140ec38e39217c00c34bf6c019a2a8e84e30', 'message': 'Rebuild charm to pick up revised memcache interface\n\nThis patchset is to rebuild the charm to pick up the fixed memcache\ninterface in [1].\n\n[1]: https://github.com/omnivector-solutions/interface-memcache/pull/4\n\nChange-Id: I7cc1a74e608edaf72b9a9e062adf897b07bdb6a9\nCloses-Bug: #1905511\n'}]",0,764546,42dc140ec38e39217c00c34bf6c019a2a8e84e30,10,4,1,20870,,,0,"Rebuild charm to pick up revised memcache interface

This patchset is to rebuild the charm to pick up the fixed memcache
interface in [1].

[1]: https://github.com/omnivector-solutions/interface-memcache/pull/4

Change-Id: I7cc1a74e608edaf72b9a9e062adf897b07bdb6a9
Closes-Bug: #1905511
",git fetch https://review.opendev.org/openstack/charm-designate refs/changes/46/764546/1 && git format-patch -1 --stdout FETCH_HEAD,['rebuild'],1,42dc140ec38e39217c00c34bf6c019a2a8e84e30,bug/1905511,468a90e0-3163-11eb-9cfe-2797c6c0a213,4fed7e86-0e2c-11eb-a443-afd060ef39de,1,1
openstack%2Fopenstack-ansible-os_adjutant~master~Id1b42c3ffdc7976373e0b2a7288c3866302bd024,openstack/openstack-ansible-os_adjutant,master,Id1b42c3ffdc7976373e0b2a7288c3866302bd024,Reduce number of processes on small systems,MERGED,2020-11-30 12:08:07.000000000,2020-12-02 12:52:30.000000000,2020-12-02 12:51:13.000000000,"[{'_account_id': 22348}, {'_account_id': 25023}, {'_account_id': 29865}]","[{'number': 1, 'created': '2020-11-30 12:08:07.000000000', 'files': ['defaults/main.yml'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_adjutant/commit/3630636befe3905c91229ea0b4852dbb9352e7b9', 'message': 'Reduce number of processes on small systems\n\nEven the most modest 4C/8T system would run with the maximum 16 processes\ndue to the calculation being VCPU*2.\n\nWe devide amount of CPUs to number of threads for hyperthreaded CPUs\n\nDepends-On: https://review.opendev.org/c/openstack/openstack-ansible/+/756310\nChange-Id: Id1b42c3ffdc7976373e0b2a7288c3866302bd024\n'}]",0,764654,3630636befe3905c91229ea0b4852dbb9352e7b9,10,3,1,28619,,,0,"Reduce number of processes on small systems

Even the most modest 4C/8T system would run with the maximum 16 processes
due to the calculation being VCPU*2.

We devide amount of CPUs to number of threads for hyperthreaded CPUs

Depends-On: https://review.opendev.org/c/openstack/openstack-ansible/+/756310
Change-Id: Id1b42c3ffdc7976373e0b2a7288c3866302bd024
",git fetch https://review.opendev.org/openstack/openstack-ansible-os_adjutant refs/changes/54/764654/1 && git format-patch -1 --stdout FETCH_HEAD,['defaults/main.yml'],1,3630636befe3905c91229ea0b4852dbb9352e7b9,api_threads,"adjutant_wsgi_processes: ""{{ [[(ansible_processor_vcpus//ansible_processor_threads_per_core)|default(1), 1] | max * 2, adjutant_wsgi_processes_max] | min }}""","adjutant_wsgi_processes: ""{{ [[ansible_processor_vcpus|default(1), 1] | max * 2, adjutant_wsgi_processes_max] | min }}""",1,1
openstack%2Fpython-tripleoclient~stable%2Fstein~I843aa5111ccbb63e7007f1eb6db93fdfbdb76a88,openstack/python-tripleoclient,stable/stein,I843aa5111ccbb63e7007f1eb6db93fdfbdb76a88,Remove centos-7-standalone-upgrade,MERGED,2020-10-23 16:46:27.000000000,2020-12-02 12:10:21.000000000,2020-12-02 12:05:58.000000000,"[{'_account_id': 3153}, {'_account_id': 7353}, {'_account_id': 9592}, {'_account_id': 14985}, {'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2020-10-23 16:46:27.000000000', 'files': ['zuul.d/layout.yaml'], 'web_link': 'https://opendev.org/openstack/python-tripleoclient/commit/ef4147e539358f3c21c46156bdfa4f767c3d1892', 'message': 'Remove centos-7-standalone-upgrade\n\nIt no longer provides quality coverage, see bug for details.\n\nChange-Id: I843aa5111ccbb63e7007f1eb6db93fdfbdb76a88\nRelated-Bug: #1901208\n'}]",0,759480,ef4147e539358f3c21c46156bdfa4f767c3d1892,26,6,1,14985,,,0,"Remove centos-7-standalone-upgrade

It no longer provides quality coverage, see bug for details.

Change-Id: I843aa5111ccbb63e7007f1eb6db93fdfbdb76a88
Related-Bug: #1901208
",git fetch https://review.opendev.org/openstack/python-tripleoclient refs/changes/80/759480/1 && git format-patch -1 --stdout FETCH_HEAD,['zuul.d/layout.yaml'],1,ef4147e539358f3c21c46156bdfa4f767c3d1892,bug/1901208,, - tripleo-ci-centos-7-standalone-upgrade: dependencies: *deps_unit_lint,0,2
openstack%2Fmanila~master~If95a0443c651c1a0a2ae646879bfb829b6130f01,openstack/manila,master,If95a0443c651c1a0a2ae646879bfb829b6130f01,Remove six,ABANDONED,2020-12-02 03:29:47.000000000,2020-12-02 12:08:58.000000000,,[],"[{'number': 1, 'created': '2020-12-02 03:29:47.000000000', 'files': ['manila/share/drivers/dell_emc/common/enas/connector.py', 'manila/share/drivers/netapp/dataontap/cluster_mode/lib_base.py', 'manila/tests/share/drivers/test_service_instance.py', 'manila/tests/share/drivers/zfsonlinux/test_driver.py', 'manila/tests/share/drivers/netapp/test_common.py', 'manila/share/drivers/dell_emc/plugins/powermax/connection.py', 'manila/api/openstack/api_version_request.py', 'manila/share_group/api.py', 'manila/api/v1/security_service.py', 'manila/api/openstack/wsgi.py', 'manila/share/drivers/dell_emc/plugins/powermax/object_manager.py', 'manila/share/drivers/hpe/hpe_3par_driver.py', 'manila/share/drivers/service_instance.py', 'manila/share/drivers/dell_emc/plugins/isilon/isilon.py', 'manila/share/drivers/qnap/api.py', 'contrib/share_driver_hooks/zaqar_notification_example_consumer.py', 'manila/tests/api/v1/test_limits.py', 'manila/scheduler/evaluator/evaluator.py', 'manila/scheduler/weighers/base.py', 'manila/utils.py', 'manila/api/views/versions.py', 'manila/share/drivers/dell_emc/plugins/isilon/isilon_api.py', 'manila/api/common.py', 'manila/share/drivers/inspur/instorage/cli_helper.py', 'manila/api/v1/share_types_extra_specs.py', 'manila/api/v1/limits.py', 'manila/tests/share/drivers/dell_emc/plugins/isilon/test_isilon_api.py', 'lower-constraints.txt', 'contrib/share_driver_hooks/README.rst', 'manila/share/drivers/infinidat/infinibox.py', 'manila/context.py', 'manila/share/drivers/zfssa/restclient.py', 'manila/tests/api/openstack/test_versioned_method.py', 'manila/tests/share/drivers/tegile/test_tegile.py', 'manila/tests/share/drivers/windows/test_service_instance.py', 'manila/share/drivers/generic.py', 'manila/api/v2/shares.py', 'manila/data/manager.py', 'manila/network/linux/interface.py', 'manila/share/drivers/hitachi/hnas/driver.py', 'manila/scheduler/filters/json.py', 'manila/tests/share/drivers/qnap/test_api.py', 'manila/share/drivers/nexenta/ns5/jsonrpc.py', 'manila/tests/share/drivers/netapp/dataontap/client/test_client_cmode.py', 'manila/share/drivers/huawei/base.py', 'manila/share/drivers/netapp/dataontap/protocols/base.py', 'manila/tests/api/v2/test_share_group_snapshots.py', 'manila/api/v1/share_snapshots.py', 'manila/tests/api/v2/test_share_snapshots.py', 'manila/share/drivers/cephfs/driver.py', 'requirements.txt', 'manila/tests/db/sqlalchemy/test_api.py', 'manila/db/sqlalchemy/api.py', 'manila/tests/api/v2/test_shares.py', 'manila/volume/cinder.py', 'manila/share/drivers/helpers.py', 'manila/share/drivers/dell_emc/common/enas/xml_api_parser.py', 'manila/tests/scheduler/test_scheduler_options.py', 'manila/tests/api/v1/test_share_snapshots.py', 'manila/tests/share/drivers/dell_emc/plugins/unity/test_connection.py', 'manila/share/drivers/dell_emc/plugins/vnx/connection.py', 'manila/tests/share/drivers/hitachi/hnas/test_ssh.py', 'manila/common/config.py', 'manila/message/api.py', 'manila/tests/share/drivers/maprfs/test_maprfs.py', 'manila/tests/network/linux/test_interface.py', 'manila/api/v2/share_servers.py', 'manila/api/v1/share_unmanage.py', 'manila/tests/share/drivers/qnap/test_qnap.py', 'manila/share/drivers/huawei/v3/helper.py', 'manila/tests/hacking/checks.py', 'manila/tests/test_api.py', 'manila/scheduler/filters/extra_specs_ops.py', 'manila/scheduler/weighers/goodness.py', 'manila/tests/api/openstack/test_wsgi.py', 'manila/tests/share/drivers/veritas/test_veritas_isa.py', 'manila/tests/fake_utils.py', 'manila/exception.py', 'manila/tests/api/v2/test_share_groups.py', 'manila/tests/api/v2/test_share_snapshot_instances.py', 'manila/network/__init__.py', 'manila/tests/api/v1/test_shares.py', 'manila/api/v2/share_networks.py', 'manila/tests/share/drivers/dell_emc/plugins/isilon/test_isilon.py', 'manila/share/drivers/nexenta/utils.py', 'manila/compute/nova.py', 'manila/share/drivers/dell_emc/plugins/base.py', 'manila/share/drivers/hitachi/hnas/ssh.py', 'manila/share/hook.py', 'manila/share/drivers/dell_emc/plugins/vnx/object_manager.py', 'manila/share/drivers/ganesha/__init__.py', 'manila/share/access.py', 'manila/tests/share/drivers/hdfs/test_hdfs_native.py', 'manila/tests/api/v2/test_share_instances.py', 'manila/tests/utils.py', 'manila/db/migrations/alembic/versions/5077ffcc5f1c_add_share_instances.py', 'manila/share/drivers/inspur/as13000/as13000_nas.py', 'manila/api/v2/share_snapshots.py', 'manila/share/drivers/netapp/dataontap/client/client_cmode.py', 'manila/tests/integrated/test_extensions.py', 'manila/share/drivers/netapp/utils.py', 'manila/network/neutron/neutron_network_plugin.py', 'manila/coordination.py', 'manila/share/drivers/hpe/hpe_3par_mediator.py', 'manila/share/drivers/quobyte/quobyte.py', 'manila/share/drivers/quobyte/jsonrpc.py', 'manila/tests/share/drivers/nexenta/ns5/test_jsonrpc.py', 'manila/api/v1/share_servers.py', 'manila/tests/network/test_standalone_network_plugin.py', 'manila/share/drivers/hdfs/hdfs_native.py', 'manila/share/drivers/zfsonlinux/utils.py', 'manila/share/drivers/inspur/instorage/instorage.py', 'manila/tests/share/test_access.py', 'manila/network/linux/ip_lib.py', 'manila/tests/share/drivers/ganesha/test_manager.py', 'manila/tests/test_utils.py', 'manila/api/v2/share_groups.py', 'manila/tests/share/drivers/test_generic.py', 'manila/api/middleware/fault.py', 'manila/api/v1/share_metadata.py', 'manila/tests/share/drivers/dell_emc/common/enas/test_connector.py', 'manila/tests/api/v1/test_security_service.py', 'manila/tests/api/v2/test_share_replicas.py', 'manila/share/drivers/glusterfs/layout_volume.py', 'manila/api/v2/messages.py', 'manila/share/drivers/maprfs/driver_util.py', 'manila/share/drivers/windows/winrm_helper.py', 'manila/share/drivers/glusterfs/layout_directory.py', 'manila/api/v1/shares.py', 'manila/scheduler/filters/driver.py', 'manila/scheduler/host_manager.py', 'manila/api/v2/share_replicas.py', 'manila/api/v2/share_instance_export_locations.py', 'manila/tests/share/drivers/quobyte/test_jsonrpc.py', 'manila/tests/share/drivers/dell_emc/common/enas/utils.py', 'manila/api/v2/share_group_snapshots.py', 'manila/api/v2/share_group_types.py', 'manila/share/drivers/ibm/gpfs.py', 'manila/share/manager.py', 'manila/tests/share/drivers/test_ganesha.py', 'manila/share/drivers/netapp/dataontap/protocols/nfs_cmode.py', 'manila/tests/cmd/test_manage.py', 'manila/tests/db/migrations/alembic/migrations_data_checks.py', 'manila/share/drivers/tegile/tegile.py', 'manila/network/standalone_network_plugin.py', 'manila/tests/share/test_manager.py', 'manila/api/v2/quota_sets.py', 'manila/tests/api/openstack/test_api_version_request.py', 'manila/share/drivers/huawei/v3/connection.py', 'manila/share/share_types.py', 'manila/api/v2/share_network_subnets.py', 'manila/tests/fake_driver.py', 'manila/share/driver.py', 'manila/share/drivers/lvm.py', 'manila/tests/api/v2/test_share_networks.py', 'manila/tests/scheduler/test_host_manager.py', 'manila/share/drivers/veritas/veritas_isa.py', 'manila/tests/share/drivers/huawei/test_huawei_nas.py', 'manila/tests/test_exception.py', 'manila/tests/api/v1/test_share_metadata.py', 'manila/tests/api/middleware/test_faults.py', 'manila/share/api.py', 'manila/api/v2/share_group_type_specs.py', 'manila/share/drivers/netapp/dataontap/client/api.py', 'manila/tests/integrated/api/client.py', 'manila/tests/share/drivers/quobyte/test_quobyte.py', 'manila/api/v2/share_replica_export_locations.py', 'manila/api/v2/share_types.py', 'manila/share/drivers/glusterfs/common.py', 'manila/share/drivers/glusterfs/layout.py', 'manila/tests/share/drivers/hpe/test_hpe_3par_mediator.py', 'manila/quota.py', 'manila/share/drivers/zfssa/zfssashare.py', 'manila/share/drivers/dell_emc/plugins/unity/client.py', 'manila/share/drivers/ganesha/manager.py', 'manila/share/drivers_private_data.py'], 'web_link': 'https://opendev.org/openstack/manila/commit/40216af37504198ee66cb9dd24c360138c4493ea', 'message': 'Remove six\n\nRemove six Replace the following items with Python 3 style code.\n- six.string_types\n- six.text_type\n- six.add_metaclass\n- six.b\n- six.moves\n- six.wraps\n- six.BytesIO\n- six.StringIO\n\nChange-Id: If95a0443c651c1a0a2ae646879bfb829b6130f01\n'}]",0,765039,40216af37504198ee66cb9dd24c360138c4493ea,5,0,1,32238,,,0,"Remove six

Remove six Replace the following items with Python 3 style code.
- six.string_types
- six.text_type
- six.add_metaclass
- six.b
- six.moves
- six.wraps
- six.BytesIO
- six.StringIO

Change-Id: If95a0443c651c1a0a2ae646879bfb829b6130f01
",git fetch https://review.opendev.org/openstack/manila refs/changes/39/765039/1 && git format-patch -1 --stdout FETCH_HEAD,"['manila/share/drivers/dell_emc/common/enas/connector.py', 'manila/share/drivers/netapp/dataontap/cluster_mode/lib_base.py', 'manila/tests/share/drivers/test_service_instance.py', 'manila/tests/share/drivers/zfsonlinux/test_driver.py', 'manila/tests/share/drivers/netapp/test_common.py', 'manila/share/drivers/dell_emc/plugins/powermax/connection.py', 'manila/api/openstack/api_version_request.py', 'manila/share_group/api.py', 'manila/api/v1/security_service.py', 'manila/api/openstack/wsgi.py', 'manila/share/drivers/dell_emc/plugins/powermax/object_manager.py', 'manila/share/drivers/hpe/hpe_3par_driver.py', 'manila/share/drivers/service_instance.py', 'manila/share/drivers/dell_emc/plugins/isilon/isilon.py', 'manila/share/drivers/qnap/api.py', 'contrib/share_driver_hooks/zaqar_notification_example_consumer.py', 'manila/tests/api/v1/test_limits.py', 'manila/scheduler/evaluator/evaluator.py', 'manila/scheduler/weighers/base.py', 'manila/utils.py', 'manila/api/views/versions.py', 'manila/share/drivers/dell_emc/plugins/isilon/isilon_api.py', 'manila/api/common.py', 'manila/share/drivers/inspur/instorage/cli_helper.py', 'manila/api/v1/share_types_extra_specs.py', 'manila/api/v1/limits.py', 'manila/tests/share/drivers/dell_emc/plugins/isilon/test_isilon_api.py', 'lower-constraints.txt', 'contrib/share_driver_hooks/README.rst', 'manila/share/drivers/infinidat/infinibox.py', 'manila/context.py', 'manila/share/drivers/zfssa/restclient.py', 'manila/tests/api/openstack/test_versioned_method.py', 'manila/tests/share/drivers/tegile/test_tegile.py', 'manila/tests/share/drivers/windows/test_service_instance.py', 'manila/share/drivers/generic.py', 'manila/api/v2/shares.py', 'manila/data/manager.py', 'manila/network/linux/interface.py', 'manila/share/drivers/hitachi/hnas/driver.py', 'manila/scheduler/filters/json.py', 'manila/tests/share/drivers/qnap/test_api.py', 'manila/share/drivers/nexenta/ns5/jsonrpc.py', 'manila/tests/share/drivers/netapp/dataontap/client/test_client_cmode.py', 'manila/share/drivers/huawei/base.py', 'manila/share/drivers/netapp/dataontap/protocols/base.py', 'manila/tests/api/v2/test_share_group_snapshots.py', 'manila/api/v1/share_snapshots.py', 'manila/tests/api/v2/test_share_snapshots.py', 'manila/share/drivers/cephfs/driver.py', 'requirements.txt', 'manila/tests/db/sqlalchemy/test_api.py', 'manila/db/sqlalchemy/api.py', 'manila/tests/api/v2/test_shares.py', 'manila/volume/cinder.py', 'manila/share/drivers/helpers.py', 'manila/share/drivers/dell_emc/common/enas/xml_api_parser.py', 'manila/tests/scheduler/test_scheduler_options.py', 'manila/tests/api/v1/test_share_snapshots.py', 'manila/tests/share/drivers/dell_emc/plugins/unity/test_connection.py', 'manila/share/drivers/dell_emc/plugins/vnx/connection.py', 'manila/tests/share/drivers/hitachi/hnas/test_ssh.py', 'manila/common/config.py', 'manila/message/api.py', 'manila/tests/share/drivers/maprfs/test_maprfs.py', 'manila/tests/network/linux/test_interface.py', 'manila/api/v2/share_servers.py', 'manila/api/v1/share_unmanage.py', 'manila/tests/share/drivers/qnap/test_qnap.py', 'manila/share/drivers/huawei/v3/helper.py', 'manila/tests/hacking/checks.py', 'manila/tests/test_api.py', 'manila/scheduler/filters/extra_specs_ops.py', 'manila/scheduler/weighers/goodness.py', 'manila/tests/api/openstack/test_wsgi.py', 'manila/tests/share/drivers/veritas/test_veritas_isa.py', 'manila/tests/fake_utils.py', 'manila/exception.py', 'manila/tests/api/v2/test_share_groups.py', 'manila/tests/api/v2/test_share_snapshot_instances.py', 'manila/network/__init__.py', 'manila/tests/api/v1/test_shares.py', 'manila/api/v2/share_networks.py', 'manila/tests/share/drivers/dell_emc/plugins/isilon/test_isilon.py', 'manila/share/drivers/nexenta/utils.py', 'manila/compute/nova.py', 'manila/share/drivers/dell_emc/plugins/base.py', 'manila/share/drivers/hitachi/hnas/ssh.py', 'manila/share/hook.py', 'manila/share/drivers/dell_emc/plugins/vnx/object_manager.py', 'manila/share/drivers/ganesha/__init__.py', 'manila/share/access.py', 'manila/tests/share/drivers/hdfs/test_hdfs_native.py', 'manila/tests/api/v2/test_share_instances.py', 'manila/tests/utils.py', 'manila/db/migrations/alembic/versions/5077ffcc5f1c_add_share_instances.py', 'manila/share/drivers/inspur/as13000/as13000_nas.py', 'manila/api/v2/share_snapshots.py', 'manila/share/drivers/netapp/dataontap/client/client_cmode.py', 'manila/tests/integrated/test_extensions.py', 'manila/share/drivers/netapp/utils.py', 'manila/network/neutron/neutron_network_plugin.py', 'manila/coordination.py', 'manila/share/drivers/hpe/hpe_3par_mediator.py', 'manila/share/drivers/quobyte/quobyte.py', 'manila/share/drivers/quobyte/jsonrpc.py', 'manila/tests/share/drivers/nexenta/ns5/test_jsonrpc.py', 'manila/api/v1/share_servers.py', 'manila/tests/network/test_standalone_network_plugin.py', 'manila/share/drivers/hdfs/hdfs_native.py', 'manila/share/drivers/zfsonlinux/utils.py', 'manila/share/drivers/inspur/instorage/instorage.py', 'manila/tests/share/test_access.py', 'manila/network/linux/ip_lib.py', 'manila/tests/share/drivers/ganesha/test_manager.py', 'manila/tests/test_utils.py', 'manila/api/v2/share_groups.py', 'manila/tests/share/drivers/test_generic.py', 'manila/api/middleware/fault.py', 'manila/api/v1/share_metadata.py', 'manila/tests/share/drivers/dell_emc/common/enas/test_connector.py', 'manila/tests/api/v1/test_security_service.py', 'manila/tests/api/v2/test_share_replicas.py', 'manila/share/drivers/glusterfs/layout_volume.py', 'manila/api/v2/messages.py', 'manila/share/drivers/maprfs/driver_util.py', 'manila/share/drivers/windows/winrm_helper.py', 'manila/share/drivers/glusterfs/layout_directory.py', 'manila/api/v1/shares.py', 'manila/scheduler/filters/driver.py', 'manila/scheduler/host_manager.py', 'manila/api/v2/share_replicas.py', 'manila/api/v2/share_instance_export_locations.py', 'manila/tests/share/drivers/quobyte/test_jsonrpc.py', 'manila/tests/share/drivers/dell_emc/common/enas/utils.py', 'manila/api/v2/share_group_snapshots.py', 'manila/api/v2/share_group_types.py', 'manila/share/drivers/ibm/gpfs.py', 'manila/share/manager.py', 'manila/tests/share/drivers/test_ganesha.py', 'manila/share/drivers/netapp/dataontap/protocols/nfs_cmode.py', 'manila/tests/cmd/test_manage.py', 'manila/tests/db/migrations/alembic/migrations_data_checks.py', 'manila/share/drivers/tegile/tegile.py', 'manila/network/standalone_network_plugin.py', 'manila/tests/share/test_manager.py', 'manila/api/v2/quota_sets.py', 'manila/tests/api/openstack/test_api_version_request.py', 'manila/share/drivers/huawei/v3/connection.py', 'manila/share/share_types.py', 'manila/api/v2/share_network_subnets.py', 'manila/tests/fake_driver.py', 'manila/share/driver.py', 'manila/share/drivers/lvm.py', 'manila/tests/api/v2/test_share_networks.py', 'manila/tests/scheduler/test_host_manager.py', 'manila/share/drivers/veritas/veritas_isa.py', 'manila/tests/share/drivers/huawei/test_huawei_nas.py', 'manila/tests/test_exception.py', 'manila/tests/api/v1/test_share_metadata.py', 'manila/tests/api/middleware/test_faults.py', 'manila/share/api.py', 'manila/api/v2/share_group_type_specs.py', 'manila/share/drivers/netapp/dataontap/client/api.py', 'manila/tests/integrated/api/client.py', 'manila/tests/share/drivers/quobyte/test_quobyte.py', 'manila/api/v2/share_replica_export_locations.py', 'manila/api/v2/share_types.py', 'manila/share/drivers/glusterfs/common.py', 'manila/share/drivers/glusterfs/layout.py', 'manila/tests/share/drivers/hpe/test_hpe_3par_mediator.py', 'manila/quota.py', 'manila/share/drivers/zfssa/zfssashare.py', 'manila/share/drivers/dell_emc/plugins/unity/client.py', 'manila/share/drivers/ganesha/manager.py', 'manila/share/drivers_private_data.py']",176,40216af37504198ee66cb9dd24c360138c4493ea,,"class StorageDriver(object, metaclass=abc.ABCMeta): % str(details)) % str(entity_id))",import six@six.add_metaclass(abc.ABCMeta) class StorageDriver(object): % six.text_type(details)) % six.text_type(entity_id)),822,1000
openstack%2Fnova-specs~master~Ia2fcd46f372ac02a15bbce34cd81739ff6aa3cf1,openstack/nova-specs,master,Ia2fcd46f372ac02a15bbce34cd81739ff6aa3cf1,libvirt: Store and allow the default machine type to be changed,MERGED,2020-11-10 19:44:25.000000000,2020-12-02 11:26:18.000000000,2020-12-02 11:24:33.000000000,"[{'_account_id': 6962}, {'_account_id': 9708}, {'_account_id': 15334}, {'_account_id': 22348}, {'_account_id': 26458}]","[{'number': 1, 'created': '2020-11-10 19:44:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/7e2023459d4a047d1ef4e24eff77a1cd7de31292', 'message': 'WIP libvirt: Allow the default machine type to be changed\n\nCo-authored-by: Kashyap Chamarthy <kchamart@redhat.com>\nChange-Id: Ia2fcd46f372ac02a15bbce34cd81739ff6aa3cf1\n'}, {'number': 2, 'created': '2020-11-10 19:45:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/910535d967d8a411244c5385ebb35ec4c56ddea5', 'message': 'WIP libvirt: Allow the default machine type to be changed\n\nCo-authored-by: Kashyap Chamarthy <kchamart@redhat.com>\nChange-Id: Ia2fcd46f372ac02a15bbce34cd81739ff6aa3cf1\n'}, {'number': 3, 'created': '2020-11-17 14:52:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/60a174cc5563ed8971a4ae1b5b7cf7a11ae79e75', 'message': 'WIP libvirt: Allow the default machine type to be changed\n\nCo-authored-by: Kashyap Chamarthy <kchamart@redhat.com>\nChange-Id: Ia2fcd46f372ac02a15bbce34cd81739ff6aa3cf1\n'}, {'number': 4, 'created': '2020-11-17 14:58:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/ee9b016de38738374ef4537255c0c079384c4411', 'message': 'WIP libvirt: Allow the default machine type to be changed\n\nCo-authored-by: Kashyap Chamarthy <kchamart@redhat.com>\nChange-Id: Ia2fcd46f372ac02a15bbce34cd81739ff6aa3cf1\n'}, {'number': 5, 'created': '2020-11-18 13:58:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/2c3f6142ca0663d070e17f1d0aaf0e844a660709', 'message': 'WIP libvirt: Allow the default machine type to be changed\n\nCo-authored-by: Kashyap Chamarthy <kchamart@redhat.com>\nChange-Id: Ia2fcd46f372ac02a15bbce34cd81739ff6aa3cf1\n'}, {'number': 6, 'created': '2020-11-18 16:14:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/049faee170cb193105441b305341c4372a00b07c', 'message': 'WIP libvirt: Allow the default machine type to be changed\n\nCo-authored-by: Kashyap Chamarthy <kchamart@redhat.com>\nChange-Id: Ia2fcd46f372ac02a15bbce34cd81739ff6aa3cf1\n'}, {'number': 7, 'created': '2020-12-01 10:23:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/96dd42b90d2d56e6491f60b527cd6764096537e8', 'message': 'libvirt: Store and allow the default machine type to be changed\n\nQEMU now provides a number of different machine types and improved\nversions of each machine type. This spec aims to outline how by storing\nthe initial machine type used by an instance we can allow the default\nmachine type defined on the host to be changed over time, allowing newer\ninstances to make use of new and improved machine types.\n\nCo-authored-by: Kashyap Chamarthy <kchamart@redhat.com>\nChange-Id: Ia2fcd46f372ac02a15bbce34cd81739ff6aa3cf1\n'}, {'number': 8, 'created': '2020-12-01 14:23:42.000000000', 'files': ['specs/wallaby/approved/libvirt-stash-instance-machine-type.rst'], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/3198a71d00d419128ee6c10c3915418576368af1', 'message': 'libvirt: Store and allow the default machine type to be changed\n\nQEMU now provides a number of different machine types and improved\nversions of each machine type. This spec aims to outline how by storing\nthe initial machine type used by an instance we can allow the default\nmachine type defined on the host to be changed over time, allowing newer\ninstances to make use of new and improved machine types.\n\nCo-authored-by: Kashyap Chamarthy <kchamart@redhat.com>\nChange-Id: Ia2fcd46f372ac02a15bbce34cd81739ff6aa3cf1\n'}]",53,762199,3198a71d00d419128ee6c10c3915418576368af1,30,5,8,10135,,,0,"libvirt: Store and allow the default machine type to be changed

QEMU now provides a number of different machine types and improved
versions of each machine type. This spec aims to outline how by storing
the initial machine type used by an instance we can allow the default
machine type defined on the host to be changed over time, allowing newer
instances to make use of new and improved machine types.

Co-authored-by: Kashyap Chamarthy <kchamart@redhat.com>
Change-Id: Ia2fcd46f372ac02a15bbce34cd81739ff6aa3cf1
",git fetch https://review.opendev.org/openstack/nova-specs refs/changes/99/762199/8 && git format-patch -1 --stdout FETCH_HEAD,['specs/wallaby/approved/libvirt-stash-instance-machine-type.rst'],1,7e2023459d4a047d1ef4e24eff77a1cd7de31292,spec/libvirt-allow-changes-to-default-machine-type,".. This work is licensed under a Creative Commons Attribution 3.0 Unported License. http://creativecommons.org/licenses/by/3.0/legalcode ====================================================== libvirt - Allow the default machine type to be changed ====================================================== Problem description =================== QEMU's ""machine type"" concept can be thought of a virtual chipset that provides certain default devices (e.g. PCIe graphics card, Ethernet controller, SATA controller, etc). QEMU supports two main variants of ""machine type"" for x86 hosts: (a) ``pc``, which corresponds to Intel's I440FX chipset, which is twenty-two years old as of this writing; and (b) ``q35``, which corresponds to Intel's 82Q35 chipset (released in 2007; a relatively modern chipset). For AArch64 hosts, the machine type is called: ``virt``. The ``pc`` machine type is considerd ""legacy"", and does not support some of the modern features. Although at this time of writing, upstream QEMU has not reached an agreement to remove new versioned variants of the ``pc`` machine type, some long-term stable Linux distributions (CentOS, RHEL, possibly others) are moving to support ``q35`` only. The libvirt virt driver has long supported the configuration of a per compute host `default machine type`_ via the ``[libvirt]/hw_machine_type`` configurable for use by QEMU or kvm based instances. This configurable provides a default machine type per host architecture to be used when no corresponding ``hw_machine_type`` image property is provided for the instance. When the configurable is not defined the libvirt driver relies on the following `hardcoded dictionary`_ of default machine types per architecture: .. code-block:: python default_mtypes = { obj_fields.Architecture.ARMV7: ""virt"", obj_fields.Architecture.AARCH64: ""virt"", obj_fields.Architecture.S390: ""s390-ccw-virtio"", obj_fields.Architecture.S390X: ""s390-ccw-virtio"", obj_fields.Architecture.I686: ""pc"", obj_fields.Architecture.X86_64: ""pc"", } However the resulting machine type used by the instance is not recorded by Nova. As such the configurable (if set) and hardcoded defaults within the libvirt driver must remain consistent between hosts in an environment *and* can never be changed without changing the emulated hardware exposed to the guest, breaking the ABI of the instances after hard reboots, move or recreation operations. This spec aims to outline how we can avoid this by always storing the machine type for the lifetime of the instance. This will allow both operators and developers to make changes to the default machine type over time while not breaking existing instances. Use Cases --------- * As a developer working on the libvirt driver I would like to update the default machine type for a given host architecture to make use of newer models of emulated hardware and features of QEMU. * As a deployer of an existing OpenStack environment I want to default a new machine type while not breaking the ABI of existing instances. * As a user I want to ensure the ABI of my instance remains the same throughout the lifetime of the instance, regardless of default configurable changes made by deployers. Proposed change =============== * Move the the hardcoded machine type defaults into the ``[libvirt]/hw_machine_type`` configurable. * Store the used machine type in the instance extras table during the initial spawn of the instance. * Ensure this is used during a hard reboots, moves or any other action that results in the domain being redefined aside from a rebuild of the instance. Alternatives ------------ Data model impact ----------------- REST API impact --------------- Security impact --------------- Notifications impact -------------------- Other end user impact --------------------- Performance Impact ------------------ N/A Other deployer impact --------------------- Developer impact ---------------- Upgrade impact -------------- Implementation ============== Assignee(s) ----------- Primary assignee: lyarwood Other contributors: Feature Liaison --------------- Feature liaison: lyarwood Work Items ---------- Dependencies ============ N/A Testing ======= Documentation Impact ==================== References ========== .. _`default machine type`: https://review.opendev.org/#/c/100664/ .. _`hardcoded dictionary`: https://github.com/openstack/nova/blob/dc93e3b510f53d5b2198c8edd22528f0c899617e/nova/virt/libvirt/utils.py#L631-L638 History ======= Optional section intended to be used each time the spec is updated to describe new design, API or any database schema updated. Useful to let reader understand what's happened along the time. .. list-table:: Revisions :header-rows: 1 * - Release Name - Description * - Wallaby - Introduced ",,182,0
openstack%2Ftrove~master~Ib08b1ae745be6aff6c90d0b653864ba6f0521aae,openstack/trove,master,Ib08b1ae745be6aff6c90d0b653864ba6f0521aae,[DNM] - debugging race ocndition,NEW,2020-12-02 07:38:40.000000000,2020-12-02 11:10:37.000000000,,[{'_account_id': 22348}],"[{'number': 1, 'created': '2020-12-02 07:38:40.000000000', 'files': ['trove/taskmanager/models.py'], 'web_link': 'https://opendev.org/openstack/trove/commit/21d16c939d20e2dceade031dcc488009db8c295b', 'message': '[DNM] - debugging race ocndition\n\nChange-Id: Ib08b1ae745be6aff6c90d0b653864ba6f0521aae\n'}]",0,765066,21d16c939d20e2dceade031dcc488009db8c295b,2,1,1,3031,,,0,"[DNM] - debugging race ocndition

Change-Id: Ib08b1ae745be6aff6c90d0b653864ba6f0521aae
",git fetch https://review.opendev.org/openstack/trove refs/changes/66/765066/1 && git format-patch -1 --stdout FETCH_HEAD,['trove/taskmanager/models.py'],1,21d16c939d20e2dceade031dcc488009db8c295b,, time.sleep(30),,1,0
openstack%2Fkuryr-tempest-plugin~master~I07f24bb754f2dde24fe47b340ebec04440ff3890,openstack/kuryr-tempest-plugin,master,I07f24bb754f2dde24fe47b340ebec04440ff3890,Create Tempest case to ensure Services without Selectors,MERGED,2020-10-12 12:24:31.000000000,2020-12-02 10:53:47.000000000,2020-12-02 10:51:54.000000000,"[{'_account_id': 3153}, {'_account_id': 4727}, {'_account_id': 11600}, {'_account_id': 13692}, {'_account_id': 22348}, {'_account_id': 23567}, {'_account_id': 27032}, {'_account_id': 30963}]","[{'number': 1, 'created': '2020-10-12 12:24:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kuryr-tempest-plugin/commit/59e08dadad7474d818573394e92624c01f69c616', 'message': 'This is tempest test for testing service without selector.\nCreate a Service without Selectors and the Endpoints and\ncheck the connectivity to the Endpoints\n\nChange-Id: I07f24bb754f2dde24fe47b340ebec04440ff3890\n'}, {'number': 2, 'created': '2020-10-12 14:48:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kuryr-tempest-plugin/commit/33667b1c793fc84ba9fda36bda2bfdd765b381a1', 'message': 'This is tempest test for testing service without selector.\nCreate a Service without Selectors and the Endpoints and\ncheck the connectivity to the Endpoints\n\nChange-Id: I07f24bb754f2dde24fe47b340ebec04440ff3890\n'}, {'number': 3, 'created': '2020-10-12 17:30:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kuryr-tempest-plugin/commit/f5f37f9e05c7171741ca46b96cb7763139b16010', 'message': 'Create Tempest case to ensure connectivity is working with Services\nwithout Selectors\n\nTo ensure that connectivity is working we need to create a new\ntempest test, which will create a service without selectors,\ncreate the endpoints and check the connectivity to the endpoints.\n\nChange-Id: I07f24bb754f2dde24fe47b340ebec04440ff3890\n'}, {'number': 4, 'created': '2020-10-13 01:39:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kuryr-tempest-plugin/commit/6ffde1dd3815e37591a1c6c0782396f0fb5f6ccb', 'message': 'Create Tempest case to ensure connectivity is working with Services\nwithout Selectors\n\nTo ensure that connectivity is working we need to create a new\ntempest test, which will create a service without selectors,\ncreate the endpoints and check the connectivity to the endpoints.\n\nChange-Id: I07f24bb754f2dde24fe47b340ebec04440ff3890\n'}, {'number': 5, 'created': '2020-10-26 14:33:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kuryr-tempest-plugin/commit/b7004cc56f74e10dcb525918676b6f9ed7c61017', 'message': 'Create Tempest case to ensure connectivity is working with Services\nwithout Selectors\n\nTo ensure that connectivity is working we need to create a new\ntempest test, which will create a service without selectors,\ncreate the endpoints and check the connectivity to the endpoints.\n\nChange-Id: I07f24bb754f2dde24fe47b340ebec04440ff3890\n'}, {'number': 6, 'created': '2020-10-26 14:58:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kuryr-tempest-plugin/commit/67b97b3226c65febb015f04b9052bcd6bde8375f', 'message': 'Create Tempest case to ensure connectivity is working with Services\nwithout Selectors\n\nTo ensure that connectivity is working we need to create a new\ntempest test, which will create a service without selectors,\ncreate the endpoints and check the connectivity to the endpoints.\n\nChange-Id: I07f24bb754f2dde24fe47b340ebec04440ff3890\n'}, {'number': 7, 'created': '2020-11-02 22:19:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kuryr-tempest-plugin/commit/03954fb6e39fe5642a6df68176c19b2d4c14d920', 'message': 'Create Tempest case to ensure Services without Selectors\n\nTo ensure that connectivity is working we need to create a new\ntempest test, which will create a service without selectors,\ncreate the endpoints and check the connectivity to the endpoints.\n\nChange-Id: I07f24bb754f2dde24fe47b340ebec04440ff3890\n'}, {'number': 8, 'created': '2020-11-06 18:42:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kuryr-tempest-plugin/commit/0fda654d91b9f7c1b97165f8c11ea9f3046cdd35', 'message': 'Create Tempest case to ensure Services without Selectors\n\nTo ensure that connectivity is working we need to create a new\ntempest test, which will create a service without selectors,\ncreate the endpoints and check the connectivity to the endpoints.\n\nChange-Id: I07f24bb754f2dde24fe47b340ebec04440ff3890\n'}, {'number': 9, 'created': '2020-11-12 16:23:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kuryr-tempest-plugin/commit/638c3f3079c89e72fb9ce86c6068be3a84bf60bf', 'message': 'Create Tempest case to ensure Services without Selectors\n\nTo ensure that connectivity is working we need to create a new\ntempest test, which will create a service without selectors,\ncreate the endpoints and check the connectivity to the endpoints.\n\nChange-Id: I07f24bb754f2dde24fe47b340ebec04440ff3890\n'}, {'number': 10, 'created': '2020-11-12 16:25:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kuryr-tempest-plugin/commit/31f01df30e6429751c269e03449b2355de4b501f', 'message': 'Create Tempest case to ensure Services without Selectors\n\nTo ensure that connectivity is working we need to create a new\ntempest test, which will create a service without selectors,\ncreate the endpoints and check the connectivity to the endpoints.\n\nChange-Id: I07f24bb754f2dde24fe47b340ebec04440ff3890\n'}, {'number': 11, 'created': '2020-11-12 16:25:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kuryr-tempest-plugin/commit/7c013fc66fd711eeea83d61fa89c5027ecf9bac3', 'message': 'Create Tempest case to ensure Services without Selectors\n\nTo ensure that connectivity is working we need to create a new\ntempest test, which will create a service without selectors,\ncreate the endpoints and check the connectivity to the endpoints.\n\nChange-Id: I07f24bb754f2dde24fe47b340ebec04440ff3890\n'}, {'number': 12, 'created': '2020-11-12 16:45:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kuryr-tempest-plugin/commit/784f63bccd1fbcc7c1666a6e33519fccc9ea3671', 'message': 'Create Tempest case to ensure Services without Selectors\n\nTo ensure that connectivity is working we need to create a new\ntempest test, which will create a service without selectors,\ncreate the endpoints and check the connectivity to the endpoints.\n\nChange-Id: I07f24bb754f2dde24fe47b340ebec04440ff3890\n'}, {'number': 13, 'created': '2020-11-13 09:38:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kuryr-tempest-plugin/commit/68d31f0b809e66ee64ef1d0b4580c1119327be1c', 'message': 'Create Tempest case to ensure Services without Selectors\n\nTo ensure that connectivity is working we need to create a new\ntempest test, which will create a service without selectors,\ncreate the endpoints and check the connectivity to the endpoints.\n\nChange-Id: I07f24bb754f2dde24fe47b340ebec04440ff3890\n'}, {'number': 14, 'created': '2020-11-13 10:57:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kuryr-tempest-plugin/commit/b68b9c5beda8e00a35a1406414768b9e4b1bc1c7', 'message': 'Create Tempest case to ensure Services without Selectors\n\nTo ensure that connectivity is working we need to create a new\ntempest test, which will create a service without selectors,\ncreate the endpoints and check the connectivity to the endpoints.\n\nChange-Id: I07f24bb754f2dde24fe47b340ebec04440ff3890\nDepends-On: https://review.opendev.org/#/c/761192\n'}, {'number': 15, 'created': '2020-11-13 18:49:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kuryr-tempest-plugin/commit/7958db6e28722c01ae3bcd675eb2015222d53f7a', 'message': 'Create Tempest case to ensure Services without Selectors\n\nTo ensure that connectivity is working we need to create a new\ntempest test, which will create a service without selectors,\ncreate the endpoints and check the connectivity to the endpoints.\n\nChange-Id: I07f24bb754f2dde24fe47b340ebec04440ff3890\nDepends-On: https://review.opendev.org/#/c/761192\n'}, {'number': 16, 'created': '2020-11-13 18:56:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kuryr-tempest-plugin/commit/c01c06ed343d77b63639932b5838a180238397d7', 'message': 'Create Tempest case to ensure Services without Selectors\n\nTo ensure that connectivity is working we need to create a new\ntempest test, which will create a service without selectors,\ncreate the endpoints and check the connectivity to the endpoints.\n\nChange-Id: I07f24bb754f2dde24fe47b340ebec04440ff3890\nDepends-On: https://review.opendev.org/#/c/761192\n'}, {'number': 17, 'created': '2020-11-15 16:00:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kuryr-tempest-plugin/commit/271ea301e495c25442ca7f76dc43cbc1759cbfe0', 'message': 'Create Tempest case to ensure Services without Selectors\n\nTo ensure that connectivity is working we need to create a new\ntempest test, which will create a service without selectors,\ncreate the endpoints and check the connectivity to the endpoints.\n\nChange-Id: I07f24bb754f2dde24fe47b340ebec04440ff3890\nDepends-On: https://review.opendev.org/#/c/761192\n'}, {'number': 18, 'created': '2020-11-23 17:31:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kuryr-tempest-plugin/commit/bc98719670fcecea8cd9cce98298f6aaeaed6381', 'message': 'Create Tempest case to ensure Services without Selectors\n\nTo ensure that connectivity is working we need to create a new\ntempest test, which will create a service without selectors,\ncreate the endpoints and check the connectivity to the endpoints.\n\nChange-Id: I07f24bb754f2dde24fe47b340ebec04440ff3890\nDepends-On: https://review.opendev.org/#/c/761192\n'}, {'number': 19, 'created': '2020-11-24 08:51:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kuryr-tempest-plugin/commit/534de8e12c1f4eef1cdfc372f6ec9a4c887649ac', 'message': 'Create Tempest case to ensure Services without Selectors\n\nTo ensure that connectivity is working we need to create a new\ntempest test, which will create a service without selectors,\ncreate the endpoints and check the connectivity to the endpoints.\n\nChange-Id: I07f24bb754f2dde24fe47b340ebec04440ff3890\nDepends-On: https://review.opendev.org/#/c/761192\n'}, {'number': 20, 'created': '2020-11-27 14:18:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kuryr-tempest-plugin/commit/7dda6dba00c5d75099382fc715b0322e7441bab2', 'message': 'Create Tempest case to ensure Services without Selectors\n\nTo ensure that connectivity is working we need to create a new\ntempest test, which will create a service without selectors,\ncreate the endpoints and check the connectivity to the endpoints.\n\nChange-Id: I07f24bb754f2dde24fe47b340ebec04440ff3890\nDepends-On: https://review.opendev.org/#/c/761192\n'}, {'number': 21, 'created': '2020-11-30 11:33:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kuryr-tempest-plugin/commit/070a0ff56a60c957668bbfdace2c857799333132', 'message': 'Create Tempest case to ensure Services without Selectors\n\nTo ensure that connectivity is working we need to create a new\ntempest test, which will create a service without selectors,\ncreate the endpoints and check the connectivity to the endpoints.\n\nChange-Id: I07f24bb754f2dde24fe47b340ebec04440ff3890\nDepends-On: https://review.opendev.org/#/c/761192\n'}, {'number': 22, 'created': '2020-11-30 11:45:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kuryr-tempest-plugin/commit/07556b86a52180ec05b65d4ebc898bf10ac045df', 'message': 'Create Tempest case to ensure Services without Selectors\n\nTo ensure that connectivity is working we need to create a new\ntempest test, which will create a service without selectors,\ncreate the endpoints and check the connectivity to the endpoints.\n\nChange-Id: I07f24bb754f2dde24fe47b340ebec04440ff3890\nDepends-On: https://review.opendev.org/#/c/761192\n'}, {'number': 23, 'created': '2020-11-30 12:02:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kuryr-tempest-plugin/commit/d51e43701a809b55a5de8032e04aa2f8b2245640', 'message': 'Create Tempest case to ensure Services without Selectors\n\nTo ensure that connectivity is working we need to create a new\ntempest test, which will create a service without selectors,\ncreate the endpoints and check the connectivity to the endpoints.\n\nChange-Id: I07f24bb754f2dde24fe47b340ebec04440ff3890\n'}, {'number': 24, 'created': '2020-11-30 17:13:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kuryr-tempest-plugin/commit/527cf67a9670c08d82c485f107eddf3a0d4c484c', 'message': 'Create Tempest case to ensure Services without Selectors\n\nTo ensure that connectivity is working we need to create a new\ntempest test, which will create a service without selectors,\ncreate the endpoints and check the connectivity to the endpoints.\n\nChange-Id: I07f24bb754f2dde24fe47b340ebec04440ff3890\n'}, {'number': 25, 'created': '2020-12-01 12:03:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kuryr-tempest-plugin/commit/8301db10a4c3739152d1360b19e2e7f3932f2009', 'message': 'Create Tempest case to ensure Services without Selectors\n\nTo ensure that connectivity is working we need to create a new\ntempest test, which will create a service without selectors,\ncreate the endpoints and check the connectivity to the endpoints.\n\nChange-Id: I07f24bb754f2dde24fe47b340ebec04440ff3890\n'}, {'number': 26, 'created': '2020-12-01 12:04:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kuryr-tempest-plugin/commit/8fc596fe2a3618797f4053c00bdb8fe3f27b8192', 'message': 'Create Tempest case to ensure Services without Selectors\n\nTo ensure that connectivity is working we need to create a new\ntempest test, which will create a service without selectors,\ncreate the endpoints and check the connectivity to the endpoints.\n\nDepends-On: Ia6404c22132af3a17ce865c4f33a57b2b6832e9f\nChange-Id: I07f24bb754f2dde24fe47b340ebec04440ff3890\n'}, {'number': 27, 'created': '2020-12-01 15:44:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kuryr-tempest-plugin/commit/56c62df08a3d4671d3a19d7393e650346392abb3', 'message': 'Create Tempest case to ensure Services without Selectors\n\nTo ensure that connectivity is working we need to create a new\ntempest test, which will create a service without selectors,\ncreate the endpoints and check the connectivity to the endpoints.\n\nDepends-On: Ia6404c22132af3a17ce865c4f33a57b2b6832e9f\nChange-Id: I07f24bb754f2dde24fe47b340ebec04440ff3890\n'}, {'number': 28, 'created': '2020-12-01 17:22:15.000000000', 'files': ['kuryr_tempest_plugin/tests/scenario/test_service.py', 'kuryr_tempest_plugin/config.py', 'kuryr_tempest_plugin/tests/scenario/base.py'], 'web_link': 'https://opendev.org/openstack/kuryr-tempest-plugin/commit/9819fe5d7f56f3409fd6d728113f3ef08897df18', 'message': 'Create Tempest case to ensure Services without Selectors\n\nTo ensure that connectivity is working we need to create a new\ntempest test, which will create a service without selectors,\ncreate the endpoints and check the connectivity to the endpoints.\n\nDepends-On: Ia6404c22132af3a17ce865c4f33a57b2b6832e9f\nChange-Id: I07f24bb754f2dde24fe47b340ebec04440ff3890\n'}]",50,757551,9819fe5d7f56f3409fd6d728113f3ef08897df18,98,8,28,30963,,,0,"Create Tempest case to ensure Services without Selectors

To ensure that connectivity is working we need to create a new
tempest test, which will create a service without selectors,
create the endpoints and check the connectivity to the endpoints.

Depends-On: Ia6404c22132af3a17ce865c4f33a57b2b6832e9f
Change-Id: I07f24bb754f2dde24fe47b340ebec04440ff3890
",git fetch https://review.opendev.org/openstack/kuryr-tempest-plugin refs/changes/51/757551/28 && git format-patch -1 --stdout FETCH_HEAD,['kuryr_tempest_plugin/tests/scenario/test_service.py'],1,59e08dadad7474d818573394e92624c01f69c616,temtest1," def test_service_without_selector(self): # Create a servvice without selector spec_type = 'ClusterIP' ns_name, ns_obj = self.create_namespace() pod_name, pod = self.create_pod(namespace=ns_name) svc_name, svc_obj = self.create_service(spec_type=spec_type, namespace=ns_name) svc_ip = self.get_svc_ip_on_crd(svc_name, ns_name) self.verify_lbaas_endpoints_configured(svc_name, namespace=ns_name)"," def test_service_udp_ping(self): # NOTE(ltomasbo): Using LoadBalancer type to avoid namespace isolation # restrictions as this test targets svc udp testing and not the # isolation self.create_setup_for_service_test(protocol=""UDP"", port=90, target_port=9090) # NOTE(ltomasbo): Ensure usage of svc clusterIP IP instead of the FIP # as the focus of this test is not to check FIP connectivity. self.check_service_internal_connectivity(service_port='90', protocol='UDP')",11,10
openstack%2Ftempest~master~I3044d59b4f1505accefdaafafecef685cb9a9af5,openstack/tempest,master,I3044d59b4f1505accefdaafafecef685cb9a9af5,Add related test to Bug #1732428,MERGED,2020-07-29 09:59:40.000000000,2020-12-02 10:52:42.000000000,2020-11-30 13:41:21.000000000,"[{'_account_id': 5689}, {'_account_id': 5803}, {'_account_id': 8556}, {'_account_id': 10135}, {'_account_id': 22348}, {'_account_id': 22873}, {'_account_id': 23181}, {'_account_id': 28332}, {'_account_id': 28627}]","[{'number': 1, 'created': '2020-07-29 09:59:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/fbcb5c830925fb589877903048dc87a57b66a351', 'message': 'Add related test to Bug #1732428\n\nReproduce data loss when migrating unshelve qcow2 instance.\n\nChange-Id: I3044d59b4f1505accefdaafafecef685cb9a9af5\nRelated-Bug: #1732428\n'}, {'number': 2, 'created': '2020-07-29 20:09:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/9558f85574beb9cb33ff0153b3dc8816bdc195db', 'message': 'Add related test to Bug #1732428\n\nReproduce data loss when migrating unshelve qcow2 instance.\n\nDepends-On: https://review.opendev.org/#/c/696084/\nChange-Id: I3044d59b4f1505accefdaafafecef685cb9a9af5\nRelated-Bug: #1732428\n'}, {'number': 3, 'created': '2020-07-30 09:26:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/c9123fb5e291a7e3adfb38a8daa20d392a8f7508', 'message': 'Add related test to Bug #1732428\n\nReproduce data loss when migrating unshelve qcow2 instance.\n\nDepends-On: https://review.opendev.org/#/c/696084/\nChange-Id: I3044d59b4f1505accefdaafafecef685cb9a9af5\nRelated-Bug: #1732428\n'}, {'number': 4, 'created': '2020-08-17 10:48:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/d469e6ce08dcf6559a9cd900a5cfae562d92ce2f', 'message': 'Add related test to Bug #1732428\n\nReproduce data loss when migrating unshelve qcow2 instance.\n\nDepends-On: https://review.opendev.org/#/c/696084/\nChange-Id: I3044d59b4f1505accefdaafafecef685cb9a9af5\nRelated-Bug: #1732428\n'}, {'number': 5, 'created': '2020-08-18 14:37:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/cda075c9a8b07c2a303fa5b92ff66c40385454da', 'message': 'Add related test to Bug #1732428\n\nReproduce data loss when migrating unshelved qcow2 instance.\n\nDepends-On: https://review.opendev.org/#/c/696084/\nChange-Id: I3044d59b4f1505accefdaafafecef685cb9a9af5\nRelated-Bug: #1732428\n'}, {'number': 6, 'created': '2020-09-25 07:06:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/807fedd8e61dfa00a325544d5ab75adf91d60594', 'message': 'Add related test to Bug #1732428\n\nReproduce data loss when migrating unshelved qcow2 instance.\n\nDepends-On: https://review.opendev.org/#/c/696084/\nDepends-On: https://review.opendev.org/#/c/752463/\nChange-Id: I3044d59b4f1505accefdaafafecef685cb9a9af5\nRelated-Bug: #1732428\n'}, {'number': 7, 'created': '2020-11-13 08:51:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/016f54d1d9a65ddab3057dc524211c8852aa94a6', 'message': 'Add related test to Bug #1732428\n\nReproduce data loss when migrating unshelved qcow2 instance.\n\nAdd also [compute-feature-enabled]/shelve_migrate config, to enable this\ntest only on supported environment.\n\nDepends-On: https://review.opendev.org/#/c/696084/\nDepends-On: https://review.opendev.org/#/c/752463/\nChange-Id: I3044d59b4f1505accefdaafafecef685cb9a9af5\nRelated-Bug: #1732428\n'}, {'number': 8, 'created': '2020-11-19 07:41:48.000000000', 'files': ['releasenotes/notes/add-compute-feature-shelve-migrate-fdbd3633abe65c4e.yaml', 'tempest/config.py', 'tempest/scenario/test_shelve_instance.py'], 'web_link': 'https://opendev.org/openstack/tempest/commit/0a9b8235b6a3222b3b0ef721c1651d0cf1f5f906', 'message': 'Add related test to Bug #1732428\n\nReproduce data loss when migrating unshelved qcow2 instance.\n\nAdd also [compute-feature-enabled]/shelve_migrate config, to enable this\ntest only on supported environment.\n\nDepends-On: https://review.opendev.org/#/c/696084/\nDepends-On: https://review.opendev.org/#/c/752463/\nChange-Id: I3044d59b4f1505accefdaafafecef685cb9a9af5\nRelated-Bug: #1732428\n'}]",12,743708,0a9b8235b6a3222b3b0ef721c1651d0cf1f5f906,59,9,8,28332,,,0,"Add related test to Bug #1732428

Reproduce data loss when migrating unshelved qcow2 instance.

Add also [compute-feature-enabled]/shelve_migrate config, to enable this
test only on supported environment.

Depends-On: https://review.opendev.org/#/c/696084/
Depends-On: https://review.opendev.org/#/c/752463/
Change-Id: I3044d59b4f1505accefdaafafecef685cb9a9af5
Related-Bug: #1732428
",git fetch https://review.opendev.org/openstack/tempest refs/changes/08/743708/1 && git format-patch -1 --stdout FETCH_HEAD,['tempest/scenario/test_shelve_instance.py'],1,fbcb5c830925fb589877903048dc87a57b66a351,bug/1732428," credentials = ['primary', 'admin'] @classmethod def setup_clients(cls): super(TestShelveInstance, cls).setup_clients() cls.admin_servers_client = cls.os_admin.servers_client def _cold_migrate_server(self, server): src_host = self.get_host_for_server(server['id']) self.admin_servers_client.migrate_server(server['id']) waiters.wait_for_server_status(self.servers_client, server['id'], 'VERIFY_RESIZE') self.servers_client.confirm_resize_server(server['id']) waiters.wait_for_server_status(self.servers_client, server['id'], 'ACTIVE') dst_host = self.get_host_for_server(server['id']) self.assertNotEqual(src_host, dst_host) def _create_server_then_shelve_and_unshelve(self, boot_from_volume=False, cold_migrate=False): if cold_migrate: # Prevent bug #1732428 from coming back self._cold_migrate_server(server) @decorators.attr(type='slow') @decorators.idempotent_id('1295fd9e-193a-4cf8-b211-55358e021bae') @testtools.skipUnless(CONF.network.public_network_id, 'The public_network_id option must be specified.') @testtools.skipUnless(CONF.compute_feature_enabled.cold_migration, 'Cold migration not available.') @testtools.skipUnless(CONF.compute.min_compute_nodes > 1, 'Less than 2 compute nodes, skipping multinode ' 'tests.') @utils.services('compute', 'network', 'image') def test_shelve_cold_migrated_instance(self): self._create_server_then_shelve_and_unshelve(cold_migrate=True)"," def _create_server_then_shelve_and_unshelve(self, boot_from_volume=False):",39,1
openstack%2Fpython-freezerclient~master~I220d81d6e82336db82f49c469f6d2cc70ab13675,openstack/python-freezerclient,master,I220d81d6e82336db82f49c469f6d2cc70ab13675,Remove unuseful param 'opts',MERGED,2020-12-02 09:03:30.000000000,2020-12-02 10:47:17.000000000,2020-12-02 10:45:44.000000000,"[{'_account_id': 21069}, {'_account_id': 22348}]","[{'number': 1, 'created': '2020-12-02 09:03:30.000000000', 'files': ['freezerclient/v1/client.py'], 'web_link': 'https://opendev.org/openstack/python-freezerclient/commit/2fe404f68f00f97ab8c5ac718f8fd026dfde28f3', 'message': ""Remove unuseful param 'opts'\n\nRemove unuseful param 'opts'\n\nChange-Id: I220d81d6e82336db82f49c469f6d2cc70ab13675\nTask: 41348\n""}]",0,765069,2fe404f68f00f97ab8c5ac718f8fd026dfde28f3,7,2,1,21069,,,0,"Remove unuseful param 'opts'

Remove unuseful param 'opts'

Change-Id: I220d81d6e82336db82f49c469f6d2cc70ab13675
Task: 41348
",git fetch https://review.opendev.org/openstack/python-freezerclient refs/changes/69/765069/1 && git format-patch -1 --stdout FETCH_HEAD,['freezerclient/v1/client.py'],1,2fe404f68f00f97ab8c5ac718f8fd026dfde28f3,," endpoint_type=None, project_name=None, self.opts = utils.Namespace({}) self.opts.os_token = token or None self.opts.os_username = username or None self.opts.os_password = password or None self.opts.os_auth_url = auth_url or None self.opts.os_backup_url = endpoint or None self.opts.os_endpoint_type = endpoint_type or None self.opts.os_project_name = project_name or None self.opts.os_project_id = project_id or None self.opts.os_user_domain_name = user_domain_name or None self.opts.os_user_domain_id = user_domain_id or None self.opts.os_project_domain_name = project_domain_name or None self.opts.os_project_domain_id = project_domain_id or None self.opts.os_cacert = cacert or None self.opts.insecure = insecure self.opts.cert = cert"," endpoint_type=None, opts=None, project_name=None, :param opts: a namespace to store all keystone data if opts is None: self.opts = utils.Namespace({}) self.opts.os_token = token or None self.opts.os_username = username or None self.opts.os_password = password or None self.opts.os_auth_url = auth_url or None self.opts.os_backup_url = endpoint or None self.opts.os_endpoint_type = endpoint_type or None self.opts.os_project_name = project_name or None self.opts.os_project_id = project_id or None self.opts.os_user_domain_name = user_domain_name or None self.opts.os_user_domain_id = user_domain_id or None self.opts.os_project_domain_name = project_domain_name or None self.opts.os_project_domain_id = project_domain_id or None self.opts.os_cacert = cacert or None self.opts.insecure = insecure self.opts.cert = cert else: self.opts = opts",17,21
openstack%2Fneutron~master~I99681736d05eefd82bdba72b3866eab9468ef5dd,openstack/neutron,master,I99681736d05eefd82bdba72b3866eab9468ef5dd,Support remote address group in SG rules,MERGED,2020-09-10 21:31:37.000000000,2020-12-02 10:42:40.000000000,2020-11-28 11:26:39.000000000,"[{'_account_id': 4694}, {'_account_id': 5948}, {'_account_id': 9845}, {'_account_id': 11975}, {'_account_id': 15752}, {'_account_id': 22348}, {'_account_id': 26622}, {'_account_id': 28159}, {'_account_id': 29963}]","[{'number': 1, 'created': '2020-09-10 21:31:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/cf92843dc125d3794ef5932f9feae43cc4a98612', 'message': '[WIP] Support remote address group in SG rules\n\nFollow-up patch of: https://review.opendev.org/#/c/738274/\n\n- Add remote-address-group-id into SG rules DB model.\n\nChange-Id: I99681736d05eefd82bdba72b3866eab9468ef5dd\nImplements: blueprint address-groups-in-sg-rules\n'}, {'number': 2, 'created': '2020-09-11 19:46:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/68ac6fb662a4e3c7ea577b843ac5544f343dfe14', 'message': '[WIP] Support remote address group in SG rules\n\nFollow-up patch of: https://review.opendev.org/#/c/738274/\n\n- Add remote-address-group-id into SG rules DB model.\n\nChange-Id: I99681736d05eefd82bdba72b3866eab9468ef5dd\nImplements: blueprint address-groups-in-sg-rules\n'}, {'number': 3, 'created': '2020-09-29 01:07:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/da98885ec755b2dd73c266574f40391255468945', 'message': '[WIP] Support remote address group in SG rules\n\nFollow-up patch of: https://review.opendev.org/#/c/738274/\n\n- Use normalized cidrs in address groups.\n- Add api extension and db model changes to support remote_address_group_id\n  in SG rules.\n\nChange-Id: I99681736d05eefd82bdba72b3866eab9468ef5dd\nImplements: blueprint address-groups-in-sg-rules\n'}, {'number': 4, 'created': '2020-09-29 22:17:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/19cba7752d514053e290680feb71f7f746a1744d', 'message': '[WIP] Support remote address group in SG rules\n\nFollow-up patch of: https://review.opendev.org/#/c/738274/\n\n- Use normalized cidrs in address groups.\n- Add api extension and db model changes to support remote_address_group_id\n  in SG rules.\n\nChange-Id: I99681736d05eefd82bdba72b3866eab9468ef5dd\nImplements: blueprint address-groups-in-sg-rules\n'}, {'number': 5, 'created': '2020-09-30 22:13:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/d90c89ed108cf680ca2eb9d150141b779e3f9c8e', 'message': 'Support remote address group in SG rules\n\nFollow-up patch of: https://review.opendev.org/#/c/738274/\n\n- Use normalized cidrs in address groups.\n- Add api extension and db model changes to support remote_address_group_id\n  in SG rules.\n- TODO: firewall drivers\n\nChange-Id: I99681736d05eefd82bdba72b3866eab9468ef5dd\nImplements: blueprint address-groups-in-sg-rules\n'}, {'number': 6, 'created': '2020-10-01 21:27:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/227b703fdf8f40b60a6493176c18d1333637c409', 'message': 'Support remote address group in SG rules\n\n- Add api extension and db model changes to support remote_address_group_id\n  in SG rules.\n- TODO: firewall drivers\n\nChange-Id: I99681736d05eefd82bdba72b3866eab9468ef5dd\nImplements: blueprint address-groups-in-sg-rules\nDepends-On: https://review.opendev.org/755650\n'}, {'number': 7, 'created': '2020-10-05 18:42:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/532965587af228c3b383c2840e784f770fd35d91', 'message': 'Support remote address group in SG rules\n\n- Add api extension and db model changes to support remote_address_group_id\n  in SG rules.\n- TODO: firewall drivers\n\nChange-Id: I99681736d05eefd82bdba72b3866eab9468ef5dd\nImplements: blueprint address-groups-in-sg-rules\nDepends-On: https://review.opendev.org/755650\n'}, {'number': 8, 'created': '2020-10-14 15:22:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/97f0444056625809433e9125ac7f099aa96448e7', 'message': 'Support remote address group in SG rules\n\n- Add api extension and db model changes to support remote_address_group_id\n  in SG rules.\n- RPC and firewall agent changes will be in the follow-up patches.\n\nChange-Id: I99681736d05eefd82bdba72b3866eab9468ef5dd\nImplements: blueprint address-groups-in-sg-rules\nDepends-On: https://review.opendev.org/755650\n'}, {'number': 9, 'created': '2020-10-16 20:16:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/7e5112337fa66903e8f0f9364f938ac858d0f6da', 'message': 'Support remote address group in SG rules\n\n- Add api extension and db model changes to support remote_address_group_id\n  in SG rules.\n- RPC and firewall agent changes will be in the follow-up patches.\n\nChange-Id: I99681736d05eefd82bdba72b3866eab9468ef5dd\nImplements: blueprint address-groups-in-sg-rules\nDepends-On: https://review.opendev.org/755650\n'}, {'number': 10, 'created': '2020-10-16 21:41:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/3fdeb7a07fa0ee1396ae63af1aff8daa36e45ad3', 'message': 'Support remote address group in SG rules\n\n- Add api extension and db model changes to support remote_address_group_id\n  in SG rules.\n- RPC and firewall agent changes will be in the follow-up patches.\n\nChange-Id: I99681736d05eefd82bdba72b3866eab9468ef5dd\nImplements: blueprint address-groups-in-sg-rules\nDepends-On: https://review.opendev.org/755650\n'}, {'number': 11, 'created': '2020-11-09 16:07:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/142a1c5937b8d4ee90fe47b653b75570ffe6156a', 'message': 'Support remote address group in SG rules\n\n- Add api extension and db model changes to support remote_address_group_id\n  in SG rules.\n- RPC and firewall agent changes will be in the follow-up patches.\n\nChange-Id: I99681736d05eefd82bdba72b3866eab9468ef5dd\nImplements: blueprint address-groups-in-sg-rules\nDepends-On: https://review.opendev.org/755650\n'}, {'number': 12, 'created': '2020-11-11 17:56:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/f15e5ae9ed6e0e42d50fa165952e8e382c17c6f2', 'message': 'Support remote address group in SG rules\n\n- Add api extension and db model changes to support remote_address_group_id\n  in SG rules.\n- RPC and firewall agent changes will be in the follow-up patches.\n\nChange-Id: I99681736d05eefd82bdba72b3866eab9468ef5dd\nImplements: blueprint address-groups-in-sg-rules\n'}, {'number': 13, 'created': '2020-11-23 17:44:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/843ba53d837ee2021aafc5c3c8d499f83686d504', 'message': 'Support remote address group in SG rules\n\n- Add api extension and db model changes to support remote_address_group_id\n  in SG rules.\n- RPC and firewall agent changes will be in the follow-up patches.\n\nChange-Id: I99681736d05eefd82bdba72b3866eab9468ef5dd\nImplements: blueprint address-groups-in-sg-rules\n'}, {'number': 14, 'created': '2020-11-24 21:18:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/7f6ba1ddc47b5773a403909b3d29488b7000cc96', 'message': 'Support remote address group in SG rules\n\n- Add api extension and db model changes to support remote_address_group_id\n  in SG rules.\n- RPC and firewall agent changes will be in the follow-up patches.\n\nChange-Id: I99681736d05eefd82bdba72b3866eab9468ef5dd\nImplements: blueprint address-groups-in-sg-rules\n'}, {'number': 15, 'created': '2020-11-25 16:35:03.000000000', 'files': ['neutron/db/securitygroups_db.py', 'neutron/tests/unit/objects/test_securitygroup.py', 'neutron/objects/securitygroup.py', 'neutron/tests/unit/db/test_securitygroups_db.py', 'neutron/tests/unit/plugins/ml2/test_ovo_rpc.py', 'neutron/db/migration/alembic_migrations/versions/EXPAND_HEAD', 'neutron/tests/unit/services/revisions/test_revision_plugin.py', 'neutron/db/migration/alembic_migrations/versions/wallaby/expand/a964d94b4677_support_remote_address_group_in_sg_rules.py', 'neutron/tests/unit/db/test_ovn_revision_numbers_db.py', 'neutron/agent/securitygroups_rpc.py', 'neutron/plugins/ml2/plugin.py', 'neutron/tests/unit/extensions/test_securitygroup.py', 'neutron/tests/unit/objects/test_objects.py', 'neutron/db/address_group_db.py', 'neutron/db/models/securitygroup.py', 'neutron/tests/contrib/hooks/api_all_extensions', 'neutron/extensions/security_groups_remote_address_group.py', 'neutron/extensions/securitygroup.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/85c089eef2793d127698e524df74ccd512755ddf', 'message': 'Support remote address group in SG rules\n\n- Add api extension and db model changes to support remote_address_group_id\n  in SG rules.\n- RPC and firewall agent changes will be in the follow-up patches.\n\nChange-Id: I99681736d05eefd82bdba72b3866eab9468ef5dd\nImplements: blueprint address-groups-in-sg-rules\n'}]",28,751110,85c089eef2793d127698e524df74ccd512755ddf,121,9,15,28159,,,0,"Support remote address group in SG rules

- Add api extension and db model changes to support remote_address_group_id
  in SG rules.
- RPC and firewall agent changes will be in the follow-up patches.

Change-Id: I99681736d05eefd82bdba72b3866eab9468ef5dd
Implements: blueprint address-groups-in-sg-rules
",git fetch https://review.opendev.org/openstack/neutron refs/changes/10/751110/5 && git format-patch -1 --stdout FETCH_HEAD,"['neutron/objects/securitygroup.py', 'neutron/db/models/securitygroup.py', 'neutron/db/migration/alembic_migrations/versions/EXPAND_HEAD', 'neutron/db/migration/alembic_migrations/versions/victoria/expand/a964d94b4677_support_remote_address_group_in_sg_rules.py', 'neutron/tests/unit/objects/test_objects.py']",5,cf92843dc125d3794ef5932f9feae43cc4a98612,bp/address-groups-in-sg-rules," 'SecurityGroupRule': '1.1-0a8614633901e353dd32948dc2f8708f',"," 'SecurityGroupRule': '1.0-e9b8dace9d48b936c62ad40fe1f339d5',",50,4
openstack%2Freleases~master~If873265d0f5c5f9308e2fe34635deec348aa9b8f,openstack/releases,master,If873265d0f5c5f9308e2fe34635deec348aa9b8f,Release python-saharaclient for wallaby-1 milestone,MERGED,2020-11-30 13:49:44.000000000,2020-12-02 10:25:43.000000000,2020-12-02 10:25:43.000000000,"[{'_account_id': 308}, {'_account_id': 22348}, {'_account_id': 23078}, {'_account_id': 28522}]","[{'number': 1, 'created': '2020-11-30 13:49:44.000000000', 'files': ['deliverables/wallaby/python-saharaclient.yaml'], 'web_link': 'https://opendev.org/openstack/releases/commit/b535cb0f2b7dbecc2d5561e605d305d73b15e9cc', 'message': 'Release python-saharaclient for wallaby-1 milestone\n\nThis is a library release for python-saharaclient for the wallaby-1\nmilestone. This repo includes commits that have not been releases for\nthis cycle yet.\n\nIf the team is ready to process with this release, please leave a +1\nto indicate we should go ahead with the release.\n\nIf the team needs more time for things about to merge, or if there is\nsome other reason a release should not be done at this time, please\nleave a -1 with a comment indicating the status. Then update the patch\nwith the new commit hash to use once the team is ready to do the\nrelease.\n\nChange-Id: If873265d0f5c5f9308e2fe34635deec348aa9b8f\n'}]",0,764744,b535cb0f2b7dbecc2d5561e605d305d73b15e9cc,9,4,1,28522,,,0,"Release python-saharaclient for wallaby-1 milestone

This is a library release for python-saharaclient for the wallaby-1
milestone. This repo includes commits that have not been releases for
this cycle yet.

If the team is ready to process with this release, please leave a +1
to indicate we should go ahead with the release.

If the team needs more time for things about to merge, or if there is
some other reason a release should not be done at this time, please
leave a -1 with a comment indicating the status. Then update the patch
with the new commit hash to use once the team is ready to do the
release.

Change-Id: If873265d0f5c5f9308e2fe34635deec348aa9b8f
",git fetch https://review.opendev.org/openstack/releases refs/changes/44/764744/1 && git format-patch -1 --stdout FETCH_HEAD,['deliverables/wallaby/python-saharaclient.yaml'],1,b535cb0f2b7dbecc2d5561e605d305d73b15e9cc,w1-c-w-i,releases: - version: 3.3.0 projects: - repo: openstack/python-saharaclient hash: 401e663f6791bfb813c75f1acba40f1fb4db196c,,5,0
openstack%2Freleases~master~I39c87eec9a1f52adb97a0e844b952dfee356b014,openstack/releases,master,I39c87eec9a1f52adb97a0e844b952dfee356b014,Release python-vitrageclient for wallaby-1 milestone,MERGED,2020-11-30 13:52:21.000000000,2020-12-02 10:25:31.000000000,2020-12-02 10:25:31.000000000,"[{'_account_id': 308}, {'_account_id': 19134}, {'_account_id': 22348}, {'_account_id': 28522}]","[{'number': 1, 'created': '2020-11-30 13:52:21.000000000', 'files': ['deliverables/wallaby/python-vitrageclient.yaml'], 'web_link': 'https://opendev.org/openstack/releases/commit/7df75a29f9d5c8d945213f2955ae20f2c948ad5a', 'message': 'Release python-vitrageclient for wallaby-1 milestone\n\nThis is a library release for python-vitrageclient for the wallaby-1\nmilestone. This repo includes commits that have not been releases for\nthis cycle yet.\n\nIf the team is ready to process with this release, please leave a +1\nto indicate we should go ahead with the release.\n\nIf the team needs more time for things about to merge, or if there is\nsome other reason a release should not be done at this time, please\nleave a -1 with a comment indicating the status. Then update the patch\nwith the new commit hash to use once the team is ready to do the\nrelease.\n\nChange-Id: I39c87eec9a1f52adb97a0e844b952dfee356b014\n'}]",0,764749,7df75a29f9d5c8d945213f2955ae20f2c948ad5a,9,4,1,28522,,,0,"Release python-vitrageclient for wallaby-1 milestone

This is a library release for python-vitrageclient for the wallaby-1
milestone. This repo includes commits that have not been releases for
this cycle yet.

If the team is ready to process with this release, please leave a +1
to indicate we should go ahead with the release.

If the team needs more time for things about to merge, or if there is
some other reason a release should not be done at this time, please
leave a -1 with a comment indicating the status. Then update the patch
with the new commit hash to use once the team is ready to do the
release.

Change-Id: I39c87eec9a1f52adb97a0e844b952dfee356b014
",git fetch https://review.opendev.org/openstack/releases refs/changes/49/764749/1 && git format-patch -1 --stdout FETCH_HEAD,['deliverables/wallaby/python-vitrageclient.yaml'],1,7df75a29f9d5c8d945213f2955ae20f2c948ad5a,w1-c-w-i,releases: - version: 4.2.0 projects: - repo: openstack/python-vitrageclient hash: 3b976540d9ca5881003c3884bed12993d43b00cc,,5,0
openstack%2Fproject-config~master~I39e67031f126dc3e7c55a1acf7ab4aa0f1f3125c,openstack/project-config,master,I39e67031f126dc3e7c55a1acf7ab4aa0f1f3125c,Remove openstack-python and openstack-docs job for x/vmtp project.,MERGED,2020-11-24 19:19:16.000000000,2020-12-02 10:21:38.000000000,2020-12-02 10:21:38.000000000,"[{'_account_id': 6547}, {'_account_id': 7118}, {'_account_id': 11744}, {'_account_id': 17850}, {'_account_id': 22348}]","[{'number': 1, 'created': '2020-11-24 19:19:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/project-config/commit/9ddebf770dd8d554769f7203759d0c5ff0ccc7f0', 'message': 'Enable python 3.6 job only for x/vmtp project.\n\nChange-Id: I39e67031f126dc3e7c55a1acf7ab4aa0f1f3125c\n'}, {'number': 2, 'created': '2020-11-24 22:03:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/project-config/commit/715186c5970fdc92eb34a2c39ce6a7a9ff919032', 'message': 'Enable python 3.6 job only for x/vmtp project.\n\nChange-Id: I39e67031f126dc3e7c55a1acf7ab4aa0f1f3125c\n'}, {'number': 3, 'created': '2020-11-25 15:02:57.000000000', 'files': ['zuul.d/projects.yaml'], 'web_link': 'https://opendev.org/openstack/project-config/commit/ff449822b4d9def379905d2a373e695128c1c042', 'message': 'Remove openstack-python and openstack-docs job for x/vmtp project.\n\nChange-Id: I39e67031f126dc3e7c55a1acf7ab4aa0f1f3125c\n'}]",3,764054,ff449822b4d9def379905d2a373e695128c1c042,18,5,3,11744,,,0,"Remove openstack-python and openstack-docs job for x/vmtp project.

Change-Id: I39e67031f126dc3e7c55a1acf7ab4aa0f1f3125c
",git fetch https://review.opendev.org/openstack/project-config refs/changes/54/764054/3 && git format-patch -1 --stdout FETCH_HEAD,['zuul.d/projects.yaml'],1,9ddebf770dd8d554769f7203759d0c5ff0ccc7f0,, - openstack-python36-jobs, - openstack-python-jobs,1,1
openstack%2Freleases~master~I125f0286d21481ea071454ba3fff85ec13ba0451,openstack/releases,master,I125f0286d21481ea071454ba3fff85ec13ba0451,Release python-masakariclient for wallaby-1 milestone,MERGED,2020-11-30 13:46:07.000000000,2020-12-02 10:19:49.000000000,2020-12-02 10:19:49.000000000,"[{'_account_id': 308}, {'_account_id': 22348}, {'_account_id': 28522}, {'_account_id': 30491}]","[{'number': 1, 'created': '2020-11-30 13:46:07.000000000', 'files': ['deliverables/wallaby/python-masakariclient.yaml'], 'web_link': 'https://opendev.org/openstack/releases/commit/d9dd8fa55420023d50c5cfdc57eb89ad3b43f308', 'message': 'Release python-masakariclient for wallaby-1 milestone\n\nThis is a library release for python-masakariclient for the wallaby-1\nmilestone. This repo includes commits that have not been releases for\nthis cycle yet.\n\nIf the team is ready to process with this release, please leave a +1\nto indicate we should go ahead with the release.\n\nIf the team needs more time for things about to merge, or if there is\nsome other reason a release should not be done at this time, please\nleave a -1 with a comment indicating the status. Then update the patch\nwith the new commit hash to use once the team is ready to do the\nrelease.\n\nChange-Id: I125f0286d21481ea071454ba3fff85ec13ba0451\n'}]",0,764736,d9dd8fa55420023d50c5cfdc57eb89ad3b43f308,9,4,1,28522,,,0,"Release python-masakariclient for wallaby-1 milestone

This is a library release for python-masakariclient for the wallaby-1
milestone. This repo includes commits that have not been releases for
this cycle yet.

If the team is ready to process with this release, please leave a +1
to indicate we should go ahead with the release.

If the team needs more time for things about to merge, or if there is
some other reason a release should not be done at this time, please
leave a -1 with a comment indicating the status. Then update the patch
with the new commit hash to use once the team is ready to do the
release.

Change-Id: I125f0286d21481ea071454ba3fff85ec13ba0451
",git fetch https://review.opendev.org/openstack/releases refs/changes/36/764736/1 && git format-patch -1 --stdout FETCH_HEAD,['deliverables/wallaby/python-masakariclient.yaml'],1,d9dd8fa55420023d50c5cfdc57eb89ad3b43f308,w1-c-w-i,releases: - version: 6.2.0 projects: - repo: openstack/python-masakariclient hash: cecef8bbb4c4afc29ae909d60686f346e256546f,,5,0
openstack%2Freleases~master~I93c35f3de4442cb8f94406aa61ddeee3748b2d7f,openstack/releases,master,I93c35f3de4442cb8f94406aa61ddeee3748b2d7f,Release python-pankoclient for wallaby-1 milestone,MERGED,2020-11-30 13:49:23.000000000,2020-12-02 10:19:45.000000000,2020-12-02 10:19:45.000000000,"[{'_account_id': 308}, {'_account_id': 4264}, {'_account_id': 11904}, {'_account_id': 22348}]","[{'number': 1, 'created': '2020-11-30 13:49:23.000000000', 'files': ['deliverables/wallaby/python-pankoclient.yaml'], 'web_link': 'https://opendev.org/openstack/releases/commit/5246d38474307b0213001a532d3aa8d7eb1fea56', 'message': 'Release python-pankoclient for wallaby-1 milestone\n\nThis is a library release for python-pankoclient for the wallaby-1\nmilestone. This repo includes commits that have not been releases for\nthis cycle yet.\n\nIf the team is ready to process with this release, please leave a +1\nto indicate we should go ahead with the release.\n\nIf the team needs more time for things about to merge, or if there is\nsome other reason a release should not be done at this time, please\nleave a -1 with a comment indicating the status. Then update the patch\nwith the new commit hash to use once the team is ready to do the\nrelease.\n\nChange-Id: I93c35f3de4442cb8f94406aa61ddeee3748b2d7f\n'}]",0,764743,5246d38474307b0213001a532d3aa8d7eb1fea56,9,4,1,28522,,,0,"Release python-pankoclient for wallaby-1 milestone

This is a library release for python-pankoclient for the wallaby-1
milestone. This repo includes commits that have not been releases for
this cycle yet.

If the team is ready to process with this release, please leave a +1
to indicate we should go ahead with the release.

If the team needs more time for things about to merge, or if there is
some other reason a release should not be done at this time, please
leave a -1 with a comment indicating the status. Then update the patch
with the new commit hash to use once the team is ready to do the
release.

Change-Id: I93c35f3de4442cb8f94406aa61ddeee3748b2d7f
",git fetch https://review.opendev.org/openstack/releases refs/changes/43/764743/1 && git format-patch -1 --stdout FETCH_HEAD,['deliverables/wallaby/python-pankoclient.yaml'],1,5246d38474307b0213001a532d3aa8d7eb1fea56,w1-c-w-i,releases: - version: 1.2.0 projects: - repo: openstack/python-pankoclient hash: a20549e143af685cdeb8152aca942844275e1d7c,,5,0
openstack%2Freleases~master~Iebd9f6116b7fdd1d0c61a1d442203b87decf00ce,openstack/releases,master,Iebd9f6116b7fdd1d0c61a1d442203b87decf00ce,Release mistral-lib for wallaby-1 milestone,MERGED,2020-11-30 13:17:02.000000000,2020-12-02 10:19:40.000000000,2020-12-02 10:19:40.000000000,"[{'_account_id': 8731}, {'_account_id': 11904}, {'_account_id': 22348}, {'_account_id': 28522}]","[{'number': 1, 'created': '2020-11-30 13:17:02.000000000', 'files': ['deliverables/wallaby/mistral-lib.yaml'], 'web_link': 'https://opendev.org/openstack/releases/commit/f6015563dba80eddcca6b96a216bd4e62cff711a', 'message': 'Release mistral-lib for wallaby-1 milestone\n\nThis is a library release for mistral-lib for the wallaby-1\nmilestone. This repo includes commits that have not been releases for\nthis cycle yet.\n\nIf the team is ready to process with this release, please leave a +1\nto indicate we should go ahead with the release.\n\nIf the team needs more time for things about to merge, or if there is\nsome other reason a release should not be done at this time, please\nleave a -1 with a comment indicating the status. Then update the patch\nwith the new commit hash to use once the team is ready to do the\nrelease.\n\nChange-Id: Iebd9f6116b7fdd1d0c61a1d442203b87decf00ce\n'}]",0,764696,f6015563dba80eddcca6b96a216bd4e62cff711a,7,4,1,28522,,,0,"Release mistral-lib for wallaby-1 milestone

This is a library release for mistral-lib for the wallaby-1
milestone. This repo includes commits that have not been releases for
this cycle yet.

If the team is ready to process with this release, please leave a +1
to indicate we should go ahead with the release.

If the team needs more time for things about to merge, or if there is
some other reason a release should not be done at this time, please
leave a -1 with a comment indicating the status. Then update the patch
with the new commit hash to use once the team is ready to do the
release.

Change-Id: Iebd9f6116b7fdd1d0c61a1d442203b87decf00ce
",git fetch https://review.opendev.org/openstack/releases refs/changes/96/764696/1 && git format-patch -1 --stdout FETCH_HEAD,['deliverables/wallaby/mistral-lib.yaml'],1,f6015563dba80eddcca6b96a216bd4e62cff711a,w1-c-w-i,releases: - version: 2.4.0 projects: - repo: openstack/mistral-lib hash: 95724c5ad0d249e8774d12c306c89dba000e2d33,,5,0
openstack%2Freleases~master~I1ed118e982d7f4075b83377b2fd3d4945e013568,openstack/releases,master,I1ed118e982d7f4075b83377b2fd3d4945e013568,Release metalsmith for wallaby-1 milestone,MERGED,2020-11-30 13:16:15.000000000,2020-12-02 10:18:33.000000000,2020-12-02 10:18:33.000000000,"[{'_account_id': 10239}, {'_account_id': 11655}, {'_account_id': 11904}, {'_account_id': 14826}, {'_account_id': 22348}, {'_account_id': 28522}]","[{'number': 1, 'created': '2020-11-30 13:16:15.000000000', 'files': ['deliverables/wallaby/metalsmith.yaml'], 'web_link': 'https://opendev.org/openstack/releases/commit/2984ea25cf1519aebe37877650c7cee2c8b10f2a', 'message': 'Release metalsmith for wallaby-1 milestone\n\nThis is a library release for metalsmith for the wallaby-1\nmilestone. This repo includes commits that have not been releases for\nthis cycle yet.\n\nIf the team is ready to process with this release, please leave a +1\nto indicate we should go ahead with the release.\n\nIf the team needs more time for things about to merge, or if there is\nsome other reason a release should not be done at this time, please\nleave a -1 with a comment indicating the status. Then update the patch\nwith the new commit hash to use once the team is ready to do the\nrelease.\n\nChange-Id: I1ed118e982d7f4075b83377b2fd3d4945e013568\n'}]",0,764674,2984ea25cf1519aebe37877650c7cee2c8b10f2a,7,6,1,28522,,,0,"Release metalsmith for wallaby-1 milestone

This is a library release for metalsmith for the wallaby-1
milestone. This repo includes commits that have not been releases for
this cycle yet.

If the team is ready to process with this release, please leave a +1
to indicate we should go ahead with the release.

If the team needs more time for things about to merge, or if there is
some other reason a release should not be done at this time, please
leave a -1 with a comment indicating the status. Then update the patch
with the new commit hash to use once the team is ready to do the
release.

Change-Id: I1ed118e982d7f4075b83377b2fd3d4945e013568
",git fetch https://review.opendev.org/openstack/releases refs/changes/74/764674/1 && git format-patch -1 --stdout FETCH_HEAD,['deliverables/wallaby/metalsmith.yaml'],1,2984ea25cf1519aebe37877650c7cee2c8b10f2a,w1-c-w-i,releases: - version: 1.3.0 projects: - repo: openstack/metalsmith hash: 1c06881c3219cb5cdefd78e49d4327ef115d3ca4,,5,0
openstack%2Freleases~master~I10e2fac4fdef97e95d4d10a2da9bb0dd0ad483af,openstack/releases,master,I10e2fac4fdef97e95d4d10a2da9bb0dd0ad483af,Release keystonemiddleware for wallaby-1 milestone,MERGED,2020-11-30 13:15:26.000000000,2020-12-02 10:18:29.000000000,2020-12-02 10:18:29.000000000,"[{'_account_id': 11904}, {'_account_id': 16465}, {'_account_id': 22348}, {'_account_id': 28522}]","[{'number': 1, 'created': '2020-11-30 13:15:26.000000000', 'files': ['deliverables/wallaby/keystonemiddleware.yaml'], 'web_link': 'https://opendev.org/openstack/releases/commit/edf835d83ab5ee1b908807bf7d71e2f4c8978ba3', 'message': 'Release keystonemiddleware for wallaby-1 milestone\n\nThis is a library release for keystonemiddleware for the wallaby-1\nmilestone. This repo includes commits that have not been releases for\nthis cycle yet.\n\nIf the team is ready to process with this release, please leave a +1\nto indicate we should go ahead with the release.\n\nIf the team needs more time for things about to merge, or if there is\nsome other reason a release should not be done at this time, please\nleave a -1 with a comment indicating the status. Then update the patch\nwith the new commit hash to use once the team is ready to do the\nrelease.\n\nChange-Id: I10e2fac4fdef97e95d4d10a2da9bb0dd0ad483af\n'}]",0,764672,edf835d83ab5ee1b908807bf7d71e2f4c8978ba3,7,4,1,28522,,,0,"Release keystonemiddleware for wallaby-1 milestone

This is a library release for keystonemiddleware for the wallaby-1
milestone. This repo includes commits that have not been releases for
this cycle yet.

If the team is ready to process with this release, please leave a +1
to indicate we should go ahead with the release.

If the team needs more time for things about to merge, or if there is
some other reason a release should not be done at this time, please
leave a -1 with a comment indicating the status. Then update the patch
with the new commit hash to use once the team is ready to do the
release.

Change-Id: I10e2fac4fdef97e95d4d10a2da9bb0dd0ad483af
",git fetch https://review.opendev.org/openstack/releases refs/changes/72/764672/1 && git format-patch -1 --stdout FETCH_HEAD,['deliverables/wallaby/keystonemiddleware.yaml'],1,edf835d83ab5ee1b908807bf7d71e2f4c8978ba3,w1-c-w-i,releases: - version: 9.2.0 projects: - repo: openstack/keystonemiddleware hash: 3659bdad861c1648dc53a1f66c968e82b498eb9c,,5,0
openstack%2Ftripleo-heat-templates~master~I4b876386bc67baae982c2a15c0b6b32f3b04f434,openstack/tripleo-heat-templates,master,I4b876386bc67baae982c2a15c0b6b32f3b04f434,DNM WIP test new TCIB containers with ed25519,ABANDONED,2020-10-02 16:57:05.000000000,2020-12-02 09:46:40.000000000,,"[{'_account_id': 20778}, {'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2020-10-02 16:57:05.000000000', 'files': ['deployment/database/mysql-base.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/9485e6500858f28690c0bc995f86de63e83ee49d', 'message': 'DNM WIP test new TCIB containers with ed25519\n\nDepends-On: https://review.opendev.org/755848\nChange-Id: I4b876386bc67baae982c2a15c0b6b32f3b04f434\n'}]",0,755850,9485e6500858f28690c0bc995f86de63e83ee49d,6,3,1,20778,,,0,"DNM WIP test new TCIB containers with ed25519

Depends-On: https://review.opendev.org/755848
Change-Id: I4b876386bc67baae982c2a15c0b6b32f3b04f434
",git fetch https://review.opendev.org/openstack/tripleo-heat-templates refs/changes/50/755850/1 && git format-patch -1 --stdout FETCH_HEAD,['deployment/database/mysql-base.yaml'],1,9485e6500858f28690c0bc995f86de63e83ee49d,tht-ed25519-test, default: true, default: false,1,1
openstack%2Fironic~master~Ie09f4daced5ffd9d953b9add4d5484bbdd1ba1ac,openstack/ironic,master,Ie09f4daced5ffd9d953b9add4d5484bbdd1ba1ac,CI: add a non-voting bifrost-vmedia-uefi job,MERGED,2020-11-26 11:12:39.000000000,2020-12-02 09:06:33.000000000,2020-12-02 09:01:44.000000000,"[{'_account_id': 11076}, {'_account_id': 22348}, {'_account_id': 23851}]","[{'number': 1, 'created': '2020-11-26 11:12:39.000000000', 'files': ['zuul.d/project.yaml'], 'web_link': 'https://opendev.org/openstack/ironic/commit/9ea4142982a3c47331f7d2a62650208c5b871906', 'message': 'CI: add a non-voting bifrost-vmedia-uefi job\n\nIt provides useful coverage of e.g. fast-track with virtual media.\n\nChange-Id: Ie09f4daced5ffd9d953b9add4d5484bbdd1ba1ac\n'}]",0,764324,9ea4142982a3c47331f7d2a62650208c5b871906,8,3,1,10239,,,0,"CI: add a non-voting bifrost-vmedia-uefi job

It provides useful coverage of e.g. fast-track with virtual media.

Change-Id: Ie09f4daced5ffd9d953b9add4d5484bbdd1ba1ac
",git fetch https://review.opendev.org/openstack/ironic refs/changes/24/764324/1 && git format-patch -1 --stdout FETCH_HEAD,['zuul.d/project.yaml'],1,9ea4142982a3c47331f7d2a62650208c5b871906,ci, - bifrost-integration-redfish-vmedia-uefi-centos-8: voting: false,,2,0
openstack%2Ftempest~master~I4d8236f4b2222c6a07aaafc502c3b660d49d663c,openstack/tempest,master,I4d8236f4b2222c6a07aaafc502c3b660d49d663c,Allow kwargs in create_volume_type,MERGED,2020-10-18 17:38:09.000000000,2020-12-02 08:18:07.000000000,2020-12-02 08:16:07.000000000,"[{'_account_id': 8556}, {'_account_id': 20190}, {'_account_id': 22348}]","[{'number': 1, 'created': '2020-10-18 17:38:09.000000000', 'files': ['tempest/scenario/manager.py'], 'web_link': 'https://opendev.org/openstack/tempest/commit/8e673a408a95690d137ac85780f11cd8bffc215c', 'message': 'Allow kwargs in create_volume_type\n\nAs a part of the scenario/manager.py stabilization tracked by\nthe below BP the patch adds kwargs argument for create_volume_type\nmethod so that the consumers are able to pass additional parameters\nif needed.\n\nImplements: blueprint tempest-scenario-manager-stable\nChange-Id: I4d8236f4b2222c6a07aaafc502c3b660d49d663c\n'}]",0,758681,8e673a408a95690d137ac85780f11cd8bffc215c,28,3,1,22873,,,0,"Allow kwargs in create_volume_type

As a part of the scenario/manager.py stabilization tracked by
the below BP the patch adds kwargs argument for create_volume_type
method so that the consumers are able to pass additional parameters
if needed.

Implements: blueprint tempest-scenario-manager-stable
Change-Id: I4d8236f4b2222c6a07aaafc502c3b660d49d663c
",git fetch https://review.opendev.org/openstack/tempest refs/changes/81/758681/1 && git format-patch -1 --stdout FETCH_HEAD,['tempest/scenario/manager.py'],1,8e673a408a95690d137ac85780f11cd8bffc215c,bp/tempest-scenario-manager-stable," def create_volume_type(self, client=None, name=None, backend_name=None, **kwargs): extra_specs = kwargs.pop(""extra_specs"", {}) if backend_name: extra_specs.update({""volume_backend_name"": backend_name}) volume_type_resp = client.create_volume_type( name=randomized_name, extra_specs=extra_specs, **kwargs) volume_type = volume_type_resp['volume_type'] "," def create_volume_type(self, client=None, name=None, backend_name=None): extra_specs = {} if backend_name: extra_specs = {""volume_backend_name"": backend_name} volume_type = client.create_volume_type( name=randomized_name, extra_specs=extra_specs)['volume_type']",8,5
openstack%2Fansible-role-collect-logs~master~I2ea7fe9af8e3b21a3ef6a89dc8af687feacc8300,openstack/ansible-role-collect-logs,master,I2ea7fe9af8e3b21a3ef6a89dc8af687feacc8300,Collect cluster cib as well,MERGED,2020-11-29 11:08:07.000000000,2020-12-02 07:11:11.000000000,2020-12-02 07:11:11.000000000,"[{'_account_id': 14985}, {'_account_id': 20778}, {'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2020-11-29 11:08:07.000000000', 'files': ['defaults/main.yml'], 'web_link': 'https://opendev.org/openstack/ansible-role-collect-logs/commit/ec28d9545bb931610b1db2ab535d154637500218', 'message': ""Collect cluster cib as well\n\npcs config only outputs a partial state of the cluster.\nLet's collect the whole CIB as well which gives us the xml\nrepresenting both the cluster configration and the current\nstate it is in as well.\n\nChange-Id: I2ea7fe9af8e3b21a3ef6a89dc8af687feacc8300\n""}]",0,764587,ec28d9545bb931610b1db2ab535d154637500218,15,4,1,20172,,,0,"Collect cluster cib as well

pcs config only outputs a partial state of the cluster.
Let's collect the whole CIB as well which gives us the xml
representing both the cluster configration and the current
state it is in as well.

Change-Id: I2ea7fe9af8e3b21a3ef6a89dc8af687feacc8300
",git fetch https://review.opendev.org/openstack/ansible-role-collect-logs refs/changes/87/764587/1 && git format-patch -1 --stdout FETCH_HEAD,['defaults/main.yml'],1,ec28d9545bb931610b1db2ab535d154637500218,cluster-cib," echo ""+ pcs cluster cib"" pcs cluster cib",,2,0
openstack%2Fwatcher~master~I010d9d1e9ddb8790c398bcf06d0772a0d17f57ec,openstack/watcher,master,I010d9d1e9ddb8790c398bcf06d0772a0d17f57ec,Fix missing self argument in instances_no_attached,MERGED,2020-11-27 09:03:55.000000000,2020-12-02 06:49:55.000000000,2020-12-02 06:48:17.000000000,"[{'_account_id': 21692}, {'_account_id': 22348}]","[{'number': 1, 'created': '2020-11-27 09:03:55.000000000', 'files': ['watcher/decision_engine/strategy/strategies/zone_migration.py'], 'web_link': 'https://opendev.org/openstack/watcher/commit/204b276693134219bd84afe084e8ef0eff30bdb2', 'message': 'Fix missing self argument in instances_no_attached\n\ninstances_no_attached should have self as the first argument, this is\nto add it.\n\nChange-Id: I010d9d1e9ddb8790c398bcf06d0772a0d17f57ec\n'}]",0,764423,204b276693134219bd84afe084e8ef0eff30bdb2,8,2,1,20190,,,0,"Fix missing self argument in instances_no_attached

instances_no_attached should have self as the first argument, this is
to add it.

Change-Id: I010d9d1e9ddb8790c398bcf06d0772a0d17f57ec
",git fetch https://review.opendev.org/openstack/watcher refs/changes/23/764423/1 && git format-patch -1 --stdout FETCH_HEAD,['watcher/decision_engine/strategy/strategies/zone_migration.py'],1,204b276693134219bd84afe084e8ef0eff30bdb2,missing_self," def instances_no_attached(self, instances):", def instances_no_attached(instances):,1,1
openstack%2Foctavia~stable%2Fussuri~I293587fa6d1f7a06aae9d1cca5b81342478c5df2,openstack/octavia,stable/ussuri,I293587fa6d1f7a06aae9d1cca5b81342478c5df2,[Amphorav2] Healthmonitor operation minor fixes,MERGED,2020-09-24 08:30:29.000000000,2020-12-02 06:24:16.000000000,2020-12-02 06:22:31.000000000,"[{'_account_id': 6469}, {'_account_id': 11628}, {'_account_id': 22348}]","[{'number': 1, 'created': '2020-09-24 08:30:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/octavia/commit/16526601732a5b4d4f0581018f24e155dfff7f2a', 'message': '[Amphorav2] Healthmonitor operation minor fixes\n\n* Fix logging messages for healthmonitor operations\n* Add retry when healthmonitor is not in db yet\n* Fix setting ONLINE operating_status\n\nThis fix api test_healthmonitor_update test.\n\nChange-Id: I293587fa6d1f7a06aae9d1cca5b81342478c5df2\n(cherry picked from commit db180bf81869762f71423c4d99c50587d12f59bf)\n'}, {'number': 2, 'created': '2020-10-08 08:33:27.000000000', 'files': ['octavia/controller/worker/v2/tasks/database_tasks.py', 'octavia/controller/worker/v2/controller_worker.py', 'octavia/controller/queue/v2/endpoints.py'], 'web_link': 'https://opendev.org/openstack/octavia/commit/f9952c06086457f766033467668cbf4b12a96287', 'message': '[Amphorav2] Healthmonitor operation minor fixes\n\n* Fix logging messages for healthmonitor operations\n* Add retry when healthmonitor is not in db yet\n* Fix setting ONLINE operating_status\n\nThis fix api test_healthmonitor_update test.\n\nChange-Id: I293587fa6d1f7a06aae9d1cca5b81342478c5df2\n(cherry picked from commit db180bf81869762f71423c4d99c50587d12f59bf)\n'}]",0,753969,f9952c06086457f766033467668cbf4b12a96287,11,3,2,7249,,,0,"[Amphorav2] Healthmonitor operation minor fixes

* Fix logging messages for healthmonitor operations
* Add retry when healthmonitor is not in db yet
* Fix setting ONLINE operating_status

This fix api test_healthmonitor_update test.

Change-Id: I293587fa6d1f7a06aae9d1cca5b81342478c5df2
(cherry picked from commit db180bf81869762f71423c4d99c50587d12f59bf)
",git fetch https://review.opendev.org/openstack/octavia refs/changes/69/753969/2 && git format-patch -1 --stdout FETCH_HEAD,"['octavia/controller/worker/v2/tasks/database_tasks.py', 'octavia/controller/worker/v2/controller_worker.py', 'octavia/controller/queue/v2/endpoints.py']",3,16526601732a5b4d4f0581018f24e155dfff7f2a,, constants.HEALTHMONITOR_ID)) original_health_monitor.get(constants.HEALTHMONITOR_ID)) constants.HEALTHMONITOR_ID)), constants.ID)) original_health_monitor.get(constants.ID)) constants.ID)),12,4
openstack%2Fpython-freezerclient~master~Ib187a4d7d5ea92c1dbe5e4505b3646d5d050c53f,openstack/python-freezerclient,master,Ib187a4d7d5ea92c1dbe5e4505b3646d5d050c53f,Remove unsueful 'opts' param,MERGED,2020-12-02 03:53:48.000000000,2020-12-02 06:23:27.000000000,2020-12-02 06:21:40.000000000,"[{'_account_id': 21069}, {'_account_id': 22348}]","[{'number': 1, 'created': '2020-12-02 03:53:48.000000000', 'files': ['freezerclient/utils.py'], 'web_link': 'https://opendev.org/openstack/python-freezerclient/commit/397618e8515d87244ad2a466a9e87ca9a47deb88', 'message': ""Remove unsueful 'opts' param\n\nThe opts param is unuseful for get_client_instance() func.\n\nChange-Id: Ib187a4d7d5ea92c1dbe5e4505b3646d5d050c53f\nTask:41348\n""}]",0,765040,397618e8515d87244ad2a466a9e87ca9a47deb88,7,2,1,21069,,,0,"Remove unsueful 'opts' param

The opts param is unuseful for get_client_instance() func.

Change-Id: Ib187a4d7d5ea92c1dbe5e4505b3646d5d050c53f
Task:41348
",git fetch https://review.opendev.org/openstack/python-freezerclient refs/changes/40/765040/1 && git format-patch -1 --stdout FETCH_HEAD,['freezerclient/utils.py'],1,397618e8515d87244ad2a466a9e87ca9a47deb88,,"def get_client_instance(opts={}, api_version=None): return get_client_class(api_version)(**opts)","def get_client_instance(kwargs={}, opts=None, api_version=None): return get_client_class(api_version)(opts=opts, **kwargs)",2,2
openstack%2Foctavia~stable%2Fussuri~Ia9d9d844b325296401577f5617d2b89cf1a017a7,openstack/octavia,stable/ussuri,Ia9d9d844b325296401577f5617d2b89cf1a017a7,Add some details on enable_anti_affinity option,MERGED,2020-09-21 06:15:34.000000000,2020-12-02 06:22:45.000000000,2020-12-02 06:20:50.000000000,"[{'_account_id': 11628}, {'_account_id': 22348}, {'_account_id': 29244}]","[{'number': 1, 'created': '2020-09-21 06:15:34.000000000', 'files': ['octavia/common/config.py'], 'web_link': 'https://opendev.org/openstack/octavia/commit/6a1121420f8e60648dd2b6be37af38e8a725a1d9', 'message': 'Add some details on enable_anti_affinity option\n\nExplain that ""enable_anti_affinity"" affects only amphorae in\nACTIVE_STANDBY topology.\n\nChange-Id: Ia9d9d844b325296401577f5617d2b89cf1a017a7\n(cherry picked from commit 259f19ec152fe64777ea9bdb658929e22d59427b)\n'}]",0,752865,6a1121420f8e60648dd2b6be37af38e8a725a1d9,8,3,1,6469,,,0,"Add some details on enable_anti_affinity option

Explain that ""enable_anti_affinity"" affects only amphorae in
ACTIVE_STANDBY topology.

Change-Id: Ia9d9d844b325296401577f5617d2b89cf1a017a7
(cherry picked from commit 259f19ec152fe64777ea9bdb658929e22d59427b)
",git fetch https://review.opendev.org/openstack/octavia refs/changes/65/752865/1 && git format-patch -1 --stdout FETCH_HEAD,['octavia/common/config.py'],1,6a1121420f8e60648dd2b6be37af38e8a725a1d9,," 'turned on. This option is only used when creating ' 'amphorae in ACTIVE_STANDBY topology.')),"," 'turned on.')),",2,1
openstack%2Ftripleo-common~master~Idc49a3ad3f8d52b0709abfa6b4c7eb4103f04410,openstack/tripleo-common,master,Idc49a3ad3f8d52b0709abfa6b4c7eb4103f04410,Switch defaults to quay.io,MERGED,2020-11-19 15:48:16.000000000,2020-12-02 05:40:45.000000000,2020-12-02 05:38:35.000000000,"[{'_account_id': 6926}, {'_account_id': 7144}, {'_account_id': 9592}, {'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2020-11-19 15:48:16.000000000', 'files': ['container-images/container_image_prepare_defaults.yaml', 'container-images/tripleo_containers.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-common/commit/38392c009022dc76a5ea4413c4b25da3895bd9ff', 'message': 'Switch defaults to quay.io\n\nChange-Id: Idc49a3ad3f8d52b0709abfa6b4c7eb4103f04410\n'}]",0,763400,38392c009022dc76a5ea4413c4b25da3895bd9ff,10,5,1,14985,,,0,"Switch defaults to quay.io

Change-Id: Idc49a3ad3f8d52b0709abfa6b4c7eb4103f04410
",git fetch https://review.opendev.org/openstack/tripleo-common refs/changes/00/763400/1 && git format-patch -1 --stdout FETCH_HEAD,"['container-images/container_image_prepare_defaults.yaml', 'container-images/tripleo_containers.yaml']",2,38392c009022dc76a5ea4413c4b25da3895bd9ff,quay,- imagename: quay.io/tripleomaster/openstack-aodh-api:current-tripleo- imagename: quay.io/tripleomaster/openstack-aodh-evaluator:current-tripleo- imagename: quay.io/tripleomaster/openstack-aodh-listener:current-tripleo- imagename: quay.io/tripleomaster/openstack-aodh-notifier:current-tripleo- imagename: quay.io/tripleomaster/openstack-barbican-api:current-tripleo- imagename: quay.io/tripleomaster/openstack-barbican-keystone-listener:current-tripleo- imagename: quay.io/tripleomaster/openstack-barbican-worker:current-tripleo- imagename: quay.io/tripleomaster/openstack-ceilometer-central:current-tripleo- imagename: quay.io/tripleomaster/openstack-ceilometer-compute:current-tripleo- imagename: quay.io/tripleomaster/openstack-ceilometer-notification:current-tripleo- imagename: quay.io/tripleomaster/openstack-ceilometer-ipmi:current-tripleo- imagename: quay.io/tripleomaster/openstack-cinder-api:current-tripleo- imagename: quay.io/tripleomaster/openstack-cinder-backup:current-tripleo- imagename: quay.io/tripleomaster/openstack-cinder-scheduler:current-tripleo- imagename: quay.io/tripleomaster/openstack-cinder-volume:current-tripleo- imagename: quay.io/tripleomaster/openstack-collectd:current-tripleo- imagename: quay.io/tripleomaster/openstack-cron:current-tripleo- imagename: quay.io/tripleomaster/openstack-designate-api:current-tripleo- imagename: quay.io/tripleomaster/openstack-designate-backend-bind9:current-tripleo- imagename: quay.io/tripleomaster/openstack-designate-central:current-tripleo- imagename: quay.io/tripleomaster/openstack-designate-mdns:current-tripleo- imagename: quay.io/tripleomaster/openstack-designate-producer:current-tripleo- imagename: quay.io/tripleomaster/openstack-designate-sink:current-tripleo- imagename: quay.io/tripleomaster/openstack-designate-worker:current-tripleo- imagename: quay.io/tripleomaster/openstack-etcd:current-tripleo- imagename: quay.io/tripleomaster/openstack-glance-api:current-tripleo- imagename: quay.io/tripleomaster/openstack-gnocchi-api:current-tripleo- imagename: quay.io/tripleomaster/openstack-gnocchi-metricd:current-tripleo- imagename: quay.io/tripleomaster/openstack-gnocchi-statsd:current-tripleo- imagename: quay.io/tripleomaster/openstack-haproxy:current-tripleo- imagename: quay.io/tripleomaster/openstack-heat-all:current-tripleo- imagename: quay.io/tripleomaster/openstack-heat-api-cfn:current-tripleo- imagename: quay.io/tripleomaster/openstack-heat-api:current-tripleo- imagename: quay.io/tripleomaster/openstack-heat-engine:current-tripleo- imagename: quay.io/tripleomaster/openstack-horizon:current-tripleo- imagename: quay.io/tripleomaster/openstack-ironic-api:current-tripleo- imagename: quay.io/tripleomaster/openstack-ironic-conductor:current-tripleo- imagename: quay.io/tripleomaster/openstack-ironic-inspector:current-tripleo- imagename: quay.io/tripleomaster/openstack-ironic-pxe:current-tripleo- imagename: quay.io/tripleomaster/openstack-ironic-neutron-agent:current-tripleo- imagename: quay.io/tripleomaster/openstack-iscsid:current-tripleo- imagename: quay.io/tripleomaster/openstack-keepalived:current-tripleo- imagename: quay.io/tripleomaster/openstack-keystone:current-tripleo- imagename: quay.io/tripleomaster/openstack-manila-api:current-tripleo- imagename: quay.io/tripleomaster/openstack-manila-scheduler:current-tripleo- imagename: quay.io/tripleomaster/openstack-manila-share:current-tripleo- imagename: quay.io/tripleomaster/openstack-mariadb:current-tripleo- imagename: quay.io/tripleomaster/openstack-memcached:current-tripleo- imagename: quay.io/tripleomaster/openstack-mistral-api:current-tripleo- imagename: quay.io/tripleomaster/openstack-mistral-engine:current-tripleo- imagename: quay.io/tripleomaster/openstack-mistral-executor:current-tripleo- imagename: quay.io/tripleomaster/openstack-mistral-event-engine:current-tripleo- imagename: quay.io/tripleomaster/openstack-multipathd:current-tripleo- imagename: quay.io/tripleomaster/openstack-neutron-dhcp-agent:current-tripleo- imagename: quay.io/tripleomaster/openstack-neutron-l3-agent:current-tripleo- imagename: quay.io/tripleomaster/openstack-neutron-metadata-agent:current-tripleo- imagename: quay.io/tripleomaster/openstack-neutron-openvswitch-agent:current-tripleo- imagename: quay.io/tripleomaster/openstack-neutron-sriov-agent:current-tripleo- imagename: quay.io/tripleomaster/openstack-neutron-mlnx-agent:current-tripleo- imagename: quay.io/tripleomaster/openstack-neutron-server:current-tripleo- imagename: quay.io/tripleomaster/openstack-neutron-metadata-agent-ovn:current-tripleo- imagename: quay.io/tripleomaster/openstack-nova-api:current-tripleo- imagename: quay.io/tripleomaster/openstack-nova-compute-ironic:current-tripleo- imagename: quay.io/tripleomaster/openstack-nova-compute:current-tripleo- imagename: quay.io/tripleomaster/openstack-nova-conductor:current-tripleo- imagename: quay.io/tripleomaster/openstack-nova-libvirt:current-tripleo- imagename: quay.io/tripleomaster/openstack-nova-novncproxy:current-tripleo- imagename: quay.io/tripleomaster/openstack-nova-scheduler:current-tripleo- imagename: quay.io/tripleomaster/openstack-novajoin-notifier:current-tripleo- imagename: quay.io/tripleomaster/openstack-novajoin-server:current-tripleo- imagename: quay.io/tripleomaster/openstack-octavia-api:current-tripleo- imagename: quay.io/tripleomaster/openstack-octavia-health-manager:current-tripleo- imagename: quay.io/tripleomaster/openstack-octavia-housekeeping:current-tripleo- imagename: quay.io/tripleomaster/openstack-octavia-worker:current-tripleo- imagename: quay.io/tripleomaster/openstack-ovn-controller:current-tripleo- imagename: quay.io/tripleomaster/openstack-ovn-nb-db-server:current-tripleo- imagename: quay.io/tripleomaster/openstack-ovn-northd:current-tripleo- imagename: quay.io/tripleomaster/openstack-ovn-sb-db-server:current-tripleo- imagename: quay.io/tripleomaster/openstack-placement-api:current-tripleo- imagename: quay.io/tripleomaster/openstack-qdrouterd:current-tripleo- imagename: quay.io/tripleomaster/openstack-rabbitmq:current-tripleo- imagename: quay.io/tripleomaster/openstack-redis:current-tripleo- imagename: quay.io/tripleomaster/openstack-swift-account:current-tripleo- imagename: quay.io/tripleomaster/openstack-swift-container:current-tripleo- imagename: quay.io/tripleomaster/openstack-swift-object:current-tripleo- imagename: quay.io/tripleomaster/openstack-swift-proxy-server:current-tripleo- imagename: quay.io/tripleomaster/openstack-zaqar-wsgi:current-tripleo- imagename: quay.io/tripleomaster/openstack-tempest:current-tripleo- imagename: quay.io/tripleomaster/openstack-rsyslog:current-tripleo,- imagename: docker.io/tripleomaster/openstack-aodh-api:current-tripleo- imagename: docker.io/tripleomaster/openstack-aodh-evaluator:current-tripleo- imagename: docker.io/tripleomaster/openstack-aodh-listener:current-tripleo- imagename: docker.io/tripleomaster/openstack-aodh-notifier:current-tripleo- imagename: docker.io/tripleomaster/openstack-barbican-api:current-tripleo- imagename: docker.io/tripleomaster/openstack-barbican-keystone-listener:current-tripleo- imagename: docker.io/tripleomaster/openstack-barbican-worker:current-tripleo- imagename: docker.io/tripleomaster/openstack-ceilometer-central:current-tripleo- imagename: docker.io/tripleomaster/openstack-ceilometer-compute:current-tripleo- imagename: docker.io/tripleomaster/openstack-ceilometer-notification:current-tripleo- imagename: docker.io/tripleomaster/openstack-ceilometer-ipmi:current-tripleo- imagename: docker.io/tripleomaster/openstack-cinder-api:current-tripleo- imagename: docker.io/tripleomaster/openstack-cinder-backup:current-tripleo- imagename: docker.io/tripleomaster/openstack-cinder-scheduler:current-tripleo- imagename: docker.io/tripleomaster/openstack-cinder-volume:current-tripleo- imagename: docker.io/tripleomaster/openstack-collectd:current-tripleo- imagename: docker.io/tripleomaster/openstack-cron:current-tripleo- imagename: docker.io/tripleomaster/openstack-designate-api:current-tripleo- imagename: docker.io/tripleomaster/openstack-designate-backend-bind9:current-tripleo- imagename: docker.io/tripleomaster/openstack-designate-central:current-tripleo- imagename: docker.io/tripleomaster/openstack-designate-mdns:current-tripleo- imagename: docker.io/tripleomaster/openstack-designate-producer:current-tripleo- imagename: docker.io/tripleomaster/openstack-designate-sink:current-tripleo- imagename: docker.io/tripleomaster/openstack-designate-worker:current-tripleo- imagename: docker.io/tripleomaster/openstack-etcd:current-tripleo- imagename: docker.io/tripleomaster/openstack-glance-api:current-tripleo- imagename: docker.io/tripleomaster/openstack-gnocchi-api:current-tripleo- imagename: docker.io/tripleomaster/openstack-gnocchi-metricd:current-tripleo- imagename: docker.io/tripleomaster/openstack-gnocchi-statsd:current-tripleo- imagename: docker.io/tripleomaster/openstack-haproxy:current-tripleo- imagename: docker.io/tripleomaster/openstack-heat-all:current-tripleo- imagename: docker.io/tripleomaster/openstack-heat-api-cfn:current-tripleo- imagename: docker.io/tripleomaster/openstack-heat-api:current-tripleo- imagename: docker.io/tripleomaster/openstack-heat-engine:current-tripleo- imagename: docker.io/tripleomaster/openstack-horizon:current-tripleo- imagename: docker.io/tripleomaster/openstack-ironic-api:current-tripleo- imagename: docker.io/tripleomaster/openstack-ironic-conductor:current-tripleo- imagename: docker.io/tripleomaster/openstack-ironic-inspector:current-tripleo- imagename: docker.io/tripleomaster/openstack-ironic-pxe:current-tripleo- imagename: docker.io/tripleomaster/openstack-ironic-neutron-agent:current-tripleo- imagename: docker.io/tripleomaster/openstack-iscsid:current-tripleo- imagename: docker.io/tripleomaster/openstack-keepalived:current-tripleo- imagename: docker.io/tripleomaster/openstack-keystone:current-tripleo- imagename: docker.io/tripleomaster/openstack-manila-api:current-tripleo- imagename: docker.io/tripleomaster/openstack-manila-scheduler:current-tripleo- imagename: docker.io/tripleomaster/openstack-manila-share:current-tripleo- imagename: docker.io/tripleomaster/openstack-mariadb:current-tripleo- imagename: docker.io/tripleomaster/openstack-memcached:current-tripleo- imagename: docker.io/tripleomaster/openstack-mistral-api:current-tripleo- imagename: docker.io/tripleomaster/openstack-mistral-engine:current-tripleo- imagename: docker.io/tripleomaster/openstack-mistral-executor:current-tripleo- imagename: docker.io/tripleomaster/openstack-mistral-event-engine:current-tripleo- imagename: docker.io/tripleomaster/openstack-multipathd:current-tripleo- imagename: docker.io/tripleomaster/openstack-neutron-dhcp-agent:current-tripleo- imagename: docker.io/tripleomaster/openstack-neutron-l3-agent:current-tripleo- imagename: docker.io/tripleomaster/openstack-neutron-metadata-agent:current-tripleo- imagename: docker.io/tripleomaster/openstack-neutron-openvswitch-agent:current-tripleo- imagename: docker.io/tripleomaster/openstack-neutron-sriov-agent:current-tripleo- imagename: docker.io/tripleomaster/openstack-neutron-mlnx-agent:current-tripleo- imagename: docker.io/tripleomaster/openstack-neutron-server:current-tripleo- imagename: docker.io/tripleomaster/openstack-neutron-metadata-agent-ovn:current-tripleo- imagename: docker.io/tripleomaster/openstack-nova-api:current-tripleo- imagename: docker.io/tripleomaster/openstack-nova-compute-ironic:current-tripleo- imagename: docker.io/tripleomaster/openstack-nova-compute:current-tripleo- imagename: docker.io/tripleomaster/openstack-nova-conductor:current-tripleo- imagename: docker.io/tripleomaster/openstack-nova-libvirt:current-tripleo- imagename: docker.io/tripleomaster/openstack-nova-novncproxy:current-tripleo- imagename: docker.io/tripleomaster/openstack-nova-scheduler:current-tripleo- imagename: docker.io/tripleomaster/openstack-novajoin-notifier:current-tripleo- imagename: docker.io/tripleomaster/openstack-novajoin-server:current-tripleo- imagename: docker.io/tripleomaster/openstack-octavia-api:current-tripleo- imagename: docker.io/tripleomaster/openstack-octavia-health-manager:current-tripleo- imagename: docker.io/tripleomaster/openstack-octavia-housekeeping:current-tripleo- imagename: docker.io/tripleomaster/openstack-octavia-worker:current-tripleo- imagename: docker.io/tripleomaster/openstack-ovn-controller:current-tripleo- imagename: docker.io/tripleomaster/openstack-ovn-nb-db-server:current-tripleo- imagename: docker.io/tripleomaster/openstack-ovn-northd:current-tripleo- imagename: docker.io/tripleomaster/openstack-ovn-sb-db-server:current-tripleo- imagename: docker.io/tripleomaster/openstack-placement-api:current-tripleo- imagename: docker.io/tripleomaster/openstack-qdrouterd:current-tripleo- imagename: docker.io/tripleomaster/openstack-rabbitmq:current-tripleo- imagename: docker.io/tripleomaster/openstack-redis:current-tripleo- imagename: docker.io/tripleomaster/openstack-swift-account:current-tripleo- imagename: docker.io/tripleomaster/openstack-swift-container:current-tripleo- imagename: docker.io/tripleomaster/openstack-swift-object:current-tripleo- imagename: docker.io/tripleomaster/openstack-swift-proxy-server:current-tripleo- imagename: docker.io/tripleomaster/openstack-zaqar-wsgi:current-tripleo- imagename: docker.io/tripleomaster/openstack-tempest:current-tripleo- imagename: docker.io/tripleomaster/openstack-rsyslog:current-tripleo,90,90
openstack%2Fos-net-config~stable%2Fvictoria~I7e79029602f403885b347289d2ae6a3d47453a4e,openstack/os-net-config,stable/victoria,I7e79029602f403885b347289d2ae6a3d47453a4e,Support binding VFs after moving to switchdev,MERGED,2020-11-29 09:16:01.000000000,2020-12-02 05:40:41.000000000,2020-12-02 05:38:29.000000000,"[{'_account_id': 14985}, {'_account_id': 22348}]","[{'number': 1, 'created': '2020-11-29 09:16:01.000000000', 'files': ['os_net_config/sriov_bind_config.py', 'os_net_config/tests/test_sriov_bind_config.py', 'setup.cfg', 'os_net_config/sriov_config.py'], 'web_link': 'https://opendev.org/openstack/os-net-config/commit/157df251cf9086cbc58315808ec2f59605626f81', 'message': ""Support binding VFs after moving to switchdev\n\nCurrently for Mellanox vendor ID we don't bind vfs after moving to switchdev\nbecause it affects VF-lAG feature, but for other features like OVS-DPDK SRIOV,\nOVS-DPDK VDPA and OVS-Kernel Forwarder we have to bind them.\n\nTo support binding VFs to networking driver, there are two scenarios\nthat we need to address:\n    * Deployment case\n      In deployment case, we are binding vfs after moving all the\n      sriov_pfs to switchdev and also configuring sriov_bind service\n    * Reboot case\n      In reboot case, we start sriov_bind service which will run\n      after network.service sriov_config.service (The case that we are\n      sure that VF-LAG activation done)\n\nChange-Id: I7e79029602f403885b347289d2ae6a3d47453a4e\n(cherry picked from commit 3144a8fc4fae95e3cfdc680ccdcbd5144a9a17a8)\n""}]",0,764502,157df251cf9086cbc58315808ec2f59605626f81,11,2,1,25241,,,0,"Support binding VFs after moving to switchdev

Currently for Mellanox vendor ID we don't bind vfs after moving to switchdev
because it affects VF-lAG feature, but for other features like OVS-DPDK SRIOV,
OVS-DPDK VDPA and OVS-Kernel Forwarder we have to bind them.

To support binding VFs to networking driver, there are two scenarios
that we need to address:
    * Deployment case
      In deployment case, we are binding vfs after moving all the
      sriov_pfs to switchdev and also configuring sriov_bind service
    * Reboot case
      In reboot case, we start sriov_bind service which will run
      after network.service sriov_config.service (The case that we are
      sure that VF-LAG activation done)

Change-Id: I7e79029602f403885b347289d2ae6a3d47453a4e
(cherry picked from commit 3144a8fc4fae95e3cfdc680ccdcbd5144a9a17a8)
",git fetch https://review.opendev.org/openstack/os-net-config refs/changes/02/764502/1 && git format-patch -1 --stdout FETCH_HEAD,"['os_net_config/sriov_bind_config.py', 'os_net_config/tests/test_sriov_bind_config.py', 'setup.cfg', 'os_net_config/sriov_config.py']",4,157df251cf9086cbc58315808ec2f59605626f81,,"from os_net_config import sriov_bind_config_MLNX_DRIVER = ""mlx5_core"" MLNX_VENDOR_ID = ""0x15b3"" mlnx_vfs_pcis_list = [] mlnx_vfs_pcis_list += vf_pcis_list if mlnx_vfs_pcis_list: sriov_bind_pcis_map = {_MLNX_DRIVER: mlnx_vfs_pcis_list} if not execution_from_cli: sriov_bind_config.update_sriov_bind_pcis_map(sriov_bind_pcis_map) else: sriov_bind_config.configure_sriov_bind_service() sriov_bind_config.bind_vfs(sriov_bind_pcis_map) "," MLNX_VENDOR_ID = ""0x15b3""",204,1
openstack%2Fos-net-config~stable%2Fussuri~I7e79029602f403885b347289d2ae6a3d47453a4e,openstack/os-net-config,stable/ussuri,I7e79029602f403885b347289d2ae6a3d47453a4e,Support binding VFs after moving to switchdev,MERGED,2020-11-29 09:15:20.000000000,2020-12-02 05:40:20.000000000,2020-12-02 05:38:32.000000000,"[{'_account_id': 14985}, {'_account_id': 22348}]","[{'number': 1, 'created': '2020-11-29 09:15:20.000000000', 'files': ['os_net_config/sriov_bind_config.py', 'os_net_config/tests/test_sriov_bind_config.py', 'setup.cfg', 'os_net_config/sriov_config.py'], 'web_link': 'https://opendev.org/openstack/os-net-config/commit/c3a0744706cf08f29a87e4fc836c48f22fe4dcea', 'message': ""Support binding VFs after moving to switchdev\n\nCurrently for Mellanox vendor ID we don't bind vfs after moving to switchdev\nbecause it affects VF-lAG feature, but for other features like OVS-DPDK SRIOV,\nOVS-DPDK VDPA and OVS-Kernel Forwarder we have to bind them.\n\nTo support binding VFs to networking driver, there are two scenarios\nthat we need to address:\n    * Deployment case\n      In deployment case, we are binding vfs after moving all the\n      sriov_pfs to switchdev and also configuring sriov_bind service\n    * Reboot case\n      In reboot case, we start sriov_bind service which will run\n      after network.service sriov_config.service (The case that we are\n      sure that VF-LAG activation done)\n\nChange-Id: I7e79029602f403885b347289d2ae6a3d47453a4e\n(cherry picked from commit 3144a8fc4fae95e3cfdc680ccdcbd5144a9a17a8)\n""}]",0,764501,c3a0744706cf08f29a87e4fc836c48f22fe4dcea,11,2,1,25241,,,0,"Support binding VFs after moving to switchdev

Currently for Mellanox vendor ID we don't bind vfs after moving to switchdev
because it affects VF-lAG feature, but for other features like OVS-DPDK SRIOV,
OVS-DPDK VDPA and OVS-Kernel Forwarder we have to bind them.

To support binding VFs to networking driver, there are two scenarios
that we need to address:
    * Deployment case
      In deployment case, we are binding vfs after moving all the
      sriov_pfs to switchdev and also configuring sriov_bind service
    * Reboot case
      In reboot case, we start sriov_bind service which will run
      after network.service sriov_config.service (The case that we are
      sure that VF-LAG activation done)

Change-Id: I7e79029602f403885b347289d2ae6a3d47453a4e
(cherry picked from commit 3144a8fc4fae95e3cfdc680ccdcbd5144a9a17a8)
",git fetch https://review.opendev.org/openstack/os-net-config refs/changes/01/764501/1 && git format-patch -1 --stdout FETCH_HEAD,"['os_net_config/sriov_bind_config.py', 'os_net_config/tests/test_sriov_bind_config.py', 'setup.cfg', 'os_net_config/sriov_config.py']",4,c3a0744706cf08f29a87e4fc836c48f22fe4dcea,,"from os_net_config import sriov_bind_config_MLNX_DRIVER = ""mlx5_core"" MLNX_VENDOR_ID = ""0x15b3"" mlnx_vfs_pcis_list = [] mlnx_vfs_pcis_list += vf_pcis_list if mlnx_vfs_pcis_list: sriov_bind_pcis_map = {_MLNX_DRIVER: mlnx_vfs_pcis_list} if not execution_from_cli: sriov_bind_config.update_sriov_bind_pcis_map(sriov_bind_pcis_map) else: sriov_bind_config.configure_sriov_bind_service() sriov_bind_config.bind_vfs(sriov_bind_pcis_map) "," MLNX_VENDOR_ID = ""0x15b3""",204,1
openstack%2Ftripleo-validations~stable%2Ftrain~Ia194cebaeb7dcc40b4011e50cdde7648b4bf87b1,openstack/tripleo-validations,stable/train,Ia194cebaeb7dcc40b4011e50cdde7648b4bf87b1,Fix conditionals/types in check_flavors and verify_profiles,MERGED,2020-11-26 12:19:39.000000000,2020-12-02 05:40:05.000000000,2020-12-02 05:38:16.000000000,"[{'_account_id': 11491}, {'_account_id': 22348}]","[{'number': 1, 'created': '2020-11-26 12:19:39.000000000', 'files': ['releasenotes/notes/consider_existing_resources-addc5b2527d9db1b.yaml', 'library/verify_profiles.py', 'library/check_flavors.py'], 'web_link': 'https://opendev.org/openstack/tripleo-validations/commit/658cc5ca1589f3284595257a8135ebbb308e9cfd', 'message': 'Fix conditionals/types in check_flavors and verify_profiles\n\nExisting resources ""DISK_GB"", ""MEMORY_MB"", ""VCPU"" were not considered to\nbe available in case of custom_resource_class_val == False, also use correct\ntypes for resource comparison and required_count calculation.\n\nChange-Id: Ia194cebaeb7dcc40b4011e50cdde7648b4bf87b1\nCloses-Bug: #1905018\n(cherry picked from commit 3221727a8d56d9edb8f6b3dd4cdfb0094b49f757)\n(cherry picked from commit 484557f023948b3363b7c5d78d6a457810e8f64d)\n'}]",0,764299,658cc5ca1589f3284595257a8135ebbb308e9cfd,27,2,1,17216,,,0,"Fix conditionals/types in check_flavors and verify_profiles

Existing resources ""DISK_GB"", ""MEMORY_MB"", ""VCPU"" were not considered to
be available in case of custom_resource_class_val == False, also use correct
types for resource comparison and required_count calculation.

Change-Id: Ia194cebaeb7dcc40b4011e50cdde7648b4bf87b1
Closes-Bug: #1905018
(cherry picked from commit 3221727a8d56d9edb8f6b3dd4cdfb0094b49f757)
(cherry picked from commit 484557f023948b3363b7c5d78d6a457810e8f64d)
",git fetch https://review.opendev.org/openstack/tripleo-validations refs/changes/99/764299/1 && git format-patch -1 --stdout FETCH_HEAD,"['releasenotes/notes/consider_existing_resources-addc5b2527d9db1b.yaml', 'library/verify_profiles.py', 'library/check_flavors.py']",3,658cc5ca1589f3284595257a8135ebbb308e9cfd,1893896-stable/ussuri-stable/train," if key not in [""DISK_GB"", ""MEMORY_MB"", ""VCPU""] and \ not custom_resource_class_val: if any(int(resource) != 0 for resource in [disk, memory, vcpu]):"," if not custom_resource_class_val: if any(int(resource) != 0 for resource in [disk, memory, vcpu]):",11,4
openstack%2Fpuppet-tripleo~stable%2Fussuri~I4827a262460fdc33452f124fb90476dc9b20f6d2,openstack/puppet-tripleo,stable/ussuri,I4827a262460fdc33452f124fb90476dc9b20f6d2,"Revert ""Cleanup old workaround for ipv6 VIPs""",MERGED,2020-11-30 19:54:18.000000000,2020-12-02 05:38:39.000000000,2020-12-02 05:38:39.000000000,"[{'_account_id': 9592}, {'_account_id': 20172}, {'_account_id': 20778}, {'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2020-11-30 19:54:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-tripleo/commit/5d3edf05298d707c027ed3c1fdd96d29d2479f53', 'message': 'Revert ""Cleanup old workaround for ipv6 VIPs""\n\nThis reverts commit 201c12bdea4836f39de49b28ac1dcc829bbda31f.\n\nReason for revert:\nresource-agent ipv6 is still not working correctly https://bugzilla.redhat.com/show_bug.cgi?id=1902851\n\nChange-Id: I4827a262460fdc33452f124fb90476dc9b20f6d2\n'}, {'number': 2, 'created': '2020-12-01 13:32:11.000000000', 'files': ['manifests/pacemaker/haproxy_with_vip.pp'], 'web_link': 'https://opendev.org/openstack/puppet-tripleo/commit/54aa86dd1d07d181cec738ba5e7fbbf616c015b7', 'message': 'Revert ""Cleanup old workaround for ipv6 VIPs""\n\nThis reverts commit 201c12bdea4836f39de49b28ac1dcc829bbda31f.\n\nReason for revert:\nresource-agent ipv6 is still not working correctly https://bugzilla.redhat.com/show_bug.cgi?id=1902851\n\nChange-Id: I4827a262460fdc33452f124fb90476dc9b20f6d2\n'}]",0,764843,54aa86dd1d07d181cec738ba5e7fbbf616c015b7,15,5,2,20172,,,0,"Revert ""Cleanup old workaround for ipv6 VIPs""

This reverts commit 201c12bdea4836f39de49b28ac1dcc829bbda31f.

Reason for revert:
resource-agent ipv6 is still not working correctly https://bugzilla.redhat.com/show_bug.cgi?id=1902851

Change-Id: I4827a262460fdc33452f124fb90476dc9b20f6d2
",git fetch https://review.opendev.org/openstack/puppet-tripleo refs/changes/43/764843/1 && git format-patch -1 --stdout FETCH_HEAD,['manifests/pacemaker/haproxy_with_vip.pp'],1,5d3edf05298d707c027ed3c1fdd96d29d2479f53,bgpsupport-stable/victoria-stable/ussuri," # NB: Until the IPaddr2 RA has a fix for https://bugzilla.redhat.com/show_bug.cgi?id=1445628 # we need to specify the nic when creating the ipv6 vip. $nic = interface_for_ip($ip_address) $nic = '' nic => $nic,",,5,0
openstack%2Ftripleo-quickstart-extras~master~Id3a4469fe251ccac4763d977b962f48777a554c2,openstack/tripleo-quickstart-extras,master,Id3a4469fe251ccac4763d977b962f48777a554c2,Create single playbook for ovb deploy,MERGED,2020-10-15 17:00:20.000000000,2020-12-02 05:38:07.000000000,2020-12-02 05:38:07.000000000,"[{'_account_id': 7353}, {'_account_id': 8449}, {'_account_id': 9592}, {'_account_id': 9976}, {'_account_id': 13861}, {'_account_id': 18846}, {'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2020-10-15 17:00:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-quickstart-extras/commit/c5574e48c80ccd30918ebd72079cca5c1e41f691', 'message': '[wip]Fix ovb timeout\n\nOvb job sometime is timing out on below task:-\n~~~\nTASK [tripleo-inventory : Ensure gather_facts has been run against localhost]\n~~~\n\nWith this patch we try to use single playbook ovb.yml\nwhich includes other playbook, it results in single ansible\nplaybook run instead of multiple to avoid the issue of timeout.\n\nChange-Id: Id3a4469fe251ccac4763d977b962f48777a554c2\n'}, {'number': 2, 'created': '2020-11-29 13:44:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-quickstart-extras/commit/7dbf271e8a7e637a9cfc703ec9db7289991e360b', 'message': 'Create single playbook for ovb deploy\n\nOvb jobs are showing sporadic timeouts:-\n~~~\nTASK [tripleo-inventory : Ensure gather_facts has been run against localhost]\n~~~\n\nWith this patch we are creating a single playbook ovb.yml\nwhich includes other playbook used to deploy ovb, it results in single \nansible playbook run instead of multiple to avoid the issue of timeout.\n\nRelated-Bug: #1883843\nChange-Id: Id3a4469fe251ccac4763d977b962f48777a554c2\n'}, {'number': 3, 'created': '2020-11-29 13:44:18.000000000', 'files': ['playbooks/ovb.yml'], 'web_link': 'https://opendev.org/openstack/tripleo-quickstart-extras/commit/2c5d8abd97797e7402e474df6f67dfcce82fb317', 'message': 'Create single playbook for ovb deploy\n\nOvb jobs are showing sporadic timeouts:-\n~~~\nTASK [tripleo-inventory : Ensure gather_facts has been run against localhost]\n~~~\n\nWith this patch we are creating a single playbook ovb.yml\nwhich includes other playbook used to deploy ovb, it results in single \nansible playbook run instead of multiple to avoid the issue of timeout.\n\nRelated-Bug: #1883843\nChange-Id: Id3a4469fe251ccac4763d977b962f48777a554c2\n'}]",2,758468,2c5d8abd97797e7402e474df6f67dfcce82fb317,21,8,3,29775,,,0,"Create single playbook for ovb deploy

Ovb jobs are showing sporadic timeouts:-
~~~
TASK [tripleo-inventory : Ensure gather_facts has been run against localhost]
~~~

With this patch we are creating a single playbook ovb.yml
which includes other playbook used to deploy ovb, it results in single 
ansible playbook run instead of multiple to avoid the issue of timeout.

Related-Bug: #1883843
Change-Id: Id3a4469fe251ccac4763d977b962f48777a554c2
",git fetch https://review.opendev.org/openstack/tripleo-quickstart-extras refs/changes/68/758468/1 && git format-patch -1 --stdout FETCH_HEAD,"['playbooks/ovb.yml', 'zuul.d/layout.yaml']",2,c5574e48c80ccd30918ebd72079cca5c1e41f691,fix_ovb_timeout,, templates: - tripleo-undercloud-jobs-pipeline - tripleo-multinode-container-full-pipeline - tripleo-multinode-branchful - release-notes-jobs-python3 - tripleo-standalone-scenarios-pipeline - tripleo-standalone-multinode-ipa-pipeline - tripleo-ci-centos-8-content-provider - openstack-tox-molecule: required-projects: - openstack/tripleo-quickstart - tripleo-ci-centos-8-containers-undercloud-minion: vars: &undercloud_consumer_vars consumer_job: true tags: - undercloud-setup - undercloud-scripts - undercloud-install - undercloud-validate dependencies: &deps - tripleo-ci-centos-8-content-provider files: - ^roles/.*minion.*$ - ^playbooks/.*minion.*$ - tripleo-ci-centos-8-standalone-on-multinode-ipa: vars: &ipa_consumer_vars consumer_job: true build_container_images: false tags: - standalone dependencies: *deps files: - ^roles/ipa-multinode.*$ - ^roles/standalone.*$ - ^playbooks/multinode-standalone-ipa.yml.*$,6,35
openstack%2Frequirements~master~I165058a2ffe2e5236a7ed9af71ab879042ea7aff,openstack/requirements,master,I165058a2ffe2e5236a7ed9af71ab879042ea7aff,update constraint for python-magnumclient to new release 3.3.0,MERGED,2020-12-01 17:56:24.000000000,2020-12-02 05:00:42.000000000,2020-12-02 04:59:23.000000000,"[{'_account_id': 11904}, {'_account_id': 22348}, {'_account_id': 28522}]","[{'number': 1, 'created': '2020-12-01 17:56:24.000000000', 'files': ['upper-constraints.txt'], 'web_link': 'https://opendev.org/openstack/requirements/commit/6aff26adba9eb15322aefaffed9d5c63212c1c97', 'message': 'update constraint for python-magnumclient to new release 3.3.0\n\nmeta: version: 3.3.0\nmeta: diff-start: -\nmeta: series: wallaby\nmeta: release-type: release\nmeta: pypi: yes\nmeta: first: yes\nmeta: release:Author: Herv Beraud <hberaud@redhat.com>\nmeta: release:Commit: Herv Beraud <hberaud@redhat.com>\nmeta: release:Change-Id: I03eaef53b8ee0c3178577f2c4447b946ed270715\nmeta: release:Code-Review+1: Spyros Trigazis <strigazi@gmail.com>\nmeta: release:Code-Review+2: Sean McGinnis <sean.mcginnis@gmail.com>\nmeta: release:Code-Review+2: Herv Beraud <hberaud@redhat.com>\nmeta: release:Workflow+1: Herv Beraud <hberaud@redhat.com>\nChange-Id: I165058a2ffe2e5236a7ed9af71ab879042ea7aff\n'}]",0,764990,6aff26adba9eb15322aefaffed9d5c63212c1c97,9,3,1,11131,,,0,"update constraint for python-magnumclient to new release 3.3.0

meta: version: 3.3.0
meta: diff-start: -
meta: series: wallaby
meta: release-type: release
meta: pypi: yes
meta: first: yes
meta: release:Author: Herv Beraud <hberaud@redhat.com>
meta: release:Commit: Herv Beraud <hberaud@redhat.com>
meta: release:Change-Id: I03eaef53b8ee0c3178577f2c4447b946ed270715
meta: release:Code-Review+1: Spyros Trigazis <strigazi@gmail.com>
meta: release:Code-Review+2: Sean McGinnis <sean.mcginnis@gmail.com>
meta: release:Code-Review+2: Herv Beraud <hberaud@redhat.com>
meta: release:Workflow+1: Herv Beraud <hberaud@redhat.com>
Change-Id: I165058a2ffe2e5236a7ed9af71ab879042ea7aff
",git fetch https://review.opendev.org/openstack/requirements refs/changes/90/764990/1 && git format-patch -1 --stdout FETCH_HEAD,['upper-constraints.txt'],1,6aff26adba9eb15322aefaffed9d5c63212c1c97,new-release,python-magnumclient===3.3.0,python-magnumclient===3.2.1,1,1
openstack%2Fpython-openstackclient~master~Ia01ff9b21a2dac5d0ccf2bd58a8640e88c5cbb36,openstack/python-openstackclient,master,Ia01ff9b21a2dac5d0ccf2bd58a8640e88c5cbb36,stop image downloads to memory,MERGED,2020-11-19 07:11:40.000000000,2020-12-02 04:47:20.000000000,2020-12-02 04:45:15.000000000,"[{'_account_id': 2537}, {'_account_id': 5314}, {'_account_id': 6484}, {'_account_id': 9303}, {'_account_id': 11904}, {'_account_id': 13252}, {'_account_id': 15334}, {'_account_id': 22348}, {'_account_id': 30447}]","[{'number': 1, 'created': '2020-11-19 07:11:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-openstackclient/commit/597ea5c82ed0c68b2ea7a995e59a5aff0a9439cc', 'message': 'stop image downloads to memory\n\n + Fixes issue with large images hogging memory\n + stream image downloads\n + output to stdout if file not specified\n\nChange-Id: Ia01ff9b21a2dac5d0ccf2bd58a8640e88c5cbb36\nStory: 2007672\n'}, {'number': 2, 'created': '2020-11-19 07:58:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-openstackclient/commit/e65b708cb70d8699c34b4e68695978074ccedd6a', 'message': 'stop image downloads to memory\n\n + Fixes issue with large images hogging memory\n + stream image downloads\n + output to stdout if file not specified\n\nChange-Id: Ia01ff9b21a2dac5d0ccf2bd58a8640e88c5cbb36\nStory: 2007672\n'}, {'number': 3, 'created': '2020-11-25 08:25:56.000000000', 'files': ['openstackclient/tests/unit/image/v2/test_image.py', 'openstackclient/image/v1/image.py', 'openstackclient/image/v2/image.py', 'releasenotes/notes/fix-openstak-image-save-sdk-port-eb160e8ffc92e514.yaml'], 'web_link': 'https://opendev.org/openstack/python-openstackclient/commit/5bdcd590ecacbc0aa8db2cbafa0ab1a9f3c28ce0', 'message': 'stop image downloads to memory\n\n + Fixes issue with large images hogging memory\n + stream image downloads\n + output to stdout if file not specified\n\nChange-Id: Ia01ff9b21a2dac5d0ccf2bd58a8640e88c5cbb36\nStory: 2007672\nTask: 39776\n'}]",7,763317,5bdcd590ecacbc0aa8db2cbafa0ab1a9f3c28ce0,23,9,3,30447,,,0,"stop image downloads to memory

 + Fixes issue with large images hogging memory
 + stream image downloads
 + output to stdout if file not specified

Change-Id: Ia01ff9b21a2dac5d0ccf2bd58a8640e88c5cbb36
Story: 2007672
Task: 39776
",git fetch https://review.opendev.org/openstack/python-openstackclient refs/changes/17/763317/3 && git format-patch -1 --stdout FETCH_HEAD,"['openstackclient/tests/unit/image/v2/test_image.py', 'openstackclient/image/v1/image.py', 'openstackclient/image/v2/image.py']",3,597ea5c82ed0c68b2ea7a995e59a5aff0a9439cc,fix/stream-image-save," output_file = parsed_args.file if output_file is None: output_file = getattr(sys.stdout, ""buffer"", sys.stdout) image_client.download_image(image.id, stream=True, output=output_file)"," image_client.download_image(image.id, output=parsed_args.file)",12,3
openstack%2Fneutron~stable%2Fvictoria~Ib0d3a501f88c149baea7d715c7cfe5811bc85e4f,openstack/neutron,stable/victoria,Ib0d3a501f88c149baea7d715c7cfe5811bc85e4f,Fix migration from the HA to non-HA routers,MERGED,2020-11-19 10:52:56.000000000,2020-12-02 04:47:06.000000000,2020-12-02 04:45:08.000000000,"[{'_account_id': 1131}, {'_account_id': 5948}, {'_account_id': 8313}, {'_account_id': 21798}, {'_account_id': 22348}, {'_account_id': 26622}]","[{'number': 1, 'created': '2020-11-19 10:52:56.000000000', 'files': ['neutron/agent/l3/agent.py', 'neutron/tests/unit/agent/l3/test_agent.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/311071f567cc33d9868ba317536da18b7071d14e', 'message': ""Fix migration from the HA to non-HA routers\n\nIn case if during switching HA router to be down, there will be any\nfailure, router_info will be stored in L3 agent's cache as HaRouter.\nIn case when next update on the router is migration to non-HA router\nthis is wrong class and it causes other issues, e.g. with\nremove_vip_by_ip_address() which is correct only for HA routers.\n\nThis patch fixes that issue by adding check of the router's ha and\ndistributed flags and update local cache with new router_info class\nin case if at least one of those flags don't match.\n\nChange-Id: Ib0d3a501f88c149baea7d715c7cfe5811bc85e4f\nCloses-Bug: #1892846\n(cherry picked from commit 489e0ead7297e3b17ca2bf8c4bea9701ad14a939)\n""}]",0,763344,311071f567cc33d9868ba317536da18b7071d14e,20,6,1,11975,,,0,"Fix migration from the HA to non-HA routers

In case if during switching HA router to be down, there will be any
failure, router_info will be stored in L3 agent's cache as HaRouter.
In case when next update on the router is migration to non-HA router
this is wrong class and it causes other issues, e.g. with
remove_vip_by_ip_address() which is correct only for HA routers.

This patch fixes that issue by adding check of the router's ha and
distributed flags and update local cache with new router_info class
in case if at least one of those flags don't match.

Change-Id: Ib0d3a501f88c149baea7d715c7cfe5811bc85e4f
Closes-Bug: #1892846
(cherry picked from commit 489e0ead7297e3b17ca2bf8c4bea9701ad14a939)
",git fetch https://review.opendev.org/openstack/neutron refs/changes/44/763344/1 && git format-patch -1 --stdout FETCH_HEAD,"['neutron/agent/l3/agent.py', 'neutron/tests/unit/agent/l3/test_agent.py']",2,311071f567cc33d9868ba317536da18b7071d14e,bug/1892846-stable/victoria," def mock_get(name): if name == 'ha': return router.ha if name == 'distributed': return router.distributed return mock.Mock() router_info.router.get.side_effect = mock_get def mock_get(name): if name == 'ha': return router.ha if name == 'distributed': return router.distributed return mock.Mock() router_info.router.get.side_effect = mock_get def test_process_router_if_compatible_type_match(self): agent = l3_agent.L3NATAgent(HOSTNAME, self.conf) router = {'id': _uuid(), 'routes': [], 'admin_state_up': True, 'ha': False, 'distributed': False, 'external_gateway_info': {'network_id': 'aaa'}} ri = mock.Mock(router=router) agent.router_info[router['id']] = ri with mock.patch.object(agent, ""_create_router"") as create_router_mock: agent._process_router_if_compatible(router) create_router_mock.assert_not_called() self.assertIn(router['id'], agent.router_info) self.assertFalse(agent.router_info[router['id']].router['ha']) self.assertFalse(agent.router_info[router['id']].router['distributed']) def test_process_router_if_compatible_type_changed(self): agent = l3_agent.L3NATAgent(HOSTNAME, self.conf) router = {'id': _uuid(), 'routes': [], 'admin_state_up': True, 'revision_number': 1, 'ha': True, 'distributed': False, 'external_gateway_info': {'network_id': 'aaa'}} ri = mock.Mock(router=router) agent.router_info[router['id']] = ri new_router = copy.deepcopy(router) new_router['ha'] = False with mock.patch.object(agent, ""_create_router"") as create_router_mock: agent._process_router_if_compatible(new_router) create_router_mock.assert_called_once_with( new_router['id'], new_router) self.assertIn(router['id'], agent.router_info) self.assertFalse(agent.router_info[router['id']].router['ha']) self.assertFalse(agent.router_info[router['id']].router['distributed']) ",,77,0
openstack%2Frequirements~master~I3d33dea0b56f840175a996428ae962e73db858b8,openstack/requirements,master,I3d33dea0b56f840175a996428ae962e73db858b8,update constraint for python-freezerclient to new release 4.1.0,MERGED,2020-12-01 17:59:10.000000000,2020-12-02 04:46:53.000000000,2020-12-02 04:45:32.000000000,"[{'_account_id': 11904}, {'_account_id': 22348}, {'_account_id': 28522}]","[{'number': 1, 'created': '2020-12-01 17:59:10.000000000', 'files': ['upper-constraints.txt'], 'web_link': 'https://opendev.org/openstack/requirements/commit/ea580b11e9cefb0723f18701cae4f1247aa42b5e', 'message': 'update constraint for python-freezerclient to new release 4.1.0\n\nmeta: version: 4.1.0\nmeta: diff-start: -\nmeta: series: wallaby\nmeta: release-type: release\nmeta: pypi: yes\nmeta: first: yes\nmeta: release:Author: Herv Beraud <hberaud@redhat.com>\nmeta: release:Commit: Herv Beraud <hberaud@redhat.com>\nmeta: release:Change-Id: I2a9ad25f675f046b1bedaf59f8a406195243d2c4\nmeta: release:Code-Review+1: Carl caihui <cai.hui@zte.com.cn>\nmeta: release:Code-Review+2: Sean McGinnis <sean.mcginnis@gmail.com>\nmeta: release:Code-Review+2: Herv Beraud <hberaud@redhat.com>\nmeta: release:Workflow+1: Herv Beraud <hberaud@redhat.com>\nChange-Id: I3d33dea0b56f840175a996428ae962e73db858b8\n'}]",0,764991,ea580b11e9cefb0723f18701cae4f1247aa42b5e,9,3,1,11131,,,0,"update constraint for python-freezerclient to new release 4.1.0

meta: version: 4.1.0
meta: diff-start: -
meta: series: wallaby
meta: release-type: release
meta: pypi: yes
meta: first: yes
meta: release:Author: Herv Beraud <hberaud@redhat.com>
meta: release:Commit: Herv Beraud <hberaud@redhat.com>
meta: release:Change-Id: I2a9ad25f675f046b1bedaf59f8a406195243d2c4
meta: release:Code-Review+1: Carl caihui <cai.hui@zte.com.cn>
meta: release:Code-Review+2: Sean McGinnis <sean.mcginnis@gmail.com>
meta: release:Code-Review+2: Herv Beraud <hberaud@redhat.com>
meta: release:Workflow+1: Herv Beraud <hberaud@redhat.com>
Change-Id: I3d33dea0b56f840175a996428ae962e73db858b8
",git fetch https://review.opendev.org/openstack/requirements refs/changes/91/764991/1 && git format-patch -1 --stdout FETCH_HEAD,['upper-constraints.txt'],1,ea580b11e9cefb0723f18701cae4f1247aa42b5e,new-release,python-freezerclient===4.1.0,python-freezerclient===4.0.0,1,1
openstack%2Ftripleo-ci~master~I3d544634719d82a7cf58037471a5cc3a13cc135a,openstack/tripleo-ci,master,I3d544634719d82a7cf58037471a5cc3a13cc135a,Add containers multinode stable/victoria jobs,MERGED,2020-10-27 07:45:28.000000000,2020-12-02 04:35:23.000000000,2020-12-02 04:35:23.000000000,"[{'_account_id': 8449}, {'_account_id': 12393}, {'_account_id': 20182}, {'_account_id': 22348}, {'_account_id': 23181}, {'_account_id': 30742}]","[{'number': 1, 'created': '2020-10-27 07:45:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ci/commit/e31870e9f638d3413b5b84e9ca4458c5ad2c7a57', 'message': 'Add containers multinode stable/victoria jobs\n\nAdded containers multinode jobs for stable/victoria.\nTracked by tripleo-ci squad in [1].\n\n[1] https://projects.engineering.redhat.com/browse/TRIPLEOCI-234\n\nChange-Id: I3d544634719d82a7cf58037471a5cc3a13cc135a\n'}, {'number': 2, 'created': '2020-10-27 09:31:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ci/commit/ce66bf5fffb4f58ce30b81f7f7a5a940c99f8b5f', 'message': 'Add containers multinode stable/victoria jobs\n\nAdded containers multinode jobs for stable/victoria.\nTracked by tripleo-ci squad in [1].\n\n[1] https://projects.engineering.redhat.com/browse/TRIPLEOCI-234\n\nChange-Id: I3d544634719d82a7cf58037471a5cc3a13cc135a\n'}, {'number': 3, 'created': '2020-10-27 10:48:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ci/commit/d75ad224b5adf679fea4fd5bcb75e374194d0af5', 'message': 'Add containers multinode stable/victoria jobs\n\nAdded containers multinode jobs for stable/victoria.\nTracked by tripleo-ci squad in [1].\n\n[1] https://projects.engineering.redhat.com/browse/TRIPLEOCI-234\n\nChange-Id: I3d544634719d82a7cf58037471a5cc3a13cc135a\n'}, {'number': 4, 'created': '2020-10-27 11:10:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ci/commit/71967b991a1cdf38354daa3d951faee8a44c5594', 'message': 'Add containers multinode stable/victoria jobs\n\nAdded containers multinode jobs for stable/victoria.\nTracked by tripleo-ci squad in [1].\n\n[1] https://projects.engineering.redhat.com/browse/TRIPLEOCI-234\n\nChange-Id: I3d544634719d82a7cf58037471a5cc3a13cc135a\n'}, {'number': 5, 'created': '2020-10-27 11:15:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ci/commit/b028ff38aa08248e1c93aeaf09f50bc7ff8a2eda', 'message': 'Add containers multinode stable/victoria jobs\n\nAdded containers multinode jobs for stable/victoria.\nTracked by tripleo-ci squad in [1].\n\n[1] https://projects.engineering.redhat.com/browse/TRIPLEOCI-234\n\nChange-Id: I3d544634719d82a7cf58037471a5cc3a13cc135a\n'}, {'number': 6, 'created': '2020-10-28 10:43:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ci/commit/cc9649a5aecd3810e9fe72aaab0173dfa5e3f54f', 'message': 'Add containers multinode stable/victoria jobs\n\nAdded containers multinode jobs for stable/victoria.\n\nChange-Id: I3d544634719d82a7cf58037471a5cc3a13cc135a\n'}, {'number': 7, 'created': '2020-10-28 10:55:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ci/commit/c22dfda5b655fba454ada531ff95f548728b0406', 'message': 'Add containers multinode stable/victoria jobs\n\nAdded containers multinode jobs for stable/victoria.\n\nChange-Id: I3d544634719d82a7cf58037471a5cc3a13cc135a\n'}, {'number': 8, 'created': '2020-11-03 08:28:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ci/commit/610ff923bf1faf4b84b4091c1d85096dd764d907', 'message': 'Add containers multinode stable/victoria jobs\n\nAdded containers multinode jobs for stable/victoria.\n\nChange-Id: I3d544634719d82a7cf58037471a5cc3a13cc135a\n'}, {'number': 9, 'created': '2020-11-09 06:24:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ci/commit/6347a13c73fa32cec39745e83080fb30c4cf7a13', 'message': 'Add containers multinode stable/victoria jobs\n\nAdded containers multinode jobs for stable/victoria.\n\nChange-Id: I3d544634719d82a7cf58037471a5cc3a13cc135a\n'}, {'number': 10, 'created': '2020-11-09 07:38:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ci/commit/22ea3984f006e17a9238c74a145a90d45c51a953', 'message': 'Add containers multinode stable/victoria jobs\n\nAdded containers multinode jobs for stable/victoria.\n\nChange-Id: I3d544634719d82a7cf58037471a5cc3a13cc135a\n'}, {'number': 11, 'created': '2020-11-09 13:07:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ci/commit/2128a6bdcea12e6c4be049f33388f45d9234c682', 'message': 'Add containers multinode stable/victoria jobs\n\nAdded containers multinode jobs for stable/victoria.\nAnd also fixes the periodic jobs adding the content\nproviders and required vars/dependencies.\n\nChange-Id: I3d544634719d82a7cf58037471a5cc3a13cc135a\n'}, {'number': 12, 'created': '2020-11-11 06:52:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ci/commit/cbdc055285bcd0b1ef838a85bccc39a5e6e3170d', 'message': 'Add containers multinode stable/victoria jobs\n\nAdded containers multinode jobs for stable/victoria.\nAnd also fixes the periodic jobs adding the content\nproviders and required vars/dependencies.\n\nChange-Id: I3d544634719d82a7cf58037471a5cc3a13cc135a\n'}, {'number': 13, 'created': '2020-11-19 13:16:33.000000000', 'files': ['zuul.d/multinode-jobs.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-ci/commit/10cfb822480f8eef0904af019a7af8415d0b8c12', 'message': 'Add containers multinode stable/victoria jobs\n\nAdded containers multinode jobs for stable/victoria.\nAnd also fixes the periodic jobs adding the content\nproviders and required vars/dependencies.\n\nChange-Id: I3d544634719d82a7cf58037471a5cc3a13cc135a\n'}]",6,759823,10cfb822480f8eef0904af019a7af8415d0b8c12,93,6,13,20182,,,0,"Add containers multinode stable/victoria jobs

Added containers multinode jobs for stable/victoria.
And also fixes the periodic jobs adding the content
providers and required vars/dependencies.

Change-Id: I3d544634719d82a7cf58037471a5cc3a13cc135a
",git fetch https://review.opendev.org/openstack/tripleo-ci refs/changes/23/759823/1 && git format-patch -1 --stdout FETCH_HEAD,['zuul.d/multinode-jobs.yaml'],1,e31870e9f638d3413b5b84e9ca4458c5ad2c7a57,victoria-branching, - tripleo-ci-centos-8-content-provider-victoria - tripleo-ci-centos-8-containers-multinode-victoria: irrelevant-files: *multinode_ignored vars: *multi_consumer_vars dependencies: - tripleo-ci-centos-8-content-provider-victoria - tripleo-ci-centos-8-containers-multinode-victoria: irrelevant-files: *multinode_ignored - tripleo-ci-centos-8-containers-multinode-victoria: vars: force_non_periodic: true name: tripleo-ci-centos-8-containers-multinode-victoria parent: tripleo-ci-centos-8-containers-multinode branches: master override-checkout: stable/victoria vars: branch_override: stable/victroia - job:,,19,0
openstack%2Fpython-tripleoclient~master~Ia58efb14803d54ca297218a58208c39c31641403,openstack/python-tripleoclient,master,Ia58efb14803d54ca297218a58208c39c31641403,Add new toggle to disable Swift,MERGED,2020-09-22 15:11:38.000000000,2020-12-02 04:21:25.000000000,2020-12-02 04:19:34.000000000,"[{'_account_id': 7353}, {'_account_id': 14985}, {'_account_id': 22348}]","[{'number': 1, 'created': '2020-09-22 15:11:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-tripleoclient/commit/ec6c933943629a71960afa5079f277e3eae38637', 'message': ""Add new toggle to disable Swift\n\nWe're working on an effort to remove Swift on the Undercloud.\nThis patch will help us to easily control if whether or not we want\nSwift deployed on the Undercloud.\n\nChange-Id: Ia58efb14803d54ca297218a58208c39c31641403\n""}, {'number': 2, 'created': '2020-09-23 15:38:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-tripleoclient/commit/dfc6b473f841a51838b9200a9b930b510a3280c4', 'message': ""Add new toggle to disable Swift\n\nWe're working on an effort to remove Swift on the Undercloud.\nThis patch will help us to easily control if whether or not we want\nSwift deployed on the Undercloud.\n\nChange-Id: Ia58efb14803d54ca297218a58208c39c31641403\n""}, {'number': 3, 'created': '2020-09-24 14:12:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-tripleoclient/commit/7fb43046bf48bc687bcf0c2b61deaea384f8f17c', 'message': ""Add new toggle to disable Swift\n\nWe're working on an effort to remove Swift on the Undercloud.\nThis patch will help us to easily control if whether or not we want\nSwift deployed on the Undercloud.\n\nChange-Id: Ia58efb14803d54ca297218a58208c39c31641403\n""}, {'number': 4, 'created': '2020-09-25 12:22:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-tripleoclient/commit/8269a7962455395189b478298db8697cf0de1029', 'message': ""Add new toggle to disable Swift\n\nWe're working on an effort to remove Swift on the Undercloud.\nThis patch will help us to easily control if whether or not we want\nSwift deployed on the Undercloud.\n\nChange-Id: Ia58efb14803d54ca297218a58208c39c31641403\n""}, {'number': 5, 'created': '2020-09-25 23:24:46.000000000', 'files': ['tripleoclient/config/undercloud.py', 'tripleoclient/config/standalone.py', 'tripleoclient/v1/undercloud_config.py', 'tripleoclient/tests/config/test_config_standalone.py', 'tripleoclient/tests/config/test_config_undercloud.py'], 'web_link': 'https://opendev.org/openstack/python-tripleoclient/commit/a139d4362586e5514c8332f7b40b3b1056b9a8ea', 'message': ""Add new toggle to disable Swift\n\nWe're working on an effort to remove Swift on the Undercloud.\nThis patch will help us to easily control if whether or not we want\nSwift deployed on the Undercloud.\n\nChange-Id: Ia58efb14803d54ca297218a58208c39c31641403\n""}]",1,753375,a139d4362586e5514c8332f7b40b3b1056b9a8ea,22,3,5,3153,,,0,"Add new toggle to disable Swift

We're working on an effort to remove Swift on the Undercloud.
This patch will help us to easily control if whether or not we want
Swift deployed on the Undercloud.

Change-Id: Ia58efb14803d54ca297218a58208c39c31641403
",git fetch https://review.opendev.org/openstack/python-tripleoclient refs/changes/75/753375/5 && git format-patch -1 --stdout FETCH_HEAD,"['tripleoclient/config/undercloud.py', 'tripleoclient/config/standalone.py', 'tripleoclient/v1/undercloud_config.py', 'tripleoclient/tests/config/test_config_standalone.py']",4,ec6c933943629a71960afa5079f277e3eae38637,config-download/swift," 'enable_swift', swift=True 'enable_swift', 'enable_swift',",,18,3
openstack%2Ftripleo-heat-templates~master~I3a27772b37dc6c2be8528e8ea3fb86b4a07d7e32,openstack/tripleo-heat-templates,master,I3a27772b37dc6c2be8528e8ea3fb86b4a07d7e32,Fix barbican settings missing from glance Edge nodes,MERGED,2020-11-24 17:17:48.000000000,2020-12-02 04:19:40.000000000,2020-12-02 04:19:40.000000000,"[{'_account_id': 6926}, {'_account_id': 7144}, {'_account_id': 9816}, {'_account_id': 18002}, {'_account_id': 22348}, {'_account_id': 23181}, {'_account_id': 24245}]","[{'number': 1, 'created': '2020-11-24 17:17:48.000000000', 'files': ['deployment/barbican/barbican-client-puppet.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/89fcfa5fabadcd4de1bbd7ce13044b2a7ee230ec', 'message': ""Fix barbican settings missing from glance Edge nodes\n\nFix the BarbicanClient THT to include 'glance_api_edge' in the tripleo\nservices that require access to Barbican.\n\nCloses-Bug: #1905439\nChange-Id: I3a27772b37dc6c2be8528e8ea3fb86b4a07d7e32\n""}]",0,764038,89fcfa5fabadcd4de1bbd7ce13044b2a7ee230ec,13,7,1,21129,,,0,"Fix barbican settings missing from glance Edge nodes

Fix the BarbicanClient THT to include 'glance_api_edge' in the tripleo
services that require access to Barbican.

Closes-Bug: #1905439
Change-Id: I3a27772b37dc6c2be8528e8ea3fb86b4a07d7e32
",git fetch https://review.opendev.org/openstack/tripleo-heat-templates refs/changes/38/764038/1 && git format-patch -1 --stdout FETCH_HEAD,['deployment/barbican/barbican-client-puppet.yaml'],1,89fcfa5fabadcd4de1bbd7ce13044b2a7ee230ec,bug/1905439, glance_api: &glance_barbican_config glance_api_edge: *glance_barbican_config, glance_api:,2,1
openstack%2Foctavia~stable%2Fvictoria~I923accd73e0c9cadc91c115157c576432f428622,openstack/octavia,stable/victoria,I923accd73e0c9cadc91c115157c576432f428622,Fix load balancers with failed amphora failover,MERGED,2020-11-23 14:12:27.000000000,2020-12-02 04:05:58.000000000,2020-12-02 04:04:10.000000000,"[{'_account_id': 1131}, {'_account_id': 7249}, {'_account_id': 11628}, {'_account_id': 22348}, {'_account_id': 28008}]","[{'number': 1, 'created': '2020-11-23 14:12:27.000000000', 'files': ['octavia/controller/worker/v1/tasks/amphora_driver_tasks.py', 'octavia/tests/unit/controller/worker/v1/tasks/test_amphora_driver_tasks.py'], 'web_link': 'https://opendev.org/openstack/octavia/commit/b17a5247c1932ed942e79f35964f4c1174fabb3b', 'message': 'Fix load balancers with failed amphora failover\n\nThis patch is a complement of [1] which we ensure\na fresh lb object, but only for AmpListenersUpdate\nclass.\n\nIt was observed, at least on train and ussuri\ndeployments that multiple failed amphoras were still\nhappening when using session persistence.\n\nThat is fixed and failover works flawless with session\npersistence when we also ensure a fresh lb object on\nAmphoraIndexListenerUpdate class.\n\n[1] https://review.opendev.org/#/c/756597/\n\nChange-Id: I923accd73e0c9cadc91c115157c576432f428622\nStory: 2008099\nTask: 40802\n(cherry picked from commit f96251c74275ac44a8ac20ff23a0f6c850af44f5)\n'}]",0,763731,b17a5247c1932ed942e79f35964f4c1174fabb3b,11,5,1,28619,,,0,"Fix load balancers with failed amphora failover

This patch is a complement of [1] which we ensure
a fresh lb object, but only for AmpListenersUpdate
class.

It was observed, at least on train and ussuri
deployments that multiple failed amphoras were still
happening when using session persistence.

That is fixed and failover works flawless with session
persistence when we also ensure a fresh lb object on
AmphoraIndexListenerUpdate class.

[1] https://review.opendev.org/#/c/756597/

Change-Id: I923accd73e0c9cadc91c115157c576432f428622
Story: 2008099
Task: 40802
(cherry picked from commit f96251c74275ac44a8ac20ff23a0f6c850af44f5)
",git fetch https://review.opendev.org/openstack/octavia refs/changes/31/763731/1 && git format-patch -1 --stdout FETCH_HEAD,"['octavia/controller/worker/v1/tasks/amphora_driver_tasks.py', 'octavia/tests/unit/controller/worker/v1/tasks/test_amphora_driver_tasks.py']",2,b17a5247c1932ed942e79f35964f4c1174fabb3b,," @mock.patch('octavia.db.repositories.LoadBalancerRepository.get') def test_amphorae_listeners_update(self, mock_lb_repo_get, mock_driver, mock_generate_uuid, mock_log, mock_get_session, mock_listener_repo_get, mock_listener_repo_update, mock_amphora_repo_update): mock_lb_repo_get.return_value = _LB_mock _LB_mock, _amphora_mock, self.timeout_dict)"," def test_amphorae_listeners_update( self, mock_driver, mock_generate_uuid, mock_log, mock_get_session, mock_listener_repo_get, mock_listener_repo_update, mock_amphora_repo_update): _load_balancer_mock, _amphora_mock, self.timeout_dict)",15,5
openstack%2Fpython-freezerclient~master~Iffb8e12a1cf3bb8747b63ea8e58d354d2abb208e,openstack/python-freezerclient,master,Iffb8e12a1cf3bb8747b63ea8e58d354d2abb208e,"Add ""project_domain_id"" param for clinet.Client():",MERGED,2020-12-02 02:05:43.000000000,2020-12-02 03:54:17.000000000,2020-12-02 03:52:57.000000000,"[{'_account_id': 21069}, {'_account_id': 22348}]","[{'number': 1, 'created': '2020-12-02 02:05:43.000000000', 'files': ['freezerclient/client.py'], 'web_link': 'https://opendev.org/openstack/python-freezerclient/commit/137e58b85656a819ed631ed9cfa0ff845bb9069c', 'message': 'Add ""project_domain_id"" param for clinet.Client():\n\nSometimes ""project_domain_id"" param is used in client.Client().\n\nChange-Id: Iffb8e12a1cf3bb8747b63ea8e58d354d2abb208e\n'}]",0,765034,137e58b85656a819ed631ed9cfa0ff845bb9069c,7,2,1,21069,,,0,"Add ""project_domain_id"" param for clinet.Client():

Sometimes ""project_domain_id"" param is used in client.Client().

Change-Id: Iffb8e12a1cf3bb8747b63ea8e58d354d2abb208e
",git fetch https://review.opendev.org/openstack/python-freezerclient refs/changes/34/765034/1 && git format-patch -1 --stdout FETCH_HEAD,['freezerclient/client.py'],1,137e58b85656a819ed631ed9cfa0ff845bb9069c,," user_domain_name=None, project_domain_id=None, **kwargs): if project_domain_id: kwargs[""project_domain_id""] = project_domain_id else: kwargs[""project_domain_id""] = os.environ.get('OS_PROJECT_DOMAIN_ID') "," user_domain_name=None, **kwargs):",6,1
openstack%2Fpuppet-openstack-integration~master~I61e4eb899933e2c5b5c9d43d00240f62a3c18b94,openstack/puppet-openstack-integration,master,I61e4eb899933e2c5b5c9d43d00240f62a3c18b94,Enable Ceph in CentOS8 scenario001/004 job,MERGED,2020-11-19 14:50:15.000000000,2020-12-02 03:14:07.000000000,2020-12-02 03:14:07.000000000,"[{'_account_id': 9414}, {'_account_id': 14985}, {'_account_id': 22348}]","[{'number': 1, 'created': '2020-11-19 14:50:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-openstack-integration/commit/298442eb8a62b4b7c4128d439a5a683be58ad983', 'message': 'Enable Ceph in CentOS8 scenario001/004 job\n\nThis patch enables ceph in CentOS8 scenario001 and 004, which was\ndisabled previously[1], since now ceph is available for CentOS8.\n\n[1] b44d0bdd5a19661130b6ada02f9ae825783a78a1\n\nChange-Id: I61e4eb899933e2c5b5c9d43d00240f62a3c18b94\n'}, {'number': 2, 'created': '2020-11-20 14:28:21.000000000', 'files': ['fixtures/scenario001.pp', 'fixtures/scenario004.pp'], 'web_link': 'https://opendev.org/openstack/puppet-openstack-integration/commit/5666beb4419a4714e34e540447877dba50e5f31d', 'message': 'Enable Ceph in CentOS8 scenario001/004 job\n\nThis patch enables ceph in CentOS8 scenario001 and 004, which was\ndisabled previously[1], since now ceph is available for CentOS8.\n\n[1] b44d0bdd5a19661130b6ada02f9ae825783a78a1\n\nChange-Id: I61e4eb899933e2c5b5c9d43d00240f62a3c18b94\n'}]",0,763385,5666beb4419a4714e34e540447877dba50e5f31d,10,3,2,9816,,,0,"Enable Ceph in CentOS8 scenario001/004 job

This patch enables ceph in CentOS8 scenario001 and 004, which was
disabled previously[1], since now ceph is available for CentOS8.

[1] b44d0bdd5a19661130b6ada02f9ae825783a78a1

Change-Id: I61e4eb899933e2c5b5c9d43d00240f62a3c18b94
",git fetch https://review.opendev.org/openstack/puppet-openstack-integration refs/changes/85/763385/2 && git format-patch -1 --stdout FETCH_HEAD,"['fixtures/scenario001.pp', 'fixtures/scenario004.pp']",2,298442eb8a62b4b7c4128d439a5a683be58ad983,centos8-ceph," backend => 'swift', libvirt_rbd => true, } class { 'openstack_integration::ceph': deploy_rgw => true, swift_dropin => true,","# FIXME(ykarel) Enable ceph in CentOS8 once Ceph repos are available if ($::os['family'] == 'RedHat' and Integer.new($::os['release']['major']) > 7) { $backend = undef $ceph = false } else { $backend = 'swift' $ceph = true } backend => $backend, libvirt_rbd => $ceph, } if $ceph { class { 'openstack_integration::ceph': deploy_rgw => true, swift_dropin => true, }",9,31
openstack%2Ftripleo-heat-templates~stable%2Fussuri~I1d05749c94bd58ad4badafa7d9755009cb4b64af,openstack/tripleo-heat-templates,stable/ussuri,I1d05749c94bd58ad4badafa7d9755009cb4b64af,Disable notification from services by default,MERGED,2020-10-02 09:51:46.000000000,2020-12-02 03:10:55.000000000,2020-12-02 03:09:21.000000000,"[{'_account_id': 3153}, {'_account_id': 4264}, {'_account_id': 7353}, {'_account_id': 9816}, {'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2020-10-02 09:51:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/4d5f956f5c7146653b2bccfdaeb5fcf7fe470664', 'message': ""Disable notification from services by default\n\nCurrently we disable Telemetry services like Ceilometer by defaut,\nwhich means that we don't have any consumers for notification messages.\nSo NotificationDriver should be set as noop by default so that we don't\nhave unconsumed messages in notification queues.\n\nChange-Id: I1d05749c94bd58ad4badafa7d9755009cb4b64af\nCloses-Bug: #1869355\n(cherry picked from commit afc0b731e044ed3223fb62501cdb291bdb7bc138)\nDepends-on: 753554\n""}, {'number': 2, 'created': '2020-10-12 12:16:47.000000000', 'files': ['ci/environments/scenario001-multinode-containers.yaml', 'ci/environments/scenario002-standalone.yaml', 'deployment/octavia/octavia-base.yaml', 'deployment/deprecated/sahara/sahara-base.yaml', 'deployment/experimental/designate/designate-base.yaml', 'deployment/cinder/cinder-api-container-puppet.yaml', 'deployment/glance/glance-api-container-puppet.yaml', 'deployment/aodh/aodh-base.yaml', 'environments/services/undercloud-ceilometer.yaml', 'deployment/barbican/barbican-api-container-puppet.yaml', 'ci/environments/scenario001-standalone.yaml', 'deployment/keystone/keystone-container-puppet.yaml', 'deployment/manila/manila-base.yaml', 'environments/enable-legacy-telemetry.yaml', 'deployment/mistral/mistral-base.yaml', 'releasenotes/notes/disable-notification-driver-a888d4e9b8eed1dc.yaml', 'deployment/heat/heat-base-puppet.yaml', 'deployment/ceilometer/ceilometer-base-container-puppet.yaml', 'deployment/neutron/neutron-base.yaml', 'environments/enable-stf.yaml', 'environments/services-baremetal/undercloud-ceilometer.yaml', 'deployment/nova/nova-base-puppet.yaml', 'environments/metrics/ceilometer-write-qdr.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/7ab640cfa589fe8721845587c91e7839f3cd6a05', 'message': ""Disable notification from services by default\n\nCurrently we disable Telemetry services like Ceilometer by defaut,\nwhich means that we don't have any consumers for notification messages.\nSo NotificationDriver should be set as noop by default so that we don't\nhave unconsumed messages in notification queues.\n\nChange-Id: I1d05749c94bd58ad4badafa7d9755009cb4b64af\nCloses-Bug: #1869355\n(cherry picked from commit afc0b731e044ed3223fb62501cdb291bdb7bc138)\n""}]",1,755746,7ab640cfa589fe8721845587c91e7839f3cd6a05,28,6,2,4264,,,0,"Disable notification from services by default

Currently we disable Telemetry services like Ceilometer by defaut,
which means that we don't have any consumers for notification messages.
So NotificationDriver should be set as noop by default so that we don't
have unconsumed messages in notification queues.

Change-Id: I1d05749c94bd58ad4badafa7d9755009cb4b64af
Closes-Bug: #1869355
(cherry picked from commit afc0b731e044ed3223fb62501cdb291bdb7bc138)
",git fetch https://review.opendev.org/openstack/tripleo-heat-templates refs/changes/46/755746/1 && git format-patch -1 --stdout FETCH_HEAD,"['ci/environments/scenario001-multinode-containers.yaml', 'ci/environments/scenario002-standalone.yaml', 'deployment/octavia/octavia-base.yaml', 'deployment/deprecated/sahara/sahara-base.yaml', 'deployment/experimental/designate/designate-base.yaml', 'deployment/cinder/cinder-api-container-puppet.yaml', 'deployment/glance/glance-api-container-puppet.yaml', 'deployment/aodh/aodh-base.yaml', 'environments/services/undercloud-ceilometer.yaml', 'deployment/barbican/barbican-api-container-puppet.yaml', 'ci/environments/scenario001-standalone.yaml', 'deployment/keystone/keystone-container-puppet.yaml', 'deployment/manila/manila-base.yaml', 'environments/enable-legacy-telemetry.yaml', 'deployment/mistral/mistral-base.yaml', 'releasenotes/notes/disable-notification-driver-a888d4e9b8eed1dc.yaml', 'deployment/heat/heat-base-puppet.yaml', 'deployment/ceilometer/ceilometer-base-container-puppet.yaml', 'deployment/neutron/neutron-base.yaml', 'environments/enable-stf.yaml', 'environments/services-baremetal/undercloud-ceilometer.yaml', 'deployment/nova/nova-base-puppet.yaml', 'environments/metrics/ceilometer-write-qdr.yaml']",23,4d5f956f5c7146653b2bccfdaeb5fcf7fe470664,disable_services_ussuri, NotificationDriver: 'messagingv2',,32,15
openstack%2Ftripleo-common~master~I6c306396cadeb7bcf543b0bbb734f3672f94e97b,openstack/tripleo-common,master,I6c306396cadeb7bcf543b0bbb734f3672f94e97b,config-download: allow get_overcloud_config() to run without Swift,MERGED,2020-09-22 16:04:19.000000000,2020-12-02 03:10:53.000000000,2020-12-02 03:09:27.000000000,"[{'_account_id': 7144}, {'_account_id': 7353}, {'_account_id': 14985}, {'_account_id': 22348}, {'_account_id': 23181}, {'_account_id': 25877}]","[{'number': 1, 'created': '2020-09-22 16:04:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-common/commit/58f6e1a61e018c0e79f4795819bd629f70eb22c1', 'message': ""WIP - config-download: allow get_overcloud_config() to run without Swift\n\nAllow the get_overcloud_config() function to work without Swift. It'll\njust generate the config into a work directory, and we can optionally\n(disabled by default) preserve the config on the host.\n\nThis is done so in tripleo_config_download Ansible module we can use\nthat method to generate the config.\n\nChange-Id: I6c306396cadeb7bcf543b0bbb734f3672f94e97b\n""}, {'number': 2, 'created': '2020-09-24 14:18:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-common/commit/facb6213e45efc57a7955f306a73ccc82efea386', 'message': ""config-download: allow get_overcloud_config() to run without Swift\n\nAllow the get_overcloud_config() function to work without Swift. It'll\njust generate the config into a work directory, and we can optionally\n(disabled by default) preserve the config on the host.\n\nThis is done so in tripleo_config_download Ansible module we can use\nthat method to generate the config.\n\nChange-Id: I6c306396cadeb7bcf543b0bbb734f3672f94e97b\n""}, {'number': 3, 'created': '2020-09-24 14:18:30.000000000', 'files': ['tripleo_common/utils/config.py'], 'web_link': 'https://opendev.org/openstack/tripleo-common/commit/0fde614e755e970a39b145b5108000d6180c04e5', 'message': ""config-download: allow get_overcloud_config() to run without Swift\n\nAllow the get_overcloud_config() function to work without Swift. It'll\njust generate the config into a work directory, and we can optionally\n(disabled by default) preserve the config on the host.\n\nThis is done so in tripleo_config_download Ansible module we can use\nthat method to generate the config.\n\nChange-Id: I6c306396cadeb7bcf543b0bbb734f3672f94e97b\n""}]",0,753394,0fde614e755e970a39b145b5108000d6180c04e5,17,6,3,3153,,,0,"config-download: allow get_overcloud_config() to run without Swift

Allow the get_overcloud_config() function to work without Swift. It'll
just generate the config into a work directory, and we can optionally
(disabled by default) preserve the config on the host.

This is done so in tripleo_config_download Ansible module we can use
that method to generate the config.

Change-Id: I6c306396cadeb7bcf543b0bbb734f3672f94e97b
",git fetch https://review.opendev.org/openstack/tripleo-common refs/changes/94/753394/1 && git format-patch -1 --stdout FETCH_HEAD,['tripleo_common/utils/config.py'],1,58f6e1a61e018c0e79f4795819bd629f70eb22c1,config-download/swift," config_dir=None, config_type=None, preserve_config=False): if swift: # Since the config-download directory is now a git repo, first download # the existing config container if it exists so we can reuse the # existing git repo. try: swiftutils.download_container(swift, container_config, config_dir) # Delete the existing container before we re-upload, otherwise # files may not be fully overwritten. swiftutils.delete_container(swift, container_config) except swiftexceptions.ClientException as err: if err.http_status != 404: raise if swift: with tempfile.NamedTemporaryFile() as tmp_tarball: tarball.create_tarball(config_path, tmp_tarball.name, excludes=['.tox', '*.pyc', '*.pyo']) tarball.tarball_extract_to_swift_container( swift, tmp_tarball.name, container_config) # Also upload the tarball to the container for use by export later with open(tmp_tarball.name, 'rb') as t: swift.put_object(container_config, '%s.tar.gz' % container_config, t) if not preserve_config: if os.path.exists(config_path): shutil.rmtree(config_path)"," config_dir=None, config_type=None): # Since the config-download directory is now a git repo, first download # the existing config container if it exists so we can reuse the # existing git repo. try: swiftutils.download_container(swift, container_config, config_dir) # Delete the existing container before we re-upload, otherwise # files may not be fully overwritten. swiftutils.delete_container(swift, container_config) except swiftexceptions.ClientException as err: if err.http_status != 404: raise with tempfile.NamedTemporaryFile() as tmp_tarball: tarball.create_tarball(config_path, tmp_tarball.name, excludes=['.tox', '*.pyc', '*.pyo']) tarball.tarball_extract_to_swift_container( swift, tmp_tarball.name, container_config) # Also upload the tarball to the container for use by export later with open(tmp_tarball.name, 'rb') as t: swift.put_object(container_config, '%s.tar.gz' % container_config, t) if os.path.exists(config_path): shutil.rmtree(config_path)",30,26
openstack%2Fpuppet-tripleo~stable%2Fvictoria~I6f165491228f05539193f2e762b1b10320f52c36,openstack/puppet-tripleo,stable/victoria,I6f165491228f05539193f2e762b1b10320f52c36,Filter haproxy_certificate_specs if hostname is empty,MERGED,2020-11-30 07:06:24.000000000,2020-12-02 03:04:29.000000000,2020-12-02 03:04:29.000000000,"[{'_account_id': 14985}, {'_account_id': 20172}, {'_account_id': 22348}, {'_account_id': 23181}, {'_account_id': 23811}, {'_account_id': 24245}]","[{'number': 1, 'created': '2020-11-30 07:06:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-tripleo/commit/3c6ec07e6a3fea9a1bebe1220e14b56bbf0b8c43', 'message': 'Filter haproxy_certificate_specs if hostname is empty\n\nThe HAProxy tripleo service currently attempts to generate certificate\nspecs for all enabled networks which failes on roles that omit some\nnetworks.\n\nFor now workaround it by filtering out the bad certificate specs in\npuppet-tripleo.\nA similar workaround was implemented for apache in\nI651919488cb68b0b9878b4e21ab376bfc6e3f0fe.\n\nCloses-bug: #1905604\nChange-Id: I6f165491228f05539193f2e762b1b10320f52c36\n(cherry picked from commit eaca38aa674f263ec2a95add28d645b11525e839)\n'}, {'number': 2, 'created': '2020-11-30 15:20:03.000000000', 'files': ['manifests/profile/base/certmonger_user.pp'], 'web_link': 'https://opendev.org/openstack/puppet-tripleo/commit/1c27dd46035dcaa2228444af7e0dac8dd9230cef', 'message': 'Filter haproxy_certificate_specs if hostname is empty\n\nThe HAProxy tripleo service currently attempts to generate certificate\nspecs for all enabled networks which failes on roles that omit some\nnetworks.\n\nFor now workaround it by filtering out the bad certificate specs in\npuppet-tripleo.\nA similar workaround was implemented for apache in\nI651919488cb68b0b9878b4e21ab376bfc6e3f0fe.\n\nCloses-bug: #1905604\nChange-Id: I6f165491228f05539193f2e762b1b10320f52c36\n(cherry picked from commit eaca38aa674f263ec2a95add28d645b11525e839)\n'}]",0,764505,1c27dd46035dcaa2228444af7e0dac8dd9230cef,20,6,2,17216,,,0,"Filter haproxy_certificate_specs if hostname is empty

The HAProxy tripleo service currently attempts to generate certificate
specs for all enabled networks which failes on roles that omit some
networks.

For now workaround it by filtering out the bad certificate specs in
puppet-tripleo.
A similar workaround was implemented for apache in
I651919488cb68b0b9878b4e21ab376bfc6e3f0fe.

Closes-bug: #1905604
Change-Id: I6f165491228f05539193f2e762b1b10320f52c36
(cherry picked from commit eaca38aa674f263ec2a95add28d645b11525e839)
",git fetch https://review.opendev.org/openstack/puppet-tripleo refs/changes/05/764505/1 && git format-patch -1 --stdout FETCH_HEAD,['manifests/profile/base/certmonger_user.pp'],1,3c6ec07e6a3fea9a1bebe1220e14b56bbf0b8c43,," # Remove haproxy_certificates_specs where hostname is empty. # Workaround bug: https://bugs.launchpad.net/tripleo/+bug/1905604 $haproxy_certificates_specs_filtered = $haproxy_certificates_specs.filter | $specs, $keys | { ! empty($keys[hostname]) } unless empty($haproxy_certificates_specs_filtered) { unless empty($haproxy_certificates_specs_filtered) { ensure_resources('tripleo::certmonger::haproxy', $haproxy_certificates_specs_filtered)"," unless empty($haproxy_certificates_specs) { unless empty($haproxy_certificates_specs) { ensure_resources('tripleo::certmonger::haproxy', $haproxy_certificates_specs)",7,3
openstack%2Fpython-zaqarclient~stable%2Fstein~Ie14b6dd79cdf60136ba2215edee38c066405c562,openstack/python-zaqarclient,stable/stein,Ie14b6dd79cdf60136ba2215edee38c066405c562,Remove Deprecated Group in Tests,MERGED,2020-11-27 03:47:26.000000000,2020-12-02 02:25:36.000000000,2020-12-02 02:24:08.000000000,"[{'_account_id': 6484}, {'_account_id': 22348}]","[{'number': 1, 'created': '2020-11-27 03:47:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-zaqarclient/commit/f273bbd43f3c2a84d5b97b8b42e6fb9516b1043f', 'message': 'Remove Deprecated Group in Tests\n\nSince Zaqar has removed ""group"" in stein, the tests in\nzaqarclinet should be updated.\n\nChange-Id: Ie14b6dd79cdf60136ba2215edee38c066405c562\n'}, {'number': 2, 'created': '2020-11-27 09:36:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-zaqarclient/commit/e8d5df379cddc2c15ade0fe40dbc308c1b878610', 'message': 'Remove Deprecated Group in Tests\n\nSince Zaqar has removed ""group"" in stein, the tests in\nzaqarclinet should be updated.\n\nChange-Id: Ie14b6dd79cdf60136ba2215edee38c066405c562\n'}, {'number': 3, 'created': '2020-12-01 06:07:46.000000000', 'files': ['zaqarclient/tests/queues/flavor.py', 'zaqarclient/queues/v1/flavor.py', 'zaqarclient/tests/queues/pool.py'], 'web_link': 'https://opendev.org/openstack/python-zaqarclient/commit/b03370d55ddb3ff8164c21af75d176e46679f199', 'message': 'Remove Deprecated Group in Tests\n\nSince Zaqar has removed ""group"" in stein, the tests in\nzaqarclinet should be updated.\n\nChange-Id: Ie14b6dd79cdf60136ba2215edee38c066405c562\n'}]",0,764404,b03370d55ddb3ff8164c21af75d176e46679f199,12,2,3,8846,,,0,"Remove Deprecated Group in Tests

Since Zaqar has removed ""group"" in stein, the tests in
zaqarclinet should be updated.

Change-Id: Ie14b6dd79cdf60136ba2215edee38c066405c562
",git fetch https://review.opendev.org/openstack/python-zaqarclient refs/changes/04/764404/2 && git format-patch -1 --stdout FETCH_HEAD,"['zaqarclient/tests/queues/flavor.py', 'zaqarclient/tests/queues/pool.py']",2,f273bbd43f3c2a84d5b97b8b42e6fb9516b1043f,remove-deprecated-group-in-tests,," 'group': 'us', 'group': 'us', 'group': 'us', 'group': 'us', 'group': 'us',",29,32
openstack%2Fmagnum~master~Iff451673dec61b20051866d70276b820bddc0edc,openstack/magnum,master,Iff451673dec61b20051866d70276b820bddc0edc,Fix arguments formatting in exception messages,NEW,2020-11-20 02:08:31.000000000,2020-12-02 02:19:58.000000000,,"[{'_account_id': 20190}, {'_account_id': 22348}]","[{'number': 1, 'created': '2020-11-20 02:08:31.000000000', 'files': ['magnum/tests/functional/api/v1/clients/bay_client.py', 'magnum/tests/functional/api/v1/clients/cluster_client.py'], 'web_link': 'https://opendev.org/openstack/magnum/commit/602d678de5e41fea42a63f819d2fb3b4c8319a2e', 'message': 'Fix arguments formatting in exception messages\n\nThis is to fix the ""TypeError: not all arguments converted during\nstring formatting"" error in exception messages.\n\nChange-Id: Iff451673dec61b20051866d70276b820bddc0edc\n'}]",0,763492,602d678de5e41fea42a63f819d2fb3b4c8319a2e,12,2,1,20190,,,0,"Fix arguments formatting in exception messages

This is to fix the ""TypeError: not all arguments converted during
string formatting"" error in exception messages.

Change-Id: Iff451673dec61b20051866d70276b820bddc0edc
",git fetch https://review.opendev.org/openstack/magnum refs/changes/92/763492/1 && git format-patch -1 --stdout FETCH_HEAD,"['magnum/tests/functional/api/v1/clients/bay_client.py', 'magnum/tests/functional/api/v1/clients/cluster_client.py']",2,602d678de5e41fea42a63f819d2fb3b4c8319a2e,exception_format," ""Got into an error condition: %s for %s"" %"," ""Got into an error condition: %s for %s"",",2,2
openstack%2Ftripleo-quickstart~master~I9bca2e5774ad2f9044f876aa847d35fa1cfc764b,openstack/tripleo-quickstart,master,I9bca2e5774ad2f9044f876aa847d35fa1cfc764b,DNM - Test dependent patch,ABANDONED,2020-12-01 13:46:34.000000000,2020-12-02 02:08:48.000000000,,"[{'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2020-12-01 13:46:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-quickstart/commit/8bf2184ec3566efbed4e3b65bc227c18c79efa58', 'message': 'DNM - Test dependent patch\n\nDepends-On: https://review.opendev.org//764898\nChange-Id: I9bca2e5774ad2f9044f876aa847d35fa1cfc764b\n'}, {'number': 2, 'created': '2020-12-01 13:48:07.000000000', 'files': ['requirements.txt'], 'web_link': 'https://opendev.org/openstack/tripleo-quickstart/commit/8881efe01f23d43ab8fdd1326f47cc55aca2975a', 'message': 'DNM - Test dependent patch\n\nDepends-On: https://review.opendev.org/764898\nChange-Id: I9bca2e5774ad2f9044f876aa847d35fa1cfc764b\n'}]",0,764939,8881efe01f23d43ab8fdd1326f47cc55aca2975a,5,2,2,24245,,,0,"DNM - Test dependent patch

Depends-On: https://review.opendev.org/764898
Change-Id: I9bca2e5774ad2f9044f876aa847d35fa1cfc764b
",git fetch https://review.opendev.org/openstack/tripleo-quickstart refs/changes/39/764939/1 && git format-patch -1 --stdout FETCH_HEAD,['requirements.txt'],1,8bf2184ec3566efbed4e3b65bc227c18c79efa58,test-dlrn-current-patch,# TEST,,1,0
openstack%2Ftempest~master~I984ecee81a9730b663764800f604333f28fd8180,openstack/tempest,master,I984ecee81a9730b663764800f604333f28fd8180,Decentralize the zuul jobs into zuul.d,MERGED,2020-11-25 18:01:50.000000000,2020-12-02 01:57:14.000000000,2020-12-02 01:50:43.000000000,"[{'_account_id': 5689}, {'_account_id': 22348}, {'_account_id': 22873}]","[{'number': 1, 'created': '2020-11-25 18:01:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/d2f2274670a50bcbd42ad577d7857c710ea4883b', 'message': 'Decentralise the zuul jobs into zuul.d\n\nCurrent .zuul.yaml file has 36 jobs definition and\nit is growing more which makes it hard to read and\nerror prone.\n\nThis commit move the jobs definitions to zuul.d directory to\ndifferent yaml files:\n- base.yaml includes base jobs definition\n- integrated-gate.yaml includes integrated jobs to be\n  used in other openstack projects too.\n- stable-jobs.yaml includes all stable jobs\n- tempest-specific.yaml includes jobs supposed to run on Tempest\n  gate only\n- project.yaml includes different pipelines (check, gate etc) definition\n\nChange-Id: I984ecee81a9730b663764800f604333f28fd8180\n'}, {'number': 2, 'created': '2020-11-25 18:04:17.000000000', 'files': ['.zuul.yaml', 'zuul.d/stable-jobs.yaml', 'zuul.d/base.yaml', 'zuul.d/tempest-specific.yaml', 'zuul.d/project.yaml', 'zuul.d/integrated-gate.yaml'], 'web_link': 'https://opendev.org/openstack/tempest/commit/61f5733a66be136137ce89843dd8081dbe644802', 'message': 'Decentralize the zuul jobs into zuul.d\n\nCurrent .zuul.yaml file has 36 jobs definition and\nit is growing more which makes it hard to read and\nerror prone.\n\nThis commit move the jobs definitions to zuul.d directory to\ndifferent yaml files:\n- base.yaml includes base jobs definition\n- integrated-gate.yaml includes integrated jobs to be\n  used in other openstack projects too.\n- stable-jobs.yaml includes all stable jobs\n- tempest-specific.yaml includes jobs supposed to run on Tempest\n  gate only\n- project.yaml includes different pipelines (check, gate etc) definition\n\nChange-Id: I984ecee81a9730b663764800f604333f28fd8180\n'}]",0,764226,61f5733a66be136137ce89843dd8081dbe644802,9,3,2,8556,,,0,"Decentralize the zuul jobs into zuul.d

Current .zuul.yaml file has 36 jobs definition and
it is growing more which makes it hard to read and
error prone.

This commit move the jobs definitions to zuul.d directory to
different yaml files:
- base.yaml includes base jobs definition
- integrated-gate.yaml includes integrated jobs to be
  used in other openstack projects too.
- stable-jobs.yaml includes all stable jobs
- tempest-specific.yaml includes jobs supposed to run on Tempest
  gate only
- project.yaml includes different pipelines (check, gate etc) definition

Change-Id: I984ecee81a9730b663764800f604333f28fd8180
",git fetch https://review.opendev.org/openstack/tempest refs/changes/26/764226/1 && git format-patch -1 --stdout FETCH_HEAD,"['.zuul.yaml', 'zuul.d/stable-jobs.yaml', 'zuul.d/base.yaml', 'zuul.d/project.yaml', 'zuul.d/tempest-specific.yaml', 'zuul.d/integrated-gate.yaml']",6,d2f2274670a50bcbd42ad577d7857c710ea4883b,,"# NOTE(gmann): This file includes all integrated jobs definition which # are supposed to be run by Tempest and other projects as # integrated testing. - job: name: tempest-all parent: devstack-tempest description: | Integration test that runs all tests. Former name for this job was: * legacy-periodic-tempest-dsvm-all-master vars: tox_envlist: all tempest_test_regex: tempest devstack_localrc: ENABLE_FILE_INJECTION: true - job: name: tempest-ipv6-only parent: devstack-tempest-ipv6 # This currently works from stable/pike on. branches: ^(?!stable/ocata).*$ description: | Integration test of IPv6-only deployments. This job runs smoke and IPv6 relates tests only. Basic idea is to test whether OpenStack Services listen on IPv6 addrress or not. timeout: 10800 vars: tox_envlist: ipv6-only - job: name: tempest-full parent: devstack-tempest # This currently works from stable/pike on. # Before stable/pike, legacy version of tempest-full # 'legacy-tempest-dsvm-neutron-full' run. branches: ^(?!stable/ocata).*$ description: | Base integration test with Neutron networking and py27. This job is supposed to run until stable/train setup only. If you are running it on stable/ussuri gate onwards for python2.7 coverage then you need to do override-checkout with any stable branch less than or equal to stable/train. Former names for this job where: * legacy-tempest-dsvm-neutron-full * gate-tempest-dsvm-neutron-full-ubuntu-xenial vars: tox_envlist: full devstack_localrc: ENABLE_FILE_INJECTION: true ENABLE_VOLUME_MULTIATTACH: true USE_PYTHON3: False devstack_services: # NOTE(mriedem): Disable the cinder-backup service from tempest-full # since tempest-full is in the integrated-gate project template but # the backup tests do not really involve other services so they should # be run in some more cinder-specific job, especially because the # tests fail at a high rate (see bugs 1483434, 1813217, 1745168) c-bak: false - job: name: tempest-full-py3 parent: devstack-tempest # This currently works from stable/pike on. # Before stable/pike, legacy version of tempest-full # 'legacy-tempest-dsvm-neutron-full' run. branches: ^(?!stable/ocata).*$ description: | Base integration test with Neutron networking and py3. Former names for this job where: * legacy-tempest-dsvm-py35 * gate-tempest-dsvm-py35 vars: tox_envlist: full devstack_localrc: USE_PYTHON3: true FORCE_CONFIG_DRIVE: true ENABLE_VOLUME_MULTIATTACH: true GLANCE_USE_IMPORT_WORKFLOW: True devstack_services: s-account: false s-container: false s-object: false s-proxy: false # without Swift, c-bak cannot run (in the Gate at least) # NOTE(mriedem): Disable the cinder-backup service from # tempest-full-py3 since tempest-full-py3 is in the integrated-gate-py3 # project template but the backup tests do not really involve other # services so they should be run in some more cinder-specific job, # especially because the tests fail at a high rate (see bugs 1483434, # 1813217, 1745168) c-bak: false - job: name: tempest-integrated-networking parent: devstack-tempest branches: ^(?!stable/ocata).*$ description: | This job runs integration tests for networking. This is subset of 'tempest-full-py3' job and run only Neutron and Nova related tests. This is meant to be run on neutron gate only. vars: tox_envlist: integrated-network devstack_localrc: USE_PYTHON3: true FORCE_CONFIG_DRIVE: true devstack_services: s-account: false s-container: false s-object: false s-proxy: false c-bak: false - job: name: tempest-integrated-compute parent: devstack-tempest branches: ^(?!stable/ocata).*$ description: | This job runs integration tests for compute. This is subset of 'tempest-full-py3' job and run Nova, Neutron, Cinder (except backup tests) and Glance related tests. This is meant to be run on Nova gate only. vars: tox_envlist: integrated-compute tempest_black_regex: """" devstack_localrc: USE_PYTHON3: true FORCE_CONFIG_DRIVE: true ENABLE_VOLUME_MULTIATTACH: true devstack_services: s-account: false s-container: false s-object: false s-proxy: false c-bak: false - job: name: tempest-integrated-placement parent: devstack-tempest branches: ^(?!stable/ocata).*$ description: | This job runs integration tests for placement. This is subset of 'tempest-full-py3' job and run Nova and Neutron related tests. This is meant to be run on Placement gate only. vars: tox_envlist: integrated-placement devstack_localrc: USE_PYTHON3: true FORCE_CONFIG_DRIVE: true ENABLE_VOLUME_MULTIATTACH: true devstack_services: s-account: false s-container: false s-object: false s-proxy: false c-bak: false - job: name: tempest-integrated-storage parent: devstack-tempest branches: ^(?!stable/ocata).*$ description: | This job runs integration tests for image & block storage. This is subset of 'tempest-full-py3' job and run Cinder, Glance, Swift and Nova related tests. This is meant to be run on Cinder and Glance gate only. vars: tox_envlist: integrated-storage devstack_localrc: USE_PYTHON3: true FORCE_CONFIG_DRIVE: true ENABLE_VOLUME_MULTIATTACH: true GLANCE_USE_IMPORT_WORKFLOW: True - job: name: tempest-integrated-object-storage parent: devstack-tempest branches: ^(?!stable/ocata).*$ description: | This job runs integration tests for object storage. This is subset of 'tempest-full-py3' job and run Swift, Cinder and Glance related tests. This is meant to be run on Swift gate only. vars: tox_envlist: integrated-object-storage devstack_localrc: # NOTE(gmann): swift is not ready on python3 yet and devstack # install it on python2.7 only. But settting the USE_PYTHON3 # for future once swift is ready on py3. USE_PYTHON3: true - job: name: tempest-multinode-full parent: tempest-multinode-full-base nodeset: openstack-two-node-focal # This job runs on Focal from stable/victoria on. branches: ^(?!stable/(ocata|pike|queens|rocky|stein|train|ussuri)).*$ vars: devstack_localrc: USE_PYTHON3: False group-vars: subnode: devstack_localrc: USE_PYTHON3: False - job: name: tempest-multinode-full parent: tempest-multinode-full-base nodeset: openstack-two-node-bionic # This job runs on Bionic and on python2. This is for stable/stein and stable/train. # This job is prepared to make sure all stable branches from stable/stein till stable/train # will keep running on bionic. This can be removed once stable/train is EOL. branches: - stable/stein - stable/train - stable/ussuri vars: devstack_localrc: USE_PYTHON3: False group-vars: subnode: devstack_localrc: USE_PYTHON3: False - job: name: tempest-multinode-full parent: tempest-multinode-full-base nodeset: openstack-two-node-xenial # This job runs on Xenial and this is for stable/pike, stable/queens # and stable/rocky. This job is prepared to make sure all stable branches # before stable/stein will keep running on xenial. This job can be # removed once stable/rocky is EOL. branches: - stable/pike - stable/queens - stable/rocky vars: devstack_localrc: USE_PYTHON3: False group-vars: subnode: devstack_localrc: USE_PYTHON3: False - job: name: tempest-multinode-full-py3 parent: tempest-multinode-full vars: devstack_localrc: USE_PYTHON3: true group-vars: subnode: devstack_localrc: USE_PYTHON3: true - job: name: tempest-slow parent: tempest-multinode-full description: | This multinode integration job will run all the tests tagged as slow. It enables the lvm multibackend setup to cover few scenario tests. This job will run only slow tests (API or Scenario) serially. Former names for this job were: * legacy-tempest-dsvm-neutron-scenario-multinode-lvm-multibackend * tempest-scenario-multinode-lvm-multibackend timeout: 10800 vars: tox_envlist: slow-serial devstack_localrc: CINDER_ENABLED_BACKENDS: lvm:lvmdriver-1,lvm:lvmdriver-2 ENABLE_VOLUME_MULTIATTACH: true devstack_plugins: neutron: https://opendev.org/openstack/neutron devstack_services: neutron-placement: true neutron-qos: true devstack_local_conf: post-config: ""/$NEUTRON_CORE_PLUGIN_CONF"": ovs: bridge_mappings: public:br-ex resource_provider_bandwidths: br-ex:1000000:1000000 test-config: $TEMPEST_CONFIG: network-feature-enabled: qos_placement_physnet: public tempest_concurrency: 2 group-vars: # NOTE(mriedem): The ENABLE_VOLUME_MULTIATTACH variable is used on both # the controller and subnode prior to Rocky so we have to make sure the # variable is set in both locations. subnode: devstack_localrc: ENABLE_VOLUME_MULTIATTACH: true - job: name: tempest-slow-py3 parent: tempest-slow vars: devstack_localrc: USE_PYTHON3: true devstack_services: s-account: false s-container: false s-object: false s-proxy: false # without Swift, c-bak cannot run (in the Gate at least) c-bak: false group-vars: subnode: devstack_localrc: USE_PYTHON3: true - job: name: tempest-cinder-v2-api parent: devstack-tempest branches: - master description: | This job runs the cinder API test against v2 endpoint. vars: tox_envlist: all tempest_test_regex: api.*volume devstack_localrc: TEMPEST_VOLUME_TYPE: volumev2 - job: name: tempest-pg-full parent: tempest-full-py3 description: | Base integration test with Neutron networking and PostgreSQL. Former name for this job was legacy-tempest-dsvm-neutron-pg-full. vars: devstack_localrc: ENABLE_FILE_INJECTION: true DATABASE_TYPE: postgresql - project-template: name: integrated-gate-networking description: | Run the python3 Tempest network integration tests (Nova and Neutron related) in check and gate for the neutron integrated gate. This is meant to be run on neutron gate only. check: jobs: - grenade - tempest-integrated-networking gate: jobs: - grenade - tempest-integrated-networking - project-template: name: integrated-gate-compute description: | Run the python3 Tempest compute integration tests (Nova, Neutron, Cinder and Glance related) in check and gate for the Nova integrated gate. This is meant to be run on Nova gate only. check: jobs: - grenade - tempest-integrated-compute gate: jobs: - grenade - tempest-integrated-compute - project-template: name: integrated-gate-placement description: | Run the python3 Tempest placement integration tests (Nova and Neutron related) in check and gate for the Placement integrated gate. This is meant to be run on Placement gate only. check: jobs: - grenade - tempest-integrated-placement gate: jobs: - grenade - tempest-integrated-placement - project-template: name: integrated-gate-storage description: | Run the python3 Tempest image & block storage integration tests (Cinder, Glance, Swift and Nova related) in check and gate for the neutron integrated gate. This is meant to be run on Cinder and Glance gate only. check: jobs: - grenade - tempest-integrated-storage gate: jobs: - grenade - tempest-integrated-storage - project-template: name: integrated-gate-object-storage description: | Run the python3 Tempest object storage integration tests (Swift, Cinder and Glance related) in check and gate for the swift integrated gate. This is meant to be run on swift gate only. check: jobs: - grenade - tempest-integrated-object-storage gate: jobs: - grenade - tempest-integrated-object-storage ",,780,778
openstack%2Ftripleo-heat-templates~master~Id2eefeb1276bc49c289477eba01cb09e5416671d,openstack/tripleo-heat-templates,master,Id2eefeb1276bc49c289477eba01cb09e5416671d,[PowerFlex/VxFlex OS] Fix typos in resource names,ABANDONED,2020-11-09 02:31:51.000000000,2020-12-02 01:56:26.000000000,,"[{'_account_id': 7160}, {'_account_id': 13671}, {'_account_id': 14624}, {'_account_id': 17558}, {'_account_id': 18575}, {'_account_id': 21129}, {'_account_id': 22348}, {'_account_id': 23181}, {'_account_id': 31779}]","[{'number': 1, 'created': '2020-11-09 02:31:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/1abe2034e71bd64d6f08bba5eecd934282d3cf71', 'message': '[PowerFlex/VxFlex OS] Fix typos in resource names\n\nThe PowerFlex and VxFlex OS resource names have typos.\nThis change fixes the issue.\n\nChange-Id: Id2eefeb1276bc49c289477eba01cb09e5416671d\n'}, {'number': 2, 'created': '2020-11-10 04:09:18.000000000', 'files': ['environments/cinder-dellemc-vxflexos-config.yaml', 'environments/cinder-dellemc-powerflex-config.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/771fb063f2093dfbb06c28b8e9189c248e27bd2d', 'message': '[PowerFlex/VxFlex OS] Fix typos in resource names\n\nThe PowerFlex and VxFlex OS resource names have typos.\nThis change fixes the issue.\n\nChange-Id: Id2eefeb1276bc49c289477eba01cb09e5416671d\nCloses-Bug: #1903634\n'}]",0,761849,771fb063f2093dfbb06c28b8e9189c248e27bd2d,19,9,2,14624,,,0,"[PowerFlex/VxFlex OS] Fix typos in resource names

The PowerFlex and VxFlex OS resource names have typos.
This change fixes the issue.

Change-Id: Id2eefeb1276bc49c289477eba01cb09e5416671d
Closes-Bug: #1903634
",git fetch https://review.opendev.org/openstack/tripleo-heat-templates refs/changes/49/761849/2 && git format-patch -1 --stdout FETCH_HEAD,"['environments/cinder-dellemc-vxflexos-config.yaml', 'environments/cinder-dellemc-powerflex-config.yaml']",2,1abe2034e71bd64d6f08bba5eecd934282d3cf71,bug/1903634, OS::TripleO::Services::CinderBackendDellEMCPowerFlex: ../deployment/cinder/cinder-backend-dellemc-powerflex-puppet.yaml, OS::TripleO::Services::CinderBackendPowerFlex: ../deployment/cinder/cinder-backend-dellemc-powerflex-puppet.yaml,2,2
openstack%2Ftripleo-heat-templates~master~I0b2f28cd3d92795802e51c69d975826af0ee86ee,openstack/tripleo-heat-templates,master,I0b2f28cd3d92795802e51c69d975826af0ee86ee,Run os-net-config on step 3,MERGED,2020-11-24 21:28:14.000000000,2020-12-02 00:43:21.000000000,2020-12-02 00:43:21.000000000,"[{'_account_id': 6816}, {'_account_id': 6926}, {'_account_id': 8297}, {'_account_id': 11166}, {'_account_id': 14985}, {'_account_id': 22348}, {'_account_id': 23181}, {'_account_id': 26343}]","[{'number': 1, 'created': '2020-11-24 21:28:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/903f4acfab0e26242729b64d26bdd25c09ebc417', 'message': 'Run os-net-config on step 3\n\nIn some cases such as RHEL7>RHEL8 upgrade leapp or NetworkManager may\nchange resolv.conf. This patch invokes os-net-config on step3 to ensure\nthat network parts are configured properly (interfaces, resolv.conf).\nSince os-net-config is idempotant it causes no harm or packet loss to\nundercloud.\n\nChange-Id: I0b2f28cd3d92795802e51c69d975826af0ee86ee\nResolves: rhbz#1870617\n'}, {'number': 2, 'created': '2020-11-25 10:39:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/a66ecf3e47e7c0f0ecd0cfdf763e0999a4fdc0d5', 'message': 'Run os-net-config on step 3\n\nIn some cases such as RHEL7>RHEL8 upgrade leapp or NetworkManager may\nchange resolv.conf. This patch invokes os-net-config on step3 to ensure\nthat network parts are configured properly (interfaces, resolv.conf).\nSince os-net-config is idempotant it causes no harm or packet loss to\nundercloud.\n\nChange-Id: I0b2f28cd3d92795802e51c69d975826af0ee86ee\nResolves: rhbz#1870617\n'}, {'number': 3, 'created': '2020-11-26 00:15:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/5c110479b463f37a2f6f5f1164345d72abb0de30', 'message': 'Run os-net-config on step 3\n\nIn some cases such as RHEL7>RHEL8 upgrade leapp or NetworkManager may\nchange resolv.conf. This patch invokes os-net-config on step3 to ensure\nthat network parts are configured properly (interfaces, resolv.conf).\nSince os-net-config is idempotant it causes no harm or packet loss to\nundercloud.\n\nChange-Id: I0b2f28cd3d92795802e51c69d975826af0ee86ee\nResolves: rhbz#1870617\n'}, {'number': 4, 'created': '2020-11-26 00:23:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/847243ef6043f5a0a49030e8fde0bfa34392b603', 'message': 'Run os-net-config on step 3\n\nIn some cases such as RHEL7>RHEL8 upgrade leapp or NetworkManager may\nchange resolv.conf. This patch invokes os-net-config on step3 to ensure\nthat network parts are configured properly (interfaces, resolv.conf).\nSince os-net-config is idempotant it causes no harm or packet loss to\nundercloud.\n\nChange-Id: I0b2f28cd3d92795802e51c69d975826af0ee86ee\nResolves: rhbz#1870617\n'}, {'number': 5, 'created': '2020-11-26 18:29:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/b861dd8fb925b0007a46fd64710bdb20564a08ce', 'message': 'Run os-net-config on step 3\n\nIn some cases such as RHEL7>RHEL8 upgrade leapp or NetworkManager may\nchange resolv.conf. This patch invokes os-net-config on step3 to ensure\nthat network parts are configured properly (interfaces, resolv.conf).\nSince os-net-config is idempotant it causes no harm or packet loss to\nundercloud.\n\nChange-Id: I0b2f28cd3d92795802e51c69d975826af0ee86ee\nResolves: rhbz#1870617\n'}, {'number': 6, 'created': '2020-11-27 12:48:29.000000000', 'files': ['deployment/undercloud/undercloud-upgrade.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/a4ed8120ff1b4aada84f2cbdb2bc231a77463fe1', 'message': 'Run os-net-config on step 3\n\nIn some cases such as RHEL7>RHEL8 upgrade leapp or NetworkManager may\nchange resolv.conf. This patch invokes os-net-config on step3 to ensure\nthat network parts are configured properly (interfaces, resolv.conf).\nSince os-net-config is idempotant it causes no harm or packet loss to\nundercloud.\n\nChange-Id: I0b2f28cd3d92795802e51c69d975826af0ee86ee\nResolves: rhbz#1870617\n'}]",9,764068,a4ed8120ff1b4aada84f2cbdb2bc231a77463fe1,30,8,6,11090,,,0,"Run os-net-config on step 3

In some cases such as RHEL7>RHEL8 upgrade leapp or NetworkManager may
change resolv.conf. This patch invokes os-net-config on step3 to ensure
that network parts are configured properly (interfaces, resolv.conf).
Since os-net-config is idempotant it causes no harm or packet loss to
undercloud.

Change-Id: I0b2f28cd3d92795802e51c69d975826af0ee86ee
Resolves: rhbz#1870617
",git fetch https://review.opendev.org/openstack/tripleo-heat-templates refs/changes/68/764068/6 && git format-patch -1 --stdout FETCH_HEAD,['deployment/undercloud/undercloud-upgrade.yaml'],1,903f4acfab0e26242729b64d26bdd25c09ebc417,fix_resolv_conf," - name: take new os-net-config parameters into account now when: step|int == 3 command: os-net-config --no-activate -c /etc/os-net-config/config.json -v --detailed-exit-codes register: os_net_config_upgrade failed_when: os_net_config_upgrade.rc not in [0,2] changed_when: os_net_config_upgrade.rc == 2",,6,0
openstack%2Foctavia~stable%2Ftrain~Ibc525d9a046a5ab7f090a942459d80a2df66ae2e,openstack/octavia,stable/train,Ibc525d9a046a5ab7f090a942459d80a2df66ae2e,Fix memory consumption issues with default connection_limit,MERGED,2020-08-24 09:25:55.000000000,2020-12-02 00:06:05.000000000,2020-12-02 00:04:18.000000000,"[{'_account_id': 6469}, {'_account_id': 7249}, {'_account_id': 11628}, {'_account_id': 22348}]","[{'number': 1, 'created': '2020-08-24 09:25:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/octavia/commit/fd5a036d407071085e0f6bb7f502dacab70a0eae', 'message': 'Fix memory consumption issues with default connection_limit\n\nWith 1.8.x releases, haproxy consumes a lot of memory when\nusing 1,000,000 as default connection_limit.\n\nThis commit introduces a new configuration option for the Amphora\nprovider: [haproxy_amphora].default_connection_limit (defaulted to\n50,000). This value is used when creating a listener with -1 (which is\nthe default) as connection_limit, or when unsetting connection_limit in\na listener.\nUpdating an existing listener by setting connection_limit to -1 also\nsets it to default_connection_limit.\n\nThe global connection_limit for a load balancer is the sum of the\nconnection_limit of the listeners, but it cannot be over\nHAPROXY_MAX_MAXCONN (which is still 1,000,000).\n\nStory: 2007794\nTask: 40046\n\nChange-Id: Ibc525d9a046a5ab7f090a942459d80a2df66ae2e\n(cherry picked from commit f4305e036c30b23588d7d1448448010b95c24069)\n(cherry picked from commit 242239a705b53eac4b5cace51bc5d5a2b4a12df6)\n'}, {'number': 2, 'created': '2020-09-09 09:36:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/octavia/commit/ad7dc6c26022fb1c3b4dc0b694f00ef859787fab', 'message': 'Fix memory consumption issues with default connection_limit\n\nWith 1.8.x releases, haproxy consumes a lot of memory when\nusing 1,000,000 as default connection_limit.\n\nThis commit introduces a new configuration option for the Amphora\nprovider: [haproxy_amphora].default_connection_limit (defaulted to\n50,000). This value is used when creating a listener with -1 (which is\nthe default) as connection_limit, or when unsetting connection_limit in\na listener.\nUpdating an existing listener by setting connection_limit to -1 also\nsets it to default_connection_limit.\n\nThe global connection_limit for a load balancer is the sum of the\nconnection_limit of the listeners, but it cannot be over\nHAPROXY_MAX_MAXCONN (which is still 1,000,000).\n\nStory: 2007794\nTask: 40046\n\nChange-Id: Ibc525d9a046a5ab7f090a942459d80a2df66ae2e\n(cherry picked from commit f4305e036c30b23588d7d1448448010b95c24069)\n(cherry picked from commit 242239a705b53eac4b5cace51bc5d5a2b4a12df6)\n'}, {'number': 3, 'created': '2020-12-01 19:41:26.000000000', 'files': ['api-ref/source/parameters.yaml', 'octavia/common/config.py', 'octavia/common/jinja/haproxy/combined_listeners/jinja_cfg.py', 'octavia/tests/unit/amphorae/backends/agent/api_server/test_haproxy_compatibility.py', 'octavia/common/constants.py', 'releasenotes/notes/new-default_connection_limit-config-option-3ed9f0ed6ec2b514.yaml', 'octavia/tests/functional/api/v2/test_load_balancer.py', 'octavia/tests/unit/common/jinja/haproxy/combined_listeners/test_jinja_cfg.py', 'etc/octavia.conf', 'octavia/tests/unit/common/sample_configs/sample_configs_combined.py'], 'web_link': 'https://opendev.org/openstack/octavia/commit/6ba8dc62b6b9e4aa01f77a39efd5eceb3fdc98a2', 'message': 'Fix memory consumption issues with default connection_limit\n\nWith 1.8.x releases, haproxy consumes a lot of memory when\nusing 1,000,000 as default connection_limit.\n\nThis commit introduces a new configuration option for the Amphora\nprovider: [haproxy_amphora].default_connection_limit (defaulted to\n50,000). This value is used when creating a listener with -1 (which is\nthe default) as connection_limit, or when unsetting connection_limit in\na listener.\nUpdating an existing listener by setting connection_limit to -1 also\nsets it to default_connection_limit.\n\nThe global connection_limit for a load balancer is the sum of the\nconnection_limit of the listeners, but it cannot be over\nHAPROXY_MAX_MAXCONN (which is still 1,000,000).\n\nStory: 2007794\nTask: 40046\n\nChange-Id: Ibc525d9a046a5ab7f090a942459d80a2df66ae2e\n(cherry picked from commit f4305e036c30b23588d7d1448448010b95c24069)\n(cherry picked from commit 242239a705b53eac4b5cace51bc5d5a2b4a12df6)\n'}]",0,747662,6ba8dc62b6b9e4aa01f77a39efd5eceb3fdc98a2,35,4,3,29244,,,0,"Fix memory consumption issues with default connection_limit

With 1.8.x releases, haproxy consumes a lot of memory when
using 1,000,000 as default connection_limit.

This commit introduces a new configuration option for the Amphora
provider: [haproxy_amphora].default_connection_limit (defaulted to
50,000). This value is used when creating a listener with -1 (which is
the default) as connection_limit, or when unsetting connection_limit in
a listener.
Updating an existing listener by setting connection_limit to -1 also
sets it to default_connection_limit.

The global connection_limit for a load balancer is the sum of the
connection_limit of the listeners, but it cannot be over
HAPROXY_MAX_MAXCONN (which is still 1,000,000).

Story: 2007794
Task: 40046

Change-Id: Ibc525d9a046a5ab7f090a942459d80a2df66ae2e
(cherry picked from commit f4305e036c30b23588d7d1448448010b95c24069)
(cherry picked from commit 242239a705b53eac4b5cace51bc5d5a2b4a12df6)
",git fetch https://review.opendev.org/openstack/octavia refs/changes/62/747662/1 && git format-patch -1 --stdout FETCH_HEAD,"['api-ref/source/parameters.yaml', 'octavia/common/config.py', 'octavia/common/jinja/haproxy/combined_listeners/jinja_cfg.py', 'octavia/common/constants.py', 'octavia/tests/unit/amphorae/backends/agent/api_server/test_haproxy_compatibility.py', 'releasenotes/notes/new-default_connection_limit-config-option-3ed9f0ed6ec2b514.yaml', 'octavia/tests/functional/api/v2/test_load_balancer.py', 'octavia/tests/unit/common/jinja/haproxy/combined_listeners/test_jinja_cfg.py', 'etc/octavia.conf', 'octavia/tests/unit/common/sample_configs/sample_configs_combined.py']",10,fd5a036d407071085e0f6bb7f502dacab70a0eae,," 'connection_limit': constants.HAPROXY_DEFAULT_MAXCONN, 'connection_limit': constants.HAPROXY_DEFAULT_MAXCONN, 'connection_limit': constants.HAPROXY_DEFAULT_MAXCONN, 'connection_limit': constants.HAPROXY_DEFAULT_MAXCONN, 'global_connection_limit': constants.HAPROXY_DEFAULT_MAXCONN, 'global_connection_limit': constants.HAPROXY_DEFAULT_MAXCONN, disabled_member=False, connection_limit=constants.DEFAULT_CONNECTION_LIMIT, maxconn=constants.HAPROXY_DEFAULT_MAXCONN) ""\n"").format(maxconn=constants.HAPROXY_DEFAULT_MAXCONN) maxconn=constants.HAPROXY_DEFAULT_MAXCONN)"," 'connection_limit': constants.HAPROXY_MAX_MAXCONN, 'connection_limit': constants.HAPROXY_MAX_MAXCONN, 'connection_limit': constants.HAPROXY_MAX_MAXCONN, 'connection_limit': constants.HAPROXY_MAX_MAXCONN, 'global_connection_limit': constants.HAPROXY_MAX_MAXCONN, 'global_connection_limit': constants.HAPROXY_MAX_MAXCONN, disabled_member=False, connection_limit=-1, maxconn=constants.HAPROXY_MAX_MAXCONN) ""\n"").format(maxconn=constants.HAPROXY_MAX_MAXCONN) maxconn=constants.HAPROXY_MAX_MAXCONN)",136,63
openstack%2Fopenstack-ansible-tests~stable%2Fussuri~Ice2bd1408f65ff4979c9c5244f0ca026e8c246e4,openstack/openstack-ansible-tests,stable/ussuri,Ice2bd1408f65ff4979c9c5244f0ca026e8c246e4,Apply OSA global-requirements-pins during functional tests,MERGED,2020-12-01 16:04:46.000000000,2020-12-01 23:59:28.000000000,2020-12-01 23:57:54.000000000,"[{'_account_id': 22348}, {'_account_id': 25023}, {'_account_id': 28619}]","[{'number': 1, 'created': '2020-12-01 16:04:46.000000000', 'files': ['test-vars.yml'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-tests/commit/1d8091b95f8b4fe97a2d508b8dd9c42f6b7877e5', 'message': 'Apply OSA global-requirements-pins during functional tests\n\nChange-Id: Ice2bd1408f65ff4979c9c5244f0ca026e8c246e4\n(cherry picked from commit aaecefaee91d468f6f96cac26bc8a119d5fd2dca)\n'}]",0,764895,1d8091b95f8b4fe97a2d508b8dd9c42f6b7877e5,8,3,1,25023,,,0,"Apply OSA global-requirements-pins during functional tests

Change-Id: Ice2bd1408f65ff4979c9c5244f0ca026e8c246e4
(cherry picked from commit aaecefaee91d468f6f96cac26bc8a119d5fd2dca)
",git fetch https://review.opendev.org/openstack/openstack-ansible-tests refs/changes/95/764895/1 && git format-patch -1 --stdout FETCH_HEAD,['test-vars.yml'],1,1d8091b95f8b4fe97a2d508b8dd9c42f6b7877e5,,"# apply openstack-ansible global constraints for python_venv_build _global_pins_file_url: ""https://opendev.org/openstack/openstack-ansible/raw/{{ test_branch }}/global-requirement-pins.txt"" venv_build_global_constraints: >- {{ lookup('url', _global_pins_file_url, wantlist=True) | reject('match','^#.*$') | reject('equalto', '') | list }} ",,6,0
openstack%2Fopenstack-ansible-tests~stable%2Ftrain~Ice2bd1408f65ff4979c9c5244f0ca026e8c246e4,openstack/openstack-ansible-tests,stable/train,Ice2bd1408f65ff4979c9c5244f0ca026e8c246e4,Apply OSA global-requirements-pins during functional tests,MERGED,2020-12-01 16:09:40.000000000,2020-12-01 23:59:06.000000000,2020-12-01 23:57:50.000000000,"[{'_account_id': 22348}, {'_account_id': 25023}, {'_account_id': 28619}]","[{'number': 1, 'created': '2020-12-01 16:09:40.000000000', 'files': ['test-vars.yml'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-tests/commit/993bf361781ab263701bf1c5b7ff3ffe1d8d5d8f', 'message': 'Apply OSA global-requirements-pins during functional tests\n\nChange-Id: Ice2bd1408f65ff4979c9c5244f0ca026e8c246e4\n(cherry picked from commit aaecefaee91d468f6f96cac26bc8a119d5fd2dca)\n'}]",0,764976,993bf361781ab263701bf1c5b7ff3ffe1d8d5d8f,8,3,1,25023,,,0,"Apply OSA global-requirements-pins during functional tests

Change-Id: Ice2bd1408f65ff4979c9c5244f0ca026e8c246e4
(cherry picked from commit aaecefaee91d468f6f96cac26bc8a119d5fd2dca)
",git fetch https://review.opendev.org/openstack/openstack-ansible-tests refs/changes/76/764976/1 && git format-patch -1 --stdout FETCH_HEAD,['test-vars.yml'],1,993bf361781ab263701bf1c5b7ff3ffe1d8d5d8f,,"# apply openstack-ansible global constraints for python_venv_build _global_pins_file_url: ""https://opendev.org/openstack/openstack-ansible/raw/{{ test_branch }}/global-requirement-pins.txt"" venv_build_global_constraints: >- {{ lookup('url', _global_pins_file_url, wantlist=True) | reject('match','^#.*$') | reject('equalto', '') | list }} ",,6,0
openstack%2Ftacker~master~Ibf71848d0feca6e0c5c244fbc20d3b6d007d45b3,openstack/tacker,master,Ibf71848d0feca6e0c5c244fbc20d3b6d007d45b3,Fix the alembic migration for vnf_software_images column types,MERGED,2020-11-10 14:32:00.000000000,2020-12-01 23:57:03.000000000,2020-11-11 12:27:45.000000000,"[{'_account_id': 4149}, {'_account_id': 17255}, {'_account_id': 22348}, {'_account_id': 25701}, {'_account_id': 26222}, {'_account_id': 31072}, {'_account_id': 32102}, {'_account_id': 32395}]","[{'number': 1, 'created': '2020-11-10 14:32:00.000000000', 'files': ['tacker/db/migration/alembic_migrations/versions/HEAD', 'tacker/db/migration/alembic_migrations/versions/329cd1619d41_alter_vnf_software_images.py'], 'web_link': 'https://opendev.org/openstack/tacker/commit/7b5464e5a8e9d653b4a81fbde16127406f3b8beb', 'message': 'Fix the alembic migration for vnf_software_images column types\n\nChange 731636 [1] was merged without merging the alembic branches nor\nupdating the source revision. Precisely speaking, when the Patch Set\n12 for Change 731636 [1] was rebased to the master branch, the source\ncode gets to contain the migration file for Change 756703 [2], though\nno proper fix has been done. Afterwards the migration ""alter min_ram,\nmin_disk columns of vnf_software_images"" becomes ignored.\n\n[1]: https://review.opendev.org/#/c/731636\n[2]: https://review.opendev.org/#/c/756703/\n\nChange-Id: Ibf71848d0feca6e0c5c244fbc20d3b6d007d45b3\n'}]",0,762149,7b5464e5a8e9d653b4a81fbde16127406f3b8beb,16,8,1,32395,,,0,"Fix the alembic migration for vnf_software_images column types

Change 731636 [1] was merged without merging the alembic branches nor
updating the source revision. Precisely speaking, when the Patch Set
12 for Change 731636 [1] was rebased to the master branch, the source
code gets to contain the migration file for Change 756703 [2], though
no proper fix has been done. Afterwards the migration ""alter min_ram,
min_disk columns of vnf_software_images"" becomes ignored.

[1]: https://review.opendev.org/#/c/731636
[2]: https://review.opendev.org/#/c/756703/

Change-Id: Ibf71848d0feca6e0c5c244fbc20d3b6d007d45b3
",git fetch https://review.opendev.org/openstack/tacker refs/changes/49/762149/1 && git format-patch -1 --stdout FETCH_HEAD,"['tacker/db/migration/alembic_migrations/versions/HEAD', 'tacker/db/migration/alembic_migrations/versions/329cd1619d41_alter_vnf_software_images.py']",2,7b5464e5a8e9d653b4a81fbde16127406f3b8beb,fix-alembic-migration,Revises: d25c7c865ce8down_revision = 'd25c7c865ce8',Revises: d2e39e01d540down_revision = '329cd1619d41',3,3
openstack%2Fnova~stable%2Fvictoria~Ifd19f636f58ae353d912bde57cba2cd0a29a9baa,openstack/nova,stable/victoria,Ifd19f636f58ae353d912bde57cba2cd0a29a9baa,Fix a hacking test,MERGED,2020-10-14 12:57:04.000000000,2020-12-01 23:56:03.000000000,2020-12-01 23:53:22.000000000,"[{'_account_id': 10135}, {'_account_id': 17685}, {'_account_id': 22348}, {'_account_id': 26515}, {'_account_id': 29963}, {'_account_id': 32291}]","[{'number': 1, 'created': '2020-10-14 12:57:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/5c1493d0590618386e154e3cb740d6c75330e534', 'message': 'Fix a hacking test\n\nIn test_useless_assertion,\nthe useless_assertion method should be checked instead of\nnonexistent_assertion_methods_and_attributes.\n\nChange-Id: Ifd19f636f58ae353d912bde57cba2cd0a29a9baa\nSigned-off-by: Takashi Natsume <takanattie@gmail.com>\n(cherry picked from commit 117508129461436e13c148bb068b0775d67e85d3)\n'}, {'number': 2, 'created': '2020-11-04 15:02:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/53f9a7b53c019d1cf006e101294c080e7d79ea07', 'message': 'Fix a hacking test\n\nIn test_useless_assertion,\nthe useless_assertion method should be checked instead of\nnonexistent_assertion_methods_and_attributes.\n\nChange-Id: Ifd19f636f58ae353d912bde57cba2cd0a29a9baa\nSigned-off-by: Takashi Natsume <takanattie@gmail.com>\n(cherry picked from commit 117508129461436e13c148bb068b0775d67e85d3)\n'}, {'number': 3, 'created': '2020-11-11 12:54:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/0facd7318460a322c0146dfceaeff979c976209a', 'message': 'Fix a hacking test\n\nIn test_useless_assertion,\nthe useless_assertion method should be checked instead of\nnonexistent_assertion_methods_and_attributes.\n\nChange-Id: Ifd19f636f58ae353d912bde57cba2cd0a29a9baa\nSigned-off-by: Takashi Natsume <takanattie@gmail.com>\n(cherry picked from commit 117508129461436e13c148bb068b0775d67e85d3)\n'}, {'number': 4, 'created': '2020-11-28 01:38:55.000000000', 'files': ['nova/tests/unit/test_hacking.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/f4d62e1a0b77f9611a3be8427adafd96caf24bb1', 'message': 'Fix a hacking test\n\nIn test_useless_assertion,\nthe useless_assertion method should be checked instead of\nnonexistent_assertion_methods_and_attributes.\n\nChange-Id: Ifd19f636f58ae353d912bde57cba2cd0a29a9baa\nSigned-off-by: Takashi Natsume <takanattie@gmail.com>\n(cherry picked from commit 117508129461436e13c148bb068b0775d67e85d3)\n'}]",0,758112,f4d62e1a0b77f9611a3be8427adafd96caf24bb1,26,6,4,7634,,,0,"Fix a hacking test

In test_useless_assertion,
the useless_assertion method should be checked instead of
nonexistent_assertion_methods_and_attributes.

Change-Id: Ifd19f636f58ae353d912bde57cba2cd0a29a9baa
Signed-off-by: Takashi Natsume <takanattie@gmail.com>
(cherry picked from commit 117508129461436e13c148bb068b0775d67e85d3)
",git fetch https://review.opendev.org/openstack/nova refs/changes/12/758112/1 && git format-patch -1 --stdout FETCH_HEAD,['nova/tests/unit/test_hacking.py'],1,5c1493d0590618386e154e3cb740d6c75330e534,fix_hacking_test," code, checks.useless_assertion,"," code, checks.nonexistent_assertion_methods_and_attributes,",1,1
openstack%2Fnova~stable%2Ftrain~Ibbd4bd26408328b9e1a1128b3794721405631193,openstack/nova,stable/train,Ibbd4bd26408328b9e1a1128b3794721405631193,Change default num_retries for glance to 3,MERGED,2020-11-13 04:11:43.000000000,2020-12-01 23:55:50.000000000,2020-12-01 23:53:04.000000000,"[{'_account_id': 4690}, {'_account_id': 10118}, {'_account_id': 10135}, {'_account_id': 17685}, {'_account_id': 22348}, {'_account_id': 25613}, {'_account_id': 26515}, {'_account_id': 29963}, {'_account_id': 32291}]","[{'number': 1, 'created': '2020-11-13 04:11:43.000000000', 'files': ['releasenotes/notes/increase_glance_num_retries-ddfcd7053631882b.yaml', 'nova/conf/glance.py', 'nova/tests/unit/virt/xenapi/test_vm_utils.py', 'nova/tests/unit/virt/xenapi/image/test_glance.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/ca2fd8098a47cf2c38351dc4c8c65c7c5fe0afc3', 'message': 'Change default num_retries for glance to 3\n\nPreviously, the default value of num_retries for glance is 0.\nIt means that the request to glance is sent only one time.\nOn the other hand, neutron and cinder clients set the default\nvalue to 3.\nTo align the default value for retry to other components, we\nshould change the default value to 3.\n\nCloses-Bug: #1888168\nChange-Id: Ibbd4bd26408328b9e1a1128b3794721405631193\n(cherry picked from commit 662af9fab6eacb46bcaee38d076d33c2c0f82b9b)\n(cherry picked from commit 1f9dd694b937cc55a81a64fdce442829f009afb3)\n'}]",0,762610,ca2fd8098a47cf2c38351dc4c8c65c7c5fe0afc3,17,9,1,25613,,,0,"Change default num_retries for glance to 3

Previously, the default value of num_retries for glance is 0.
It means that the request to glance is sent only one time.
On the other hand, neutron and cinder clients set the default
value to 3.
To align the default value for retry to other components, we
should change the default value to 3.

Closes-Bug: #1888168
Change-Id: Ibbd4bd26408328b9e1a1128b3794721405631193
(cherry picked from commit 662af9fab6eacb46bcaee38d076d33c2c0f82b9b)
(cherry picked from commit 1f9dd694b937cc55a81a64fdce442829f009afb3)
",git fetch https://review.opendev.org/openstack/nova refs/changes/10/762610/1 && git format-patch -1 --stdout FETCH_HEAD,"['releasenotes/notes/increase_glance_num_retries-ddfcd7053631882b.yaml', 'nova/conf/glance.py', 'nova/tests/unit/virt/xenapi/test_vm_utils.py', 'nova/tests/unit/virt/xenapi/image/test_glance.py']",4,ca2fd8098a47cf2c38351dc4c8c65c7c5fe0afc3,increase_glance_num_retries-stable/train," self.session, 3, mock.ANY, mock.ANY, 'fake_image_uuid', self.session, 3, mock.ANY, mock.ANY, 'fake_image_uuid', self.session, 3, mock.ANY, mock.ANY, 'fake_image_uuid', self.session, 3, mock.ANY, mock.ANY, 'fake_image_uuid', self.session, 3, mock.ANY, mock.ANY, 'fake_image_uuid', self.session, 3, mock.ANY, mock.ANY, 'fake_image_uuid',"," self.session, 0, mock.ANY, mock.ANY, 'fake_image_uuid', self.session, 0, mock.ANY, mock.ANY, 'fake_image_uuid', self.session, 0, mock.ANY, mock.ANY, 'fake_image_uuid', self.session, 0, mock.ANY, mock.ANY, 'fake_image_uuid', self.session, 0, mock.ANY, mock.ANY, 'fake_image_uuid', self.session, 0, mock.ANY, mock.ANY, 'fake_image_uuid',",19,8
openstack%2Frequirements~master~I0fca8d724c431e006dd05d1251a65c88146e58df,openstack/requirements,master,I0fca8d724c431e006dd05d1251a65c88146e58df,Remove the qinling deliverables from req,MERGED,2020-11-28 02:10:22.000000000,2020-12-01 23:55:43.000000000,2020-12-01 23:53:42.000000000,"[{'_account_id': 11904}, {'_account_id': 14288}, {'_account_id': 22348}]","[{'number': 1, 'created': '2020-11-28 02:10:22.000000000', 'files': ['global-requirements.txt', 'projects.txt', 'upper-constraints.txt'], 'web_link': 'https://opendev.org/openstack/requirements/commit/fec5f64f3945346b8395b4d21f475350b2299c31', 'message': ""Remove the qinling deliverables from req\n\nQinling deliverables are going to be retired in Wallaby[1],\nso let's stop syncing the qinling deveilerables req.\n\n[1] http://lists.openstack.org/pipermail/openstack-discuss/2020-November/018638.html\n\nChange-Id: I0fca8d724c431e006dd05d1251a65c88146e58df\n""}]",0,764517,fec5f64f3945346b8395b4d21f475350b2299c31,12,3,1,8556,,,0,"Remove the qinling deliverables from req

Qinling deliverables are going to be retired in Wallaby[1],
so let's stop syncing the qinling deveilerables req.

[1] http://lists.openstack.org/pipermail/openstack-discuss/2020-November/018638.html

Change-Id: I0fca8d724c431e006dd05d1251a65c88146e58df
",git fetch https://review.opendev.org/openstack/requirements refs/changes/17/764517/1 && git format-patch -1 --stdout FETCH_HEAD,"['global-requirements.txt', 'projects.txt', 'upper-constraints.txt']",3,fec5f64f3945346b8395b4d21f475350b2299c31,retire-qinling,,python-qinlingclient===5.1.1,0,5
openstack%2Fpython-openstackclient~stable%2Fqueens~I08f785dc9e840da2e16915683eecfe49189c44b3,openstack/python-openstackclient,stable/queens,I08f785dc9e840da2e16915683eecfe49189c44b3,Fix the `role implies list` command.,MERGED,2018-09-26 09:23:15.000000000,2020-12-01 23:22:59.000000000,2020-12-01 23:22:59.000000000,"[{'_account_id': 4978}, {'_account_id': 6482}, {'_account_id': 10413}, {'_account_id': 11904}, {'_account_id': 22348}]","[{'number': 1, 'created': '2018-09-26 09:23:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-openstackclient/commit/fe3a3da3264f5e726f1f2e77041b46787954c598', 'message': 'Fix the `role implies list` command.\n\nThe code was calling an unexisting function which never existed.\nThe module refers now to the correct `InferenceRuleManager`. It\nalso allows the compatibility with the future python-keystoneclient\nin which the compatibility method will be removed from the\nRoleManager.\n\nConflicts:\n    openstackclient/tests/unit/identity/v3/fakes.py\n\nStory: 2003877\nTask: 26736\n\nChange-Id: I08f785dc9e840da2e16915683eecfe49189c44b3\n(cherry picked from commit 08dbd154e5da266e44f44386f711a3177e9061bd)\n'}, {'number': 2, 'created': '2018-09-26 13:22:48.000000000', 'files': ['openstackclient/tests/functional/identity/v3/test_role.py', 'openstackclient/identity/v3/implied_role.py', 'openstackclient/tests/unit/identity/v3/test_implied_role.py', 'openstackclient/tests/unit/identity/v3/fakes.py', 'openstackclient/tests/functional/identity/v3/common.py'], 'web_link': 'https://opendev.org/openstack/python-openstackclient/commit/212e133e5b3e987b7824bb090e355d5b4cb589a4', 'message': 'Fix the `role implies list` command.\n\nThe code was calling an unexisting function which never existed.\nThe module refers now to the correct `InferenceRuleManager`. It\nalso allows the compatibility with the future python-keystoneclient\nin which the compatibility method will be removed from the\nRoleManager.\n\nConflicts:\n    openstackclient/tests/unit/identity/v3/fakes.py\n\nBackport note: Also changed the functional test test_implied_role_list\nto expect 1 items instead of 3, in line with Queens expectations. The\nadditional 2 implied roles were only added during Rocky in Keystone\nwith Ie18a269e3d1075d955fe494acaf634a393c6bd7b.\n\nStory: 2003877\nTask: 26736\n\nChange-Id: I08f785dc9e840da2e16915683eecfe49189c44b3\n(cherry picked from commit 08dbd154e5da266e44f44386f711a3177e9061bd)\n'}]",0,605375,212e133e5b3e987b7824bb090e355d5b4cb589a4,15,5,2,4978,,,0,"Fix the `role implies list` command.

The code was calling an unexisting function which never existed.
The module refers now to the correct `InferenceRuleManager`. It
also allows the compatibility with the future python-keystoneclient
in which the compatibility method will be removed from the
RoleManager.

Conflicts:
    openstackclient/tests/unit/identity/v3/fakes.py

Backport note: Also changed the functional test test_implied_role_list
to expect 1 items instead of 3, in line with Queens expectations. The
additional 2 implied roles were only added during Rocky in Keystone
with Ie18a269e3d1075d955fe494acaf634a393c6bd7b.

Story: 2003877
Task: 26736

Change-Id: I08f785dc9e840da2e16915683eecfe49189c44b3
(cherry picked from commit 08dbd154e5da266e44f44386f711a3177e9061bd)
",git fetch https://review.opendev.org/openstack/python-openstackclient refs/changes/75/605375/1 && git format-patch -1 --stdout FETCH_HEAD,"['openstackclient/tests/functional/identity/v3/test_role.py', 'openstackclient/identity/v3/implied_role.py', 'openstackclient/tests/unit/identity/v3/test_implied_role.py', 'openstackclient/tests/unit/identity/v3/fakes.py', 'openstackclient/tests/functional/identity/v3/common.py']",5,fe3a3da3264f5e726f1f2e77041b46787954c598,sb2003877," IMPLIED_ROLE_LIST_HEADERS = ['Prior Role ID', 'Prior Role Name', 'Implied Role ID', 'Implied Role Name'] def _create_dummy_implied_role(self, add_clean_up=True): role_name = self._create_dummy_role(add_clean_up) implied_role_name = self._create_dummy_role(add_clean_up) self.openstack( 'implied role create ' '--implied-role %(implied_role)s ' '%(role)s' % {'implied_role': implied_role_name, 'role': role_name}) return implied_role_name, role_name ",,63,15
openstack%2Fopenstack-ansible-os_neutron~master~I30b622341f377997919c5e1e4ceb01d1e38fb183,openstack/openstack-ansible-os_neutron,master,I30b622341f377997919c5e1e4ceb01d1e38fb183,Reduce number of processes on small systems,MERGED,2020-11-30 11:49:41.000000000,2020-12-01 23:14:54.000000000,2020-12-01 23:13:14.000000000,"[{'_account_id': 22348}, {'_account_id': 25023}, {'_account_id': 31542}]","[{'number': 1, 'created': '2020-11-30 11:49:41.000000000', 'files': ['defaults/main.yml'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_neutron/commit/4075fbacee890b4f1a78131c470e1ef7cae679f2', 'message': 'Reduce number of processes on small systems\n\nEven the most modest 4C/8T system would run with the maximum 16 processes\ndue to the calculation being VCPU*2.\n\nWe devide amount of CPUs to number of threads for hyperthreaded CPUs\n\nChange-Id: I30b622341f377997919c5e1e4ceb01d1e38fb183\n'}]",0,764644,4075fbacee890b4f1a78131c470e1ef7cae679f2,12,3,1,28619,,,0,"Reduce number of processes on small systems

Even the most modest 4C/8T system would run with the maximum 16 processes
due to the calculation being VCPU*2.

We devide amount of CPUs to number of threads for hyperthreaded CPUs

Change-Id: I30b622341f377997919c5e1e4ceb01d1e38fb183
",git fetch https://review.opendev.org/openstack/openstack-ansible-os_neutron refs/changes/44/764644/1 && git format-patch -1 --stdout FETCH_HEAD,['defaults/main.yml'],1,4075fbacee890b4f1a78131c470e1ef7cae679f2,api_threads,"neutron_rpc_workers: ""{{ [[(ansible_processor_vcpus//ansible_processor_threads_per_core)|default(1), 1] | max * 2, neutron_rpc_workers_max] | min }}""","neutron_rpc_workers: ""{{ [[ansible_processor_vcpus|default(2) // 2, 1] | max, neutron_rpc_workers_max] | min }}""",1,1
openstack%2Foctavia~master~If94b59e00282e8077711945917a208317767f78a,openstack/octavia,master,If94b59e00282e8077711945917a208317767f78a,Fix FD limit warning message in amphora,NEW,2020-11-27 11:37:07.000000000,2020-12-01 22:49:38.000000000,,"[{'_account_id': 1131}, {'_account_id': 22348}]","[{'number': 1, 'created': '2020-11-27 11:37:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/octavia/commit/cbb2938b7ef6c5c2f7f686926cbb71a366b37ea9', 'message': 'Fix FD limit warning message in amphora\n\nWhen loadbalancer has unlimited connection limit, amphora image will\nclaim on insufficient file limit. So during haproxy reload you can find\nthe following warning message in log [1]\n\nWe increase this limit to avoid this issue and make reload process clean\n\n[1] http://paste.openstack.org/show/800494/\n\nChange-Id: If94b59e00282e8077711945917a208317767f78a\n'}, {'number': 2, 'created': '2020-11-30 17:04:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/octavia/commit/8cf414b279f9329742235a822d3ded22d9a07b37', 'message': ""Fix FD limit warning message in amphora\n\nWhen loadbalancer has max connection limit, haproxy during reload\nwould claim on insufficent limits for it's operation.\n\nWe increase this limit to avoid this issue and make reload process clean\n\nCloses-Bug: #2008399\nChange-Id: If94b59e00282e8077711945917a208317767f78a\n""}, {'number': 3, 'created': '2020-12-01 14:58:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/octavia/commit/346e95e2d1f76c1382e955e2ab84bf692a44b306', 'message': ""Fix FD limit warning message in amphora\n\nWhen loadbalancer has max connection limit, haproxy during reload\nwould claim on insufficent limits for it's operation.\n\nWe increase this limit to avoid this issue and make reload process clean\n\nStory: 2008399\nChange-Id: If94b59e00282e8077711945917a208317767f78a\n""}, {'number': 4, 'created': '2020-12-01 19:59:39.000000000', 'files': ['octavia/amphorae/backends/agent/api_server/templates/systemd.conf.j2', 'elements/haproxy-octavia/post-install.d/20-haproxy-tune-kernel'], 'web_link': 'https://opendev.org/openstack/octavia/commit/71b6e34074d096e00f80cb0ba1bb4ef3b609594b', 'message': ""Fix FD limit warning message in amphora\n\nWhen loadbalancer has max connection limit, haproxy during reload\nwould claim on insufficent limits for it's operation.\n\nWe increase this limit to avoid this issue and make reload process clean\n\nStory: 2008399\nTask: 41332\nChange-Id: If94b59e00282e8077711945917a208317767f78a\n""}]",2,764448,71b6e34074d096e00f80cb0ba1bb4ef3b609594b,11,2,4,28619,,,0,"Fix FD limit warning message in amphora

When loadbalancer has max connection limit, haproxy during reload
would claim on insufficent limits for it's operation.

We increase this limit to avoid this issue and make reload process clean

Story: 2008399
Task: 41332
Change-Id: If94b59e00282e8077711945917a208317767f78a
",git fetch https://review.opendev.org/openstack/octavia refs/changes/48/764448/1 && git format-patch -1 --stdout FETCH_HEAD,"['octavia/amphorae/backends/agent/api_server/templates/systemd.conf.j2', 'elements/haproxy-octavia/post-install.d/20-haproxy-tune-kernel']",2,cbb2938b7ef6c5c2f7f686926cbb71a366b37ea9,,sysctl-write-value fs.file-max 2500040 sysctl-write-value fs.nr_open 2500040,sysctl-write-value fs.file-max 2097152 sysctl-write-value fs.nr_open 2097152,3,3
openstack%2Fpython-openstackclient~master~I4faea8a3d3aecb21ec535e55c238c71745fc68cb,openstack/python-openstackclient,master,I4faea8a3d3aecb21ec535e55c238c71745fc68cb,"Add NODE and HOST parameters in ""server create"" help text",MERGED,2018-08-15 07:49:10.000000000,2020-12-01 22:47:37.000000000,2020-12-01 22:46:10.000000000,"[{'_account_id': 15334}, {'_account_id': 22348}, {'_account_id': 26311}]","[{'number': 1, 'created': '2018-08-15 07:49:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-openstackclient/commit/18a472c42fa32bd8ce9c1e5a63ddfd5a2bf528ac', 'message': 'Add NODE and HOST parameters in ""server create"" help text\n\nAdd optional parameters ""NODE"" and ""HOST"" in the help text of the\nserver create comand for --availability-zone.\n\nChange-Id: I4faea8a3d3aecb21ec535e55c238c71745fc68cb\nTask: 24274\nStory: 2003313\n'}, {'number': 2, 'created': '2018-08-15 10:24:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-openstackclient/commit/58c8e9e833770698442b348526ffd4934bc74190', 'message': 'Add NODE and HOST parameters in ""server create"" help text\n\nAdd optional parameters ""NODE"" and ""HOST"" in the help text of the\nserver create comand for --availability-zone.\n\nChange-Id: I4faea8a3d3aecb21ec535e55c238c71745fc68cb\nTask: 24274\nStory: 2003313\n'}, {'number': 3, 'created': '2018-08-16 03:37:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-openstackclient/commit/8e9eff406948cb7b27f5dfb0a3f63ec4addb349c', 'message': 'Add NODE and HOST parameters in ""server create"" help text\n\nAdd optional parameters ""NODE"" and ""HOST"" in the help text of the\nserver create comand for --availability-zone.\n\nChange-Id: I4faea8a3d3aecb21ec535e55c238c71745fc68cb\nTask: 24274\nStory: 2003313\n'}, {'number': 4, 'created': '2018-09-25 11:42:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-openstackclient/commit/701a2b39f6f1dac353c78a96179327a09f004323', 'message': 'Add NODE and HOST parameters in ""server create"" help text\n\nAdd optional parameters ""NODE"" and ""HOST"" in the help text of the\nserver create comand for --availability-zone.\n\nCo-Authored-By: tianhui <tianhui@awcloud.com>\nChange-Id: I4faea8a3d3aecb21ec535e55c238c71745fc68cb\nTask: 24274\nStory: 2003313\n'}, {'number': 5, 'created': '2020-12-01 11:49:36.000000000', 'files': ['openstackclient/compute/v2/server.py'], 'web_link': 'https://opendev.org/openstack/python-openstackclient/commit/3e8968af3dc82715dc93e7e76209e1bdcbdb2c14', 'message': 'Add NODE and HOST parameters in ""server create"" help text\n\nAdd optional parameters ""NODE"" and ""HOST"" in the help text of the\nserver create comand for --availability-zone.\n\nCo-Authored-By: tianhui <tianhui@awcloud.com>\nChange-Id: I4faea8a3d3aecb21ec535e55c238c71745fc68cb\nTask: 24274\nStory: 2003313\n'}]",1,591944,3e8968af3dc82715dc93e7e76209e1bdcbdb2c14,18,3,5,25564,,,0,"Add NODE and HOST parameters in ""server create"" help text

Add optional parameters ""NODE"" and ""HOST"" in the help text of the
server create comand for --availability-zone.

Co-Authored-By: tianhui <tianhui@awcloud.com>
Change-Id: I4faea8a3d3aecb21ec535e55c238c71745fc68cb
Task: 24274
Story: 2003313
",git fetch https://review.opendev.org/openstack/python-openstackclient refs/changes/44/591944/5 && git format-patch -1 --stdout FETCH_HEAD,['openstackclient/compute/v2/server.py'],1,18a472c42fa32bd8ce9c1e5a63ddfd5a2bf528ac,story/2003313," help=_('Select an availability zone for the server.\n' 'HOST and NODE are optional parameters. Availability zone in the format\n ' '<zone-name>::<node-name>, <zone-name>:<host-name> or <zone-name>'),"," help=_('Select an availability zone for the server'),",3,1
openstack%2Fopenstack-ansible~master~Ie05e07624b204c92f02e05d6d8c8d02ab8ff9008,openstack/openstack-ansible,master,Ie05e07624b204c92f02e05d6d8c8d02ab8ff9008,Cover nova metadata with SSL,MERGED,2020-10-28 15:17:13.000000000,2020-12-01 22:41:58.000000000,2020-12-01 22:40:00.000000000,"[{'_account_id': 22348}, {'_account_id': 25023}, {'_account_id': 28619}, {'_account_id': 31542}]","[{'number': 1, 'created': '2020-10-28 15:17:13.000000000', 'files': ['inventory/group_vars/nova_all.yml', 'inventory/group_vars/all/nova.yml', 'inventory/group_vars/haproxy/haproxy.yml'], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/2fc0afec71393e82d45d82f964aaf90a029af360', 'message': 'Cover nova metadata with SSL\n\nWe should also cover nova metadata endpoint with SSL in case\nhaproxy_ssl_all_vips is set to true.\n\nThis also places nova_metadata_* variables under correct scope, since\nthe only place they are used is\nneutron hosts\n\nChange-Id: Ie05e07624b204c92f02e05d6d8c8d02ab8ff9008\n'}]",0,760165,2fc0afec71393e82d45d82f964aaf90a029af360,22,4,1,28619,,,0,"Cover nova metadata with SSL

We should also cover nova metadata endpoint with SSL in case
haproxy_ssl_all_vips is set to true.

This also places nova_metadata_* variables under correct scope, since
the only place they are used is
neutron hosts

Change-Id: Ie05e07624b204c92f02e05d6d8c8d02ab8ff9008
",git fetch https://review.opendev.org/openstack/openstack-ansible refs/changes/65/760165/1 && git format-patch -1 --stdout FETCH_HEAD,"['inventory/group_vars/nova_all.yml', 'inventory/group_vars/all/nova.yml', 'inventory/group_vars/haproxy/haproxy.yml']",3,2fc0afec71393e82d45d82f964aaf90a029af360,," haproxy_ssl: ""{{ haproxy_ssl_all_vips }}"" haproxy_ssl_all_vips: ""{{ haproxy_ssl_all_vips }}""", haproxy_ssl: False,4,5
openstack%2Ftripleo-heat-templates~stable%2Ftrain~I844f78c520d7b507d906faf7242e72dd717f9cb5,openstack/tripleo-heat-templates,stable/train,I844f78c520d7b507d906faf7242e72dd717f9cb5,Fix delegation with FreeIPA cleanup,MERGED,2020-08-12 19:31:53.000000000,2020-12-01 22:34:41.000000000,2020-08-18 02:28:50.000000000,"[{'_account_id': 3153}, {'_account_id': 5046}, {'_account_id': 9914}, {'_account_id': 9954}, {'_account_id': 14250}, {'_account_id': 20172}, {'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2020-08-12 19:31:53.000000000', 'files': ['deployment/ipa/ipaservices-baremetal-ansible.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/d0c5bcac80f30364aafbf63b3f75a302ffcca216', 'message': 'Fix delegation with FreeIPA cleanup\n\nPreviously, we were delegating the IPA cleanup role to the undercloud\nvia localhost. This is because the keytab used to authenticate to\nFreeIPA and perform the cleanup of host entries during scale down is on\nthe undercloud. However, when using train, ansible is invoked from the\nmistral container when using `delegate_to: localhost`. In this case,\nyou\'ll end up with a privilege escalation error:\n\n  ""sudo: unable to open /run/sudo/ts/mistral: Permission denied\\nsudo: a password is required\\n"",\n\nThis is because the mistral container doesn\'t have passwordless sudo,\nresulting in a failed privilege escalation.\n\nInstead, we should make sure we delegate this task to the Undercloud,\nwhere we know the tripleo-admin user is setup properly.\n\nChange-Id: I844f78c520d7b507d906faf7242e72dd717f9cb5\nRelated-Bug: 1891317\n(cherry picked from commit 1547fc8e30df3745c615d10653e9febbbb0d37bc)\n'}]",1,745956,d0c5bcac80f30364aafbf63b3f75a302ffcca216,19,8,1,5046,,,0,"Fix delegation with FreeIPA cleanup

Previously, we were delegating the IPA cleanup role to the undercloud
via localhost. This is because the keytab used to authenticate to
FreeIPA and perform the cleanup of host entries during scale down is on
the undercloud. However, when using train, ansible is invoked from the
mistral container when using `delegate_to: localhost`. In this case,
you'll end up with a privilege escalation error:

  ""sudo: unable to open /run/sudo/ts/mistral: Permission denied\nsudo: a password is required\n"",

This is because the mistral container doesn't have passwordless sudo,
resulting in a failed privilege escalation.

Instead, we should make sure we delegate this task to the Undercloud,
where we know the tripleo-admin user is setup properly.

Change-Id: I844f78c520d7b507d906faf7242e72dd717f9cb5
Related-Bug: 1891317
(cherry picked from commit 1547fc8e30df3745c615d10653e9febbbb0d37bc)
",git fetch https://review.opendev.org/openstack/tripleo-heat-templates refs/changes/56/745956/1 && git format-patch -1 --stdout FETCH_HEAD,['deployment/ipa/ipaservices-baremetal-ansible.yaml'],1,d0c5bcac80f30364aafbf63b3f75a302ffcca216,, delegate_to: Undercloud, delegate_to: localhost,1,1
openstack%2Fopenstack-ansible-os_senlin~master~I26947d70550426b13f1954a7b6c344e3c9a8176f,openstack/openstack-ansible-os_senlin,master,I26947d70550426b13f1954a7b6c344e3c9a8176f,Simplify service creation,MERGED,2020-11-30 12:47:11.000000000,2020-12-01 22:17:20.000000000,2020-12-01 22:15:07.000000000,"[{'_account_id': 22348}, {'_account_id': 25023}, {'_account_id': 28752}, {'_account_id': 31542}]","[{'number': 1, 'created': '2020-11-30 12:47:11.000000000', 'files': ['tasks/main.yml', 'doc/source/index.rst', 'tasks/senlin_service_setup.yml', 'defaults/main.yml'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_senlin/commit/3fafd5eea51c58891cb2f7640250f30cf4dd06ef', 'message': 'Simplify service creation\n\nSenlin docs [1] do not mention the requirement of the separate domain,\nso I suggest this part has been copy-pasted from heat role. So we drop\ncorrisponsive variables and code to simplify things and not create\nunnecessary structures. We also adjust required secrets to contain valid\nentries.\n\n[1] https://docs.openstack.org/senlin/latest/install/install-rdo.html#install-and-configure-components\n\nChange-Id: I26947d70550426b13f1954a7b6c344e3c9a8176f\n'}]",0,764661,3fafd5eea51c58891cb2f7640250f30cf4dd06ef,15,4,1,28619,,,0,"Simplify service creation

Senlin docs [1] do not mention the requirement of the separate domain,
so I suggest this part has been copy-pasted from heat role. So we drop
corrisponsive variables and code to simplify things and not create
unnecessary structures. We also adjust required secrets to contain valid
entries.

[1] https://docs.openstack.org/senlin/latest/install/install-rdo.html#install-and-configure-components

Change-Id: I26947d70550426b13f1954a7b6c344e3c9a8176f
",git fetch https://review.opendev.org/openstack/openstack-ansible-os_senlin refs/changes/61/764661/1 && git format-patch -1 --stdout FETCH_HEAD,"['tasks/main.yml', 'doc/source/index.rst', 'tasks/senlin_service_setup.yml', 'defaults/main.yml']",4,3fafd5eea51c58891cb2f7640250f30cf4dd06ef,, - senlin_oslomsg_rpc_password,## Stack senlin_stack_domain_admin: stack_domain_admin senlin_stack_owner_name: senlin_stack_owner senlin_stack_domain_description: Owns users and projects created by senlin senlin_stack_user_domain_name: senlin - senlin_rabbitmq_password,32,111
openstack%2Fnetworking-bagpipe~master~Ifedff9e638a077f3ea092fc82d48db12c777c816,openstack/networking-bagpipe,master,Ifedff9e638a077f3ea092fc82d48db12c777c816,"Implement ""modprobe"" using oslo.privsep",MERGED,2020-06-23 14:44:46.000000000,2020-12-01 22:14:33.000000000,2020-12-01 22:13:08.000000000,"[{'_account_id': 8313}, {'_account_id': 11975}, {'_account_id': 12021}, {'_account_id': 16688}, {'_account_id': 22348}]","[{'number': 1, 'created': '2020-06-23 14:44:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/networking-bagpipe/commit/fba2fdce87d92dea03b0fc08de7f2d18c47a11df', 'message': 'Implement ""modprobe"" using oslo.privsep\n\nRemove the use of oslo.rootwrap when executing ""modprobe"" commands\nand replace them with oslo.privsep.\n\nStory: #2007686\nTask: #39974\nChange-Id: Ifedff9e638a077f3ea092fc82d48db12c777c816\n'}, {'number': 2, 'created': '2020-06-24 08:21:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/networking-bagpipe/commit/c9a93d9282acbec8966b0a0dfabae71689e8959c', 'message': 'Implement ""modprobe"" using oslo.privsep\n\nRemove the use of oslo.rootwrap when executing ""modprobe"" commands\nand replace them with oslo.privsep.\n\nStory: #2007686\nTask: #39974\nChange-Id: Ifedff9e638a077f3ea092fc82d48db12c777c816\n'}, {'number': 3, 'created': '2020-07-01 09:54:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/networking-bagpipe/commit/6756b247e2f0bbbc4c4052e80690c3bcb0af3440', 'message': 'Implement ""modprobe"" using oslo.privsep\n\nRemove the use of oslo.rootwrap when executing ""modprobe"" commands\nand replace them with oslo.privsep.\n\nStory: #2007686\nTask: #39974\nChange-Id: Ifedff9e638a077f3ea092fc82d48db12c777c816\n'}, {'number': 4, 'created': '2020-07-01 15:44:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/networking-bagpipe/commit/34a05bb41183f7a11d1e5453e073c0406dd138ce', 'message': 'Implement ""modprobe"" using oslo.privsep\n\nRemove the use of oslo.rootwrap when executing ""modprobe"" commands\nand replace them with oslo.privsep.\n\nStory: #2007686\nTask: #40259\nChange-Id: Ifedff9e638a077f3ea092fc82d48db12c777c816\n'}, {'number': 5, 'created': '2020-10-12 09:54:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/networking-bagpipe/commit/95baacc856933d3c71bfc6b0cfcbcb3777ecc6dc', 'message': 'Implement ""modprobe"" using oslo.privsep\n\nRemove the use of oslo.rootwrap when executing ""modprobe"" commands\nand replace them with oslo.privsep.\n\nStory: #2007686\nTask: #40259\nChange-Id: Ifedff9e638a077f3ea092fc82d48db12c777c816\n'}, {'number': 6, 'created': '2020-10-13 09:14:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/networking-bagpipe/commit/3c32b95b527ddaaaaebc1a8bb381b846283519a5', 'message': 'Implement ""modprobe"" using oslo.privsep\n\nRemove the use of oslo.rootwrap when executing ""modprobe"" commands\nand replace them with oslo.privsep.\n\nStory: #2007686\nTask: #40259\nChange-Id: Ifedff9e638a077f3ea092fc82d48db12c777c816\n'}, {'number': 7, 'created': '2020-12-01 18:46:17.000000000', 'files': ['etc/bagpipe-bgp/rootwrap.d/linux-vxlan.filters', 'networking_bagpipe/tests/unit/privileged/test_privileged_utils.py', 'networking_bagpipe/bagpipe_bgp/vpn/evpn/linux_vxlan.py', 'networking_bagpipe/bagpipe_bgp/vpn/ipvpn/mpls_linux_dataplane.py', 'networking_bagpipe/privileged/privileged_utils.py'], 'web_link': 'https://opendev.org/openstack/networking-bagpipe/commit/fbda54e1601773f762439f7ce7c70ff97a5484b6', 'message': 'Implement ""modprobe"" using oslo.privsep\n\nRemove the use of oslo.rootwrap when executing ""modprobe"" commands\nand replace them with oslo.privsep.\n\nStory: #2007686\nTask: #40259\nChange-Id: Ifedff9e638a077f3ea092fc82d48db12c777c816\n'}]",0,737554,fbda54e1601773f762439f7ce7c70ff97a5484b6,25,5,7,8313,,,0,"Implement ""modprobe"" using oslo.privsep

Remove the use of oslo.rootwrap when executing ""modprobe"" commands
and replace them with oslo.privsep.

Story: #2007686
Task: #40259
Change-Id: Ifedff9e638a077f3ea092fc82d48db12c777c816
",git fetch https://review.opendev.org/openstack/networking-bagpipe refs/changes/54/737554/1 && git format-patch -1 --stdout FETCH_HEAD,"['networking_bagpipe/tests/unit/privileged/test_privileged_utils.py', 'networking_bagpipe/bagpipe_bgp/vpn/evpn/linux_vxlan.py', 'networking_bagpipe/bagpipe_bgp/vpn/ipvpn/mpls_linux_dataplane.py', 'networking_bagpipe/privileged/privileged_utils.py']",4,fba2fdce87d92dea03b0fc08de7f2d18c47a11df,privsep," @privileged.default_cmd.entrypoint def modprobe(module_name): """"""run modprobe command :param module_name: the name of the module to check with modprobe """""" cmd = ['modprobe', module_name] processutils.execute(*cmd, check_exit_code=True)",,31,6
openstack%2Fpython-openstackclient~master~I0d580fb1d34dd56740eb6d976caa795e0e951047,openstack/python-openstackclient,master,I0d580fb1d34dd56740eb6d976caa795e0e951047,Let autoprogram-cliff know who's running,MERGED,2019-10-31 23:42:52.000000000,2020-12-01 22:05:35.000000000,2020-12-01 22:03:55.000000000,"[{'_account_id': 14070}, {'_account_id': 15334}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-10-31 23:42:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-openstackclient/commit/55866c3654f9d7dc1c0e04ed10f22caaeff94a43', 'message': ""Let autoprogram-cliff know who's running\n\nThe autoprogram-cliff directive has a habit of producing text like\n\n  This command is provided by the $me plugin.\n\nwhich doesn't make any sense.\n\nCliff recently added a config option whereby consumers can let it know\nwho $me is so it can suppress that message where appropriate (while\nstill producing it for $plugin, as intended).\n\nDepends-On: https://review.opendev.org/692464\nChange-Id: I0d580fb1d34dd56740eb6d976caa795e0e951047\n""}, {'number': 2, 'created': '2020-12-01 11:54:59.000000000', 'files': ['doc/source/conf.py'], 'web_link': 'https://opendev.org/openstack/python-openstackclient/commit/284c38bcf2624c8b82d77f2eb5a2015822f21aa0', 'message': ""Let autoprogram-cliff know who's running\n\nThe autoprogram-cliff directive has a habit of producing text like\n\n  This command is provided by the $me plugin.\n\nwhich doesn't make any sense.\n\nCliff recently added a config option whereby consumers can let it know\nwho $me is so it can suppress that message where appropriate (while\nstill producing it for $plugin, as intended).\n\nDepends-On: https://review.opendev.org/692464\nChange-Id: I0d580fb1d34dd56740eb6d976caa795e0e951047\n""}]",1,692465,284c38bcf2624c8b82d77f2eb5a2015822f21aa0,10,3,2,14070,,,0,"Let autoprogram-cliff know who's running

The autoprogram-cliff directive has a habit of producing text like

  This command is provided by the $me plugin.

which doesn't make any sense.

Cliff recently added a config option whereby consumers can let it know
who $me is so it can suppress that message where appropriate (while
still producing it for $plugin, as intended).

Depends-On: https://review.opendev.org/692464
Change-Id: I0d580fb1d34dd56740eb6d976caa795e0e951047
",git fetch https://review.opendev.org/openstack/python-openstackclient refs/changes/65/692465/2 && git format-patch -1 --stdout FETCH_HEAD,['doc/source/conf.py'],1,55866c3654f9d7dc1c0e04ed10f22caaeff94a43,suppress-self-provided-command-text,"# Prevent cliff from generating ""This command is provided by the # python-openstackclient plugin."" autoprogram_cliff_app_dist_name = 'python-openstackclient'",,3,0
openstack%2Fgrenade~stable%2Ftrain~I8f976041e98502de4770ece8cb7f04a928e8f3d9,openstack/grenade,stable/train,I8f976041e98502de4770ece8cb7f04a928e8f3d9,Remove the trove-grenade job,MERGED,2020-11-18 14:18:59.000000000,2020-12-01 21:05:07.000000000,2020-12-01 20:58:30.000000000,"[{'_account_id': 8556}, {'_account_id': 22348}, {'_account_id': 30491}]","[{'number': 1, 'created': '2020-11-18 14:18:59.000000000', 'files': ['.zuul.yaml'], 'web_link': 'https://opendev.org/openstack/grenade/commit/da78382cd1faf58886442fd632cad33d852a9f4f', 'message': 'Remove the trove-grenade job\n\nThe job is only executed by the grenade experimental queue, but:\n\n- it is not run for changes in the trove respository (from\n  I49bd6c824b837d22d9f3945a3e8c2343c831b352) and when it was,\n  it was experimental anyway;\n- more important: trove has no grenade plugin,\n  so the test is probably not relevant;\n- as a side effect, this will allow us to remove\n  that legacy job completely, as a trove grenade\n  plugin may not arrive soon.\n\nConflicts:\n\t.zuul.yaml\nThe affected code had changed a bit since train (irrelevant-files)\nand the patch had to be adapted.\n\nChange-Id: I8f976041e98502de4770ece8cb7f04a928e8f3d9\n(cherry picked from commit a267f2d381916d73eaed6ff3a57ec14bb85e60fc)\n(cherry picked from commit f2c4fe2ba92c9bebdd63b1fcc12096ff8c1192a8)\n'}]",0,763190,da78382cd1faf58886442fd632cad33d852a9f4f,8,3,1,10459,,,0,"Remove the trove-grenade job

The job is only executed by the grenade experimental queue, but:

- it is not run for changes in the trove respository (from
  I49bd6c824b837d22d9f3945a3e8c2343c831b352) and when it was,
  it was experimental anyway;
- more important: trove has no grenade plugin,
  so the test is probably not relevant;
- as a side effect, this will allow us to remove
  that legacy job completely, as a trove grenade
  plugin may not arrive soon.

Conflicts:
	.zuul.yaml
The affected code had changed a bit since train (irrelevant-files)
and the patch had to be adapted.

Change-Id: I8f976041e98502de4770ece8cb7f04a928e8f3d9
(cherry picked from commit a267f2d381916d73eaed6ff3a57ec14bb85e60fc)
(cherry picked from commit f2c4fe2ba92c9bebdd63b1fcc12096ff8c1192a8)
",git fetch https://review.opendev.org/openstack/grenade refs/changes/90/763190/1 && git format-patch -1 --stdout FETCH_HEAD,['.zuul.yaml'],1,da78382cd1faf58886442fd632cad33d852a9f4f,native-zuulv3-migration,, - trove-grenade: irrelevant-files: *legacy-irrelevant-files,0,2
openstack%2Ftripleo-upgrade~stable%2Fvictoria~I7f30f5361773b96de13325f5038c89477b575e65,openstack/tripleo-upgrade,stable/victoria,I7f30f5361773b96de13325f5038c89477b575e65,Improve ping test coverage during update.,MERGED,2020-11-30 14:50:17.000000000,2020-12-01 20:39:38.000000000,2020-12-01 20:39:38.000000000,"[{'_account_id': 11090}, {'_account_id': 22348}, {'_account_id': 26343}]","[{'number': 1, 'created': '2020-11-30 14:50:17.000000000', 'files': ['tasks/common/create_l3_agent_connectivity_check_script.yml', 'templates/l3_agent_stop_ping.sh.j2', 'tasks/update/overcloud_update_run.yml', 'tasks/common/l3_agent_connectivity_check_start_script.yml', 'tasks/update/overcloud_update_run_role.yml', 'templates/l3_agent_wait_ping.sh.j2', 'defaults/main.yml', 'templates/l3_agent_start_ping.sh.j2'], 'web_link': 'https://opendev.org/openstack/tripleo-upgrade/commit/972c10aa38208ea57d677f91a1170a7d5be935aa', 'message': 'Improve ping test coverage during update.\n\nThe ping test starts at the beginning of the ""update run"" phase and\nstops after it finishes. This means after all roles has been updated.\n\nWith this patch we stop, test and restart the ping in-between each\nrole update.\n\nThis means:\n\n 1. that we detect error earlier;\n 2. we detect error related to new flow being created during update\n    run;\n\nThe point 2. was discovered to be an important test as ovn can have\nexisting flow still working, but new flow breaking. With this new\nbehavior for the ping test we catch such error.\n\nThe downside is that we have even more sensible to any % based testing\nas the same number of error will give you an higher percentage as we\nspend less time in the test for each run. This could be seen as\nanother improvement.\n\nWe\'re splitting the ping test into two stages so that if the ping\nfails to start (as it would be for this particular issue) we would\ndetect it immediately instead of waiting for the end of the run.\n\nWhen we doing batch update (all roles in parallel) we deactivate that\nmechanism and fall back to the previous one as there is no in-between\nrole step there.\n\nWe also prevent the stop ping from searching into all home\nsubdirectory as I had an issue in local testing where one subdirectory\nhad unreadable files (after a local podman run). This shouldn\'t happen\nin CI, but is good to have for local testing.\n\nChange-Id: I7f30f5361773b96de13325f5038c89477b575e65\n(cherry picked from commit a87fcb7ef4d6ce9b63d62d2f193594dfae1fd4d0)\n'}]",0,764680,972c10aa38208ea57d677f91a1170a7d5be935aa,7,3,1,8297,,,0,"Improve ping test coverage during update.

The ping test starts at the beginning of the ""update run"" phase and
stops after it finishes. This means after all roles has been updated.

With this patch we stop, test and restart the ping in-between each
role update.

This means:

 1. that we detect error earlier;
 2. we detect error related to new flow being created during update
    run;

The point 2. was discovered to be an important test as ovn can have
existing flow still working, but new flow breaking. With this new
behavior for the ping test we catch such error.

The downside is that we have even more sensible to any % based testing
as the same number of error will give you an higher percentage as we
spend less time in the test for each run. This could be seen as
another improvement.

We're splitting the ping test into two stages so that if the ping
fails to start (as it would be for this particular issue) we would
detect it immediately instead of waiting for the end of the run.

When we doing batch update (all roles in parallel) we deactivate that
mechanism and fall back to the previous one as there is no in-between
role step there.

We also prevent the stop ping from searching into all home
subdirectory as I had an issue in local testing where one subdirectory
had unreadable files (after a local podman run). This shouldn't happen
in CI, but is good to have for local testing.

Change-Id: I7f30f5361773b96de13325f5038c89477b575e65
(cherry picked from commit a87fcb7ef4d6ce9b63d62d2f193594dfae1fd4d0)
",git fetch https://review.opendev.org/openstack/tripleo-upgrade refs/changes/80/764680/1 && git format-patch -1 --stdout FETCH_HEAD,"['tasks/common/create_l3_agent_connectivity_check_script.yml', 'templates/l3_agent_stop_ping.sh.j2', 'tasks/update/overcloud_update_run.yml', 'tasks/common/l3_agent_connectivity_check_start_script.yml', 'tasks/update/overcloud_update_run_role.yml', 'templates/l3_agent_wait_ping.sh.j2', 'defaults/main.yml', 'templates/l3_agent_start_ping.sh.j2']",8,972c10aa38208ea57d677f91a1170a7d5be935aa,,,"# Block 1 minute for the fip to be ready. cpt=1 while ! ping -c 1 -w 1 ""${VM_IP}""; do echo ""Waiting for fip to be ready ... for $cpt seconds"" if [ $cpt -gt 60 ]; then echo ""The fip ${VM_IP} took more than 1 minute to be available, aborting"" exit 1 fi cpt=$((cpt+1)) done ",50,23
openstack%2Ftripleo-heat-templates~stable%2Ftrain~Ia6f6674444a40ca269c2defc6f839a5e65818603,openstack/tripleo-heat-templates,stable/train,Ia6f6674444a40ca269c2defc6f839a5e65818603,[TRAIN-ONLY] Fix tripleo-work-dir role name in ceph-base,MERGED,2020-11-25 09:18:03.000000000,2020-12-01 20:39:33.000000000,2020-12-01 20:39:33.000000000,"[{'_account_id': 6796}, {'_account_id': 8175}, {'_account_id': 8367}, {'_account_id': 8449}, {'_account_id': 9592}, {'_account_id': 13861}, {'_account_id': 14985}, {'_account_id': 18002}, {'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2020-11-25 09:18:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/29531ccfdbef9fcd7841d4d45099da19a9279bcd', 'message': '[TRAIN-ONLY] Fix tripleo-work-dir role name in ceph-base\n\nThis patch fixes the issue introduced by the change [1], where\nthe wrong tripleo-work-dir name is used.\n\n[1] https://review.opendev.org/q/1fafca733c995dc835cbe040c12d766e8ac02cd4\n\nCloses-Bug: #1905536\nDepends-On: I569732617bd74302529918a7f303f76ed0c2b23b\nChange-Id: Ia6f6674444a40ca269c2defc6f839a5e65818603\n'}, {'number': 2, 'created': '2020-11-25 09:21:27.000000000', 'files': ['deployment/ceph-ansible/ceph-base.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/43049567a778bd6b1f19931d2327356cd6741c79', 'message': '[TRAIN-ONLY] Fix tripleo-work-dir role name in ceph-base\n\nThis patch fixes the issue introduced by the change [1], where\nthe wrong tripleo-work-dir name is used.\n\n[1] https://review.opendev.org/q/1fafca733c995dc835cbe040c12d766e8ac02cd4\n\nCloses-Bug: #1905536\nDepends-On: I569732617bd74302529918a7f303f76ed0c2b23b\nDepends-On: Ib365e9dc18072e9e923762c522e3bc1d6ef6af0b\nChange-Id: Ia6f6674444a40ca269c2defc6f839a5e65818603\n'}]",0,764140,43049567a778bd6b1f19931d2327356cd6741c79,54,10,2,25402,,,0,"[TRAIN-ONLY] Fix tripleo-work-dir role name in ceph-base

This patch fixes the issue introduced by the change [1], where
the wrong tripleo-work-dir name is used.

[1] https://review.opendev.org/q/1fafca733c995dc835cbe040c12d766e8ac02cd4

Closes-Bug: #1905536
Depends-On: I569732617bd74302529918a7f303f76ed0c2b23b
Depends-On: Ib365e9dc18072e9e923762c522e3bc1d6ef6af0b
Change-Id: Ia6f6674444a40ca269c2defc6f839a5e65818603
",git fetch https://review.opendev.org/openstack/tripleo-heat-templates refs/changes/40/764140/2 && git format-patch -1 --stdout FETCH_HEAD,['deployment/ceph-ansible/ceph-base.yaml'],1,29531ccfdbef9fcd7841d4d45099da19a9279bcd,, name: tripleo-ceph-work-dir, name: tripleo_ceph_work_dir,1,1
openstack%2Fopenstack-helm-infra~master~I97a3cc0832554a31146cd2b6d86deb77fd73db41,openstack/openstack-helm-infra,master,I97a3cc0832554a31146cd2b6d86deb77fd73db41,Fluentd: Add Configurable Readiness and Liveness Probes,MERGED,2020-11-25 00:59:39.000000000,2020-12-01 20:24:52.000000000,2020-12-01 20:22:57.000000000,"[{'_account_id': 20466}, {'_account_id': 21420}, {'_account_id': 22348}, {'_account_id': 24780}, {'_account_id': 31479}, {'_account_id': 31713}]","[{'number': 1, 'created': '2020-11-25 00:59:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/5d009016dbacd009fa51a146effffc243f83eb94', 'message': 'Fluent: Add Configurable Readiness and Liveness Probes\n\nThis change adds the HTK probe function to the Fluentd Daemonset\n\nChange-Id: I97a3cc0832554a31146cd2b6d86deb77fd73db41\n'}, {'number': 2, 'created': '2020-11-25 01:06:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/08284133be24faef5902a86322fc38e61944561c', 'message': '[wip] Fluentd: Add Configurable Readiness and Liveness Probes\n\nThis change adds the HTK probe function to the Fluentd Daemonset\n\nChange-Id: I97a3cc0832554a31146cd2b6d86deb77fd73db41\n'}, {'number': 3, 'created': '2020-11-30 18:24:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/5dc7cb3890738afeed9ae7dc06e6161dca76fa48', 'message': 'Fluentd: Add Configurable Readiness and Liveness Probes\n\nThis change updates the fluentd chart to use HTK probe templates\nto allow configuration by value overrides\n\nChange-Id: I97a3cc0832554a31146cd2b6d86deb77fd73db41\n'}, {'number': 4, 'created': '2020-11-30 18:39:15.000000000', 'files': ['fluentd/templates/daemonset.yaml', 'fluentd/values.yaml', 'fluentd/Chart.yaml'], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/29489acf39a0d406a1ac0d1c78183917a508657e', 'message': 'Fluentd: Add Configurable Readiness and Liveness Probes\n\nThis change updates the fluentd chart to use HTK probe templates\nto allow configuration by value overrides\n\nChange-Id: I97a3cc0832554a31146cd2b6d86deb77fd73db41\n'}]",0,764106,29489acf39a0d406a1ac0d1c78183917a508657e,15,6,4,30777,,,0,"Fluentd: Add Configurable Readiness and Liveness Probes

This change updates the fluentd chart to use HTK probe templates
to allow configuration by value overrides

Change-Id: I97a3cc0832554a31146cd2b6d86deb77fd73db41
",git fetch https://review.opendev.org/openstack/openstack-helm-infra refs/changes/06/764106/1 && git format-patch -1 --stdout FETCH_HEAD,"['fluentd/templates/daemonset.yaml', 'fluentd/values.yaml', 'fluentd/Chart.yaml']",3,5d009016dbacd009fa51a146effffc243f83eb94,,appVersion: v1.10.1version: 0.1.2,appVersion: v1.0.0version: 0.1.1,23,18
openstack%2Fopenstack-ansible-os_panko~master~I91b62df6b54bb2e42c4b191c4a09ca4f2f854a75,openstack/openstack-ansible-os_panko,master,I91b62df6b54bb2e42c4b191c4a09ca4f2f854a75,Reduce number of processes on small systems,MERGED,2020-11-30 11:55:52.000000000,2020-12-01 20:20:21.000000000,2020-12-01 20:18:27.000000000,"[{'_account_id': 22348}, {'_account_id': 25023}, {'_account_id': 31542}]","[{'number': 1, 'created': '2020-11-30 11:55:52.000000000', 'files': ['defaults/main.yml'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_panko/commit/e7c77969469248d20d7764b91407a12b13422166', 'message': 'Reduce number of processes on small systems\n\nEven the most modest 4C/8T system would run with the maximum 16 processes\ndue to the calculation being VCPU*2.\n\nWe devide amount of CPUs to number of threads for hyperthreaded CPUs\n\nChange-Id: I91b62df6b54bb2e42c4b191c4a09ca4f2f854a75\n'}]",0,764648,e7c77969469248d20d7764b91407a12b13422166,12,3,1,28619,,,0,"Reduce number of processes on small systems

Even the most modest 4C/8T system would run with the maximum 16 processes
due to the calculation being VCPU*2.

We devide amount of CPUs to number of threads for hyperthreaded CPUs

Change-Id: I91b62df6b54bb2e42c4b191c4a09ca4f2f854a75
",git fetch https://review.opendev.org/openstack/openstack-ansible-os_panko refs/changes/48/764648/1 && git format-patch -1 --stdout FETCH_HEAD,['defaults/main.yml'],1,e7c77969469248d20d7764b91407a12b13422166,api_threads,"panko_wsgi_processes: ""{{ [[(ansible_processor_vcpus//ansible_processor_threads_per_core)|default(1), 1] | max * 2, panko_wsgi_processes_max] | min }}""","panko_wsgi_processes: ""{{ [[ansible_processor_vcpus|default(1), 1] | max * 2, panko_wsgi_processes_max] | min }}""",1,1
openstack%2Fopenstack-ansible-os_tempest~stable%2Fussuri~I639aa89e9ce4767b1bef790e3455ba3f2e6098b6,openstack/openstack-ansible-os_tempest,stable/ussuri,I639aa89e9ce4767b1bef790e3455ba3f2e6098b6,Switch tripleo jobs to content provider,MERGED,2020-11-02 20:36:07.000000000,2020-12-01 20:19:53.000000000,2020-12-01 20:14:52.000000000,"[{'_account_id': 8175}, {'_account_id': 8367}, {'_account_id': 10969}, {'_account_id': 12393}, {'_account_id': 22348}, {'_account_id': 25023}, {'_account_id': 28619}, {'_account_id': 30750}]","[{'number': 1, 'created': '2020-11-02 20:36:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_tempest/commit/5beead593c25c3d98a08db0de7e35c2ceaab782f', 'message': 'Switch tripleo jobs to content provider\n\nAnd remove docker.io pulls dependency.\n\nChange-Id: I639aa89e9ce4767b1bef790e3455ba3f2e6098b6\n'}, {'number': 2, 'created': '2020-11-06 13:55:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_tempest/commit/d25ef2b6f500cf9b387e325d4c4b14382ee7cf2f', 'message': 'Build containers for single consumer job\n\nMake standalone job build containers when there is one single\nconsumer job in layout. Do not run content provider jobs in\nthis case.\n\nChange-Id: I639aa89e9ce4767b1bef790e3455ba3f2e6098b6\n'}, {'number': 3, 'created': '2020-11-11 17:03:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_tempest/commit/22ae9e44b1c9c0b3d1cb77e51c028e6fcd50ccb0', 'message': 'Build containers for single consumer job\n\nMake standalone job build containers when there is one single\nconsumer job in layout. Do not run content provider jobs in\nthis case.\n\nChange-Id: I639aa89e9ce4767b1bef790e3455ba3f2e6098b6\n'}, {'number': 4, 'created': '2020-11-26 14:46:11.000000000', 'files': ['zuul.d/project.yaml', 'zuul.d/jobs.yaml'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_tempest/commit/4fbb0ff2acde78855965acb650c645f32deb9f97', 'message': 'Switch tripleo jobs to content provider\n\nAnd remove docker.io pulls dependency.\n\nChange-Id: I639aa89e9ce4767b1bef790e3455ba3f2e6098b6\n'}]",2,761019,4fbb0ff2acde78855965acb650c645f32deb9f97,30,8,4,8175,,,0,"Switch tripleo jobs to content provider

And remove docker.io pulls dependency.

Change-Id: I639aa89e9ce4767b1bef790e3455ba3f2e6098b6
",git fetch https://review.opendev.org/openstack/openstack-ansible-os_tempest refs/changes/19/761019/4 && git format-patch -1 --stdout FETCH_HEAD,['zuul.d/project.yaml'],1,5beead593c25c3d98a08db0de7e35c2ceaab782f,new-ci-job, - tripleo-ci-centos-8-content-provider - tripleo-ci-centos-8-standalone: &consumer_job vars: consumer_job: true build_container_images: false remove_tags: - build dependencies: - tripleo-ci-centos-8-content-provider - tripleo-ci-centos-8-content-provider - tripleo-ci-centos-8-standalone: *consumer_job, - tripleo-ci-centos-8-standalone - tripleo-ci-centos-8-standalone,11,2
openstack%2Fhorizon~master~Iac0e58500f553cdc7c558cb6d9c5d566f2696c6c,openstack/horizon,master,Iac0e58500f553cdc7c558cb6d9c5d566f2696c6c,Imported Translations from Zanata,MERGED,2020-11-25 07:25:50.000000000,2020-12-01 20:10:22.000000000,2020-12-01 20:06:43.000000000,"[{'_account_id': 841}, {'_account_id': 22348}, {'_account_id': 29313}]","[{'number': 1, 'created': '2020-11-25 07:25:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/c34b4a3d37704fc571bf0e714e2ab9f10c80e3ee', 'message': 'Imported Translations from Zanata\n\nFor more information about this automatic import see:\nhttps://docs.openstack.org/i18n/latest/reviewing-translation-import.html\n\nChange-Id: Iac0e58500f553cdc7c558cb6d9c5d566f2696c6c\n'}, {'number': 2, 'created': '2020-11-27 06:58:06.000000000', 'files': ['doc/source/locale/eo/LC_MESSAGES/doc-install.po', 'doc/source/locale/ko_KR/LC_MESSAGES/doc-install.po', 'doc/source/locale/en_GB/LC_MESSAGES/doc-install.po', 'releasenotes/source/locale/en_GB/LC_MESSAGES/releasenotes.po', 'doc/source/locale/id/LC_MESSAGES/doc-install.po', 'doc/source/locale/de/LC_MESSAGES/doc-install.po'], 'web_link': 'https://opendev.org/openstack/horizon/commit/02aa5dd7c8e195357a00c526d81a941ac07ba29f', 'message': 'Imported Translations from Zanata\n\nFor more information about this automatic import see:\nhttps://docs.openstack.org/i18n/latest/reviewing-translation-import.html\n\nChange-Id: Iac0e58500f553cdc7c558cb6d9c5d566f2696c6c\n'}]",0,764128,02aa5dd7c8e195357a00c526d81a941ac07ba29f,11,3,2,11131,,,0,"Imported Translations from Zanata

For more information about this automatic import see:
https://docs.openstack.org/i18n/latest/reviewing-translation-import.html

Change-Id: Iac0e58500f553cdc7c558cb6d9c5d566f2696c6c
",git fetch https://review.opendev.org/openstack/horizon refs/changes/28/764128/2 && git format-patch -1 --stdout FETCH_HEAD,['releasenotes/source/locale/en_GB/LC_MESSAGES/releasenotes.po'],1,c34b4a3d37704fc571bf0e714e2ab9f10c80e3ee,zanata/translations,"""POT-Creation-Date: 2020-11-24 11:54+0000\n""""PO-Revision-Date: 2020-11-24 02:41+0000\n""msgid ""18.6.0-40"" msgstr ""18.6.0-40""","""POT-Creation-Date: 2020-11-23 00:37+0000\n""""PO-Revision-Date: 2020-11-23 11:25+0000\n""msgid ""18.6.0-39"" msgstr ""18.6.0-39""",4,4
openstack%2Fhorizon~master~I032bfb10ce6cccfed63b963437392576c9fbb488,openstack/horizon,master,I032bfb10ce6cccfed63b963437392576c9fbb488,Add integration-test for Volume Group Type,MERGED,2020-08-24 10:47:52.000000000,2020-12-01 20:08:34.000000000,2020-12-01 20:06:32.000000000,"[{'_account_id': 841}, {'_account_id': 1736}, {'_account_id': 8648}, {'_account_id': 22348}, {'_account_id': 29313}]","[{'number': 1, 'created': '2020-08-24 10:47:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/c6f8f5c56152cbd2e0a8cec0b275fa094b1b6e5e', 'message': 'Add integration-test for Volume Group Type\n\nThis patch adds integration-tests for testing create/view/delete\nvolume group-type operation.\n\nChange-Id: I032bfb10ce6cccfed63b963437392576c9fbb488\nCloses-Bug: #1892679\n'}, {'number': 2, 'created': '2020-08-24 11:43:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/0f011f9ca75826c2fe1239af5e8ba66f40ab0c9e', 'message': 'Add integration-test for Volume Group Type\n\nThis patch adds integration-tests for testing create/view/delete\nvolume group-type operation.\n\nChange-Id: I032bfb10ce6cccfed63b963437392576c9fbb488\nCloses-Bug: #1892679\n'}, {'number': 3, 'created': '2020-08-24 11:51:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/7ab0ed384c53be6ecad51f6d11ffe69ff1291bdf', 'message': 'Add integration-test for Volume Group Type\n\nThis patch adds integration-tests for testing create/view/delete\nvolume group-type operation.\n\nChange-Id: I032bfb10ce6cccfed63b963437392576c9fbb488\nCloses-Bug: #1892679\n'}, {'number': 4, 'created': '2020-10-30 13:01:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/0cc115b8483772556d5ba1ec978c4417a33caa31', 'message': 'Add integration-test for Volume Group Type\n\nThis patch adds integration-tests for volume group-type.\n\nChange-Id: I032bfb10ce6cccfed63b963437392576c9fbb488\nCloses-Bug: #1892679\n'}, {'number': 5, 'created': '2020-11-26 11:06:45.000000000', 'files': ['openstack_dashboard/test/integration_tests/pages/navigation.py', 'openstack_dashboard/test/integration_tests/tests/test_grouptypes.py', 'openstack_dashboard/test/integration_tests/pages/admin/volume/grouptypespage.py'], 'web_link': 'https://opendev.org/openstack/horizon/commit/85d75107cf984b42b0192323bf41efba4609a07d', 'message': 'Add integration-test for Volume Group Type\n\nThis patch adds integration-tests for volume group-type.\n\nChange-Id: I032bfb10ce6cccfed63b963437392576c9fbb488\nCloses-Bug: #1892679\n'}]",4,747682,85d75107cf984b42b0192323bf41efba4609a07d,22,5,5,29313,,,0,"Add integration-test for Volume Group Type

This patch adds integration-tests for volume group-type.

Change-Id: I032bfb10ce6cccfed63b963437392576c9fbb488
Closes-Bug: #1892679
",git fetch https://review.opendev.org/openstack/horizon refs/changes/82/747682/2 && git format-patch -1 --stdout FETCH_HEAD,['openstack_dashboard/test/integration_tests/tests/test_grouptypes.py'],1,c6f8f5c56152cbd2e0a8cec0b275fa094b1b6e5e,bug/1892679,"# Licensed under the Apache License, Version 2.0 (the ""License""); you may # not use this file except in compliance with the License. You may obtain # a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT # WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the # License for the specific language governing permissions and limitations # under the License. from openstack_dashboard.test.integration_tests import helpers from openstack_dashboard.test.integration_tests.regions import messages class TestAdminGroupTypes(helpers.AdminTestCase): Group_TYPE_NAME = helpers.gen_random_resource_name(""group_type"") def test_group_type_create_delete(self): """"""This test case checks create, delete group type: Steps: 1. Login to Horizon Dashboard as admin user 2. Navigate to Admin -> Volume -> Group Types page 3. Create new group type 4. Check that the group type is in the list 5. Check that no Error messages present 6. Delete the group type 7. Check that the group type is absent in the list 8. Check that no Error messages present """""" group_types_page = self.home_pg.go_to_admin_volume_grouptypespage() group_types_page.create_group_type(self.GROUP_TYPE_NAME) self.assertTrue( group_types_page.find_message_and_dismiss(messages.SUCCESS)) self.assertFalse( group_types_page.find_message_and_dismiss(messages.ERROR)) self.assertTrue(group_types_page.is_group_type_present( self.GROUP_TYPE_NAME)) group_types_page.delete_group_type(self.GROUP_TYPE_NAME) self.assertTrue( group_types_page.find_message_and_dismiss(messages.SUCCESS)) self.assertFalse( group_types_page.find_message_and_dismiss(messages.ERROR)) self.assertTrue(group_types_page.is_group_type_deleted( self.GROUP_TYPE_NAME)) ",,47,0
openstack%2Fopenstack-ansible-os_neutron~master~I073da66f9e395bbb99b1c21701c808f252c3a6cb,openstack/openstack-ansible-os_neutron,master,I073da66f9e395bbb99b1c21701c808f252c3a6cb,Rename nova_metadata_* variables,MERGED,2020-10-28 14:27:03.000000000,2020-12-01 19:56:34.000000000,2020-12-01 19:55:08.000000000,"[{'_account_id': 22348}, {'_account_id': 25023}, {'_account_id': 28619}, {'_account_id': 29865}]","[{'number': 1, 'created': '2020-10-28 14:27:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_neutron/commit/81bede17fc289be591b5e01649543533de39ba3d', 'message': 'Rename nova_metadata_* variables\n\nRename nova_metadata_* variables to neutron_nova_metadata_*\nso less confusing names. At the same time these new variables will\nhave their defaults set to nova_metadata_*\n\nChange-Id: I073da66f9e395bbb99b1c21701c808f252c3a6cb\n'}, {'number': 2, 'created': '2020-11-10 16:54:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_neutron/commit/46bf2378ba3c336a077d87930c367410efd3732e', 'message': 'Rename nova_metadata_* variables\n\nRename nova_metadata_* variables to neutron_nova_metadata_*\nso less confusing names. At the same time these new variables will\nhave their defaults set to nova_metadata_*\n\nChange-Id: I073da66f9e395bbb99b1c21701c808f252c3a6cb\n'}, {'number': 3, 'created': '2020-11-25 13:22:32.000000000', 'files': ['templates/metadata_agent.ini.j2', 'defaults/main.yml'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_neutron/commit/e43313af85dddb8f5f9af454b276a24837b3c10d', 'message': 'Rename nova_metadata_* variables\n\nRename nova_metadata_* variables to neutron_nova_metadata_*\nso less confusing names. At the same time these new variables will\nhave their defaults set to nova_metadata_*\n\nChange-Id: I073da66f9e395bbb99b1c21701c808f252c3a6cb\n'}]",0,760149,e43313af85dddb8f5f9af454b276a24837b3c10d,27,4,3,28619,,,0,"Rename nova_metadata_* variables

Rename nova_metadata_* variables to neutron_nova_metadata_*
so less confusing names. At the same time these new variables will
have their defaults set to nova_metadata_*

Change-Id: I073da66f9e395bbb99b1c21701c808f252c3a6cb
",git fetch https://review.opendev.org/openstack/openstack-ansible-os_neutron refs/changes/49/760149/3 && git format-patch -1 --stdout FETCH_HEAD,"['templates/metadata_agent.ini.j2', 'defaults/main.yml']",2,81bede17fc289be591b5e01649543533de39ba3d,,"# The port used by neutron to access the nova metadata service. neutron_nova_metadata_port: ""{{ nova_metadata_port | default(8775) }}"" neutron_nova_metadata_protocol: ""{{ nova_metadata_protocol | default('http') }}""neutron_nova_metadata_insecure: ""{{ nova_metadata_insecure | default(False) }}""",nova_metadata_protocol: httpnova_metadata_insecure: False,8,5
openstack%2Fopenstack-ansible-os_nova~stable%2Fstein~I4953ee9de704c90dac67a70f9296062e5a071a77,openstack/openstack-ansible-os_nova,stable/stein,I4953ee9de704c90dac67a70f9296062e5a071a77,Enable notifications when Designate is enabled,MERGED,2020-10-15 12:09:49.000000000,2020-12-01 19:50:58.000000000,2020-12-01 19:49:37.000000000,"[{'_account_id': 819}, {'_account_id': 13095}, {'_account_id': 22348}, {'_account_id': 25023}, {'_account_id': 28182}, {'_account_id': 31542}]","[{'number': 1, 'created': '2020-10-15 12:09:49.000000000', 'files': ['templates/nova.conf.j2'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_nova/commit/329f1e6a39e23469c97652947b87988f006e745d', 'message': 'Enable notifications when Designate is enabled\n\nChange-Id: I4953ee9de704c90dac67a70f9296062e5a071a77\n(cherry picked from commit 881620bd6476d008b218721b70807deca451b8c6)\n'}]",0,758413,329f1e6a39e23469c97652947b87988f006e745d,41,6,1,819,,,0,"Enable notifications when Designate is enabled

Change-Id: I4953ee9de704c90dac67a70f9296062e5a071a77
(cherry picked from commit 881620bd6476d008b218721b70807deca451b8c6)
",git fetch https://review.opendev.org/openstack/openstack-ansible-os_nova refs/changes/13/758413/1 && git format-patch -1 --stdout FETCH_HEAD,['templates/nova.conf.j2'],1,329f1e6a39e23469c97652947b87988f006e745d,enable-notifications-designate-stable/stein,"{% set notification_topics = [] %} {% if nova_ceilometer_enabled %} {% set _ = notification_topics.append('notifications') %} {% endif %}driver = {{ (notification_topics | length > 0) | ternary('messagingv2', 'noop') }}","{% set notification_topics = ['notifications'] %}driver = {{ (nova_ceilometer_enabled | bool) | ternary('messagingv2', 'noop') }}",5,2
openstack%2Fkolla~stable%2Fvictoria~I34a2880a06e80ec1b7737ec1ffbef5f6ba7bed47,openstack/kolla,stable/victoria,I34a2880a06e80ec1b7737ec1ffbef5f6ba7bed47,Update the'image-building.rst' document,MERGED,2020-11-26 03:03:28.000000000,2020-12-01 19:47:04.000000000,2020-12-01 19:45:09.000000000,"[{'_account_id': 14826}, {'_account_id': 22348}, {'_account_id': 22629}, {'_account_id': 24072}]","[{'number': 1, 'created': '2020-11-26 03:03:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla/commit/64837ef3c522999624257fcadbe36b9ca60a66ab', 'message': ""Update the'image-building.rst' document\n\nThe openstack Ussuri and Victoria versions no longer support\npython2 and python-pip packages by default,\nupdate the'image-building.rst' document\n\nChange-Id: I34a2880a06e80ec1b7737ec1ffbef5f6ba7bed47\n(cherry picked from commit 0f2b0e047d6bdcdb37fc0a6a8dfa3470f31dcc66)\n""}, {'number': 2, 'created': '2020-12-01 05:24:37.000000000', 'files': ['doc/source/admin/image-building.rst'], 'web_link': 'https://opendev.org/openstack/kolla/commit/6c0b7159f1819786bb12f1d8a225b8090df9ec10', 'message': ""Update the'image-building.rst' document\n\nThe openstack Ussuri and Victoria versions no longer support\npython2 and python-pip packages by default,\nupdate the'image-building.rst' document\n\nChange-Id: I34a2880a06e80ec1b7737ec1ffbef5f6ba7bed47\n(cherry picked from commit 0f2b0e047d6bdcdb37fc0a6a8dfa3470f31dcc66)\n""}]",0,764267,6c0b7159f1819786bb12f1d8a225b8090df9ec10,11,4,2,31506,,,0,"Update the'image-building.rst' document

The openstack Ussuri and Victoria versions no longer support
python2 and python-pip packages by default,
update the'image-building.rst' document

Change-Id: I34a2880a06e80ec1b7737ec1ffbef5f6ba7bed47
(cherry picked from commit 0f2b0e047d6bdcdb37fc0a6a8dfa3470f31dcc66)
",git fetch https://review.opendev.org/openstack/kolla refs/changes/67/764267/2 && git format-patch -1 --stdout FETCH_HEAD,['doc/source/admin/image-building.rst'],1,64837ef3c522999624257fcadbe36b9ca60a66ab,,folder of the Kolla pip3 package. But you should only do that for pip3 install tox python3 tools/build.py python3 tools/build.py -b ubuntu python3 tools/build.py keystone python3 tools/build.py keystone nova python3 tools/build.py -t source python3 tools/build.py --template-override template-overrides.j2 horizon python3 tools/build.py --template-override template-overrides.j2 horizon && pip3 --no-cache-dir install networking-cisco pip3 --no-cache-dir install /plugins/*,folder of the Kolla pip package. But you should only do that for pip install tox python tools/build.py python tools/build.py -b ubuntu python tools/build.py keystone python tools/build.py keystone nova python tools/build.py -t source python tools/build.py --template-override template-overrides.j2 horizon python tools/build.py --template-override template-overrides.j2 horizon && pip --no-cache-dir install networking-cisco pip --no-cache-dir install /plugins/*,11,11
openstack%2Fkolla~stable%2Fussuri~I34a2880a06e80ec1b7737ec1ffbef5f6ba7bed47,openstack/kolla,stable/ussuri,I34a2880a06e80ec1b7737ec1ffbef5f6ba7bed47,Update the'image-building.rst' document,MERGED,2020-11-26 03:05:47.000000000,2020-12-01 19:46:57.000000000,2020-12-01 19:45:16.000000000,"[{'_account_id': 14826}, {'_account_id': 22348}, {'_account_id': 22629}, {'_account_id': 24072}]","[{'number': 1, 'created': '2020-11-26 03:05:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla/commit/ac875dda057111552fb4a3e516a1020de55247b9', 'message': ""Update the'image-building.rst' document\n\nThe openstack Ussuri and Victoria versions no longer support\npython2 and python-pip packages by default,\nupdate the'image-building.rst' document\n\nChange-Id: I34a2880a06e80ec1b7737ec1ffbef5f6ba7bed47\n(cherry picked from commit 0f2b0e047d6bdcdb37fc0a6a8dfa3470f31dcc66)\n""}, {'number': 2, 'created': '2020-12-01 05:33:11.000000000', 'files': ['doc/source/admin/image-building.rst'], 'web_link': 'https://opendev.org/openstack/kolla/commit/09ead6310d52eaa9efd64c5cb1de79e447da7e11', 'message': ""Update the'image-building.rst' document\n\nThe openstack Ussuri and Victoria versions no longer support\npython2 and python-pip packages by default,\nupdate the'image-building.rst' document\n\nChange-Id: I34a2880a06e80ec1b7737ec1ffbef5f6ba7bed47\n(cherry picked from commit 0f2b0e047d6bdcdb37fc0a6a8dfa3470f31dcc66)\n""}]",0,764268,09ead6310d52eaa9efd64c5cb1de79e447da7e11,11,4,2,31506,,,0,"Update the'image-building.rst' document

The openstack Ussuri and Victoria versions no longer support
python2 and python-pip packages by default,
update the'image-building.rst' document

Change-Id: I34a2880a06e80ec1b7737ec1ffbef5f6ba7bed47
(cherry picked from commit 0f2b0e047d6bdcdb37fc0a6a8dfa3470f31dcc66)
",git fetch https://review.opendev.org/openstack/kolla refs/changes/68/764268/2 && git format-patch -1 --stdout FETCH_HEAD,['doc/source/admin/image-building.rst'],1,ac875dda057111552fb4a3e516a1020de55247b9,,folder of the Kolla pip3 package. But you should only do that for pip3 install tox python3 tools/build.py python3 tools/build.py -b ubuntu python3 tools/build.py keystone python3 tools/build.py keystone nova python3 tools/build.py -t source python3 tools/build.py --template-override template-overrides.j2 horizon python3 tools/build.py --template-override template-overrides.j2 horizon && pip3 --no-cache-dir install networking-cisco pip3 --no-cache-dir install /plugins/*,folder of the Kolla pip package. But you should only do that for pip install tox python tools/build.py python tools/build.py -b ubuntu python tools/build.py keystone python tools/build.py keystone nova python tools/build.py -t source python tools/build.py --template-override template-overrides.j2 horizon python tools/build.py --template-override template-overrides.j2 horizon && pip --no-cache-dir install networking-cisco pip --no-cache-dir install /plugins/*,11,11
openstack%2Fkolla~master~Ie8ee04f036cf576888964d24b4eee83bce12a9c5,openstack/kolla,master,Ie8ee04f036cf576888964d24b4eee83bce12a9c5,docs: stable branch lifecycle,MERGED,2020-11-25 17:18:11.000000000,2020-12-01 19:46:53.000000000,2020-12-01 19:45:04.000000000,"[{'_account_id': 22348}, {'_account_id': 22629}, {'_account_id': 24072}, {'_account_id': 30491}]","[{'number': 1, 'created': '2020-11-25 17:18:11.000000000', 'files': ['doc/source/contributor/release-management.rst'], 'web_link': 'https://opendev.org/openstack/kolla/commit/97bcf0354c897d4a6f29606b4f305edd94df6c2f', 'message': 'docs: stable branch lifecycle\n\nChange-Id: Ie8ee04f036cf576888964d24b4eee83bce12a9c5\n'}]",0,764221,97bcf0354c897d4a6f29606b4f305edd94df6c2f,8,4,1,14826,,,0,"docs: stable branch lifecycle

Change-Id: Ie8ee04f036cf576888964d24b4eee83bce12a9c5
",git fetch https://review.opendev.org/openstack/kolla refs/changes/21/764221/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/source/contributor/release-management.rst'],1,97bcf0354c897d4a6f29606b4f305edd94df6c2f,," Branch Lifecycle ================ The lifecycle of stable branches in OpenStack is described in the `project team guide <https://docs.openstack.org/project-team-guide/stable-branches.html>`__. The current status of each branch is published on the `releases <https://releases.openstack.org/>`__ site. Extended Maintenance (EM) ------------------------- When a branch is entering EM, projects will make final releases. The release team will propose tagging the Kolla deliverables as EM, but this should only be done once all other dependent projects have made their final release, and final Kolla releases have been made including those dependencies. After a branch enters EM, we typically do the following: * stop backporting fixes to the branch by default. Important fixes or those requested by community members may be merged if deemed appropriate * stop publishing images to Dockerhub * stop actively maintaining CI End of Life (EOL) ----------------- Once a branch has been unmaintained (failing CI, no patches merged) for 6 months, it may be moved to EOL. Since this is done at different times for different projects, send an email to openstack-discuss to keep the community informed.",,31,0
openstack%2Fcharm-glance~master~Ie59f02bbb7d49a07d9d2193952a2da46c0e3b61f,openstack/charm-glance,master,Ie59f02bbb7d49a07d9d2193952a2da46c0e3b61f,Review README,MERGED,2020-11-17 04:06:17.000000000,2020-12-01 19:41:51.000000000,2020-12-01 19:41:51.000000000,"[{'_account_id': 20648}, {'_account_id': 20805}, {'_account_id': 20870}, {'_account_id': 22348}, {'_account_id': 30561}]","[{'number': 1, 'created': '2020-11-17 04:06:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-glance/commit/423c2607afd463723c9437531e97aeb472ccf0d4', 'message': 'Review README\n\nApply README template elements.\n\nImprove and correct deployment instructions.\n\nGeneral improvements.\n\nChange-Id: Ie59f02bbb7d49a07d9d2193952a2da46c0e3b61f\n'}, {'number': 2, 'created': '2020-11-17 15:02:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-glance/commit/68c4a7a135d47e54693a26c4c8a434c267a0f798', 'message': 'Review README\n\nApply README template elements.\n\nImprove and correct deployment instructions.\n\nGeneral improvements.\n\nChange-Id: Ie59f02bbb7d49a07d9d2193952a2da46c0e3b61f\n'}, {'number': 3, 'created': '2020-11-20 04:21:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-glance/commit/33e929a3a88a37884a222fadc679308aac18eeb2', 'message': 'Review README\n\nApply README template elements.\n\nImprove and correct deployment instructions.\n\nGeneral improvements.\n\nChange-Id: Ie59f02bbb7d49a07d9d2193952a2da46c0e3b61f\n'}, {'number': 4, 'created': '2020-11-24 14:35:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-glance/commit/a093623ba8650841903672bdc681da4f96c0ab62', 'message': 'Review README\n\nApply README template elements.\n\nImprove and correct deployment instructions.\n\nGeneral improvements.\n\nChange-Id: Ie59f02bbb7d49a07d9d2193952a2da46c0e3b61f\n'}, {'number': 5, 'created': '2020-11-24 14:41:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-glance/commit/8d76f207247af1aefcf6a533671598f4d2aa3086', 'message': 'Review README\n\nApply README template elements.\n\nImprove and correct deployment instructions.\n\nGeneral improvements.\n\nChange-Id: Ie59f02bbb7d49a07d9d2193952a2da46c0e3b61f\n'}, {'number': 6, 'created': '2020-11-24 15:02:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-glance/commit/a77976a0348cc10407e879091bc8bdf95c518531', 'message': 'Review README\n\nApply README template elements.\n\nImprove and correct deployment instructions.\n\nGeneral improvements.\n\nChange-Id: Ie59f02bbb7d49a07d9d2193952a2da46c0e3b61f\n'}, {'number': 7, 'created': '2020-11-25 00:10:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-glance/commit/0f68b7767682b0ed7cffaec95eecdc7693f561a7', 'message': 'Review README\n\nApply README template elements.\n\nImprove and correct deployment instructions.\n\nGeneral improvements.\n\nChange-Id: Ie59f02bbb7d49a07d9d2193952a2da46c0e3b61f\n'}, {'number': 8, 'created': '2020-11-25 00:11:15.000000000', 'files': ['README.md'], 'web_link': 'https://opendev.org/openstack/charm-glance/commit/a92fff1da0c618214b1bc1573975c6240235eac8', 'message': 'Review README\n\nApply README template elements.\n\nImprove and correct deployment instructions.\n\nGeneral improvements.\n\nChange-Id: Ie59f02bbb7d49a07d9d2193952a2da46c0e3b61f\n'}]",9,762949,a92fff1da0c618214b1bc1573975c6240235eac8,27,5,8,30561,,,0,"Review README

Apply README template elements.

Improve and correct deployment instructions.

General improvements.

Change-Id: Ie59f02bbb7d49a07d9d2193952a2da46c0e3b61f
",git fetch https://review.opendev.org/openstack/charm-glance refs/changes/49/762949/8 && git format-patch -1 --stdout FETCH_HEAD,['README.md'],1,423c2607afd463723c9437531e97aeb472ccf0d4,review-readme,"The glance charm deploys [Glance][upstream-glance], the core OpenStack service that acts as the central repository for virtual images. The charm works alongside other Juju-deployed OpenStack services.OpenStack UCA release (e.g. 'cloud:bionic-ussuri' or 'cloud:focal-victoria').## Deployment This section includes three different deployment scenarios, each of which requires these applications to be present: keystone, nova-cloud-controller, nova-compute, and a cloud database application ([percona-cluster][percona-cluster-charm] or [mysql-innodb-cluster][mysql-innodb-cluster-charm]). For the latter, mysql-innodb-cluster will be used below. ### Ceph-backed storage Ceph is the recommended storage backend solution for Glance. The steps below assume a pre-existing Ceph cluster (see the [ceph-mon][ceph-mon-charm] and [ceph-osd][ceph-osd-charm] charms). Here, Glance is deployed to a container on machine '1' and related to the Ceph cluster via the ceph-mon charm: juju deploy --to lxd:1 glance juju add-relation glance:ceph ceph-mon:client Proceed with a group of commands common to all three scenarios: juju add-relation glance:identity-service keystone:identity-service juju add-relation glance:image-service nova-cloud-controller:image-service juju add-relation glance:image-service nova-compute:image-service juju deploy mysql-router glance-mysql-router juju add-relation glance-mysql-router:db-router mysql-innodb-cluster:db-router juju add-relation glance-mysql-router:shared-db glance:shared-db This configuration can be used to support Glance in HA/scale-out deployments. > **Note**: In this scenario Glance acts as a Ceph client, which requires L3 network connectivity to Ceph monitors and OSDs. For MAAS-based deployments this can be addressed with network spaces (see section 'Network spaces' below). ### Swift-backed storage Glance can use OpenStack Swift as its storage backend. The steps below assume a pre-existing Swift deployment (see the [swift-proxy][swift-proxy-charm] and [swift-storage][swift-storage-charm] charms). Here, Glance is deployed to a container on machine '1' and related to Swift via the swift-proxy charm: juju deploy --to lxd:1 glance juju add-relation glance swift-proxy Proceed with the common group of commands from the Ceph scenario. This configuration can be used to support Glance in HA/scale-out deployments. ### Local storage Glance can simply use the storage available on the application unit's machine to store image data. For this reason the application is not containerised: juju deploy glance Proceed with the common group of commands from the Ceph scenario. ## Actions This section covers Juju [actions][juju-docs-actions] supported by the charm. Actions allow specific operations to be performed on a per-unit basis. To display action descriptions run `juju actions glance`. If the charm is not deployed then see file `actions.yaml`. * `openstack-upgrade` * `pause` * `resume` * `security-checklist` Glance metering can be achieved with Ceilometer. The [rabbitmq-server][rabbitmq-server-charm] and [ceilometer-agent][ceilometer-agent-charm] applications are required to be present. Assuming Glance is deployed, add two relations: juju add-relation glance:amqp rabbitmq-server:amqp juju add-relation glance:juju-info ceilometer-agent:container[ceph-mon-charm]: https://jaas.ai/ceph-mon [ceph-osd-charm]: https://jaas.ai/ceph-osd [swift-proxy-charm]: https://jaas.ai/swift-proxy [swift-storage-charm]: https://jaas.ai/swift-storage [percona-cluster-charm]: https://jaas.ai/percona-cluster [mysql-innodb-cluster-charm]: https://jaas.ai/mysql-innodb-cluster [rabbitmq-server-charm]: https://jaas.ai/rabbitmq-server [ceilometer-agent-charm]: https://jaas.ai/ceilometer-agent[upstream-glance]: https://docs.openstack.org/glance/latest/ [juju-docs-actions]: https://jaas.ai/docs/actions","The glance charm provides the Glance image service for OpenStack. It is intended to be used alongside the other OpenStack components.Glance may be deployed in a number of ways. This charm focuses on 3 main configurations. All require the existence of the other core OpenStack services deployed via Juju charms, specifically: mysql, keystone and nova-cloud-controller. The following assumes these services have already been deployed. OpenStack UCA release (e.g. 'cloud:xenial-queens' or 'cloud:bionic-ussuri').## Local Storage In this configuration, Glance uses the local storage available on the server to store image data: juju deploy glance juju add-relation glance keystone juju add-relation glance mysql juju add-relation glance nova-cloud-controller ## Swift backed storage Glance can also use Swift Object storage for image storage. Swift is often deployed as part of an OpenStack cloud and provides increased resilience and scale when compared to using local disk storage. This configuration assumes that you have already deployed Swift using the swift-proxy and swift-storage charms: juju deploy glance juju add-relation glance keystone juju add-relation glance mysql juju add-relation glance nova-cloud-controller juju add-relation glance swift-proxy This configuration can be used to support Glance in HA/Scale-out deployments. ## Ceph backed storage In this configuration, Glance uses Ceph based object storage to provide scalable, resilient storage of images. This configuration assumes that you have already deployed Ceph using the ceph charm: juju deploy glance juju add-relation glance keystone juju add-relation glance mysql juju add-relation glance nova-cloud-controller juju add-relation glance ceph-mon This configuration can also be used to support Glance in HA/Scale-out deployments. > **Note**: Glance acts as a Ceph client in this case which requires IP (L3) connectivity to Ceph monitors and OSDs. For MAAS-based deployments this can be addressed with network spaces (see section 'Network spaces' below). In order to do Glance metering with Ceilometer, an AMQP relation is required e.g. juju deploy glance juju deploy rabbitmq-server juju deploy ceilometer-agent ... juju add-relation glance rabbitmq-server juju add-relation glance ceilometer-agent ...",97,63
openstack%2Frpm-packaging~master~I8fd27a928cabfa1aca2a8dbfbf29968844e2291c,openstack/rpm-packaging,master,I8fd27a928cabfa1aca2a8dbfbf29968844e2291c,update glance_store to 2.4.0,MERGED,2020-11-25 15:05:20.000000000,2020-12-01 19:30:33.000000000,2020-12-01 17:56:52.000000000,"[{'_account_id': 6593}, {'_account_id': 13294}, {'_account_id': 19648}, {'_account_id': 22348}, {'_account_id': 23181}, {'_account_id': 28522}]","[{'number': 1, 'created': '2020-11-25 15:05:20.000000000', 'files': ['openstack/glance_store/glance_store.spec.j2'], 'web_link': 'https://opendev.org/openstack/rpm-packaging/commit/91318d776ee759ff52d1b489e03c84ab3c6375a5', 'message': 'update glance_store to 2.4.0\n\nChange-Id: I8fd27a928cabfa1aca2a8dbfbf29968844e2291c\n'}]",0,764206,91318d776ee759ff52d1b489e03c84ab3c6375a5,10,6,1,30533,,,0,"update glance_store to 2.4.0

Change-Id: I8fd27a928cabfa1aca2a8dbfbf29968844e2291c
",git fetch https://review.opendev.org/openstack/rpm-packaging refs/changes/06/764206/1 && git format-patch -1 --stdout FETCH_HEAD,['openstack/glance_store/glance_store.spec.j2'],1,91318d776ee759ff52d1b489e03c84ab3c6375a5,bug/glance_store,{% set upstream_version = upstream_version('2.4.0') %},{% set upstream_version = upstream_version('2.3.0') %},1,1
openstack%2Foctavia~stable%2Ftrain~I254557083715328fa02cf99f03e8c83037b4d640,openstack/octavia,stable/train,I254557083715328fa02cf99f03e8c83037b4d640,Enable octavia-tempest-plugin for grenade job,MERGED,2020-11-13 15:53:28.000000000,2020-12-01 19:17:52.000000000,2020-12-01 19:14:27.000000000,"[{'_account_id': 1131}, {'_account_id': 6469}, {'_account_id': 11628}, {'_account_id': 22348}]","[{'number': 1, 'created': '2020-11-13 15:53:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/octavia/commit/a84d57e1b5f0ce2a7e07f0aad49f6b5b3ac23547', 'message': 'Enable octavia-tempest-plugin for grenade job\n\nThis is a hack, but have to start somewhere\n\nChange-Id: I254557083715328fa02cf99f03e8c83037b4d640\n'}, {'number': 2, 'created': '2020-11-13 17:48:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/octavia/commit/88ddd15dd8e48d041d26ab1d0f904098c4bff959', 'message': 'Enable octavia-tempest-plugin for grenade job\n\nThis is a hack, but have to start somewhere\n\nChange-Id: I254557083715328fa02cf99f03e8c83037b4d640\n'}, {'number': 3, 'created': '2020-11-13 19:43:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/octavia/commit/d2507daa81f21c5cb696dd8df101b71396c60357', 'message': 'Enable octavia-tempest-plugin for grenade job\n\nThis is a hack, but have to start somewhere\n\nChange-Id: I254557083715328fa02cf99f03e8c83037b4d640\n'}, {'number': 4, 'created': '2020-11-13 21:59:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/octavia/commit/e1a96ff1fe4c97a41cc538d18f6dcab5b176a5ed', 'message': 'Enable octavia-tempest-plugin for grenade job\n\nThis is a hack, but have to start somewhere\n\nDepends-On: https://review.opendev.org/762716\n\nChange-Id: I254557083715328fa02cf99f03e8c83037b4d640\n'}, {'number': 5, 'created': '2020-11-14 22:25:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/octavia/commit/0357abbdf4f31bc6111c02de00a642cbb85aa91c', 'message': 'Enable octavia-tempest-plugin for grenade job\n\nRequired to get the test server binary installed.\n\nDepends-On: https://review.opendev.org/762716\n\nChange-Id: I254557083715328fa02cf99f03e8c83037b4d640\n'}, {'number': 6, 'created': '2020-11-17 19:39:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/octavia/commit/b01602b816e21fe9d418a248d0540fd58390c0e2', 'message': 'Enable octavia-tempest-plugin for grenade job\n\nRequired to get the test server binary installed.\n\nHad to change octavia-v2-dsvm-noop-py2-api to non-voting\nas py2 jobs will no longer run with tempest.\n\nDepends-On: https://review.opendev.org/762716\n\nChange-Id: I254557083715328fa02cf99f03e8c83037b4d640\n'}, {'number': 7, 'created': '2020-11-18 17:29:22.000000000', 'files': ['playbooks/legacy/grenade-devstack-octavia/run.yaml'], 'web_link': 'https://opendev.org/openstack/octavia/commit/811a6c83e3f9c0f23838a09ab4cf9c8ab8574abe', 'message': 'Enable octavia-tempest-plugin for grenade job\n\nRequired to get the test server binary installed.\n\nDepends-On: https://review.opendev.org/763228\n\nChange-Id: I254557083715328fa02cf99f03e8c83037b4d640\n'}]",0,762677,811a6c83e3f9c0f23838a09ab4cf9c8ab8574abe,36,4,7,1131,,,0,"Enable octavia-tempest-plugin for grenade job

Required to get the test server binary installed.

Depends-On: https://review.opendev.org/763228

Change-Id: I254557083715328fa02cf99f03e8c83037b4d640
",git fetch https://review.opendev.org/openstack/octavia refs/changes/77/762677/5 && git format-patch -1 --stdout FETCH_HEAD,['playbooks/legacy/grenade-devstack-octavia/run.yaml'],1,a84d57e1b5f0ce2a7e07f0aad49f6b5b3ac23547,train-grenade-otp," export GRENADE_PLUGINRC+=$'\n'""enable_grenade_plugin octavia-tempest-plugin https://opendev.org/openstack/octavia-tempest-plugin""",,1,0
openstack%2Fpanko~master~I8f2d68973498093d33f147226f988c62561ab72c,openstack/panko,master,I8f2d68973498093d33f147226f988c62561ab72c,"Revert ""Temporarily switch dvsm-integration off""",MERGED,2020-11-27 08:22:10.000000000,2020-12-01 19:17:01.000000000,2020-12-01 19:10:44.000000000,"[{'_account_id': 4264}, {'_account_id': 22348}]","[{'number': 1, 'created': '2020-11-27 08:22:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/panko/commit/8005dd5cd25d21f746ea58db3a7040d16175b4e9', 'message': 'Revert ""Temporarily switch dvsm-integration off""\n\nThis reverts commit 123448bd431e65e876b2a98d016e011fd4b36dbf.\n\nChange-Id: I8f2d68973498093d33f147226f988c62561ab72c\n'}, {'number': 2, 'created': '2020-11-27 09:25:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/panko/commit/4a79961f455a874b29b27990bc911568749b38ad', 'message': 'Revert ""Temporarily switch dvsm-integration off""\n\nThis reverts commit 123448bd431e65e876b2a98d016e011fd4b36dbf.\n\nDepends-on: https://review.opendev.org/c/openstack/aodh/+/763932/\nChange-Id: I8f2d68973498093d33f147226f988c62561ab72c\n'}, {'number': 3, 'created': '2020-12-01 15:18:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/panko/commit/67a808dbdf8e8ce54903655f444b4734320866aa', 'message': 'Revert ""Temporarily switch dvsm-integration off""\n\nThis reverts commit 123448bd431e65e876b2a98d016e011fd4b36dbf.\n\nChange-Id: I8f2d68973498093d33f147226f988c62561ab72c\n'}, {'number': 4, 'created': '2020-12-01 15:21:40.000000000', 'files': ['.zuul.yaml'], 'web_link': 'https://opendev.org/openstack/panko/commit/0a22e282dbd07dc39f745e5bec6da592ed314d3a', 'message': 'Revert ""Temporarily switch dvsm-integration off""\n\nThis reverts commit 123448bd431e65e876b2a98d016e011fd4b36dbf.\n\nChange-Id: I8f2d68973498093d33f147226f988c62561ab72c\n'}]",3,764421,0a22e282dbd07dc39f745e5bec6da592ed314d3a,18,2,4,4264,,,0,"Revert ""Temporarily switch dvsm-integration off""

This reverts commit 123448bd431e65e876b2a98d016e011fd4b36dbf.

Change-Id: I8f2d68973498093d33f147226f988c62561ab72c
",git fetch https://review.opendev.org/openstack/panko refs/changes/21/764421/2 && git format-patch -1 --stdout FETCH_HEAD,['.zuul.yaml'],1,8005dd5cd25d21f746ea58db3a7040d16175b4e9,remove-workaround," check: jobs: - telemetry-dsvm-integration: irrelevant-files: &base-irrelevant-files - ^(test-|)requirements.txt$ - ^.*\.rst$ - ^.git.*$ - ^doc/.*$ - ^panko/hacking/.*$ - ^panko/locale/.*$ - ^panko/tests/.*$ - ^releasenotes/.*$ - ^setup.cfg$ - ^tools/.*$ - ^tox.ini$ - telemetry-dsvm-integration-ipv6-only: irrelevant-files: *base-irrelevant-files # TripleO jobs that deploy Telemetry. # Note we don't use a project-template here, so it's easier # to disable voting on one specific job if things go wrong. # tripleo-ci-centos-7-scenario00(1|2)-multinode-oooq will only # run on stable/pike while the -container will run in Queens # and beyond. # If you need any support to debug these jobs in case of # failures, please reach us on #tripleo IRC channel. - tripleo-ci-centos-7-scenario001-multinode-oooq: voting: false - tripleo-ci-centos-7-scenario001-standalone: voting: false - tripleo-ci-centos-7-scenario002-multinode-oooq: voting: false - tripleo-ci-centos-7-scenario002-standalone: voting: false gate: jobs: - telemetry-dsvm-integration: irrelevant-files: *base-irrelevant-files - telemetry-dsvm-integration-ipv6-only: irrelevant-files: *base-irrelevant-files",,39,0
openstack%2Ftripleo-heat-templates~stable%2Ftrain~I0bca04cd4883a1bf61b06a0828e323bc388a95be,openstack/tripleo-heat-templates,stable/train,I0bca04cd4883a1bf61b06a0828e323bc388a95be,Set ServerDeletionPolicy during upgrade prepare and converge,ABANDONED,2020-01-07 22:24:59.000000000,2020-12-01 19:14:29.000000000,,"[{'_account_id': 11090}, {'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2020-01-07 22:24:59.000000000', 'files': ['environments/lifecycle/upgrade-converge.yaml', 'environments/lifecycle/upgrade-prepare.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/e42558dc09242fbb80de2baacb9eaad5c5e4598b', 'message': ""Set ServerDeletionPolicy during upgrade prepare and converge\n\nThis change will always set ServerDeletionPolicy to 'retain' during\nupgrade prepare, and back to the default 'delete' during the converge.\n\nFor a normal upgrade this will have no effect since scale-down is not\nrecommended during an upgrade.\n\nFor a transition from nova based undercloud to nova-less, this allows\nthe following steps to work:\n1. operator builds a valid deployed-server environment file by running\n   'openstack overcloud node extract provisioned'[1]\n2. running 'openstack overcloud upgrade prepare' will prevent the next\n   stack update from deleting any nova servers\n3. running 'openstack overcloud upgrade converge' with the environment\n   from 1. will replace nova heat resources with deployed server\n   resources which are managed directly with the provision/unprovision\n   commands\n\nThis approach is an alternative to preventing the heat nova resource\nfrom ever deleting a nova server after the undercloud upgrade[2]\n\nThis is a medium risk backport as it affects major upgrades, but it\nactually reduces the risk of accidentally deleting servers during\nupgrade.\n\n[1] https://review.opendev.org/#/c/674141/\n[2] https://review.opendev.org/#/c/675498/\nBlueprint: bp/nova-less-deploy\n\nChange-Id: I0bca04cd4883a1bf61b06a0828e323bc388a95be\n(cherry picked from commit ab958c2f3e7d836b5095f234103e6b30525de9f0)\n""}]",4,701467,e42558dc09242fbb80de2baacb9eaad5c5e4598b,10,3,1,4571,,,0,"Set ServerDeletionPolicy during upgrade prepare and converge

This change will always set ServerDeletionPolicy to 'retain' during
upgrade prepare, and back to the default 'delete' during the converge.

For a normal upgrade this will have no effect since scale-down is not
recommended during an upgrade.

For a transition from nova based undercloud to nova-less, this allows
the following steps to work:
1. operator builds a valid deployed-server environment file by running
   'openstack overcloud node extract provisioned'[1]
2. running 'openstack overcloud upgrade prepare' will prevent the next
   stack update from deleting any nova servers
3. running 'openstack overcloud upgrade converge' with the environment
   from 1. will replace nova heat resources with deployed server
   resources which are managed directly with the provision/unprovision
   commands

This approach is an alternative to preventing the heat nova resource
from ever deleting a nova server after the undercloud upgrade[2]

This is a medium risk backport as it affects major upgrades, but it
actually reduces the risk of accidentally deleting servers during
upgrade.

[1] https://review.opendev.org/#/c/674141/
[2] https://review.opendev.org/#/c/675498/
Blueprint: bp/nova-less-deploy

Change-Id: I0bca04cd4883a1bf61b06a0828e323bc388a95be
(cherry picked from commit ab958c2f3e7d836b5095f234103e6b30525de9f0)
",git fetch https://review.opendev.org/openstack/tripleo-heat-templates refs/changes/67/701467/1 && git format-patch -1 --stdout FETCH_HEAD,"['environments/lifecycle/upgrade-converge.yaml', 'environments/lifecycle/upgrade-prepare.yaml']",2,e42558dc09242fbb80de2baacb9eaad5c5e4598b,train-bp/nova-less-deploy, ServerDeletionPolicy: retain,,2,0
openstack%2Fpuppet-openstack-integration~master~Ia552483e39606419174965af1560ff6e05eab5db,openstack/puppet-openstack-integration,master,Ia552483e39606419174965af1560ff6e05eab5db,Updated from Puppet OpenStack modules constraints,MERGED,2020-12-01 06:11:58.000000000,2020-12-01 18:52:54.000000000,2020-12-01 18:52:54.000000000,"[{'_account_id': 14985}, {'_account_id': 16137}, {'_account_id': 22348}]","[{'number': 1, 'created': '2020-12-01 06:11:58.000000000', 'files': ['Puppetfile'], 'web_link': 'https://opendev.org/openstack/puppet-openstack-integration/commit/35d162131c4caa904ad7c594a58dbf2f626c8814', 'message': 'Updated from Puppet OpenStack modules constraints\n\nChange-Id: Ia552483e39606419174965af1560ff6e05eab5db\n'}]",0,764900,35d162131c4caa904ad7c594a58dbf2f626c8814,7,3,1,11131,,,0,"Updated from Puppet OpenStack modules constraints

Change-Id: Ia552483e39606419174965af1560ff6e05eab5db
",git fetch https://review.opendev.org/openstack/puppet-openstack-integration refs/changes/00/764900/1 && git format-patch -1 --stdout FETCH_HEAD,['Puppetfile'],1,35d162131c4caa904ad7c594a58dbf2f626c8814,openstack/puppet/constraints, :ref => 'v6.3.0', :ref => 'v6.2.0',1,1
openstack%2Ftripleo-heat-templates~stable%2Fvictoria~Iea8cccd77caac4b84764d84a213918ed57bd4e3e,openstack/tripleo-heat-templates,stable/victoria,Iea8cccd77caac4b84764d84a213918ed57bd4e3e,Set correct default NovaLibvirtCPUMode,MERGED,2020-11-27 17:02:09.000000000,2020-12-01 18:49:10.000000000,2020-12-01 18:47:19.000000000,"[{'_account_id': 14985}, {'_account_id': 20172}, {'_account_id': 20733}, {'_account_id': 22348}, {'_account_id': 23181}, {'_account_id': 23811}]","[{'number': 1, 'created': '2020-11-27 17:02:09.000000000', 'files': ['deployment/nova/nova-compute-container-puppet.yaml', 'releasenotes/notes/nova_compute_default_cpu_mode-cda2bb3e56463b3a.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/125d41b857ef2a257bc6263ad148ab37374d1426', 'message': ""Set correct default NovaLibvirtCPUMode\n\nhttps://review.opendev.org/q/I8df21d5d171976cbb8670dc5aef744b5fae657b2\nintroduced THT parameters to set libvirt/cpu_mode. The patch sets the\nNovaLibvirtCPUMode wrong to 'none' string which results in puppet-nova\nnot to handle the default cases correct and sets libvirt/cpu_mode to\nnone which results in 'qemu64' CPU model, which is highly buggy and\nundesirable for production usage.  This changes the default to the\nrecommended CPU mode 'host-model', for various benefits documented\nelsewhere.\n\nCloses-Bug: #1905544\n\nChange-Id: Iea8cccd77caac4b84764d84a213918ed57bd4e3e\n(cherry picked from commit c290a5e3a10b2ca6599b09f813da875d6aaa4f9f)\n""}]",0,764312,125d41b857ef2a257bc6263ad148ab37374d1426,14,6,1,17216,,,0,"Set correct default NovaLibvirtCPUMode

https://review.opendev.org/q/I8df21d5d171976cbb8670dc5aef744b5fae657b2
introduced THT parameters to set libvirt/cpu_mode. The patch sets the
NovaLibvirtCPUMode wrong to 'none' string which results in puppet-nova
not to handle the default cases correct and sets libvirt/cpu_mode to
none which results in 'qemu64' CPU model, which is highly buggy and
undesirable for production usage.  This changes the default to the
recommended CPU mode 'host-model', for various benefits documented
elsewhere.

Closes-Bug: #1905544

Change-Id: Iea8cccd77caac4b84764d84a213918ed57bd4e3e
(cherry picked from commit c290a5e3a10b2ca6599b09f813da875d6aaa4f9f)
",git fetch https://review.opendev.org/openstack/tripleo-heat-templates refs/changes/12/764312/1 && git format-patch -1 --stdout FETCH_HEAD,"['deployment/nova/nova-compute-container-puppet.yaml', 'releasenotes/notes/nova_compute_default_cpu_mode-cda2bb3e56463b3a.yaml']",2,125d41b857ef2a257bc6263ad148ab37374d1426,fix_default_cpu_mode-stable/victoria,"--- fixes: - | https://review.opendev.org/q/I8df21d5d171976cbb8670dc5aef744b5fae657b2 introduced THT parameters to set libvirt/cpu_mode. The patch sets the NovaLibvirtCPUMode wrong to 'none' string which results in puppet-nova not to handle the default cases correct and sets libvirt/cpu_mode to none which results in 'qemu64' CPU model, which is highly buggy and undesirable for production usage. This changes the default to the recommended CPU mode 'host-model', for various benefits documented elsewhere. ",,12,1
openstack%2Fvalidations-libs~master~I07c39901744580a45f26f19ce60a54510c10d701,openstack/validations-libs,master,I07c39901744580a45f26f19ce60a54510c10d701,Update TOX_CONSTRAINTS_FILE,MERGED,2020-11-19 09:27:24.000000000,2020-12-01 18:47:24.000000000,2020-12-01 18:47:24.000000000,"[{'_account_id': 11491}, {'_account_id': 14985}, {'_account_id': 22348}, {'_account_id': 26285}]","[{'number': 1, 'created': '2020-11-19 09:27:24.000000000', 'files': ['tox.ini'], 'web_link': 'https://opendev.org/openstack/validations-libs/commit/671e3221e9dc1c2ad8020cd7225a099bc1aff524', 'message': 'Update TOX_CONSTRAINTS_FILE\n\nUPPER_CONSTRAINTS_FILE is old name and deprecated\n-https://zuul-ci.org/docs/zuul-jobs/python-roles.html#rolevar-tox.tox_constraints_file\nThis allows to use lower-constraints file as more\nreadable way instead of UPPER_CONSTRAINTS_FILE=<lower-constraints file>.\n\nChange-Id: I07c39901744580a45f26f19ce60a54510c10d701\n'}]",0,763326,671e3221e9dc1c2ad8020cd7225a099bc1aff524,8,4,1,32291,,,0,"Update TOX_CONSTRAINTS_FILE

UPPER_CONSTRAINTS_FILE is old name and deprecated
-https://zuul-ci.org/docs/zuul-jobs/python-roles.html#rolevar-tox.tox_constraints_file
This allows to use lower-constraints file as more
readable way instead of UPPER_CONSTRAINTS_FILE=<lower-constraints file>.

Change-Id: I07c39901744580a45f26f19ce60a54510c10d701
",git fetch https://review.opendev.org/openstack/validations-libs refs/changes/26/763326/1 && git format-patch -1 --stdout FETCH_HEAD,['tox.ini'],1,671e3221e9dc1c2ad8020cd7225a099bc1aff524,, -c {env:TOX_CONSTRAINTS_FILE:https://opendev.org/openstack/requirements/raw/branch/master/upper-constraints.txt} -c {env:TOX_CONSTRAINTS_FILE:https://opendev.org/openstack/requirements/raw/branch/master/upper-constraints.txt}, -c {env:UPPER_CONSTRAINTS_FILE:https://opendev.org/openstack/requirements/raw/branch/master/upper-constraints.txt},2,1
openstack%2Ftripleo-ansible~master~Ie66907eb1953b671031bd42ad9e40760cfe1a84c,openstack/tripleo-ansible,master,Ie66907eb1953b671031bd42ad9e40760cfe1a84c,Fix issue updating single segment networks,MERGED,2020-11-23 15:38:00.000000000,2020-12-01 18:41:25.000000000,2020-12-01 18:41:25.000000000,"[{'_account_id': 4571}, {'_account_id': 7353}, {'_account_id': 8833}, {'_account_id': 14985}, {'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2020-11-23 15:38:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ansible/commit/4278de2e4e3558909a2b1a3c8f18bb8a7d8be1b2', 'message': 'Fix issue updating single segment networks\n\nUpdating single segment networks created with this\nmodule failed with:\n  ""Cannot update provider:physical_network in\n   existing network""\n\nSingle segment networks have the physical_network\nset at the network level. For multi-segment networks\nthe physical_network is only set on the segments.\n\nDue to the incremental addition of support for multiple\nsegments in THT the nameing convention for the base\nsegment and additional segments are not identical.\n\nThis change relaxes the test for physical_network\nchange not allowed so that it accepts both naming\nconventions.\n\nChange-Id: Ie66907eb1953b671031bd42ad9e40760cfe1a84c\n'}, {'number': 2, 'created': '2020-11-30 11:19:13.000000000', 'files': ['tripleo_ansible/ansible_plugins/modules/tripleo_composable_network.py'], 'web_link': 'https://opendev.org/openstack/tripleo-ansible/commit/feb3ce7e9a2c753b5f1aab0dfbdc6c5e1cbf127b', 'message': 'Fix issue updating single segment networks\n\nUpdating single segment networks created with this\nmodule failed with:\n  ""Cannot update provider:physical_network in\n   existing network""\n\nSingle segment networks have the physical_network\nset at the network level. For multi-segment networks\nthe physical_network is only set on the segments.\n\nDue to the incremental addition of support for multiple\nsegments in THT the nameing convention for the base\nsegment and additional segments are not identical.\n\nThis change relaxes the test for physical_network\nchange not allowed so that it accepts both naming\nconventions.\n\nChange-Id: Ie66907eb1953b671031bd42ad9e40760cfe1a84c\n'}]",0,763800,feb3ce7e9a2c753b5f1aab0dfbdc6c5e1cbf127b,13,6,2,24245,,,0,"Fix issue updating single segment networks

Updating single segment networks created with this
module failed with:
  ""Cannot update provider:physical_network in
   existing network""

Single segment networks have the physical_network
set at the network level. For multi-segment networks
the physical_network is only set on the segments.

Due to the incremental addition of support for multiple
segments in THT the nameing convention for the base
segment and additional segments are not identical.

This change relaxes the test for physical_network
change not allowed so that it accepts both naming
conventions.

Change-Id: Ie66907eb1953b671031bd42ad9e40760cfe1a84c
",git fetch https://review.opendev.org/openstack/tripleo-ansible refs/changes/00/763800/2 && git format-patch -1 --stdout FETCH_HEAD,['tripleo_ansible/ansible_plugins/modules/tripleo_composable_network.py'],1,4278de2e4e3558909a2b1a3c8f18bb8a7d8be1b2,network-data-v2," if (net_spec.pop('provider:physical_network') not in [network.provider_physical_network, net_spec['name']]", if (network.provider_physical_network != net_spec.pop( 'provider:physical_network'),2,2
openstack%2Fnova~master~I2a37cb38d9dcba22c679a37838b8e5ddd34262c4,openstack/nova,master,I2a37cb38d9dcba22c679a37838b8e5ddd34262c4,remove python warnning  from tox,MERGED,2020-09-16 06:32:31.000000000,2020-12-01 18:13:44.000000000,2020-12-01 18:09:49.000000000,"[{'_account_id': 7634}, {'_account_id': 9008}, {'_account_id': 10118}, {'_account_id': 15334}, {'_account_id': 15941}, {'_account_id': 16376}, {'_account_id': 22348}, {'_account_id': 26285}, {'_account_id': 26515}, {'_account_id': 29963}, {'_account_id': 32067}, {'_account_id': 32231}]","[{'number': 1, 'created': '2020-09-16 06:32:31.000000000', 'files': ['tox.ini'], 'web_link': 'https://opendev.org/openstack/nova/commit/50ff47d55388a44b47b1e6a997e1eb1fd7d95510', 'message': 'remove python warnning  from tox\n\nthe minimum constraints of psycopg2 is 2.8 now, we can remove the\nTODO\n\nChange-Id: I2a37cb38d9dcba22c679a37838b8e5ddd34262c4\n'}]",0,752190,50ff47d55388a44b47b1e6a997e1eb1fd7d95510,24,12,1,26285,,,0,"remove python warnning  from tox

the minimum constraints of psycopg2 is 2.8 now, we can remove the
TODO

Change-Id: I2a37cb38d9dcba22c679a37838b8e5ddd34262c4
",git fetch https://review.opendev.org/openstack/nova refs/changes/90/752190/1 && git format-patch -1 --stdout FETCH_HEAD,['tox.ini'],1,50ff47d55388a44b47b1e6a997e1eb1fd7d95510,,,# TODO(stephenfin): Remove psycopg2 when minimum constraints is bumped to 2.8 PYTHONWARNINGS = ignore::UserWarning:psycopg2,0,2
openstack%2Fopenstack-ansible-os_keystone~master~I233d79c8eb82553156880dc7e437e4833a306ac0,openstack/openstack-ansible-os_keystone,master,I233d79c8eb82553156880dc7e437e4833a306ac0,Adding tags to federated openid support using auth_mod_openidc,MERGED,2020-11-28 14:24:34.000000000,2020-12-01 18:04:16.000000000,2020-12-01 18:02:34.000000000,"[{'_account_id': 22348}, {'_account_id': 25023}, {'_account_id': 28619}, {'_account_id': 29865}]","[{'number': 1, 'created': '2020-11-28 14:24:34.000000000', 'files': ['tasks/main.yml'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_keystone/commit/fc7d16879ee5fd8da2fdc4b75885df3c91b7b02b', 'message': 'Adding tags to federated openid support using auth_mod_openidc\n\nCloses-Bug: 1906108\nChange-Id: I233d79c8eb82553156880dc7e437e4833a306ac0\n'}]",0,764552,fc7d16879ee5fd8da2fdc4b75885df3c91b7b02b,8,4,1,29605,,,0,"Adding tags to federated openid support using auth_mod_openidc

Closes-Bug: 1906108
Change-Id: I233d79c8eb82553156880dc7e437e4833a306ac0
",git fetch https://review.opendev.org/openstack/openstack-ansible-os_keystone refs/changes/52/764552/1 && git format-patch -1 --stdout FETCH_HEAD,['tasks/main.yml'],1,fc7d16879ee5fd8da2fdc4b75885df3c91b7b02b,, tags: - always tags: - always,,4,0
openstack%2Ftripleo-ansible~master~Id99aa83d3025202ffd27480157aaf3e101c2f471,openstack/tripleo-ansible,master,Id99aa83d3025202ffd27480157aaf3e101c2f471,Add tag with network name on network resources,MERGED,2020-11-23 15:38:00.000000000,2020-12-01 17:55:28.000000000,2020-12-01 17:55:28.000000000,"[{'_account_id': 4571}, {'_account_id': 7353}, {'_account_id': 8833}, {'_account_id': 14985}, {'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2020-11-23 15:38:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ansible/commit/ea72e7c22b8b90ca03209b1bf707cc8610fbd4cc', 'message': 'Add tag with network name on network resources\n\nThe network name in uppercase is needed to write\ngroup_vars in ansible inventory. The name_lower\nvalue is used as the actual network resouce name\nin neutron.\n\nChange-Id: Id99aa83d3025202ffd27480157aaf3e101c2f471\n'}, {'number': 2, 'created': '2020-11-30 11:19:13.000000000', 'files': ['tripleo_ansible/tests/modules/test_tripleo_composable_network.py', 'tripleo_ansible/ansible_plugins/modules/tripleo_composable_network.py'], 'web_link': 'https://opendev.org/openstack/tripleo-ansible/commit/2e77f1f238472df798d45a76bf53e3ee3e3295e9', 'message': 'Add tag with network name on network resources\n\nThe network name in uppercase is needed to write\ngroup_vars in ansible inventory. The name_lower\nvalue is used as the actual network resouce name\nin neutron.\n\nChange-Id: Id99aa83d3025202ffd27480157aaf3e101c2f471\n'}]",0,763799,2e77f1f238472df798d45a76bf53e3ee3e3295e9,14,6,2,24245,,,0,"Add tag with network name on network resources

The network name in uppercase is needed to write
group_vars in ansible inventory. The name_lower
value is used as the actual network resouce name
in neutron.

Change-Id: Id99aa83d3025202ffd27480157aaf3e101c2f471
",git fetch https://review.opendev.org/openstack/tripleo-ansible refs/changes/99/763799/2 && git format-patch -1 --stdout FETCH_HEAD,"['tripleo_ansible/tests/modules/test_tripleo_composable_network.py', 'tripleo_ansible/ansible_plugins/modules/tripleo_composable_network.py']",2,ea72e7c22b8b90ca03209b1bf707cc8610fbd4cc,network-data-v2," tags = ['='.join(['tripleo_network_name', net_data['name']])]", tags = [],5,4
openstack%2Fopenstack-helm-infra~master~I39606e388a9a1d3a4e9c547de56aac4fc5606ea2,openstack/openstack-helm-infra,master,I39606e388a9a1d3a4e9c547de56aac4fc5606ea2,[ceph-osd] Add a check for misplaced objects to the post-apply job,MERGED,2020-11-30 17:24:24.000000000,2020-12-01 17:39:29.000000000,2020-12-01 17:38:04.000000000,"[{'_account_id': 8898}, {'_account_id': 18250}, {'_account_id': 18511}, {'_account_id': 20466}, {'_account_id': 21420}, {'_account_id': 22348}, {'_account_id': 22636}, {'_account_id': 23928}, {'_account_id': 28372}, {'_account_id': 30495}, {'_account_id': 30777}, {'_account_id': 32190}, {'_account_id': 32433}]","[{'number': 1, 'created': '2020-11-30 17:24:24.000000000', 'files': ['ceph-osd/templates/bin/_post-apply.sh.tpl', 'ceph-osd/Chart.yaml'], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/e37d1fc2ab9cfffb549cf46254d20896fc384f41', 'message': '[ceph-osd] Add a check for misplaced objects to the post-apply job\n\nOSD failures during an update can cause degraded and misplaced\nobjects. The post-apply job restarts OSDs in failure domain\nbatches in order to accomplish the restarts efficiently. There is\nalready a wait for degraded objects to ensure that OSDs are not\nrestarted on degraded PGs, but misplaced objects could mean that\nmultiple object replicas exist in the same failure domain, so the\njob should wait for those to recover as well before restarting\nOSDs in order to avoid potential disruption under these failure\nconditions.\n\nChange-Id: I39606e388a9a1d3a4e9c547de56aac4fc5606ea2\n'}]",0,764802,e37d1fc2ab9cfffb549cf46254d20896fc384f41,15,13,1,29974,,,0,"[ceph-osd] Add a check for misplaced objects to the post-apply job

OSD failures during an update can cause degraded and misplaced
objects. The post-apply job restarts OSDs in failure domain
batches in order to accomplish the restarts efficiently. There is
already a wait for degraded objects to ensure that OSDs are not
restarted on degraded PGs, but misplaced objects could mean that
multiple object replicas exist in the same failure domain, so the
job should wait for those to recover as well before restarting
OSDs in order to avoid potential disruption under these failure
conditions.

Change-Id: I39606e388a9a1d3a4e9c547de56aac4fc5606ea2
",git fetch https://review.opendev.org/openstack/openstack-helm-infra refs/changes/02/764802/1 && git format-patch -1 --stdout FETCH_HEAD,"['ceph-osd/templates/bin/_post-apply.sh.tpl', 'ceph-osd/Chart.yaml']",2,e37d1fc2ab9cfffb549cf46254d20896fc384f41,,version: 0.1.12,version: 0.1.11,6,6
openstack%2Freleases~master~I2a9ad25f675f046b1bedaf59f8a406195243d2c4,openstack/releases,master,I2a9ad25f675f046b1bedaf59f8a406195243d2c4,Release python-freezerclient for wallaby-1 milestone,MERGED,2020-11-30 13:40:28.000000000,2020-12-01 17:34:34.000000000,2020-12-01 17:34:34.000000000,"[{'_account_id': 11904}, {'_account_id': 13940}, {'_account_id': 21069}, {'_account_id': 22348}, {'_account_id': 28522}]","[{'number': 1, 'created': '2020-11-30 13:40:28.000000000', 'files': ['deliverables/wallaby/python-freezerclient.yaml'], 'web_link': 'https://opendev.org/openstack/releases/commit/20efd75f130a70848377624ddc7d84df3a5773bb', 'message': 'Release python-freezerclient for wallaby-1 milestone\n\nThis is a library release for python-freezerclient for the wallaby-1\nmilestone. This repo includes commits that have not been releases for\nthis cycle yet.\n\nIf the team is ready to process with this release, please leave a +1\nto indicate we should go ahead with the release.\n\nIf the team needs more time for things about to merge, or if there is\nsome other reason a release should not be done at this time, please\nleave a -1 with a comment indicating the status. Then update the patch\nwith the new commit hash to use once the team is ready to do the\nrelease.\n\nChange-Id: I2a9ad25f675f046b1bedaf59f8a406195243d2c4\n'}]",0,764728,20efd75f130a70848377624ddc7d84df3a5773bb,9,5,1,28522,,,0,"Release python-freezerclient for wallaby-1 milestone

This is a library release for python-freezerclient for the wallaby-1
milestone. This repo includes commits that have not been releases for
this cycle yet.

If the team is ready to process with this release, please leave a +1
to indicate we should go ahead with the release.

If the team needs more time for things about to merge, or if there is
some other reason a release should not be done at this time, please
leave a -1 with a comment indicating the status. Then update the patch
with the new commit hash to use once the team is ready to do the
release.

Change-Id: I2a9ad25f675f046b1bedaf59f8a406195243d2c4
",git fetch https://review.opendev.org/openstack/releases refs/changes/28/764728/1 && git format-patch -1 --stdout FETCH_HEAD,['deliverables/wallaby/python-freezerclient.yaml'],1,20efd75f130a70848377624ddc7d84df3a5773bb,w1-c-w-i,releases: - version: 4.1.0 projects: - repo: openstack/python-freezerclient hash: cf06e431518eaa0d65d9b0b4ea34a25f3e40b5bf,,5,0
openstack%2Freleases~master~I03eaef53b8ee0c3178577f2c4447b946ed270715,openstack/releases,master,I03eaef53b8ee0c3178577f2c4447b946ed270715,Release python-magnumclient for wallaby-1 milestone,MERGED,2020-11-30 13:44:33.000000000,2020-12-01 17:32:21.000000000,2020-12-01 17:32:21.000000000,"[{'_account_id': 11904}, {'_account_id': 20498}, {'_account_id': 22348}, {'_account_id': 28522}]","[{'number': 1, 'created': '2020-11-30 13:44:33.000000000', 'files': ['deliverables/wallaby/python-magnumclient.yaml'], 'web_link': 'https://opendev.org/openstack/releases/commit/a91990fb91041a01e9a2909cfb23ea4f0a2b7976', 'message': 'Release python-magnumclient for wallaby-1 milestone\n\nThis is a library release for python-magnumclient for the wallaby-1\nmilestone. This repo includes commits that have not been releases for\nthis cycle yet.\n\nIf the team is ready to process with this release, please leave a +1\nto indicate we should go ahead with the release.\n\nIf the team needs more time for things about to merge, or if there is\nsome other reason a release should not be done at this time, please\nleave a -1 with a comment indicating the status. Then update the patch\nwith the new commit hash to use once the team is ready to do the\nrelease.\n\nChange-Id: I03eaef53b8ee0c3178577f2c4447b946ed270715\n'}]",0,764734,a91990fb91041a01e9a2909cfb23ea4f0a2b7976,9,4,1,28522,,,0,"Release python-magnumclient for wallaby-1 milestone

This is a library release for python-magnumclient for the wallaby-1
milestone. This repo includes commits that have not been releases for
this cycle yet.

If the team is ready to process with this release, please leave a +1
to indicate we should go ahead with the release.

If the team needs more time for things about to merge, or if there is
some other reason a release should not be done at this time, please
leave a -1 with a comment indicating the status. Then update the patch
with the new commit hash to use once the team is ready to do the
release.

Change-Id: I03eaef53b8ee0c3178577f2c4447b946ed270715
",git fetch https://review.opendev.org/openstack/releases refs/changes/34/764734/1 && git format-patch -1 --stdout FETCH_HEAD,['deliverables/wallaby/python-magnumclient.yaml'],1,a91990fb91041a01e9a2909cfb23ea4f0a2b7976,w1-c-w-i,releases: - version: 3.3.0 projects: - repo: openstack/python-magnumclient hash: d549651f6d6699d0c429ab9eed8ffd0d6fe0a4c9,,5,0
openstack%2Ftripleo-heat-templates~stable%2Fqueens~I5050f198f0109faa9299de85e01b0dbe4e5a30ab,openstack/tripleo-heat-templates,stable/queens,I5050f198f0109faa9299de85e01b0dbe4e5a30ab,fix nova_statedir_ownership,MERGED,2020-11-24 11:04:44.000000000,2020-12-01 17:28:58.000000000,2020-12-01 17:28:58.000000000,"[{'_account_id': 8449}, {'_account_id': 11090}, {'_account_id': 13861}, {'_account_id': 14985}, {'_account_id': 20172}, {'_account_id': 22348}, {'_account_id': 23181}, {'_account_id': 23811}]","[{'number': 1, 'created': '2020-11-24 11:04:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/73a96475f449361bcd120996d3352de061f2220e', 'message': ""fix nova_statedir_ownership\n\nwith change in Ic6f053d56194613046ae0a4a908206ebb453fcf4 run() was\nremoved to be triggered, as a result the script actually don't run.\n\nChange-Id: I5050f198f0109faa9299de85e01b0dbe4e5a30ab\nCloses-Bug: #1903033\n(cherry picked from commit 70818dc6843d70df4d517a07a6ff628d11d22d70)\n""}, {'number': 2, 'created': '2020-11-25 05:23:20.000000000', 'files': ['docker_config_scripts/nova_statedir_ownership.py'], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/407991def9fa04cd6650e24deb1cdd267d6860ac', 'message': ""fix nova_statedir_ownership\n\nwith change in Ic6f053d56194613046ae0a4a908206ebb453fcf4 run() was\nremoved to be triggered, as a result the script actually don't run.\n\nDepends-On: https://review.opendev.org/#/c/763712\nDepends-On: https://review.opendev.org/#/c/763747\nChange-Id: I5050f198f0109faa9299de85e01b0dbe4e5a30ab\nCloses-Bug: #1903033\n(cherry picked from commit 70818dc6843d70df4d517a07a6ff628d11d22d70)\n""}]",0,763961,407991def9fa04cd6650e24deb1cdd267d6860ac,22,8,2,17216,,,0,"fix nova_statedir_ownership

with change in Ic6f053d56194613046ae0a4a908206ebb453fcf4 run() was
removed to be triggered, as a result the script actually don't run.

Depends-On: https://review.opendev.org/#/c/763712
Depends-On: https://review.opendev.org/#/c/763747
Change-Id: I5050f198f0109faa9299de85e01b0dbe4e5a30ab
Closes-Bug: #1903033
(cherry picked from commit 70818dc6843d70df4d517a07a6ff628d11d22d70)
",git fetch https://review.opendev.org/openstack/tripleo-heat-templates refs/changes/61/763961/1 && git format-patch -1 --stdout FETCH_HEAD,['docker_config_scripts/nova_statedir_ownership.py'],1,73a96475f449361bcd120996d3352de061f2220e,1903033-queens," NovaStatedirOwnershipManager('/var/lib/nova', exclude_paths=get_exclude_paths()).run()"," NovaStatedirOwnershipManager('/var/lib/nova', exclude_paths=get_exclude_paths())",1,1
openstack%2Fopenstack-ansible-os_nova~master~Id1cd254fb758a09c07b7b56ba735b00b94d7a040,openstack/openstack-ansible-os_nova,master,Id1cd254fb758a09c07b7b56ba735b00b94d7a040,Reduce number of processes on small systems,MERGED,2020-11-30 11:52:58.000000000,2020-12-01 17:11:55.000000000,2020-12-01 17:10:04.000000000,"[{'_account_id': 22348}, {'_account_id': 25023}, {'_account_id': 31542}]","[{'number': 1, 'created': '2020-11-30 11:52:58.000000000', 'files': ['defaults/main.yml'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_nova/commit/246db283d96cf5b0fcf3aa4875326a45bbb9cdff', 'message': 'Reduce number of processes on small systems\n\nEven the most modest 4C/8T system would run with the maximum 16 processes\ndue to the calculation being VCPU*2.\n\nWe devide amount of CPUs to number of threads for hyperthreaded CPUs\n\nChange-Id: Id1cd254fb758a09c07b7b56ba735b00b94d7a040\n'}]",0,764646,246db283d96cf5b0fcf3aa4875326a45bbb9cdff,8,3,1,28619,,,0,"Reduce number of processes on small systems

Even the most modest 4C/8T system would run with the maximum 16 processes
due to the calculation being VCPU*2.

We devide amount of CPUs to number of threads for hyperthreaded CPUs

Change-Id: Id1cd254fb758a09c07b7b56ba735b00b94d7a040
",git fetch https://review.opendev.org/openstack/openstack-ansible-os_nova refs/changes/46/764646/1 && git format-patch -1 --stdout FETCH_HEAD,['defaults/main.yml'],1,246db283d96cf5b0fcf3aa4875326a45bbb9cdff,api_threads,"nova_api_threads: ""{{ [[(ansible_processor_vcpus//ansible_processor_threads_per_core)|default(1), 1] | max * 2, nova_api_threads_max] | min }}""","nova_api_threads: ""{{ [[ansible_processor_vcpus|default(2) // 2, 1] | max, nova_api_threads_max] | min }}""",1,1
openstack%2Fopenstack-ansible-os_adjutant~master~Ia5e223493ec0e8469621ba9a8c90f9bc5d995426,openstack/openstack-ansible-os_adjutant,master,Ia5e223493ec0e8469621ba9a8c90f9bc5d995426,Updated from OpenStack Ansible Tests,MERGED,2020-06-18 13:44:28.000000000,2020-12-01 17:06:19.000000000,2020-12-01 17:04:23.000000000,"[{'_account_id': 22348}, {'_account_id': 28619}]","[{'number': 1, 'created': '2020-06-18 13:44:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_adjutant/commit/7f0e4bde87a2a3d390a26dbc0ea3785471d1bbd7', 'message': 'Updated from OpenStack Ansible Tests\n\nChange-Id: Ia5e223493ec0e8469621ba9a8c90f9bc5d995426\n'}, {'number': 2, 'created': '2020-09-24 16:54:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_adjutant/commit/ad6a7d7866158dfaef86a41bd2ddf563ce51fff0', 'message': 'Updated from OpenStack Ansible Tests\n\nChange-Id: Ia5e223493ec0e8469621ba9a8c90f9bc5d995426\n'}, {'number': 3, 'created': '2020-12-01 13:21:27.000000000', 'files': ['run_tests.sh', '.gitignore', 'bindep.txt', 'tasks/service_setup.yml', 'Vagrantfile'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_adjutant/commit/1d3f4828c8ce693963622040cd356d8153244753', 'message': 'Updated from OpenStack Ansible Tests\n\nChange-Id: Ia5e223493ec0e8469621ba9a8c90f9bc5d995426\n'}]",0,736723,1d3f4828c8ce693963622040cd356d8153244753,9,2,3,11131,,,0,"Updated from OpenStack Ansible Tests

Change-Id: Ia5e223493ec0e8469621ba9a8c90f9bc5d995426
",git fetch https://review.opendev.org/openstack/openstack-ansible-os_adjutant refs/changes/23/736723/3 && git format-patch -1 --stdout FETCH_HEAD,"['run_tests.sh', '.gitignore', 'bindep.txt', 'Vagrantfile']",4,7f0e4bde87a2a3d390a26dbc0ea3785471d1bbd7,openstack/openstack-ansible-tests/sync-tests,"# https://opendev.org/openstack/openstack-ansible-tests/src/Vagrantfile v.memory = 6144 # https://github.com/hashicorp/vagrant/issues/9524 v.customize [""modifyvm"", :id, ""--audio"", ""none""] config.vm.define ""debian8"" do |debian8| debian8.vm.box = ""debian/jessie64"" end config.vm.define ""debian9"" do |debian9| debian9.vm.box = ""debian/stretch64"" end config.vm.define ""gentoo"" do |gentoo| gentoo.vm.box = ""generic/gentoo"" end config.vm.define ""opensuse150"" do |leap150| leap150.vm.box = ""opensuse/openSUSE-15.0-x86_64"" end config.vm.define ""opensuse151"" do |leap151| leap151.vm.box = ""opensuse/openSUSE-15.1-x86_64"" end config.vm.define ""ubuntu1804"" do |bionic| bionic.disksize.size = ""40GB"" bionic.vm.box = ""ubuntu/bionic64"" end","# https://git.openstack.org/cgit/openstack/openstack-ansible-tests/tree/Vagrantfile v.memory = 4096 config.vm.define ""ubuntu1604"" do |xenial| xenial.disksize.size = ""40GB"" xenial.vm.box = ""ubuntu/xenial64"" end config.vm.define ""opensuse422"" do |leap422| leap422.vm.box = ""opensuse/openSUSE-42.2-x86_64"" end config.vm.define ""opensuse423"" do |leap423| leap423.vm.box = ""opensuse/openSUSE-42.3-x86_64"" end ",115,65
openstack%2Fopenstack-ansible-os_magnum~master~Ica00d078bddafd783ee6d24b0ac9151a8b57c3e1,openstack/openstack-ansible-os_magnum,master,Ica00d078bddafd783ee6d24b0ac9151a8b57c3e1,Add docs for suggested cluster template and debugging hints,MERGED,2020-11-30 10:32:40.000000000,2020-12-01 16:50:51.000000000,2020-12-01 16:48:54.000000000,"[{'_account_id': 22348}, {'_account_id': 28008}, {'_account_id': 28619}]","[{'number': 1, 'created': '2020-11-30 10:32:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_magnum/commit/93f02062d342c08e38f92597a45a2d04bce9cdab', 'message': 'Add docs for suggested cluster template and debugging hints\n\nChange-Id: Ica00d078bddafd783ee6d24b0ac9151a8b57c3e1\n'}, {'number': 2, 'created': '2020-11-30 13:33:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_magnum/commit/cd4a13269131386249925e74000d5547606cbc0d', 'message': 'Add docs for suggested cluster template and debugging hints\n\nChange-Id: Ica00d078bddafd783ee6d24b0ac9151a8b57c3e1\n'}, {'number': 3, 'created': '2020-11-30 13:41:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_magnum/commit/d1c8e07165befcc3004e7cd7764889ef29b65f97', 'message': 'Add docs for suggested cluster template and debugging hints\n\nChange-Id: Ica00d078bddafd783ee6d24b0ac9151a8b57c3e1\n'}, {'number': 4, 'created': '2020-11-30 14:09:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_magnum/commit/9d07e4f7bfb7244c990c5aa7151ec24f5931c521', 'message': 'Add docs for suggested cluster template and debugging hints\n\nChange-Id: Ica00d078bddafd783ee6d24b0ac9151a8b57c3e1\n'}, {'number': 5, 'created': '2020-11-30 15:42:48.000000000', 'files': ['doc/source/index.rst'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_magnum/commit/3fa5ab07ccbfaa7ad6d725f8578f87f47854e822', 'message': 'Add docs for suggested cluster template and debugging hints\n\nChange-Id: Ica00d078bddafd783ee6d24b0ac9151a8b57c3e1\n'}]",5,764627,3fa5ab07ccbfaa7ad6d725f8578f87f47854e822,21,3,5,25023,,,0,"Add docs for suggested cluster template and debugging hints

Change-Id: Ica00d078bddafd783ee6d24b0ac9151a8b57c3e1
",git fetch https://review.opendev.org/openstack/openstack-ansible-os_magnum refs/changes/27/764627/4 && git format-patch -1 --stdout FETCH_HEAD,['doc/source/index.rst'],1,93f02062d342c08e38f92597a45a2d04bce9cdab,," Post-deployment configuration ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ Deploying the magum service makes the API components available to use. Additional configuration is required to make a working Kubernetes cluster, including loading the correct Image and setting up a suitable Cluster Template This example is intended to show the steps required and should be updated as needed for the version of k8s and associated components. .. code-block:: bash # stable/ussuri as of 2020.10.28 magnum_git_install_branch: ""fe35af8ef5d9e65a4074aa3ba3ed3116b7322415"" openstack coe cluster template create <name> --coe kubernetes --external-network <ext-net> --image ""fedora-coreos-32.20201004.3.0-openstack.x86_64"" --master-flavor <flavor> --flavor <flavor> --master-lb-enabled --docker-volume-size 50 --network-driver calico --docker-storage-driver overlay2 --volume-driver cinder --labels boot_volume_type=<your volume type>,boot_volume_size=50,kube_tag=v1.18.6,availability_zone=nova,helm_client_url=""https://get.helm.sh/helm-v3.4.0-linux-amd64.tar.gz"",helm_client_sha256=""270acb0f085b72ec28aee894c7443739271758010323d72ced0e92cd2c96ffdb"",helm_client_tag=""v3.4.0"",etcd_volume_size=50,auto_scaling_enabled=true,auto_healing_enabled=true,auto_healing_controller=magnum-auto-healer,etcd_volume_type=<your volume type>,kube_dashboard_enabled=True,monitoring_enabled=True,ingress_controller=nginx,cloud_provider_tag=v1.19.0,magnum_auto_healer_tag=v1.19.0,container_infra_prefix=<docker-registry-without-rate-limit> -f yaml -c uuid wget https://builds.coreos.fedoraproject.org/prod/streams/stable/builds/32.20201004.3.0/x86_64/fedora-coreos-32.20201004.3.0-openstack.x86_64.qcow2.xz openstack image create ""fedora-coreos-32.20201004.3.0-openstack.x86_64"" --disk-format raw --container-format bare --file fedora-coreos-32.20201004.3.0-openstack.x86_64.raw --property os_distro='fedora-coreos' Note that openstack-ansible deploys the Magnum API service. It is not in scope for openstack-ansible to maintain a guaranteed working cluster template as this will vary depending on the precise version of Magnum deployed and the required version of k8s and it's dependancies. It will be necessary to specify a docker registry (potentially hosting your own mirror or cache) which does not enforce rate limits when deploying Magnum in a production environment. Post-deployment debugging ~~~~~~~~~~~~~~~~~~~~~~~~~ If the k8s cluster does not create properly, or times out then the cloud-init logs in the master/minion nodes should be examined, also check the heat-config log and heat-container-agent status.",,37,0
openstack%2Fopenstack-ansible~stable%2Fstein~Ibfe5dd2ef97d2c6684e9e563b82c6956ad7ddf76,openstack/openstack-ansible,stable/stein,Ibfe5dd2ef97d2c6684e9e563b82c6956ad7ddf76,Switch to stable/stein for EM,MERGED,2020-11-09 14:37:14.000000000,2020-12-01 16:49:21.000000000,2020-12-01 16:45:48.000000000,"[{'_account_id': 22348}, {'_account_id': 25023}, {'_account_id': 29865}]","[{'number': 1, 'created': '2020-11-09 14:37:14.000000000', 'files': ['playbooks/defaults/repo_packages/openstack_services.yml', 'playbooks/defaults/repo_packages/gnocchi.yml', 'ansible-role-requirements.yml'], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/61e85207f1c8066cbcc3affb47c1322faa854370', 'message': ""Switch to stable/stein for EM\n\nSince within EM we won't be able to do releases anymore, we switch sources\nto stable/stein so that on EM ppl would get all patches we could probably\nbackport later.\n\nChange-Id: Ibfe5dd2ef97d2c6684e9e563b82c6956ad7ddf76\n""}]",0,761937,61e85207f1c8066cbcc3affb47c1322faa854370,8,3,1,28619,,,0,"Switch to stable/stein for EM

Since within EM we won't be able to do releases anymore, we switch sources
to stable/stein so that on EM ppl would get all patches we could probably
backport later.

Change-Id: Ibfe5dd2ef97d2c6684e9e563b82c6956ad7ddf76
",git fetch https://review.opendev.org/openstack/openstack-ansible refs/changes/37/761937/1 && git format-patch -1 --stdout FETCH_HEAD,"['playbooks/defaults/repo_packages/openstack_services.yml', 'playbooks/defaults/repo_packages/gnocchi.yml', 'ansible-role-requirements.yml']",3,61e85207f1c8066cbcc3affb47c1322faa854370,, version: stable/stein version: stable/stein version: stable/stein version: stable/stein version: stable/stein version: stable/stein version: 3.13.2 version: stable/stein version: stable/stein version: stable/stein version: stable/stein version: stable/stein version: stable/stein version: stable/stein version: stable/stein version: stable/stein version: stable/stein version: stable/stein version: stable/stein version: stable/stein version: stable/stein version: stable/stein version: stable/stein version: stable/stein version: stable/stein version: stable/stein version: stable/stein version: stable/stein version: stable/stein version: stable/stein version: stable/stein version: stable/stein version: stable/stein version: stable/stein version: stable/stein version: stable/stein version: stable/stein version: stable/stein version: stable/stein version: stable/stein version: stable/stein version: stable/stein version: stable/stein version: stable/stein version: stable/stein version: stable-3.2 version: stable/stein version: stable/stein version: stable/stein version: stable/stein version: stable/stein version: stable/stein, version: a9e1753ecc40ad7e2827853f483d70cad6227835 version: 14c2620785303097dbddf1b7dc58c418b8e95819 version: afdbacc5f16af04021a046e153fe100e1574901a version: 829b749732cfcf9fcc87aa66963f9f2fead40dc0 version: c1edab7aabd1fea17bce04c54b94d3dbf3872163 version: bc9c3548c41681017feb1eef20269eee70ff4d77 version: 709f5aadf0bd969b54046f9e891c28dddcfe79b0 version: 2eb9cfd1be8a5f01c1ae6aa1879dd057345aab1b version: c52784341834de13bb04cedd9b4529d1b3ca12ea version: 53c47874e5daa67741d6cb773be7589bd1d95722 version: 2d5e7a4bf4da0a71106855869d3aa8311c4fc0f0 version: 50ebe7835bd3616b02098f586e55568484ad484f version: 0e3aa057e3246d72051f4cad218233619fecdf8d version: f292913132a80986f348de4d54a6cfcad9048e98 version: 7781f24af089276d7fb1252ccaead6b6a9afa355 version: d16a1906e91e6f13da2ff70dbe345481f71ee4a6 version: e613a300669070ee29c0cf4ee1efee93c2c7170d version: 20698cb76c257e62df57654cc46a3f33db922e1c version: 526ec716bc6095c42cb15c99833c484e4e341063 version: c7ffaaafb416b697af1f67ef985f012db3078f53 version: 0e7457a35ddf1bc3f380a1ea1afe9c6faf5c6c8f version: 7c78bdcf7fdce01363369d5568718de3ffe51618 version: 283a521d926f67da6c1208723a5e3739e0209068 version: 4df265206ff680ba982a8b9d52db78a84590c89d version: a6608a8da7e54c70e48d1616f042a915053d56a9 version: 1e9804858ae52ce7e8edc1cf9684e45343783e84 version: e04744c79836f680aee087d7973dae6699286220 version: 6bff0044e46a392ca433c3e37784ebc57f28bf81 version: b774f0e62f17d0337cc401ad69664bccc48a8813 version: d2af6918e97dd27c96fb1c4972e915f8fddfb127 version: dda91ae04925fea37884864b3d5fb314647f3c15 version: 2b8f71c85dfc6f57f2ccbaaa515508fde4af0df3 version: 0f8684a54a8cba97d923bec0d4d18b674ca67269 version: 1af78bb2b6331cb1a79c01660e4c04b7df50e039 version: 7316b92e6ab0ad5030297f95a46400f68013f1d9 version: e54ba6fe3166e09a77abeb0fb4d9b88b42630cb5 version: 524efabe97d4942acc8aa58913c2e7f8deb2fdbf version: cfbfd94b3df42470f5a8aa85f9644a261f2b3bed version: d9fed6ebe0c376d0420fa666403b4731af4a6de2 version: f3efb647e3f48d40627a1dd81045ae6db6bb68b8 version: eac5f430863fb71b90fd89a0077558192517da17 version: d371e41167dd0378e56836b15fa309c54c1ac498 version: c801daedaf07d4df36869685a27637e4de7768e0 version: ef875a488a1a3e4450afeb7e90ea48762413e0a5 version: 9efa53f36c2c10926adac48ea9ecfb3d9c5590b0 version: 8b6aedc8715aa33fba8fe2fa8205b69b37e7961d version: 0de6bf805343b265f018ab3c17dff6a12a93bd45 version: ddb1b6e69b1660f24f345806cf27dbc86dd4afb3 version: 7f22ad73e990f8a15d9cda697f1d15d35ba5936c version: 16c7fb71efd218559718dfc903a4a2cabf6a53f5 version: 311961b7e93b8f23011cdff9fbf927e970a9e2e8 version: 0f2f4e2eaba638949d42fb0b2793b6ba203519a0,99,99
openstack%2Fopenstack-ansible~stable%2Ftrain~I654b0af0e884de7b903cce441179af2fb8a7df89,openstack/openstack-ansible,stable/train,I654b0af0e884de7b903cce441179af2fb8a7df89,Remove git repo haproxy backend,MERGED,2020-11-10 21:26:57.000000000,2020-12-01 16:48:15.000000000,2020-12-01 16:45:30.000000000,"[{'_account_id': 22348}, {'_account_id': 25023}, {'_account_id': 28619}]","[{'number': 1, 'created': '2020-11-10 21:26:57.000000000', 'files': ['inventory/group_vars/haproxy/haproxy.yml'], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/543c7374d0ad7d9218d37811e30f9c1aebc92629', 'message': ""Remove git repo haproxy backend\n\nCaching git repositories has been deprecated in Queens, so it's high time\nwe removed this endpoint.\nWe're setting endpoint state to absent in order to remove endpoint during\nthe upgrade process\n\nChange-Id: I654b0af0e884de7b903cce441179af2fb8a7df89\n(cherry picked from commit 9c0303398182361752d48193f4e7a38597647b18)\n""}]",0,762209,543c7374d0ad7d9218d37811e30f9c1aebc92629,8,3,1,26647,,,0,"Remove git repo haproxy backend

Caching git repositories has been deprecated in Queens, so it's high time
we removed this endpoint.
We're setting endpoint state to absent in order to remove endpoint during
the upgrade process

Change-Id: I654b0af0e884de7b903cce441179af2fb8a7df89
(cherry picked from commit 9c0303398182361752d48193f4e7a38597647b18)
",git fetch https://review.opendev.org/openstack/openstack-ansible refs/changes/09/762209/1 && git format-patch -1 --stdout FETCH_HEAD,['inventory/group_vars/haproxy/haproxy.yml'],1,543c7374d0ad7d9218d37811e30f9c1aebc92629,, state: absent,,1,0
openstack%2Fironic~master~I20836d586edccfb8cd8fed1f3a89f1497ff96943,openstack/ironic,master,I20836d586edccfb8cd8fed1f3a89f1497ff96943,Use openstack-tox for ironic-tox-unit-with-driver-libs,MERGED,2020-11-27 11:21:46.000000000,2020-12-01 16:47:51.000000000,2020-12-01 16:40:13.000000000,"[{'_account_id': 11655}, {'_account_id': 15519}, {'_account_id': 22348}]","[{'number': 1, 'created': '2020-11-27 11:21:46.000000000', 'files': ['zuul.d/ironic-jobs.yaml'], 'web_link': 'https://opendev.org/openstack/ironic/commit/475af371ddaa8a6d381c6b73193fedab0c058c6c', 'message': 'Use openstack-tox for ironic-tox-unit-with-driver-libs\n\nAll the tox jobs are based on openstack-tox, we should convert\nironic-tox-unit-with-driver-libs too.\n\nChange-Id: I20836d586edccfb8cd8fed1f3a89f1497ff96943\n'}]",0,764445,475af371ddaa8a6d381c6b73193fedab0c058c6c,12,3,1,23851,,,0,"Use openstack-tox for ironic-tox-unit-with-driver-libs

All the tox jobs are based on openstack-tox, we should convert
ironic-tox-unit-with-driver-libs too.

Change-Id: I20836d586edccfb8cd8fed1f3a89f1497ff96943
",git fetch https://review.opendev.org/openstack/ironic refs/changes/45/764445/1 && git format-patch -1 --stdout FETCH_HEAD,['zuul.d/ironic-jobs.yaml'],1,475af371ddaa8a6d381c6b73193fedab0c058c6c,openstack-tox-driver-libs, parent: openstack-tox, parent: tox,1,1
openstack%2Fkuryr-kubernetes~master~Ia6404c22132af3a17ce865c4f33a57b2b6832e9f,openstack/kuryr-kubernetes,master,Ia6404c22132af3a17ce865c4f33a57b2b6832e9f,Updating tempest conf file,MERGED,2020-11-13 11:17:52.000000000,2020-12-01 16:39:21.000000000,2020-12-01 16:37:26.000000000,"[{'_account_id': 11600}, {'_account_id': 13692}, {'_account_id': 22348}, {'_account_id': 23567}, {'_account_id': 27032}, {'_account_id': 30963}]","[{'number': 1, 'created': '2020-11-13 11:17:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kuryr-kubernetes/commit/e539fa5faa50836aef3ecc9c11ead5b0e0c37702', 'message': 'Updating tempest conf file\n\nThis patch is setting kuryr-kubernetes option on\ntest_services_without_selector to True.\n\nDepends-On: https://review.opendev.org/#/c/757551\nChange-Id: Ia6404c22132af3a17ce865c4f33a57b2b6832e9f\n'}, {'number': 2, 'created': '2020-11-24 08:41:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kuryr-kubernetes/commit/7a17a1fe12ec70bf0bc3e0c5608ebccdb7a8df39', 'message': 'Updating tempest conf file\n\nThis patch is setting kuryr-kubernetes option on\ntest_services_without_selector to True.\n\nDepends-On: https://review.opendev.org/#/c/757551\nChange-Id: Ia6404c22132af3a17ce865c4f33a57b2b6832e9f\n'}, {'number': 3, 'created': '2020-11-24 11:45:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kuryr-kubernetes/commit/6384a53631f86e873d5406cb5d12f472d59b5371', 'message': 'Updating tempest conf file\n\nThis patch is setting kuryr-kubernetes option on\ntest_services_without_selector to True.\n\nDepends-On: https://review.opendev.org/#/c/757551\nChange-Id: Ia6404c22132af3a17ce865c4f33a57b2b6832e9f\n'}, {'number': 4, 'created': '2020-12-01 12:04:46.000000000', 'files': ['devstack/plugin.sh'], 'web_link': 'https://opendev.org/openstack/kuryr-kubernetes/commit/5fab420948f69472c9745fe3871dac01e7293672', 'message': 'Updating tempest conf file\n\nThis patch is setting kuryr-kubernetes option on\ntest_services_without_selector to True.\n\nChange-Id: Ia6404c22132af3a17ce865c4f33a57b2b6832e9f\n'}]",1,762642,5fab420948f69472c9745fe3871dac01e7293672,39,6,4,30963,,,0,"Updating tempest conf file

This patch is setting kuryr-kubernetes option on
test_services_without_selector to True.

Change-Id: Ia6404c22132af3a17ce865c4f33a57b2b6832e9f
",git fetch https://review.opendev.org/openstack/kuryr-kubernetes refs/changes/42/762642/2 && git format-patch -1 --stdout FETCH_HEAD,['devstack/plugin.sh'],1,e539fa5faa50836aef3ecc9c11ead5b0e0c37702,plugin_fix, iniset $TEMPEST_CONFIG kuryr_kubernetes test_services_without_selector True,,1,0
openstack%2Fgrenade~stable%2Ftrain~I389e2a4f8135e0e22a70098b95c17457cbedf1cf,openstack/grenade,stable/train,I389e2a4f8135e0e22a70098b95c17457cbedf1cf,Fix horizon upgrade: remove screen_stop call,MERGED,2020-11-17 16:18:55.000000000,2020-12-01 16:35:11.000000000,2020-12-01 16:33:31.000000000,"[{'_account_id': 8556}, {'_account_id': 22348}, {'_account_id': 30491}]","[{'number': 1, 'created': '2020-11-17 16:18:55.000000000', 'files': ['projects/80_horizon/upgrade.sh'], 'web_link': 'https://opendev.org/openstack/grenade/commit/c90159e6579281b31660224ca8cdc1aedbb62eb0', 'message': 'Fix horizon upgrade: remove screen_stop call\n\nThe screen_stop function was removed some time ago together\nwith the screen support (I8c27182f60b0f5310b3a8bf5feb02beb7ffbb26a)\n\nThis does probably mean no proper horizon/grenade testing has been\ndone in the past 3 years...\n\nChange-Id: I389e2a4f8135e0e22a70098b95c17457cbedf1cf\n(cherry picked from commit 290ebb4220e95da85a7906fe0de9bc1c8728b295)\n(cherry picked from commit 451d8fd19c9e8a5161231412fb81376b7a239e54)\n'}]",0,763042,c90159e6579281b31660224ca8cdc1aedbb62eb0,12,3,1,10459,,,0,"Fix horizon upgrade: remove screen_stop call

The screen_stop function was removed some time ago together
with the screen support (I8c27182f60b0f5310b3a8bf5feb02beb7ffbb26a)

This does probably mean no proper horizon/grenade testing has been
done in the past 3 years...

Change-Id: I389e2a4f8135e0e22a70098b95c17457cbedf1cf
(cherry picked from commit 290ebb4220e95da85a7906fe0de9bc1c8728b295)
(cherry picked from commit 451d8fd19c9e8a5161231412fb81376b7a239e54)
",git fetch https://review.opendev.org/openstack/grenade refs/changes/42/763042/1 && git format-patch -1 --stdout FETCH_HEAD,['projects/80_horizon/upgrade.sh'],1,c90159e6579281b31660224ca8cdc1aedbb62eb0,fix-horizon-upgrade-screen,,# Kill horizon screen session if there one screen_stop horizon,0,2
openstack%2Fopenstack-ansible-os_senlin~master~I35dcc306169ed819a3adadb42ef83bc8ae6acc93,openstack/openstack-ansible-os_senlin,master,I35dcc306169ed819a3adadb42ef83bc8ae6acc93,Define condition for the first play host one time,MERGED,2020-11-30 12:25:51.000000000,2020-12-01 16:15:51.000000000,2020-12-01 16:10:28.000000000,"[{'_account_id': 22348}, {'_account_id': 25023}, {'_account_id': 28752}, {'_account_id': 31542}]","[{'number': 1, 'created': '2020-11-30 12:25:51.000000000', 'files': ['tasks/main.yml', 'vars/main.yml'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_senlin/commit/40cae435f36dea4aa13e7a7d10e4225e76c62aca', 'message': 'Define condition for the first play host one time\n\nWe use the same condition, which defines against what host some ""service""\ntasks should run against, several times. It\'s hard to keep it the same\nacross the role and ansible spending additional resources to evaluate\nit each time, so it\'s simpler and better for the maintenance to set\na boolean variable which will say for all tasks, that we want to run\nonly against signle host, if they should run or not now.\n\nChange-Id: I35dcc306169ed819a3adadb42ef83bc8ae6acc93\n'}]",0,764659,40cae435f36dea4aa13e7a7d10e4225e76c62aca,9,4,1,28619,,,0,"Define condition for the first play host one time

We use the same condition, which defines against what host some ""service""
tasks should run against, several times. It's hard to keep it the same
across the role and ansible spending additional resources to evaluate
it each time, so it's simpler and better for the maintenance to set
a boolean variable which will say for all tasks, that we want to run
only against signle host, if they should run or not now.

Change-Id: I35dcc306169ed819a3adadb42ef83bc8ae6acc93
",git fetch https://review.opendev.org/openstack/openstack-ansible-os_senlin refs/changes/59/764659/1 && git format-patch -1 --stdout FETCH_HEAD,"['tasks/main.yml', 'vars/main.yml']",2,40cae435f36dea4aa13e7a7d10e4225e76c62aca,run_condition,"_senlin_is_first_play_host: ""{{ (senlin_services['senlin-api']['group'] in group_names and inventory_hostname == (groups[senlin_services['senlin-api']['group']] | intersect(ansible_play_hosts)) | first) | bool }}"" ",,6,4
openstack%2Fopenstack-ansible-os_senlin~master~Ie68fae480f1ab1450659e1b4b2f75f65360fce7f,openstack/openstack-ansible-os_senlin,master,Ie68fae480f1ab1450659e1b4b2f75f65360fce7f,Reduce number of processes on small systems,MERGED,2020-11-30 11:57:52.000000000,2020-12-01 16:13:39.000000000,2020-12-01 16:09:36.000000000,"[{'_account_id': 22348}, {'_account_id': 25023}, {'_account_id': 28752}, {'_account_id': 31542}]","[{'number': 1, 'created': '2020-11-30 11:57:52.000000000', 'files': ['defaults/main.yml'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_senlin/commit/b0eb41f868f6513ab55514f4bccb0a486518ef0f', 'message': 'Reduce number of processes on small systems\n\nEven the most modest 4C/8T system would run with the maximum 16 processes\ndue to the calculation being VCPU*2.\n\nWe devide amount of CPUs to number of threads for hyperthreaded CPUs\n\nChange-Id: Ie68fae480f1ab1450659e1b4b2f75f65360fce7f\n'}]",0,764650,b0eb41f868f6513ab55514f4bccb0a486518ef0f,9,4,1,28619,,,0,"Reduce number of processes on small systems

Even the most modest 4C/8T system would run with the maximum 16 processes
due to the calculation being VCPU*2.

We devide amount of CPUs to number of threads for hyperthreaded CPUs

Change-Id: Ie68fae480f1ab1450659e1b4b2f75f65360fce7f
",git fetch https://review.opendev.org/openstack/openstack-ansible-os_senlin refs/changes/50/764650/1 && git format-patch -1 --stdout FETCH_HEAD,['defaults/main.yml'],1,b0eb41f868f6513ab55514f4bccb0a486518ef0f,api_threads,"senlin_api_threads: ""{{ [[(ansible_processor_vcpus//ansible_processor_threads_per_core)|default(1), 1] | max * 2, senlin_api_threads_max] | min }}""","senlin_api_threads: ""{{ [[ansible_processor_vcpus|default(2) // 2, 1] | max, senlin_api_threads_max] | min }}""",1,1
openstack%2Fopenstack-ansible-os_adjutant~master~I360e6c7bc1910d3c013ff225a25f95a191252639,openstack/openstack-ansible-os_adjutant,master,I360e6c7bc1910d3c013ff225a25f95a191252639,Trigger uwsgi restart,MERGED,2020-11-30 12:12:43.000000000,2020-12-01 16:13:31.000000000,2020-12-01 16:11:06.000000000,"[{'_account_id': 22348}, {'_account_id': 25023}, {'_account_id': 31542}]","[{'number': 1, 'created': '2020-11-30 12:12:43.000000000', 'files': ['tasks/adjutant_post_install.yml', 'handlers/main.yml'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_adjutant/commit/1b8cee42a09397958473dd2eef8ee99b3c02ea75', 'message': 'Trigger uwsgi restart\n\nWhen we were migrating service to uwsgi usage, we clean forgot to\ntrigger uwsgi restart on service config change.\nWe also use modern ""listen"" for service handlers that not using uwsgi.\n\nDepends-On: https://review.opendev.org/c/openstack/openstack-ansible/+/756310\nChange-Id: I360e6c7bc1910d3c013ff225a25f95a191252639\n'}]",0,764655,1b8cee42a09397958473dd2eef8ee99b3c02ea75,8,3,1,28619,,,0,"Trigger uwsgi restart

When we were migrating service to uwsgi usage, we clean forgot to
trigger uwsgi restart on service config change.
We also use modern ""listen"" for service handlers that not using uwsgi.

Depends-On: https://review.opendev.org/c/openstack/openstack-ansible/+/756310
Change-Id: I360e6c7bc1910d3c013ff225a25f95a191252639
",git fetch https://review.opendev.org/openstack/openstack-ansible-os_adjutant refs/changes/55/764655/1 && git format-patch -1 --stdout FETCH_HEAD,"['tasks/adjutant_post_install.yml', 'handlers/main.yml']",2,1b8cee42a09397958473dd2eef8ee99b3c02ea75,restart-uwsgi, listen: - Restart adjutant services listen: - Restart adjutant services,"- name: Restart adjutant services command: ""/bin/true"" notify: - Stop services - Start services ",6,6
openstack%2Fvitrage~master~Ie8426b50595b87539bef42520c78a138db32ac7f,openstack/vitrage,master,Ie8426b50595b87539bef42520c78a138db32ac7f,Remove unicode  from datasource,MERGED,2020-12-01 05:56:30.000000000,2020-12-01 16:13:26.000000000,2020-12-01 16:11:21.000000000,"[{'_account_id': 19134}, {'_account_id': 22348}]","[{'number': 1, 'created': '2020-12-01 05:56:30.000000000', 'files': ['vitrage/datasources/prometheus/driver.py'], 'web_link': 'https://opendev.org/openstack/vitrage/commit/9047c458bc4059e21b5e360131967072e806b832', 'message': 'Remove unicode  from datasource\n\nChange-Id: Ie8426b50595b87539bef42520c78a138db32ac7f\n'}]",0,764899,9047c458bc4059e21b5e360131967072e806b832,9,2,1,32577,,,0,"Remove unicode  from datasource

Change-Id: Ie8426b50595b87539bef42520c78a138db32ac7f
",git fetch https://review.opendev.org/openstack/vitrage refs/changes/99/764899/1 && git format-patch -1 --stdout FETCH_HEAD,['vitrage/datasources/prometheus/driver.py'],1,9047c458bc4059e21b5e360131967072e806b832,update-py," {'instance_name': 'instance-00000004', 'host_id': 'my-host-name'} {'instance': '1.1.1.1:9999', 'domain': 'instance-00000004'} {'instance_name': 'domain', 'host_id': 'instance'}"," {u'instance_name': 'instance-00000004', u'host_id': 'my-host-name'} {u'instance': u'1.1.1.1:9999', u'domain': u'instance-00000004'} {u'instance_name': u'domain', u'host_id': u'instance'}",4,4
openstack%2Fopenstack-ansible-os_trove~master~I2ae9039871158f8a94e3f96694ddadea3005537b,openstack/openstack-ansible-os_trove,master,I2ae9039871158f8a94e3f96694ddadea3005537b,Reduce number of processes on small systems,MERGED,2020-11-30 12:03:57.000000000,2020-12-01 16:11:50.000000000,2020-12-01 16:08:12.000000000,"[{'_account_id': 22348}, {'_account_id': 25023}, {'_account_id': 31542}]","[{'number': 1, 'created': '2020-11-30 12:03:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_trove/commit/65d9ce941d914a6a4e1274598edf69647f8846fd', 'message': 'Reduce number of processes on small systems\n\nEven the most modest 4C/8T system would run with the maximum 16 processes\ndue to the calculation being VCPU*2.\n\nWe devide amount of CPUs to number of threads for hyperthreaded CPUs\n\nChange-Id: I2ae9039871158f8a94e3f96694ddadea3005537b\n'}, {'number': 2, 'created': '2020-11-30 12:04:18.000000000', 'files': ['defaults/main.yml'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_trove/commit/f37cb8868032b86fbc6aa843321c00b10441eafd', 'message': 'Reduce number of processes on small systems\n\nEven the most modest 4C/8T system would run with the maximum 16 processes\ndue to the calculation being VCPU*2.\n\nWe devide amount of CPUs to number of threads for hyperthreaded CPUs\n\nChange-Id: I2ae9039871158f8a94e3f96694ddadea3005537b\n'}]",0,764653,f37cb8868032b86fbc6aa843321c00b10441eafd,9,3,2,28619,,,0,"Reduce number of processes on small systems

Even the most modest 4C/8T system would run with the maximum 16 processes
due to the calculation being VCPU*2.

We devide amount of CPUs to number of threads for hyperthreaded CPUs

Change-Id: I2ae9039871158f8a94e3f96694ddadea3005537b
",git fetch https://review.opendev.org/openstack/openstack-ansible-os_trove refs/changes/53/764653/2 && git format-patch -1 --stdout FETCH_HEAD,['defaults/main.yml'],1,65d9ce941d914a6a4e1274598edf69647f8846fd,api_threads,"trove_api_workers: ""{{ [[(ansible_processor_vcpus//ansible_processor_threads_per_core)|default(1), 1] | max * 2, trove_api_workers_max] | min }}""trove_conductor_workers: ""{{ [[(ansible_processor_vcpus//ansible_processor_threads_per_core)|default(1), 1] | max * 2, trove_conductor_workers_max] | min }}""","trove_api_workers: ""{{ [[ansible_processor_vcpus|default(2) // 2, 1] | max, trove_api_workers_max] | min }}""trove_conductor_workers: ""{{ [[ansible_processor_vcpus|default(2) // 2, 1] | max, trove_conductor_workers_max] | min }}""",2,2
openstack%2Fopenstack-ansible-os_swift~master~Ie3c590d413b001ac9ccdb6522c9654b4372b5e10,openstack/openstack-ansible-os_swift,master,Ie3c590d413b001ac9ccdb6522c9654b4372b5e10,Reduce number of processes on small systems,MERGED,2020-11-30 12:01:50.000000000,2020-12-01 16:01:52.000000000,2020-12-01 16:00:32.000000000,"[{'_account_id': 22348}, {'_account_id': 25023}, {'_account_id': 31542}]","[{'number': 1, 'created': '2020-11-30 12:01:50.000000000', 'files': ['defaults/main.yml'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_swift/commit/5e4c9582f19ae54ff68d68c68ef7e37f1162faac', 'message': 'Reduce number of processes on small systems\n\nEven the most modest 4C/8T system would run with the maximum 16 processes\ndue to the calculation being VCPU*2.\n\nWe devide amount of CPUs to number of threads for hyperthreaded CPUs\n\nChange-Id: Ie3c590d413b001ac9ccdb6522c9654b4372b5e10\n'}]",0,764652,5e4c9582f19ae54ff68d68c68ef7e37f1162faac,8,3,1,28619,,,0,"Reduce number of processes on small systems

Even the most modest 4C/8T system would run with the maximum 16 processes
due to the calculation being VCPU*2.

We devide amount of CPUs to number of threads for hyperthreaded CPUs

Change-Id: Ie3c590d413b001ac9ccdb6522c9654b4372b5e10
",git fetch https://review.opendev.org/openstack/openstack-ansible-os_swift refs/changes/52/764652/1 && git format-patch -1 --stdout FETCH_HEAD,['defaults/main.yml'],1,5e4c9582f19ae54ff68d68c68ef7e37f1162faac,api_threads,"swift_proxy_server_workers_not_capped: ""{{ [(ansible_processor_vcpus//ansible_processor_threads_per_core)|default(1), 1] | max * 2 }}""","swift_proxy_server_workers_not_capped: ""{{ [ansible_processor_vcpus|default(2) // 2, 1] | max }}""",1,1
openstack%2Fcharm-glance-simplestreams-sync~master~Id431d33f0e46eeca8a19fc2441d97f0b1bdf2be0,openstack/charm-glance-simplestreams-sync,master,Id431d33f0e46eeca8a19fc2441d97f0b1bdf2be0,Add Groovy to the test gate,MERGED,2020-11-05 11:46:57.000000000,2020-12-01 15:55:40.000000000,2020-12-01 15:55:40.000000000,"[{'_account_id': 12549}, {'_account_id': 20648}, {'_account_id': 22348}]","[{'number': 1, 'created': '2020-11-05 11:46:57.000000000', 'files': ['tests/tests.yaml', 'charmhelpers/contrib/openstack/utils.py', 'charmhelpers/contrib/storage/linux/ceph.py'], 'web_link': 'https://opendev.org/openstack/charm-glance-simplestreams-sync/commit/5ee94d7d8fb246751b4cdbe8bcd3f82d5399dc52', 'message': 'Add Groovy to the test gate\n\nChange-Id: Id431d33f0e46eeca8a19fc2441d97f0b1bdf2be0\n'}]",0,761557,5ee94d7d8fb246751b4cdbe8bcd3f82d5399dc52,14,3,1,31289,,,0,"Add Groovy to the test gate

Change-Id: Id431d33f0e46eeca8a19fc2441d97f0b1bdf2be0
",git fetch https://review.opendev.org/openstack/charm-glance-simplestreams-sync refs/changes/57/761557/1 && git format-patch -1 --stdout FETCH_HEAD,"['tests/tests.yaml', 'charmhelpers/contrib/openstack/utils.py', 'charmhelpers/contrib/storage/linux/ceph.py']",3,5ee94d7d8fb246751b4cdbe8bcd3f82d5399dc52,groovy-charm-gate," application_name,def send_application_name(relid=None): """"""Send the application name down the relation. :param relid: Relation id to set application name in. :type relid: str """""" relation_set( relation_id=relid, relation_settings={'application-name': application_name()}) Profiles are considered immutable so will not be updated if the named profile already exists. Please refer to [0] for more details. if erasure_profile_exists(service, profile_name): log('EC profile {} exists, skipping update'.format(profile_name), level=WARNING) return relation_set(relation_id=rid, relation_settings={'unit-name': local_unit()})"," Updates the profile if it exists. Please refer to [0] for more details. if erasure_profile_exists(service, profile_name): cmd.append('--force') ",24,11
openstack%2Fopenstack-ansible-os_placement~master~I1dbbfc82f24732f8534594ff25aefc03e5c4003c,openstack/openstack-ansible-os_placement,master,I1dbbfc82f24732f8534594ff25aefc03e5c4003c,Reduce number of processes on small systems,MERGED,2020-11-30 12:20:25.000000000,2020-12-01 15:53:12.000000000,2020-12-01 15:51:52.000000000,"[{'_account_id': 22348}, {'_account_id': 25023}, {'_account_id': 31542}]","[{'number': 1, 'created': '2020-11-30 12:20:25.000000000', 'files': ['defaults/main.yml'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_placement/commit/bf42c4a4038d7743df5134f41f803f26c3cdbd90', 'message': 'Reduce number of processes on small systems\n\nEven the most modest 4C/8T system would run with the maximum 16 processes\ndue to the calculation being VCPU*2.\n\nWe devide amount of CPUs to number of threads for hyperthreaded CPUs\n\nChange-Id: I1dbbfc82f24732f8534594ff25aefc03e5c4003c\n'}]",0,764658,bf42c4a4038d7743df5134f41f803f26c3cdbd90,8,3,1,28619,,,0,"Reduce number of processes on small systems

Even the most modest 4C/8T system would run with the maximum 16 processes
due to the calculation being VCPU*2.

We devide amount of CPUs to number of threads for hyperthreaded CPUs

Change-Id: I1dbbfc82f24732f8534594ff25aefc03e5c4003c
",git fetch https://review.opendev.org/openstack/openstack-ansible-os_placement refs/changes/58/764658/1 && git format-patch -1 --stdout FETCH_HEAD,['defaults/main.yml'],1,bf42c4a4038d7743df5134f41f803f26c3cdbd90,api_threads,"placement_wsgi_processes: ""{{ [[(ansible_processor_vcpus//ansible_processor_threads_per_core)|default(1), 1] | max * 2, placement_wsgi_processes_max] | min }}""","placement_wsgi_processes: ""{{ [[ansible_processor_vcpus|default(1), 1] | max * 2, placement_wsgi_processes_max] | min }}""",1,1
openstack%2Fhorizon~master~Id143db0e985c7b53cbb16e89547765ad02beed4d,openstack/horizon,master,Id143db0e985c7b53cbb16e89547765ad02beed4d,Remove retired qinling-dashbaord usage,MERGED,2020-11-28 16:45:46.000000000,2020-12-01 15:52:16.000000000,2020-12-01 15:48:57.000000000,"[{'_account_id': 841}, {'_account_id': 8648}, {'_account_id': 22348}, {'_account_id': 29313}, {'_account_id': 32231}]","[{'number': 1, 'created': '2020-11-28 16:45:46.000000000', 'files': ['plugin-registry.csv'], 'web_link': 'https://opendev.org/openstack/horizon/commit/0335f2f37d9310045af696a18b97ca71e8cd6abc', 'message': 'Remove retired qinling-dashbaord usage\n\nQinling project is retiring in Wallaby cycle[1].\nThis commit removes the usages/support of qinling-dashboard\nbefore its code is removed.\n\nNeeded-By: https://review.opendev.org/c/openstack/qinling-dashboard/+/764522\n\n[1] http://lists.openstack.org/pipermail/openstack-discuss/2020-November/018638.html\n\nChange-Id: Id143db0e985c7b53cbb16e89547765ad02beed4d\n'}]",0,764562,0335f2f37d9310045af696a18b97ca71e8cd6abc,10,5,1,8556,,,0,"Remove retired qinling-dashbaord usage

Qinling project is retiring in Wallaby cycle[1].
This commit removes the usages/support of qinling-dashboard
before its code is removed.

Needed-By: https://review.opendev.org/c/openstack/qinling-dashboard/+/764522

[1] http://lists.openstack.org/pipermail/openstack-discuss/2020-November/018638.html

Change-Id: Id143db0e985c7b53cbb16e89547765ad02beed4d
",git fetch https://review.opendev.org/openstack/horizon refs/changes/62/764562/1 && git format-patch -1 --stdout FETCH_HEAD,['plugin-registry.csv'],1,0335f2f37d9310045af696a18b97ca71e8cd6abc,retire-qinling,,"qinling-dashboard,:opendev-repo:`openstack/qinling-dashboard`,:storyboard:`openstack/qinling-dashboard`",0,1
openstack%2Fopenstack-ansible-os_ceilometer~stable%2Fussuri~Ica34b308378974a2b5501e85b2a8040ad457f4cb,openstack/openstack-ansible-os_ceilometer,stable/ussuri,Ica34b308378974a2b5501e85b2a8040ad457f4cb,Add event_pipeline support,MERGED,2020-11-15 07:29:43.000000000,2020-12-01 15:51:57.000000000,2020-12-01 15:49:49.000000000,"[{'_account_id': 22348}, {'_account_id': 25023}, {'_account_id': 28619}]","[{'number': 1, 'created': '2020-11-15 07:29:43.000000000', 'files': ['defaults/main.yml', 'vars/main.yml'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_ceilometer/commit/396b89817c654ceb18813b624b47bfbf7afcafd8', 'message': 'Add event_pipeline support\n\nChange-Id: Ica34b308378974a2b5501e85b2a8040ad457f4cb\nCloses-Bug: 1903395\n(cherry picked from commit edb0d72ad88d0ceb60180e55ff403eab9f20c0f8)\n'}]",0,762743,396b89817c654ceb18813b624b47bfbf7afcafd8,8,3,1,29605,,,0,"Add event_pipeline support

Change-Id: Ica34b308378974a2b5501e85b2a8040ad457f4cb
Closes-Bug: 1903395
(cherry picked from commit edb0d72ad88d0ceb60180e55ff403eab9f20c0f8)
",git fetch https://review.opendev.org/openstack/openstack-ansible-os_ceilometer refs/changes/43/762743/1 && git format-patch -1 --stdout FETCH_HEAD,"['defaults/main.yml', 'vars/main.yml']",2,396b89817c654ceb18813b624b47bfbf7afcafd8,762083-patch2-stable/ussuri,"ceilometer_event_pipeline_user_content: ""{{ lookup('file', ceilometer_event_pipeline_default_file_path, errors='ignore') }}"" - tmp_f: ""{{ (ceilometer_event_pipeline_user_content | length > 0) | ternary(false, '/tmp/event_pipeline.yaml') }}"" source_f: ""{{ ceilometer_lib_dir }}/ceilometer/pipeline/data/event_pipeline.yaml"" config_overrides: ""{{ ceilometer_event_pipeline_yaml_overrides }}"" config_type: ""yaml"" list_extend: false content: ""{{ ceilometer_event_pipeline_user_content }}""",,9,0
openstack%2Fnetworking-bagpipe~master~I18b7d2f8ec64a591b6297cca292a4cd476b3a502,openstack/networking-bagpipe,master,I18b7d2f8ec64a591b6297cca292a4cd476b3a502,Add privsep boilerplate for bagpipe,MERGED,2020-06-05 14:02:11.000000000,2020-12-01 15:50:04.000000000,2020-12-01 15:47:32.000000000,"[{'_account_id': 8313}, {'_account_id': 11975}, {'_account_id': 12021}, {'_account_id': 16688}, {'_account_id': 22348}]","[{'number': 1, 'created': '2020-06-05 14:02:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/networking-bagpipe/commit/dfeb8cc183d20aa2f66c137c4627b1e6026372e8', 'message': 'Add privsep boilerplate for bagpipe\n\nAdd boilerplate for using privsep in networking-bagpipe and change\ncalling sysctl to use privsep.\n\nChange-Id: I18b7d2f8ec64a591b6297cca292a4cd476b3a502\n'}, {'number': 2, 'created': '2020-06-08 12:30:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/networking-bagpipe/commit/887b9e840bc21b71997adc5c4445d52459dd7f17', 'message': 'Add privsep boilerplate for bagpipe\n\nAdd boilerplate for using privsep in networking-bagpipe and change\ncalling sysctl to use privsep.\n\nChange-Id: I18b7d2f8ec64a591b6297cca292a4cd476b3a502\n'}, {'number': 3, 'created': '2020-06-09 15:35:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/networking-bagpipe/commit/f1dfbce33664d7a850888e696c1115f778e7ed03', 'message': 'Add privsep boilerplate for bagpipe\n\nAdd boilerplate for using privsep in networking-bagpipe and change\ncalling sysctl to use privsep.\n\nChange-Id: I18b7d2f8ec64a591b6297cca292a4cd476b3a502\nStory: #2007686\nTask: #40027\n'}, {'number': 4, 'created': '2020-06-11 14:24:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/networking-bagpipe/commit/7aba02088954f1a6593735ae5942145d0c3d006e', 'message': 'Add privsep boilerplate for bagpipe\n\nAdd boilerplate for using privsep in networking-bagpipe and change\ncalling sysctl to use privsep.\n\nChange-Id: I18b7d2f8ec64a591b6297cca292a4cd476b3a502\nStory: #2007686\nTask: #40027\n'}, {'number': 5, 'created': '2020-06-16 12:18:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/networking-bagpipe/commit/733733a9aaccf8da70f85ee2a01505e3849703a3', 'message': 'Add privsep boilerplate for bagpipe\n\nAdd boilerplate for using privsep in networking-bagpipe and change\ncalling sysctl to use privsep.\n\nChange-Id: I18b7d2f8ec64a591b6297cca292a4cd476b3a502\nStory: #2007686\nTask: #40027\n'}, {'number': 6, 'created': '2020-06-17 19:45:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/networking-bagpipe/commit/1065a8d7c3e8ade523fd5cbd73e2cdfbb0ece247', 'message': 'Add privsep boilerplate for bagpipe\n\nAdd boilerplate for using privsep in networking-bagpipe and change\ncalling sysctl to use privsep.\n\nChange-Id: I18b7d2f8ec64a591b6297cca292a4cd476b3a502\nStory: #2007686\nTask: #40027\n'}, {'number': 7, 'created': '2020-06-23 14:44:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/networking-bagpipe/commit/95fb6ebdd3c4edbe0e230a18682ab2f9f5e62bf0', 'message': 'Add privsep boilerplate for bagpipe\n\nAdd boilerplate for using privsep in networking-bagpipe and change\ncalling sysctl to use privsep.\n\nChange-Id: I18b7d2f8ec64a591b6297cca292a4cd476b3a502\nStory: #2007686\nTask: #40027\n'}, {'number': 8, 'created': '2020-10-12 09:54:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/networking-bagpipe/commit/4ee5dff5161153a8540359dd3993db5e17de24b0', 'message': 'Add privsep boilerplate for bagpipe\n\nAdd boilerplate for using privsep in networking-bagpipe and change\ncalling sysctl to use privsep.\n\nChange-Id: I18b7d2f8ec64a591b6297cca292a4cd476b3a502\nStory: #2007686\nTask: #40027\n'}, {'number': 9, 'created': '2020-10-12 17:11:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/networking-bagpipe/commit/00674f465b4b0ad45507f3decf141a3e7bf4c467', 'message': 'Add privsep boilerplate for bagpipe\n\nAdd boilerplate for using privsep in networking-bagpipe and change\ncalling sysctl to use privsep.\n\nChange-Id: I18b7d2f8ec64a591b6297cca292a4cd476b3a502\nStory: #2007686\nTask: #40027\n'}, {'number': 10, 'created': '2020-10-13 11:01:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/networking-bagpipe/commit/9dba51bfcad0a5a9000f2c1de46ed5f9434aca35', 'message': 'Add privsep boilerplate for bagpipe\n\nAdd boilerplate for using privsep in networking-bagpipe and change\ncalling sysctl to use privsep.\n\nChange-Id: I18b7d2f8ec64a591b6297cca292a4cd476b3a502\nDepends-On: https://review.opendev.org/755719\nStory: #2007686\nTask: #40027\n'}, {'number': 11, 'created': '2020-11-09 12:13:28.000000000', 'files': ['networking_bagpipe/tests/unit/privileged/test_privileged_utils.py', 'networking_bagpipe/tests/unit/privileged/__init__.py', 'releasenotes/notes/privsep-sysctl-a6321b31de29fce1.yaml', 'networking_bagpipe/bagpipe_bgp/vpn/ipvpn/mpls_ovs_dataplane.py', 'lower-constraints.txt', 'networking_bagpipe/bagpipe_bgp/common/config.py', 'requirements.txt', 'bindep.txt', 'networking_bagpipe/bagpipe_bgp/vpn/ipvpn/mpls_linux_dataplane.py', 'networking_bagpipe/tests/unit/privileged/privsep_fixtures.py', 'networking_bagpipe/privileged/__init__.py', 'networking_bagpipe/privileged/privileged_utils.py'], 'web_link': 'https://opendev.org/openstack/networking-bagpipe/commit/93d660c210371827cff4a4f5d944fbb97d462a9d', 'message': 'Add privsep boilerplate for bagpipe\n\nAdd boilerplate for using privsep in networking-bagpipe and change\ncalling sysctl to use privsep.\n\nChange-Id: I18b7d2f8ec64a591b6297cca292a4cd476b3a502\nDepends-On: https://review.opendev.org/755719\nStory: #2007686\nTask: #40027\n'}]",27,733848,93d660c210371827cff4a4f5d944fbb97d462a9d,53,5,11,8313,,,0,"Add privsep boilerplate for bagpipe

Add boilerplate for using privsep in networking-bagpipe and change
calling sysctl to use privsep.

Change-Id: I18b7d2f8ec64a591b6297cca292a4cd476b3a502
Depends-On: https://review.opendev.org/755719
Story: #2007686
Task: #40027
",git fetch https://review.opendev.org/openstack/networking-bagpipe refs/changes/48/733848/9 && git format-patch -1 --stdout FETCH_HEAD,"['networking_bagpipe/bagpipe_bgp/vpn/ipvpn/mpls_linux_dataplane.py', 'releasenotes/notes/privsep-sysctl-a6321b31de29fce1.yaml', 'etc/bagpipe-bgp/rootwrap.d/linux-sysctl.filters', 'networking_bagpipe/privileged/__init__.py', 'networking_bagpipe/privileged/privileged_sysctl.py']",5,dfeb8cc183d20aa2f66c137c4627b1e6026372e8,privsep,"# Licensed under the Apache License, Version 2.0 (the ""License""); you may # not use this file except in compliance with the License. You may obtain # a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT # WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the # License for the specific language governing permissions and limitations # under the License. from oslo_concurrency import processutils from networking_bagpipe import privileged @privileged.sysctl_cmd.entrypoint def sysctl(knob, value): """"""Run sysctl command :param knob: (string) sysctl knob name, a path under /proc/sys, see: https://review.opendev.org/665155 :param value: (int) value to be set in the knob :return: 1 if the command succeeded, 0 otherwise """""" cmd = ['sysctl'] knob = '/proc/sys/' + knob cmd += ['-w', '%s=%s' % (knob, value)] result = processutils.execute(*cmd, check_exit_code=True) return 1 if result[1] else 0 ",,76,14
openstack%2Fhorizon~master~I4d73c0e09630ad37ef9401137fd55b086178fa2c,openstack/horizon,master,I4d73c0e09630ad37ef9401137fd55b086178fa2c,Remove retired searchlight-ui usage,MERGED,2020-11-28 22:08:11.000000000,2020-12-01 15:31:59.000000000,2020-12-01 15:27:59.000000000,"[{'_account_id': 841}, {'_account_id': 8648}, {'_account_id': 22348}, {'_account_id': 28182}, {'_account_id': 29313}, {'_account_id': 32231}]","[{'number': 1, 'created': '2020-11-28 22:08:11.000000000', 'files': ['plugin-registry.csv'], 'web_link': 'https://opendev.org/openstack/horizon/commit/94707c743be827c407eea52f1d6ee5695094bfb8', 'message': 'Remove retired searchlight-ui usage\n\nSearchlight project is retiring in Wallaby cycle[1].\nThis commit removes the usages/support of searchlight-ui\nbefore its code is removed.\n\nNeeded-By: https://review.opendev.org/c/openstack/searchlight-ui/+/764528\n\n[1] http://lists.openstack.org/pipermail/openstack-discuss/2020-November/018637.html\n\nChange-Id: I4d73c0e09630ad37ef9401137fd55b086178fa2c\n'}]",0,764567,94707c743be827c407eea52f1d6ee5695094bfb8,11,6,1,8556,,,0,"Remove retired searchlight-ui usage

Searchlight project is retiring in Wallaby cycle[1].
This commit removes the usages/support of searchlight-ui
before its code is removed.

Needed-By: https://review.opendev.org/c/openstack/searchlight-ui/+/764528

[1] http://lists.openstack.org/pipermail/openstack-discuss/2020-November/018637.html

Change-Id: I4d73c0e09630ad37ef9401137fd55b086178fa2c
",git fetch https://review.opendev.org/openstack/horizon refs/changes/67/764567/1 && git format-patch -1 --stdout FETCH_HEAD,['plugin-registry.csv'],1,94707c743be827c407eea52f1d6ee5695094bfb8,retire-searchlight,,"searchlight-ui,:opendev-repo:`openstack/searchlight-ui`,:storyboard:`openstack/searchlight-ui`",0,1
openstack%2Fpanko~master~Idf9a184f969e5f77de0c2f2a2b99c2931f5647e0,openstack/panko,master,Idf9a184f969e5f77de0c2f2a2b99c2931f5647e0,Add a /healthcheck by default,MERGED,2020-06-16 10:48:28.000000000,2020-12-01 15:23:43.000000000,2020-12-01 15:18:23.000000000,"[{'_account_id': 1736}, {'_account_id': 4264}, {'_account_id': 6476}, {'_account_id': 6732}, {'_account_id': 22348}]","[{'number': 1, 'created': '2020-06-16 10:48:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/panko/commit/f8a7dd0c3742f0daa787eb9ee1ac2b5014b020cc', 'message': 'Add a /healthcheck by default\n\nThis patch adds a /healthcheck URL by default, using oslo.middleware,\nso that operators can use it to configure haproxy / monitoring.\n\nChange-Id: Idf9a184f969e5f77de0c2f2a2b99c2931f5647e0\n'}, {'number': 2, 'created': '2020-07-02 09:27:25.000000000', 'files': ['etc/panko/api_paste.ini'], 'web_link': 'https://opendev.org/openstack/panko/commit/e8a71c83adb30293f3aea4e55fcb686c3d9aa6c4', 'message': 'Add a /healthcheck by default\n\nThis patch adds a /healthcheck URL by default, using oslo.middleware,\nso that operators can use it to configure haproxy / monitoring.\n\nChange-Id: Idf9a184f969e5f77de0c2f2a2b99c2931f5647e0\n'}]",2,735867,e8a71c83adb30293f3aea4e55fcb686c3d9aa6c4,12,5,2,6476,,,0,"Add a /healthcheck by default

This patch adds a /healthcheck URL by default, using oslo.middleware,
so that operators can use it to configure haproxy / monitoring.

Change-Id: Idf9a184f969e5f77de0c2f2a2b99c2931f5647e0
",git fetch https://review.opendev.org/openstack/panko refs/changes/67/735867/1 && git format-patch -1 --stdout FETCH_HEAD,['etc/panko/api_paste.ini'],1,f8a7dd0c3742f0daa787eb9ee1ac2b5014b020cc,,/healthcheck = healthcheck/healthcheck = healthcheck [app:healthcheck] paste.app_factory = oslo_middleware:Healthcheck.app_factory backends = disable_by_file disable_by_file_path = /etc/cinder/healthcheck_disable,,7,0
openstack%2Fnova-specs~master~I476a4e460fd61ff9da800b4dd438da37a10806d9,openstack/nova-specs,master,I476a4e460fd61ff9da800b4dd438da37a10806d9,Add IP address to libvirt guest metadata,MERGED,2020-11-02 06:26:02.000000000,2020-12-01 15:19:33.000000000,2020-12-01 15:14:29.000000000,"[{'_account_id': 7166}, {'_account_id': 9531}, {'_account_id': 9708}, {'_account_id': 11604}, {'_account_id': 15334}, {'_account_id': 22348}]","[{'number': 1, 'created': '2020-11-02 06:26:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/6aadfc45371fb644cd59bc8121331c7bfe955a19', 'message': 'Add IP address to libvirt guest metadata\n\nChange-Id: I476a4e460fd61ff9da800b4dd438da37a10806d9\nblueprint: libvirt-driver-ip-metadata\nSigned-off-by: Nobuhiro MIKI <nmiki@yahoo-corp.jp>\n'}, {'number': 2, 'created': '2020-11-02 06:54:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/063be1c9a5b5e433f14386ca2d26029813bbdd0e', 'message': 'Add IP address to libvirt guest metadata\n\nChange-Id: I476a4e460fd61ff9da800b4dd438da37a10806d9\nblueprint: libvirt-driver-ip-metadata\nSigned-off-by: Nobuhiro MIKI <nmiki@yahoo-corp.jp>\n'}, {'number': 3, 'created': '2020-11-24 08:05:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/f81e78ff3464f2cafff097d1bef31376375ef200', 'message': 'Add IP address to libvirt guest metadata\n\nChange-Id: I476a4e460fd61ff9da800b4dd438da37a10806d9\nblueprint: libvirt-driver-ip-metadata\nSigned-off-by: Nobuhiro MIKI <nmiki@yahoo-corp.jp>\n'}, {'number': 4, 'created': '2020-11-24 08:26:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/5f6aea8260c78d4482ad28b9d25ba7f73554e2f3', 'message': 'Add IP address to libvirt guest metadata\n\nChange-Id: I476a4e460fd61ff9da800b4dd438da37a10806d9\nblueprint: libvirt-driver-ip-metadata\nSigned-off-by: Nobuhiro MIKI <nmiki@yahoo-corp.jp>\n'}, {'number': 5, 'created': '2020-11-26 02:19:12.000000000', 'files': ['specs/wallaby/approved/libvirt-driver-ip-metadata.rst'], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/0c413047f1687887314321e66ef1f1b36615d229', 'message': 'Add IP address to libvirt guest metadata\n\nChange-Id: I476a4e460fd61ff9da800b4dd438da37a10806d9\nblueprint: libvirt-driver-ip-metadata\nSigned-off-by: Nobuhiro MIKI <nmiki@yahoo-corp.jp>\n'}]",21,760750,0c413047f1687887314321e66ef1f1b36615d229,23,6,5,31652,,,0,"Add IP address to libvirt guest metadata

Change-Id: I476a4e460fd61ff9da800b4dd438da37a10806d9
blueprint: libvirt-driver-ip-metadata
Signed-off-by: Nobuhiro MIKI <nmiki@yahoo-corp.jp>
",git fetch https://review.opendev.org/openstack/nova-specs refs/changes/50/760750/4 && git format-patch -1 --stdout FETCH_HEAD,['specs/wallaby/approved/libvirt-driver-ip-metadata.rst'],1,6aadfc45371fb644cd59bc8121331c7bfe955a19,bp/libvirt-driver-ip-metadata,".. This work is licensed under a Creative Commons Attribution 3.0 Unported License. http://creativecommons.org/licenses/by/3.0/legalcode ========================================== Add IP address to libvirt guest metadata ========================================== https://blueprints.launchpad.net/nova/+spec/libvirt-driver-ip-metadata Past Blueprint [1]_ has provided useful instance information to system administrators through the libvirt domain XML configuration. This time, I propose to extend this metadata to include IP addresses of instances. Problem description =================== In a virtualized environment using libvirt, qemu and kvm, the instance configuration information is stored in XML and used by libvirt to launch and manage instances. This XML contains useful configuration information such as instance names, flavors and images as metadata [2]_. Here, I noticed that IP addresses are not included. Use Cases --------- With this proposal, we can get IP addresses of instances on the nova-compute node without going through nova or neutron's REST API. As an example, operators can collect and monitor statistics based on an instance's IP address at the low cost of simply loading XML. Proposed change =============== So I propose to add IP addresses to the metadata in this Blueprint. Here is an example of the metadata description with the IP address. If an instance has more than one IP address, enumerate those IP addresses. :: <domain type='kvm' id='5'> ... <metadata> <nova:instance xmlns:nova=""http://openstack.org/xmlns/libvirt/nova/1.0""> <nova:package version=""18.1.1""/> <nova:name>sample-instance-name</nova:name> <nova:creationTime>2020-10-23 05:36:41</nova:creationTime> <nova:flavor name=""sample-flavor""> <nova:memory>348160</nova:memory> <nova:disk>100</nova:disk> <nova:swap>0</nova:swap> <nova:ephemeral>0</nova:ephemeral> <nova:vcpus>80</nova:vcpus> </nova:flavor> <nova:owner> <nova:user uuid=""2997526f-669c-4bd9-af5f-68c6ba0cc2f0"">sample-user</nova:user> <nova:project uuid=""acf923f2-9b4d-4e0d-acfb-1b2976dd480f"">sample-project</nova:project> </nova:owner> <nova:root type=""image"" uuid=""66e81ebe-9d4f-45ae-b79b-b3d9dc989b21""/> <!-- I suggest adding the following line --> <nova:ip type=""fixed"" address=""192.168.1.1""/> </nova:instance> </metadata> ... </domain> Alternatives ------------ Of course, we can get IP addresses of instances via the REST API. However, in the above use case, we can get that information at a lower cost by loading XML. Data model impact ----------------- None. REST API impact --------------- None. Security impact --------------- None. Notifications impact -------------------- None. Other end user impact --------------------- None. Existing metadata is not manipulated. Performance Impact ------------------ None. Other deployer impact --------------------- None. Developer impact ---------------- None. Upgrade impact -------------- None. Implementation ============== Assignee(s) ----------- Primary assignee: nmiki Other contributors: None Feature Liaison --------------- Liaison Needed. Work Items ---------- * Add a new object that corresponds to the IP address in nova/virt/libvirt/config.py. For example, it would be named something like LibvirtConfigGuestMetaNovaIp. * Add network_info as an argument to _get_guest_config_meta to retrieve information about networks, including IP addresses. * Implement unit tests in nova/tests/unit/virt/libvirt/test_config.py. Dependencies ============ None. Testing ======= There is no integration with other systems, so only unit tests can ensure correctness. It covers the case of having no IP address, only one, or multiple IP addresses. Documentation Impact ==================== Documentation for administrators describing that IP addresses are added as metadata in libvirt xml. References ========== .. [1] https://blueprints.launchpad.net/nova/+spec/libvirt-driver-domain-metadata .. [2] http://libvirt.org/formatdomain.html#elementsMetadata History ======= .. list-table:: Revisions :header-rows: 1 * - Release Name - Description * - Wallaby - Introduced ",,189,0
openstack%2Fopenstack-ansible-openstack_openrc~stable%2Fussuri~Iff5a0892d812601c0fa3fd549b7f00a468cfdd97,openstack/openstack-ansible-openstack_openrc,stable/ussuri,Iff5a0892d812601c0fa3fd549b7f00a468cfdd97,Adding support of system scoped openrc and clouds.yaml,MERGED,2020-11-20 07:08:43.000000000,2020-12-01 15:19:09.000000000,2020-12-01 15:13:34.000000000,"[{'_account_id': 22348}, {'_account_id': 25023}, {'_account_id': 28619}]","[{'number': 1, 'created': '2020-11-20 07:08:43.000000000', 'files': ['releasenotes/notes/system_scope_support-ab364c1725e2506e.yaml', 'tasks/main.yml', 'templates/openrc-system-scope.j2', 'defaults/main.yml', 'templates/clouds.yaml.j2'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-openstack_openrc/commit/2156eb0c55d1a715b589dd1524a84318b10b7f8b', 'message': 'Adding support of system scoped openrc and clouds.yaml\n\nChange-Id: Iff5a0892d812601c0fa3fd549b7f00a468cfdd97\nCloses-Bug: 1903656\n(cherry picked from commit fdc640ddcbc13de17609005f4ca34cc4067cd5f8)\n'}]",0,763508,2156eb0c55d1a715b589dd1524a84318b10b7f8b,8,3,1,29605,,,0,"Adding support of system scoped openrc and clouds.yaml

Change-Id: Iff5a0892d812601c0fa3fd549b7f00a468cfdd97
Closes-Bug: 1903656
(cherry picked from commit fdc640ddcbc13de17609005f4ca34cc4067cd5f8)
",git fetch https://review.opendev.org/openstack/openstack-ansible-openstack_openrc refs/changes/08/763508/1 && git format-patch -1 --stdout FETCH_HEAD,"['releasenotes/notes/system_scope_support-ab364c1725e2506e.yaml', 'tasks/main.yml', 'templates/openrc-system-scope.j2', 'defaults/main.yml', 'templates/clouds.yaml.j2']",5,2156eb0c55d1a715b589dd1524a84318b10b7f8b,762090-patch4-patch6-stable/ussuri,"{% if openrc_system_scope | default(false) | bool %} system_scope: all {% else %} project_domain_name: {{ openrc_os_domain_name }} {% endif %}{% if openrc_system_scope | default(false) | bool %} default_project_scope: auth: auth_url: {{ openrc_os_auth_url }} project_name: {{ openrc_os_tenant_name }} tenant_name: {{ openrc_os_tenant_name }} project_domain_name: {{ openrc_os_domain_name }} username: {{ openrc_os_username }} password: {{ openrc_os_password }} user_domain_name: {{ openrc_os_domain_name }} region_name: {{ openrc_region_name }} interface: {{ openrc_clouds_yml_interface }} {% if openrc_os_auth_url.endswith('v2.0') %} identity_api_version: ""2.0"" {% else %} identity_api_version: ""3"" {% endif %} {% if openrc_insecure | bool %} verify: false insecure: true {% endif %} {% endif %}", project_domain_name: {{ openrc_os_domain_name }},106,4
openstack%2Fcharm-cinder-backup-swift-proxy~master~I9f9f7ec89b9d1ea1e179425d4bf51b5cad26080d,openstack/charm-cinder-backup-swift-proxy,master,I9f9f7ec89b9d1ea1e179425d4bf51b5cad26080d,Add Groovy to the test gate,MERGED,2020-11-05 11:45:29.000000000,2020-12-01 15:11:13.000000000,2020-12-01 15:11:13.000000000,"[{'_account_id': 12549}, {'_account_id': 20648}, {'_account_id': 22348}]","[{'number': 1, 'created': '2020-11-05 11:45:29.000000000', 'files': ['src/tests/tests.yaml'], 'web_link': 'https://opendev.org/openstack/charm-cinder-backup-swift-proxy/commit/27e22e85726047ecbb16ef51bc73b86defb76e1a', 'message': 'Add Groovy to the test gate\n\nChange-Id: I9f9f7ec89b9d1ea1e179425d4bf51b5cad26080d\n'}]",0,761551,27e22e85726047ecbb16ef51bc73b86defb76e1a,9,3,1,31289,,,0,"Add Groovy to the test gate

Change-Id: I9f9f7ec89b9d1ea1e179425d4bf51b5cad26080d
",git fetch https://review.opendev.org/openstack/charm-cinder-backup-swift-proxy refs/changes/51/761551/1 && git format-patch -1 --stdout FETCH_HEAD,['src/tests/tests.yaml'],1,27e22e85726047ecbb16ef51bc73b86defb76e1a,groovy-charm-gate, - groovy-victoria-swift-v3,dev_bundles: - groovy-victoria-swift-v3,1,2
openstack%2Fcharm-designate-bind~master~I8c0a019a056e5decf53ef9652ece2c9ba10994a7,openstack/charm-designate-bind,master,I8c0a019a056e5decf53ef9652ece2c9ba10994a7,Add Groovy to the test gate,MERGED,2020-11-05 11:46:27.000000000,2020-12-01 15:10:53.000000000,2020-12-01 15:10:53.000000000,"[{'_account_id': 12549}, {'_account_id': 19298}, {'_account_id': 20648}, {'_account_id': 22348}]","[{'number': 1, 'created': '2020-11-05 11:46:27.000000000', 'files': ['src/tests/tests.yaml'], 'web_link': 'https://opendev.org/openstack/charm-designate-bind/commit/2a2004096c06b6e4a65be96f5510b70decf58d48', 'message': 'Add Groovy to the test gate\n\nChange-Id: I8c0a019a056e5decf53ef9652ece2c9ba10994a7\n'}]",0,761555,2a2004096c06b6e4a65be96f5510b70decf58d48,10,4,1,31289,,,0,"Add Groovy to the test gate

Change-Id: I8c0a019a056e5decf53ef9652ece2c9ba10994a7
",git fetch https://review.opendev.org/openstack/charm-designate-bind refs/changes/55/761555/1 && git format-patch -1 --stdout FETCH_HEAD,['src/tests/tests.yaml'],1,2a2004096c06b6e4a65be96f5510b70decf58d48,groovy-charm-gate,, dev_bundles:,0,2
openstack%2Fcastellan~master~I9dddba1e52bbf1ee1d8227fdb45e625fdbf0a21b,openstack/castellan,master,I9dddba1e52bbf1ee1d8227fdb45e625fdbf0a21b,Don't expect barbican service name to be barbican.,MERGED,2020-12-01 02:54:40.000000000,2020-12-01 15:01:11.000000000,2020-12-01 14:56:23.000000000,"[{'_account_id': 7973}, {'_account_id': 10873}, {'_account_id': 22348}, {'_account_id': 27954}]","[{'number': 1, 'created': '2020-12-01 02:54:40.000000000', 'files': ['castellan/key_manager/barbican_key_manager.py'], 'web_link': 'https://opendev.org/openstack/castellan/commit/4a4544b8ec2a68b1fdbf79cf0e6142c9e8c5357b', 'message': ""Don't expect barbican service name to be barbican.\n\nIt is standard practice to search for services in the catalog by\nservice type and interface only. Service name should be left\nto deployers to choose and this could be something other than barbican.\n\nChange-Id: I9dddba1e52bbf1ee1d8227fdb45e625fdbf0a21b\n""}]",0,764874,4a4544b8ec2a68b1fdbf79cf0e6142c9e8c5357b,11,4,1,3031,,,0,"Don't expect barbican service name to be barbican.

It is standard practice to search for services in the catalog by
service type and interface only. Service name should be left
to deployers to choose and this could be something other than barbican.

Change-Id: I9dddba1e52bbf1ee1d8227fdb45e625fdbf0a21b
",git fetch https://review.opendev.org/openstack/castellan refs/changes/74/764874/1 && git format-patch -1 --stdout FETCH_HEAD,['castellan/key_manager/barbican_key_manager.py'],1,4a4544b8ec2a68b1fdbf79cf0e6142c9e8c5357b,,," 'service_name': 'barbican',",0,1
openstack%2Ftosca-parser~master~Ic57383420558744f48eeb12eb8cbe6b1ab3dc0e3,openstack/tosca-parser,master,Ic57383420558744f48eeb12eb8cbe6b1ab3dc0e3,Add Python3 wallaby unit tests,MERGED,2020-11-27 02:54:53.000000000,2020-12-01 15:00:41.000000000,2020-12-01 14:49:36.000000000,"[{'_account_id': 6456}, {'_account_id': 16511}, {'_account_id': 17255}, {'_account_id': 22348}, {'_account_id': 31821}, {'_account_id': 32102}]","[{'number': 1, 'created': '2020-11-27 02:54:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tosca-parser/commit/39d024fb026771f0b68b046b676b31beb14836df', 'message': '[DNM] Add Python3 wallaby unit tests\n\nThis update is to switch to wallaby jobs run with the latest tested\nruntimes. See Project Testing Interface for the details [1].\n\n[1] https://governance.openstack.org/tc/reference/project-testing-interface.html\n\nSigned-off-by: Yasufumi Ogawa <yasufum.o@gmail.com>\nChange-Id: Ic57383420558744f48eeb12eb8cbe6b1ab3dc0e3\n'}, {'number': 2, 'created': '2020-11-27 03:58:27.000000000', 'files': ['.zuul.yaml'], 'web_link': 'https://opendev.org/openstack/tosca-parser/commit/62f0d45fe15c672c905af32c66eb1d238b2ed6e8', 'message': 'Add Python3 wallaby unit tests\n\nThis update is to switch to wallaby jobs run with the latest tested\nruntimes. See Project Testing Interface for the details [1].\n\n[1] https://governance.openstack.org/tc/reference/project-testing-interface.html\n\nSigned-off-by: Yasufumi Ogawa <yasufum.o@gmail.com>\nChange-Id: Ic57383420558744f48eeb12eb8cbe6b1ab3dc0e3\n'}]",0,764400,62f0d45fe15c672c905af32c66eb1d238b2ed6e8,13,6,2,25701,,,0,"Add Python3 wallaby unit tests

This update is to switch to wallaby jobs run with the latest tested
runtimes. See Project Testing Interface for the details [1].

[1] https://governance.openstack.org/tc/reference/project-testing-interface.html

Signed-off-by: Yasufumi Ogawa <yasufum.o@gmail.com>
Change-Id: Ic57383420558744f48eeb12eb8cbe6b1ab3dc0e3
",git fetch https://review.opendev.org/openstack/tosca-parser refs/changes/00/764400/1 && git format-patch -1 --stdout FETCH_HEAD,['.zuul.yaml'],1,39d024fb026771f0b68b046b676b31beb14836df,add-wallaby-python-jobtemplates, - openstack-python3-wallaby-jobs, - openstack-python3-ussuri-jobs,1,1
openstack%2Fbarbican~master~Iad2e2f56e4cd71f371c760eef85cb121ef1438fe,openstack/barbican,master,Iad2e2f56e4cd71f371c760eef85cb121ef1438fe,Fix hacking min version to 3.0.1,MERGED,2020-11-02 05:58:48.000000000,2020-12-01 15:00:29.000000000,2020-12-01 14:46:48.000000000,"[{'_account_id': 7973}, {'_account_id': 22348}, {'_account_id': 27954}, {'_account_id': 32291}]","[{'number': 1, 'created': '2020-11-02 05:58:48.000000000', 'files': ['test-requirements.txt'], 'web_link': 'https://opendev.org/openstack/barbican/commit/dbda8ecbe3c4bedc1d6d89d850a8a574603e244a', 'message': 'Fix hacking min version to 3.0.1\n\nflake8 new release 3.8.0 added new checks and gate pep8\njob start failing. hacking 3.0.1 fix the pinning of flake8 to\navoid bringing in a new version with new checks.\n\nThough it is fixed in latest hacking but 2.0 and 3.0 has cap for\nflake8 as <4.0.0 which mean flake8 new version 3.9.0 can also\nbreak the pep8 job if new check are added.\n\nTo avoid similar gate break in future, we need to bump the hacking min\nversion.\n\n- http://lists.openstack.org/pipermail/openstack-discuss/2020-May/014828.html\n\nChange-Id: Iad2e2f56e4cd71f371c760eef85cb121ef1438fe\n'}]",0,760744,dbda8ecbe3c4bedc1d6d89d850a8a574603e244a,13,4,1,32291,,,0,"Fix hacking min version to 3.0.1

flake8 new release 3.8.0 added new checks and gate pep8
job start failing. hacking 3.0.1 fix the pinning of flake8 to
avoid bringing in a new version with new checks.

Though it is fixed in latest hacking but 2.0 and 3.0 has cap for
flake8 as <4.0.0 which mean flake8 new version 3.9.0 can also
break the pep8 job if new check are added.

To avoid similar gate break in future, we need to bump the hacking min
version.

- http://lists.openstack.org/pipermail/openstack-discuss/2020-May/014828.html

Change-Id: Iad2e2f56e4cd71f371c760eef85cb121ef1438fe
",git fetch https://review.opendev.org/openstack/barbican refs/changes/44/760744/1 && git format-patch -1 --stdout FETCH_HEAD,['test-requirements.txt'],1,dbda8ecbe3c4bedc1d6d89d850a8a574603e244a,,"hacking>=3.0.1,<3.1.0 # Apache-2.0","hacking>=3.0,<3.1.0 # Apache-2.0",1,1
openstack%2Fbarbican~master~I7dfc70c048fadd2f4efd491af423e8d11c42b229,openstack/barbican,master,I7dfc70c048fadd2f4efd491af423e8d11c42b229,Imported Translations from Zanata,MERGED,2020-11-04 06:57:49.000000000,2020-12-01 14:57:31.000000000,2020-12-01 14:45:08.000000000,"[{'_account_id': 7973}, {'_account_id': 22348}, {'_account_id': 27954}]","[{'number': 1, 'created': '2020-11-04 06:57:49.000000000', 'files': ['releasenotes/source/locale/en_GB/LC_MESSAGES/releasenotes.po'], 'web_link': 'https://opendev.org/openstack/barbican/commit/90cae5ae0fe4d8618cde0dca6b8f9404eb992359', 'message': 'Imported Translations from Zanata\n\nFor more information about this automatic import see:\nhttps://docs.openstack.org/i18n/latest/reviewing-translation-import.html\n\nChange-Id: I7dfc70c048fadd2f4efd491af423e8d11c42b229\n'}]",0,761281,90cae5ae0fe4d8618cde0dca6b8f9404eb992359,8,3,1,11131,,,0,"Imported Translations from Zanata

For more information about this automatic import see:
https://docs.openstack.org/i18n/latest/reviewing-translation-import.html

Change-Id: I7dfc70c048fadd2f4efd491af423e8d11c42b229
",git fetch https://review.opendev.org/openstack/barbican refs/changes/81/761281/1 && git format-patch -1 --stdout FETCH_HEAD,['releasenotes/source/locale/en_GB/LC_MESSAGES/releasenotes.po'],1,90cae5ae0fe4d8618cde0dca6b8f9404eb992359,zanata/translations,"""POT-Creation-Date: 2020-10-30 16:27+0000\n""""PO-Revision-Date: 2020-11-03 10:09+0000\n""msgid ""11.0.0-15"" msgstr ""11.0.0-15"" ""Fixed Story #2006978: An admin user now can delete other users secrets by "" ""adjust the policy file."" msgstr """" ""Fixed Story #2006978: An admin user now can delete other users secrets by "" ""adjust the policy file."" msgid """"""The hsm subcommand for the barbican-manage command line tool no longer "" ""requires any parameters at run time. If any value used by the PKCS#11 value "" ""is needed it will be taken from /etc/barbican/barbican.conf. You may "" ""continue to specify any values on the command line, and those will take "" ""precedence over the values specified in barbican.conf, so any existing "" ""scripts that use barbican-manage should continue to work as expected."" msgstr """" ""The hsm subcommand for the barbican-manage command line tool no longer "" ""requires any parameters at run time. If any value used by the PKCS#11 value "" ""is needed it will be taken from /etc/barbican/barbican.conf. You may "" ""continue to specify any values on the command line, and those will take "" ""precedence over the values specified in barbican.conf, so any existing "" ""scripts that use barbican-manage should continue to work as expected."" msgid """"","""POT-Creation-Date: 2020-10-28 22:41+0000\n""""PO-Revision-Date: 2020-10-28 01:16+0000\n""",27,2
openstack%2Fbarbican-tempest-plugin~master~I234c3b205ee21b59953aa6ce7af5c2a1e4a6cfa6,openstack/barbican-tempest-plugin,master,I234c3b205ee21b59953aa6ce7af5c2a1e4a6cfa6,Remove six,MERGED,2020-11-03 05:43:45.000000000,2020-12-01 14:44:07.000000000,2020-12-01 14:44:07.000000000,"[{'_account_id': 7973}, {'_account_id': 22348}, {'_account_id': 27954}, {'_account_id': 32238}]","[{'number': 1, 'created': '2020-11-03 05:43:45.000000000', 'files': ['barbican_tempest_plugin/services/key_manager/json/order_client.py', 'requirements.txt', 'barbican_tempest_plugin/services/key_manager/json/quota_client.py', 'barbican_tempest_plugin/services/key_manager/json/consumer_client.py', 'barbican_tempest_plugin/services/key_manager/json/container_client.py', 'barbican_tempest_plugin/services/key_manager/json/secret_client.py'], 'web_link': 'https://opendev.org/openstack/barbican-tempest-plugin/commit/0525790271114323c9028e24777218823e613ec3', 'message': 'Remove six\n\nRemove six Replace the following items with Python 3 style code.\n- six.moves.urllib\n- six.binary_type\n\nChange-Id: I234c3b205ee21b59953aa6ce7af5c2a1e4a6cfa6\n'}]",0,761051,0525790271114323c9028e24777218823e613ec3,17,4,1,32238,,,0,"Remove six

Remove six Replace the following items with Python 3 style code.
- six.moves.urllib
- six.binary_type

Change-Id: I234c3b205ee21b59953aa6ce7af5c2a1e4a6cfa6
",git fetch https://review.opendev.org/openstack/barbican-tempest-plugin refs/changes/51/761051/1 && git format-patch -1 --stdout FETCH_HEAD,"['barbican_tempest_plugin/services/key_manager/json/order_client.py', 'requirements.txt', 'barbican_tempest_plugin/services/key_manager/json/quota_client.py', 'barbican_tempest_plugin/services/key_manager/json/consumer_client.py', 'barbican_tempest_plugin/services/key_manager/json/container_client.py', 'barbican_tempest_plugin/services/key_manager/json/secret_client.py']",6,0525790271114323c9028e24777218823e613ec3,, if 'payload' in kwargs and type(kwargs['payload']) is bytes:,import six if 'payload' in kwargs and type(kwargs['payload']) is six.binary_type:,5,7
openstack%2Fopenstack-ansible~stable%2Ftrain~Ib7532b50957012b6b41fa00cb488e724c5bac6e7,openstack/openstack-ansible,stable/train,Ib7532b50957012b6b41fa00cb488e724c5bac6e7,Bump SHAs for stable/train,MERGED,2020-11-29 17:03:17.000000000,2020-12-01 14:43:12.000000000,2020-12-01 14:39:53.000000000,"[{'_account_id': 22348}, {'_account_id': 25023}, {'_account_id': 31542}]","[{'number': 1, 'created': '2020-11-29 17:03:17.000000000', 'files': ['playbooks/defaults/repo_packages/openstack_services.yml', 'playbooks/defaults/repo_packages/gnocchi.yml', 'playbooks/defaults/repo_packages/nova_consoles.yml', 'ansible-role-requirements.yml'], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/6fc02d56e8a4404c0601804242e6b730a8f9bb05', 'message': 'Bump SHAs for stable/train\n\nChange-Id: Ib7532b50957012b6b41fa00cb488e724c5bac6e7\n'}]",0,764591,6fc02d56e8a4404c0601804242e6b730a8f9bb05,16,3,1,28619,,,0,"Bump SHAs for stable/train

Change-Id: Ib7532b50957012b6b41fa00cb488e724c5bac6e7
",git fetch https://review.opendev.org/openstack/openstack-ansible refs/changes/91/764591/1 && git format-patch -1 --stdout FETCH_HEAD,"['playbooks/defaults/repo_packages/openstack_services.yml', 'playbooks/defaults/repo_packages/gnocchi.yml', 'playbooks/defaults/repo_packages/nova_consoles.yml', 'ansible-role-requirements.yml']",4,6fc02d56e8a4404c0601804242e6b730a8f9bb05,bump_osa, version: 399654cc70d58bc60376f7dd4eb9d0e8db2605d8 version: fe699897ed1fe0d69768a7c28512b796cbeed9aa, version: c6b8b21cc6c5962d69a9cf8342cbeda8d6332d0c version: 522e183d8f2755d17678a383a3e414dac2cc6ccc,48,48
openstack%2Fgovernance~master~I3c32aa73a0e472d4af992a38f54e886f7fefda03,openstack/governance,master,I3c32aa73a0e472d4af992a38f54e886f7fefda03,Propose Kendall Nelson for vice chair,MERGED,2020-11-10 00:04:51.000000000,2020-12-01 14:42:44.000000000,2020-12-01 14:37:07.000000000,"[{'_account_id': 308}, {'_account_id': 1004}, {'_account_id': 8099}, {'_account_id': 22348}, {'_account_id': 30491}]","[{'number': 1, 'created': '2020-11-10 00:04:51.000000000', 'files': ['reference/members.yaml'], 'web_link': 'https://opendev.org/openstack/governance/commit/be51c7ba770d74774b753c954f89f267da3a6b40', 'message': 'Propose Kendall Nelson for vice chair\n\nChange-Id: I3c32aa73a0e472d4af992a38f54e886f7fefda03\n'}]",0,762014,be51c7ba770d74774b753c954f89f267da3a6b40,14,5,1,16708,,,0,"Propose Kendall Nelson for vice chair

Change-Id: I3c32aa73a0e472d4af992a38f54e886f7fefda03
",git fetch https://review.opendev.org/openstack/governance refs/changes/14/762014/1 && git format-patch -1 --stdout FETCH_HEAD,['reference/members.yaml'],1,be51c7ba770d74774b753c954f89f267da3a6b40,, role: vice-chair, role: null,1,1
openstack%2Fgovernance~master~I9a7574a71ebdb7a64958e026767016e497e8ff43,openstack/governance,master,I9a7574a71ebdb7a64958e026767016e497e8ff43,Add election schedule exceptions in charter,MERGED,2020-09-15 02:00:42.000000000,2020-12-01 14:39:11.000000000,2020-12-01 14:33:18.000000000,"[{'_account_id': 308}, {'_account_id': 1004}, {'_account_id': 4393}, {'_account_id': 5263}, {'_account_id': 7198}, {'_account_id': 8099}, {'_account_id': 8556}, {'_account_id': 13995}, {'_account_id': 16708}, {'_account_id': 17068}, {'_account_id': 22348}]","[{'number': 1, 'created': '2020-09-15 02:00:42.000000000', 'files': ['reference/charter.rst'], 'web_link': 'https://opendev.org/openstack/governance/commit/1bde4eb753b53eca77dbf2ce531770d60c4ab0f9', 'message': ""Add election schedule exceptions in charter\n\nlet's add election schedule exceptions reference page in\nTC charter so that we can follow the exception\nprocess in future.\n\nChange-Id: I9a7574a71ebdb7a64958e026767016e497e8ff43\n""}]",0,751941,1bde4eb753b53eca77dbf2ce531770d60c4ab0f9,20,11,1,8556,,,0,"Add election schedule exceptions in charter

let's add election schedule exceptions reference page in
TC charter so that we can follow the exception
process in future.

Change-Id: I9a7574a71ebdb7a64958e026767016e497e8ff43
",git fetch https://review.opendev.org/openstack/governance refs/changes/41/751941/1 && git format-patch -1 --stdout FETCH_HEAD,['reference/charter.rst'],1,1bde4eb753b53eca77dbf2ce531770d60c4ab0f9,charter-change,Any exception to PTL election schedule needs to be recorded in :doc:`Election Exceptions </reference/election-exceptions>` Any exception to TC election schedule needs to be recorded in :doc:`Election Exceptions </reference/election-exceptions>` ,,6,0
openstack%2Fcastellan~master~I4f955502694a26db13a36ff4b1fea1c0a3b3b03e,openstack/castellan,master,I4f955502694a26db13a36ff4b1fea1c0a3b3b03e,Use py3 as the default runtime for tox,MERGED,2020-11-04 09:00:42.000000000,2020-12-01 14:38:54.000000000,2020-12-01 14:32:06.000000000,"[{'_account_id': 7973}, {'_account_id': 22348}, {'_account_id': 27954}]","[{'number': 1, 'created': '2020-11-04 09:00:42.000000000', 'files': ['tox.ini'], 'web_link': 'https://opendev.org/openstack/castellan/commit/47b173319851aa4083a1ed4be1892c4b0d841ae4', 'message': ""Use py3 as the default runtime for tox\n\nMoving on py3 as the default runtime for tox to avoid to update this at\neach new cycle.\n\nWallaby support officially the following runtimes [1]:\n- Python 3.6\n- Python 3.8\n\nDuring Victoria Python 3.7 was used as the default runtime [2] however this\nversion isn't longer officially supported.\n\n[1] https://governance.openstack.org/tc/reference/runtimes/wallaby.html#python-runtimes-for-wallaby\n[2] https://governance.openstack.org/tc/reference/runtimes/victoria.html#python-runtimes-for-victoria\n\nChange-Id: I4f955502694a26db13a36ff4b1fea1c0a3b3b03e\n""}]",0,761299,47b173319851aa4083a1ed4be1892c4b0d841ae4,9,3,1,28522,,,0,"Use py3 as the default runtime for tox

Moving on py3 as the default runtime for tox to avoid to update this at
each new cycle.

Wallaby support officially the following runtimes [1]:
- Python 3.6
- Python 3.8

During Victoria Python 3.7 was used as the default runtime [2] however this
version isn't longer officially supported.

[1] https://governance.openstack.org/tc/reference/runtimes/wallaby.html#python-runtimes-for-wallaby
[2] https://governance.openstack.org/tc/reference/runtimes/victoria.html#python-runtimes-for-victoria

Change-Id: I4f955502694a26db13a36ff4b1fea1c0a3b3b03e
",git fetch https://review.opendev.org/openstack/castellan refs/changes/99/761299/1 && git format-patch -1 --stdout FETCH_HEAD,['tox.ini'],1,47b173319851aa4083a1ed4be1892c4b0d841ae4,tox-python38,"envlist = py3,pep8","envlist = py38,pep8",1,1
openstack%2Fkolla-ansible~master~I1ff4cbdf3f60cb7fd5fe5d3c5d498e05fe2df79a,openstack/kolla-ansible,master,I1ff4cbdf3f60cb7fd5fe5d3c5d498e05fe2df79a,RabbitMQ handler refactored to restart services in serial,MERGED,2020-11-18 08:56:25.000000000,2020-12-01 14:34:31.000000000,2020-12-01 14:28:46.000000000,"[{'_account_id': 10068}, {'_account_id': 14826}, {'_account_id': 22348}, {'_account_id': 30491}, {'_account_id': 32688}]","[{'number': 1, 'created': '2020-11-18 08:56:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/137076e4e14bd5bd5696c808597aa3dda38c0f42', 'message': '1904702: rabbitmq handler refactored to restart services in serial\n\nChange-Id: I1ff4cbdf3f60cb7fd5fe5d3c5d498e05fe2df79a\n'}, {'number': 2, 'created': '2020-11-18 09:03:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/7921d2371eb8fe21ba55adab6a290463f7d670e6', 'message': 'RabbitMQ handler refactored to restart services in serial\n\nChange-Id: I1ff4cbdf3f60cb7fd5fe5d3c5d498e05fe2df79a\nCloses-Bug: #190470\n'}, {'number': 3, 'created': '2020-11-18 09:05:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/743567aff9fa40487790a319385b0a700b1ca3ca', 'message': 'RabbitMQ handler refactored to restart services in serial\n\nChange-Id: I1ff4cbdf3f60cb7fd5fe5d3c5d498e05fe2df79a\nCloses-Bug: #1904702\n'}, {'number': 4, 'created': '2020-11-18 11:45:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/acb59eeaf5ad85cd04b3901356a5fc676fd8b48f', 'message': 'RabbitMQ handler refactored to restart services in serial\n\nChange-Id: I1ff4cbdf3f60cb7fd5fe5d3c5d498e05fe2df79a\nCloses-Bug: #1904702\n'}, {'number': 5, 'created': '2020-11-18 16:00:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/c62e3f32a8f959fad3fcceccda792f911e2fbb6e', 'message': 'RabbitMQ handler refactored to restart services in serial\n\nChange-Id: I1ff4cbdf3f60cb7fd5fe5d3c5d498e05fe2df79a\nCloses-Bug: #1904702\n'}, {'number': 6, 'created': '2020-11-19 12:49:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/d2636f2ab6f387c051e7c892ff94f7f9385f0b07', 'message': 'RabbitMQ handler refactored to restart services in serial\n\nChange-Id: I1ff4cbdf3f60cb7fd5fe5d3c5d498e05fe2df79a\nCloses-Bug: #1904702\n'}, {'number': 7, 'created': '2020-11-19 17:12:12.000000000', 'files': ['ansible/roles/rabbitmq/handlers/main.yml', 'ansible/roles/rabbitmq/tasks/restart_services.yml', 'releasenotes/notes/bug-1904702-7451dd8c4caa309b.yaml'], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/4cc4ba59dac8d0835d7eaa1cfc9df5dd481e60c9', 'message': 'RabbitMQ handler refactored to restart services in serial\n\nChange-Id: I1ff4cbdf3f60cb7fd5fe5d3c5d498e05fe2df79a\nCloses-Bug: #1904702\n'}]",3,763137,4cc4ba59dac8d0835d7eaa1cfc9df5dd481e60c9,30,5,7,32688,,,0,"RabbitMQ handler refactored to restart services in serial

Change-Id: I1ff4cbdf3f60cb7fd5fe5d3c5d498e05fe2df79a
Closes-Bug: #1904702
",git fetch https://review.opendev.org/openstack/kolla-ansible refs/changes/37/763137/6 && git format-patch -1 --stdout FETCH_HEAD,"['ansible/roles/rabbitmq/handlers/main.yml', 'ansible/roles/rabbitmq/tasks/restart_services.yml']",2,137076e4e14bd5bd5696c808597aa3dda38c0f42,rmq-handler-1904702,"--- - name: Restart rabbitmq container vars: service_name: ""rabbitmq"" service: ""{{ rabbitmq_services[service_name] }}"" become: true kolla_docker: action: ""recreate_or_restart_container"" common_options: ""{{ docker_common_options }}"" name: ""{{ service.container_name }}"" image: ""{{ service.image }}"" volumes: ""{{ service.volumes }}"" environment: ""{{ service.environment }}"" dimensions: ""{{ service.dimensions }}"" when: - kolla_action != ""config"" - name: Waiting for rabbitmq to start vars: service_name: ""rabbitmq"" service: ""{{ rabbitmq_services[service_name] }}"" become: true shell: ""docker exec {{ service.container_name }} rabbitmqctl wait {{ rabbitmq_pid_file }}"" ",,27,40
openstack%2Fbarbican-tempest-plugin~master~I1efa783233a435b6dbe134e035e0c2efb8ac1a6d,openstack/barbican-tempest-plugin,master,I1efa783233a435b6dbe134e035e0c2efb8ac1a6d,Add py38 package metadata,MERGED,2020-11-04 01:20:07.000000000,2020-12-01 14:27:37.000000000,2020-12-01 14:27:37.000000000,"[{'_account_id': 7973}, {'_account_id': 22348}, {'_account_id': 27954}, {'_account_id': 32291}]","[{'number': 1, 'created': '2020-11-04 01:20:07.000000000', 'files': ['setup.cfg'], 'web_link': 'https://opendev.org/openstack/barbican-tempest-plugin/commit/35ffd4e3c5af272c03cab265e91812f26a91b891', 'message': 'Add py38 package metadata\n\nChange-Id: I1efa783233a435b6dbe134e035e0c2efb8ac1a6d\n'}]",0,761257,35ffd4e3c5af272c03cab265e91812f26a91b891,9,4,1,32291,,,0,"Add py38 package metadata

Change-Id: I1efa783233a435b6dbe134e035e0c2efb8ac1a6d
",git fetch https://review.opendev.org/openstack/barbican-tempest-plugin refs/changes/57/761257/1 && git format-patch -1 --stdout FETCH_HEAD,['setup.cfg'],1,35ffd4e3c5af272c03cab265e91812f26a91b891,, Programming Language :: Python :: 3.8,,1,0
openstack%2Fpython-openstackclient~master~I8dbdba2a029ea8e6a268ddf29627e1466a7e3a8a,openstack/python-openstackclient,master,I8dbdba2a029ea8e6a268ddf29627e1466a7e3a8a,Remove None valued network quota entries,MERGED,2020-08-16 07:26:16.000000000,2020-12-01 13:57:26.000000000,2020-12-01 13:51:20.000000000,"[{'_account_id': 15334}, {'_account_id': 20363}, {'_account_id': 22348}, {'_account_id': 28522}]","[{'number': 1, 'created': '2020-08-16 07:26:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-openstackclient/commit/d4741af3b08283aeab166c235bfecc221320c494', 'message': ""Remove None valued network quota entries\n\nSince the openstack SDK stil has the neutron-lbaas entries in the network quota,\nbut those are already deprecated, the 'opentack quota show' command shows those\nas None value.\nThis fix removes those empty deprecated values from the output.\n\nChange-Id: I8dbdba2a029ea8e6a268ddf29627e1466a7e3a8a\n""}, {'number': 2, 'created': '2020-08-20 05:51:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-openstackclient/commit/3e85d1fa7ea5b93939fcb5f6748629b3717ac75e', 'message': ""Remove None valued network quota entries\n\nSince the openstack SDK still has the neutron-lbaas entries in the network quota,\nbut those are already deprecated [1], the 'opentack quota show' command shows those\nas None value.\nThis fix removes those empty deprecated values from the output.\n\n[1] https://review.opendev.org/#/c/658494/\nChange-Id: I8dbdba2a029ea8e6a268ddf29627e1466a7e3a8a\n""}, {'number': 3, 'created': '2020-09-22 05:12:09.000000000', 'files': ['openstackclient/tests/unit/common/test_quota.py', 'releasenotes/notes/remove-nlbaas-quota-8b38e0c91ab113cb.yaml', 'openstackclient/common/quota.py'], 'web_link': 'https://opendev.org/openstack/python-openstackclient/commit/e9bd4ef007153e4f2e2d69f3bcb94eef8e8983c2', 'message': ""Remove None valued network quota entries\n\nSince the openstack SDK still has the neutron-lbaas entries in the network quota,\nbut those are already deprecated [1], the 'opentack quota show' command shows those\nas None value.\nThis fix removes those empty deprecated values from the output.\n\n[1] https://review.opendev.org/#/c/658494/\nChange-Id: I8dbdba2a029ea8e6a268ddf29627e1466a7e3a8a\n""}]",4,746392,e9bd4ef007153e4f2e2d69f3bcb94eef8e8983c2,16,4,3,20363,,,0,"Remove None valued network quota entries

Since the openstack SDK still has the neutron-lbaas entries in the network quota,
but those are already deprecated [1], the 'opentack quota show' command shows those
as None value.
This fix removes those empty deprecated values from the output.

[1] https://review.opendev.org/#/c/658494/
Change-Id: I8dbdba2a029ea8e6a268ddf29627e1466a7e3a8a
",git fetch https://review.opendev.org/openstack/python-openstackclient refs/changes/92/746392/1 && git format-patch -1 --stdout FETCH_HEAD,['openstackclient/common/quota.py'],1,d4741af3b08283aeab166c235bfecc221320c494,," def _network_quota_to_dict(self, network_quota): if type(network_quota) is not dict: dict_quota = network_quota.to_dict() return {k: v for k, v in dict_quota.items() if v is not None} return network_quota network_quota = self._network_quota_to_dict(network_quota) network_quota = self._network_quota_to_dict(network_quota)", if type(network_quota) is not dict: network_quota = network_quota.to_dict() if type(network_quota) is not dict: network_quota = network_quota.to_dict(),8,4
openstack%2Fpython-openstackclient~master~I59ce3a5f54700ba5a735f0b3b4b3b73b3a8658fa,openstack/python-openstackclient,master,I59ce3a5f54700ba5a735f0b3b4b3b73b3a8658fa,Add id and enabled param in ListIdentityProvider parser,MERGED,2020-07-24 13:56:37.000000000,2020-12-01 13:55:14.000000000,2020-12-01 13:50:56.000000000,"[{'_account_id': 15334}, {'_account_id': 22348}, {'_account_id': 28522}]","[{'number': 1, 'created': '2020-07-24 13:56:37.000000000', 'files': ['releasenotes/notes/add_id_and_enabled_to_list_identity_provider-e0981063a2dc5961.yaml', 'openstackclient/tests/unit/identity/v3/test_identity_provider.py', 'openstackclient/identity/v3/identity_provider.py'], 'web_link': 'https://opendev.org/openstack/python-openstackclient/commit/1e053babf4d674ac31d51dfba048704f32b558b3', 'message': 'Add id and enabled param in ListIdentityProvider parser\n\nwhen doing openstack identity provider list --name xyz_id,\nand openstack identity provider list --enabled CLI raising\nerror unrecognized arguments, whereas in api-ref document [1],\nuser can pass name and enabled as optional query param. This\naddresses the above issue, by adding param --id and --enabled in\nparser of ListIdentityProvider.\n\n[1] https://docs.openstack.org/api-ref/identity/v3-ext/?expanded=list-identity-providers-detail#list-identity-providers\n\nChange-Id: I59ce3a5f54700ba5a735f0b3b4b3b73b3a8658fa\n'}]",0,742886,1e053babf4d674ac31d51dfba048704f32b558b3,9,3,1,27621,,,0,"Add id and enabled param in ListIdentityProvider parser

when doing openstack identity provider list --name xyz_id,
and openstack identity provider list --enabled CLI raising
error unrecognized arguments, whereas in api-ref document [1],
user can pass name and enabled as optional query param. This
addresses the above issue, by adding param --id and --enabled in
parser of ListIdentityProvider.

[1] https://docs.openstack.org/api-ref/identity/v3-ext/?expanded=list-identity-providers-detail#list-identity-providers

Change-Id: I59ce3a5f54700ba5a735f0b3b4b3b73b3a8658fa
",git fetch https://review.opendev.org/openstack/python-openstackclient refs/changes/86/742886/1 && git format-patch -1 --stdout FETCH_HEAD,"['openstackclient/tests/unit/identity/v3/test_identity_provider.py', 'releasenotes/notes/add_id_and_enabled_to_list_identity_provider-e0981063a2dc5961.yaml', 'openstackclient/identity/v3/identity_provider.py']",3,1e053babf4d674ac31d51dfba048704f32b558b3,," def get_parser(self, prog_name): parser = super(ListIdentityProvider, self).get_parser(prog_name) parser.add_argument( '--id', metavar='<id>', help=_('The Identity Providers ID attribute'), ) parser.add_argument( '--enabled', dest='enabled', action='store_true', help=_('The Identity Providers that are enabled will be returned'), ) return parser kwargs = {} if parsed_args.id: kwargs['id'] = parsed_args.id if parsed_args.enabled: kwargs['enabled'] = True data = identity_client.federation.identity_providers.list(**kwargs)", data = identity_client.federation.identity_providers.list(),81,1
openstack%2Fopenstack-ansible~master~I1e02164c470a520ff8fd1543afa6884d8a78c391,openstack/openstack-ansible,master,I1e02164c470a520ff8fd1543afa6884d8a78c391,Bootstrap ansible with python3,ABANDONED,2019-05-02 18:07:40.000000000,2020-12-01 13:50:11.000000000,,"[{'_account_id': 6816}, {'_account_id': 9061}, {'_account_id': 17799}, {'_account_id': 22348}, {'_account_id': 28619}]","[{'number': 1, 'created': '2019-05-02 18:07:40.000000000', 'files': ['scripts/bootstrap-ansible.sh'], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/d731474c94090af10b4c68c9d918c094eaeda3a2', 'message': 'Bootstrap ansible with python3\n\nSwitch to using python3 for the ansible runtime venv.\n\nChange-Id: I1e02164c470a520ff8fd1543afa6884d8a78c391\n'}]",11,656837,d731474c94090af10b4c68c9d918c094eaeda3a2,13,5,1,17799,,,0,"Bootstrap ansible with python3

Switch to using python3 for the ansible runtime venv.

Change-Id: I1e02164c470a520ff8fd1543afa6884d8a78c391
",git fetch https://review.opendev.org/openstack/openstack-ansible refs/changes/37/656837/1 && git format-patch -1 --stdout FETCH_HEAD,['scripts/bootstrap-ansible.sh'],1,d731474c94090af10b4c68c9d918c094eaeda3a2,osa/python3,"PYTHON_EXEC_PATH=""${PYTHON_EXEC_PATH:-$(which python3 || which python2 || which python)}""","# Force using python2. When python3 and python2 dual stack is supported uncomment the following: #PYTHON_EXEC_PATH=""${PYTHON_EXEC_PATH:-$(which python3 || which python2 || which python)}"" PYTHON_EXEC_PATH=""${PYTHON_EXEC_PATH:-$(which python2 || which python)}""",1,3
openstack%2Fopenstack-ansible~master~I3d82ca5ffb01ec95d5fda49eae17027bed61c27d,openstack/openstack-ansible,master,I3d82ca5ffb01ec95d5fda49eae17027bed61c27d,Use python3 for all venv builds,ABANDONED,2019-05-03 21:19:59.000000000,2020-12-01 13:48:50.000000000,,"[{'_account_id': 9061}, {'_account_id': 17799}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-05-03 21:19:59.000000000', 'files': ['inventory/group_vars/all/all.yml'], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/3c9be6f0f3b82f6501ab19443a1009c85d9a3d9d', 'message': 'Use python3 for all venv builds\n\nChange-Id: I3d82ca5ffb01ec95d5fda49eae17027bed61c27d\n'}]",0,657057,3c9be6f0f3b82f6501ab19443a1009c85d9a3d9d,6,3,1,17799,,,0,"Use python3 for all venv builds

Change-Id: I3d82ca5ffb01ec95d5fda49eae17027bed61c27d
",git fetch https://review.opendev.org/openstack/openstack-ansible refs/changes/57/657057/1 && git format-patch -1 --stdout FETCH_HEAD,['inventory/group_vars/all/all.yml'],1,3c9be6f0f3b82f6501ab19443a1009c85d9a3d9d,osa/python3,venv_python_executable: python3,,1,0
openstack%2Fbarbican~master~I33032226d0dd891b9c33c4705fd8627c66bd76d9,openstack/barbican,master,I33032226d0dd891b9c33c4705fd8627c66bd76d9,[doc] Adjust documentation for Thales Luna,MERGED,2020-11-12 12:05:40.000000000,2020-12-01 13:44:17.000000000,2020-12-01 13:42:36.000000000,"[{'_account_id': 7973}, {'_account_id': 22348}, {'_account_id': 27954}]","[{'number': 1, 'created': '2020-11-12 12:05:40.000000000', 'files': ['doc/source/install/barbican-backend.rst'], 'web_link': 'https://opendev.org/openstack/barbican/commit/960c5ef519b66a7c74e777584a63b55859c9873d', 'message': '[doc] Adjust documentation for Thales Luna\n\nLuna Network HSM configuration was not full which may raise unnecessary\nquestions during integration. Also worth mentioning, when store_crypto\nhas effect on the barbican behavior.\n\nChange-Id: I33032226d0dd891b9c33c4705fd8627c66bd76d9\n'}]",0,762507,960c5ef519b66a7c74e777584a63b55859c9873d,8,3,1,28619,,,0,"[doc] Adjust documentation for Thales Luna

Luna Network HSM configuration was not full which may raise unnecessary
questions during integration. Also worth mentioning, when store_crypto
has effect on the barbican behavior.

Change-Id: I33032226d0dd891b9c33c4705fd8627c66bd76d9
",git fetch https://review.opendev.org/openstack/barbican refs/changes/07/762507/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/source/install/barbican-backend.rst'],1,960c5ef519b66a7c74e777584a63b55859c9873d,,".. note:: Setting crypto plugins has effect only when `secretstore` plugin is set to `store_crypto` unless multibackend storage is used. So, for example, using vault for secretstore and PKCS#11 for crypto will not work (vault will be responsible for both storage and encryption). Key Encryption Key (KEK), which in it's turn encrypted with Master Key (MKEK) and signed with HMAC key. Both MKEK and HMAC resides in the HSM.Thales Luna Network HSM (Safenet) +++++++++++++++++++++++++++++++++ The PKCS#11 plugin configuration for Luna Network HSM looks like: # ================= Crypto plugin =================== [crypto] .. enabled_crypto_plugins = p11_crypto #token_serial_number = 12345678.. note:: Barbican does not support FIPS mode enabled for SafeNet Luna HSM or Data Protection on Demand HSM. Make sure that it's operating in non-FIPS mode while integrating with Barbican. The HMAC and MKEK keys can be generated as follows: .. code-block:: ini barbican-manage hsm gen_hmac --library-path /usr/lib/libCryptoki2_64.so \ --passphrase XXX --slot-id 1 --label thales_hmac_0 .. code-block:: ini barbican-manage hsm gen_mkek --library-path /usr/lib/libCryptoki2_64.so \ --passphrase XXX --slot-id 1 --label thales_hmac_0 # ================= Crypto plugin =================== [crypto] .. enabled_crypto_plugins = p11_crypto # ================= Crypto plugin =================== [crypto] .. enabled_crypto_plugins = p11_crypto # ================= Crypto plugin =================== [crypto] .. enabled_crypto_plugins = p11_crypto ","Key Encryption Key (KEK), which resides in the HSM.Safenet +++++++ The PKCS#11 plugin configuration looks like: token_serial_number = 12345678",52,5
openstack%2Fhorizon~master~I0be12e587e57d1c9249d66d8a6f8ea79b5672369,openstack/horizon,master,I0be12e587e57d1c9249d66d8a6f8ea79b5672369,Input['number'] limits the input value,NEW,2019-01-21 07:46:41.000000000,2020-12-01 13:43:33.000000000,,"[{'_account_id': 1736}, {'_account_id': 5623}, {'_account_id': 8648}, {'_account_id': 22348}, {'_account_id': 27822}, {'_account_id': 29313}]","[{'number': 1, 'created': '2019-01-21 07:46:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/895c44786a18ea0d31bc10a801f1e759ac1efde9', 'message': ""input['number'] limits the input value\n\nThe range of integer types in JavaScript is -2^53 - 2^53\nWhen the value exceeds 2**53, the down button is invalid\n\nChange-Id: I0be12e587e57d1c9249d66d8a6f8ea79b5672369\n""}, {'number': 2, 'created': '2019-01-21 08:10:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/a2f9040bb34eeaca786cee4b938cf2b121d772db', 'message': ""input['number'] limits the input value\n\nThe range of integer types in JavaScript is -2^53 - 2^53\nWhen the value exceeds 2**53, the down button is invalid\n\nChange-Id: I0be12e587e57d1c9249d66d8a6f8ea79b5672369\n""}, {'number': 3, 'created': '2019-01-21 09:15:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/a2b59f8d833bf555648236ad007602df68fdbb22', 'message': ""input['number'] limits the input value\n\nThe range of integer types in JavaScript is -2^53 - 2^53\nWhen the value exceeds 2**53, the down button is invalid\n\nChange-Id: I0be12e587e57d1c9249d66d8a6f8ea79b5672369\n""}, {'number': 4, 'created': '2019-02-12 02:12:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/791aa06963e1567779a45c2f2de14156230a6d55', 'message': ""input['number'] limits the input value\n\nThe range of integer types in JavaScript is -2^53 - 2^53\nWhen the value exceeds 2**53, the down button is invalid\n\nChange-Id: I0be12e587e57d1c9249d66d8a6f8ea79b5672369\n""}, {'number': 5, 'created': '2019-02-12 02:15:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/6bd6028ec6d8730c0889d282955ca40fda840680', 'message': ""input['number'] limits the input value\n\nThe range of integer types in JavaScript is -2^53 - 2^53\nWhen the value exceeds 2**53, the down button is invalid\n\nChange-Id: I0be12e587e57d1c9249d66d8a6f8ea79b5672369\n""}, {'number': 6, 'created': '2019-02-12 06:10:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/83f9146550f1bf4e8048d82fdc9918b89fbff360', 'message': ""input['number'] limits the input value\n\nThe range of integer types in JavaScript is -2^53 - 2^53\nWhen the value exceeds 2**53, the down button is invalid\n\nChange-Id: I0be12e587e57d1c9249d66d8a6f8ea79b5672369\n""}, {'number': 7, 'created': '2019-02-18 01:46:17.000000000', 'files': ['horizon/static/horizon/js/horizon.forms.js'], 'web_link': 'https://opendev.org/openstack/horizon/commit/027d978b4cf1300d06610fed69a02f05df958028', 'message': ""Input['number'] limits the input value\n\nThe range of integer types in JavaScript is -2^53 - 2^53\nWhen the value exceeds 2**53, the down button is invalid\n\nChange-Id: I0be12e587e57d1c9249d66d8a6f8ea79b5672369\n""}]",5,632037,027d978b4cf1300d06610fed69a02f05df958028,21,6,7,27822,,,0,"Input['number'] limits the input value

The range of integer types in JavaScript is -2^53 - 2^53
When the value exceeds 2**53, the down button is invalid

Change-Id: I0be12e587e57d1c9249d66d8a6f8ea79b5672369
",git fetch https://review.opendev.org/openstack/horizon refs/changes/37/632037/3 && git format-patch -1 --stdout FETCH_HEAD,['horizon/static/horizon/js/horizon.forms.js'],1,895c44786a18ea0d31bc10a801f1e759ac1efde9,Bug#limitvalue,"horizon.forms.limitSpinnerValue = function($inputs) { $inputs.each(function (index, input) { var $input = $(input); var val = $input.attr('value'); if (val > 2**53) { val = 2**53; } $input.val(val); }); } $input.on('input', function(e) { horizon.forms.limitSpinnerValue($(e.delegateTarget)); });",,14,0
openstack%2Fhorizon~master~I0a5dbc42b8c40cda8f4c910f21cd65691af26b37,openstack/horizon,master,I0a5dbc42b8c40cda8f4c910f21cd65691af26b37,Read LOCAL_SETTINGS_DIR_PATH from the environment variable,NEW,2020-11-03 16:50:16.000000000,2020-12-01 13:38:42.000000000,,"[{'_account_id': 841}, {'_account_id': 1736}, {'_account_id': 22348}, {'_account_id': 29313}]","[{'number': 1, 'created': '2020-11-03 16:50:16.000000000', 'files': ['releasenotes/notes/local-settings-dir-from-environment-a29c21066b246cbb.yaml', 'openstack_dashboard/settings.py'], 'web_link': 'https://opendev.org/openstack/horizon/commit/428e6a491aafa2941bf6b64b8f0c10e58e126834', 'message': ""Read LOCAL_SETTINGS_DIR_PATH from the environment variable\n\nIn a containerized environment we can't always put settings inside Python's\n'site-packages'. It's a common pattern to use environment variable for a\nconfig values. To make this backward-compatible we'll use current\napproach if LOCAL_SETTINGS_DIR_PATH environment variable is not set.\n\nChange-Id: I0a5dbc42b8c40cda8f4c910f21cd65691af26b37\n""}]",1,761197,428e6a491aafa2941bf6b64b8f0c10e58e126834,11,4,1,1736,,,0,"Read LOCAL_SETTINGS_DIR_PATH from the environment variable

In a containerized environment we can't always put settings inside Python's
'site-packages'. It's a common pattern to use environment variable for a
config values. To make this backward-compatible we'll use current
approach if LOCAL_SETTINGS_DIR_PATH environment variable is not set.

Change-Id: I0a5dbc42b8c40cda8f4c910f21cd65691af26b37
",git fetch https://review.opendev.org/openstack/horizon refs/changes/97/761197/1 && git format-patch -1 --stdout FETCH_HEAD,"['releasenotes/notes/local-settings-dir-from-environment-a29c21066b246cbb.yaml', 'openstack_dashboard/settings.py']",2,428e6a491aafa2941bf6b64b8f0c10e58e126834,local-setting-dir-path,"if os.environ.get('LOCAL_SETTINGS_DIR_PATH'): LOCAL_SETTINGS_DIR_PATH = os.environ.get('LOCAL_SETTINGS_DIR_PATH') else: LOCAL_SETTINGS_DIR_PATH = os.path.join(LOCAL_PATH, ""local_settings.d"")","LOCAL_SETTINGS_DIR_PATH = os.path.join(LOCAL_PATH, ""local_settings.d"")LOCAL_SETTINGS_DIR_PATH = os.path.join(ROOT_PATH, ""local"", ""local_settings.d"")",9,2
openstack%2Fbarbican~stable%2Ftrain~I69fd56ca1cdbae4c5442fb79fd3c1f5f79290044,openstack/barbican,stable/train,I69fd56ca1cdbae4c5442fb79fd3c1f5f79290044,Fix PDF build,ABANDONED,2020-09-25 08:46:57.000000000,2020-12-01 13:27:14.000000000,,"[{'_account_id': 22348}, {'_account_id': 27954}]","[{'number': 1, 'created': '2020-09-25 08:46:57.000000000', 'files': ['doc/source/sample_config.rst'], 'web_link': 'https://opendev.org/openstack/barbican/commit/6ee214e2b095b7ee1fe612631cc9442bd1d7e308', 'message': 'Fix PDF build\n\nDo not include config sample since PDF building fails with the\nlarge file. This fix PDF building of openstack-tox-docs job.\n\nChange-Id: I69fd56ca1cdbae4c5442fb79fd3c1f5f79290044\nSigned-off-by: Moiss Guimares de Medeiros <moguimar@redhat.com>\n(cherry picked from commit df194df8169250eea267474b145e11e318933b25)\n'}]",0,754332,6ee214e2b095b7ee1fe612631cc9442bd1d7e308,8,2,1,27954,,,0,"Fix PDF build

Do not include config sample since PDF building fails with the
large file. This fix PDF building of openstack-tox-docs job.

Change-Id: I69fd56ca1cdbae4c5442fb79fd3c1f5f79290044
Signed-off-by: Moiss Guimares de Medeiros <moguimar@redhat.com>
(cherry picked from commit df194df8169250eea267474b145e11e318933b25)
",git fetch https://review.opendev.org/openstack/barbican refs/changes/32/754332/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/source/sample_config.rst'],1,6ee214e2b095b7ee1fe612631cc9442bd1d7e308,fix-pdf-docs,.. only:: html .. literalinclude:: _static/barbican.conf.sample,.. literalinclude:: _static/barbican.conf.sample,3,1
openstack%2Fbarbican~stable%2Fussuri~I69fd56ca1cdbae4c5442fb79fd3c1f5f79290044,openstack/barbican,stable/ussuri,I69fd56ca1cdbae4c5442fb79fd3c1f5f79290044,Fix PDF build,ABANDONED,2020-09-25 08:46:27.000000000,2020-12-01 13:26:55.000000000,,"[{'_account_id': 22348}, {'_account_id': 27954}]","[{'number': 1, 'created': '2020-09-25 08:46:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/barbican/commit/3292ffac6709e7e51bad7c5c4f0ce55bb80e9a47', 'message': 'Fix PDF build\n\nDo not include config sample since PDF building fails with the\nlarge file. This fix PDF building of openstack-tox-docs job.\n\nChange-Id: I69fd56ca1cdbae4c5442fb79fd3c1f5f79290044\nSigned-off-by: Moiss Guimares de Medeiros <moguimar@redhat.com>\n(cherry picked from commit df194df8169250eea267474b145e11e318933b25)\n'}, {'number': 2, 'created': '2020-12-01 13:25:53.000000000', 'files': ['doc/source/sample_config.rst'], 'web_link': 'https://opendev.org/openstack/barbican/commit/3f47916a0873b7745e3b2ad369a68ed26d23b1cd', 'message': 'Fix PDF build\n\nDo not include config sample since PDF building fails with the\nlarge file. This fix PDF building of openstack-tox-docs job.\n\nChange-Id: I69fd56ca1cdbae4c5442fb79fd3c1f5f79290044\nSigned-off-by: Moiss Guimares de Medeiros <moguimar@redhat.com>\n(cherry picked from commit df194df8169250eea267474b145e11e318933b25)\n'}]",0,754331,3f47916a0873b7745e3b2ad369a68ed26d23b1cd,10,2,2,27954,,,0,"Fix PDF build

Do not include config sample since PDF building fails with the
large file. This fix PDF building of openstack-tox-docs job.

Change-Id: I69fd56ca1cdbae4c5442fb79fd3c1f5f79290044
Signed-off-by: Moiss Guimares de Medeiros <moguimar@redhat.com>
(cherry picked from commit df194df8169250eea267474b145e11e318933b25)
",git fetch https://review.opendev.org/openstack/barbican refs/changes/31/754331/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/source/sample_config.rst'],1,3292ffac6709e7e51bad7c5c4f0ce55bb80e9a47,fix-pdf-docs,.. only:: html .. literalinclude:: _static/barbican.conf.sample,.. literalinclude:: _static/barbican.conf.sample,3,1
openstack%2Frequirements~stable%2Ftrain~I57219027d23e35ddc3147becffcfda099efadf9e,openstack/requirements,stable/train,I57219027d23e35ddc3147becffcfda099efadf9e,update constraint for castellan to new release 1.3.4,MERGED,2020-11-30 11:13:17.000000000,2020-12-01 13:20:56.000000000,2020-12-01 13:20:56.000000000,"[{'_account_id': 11904}, {'_account_id': 14288}, {'_account_id': 22348}]","[{'number': 1, 'created': '2020-11-30 11:13:17.000000000', 'files': ['upper-constraints.txt'], 'web_link': 'https://opendev.org/openstack/requirements/commit/453513c0f8619357a8fb1b624d898d4cff819eb0', 'message': 'update constraint for castellan to new release 1.3.4\n\nmeta: version: 1.3.4\nmeta: diff-start: -\nmeta: series: train\nmeta: release-type: release\nmeta: pypi: no\nmeta: first: no\nmeta: release:Author: Daniel Bengtsson <dbengt@redhat.com>\nmeta: release:Commit: Daniel Bengtsson <dbengt@redhat.com>\nmeta: release:Change-Id: If5898b9139fab8378a193fcd26ea1cc024c57dba\nmeta: release:Code-Review+2: Herv Beraud <hberaud@redhat.com>\nmeta: release:Code-Review+2: Thierry Carrez <thierry@openstack.org>\nmeta: release:Workflow+1: Thierry Carrez <thierry@openstack.org>\nChange-Id: I57219027d23e35ddc3147becffcfda099efadf9e\n'}]",0,764636,453513c0f8619357a8fb1b624d898d4cff819eb0,10,3,1,11131,,,0,"update constraint for castellan to new release 1.3.4

meta: version: 1.3.4
meta: diff-start: -
meta: series: train
meta: release-type: release
meta: pypi: no
meta: first: no
meta: release:Author: Daniel Bengtsson <dbengt@redhat.com>
meta: release:Commit: Daniel Bengtsson <dbengt@redhat.com>
meta: release:Change-Id: If5898b9139fab8378a193fcd26ea1cc024c57dba
meta: release:Code-Review+2: Herv Beraud <hberaud@redhat.com>
meta: release:Code-Review+2: Thierry Carrez <thierry@openstack.org>
meta: release:Workflow+1: Thierry Carrez <thierry@openstack.org>
Change-Id: I57219027d23e35ddc3147becffcfda099efadf9e
",git fetch https://review.opendev.org/openstack/requirements refs/changes/36/764636/1 && git format-patch -1 --stdout FETCH_HEAD,['upper-constraints.txt'],1,453513c0f8619357a8fb1b624d898d4cff819eb0,new-release,castellan===1.3.4,castellan===1.3.3,1,1
openstack%2Fopenstack-ansible-tests~master~Ice2bd1408f65ff4979c9c5244f0ca026e8c246e4,openstack/openstack-ansible-tests,master,Ice2bd1408f65ff4979c9c5244f0ca026e8c246e4,Apply OSA global-requirements-pins during functional tests,MERGED,2020-11-30 20:26:34.000000000,2020-12-01 13:07:05.000000000,2020-12-01 13:05:39.000000000,"[{'_account_id': 22348}, {'_account_id': 28619}, {'_account_id': 29865}]","[{'number': 1, 'created': '2020-11-30 20:26:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-tests/commit/b3ce0ea96fab949dc44c1b3d7b16f6404635879e', 'message': 'Apply OSA global-requirements-pins during functional tests\n\nChange-Id: Ice2bd1408f65ff4979c9c5244f0ca026e8c246e4\n'}, {'number': 2, 'created': '2020-12-01 08:50:48.000000000', 'files': ['test-vars.yml'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-tests/commit/aaecefaee91d468f6f96cac26bc8a119d5fd2dca', 'message': 'Apply OSA global-requirements-pins during functional tests\n\nChange-Id: Ice2bd1408f65ff4979c9c5244f0ca026e8c246e4\n'}]",0,764824,aaecefaee91d468f6f96cac26bc8a119d5fd2dca,10,3,2,25023,,,0,"Apply OSA global-requirements-pins during functional tests

Change-Id: Ice2bd1408f65ff4979c9c5244f0ca026e8c246e4
",git fetch https://review.opendev.org/openstack/openstack-ansible-tests refs/changes/24/764824/2 && git format-patch -1 --stdout FETCH_HEAD,['test-vars.yml'],1,b3ce0ea96fab949dc44c1b3d7b16f6404635879e,,"# apply openstack-ansible global constraints for python_venv_build _global_pins_file_url: ""https://opendev.org/openstack/openstack-ansible/raw/{{ test_branch }}/global-requirement-pins.txt"" venv_build_global_constraints: >- {{ lookup('url', _global_pins_file_url) | reject('match','^#.*$') | reject('equalto', '') | list }} ",,6,0
openstack%2Fpython-watcherclient~master~Idc593565a5965a8a0bab5a569f0efd09a0a19e64,openstack/python-watcherclient,master,Idc593565a5965a8a0bab5a569f0efd09a0a19e64,[Part1] Remove six,NEW,2020-10-14 02:11:33.000000000,2020-12-01 12:56:31.000000000,,"[{'_account_id': 11904}, {'_account_id': 22348}]","[{'number': 1, 'created': '2020-10-14 02:11:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-watcherclient/commit/8a754f506dcd1ee916bd631097ff4164bb8bb0ab', 'message': ""Remove six\n\nWe don't need this in a Python 3-only world.\nRemove six.StringIO\n\nChange-Id: Idc593565a5965a8a0bab5a569f0efd09a0a19e64\n""}, {'number': 2, 'created': '2020-10-14 03:11:07.000000000', 'files': ['watcherclient/tests/unit/v1/test_action_plan_shell.py', 'watcherclient/tests/unit/v1/test_goal_shell.py', 'watcherclient/tests/unit/v1/test_service_shell.py', 'watcherclient/tests/unit/v1/test_strategy_shell.py', 'watcherclient/tests/unit/v1/test_action_shell.py', 'watcherclient/tests/unit/v1/test_audit_template_shell.py', 'watcherclient/v1/action_plan_shell.py', 'watcherclient/tests/unit/utils.py', 'watcherclient/tests/unit/v1/test_scoring_engine_shell.py', 'watcherclient/tests/unit/v1/test_audit_shell.py', 'watcherclient/tests/unit/v1/test_data_model_shell.py'], 'web_link': 'https://opendev.org/openstack/python-watcherclient/commit/d673ba03cb3be31e42097cada40888357d5cab9c', 'message': ""[Part1] Remove six\n\nWe don't need this in a Python 3-only world.\nRemove six.StringIO\n\nChange-Id: Idc593565a5965a8a0bab5a569f0efd09a0a19e64\n""}]",1,757980,d673ba03cb3be31e42097cada40888357d5cab9c,6,2,2,17130,,,0,"[Part1] Remove six

We don't need this in a Python 3-only world.
Remove six.StringIO

Change-Id: Idc593565a5965a8a0bab5a569f0efd09a0a19e64
",git fetch https://review.opendev.org/openstack/python-watcherclient refs/changes/80/757980/2 && git format-patch -1 --stdout FETCH_HEAD,"['watcherclient/tests/unit/v1/test_action_plan_shell.py', 'watcherclient/tests/unit/v1/test_goal_shell.py', 'watcherclient/tests/unit/v1/test_action_shell.py', 'watcherclient/tests/unit/v1/test_service_shell.py', 'watcherclient/tests/unit/v1/test_strategy_shell.py', 'watcherclient/tests/unit/v1/test_audit_template_shell.py', 'watcherclient/v1/action_plan_shell.py', 'watcherclient/tests/unit/utils.py', 'watcherclient/tests/unit/v1/test_scoring_engine_shell.py', 'watcherclient/tests/unit/v1/test_audit_shell.py', 'watcherclient/tests/unit/v1/test_data_model_shell.py']",11,8a754f506dcd1ee916bd631097ff4164bb8bb0ab,,import io self.stdout = io.StringIO(),import six self.stdout = six.StringIO(),25,32
openstack%2Fpython-cloudkittyclient~master~I25d4154797da0453f59e310d2392d30ca35e5258,openstack/python-cloudkittyclient,master,I25d4154797da0453f59e310d2392d30ca35e5258,Replace deprecated UPPER_CONSTRAINTS_FILE variable,MERGED,2020-11-27 12:41:38.000000000,2020-12-01 12:52:05.000000000,2020-12-01 12:50:40.000000000,"[{'_account_id': 15197}, {'_account_id': 22348}, {'_account_id': 28356}, {'_account_id': 32231}]","[{'number': 1, 'created': '2020-11-27 12:41:38.000000000', 'files': ['tox.ini'], 'web_link': 'https://opendev.org/openstack/python-cloudkittyclient/commit/c2b5ed9535d99692ffb2a2ea8873aafe33a369a1', 'message': 'Replace deprecated UPPER_CONSTRAINTS_FILE variable\n\nUPPER_CONSTRAINTS_FILE is old name and deprecated\n-https://zuul-ci.org/docs/zuul-jobs/python-roles.html#rolevar-tox.tox_constraints_file\nThis allows to use lower-constraints file as more\nreadable way instead of UPPER_CONSTRAINTS_FILE=<lower-constraints file>.\n\nChange-Id: I25d4154797da0453f59e310d2392d30ca35e5258\n'}]",0,764461,c2b5ed9535d99692ffb2a2ea8873aafe33a369a1,9,4,1,26285,,,0,"Replace deprecated UPPER_CONSTRAINTS_FILE variable

UPPER_CONSTRAINTS_FILE is old name and deprecated
-https://zuul-ci.org/docs/zuul-jobs/python-roles.html#rolevar-tox.tox_constraints_file
This allows to use lower-constraints file as more
readable way instead of UPPER_CONSTRAINTS_FILE=<lower-constraints file>.

Change-Id: I25d4154797da0453f59e310d2392d30ca35e5258
",git fetch https://review.opendev.org/openstack/python-cloudkittyclient refs/changes/61/764461/1 && git format-patch -1 --stdout FETCH_HEAD,['tox.ini'],1,c2b5ed9535d99692ffb2a2ea8873aafe33a369a1,, -c{env:TOX_CONSTRAINTS_FILE:https://opendev.org/openstack/requirements/raw/branch/master/upper-constraints.txt}, -c{env:UPPER_CONSTRAINTS_FILE:https://opendev.org/openstack/requirements/raw/branch/master/upper-constraints.txt},1,1
openstack%2Fcharm-deployment-guide~master~I4f2f579019a8a3701e8f99b013688806c3739aa9,openstack/charm-deployment-guide,master,I4f2f579019a8a3701e8f99b013688806c3739aa9,Add upgrade issue for Keystone Fernet tokens,MERGED,2020-11-30 18:28:50.000000000,2020-12-01 12:46:04.000000000,2020-12-01 12:44:39.000000000,"[{'_account_id': 22348}, {'_account_id': 31289}]","[{'number': 1, 'created': '2020-11-30 18:28:50.000000000', 'files': ['deploy-guide/source/app-upgrade-openstack.rst'], 'web_link': 'https://opendev.org/openstack/charm-deployment-guide/commit/cfbe914b29814322e462f7791aeca0243db855c8', 'message': 'Add upgrade issue for Keystone Fernet tokens\n\nCloses-Bug: #1901980\n\nChange-Id: I4f2f579019a8a3701e8f99b013688806c3739aa9\n'}]",0,764812,cfbe914b29814322e462f7791aeca0243db855c8,7,2,1,30561,,,0,"Add upgrade issue for Keystone Fernet tokens

Closes-Bug: #1901980

Change-Id: I4f2f579019a8a3701e8f99b013688806c3739aa9
",git fetch https://review.opendev.org/openstack/charm-deployment-guide refs/changes/12/764812/1 && git format-patch -1 --stdout FETCH_HEAD,['deploy-guide/source/app-upgrade-openstack.rst'],1,cfbe914b29814322e462f7791aeca0243db855c8,lp1901980-known-issue-rocky-fernet,"Keystone and Fernet tokens: upgrading from Queens to Rocky ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ Starting with OpenStack Rocky only the Fernet format for authentication tokens is supported. Therefore, prior to upgrading Keystone to Rocky a transition must be made from the legacy format (of UUID) to Fernet. Fernet support is available upstream (and in the keystone charm) starting with Ocata so the transition can be made on either Ocata, Pike, or Queens. Use option ``token-provider`` to transition to Fernet tokens: .. code-block:: none juju config keystone token-provider=fernet The ``token-provider`` option has no effect starting with Rocky, where the charm defaults to Fernet and where upstream removes support for UUID. See `Keystone Fernet Token Implementation`_ for more information. .. _Keystone Fernet Token Implementation: https://specs.openstack.org/openstack/charm-specs/specs/rocky/implemented/keystone-fernet-tokens.html",,21,0
openstack%2Frequirements~master~I71fe4447b09c49b5721e114f84faeb4371a30aeb,openstack/requirements,master,I71fe4447b09c49b5721e114f84faeb4371a30aeb,update constraint for python-tackerclient to new release 1.4.0,MERGED,2020-12-01 08:45:11.000000000,2020-12-01 12:40:50.000000000,2020-12-01 12:39:31.000000000,"[{'_account_id': 11904}, {'_account_id': 14288}, {'_account_id': 22348}]","[{'number': 1, 'created': '2020-12-01 08:45:11.000000000', 'files': ['upper-constraints.txt'], 'web_link': 'https://opendev.org/openstack/requirements/commit/d7f43d40ada612e606443b1d819819dc19f48a60', 'message': 'update constraint for python-tackerclient to new release 1.4.0\n\nmeta: version: 1.4.0\nmeta: diff-start: -\nmeta: series: wallaby\nmeta: release-type: release\nmeta: pypi: yes\nmeta: first: yes\nmeta: release:Author: Herv Beraud <hberaud@redhat.com>\nmeta: release:Commit: Herv Beraud <hberaud@redhat.com>\nmeta: release:Change-Id: I704353ffb93d102eaa645bb05d35a0630a3b903d\nmeta: release:Code-Review+1: Yasufumi Ogawa <yasufum.o@gmail.com>\nmeta: release:Code-Review+2: Sean McGinnis <sean.mcginnis@gmail.com>\nmeta: release:Code-Review+2: Herv Beraud <hberaud@redhat.com>\nmeta: release:Workflow+1: Herv Beraud <hberaud@redhat.com>\nChange-Id: I71fe4447b09c49b5721e114f84faeb4371a30aeb\n'}]",0,764910,d7f43d40ada612e606443b1d819819dc19f48a60,10,3,1,11131,,,0,"update constraint for python-tackerclient to new release 1.4.0

meta: version: 1.4.0
meta: diff-start: -
meta: series: wallaby
meta: release-type: release
meta: pypi: yes
meta: first: yes
meta: release:Author: Herv Beraud <hberaud@redhat.com>
meta: release:Commit: Herv Beraud <hberaud@redhat.com>
meta: release:Change-Id: I704353ffb93d102eaa645bb05d35a0630a3b903d
meta: release:Code-Review+1: Yasufumi Ogawa <yasufum.o@gmail.com>
meta: release:Code-Review+2: Sean McGinnis <sean.mcginnis@gmail.com>
meta: release:Code-Review+2: Herv Beraud <hberaud@redhat.com>
meta: release:Workflow+1: Herv Beraud <hberaud@redhat.com>
Change-Id: I71fe4447b09c49b5721e114f84faeb4371a30aeb
",git fetch https://review.opendev.org/openstack/requirements refs/changes/10/764910/1 && git format-patch -1 --stdout FETCH_HEAD,['upper-constraints.txt'],1,d7f43d40ada612e606443b1d819819dc19f48a60,new-release,python-tackerclient===1.4.0,python-tackerclient===1.3.0,1,1
openstack%2Fansible-role-collect-logs~master~Ib564a4f4271108015a6b54669789fffdb43d19c4,openstack/ansible-role-collect-logs,master,Ib564a4f4271108015a6b54669789fffdb43d19c4,Fix extra/podman/containers sometimes missing,MERGED,2020-11-26 14:12:11.000000000,2020-12-01 12:35:00.000000000,2020-12-01 12:35:00.000000000,"[{'_account_id': 6926}, {'_account_id': 8449}, {'_account_id': 14985}, {'_account_id': 22348}, {'_account_id': 22873}, {'_account_id': 23181}]","[{'number': 1, 'created': '2020-11-26 14:12:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ansible-role-collect-logs/commit/21bd993e196883b26152caeec0c36595d07435d7', 'message': ""Fix extra/podman/containers sometimes missing\n\nThere is bug that sometimes /var/log/extra/podman/containers\nis completely missing for some nodes (while it may be there for others).\n\nIt's caused by timing of parallel-container-log-generation+sync\nand generating the list for files to collect using find.\n\nIf container logs are not generated yet or in progress,\nfind may miss these files and so later rsync will not collect them.\n\nFix seems to be simple - to move the step Wait-for-containers-logs\njust before the execution of find.\n\nRHOSINFRA-3758\n\nChange-Id: Ib564a4f4271108015a6b54669789fffdb43d19c4\n""}, {'number': 2, 'created': '2020-11-27 17:02:18.000000000', 'files': ['tasks/collect.yml'], 'web_link': 'https://opendev.org/openstack/ansible-role-collect-logs/commit/4137e6422be3bf76d408e5f65e0f263cd6ff4523', 'message': ""Fix extra/podman/containers sometimes missing\n\nThere is bug that sometimes /var/log/extra/podman/containers\nis completely missing for some nodes (while it may be there for others).\n\nIt's caused by timing of parallel-container-log-generation+sync\nand generating the list for files to collect using find.\n\nIf container logs are not generated yet or in progress,\nfind may miss these files and so later rsync will not collect them.\n\nFix seems to be simple - to move the step Wait-for-containers-logs\njust before the execution of find.\n\nCloses-Bug: #1905991\nChange-Id: Ib564a4f4271108015a6b54669789fffdb43d19c4\n""}]",5,764349,4137e6422be3bf76d408e5f65e0f263cd6ff4523,19,6,2,6683,,,0,"Fix extra/podman/containers sometimes missing

There is bug that sometimes /var/log/extra/podman/containers
is completely missing for some nodes (while it may be there for others).

It's caused by timing of parallel-container-log-generation+sync
and generating the list for files to collect using find.

If container logs are not generated yet or in progress,
find may miss these files and so later rsync will not collect them.

Fix seems to be simple - to move the step Wait-for-containers-logs
just before the execution of find.

Closes-Bug: #1905991
Change-Id: Ib564a4f4271108015a6b54669789fffdb43d19c4
",git fetch https://review.opendev.org/openstack/ansible-role-collect-logs refs/changes/49/764349/1 && git format-patch -1 --stdout FETCH_HEAD,['tasks/collect.yml'],1,21bd993e196883b26152caeec0c36595d07435d7,,"- name: Wait for container logs collection if not finished yet become: true async_status: jid: ""{{ container_collection.ansible_job_id }}"" register: container_collection_result until: container_collection_result.finished delay: 10 retries: 60 when: ""'container' in collect_log_types"" # All log-generating/dumping steps need to finish before this step # or those files will not be found and so ignored during collection step","- name: Wait for container logs collection if not finished yet become: true async_status: jid: ""{{ container_collection.ansible_job_id }}"" register: container_collection_result until: container_collection_result.finished delay: 10 retries: 60 when: ""'container' in collect_log_types"" ",12,10
openstack%2Fpython-neutronclient~stable%2Fvictoria~I0ae78e7b87667a94503f5a7bddd98ee7741e69a1,openstack/python-neutronclient,stable/victoria,I0ae78e7b87667a94503f5a7bddd98ee7741e69a1,Update TOX_CONSTRAINTS_FILE for stable/victoria,MERGED,2020-09-09 16:36:40.000000000,2020-12-01 12:27:04.000000000,2020-12-01 12:25:09.000000000,"[{'_account_id': 1131}, {'_account_id': 11975}, {'_account_id': 21798}, {'_account_id': 22348}, {'_account_id': 32238}]","[{'number': 1, 'created': '2020-09-09 16:36:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-neutronclient/commit/c3105854eb0f161bf46523a2bc7d3cdd4537060f', 'message': 'Update TOX_CONSTRAINTS_FILE for stable/victoria\n\nUpdate the URL to the upper-constraints file to point to the redirect\nrule on releases.openstack.org so that anyone working on this branch\nwill switch to the correct upper-constraints list automatically when\nthe requirements repository branches.\n\nUntil the requirements repository has as stable/victoria branch, tests will\ncontinue to use the upper-constraints list on master.\n\nChange-Id: I0ae78e7b87667a94503f5a7bddd98ee7741e69a1\n'}, {'number': 2, 'created': '2020-09-17 07:03:04.000000000', 'files': ['tox.ini'], 'web_link': 'https://opendev.org/openstack/python-neutronclient/commit/af15f09b8039ba833429aeeb4bcaf62630a450a3', 'message': 'Update TOX_CONSTRAINTS_FILE for stable/victoria\n\nUpdate the URL to the upper-constraints file to point to the redirect\nrule on releases.openstack.org so that anyone working on this branch\nwill switch to the correct upper-constraints list automatically when\nthe requirements repository branches.\n\nUntil the requirements repository has as stable/victoria branch, tests will\ncontinue to use the upper-constraints list on master.\n\nChange-Id: I0ae78e7b87667a94503f5a7bddd98ee7741e69a1\n'}]",1,750729,af15f09b8039ba833429aeeb4bcaf62630a450a3,18,5,2,22816,,,0,"Update TOX_CONSTRAINTS_FILE for stable/victoria

Update the URL to the upper-constraints file to point to the redirect
rule on releases.openstack.org so that anyone working on this branch
will switch to the correct upper-constraints list automatically when
the requirements repository branches.

Until the requirements repository has as stable/victoria branch, tests will
continue to use the upper-constraints list on master.

Change-Id: I0ae78e7b87667a94503f5a7bddd98ee7741e69a1
",git fetch https://review.opendev.org/openstack/python-neutronclient refs/changes/29/750729/2 && git format-patch -1 --stdout FETCH_HEAD,['tox.ini'],1,c3105854eb0f161bf46523a2bc7d3cdd4537060f,create-victoria,deps = -c{env:TOX_CONSTRAINTS_FILE:https://releases.openstack.org/constraints/upper/victoria},deps = -c{env:UPPER_CONSTRAINTS_FILE:https://opendev.org/openstack/requirements/raw/branch/master/upper-constraints.txt},1,1
openstack%2Fpython-novaclient~master~Ie2299990f5b125b692ce5dcd842d0e2f95067284,openstack/python-novaclient,master,Ie2299990f5b125b692ce5dcd842d0e2f95067284,DNM test a devstack-tox-functional change,ABANDONED,2020-10-10 17:29:24.000000000,2020-12-01 12:04:51.000000000,,"[{'_account_id': 679}, {'_account_id': 10459}, {'_account_id': 22348}]","[{'number': 1, 'created': '2020-10-10 17:29:24.000000000', 'files': ['tox.ini'], 'web_link': 'https://opendev.org/openstack/python-novaclient/commit/348505651bbc03a7639c6f64d1ee27d4396cda70', 'message': 'DNM test a devstack-tox-functional change\n\nDepends-On: https://review.opendev.org/757293\nChange-Id: Ie2299990f5b125b692ce5dcd842d0e2f95067284\n'}]",0,757303,348505651bbc03a7639c6f64d1ee27d4396cda70,5,3,1,10459,,,0,"DNM test a devstack-tox-functional change

Depends-On: https://review.opendev.org/757293
Change-Id: Ie2299990f5b125b692ce5dcd842d0e2f95067284
",git fetch https://review.opendev.org/openstack/python-novaclient refs/changes/03/757303/1 && git format-patch -1 --stdout FETCH_HEAD,['tox.ini'],1,348505651bbc03a7639c6f64d1ee27d4396cda70,func-allow-existing-tox-environment,,,1,0
openstack%2Fshade~master~Ic76147515dbade8c7c7faf48adb857fce36ccf13,openstack/shade,master,Ic76147515dbade8c7c7faf48adb857fce36ccf13,DNM test a devstack-tox-functional change,ABANDONED,2020-08-18 09:31:56.000000000,2020-12-01 12:04:41.000000000,,"[{'_account_id': 10459}, {'_account_id': 22348}]","[{'number': 1, 'created': '2020-08-18 09:31:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/shade/commit/9e206a4de9d45e456d4a5c7d08b1a0fd2ebf2a0e', 'message': 'DNM test a devstack-tox-functional change\n\nDepends-On: https://review.opendev.org/746235\nChange-Id: Ic76147515dbade8c7c7faf48adb857fce36ccf13\n'}, {'number': 2, 'created': '2020-10-10 17:26:47.000000000', 'files': ['tox.ini'], 'web_link': 'https://opendev.org/openstack/shade/commit/1ee1563fb02438e657fec38235169839a606ccda', 'message': 'DNM test a devstack-tox-functional change\n\nDepends-On: https://review.opendev.org/757293\nChange-Id: Ic76147515dbade8c7c7faf48adb857fce36ccf13\n'}]",0,746670,1ee1563fb02438e657fec38235169839a606ccda,12,2,2,10459,,,0,"DNM test a devstack-tox-functional change

Depends-On: https://review.opendev.org/757293
Change-Id: Ic76147515dbade8c7c7faf48adb857fce36ccf13
",git fetch https://review.opendev.org/openstack/shade refs/changes/70/746670/1 && git format-patch -1 --stdout FETCH_HEAD,['tox.ini'],1,9e206a4de9d45e456d4a5c7d08b1a0fd2ebf2a0e,func-allow-existing-tox-environment,,,1,0
openstack%2Fopenstacksdk~master~I6eef26db244352a7fd13093114699641b994b102,openstack/openstacksdk,master,I6eef26db244352a7fd13093114699641b994b102,DNM test a devstack-tox-functional change,ABANDONED,2020-10-10 17:30:55.000000000,2020-12-01 12:04:38.000000000,,"[{'_account_id': 10239}, {'_account_id': 10459}, {'_account_id': 22348}]","[{'number': 1, 'created': '2020-10-10 17:30:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstacksdk/commit/676ce9cdcaad0c5fb42f803a5c9807e006fc421b', 'message': 'DNM test a devstack-tox-functional change\n\nDepends-On: https://review.opendev.org/757293\nChange-Id: I6eef26db244352a7fd13093114699641b994b102\n'}, {'number': 2, 'created': '2020-10-10 23:14:14.000000000', 'files': ['.zuul.yaml', 'tox.ini'], 'web_link': 'https://opendev.org/openstack/openstacksdk/commit/27d723966a82daf64ed447d2ed3d63335ae4ccd6', 'message': 'DNM test a devstack-tox-functional change\n\nIncludes the fix from\nhttps://review.opendev.org/#/c/757123/2/.zuul.yaml\nfor testing purposes.\n\nDepends-On: https://review.opendev.org/757293\nChange-Id: I6eef26db244352a7fd13093114699641b994b102\n'}]",0,757304,27d723966a82daf64ed447d2ed3d63335ae4ccd6,10,3,2,10459,,,0,"DNM test a devstack-tox-functional change

Includes the fix from
https://review.opendev.org/#/c/757123/2/.zuul.yaml
for testing purposes.

Depends-On: https://review.opendev.org/757293
Change-Id: I6eef26db244352a7fd13093114699641b994b102
",git fetch https://review.opendev.org/openstack/openstacksdk refs/changes/04/757304/1 && git format-patch -1 --stdout FETCH_HEAD,['tox.ini'],1,676ce9cdcaad0c5fb42f803a5c9807e006fc421b,func-allow-existing-tox-environment,,,1,0
openstack%2Fpython-openstackclient~master~I4f2501772e81cabea7dfec332f0ececbc1f570c8,openstack/python-openstackclient,master,I4f2501772e81cabea7dfec332f0ececbc1f570c8,DNM test a devstack-tox-functional change,ABANDONED,2020-08-18 09:24:42.000000000,2020-12-01 12:04:20.000000000,,"[{'_account_id': 10459}, {'_account_id': 22348}, {'_account_id': 28182}]","[{'number': 1, 'created': '2020-08-18 09:24:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-openstackclient/commit/bc8a5240e8898e4c84f4cac3a366bc8506b654d0', 'message': 'DNM test a devstack-tox-functional change\n\nDepends-On: https://review.opendev.org/746235\nChange-Id: I4f2501772e81cabea7dfec332f0ececbc1f570c8\n'}, {'number': 2, 'created': '2020-10-10 17:27:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-openstackclient/commit/6b919a4007cb60fd50e9a05456fa637192ceca24', 'message': 'DNM test a devstack-tox-functional change\n\nDepends-On: https://review.opendev.org/757293\nChange-Id: I4f2501772e81cabea7dfec332f0ececbc1f570c8\n'}, {'number': 3, 'created': '2020-10-10 17:28:02.000000000', 'files': ['tox.ini'], 'web_link': 'https://opendev.org/openstack/python-openstackclient/commit/40e440ffc3f9f47e9d7dafaac64642d2727f3676', 'message': 'DNM test a devstack-tox-functional change\n\nDepends-On: https://review.opendev.org/757293\nChange-Id: I4f2501772e81cabea7dfec332f0ececbc1f570c8\n'}]",0,746667,40e440ffc3f9f47e9d7dafaac64642d2727f3676,23,3,3,10459,,,0,"DNM test a devstack-tox-functional change

Depends-On: https://review.opendev.org/757293
Change-Id: I4f2501772e81cabea7dfec332f0ececbc1f570c8
",git fetch https://review.opendev.org/openstack/python-openstackclient refs/changes/67/746667/1 && git format-patch -1 --stdout FETCH_HEAD,['tox.ini'],1,bc8a5240e8898e4c84f4cac3a366bc8506b654d0,func-allow-existing-tox-environment,,,1,0
openstack%2Fpython-watcherclient~master~I1c53a9542402daa4be5ed7e2bbebbae5bf8a6afb,openstack/python-watcherclient,master,I1c53a9542402daa4be5ed7e2bbebbae5bf8a6afb,requirements: Drop os-testr,NEW,2020-10-14 02:46:50.000000000,2020-12-01 11:56:24.000000000,,"[{'_account_id': 11904}, {'_account_id': 22348}, {'_account_id': 32231}]","[{'number': 1, 'created': '2020-10-14 02:46:50.000000000', 'files': ['lower-constraints.txt'], 'web_link': 'https://opendev.org/openstack/python-watcherclient/commit/94c553235b8fbc64eadc6c9e63da109ea844c79c', 'message': 'requirements: Drop os-testr\n\nDrop os-testr switched to stestr\n\nChange-Id: I1c53a9542402daa4be5ed7e2bbebbae5bf8a6afb\n'}]",0,757983,94c553235b8fbc64eadc6c9e63da109ea844c79c,4,3,1,32238,,,0,"requirements: Drop os-testr

Drop os-testr switched to stestr

Change-Id: I1c53a9542402daa4be5ed7e2bbebbae5bf8a6afb
",git fetch https://review.opendev.org/openstack/python-watcherclient refs/changes/83/757983/1 && git format-patch -1 --stdout FETCH_HEAD,['lower-constraints.txt'],1,94c553235b8fbc64eadc6c9e63da109ea844c79c,,,os-testr==1.0.0,0,1
openstack%2Fpython-openstackclient~master~I83048af60d7ea5400275c06da91d7959f7a8254d,openstack/python-openstackclient,master,I83048af60d7ea5400275c06da91d7959f7a8254d,Extension to the DSCP Marking Rule This extends the CLI to include the classification_group_id and the classification_priority value for deciding the relitive priority of the rules.,ABANDONED,2019-12-18 18:46:39.000000000,2020-12-01 11:52:38.000000000,,"[{'_account_id': 11904}, {'_account_id': 18051}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-12-18 18:46:39.000000000', 'files': ['openstackclient/network/v2/network_qos_rule.py', 'openstackclient/network/v2/network_classification_group.py', 'openstackclient/network/v2/network_classification.py'], 'web_link': 'https://opendev.org/openstack/python-openstackclient/commit/b8679e9111caac4bd1293809788ab36599bd323d', 'message': 'Extension to the DSCP Marking Rule\nThis extends the CLI to include the classification_group_id\nand the classification_priority value for deciding the relitive\npriority of the rules.\n\nChange-Id: I83048af60d7ea5400275c06da91d7959f7a8254d\n'}]",8,699832,b8679e9111caac4bd1293809788ab36599bd323d,7,3,1,18051,,,0,"Extension to the DSCP Marking Rule
This extends the CLI to include the classification_group_id
and the classification_priority value for deciding the relitive
priority of the rules.

Change-Id: I83048af60d7ea5400275c06da91d7959f7a8254d
",git fetch https://review.opendev.org/openstack/python-openstackclient refs/changes/32/699832/1 && git format-patch -1 --stdout FETCH_HEAD,"['openstackclient/network/v2/network_qos_rule.py', 'openstackclient/network/v2/network_classification_group.py', 'openstackclient/network/v2/network_classification.py']",3,b8679e9111caac4bd1293809788ab36599bd323d,bp/neutron-classifier-neutron-qos," 'type', metavar='type', 'name', metavar='name', nargs='?', eth_type = parsed_args.ethertype if isinstance(eth_type, int)\ else int(eth_type, 16) definition['ethertype'] = eth_type"," 'type', metavar='TYPE', '--name', metavar='NAME', definition['ethertype'] = parsed_args.ethertype",31,5
openstack%2Fpython-openstackclient~master~I6c04541c17d301fce1b18bd5e1c1d55a56c5adb5,openstack/python-openstackclient,master,I6c04541c17d301fce1b18bd5e1c1d55a56c5adb5,Neutron Classifier CLI,ABANDONED,2019-10-08 09:42:00.000000000,2020-12-01 11:52:35.000000000,,"[{'_account_id': 11904}, {'_account_id': 18051}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-10-08 09:42:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-openstackclient/commit/9dc6b0cb7087658812c80270be9546d7ac08e21e', 'message': '[POC] Neutron Classifier CLI\nMock up of Neutron Classifier CLI\n\nChange-Id: I6c04541c17d301fce1b18bd5e1c1d55a56c5adb5\n'}, {'number': 2, 'created': '2019-12-18 18:46:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-openstackclient/commit/cfcc88ab95c9b13f426a17e96b8b337a345cbb74', 'message': '[POC] Neutron Classifier CLI\nMock up of Neutron Classifier CLI\n\nChange-Id: I6c04541c17d301fce1b18bd5e1c1d55a56c5adb5\n'}, {'number': 3, 'created': '2020-01-17 18:52:13.000000000', 'files': ['openstackclient/network/v2/network_classification_group.py', 'openstackclient/network/v2/network_classification.py', 'openstackclient/network/v2/network_classification_types.py', 'setup.cfg'], 'web_link': 'https://opendev.org/openstack/python-openstackclient/commit/db79cd022a7e4cd63a22ba92aa2b26c5f8c6dea1', 'message': 'Neutron Classifier CLI\n\nCLI to a neutron classification extension to be consumed by other\nneutron extensions.\n\nChange-Id: I6c04541c17d301fce1b18bd5e1c1d55a56c5adb5\n'}]",2,687256,db79cd022a7e4cd63a22ba92aa2b26c5f8c6dea1,14,3,3,18051,,,0,"Neutron Classifier CLI

CLI to a neutron classification extension to be consumed by other
neutron extensions.

Change-Id: I6c04541c17d301fce1b18bd5e1c1d55a56c5adb5
",git fetch https://review.opendev.org/openstack/python-openstackclient refs/changes/56/687256/1 && git format-patch -1 --stdout FETCH_HEAD,"['openstackclient/network/v2/network_classification_group.py', 'openstackclient/network/v2/network_classification.py', 'openstackclient/network/v2/network_classification_types.py', 'setup.cfg']",4,9dc6b0cb7087658812c80270be9546d7ac08e21e,bp/neutron-classifier-neutron-qos, network_classification_create = openstackclient.network.v2.network_classification:CreateClassification network_classification_delete = openstackclient.network.v2.network_classification:DeleteClassification network_classification_list = openstackclient.network.v2.network_classification:ListClassification network_classification_show = openstackclient.network.v2.network_classification:ShowClassification network_classification_group_create = openstackclient.network.v2.network_classification_group:CreateClassificationGroup network_classification_group_delete = openstackclient.network.v2.network_classification_group:DeleteClassificationGroup network_classification_group_list = openstackclient.network.v2.network_classification_group:ListClassificationGroup network_classification_group_show = openstackclient.network.v2.network_classification_group:ShowClassificationGroup network_classification_types_list = openstackclient.network.v2.network_classification_types:ListClassificationTypes ,,593,0
openstack%2Fpython-openstackclient~master~I10015ada525814d47ba704d44c54d94b158d3387,openstack/python-openstackclient,master,I10015ada525814d47ba704d44c54d94b158d3387,Display the host field and allow filtering by host,ABANDONED,2019-11-21 21:39:36.000000000,2020-12-01 11:51:58.000000000,,"[{'_account_id': 10135}, {'_account_id': 22348}, {'_account_id': 29349}]","[{'number': 1, 'created': '2019-11-21 21:39:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-openstackclient/commit/bd692a01bdf65a5fe0bb294b376aa834911e6988', 'message': 'Display the host field and allow filtering by host\n\nAs an operator, when servicing a volume node, it may be useful to list\nall volume nodes of a specific host. So this patch adds the\nos-vol-host-attr:host field which the cinder API provides, displayed as\njust ""Host"". We also have the --host filter, which makes it possible to\nlist all volumes of a specific host.\n\nChange-Id: I10015ada525814d47ba704d44c54d94b158d3387\n'}, {'number': 2, 'created': '2019-11-22 07:50:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-openstackclient/commit/ad326cd81d2cb50505442dc7c412192ff28b00fa', 'message': 'Display the host field and allow filtering by host\n\nAs an operator, when servicing a volume node, it may be useful to list\nall volume nodes of a specific host. So this patch adds the\nos-vol-host-attr:host field which the cinder API provides, displayed as\njust ""Host"". We also have the --host filter, which makes it possible to\nlist all volumes of a specific host.\n\nChange-Id: I10015ada525814d47ba704d44c54d94b158d3387\n'}, {'number': 3, 'created': '2019-11-22 10:38:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-openstackclient/commit/ee3e9d7c00ba763b31e827dc9321e3838ac05853', 'message': 'Display the host field and allow filtering by host\n\nAs an operator, when servicing a volume node, it may be useful to list\nall volume nodes of a specific host. So this patch adds the\nos-vol-host-attr:host field which the cinder API provides, displayed as\njust ""Host"". We also have the --host filter, which makes it possible to\nlist all volumes of a specific host.\n\nChange-Id: I10015ada525814d47ba704d44c54d94b158d3387\n'}, {'number': 4, 'created': '2019-11-22 11:04:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-openstackclient/commit/b3d893b7a60508002db147d8246ef0b5fa23c265', 'message': 'Display the host field and allow filtering by host\n\nAs an operator, when servicing a volume node, it may be useful to list\nall volume nodes of a specific host. So this patch adds the\nos-vol-host-attr:host field which the cinder API provides, displayed as\njust ""Host"". We also have the --host filter, which makes it possible to\nlist all volumes of a specific host.\n\nChange-Id: I10015ada525814d47ba704d44c54d94b158d3387\n'}, {'number': 5, 'created': '2019-11-22 11:13:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-openstackclient/commit/aed7f34c05f45df33699c8cb3001f318f90ca3b9', 'message': 'Display the host field and allow filtering by host\n\nAs an operator, when servicing a volume node, it may be useful to list\nall volume nodes of a specific host. So this patch adds the\nos-vol-host-attr:host field which the cinder API provides, displayed as\njust ""Host"". We also have the --host filter, which makes it possible to\nlist all volumes of a specific host.\n\nChange-Id: I10015ada525814d47ba704d44c54d94b158d3387\n'}, {'number': 6, 'created': '2019-11-22 11:28:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-openstackclient/commit/6b3f5966e6d3528c918897db6d3d4214992c417c', 'message': 'Display the host field and allow filtering by host\n\nAs an operator, when servicing a volume node, it may be useful to list\nall volume nodes of a specific host. So this patch adds the\nos-vol-host-attr:host field which the cinder API provides, displayed as\njust ""Host"". We also have the --host filter, which makes it possible to\nlist all volumes of a specific host.\n\nChange-Id: I10015ada525814d47ba704d44c54d94b158d3387\n'}, {'number': 7, 'created': '2019-11-22 11:39:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-openstackclient/commit/01b0370cb6901dfb51e820ae9dfcb38bc7612c18', 'message': 'Display the host field and allow filtering by host\n\nAs an operator, when servicing a volume node, it may be useful to list\nall volume nodes of a specific host. So this patch adds the\nos-vol-host-attr:host field which the cinder API provides, displayed as\njust ""Host"". We also have the --host filter, which makes it possible to\nlist all volumes of a specific host.\n\nChange-Id: I10015ada525814d47ba704d44c54d94b158d3387\n'}, {'number': 8, 'created': '2019-11-22 12:10:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-openstackclient/commit/6caee13c1276341b9ca5ffefad924671d61e5037', 'message': 'Display the host field and allow filtering by host\n\nAs an operator, when servicing a volume node, it may be useful to list\nall volume nodes of a specific host. So this patch adds the\nos-vol-host-attr:host field which the cinder API provides, displayed as\njust ""Host"". We also have the --host filter, which makes it possible to\nlist all volumes of a specific host.\n\nChange-Id: I10015ada525814d47ba704d44c54d94b158d3387\n'}, {'number': 9, 'created': '2019-11-22 12:57:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-openstackclient/commit/bb98cc86615141cad2e4cfff9134f7ecb9c30266', 'message': 'Display the host field and allow filtering by host\n\nAs an operator, when servicing a volume node, it may be useful to list\nall volume nodes of a specific host. So this patch adds the\nos-vol-host-attr:host field which the cinder API provides, displayed as\njust ""Host"". We also have the --host filter, which makes it possible to\nlist all volumes of a specific host.\n\nChange-Id: I10015ada525814d47ba704d44c54d94b158d3387\n'}, {'number': 10, 'created': '2019-11-22 13:05:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-openstackclient/commit/1e37464e0482d34d545807f1af16c453d7ecee38', 'message': 'Display the host field and allow filtering by host\n\nAs an operator, when servicing a volume node, it may be useful to list\nall volume nodes of a specific host. So this patch adds the\nos-vol-host-attr:host field which the cinder API provides, displayed as\njust ""Host"". We also have the --host filter, which makes it possible to\nlist all volumes of a specific host.\n\nChange-Id: I10015ada525814d47ba704d44c54d94b158d3387\n'}, {'number': 11, 'created': '2019-11-22 13:07:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-openstackclient/commit/c56ca05b103912c195b064064802fd9789ddfe15', 'message': 'Display the host field and allow filtering by host\n\nAs an operator, when servicing a volume node, it may be useful to list\nall volume nodes of a specific host. So this patch adds the\nos-vol-host-attr:host field which the cinder API provides, displayed as\njust ""Host"". We also have the --host filter, which makes it possible to\nlist all volumes of a specific host.\n\nChange-Id: I10015ada525814d47ba704d44c54d94b158d3387\n'}, {'number': 12, 'created': '2019-11-22 13:19:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-openstackclient/commit/5dfa87d84a1a97d8cb18a95a0647ddc96c34184e', 'message': 'Display the host field and allow filtering by host\n\nAs an operator, when servicing a volume node, it may be useful to list\nall volume nodes of a specific host. So this patch adds the\nos-vol-host-attr:host field which the cinder API provides, displayed as\njust ""Host"". We also have the --host filter, which makes it possible to\nlist all volumes of a specific host.\n\nChange-Id: I10015ada525814d47ba704d44c54d94b158d3387\n'}, {'number': 13, 'created': '2019-11-22 13:31:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-openstackclient/commit/70556132fc006204dd6ce90eb430c0f6210bdd0c', 'message': 'Display the host field and allow filtering by host\n\nAs an operator, when servicing a volume node, it may be useful to list\nall volume nodes of a specific host. So this patch adds the\nos-vol-host-attr:host field which the cinder API provides, displayed as\njust ""Host"". We also have the --host filter, which makes it possible to\nlist all volumes of a specific host.\n\nChange-Id: I10015ada525814d47ba704d44c54d94b158d3387\n'}, {'number': 14, 'created': '2019-11-22 13:38:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-openstackclient/commit/c51e1ec701d76e87628ee7a0e830761dddc2ce8b', 'message': 'Display the host field and allow filtering by host\n\nAs an operator, when servicing a volume node, it may be useful to list\nall volume nodes of a specific host. So this patch adds the\nos-vol-host-attr:host field which the cinder API provides, displayed as\njust ""Host"". We also have the --host filter, which makes it possible to\nlist all volumes of a specific host.\n\nChange-Id: I10015ada525814d47ba704d44c54d94b158d3387\n'}, {'number': 15, 'created': '2019-11-22 14:37:30.000000000', 'files': ['openstackclient/tests/unit/volume/v1/fakes.py', 'openstackclient/volume/v2/volume.py', 'openstackclient/tests/unit/volume/v2/fakes.py', 'openstackclient/volume/v1/volume.py', 'openstackclient/tests/unit/volume/v1/test_volume.py', 'openstackclient/tests/unit/volume/v2/test_volume.py'], 'web_link': 'https://opendev.org/openstack/python-openstackclient/commit/3c0b829402677598c456c5ddc1f98f84cec08780', 'message': 'Display the host field and allow filtering by host\n\nAs an operator, when servicing a volume node, it may be useful to list\nall volume nodes of a specific host. So this patch adds the\nos-vol-host-attr:host field which the cinder API provides, displayed as\njust ""Host"". We also have the --host filter, which makes it possible to\nlist all volumes of a specific host.\n\nChange-Id: I10015ada525814d47ba704d44c54d94b158d3387\n'}]",0,695586,3c0b829402677598c456c5ddc1f98f84cec08780,20,3,15,6476,,,0,"Display the host field and allow filtering by host

As an operator, when servicing a volume node, it may be useful to list
all volume nodes of a specific host. So this patch adds the
os-vol-host-attr:host field which the cinder API provides, displayed as
just ""Host"". We also have the --host filter, which makes it possible to
list all volumes of a specific host.

Change-Id: I10015ada525814d47ba704d44c54d94b158d3387
",git fetch https://review.opendev.org/openstack/python-openstackclient refs/changes/86/695586/1 && git format-patch -1 --stdout FETCH_HEAD,['openstackclient/volume/v2/volume.py'],1,bd692a01bdf65a5fe0bb294b376aa834911e6988,," '--host', metavar='<host>', help=_('Filter results by host'), ) parser.add_argument( 'os-vol-host-attr:host', column_headers[8] = 'Host' 'host': parsed_args.host,",,8,0
openstack%2Fpython-openstackclient~master~I4b9206260707829047c860d9acd484d2b47fd2ee,openstack/python-openstackclient,master,I4b9206260707829047c860d9acd484d2b47fd2ee,network: add cascade delete,ABANDONED,2019-06-10 19:05:35.000000000,2020-12-01 11:50:52.000000000,,"[{'_account_id': 1131}, {'_account_id': 4694}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-06-10 19:05:35.000000000', 'files': ['openstackclient/network/v2/network.py'], 'web_link': 'https://opendev.org/openstack/python-openstackclient/commit/4759072695429b4a760c44763f50f0fde744bb72', 'message': 'network: add cascade delete\n\nIt is very common for a user to try to delete a network and end\nup with a message saying that it has failed to delete because\nof some other resources (i.e. ports) still there.  This is not\nvery intiuitive for the user to deal with.\n\nThis patch adds a `--cascade` flag to deleting network which\nwill list all ports and subnets and delete them before deleting\nthe network.  This will make life a lot easier for users that\njust want to blow a network away.\n\nChange-Id: I4b9206260707829047c860d9acd484d2b47fd2ee\n'}]",1,664422,4759072695429b4a760c44763f50f0fde744bb72,4,3,1,1004,,,0,"network: add cascade delete

It is very common for a user to try to delete a network and end
up with a message saying that it has failed to delete because
of some other resources (i.e. ports) still there.  This is not
very intiuitive for the user to deal with.

This patch adds a `--cascade` flag to deleting network which
will list all ports and subnets and delete them before deleting
the network.  This will make life a lot easier for users that
just want to blow a network away.

Change-Id: I4b9206260707829047c860d9acd484d2b47fd2ee
",git fetch https://review.opendev.org/openstack/python-openstackclient refs/changes/22/664422/1 && git format-patch -1 --stdout FETCH_HEAD,['openstackclient/network/v2/network.py'],1,4759072695429b4a760c44763f50f0fde744bb72,," parser.add_argument( '--cascade', action='store_true', default=False, help=_(""Cascade delete (deletes subnets, ports)"") ) if obj and parsed_args.cascade: for port in client.ports(network_id=obj.id): client.delete_port(port) for subnet in client.subnets(network_id=obj.id): client.delete_subnet(subnet) ",,12,0
openstack%2Fpython-openstackclient~master~I8246ebc600cc4d06d477096db121e503ec1f3683,openstack/python-openstackclient,master,I8246ebc600cc4d06d477096db121e503ec1f3683,"Its in relation to the bug, https://bugs.launchpad.net/python-openstackclient/+bug/1810260",ABANDONED,2018-12-28 12:18:07.000000000,2020-12-01 11:49:04.000000000,,"[{'_account_id': 841}, {'_account_id': 10068}, {'_account_id': 22348}, {'_account_id': 29561}]","[{'number': 1, 'created': '2018-12-28 12:18:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-openstackclient/commit/d04cec67a3d2d51e588ee21222a7a2408a0fcb6d', 'message': 'commiting changes\n\nChange-Id: I8246ebc600cc4d06d477096db121e503ec1f3683\n'}, {'number': 2, 'created': '2019-01-02 06:50:20.000000000', 'files': ['openstackclient/common/quota.py'], 'web_link': 'https://opendev.org/openstack/python-openstackclient/commit/3b5c2007b25424c66a3830a4717cbd3e0b381b9a', 'message': 'Its in relation to the bug, https://bugs.launchpad.net/python-openstackclient/+bug/1810260\n\nChanges are made in quota.py file to check the network quota usage values, and then  set the quota if the value is greater than usgae, else throw an error message.\n\n\nChange-Id: I8246ebc600cc4d06d477096db121e503ec1f3683\n'}]",2,627631,3b5c2007b25424c66a3830a4717cbd3e0b381b9a,8,4,2,29561,,,0,"Its in relation to the bug, https://bugs.launchpad.net/python-openstackclient/+bug/1810260

Changes are made in quota.py file to check the network quota usage values, and then  set the quota if the value is greater than usgae, else throw an error message.


Change-Id: I8246ebc600cc4d06d477096db121e503ec1f3683
",git fetch https://review.opendev.org/openstack/python-openstackclient refs/changes/31/627631/1 && git format-patch -1 --stdout FETCH_HEAD,['openstackclient/common/quota.py'],1,d04cec67a3d2d51e588ee21222a7a2408a0fcb6d,new-branch,"NEW_NETWORK_QUOTA = { 'l7policy': 'l7_policies', 'subnetpool': 'subnet_pools', 'vip': 'vips', 'port': 'ports', 'subnet': 'subnets', 'network': 'networks', 'floatingip': 'floating_ips', 'security_group_rule': 'security_group_rules', 'healthmonitor': 'health_monitors', 'security_group': 'security_groups', 'router': 'routers', 'rbac_policy': 'rbac_policies' } network_client = self.app.client_manager.network show = ShowQuota(self.app, None) test_args = vars(parsed_args) test_args['default'] = False project_info = show._get_project(parsed_args) project_id = project_info['id'] network_quota = network_client.get_quota(project_id, True) network_quota = network_quota.to_dict() network_kwar = {} x = y = 0 for k, v in NEW_NETWORK_QUOTA.items(): x += 1 if value > network_quota[v]['used']: network_kwar[k] = value y += 1 if x == y: network_kwargs = network_kwar else: print('Quota value(s) cannot be less than the \ current usage value(s)')"," for k, v in NETWORK_QUOTAS.items(): network_kwargs[k] = value",35,2
openstack%2Frpm-packaging~stable%2Ftrain~Id7a39eade6068031bfee1359ab55753dc219e450,openstack/rpm-packaging,stable/train,Id7a39eade6068031bfee1359ab55753dc219e450,Train new releases up to Nov 2020,MERGED,2020-11-09 12:11:46.000000000,2020-12-01 11:40:19.000000000,2020-12-01 11:40:19.000000000,"[{'_account_id': 6593}, {'_account_id': 13294}, {'_account_id': 19648}, {'_account_id': 22348}, {'_account_id': 23181}, {'_account_id': 27380}, {'_account_id': 28522}]","[{'number': 1, 'created': '2020-11-09 12:11:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rpm-packaging/commit/17c29f03c5b12b708f570d226701360e735f1abc', 'message': 'Train new releases up to Nov 2020\n\nChange-Id: Id7a39eade6068031bfee1359ab55753dc219e450\nSigned-off-by: Dirk Mueller <dirk@dmllr.de>\n'}, {'number': 2, 'created': '2020-11-10 13:12:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rpm-packaging/commit/0a9e9196e167d61479d1bc86323f83ec5f44f74d', 'message': 'Train new releases up to Nov 2020\n\nChange-Id: Id7a39eade6068031bfee1359ab55753dc219e450\nSigned-off-by: Dirk Mueller <dirk@dmllr.de>\n'}, {'number': 3, 'created': '2020-11-13 08:21:33.000000000', 'files': ['openstack/python-heatclient/python-heatclient.spec.j2', 'openstack/os-brick/os-brick.spec.j2', 'openstack/castellan/castellan.spec.j2', 'openstack/python-openstackclient/python-openstackclient.spec.j2', 'openstack/oslo.messaging/oslo.messaging.spec.j2', 'openstack/python-troveclient/python-troveclient.spec.j2', 'openstack/ovsdbapp/ovsdbapp.spec.j2'], 'web_link': 'https://opendev.org/openstack/rpm-packaging/commit/861b5fd7fd3b78a9a9b33074e00347cfe4723711', 'message': 'Train new releases up to Nov 2020\n\nChange-Id: Id7a39eade6068031bfee1359ab55753dc219e450\nSigned-off-by: Dirk Mueller <dirk@dmllr.de>\n'}]",5,761900,861b5fd7fd3b78a9a9b33074e00347cfe4723711,27,7,3,6593,,,0,"Train new releases up to Nov 2020

Change-Id: Id7a39eade6068031bfee1359ab55753dc219e450
Signed-off-by: Dirk Mueller <dirk@dmllr.de>
",git fetch https://review.opendev.org/openstack/rpm-packaging refs/changes/00/761900/2 && git format-patch -1 --stdout FETCH_HEAD,"['openstack/python-heatclient/python-heatclient.spec.j2', 'openstack/os-brick/os-brick.spec.j2', 'openstack/castellan/castellan.spec.j2', 'openstack/oslo.messaging/oslo.messaging.spec.j2', 'openstack/python-openstackclient/python-openstackclient.spec.j2', 'openstack/python-troveclient/python-troveclient.spec.j2', 'openstack/ovsdbapp/ovsdbapp.spec.j2']",7,17c29f03c5b12b708f570d226701360e735f1abc,,{% set upstream_version = upstream_version('0.17.5') %,{% set upstream_version = upstream_version('0.17.3') %},7,7
openstack%2Frpm-packaging~master~Ia2741891cbea5ff6c67082cc1a09013813693edc,openstack/rpm-packaging,master,Ia2741891cbea5ff6c67082cc1a09013813693edc,update stevedore to 3.3.0,MERGED,2020-12-01 01:27:25.000000000,2020-12-01 11:35:37.000000000,2020-12-01 11:35:37.000000000,"[{'_account_id': 6593}, {'_account_id': 13294}, {'_account_id': 19648}, {'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2020-12-01 01:27:25.000000000', 'files': ['openstack/stevedore/stevedore.spec.j2'], 'web_link': 'https://opendev.org/openstack/rpm-packaging/commit/0a75dc9757e1d9c66376f3119ce4d3fad423bd7a', 'message': 'update stevedore to 3.3.0\n\nChange-Id: Ia2741891cbea5ff6c67082cc1a09013813693edc\n'}]",0,764865,0a75dc9757e1d9c66376f3119ce4d3fad423bd7a,12,5,1,30533,,,0,"update stevedore to 3.3.0

Change-Id: Ia2741891cbea5ff6c67082cc1a09013813693edc
",git fetch https://review.opendev.org/openstack/rpm-packaging refs/changes/65/764865/1 && git format-patch -1 --stdout FETCH_HEAD,['openstack/stevedore/stevedore.spec.j2'],1,0a75dc9757e1d9c66376f3119ce4d3fad423bd7a,bug/stevedore,{% set upstream_version = upstream_version('3.3.0') %},{% set upstream_version = upstream_version('3.2.2') %},1,1
openstack%2Fnova-specs~master~I2c5e34c75aec4b92fcb293d12d5284bd385fea43,openstack/nova-specs,master,I2c5e34c75aec4b92fcb293d12d5284bd385fea43,Update modernize-os-hypervisors-api spec,MERGED,2020-11-17 16:35:31.000000000,2020-12-01 11:22:40.000000000,2020-12-01 11:20:57.000000000,"[{'_account_id': 7166}, {'_account_id': 8556}, {'_account_id': 11604}, {'_account_id': 15334}, {'_account_id': 22348}]","[{'number': 1, 'created': '2020-11-17 16:35:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/356c5acd1c4640c17abb01e625ca7acb98e0e77b', 'message': ""Update modernize-os-hypervisors-api spec\n\nAmend the spec to include policy changes that will allow users with the\n'PROJECT_ADMIN' role to list hypervisors that their project has access\nto.\n\nChange-Id: I2c5e34c75aec4b92fcb293d12d5284bd385fea43\nSigned-off-by: Stephen Finucane <stephenfin@redhat.com>\n""}, {'number': 2, 'created': '2020-11-20 11:52:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/a1ab7978406e586d53efd8ca3c9390f5ad30c72f', 'message': ""Update modernize-os-hypervisors-api spec\n\nAmend the spec to include policy changes that will allow users with the\n'PROJECT_ADMIN' role to list hypervisors that their project has access\nto.\n\nChange-Id: I2c5e34c75aec4b92fcb293d12d5284bd385fea43\nSigned-off-by: Stephen Finucane <stephenfin@redhat.com>\n""}, {'number': 3, 'created': '2020-11-24 17:33:22.000000000', 'files': ['specs/wallaby/approved/modernize-os-hypervisors-api.rst'], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/8f1576a6b6bbde6d0d817c8236722be5eddc31e1', 'message': ""Update modernize-os-hypervisors-api spec\n\nAmend the spec to include policy changes that will allow users with the\n'PROJECT_ADMIN' role to list hypervisors that their project has access\nto.\n\nChange-Id: I2c5e34c75aec4b92fcb293d12d5284bd385fea43\nSigned-off-by: Stephen Finucane <stephenfin@redhat.com>\n""}]",17,763043,8f1576a6b6bbde6d0d817c8236722be5eddc31e1,20,5,3,15334,,,0,"Update modernize-os-hypervisors-api spec

Amend the spec to include policy changes that will allow users with the
'PROJECT_ADMIN' role to list hypervisors that their project has access
to.

Change-Id: I2c5e34c75aec4b92fcb293d12d5284bd385fea43
Signed-off-by: Stephen Finucane <stephenfin@redhat.com>
",git fetch https://review.opendev.org/openstack/nova-specs refs/changes/43/763043/2 && git format-patch -1 --stdout FETCH_HEAD,['specs/wallaby/approved/modernize-os-hypervisors-api.rst'],1,356c5acd1c4640c17abb01e625ca7acb98e0e77b,bp/modernize-os-hypervisors-api,"Finally, the useless fields. There are varied reasons their uselessness, described below, but all should be removed: misunderstood by end-users.While we can remove the useless fields, the useful ones are still limited in their usefulness owing to the restrictive policy in place for this API. We can improve this by allowing users with the ``PROJECT_ADMIN`` role to list all hypervisors their project is allowed to access. API in its entirety. Modify the policy checks and output of the ``/os-hypervisors`` API to allow users with the ``PROJECT_ADMIN`` role to see all hypervisors their project is allowed to access, based on aggregate metadata.In addition, the ``/os-hypervisors/statistics`` API will be removed entirely and will return a HTTP 410 (Gone). Finally, a new policy will be introduced allowing users with the ``PROJECT_ADMIN`` role to see all hypervisors their project is allowed access to via the ``/os-hypervisors`` API.","Finally, the useless fields: misunderstood by end-users. Use placement.API in its entirety.Starting from the new API microversion, the ``/os-hypervisors/statistics`` API will be removed entirely and will return a HTTP 410 (Gone).",18,5
openstack%2Fnova-specs~master~Iba56a7b66d69513f4dc4049a5c3507844735f3b6,openstack/nova-specs,master,Iba56a7b66d69513f4dc4049a5c3507844735f3b6,[WIP]Add blueprint snapshot-vms-with-state-of-processes,ABANDONED,2019-10-06 18:24:11.000000000,2020-12-01 11:11:56.000000000,,"[{'_account_id': 782}, {'_account_id': 4393}, {'_account_id': 4690}, {'_account_id': 5754}, {'_account_id': 7166}, {'_account_id': 9708}, {'_account_id': 11604}, {'_account_id': 14070}, {'_account_id': 15334}, {'_account_id': 22348}, {'_account_id': 26458}, {'_account_id': 30977}]","[{'number': 1, 'created': '2019-10-06 18:24:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/efe213b30cf23dfb96e2f09b96d7046abb6ef623', 'message': 'add snapshot blueprint\n\nChange-Id: Iba56a7b66d69513f4dc4049a5c3507844735f3b6\nSigned-off-by: SonPham <phamngocsonls@gmail.com>\n'}, {'number': 2, 'created': '2019-10-09 16:20:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/f5f928edd9df95cece756d7185b79eb70aede3b1', 'message': 'add snapshot blueprint\n\nChange-Id: Iba56a7b66d69513f4dc4049a5c3507844735f3b6\nSigned-off-by: SonPham <phamngocsonls@gmail.com>\n'}, {'number': 3, 'created': '2019-10-09 16:41:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/6b60829773e76dbbba7fab61691b800ec86159eb', 'message': '[WIP]Add blueprint: snapshot-vms-with-state of-processes\n\nCreate a new type of live-snapshot\nwith state of processes via libvirt.\n\nChange-Id: Iba56a7b66d69513f4dc4049a5c3507844735f3b6\nSigned-off-by: SonPham <phamngocsonls@gmail.com>\n'}, {'number': 4, 'created': '2019-10-14 18:00:37.000000000', 'files': ['specs/pike/approved/snapshot-vms-with-state-of-processes.rst'], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/86dc9f5094250b584dd5d1052947de7d4232a2a4', 'message': '[WIP]Add blueprint snapshot-vms-with-state-of-processes\n\nCreate a new type of live-snapshot\nwith state of processes via libvirt.\n\nChange-Id: Iba56a7b66d69513f4dc4049a5c3507844735f3b6\nSigned-off-by: SonPham <phamngocsonls@gmail.com>\n'}]",12,686948,86dc9f5094250b584dd5d1052947de7d4232a2a4,20,12,4,30977,,,0,"[WIP]Add blueprint snapshot-vms-with-state-of-processes

Create a new type of live-snapshot
with state of processes via libvirt.

Change-Id: Iba56a7b66d69513f4dc4049a5c3507844735f3b6
Signed-off-by: SonPham <phamngocsonls@gmail.com>
",git fetch https://review.opendev.org/openstack/nova-specs refs/changes/48/686948/4 && git format-patch -1 --stdout FETCH_HEAD,['specs/pike/approved/snapshot-vms-with-state-of-processes.rst'],1,efe213b30cf23dfb96e2f09b96d7046abb6ef623,,".. This work is licensed under a Creative Commons Attribution 3.0 Unported License. http://creativecommons.org/licenses/by/3.0/legalcode ============================================ Live snapshot for VM with state of processes ============================================ https://blueprints.launchpad.net/nova/+spec/snapshot-vms-with-state-of-processes The aim of this feature is to let create a new type of live-snapshot with state of processes. Problem description =================== Openstack Snapshot is supported live-snapshot but a snapshot is a disk snapshot. When you want to use a snapshot, you must create new instance with image and volume created created earlier. There is no solution yet to keep running process of Instance in snapshot. Use Cases --------- As a user in an OpenStack, it's important that I can save my data with snapshot, reduce boot time of instance. Preserve all state of the instance at the time of snapshot creation. Proposed change =============== Add a configuration option to create new snapshot type(snapshot keep process). * A new snapshot type use libvirt for snapshot, revert snapshot and delete. * A new type of boot is required. After instance has been snapshotted, it is difficult to start instance. Because after snapshot, cinder will not manage instance storage. Instance disk type has been converted form RAW to QCOW2 and move instance disk to other directory. Start instance has new snapshot type will make it error, because instance is no longer booting from cinder volume. Action ""start"" like ""Hard reboot instance"", Nova will reload information from old xml file. ""Soft reboot"" does not make instance error but can't use soft reboot when instance status is ""Shutoff"" but we can fix it. A new type of boot is ""soft snapshot"" when shutoff (Please disable hard reboot when instance has been snapshotted. * Before delete instance, instance must be deleted all snapshot. ""Delete an instance"" action include delete snapshots. * Revert snapshot with input: domain name, snapshot name ( use libvirt for revert) example command: virsh snapshot-revert <domain-name> <snapshot-name> Alternatives ------------ None Data model impact ----------------- None REST API impact --------------- Updating ... Security impact --------------- Nova no longer needs to store the volume connection information Notifications impact -------------------- None Other end user impact --------------------- None Performance Impact ------------------ Create and restore snapshot will make instance ""pause"" some minute depending on the size of the product. Create more snapshot on instance make the waiting time gets bigger. User can delete older snapshot, restart, change disk-cache type to unsafe to make faster. Other deployer impact --------------------- With Openstack multi-node system, Qcow2 volume disk( instance vloume and storage snapshot) is located at compute node. Developer impact ---------------- None Implementation ============== Assignee(s) ----------- Primary assignee: Son Pham Ngoc (sonpn) Other contributors: Cloudrity Work Items ---------- #. Create/restore live-snapshot with state of processes via Libvirt #. Soft start for instance has new snapshot type #. Fix ``Delete instance`` to delete instance has new snapshot type #. Dashboard on Horizon to show more information about instance's snapshot #. Provide Nova API for Create snapshot, Revert to snapshot, Delete snapshot,etc Dependencies ============ * libvirt-python Testing ======= None Documentation Impact ==================== * API documentation will need to be updated * The documentation for ``new snapshot type`` References ========== None History ======= None .. list-table:: Revisions :header-rows: 1 * - Release Name - Description * - Pike - Introduced ",,171,0
openstack%2Fnova-specs~master~Ie9117151b5a093f78bbbd7b878033970ebfcd4f4,openstack/nova-specs,master,Ie9117151b5a093f78bbbd7b878033970ebfcd4f4,enable-disable-duplicate-neutron-networks,ABANDONED,2014-04-22 06:57:39.000000000,2020-12-01 11:11:07.000000000,,[],"[{'number': 1, 'created': '2014-04-22 06:57:39.000000000', 'files': ['specs/juno/enable-disable-duplicate-neutron-networks.rst'], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/c1ba4f42314af61ee105ad46396240e1b9411a03', 'message': 'enable-disable-duplicate-neutron-networks\n\nChange-Id: Ie9117151b5a093f78bbbd7b878033970ebfcd4f4\n'}]",0,89491,c1ba4f42314af61ee105ad46396240e1b9411a03,1,0,1,8499,,,0,"enable-disable-duplicate-neutron-networks

Change-Id: Ie9117151b5a093f78bbbd7b878033970ebfcd4f4
",git fetch https://review.opendev.org/openstack/nova-specs refs/changes/91/89491/1 && git format-patch -1 --stdout FETCH_HEAD,['specs/juno/enable-disable-duplicate-neutron-networks.rst'],1,c1ba4f42314af61ee105ad46396240e1b9411a03,bp/enable-disable-duplicate-neutron-networks,".. This work is licensed under a Creative Commons Attribution 3.0 Unported License. http://creativecommons.org/licenses/by/3.0/legalcode ======================================================================= Allow/disallow instances to have multiple vnics on same Neutron network ======================================================================= https://blueprints.launchpad.net/nova/+spec/enable-disable-duplicate-neutron-networks If a nova config flag (named for instance ""duplicate_networks"" is set to ""enable"" (the default config flag could be set either to enable or disable) then Nova should allow booting VMs with multiple vNICs on same Neutron network for instance with --nic net-id <netid1> --nic net-id <netid1>,  (i.e. ports to be created on the same network) and --nic port-id <portid1> --nic port-id <portid2>,  (i.e. ports already created on the same network) Problem description =================== Currently, in Neutron client in Nova, creating a VM instance with multiple vNICs on same network is not allowed (neither by requesting the same network uuid more than once nor by specifying multiple pre-created ports on same network). It raises a ""duplicate networks"" exception. There are some few use cases in which we may want to create a VM with multiple vNICs on same Neutron network: * Neutron allows to have multiple subnets in one L2 network. Networks could be logically isolated using different subnets and therefore a VM could have multiple vNICs on different subnets on the same L2 network. This could be potentially beneficial if Neutron is configured with a limited number of VLANs with each one that could be reused for multiple subnets addresses isolation. * If further isolation between networks could be achieved using other mechanisms such as security groups (filters based on MAC addresses, IP addresses, etc.) or other external controller mechanisms, then a VM could have multiple vNICs on same L2 network and get further isolation specified and implemented by these mechanisms. * This is the case of OpenStack managing network service VMs for Neutron services such as firewall as a service. Running a firewall as a bridge service VM requires at least two vNICs that needs to be in same L2 network if running as a bridge. Bridged firewall is known to have several operational benefits: increased flexbility from decoupling routing and transparent filtering. A bridged firewall filter could be transparently inserted in-line anywhere in the network topology without any extra subnetting or IP renumbering or any other reconfiguration. Also the bridged firewall could be moved with zero downtime. Proposed change =============== We changed Neutron client in Nova so that if the same L2 network is requested multiple times in requested_networks, or resp. multiple ports on same L2 network are allocated for the same VM, then it will create or resp. attach the ports on same network if an added flag to nova.conf ""duplicate_networks"" is set to true. * If requested_networks includes duplicates then these duplicates could be counted in a dict indexed by the network_uuid, so that multiple ports would be created for the VM instances on each of the network with network_uuid * If multiple existent ports with same network_uuid are specified for the VM, then multiple VM vNICs should be attached to these ports on same L2 network. Alternatives ------------ Status quo Data model impact ----------------- None REST API impact --------------- None Security impact --------------- * If OpenStack is managing service VMs: None * If Openstack is managing user VMs: In the case ""duplicate_networks"" is enabled in nova.conf, and a tenant user instantiates a VM with multiple vNICs on same L2 network and executes a commands sequence inside the VM to install tools such as bridge-utils and then bridges between these multiple vNICs in a way that linux bridging will rewrite MAC src/dst in MAC frames and forward these to the same L2. Or if the tenant user could do this for more than one VM even on different L2 networks as it is currently allowed in Neutron client in Nova, then it will create a loop. Subsequent broadcast storm issues could be mitigated used proper means such as a dynamic rate limiting of that filtered traffic or ... Notifications impact -------------------- None Other end user impact --------------------- None Performance Impact ------------------ None Other deployer impact --------------------- None Developer impact ---------------- None Implementation ============== Assignee(s) ----------- Primary assignee: rbenali Work Items ---------- Bugfix is already available for review at : https://review.openstack.org/#/c/66777/ Dependencies ============ None Testing ======= Some testing should be added. Documentation Impact ==================== We expect to have the following documentation changes: * The added duplicate_networks flag related documentation * The way duplicate networks/ports on same network should be requested in nova boot CLI command References ========== * https://review.openstack.org/#/c/66777/ * http://lists.openstack.org/pipermail/openstack-dev/2014-April/033050.html ",,157,0
openstack%2Fnova-specs~master~I900c27709677821e61ae14b2e3899744be579c7f,openstack/nova-specs,master,I900c27709677821e61ae14b2e3899744be579c7f,Add CPU CQM (Cache Qos Monitoring) management,ABANDONED,2014-05-04 06:41:30.000000000,2020-12-01 11:11:01.000000000,,[{'_account_id': 4458}],"[{'number': 1, 'created': '2014-05-04 06:41:30.000000000', 'files': ['specs/juno/cache-qos-monitoring.rst'], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/e1d9f6bea525bcfc5ba7d5b479b7f03024ae63fd', 'message': ""Add CPU CQM (Cache Qos Monitoring) management\n\nIntel's new CPUs introduce Cache QoS Monitoring (CQM) allows an Operating System,\nHypervisor or similar system management agent to determine the usage of cache\nby applications running on the platform. The initial implementation is directed\nat last level cache (LLC) monitoring. So this can be used to monitor the\ninstance's cache.\n\nAdd the RMID resouce plugin to manager which instance can be monitored\nthe cache.\n\nChange-Id: I900c27709677821e61ae14b2e3899744be579c7f\n""}]",0,91994,e1d9f6bea525bcfc5ba7d5b479b7f03024ae63fd,2,1,1,7641,,,0,"Add CPU CQM (Cache Qos Monitoring) management

Intel's new CPUs introduce Cache QoS Monitoring (CQM) allows an Operating System,
Hypervisor or similar system management agent to determine the usage of cache
by applications running on the platform. The initial implementation is directed
at last level cache (LLC) monitoring. So this can be used to monitor the
instance's cache.

Add the RMID resouce plugin to manager which instance can be monitored
the cache.

Change-Id: I900c27709677821e61ae14b2e3899744be579c7f
",git fetch https://review.opendev.org/openstack/nova-specs refs/changes/94/91994/1 && git format-patch -1 --stdout FETCH_HEAD,['specs/juno/cache-qos-monitoring.rst'],1,e1d9f6bea525bcfc5ba7d5b479b7f03024ae63fd,cqm,".. This work is licensed under a Creative Commons Attribution 3.0 Unported License. http://creativecommons.org/licenses/by/3.0/legalcode ============================================== Add CPU CQM (Cache Qos Monitoring) management ============================================== https://blueprints.launchpad.net/nova/+spec/cache-qos-monitoring CQM:Enables monitoring of cache occupancy on a per-thread (via RMID) basis. RMID : The ID of the application or thread on a core as specified by the OS/VMM. This ID is provided by the OS/VMM, and used by the platform to tag and monitor events such as cache occupancy. Intel's new CPUs introduce Cache QoS Monitoring (CQM) allows an Operating System, Hypervisor or similar system management agent to determine the usage of cache by applications running on the platform. The initial implementation is directed at last level cache (LLC) monitoring. We want to add this new feature into OpenStack in this blueprint. And this need kernel and xen to support the CQM feature. So We will do some work in kernel, xen, libvirt, xenapi and OpenStack. When get one instance's' cache data, should via a RMID, but the total RMID numbers of different platforms are differents. So we want to add a RMID managerment in Nova. Problem description =================== The main use case is to monitor the cache of each intstance. The user can enable the CQM function in the Nova and get the instance's 'cache data from Ceilometer agent[3]. #TBD Proposed change =============== This blueprint dependencies on Paul Murray's blueprint[1]. Add a RMID resource plugin to manager the RMID resource. The RMID plugin record how many RMIDs are used and the total RMID numbers of host. The deployer should add a key (""resource:cpu_cqm"":True ) to extra_specs to mark if the instance need to use the CQM monitor, the RMID plugin will put the key to instance_system_metadata, when libvirt/xenapi creates the instance, it will start the instance's cache monitoring. if the instance is created successfully, the plugin will record one RMID was used. Also need a RMID filter to check if the host has RMID to the new instance, if not, will return 0. #TBD (more details about the libvirt module) Alternatives ------------ None Data model impact ----------------- The blueprint used the extra_resources field in the compute node table to communicate the resource tracking information. This field was added to the database in Icehouse-2 but has not yet been used. The extra_specs field will be added to the instances table in Paul Murray's blueprint[1]. REST API impact --------------- None Security impact --------------- None Notifications impact -------------------- None Other end user impact --------------------- None Performance Impact ------------------ None Other deployer impact --------------------- The plugins will be configured in the blueprint extensible-resource-tracking ways. Developer impact ---------------- None Implementation ============== Assignee(s) ----------- Primary assignee: shuangtai-tian qiaowei-ren Work Items ---------- * Add the RMID resource plugin to resource tracker * Add the RMID resource consumer plubin to the host manager * Add extra_specs (""resource:cpu_cqm"":True) to instance_system_metadata Dependencies ============ *This blueprint dependency on extensible-resource-tracking https://blueprints.launchpad.net/nova/+spec/extensible-resource-tracking *Also dependecy on the new version of kernel, xen, libvirt and xenapi. #TBD Testing ======= Unit tests are sufficient to cover feature changes. Documentation Impact ==================== None References ========== [1]https://blueprints.launchpad.net/nova/+spec/extensible-resource-tracking [2]https://blueprints.launchpad.net/nova/+spec/cache-qos-monitoring [3]https://blueprints.launchpad.net/ceilometer/+spec/cache-qos-monitoring ",,154,0
openstack%2Fnova-specs~master~I51377f21f7cd833688520a27e00493babe5a3c5e,openstack/nova-specs,master,I51377f21f7cd833688520a27e00493babe5a3c5e,Make Q35 machine type the default for x86,ABANDONED,2019-01-16 07:40:18.000000000,2020-12-01 10:32:58.000000000,,"[{'_account_id': 2394}, {'_account_id': 6873}, {'_account_id': 6962}, {'_account_id': 8768}, {'_account_id': 8864}, {'_account_id': 9708}, {'_account_id': 10135}, {'_account_id': 11347}, {'_account_id': 11604}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-01-16 07:40:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/eb04a642966b1ab21782a3dfe5be3a0c9b41094b', 'message': 'WIP: Gracefully handle QEMU machine types for guests\n\nBlueprint: handle-default-machine-type-as-q35\n\nChange-Id: I51377f21f7cd833688520a27e00493babe5a3c5e\nSigned-off-by: Kashyap Chamarthy <kchamart@redhat.com>\n'}, {'number': 2, 'created': '2019-01-30 19:13:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/dd01fd9bf64ff8b692d2090744c65c1a4c7fab95', 'message': ""WIP: Gracefully handle QEMU machine types for guests\n\nTODO: Rework some of the design in light of the following libvirt\nchange:\n\n    https://libvirt.org/git/?p=libvirt.git;a=commit;h=26cfb1a3cd\n    qemu: ensure default machine types don't change if QEMU changes\n\nI.e. libvirt (v4.10.0 onwards) ignores the QEMU's built-in default to\nnot break applications, if QEMU were to change its default.\n\nBlueprint: handle-default-machine-type-as-q35\n\nChange-Id: I51377f21f7cd833688520a27e00493babe5a3c5e\nSigned-off-by: Kashyap Chamarthy <kchamart@redhat.com>\n""}, {'number': 3, 'created': '2019-03-12 00:44:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/ceb307077783327ec022ab2505d3bf121e0df5d5', 'message': 'WIP: Gracefully handle QEMU machine types for guests\n\nTODO:\n\n  - Work out a sane default machine type policy for Nova.  Or should\n    that be done by orchestrators?\n\n  - Consider whether to use libosinfo.\n\n  - Consider allowing to configure machine types via flavor ""extra\n    specs""\n\n  - Rework some of the design in light of the following libvirt change:\n\n      https://libvirt.org/git/?p=libvirt.git;a=commit;h=26cfb1a3cd\n      qemu: ensure default machine types don\'t change if QEMU changes\n\nI.e. libvirt (v4.10.0 onwards) ignores the QEMU\'s built-in default to\nnot break applications, if QEMU were to change its default.\n\nBlueprint: handle-default-machine-type-as-q35\n\nChange-Id: I51377f21f7cd833688520a27e00493babe5a3c5e\nSigned-off-by: Kashyap Chamarthy <kchamart@redhat.com>\n'}, {'number': 4, 'created': '2019-03-14 17:37:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/33b70c09ea150fad46e78f2d68d7d8820351d5e2', 'message': 'WIP: Gracefully handle QEMU machine types for guests\n\nTODO:\n\n  - Work out a sane default machine type policy for Nova.  Or should\n    that be done by orchestrators?\n\n  - Consider whether to use libosinfo.\n\n  - Consider allowing to configure machine types via flavor ""extra\n    specs""\n\n  - Rework some of the design in light of the following libvirt change:\n\n      https://libvirt.org/git/?p=libvirt.git;a=commit;h=26cfb1a3cd\n      qemu: ensure default machine types don\'t change if QEMU changes\n\nI.e. libvirt (v4.10.0 onwards) ignores the QEMU\'s built-in default to\nnot break applications, if QEMU were to change its default.\n\nBlueprint: gracefully-handle-qemu-machine-types\n\nChange-Id: I51377f21f7cd833688520a27e00493babe5a3c5e\nSigned-off-by: Kashyap Chamarthy <kchamart@redhat.com>\n'}, {'number': 5, 'created': '2020-04-22 12:05:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/c68d25c14c0d47f35fdaa03efbbf7eae8245ba25', 'message': 'Make Q35 machine type the default for x86\n\nThis spec proposes to change the default from the legacy `pc` to `q35`\nas the default machine type.\n\nQEMU supports two main variants of ""machine type"" (think of it as a\nvirtual chipset) for x86 hosts: (a) \'pc\', which corresponds to Intel\'s\n\'i440FX\' chipset; and (b) \'q35\', which corresponds to Intel\'s 82Q35\nchipset. (For AArch64 hosts, the machine type is called: \'virt\').\n\nThe \'q35\' machine type provides some advanced features by default:\nnative PCIe hotplug (which is faster than ACPI-based hotplug, which\nolder \'pc\' machine type uses), Intel IOMMU, faster SATA emulation,\nSecure Boot, and so forth.\n\nThe \'pc\' machine type may not get any future updates, besides critical\nsecurity fixes, and is most likely to be deprecated.  Hence it is\nimportant that Nova switches the default to \'q35\'.\n\nBlueprint: gracefully-handle-qemu-machine-types\n\nChange-Id: I51377f21f7cd833688520a27e00493babe5a3c5e\nSigned-off-by: Kashyap Chamarthy <kchamart@redhat.com>\n'}, {'number': 6, 'created': '2020-04-23 17:30:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/a75ff679193e565947ef2572b70c7d75b16fdb58', 'message': 'Make Q35 machine type the default for x86\n\nThis spec proposes to change the default from the legacy `pc` to `q35`\nas the default machine type.\n\nQEMU supports two main variants of ""machine type"" (think of it as a\nvirtual chipset) for x86 hosts: (a) \'pc\', which corresponds to Intel\'s\n\'i440FX\' chipset; and (b) \'q35\', which corresponds to Intel\'s 82Q35\nchipset. (For AArch64 hosts, the machine type is called: \'virt\').\n\nThe \'q35\' machine type provides some advanced features by default:\nnative PCIe hotplug (which is faster than ACPI-based hotplug, which\nolder \'pc\' machine type uses), Intel IOMMU, faster SATA emulation,\nSecure Boot, and so forth.\n\nThe \'pc\' machine type may not get any future updates, besides critical\nsecurity fixes, and is most likely to be deprecated.  Hence it is\nimportant that Nova switches the default to \'q35\'.\n\nBlueprint: qemu-q35-machine-type-as-default-for-x86\n\nChange-Id: I51377f21f7cd833688520a27e00493babe5a3c5e\nSigned-off-by: Kashyap Chamarthy <kchamart@redhat.com>\n'}, {'number': 7, 'created': '2020-04-24 11:35:49.000000000', 'files': ['specs/victoria/approved/q35_qemu_machine_type_as_the_default.rst'], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/02fb2b687eb90c06206dabd7ca76d1ba62064926', 'message': 'Make Q35 machine type the default for x86\n\nThis spec proposes to change the default from the legacy `pc` to `q35`\nas the default machine type.\n\nQEMU supports two main variants of ""machine type"" (think of it as a\nvirtual chipset) for x86 hosts: (a) \'pc\', which corresponds to Intel\'s\n\'i440FX\' chipset; and (b) \'q35\', which corresponds to Intel\'s 82Q35\nchipset. (For AArch64 hosts, the machine type is called: \'virt\').\n\nThe \'q35\' machine type provides some advanced features by default:\nnative PCIe hotplug (which is faster than ACPI-based hotplug, which\nolder \'pc\' machine type uses), Intel IOMMU, faster SATA emulation,\nSecure Boot, and so forth.\n\nThe \'pc\' machine type may not get any future updates, besides critical\nsecurity fixes, and is most likely to be deprecated.  Hence it is\nimportant that Nova switches the default to \'q35\'.\n\nBlueprint: qemu-q35-machine-type-as-default-for-x86\n\nChange-Id: I51377f21f7cd833688520a27e00493babe5a3c5e\nSigned-off-by: Kashyap Chamarthy <kchamart@redhat.com>\n'}]",164,631154,02fb2b687eb90c06206dabd7ca76d1ba62064926,63,10,7,6962,,,0,"Make Q35 machine type the default for x86

This spec proposes to change the default from the legacy `pc` to `q35`
as the default machine type.

QEMU supports two main variants of ""machine type"" (think of it as a
virtual chipset) for x86 hosts: (a) 'pc', which corresponds to Intel's
'i440FX' chipset; and (b) 'q35', which corresponds to Intel's 82Q35
chipset. (For AArch64 hosts, the machine type is called: 'virt').

The 'q35' machine type provides some advanced features by default:
native PCIe hotplug (which is faster than ACPI-based hotplug, which
older 'pc' machine type uses), Intel IOMMU, faster SATA emulation,
Secure Boot, and so forth.

The 'pc' machine type may not get any future updates, besides critical
security fixes, and is most likely to be deprecated.  Hence it is
important that Nova switches the default to 'q35'.

Blueprint: qemu-q35-machine-type-as-default-for-x86

Change-Id: I51377f21f7cd833688520a27e00493babe5a3c5e
Signed-off-by: Kashyap Chamarthy <kchamart@redhat.com>
",git fetch https://review.opendev.org/openstack/nova-specs refs/changes/54/631154/4 && git format-patch -1 --stdout FETCH_HEAD,['specs/stein/approved/gracefully-handle-qemu-machine-types.rst'],1,eb04a642966b1ab21782a3dfe5be3a0c9b41094b,gracefully_handle_machine_types,".. This work is licensed under a Creative Commons Attribution 3.0 Unported License. http://creativecommons.org/licenses/by/3.0/legalcode ========================================== Example Spec - The title of your blueprint ========================================== Include the URL of your launchpad blueprint: https://blueprints.launchpad.net/nova/+spec/handle-default-machine-type-as-q35 Background ========== QEMU supports two main variants of ""machine type"" (the virtual chipset) for x86 hosts: (a) 'pc', which corresponds to Intel's 'I440FX' chipset, which is 22 years old as of this writing; and (b) 'q35', which corresponds to Intel's 82Q35 chipset (a relatively modern chipset, released in 2007). For AArch64 hosts, the machine type is called: 'virt'. This spec aims to rework Nova's libvirt driver to use 'q35' machine type, that enables a few advanced features, based on certain criteria. Problem description =================== The Intel 'I440FX' (or ""pc"") machine type is legacy, and doesn't really support some of the modern features (refer the Use And upstream QEMU is considering to stop adding new variants of the legacy 'pc' machine type. Use Cases --------- The Q35 machine type brings several advantages: - Native PCIe hotplug, which is more effective / ""cleaner"" than the ACPI-based hotplug that is used by the legacy 'pc' machine type. - vIOMMU emulation. This has a few use cases[2]_, namely: (a) protecting the guest memory from untrusted devices that are directly assigned to the guest; (b) protecting guests from untrusted user space drivers (e.g. DPDK); (c) assigning devices to nested virtual guests. - Faster SATA emulation  in comparison to the IDE emulation that the legacy 'pc' machine type uses. Note that this is useful only when a guest OS doesn't support 'virtio' devices (which is what any modern guest should be using, and this is what Nova configures). - Q35 machine type makes Secure Boot (in combination with OVMF, the project that enables UEFI support for QEMU / KVM guests) _actually_ secure. The low-level explanation, this is because a malicious guest kernel might attempt to tamper with the emulated 'pflash' chip (which stores Secure Boot related persistent UEFI variables) directly, skipping the UEFI runtime variable service altogether. In order to prevent this, QEMU and KVM emulate SMM (System Management Mode), and restrict 'pflash' hardware access to code that runs in SMM. And SSM emulation is in QEMU/KVM is only provided by 'q35'; 'i440fx' does not have the necessary (virtual) hardware. (Thanks to Laszlo Ersek, OVMF maintainer, for this explanation.) Proposed change =============== Given that certain Linux distributions might change the default machine type to 'q35' (and not to mention the legacy 'pc' machine type is most likely to not get any Regardless of upstream QEMU's plans, Nova should be prepared to not break when that happens. (Refer the ""What will break?"" section below.) (1) Use the Nova metadata property: 'hw_machine_type' to set the machine type on the guest. (2) Ask 'libosinfo', and pick q35 if it says guest can do both 'pc' or 'q35'. (3) Or Operators can just use 'q35' (this shouldn't need code changes, propose to solve this problem? If this is one part of a larger effort make it clear where this piece ends. In other words, what's the scope of this effort? At this point, if you would like to just get feedback on if the problem and proposed change fit in nova, you can stop here and post this for review to get preliminary feedback. If so please say: Posting to get preliminary feedback on the scope of this spec. Alternatives ------------ None Data model impact ----------------- None REST API impact --------------- None Security impact --------------- FIXME: Since Q35 indirectly enables Secure Boot, wonder if that should be mentioned here. My guess: ""no"" -- because, the change itself isn't introducing any security-sensitive code. Notifications impact -------------------- None Other end user impact --------------------- FIXME: Talk about guests Performance Impact ------------------ FIXME: Other deployer impact --------------------- FIXME: Consider where to mention this: Any Linux distribution that was released earlier than 2007 should use 'i440fx' (or 'pc') machine type, and those released in 2007 (the year when Intel introduced the Q35 chipset) or newer should use 'q35' Developer impact ---------------- Discuss things that will affect other developers working on OpenStack, such as: * If the blueprint proposes a change to the driver API, discussion of how other hypervisors would implement the feature is required. Upgrade impact -------------- FIXME: [...] Implementation ============== Assignee(s) ----------- Primary assignee: kashyapc Work Items ---------- * Work items or tasks -- break the feature up into the things that need to be done to implement it. Those parts might end up being done by different people, but we're mostly trying to understand the timeline for implementation. Dependencies ============ * The 'libosinfo' project should add * Include specific references to specs and/or blueprints in nova, or in other projects, that this one either depends on or is related to. * Does this feature require any new library dependencies or code otherwise not included in OpenStack? Or does it depend on a specific version of library? Testing ======= FIXME - Migration needs to be tested Please discuss the important scenarios needed to test here, as well as specific edge cases we should be ensuring work correctly. For each scenario please specify if this requires specialized hardware, a full openstack environment, or can be simulated inside the Nova tree. Please discuss how the change will be tested. We especially want to know what tempest tests will be added. It is assumed that unit test coverage will be added so that doesn't need to be mentioned explicitly, but discussion of why you think unit tests are sufficient and we don't need to add more tempest tests would need to be included. Is this untestable in gate given current limitations (specific hardware / software configurations available)? If so, are there mitigation plans (3rd party testing, gate enhancements, etc). Documentation Impact ==================== Which audiences are affected most by this change, and which documentation titles on docs.openstack.org should be updated because of this change? Don't repeat details discussed above, but reference them here in the context of documentation for multiple audiences. For example, the Operations Guide targets cloud operators, and the End User Guide would need to be updated if the change offers a new feature available through the CLI or dashboard. If a config option changes or is deprecated, note here that the documentation needs to be updated to reflect this specification's change. References ========== Please add any useful references here. You are not required to have any reference. Moreover, this specification should still make sense when your references are unavailable. Examples of what you could include are: [1] An overview of Q35 machine type: https://wiki.qemu.org/images/4/4e/Q35.pdf [*] Emumlated Q35 config: https://git.qemu.org/?p=qemu.git;a=blob;f=docs/config/q35-emulated.cfg [*] libosinfo: https://bugzilla.redhat.com/show_bug.cgi?id=1623501 (RFE: provide machine-type information) * Links to relevant research, if appropriate History ======= Optional section intended to be used each time the spec is updated to describe new design, API or any database schema updated. Useful to let reader understand what's happened along the time. .. list-table:: Revisions :header-rows: 1 * - Release Name - Description * - Stein - Introduced ",,256,0
openstack%2Fneutron-lib~master~Ib9878042dc01654fd880d497e46e1a9b277c9710,openstack/neutron-lib,master,Ib9878042dc01654fd880d497e46e1a9b277c9710,"Remove ""autonested_transaction"" method",MERGED,2020-11-06 11:36:11.000000000,2020-12-01 10:30:22.000000000,2020-12-01 10:28:54.000000000,"[{'_account_id': 5948}, {'_account_id': 11975}, {'_account_id': 16688}, {'_account_id': 22348}]","[{'number': 1, 'created': '2020-11-06 11:36:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-lib/commit/9097628ecca92d4141d6e84c7c493fd6a58d7fd0', 'message': 'Remove ""autonested_transaction"" method\n\nWith the new engine facade, a new reader or writer python context can\nbe created using the passed session context.\n\nPartially-Implements blueprint: enginefacade-switch\n\nChange-Id: Ib9878042dc01654fd880d497e46e1a9b277c9710\n'}, {'number': 2, 'created': '2020-11-30 14:23:01.000000000', 'files': ['neutron_lib/db/api.py'], 'web_link': 'https://opendev.org/openstack/neutron-lib/commit/d80dc7f54a92cceb24201e061be2ef80c4ab4266', 'message': 'Remove ""autonested_transaction"" method\n\nWith the new engine facade, a new reader or writer python context can\nbe created using the passed session context.\n\nPartially-Implements blueprint: enginefacade-switch\n\nChange-Id: Ib9878042dc01654fd880d497e46e1a9b277c9710\n'}]",1,761728,d80dc7f54a92cceb24201e061be2ef80c4ab4266,12,4,2,16688,,,0,"Remove ""autonested_transaction"" method

With the new engine facade, a new reader or writer python context can
be created using the passed session context.

Partially-Implements blueprint: enginefacade-switch

Change-Id: Ib9878042dc01654fd880d497e46e1a9b277c9710
",git fetch https://review.opendev.org/openstack/neutron-lib refs/changes/28/761728/1 && git format-patch -1 --stdout FETCH_HEAD,['neutron_lib/db/api.py'],1,9097628ecca92d4141d6e84c7c493fd6a58d7fd0,bp/enginefacade-switch,,"@contextlib.contextmanager def autonested_transaction(sess): """"""This is a convenience context to not bother with 'nested' parameter. :param sess: The database session. :returns: Yields the context transaction from sess. """""" if sess.is_active: session_context = sess.begin(nested=True) else: session_context = sess.begin(subtransactions=True) with session_context as tx: yield tx ",0,15
openstack%2Fopenstack-ansible-os_zun~master~I7d5a7ed74fe116cbcdb703a14c374c77cff75926,openstack/openstack-ansible-os_zun,master,I7d5a7ed74fe116cbcdb703a14c374c77cff75926,Fix linter errors,ABANDONED,2020-10-29 09:08:24.000000000,2020-12-01 10:04:09.000000000,,"[{'_account_id': 22348}, {'_account_id': 31542}]","[{'number': 1, 'created': '2020-10-29 09:08:24.000000000', 'files': ['tasks/zun_post_install.yml'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_zun/commit/879aa994767ecd8d9b3b2056a17734383c7ff46c', 'message': 'Fix linter errors\n\nChange-Id: I7d5a7ed74fe116cbcdb703a14c374c77cff75926\n'}]",0,760304,879aa994767ecd8d9b3b2056a17734383c7ff46c,5,2,1,31542,,,0,"Fix linter errors

Change-Id: I7d5a7ed74fe116cbcdb703a14c374c77cff75926
",git fetch https://review.opendev.org/openstack/openstack-ansible-os_zun refs/changes/04/760304/1 && git format-patch -1 --stdout FETCH_HEAD,['tasks/zun_post_install.yml'],1,879aa994767ecd8d9b3b2056a17734383c7ff46c,osa-linters-update," docker version -f ""{{ .Client.APIVersion }}"""," docker version -f ""{{.Client.APIVersion }}""",1,1
openstack%2Fkolla~master~I0743faacad8fe26d7d7992da8abb3d8b4af3a198,openstack/kolla,master,I0743faacad8fe26d7d7992da8abb3d8b4af3a198,Remove the unused coding style modules,ABANDONED,2020-10-22 06:30:34.000000000,2020-12-01 09:51:47.000000000,,"[{'_account_id': 22348}, {'_account_id': 26285}, {'_account_id': 30491}]","[{'number': 1, 'created': '2020-10-22 06:30:34.000000000', 'files': ['lower-constraints.txt'], 'web_link': 'https://opendev.org/openstack/kolla/commit/a3f0ff5b29770e50ec63506eaa231a58b7be19ce', 'message': 'Remove the unused coding style modules\n\nPython modules related to coding style checks (listed in blacklist.txt in\nopenstack/requirements repo) are dropped from lower-constraints.txt\nthey are not needed during installation.\ntrivial fix\n\nChange-Id: I0743faacad8fe26d7d7992da8abb3d8b4af3a198\n'}]",0,759189,a3f0ff5b29770e50ec63506eaa231a58b7be19ce,5,3,1,26285,,,0,"Remove the unused coding style modules

Python modules related to coding style checks (listed in blacklist.txt in
openstack/requirements repo) are dropped from lower-constraints.txt
they are not needed during installation.
trivial fix

Change-Id: I0743faacad8fe26d7d7992da8abb3d8b4af3a198
",git fetch https://review.opendev.org/openstack/kolla refs/changes/89/759189/1 && git format-patch -1 --stdout FETCH_HEAD,['lower-constraints.txt'],1,a3f0ff5b29770e50ec63506eaa231a58b7be19ce,,,mccabe==0.2.1,0,1
openstack%2Fdevstack~master~I1feed4573820436f91f8f654cc189fa3a21956fd,openstack/devstack,master,I1feed4573820436f91f8f654cc189fa3a21956fd,Workaround for new pip 20.3 behavior,MERGED,2020-11-30 17:34:44.000000000,2020-12-01 09:27:23.000000000,2020-12-01 09:23:38.000000000,"[{'_account_id': 8556}, {'_account_id': 22348}, {'_account_id': 30491}]","[{'number': 1, 'created': '2020-11-30 17:34:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack/commit/f7cab562bcb33b2162d7661805ffcbef99d31a24', 'message': 'WIP: Workaround for new pip 20.3 behavior\n\nThis patch caps pip version during bootstrap to avoid the issue:\n\n""ERROR: Links are not allowed as constraints""\n\nA proper fix would be to adapt to new pip behavior.\n\nChange-Id: I1feed4573820436f91f8f654cc189fa3a21956fd\n'}, {'number': 2, 'created': '2020-11-30 18:08:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack/commit/9860382273f6c8e81f3206faacceee4d373c0bd9', 'message': 'WIP: Workaround for new pip 20.3 behavior\n\nThis patch caps pip version during bootstrap to avoid the issue:\n\n""ERROR: Links are not allowed as constraints""\n\nA proper fix would be to adapt to new pip behavior.\n\nDepends-On: https://review.opendev.org/764811\nChange-Id: I1feed4573820436f91f8f654cc189fa3a21956fd\n'}, {'number': 3, 'created': '2020-11-30 22:48:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack/commit/3ad2e04fee8d9d61bba54468579bd63d8ecf8e60', 'message': 'WIP: Workaround for new pip 20.3 behavior\n\nThis patch caps pip version during bootstrap to avoid the issue:\n\n""ERROR: Links are not allowed as constraints""\n\nA proper fix would be to adapt to new pip behavior.\n\nDepends-On: https://review.opendev.org/764811\nChange-Id: I1feed4573820436f91f8f654cc189fa3a21956fd\n'}, {'number': 4, 'created': '2020-11-30 22:48:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack/commit/62b50ddf1be0c4ba0a75948cf2987ba64ed327b5', 'message': 'Workaround for new pip 20.3 behavior\n\nThis patch caps pip version during bootstrap to avoid the issue:\n\n""ERROR: Links are not allowed as constraints""\n\nA proper fix would be to adapt to new pip behavior.\n\nDepends-On: https://review.opendev.org/764811\nChange-Id: I1feed4573820436f91f8f654cc189fa3a21956fd\n'}, {'number': 5, 'created': '2020-11-30 23:01:23.000000000', 'files': ['tools/install_pip.sh', 'tools/cap-pip.txt'], 'web_link': 'https://opendev.org/openstack/devstack/commit/7a3a7ce876a37376fe0dca7278e41a4f46867daa', 'message': 'Workaround for new pip 20.3 behavior\n\nThis patch caps pip version during bootstrap to avoid the issue:\n\n""ERROR: Links are not allowed as constraints""\n\nA proper fix would be to adapt to new pip behavior.\n\nDepends-On: https://review.opendev.org/764811\nChange-Id: I1feed4573820436f91f8f654cc189fa3a21956fd\n'}]",0,764803,7a3a7ce876a37376fe0dca7278e41a4f46867daa,18,3,5,17685,,,0,"Workaround for new pip 20.3 behavior

This patch caps pip version during bootstrap to avoid the issue:

""ERROR: Links are not allowed as constraints""

A proper fix would be to adapt to new pip behavior.

Depends-On: https://review.opendev.org/764811
Change-Id: I1feed4573820436f91f8f654cc189fa3a21956fd
",git fetch https://review.opendev.org/openstack/devstack refs/changes/03/764803/3 && git format-patch -1 --stdout FETCH_HEAD,['tools/install_pip.sh'],1,f7cab562bcb33b2162d7661805ffcbef99d31a24,cap-pip-23-0, # TODO: remove the trailing pip constraint when a proper fix # arrives for issue: # ERROR: Links are not allowed as constraints sudo -H -E python${PYTHON3_VERSION} $LOCAL_PIP 'pip<20.3', sudo -H -E python${PYTHON3_VERSION} $LOCAL_PIP,4,1
openstack%2Fdevstack~stable%2Fussuri~I1feed4573820436f91f8f654cc189fa3a21956fd,openstack/devstack,stable/ussuri,I1feed4573820436f91f8f654cc189fa3a21956fd,Workaround for new pip 20.3 behavior,MERGED,2020-11-30 22:50:14.000000000,2020-12-01 09:27:04.000000000,2020-12-01 09:22:37.000000000,"[{'_account_id': 8556}, {'_account_id': 13734}, {'_account_id': 17685}, {'_account_id': 22348}, {'_account_id': 30491}]","[{'number': 1, 'created': '2020-11-30 22:50:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack/commit/1bc0ce953d962d9055bccfbead811a57c9ba82a4', 'message': 'Workaround for new pip 20.3 behavior\n\nThis patch caps pip version during bootstrap to avoid the issue:\n\n""ERROR: Links are not allowed as constraints""\n\nA proper fix would be to adapt to new pip behavior.\n\nDepends-On: https://review.opendev.org/764811\nChange-Id: I1feed4573820436f91f8f654cc189fa3a21956fd\n'}, {'number': 2, 'created': '2020-11-30 22:53:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack/commit/dee5c96b42404d971f073657c071c504bf8ce84c', 'message': 'Workaround for new pip 20.3 behavior\n\nThis patch caps pip version during bootstrap to avoid the issue:\n\n""ERROR: Links are not allowed as constraints""\n\nA proper fix would be to adapt to new pip behavior.\n\nDepends-On: https://review.opendev.org/764811\nChange-Id: I1feed4573820436f91f8f654cc189fa3a21956fd\n'}, {'number': 3, 'created': '2020-11-30 23:02:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack/commit/46f8fd97d85b714a06a816f8c6e73476fb6d8150', 'message': 'Workaround for new pip 20.3 behavior\n\nThis patch caps pip version during bootstrap to avoid the issue:\n\n""ERROR: Links are not allowed as constraints""\n\nA proper fix would be to adapt to new pip behavior.\n\nDepends-On: https://review.opendev.org/764811\nChange-Id: I1feed4573820436f91f8f654cc189fa3a21956fd\n'}, {'number': 4, 'created': '2020-11-30 23:03:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack/commit/d3366634104e9ebe116399116fe5868420c99b6f', 'message': 'Workaround for new pip 20.3 behavior\n\nThis patch caps pip version during bootstrap to avoid the issue:\n\n""ERROR: Links are not allowed as constraints""\n\nA proper fix would be to adapt to new pip behavior.\n\nDepends-On: https://review.opendev.org/764811\nChange-Id: I1feed4573820436f91f8f654cc189fa3a21956fd\n'}, {'number': 5, 'created': '2020-11-30 23:06:15.000000000', 'files': ['tools/install_pip.sh', 'tools/cap-pip.txt'], 'web_link': 'https://opendev.org/openstack/devstack/commit/83f29bdd42ab06f6f16b5205ca4cbb3e482ef25b', 'message': 'Workaround for new pip 20.3 behavior\n\nThis patch caps pip version during bootstrap to avoid the issue:\n\n""ERROR: Links are not allowed as constraints""\n\nA proper fix would be to adapt to new pip behavior.\n\n\nChange-Id: I1feed4573820436f91f8f654cc189fa3a21956fd\n'}]",0,764876,83f29bdd42ab06f6f16b5205ca4cbb3e482ef25b,16,5,5,8556,,,0,"Workaround for new pip 20.3 behavior

This patch caps pip version during bootstrap to avoid the issue:

""ERROR: Links are not allowed as constraints""

A proper fix would be to adapt to new pip behavior.


Change-Id: I1feed4573820436f91f8f654cc189fa3a21956fd
",git fetch https://review.opendev.org/openstack/devstack refs/changes/76/764876/1 && git format-patch -1 --stdout FETCH_HEAD,['tools/install_pip.sh'],1,1bc0ce953d962d9055bccfbead811a57c9ba82a4,cap-pip-23-0,"<<<<<<< HEAD (46acea Merge ""Fix is_fedora RHEL 8 detection"" into stable/ussuri)======= # TODO: remove the trailing pip constraint when a proper fix # arrives for bug https://bugs.launchpad.net/devstack/+bug/1906322 sudo -H -E python${PYTHON3_VERSION} $LOCAL_PIP 'pip<20.3' >>>>>>> CHANGE (a94a3c Workaround for new pip 20.3 behavior)",,6,0
openstack%2Fdevstack~stable%2Fvictoria~I1feed4573820436f91f8f654cc189fa3a21956fd,openstack/devstack,stable/victoria,I1feed4573820436f91f8f654cc189fa3a21956fd,Workaround for new pip 20.3 behavior,MERGED,2020-11-30 18:06:54.000000000,2020-12-01 09:26:01.000000000,2020-12-01 09:23:17.000000000,"[{'_account_id': 8556}, {'_account_id': 22348}, {'_account_id': 28006}, {'_account_id': 30491}]","[{'number': 1, 'created': '2020-11-30 18:06:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack/commit/26416d59f08042993214f9e6050723c78fa32a7b', 'message': 'WIP: Workaround for new pip 20.3 behavior\n\nThis patch caps pip version during bootstrap to avoid the issue:\n\n""ERROR: Links are not allowed as constraints""\n\nA proper fix would be to adapt to new pip behavior.\n\nChange-Id: I1feed4573820436f91f8f654cc189fa3a21956fd\n(cherry picked from commit f7cab562bcb33b2162d7661805ffcbef99d31a24)\n'}, {'number': 2, 'created': '2020-11-30 22:49:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack/commit/a94a3c50ecbb400909066e330316f04d5ff1b4b6', 'message': 'Workaround for new pip 20.3 behavior\n\nThis patch caps pip version during bootstrap to avoid the issue:\n\n""ERROR: Links are not allowed as constraints""\n\nA proper fix would be to adapt to new pip behavior.\n\nDepends-On: https://review.opendev.org/764811\nChange-Id: I1feed4573820436f91f8f654cc189fa3a21956fd\n'}, {'number': 3, 'created': '2020-11-30 23:02:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack/commit/e852d5cefcd5176d38fe01bf347916f56921a784', 'message': 'Workaround for new pip 20.3 behavior\n\nThis patch caps pip version during bootstrap to avoid the issue:\n\n""ERROR: Links are not allowed as constraints""\n\nA proper fix would be to adapt to new pip behavior.\n\nDepends-On: https://review.opendev.org/764811\nChange-Id: I1feed4573820436f91f8f654cc189fa3a21956fd\n'}, {'number': 4, 'created': '2020-11-30 23:06:52.000000000', 'files': ['tools/install_pip.sh', 'tools/cap-pip.txt'], 'web_link': 'https://opendev.org/openstack/devstack/commit/7a0e578d19d269cfab15a6fe80b4717c0318e76e', 'message': 'Workaround for new pip 20.3 behavior\n\nThis patch caps pip version during bootstrap to avoid the issue:\n\n""ERROR: Links are not allowed as constraints""\n\nA proper fix would be to adapt to new pip behavior.\n\nDepends-On: https://review.opendev.org/c/openstack/devstack/+/764876\nChange-Id: I1feed4573820436f91f8f654cc189fa3a21956fd\n'}]",0,764811,7a0e578d19d269cfab15a6fe80b4717c0318e76e,55,4,4,17685,,,0,"Workaround for new pip 20.3 behavior

This patch caps pip version during bootstrap to avoid the issue:

""ERROR: Links are not allowed as constraints""

A proper fix would be to adapt to new pip behavior.

Depends-On: https://review.opendev.org/c/openstack/devstack/+/764876
Change-Id: I1feed4573820436f91f8f654cc189fa3a21956fd
",git fetch https://review.opendev.org/openstack/devstack refs/changes/11/764811/4 && git format-patch -1 --stdout FETCH_HEAD,['tools/install_pip.sh'],1,26416d59f08042993214f9e6050723c78fa32a7b,cap-pip-23-0, # TODO: remove the trailing pip constraint when a proper fix # arrives for issue: # ERROR: Links are not allowed as constraints sudo -H -E python${PYTHON3_VERSION} $LOCAL_PIP 'pip<20.3', sudo -H -E python${PYTHON3_VERSION} $LOCAL_PIP,4,1
openstack%2Frpm-packaging~master~I426496c37d74dedced5e8c43b75a9e7535754af4,openstack/rpm-packaging,master,I426496c37d74dedced5e8c43b75a9e7535754af4,update tooz to 2.8.0,MERGED,2020-12-01 01:30:44.000000000,2020-12-01 09:24:36.000000000,2020-12-01 09:24:36.000000000,"[{'_account_id': 6593}, {'_account_id': 13294}, {'_account_id': 19648}, {'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2020-12-01 01:30:44.000000000', 'files': ['openstack/tooz/tooz.spec.j2'], 'web_link': 'https://opendev.org/openstack/rpm-packaging/commit/9e44d1e6d0053f45b732293cadd313eb7137f471', 'message': 'update tooz to 2.8.0\n\nChange-Id: I426496c37d74dedced5e8c43b75a9e7535754af4\n'}]",0,764866,9e44d1e6d0053f45b732293cadd313eb7137f471,9,5,1,30533,,,0,"update tooz to 2.8.0

Change-Id: I426496c37d74dedced5e8c43b75a9e7535754af4
",git fetch https://review.opendev.org/openstack/rpm-packaging refs/changes/66/764866/1 && git format-patch -1 --stdout FETCH_HEAD,['openstack/tooz/tooz.spec.j2'],1,9e44d1e6d0053f45b732293cadd313eb7137f471,bug/tooz,{% set upstream_version = upstream_version('2.8.0') %},{% set upstream_version = upstream_version('2.7.1') %},1,1
openstack%2Fnetworking-odl~master~I27b1c0fadb84e880b7f888f12bc458e5845e174e,openstack/networking-odl,master,I27b1c0fadb84e880b7f888f12bc458e5845e174e,Update TOX_CONSTRAINTS_FILE,MERGED,2020-11-18 03:47:06.000000000,2020-12-01 09:19:42.000000000,2020-12-01 09:18:08.000000000,"[{'_account_id': 8313}, {'_account_id': 11975}, {'_account_id': 22348}]","[{'number': 1, 'created': '2020-11-18 03:47:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/networking-odl/commit/81fdd123cfa0bb88396bec6d008f7e3a253f9cf2', 'message': 'Update TOX_CONSTRAINTS_FILE\n\nUPPER_CONSTRAINTS_FILE is old name and deprecated\n-https://zuul-ci.org/docs/zuul-jobs/python-roles.html#rolevar-tox.tox_constraints_file\nThis allows to use lower-constraints file as more\nreadable way instead of UPPER_CONSTRAINTS_FILE=<lower-constraints file>.\n\nChange-Id: I27b1c0fadb84e880b7f888f12bc458e5845e174e\n'}, {'number': 2, 'created': '2020-11-25 01:45:05.000000000', 'files': ['tox.ini'], 'web_link': 'https://opendev.org/openstack/networking-odl/commit/7e65409f774102a372fc08f7c4b197eab867dfd3', 'message': 'Update TOX_CONSTRAINTS_FILE\n\nUPPER_CONSTRAINTS_FILE is old name and deprecated\n-https://zuul-ci.org/docs/zuul-jobs/python-roles.html#rolevar-tox.tox_constraints_file\nThis allows to use lower-constraints file as more\nreadable way instead of UPPER_CONSTRAINTS_FILE=<lower-constraints file>.\n\nChange-Id: I27b1c0fadb84e880b7f888f12bc458e5845e174e\n'}]",2,763123,7e65409f774102a372fc08f7c4b197eab867dfd3,17,3,2,32291,,,0,"Update TOX_CONSTRAINTS_FILE

UPPER_CONSTRAINTS_FILE is old name and deprecated
-https://zuul-ci.org/docs/zuul-jobs/python-roles.html#rolevar-tox.tox_constraints_file
This allows to use lower-constraints file as more
readable way instead of UPPER_CONSTRAINTS_FILE=<lower-constraints file>.

Change-Id: I27b1c0fadb84e880b7f888f12bc458e5845e174e
",git fetch https://review.opendev.org/openstack/networking-odl refs/changes/23/763123/2 && git format-patch -1 --stdout FETCH_HEAD,['tox.ini'],1,81fdd123cfa0bb88396bec6d008f7e3a253f9cf2,,deps = -c{env:TOX_CONSTRAINTS_FILE:https://releases.openstack.org/constraints/upper/master}deps = -c{env:TOX_CONSTRAINTS_FILE:https://releases.openstack.org/constraints/upper/master} -c{env:TOX_CONSTRAINTS_FILE:https://releases.openstack.org/constraints/upper/master} -c{env:TOX_CONSTRAINTS_FILE:https://releases.openstack.org/constraints/upper/master},deps = -c{env:UPPER_CONSTRAINTS_FILE:https://releases.openstack.org/constraints/upper/master}deps = -c{env:UPPER_CONSTRAINTS_FILE:https://releases.openstack.org/constraints/upper/master} -c{env:UPPER_CONSTRAINTS_FILE:https://releases.openstack.org/constraints/upper/master} -c{env:UPPER_CONSTRAINTS_FILE:https://releases.openstack.org/constraints/upper/master},4,4
openstack%2Fneutron-vpnaas-dashboard~stable%2Fvictoria~I3fa1a37c248566b2fc8c8b0753d60b21b9e952f9,openstack/neutron-vpnaas-dashboard,stable/victoria,I3fa1a37c248566b2fc8c8b0753d60b21b9e952f9,Imported Translations from Zanata,MERGED,2020-11-02 08:19:02.000000000,2020-12-01 09:19:23.000000000,2020-12-01 09:18:11.000000000,"[{'_account_id': 11975}, {'_account_id': 22348}]","[{'number': 1, 'created': '2020-11-02 08:19:02.000000000', 'files': ['neutron_vpnaas_dashboard/locale/en_GB/LC_MESSAGES/django.po'], 'web_link': 'https://opendev.org/openstack/neutron-vpnaas-dashboard/commit/cfdd5659df792fb75aa21dddc7e970ed1c5e6675', 'message': 'Imported Translations from Zanata\n\nFor more information about this automatic import see:\nhttps://docs.openstack.org/i18n/latest/reviewing-translation-import.html\n\nChange-Id: I3fa1a37c248566b2fc8c8b0753d60b21b9e952f9\n'}]",0,760787,cfdd5659df792fb75aa21dddc7e970ed1c5e6675,7,2,1,11131,,,0,"Imported Translations from Zanata

For more information about this automatic import see:
https://docs.openstack.org/i18n/latest/reviewing-translation-import.html

Change-Id: I3fa1a37c248566b2fc8c8b0753d60b21b9e952f9
",git fetch https://review.opendev.org/openstack/neutron-vpnaas-dashboard refs/changes/87/760787/1 && git format-patch -1 --stdout FETCH_HEAD,['neutron_vpnaas_dashboard/locale/en_GB/LC_MESSAGES/django.po'],1,cfdd5659df792fb75aa21dddc7e970ed1c5e6675,zanata/translations,"# Andi Chandler <andi@gowling.com>, 2020. #zanata""POT-Creation-Date: 2020-10-14 12:56+0000\n""""PO-Revision-Date: 2020-11-02 02:59+0000\n""msgid ""Phase 1 negotiation mode limited to using 'main' and 'aggressive'."" msgstr ""Phase 1 negotiation mode limited to using 'main' and 'aggressive'."" msgid ""Unable to delete IKE policy."" msgstr ""Unable to delete IKE policy."" msgid ""Unable to delete IPsec policy."" msgstr ""Unable to delete IPsec policy."" msgid ""Unable to delete IPsec site connection."" msgstr ""Unable to delete IPsec site connection."" msgid ""Unable to delete VPN service."" msgstr ""Unable to delete VPN service."" msgid ""Unable to delete endpoint group."" msgstr ""Unable to delete endpoint group."" ","""POT-Creation-Date: 2020-09-04 01:59+0000\n""""PO-Revision-Date: 2019-01-15 12:23+0000\n""",21,2
openstack%2Foctavia~master~I5340eda9378b9df410f5f2ea0f9c3e8fc4d672be,openstack/octavia,master,I5340eda9378b9df410f5f2ea0f9c3e8fc4d672be,Support to create amphora with customized metadata,NEW,2019-10-24 11:24:57.000000000,2020-12-01 09:08:43.000000000,,"[{'_account_id': 6469}, {'_account_id': 7249}, {'_account_id': 10273}, {'_account_id': 11628}, {'_account_id': 22348}, {'_account_id': 22623}, {'_account_id': 28691}, {'_account_id': 28910}]","[{'number': 1, 'created': '2019-10-24 11:24:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/octavia/commit/e16ad4c379c52e4346c2d7439743552507e6f0b7', 'message': 'Support to create amphora with customized metadata\n\nhttps://storyboard.openstack.org/#!/story/2006763\n\nChange-Id: I5340eda9378b9df410f5f2ea0f9c3e8fc4d672be\n'}, {'number': 2, 'created': '2019-10-28 02:58:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/octavia/commit/0b95bd42fee53c30bccda3ad6af173d9bc0ef965', 'message': 'Support to create amphora with customized metadata\n\nRefer: https://storyboard.openstack.org/#!/story/2006763\n\nChange-Id: I5340eda9378b9df410f5f2ea0f9c3e8fc4d672be\n'}, {'number': 3, 'created': '2020-11-04 07:06:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/octavia/commit/80465c7aa928acef7781b3ec91a6ed932237c3bd', 'message': 'Support to create amphora with customized metadata\n\nRefer: https://storyboard.openstack.org/#!/story/2006763\n\nChange-Id: I5340eda9378b9df410f5f2ea0f9c3e8fc4d672be\n'}, {'number': 4, 'created': '2020-11-19 04:08:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/octavia/commit/1b6774bf5c953867f8eaab7b0e0d21c688a69964', 'message': 'Support to create amphora with customized metadata\n\nRefer: https://storyboard.openstack.org/#!/story/2006763\n\nChange-Id: I5340eda9378b9df410f5f2ea0f9c3e8fc4d672be\n'}, {'number': 5, 'created': '2020-11-19 06:49:15.000000000', 'files': ['octavia/common/config.py', 'octavia/tests/unit/controller/worker/v1/tasks/test_compute_tasks.py', 'octavia/tests/unit/controller/worker/v2/test_controller_worker.py', 'octavia/compute/compute_base.py', 'octavia/compute/drivers/nova_driver.py', 'octavia/tests/unit/controller/worker/v1/test_controller_worker.py', 'octavia/controller/worker/v1/controller_worker.py', 'octavia/tests/unit/controller/worker/v2/tasks/test_compute_tasks.py', 'octavia/common/constants.py', 'octavia/controller/worker/v2/controller_worker.py', 'octavia/controller/worker/v2/tasks/compute_tasks.py', 'octavia/controller/worker/v1/tasks/compute_tasks.py', 'octavia/tests/unit/compute/drivers/test_nova_driver.py', 'octavia/compute/drivers/noop_driver/driver.py'], 'web_link': 'https://opendev.org/openstack/octavia/commit/3fe107f01fa21fbd0d561c47e270196b2df38571', 'message': 'Support to create amphora with customized metadata\n\nRefer: https://storyboard.openstack.org/#!/story/2006763\n\nChange-Id: I5340eda9378b9df410f5f2ea0f9c3e8fc4d672be\n'}]",6,690925,3fe107f01fa21fbd0d561c47e270196b2df38571,27,8,5,28910,,,0,"Support to create amphora with customized metadata

Refer: https://storyboard.openstack.org/#!/story/2006763

Change-Id: I5340eda9378b9df410f5f2ea0f9c3e8fc4d672be
",git fetch https://review.opendev.org/openstack/octavia refs/changes/25/690925/1 && git format-patch -1 --stdout FETCH_HEAD,"['octavia/common/config.py', 'octavia/tests/unit/controller/worker/v2/tasks/test_compute_tasks.py', 'octavia/tests/unit/controller/worker/v1/tasks/test_compute_tasks.py', 'octavia/compute/compute_base.py', 'octavia/tests/unit/compute/drivers/test_compute_noop_driver.py', 'octavia/compute/drivers/nova_driver.py', 'octavia/controller/worker/v2/tasks/compute_tasks.py', 'octavia/controller/worker/v1/tasks/compute_tasks.py', 'octavia/tests/unit/compute/drivers/test_nova_driver.py', 'octavia/compute/drivers/noop_driver/driver.py']",10,e16ad4c379c52e4346c2d7439743552507e6f0b7,2006763-Add_amphora_metadata," server_group_id=None, meta=None): ""user_data %s, port_ids %s, server_group_id %s, meta %s"", user_data, port_ids, server_group_id, meta) server_group_id, frozenset(meta.items()))] = ( server_group_id, frozenset(meta.items()), 'build') server_group_id=None, meta=None): server_group_id, meta)"," server_group_id=None): ""user_data %s, port_ids %s, server_group_id %s"", user_data, port_ids, server_group_id) server_group_id)] = ( server_group_id, 'build') server_group_id=None): server_group_id)",222,26
openstack%2Frpm-packaging~master~I43532b22a11cd8f86d3a37f8808b8a1f3b2dd3c9,openstack/rpm-packaging,master,I43532b22a11cd8f86d3a37f8808b8a1f3b2dd3c9,update python-troveclient to 6.0.0,MERGED,2020-12-01 01:34:40.000000000,2020-12-01 09:07:51.000000000,2020-12-01 09:07:51.000000000,"[{'_account_id': 6593}, {'_account_id': 13294}, {'_account_id': 19648}, {'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2020-12-01 01:34:40.000000000', 'files': ['openstack/python-troveclient/python-troveclient.spec.j2'], 'web_link': 'https://opendev.org/openstack/rpm-packaging/commit/8126518a2d8514c21dabc4e969aa83d867b91f5a', 'message': 'update python-troveclient to 6.0.0\n\nChange-Id: I43532b22a11cd8f86d3a37f8808b8a1f3b2dd3c9\n'}]",0,764867,8126518a2d8514c21dabc4e969aa83d867b91f5a,9,5,1,30533,,,0,"update python-troveclient to 6.0.0

Change-Id: I43532b22a11cd8f86d3a37f8808b8a1f3b2dd3c9
",git fetch https://review.opendev.org/openstack/rpm-packaging refs/changes/67/764867/1 && git format-patch -1 --stdout FETCH_HEAD,['openstack/python-troveclient/python-troveclient.spec.j2'],1,8126518a2d8514c21dabc4e969aa83d867b91f5a,bug/python-troveclient,{% set upstream_version = upstream_version('6.0.0') %},{% set upstream_version = upstream_version('5.1.1') %},1,1
openstack%2Frpm-packaging~master~If57d07ee30b53405ab0415a3fd4652cf10ccfcc6,openstack/rpm-packaging,master,If57d07ee30b53405ab0415a3fd4652cf10ccfcc6,update osc-lib to 2.3.0,MERGED,2020-11-13 00:47:21.000000000,2020-12-01 08:35:37.000000000,2020-12-01 08:35:37.000000000,"[{'_account_id': 6593}, {'_account_id': 13294}, {'_account_id': 19648}, {'_account_id': 22348}, {'_account_id': 23181}, {'_account_id': 27380}]","[{'number': 1, 'created': '2020-11-13 00:47:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rpm-packaging/commit/fc20afc3d7ac9e9bbbdd45e0f4e1fbd32f43b892', 'message': 'update osc-lib to 2.3.0\n\nChange-Id: If57d07ee30b53405ab0415a3fd4652cf10ccfcc6\n'}, {'number': 2, 'created': '2020-11-30 21:47:20.000000000', 'files': ['openstack/osc-lib/osc-lib.spec.j2'], 'web_link': 'https://opendev.org/openstack/rpm-packaging/commit/407d92a455ee36efe211392ae031250b72558590', 'message': 'update osc-lib to 2.3.0\n\nChange-Id: If57d07ee30b53405ab0415a3fd4652cf10ccfcc6\n'}]",0,762599,407d92a455ee36efe211392ae031250b72558590,33,6,2,30533,,,0,"update osc-lib to 2.3.0

Change-Id: If57d07ee30b53405ab0415a3fd4652cf10ccfcc6
",git fetch https://review.opendev.org/openstack/rpm-packaging refs/changes/99/762599/1 && git format-patch -1 --stdout FETCH_HEAD,['openstack/osc-lib/osc-lib.spec.j2'],1,fc20afc3d7ac9e9bbbdd45e0f4e1fbd32f43b892,bug/osc-lib,{% set upstream_version = upstream_version('2.3.0') %},{% set upstream_version = upstream_version('2.2.1') %},1,1
openstack%2Freleases~master~Ia6b830ea105f7360ffbbc7e14b44fce7b7902808,openstack/releases,master,Ia6b830ea105f7360ffbbc7e14b44fce7b7902808,Release neutron-lib for wallaby-1 milestone,MERGED,2020-11-30 13:18:28.000000000,2020-12-01 08:32:19.000000000,2020-12-01 08:32:19.000000000,"[{'_account_id': 841}, {'_account_id': 11904}, {'_account_id': 11975}, {'_account_id': 22348}, {'_account_id': 28522}]","[{'number': 1, 'created': '2020-11-30 13:18:28.000000000', 'files': ['deliverables/wallaby/neutron-lib.yaml'], 'web_link': 'https://opendev.org/openstack/releases/commit/e85a7895845415e841a9eddb6cfc9f8ac4073c47', 'message': 'Release neutron-lib for wallaby-1 milestone\n\nThis is a library release for neutron-lib for the wallaby-1\nmilestone. This repo includes commits that have not been releases for\nthis cycle yet.\n\nIf the team is ready to process with this release, please leave a +1\nto indicate we should go ahead with the release.\n\nIf the team needs more time for things about to merge, or if there is\nsome other reason a release should not be done at this time, please\nleave a -1 with a comment indicating the status. Then update the patch\nwith the new commit hash to use once the team is ready to do the\nrelease.\n\nChange-Id: Ia6b830ea105f7360ffbbc7e14b44fce7b7902808\n'}]",0,764699,e85a7895845415e841a9eddb6cfc9f8ac4073c47,9,5,1,28522,,,0,"Release neutron-lib for wallaby-1 milestone

This is a library release for neutron-lib for the wallaby-1
milestone. This repo includes commits that have not been releases for
this cycle yet.

If the team is ready to process with this release, please leave a +1
to indicate we should go ahead with the release.

If the team needs more time for things about to merge, or if there is
some other reason a release should not be done at this time, please
leave a -1 with a comment indicating the status. Then update the patch
with the new commit hash to use once the team is ready to do the
release.

Change-Id: Ia6b830ea105f7360ffbbc7e14b44fce7b7902808
",git fetch https://review.opendev.org/openstack/releases refs/changes/99/764699/1 && git format-patch -1 --stdout FETCH_HEAD,['deliverables/wallaby/neutron-lib.yaml'],1,e85a7895845415e841a9eddb6cfc9f8ac4073c47,w1-c-w-i,releases: - version: 2.7.0 projects: - repo: openstack/neutron-lib hash: 28373a924b0bc6fab56f5f52067ae607705f6654,,5,0
openstack%2Freleases~master~I704353ffb93d102eaa645bb05d35a0630a3b903d,openstack/releases,master,I704353ffb93d102eaa645bb05d35a0630a3b903d,Release python-tackerclient for wallaby-1 milestone,MERGED,2020-11-30 13:51:43.000000000,2020-12-01 08:32:14.000000000,2020-12-01 08:32:14.000000000,"[{'_account_id': 11904}, {'_account_id': 22348}, {'_account_id': 25701}, {'_account_id': 28522}]","[{'number': 1, 'created': '2020-11-30 13:51:43.000000000', 'files': ['deliverables/wallaby/python-tackerclient.yaml'], 'web_link': 'https://opendev.org/openstack/releases/commit/6b2b33f965b73723668c4824a3ca16a9b36b6516', 'message': 'Release python-tackerclient for wallaby-1 milestone\n\nThis is a library release for python-tackerclient for the wallaby-1\nmilestone. This repo includes commits that have not been releases for\nthis cycle yet.\n\nIf the team is ready to process with this release, please leave a +1\nto indicate we should go ahead with the release.\n\nIf the team needs more time for things about to merge, or if there is\nsome other reason a release should not be done at this time, please\nleave a -1 with a comment indicating the status. Then update the patch\nwith the new commit hash to use once the team is ready to do the\nrelease.\n\nChange-Id: I704353ffb93d102eaa645bb05d35a0630a3b903d\n'}]",0,764748,6b2b33f965b73723668c4824a3ca16a9b36b6516,9,4,1,28522,,,0,"Release python-tackerclient for wallaby-1 milestone

This is a library release for python-tackerclient for the wallaby-1
milestone. This repo includes commits that have not been releases for
this cycle yet.

If the team is ready to process with this release, please leave a +1
to indicate we should go ahead with the release.

If the team needs more time for things about to merge, or if there is
some other reason a release should not be done at this time, please
leave a -1 with a comment indicating the status. Then update the patch
with the new commit hash to use once the team is ready to do the
release.

Change-Id: I704353ffb93d102eaa645bb05d35a0630a3b903d
",git fetch https://review.opendev.org/openstack/releases refs/changes/48/764748/1 && git format-patch -1 --stdout FETCH_HEAD,['deliverables/wallaby/python-tackerclient.yaml'],1,6b2b33f965b73723668c4824a3ca16a9b36b6516,w1-c-w-i,releases: - version: 1.4.0 projects: - repo: openstack/python-tackerclient hash: 754f6df5a7d59f762734d8648c89f99cefe685a5,,5,0
openstack%2Foctavia-tempest-plugin~master~If0e07122df81447c1653cbd17b2e39f1367f00b4,openstack/octavia-tempest-plugin,master,If0e07122df81447c1653cbd17b2e39f1367f00b4,Skip octavia tests using 'screen' on advanced images,ABANDONED,2020-11-30 11:41:48.000000000,2020-12-01 07:56:57.000000000,,"[{'_account_id': 6469}, {'_account_id': 11628}, {'_account_id': 19118}, {'_account_id': 22348}, {'_account_id': 29244}, {'_account_id': 29350}, {'_account_id': 29681}]","[{'number': 1, 'created': '2020-11-30 11:41:48.000000000', 'files': ['octavia_tempest_plugin/tests/test_base.py'], 'web_link': 'https://opendev.org/openstack/octavia-tempest-plugin/commit/26daa122de4a7ff786945b44bafea815bb3f6423', 'message': ""Skip octavia tests using 'screen' on advanced images\n\nscreen is available by default on cirros images, but it is not on\nadvanced images, such as RHEL, used in some downstream jobs\n\nChange-Id: If0e07122df81447c1653cbd17b2e39f1367f00b4\n""}]",1,764643,26daa122de4a7ff786945b44bafea815bb3f6423,6,7,1,31291,,,0,"Skip octavia tests using 'screen' on advanced images

screen is available by default on cirros images, but it is not on
advanced images, such as RHEL, used in some downstream jobs

Change-Id: If0e07122df81447c1653cbd17b2e39f1367f00b4
",git fetch https://review.opendev.org/openstack/octavia-tempest-plugin refs/changes/43/764643/1 && git format-patch -1 --stdout FETCH_HEAD,['octavia_tempest_plugin/tests/test_base.py'],1,26daa122de4a7ff786945b44bafea815bb3f6423,," def skip_checks(cls): """"""Check if we should skip all of the children tests."""""" super(LoadBalancerBaseTestWithCompute, cls).skip_checks() if CONF.neutron_plugin_options.default_image_is_advanced: msg = ('These tests cannot be executed on advanced images because ' 'screen package is not available on them.') raise cls.skipException(msg) @classmethod",,10,0
openstack%2Fproject-config~master~I9a4f8e34d0edb61fed3a80fa8aa99bbdc08c2ccd,openstack/project-config,master,I9a4f8e34d0edb61fed3a80fa8aa99bbdc08c2ccd,Remove ceilometer-zvm entry,MERGED,2020-11-23 07:12:02.000000000,2020-12-01 07:45:53.000000000,2020-12-01 07:45:53.000000000,"[{'_account_id': 1004}, {'_account_id': 4146}, {'_account_id': 6547}, {'_account_id': 7118}, {'_account_id': 22348}]","[{'number': 1, 'created': '2020-11-23 07:12:02.000000000', 'files': ['zuul.d/projects.yaml'], 'web_link': 'https://opendev.org/openstack/project-config/commit/7c823ae7ed89f79efc9f07d62072a9afa28b155b', 'message': 'Remove ceilometer-zvm entry\n\nAs part of dropping py27 job, openstack-python3-ussuri-jobs\nhas been added to ceilomter-zvm .zuul.yaml file:\n\nhttps://review.opendev.org/c/x/ceilometer-zvm/+/763635\n\nRemoving the ceilometer-zvm entry in zuul.d/projects.yaml\nas it is no longer needed anymore.\n\nChange-Id: I9a4f8e34d0edb61fed3a80fa8aa99bbdc08c2ccd\n'}]",0,763742,7c823ae7ed89f79efc9f07d62072a9afa28b155b,7,5,1,9725,,,0,"Remove ceilometer-zvm entry

As part of dropping py27 job, openstack-python3-ussuri-jobs
has been added to ceilomter-zvm .zuul.yaml file:

https://review.opendev.org/c/x/ceilometer-zvm/+/763635

Removing the ceilometer-zvm entry in zuul.d/projects.yaml
as it is no longer needed anymore.

Change-Id: I9a4f8e34d0edb61fed3a80fa8aa99bbdc08c2ccd
",git fetch https://review.opendev.org/openstack/project-config refs/changes/42/763742/1 && git format-patch -1 --stdout FETCH_HEAD,['zuul.d/projects.yaml'],1,7c823ae7ed89f79efc9f07d62072a9afa28b155b,drop-py27-ceilometer-zvm,, - project: name: x/ceilometer-zvm templates: - openstack-python-jobs ,0,6
openstack%2Frequirements~master~I45806224b4397568b054932dcad25c9d5e9020c3,openstack/requirements,master,I45806224b4397568b054932dcad25c9d5e9020c3,update constraint for stevedore to new release 3.3.0,MERGED,2020-11-30 18:03:20.000000000,2020-12-01 06:42:43.000000000,2020-12-01 06:41:04.000000000,"[{'_account_id': 14288}, {'_account_id': 22348}]","[{'number': 1, 'created': '2020-11-30 18:03:20.000000000', 'files': ['upper-constraints.txt'], 'web_link': 'https://opendev.org/openstack/requirements/commit/e7c767c079eef6fbb7ff338176e4f4d575cd39ad', 'message': 'update constraint for stevedore to new release 3.3.0\n\nmeta: version: 3.3.0\nmeta: diff-start: -\nmeta: series: wallaby\nmeta: release-type: release\nmeta: pypi: yes\nmeta: first: yes\nmeta: release:Author: Daniel Bengtsson <dbengt@redhat.com>\nmeta: release:Commit: Daniel Bengtsson <dbengt@redhat.com>\nmeta: release:Change-Id: I41c36467f5f0e130ab6c40299f536a66d6991bc8\nmeta: release:Code-Review+2: Thierry Carrez <thierry@openstack.org>\nmeta: release:Code-Review+2: Sean McGinnis <sean.mcginnis@gmail.com>\nmeta: release:Workflow+1: Sean McGinnis <sean.mcginnis@gmail.com>\nChange-Id: I45806224b4397568b054932dcad25c9d5e9020c3\n'}]",0,764809,e7c767c079eef6fbb7ff338176e4f4d575cd39ad,8,2,1,11131,,,0,"update constraint for stevedore to new release 3.3.0

meta: version: 3.3.0
meta: diff-start: -
meta: series: wallaby
meta: release-type: release
meta: pypi: yes
meta: first: yes
meta: release:Author: Daniel Bengtsson <dbengt@redhat.com>
meta: release:Commit: Daniel Bengtsson <dbengt@redhat.com>
meta: release:Change-Id: I41c36467f5f0e130ab6c40299f536a66d6991bc8
meta: release:Code-Review+2: Thierry Carrez <thierry@openstack.org>
meta: release:Code-Review+2: Sean McGinnis <sean.mcginnis@gmail.com>
meta: release:Workflow+1: Sean McGinnis <sean.mcginnis@gmail.com>
Change-Id: I45806224b4397568b054932dcad25c9d5e9020c3
",git fetch https://review.opendev.org/openstack/requirements refs/changes/09/764809/1 && git format-patch -1 --stdout FETCH_HEAD,['upper-constraints.txt'],1,e7c767c079eef6fbb7ff338176e4f4d575cd39ad,new-release,stevedore===3.3.0,stevedore===3.2.2,1,1
openstack%2Frequirements~master~I19ec68613f5a71a17a5f53392c69b8b0e22de120,openstack/requirements,master,I19ec68613f5a71a17a5f53392c69b8b0e22de120,update constraint for tooz to new release 2.8.0,MERGED,2020-11-30 16:16:17.000000000,2020-12-01 06:38:54.000000000,2020-12-01 06:37:30.000000000,"[{'_account_id': 14288}, {'_account_id': 22348}, {'_account_id': 28522}]","[{'number': 1, 'created': '2020-11-30 16:16:17.000000000', 'files': ['upper-constraints.txt'], 'web_link': 'https://opendev.org/openstack/requirements/commit/f369f261e5c2cd318cb1481c226e68a24b9410e0', 'message': 'update constraint for tooz to new release 2.8.0\n\nmeta: version: 2.8.0\nmeta: diff-start: -\nmeta: series: wallaby\nmeta: release-type: release\nmeta: pypi: yes\nmeta: first: yes\nmeta: release:Author: Daniel Bengtsson <dbengt@redhat.com>\nmeta: release:Commit: Daniel Bengtsson <dbengt@redhat.com>\nmeta: release:Change-Id: I2a3b3766077c792924f203f95107e3b427bebaf0\nmeta: release:Code-Review+2: Thierry Carrez <thierry@openstack.org>\nmeta: release:Code-Review+2: Sean McGinnis <sean.mcginnis@gmail.com>\nmeta: release:Workflow+1: Sean McGinnis <sean.mcginnis@gmail.com>\nChange-Id: I19ec68613f5a71a17a5f53392c69b8b0e22de120\n'}]",0,764781,f369f261e5c2cd318cb1481c226e68a24b9410e0,9,3,1,11131,,,0,"update constraint for tooz to new release 2.8.0

meta: version: 2.8.0
meta: diff-start: -
meta: series: wallaby
meta: release-type: release
meta: pypi: yes
meta: first: yes
meta: release:Author: Daniel Bengtsson <dbengt@redhat.com>
meta: release:Commit: Daniel Bengtsson <dbengt@redhat.com>
meta: release:Change-Id: I2a3b3766077c792924f203f95107e3b427bebaf0
meta: release:Code-Review+2: Thierry Carrez <thierry@openstack.org>
meta: release:Code-Review+2: Sean McGinnis <sean.mcginnis@gmail.com>
meta: release:Workflow+1: Sean McGinnis <sean.mcginnis@gmail.com>
Change-Id: I19ec68613f5a71a17a5f53392c69b8b0e22de120
",git fetch https://review.opendev.org/openstack/requirements refs/changes/81/764781/1 && git format-patch -1 --stdout FETCH_HEAD,['upper-constraints.txt'],1,f369f261e5c2cd318cb1481c226e68a24b9410e0,new-release,tooz===2.8.0,tooz===2.7.1,1,1
openstack%2Ftacker-specs~master~I4f493f7060fc9358a94d5c01474977ead40304d8,openstack/tacker-specs,master,I4f493f7060fc9358a94d5c01474977ead40304d8,Support deploying Kubernetes cluster with MgmtDriver,MERGED,2020-10-26 22:56:01.000000000,2020-12-01 05:18:24.000000000,2020-12-01 05:17:15.000000000,"[{'_account_id': 17255}, {'_account_id': 22348}, {'_account_id': 25701}, {'_account_id': 26222}, {'_account_id': 26588}, {'_account_id': 27880}, {'_account_id': 31821}]","[{'number': 1, 'created': '2020-10-26 22:56:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tacker-specs/commit/676e1e9f68f8f7984698801ce1d9caf03b19eb2f', 'message': 'Support deploying Kubernetes cluster with MgmtDriver\n\nThis specification proposes a way to deploy a Kubernetes cluster\nas VNF with ETSI NFV-SOL specifications. The process will consist\nof VM instantiation and Kubernetes cluster installation on new VMs.\n\nThe following changes are required:\n* VnfLcmDriver supports MgmtDriver as Vnflcm Interface defined in\nESTI NFV-SOL 001.\n* MgmtDriver enables the ``instantiate_end`` operation to install\nand configure Kubernetes cluster.\n\nChange-Id: I4f493f7060fc9358a94d5c01474977ead40304d8\nBlueprint: cnf-support-with-etsi-nfv-specs\n'}, {'number': 2, 'created': '2020-11-18 09:05:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tacker-specs/commit/921b748b39a3d67e68c0960c934827183f5c3516', 'message': 'Support deploying Kubernetes cluster with MgmtDriver\n\nThis specification proposes a way to deploy a Kubernetes cluster\nas VNF with ETSI NFV-SOL specifications. The process will consist\nof VM instantiation and Kubernetes cluster installation on new VMs.\n\nThe following changes are required:\n* VnfLcmDriver supports MgmtDriver as Vnflcm Interface defined in\nESTI NFV-SOL 001.\n* MgmtDriver enables the ``instantiate_end`` operation to install\nand configure Kubernetes cluster.\n\nChange-Id: I4f493f7060fc9358a94d5c01474977ead40304d8\nBlueprint: cnf-support-with-etsi-nfv-specs\n'}, {'number': 3, 'created': '2020-11-24 00:58:17.000000000', 'files': ['specs/wallaby/mgmt-driver-for-k8s-cluster.rst'], 'web_link': 'https://opendev.org/openstack/tacker-specs/commit/4dd95f6a20e74be90d1d8e42242909bea517faf9', 'message': 'Support deploying Kubernetes cluster with MgmtDriver\n\nThis specification proposes a way to deploy a Kubernetes cluster\nas VNF with ETSI NFV-SOL specifications. The process will consist\nof VM instantiation and Kubernetes cluster installation on new VMs.\n\nThe following changes are required:\n* VnfLcmDriver supports MgmtDriver as Vnflcm Interface defined in\nESTI NFV-SOL 001.\n* MgmtDriver enables the ``instantiate_end`` operation to install\nand configure Kubernetes cluster.\n\nChange-Id: I4f493f7060fc9358a94d5c01474977ead40304d8\nBlueprint: cnf-support-with-etsi-nfv-specs\n'}]",4,759768,4dd95f6a20e74be90d1d8e42242909bea517faf9,18,7,3,27880,,,0,"Support deploying Kubernetes cluster with MgmtDriver

This specification proposes a way to deploy a Kubernetes cluster
as VNF with ETSI NFV-SOL specifications. The process will consist
of VM instantiation and Kubernetes cluster installation on new VMs.

The following changes are required:
* VnfLcmDriver supports MgmtDriver as Vnflcm Interface defined in
ESTI NFV-SOL 001.
* MgmtDriver enables the ``instantiate_end`` operation to install
and configure Kubernetes cluster.

Change-Id: I4f493f7060fc9358a94d5c01474977ead40304d8
Blueprint: cnf-support-with-etsi-nfv-specs
",git fetch https://review.opendev.org/openstack/tacker-specs refs/changes/68/759768/2 && git format-patch -1 --stdout FETCH_HEAD,['specs/wallaby/mgmt-driver-for-k8s-cluster.rst'],1,676e1e9f68f8f7984698801ce1d9caf03b19eb2f,bp/cnf-support-with-etsi-nfv-specs,"===================================================== Support deploying Kubernetes cluster with MgmtDriver ===================================================== https://blueprints.launchpad.net/tacker/+spec/cnf-support-with-etsi-nfv-specs This specification describes enhancement of VNF Lifecycle Management for Container Network Function (CNF) in Tacker. Problem description =================== The Kubernetes Infra Driver in Tacker can deploy CNF on pre-installed Kubernetes cluster [#add-kubernetes-cnf-support]_. This specification proposes a way to deploy CNF when Kubernetes cluster is not present. The process will consist of VM instantiation, Kubernetes cluster installation on new VMs, and CNF will be deployed on the new Kubernetes cluster. Proposed Change =============== The following changes are needed: The CNF instantiation process will be split into two VNF instances. Let's call the two instances as VNF-A and VNF-B respectively. #. VNF-A: Create VMs and set up Kubernetes cluster. #. VNF-B: Deploy CNF on the Kubernetes cluster inside VNF-A. The VIM type and ``additionalParams`` parameter provided in the VNF instantiation request will be important part of this multi-stage deployment process. VNF-A: Create VMs and set up Kubernetes cluster ----------------------------------------------- As Kubernetes cluster, there are two architectures to be supported. * The `Kuryr-Kubernetes`_. * Additional information required for ""Kubernetes with Kube-adm"". TODO: What type of distro or CNI in Kubernetes will be used in Tacker? It needs to be discussed in the community. Currently it is assumed that Kuryr-Kubernetes/Kube-adm will be used. .. note:: Kubernetes v1.16.0 and Kubernetes python client v11.0 are supported for Kubernetes VIM. VNF-A: Create VMs and set up Kubernetes cluster (Kuryr-Kubernetes) ------------------------------------------------------------------ Kuryr-Kubernetes provides a CNI enabling the Service resource to cooperate with Neutron ports and LBaaS. When users create a Service with their Pods, CNI asks Neutron to create and assign a port on LBaaS. This helps users to expose their applications to the public network. The diagram below shows Creating VMs and set up Kubernetes cluster: .. code-block:: +---------+ +---------+ | Cluster | | | | Install | | VNFD | | Script | | | +-------+-+ +-+-------+ | | +--------------+ v v +---------------+ | LCM operation| +----------+ | Instantiation | | User Data |------>| | | Request with | +--------------+ | CSAR | | Additional | +-----------+ +--->| | | Params | | Heat | | +----+-----+ +-+-------------+ | Template |--+ | | | (Base HOT)| | | +-----------+ +-----+----------+--------------+ | v v VNFM | | +-------------------+ | | | TackerServer | | | +-------+-----------+ | | | | | v | 2. Kubernetes Cluster | +----------------------+ | Installation | | +-------------+ | | +-------------+------------------------+--+----| MgmtDriver | | | | | | | +-------------+ | | +-------|-------------|------------+ | | | | | | | | | | | | | +----|------+ +---|-------+ | | | | | | | v | | v | | | | +-------------+ | | | | +------+ | | +------+ | | 1. Create | | |OpenStack | | | | | |Worker| | | |Master| |<---------------+--+----|Infra Driver | | | | | +------+ | | +------+ | | VMs | | +-------------+ | | | | VM | | VM | | | | | | | +-----------+ +-----------+ | | | | | +----------------------------------+ | | Tacker Conductor| | +----------------------------------+ | +----------------------+ | | Hardware Resources | | | +----------------------------------+ +-------------------------------+ The diagram shows related component of this spec proposal and an overview of the following processing: #. OpenStackInfraDriver creates new VMs. #. MgmtDriver installs the Kubernetes cluster by ``instantiate_end``. #. MgmtDriver uses a shell script to install Kubernetes on Master-node and Worker-node. #. MgmtDriver registers Kubernetes VIM to tacker. #. MgmtDriver appends Kubernetes cluster VIM info to VimConnectionInfo. Here are the topology of Kuryr-Kubernetes cluster connecting with public network: .. code-block:: +-----------+ | | | External | | Network | | | +-----------+ | +-----------+ | | | LBaaS | | | +-----------+ | +-------------------------------------------------+ |VNF-A | | |(Kubernetes Cluster)| | | | Kubernetes Service Network | | | | | |Cluster IP | | +-----*-----+ | | | | | | | Service | | | | | | | +-----------+ | | | | | | Kubernetes Pod Network | | +-----+-----+ | | | | | | +-----------------------------+ | | | | | | | | | +---*---+ +---*---+ | | | | | Pod | | Pod | | | | | +-------+ +-------+ | | | | VNF-B (e.g. Deployments) | | | +-----------------------------+ | +-------------------------------------------------+ Following sequence diagram describes the components involved and the flow of install Kubernetes cluster with MgmtDriver operation: .. seqdiag:: seqdiag { node_width = 80; edge_length = 100; ""Client"" ""Tacker-server"" ""Tacker-conductor"" ""VnfLcmDriver"" ""OpenstackDriver"" ""Heat"" ""MgmtDriver"" ""VnfInstance(Tacker DB)"" ""RemoteCommandExecutor"" ""NfvoPlugin"" Client -> ""Tacker-server"" [label = ""POST /vnf_instances/{vnfInstanceId}/instantiate""]; Client <-- ""Tacker-server"" [label = ""Response 202 Accepted""]; ""Tacker-server"" -> ""Tacker-conductor"" [label = ""trigger asynchronous task""]; ""Tacker-conductor"" -> ""VnfLcmDriver"" [label = ""execute VnfLcmDriver""]; ""VnfLcmDriver"" -> ""OpenstackDriver"" [label = ""execute OpenstackDriver""]; ""OpenstackDriver"" -> ""Heat"" [label = ""create stack""]; ""OpenstackDriver"" <-- ""Heat"" [label = ""return stack id""]; ""VnfLcmDriver"" <-- ""OpenstackDriver"" [label = ""return instance_id""]; ""VnfLcmDriver"" -> ""MgmtDriver"" [label = ""instantiate_end""]; ""MgmtDriver"" -> ""VnfInstance(Tacker DB)"" [label = ""get stack id""]; ""MgmtDriver"" <-- ""VnfInstance(Tacker DB)"" [label = """"]; ""MgmtDriver"" -> ""Heat"" [label = ""get ssh ip address and Kubernetes address using stack id""]; ""MgmtDriver"" <-- ""Heat"" [label = """"]; ""MgmtDriver"" -> ""RemoteCommandExecutor"" [label = ""install Kubernetes on the new node""]; ""MgmtDriver"" <-- ""RemoteCommandExecutor"" [label = """"]; ""MgmtDriver"" -> ""RemoteCommandExecutor"" [label = ""get identification token from Kubernetes cluster""]; ""MgmtDriver"" <-- ""RemoteCommandExecutor"" [label = """"]; ""MgmtDriver"" -> ""NfvoPlugin"" [label = ""register Kubernetes VIM to tacker""]; ""MgmtDriver"" <-- ""NfvoPlugin"" [label = """"] ""MgmtDriver"" -> ""VnfInstance(Tacker DB)"" [label = ""append Kubernetes cluster VIM info to VimConnectionInfo""] ""MgmtDriver"" <-- ""VnfInstance(Tacker DB)"" [label = """"] ""VnfLcmDriver"" <-- ""MgmtDriver"" [label = """"]; ""Tacker-conductor"" <-- ""VnfLcmDriver"" [label = """"]; } The procedure consists of the following steps as illustrated in above sequence. #. Client sends ""instantiate"" as a POST request. #. Basically the same sequence as described in the ""2) Flow of Instantiation of a VNF instance"" chapter of spec `etsi-nfv-sol-rest-api-for-VNF-deployment`_, except for the MgmtDriver. #. The following processes are performed in ``instantiate_end``. #. MgmtDriver gets new VM information from Heat. #. MgmtDriver installs Kubernetes on the new node by a shell script. #. MgmtDriver installs etcd cluster by invoking shell script. #. MgmtDriver registers Kubernetes VIM to tacker. #. MgmtDriver appends Kubernetes cluster VIM info to VimConnectionInfo. VNFD for Kuryr-Kubernetes with UserData ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ VMs will be deployed using a Heat template provided in the CSAR as specified in `LCM-operation-with-user-data`_ specification. The reason is that the Kubernetes cluster will be set up with `Kuryr-Kubernetes`_. The cluster installation requires some essential network entities such as Router and LoadBalancer. .. note:: It is not supported to deploy Kuryr-Kubernetes with TOSCA because LoadBalancer is not supported by heat-translator while TOSCA v1.2 has definition. Router definition is not present in TOSCA v1.2. It is assumed to utilize user-data based instantiation with base HOT. .. note:: Although VM resource information can be included in VNFD in future, it is out of scope of this specification. Following components of CSAR package will be required for VM instantiation: * VNFD VNFD will not contain any VM resource information such as VDU, Connection points, Virtual links because all required components of VM will be specified in the heat template (Base HOT). To execute a script to install Kubernetes cluster after instantiation of VM with Base HOT, ``Tosca.interfaces.nfv.Vnflcm`` should be described in VNFD. According to ETSI SOL001 [#etsi-sol001]_ section 6.7, ``instantiate_end`` resource can be defined to enable postamble. The input parameters are provided by ``additionalParams`` in instantiate parameters. .. note:: The logic to enable ``Tosca.interfaces.nfv.Vnflcm`` will be implemented with the MgmtDriver [#action-driver]_. In this specification, the scope is to implement the MgmtDriver to install a Kubernetes cluster. * Heat template (Base HOT) The heat template will contain resource information for instantiation of VM and network entities such as Router, LoadBalancer. It will be used as mentioned in `LCM-operation-with-user-data`_ specification. * LCM operation user data It will contain a python module for processing parameters required for heat template provided in BaseHOT directory. It will be used as mentioned in `LCM-operation-with-user-data`_ specification. VNFD needs to have ``instantiate_end`` definition as the following sample: .. code-block:: yaml node_templates: VNF: type: tacker.sample.VNF properties: flavour_description: A simple flavour interfaces: Vnflcm: instantiate: [] # inputs: # key_1: value_1 # additional_parameters: # type: MyCompany.datatypes.nfv.VnfInstantiateAdditionalParameters instantiate_start: [] instantiate_end: implementation: mgmt-drivers-kubernetes artifacts: mgmt-drivers-kubernetes: description: Management driver for Kubernetes cluster type: tosca.artifacts.Implementation.Python file: /.../mgmt_drivers/kubernetes_mgmt.py # data_types: # MyCompany.datatypes.nfv.VnfInstantiateAdditionalParameters: # derived_from: tosca.datatypes.nfv.VnfOperationAdditionalParameters # properties: # key_1: # type: string # required: true Below is a sample of body provided in the VNF instantiation request `POST /vnflcm/v1/vnf_instances/{vnfInstanceId}/instantiate` .. code-block:: json { ""flavourId"": ""cluster_install"", ""additionalParams"": { ""lcm-operation-user-data"": ""UserData/base_user_data.py"", ""lcm-operation-user-data-class"": ""BaseUserData"", ""input_params"":"""" }, ""vimConnectionInfo"": [ { ""id"": ""8a3adb69-0784-43c7-833e-aab0b6ab4470"", ""vimId"": ""7dc3c839-bf15-45ac-8dff-fc5b95c2940e"", ""vimType"": ""openstack"" } ] } .. note:: details of input parameters is written in ""Kubernetes cluster installation"" section Kubernetes cluster installation ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ This spec proposes a way to configure a Kubernetes cluster on the VM deployed in previous step. The cluster will be configured using MgmtDriver to call ``mgmt_call()`` method. The configuration can be implemented as a shell script or a python script. To call an ansible script deployed as a maintenance VM in VNF can be an alternative design. The scripts are also responsible for returning the cluster access information. The cluster access information will be stored in the database as VIM connection info. .. note:: VNFM will access the artifacts directly from the VNF package. APIs specified by `Add-artifacts-support-for-VNF-package`_ will be used in future. .. note:: Since MgmtDriver is still in development, sequence of MgmtDriver and install script may change in future. Please take them as just a reference. The needed change in VNF LCM driver will be implemented in the specification of ActionDriver. The scripts will take script path and parameters required for cluster setup as arguments. The function will return cluster access information in following format. .. code-block:: json { ""server"" : ""https://123.124.64.6:8443"", ""username"" : ""some-username"", ""password"" : ""some-password"" } The Management driver will map this information to ``vim_connection_info`` as shown below. It will be stored in ``vim_connection_info`` column of the ``vnf_instances`` table. Sample of ``vim_connection_info`` record stored in the database: .. code-block:: json { ""vim_type"": ""kubernetes"", ""access_info"": { ""auth_url"":""http://123.124.64.6:8443"", ""username"": ""some-username"", ""password"": ""some-password"" }, ""interface_info"": { } } The Kubernetes cluster installation requires following parameters: * Kuryr Kubernetes: * ID of Security group for pods * ID of Subnets for Pods * ID of project * ID of Subnet for k8s services * ID of LBaaS TODO: The list is incomplete. Need to identify all required parameters. The actual parameters provided in ""additionalParams"" are like below: * information for each VM: * Cluster role of this VM(Worker/Master) * ssh login information * username * password * k8s cluster information * k8s API cluster subnet * k8s pod subnet * proxy information * http_proxy * https_proxy * no_proxy * name of k8s VIM These parameters will be parsed from ""additionalParams"" in request body as described above. And will be parsed to script by script running options. .. note:: IP addresses used for ssh access and Kubernetes cluster will be got from heat-client by checking resources of the stack created by instantiate process above. As it is needed to specify master and worker VM in heat client, master/worker's resource name should follow as masterNode/workerNode. .. note:: A sample heat-template will be provided to users. In ``instantiate_end`` phase, MgmtDriver will be called to execute user's script on target VM. This function will be included in mgmt_drivers/kubernetes_mgmt.py: 1. access target VM through python SSH client 2. copy user's script to target VM 3. execute user's script and pass the parameters by optional .. note:: A Sample Kubernetes Install Script will be provided to users. VNF-A: Create VMs and set up Kubernetes cluster (Kube-adm) ---------------------------------------------------------- Describes the additional information required for ""Kubernetes with Kube-adm"". The diagram below shows Creating VMs and set up Kubernetes cluster: .. code-block:: +---------+ +---------+ | Cluster | | | | Install | | VNFD | | Script | | | +-------+-+ +-+-------+ | | v v +---------------+ +----------+ | Instantiation | | | | Request with | | CSAR | | Additional | | | | Params | +----+-----+ +-+-------------+ | | | | +-----+----------+--------------+ | v v VNFM | | +-------------------+ | | | TackerServer | | | +-------+-----------+ | | | | | v | 2. Kubernetes Cluster | +----------------------+ | Installation | | +-------------+ | | +-------------+------------------------+--+----| MgmtDriver | | | | | | | +-------------+ | | +-------|-------------|------------+ | | | | | | | | | | | | | +----|------+ +---|-------+ | | | | | | | v | | v | | | | +-------------+ | | | | +------+ | | +------+ | | 1. Create | | |OpenStack | | | | | |Worker| | | |Master| |<---------------+--+----|Infra Driver | | | | | +------+ | | +------+ | | VMs | | +-------------+ | | | | VM | | VM | | | | | | | +-----------+ +-----------+ | | | | | +----------------------------------+ | | Tacker Conductor| | +----------------------------------+ | +----------------------+ | | Hardware Resources | | | +----------------------------------+ +-------------------------------+ The diagram shows related component of this spec proposal and an overview of the following processing: #. OpenStackInfraDriver creates new VMs. #. MgmtDriver installs the Kubernetes cluster by ``instantiate_end``. #. MgmtDriver uses a shell script to install Kubernetes on Master-node and Worker-node. #. MgmtDriver registers Kubernetes VIM to tacker. #. MgmtDriver appends Kubernetes cluster VIM info to VimConnectionInfo. Here are the topology of Kube-adm cluster connecting with public network: For Kube-adm, user needs to cooperate another SDN-controller to connect public network .. code-block:: +-----------+ | | | External | | Network | | | +-----------+ | +------------+ | | +------------+ | External | | SDN | | Load +-+ Controller | | Balancer | | | +------------+ +------------+ | +-------------------------------------------------+ |VNF-A | | |(Kubernetes Cluster)| | | | Kubernetes Service Network | | | | | |Cluster IP | | +-----*-----+ | | | | | | | Service | | | | | | | +-----------+ | | | | | | Kubernetes Pod Network | | +-----+-----+ | | | | | | +-----------------------------+ | | | | | | | | | +---*---+ +---*---+ | | | | | Pod | | Pod | | | | | +-------+ +-------+ | | | | VNF-B (e.g. Deployments) | | | +-----------------------------+ | +- -----------------------------------------------+ Following sequence diagram describes the components involved and the flow of install Kubernetes cluster with MgmtDriver operation: .. seqdiag:: seqdiag { node_width = 80; edge_length = 100; ""Client"" ""Tacker-server"" ""Tacker-conductor"" ""VnfLcmDriver"" ""OpenstackDriver"" ""Heat"" ""MgmtDriver"" ""VnfInstance(Tacker DB)"" ""RemoteCommandExecutor"" ""NfvoPlugin"" Client -> ""Tacker-server"" [label = ""POST /vnf_instances/{vnfInstanceId}/instantiate""]; Client <-- ""Tacker-server"" [label = ""Response 202 Accepted""]; ""Tacker-server"" -> ""Tacker-conductor"" [label = ""trigger asynchronous task""]; ""Tacker-conductor"" -> ""VnfLcmDriver"" [label = ""execute VnfLcmDriver""]; ""VnfLcmDriver"" -> ""OpenstackDriver"" [label = ""execute OpenstackDriver""]; ""OpenstackDriver"" -> ""Heat"" [label = ""create stack""]; ""OpenstackDriver"" <-- ""Heat"" [label = ""return stack id""]; ""VnfLcmDriver"" <-- ""OpenstackDriver"" [label = ""return instance_id""]; ""VnfLcmDriver"" -> ""MgmtDriver"" [label = ""instantiate_end""]; ""MgmtDriver"" -> ""VnfInstance(Tacker DB)"" [label = ""get stack id""]; ""MgmtDriver"" <-- ""VnfInstance(Tacker DB)"" [label = """"]; ""MgmtDriver"" -> ""Heat"" [label = ""get ssh ipaddress and Kubernetes address using stack id""]; ""MgmtDriver"" <-- ""Heat"" [label = """"]; ""MgmtDriver"" -> ""RemoteCommandExecutor"" [label = ""install Kubernetes on the new node""]; ""MgmtDriver"" <-- ""RemoteCommandExecutor"" [label = """"]; ""MgmtDriver"" -> ""RemoteCommandExecutor"" [label = ""get identification token and hash value of ssl certificates from Kubernets Custer""]; ""MgmtDriver"" <-- ""RemoteCommandExecutor"" [label = """"]; ""MgmtDriver"" -> ""NfvoPlugin"" [label = ""register Kubernetes VIM to tacker""]; ""MgmtDriver"" <-- ""NfvoPlugin"" [label = """"] ""MgmtDriver"" -> ""VnfInstance(Tacker DB)"" [label = ""append Kubernetes cluster VIM info to VimConnectionInfo""] ""MgmtDriver"" <-- ""VnfInstance(Tacker DB)"" [label = """"] ""VnfLcmDriver"" <-- ""MgmtDriver"" [label = """"]; ""Tacker-conductor"" <-- ""VnfLcmDriver"" [label = """"]; } The procedure consists of the following steps as illustrated in above sequence. #. Client sends ""instantiate"" as a POST request. #. Basically the same sequence as described in the ""2) Flow of Instantiation of a VNF instance"" chapter of spec `etsi-nfv-sol-rest-api-for-VNF-deployment`_, except for the MgmtDriver. #. The following processes are performed in ``instantiate_end``. #. MgmtDriver gets new VM information from Heat. #. MgmtDriver installs Kubernetes on the new node by a shell script. #. MgmtDriver gets authentication information from Kubernetes cluster. #. MgmtDriver registers Kubernetes VIM to tacker. #. MgmtDriver appends Kubernetes cluster VIM info to VimConnectionInfo. VNFD for Kube-adm with TOSCA template ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ In Kube-adm, LCM operation user data will not be used since VM in Kube-adm, Openstack resources is not used. VM information could be included in VNFD file with instantiated_end section in Vnflcm of interface. Here is an example of VNFD file with 1 master node and 1 worker node: .. code-block:: tosca_definitions_version: tosca_simple_yaml_1_2 description: Deployment flavour for MgmtDriver for k8s cluster imports: - etsi_nfv_sol001_common_types.yaml - etsi_nfv_sol001_vnfd_types.yaml topology_template: inputs: id: type: string vendor: type: string version: type: version descriptor_id: type: string descriptor_version: type: string provider: type: string product_name: type: string software_version: type: string vnfm_info: type: list entry_schema: type: string flavour_id: type: string flavour_description: type: string substitution_mappings: node_type: Company.Tacker.KubernetesCluster properties: flavour_id: cluster_install node_templates: VNF: type: company.provider.VNF properties: flavour_description: A simple flavour interfaces: Vnflcm: instantiate: [] instantiate_start: [] instantiate_end: implementation: mgmt-drivers-kubernetes artifacts: mgmt-drivers-kubernetes: description: Management driver for Kubernetes cluster type: tosca.artifacts.Implementation.Python file: /.../mgmt_drivers/kubernetes_mgmt.py] masterNode: type: tosca.nodes.nfv.Vdu.Compute properties: name: masterNode description: masterNode vdu_profile: min_number_of_instances: 1 max_number_of_instances: 1 workerNode: type: tosca.nodes.nfv.Vdu.Compute properties: name: workerNode description: workerNode vdu_profile: min_number_of_instances: 1 max_number_of_instances: 1 masterNodeInternalCP: type: tosca.nodes.nfv.VduCp properties: layer_protocols: [ ipv4 ] order: 0 requirements: - virtual_binding: masterNode - virtual_link: internalVL masterNodeExternalCP: type: tosca.nodes.nfv.VduCp properties: layer_protocols: [ ipv4 ] order: 1 requirements: - virtual_binding: masterNode # - virtual_link: # the target node is determined in the NSD workerNodeInternalCP: type: tosca.nodes.nfv.VduCp properties: layer_protocols: [ ipv4 ] order: 2 requirements: - virtual_binding: workerNode - virtual_link: internalVL workerNodeExternalCP: type: tosca.nodes.nfv.VduCp properties: layer_protocols: [ ipv4 ] order: 3 requirements: - virtual_binding: workerNode # - virtual_link: # the target node is determined in the NSD internalVL: type: tosca.nodes.nfv.VnfVirtualLink properties: connectivity_type: layer_protocols: [ ipv4 ] description: Internal Virtual link in the VNF(for k8s cluster) vl_profile: virtual_link_protocol_data: - associated_layer_protocol: ipv4 l3_protocol_data: ip_version: ipv4 cidr: 10.10.0.0/24 .. note:: The name of master/worker node should be started with master/worker to specify ip address from heat client. Below is a sample of body provided in the VNF instantiation request `POST /vnflcm/v1/vnf_instances/{vnfInstanceId}/instantiate` .. code-block:: json { ""flavourId"": ""cluster_install"", ""additionalParams"": { ""input_params"":"""" }, ""vimConnectionInfo"": [ { ""id"": ""8a3adb69-0784-43c7-833e-aab0b6ab4470"", ""vimId"": ""7dc3c839-bf15-45ac-8dff-fc5b95c2940e"", ""vimType"": ""openstack"" } ] } .. note:: details of input_params is discussed in section ""Kubernetes cluster installation"" below Kubernetes cluster installation ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ This spec proposes a way to configure a Kubernetes cluster on the VM deployed in previous step. The cluster will be configured using MgmtDriver to call ``mgmt_call()`` method. The configuration can be implemented as a shell script or a python script. To call an ansible script deployed as a maintenance VM in VNF can be an alternative design. The scripts are also responsible for returning the cluster access information. The cluster access information will be stored in the database as VIM connection info. .. note:: VNFM will access the artifacts directly from the VNF package. APIs specified by `Add-artifacts-support-for-VNF-package`_ will be used in future. .. note:: Since MgmtDriver is still in development, sequence of MgmtDriver and install script may change in future. Please take them as just a reference. The needed change in VNF LCM driver will be implemented in the specification of ActionDriver. The scripts will take script path and parameters required for cluster setup as arguments. The function will return cluster access information in following format. .. code-block:: json { ""server"" : ""https://123.124.64.6:8443"", ""username"" : ""some-username"", ""password"" : ""some-password"" } The Management driver will map this information to ``vim_connection_info`` as shown below. It will be stored in ``vim_connection_info`` column of the ``vnf_instances`` table. During Kube-adm Kubernetes cluster is deploying, a ca-certificate and a certificate key will be generated by Kube-adm, and will be used in https requests to Kube-adm Kubernetes cluster. The certificate and key will also be stored in `vimConnectionInfo` in vnf_instance table with identification token during appending Kubernetes cluster VIM info to Tacker DB. Sample of ``vim_connection_info`` record stored in the database: .. code-block:: json { ""vim_type"": ""kubernetes"", ""access_info"": { ""auth_url"":""http://123.124.64.6:8443"", ""username"": ""some-username"", ""password"": ""some-password"", ""bearer_token"": ""value of bearer token"", ""ssl_ca_cert_hash"": ""hash value of ssl ca certification"", ""certificate_key"": ""value of certificate key"" }, ""interface_info"": { } } Also, Kubernetes VIM information will also be added to Vim table in tackerDB. Comparing to openstack VIM, Kubernetes VIM will have extra attributes in vim_auth table. Sample of ``VimAuth`` record stored in the database: .. code-block:: json { ""vim_id"": ""id of Kubernetes VIM"", ""auth_url"": ""ip address of Kubernetes cluster"" ""vim_project"": {} ""auth_cred"": { ""username"": ""username"", ""password"": ""password"", ""bearer_token"": ""value of bearer_token"", ""ssl_ca_cert_hash"": ""hash value of ssl ca certification"", ""certificate_key"": ""value of certificate key"" } } .. note:: Username/password and bearer_token is not a required attribute here, but at least one of them should exist. Ssl_ca_cert_hash and certificate_key are required here for https request and joining worker nodes. .. note:: In Kube-adm, 3 ways of user authentication are available. Please refer `auth-of-kube-adm`_. In tacker, basic auth/Bearer Token will be supported. For generation of bearer token, service account tokens method will be supported rather than static token file method. .. note:: During Kube-adm installation, a service account token will be automatically generated. However this token does not have authority for pods operation. Thus install script will generate a new service account token and store it in tacker DB. The Kubernetes cluster installation requires following parameters: * Kube-adm: * k8s API cluster IP * k8s API cluster subnet * k8s pod subnet TODO: The list is incomplete. Need to identify all required parameters. The actual parameters provided in ""additionalParams"" are like below: * information for each VM: * Cluster role of this VM(Worker/Master) * ssh login information * username * password * k8s cluster information * k8s API cluster subnet * k8s pod subnet * proxy information * http_proxy * https_proxy * no_proxy * name of k8s VIM These parameters will be parsed from ""additionalParams"" in request body as described above. And will be parsed to script by script running options. .. note:: IP addresses used for ssh access and Kubernetes cluster will be got from heat-client by checking resources of the stack created by instantiate process above. As it is needed to specify master and worker VM in heat client, master/worker's resource name should follow as masterNode/workerNode. .. note:: A sample heat-template will be provided to users. In ``instantiate_end`` phase, MgmtDriver will be called to execute user's script on target VM. This function will be included in mgmt_drivers/kubernetes_mgmt.py: 1. access target VM through python ssh client 2. copy user's script to target VM 3. execute user's script and pass the parameters by optional .. note:: A Sample Kubernetes Install Script will be provided to users. VNF-A: Termination of VNF-A --------------------------- VNF-B needs to be terminated before VNF-A, see termination of VNF-B for detail. Also, vim connection information needs to be deleted during VNF-A termination. Same to instantiation, this logic will be executed through MgmtDriver in ``terminate_end`` phase of vnflcm. Following sequence diagram describes the components involved and the flow of terminate Kubernetes cluster with MgmtDriver operation: .. seqdiag:: seqdiag { node_width = 80; edge_length = 100; ""Client"" ""Tacker-server"" ""Tacker-conductor"" ""VnfLcmDriver"" ""OpenstackDriver"" ""Heat"" ""MgmtDriver"" ""VnfInstance(Tacker DB)"" ""NfvoPlugin"" Client -> ""Tacker-server"" [label = ""POST /vnf_instances/{vnfInstanceId}/terminate""]; Client <-- ""Tacker-server"" [label = ""Response 202 Accepted""]; ""Tacker-server"" -> ""Tacker-conductor"" [label = ""trigger asynchronous task""]; ""Tacker-conductor"" -> ""VnfLcmDriver"" [label = ""execute VnfLcmDriver""]; ""VnfLcmDriver"" -> ""OpenstackDriver"" [label = ""execute OpenstackDriver""]; ""OpenstackDriver"" -> ""Heat"" [label = ""delete stack""]; ""OpenstackDriver"" <-- ""Heat"" [label = ""stack deleted""]; ""VnfLcmDriver"" <-- ""OpenstackDriver"" [label = ""resources removed""]; ""VnfLcmDriver"" -> ""MgmtDriver"" [label = ""terminate_end""]; ""MgmtDriver"" -> ""NfvoPlugin"" [label = ""delete the VIM information""]; ""MgmtDriver"" <-- ""NfvoPlugin"" [label = """"]; ""MgmtDriver"" -> ""VnfInstance(Tacker DB)"" [label = ""Clear the Kubernetes cluster information stored in the vim_connection_info of the VNF Instance""]; ""MgmtDriver"" <-- ""VnfInstance(Tacker DB)"" [label = """"]; ""VnfLcmDriver"" <-- ""MgmtDriver"" [label = """"]; ""Tacker-conductor"" <-- ""VnfLcmDriver"" [label = """"]; } The procedure consists of the following steps as illustrated in above sequence: #. Client sends ""terminate"" as a POST request. #. Basically the same sequence as described in the ""4) Flow of Termination of a VNF instance"" chapter of spec `etsi-nfv-sol-rest-api-for-VNF-deployment`_, except for the MgmtDriver. #. The following processes are performed in ``terminate_end``. #. Delete VIM information of Kubernetes cluster in Tacker DB. #. Clear the old Kubernetes cluster information stored in the vim_connection_info of the VNF Instance. VNFD needs to have ``terminate_end`` definition as the following sample: .. code-block:: yaml node_templates: VNF: type: tacker.sample.VNF properties: flavour_description: A simple flavour interfaces: Vnflcm: instantiate_start: [] instantiate_end: implementation: mgmt-drivers-kubernetes terminate_start: [] terminate_end: implementation: mgmt-drivers-kubernetes artifacts: mgmt-drivers-kubernetes: description: Management driver for Kubernetes cluster type: tosca.artifacts.Implementation.Python file: /.../mgmt_drivers/kubernetes_mgmt.py VNF-B: Deploy CNF on the Kubernetes cluster inside VNF-A -------------------------------------------------------- The following shows how to deploy CNF to a Kubernetes cluster in VNF-A. VNF-B: CNF instantiation ~~~~~~~~~~~~~~~~~~~~~~~~ CNF instantiation requires a VIM of type ``kubernetes``. As mentioned in above sections, the access information for the Kubernetes cluster created in VNF-A will be present in ``vim_connection_info`` column of ``vnf_instances`` table. User will call `GET /vnflcm/v1/vnf_instances/{vnfInstanceId}` API and manually register a VIM of type ``kubernetes`` using ``vimConnectionInfo`` from the response. CNF instantiation will be done as specified in `Container-Network-Function`_ specification. Hence no design changes will be required for this step. The diagram below shows how CNF (VNF-B) will be deployed on Kubernetes cluster created in VNF-A: .. code-block:: +----------+ | | | VNFD | | | +-+--------+ | v +----------+ +-------------------+ +---------------+ | | | Instantiation | | CNF Definition| | CSAR | | Request with | | File +-----------> | | | Additional Params | +---------------+ +------+---+ +---+---------------+ | | +---------------------------------+ | v v VNFM | + - - - - - - - - - - - - - - - - - - - -+ | +----------------+ | : VNF-B : | | TackerServer | | : +------------------------------+ : | +----------------+ | : | +----------+ +----------+ | : | | | : | | App | | App | | : | +------------------------+ | : | +----------+ +----------+ | : | | v | | : | +----------+ +----------+ | : | | +---------------+ | | : | |Container | |Container | | <-------------+ Kubernetes | | | : | +----------+ +----------+ | : | | | Infra Driver | | | : +------------------------------+ : | | +---------------+ | | + - - - - - - - - - - - - - - - - - - - -+ | | ^ | | | | | | | + - - - - - - - - - - - - - - - - - - - -+ | | +-------+-------+ | | : VNF-A : | | | VNF LCM | | | : +------------------------------+ : | | | Driver | | | : | Kubernetes cluster | : | | +---------------+ | | : | +----------+ +----------+ | : | | | | : | | +------+ | | +------+ | | : | | | | : | | |Worker| | | |Master| | | : | | +---------------+ | | : | | +------+ | | +------+ | | : | | | OpenStack | | | : | | VM | | VM | | : | | | Infra Driver | | | : | +----------+ +----------+ | : | | +---------------+ | | : +------------------------------+ : | | | | + - - - - - - - - - - - - - - - - - - - -+ | | Tacker Conductor | | | | | | +------------------------------+ | +------------------------+ | | Hardware Resources | | | +------------------------------+ +---------------------------------+ Implications of dependency of VNF-B on VNF-A -------------------------------------------- Since CNF-B will be deployed on the Kubernetes cluster created inside VNF-A, the operations performed on VNF-A will affect VNF-B. Termination of VNF-B ~~~~~~~~~~~~~~~~~~~~ This will destroy VNF-B and data being processed by VNF-B will become inconsistent. For this reason, VNF-B must be terminated gracefully before VNF-A. Performing such termination sequence automatically is out of scope of this spec, hence the required sequence will be described in the user guide. Healing of VNF-A ~~~~~~~~~~~~~~~~ The heal use case of VNF LCM sequence terminates existing VM and spawns a new replacement VM. The termination of VM running Kubernetes cluster's Master or Worker node may break VNF-B. Hence it may be necessary to terminate VNF-B gracefully or to evacuate Pods before performing heal operation on VNF-A. The required sequence will be described in the user guide. Data model impact ----------------- None REST API impact --------------- None Security impact --------------- None Notifications impact -------------------- None Other end user impact --------------------- None Performance impact ------------------ None Other deployer impact --------------------- None Developer impact ---------------- None Implementation ============== Assignee(s) ----------- Primary assignee: Yoshito Ito <yoshito.itou.dr@hco.ntt.co.jp> Other contributors: Nitin Uikey <nitin.uikey@nttdata.com> Tushar Patil <tushar.vitthal.patil@gmail.com> Prashant Bhole <prashant.bhole@nttdata.com> Ayumu Ueha <ueha.ayumu@fujitsu.com> Liang Lu <lu.liang@jp.fujitsu.com> Work Items ---------- * Implement Management driver to support: * Kubernetes cluster configuration * Storing and deleting Kubernetes VIM connection info * Provide a sample script to be executed by MgmtDriver to install and/or configure Kubernetes cluster * Add new unit and functional tests. Dependencies ============ None Testing ======= Unit and functional tests will be added to cover cases required in the spec. Documentation Impact ==================== * Complete user guide will be added to explain CNF instantiation on Kubernetes cluster inside VM. * The procedure for terminating the VNFs will be described in the user guide. References ========== .. [#add-kubernetes-cnf-support] : https://specs.openstack.org/openstack/tacker-specs/specs/queens/kubernetes-type-for-containerized-VNF.html .. [#etsi-sol001] : https://www.etsi.org/deliver/etsi_gs/NFV-SOL/001_099/001/02.07.01_60/gs_NFV-SOL001v020701p.pdf .. [#action-driver] : https://specs.openstack.org/openstack/tacker-specs/specs/victoria/action-driver.html .. _Add-artifacts-support-for-VNF-package : https://specs.openstack.org/openstack/tacker-specs/specs/victoria/add-artifacts.html .. _Container-Network-Function : https://specs.openstack.org/openstack/tacker-specs/specs/victoria/container-network-function.html .. _LCM-operation-with-user-data : https://specs.openstack.org/openstack/tacker-specs/specs/ussuri/lcm-operation-with-lcm-operation-user-data.html .. _Kuryr-Kubernetes : https://github.com/openstack/kuryr-kubernetes .. _etsi-nfv-sol-rest-api-for-VNF-deployment: https://specs.openstack.org/openstack/tacker-specs/specs/ussuri/etsi-nfv-sol -rest-api-for-VNF-deployment.html .. _auth-of-kube-adm: https://kubernetes.io/docs/reference/access-authn-authz/authentication/ ",,1266,0
openstack%2Fpuppet-openstack-integration~master~I509ef730bd0d9355ed529146b778f3b879dd2420,openstack/puppet-openstack-integration,master,I509ef730bd0d9355ed529146b778f3b879dd2420,Use ironic::inspector::ironic class to set ironic parameters,MERGED,2020-10-26 16:23:28.000000000,2020-12-01 05:15:21.000000000,2020-12-01 05:15:21.000000000,"[{'_account_id': 9414}, {'_account_id': 9816}, {'_account_id': 14985}, {'_account_id': 22348}]","[{'number': 1, 'created': '2020-10-26 16:23:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-openstack-integration/commit/ad72f703d6c1eabae63a6f9d9656e91a3f13c057', 'message': 'Use ironic::inspector::ironic class to set ironic parameters\n\n... because the ironic_* parameters have been deprecated in favor of\nthe ironic::inspector::ironic class[1].\n\n[1] 762804b38e65ac5ccfa4e6254180f47641242e83\n\nChange-Id: I509ef730bd0d9355ed529146b778f3b879dd2420\n'}, {'number': 2, 'created': '2020-10-26 23:26:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-openstack-integration/commit/c5bbad047ff3a9e81fd4dd4343b3e09ac6fd1161', 'message': 'Use ironic::inspector::ironic class to set ironic parameters\n\n... because the ironic_* parameters have been deprecated in favor of\nthe ironic::inspector::ironic class[1].\n\n[1] 762804b38e65ac5ccfa4e6254180f47641242e83\n\nChange-Id: I509ef730bd0d9355ed529146b778f3b879dd2420\n'}, {'number': 3, 'created': '2020-11-26 02:42:24.000000000', 'files': ['manifests/ironic.pp'], 'web_link': 'https://opendev.org/openstack/puppet-openstack-integration/commit/f4dfb9ee9f7437953088bff66a283eedb7c82a21', 'message': 'Use ironic::inspector::ironic class to set ironic parameters\n\n... because the ironic_* parameters have been deprecated in favor of\nthe ironic::inspector::ironic class[1].\n\n[1] 762804b38e65ac5ccfa4e6254180f47641242e83\n\nChange-Id: I509ef730bd0d9355ed529146b778f3b879dd2420\n'}]",0,759732,f4dfb9ee9f7437953088bff66a283eedb7c82a21,18,4,3,9816,,,0,"Use ironic::inspector::ironic class to set ironic parameters

... because the ironic_* parameters have been deprecated in favor of
the ironic::inspector::ironic class[1].

[1] 762804b38e65ac5ccfa4e6254180f47641242e83

Change-Id: I509ef730bd0d9355ed529146b778f3b879dd2420
",git fetch https://review.opendev.org/openstack/puppet-openstack-integration refs/changes/32/759732/1 && git format-patch -1 --stdout FETCH_HEAD,['manifests/ironic.pp'],1,ad72f703d6c1eabae63a6f9d9656e91a3f13c057,deprecated," class { 'ironic::inspector::ironic': ironic_password => 'a_big_secret', ironic_auth_url => ""${::openstack_integration::config::keystone_auth_uri}/v3"", }"," ironic_password => 'a_big_secret', ironic_auth_url => ""${::openstack_integration::config::keystone_auth_uri}/v3"",",4,2
openstack%2Fkolla~master~I34a2880a06e80ec1b7737ec1ffbef5f6ba7bed47,openstack/kolla,master,I34a2880a06e80ec1b7737ec1ffbef5f6ba7bed47,Update the'image-building.rst' document,MERGED,2020-11-26 02:56:55.000000000,2020-12-01 03:07:13.000000000,2020-12-01 03:05:51.000000000,"[{'_account_id': 14826}, {'_account_id': 22348}, {'_account_id': 26285}]","[{'number': 1, 'created': '2020-11-26 02:56:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla/commit/0f2b0e047d6bdcdb37fc0a6a8dfa3470f31dcc66', 'message': ""Update the'image-building.rst' document\n\nThe openstack Ussuri and Victoria versions no longer support\npython2 and python-pip packages by default,\nupdate the'image-building.rst' document\n\nChange-Id: I34a2880a06e80ec1b7737ec1ffbef5f6ba7bed47\n""}, {'number': 2, 'created': '2020-11-27 00:58:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla/commit/0dae7c2e5a8fa2cff9dd98e9db6ba9579a1b96ba', 'message': ""Update the'image-building.rst' document\n\nThe openstack Ussuri and Victoria versions no longer support\npython2 and python-pip packages by default,\nupdate the'image-building.rst' document\n\nChange-Id: I34a2880a06e80ec1b7737ec1ffbef5f6ba7bed47\n""}, {'number': 3, 'created': '2020-11-30 02:13:40.000000000', 'files': ['doc/source/admin/image-building.rst'], 'web_link': 'https://opendev.org/openstack/kolla/commit/963d4c13660553b32fb319a71820ce6e8e477197', 'message': ""Update the'image-building.rst' document\n\nThe openstack Ussuri and Victoria versions no longer support\npython2 and python-pip packages by default,\nupdate the'image-building.rst' document\n\nChange-Id: I34a2880a06e80ec1b7737ec1ffbef5f6ba7bed47\n""}]",5,764266,963d4c13660553b32fb319a71820ce6e8e477197,18,3,3,31506,,,0,"Update the'image-building.rst' document

The openstack Ussuri and Victoria versions no longer support
python2 and python-pip packages by default,
update the'image-building.rst' document

Change-Id: I34a2880a06e80ec1b7737ec1ffbef5f6ba7bed47
",git fetch https://review.opendev.org/openstack/kolla refs/changes/66/764266/2 && git format-patch -1 --stdout FETCH_HEAD,['doc/source/admin/image-building.rst'],1,0f2b0e047d6bdcdb37fc0a6a8dfa3470f31dcc66,,folder of the Kolla pip3 package. But you should only do that for pip3 install tox python3 tools/build.py python3 tools/build.py -b ubuntu python3 tools/build.py keystone python3 tools/build.py keystone nova python3 tools/build.py -t source python3 tools/build.py --template-override template-overrides.j2 horizon python3 tools/build.py --template-override template-overrides.j2 horizon && pip3 --no-cache-dir install networking-cisco pip3 --no-cache-dir install /plugins/*,folder of the Kolla pip package. But you should only do that for pip install tox python tools/build.py python tools/build.py -b ubuntu python tools/build.py keystone python tools/build.py keystone nova python tools/build.py -t source python tools/build.py --template-override template-overrides.j2 horizon python tools/build.py --template-override template-overrides.j2 horizon && pip --no-cache-dir install networking-cisco pip --no-cache-dir install /plugins/*,11,11
openstack%2Fcyborg-tempest-plugin~master~I95c57027a2b14b7231e733d668903c8ff7e6ec6e,openstack/cyborg-tempest-plugin,master,I95c57027a2b14b7231e733d668903c8ff7e6ec6e,add accelerator request list get delete test method,MERGED,2020-11-30 02:08:36.000000000,2020-12-01 02:54:22.000000000,2020-12-01 02:54:22.000000000,"[{'_account_id': 22348}, {'_account_id': 26458}, {'_account_id': 31412}]","[{'number': 1, 'created': '2020-11-30 02:08:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cyborg-tempest-plugin/commit/0913da81938f6bde6ad3d8e13d2f367f93beaee3', 'message': 'add accelerator request list get delete test method\n\nadd accelerator request list get interface method and api test\nChange-Id: I95c57027a2b14b7231e733d668903c8ff7e6ec6e\n'}, {'number': 2, 'created': '2020-11-30 03:01:03.000000000', 'files': ['cyborg_tempest_plugin/tests/api/test_accelerator_request.py', 'cyborg_tempest_plugin/services/cyborg_rest_client.py'], 'web_link': 'https://opendev.org/openstack/cyborg-tempest-plugin/commit/2889e8d29a9651936f53766eb2d146eb59142f98', 'message': 'add accelerator request list get delete test method\n\nadd accelerator request list get interface method and api test\nChange-Id: I95c57027a2b14b7231e733d668903c8ff7e6ec6e\n'}]",1,764598,2889e8d29a9651936f53766eb2d146eb59142f98,10,3,2,30409,,,0,"add accelerator request list get delete test method

add accelerator request list get interface method and api test
Change-Id: I95c57027a2b14b7231e733d668903c8ff7e6ec6e
",git fetch https://review.opendev.org/openstack/cyborg-tempest-plugin refs/changes/98/764598/1 && git format-patch -1 --stdout FETCH_HEAD,"['cyborg_tempest_plugin/tests/api/test_accelerator_request.py', 'cyborg_tempest_plugin/services/cyborg_rest_client.py']",2,0913da81938f6bde6ad3d8e13d2f367f93beaee3,master3," def list_accelerator_request(self): resp, body = self.get(self.AR_URL) return self._response_helper(resp, body) def get_accelerator_request(self, accelerator_request_uuid): url = self.AR_URL + ""/"" + accelerator_request_uuid resp, body = self.get(self.url) return self._response_helper(resp, body) ",,47,0
openstack%2Fcyborg-tempest-plugin~master~I9f2d7c640e00ecfde9164aa33ea1e791c33bbe2a,openstack/cyborg-tempest-plugin,master,I9f2d7c640e00ecfde9164aa33ea1e791c33bbe2a,add device profile negative testcase,MERGED,2020-11-30 02:53:20.000000000,2020-12-01 02:54:19.000000000,2020-12-01 02:54:19.000000000,"[{'_account_id': 22348}, {'_account_id': 26458}, {'_account_id': 31412}]","[{'number': 1, 'created': '2020-11-30 02:53:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cyborg-tempest-plugin/commit/e8c5c25b159d5ffd6f1450b0e43fa39fbcb2655a', 'message': 'add device profile negative testcase\n\nadd device profile negative testcase of get device profile interface\nChange-Id: I9f2d7c640e00ecfde9164aa33ea1e791c33bbe2a\n'}, {'number': 2, 'created': '2020-11-30 03:31:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cyborg-tempest-plugin/commit/933b62a1d05bbd4f801b174c64e4bd9b70910768', 'message': 'add device profile negative testcase\n\nadd device profile negative testcase of get device profile interface\nChange-Id: I9f2d7c640e00ecfde9164aa33ea1e791c33bbe2a\n'}, {'number': 3, 'created': '2020-11-30 04:19:23.000000000', 'files': ['cyborg_tempest_plugin/tests/api/test_device_profile_negative.py'], 'web_link': 'https://opendev.org/openstack/cyborg-tempest-plugin/commit/b9eb30f40d12e3e0f8357094b4d07d342911069e', 'message': 'add device profile negative testcase\n\nadd device profile negative testcase of get device profile interface\nChange-Id: I9f2d7c640e00ecfde9164aa33ea1e791c33bbe2a\n'}]",0,764599,b9eb30f40d12e3e0f8357094b4d07d342911069e,14,3,3,30409,,,0,"add device profile negative testcase

add device profile negative testcase of get device profile interface
Change-Id: I9f2d7c640e00ecfde9164aa33ea1e791c33bbe2a
",git fetch https://review.opendev.org/openstack/cyborg-tempest-plugin refs/changes/99/764599/1 && git format-patch -1 --stdout FETCH_HEAD,['cyborg_tempest_plugin/tests/api/test_device_profile_negative.py'],1,e8c5c25b159d5ffd6f1450b0e43fa39fbcb2655a,master4,"# Copyright 2020 Inspur # All Rights Reserved. # # Licensed under the Apache License, Version 2.0 (the ""License""); you may # not use this file except in compliance with the License. You may obtain # a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT # WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the # License for the specific language governing permissions and limitations # under the License. import uuid from cyborg_tempest_plugin.tests.api import base from tempest import exceptions from tempest import test class DeviceProfileNegativeTest(base.BaseAPITest): credentials = ['admin'] @test.attr(type=['negative', 'gate']) def test_get_non_existent_device_profile(self): # get the non-existent device_profile non_existent_id = str(uuid.uuid4()) self.assertRaises(exceptions.NotFound, self.os_admin.cyborg_client.get_device_profile, non_existent_id) @test.attr(type=['negative', 'gate']) def test_get_device_profile_null_id(self): # get device_profile with device_profile_id = NULL device_profile_id = """" self.assertRaises(exceptions.NotFound, self.os_admin.cyborg_client.get_device_profile, device_profile_id) ",,41,0
openstack%2Ftrove~master~I5b83b7d11a7ae11a1b48b02d5c7d7b7483875b8f,openstack/trove,master,I5b83b7d11a7ae11a1b48b02d5c7d7b7483875b8f,Update docs for Ubuntu 20.04,NEW,2020-11-19 05:46:30.000000000,2020-12-01 01:42:08.000000000,,"[{'_account_id': 3031}, {'_account_id': 6732}, {'_account_id': 22348}]","[{'number': 1, 'created': '2020-11-19 05:46:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/trove/commit/1cd906db4459a159d57a727afeb7638138705b99', 'message': ""Update docs for Ubuntu 20.04\n\n* Use 'apt install' command instead of legacy 'apt-get'\n\nChange-Id: I5b83b7d11a7ae11a1b48b02d5c7d7b7483875b8f\n""}, {'number': 2, 'created': '2020-11-26 06:25:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/trove/commit/831f50ebe5412e190d39655e84141fe4099cddaa', 'message': ""Update docs for Ubuntu 20.04\n\n* Use 'apt install' command instead of legacy 'apt-get'\n\nChange-Id: I5b83b7d11a7ae11a1b48b02d5c7d7b7483875b8f\n""}, {'number': 3, 'created': '2020-11-27 01:28:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/trove/commit/443403706d64f704bfbf720d68dc3125d3ec9208', 'message': ""Update docs for Ubuntu 20.04\n\n* Use 'apt install' command instead of legacy 'apt-get'\n\n[1] https://ubuntu.com/server/docs/package-management\n\nChange-Id: I5b83b7d11a7ae11a1b48b02d5c7d7b7483875b8f\n""}, {'number': 4, 'created': '2020-12-01 01:31:27.000000000', 'files': ['doc/source/install/install-ubuntu.rst', 'doc/source/install/apache-mod-wsgi.rst', 'doc/source/install/install-devstack.rst', 'doc/source/install/install-manual.rst'], 'web_link': 'https://opendev.org/openstack/trove/commit/9c7fc2750349cf3856df630900e7152f95b6ba0c', 'message': ""Update docs for Ubuntu 20.04\n\n* Use 'apt install' command instead of legacy 'apt-get'\n\n[1] https://ubuntu.com/server/docs/package-management\n\nChange-Id: I5b83b7d11a7ae11a1b48b02d5c7d7b7483875b8f\n""}]",8,763313,9c7fc2750349cf3856df630900e7152f95b6ba0c,16,3,4,32029,,,0,"Update docs for Ubuntu 20.04

* Use 'apt install' command instead of legacy 'apt-get'

[1] https://ubuntu.com/server/docs/package-management

Change-Id: I5b83b7d11a7ae11a1b48b02d5c7d7b7483875b8f
",git fetch https://review.opendev.org/openstack/trove refs/changes/13/763313/1 && git format-patch -1 --stdout FETCH_HEAD,"['doc/source/install/install-ubuntu.rst', 'doc/source/install/apache-mod-wsgi.rst', 'doc/source/install/install-devstack.rst', 'doc/source/install/install-manual.rst']",4,1cd906db4459a159d57a727afeb7638138705b99,apt,"A running OpenStack environment installed on Ubuntu 16.04 or 18.04 or 20.04 LTS is required, including the following components: $ sudo apt install -y build-essential python-dev libpython-dev \","A running OpenStack environment installed on Ubuntu 16.04 or 18.04 LTS is required, including the following components: $ sudo apt-get install -y build-essential python-dev libpython-dev \",7,7
openstack%2Fopenstack-ansible~master~I7203536111eb2120fa74d639ad9fc7b783d3cca7,openstack/openstack-ansible,master,I7203536111eb2120fa74d639ad9fc7b783d3cca7,Added Openstack Adjutant role deployment,MERGED,2020-10-06 14:07:28.000000000,2020-12-01 01:02:02.000000000,2020-12-01 00:58:11.000000000,"[{'_account_id': 22348}, {'_account_id': 25023}, {'_account_id': 28619}, {'_account_id': 31542}]","[{'number': 1, 'created': '2020-10-06 14:07:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/fa29325a390540752f4461ed2084de782fd49d26', 'message': 'Added Openstack Adjutant role deployment\n\nThis commit adds experimental deployment of Adjutant role.\n\nChange-Id: I7203536111eb2120fa74d639ad9fc7b783d3cca7\n'}, {'number': 2, 'created': '2020-10-08 17:32:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/99c1803b8a4dbcd631e4eefcc66a755d4de16339', 'message': 'Added Openstack Adjutant role deployment\n\nThis commit adds experimental deployment of Adjutant role.\n\nChange-Id: I7203536111eb2120fa74d639ad9fc7b783d3cca7\n'}, {'number': 3, 'created': '2020-10-13 19:26:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/722b088da755940f61b2bb215098e6382e463b07', 'message': 'Added Openstack Adjutant role deployment\n\nThis commit adds experimental deployment of Adjutant role.\n\nChange-Id: I7203536111eb2120fa74d639ad9fc7b783d3cca7\n'}, {'number': 4, 'created': '2020-10-13 19:54:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/25d5f137a34488be86b708cc7752aca158c4849a', 'message': 'Added Openstack Adjutant role deployment\n\nThis commit adds experimental deployment of Adjutant role.\n\nChange-Id: I7203536111eb2120fa74d639ad9fc7b783d3cca7\n'}, {'number': 5, 'created': '2020-10-16 15:47:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/ff9716ea42be3ce40bbd6b70d92c4dde9832cf19', 'message': 'Added Openstack Adjutant role deployment\n\nThis commit adds experimental deployment of Adjutant role.\n\nChange-Id: I7203536111eb2120fa74d639ad9fc7b783d3cca7\n'}, {'number': 6, 'created': '2020-10-16 15:47:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/c28b566f655fec989701130ebd5b2390d5a34833', 'message': 'Added Openstack Adjutant role deployment\n\nThis commit adds experimental deployment of Adjutant role.\n\nChange-Id: I7203536111eb2120fa74d639ad9fc7b783d3cca7\n'}, {'number': 7, 'created': '2020-10-21 07:45:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/ce259c9770fe2f1b7f536f281fb22267263fd64d', 'message': 'Added Openstack Adjutant role deployment\n\nThis commit adds experimental deployment of Adjutant role.\n\nDepends-On: https://review.opendev.org/756313\nChange-Id: I7203536111eb2120fa74d639ad9fc7b783d3cca7\n'}, {'number': 8, 'created': '2020-10-21 07:45:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/3f159172b99aef2e9bb82b2a4ba7a0c4408e0fe2', 'message': 'Added Openstack Adjutant role deployment\n\nThis commit adds experimental deployment of Adjutant role.\n\nDepends-On: https://review.opendev.org/756313\nChange-Id: I7203536111eb2120fa74d639ad9fc7b783d3cca7\n'}, {'number': 9, 'created': '2020-10-27 19:04:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/b965aeb0babcd620534373ab08c808a8e9311c48', 'message': 'Added Openstack Adjutant role deployment\n\nThis commit adds experimental deployment of Adjutant role.\n\nDepends-On: https://review.opendev.org/756313\nChange-Id: I7203536111eb2120fa74d639ad9fc7b783d3cca7\n'}, {'number': 10, 'created': '2020-11-01 09:58:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/af75cce71b11da6b6255bc098df2f3b69daba84d', 'message': 'Added Openstack Adjutant role deployment\n\nThis commit adds experimental deployment of Adjutant role.\n\nDepends-On: https://review.opendev.org/756313\nChange-Id: I7203536111eb2120fa74d639ad9fc7b783d3cca7\n'}, {'number': 11, 'created': '2020-11-02 17:13:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/68b2d253e461cfaddb5c16e381460608b708eb4f', 'message': 'Added Openstack Adjutant role deployment\n\nThis commit adds experimental deployment of Adjutant role.\n\nDepends-On: https://review.opendev.org/756313\nChange-Id: I7203536111eb2120fa74d639ad9fc7b783d3cca7\n'}, {'number': 12, 'created': '2020-11-09 14:41:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/460248a51bb5c83cf4dad68b27e0e5d4c3b02353', 'message': 'Added Openstack Adjutant role deployment\n\nThis commit adds experimental deployment of Adjutant role.\n\nDepends-On: https://review.opendev.org/756313\nChange-Id: I7203536111eb2120fa74d639ad9fc7b783d3cca7\n'}, {'number': 13, 'created': '2020-11-24 12:48:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/967c5361c0ec2851c44c7f1aca6c340cac3869af', 'message': 'Added Openstack Adjutant role deployment\n\nThis commit adds experimental deployment of Adjutant role.\n\nDepends-On: https://review.opendev.org/756313\nChange-Id: I7203536111eb2120fa74d639ad9fc7b783d3cca7\n'}, {'number': 14, 'created': '2020-11-30 11:29:54.000000000', 'files': ['deploy-guide/source/configure.rst', 'etc/openstack_deploy/conf.d/adjutant.yml.aio', 'doc/source/contributor/role-maturity-matrix.html', 'etc/openstack_deploy/conf.d/adjutant.yml.example', 'ansible-role-requirements.yml', 'playbooks/defaults/repo_packages/openstack_services.yml', 'inventory/env.d/adjutant.yml', 'etc/openstack_deploy/user_secrets.yml', 'releasenotes/notes/os_adjutant-ec59fc6a996e1fbe.yaml', 'inventory/group_vars/haproxy/haproxy.yml', 'inventory/group_vars/horizon_all.yml', 'inventory/inventory.ini', 'playbooks/os-adjutant-install.yml', 'playbooks/setup-openstack.yml', 'tests/test_inventory.py', 'zuul.d/jobs.yaml'], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/9949f3fb4ad26dc68e7fde8923264f6cee044e61', 'message': 'Added Openstack Adjutant role deployment\n\nThis commit adds experimental deployment of Adjutant role.\n\nDepends-On: https://review.opendev.org/756313\nChange-Id: I7203536111eb2120fa74d639ad9fc7b783d3cca7\n'}]",1,756310,9949f3fb4ad26dc68e7fde8923264f6cee044e61,44,4,14,28619,,,0,"Added Openstack Adjutant role deployment

This commit adds experimental deployment of Adjutant role.

Depends-On: https://review.opendev.org/756313
Change-Id: I7203536111eb2120fa74d639ad9fc7b783d3cca7
",git fetch https://review.opendev.org/openstack/openstack-ansible refs/changes/10/756310/11 && git format-patch -1 --stdout FETCH_HEAD,"['deploy-guide/source/configure.rst', 'etc/openstack_deploy/conf.d/adjutant.yml.aio', 'doc/source/contributor/role-maturity-matrix.html', 'etc/openstack_deploy/conf.d/adjutant.yml.example', 'ansible-role-requirements.yml', 'playbooks/defaults/repo_packages/openstack_services.yml', 'inventory/env.d/adjutant.yml', 'etc/openstack_deploy/user_secrets.yml', 'releasenotes/notes/os_adjutant-ec59fc6a996e1fbe.yaml', 'inventory/group_vars/haproxy/haproxy.yml', 'inventory/group_vars/horizon_all.yml', 'inventory/inventory.ini', 'playbooks/os-adjutant-install.yml', 'playbooks/setup-openstack.yml', 'tests/test_inventory.py', 'zuul.d/jobs.yaml']",16,fa29325a390540752f4461ed2084de782fd49d26,bump_osa, - name: openstack/openstack-ansible-os_adjutant - name: openstack/adjutant,,171,10
openstack%2Ftripleo-quickstart~master~I8ece0610abf455fc2c3f3ff7d35deb231e988c34,openstack/tripleo-quickstart,master,I8ece0610abf455fc2c3f3ff7d35deb231e988c34,Fix new pip install issues,MERGED,2020-11-30 15:48:01.000000000,2020-11-30 23:41:21.000000000,2020-11-30 23:40:06.000000000,"[{'_account_id': 9592}, {'_account_id': 9976}, {'_account_id': 12393}, {'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2020-11-30 15:48:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-quickstart/commit/f6b1d40d7961e061a03c02d53e53d10f93e77bae', 'message': 'do not pin cmd2, let requirements do it\n\nCloses-Bug: #1906265\nChange-Id: I8ece0610abf455fc2c3f3ff7d35deb231e988c34\n'}, {'number': 2, 'created': '2020-11-30 16:15:20.000000000', 'files': ['requirements.txt', 'quickstart-extras-requirements.txt', 'config/general_config/deprecated/featureset053.yml'], 'web_link': 'https://opendev.org/openstack/tripleo-quickstart/commit/1241789e7de9cbba32a49c0282c90e45f570a8fa', 'message': 'Fix new pip install issues\n\ncmd2 was failing.\nAlso pyrsistent>=0.17.0 from browbeat.\n * remove browbeat from tqe-requirements\n\nCloses-Bug: #1906265\nChange-Id: I8ece0610abf455fc2c3f3ff7d35deb231e988c34\n'}]",0,764778,1241789e7de9cbba32a49c0282c90e45f570a8fa,12,5,2,9592,,,0,"Fix new pip install issues

cmd2 was failing.
Also pyrsistent>=0.17.0 from browbeat.
 * remove browbeat from tqe-requirements

Closes-Bug: #1906265
Change-Id: I8ece0610abf455fc2c3f3ff7d35deb231e988c34
",git fetch https://review.opendev.org/openstack/tripleo-quickstart refs/changes/78/764778/2 && git format-patch -1 --stdout FETCH_HEAD,['requirements.txt'],1,f6b1d40d7961e061a03c02d53e53d10f93e77bae,,cmd2>=0.8.5,cmd2==0.8.5,1,1
openstack%2Ftripleo-upgrade~stable%2Fvictoria~I50426d2cc296e237fa8a8cf6c750e760b0992dd2,openstack/tripleo-upgrade,stable/victoria,I50426d2cc296e237fa8a8cf6c750e760b0992dd2,Add the -n flag in the run parameters conversion script,MERGED,2020-11-30 10:23:48.000000000,2020-11-30 23:40:10.000000000,2020-11-30 23:40:10.000000000,"[{'_account_id': 11090}, {'_account_id': 22348}, {'_account_id': 32704}]","[{'number': 1, 'created': '2020-11-30 10:23:48.000000000', 'files': ['tasks/common/convert_nic_template.yaml', 'defaults/main.yml'], 'web_link': 'https://opendev.org/openstack/tripleo-upgrade/commit/ee59660fe8a280c89c47996628dd2cfe17a75a1f', 'message': 'Add the -n flag in the run parameters conversion script\n\nThe FFU procedure will fail to adjust the NIC templates for environments with composable roles because it will point to the default network data file. In order to circumvent this, we want to provide a means to provide custom network data, which is done by adding the -n flag to the run parameters conversion script.\n\nChange-Id: I50426d2cc296e237fa8a8cf6c750e760b0992dd2\n(cherry picked from commit 19e50866d700dd9440c05a00972632942c0e1072)\n'}]",0,764621,ee59660fe8a280c89c47996628dd2cfe17a75a1f,6,3,1,10459,,,0,"Add the -n flag in the run parameters conversion script

The FFU procedure will fail to adjust the NIC templates for environments with composable roles because it will point to the default network data file. In order to circumvent this, we want to provide a means to provide custom network data, which is done by adding the -n flag to the run parameters conversion script.

Change-Id: I50426d2cc296e237fa8a8cf6c750e760b0992dd2
(cherry picked from commit 19e50866d700dd9440c05a00972632942c0e1072)
",git fetch https://review.opendev.org/openstack/tripleo-upgrade refs/changes/21/764621/1 && git format-patch -1 --stdout FETCH_HEAD,"['tasks/common/convert_nic_template.yaml', 'defaults/main.yml']",2,ee59660fe8a280c89c47996628dd2cfe17a75a1f,composable_role_fix,"# default network_data.yaml default_network_data: ""{{ tht_directory }}/network_data.yaml"" ",,4,0
openstack%2Fironic~master~I444b978dbcb55cb9ae45bd67c0dc6565dee39b40,openstack/ironic,master,I444b978dbcb55cb9ae45bd67c0dc6565dee39b40,Add admin-only provisioner reference arch,ABANDONED,2018-07-27 16:55:32.000000000,2020-11-30 23:31:49.000000000,,"[{'_account_id': 10239}, {'_account_id': 11292}, {'_account_id': 11655}, {'_account_id': 12356}, {'_account_id': 14208}, {'_account_id': 14629}, {'_account_id': 19339}, {'_account_id': 22348}, {'_account_id': 24828}]","[{'number': 1, 'created': '2018-07-27 16:55:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/627cddce814441aeccc9ffb12a20cd681ba6baf9', 'message': ""Add admin-only provisioner reference arch\n\nAdding documentation that hopefully fits the reference\narchitecture needs of admin-only deployments, geared to\nlarger/frequent deployments but also contrasting some of\nthe differences and different networks in one document.\n\nI did so because I'm not entirely convinced that there is\na reference architecture need for small scale/infrequent,\nand most differences are going to be business needs driven\nnot workload wise.\n\nChange-Id: I444b978dbcb55cb9ae45bd67c0dc6565dee39b40\nStory: #2001745\nTask: #12103\nTask: #12107\n""}, {'number': 2, 'created': '2018-07-30 20:16:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/f6157b9c8e3543c6440dd7fa7d254ac17b5bd40a', 'message': ""Add admin-only provisioner reference arch\n\nAdding documentation that hopefully fits the reference\narchitecture needs of admin-only deployments, geared to\nlarger/frequent deployments but also contrasting some of\nthe differences and different networks in one document.\n\nI did so because I'm not entirely convinced that there is\na reference architecture need for small scale/infrequent,\nand most differences are going to be business needs driven\nnot workload wise.\n\nChange-Id: I444b978dbcb55cb9ae45bd67c0dc6565dee39b40\nStory: #2001745\nTask: #12103\nTask: #12107\n""}, {'number': 3, 'created': '2018-08-07 19:48:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/b3409390b6c5485b8f96739c728eef96755c8a0e', 'message': ""Add admin-only provisioner reference arch\n\nAdding documentation that hopefully fits the reference\narchitecture needs of admin-only deployments, geared to\nlarger/frequent deployments but also contrasting some of\nthe differences and different networks in one document.\n\nI did so because I'm not entirely convinced that there is\na reference architecture need for small scale/infrequent,\nand most differences are going to be business needs driven\nnot workload wise.\n\nChange-Id: I444b978dbcb55cb9ae45bd67c0dc6565dee39b40\nStory: #2001745\nTask: #12103\nTask: #12107\n""}, {'number': 4, 'created': '2018-08-20 21:01:43.000000000', 'files': ['doc/source/install/refarch/index.rst', 'doc/source/install/refarch/datacenter-hardware-management.rst'], 'web_link': 'https://opendev.org/openstack/ironic/commit/43e42c3d7244ccd5ca19f261678352e3b19e1187', 'message': ""Add admin-only provisioner reference arch\n\nAdding documentation that hopefully fits the reference\narchitecture needs of admin-only deployments, geared to\nlarger/frequent deployments but also contrasting some of\nthe differences and different networks in one document.\n\nI did so because I'm not entirely convinced that there is\na reference architecture need for small scale/infrequent,\nand most differences are going to be business needs driven\nnot workload wise.\n\nChange-Id: I444b978dbcb55cb9ae45bd67c0dc6565dee39b40\nStory: #2001745\nTask: #12103\nTask: #12107\n""}]",65,586618,43e42c3d7244ccd5ca19f261678352e3b19e1187,22,9,4,11655,,,0,"Add admin-only provisioner reference arch

Adding documentation that hopefully fits the reference
architecture needs of admin-only deployments, geared to
larger/frequent deployments but also contrasting some of
the differences and different networks in one document.

I did so because I'm not entirely convinced that there is
a reference architecture need for small scale/infrequent,
and most differences are going to be business needs driven
not workload wise.

Change-Id: I444b978dbcb55cb9ae45bd67c0dc6565dee39b40
Story: #2001745
Task: #12103
Task: #12107
",git fetch https://review.opendev.org/openstack/ironic refs/changes/18/586618/4 && git format-patch -1 --stdout FETCH_HEAD,"['doc/source/install/refarch/index.rst', 'doc/source/install/refarch/datacenter-hardware-management.rst']",2,627cddce814441aeccc9ffb12a20cd681ba6baf9,586618,"Datacenter Hardware Management ============================== Story ----- As a user and operator I would like the ability to manage my bare metal infrastructure in a vendor agnostic and programmatic fashion. I do not need nor care about virtualization at this level, as my operational focus is the bare metal resources in the data center. Components ---------- This architecture assumes a lightweight installation that can be scaled to meet the datacenter operational needs. While this can be similar to using an `an OpenStack installation`_, it does not necessarily require it. Services that integrate well in this use case are, but may not be needed depending on operational needs or processes: * The `Networking service`_ provides DHCP for bare metal instances. * The `Bare Metal Introspection service`_ simplifies enrolling new bare metal machines by conducting in-band introspection. It must be stressed that without the `Compute service`_, management of the provisioning of bare metal nodes must be performed by the operator using command, Ansible Playbooks, Rest API calls, or other mechanisms. Node roles ---------- An OpenStack installation in this guide has at least these three types of nodes: * A *controller* node hosts the control plane services. The *controller* nodes host the Bare Metal service components. Networking ---------- The networking architecture will highly depend on the exact operating requirements. Two networks are generally expected for the management of bare metal nodes: A *bare metal* network, and a *management* network. Additional networks may exist, and architectures above and beyond a single flat network may be used with additional (manual) configuration of DHCP or DHCP relaying for the deployment of nodes. Scenarios such as this would be similar to a spine-and-leaf style infrastructure where Top-of-Rack (TOR) switches perform L3 routing. If bare metal nodes are statically attached to additional networks, then it is best for Ironic to not be aware of the interface MAC addresses, or *ports* in ironic terminology. If there is any desire to allocate network interfaces to specific virtual networks, then the `Networking service`_ integration will be required. In such a case, all *ports* must be known by ironic. .. TODO(TheJulia): a nice picture (or three) to illustrate the layout Bare metal network ~~~~~~~~~~~~~~~~~ The *Bare metal network* is the dedicated infrastructure connecting bare metal nodes for all purposes beyond Out-of-Band Management. Bare metal nodes *can* be statically attached to other networks, however this increases operational deployment time depending on network interface boot order, and additional brings additional risk where the Deployment Ramdisk used to write Operating System images to the local storage and wipe the local storage contents after deployment becomes a potential point of exposure. If bare metal nodes are statically attached to additional networks, then it is best for Ironic to not be aware of the interface MAC addresses, or *ports* in ironic terminology. This will govern how the Bare Metal Intropection service is configured and leveraged. If there is any desire to allocate network interfaces to specific virtual networks, then the `Networking service`_ integration will be required. In such a case, all *ports* must be known by ironic. Doing so enables greater operational security by enabling *provisioning*, *cleaning*, and *rescue* operations to take place on a separate VLAN. In this scenario, if the Bare Metal Intropection service is utilized, it is advisable that the default network for the switch ports is leveraged for this to support node discovery. This also helps reduce physical interface port configuration conflicts with Networking service plugins as some plugins expect the initial port state in the switch configuration to be at a vendor default for the ports under its management. .. TODO(TheJulia): We should split these into two subsections to be able to properly delineate them. If the Networking service is not leveraged, then DHCP configuration will need to be used to point the bare metal nodes to an initial PXE boot loader that should be hosted by the node hosting the ``ironic-conductor`` process. Ultimately, as long as the DHCP configuration points to the node hosting the ``ironic-conductor`` process, where ``/tftpboot`` is managed, the conductor will be able to supply sufficent configuration to boot the node and supply the URL to reach an ``ironic-api`` API endpoint. For users with iPXE, the same applies, although in those cases it would be whatever node hosts the HTTP URL hosting ``/httpboot``. .. NOTE:: The Bare Metal as a Service team recommends the use if iPXE where possible as it provides the greatest amount of operator flexibility and performance via the use of HTTP(S) based connections. .. TODO(TheJulia): Add information about conductor_groups? Management network ~~~~~~~~~~~~~~~~~ *Management network* is an independent network on which BMCs of the bare metal nodes are located. The ``ironic-conductor`` process needs access to this network. The tenants or users of the bare metal nodes must not have access to it. This network does not have to be physically attached to the *controllers* hosting the ``ironic-conductor``, and routed access can be used. If separate data centers or environments exist, the ``conductor_group`` option would be advisable to constrain the management domain for the ``ironic-conductor`` processes. Controllers ----------- A *controller* in this context is a node that hosts the ``ironic-api``, ``ironic-conductor`` and the Authentication servie (if desired). This can be a *controller* that is part of a larger OpenStack deployment that has been deployed in alignment with the `control plane design guide`_ or as individual components. .. TODO(TheJulia): It feels like more should be said here. Perhaps mention bifrost, metalsmith? Bare Metal services ~~~~~~~~~~~~~~~~~~ The following components of the Bare Metal service are installed on a *controller* (see :ref:`components of the Bare Metal service <refarch-common-components>`): * The Bare Metal API service either as a WSGI application or the ``ironic-api`` process. Typically, a load balancer, such as HAProxy, spreads the load between the API instances on the *controllers*. The API has to be served on the *control plane network*. Additionally, it has to be exposed to the *bare metal network* for the ramdisk callback API. * The ``ironic-conductor`` process. These processes work in active/active HA mode as explained in :ref:`refarch-common-ha`, thus they can be installed on all *controllers*. Each will handle a subset of bare metal nodes. The ``ironic-conductor`` processes have to have access to the following networks: * *management* for contacting node's BMCs * *bare metal* for contacting deployment, cleaning or rescue ramdisks * TFTP and HTTP service for booting the nodes. Each ``ironic-conductor`` process has to have a matching TFTP and HTTP service. They should be exposed only to the *bare metal network* and must not be behind a load balancer. If using the Networking service: * The networking-baremetal_ ML2 plugin should be loaded into the Networking service to assist with binding bare metal ports. The ironic-neutron-agent_ service should be started as well. .. NOTE:: This plugin does not facilitate automation of switch port interfaces on individual switches in a Date Center. For that functionality, a vendor specific ML2 plugin is required. * If the Bare Metal introspection is used, its ``ironic-inspector`` process has to be installed on all *controllers*. Each such process works as both Bare Metal Introspection API and conductor service. A load balancer should be used to spread the API load between *controllers*. The API has to be served on the *control plane network*. Additionally, it has to be exposed to the *bare metal network* for the ramdisk callback API. .. NOTE(TheJulia): Why all controllers? That doesn't seem necessary in all cases. perhaps it is recommended instead?? .. TODO(dtantsur): a nice picture to illustrate the above Shared services ~~~~~~~~~~~~~~ A *controller* also hosts two services required for the normal operation of OpenStack: * Database service (MySQL/MariaDB is typically used, but other enterprise-grade database solutions can be used as well). All Bare Metal service components need access to the database service. * Message queue service (RabbitMQ is typically used, but other enterprise-grade message queue brokers can be used as well). Both Bare Metal API (WSGI application or ``ironic-api`` process) and the ``ironic-conductor`` processes need access to the message queue service. The Bare Metal Introspection service does not need it. .. note:: These services are required for all OpenStack services. If you're adding the Bare Metal service to your cloud, you may reuse the existing database and messaging queue services. Bare metal nodes ---------------- Each bare metal node must be capable of booting from network, virtual media or other boot technology supported by the Bare Metal service as explained in :ref:`refarch-common-boot`. Each node must have at-least one NIC on the *bare metal network*, and this NIC must be configured to be able to boot from network. This is usually done in the *BIOS setup* or a similar firmware settings. The NIC on the *bare metal network* should have untagged connectivity to it, since PXE firmware usually does not support VLANs - see :ref:`refarch-common-networking` for details. .. _an OpenStack installation: https://docs.openstack.org/arch-design/use-cases/use-case-general-compute.html .. _Compute service: https://docs.openstack.org/nova/latest/ .. _Networking service: https://docs.openstack.org/neutron/latest/ .. _Bare Metal Introspection service: https://docs.openstack.org/ironic-inspector/latest/ .. _control plane design guide: https://docs.openstack.org/arch-design/design-control-plane.html .. _networking-baremetal: https://docs.openstack.org/networking-baremetal/latest/ .. _ironic-neutron-agent: https://docs.openstack.org/networking-baremetal/latest/install/index.html#configure-ironic-neutron-agent ",,245,0
openstack%2Fkolla~master~I97f38a920e4d797fd37e2e124993bdf913266b12,openstack/kolla,master,I97f38a920e4d797fd37e2e124993bdf913266b12,Support Shibboleth service provider for keystone to keystone.,ABANDONED,2019-10-23 06:54:30.000000000,2020-11-30 23:08:08.000000000,,"[{'_account_id': 22348}, {'_account_id': 22629}, {'_account_id': 23181}, {'_account_id': 28910}, {'_account_id': 30491}]","[{'number': 1, 'created': '2019-10-23 06:54:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla/commit/fa4f90e7f1c0b6e84c0bce0742bc2c271a5227f9', 'message': 'Support Shibboleth service provider for keystone to keystone.\n\nUse keystone as identity provider and Shibboleth as service\nprovider in login multi-cloud.\n\nChange-Id: I97f38a920e4d797fd37e2e124993bdf913266b12\n'}, {'number': 2, 'created': '2019-10-23 07:21:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla/commit/ea0aa4441b024fd19d5998b8f73d58f91d9edb66', 'message': 'Support Shibboleth service provider for keystone to keystone.\n\nUse keystone as identity provider and Shibboleth as service\nprovider in login multi-cloud.\n\nChange-Id: I97f38a920e4d797fd37e2e124993bdf913266b12\n'}, {'number': 3, 'created': '2020-11-05 02:35:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla/commit/c773ff538ebd94a23a8d918666563440abae8be9', 'message': 'Support Shibboleth service provider for keystone to keystone.\n\nUse keystone as identity provider and Shibboleth as service\nprovider in login multi-cloud.\n\nChange-Id: I97f38a920e4d797fd37e2e124993bdf913266b12\n'}, {'number': 4, 'created': '2020-11-05 06:45:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla/commit/0413b537eeaea3d644ff1fbda34a93394c66d623', 'message': 'Support Shibboleth service provider for keystone to keystone.\n\nUse keystone as identity provider and Shibboleth as service\nprovider in login multi-cloud.\n\nChange-Id: I97f38a920e4d797fd37e2e124993bdf913266b12\n'}, {'number': 5, 'created': '2020-11-06 07:48:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla/commit/403b11ef78f2e17bb0ced0b9eef087ac37a56b6b', 'message': 'Support Shibboleth service provider for keystone to keystone.\n\nUse keystone as identity provider and Shibboleth as service\nprovider in login multi-cloud.\n\nChange-Id: I97f38a920e4d797fd37e2e124993bdf913266b12\n'}, {'number': 6, 'created': '2020-11-06 07:51:32.000000000', 'files': ['docker/keystone/keystone-shibboleth/extend_start.sh', 'docker/keystone/keystone-shibboleth/Dockerfile.j2', 'docker/base/Dockerfile.j2', 'docker/base/shibboleth.repo', 'docker/keystone/keystone-base/Dockerfile.j2', 'releasenotes/notes/support-shibboleth-59e66d00d745fd02.yaml', 'kolla/template/repos.yaml'], 'web_link': 'https://opendev.org/openstack/kolla/commit/14e4dea012652be0f408ac79bf01a989917a31bf', 'message': 'Support Shibboleth service provider for keystone to keystone.\n\nUse keystone as identity provider and Shibboleth as service\nprovider in login multi-cloud.\n\nChange-Id: I97f38a920e4d797fd37e2e124993bdf913266b12\n'}]",8,690478,14e4dea012652be0f408ac79bf01a989917a31bf,34,5,6,28910,,,0,"Support Shibboleth service provider for keystone to keystone.

Use keystone as identity provider and Shibboleth as service
provider in login multi-cloud.

Change-Id: I97f38a920e4d797fd37e2e124993bdf913266b12
",git fetch https://review.opendev.org/openstack/kolla refs/changes/78/690478/3 && git format-patch -1 --stdout FETCH_HEAD,"['docker/keystone/keystone-shibboleth/extend_start.sh', 'docker/keystone/keystone-shibboleth/Dockerfile.j2', 'docker/base/Dockerfile.j2', 'docker/base/shibboleth.repo', 'docker/keystone/keystone-base/Dockerfile.j2', 'releasenotes/notes/support-shibboleth-59e66d00d745fd02.yaml']",6,fa4f90e7f1c0b6e84c0bce0742bc2c271a5227f9,bp/K2K_shibboleth,--- features: - Support Shibboleth service provider in integrating keystone to keystone for RHEL/CENTOS distro. ,,47,2
openstack%2Fdevstack~stable%2Ftrain~I1feed4573820436f91f8f654cc189fa3a21956fd,openstack/devstack,stable/train,I1feed4573820436f91f8f654cc189fa3a21956fd,Workaround for new pip 20.3 behavior,ABANDONED,2020-11-30 22:54:46.000000000,2020-11-30 22:56:15.000000000,,[{'_account_id': 17685}],"[{'number': 1, 'created': '2020-11-30 22:54:46.000000000', 'files': ['tools/install_pip.sh'], 'web_link': 'https://opendev.org/openstack/devstack/commit/fd8958b26aa1f7c690fb33853c457ce0931a8ad8', 'message': 'Workaround for new pip 20.3 behavior\n\nThis patch caps pip version during bootstrap to avoid the issue:\n\n""ERROR: Links are not allowed as constraints""\n\nA proper fix would be to adapt to new pip behavior.\n\nDepends-On: https://review.opendev.org/764811\nChange-Id: I1feed4573820436f91f8f654cc189fa3a21956fd\n'}]",0,764877,fd8958b26aa1f7c690fb33853c457ce0931a8ad8,2,1,1,8556,,,0,"Workaround for new pip 20.3 behavior

This patch caps pip version during bootstrap to avoid the issue:

""ERROR: Links are not allowed as constraints""

A proper fix would be to adapt to new pip behavior.

Depends-On: https://review.opendev.org/764811
Change-Id: I1feed4573820436f91f8f654cc189fa3a21956fd
",git fetch https://review.opendev.org/openstack/devstack refs/changes/77/764877/1 && git format-patch -1 --stdout FETCH_HEAD,['tools/install_pip.sh'],1,fd8958b26aa1f7c690fb33853c457ce0931a8ad8,,<<<<<<< HEAD (1b3558 Use SETUPTOOLS_USE_DISTUTILS=stdlib for global pip installs)======= # TODO: remove the trailing pip constraint when a proper fix # arrives for bug https://bugs.launchpad.net/devstack/+bug/1906322 sudo -H -E python${PYTHON3_VERSION} $LOCAL_PIP 'pip<20.3' if ! python3_enabled; then sudo -H -E python $LOCAL_PIP 'pip<20.3' >>>>>>> CHANGE (dee5c9 Workaround for new pip 20.3 behavior),,8,0
openstack%2Fsenlin~master~I43f1181c1592144d49784ba0d3c51c01bf2f1060,openstack/senlin,master,I43f1181c1592144d49784ba0d3c51c01bf2f1060,Perform port update if security group changed,MERGED,2020-11-25 00:02:03.000000000,2020-11-30 22:43:40.000000000,2020-11-30 22:42:13.000000000,"[{'_account_id': 8246}, {'_account_id': 22348}, {'_account_id': 22623}, {'_account_id': 30596}]","[{'number': 1, 'created': '2020-11-25 00:02:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/senlin/commit/8892141ed425eb9367f582232613ee26501c8f14', 'message': 'Perform port update if security group changed\n\nIf only the security groups for a network changed in a profile, do not\ndelete and recreate the network during a profile update.  Instead apply\nthe security group change by an update to the existing port.\n\nCloses-Bug: bug/1905490\nChange-Id: I43f1181c1592144d49784ba0d3c51c01bf2f1060\n'}, {'number': 2, 'created': '2020-11-25 16:55:49.000000000', 'files': ['senlin/profiles/os/nova/server.py', 'senlin/tests/unit/profiles/test_nova_server_update.py'], 'web_link': 'https://opendev.org/openstack/senlin/commit/6dff71e13f4752c02b5c119d25f3e31a93ade1bf', 'message': 'Perform port update if security group changed\n\nIf only the security groups for a network changed in a profile, do not\ndelete and recreate the network during a profile update.  Instead apply\nthe security group change by an update to the existing port.\n\nCloses-Bug: #1905490\nChange-Id: I43f1181c1592144d49784ba0d3c51c01bf2f1060\n'}]",0,764097,6dff71e13f4752c02b5c119d25f3e31a93ade1bf,11,4,2,27224,,,0,"Perform port update if security group changed

If only the security groups for a network changed in a profile, do not
delete and recreate the network during a profile update.  Instead apply
the security group change by an update to the existing port.

Closes-Bug: #1905490
Change-Id: I43f1181c1592144d49784ba0d3c51c01bf2f1060
",git fetch https://review.opendev.org/openstack/senlin refs/changes/97/764097/2 && git format-patch -1 --stdout FETCH_HEAD,"['senlin/profiles/os/nova/server.py', 'senlin/tests/unit/profiles/test_nova_server_update.py']",2,8892141ed425eb9367f582232613ee26501c8f14,sg_only_update," def test_update_port(self): cc = mock.Mock() cc.server_get.return_value = mock.Mock(status=consts.VS_ACTIVE) nc = mock.Mock() net1 = mock.Mock(id='net1') nc.network_get.return_value = net1 nc.port_find.return_value = mock.Mock(id='port3', status='DOWN') profile = server.ServerProfile('t', self.spec) profile.stop_timeout = 232 profile._computeclient = cc profile._networkclient = nc validation_results = [ {'network': 'net1_id', 'fixed_ip': 'ip1', 'security_groups': ['sg1_id']}, {'network': 'net1_id', 'fixed_ip': 'ip1', 'security_groups': ['sg1_id', 'sg2_id']}, {'network': 'net1_id', 'fixed_ip': 'ip1'} ] mock_validate = self.patchobject(profile, '_validate_network', side_effect=validation_results) candidate_ports = [ [{'id': 'port1_id', 'network_id': 'net1_id', 'fixed_ips': [{'ip_address': 'ip1'}]}], [{'id': 'port2_id', 'network_id': 'net1_id', 'fixed_ips': [{'ip_address': 'ip1'}]}], [{'id': 'port3_id', 'network_id': 'net1_id', 'fixed_ips': [{'ip_address': 'ip1'}]}] ] self.patchobject(profile, '_find_port_by_net_spec', side_effect=candidate_ports) obj = mock.Mock(physical_id='NOVA_ID', data={'internal_ports': [ {'id': 'port1', 'network_id': 'net1', 'fixed_ips': [{'ip_address': 'ip1'}]}, {'id': 'port2', 'network_id': 'net1', 'remove': True, 'fixed_ips': [{'ip_address': 'ip-random2'}], 'security_groups': ['default']}, {'id': 'port3', 'network_id': 'net1', 'remove': True, 'fixed_ips': [{'ip_address': 'ip3'}], 'security_groups': ['default']} ]}) networks = [ {'network': 'net1', 'port': None, 'fixed_ip': 'ip1', 'security_groups': ['default'], 'floating_network': None, 'floating_ip': None}, {'network': 'net1', 'port': None, 'fixed_ip': 'ip1', 'security_groups': ['default', 'blah'], 'floating_network': None, 'floating_ip': None}, {'network': 'net1', 'port': None, 'fixed_ip': 'ip1', 'security_groups': None, 'floating_network': None, 'floating_ip': None}, ] res = profile._update_network_update_port(obj, networks) self.assertIsNone(res) validation_calls = [ mock.call(obj, {'network': 'net1', 'port': None, 'fixed_ip': 'ip1', 'security_groups': ['default'], 'floating_network': None, 'floating_ip': None}, 'update'), mock.call(obj, {'network': 'net1', 'port': None, 'fixed_ip': 'ip1', 'security_groups': ['default', 'blah'], 'floating_network': None, 'floating_ip': None}, 'update'), mock.call(obj, {'network': 'net1', 'port': None, 'fixed_ip': 'ip1', 'security_groups': None, 'floating_network': None, 'floating_ip': None}, 'update') ] mock_validate.assert_has_calls(validation_calls) update_calls = [ mock.call('port1_id', security_groups=['sg1_id']), mock.call('port2_id', security_groups=['sg1_id', 'sg2_id']), mock.call('port3_id', security_groups=[]), ] nc.port_update.assert_has_calls(update_calls) @mock.patch.object(server.ServerProfile, '_update_network_update_port') def test_update_network(self, mock_create, mock_delete, mock_update): # sg only changes: {'network': 'net3', 'fixed_ip': 'ip1'}, {'network': 'net4', 'fixed_ip': 'ip1', 'security_groups': ['blah']}, {'port': 'port5', 'security_groups': ['default']}, # sg only changes: {'network': 'net3', 'fixed_ip': 'ip1', 'security_groups': ['default']}, {'network': 'net4', 'fixed_ip': 'ip1', 'security_groups': ['default']}, {'port': 'port5', 'security_groups': ['default', 'blah']}, networks_update = [ {'network': 'net3', 'port': None, 'fixed_ip': 'ip1', 'security_groups': ['default'], 'floating_network': None, 'floating_ip': None}, {'network': 'net4', 'port': None, 'fixed_ip': 'ip1', 'security_groups': ['default'], 'floating_network': None, 'floating_ip': None}, {'network': None, 'port': 'port5', 'fixed_ip': None, 'security_groups': ['default', 'blah'], 'floating_network': None, 'floating_ip': None} ] mock_update.assert_called_once_with(obj, networks_update)"," def test_update_network(self, mock_create, mock_delete):",173,5
openstack%2Ftrove~stable%2Fvictoria~Ic4e2c79f48bfcaea806babbf50d4757a9c153132,openstack/trove,stable/victoria,Ic4e2c79f48bfcaea806babbf50d4757a9c153132,Get slave_pos to choose latest replica,MERGED,2020-11-30 09:02:25.000000000,2020-11-30 22:41:30.000000000,2020-11-30 22:40:20.000000000,"[{'_account_id': 6732}, {'_account_id': 22348}]","[{'number': 1, 'created': '2020-11-30 09:02:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/trove/commit/887235171ce5cf9c97d8357a0541201d5353c93c', 'message': 'Get slave_pos to choose latest replica\n\nLatest replica have slave_pos biggest, so we just need use slave_pos to\ncompare replicas.\n\nChange-Id: Ic4e2c79f48bfcaea806babbf50d4757a9c153132\n'}, {'number': 2, 'created': '2020-11-30 09:56:58.000000000', 'files': ['trove/guestagent/datastore/mariadb/service.py'], 'web_link': 'https://opendev.org/openstack/trove/commit/753252ab1c2248831403b04ebb4652d083c6278b', 'message': 'Get slave_pos to choose latest replica\n\nLatest replica have slave_pos biggest, so we just need use slave_pos to\ncompare replicas.\n\nChange-Id: Ic4e2c79f48bfcaea806babbf50d4757a9c153132\n(cherry picked from commit df82af30f21b89097597bf471c2aa5a08d19386c)\n'}]",0,764507,753252ab1c2248831403b04ebb4652d083c6278b,8,2,2,31662,,,0,"Get slave_pos to choose latest replica

Latest replica have slave_pos biggest, so we just need use slave_pos to
compare replicas.

Change-Id: Ic4e2c79f48bfcaea806babbf50d4757a9c153132
(cherry picked from commit df82af30f21b89097597bf471c2aa5a08d19386c)
",git fetch https://review.opendev.org/openstack/trove refs/changes/07/764507/2 && git format-patch -1 --stdout FETCH_HEAD,['trove/guestagent/datastore/mariadb/service.py'],1,887235171ce5cf9c97d8357a0541201d5353c93c,, def _get_gtid_slave_executed(self): with mysql_util.SqlClient(self.get_engine()) as client: return client.execute('SELECT @@global.gtid_slave_pos').first()[0] gtid_executed = self._get_gtid_slave_executed(), gtid_executed = self._get_gtid_executed(),5,1
openstack%2Fcharms.openstack~master~I421b52d502644b52f4e31162e74dea8a1befdfa0,openstack/charms.openstack,master,I421b52d502644b52f4e31162e74dea8a1befdfa0,"Checked if release_pkg is set. If not, ensure a RuntimeError raised. Added test case to verify RuntimeError is raised when release_pkg is not set.",MERGED,2020-11-29 23:00:11.000000000,2020-11-30 22:04:28.000000000,2020-11-30 22:04:28.000000000,"[{'_account_id': 20805}, {'_account_id': 22348}]","[{'number': 1, 'created': '2020-11-29 23:00:11.000000000', 'files': ['unit_tests/charms_openstack/charm/test_defaults.py', 'charms_openstack/charm/defaults.py'], 'web_link': 'https://opendev.org/openstack/charms.openstack/commit/8c2283a50849520eda3955f9599864f8f227fcc1', 'message': 'Checked if release_pkg is set. If not, ensure a RuntimeError raised.\nAdded test case to verify RuntimeError is raised when release_pkg is not set.\n\nCloses-Bug: #1904494\nChange-Id: I421b52d502644b52f4e31162e74dea8a1befdfa0\n'}]",0,764595,8c2283a50849520eda3955f9599864f8f227fcc1,6,2,1,32578,,,0,"Checked if release_pkg is set. If not, ensure a RuntimeError raised.
Added test case to verify RuntimeError is raised when release_pkg is not set.

Closes-Bug: #1904494
Change-Id: I421b52d502644b52f4e31162e74dea8a1befdfa0
",git fetch https://review.opendev.org/openstack/charms.openstack refs/changes/95/764595/1 && git format-patch -1 --stdout FETCH_HEAD,"['unit_tests/charms_openstack/charm/test_defaults.py', 'charms_openstack/charm/defaults.py']",2,8c2283a50849520eda3955f9599864f8f227fcc1,bug/1904494," if singleton.release_pkg is None: raise RuntimeError(""release_pkg is not set"")",,8,0
openstack%2Fkolla-ansible~stable%2Ftrain~I2fe6eb13ce7be68d346b1b3b7036859f34c896c4,openstack/kolla-ansible,stable/train,I2fe6eb13ce7be68d346b1b3b7036859f34c896c4,Fix kolla-ansible to work with pyenv-virtualenv,MERGED,2020-11-19 13:34:30.000000000,2020-11-30 21:58:56.000000000,2020-11-30 21:57:44.000000000,"[{'_account_id': 14826}, {'_account_id': 22348}, {'_account_id': 30491}, {'_account_id': 32662}]","[{'number': 1, 'created': '2020-11-19 13:34:30.000000000', 'files': ['tools/kolla-ansible'], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/1aa3ab5e5b0aee1d28ae910f9d645c09b449c82e', 'message': 'Fix kolla-ansible to work with pyenv-virtualenv\n\nOne of the pyenv-virtualenv-set-up aliases depends on a symlink.\nIt seems pyenv runs the bash script from such a path and it fails\nbecause of a failing comparison (VIRTUAL_ENV not detected).\n\nThe VIRTUAL_ENV is ensured to be fully resolved as well for safety.\n\nThis requires readlink from GNU coreutils but all supported platforms\nhave it by default.\n\nExtra comments included, as well as simplification of directory\ndetection - readlink handles this (not that `bin` itself was\never a symlink...).\n\nCloses-Bug: #1903887\nCo-Authored-By: Radosaw Piliszek <radoslaw.piliszek@gmail.com>\nChange-Id: I2fe6eb13ce7be68d346b1b3b7036859f34c896c4\n(cherry picked from commit aaab1d1b68db0c737b63ae6bce3179df0487f23f)\n'}]",0,763368,1aa3ab5e5b0aee1d28ae910f9d645c09b449c82e,14,4,1,30491,,,0,"Fix kolla-ansible to work with pyenv-virtualenv

One of the pyenv-virtualenv-set-up aliases depends on a symlink.
It seems pyenv runs the bash script from such a path and it fails
because of a failing comparison (VIRTUAL_ENV not detected).

The VIRTUAL_ENV is ensured to be fully resolved as well for safety.

This requires readlink from GNU coreutils but all supported platforms
have it by default.

Extra comments included, as well as simplification of directory
detection - readlink handles this (not that `bin` itself was
ever a symlink...).

Closes-Bug: #1903887
Co-Authored-By: Radosaw Piliszek <radoslaw.piliszek@gmail.com>
Change-Id: I2fe6eb13ce7be68d346b1b3b7036859f34c896c4
(cherry picked from commit aaab1d1b68db0c737b63ae6bce3179df0487f23f)
",git fetch https://review.opendev.org/openstack/kolla-ansible refs/changes/68/763368/1 && git format-patch -1 --stdout FETCH_HEAD,['tools/kolla-ansible'],1,1aa3ab5e5b0aee1d28ae910f9d645c09b449c82e,BUG-1903887-stable/victoria-stable/ussuri-stable/train," dir_name=$(dirname ""$0"") # NOTE(yoctozepto): Fix the case where dir_name is a symlink and VIRTUAL_ENV might not be. This # happens with pyenv-virtualenv, see https://bugs.launchpad.net/kolla-ansible/+bug/1903887 dir_name=$(readlink -e ""$dir_name"") elif [[ -n ${VIRTUAL_ENV} ]] && [[ ${dir_name} == ""$(readlink -e ""${VIRTUAL_ENV}/bin"")"" ]]; then # Running from sources (repo)."," dir_name=$(cd ""$(dirname ""$0"")"" &>/dev/null && pwd) elif [[ -n ${VIRTUAL_ENV} ]] && [[ ${dir_name} == ""${VIRTUAL_ENV}/bin"" ]]; then",6,2
openstack%2Fpuppet-designate~master~I8a1861afc2c74fd52836e4b5955bc6bdd929fbf6,openstack/puppet-designate,master,I8a1861afc2c74fd52836e4b5955bc6bdd929fbf6,Deprecate support for configuration of powerdns 3 driver,MERGED,2020-11-25 11:56:18.000000000,2020-11-30 20:45:58.000000000,2020-11-30 20:44:29.000000000,"[{'_account_id': 9414}, {'_account_id': 14985}, {'_account_id': 22348}]","[{'number': 1, 'created': '2020-11-25 11:56:18.000000000', 'files': ['manifests/backend/powerdns.pp', 'spec/classes/designate_db_powerdns_mysql_spec.rb', 'releasenotes/notes/deprecate-support-for-powerdns3-driver-b9b2c520054a5f86.yaml', 'manifests/db/powerdns/sync.pp', 'spec/classes/designate_backend_powerdns_spec.rb', 'manifests/db/powerdns/mysql.pp', 'spec/classes/designate_db_powerdns_sync_spec.rb'], 'web_link': 'https://opendev.org/openstack/puppet-designate/commit/5ce240bc4d9c8fb42bab2a8a719514671d804102', 'message': 'Deprecate support for configuration of powerdns 3 driver\n\n... because it was removed from designate[1]\n\n[1] 660eacbce4b1a4a409cd084a9c9f6e6e8f5e581a\n\nChange-Id: I8a1861afc2c74fd52836e4b5955bc6bdd929fbf6\n'}]",0,764157,5ce240bc4d9c8fb42bab2a8a719514671d804102,8,3,1,9816,,,0,"Deprecate support for configuration of powerdns 3 driver

... because it was removed from designate[1]

[1] 660eacbce4b1a4a409cd084a9c9f6e6e8f5e581a

Change-Id: I8a1861afc2c74fd52836e4b5955bc6bdd929fbf6
",git fetch https://review.opendev.org/openstack/puppet-designate refs/changes/57/764157/1 && git format-patch -1 --stdout FETCH_HEAD,"['manifests/backend/powerdns.pp', 'spec/classes/designate_db_powerdns_mysql_spec.rb', 'releasenotes/notes/deprecate-support-for-powerdns3-driver-b9b2c520054a5f86.yaml', 'manifests/db/powerdns/sync.pp', 'manifests/db/powerdns/mysql.pp', 'spec/classes/designate_backend_powerdns_spec.rb', 'spec/classes/designate_db_powerdns_sync_spec.rb']",7,5ce240bc4d9c8fb42bab2a8a719514671d804102,powerdns,,"# # Unit tests for designate::db::powerdns::sync # require 'spec_helper' describe 'designate::db::powerdns::sync' do shared_examples_for 'designate-db-powerdns-sync' do context 'with default parameters' do it 'runs designate-powerdns-dbsync' do is_expected.to contain_exec('designate-powerdns-dbsync').with( :command => 'designate-manage powerdns sync', :path => '/usr/bin', :user => 'root', :refreshonly => 'true', :logoutput => 'on_failure', :subscribe => ['Anchor[designate::install::end]', 'Anchor[designate::config::end]', 'Anchor[designate::dbsync::begin]'], :notify => 'Anchor[designate::dbsync::end]', ) end end context 'with parameter overrides' do let :params do { :extra_params => '--config-file /etc/designate/designate.conf' } end it 'runs designate manage with diffent config' do is_expected.to contain_exec('designate-powerdns-dbsync').with( :command => 'designate-manage --config-file /etc/designate/designate.conf powerdns sync', :path => '/usr/bin', :user => 'root', :refreshonly => 'true', :logoutput => 'on_failure', :subscribe => ['Anchor[designate::install::end]', 'Anchor[designate::config::end]', 'Anchor[designate::dbsync::begin]'], :notify => 'Anchor[designate::dbsync::end]', ) end end end on_supported_os({ :supported_os => OSDefaults.get_supported_os }).each do |os,facts| context ""on #{os}"" do let (:facts) do facts.merge!(OSDefaults.get_facts()) end it_behaves_like 'designate-db-powerdns-sync' end end end ",18,221
openstack%2Fkolla~stable%2Ftrain~I1184825371724c9a7d0a47331f3912519d94e8b6,openstack/kolla,stable/train,I1184825371724c9a7d0a47331f3912519d94e8b6,Bump OpenStack versions for Train,MERGED,2020-11-25 14:37:40.000000000,2020-11-30 20:24:55.000000000,2020-11-30 20:23:14.000000000,"[{'_account_id': 22348}, {'_account_id': 30491}, {'_account_id': 30523}]","[{'number': 1, 'created': '2020-11-25 14:37:40.000000000', 'files': ['kolla/common/config.py'], 'web_link': 'https://opendev.org/openstack/kolla/commit/2dd1027dd9383fd8a2e8c054f9f90e5a17a50d07', 'message': 'Bump OpenStack versions for Train\n\nChange-Id: I1184825371724c9a7d0a47331f3912519d94e8b6\n'}]",0,764197,2dd1027dd9383fd8a2e8c054f9f90e5a17a50d07,12,3,1,14826,,,0,"Bump OpenStack versions for Train

Change-Id: I1184825371724c9a7d0a47331f3912519d94e8b6
",git fetch https://review.opendev.org/openstack/kolla refs/changes/97/764197/1 && git format-patch -1 --stdout FETCH_HEAD,['kolla/common/config.py'],1,2dd1027dd9383fd8a2e8c054f9f90e5a17a50d07,," 'masakari-dashboard-1.0.1.tar.gz')}, 'masakari-8.1.0.tar.gz')}, 'masakari-monitors-8.0.2.tar.gz')}, 'nova-20.4.1.tar.gz')}, 'octavia-5.0.3.tar.gz')},"," 'masakari-dashboard-1.0.0.tar.gz')}, 'masakari-8.0.0.tar.gz')}, 'masakari-monitors-8.0.1.tar.gz')}, 'nova-20.4.0.tar.gz')}, 'octavia-5.0.2.tar.gz')},",5,5
openstack%2Fansible-collections-openstack~master~I4fd36bf3ed347e020151721a6b56d1cac0a8fd23,openstack/ansible-collections-openstack,master,I4fd36bf3ed347e020151721a6b56d1cac0a8fd23,Refactor loadbalancer module,MERGED,2020-10-09 11:29:57.000000000,2020-11-30 20:20:54.000000000,2020-11-30 20:20:54.000000000,"[{'_account_id': 10969}, {'_account_id': 11628}, {'_account_id': 22348}, {'_account_id': 29260}]","[{'number': 1, 'created': '2020-10-09 11:29:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ansible-collections-openstack/commit/8b887ca0b9adb8ae14464c5e16657ce0b740dda3', 'message': 'Refactor loadbalancer module\n * enable check_mode\n * enable allowed_cidrs on listener if octavia version is >= 2.12\n * Only send flavor_id if it is not None\n\nChange-Id: I4fd36bf3ed347e020151721a6b56d1cac0a8fd23\n'}, {'number': 2, 'created': '2020-10-09 11:32:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ansible-collections-openstack/commit/ff57e43fa4116af616e97dfb0139a0140f932f77', 'message': 'Refactor loadbalancer module\n\n * enable check_mode\n * enable allowed_cidrs on listener if octavia version is >= 2.12\n * Only send flavor_id if it is not None\n\nChange-Id: I4fd36bf3ed347e020151721a6b56d1cac0a8fd23\n'}, {'number': 3, 'created': '2020-10-12 17:14:27.000000000', 'files': ['plugins/modules/loadbalancer.py'], 'web_link': 'https://opendev.org/openstack/ansible-collections-openstack/commit/ab96eb6a11d0f876b00a87a3efbfaaf4a884a6ad', 'message': 'Refactor loadbalancer module\n\n * enable check_mode\n * enable allowed_cidrs on listener if octavia version is >= 2.12\n * Only send flavor_id if it is not None\n\nChange-Id: I4fd36bf3ed347e020151721a6b56d1cac0a8fd23\n'}]",3,757081,ab96eb6a11d0f876b00a87a3efbfaaf4a884a6ad,14,4,3,29260,,,0,"Refactor loadbalancer module

 * enable check_mode
 * enable allowed_cidrs on listener if octavia version is >= 2.12
 * Only send flavor_id if it is not None

Change-Id: I4fd36bf3ed347e020151721a6b56d1cac0a8fd23
",git fetch https://review.opendev.org/openstack/ansible-collections-openstack refs/changes/81/757081/2 && git format-patch -1 --stdout FETCH_HEAD,['plugins/modules/loadbalancer.py'],1,8b887ca0b9adb8ae14464c5e16657ce0b740dda3,," allowed_cidrs: description: - A list of cidrs allowed access to the listener, an emty list means access from any ignored on unsupported Octavia versions (less than 2.12) default: []from ansible_collections.openstack.cloud.plugins.module_utils.openstack import OpenStackModule class LoadBalancerModule(OpenStackModule): def _wait_for_lb(self, lb, status, failures, interval=5): """"""Wait for load balancer to be in a particular provisioning status."""""" timeout = self.params['timeout'] total_sleep = 0 if failures is None: failures = [] while total_sleep < timeout: lb = self.conn.load_balancer.find_load_balancer(lb.id) if lb: if lb.provisioning_status == status: return None if lb.provisioning_status in failures: self.fail_json( msg=""Load Balancer %s transitioned to failure state %s"" % (lb.id, lb.provisioning_status) ) else: if status == ""DELETED"": return None else: self.fail_json( msg=""Load Balancer %s transitioned to DELETED"" % lb.id ) time.sleep(interval) total_sleep += interval self.fail_json( msg=""Timeout waiting for Load Balancer %s to transition to %s"" % (lb.id, status) ) argument_spec = dict( module_kwargs = dict(supports_check_mode=True) def run(self): flavor = self.params['flavor'] vip_network = self.params['vip_network'] vip_subnet = self.params['vip_subnet'] vip_port = self.params['vip_port'] listeners = self.params['listeners'] public_vip_address = self.params['public_ip_address'] allocate_fip = self.params['auto_public_ip'] delete_fip = self.params['delete_public_ip'] public_network = self.params['public_network'] vip_network_id = None vip_subnet_id = None vip_port_id = None flavor_id = None try: max_microversion = 1 max_majorversion = 2 changed = False lb = self.conn.load_balancer.find_load_balancer( name_or_id=self.params['name']) if self.params['state'] == 'present': if lb and self.ansible.check_mode: self.exit_json(changed=False) if lb: self.exit_json(changed=False) ver_data = self.conn.load_balancer.get_all_version_data() region = list(ver_data.keys())[0] interface_type = list(ver_data[region].keys())[0] versions = ver_data[region][interface_type]['load-balancer'] for ver in versions: if ver['status'] == 'CURRENT': curversion = ver['version'].split(""."") max_majorversion = int(curversion[0]) max_microversion = int(curversion[1]) if not lb: if self.ansible.check_mode: self.exit_json(changed=True) if not (vip_network or vip_subnet or vip_port): self.fail_json( msg=""One of vip_network, vip_subnet, or vip_port must "" ""be specified for load balancer creation"" if flavor: _flavor = self.conn.load_balancer.find_flavor(flavor) if not _flavor: self.fail_json( msg='flavor %s not found' % flavor ) flavor_id = _flavor.id if vip_network: network = self.conn.get_network(vip_network) if not network: self.fail_json( msg='network %s is not found' % vip_network ) vip_network_id = network.id if vip_subnet: subnet = self.conn.get_subnet(vip_subnet) if not subnet: self.fail_json( msg='subnet %s is not found' % vip_subnet ) vip_subnet_id = subnet.id if vip_port: port = self.conn.get_port(vip_port) if not port: self.fail_json( msg='port %s is not found' % vip_port ) vip_port_id = port.id lbargs = {""name"": self.params['name'], ""vip_network_id"": vip_network_id, ""vip_subnet_id"": vip_subnet_id, ""vip_port_id"": vip_port_id, ""vip_address"": self.params['vip_address'] } if flavor_id is not None: lbargs[""flavor_id""] = flavor_id lb = self.conn.load_balancer.create_load_balancer(**lbargs) if not listeners and not self.params['wait']: self.exit_json( changed=changed, loadbalancer=lb.to_dict(), id=lb.id ) self._wait_for_lb(lb, ""ACTIVE"", [""ERROR""]) for listener_def in listeners: listener_name = listener_def.get(""name"") pool_def = listener_def.get(""pool"") if not listener_name: self.fail_json(msg='listener name is required') listener = self.conn.load_balancer.find_listener( name_or_id=listener_name ) if not listener: self._wait_for_lb(lb, ""ACTIVE"", [""ERROR""]) protocol = listener_def.get(""protocol"", ""HTTP"") protocol_port = listener_def.get(""protocol_port"", 80) allowed_cidrs = listener_def.get(""allowed_cidrs"", []) listenerargs = {""name"": listener_name, ""loadbalancer_id"": lb.id, ""protocol"": protocol, ""protocol_port"": protocol_port } if max_microversion >= 12 and max_majorversion >= 2: listenerargs['allowed_cidrs'] = allowed_cidrs listener = self.conn.load_balancer.create_listener(**listenerargs) # Ensure pool in the listener. if pool_def: pool_name = pool_def.get(""name"") members = pool_def.get('members', []) if not pool_name: self.fail_json(msg='pool name is required') pool = self.conn.load_balancer.find_pool(name_or_id=pool_name) if not pool: self._wait_for_lb(lb, ""ACTIVE"", [""ERROR""]) protocol = pool_def.get(""protocol"", ""HTTP"") lb_algorithm = pool_def.get(""lb_algorithm"", ""ROUND_ROBIN"") pool = self.conn.load_balancer.create_pool( name=pool_name, listener_id=listener.id, protocol=protocol, lb_algorithm=lb_algorithm ) changed = True for member_def in members: member_name = member_def.get(""name"") if not member_name: self.fail_json(msg='member name is required') member = self.conn.load_balancer.find_member(member_name, pool.id ) if not member: self._wait_for_lb(lb, ""ACTIVE"", [""ERROR""]) self.fail_json( subnet = self.conn.get_subnet(subnet_id) if not subnet: self.fail_json( member = self.conn.load_balancer.create_member( # Associate public ip to the load balancer VIP. If # public_vip_address is provided, use that IP, otherwise, either # find an available public ip or create a new one. fip = None orig_public_ip = None new_public_ip = None if public_vip_address or allocate_fip: ips = self.conn.network.ips( orig_public_ip = ips[0] new_public_ip = orig_public_ip.floating_ip_address if public_vip_address and public_vip_address != orig_public_ip: fip = self.conn.network.find_ip(public_vip_address) if not fip: self.fail_json( msg='Public IP %s is unavailable' % public_vip_address ) # Release origin public ip first self.conn.network.update_ip( orig_public_ip, fixed_ip_address=None, port_id=None ) # Associate new public ip self.conn.network.update_ip( fip, fixed_ip_address=lb.vip_address, port_id=lb.vip_port_id ) new_public_ip = public_vip_address changed = True elif allocate_fip and not orig_public_ip: fip = self.conn.network.find_available_ip() if not fip: if not public_network: self.fail_json(msg=""Public network is not provided"") pub_net = self.conn.network.find_network(public_network) if not pub_net: self.fail_json( msg='Public network %s not found' % public_network ) fip = self.conn.network.create_ip( floating_network_id=pub_net.id ) self.conn.network.update_ip( fip, fixed_ip_address=lb.vip_address, port_id=lb.vip_port_id ) new_public_ip = fip.floating_ip_address changed = True # Include public_vip_address in the result. lb = self.conn.load_balancer.find_load_balancer(name_or_id=lb.id) lb_dict = lb.to_dict() lb_dict.update({""public_vip_address"": new_public_ip}) self.exit_json( changed=changed, loadbalancer=lb_dict, id=lb.id ) elif self.params['state'] == 'absent': changed = False public_vip_address = None if lb: if self.ansible.check_mode: self.exit_json(changed=True) if delete_fip: ips = self.conn.network.ips( port_id=lb.vip_port_id, fixed_ip_address=lb.vip_address ) ips = list(ips) if ips: public_vip_address = ips[0] # Deleting load balancer with `cascade=False` does not make # sense because the deletion will always fail if there are # sub-resources. self.conn.load_balancer.delete_load_balancer(lb, cascade=True) changed = True if self.params['wait']: self._wait_for_lb(lb, ""DELETED"", [""ERROR""]) if delete_fip and public_vip_address: self.conn.network.delete_ip(public_vip_address) changed = True elif self.ansible.check_mode: self.exit_json(changed=False) self.exit_json(changed=changed) except Exception as e: self.fail_json(msg=str(e)) def main(): module = LoadBalancerModule() module()"," from ansible.module_utils.basic import AnsibleModule from ansible_collections.openstack.cloud.plugins.module_utils.openstack import (openstack_full_argument_spec, openstack_module_kwargs, openstack_cloud_from_module) def _wait_for_lb(module, cloud, lb, status, failures, interval=5): """"""Wait for load balancer to be in a particular provisioning status."""""" timeout = module.params['timeout'] total_sleep = 0 if failures is None: failures = [] while total_sleep < timeout: lb = cloud.load_balancer.find_load_balancer(lb.id) if lb: if lb.provisioning_status == status: return None if lb.provisioning_status in failures: module.fail_json( msg=""Load Balancer %s transitioned to failure state %s"" % (lb.id, lb.provisioning_status) ) else: if status == ""DELETED"": return None else: module.fail_json( msg=""Load Balancer %s transitioned to DELETED"" % lb.id ) time.sleep(interval) total_sleep += interval module.fail_json( msg=""Timeout waiting for Load Balancer %s to transition to %s"" % (lb.id, status) ) def main(): argument_spec = openstack_full_argument_spec( module_kwargs = openstack_module_kwargs() module = AnsibleModule(argument_spec, **module_kwargs) sdk, cloud = openstack_cloud_from_module(module) flavor = module.params['flavor'] vip_network = module.params['vip_network'] vip_subnet = module.params['vip_subnet'] vip_port = module.params['vip_port'] listeners = module.params['listeners'] public_vip_address = module.params['public_ip_address'] allocate_fip = module.params['auto_public_ip'] delete_fip = module.params['delete_public_ip'] public_network = module.params['public_network'] vip_network_id = None vip_subnet_id = None vip_port_id = None flavor_id = None try: changed = False lb = cloud.load_balancer.find_load_balancer( name_or_id=module.params['name']) if module.params['state'] == 'present': if not lb: if not (vip_network or vip_subnet or vip_port): module.fail_json( msg=""One of vip_network, vip_subnet, or vip_port must "" ""be specified for load balancer creation"" ) if flavor: _flavor = cloud.load_balancer.find_flavor(flavor) if not _flavor: module.fail_json( msg='flavor %s not found' % flavor flavor_id = _flavor.id if vip_network: network = cloud.get_network(vip_network) if not network: module.fail_json( msg='network %s is not found' % vip_network ) vip_network_id = network.id if vip_subnet: subnet = cloud.get_subnet(vip_subnet) if not subnet: module.fail_json( msg='subnet %s is not found' % vip_subnet ) vip_subnet_id = subnet.id if vip_port: port = cloud.get_port(vip_port) if not port: module.fail_json( msg='port %s is not found' % vip_port ) vip_port_id = port.id lb = cloud.load_balancer.create_load_balancer( name=module.params['name'], flavor_id=flavor_id, vip_network_id=vip_network_id, vip_subnet_id=vip_subnet_id, vip_port_id=vip_port_id, vip_address=module.params['vip_address'], ) changed = True if not listeners and not module.params['wait']: module.exit_json( changed=changed, loadbalancer=lb.to_dict(), id=lb.id ) _wait_for_lb(module, cloud, lb, ""ACTIVE"", [""ERROR""]) for listener_def in listeners: listener_name = listener_def.get(""name"") pool_def = listener_def.get(""pool"") if not listener_name: module.fail_json(msg='listener name is required') listener = cloud.load_balancer.find_listener( name_or_id=listener_name ) if not listener: _wait_for_lb(module, cloud, lb, ""ACTIVE"", [""ERROR""]) protocol = listener_def.get(""protocol"", ""HTTP"") protocol_port = listener_def.get(""protocol_port"", 80) listener = cloud.load_balancer.create_listener( name=listener_name, loadbalancer_id=lb.id, protocol=protocol, protocol_port=protocol_port, ) # Ensure pool in the listener. if pool_def: pool_name = pool_def.get(""name"") members = pool_def.get('members', []) if not pool_name: module.fail_json(msg='pool name is required') pool = cloud.load_balancer.find_pool(name_or_id=pool_name) if not pool: _wait_for_lb(module, cloud, lb, ""ACTIVE"", [""ERROR""]) protocol = pool_def.get(""protocol"", ""HTTP"") lb_algorithm = pool_def.get(""lb_algorithm"", ""ROUND_ROBIN"") pool = cloud.load_balancer.create_pool( name=pool_name, listener_id=listener.id, protocol=protocol, lb_algorithm=lb_algorithm ) for member_def in members: member_name = member_def.get(""name"") if not member_name: module.fail_json(msg='member name is required') member = cloud.load_balancer.find_member(member_name, pool.id) if not member: _wait_for_lb(module, cloud, lb, ""ACTIVE"", [""ERROR""]) module.fail_json( subnet = cloud.get_subnet(subnet_id) if not subnet: module.fail_json( member = cloud.load_balancer.create_member( # Associate public ip to the load balancer VIP. If # public_vip_address is provided, use that IP, otherwise, either # find an available public ip or create a new one. fip = None orig_public_ip = None new_public_ip = None if public_vip_address or allocate_fip: ips = cloud.network.ips( port_id=lb.vip_port_id, fixed_ip_address=lb.vip_address ) ips = list(ips) if ips: orig_public_ip = ips[0] new_public_ip = orig_public_ip.floating_ip_address if public_vip_address and public_vip_address != orig_public_ip: fip = cloud.network.find_ip(public_vip_address) if not fip: module.fail_json( msg='Public IP %s is unavailable' % public_vip_address ) # Release origin public ip first cloud.network.update_ip( orig_public_ip, fixed_ip_address=None, port_id=None ) # Associate new public ip cloud.network.update_ip( fip, fixed_ip_address=lb.vip_address, port_id=lb.vip_port_id ) new_public_ip = public_vip_address changed = True elif allocate_fip and not orig_public_ip: fip = cloud.network.find_available_ip() if not fip: if not public_network: module.fail_json(msg=""Public network is not provided"") pub_net = cloud.network.find_network(public_network) if not pub_net: module.fail_json( msg='Public network %s not found' % public_network ) fip = cloud.network.create_ip( floating_network_id=pub_net.id ) cloud.network.update_ip( fip, fixed_ip_address=lb.vip_address, port_id=lb.vip_port_id ) new_public_ip = fip.floating_ip_address changed = True # Include public_vip_address in the result. lb = cloud.load_balancer.find_load_balancer(name_or_id=lb.id) lb_dict = lb.to_dict() lb_dict.update({""public_vip_address"": new_public_ip}) module.exit_json( changed=changed, loadbalancer=lb_dict, id=lb.id ) elif module.params['state'] == 'absent': changed = False public_vip_address = None if lb: if delete_fip: ips = cloud.network.ips( public_vip_address = ips[0] # Deleting load balancer with `cascade=False` does not make # sense because the deletion will always fail if there are # sub-resources. cloud.load_balancer.delete_load_balancer(lb, cascade=True) changed = True if module.params['wait']: _wait_for_lb(module, cloud, lb, ""DELETED"", [""ERROR""]) if delete_fip and public_vip_address: cloud.network.delete_ip(public_vip_address) changed = True module.exit_json(changed=changed) except sdk.exceptions.OpenStackCloudException as e: module.fail_json(msg=str(e), extra_data=e.extra_data)",289,255
openstack%2Fansible-collections-openstack~master~Ib479dbef68cede6189d25e75388d8cb1fc61f95f,openstack/ansible-collections-openstack,master,Ib479dbef68cede6189d25e75388d8cb1fc61f95f,Refactor TCP/UDP port check.,MERGED,2020-11-26 14:34:55.000000000,2020-11-30 20:10:59.000000000,2020-11-30 20:10:59.000000000,"[{'_account_id': 10969}, {'_account_id': 22348}]","[{'number': 1, 'created': '2020-11-26 14:34:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ansible-collections-openstack/commit/3f949dd8cd6e9f2d549c7a0e4ebe28152b705558', 'message': 'Refactor TCP/UDP port check.\n\nTask: 41314\nStory: 2008390\nChange-Id: Ib479dbef68cede6189d25e75388d8cb1fc61f95f\n'}, {'number': 2, 'created': '2020-11-26 14:53:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ansible-collections-openstack/commit/4186a4eddd0bd16722342b4488c68117e556ecb2', 'message': 'Refactor TCP/UDP port check.\n\nTask: 41314\nStory: 2008390\nChange-Id: Ib479dbef68cede6189d25e75388d8cb1fc61f95f\n'}, {'number': 3, 'created': '2020-11-26 15:50:11.000000000', 'files': ['plugins/modules/security_group_rule.py', 'ci/roles/security_group/tasks/main.yml'], 'web_link': 'https://opendev.org/openstack/ansible-collections-openstack/commit/bce3eea5c063d466f44ced5a2c641fc7dffa8547', 'message': 'Refactor TCP/UDP port check.\n\nTask: 41314\nStory: 2008390\nChange-Id: Ib479dbef68cede6189d25e75388d8cb1fc61f95f\n'}]",60,764350,bce3eea5c063d466f44ced5a2c641fc7dffa8547,11,2,3,29605,,,0,"Refactor TCP/UDP port check.

Task: 41314
Story: 2008390
Change-Id: Ib479dbef68cede6189d25e75388d8cb1fc61f95f
",git fetch https://review.opendev.org/openstack/ansible-collections-openstack refs/changes/50/764350/1 && git format-patch -1 --stdout FETCH_HEAD,"['plugins/modules/security_group_rule.py', 'ci/roles/security_group/tasks/main.yml']",2,3f949dd8cd6e9f2d549c7a0e4ebe28152b705558,,"- name: Create TCP rule again with port range (1, 65535) openstack.cloud.security_group_rule: cloud: ""{{ cloud }}"" security_group: ""{{ secgroup_name }}"" state: present protocol: tcp port_range_min: 1 port_range_max: 65535 remote_ip_prefix: 0.0.0.0/0 - name: Create TCP rule again with port range (-1, -1) openstack.cloud.security_group_rule: cloud: ""{{ cloud }}"" security_group: ""{{ secgroup_name }}"" state: present protocol: tcp port_range_min: -1 port_range_max: -1 remote_ip_prefix: 0.0.0.0/0 - name: Create UDP rule again with port range (1, 65535) openstack.cloud.security_group_rule: cloud: ""{{ cloud }}"" security_group: ""{{ secgroup_name }}"" state: present protocol: udp port_range_min: 1 port_range_max: 65535 remote_ip_prefix: 0.0.0.0/0 - name: Create UDP rule again with port range (-1, -1) openstack.cloud.security_group_rule: cloud: ""{{ cloud }}"" security_group: ""{{ secgroup_name }}"" state: present protocol: udp port_range_min: -1 port_range_max: -1 remote_ip_prefix: 0.0.0.0/0 ",,51,12
openstack%2Fpuppet-tripleo~stable%2Ftrain~Ia41046f148e0593ea773e8409494ce5dcca4b7a2,openstack/puppet-tripleo,stable/train,Ia41046f148e0593ea773e8409494ce5dcca4b7a2,Cleanup old workaround for ipv6 VIPs,MERGED,2020-11-03 21:05:15.000000000,2020-11-30 19:54:30.000000000,2020-11-11 02:22:06.000000000,"[{'_account_id': 9592}, {'_account_id': 14985}, {'_account_id': 20172}, {'_account_id': 20778}, {'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2020-11-03 21:05:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-tripleo/commit/d1740cee4bad27fc0325dcbe3cd9ffa3e66a2b44', 'message': ""Cleanup old workaround for ipv6 VIPs\n\nhttps://bugzilla.redhat.com/show_bug.cgi?id=1445628 has been fixed\nin RHEL 7.3. There is no need to carry around this workaround any\nlonger.\n\nWe can entirely remove the nic parameter since it is set to '' by\ndefault anyway in puppet-pacemaker.\n\nChange-Id: Ia41046f148e0593ea773e8409494ce5dcca4b7a2\n(cherry picked from commit 473929d083046e5b1d14bed003dfde320c69db5e)\n""}, {'number': 2, 'created': '2020-11-08 09:06:48.000000000', 'files': ['manifests/pacemaker/haproxy_with_vip.pp'], 'web_link': 'https://opendev.org/openstack/puppet-tripleo/commit/ecf7416a6bcd699447fdca420790ed04fd1979f6', 'message': ""Cleanup old workaround for ipv6 VIPs\n\nhttps://bugzilla.redhat.com/show_bug.cgi?id=1445628 has been fixed\nin RHEL 7.3. There is no need to carry around this workaround any\nlonger.\n\nWe can entirely remove the nic parameter since it is set to '' by\ndefault anyway in puppet-pacemaker.\n\nChange-Id: Ia41046f148e0593ea773e8409494ce5dcca4b7a2\n(cherry picked from commit 2b44f5c31916f3d549a560b03c7ba7caf94c2189)\n""}]",0,761227,ecf7416a6bcd699447fdca420790ed04fd1979f6,18,6,2,20172,,,0,"Cleanup old workaround for ipv6 VIPs

https://bugzilla.redhat.com/show_bug.cgi?id=1445628 has been fixed
in RHEL 7.3. There is no need to carry around this workaround any
longer.

We can entirely remove the nic parameter since it is set to '' by
default anyway in puppet-pacemaker.

Change-Id: Ia41046f148e0593ea773e8409494ce5dcca4b7a2
(cherry picked from commit 2b44f5c31916f3d549a560b03c7ba7caf94c2189)
",git fetch https://review.opendev.org/openstack/puppet-tripleo refs/changes/27/761227/1 && git format-patch -1 --stdout FETCH_HEAD,['manifests/pacemaker/haproxy_with_vip.pp'],1,d1740cee4bad27fc0325dcbe3cd9ffa3e66a2b44,wip-nic,," # NB: Until the IPaddr2 RA has a fix for https://bugzilla.redhat.com/show_bug.cgi?id=1445628 # we need to specify the nic when creating the ipv6 vip. $nic = interface_for_ip($ip_address) $nic = '' nic => $nic,",0,5
openstack%2Fpuppet-tripleo~stable%2Fussuri~Ia41046f148e0593ea773e8409494ce5dcca4b7a2,openstack/puppet-tripleo,stable/ussuri,Ia41046f148e0593ea773e8409494ce5dcca4b7a2,Cleanup old workaround for ipv6 VIPs,MERGED,2020-11-08 09:06:41.000000000,2020-11-30 19:54:18.000000000,2020-11-14 14:52:02.000000000,"[{'_account_id': 9592}, {'_account_id': 20172}, {'_account_id': 20778}, {'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2020-11-08 09:06:41.000000000', 'files': ['manifests/pacemaker/haproxy_with_vip.pp'], 'web_link': 'https://opendev.org/openstack/puppet-tripleo/commit/201c12bdea4836f39de49b28ac1dcc829bbda31f', 'message': ""Cleanup old workaround for ipv6 VIPs\n\nhttps://bugzilla.redhat.com/show_bug.cgi?id=1445628 has been fixed\nin RHEL 7.3. There is no need to carry around this workaround any\nlonger.\n\nWe can entirely remove the nic parameter since it is set to '' by\ndefault anyway in puppet-pacemaker.\n\nChange-Id: Ia41046f148e0593ea773e8409494ce5dcca4b7a2\n(cherry picked from commit 2b44f5c31916f3d549a560b03c7ba7caf94c2189)\n""}]",0,761833,201c12bdea4836f39de49b28ac1dcc829bbda31f,32,5,1,20172,,,0,"Cleanup old workaround for ipv6 VIPs

https://bugzilla.redhat.com/show_bug.cgi?id=1445628 has been fixed
in RHEL 7.3. There is no need to carry around this workaround any
longer.

We can entirely remove the nic parameter since it is set to '' by
default anyway in puppet-pacemaker.

Change-Id: Ia41046f148e0593ea773e8409494ce5dcca4b7a2
(cherry picked from commit 2b44f5c31916f3d549a560b03c7ba7caf94c2189)
",git fetch https://review.opendev.org/openstack/puppet-tripleo refs/changes/33/761833/1 && git format-patch -1 --stdout FETCH_HEAD,['manifests/pacemaker/haproxy_with_vip.pp'],1,201c12bdea4836f39de49b28ac1dcc829bbda31f,bgpsupport-stable/victoria-stable/ussuri,," # NB: Until the IPaddr2 RA has a fix for https://bugzilla.redhat.com/show_bug.cgi?id=1445628 # we need to specify the nic when creating the ipv6 vip. $nic = interface_for_ip($ip_address) $nic = '' nic => $nic,",0,5
openstack%2Frequirements~stable%2Fvictoria~Id5ca21336f302f5eddc3f569ebfcb4bfd8882313,openstack/requirements,stable/victoria,Id5ca21336f302f5eddc3f569ebfcb4bfd8882313,Add neutron to stable upper-constraints,MERGED,2020-11-24 16:38:29.000000000,2020-11-30 19:02:29.000000000,2020-11-30 19:02:29.000000000,"[{'_account_id': 11904}, {'_account_id': 14288}, {'_account_id': 22348}]","[{'number': 1, 'created': '2020-11-24 16:38:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/requirements/commit/a5e15354bb4ee8b953b8368dd65efd449ff02262', 'message': 'Add neutron to stable upper-constraints\n\nSome projects, notably neutron plugins, are using the neutron service as\na library. There is the neutron-lib package, but apparently they have\nnot moved everything needed over to there yet.\n\nThis is being added directly in stable branches only. Master needs to\nget the latest version available, so these will need to be added at each\nrelease so the stable branches use the correct version of neutron for\ntheir respective stable release.\n\nCloses-Bug: #1903689\nChange-Id: Id5ca21336f302f5eddc3f569ebfcb4bfd8882313\n'}, {'number': 2, 'created': '2020-11-24 22:20:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/requirements/commit/6d11273cb0cce1a25d47598672512047b51458e0', 'message': 'Add neutron to stable upper-constraints\n\nSome projects, notably neutron plugins, are using the neutron service as\na library. There is the neutron-lib package, but apparently they have\nnot moved everything needed over to there yet.\n\nThis is being added directly in stable branches only. Master needs to\nget the latest version available, so these will need to be added at each\nrelease so the stable branches use the correct version of neutron for\ntheir respective stable release.\n\nCloses-Bug: #1903689\nChange-Id: Id5ca21336f302f5eddc3f569ebfcb4bfd8882313\n'}, {'number': 3, 'created': '2020-11-25 15:02:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/requirements/commit/01161128e5754a18b25ee76e77d0de41fd91f967', 'message': 'Add neutron to stable upper-constraints\n\nSome projects, notably neutron plugins, are using the neutron service as\na library. There is the neutron-lib package, but apparently they have\nnot moved everything needed over to there yet.\n\nThis is being added directly in stable branches only. Master needs to\nget the latest version available, so these will need to be added at each\nrelease so the stable branches use the correct version of neutron for\ntheir respective stable release.\n\nTo allower upper capping, this commit also drops neutron from blacklist\n\nCloses-Bug: #1903689\nChange-Id: Id5ca21336f302f5eddc3f569ebfcb4bfd8882313\n'}, {'number': 4, 'created': '2020-11-26 15:20:30.000000000', 'files': ['blacklist.txt', 'upper-constraints.txt'], 'web_link': 'https://opendev.org/openstack/requirements/commit/36710831f3154ec0844fb2a38317815435da46bc', 'message': 'Add neutron to stable upper-constraints\n\nSome projects, notably neutron plugins, are using the neutron service as\na library. There is the neutron-lib package, but apparently they have\nnot moved everything needed over to there yet.\n\nThis is being added directly in stable branches only. Master needs to\nget the latest version available, so these will need to be added at each\nrelease so the stable branches use the correct version of neutron for\ntheir respective stable release.\n\nTo allower upper capping, this commit also drops neutron from blacklist\n\nCloses-Bug: #1903689\nChange-Id: Id5ca21336f302f5eddc3f569ebfcb4bfd8882313\n'}]",2,764022,36710831f3154ec0844fb2a38317815435da46bc,27,3,4,21798,,,0,"Add neutron to stable upper-constraints

Some projects, notably neutron plugins, are using the neutron service as
a library. There is the neutron-lib package, but apparently they have
not moved everything needed over to there yet.

This is being added directly in stable branches only. Master needs to
get the latest version available, so these will need to be added at each
release so the stable branches use the correct version of neutron for
their respective stable release.

To allower upper capping, this commit also drops neutron from blacklist

Closes-Bug: #1903689
Change-Id: Id5ca21336f302f5eddc3f569ebfcb4bfd8882313
",git fetch https://review.opendev.org/openstack/requirements refs/changes/22/764022/4 && git format-patch -1 --stdout FETCH_HEAD,['upper-constraints.txt'],1,a5e15354bb4ee8b953b8368dd65efd449ff02262,victoria-neutron-uc,neutron==17.0.0,,1,0
openstack%2Fopenstack-ansible~master~I83387179465aec7c1b12fb1f38733bc58d719051,openstack/openstack-ansible,master,I83387179465aec7c1b12fb1f38733bc58d719051,Set service region for masakari,MERGED,2020-11-08 22:40:05.000000000,2020-11-30 18:36:30.000000000,2020-11-30 18:34:22.000000000,"[{'_account_id': 22348}, {'_account_id': 28619}, {'_account_id': 29865}]","[{'number': 1, 'created': '2020-11-08 22:40:05.000000000', 'files': ['inventory/group_vars/masakari_all.yml'], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/fe95e7b9865f033f0b8440c1144c586edba71c2f', 'message': 'Set service region for masakari\n\nChange-Id: I83387179465aec7c1b12fb1f38733bc58d719051\n'}]",0,761842,fe95e7b9865f033f0b8440c1144c586edba71c2f,14,3,1,25023,,,0,"Set service region for masakari

Change-Id: I83387179465aec7c1b12fb1f38733bc58d719051
",git fetch https://review.opendev.org/openstack/openstack-ansible refs/changes/42/761842/1 && git format-patch -1 --stdout FETCH_HEAD,['inventory/group_vars/masakari_all.yml'],1,fe95e7b9865f033f0b8440c1144c586edba71c2f,,"--- # Copyright 2020, Jonathan Rosser BBC R&D # # Licensed under the Apache License, Version 2.0 (the ""License""); # you may not use this file except in compliance with the License. # You may obtain a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. # See the License for the specific language governing permissions and # limitations under the License. masakari_service_region: ""{{ service_region }}"" ",,16,0
openstack%2Fopenstack-ansible~stable%2Fussuri~I973808f6d25e41c2700c06cbe785c615dac12919,openstack/openstack-ansible,stable/ussuri,I973808f6d25e41c2700c06cbe785c615dac12919,Bump SHAs for stable/ussuri,MERGED,2020-11-29 17:03:13.000000000,2020-11-30 18:34:55.000000000,2020-11-30 18:33:23.000000000,"[{'_account_id': 22348}, {'_account_id': 25023}, {'_account_id': 31542}]","[{'number': 1, 'created': '2020-11-29 17:03:13.000000000', 'files': ['playbooks/defaults/repo_packages/openstack_services.yml', 'playbooks/defaults/repo_packages/gnocchi.yml', 'playbooks/defaults/repo_packages/nova_consoles.yml', 'ansible-role-requirements.yml'], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/1973fee1f3c172ad65a7440864092be237a01b10', 'message': 'Bump SHAs for stable/ussuri\n\nChange-Id: I973808f6d25e41c2700c06cbe785c615dac12919\n'}]",0,764590,1973fee1f3c172ad65a7440864092be237a01b10,8,3,1,28619,,,0,"Bump SHAs for stable/ussuri

Change-Id: I973808f6d25e41c2700c06cbe785c615dac12919
",git fetch https://review.opendev.org/openstack/openstack-ansible refs/changes/90/764590/1 && git format-patch -1 --stdout FETCH_HEAD,"['playbooks/defaults/repo_packages/openstack_services.yml', 'playbooks/defaults/repo_packages/gnocchi.yml', 'playbooks/defaults/repo_packages/nova_consoles.yml', 'ansible-role-requirements.yml']",4,1973fee1f3c172ad65a7440864092be237a01b10,bump_osa, version: 399654cc70d58bc60376f7dd4eb9d0e8db2605d8 version: e6be9ced0357db618b92f5b25991fba691941ebc version: 0cf97985d5635b03d98b07c107675a4372f7dd12, version: c6b8b21cc6c5962d69a9cf8342cbeda8d6332d0c version: 63d14e585090011fe3ac947c70557938bb60fe21 version: d1a20e3de721d7853265f8e20d23532e65d3575e,53,53
openstack%2Fopenstack-manuals~master~I9cf18a7b383810f54a0e00af3ebb78d18d495297,openstack/openstack-manuals,master,I9cf18a7b383810f54a0e00af3ebb78d18d495297,Retire searchlight repos: update doc site,MERGED,2020-11-28 05:36:28.000000000,2020-11-30 18:27:55.000000000,2020-11-30 18:02:40.000000000,"[{'_account_id': 6547}, {'_account_id': 22348}]","[{'number': 1, 'created': '2020-11-28 05:36:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/f101b3c2882f0adb0f287de581fcb733fdec00ed', 'message': 'Retire python-searchlightclient: update doc site\n\nSearchlight project is retiring in Wallaby cycle[1].\nThis commit update openstack-manual to redirect\nthe repo doc site to REAMDE file.\n\nDepends-On: https://review.opendev.org/c/openstack/project-config/+/764535/1\n\n[1] http://lists.openstack.org/pipermail/openstack-discuss/2020-November/018637.html\n\nChange-Id: I9cf18a7b383810f54a0e00af3ebb78d18d495297\n'}, {'number': 2, 'created': '2020-11-28 21:47:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/ed6a3378fb157afd468d8763981569fc3a39e2a0', 'message': 'Retire searchlight repos: update doc site\n\nSearchlight project is retiring in Wallaby cycle[1].\nThis commit update openstack-manual to redirect\nthe repo doc site to REAMDE file.\n\nNeeded-by: https://review.opendev.org/c/openstack/python-searchlightclient/+/764529\nNeeded-by: https://review.opendev.org/c/openstack/searchlight-ui/+/764528\nNeeded-By: https://review.opendev.org/c/openstack/searchlight-specs/+/764527\n\n[1] http://lists.openstack.org/pipermail/openstack-discuss/2020-November/018637.html\n\nChange-Id: I9cf18a7b383810f54a0e00af3ebb78d18d495297\n'}, {'number': 3, 'created': '2020-11-30 15:46:23.000000000', 'files': ['tools/www-generator.py'], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/fd3717480f30420c7a1517501545e218c26bd0e3', 'message': 'Retire searchlight repos: update doc site\n\nSearchlight project is retiring in Wallaby cycle[1].\nThis commit update openstack-manual to redirect\nthe repo doc site to REAMDE file.\n\nNeeded-by: https://review.opendev.org/c/openstack/python-searchlightclient/+/764529\nNeeded-by: https://review.opendev.org/c/openstack/searchlight-ui/+/764528\nNeeded-By: https://review.opendev.org/c/openstack/searchlight-specs/+/764527\n\n[1] http://lists.openstack.org/pipermail/openstack-discuss/2020-November/018637.html\n\nChange-Id: I9cf18a7b383810f54a0e00af3ebb78d18d495297\n'}]",0,764539,fd3717480f30420c7a1517501545e218c26bd0e3,13,2,3,8556,,,0,"Retire searchlight repos: update doc site

Searchlight project is retiring in Wallaby cycle[1].
This commit update openstack-manual to redirect
the repo doc site to REAMDE file.

Needed-by: https://review.opendev.org/c/openstack/python-searchlightclient/+/764529
Needed-by: https://review.opendev.org/c/openstack/searchlight-ui/+/764528
Needed-By: https://review.opendev.org/c/openstack/searchlight-specs/+/764527

[1] http://lists.openstack.org/pipermail/openstack-discuss/2020-November/018637.html

Change-Id: I9cf18a7b383810f54a0e00af3ebb78d18d495297
",git fetch https://review.opendev.org/openstack/openstack-manuals refs/changes/39/764539/3 && git format-patch -1 --stdout FETCH_HEAD,['tools/www-generator.py'],1,f101b3c2882f0adb0f287de581fcb733fdec00ed,retire-searchlight," 'openstack/python-searchlightclient',",,1,0
openstack%2Foslo.i18n~master~I3d2b0f7a78d4914913a3af3b68388392bf30b982,openstack/oslo.i18n,master,I3d2b0f7a78d4914913a3af3b68388392bf30b982,Remove all usage of six library,MERGED,2020-10-07 06:39:39.000000000,2020-11-30 18:20:10.000000000,2020-11-30 18:18:51.000000000,"[{'_account_id': 2472}, {'_account_id': 4257}, {'_account_id': 6928}, {'_account_id': 8770}, {'_account_id': 11904}, {'_account_id': 15334}, {'_account_id': 22348}, {'_account_id': 28522}, {'_account_id': 30407}]","[{'number': 1, 'created': '2020-10-07 06:39:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.i18n/commit/53d95329760dd481f0caf94d8b10c722dff89efd', 'message': 'Remove all usage of six library\n\nReplace six with Python 3 style code.\n\nChange-Id: I3d2b0f7a78d4914913a3af3b68388392bf30b982\n'}, {'number': 2, 'created': '2020-10-07 08:49:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.i18n/commit/b097821425450d5ad347412a521db99719595b84', 'message': 'Remove all usage of six library\n\nReplace six with Python 3 style code.\n\nChange-Id: I3d2b0f7a78d4914913a3af3b68388392bf30b982\n'}, {'number': 3, 'created': '2020-10-09 01:26:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.i18n/commit/ecc898af50c7dbe25b148921c40aabf2f60ea232', 'message': 'Remove all usage of six library\n\nReplace six with Python 3 style code.\n\nChange-Id: I3d2b0f7a78d4914913a3af3b68388392bf30b982\n'}, {'number': 4, 'created': '2020-10-09 11:17:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.i18n/commit/fc99cd6fdf941f25c8574e9a3a23c48d41810127', 'message': 'Remove all usage of six library\n\nReplace six with Python 3 style code.\n\nChange-Id: I3d2b0f7a78d4914913a3af3b68388392bf30b982\n'}, {'number': 5, 'created': '2020-11-26 06:41:31.000000000', 'files': ['oslo_i18n/fixture.py', 'oslo_i18n/tests/test_gettextutils.py', 'oslo_i18n/tests/test_fixture.py', 'lower-constraints.txt', 'oslo_i18n/tests/test_message.py', 'requirements.txt', 'oslo_i18n/_gettextutils.py', 'oslo_i18n/tests/test_factory.py', 'oslo_i18n/tests/test_public_api.py', 'oslo_i18n/_translate.py', 'oslo_i18n/_message.py', 'oslo_i18n/tests/test_handler.py'], 'web_link': 'https://opendev.org/openstack/oslo.i18n/commit/8609dc2c4ceacd2b5b3acb34430de29838a219fa', 'message': 'Remove all usage of six library\n\nReplace six with Python 3 style code.\n\nChange-Id: I3d2b0f7a78d4914913a3af3b68388392bf30b982\n'}]",7,756438,8609dc2c4ceacd2b5b3acb34430de29838a219fa,22,9,5,30407,,,0,"Remove all usage of six library

Replace six with Python 3 style code.

Change-Id: I3d2b0f7a78d4914913a3af3b68388392bf30b982
",git fetch https://review.opendev.org/openstack/oslo.i18n refs/changes/38/756438/1 && git format-patch -1 --stdout FETCH_HEAD,"['oslo_i18n/fixture.py', 'oslo_i18n/tests/test_gettextutils.py', 'oslo_i18n/tests/test_fixture.py', 'lower-constraints.txt', 'oslo_i18n/tests/test_message.py', 'requirements.txt', 'oslo_i18n/_gettextutils.py', 'oslo_i18n/tests/test_factory.py', 'oslo_i18n/tests/test_public_api.py', 'oslo_i18n/_translate.py', 'oslo_i18n/_message.py', 'oslo_i18n/tests/test_handler.py']",12,53d95329760dd481f0caf94d8b10c722dff89efd,,import io self.stream = io.StringIO(),import six self.stream = six.StringIO(),47,60
openstack%2Frequirements~master~I1c587182219f63234770004cbcca04dacf683f40,openstack/requirements,master,I1c587182219f63234770004cbcca04dacf683f40,update constraint for python-troveclient to new release 6.0.0,MERGED,2020-11-30 11:12:41.000000000,2020-11-30 18:18:16.000000000,2020-11-30 18:16:55.000000000,"[{'_account_id': 14288}, {'_account_id': 22348}, {'_account_id': 28522}]","[{'number': 1, 'created': '2020-11-30 11:12:41.000000000', 'files': ['upper-constraints.txt'], 'web_link': 'https://opendev.org/openstack/requirements/commit/733472f4621641a0a0b85a896f07f3d2f2ea19ce', 'message': 'update constraint for python-troveclient to new release 6.0.0\n\nmeta: version: 6.0.0\nmeta: diff-start: -\nmeta: series: wallaby\nmeta: release-type: release\nmeta: pypi: yes\nmeta: first: yes\nmeta: release:Author: Lingxian Kong <anlin.kong@gmail.com>\nmeta: release:Commit: Lingxian Kong <anlin.kong@gmail.com>\nmeta: release:Change-Id: I841969913698591984d6920a84913968f41fa618\nmeta: release:Code-Review+2: Herv Beraud <hberaud@redhat.com>\nmeta: release:Code-Review+2: Thierry Carrez <thierry@openstack.org>\nmeta: release:Workflow+1: Thierry Carrez <thierry@openstack.org>\nChange-Id: I1c587182219f63234770004cbcca04dacf683f40\n'}]",0,764635,733472f4621641a0a0b85a896f07f3d2f2ea19ce,9,3,1,11131,,,0,"update constraint for python-troveclient to new release 6.0.0

meta: version: 6.0.0
meta: diff-start: -
meta: series: wallaby
meta: release-type: release
meta: pypi: yes
meta: first: yes
meta: release:Author: Lingxian Kong <anlin.kong@gmail.com>
meta: release:Commit: Lingxian Kong <anlin.kong@gmail.com>
meta: release:Change-Id: I841969913698591984d6920a84913968f41fa618
meta: release:Code-Review+2: Herv Beraud <hberaud@redhat.com>
meta: release:Code-Review+2: Thierry Carrez <thierry@openstack.org>
meta: release:Workflow+1: Thierry Carrez <thierry@openstack.org>
Change-Id: I1c587182219f63234770004cbcca04dacf683f40
",git fetch https://review.opendev.org/openstack/requirements refs/changes/35/764635/1 && git format-patch -1 --stdout FETCH_HEAD,['upper-constraints.txt'],1,733472f4621641a0a0b85a896f07f3d2f2ea19ce,new-release,python-troveclient===6.0.0,python-troveclient===5.1.1,1,1
openstack%2Freleases~master~I41c36467f5f0e130ab6c40299f536a66d6991bc8,openstack/releases,master,I41c36467f5f0e130ab6c40299f536a66d6991bc8,New feature release of stevedore for wallaby.,MERGED,2020-11-27 17:19:13.000000000,2020-11-30 17:47:21.000000000,2020-11-30 17:47:21.000000000,"[{'_account_id': 308}, {'_account_id': 11904}, {'_account_id': 22348}]","[{'number': 1, 'created': '2020-11-27 17:19:13.000000000', 'files': ['deliverables/wallaby/stevedore.yaml'], 'web_link': 'https://opendev.org/openstack/releases/commit/377a486d3ca380303c636e786eaa2d9cee88c393', 'message': 'New feature release of stevedore for wallaby.\n\n The first release for a series must be at least a feature\n release to allow for stable releases from the previous\n series.\n\nChange-Id: I41c36467f5f0e130ab6c40299f536a66d6991bc8\n'}]",1,764480,377a486d3ca380303c636e786eaa2d9cee88c393,8,3,1,31245,,,0,"New feature release of stevedore for wallaby.

 The first release for a series must be at least a feature
 release to allow for stable releases from the previous
 series.

Change-Id: I41c36467f5f0e130ab6c40299f536a66d6991bc8
",git fetch https://review.opendev.org/openstack/releases refs/changes/80/764480/1 && git format-patch -1 --stdout FETCH_HEAD,['deliverables/wallaby/stevedore.yaml'],1,377a486d3ca380303c636e786eaa2d9cee88c393,stevedore_for_wallaby,releases: - version: 3.3.0 projects: - repo: openstack/stevedore hash: 7d7154f7ea8f739c9d766855f93d04ab205e5ce1,,5,0
openstack%2Freleases~master~Ie378d7bfe1922d738a91ff2fb1e2a6ae06c4b0f1,openstack/releases,master,Ie378d7bfe1922d738a91ff2fb1e2a6ae06c4b0f1,Retiring the Karbor's projects,MERGED,2020-11-27 10:30:58.000000000,2020-11-30 17:46:09.000000000,2020-11-30 17:46:09.000000000,"[{'_account_id': 8556}, {'_account_id': 11904}, {'_account_id': 22348}]","[{'number': 1, 'created': '2020-11-27 10:30:58.000000000', 'files': ['deliverables/wallaby/karbor.yaml', 'deliverables/wallaby/karbor-dashboard.yaml', 'deliverables/wallaby/python-karborclient.yaml'], 'web_link': 'https://opendev.org/openstack/releases/commit/1436ca9ae058d208fec1dfa3243b20f6211c1577', 'message': ""Retiring the Karbor's projects\n\nMake sure that karbor deliverables are removed before Wallaby-1 so that we don't\naccidentally release them.\n\nhttp://lists.openstack.org/pipermail/openstack-discuss/2020-November/018643.html\n\nChange-Id: Ie378d7bfe1922d738a91ff2fb1e2a6ae06c4b0f1\n""}]",0,764438,1436ca9ae058d208fec1dfa3243b20f6211c1577,10,3,1,28522,,,0,"Retiring the Karbor's projects

Make sure that karbor deliverables are removed before Wallaby-1 so that we don't
accidentally release them.

http://lists.openstack.org/pipermail/openstack-discuss/2020-November/018643.html

Change-Id: Ie378d7bfe1922d738a91ff2fb1e2a6ae06c4b0f1
",git fetch https://review.opendev.org/openstack/releases refs/changes/38/764438/1 && git format-patch -1 --stdout FETCH_HEAD,"['deliverables/wallaby/karbor.yaml', 'deliverables/wallaby/karbor-dashboard.yaml', 'deliverables/wallaby/python-karborclient.yaml']",3,1436ca9ae058d208fec1dfa3243b20f6211c1577,retiring-deliverables-before-M-1,,--- include-pypi-link: true launchpad: python-karborclient release-model: cycle-with-intermediary team: karbor type: client-library repository-settings: openstack/python-karborclient: {} ,0,23
openstack%2Freleases~master~Iccdff3091f114b7c6def4d0934b53019f0a0a07c,openstack/releases,master,Iccdff3091f114b7c6def4d0934b53019f0a0a07c,Retiring the Searchllight's projects,MERGED,2020-11-27 10:36:11.000000000,2020-11-30 17:46:04.000000000,2020-11-30 17:46:04.000000000,"[{'_account_id': 8556}, {'_account_id': 11904}, {'_account_id': 22348}, {'_account_id': 27068}]","[{'number': 1, 'created': '2020-11-27 10:36:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/releases/commit/35a55f186d6e6a9088936218bad7190566bf9fbd', 'message': ""Retiring the Karbor's projects\n\nMake sure that karbor deliverables are removed before Wallaby-1 so that we don't\naccidentally release them.\n\nhttp://lists.openstack.org/pipermail/openstack-discuss/2020-November/018637.html\n\nChange-Id: Iccdff3091f114b7c6def4d0934b53019f0a0a07c\n""}, {'number': 2, 'created': '2020-11-27 10:37:13.000000000', 'files': ['deliverables/wallaby/searchlight.yaml', 'deliverables/wallaby/python-searchlightclient.yaml', 'deliverables/wallaby/searchlight-ui.yaml'], 'web_link': 'https://opendev.org/openstack/releases/commit/14856eb91028690c1842fdbed5b303935e341dea', 'message': ""Retiring the Searchllight's projects\n\nMake sure that Searchllight deliverables are removed before Wallaby-1 so that we don't\naccidentally release them.\n\nhttp://lists.openstack.org/pipermail/openstack-discuss/2020-November/018637.html\n\nChange-Id: Iccdff3091f114b7c6def4d0934b53019f0a0a07c\n""}]",0,764440,14856eb91028690c1842fdbed5b303935e341dea,13,4,2,28522,,,0,"Retiring the Searchllight's projects

Make sure that Searchllight deliverables are removed before Wallaby-1 so that we don't
accidentally release them.

http://lists.openstack.org/pipermail/openstack-discuss/2020-November/018637.html

Change-Id: Iccdff3091f114b7c6def4d0934b53019f0a0a07c
",git fetch https://review.opendev.org/openstack/releases refs/changes/40/764440/2 && git format-patch -1 --stdout FETCH_HEAD,"['deliverables/wallaby/searchlight.yaml', 'deliverables/wallaby/python-searchlightclient.yaml', 'deliverables/wallaby/searchlight-ui.yaml']",3,35a55f186d6e6a9088936218bad7190566bf9fbd,retiring-deliverables-before-M-1,,--- include-pypi-link: true storyboard: openstack/searchlight-ui release-model: cycle-with-rc team: searchlight type: horizon-plugin repository-settings: openstack/searchlight-ui: {} ,0,24
openstack%2Freleases~master~I069f2860e1e3a15747a368c69dfa8e52bf8663fd,openstack/releases,master,I069f2860e1e3a15747a368c69dfa8e52bf8663fd,Retiring the Qinling's projects,MERGED,2020-11-27 10:33:28.000000000,2020-11-30 17:43:15.000000000,2020-11-30 17:43:15.000000000,"[{'_account_id': 6732}, {'_account_id': 8556}, {'_account_id': 11904}, {'_account_id': 22348}]","[{'number': 1, 'created': '2020-11-27 10:33:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/releases/commit/bc9942fef7e8ed8c701d0edcf9da8b2e8c97a97f', 'message': ""Retiring the Qinling's projects\n\nMake sure that karbor deliverables are removed before Wallaby-1 so that we don't\naccidentally release them.\n\nhttp://lists.openstack.org/pipermail/openstack-discuss/2020-November/018641.html\n\nChange-Id: I069f2860e1e3a15747a368c69dfa8e52bf8663fd\n""}, {'number': 2, 'created': '2020-11-27 10:38:02.000000000', 'files': ['deliverables/wallaby/qinling-dashboard.yaml', 'deliverables/wallaby/python-qinlingclient.yaml', 'deliverables/wallaby/qinling.yaml'], 'web_link': 'https://opendev.org/openstack/releases/commit/a4cbb0aeec98f6d72f4e476afeb7cf1253cdad28', 'message': ""Retiring the Qinling's projects\n\nMake sure that Qinling deliverables are removed before Wallaby-1 so that we don't\naccidentally release them.\n\nhttp://lists.openstack.org/pipermail/openstack-discuss/2020-November/018641.html\n\nChange-Id: I069f2860e1e3a15747a368c69dfa8e52bf8663fd\n""}]",0,764439,a4cbb0aeec98f6d72f4e476afeb7cf1253cdad28,11,4,2,28522,,,0,"Retiring the Qinling's projects

Make sure that Qinling deliverables are removed before Wallaby-1 so that we don't
accidentally release them.

http://lists.openstack.org/pipermail/openstack-discuss/2020-November/018641.html

Change-Id: I069f2860e1e3a15747a368c69dfa8e52bf8663fd
",git fetch https://review.opendev.org/openstack/releases refs/changes/39/764439/1 && git format-patch -1 --stdout FETCH_HEAD,"['deliverables/wallaby/qinling-dashboard.yaml', 'deliverables/wallaby/python-qinlingclient.yaml', 'deliverables/wallaby/qinling.yaml']",3,bc9942fef7e8ed8c701d0edcf9da8b2e8c97a97f,retiring-deliverables-before-M-1,,--- team: qinling type: service storyboard: 927 release-model: cycle-with-rc repository-settings: openstack/qinling: {} ,0,22
openstack%2Ftripleo-quickstart-extras~master~I330aca8bd745442c9c9f59d2feb9c0f562d3ac44,openstack/tripleo-quickstart-extras,master,I330aca8bd745442c9c9f59d2feb9c0f562d3ac44,Updating docker registry for registry container,NEW,2020-11-25 16:26:26.000000000,2020-11-30 16:51:00.000000000,,"[{'_account_id': 8175}, {'_account_id': 12393}, {'_account_id': 13294}, {'_account_id': 13861}, {'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2020-11-25 16:26:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-quickstart-extras/commit/c427378af957bb7c6183478771321a11a8eadd9e', 'message': 'Updating docker registry for registry container\n\nQuay.io is down, so we are switching for rdo registry that is more\nreliable.\n\nChange-Id: I330aca8bd745442c9c9f59d2feb9c0f562d3ac44\n'}, {'number': 2, 'created': '2020-11-25 16:35:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-quickstart-extras/commit/3464eade500d01964f513c7f94ac7c86ed3dfaf0', 'message': 'Updating docker registry for registry container\n\nQuay.io is down, so we are switching for rdo registry that is more\nreliable.\n\nCloses-Bug: #1905592\nChange-Id: I330aca8bd745442c9c9f59d2feb9c0f562d3ac44\n'}, {'number': 3, 'created': '2020-11-26 02:40:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-quickstart-extras/commit/86bac53ff37046f9f450b6bd610c95589557cc6a', 'message': 'Updating docker registry for registry container\n\nQuay.io is down, so we are switching for rdo registry that is more\nreliable.\n\nCloses-Bug: #1905592\nChange-Id: I330aca8bd745442c9c9f59d2feb9c0f562d3ac44\n'}, {'number': 4, 'created': '2020-11-30 09:05:15.000000000', 'files': ['roles/container-build/tasks/main.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-quickstart-extras/commit/ffdd55116c2137eec36edc47c1ab9d9682185f84', 'message': 'Updating docker registry for registry container\n\nQuay.io is down, so we are switching for rdo registry that is more\nreliable.\n\nCloses-Bug: #1905592\nChange-Id: I330aca8bd745442c9c9f59d2feb9c0f562d3ac44\n'}]",4,764217,ffdd55116c2137eec36edc47c1ab9d9682185f84,16,6,4,8367,,,0,"Updating docker registry for registry container

Quay.io is down, so we are switching for rdo registry that is more
reliable.

Closes-Bug: #1905592
Change-Id: I330aca8bd745442c9c9f59d2feb9c0f562d3ac44
",git fetch https://review.opendev.org/openstack/tripleo-quickstart-extras refs/changes/17/764217/4 && git format-patch -1 --stdout FETCH_HEAD,['roles/container-build/tasks/main.yaml'],1,c427378af957bb7c6183478771321a11a8eadd9e,rdo-registry, image: trunk.registry.rdoproject.org/ceph/registry:2, image: quay.io/tripleoci/registry:2,1,1
openstack%2Fopenstack-helm-infra~master~I5fd7f422d710c18dee237c0ae97ae1a770606605,openstack/openstack-helm-infra,master,I5fd7f422d710c18dee237c0ae97ae1a770606605,[ceph-osd] Fix post-apply job failure related to fault tolerance,MERGED,2020-11-23 21:56:42.000000000,2020-11-30 16:42:52.000000000,2020-11-24 19:49:18.000000000,"[{'_account_id': 8898}, {'_account_id': 18511}, {'_account_id': 20466}, {'_account_id': 21420}, {'_account_id': 22348}, {'_account_id': 23928}, {'_account_id': 28372}, {'_account_id': 28849}, {'_account_id': 29974}, {'_account_id': 30777}, {'_account_id': 32190}, {'_account_id': 32433}]","[{'number': 1, 'created': '2020-11-23 21:56:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/2284c86edccc43154f2b3f8615ba35ce9d07b596', 'message': ""[ceph-osd] Fix post-apply job failure related to fault tolerance\n\nA recent change to wait_for_pods() to allow for fault tolerance\nappears to be causing wait_for_pgs() to fail and exit the post-\napply script prematurely in some cases. The existing\nwait_for_degraded_objects() logic won't pass until pods and PGs\nhave recovered while the noout flag is set, so the pod and PG\nwaits can simply be removed.\n\nChange-Id: I5fd7f422d710c18dee237c0ae97ae1a770606605\n""}, {'number': 2, 'created': '2020-11-24 13:30:52.000000000', 'files': ['ceph-osd/templates/bin/_post-apply.sh.tpl', 'ceph-osd/Chart.yaml'], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/791b0de5ee2e6e7ff65ab08bf04f6fc8c2dac6f8', 'message': ""[ceph-osd] Fix post-apply job failure related to fault tolerance\n\nA recent change to wait_for_pods() to allow for fault tolerance\nappears to be causing wait_for_pgs() to fail and exit the post-\napply script prematurely in some cases. The existing\nwait_for_degraded_objects() logic won't pass until pods and PGs\nhave recovered while the noout flag is set, so the pod and PG\nwaits can simply be removed.\n\nChange-Id: I5fd7f422d710c18dee237c0ae97ae1a770606605\n""}]",2,763865,791b0de5ee2e6e7ff65ab08bf04f6fc8c2dac6f8,19,12,2,29974,,,0,"[ceph-osd] Fix post-apply job failure related to fault tolerance

A recent change to wait_for_pods() to allow for fault tolerance
appears to be causing wait_for_pgs() to fail and exit the post-
apply script prematurely in some cases. The existing
wait_for_degraded_objects() logic won't pass until pods and PGs
have recovered while the noout flag is set, so the pod and PG
waits can simply be removed.

Change-Id: I5fd7f422d710c18dee237c0ae97ae1a770606605
",git fetch https://review.opendev.org/openstack/openstack-helm-infra refs/changes/65/763865/2 && git format-patch -1 --stdout FETCH_HEAD,['ceph-osd/templates/bin/_post-apply.sh.tpl'],1,2284c86edccc43154f2b3f8615ba35ce9d07b596,," # Degraded objects won't recover with noout set unless pods come back and # PGs become healthy, so simply wait for 0 degraded objects"," wait_for_pods $CEPH_NAMESPACE echo ""waiting for inactive pgs after osds restarted from rack $rack"" wait_for_pgs",2,3
openstack%2Fbifrost~master~I8b54030ef598c5860cd8d9929e9b58487f915fb1,openstack/bifrost,master,I8b54030ef598c5860cd8d9929e9b58487f915fb1,Allow inserting SSH public key for dynamic-login,MERGED,2020-11-23 16:50:44.000000000,2020-11-30 16:36:05.000000000,2020-11-30 11:40:46.000000000,"[{'_account_id': 4571}, {'_account_id': 22348}, {'_account_id': 23851}, {'_account_id': 24828}]","[{'number': 1, 'created': '2020-11-23 16:50:44.000000000', 'files': ['releasenotes/notes/add-ssh-key-eceb7cde22c3eb4a.yaml', 'playbooks/roles/bifrost-ironic-install/ssh_public_key_path.yaml', 'playbooks/roles/bifrost-ironic-install/defaults/main.yml', 'playbooks/roles/bifrost-ironic-install/tasks/bootstrap.yml'], 'web_link': 'https://opendev.org/openstack/bifrost/commit/b604f66e3860d103d428a1eb61e2f420bf3ce97e', 'message': 'Allow inserting SSH public key for dynamic-login\n\nChange-Id: I8b54030ef598c5860cd8d9929e9b58487f915fb1\n'}]",6,763806,b604f66e3860d103d428a1eb61e2f420bf3ce97e,15,4,1,10239,,,0,"Allow inserting SSH public key for dynamic-login

Change-Id: I8b54030ef598c5860cd8d9929e9b58487f915fb1
",git fetch https://review.opendev.org/openstack/bifrost refs/changes/06/763806/1 && git format-patch -1 --stdout FETCH_HEAD,"['releasenotes/notes/add-ssh-key-eceb7cde22c3eb4a.yaml', 'playbooks/roles/bifrost-ironic-install/ssh_public_key_path.yaml', 'playbooks/roles/bifrost-ironic-install/defaults/main.yml', 'playbooks/roles/bifrost-ironic-install/tasks/bootstrap.yml']",4,b604f66e3860d103d428a1eb61e2f420bf3ce97e,add-ssh-key,"- name: ""Read SSH key if needed"" import_tasks: ssh_public_key_path.yaml when: ipa_add_ssh_key | bool ",,58,0
openstack%2Fcinder~master~I47feac4e2eab1f868b93c0d90341d5465f42693b,openstack/cinder,master,I47feac4e2eab1f868b93c0d90341d5465f42693b,Tests: Improve get_qemu_img_version coverage,MERGED,2020-07-27 21:04:44.000000000,2020-11-30 16:31:30.000000000,2020-11-30 16:28:55.000000000,"[{'_account_id': 1736}, {'_account_id': 4523}, {'_account_id': 5314}, {'_account_id': 9008}, {'_account_id': 11611}, {'_account_id': 11904}, {'_account_id': 12016}, {'_account_id': 12017}, {'_account_id': 12032}, {'_account_id': 12033}, {'_account_id': 12369}, {'_account_id': 14384}, {'_account_id': 15386}, {'_account_id': 15941}, {'_account_id': 19933}, {'_account_id': 21863}, {'_account_id': 22248}, {'_account_id': 22348}, {'_account_id': 22510}, {'_account_id': 23613}, {'_account_id': 24814}, {'_account_id': 24815}, {'_account_id': 24921}, {'_account_id': 25678}, {'_account_id': 26537}, {'_account_id': 28801}, {'_account_id': 29705}, {'_account_id': 30615}, {'_account_id': 30688}, {'_account_id': 32159}]","[{'number': 1, 'created': '2020-07-27 21:04:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/97fafa692a8186675b6990f0dde5763e6e54ebc4', 'message': 'Tests: Improve get_qemu_img_version coverage\n\nTest the cached value path of this method too.\n\nChange-Id: I47feac4e2eab1f868b93c0d90341d5465f42693b\n'}, {'number': 2, 'created': '2020-11-12 18:52:10.000000000', 'files': ['cinder/tests/unit/test_image_utils.py'], 'web_link': 'https://opendev.org/openstack/cinder/commit/563c7e05f79a9739a049afb78b115aec041c4a2c', 'message': 'Tests: Improve get_qemu_img_version coverage\n\nTest the cached value path of this method too.\n\nChange-Id: I47feac4e2eab1f868b93c0d90341d5465f42693b\n'}]",2,743413,563c7e05f79a9739a049afb78b115aec041c4a2c,65,30,2,4523,,,0,"Tests: Improve get_qemu_img_version coverage

Test the cached value path of this method too.

Change-Id: I47feac4e2eab1f868b93c0d90341d5465f42693b
",git fetch https://review.opendev.org/openstack/cinder refs/changes/13/743413/2 && git format-patch -1 --stdout FETCH_HEAD,['cinder/tests/unit/test_image_utils.py'],1,97fafa692a8186675b6990f0dde5763e6e54ebc4,," self.assertEqual(mock_exec.call_count, 1) version = image_utils.get_qemu_img_version() # verify that cached value was used instead of calling execute self.assertEqual(expected_version, version) self.assertEqual(mock_exec.call_count, 1)",,7,0
openstack%2Ftripleo-common~master~I9842dd3dda8d61e478c55a50d886936955c5a7c5,openstack/tripleo-common,master,I9842dd3dda8d61e478c55a50d886936955c5a7c5,tripleo ipa image should use the new ipa-ramdisk,NEW,2020-07-23 16:43:15.000000000,2020-11-30 16:20:08.000000000,,"[{'_account_id': 3153}, {'_account_id': 7144}, {'_account_id': 10239}, {'_account_id': 11655}, {'_account_id': 14985}, {'_account_id': 15519}, {'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2020-07-23 16:43:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-common/commit/f3ddd42905e62c1cb9e2ccf09c44d92802badf78', 'message': 'WIP: DNM, tripleo ipa image should use ironic-agent-builder\n\nChange-Id: I9842dd3dda8d61e478c55a50d886936955c5a7c5\n'}, {'number': 2, 'created': '2020-07-24 12:23:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-common/commit/287bd8e5de971521e58b15535973b4c3ac0f1e90', 'message': ""tripleo ipa image should use the new ipa-ramdisk\n\nIt was pointed out by dtantsur.\ndtantsur> heads up, folks, the job\ntripleo-buildimage-ironic-python-agent-centos-8\nseems to use the old 'ironic-agent' element\n\nReference:\nhttps://tinyurl.com/yxm4dtcx\n\nChange-Id: I9842dd3dda8d61e478c55a50d886936955c5a7c5\n""}, {'number': 3, 'created': '2020-08-27 13:00:21.000000000', 'files': ['image-yaml/overcloud-images-python3.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-common/commit/5031742163ed85f336b442d1c1957acc66c07805', 'message': ""tripleo ipa image should use the new ipa-ramdisk\n\nIt was pointed out by dtantsur.\ndtantsur> heads up, folks, the job\ntripleo-buildimage-ironic-python-agent-centos-8\nseems to use the old 'ironic-agent' element\n\nReference:\nhttps://tinyurl.com/yxm4dtcx\n\nChange-Id: I9842dd3dda8d61e478c55a50d886936955c5a7c5\n""}]",2,742707,5031742163ed85f336b442d1c1957acc66c07805,32,8,3,9592,,,0,"tripleo ipa image should use the new ipa-ramdisk

It was pointed out by dtantsur.
dtantsur> heads up, folks, the job
tripleo-buildimage-ironic-python-agent-centos-8
seems to use the old 'ironic-agent' element

Reference:
https://tinyurl.com/yxm4dtcx

Change-Id: I9842dd3dda8d61e478c55a50d886936955c5a7c5
",git fetch https://review.opendev.org/openstack/tripleo-common refs/changes/07/742707/2 && git format-patch -1 --stdout FETCH_HEAD,['image-yaml/overcloud-images-python3.yaml'],1,f3ddd42905e62c1cb9e2ccf09c44d92802badf78,, - ironic-agent-builder, - ironic-agent,1,1
openstack%2Fkolla-ansible~stable%2Fstein~I2fe6eb13ce7be68d346b1b3b7036859f34c896c4,openstack/kolla-ansible,stable/stein,I2fe6eb13ce7be68d346b1b3b7036859f34c896c4,Fix kolla-ansible to work with pyenv-virtualenv,MERGED,2020-11-19 13:34:39.000000000,2020-11-30 16:18:36.000000000,2020-11-30 16:16:51.000000000,"[{'_account_id': 22348}, {'_account_id': 30491}, {'_account_id': 30523}, {'_account_id': 32662}]","[{'number': 1, 'created': '2020-11-19 13:34:39.000000000', 'files': ['tools/kolla-ansible'], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/fe673130c00adf2b2e21e87620edc8b2288bf94c', 'message': 'Fix kolla-ansible to work with pyenv-virtualenv\n\nOne of the pyenv-virtualenv-set-up aliases depends on a symlink.\nIt seems pyenv runs the bash script from such a path and it fails\nbecause of a failing comparison (VIRTUAL_ENV not detected).\n\nThe VIRTUAL_ENV is ensured to be fully resolved as well for safety.\n\nThis requires readlink from GNU coreutils but all supported platforms\nhave it by default.\n\nExtra comments included, as well as simplification of directory\ndetection - readlink handles this (not that `bin` itself was\never a symlink...).\n\nCloses-Bug: #1903887\nCo-Authored-By: Radosaw Piliszek <radoslaw.piliszek@gmail.com>\nChange-Id: I2fe6eb13ce7be68d346b1b3b7036859f34c896c4\n(cherry picked from commit aaab1d1b68db0c737b63ae6bce3179df0487f23f)\n'}]",0,763369,fe673130c00adf2b2e21e87620edc8b2288bf94c,17,4,1,30491,,,0,"Fix kolla-ansible to work with pyenv-virtualenv

One of the pyenv-virtualenv-set-up aliases depends on a symlink.
It seems pyenv runs the bash script from such a path and it fails
because of a failing comparison (VIRTUAL_ENV not detected).

The VIRTUAL_ENV is ensured to be fully resolved as well for safety.

This requires readlink from GNU coreutils but all supported platforms
have it by default.

Extra comments included, as well as simplification of directory
detection - readlink handles this (not that `bin` itself was
ever a symlink...).

Closes-Bug: #1903887
Co-Authored-By: Radosaw Piliszek <radoslaw.piliszek@gmail.com>
Change-Id: I2fe6eb13ce7be68d346b1b3b7036859f34c896c4
(cherry picked from commit aaab1d1b68db0c737b63ae6bce3179df0487f23f)
",git fetch https://review.opendev.org/openstack/kolla-ansible refs/changes/69/763369/1 && git format-patch -1 --stdout FETCH_HEAD,['tools/kolla-ansible'],1,fe673130c00adf2b2e21e87620edc8b2288bf94c,BUG-1903887-stable/victoria-stable/ussuri-stable/train-stable/stein," dir_name=$(dirname ""$0"") # NOTE(yoctozepto): Fix the case where dir_name is a symlink and VIRTUAL_ENV might not be. This # happens with pyenv-virtualenv, see https://bugs.launchpad.net/kolla-ansible/+bug/1903887 dir_name=$(readlink -e ""$dir_name"") elif [[ -n ${VIRTUAL_ENV} ]] && [[ ${dir_name} == ""$(readlink -e ""${VIRTUAL_ENV}/bin"")"" ]]; then # Running from sources (repo)."," dir_name=$(cd ""$(dirname ""$0"")"" &>/dev/null && pwd) elif [[ -n ${VIRTUAL_ENV} ]] && [[ ${dir_name} == ""${VIRTUAL_ENV}/bin"" ]]; then",6,2
openstack%2Foslo-incubator~master~I083f28ba1ed55100c170b212add00ab79998115c,openstack/oslo-incubator,master,I083f28ba1ed55100c170b212add00ab79998115c,Weakref cache,ABANDONED,2014-02-27 16:12:08.000000000,2020-11-30 16:16:13.000000000,,[],"[{'number': 1, 'created': '2014-02-27 16:12:08.000000000', 'files': ['openstack/common/cache/decorators.py', 'openstack/common/cache/_backends/weakref.py', 'tests/unit/cache/test_weak_ref.py'], 'web_link': 'https://opendev.org/openstack/oslo-incubator/commit/b49b78c08afe89e5be4109830a17cc60cc88a74b', 'message': 'Weakref cache\n\nA cache based on weak reference objects that can grow and shrink\nbased on local memory availability. This is idea for small caches\nused in performance tuning.\n\nIntended as a backend for a memoizer\n\nChange-Id: I083f28ba1ed55100c170b212add00ab79998115c\n'}]",0,76905,b49b78c08afe89e5be4109830a17cc60cc88a74b,1,0,1,7629,,,0,"Weakref cache

A cache based on weak reference objects that can grow and shrink
based on local memory availability. This is idea for small caches
used in performance tuning.

Intended as a backend for a memoizer

Change-Id: I083f28ba1ed55100c170b212add00ab79998115c
",git fetch https://review.opendev.org/openstack/oslo-incubator refs/changes/05/76905/1 && git format-patch -1 --stdout FETCH_HEAD,"['openstack/common/cache/decorators.py', 'openstack/common/cache/_backends/weakref.py', 'tests/unit/cache/test_weak_ref.py']",3,b49b78c08afe89e5be4109830a17cc60cc88a74b,weak-ref-cache,"# Copyright 2014 VMware # # Licensed under the Apache License, Version 2.0 (the ""License""); you may # not use this file except in compliance with the License. You may obtain # a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT # WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the # License for the specific language governing permissions and limitations # under the License. import datetime from tests.unit.cache import base class WeakRefCacheTest(base.CacheBaseTest): cache_url = 'weakref://' ",,192,0
openstack%2Freleases~master~I2a3b3766077c792924f203f95107e3b427bebaf0,openstack/releases,master,I2a3b3766077c792924f203f95107e3b427bebaf0,New bugfix release of tooz for wallaby.,MERGED,2020-11-27 17:33:08.000000000,2020-11-30 15:58:03.000000000,2020-11-30 15:58:03.000000000,"[{'_account_id': 308}, {'_account_id': 11904}, {'_account_id': 22348}]","[{'number': 1, 'created': '2020-11-27 17:33:08.000000000', 'files': ['deliverables/wallaby/tooz.yaml'], 'web_link': 'https://opendev.org/openstack/releases/commit/3be5dad1ff127665eef3fd4199dfb9ed26276eb9', 'message': 'New bugfix release of tooz for wallaby.\n\nSeveral new features.\n\nChange-Id: I2a3b3766077c792924f203f95107e3b427bebaf0\n'}]",0,764481,3be5dad1ff127665eef3fd4199dfb9ed26276eb9,8,3,1,31245,,,0,"New bugfix release of tooz for wallaby.

Several new features.

Change-Id: I2a3b3766077c792924f203f95107e3b427bebaf0
",git fetch https://review.opendev.org/openstack/releases refs/changes/81/764481/1 && git format-patch -1 --stdout FETCH_HEAD,['deliverables/wallaby/tooz.yaml'],1,3be5dad1ff127665eef3fd4199dfb9ed26276eb9,tooz_for_wallaby,releases: - version: 2.8.0 projects: - repo: openstack/tooz hash: 54448e9d8b968c6d537a4a3b648ed280174b4f2c,,5,0
openstack%2Fopenstack-ansible-os_magnum~master~Ib1d5788af53556196e89c754975e329da90970a0,openstack/openstack-ansible-os_magnum,master,Ib1d5788af53556196e89c754975e329da90970a0,Use openstack_service_*uri_proto vars by default,MERGED,2016-12-14 10:45:47.000000000,2020-11-30 15:51:40.000000000,2020-11-30 15:32:44.000000000,"[{'_account_id': 6816}, {'_account_id': 22348}, {'_account_id': 25023}, {'_account_id': 28619}]","[{'number': 1, 'created': '2016-12-14 10:45:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_magnum/commit/5f0c4e8a89e8a83a267906508c75d35ba6b0eb14', 'message': 'Use openstack_service_*uri_proto vars by default\n\nChange-Id: Ib1d5788af53556196e89c754975e329da90970a0\n'}, {'number': 2, 'created': '2020-10-15 07:21:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_magnum/commit/f3e444e06dd01484a6d2ab5639e69949de208106', 'message': 'Use openstack_service_*uri_proto vars by default\n\nChange-Id: Ib1d5788af53556196e89c754975e329da90970a0\n'}, {'number': 3, 'created': '2020-11-29 22:05:18.000000000', 'files': ['defaults/main.yml'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_magnum/commit/8da1816b7c951f41ff1b3b685fa52cdf26a017c5', 'message': 'Use openstack_service_*uri_proto vars by default\n\nChange-Id: Ib1d5788af53556196e89c754975e329da90970a0\n'}]",0,410681,8da1816b7c951f41ff1b3b685fa52cdf26a017c5,14,4,3,819,,,0,"Use openstack_service_*uri_proto vars by default

Change-Id: Ib1d5788af53556196e89c754975e329da90970a0
",git fetch https://review.opendev.org/openstack/openstack-ansible-os_magnum refs/changes/81/410681/2 && git format-patch -1 --stdout FETCH_HEAD,['defaults/main.yml'],1,5f0c4e8a89e8a83a267906508c75d35ba6b0eb14,default-proto-vars,"magnum_service_proto: http magnum_service_publicuri_proto: ""{{ openstack_service_publicuri_proto | default(magnum_service_proto) }}""magnum_service_internaluri_proto: ""{{ openstack_service_internaluri_proto | default(magnum_service_proto) }}""magnum_service_adminuri_proto: ""{{ openstack_service_adminuri_proto | default(magnum_service_proto) }}""",magnum_service_publicuri_proto: httpmagnum_service_internaluri_proto: httpmagnum_service_adminuri_proto: http,4,3
openstack%2Fneutron~master~Icef16ae0110ba76ac0cf4fca9f29e70d19d34ac0,openstack/neutron,master,Icef16ae0110ba76ac0cf4fca9f29e70d19d34ac0,[Doc] Remove info about compiling ovs kernel module in fullstack job,MERGED,2020-11-26 15:27:04.000000000,2020-11-30 15:50:00.000000000,2020-11-30 15:28:18.000000000,"[{'_account_id': 1131}, {'_account_id': 8313}, {'_account_id': 22348}]","[{'number': 1, 'created': '2020-11-26 15:27:04.000000000', 'files': ['TESTING.rst'], 'web_link': 'https://opendev.org/openstack/neutron/commit/087bd9aa1c0594af950ea52bbe2e22972f4188e1', 'message': ""[Doc] Remove info about compiling ovs kernel module in fullstack job\n\nThis isn't true since long time so lets make docs up to date also.\n\nTrivialFix\n\nChange-Id: Icef16ae0110ba76ac0cf4fca9f29e70d19d34ac0\n""}]",0,764354,087bd9aa1c0594af950ea52bbe2e22972f4188e1,8,3,1,11975,,,0,"[Doc] Remove info about compiling ovs kernel module in fullstack job

This isn't true since long time so lets make docs up to date also.

TrivialFix

Change-Id: Icef16ae0110ba76ac0cf4fca9f29e70d19d34ac0
",git fetch https://review.opendev.org/openstack/neutron refs/changes/54/764354/1 && git format-patch -1 --stdout FETCH_HEAD,['TESTING.rst'],1,087bd9aa1c0594af950ea52bbe2e22972f4188e1,new-debugging-guides,,Gate exceptions +++++++++++++++ Currently we compile openvswitch kernel module from source for fullstack job on the gate. The reason is to fix bug related to local VXLAN tunneling which is present in current Ubuntu Xenial 16.04 kernel. Kernel was fixed with this `commit <https://github.com/torvalds/linux/commit/bbec7802c6948c8626b71a4fe31283cb4691c358>`_ and backported with this `openvswitch commit <https://github.com/openvswitch/ovs/commit/b1c74f35273122db4ce2728a70fd34b98f525434>`_. ,0,10
openstack%2Fkuryr-kubernetes~master~Ia91ad1c3384a35bb9c87c092e20862a188aa2fdf,openstack/kuryr-kubernetes,master,Ia91ad1c3384a35bb9c87c092e20862a188aa2fdf,Change registry for fetching coredns image.,MERGED,2020-11-26 15:40:56.000000000,2020-11-30 15:42:06.000000000,2020-11-30 15:23:50.000000000,"[{'_account_id': 11600}, {'_account_id': 22348}, {'_account_id': 23567}, {'_account_id': 27032}, {'_account_id': 30963}]","[{'number': 1, 'created': '2020-11-26 15:40:56.000000000', 'files': ['devstack/plugin.sh'], 'web_link': 'https://opendev.org/openstack/kuryr-kubernetes/commit/42b5790064bb785d1bb5c79cf10f9507c364559d', 'message': 'Change registry for fetching coredns image.\n\nWe see a lot of issues regarding fetching images from docker.io, due to\ntheir latest changes to the quota policy, so that we decided to move to\nregistry quay.io.\n\nChange-Id: Ia91ad1c3384a35bb9c87c092e20862a188aa2fdf\n'}]",0,764358,42b5790064bb785d1bb5c79cf10f9507c364559d,23,5,1,13692,,,0,"Change registry for fetching coredns image.

We see a lot of issues regarding fetching images from docker.io, due to
their latest changes to the quota policy, so that we decided to move to
registry quay.io.

Change-Id: Ia91ad1c3384a35bb9c87c092e20862a188aa2fdf
",git fetch https://review.opendev.org/openstack/kuryr-kubernetes refs/changes/58/764358/1 && git format-patch -1 --stdout FETCH_HEAD,['devstack/plugin.sh'],1,42b5790064bb785d1bb5c79cf10f9507c364559d,move-to-quay, image: quay.io/kuryr/coredns:1.5.0, image: coredns/coredns:1.5.0,1,1
openstack%2Frpm-packaging~master~I833403fc8ade9721a1a8fc24dfc9787d4ab708aa,openstack/rpm-packaging,master,I833403fc8ade9721a1a8fc24dfc9787d4ab708aa,Retire congressclient and qinlingclient,MERGED,2020-11-19 14:07:37.000000000,2020-11-30 15:29:49.000000000,2020-11-30 13:35:32.000000000,"[{'_account_id': 6593}, {'_account_id': 7102}, {'_account_id': 19648}, {'_account_id': 22348}, {'_account_id': 23181}, {'_account_id': 27380}, {'_account_id': 28522}]","[{'number': 1, 'created': '2020-11-19 14:07:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rpm-packaging/commit/1b6cd203343543ac62732e64e4f5d5da817927c3', 'message': 'Retire congressclient and qinlingclient\n\nBoth projects have already been removed [1] or in the process of\nbeing removed [2].\n\n[1] - https://review.opendev.org/721741\n[2] - http://lists.openstack.org/pipermail/openstack-discuss/2020-November/018638.html\n\nChange-Id: I833403fc8ade9721a1a8fc24dfc9787d4ab708aa\n'}, {'number': 2, 'created': '2020-11-30 13:15:40.000000000', 'files': ['openstack/python-congressclient/python-congressclient.spec.j2', 'openstack/python-openstackclient/python-openstackclient.spec.j2', 'openstack/python-qinlingclient/python-qinlingclient.spec.j2'], 'web_link': 'https://opendev.org/openstack/rpm-packaging/commit/e81195d254953d6a40aad748f593bac46bf14727', 'message': 'Retire congressclient and qinlingclient\n\nBoth projects have already been removed [1] or in the process of\nbeing removed [2].\n\n[1] - https://review.opendev.org/721741\n[2] - http://lists.openstack.org/pipermail/openstack-discuss/2020-November/018638.html\n\nChange-Id: I833403fc8ade9721a1a8fc24dfc9787d4ab708aa\n'}]",0,763376,e81195d254953d6a40aad748f593bac46bf14727,33,7,2,13294,,,0,"Retire congressclient and qinlingclient

Both projects have already been removed [1] or in the process of
being removed [2].

[1] - https://review.opendev.org/721741
[2] - http://lists.openstack.org/pipermail/openstack-discuss/2020-November/018638.html

Change-Id: I833403fc8ade9721a1a8fc24dfc9787d4ab708aa
",git fetch https://review.opendev.org/openstack/rpm-packaging refs/changes/76/763376/1 && git format-patch -1 --stdout FETCH_HEAD,"['openstack/python-congressclient/python-congressclient.spec.j2', 'openstack/python-openstackclient/python-openstackclient.spec.j2', 'openstack/python-qinlingclient/python-qinlingclient.spec.j2']",3,1b6cd203343543ac62732e64e4f5d5da817927c3,,,"{% set pypi_name = 'python-qinlingclient' %} {% set upstream_version = upstream_version('5.1.1') %} {% set rpm_release = '1' %} {% set source = url_pypi() %} Name: {{ py2name() }} Version: {{ py2rpmversion() }} Release: {{ py2rpmrelease() }} Summary: Python API and CLI for OpenStack Qinling License: {{ license('Apache-2.0')}} Group: Development/Languages/Python URL: https://docs.openstack.org/{{ pypi_name }} Source0: {{ source }} BuildRequires: openstack-macros BuildRequires: {{ py3('cliff') }} BuildRequires: {{ py3('keystoneauth1') }} BuildRequires: {{ py3('python-keystoneclient') }} BuildRequires: {{ py3('mock') }} BuildRequires: {{ py3('osc-lib') }} BuildRequires: {{ py3('oslo.log') }} BuildRequires: {{ py3('oslotest') }} BuildRequires: {{ py3('pbr') }} BuildRequires: {{ py3('requests-mock') }} BuildRequires: {{ py3('stestr') }} BuildRequires: {{ py3('testscenarios') }} BuildRequires: {{ py3('testtools') }} BuildArch: noarch %description This is an OpenStack Client (OSC) plugin for Qinling, an OpenStack Function as a Service project. %package -n python3-qinlingclient Summary: Python API and CLI for OpenStack Qinling Requires: {{ py3('Babel') }} Requires: {{ py3('PrettyTable') }} Requires: {{ py3('PyYAML') }} Requires: {{ py3('iso8601') }} Requires: {{ py3('python-keystoneclient') }} Requires: {{ py3('python-openstackclient') }} Requires: {{ py3('osc-lib') }} Requires: {{ py3('oslo.i18n') }} Requires: {{ py3('oslo.log') }} Requires: {{ py3('oslo.serialization') }} Requires: {{ py3('oslo.utils') }} Requires: {{ py3('pbr') }} Requires: {{ py3('requests') }} Requires: {{ py3('six') }} %description -n python3-qinlingclient This is an OpenStack Client (OSC) plugin for Qinling, an OpenStack Function as a Service project. This package contains the Python 3.x module. %package -n python-qinlingclient-doc Summary: Documentation for OpenStack Qinling API Client Group: Documentation/HTML BuildRequires: {{ py3('Sphinx') }} BuildRequires: {{ py3('openstackdocstheme') }} BuildRequires: {{ py3('reno') }} %description -n python-qinlingclient-doc This is an OpenStack Client (OSC) plugin for Qinling, an OpenStack Function as a Service project. This package contains auto-generated documentation. %prep %autosetup -p1 -n {{ pypi_name }}-{{ upstream_version }} %py_req_cleanup %build %{py3_build} PBR_VERSION={{ upstream_version }} %sphinx_build -b html doc/source doc/build/html # remove the sphinx-build leftovers rm -rf doc/build/html/.{doctrees,buildinfo} %install %{py3_install} %check python3 -m stestr.cli run %files -n python3-qinlingclient %license LICENSE %doc README.rst ChangeLog %{python3_sitelib}/qinlingclient %{python3_sitelib}/*.egg-info %files -n python-qinlingclient-doc %license LICENSE %doc doc/build/html %changelog ",0,191
openstack%2Frpm-packaging~master~If219a47aee97af869eb4c66430d511a9eb27e28a,openstack/rpm-packaging,master,If219a47aee97af869eb4c66430d511a9eb27e28a,Remove retired python-qinlingclient usage,ABANDONED,2020-11-28 16:41:07.000000000,2020-11-30 15:22:01.000000000,,"[{'_account_id': 13294}, {'_account_id': 19648}, {'_account_id': 22348}, {'_account_id': 23181}, {'_account_id': 28522}]","[{'number': 1, 'created': '2020-11-28 16:41:07.000000000', 'files': ['openstack/python-qinlingclient/python-qinlingclient.spec.j2'], 'web_link': 'https://opendev.org/openstack/rpm-packaging/commit/e31335f078dc61c1461f5e7d85c9aef7f99f1395', 'message': 'Remove retired python-qinlingclient usage\n\nQinling project is retiring in Wallaby cycle[1].\nThis commit removes the usages/support of python-qinlingclient\nproject before its code is removed.\n\nNeeded-By: https://review.opendev.org/c/openstack/qinling/+/764521\n\n[1] http://lists.openstack.org/pipermail/openstack-discuss/2020-November/018638.html\n\nChange-Id: If219a47aee97af869eb4c66430d511a9eb27e28a\n'}]",0,764561,e31335f078dc61c1461f5e7d85c9aef7f99f1395,8,5,1,8556,,,0,"Remove retired python-qinlingclient usage

Qinling project is retiring in Wallaby cycle[1].
This commit removes the usages/support of python-qinlingclient
project before its code is removed.

Needed-By: https://review.opendev.org/c/openstack/qinling/+/764521

[1] http://lists.openstack.org/pipermail/openstack-discuss/2020-November/018638.html

Change-Id: If219a47aee97af869eb4c66430d511a9eb27e28a
",git fetch https://review.opendev.org/openstack/rpm-packaging refs/changes/61/764561/1 && git format-patch -1 --stdout FETCH_HEAD,['openstack/python-qinlingclient/python-qinlingclient.spec.j2'],1,e31335f078dc61c1461f5e7d85c9aef7f99f1395,retire-qinling,,"{% set pypi_name = 'python-qinlingclient' %} {% set upstream_version = upstream_version('5.1.1') %} {% set rpm_release = '1' %} {% set source = url_pypi() %} Name: {{ py2name() }} Version: {{ py2rpmversion() }} Release: {{ py2rpmrelease() }} Summary: Python API and CLI for OpenStack Qinling License: {{ license('Apache-2.0')}} Group: Development/Languages/Python URL: https://docs.openstack.org/{{ pypi_name }} Source0: {{ source }} BuildRequires: openstack-macros BuildRequires: {{ py3('cliff') }} BuildRequires: {{ py3('keystoneauth1') }} BuildRequires: {{ py3('python-keystoneclient') }} BuildRequires: {{ py3('mock') }} BuildRequires: {{ py3('osc-lib') }} BuildRequires: {{ py3('oslo.log') }} BuildRequires: {{ py3('oslotest') }} BuildRequires: {{ py3('pbr') }} BuildRequires: {{ py3('requests-mock') }} BuildRequires: {{ py3('stestr') }} BuildRequires: {{ py3('testscenarios') }} BuildRequires: {{ py3('testtools') }} BuildArch: noarch %description This is an OpenStack Client (OSC) plugin for Qinling, an OpenStack Function as a Service project. %package -n python3-qinlingclient Summary: Python API and CLI for OpenStack Qinling Requires: {{ py3('Babel') }} Requires: {{ py3('PrettyTable') }} Requires: {{ py3('PyYAML') }} Requires: {{ py3('iso8601') }} Requires: {{ py3('python-keystoneclient') }} Requires: {{ py3('python-openstackclient') }} Requires: {{ py3('osc-lib') }} Requires: {{ py3('oslo.i18n') }} Requires: {{ py3('oslo.log') }} Requires: {{ py3('oslo.serialization') }} Requires: {{ py3('oslo.utils') }} Requires: {{ py3('pbr') }} Requires: {{ py3('requests') }} Requires: {{ py3('six') }} %description -n python3-qinlingclient This is an OpenStack Client (OSC) plugin for Qinling, an OpenStack Function as a Service project. This package contains the Python 3.x module. %package -n python-qinlingclient-doc Summary: Documentation for OpenStack Qinling API Client Group: Documentation/HTML BuildRequires: {{ py3('Sphinx') }} BuildRequires: {{ py3('openstackdocstheme') }} BuildRequires: {{ py3('reno') }} %description -n python-qinlingclient-doc This is an OpenStack Client (OSC) plugin for Qinling, an OpenStack Function as a Service project. This package contains auto-generated documentation. %prep %autosetup -p1 -n {{ pypi_name }}-{{ upstream_version }} %py_req_cleanup %build %{py3_build} PBR_VERSION={{ upstream_version }} %sphinx_build -b html doc/source doc/build/html # remove the sphinx-build leftovers rm -rf doc/build/html/.{doctrees,buildinfo} %install %{py3_install} %check python3 -m stestr.cli run %files -n python3-qinlingclient %license LICENSE %doc README.rst ChangeLog %{python3_sitelib}/qinlingclient %{python3_sitelib}/*.egg-info %files -n python-qinlingclient-doc %license LICENSE %doc doc/build/html %changelog ",0,95
openstack%2Fnova~master~I6071d9ac8026c0b4c324ad8d088d0031c9753ec4,openstack/nova,master,I6071d9ac8026c0b4c324ad8d088d0031c9753ec4,DNM,ABANDONED,2020-11-30 15:15:08.000000000,2020-11-30 15:20:28.000000000,,[],"[{'number': 1, 'created': '2020-11-30 15:15:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/f8c5bc79389c97b33f8640fd8001cc1e1b0093fd', 'message': 'DNM\n\nChange-Id: I6071d9ac8026c0b4c324ad8d088d0031c9753ec4\n'}]",0,764773,f8c5bc79389c97b33f8640fd8001cc1e1b0093fd,2,0,1,9708,,,0,"DNM

Change-Id: I6071d9ac8026c0b4c324ad8d088d0031c9753ec4
",git fetch https://review.opendev.org/openstack/nova refs/changes/73/764773/1 && git format-patch -1 --stdout FETCH_HEAD,[],0,f8c5bc79389c97b33f8640fd8001cc1e1b0093fd,,,,0,0
openstack%2Fnova~master~I926ae8435e2714895cc0ada4b727d3370782824b,openstack/nova,master,I926ae8435e2714895cc0ada4b727d3370782824b,DNM,ABANDONED,2020-11-30 15:13:50.000000000,2020-11-30 15:20:21.000000000,,[],"[{'number': 1, 'created': '2020-11-30 15:13:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/89585423fb2ac38c3a649e3a160e1aef0320d782', 'message': 'DNM\n\nChange-Id: I926ae8435e2714895cc0ada4b727d3370782824b\n'}]",0,764772,89585423fb2ac38c3a649e3a160e1aef0320d782,2,0,1,9708,,,0,"DNM

Change-Id: I926ae8435e2714895cc0ada4b727d3370782824b
",git fetch https://review.opendev.org/openstack/nova refs/changes/72/764772/1 && git format-patch -1 --stdout FETCH_HEAD,[],0,89585423fb2ac38c3a649e3a160e1aef0320d782,,,,0,0
openstack%2Fnova~master~I804d9122926866d5af92b58eb7c83bf038d4310d,openstack/nova,master,I804d9122926866d5af92b58eb7c83bf038d4310d,DNM,ABANDONED,2020-11-30 15:11:54.000000000,2020-11-30 15:13:00.000000000,,[],"[{'number': 1, 'created': '2020-11-30 15:11:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/8f78a12bd4ff9124049b1dae5da4cb242b43e3c8', 'message': 'DNM\n\nChange-Id: I804d9122926866d5af92b58eb7c83bf038d4310d\n'}]",0,764771,8f78a12bd4ff9124049b1dae5da4cb242b43e3c8,2,0,1,9708,,,0,"DNM

Change-Id: I804d9122926866d5af92b58eb7c83bf038d4310d
",git fetch https://review.opendev.org/openstack/nova refs/changes/71/764771/1 && git format-patch -1 --stdout FETCH_HEAD,[],0,8f78a12bd4ff9124049b1dae5da4cb242b43e3c8,,,,0,0
openstack%2Fcloudkitty~master~I7b88b55bfceff177b0ed0586d105353f7159b171,openstack/cloudkitty,master,I7b88b55bfceff177b0ed0586d105353f7159b171,Replace deprecated UPPER_CONSTRAINTS_FILE variable,MERGED,2020-11-27 12:40:49.000000000,2020-11-30 15:08:57.000000000,2020-11-30 15:06:09.000000000,"[{'_account_id': 15197}, {'_account_id': 22348}, {'_account_id': 28356}, {'_account_id': 32231}]","[{'number': 1, 'created': '2020-11-27 12:40:49.000000000', 'files': ['tox.ini'], 'web_link': 'https://opendev.org/openstack/cloudkitty/commit/11ff713042eb0354f497f7051130630c46860735', 'message': 'Replace deprecated UPPER_CONSTRAINTS_FILE variable\n\nUPPER_CONSTRAINTS_FILE is old name and deprecated\n-https://zuul-ci.org/docs/zuul-jobs/python-roles.html#rolevar-tox.tox_constraints_file\nThis allows to use lower-constraints file as more\nreadable way instead of UPPER_CONSTRAINTS_FILE=<lower-constraints file>.\n\nChange-Id: I7b88b55bfceff177b0ed0586d105353f7159b171\n'}]",0,764460,11ff713042eb0354f497f7051130630c46860735,9,4,1,26285,,,0,"Replace deprecated UPPER_CONSTRAINTS_FILE variable

UPPER_CONSTRAINTS_FILE is old name and deprecated
-https://zuul-ci.org/docs/zuul-jobs/python-roles.html#rolevar-tox.tox_constraints_file
This allows to use lower-constraints file as more
readable way instead of UPPER_CONSTRAINTS_FILE=<lower-constraints file>.

Change-Id: I7b88b55bfceff177b0ed0586d105353f7159b171
",git fetch https://review.opendev.org/openstack/cloudkitty refs/changes/60/764460/1 && git format-patch -1 --stdout FETCH_HEAD,['tox.ini'],1,11ff713042eb0354f497f7051130630c46860735,,install_command = pip install -c{env:TOX_CONSTRAINTS_FILE:https://releases.openstack.org/constraints/upper/master} {opts} {packages},install_command = pip install -c{env:UPPER_CONSTRAINTS_FILE:https://releases.openstack.org/constraints/upper/master} {opts} {packages},1,1
openstack%2Fpuppet-ovn~master~I884a1bd836d21fba520bf5a6c17ff2bdc949e31f,openstack/puppet-ovn,master,I884a1bd836d21fba520bf5a6c17ff2bdc949e31f,Add new update parameter: enable_ovn_match_northd.,MERGED,2020-11-24 01:45:05.000000000,2020-11-30 15:06:18.000000000,2020-11-30 15:06:18.000000000,"[{'_account_id': 8655}, {'_account_id': 9816}, {'_account_id': 10237}, {'_account_id': 11082}, {'_account_id': 14985}, {'_account_id': 22348}]","[{'number': 1, 'created': '2020-11-24 01:45:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-ovn/commit/b1f51f7abcaa1dac386f8bfd36e2ff1043b14df6', 'message': ""Add new update parameter: enable_ovn_match_northd.\n\nThis new boolean parameter enable one to update ovn-controller before\novn-northd. It tells the ovn-controller to not fetch new messages from\nthe ovn-northd if this later is newer.\n\nIt's false by default so nothing changes.\n\nChange-Id: I884a1bd836d21fba520bf5a6c17ff2bdc949e31f\n""}, {'number': 2, 'created': '2020-11-24 02:09:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-ovn/commit/f9a029cb4480b14cc051a710ada1c61f8fe08a84', 'message': ""Add new update parameter: enable_ovn_match_northd.\n\nThis new boolean parameter enable one to update ovn-controller before\novn-northd. It tells the ovn-controller to not fetch new messages from\nthe ovn-northd if this later is newer.\n\nIt's false by default so nothing changes.\n\nChange-Id: I884a1bd836d21fba520bf5a6c17ff2bdc949e31f\n""}, {'number': 3, 'created': '2020-11-24 13:47:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-ovn/commit/a88c149293d4530a54f74b1260ddab055b429a3d', 'message': ""Add new update parameter: enable_ovn_match_northd.\n\nThis new boolean parameter enables update of the ovn-controllers after\novn-northd. It tells the ovn-controller to not fetch new messages from\nthe ovn-northd until they are both the same version.\n\nIt's false by default so nothing changes.\n\nChange-Id: I884a1bd836d21fba520bf5a6c17ff2bdc949e31f\n""}, {'number': 4, 'created': '2020-11-25 18:27:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-ovn/commit/df0cd14fedad12b179b645ca52abaf6e6ddf9d0e', 'message': ""Add new update parameter: enable_ovn_match_northd.\n\nThis new boolean parameter enables update of the ovn-controllers after\novn-northd. It tells the ovn-controller to not fetch new messages from\nthe ovn-northd until they are both the same version.\n\nIt's false by default so nothing changes.\n\nChange-Id: I884a1bd836d21fba520bf5a6c17ff2bdc949e31f\n""}, {'number': 5, 'created': '2020-11-25 20:11:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-ovn/commit/011aa7f933e66739baa70b7b83b850ba337d7bae', 'message': ""Add new update parameter: enable_ovn_match_northd.\n\nThis new boolean parameter enables update of the ovn-controllers after\novn-northd. It tells the ovn-controller to not fetch new messages from\nthe ovn-northd until they are both the same version.\n\nIt's false by default so nothing changes.\n\nChange-Id: I884a1bd836d21fba520bf5a6c17ff2bdc949e31f\n""}, {'number': 6, 'created': '2020-11-25 23:11:07.000000000', 'files': ['spec/classes/ovn_controller_spec.rb', 'manifests/controller.pp'], 'web_link': 'https://opendev.org/openstack/puppet-ovn/commit/392ad7946ef5c7659f9320a3f832245e21f8365f', 'message': ""Add new update parameter: enable_ovn_match_northd.\n\nThis new boolean parameter enables update of the ovn-controllers after\novn-northd. It tells the ovn-controller to not fetch new messages from\nthe ovn-northd until they are both the same version.\n\nIt's false by default so nothing changes.\n\nChange-Id: I884a1bd836d21fba520bf5a6c17ff2bdc949e31f\n""}]",10,763895,392ad7946ef5c7659f9320a3f832245e21f8365f,24,6,6,8297,,,0,"Add new update parameter: enable_ovn_match_northd.

This new boolean parameter enables update of the ovn-controllers after
ovn-northd. It tells the ovn-controller to not fetch new messages from
the ovn-northd until they are both the same version.

It's false by default so nothing changes.

Change-Id: I884a1bd836d21fba520bf5a6c17ff2bdc949e31f
",git fetch https://review.opendev.org/openstack/puppet-ovn refs/changes/95/763895/6 && git format-patch -1 --stdout FETCH_HEAD,"['spec/classes/ovn_controller_spec.rb', 'manifests/controller.pp']",2,b1f51f7abcaa1dac386f8bfd36e2ff1043b14df6,," $enable_ovn_match_northd = false, if $enable_ovn_match_northd { $ovn_match_northd = { 'external_ids:ovn-match-northd-version' => { 'value' => 'true' } } } else { $ovn_match_northd = {} } create_resources('vs_config', merge($config_items, $bridge_items, $tz_items, $hw_offload, $datapath_config, $enable_ovn_match_northd))"," create_resources('vs_config', merge($config_items, $bridge_items, $tz_items, $hw_offload, $datapath_config))",10,1
openstack%2Fansible-role-qdrouterd~stable%2Fussuri~I3adbc415f5afcb020f648a5e98a5dda193673624,openstack/ansible-role-qdrouterd,stable/ussuri,I3adbc415f5afcb020f648a5e98a5dda193673624,Add centos-8 and ubuntu focal support,MERGED,2020-11-04 16:36:09.000000000,2020-11-30 14:58:39.000000000,2020-11-30 14:50:01.000000000,"[{'_account_id': 22348}, {'_account_id': 25023}, {'_account_id': 28619}, {'_account_id': 28752}, {'_account_id': 29865}]","[{'number': 1, 'created': '2020-11-04 16:36:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ansible-role-qdrouterd/commit/1fcb4e076d18a60c5389188151685bf917157d1f', 'message': 'Add centos-8 and ubuntu focal support\n\nadding python3-qpid-proton package for centos-8 and focal support.\n\nChange-Id: I3adbc415f5afcb020f648a5e98a5dda193673624\n(cherry picked from commit 2b7b2ada9fc0ce7c0ca5508f6432627dc70edbac)\n'}, {'number': 2, 'created': '2020-11-23 09:22:06.000000000', 'files': ['bindep.txt', 'vars/redhat.yml', 'vars/ubuntu.yml', 'tasks/qdrouterd_install_dnf.yml', 'zuul.d/project.yaml'], 'web_link': 'https://opendev.org/openstack/ansible-role-qdrouterd/commit/19dc77221f9602280e7dacef491143117689c0d2', 'message': 'Add centos-8 and ubuntu focal support\n\nadding python3-qpid-proton package for centos-8 and focal support.\n\nChange-Id: I3adbc415f5afcb020f648a5e98a5dda193673624\n(cherry picked from commit 2b7b2ada9fc0ce7c0ca5508f6432627dc70edbac)\n'}]",0,761444,19dc77221f9602280e7dacef491143117689c0d2,14,5,2,28619,,,0,"Add centos-8 and ubuntu focal support

adding python3-qpid-proton package for centos-8 and focal support.

Change-Id: I3adbc415f5afcb020f648a5e98a5dda193673624
(cherry picked from commit 2b7b2ada9fc0ce7c0ca5508f6432627dc70edbac)
",git fetch https://review.opendev.org/openstack/ansible-role-qdrouterd refs/changes/44/761444/1 && git format-patch -1 --stdout FETCH_HEAD,"['vars/redhat.yml', 'vars/ubuntu.yml', 'tasks/qdrouterd_install_dnf.yml', 'zuul.d/project.yaml']",4,1fcb4e076d18a60c5389188151685bf917157d1f,osa/el8-stable/ussuri, - openstack-ansible-functional-centos-8 - openstack-ansible-functional-ubuntu-focal - openstack-ansible-functional-centos-8 - openstack-ansible-functional-ubuntu-focal,,7,2
openstack%2Fnova~master~I75c21298ef1015edddb85f1413580ade32b455e0,openstack/nova,master,I75c21298ef1015edddb85f1413580ade32b455e0,DNM,ABANDONED,2020-11-30 14:47:45.000000000,2020-11-30 14:51:43.000000000,,[],"[{'number': 1, 'created': '2020-11-30 14:47:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/3de94b002af039bd1cf340e7f0f42b66ed7f71b0', 'message': 'DNM\n\nChange-Id: I75c21298ef1015edddb85f1413580ade32b455e0\n'}]",0,764766,3de94b002af039bd1cf340e7f0f42b66ed7f71b0,2,0,1,9708,,,0,"DNM

Change-Id: I75c21298ef1015edddb85f1413580ade32b455e0
",git fetch https://review.opendev.org/openstack/nova refs/changes/66/764766/1 && git format-patch -1 --stdout FETCH_HEAD,[],0,3de94b002af039bd1cf340e7f0f42b66ed7f71b0,,,,0,0
openstack%2Ftripleo-common~master~I6db21d1f8c0e531c49c151858de9098639fb05f5,openstack/tripleo-common,master,I6db21d1f8c0e531c49c151858de9098639fb05f5,TCIB: Pick not best when building on centos/ubi,MERGED,2020-11-18 15:31:15.000000000,2020-11-30 14:38:54.000000000,2020-11-30 14:33:33.000000000,"[{'_account_id': 3153}, {'_account_id': 6926}, {'_account_id': 7353}, {'_account_id': 9592}, {'_account_id': 10969}, {'_account_id': 13861}, {'_account_id': 14985}, {'_account_id': 16312}, {'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2020-11-18 15:31:15.000000000', 'files': ['container-images/tcib/base/base.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-common/commit/257cee80d7a173fb32bf43fb04f8e0dd4244c57c', 'message': 'TCIB: Pick not best when building on centos/ubi\n\nWhen building on UBI (like we do in upstream CI), we may need some\ncentos repos. And those may bring conflicts with ubi repos.\n\nAllowing --nobest mode for the package manager, highly likely\nresolves those conflicts... as the best effort.\n\nChange-Id: I6db21d1f8c0e531c49c151858de9098639fb05f5\nSigned-off-by: Bogdan Dobrelya <bdobreli@redhat.com>\n'}]",0,763203,257cee80d7a173fb32bf43fb04f8e0dd4244c57c,34,10,1,6926,,,0,"TCIB: Pick not best when building on centos/ubi

When building on UBI (like we do in upstream CI), we may need some
centos repos. And those may bring conflicts with ubi repos.

Allowing --nobest mode for the package manager, highly likely
resolves those conflicts... as the best effort.

Change-Id: I6db21d1f8c0e531c49c151858de9098639fb05f5
Signed-off-by: Bogdan Dobrelya <bdobreli@redhat.com>
",git fetch https://review.opendev.org/openstack/tripleo-common refs/changes/03/763203/1 && git format-patch -1 --stdout FETCH_HEAD,['container-images/tcib/base/base.yaml'],1,257cee80d7a173fb32bf43fb04f8e0dd4244c57c,bug/1902846, if [ '{{ tcib_distro }}' == 'centos' ];then crudini --set /etc/dnf/dnf.conf main best False; fi &&,,1,0
openstack%2Ftripleo-heat-templates~master~I7f7aa92695fa4b5eff5b3e0b8d282d65c4c4b0da,openstack/tripleo-heat-templates,master,I7f7aa92695fa4b5eff5b3e0b8d282d65c4c4b0da,WIP: VXLAN test,ABANDONED,2020-11-04 07:49:38.000000000,2020-11-30 14:08:17.000000000,,"[{'_account_id': 11082}, {'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2020-11-04 07:49:38.000000000', 'files': ['environments/services/neutron-ovn-ha.yaml', 'environments/services/neutron-ovn-standalone.yaml', 'environments/services-baremetal/neutron-ovn-ha.yaml', 'releasenotes/notes/vxlan-support-for-ovn-1320be8046aca9c6.yaml', 'environments/services-baremetal/neutron-ovn-dvr-ha.yaml', 'deployment/neutron/neutron-plugin-ml2.yaml', 'tools/yaml-validate.py', 'environments/services/neutron-ovn-dvr-ha.yaml', 'deployment/neutron/neutron-plugin-ml2-ovn.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/feaa3c676a0b85a959c5e8a1b950f34882c5c02e', 'message': 'WIP: VXLAN test\n\nChange-Id: I7f7aa92695fa4b5eff5b3e0b8d282d65c4c4b0da\n'}]",0,761290,feaa3c676a0b85a959c5e8a1b950f34882c5c02e,7,3,1,11082,,,0,"WIP: VXLAN test

Change-Id: I7f7aa92695fa4b5eff5b3e0b8d282d65c4c4b0da
",git fetch https://review.opendev.org/openstack/tripleo-heat-templates refs/changes/90/761290/1 && git format-patch -1 --stdout FETCH_HEAD,"['environments/services/neutron-ovn-ha.yaml', 'environments/services/neutron-ovn-standalone.yaml', 'environments/services-baremetal/neutron-ovn-ha.yaml', 'releasenotes/notes/vxlan-support-for-ovn-1320be8046aca9c6.yaml', 'environments/services-baremetal/neutron-ovn-dvr-ha.yaml', 'deployment/neutron/neutron-plugin-ml2.yaml', 'tools/yaml-validate.py', 'environments/services/neutron-ovn-dvr-ha.yaml', 'deployment/neutron/neutron-plugin-ml2-ovn.yaml']",9,feaa3c676a0b85a959c5e8a1b950f34882c5c02e,vxlan_test, NeutronNetworkType: default: 'geneve' description: The tenant network type for Neutron. type: comma_delimited_list constraints: - allowed_values: - geneve - vxlan - vlan - flat neutron::plugins::ml2::tenant_network_types: {get_param: NeutronNetworkType}," # NOTE(anil): OVN supports only VLAN, geneve and flat networks NeutronNetworkType: default: 'geneve' description: The tenant network type for Neutron. type: comma_delimited_list constraints: - allowed_values: - geneve - vlan - flat neutron::plugins::ml2::tenant_network_types: {get_param: NeutronNetworkType}",31,21
openstack%2Fopenstack-helm-infra~master~I1ad48ade3984e455d07be3a8b8ee3d9b25b449a2,openstack/openstack-helm-infra,master,I1ad48ade3984e455d07be3a8b8ee3d9b25b449a2,fix(secret): changes rmq-exporter secret src,MERGED,2020-11-20 00:15:18.000000000,2020-11-30 14:05:38.000000000,2020-11-23 22:52:55.000000000,"[{'_account_id': 8898}, {'_account_id': 21420}, {'_account_id': 22348}, {'_account_id': 30777}]","[{'number': 1, 'created': '2020-11-20 00:15:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/6e2a4e492f752f287f650fb19ba6da934538697f', 'message': ""fix(secret): changes rmq-exporter secret src\n\nThis patch set changes the source of the rabbitmq-exporter's admin user\ncredential to leverage the existing secret rather than the values in the\nValues.yaml file.\n\nChange-Id: I1ad48ade3984e455d07be3a8b8ee3d9b25b449a2\nSigned-off-by: Tin Lam <tin@irrational.io>\n""}, {'number': 2, 'created': '2020-11-20 00:16:53.000000000', 'files': ['rabbitmq/templates/monitoring/prometheus/exporter-deployment.yaml', 'rabbitmq/Chart.yaml', 'rabbitmq/values.yaml'], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/f001105aadd90b75afb510198a04c5d40c955952', 'message': ""fix(secret): changes rmq-exporter secret src\n\nThis patch set changes the source of the rabbitmq-exporter's admin user\ncredential to leverage the existing secret rather than the values in the\nValues.yaml file.\n\nChange-Id: I1ad48ade3984e455d07be3a8b8ee3d9b25b449a2\nSigned-off-by: Tin Lam <tin@irrational.io>\n""}]",0,763483,f001105aadd90b75afb510198a04c5d40c955952,10,4,2,20466,,,0,"fix(secret): changes rmq-exporter secret src

This patch set changes the source of the rabbitmq-exporter's admin user
credential to leverage the existing secret rather than the values in the
Values.yaml file.

Change-Id: I1ad48ade3984e455d07be3a8b8ee3d9b25b449a2
Signed-off-by: Tin Lam <tin@irrational.io>
",git fetch https://review.opendev.org/openstack/openstack-helm-infra refs/changes/83/763483/1 && git format-patch -1 --stdout FETCH_HEAD,"['rabbitmq/templates/monitoring/prometheus/exporter-deployment.yaml', 'rabbitmq/values.yaml']",2,6e2a4e492f752f287f650fb19ba6da934538697f,password-secret, secret_erlang_cookie: true, secret_erlang_cookie: true,9,3
openstack%2Fopenstack-helm-infra~master~I7bab0c9da4f71fe26bce99497c6f5cdf65e56d69,openstack/openstack-helm-infra,master,I7bab0c9da4f71fe26bce99497c6f5cdf65e56d69,Ensure pods are restricted from acquiring new priveleges,ABANDONED,2020-11-17 18:11:44.000000000,2020-11-30 13:57:50.000000000,,"[{'_account_id': 8898}, {'_account_id': 20466}, {'_account_id': 22348}]","[{'number': 1, 'created': '2020-11-17 18:11:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/be5a563e7574cdc22f792b3be9c222858b4ef16e', 'message': 'Ensure pods are restricted from acquiring new priveleges\n\nChange-Id: I7bab0c9da4f71fe26bce99497c6f5cdf65e56d69\n'}, {'number': 2, 'created': '2020-11-18 14:20:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/39ec94d5284af2919f7f9d6e87a4029b8d04b343', 'message': 'Ensure pods are restricted from acquiring new priveleges\n\nChange-Id: I7bab0c9da4f71fe26bce99497c6f5cdf65e56d69\n'}, {'number': 3, 'created': '2020-11-18 16:47:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/1082a81b6058e6d16ea844fde6a3fd5be9e44986', 'message': 'Ensure pods are restricted from acquiring new priveleges\n\nChange-Id: I7bab0c9da4f71fe26bce99497c6f5cdf65e56d69\n'}, {'number': 4, 'created': '2020-11-18 17:54:26.000000000', 'files': ['calico/values.yaml', 'metacontroller/values.yaml', 'elasticsearch/values.yaml', 'etcd/values.yaml', 'mariadb/values.yaml', 'rabbitmq/values.yaml'], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/cd0fd0cde62b7842c9789935fbb1437e05af1216', 'message': 'Ensure pods are restricted from acquiring new priveleges\n\nChange-Id: I7bab0c9da4f71fe26bce99497c6f5cdf65e56d69\n'}]",1,763066,cd0fd0cde62b7842c9789935fbb1437e05af1216,11,3,4,31660,,,0,"Ensure pods are restricted from acquiring new priveleges

Change-Id: I7bab0c9da4f71fe26bce99497c6f5cdf65e56d69
",git fetch https://review.opendev.org/openstack/openstack-helm-infra refs/changes/66/763066/4 && git format-patch -1 --stdout FETCH_HEAD,"['metacontroller/values.yaml', 'mariadb/values.yaml']",2,be5a563e7574cdc22f792b3be9c222858b4ef16e,, allowPrivilegeEscalation: false,,2,0
openstack%2Ftripleo-specs~master~I7890f87acfb9d5aab47ee943ab85364d309867cb,openstack/tripleo-specs,master,I7890f87acfb9d5aab47ee943ab85364d309867cb,Add spec for the removal of Swift from the Undercloud,MERGED,2020-09-15 16:37:40.000000000,2020-11-30 13:52:10.000000000,2020-11-30 13:50:10.000000000,"[{'_account_id': 360}, {'_account_id': 3153}, {'_account_id': 6681}, {'_account_id': 6968}, {'_account_id': 7144}, {'_account_id': 7353}, {'_account_id': 8449}, {'_account_id': 10239}, {'_account_id': 14985}, {'_account_id': 16515}, {'_account_id': 18002}, {'_account_id': 18575}, {'_account_id': 21129}, {'_account_id': 22348}, {'_account_id': 22865}, {'_account_id': 24245}, {'_account_id': 25402}, {'_account_id': 25877}, {'_account_id': 28223}]","[{'number': 1, 'created': '2020-09-15 16:37:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-specs/commit/e71c8dedb48c4e8558f09b3afc8800a12b8c7539', 'message': 'Add spec for the removal of Swift from the Undercloud\n\nThis spec has been submitted to enable us to remove Swift from the\nUndercloud. The Spec is a highlevel document which provides insight\ninto the process we believe we can take to excise swift from the\nUndercloud.\n\nChange-Id: I7890f87acfb9d5aab47ee943ab85364d309867cb\nSigned-off-by: Kevin Carter <kecarter@redhat.com>\n'}, {'number': 2, 'created': '2020-09-18 15:26:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-specs/commit/be650bcc375395d360d260a0096e58dbe4967332', 'message': 'Add spec for the removal of Swift from the Undercloud\n\nThis spec has been submitted to enable us to remove Swift from the\nUndercloud. The Spec is a highlevel document which provides insight\ninto the process we believe we can take to excise swift from the\nUndercloud.\n\nChange-Id: I7890f87acfb9d5aab47ee943ab85364d309867cb\nSigned-off-by: Kevin Carter <kecarter@redhat.com>\n'}, {'number': 3, 'created': '2020-09-21 20:44:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-specs/commit/43aa003ffef9c72c3e7a905e93c7fc44f140a9b8', 'message': 'Add spec for the removal of Swift from the Undercloud\n\nThis spec has been submitted to enable us to remove Swift from the\nUndercloud. The Spec is a highlevel document which provides insight\ninto the process we believe we can take to excise swift from the\nUndercloud.\n\nChange-Id: I7890f87acfb9d5aab47ee943ab85364d309867cb\nSigned-off-by: Kevin Carter <kecarter@redhat.com>\n'}, {'number': 4, 'created': '2020-09-22 15:03:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-specs/commit/df254dcad5dfeb7e012d3da66d23ae4de0d84a30', 'message': 'Add spec for the removal of Swift from the Undercloud\n\nThis spec has been submitted to enable us to remove Swift from the\nUndercloud. The Spec is a highlevel document which provides insight\ninto the process we believe we can take to excise swift from the\nUndercloud.\n\nChange-Id: I7890f87acfb9d5aab47ee943ab85364d309867cb\nSigned-off-by: Kevin Carter <kecarter@redhat.com>\n'}, {'number': 5, 'created': '2020-11-12 22:06:27.000000000', 'files': ['specs/wallaby/excise-swift.rst'], 'web_link': 'https://opendev.org/openstack/tripleo-specs/commit/e83d8aba3a950da83a33c23bcef6ffc38f00002f', 'message': 'Add spec for the removal of Swift from the Undercloud\n\nThis spec has been submitted to enable us to remove Swift from the\nUndercloud. The Spec is a highlevel document which provides insight\ninto the process we believe we can take to excise swift from the\nUndercloud.\n\nChange-Id: I7890f87acfb9d5aab47ee943ab85364d309867cb\nSigned-off-by: Kevin Carter <kecarter@redhat.com>\n'}]",59,752078,e83d8aba3a950da83a33c23bcef6ffc38f00002f,58,19,5,7353,,,0,"Add spec for the removal of Swift from the Undercloud

This spec has been submitted to enable us to remove Swift from the
Undercloud. The Spec is a highlevel document which provides insight
into the process we believe we can take to excise swift from the
Undercloud.

Change-Id: I7890f87acfb9d5aab47ee943ab85364d309867cb
Signed-off-by: Kevin Carter <kecarter@redhat.com>
",git fetch https://review.opendev.org/openstack/tripleo-specs refs/changes/78/752078/3 && git format-patch -1 --stdout FETCH_HEAD,['specs/victoria/excise-swift.rst'],1,e71c8dedb48c4e8558f09b3afc8800a12b8c7539,,".. This work is licensed under a Creative Commons Attribution 3.0 Unported License. http://creativecommons.org/licenses/by/3.0/legalcode ================================ Remove Swift from the Undercloud ================================ The goal of this proposal is to introduce the community to the idea of removing Swift from the TripleO Undercloud. Within this propose we intend to provide a high-level overview of how we can accomplish this goal. Problem Description =================== Swift is being used to store object related to the deployment which are managed entirely on the Undercloud. In the past, there was an API / UI to interact with the deployment tooling; however, with the deprecation of the UI and the removal of Mistral this is no longer the case. The Undercloud is assumed to be a single node which is used to deploy OpenStack clouds, and requires the user to login to the node to run commands. Because we're no longer attempting to make the Undercloud a distributed system there's no need for an API'able distributed storage service. Swift, in it's current state, is under-utilized and carries unnecessary operational and resource overhead. Proposed Change =============== Overview -------- Decommission Swift from the Undercloud. To decommission Swift, we'll start by removing all of the `tripleoclient` Swift interactions. These interactions are largely storing and retrieving YAML files which provide context to the user for current deployment status. To ensure we're not breaking deployment expectations, we'll push everything to the local file system and retain all of the file properties wherever possible. We will need coordinate with tripleo-ansible to ensure we're making all direct Swift client and module interactions optional. Once we're able to remove the `tripleoclient` Swift interactions, we'll move to remove Swift interactions from tripleo-common. These interactions are similar to the ones found within the `tripleoclient`, though tripleo-common has some complexity; we'll need to ensure we're not breaking expectations we've created with our puppet deployment methodologies which have some Swift assumptions. Alternatives ------------ We keep everything as-is. Security Impact --------------- There should be no significant security implications with the removal of Swift. It could be argued that removing Swift might make the deployment more secure as we'll lessen the attack surface, however, given the fact that Swift on the Undercloud is only used by director I would consider any benefit insignificant. Upgrade Impact -------------- There will be no upgrade impact; this change will be transparent to the end-user. Other End User Impact --------------------- None. Performance Impact ------------------ The removal of Swift could make some client interactions faster; however, the benefit should be negligible. That said, the removal of Swift would remove a service on the Undercloud, which would make setup faster and reduce the resources required to run the Undercloud. Other Deployer Impact --------------------- Operationally we should see an improvement as it will no longer be required to explore a Swift container, and download files to debug different parts of the deployment. All deployment related file artifacts housed within Swift will exist on the Undercloud using the local file system, and should be easily interacted with. Developer Impact ---------------- None, if anything the removal of Swift should make the life of a TripleO developer easier. Implementation ============== All of the objects stored within Swift will be stored in `/var/lib/tripleo/artifacts`. This will allow us to implement all of the same core logic in our various libraries just without the use of the API call to store the object. Excising Swift client interactions will be handled directly in as few reviews as possible; hopefully allowing us to backport this change, should it be deemed valuable to stable releases. Assignee(s) ----------- Primary assignee: cloudnull Other contributors: - emilien Work Items ---------- The work items listed here are high level, and not meant to provide specific implementation details or timelines. * Enumerate all of the Swift interactions * Create a space on the Undercloud to house the files ** This location will be on the local file system and will be created into a git archive; git is used for easier debug, rapid rollback, and will provide simple versioning. * Convert client interactions to using the local file system * Ensure all tripleo-ansible Swift client calls are made optional * Convert tripleo-common Swift interactions to using the local file system * Disable swift on the Undercloud Dependencies ============ None Testing ======= The Swift tests will need to be updated to use the local file system, however the existing tests and test structure will be reused. Documentation Impact ==================== There are several references to Swift in our documentation which we will need to update. References ========== * https://etherpad.opendev.org/p/tripleo-heat-Swift-removal-Undercloud * https://pasted.tech/pastes/4280d42698b631b1cb47c087027f8c225a8b4dd4 ",,171,0
openstack%2Fnova~master~I87c21431d8e286af793178ac934cc8f13cece523,openstack/nova,master,I87c21431d8e286af793178ac934cc8f13cece523,doc: Fix rendering in the PTL guide,MERGED,2020-11-25 14:23:17.000000000,2020-11-30 13:47:19.000000000,2020-11-30 13:41:58.000000000,"[{'_account_id': 15334}, {'_account_id': 22348}]","[{'number': 1, 'created': '2020-11-25 14:23:17.000000000', 'files': ['doc/source/contributor/ptl-guide.rst'], 'web_link': 'https://opendev.org/openstack/nova/commit/9c0ea4a901d1a49f5ca47ab38fe2e2cc7ac5f0ae', 'message': 'doc: Fix rendering in the PTL guide\n\nChange-Id: I87c21431d8e286af793178ac934cc8f13cece523\nSigned-off-by: Takashi Natsume <takanattie@gmail.com>\n'}]",0,764175,9c0ea4a901d1a49f5ca47ab38fe2e2cc7ac5f0ae,8,2,1,7634,,,0,"doc: Fix rendering in the PTL guide

Change-Id: I87c21431d8e286af793178ac934cc8f13cece523
Signed-off-by: Takashi Natsume <takanattie@gmail.com>
",git fetch https://review.opendev.org/openstack/nova refs/changes/75/764175/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/source/contributor/ptl-guide.rst'],1,9c0ea4a901d1a49f5ca47ab38fe2e2cc7ac5f0ae,fix_ptl_guide,,,1,0
openstack%2Freleases~master~Ife77612c0ee674dee3ecf7b7b508f49d60adcdb4,openstack/releases,master,Ife77612c0ee674dee3ecf7b7b508f49d60adcdb4,Move oslo.i18n repos from wallaby to independent,ABANDONED,2020-11-27 10:09:16.000000000,2020-11-30 13:06:12.000000000,,"[{'_account_id': 308}, {'_account_id': 22348}]","[{'number': 1, 'created': '2020-11-27 10:09:16.000000000', 'files': ['deliverables/train/oslo.i18n.yaml', 'deliverables/wallaby/oslo.i18n.yaml', 'deliverables/victoria/oslo.i18n.yaml', 'deliverables/_independent/oslo.i18n.yaml'], 'web_link': 'https://opendev.org/openstack/releases/commit/5f500306aca80e27fd6ad83b19eff01ecce4a07c', 'message': 'Move oslo.i18n repos from wallaby to independent\n\nRemove victoria|ussuri|train branches and move oslo.i18n\nto indenpendent in order to make them branchless.\n\nChange-Id: Ife77612c0ee674dee3ecf7b7b508f49d60adcdb4\n'}]",0,764434,5f500306aca80e27fd6ad83b19eff01ecce4a07c,5,2,1,28522,,,0,"Move oslo.i18n repos from wallaby to independent

Remove victoria|ussuri|train branches and move oslo.i18n
to indenpendent in order to make them branchless.

Change-Id: Ife77612c0ee674dee3ecf7b7b508f49d60adcdb4
",git fetch https://review.opendev.org/openstack/releases refs/changes/34/764434/1 && git format-patch -1 --stdout FETCH_HEAD,"['deliverables/train/oslo.i18n.yaml', 'deliverables/wallaby/oslo.i18n.yaml', 'deliverables/victoria/oslo.i18n.yaml', 'deliverables/_independent/oslo.i18n.yaml']",4,5f500306aca80e27fd6ad83b19eff01ecce4a07c,oslo-transition-independent, - version: 3.24.0 projects: - repo: openstack/oslo.i18n hash: 91b39bb60de37b061c7da032cf196014bd0d67b1 - version: 5.0.0 projects: - repo: openstack/oslo.i18n hash: 761ce995883b9db5f2469d941084f0a2e64b61fb - version: 5.0.1 projects: - repo: openstack/oslo.i18n hash: 73187bd86903fc87665a829c9a0c714db6aa3022 release-notes: https://docs.openstack.org/releasenotes/oslo.i18n/,release-model: cycle-with-intermediarybranches: - name: stable/ussuri location: 4.0.1 release-notes: https://docs.openstack.org/releasenotes/oslo.i18n/ussuri.html,13,51
openstack%2Fopenstack-ansible-os_placement~stable%2Ftrain~I1986c4c15ec634a4ebd5620ecc070ce29c0bdc73,openstack/openstack-ansible-os_placement,stable/train,I1986c4c15ec634a4ebd5620ecc070ce29c0bdc73,Reduce number of processes on small systems,ABANDONED,2020-11-30 11:56:38.000000000,2020-11-30 12:18:20.000000000,,[],"[{'number': 1, 'created': '2020-11-30 11:56:38.000000000', 'files': ['defaults/main.yml'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_placement/commit/b92aa623ec391b5fbfe4b33fb6b321a972b46d38', 'message': 'Reduce number of processes on small systems\n\nEven the most modest 4C/8T system would run with the maximum 16 processes\ndue to the calculation being VCPU*2.\n\nWe devide amount of CPUs to number of threads for hyperthreaded CPUs\n\nChange-Id: I1986c4c15ec634a4ebd5620ecc070ce29c0bdc73\n'}]",0,764649,b92aa623ec391b5fbfe4b33fb6b321a972b46d38,2,0,1,28619,,,0,"Reduce number of processes on small systems

Even the most modest 4C/8T system would run with the maximum 16 processes
due to the calculation being VCPU*2.

We devide amount of CPUs to number of threads for hyperthreaded CPUs

Change-Id: I1986c4c15ec634a4ebd5620ecc070ce29c0bdc73
",git fetch https://review.opendev.org/openstack/openstack-ansible-os_placement refs/changes/49/764649/1 && git format-patch -1 --stdout FETCH_HEAD,['defaults/main.yml'],1,b92aa623ec391b5fbfe4b33fb6b321a972b46d38,api_threads,"placement_wsgi_processes: ""{{ [[(ansible_processor_vcpus//ansible_processor_threads_per_core)|default(1), 1] | max * 2, placement_wsgi_processes_max] | min }}""","placement_wsgi_processes: ""{{ [[ansible_processor_vcpus|default(1), 1] | max * 2, placement_wsgi_processes_max] | min }}""",1,1
openstack%2Fnova~master~I29b3cd1a7fa0cf51a68a1c9a75dd96393702564e,openstack/nova,master,I29b3cd1a7fa0cf51a68a1c9a75dd96393702564e,Modify the default value of the force parameter in live migration,NEW,2020-11-12 02:45:54.000000000,2020-11-30 11:50:25.000000000,,"[{'_account_id': 9008}, {'_account_id': 9732}, {'_account_id': 10118}, {'_account_id': 15751}, {'_account_id': 22348}, {'_account_id': 23498}, {'_account_id': 26515}, {'_account_id': 29963}]","[{'number': 1, 'created': '2020-11-12 02:45:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/3fdf4e34ca533f3ca308cb850cbc943d92a63636', 'message': 'Modify the default value of the force parameter in live migration\n\nSolve the problem of the live migration that does not specify\nthe micro version and does not specify the force parameters,\nbut it becomes a forced migration.\n\nChange-Id: I29b3cd1a7fa0cf51a68a1c9a75dd96393702564e\nCloses-Bug: #1903931\n'}, {'number': 2, 'created': '2020-11-12 09:48:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/053c1810bbc78009d36662e60af8b2306afbb928', 'message': 'Modify the default value of the force parameter in live migration\n\nSolve the problem of the live migration that does not specify\nthe micro version and does not specify the force parameters,\nbut it becomes a forced migration.\n\nChange-Id: I29b3cd1a7fa0cf51a68a1c9a75dd96393702564e\nCloses-Bug: #1903931\n'}, {'number': 3, 'created': '2020-11-13 02:18:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/e7d0193cedd79d6b9e8e6bd01c347997088baf6f', 'message': 'Modify the default value of the force parameter in live migration\n\nSolve the problem of the live migration that does not specify\nthe micro version and does not specify the force parameters,\nbut it becomes a forced migration.\n\nChange-Id: I29b3cd1a7fa0cf51a68a1c9a75dd96393702564e\nCloses-Bug: #1903931\n'}, {'number': 4, 'created': '2020-11-30 08:55:28.000000000', 'files': ['nova/api/openstack/compute/migrate_server.py', 'nova/tests/unit/api/openstack/compute/test_migrate_server.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/bd45264eea3fdee4b603220039d749ce1e72b611', 'message': 'Modify the default value of the force parameter in live migration\n\nSolve the problem of the live migration that does not specify\nthe micro version and does not specify the force parameters,\nbut it becomes a forced migration.\n\nChange-Id: I29b3cd1a7fa0cf51a68a1c9a75dd96393702564e\nCloses-Bug: #1903931\n'}]",0,762458,bd45264eea3fdee4b603220039d749ce1e72b611,30,8,4,12203,,,0,"Modify the default value of the force parameter in live migration

Solve the problem of the live migration that does not specify
the micro version and does not specify the force parameters,
but it becomes a forced migration.

Change-Id: I29b3cd1a7fa0cf51a68a1c9a75dd96393702564e
Closes-Bug: #1903931
",git fetch https://review.opendev.org/openstack/nova refs/changes/58/762458/2 && git format-patch -1 --stdout FETCH_HEAD,"['nova/api/openstack/compute/migrate_server.py', 'nova/compute/api.py']",2,3fdf4e34ca533f3ca308cb850cbc943d92a63636,bug/1903931," disk_over_commit, host_name, force=False, async_=False):"," disk_over_commit, host_name, force=None, async_=False):",2,2
openstack%2Ftripleo-heat-templates~stable%2Fussuri~Ia7f055d2c636f950c3fe6d8611834c4ab290f31a,openstack/tripleo-heat-templates,stable/ussuri,Ia7f055d2c636f950c3fe6d8611834c4ab290f31a,Use ansible for nodes validation,MERGED,2020-11-17 17:52:29.000000000,2020-11-30 11:46:43.000000000,2020-11-30 11:46:43.000000000,"[{'_account_id': 6469}, {'_account_id': 14985}, {'_account_id': 20172}, {'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2020-11-17 17:52:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/a789ebf8e3eec33116b8fa7d09614c62fa14fc44', 'message': 'Use ansible for nodes validation\n\nThe old all nodes validation used a bash script to run some basic ping\ntests after the network setup. It used to be a software config but\neventually got baked into the deployment framework. This patch switches\nto the ansible role implementation and cleans up the old references to\nthe old heat resource.\n\nNote: Some conflicts in:\n\tci/environments/multinode-containers.yaml\n\tci/environments/scenario003-standalone.yaml\n\tci/environments/scenario013-standalone.yaml\n\tcommon/deploy-steps.j2\n\nChange-Id: Ia7f055d2c636f950c3fe6d8611834c4ab290f31a\nDepends-On: https://review.opendev.org/#/c/763052/\n(cherry picked from commit 78ca1fe143bbb09eaa82e1a87fd38bff94888382)\n'}, {'number': 2, 'created': '2020-11-18 09:29:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/4d867585fcce098643b76c11432d0d5792e1f845', 'message': 'Use ansible for nodes validation\n\nThe old all nodes validation used a bash script to run some basic ping\ntests after the network setup. It used to be a software config but\neventually got baked into the deployment framework. This patch switches\nto the ansible role implementation and cleans up the old references to\nthe old heat resource.\n\nNote: Some conflicts in:\n\tci/environments/multinode-containers.yaml\n\tci/environments/scenario003-standalone.yaml\n\tci/environments/scenario013-standalone.yaml\n\tcommon/deploy-steps.j2\n\nCloses-Bug: #1904711\n\nChange-Id: Ia7f055d2c636f950c3fe6d8611834c4ab290f31a\nDepends-On: https://review.opendev.org/#/c/763052/\n(cherry picked from commit 78ca1fe143bbb09eaa82e1a87fd38bff94888382)\n'}, {'number': 3, 'created': '2020-11-27 13:37:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/2568e390d2d8f535424d6d9b651ad026ced0bceb', 'message': 'Use ansible for nodes validation\n\nThe old all nodes validation used a bash script to run some basic ping\ntests after the network setup. It used to be a software config but\neventually got baked into the deployment framework. This patch switches\nto the ansible role implementation and cleans up the old references to\nthe old heat resource.\n\nNote: Some conflicts in:\n\tci/environments/multinode-containers.yaml\n\tci/environments/scenario003-standalone.yaml\n\tci/environments/scenario013-standalone.yaml\n\tcommon/deploy-steps.j2\n\nCloses-Bug: #1904711\n\nChange-Id: Ia7f055d2c636f950c3fe6d8611834c4ab290f31a\nDepends-On: https://review.opendev.org/#/c/763052/\n(cherry picked from commit 78ca1fe143bbb09eaa82e1a87fd38bff94888382)\n'}, {'number': 4, 'created': '2020-11-29 07:55:41.000000000', 'files': ['ci/environments/scenario010-multinode-containers.yaml', 'ci/environments/scenario001-multinode-containers.yaml', 'ci/environments/scenario002-standalone.yaml', 'ci/environments/scenario003-standalone.yaml', 'ci/environments/scenario007-multinode-containers.yaml', 'ci/environments/scenario010-standalone.yaml', 'common/deploy-steps.j2', 'ci/environments/scenario007-standalone.yaml', 'all-nodes-validation.yaml', 'ci/environments/scenario001-standalone.yaml', 'ci/environments/scenario012-standalone.yaml', 'ci/environments/scenario004-standalone.yaml', 'ci/environments/scenario000-standalone.yaml', 'ci/environments/scenario000-multinode-containers.yaml', 'ci/common/all-nodes-validation-disabled.yaml', 'ci/environments/multinode-containers.yaml', 'overcloud-resource-registry-puppet.j2.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/d5a87a297f1f013c967166c2b0ddd183b3012928', 'message': 'Use ansible for nodes validation\n\nThe old all nodes validation used a bash script to run some basic ping\ntests after the network setup. It used to be a software config but\neventually got baked into the deployment framework. This patch switches\nto the ansible role implementation and cleans up the old references to\nthe old heat resource.\n\nNote: Some conflicts in:\n\tci/environments/multinode-containers.yaml\n\tci/environments/scenario003-standalone.yaml\n\tci/environments/scenario013-standalone.yaml\n\tcommon/deploy-steps.j2\n\nCloses-Bug: #1904711\n\nChange-Id: Ia7f055d2c636f950c3fe6d8611834c4ab290f31a\nDepends-On: https://review.opendev.org/#/c/763052/\n(cherry picked from commit 78ca1fe143bbb09eaa82e1a87fd38bff94888382)\n'}]",0,763058,d5a87a297f1f013c967166c2b0ddd183b3012928,40,5,4,20172,,,0,"Use ansible for nodes validation

The old all nodes validation used a bash script to run some basic ping
tests after the network setup. It used to be a software config but
eventually got baked into the deployment framework. This patch switches
to the ansible role implementation and cleans up the old references to
the old heat resource.

Note: Some conflicts in:
	ci/environments/multinode-containers.yaml
	ci/environments/scenario003-standalone.yaml
	ci/environments/scenario013-standalone.yaml
	common/deploy-steps.j2

Closes-Bug: #1904711

Change-Id: Ia7f055d2c636f950c3fe6d8611834c4ab290f31a
Depends-On: https://review.opendev.org/#/c/763052/
(cherry picked from commit 78ca1fe143bbb09eaa82e1a87fd38bff94888382)
",git fetch https://review.opendev.org/openstack/tripleo-heat-templates refs/changes/58/763058/1 && git format-patch -1 --stdout FETCH_HEAD,"['ci/environments/scenario010-multinode-containers.yaml', 'ci/environments/scenario001-multinode-containers.yaml', 'ci/environments/scenario002-standalone.yaml', 'ci/environments/scenario003-standalone.yaml', 'ci/environments/scenario007-multinode-containers.yaml', 'ci/environments/scenario010-standalone.yaml', 'common/deploy-steps.j2', 'ci/environments/scenario007-standalone.yaml', 'all-nodes-validation.yaml', 'ci/environments/scenario001-standalone.yaml', 'ci/environments/scenario012-standalone.yaml', 'ci/environments/scenario004-standalone.yaml', 'ci/environments/scenario000-standalone.yaml', 'ci/environments/scenario000-multinode-containers.yaml', 'ci/common/all-nodes-validation-disabled.yaml', 'ci/environments/multinode-containers.yaml', 'overcloud-resource-registry-puppet.j2.yaml']",17,a789ebf8e3eec33116b8fa7d09614c62fa14fc44,stable-ussuri,, # validation resources OS::TripleO::AllNodes::Validation: all-nodes-validation.yaml ,8,133
openstack%2Fcharm-ceph-osd~master~I417c0074fe64c2afceecdfb09b8673930087f65f,openstack/charm-ceph-osd,master,I417c0074fe64c2afceecdfb09b8673930087f65f,add function to check if device exists,MERGED,2020-10-16 08:37:13.000000000,2020-11-30 11:43:00.000000000,2020-11-30 11:43:00.000000000,"[{'_account_id': 14567}, {'_account_id': 15382}, {'_account_id': 20648}, {'_account_id': 20870}, {'_account_id': 22348}, {'_account_id': 31289}, {'_account_id': 32363}]","[{'number': 1, 'created': '2020-10-16 08:37:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-ceph-osd/commit/cb5a4a97383a6d044fc2c2feb6418cfcf6428cd2', 'message': 'add function to check if device exists\n\n- if the device does not exists, the action failed\n\nCloses-Bug: #1885336\nChange-Id: I417c0074fe64c2afceecdfb09b8673930087f65f\n'}, {'number': 2, 'created': '2020-10-16 08:47:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-ceph-osd/commit/8966b5d8a33e18026d4cb611def08c34c11c653b', 'message': ""add function to check if device exists\n\n- if the device does not exists, the action failed with message:\n  '/dev/<device>: Device does not exists.'\n\nCloses-Bug: #1885336\nChange-Id: I417c0074fe64c2afceecdfb09b8673930087f65f\n""}, {'number': 3, 'created': '2020-10-19 14:22:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-ceph-osd/commit/3a0f50eb7b48a32aa64a127e8c14e874d8142246', 'message': ""add function to check if device exists\n\n- if the device does not exists, the action failed with message:\n  '/dev/<device>: Device does not exists.'\n\nCloses-Bug: #1885336\nChange-Id: I417c0074fe64c2afceecdfb09b8673930087f65f\n""}, {'number': 4, 'created': '2020-10-19 14:46:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-ceph-osd/commit/72f7000fab1e7bdb0bd5df9029a88daede81044b', 'message': ""add function to check if device exists\n\n- if the device does not exists, the action failed with message:\n  '/dev/<device>: Device does not exists.'\n\nCloses-Bug: #1885336\nChange-Id: I417c0074fe64c2afceecdfb09b8673930087f65f\n""}, {'number': 5, 'created': '2020-10-19 15:05:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-ceph-osd/commit/b71df5df9573b735239c8719456b628d70072e4e', 'message': ""add function to check if device exists\n\n- if the device does not exists, the action failed with message:\n  '/dev/<device>: Device does not exists.'\n\nCloses-Bug: #1885336\nChange-Id: I417c0074fe64c2afceecdfb09b8673930087f65f\n""}, {'number': 6, 'created': '2020-11-06 14:56:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-ceph-osd/commit/84a4b29c617dc5f499486f85dae9a3c00e681f52', 'message': ""add function to check if device exists\n\n- if the device does not exists, the action failed with message:\n  '/dev/<device>: Device does not exists.'\n\nCloses-Bug: #1885336\nChange-Id: I417c0074fe64c2afceecdfb09b8673930087f65f\n""}, {'number': 7, 'created': '2020-11-25 11:45:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-ceph-osd/commit/02bf65f846399044b2379b78c22b342e92d8ab1a', 'message': ""add function to check if device exists\n\n- if the device does not exists, the action failed with message:\n  '/dev/<device>: Device does not exists.'\n\nCloses-Bug: #1885336\nChange-Id: I417c0074fe64c2afceecdfb09b8673930087f65f\n""}, {'number': 8, 'created': '2020-11-25 11:55:11.000000000', 'files': ['actions/zap_disk.py', 'unit_tests/test_actions_zap_disk.py'], 'web_link': 'https://opendev.org/openstack/charm-ceph-osd/commit/bc071cd20842c471ede8b0fedd47e7f00d15d61a', 'message': ""add function to check if device exists\n\n- if the device does not exists, the action failed with message:\n  '/dev/<device>: Device does not exists.'\n\nCloses-Bug: #1885336\nChange-Id: I417c0074fe64c2afceecdfb09b8673930087f65f\n""}]",10,758537,bc071cd20842c471ede8b0fedd47e7f00d15d61a,36,7,8,32363,,,0,"add function to check if device exists

- if the device does not exists, the action failed with message:
  '/dev/<device>: Device does not exists.'

Closes-Bug: #1885336
Change-Id: I417c0074fe64c2afceecdfb09b8673930087f65f
",git fetch https://review.opendev.org/openstack/charm-ceph-osd refs/changes/37/758537/8 && git format-patch -1 --stdout FETCH_HEAD,"['actions/zap_disk.py', 'unit_tests/test_actions_zap_disk.py']",2,cb5a4a97383a6d044fc2c2feb6418cfcf6428cd2,bug/1885336," 'kv', 'check_device']) self.check_device.return_value = True _zap_disk): class ZapDiskActionFailedTests(CharmTestCase): def setUp(self): super(ZapDiskActionFailedTests, self).setUp( zap_disk, ['hookenv']) self.hookenv.local_unit.return_value = ""ceph-osd-test/0"" @mock.patch.object(zap_disk, 'zap_disk') def test_wont_zap_non_existent_device(self, _zap_disk): """"""Will zap non-existent disk"""""" def side_effect(arg): return { 'devices': '/dev/not-valid-disk', 'i-really-mean-it': True, }.get(arg) self.hookenv.action_get.side_effect = side_effect zap_disk.zap() _zap_disk.assert_not_called() self.hookenv.action_fail.assert_called_with( '/dev/not-valid-disk: Device does not exists.') self.hookenv.action_set.assert_not_called() @mock.patch.object(zap_disk, 'zap_disk') def test_wont_zap_not_abs_path(self, _zap_disk): """"""Will zap not absolute path"""""" def side_effect(arg): return { 'devices': 'not-absolute', 'i-really-mean-it': True, }.get(arg) self.hookenv.action_get.side_effect = side_effect zap_disk.zap() _zap_disk.assert_not_called() self.hookenv.action_fail.assert_called_with( 'not-absolute: Not absolute path.') self.hookenv.action_set.assert_not_called()"," 'kv']) _zap_disk,):",64,3
openstack%2Fopenstack-ansible~stable%2Fussuri~Ib5783a2e36a7b3b06a9772712515c71f9cad371b,openstack/openstack-ansible,stable/ussuri,Ib5783a2e36a7b3b06a9772712515c71f9cad371b,Bump SHAs for stable/ussuri,ABANDONED,2020-11-15 16:46:24.000000000,2020-11-30 11:25:11.000000000,,"[{'_account_id': 22348}, {'_account_id': 31542}]","[{'number': 1, 'created': '2020-11-15 16:46:24.000000000', 'files': ['playbooks/defaults/repo_packages/openstack_services.yml', 'playbooks/defaults/repo_packages/gnocchi.yml', 'playbooks/defaults/repo_packages/nova_consoles.yml', 'ansible-role-requirements.yml'], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/2ee15f6c222c197c453c9310bf388b4663f80e76', 'message': 'Bump SHAs for stable/ussuri\n\nChange-Id: Ib5783a2e36a7b3b06a9772712515c71f9cad371b\n'}]",0,762763,2ee15f6c222c197c453c9310bf388b4663f80e76,4,2,1,28619,,,0,"Bump SHAs for stable/ussuri

Change-Id: Ib5783a2e36a7b3b06a9772712515c71f9cad371b
",git fetch https://review.opendev.org/openstack/openstack-ansible refs/changes/63/762763/1 && git format-patch -1 --stdout FETCH_HEAD,"['playbooks/defaults/repo_packages/openstack_services.yml', 'playbooks/defaults/repo_packages/gnocchi.yml', 'playbooks/defaults/repo_packages/nova_consoles.yml', 'ansible-role-requirements.yml']",4,2ee15f6c222c197c453c9310bf388b4663f80e76,bump_osa, version: 709f5aadf0bd969b54046f9e891c28dddcfe79b0 version: 0cf97985d5635b03d98b07c107675a4372f7dd12, version: c6b8b21cc6c5962d69a9cf8342cbeda8d6332d0c version: d1a20e3de721d7853265f8e20d23532e65d3575e,52,52
openstack%2Fopenstack-ansible~stable%2Ftrain~I3c970119819335371e781ba3ac36f08e40e7ab82,openstack/openstack-ansible,stable/train,I3c970119819335371e781ba3ac36f08e40e7ab82,Bump SHAs for stable/train,ABANDONED,2020-11-15 16:46:31.000000000,2020-11-30 11:25:08.000000000,,"[{'_account_id': 22348}, {'_account_id': 31542}]","[{'number': 1, 'created': '2020-11-15 16:46:31.000000000', 'files': ['playbooks/defaults/repo_packages/openstack_services.yml', 'playbooks/defaults/repo_packages/gnocchi.yml', 'playbooks/defaults/repo_packages/nova_consoles.yml', 'ansible-role-requirements.yml'], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/b58ef5199cdf6314ab8ebd22b7b5944c7208660e', 'message': 'Bump SHAs for stable/train\n\nChange-Id: I3c970119819335371e781ba3ac36f08e40e7ab82\n'}]",0,762764,b58ef5199cdf6314ab8ebd22b7b5944c7208660e,4,2,1,28619,,,0,"Bump SHAs for stable/train

Change-Id: I3c970119819335371e781ba3ac36f08e40e7ab82
",git fetch https://review.opendev.org/openstack/openstack-ansible refs/changes/64/762764/1 && git format-patch -1 --stdout FETCH_HEAD,"['playbooks/defaults/repo_packages/openstack_services.yml', 'playbooks/defaults/repo_packages/gnocchi.yml', 'playbooks/defaults/repo_packages/nova_consoles.yml', 'ansible-role-requirements.yml']",4,b58ef5199cdf6314ab8ebd22b7b5944c7208660e,bump_osa, version: 709f5aadf0bd969b54046f9e891c28dddcfe79b0 version: 2ea3db269e6187485b8c37e440845ee57b67a34b, version: c6b8b21cc6c5962d69a9cf8342cbeda8d6332d0c version: 522e183d8f2755d17678a383a3e414dac2cc6ccc,48,48
openstack%2Fopenstack-ansible~master~I8f49324e168fa54da626a938e29277dff60e61de,openstack/openstack-ansible,master,I8f49324e168fa54da626a938e29277dff60e61de,Bump SHAs for master,MERGED,2020-11-29 17:02:53.000000000,2020-11-30 11:24:57.000000000,2020-11-30 11:23:02.000000000,"[{'_account_id': 22348}, {'_account_id': 25023}, {'_account_id': 31542}]","[{'number': 1, 'created': '2020-11-29 17:02:53.000000000', 'files': ['releasenotes/notes/barbican_backends-7d070edd33401f35.yaml', 'releasenotes/notes/barbican_libraries-af0d43f90a4b995d.yaml', 'releasenotes/notes/system_scope_support-ab364c1725e2506e.yaml', 'playbooks/defaults/repo_packages/openstack_services.yml', 'releasenotes/notes/pipeline_yml-779d1ee79fd91f5f.yaml', 'playbooks/defaults/repo_packages/gnocchi.yml', 'playbooks/defaults/repo_packages/nova_consoles.yml', 'playbooks/defaults/repo_packages/openstack_testing.yml'], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/380b3b102e99768df9e8cd44f19121e99a70b3a3', 'message': 'Bump SHAs for master\n\nChange-Id: I8f49324e168fa54da626a938e29277dff60e61de\n'}]",0,764589,380b3b102e99768df9e8cd44f19121e99a70b3a3,8,3,1,28619,,,0,"Bump SHAs for master

Change-Id: I8f49324e168fa54da626a938e29277dff60e61de
",git fetch https://review.opendev.org/openstack/openstack-ansible refs/changes/89/764589/1 && git format-patch -1 --stdout FETCH_HEAD,"['playbooks/defaults/repo_packages/openstack_services.yml', 'releasenotes/notes/barbican_backends-7d070edd33401f35.yaml', 'releasenotes/notes/barbican_libraries-af0d43f90a4b995d.yaml', 'releasenotes/notes/system_scope_support-ab364c1725e2506e.yaml', 'releasenotes/notes/pipeline_yml-779d1ee79fd91f5f.yaml', 'playbooks/defaults/repo_packages/gnocchi.yml', 'playbooks/defaults/repo_packages/nova_consoles.yml', 'playbooks/defaults/repo_packages/openstack_testing.yml']",8,380b3b102e99768df9e8cd44f19121e99a70b3a3,bump_osa,tempest_git_install_branch: ae5285d5d8468b491e4ae3120101453c1f96b930 # HEAD as of 29.11.2020,tempest_git_install_branch: c6d6ac2df1eeb8cc3c6432798f61c79cb3ad565b # HEAD as of 15.11.2020,94,54
openstack%2Fopenstack-ansible~master~Ic5c4167cbd2bd484f5bc0820af22816be412a5a7,openstack/openstack-ansible,master,Ic5c4167cbd2bd484f5bc0820af22816be412a5a7,Bump SHAs for master,ABANDONED,2020-11-29 07:52:06.000000000,2020-11-30 11:22:38.000000000,,[{'_account_id': 22348}],"[{'number': 1, 'created': '2020-11-29 07:52:06.000000000', 'files': ['releasenotes/notes/barbican_backends-7d070edd33401f35.yaml', 'releasenotes/notes/barbican_libraries-af0d43f90a4b995d.yaml', 'releasenotes/notes/system_scope_support-ab364c1725e2506e.yaml', 'playbooks/defaults/repo_packages/openstack_services.yml', 'releasenotes/notes/pipeline_yml-779d1ee79fd91f5f.yaml', 'playbooks/defaults/repo_packages/gnocchi.yml', 'playbooks/defaults/repo_packages/nova_consoles.yml', 'playbooks/defaults/repo_packages/openstack_testing.yml'], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/8d0bf4edf8d2938473f93ba8d1d39c2d90681163', 'message': 'Bump SHAs for master\n\nChange-Id: Ic5c4167cbd2bd484f5bc0820af22816be412a5a7\n'}]",0,764580,8d0bf4edf8d2938473f93ba8d1d39c2d90681163,4,1,1,28619,,,0,"Bump SHAs for master

Change-Id: Ic5c4167cbd2bd484f5bc0820af22816be412a5a7
",git fetch https://review.opendev.org/openstack/openstack-ansible refs/changes/80/764580/1 && git format-patch -1 --stdout FETCH_HEAD,"['playbooks/defaults/repo_packages/openstack_services.yml', 'releasenotes/notes/barbican_backends-7d070edd33401f35.yaml', 'releasenotes/notes/barbican_libraries-af0d43f90a4b995d.yaml', 'releasenotes/notes/system_scope_support-ab364c1725e2506e.yaml', 'releasenotes/notes/pipeline_yml-779d1ee79fd91f5f.yaml', 'playbooks/defaults/repo_packages/gnocchi.yml', 'playbooks/defaults/repo_packages/nova_consoles.yml', 'playbooks/defaults/repo_packages/openstack_testing.yml']",8,8d0bf4edf8d2938473f93ba8d1d39c2d90681163,bump_osa,tempest_git_install_branch: ae5285d5d8468b491e4ae3120101453c1f96b930 # HEAD as of 29.11.2020,tempest_git_install_branch: c6d6ac2df1eeb8cc3c6432798f61c79cb3ad565b # HEAD as of 15.11.2020,94,54
openstack%2Fopenstack-ansible~stable%2Fussuri~Iff55e40ad16abd6dcc1d6c0fa36134729ba5a069,openstack/openstack-ansible,stable/ussuri,Iff55e40ad16abd6dcc1d6c0fa36134729ba5a069,Bump SHAs for stable/ussuri,ABANDONED,2020-11-29 07:52:24.000000000,2020-11-30 11:22:03.000000000,,[{'_account_id': 22348}],"[{'number': 1, 'created': '2020-11-29 07:52:24.000000000', 'files': ['playbooks/defaults/repo_packages/openstack_services.yml', 'playbooks/defaults/repo_packages/gnocchi.yml', 'playbooks/defaults/repo_packages/nova_consoles.yml', 'ansible-role-requirements.yml'], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/8fc4308ac65a2318df739f89574dc4435f37d827', 'message': 'Bump SHAs for stable/ussuri\n\nChange-Id: Iff55e40ad16abd6dcc1d6c0fa36134729ba5a069\n'}]",0,764582,8fc4308ac65a2318df739f89574dc4435f37d827,3,1,1,28619,,,0,"Bump SHAs for stable/ussuri

Change-Id: Iff55e40ad16abd6dcc1d6c0fa36134729ba5a069
",git fetch https://review.opendev.org/openstack/openstack-ansible refs/changes/82/764582/1 && git format-patch -1 --stdout FETCH_HEAD,"['playbooks/defaults/repo_packages/openstack_services.yml', 'playbooks/defaults/repo_packages/gnocchi.yml', 'playbooks/defaults/repo_packages/nova_consoles.yml', 'ansible-role-requirements.yml']",4,8fc4308ac65a2318df739f89574dc4435f37d827,bump_osa, version: 399654cc70d58bc60376f7dd4eb9d0e8db2605d8 version: e6be9ced0357db618b92f5b25991fba691941ebc version: 0cf97985d5635b03d98b07c107675a4372f7dd12, version: c6b8b21cc6c5962d69a9cf8342cbeda8d6332d0c version: 63d14e585090011fe3ac947c70557938bb60fe21 version: d1a20e3de721d7853265f8e20d23532e65d3575e,53,53
openstack%2Fopenstack-ansible~stable%2Ftrain~Ib08aef369ab79941b650c55903e2d7c41eaed3ac,openstack/openstack-ansible,stable/train,Ib08aef369ab79941b650c55903e2d7c41eaed3ac,Bump SHAs for stable/train,ABANDONED,2020-11-29 07:38:11.000000000,2020-11-30 11:21:59.000000000,,[{'_account_id': 22348}],"[{'number': 1, 'created': '2020-11-29 07:38:11.000000000', 'files': ['playbooks/defaults/repo_packages/openstack_services.yml', 'playbooks/defaults/repo_packages/gnocchi.yml', 'playbooks/defaults/repo_packages/nova_consoles.yml', 'ansible-role-requirements.yml'], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/4e571f5135a256f245bd01cf30fe31f97f949acb', 'message': 'Bump SHAs for stable/train\n\nChange-Id: Ib08aef369ab79941b650c55903e2d7c41eaed3ac\n'}]",0,764579,4e571f5135a256f245bd01cf30fe31f97f949acb,3,1,1,28619,,,0,"Bump SHAs for stable/train

Change-Id: Ib08aef369ab79941b650c55903e2d7c41eaed3ac
",git fetch https://review.opendev.org/openstack/openstack-ansible refs/changes/79/764579/1 && git format-patch -1 --stdout FETCH_HEAD,"['playbooks/defaults/repo_packages/openstack_services.yml', 'playbooks/defaults/repo_packages/gnocchi.yml', 'playbooks/defaults/repo_packages/nova_consoles.yml', 'ansible-role-requirements.yml']",4,4e571f5135a256f245bd01cf30fe31f97f949acb,bump_osa, version: 399654cc70d58bc60376f7dd4eb9d0e8db2605d8 version: fe699897ed1fe0d69768a7c28512b796cbeed9aa, version: c6b8b21cc6c5962d69a9cf8342cbeda8d6332d0c version: 522e183d8f2755d17678a383a3e414dac2cc6ccc,48,48
openstack%2Fopenstack-ansible~stable%2Ftrain~I84720aef4b4953016b604f976b5ce4f15edb4c13,openstack/openstack-ansible,stable/train,I84720aef4b4953016b604f976b5ce4f15edb4c13,Bump SHAs for stable/train,ABANDONED,2020-11-29 07:52:23.000000000,2020-11-30 11:21:33.000000000,,[{'_account_id': 22348}],"[{'number': 1, 'created': '2020-11-29 07:52:23.000000000', 'files': ['playbooks/defaults/repo_packages/openstack_services.yml', 'playbooks/defaults/repo_packages/gnocchi.yml', 'playbooks/defaults/repo_packages/nova_consoles.yml', 'ansible-role-requirements.yml'], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/81d56494d3afc64b0e8ada204302e587c1136c7b', 'message': 'Bump SHAs for stable/train\n\nChange-Id: I84720aef4b4953016b604f976b5ce4f15edb4c13\n'}]",0,764581,81d56494d3afc64b0e8ada204302e587c1136c7b,3,1,1,28619,,,0,"Bump SHAs for stable/train

Change-Id: I84720aef4b4953016b604f976b5ce4f15edb4c13
",git fetch https://review.opendev.org/openstack/openstack-ansible refs/changes/81/764581/1 && git format-patch -1 --stdout FETCH_HEAD,"['playbooks/defaults/repo_packages/openstack_services.yml', 'playbooks/defaults/repo_packages/gnocchi.yml', 'playbooks/defaults/repo_packages/nova_consoles.yml', 'ansible-role-requirements.yml']",4,81d56494d3afc64b0e8ada204302e587c1136c7b,bump_osa, version: 399654cc70d58bc60376f7dd4eb9d0e8db2605d8 version: fe699897ed1fe0d69768a7c28512b796cbeed9aa, version: c6b8b21cc6c5962d69a9cf8342cbeda8d6332d0c version: 522e183d8f2755d17678a383a3e414dac2cc6ccc,48,48
openstack%2Fopenstack-ansible-os_magnum~master~Ife266361eb0bf9a90686773d4d47b5a81590710d,openstack/openstack-ansible-os_magnum,master,Ife266361eb0bf9a90686773d4d47b5a81590710d,Drop magnum distro CI jobs,MERGED,2020-10-30 09:51:21.000000000,2020-11-30 11:12:21.000000000,2020-11-30 11:06:38.000000000,"[{'_account_id': 22348}, {'_account_id': 25023}, {'_account_id': 28619}, {'_account_id': 31542}]","[{'number': 1, 'created': '2020-10-30 09:51:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_magnum/commit/aeb35e44282fff8677f0dd73b5079bd1ef25475e', 'message': 'Drop magnum distro CI jobs\n\nDistro path is not available at the moment for magnum, so\nno reason in testing this path in CI\n\nChange-Id: Ife266361eb0bf9a90686773d4d47b5a81590710d\n'}, {'number': 2, 'created': '2020-11-01 05:59:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_magnum/commit/1364e743476d0049599d505c5ebe55e2446d78b3', 'message': 'Drop magnum distro CI jobs\n\nDistro path is not available at the moment for magnum, so\nno reason in testing this path in CI\n\nChange-Id: Ife266361eb0bf9a90686773d4d47b5a81590710d\n'}, {'number': 3, 'created': '2020-11-29 22:05:39.000000000', 'files': ['zuul.d/project.yaml'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_magnum/commit/dca09f3b6b7ef61ca8a555bbf11469531ab743ea', 'message': 'Drop magnum distro CI jobs\n\nDistro path is not available at the moment for magnum, so\nno reason in testing this path in CI\n\nChange-Id: Ife266361eb0bf9a90686773d4d47b5a81590710d\n'}]",0,760525,dca09f3b6b7ef61ca8a555bbf11469531ab743ea,16,4,3,28619,,,0,"Drop magnum distro CI jobs

Distro path is not available at the moment for magnum, so
no reason in testing this path in CI

Change-Id: Ife266361eb0bf9a90686773d4d47b5a81590710d
",git fetch https://review.opendev.org/openstack/openstack-ansible-os_magnum refs/changes/25/760525/2 && git format-patch -1 --stdout FETCH_HEAD,['zuul.d/project.yaml'],1,aeb35e44282fff8677f0dd73b5079bd1ef25475e,,, - openstack-ansible-deploy-aio_distro_metal-jobs check: jobs: - openstack-ansible-deploy-aio_distro_metal-centos-7: voting: false gate: jobs: - openstack-ansible-deploy-aio_distro_metal-centos-7: voting: false,0,9
openstack%2Fopenstack-ansible-os_magnum~master~I23fa200a017c290b342bfd4594cbffa5efd24566,openstack/openstack-ansible-os_magnum,master,I23fa200a017c290b342bfd4594cbffa5efd24566,Reduce number of processes on small systems,MERGED,2020-10-30 16:32:12.000000000,2020-11-30 11:11:08.000000000,2020-11-30 11:06:35.000000000,"[{'_account_id': 22348}, {'_account_id': 25023}, {'_account_id': 28619}, {'_account_id': 31542}]","[{'number': 1, 'created': '2020-10-30 16:32:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_magnum/commit/f5d8145417840f2be0e4c8a4e4957e29d53cb20d', 'message': 'Reduce number of processes on small systems\n\nEven the most modest 4C/8T system would run with the maximum 16 processes\ndue to the calculation being VCPU*2.\n\nWe devide amount of CPUs to number of threads for hyperthreaded CPUs\n\nChange-Id: I23fa200a017c290b342bfd4594cbffa5efd24566\n'}, {'number': 2, 'created': '2020-11-01 05:59:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_magnum/commit/22e355a6a4e61a2aca88fc059cb03a8faeb61696', 'message': 'Reduce number of processes on small systems\n\nEven the most modest 4C/8T system would run with the maximum 16 processes\ndue to the calculation being VCPU*2.\n\nWe devide amount of CPUs to number of threads for hyperthreaded CPUs\n\nChange-Id: I23fa200a017c290b342bfd4594cbffa5efd24566\n'}, {'number': 3, 'created': '2020-11-29 22:05:31.000000000', 'files': ['defaults/main.yml'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_magnum/commit/6c4016afbef678d2b5a26f7c2dac6039202e3357', 'message': 'Reduce number of processes on small systems\n\nEven the most modest 4C/8T system would run with the maximum 16 processes\ndue to the calculation being VCPU*2.\n\nWe devide amount of CPUs to number of threads for hyperthreaded CPUs\n\nChange-Id: I23fa200a017c290b342bfd4594cbffa5efd24566\n'}]",0,760633,6c4016afbef678d2b5a26f7c2dac6039202e3357,15,4,3,28619,,,0,"Reduce number of processes on small systems

Even the most modest 4C/8T system would run with the maximum 16 processes
due to the calculation being VCPU*2.

We devide amount of CPUs to number of threads for hyperthreaded CPUs

Change-Id: I23fa200a017c290b342bfd4594cbffa5efd24566
",git fetch https://review.opendev.org/openstack/openstack-ansible-os_magnum refs/changes/33/760633/2 && git format-patch -1 --stdout FETCH_HEAD,['defaults/main.yml'],1,f5d8145417840f2be0e4c8a4e4957e29d53cb20d,api_threads,"magnum_wsgi_processes: ""{{ [[(ansible_processor_vcpus//ansible_processor_threads_per_core)|default(1), 1] | max * 2, magnum_wsgi_processes_max] | min }}""","magnum_wsgi_processes: ""{{ [[ansible_processor_vcpus|default(1), 1] | max * 2, magnum_wsgi_processes_max] | min }}""",1,1
openstack%2Fneutron~master~I83985e1437f088312a4d0a867f570e8c707f1ca8,openstack/neutron,master,I83985e1437f088312a4d0a867f570e8c707f1ca8,Replace deprecated UPPER_CONSTRAINTS_FILE variable,ABANDONED,2020-11-12 02:36:43.000000000,2020-11-30 11:01:55.000000000,,"[{'_account_id': 11975}, {'_account_id': 15752}, {'_account_id': 22348}, {'_account_id': 26622}, {'_account_id': 32291}]","[{'number': 1, 'created': '2020-11-12 02:36:43.000000000', 'files': ['tox.ini'], 'web_link': 'https://opendev.org/openstack/neutron/commit/e0ff1df7ff5a5eef0a97f79792231a8745a87768', 'message': 'Replace deprecated UPPER_CONSTRAINTS_FILE variable\n\nChange-Id: I83985e1437f088312a4d0a867f570e8c707f1ca8\n'}]",0,762457,e0ff1df7ff5a5eef0a97f79792231a8745a87768,18,5,1,32291,,,0,"Replace deprecated UPPER_CONSTRAINTS_FILE variable

Change-Id: I83985e1437f088312a4d0a867f570e8c707f1ca8
",git fetch https://review.opendev.org/openstack/neutron refs/changes/57/762457/1 && git format-patch -1 --stdout FETCH_HEAD,['tox.ini'],1,e0ff1df7ff5a5eef0a97f79792231a8745a87768,, -c{env:TOX_CONSTRAINTS_FILE:https://releases.openstack.org/constraints/upper/master} -c{env:TOX_CONSTRAINTS_FILE:https://releases.openstack.org/constraints/upper/master}, -c{env:UPPER_CONSTRAINTS_FILE:https://releases.openstack.org/constraints/upper/master} -c{env:UPPER_CONSTRAINTS_FILE:https://releases.openstack.org/constraints/upper/master},2,2
openstack%2Freleases~master~Idc2200d09bdfd473153558a02bb44f17422d6f4b,openstack/releases,master,Idc2200d09bdfd473153558a02bb44f17422d6f4b,New bugfix release of tooz for ussuri.,MERGED,2020-11-27 16:32:57.000000000,2020-11-30 10:57:05.000000000,2020-11-30 10:57:05.000000000,"[{'_account_id': 308}, {'_account_id': 22348}, {'_account_id': 28522}]","[{'number': 1, 'created': '2020-11-27 16:32:57.000000000', 'files': ['deliverables/ussuri/tooz.yaml'], 'web_link': 'https://opendev.org/openstack/releases/commit/d74b2f479dbe034e280f69867007d5c031bd2870', 'message': 'New bugfix release of tooz for ussuri.\n\nFix broken CI and PyMySQL support.\n\nChange-Id: Idc2200d09bdfd473153558a02bb44f17422d6f4b\n'}]",0,764474,d74b2f479dbe034e280f69867007d5c031bd2870,7,3,1,31245,,,0,"New bugfix release of tooz for ussuri.

Fix broken CI and PyMySQL support.

Change-Id: Idc2200d09bdfd473153558a02bb44f17422d6f4b
",git fetch https://review.opendev.org/openstack/releases refs/changes/74/764474/1 && git format-patch -1 --stdout FETCH_HEAD,['deliverables/ussuri/tooz.yaml'],1,d74b2f479dbe034e280f69867007d5c031bd2870,tooz_for_ussuri, - version: 2.3.1 projects: - repo: openstack/tooz hash: 667e2ec1f4d179c1ec9bd5f89ed12a50cad71e24,,4,0
openstack%2Fcharm-cinder-ceph~master~Ia4c1e9741ae8eab2e41d7ba4e4615475914c43e5,openstack/charm-cinder-ceph,master,Ia4c1e9741ae8eab2e41d7ba4e4615475914c43e5,Charmhelpers sync,MERGED,2020-11-24 16:08:01.000000000,2020-11-30 10:56:24.000000000,2020-11-30 10:56:24.000000000,"[{'_account_id': 20648}, {'_account_id': 22348}, {'_account_id': 31289}]","[{'number': 1, 'created': '2020-11-24 16:08:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-cinder-ceph/commit/2c3f59500595b68ed0476c73030ff674ec534cb1', 'message': 'Charmhelpers sync\n\nThis is required to get the updated broker request handler\ncontaining the new rbd-mirroring-mode flag.\n\nChange-Id: Ia4c1e9741ae8eab2e41d7ba4e4615475914c43e5\n'}, {'number': 2, 'created': '2020-11-25 13:39:26.000000000', 'files': ['charmhelpers/contrib/openstack/utils.py', 'charmhelpers/core/host.py', 'charmhelpers/contrib/openstack/ip.py', 'charmhelpers/core/decorators.py', 'charmhelpers/contrib/storage/linux/ceph.py', 'charmhelpers/contrib/network/ip.py', 'charmhelpers/contrib/openstack/templates/section-placement', 'charmhelpers/contrib/openstack/cert_utils.py'], 'web_link': 'https://opendev.org/openstack/charm-cinder-ceph/commit/4114828b930102c407554307a924047141df1a01', 'message': 'Charmhelpers sync\n\nThis is required to get the updated broker request handler\ncontaining the new rbd-mirroring-mode flag.\n\nChange-Id: Ia4c1e9741ae8eab2e41d7ba4e4615475914c43e5\n'}]",0,764005,4114828b930102c407554307a924047141df1a01,12,3,2,32431,,,0,"Charmhelpers sync

This is required to get the updated broker request handler
containing the new rbd-mirroring-mode flag.

Change-Id: Ia4c1e9741ae8eab2e41d7ba4e4615475914c43e5
",git fetch https://review.opendev.org/openstack/charm-cinder-ceph refs/changes/05/764005/1 && git format-patch -1 --stdout FETCH_HEAD,"['charmhelpers/contrib/openstack/utils.py', 'charmhelpers/core/host.py', 'charmhelpers/contrib/openstack/ip.py', 'charmhelpers/core/decorators.py', 'charmhelpers/contrib/storage/linux/ceph.py', 'charmhelpers/contrib/network/ip.py', 'charmhelpers/contrib/openstack/templates/section-placement', 'charmhelpers/contrib/openstack/cert_utils.py']",8,2c3f59500595b68ed0476c73030ff674ec534cb1,cinder-ceph-replication," ADDRESS_MAP, get_default_api_bindings, ) from charmhelpers.contrib.network.ip import ( get_relation_ip, )def get_certificate_request(json_encode=True, bindings=None): """"""Generate a certificate requests based on the network configuration :param json_encode: Encode request in JSON or not. Used for setting directly on a relation. :type json_encode: boolean :param bindings: List of bindings to check in addition to default api bindings. :type bindings: list of strings :returns: CertRequest request as dictionary or JSON string. :rtype: Union[dict, json] if bindings: # Add default API bindings to bindings list bindings = set(bindings + get_default_api_bindings()) else: # Use default API bindings bindings = get_default_api_bindings() _sans = get_certificate_sans() # Handle specific hostnames per binding for binding in bindings: hostname_override = config(ADDRESS_MAP[binding]['override']) try: net_addr = resolve_address(endpoint_type=binding) ADDRESS_MAP[binding]['binding']) # Add hostname certificate request if hostname_override: binding, hostname_override, # Remove hostname specific addresses from _sans for addr in addresses: try: _sans.remove(addr) except (ValueError, KeyError): pass ""local address found"".format(binding), WARNING) # Gurantee all SANs are covered # These are network addresses with no corresponding hostname. # Add the ips to the hostname cert to allow for this. req.add_hostname_cn_ip(_sans)def get_certificate_sans(bindings=None): """"""Get all possible IP addresses for certificate SANs. """""" _sans = [unit_get('private-address')] if bindings: # Add default API bindings to bindings list bindings = set(bindings + get_default_api_bindings()) else: # Use default API bindings bindings = get_default_api_bindings() for binding in bindings: # Check for config override try: net_config = config(ADDRESS_MAP[binding]['config']) except KeyError: # There is no configuration network for this binding name net_config = None # Using resolve_address is likely redundant. Keeping it here in # case there is an edge case it handles. net_addr = resolve_address(endpoint_type=binding) ip = get_relation_ip(binding, cidr_network=net_config) _sans = _sans + [net_addr, ip] vip = get_vip_in_network(resolve_network_cidr(ip)) if vip: _sans.append(vip) return set(_sans) # This includes the hostname cert and any specific bindng certs: # admin, internal, public req = get_certificate_request(json_encode=False)[""cert_requests""] # Specific certs for cert_req in req.keys(): requested_cert = os.path.join( ssl_dir, 'cert_{}'.format(cert_req)) requested_key = os.path.join( ssl_dir, 'key_{}'.format(cert_req)) for addr in req[cert_req]['sans']: cert = os.path.join(ssl_dir, 'cert_{}'.format(addr)) key = os.path.join(ssl_dir, 'key_{}'.format(addr)) if os.path.isfile(requested_cert) and not os.path.isfile(cert): os.symlink(requested_cert, cert) os.symlink(requested_key, key) # Handle custom hostnames"," ADMIN, INTERNAL, PUBLIC, ADDRESS_MAP)def get_certificate_request(json_encode=True): """"""Generate a certificatee requests based on the network confioguration for net_type in [INTERNAL, ADMIN, PUBLIC]: net_config = config(ADDRESS_MAP[net_type]['override']) try: net_addr = resolve_address(endpoint_type=net_type) ADDRESS_MAP[net_type]['binding']) if net_config: net_type, net_config, else: # There is network address with no corresponding hostname. # Add the ip to the hostname cert to allow for this. req.add_hostname_cn_ip(addresses) ""local address found"".format(net_type), WARNING) # Add links to hostname cert, used if os-hostname vars not set for net_type in [INTERNAL, ADMIN, PUBLIC]: try: addr = resolve_address(endpoint_type=net_type) cert = os.path.join(ssl_dir, 'cert_{}'.format(addr)) key = os.path.join(ssl_dir, 'key_{}'.format(addr)) if os.path.isfile(hostname_cert) and not os.path.isfile(cert): os.symlink(hostname_cert, cert) os.symlink(hostname_key, key) except NoNetworkBinding: log(""Skipping creating cert symlink for ip in {} space, no "" ""local address found"".format(net_type), WARNING)",193,42
openstack%2Freleases~master~If5898b9139fab8378a193fcd26ea1cc024c57dba,openstack/releases,master,If5898b9139fab8378a193fcd26ea1cc024c57dba,New bugfix release of castellan for train.,MERGED,2020-11-27 16:21:52.000000000,2020-11-30 10:52:10.000000000,2020-11-30 10:52:10.000000000,"[{'_account_id': 308}, {'_account_id': 22348}, {'_account_id': 28522}]","[{'number': 1, 'created': '2020-11-27 16:21:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/releases/commit/4c6d5f45fad56d0afdba288605abebb2bc971255', 'message': ""New bugfix release of oslo.concurrency for train.\n\nUse 'barbican_endpoint_type'config option to get endpoint from catalog.\n\nChange-Id: If5898b9139fab8378a193fcd26ea1cc024c57dba\n""}, {'number': 2, 'created': '2020-11-27 16:24:07.000000000', 'files': ['deliverables/train/castellan.yaml'], 'web_link': 'https://opendev.org/openstack/releases/commit/a485926b0e88699846f362bae18f524d8a6210d0', 'message': ""New bugfix release of castellan for train.\n\nUse 'barbican_endpoint_type'config option to get endpoint from catalog.\n\nChange-Id: If5898b9139fab8378a193fcd26ea1cc024c57dba\n""}]",0,764473,a485926b0e88699846f362bae18f524d8a6210d0,8,3,2,31245,,,0,"New bugfix release of castellan for train.

Use 'barbican_endpoint_type'config option to get endpoint from catalog.

Change-Id: If5898b9139fab8378a193fcd26ea1cc024c57dba
",git fetch https://review.opendev.org/openstack/releases refs/changes/73/764473/1 && git format-patch -1 --stdout FETCH_HEAD,['deliverables/train/castellan.yaml'],1,4c6d5f45fad56d0afdba288605abebb2bc971255,castellan_for_train, - version: 1.3.4 projects: - repo: openstack/castellan hash: edf96c465c4574b38c5324a3773cf41429b6820e,,4,0
openstack%2Freleases~master~I841969913698591984d6920a84913968f41fa618,openstack/releases,master,I841969913698591984d6920a84913968f41fa618,python-troveclient 6.0.0 for Wallaby,MERGED,2020-11-27 11:03:59.000000000,2020-11-30 10:51:57.000000000,2020-11-30 10:51:57.000000000,"[{'_account_id': 308}, {'_account_id': 22348}, {'_account_id': 28522}]","[{'number': 1, 'created': '2020-11-27 11:03:59.000000000', 'files': ['deliverables/wallaby/python-troveclient.yaml'], 'web_link': 'https://opendev.org/openstack/releases/commit/e9e761e8d8277ff967900e76ee63e86dc9620dfc', 'message': 'python-troveclient 6.0.0 for Wallaby\n\nChange-Id: I841969913698591984d6920a84913968f41fa618\n'}]",0,764443,e9e761e8d8277ff967900e76ee63e86dc9620dfc,8,3,1,6732,,,0,"python-troveclient 6.0.0 for Wallaby

Change-Id: I841969913698591984d6920a84913968f41fa618
",git fetch https://review.opendev.org/openstack/releases refs/changes/43/764443/1 && git format-patch -1 --stdout FETCH_HEAD,['deliverables/wallaby/python-troveclient.yaml'],1,e9e761e8d8277ff967900e76ee63e86dc9620dfc,troveclient-6.0.0,releases: - version: 6.0.0 projects: - repo: openstack/python-troveclient hash: 8b892239dcc012d833ea4fb95d4bfd7db6ae7869,,5,0
openstack%2Fkolla-ansible~master~Ic7eb12823d65b3e9b50e0778c2bef6cd8fe567bb,openstack/kolla-ansible,master,Ic7eb12823d65b3e9b50e0778c2bef6cd8fe567bb,Add OVN bits to octavia.conf,ABANDONED,2020-11-09 14:00:33.000000000,2020-11-30 10:48:54.000000000,,"[{'_account_id': 14826}, {'_account_id': 22348}, {'_account_id': 22629}, {'_account_id': 23084}]","[{'number': 1, 'created': '2020-11-09 14:00:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/597cbd848be42f21ad207b31695eb7e320d3ee57', 'message': 'WIP: Add OVN bits to octavia.conf\n\nChange-Id: Ic7eb12823d65b3e9b50e0778c2bef6cd8fe567bb\n'}, {'number': 2, 'created': '2020-11-09 15:54:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/fdb5f3bd6a8170b8419b66e9e2819b9c3c346fd1', 'message': 'WIP: Add OVN bits to octavia.conf\n\nChange-Id: Ic7eb12823d65b3e9b50e0778c2bef6cd8fe567bb\n'}, {'number': 3, 'created': '2020-11-10 08:22:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/77f81c214a2ae070259c9a53665a0f489f07bc03', 'message': 'WIP: Add OVN bits to octavia.conf\n\nChange-Id: Ic7eb12823d65b3e9b50e0778c2bef6cd8fe567bb\n'}, {'number': 4, 'created': '2020-11-10 14:46:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/ce90c885a874ef7670963da283411a7dcf6ee4f6', 'message': 'WIP: Add OVN bits to octavia.conf\n\nChange-Id: Ic7eb12823d65b3e9b50e0778c2bef6cd8fe567bb\n'}, {'number': 5, 'created': '2020-11-10 14:47:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/5f1295e9029f03c607262a8761d5952fb4322f35', 'message': 'Add OVN bits to octavia.conf\n\nChange-Id: Ic7eb12823d65b3e9b50e0778c2bef6cd8fe567bb\n'}, {'number': 6, 'created': '2020-11-10 14:47:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/19ed90b4f84a8c20e0bc132ecd1550793e4856b7', 'message': 'Add OVN bits to octavia.conf\n\nChange-Id: Ic7eb12823d65b3e9b50e0778c2bef6cd8fe567bb\n'}, {'number': 7, 'created': '2020-11-10 18:13:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/448a6c7f741599eb48c0b00bcf02b3e4feb72261', 'message': 'Add OVN bits to octavia.conf\n\nChange-Id: Ic7eb12823d65b3e9b50e0778c2bef6cd8fe567bb\n'}, {'number': 8, 'created': '2020-11-25 10:35:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/402a383da27937538de152a93b2bc794d05788f5', 'message': 'Add OVN bits to octavia.conf\n\nChange-Id: Ic7eb12823d65b3e9b50e0778c2bef6cd8fe567bb\n'}, {'number': 9, 'created': '2020-11-30 10:27:47.000000000', 'files': ['ansible/roles/octavia/templates/octavia.conf.j2', 'tests/run.yml', 'tests/templates/globals-default.j2', 'tests/test-ovn.sh', 'zuul.d/base.yaml', 'zuul.d/project.yaml'], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/585b5f5b7d254737434ad0b046d25c02a611ff0e', 'message': 'Add OVN bits to octavia.conf\n\nChange-Id: Ic7eb12823d65b3e9b50e0778c2bef6cd8fe567bb\n'}]",7,761927,585b5f5b7d254737434ad0b046d25c02a611ff0e,24,4,9,22629,,,0,"Add OVN bits to octavia.conf

Change-Id: Ic7eb12823d65b3e9b50e0778c2bef6cd8fe567bb
",git fetch https://review.opendev.org/openstack/kolla-ansible refs/changes/27/761927/3 && git format-patch -1 --stdout FETCH_HEAD,"['ansible/roles/octavia/templates/octavia.conf.j2', 'tests/run.yml', 'tests/templates/globals-default.j2']",3,597cbd848be42f21ad207b31695eb7e320d3ee57,octavia_driver_agent,"enable_octavia: ""yes""",,10,1
openstack%2Fceilometer~master~Iaf2b3d3c0a5648878a390b55e00fed663af8086c,openstack/ceilometer,master,Iaf2b3d3c0a5648878a390b55e00fed663af8086c,Imported Translations from Zanata,MERGED,2020-11-25 06:53:50.000000000,2020-11-30 10:42:59.000000000,2020-11-30 10:41:24.000000000,"[{'_account_id': 4264}, {'_account_id': 14107}, {'_account_id': 22348}]","[{'number': 1, 'created': '2020-11-25 06:53:50.000000000', 'files': ['releasenotes/source/locale/en_GB/LC_MESSAGES/releasenotes.po'], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/17b03d67de6dbb3651993bd5cd96fdcd24773ac3', 'message': 'Imported Translations from Zanata\n\nFor more information about this automatic import see:\nhttps://docs.openstack.org/i18n/latest/reviewing-translation-import.html\n\nChange-Id: Iaf2b3d3c0a5648878a390b55e00fed663af8086c\n'}]",0,764126,17b03d67de6dbb3651993bd5cd96fdcd24773ac3,8,3,1,11131,,,0,"Imported Translations from Zanata

For more information about this automatic import see:
https://docs.openstack.org/i18n/latest/reviewing-translation-import.html

Change-Id: Iaf2b3d3c0a5648878a390b55e00fed663af8086c
",git fetch https://review.opendev.org/openstack/ceilometer refs/changes/26/764126/1 && git format-patch -1 --stdout FETCH_HEAD,['releasenotes/source/locale/en_GB/LC_MESSAGES/releasenotes.po'],1,17b03d67de6dbb3651993bd5cd96fdcd24773ac3,zanata/translations,"""POT-Creation-Date: 2020-11-17 16:39+0000\n""""PO-Revision-Date: 2020-11-24 02:39+0000\n""msgid ""15.0.0-20"" msgstr ""15.0.0-20""","""POT-Creation-Date: 2020-11-10 06:20+0000\n""""PO-Revision-Date: 2020-11-16 01:28+0000\n""msgid ""15.0.0-18"" msgstr ""15.0.0-18""",4,4
openstack%2Fnova~master~I999336dff277954e7621489cc7f5e486962ee2a5,openstack/nova,master,I999336dff277954e7621489cc7f5e486962ee2a5,"Revert ""zuul: Skip test_attach_scsi_disk_with_config_drive in nova-ceph-multistore""",MERGED,2020-11-27 15:10:43.000000000,2020-11-30 10:28:34.000000000,2020-11-30 10:23:11.000000000,"[{'_account_id': 7166}, {'_account_id': 8556}, {'_account_id': 9708}, {'_account_id': 10135}, {'_account_id': 15334}, {'_account_id': 22348}]","[{'number': 1, 'created': '2020-11-27 15:10:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/02460e248abb0f841368858304ff486bc6a5a5c7', 'message': 'Revert ""zuul: Skip test_attach_scsi_disk_with_config_drive in nova-ceph-multistore""\n\nThis reverts commit 836e13cd5785a9614bcddb98ee2b7367a3dc8541.\n\nReason for revert: <INSERT REASONING HERE>\n\ndepends-on patch fixed the test.\n\nChange-Id: I999336dff277954e7621489cc7f5e486962ee2a5\nDepends-On: https://review.opendev.org/c/openstack/tempest/+/764407\n'}, {'number': 2, 'created': '2020-11-28 14:36:53.000000000', 'files': ['.zuul.yaml'], 'web_link': 'https://opendev.org/openstack/nova/commit/4bea68f12b2d3355ec95c471bf12306d08c58729', 'message': 'Revert ""zuul: Skip test_attach_scsi_disk_with_config_drive in nova-ceph-multistore""\n\nThis reverts commit 836e13cd5785a9614bcddb98ee2b7367a3dc8541.\n\nReason for revert: depends-on patch fixed the test.\n\nChange-Id: I999336dff277954e7621489cc7f5e486962ee2a5\nDepends-On: https://review.opendev.org/c/openstack/tempest/+/764407\n'}]",2,764311,4bea68f12b2d3355ec95c471bf12306d08c58729,21,6,2,8556,,,0,"Revert ""zuul: Skip test_attach_scsi_disk_with_config_drive in nova-ceph-multistore""

This reverts commit 836e13cd5785a9614bcddb98ee2b7367a3dc8541.

Reason for revert: depends-on patch fixed the test.

Change-Id: I999336dff277954e7621489cc7f5e486962ee2a5
Depends-On: https://review.opendev.org/c/openstack/tempest/+/764407
",git fetch https://review.opendev.org/openstack/nova refs/changes/11/764311/2 && git format-patch -1 --stdout FETCH_HEAD,['.zuul.yaml'],1,02460e248abb0f841368858304ff486bc6a5a5c7,, tempest_black_regex: .*encrypted_cinder_volumes.*, # FIXME(lyarwood): test_attach_scsi_disk_with_config_drive attempts to # delete an image that has been cloned by nova ahead of the instance # being removed. Skip this test until it is reworked to remove the server # ahead of the image. tempest_black_regex: .*encrypted_cinder_volumes.*|.*test_attach_scsi_disk_with_config_drive,1,5
openstack%2Fopenstack-ansible-os_cinder~stable%2Ftrain~I064da0fa840b0ac051fc6ee1ad728c3040d9d9f8,openstack/openstack-ansible-os_cinder,stable/train,I064da0fa840b0ac051fc6ee1ad728c3040d9d9f8,Set correct permissions for rootwrap.d,MERGED,2020-11-16 07:44:48.000000000,2020-11-30 10:27:57.000000000,2020-11-30 10:26:43.000000000,"[{'_account_id': 22348}, {'_account_id': 29865}, {'_account_id': 31542}]","[{'number': 1, 'created': '2020-11-16 07:44:48.000000000', 'files': ['tasks/cinder_post_install.yml'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_cinder/commit/75d09f16af73dec5395858143400992f27a3a93e', 'message': 'Set correct permissions for rootwrap.d\n\nRecursive task against /etc/cinder/rootwrap.d set directory permissions\nto 0640 as well, which is not really valid. Also it was not idempotent\nwith dir creation from pre-install step.\n\nChange-Id: I064da0fa840b0ac051fc6ee1ad728c3040d9d9f8\n(cherry picked from commit f5ba9b5b9a88ab09f3d6afded011976525c863a3)\n'}]",0,762790,75d09f16af73dec5395858143400992f27a3a93e,8,3,1,28619,,,0,"Set correct permissions for rootwrap.d

Recursive task against /etc/cinder/rootwrap.d set directory permissions
to 0640 as well, which is not really valid. Also it was not idempotent
with dir creation from pre-install step.

Change-Id: I064da0fa840b0ac051fc6ee1ad728c3040d9d9f8
(cherry picked from commit f5ba9b5b9a88ab09f3d6afded011976525c863a3)
",git fetch https://review.opendev.org/openstack/openstack-ansible-os_cinder refs/changes/90/762790/1 && git format-patch -1 --stdout FETCH_HEAD,['tasks/cinder_post_install.yml'],1,75d09f16af73dec5395858143400992f27a3a93e,,"# NOTE(noonedeadpunk): X keeps execute permissions for rootwrap.d itself. mode: ""u=rwX,g=rX,o="""," mode: ""0640""",2,1
openstack%2Fneutron-tempest-plugin~master~If34ed0bd65a2eedae85894d80fb4f47eedef0165,openstack/neutron-tempest-plugin,master,If34ed0bd65a2eedae85894d80fb4f47eedef0165,Switch neutron-tempest-plugin-api job to be uwsgi based,MERGED,2020-11-05 13:56:53.000000000,2020-11-30 10:20:03.000000000,2020-11-30 10:20:03.000000000,"[{'_account_id': 4694}, {'_account_id': 8313}, {'_account_id': 11975}, {'_account_id': 16688}, {'_account_id': 21798}, {'_account_id': 22348}]","[{'number': 1, 'created': '2020-11-05 13:56:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-tempest-plugin/commit/7412fdf0c934cce27172f09eefae71b1660d72a2', 'message': 'Switch neutron-tempest-plugin-api job to be uwsgi based\n\nTest of uwsgi based deployment is most important on the API\nlevel, so this patch switches neutron-tempest-plugin-api job to\nrun neutron with uwsgi there.\nThanks to that we will also drop neutron-tempest-with-uwsgi\nwhich is defined in the neutron repo from neutron CI queues.\n\nChange-Id: If34ed0bd65a2eedae85894d80fb4f47eedef0165\n'}, {'number': 2, 'created': '2020-11-26 13:07:59.000000000', 'files': ['zuul.d/queens_jobs.yaml', 'zuul.d/stein_jobs.yaml', 'zuul.d/train_jobs.yaml', 'zuul.d/ussuri_jobs.yaml', 'zuul.d/master_jobs.yaml', 'zuul.d/victoria_jobs.yaml', 'zuul.d/rocky_jobs.yaml'], 'web_link': 'https://opendev.org/openstack/neutron-tempest-plugin/commit/de20363bc107f6a99a9a5f54ee0edeb01ef3eaf0', 'message': 'Switch neutron-tempest-plugin-api job to be uwsgi based\n\nTest of uwsgi based deployment is most important on the API\nlevel, so this patch switches neutron-tempest-plugin-api job to\nrun neutron with uwsgi there.\nThanks to that we will also drop neutron-tempest-with-uwsgi\nwhich is defined in the neutron repo from neutron CI queues.\n\nChange-Id: If34ed0bd65a2eedae85894d80fb4f47eedef0165\n'}]",0,761611,de20363bc107f6a99a9a5f54ee0edeb01ef3eaf0,24,6,2,11975,,,0,"Switch neutron-tempest-plugin-api job to be uwsgi based

Test of uwsgi based deployment is most important on the API
level, so this patch switches neutron-tempest-plugin-api job to
run neutron with uwsgi there.
Thanks to that we will also drop neutron-tempest-with-uwsgi
which is defined in the neutron repo from neutron CI queues.

Change-Id: If34ed0bd65a2eedae85894d80fb4f47eedef0165
",git fetch https://review.opendev.org/openstack/neutron-tempest-plugin refs/changes/11/761611/1 && git format-patch -1 --stdout FETCH_HEAD,"['zuul.d/queens_jobs.yaml', 'zuul.d/stein_jobs.yaml', 'zuul.d/train_jobs.yaml', 'zuul.d/ussuri_jobs.yaml', 'zuul.d/master_jobs.yaml', 'zuul.d/victoria_jobs.yaml', 'zuul.d/rocky_jobs.yaml']",7,7412fdf0c934cce27172f09eefae71b1660d72a2,improve-neutron-ci, NEUTRON_DEPLOY_MOD_WSGI: false,,8,0
openstack%2Fkolla~master~Icae24e3a5f522ec97cc43d6eda1811d5b2231d94,openstack/kolla,master,Icae24e3a5f522ec97cc43d6eda1811d5b2231d94,Use apt instead of legacy apt-get,ABANDONED,2020-11-20 01:52:50.000000000,2020-11-30 10:12:41.000000000,,"[{'_account_id': 14826}, {'_account_id': 22348}, {'_account_id': 24072}]","[{'number': 1, 'created': '2020-11-20 01:52:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla/commit/8b6a63585499e061571b1c925cc5f54d0bfa3273', 'message': ""Update docs for Ubuntu 20.04\n\n* Use 'apt install' command instead of legacy 'apt-get'\n\nChange-Id: Icae24e3a5f522ec97cc43d6eda1811d5b2231d94\n""}, {'number': 2, 'created': '2020-11-20 09:41:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla/commit/9d6969e3dafeefa0eb7876bfc732bb66418d5bf7', 'message': ""Update dockerfiles for Ubuntu 20.04\n\n* Use 'apt install' command instead of legacy 'apt-get'\n\nChange-Id: Icae24e3a5f522ec97cc43d6eda1811d5b2231d94\n""}, {'number': 3, 'created': '2020-11-27 07:12:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla/commit/e109bef7b9c4fa2378c51d61d0bda1fad01917a6', 'message': ""Update dockerfiles for Ubuntu 20.04\n\n* Use 'apt install' command instead of legacy 'apt-get'\n\nChange-Id: Icae24e3a5f522ec97cc43d6eda1811d5b2231d94\n""}, {'number': 4, 'created': '2020-11-30 09:30:43.000000000', 'files': ['kolla/template/methods.py', 'docker/bifrost/bifrost-base/Dockerfile.j2', 'docker/base/Dockerfile.j2', 'tools/validate-install-command.sh', 'kolla/tests/test_methods.py'], 'web_link': 'https://opendev.org/openstack/kolla/commit/428dea79a2ac99ce2d1fcd4d9e7af98ffabd6f7d', 'message': 'Use apt instead of legacy apt-get\n\nChange-Id: Icae24e3a5f522ec97cc43d6eda1811d5b2231d94\n'}]",2,763491,428dea79a2ac99ce2d1fcd4d9e7af98ffabd6f7d,13,3,4,32029,,,0,"Use apt instead of legacy apt-get

Change-Id: Icae24e3a5f522ec97cc43d6eda1811d5b2231d94
",git fetch https://review.opendev.org/openstack/kolla refs/changes/91/763491/4 && git format-patch -1 --stdout FETCH_HEAD,"['kolla/template/methods.py', 'docker/bifrost/bifrost-base/Dockerfile.j2', 'docker/base/Dockerfile.j2', 'tools/validate-install-command.sh', 'kolla/tests/test_methods.py']",5,8b6a63585499e061571b1c925cc5f54d0bfa3273,apt, expectCmd = 'apt -y install --no-install-recommends package2.deb', expectCmd = 'apt-get -y install --no-install-recommends package2.deb',16,16
openstack%2Fcharm-ceph-mon~master~I1d2b5351574a8741e55a8e6482d0c4a168562050,openstack/charm-ceph-mon,master,I1d2b5351574a8741e55a8e6482d0c4a168562050,Sync charmhelpers,MERGED,2020-11-19 12:00:10.000000000,2020-11-30 10:12:18.000000000,2020-11-30 10:12:18.000000000,"[{'_account_id': 10068}, {'_account_id': 20648}, {'_account_id': 22348}, {'_account_id': 31289}]","[{'number': 1, 'created': '2020-11-19 12:00:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-ceph-mon/commit/d1a8c0e09803d32d807556be2862264661bb13dc', 'message': 'Sync charmhelpers\nRecent charmhelpers change forwards the broker requests to the\nceph-rbd-mirror with information about the RBD mirroring mode.\nThis is needed for Cinder Ceph Replication spec\n\nChange-Id: I1d2b5351574a8741e55a8e6482d0c4a168562050\nCo-authored-by: Ionut Balutiou <ibalutoiu@cloudbasesolutions.com>\n'}, {'number': 2, 'created': '2020-11-23 17:24:16.000000000', 'files': ['hooks/charmhelpers/contrib/openstack/utils.py', 'hooks/charmhelpers/contrib/storage/linux/ceph.py', 'hooks/charmhelpers/core/host.py', 'hooks/charmhelpers/contrib/network/ip.py', 'hooks/charmhelpers/core/decorators.py'], 'web_link': 'https://opendev.org/openstack/charm-ceph-mon/commit/00e7129d87f514f5a5fe7f5f75143bebea46b00b', 'message': 'Sync charmhelpers\n\nRecent charmhelpers change forwards the broker requests to the\nceph-rbd-mirror with information about the RBD mirroring mode.\nThis is needed for Cinder Ceph Replication spec\n\nChange-Id: I1d2b5351574a8741e55a8e6482d0c4a168562050\nCo-authored-by: Ionut Balutiou <ibalutoiu@cloudbasesolutions.com>\n'}]",0,763361,00e7129d87f514f5a5fe7f5f75143bebea46b00b,32,4,2,32431,,,0,"Sync charmhelpers

Recent charmhelpers change forwards the broker requests to the
ceph-rbd-mirror with information about the RBD mirroring mode.
This is needed for Cinder Ceph Replication spec

Change-Id: I1d2b5351574a8741e55a8e6482d0c4a168562050
Co-authored-by: Ionut Balutiou <ibalutoiu@cloudbasesolutions.com>
",git fetch https://review.opendev.org/openstack/charm-ceph-mon refs/changes/61/763361/1 && git format-patch -1 --stdout FETCH_HEAD,"['hooks/charmhelpers/contrib/openstack/utils.py', 'hooks/charmhelpers/contrib/storage/linux/ceph.py', 'hooks/charmhelpers/core/host.py', 'hooks/charmhelpers/core/decorators.py', 'hooks/charmhelpers/contrib/openstack/context.py']",5,d1a8c0e09803d32d807556be2862264661bb13dc,cinder-ceph-replication," def __init__(self, ceph_relation='ceph'): self._ceph_relation = ceph_relation self.interfaces = [ceph_relation] if not relation_ids(self._ceph_relation): rbd_mirroring_mode = config('rbd-mirroring-mode') for rid in relation_ids(self._ceph_relation): if rbd_mirroring_mode != ""image"" and not ctxt.get('rbd_features'):", interfaces = ['ceph'] if not relation_ids('ceph'): for rid in relation_ids('ceph'): if not ctxt.get('rbd_features'):,80,10
openstack%2Fneutron~master~Ibcc29c998065da521b35e5845727794a68782db0,openstack/neutron,master,Ibcc29c998065da521b35e5845727794a68782db0,Neutron ovs agent: set mtu of smartnic port,MERGED,2020-10-12 02:34:51.000000000,2020-11-30 10:10:47.000000000,2020-11-30 10:08:52.000000000,"[{'_account_id': 5948}, {'_account_id': 8313}, {'_account_id': 9845}, {'_account_id': 10068}, {'_account_id': 11975}, {'_account_id': 12171}, {'_account_id': 15752}, {'_account_id': 16688}, {'_account_id': 16690}, {'_account_id': 22348}, {'_account_id': 26622}, {'_account_id': 28714}, {'_account_id': 29963}, {'_account_id': 32291}, {'_account_id': 32461}]","[{'number': 1, 'created': '2020-10-12 02:34:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/4b8bd49b5e5dd3896e386b73adf225a30da382e5', 'message': ""Neutron ovs agent: set mtu of smartnic port\n\nThe smartnic port's MTU should be set according to the network's MTU\nwhich the port belongs to.\n\nChange-Id: Ibcc29c998065da521b35e5845727794a68782db0\nSigned-off-by: Xiaoyu Min <jackmin@nvidia.com>\n""}, {'number': 2, 'created': '2020-10-15 02:38:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/d76b22cf048086653af61afabdf691262db4b317', 'message': ""Neutron ovs agent: set mtu of smartnic port\n\nThe smartnic port's MTU should be set according to the network's MTU\nwhich the port belongs to.\n\nCloses-Bug: #1899864\nChange-Id: Ibcc29c998065da521b35e5845727794a68782db0\nSigned-off-by: Xiaoyu Min <jackmin@nvidia.com>\n""}, {'number': 3, 'created': '2020-10-21 02:58:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/d8a461e233fd5c192a2df37303475de7e56fbe6f', 'message': ""Neutron ovs agent: set mtu of smartnic port\n\nThe smartnic port's MTU should be set according to the network's MTU\nwhich the port belongs to.\n\nCloses-Bug: #1899864\nChange-Id: Ibcc29c998065da521b35e5845727794a68782db0\nSigned-off-by: Xiaoyu Min <jackmin@nvidia.com>\n""}, {'number': 4, 'created': '2020-10-21 03:03:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/3da919c18ffafb43e60b1bdcaa7b6338f1b70c76', 'message': ""Neutron ovs agent: set mtu of smartnic port\n\nThe smartnic port's MTU should be set according to the network's MTU\nwhich the port belongs to.\n\nCloses-Bug: #1899864\nChange-Id: Ibcc29c998065da521b35e5845727794a68782db0\nSigned-off-by: Xiaoyu Min <jackmin@nvidia.com>\n""}, {'number': 5, 'created': '2020-10-23 06:20:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/5214f5aee5b370436dfe5f99fdfbff5d3a06a9ae', 'message': ""Neutron ovs agent: set mtu of smartnic port\n\nThe smartnic port's MTU should be set according to the network's MTU\nwhich the port belongs to.\n\nCloses-Bug: #1899864\nChange-Id: Ibcc29c998065da521b35e5845727794a68782db0\nSigned-off-by: Xiaoyu Min <jackmin@nvidia.com>\n""}, {'number': 6, 'created': '2020-11-26 09:55:13.000000000', 'files': ['neutron/plugins/ml2/drivers/openvswitch/agent/ovs_neutron_agent.py', 'neutron/tests/unit/plugins/ml2/drivers/openvswitch/agent/test_ovs_neutron_agent.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/fc1fe016aa4e77c982da8ea0e6c7b88d7c1dad68', 'message': ""Neutron ovs agent: set mtu of smartnic port\n\nThe smartnic port's MTU should be set according to the network's MTU\nwhich the port belongs to.\n\nCloses-Bug: #1899864\nChange-Id: Ibcc29c998065da521b35e5845727794a68782db0\nSigned-off-by: Xiaoyu Min <jackmin@nvidia.com>\n""}]",8,757368,fc1fe016aa4e77c982da8ea0e6c7b88d7c1dad68,65,15,6,32461,,,0,"Neutron ovs agent: set mtu of smartnic port

The smartnic port's MTU should be set according to the network's MTU
which the port belongs to.

Closes-Bug: #1899864
Change-Id: Ibcc29c998065da521b35e5845727794a68782db0
Signed-off-by: Xiaoyu Min <jackmin@nvidia.com>
",git fetch https://review.opendev.org/openstack/neutron refs/changes/68/757368/1 && git format-patch -1 --stdout FETCH_HEAD,"['neutron/plugins/ml2/drivers/openvswitch/agent/ovs_neutron_agent.py', 'neutron/tests/unit/plugins/ml2/drivers/openvswitch/agent/test_ovs_neutron_agent.py']",2,4b8bd49b5e5dd3896e386b73adf225a30da382e5,bug/1899864,"TEST_MTU = 7824 network_id = 'e850ed99-5f46-47bc-8c06-86d9d519c46b' port_arg = {""id"": TEST_PORT_ID1, ""network_id"": network_id} network = {'id': network_id, 'mtu': TEST_MTU} ""get_resource_by_id"") as mocked_resource,\ mock.patch.object(self.agent.plugin_rpc, ""get_network_details"", return_value=network): port['network_id'] = network_id 'vif_type': bindings_data['vif_type'], 'mtu': TEST_MTU default_mtu = 1500 'vif_type': portbindings.VIF_TYPE_UNBOUND, 'mtu': default_mtu 'vif_type': vif_type, 'mtu': TEST_MTU} vif = agent._get_vif_object(iface_id, rep_port, mac, TEST_MTU) default_mtu = 1500 'vm_uuid': '', 'mtu': default_mtu}] default_mtu = 1500 network = {'id': TEST_NETWORK_ID1, 'mtu': TEST_MTU} 'binding:vif_type': portbindings.VIF_TYPE_OVS, 'network_id': TEST_NETWORK_ID1 'vm_uuid': '', 'mtu': default_mtu}, 'vm_uuid': ""407a79e0-e0be-4b7d-92a6-513b2161011e"", 'mtu': TEST_MTU}] return_value=ports_int_br),\ mock.patch.object(self.agent.plugin_rpc, ""get_network_details"", return_value=network): vm_uuid, TEST_MTU) 'vif_type': portbindings.VIF_TYPE_OVS, 'mtu': TEST_MTU} portbindings.VIF_TYPE_UNBOUND, mtu=TEST_MTU) 'vif_type': portbindings.VIF_TYPE_UNBOUND, 'mtu': TEST_MTU}"," port_arg = {""id"": TEST_PORT_ID1} ""get_resource_by_id"") as mocked_resource: 'vif_type': bindings_data['vif_type'] 'vif_type': portbindings.VIF_TYPE_UNBOUND 'vif_type': vif_type} vif = agent._get_vif_object(iface_id, rep_port, mac) 'vm_uuid': ''}] 'binding:vif_type': portbindings.VIF_TYPE_OVS 'vm_uuid': ''}, 'vm_uuid': ""407a79e0-e0be-4b7d-92a6-513b2161011e""}] return_value=ports_int_br): vm_uuid,) 'vif_type': portbindings.VIF_TYPE_OVS} portbindings.VIF_TYPE_UNBOUND) 'vif_type': portbindings.VIF_TYPE_UNBOUND}",59,22
openstack%2Fopenstack-ansible-os_cinder~stable%2Fussuri~I064da0fa840b0ac051fc6ee1ad728c3040d9d9f8,openstack/openstack-ansible-os_cinder,stable/ussuri,I064da0fa840b0ac051fc6ee1ad728c3040d9d9f8,Set correct permissions for rootwrap.d,MERGED,2020-11-16 07:44:40.000000000,2020-11-30 09:57:58.000000000,2020-11-30 09:56:42.000000000,"[{'_account_id': 22348}, {'_account_id': 29865}, {'_account_id': 31542}]","[{'number': 1, 'created': '2020-11-16 07:44:40.000000000', 'files': ['tasks/cinder_post_install.yml'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_cinder/commit/1e31311b567708c58cd2c9077de67c4f912ddb3e', 'message': 'Set correct permissions for rootwrap.d\n\nRecursive task against /etc/cinder/rootwrap.d set directory permissions\nto 0640 as well, which is not really valid. Also it was not idempotent\nwith dir creation from pre-install step.\n\nChange-Id: I064da0fa840b0ac051fc6ee1ad728c3040d9d9f8\n(cherry picked from commit f5ba9b5b9a88ab09f3d6afded011976525c863a3)\n'}]",0,762789,1e31311b567708c58cd2c9077de67c4f912ddb3e,9,3,1,28619,,,0,"Set correct permissions for rootwrap.d

Recursive task against /etc/cinder/rootwrap.d set directory permissions
to 0640 as well, which is not really valid. Also it was not idempotent
with dir creation from pre-install step.

Change-Id: I064da0fa840b0ac051fc6ee1ad728c3040d9d9f8
(cherry picked from commit f5ba9b5b9a88ab09f3d6afded011976525c863a3)
",git fetch https://review.opendev.org/openstack/openstack-ansible-os_cinder refs/changes/89/762789/1 && git format-patch -1 --stdout FETCH_HEAD,['tasks/cinder_post_install.yml'],1,1e31311b567708c58cd2c9077de67c4f912ddb3e,,"# NOTE(noonedeadpunk): X keeps execute permissions for rootwrap.d itself. mode: ""u=rwX,g=rX,o="""," mode: ""0640""",2,1
openstack%2Fcharm-ceph-proxy~master~I60d6b713c152c14b5af37b5c87308c72408801e3,openstack/charm-ceph-proxy,master,I60d6b713c152c14b5af37b5c87308c72408801e3,Add Groovy to the test gate,MERGED,2020-11-05 11:44:31.000000000,2020-11-30 09:51:49.000000000,2020-11-30 09:51:49.000000000,"[{'_account_id': 20648}, {'_account_id': 20870}, {'_account_id': 22348}]","[{'number': 1, 'created': '2020-11-05 11:44:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-ceph-proxy/commit/5b222476d2b397975471d2cb54b28a1f9d722e61', 'message': 'Add Groovy to the test gate\n\nChange-Id: I60d6b713c152c14b5af37b5c87308c72408801e3\n'}, {'number': 2, 'created': '2020-11-27 13:10:14.000000000', 'files': ['tests/tests.yaml', 'charmhelpers/contrib/openstack/utils.py', 'lib/charms_ceph/utils.py', 'charmhelpers/core/host.py', 'charmhelpers/contrib/openstack/ip.py', 'lib/charms_ceph/broker.py', 'charmhelpers/core/decorators.py', 'charmhelpers/contrib/storage/linux/ceph.py', 'charmhelpers/contrib/network/ip.py', 'charmhelpers/core/host_factory/ubuntu.py', 'charmhelpers/contrib/hahelpers/apache.py'], 'web_link': 'https://opendev.org/openstack/charm-ceph-proxy/commit/bee30372d699fe1277f354e55e7f309ded46b622', 'message': 'Add Groovy to the test gate\n\nAlso sync libraries\n\nChange-Id: I60d6b713c152c14b5af37b5c87308c72408801e3\n'}]",0,761547,bee30372d699fe1277f354e55e7f309ded46b622,16,3,2,31289,,,0,"Add Groovy to the test gate

Also sync libraries

Change-Id: I60d6b713c152c14b5af37b5c87308c72408801e3
",git fetch https://review.opendev.org/openstack/charm-ceph-proxy refs/changes/47/761547/2 && git format-patch -1 --stdout FETCH_HEAD,"['tests/tests.yaml', 'charmhelpers/contrib/openstack/utils.py', 'lib/charms_ceph/utils.py', 'lib/charms_ceph/broker.py', 'charmhelpers/contrib/storage/linux/ceph.py', 'charmhelpers/core/host_factory/ubuntu.py']",6,5b222476d2b397975471d2cb54b28a1f9d722e61,groovy-charm-gate," 'focal', 'groovy'", 'focal',39,10
openstack%2Fcharm-neutron-api-plugin-ovn~master~Ie420f21333280de95799538fd733fbbf69b677e7,openstack/charm-neutron-api-plugin-ovn,master,Ie420f21333280de95799538fd733fbbf69b677e7,Add Groovy to the test gate,MERGED,2020-11-05 11:50:48.000000000,2020-11-30 09:51:26.000000000,2020-11-30 09:51:26.000000000,"[{'_account_id': 20648}, {'_account_id': 20870}, {'_account_id': 22348}]","[{'number': 1, 'created': '2020-11-05 11:50:48.000000000', 'files': ['src/tests/tests.yaml'], 'web_link': 'https://opendev.org/openstack/charm-neutron-api-plugin-ovn/commit/06a53a62c6aeac5f975b7711c81a334877b967ab', 'message': 'Add Groovy to the test gate\n\nChange-Id: Ie420f21333280de95799538fd733fbbf69b677e7\n'}]",0,761573,06a53a62c6aeac5f975b7711c81a334877b967ab,12,3,1,31289,,,0,"Add Groovy to the test gate

Change-Id: Ie420f21333280de95799538fd733fbbf69b677e7
",git fetch https://review.opendev.org/openstack/charm-neutron-api-plugin-ovn refs/changes/73/761573/1 && git format-patch -1 --stdout FETCH_HEAD,['src/tests/tests.yaml'],1,06a53a62c6aeac5f975b7711c81a334877b967ab,groovy-charm-gate,,dev_bundles:,0,1
openstack%2Fcharm-ironic-conductor~master~I28e7c5ed5c08180c29fb92241a7fe695892e008c,openstack/charm-ironic-conductor,master,I28e7c5ed5c08180c29fb92241a7fe695892e008c,Add Victoria bundles to the gate,MERGED,2020-11-04 09:49:29.000000000,2020-11-30 09:51:12.000000000,2020-11-30 09:51:12.000000000,"[{'_account_id': 20648}, {'_account_id': 20870}, {'_account_id': 22348}, {'_account_id': 31289}]","[{'number': 1, 'created': '2020-11-04 09:49:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-ironic-conductor/commit/02f755246becbcf4352812124274e17639d81dcb', 'message': 'Add Victoria bundles to the gate\n\nAnd fix Zaza charm name.\n\nChange-Id: I28e7c5ed5c08180c29fb92241a7fe695892e008c\n'}, {'number': 2, 'created': '2020-11-04 13:36:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-ironic-conductor/commit/21d2b4c2dadffc64871a2fc3e46a30841ea4025b', 'message': 'Add Victoria bundles to the gate\n\nChange-Id: I28e7c5ed5c08180c29fb92241a7fe695892e008c\n'}, {'number': 3, 'created': '2020-11-05 10:24:40.000000000', 'files': ['src/tests/bundles/focal-ussuri.yaml', 'src/tests/bundles/focal-victoria.yaml', 'src/tests/bundles/groovy-victoria.yaml', 'src/tests/tests.yaml', 'src/tests/bundles/bionic-train.yaml', 'src/tests/bundles/bionic-ussuri.yaml', 'src/tests/bundles/overlays/groovy-victoria.yaml.j2'], 'web_link': 'https://opendev.org/openstack/charm-ironic-conductor/commit/0717220e3be9cea5ae7cdb7c01a04691feae53d2', 'message': 'Add Victoria bundles to the gate\n\nChange-Id: I28e7c5ed5c08180c29fb92241a7fe695892e008c\n'}]",0,761348,0717220e3be9cea5ae7cdb7c01a04691feae53d2,17,4,3,31289,,,0,"Add Victoria bundles to the gate

Change-Id: I28e7c5ed5c08180c29fb92241a7fe695892e008c
",git fetch https://review.opendev.org/openstack/charm-ironic-conductor refs/changes/48/761348/3 && git format-patch -1 --stdout FETCH_HEAD,"['src/tests/bundles/groovy-victoria.yaml', 'src/tests/tests.yaml', 'src/tests/bundles/overlays/groovy-victoria.yaml.j2']",3,02f755246becbcf4352812124274e17639d81dcb,groovy-charm-gate,ironic.j2,,288,3
openstack%2Fcharm-cinder~master~I9460ea2d117ad5630fb8826b5a4e5417c0635757,openstack/charm-cinder,master,I9460ea2d117ad5630fb8826b5a4e5417c0635757,Add Groovy to the test gate,MERGED,2020-11-05 11:45:15.000000000,2020-11-30 09:47:01.000000000,2020-11-30 09:47:01.000000000,"[{'_account_id': 20648}, {'_account_id': 20870}, {'_account_id': 22348}]","[{'number': 1, 'created': '2020-11-05 11:45:15.000000000', 'files': ['tests/tests.yaml', 'charmhelpers/contrib/openstack/utils.py', 'charmhelpers/contrib/storage/linux/ceph.py'], 'web_link': 'https://opendev.org/openstack/charm-cinder/commit/33110e8192c09af2cc3d5ed72e3d088e278206b4', 'message': 'Add Groovy to the test gate\n\nChange-Id: I9460ea2d117ad5630fb8826b5a4e5417c0635757\n'}]",0,761550,33110e8192c09af2cc3d5ed72e3d088e278206b4,9,3,1,31289,,,0,"Add Groovy to the test gate

Change-Id: I9460ea2d117ad5630fb8826b5a4e5417c0635757
",git fetch https://review.opendev.org/openstack/charm-cinder refs/changes/50/761550/1 && git format-patch -1 --stdout FETCH_HEAD,"['tests/tests.yaml', 'charmhelpers/contrib/openstack/utils.py', 'charmhelpers/contrib/storage/linux/ceph.py']",3,33110e8192c09af2cc3d5ed72e3d088e278206b4,groovy-charm-gate," application_name,def send_application_name(relid=None): """"""Send the application name down the relation. :param relid: Relation id to set application name in. :type relid: str """""" relation_set( relation_id=relid, relation_settings={'application-name': application_name()}) Profiles are considered immutable so will not be updated if the named profile already exists. Please refer to [0] for more details. if erasure_profile_exists(service, profile_name): log('EC profile {} exists, skipping update'.format(profile_name), level=WARNING) return relation_set(relation_id=rid, relation_settings={'unit-name': local_unit()})"," Updates the profile if it exists. Please refer to [0] for more details. if erasure_profile_exists(service, profile_name): cmd.append('--force') ",24,7
openstack%2Fmagnum~master~If9dd67672becb6def9f97afa7e60b2660cf5b27e,openstack/magnum,master,If9dd67672becb6def9f97afa7e60b2660cf5b27e,Fix Cinder CSI,MERGED,2020-11-10 00:48:57.000000000,2020-11-30 09:45:11.000000000,2020-11-30 09:42:33.000000000,"[{'_account_id': 6484}, {'_account_id': 20498}, {'_account_id': 22348}, {'_account_id': 28022}]","[{'number': 1, 'created': '2020-11-10 00:48:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/magnum/commit/51fc7b0fbc11bc6abf562a229d96ded19f98225b', 'message': 'Fix Cinder CSI\n\nA regression issue introduced by [1], which is causing Cinder CSI pods\nfailed to start. This patch will fixed it.\n\n[1] https://review.opendev.org/#/c/749101/\n\nChange-Id: If9dd67672becb6def9f97afa7e60b2660cf5b27e\nTask: 41097\nStory: 2008250\n'}, {'number': 2, 'created': '2020-11-15 23:01:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/magnum/commit/3af17d9e5abd5c5a385537d00b53dbd4e148e3ad', 'message': 'Fix Cinder CSI\n\nA regression issue introduced by [1], which is causing Cinder CSI pods\nfailed to start. This patch will fixed it.\n\n[1] https://review.opendev.org/#/c/749101/\n\nChange-Id: If9dd67672becb6def9f97afa7e60b2660cf5b27e\nTask: 41097\nStory: 2008250\n'}, {'number': 3, 'created': '2020-11-15 23:03:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/magnum/commit/1bac20942224870b9233db8cff22f5424254e1ee', 'message': 'Fix Cinder CSI\n\nA regression issue introduced by [1], which is causing Cinder CSI pods\nfailed to start. This patch will fixed it.\n\n[1] https://review.opendev.org/#/c/749101/\n\nChange-Id: If9dd67672becb6def9f97afa7e60b2660cf5b27e\nTask: 41097\nStory: 2008250\n'}, {'number': 4, 'created': '2020-11-19 20:14:22.000000000', 'files': ['magnum/drivers/k8s_fedora_coreos_v1/templates/user_data.json', 'magnum/drivers/common/templates/kubernetes/fragments/enable-cinder-csi.sh', 'magnum/drivers/common/templates/kubernetes/fragments/write-kube-os-config.sh', 'magnum/drivers/k8s_fedora_coreos_v1/templates/fcct-config.yaml'], 'web_link': 'https://opendev.org/openstack/magnum/commit/56583ac8fe0dffe932808afc81a57279469b9d56', 'message': 'Fix Cinder CSI\n\nA regression issue introduced by [1], which is causing Cinder CSI pods\nfailed to start. This patch will fixed it.\n\n[1] https://review.opendev.org/#/c/749101/\n\nChange-Id: If9dd67672becb6def9f97afa7e60b2660cf5b27e\nTask: 41097\nStory: 2008250\n'}]",0,762017,56583ac8fe0dffe932808afc81a57279469b9d56,31,4,4,6484,,,0,"Fix Cinder CSI

A regression issue introduced by [1], which is causing Cinder CSI pods
failed to start. This patch will fixed it.

[1] https://review.opendev.org/#/c/749101/

Change-Id: If9dd67672becb6def9f97afa7e60b2660cf5b27e
Task: 41097
Story: 2008250
",git fetch https://review.opendev.org/openstack/magnum refs/changes/17/762017/1 && git format-patch -1 --stdout FETCH_HEAD,"['magnum/drivers/common/templates/kubernetes/fragments/configure-kubernetes-minion.sh', 'magnum/drivers/common/templates/kubernetes/fragments/configure-kubernetes-master.sh', 'magnum/drivers/common/templates/kubernetes/fragments/enable-cinder-csi.sh', 'magnum/drivers/common/templates/kubernetes/fragments/write-kube-os-config.sh']",4,51fc7b0fbc11bc6abf562a229d96ded19f98225b,fix-cinder-csi,,$ssh_cmd cp /etc/pki/tls/certs/ca-bundle.crt /etc/kubernetes/ca-bundle.crt,12,1
openstack%2Ftrove~master~Ic4e2c79f48bfcaea806babbf50d4757a9c153132,openstack/trove,master,Ic4e2c79f48bfcaea806babbf50d4757a9c153132,Get slave_pos to choose latest replica,MERGED,2020-11-20 03:06:04.000000000,2020-11-30 09:40:50.000000000,2020-11-30 09:39:24.000000000,"[{'_account_id': 6732}, {'_account_id': 22348}]","[{'number': 1, 'created': '2020-11-20 03:06:04.000000000', 'files': ['trove/guestagent/datastore/mariadb/service.py'], 'web_link': 'https://opendev.org/openstack/trove/commit/df82af30f21b89097597bf471c2aa5a08d19386c', 'message': 'Get slave_pos to choose latest replica\n\nLatest replica have slave_pos biggest, so we just need use slave_pos to\ncompare replicas.\n\nChange-Id: Ic4e2c79f48bfcaea806babbf50d4757a9c153132\n'}]",2,763498,df82af30f21b89097597bf471c2aa5a08d19386c,12,2,1,31662,,,0,"Get slave_pos to choose latest replica

Latest replica have slave_pos biggest, so we just need use slave_pos to
compare replicas.

Change-Id: Ic4e2c79f48bfcaea806babbf50d4757a9c153132
",git fetch https://review.opendev.org/openstack/trove refs/changes/98/763498/1 && git format-patch -1 --stdout FETCH_HEAD,['trove/guestagent/datastore/mariadb/service.py'],1,df82af30f21b89097597bf471c2aa5a08d19386c,, def _get_gtid_slave_executed(self): with mysql_util.SqlClient(self.get_engine()) as client: return client.execute('SELECT @@global.gtid_slave_pos').first()[0] gtid_executed = self._get_gtid_slave_executed(), gtid_executed = self._get_gtid_executed(),5,1
openstack%2Frpm-packaging~master~I4fc825dd82fe5d38fd04ab5b8906cd3b535144d4,openstack/rpm-packaging,master,I4fc825dd82fe5d38fd04ab5b8906cd3b535144d4,murano: remove congressclient dependency,MERGED,2020-11-19 13:42:00.000000000,2020-11-30 09:22:52.000000000,2020-11-30 09:22:52.000000000,"[{'_account_id': 6593}, {'_account_id': 19648}, {'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2020-11-19 13:42:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rpm-packaging/commit/27680df75ccd17f5559ca3a3e10fdd42537d848a', 'message': 'murano: remove congressclient dependency\n\nThis was removed from the project in\nhttps://review.opendev.org/#/c/744581/ .\n\nChange-Id: I4fc825dd82fe5d38fd04ab5b8906cd3b535144d4\n'}, {'number': 2, 'created': '2020-11-25 14:44:27.000000000', 'files': ['openstack/murano/murano.spec.j2'], 'web_link': 'https://opendev.org/openstack/rpm-packaging/commit/2f586b7dc68464d3859baae0561ff3724c2ac705', 'message': 'murano: remove congressclient dependency\n\nThis was removed from the project in\nhttps://review.opendev.org/#/c/744581/ .\n\nChange-Id: I4fc825dd82fe5d38fd04ab5b8906cd3b535144d4\n'}]",0,763370,2f586b7dc68464d3859baae0561ff3724c2ac705,20,4,2,13294,,,0,"murano: remove congressclient dependency

This was removed from the project in
https://review.opendev.org/#/c/744581/ .

Change-Id: I4fc825dd82fe5d38fd04ab5b8906cd3b535144d4
",git fetch https://review.opendev.org/openstack/rpm-packaging refs/changes/70/763370/2 && git format-patch -1 --stdout FETCH_HEAD,['openstack/murano/murano.spec.j2'],1,27680df75ccd17f5559ca3a3e10fdd42537d848a,,,BuildRequires: {{ py3('python-congressclient') }}Requires: {{ py3('python-congressclient') }},0,2
openstack%2Frpm-packaging~master~Ib41433563b945011d0eef7de10cf707a2033d5cc,openstack/rpm-packaging,master,Ib41433563b945011d0eef7de10cf707a2033d5cc,update oslo.policy to 3.6.0,MERGED,2020-11-26 00:59:39.000000000,2020-11-30 09:15:25.000000000,2020-11-30 09:15:25.000000000,"[{'_account_id': 6593}, {'_account_id': 13294}, {'_account_id': 19648}, {'_account_id': 22348}, {'_account_id': 23181}, {'_account_id': 28522}]","[{'number': 1, 'created': '2020-11-26 00:59:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rpm-packaging/commit/b29b64ee7e7fe3b385f45bb07f5d8b14871ddcab', 'message': 'update oslo.policy to 3.6.0\n\nChange-Id: Ib41433563b945011d0eef7de10cf707a2033d5cc\n'}, {'number': 2, 'created': '2020-11-26 09:06:00.000000000', 'files': ['openstack/oslo.policy/oslo.policy.spec.j2'], 'web_link': 'https://opendev.org/openstack/rpm-packaging/commit/1c8711b0e3c1716ce92ac2ad35c949f3e0ffd031', 'message': 'update oslo.policy to 3.6.0\n\nChange-Id: Ib41433563b945011d0eef7de10cf707a2033d5cc\n'}]",1,764257,1c8711b0e3c1716ce92ac2ad35c949f3e0ffd031,17,6,2,30533,,,0,"update oslo.policy to 3.6.0

Change-Id: Ib41433563b945011d0eef7de10cf707a2033d5cc
",git fetch https://review.opendev.org/openstack/rpm-packaging refs/changes/57/764257/1 && git format-patch -1 --stdout FETCH_HEAD,['openstack/oslo.policy/oslo.policy.spec.j2'],1,b29b64ee7e7fe3b385f45bb07f5d8b14871ddcab,bug/oslo.policy,{% set upstream_version = upstream_version('3.6.0') %},{% set upstream_version = upstream_version('3.5.0') %},1,1
openstack%2Fpymod2pkg~master~Ief6a62bcd36d15ef1eb8ce97957a6cedf721fe2b,openstack/pymod2pkg,master,Ief6a62bcd36d15ef1eb8ce97957a6cedf721fe2b,Remove retired Searchlight usage,MERGED,2020-11-28 22:51:32.000000000,2020-11-30 09:15:16.000000000,2020-11-30 09:13:49.000000000,"[{'_account_id': 13294}, {'_account_id': 22348}, {'_account_id': 28522}]","[{'number': 1, 'created': '2020-11-28 22:51:32.000000000', 'files': ['pymod2pkg/__init__.py'], 'web_link': 'https://opendev.org/openstack/pymod2pkg/commit/298e4119cb1cf72823b652a0fe84f2576c318896', 'message': 'Remove retired Searchlight usage\n\nSearchlight project is retiring in Wallaby cycle[1].\nThis commit removes the usage of Searchlight project\nbefore its code is removed.\n\nNeeded-By: https://review.opendev.org/c/openstack/searchlight/+/764526\n\n[1] http://lists.openstack.org/pipermail/openstack-discuss/2020-November/018637.html\n\nChange-Id: Ief6a62bcd36d15ef1eb8ce97957a6cedf721fe2b\n'}]",0,764576,298e4119cb1cf72823b652a0fe84f2576c318896,8,3,1,8556,,,0,"Remove retired Searchlight usage

Searchlight project is retiring in Wallaby cycle[1].
This commit removes the usage of Searchlight project
before its code is removed.

Needed-By: https://review.opendev.org/c/openstack/searchlight/+/764526

[1] http://lists.openstack.org/pipermail/openstack-discuss/2020-November/018637.html

Change-Id: Ief6a62bcd36d15ef1eb8ce97957a6cedf721fe2b
",git fetch https://review.opendev.org/openstack/pymod2pkg refs/changes/76/764576/1 && git format-patch -1 --stdout FETCH_HEAD,['pymod2pkg/__init__.py'],1,298e4119cb1cf72823b652a0fe84f2576c318896,retire-searchlight," 'openstack', 'qinling', 'sahara', 'scci', 'senlin',"," 'openstack', 'qinling', 'sahara', 'scci', 'searchlight', 'senlin',",1,1
openstack%2Fmistral-extra~master~Ic35b8fb37fb1916a6e51c147372a92cdc04281cf,openstack/mistral-extra,master,Ic35b8fb37fb1916a6e51c147372a92cdc04281cf,Remove retired Qinling support,MERGED,2020-11-28 05:49:07.000000000,2020-11-30 09:09:28.000000000,2020-11-30 09:07:55.000000000,"[{'_account_id': 8731}, {'_account_id': 15895}, {'_account_id': 19134}, {'_account_id': 22348}]","[{'number': 1, 'created': '2020-11-28 05:49:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/mistral-extra/commit/e1e0eaa4cb0613130ad803de0b3e89152e710709', 'message': 'Remove retiring Qinling\n\nQinling project is retiring in Wallaby cycle[1].\nThis commit removes the usages of Qinling project\nbefore its code is removed.\n\nNeeded-By: https://review.opendev.org/c/openstack/qinling/+/764521\n\n[1] http://lists.openstack.org/pipermail/openstack-discuss/2020-November/018638.html\n\nChange-Id: Ic35b8fb37fb1916a6e51c147372a92cdc04281cf\n'}, {'number': 2, 'created': '2020-11-28 06:01:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/mistral-extra/commit/8eddd89d7c6075f2cb03e5322969ecde0263cf3d', 'message': 'Remove retired Qinling support\n\nQinling project is retiring in Wallaby cycle[1].\nThis commit removes the usages of Qinling project\nbefore its code is removed.\n\nNeeded-By: https://review.opendev.org/c/openstack/qinling/+/764521\n\n[1] http://lists.openstack.org/pipermail/openstack-discuss/2020-November/018638.html\n\nChange-Id: Ic35b8fb37fb1916a6e51c147372a92cdc04281cf\n'}, {'number': 3, 'created': '2020-11-28 14:59:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/mistral-extra/commit/29a1dbaa9359d415d1347da3d292e3e000be7806', 'message': 'Remove retired Qinling support\n\nQinling project is retiring in Wallaby cycle[1].\nThis commit removes the usages of Qinling project\nbefore its code is removed.\n\nNeeded-By: https://review.opendev.org/c/openstack/qinling/+/764521\n\n[1] http://lists.openstack.org/pipermail/openstack-discuss/2020-November/018638.html\n\nChange-Id: Ic35b8fb37fb1916a6e51c147372a92cdc04281cf\n'}, {'number': 4, 'created': '2020-11-29 00:02:48.000000000', 'files': ['requirements.txt', 'mistral_extra/actions/openstack/actions.py', 'releasenotes/notes/remove-qinling-suport-523fc534d7008f3f.yaml', 'mistral_extra/tests/unit/actions/openstack/test_generator.py', 'lower-constraints.txt', 'mistral_extra/actions/generator_factory.py', 'mistral_extra/tests/unit/actions/openstack/test_openstack_actions.py', 'mistral_extra/actions/openstack/mapping.json'], 'web_link': 'https://opendev.org/openstack/mistral-extra/commit/dfc6c56490eb358018f79822ae9847e2be89d8b3', 'message': 'Remove retired Qinling support\n\nQinling project is retiring in Wallaby cycle[1].\nThis commit removes the usages of Qinling project\nbefore its code is removed.\n\nNeeded-By: https://review.opendev.org/c/openstack/qinling/+/764521\n\n[1] http://lists.openstack.org/pipermail/openstack-discuss/2020-November/018638.html\n\nChange-Id: Ic35b8fb37fb1916a6e51c147372a92cdc04281cf\n'}]",0,764540,dfc6c56490eb358018f79822ae9847e2be89d8b3,14,4,4,8556,,,0,"Remove retired Qinling support

Qinling project is retiring in Wallaby cycle[1].
This commit removes the usages of Qinling project
before its code is removed.

Needed-By: https://review.opendev.org/c/openstack/qinling/+/764521

[1] http://lists.openstack.org/pipermail/openstack-discuss/2020-November/018638.html

Change-Id: Ic35b8fb37fb1916a6e51c147372a92cdc04281cf
",git fetch https://review.opendev.org/openstack/mistral-extra refs/changes/40/764540/1 && git format-patch -1 --stdout FETCH_HEAD,"['requirements.txt', 'mistral_extra/actions/openstack/actions.py', 'mistral_extra/tests/unit/actions/openstack/test_generator.py', 'lower-constraints.txt', 'mistral_extra/actions/openstack/mapping.json', 'mistral_extra/tests/unit/actions/openstack/test_openstack_actions.py']",6,e1e0eaa4cb0613130ad803de0b3e89152e710709,retire-qinling,," @mock.patch.object(actions.QinlingAction, '_get_client') def test_qinling_action(self, mocked): mock_ctx = mock.Mock() method_name = ""runtimes.get"" action_class = actions.QinlingAction action_class.client_method_name = method_name params = {'id': '1234-abcd'} action = action_class(**params) action.run(mock_ctx) self.assertTrue(mocked().runtimes.get.called) mocked().runtimes.get.assert_called_once_with(id=""1234-abcd"") ",2,68
openstack%2Fcharm-ceph-mon~master~I7348eb053cb3e1dcac830afb6f9c298380b32f35,openstack/charm-ceph-mon,master,I7348eb053cb3e1dcac830afb6f9c298380b32f35,"Fix the misspelling of ""available""",ABANDONED,2019-01-22 03:52:55.000000000,2020-11-30 08:39:15.000000000,,"[{'_account_id': 20634}, {'_account_id': 20648}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-01-22 03:52:55.000000000', 'files': ['lib/ceph/utils.py'], 'web_link': 'https://opendev.org/openstack/charm-ceph-mon/commit/5e99be1b39993540e6568e4245457fc007ab9b9c', 'message': 'Fix the misspelling of ""available""\n\nChange-Id: I7348eb053cb3e1dcac830afb6f9c298380b32f35\n'}]",0,632207,5e99be1b39993540e6568e4245457fc007ab9b9c,5,3,1,29721,,,0,"Fix the misspelling of ""available""

Change-Id: I7348eb053cb3e1dcac830afb6f9c298380b32f35
",git fetch https://review.opendev.org/openstack/charm-ceph-mon refs/changes/07/632207/1 && git format-patch -1 --stdout FETCH_HEAD,['lib/ceph/utils.py'],1,5e99be1b39993540e6568e4245457fc007ab9b9c,, Initialize a raw block device consuming 100% of the available, Initialize a raw block device consuming 100% of the avaliable,1,1
openstack%2Ftripleo-heat-templates~stable%2Fussuri~I934a1ae5bc0d77fd39b25f5039635e5df6e9004f,openstack/tripleo-heat-templates,stable/ussuri,I934a1ae5bc0d77fd39b25f5039635e5df6e9004f,Deploy multipathd using tripleo_multipathd ansible role,MERGED,2020-11-02 21:14:42.000000000,2020-11-30 07:47:20.000000000,2020-11-30 07:45:59.000000000,"[{'_account_id': 6796}, {'_account_id': 8449}, {'_account_id': 18002}, {'_account_id': 21129}, {'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2020-11-02 21:14:42.000000000', 'files': ['environments/multipathd.yaml', 'releasenotes/notes/configure-multipathd-with-ansible-f32f3ea627815191.yaml', 'ci/environments/scenario001-standalone.yaml', 'deployment/deprecated/multipathd-container.yaml', 'deployment/multipathd/multipathd-container-ansible.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/a19a3c6aefc5d0212d6da39f29318b0bd207a5a1', 'message': ""Deploy multipathd using tripleo_multipathd ansible role\n\nThe puppet and ansible tasks for deploying the Multipathd service have\nbeen moved to a new tripleo_multipathd ansible role. THT uses that role\npassing in parameter values via ansible variables.\n\nTwo new THT parameters are supported:\n- MultipathdCustomConfigFile provides a way for the user to specify a\n  custom multipath.conf file. This makes it easier for the user to\n  manage custom settings that are unique to their deployment, such as\n  vendor specific hardware tuning.\n- MultipathdSkipKpartx provides a means for overriding multipathd's\n  default behavior whereby it automatically creates disk partitions on\n  multipath devices. Partitions should be managed by VM servers accessing\n  the device, not by the overcloud host itself.\n\nDepends-On: Icf9faff31d83f0ea77d00a59a53d6ad36b06da4f\nDepends-On: I3478312b5117da5c2e819e47c99f574246e84838\nChange-Id: I934a1ae5bc0d77fd39b25f5039635e5df6e9004f\n(cherry picked from commit 80fcd33248c3861a427c0eabdfbff4d4e2622380)\n""}]",0,761026,a19a3c6aefc5d0212d6da39f29318b0bd207a5a1,25,6,1,21129,,,0,"Deploy multipathd using tripleo_multipathd ansible role

The puppet and ansible tasks for deploying the Multipathd service have
been moved to a new tripleo_multipathd ansible role. THT uses that role
passing in parameter values via ansible variables.

Two new THT parameters are supported:
- MultipathdCustomConfigFile provides a way for the user to specify a
  custom multipath.conf file. This makes it easier for the user to
  manage custom settings that are unique to their deployment, such as
  vendor specific hardware tuning.
- MultipathdSkipKpartx provides a means for overriding multipathd's
  default behavior whereby it automatically creates disk partitions on
  multipath devices. Partitions should be managed by VM servers accessing
  the device, not by the overcloud host itself.

Depends-On: Icf9faff31d83f0ea77d00a59a53d6ad36b06da4f
Depends-On: I3478312b5117da5c2e819e47c99f574246e84838
Change-Id: I934a1ae5bc0d77fd39b25f5039635e5df6e9004f
(cherry picked from commit 80fcd33248c3861a427c0eabdfbff4d4e2622380)
",git fetch https://review.opendev.org/openstack/tripleo-heat-templates refs/changes/26/761026/1 && git format-patch -1 --stdout FETCH_HEAD,"['environments/multipathd.yaml', 'releasenotes/notes/configure-multipathd-with-ansible-f32f3ea627815191.yaml', 'ci/environments/scenario001-standalone.yaml', 'deployment/deprecated/multipathd-container.yaml', 'deployment/multipathd/multipathd-container-ansible.yaml']",5,a19a3c6aefc5d0212d6da39f29318b0bd207a5a1,multipath-v2,"heat_template_version: rocky description: > OpenStack containerized Multipathd service parameters: ContainerMultipathdImage: description: image type: string ContainerMultipathdConfigImage: description: The container image to use for the multipathd config_volume type: string MultipathdEnable: default: false description: Whether to enable the multipath daemon type: boolean MultipathdCustomConfigFile: default: '' description: Fully qualified path of a local multipath.conf file to be installed on the overcloud nodes. By default, a minimal multipath.conf file will be installed. NOTE - Other TripleO multipath parameters will override any corresponding value in the local custom config file. For example, if MultipathdEnableUserFriendlyNames is False, the files on the overcloud nodes will be updated match, even if the setting is enabled in the local custom file. type: string MultipathdEnableUserFriendlyNames: default: false description: Whether to enable assigning a user friendly name to each path type: boolean MultipathdEnableFindMultipaths: default: true description: Whether to automatically create a multipath device for each path type: boolean MultipathdSkipKpartx: default: true description: Whether to skip automatically creating partitions on the device type: boolean EndpointMap: default: {} description: Mapping of service endpoint -> protocol. Typically set via parameter_defaults in the resource registry. type: json ServiceData: default: {} description: Dictionary packing service data type: json ServiceNetMap: default: {} description: Mapping of service_name -> network name. Typically set via parameter_defaults in the resource registry. This mapping overrides those in ServiceNetMapDefaults. type: json RoleName: default: '' description: Role name on which the service is applied type: string RoleParameters: default: {} description: Parameters specific to the role type: json DefaultPasswords: default: {} type: json resources: ContainersCommon: type: ../containers-common.yaml outputs: role_data: description: Role data for the Multipathd API role. value: service_name: multipathd config_settings: {} service_config_settings: {} kolla_config: /var/lib/kolla/config_files/multipathd.json: command: /usr/sbin/multipathd -d config_files: - source: ""/var/lib/kolla/config_files/src-iscsid/*"" dest: ""/etc/iscsi/"" merge: true preserve_properties: true docker_config: step_3: multipathd: start_order: 1 image: {get_param: ContainerMultipathdImage} net: host privileged: true restart: always healthcheck: test: /openstack/healthcheck volumes: list_concat: - {get_attr: [ContainersCommon, volumes]} - - /var/lib/kolla/config_files/multipathd.json:/var/lib/kolla/config_files/config.json:ro - /etc/iscsi:/var/lib/kolla/config_files/src-iscsid:ro - /dev/:/dev/ - /run/:/run/ - /sys:/sys - /lib/modules:/lib/modules:ro - /var/lib/iscsi:/var/lib/iscsi:z - /etc/multipath:/etc/multipath:z - /etc/multipath.conf:/etc/multipath.conf:ro environment: KOLLA_CONFIG_STRATEGY: COPY_ALWAYS deploy_steps_tasks: - name: Configure multipathd when: step|int == 2 import_role: name: tripleo_multipathd vars: tripleo_multipathd_enable: {get_param: MultipathdEnable} tripleo_multipathd_custom_config_file: {get_param: MultipathdCustomConfigFile} tripleo_multipathd_find_multipaths: {get_param: MultipathdEnableFindMultipaths} tripleo_multipathd_skip_kpartx: {get_param: MultipathdSkipKpartx} tripleo_multipathd_user_friendly_names: {get_param: MultipathdEnableUserFriendlyNames} host_prep_tasks: - name: Prep host for multipathd import_role: name: tripleo_multipathd tasks_from: host_prep upgrade_tasks: [] ",,152,1
openstack%2Fmagnum~master~I2028a23678bf6ff7fa7a33a60317c5cbd8576b3b,openstack/magnum,master,I2028a23678bf6ff7fa7a33a60317c5cbd8576b3b,CI: Install debianutils and vim,MERGED,2020-11-17 11:08:19.000000000,2020-11-30 06:34:16.000000000,2020-11-30 06:31:49.000000000,"[{'_account_id': 6484}, {'_account_id': 22348}, {'_account_id': 28022}]","[{'number': 1, 'created': '2020-11-17 11:08:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/magnum/commit/539b49889627914be9c53ba80d34f088c8b24e81', 'message': 'CI: Install debianutils\n\nwhich is required for:\nhttps://github.com/python-cmd2/cmd2/blob/baf0392007659d069a7fed543335ac5e0e937556/cmd2/utils.py#L201\n\nChange-Id: I2028a23678bf6ff7fa7a33a60317c5cbd8576b3b\nSigned-off-by: Spyros Trigazis <spyridon.trigazis@cern.ch>\n'}, {'number': 2, 'created': '2020-11-17 11:19:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/magnum/commit/431df688f4af570c68d9eb7c0ce5472713298094', 'message': 'CI: Install debianutils and vim\n\nBoth required for:\nhttps://github.com/python-cmd2/cmd2/blob/baf0392007659d069a7fed543335ac5e0e937556/cmd2/utils.py#L201\n\nChange-Id: I2028a23678bf6ff7fa7a33a60317c5cbd8576b3b\nSigned-off-by: Spyros Trigazis <spyridon.trigazis@cern.ch>\n'}, {'number': 3, 'created': '2020-11-27 12:46:11.000000000', 'files': ['bindep.txt', 'devstack/files/debs/magnum'], 'web_link': 'https://opendev.org/openstack/magnum/commit/bc051d522f569ca6fd1190c2958eff768699f989', 'message': 'CI: Install debianutils and vim\n\nBoth required for:\nhttps://github.com/python-cmd2/cmd2/blob/baf0392007659d069a7fed543335ac5e0e937556/cmd2/utils.py#L201\n\nChange-Id: I2028a23678bf6ff7fa7a33a60317c5cbd8576b3b\nSigned-off-by: Spyros Trigazis <spyridon.trigazis@cern.ch>\n'}]",0,762991,bc051d522f569ca6fd1190c2958eff768699f989,11,3,3,20498,,,0,"CI: Install debianutils and vim

Both required for:
https://github.com/python-cmd2/cmd2/blob/baf0392007659d069a7fed543335ac5e0e937556/cmd2/utils.py#L201

Change-Id: I2028a23678bf6ff7fa7a33a60317c5cbd8576b3b
Signed-off-by: Spyros Trigazis <spyridon.trigazis@cern.ch>
",git fetch https://review.opendev.org/openstack/magnum refs/changes/91/762991/1 && git format-patch -1 --stdout FETCH_HEAD,['devstack/files/debs/magnum'],1,539b49889627914be9c53ba80d34f088c8b24e81,fix-ci,debianutils ,,1,0
openstack%2Ftripleo-ansible~master~Ie77be94849bba28f322a09d254be650a9ec687f5,openstack/tripleo-ansible,master,Ie77be94849bba28f322a09d254be650a9ec687f5,Add test_deps_setup_tripleo var,MERGED,2020-11-18 08:27:10.000000000,2020-11-30 05:27:12.000000000,2020-11-30 05:25:46.000000000,"[{'_account_id': 8449}, {'_account_id': 14985}, {'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2020-11-18 08:27:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ansible/commit/157758af21d192320957ebf6955de71310fbeade', 'message': 'Use openvswitch package name\n\nCurrently ovs_dpdk molecule jobs are failing with openvswitch\npackage is not available.\n\nReplacing openvswitch* to openvswitch fixes the issue.\n\nChange-Id: Ie77be94849bba28f322a09d254be650a9ec687f5\nSigned-off-by: Chandan Kumar (raukadah) <chkumar@redhat.com>\n'}, {'number': 2, 'created': '2020-11-18 08:49:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ansible/commit/c8cdbdbc0acb84022d21b1aecab800c4836979e1', 'message': 'Add test_deps_setup_tripleo var\n\nCurrently ovs_dpdk molecule jobs are failing with openvswitch\npackage is not available.\n\ntest_deps_setup_tripleo for test_deps role fixes the issue.\n\nChange-Id: Ie77be94849bba28f322a09d254be650a9ec687f5\nSigned-off-by: Chandan Kumar (raukadah) <chkumar@redhat.com>\n'}, {'number': 3, 'created': '2020-11-18 10:08:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ansible/commit/6503d74868ed31e68effe886689616b6fd7ef5eb', 'message': 'Add test_deps_setup_tripleo var\n\nCurrently ovs_dpdk molecule jobs are failing with openvswitch\npackage is not available.\n\ntest_deps_setup_tripleo for test_deps role fixes the issue.\n\nFixed the package name for openvswitch.\n\nChange-Id: Ie77be94849bba28f322a09d254be650a9ec687f5\nSigned-off-by: Chandan Kumar (raukadah) <chkumar@redhat.com>\n'}, {'number': 4, 'created': '2020-11-19 09:03:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ansible/commit/c0508d8222e9ce75e9ce30115f499e8feb65c423', 'message': 'Add test_deps_setup_tripleo var\n\nCurrently ovs_dpdk molecule jobs are failing with openvswitch\npackage is not available.\n\ntest_deps_setup_tripleo for test_deps role fixes the issue.\n\nFixed the package name for openvswitch.\nupdated the job timig also.\n\nChange-Id: Ie77be94849bba28f322a09d254be650a9ec687f5\nSigned-off-by: Chandan Kumar (raukadah) <chkumar@redhat.com>\n'}, {'number': 5, 'created': '2020-11-20 04:37:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ansible/commit/f356e3cf914c9148d15ee4223908d87d8780f4df', 'message': 'Add test_deps_setup_tripleo var\n\nCurrently ovs_dpdk molecule jobs are failing with openvswitch\npackage is not available.\n\ntest_deps_setup_tripleo for test_deps role fixes the issue.\n\nFixed the package name for openvswitch.\nupdated the job timig also.\n\nChange-Id: Ie77be94849bba28f322a09d254be650a9ec687f5\nSigned-off-by: Chandan Kumar (raukadah) <chkumar@redhat.com>\n'}, {'number': 6, 'created': '2020-11-25 03:21:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ansible/commit/0542d0b013bec90494a5b133f98cbb5e06d938d1', 'message': 'Add test_deps_setup_tripleo var\n\nCurrently ovs_dpdk molecule jobs are failing with openvswitch\npackage is not available.\n\ntest_deps_setup_tripleo for test_deps role fixes the issue.\n\nFixed the package name for openvswitch.\nupdated the job timig also.\n\nChange-Id: Ie77be94849bba28f322a09d254be650a9ec687f5\nSigned-off-by: Chandan Kumar (raukadah) <chkumar@redhat.com>\n'}, {'number': 7, 'created': '2020-11-25 07:32:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ansible/commit/7b570449b8013f92ff6d6c7784a818d45adc6856', 'message': 'Add test_deps_setup_tripleo var\n\nCurrently ovs_dpdk molecule jobs are failing with openvswitch\npackage is not available.\n\ntest_deps_setup_tripleo for test_deps role fixes the issue.\n\nFixed the package name for openvswitch.\nupdated the job timig also.\n\nSwitch to ubi:8.2 base image in molecule job to fix package\nconflict issue caused by ubi:8.3\n\nChange-Id: Ie77be94849bba28f322a09d254be650a9ec687f5\nSigned-off-by: Chandan Kumar (raukadah) <chkumar@redhat.com>\n'}, {'number': 8, 'created': '2020-11-25 08:45:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ansible/commit/fa0284481bf8698c6c4bdcc659441028b3ca60eb', 'message': 'Add test_deps_setup_tripleo var\n\nCurrently ovs_dpdk molecule jobs are failing with openvswitch\npackage is not available.\n\ntest_deps_setup_tripleo for test_deps role fixes the issue.\n\nFixed the package name for openvswitch.\nupdated the job timig also.\n\nSwitch to ubi:8.2 base image in molecule job to fix package\nconflict issue caused by ubi:8.3\n\nChange-Id: Ie77be94849bba28f322a09d254be650a9ec687f5\nSigned-off-by: Chandan Kumar (raukadah) <chkumar@redhat.com>\n'}, {'number': 9, 'created': '2020-11-26 08:27:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ansible/commit/1c16a42dd79c3c50688546ae68288376a920f3fd', 'message': 'Add test_deps_setup_tripleo var\n\nCurrently ovs_dpdk molecule jobs are failing with openvswitch\npackage is not available.\n\ntest_deps_setup_tripleo for test_deps role fixes the issue.\n\nFixed the package name for openvswitch.\nupdated the job timig also.\n\nSwitch to ubi:8.2 base image in molecule job to fix package\nconflict issue caused by ubi:8.3\n\nCloses-Bug: #1905683\nCloses-Bug: #1905687\n\nChange-Id: Ie77be94849bba28f322a09d254be650a9ec687f5\nSigned-off-by: Chandan Kumar (raukadah) <chkumar@redhat.com>\n'}, {'number': 10, 'created': '2020-11-26 09:15:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ansible/commit/8e073c83da9b9a8d41b1a985fe63660ffc835064', 'message': 'Add test_deps_setup_tripleo var\n\nCurrently ovs_dpdk molecule jobs are failing with openvswitch\npackage is not available.\n\ntest_deps_setup_tripleo for test_deps role fixes the issue.\n\nFixed the package name for openvswitch.\nupdated the job timig also.\n\nSwitch to ubi:8.2 base image in molecule job to fix package\nconflict issue caused by ubi:8.3\n\nCloses-Bug: #1905683\nCloses-Bug: #1905687\n\nChange-Id: Ie77be94849bba28f322a09d254be650a9ec687f5\nSigned-off-by: Chandan Kumar (raukadah) <chkumar@redhat.com>\n'}, {'number': 11, 'created': '2020-11-26 11:07:21.000000000', 'files': ['tripleo_ansible/roles/tripleo_network_config/molecule/default/molecule.yml', 'tripleo_ansible/roles/tripleo_sshd/molecule/banners/molecule.yml', 'tripleo_ansible/roles/tripleo_ssh_known_hosts/molecule/no_networks/molecule.yml', 'tripleo_ansible/roles/tripleo_create_admin/molecule/addkey/molecule.yml', 'tripleo_ansible/roles/tripleo_ha_wrapper/molecule/default/molecule.yml', 'tripleo_ansible/roles/tripleo_clients_install/molecule/default/molecule.yml', 'tripleo_ansible/roles/tripleo_create_admin/molecule/keygen/molecule.yml', 'zuul.d/base.yaml', 'tripleo_ansible/roles/tripleo_ovs_dpdk/molecule/default/prepare.yml', 'tripleo_ansible/roles/tripleo_create_admin/molecule/default/molecule.yml', 'tripleo_ansible/roles/tripleo_ovs_dpdk/molecule/positive/prepare.yml', 'tripleo_ansible/roles/tripleo_validations_package/molecule/default/molecule.yml', 'tripleo_ansible/roles/tripleo_nvdimm/molecule/default/molecule.yml', 'tripleo_ansible/roles/tripleo_ssh_known_hosts/molecule/default/molecule.yml', 'tripleo_ansible/roles/tripleo_sshd/molecule/default/molecule.yml'], 'web_link': 'https://opendev.org/openstack/tripleo-ansible/commit/641e378bde529d4575ad345c4ce1187a3c9b30df', 'message': 'Add test_deps_setup_tripleo var\n\nCurrently ovs_dpdk molecule jobs are failing with openvswitch\npackage is not available.\n\ntest_deps_setup_tripleo for test_deps role fixes the issue.\n\nFixed the package name for openvswitch.\nupdated the job timig also.\n\nSwitch to ubi:8.2 base image in molecule job to fix package\nconflict issue caused by ubi:8.3\n\nCloses-Bug: #1905683\nCloses-Bug: #1905687\n\nChange-Id: Ie77be94849bba28f322a09d254be650a9ec687f5\nSigned-off-by: Chandan Kumar (raukadah) <chkumar@redhat.com>\n'}]",8,763136,641e378bde529d4575ad345c4ce1187a3c9b30df,54,4,11,12393,,,0,"Add test_deps_setup_tripleo var

Currently ovs_dpdk molecule jobs are failing with openvswitch
package is not available.

test_deps_setup_tripleo for test_deps role fixes the issue.

Fixed the package name for openvswitch.
updated the job timig also.

Switch to ubi:8.2 base image in molecule job to fix package
conflict issue caused by ubi:8.3

Closes-Bug: #1905683
Closes-Bug: #1905687

Change-Id: Ie77be94849bba28f322a09d254be650a9ec687f5
Signed-off-by: Chandan Kumar (raukadah) <chkumar@redhat.com>
",git fetch https://review.opendev.org/openstack/tripleo-ansible refs/changes/36/763136/6 && git format-patch -1 --stdout FETCH_HEAD,"['tripleo_ansible/roles/tripleo_ovs_dpdk/molecule/positive/prepare.yml', 'tripleo_ansible/roles/tripleo_ovs_dpdk/molecule/default/prepare.yml']",2,157758af21d192320957ebf6955de71310fbeade,fix_ovs, - openvswitch, - openvswitch*,2,2
openstack%2Fpuppet-cinder~master~I02fcb369f9435c729081aa7b0d5682da83d8446d,openstack/puppet-cinder,master,I02fcb369f9435c729081aa7b0d5682da83d8446d,Allow db sync timeouts to be configurable,MERGED,2020-11-23 01:39:47.000000000,2020-11-30 04:49:16.000000000,2020-11-30 04:48:11.000000000,"[{'_account_id': 9816}, {'_account_id': 14985}, {'_account_id': 22348}]","[{'number': 1, 'created': '2020-11-23 01:39:47.000000000', 'files': ['manifests/db/sync.pp', 'releasenotes/notes/add_db_sync_timeout-bea2ebf6564d0990.yaml', 'spec/classes/cinder_db_sync_spec.rb'], 'web_link': 'https://opendev.org/openstack/puppet-cinder/commit/0f2219c5efb041d134472a125ee26e49fd438c3a', 'message': 'Allow db sync timeouts to be configurable\n\nAs Openstack projects continue to have longer database migration\nchains, the Puppet default timeout of 300 seconds for an execution\nis becoming too short a duration on some hardware, leading to timeouts.\nAs projects continue to add more migration scripts without pruning\nthe base, timeouts will continue to become more frequent unless\nthis time can be expanded.\n\nChange-Id: I02fcb369f9435c729081aa7b0d5682da83d8446d\nCloses-Bug: #1904962\n'}]",0,763697,0f2219c5efb041d134472a125ee26e49fd438c3a,23,3,1,9414,,,0,"Allow db sync timeouts to be configurable

As Openstack projects continue to have longer database migration
chains, the Puppet default timeout of 300 seconds for an execution
is becoming too short a duration on some hardware, leading to timeouts.
As projects continue to add more migration scripts without pruning
the base, timeouts will continue to become more frequent unless
this time can be expanded.

Change-Id: I02fcb369f9435c729081aa7b0d5682da83d8446d
Closes-Bug: #1904962
",git fetch https://review.opendev.org/openstack/puppet-cinder refs/changes/97/763697/1 && git format-patch -1 --stdout FETCH_HEAD,"['manifests/db/sync.pp', 'releasenotes/notes/add_db_sync_timeout-bea2ebf6564d0990.yaml', 'spec/classes/cinder_db_sync_spec.rb']",3,0f2219c5efb041d134472a125ee26e49fd438c3a,bug/1904962," :timeout => 300, context ""overriding params"" do :extra_params => '--config-file /etc/cinder/cinder.conf', :db_sync_timeout => 750, :timeout => 750,"," context ""overriding extra_params"" do :extra_params => '--config-file /etc/cinder/cinder.conf',",15,3
openstack%2Faodh~master~I96aaf025ccae8450589afbfdc8a3e654b1896b75,openstack/aodh,master,I96aaf025ccae8450589afbfdc8a3e654b1896b75,Fix gnocchi alarm query update issue,ABANDONED,2017-10-13 06:27:20.000000000,2020-11-30 04:46:16.000000000,,"[{'_account_id': 3}, {'_account_id': 1669}, {'_account_id': 2813}, {'_account_id': 6537}, {'_account_id': 22348}, {'_account_id': 22752}, {'_account_id': 26721}]","[{'number': 1, 'created': '2017-10-13 06:27:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/aodh/commit/215186cedc68f5aa7fc1847687c0b8931e0c37d9', 'message': 'Fix gnocchi alarm query update issue and tox.ini\n\n1) Aodh gnocchi alarm query should not be updated when the project condition\nhas already be appended.\n\nBug: #1721452\n\n2) Add whitelist_externals in tox.ini\n\nChange-Id: I96aaf025ccae8450589afbfdc8a3e654b1896b75\n'}, {'number': 2, 'created': '2017-10-14 10:55:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/aodh/commit/f1ebf866b165c965f3a4d14b12fa1ff161944c48', 'message': 'Fix gnocchi alarm query update issue\n\nAodh gnocchi alarm query should not be updated when the project condition\nhas already been appended.\n\nCloses-Bug: #1721452\n\nChange-Id: I96aaf025ccae8450589afbfdc8a3e654b1896b75\n'}, {'number': 3, 'created': '2017-10-17 04:00:29.000000000', 'files': ['aodh/api/controllers/v2/alarm_rules/gnocchi.py', 'aodh/tests/functional/api/v2/test_alarm_scenarios.py'], 'web_link': 'https://opendev.org/openstack/aodh/commit/d53d9f9977b59696746c94b38ed25db41c56b24e', 'message': 'Fix gnocchi alarm query update issue\n\nAodh gnocchi alarm query should not be updated when the project condition\nhas already been appended.\n\nCloses-Bug: #1721452\n\nChange-Id: I96aaf025ccae8450589afbfdc8a3e654b1896b75\n'}]",9,511723,d53d9f9977b59696746c94b38ed25db41c56b24e,23,7,3,26721,,,0,"Fix gnocchi alarm query update issue

Aodh gnocchi alarm query should not be updated when the project condition
has already been appended.

Closes-Bug: #1721452

Change-Id: I96aaf025ccae8450589afbfdc8a3e654b1896b75
",git fetch https://review.opendev.org/openstack/aodh refs/changes/23/511723/1 && git format-patch -1 --stdout FETCH_HEAD,"['aodh/api/controllers/v2/alarm_rules/gnocchi.py', 'tox.ini']",2,215186cedc68f5aa7fc1847687c0b8931e0c37d9,bug/1721452,whitelist_externals = bash,,4,1
openstack%2Fpuppet-nova~stable%2Fussuri~I4fe8e0adcfbb0c3668d04917364ec0349324b75b,openstack/puppet-nova,stable/ussuri,I4fe8e0adcfbb0c3668d04917364ec0349324b75b,Add support for more image related options,MERGED,2020-11-03 12:51:46.000000000,2020-11-30 03:17:56.000000000,2020-11-30 03:16:50.000000000,"[{'_account_id': 9414}, {'_account_id': 14985}, {'_account_id': 22348}]","[{'number': 1, 'created': '2020-11-03 12:51:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-nova/commit/e985868a1810d6adce0458798dfed25d99b972ab', 'message': 'Add support for more image related options\n\nChange-Id: I4fe8e0adcfbb0c3668d04917364ec0349324b75b\n(cherry picked from commit 558624bfecadae273c8c61c874598eff5bb40927)\n'}, {'number': 2, 'created': '2020-11-11 11:15:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-nova/commit/8046028e68c5d25acb0dfab1801666c4d29d728b', 'message': 'Add support for more image related options\n\nChange-Id: I4fe8e0adcfbb0c3668d04917364ec0349324b75b\n(cherry picked from commit 558624bfecadae273c8c61c874598eff5bb40927)\n(cherry picked from commit a382ba55f8bd5e0b884e3990614a62df30905924)\n'}, {'number': 3, 'created': '2020-11-11 11:16:04.000000000', 'files': ['manifests/compute.pp', 'spec/classes/nova_compute_spec.rb', 'releasenotes/notes/add_more_image_related_options-37d640d3f76adbbd.yaml'], 'web_link': 'https://opendev.org/openstack/puppet-nova/commit/c69354254db6a205bee4e9fc511cc7402543f7b2', 'message': 'Add support for more image related options\n\nChange-Id: I4fe8e0adcfbb0c3668d04917364ec0349324b75b\n(cherry picked from commit 558624bfecadae273c8c61c874598eff5bb40927)\n(cherry picked from commit a382ba55f8bd5e0b884e3990614a62df30905924)\n'}]",0,761130,c69354254db6a205bee4e9fc511cc7402543f7b2,12,3,3,26721,,,0,"Add support for more image related options

Change-Id: I4fe8e0adcfbb0c3668d04917364ec0349324b75b
(cherry picked from commit 558624bfecadae273c8c61c874598eff5bb40927)
(cherry picked from commit a382ba55f8bd5e0b884e3990614a62df30905924)
",git fetch https://review.opendev.org/openstack/puppet-nova refs/changes/30/761130/2 && git format-patch -1 --stdout FETCH_HEAD,"['manifests/compute.pp', 'spec/classes/nova_compute_spec.rb', 'releasenotes/notes/add_more_image_related_options-37d640d3f76adbbd.yaml']",3,e985868a1810d6adce0458798dfed25d99b972ab,backport,--- features: - | The new ``nova::compute::use_cow_images`` parameter has been added to enable use of copy-on-write images. - | The new ``nova::compute::virt_mkfs`` parameter has been added to support to specify the mkfs commands for ephemeral devices. ,,28,4
openstack%2Ftrove~master~I953d82c72c0a009d81443433ce301a79150084cf,openstack/trove,master,I953d82c72c0a009d81443433ce301a79150084cf,Fix error when create multi replica,ABANDONED,2020-06-15 05:18:04.000000000,2020-11-30 03:10:57.000000000,,"[{'_account_id': 6732}, {'_account_id': 22348}, {'_account_id': 25254}, {'_account_id': 28182}]","[{'number': 1, 'created': '2020-06-15 05:18:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/trove/commit/9030726844ed9bc4ba4971144fd130e24bac0754', 'message': 'Fix error when create multi replica\n\nonly create user if not exists or drop user if exists\n\nChange-Id: I953d82c72c0a009d81443433ce301a79150084cf\nStory: #2007812\n'}, {'number': 2, 'created': '2020-06-15 06:14:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/trove/commit/61403b71db2eb6fc86735c5e980d1fb9849b4e81', 'message': 'Fix error when create multi replica\n\nonly create user if not exists or drop user if exists\n\nChange-Id: I953d82c72c0a009d81443433ce301a79150084cf\nStory: #2007812\n'}, {'number': 3, 'created': '2020-06-23 10:07:37.000000000', 'files': ['trove/guestagent/datastore/mysql_common/service.py', 'trove/guestagent/common/sql_query.py'], 'web_link': 'https://opendev.org/openstack/trove/commit/62c793c89825d0377ed7947c5bbd3475fd4fd40f', 'message': 'Fix error when create multi replica\n\nonly create user if not exists or drop user if exists\n\nChange-Id: I953d82c72c0a009d81443433ce301a79150084cf\nStory: #2007812\n'}]",2,735498,62c793c89825d0377ed7947c5bbd3475fd4fd40f,12,4,3,31662,,,0,"Fix error when create multi replica

only create user if not exists or drop user if exists

Change-Id: I953d82c72c0a009d81443433ce301a79150084cf
Story: #2007812
",git fetch https://review.opendev.org/openstack/trove refs/changes/98/735498/1 && git format-patch -1 --stdout FETCH_HEAD,"['trove/guestagent/datastore/mysql_common/service.py', 'trove/guestagent/common/sql_query.py']",2,9030726844ed9bc4ba4971144fd130e24bac0754,," query = [""CREATE USER IF NOT EXISTS :user@:host"", return ""DROP USER IF EXISTS `%s`@`%s`;"" % (self.user, self.host)"," query = [""CREATE USER :user@:host"", return ""DROP USER `%s`@`%s`;"" % (self.user, self.host)",11,6
openstack%2Fpuppet-nova~stable%2Fussuri~If64007fee7cac65c1e9c38919bb052c800e42830,openstack/puppet-nova,stable/ussuri,If64007fee7cac65c1e9c38919bb052c800e42830,Add support for more instance timeout options,MERGED,2020-11-03 12:51:46.000000000,2020-11-30 02:55:20.000000000,2020-11-30 02:53:16.000000000,"[{'_account_id': 9816}, {'_account_id': 14985}, {'_account_id': 22348}]","[{'number': 1, 'created': '2020-11-03 12:51:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-nova/commit/62271c333832bf5132664a39144fc5e4c035890e', 'message': 'Add support for more instance timeout options\n\nChange-Id: If64007fee7cac65c1e9c38919bb052c800e42830\n'}, {'number': 2, 'created': '2020-11-11 11:14:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-nova/commit/4dfd17a561b04f5941ff25712afdaab3bb2eb841', 'message': 'Add support for more instance timeout options\n\nChange-Id: If64007fee7cac65c1e9c38919bb052c800e42830\n(cherry picked from commit 2b19fa45a2c5f0a33a14aa38433f5f2d3e0ca559)\n(cherry picked from commit d52161f768b4414c872d642334624d4087a6f268)\n'}, {'number': 3, 'created': '2020-11-11 11:14:37.000000000', 'files': ['manifests/compute.pp', 'spec/classes/nova_compute_spec.rb', 'releasenotes/notes/add_more_instance_timeout_options-3f7f6f99a921ac71.yaml'], 'web_link': 'https://opendev.org/openstack/puppet-nova/commit/070a9bd9d82732e9d32d92dc4aa5b6de518149b9', 'message': 'Add support for more instance timeout options\n\nChange-Id: If64007fee7cac65c1e9c38919bb052c800e42830\n(cherry picked from commit 2b19fa45a2c5f0a33a14aa38433f5f2d3e0ca559)\n(cherry picked from commit d52161f768b4414c872d642334624d4087a6f268)\n'}]",0,761129,070a9bd9d82732e9d32d92dc4aa5b6de518149b9,12,3,3,26721,,,0,"Add support for more instance timeout options

Change-Id: If64007fee7cac65c1e9c38919bb052c800e42830
(cherry picked from commit 2b19fa45a2c5f0a33a14aa38433f5f2d3e0ca559)
(cherry picked from commit d52161f768b4414c872d642334624d4087a6f268)
",git fetch https://review.opendev.org/openstack/puppet-nova refs/changes/29/761129/2 && git format-patch -1 --stdout FETCH_HEAD,"['manifests/compute.pp', 'spec/classes/nova_compute_spec.rb', 'releasenotes/notes/add_more_instance_timeout_options-3f7f6f99a921ac71.yaml']",3,62271c333832bf5132664a39144fc5e4c035890e,backport,--- features: - | The new ``nova::compute::reboot_timeout`` parameter has been added to support to set a time interval after which an instance is hard rebooted automatically.- | - | The new ``nova::compute::instance_build_timeout`` parameter has been added to support to specify the maximum time for instance to build. - | The new ``nova::compute::rescue_timeout`` parameter has been added to support to set an interval to wait before un-rescuing an instance stuck in RESCUE. - | The new ``nova::compute::shutdown_timeout`` parameter has been added to support to set a time to wait in seconds for an instance to perform a clean shutdown. ,,63,3
openstack%2Fpuppet-nova~stable%2Fussuri~I6c98eeae70ba95dfdf5b06709b4b8ae0079c4dbd,openstack/puppet-nova,stable/ussuri,I6c98eeae70ba95dfdf5b06709b4b8ae0079c4dbd,Add support for running deleted instance related options,MERGED,2020-11-03 12:51:46.000000000,2020-11-30 02:54:24.000000000,2020-11-30 02:53:12.000000000,"[{'_account_id': 9816}, {'_account_id': 14985}, {'_account_id': 22348}]","[{'number': 1, 'created': '2020-11-03 12:51:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-nova/commit/8e7fc614be27a52482d4a1de4b044735ee8786b7', 'message': 'Add support for running deleted instance related options\n\nChange-Id: I6c98eeae70ba95dfdf5b06709b4b8ae0079c4dbd\n'}, {'number': 2, 'created': '2020-11-11 11:11:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-nova/commit/6045f46d1a0abd1712df55097a44f93317fb4299', 'message': 'Add support for running deleted instance related options\n\nChange-Id: I6c98eeae70ba95dfdf5b06709b4b8ae0079c4dbd\n(cherry picked from commit 86b572c895b4a77c134ad277aa7e42dcc609f086)\n(cherry picked from commit 4b3566ac2ab84dfc9f76107c778b5dcae09b8915)\n'}, {'number': 3, 'created': '2020-11-11 11:12:57.000000000', 'files': ['manifests/compute.pp', 'spec/classes/nova_compute_spec.rb', 'releasenotes/notes/add_running_deleted_instance_options-060792280c684273.yaml'], 'web_link': 'https://opendev.org/openstack/puppet-nova/commit/b0c285affff1ff01f0264e020ff6fe902780b964', 'message': 'Add support for running deleted instance related options\n\nChange-Id: I6c98eeae70ba95dfdf5b06709b4b8ae0079c4dbd\n(cherry picked from commit 86b572c895b4a77c134ad277aa7e42dcc609f086)\n(cherry picked from commit 4b3566ac2ab84dfc9f76107c778b5dcae09b8915)\n'}]",0,761128,b0c285affff1ff01f0264e020ff6fe902780b964,12,3,3,26721,,,0,"Add support for running deleted instance related options

Change-Id: I6c98eeae70ba95dfdf5b06709b4b8ae0079c4dbd
(cherry picked from commit 86b572c895b4a77c134ad277aa7e42dcc609f086)
(cherry picked from commit 4b3566ac2ab84dfc9f76107c778b5dcae09b8915)
",git fetch https://review.opendev.org/openstack/puppet-nova refs/changes/28/761128/2 && git format-patch -1 --stdout FETCH_HEAD,"['manifests/compute.pp', 'spec/classes/nova_compute_spec.rb', 'releasenotes/notes/add_running_deleted_instance_options-060792280c684273.yaml']",3,8e7fc614be27a52482d4a1de4b044735ee8786b7,backport,--- features: - | The new ``nova::compute::running_deleted_instance_action`` parameter has been added to support to select the action to be taken when a instance is identified as deleted. - | The new ``nova::compute::running_deleted_instance_poll_interval`` parameter has been added to support to set a time interval to wait between runs for the clean up action. - | The new ``nova::compute::running_deleted_instance_timeout`` parameter has been added to support to set a time interval to wait for the deleted instances cleanup. ,,46,0
openstack%2Fopenstack-ansible-os_magnum~master~Ice4664143eed522048a3b1daeb12717a17deeb67,openstack/openstack-ansible-os_magnum,master,Ice4664143eed522048a3b1daeb12717a17deeb67,Updated from OpenStack Ansible Tests,MERGED,2020-10-01 14:30:45.000000000,2020-11-30 02:26:16.000000000,2020-11-30 02:25:00.000000000,"[{'_account_id': 22348}, {'_account_id': 28619}]","[{'number': 1, 'created': '2020-10-01 14:30:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_magnum/commit/23338c14d76048c1a49e1d4629c1a0e9cd3cb2de', 'message': 'Updated from OpenStack Ansible Tests\n\nChange-Id: Ice4664143eed522048a3b1daeb12717a17deeb67\n'}, {'number': 2, 'created': '2020-10-19 09:20:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_magnum/commit/939d4684beadae9bdf7a019a587f8f47e7cb964b', 'message': 'Updated from OpenStack Ansible Tests\n\nChange-Id: Ice4664143eed522048a3b1daeb12717a17deeb67\n'}, {'number': 3, 'created': '2020-11-01 05:59:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_magnum/commit/9a9b1ed6e631ec9221ea0ff8fec32403753503b7', 'message': 'Updated from OpenStack Ansible Tests\n\nChange-Id: Ice4664143eed522048a3b1daeb12717a17deeb67\n'}, {'number': 4, 'created': '2020-11-29 22:05:25.000000000', 'files': ['tasks/db_setup.yml', 'tasks/service_setup.yml', 'tasks/mq_setup.yml'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_magnum/commit/af54ecc08b7e1e5464842dc6f263c3a721c0f8c4', 'message': 'Updated from OpenStack Ansible Tests\n\nChange-Id: Ice4664143eed522048a3b1daeb12717a17deeb67\n'}]",0,755537,af54ecc08b7e1e5464842dc6f263c3a721c0f8c4,14,2,4,11131,,,0,"Updated from OpenStack Ansible Tests

Change-Id: Ice4664143eed522048a3b1daeb12717a17deeb67
",git fetch https://review.opendev.org/openstack/openstack-ansible-os_magnum refs/changes/37/755537/4 && git format-patch -1 --stdout FETCH_HEAD,"['tasks/db_setup.yml', 'tasks/mq_setup.yml']",2,23338c14d76048c1a49e1d4629c1a0e9cd3cb2de,openstack/openstack-ansible-tests/sync-tests, community.rabbitmq.rabbitmq_vhost: community.rabbitmq.rabbitmq_policy: community.rabbitmq.rabbitmq_user: community.rabbitmq.rabbitmq_vhost: community.rabbitmq.rabbitmq_policy: community.rabbitmq.rabbitmq_user:, rabbitmq_vhost: rabbitmq_policy: rabbitmq_user: rabbitmq_vhost: rabbitmq_policy: rabbitmq_user:,8,8
openstack%2Fpuppet-openstack-integration~master~I23191893d9f69c87f81fa70ed6ae20c439cea432,openstack/puppet-openstack-integration,master,I23191893d9f69c87f81fa70ed6ae20c439cea432,Updated from Puppet OpenStack modules constraints,MERGED,2020-11-25 06:08:41.000000000,2020-11-30 01:52:59.000000000,2020-11-30 01:52:59.000000000,"[{'_account_id': 9816}, {'_account_id': 16137}, {'_account_id': 22348}]","[{'number': 1, 'created': '2020-11-25 06:08:41.000000000', 'files': ['Puppetfile'], 'web_link': 'https://opendev.org/openstack/puppet-openstack-integration/commit/eff8f352b9a57ec039580415567d3a4eaf919512', 'message': 'Updated from Puppet OpenStack modules constraints\n\nChange-Id: I23191893d9f69c87f81fa70ed6ae20c439cea432\n'}]",0,764121,eff8f352b9a57ec039580415567d3a4eaf919512,7,3,1,11131,,,0,"Updated from Puppet OpenStack modules constraints

Change-Id: I23191893d9f69c87f81fa70ed6ae20c439cea432
",git fetch https://review.opendev.org/openstack/puppet-openstack-integration refs/changes/21/764121/1 && git format-patch -1 --stdout FETCH_HEAD,['Puppetfile'],1,eff8f352b9a57ec039580415567d3a4eaf919512,openstack/puppet/constraints, :ref => 'v5.7.0', :ref => 'v5.6.0',1,1
openstack%2Ffreezer~master~I47416c166d07104ddf647cbbdb17525614311673,openstack/freezer,master,I47416c166d07104ddf647cbbdb17525614311673,Dep's should be restricted by upper-constraints,MERGED,2020-11-20 06:43:10.000000000,2020-11-30 01:51:04.000000000,2020-11-30 01:48:02.000000000,"[{'_account_id': 21069}, {'_account_id': 22348}]","[{'number': 1, 'created': '2020-11-20 06:43:10.000000000', 'files': ['tox.ini'], 'web_link': 'https://opendev.org/openstack/freezer/commit/de4175d546c44bde184a6ad9e7a36754c825260d', 'message': ""Dep's should be restricted by upper-constraints\n\nTox trying to install latest versions for building docs which may\nnot be supported by stable and lower branches, so should be\nrestricted by respective version's upper-constraints.txt\n\nChange-Id: I47416c166d07104ddf647cbbdb17525614311673\n""}]",0,763505,de4175d546c44bde184a6ad9e7a36754c825260d,8,2,1,32291,,,0,"Dep's should be restricted by upper-constraints

Tox trying to install latest versions for building docs which may
not be supported by stable and lower branches, so should be
restricted by respective version's upper-constraints.txt

Change-Id: I47416c166d07104ddf647cbbdb17525614311673
",git fetch https://review.opendev.org/openstack/freezer refs/changes/05/763505/1 && git format-patch -1 --stdout FETCH_HEAD,['tox.ini'],1,de4175d546c44bde184a6ad9e7a36754c825260d,,deps = -c{env:UPPER_CONSTRAINTS_FILE:https://releases.openstack.org/constraints/upper/master} -r{toxinidir}/doc/requirements.txtdeps = -c{env:UPPER_CONSTRAINTS_FILE:https://releases.openstack.org/constraints/upper/master} -r{toxinidir}/doc/requirements.txt,deps = -r{toxinidir}/doc/requirements.txtdeps = -r{toxinidir}/doc/requirements.txt,6,2
openstack%2Ftrove~master~I930a1468fec5922916af0819698fceb94bddb2f3,openstack/trove,master,I930a1468fec5922916af0819698fceb94bddb2f3,Use nested virt node for trove functional test,MERGED,2020-11-22 10:05:05.000000000,2020-11-30 01:50:59.000000000,2020-11-30 01:47:58.000000000,"[{'_account_id': 6732}, {'_account_id': 22348}]","[{'number': 1, 'created': '2020-11-22 10:05:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/trove/commit/0f0d5cf387e709a3f448cbd0c038f2d486b55083', 'message': '[WIP] Use nested virt node for trove functional test\n\nChange-Id: I930a1468fec5922916af0819698fceb94bddb2f3\n'}, {'number': 2, 'created': '2020-11-23 00:36:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/trove/commit/5b5ef5950ce4357421fb42e556701639ede88aca', 'message': 'Use nested virt node for trove functional test\n\nEnable the job trove-functional-mysql \n\nChange-Id: I930a1468fec5922916af0819698fceb94bddb2f3\n'}, {'number': 3, 'created': '2020-11-25 04:58:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/trove/commit/5c17320ac92c7be554abb251ad364ed8b3e0daad', 'message': 'Use nested virt node for trove functional test\n\nEnable the job trove-functional-mysql \n\nChange-Id: I930a1468fec5922916af0819698fceb94bddb2f3\n'}, {'number': 4, 'created': '2020-11-26 00:12:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/trove/commit/4d05f3e339c03dbb28a3bdd93c68f73fd7b30f31', 'message': 'Use nested virt node for trove functional test\n\nEnable the job trove-functional-mysql\n\nDepends-On: https://review.opendev.org/c/openstack/trove/+/764073\nChange-Id: I930a1468fec5922916af0819698fceb94bddb2f3\n'}, {'number': 5, 'created': '2020-11-29 08:40:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/trove/commit/97e5294a17b1b5719a0430bf5340ee5cd2f66cd4', 'message': 'Use nested virt node for trove functional test\n\nEnable the job trove-functional-mysql\n\nDepends-On: https://review.opendev.org/c/openstack/trove/+/764073\nChange-Id: I930a1468fec5922916af0819698fceb94bddb2f3\n'}, {'number': 6, 'created': '2020-11-29 08:41:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/trove/commit/155eb99311f88b6bbd5222288ddb36ba0156cf07', 'message': 'Use nested virt node for trove functional test\n\nEnable the job trove-functional-mysql\n\nChange-Id: I930a1468fec5922916af0819698fceb94bddb2f3\n'}, {'number': 7, 'created': '2020-11-29 20:47:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/trove/commit/54c7b43582f637073678f1b61174c201203258d5', 'message': 'Use nested virt node for trove functional test\n\nEnable the job trove-functional-mysql\n\nDepends-On: https://review.opendev.org/c/openstack/trove/+/764073\nChange-Id: I930a1468fec5922916af0819698fceb94bddb2f3\n'}, {'number': 8, 'created': '2020-11-29 20:48:53.000000000', 'files': ['.zuul.yaml', 'devstack/plugin.sh'], 'web_link': 'https://opendev.org/openstack/trove/commit/cc57e32c48f4a2acc3b0c57e50573cda3ce5ac98', 'message': 'Use nested virt node for trove functional test\n\nEnable the jobs trove-functional-mysql and trove-tempest.\n\nChange-Id: I930a1468fec5922916af0819698fceb94bddb2f3\n'}]",0,763630,cc57e32c48f4a2acc3b0c57e50573cda3ce5ac98,36,2,8,6732,,,0,"Use nested virt node for trove functional test

Enable the jobs trove-functional-mysql and trove-tempest.

Change-Id: I930a1468fec5922916af0819698fceb94bddb2f3
",git fetch https://review.opendev.org/openstack/trove refs/changes/30/763630/2 && git format-patch -1 --stdout FETCH_HEAD,['.zuul.yaml'],1,0f0d5cf387e709a3f448cbd0c038f2d486b55083,nested-ci,- nodeset: name: trove-ubuntu-bionic nodes: - name: controller label: nested-virt-ubuntu-bionic groups: - name: controller nodes: - controller - trove-functional-mysql: voting: false nodeset: trove-ubuntu-bionic,,13,0
openstack%2Ftripleo-heat-templates~stable%2Fussuri~I75a59f3d4b640f3146f2a865eff8be3f1383e078,openstack/tripleo-heat-templates,stable/ussuri,I75a59f3d4b640f3146f2a865eff8be3f1383e078,Move enable ksm on compute node to deploy step 1,MERGED,2020-11-14 15:44:10.000000000,2020-11-30 00:51:31.000000000,2020-11-30 00:50:12.000000000,"[{'_account_id': 6681}, {'_account_id': 7353}, {'_account_id': 14985}, {'_account_id': 17216}, {'_account_id': 20172}, {'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2020-11-14 15:44:10.000000000', 'files': ['releasenotes/notes/nova_compute_ksm-444f1cc51ceafb66.yaml', 'deployment/nova/nova-compute-container-puppet.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/3653973235606c17940792e50fa1b64c2b65d165', 'message': 'Move enable ksm on compute node to deploy step 1\n\nWhen using RHSM Service (deployment/rhsm/rhsm-baremetal-ansible.yaml) based\nregistration of the overcloud nodes and enabling the KSM using\nNovaComputeEnableKsm=True the overcloud deployment will fail because the\nRHSM registration and the ksm task run as host_prep task. The handling\nof enable/disable ksm is now handled in deploy step 1.\n\nCloses-Bug: #1904184\n\nChange-Id: I75a59f3d4b640f3146f2a865eff8be3f1383e078\n(cherry picked from commit c329204dece419afb3c1615b4f6ffef6581b50cd)\n'}]",0,762735,3653973235606c17940792e50fa1b64c2b65d165,39,7,1,20172,,,0,"Move enable ksm on compute node to deploy step 1

When using RHSM Service (deployment/rhsm/rhsm-baremetal-ansible.yaml) based
registration of the overcloud nodes and enabling the KSM using
NovaComputeEnableKsm=True the overcloud deployment will fail because the
RHSM registration and the ksm task run as host_prep task. The handling
of enable/disable ksm is now handled in deploy step 1.

Closes-Bug: #1904184

Change-Id: I75a59f3d4b640f3146f2a865eff8be3f1383e078
(cherry picked from commit c329204dece419afb3c1615b4f6ffef6581b50cd)
",git fetch https://review.opendev.org/openstack/tripleo-heat-templates refs/changes/35/762735/1 && git format-patch -1 --stdout FETCH_HEAD,"['releasenotes/notes/nova_compute_ksm-444f1cc51ceafb66.yaml', 'deployment/nova/nova-compute-container-puppet.yaml']",2,3653973235606c17940792e50fa1b64c2b65d165,1895894-stable/victoria-stable/ussuri," - name: Is irqbalance enabled set_fact: compute_irqbalance_disabled: {get_attr: [RoleParametersValue, value, compute_disable_irqbalance]} - name: disable irqbalance service on compute when: compute_irqbalance_disabled|bool service: name: irqbalance.service state: stopped enabled: no deploy_steps_tasks: - name: validate nova-compute container state podman_container_info: name: nova_compute register: nova_compute_infos failed_when: - nova_compute_infos.containers.0.Healthcheck.Status is defined - ""'healthy' not in nova_compute_infos.containers.0.Healthcheck.Status"" retries: 10 delay: 30 tags: - opendev-validation - opendev-validation-nova when: - container_cli == 'podman' - not container_healthcheck_disabled - step|int == 6 #FIXME: there is no step6 - name: manage PMEM namespaces for vPMEM include_role: name: tripleo_nvdimm vars: tripleo_nvdimm_pmem_namespaces: {get_attr: [RoleParametersValue, value, nova_pmem_namespaces]} when: - step|int == 1 - tripleo_nvdimm_pmem_namespaces != '' - name: enable/disable ksm when: - step|int == 1 block:"," - name: Is irqbalance enabled set_fact: compute_irqbalance_disabled: {get_attr: [RoleParametersValue, value, compute_disable_irqbalance]} - name: disable irqbalance service on compute when: compute_irqbalance_disabled|bool service: name: irqbalance.service state: stopped enabled: no deploy_steps_tasks: - name: validate nova-compute container state podman_container_info: name: nova_compute register: nova_compute_infos failed_when: - nova_compute_infos.containers.0.Healthcheck.Status is defined - ""'healthy' not in nova_compute_infos.containers.0.Healthcheck.Status"" retries: 10 delay: 30 tags: - opendev-validation - opendev-validation-nova when: - container_cli == 'podman' - not container_healthcheck_disabled - step|int == 6 #FIXME: there is no step6 - name: manage PMEM namespaces for vPMEM include_role: name: tripleo_nvdimm vars: tripleo_nvdimm_pmem_namespaces: {get_attr: [RoleParametersValue, value, nova_pmem_namespaces]} when: - step|int == 1 - tripleo_nvdimm_pmem_namespaces != ''",46,34
openstack%2Fdevstack~master~I4fe0b468ffae77ad7ba79699586048da6b7f0afa,openstack/devstack,master,I4fe0b468ffae77ad7ba79699586048da6b7f0afa,Ensure permissions on NOVA_INSTANCES_PATH,ABANDONED,2020-09-09 09:00:22.000000000,2020-11-29 22:27:57.000000000,,"[{'_account_id': 13252}, {'_account_id': 22348}, {'_account_id': 27329}, {'_account_id': 29963}]","[{'number': 1, 'created': '2020-09-09 09:00:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack/commit/100036a2ac81a2a1dd655518dbbdff0a828db839', 'message': 'Ensure permissions on NOVA_INSTANCES_PATH\n\nThis workaround a permission problem when performing cold\nmigration.\n\nChange-Id: I4fe0b468ffae77ad7ba79699586048da6b7f0afa\n'}, {'number': 2, 'created': '2020-09-10 05:58:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack/commit/9fe0cacb8f1129dee2188673cd1bd4a84ea8dbd0', 'message': 'Ensure permissions on NOVA_INSTANCES_PATH\n\nThis workaround a permission problem when performing cold\nmigration.\n\nChange-Id: I4fe0b468ffae77ad7ba79699586048da6b7f0afa\n'}, {'number': 3, 'created': '2020-09-16 07:07:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack/commit/6131b3649d5769cfb9b3e1ead8adb70b3c1ef1ba', 'message': 'Ensure permissions on NOVA_INSTANCES_PATH\n\nThis workaround a permission problem when performing cold\nmigration.\n\nChange-Id: I4fe0b468ffae77ad7ba79699586048da6b7f0afa\n'}, {'number': 4, 'created': '2020-09-22 12:52:59.000000000', 'files': ['lib/nova'], 'web_link': 'https://opendev.org/openstack/devstack/commit/453b12fd9da7037340b49b1849ccb14328659aa1', 'message': 'Ensure permissions on NOVA_INSTANCES_PATH\n\nThis workaround a permission problem when performing cold\nmigration.\n\nChange-Id: I4fe0b468ffae77ad7ba79699586048da6b7f0afa\n'}]",0,750601,453b12fd9da7037340b49b1849ccb14328659aa1,17,4,4,27329,,,0,"Ensure permissions on NOVA_INSTANCES_PATH

This workaround a permission problem when performing cold
migration.

Change-Id: I4fe0b468ffae77ad7ba79699586048da6b7f0afa
",git fetch https://review.opendev.org/openstack/devstack refs/changes/01/750601/3 && git format-patch -1 --stdout FETCH_HEAD,['lib/nova'],1,100036a2ac81a2a1dd655518dbbdff0a828db839,fix-nova-migrate, sudo install -d -o $STACK_USER -m 0755 $NOVA_INSTANCES_PATH, sudo install -d -o $STACK_USER $NOVA_INSTANCES_PATH,1,1
openstack%2Fcinder~master~Ic3f02a1a2478f106e008d0d868c66ebed1566c08,openstack/cinder,master,Ic3f02a1a2478f106e008d0d868c66ebed1566c08,Imported Translations from Zanata,MERGED,2020-11-27 06:16:28.000000000,2020-11-29 19:15:04.000000000,2020-11-27 13:28:06.000000000,"[{'_account_id': 11904}, {'_account_id': 22348}]","[{'number': 1, 'created': '2020-11-27 06:16:28.000000000', 'files': ['releasenotes/source/locale/en_GB/LC_MESSAGES/releasenotes.po'], 'web_link': 'https://opendev.org/openstack/cinder/commit/c0983a8e82a5df085d901d1a659a240adc600d29', 'message': 'Imported Translations from Zanata\n\nFor more information about this automatic import see:\nhttps://docs.openstack.org/i18n/latest/reviewing-translation-import.html\n\nChange-Id: Ic3f02a1a2478f106e008d0d868c66ebed1566c08\n'}]",0,764410,c0983a8e82a5df085d901d1a659a240adc600d29,17,2,1,11131,,,0,"Imported Translations from Zanata

For more information about this automatic import see:
https://docs.openstack.org/i18n/latest/reviewing-translation-import.html

Change-Id: Ic3f02a1a2478f106e008d0d868c66ebed1566c08
",git fetch https://review.opendev.org/openstack/cinder refs/changes/10/764410/1 && git format-patch -1 --stdout FETCH_HEAD,['releasenotes/source/locale/en_GB/LC_MESSAGES/releasenotes.po'],1,c0983a8e82a5df085d901d1a659a240adc600d29,zanata/translations,"""POT-Creation-Date: 2020-11-25 17:34+0000\n""""PO-Revision-Date: 2020-11-26 11:01+0000\n""msgid ""**Supported Ceph versions**"" msgstr ""**Supported Ceph versions**"" msgid ""15.4.0-10"" msgstr ""15.4.0-10""msgid ""16.2.0-8"" msgstr ""16.2.0-8""msgid ""17.0.0.0rc1-76"" msgstr ""17.0.0.0rc1-76""""For a given OpenStack release, Cinder supports the current Ceph active "" ""stable releases plus the two prior releases."" msgstr """" ""For a given OpenStack release, Cinder supports the current Ceph active "" ""stable releases plus the two prior releases."" msgid """" ""For any OpenStack release, it is expected that the versions of the Ceph "" ""client and server are in alignment."" msgstr """" ""For any OpenStack release, it is expected that the versions of the Ceph "" ""client and server are in alignment."" msgid """"""RBD driver: Prior to this release, the Cinder project did not have a "" ""statement concerning what versions of Ceph are supported by Cinder. We "" ""hereby announce that:"" msgstr """" ""RBD driver: Prior to this release, the Cinder project did not have a "" ""statement concerning what versions of Ceph are supported by Cinder. We "" ""hereby announce that:"" msgid """"""The Cinder project wishes to clarify its policy concerning what versions of "" ""Ceph are supported by Cinder."" msgstr """" ""The Cinder project wishes to clarify its policy concerning what versions of "" ""Ceph are supported by Cinder."" msgid """"""The `Ceph RADOS Block Device (RBD) <https://docs.openstack.org/cinder/latest/"" ""configuration/block-storage/drivers/ceph-rbd-volume-driver.html>`__ driver "" ""documentation has been updated to reflect this policy and explains it in "" ""more detail."" msgstr """" ""The `Ceph RADOS Block Device (RBD) <https://docs.openstack.org/cinder/latest/"" ""configuration/block-storage/drivers/ceph-rbd-volume-driver.html>`__ driver "" ""documentation has been updated to reflect this policy and explains it in "" ""more detail."" msgid """"","""POT-Creation-Date: 2020-11-17 23:52+0000\n""""PO-Revision-Date: 2020-11-24 02:39+0000\n""msgid ""15.4.0-8"" msgstr ""15.4.0-8""msgid ""16.2.0-7"" msgstr ""16.2.0-7""msgid ""17.0.0.0rc1-74"" msgstr ""17.0.0.0rc1-74""",52,8
openstack%2Ftripleo-heat-templates~stable%2Fussuri~Ida039c3e0f4c73c8f666f730f290bf18c24f92ed,openstack/tripleo-heat-templates,stable/ussuri,Ida039c3e0f4c73c8f666f730f290bf18c24f92ed,Switch novajoin to use RpcUserName,MERGED,2020-11-25 08:19:21.000000000,2020-11-29 18:08:51.000000000,2020-11-29 18:08:51.000000000,"[{'_account_id': 6926}, {'_account_id': 20172}, {'_account_id': 20778}, {'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2020-11-25 08:19:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/7103eae91b557b2e7200843d425f5f7033a79479', 'message': 'Switch novajoin to use RpcUserName\n\nIn queens with instack-undercloud we used to generate a random\nrabbitmq user. During a UC upgrade this gets migrated to the RpcUserName\nenv variable. But since novajoin uses RabbitUserName it will default\nto guest during an upgrade and will fail to connect to rabbitmq:\n2020-11-24 20:01:31.569 7 ERROR join     method_sig, payload, content,\n2020-11-24 20:01:31.569 7 ERROR join   File\n""/usr/lib/python3.6/site-packages/amqp/abstract_channel.py"", line 126,\nin dispatch_method\n2020-11-24 20:01:31.569 7 ERROR join     listener(*args)\n2020-11-24 20:01:31.569 7 ERROR join   File\n""/usr/lib/python3.6/site-packages/amqp/connection.py"", line 639, in\n_on_close\n2020-11-24 20:01:31.569 7 ERROR join     (class_id, method_id),\nConnectionError)\n2020-11-24 20:01:31.569 7 ERROR join amqp.exceptions.AccessRefused: (0,\n0): (403) ACCESS_REFUSED - Login was refused using authentication\n  mechanism AMQPLAIN. For detail s see the broker logfile.\n\nServer side wo;; gives us:\n2020-11-24 20:12:31.426 [error] <0.5096.1> Error on AMQP connection\n<0.5096.1> (192.168.24.1:57254 -> 192.168.24.1:5672, state: starting):\nAMQPLAIN login refused: user \'guest\' - invalid credentials\nDuring a queens->train FF\n\nLet\'s just switch to use RpcUserName and make this more consistent.\nThis is fine, as both RabbitUserName and RpcUserName default to \'guest\'\nand changing one but not the other is not really feasible in a\ndeployment.\n\nTested and a full FFU with TLS-E correctly works now.\n\nCloses-Bug: #1905526\n\nChange-Id: Ida039c3e0f4c73c8f666f730f290bf18c24f92ed\n'}, {'number': 2, 'created': '2020-11-27 11:45:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/eefda54d193fb8a4e213f4bfb4021d41704e0088', 'message': 'Switch novajoin to use RpcUserName\n\nIn queens with instack-undercloud we used to generate a random\nrabbitmq user. During a UC upgrade this gets migrated to the RpcUserName\nenv variable. But since novajoin uses RabbitUserName it will default\nto guest during an upgrade and will fail to connect to rabbitmq:\n2020-11-24 20:01:31.569 7 ERROR join     method_sig, payload, content,\n2020-11-24 20:01:31.569 7 ERROR join   File\n""/usr/lib/python3.6/site-packages/amqp/abstract_channel.py"", line 126,\nin dispatch_method\n2020-11-24 20:01:31.569 7 ERROR join     listener(*args)\n2020-11-24 20:01:31.569 7 ERROR join   File\n""/usr/lib/python3.6/site-packages/amqp/connection.py"", line 639, in\n_on_close\n2020-11-24 20:01:31.569 7 ERROR join     (class_id, method_id),\nConnectionError)\n2020-11-24 20:01:31.569 7 ERROR join amqp.exceptions.AccessRefused: (0,\n0): (403) ACCESS_REFUSED - Login was refused using authentication\n  mechanism AMQPLAIN. For detail s see the broker logfile.\n\nServer side wo;; gives us:\n2020-11-24 20:12:31.426 [error] <0.5096.1> Error on AMQP connection\n<0.5096.1> (192.168.24.1:57254 -> 192.168.24.1:5672, state: starting):\nAMQPLAIN login refused: user \'guest\' - invalid credentials\nDuring a queens->train FF\n\nLet\'s just switch to use RpcUserName and make this more consistent.\nThis is fine, as both RabbitUserName and RpcUserName default to \'guest\'\nand changing one but not the other is not really feasible in a\ndeployment.\n\nTested and a full FFU with TLS-E correctly works now.\n\nCloses-Bug: #1905526\n\nChange-Id: Ida039c3e0f4c73c8f666f730f290bf18c24f92ed\n'}, {'number': 3, 'created': '2020-11-29 08:49:18.000000000', 'files': ['deployment/nova/novajoin-container-puppet.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/47d31250e80fd0c76f0dc600313ad5f8792d90e7', 'message': 'Switch novajoin to use RpcUserName\n\nIn queens with instack-undercloud we used to generate a random\nrabbitmq user. During a UC upgrade this gets migrated to the RpcUserName\nenv variable. But since novajoin uses RabbitUserName it will default\nto guest during an upgrade and will fail to connect to rabbitmq:\n2020-11-24 20:01:31.569 7 ERROR join     method_sig, payload, content,\n2020-11-24 20:01:31.569 7 ERROR join   File\n""/usr/lib/python3.6/site-packages/amqp/abstract_channel.py"", line 126,\nin dispatch_method\n2020-11-24 20:01:31.569 7 ERROR join     listener(*args)\n2020-11-24 20:01:31.569 7 ERROR join   File\n""/usr/lib/python3.6/site-packages/amqp/connection.py"", line 639, in\n_on_close\n2020-11-24 20:01:31.569 7 ERROR join     (class_id, method_id),\nConnectionError)\n2020-11-24 20:01:31.569 7 ERROR join amqp.exceptions.AccessRefused: (0,\n0): (403) ACCESS_REFUSED - Login was refused using authentication\n  mechanism AMQPLAIN. For detail s see the broker logfile.\n\nServer side wo;; gives us:\n2020-11-24 20:12:31.426 [error] <0.5096.1> Error on AMQP connection\n<0.5096.1> (192.168.24.1:57254 -> 192.168.24.1:5672, state: starting):\nAMQPLAIN login refused: user \'guest\' - invalid credentials\nDuring a queens->train FF\n\nLet\'s just switch to use RpcUserName and make this more consistent.\nThis is fine, as both RabbitUserName and RpcUserName default to \'guest\'\nand changing one but not the other is not really feasible in a\ndeployment.\n\nTested and a full FFU with TLS-E correctly works now.\n\nCloses-Bug: #1905526\n\nChange-Id: Ida039c3e0f4c73c8f666f730f290bf18c24f92ed\n'}]",0,764084,47d31250e80fd0c76f0dc600313ad5f8792d90e7,23,5,3,20172,,,0,"Switch novajoin to use RpcUserName

In queens with instack-undercloud we used to generate a random
rabbitmq user. During a UC upgrade this gets migrated to the RpcUserName
env variable. But since novajoin uses RabbitUserName it will default
to guest during an upgrade and will fail to connect to rabbitmq:
2020-11-24 20:01:31.569 7 ERROR join     method_sig, payload, content,
2020-11-24 20:01:31.569 7 ERROR join   File
""/usr/lib/python3.6/site-packages/amqp/abstract_channel.py"", line 126,
in dispatch_method
2020-11-24 20:01:31.569 7 ERROR join     listener(*args)
2020-11-24 20:01:31.569 7 ERROR join   File
""/usr/lib/python3.6/site-packages/amqp/connection.py"", line 639, in
_on_close
2020-11-24 20:01:31.569 7 ERROR join     (class_id, method_id),
ConnectionError)
2020-11-24 20:01:31.569 7 ERROR join amqp.exceptions.AccessRefused: (0,
0): (403) ACCESS_REFUSED - Login was refused using authentication
  mechanism AMQPLAIN. For detail s see the broker logfile.

Server side wo;; gives us:
2020-11-24 20:12:31.426 [error] <0.5096.1> Error on AMQP connection
<0.5096.1> (192.168.24.1:57254 -> 192.168.24.1:5672, state: starting):
AMQPLAIN login refused: user 'guest' - invalid credentials
During a queens->train FF

Let's just switch to use RpcUserName and make this more consistent.
This is fine, as both RabbitUserName and RpcUserName default to 'guest'
and changing one but not the other is not really feasible in a
deployment.

Tested and a full FFU with TLS-E correctly works now.

Closes-Bug: #1905526

Change-Id: Ida039c3e0f4c73c8f666f730f290bf18c24f92ed
",git fetch https://review.opendev.org/openstack/tripleo-heat-templates refs/changes/84/764084/3 && git format-patch -1 --stdout FETCH_HEAD,['deployment/nova/novajoin-container-puppet.yaml'],1,7103eae91b557b2e7200843d425f5f7033a79479,fix-ffu-stable/ussuri, RpcUserName: tripleo::profile::base::novajoin::oslomsg_rpc_username: {get_param: RpcUserName}, RabbitUserName: tripleo::profile::base::novajoin::oslomsg_rpc_username: {get_param: RabbitUserName},2,2
openstack%2Fcinder~master~If5df3c3b34936911a1053f86fba6fad2a922dec4,openstack/cinder,master,If5df3c3b34936911a1053f86fba6fad2a922dec4,[IBM DS8000] Support volume name template,MERGED,2020-10-29 14:47:47.000000000,2020-11-29 17:00:48.000000000,2020-11-29 16:58:59.000000000,"[{'_account_id': 1736}, {'_account_id': 5997}, {'_account_id': 9008}, {'_account_id': 10118}, {'_account_id': 12016}, {'_account_id': 12017}, {'_account_id': 12032}, {'_account_id': 12033}, {'_account_id': 12369}, {'_account_id': 12540}, {'_account_id': 15386}, {'_account_id': 18883}, {'_account_id': 22248}, {'_account_id': 22348}, {'_account_id': 22510}, {'_account_id': 23613}, {'_account_id': 24814}, {'_account_id': 24815}, {'_account_id': 24921}, {'_account_id': 25243}, {'_account_id': 26077}, {'_account_id': 26537}, {'_account_id': 28801}, {'_account_id': 30688}, {'_account_id': 31868}, {'_account_id': 32036}, {'_account_id': 32159}]","[{'number': 1, 'created': '2020-10-29 14:47:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/b697187aced4393d037264483301ceed77752a7e', 'message': '[IBM DS8000] Support volume name template\n\nPrevious cinder driver use display name as volume name in the backend.\nNow DS8000 cinder driver will use name based on volume_name_template.\n\nChange-Id: If5df3c3b34936911a1053f86fba6fad2a922dec4\nCloses-bug: #1884030\n'}, {'number': 2, 'created': '2020-11-12 11:28:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/0d4be3f92d7bc9578585eb360ff9e1f752ffc825', 'message': '[IBM DS8000] Support volume name template\n\nPrevious cinder driver use display name as volume name in the backend.\nNow DS8000 cinder driver will use name based on volume_name_template.\n\nChange-Id: If5df3c3b34936911a1053f86fba6fad2a922dec4\nCloses-bug: #1884030\n'}, {'number': 3, 'created': '2020-11-16 19:05:02.000000000', 'files': ['cinder/volume/drivers/ibm/ibm_storage/ds8k_proxy.py', 'releasenotes/notes/bug-1884030-ds8k_support_volume_name_template-91e1b70ece172ef8.yaml', 'cinder/tests/unit/volume/drivers/ibm/test_ds8k_proxy.py'], 'web_link': 'https://opendev.org/openstack/cinder/commit/a791d3032ce8681e86e8d2f5877687ae538badbc', 'message': '[IBM DS8000] Support volume name template\n\nPrevious cinder driver use display name as volume name in the backend.\nNow DS8000 cinder driver will use name based on volume_name_template.\n\nChange-Id: If5df3c3b34936911a1053f86fba6fad2a922dec4\nCloses-bug: #1884030\n'}]",7,760374,a791d3032ce8681e86e8d2f5877687ae538badbc,78,27,3,32074,,,0,"[IBM DS8000] Support volume name template

Previous cinder driver use display name as volume name in the backend.
Now DS8000 cinder driver will use name based on volume_name_template.

Change-Id: If5df3c3b34936911a1053f86fba6fad2a922dec4
Closes-bug: #1884030
",git fetch https://review.opendev.org/openstack/cinder refs/changes/74/760374/3 && git format-patch -1 --stdout FETCH_HEAD,"['cinder/volume/drivers/ibm/ibm_storage/ds8k_proxy.py', 'releasenotes/notes/bug-1884030-ds8k_support_volume_name_template-91e1b70ece172ef8.yaml', 'cinder/tests/unit/volume/drivers/ibm/test_ds8k_proxy.py']",3,b697187aced4393d037264483301ceed77752a7e,bug/1884030," @mock.patch('cinder.volume.volume_utils.CONF') def test_create_volume_with_template(self, mock_conf): self.driver = FakeDS8KProxy(self.storage_info, self.logger, self.exception, self) self.driver.setup(self.ctxt) mock_conf.volume_name_template = 'volume-%s' vol_id = 'd403b4d9-473a-42d0-94c5-be45a1268928' vol_name = mock_conf.volume_name_template % vol_id volume = self._create_volume(id=vol_id) lun = ds8kproxy.Lun(volume) exp_vol_name = helper.filter_alnum(vol_name)[:16] self.assertEqual(lun.ds_name, exp_vol_name)",,22,10
openstack%2Fcinder~master~I704b3c41611c4778443256a0533e0522056985a4,openstack/cinder,master,I704b3c41611c4778443256a0533e0522056985a4,Add links to package metadata,MERGED,2020-06-23 12:15:24.000000000,2020-11-29 16:53:34.000000000,2020-11-29 16:50:42.000000000,"[{'_account_id': 1736}, {'_account_id': 5997}, {'_account_id': 9008}, {'_account_id': 11611}, {'_account_id': 12017}, {'_account_id': 12032}, {'_account_id': 12033}, {'_account_id': 12369}, {'_account_id': 14384}, {'_account_id': 15386}, {'_account_id': 15941}, {'_account_id': 21863}, {'_account_id': 21884}, {'_account_id': 22348}, {'_account_id': 22510}, {'_account_id': 23613}, {'_account_id': 24921}, {'_account_id': 25243}, {'_account_id': 26077}, {'_account_id': 26537}, {'_account_id': 28522}, {'_account_id': 28801}, {'_account_id': 29705}, {'_account_id': 30615}]","[{'number': 1, 'created': '2020-06-23 12:15:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/f17c22e934654316aab2ca5dd6b29647ae903db9', 'message': 'Add links to package metadata\n\nThis adds the Source and Tracker links to our package metadata so that\nthe links show up on the PyPi page for this package.\n\nhttps://pypi.org/project/cinder/\n\nChange-Id: I704b3c41611c4778443256a0533e0522056985a4\nSigned-off-by: Sean McGinnis <sean.mcginnis@gmail.com>\n'}, {'number': 2, 'created': '2020-06-23 12:55:58.000000000', 'files': ['setup.cfg'], 'web_link': 'https://opendev.org/openstack/cinder/commit/90be2b4251999f46b2657917e2ed56f1aed17d04', 'message': 'Add links to package metadata\n\nThis adds the Source and Tracker links to our package metadata so that\nthe links show up on the PyPi page for this package.\n\nhttps://pypi.org/project/cinder/\n\nChange-Id: I704b3c41611c4778443256a0533e0522056985a4\nSigned-off-by: Sean McGinnis <sean.mcginnis@gmail.com>\n'}]",0,737510,90be2b4251999f46b2657917e2ed56f1aed17d04,40,24,2,11904,,,0,"Add links to package metadata

This adds the Source and Tracker links to our package metadata so that
the links show up on the PyPi page for this package.

https://pypi.org/project/cinder/

Change-Id: I704b3c41611c4778443256a0533e0522056985a4
Signed-off-by: Sean McGinnis <sean.mcginnis@gmail.com>
",git fetch https://review.opendev.org/openstack/cinder refs/changes/10/737510/1 && git format-patch -1 --stdout FETCH_HEAD,['setup.cfg'],1,f17c22e934654316aab2ca5dd6b29647ae903db9,pypi-links,project_utls: Source=https://opendev.org/openstack/cinder Tracker=https://bugs.launchpad.net/cinder,,3,0
openstack%2Fcinder~master~Ia135b2057118960bb9a395297efaadd0e7ba2720,openstack/cinder,master,Ia135b2057118960bb9a395297efaadd0e7ba2720,Race in Cinder backup manager,MERGED,2020-07-16 20:50:21.000000000,2020-11-29 16:52:17.000000000,2020-11-29 16:50:16.000000000,"[{'_account_id': 5997}, {'_account_id': 9008}, {'_account_id': 9732}, {'_account_id': 10118}, {'_account_id': 11611}, {'_account_id': 11904}, {'_account_id': 12016}, {'_account_id': 12017}, {'_account_id': 12032}, {'_account_id': 12033}, {'_account_id': 12369}, {'_account_id': 14384}, {'_account_id': 15386}, {'_account_id': 15941}, {'_account_id': 19933}, {'_account_id': 22126}, {'_account_id': 22248}, {'_account_id': 22348}, {'_account_id': 22510}, {'_account_id': 23613}, {'_account_id': 24814}, {'_account_id': 24921}, {'_account_id': 25243}, {'_account_id': 25678}, {'_account_id': 26077}, {'_account_id': 26537}, {'_account_id': 28801}, {'_account_id': 29568}, {'_account_id': 29705}, {'_account_id': 30615}, {'_account_id': 30688}, {'_account_id': 32159}]","[{'number': 1, 'created': '2020-07-16 20:50:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/04db5acaa300c0dd38d1d30fa65654af5169d023', 'message': 'Race in Cinder backup manager\n\nFixed an race in Cinder Backup Manager.\n\nChange-Id: Ia135b2057118960bb9a395297efaadd0e7ba2720\nCloses-Bug: 1887859\n'}, {'number': 2, 'created': '2020-07-20 12:11:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/dbbaaaf6e333f68f486e16b84b1ad5c98d1bcec0', 'message': 'Race in Cinder backup manager\n\nFix for a race in Cinder Backup Manager.\n\nCloses-Bug: 1887859\nChange-Id: Ia135b2057118960bb9a395297efaadd0e7ba2720\n'}, {'number': 3, 'created': '2020-07-22 11:14:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/da18895f52a07ccbc1f5dd862dfb4bdd2aebbe1f', 'message': 'Race in Cinder backup manager\n\nFix for a race in Cinder Backup Manager.\n\nCloses-Bug: 1887859\nChange-Id: Ia135b2057118960bb9a395297efaadd0e7ba2720\n'}, {'number': 4, 'created': '2020-07-24 16:44:09.000000000', 'files': ['cinder/backup/manager.py', 'releasenotes/notes/bug-1887859-backup-manager-fb8dbf289eedc4b0.yaml'], 'web_link': 'https://opendev.org/openstack/cinder/commit/9893b1c9588384b080bc34821f1c93badf8f17df', 'message': 'Race in Cinder backup manager\n\nFix for a race in Cinder Backup Manager.\n\nCloses-Bug: 1887859\nChange-Id: Ia135b2057118960bb9a395297efaadd0e7ba2720\n'}]",3,741543,9893b1c9588384b080bc34821f1c93badf8f17df,120,32,4,29568,,,0,"Race in Cinder backup manager

Fix for a race in Cinder Backup Manager.

Closes-Bug: 1887859
Change-Id: Ia135b2057118960bb9a395297efaadd0e7ba2720
",git fetch https://review.opendev.org/openstack/cinder refs/changes/43/741543/4 && git format-patch -1 --stdout FETCH_HEAD,['cinder/backup/manager.py'],1,04db5acaa300c0dd38d1d30fa65654af5169d023,bug/1887859,, if not self.is_working(): self.setup_backup_backend(context),0,2
openstack%2Fcinder~master~I8c2c58092da4d5801642036a96079da45eafb290,openstack/cinder,master,I8c2c58092da4d5801642036a96079da45eafb290,Fix volume rekey during clone,MERGED,2020-11-16 17:28:46.000000000,2020-11-29 16:48:16.000000000,2020-11-29 16:46:41.000000000,"[{'_account_id': 4523}, {'_account_id': 5314}, {'_account_id': 5997}, {'_account_id': 9008}, {'_account_id': 9732}, {'_account_id': 10118}, {'_account_id': 12016}, {'_account_id': 12017}, {'_account_id': 12032}, {'_account_id': 12033}, {'_account_id': 12369}, {'_account_id': 15386}, {'_account_id': 20813}, {'_account_id': 21129}, {'_account_id': 21884}, {'_account_id': 22248}, {'_account_id': 22348}, {'_account_id': 22510}, {'_account_id': 23601}, {'_account_id': 23613}, {'_account_id': 24814}, {'_account_id': 24815}, {'_account_id': 24921}, {'_account_id': 25243}, {'_account_id': 25678}, {'_account_id': 26077}, {'_account_id': 26537}, {'_account_id': 28801}, {'_account_id': 30615}, {'_account_id': 30688}, {'_account_id': 31868}, {'_account_id': 32159}]","[{'number': 1, 'created': '2020-11-16 17:28:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/014d75a17205fe0bcc79a8c7678efe75ee87cf9d', 'message': 'Fix volume rekey during clone\n\nApply the correct encryption key to the\nnew volume.\n\nChange-Id: I8c2c58092da4d5801642036a96079da45eafb290\nCloses-Bug: #1904440\n'}, {'number': 2, 'created': '2020-11-17 13:29:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/ff4d0fca11cc5bae70d8a61fb439a00f8213d0ba', 'message': 'Fix volume rekey during clone\n\nApply the correct encryption key to the\nnew volume during clone.\n\nChange-Id: I8c2c58092da4d5801642036a96079da45eafb290\nCloses-Bug: #1904440\n'}, {'number': 3, 'created': '2020-11-17 18:50:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/c9f457aa6c6d94cca39891b6ff06ac4802358e6a', 'message': 'Fix volume rekey during clone\n\nApply the correct encryption key to the\nnew volume during clone.\n\nCloses-Bug: #1904440\nChange-Id: I8c2c58092da4d5801642036a96079da45eafb290\n'}, {'number': 4, 'created': '2020-11-18 13:23:11.000000000', 'files': ['cinder/volume/flows/manager/create_volume.py', 'cinder/tests/unit/volume/test_volume.py', 'releasenotes/notes/bug-1904440-clone-rekey-fd57a2b5f6224e0f.yaml'], 'web_link': 'https://opendev.org/openstack/cinder/commit/25cded9d106ea3c4d23b87d594451dc7fb9e0484', 'message': 'Fix volume rekey during clone\n\nApply the correct encryption key to the\nnew volume during clone.\n\nCloses-Bug: #1904440\nChange-Id: I8c2c58092da4d5801642036a96079da45eafb290\n'}]",2,762884,25cded9d106ea3c4d23b87d594451dc7fb9e0484,113,32,4,4523,,,0,"Fix volume rekey during clone

Apply the correct encryption key to the
new volume during clone.

Closes-Bug: #1904440
Change-Id: I8c2c58092da4d5801642036a96079da45eafb290
",git fetch https://review.opendev.org/openstack/cinder refs/changes/84/762884/4 && git format-patch -1 --stdout FETCH_HEAD,['cinder/volume/flows/manager/create_volume.py'],1,014d75a17205fe0bcc79a8c7678efe75ee87cf9d,," new_key = keymgr.get(context, new_key_id)"," new_key = keymgr.get(context, encryption['encryption_key_id'])",1,1
openstack%2Fneutron~master~I2bf2d25f6a6f651a740578e92720676975f8283f,openstack/neutron,master,I2bf2d25f6a6f651a740578e92720676975f8283f,Add irrelevant-files for tripleo standalone jobs,MERGED,2020-11-19 16:47:18.000000000,2020-11-29 15:57:16.000000000,2020-11-29 15:52:38.000000000,"[{'_account_id': 11975}, {'_account_id': 15752}, {'_account_id': 16688}, {'_account_id': 21798}, {'_account_id': 22348}, {'_account_id': 26622}, {'_account_id': 32067}, {'_account_id': 32291}]","[{'number': 1, 'created': '2020-11-19 16:47:18.000000000', 'files': ['zuul.d/project.yaml'], 'web_link': 'https://opendev.org/openstack/neutron/commit/d2187e8aa232e89d268bb6e36b814be2cfadf141', 'message': 'Add irrelevant-files for tripleo standalone jobs\n\nNow that these job depend on tripleo-ci-centos-8-content-provider job to\nrun, they should have the same list. Else, these jobs will try to run\nwhile the parent one did not, generating zuul errors as seen for example\nin [1]\n\n[1] https://review.opendev.org/#/c/763218/\n\nChange-Id: I2bf2d25f6a6f651a740578e92720676975f8283f\n'}]",0,763408,d2187e8aa232e89d268bb6e36b814be2cfadf141,37,8,1,21798,,,0,"Add irrelevant-files for tripleo standalone jobs

Now that these job depend on tripleo-ci-centos-8-content-provider job to
run, they should have the same list. Else, these jobs will try to run
while the parent one did not, generating zuul errors as seen for example
in [1]

[1] https://review.opendev.org/#/c/763218/

Change-Id: I2bf2d25f6a6f651a740578e92720676975f8283f
",git fetch https://review.opendev.org/openstack/neutron refs/changes/08/763408/1 && git format-patch -1 --stdout FETCH_HEAD,['zuul.d/project.yaml'],1,d2187e8aa232e89d268bb6e36b814be2cfadf141,," irrelevant-files: &consumer_irrelevant_files # use same list as dependency job # synced from tripleo-ci-base-centos-8 base - ^.*\.md$ - ^.*\.rst$ - ^doc/.*$ - ^etc/.*$ - ^metadata.json$ - ^releasenotes/.*$ # do not put requirements.txt here, as it can have a huge impact - ^test-requirements.txt$ - ^lower-constraints.txt$ - ^spec/.*$ - ^Puppetfile.*$ - tox.ini - ^setup.*$ - ^vars/sova-patterns.yml$ ^.ansible-lint$ - ^.pre-commit-config.yaml$ - ^.yamllint$ irrelevant-files: *consumer_irrelevant_files",,21,0
openstack%2Fpuppet-tripleo~master~I6f165491228f05539193f2e762b1b10320f52c36,openstack/puppet-tripleo,master,I6f165491228f05539193f2e762b1b10320f52c36,Filter haproxy_certificate_specs if hostname is empty,MERGED,2020-11-25 17:59:17.000000000,2020-11-29 15:54:53.000000000,2020-11-29 15:54:53.000000000,"[{'_account_id': 6926}, {'_account_id': 9914}, {'_account_id': 14985}, {'_account_id': 17216}, {'_account_id': 21129}, {'_account_id': 22348}, {'_account_id': 23181}, {'_account_id': 24245}]","[{'number': 1, 'created': '2020-11-25 17:59:17.000000000', 'files': ['manifests/profile/base/certmonger_user.pp'], 'web_link': 'https://opendev.org/openstack/puppet-tripleo/commit/eaca38aa674f263ec2a95add28d645b11525e839', 'message': 'Filter haproxy_certificate_specs if hostname is empty\n\nThe HAProxy tripleo service currently attempts to generate certificate\nspecs for all enabled networks which failes on roles that omit some\nnetworks.\n\nFor now workaround it by filtering out the bad certificate specs in\npuppet-tripleo.\nA similar workaround was implemented for apache in\nI651919488cb68b0b9878b4e21ab376bfc6e3f0fe.\n\nCloses-bug: #1905604\nChange-Id: I6f165491228f05539193f2e762b1b10320f52c36\n'}]",0,764225,eaca38aa674f263ec2a95add28d645b11525e839,16,8,1,23811,,,0,"Filter haproxy_certificate_specs if hostname is empty

The HAProxy tripleo service currently attempts to generate certificate
specs for all enabled networks which failes on roles that omit some
networks.

For now workaround it by filtering out the bad certificate specs in
puppet-tripleo.
A similar workaround was implemented for apache in
I651919488cb68b0b9878b4e21ab376bfc6e3f0fe.

Closes-bug: #1905604
Change-Id: I6f165491228f05539193f2e762b1b10320f52c36
",git fetch https://review.opendev.org/openstack/puppet-tripleo refs/changes/25/764225/1 && git format-patch -1 --stdout FETCH_HEAD,['manifests/profile/base/certmonger_user.pp'],1,eaca38aa674f263ec2a95add28d645b11525e839,," # Remove haproxy_certificates_specs where hostname is empty. # Workaround bug: https://bugs.launchpad.net/tripleo/+bug/1905604 $haproxy_certificates_specs_filtered = $haproxy_certificates_specs.filter | $specs, $keys | { ! empty($keys[hostname]) } unless empty($haproxy_certificates_specs_filtered) { unless empty($haproxy_certificates_specs_filtered) { ensure_resources('tripleo::certmonger::haproxy', $haproxy_certificates_specs_filtered)"," unless empty($haproxy_certificates_specs) { unless empty($haproxy_certificates_specs) { ensure_resources('tripleo::certmonger::haproxy', $haproxy_certificates_specs)",7,3
openstack%2Fdevstack~master~I31cd00c9117607682213cfa0399709e560f4ad0d,openstack/devstack,master,I31cd00c9117607682213cfa0399709e560f4ad0d,tempest: Enable shelve_migrate tests with Libvirt,MERGED,2020-09-17 13:06:35.000000000,2020-11-29 12:45:08.000000000,2020-11-29 12:43:55.000000000,"[{'_account_id': 5803}, {'_account_id': 8556}, {'_account_id': 10135}, {'_account_id': 22348}, {'_account_id': 22873}, {'_account_id': 29963}]","[{'number': 1, 'created': '2020-09-17 13:06:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack/commit/c4d111f73de949ee4579263410bebcca9e49d5ac', 'message': 'tempest: Enable shelve_migrate tests with Libvirt\n\nEnable the compute feature for shelve_migrate on all but LXC and\nXen virt_types.\n\nRelated-Bug: #1732428\nDepends-On: https://review.opendev.org/#/c/696084/\nDepends-On: https://review.opendev.org/#/c/743708/\nChange-Id: I31cd00c9117607682213cfa0399709e560f4ad0d\n'}, {'number': 2, 'created': '2020-09-25 07:13:13.000000000', 'files': ['lib/tempest'], 'web_link': 'https://opendev.org/openstack/devstack/commit/4a1186aa90570b9c25782b423c5abe31da0e9033', 'message': 'tempest: Enable shelve_migrate tests with Libvirt\n\nEnable the compute feature for shelve_migrate on all but LXC and\nXen virt_types.\n\nRelated-Bug: #1732428\nDepends-On: https://review.opendev.org/#/c/696084/\nChange-Id: I31cd00c9117607682213cfa0399709e560f4ad0d\n'}]",0,752463,4a1186aa90570b9c25782b423c5abe31da0e9033,27,6,2,28332,,,0,"tempest: Enable shelve_migrate tests with Libvirt

Enable the compute feature for shelve_migrate on all but LXC and
Xen virt_types.

Related-Bug: #1732428
Depends-On: https://review.opendev.org/#/c/696084/
Change-Id: I31cd00c9117607682213cfa0399709e560f4ad0d
",git fetch https://review.opendev.org/openstack/devstack refs/changes/63/752463/1 && git format-patch -1 --stdout FETCH_HEAD,['lib/tempest'],1,c4d111f73de949ee4579263410bebcca9e49d5ac,bug/1732428, iniset $TEMPEST_CONFIG compute-feature-enabled shelve_migrate True,,1,0
openstack%2Fcyborg~master~I80ddc0e8200a644613f3b45a15255d8c6b57a74b,openstack/cyborg,master,I80ddc0e8200a644613f3b45a15255d8c6b57a74b,Remove cyborg-dbsync unsupport argument,MERGED,2020-11-16 10:41:47.000000000,2020-11-29 11:37:58.000000000,2020-11-29 11:35:40.000000000,"[{'_account_id': 22348}, {'_account_id': 24872}, {'_account_id': 25738}, {'_account_id': 25847}, {'_account_id': 31412}]","[{'number': 1, 'created': '2020-11-16 10:41:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cyborg/commit/edba8f13f0be7167a1251df574cb8f4c2e9b23ee', 'message': ""Remove cyborg-dbsync unsupport argument\n\nNow we cannot run ``cyborg-dbsync - for backward compatibility``, it\nwill raise an error, that unsupport argument, and this command\nseems to have no meaning, as bellow:\n\nusage: cyborg-dbsync [-h] [--config-dir DIR] [--config-file PATH]\n                     [--debug] [--log-config-append PATH]\n                     [--log-date-format DATE_FORMAT] [--log-dir LOG_DIR]\n                     [--log-file PATH] [--nodebug] [--nouse-journal]\n                     [--nouse-json] [--nouse-syslog]\n                     [--nowatch-log-file] [--syslog-log-facility SYSLOG_LOG_FACILITY]\n                     [--use-journal] [--use-json] [--use-syslog]\n                     [--version] [--watch-log-file]\n                     {upgrade,revision,stamp,version,create_schema} ...\ncyborg-dbsync: error: argument command: invalid choice: 'for' (choose from 'upgrade',\n'revision', 'stamp', 'version', 'create_schema')\n\nChange-Id: I80ddc0e8200a644613f3b45a15255d8c6b57a74b\n""}, {'number': 2, 'created': '2020-11-16 10:43:21.000000000', 'files': ['cyborg/db/sqlalchemy/alembic/README.rst'], 'web_link': 'https://opendev.org/openstack/cyborg/commit/38d395d264eea87f0dda2c5c3129cad3bc54f06f', 'message': ""Remove cyborg-dbsync unsupport argument\n\nNow we cannot run ``cyborg-dbsync - for backward compatibility``, it\nwill raise an error, that unsupport argument, and this command\nseems to have no meaning, as bellow:\n\nusage: cyborg-dbsync [-h] [--config-dir DIR] [--config-file PATH]\n                     [--debug] [--log-config-append PATH]\n                     [--log-date-format DATE_FORMAT] [--log-dir LOG_DIR]\n                     [--log-file PATH] [--nodebug] [--nouse-journal]\n                     [--nouse-json] [--nouse-syslog]\n                     [--nowatch-log-file] [--syslog-log-facility SYSLOG_LOG_FACILITY]\n                     [--use-journal] [--use-json] [--use-syslog]\n                     [--version] [--watch-log-file]\n                     {upgrade,revision,stamp,version,create_schema} ...\ncyborg-dbsync: error: argument command: invalid choice: 'for' (choose from 'upgrade',\n'revision', 'stamp', 'version', 'create_schema')\n\nAnother change is rename this file to README.rst, adding the *rst*\nsubfix.\n\nChange-Id: I80ddc0e8200a644613f3b45a15255d8c6b57a74b\n""}]",0,762814,38d395d264eea87f0dda2c5c3129cad3bc54f06f,9,5,2,26458,,,0,"Remove cyborg-dbsync unsupport argument

Now we cannot run ``cyborg-dbsync - for backward compatibility``, it
will raise an error, that unsupport argument, and this command
seems to have no meaning, as bellow:

usage: cyborg-dbsync [-h] [--config-dir DIR] [--config-file PATH]
                     [--debug] [--log-config-append PATH]
                     [--log-date-format DATE_FORMAT] [--log-dir LOG_DIR]
                     [--log-file PATH] [--nodebug] [--nouse-journal]
                     [--nouse-json] [--nouse-syslog]
                     [--nowatch-log-file] [--syslog-log-facility SYSLOG_LOG_FACILITY]
                     [--use-journal] [--use-json] [--use-syslog]
                     [--version] [--watch-log-file]
                     {upgrade,revision,stamp,version,create_schema} ...
cyborg-dbsync: error: argument command: invalid choice: 'for' (choose from 'upgrade',
'revision', 'stamp', 'version', 'create_schema')

Another change is rename this file to README.rst, adding the *rst*
subfix.

Change-Id: I80ddc0e8200a644613f3b45a15255d8c6b57a74b
",git fetch https://review.opendev.org/openstack/cyborg refs/changes/14/762814/2 && git format-patch -1 --stdout FETCH_HEAD,['cyborg/db/sqlalchemy/alembic/README.rst'],1,edba8f13f0be7167a1251df574cb8f4c2e9b23ee,,,$ cyborg-dbsync - for backward compatibility,0,1
openstack%2Fcyborg~master~Ia3d3175ca22b8c19c85f361989d759e47e5da759,openstack/cyborg,master,Ia3d3175ca22b8c19c85f361989d759e47e5da759,Add microversion instructions,MERGED,2020-07-29 10:53:18.000000000,2020-11-29 11:37:05.000000000,2020-11-29 11:35:36.000000000,"[{'_account_id': 22348}, {'_account_id': 24872}, {'_account_id': 25738}, {'_account_id': 26458}, {'_account_id': 27458}, {'_account_id': 31412}]","[{'number': 1, 'created': '2020-07-29 10:53:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cyborg/commit/9945475f9d11ea0a07b045af55a8a755767fda9f', 'message': 'WIP: Add microversion instructions\n\nReference:\nhttps://specs.openstack.org/openstack/api-wg/guidelines/microversion_specification.html\n\nChange-Id: Ia3d3175ca22b8c19c85f361989d759e47e5da759\n'}, {'number': 2, 'created': '2020-09-17 03:02:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cyborg/commit/231ac048f5f4db06d2551afb327a366be5f18a67', 'message': 'WIP: Add microversion instructions\n\nReference:\nhttps://specs.openstack.org/openstack/api-wg/guidelines/microversion_specification.html\n\nChange-Id: Ia3d3175ca22b8c19c85f361989d759e47e5da759\n'}, {'number': 3, 'created': '2020-10-08 03:22:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cyborg/commit/6f5b9318d09a3078b7c0e370b28120a62e837174', 'message': 'WIP: Add microversion instructions\n\nReference:\nhttps://specs.openstack.org/openstack/api-wg/guidelines/microversion_specification.html\n\nChange-Id: Ia3d3175ca22b8c19c85f361989d759e47e5da759\n'}, {'number': 4, 'created': '2020-10-12 03:03:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cyborg/commit/7a06ca13d3541993593dd5862279057638efd7c2', 'message': 'WIP: Add microversion instructions\n\nReference:\nhttps://specs.openstack.org/openstack/api-wg/guidelines/microversion_specification.html\n\nChange-Id: Ia3d3175ca22b8c19c85f361989d759e47e5da759\n'}, {'number': 5, 'created': '2020-10-23 02:42:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cyborg/commit/6741b98bfa68507c758383de53ebb241ebc43691', 'message': 'WIP: Add microversion instructions\n\nReference:\nhttps://specs.openstack.org/openstack/api-wg/guidelines/microversion_specification.html\n\nChange-Id: Ia3d3175ca22b8c19c85f361989d759e47e5da759\n'}, {'number': 6, 'created': '2020-10-23 02:49:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cyborg/commit/5a2abca66fb103648b7e025f6a0920732eaae36f', 'message': 'Add microversion instructions\n\nReference:\nhttps://specs.openstack.org/openstack/api-wg/guidelines/microversion_specification.html\n\nChange-Id: Ia3d3175ca22b8c19c85f361989d759e47e5da759\n'}, {'number': 7, 'created': '2020-10-23 05:10:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cyborg/commit/a7da39734536b9e9ec706dff5234ed7cadb8834c', 'message': 'Add microversion instructions\n\nReference:\nhttps://specs.openstack.org/openstack/api-wg/guidelines/microversion_specification.html\n\nChange-Id: Ia3d3175ca22b8c19c85f361989d759e47e5da759\n'}, {'number': 8, 'created': '2020-10-23 05:40:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cyborg/commit/a2945a6a1f22adb7aa4582c91c2ffb5ac9881216', 'message': 'Add microversion instructions\n\nReference:\nhttps://specs.openstack.org/openstack/api-wg/guidelines/microversion_specification.html\n\nChange-Id: Ia3d3175ca22b8c19c85f361989d759e47e5da759\n'}, {'number': 9, 'created': '2020-10-24 02:59:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cyborg/commit/ec7ef1e55ab4fca7167322eea1ea2c27b7a9b06e', 'message': 'Add microversion instructions\n\nReference:\nhttps://specs.openstack.org/openstack/api-wg/guidelines/microversion_specification.html\n\nChange-Id: Ia3d3175ca22b8c19c85f361989d759e47e5da759\n'}, {'number': 10, 'created': '2020-10-24 03:49:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cyborg/commit/cd49e8fd099a928c64e762f74000d6130388ab52', 'message': 'Add microversion instructions\n\nIn Ussuri we introducing the microversion, and improved it in Victoria\nrelease, now we should add the guide for using microversion.\n\nReference:\nhttps://specs.openstack.org/openstack/api-wg/guidelines/microversion_specification.html\n\nChange-Id: Ia3d3175ca22b8c19c85f361989d759e47e5da759\n'}, {'number': 11, 'created': '2020-10-24 05:25:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cyborg/commit/c564a19ef31270942ddffc0d59efafbe74281562', 'message': 'Add microversion instructions\n\nIn Ussuri we introducing the microversion, and improved it in Victoria\nrelease, now we should add the guide for using microversion.\n\nReference:\nhttps://specs.openstack.org/openstack/api-wg/guidelines/microversion_specification.html\n\nChange-Id: Ia3d3175ca22b8c19c85f361989d759e47e5da759\n'}, {'number': 12, 'created': '2020-10-24 09:31:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cyborg/commit/191dbd59e32de8d761030d6cb439f20370e4e654', 'message': 'Add microversion instructions\n\nIn Ussuri we introducing the microversion, and improved it in Victoria\nrelease, now we should add the guide for using microversion.\n\nReference:\nhttps://specs.openstack.org/openstack/api-wg/guidelines/microversion_specification.html\n\nChange-Id: Ia3d3175ca22b8c19c85f361989d759e47e5da759\n'}, {'number': 13, 'created': '2020-10-25 02:44:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cyborg/commit/66bd9955252db8d317df4cf2a4ff935fe184c4d2', 'message': 'Add microversion instructions\n\nIn Ussuri we introducing the microversion, and improved it in Victoria\nrelease, now we should add the guide for using microversion.\n\nReference:\nhttps://specs.openstack.org/openstack/api-wg/guidelines/microversion_specification.html\n\nChange-Id: Ia3d3175ca22b8c19c85f361989d759e47e5da759\n'}, {'number': 14, 'created': '2020-10-26 11:16:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cyborg/commit/ea36b35b01536f85f673fb3ab96b1f0a632868de', 'message': 'Add microversion instructions\n\nIn Ussuri we introducing the microversion, and improved it in Victoria\nrelease, now we should add the guide for using microversion.\n\nReference:\nhttps://specs.openstack.org/openstack/api-wg/guidelines/microversion_specification.html\n\nChange-Id: Ia3d3175ca22b8c19c85f361989d759e47e5da759\n'}, {'number': 15, 'created': '2020-10-26 12:01:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cyborg/commit/8013dade36996c897332493641f8857fc95f5923', 'message': 'Add microversion instructions\n\nIn Ussuri we introducing the microversion, and improved it in Victoria\nrelease, now we should add the guide for using microversion.\n\nReference:\nhttps://specs.openstack.org/openstack/api-wg/guidelines/microversion_specification.html\n\nChange-Id: Ia3d3175ca22b8c19c85f361989d759e47e5da759\n'}, {'number': 16, 'created': '2020-10-27 00:45:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cyborg/commit/b8eb8d2aa4bff62a89bde323d9558043ab794c78', 'message': 'Add microversion instructions\n\nIn Ussuri we introducing the microversion, and improved it in Victoria\nrelease, now we should add the guide for using microversion.\n\nReference:\nhttps://specs.openstack.org/openstack/api-wg/guidelines/microversion_specification.html\n\nChange-Id: Ia3d3175ca22b8c19c85f361989d759e47e5da759\n'}, {'number': 17, 'created': '2020-11-10 11:22:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cyborg/commit/abda92c87a4c7099f910f1a4b89c3c5cffa1f6c8', 'message': 'Add microversion instructions\n\nIn Ussuri we introducing the microversion, and improved it in Victoria\nrelease, now we should add the guide for using microversion.\n\nReference:\nhttps://specs.openstack.org/openstack/api-wg/guidelines/microversion_specification.html\n\nCo-Authored-By: Wenping Song <songwenping@inspur.com>\n\nChange-Id: Ia3d3175ca22b8c19c85f361989d759e47e5da759\n'}, {'number': 18, 'created': '2020-11-10 21:23:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cyborg/commit/09b69249fc42a6f216c691c7e86abfc602dae942', 'message': 'Add microversion instructions\n\nIn Ussuri we introducing the microversion, and improved it in Victoria\nrelease, now we should add the guide for using microversion.\n\nReference:\nhttps://specs.openstack.org/openstack/api-wg/guidelines/microversion_specification.html\n\nCo-Authored-By: Wenping Song <songwenping@inspur.com>\n\nChange-Id: Ia3d3175ca22b8c19c85f361989d759e47e5da759\n'}, {'number': 19, 'created': '2020-11-11 01:41:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cyborg/commit/3cedd28bc34d1a67e59f5c78df485484761fe7dc', 'message': 'Add microversion instructions\n\nIn Ussuri we introducing the microversion, and improved it in Victoria\nrelease, now we should add the guide for using microversion.\n\nReference:\nhttps://specs.openstack.org/openstack/api-wg/guidelines/microversion_specification.html\n\nCo-Authored-By: Wenping Song <songwenping@inspur.com>\n\nChange-Id: Ia3d3175ca22b8c19c85f361989d759e47e5da759\n'}, {'number': 20, 'created': '2020-11-16 07:34:52.000000000', 'files': ['bindep.txt', 'doc/source/contributor/index.rst', 'doc/source/conf.py', 'doc/source/contributor/microversions.rst'], 'web_link': 'https://opendev.org/openstack/cyborg/commit/eabd6e1f791d9727a0a97e85bac9a5005f5b7d91', 'message': 'Add microversion instructions\n\nIn Ussuri we introducing the microversion, and improved it in Victoria\nrelease, now we should add the guide for using microversion.\n\nReference:\nhttps://specs.openstack.org/openstack/api-wg/guidelines/microversion_specification.html\n\nCo-Authored-By: Wenping Song <songwenping@inspur.com>\n\nChange-Id: Ia3d3175ca22b8c19c85f361989d759e47e5da759\n'}]",32,743722,eabd6e1f791d9727a0a97e85bac9a5005f5b7d91,63,6,20,26458,,,0,"Add microversion instructions

In Ussuri we introducing the microversion, and improved it in Victoria
release, now we should add the guide for using microversion.

Reference:
https://specs.openstack.org/openstack/api-wg/guidelines/microversion_specification.html

Co-Authored-By: Wenping Song <songwenping@inspur.com>

Change-Id: Ia3d3175ca22b8c19c85f361989d759e47e5da759
",git fetch https://review.opendev.org/openstack/cyborg refs/changes/22/743722/20 && git format-patch -1 --stdout FETCH_HEAD,['doc/source/contributor/microversions.rst'],1,9945475f9d11ea0a07b045af55a8a755767fda9f,,"API Microversions ================= Background ---------- Cyborg uses a framework we call 'API Microversions' for allowing changes to the API while preserving backward compatibility. The basic idea is that a user has to explicitly ask for their request to be treated with a particular version of the API. So breaking changes can be added to the API without breaking users who don't specifically ask for it. This is done with an HTTP header ``OpenStack-API-Version`` which has as its value a string containing the name of the service, ``accelerator``, and a monotonically increasing semantic version number starting from ``2.0``. The full form of the header takes the form:: OpenStack-API-Version: accelerator 2.0 If a user makes a request without specifying a version, they will get the ``2.0`` as the default version (it is defined in ``cyborg/api/controllers/v2/versions.py``, using ``_MIN_VERSION_STRING``). This value is currently ``2.0`` and is expected to remain so for quite a long time. .. TODO:: Need to add the ``latest`` behave as if maximum version was specified. There is a special value ``latest`` which can be specified, which will allow a client to always receive the most recent version of API responses from the server. .. NOTE:: In cyborgclinet the ``latest`` already required (as above TODO) .. warning:: The ``latest`` value is mostly meant for integration testing and would be dangerous to rely on in client code since Cyborg microversions are not following semver and therefore backward compatibility is not guaranteed. Clients, like python-cyborgclient, should always require a specific microversion but limit what is acceptable to the version range that it understands at the time. For full details please read the `Ussuri spec for microversions <https://specs.openstack.org/openstack/cyborg-specs/specs/ussuri/approved/cyborg-api.html>`_ and `Microversion Specification <http://specs.openstack.org/openstack/api-wg/guidelines/microversion_specification.html>`_. When do I need a new Microversion? ---------------------------------- A microversion is needed when the contract to the user is changed. The user contract covers many kinds of information such as: - the Request - the list of resource urls which exist on the server Example: adding a new accelerator_requests/{ID}/foo which didn't exist in a previous version of the code - the list of query parameters that are valid on urls Example: adding a new parameter ``is_yellow`` accelerator_requests/{ID}?is_yellow=True - the list of query parameter values for non free form fields Example: parameter filter_by takes a small set of constants/enums ""A"", ""B"", ""C"". Adding support for new enum ""D"". - new headers accepted on a request - the list of attributes and data structures accepted. Example: adding a new attribute 'description' to the accelerator request body - the Response - the list of attributes and data structures returned Example: adding a new attribute 'description' to the output of accelerator_requests/{ID} - the allowed values of non free form fields Example: adding a new allowed ``status`` to accelerator_requests/{ID} - the list of status codes allowed for a particular request Example: an API previously could return 200, 400, 403, 404 and the change would make the API now also be allowed to return 409. See [#f2]_ for the 400, 403, 404 and 415 cases. - changing a status code on a particular response Example: changing the return code of an API from 501 to 400. .. note:: Fixing a bug so that a 400+ code is returned rather than a 500 or 503 does not require a microversion change. It's assumed that clients are not expected to handle a 500 or 503 response and therefore should not need to opt-in to microversion changes that fixes a 500 or 503 response from happening. According to the OpenStack API Working Group, a **500 Internal Server Error** should **not** be returned to the user for failures due to user error that can be fixed by changing the request on the client side. See [#f1]_. - new headers returned on a response The following flow chart attempts to walk through the process of ""do we need a microversion"". .. graphviz:: digraph states { label=""Do I need a microversion?"" silent_fail[shape=""diamond"", style="""", group=g1, label=""Did we silently fail to do what is asked?""]; ret_500[shape=""diamond"", style="""", group=g1, label=""Did we return a 500 before?""]; new_error[shape=""diamond"", style="""", group=g1, label=""Are we changing what status code is returned?""]; new_attr[shape=""diamond"", style="""", group=g1, label=""Did we add or remove an attribute to a payload?""]; new_param[shape=""diamond"", style="""", group=g1, label=""Did we add or remove an accepted query string parameter or value?""]; new_resource[shape=""diamond"", style="""", group=g1, label=""Did we add or remove a resource url?""]; no[shape=""box"", style=rounded, label=""No microversion needed""]; yes[shape=""box"", style=rounded, label=""Yes, you need a microversion""]; no2[shape=""box"", style=rounded, label=""No microversion needed, it's a bug""]; silent_fail -> ret_500[label="" no""]; silent_fail -> no2[label=""yes""]; ret_500 -> no2[label=""yes [1]""]; ret_500 -> new_error[label="" no""]; new_error -> new_attr[label="" no""]; new_error -> yes[label=""yes""]; new_attr -> new_param[label="" no""]; new_attr -> yes[label=""yes""]; new_param -> new_resource[label="" no""]; new_param -> yes[label=""yes""]; new_resource -> no[label="" no""]; new_resource -> yes[label=""yes""]; {rank=same; yes new_attr} {rank=same; no2 ret_500} {rank=min; silent_fail} } **Footnotes** .. [#f1] When fixing 500 errors that previously caused stack traces, try to map the new error into the existing set of errors that API call could previously return (400 if nothing else is appropriate). Changing the set of allowed status codes from a request is changing the contract, and should be part of a microversion (except in [#f2]_). The reason why we are so strict on contract is that we'd like application writers to be able to know, for sure, what the contract is at every microversion in Cyborg. If they do not, they will need to write conditional code in their application to handle ambiguities. When in doubt, consider application authors. If it would work with no client side changes on both Cyborg versions, you probably don't need a microversion. If, on the other hand, there is any ambiguity, a microversion is probably needed. .. [#f2] The exception to not needing a microversion when returning a previously unspecified error code is the 400, 403, 404 and 415 cases. This is considered OK to return even if previously unspecified in the code since it's implied given keystone authentication can fail with a 403 and API validation can fail with a 400 for invalid json request body. Request to url/resource that does not exist always fails with 404. Invalid content types are handled before API methods are called which results in a 415. .. note:: When in doubt about whether or not a microversion is required for changing an error response code, consult the `Cyborg core team`_. .. _Cyborg core team: https://review.opendev.org/#/admin/groups/1243,members When a microversion is not needed --------------------------------- A microversion is not needed in the following situation: - the response - Changing the error message without changing the response code does not require a new microversion. - Removing an inapplicable HTTP header, for example, suppose the Retry-After HTTP header is being returned with a 4xx code. This header should only be returned with a 503 or 3xx response, so it may be removed without bumping the microversion. - An obvious regression bug in an admin-only API where the bug can still be fixed upstream on active stable branches. Admin-only APIs are less of a concern for interoperability and generally a regression in behavior can be dealt with as a bug fix when the documentation clearly shows the API behavior was unexpectedly regressed. In Code ------- In ``nova/api/openstack/wsgi.py`` we define an ``@api_version`` decorator which is intended to be used on top-level Controller methods. It is not appropriate for lower-level methods. Some examples::x which is intended to be used on top-level Controller methods. It is not appropriate for lower-level methods. Some examples: Adding a new API method ~~~~~~~~~~~~~~~~~~~~~~~ In the controller class:: @wsgi.Controller.api_version(""2.4"") def my_api_method(self, req, id): .... This method would only be available if the caller had specified an ``OpenStack-API-Version`` of >= ``2.4``. If they had specified a lower version (or not specified it and received the default of ``2.1``) the server would respond with ``HTTP/404``. Removing an API method ~~~~~~~~~~~~~~~~~~~~~~ In the controller class:: @wsgi.Controller.api_version(""2.1"", ""2.4"") def my_api_method(self, req, id): .... This method would only be available if the caller had specified an ``OpenStack-API-Version`` of <= ``2.4``. If ``2.5`` or later is specified the server will respond with ``HTTP/404``. Changing a method's behavior ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ In the controller class:: @wsgi.Controller.api_version(""2.1"", ""2.3"") def my_api_method(self, req, id): .... method_1 ... @wsgi.Controller.api_version(""2.4"") # noqa def my_api_method(self, req, id): .... method_2 ... If a caller specified ``2.1``, ``2.2`` or ``2.3`` (or received the default of ``2.1``) they would see the result from ``method_1``, ``2.4`` or later ``method_2``. It is vital that the two methods have the same name, so the second of them will need ``# noqa`` to avoid failing flake8's ``F811`` rule. The two methods may be different in any kind of semantics (schema validation, return values, response codes, etc) A change in schema only ~~~~~~~~~~~~~~~~~~~~~~~ If there is no change to the method, only to the schema that is used for validation, you can add a version range to the ``validation.schema`` decorator:: @wsgi.Controller.api_version(""2.1"") @validation.schema(dummy_schema.dummy, ""2.3"", ""2.8"") @validation.schema(dummy_schema.dummy2, ""2.9"") def update(self, req, id, body): .... This method will be available from version ``2.1``, validated according to ``dummy_schema.dummy`` from ``2.3`` to ``2.8``, and validated according to ``dummy_schema.dummy2`` from ``2.9`` onward. When not using decorators ~~~~~~~~~~~~~~~~~~~~~~~~~ When you don't want to use the ``@api_version`` decorator on a method or you want to change behavior within a method (say it leads to simpler or simply a lot less code) you can directly test for the requested version with a method as long as you have access to the api request object (commonly called ``req``). Every API method has an api_version_request object attached to the req object and that can be used to modify behavior based on its value:: def index(self, req): <common code> req_version = req.api_version_request req1_min = api_version_request.APIVersionRequest(""2.1"") req1_max = api_version_request.APIVersionRequest(""2.5"") req2_min = api_version_request.APIVersionRequest(""2.6"") req2_max = api_version_request.APIVersionRequest(""2.10"") if req_version.matches(req1_min, req1_max): ....stuff.... elif req_version.matches(req2min, req2_max): ....other stuff.... elif req_version > api_version_request.APIVersionRequest(""2.10""): ....more stuff..... <common code> The first argument to the matches method is the minimum acceptable version and the second is maximum acceptable version. A specified version can be null:: null_version = APIVersionRequest() If the minimum version specified is null then there is no restriction on the minimum version, and likewise if the maximum version is null there is no restriction the maximum version. Alternatively a one sided comparison can be used as in the example above. Other necessary changes ----------------------- If you are adding a patch which adds a new microversion, it is necessary to add changes to other places which describe your change: * Update ``REST_API_VERSION_HISTORY`` in ``nova/api/openstack/api_version_request.py`` * Update ``_MAX_API_VERSION`` in ``nova/api/openstack/api_version_request.py`` * Add a verbose description to ``nova/api/openstack/compute/rest_api_version_history.rst``. * Add a :doc:`release note </contributor/releasenotes>` with a ``features`` section announcing the new or changed feature and the microversion. * Update the expected versions in affected tests, for example in ``nova/tests/unit/api/openstack/compute/test_versions.py``. * Update the get versions api sample file: ``doc/api_samples/versions/versions-get-resp.json`` and ``doc/api_samples/versions/v21-version-get-resp.json``. * Make a new commit to python-novaclient and update corresponding files to enable the newly added microversion API. See :python-novaclient-doc:`Adding support for a new microversion <contributor/microversions>` in python-novaclient for more details. * If the microversion changes the response schema, a new schema and test for the microversion must be added to Tempest. * If applicable, add Functional sample tests under ``nova/tests/functional/api_sample_tests``. Also, add JSON examples to ``doc/api_samples`` directory which can be generated automatically via tox env ``api-samples`` or run test with env var ``GENERATE_SAMPLES`` True. * Update the `API Reference`_ documentation as appropriate. The source is located under `api-ref/source/`. * If the microversion changes servers related APIs, update the ``api-guide/source/server_concepts.rst`` accordingly. .. _API Reference: https://docs.openstack.org/api-ref/compute/ Allocating a microversion ------------------------- If you are adding a patch which adds a new microversion, it is necessary to allocate the next microversion number. Except under extremely unusual circumstances and this would have been mentioned in the nova spec for the change, the minor number of ``_MAX_API_VERSION`` will be incremented. This will also be the new microversion number for the API change. It is possible that multiple microversion patches would be proposed in parallel and the microversions would conflict between patches. This will cause a merge conflict. We don't reserve a microversion for each patch in advance as we don't know the final merge order. Developers may need over time to rebase their patch calculating a new version number as above based on the updated value of ``_MAX_API_VERSION``. Testing Microversioned API Methods ---------------------------------- Testing a microversioned API method is very similar to a normal controller method test, you just need to add the ``OpenStack-API-Version`` header, for example:: req = fakes.HTTPRequest.blank('/testable/url/endpoint') req.headers = {'OpenStack-API-Version': 'compute 2.28'} req.api_version_request = api_version.APIVersionRequest('2.6') controller = controller.TestableController() res = controller.index(req) ... assertions about the response ... For many examples of testing, the canonical examples are in ``nova/tests/unit/api/openstack/compute/test_microversions.py``. ",,411,0
openstack%2Fopenstack-manuals~master~Ic8351ae186a4ca25eac60896f43f2f55c715716b,openstack/openstack-manuals,master,Ic8351ae186a4ca25eac60896f43f2f55c715716b,"Retire python-qinlingclient, qinling-dashboard: update doc site",MERGED,2020-11-28 05:29:10.000000000,2020-11-29 11:11:26.000000000,2020-11-29 10:55:29.000000000,"[{'_account_id': 6547}, {'_account_id': 22348}]","[{'number': 1, 'created': '2020-11-28 05:29:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/473247411b0b821aa0b31798c40c51b18e6b4bb3', 'message': 'Retire python-qinlingclient: update doc site\n\nQinling project is retiring in Wallaby cycle[1].\nThis commit update openstack-manual to redirect\nthe repo doc site to REAMDE file.\n\n[1] http://lists.openstack.org/pipermail/openstack-discuss/2020-November/018638.html\n\nChange-Id: Ic8351ae186a4ca25eac60896f43f2f55c715716b\n'}, {'number': 2, 'created': '2020-11-28 05:30:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/3b4d2d98757ddc33b47bd9bd567fdce12449de0a', 'message': 'Retire python-qinlingclient: update doc site\n\nQinling project is retiring in Wallaby cycle[1].\nThis commit update openstack-manual to redirect\nthe repo doc site to REAMDE file.\n\nDepends-On: https://review.opendev.org/c/openstack/project-config/+/764536\n\n[1] http://lists.openstack.org/pipermail/openstack-discuss/2020-November/018638.html\n\nChange-Id: Ic8351ae186a4ca25eac60896f43f2f55c715716b\n'}, {'number': 3, 'created': '2020-11-28 21:42:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/42df0295ebfe5fd9e5cff866be755219e4889ed8', 'message': 'Retire python-qinlingclient: update doc site\n\nQinling project is retiring in Wallaby cycle[1].\nThis commit update openstack-manual to redirect\nthe repo doc site to REAMDE file.\n\nDepends-On: https://review.opendev.org/c/openstack/project-config/+/764536\n\n[1] http://lists.openstack.org/pipermail/openstack-discuss/2020-November/018638.html\n\nChange-Id: Ic8351ae186a4ca25eac60896f43f2f55c715716b\n'}, {'number': 4, 'created': '2020-11-28 21:43:43.000000000', 'files': ['tools/www-generator.py'], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/06be8f71c3caabd66baf3310cf08f86dbce65109', 'message': 'Retire python-qinlingclient, qinling-dashboard: update doc site\n\nQinling project is retiring in Wallaby cycle[1].\nThis commit update openstack-manual to redirect\nthe repo doc site to REAMDE file.\n\nNeeded-by: https://review.opendev.org/c/openstack/qinling-dashboard/+/764522\nNeeded-by: https://review.opendev.org/c/openstack/python-qinlingclient/+/764525\n\n[1] http://lists.openstack.org/pipermail/openstack-discuss/2020-November/018638.html\n\nChange-Id: Ic8351ae186a4ca25eac60896f43f2f55c715716b\n'}]",0,764538,06be8f71c3caabd66baf3310cf08f86dbce65109,12,2,4,8556,,,0,"Retire python-qinlingclient, qinling-dashboard: update doc site

Qinling project is retiring in Wallaby cycle[1].
This commit update openstack-manual to redirect
the repo doc site to REAMDE file.

Needed-by: https://review.opendev.org/c/openstack/qinling-dashboard/+/764522
Needed-by: https://review.opendev.org/c/openstack/python-qinlingclient/+/764525

[1] http://lists.openstack.org/pipermail/openstack-discuss/2020-November/018638.html

Change-Id: Ic8351ae186a4ca25eac60896f43f2f55c715716b
",git fetch https://review.opendev.org/openstack/openstack-manuals refs/changes/38/764538/1 && git format-patch -1 --stdout FETCH_HEAD,['tools/www-generator.py'],1,473247411b0b821aa0b31798c40c51b18e6b4bb3,retire-qinling," 'openstack/python-qinlingclient',",,1,0
openstack%2Fcyborg~master~Ib9b36d015bac074fe65205c6ca14706e36e20195,openstack/cyborg,master,Ib9b36d015bac074fe65205c6ca14706e36e20195,Add index page for contributors guide,MERGED,2020-10-24 01:58:13.000000000,2020-11-29 11:08:18.000000000,2020-11-29 11:07:13.000000000,"[{'_account_id': 6547}, {'_account_id': 22348}, {'_account_id': 24872}, {'_account_id': 25738}, {'_account_id': 26458}, {'_account_id': 27458}, {'_account_id': 31412}]","[{'number': 1, 'created': '2020-10-24 01:58:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cyborg/commit/f886c4b9fc3648019a63680639aa24f5232413b7', 'message': 'Add index page for contributors guide\n\nChange-Id: Ib9b36d015bac074fe65205c6ca14706e36e20195\n'}, {'number': 2, 'created': '2020-10-24 02:19:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cyborg/commit/620c5c25dc3f4a7c676f680970d7512dd517f746', 'message': 'Add index page for contributors guide\n\nAdd ""releasenotes"", ""devstack_setup"" and ""driver-development-guide"" to\nthe index page, and add a releasenote guide for users.\n\nChange-Id: Ib9b36d015bac074fe65205c6ca14706e36e20195\n'}, {'number': 3, 'created': '2020-10-24 02:37:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cyborg/commit/96d36ba6286dc45647eefd8c3606d31701ee53e2', 'message': 'Add index page for contributors guide\n\nAdd ""releasenotes"", ""devstack_setup"" and ""driver-development-guide"" to\nthe index page, and add a releasenote guide for users.\n\nChange-Id: Ib9b36d015bac074fe65205c6ca14706e36e20195\n'}, {'number': 4, 'created': '2020-10-27 00:44:36.000000000', 'files': ['doc/source/index.rst', 'doc/source/contributor/index.rst', 'doc/source/contributor/releasenotes.rst'], 'web_link': 'https://opendev.org/openstack/cyborg/commit/0da7417ccc5d1ec625d4b73ad7c188fff1acac93', 'message': 'Add index page for contributors guide\n\nAdd ""releasenotes"", ""devstack_setup"" and ""driver-development-guide"" to\nthe index page, and add a releasenote guide for users.\n\nChange-Id: Ib9b36d015bac074fe65205c6ca14706e36e20195\n'}]",7,759540,0da7417ccc5d1ec625d4b73ad7c188fff1acac93,17,7,4,26458,,,0,"Add index page for contributors guide

Add ""releasenotes"", ""devstack_setup"" and ""driver-development-guide"" to
the index page, and add a releasenote guide for users.

Change-Id: Ib9b36d015bac074fe65205c6ca14706e36e20195
",git fetch https://review.opendev.org/openstack/cyborg refs/changes/40/759540/3 && git format-patch -1 --stdout FETCH_HEAD,['doc/source/contributor/index.rst'],1,f886c4b9fc3648019a63680639aa24f5232413b7,,"=========================== Contributor Documentation =========================== Contributing to Cybrog gives you the power to help add features, fix bugs, enhance documentation, and increase testing. Contributions of any type are valuable, and part of what keeps the project going. Here are a list of resources to get your started. Basic Information ================= .. toctree:: :maxdepth: 2 contributing Reviewing ========= * :doc:`/contributor/releasenotes`: When we need a release note for a contribution. * :doc:`/contributor/devstack_setup`: Guidelines for handling setup devstack * :doc:`/contributor/driver-development-guide`: Get your driver development guide to contribute .. # NOTE: toctree needs to be placed at the end of the secion to # keep the document structure in the PDF doc. .. toctree:: :hidden: releasenotes devstack_setup driver-development-guide ",,36,0
openstack%2Ftrove~stable%2Fvictoria~If129aef794c9b2e547c0a3acfc6855c3506cf930,openstack/trove,stable/victoria,If129aef794c9b2e547c0a3acfc6855c3506cf930,Use current slave_pos of slave to continue replicate,MERGED,2020-11-28 19:18:40.000000000,2020-11-29 10:50:11.000000000,2020-11-29 10:49:05.000000000,"[{'_account_id': 6732}, {'_account_id': 22348}, {'_account_id': 31662}]","[{'number': 1, 'created': '2020-11-28 19:18:40.000000000', 'files': ['trove/guestagent/strategies/replication/mariadb_gtid.py'], 'web_link': 'https://opendev.org/openstack/trove/commit/d6b35435e0114c663ab481680371de45acd99c2e', 'message': ""Use current slave_pos of slave to continue replicate\n\nBecause gtid is global and all operation are write to binlog, so incase\nchange to new master, we just use current slave_pos of slave, the slave\nwill just continue from the appropriate point in the new master's binlog.\n\nStory: #2008376\nTask: #41294\nChange-Id: If129aef794c9b2e547c0a3acfc6855c3506cf930\n(cherry picked from commit 8987244c407b7dcb13dec1f20d3cc8a2c82c4dcd)\n""}]",0,764500,d6b35435e0114c663ab481680371de45acd99c2e,7,3,1,6732,,,0,"Use current slave_pos of slave to continue replicate

Because gtid is global and all operation are write to binlog, so incase
change to new master, we just use current slave_pos of slave, the slave
will just continue from the appropriate point in the new master's binlog.

Story: #2008376
Task: #41294
Change-Id: If129aef794c9b2e547c0a3acfc6855c3506cf930
(cherry picked from commit 8987244c407b7dcb13dec1f20d3cc8a2c82c4dcd)
",git fetch https://review.opendev.org/openstack/trove refs/changes/00/764500/1 && git format-patch -1 --stdout FETCH_HEAD,['trove/guestagent/strategies/replication/mariadb_gtid.py'],1,d6b35435e0114c663ab481680371de45acd99c2e,," if 'dataset' in master_info: set_gtid_cmd = ""SET GLOBAL gtid_slave_pos='%s';"" % last_gtid service.execute_sql(set_gtid_cmd)"," if 'gtid_pos' in logging_config: # This will happen during master failover. last_gtid = logging_config['gtid_pos'] elif 'dataset' in master_info: set_gtid_cmd = ""SET GLOBAL gtid_slave_pos='%s';"" % last_gtid service.execute_sql(set_gtid_cmd)",3,7
openstack%2Ftrove~master~I6d70add380f4b61ebe89c72765612d8cb6127ccb,openstack/trove,master,I6d70add380f4b61ebe89c72765612d8cb6127ccb,Improve trove guest image build script,MERGED,2020-11-26 01:19:24.000000000,2020-11-29 10:50:09.000000000,2020-11-29 10:49:01.000000000,"[{'_account_id': 6732}, {'_account_id': 22348}]","[{'number': 1, 'created': '2020-11-26 01:19:24.000000000', 'files': ['integration/scripts/files/elements/ubuntu-docker/install.d/21-docker', 'integration/scripts/files/elements/guest-agent/package-installs.yaml', 'integration/scripts/files/elements/guest-agent/post-install.d/99-clean-apt', 'integration/scripts/files/elements/guest-agent/element-deps', 'integration/scripts/functions_qemu'], 'web_link': 'https://opendev.org/openstack/trove/commit/a97ff84c19580a9d6e3d393a33ee773ac4ecf3c8', 'message': 'Improve trove guest image build script\n\nAlso using ubuntu-minimal to decrease the image size a little bit, from 963M\nto 815M in the test.\n\nChange-Id: I6d70add380f4b61ebe89c72765612d8cb6127ccb\n'}]",0,764260,a97ff84c19580a9d6e3d393a33ee773ac4ecf3c8,7,2,1,6732,,,0,"Improve trove guest image build script

Also using ubuntu-minimal to decrease the image size a little bit, from 963M
to 815M in the test.

Change-Id: I6d70add380f4b61ebe89c72765612d8cb6127ccb
",git fetch https://review.opendev.org/openstack/trove refs/changes/60/764260/1 && git format-patch -1 --stdout FETCH_HEAD,"['integration/scripts/files/elements/guest-agent/package-installs.yaml', 'integration/scripts/files/elements/ubuntu-docker/install.d/21-docker', 'integration/scripts/files/elements/guest-agent/post-install.d/99-clean-apt', 'integration/scripts/files/elements/guest-agent/element-deps', 'integration/scripts/functions_qemu']",5,a97ff84c19580a9d6e3d393a33ee773ac4ecf3c8,image-size," # For system-wide installs, DIB will automatically find the elements, so we only check local path if [[ ""${DIB_LOCAL_ELEMENTS_PATH}"" ]]; then export ELEMENTS_PATH=${trove_elements_path}:${DIB_LOCAL_ELEMENTS_PATH} else export ELEMENTS_PATH=${trove_elements_path} fi # Prepare elements for diskimage-builder export DIB_CLOUD_INIT_ETC_HOSTS=""localhost"" local elementes=""base vm"" # Only support ubuntu at the moment. if [[ ""${guest_os}"" == ""ubuntu"" ]]; then export DIB_RELEASE=${guest_release} # https://cloud-images.ubuntu.com/releases is more stable than the daily # builds (https://cloud-images.ubuntu.com/xenial/current/), # e.g. sometimes SHA256SUMS file is missing in the daily builds website. # Ref: diskimage_builder/elements/ubuntu/root.d/10-cache-ubuntu-tarball declare -A image_file_mapping=( [""xenial""]=""ubuntu-16.04-server-cloudimg-amd64-root.tar.gz"" [""bionic""]=""ubuntu-18.04-server-cloudimg-amd64.squashfs"" ) export DIB_CLOUD_IMAGES=""https://cloud-images.ubuntu.com/releases/${DIB_RELEASE}/release/"" export BASE_IMAGE_FILE=${image_file_mapping[${DIB_RELEASE}]} elementes=""$elementes ubuntu-minimal"" fi export DIB_CLOUD_INIT_DATASOURCES=${DIB_CLOUD_INIT_DATASOURCES:-""ConfigDrive""} elementes=""$elementes cloud-init-datasources"" "," local elementes=""base vm"" # For system-wide installs, DIB will automatically find the elements, so we only check local path if [[ ""${DIB_LOCAL_ELEMENTS_PATH}"" ]]; then export ELEMENTS_PATH=${trove_elements_path}:${DIB_LOCAL_ELEMENTS_PATH} else export ELEMENTS_PATH=${trove_elements_path} fi export DIB_RELEASE=${guest_release} export DIB_CLOUD_INIT_DATASOURCES=""ConfigDrive"" export DIB_CLOUD_INIT_ETC_HOSTS=""localhost"" # https://cloud-images.ubuntu.com/releases is more stable than the daily # builds (https://cloud-images.ubuntu.com/xenial/current/), # e.g. sometimes SHA256SUMS file is missing in the daily builds website. # Ref: diskimage_builder/elements/ubuntu/root.d/10-cache-ubuntu-tarball declare -A image_file_mapping=( [""xenial""]=""ubuntu-16.04-server-cloudimg-amd64-root.tar.gz"" [""bionic""]=""ubuntu-18.04-server-cloudimg-amd64.squashfs"" ) export DIB_CLOUD_IMAGES=""https://cloud-images.ubuntu.com/releases/${DIB_RELEASE}/release/"" export BASE_IMAGE_FILE=${image_file_mapping[${DIB_RELEASE}]} elementes=""$elementes ${guest_os}""",60,27
openstack%2Fopenstack-ansible-os_magnum~master~Iaa7a0aae186eaf080b7be3949821ed9e90c52456,openstack/openstack-ansible-os_magnum,master,Iaa7a0aae186eaf080b7be3949821ed9e90c52456,Fix linter errors,MERGED,2020-10-01 15:48:41.000000000,2020-11-29 09:55:25.000000000,2020-11-29 09:54:16.000000000,"[{'_account_id': 22348}, {'_account_id': 25023}, {'_account_id': 28619}]","[{'number': 1, 'created': '2020-10-01 15:48:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_magnum/commit/f3bfd06845308da48adacf8267a3eeedde27b478', 'message': 'Fix linter errors\n\nChange-Id: Iaa7a0aae186eaf080b7be3949821ed9e90c52456\n'}, {'number': 2, 'created': '2020-10-02 07:28:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_magnum/commit/8089abdca1b7078e0bc3a170bc0ab499ed15de52', 'message': 'Fix linter errors\n\nChange-Id: Iaa7a0aae186eaf080b7be3949821ed9e90c52456\n'}, {'number': 3, 'created': '2020-10-02 10:26:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_magnum/commit/5b27fc0eaccd82cf9b51738a18c2a704709fe22f', 'message': 'Fix linter errors\n\nWe also fix magnum config in order to work with bind-to-mgmt,\nuntil [1] got merged\n\n[1] https://review.opendev.org/733408\n\nChange-Id: Iaa7a0aae186eaf080b7be3949821ed9e90c52456\n'}, {'number': 4, 'created': '2020-10-02 12:22:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_magnum/commit/3da68b533e3f4c99f8e27f44a1a95251c22813f7', 'message': 'Fix linter errors\n\nWe also fix magnum config in order to work with bind-to-mgmt,\nuntil [1] got merged\n\n[1] https://review.opendev.org/733408\n\nDepends-On: https://review.opendev.org/733408\nChange-Id: Iaa7a0aae186eaf080b7be3949821ed9e90c52456\n'}, {'number': 5, 'created': '2020-10-15 16:55:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_magnum/commit/544005fca9a391f6e31d60b3c0900c5bcbffd4aa', 'message': 'Fix linter errors\n\nWe also fix magnum config in order to work with bind-to-mgmt,\nuntil [1] got merged\n\n[1] https://review.opendev.org/733408\n\nDepends-On: https://review.opendev.org/758461\nChange-Id: Iaa7a0aae186eaf080b7be3949821ed9e90c52456\n'}, {'number': 6, 'created': '2020-11-17 17:20:45.000000000', 'files': ['tasks/magnum_db_sync.yml', 'doc/source/conf.py', 'templates/magnum.conf.j2'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_magnum/commit/7c90bb17291f6662c6995ee728eadaed52b976e6', 'message': 'Fix linter errors\n\nWe also fix magnum config in order to work with bind-to-mgmt,\nuntil [1] got merged\n\n[1] https://review.opendev.org/733408\n\nDepends-On: https://review.opendev.org/763049\nChange-Id: Iaa7a0aae186eaf080b7be3949821ed9e90c52456\n'}]",2,755569,7c90bb17291f6662c6995ee728eadaed52b976e6,36,3,6,25023,,,0,"Fix linter errors

We also fix magnum config in order to work with bind-to-mgmt,
until [1] got merged

[1] https://review.opendev.org/733408

Depends-On: https://review.opendev.org/763049
Change-Id: Iaa7a0aae186eaf080b7be3949821ed9e90c52456
",git fetch https://review.opendev.org/openstack/openstack-ansible-os_magnum refs/changes/69/755569/5 && git format-patch -1 --stdout FETCH_HEAD,['doc/source/conf.py'],1,f3bfd06845308da48adacf8267a3eeedde27b478,755569," title.replace(""_"", r""\_""), author, 'manual'),"," title.replace(""_"", ""\_""), author, 'manual'),",1,1
openstack%2Ftempest~master~I8a33bd4f4ea189ce9247dfecec1e53001682b870,openstack/tempest,master,I8a33bd4f4ea189ce9247dfecec1e53001682b870,"Fix ""TypeError: format requires a mapping"" in waiters",MERGED,2020-11-19 09:01:37.000000000,2020-11-29 02:16:14.000000000,2020-11-29 02:14:43.000000000,"[{'_account_id': 5689}, {'_account_id': 8556}, {'_account_id': 22348}, {'_account_id': 22873}, {'_account_id': 32238}]","[{'number': 1, 'created': '2020-11-19 09:01:37.000000000', 'files': ['tempest/tests/common/test_waiters.py', 'tempest/common/waiters.py'], 'web_link': 'https://opendev.org/openstack/tempest/commit/414ffbacb7773915f2a5f6dfe127ded15d375f55', 'message': 'Fix ""TypeError: format requires a mapping"" in waiters\n\nThis is to fix the ""TypeError: format requires a mapping"" in\nwait_for_image_imported_to_stores and wait_for_image_copied_to_stores.\n\nChange-Id: I8a33bd4f4ea189ce9247dfecec1e53001682b870\n'}]",0,763321,414ffbacb7773915f2a5f6dfe127ded15d375f55,14,5,1,20190,,,0,"Fix ""TypeError: format requires a mapping"" in waiters

This is to fix the ""TypeError: format requires a mapping"" in
wait_for_image_imported_to_stores and wait_for_image_copied_to_stores.

Change-Id: I8a33bd4f4ea189ce9247dfecec1e53001682b870
",git fetch https://review.opendev.org/openstack/tempest refs/changes/21/763321/1 && git format-patch -1 --stdout FETCH_HEAD,"['tempest/tests/common/test_waiters.py', 'tempest/common/waiters.py']",2,414ffbacb7773915f2a5f6dfe127ded15d375f55,waiters," message = ('Image %s failed to import on stores: %s' % (image_id, str(image['os_glance_failed_import']))) message = ('Image %s failed to finish the copy operation ' 'on stores: %s' % (image_id, str(store_left)))", message = ('Image %(image_id)s failed to import ' 'on stores: %s' % str(image['os_glance_failed_import'])) message = ('Image %(image_id)s failed to finish the copy operation ' 'on stores: %s' % str(store_left)),54,4
openstack%2Ftripleo-quickstart-extras~master~Iad71c1af41b2039591eccdb420c2a35b05ade4ac,openstack/tripleo-quickstart-extras,master,Iad71c1af41b2039591eccdb420c2a35b05ade4ac,Add native variable to locally build containers,MERGED,2020-09-24 17:25:35.000000000,2020-11-29 00:34:16.000000000,2020-11-29 00:34:16.000000000,"[{'_account_id': 8449}, {'_account_id': 9976}, {'_account_id': 10969}, {'_account_id': 12393}, {'_account_id': 13861}, {'_account_id': 18846}, {'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2020-09-24 17:25:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-quickstart-extras/commit/dfcb7a6166de5c3b6c302b7a46caff5d9550854c', 'message': 'Add native variable to locally build containers\n\natm there is an option to turn on local container\nbuilds for standalone that is defined in zuul only.\nATM we are considering turning this on for all standalone\nmaster jobs to reduce the load on docker.io\n\nChange-Id: Iad71c1af41b2039591eccdb420c2a35b05ade4ac\n'}, {'number': 2, 'created': '2020-11-20 12:03:14.000000000', 'files': ['roles/container-build/defaults/main.yaml', 'roles/extras-common/defaults/main.yml', 'roles/standalone/templates/standalone_config.yaml.j2', 'roles/standalone/tasks/containers.yml'], 'web_link': 'https://opendev.org/openstack/tripleo-quickstart-extras/commit/c0278f637bab07dfa8ee931d74b1282d6e197089', 'message': 'Add native variable to locally build containers\n\natm there is an option to turn on local container\nbuilds for standalone that is defined in zuul only.\nATM we are considering turning this on for all standalone\nmaster jobs to reduce the load on docker.io\n\nChange-Id: Iad71c1af41b2039591eccdb420c2a35b05ade4ac\n'}]",5,754202,c0278f637bab07dfa8ee931d74b1282d6e197089,26,8,2,9592,,,0,"Add native variable to locally build containers

atm there is an option to turn on local container
builds for standalone that is defined in zuul only.
ATM we are considering turning this on for all standalone
master jobs to reduce the load on docker.io

Change-Id: Iad71c1af41b2039591eccdb420c2a35b05ade4ac
",git fetch https://review.opendev.org/openstack/tripleo-quickstart-extras refs/changes/02/754202/1 && git format-patch -1 --stdout FETCH_HEAD,"['roles/extras-common/defaults/main.yml', 'roles/standalone/tasks/containers.yml']",2,dfcb7a6166de5c3b6c302b7a46caff5d9550854c,754202, - build_container_images|default(false)|bool - not build_container_images|default(false)|bool, - job.build_container_images|default(false)|bool - not job.build_container_images|default(false)|bool,7,3
openstack%2Fcharm-percona-cluster~master~Id35b0331322c2744a9f839b3eb153eed1bc53aac,openstack/charm-percona-cluster,master,Id35b0331322c2744a9f839b3eb153eed1bc53aac,NRPE: Monitor threads connected to MySQL.,MERGED,2020-11-04 17:03:30.000000000,2020-11-28 19:31:49.000000000,2020-11-28 19:31:49.000000000,"[{'_account_id': 20648}, {'_account_id': 20870}, {'_account_id': 22348}, {'_account_id': 24890}, {'_account_id': 32363}]","[{'number': 1, 'created': '2020-11-04 17:03:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-percona-cluster/commit/981c2e3f575106890f0cccee482ce1cae1d0be08', 'message': 'Check NRPE of threads connected to MySQL\n\nAdd an NRPE check to check the number of threads connected to the MySQL database.\nWarning and critical percentages can be configured.\n\nChange-Id: Id35b0331322c2744a9f839b3eb153eed1bc53aac\nCloses-Bug: #1816759\n'}, {'number': 2, 'created': '2020-11-06 09:09:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-percona-cluster/commit/5894cf69afea2741bcdd4644a0dbc593bbad78bb', 'message': 'Check NRPE of threads connected to MySQL\n\nAdd an NRPE check to check the number of threads connected to the MySQL database.\nWarning and critical percentages can be configured.\n\nChange-Id: Id35b0331322c2744a9f839b3eb153eed1bc53aac\nCloses-Bug: #1816759\n'}, {'number': 3, 'created': '2020-11-09 13:19:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-percona-cluster/commit/6656dea0089d396ff6ac93af7ca6242766adc653', 'message': 'NRPE: Monitor threads connected to MySQL.\n\nAdd a NRPE check to monitor the number of threads connected\nto the MySQL database, in proportion to the maximum number of connections.\nFor this check, a nagios user will be created. This user has no permission\nset and has access without a password, but only from localhost.\nWarning and Critical thresholds (in percentage) can be configured.\n\nCloses-Bug: #1816759\nChange-Id: Id35b0331322c2744a9f839b3eb153eed1bc53aac\n'}, {'number': 4, 'created': '2020-11-09 13:25:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-percona-cluster/commit/518d75b93246623234ef462c2a8362931d43757f', 'message': 'NRPE: Monitor threads connected to MySQL.\n\nAdd a NRPE check to monitor the number of threads connected\nto the MySQL database, in proportion to the maximum number of connections.\nFor this check, a nagios user will be created. This user has no permission\nset and has access without a password, but only on localhost.\nWarning and Critical thresholds (in percentage) can be configured.\n\nCloses-Bug: #1816759\nChange-Id: Id35b0331322c2744a9f839b3eb153eed1bc53aac\n'}, {'number': 5, 'created': '2020-11-10 17:10:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-percona-cluster/commit/dc88db42e78da4bf5e24a2ce1fb854b2f2bfd0d4', 'message': 'NRPE: Monitor threads connected to MySQL.\n\nAdd a NRPE check to monitor the number of threads connected\nto the MySQL database, in proportion to the maximum number of connections.\nFor this check, a nagios user will be created. This user does not have any\npermissions set, does not have access to any database and can only connect\nfrom localhost.\nWarning and Critical thresholds (in percentage) can be configured.\n\nCloses-Bug: #1816759\nChange-Id: Id35b0331322c2744a9f839b3eb153eed1bc53aac\n'}, {'number': 6, 'created': '2020-11-11 10:59:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-percona-cluster/commit/c2487fae491aa1af9be3b49f1453cad5b232ba18', 'message': 'NRPE: Monitor threads connected to MySQL.\n\nAdd a NRPE check to monitor the number of threads connected\nto the MySQL database, in proportion to the maximum number of connections.\nFor this check, a nagios user will be created. This user does not have any\npermissions set, does not have access to any database and can only connect\nfrom localhost.\nWarning and Critical thresholds (in percentage) can be configured.\n\nCloses-Bug: #1816759\nChange-Id: Id35b0331322c2744a9f839b3eb153eed1bc53aac\n'}, {'number': 7, 'created': '2020-11-12 14:47:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-percona-cluster/commit/c9eae288323d3daa97654bd11e66d3a4c6db7f17', 'message': 'NRPE: Monitor threads connected to MySQL.\n\nAdd a NRPE check to monitor the number of threads connected\nto the MySQL database, in proportion to the maximum number of connections.\nFor this check, a nagios user will be created. This user does not have any\npermissions set, does not have access to any database and can only connect\nfrom localhost.\nWarning and Critical thresholds (in percentage) can be configured.\n\nCloses-Bug: #1816759\nChange-Id: Id35b0331322c2744a9f839b3eb153eed1bc53aac\n'}, {'number': 8, 'created': '2020-11-23 17:17:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-percona-cluster/commit/385c0fc8f94d025ec55c8d1efe44eaeaac6718a8', 'message': 'NRPE: Monitor threads connected to MySQL.\n\nAdd a NRPE check to monitor the number of threads connected\nto the MySQL database, in proportion to the maximum number of connections.\nFor this check, a nagios user will be created. This user does not have any\npermissions set, does not have access to any database and can only connect\nfrom localhost.\nWarning and Critical thresholds (in percentage) can be configured.\n\nCloses-Bug: #1816759\nChange-Id: Id35b0331322c2744a9f839b3eb153eed1bc53aac\n'}, {'number': 9, 'created': '2020-11-25 11:28:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-percona-cluster/commit/be97759101537a7335fe2edfe04b00c2764cb02f', 'message': 'NRPE: Monitor threads connected to MySQL.\n\nAdd a NRPE check to monitor the number of threads connected\nto the MySQL database, in proportion to the maximum number of connections.\nFor this check, a nagios user will be created. This user does not have any\npermissions set, does not have access to any database and can only connect\nfrom localhost.\nWarning and Critical thresholds (in percentage) can be configured.\n\nCloses-Bug: #1816759\nChange-Id: Id35b0331322c2744a9f839b3eb153eed1bc53aac\n'}, {'number': 10, 'created': '2020-11-25 16:19:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-percona-cluster/commit/642b9efc6663d3936fa98c2ffc54cbf47e5260c7', 'message': ""NRPE: Monitor threads connected to MySQL.\n\nAdd a NRPE check to monitor the number of threads connected\nto the MySQL database, in proportion to the maximum number of connections.\nFor this check, a nagios user will be created. This user does not have any\npermissions set, does not have access to any database and can only connect\nfrom localhost.\nWarning and Critical thresholds (in percentage) can be configured.\n\nAdd an action to reset nagios's password. This action could only be run\non the leader unit.\n\nCloses-Bug: #1816759\nChange-Id: Id35b0331322c2744a9f839b3eb153eed1bc53aac\n""}, {'number': 11, 'created': '2020-11-26 14:18:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-percona-cluster/commit/6eaee16823c26c14f2fa66de5ab655c21c7b9c0d', 'message': ""NRPE: Monitor threads connected to MySQL.\n\nAdd a NRPE check to monitor the number of threads connected\nto the MySQL database, in proportion to the maximum number of connections.\nFor this check, a nagios user will be created. This user does not have any\npermissions set, does not have access to any database and can only connect\nfrom localhost.\nWarning and Critical thresholds (in percentage) can be configured.\n\nAdd an action to reset nagios's password. This action could only be run\non the leader unit.\n\nCloses-Bug: #1816759\nChange-Id: Id35b0331322c2744a9f839b3eb153eed1bc53aac\n""}, {'number': 12, 'created': '2020-11-26 15:30:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-percona-cluster/commit/e9d3f44f353541582c89a8619739441213c953f3', 'message': ""NRPE: Monitor threads connected to MySQL.\n\nAdd a NRPE check to monitor the number of threads connected\nto the MySQL database, in proportion to the maximum number of connections.\nFor this check, a nagios user will be created. This user does not have any\npermissions set, does not have access to any database and can only connect\nfrom localhost.\nWarning and Critical thresholds (in percentage) can be configured.\n\nAdd an action to reset nagios's password. This action could only be run\non the leader unit.\n\nCloses-Bug: #1816759\nChange-Id: Id35b0331322c2744a9f839b3eb153eed1bc53aac\n""}, {'number': 13, 'created': '2020-11-27 14:50:02.000000000', 'files': ['unit_tests/test_percona_utils.py', 'actions/generate-nagios-password', 'actions/actions.py', 'unit_tests/test_percona_hooks.py', 'unit_tests/test_actions.py', 'config.yaml', 'templates/nagios-my.cnf', 'hooks/percona_hooks.py', 'README.md', 'hooks/percona_utils.py', 'actions.yaml'], 'web_link': 'https://opendev.org/openstack/charm-percona-cluster/commit/11ee1ef563e3e7a3213fce6ef6151fe5283d0161', 'message': ""NRPE: Monitor threads connected to MySQL.\n\nAdd a NRPE check to monitor the number of threads connected\nto the MySQL database, in proportion to the maximum number of connections.\nFor this check, a nagios user will be created. This user does not have any\npermissions set, does not have access to any database and can only connect\nfrom localhost.\nWarning and Critical thresholds (in percentage) can be configured.\n\nAdd an action to reset nagios's password. This action could only be run\non the leader unit.\n\nCloses-Bug: #1816759\nChange-Id: Id35b0331322c2744a9f839b3eb153eed1bc53aac\n""}]",38,761449,11ee1ef563e3e7a3213fce6ef6151fe5283d0161,78,5,13,32363,,,0,"NRPE: Monitor threads connected to MySQL.

Add a NRPE check to monitor the number of threads connected
to the MySQL database, in proportion to the maximum number of connections.
For this check, a nagios user will be created. This user does not have any
permissions set, does not have access to any database and can only connect
from localhost.
Warning and Critical thresholds (in percentage) can be configured.

Add an action to reset nagios's password. This action could only be run
on the leader unit.

Closes-Bug: #1816759
Change-Id: Id35b0331322c2744a9f839b3eb153eed1bc53aac
",git fetch https://review.opendev.org/openstack/charm-percona-cluster refs/changes/49/761449/3 && git format-patch -1 --stdout FETCH_HEAD,"['unit_tests/test_percona_hooks.py', 'config.yaml', 'hooks/percona_hooks.py']",3,981c2e3f575106890f0cccee482ce1cae1d0be08,bug/1816759," # nagios-plugins-contrib add pmp-check-mysql-status check apt_install('nagios-plugins-contrib') description='Check MySQL process {}'.format(current_unit), warning_threads, critical_threads = \ config('mysql-threads-connected').split(',') nrpe_setup.add_check( shortname='mysql_threads', description='Check MySQL connected threads', check_cmd='pmp-check-mysql-status -l root -p {password} ' '-x Threads_connected -o / -y max_connections -T pct ' '-w {warning} -c {critical}'.format( password=root_password(), warning=warning_threads, critical=critical_threads) )"," description='Check MySQL process {%s}' % current_unit,",46,3
openstack%2Ftripleo-common~stable%2Fussuri~I2238eb33f8d6a8df366bdc908dbbc568500179c0,openstack/tripleo-common,stable/ussuri,I2238eb33f8d6a8df366bdc908dbbc568500179c0,Re-add ndctl to nova-compute image,MERGED,2020-11-16 17:52:01.000000000,2020-11-28 17:29:29.000000000,2020-11-28 17:28:20.000000000,"[{'_account_id': 14985}, {'_account_id': 20172}, {'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2020-11-16 17:52:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-common/commit/6b1eec28a58a515ea59c4025936681ff23f788a1', 'message': 'Re-add ndctl to nova-compute image\n\nWhile ndctl was added to kolla with I8ed1b6c1d0985b2a73206bd9249a5664cd80c912\nthe package is now missing in the tcib created container image. Seems the\nchange got missed on sync to tcib. This fix adds it back to the nova-compute\ncontainer definition.\n\nCloses-Bug: #1904448\n\nChange-Id: I2238eb33f8d6a8df366bdc908dbbc568500179c0\n'}, {'number': 2, 'created': '2020-11-16 18:05:40.000000000', 'files': ['container-images/tcib/base/os/nova-base/nova-compute/nova-compute.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-common/commit/2c6f574c04707515f107087e5be2ed364be89a64', 'message': 'Re-add ndctl to nova-compute image\n\nWhile ndctl was added to kolla with I8ed1b6c1d0985b2a73206bd9249a5664cd80c912\nthe package is now missing in the tcib created container image. Seems the\nchange got missed on sync to tcib. This fix adds it back to the nova-compute\ncontainer definition.\n\nCloses-Bug: #1904448\n\nChange-Id: I2238eb33f8d6a8df366bdc908dbbc568500179c0\n(cherry picked from commit 5a7c14fcabe10bb7946e264483641a9022f6eb1d)\n'}]",0,762901,2c6f574c04707515f107087e5be2ed364be89a64,11,4,2,17216,,,0,"Re-add ndctl to nova-compute image

While ndctl was added to kolla with I8ed1b6c1d0985b2a73206bd9249a5664cd80c912
the package is now missing in the tcib created container image. Seems the
change got missed on sync to tcib. This fix adds it back to the nova-compute
container definition.

Closes-Bug: #1904448

Change-Id: I2238eb33f8d6a8df366bdc908dbbc568500179c0
(cherry picked from commit 5a7c14fcabe10bb7946e264483641a9022f6eb1d)
",git fetch https://review.opendev.org/openstack/tripleo-common refs/changes/01/762901/2 && git format-patch -1 --stdout FETCH_HEAD,['container-images/tcib/base/os/nova-base/nova-compute/nova-compute.yaml'],1,6b1eec28a58a515ea59c4025936681ff23f788a1,re-add_ndctl-stable/victoria-stable/ussuri, - ndctl,,1,0
openstack%2Fansible-role-collect-logs~master~I4bdd9f6f04181f2c76ddf82d47edcee590d2bfde,openstack/ansible-role-collect-logs,master,I4bdd9f6f04181f2c76ddf82d47edcee590d2bfde,Use unittest.mock instead of mock,MERGED,2020-06-08 20:21:58.000000000,2020-11-28 16:35:39.000000000,2020-11-28 16:35:39.000000000,"[{'_account_id': 14985}, {'_account_id': 22348}, {'_account_id': 22873}, {'_account_id': 23181}, {'_account_id': 24162}]","[{'number': 1, 'created': '2020-06-08 20:21:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ansible-role-collect-logs/commit/8efeb7056dea3310e3ccc46c1cd534f549853479', 'message': 'Use unittest.mock instead of mock\n\nThe mock third party library was needed for mock support in py2\nruntimes. Since we now only support py36 and later, we can use the\nstandard lib unittest.mock module instead.\n\nChange-Id: I4bdd9f6f04181f2c76ddf82d47edcee590d2bfde\n'}, {'number': 2, 'created': '2020-11-23 17:53:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ansible-role-collect-logs/commit/09650313f77d76bb63fd74cf62ed6f0c95d7cb29', 'message': 'Use unittest.mock instead of mock\n\nThe mock third party library was needed for mock support in py2\nruntimes. Since we now only support py36 and later, we can use the\nstandard lib unittest.mock module instead.\n\nChange-Id: I4bdd9f6f04181f2c76ddf82d47edcee590d2bfde\n'}, {'number': 3, 'created': '2020-11-26 09:10:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ansible-role-collect-logs/commit/230b3840bf24666d4f09c2874934e01a4956e52f', 'message': 'Use unittest.mock instead of mock\n\nThe mock third party library was needed for mock support in py2\nruntimes. Since we now only support py36 and later, we can use the\nstandard lib unittest.mock module instead.\n\nChange-Id: I4bdd9f6f04181f2c76ddf82d47edcee590d2bfde\n'}, {'number': 4, 'created': '2020-11-27 13:31:33.000000000', 'files': ['tests/common/utils.py', 'test-requirements.txt', 'tox.ini'], 'web_link': 'https://opendev.org/openstack/ansible-role-collect-logs/commit/d4763bcbf46d465f153113c3f3e9a7d3348d3fdd', 'message': 'Use unittest.mock instead of mock\n\nThe mock third party library was needed for mock support in py2\nruntimes. Since we now only support py36 and later, we can use the\nstandard lib unittest.mock module instead.\n\nChange-Id: I4bdd9f6f04181f2c76ddf82d47edcee590d2bfde\n'}]",0,734217,d4763bcbf46d465f153113c3f3e9a7d3348d3fdd,24,5,4,28522,,,0,"Use unittest.mock instead of mock

The mock third party library was needed for mock support in py2
runtimes. Since we now only support py36 and later, we can use the
standard lib unittest.mock module instead.

Change-Id: I4bdd9f6f04181f2c76ddf82d47edcee590d2bfde
",git fetch https://review.opendev.org/openstack/ansible-role-collect-logs refs/changes/17/734217/4 && git format-patch -1 --stdout FETCH_HEAD,['test-requirements.txt'],1,8efeb7056dea3310e3ccc46c1cd534f549853479,drop_mock,,mock,0,1
openstack%2Fnova~master~If0ec11e7b7fcde4dacc57265c4dd77b0f536bfab,openstack/nova,master,If0ec11e7b7fcde4dacc57265c4dd77b0f536bfab,Replace md5 with oslo version,MERGED,2020-10-07 05:51:11.000000000,2020-11-28 14:49:26.000000000,2020-11-28 14:47:43.000000000,"[{'_account_id': 6962}, {'_account_id': 7634}, {'_account_id': 9008}, {'_account_id': 9708}, {'_account_id': 9914}, {'_account_id': 10118}, {'_account_id': 10135}, {'_account_id': 10873}, {'_account_id': 15334}, {'_account_id': 15751}, {'_account_id': 15941}, {'_account_id': 22348}, {'_account_id': 23498}, {'_account_id': 26515}, {'_account_id': 29963}, {'_account_id': 32067}]","[{'number': 1, 'created': '2020-10-07 05:51:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/627d449b0af7d66712c38e381ea42b96f6cd5201', 'message': 'Replace md5 with oslo version\n\nmd5 is not an approved algorithm in FIPS mode, and trying to\ninstantiate a hashlib.md5() will fail when the system is running in\nFIPS mode.\n\nmd5 is allowed when in a non-security context.  There is a plan to\nadd a keyword parameter (usedforsecurity) to hashlib.md5() to annotate\nwhether or not the instance is being used in a security context.\n\nIn the case where it is not, the instantiation of md5 will be allowed.\nSee https://bugs.python.org/issue9216 for more details.\n\nSome downstream python versions already support this parameter.  To\nsupport these versions, a new encapsulation of md5() has been added to\noslo_utils.  See https://review.opendev.org/#/c/750031/\n\nThis patch is to replace the instances of hashlib.md5() with this new\nencapsulation, adding an annotation indicating whether the usage is\na security context or not.\n\nThe instances being replaced here appear to be used to provide\nrepresentations for paths.  There is in fact already a sha256 version\nof get_hash_str that is supposed to be used in security sensitive\nusages.\n\nWith this change (and the related dependent changes), the unit and\nfunctional tests pass when run on a FIPS enabled system.\n\nChange-Id: If0ec11e7b7fcde4dacc57265c4dd77b0f536bfab\nDepends-On: https://review.opendev.org/#/c/756432\nDepends-On: https://review.opendev.org/#/c/756153\n'}, {'number': 2, 'created': '2020-10-29 19:59:40.000000000', 'files': ['requirements.txt', 'nova/tests/unit/test_utils.py', 'lower-constraints.txt', 'nova/utils.py', 'nova/privsep/fs.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/c82ce37635e397d0e3344ff99c971d92f06aa6c5', 'message': 'Replace md5 with oslo version\n\nmd5 is not an approved algorithm in FIPS mode, and trying to\ninstantiate a hashlib.md5() will fail when the system is running in\nFIPS mode.\n\nmd5 is allowed when in a non-security context.  There is a plan to\nadd a keyword parameter (usedforsecurity) to hashlib.md5() to annotate\nwhether or not the instance is being used in a security context.\n\nIn the case where it is not, the instantiation of md5 will be allowed.\nSee https://bugs.python.org/issue9216 for more details.\n\nSome downstream python versions already support this parameter.  To\nsupport these versions, a new encapsulation of md5() has been added to\noslo_utils.  See https://review.opendev.org/#/c/750031/\n\nThis patch is to replace the instances of hashlib.md5() with this new\nencapsulation, adding an annotation indicating whether the usage is\na security context or not.\n\nThe instances being replaced here appear to be used to provide\nrepresentations for paths.  There is in fact already a sha256 version\nof get_hash_str that is supposed to be used in security sensitive\nusages.\n\nWith this change (and the related dependent changes), the unit and\nfunctional tests pass when run on a FIPS enabled system.\n\nChange-Id: If0ec11e7b7fcde4dacc57265c4dd77b0f536bfab\nDepends-On: https://review.opendev.org/#/c/756432\nDepends-On: https://review.opendev.org/#/c/756153\nDepends-On: https://review.opendev.org/#/c/760160\n'}]",5,756434,c82ce37635e397d0e3344ff99c971d92f06aa6c5,54,16,2,9914,,,0,"Replace md5 with oslo version

md5 is not an approved algorithm in FIPS mode, and trying to
instantiate a hashlib.md5() will fail when the system is running in
FIPS mode.

md5 is allowed when in a non-security context.  There is a plan to
add a keyword parameter (usedforsecurity) to hashlib.md5() to annotate
whether or not the instance is being used in a security context.

In the case where it is not, the instantiation of md5 will be allowed.
See https://bugs.python.org/issue9216 for more details.

Some downstream python versions already support this parameter.  To
support these versions, a new encapsulation of md5() has been added to
oslo_utils.  See https://review.opendev.org/#/c/750031/

This patch is to replace the instances of hashlib.md5() with this new
encapsulation, adding an annotation indicating whether the usage is
a security context or not.

The instances being replaced here appear to be used to provide
representations for paths.  There is in fact already a sha256 version
of get_hash_str that is supposed to be used in security sensitive
usages.

With this change (and the related dependent changes), the unit and
functional tests pass when run on a FIPS enabled system.

Change-Id: If0ec11e7b7fcde4dacc57265c4dd77b0f536bfab
Depends-On: https://review.opendev.org/#/c/756432
Depends-On: https://review.opendev.org/#/c/756153
Depends-On: https://review.opendev.org/#/c/760160
",git fetch https://review.opendev.org/openstack/nova refs/changes/34/756434/2 && git format-patch -1 --stdout FETCH_HEAD,"['nova/tests/unit/test_utils.py', 'nova/utils.py', 'nova/privsep/fs.py']",3,627d449b0af7d66712c38e381ea42b96f6cd5201,replace_md5_for_fips,"from oslo_utils.secretutils import md5 return md5(base_str, usedforsecurity=False).hexdigest()",import hashlib return hashlib.md5(base_str).hexdigest(),6,5
openstack%2Ftripleo-heat-templates~stable%2Fussuri~Idc2f9b284471947c098128297d8b796af65fa86d,openstack/tripleo-heat-templates,stable/ussuri,Idc2f9b284471947c098128297d8b796af65fa86d,"[stable/ussuri,train] Add cidr to outputs of port_from_pool.j2",MERGED,2020-11-10 09:23:19.000000000,2020-11-28 14:28:12.000000000,2020-11-28 14:28:12.000000000,"[{'_account_id': 6681}, {'_account_id': 8833}, {'_account_id': 22348}, {'_account_id': 23181}, {'_account_id': 24245}, {'_account_id': 25877}]","[{'number': 1, 'created': '2020-11-10 09:23:19.000000000', 'files': ['network/ports/port_from_pool.j2'], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/013d15f487f611b8b1749313c3bbf53d8222827c', 'message': '[stable/ussuri,train] Add cidr to outputs of port_from_pool.j2\n\nWith change I4e4e5b1195d17f59c825a3f7df73920921e1f86e, we use\ncidr attribute of {{network.name}}Port for ansible vars. However,\nit does not exist in outputs of port_form_pool.2.\n\nNot required in master and stable/victoria.\n\nChange-Id: Idc2f9b284471947c098128297d8b796af65fa86d\nCloses-Bug: #1903666\n'}]",0,762099,013d15f487f611b8b1749313c3bbf53d8222827c,30,6,1,8833,,,0,"[stable/ussuri,train] Add cidr to outputs of port_from_pool.j2

With change I4e4e5b1195d17f59c825a3f7df73920921e1f86e, we use
cidr attribute of {{network.name}}Port for ansible vars. However,
it does not exist in outputs of port_form_pool.2.

Not required in master and stable/victoria.

Change-Id: Idc2f9b284471947c098128297d8b796af65fa86d
Closes-Bug: #1903666
",git fetch https://review.opendev.org/openstack/tripleo-heat-templates refs/changes/99/762099/1 && git format-patch -1 --stdout FETCH_HEAD,['network/ports/port_from_pool.j2'],1,013d15f487f611b8b1749313c3bbf53d8222827c,," cidr: description: CIDR of the ports subnet value: str_split: ['/', {get_param: {{network.name}}NetCidr}, 1]",,4,0
openstack%2Fha-guide~master~Iba51e5e6b7f6036128f2416892b953eefddc4f65,openstack/ha-guide,master,Iba51e5e6b7f6036128f2416892b953eefddc4f65,Updated from openstack-manuals,MERGED,2020-11-28 12:06:27.000000000,2020-11-28 13:23:39.000000000,2020-11-28 13:22:35.000000000,"[{'_account_id': 6547}, {'_account_id': 22348}]","[{'number': 1, 'created': '2020-11-28 12:06:27.000000000', 'files': ['doc/source/common/app-support.rst'], 'web_link': 'https://opendev.org/openstack/ha-guide/commit/ce6945003b24210adc66c1cae712aa6cb02d8c8f', 'message': 'Updated from openstack-manuals\n\nChange-Id: Iba51e5e6b7f6036128f2416892b953eefddc4f65\n'}]",0,764549,ce6945003b24210adc66c1cae712aa6cb02d8c8f,7,2,1,11131,,,0,"Updated from openstack-manuals

Change-Id: Iba51e5e6b7f6036128f2416892b953eefddc4f65
",git fetch https://review.opendev.org/openstack/ha-guide refs/changes/49/764549/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/source/common/app-support.rst'],1,ce6945003b24210adc66c1cae712aa6cb02d8c8f,openstack/openstack-manuals,,* `Bugs: Function engine (qinling) <https://storyboard.openstack.org/#!/project/openstack/qinling>`_ ,0,3
openstack%2Ftripleo-common~stable%2Fvictoria~I2238eb33f8d6a8df366bdc908dbbc568500179c0,openstack/tripleo-common,stable/victoria,I2238eb33f8d6a8df366bdc908dbbc568500179c0,Re-add ndctl to nova-compute image,MERGED,2020-11-16 17:51:51.000000000,2020-11-28 12:30:54.000000000,2020-11-28 12:29:34.000000000,"[{'_account_id': 6681}, {'_account_id': 14985}, {'_account_id': 17216}, {'_account_id': 22348}, {'_account_id': 23181}, {'_account_id': 27478}]","[{'number': 1, 'created': '2020-11-16 17:51:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-common/commit/ffd7fce5b0731466f3d361a895d872d3dde04da5', 'message': 'Re-add ndctl to nova-compute image\n\nWhile ndctl was added to kolla with I8ed1b6c1d0985b2a73206bd9249a5664cd80c912\nthe package is now missing in the tcib created container image. Seems the\nchange got missed on sync to tcib. This fix adds it back to the nova-compute\ncontainer definition.\n\nCloses-Bug: #1904448\n\nChange-Id: I2238eb33f8d6a8df366bdc908dbbc568500179c0\n'}, {'number': 2, 'created': '2020-11-16 18:04:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-common/commit/c34cc0092ead805f7e6b10b3185f021fd00dbbbf', 'message': 'Re-add ndctl to nova-compute image\n\nWhile ndctl was added to kolla with I8ed1b6c1d0985b2a73206bd9249a5664cd80c912\nthe package is now missing in the tcib created container image. Seems the\nchange got missed on sync to tcib. This fix adds it back to the nova-compute\ncontainer definition.\n\nCloses-Bug: #1904448\n\nChange-Id: I2238eb33f8d6a8df366bdc908dbbc568500179c0\n(cherry picked from commit 7556fe80556805cd47f21d5fcec44b7ec900274b)\n'}, {'number': 3, 'created': '2020-11-16 18:05:00.000000000', 'files': ['container-images/tcib/base/os/nova-base/nova-compute/nova-compute.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-common/commit/ac0b7c3d94064ebdcb76ec3490dfc1e4bc64cc6d', 'message': 'Re-add ndctl to nova-compute image\n\nWhile ndctl was added to kolla with I8ed1b6c1d0985b2a73206bd9249a5664cd80c912\nthe package is now missing in the tcib created container image. Seems the\nchange got missed on sync to tcib. This fix adds it back to the nova-compute\ncontainer definition.\n\nCloses-Bug: #1904448\n\nChange-Id: I2238eb33f8d6a8df366bdc908dbbc568500179c0\n(cherry picked from commit 5a7c14fcabe10bb7946e264483641a9022f6eb1d)\n'}]",0,762900,ac0b7c3d94064ebdcb76ec3490dfc1e4bc64cc6d,43,6,3,17216,,,0,"Re-add ndctl to nova-compute image

While ndctl was added to kolla with I8ed1b6c1d0985b2a73206bd9249a5664cd80c912
the package is now missing in the tcib created container image. Seems the
change got missed on sync to tcib. This fix adds it back to the nova-compute
container definition.

Closes-Bug: #1904448

Change-Id: I2238eb33f8d6a8df366bdc908dbbc568500179c0
(cherry picked from commit 5a7c14fcabe10bb7946e264483641a9022f6eb1d)
",git fetch https://review.opendev.org/openstack/tripleo-common refs/changes/00/762900/1 && git format-patch -1 --stdout FETCH_HEAD,['container-images/tcib/base/os/nova-base/nova-compute/nova-compute.yaml'],1,ffd7fce5b0731466f3d361a895d872d3dde04da5,re-add_ndctl-stable/victoria, - ndctl,,1,0
openstack%2Ftripleo-heat-templates~master~If64ff16e2eab7849275dcc88e504477e441e341e,openstack/tripleo-heat-templates,master,If64ff16e2eab7849275dcc88e504477e441e341e,Fix typo in bond options group var name (2/2),MERGED,2020-11-03 02:51:52.000000000,2020-11-28 12:29:38.000000000,2020-11-28 12:29:38.000000000,"[{'_account_id': 4571}, {'_account_id': 8833}, {'_account_id': 22348}, {'_account_id': 23181}, {'_account_id': 24245}]","[{'number': 1, 'created': '2020-11-03 02:51:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/fe43f672b5c76cdbad670cc8e7bef588885d6eaa', 'message': 'Fix typo in bond options group var name (2/2)\n\ns/bound_interface_ovs_options/bond_interface_ovs_options/\n\nDepends-On: https://review.opendev.org/761040\nChange-Id: If64ff16e2eab7849275dcc88e504477e441e341e\n'}, {'number': 2, 'created': '2020-11-09 12:22:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/fc8a19310f203f7c235cd4c273e7e89d2a5ca360', 'message': 'Fix typo in bond options group var name (2/2)\n\ns/bound_interface_ovs_options/bond_interface_ovs_options/\n\nDepends-On: https://review.opendev.org/761040\nChange-Id: If64ff16e2eab7849275dcc88e504477e441e341e\n'}, {'number': 3, 'created': '2020-11-24 15:16:58.000000000', 'files': ['overcloud.j2.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/841ffc0ad3554cb1dd920deeea22a4fd3e141f03', 'message': 'Fix typo in bond options group var name (2/2)\n\ns/bound_interface_ovs_options/bond_interface_ovs_options/\n\nDepends-On: https://review.opendev.org/761040\nChange-Id: If64ff16e2eab7849275dcc88e504477e441e341e\n'}]",0,761041,841ffc0ad3554cb1dd920deeea22a4fd3e141f03,28,5,3,24245,,,0,"Fix typo in bond options group var name (2/2)

s/bound_interface_ovs_options/bond_interface_ovs_options/

Depends-On: https://review.opendev.org/761040
Change-Id: If64ff16e2eab7849275dcc88e504477e441e341e
",git fetch https://review.opendev.org/openstack/tripleo-heat-templates refs/changes/41/761041/1 && git format-patch -1 --stdout FETCH_HEAD,['overcloud.j2.yaml'],1,fe43f672b5c76cdbad670cc8e7bef588885d6eaa,fix-bond-options-typo,, bound_interface_ovs_options: {get_param: BondInterfaceOvsOptions},0,1
openstack%2Fnova~master~I0933447e6caa0013f0b26dbf6532ff1976197e80,openstack/nova,master,I0933447e6caa0013f0b26dbf6532ff1976197e80,zuul: Add devstack-plugin-ceph-compute-local-ephemeral to experimental,MERGED,2020-07-27 13:00:57.000000000,2020-11-28 12:26:45.000000000,2020-11-28 12:22:38.000000000,"[{'_account_id': 7634}, {'_account_id': 9008}, {'_account_id': 9708}, {'_account_id': 9963}, {'_account_id': 10118}, {'_account_id': 10135}, {'_account_id': 14384}, {'_account_id': 14595}, {'_account_id': 15334}, {'_account_id': 15751}, {'_account_id': 15941}, {'_account_id': 22348}, {'_account_id': 23498}, {'_account_id': 26515}, {'_account_id': 29963}]","[{'number': 1, 'created': '2020-07-27 13:00:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/3f6c664bcf7495b26f511808e73685e30506312b', 'message': 'WIP zuul: Enable [glance]/allowed_direct_url_schemes within nova-ceph-multistore\n\nChange-Id: I0933447e6caa0013f0b26dbf6532ff1976197e80\n'}, {'number': 2, 'created': '2020-08-18 19:44:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/cfecb5d18a4317f317d611c512315a08c0bbff54', 'message': 'DNM zuul: Enable [glance]/allowed_direct_url_schemes within nova-ceph-multistore\n\nThis is just for testing I3032bbe6bd2d6acc9ba0f0cac4d00ed4b4464ceb,\nlonger term we might even want a separate job to test this case but for\nnow just exercise the export from rbd into the local imagecache.\n\nChange-Id: I0933447e6caa0013f0b26dbf6532ff1976197e80\n'}, {'number': 3, 'created': '2020-08-19 10:38:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/8b5c1934776c0ade1c493e326e67b2d68d1139f6', 'message': 'DNM zuul: Enable [glance]/allowed_direct_url_schemes within nova-ceph-multistore\n\nThis is just for testing I3032bbe6bd2d6acc9ba0f0cac4d00ed4b4464ceb,\nlonger term we might even want a separate job to test this case but for\nnow just exercise the export from rbd into the local imagecache.\n\nChange-Id: I0933447e6caa0013f0b26dbf6532ff1976197e80\n'}, {'number': 4, 'created': '2020-08-24 15:02:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/284ea5bac9972769ecb71b46a2d16074f3d04546', 'message': 'DNM zuul: Enable [glance]/allowed_direct_url_schemes within nova-ceph-multistore\n\nThis is just for testing I3032bbe6bd2d6acc9ba0f0cac4d00ed4b4464ceb,\nlonger term we might even want a separate job to test this case but for\nnow just exercise the export from rbd into the local imagecache.\n\nChange-Id: I0933447e6caa0013f0b26dbf6532ff1976197e80\n'}, {'number': 5, 'created': '2020-08-26 12:37:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/7a467b8dc910a40b46cf68ab8343622c4b7444c5', 'message': 'zuul: Add devstack-plugin-ceph-compute-qcow2 to experimental queue\n\nThis job tests the recently introduced direct download of rbd hosted\nGlance images into a file based imagecache.\n\nDepends-On: https://review.opendev.org/748212\nChange-Id: I0933447e6caa0013f0b26dbf6532ff1976197e80\n'}, {'number': 6, 'created': '2020-09-03 08:43:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/a297ab89cf62cdd8f19c8975bb601f56dfc97674', 'message': 'zuul: Add devstack-plugin-ceph-compute-local-eph to the experimental queue\n\nThis job tests the recently introduced direct download of rbd hosted\nGlance images into a file based imagecache.\n\nDepends-On: https://review.opendev.org/748212\nChange-Id: I0933447e6caa0013f0b26dbf6532ff1976197e80\n'}, {'number': 7, 'created': '2020-09-03 08:45:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/a86759e2ed8b8e63cc3fb8afc2777882ca4f76e5', 'message': 'zuul: Add devstack-plugin-ceph-compute-local-ephemeral to experimental\n\nThis job tests the recently introduced direct download of rbd hosted\nGlance images into a file based imagecache.\n\nDepends-On: https://review.opendev.org/748212\nChange-Id: I0933447e6caa0013f0b26dbf6532ff1976197e80\n'}, {'number': 8, 'created': '2020-11-19 11:14:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/95b41276346162da391b6756553456dd7eb6c211', 'message': 'zuul: Add devstack-plugin-ceph-compute-local-ephemeral to experimental\n\nThis job tests the recently introduced direct download of rbd hosted\nGlance images into a file based imagecache.\n\nDepends-On: https://review.opendev.org/748212\nChange-Id: I0933447e6caa0013f0b26dbf6532ff1976197e80\n'}, {'number': 9, 'created': '2020-11-27 13:33:41.000000000', 'files': ['.zuul.yaml'], 'web_link': 'https://opendev.org/openstack/nova/commit/7f7a7a163ed0280983bd2a7a34148d6e32d4237e', 'message': 'zuul: Add devstack-plugin-ceph-compute-local-ephemeral to experimental\n\nThis job tests the recently introduced direct download of rbd hosted\nGlance images into a file based imagecache.\n\nDepends-On: https://review.opendev.org/748212\nChange-Id: I0933447e6caa0013f0b26dbf6532ff1976197e80\n'}]",0,743220,7f7a7a163ed0280983bd2a7a34148d6e32d4237e,113,15,9,10135,,,0,"zuul: Add devstack-plugin-ceph-compute-local-ephemeral to experimental

This job tests the recently introduced direct download of rbd hosted
Glance images into a file based imagecache.

Depends-On: https://review.opendev.org/748212
Change-Id: I0933447e6caa0013f0b26dbf6532ff1976197e80
",git fetch https://review.opendev.org/openstack/nova refs/changes/20/743220/3 && git format-patch -1 --stdout FETCH_HEAD,['.zuul.yaml'],1,3f6c664bcf7495b26f511808e73685e30506312b,change-743220-8, glance: allowed_direct_url_schemes: rbd,,2,0
openstack%2Foperations-guide~master~I8d863cd66e1401b4344f6235b6df5d9a51c55083,openstack/operations-guide,master,I8d863cd66e1401b4344f6235b6df5d9a51c55083,Updated from openstack-manuals,MERGED,2020-11-28 12:06:36.000000000,2020-11-28 12:22:53.000000000,2020-11-28 12:21:31.000000000,"[{'_account_id': 11904}, {'_account_id': 22348}]","[{'number': 1, 'created': '2020-11-28 12:06:36.000000000', 'files': ['doc/source/common/app-support.rst'], 'web_link': 'https://opendev.org/openstack/operations-guide/commit/6e29e3240c31329771858aad1c7d1fd28b2db4a9', 'message': 'Updated from openstack-manuals\n\nChange-Id: I8d863cd66e1401b4344f6235b6df5d9a51c55083\n'}]",0,764550,6e29e3240c31329771858aad1c7d1fd28b2db4a9,7,2,1,11131,,,0,"Updated from openstack-manuals

Change-Id: I8d863cd66e1401b4344f6235b6df5d9a51c55083
",git fetch https://review.opendev.org/openstack/operations-guide refs/changes/50/764550/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/source/common/app-support.rst'],1,6e29e3240c31329771858aad1c7d1fd28b2db4a9,openstack/openstack-manuals,,* `Bugs: Function engine (qinling) <https://storyboard.openstack.org/#!/project/openstack/qinling>`_ ,0,3
openstack%2Fopenstack-manuals~master~Ie074fa9a6a55c46470f697ec8cf5daef6bd36360,openstack/openstack-manuals,master,Ie074fa9a6a55c46470f697ec8cf5daef6bd36360,Remove retired Qinling usage,MERGED,2020-11-28 11:40:49.000000000,2020-11-28 12:21:44.000000000,2020-11-28 12:02:42.000000000,"[{'_account_id': 6547}, {'_account_id': 22348}]","[{'number': 1, 'created': '2020-11-28 11:40:49.000000000', 'files': ['doc/common/app-support.rst'], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/204df9e573201d8904a39afb5d54c5b60743b0ee', 'message': 'Remove retired Qinling usage\n\nQinling project is retiring in Wallaby cycle[1].\nThis commit removes the usages of Qinling project\nbefore its code is removed.\n\nNeeded-By: https://review.opendev.org/c/openstack/qinling/+/764521\n\n[1] http://lists.openstack.org/pipermail/openstack-discuss/2020-November/018638.html\n\nChange-Id: Ie074fa9a6a55c46470f697ec8cf5daef6bd36360\nCo-Authored-By: Ghanshyam Mann <gmann@ghanshyammann.com>\n'}]",0,764548,204df9e573201d8904a39afb5d54c5b60743b0ee,7,2,1,6547,,,0,"Remove retired Qinling usage

Qinling project is retiring in Wallaby cycle[1].
This commit removes the usages of Qinling project
before its code is removed.

Needed-By: https://review.opendev.org/c/openstack/qinling/+/764521

[1] http://lists.openstack.org/pipermail/openstack-discuss/2020-November/018638.html

Change-Id: Ie074fa9a6a55c46470f697ec8cf5daef6bd36360
Co-Authored-By: Ghanshyam Mann <gmann@ghanshyammann.com>
",git fetch https://review.opendev.org/openstack/openstack-manuals refs/changes/48/764548/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/common/app-support.rst'],1,204df9e573201d8904a39afb5d54c5b60743b0ee,retire-qinling,,* `Bugs: Function engine (qinling) <https://storyboard.openstack.org/#!/project/openstack/qinling>`_ ,0,3
openstack%2Fnova~master~I5dda9e8bca5fbaae77ece12b67176945ca4d9a4c,openstack/nova,master,I5dda9e8bca5fbaae77ece12b67176945ca4d9a4c,compute: Don't detach volumes when RescheduledException raised without retry,MERGED,2020-10-13 15:25:26.000000000,2020-11-28 11:57:11.000000000,2020-11-28 11:55:12.000000000,"[{'_account_id': 7634}, {'_account_id': 9008}, {'_account_id': 9708}, {'_account_id': 10118}, {'_account_id': 10135}, {'_account_id': 14384}, {'_account_id': 15334}, {'_account_id': 15751}, {'_account_id': 15941}, {'_account_id': 22348}, {'_account_id': 23498}, {'_account_id': 26515}, {'_account_id': 29963}]","[{'number': 1, 'created': '2020-10-13 15:25:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/32f0fe82b776868c8c63557cb0ba71b33a9956c3', 'message': ""compute: Don't detach volumes when RescheduledException raised without retry\n\nI877d8eff8d2fecde0cd16b01e80bff41bdb8d88a introduced a crude call to\n_cleanup_volumes within _do_build_and_run_instance when handling a\nRescheduledException exception raised from _build_and_run_instance\nwithout any retry information provided from the scheduler.\n\nThis situation can arise when using the 'availability_zone' parameter to\nskip the scheduler by providing both a target availability_zone and host\nin the format of `$availability_zone:$host`. If the instance is unable\nto build on the compute the failure will eventually lead to\n_cleanup_volumes calling DriverVolumeBlockDevice.detach that will either\ndetach (cinderv2) or delete the associated volume attachments (cinderv3)\nmoving the volume to an `available` state, assuming it isn't\nmulti-attached etc.\n\nThe issue with this is that this behaviour is in stark contrast to that\nof volumes associated with instances that have failed to schedule. In\nthat case the volumes remain marked as reserved and associated with the\nERROR'd out instance until the instance itself is deleted.\n\nThis change aims to align both cases by removing the call to\n_cleanup_volumes and in doing so keeping any volumes in a `reserved`\nstate until the underlying instance is deleted.\n\nCloses-Bug: #1899649\nChange-Id: I5dda9e8bca5fbaae77ece12b67176945ca4d9a4c\n""}, {'number': 2, 'created': '2020-10-14 08:00:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/b7e87f5f425b68a2d87c4d26a04194563e2a97e3', 'message': ""compute: Don't detach volumes when RescheduledException raised without retry\n\nI877d8eff8d2fecde0cd16b01e80bff41bdb8d88a introduced a crude call to\n_cleanup_volumes within _do_build_and_run_instance when handling a\nRescheduledException exception raised from _build_and_run_instance\nwithout any retry information provided from the scheduler.\n\nThis situation can arise when using the 'availability_zone' parameter to\nskip the scheduler by providing both a target availability_zone and host\nin the format of `$availability_zone:$host`. If the instance is unable\nto build on the compute the failure will eventually lead to\n_cleanup_volumes calling DriverVolumeBlockDevice.detach that will either\ndetach (cinderv2) or delete the associated volume attachments (cinderv3)\nmoving the volume to an `available` state, assuming it isn't\nmulti-attached etc.\n\nThe issue with this is that this behaviour is in stark contrast to that\nof volumes associated with instances that have failed to schedule. In\nthat case the volumes remain marked as reserved and associated with the\nERROR'd out instance until the instance itself is deleted.\n\nThis change aims to align both cases by removing the call to\n_cleanup_volumes and in doing so keeping any volumes in a `reserved`\nstate until the underlying instance is deleted.\n\nCloses-Bug: #1899649\nChange-Id: I5dda9e8bca5fbaae77ece12b67176945ca4d9a4c\n""}, {'number': 3, 'created': '2020-11-25 10:42:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/07fae4e4c25a3091176b02b3687a6ab4393bec99', 'message': ""compute: Don't detach volumes when RescheduledException raised without retry\n\nI8b1c05317734e14ea73dc868941351bb31210bf0 introduced a crude call to\n_cleanup_volumes within _do_build_and_run_instance when handling a\nRescheduledException exception raised from _build_and_run_instance\nwithout any retry information provided from the scheduler.\n\nThis situation can arise when using the 'availability_zone' parameter to\nskip the scheduler by providing both a target availability_zone and host\nin the format of `$availability_zone:$host`. If the instance is unable\nto build on the compute the failure will eventually lead to\n_cleanup_volumes calling DriverVolumeBlockDevice.detach that will either\ndetach (cinderv2) or delete the associated volume attachments (cinderv3)\nmoving the volume to an `available` state, assuming it isn't\nmulti-attached etc.\n\nThe issue with this is that this behaviour is in stark contrast to that\nof volumes associated with instances that have failed to schedule. In\nthat case the volumes remain marked as reserved and associated with the\nERROR'd out instance until the instance itself is deleted.\n\nThis change aims to align both cases by removing the call to\n_cleanup_volumes and in doing so keeping any volumes in a `reserved`\nstate until the underlying instance is deleted.\n\nNote that leaving these volumes associated with ERROR'd out instances is\nnow safe after I4dc6c8bd3bb6c135f8a698af41f5d0e026c39117 landed and now\nensures that ports and volumes associated with such an instance are\ncorrectly cleaned up.\n\nCloses-Bug: #1899649\nChange-Id: I5dda9e8bca5fbaae77ece12b67176945ca4d9a4c\n""}, {'number': 4, 'created': '2020-11-27 13:32:55.000000000', 'files': ['nova/tests/unit/compute/test_compute_mgr.py', 'nova/tests/functional/regressions/test_bug_1899649.py', 'nova/compute/manager.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/26c46a409fa3a75f11fe0ecfc3cf1a8e77da8f51', 'message': ""compute: Don't detach volumes when RescheduledException raised without retry\n\nI8b1c05317734e14ea73dc868941351bb31210bf0 introduced a crude call to\n_cleanup_volumes within _do_build_and_run_instance when handling a\nRescheduledException exception raised from _build_and_run_instance\nwithout any retry information provided from the scheduler.\n\nThis situation can arise when using the 'availability_zone' parameter to\nskip the scheduler by providing both a target availability_zone and host\nin the format of `$availability_zone:$host`. If the instance is unable\nto build on the compute the failure will eventually lead to\n_cleanup_volumes calling DriverVolumeBlockDevice.detach that will either\ndetach (cinderv2) or delete the associated volume attachments (cinderv3)\nmoving the volume to an `available` state, assuming it isn't\nmulti-attached etc.\n\nThe issue with this is that this behaviour is in stark contrast to that\nof volumes associated with instances that have failed to schedule. In\nthat case the volumes remain marked as reserved and associated with the\nERROR'd out instance until the instance itself is deleted.\n\nThis change aims to align both cases by removing the call to\n_cleanup_volumes and in doing so keeping any volumes in a `reserved`\nstate until the underlying instance is deleted.\n\nNote that leaving these volumes associated with ERROR'd out instances is\nnow safe after I4dc6c8bd3bb6c135f8a698af41f5d0e026c39117 landed and now\nensures that ports and volumes associated with such an instance are\ncorrectly cleaned up.\n\nCloses-Bug: #1899649\nChange-Id: I5dda9e8bca5fbaae77ece12b67176945ca4d9a4c\n""}]",8,757894,26c46a409fa3a75f11fe0ecfc3cf1a8e77da8f51,72,13,4,10135,,,0,"compute: Don't detach volumes when RescheduledException raised without retry

I8b1c05317734e14ea73dc868941351bb31210bf0 introduced a crude call to
_cleanup_volumes within _do_build_and_run_instance when handling a
RescheduledException exception raised from _build_and_run_instance
without any retry information provided from the scheduler.

This situation can arise when using the 'availability_zone' parameter to
skip the scheduler by providing both a target availability_zone and host
in the format of `$availability_zone:$host`. If the instance is unable
to build on the compute the failure will eventually lead to
_cleanup_volumes calling DriverVolumeBlockDevice.detach that will either
detach (cinderv2) or delete the associated volume attachments (cinderv3)
moving the volume to an `available` state, assuming it isn't
multi-attached etc.

The issue with this is that this behaviour is in stark contrast to that
of volumes associated with instances that have failed to schedule. In
that case the volumes remain marked as reserved and associated with the
ERROR'd out instance until the instance itself is deleted.

This change aims to align both cases by removing the call to
_cleanup_volumes and in doing so keeping any volumes in a `reserved`
state until the underlying instance is deleted.

Note that leaving these volumes associated with ERROR'd out instances is
now safe after I4dc6c8bd3bb6c135f8a698af41f5d0e026c39117 landed and now
ensures that ports and volumes associated with such an instance are
correctly cleaned up.

Closes-Bug: #1899649
Change-Id: I5dda9e8bca5fbaae77ece12b67176945ca4d9a4c
",git fetch https://review.opendev.org/openstack/nova refs/changes/94/757894/1 && git format-patch -1 --stdout FETCH_HEAD,"['nova/tests/unit/compute/test_compute_mgr.py', 'nova/tests/functional/regressions/test_bug_1899649.py', 'nova/compute/manager.py']",3,32f0fe82b776868c8c63557cb0ba71b33a9956c3,bug/1899649,," self._cleanup_volumes(context, instance, block_device_mapping, raise_exc=False)",2,18
openstack%2Fsecurity-doc~master~Iffd7a8d5ab87d34198862c925b894e4095d6e7f4,openstack/security-doc,master,Iffd7a8d5ab87d34198862c925b894e4095d6e7f4,Remove retired Qinling usage,MERGED,2020-11-28 06:09:46.000000000,2020-11-28 11:42:09.000000000,2020-11-28 11:37:11.000000000,"[{'_account_id': 6547}, {'_account_id': 22348}]","[{'number': 1, 'created': '2020-11-28 06:09:46.000000000', 'files': ['common/app-support.rst'], 'web_link': 'https://opendev.org/openstack/security-doc/commit/c2c1509820e24cdb0845420d6b6e77b5db1f8d2a', 'message': 'Remove retired Qinling usage\n\nQinling project is retiring in Wallaby cycle[1].\nThis commit removes the usages of Qinling project\nbefore its code is removed.\n\nNeeded-By: https://review.opendev.org/c/openstack/qinling/+/764521\n\n[1] http://lists.openstack.org/pipermail/openstack-discuss/2020-November/018638.html\n\nChange-Id: Iffd7a8d5ab87d34198862c925b894e4095d6e7f4\n'}]",0,764542,c2c1509820e24cdb0845420d6b6e77b5db1f8d2a,9,2,1,8556,,,0,"Remove retired Qinling usage

Qinling project is retiring in Wallaby cycle[1].
This commit removes the usages of Qinling project
before its code is removed.

Needed-By: https://review.opendev.org/c/openstack/qinling/+/764521

[1] http://lists.openstack.org/pipermail/openstack-discuss/2020-November/018638.html

Change-Id: Iffd7a8d5ab87d34198862c925b894e4095d6e7f4
",git fetch https://review.opendev.org/openstack/security-doc refs/changes/42/764542/1 && git format-patch -1 --stdout FETCH_HEAD,['common/app-support.rst'],1,c2c1509820e24cdb0845420d6b6e77b5db1f8d2a,retire-qinling,,* `Bugs: Function engine (qinling) <https://storyboard.openstack.org/#!/project/openstack/qinling>`_ ,0,3
openstack%2Foperations-guide~master~I8c21a8bc184ccb8ef7e2d8bd30cf4c30613b2efc,openstack/operations-guide,master,I8c21a8bc184ccb8ef7e2d8bd30cf4c30613b2efc,Remove retired Qinling usage,ABANDONED,2020-11-28 06:10:18.000000000,2020-11-28 11:41:31.000000000,,"[{'_account_id': 6547}, {'_account_id': 22348}]","[{'number': 1, 'created': '2020-11-28 06:10:18.000000000', 'files': ['doc/source/common/app-support.rst'], 'web_link': 'https://opendev.org/openstack/operations-guide/commit/ed32acd0cb92356aff1d00ebd9cfea526b8d969e', 'message': 'Remove retired Qinling usage\n\nQinling project is retiring in Wallaby cycle[1].\nThis commit removes the usages of Qinling project\nbefore its code is removed.\n\nNeeded-By: https://review.opendev.org/c/openstack/qinling/+/764521\n\n[1] http://lists.openstack.org/pipermail/openstack-discuss/2020-November/018638.html\n\nChange-Id: I8c21a8bc184ccb8ef7e2d8bd30cf4c30613b2efc\n'}]",1,764543,ed32acd0cb92356aff1d00ebd9cfea526b8d969e,8,2,1,8556,,,0,"Remove retired Qinling usage

Qinling project is retiring in Wallaby cycle[1].
This commit removes the usages of Qinling project
before its code is removed.

Needed-By: https://review.opendev.org/c/openstack/qinling/+/764521

[1] http://lists.openstack.org/pipermail/openstack-discuss/2020-November/018638.html

Change-Id: I8c21a8bc184ccb8ef7e2d8bd30cf4c30613b2efc
",git fetch https://review.opendev.org/openstack/operations-guide refs/changes/43/764543/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/source/common/app-support.rst'],1,ed32acd0cb92356aff1d00ebd9cfea526b8d969e,retire-qinling,,* `Bugs: Function engine (qinling) <https://storyboard.openstack.org/#!/project/openstack/qinling>`_ ,0,3
openstack%2Ftrove~master~If129aef794c9b2e547c0a3acfc6855c3506cf930,openstack/trove,master,If129aef794c9b2e547c0a3acfc6855c3506cf930,Use current slave_pos of slave to continue replicate,MERGED,2020-11-16 11:00:22.000000000,2020-11-28 11:28:08.000000000,2020-11-28 11:26:47.000000000,"[{'_account_id': 6732}, {'_account_id': 22348}]","[{'number': 1, 'created': '2020-11-16 11:00:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/trove/commit/0e87d5b4e714f5929bebc765323c05be89623643', 'message': 'get_replica_context before make read only False\n\nIf we get_replica_context after make_read_only(False), users can write to\ndatabase during that time. This causes the replica to not have sufficient data\n\nChange-Id: If129aef794c9b2e547c0a3acfc6855c3506cf930\n'}, {'number': 2, 'created': '2020-11-20 02:51:05.000000000', 'files': ['trove/guestagent/strategies/replication/mariadb_gtid.py'], 'web_link': 'https://opendev.org/openstack/trove/commit/8987244c407b7dcb13dec1f20d3cc8a2c82c4dcd', 'message': ""Use current slave_pos of slave to continue replicate\n\nBecause gtid is global and all operation are write to binlog, so incase\nchange to new master, we just use current slave_pos of slave, the slave\nwill just continue from the appropriate point in the new master's binlog.\n\nStory: #2008376\nTask: #41294\nChange-Id: If129aef794c9b2e547c0a3acfc6855c3506cf930\n""}]",0,762822,8987244c407b7dcb13dec1f20d3cc8a2c82c4dcd,9,2,2,31662,,,0,"Use current slave_pos of slave to continue replicate

Because gtid is global and all operation are write to binlog, so incase
change to new master, we just use current slave_pos of slave, the slave
will just continue from the appropriate point in the new master's binlog.

Story: #2008376
Task: #41294
Change-Id: If129aef794c9b2e547c0a3acfc6855c3506cf930
",git fetch https://review.opendev.org/openstack/trove refs/changes/22/762822/1 && git format-patch -1 --stdout FETCH_HEAD,"['trove/taskmanager/manager.py', 'trove/taskmanager/models.py', 'trove/tests/unittests/taskmanager/test_models.py']",3,0e87d5b4e714f5929bebc765323c05be89623643,," self.instance_task.attach_replica(master.id, replica_context)", self.instance_task.attach_replica(master),11,8
openstack%2Ftripleo-common~master~Idfebf62e0e10b709367cfcb6977cf18550a4a4b0,openstack/tripleo-common,master,Idfebf62e0e10b709367cfcb6977cf18550a4a4b0,Fix handling of default_tag,MERGED,2020-09-04 21:54:38.000000000,2020-11-28 11:08:11.000000000,2020-11-28 11:04:41.000000000,"[{'_account_id': 3153}, {'_account_id': 6926}, {'_account_id': 7144}, {'_account_id': 14985}, {'_account_id': 20733}, {'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2020-09-04 21:54:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-common/commit/b744db900f51416da25ccf923b2105f43f528720', 'message': 'Fix handling of default_tag\n\nThe previous fix, 589ac8ac0d5a14ce4aa831892d3b0a4a31e29674 was not fully\nworking as intended because during the templating of the container image\nprepare entry, the setting for default_tag was being lost.\n\nThis fix simplifies the handling by just checking the initial\nmapping_args for the presence of a tag key to determine if the\ndefault_tag flag should be set.\n\nChange-Id: Idfebf62e0e10b709367cfcb6977cf18550a4a4b0\nPartial-Bug: #1886547\nSigned-off-by: James Slagle <jslagle@redhat.com>\n'}, {'number': 2, 'created': '2020-11-04 13:28:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-common/commit/1fc72314137c374b4b9c95d4a829e7c155724a57', 'message': 'Fix handling of default_tag\n\nThe previous fix, 589ac8ac0d5a14ce4aa831892d3b0a4a31e29674 was not fully\nworking as intended because during the templating of the container image\nprepare entry, the setting for default_tag was being lost.\n\nThis fix simplifies the handling by just checking the initial\nmapping_args for the presence of a tag key to determine if the\ndefault_tag flag should be set.\n\nChange-Id: Idfebf62e0e10b709367cfcb6977cf18550a4a4b0\nPartial-Bug: #1886547\nSigned-off-by: James Slagle <jslagle@redhat.com>\n'}, {'number': 3, 'created': '2020-11-23 14:56:06.000000000', 'files': ['tripleo_common/tests/image/test_image_uploader.py', 'container-images/container_image_prepare_defaults.yaml', 'tripleo_common/image/kolla_builder.py', 'tripleo_common/image/image_uploader.py', 'tripleo_common/tests/image/test_kolla_builder.py'], 'web_link': 'https://opendev.org/openstack/tripleo-common/commit/b4275c7b40d4546e004b70f404cb6ae11f864544', 'message': 'Fix handling of default_tag\n\nThe previous fix, 589ac8ac0d5a14ce4aa831892d3b0a4a31e29674 was not fully\nworking as intended because during the templating of the container image\nprepare entry, the setting for default_tag was being lost.\n\nThis fix simplifies the handling by just checking the initial\nmapping_args for the presence of a tag key to determine if the\ndefault_tag flag should be set.\n\nChange-Id: Idfebf62e0e10b709367cfcb6977cf18550a4a4b0\nPartial-Bug: #1886547\nSigned-off-by: James Slagle <jslagle@redhat.com>\n'}]",0,750054,b4275c7b40d4546e004b70f404cb6ae11f864544,41,7,3,7144,,,0,"Fix handling of default_tag

The previous fix, 589ac8ac0d5a14ce4aa831892d3b0a4a31e29674 was not fully
working as intended because during the templating of the container image
prepare entry, the setting for default_tag was being lost.

This fix simplifies the handling by just checking the initial
mapping_args for the presence of a tag key to determine if the
default_tag flag should be set.

Change-Id: Idfebf62e0e10b709367cfcb6977cf18550a4a4b0
Partial-Bug: #1886547
Signed-off-by: James Slagle <jslagle@redhat.com>
",git fetch https://review.opendev.org/openstack/tripleo-common refs/changes/54/750054/1 && git format-patch -1 --stdout FETCH_HEAD,"['container-images/container_image_prepare_defaults.yaml', 'tripleo_common/tests/image/test_image_uploader.py', 'tripleo_common/image/kolla_builder.py', 'tripleo_common/image/image_uploader.py', 'tripleo_common/tests/image/test_kolla_builder.py']",5,b744db900f51416da25ccf923b2105f43f528720,default_tag," @mock.patch.object(image_uploader, 'ImageUploadManager') @mock.patch('tripleo_common.image.kolla_builder.' 'detect_insecure_registries', return_value={}) def test_prepare_default_tag(self, mock_insecure, mock_manager): mock_manager_instance = mock.Mock() mock_manager.return_value = mock_manager_instance mock_uploader = mock.Mock() mock_uploader.discover_image_tags.return_value = [] mock_manager_instance.uploader.return_value = mock_uploader kb.container_images_prepare( template_file=TEMPLATE_PATH, output_env_file=constants.CONTAINER_DEFAULTS_ENVIRONMENT, output_images_file='container_images.yaml', mapping_args={}, tag_from_label=""n-v"", ) self.assertTrue( mock_uploader.discover_image_tags.call_args_list[0][0][2]) kb.container_images_prepare( template_file=TEMPLATE_PATH, output_env_file=constants.CONTAINER_DEFAULTS_ENVIRONMENT, output_images_file='container_images.yaml', mapping_args={""tag"": ""master""}, tag_from_label=""n-v"", ) self.assertFalse( mock_uploader.discover_image_tags.call_args_list[1][0][2]) "," 'default_tag': True, 'default_tag': False,",120,13
openstack%2Ftripleo-ci~master~Ie1924646efd7333ce84b2a4a18c2cfc80edb7d51,openstack/tripleo-ci,master,Ie1924646efd7333ce84b2a4a18c2cfc80edb7d51,Run only needed playbooks in undercloud jobs,MERGED,2020-11-20 08:14:43.000000000,2020-11-28 11:04:36.000000000,2020-11-28 11:04:36.000000000,"[{'_account_id': 8449}, {'_account_id': 9592}, {'_account_id': 10969}, {'_account_id': 12393}, {'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2020-11-20 08:14:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ci/commit/7802f89c305bc265e9201f0b04aacc81dfd5863f', 'message': 'Run only needed playbooks in undercloud jobs\n\nIn these jobs overcloud and upgrade playbooks also\nruns which is not needed in undercloud jobs, so\nlet\'s set the playbooks var to run only the needed\nplaybooks.\n\nUntil https://review.opendev.org/#/c/759912/\nmerged it was not an issue as due to ""tags"" tasks\nused to skip in the extra playbooks.\n\nChange-Id: Ie1924646efd7333ce84b2a4a18c2cfc80edb7d51\n'}, {'number': 2, 'created': '2020-11-20 08:34:56.000000000', 'files': ['zuul.d/undercloud-jobs.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-ci/commit/b677d24524e246bd2ad8d4c76cc381fb7437b23a', 'message': 'Run only needed playbooks in undercloud jobs\n\nIn these jobs overcloud and upgrade playbooks also\nruns which is not needed in undercloud jobs, so\nlet\'s set the playbooks var to run only the needed\nplaybooks.\n\nUntil https://review.opendev.org/#/c/759912/\nmerged it was not an issue as due to ""tags"" tasks\nused to skip in the extra playbooks.\n\nDepends-On: https://review.opendev.org/#/c/763519/\nChange-Id: Ie1924646efd7333ce84b2a4a18c2cfc80edb7d51\n'}]",1,763518,b677d24524e246bd2ad8d4c76cc381fb7437b23a,12,6,2,13861,,,0,"Run only needed playbooks in undercloud jobs

In these jobs overcloud and upgrade playbooks also
runs which is not needed in undercloud jobs, so
let's set the playbooks var to run only the needed
playbooks.

Until https://review.opendev.org/#/c/759912/
merged it was not an issue as due to ""tags"" tasks
used to skip in the extra playbooks.

Depends-On: https://review.opendev.org/#/c/763519/
Change-Id: Ie1924646efd7333ce84b2a4a18c2cfc80edb7d51
",git fetch https://review.opendev.org/openstack/tripleo-ci refs/changes/18/763518/1 && git format-patch -1 --stdout FETCH_HEAD,['zuul.d/undercloud-jobs.yaml'],1,7802f89c305bc265e9201f0b04aacc81dfd5863f,, playbooks: - quickstart.yml - multinode-undercloud.yml - multinode-validate.yml playbooks: - quickstart.yml - multinode-undercloud.yml - multinode-validate.yml playbooks: - quickstart.yml - multinode-undercloud.yml - multinode-validate.yml,,12,0
openstack%2Ftripleo-ci~master~I87134ce3b42bb1f84c7928343bc11f1d5816630d,openstack/tripleo-ci,master,I87134ce3b42bb1f84c7928343bc11f1d5816630d,Restore irrelevant-files to avoid running extra jobs,MERGED,2020-11-20 08:31:04.000000000,2020-11-28 11:04:33.000000000,2020-11-28 11:04:33.000000000,"[{'_account_id': 8449}, {'_account_id': 9592}, {'_account_id': 12393}, {'_account_id': 13861}, {'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2020-11-20 08:31:04.000000000', 'files': ['zuul.d/undercloud-jobs.yaml', 'zuul.d/multinode-jobs.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-ci/commit/55277e9ab2a5faea4907d5c94e2b3519369de277', 'message': 'Restore irrelevant-files to avoid running extra jobs\n\nIt was removed from irrelevant files list in\nhttps://review.opendev.org/#/c/759985/.\n\nChange-Id: I87134ce3b42bb1f84c7928343bc11f1d5816630d\n'}]",4,763519,55277e9ab2a5faea4907d5c94e2b3519369de277,33,6,1,13861,,,0,"Restore irrelevant-files to avoid running extra jobs

It was removed from irrelevant files list in
https://review.opendev.org/#/c/759985/.

Change-Id: I87134ce3b42bb1f84c7928343bc11f1d5816630d
",git fetch https://review.opendev.org/openstack/tripleo-ci refs/changes/19/763519/1 && git format-patch -1 --stdout FETCH_HEAD,"['zuul.d/undercloud-jobs.yaml', 'zuul.d/multinode-jobs.yaml']",2,55277e9ab2a5faea4907d5c94e2b3519369de277,, - zuul.d/layout.yaml - zuul.d/undercloud-jobs.yaml,,3,0
openstack%2Frequirements~master~I0e15eeefa3fb8af0e307b8724dc3d749fa3870d0,openstack/requirements,master,I0e15eeefa3fb8af0e307b8724dc3d749fa3870d0,manual update because bot is not running,MERGED,2020-11-27 23:29:08.000000000,2020-11-28 10:06:28.000000000,2020-11-28 10:05:20.000000000,"[{'_account_id': 11904}, {'_account_id': 22348}]","[{'number': 1, 'created': '2020-11-27 23:29:08.000000000', 'files': ['upper-constraints.txt'], 'web_link': 'https://opendev.org/openstack/requirements/commit/f74b67ac0a5a42e7f933c5cc75201e835d3413a7', 'message': 'manual update because bot is not running\n\nChange-Id: I0e15eeefa3fb8af0e307b8724dc3d749fa3870d0\n'}]",0,764495,f74b67ac0a5a42e7f933c5cc75201e835d3413a7,13,2,1,14288,,,0,"manual update because bot is not running

Change-Id: I0e15eeefa3fb8af0e307b8724dc3d749fa3870d0
",git fetch https://review.opendev.org/openstack/requirements refs/changes/95/764495/1 && git format-patch -1 --stdout FETCH_HEAD,['upper-constraints.txt'],1,f74b67ac0a5a42e7f933c5cc75201e835d3413a7,manual-update-20201127,restructuredtext-lint===1.3.2lxml===4.6.2setproctitle===1.2pyserial===3.5pyOpenSSL===19.1.0;python_version=='3.6' pyOpenSSL===20.0.0;python_version=='3.8'httpcore===0.12.2importlib-metadata===3.1.0;python_version=='3.6'boto3===1.16.25 jeepney===0.6.0 stestr===3.1.0natsort===7.1.0SecretStorage===3.3.0 opentracing===2.4.0pytest-metadata===1.11.0dogpile.cache===1.1.1botocore===1.19.25jsonpatch===1.27dulwich===0.20.14yappi===1.3.2diskimage-builder===3.4.0docker===4.4.0 storops===1.2.8cffi===1.14.4virtualenv===20.2.1,restructuredtext-lint===1.3.1lxml===4.6.1setproctitle===1.1.10pyserial===3.4pyOpenSSL===19.1.0httpcore===0.12.1importlib-metadata===2.0.0;python_version=='3.6'boto3===1.16.21 jeepney===0.5.0 stestr===3.0.1natsort===7.0.1SecretStorage===3.2.0 opentracing===2.3.0pytest-metadata===1.10.0dogpile.cache===1.1.0botocore===1.19.21jsonpatch===1.26dulwich===0.20.11yappi===1.3.0diskimage-builder===3.3.1docker===4.3.1 storops===1.2.7cffi===1.14.3virtualenv===20.1.0,25,24
openstack%2Fnova~stable%2Ftrain~I83817f7301680801beaee375825f02eda526eda1,openstack/nova,stable/train,I83817f7301680801beaee375825f02eda526eda1,Validate id as integer for os-aggregates,MERGED,2020-11-27 12:22:59.000000000,2020-11-28 07:38:52.000000000,2020-11-28 07:36:40.000000000,"[{'_account_id': 7634}, {'_account_id': 10135}, {'_account_id': 17685}, {'_account_id': 22348}, {'_account_id': 26250}]","[{'number': 1, 'created': '2020-11-27 12:22:59.000000000', 'files': ['nova/tests/unit/api/openstack/compute/test_aggregates.py', 'nova/api/openstack/compute/aggregates.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/4653245ddcf989ebac4b964a41d881d78cf9ae2c', 'message': 'Validate id as integer for os-aggregates\n\nAccording to the api-ref, the id passed to calls in os-aggregates is\nsupposed to be an integer. No function validated this, so any value\npassed to these functions would directly reach the DB. While this is\nfine for SQLite, making a query with a string for an integer column on\nother databases like PostgreSQL results in a DBError exception and thus\na HTTP 500 instead of 400 or 404.\n\nThis commit adds validation for the id parameter the same way it\'s\nalready done for other endpoints.\n\nConflicts:\n  nova/api/openstack/compute/aggregates.py\n\nChanges:\n  nova/tests/unit/api/openstack/compute/test_aggregates.py\n\nNOTE(stephenfin): Conflicts are due to absence of change\nI4ab96095106b38737ed355fcad07e758f8b5a9b0 (""Add image caching API for\naggregates"") which we don\'t want to backport. A test related to this\nfeature must also be removed.\n\nChange-Id: I83817f7301680801beaee375825f02eda526eda1\nCloses-Bug: 1865040\n(cherry picked from commit 2e70a1717f25652912886cbefa3f40e6df908c00)\n'}]",1,764455,4653245ddcf989ebac4b964a41d881d78cf9ae2c,17,5,1,15334,,,0,"Validate id as integer for os-aggregates

According to the api-ref, the id passed to calls in os-aggregates is
supposed to be an integer. No function validated this, so any value
passed to these functions would directly reach the DB. While this is
fine for SQLite, making a query with a string for an integer column on
other databases like PostgreSQL results in a DBError exception and thus
a HTTP 500 instead of 400 or 404.

This commit adds validation for the id parameter the same way it's
already done for other endpoints.

Conflicts:
  nova/api/openstack/compute/aggregates.py

Changes:
  nova/tests/unit/api/openstack/compute/test_aggregates.py

NOTE(stephenfin): Conflicts are due to absence of change
I4ab96095106b38737ed355fcad07e758f8b5a9b0 (""Add image caching API for
aggregates"") which we don't want to backport. A test related to this
feature must also be removed.

Change-Id: I83817f7301680801beaee375825f02eda526eda1
Closes-Bug: 1865040
(cherry picked from commit 2e70a1717f25652912886cbefa3f40e6df908c00)
",git fetch https://review.opendev.org/openstack/nova refs/changes/55/764455/1 && git format-patch -1 --stdout FETCH_HEAD,"['nova/tests/unit/api/openstack/compute/test_aggregates.py', 'nova/api/openstack/compute/aggregates.py']",2,4653245ddcf989ebac4b964a41d881d78cf9ae2c,bug/1865040,"from nova import utils @wsgi.expected_errors((400, 404)) try: utils.validate_integer(id, 'id') except exception.InvalidInput as e: raise exc.HTTPBadRequest(explanation=e.format_message()) utils.validate_integer(id, 'id') except exception.InvalidInput as e: raise exc.HTTPBadRequest(explanation=e.format_message()) try: try: utils.validate_integer(id, 'id') except exception.InvalidInput as e: raise exc.HTTPBadRequest(explanation=e.format_message()) @wsgi.expected_errors((400, 404, 409)) try: utils.validate_integer(id, 'id') except exception.InvalidInput as e: raise exc.HTTPBadRequest(explanation=e.format_message()) @wsgi.expected_errors((400, 404, 409)) try: utils.validate_integer(id, 'id') except exception.InvalidInput as e: raise exc.HTTPBadRequest(explanation=e.format_message()) try: utils.validate_integer(id, 'id') except exception.InvalidInput as e: raise exc.HTTPBadRequest(explanation=e.format_message()) "," @wsgi.expected_errors(404) @wsgi.expected_errors((404, 409)) @wsgi.expected_errors((404, 409))",85,21
openstack%2Ftripleo-ansible~master~I19a011bfbbcdbacbe257625310490077755a8b70,openstack/tripleo-ansible,master,I19a011bfbbcdbacbe257625310490077755a8b70,networks_lower group_var replace role_networks_lower,MERGED,2020-11-19 04:12:07.000000000,2020-11-28 06:32:47.000000000,2020-11-28 06:32:47.000000000,"[{'_account_id': 8833}, {'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2020-11-19 04:12:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ansible/commit/0531405610214c722d8403032eb74286e84d5887', 'message': ""Use 'external_mtu' group_var for external_bridge\n\nUse the 'external_mtu' group_var directly for the\nexternal_bridge interface on DVR compute nodes that\ndo not have the 'External' network associated with\nthe role.\n\nThe lookup via role_networks_lower fail's since the\n'External' network is'nt associated.\n\nAlso if the 'External' network is associated with the\nrole set the address and routes.\n\nFor the mutliple_nic_vlans add address and routes and\nthe vlan member interface on the bridge.\n\nDepends-On: https://review.opendev.org/763301\nCloses-Bug: #1904809\nChange-Id: I19a011bfbbcdbacbe257625310490077755a8b70\n""}, {'number': 2, 'created': '2020-11-19 14:07:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ansible/commit/8e14a22c46738fc8d115d7b0410b7cc3c18b4231', 'message': ""networks_lower group_var replace role_networks_lower\n\nThe 'networks_lower' group_var carries a mapping of\nnetwork.name to network.name_lower for all networks.\n\nThe external_bridge interface on DVR compute nodes\nthat do not have the 'External' network associated\nwith the role still need to be able to lookup the\nname_lower for the 'External' network.\n\nThe lookup via role_networks_lower fail's since the\n'External' network is'nt associated.\n\nAlso if the 'External' network is associated with the\nrole set the address and routes.\n\nFor the mutliple_nic_vlans add address and routes and\nthe vlan member interface on the bridge.\n\nDepends-On: https://review.opendev.org/763301\nCloses-Bug: #1904809\nChange-Id: I19a011bfbbcdbacbe257625310490077755a8b70\n""}, {'number': 3, 'created': '2020-11-19 14:38:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ansible/commit/39d5bb57f8b0e616ef0c6f2331aa1402c3108059', 'message': ""networks_lower group_var replace role_networks_lower\n\nThe 'networks_lower' group_var carries a mapping of\nnetwork.name to network.name_lower for all networks.\n\nThe external_bridge interface on DVR compute nodes\nthat do not have the 'External' network associated\nwith the role still need to be able to lookup the\nname_lower for the 'External' network.\n\nThe lookup via role_networks_lower fail's since the\n'External' network is'nt associated.\n\nAlso if the 'External' network is associated with the\nrole set the address and routes.\n\nFor the mutliple_nic_vlans add address and routes and\nthe vlan member interface on the bridge.\n\nDepends-On: https://review.opendev.org/763301\nCloses-Bug: #1904809\nChange-Id: I19a011bfbbcdbacbe257625310490077755a8b70\n""}, {'number': 4, 'created': '2020-11-20 02:48:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ansible/commit/00b29f78bb4de7f50ee095743fee561806814fc7', 'message': ""networks_lower group_var replace role_networks_lower\n\nThe 'networks_lower' group_var carries a mapping of\nnetwork.name to network.name_lower for all networks.\n\nThe external_bridge interface on DVR compute nodes\nthat do not have the 'External' network associated\nwith the role still need to be able to lookup the\nname_lower for the 'External' network.\n\nThe lookup via role_networks_lower fail's since the\n'External' network is'nt associated.\n\nAlso if the 'External' network is associated with the\nrole set the address and routes.\n\nFor the mutliple_nic_vlans add address and routes and\nthe vlan member interface on the bridge.\n\nNote, also remove duplicate name entry on the 'Tenant'\nnetwork section.\n\nDepends-On: https://review.opendev.org/763301\nCloses-Bug: #1904809\nChange-Id: I19a011bfbbcdbacbe257625310490077755a8b70\n""}, {'number': 5, 'created': '2020-11-27 01:40:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ansible/commit/f053761392968b02b6d3dd3df83ddac843aab7b6', 'message': ""networks_lower group_var replace role_networks_lower\n\nThe 'networks_lower' group_var carries a mapping of\nnetwork.name to network.name_lower for all networks.\n\nThe external_bridge interface on DVR compute nodes\nthat do not have the 'External' network associated\nwith the role still need to be able to lookup the\nname_lower for the 'External' network.\n\nThe lookup via role_networks_lower fail's since the\n'External' network is'nt associated.\n\nAlso if the 'External' network is associated with the\nrole set the address and routes.\n\nFor the mutliple_nic_vlans add address and routes and\nthe vlan member interface on the bridge.\n\nNote, also remove duplicate name entry on the 'Tenant'\nnetwork section.\n\nDepends-On: https://review.opendev.org/763301\nCloses-Bug: #1904809\nChange-Id: I19a011bfbbcdbacbe257625310490077755a8b70\n""}, {'number': 6, 'created': '2020-11-27 02:01:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ansible/commit/b74061d13f1677dfd98645193c49679a06d86547', 'message': ""networks_lower group_var replace role_networks_lower\n\nThe 'networks_lower' group_var carries a mapping of\nnetwork.name to network.name_lower for all networks.\n\nThe external_bridge interface on DVR compute nodes\nthat do not have the 'External' network associated\nwith the role still need to be able to lookup the\nname_lower for the 'External' network.\n\nThe lookup via role_networks_lower fail's since the\n'External' network is'nt associated.\n\nAlso if the 'External' network is associated with the\nrole set the address and routes.\n\nFor the mutliple_nic_vlans add address and routes and\nthe vlan member interface on the bridge.\n\nNote, also remove duplicate name entry on the 'Tenant'\nnetwork section.\n\nDepends-On: https://review.opendev.org/763301\nCloses-Bug: #1904809\nChange-Id: I19a011bfbbcdbacbe257625310490077755a8b70\n""}, {'number': 7, 'created': '2020-11-27 17:41:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ansible/commit/6d8cd1721c66545fed5ecd19f4c78f1f590c421c', 'message': ""networks_lower group_var replace role_networks_lower\n\nThe 'networks_lower' group_var carries a mapping of\nnetwork.name to network.name_lower for all networks.\n\nThe external_bridge interface on DVR compute nodes\nthat do not have the 'External' network associated\nwith the role still need to be able to lookup the\nname_lower for the 'External' network.\n\nThe lookup via role_networks_lower fail's since the\n'External' network is'nt associated.\n\nAlso if the 'External' network is associated with the\nrole set the address and routes.\n\nFor the mutliple_nic_vlans add address and routes and\nthe vlan member interface on the bridge.\n\nNote, also remove duplicate name entry on the 'Tenant'\nnetwork section.\n\nDepends-On: https://review.opendev.org/763301\nCloses-Bug: #1904809\nChange-Id: I19a011bfbbcdbacbe257625310490077755a8b70\n""}, {'number': 8, 'created': '2020-11-27 17:45:14.000000000', 'files': ['tripleo_ansible/roles/tripleo_network_config/templates/multiple_nics_vlans/multiple_nics_vlans_dvr.j2', 'tripleo_ansible/roles/tripleo_network_config/templates/multiple_nics/multiple_nics_dvr.j2'], 'web_link': 'https://opendev.org/openstack/tripleo-ansible/commit/2fe1c59d9e0d38f074374d8978651f8cc03b4d43', 'message': ""networks_lower group_var replace role_networks_lower\n\nThe 'networks_lower' group_var carries a mapping of\nnetwork.name to network.name_lower for all networks.\n\nThe external_bridge interface on DVR compute nodes\nthat do not have the 'External' network associated\nwith the role still need to be able to lookup the\nname_lower for the 'External' network.\n\nThe lookup via role_networks_lower fail's since the\n'External' network is'nt associated.\n\nAlso if the 'External' network is associated with the\nrole set the address and routes.\n\nFor the mutliple_nic_vlans add address and routes and\nthe vlan member interface on the bridge.\n\nNote, also remove duplicate name entry on the 'Tenant'\nnetwork section.\n\nDepends-On: https://review.opendev.org/763301\nCloses-Bug: #1904809\nChange-Id: I19a011bfbbcdbacbe257625310490077755a8b70\n""}]",3,763302,2fe1c59d9e0d38f074374d8978651f8cc03b4d43,30,3,8,24245,,,0,"networks_lower group_var replace role_networks_lower

The 'networks_lower' group_var carries a mapping of
network.name to network.name_lower for all networks.

The external_bridge interface on DVR compute nodes
that do not have the 'External' network associated
with the role still need to be able to lookup the
name_lower for the 'External' network.

The lookup via role_networks_lower fail's since the
'External' network is'nt associated.

Also if the 'External' network is associated with the
role set the address and routes.

For the mutliple_nic_vlans add address and routes and
the vlan member interface on the bridge.

Note, also remove duplicate name entry on the 'Tenant'
network section.

Depends-On: https://review.opendev.org/763301
Closes-Bug: #1904809
Change-Id: I19a011bfbbcdbacbe257625310490077755a8b70
",git fetch https://review.opendev.org/openstack/tripleo-ansible refs/changes/02/763302/8 && git format-patch -1 --stdout FETCH_HEAD,"['tripleo_ansible/roles/tripleo_network_config/templates/multiple_nics_vlans/multiple_nics_vlans_dvr.j2', 'tripleo_ansible/roles/tripleo_network_config/templates/multiple_nics/multiple_nics_dvr.j2']",2,0531405610214c722d8403032eb74286e84d5887,bug/1904809," mtu: {{ external_mtu }}{% if 'External' in role_networks %} addresses: - ip_netmask: {{ lookup('vars', role_networks_lower[network] ~ '_ip') }}/{{ lookup('vars', role_networks_lower[network] ~ '_cidr') }} routes: {{ lookup('vars', role_networks_lower[network] ~ '_host_routes') }} {% endif %} mtu: {{ external_mtu }} primary: true"," mtu: {{ lookup('vars', role_networks_lower['External'] ~ '_mtu') }} mtu: {{ lookup('vars', role_networks_lower['External'] ~ '_mtu') }} primary: true ",20,5
openstack%2Ftrove~stable%2Fvictoria~Ic74d10647f82044038ea9a4d99cb9a0320459675,openstack/trove,stable/victoria,Ic74d10647f82044038ea9a4d99cb9a0320459675,Remove the experimental claim of dev_mode false,MERGED,2020-11-27 10:25:56.000000000,2020-11-28 06:17:34.000000000,2020-11-28 06:14:43.000000000,"[{'_account_id': 6732}, {'_account_id': 22348}]","[{'number': 1, 'created': '2020-11-27 10:25:56.000000000', 'files': ['doc/source/admin/building_guest_images.rst', 'integration/README.md'], 'web_link': 'https://opendev.org/openstack/trove/commit/a7a92e6786e4eda792ade27c76af8c1700ae4b4b', 'message': 'Remove the experimental claim of dev_mode false\n\n(Cherry picked from https://review.opendev.org/c/openstack/trove/+/764391)\nChange-Id: Ic74d10647f82044038ea9a4d99cb9a0320459675\n'}]",0,764306,a7a92e6786e4eda792ade27c76af8c1700ae4b4b,7,2,1,6732,,,0,"Remove the experimental claim of dev_mode false

(Cherry picked from https://review.opendev.org/c/openstack/trove/+/764391)
Change-Id: Ic74d10647f82044038ea9a4d99cb9a0320459675
",git fetch https://review.opendev.org/openstack/trove refs/changes/06/764306/1 && git format-patch -1 --stdout FETCH_HEAD,"['doc/source/admin/building_guest_images.rst', 'integration/README.md']",2,a7a92e6786e4eda792ade27c76af8c1700ae4b4b,dev-mode-stable/victoria, image at the building time., image at the building time. Now `dev_mode=false` is still in experimental and not considered production ready yet.,3,5
openstack%2Fnova~master~If4783adda92da33d512d7c2834f0bb2e2a9b9654,openstack/nova,master,If4783adda92da33d512d7c2834f0bb2e2a9b9654,Support sys.argv in wsgi app,MERGED,2020-11-23 08:33:23.000000000,2020-11-28 06:11:59.000000000,2020-11-28 06:07:39.000000000,"[{'_account_id': 4393}, {'_account_id': 7166}, {'_account_id': 7634}, {'_account_id': 9708}, {'_account_id': 11604}, {'_account_id': 15334}, {'_account_id': 22348}]","[{'number': 1, 'created': '2020-11-23 08:33:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/74421ab620f049b363a657c48f5039a0e2a6d04e', 'message': 'Support sys.argv in wsgi app\n\nAt least uwsgi supports passing command line arguments to python wsgi\napps by specifying them as --pyargv for to uwsgi binary. Then the wsgi\napp can access them normally via sys.argv.\n\nThis patch makes sure that nova-api and nova-metadata-api passes\nsys.argv to oslo.config and therefore specifying config files for\nthese services now possible.\n\nFor example the following line in the systemclt service file makes sure\nthat the nova-api service reads both the nova.conf and the\nnova-extra.conf\n\nExecStart = /usr/local/bin/uwsgi --procname-prefix nova-api \\\n  --ini /etc/nova/nova-api-uwsgi.ini \\\n  --pyargv ""--config-file=/etc/nova/nova.conf\n    --config-file=/etc/nova/nova-extra.conf""\n\nChange-Id: If4783adda92da33d512d7c2834f0bb2e2a9b9654\nRelated-Bug: #1871482\n'}, {'number': 2, 'created': '2020-11-23 13:17:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/abecb04aaaf2b47fcdfa1ad1fee35eb8c6751e49', 'message': 'Support sys.argv in wsgi app\n\nAt least uwsgi supports passing command line arguments to python wsgi\napps by specifying them as --pyargv for to uwsgi binary. Then the wsgi\napp can access them normally via sys.argv.\n\nThis patch makes sure that nova-api and nova-metadata-api passes\nsys.argv to oslo.config and therefore specifying config files for\nthese services now possible.\n\nFor example the following line in the systemclt service file makes sure\nthat the nova-api service reads both the nova.conf and the\nnova-extra.conf\n\nExecStart = /usr/local/bin/uwsgi --procname-prefix nova-api \\\n  --ini /etc/nova/nova-api-uwsgi.ini \\\n  --pyargv ""--config-file=/etc/nova/nova.conf\n    --config-file=/etc/nova/nova-extra.conf""\n\nChange-Id: If4783adda92da33d512d7c2834f0bb2e2a9b9654\nRelated-Bug: #1871482\n'}, {'number': 3, 'created': '2020-11-25 11:24:38.000000000', 'files': ['nova/api/openstack/wsgi_app.py', 'nova/tests/unit/api/test_wsgi.py', 'releasenotes/notes/support-sys.argv-in-wsgi-app-2dc5006f9e9e5f9e.yaml'], 'web_link': 'https://opendev.org/openstack/nova/commit/d38b7e13a6c3c2f8a932f9a55305502b47f2e0b2', 'message': 'Support sys.argv in wsgi app\n\nAt least uwsgi supports passing command line arguments to python wsgi\napps by specifying them as --pyargv for to uwsgi binary. Then the wsgi\napp can access them normally via sys.argv.\n\nThis patch makes sure that nova-api and nova-metadata-api passes\nsys.argv to oslo.config and therefore specifying config files for\nthese services now possible.\n\nFor example the following line in the systemclt service file makes sure\nthat the nova-api service reads both the nova.conf and the\nnova-extra.conf\n\nExecStart = /usr/local/bin/uwsgi --procname-prefix nova-api \\\n  --ini /etc/nova/nova-api-uwsgi.ini \\\n  --pyargv ""--config-file=/etc/nova/nova.conf\n    --config-file=/etc/nova/nova-extra.conf""\n\nChange-Id: If4783adda92da33d512d7c2834f0bb2e2a9b9654\nRelated-Bug: #1871482\n'}]",6,763750,d38b7e13a6c3c2f8a932f9a55305502b47f2e0b2,34,7,3,9708,,,0,"Support sys.argv in wsgi app

At least uwsgi supports passing command line arguments to python wsgi
apps by specifying them as --pyargv for to uwsgi binary. Then the wsgi
app can access them normally via sys.argv.

This patch makes sure that nova-api and nova-metadata-api passes
sys.argv to oslo.config and therefore specifying config files for
these services now possible.

For example the following line in the systemclt service file makes sure
that the nova-api service reads both the nova.conf and the
nova-extra.conf

ExecStart = /usr/local/bin/uwsgi --procname-prefix nova-api \
  --ini /etc/nova/nova-api-uwsgi.ini \
  --pyargv ""--config-file=/etc/nova/nova.conf
    --config-file=/etc/nova/nova-extra.conf""

Change-Id: If4783adda92da33d512d7c2834f0bb2e2a9b9654
Related-Bug: #1871482
",git fetch https://review.opendev.org/openstack/nova refs/changes/50/763750/1 && git format-patch -1 --stdout FETCH_HEAD,"['nova/api/openstack/wsgi_app.py', 'nova/tests/unit/api/test_wsgi.py']",2,74421ab620f049b363a657c48f5039a0e2a6d04e,bug/1871482,"import sys import mockfrom nova.api.openstack import wsgi_app @mock.patch('nova.api.openstack.wsgi_app._setup_service', new=mock.Mock()) @mock.patch('paste.deploy.loadapp', new=mock.Mock()) def test_init_application_passes_sys_argv_to_config(self): sys.argv = mock.sentinel.argv with mock.patch('nova.config.parse_args') as mock_parse_args: wsgi_app.init_application('test-app') mock_parse_args.assert_called_once_with( mock.sentinel.argv, default_config_files=[ '/etc/nova/api-paste.ini', '/etc/nova/nova.conf'])",,21,1
openstack%2Fnova~master~Ic83252bbda76c205bcbf0eef184ce0b201e224fc,openstack/nova,master,Ic83252bbda76c205bcbf0eef184ce0b201e224fc,nova-live-migration: Disable *all* virt services during negative tests,MERGED,2020-11-13 09:31:52.000000000,2020-11-28 06:10:19.000000000,2020-11-28 06:07:15.000000000,"[{'_account_id': 7166}, {'_account_id': 7634}, {'_account_id': 9008}, {'_account_id': 9708}, {'_account_id': 10118}, {'_account_id': 10135}, {'_account_id': 15751}, {'_account_id': 22348}, {'_account_id': 23498}, {'_account_id': 26515}, {'_account_id': 29963}]","[{'number': 1, 'created': '2020-11-13 09:31:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/ba79e91dd7d8043c337059d4043b673a1bbea88c', 'message': 'WIP nova-live-migration: Disable *all* virt services during negative tests\n\nChange-Id: Ic83252bbda76c205bcbf0eef184ce0b201e224fc\nCloses-Bug: #1903979\n'}, {'number': 2, 'created': '2020-11-13 12:09:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/612b5d7d9eba81d07d11529f83ad368b22397452', 'message': ""nova-live-migration: Disable *all* virt services during negative tests\n\nlibvirtd was being restarted on the controller during negative\nevacuation tests that rely on the service being to cause an\nevacuation failure.\n\nThis change adds various virt services to the list of services stopped\nand now disabled on the host to ensure these don't cause systemd to\nrestart libvirtd:\n\n* libvirtd-guest.service\n* virtlogd.service\n* virtlogd-admin.socket\n* virtlogd.socket\n* virtlockd.service\n* virtlockd-admin.socket\n* virtlockd.socket\n\nCloses-Bug: #1903979\nChange-Id: Ic83252bbda76c205bcbf0eef184ce0b201e224fc\n""}, {'number': 3, 'created': '2020-11-26 17:03:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/308ae68cc39951c86fb3377dcb16e299b87d6bda', 'message': ""nova-live-migration: Disable *all* virt services during negative tests\n\nlibvirtd was being restarted on the controller during negative\nevacuation tests that rely on the service being to cause an\nevacuation failure.\n\nThis change adds various virt services to the list of services stopped\nand now disabled on the host to ensure these don't cause systemd to\nrestart libvirtd:\n\n* virtlogd.service\n* virtlogd-admin.socket\n* virtlogd.socket\n* virtlockd.service\n* virtlockd-admin.socket\n* virtlockd.socket\n\nCloses-Bug: #1903979\nChange-Id: Ic83252bbda76c205bcbf0eef184ce0b201e224fc\n""}, {'number': 4, 'created': '2020-11-27 13:35:42.000000000', 'files': ['roles/run-evacuate-hook/tasks/main.yaml'], 'web_link': 'https://opendev.org/openstack/nova/commit/76360e566bcd0e203f3e9357ca2b0ca3d7baf4b8', 'message': ""nova-live-migration: Disable *all* virt services during negative tests\n\nlibvirtd was being restarted on the controller during negative\nevacuation tests that rely on the service being to cause an\nevacuation failure.\n\nThis change adds various virt services to the list of services stopped\nand now disabled on the host to ensure these don't cause systemd to\nrestart libvirtd:\n\n* virtlogd.service\n* virtlogd-admin.socket\n* virtlogd.socket\n* virtlockd.service\n* virtlockd-admin.socket\n* virtlockd.socket\n\nCloses-Bug: #1903979\nChange-Id: Ic83252bbda76c205bcbf0eef184ce0b201e224fc\n""}]",0,762623,76360e566bcd0e203f3e9357ca2b0ca3d7baf4b8,44,11,4,10135,,,0,"nova-live-migration: Disable *all* virt services during negative tests

libvirtd was being restarted on the controller during negative
evacuation tests that rely on the service being to cause an
evacuation failure.

This change adds various virt services to the list of services stopped
and now disabled on the host to ensure these don't cause systemd to
restart libvirtd:

* virtlogd.service
* virtlogd-admin.socket
* virtlogd.socket
* virtlockd.service
* virtlockd-admin.socket
* virtlockd.socket

Closes-Bug: #1903979
Change-Id: Ic83252bbda76c205bcbf0eef184ce0b201e224fc
",git fetch https://review.opendev.org/openstack/nova refs/changes/23/762623/4 && git format-patch -1 --stdout FETCH_HEAD,['roles/run-evacuate-hook/tasks/main.yaml'],1,ba79e91dd7d8043c337059d4043b673a1bbea88c,change-762623-2, enabled: no - virtlogd.service - virtlogd-admin.socket - virtlogd.socket - virtlockd.service - virtlockd-admin.socket - virtlockd.socket enabled: yes - virtlogd.service - virtlogd-admin.socket - virtlogd.socket - virtlockd.service - virtlockd-admin.socket - virtlockd.socket,,14,0
openstack%2Fkolla-ansible~master~I06a608cef2239159d91de76ea98418fcb47a0104,openstack/kolla-ansible,master,I06a608cef2239159d91de76ea98418fcb47a0104,"Can't get ""sec_grp_info"" variable",ABANDONED,2020-11-25 08:24:19.000000000,2020-11-28 05:08:41.000000000,,"[{'_account_id': 14826}, {'_account_id': 22348}, {'_account_id': 22629}, {'_account_id': 26285}, {'_account_id': 28522}, {'_account_id': 30491}, {'_account_id': 31506}]","[{'number': 1, 'created': '2020-11-25 08:24:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/ac44c158b6191010ed546c65aa7414c21a404c7f', 'message': 'Can\'t get ""sec_grp_info"" variable\n\nWhen\'kolla_action=upgrade\', the\'prepare.yml\' task\nshould be updated\n\nChange-Id: I06a608cef2239159d91de76ea98418fcb47a0104\n'}, {'number': 2, 'created': '2020-11-25 08:51:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/0b5e8b925be337cc484eef9eda1955683df2aef4', 'message': 'Can\'t get ""sec_grp_info"" variable\n\nWhen\'kolla_action=upgrade\' and \'octavia_auto_configure=true\',\nthe\'prepare.yml\' task should be updated\n\nChange-Id: I06a608cef2239159d91de76ea98418fcb47a0104\n'}, {'number': 3, 'created': '2020-11-25 09:24:34.000000000', 'files': ['ansible/roles/octavia/tasks/deploy.yml', 'ansible/roles/octavia/tasks/config.yml'], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/22158a551a5e1837f6856a352ebdb2b649e38329', 'message': 'Can\'t get ""sec_grp_info"" variable\n\nWhen\'kolla_action=upgrade/genconfig\' and\n\'octavia_auto_configure=true\', the\'prepare.yml\'\ntask should be updated\n\nChange-Id: I06a608cef2239159d91de76ea98418fcb47a0104\n'}]",0,764132,22158a551a5e1837f6856a352ebdb2b649e38329,14,7,3,31506,,,0,"Can't get ""sec_grp_info"" variable

When'kolla_action=upgrade/genconfig' and
'octavia_auto_configure=true', the'prepare.yml'
task should be updated

Change-Id: I06a608cef2239159d91de76ea98418fcb47a0104
",git fetch https://review.opendev.org/openstack/kolla-ansible refs/changes/32/764132/3 && git format-patch -1 --stdout FETCH_HEAD,['ansible/roles/octavia/tasks/upgrade.yml'],1,ac44c158b6191010ed546c65aa7414c21a404c7f,bp/implement-automatic-deploy-of-octavia,- include_tasks: prepare.yml when: octavia_auto_configure | bool ,,3,0
openstack%2Ftempest~master~Iee5dffcafc8a6870c8a7005870055a614eaafab8,openstack/tempest,master,Iee5dffcafc8a6870c8a7005870055a614eaafab8,Allow kwargs in create_keypair,MERGED,2020-10-16 12:06:53.000000000,2020-11-28 04:29:14.000000000,2020-11-28 04:27:33.000000000,"[{'_account_id': 8556}, {'_account_id': 20190}, {'_account_id': 22348}, {'_account_id': 22873}, {'_account_id': 28182}]","[{'number': 1, 'created': '2020-10-16 12:06:53.000000000', 'files': ['tempest/scenario/manager.py'], 'web_link': 'https://opendev.org/openstack/tempest/commit/30b4d5335ab685d183809426769029da1582789e', 'message': 'Allow kwargs in create_keypair\n\nAs a part of the scenario/manager.py stabilization tracked by\nthe below BP the patch adds kwargs argument for create_keyapair\nmethod so that the consumers are able to pass additional\nparameters if needed.\n\nImplements: blueprint tempest-scenario-manager-stable\nChange-Id: Iee5dffcafc8a6870c8a7005870055a614eaafab8\n'}]",0,758555,30b4d5335ab685d183809426769029da1582789e,28,5,1,22873,,,0,"Allow kwargs in create_keypair

As a part of the scenario/manager.py stabilization tracked by
the below BP the patch adds kwargs argument for create_keyapair
method so that the consumers are able to pass additional
parameters if needed.

Implements: blueprint tempest-scenario-manager-stable
Change-Id: Iee5dffcafc8a6870c8a7005870055a614eaafab8
",git fetch https://review.opendev.org/openstack/tempest refs/changes/55/758555/1 && git format-patch -1 --stdout FETCH_HEAD,['tempest/scenario/manager.py'],1,30b4d5335ab685d183809426769029da1582789e,bp/tempest-scenario-manager-stable," def create_keypair(self, client=None, **kwargs): if not kwargs.get('name'): kwargs['name'] = data_utils.rand_name(self.__class__.__name__) body = client.create_keypair(**kwargs) self.addCleanup(client.delete_keypair, kwargs['name'])"," def create_keypair(self, client=None): name = data_utils.rand_name(self.__class__.__name__) body = client.create_keypair(name=name) self.addCleanup(client.delete_keypair, name)",5,4
openstack%2Ftrove~stable%2Fvictoria~Icae399527211a2c4f50b04889b5e1ba09b4982ed,openstack/trove,stable/victoria,Icae399527211a2c4f50b04889b5e1ba09b4982ed,Fix the guest service name in troubleshooting guide,MERGED,2020-11-27 10:51:24.000000000,2020-11-28 04:04:07.000000000,2020-11-28 04:01:31.000000000,"[{'_account_id': 6732}, {'_account_id': 22348}]","[{'number': 1, 'created': '2020-11-27 10:51:24.000000000', 'files': ['doc/source/admin/troubleshooting.rst'], 'web_link': 'https://opendev.org/openstack/trove/commit/b7f1100ef5a55b1fdd68e47b1a7222b383926f10', 'message': 'Fix the guest service name in troubleshooting guide\n\nChange-Id: Icae399527211a2c4f50b04889b5e1ba09b4982ed\n(cherry picked from commit 7f62f199d26ea8b066a5aed8a8b4b5ca5b3af85f)\n'}]",0,764307,b7f1100ef5a55b1fdd68e47b1a7222b383926f10,7,2,1,6732,,,0,"Fix the guest service name in troubleshooting guide

Change-Id: Icae399527211a2c4f50b04889b5e1ba09b4982ed
(cherry picked from commit 7f62f199d26ea8b066a5aed8a8b4b5ca5b3af85f)
",git fetch https://review.opendev.org/openstack/trove refs/changes/07/764307/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/source/admin/troubleshooting.rst'],1,b7f1100ef5a55b1fdd68e47b1a7222b383926f10,fix-doc-stable/victoria, sudo journalctl -u guest-agent.service | less # or, sudo journalctl -u trove-guest.service | less # or,1,1
openstack%2Ftripleo-ci~master~I8ccd550e158df179c21d8c9d45251e253de90c3b,openstack/tripleo-ci,master,I8ccd550e158df179c21d8c9d45251e253de90c3b,Add psi cloud configuration,MERGED,2020-11-23 15:15:18.000000000,2020-11-28 02:49:13.000000000,2020-11-28 02:49:13.000000000,"[{'_account_id': 8449}, {'_account_id': 9592}, {'_account_id': 10969}, {'_account_id': 13861}, {'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2020-11-23 15:15:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ci/commit/71504385de039fe1c4fafd1ab5426b485c846140', 'message': 'Add psi cloud configuration\n\nAdd psi cloud configuration for ovb and multinode jobs\n\nChange-Id: I8ccd550e158df179c21d8c9d45251e253de90c3b\n'}, {'number': 2, 'created': '2020-11-23 17:16:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ci/commit/00d1205bd4468ffa378b75272b6e327f0c85a6ba', 'message': 'Add psi cloud configuration\n\nAdd psi cloud configuration for ovb and multinode jobs\n\nChange-Id: I8ccd550e158df179c21d8c9d45251e253de90c3b\n'}, {'number': 3, 'created': '2020-11-23 19:34:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ci/commit/a72d93682accc63ac1d044cfa27d49cf69c91243', 'message': 'Add psi cloud configuration\n\nAdd psi cloud configuration for ovb and multinode jobs\n\nChange-Id: I8ccd550e158df179c21d8c9d45251e253de90c3b\n'}, {'number': 4, 'created': '2020-11-23 20:01:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ci/commit/f4633e3e6866a25740be2af5c6e6ca53449e2156', 'message': 'Add psi cloud configuration\n\nAdd psi cloud configuration for ovb and multinode jobs\n\nChange-Id: I8ccd550e158df179c21d8c9d45251e253de90c3b\n'}, {'number': 5, 'created': '2020-11-23 20:20:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ci/commit/425f44b9b4eab5830d592ba51db81f4ca6385df8', 'message': 'Add psi cloud configuration\n\nAdd psi cloud configuration for ovb and multinode jobs\n\nChange-Id: I8ccd550e158df179c21d8c9d45251e253de90c3b\n'}, {'number': 6, 'created': '2020-11-23 20:32:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ci/commit/fcf424752a7d347cb145812dc9d2fc94b7f780df', 'message': 'Add psi cloud configuration\n\nAdd psi cloud configuration for ovb and multinode jobs\n\nChange-Id: I8ccd550e158df179c21d8c9d45251e253de90c3b\n'}, {'number': 7, 'created': '2020-11-24 14:37:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ci/commit/e86c6c0764f489778e6c4b005d25caf254eb7ae6', 'message': 'Add psi cloud configuration\n\nAdd psi cloud configuration for ovb and multinode jobs\n\nChange-Id: I8ccd550e158df179c21d8c9d45251e253de90c3b\n'}, {'number': 8, 'created': '2020-11-27 08:04:37.000000000', 'files': ['toci-quickstart/config/testenv/singlenode-psi.yml', 'roles/common/vars/main.yaml', 'toci-quickstart/config/testenv/multinode-psi.yml', 'toci-quickstart/config/testenv/ovb-psi.yml'], 'web_link': 'https://opendev.org/openstack/tripleo-ci/commit/10d3fbc91d595a5bdce155e43d6df09ce8dcff9e', 'message': 'Add psi cloud configuration\n\nAdd psi cloud configuration for ovb and multinode jobs\n\nChange-Id: I8ccd550e158df179c21d8c9d45251e253de90c3b\n'}]",7,763793,10d3fbc91d595a5bdce155e43d6df09ce8dcff9e,37,6,8,11810,,,0,"Add psi cloud configuration

Add psi cloud configuration for ovb and multinode jobs

Change-Id: I8ccd550e158df179c21d8c9d45251e253de90c3b
",git fetch https://review.opendev.org/openstack/tripleo-ci refs/changes/93/763793/8 && git format-patch -1 --stdout FETCH_HEAD,"['toci-quickstart/config/testenv/singlenode-psi.yml', 'toci-quickstart/config/testenv/ovb-psi.yaml', 'scripts/psi.env', 'toci-quickstart/config/testenv/multinode-psi.yml', 'toci_gate_test.sh']",5,71504385de039fe1c4fafd1ab5426b485c846140,763793, elif [ ${NODEPOOL_PROVIDER:-''} == 'psi-public-nodepool-tripleo' ]; then RHCLOUD='psi',,193,0
openstack%2Fpython-novaclient~stable%2Ftrain~I8c2a6f91739d50baa283b37b16de67c542ea691b,openstack/python-novaclient,stable/train,I8c2a6f91739d50baa283b37b16de67c542ea691b,Add a cleanup for a server in a functional test,ABANDONED,2020-07-29 13:18:59.000000000,2020-11-28 02:04:34.000000000,,"[{'_account_id': 9545}, {'_account_id': 15334}, {'_account_id': 22348}]","[{'number': 1, 'created': '2020-07-29 13:18:59.000000000', 'files': ['novaclient/tests/functional/v2/test_instance_action.py'], 'web_link': 'https://opendev.org/openstack/python-novaclient/commit/ad4072648f7fed263d8d0a47d810b830f8d005c4', 'message': 'Add a cleanup for a server in a functional test\n\nA VM instance is created in the following functional test.\n\n* novaclient.tests.functional.v2.test_instance_action.\n  TestInstanceActionCLIV262.test_show_actions_with_host\n\nHowever the VM instance is not deleted after the functional test.\nAdd a cleanup for the server in the functional test.\n\nChange-Id: I8c2a6f91739d50baa283b37b16de67c542ea691b\nCloses-Bug: #1889283\nSigned-off-by: Takashi Natsume <takanattie@gmail.com>\n(cherry picked from commit 1ce9edcd73c6da9dd4dcded12747957fc297cb21)\n(cherry picked from commit 224de21684e11896c8be59d2429d0cc84dd43884)\n'}]",0,743757,ad4072648f7fed263d8d0a47d810b830f8d005c4,8,3,1,7634,,,0,"Add a cleanup for a server in a functional test

A VM instance is created in the following functional test.

* novaclient.tests.functional.v2.test_instance_action.
  TestInstanceActionCLIV262.test_show_actions_with_host

However the VM instance is not deleted after the functional test.
Add a cleanup for the server in the functional test.

Change-Id: I8c2a6f91739d50baa283b37b16de67c542ea691b
Closes-Bug: #1889283
Signed-off-by: Takashi Natsume <takanattie@gmail.com>
(cherry picked from commit 1ce9edcd73c6da9dd4dcded12747957fc297cb21)
(cherry picked from commit 224de21684e11896c8be59d2429d0cc84dd43884)
",git fetch https://review.opendev.org/openstack/python-novaclient refs/changes/57/743757/1 && git format-patch -1 --stdout FETCH_HEAD,['novaclient/tests/functional/v2/test_instance_action.py'],1,ad4072648f7fed263d8d0a47d810b830f8d005c4,bug/1889283," self.addCleanup(self.client.servers.delete, server_id) ",,2,0
openstack%2Ftempest~master~I1aa6a161d3821470fe282914929ebdc93dd5e802,openstack/tempest,master,I1aa6a161d3821470fe282914929ebdc93dd5e802,Cleanup server before image at test level,MERGED,2020-11-27 04:52:19.000000000,2020-11-28 00:48:55.000000000,2020-11-28 00:47:31.000000000,"[{'_account_id': 5689}, {'_account_id': 8556}, {'_account_id': 22348}, {'_account_id': 22873}]","[{'number': 1, 'created': '2020-11-27 04:52:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/0899ce7c3431e5244c24e24c31f5472efbca18d8', 'message': 'Cleanup server before image at test level\n\ntest_attach_scsi_disk_with_config_drive test\ncreate the server via self.create_test_server which\ndelete the server at class level cleanup and created\nimage cleanup happen at test level so throw error.\n\nWe need to delete the server at test level cleanup and before\nimage.\n\nThis is required as when both Glance and Nova use a shared RBD backend\nNova will clone an instance disk directly from the Glance RBD volume.\nThis results in any attempt to delete the Glance image to fail while the\nserver is still provisioned as it still references the Glance RBD volume.\n\nCloses-Bug: #1905725\nChange-Id: I1aa6a161d3821470fe282914929ebdc93dd5e802\n'}, {'number': 2, 'created': '2020-11-27 06:51:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/dc94dde09085ee4bff8166ceef5c0b669f716761', 'message': 'Cleanup server before image at test level\n\ntest_attach_scsi_disk_with_config_drive test\ncreate the server via self.create_test_server which\ndelete the server at class level cleanup and created\nimage cleanup happen at test level so throw error.\n\nWe need to delete the server at test level cleanup and before\nimage.\n\nThis is required as when both Glance and Nova use a shared RBD backend\nNova will clone an instance disk directly from the Glance RBD volume.\nThis results in any attempt to delete the Glance image to fail while the\nserver is still provisioned as it still references the Glance RBD volume.\n\nCloses-Bug: #1905725\nChange-Id: I1aa6a161d3821470fe282914929ebdc93dd5e802\n'}, {'number': 3, 'created': '2020-11-27 15:02:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/5ec36cc200199b86d47a8a54df0c6b662b261959', 'message': 'Cleanup server before image at test level\n\ntest_attach_scsi_disk_with_config_drive test\ncreate the server via self.create_test_server which\ndelete the server at class level cleanup and created\nimage cleanup happen at test level so throw error.\n\nWe need to delete the server at test level cleanup and before\nimage.\n\nThis is required as when both Glance and Nova use a shared RBD backend\nNova will clone an instance disk directly from the Glance RBD volume.\nThis results in any attempt to delete the Glance image to fail while the\nserver is still provisioned as it still references the Glance RBD volume.\n\nCloses-Bug: #1905725\nChange-Id: I1aa6a161d3821470fe282914929ebdc93dd5e802\n'}, {'number': 4, 'created': '2020-11-27 15:09:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/8eae055a786961ef190821e06cc26f5bf01a970e', 'message': 'Cleanup server before image at test level\n\ntest_attach_scsi_disk_with_config_drive test\ncreate the server via self.create_test_server which\ndelete the server at class level cleanup and created\nimage cleanup happen at test level so throw error.\n\nWe need to delete the server at test level cleanup and before\nimage.\n\nThis is required as when both Glance and Nova use a shared RBD backend\nNova will clone an instance disk directly from the Glance RBD volume.\nThis results in any attempt to delete the Glance image to fail while the\nserver is still provisioned as it still references the Glance RBD volume.\n\nCloses-Bug: #1905725\nChange-Id: I1aa6a161d3821470fe282914929ebdc93dd5e802\n'}, {'number': 5, 'created': '2020-11-27 16:45:57.000000000', 'files': ['tempest/api/compute/admin/test_volume.py'], 'web_link': 'https://opendev.org/openstack/tempest/commit/7d9b50a8102dfe35fe327ddc833fd342baef4241', 'message': 'Cleanup server before image at test level\n\ntest_attach_scsi_disk_with_config_drive test\ncreate the server via self.create_test_server which\ndelete the server at class level cleanup and created\nimage cleanup happen at test level so throw error.\n\nWe need to delete the server at test level cleanup and before\nimage.\n\nThis is required as when both Glance and Nova use a shared RBD backend\nNova will clone an instance disk directly from the Glance RBD volume.\nThis results in any attempt to delete the Glance image to fail while the\nserver is still provisioned as it still references the Glance RBD volume.\n\nCloses-Bug: #1905725\nChange-Id: I1aa6a161d3821470fe282914929ebdc93dd5e802\n'}]",0,764407,7d9b50a8102dfe35fe327ddc833fd342baef4241,23,4,5,8556,,,0,"Cleanup server before image at test level

test_attach_scsi_disk_with_config_drive test
create the server via self.create_test_server which
delete the server at class level cleanup and created
image cleanup happen at test level so throw error.

We need to delete the server at test level cleanup and before
image.

This is required as when both Glance and Nova use a shared RBD backend
Nova will clone an instance disk directly from the Glance RBD volume.
This results in any attempt to delete the Glance image to fail while the
server is still provisioned as it still references the Glance RBD volume.

Closes-Bug: #1905725
Change-Id: I1aa6a161d3821470fe282914929ebdc93dd5e802
",git fetch https://review.opendev.org/openstack/tempest refs/changes/07/764407/5 && git format-patch -1 --stdout FETCH_HEAD,['tempest/api/compute/admin/test_volume.py'],1,0899ce7c3431e5244c24e24c31f5472efbca18d8,bug/1905725," self.addCleanup(self.image_client.delete_image, new_image) # NOTE(lyarwood): self.create_test_server delete the server # at class level cleanup so add server cleanup to ensure that # the instance is deleted first before created image. This # avoids failures when using the rbd backend is used for both # Glance and Nova ephemeral storage. self.addCleanup(self.client.delete_server, server['id'])"," # NOTE(lyarwood): Add image cleanup *after* creating the instance to # ensure the instance is deleted first. This avoids failures when using # the rbd backend is used for both Glance and Nova ephemeral storage. self.addCleanup(self.image_client.delete_image, custom_img)",7,4
openstack%2Fpuppet-pacemaker~master~Idb6e4ba4eadbeeb52b959bc688eb5e043f11c155,openstack/puppet-pacemaker,master,Idb6e4ba4eadbeeb52b959bc688eb5e043f11c155,Fix reconnect_interval on remotes with pcs 0.10,MERGED,2020-11-25 18:07:36.000000000,2020-11-27 22:34:38.000000000,2020-11-27 22:34:38.000000000,"[{'_account_id': 14985}, {'_account_id': 20172}, {'_account_id': 20778}, {'_account_id': 22348}]","[{'number': 1, 'created': '2020-11-25 18:07:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-pacemaker/commit/30ba95e31bf8e55e5bbbcfc4f4845aa886d20d4b', 'message': 'Fix reconnect_interval on remotes with pcs 0.10\n\nWhen switching to the pcs 0.10 providers we moved from the the general\npcmk_resource provider to the pcmk_remote backend. While doing this we\nlost the ability to specify the reconnect_interval.\n\nTested by deploying tripleo with the following:\n  ExtraConfig:\n    pacemaker_remote_reconnect_interval: 180\n\nAnd correctly observing that the remotes have the right\nreconnect_interval:\n[root@controller-0 ~]# pcs resource config compute-0 |grep reconnect\n  Attributes: reconnect_interval=180 server=172.17.1.96\n\nChange-Id: Idb6e4ba4eadbeeb52b959bc688eb5e043f11c155\nCloses-Bug: #1905606\n'}, {'number': 2, 'created': '2020-11-27 07:50:18.000000000', 'files': ['lib/puppet/provider/pcmk_remote/default.rb'], 'web_link': 'https://opendev.org/openstack/puppet-pacemaker/commit/40d91a06a03e6e283cde747d80ad57e23bff6cb5', 'message': 'Fix reconnect_interval on remotes with pcs 0.10\n\nWhen switching to the pcs 0.10 providers we moved from the the general\npcmk_resource provider to the pcmk_remote backend. While doing this we\nlost the ability to specify the reconnect_interval.\n\nTested by deploying tripleo with the following:\n  ExtraConfig:\n    pacemaker_remote_reconnect_interval: 180\n\nAnd correctly observing that the remotes have the right\nreconnect_interval:\n[root@controller-0 ~]# pcs resource config compute-0 |grep reconnect\n  Attributes: reconnect_interval=180 server=172.17.1.96\n\nChange-Id: Idb6e4ba4eadbeeb52b959bc688eb5e043f11c155\nCloses-Bug: #1905606\n'}]",0,764227,40d91a06a03e6e283cde747d80ad57e23bff6cb5,12,4,2,20172,,,0,"Fix reconnect_interval on remotes with pcs 0.10

When switching to the pcs 0.10 providers we moved from the the general
pcmk_resource provider to the pcmk_remote backend. While doing this we
lost the ability to specify the reconnect_interval.

Tested by deploying tripleo with the following:
  ExtraConfig:
    pacemaker_remote_reconnect_interval: 180

And correctly observing that the remotes have the right
reconnect_interval:
[root@controller-0 ~]# pcs resource config compute-0 |grep reconnect
  Attributes: reconnect_interval=180 server=172.17.1.96

Change-Id: Idb6e4ba4eadbeeb52b959bc688eb5e043f11c155
Closes-Bug: #1905606
",git fetch https://review.opendev.org/openstack/puppet-pacemaker refs/changes/27/764227/1 && git format-patch -1 --stdout FETCH_HEAD,['lib/puppet/provider/pcmk_remote/default.rb'],1,30ba95e31bf8e55e5bbbcfc4f4845aa886d20d4b,reconnect," # reconnect_interval always has a default cmd += "" reconnect_interval=#{@resource[:reconnect_interval]}""",,2,0
openstack%2Ftripleo-quickstart-extras~master~Id0d57b3f78b51f756f5ca4d5c1fcf60452bbcc16,openstack/tripleo-quickstart-extras,master,Id0d57b3f78b51f756f5ca4d5c1fcf60452bbcc16,Skip mail send from tempest,MERGED,2020-11-23 20:01:47.000000000,2020-11-27 21:58:30.000000000,2020-11-27 21:58:30.000000000,"[{'_account_id': 8367}, {'_account_id': 12393}, {'_account_id': 13861}, {'_account_id': 14985}, {'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2020-11-23 20:01:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-quickstart-extras/commit/4d17000f5e03dcc552e59abfb6f5ee6282098029', 'message': ""Skip mail send from tempest\n\nMake validate_tempest send mail only when it's configured so.\nIt's used in queens, on recent branches we use os_tempest.\nChange-Id: Id0d57b3f78b51f756f5ca4d5c1fcf60452bbcc16\n""}, {'number': 2, 'created': '2020-11-24 11:15:01.000000000', 'files': ['roles/validate-tempest/tasks/tempest-results.yml'], 'web_link': 'https://opendev.org/openstack/tripleo-quickstart-extras/commit/5ee5804655614ae1fef03862cd44cd9ad71fb889', 'message': ""Skip mail send from tempest\n\nMake validate_tempest send mail only when it's configured so.\nIt's used in queens, on recent branches we use os_tempest.\nChange-Id: Id0d57b3f78b51f756f5ca4d5c1fcf60452bbcc16\n""}]",0,763856,5ee5804655614ae1fef03862cd44cd9ad71fb889,19,6,2,10969,,,0,"Skip mail send from tempest

Make validate_tempest send mail only when it's configured so.
It's used in queens, on recent branches we use os_tempest.
Change-Id: Id0d57b3f78b51f756f5ca4d5c1fcf60452bbcc16
",git fetch https://review.opendev.org/openstack/tripleo-quickstart-extras refs/changes/56/763856/1 && git format-patch -1 --stdout FETCH_HEAD,['roles/validate-tempest/tasks/tempest-results.yml'],1,4d17000f5e03dcc552e59abfb6f5ee6282098029,, when: send_mail_tempest|default(false)|bool ,,2,0
openstack%2Fnova~stable%2Ftrain~I4abbe30505a5e4ccba16027addd6d5f45066e31b,openstack/nova,stable/train,I4abbe30505a5e4ccba16027addd6d5f45066e31b,docs: Clarify configuration steps for PF devices,MERGED,2020-11-26 11:36:03.000000000,2020-11-27 21:48:42.000000000,2020-11-27 21:46:50.000000000,"[{'_account_id': 10135}, {'_account_id': 17685}, {'_account_id': 22348}]","[{'number': 1, 'created': '2020-11-26 11:36:03.000000000', 'files': ['nova/conf/pci.py', 'doc/source/admin/pci-passthrough.rst'], 'web_link': 'https://opendev.org/openstack/nova/commit/0c0c5b12cf05b5dfb2c3f2e8e4799e4acf94a2ea', 'message': 'docs: Clarify configuration steps for PF devices\n\nDevices that report SR-IOV capabilities cannot be used without special\nconfiguration - namely, the addition of ""\'device_type\': \'type-PF\'"" or\n""\'device_type\': \'type-VF\'"" to the \'[pci] alias\' configuration option.\nSpell this out in the docs.\n\nChange-Id: I4abbe30505a5e4ccba16027addd6d5f45066e31b\nSigned-off-by: Stephen Finucane <sfinucan@redhat.com>\nCloses-Bug: #1852727\n(cherry picked from commit 810aafc5ec9a7d25b33cf6c137c47b117c91269a)\n'}]",0,764329,0c0c5b12cf05b5dfb2c3f2e8e4799e4acf94a2ea,27,3,1,15334,,,0,"docs: Clarify configuration steps for PF devices

Devices that report SR-IOV capabilities cannot be used without special
configuration - namely, the addition of ""'device_type': 'type-PF'"" or
""'device_type': 'type-VF'"" to the '[pci] alias' configuration option.
Spell this out in the docs.

Change-Id: I4abbe30505a5e4ccba16027addd6d5f45066e31b
Signed-off-by: Stephen Finucane <sfinucan@redhat.com>
Closes-Bug: #1852727
(cherry picked from commit 810aafc5ec9a7d25b33cf6c137c47b117c91269a)
",git fetch https://review.opendev.org/openstack/nova refs/changes/29/764329/1 && git format-patch -1 --stdout FETCH_HEAD,"['nova/conf/pci.py', 'doc/source/admin/pci-passthrough.rst']",2,0c0c5b12cf05b5dfb2c3f2e8e4799e4acf94a2ea,bug/1852727,"option, which is a JSON-style configuration option that allows you to map a given device type, identified by the standard PCI ``vendor_id`` and (optional) ``product_id`` fields, to an arbitrary name or *alias*. This alias can then be used to request a PCI device using the ``pci_passthrough:alias=<alias>`` flavor extra spec, as discussed previously. For our sample device with a vendor ID of ``0x8086`` and a product ID of ``0x154d``, this would be:It's important to note the addition of the ``device_type`` field. This is necessary because this PCI device supports SR-IOV. The ``nova-compute`` service categorizes devices into one of three types, depending on the capabilities the devices report: ``type-PF`` The device supports SR-IOV and is the parent or root device. ``type-VF`` The device is a child device of a device that supports SR-IOV. ``type-PCI`` The device does not support SR-IOV. By default, it is only possible to attach ``type-PCI`` devices using PCI passthrough. If you wish to attach ``type-PF`` or ``type-VF`` devices, you must specify the ``device_type`` field in the config option. If the device was a device that did not support SR-IOV, the ``device_type`` field could be omitted. ","option. As noted previously, PCI devices are requested through flavor extra specs - specifically via the ``pci_passthrough:alias`` flavor extra spec - so this config option allows us to map a given type of device to a specific alias. For example, to map the sample PCI device to the alias ``a1``:",27,5
openstack%2Fkayobe~master~Ibe44583cb93b7dca8f5091c893386a15288af915,openstack/kayobe,master,Ibe44583cb93b7dca8f5091c893386a15288af915,Fix Python setup when venv is not used,MERGED,2020-11-22 18:28:37.000000000,2020-11-27 20:28:16.000000000,2020-11-27 20:26:39.000000000,"[{'_account_id': 14826}, {'_account_id': 17669}, {'_account_id': 22348}, {'_account_id': 22629}]","[{'number': 1, 'created': '2020-11-22 18:28:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kayobe/commit/109c698ba842612e320c9ff61c0e9fc4f970b63d', 'message': 'Fix Python setup when venv is not used\n\nSet packages argument explicitly as a list to avoid ""No package matching\n\'<generator object select_or_reject at 0x7ff25f341750>\' is available"" error.\n\nStory: 2008378\nTask: 41298\nChange-Id: Ibe44583cb93b7dca8f5091c893386a15288af915\n'}, {'number': 2, 'created': '2020-11-23 18:52:09.000000000', 'files': ['releasenotes/notes/fix-python-setup-5e7ff929a6cab092.yaml', 'ansible/kayobe-target-venv.yml'], 'web_link': 'https://opendev.org/openstack/kayobe/commit/e748faea00346aeb1a05a1810a386b1f3d21fa75', 'message': 'Fix Python setup when venv is not used\n\nSet packages argument explicitly as a list to avoid ""No package matching\n\'<generator object select_or_reject at 0x7ff25f341750>\' is available"" error.\n\nStory: 2008378\nTask: 41298\nChange-Id: Ibe44583cb93b7dca8f5091c893386a15288af915\n'}]",0,763659,e748faea00346aeb1a05a1810a386b1f3d21fa75,24,4,2,32657,,,0,"Fix Python setup when venv is not used

Set packages argument explicitly as a list to avoid ""No package matching
'<generator object select_or_reject at 0x7ff25f341750>' is available"" error.

Story: 2008378
Task: 41298
Change-Id: Ibe44583cb93b7dca8f5091c893386a15288af915
",git fetch https://review.opendev.org/openstack/kayobe refs/changes/59/763659/2 && git format-patch -1 --stdout FETCH_HEAD,['ansible/kayobe-target-venv.yml'],1,109c698ba842612e320c9ff61c0e9fc4f970b63d,enforce_list," name: ""{{ packages | select | list }}"""," name: ""{{ packages | select }}""",1,1
openstack%2Fneutron~master~I47020f11ccf99cbc2699212c7e87c316e22ddb18,openstack/neutron,master,I47020f11ccf99cbc2699212c7e87c316e22ddb18,DNM Just test openstack-tox-py36-with-ovsdbapp-master,ABANDONED,2020-09-02 15:43:57.000000000,2020-11-27 20:16:16.000000000,,"[{'_account_id': 15752}, {'_account_id': 21798}, {'_account_id': 22348}, {'_account_id': 26622}]","[{'number': 1, 'created': '2020-09-02 15:43:57.000000000', 'files': ['zuul.d/project.yaml'], 'web_link': 'https://opendev.org/openstack/neutron/commit/ad9d8b3ceca35d0a786b55d8e6bb369093e7c04c', 'message': 'DNM Just test openstack-tox-py36-with-ovsdbapp-master\n\nChange-Id: I47020f11ccf99cbc2699212c7e87c316e22ddb18\n'}]",0,749539,ad9d8b3ceca35d0a786b55d8e6bb369093e7c04c,5,4,1,11975,,,0,"DNM Just test openstack-tox-py36-with-ovsdbapp-master

Change-Id: I47020f11ccf99cbc2699212c7e87c316e22ddb18
",git fetch https://review.opendev.org/openstack/neutron refs/changes/39/749539/1 && git format-patch -1 --stdout FETCH_HEAD,['zuul.d/project.yaml'],1,ad9d8b3ceca35d0a786b55d8e6bb369093e7c04c,Icbcb5e004dfa777877d1865a5018262344c7e415, - openstack-tox-py36-with-ovsdbapp-master,,1,0
openstack%2Fopenstack-ansible-os_barbican~master~I0a0754052a0d48792322243341171593bbbd1a41,openstack/openstack-ansible-os_barbican,master,I0a0754052a0d48792322243341171593bbbd1a41,Add deployment of the external libraries,MERGED,2020-11-16 13:59:32.000000000,2020-11-27 20:01:55.000000000,2020-11-27 19:59:35.000000000,"[{'_account_id': 22348}, {'_account_id': 25023}, {'_account_id': 31542}]","[{'number': 1, 'created': '2020-11-16 13:59:32.000000000', 'files': ['releasenotes/notes/barbican_libraries-af0d43f90a4b995d.yaml', 'tasks/barbican_post_install.yml', 'defaults/main.yml'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_barbican/commit/3acae8f8c9510b2deca8dda85cb6bad430c7324c', 'message': 'Add deployment of the external libraries\n\nDeployment of user libraries might be needed for interaction of PKCS#11 module\nwith external HSM solutions.\n\nChange-Id: I0a0754052a0d48792322243341171593bbbd1a41\n'}]",0,762842,3acae8f8c9510b2deca8dda85cb6bad430c7324c,12,3,1,28619,,,0,"Add deployment of the external libraries

Deployment of user libraries might be needed for interaction of PKCS#11 module
with external HSM solutions.

Change-Id: I0a0754052a0d48792322243341171593bbbd1a41
",git fetch https://review.opendev.org/openstack/openstack-ansible-os_barbican refs/changes/42/762842/1 && git format-patch -1 --stdout FETCH_HEAD,"['releasenotes/notes/barbican_libraries-af0d43f90a4b995d.yaml', 'tasks/barbican_post_install.yml', 'defaults/main.yml']",3,3acae8f8c9510b2deca8dda85cb6bad430c7324c,," # With `barbican_user_libraries` you can deploy libraries, needed for barbican # to interact with third party services like HSM #barbican_user_libraries: # - src: /etc/openstack_deploy/barbican/libCryptoki2.so # dest: /opt/barbican/libs/libCryptoki2.so # owner: root # group: ""{{ barbican_system_group_name }}"" barbican_user_libraries: [] ",,37,0
openstack%2Fopenstack-ansible-os_barbican~master~I2a0756b851c9e862b2312b47d37b723386d6915c,openstack/openstack-ansible-os_barbican,master,I2a0756b851c9e862b2312b47d37b723386d6915c,Clean up barbican.conf,MERGED,2020-10-21 15:52:23.000000000,2020-11-27 20:00:57.000000000,2020-11-27 19:59:27.000000000,"[{'_account_id': 22348}, {'_account_id': 25023}, {'_account_id': 28619}, {'_account_id': 29865}]","[{'number': 1, 'created': '2020-10-21 15:52:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_barbican/commit/d8a05e868faa6205305be3a9df08978f8842a8e3', 'message': 'Clean up barbican.conf\n\nDrop out default or misconfigured variables from barbican.conf to\nmake config file readable.\nThis should not affect existing deployments since plugin config has to be\noverriden anyway.\n\nDepends-On: https://review.opendev.org/759082\nChange-Id: I2a0756b851c9e862b2312b47d37b723386d6915c\n'}, {'number': 2, 'created': '2020-10-23 10:06:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_barbican/commit/091f9d43c92144a61d0e21f5ceadd8dfdfb8119f', 'message': 'Clean up barbican.conf\n\nDrop out default or misconfigured variables from barbican.conf to\nmake config file readable.\nThis should not affect existing deployments since plugin config has to be\noverriden anyway.\n\nDepends-On: https://review.opendev.org/759082\nChange-Id: I2a0756b851c9e862b2312b47d37b723386d6915c\n'}, {'number': 3, 'created': '2020-11-10 12:24:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_barbican/commit/54c45f2cdca27d4f5f978ea097c81e74c3d94182', 'message': 'Clean up barbican.conf\n\nDrop out default or misconfigured variables from barbican.conf to\nmake config file readable.\nThis should not affect existing deployments since plugin config has to be\noverriden anyway.\n\nDepends-On: https://review.opendev.org/759082\nChange-Id: I2a0756b851c9e862b2312b47d37b723386d6915c\n'}, {'number': 4, 'created': '2020-11-12 17:34:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_barbican/commit/274cbb1038eca8bffc25c869faf0420c45df5b9c', 'message': 'Clean up barbican.conf\n\nDrop out default or misconfigured variables from barbican.conf to\nmake config file readable.\nThis should not affect existing deployments since plugin config has to be\noverriden anyway.\n\nChange-Id: I2a0756b851c9e862b2312b47d37b723386d6915c\n'}, {'number': 5, 'created': '2020-11-13 10:15:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_barbican/commit/684fe0e328ce2debf692d2f1bac6e01b4171591c', 'message': 'Clean up barbican.conf\n\nDrop out default or misconfigured variables from barbican.conf to\nmake config file readable.\nThis should not affect existing deployments since plugin config has to be\noverriden anyway.\n\nDepends-On: https://review.opendev.org/759082\nChange-Id: I2a0756b851c9e862b2312b47d37b723386d6915c\n'}, {'number': 6, 'created': '2020-11-13 20:34:55.000000000', 'files': ['templates/barbican.conf.j2', 'defaults/main.yml'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_barbican/commit/76b72c097571d45d59ebed67bfb556ad3464a44b', 'message': 'Clean up barbican.conf\n\nDrop out default or misconfigured variables from barbican.conf to\nmake config file readable.\nThis should not affect existing deployments since plugin config has to be\noverriden anyway.\n\nDepends-On: https://review.opendev.org/759082\nChange-Id: I2a0756b851c9e862b2312b47d37b723386d6915c\n'}]",0,759084,76b72c097571d45d59ebed67bfb556ad3464a44b,32,4,6,28619,,,0,"Clean up barbican.conf

Drop out default or misconfigured variables from barbican.conf to
make config file readable.
This should not affect existing deployments since plugin config has to be
overriden anyway.

Depends-On: https://review.opendev.org/759082
Change-Id: I2a0756b851c9e862b2312b47d37b723386d6915c
",git fetch https://review.opendev.org/openstack/openstack-ansible-os_barbican refs/changes/84/759084/5 && git format-patch -1 --stdout FETCH_HEAD,"['templates/barbican.conf.j2', 'defaults/main.yml']",2,d8a05e868faa6205305be3a9df08978f8842a8e3,,barbican_ceilometer_enabled: False,,3,326
openstack%2Fopenstack-ansible-os_barbican~master~I3369c4254f3b48f12ed9731f18d980044e6d0b43,openstack/openstack-ansible-os_barbican,master,I3369c4254f3b48f12ed9731f18d980044e6d0b43,Allow multibackend support for Barbican,MERGED,2020-11-13 16:51:26.000000000,2020-11-27 19:59:31.000000000,2020-11-27 19:59:31.000000000,"[{'_account_id': 22348}, {'_account_id': 25023}, {'_account_id': 29865}]","[{'number': 1, 'created': '2020-11-13 16:51:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_barbican/commit/2bb45e4df1cefef2acfecb1eb39a61b490861f0e', 'message': 'Allow multibackend support for Barbican\n\nThis patch introduces 2 new variables that are designed to help deployer\nwith barbican configuration. They are designed to support multibackend\ncaonfiguration of the barbican while default behavior should not change.\n\nChange-Id: I3369c4254f3b48f12ed9731f18d980044e6d0b43\n'}, {'number': 2, 'created': '2020-11-13 17:46:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_barbican/commit/4d3211bae22c6446efadff32c9c6f7f2cf79c562', 'message': 'Allow multibackend support for Barbican\n\nThis patch introduces 2 new variables that are designed to help deployer\nwith barbican configuration. They are designed to support multibackend\ncaonfiguration of the barbican while default behavior should not change.\n\nChange-Id: I3369c4254f3b48f12ed9731f18d980044e6d0b43\n'}, {'number': 3, 'created': '2020-11-13 17:53:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_barbican/commit/b237e4d31dca2d140897b4223b3f128e775d1537', 'message': 'Allow multibackend support for Barbican\n\nThis patch introduces 2 new variables that are designed to help deployer\nwith barbican configuration. They are designed to support multibackend\ncaonfiguration of the barbican while default behavior should not change.\n\nChange-Id: I3369c4254f3b48f12ed9731f18d980044e6d0b43\n'}, {'number': 4, 'created': '2020-11-13 17:55:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_barbican/commit/8c30ff7d7dfeb655cb6927112471cfef835f2ed4', 'message': 'Allow multibackend support for Barbican\n\nThis patch introduces 2 new variables that are designed to help deployer\nwith barbican configuration. They are designed to support multibackend\ncaonfiguration of the barbican while default behavior should not change.\n\nChange-Id: I3369c4254f3b48f12ed9731f18d980044e6d0b43\n'}, {'number': 5, 'created': '2020-11-13 17:59:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_barbican/commit/ae0c1ade26edc737f1e0d7f96f069add24588091', 'message': 'Allow multibackend support for Barbican\n\nThis patch introduces 2 new variables that are designed to help deployer\nwith barbican configuration. They are designed to support multibackend\ncaonfiguration of the barbican while default behavior should not change.\n\nChange-Id: I3369c4254f3b48f12ed9731f18d980044e6d0b43\n'}, {'number': 6, 'created': '2020-11-14 07:29:30.000000000', 'files': ['releasenotes/notes/barbican_backends-7d070edd33401f35.yaml', 'templates/barbican.conf.j2', 'defaults/main.yml'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_barbican/commit/50c983e0348ed104ecdc72038a0daf70220d500b', 'message': 'Allow multibackend support for Barbican\n\nThis patch introduces 2 new variables that are designed to help deployer\nwith barbican configuration. They are designed to support multibackend\ncaonfiguration of the barbican while default behavior should not change.\n\nChange-Id: I3369c4254f3b48f12ed9731f18d980044e6d0b43\n'}]",0,762691,50c983e0348ed104ecdc72038a0daf70220d500b,19,3,6,28619,,,0,"Allow multibackend support for Barbican

This patch introduces 2 new variables that are designed to help deployer
with barbican configuration. They are designed to support multibackend
caonfiguration of the barbican while default behavior should not change.

Change-Id: I3369c4254f3b48f12ed9731f18d980044e6d0b43
",git fetch https://review.opendev.org/openstack/openstack-ansible-os_barbican refs/changes/91/762691/1 && git format-patch -1 --stdout FETCH_HEAD,"['releasenotes/notes/barbican_backends-7d070edd33401f35.yaml', 'templates/barbican.conf.j2', 'defaults/main.yml']",3,2bb45e4df1cefef2acfecb1eb39a61b490861f0e,759084,"# Variable defines barbican store backends configuration. It supports multibackend scenario # in case list length > 1. Then additional key global_default should be present, otherwise # first element would be set as global default. For multibackend one backend should be set # as global_default: True barbican_backends_config: software: secret_store_plugin: store_crypto crypto_plugin: simple_crypto # Variable defines barbican crypto configuration. barbican_crypto_plugins_config: simple_crypto_plugin: kek: ""{{ barbican_simple_crypto_key | b64encode }}"" ",,42,3
openstack%2Fopenstack-helm-infra~master~I53744117af6962d51519bc1d96329129473d9970,openstack/openstack-helm-infra,master,I53744117af6962d51519bc1d96329129473d9970,Fix values_overrides directory naming,MERGED,2020-11-26 13:55:13.000000000,2020-11-27 19:23:45.000000000,2020-11-27 19:22:34.000000000,"[{'_account_id': 7769}, {'_account_id': 8863}, {'_account_id': 8898}, {'_account_id': 12281}, {'_account_id': 20466}, {'_account_id': 21420}, {'_account_id': 22348}, {'_account_id': 22477}, {'_account_id': 23928}, {'_account_id': 30777}]","[{'number': 1, 'created': '2020-11-26 13:55:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/a69a2694eb8a47b4d634711d9361e451b74ba507', 'message': 'Fix values_overrides directory naming\n\nAccording to get-values-overrides.sh script it is expected to\nhave values_overrides directory, not value_overrides.\n\nChange-Id: I53744117af6962d51519bc1d96329129473d9970\n'}, {'number': 2, 'created': '2020-11-27 08:59:31.000000000', 'files': ['prometheus-process-exporter/values_overrides/apparmor.yaml', 'prometheus-process-exporter/Chart.yaml'], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/5f6adeca06d6fb59b67b9f4a31a36e3cd3a2bb59', 'message': 'Fix values_overrides directory naming\n\nAccording to get-values-overrides.sh script it is expected to\nhave values_overrides directory, not value_overrides.\n\nChange-Id: I53744117af6962d51519bc1d96329129473d9970\n'}]",0,764348,5f6adeca06d6fb59b67b9f4a31a36e3cd3a2bb59,13,10,2,28735,,,0,"Fix values_overrides directory naming

According to get-values-overrides.sh script it is expected to
have values_overrides directory, not value_overrides.

Change-Id: I53744117af6962d51519bc1d96329129473d9970
",git fetch https://review.opendev.org/openstack/openstack-helm-infra refs/changes/48/764348/2 && git format-patch -1 --stdout FETCH_HEAD,['prometheus-process-exporter/values_overrides/apparmor.yaml'],1,a69a2694eb8a47b4d634711d9361e451b74ba507,,,,0,0
openstack%2Fopenstack-helm-infra~master~I216d16de1f4fb1438534c9362b57499ec3d6725b,openstack/openstack-helm-infra,master,I216d16de1f4fb1438534c9362b57499ec3d6725b,Changing the kube version to 1.18.9,MERGED,2020-10-15 18:44:14.000000000,2020-11-27 19:22:26.000000000,2020-11-27 19:20:56.000000000,"[{'_account_id': 8863}, {'_account_id': 8898}, {'_account_id': 12281}, {'_account_id': 18256}, {'_account_id': 22348}, {'_account_id': 22636}, {'_account_id': 29131}, {'_account_id': 29144}, {'_account_id': 29161}, {'_account_id': 32029}]","[{'number': 1, 'created': '2020-10-15 18:44:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/91034a4be7b69526fa753f2db1350ebaa862e928', 'message': 'Changing the kube version to 1.18.9\n\nChange-Id: I216d16de1f4fb1438534c9362b57499ec3d6725b\n'}, {'number': 2, 'created': '2020-10-15 21:09:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/e08d3573c53e5cd22cbbee363b28fc5fd12aba2a', 'message': 'Changing the kube version to 1.18.9\n\nChange-Id: I216d16de1f4fb1438534c9362b57499ec3d6725b\n'}, {'number': 3, 'created': '2020-11-09 23:15:33.000000000', 'files': ['tools/images/kubeadm-aio/assets/opt/playbooks/vars.yaml', 'tools/images/kubeadm-aio/Dockerfile', 'roles/build-images/defaults/main.yml'], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/c988632091a03155186ddb96b6c8cd25c227dc7b', 'message': 'Changing the kube version to 1.18.9\n\nChange-Id: I216d16de1f4fb1438534c9362b57499ec3d6725b\n'}]",0,758478,c988632091a03155186ddb96b6c8cd25c227dc7b,21,10,3,24780,,,0,"Changing the kube version to 1.18.9

Change-Id: I216d16de1f4fb1438534c9362b57499ec3d6725b
",git fetch https://review.opendev.org/openstack/openstack-helm-infra refs/changes/78/758478/1 && git format-patch -1 --stdout FETCH_HEAD,['tools/images/kubeadm-aio/Dockerfile'],1,91034a4be7b69526fa753f2db1350ebaa862e928,,"ARG KUBE_VERSION=""v1.18.9""","ARG KUBE_VERSION=""v1.16.2""",1,1
openstack%2Ftripleo-heat-templates~master~Iea8cccd77caac4b84764d84a213918ed57bd4e3e,openstack/tripleo-heat-templates,master,Iea8cccd77caac4b84764d84a213918ed57bd4e3e,Set correct default NovaLibvirtCPUMode,MERGED,2020-11-25 12:09:13.000000000,2020-11-27 17:01:05.000000000,2020-11-27 16:59:42.000000000,"[{'_account_id': 6926}, {'_account_id': 6962}, {'_account_id': 8449}, {'_account_id': 11090}, {'_account_id': 14985}, {'_account_id': 20172}, {'_account_id': 20733}, {'_account_id': 22348}, {'_account_id': 23181}, {'_account_id': 23811}]","[{'number': 1, 'created': '2020-11-25 12:09:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/7b0ae65f7891102df54a8fa9a7080f63f0a35bf4', 'message': ""Set correct default NovaLibvirtCPUMode\n\nhttps://review.opendev.org/q/I8df21d5d171976cbb8670dc5aef744b5fae657b2\nintroduced THT parameters to set libvirt/cpu_mode. The patch sets the\nNovaLibvirtCPUMode wrong to 'none' string which results in puppet-nova not\nto handle the default cases correct and sets libvirt/cpu_mode to none which\nresults in qemu64 CPU model be used. This changes the default to 'host-model'\n\nCloses-Bug: #1905544\n\nChange-Id: Iea8cccd77caac4b84764d84a213918ed57bd4e3e\n""}, {'number': 2, 'created': '2020-11-25 14:16:48.000000000', 'files': ['deployment/nova/nova-compute-container-puppet.yaml', 'releasenotes/notes/nova_compute_default_cpu_mode-cda2bb3e56463b3a.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/c290a5e3a10b2ca6599b09f813da875d6aaa4f9f', 'message': ""Set correct default NovaLibvirtCPUMode\n\nhttps://review.opendev.org/q/I8df21d5d171976cbb8670dc5aef744b5fae657b2\nintroduced THT parameters to set libvirt/cpu_mode. The patch sets the\nNovaLibvirtCPUMode wrong to 'none' string which results in puppet-nova\nnot to handle the default cases correct and sets libvirt/cpu_mode to\nnone which results in 'qemu64' CPU model, which is highly buggy and\nundesirable for production usage.  This changes the default to the\nrecommended CPU mode 'host-model', for various benefits documented\nelsewhere.\n\nCloses-Bug: #1905544\n\nChange-Id: Iea8cccd77caac4b84764d84a213918ed57bd4e3e\n""}]",3,764158,c290a5e3a10b2ca6599b09f813da875d6aaa4f9f,27,10,2,17216,,,0,"Set correct default NovaLibvirtCPUMode

https://review.opendev.org/q/I8df21d5d171976cbb8670dc5aef744b5fae657b2
introduced THT parameters to set libvirt/cpu_mode. The patch sets the
NovaLibvirtCPUMode wrong to 'none' string which results in puppet-nova
not to handle the default cases correct and sets libvirt/cpu_mode to
none which results in 'qemu64' CPU model, which is highly buggy and
undesirable for production usage.  This changes the default to the
recommended CPU mode 'host-model', for various benefits documented
elsewhere.

Closes-Bug: #1905544

Change-Id: Iea8cccd77caac4b84764d84a213918ed57bd4e3e
",git fetch https://review.opendev.org/openstack/tripleo-heat-templates refs/changes/58/764158/2 && git format-patch -1 --stdout FETCH_HEAD,"['deployment/nova/nova-compute-container-puppet.yaml', 'releasenotes/notes/nova_compute_default_cpu_mode-cda2bb3e56463b3a.yaml']",2,7b0ae65f7891102df54a8fa9a7080f63f0a35bf4,fix_default_cpu_mode,--- fixes: - | https://review.opendev.org/q/I8df21d5d171976cbb8670dc5aef744b5fae657b2 introduced THT parameters to set libvirt/cpu_mode. The patch sets the NovaLibvirtCPUMode wrong to 'none' string which results in puppet-nova not to handle the default cases correct and sets libvirt/cpu_mode to none which results in qemu64 CPU model be used. This changes the default to 'host-model' ,,9,1
openstack%2Fopenstack-helm-infra~master~I65955c4a9ddfa92a98b7aa3aaadef8fbc5f04a37,openstack/openstack-helm-infra,master,I65955c4a9ddfa92a98b7aa3aaadef8fbc5f04a37,Ensure Openstack containers are restricted from acquiring new priviliges,ABANDONED,2020-11-25 13:12:55.000000000,2020-11-27 16:41:12.000000000,,[{'_account_id': 22348}],"[{'number': 1, 'created': '2020-11-25 13:12:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/06a403d9fdb65287539734d581fa0c95d8e34fa9', 'message': 'Ensure Openstack containers are restricted from acquiring new priviliges\n\nChange-Id: I65955c4a9ddfa92a98b7aa3aaadef8fbc5f04a37\n'}, {'number': 2, 'created': '2020-11-25 14:21:57.000000000', 'files': ['nagios/Chart.yaml', 'nagios/values.yaml', 'mariadb/Chart.yaml', 'mariadb/values.yaml'], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/a2d60ddb8deb180adce38c54a110b60fb6e97060', 'message': 'Ensure Openstack containers are restricted from acquiring new priviliges\n\nChange-Id: I65955c4a9ddfa92a98b7aa3aaadef8fbc5f04a37\n'}]",0,764164,a2d60ddb8deb180adce38c54a110b60fb6e97060,7,1,2,32725,,,0,"Ensure Openstack containers are restricted from acquiring new priviliges

Change-Id: I65955c4a9ddfa92a98b7aa3aaadef8fbc5f04a37
",git fetch https://review.opendev.org/openstack/openstack-helm-infra refs/changes/64/764164/1 && git format-patch -1 --stdout FETCH_HEAD,"['nagios/values.yaml', 'mariadb/values.yaml']",2,06a403d9fdb65287539734d581fa0c95d8e34fa9,, readOnlyRootFilesystem: true, readOnlyRootFilesystem: false,2,2
openstack%2Fopenstack-helm~master~I29115c1b6812b762126c04d6559d882360b6cb8f,openstack/openstack-helm,master,I29115c1b6812b762126c04d6559d882360b6cb8f,Ensure Openstack containers are restricted from acquiring new privileges,ABANDONED,2020-11-25 12:49:19.000000000,2020-11-27 16:40:56.000000000,,[{'_account_id': 22348}],"[{'number': 1, 'created': '2020-11-25 12:49:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm/commit/74789d74532e03bb40c62bd641170e349927cc37', 'message': 'Ensure Openstack containers are restricted from acquiring new privileges\n\nChange-Id: I29115c1b6812b762126c04d6559d882360b6cb8f\n'}, {'number': 2, 'created': '2020-11-25 14:23:41.000000000', 'files': ['placement/values.yaml', 'placement/Chart.yaml'], 'web_link': 'https://opendev.org/openstack/openstack-helm/commit/8c94d887826f6e3c6571a46cab92638c2dee5698', 'message': 'Ensure Openstack containers are restricted from acquiring new privileges\n\nChange-Id: I29115c1b6812b762126c04d6559d882360b6cb8f\n'}]",0,764161,8c94d887826f6e3c6571a46cab92638c2dee5698,7,1,2,32725,,,0,"Ensure Openstack containers are restricted from acquiring new privileges

Change-Id: I29115c1b6812b762126c04d6559d882360b6cb8f
",git fetch https://review.opendev.org/openstack/openstack-helm refs/changes/61/764161/1 && git format-patch -1 --stdout FETCH_HEAD,['placement/values.yaml'],1,74789d74532e03bb40c62bd641170e349927cc37,, readOnlyRootFilesystem: true, readOnlyRootFilesystem: false,1,1
openstack%2Fnova~stable%2Fvictoria~Ia108a7ac04defe742efcac09e7c0d61b08ab4e6d,openstack/nova,stable/victoria,Ia108a7ac04defe742efcac09e7c0d61b08ab4e6d,zuul: Skip test_attach_scsi_disk_with_config_drive in nova-ceph-multistore,ABANDONED,2020-11-27 13:41:51.000000000,2020-11-27 15:59:32.000000000,,"[{'_account_id': 7166}, {'_account_id': 17685}]","[{'number': 1, 'created': '2020-11-27 13:41:51.000000000', 'files': ['.zuul.yaml'], 'web_link': 'https://opendev.org/openstack/nova/commit/0575a944d5d4df553da5beaef5cc870ed5afb5fc', 'message': 'zuul: Skip test_attach_scsi_disk_with_config_drive in nova-ceph-multistore\n\nRelated-Bug: #1905725\nChange-Id: Ia108a7ac04defe742efcac09e7c0d61b08ab4e6d\n(cherry picked from commit 836e13cd5785a9614bcddb98ee2b7367a3dc8541)\n'}]",1,764464,0575a944d5d4df553da5beaef5cc870ed5afb5fc,4,2,1,10135,,,0,"zuul: Skip test_attach_scsi_disk_with_config_drive in nova-ceph-multistore

Related-Bug: #1905725
Change-Id: Ia108a7ac04defe742efcac09e7c0d61b08ab4e6d
(cherry picked from commit 836e13cd5785a9614bcddb98ee2b7367a3dc8541)
",git fetch https://review.opendev.org/openstack/nova refs/changes/64/764464/1 && git format-patch -1 --stdout FETCH_HEAD,['.zuul.yaml'],1,0575a944d5d4df553da5beaef5cc870ed5afb5fc,, # FIXME(lyarwood): test_attach_scsi_disk_with_config_drive attempts to # delete an image that has been cloned by nova ahead of the instance # being removed. Skip this test until it is reworked to remove the server # ahead of the image. tempest_black_regex: .*encrypted_cinder_volumes.*|.*test_attach_scsi_disk_with_config_drive, tempest_black_regex: .*encrypted_cinder_volumes.*,5,1
openstack%2Fproject-config~master~I2ce1c12dbb57e5e0fc366856009396a55ecf5468,openstack/project-config,master,I2ce1c12dbb57e5e0fc366856009396a55ecf5468,add review-priority for tripleo-ci,MERGED,2020-03-25 21:17:09.000000000,2020-11-27 15:48:39.000000000,2020-11-27 15:38:11.000000000,"[{'_account_id': 3153}, {'_account_id': 4146}, {'_account_id': 5263}, {'_account_id': 7118}, {'_account_id': 14985}, {'_account_id': 22348}, {'_account_id': 24162}]","[{'number': 1, 'created': '2020-03-25 21:17:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/project-config/commit/443f268446bbb2c415f0825cceb2be2d5d61972e', 'message': 'add review-priority for tripleo-ci\n\nadd review priority as an experiment for the\nrest of tripleo before changing all of the\ntripleo repos.\n\nChange-Id: I2ce1c12dbb57e5e0fc366856009396a55ecf5468\n'}, {'number': 2, 'created': '2020-11-24 13:08:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/project-config/commit/db6a356fcc9f5e09c298ae30ce14cd3f00d593de', 'message': 'add review-priority for tripleo-ci\n\nadd review priority as an experiment for the\nrest of tripleo before changing all of the\ntripleo repos.\n\nChange-Id: I2ce1c12dbb57e5e0fc366856009396a55ecf5468\n'}, {'number': 3, 'created': '2020-11-24 14:39:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/project-config/commit/b1284c75e3c3aa62bd5806a1567864874af502b3', 'message': 'add review-priority for tripleo-ci\n\nadd review priority as an experiment for the\nrest of tripleo before changing all of the\ntripleo repos.\n\nChange-Id: I2ce1c12dbb57e5e0fc366856009396a55ecf5468\n'}, {'number': 4, 'created': '2020-11-24 16:01:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/project-config/commit/19656dc48a51180bb8d327d465f08b792cff52dd', 'message': 'add review-priority for tripleo-ci\n\nadd review priority as an experiment for the\nrest of tripleo before changing all of the\ntripleo repos.\n\nChange-Id: I2ce1c12dbb57e5e0fc366856009396a55ecf5468\n'}, {'number': 5, 'created': '2020-11-27 13:34:09.000000000', 'files': ['gerrit/acls/openstack/tripleo-ci.config'], 'web_link': 'https://opendev.org/openstack/project-config/commit/845a3d9724c1ba60971772bec13d94fa20c6f83a', 'message': 'add review-priority for tripleo-ci\n\nadd review priority as an experiment for the\nrest of tripleo before changing all of the\ntripleo repos.\n\nChange-Id: I2ce1c12dbb57e5e0fc366856009396a55ecf5468\n'}]",3,715069,845a3d9724c1ba60971772bec13d94fa20c6f83a,22,7,5,9592,,,0,"add review-priority for tripleo-ci

add review priority as an experiment for the
rest of tripleo before changing all of the
tripleo repos.

Change-Id: I2ce1c12dbb57e5e0fc366856009396a55ecf5468
",git fetch https://review.opendev.org/openstack/project-config refs/changes/69/715069/1 && git format-patch -1 --stdout FETCH_HEAD,['gerrit/acls/openstack/tripleo-ci.config'],1,443f268446bbb2c415f0825cceb2be2d5d61972e,," [label ""Review-Priority""] copyAllScoresIfNoCodeChange = true copyAllScoresOnTrivialRebase = true copyMaxScore = true copyMinScore = true defaultValue = 0 function = AnyWithBlock value = -1 Branch Freeze value = 0 No Priority value = +1 Important Change value = +2 Gate Blocker Fix / Urgent Change",,12,0
openstack%2Fcinder~master~I01e083009b3ee3dc4885486efe641a3b88df7e1d,openstack/cinder,master,I01e083009b3ee3dc4885486efe641a3b88df7e1d,PowerMax Driver - Remove six for PowerMax driver,ABANDONED,2020-10-27 19:06:48.000000000,2020-11-27 15:46:31.000000000,,"[{'_account_id': 9008}, {'_account_id': 10118}, {'_account_id': 11611}, {'_account_id': 12016}, {'_account_id': 12017}, {'_account_id': 12032}, {'_account_id': 12033}, {'_account_id': 12369}, {'_account_id': 12670}, {'_account_id': 15386}, {'_account_id': 15941}, {'_account_id': 21884}, {'_account_id': 22248}, {'_account_id': 22348}, {'_account_id': 22510}, {'_account_id': 23601}, {'_account_id': 23613}, {'_account_id': 24814}, {'_account_id': 24815}, {'_account_id': 24921}, {'_account_id': 25243}, {'_account_id': 25678}, {'_account_id': 26077}, {'_account_id': 26537}, {'_account_id': 28801}, {'_account_id': 30688}, {'_account_id': 31868}, {'_account_id': 32159}]","[{'number': 1, 'created': '2020-10-27 19:06:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/a7e1d2da37cb519de8ec090dd27a95fea57f012b', 'message': 'PowerMax Driver - Remove six for PowerMax driver\n\nReplace the following items with the Python3 style code\nsix.string_types\nsix.text_type\n\nChange-Id: I01e083009b3ee3dc4885486efe641a3b88df7e1d\nImplements: blueprint powermax-six-removal\n'}, {'number': 2, 'created': '2020-11-19 15:20:19.000000000', 'files': ['cinder/volume/drivers/dell_emc/powermax/iscsi.py', 'cinder/volume/drivers/dell_emc/powermax/performance.py', 'cinder/volume/drivers/dell_emc/powermax/masking.py', 'cinder/tests/unit/volume/drivers/dell_emc/powermax/test_powermax_performance.py', 'cinder/volume/drivers/dell_emc/powermax/common.py', 'cinder/volume/drivers/dell_emc/powermax/metadata.py', 'cinder/tests/unit/volume/drivers/dell_emc/powermax/test_powermax_utils.py', 'cinder/volume/drivers/dell_emc/powermax/rest.py', 'cinder/tests/unit/volume/drivers/dell_emc/powermax/test_powermax_common.py', 'cinder/volume/drivers/dell_emc/powermax/utils.py', 'cinder/tests/unit/volume/drivers/dell_emc/powermax/test_powermax_replication.py', 'cinder/tests/unit/volume/drivers/dell_emc/powermax/powermax_data.py'], 'web_link': 'https://opendev.org/openstack/cinder/commit/6ad3a66b1a2017ee1e0f079976f4e59e89c9919f', 'message': 'PowerMax Driver - Remove six for PowerMax driver\n\nReplace the following items with the Python3 style code\nsix.string_types\nsix.text_type\n\nChange-Id: I01e083009b3ee3dc4885486efe641a3b88df7e1d\nImplements: blueprint powermax-six-removal\n'}]",0,759930,6ad3a66b1a2017ee1e0f079976f4e59e89c9919f,66,28,2,12670,,,0,"PowerMax Driver - Remove six for PowerMax driver

Replace the following items with the Python3 style code
six.string_types
six.text_type

Change-Id: I01e083009b3ee3dc4885486efe641a3b88df7e1d
Implements: blueprint powermax-six-removal
",git fetch https://review.opendev.org/openstack/cinder refs/changes/30/759930/1 && git format-patch -1 --stdout FETCH_HEAD,"['cinder/volume/drivers/dell_emc/powermax/iscsi.py', 'cinder/volume/drivers/dell_emc/powermax/masking.py', 'cinder/tests/unit/volume/drivers/dell_emc/powermax/test_powermax_common.py', 'cinder/volume/drivers/dell_emc/powermax/common.py', 'cinder/volume/drivers/dell_emc/powermax/metadata.py', 'cinder/tests/unit/volume/drivers/dell_emc/powermax/test_powermax_utils.py', 'cinder/volume/drivers/dell_emc/powermax/utils.py', 'cinder/tests/unit/volume/drivers/dell_emc/powermax/test_powermax_replication.py', 'cinder/tests/unit/volume/drivers/dell_emc/powermax/powermax_data.py', 'cinder/volume/drivers/dell_emc/powermax/rest.py']",10,a7e1d2da37cb519de8ec090dd27a95fea57f012b,,"# Copyright (c) 2020 Dell Inc. or its subsidiaries. # All Rights Reserved. # # Licensed under the Apache License, Version 2.0 (the ""License""); you may # not use this file except in compliance with the License. You may obtain # a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT # WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the # License for the specific language governing permissions and limitations # under the License. import json import re import sys import time from oslo_log import log as logging from oslo_service import loopingcall import requests import requests.auth import requests.exceptions as r_exc # pylint: disable=E0401 import requests.packages.urllib3.util.retry as requests_retry from cinder import exception from cinder.i18n import _ from cinder.utils import retry from cinder.volume.drivers.dell_emc.powermax import utils LOG = logging.getLogger(__name__) SLOPROVISIONING = 'sloprovisioning' REPLICATION = 'replication' SYSTEM = 'system' U4V_VERSION = '92' MIN_U4P_VERSION = '9.2.0.0' UCODE_5978 = '5978' retry_exc_tuple = (exception.VolumeBackendAPIException,) u4p_failover_max_wait = 120 # HTTP constants GET = 'GET' POST = 'POST' PUT = 'PUT' DELETE = 'DELETE' STATUS_200 = 200 STATUS_201 = 201 STATUS_202 = 202 STATUS_204 = 204 SERVER_ERROR_STATUS_CODES = [408, 501, 502, 503, 504] ITERATOR_EXPIRATION = 180 # Job constants INCOMPLETE_LIST = ['created', 'unscheduled', 'scheduled', 'running', 'validating', 'validated'] CREATED = 'created' SUCCEEDED = 'succeeded' CREATE_VOL_STRING = ""Creating new Volumes"" POPULATE_SG_LIST = ""Populating Storage Group(s) with volumes"" class PowerMaxRest(object): """"""Rest class based on Unisphere for PowerMax Rest API."""""" def __init__(self): self.utils = utils.PowerMaxUtils() self.session = None self.base_uri = None self.user = None self.passwd = None self.verify = None self.cert = None # Failover Unisphere configuration self.primary_u4p = None self.u4p_failover_enabled = False self.u4p_failover_autofailback = True self.u4p_failover_targets = list() self.u4p_failover_retries = 3 self.u4p_failover_timeout = 30 self.u4p_failover_backoff_factor = 1 self.u4p_in_failover = False self.u4p_failover_lock = False self.ucode_major_level = None self.ucode_minor_level = None self.is_snap_id = False def set_rest_credentials(self, array_info): """"""Given the array record set the rest server credentials. :param array_info: record """""" ip = array_info['RestServerIp'] port = array_info['RestServerPort'] self.user = array_info['RestUserName'] self.passwd = array_info['RestPassword'] self.verify = array_info['SSLVerify'] ip_port = ""%(ip)s:%(port)s"" % {'ip': ip, 'port': port} self.base_uri = (""https://%(ip_port)s/univmax/restapi"" % { 'ip_port': ip_port}) self.session = self._establish_rest_session() self.ucode_major_level, self.ucode_minor_level = ( self.get_major_minor_ucode(array_info['SerialNumber'])) self.is_snap_id = self._is_snapid_enabled() def set_u4p_failover_config(self, failover_info): """"""Set the environment failover Unisphere targets and configuration.. :param failover_info: failover target record """""" self.u4p_failover_enabled = True self.primary_u4p = failover_info['u4p_primary'] self.u4p_failover_targets = failover_info['u4p_failover_targets'] if failover_info['u4p_failover_retries']: self.u4p_failover_retries = failover_info['u4p_failover_retries'] if failover_info['u4p_failover_timeout']: self.u4p_failover_timeout = failover_info['u4p_failover_timeout'] if failover_info['u4p_failover_backoff_factor']: self.u4p_failover_backoff_factor = failover_info[ 'u4p_failover_backoff_factor'] if failover_info['u4p_failover_autofailback']: self.u4p_failover_autofailback = failover_info[ 'u4p_failover_autofailback'] def _establish_rest_session(self): """"""Establish the rest session. :returns: requests.session() -- session, the rest session """""" LOG.info(""Establishing REST session with %(base_uri)s"", {'base_uri': self.base_uri}) if self.session: self.session.close() session = requests.session() session.headers = {'content-type': 'application/json', 'accept': 'application/json', 'Application-Type': 'openstack'} session.auth = requests.auth.HTTPBasicAuth(self.user, self.passwd) if self.verify is not None: session.verify = self.verify # SESSION FAILOVER CONFIGURATION if self.u4p_failover_enabled: timeout = self.u4p_failover_timeout class MyHTTPAdapter(requests.adapters.HTTPAdapter): def send(self, *args, **kwargs): kwargs['timeout'] = timeout return super(MyHTTPAdapter, self).send(*args, **kwargs) retry = requests_retry.Retry( total=self.u4p_failover_retries, backoff_factor=self.u4p_failover_backoff_factor, status_forcelist=SERVER_ERROR_STATUS_CODES) adapter = MyHTTPAdapter(max_retries=retry) session.mount('https://', adapter) session.mount('http://', adapter) return session def _handle_u4p_failover(self): """"""Handle the failover process to secondary instance of Unisphere. :raises: VolumeBackendAPIException """""" if self.u4p_failover_targets: LOG.error(""Unisphere failure at %(prim)s, switching to next "" ""backup instance of Unisphere at %(sec)s"", { 'prim': self.base_uri, 'sec': self.u4p_failover_targets[0][ 'RestServerIp']}) self.set_rest_credentials(self.u4p_failover_targets[0]) self.u4p_failover_targets.pop(0) if self.u4p_in_failover: LOG.warning(""PowerMax driver still in u4p failover mode. A "" ""periodic check will be made to see if primary "" ""Unisphere comes back online for seamless "" ""restoration."") else: LOG.warning(""PowerMax driver set to u4p failover mode. A "" ""periodic check will be made to see if primary "" ""Unisphere comes back online for seamless "" ""restoration."") self.u4p_in_failover = True else: msg = _(""A connection could not be established with the "" ""primary instance of Unisphere or any of the "" ""specified failover instances of Unisphere. Please "" ""check your local environment setup and restart "" ""Cinder Volume service to revert back to the primary "" ""Unisphere instance."") self.u4p_failover_lock = False raise exception.VolumeBackendAPIException(message=msg) def request(self, target_uri, method, params=None, request_object=None, u4p_check=False, retry=False): """"""Sends a request (GET, POST, PUT, DELETE) to the target api. :param target_uri: target uri (string) :param method: The method (GET, POST, PUT, or DELETE) :param params: Additional URL parameters :param request_object: request payload (dict) :param u4p_check: if request is testing connection (boolean) :param retry: if request is retry from prior failed request (boolean) :returns: server response object (dict) :raises: VolumeBackendAPIException, Timeout, ConnectionError, HTTPError, SSLError """""" waiting_time = 0 while self.u4p_failover_lock and not retry and ( waiting_time < u4p_failover_max_wait): LOG.warning(""Unisphere failover lock in process, holding request "" ""until lock is released when Unisphere connection "" ""re-established."") sleeptime = 10 time.sleep(sleeptime) waiting_time += sleeptime if waiting_time >= u4p_failover_max_wait: self.u4p_failover_lock = False url, message, status_code, response = None, None, None, None if not self.session: self.session = self._establish_rest_session() try: url = (""%(self.base_uri)s%(target_uri)s"" % { 'self.base_uri': self.base_uri, 'target_uri': target_uri}) if request_object: response = self.session.request( method=method, url=url, data=json.dumps(request_object, sort_keys=True, indent=4)) elif params: response = self.session.request( method=method, url=url, params=params) else: response = self.session.request( method=method, url=url) status_code = response.status_code if retry and status_code and status_code in [STATUS_200, STATUS_201, STATUS_202, STATUS_204]: self.u4p_failover_lock = False try: message = response.json() except ValueError: LOG.debug(""No response received from API. Status code "" ""received is: %(status_code)s"", { 'status_code': status_code}) message = None if retry: self.u4p_failover_lock = False LOG.debug(""%(method)s request to %(url)s has returned with "" ""a status code of: %(status_code)s."", { 'method': method, 'url': url, 'status_code': status_code}) except r_exc.SSLError as e: if retry: self.u4p_failover_lock = False msg = _(""The connection to %(base_uri)s has encountered an "" ""SSL error. Please check your SSL config or supplied "" ""SSL cert in Cinder configuration. SSL Exception "" ""message: %(e)s"") raise r_exc.SSLError(msg % {'base_uri': self.base_uri, 'e': e}) except (r_exc.Timeout, r_exc.ConnectionError, r_exc.HTTPError) as e: if self.u4p_failover_enabled or u4p_check: if not u4p_check: # Failover process LOG.warning(""Running failover to backup instance "" ""of Unisphere"") self.u4p_failover_lock = True self._handle_u4p_failover() # Failover complete, re-run failed operation LOG.info(""Running request again to backup instance of "" ""Unisphere"") status_code, message = self.request( target_uri, method, params, request_object, retry=True) elif not self.u4p_failover_enabled: exc_class, __, __ = sys.exc_info() msg = _(""The %(method)s to Unisphere server %(base)s has "" ""experienced a %(error)s error. Please check your "" ""Unisphere server connection/availability. "" ""Exception message: %(exc_msg)s"") raise exc_class(msg % {'method': method, 'base': self.base_uri, 'error': e.__class__.__name__, 'exc_msg': e}) except Exception as e: if retry: self.u4p_failover_lock = False msg = _(""The %s request to URL %s failed with exception "" ""%s"" % (method, url, str(e))) LOG.error(msg) raise exception.VolumeBackendAPIException(message=msg) return status_code, message def wait_for_job_complete(self, job, extra_specs): """"""Given the job wait for it to complete. :param job: the job dict :param extra_specs: the extra_specs dict. :returns: rc -- int, result -- string, status -- string, task -- list of dicts detailing tasks in the job :raises: VolumeBackendAPIException """""" res, tasks = None, None if job['status'].lower == CREATED: try: res, tasks = job['result'], job['task'] except KeyError: pass return 0, res, job['status'], tasks def _wait_for_job_complete(): result = None # Called at an interval until the job is finished. retries = kwargs['retries'] try: kwargs['retries'] = retries + 1 if not kwargs['wait_for_job_called']: is_complete, result, rc, status, task = ( self._is_job_finished(job_id)) if is_complete is True: kwargs['wait_for_job_called'] = True kwargs['rc'], kwargs['status'] = rc, status kwargs['result'], kwargs['task'] = result, task except Exception: exception_message = (_(""Issue encountered waiting for job."")) LOG.error(exception_message) raise exception.VolumeBackendAPIException( message=exception_message) if retries > int(extra_specs[utils.RETRIES]): LOG.error(""_wait_for_job_complete failed after "" ""%(retries)d tries."", {'retries': retries}) kwargs['rc'], kwargs['result'] = -1, result raise loopingcall.LoopingCallDone() if kwargs['wait_for_job_called']: raise loopingcall.LoopingCallDone() job_id = job['jobId'] kwargs = {'retries': 0, 'wait_for_job_called': False, 'rc': 0, 'result': None} timer = loopingcall.FixedIntervalLoopingCall(_wait_for_job_complete) timer.start(interval=int(extra_specs[utils.INTERVAL])).wait() LOG.debug(""Return code is: %(rc)lu. Result is %(res)s."", {'rc': kwargs['rc'], 'res': kwargs['result']}) return (kwargs['rc'], kwargs['result'], kwargs['status'], kwargs['task']) def _is_job_finished(self, job_id): """"""Check if the job is finished. :param job_id: the id of the job :returns: complete -- bool, result -- string, rc -- int, status -- string, task -- list of dicts """""" complete, rc, status, result, task = False, 0, None, None, None job_url = ""/%s/system/job/%s"" % (U4V_VERSION, job_id) job = self.get_request(job_url, 'job') if job: status = job['status'] try: result, task = job['result'], job['task'] except KeyError: pass if status.lower() == SUCCEEDED: complete = True elif status.lower() in INCOMPLETE_LIST: complete = False else: rc, complete = -1, True return complete, result, rc, status, task @staticmethod def check_status_code_success(operation, status_code, message): """"""Check if a status code indicates success. :param operation: the operation :param status_code: the status code :param message: the server response :raises: VolumeBackendAPIException """""" if status_code not in [STATUS_200, STATUS_201, STATUS_202, STATUS_204]: exception_message = ( _(""Error %(operation)s. The status code received is %(sc)s "" ""and the message is %(message)s."") % { 'operation': operation, 'sc': status_code, 'message': message}) raise exception.VolumeBackendAPIException( message=exception_message) def wait_for_job(self, operation, status_code, job, extra_specs): """"""Check if call is async, wait for it to complete. :param operation: the operation being performed :param status_code: the status code :param job: the job :param extra_specs: the extra specifications :returns: task -- list of dicts detailing tasks in the job :raises: VolumeBackendAPIException """""" task = None if status_code == STATUS_202: rc, result, status, task = self.wait_for_job_complete( job, extra_specs) if rc != 0: exception_message = ( _(""Error %(operation)s. Status code: %(sc)lu. Error: "" ""%(error)s. Status: %(status)s."") % { 'operation': operation, 'sc': rc, 'error': str(result), 'status': status}) LOG.error(exception_message) raise exception.VolumeBackendAPIException( message=exception_message) return task def build_uri(self, *args, **kwargs): """"""Build the target url. :param args: input args, see _build_uri_legacy_args() for input breakdown :param kwargs: input keyword args, see _build_uri_kwargs() for input breakdown :return: target uri -- str """""" if args: target_uri = self._build_uri_legacy_args(*args, **kwargs) else: target_uri = self._build_uri_kwargs(**kwargs) return target_uri @staticmethod def _build_uri_legacy_args(*args, **kwargs): """"""Build the target URI using legacy args & kwargs. Expected format: arg[0]: the array serial number: the array serial number -- str arg[1]: the resource category e.g. 'sloprovisioning' -- str arg[2]: the resource type e.g. 'maskingview' -- str kwarg resource_name: the name of a specific resource -- str kwarg private: if endpoint is private -- bool kwarg version: U4V REST endpoint version -- int/str kwarg no_version: if endpoint should be versionless -- bool :param args: input args -- see above :param kwargs: input keyword args -- see above :return: target URI -- str """""" # Extract args following legacy _build_uri() format array_id, category, resource_type = args[0], args[1], args[2] # Extract keyword args following legacy _build_uri() format resource_name = kwargs.get('resource_name') private = kwargs.get('private') version = kwargs.get('version', U4V_VERSION) if kwargs.get('no_version'): version = None # Build URI target_uri = '' if private: target_uri += '/private' if version: target_uri += '/%(version)s' % {'version': version} target_uri += ( '/{cat}/symmetrix/{array_id}/{res_type}'.format( cat=category, array_id=array_id, res_type=resource_type)) if resource_name: target_uri += '/{resource_name}'.format( resource_name=kwargs.get('resource_name')) return target_uri @staticmethod def _build_uri_kwargs(**kwargs): """"""Build the target URI using kwargs. Expected kwargs: private: if endpoint is private (optional) -- bool version: U4P REST endpoint version (optional) -- int/None no_version: if endpoint should be versionless (optional) -- bool category: U4P REST category eg. 'common', 'replication'-- str resource_level: U4P REST resource level eg. 'symmetrix' (optional) -- str resource_level_id: U4P REST resource level id (optional) -- str resource_type: U4P REST resource type eg. 'rdf_director', 'host' (optional) -- str resource_type_id: U4P REST resource type id (optional) -- str resource: U4P REST resource eg. 'port' (optional) -- str resource_id: U4P REST resource id (optional) -- str object_type: U4P REST resource eg. 'rdf_group' (optional) -- str object_type_id: U4P REST resource id (optional) -- str :param kwargs: input keyword args -- see above :return: target URI -- str """""" version = kwargs.get('version', U4V_VERSION) if kwargs.get('no_version'): version = None target_uri = '' if kwargs.get('private'): target_uri += '/private' if version: target_uri += '/%(ver)s' % {'ver': version} target_uri += '/%(cat)s' % {'cat': kwargs.get('category')} if kwargs.get('resource_level'): target_uri += '/%(res_level)s' % { 'res_level': kwargs.get('resource_level')} if kwargs.get('resource_level_id'): target_uri += '/%(res_level_id)s' % { 'res_level_id': kwargs.get('resource_level_id')} if kwargs.get('resource_type'): target_uri += '/%(res_type)s' % { 'res_type': kwargs.get('resource_type')} if kwargs.get('resource_type_id'): target_uri += '/%(res_type_id)s' % { 'res_type_id': kwargs.get('resource_type_id')} if kwargs.get('resource'): target_uri += '/%(res)s' % { 'res': kwargs.get('resource')} if kwargs.get('resource_id'): target_uri += '/%(res_id)s' % { 'res_id': kwargs.get('resource_id')} if kwargs.get('object_type'): target_uri += '/%(object_type)s' % { 'object_type': kwargs.get('object_type')} if kwargs.get('object_type_id'): target_uri += '/%(object_type_id)s' % { 'object_type_id': kwargs.get('object_type_id')} return target_uri def get_request(self, target_uri, resource_type, params=None): """"""Send a GET request to the array. :param target_uri: the target uri :param resource_type: the resource type, e.g. maskingview :param params: optional dict of filter params :returns: resource_object -- dict or None """""" resource_object = None sc, message = self.request(target_uri, GET, params=params) operation = 'get %(res)s' % {'res': resource_type} try: self.check_status_code_success(operation, sc, message) except Exception as e: LOG.debug(""Get resource failed with %(e)s"", {'e': e}) if sc == STATUS_200: resource_object = message resource_object = self.list_pagination(resource_object) return resource_object def post_request(self, target_uri, resource_type, request_body): """"""Send a POST request to the array. :param target_uri: the target uri -- str :param resource_type: the resource type -- str :param request_body: the POST request body -- dict :return: resource object -- dict or None """""" resource_object = None sc, msg = self.request(target_uri, POST, request_object=request_body) operation = 'POST %(res)s' % {'res': resource_type} try: self.check_status_code_success(operation, sc, msg) except Exception as e: LOG.debug(""POST resource failed with %(e)s"", {'e': e}) if sc == STATUS_200: resource_object = msg return resource_object def get_resource(self, array, category, resource_type, resource_name=None, params=None, private=False, version=U4V_VERSION): """"""Get resource details from array. :param array: the array serial number :param category: the resource category e.g. sloprovisioning :param resource_type: the resource type e.g. maskingview :param resource_name: the name of a specific resource :param params: query parameters :param private: empty string or '/private' if private url :param version: None or specific version number if required :returns: resource object -- dict or None """""" target_uri = self.build_uri( array, category, resource_type, resource_name=resource_name, private=private, version=version) return self.get_request(target_uri, resource_type, params) def create_resource(self, array, category, resource_type, payload, private=False): """"""Create a provisioning resource. :param array: the array serial number :param category: the category :param resource_type: the resource type :param payload: the payload :param private: empty string or '/private' if private url :returns: status_code -- int, message -- string, server response """""" target_uri = self.build_uri( array, category, resource_type, private=private) status_code, message = self.request(target_uri, POST, request_object=payload) operation = 'Create %(res)s resource' % {'res': resource_type} self.check_status_code_success( operation, status_code, message) return status_code, message def modify_resource( self, array, category, resource_type, payload, version=U4V_VERSION, resource_name=None, private=False): """"""Modify a resource. :param version: the uv4 version :param array: the array serial number :param category: the category :param resource_type: the resource type :param payload: the payload :param resource_name: the resource name :param private: empty string or '/private' if private url :returns: status_code -- int, message -- string (server response) """""" target_uri = self.build_uri( array, category, resource_type, resource_name=resource_name, private=private, version=version) status_code, message = self.request(target_uri, PUT, request_object=payload) operation = 'modify %(res)s resource' % {'res': resource_type} self.check_status_code_success(operation, status_code, message) return status_code, message @retry(retry_exc_tuple, interval=2, retries=3) def delete_resource( self, array, category, resource_type, resource_name, payload=None, private=False, params=None): """"""Delete a provisioning resource. :param array: the array serial number :param category: the resource category e.g. sloprovisioning :param resource_type: the type of resource to be deleted :param resource_name: the name of the resource to be deleted :param payload: the payload, optional :param private: empty string or '/private' if private url :param params: dict of optional query params """""" target_uri = self.build_uri( array, category, resource_type, resource_name=resource_name, private=private) status_code, message = self.request(target_uri, DELETE, request_object=payload, params=params) operation = 'delete %(res)s resource' % {'res': resource_type} self.check_status_code_success(operation, status_code, message) def get_arrays_list(self): """"""Get a list of all arrays on U4P instance. :returns arrays -- list """""" target_uri = '/%s/sloprovisioning/symmetrix' % U4V_VERSION array_details = self.get_request(target_uri, 'sloprovisioning') if not array_details: LOG.error(""Could not get array details from Unisphere instance."") arrays = array_details.get('symmetrixId', list()) return arrays def get_array_detail(self, array): """"""Get an array from its serial number. :param array: the array serial number :returns: array_details -- dict or None """""" target_uri = '/%s/system/symmetrix/%s' % (U4V_VERSION, array) array_details = self.get_request(target_uri, 'system') if not array_details: LOG.error(""Cannot connect to array %(array)s."", {'array': array}) return array_details def get_array_tags(self, array): """"""Get the tags from its serial number. :param array: the array serial number :returns: tag list -- list or empty list """""" target_uri = '/%s/system/tag?array_id=%s' % (U4V_VERSION, array) array_tags = self.get_request(target_uri, 'system') return array_tags.get('tag_name') def is_next_gen_array(self, array): """"""Check to see if array is a next gen array(ucode 5978 or greater). :param array: the array serial number :returns: bool """""" is_next_gen = False array_details = self.get_array_detail(array) if array_details: ucode_version = array_details['ucode'].split('.')[0] if ucode_version >= UCODE_5978: is_next_gen = True return is_next_gen def get_uni_version(self): """"""Get the unisphere version from the server. :returns: version and major_version(e.g. (""V8.4.0.16"", ""84"")) """""" version, major_version = None, None response = self.get_unisphere_version() if response and response.get('version'): version = response['version'] version_list = version.split('.') major_version = version_list[0][1] + version_list[1] return version, major_version def get_unisphere_version(self): """"""Get the unisphere version from the server. :returns: version dict """""" post_90_endpoint = '/version' pre_91_endpoint = '/system/version' status_code, version_dict = self.request(post_90_endpoint, GET) if status_code is not STATUS_200: status_code, version_dict = self.request(pre_91_endpoint, GET) if not version_dict: LOG.error(""Unisphere version info not found."") return version_dict def get_srp_by_name(self, array, srp=None): """"""Returns the details of a storage pool. :param array: the array serial number :param srp: the storage resource pool name :returns: SRP_details -- dict or None """""" LOG.debug(""storagePoolName: %(srp)s, array: %(array)s."", {'srp': srp, 'array': array}) srp_details = self.get_resource(array, SLOPROVISIONING, 'srp', resource_name=srp, params=None) return srp_details def get_slo_list(self, array, is_next_gen, array_model): """"""Retrieve the list of slo's from the array :param array: the array serial number :param is_next_gen: next generation flag :param array_model :returns: slo_list -- list of service level names """""" slo_list = [] slo_dict = self.get_resource(array, SLOPROVISIONING, 'slo') if slo_dict and slo_dict.get('sloId'): if not is_next_gen and ( any(array_model in x for x in utils.VMAX_AFA_MODELS)): if 'Optimized' in slo_dict.get('sloId'): slo_dict['sloId'].remove('Optimized') for slo in slo_dict['sloId']: if slo and slo not in slo_list: slo_list.append(slo) return slo_list def get_workload_settings(self, array, is_next_gen): """"""Get valid workload options from array. Workloads are no longer supported from HyperMaxOS 5978 onwards. :param array: the array serial number :param is_next_gen: is next generation flag :returns: workload_setting -- list of workload names """""" workload_setting = [] if is_next_gen: workload_setting.append('None') else: wl_details = self.get_resource( array, SLOPROVISIONING, 'workloadtype') if wl_details: workload_setting = wl_details['workloadId'] return workload_setting def get_vmax_model(self, array): """"""Get the PowerMax/VMAX model. :param array: the array serial number :returns: the PowerMax/VMAX model """""" vmax_version = None system_info = self.get_array_detail(array) if system_info and system_info.get('model'): vmax_version = system_info.get('model') return vmax_version def get_array_model_info(self, array): """"""Get the PowerMax/VMAX model. :param array: the array serial number :returns: the PowerMax/VMAX model """""" array_model = None is_next_gen = False system_info = self.get_array_detail(array) if system_info and system_info.get('model'): array_model = system_info.get('model') if system_info: ucode_version = system_info['ucode'].split('.')[0] if ucode_version >= UCODE_5978: is_next_gen = True return array_model, is_next_gen def get_array_ucode_version(self, array): """"""Get the PowerMax/VMAX uCode version. :param array: the array serial number :returns: the PowerMax/VMAX uCode version """""" ucode_version = None system_info = self.get_array_detail(array) if system_info: ucode_version = system_info['ucode'] return ucode_version def is_compression_capable(self, array): """"""Check if array is compression capable. :param array: array serial number :returns: bool """""" is_compression_capable = False target_uri = (""/%s/sloprovisioning/symmetrix?compressionCapable=true"" % U4V_VERSION) status_code, message = self.request(target_uri, GET) self.check_status_code_success( ""Check if compression enabled"", status_code, message) if message.get('symmetrixId'): if array in message['symmetrixId']: is_compression_capable = True return is_compression_capable def get_storage_group(self, array, storage_group_name): """"""Given a name, return storage group details. :param array: the array serial number :param storage_group_name: the name of the storage group :returns: storage group dict or None """""" return self.get_resource( array, SLOPROVISIONING, 'storagegroup', resource_name=storage_group_name) def get_storage_group_list(self, array, params=None): """"""Given a name, return storage group details. :param array: the array serial number :param params: dict of optional filters :returns: storage group dict or None """""" return self.get_resource( array, SLOPROVISIONING, 'storagegroup', params=params) def get_num_vols_in_sg(self, array, storage_group_name): """"""Get the number of volumes in a storage group. :param array: the array serial number :param storage_group_name: the storage group name :returns: num_vols -- int """""" num_vols = 0 storagegroup = self.get_storage_group(array, storage_group_name) try: num_vols = int(storagegroup['num_of_vols']) except (KeyError, TypeError): pass return num_vols def is_child_sg_in_parent_sg(self, array, child_name, parent_name): """"""Check if a child storage group is a member of a parent group. :param array: the array serial number :param child_name: the child sg name :param parent_name: the parent sg name :returns: bool """""" parent_sg = self.get_storage_group(array, parent_name) if parent_sg and parent_sg.get('child_storage_group'): child_sg_list = parent_sg['child_storage_group'] if child_name in child_sg_list: return True return False def add_child_sg_to_parent_sg( self, array, child_sg, parent_sg, extra_specs): """"""Add a storage group to a parent storage group. This method adds an existing storage group to another storage group, i.e. cascaded storage groups. :param array: the array serial number :param child_sg: the name of the child sg :param parent_sg: the name of the parent sg :param extra_specs: the extra specifications """""" payload = {""editStorageGroupActionParam"": { ""expandStorageGroupParam"": { ""addExistingStorageGroupParam"": { ""storageGroupId"": [child_sg]}}}} sc, job = self.modify_storage_group(array, parent_sg, payload) self.wait_for_job('Add child sg to parent sg', sc, job, extra_specs) def remove_child_sg_from_parent_sg( self, array, child_sg, parent_sg, extra_specs): """"""Remove a storage group from its parent storage group. This method removes a child storage group from its parent group. :param array: the array serial number :param child_sg: the name of the child sg :param parent_sg: the name of the parent sg :param extra_specs: the extra specifications """""" payload = {""editStorageGroupActionParam"": { ""removeStorageGroupParam"": { ""storageGroupId"": [child_sg], ""force"": 'true'}}} status_code, job = self.modify_storage_group( array, parent_sg, payload) self.wait_for_job( 'Remove child sg from parent sg', status_code, job, extra_specs) def _create_storagegroup(self, array, payload): """"""Create a storage group. :param array: the array serial number :param payload: the payload -- dict :returns: status_code -- int, message -- string, server response """""" return self.create_resource( array, SLOPROVISIONING, 'storagegroup', payload) def create_storage_group(self, array, storagegroup_name, srp, slo, workload, extra_specs, do_disable_compression=False): """"""Create the volume in the specified storage group. :param array: the array serial number :param storagegroup_name: the group name (String) :param srp: the SRP (String) :param slo: the SLO (String) :param workload: the workload (String) :param do_disable_compression: flag for disabling compression :param extra_specs: additional info :returns: storagegroup_name - string """""" srp_id = srp if slo else ""None"" payload = ({""srpId"": srp_id, ""storageGroupId"": storagegroup_name, ""emulation"": ""FBA""}) if slo: if self.is_next_gen_array(array): workload = 'NONE' slo_param = {""sloId"": slo, ""workloadSelection"": workload, ""volumeAttributes"": [{ ""volume_size"": ""0"", ""capacityUnit"": ""GB"", ""num_of_vols"": 0}]} if do_disable_compression: slo_param.update({""noCompression"": ""true""}) elif self.is_compression_capable(array): slo_param.update({""noCompression"": ""false""}) payload.update({""sloBasedStorageGroupParam"": [slo_param]}) status_code, job = self._create_storagegroup(array, payload) self.wait_for_job('Create storage group', status_code, job, extra_specs) return storagegroup_name def modify_storage_group(self, array, storagegroup, payload, version=U4V_VERSION): """"""Modify a storage group (PUT operation). :param version: the uv4 version :param array: the array serial number :param storagegroup: storage group name :param payload: the request payload :returns: status_code -- int, message -- string, server response """""" return self.modify_resource( array, SLOPROVISIONING, 'storagegroup', payload, version, resource_name=storagegroup) def modify_storage_array(self, array, payload): """"""Modify a storage array (PUT operation). :param array: the array serial number :param payload: the request payload :returns: status_code -- int, message -- string, server response """""" target_uri = '/%s/sloprovisioning/symmetrix/%s' % (U4V_VERSION, array) status_code, message = self.request(target_uri, PUT, request_object=payload) operation = 'modify %(res)s resource' % {'res': 'symmetrix'} self.check_status_code_success(operation, status_code, message) return status_code, message def create_volume_from_sg(self, array, volume_name, storagegroup_name, volume_size, extra_specs, rep_info=None): """"""Create a new volume in the given storage group. :param array: the array serial number :param volume_name: the volume name (String) :param storagegroup_name: the storage group name :param volume_size: volume size (String) :param extra_specs: the extra specifications :param rep_info: replication info dict if volume is replication enabled :returns: dict -- volume_dict - the volume dict :raises: VolumeBackendAPIException """""" payload = ( {""executionOption"": ""ASYNCHRONOUS"", ""editStorageGroupActionParam"": { ""expandStorageGroupParam"": { ""addVolumeParam"": { ""emulation"": ""FBA"", ""create_new_volumes"": ""False"", ""volumeAttributes"": [ { ""num_of_vols"": 1, ""volumeIdentifier"": { ""identifier_name"": volume_name, ""volumeIdentifierChoice"": ""identifier_name"" }, ""volume_size"": volume_size, ""capacityUnit"": ""GB""}]}}}}) if rep_info: payload = self.utils.update_payload_for_rdf_vol_create( payload, rep_info[utils.REMOTE_ARRAY], storagegroup_name) status_code, job = self.modify_storage_group( array, storagegroup_name, payload) LOG.debug(""Create Volume: %(volumename)s. Status code: %(sc)lu."", {'volumename': volume_name, 'sc': status_code}) task = self.wait_for_job('Create volume', status_code, job, extra_specs) # Find the newly created volume. device_id = None if rep_info: updated_device_list = self.get_volume_list( array, {'storageGroupId': storagegroup_name, 'rdf_group_number': rep_info['rdf_group_no']}) unique_devices = self.utils.get_unique_device_ids_from_lists( rep_info['initial_device_list'], updated_device_list) if 0 < len(unique_devices) < 2: device_id = unique_devices[0] self.rename_volume(array, device_id, volume_name) else: raise exception.VolumeBackendAPIException(_( ""There has been more than one volume created in the "" ""SRDF protected Storage Group since the current create "" ""volume process begun. Not possible to discern what "" ""volume has been created by PowerMax Cinder driver."")) # Find the newly created volume if not located as part of replication # OPT workaround if not device_id and task: for t in task: try: desc = t[""description""] if CREATE_VOL_STRING in desc: t_list = desc.split() device_id = t_list[(len(t_list) - 1)] device_id = device_id[1:-1] break elif POPULATE_SG_LIST in desc: regex_str = (r'Populating Storage Group\(s\) ' + r'with volumes : \[(.+)\]$') full_str = re.compile(regex_str) match = full_str.match(desc) device_id = match.group(1) if match else None if device_id: self.get_volume(array, device_id) except Exception as e: LOG.info(""Could not retrieve device id from job. "" ""Exception received was %(e)s. Attempting "" ""retrieval by volume_identifier."", {'e': e}) if not device_id: device_id = self.find_volume_device_id(array, volume_name) volume_dict = {utils.ARRAY: array, utils.DEVICE_ID: device_id} return volume_dict def add_storage_group_tag(self, array, storagegroup_name, tag_list, extra_specs): """"""Create a new tag(s) on a storage group :param array: the array serial number :param storagegroup_name: the storage group name :param tag_list: comma delimited list :param extra_specs: the extra specifications """""" payload = ( {""executionOption"": ""ASYNCHRONOUS"", ""editStorageGroupActionParam"": { ""tagManagementParam"": { ""addTagsParam"": { ""tag_name"": tag_list }}}}) status_code, job = self.modify_storage_group( array, storagegroup_name, payload) LOG.debug(""Add tag to storage group: %(sg_name)s. "" ""Status code: %(sc)lu."", {'sg_name': storagegroup_name, 'sc': status_code}) self.wait_for_job( 'Add tag to storage group', status_code, job, extra_specs) def add_storage_array_tags(self, array, tag_list, extra_specs): """"""Create a new tag(s) on a storage group :param array: the array serial number :param tag_list: comma delimited list :param extra_specs: the extra specifications """""" payload = ( {""executionOption"": ""ASYNCHRONOUS"", ""editSymmetrixActionParam"": { ""tagManagementParam"": { ""addTagsParam"": { ""tag_name"": tag_list }}}}) status_code, job = self.modify_storage_array( array, payload) LOG.debug(""Add tag to storage array: %(array)s. "" ""Status code: %(sc)lu."", {'array': array, 'sc': status_code}) self.wait_for_job( 'Add tag to storage array', status_code, job, extra_specs) def check_volume_device_id(self, array, device_id, volume_id, name_id=None): """"""Check if the identifiers match for a given volume. :param array: the array serial number :param device_id: the device id :param volume_id: cinder volume id :param name_id: name id - used in host_assisted migration, optional :returns: found_device_id """""" found_device_id = None if not device_id: return found_device_id element_name = self.utils.get_volume_element_name(volume_id) vol_details = self.get_volume(array, device_id) if vol_details: vol_identifier = vol_details.get('volume_identifier', None) LOG.debug('Element name = %(en)s, Vol identifier = %(vi)s, ' 'Device id = %(di)s', {'en': element_name, 'vi': vol_identifier, 'di': device_id}) if vol_identifier: if vol_identifier in element_name: found_device_id = device_id if vol_identifier != element_name: LOG.debug(""Device %(di)s is a legacy volume created "" ""using SMI-S."", {'di': device_id}) elif name_id: # This may be host-assisted migration case element_name = self.utils.get_volume_element_name(name_id) if vol_identifier == element_name: found_device_id = device_id return found_device_id def add_vol_to_sg(self, array, storagegroup_name, device_id, extra_specs, force=False): """"""Add a volume to a storage group. :param array: the array serial number :param storagegroup_name: storage group name :param device_id: the device id :param extra_specs: extra specifications :param force: add force argument to call """""" if not isinstance(device_id, list): device_id = [device_id] force_add = ""true"" if force else ""false"" payload = ({""executionOption"": ""ASYNCHRONOUS"", ""editStorageGroupActionParam"": { ""expandStorageGroupParam"": { ""addSpecificVolumeParam"": { ""volumeId"": device_id, ""remoteSymmSGInfoParam"": { ""force"": force_add}}}}}) status_code, job = self.modify_storage_group( array, storagegroup_name, payload) self.wait_for_job('Add volume to sg', status_code, job, extra_specs) @retry(retry_exc_tuple, interval=2, retries=3) def remove_vol_from_sg(self, array, storagegroup_name, device_id, extra_specs): """"""Remove a volume from a storage group. :param array: the array serial number :param storagegroup_name: storage group name :param device_id: the device id :param extra_specs: the extra specifications """""" force_vol_edit = ( ""true"" if utils.FORCE_VOL_EDIT in extra_specs else ""false"") if not isinstance(device_id, list): device_id = [device_id] payload = ({""executionOption"": ""ASYNCHRONOUS"", ""editStorageGroupActionParam"": { ""removeVolumeParam"": { ""volumeId"": device_id, ""remoteSymmSGInfoParam"": { ""force"": force_vol_edit}}}}) status_code, job = self.modify_storage_group( array, storagegroup_name, payload) self.wait_for_job('Remove vol from sg', status_code, job, extra_specs) def update_storagegroup_qos(self, array, storage_group_name, extra_specs): """"""Update the storagegroupinstance with qos details. If maxIOPS or maxMBPS is in extra_specs, then DistributionType can be modified in addition to maxIOPS or/and maxMBPS If maxIOPS or maxMBPS is NOT in extra_specs, we check to see if either is set in StorageGroup. If so, then DistributionType can be modified :param array: the array serial number :param storage_group_name: the storagegroup instance name :param extra_specs: extra specifications :returns: bool, True if updated, else False """""" return_value = False sg_details = self.get_storage_group(array, storage_group_name) sg_qos_details = None sg_maxiops = None sg_maxmbps = None sg_distribution_type = None property_dict = {} try: sg_qos_details = sg_details['hostIOLimit'] sg_maxiops = sg_qos_details['host_io_limit_io_sec'] sg_maxmbps = sg_qos_details['host_io_limit_mb_sec'] sg_distribution_type = sg_qos_details['dynamicDistribution'] except KeyError: LOG.debug(""Unable to get storage group QoS details."") if 'total_iops_sec' in extra_specs.get('qos'): property_dict = self.utils.validate_qos_input( 'total_iops_sec', sg_maxiops, extra_specs.get('qos'), property_dict) if 'total_bytes_sec' in extra_specs.get('qos'): property_dict = self.utils.validate_qos_input( 'total_bytes_sec', sg_maxmbps, extra_specs.get('qos'), property_dict) if 'DistributionType' in extra_specs.get('qos') and property_dict: property_dict = self.utils.validate_qos_distribution_type( sg_distribution_type, extra_specs.get('qos'), property_dict) if property_dict: payload = {""editStorageGroupActionParam"": { ""setHostIOLimitsParam"": property_dict}} status_code, message = ( self.modify_storage_group(array, storage_group_name, payload)) try: self.check_status_code_success('Add qos specs', status_code, message) return_value = True except Exception as e: LOG.error(""Error setting qos. Exception received was: "" ""%(e)s"", {'e': e}) return_value = False return return_value def set_storagegroup_srp( self, array, storagegroup_name, srp_name, extra_specs): """"""Modify a storage group's srp value. :param array: the array serial number :param storagegroup_name: the storage group name :param srp_name: the srp pool name :param extra_specs: the extra specifications """""" payload = {""editStorageGroupActionParam"": { ""editStorageGroupSRPParam"": {""srpId"": srp_name}}} status_code, job = self.modify_storage_group( array, storagegroup_name, payload) self.wait_for_job(""Set storage group srp"", status_code, job, extra_specs) def get_vmax_default_storage_group( self, array, srp, slo, workload, do_disable_compression=False, is_re=False, rep_mode=None): """"""Get the default storage group. :param array: the array serial number :param srp: the pool name :param slo: the SLO :param workload: the workload :param do_disable_compression: flag for disabling compression :param is_re: flag for replication :param rep_mode: flag to indicate replication mode :returns: the storage group dict (or None), the storage group name """""" if self.is_next_gen_array(array): workload = 'NONE' storagegroup_name = self.utils.get_default_storage_group_name( srp, slo, workload, do_disable_compression, is_re, rep_mode) storagegroup = self.get_storage_group(array, storagegroup_name) return storagegroup, storagegroup_name def delete_storage_group(self, array, storagegroup_name): """"""Delete a storage group. :param array: the array serial number :param storagegroup_name: storage group name """""" self.delete_resource( array, SLOPROVISIONING, 'storagegroup', storagegroup_name) LOG.debug(""Storage Group successfully deleted."") def move_volume_between_storage_groups( self, array, device_id, source_storagegroup_name, target_storagegroup_name, extra_specs, force=False): """"""Move a volume to a different storage group. :param array: the array serial number :param source_storagegroup_name: the originating storage group name :param target_storagegroup_name: the destination storage group name :param device_id: the device id :param extra_specs: extra specifications :param force: force flag (necessary on a detach) """""" force_flag = ""true"" if force else ""false"" payload = ({""executionOption"": ""ASYNCHRONOUS"", ""editStorageGroupActionParam"": { ""moveVolumeToStorageGroupParam"": { ""volumeId"": [device_id], ""storageGroupId"": target_storagegroup_name, ""force"": force_flag}}}) status_code, job = self.modify_storage_group( array, source_storagegroup_name, payload) self.wait_for_job('move volume between storage groups', status_code, job, extra_specs) def get_volume(self, array, device_id): """"""Get a PowerMax/VMAX volume from array. :param array: the array serial number :param device_id: the volume device id :returns: volume dict :raises: VolumeBackendAPIException """""" version = self.get_uni_version()[1] volume_dict = self.get_resource( array, SLOPROVISIONING, 'volume', resource_name=device_id, version=version) if not volume_dict: exception_message = (_(""Volume %(deviceID)s not found."") % {'deviceID': device_id}) LOG.error(exception_message) raise exception.VolumeBackendAPIException( message=exception_message) return volume_dict def _get_private_volume(self, array, device_id): """"""Get a more detailed list of attributes of a volume. :param array: the array serial number :param device_id: the volume device id :returns: volume dict :raises: VolumeBackendAPIException """""" try: wwn = (self.get_volume(array, device_id))['wwn'] params = {'wwn': wwn} volume_info = self.get_resource( array, SLOPROVISIONING, 'volume', params=params, private='/private') volume_dict = volume_info[0] except (KeyError, TypeError): exception_message = (_(""Volume %(deviceID)s not found."") % {'deviceID': device_id}) LOG.error(exception_message) raise exception.VolumeBackendAPIException( message=exception_message) return volume_dict def get_volume_list(self, array, params): """"""Get a filtered list of PowerMax/VMAX volumes from array. Filter parameters are required as the unfiltered volume list could be very large and could affect performance if called often. :param array: the array serial number :param params: filter parameters :returns: device_ids -- list """""" device_ids = [] volume_dict_list = self.get_resource( array, SLOPROVISIONING, 'volume', params=params) try: for vol_dict in volume_dict_list: device_id = vol_dict['volumeId'] device_ids.append(device_id) except (KeyError, TypeError): pass return device_ids def get_private_volume_list(self, array, params=None): """"""Retrieve list with volume details. :param array: the array serial number :param params: filter parameters :returns: list -- dicts with volume information """""" if isinstance(params, dict): params['expiration_time_mins'] = ITERATOR_EXPIRATION elif isinstance(params, str): params += '&expiration_time_mins=%(expire)s' % { 'expire': ITERATOR_EXPIRATION} else: params = {'expiration_time_mins': ITERATOR_EXPIRATION} return self.get_resource( array, SLOPROVISIONING, 'volume', params=params, private='/private') def _modify_volume(self, array, device_id, payload): """"""Modify a volume (PUT operation). :param array: the array serial number :param device_id: volume device id :param payload: the request payload """""" return self.modify_resource(array, SLOPROVISIONING, 'volume', payload, resource_name=device_id) def extend_volume(self, array, device_id, new_size, extra_specs, rdf_grp_no=None): """"""Extend a PowerMax/VMAX volume. :param array: the array serial number :param device_id: volume device id :param new_size: the new required size for the device :param extra_specs: the extra specifications :param rdf_grp_no: the RDG group number """""" extend_vol_payload = {'executionOption': 'ASYNCHRONOUS', 'editVolumeActionParam': { 'expandVolumeParam': { 'volumeAttribute': { 'volume_size': new_size, 'capacityUnit': 'GB'}}}} if rdf_grp_no: extend_vol_payload['editVolumeActionParam'][ 'expandVolumeParam'].update({'rdfGroupNumber': rdf_grp_no}) status_code, job = self._modify_volume( array, device_id, extend_vol_payload) LOG.debug(""Extend Device: %(device_id)s. Status code: %(sc)lu."", {'device_id': device_id, 'sc': status_code}) self.wait_for_job('Extending volume', status_code, job, extra_specs) def rename_volume(self, array, device_id, new_name): """"""Rename a volume. :param array: the array serial number :param device_id: the volume device id :param new_name: the new name for the volume, can be None """""" if new_name is not None: vol_identifier_dict = { ""identifier_name"": new_name, ""volumeIdentifierChoice"": ""identifier_name""} else: vol_identifier_dict = {""volumeIdentifierChoice"": ""none""} rename_vol_payload = {""editVolumeActionParam"": { ""modifyVolumeIdentifierParam"": { ""volumeIdentifier"": vol_identifier_dict}}} self._modify_volume(array, device_id, rename_vol_payload) def delete_volume(self, array, device_id): """"""Delete a volume. :param array: the array serial number :param device_id: volume device id """""" if ((self.ucode_major_level >= utils.UCODE_5978) and (self.ucode_minor_level > utils.UCODE_5978_ELMSR)): # Use Rapid TDEV Deallocation to delete after ELMSR try: # Rename volume, removing the OS-<cinderUUID> self.rename_volume(array, device_id, None) self.delete_resource(array, SLOPROVISIONING, ""volume"", device_id) except Exception as e: LOG.warning('Delete volume failed with %(e)s.', {'e': e}) raise else: # Pre-Foxtail, deallocation and delete are separate calls payload = {""editVolumeActionParam"": { ""freeVolumeParam"": {""free_volume"": 'true'}}} try: # Rename volume, removing the OS-<cinderUUID> self.rename_volume(array, device_id, None) self._modify_volume(array, device_id, payload) pass except Exception as e: LOG.warning('Deallocate volume failed with %(e)s.' 'Attempting delete.', {'e': e}) # Try to delete the volume if deallocate failed. self.delete_resource(array, SLOPROVISIONING, ""volume"", device_id) def find_mv_connections_for_vol(self, array, maskingview, device_id): """"""Find the host_lun_id for a volume in a masking view. :param array: the array serial number :param maskingview: the masking view name :param device_id: the device ID :returns: host_lun_id -- int """""" host_lun_id = None resource_name = ('%(maskingview)s/connections' % {'maskingview': maskingview}) params = {'volume_id': device_id} connection_info = self.get_resource( array, SLOPROVISIONING, 'maskingview', resource_name=resource_name, params=params) if not connection_info: LOG.error('Cannot retrieve masking view connection information ' 'for %(mv)s.', {'mv': maskingview}) else: try: host_lun_id = ( connection_info[ 'maskingViewConnection'][0]['host_lun_address']) host_lun_id = int(host_lun_id, 16) except Exception as e: LOG.error(""Unable to retrieve connection information "" ""for volume %(vol)s in masking view %(mv)s. "" ""Exception received: %(e)s."", {'vol': device_id, 'mv': maskingview, 'e': e}) return host_lun_id def get_storage_groups_from_volume(self, array, device_id): """"""Returns all the storage groups for a particular volume. :param array: the array serial number :param device_id: the volume device id :returns: storagegroup_list """""" sg_list = [] vol = self.get_volume(array, device_id) if vol and vol.get('storageGroupId'): sg_list = vol['storageGroupId'] num_storage_groups = len(sg_list) LOG.debug(""There are %(num)d storage groups associated "" ""with volume %(deviceId)s."", {'num': num_storage_groups, 'deviceId': device_id}) return sg_list def is_volume_in_storagegroup(self, array, device_id, storagegroup): """"""See if a volume is a member of the given storage group. :param array: the array serial number :param device_id: the device id :param storagegroup: the storage group name :returns: bool """""" is_vol_in_sg = False sg_list = self.get_storage_groups_from_volume(array, device_id) if storagegroup in sg_list: is_vol_in_sg = True return is_vol_in_sg def find_volume_device_id(self, array, volume_name): """"""Given a volume identifier, find the corresponding device_id. :param array: the array serial number :param volume_name: the volume name (OS-<UUID>) :returns: device_id """""" device_id = None params = {""volume_identifier"": volume_name} volume_list = self.get_volume_list(array, params) if not volume_list: LOG.debug(""Cannot find record for volume %(volumeId)s."", {'volumeId': volume_name}) else: device_id = volume_list[0] return device_id def find_volume_identifier(self, array, device_id): """"""Get the volume identifier of a PowerMax/VMAX volume. :param array: array serial number :param device_id: the device id :returns: the volume identifier -- string """""" vol = self.get_volume(array, device_id) return vol['volume_identifier'] def get_size_of_device_on_array(self, array, device_id): """"""Get the size of the volume from the array. :param array: the array serial number :param device_id: the volume device id :returns: size -- or None """""" cap = None try: vol = self.get_volume(array, device_id) cap = vol['cap_gb'] except Exception as e: LOG.error(""Error retrieving size of volume %(vol)s. "" ""Exception received was %(e)s."", {'vol': device_id, 'e': e}) return cap def get_portgroup(self, array, portgroup): """"""Get a portgroup from the array. :param array: array serial number :param portgroup: the portgroup name :returns: portgroup dict or None """""" return self.get_resource( array, SLOPROVISIONING, 'portgroup', resource_name=portgroup) def get_port_ids(self, array, portgroup): """"""Get a list of port identifiers from a port group. :param array: the array serial number :param portgroup: the name of the portgroup :returns: list of port ids, e.g. ['FA-3D:35', 'FA-4D:32'] """""" portlist = [] portgroup_info = self.get_portgroup(array, portgroup) if portgroup_info: port_key = portgroup_info[""symmetrixPortKey""] for key in port_key: port = ""%s:%s"" % (key['directorId'], key['portId']) portlist.append(port) return portlist def get_port(self, array, port_id): """"""Get director port details. :param array: the array serial number :param port_id: the port id :returns: port dict, or None """""" dir_id = port_id.split(':')[0] port_no = port_id.split(':')[1] resource_name = ('%(directorId)s/port/%(port_number)s' % {'directorId': dir_id, 'port_number': port_no}) return self.get_resource(array, SYSTEM, 'director', resource_name=resource_name) def get_iscsi_ip_address_and_iqn(self, array, port_id): """"""Get the IPv4Address from the director port. :param array: the array serial number :param port_id: the director port identifier :returns: (list of ip_addresses, iqn) """""" ip_addresses, iqn = None, None port_details = self.get_port(array, port_id) if port_details: ip_addresses = port_details['symmetrixPort']['ip_addresses'] iqn = port_details['symmetrixPort']['identifier'] return ip_addresses, iqn def get_ip_interface_physical_port(self, array_id, virtual_port, ip_address): """"""Get the physical port associated with a virtual port and IP address. :param array_id: the array serial number -- str :param virtual_port: the director & virtual port identifier -- str :param ip_address: the ip address associated with the port -- str :returns: physical director:port -- str """""" director_id = virtual_port.split(':')[0] params = {'ip_list': ip_address, 'iscsi_target': False} target_uri = self.build_uri( category=SYSTEM, resource_level='symmetrix', resource_level_id=array_id, resource_type='director', resource_type_id=director_id, resource='port') port_info = self.get_request( target_uri, 'port IP interface', params) port_key = port_info.get('symmetrixPortKey', []) if len(port_key) == 1: port_info = port_key[0] port_id = port_info.get('portId') dir_port = '%(d)s:%(p)s' % {'d': director_id, 'p': port_id} else: if len(port_key) == 0: msg = (_( ""Virtual port %(vp)s and IP address %(ip)s are not "" ""associated a physical director:port. Please check "" ""iSCSI configuration of backend array %(arr)s."" % { 'vp': virtual_port, 'ip': ip_address, 'arr': array_id} )) else: msg = (_( ""Virtual port %(vp)s and IP address %(ip)s are associated "" ""with more than one physical director:port. Please check "" ""iSCSI configuration of backend array %(arr)s."" % { 'vp': virtual_port, 'ip': ip_address, 'arr': array_id} )) LOG.error(msg) raise exception.VolumeBackendAPIException(message=msg) return dir_port def get_target_wwns(self, array, portgroup): """"""Get the director ports' wwns. :param array: the array serial number :param portgroup: portgroup :returns: target_wwns -- the list of target wwns for the masking view """""" target_wwns = [] port_ids = self.get_port_ids(array, portgroup) for port in port_ids: port_info = self.get_port(array, port) if port_info: wwn = port_info['symmetrixPort']['identifier'] target_wwns.append(wwn) else: LOG.error(""Error retrieving port %(port)s "" ""from portgroup %(portgroup)s."", {'port': port, 'portgroup': portgroup}) return target_wwns def get_initiator_group(self, array, initiator_group=None, params=None): """"""Retrieve initiator group details from the array. :param array: the array serial number :param initiator_group: the initaitor group name :param params: optional filter parameters :returns: initiator group dict, or None """""" return self.get_resource( array, SLOPROVISIONING, 'host', resource_name=initiator_group, params=params) def get_initiator(self, array, initiator_id): """"""Retrieve initiator details from the array. :param array: the array serial number :param initiator_id: the initiator id :returns: initiator dict, or None """""" return self.get_resource( array, SLOPROVISIONING, 'initiator', resource_name=initiator_id) def get_initiator_list(self, array, params=None): """"""Retrieve initiator list from the array. :param array: the array serial number :param params: dict of optional params :returns: list of initiators """""" init_dict = self.get_resource(array, SLOPROVISIONING, 'initiator', params=params) try: init_list = init_dict['initiatorId'] except (KeyError, TypeError): init_list = [] return init_list def get_initiator_group_from_initiator(self, array, initiator): """"""Given an initiator, get its corresponding initiator group, if any. :param array: the array serial number :param initiator: the initiator id :returns: found_init_group_name -- string """""" found_init_group_name = None init_details = self.get_initiator(array, initiator) if init_details: found_init_group_name = init_details.get('host') else: LOG.error(""Unable to retrieve initiator details for "" ""%(init)s."", {'init': initiator}) return found_init_group_name def create_initiator_group(self, array, init_group_name, init_list, extra_specs): """"""Create a new initiator group containing the given initiators. :param array: the array serial number :param init_group_name: the initiator group name :param init_list: the list of initiators :param extra_specs: extra specifications """""" new_ig_data = ({""executionOption"": ""ASYNCHRONOUS"", ""hostId"": init_group_name, ""initiatorId"": init_list}) sc, job = self.create_resource(array, SLOPROVISIONING, 'host', new_ig_data) self.wait_for_job('create initiator group', sc, job, extra_specs) def delete_initiator_group(self, array, initiatorgroup_name): """"""Delete an initiator group. :param array: the array serial number :param initiatorgroup_name: initiator group name """""" self.delete_resource( array, SLOPROVISIONING, 'host', initiatorgroup_name) LOG.debug(""Initiator Group successfully deleted."") def get_masking_view(self, array, masking_view_name): """"""Get details of a masking view. :param array: array serial number :param masking_view_name: the masking view name :returns: masking view dict """""" return self.get_resource( array, SLOPROVISIONING, 'maskingview', masking_view_name) def get_masking_view_list(self, array, params): """"""Get a list of masking views from the array. :param array: array serial number :param params: optional GET parameters :returns: masking view list """""" masking_view_list = [] masking_view_details = self.get_resource( array, SLOPROVISIONING, 'maskingview', params=params) try: masking_view_list = masking_view_details['maskingViewId'] except (KeyError, TypeError): pass return masking_view_list def get_masking_views_from_storage_group(self, array, storagegroup): """"""Return any masking views associated with a storage group. :param array: the array serial number :param storagegroup: the storage group name :returns: masking view list """""" maskingviewlist = [] storagegroup = self.get_storage_group(array, storagegroup) if storagegroup and storagegroup.get('maskingview'): maskingviewlist = storagegroup['maskingview'] return maskingviewlist def get_masking_views_by_initiator_group( self, array, initiatorgroup_name): """"""Given initiator group, retrieve the masking view instance name. Retrieve the list of masking view instances associated with the given initiator group. :param array: the array serial number :param initiatorgroup_name: the name of the initiator group :returns: list of masking view names """""" masking_view_list = [] ig_details = self.get_initiator_group( array, initiatorgroup_name) if ig_details: if ig_details.get('maskingview'): masking_view_list = ig_details['maskingview'] else: LOG.error(""Error retrieving initiator group %(ig_name)s"", {'ig_name': initiatorgroup_name}) return masking_view_list def get_element_from_masking_view( self, array, maskingview_name, portgroup=False, host=False, storagegroup=False): """"""Return the name of the specified element from a masking view. :param array: the array serial number :param maskingview_name: the masking view name :param portgroup: the port group name - optional :param host: the host name - optional :param storagegroup: the storage group name - optional :returns: name of the specified element -- string :raises: VolumeBackendAPIException """""" element = None masking_view_details = self.get_masking_view(array, maskingview_name) if masking_view_details: if portgroup: element = masking_view_details['portGroupId'] elif host: element = masking_view_details['hostId'] elif storagegroup: element = masking_view_details['storageGroupId'] else: exception_message = (_(""Error retrieving masking group."")) LOG.error(exception_message) raise exception.VolumeBackendAPIException( message=exception_message) return element def get_common_masking_views(self, array, portgroup_name, ig_name): """"""Get common masking views for a given portgroup and initiator group. :param array: the array serial number :param portgroup_name: the port group name :param ig_name: the initiator group name :returns: masking view list """""" params = {'port_group_name': portgroup_name, 'host_or_host_group_name': ig_name} masking_view_list = self.get_masking_view_list(array, params) if not masking_view_list: LOG.info(""No common masking views found for %(pg_name)s "" ""and %(ig_name)s."", {'pg_name': portgroup_name, 'ig_name': ig_name}) return masking_view_list def create_masking_view(self, array, maskingview_name, storagegroup_name, port_group_name, init_group_name, extra_specs): """"""Create a new masking view. :param array: the array serial number :param maskingview_name: the masking view name :param storagegroup_name: the storage group name :param port_group_name: the port group :param init_group_name: the initiator group :param extra_specs: extra specifications """""" payload = ({""executionOption"": ""ASYNCHRONOUS"", ""portGroupSelection"": { ""useExistingPortGroupParam"": { ""portGroupId"": port_group_name}}, ""maskingViewId"": maskingview_name, ""hostOrHostGroupSelection"": { ""useExistingHostParam"": { ""hostId"": init_group_name}}, ""storageGroupSelection"": { ""useExistingStorageGroupParam"": { ""storageGroupId"": storagegroup_name}}}) status_code, job = self.create_resource( array, SLOPROVISIONING, 'maskingview', payload) self.wait_for_job('Create masking view', status_code, job, extra_specs) def delete_masking_view(self, array, maskingview_name): """"""Delete a masking view. :param array: the array serial number :param maskingview_name: the masking view name """""" return self.delete_resource( array, SLOPROVISIONING, 'maskingview', maskingview_name) def get_replication_capabilities(self, array): """"""Check what replication features are licensed and enabled. Example return value for this method: .. code:: python {""symmetrixId"": ""000197800128"", ""snapVxCapable"": true, ""rdfCapable"": true} :param array :returns: capabilities dict for the given array """""" array_capabilities = None target_uri = (""/%s/replication/capabilities/symmetrix"" % U4V_VERSION) capabilities = self.get_request( target_uri, 'replication capabilities') if capabilities: symm_list = capabilities['symmetrixCapability'] for symm in symm_list: if symm['symmetrixId'] == array: array_capabilities = symm break return array_capabilities def is_snapvx_licensed(self, array): """"""Check if the snapVx feature is licensed and enabled. :param array: the array serial number :returns: True if licensed and enabled; False otherwise. """""" snap_capability = False capabilities = self.get_replication_capabilities(array) if capabilities: snap_capability = capabilities['snapVxCapable'] else: LOG.error(""Cannot access replication capabilities "" ""for array %(array)s"", {'array': array}) return snap_capability def create_volume_snap(self, array, snap_name, device_id, extra_specs, ttl=0): """"""Create a snapVx snapshot of a volume. :param array: the array serial number :param snap_name: the name of the snapshot :param device_id: the source device id :param extra_specs: the extra specifications :param ttl: time to live in hours, defaults to 0 """""" payload = {""deviceNameListSource"": [{""name"": device_id}], ""bothSides"": 'false', ""star"": 'false', ""force"": 'false'} if int(ttl) > 0: payload['timeToLive'] = ttl payload['timeInHours'] = 'true' resource_type = 'snapshot/%(snap)s' % {'snap': snap_name} status_code, job = self.create_resource( array, REPLICATION, resource_type, payload, private='/private') self.wait_for_job('Create volume snapVx', status_code, job, extra_specs) def modify_volume_snap(self, array, source_id, target_id, snap_name, extra_specs, snap_id=None, link=False, unlink=False, rename=False, new_snap_name=None, restore=False, list_volume_pairs=None, copy=False): """"""Modify a snapvx snapshot :param array: the array serial number :param source_id: the source device id :param target_id: the target device id :param snap_name: the snapshot name :param extra_specs: extra specifications :param snap_id: the unique snap id of the snapVX :param link: Flag to indicate action = Link :param unlink: Flag to indicate action = Unlink :param rename: Flag to indicate action = Rename :param new_snap_name: Optional new snapshot name :param restore: Flag to indicate action = Restore :param list_volume_pairs: list of volume pairs to link, optional :param copy: If copy mode should be used for SnapVX target links """""" action, operation, payload = '', '', {} copy = 'true' if copy else 'false' if link: action = ""Link"" elif unlink: action = ""Unlink"" elif rename: action = ""Rename"" elif restore: action = ""Restore"" if action == ""Restore"": operation = 'Restore snapVx snapshot' payload = {""deviceNameListSource"": [{""name"": source_id}], ""deviceNameListTarget"": [{""name"": source_id}], ""action"": action, ""star"": 'false', ""force"": 'false'} elif action in ('Link', 'Unlink'): operation = 'Modify snapVx relationship to target' src_list, tgt_list = [], [] if list_volume_pairs: for a, b in list_volume_pairs: src_list.append({'name': a}) tgt_list.append({'name': b}) else: src_list.append({'name': source_id}) tgt_list.append({'name': target_id}) payload = {""deviceNameListSource"": src_list, ""deviceNameListTarget"": tgt_list, ""copy"": copy, ""action"": action, ""star"": 'false', ""force"": 'false', ""exact"": 'false', ""remote"": 'false', ""symforce"": 'false'} elif action == ""Rename"": operation = 'Rename snapVx snapshot' payload = {""deviceNameListSource"": [{""name"": source_id}], ""deviceNameListTarget"": [{""name"": source_id}], ""action"": action, ""newsnapshotname"": new_snap_name} if self.is_snap_id: payload.update({""snap_id"": snap_id}) if snap_id else ( payload.update({""generation"": ""0""})) else: payload.update({""generation"": snap_id}) if snap_id else ( payload.update({""generation"": ""0""})) if action: status_code, job = self.modify_resource( array, REPLICATION, 'snapshot', payload, resource_name=snap_name, private='/private') self.wait_for_job(operation, status_code, job, extra_specs) def delete_volume_snap(self, array, snap_name, source_device_ids, snap_id=None, restored=False): """"""Delete the snapshot of a volume or volumes. :param array: the array serial number :param snap_name: the name of the snapshot :param source_device_ids: the source device ids :param snap_id: the unique snap id of the snapVX :param restored: Flag to indicate terminate restore session """""" device_list = [] if not isinstance(source_device_ids, list): source_device_ids = [source_device_ids] for dev in source_device_ids: device_list.append({""name"": dev}) payload = {""deviceNameListSource"": device_list} if self.is_snap_id: payload.update({""snap_id"": snap_id}) if snap_id else ( payload.update({""generation"": 0})) else: payload.update({""generation"": snap_id}) if snap_id else ( payload.update({""generation"": 0})) if restored: payload.update({""restore"": True}) LOG.debug(""The payload is %(payload)s."", {'payload': payload}) return self.delete_resource( array, REPLICATION, 'snapshot', snap_name, payload=payload, private='/private') def get_volume_snap_info(self, array, source_device_id): """"""Get snapVx information associated with a volume. :param array: the array serial number :param source_device_id: the source volume device ID :returns: message -- dict, or None """""" resource_name = (""%(device_id)s/snapshot"" % {'device_id': source_device_id}) return self.get_resource(array, REPLICATION, 'volume', resource_name, private='/private') def get_volume_snap(self, array, device_id, snap_name, snap_id): """"""Given a volume snap info, retrieve the snapVx object. :param array: the array serial number :param device_id: the source volume device id :param snap_name: the name of the snapshot :param snap_id: the unique snap id of the snapVX :returns: snapshot dict, or None """""" snapshot = None snap_info = self.get_volume_snap_info(array, device_id) if snap_info: if (snap_info.get('snapshotSrcs', None) and bool(snap_info['snapshotSrcs'])): for snap in snap_info['snapshotSrcs']: if snap['snapshotName'] == snap_name: if self.is_snap_id: if snap['snap_id'] == snap_id: snapshot = snap break else: if snap['generation'] == snap_id: snapshot = snap break return snapshot def get_volume_snaps(self, array, device_id, snap_name): """"""Given a volume snap info, retrieve the snapVx object. :param array: the array serial number :param device_id: the source volume device id :param snap_name: the name of the snapshot :returns: snapshot dict, or None """""" snapshots = list() snap_info = self.get_volume_snap_info(array, device_id) if snap_info: if (snap_info.get('snapshotSrcs', None) and bool(snap_info['snapshotSrcs'])): for snap in snap_info['snapshotSrcs']: if snap['snapshotName'] == snap_name: snapshots.append(snap) return snapshots def get_volume_snapshot_list(self, array, source_device_id): """"""Get a list of snapshot details for a particular volume. :param array: the array serial number :param source_device_id: the osurce device id :returns: snapshot list or None """""" snapshot_list = [] snap_info = self.get_volume_snap_info(array, source_device_id) if snap_info: if (snap_info.get('snapshotSrcs', None) and bool(snap_info['snapshotSrcs'])): snapshot_list = snap_info['snapshotSrcs'] return snapshot_list def is_vol_in_rep_session(self, array, device_id): """"""Check if a volume is in a replication session. :param array: the array serial number :param device_id: the device id :returns: snapvx_tgt -- bool, snapvx_src -- bool, rdf_grp -- list or None """""" snapvx_src = False snapvx_tgt = False rdf_grp = None volume_details = self.get_volume(array, device_id) if volume_details: if volume_details.get('snapvx_target'): snapvx_tgt = volume_details['snapvx_target'] if volume_details.get('snapvx_source'): snapvx_src = volume_details['snapvx_source'] if volume_details.get('rdfGroupId'): rdf_grp = volume_details['rdfGroupId'] return snapvx_tgt, snapvx_src, rdf_grp def is_sync_complete(self, array, source_device_id, target_device_id, snap_name, extra_specs, snap_id): """"""Check if a sync session is complete. :param array: the array serial number :param source_device_id: source device id :param target_device_id: target device id :param snap_name: snapshot name :param extra_specs: extra specifications :param snap_id: the unique snap id of the SnapVX :returns: bool """""" def _wait_for_sync(): """"""Called at an interval until the synchronization is finished. :raises: loopingcall.LoopingCallDone :raises: VolumeBackendAPIException """""" retries = kwargs['retries'] try: kwargs['retries'] = retries + 1 if not kwargs['wait_for_sync_called']: if self._is_sync_complete( array, source_device_id, snap_name, target_device_id, snap_id): kwargs['wait_for_sync_called'] = True except Exception: exception_message = (_(""Issue encountered waiting for "" ""synchronization."")) LOG.error(exception_message) raise exception.VolumeBackendAPIException( message=exception_message) if kwargs['retries'] > int(extra_specs[utils.RETRIES]): LOG.error(""_wait_for_sync failed after %(retries)d "" ""tries."", {'retries': retries}) raise loopingcall.LoopingCallDone( retvalue=int(extra_specs[utils.RETRIES])) if kwargs['wait_for_sync_called']: raise loopingcall.LoopingCallDone() kwargs = {'retries': 0, 'wait_for_sync_called': False} timer = loopingcall.FixedIntervalLoopingCall(_wait_for_sync) rc = timer.start(interval=int(extra_specs[utils.INTERVAL])).wait() return rc def _is_sync_complete(self, array, source_device_id, snap_name, target_device_id, snap_id): """"""Helper function to check if snapVx sync session is complete. :param array: the array serial number :param source_device_id: source device id :param snap_name: the snapshot name :param target_device_id: the target device id :param snap_id: the unique snap id of the SnapVX :returns: defined -- bool """""" defined = True session = self.get_sync_session( array, source_device_id, snap_name, target_device_id, snap_id) if session: defined = session['defined'] return defined def get_sync_session(self, array, source_device_id, snap_name, target_device_id, snap_id): """"""Get a particular sync session. :param array: the array serial number :param source_device_id: source device id :param snap_name: the snapshot name :param target_device_id: the target device id :param snap_id: the unique snapid of the snapshot :returns: sync session -- dict, or None """""" session = None linked_device_list = self.get_snap_linked_device_list( array, source_device_id, snap_name, snap_id) for target in linked_device_list: if target_device_id == target['targetDevice']: session = target break return session def _find_snap_vx_source_sessions(self, array, source_device_id): """"""Find all snap sessions for a given source volume. :param array: the array serial number :param source_device_id: the source device id :returns: list of snapshot dicts """""" snap_dict_list = [] snapshots = self.get_volume_snapshot_list(array, source_device_id) for snapshot in snapshots: try: snap_id = snapshot['snap_id'] if self.is_snap_id else ( snapshot['generation']) if bool(snapshot['linkedDevices']): link_info = {'linked_vols': snapshot['linkedDevices'], 'snap_name': snapshot['snapshotName'], 'snapid': snap_id} snap_dict_list.append(link_info) except KeyError: pass return snap_dict_list def get_snap_linked_device_list(self, array, source_device_id, snap_name, snap_id, state=None): """"""Get the list of linked devices for a particular snapVx snapshot. :param array: the array serial number :param source_device_id: source device id :param snap_name: the snapshot name :param snap_id: the unique snapid of the snapshot :param state: filter for state of the link :returns: linked_device_list or empty list """""" snap_dict_list = None linked_device_list = [] snap_dict_list = self._get_snap_linked_device_dict_list( array, source_device_id, snap_name, state=state) for snap_dict in snap_dict_list: if snap_id == snap_dict['snapid']: linked_device_list = snap_dict['linked_vols'] break return linked_device_list def _get_snap_linked_device_dict_list( self, array, source_device_id, snap_name, state=None): """"""Get list of linked devices for all snap ids for a snapVx snapshot :param array: the array serial number :param source_device_id: source device id :param snap_name: the snapshot name :param state: filter for state of the link :returns: list of dict of snapids with linked devices """""" snap_dict_list = [] snap_list = self._find_snap_vx_source_sessions( array, source_device_id) for snap in snap_list: if snap['snap_name'] == snap_name: for linked_vol in snap['linked_vols']: snap_state = linked_vol.get('state', None) # If state is None or # both snap_state and state are not None and are equal if not state or (snap_state and state and snap_state == state): snap_id = snap['snapid'] found = False for snap_dict in snap_dict_list: if snap_id == snap_dict['snapid']: snap_dict['linked_vols'].append( linked_vol) found = True break if not found: snap_dict_list.append( {'snapid': snap_id, 'linked_vols': [linked_vol]}) return snap_dict_list def find_snap_vx_sessions(self, array, device_id, tgt_only=False): """"""Find all snapVX sessions for a device (source and target). :param array: the array serial number :param device_id: the device id :param tgt_only: Flag - return only sessions where device is target :returns: list of snapshot dicts """""" snap_tgt_dict, snap_src_dict_list = dict(), list() s_in = self.get_volume_snap_info(array, device_id) snap_src = ( s_in['snapshotSrcs'] if s_in.get('snapshotSrcs') else list()) snap_tgt = ( s_in['snapshotLnks'][0] if s_in.get('snapshotLnks') else dict()) if snap_src and not tgt_only: for session in snap_src: snap_src_dict = dict() snap_src_dict['source_vol_id'] = device_id snap_src_dict['snapid'] = session.get( 'snap_id') if self.is_snap_id else session.get( 'generation') snap_src_dict['snap_name'] = session.get('snapshotName') snap_src_dict['expired'] = session.get('expired') if session.get('linkedDevices'): snap_src_link = session.get('linkedDevices')[0] snap_src_dict['target_vol_id'] = snap_src_link.get( 'targetDevice') snap_src_dict['copy_mode'] = snap_src_link.get('copy') snap_src_dict['state'] = snap_src_link.get('state') snap_src_dict_list.append(snap_src_dict) if snap_tgt: snap_tgt_dict['source_vol_id'] = snap_tgt.get('linkSourceName') snap_tgt_dict['target_vol_id'] = device_id snap_tgt_dict['state'] = snap_tgt.get('state') snap_tgt_dict['copy_mode'] = snap_tgt.get('copy') vol_info = self._get_private_volume(array, device_id) if vol_info.get('timeFinderInfo'): vol_tf_sessions = vol_info.get( 'timeFinderInfo').get('snapVXSession') if vol_tf_sessions: for session in vol_tf_sessions: if session.get('tgtSrcSnapshotGenInfo'): snap_tgt_link = session.get( 'tgtSrcSnapshotGenInfo') snap_tgt_dict['snap_name'] = snap_tgt_link.get( 'snapshotName') snap_tgt_dict['expired'] = snap_tgt_link.get( 'expired') snap_tgt_dict['snapid'] = snap_tgt_link.get( 'snapid') if self.is_snap_id else ( snap_tgt_link.get('generation')) return snap_src_dict_list, snap_tgt_dict def get_rdf_group(self, array, rdf_number): """"""Get specific rdf group details. :param array: the array serial number :param rdf_number: the rdf number """""" return self.get_resource(array, REPLICATION, 'rdf_group', rdf_number) def get_storage_group_rdf_group_state(self, array, storage_group, rdf_group_no): """"""Get the RDF group state from a replication enabled Storage Group. :param array: the array serial number :param storage_group: the storage group name :param rdf_group_no: the RDF group number :returns: storage group RDF group state """""" resource = ('storagegroup/%(sg)s/rdf_group/%(rdfg)s' % { 'sg': storage_group, 'rdfg': rdf_group_no}) rdf_group = self.get_resource(array, REPLICATION, resource) return rdf_group.get('states', list()) if rdf_group else dict() def get_storage_group_rdf_groups(self, array, storage_group): """"""Get a list of rdf group numbers used by a storage group. :param array: the array serial number -- str :param storage_group: the storage group name to check -- str :return: RDFGs associated with the storage group -- dict """""" resource = ('storagegroup/%(storage_group)s/rdf_group' % { 'storage_group': storage_group}) storage_group_details = self.get_resource(array, REPLICATION, resource) return storage_group_details['rdfgs'] def get_rdf_group_list(self, array): """"""Get rdf group list from array. :param array: the array serial number """""" return self.get_resource(array, REPLICATION, 'rdf_group') def get_rdf_group_volume_list(self, array, rdf_group_no): """"""Get a list of all volumes in an RDFG. :param array: the array serial number -- str :param rdf_group_no: the RDF group number -- str :return: RDFG volume list -- list """""" resource = ('rdf_group/%(rdf_group)s/volume' % { 'rdf_group': rdf_group_no}) rdf_group_volumes = self.get_resource(array, REPLICATION, resource) return rdf_group_volumes['name'] def get_rdf_group_volume(self, array, src_device_id): """"""Get the RDF details for a volume. :param array: the array serial number :param src_device_id: the source device id :returns: rdf_session """""" rdf_session = None volume = self._get_private_volume(array, src_device_id) try: rdf_session = volume['rdfInfo']['RDFSession'][0] except (KeyError, TypeError, IndexError): LOG.warning(""Cannot locate source RDF volume %s"", src_device_id) return rdf_session def get_rdf_pair_volume(self, array, rdf_group_no, device_id): """"""Get information on an RDF pair from the source volume. :param array: the array serial number :param rdf_group_no: the RDF group number :param device_id: the source device ID :returns: RDF pair information -- dict """""" resource = ('rdf_group/%(rdf_group)s/volume/%(device)s' % { 'rdf_group': rdf_group_no, 'device': device_id}) return self.get_resource(array, REPLICATION, resource) def are_vols_rdf_paired(self, array, remote_array, device_id, target_device): """"""Check if a pair of volumes are RDF paired. :param array: the array serial number :param remote_array: the remote array serial number :param device_id: the device id :param target_device: the target device id :returns: paired -- bool, local_vol_state, rdf_pair_state """""" paired, local_vol_state, rdf_pair_state = False, '', '' rdf_session = self.get_rdf_group_volume(array, device_id) if rdf_session: remote_volume = rdf_session['remoteDeviceID'] remote_symm = rdf_session['remoteSymmetrixID'] if (remote_volume == target_device and remote_array == remote_symm): paired = True local_vol_state = rdf_session['SRDFStatus'] rdf_pair_state = rdf_session['pairState'] else: LOG.warning(""Cannot locate RDF session for volume %s"", device_id) return paired, local_vol_state, rdf_pair_state def wait_for_rdf_group_sync(self, array, storage_group, rdf_group_no, rep_extra_specs): """"""Wait for an RDF group to reach 'Synchronised' state. :param array: the array serial number :param storage_group: the storage group name :param rdf_group_no: the RDF group number :param rep_extra_specs: replication extra specifications :raises: exception.VolumeBackendAPIException """""" def _wait_for_synced_state(): try: kwargs['retries'] -= 1 if not kwargs['synced']: rdf_group_state = self.get_storage_group_rdf_group_state( array, storage_group, rdf_group_no) if rdf_group_state: kwargs['state'] = rdf_group_state[0] if kwargs['state'].lower() in utils.RDF_SYNCED_STATES: kwargs['synced'] = True kwargs['rc'] = 0 except Exception as e_msg: ex_msg = _(""Issue encountered waiting for job: %(e)s"" % { 'e': e_msg}) LOG.error(ex_msg) raise exception.VolumeBackendAPIException(message=ex_msg) if kwargs['retries'] == 0: ex_msg = _(""Wait for RDF Sync State failed after %(r)d "" ""tries."" % {'r': rep_extra_specs['sync_retries']}) LOG.error(ex_msg) raise exception.VolumeBackendAPIException(message=ex_msg) if kwargs['synced']: raise loopingcall.LoopingCallDone() kwargs = {'retries': rep_extra_specs['sync_retries'], 'synced': False, 'rc': 0, 'state': 'syncinprog'} timer = loopingcall.FixedIntervalLoopingCall(_wait_for_synced_state) timer.start(interval=rep_extra_specs['sync_interval']).wait() LOG.debug(""Return code is: %(rc)lu. State is %(state)s"", {'rc': kwargs['rc'], 'state': kwargs['state']}) def wait_for_rdf_pair_sync(self, array, rdf_group_no, device_id, rep_extra_specs): """"""Wait for an RDF device pair to reach 'Synchronised' state. :param array: the array serial number :param rdf_group_no: the RDF group number :param device_id: the source device ID :param rep_extra_specs: replication extra specifications :raises: exception.VolumeBackendAPIException """""" def _wait_for_synced_state(): try: kwargs['retries'] -= 1 if not kwargs['synced']: rdf_pair = self.get_rdf_pair_volume(array, rdf_group_no, device_id) kwargs['state'] = rdf_pair['rdfpairState'] if kwargs['state'].lower() in utils.RDF_SYNCED_STATES: kwargs['synced'] = True kwargs['rc'] = 0 except Exception as e_msg: ex_msg = _(""Issue encountered waiting for job: %(e)s"" % { 'e': e_msg}) LOG.error(ex_msg) raise exception.VolumeBackendAPIException(message=ex_msg) if kwargs['retries'] == 0: ex_msg = _(""Wait for RDF Sync State failed after %(r)d "" ""tries."" % {'r': rep_extra_specs['sync_retries']}) LOG.error(ex_msg) raise exception.VolumeBackendAPIException(message=ex_msg) if kwargs['synced']: raise loopingcall.LoopingCallDone() kwargs = {'retries': rep_extra_specs['sync_retries'], 'synced': False, 'rc': 0, 'state': 'syncinprog'} timer = loopingcall.FixedIntervalLoopingCall(_wait_for_synced_state) timer.start(interval=rep_extra_specs['sync_interval']).wait() LOG.debug(""Return code is: %(rc)lu. State is %(state)s"", {'rc': kwargs['rc'], 'state': kwargs['state']}) def rdf_resume_with_retries(self, array, rep_extra_specs): """"""Resume RDF on a RDF group with retry operator included. The retry operator is required here because on occassion when we are waiting on a snap copy session to complete we have no way of determining if the copy is complete, operation is retried until either the copy completes or the max interval/retries has been met. :param array: the array serial number :param rep_extra_specs: replication extra specifications :raises: exception.VolumeBackendAPIException """""" def wait_for_copy_complete(): kwargs['retries'] -= 1 if not kwargs['copied']: try: self.srdf_resume_replication( array, rep_extra_specs['sg_name'], rep_extra_specs['rdf_group_no'], rep_extra_specs, async_call=False) kwargs['copied'] = True kwargs['state'] = 'copy_complete' kwargs['rc'] = 0 raise loopingcall.LoopingCallDone() except exception.VolumeBackendAPIException: LOG.debug('Snapshot copy process still ongoing, Cinder ' 'will retry again in %(interval)s seconds. ' 'There are %(retries)s remaining.', { 'interval': rep_extra_specs['sync_interval'], 'retries': kwargs['retries']}) if kwargs['retries'] == 0: ex_msg = _(""Wait for snapshot copy complete failed after "" ""%(r)d tries."" % { 'r': rep_extra_specs['sync_retries']}) LOG.error(ex_msg) raise exception.VolumeBackendAPIException(message=ex_msg) kwargs = {'retries': rep_extra_specs['sync_retries'], 'copied': False, 'rc': 0, 'state': 'copy_in_progress'} timer = loopingcall.FixedIntervalLoopingCall(wait_for_copy_complete) timer.start(interval=rep_extra_specs['sync_interval']).wait() LOG.debug(""Return code: %(rc)lu. State: %(state)s"", {'rc': kwargs['rc'], 'state': kwargs['state']}) def get_rdf_group_number(self, array, rdf_group_label): """"""Given an rdf_group_label, return the associated group number. :param array: the array serial number :param rdf_group_label: the group label :returns: rdf_group_number """""" number = None rdf_list = self.get_rdf_group_list(array) if rdf_list and rdf_list.get('rdfGroupID'): number_list = [rdf['rdfgNumber'] for rdf in rdf_list['rdfGroupID'] if rdf['label'] == rdf_group_label] number = number_list[0] if len(number_list) > 0 else None if number: rdf_group = self.get_rdf_group(array, number) if not rdf_group: number = None return number def _get_async_payload_info(self, array, rdf_group_no): """"""Get the payload details for an async create pair. :param array: the array serial number :param rdf_group_no: the rdf group number :returns: payload_update """""" num_vols, payload_update = 0, {} rdfg_details = self.get_rdf_group(array, rdf_group_no) if rdfg_details is not None and rdfg_details.get('numDevices'): num_vols = int(rdfg_details['numDevices']) if num_vols > 0: payload_update = {'exempt': 'true'} return payload_update def get_metro_payload_info(self, array, payload, rdf_group_no, extra_specs, next_gen): """"""Get the payload details for a metro active create pair. :param array: the array serial number :param payload: the payload :param rdf_group_no: the rdf group number :param extra_specs: the replication configuration :param next_gen: if the array is next gen uCode :returns: updated payload """""" num_vols = 0 payload[""rdfMode""] = ""Active"" payload['rdfType'] = ""RDF1"" rdfg_details = self.get_rdf_group(array, rdf_group_no) if rdfg_details is not None and rdfg_details.get('numDevices'): num_vols = int(rdfg_details['numDevices']) if num_vols == 0: # First volume - set bias if required if extra_specs.get(utils.METROBIAS): payload.update({""metroBias"": ""true""}) else: if next_gen: payload[""exempt""] = ""true"" if payload.get('establish'): payload.pop('establish') return payload def srdf_protect_storage_group( self, array_id, remote_array_id, rdf_group_no, replication_mode, sg_name, service_level, extra_specs, target_sg=None): """"""SRDF protect a storage group. :param array_id: local array serial number :param remote_array_id: remote array serial number :param rdf_group_no: RDF group number :param replication_mode: replication mode :param sg_name: storage group name :param service_level: service level :param extra_specs: extra specifications :param target_sg: target storage group -- optional """""" remote_sg = target_sg if target_sg else sg_name payload = { ""executionOption"": ""ASYNCHRONOUS"", ""replicationMode"": replication_mode, ""remoteSLO"": service_level, ""remoteSymmId"": remote_array_id, ""rdfgNumber"": rdf_group_no, ""remoteStorageGroupName"": remote_sg, ""establish"": ""true""} # Metro specific configuration if replication_mode == utils.REP_METRO: bias = ""true"" if extra_specs.get(utils.METROBIAS) else ""false"" payload.update({ ""replicationMode"": ""Active"", ""metroBias"": bias}) LOG.debug('SRDF Protect Payload: %(pay)s', {'pay': payload}) resource = 'storagegroup/%(sg_name)s/rdf_group' % {'sg_name': sg_name} status_code, job = self.create_resource(array_id, REPLICATION, resource, payload) self.wait_for_job('SRDF Protect Storage Group', status_code, job, extra_specs) def srdf_modify_group(self, array, rdf_group_no, storage_group, payload, extra_specs, msg, async_call=True): """"""Modify RDF enabled storage group replication options. :param array: array serial number :param rdf_group_no: RDF group number :param storage_group: storage group name :param payload: REST request payload dict :param extra_specs: extra specifications :param msg: message to use for logs when waiting on job to complete :param async_call: if the REST call should be run, this only comes into effect when trying to resume replication and interval/retries are a factor. """""" resource = ('storagegroup/%(sg_name)s/rdf_group/%(rdf_group_no)s' % { 'sg_name': storage_group, 'rdf_group_no': rdf_group_no}) if async_call: payload.update({""executionOption"": ""ASYNCHRONOUS""}) status_code, job = self.modify_resource(array, REPLICATION, resource, payload) self.wait_for_job(msg, status_code, job, extra_specs) else: self.modify_resource(array, REPLICATION, resource, payload) def srdf_suspend_replication(self, array_id, storage_group, rdf_group_no, rep_extra_specs): """"""Suspend replication on a RDF group. :param array_id: array serial number :param storage_group: storage group name :param rdf_group_no: RDF group number :param rep_extra_specs: replication extra specifications """""" group_state = self.get_storage_group_rdf_group_state( array_id, storage_group, rdf_group_no) if group_state: group_state = [x.lower() for x in group_state] if len(group_state) == 1 and utils.RDF_SUSPENDED_STATE in group_state: LOG.info('SRDF Group %(grp_num)s is already in a suspended state', {'grp_num': rdf_group_no}) else: self.srdf_modify_group( array_id, rdf_group_no, storage_group, {""suspend"": {""force"": ""true""}, ""action"": ""Suspend""}, rep_extra_specs, 'Suspend SRDF Group Replication') def srdf_resume_replication(self, array_id, storage_group, rdf_group_no, rep_extra_specs, async_call=True): """"""Resume replication on a RDF group. :param array_id: array serial number :param storage_group: storage group name :param rdf_group_no: RDF group number :param rep_extra_specs: replication extra specifications :param async_call: if the REST call should be run, this only comes into effect when trying to resume replication and interval/retries are a factor. """""" if self.get_storage_group(array_id, storage_group): group_state = self.get_storage_group_rdf_group_state( array_id, storage_group, rdf_group_no) if group_state: group_state = [x.lower() for x in group_state] if utils.RDF_SUSPENDED_STATE in group_state: payload = {""action"": ""Resume""} if rep_extra_specs['rep_mode'] == utils.REP_METRO: payload = {""action"": ""Establish""} if rep_extra_specs.get(utils.METROBIAS): payload.update({""establish"": {""metroBias"": ""true""}}) self.srdf_modify_group( array_id, rdf_group_no, storage_group, payload, rep_extra_specs, 'Resume SRDF Group Replication', async_call) else: LOG.debug('SRDF Group %(grp_num)s is already in a resumed ' 'state.', {'grp_num': rdf_group_no}) else: LOG.debug('Storage Group %(sg)s not present on array ' '%(array)s, no resume required.', { 'sg': storage_group, 'array': array_id}) def srdf_establish_replication(self, array_id, storage_group, rdf_group_no, rep_extra_specs): """"""Establish replication on a RDF group. :param array_id: array serial number :param storage_group: storage group name :param rdf_group_no: RDF group number :param rep_extra_specs: replication extra specifications """""" group_state = self.get_storage_group_rdf_group_state( array_id, storage_group, rdf_group_no) if utils.RDF_SUSPENDED_STATE not in group_state: LOG.info('Suspending SRDF Group %(grp_num)s', { 'grp_num': rdf_group_no}) self.srdf_modify_group( array_id, rdf_group_no, storage_group, {""action"": ""Suspend""}, rep_extra_specs, 'Suspend SRDF Group Replication') wait_msg = 'Incremental Establish SRDF Group Replication' LOG.info('Initiating incremental establish on SRDF Group %(grp_num)s', {'grp_num': rdf_group_no}) self.srdf_modify_group( array_id, rdf_group_no, storage_group, {""action"": ""Establish""}, rep_extra_specs, wait_msg) def srdf_failover_group(self, array_id, storage_group, rdf_group_no, rep_extra_specs): """"""Failover a RDFG/SG volume group to replication target. :param array_id: array serial number :param storage_group: storage group name :param rdf_group_no: RDF group number :param rep_extra_specs: replication extra specifications """""" self.srdf_modify_group( array_id, rdf_group_no, storage_group, {""action"": ""Failover""}, rep_extra_specs, 'Failing over SRDF group replication') def srdf_failback_group(self, array_id, storage_group, rdf_group_no, rep_extra_specs): """"""Failback a RDFG/SG volume group from replication target. :param array_id: :param storage_group: :param rdf_group_no: :param rep_extra_specs: """""" self.srdf_modify_group( array_id, rdf_group_no, storage_group, {""action"": ""Failback""}, rep_extra_specs, 'Failing back SRDF group replication') def srdf_remove_device_pair_from_storage_group( self, array_id, storage_group, remote_array_id, device_id, rep_extra_specs): """"""Remove a volume from local and remote storage groups simultaneously. :param array_id: local array serial number :param storage_group: storage group name :param remote_array_id: remote array serial number :param device_id: source device id :param rep_extra_specs: replication extra specifications """""" payload = { ""editStorageGroupActionParam"": { ""removeVolumeParam"": { ""volumeId"": [device_id], ""remoteSymmSGInfoParam"": { ""remote_symmetrix_1_id"": remote_array_id, ""remote_symmetrix_1_sgs"": [storage_group]}}}} status_code, job = self.modify_storage_group(array_id, storage_group, payload) self.wait_for_job('SRDF Group remove device pair', status_code, job, rep_extra_specs) def srdf_delete_device_pair(self, array, rdf_group_no, local_device_id): """"""Delete a RDF device pair. :param array: array serial number :param rdf_group_no: RDF group number :param local_device_id: local device id """""" resource = ('%(rdfg)s/volume/%(dev)s' % { 'rdfg': rdf_group_no, 'dev': local_device_id}) self.delete_resource(array, REPLICATION, 'rdf_group', resource) LOG.debug(""Device Pair successfully deleted."") def srdf_create_device_pair(self, array, rdf_group_no, mode, device_id, rep_extra_specs, next_gen): """"""Create a RDF device pair in an existing RDF group. :param array: array serial number :param rdf_group_no: RDF group number :param mode: replication mode :param device_id: local device ID :param rep_extra_specs: replication extra specifications :param next_gen: if the array is next gen uCode :returns: replication session info -- dict """""" payload = { ""executionOption"": ""ASYNCHRONOUS"", ""rdfMode"": mode, ""localDeviceListCriteriaParam"": {""localDeviceList"": [device_id]}, ""rdfType"": ""RDF1""} if mode == utils.REP_SYNC: payload.update({""establish"": ""true""}) elif mode == utils.REP_ASYNC: payload.update({""invalidateR2"": ""true"", ""exempt"": ""true""}) elif mode.lower() in [utils.REP_METRO.lower(), utils.RDF_ACTIVE.lower()]: payload = self.get_metro_payload_info( array, payload, rdf_group_no, rep_extra_specs, next_gen) LOG.debug('Create Pair Payload: %(pay)s', {'pay': payload}) resource = 'rdf_group/%(rdfg)s/volume' % {'rdfg': rdf_group_no} status_code, job = self.create_resource( array, REPLICATION, resource, payload) self.wait_for_job('SRDF Group remove device pair', status_code, job, rep_extra_specs) session_info = self.get_rdf_pair_volume(array, rdf_group_no, device_id) r2_device_id = session_info['remoteVolumeName'] return {'array': session_info['localSymmetrixId'], 'remote_array': session_info['remoteSymmetrixId'], 'src_device': device_id, 'tgt_device': r2_device_id, 'session_info': session_info} def get_storage_group_rep(self, array, storage_group_name): """"""Given a name, return storage group details wrt replication. :param array: the array serial number :param storage_group_name: the name of the storage group :returns: storage group dict or None """""" return self.get_resource( array, REPLICATION, 'storagegroup', resource_name=storage_group_name) def get_volumes_in_storage_group(self, array, storagegroup_name): """"""Given a volume identifier, find the corresponding device_id. :param array: the array serial number :param storagegroup_name: the storage group name :returns: volume_list """""" params = {""storageGroupId"": storagegroup_name} volume_list = self.get_volume_list(array, params) if not volume_list: LOG.debug(""Cannot find record for storage group %(storageGrpId)s"", {'storageGrpId': storagegroup_name}) return volume_list def create_storagegroup_snap(self, array, source_group, snap_name, extra_specs): """"""Create a snapVx snapshot of a storage group. :param array: the array serial number :param source_group: the source group name :param snap_name: the name of the snapshot :param extra_specs: the extra specifications """""" payload = {""snapshotName"": snap_name} resource_type = ('storagegroup/%(sg_name)s/snapshot' % {'sg_name': source_group}) status_code, job = self.create_resource( array, REPLICATION, resource_type, payload) self.wait_for_job('Create storage group snapVx', status_code, job, extra_specs) def delete_storagegroup_snap(self, array, source_group, snap_name, snap_id): """"""Delete a snapVx snapshot of a storage group. :param array: the array serial number :param source_group: the source group name :param snap_name: the name of the snapshot :param snap_id: the unique snap id of the SnapVX """""" postfix_uri = ""/snapid/%s"" % snap_id if self.is_snap_id else ( ""/generation/%s"" % snap_id) resource_name = (""%(sg_name)s/snapshot/%(snap_name)s"" ""%(postfix_uri)s"" % {'sg_name': source_group, 'snap_name': snap_name, 'postfix_uri': postfix_uri}) self.delete_resource( array, REPLICATION, 'storagegroup', resource_name=resource_name) def get_storage_group_snap_id_list( self, array, source_group, snap_name): """"""Get a snapshot and its snapid count information for an sg. :param array: name of the array -- str :param source_group: name of the storage group -- str :param snap_name: the name of the snapshot -- str :returns: snapids -- list """""" postfix_uri = ""snapid"" if self.is_snap_id else ""generation"" resource_name = (""%(sg_name)s/snapshot/%(snap_name)s/%(postfix_uri)s"" % {'sg_name': source_group, 'snap_name': snap_name, 'postfix_uri': postfix_uri}) response = self.get_resource(array, REPLICATION, 'storagegroup', resource_name=resource_name) if self.is_snap_id: return response.get('snapids', list()) if response else list() else: return response.get('generations', list()) if response else list() def get_storagegroup_rdf_details(self, array, storagegroup_name, rdf_group_num): """"""Get the remote replication details of a storage group. :param array: the array serial number :param storagegroup_name: the storage group name :param rdf_group_num: the rdf group number """""" resource_name = (""%(sg_name)s/rdf_group/%(rdf_num)s"" % {'sg_name': storagegroup_name, 'rdf_num': rdf_group_num}) return self.get_resource(array, REPLICATION, 'storagegroup', resource_name=resource_name) def replicate_group(self, array, storagegroup_name, rdf_group_num, remote_array, extra_specs): """"""Create a target group on the remote array and enable replication. :param array: the array serial number :param storagegroup_name: the name of the group :param rdf_group_num: the rdf group number :param remote_array: the remote array serial number :param extra_specs: the extra specifications """""" resource_name = (""storagegroup/%(sg_name)s/rdf_group"" % {'sg_name': storagegroup_name}) payload = {""executionOption"": ""ASYNCHRONOUS"", ""replicationMode"": utils.REP_SYNC, ""remoteSymmId"": remote_array, ""remoteStorageGroupName"": storagegroup_name, ""rdfgNumber"": rdf_group_num, ""establish"": 'true'} status_code, job = self.create_resource( array, REPLICATION, resource_name, payload) self.wait_for_job('Create storage group rdf', status_code, job, extra_specs) def _verify_rdf_state(self, array, storagegroup_name, rdf_group_num, action): """"""Verify if a storage group requires the requested state change. :param array: the array serial number :param storagegroup_name: the storage group name :param rdf_group_num: the rdf group number :param action: the requested action :returns: bool """""" mod_rqd = False sg_rdf_details = self.get_storagegroup_rdf_details( array, storagegroup_name, rdf_group_num) if sg_rdf_details: state_list = sg_rdf_details['states'] LOG.debug(""RDF state: %(sl)s; Action required: %(action)s"", {'sl': state_list, 'action': action}) for state in state_list: if (action.lower() in [""establish"", ""failback"", ""resume""] and state.lower() in [utils.RDF_SUSPENDED_STATE, utils.RDF_FAILEDOVER_STATE]): mod_rqd = True break elif (action.lower() in [""split"", ""failover"", ""suspend""] and state.lower() in [utils.RDF_SYNC_STATE, utils.RDF_SYNCINPROG_STATE, utils.RDF_CONSISTENT_STATE, utils.RDF_ACTIVE, utils.RDF_ACTIVEACTIVE, utils.RDF_ACTIVEBIAS]): mod_rqd = True break return mod_rqd def delete_storagegroup_rdf(self, array, storagegroup_name, rdf_group_num): """"""Delete the rdf pairs for a storage group. :param array: the array serial number :param storagegroup_name: the name of the storage group :param rdf_group_num: the number of the rdf group """""" resource_name = ('%(sg_name)s/rdf_group/%(rdf_num)s' % {'sg_name': storagegroup_name, 'rdf_num': rdf_group_num}) self.delete_resource( array, REPLICATION, 'storagegroup', resource_name=resource_name) def list_pagination(self, list_info): """"""Process lists under or over the maxPageSize :param list_info: the object list information :returns: the result list """""" result_list = [] try: result_list = list_info['resultList']['result'] iterator_id = list_info['id'] list_count = list_info['count'] max_page_size = list_info['maxPageSize'] start_position = list_info['resultList']['from'] end_position = list_info['resultList']['to'] except (KeyError, TypeError): return list_info if list_count > max_page_size: LOG.info(""More entries exist in the result list, retrieving "" ""remainder of results from iterator."") start_position = end_position + 1 if list_count < (end_position + max_page_size): end_position = list_count else: end_position += max_page_size iterator_response = self.get_iterator_page_list( iterator_id, list_count, start_position, end_position, max_page_size) result_list += iterator_response return result_list def get_iterator_page_list(self, iterator_id, result_count, start_position, end_position, max_page_size): """"""Iterate through response if more than one page available. :param iterator_id: the iterator ID :param result_count: the amount of results in the iterator :param start_position: position to begin iterator from :param end_position: position to stop iterator :param max_page_size: the max page size :returns: list -- merged results from multiple pages """""" LOG.debug('Iterator %(it)s contains %(cnt)s results.', { 'it': iterator_id, 'cnt': result_count}) iterator_result = [] has_more_entries = True while has_more_entries: if start_position <= result_count <= end_position: end_position = result_count has_more_entries = False params = {'to': end_position, 'from': start_position} LOG.debug('Retrieving iterator %(it)s page %(st)s to %(fn)s', { 'it': iterator_id, 'st': start_position, 'fn': end_position}) target_uri = ('/common/Iterator/%(iterator_id)s/page' % { 'iterator_id': iterator_id}) iterator_response = self.get_request(target_uri, 'iterator', params) try: iterator_result += iterator_response['result'] start_position += max_page_size end_position += max_page_size except (KeyError, TypeError): pass LOG.info('All results extracted, deleting iterator %(it)s', { 'it': iterator_id}) self._delete_iterator(iterator_id) return iterator_result def _delete_iterator(self, iterator_id): """"""Delete an iterator containing full request result list. Note: This should only be called once all required results have been extracted from the iterator. :param iterator_id: the iterator ID -- str """""" target_uri = self.build_uri( category='common', resource_level='Iterator', resource_level_id=iterator_id, no_version=True) status_code, message = self.request(target_uri, DELETE) operation = 'delete iterator' self.check_status_code_success(operation, status_code, message) LOG.info('Successfully deleted iterator %(it)s', {'it': iterator_id}) def validate_unisphere_version(self): """"""Validate that the running Unisphere version meets min requirement :returns: unisphere_meets_min_req -- boolean """""" running_version, major_version = self.get_uni_version() minimum_version = MIN_U4P_VERSION unisphere_meets_min_req = False if running_version and (running_version[0].isalpha()): # remove leading letter if running_version.lower()[0] == 'v': version = running_version[1:] unisphere_meets_min_req = ( self.utils.version_meet_req(version, minimum_version)) elif running_version.lower()[0] == 't': LOG.warning(""%(version)s This is not a official release of "" ""Unisphere."", {'version': running_version}) return major_version >= U4V_VERSION if unisphere_meets_min_req: LOG.info(""Unisphere version %(running_version)s meets minimum "" ""requirement of version %(minimum_version)s."", {'running_version': running_version, 'minimum_version': minimum_version}) elif running_version: LOG.error(""Unisphere version %(running_version)s does not meet "" ""minimum requirement for use with this release, please "" ""upgrade to Unisphere %(minimum_version)s at minimum."", {'running_version': running_version, 'minimum_version': minimum_version}) else: LOG.warning(""Unable to validate Unisphere instance meets minimum "" ""requirements."") return unisphere_meets_min_req def get_snap_id(self, array, device_id, snap_name): """"""Get the unique snap id for a particular snap name :param array: the array serial number :param device_id: the source device ID :param snap_name: the user supplied snapVX name :raises: VolumeBackendAPIException :returns: snap_id -- str """""" snapshots = self.get_volume_snaps(array, device_id, snap_name) if not snapshots: exception_message = (_( ""Snapshot %(snap_name)s is not associated with "" ""specified volume %(device_id)s."") % { 'device_id': device_id, 'snap_name': snap_name}) LOG.error(exception_message) raise exception.VolumeBackendAPIException( message=exception_message) elif len(snapshots) > 1: exception_message = (_( ""Snapshot %(snap_name)s is associated with more than "" ""one snap id. No information available to choose "" ""which one."") % { 'device_id': device_id, 'snap_name': snap_name}) LOG.error(exception_message) raise exception.VolumeBackendAPIException( message=exception_message) else: return snapshots[0].get('snap_id') if self.is_snap_id else ( snapshots[0].get('generation')) def get_major_minor_ucode(self, array): """"""Get the major and minor parts of the ucode :param array: the array serial number :returns: ucode_major_level, ucode_minor_level -- str, str """""" array_details = self.get_array_detail(array) ucode_major_level = 0 ucode_minor_level = 0 if array_details: split_ucode_level = array_details['ucode'].split('.') ucode_level = [int(level) for level in split_ucode_level] ucode_major_level = ucode_level[0] ucode_minor_level = ucode_level[1] return ucode_major_level, ucode_minor_level def _is_snapid_enabled(self): """"""Check if array is snap_id enabled :returns: boolean """""" return (self.ucode_major_level >= utils.UCODE_5978 and self.ucode_minor_level >= utils.UCODE_5978_HICKORY) ","# Copyright (c) 2020 Dell Inc. or its subsidiaries. # All Rights Reserved. # # Licensed under the Apache License, Version 2.0 (the ""License""); you may # not use this file except in compliance with the License. You may obtain # a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT # WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the # License for the specific language governing permissions and limitations # under the License. import json import re import sys import time from oslo_log import log as logging from oslo_service import loopingcall import requests import requests.auth import requests.exceptions as r_exc # pylint: disable=E0401 import requests.packages.urllib3.util.retry as requests_retry import six from cinder import exception from cinder.i18n import _ from cinder.utils import retry from cinder.volume.drivers.dell_emc.powermax import utils LOG = logging.getLogger(__name__) SLOPROVISIONING = 'sloprovisioning' REPLICATION = 'replication' SYSTEM = 'system' U4V_VERSION = '92' MIN_U4P_VERSION = '9.2.0.0' UCODE_5978 = '5978' retry_exc_tuple = (exception.VolumeBackendAPIException,) u4p_failover_max_wait = 120 # HTTP constants GET = 'GET' POST = 'POST' PUT = 'PUT' DELETE = 'DELETE' STATUS_200 = 200 STATUS_201 = 201 STATUS_202 = 202 STATUS_204 = 204 SERVER_ERROR_STATUS_CODES = [408, 501, 502, 503, 504] ITERATOR_EXPIRATION = 180 # Job constants INCOMPLETE_LIST = ['created', 'unscheduled', 'scheduled', 'running', 'validating', 'validated'] CREATED = 'created' SUCCEEDED = 'succeeded' CREATE_VOL_STRING = ""Creating new Volumes"" POPULATE_SG_LIST = ""Populating Storage Group(s) with volumes"" class PowerMaxRest(object): """"""Rest class based on Unisphere for PowerMax Rest API."""""" def __init__(self): self.utils = utils.PowerMaxUtils() self.session = None self.base_uri = None self.user = None self.passwd = None self.verify = None self.cert = None # Failover Unisphere configuration self.primary_u4p = None self.u4p_failover_enabled = False self.u4p_failover_autofailback = True self.u4p_failover_targets = list() self.u4p_failover_retries = 3 self.u4p_failover_timeout = 30 self.u4p_failover_backoff_factor = 1 self.u4p_in_failover = False self.u4p_failover_lock = False self.ucode_major_level = None self.ucode_minor_level = None self.is_snap_id = False def set_rest_credentials(self, array_info): """"""Given the array record set the rest server credentials. :param array_info: record """""" ip = array_info['RestServerIp'] port = array_info['RestServerPort'] self.user = array_info['RestUserName'] self.passwd = array_info['RestPassword'] self.verify = array_info['SSLVerify'] ip_port = ""%(ip)s:%(port)s"" % {'ip': ip, 'port': port} self.base_uri = (""https://%(ip_port)s/univmax/restapi"" % { 'ip_port': ip_port}) self.session = self._establish_rest_session() self.ucode_major_level, self.ucode_minor_level = ( self.get_major_minor_ucode(array_info['SerialNumber'])) self.is_snap_id = self._is_snapid_enabled() def set_u4p_failover_config(self, failover_info): """"""Set the environment failover Unisphere targets and configuration.. :param failover_info: failover target record """""" self.u4p_failover_enabled = True self.primary_u4p = failover_info['u4p_primary'] self.u4p_failover_targets = failover_info['u4p_failover_targets'] if failover_info['u4p_failover_retries']: self.u4p_failover_retries = failover_info['u4p_failover_retries'] if failover_info['u4p_failover_timeout']: self.u4p_failover_timeout = failover_info['u4p_failover_timeout'] if failover_info['u4p_failover_backoff_factor']: self.u4p_failover_backoff_factor = failover_info[ 'u4p_failover_backoff_factor'] if failover_info['u4p_failover_autofailback']: self.u4p_failover_autofailback = failover_info[ 'u4p_failover_autofailback'] def _establish_rest_session(self): """"""Establish the rest session. :returns: requests.session() -- session, the rest session """""" LOG.info(""Establishing REST session with %(base_uri)s"", {'base_uri': self.base_uri}) if self.session: self.session.close() session = requests.session() session.headers = {'content-type': 'application/json', 'accept': 'application/json', 'Application-Type': 'openstack'} session.auth = requests.auth.HTTPBasicAuth(self.user, self.passwd) if self.verify is not None: session.verify = self.verify # SESSION FAILOVER CONFIGURATION if self.u4p_failover_enabled: timeout = self.u4p_failover_timeout class MyHTTPAdapter(requests.adapters.HTTPAdapter): def send(self, *args, **kwargs): kwargs['timeout'] = timeout return super(MyHTTPAdapter, self).send(*args, **kwargs) retry = requests_retry.Retry( total=self.u4p_failover_retries, backoff_factor=self.u4p_failover_backoff_factor, status_forcelist=SERVER_ERROR_STATUS_CODES) adapter = MyHTTPAdapter(max_retries=retry) session.mount('https://', adapter) session.mount('http://', adapter) return session def _handle_u4p_failover(self): """"""Handle the failover process to secondary instance of Unisphere. :raises: VolumeBackendAPIException """""" if self.u4p_failover_targets: LOG.error(""Unisphere failure at %(prim)s, switching to next "" ""backup instance of Unisphere at %(sec)s"", { 'prim': self.base_uri, 'sec': self.u4p_failover_targets[0][ 'RestServerIp']}) self.set_rest_credentials(self.u4p_failover_targets[0]) self.u4p_failover_targets.pop(0) if self.u4p_in_failover: LOG.warning(""PowerMax driver still in u4p failover mode. A "" ""periodic check will be made to see if primary "" ""Unisphere comes back online for seamless "" ""restoration."") else: LOG.warning(""PowerMax driver set to u4p failover mode. A "" ""periodic check will be made to see if primary "" ""Unisphere comes back online for seamless "" ""restoration."") self.u4p_in_failover = True else: msg = _(""A connection could not be established with the "" ""primary instance of Unisphere or any of the "" ""specified failover instances of Unisphere. Please "" ""check your local environment setup and restart "" ""Cinder Volume service to revert back to the primary "" ""Unisphere instance."") self.u4p_failover_lock = False raise exception.VolumeBackendAPIException(message=msg) def request(self, target_uri, method, params=None, request_object=None, u4p_check=False, retry=False): """"""Sends a request (GET, POST, PUT, DELETE) to the target api. :param target_uri: target uri (string) :param method: The method (GET, POST, PUT, or DELETE) :param params: Additional URL parameters :param request_object: request payload (dict) :param u4p_check: if request is testing connection (boolean) :param retry: if request is retry from prior failed request (boolean) :returns: server response object (dict) :raises: VolumeBackendAPIException, Timeout, ConnectionError, HTTPError, SSLError """""" waiting_time = 0 while self.u4p_failover_lock and not retry and ( waiting_time < u4p_failover_max_wait): LOG.warning(""Unisphere failover lock in process, holding request "" ""until lock is released when Unisphere connection "" ""re-established."") sleeptime = 10 time.sleep(sleeptime) waiting_time += sleeptime if waiting_time >= u4p_failover_max_wait: self.u4p_failover_lock = False url, message, status_code, response = None, None, None, None if not self.session: self.session = self._establish_rest_session() try: url = (""%(self.base_uri)s%(target_uri)s"" % { 'self.base_uri': self.base_uri, 'target_uri': target_uri}) if request_object: response = self.session.request( method=method, url=url, data=json.dumps(request_object, sort_keys=True, indent=4)) elif params: response = self.session.request( method=method, url=url, params=params) else: response = self.session.request( method=method, url=url) status_code = response.status_code if retry and status_code and status_code in [STATUS_200, STATUS_201, STATUS_202, STATUS_204]: self.u4p_failover_lock = False try: message = response.json() except ValueError: LOG.debug(""No response received from API. Status code "" ""received is: %(status_code)s"", { 'status_code': status_code}) message = None if retry: self.u4p_failover_lock = False LOG.debug(""%(method)s request to %(url)s has returned with "" ""a status code of: %(status_code)s."", { 'method': method, 'url': url, 'status_code': status_code}) except r_exc.SSLError as e: if retry: self.u4p_failover_lock = False msg = _(""The connection to %(base_uri)s has encountered an "" ""SSL error. Please check your SSL config or supplied "" ""SSL cert in Cinder configuration. SSL Exception "" ""message: %(e)s"") raise r_exc.SSLError(msg % {'base_uri': self.base_uri, 'e': e}) except (r_exc.Timeout, r_exc.ConnectionError, r_exc.HTTPError) as e: if self.u4p_failover_enabled or u4p_check: if not u4p_check: # Failover process LOG.warning(""Running failover to backup instance "" ""of Unisphere"") self.u4p_failover_lock = True self._handle_u4p_failover() # Failover complete, re-run failed operation LOG.info(""Running request again to backup instance of "" ""Unisphere"") status_code, message = self.request( target_uri, method, params, request_object, retry=True) elif not self.u4p_failover_enabled: exc_class, __, __ = sys.exc_info() msg = _(""The %(method)s to Unisphere server %(base)s has "" ""experienced a %(error)s error. Please check your "" ""Unisphere server connection/availability. "" ""Exception message: %(exc_msg)s"") raise exc_class(msg % {'method': method, 'base': self.base_uri, 'error': e.__class__.__name__, 'exc_msg': e}) except Exception as e: if retry: self.u4p_failover_lock = False msg = _(""The %s request to URL %s failed with exception "" ""%s"" % (method, url, six.text_type(e))) LOG.error(msg) raise exception.VolumeBackendAPIException(message=msg) return status_code, message def wait_for_job_complete(self, job, extra_specs): """"""Given the job wait for it to complete. :param job: the job dict :param extra_specs: the extra_specs dict. :returns: rc -- int, result -- string, status -- string, task -- list of dicts detailing tasks in the job :raises: VolumeBackendAPIException """""" res, tasks = None, None if job['status'].lower == CREATED: try: res, tasks = job['result'], job['task'] except KeyError: pass return 0, res, job['status'], tasks def _wait_for_job_complete(): result = None # Called at an interval until the job is finished. retries = kwargs['retries'] try: kwargs['retries'] = retries + 1 if not kwargs['wait_for_job_called']: is_complete, result, rc, status, task = ( self._is_job_finished(job_id)) if is_complete is True: kwargs['wait_for_job_called'] = True kwargs['rc'], kwargs['status'] = rc, status kwargs['result'], kwargs['task'] = result, task except Exception: exception_message = (_(""Issue encountered waiting for job."")) LOG.error(exception_message) raise exception.VolumeBackendAPIException( message=exception_message) if retries > int(extra_specs[utils.RETRIES]): LOG.error(""_wait_for_job_complete failed after "" ""%(retries)d tries."", {'retries': retries}) kwargs['rc'], kwargs['result'] = -1, result raise loopingcall.LoopingCallDone() if kwargs['wait_for_job_called']: raise loopingcall.LoopingCallDone() job_id = job['jobId'] kwargs = {'retries': 0, 'wait_for_job_called': False, 'rc': 0, 'result': None} timer = loopingcall.FixedIntervalLoopingCall(_wait_for_job_complete) timer.start(interval=int(extra_specs[utils.INTERVAL])).wait() LOG.debug(""Return code is: %(rc)lu. Result is %(res)s."", {'rc': kwargs['rc'], 'res': kwargs['result']}) return (kwargs['rc'], kwargs['result'], kwargs['status'], kwargs['task']) def _is_job_finished(self, job_id): """"""Check if the job is finished. :param job_id: the id of the job :returns: complete -- bool, result -- string, rc -- int, status -- string, task -- list of dicts """""" complete, rc, status, result, task = False, 0, None, None, None job_url = ""/%s/system/job/%s"" % (U4V_VERSION, job_id) job = self.get_request(job_url, 'job') if job: status = job['status'] try: result, task = job['result'], job['task'] except KeyError: pass if status.lower() == SUCCEEDED: complete = True elif status.lower() in INCOMPLETE_LIST: complete = False else: rc, complete = -1, True return complete, result, rc, status, task @staticmethod def check_status_code_success(operation, status_code, message): """"""Check if a status code indicates success. :param operation: the operation :param status_code: the status code :param message: the server response :raises: VolumeBackendAPIException """""" if status_code not in [STATUS_200, STATUS_201, STATUS_202, STATUS_204]: exception_message = ( _(""Error %(operation)s. The status code received is %(sc)s "" ""and the message is %(message)s."") % { 'operation': operation, 'sc': status_code, 'message': message}) raise exception.VolumeBackendAPIException( message=exception_message) def wait_for_job(self, operation, status_code, job, extra_specs): """"""Check if call is async, wait for it to complete. :param operation: the operation being performed :param status_code: the status code :param job: the job :param extra_specs: the extra specifications :returns: task -- list of dicts detailing tasks in the job :raises: VolumeBackendAPIException """""" task = None if status_code == STATUS_202: rc, result, status, task = self.wait_for_job_complete( job, extra_specs) if rc != 0: exception_message = ( _(""Error %(operation)s. Status code: %(sc)lu. Error: "" ""%(error)s. Status: %(status)s."") % { 'operation': operation, 'sc': rc, 'error': six.text_type(result), 'status': status}) LOG.error(exception_message) raise exception.VolumeBackendAPIException( message=exception_message) return task def build_uri(self, *args, **kwargs): """"""Build the target url. :param args: input args, see _build_uri_legacy_args() for input breakdown :param kwargs: input keyword args, see _build_uri_kwargs() for input breakdown :return: target uri -- str """""" if args: target_uri = self._build_uri_legacy_args(*args, **kwargs) else: target_uri = self._build_uri_kwargs(**kwargs) return target_uri @staticmethod def _build_uri_legacy_args(*args, **kwargs): """"""Build the target URI using legacy args & kwargs. Expected format: arg[0]: the array serial number: the array serial number -- str arg[1]: the resource category e.g. 'sloprovisioning' -- str arg[2]: the resource type e.g. 'maskingview' -- str kwarg resource_name: the name of a specific resource -- str kwarg private: if endpoint is private -- bool kwarg version: U4V REST endpoint version -- int/str kwarg no_version: if endpoint should be versionless -- bool :param args: input args -- see above :param kwargs: input keyword args -- see above :return: target URI -- str """""" # Extract args following legacy _build_uri() format array_id, category, resource_type = args[0], args[1], args[2] # Extract keyword args following legacy _build_uri() format resource_name = kwargs.get('resource_name') private = kwargs.get('private') version = kwargs.get('version', U4V_VERSION) if kwargs.get('no_version'): version = None # Build URI target_uri = '' if private: target_uri += '/private' if version: target_uri += '/%(version)s' % {'version': version} target_uri += ( '/{cat}/symmetrix/{array_id}/{res_type}'.format( cat=category, array_id=array_id, res_type=resource_type)) if resource_name: target_uri += '/{resource_name}'.format( resource_name=kwargs.get('resource_name')) return target_uri @staticmethod def _build_uri_kwargs(**kwargs): """"""Build the target URI using kwargs. Expected kwargs: private: if endpoint is private (optional) -- bool version: U4P REST endpoint version (optional) -- int/None no_version: if endpoint should be versionless (optional) -- bool category: U4P REST category eg. 'common', 'replication'-- str resource_level: U4P REST resource level eg. 'symmetrix' (optional) -- str resource_level_id: U4P REST resource level id (optional) -- str resource_type: U4P REST resource type eg. 'rdf_director', 'host' (optional) -- str resource_type_id: U4P REST resource type id (optional) -- str resource: U4P REST resource eg. 'port' (optional) -- str resource_id: U4P REST resource id (optional) -- str object_type: U4P REST resource eg. 'rdf_group' (optional) -- str object_type_id: U4P REST resource id (optional) -- str :param kwargs: input keyword args -- see above :return: target URI -- str """""" version = kwargs.get('version', U4V_VERSION) if kwargs.get('no_version'): version = None target_uri = '' if kwargs.get('private'): target_uri += '/private' if version: target_uri += '/%(ver)s' % {'ver': version} target_uri += '/%(cat)s' % {'cat': kwargs.get('category')} if kwargs.get('resource_level'): target_uri += '/%(res_level)s' % { 'res_level': kwargs.get('resource_level')} if kwargs.get('resource_level_id'): target_uri += '/%(res_level_id)s' % { 'res_level_id': kwargs.get('resource_level_id')} if kwargs.get('resource_type'): target_uri += '/%(res_type)s' % { 'res_type': kwargs.get('resource_type')} if kwargs.get('resource_type_id'): target_uri += '/%(res_type_id)s' % { 'res_type_id': kwargs.get('resource_type_id')} if kwargs.get('resource'): target_uri += '/%(res)s' % { 'res': kwargs.get('resource')} if kwargs.get('resource_id'): target_uri += '/%(res_id)s' % { 'res_id': kwargs.get('resource_id')} if kwargs.get('object_type'): target_uri += '/%(object_type)s' % { 'object_type': kwargs.get('object_type')} if kwargs.get('object_type_id'): target_uri += '/%(object_type_id)s' % { 'object_type_id': kwargs.get('object_type_id')} return target_uri def get_request(self, target_uri, resource_type, params=None): """"""Send a GET request to the array. :param target_uri: the target uri :param resource_type: the resource type, e.g. maskingview :param params: optional dict of filter params :returns: resource_object -- dict or None """""" resource_object = None sc, message = self.request(target_uri, GET, params=params) operation = 'get %(res)s' % {'res': resource_type} try: self.check_status_code_success(operation, sc, message) except Exception as e: LOG.debug(""Get resource failed with %(e)s"", {'e': e}) if sc == STATUS_200: resource_object = message resource_object = self.list_pagination(resource_object) return resource_object def post_request(self, target_uri, resource_type, request_body): """"""Send a POST request to the array. :param target_uri: the target uri -- str :param resource_type: the resource type -- str :param request_body: the POST request body -- dict :return: resource object -- dict or None """""" resource_object = None sc, msg = self.request(target_uri, POST, request_object=request_body) operation = 'POST %(res)s' % {'res': resource_type} try: self.check_status_code_success(operation, sc, msg) except Exception as e: LOG.debug(""POST resource failed with %(e)s"", {'e': e}) if sc == STATUS_200: resource_object = msg return resource_object def get_resource(self, array, category, resource_type, resource_name=None, params=None, private=False, version=U4V_VERSION): """"""Get resource details from array. :param array: the array serial number :param category: the resource category e.g. sloprovisioning :param resource_type: the resource type e.g. maskingview :param resource_name: the name of a specific resource :param params: query parameters :param private: empty string or '/private' if private url :param version: None or specific version number if required :returns: resource object -- dict or None """""" target_uri = self.build_uri( array, category, resource_type, resource_name=resource_name, private=private, version=version) return self.get_request(target_uri, resource_type, params) def create_resource(self, array, category, resource_type, payload, private=False): """"""Create a provisioning resource. :param array: the array serial number :param category: the category :param resource_type: the resource type :param payload: the payload :param private: empty string or '/private' if private url :returns: status_code -- int, message -- string, server response """""" target_uri = self.build_uri( array, category, resource_type, private=private) status_code, message = self.request(target_uri, POST, request_object=payload) operation = 'Create %(res)s resource' % {'res': resource_type} self.check_status_code_success( operation, status_code, message) return status_code, message def modify_resource( self, array, category, resource_type, payload, version=U4V_VERSION, resource_name=None, private=False): """"""Modify a resource. :param version: the uv4 version :param array: the array serial number :param category: the category :param resource_type: the resource type :param payload: the payload :param resource_name: the resource name :param private: empty string or '/private' if private url :returns: status_code -- int, message -- string (server response) """""" target_uri = self.build_uri( array, category, resource_type, resource_name=resource_name, private=private, version=version) status_code, message = self.request(target_uri, PUT, request_object=payload) operation = 'modify %(res)s resource' % {'res': resource_type} self.check_status_code_success(operation, status_code, message) return status_code, message @retry(retry_exc_tuple, interval=2, retries=3) def delete_resource( self, array, category, resource_type, resource_name, payload=None, private=False, params=None): """"""Delete a provisioning resource. :param array: the array serial number :param category: the resource category e.g. sloprovisioning :param resource_type: the type of resource to be deleted :param resource_name: the name of the resource to be deleted :param payload: the payload, optional :param private: empty string or '/private' if private url :param params: dict of optional query params """""" target_uri = self.build_uri( array, category, resource_type, resource_name=resource_name, private=private) status_code, message = self.request(target_uri, DELETE, request_object=payload, params=params) operation = 'delete %(res)s resource' % {'res': resource_type} self.check_status_code_success(operation, status_code, message) def get_arrays_list(self): """"""Get a list of all arrays on U4P instance. :returns arrays -- list """""" target_uri = '/%s/sloprovisioning/symmetrix' % U4V_VERSION array_details = self.get_request(target_uri, 'sloprovisioning') if not array_details: LOG.error(""Could not get array details from Unisphere instance."") arrays = array_details.get('symmetrixId', list()) return arrays def get_array_detail(self, array): """"""Get an array from its serial number. :param array: the array serial number :returns: array_details -- dict or None """""" target_uri = '/%s/system/symmetrix/%s' % (U4V_VERSION, array) array_details = self.get_request(target_uri, 'system') if not array_details: LOG.error(""Cannot connect to array %(array)s."", {'array': array}) return array_details def get_array_tags(self, array): """"""Get the tags from its serial number. :param array: the array serial number :returns: tag list -- list or empty list """""" target_uri = '/%s/system/tag?array_id=%s' % (U4V_VERSION, array) array_tags = self.get_request(target_uri, 'system') return array_tags.get('tag_name') def is_next_gen_array(self, array): """"""Check to see if array is a next gen array(ucode 5978 or greater). :param array: the array serial number :returns: bool """""" is_next_gen = False array_details = self.get_array_detail(array) if array_details: ucode_version = array_details['ucode'].split('.')[0] if ucode_version >= UCODE_5978: is_next_gen = True return is_next_gen def get_uni_version(self): """"""Get the unisphere version from the server. :returns: version and major_version(e.g. (""V8.4.0.16"", ""84"")) """""" version, major_version = None, None response = self.get_unisphere_version() if response and response.get('version'): version = response['version'] version_list = version.split('.') major_version = version_list[0][1] + version_list[1] return version, major_version def get_unisphere_version(self): """"""Get the unisphere version from the server. :returns: version dict """""" post_90_endpoint = '/version' pre_91_endpoint = '/system/version' status_code, version_dict = self.request(post_90_endpoint, GET) if status_code is not STATUS_200: status_code, version_dict = self.request(pre_91_endpoint, GET) if not version_dict: LOG.error(""Unisphere version info not found."") return version_dict def get_srp_by_name(self, array, srp=None): """"""Returns the details of a storage pool. :param array: the array serial number :param srp: the storage resource pool name :returns: SRP_details -- dict or None """""" LOG.debug(""storagePoolName: %(srp)s, array: %(array)s."", {'srp': srp, 'array': array}) srp_details = self.get_resource(array, SLOPROVISIONING, 'srp', resource_name=srp, params=None) return srp_details def get_slo_list(self, array, is_next_gen, array_model): """"""Retrieve the list of slo's from the array :param array: the array serial number :param is_next_gen: next generation flag :param array_model :returns: slo_list -- list of service level names """""" slo_list = [] slo_dict = self.get_resource(array, SLOPROVISIONING, 'slo') if slo_dict and slo_dict.get('sloId'): if not is_next_gen and ( any(array_model in x for x in utils.VMAX_AFA_MODELS)): if 'Optimized' in slo_dict.get('sloId'): slo_dict['sloId'].remove('Optimized') for slo in slo_dict['sloId']: if slo and slo not in slo_list: slo_list.append(slo) return slo_list def get_workload_settings(self, array, is_next_gen): """"""Get valid workload options from array. Workloads are no longer supported from HyperMaxOS 5978 onwards. :param array: the array serial number :param is_next_gen: is next generation flag :returns: workload_setting -- list of workload names """""" workload_setting = [] if is_next_gen: workload_setting.append('None') else: wl_details = self.get_resource( array, SLOPROVISIONING, 'workloadtype') if wl_details: workload_setting = wl_details['workloadId'] return workload_setting def get_vmax_model(self, array): """"""Get the PowerMax/VMAX model. :param array: the array serial number :returns: the PowerMax/VMAX model """""" vmax_version = None system_info = self.get_array_detail(array) if system_info and system_info.get('model'): vmax_version = system_info.get('model') return vmax_version def get_array_model_info(self, array): """"""Get the PowerMax/VMAX model. :param array: the array serial number :returns: the PowerMax/VMAX model """""" array_model = None is_next_gen = False system_info = self.get_array_detail(array) if system_info and system_info.get('model'): array_model = system_info.get('model') if system_info: ucode_version = system_info['ucode'].split('.')[0] if ucode_version >= UCODE_5978: is_next_gen = True return array_model, is_next_gen def get_array_ucode_version(self, array): """"""Get the PowerMax/VMAX uCode version. :param array: the array serial number :returns: the PowerMax/VMAX uCode version """""" ucode_version = None system_info = self.get_array_detail(array) if system_info: ucode_version = system_info['ucode'] return ucode_version def is_compression_capable(self, array): """"""Check if array is compression capable. :param array: array serial number :returns: bool """""" is_compression_capable = False target_uri = (""/%s/sloprovisioning/symmetrix?compressionCapable=true"" % U4V_VERSION) status_code, message = self.request(target_uri, GET) self.check_status_code_success( ""Check if compression enabled"", status_code, message) if message.get('symmetrixId'): if array in message['symmetrixId']: is_compression_capable = True return is_compression_capable def get_storage_group(self, array, storage_group_name): """"""Given a name, return storage group details. :param array: the array serial number :param storage_group_name: the name of the storage group :returns: storage group dict or None """""" return self.get_resource( array, SLOPROVISIONING, 'storagegroup', resource_name=storage_group_name) def get_storage_group_list(self, array, params=None): """"""Given a name, return storage group details. :param array: the array serial number :param params: dict of optional filters :returns: storage group dict or None """""" return self.get_resource( array, SLOPROVISIONING, 'storagegroup', params=params) def get_num_vols_in_sg(self, array, storage_group_name): """"""Get the number of volumes in a storage group. :param array: the array serial number :param storage_group_name: the storage group name :returns: num_vols -- int """""" num_vols = 0 storagegroup = self.get_storage_group(array, storage_group_name) try: num_vols = int(storagegroup['num_of_vols']) except (KeyError, TypeError): pass return num_vols def is_child_sg_in_parent_sg(self, array, child_name, parent_name): """"""Check if a child storage group is a member of a parent group. :param array: the array serial number :param child_name: the child sg name :param parent_name: the parent sg name :returns: bool """""" parent_sg = self.get_storage_group(array, parent_name) if parent_sg and parent_sg.get('child_storage_group'): child_sg_list = parent_sg['child_storage_group'] if child_name in child_sg_list: return True return False def add_child_sg_to_parent_sg( self, array, child_sg, parent_sg, extra_specs): """"""Add a storage group to a parent storage group. This method adds an existing storage group to another storage group, i.e. cascaded storage groups. :param array: the array serial number :param child_sg: the name of the child sg :param parent_sg: the name of the parent sg :param extra_specs: the extra specifications """""" payload = {""editStorageGroupActionParam"": { ""expandStorageGroupParam"": { ""addExistingStorageGroupParam"": { ""storageGroupId"": [child_sg]}}}} sc, job = self.modify_storage_group(array, parent_sg, payload) self.wait_for_job('Add child sg to parent sg', sc, job, extra_specs) def remove_child_sg_from_parent_sg( self, array, child_sg, parent_sg, extra_specs): """"""Remove a storage group from its parent storage group. This method removes a child storage group from its parent group. :param array: the array serial number :param child_sg: the name of the child sg :param parent_sg: the name of the parent sg :param extra_specs: the extra specifications """""" payload = {""editStorageGroupActionParam"": { ""removeStorageGroupParam"": { ""storageGroupId"": [child_sg], ""force"": 'true'}}} status_code, job = self.modify_storage_group( array, parent_sg, payload) self.wait_for_job( 'Remove child sg from parent sg', status_code, job, extra_specs) def _create_storagegroup(self, array, payload): """"""Create a storage group. :param array: the array serial number :param payload: the payload -- dict :returns: status_code -- int, message -- string, server response """""" return self.create_resource( array, SLOPROVISIONING, 'storagegroup', payload) def create_storage_group(self, array, storagegroup_name, srp, slo, workload, extra_specs, do_disable_compression=False): """"""Create the volume in the specified storage group. :param array: the array serial number :param storagegroup_name: the group name (String) :param srp: the SRP (String) :param slo: the SLO (String) :param workload: the workload (String) :param do_disable_compression: flag for disabling compression :param extra_specs: additional info :returns: storagegroup_name - string """""" srp_id = srp if slo else ""None"" payload = ({""srpId"": srp_id, ""storageGroupId"": storagegroup_name, ""emulation"": ""FBA""}) if slo: if self.is_next_gen_array(array): workload = 'NONE' slo_param = {""sloId"": slo, ""workloadSelection"": workload, ""volumeAttributes"": [{ ""volume_size"": ""0"", ""capacityUnit"": ""GB"", ""num_of_vols"": 0}]} if do_disable_compression: slo_param.update({""noCompression"": ""true""}) elif self.is_compression_capable(array): slo_param.update({""noCompression"": ""false""}) payload.update({""sloBasedStorageGroupParam"": [slo_param]}) status_code, job = self._create_storagegroup(array, payload) self.wait_for_job('Create storage group', status_code, job, extra_specs) return storagegroup_name def modify_storage_group(self, array, storagegroup, payload, version=U4V_VERSION): """"""Modify a storage group (PUT operation). :param version: the uv4 version :param array: the array serial number :param storagegroup: storage group name :param payload: the request payload :returns: status_code -- int, message -- string, server response """""" return self.modify_resource( array, SLOPROVISIONING, 'storagegroup', payload, version, resource_name=storagegroup) def modify_storage_array(self, array, payload): """"""Modify a storage array (PUT operation). :param array: the array serial number :param payload: the request payload :returns: status_code -- int, message -- string, server response """""" target_uri = '/%s/sloprovisioning/symmetrix/%s' % (U4V_VERSION, array) status_code, message = self.request(target_uri, PUT, request_object=payload) operation = 'modify %(res)s resource' % {'res': 'symmetrix'} self.check_status_code_success(operation, status_code, message) return status_code, message def create_volume_from_sg(self, array, volume_name, storagegroup_name, volume_size, extra_specs, rep_info=None): """"""Create a new volume in the given storage group. :param array: the array serial number :param volume_name: the volume name (String) :param storagegroup_name: the storage group name :param volume_size: volume size (String) :param extra_specs: the extra specifications :param rep_info: replication info dict if volume is replication enabled :returns: dict -- volume_dict - the volume dict :raises: VolumeBackendAPIException """""" payload = ( {""executionOption"": ""ASYNCHRONOUS"", ""editStorageGroupActionParam"": { ""expandStorageGroupParam"": { ""addVolumeParam"": { ""emulation"": ""FBA"", ""create_new_volumes"": ""False"", ""volumeAttributes"": [ { ""num_of_vols"": 1, ""volumeIdentifier"": { ""identifier_name"": volume_name, ""volumeIdentifierChoice"": ""identifier_name"" }, ""volume_size"": volume_size, ""capacityUnit"": ""GB""}]}}}}) if rep_info: payload = self.utils.update_payload_for_rdf_vol_create( payload, rep_info[utils.REMOTE_ARRAY], storagegroup_name) status_code, job = self.modify_storage_group( array, storagegroup_name, payload) LOG.debug(""Create Volume: %(volumename)s. Status code: %(sc)lu."", {'volumename': volume_name, 'sc': status_code}) task = self.wait_for_job('Create volume', status_code, job, extra_specs) # Find the newly created volume. device_id = None if rep_info: updated_device_list = self.get_volume_list( array, {'storageGroupId': storagegroup_name, 'rdf_group_number': rep_info['rdf_group_no']}) unique_devices = self.utils.get_unique_device_ids_from_lists( rep_info['initial_device_list'], updated_device_list) if 0 < len(unique_devices) < 2: device_id = unique_devices[0] self.rename_volume(array, device_id, volume_name) else: raise exception.VolumeBackendAPIException(_( ""There has been more than one volume created in the "" ""SRDF protected Storage Group since the current create "" ""volume process begun. Not possible to discern what "" ""volume has been created by PowerMax Cinder driver."")) # Find the newly created volume if not located as part of replication # OPT workaround if not device_id and task: for t in task: try: desc = t[""description""] if CREATE_VOL_STRING in desc: t_list = desc.split() device_id = t_list[(len(t_list) - 1)] device_id = device_id[1:-1] break elif POPULATE_SG_LIST in desc: regex_str = (r'Populating Storage Group\(s\) ' + r'with volumes : \[(.+)\]$') full_str = re.compile(regex_str) match = full_str.match(desc) device_id = match.group(1) if match else None if device_id: self.get_volume(array, device_id) except Exception as e: LOG.info(""Could not retrieve device id from job. "" ""Exception received was %(e)s. Attempting "" ""retrieval by volume_identifier."", {'e': e}) if not device_id: device_id = self.find_volume_device_id(array, volume_name) volume_dict = {utils.ARRAY: array, utils.DEVICE_ID: device_id} return volume_dict def add_storage_group_tag(self, array, storagegroup_name, tag_list, extra_specs): """"""Create a new tag(s) on a storage group :param array: the array serial number :param storagegroup_name: the storage group name :param tag_list: comma delimited list :param extra_specs: the extra specifications """""" payload = ( {""executionOption"": ""ASYNCHRONOUS"", ""editStorageGroupActionParam"": { ""tagManagementParam"": { ""addTagsParam"": { ""tag_name"": tag_list }}}}) status_code, job = self.modify_storage_group( array, storagegroup_name, payload) LOG.debug(""Add tag to storage group: %(sg_name)s. "" ""Status code: %(sc)lu."", {'sg_name': storagegroup_name, 'sc': status_code}) self.wait_for_job( 'Add tag to storage group', status_code, job, extra_specs) def add_storage_array_tags(self, array, tag_list, extra_specs): """"""Create a new tag(s) on a storage group :param array: the array serial number :param tag_list: comma delimited list :param extra_specs: the extra specifications """""" payload = ( {""executionOption"": ""ASYNCHRONOUS"", ""editSymmetrixActionParam"": { ""tagManagementParam"": { ""addTagsParam"": { ""tag_name"": tag_list }}}}) status_code, job = self.modify_storage_array( array, payload) LOG.debug(""Add tag to storage array: %(array)s. "" ""Status code: %(sc)lu."", {'array': array, 'sc': status_code}) self.wait_for_job( 'Add tag to storage array', status_code, job, extra_specs) def check_volume_device_id(self, array, device_id, volume_id, name_id=None): """"""Check if the identifiers match for a given volume. :param array: the array serial number :param device_id: the device id :param volume_id: cinder volume id :param name_id: name id - used in host_assisted migration, optional :returns: found_device_id """""" found_device_id = None if not device_id: return found_device_id element_name = self.utils.get_volume_element_name(volume_id) vol_details = self.get_volume(array, device_id) if vol_details: vol_identifier = vol_details.get('volume_identifier', None) LOG.debug('Element name = %(en)s, Vol identifier = %(vi)s, ' 'Device id = %(di)s', {'en': element_name, 'vi': vol_identifier, 'di': device_id}) if vol_identifier: if vol_identifier in element_name: found_device_id = device_id if vol_identifier != element_name: LOG.debug(""Device %(di)s is a legacy volume created "" ""using SMI-S."", {'di': device_id}) elif name_id: # This may be host-assisted migration case element_name = self.utils.get_volume_element_name(name_id) if vol_identifier == element_name: found_device_id = device_id return found_device_id def add_vol_to_sg(self, array, storagegroup_name, device_id, extra_specs, force=False): """"""Add a volume to a storage group. :param array: the array serial number :param storagegroup_name: storage group name :param device_id: the device id :param extra_specs: extra specifications :param force: add force argument to call """""" if not isinstance(device_id, list): device_id = [device_id] force_add = ""true"" if force else ""false"" payload = ({""executionOption"": ""ASYNCHRONOUS"", ""editStorageGroupActionParam"": { ""expandStorageGroupParam"": { ""addSpecificVolumeParam"": { ""volumeId"": device_id, ""remoteSymmSGInfoParam"": { ""force"": force_add}}}}}) status_code, job = self.modify_storage_group( array, storagegroup_name, payload) self.wait_for_job('Add volume to sg', status_code, job, extra_specs) @retry(retry_exc_tuple, interval=2, retries=3) def remove_vol_from_sg(self, array, storagegroup_name, device_id, extra_specs): """"""Remove a volume from a storage group. :param array: the array serial number :param storagegroup_name: storage group name :param device_id: the device id :param extra_specs: the extra specifications """""" force_vol_edit = ( ""true"" if utils.FORCE_VOL_EDIT in extra_specs else ""false"") if not isinstance(device_id, list): device_id = [device_id] payload = ({""executionOption"": ""ASYNCHRONOUS"", ""editStorageGroupActionParam"": { ""removeVolumeParam"": { ""volumeId"": device_id, ""remoteSymmSGInfoParam"": { ""force"": force_vol_edit}}}}) status_code, job = self.modify_storage_group( array, storagegroup_name, payload) self.wait_for_job('Remove vol from sg', status_code, job, extra_specs) def update_storagegroup_qos(self, array, storage_group_name, extra_specs): """"""Update the storagegroupinstance with qos details. If maxIOPS or maxMBPS is in extra_specs, then DistributionType can be modified in addition to maxIOPS or/and maxMBPS If maxIOPS or maxMBPS is NOT in extra_specs, we check to see if either is set in StorageGroup. If so, then DistributionType can be modified :param array: the array serial number :param storage_group_name: the storagegroup instance name :param extra_specs: extra specifications :returns: bool, True if updated, else False """""" return_value = False sg_details = self.get_storage_group(array, storage_group_name) sg_qos_details = None sg_maxiops = None sg_maxmbps = None sg_distribution_type = None property_dict = {} try: sg_qos_details = sg_details['hostIOLimit'] sg_maxiops = sg_qos_details['host_io_limit_io_sec'] sg_maxmbps = sg_qos_details['host_io_limit_mb_sec'] sg_distribution_type = sg_qos_details['dynamicDistribution'] except KeyError: LOG.debug(""Unable to get storage group QoS details."") if 'total_iops_sec' in extra_specs.get('qos'): property_dict = self.utils.validate_qos_input( 'total_iops_sec', sg_maxiops, extra_specs.get('qos'), property_dict) if 'total_bytes_sec' in extra_specs.get('qos'): property_dict = self.utils.validate_qos_input( 'total_bytes_sec', sg_maxmbps, extra_specs.get('qos'), property_dict) if 'DistributionType' in extra_specs.get('qos') and property_dict: property_dict = self.utils.validate_qos_distribution_type( sg_distribution_type, extra_specs.get('qos'), property_dict) if property_dict: payload = {""editStorageGroupActionParam"": { ""setHostIOLimitsParam"": property_dict}} status_code, message = ( self.modify_storage_group(array, storage_group_name, payload)) try: self.check_status_code_success('Add qos specs', status_code, message) return_value = True except Exception as e: LOG.error(""Error setting qos. Exception received was: "" ""%(e)s"", {'e': e}) return_value = False return return_value def set_storagegroup_srp( self, array, storagegroup_name, srp_name, extra_specs): """"""Modify a storage group's srp value. :param array: the array serial number :param storagegroup_name: the storage group name :param srp_name: the srp pool name :param extra_specs: the extra specifications """""" payload = {""editStorageGroupActionParam"": { ""editStorageGroupSRPParam"": {""srpId"": srp_name}}} status_code, job = self.modify_storage_group( array, storagegroup_name, payload) self.wait_for_job(""Set storage group srp"", status_code, job, extra_specs) def get_vmax_default_storage_group( self, array, srp, slo, workload, do_disable_compression=False, is_re=False, rep_mode=None): """"""Get the default storage group. :param array: the array serial number :param srp: the pool name :param slo: the SLO :param workload: the workload :param do_disable_compression: flag for disabling compression :param is_re: flag for replication :param rep_mode: flag to indicate replication mode :returns: the storage group dict (or None), the storage group name """""" if self.is_next_gen_array(array): workload = 'NONE' storagegroup_name = self.utils.get_default_storage_group_name( srp, slo, workload, do_disable_compression, is_re, rep_mode) storagegroup = self.get_storage_group(array, storagegroup_name) return storagegroup, storagegroup_name def delete_storage_group(self, array, storagegroup_name): """"""Delete a storage group. :param array: the array serial number :param storagegroup_name: storage group name """""" self.delete_resource( array, SLOPROVISIONING, 'storagegroup', storagegroup_name) LOG.debug(""Storage Group successfully deleted."") def move_volume_between_storage_groups( self, array, device_id, source_storagegroup_name, target_storagegroup_name, extra_specs, force=False): """"""Move a volume to a different storage group. :param array: the array serial number :param source_storagegroup_name: the originating storage group name :param target_storagegroup_name: the destination storage group name :param device_id: the device id :param extra_specs: extra specifications :param force: force flag (necessary on a detach) """""" force_flag = ""true"" if force else ""false"" payload = ({""executionOption"": ""ASYNCHRONOUS"", ""editStorageGroupActionParam"": { ""moveVolumeToStorageGroupParam"": { ""volumeId"": [device_id], ""storageGroupId"": target_storagegroup_name, ""force"": force_flag}}}) status_code, job = self.modify_storage_group( array, source_storagegroup_name, payload) self.wait_for_job('move volume between storage groups', status_code, job, extra_specs) def get_volume(self, array, device_id): """"""Get a PowerMax/VMAX volume from array. :param array: the array serial number :param device_id: the volume device id :returns: volume dict :raises: VolumeBackendAPIException """""" version = self.get_uni_version()[1] volume_dict = self.get_resource( array, SLOPROVISIONING, 'volume', resource_name=device_id, version=version) if not volume_dict: exception_message = (_(""Volume %(deviceID)s not found."") % {'deviceID': device_id}) LOG.error(exception_message) raise exception.VolumeBackendAPIException( message=exception_message) return volume_dict def _get_private_volume(self, array, device_id): """"""Get a more detailed list of attributes of a volume. :param array: the array serial number :param device_id: the volume device id :returns: volume dict :raises: VolumeBackendAPIException """""" try: wwn = (self.get_volume(array, device_id))['wwn'] params = {'wwn': wwn} volume_info = self.get_resource( array, SLOPROVISIONING, 'volume', params=params, private='/private') volume_dict = volume_info[0] except (KeyError, TypeError): exception_message = (_(""Volume %(deviceID)s not found."") % {'deviceID': device_id}) LOG.error(exception_message) raise exception.VolumeBackendAPIException( message=exception_message) return volume_dict def get_volume_list(self, array, params): """"""Get a filtered list of PowerMax/VMAX volumes from array. Filter parameters are required as the unfiltered volume list could be very large and could affect performance if called often. :param array: the array serial number :param params: filter parameters :returns: device_ids -- list """""" device_ids = [] volume_dict_list = self.get_resource( array, SLOPROVISIONING, 'volume', params=params) try: for vol_dict in volume_dict_list: device_id = vol_dict['volumeId'] device_ids.append(device_id) except (KeyError, TypeError): pass return device_ids def get_private_volume_list(self, array, params=None): """"""Retrieve list with volume details. :param array: the array serial number :param params: filter parameters :returns: list -- dicts with volume information """""" if isinstance(params, dict): params['expiration_time_mins'] = ITERATOR_EXPIRATION elif isinstance(params, str): params += '&expiration_time_mins=%(expire)s' % { 'expire': ITERATOR_EXPIRATION} else: params = {'expiration_time_mins': ITERATOR_EXPIRATION} return self.get_resource( array, SLOPROVISIONING, 'volume', params=params, private='/private') def _modify_volume(self, array, device_id, payload): """"""Modify a volume (PUT operation). :param array: the array serial number :param device_id: volume device id :param payload: the request payload """""" return self.modify_resource(array, SLOPROVISIONING, 'volume', payload, resource_name=device_id) def extend_volume(self, array, device_id, new_size, extra_specs, rdf_grp_no=None): """"""Extend a PowerMax/VMAX volume. :param array: the array serial number :param device_id: volume device id :param new_size: the new required size for the device :param extra_specs: the extra specifications :param rdf_grp_no: the RDG group number """""" extend_vol_payload = {'executionOption': 'ASYNCHRONOUS', 'editVolumeActionParam': { 'expandVolumeParam': { 'volumeAttribute': { 'volume_size': new_size, 'capacityUnit': 'GB'}}}} if rdf_grp_no: extend_vol_payload['editVolumeActionParam'][ 'expandVolumeParam'].update({'rdfGroupNumber': rdf_grp_no}) status_code, job = self._modify_volume( array, device_id, extend_vol_payload) LOG.debug(""Extend Device: %(device_id)s. Status code: %(sc)lu."", {'device_id': device_id, 'sc': status_code}) self.wait_for_job('Extending volume', status_code, job, extra_specs) def rename_volume(self, array, device_id, new_name): """"""Rename a volume. :param array: the array serial number :param device_id: the volume device id :param new_name: the new name for the volume, can be None """""" if new_name is not None: vol_identifier_dict = { ""identifier_name"": new_name, ""volumeIdentifierChoice"": ""identifier_name""} else: vol_identifier_dict = {""volumeIdentifierChoice"": ""none""} rename_vol_payload = {""editVolumeActionParam"": { ""modifyVolumeIdentifierParam"": { ""volumeIdentifier"": vol_identifier_dict}}} self._modify_volume(array, device_id, rename_vol_payload) def delete_volume(self, array, device_id): """"""Delete a volume. :param array: the array serial number :param device_id: volume device id """""" if ((self.ucode_major_level >= utils.UCODE_5978) and (self.ucode_minor_level > utils.UCODE_5978_ELMSR)): # Use Rapid TDEV Deallocation to delete after ELMSR try: # Rename volume, removing the OS-<cinderUUID> self.rename_volume(array, device_id, None) self.delete_resource(array, SLOPROVISIONING, ""volume"", device_id) except Exception as e: LOG.warning('Delete volume failed with %(e)s.', {'e': e}) raise else: # Pre-Foxtail, deallocation and delete are separate calls payload = {""editVolumeActionParam"": { ""freeVolumeParam"": {""free_volume"": 'true'}}} try: # Rename volume, removing the OS-<cinderUUID> self.rename_volume(array, device_id, None) self._modify_volume(array, device_id, payload) pass except Exception as e: LOG.warning('Deallocate volume failed with %(e)s.' 'Attempting delete.', {'e': e}) # Try to delete the volume if deallocate failed. self.delete_resource(array, SLOPROVISIONING, ""volume"", device_id) def find_mv_connections_for_vol(self, array, maskingview, device_id): """"""Find the host_lun_id for a volume in a masking view. :param array: the array serial number :param maskingview: the masking view name :param device_id: the device ID :returns: host_lun_id -- int """""" host_lun_id = None resource_name = ('%(maskingview)s/connections' % {'maskingview': maskingview}) params = {'volume_id': device_id} connection_info = self.get_resource( array, SLOPROVISIONING, 'maskingview', resource_name=resource_name, params=params) if not connection_info: LOG.error('Cannot retrieve masking view connection information ' 'for %(mv)s.', {'mv': maskingview}) else: try: host_lun_id = ( connection_info[ 'maskingViewConnection'][0]['host_lun_address']) host_lun_id = int(host_lun_id, 16) except Exception as e: LOG.error(""Unable to retrieve connection information "" ""for volume %(vol)s in masking view %(mv)s. "" ""Exception received: %(e)s."", {'vol': device_id, 'mv': maskingview, 'e': e}) return host_lun_id def get_storage_groups_from_volume(self, array, device_id): """"""Returns all the storage groups for a particular volume. :param array: the array serial number :param device_id: the volume device id :returns: storagegroup_list """""" sg_list = [] vol = self.get_volume(array, device_id) if vol and vol.get('storageGroupId'): sg_list = vol['storageGroupId'] num_storage_groups = len(sg_list) LOG.debug(""There are %(num)d storage groups associated "" ""with volume %(deviceId)s."", {'num': num_storage_groups, 'deviceId': device_id}) return sg_list def is_volume_in_storagegroup(self, array, device_id, storagegroup): """"""See if a volume is a member of the given storage group. :param array: the array serial number :param device_id: the device id :param storagegroup: the storage group name :returns: bool """""" is_vol_in_sg = False sg_list = self.get_storage_groups_from_volume(array, device_id) if storagegroup in sg_list: is_vol_in_sg = True return is_vol_in_sg def find_volume_device_id(self, array, volume_name): """"""Given a volume identifier, find the corresponding device_id. :param array: the array serial number :param volume_name: the volume name (OS-<UUID>) :returns: device_id """""" device_id = None params = {""volume_identifier"": volume_name} volume_list = self.get_volume_list(array, params) if not volume_list: LOG.debug(""Cannot find record for volume %(volumeId)s."", {'volumeId': volume_name}) else: device_id = volume_list[0] return device_id def find_volume_identifier(self, array, device_id): """"""Get the volume identifier of a PowerMax/VMAX volume. :param array: array serial number :param device_id: the device id :returns: the volume identifier -- string """""" vol = self.get_volume(array, device_id) return vol['volume_identifier'] def get_size_of_device_on_array(self, array, device_id): """"""Get the size of the volume from the array. :param array: the array serial number :param device_id: the volume device id :returns: size -- or None """""" cap = None try: vol = self.get_volume(array, device_id) cap = vol['cap_gb'] except Exception as e: LOG.error(""Error retrieving size of volume %(vol)s. "" ""Exception received was %(e)s."", {'vol': device_id, 'e': e}) return cap def get_portgroup(self, array, portgroup): """"""Get a portgroup from the array. :param array: array serial number :param portgroup: the portgroup name :returns: portgroup dict or None """""" return self.get_resource( array, SLOPROVISIONING, 'portgroup', resource_name=portgroup) def get_port_ids(self, array, portgroup): """"""Get a list of port identifiers from a port group. :param array: the array serial number :param portgroup: the name of the portgroup :returns: list of port ids, e.g. ['FA-3D:35', 'FA-4D:32'] """""" portlist = [] portgroup_info = self.get_portgroup(array, portgroup) if portgroup_info: port_key = portgroup_info[""symmetrixPortKey""] for key in port_key: port = ""%s:%s"" % (key['directorId'], key['portId']) portlist.append(port) return portlist def get_port(self, array, port_id): """"""Get director port details. :param array: the array serial number :param port_id: the port id :returns: port dict, or None """""" dir_id = port_id.split(':')[0] port_no = port_id.split(':')[1] resource_name = ('%(directorId)s/port/%(port_number)s' % {'directorId': dir_id, 'port_number': port_no}) return self.get_resource(array, SYSTEM, 'director', resource_name=resource_name) def get_iscsi_ip_address_and_iqn(self, array, port_id): """"""Get the IPv4Address from the director port. :param array: the array serial number :param port_id: the director port identifier :returns: (list of ip_addresses, iqn) """""" ip_addresses, iqn = None, None port_details = self.get_port(array, port_id) if port_details: ip_addresses = port_details['symmetrixPort']['ip_addresses'] iqn = port_details['symmetrixPort']['identifier'] return ip_addresses, iqn def get_ip_interface_physical_port(self, array_id, virtual_port, ip_address): """"""Get the physical port associated with a virtual port and IP address. :param array_id: the array serial number -- str :param virtual_port: the director & virtual port identifier -- str :param ip_address: the ip address associated with the port -- str :returns: physical director:port -- str """""" director_id = virtual_port.split(':')[0] params = {'ip_list': ip_address, 'iscsi_target': False} target_uri = self.build_uri( category=SYSTEM, resource_level='symmetrix', resource_level_id=array_id, resource_type='director', resource_type_id=director_id, resource='port') port_info = self.get_request( target_uri, 'port IP interface', params) port_key = port_info.get('symmetrixPortKey', []) if len(port_key) == 1: port_info = port_key[0] port_id = port_info.get('portId') dir_port = '%(d)s:%(p)s' % {'d': director_id, 'p': port_id} else: if len(port_key) == 0: msg = (_( ""Virtual port %(vp)s and IP address %(ip)s are not "" ""associated a physical director:port. Please check "" ""iSCSI configuration of backend array %(arr)s."" % { 'vp': virtual_port, 'ip': ip_address, 'arr': array_id} )) else: msg = (_( ""Virtual port %(vp)s and IP address %(ip)s are associated "" ""with more than one physical director:port. Please check "" ""iSCSI configuration of backend array %(arr)s."" % { 'vp': virtual_port, 'ip': ip_address, 'arr': array_id} )) LOG.error(msg) raise exception.VolumeBackendAPIException(message=msg) return dir_port def get_target_wwns(self, array, portgroup): """"""Get the director ports' wwns. :param array: the array serial number :param portgroup: portgroup :returns: target_wwns -- the list of target wwns for the masking view """""" target_wwns = [] port_ids = self.get_port_ids(array, portgroup) for port in port_ids: port_info = self.get_port(array, port) if port_info: wwn = port_info['symmetrixPort']['identifier'] target_wwns.append(wwn) else: LOG.error(""Error retrieving port %(port)s "" ""from portgroup %(portgroup)s."", {'port': port, 'portgroup': portgroup}) return target_wwns def get_initiator_group(self, array, initiator_group=None, params=None): """"""Retrieve initiator group details from the array. :param array: the array serial number :param initiator_group: the initaitor group name :param params: optional filter parameters :returns: initiator group dict, or None """""" return self.get_resource( array, SLOPROVISIONING, 'host', resource_name=initiator_group, params=params) def get_initiator(self, array, initiator_id): """"""Retrieve initiator details from the array. :param array: the array serial number :param initiator_id: the initiator id :returns: initiator dict, or None """""" return self.get_resource( array, SLOPROVISIONING, 'initiator', resource_name=initiator_id) def get_initiator_list(self, array, params=None): """"""Retrieve initiator list from the array. :param array: the array serial number :param params: dict of optional params :returns: list of initiators """""" init_dict = self.get_resource(array, SLOPROVISIONING, 'initiator', params=params) try: init_list = init_dict['initiatorId'] except (KeyError, TypeError): init_list = [] return init_list def get_initiator_group_from_initiator(self, array, initiator): """"""Given an initiator, get its corresponding initiator group, if any. :param array: the array serial number :param initiator: the initiator id :returns: found_init_group_name -- string """""" found_init_group_name = None init_details = self.get_initiator(array, initiator) if init_details: found_init_group_name = init_details.get('host') else: LOG.error(""Unable to retrieve initiator details for "" ""%(init)s."", {'init': initiator}) return found_init_group_name def create_initiator_group(self, array, init_group_name, init_list, extra_specs): """"""Create a new initiator group containing the given initiators. :param array: the array serial number :param init_group_name: the initiator group name :param init_list: the list of initiators :param extra_specs: extra specifications """""" new_ig_data = ({""executionOption"": ""ASYNCHRONOUS"", ""hostId"": init_group_name, ""initiatorId"": init_list}) sc, job = self.create_resource(array, SLOPROVISIONING, 'host', new_ig_data) self.wait_for_job('create initiator group', sc, job, extra_specs) def delete_initiator_group(self, array, initiatorgroup_name): """"""Delete an initiator group. :param array: the array serial number :param initiatorgroup_name: initiator group name """""" self.delete_resource( array, SLOPROVISIONING, 'host', initiatorgroup_name) LOG.debug(""Initiator Group successfully deleted."") def get_masking_view(self, array, masking_view_name): """"""Get details of a masking view. :param array: array serial number :param masking_view_name: the masking view name :returns: masking view dict """""" return self.get_resource( array, SLOPROVISIONING, 'maskingview', masking_view_name) def get_masking_view_list(self, array, params): """"""Get a list of masking views from the array. :param array: array serial number :param params: optional GET parameters :returns: masking view list """""" masking_view_list = [] masking_view_details = self.get_resource( array, SLOPROVISIONING, 'maskingview', params=params) try: masking_view_list = masking_view_details['maskingViewId'] except (KeyError, TypeError): pass return masking_view_list def get_masking_views_from_storage_group(self, array, storagegroup): """"""Return any masking views associated with a storage group. :param array: the array serial number :param storagegroup: the storage group name :returns: masking view list """""" maskingviewlist = [] storagegroup = self.get_storage_group(array, storagegroup) if storagegroup and storagegroup.get('maskingview'): maskingviewlist = storagegroup['maskingview'] return maskingviewlist def get_masking_views_by_initiator_group( self, array, initiatorgroup_name): """"""Given initiator group, retrieve the masking view instance name. Retrieve the list of masking view instances associated with the given initiator group. :param array: the array serial number :param initiatorgroup_name: the name of the initiator group :returns: list of masking view names """""" masking_view_list = [] ig_details = self.get_initiator_group( array, initiatorgroup_name) if ig_details: if ig_details.get('maskingview'): masking_view_list = ig_details['maskingview'] else: LOG.error(""Error retrieving initiator group %(ig_name)s"", {'ig_name': initiatorgroup_name}) return masking_view_list def get_element_from_masking_view( self, array, maskingview_name, portgroup=False, host=False, storagegroup=False): """"""Return the name of the specified element from a masking view. :param array: the array serial number :param maskingview_name: the masking view name :param portgroup: the port group name - optional :param host: the host name - optional :param storagegroup: the storage group name - optional :returns: name of the specified element -- string :raises: VolumeBackendAPIException """""" element = None masking_view_details = self.get_masking_view(array, maskingview_name) if masking_view_details: if portgroup: element = masking_view_details['portGroupId'] elif host: element = masking_view_details['hostId'] elif storagegroup: element = masking_view_details['storageGroupId'] else: exception_message = (_(""Error retrieving masking group."")) LOG.error(exception_message) raise exception.VolumeBackendAPIException( message=exception_message) return element def get_common_masking_views(self, array, portgroup_name, ig_name): """"""Get common masking views for a given portgroup and initiator group. :param array: the array serial number :param portgroup_name: the port group name :param ig_name: the initiator group name :returns: masking view list """""" params = {'port_group_name': portgroup_name, 'host_or_host_group_name': ig_name} masking_view_list = self.get_masking_view_list(array, params) if not masking_view_list: LOG.info(""No common masking views found for %(pg_name)s "" ""and %(ig_name)s."", {'pg_name': portgroup_name, 'ig_name': ig_name}) return masking_view_list def create_masking_view(self, array, maskingview_name, storagegroup_name, port_group_name, init_group_name, extra_specs): """"""Create a new masking view. :param array: the array serial number :param maskingview_name: the masking view name :param storagegroup_name: the storage group name :param port_group_name: the port group :param init_group_name: the initiator group :param extra_specs: extra specifications """""" payload = ({""executionOption"": ""ASYNCHRONOUS"", ""portGroupSelection"": { ""useExistingPortGroupParam"": { ""portGroupId"": port_group_name}}, ""maskingViewId"": maskingview_name, ""hostOrHostGroupSelection"": { ""useExistingHostParam"": { ""hostId"": init_group_name}}, ""storageGroupSelection"": { ""useExistingStorageGroupParam"": { ""storageGroupId"": storagegroup_name}}}) status_code, job = self.create_resource( array, SLOPROVISIONING, 'maskingview', payload) self.wait_for_job('Create masking view', status_code, job, extra_specs) def delete_masking_view(self, array, maskingview_name): """"""Delete a masking view. :param array: the array serial number :param maskingview_name: the masking view name """""" return self.delete_resource( array, SLOPROVISIONING, 'maskingview', maskingview_name) def get_replication_capabilities(self, array): """"""Check what replication features are licensed and enabled. Example return value for this method: .. code:: python {""symmetrixId"": ""000197800128"", ""snapVxCapable"": true, ""rdfCapable"": true} :param array :returns: capabilities dict for the given array """""" array_capabilities = None target_uri = (""/%s/replication/capabilities/symmetrix"" % U4V_VERSION) capabilities = self.get_request( target_uri, 'replication capabilities') if capabilities: symm_list = capabilities['symmetrixCapability'] for symm in symm_list: if symm['symmetrixId'] == array: array_capabilities = symm break return array_capabilities def is_snapvx_licensed(self, array): """"""Check if the snapVx feature is licensed and enabled. :param array: the array serial number :returns: True if licensed and enabled; False otherwise. """""" snap_capability = False capabilities = self.get_replication_capabilities(array) if capabilities: snap_capability = capabilities['snapVxCapable'] else: LOG.error(""Cannot access replication capabilities "" ""for array %(array)s"", {'array': array}) return snap_capability def create_volume_snap(self, array, snap_name, device_id, extra_specs, ttl=0): """"""Create a snapVx snapshot of a volume. :param array: the array serial number :param snap_name: the name of the snapshot :param device_id: the source device id :param extra_specs: the extra specifications :param ttl: time to live in hours, defaults to 0 """""" payload = {""deviceNameListSource"": [{""name"": device_id}], ""bothSides"": 'false', ""star"": 'false', ""force"": 'false'} if int(ttl) > 0: payload['timeToLive'] = ttl payload['timeInHours'] = 'true' resource_type = 'snapshot/%(snap)s' % {'snap': snap_name} status_code, job = self.create_resource( array, REPLICATION, resource_type, payload, private='/private') self.wait_for_job('Create volume snapVx', status_code, job, extra_specs) def modify_volume_snap(self, array, source_id, target_id, snap_name, extra_specs, snap_id=None, link=False, unlink=False, rename=False, new_snap_name=None, restore=False, list_volume_pairs=None, copy=False): """"""Modify a snapvx snapshot :param array: the array serial number :param source_id: the source device id :param target_id: the target device id :param snap_name: the snapshot name :param extra_specs: extra specifications :param snap_id: the unique snap id of the snapVX :param link: Flag to indicate action = Link :param unlink: Flag to indicate action = Unlink :param rename: Flag to indicate action = Rename :param new_snap_name: Optional new snapshot name :param restore: Flag to indicate action = Restore :param list_volume_pairs: list of volume pairs to link, optional :param copy: If copy mode should be used for SnapVX target links """""" action, operation, payload = '', '', {} copy = 'true' if copy else 'false' if link: action = ""Link"" elif unlink: action = ""Unlink"" elif rename: action = ""Rename"" elif restore: action = ""Restore"" if action == ""Restore"": operation = 'Restore snapVx snapshot' payload = {""deviceNameListSource"": [{""name"": source_id}], ""deviceNameListTarget"": [{""name"": source_id}], ""action"": action, ""star"": 'false', ""force"": 'false'} elif action in ('Link', 'Unlink'): operation = 'Modify snapVx relationship to target' src_list, tgt_list = [], [] if list_volume_pairs: for a, b in list_volume_pairs: src_list.append({'name': a}) tgt_list.append({'name': b}) else: src_list.append({'name': source_id}) tgt_list.append({'name': target_id}) payload = {""deviceNameListSource"": src_list, ""deviceNameListTarget"": tgt_list, ""copy"": copy, ""action"": action, ""star"": 'false', ""force"": 'false', ""exact"": 'false', ""remote"": 'false', ""symforce"": 'false'} elif action == ""Rename"": operation = 'Rename snapVx snapshot' payload = {""deviceNameListSource"": [{""name"": source_id}], ""deviceNameListTarget"": [{""name"": source_id}], ""action"": action, ""newsnapshotname"": new_snap_name} if self.is_snap_id: payload.update({""snap_id"": snap_id}) if snap_id else ( payload.update({""generation"": ""0""})) else: payload.update({""generation"": snap_id}) if snap_id else ( payload.update({""generation"": ""0""})) if action: status_code, job = self.modify_resource( array, REPLICATION, 'snapshot', payload, resource_name=snap_name, private='/private') self.wait_for_job(operation, status_code, job, extra_specs) def delete_volume_snap(self, array, snap_name, source_device_ids, snap_id=None, restored=False): """"""Delete the snapshot of a volume or volumes. :param array: the array serial number :param snap_name: the name of the snapshot :param source_device_ids: the source device ids :param snap_id: the unique snap id of the snapVX :param restored: Flag to indicate terminate restore session """""" device_list = [] if not isinstance(source_device_ids, list): source_device_ids = [source_device_ids] for dev in source_device_ids: device_list.append({""name"": dev}) payload = {""deviceNameListSource"": device_list} if self.is_snap_id: payload.update({""snap_id"": snap_id}) if snap_id else ( payload.update({""generation"": 0})) else: payload.update({""generation"": snap_id}) if snap_id else ( payload.update({""generation"": 0})) if restored: payload.update({""restore"": True}) LOG.debug(""The payload is %(payload)s."", {'payload': payload}) return self.delete_resource( array, REPLICATION, 'snapshot', snap_name, payload=payload, private='/private') def get_volume_snap_info(self, array, source_device_id): """"""Get snapVx information associated with a volume. :param array: the array serial number :param source_device_id: the source volume device ID :returns: message -- dict, or None """""" resource_name = (""%(device_id)s/snapshot"" % {'device_id': source_device_id}) return self.get_resource(array, REPLICATION, 'volume', resource_name, private='/private') def get_volume_snap(self, array, device_id, snap_name, snap_id): """"""Given a volume snap info, retrieve the snapVx object. :param array: the array serial number :param device_id: the source volume device id :param snap_name: the name of the snapshot :param snap_id: the unique snap id of the snapVX :returns: snapshot dict, or None """""" snapshot = None snap_info = self.get_volume_snap_info(array, device_id) if snap_info: if (snap_info.get('snapshotSrcs', None) and bool(snap_info['snapshotSrcs'])): for snap in snap_info['snapshotSrcs']: if snap['snapshotName'] == snap_name: if self.is_snap_id: if snap['snap_id'] == snap_id: snapshot = snap break else: if snap['generation'] == snap_id: snapshot = snap break return snapshot def get_volume_snaps(self, array, device_id, snap_name): """"""Given a volume snap info, retrieve the snapVx object. :param array: the array serial number :param device_id: the source volume device id :param snap_name: the name of the snapshot :returns: snapshot dict, or None """""" snapshots = list() snap_info = self.get_volume_snap_info(array, device_id) if snap_info: if (snap_info.get('snapshotSrcs', None) and bool(snap_info['snapshotSrcs'])): for snap in snap_info['snapshotSrcs']: if snap['snapshotName'] == snap_name: snapshots.append(snap) return snapshots def get_volume_snapshot_list(self, array, source_device_id): """"""Get a list of snapshot details for a particular volume. :param array: the array serial number :param source_device_id: the osurce device id :returns: snapshot list or None """""" snapshot_list = [] snap_info = self.get_volume_snap_info(array, source_device_id) if snap_info: if (snap_info.get('snapshotSrcs', None) and bool(snap_info['snapshotSrcs'])): snapshot_list = snap_info['snapshotSrcs'] return snapshot_list def is_vol_in_rep_session(self, array, device_id): """"""Check if a volume is in a replication session. :param array: the array serial number :param device_id: the device id :returns: snapvx_tgt -- bool, snapvx_src -- bool, rdf_grp -- list or None """""" snapvx_src = False snapvx_tgt = False rdf_grp = None volume_details = self.get_volume(array, device_id) if volume_details: if volume_details.get('snapvx_target'): snapvx_tgt = volume_details['snapvx_target'] if volume_details.get('snapvx_source'): snapvx_src = volume_details['snapvx_source'] if volume_details.get('rdfGroupId'): rdf_grp = volume_details['rdfGroupId'] return snapvx_tgt, snapvx_src, rdf_grp def is_sync_complete(self, array, source_device_id, target_device_id, snap_name, extra_specs, snap_id): """"""Check if a sync session is complete. :param array: the array serial number :param source_device_id: source device id :param target_device_id: target device id :param snap_name: snapshot name :param extra_specs: extra specifications :param snap_id: the unique snap id of the SnapVX :returns: bool """""" def _wait_for_sync(): """"""Called at an interval until the synchronization is finished. :raises: loopingcall.LoopingCallDone :raises: VolumeBackendAPIException """""" retries = kwargs['retries'] try: kwargs['retries'] = retries + 1 if not kwargs['wait_for_sync_called']: if self._is_sync_complete( array, source_device_id, snap_name, target_device_id, snap_id): kwargs['wait_for_sync_called'] = True except Exception: exception_message = (_(""Issue encountered waiting for "" ""synchronization."")) LOG.error(exception_message) raise exception.VolumeBackendAPIException( message=exception_message) if kwargs['retries'] > int(extra_specs[utils.RETRIES]): LOG.error(""_wait_for_sync failed after %(retries)d "" ""tries."", {'retries': retries}) raise loopingcall.LoopingCallDone( retvalue=int(extra_specs[utils.RETRIES])) if kwargs['wait_for_sync_called']: raise loopingcall.LoopingCallDone() kwargs = {'retries': 0, 'wait_for_sync_called': False} timer = loopingcall.FixedIntervalLoopingCall(_wait_for_sync) rc = timer.start(interval=int(extra_specs[utils.INTERVAL])).wait() return rc def _is_sync_complete(self, array, source_device_id, snap_name, target_device_id, snap_id): """"""Helper function to check if snapVx sync session is complete. :param array: the array serial number :param source_device_id: source device id :param snap_name: the snapshot name :param target_device_id: the target device id :param snap_id: the unique snap id of the SnapVX :returns: defined -- bool """""" defined = True session = self.get_sync_session( array, source_device_id, snap_name, target_device_id, snap_id) if session: defined = session['defined'] return defined def get_sync_session(self, array, source_device_id, snap_name, target_device_id, snap_id): """"""Get a particular sync session. :param array: the array serial number :param source_device_id: source device id :param snap_name: the snapshot name :param target_device_id: the target device id :param snap_id: the unique snapid of the snapshot :returns: sync session -- dict, or None """""" session = None linked_device_list = self.get_snap_linked_device_list( array, source_device_id, snap_name, snap_id) for target in linked_device_list: if target_device_id == target['targetDevice']: session = target break return session def _find_snap_vx_source_sessions(self, array, source_device_id): """"""Find all snap sessions for a given source volume. :param array: the array serial number :param source_device_id: the source device id :returns: list of snapshot dicts """""" snap_dict_list = [] snapshots = self.get_volume_snapshot_list(array, source_device_id) for snapshot in snapshots: try: snap_id = snapshot['snap_id'] if self.is_snap_id else ( snapshot['generation']) if bool(snapshot['linkedDevices']): link_info = {'linked_vols': snapshot['linkedDevices'], 'snap_name': snapshot['snapshotName'], 'snapid': snap_id} snap_dict_list.append(link_info) except KeyError: pass return snap_dict_list def get_snap_linked_device_list(self, array, source_device_id, snap_name, snap_id, state=None): """"""Get the list of linked devices for a particular snapVx snapshot. :param array: the array serial number :param source_device_id: source device id :param snap_name: the snapshot name :param snap_id: the unique snapid of the snapshot :param state: filter for state of the link :returns: linked_device_list or empty list """""" snap_dict_list = None linked_device_list = [] snap_dict_list = self._get_snap_linked_device_dict_list( array, source_device_id, snap_name, state=state) for snap_dict in snap_dict_list: if snap_id == snap_dict['snapid']: linked_device_list = snap_dict['linked_vols'] break return linked_device_list def _get_snap_linked_device_dict_list( self, array, source_device_id, snap_name, state=None): """"""Get list of linked devices for all snap ids for a snapVx snapshot :param array: the array serial number :param source_device_id: source device id :param snap_name: the snapshot name :param state: filter for state of the link :returns: list of dict of snapids with linked devices """""" snap_dict_list = [] snap_list = self._find_snap_vx_source_sessions( array, source_device_id) for snap in snap_list: if snap['snap_name'] == snap_name: for linked_vol in snap['linked_vols']: snap_state = linked_vol.get('state', None) # If state is None or # both snap_state and state are not None and are equal if not state or (snap_state and state and snap_state == state): snap_id = snap['snapid'] found = False for snap_dict in snap_dict_list: if snap_id == snap_dict['snapid']: snap_dict['linked_vols'].append( linked_vol) found = True break if not found: snap_dict_list.append( {'snapid': snap_id, 'linked_vols': [linked_vol]}) return snap_dict_list def find_snap_vx_sessions(self, array, device_id, tgt_only=False): """"""Find all snapVX sessions for a device (source and target). :param array: the array serial number :param device_id: the device id :param tgt_only: Flag - return only sessions where device is target :returns: list of snapshot dicts """""" snap_tgt_dict, snap_src_dict_list = dict(), list() s_in = self.get_volume_snap_info(array, device_id) snap_src = ( s_in['snapshotSrcs'] if s_in.get('snapshotSrcs') else list()) snap_tgt = ( s_in['snapshotLnks'][0] if s_in.get('snapshotLnks') else dict()) if snap_src and not tgt_only: for session in snap_src: snap_src_dict = dict() snap_src_dict['source_vol_id'] = device_id snap_src_dict['snapid'] = session.get( 'snap_id') if self.is_snap_id else session.get( 'generation') snap_src_dict['snap_name'] = session.get('snapshotName') snap_src_dict['expired'] = session.get('expired') if session.get('linkedDevices'): snap_src_link = session.get('linkedDevices')[0] snap_src_dict['target_vol_id'] = snap_src_link.get( 'targetDevice') snap_src_dict['copy_mode'] = snap_src_link.get('copy') snap_src_dict['state'] = snap_src_link.get('state') snap_src_dict_list.append(snap_src_dict) if snap_tgt: snap_tgt_dict['source_vol_id'] = snap_tgt.get('linkSourceName') snap_tgt_dict['target_vol_id'] = device_id snap_tgt_dict['state'] = snap_tgt.get('state') snap_tgt_dict['copy_mode'] = snap_tgt.get('copy') vol_info = self._get_private_volume(array, device_id) if vol_info.get('timeFinderInfo'): vol_tf_sessions = vol_info.get( 'timeFinderInfo').get('snapVXSession') if vol_tf_sessions: for session in vol_tf_sessions: if session.get('tgtSrcSnapshotGenInfo'): snap_tgt_link = session.get( 'tgtSrcSnapshotGenInfo') snap_tgt_dict['snap_name'] = snap_tgt_link.get( 'snapshotName') snap_tgt_dict['expired'] = snap_tgt_link.get( 'expired') snap_tgt_dict['snapid'] = snap_tgt_link.get( 'snapid') if self.is_snap_id else ( snap_tgt_link.get('generation')) return snap_src_dict_list, snap_tgt_dict def get_rdf_group(self, array, rdf_number): """"""Get specific rdf group details. :param array: the array serial number :param rdf_number: the rdf number """""" return self.get_resource(array, REPLICATION, 'rdf_group', rdf_number) def get_storage_group_rdf_group_state(self, array, storage_group, rdf_group_no): """"""Get the RDF group state from a replication enabled Storage Group. :param array: the array serial number :param storage_group: the storage group name :param rdf_group_no: the RDF group number :returns: storage group RDF group state """""" resource = ('storagegroup/%(sg)s/rdf_group/%(rdfg)s' % { 'sg': storage_group, 'rdfg': rdf_group_no}) rdf_group = self.get_resource(array, REPLICATION, resource) return rdf_group.get('states', list()) if rdf_group else dict() def get_storage_group_rdf_groups(self, array, storage_group): """"""Get a list of rdf group numbers used by a storage group. :param array: the array serial number -- str :param storage_group: the storage group name to check -- str :return: RDFGs associated with the storage group -- dict """""" resource = ('storagegroup/%(storage_group)s/rdf_group' % { 'storage_group': storage_group}) storage_group_details = self.get_resource(array, REPLICATION, resource) return storage_group_details['rdfgs'] def get_rdf_group_list(self, array): """"""Get rdf group list from array. :param array: the array serial number """""" return self.get_resource(array, REPLICATION, 'rdf_group') def get_rdf_group_volume_list(self, array, rdf_group_no): """"""Get a list of all volumes in an RDFG. :param array: the array serial number -- str :param rdf_group_no: the RDF group number -- str :return: RDFG volume list -- list """""" resource = ('rdf_group/%(rdf_group)s/volume' % { 'rdf_group': rdf_group_no}) rdf_group_volumes = self.get_resource(array, REPLICATION, resource) return rdf_group_volumes['name'] def get_rdf_group_volume(self, array, src_device_id): """"""Get the RDF details for a volume. :param array: the array serial number :param src_device_id: the source device id :returns: rdf_session """""" rdf_session = None volume = self._get_private_volume(array, src_device_id) try: rdf_session = volume['rdfInfo']['RDFSession'][0] except (KeyError, TypeError, IndexError): LOG.warning(""Cannot locate source RDF volume %s"", src_device_id) return rdf_session def get_rdf_pair_volume(self, array, rdf_group_no, device_id): """"""Get information on an RDF pair from the source volume. :param array: the array serial number :param rdf_group_no: the RDF group number :param device_id: the source device ID :returns: RDF pair information -- dict """""" resource = ('rdf_group/%(rdf_group)s/volume/%(device)s' % { 'rdf_group': rdf_group_no, 'device': device_id}) return self.get_resource(array, REPLICATION, resource) def are_vols_rdf_paired(self, array, remote_array, device_id, target_device): """"""Check if a pair of volumes are RDF paired. :param array: the array serial number :param remote_array: the remote array serial number :param device_id: the device id :param target_device: the target device id :returns: paired -- bool, local_vol_state, rdf_pair_state """""" paired, local_vol_state, rdf_pair_state = False, '', '' rdf_session = self.get_rdf_group_volume(array, device_id) if rdf_session: remote_volume = rdf_session['remoteDeviceID'] remote_symm = rdf_session['remoteSymmetrixID'] if (remote_volume == target_device and remote_array == remote_symm): paired = True local_vol_state = rdf_session['SRDFStatus'] rdf_pair_state = rdf_session['pairState'] else: LOG.warning(""Cannot locate RDF session for volume %s"", device_id) return paired, local_vol_state, rdf_pair_state def wait_for_rdf_group_sync(self, array, storage_group, rdf_group_no, rep_extra_specs): """"""Wait for an RDF group to reach 'Synchronised' state. :param array: the array serial number :param storage_group: the storage group name :param rdf_group_no: the RDF group number :param rep_extra_specs: replication extra specifications :raises: exception.VolumeBackendAPIException """""" def _wait_for_synced_state(): try: kwargs['retries'] -= 1 if not kwargs['synced']: rdf_group_state = self.get_storage_group_rdf_group_state( array, storage_group, rdf_group_no) if rdf_group_state: kwargs['state'] = rdf_group_state[0] if kwargs['state'].lower() in utils.RDF_SYNCED_STATES: kwargs['synced'] = True kwargs['rc'] = 0 except Exception as e_msg: ex_msg = _(""Issue encountered waiting for job: %(e)s"" % { 'e': e_msg}) LOG.error(ex_msg) raise exception.VolumeBackendAPIException(message=ex_msg) if kwargs['retries'] == 0: ex_msg = _(""Wait for RDF Sync State failed after %(r)d "" ""tries."" % {'r': rep_extra_specs['sync_retries']}) LOG.error(ex_msg) raise exception.VolumeBackendAPIException(message=ex_msg) if kwargs['synced']: raise loopingcall.LoopingCallDone() kwargs = {'retries': rep_extra_specs['sync_retries'], 'synced': False, 'rc': 0, 'state': 'syncinprog'} timer = loopingcall.FixedIntervalLoopingCall(_wait_for_synced_state) timer.start(interval=rep_extra_specs['sync_interval']).wait() LOG.debug(""Return code is: %(rc)lu. State is %(state)s"", {'rc': kwargs['rc'], 'state': kwargs['state']}) def wait_for_rdf_pair_sync(self, array, rdf_group_no, device_id, rep_extra_specs): """"""Wait for an RDF device pair to reach 'Synchronised' state. :param array: the array serial number :param rdf_group_no: the RDF group number :param device_id: the source device ID :param rep_extra_specs: replication extra specifications :raises: exception.VolumeBackendAPIException """""" def _wait_for_synced_state(): try: kwargs['retries'] -= 1 if not kwargs['synced']: rdf_pair = self.get_rdf_pair_volume(array, rdf_group_no, device_id) kwargs['state'] = rdf_pair['rdfpairState'] if kwargs['state'].lower() in utils.RDF_SYNCED_STATES: kwargs['synced'] = True kwargs['rc'] = 0 except Exception as e_msg: ex_msg = _(""Issue encountered waiting for job: %(e)s"" % { 'e': e_msg}) LOG.error(ex_msg) raise exception.VolumeBackendAPIException(message=ex_msg) if kwargs['retries'] == 0: ex_msg = _(""Wait for RDF Sync State failed after %(r)d "" ""tries."" % {'r': rep_extra_specs['sync_retries']}) LOG.error(ex_msg) raise exception.VolumeBackendAPIException(message=ex_msg) if kwargs['synced']: raise loopingcall.LoopingCallDone() kwargs = {'retries': rep_extra_specs['sync_retries'], 'synced': False, 'rc': 0, 'state': 'syncinprog'} timer = loopingcall.FixedIntervalLoopingCall(_wait_for_synced_state) timer.start(interval=rep_extra_specs['sync_interval']).wait() LOG.debug(""Return code is: %(rc)lu. State is %(state)s"", {'rc': kwargs['rc'], 'state': kwargs['state']}) def rdf_resume_with_retries(self, array, rep_extra_specs): """"""Resume RDF on a RDF group with retry operator included. The retry operator is required here because on occassion when we are waiting on a snap copy session to complete we have no way of determining if the copy is complete, operation is retried until either the copy completes or the max interval/retries has been met. :param array: the array serial number :param rep_extra_specs: replication extra specifications :raises: exception.VolumeBackendAPIException """""" def wait_for_copy_complete(): kwargs['retries'] -= 1 if not kwargs['copied']: try: self.srdf_resume_replication( array, rep_extra_specs['sg_name'], rep_extra_specs['rdf_group_no'], rep_extra_specs, async_call=False) kwargs['copied'] = True kwargs['state'] = 'copy_complete' kwargs['rc'] = 0 raise loopingcall.LoopingCallDone() except exception.VolumeBackendAPIException: LOG.debug('Snapshot copy process still ongoing, Cinder ' 'will retry again in %(interval)s seconds. ' 'There are %(retries)s remaining.', { 'interval': rep_extra_specs['sync_interval'], 'retries': kwargs['retries']}) if kwargs['retries'] == 0: ex_msg = _(""Wait for snapshot copy complete failed after "" ""%(r)d tries."" % { 'r': rep_extra_specs['sync_retries']}) LOG.error(ex_msg) raise exception.VolumeBackendAPIException(message=ex_msg) kwargs = {'retries': rep_extra_specs['sync_retries'], 'copied': False, 'rc': 0, 'state': 'copy_in_progress'} timer = loopingcall.FixedIntervalLoopingCall(wait_for_copy_complete) timer.start(interval=rep_extra_specs['sync_interval']).wait() LOG.debug(""Return code: %(rc)lu. State: %(state)s"", {'rc': kwargs['rc'], 'state': kwargs['state']}) def get_rdf_group_number(self, array, rdf_group_label): """"""Given an rdf_group_label, return the associated group number. :param array: the array serial number :param rdf_group_label: the group label :returns: rdf_group_number """""" number = None rdf_list = self.get_rdf_group_list(array) if rdf_list and rdf_list.get('rdfGroupID'): number_list = [rdf['rdfgNumber'] for rdf in rdf_list['rdfGroupID'] if rdf['label'] == rdf_group_label] number = number_list[0] if len(number_list) > 0 else None if number: rdf_group = self.get_rdf_group(array, number) if not rdf_group: number = None return number def _get_async_payload_info(self, array, rdf_group_no): """"""Get the payload details for an async create pair. :param array: the array serial number :param rdf_group_no: the rdf group number :returns: payload_update """""" num_vols, payload_update = 0, {} rdfg_details = self.get_rdf_group(array, rdf_group_no) if rdfg_details is not None and rdfg_details.get('numDevices'): num_vols = int(rdfg_details['numDevices']) if num_vols > 0: payload_update = {'exempt': 'true'} return payload_update def get_metro_payload_info(self, array, payload, rdf_group_no, extra_specs, next_gen): """"""Get the payload details for a metro active create pair. :param array: the array serial number :param payload: the payload :param rdf_group_no: the rdf group number :param extra_specs: the replication configuration :param next_gen: if the array is next gen uCode :returns: updated payload """""" num_vols = 0 payload[""rdfMode""] = ""Active"" payload['rdfType'] = ""RDF1"" rdfg_details = self.get_rdf_group(array, rdf_group_no) if rdfg_details is not None and rdfg_details.get('numDevices'): num_vols = int(rdfg_details['numDevices']) if num_vols == 0: # First volume - set bias if required if extra_specs.get(utils.METROBIAS): payload.update({""metroBias"": ""true""}) else: if next_gen: payload[""exempt""] = ""true"" if payload.get('establish'): payload.pop('establish') return payload def srdf_protect_storage_group( self, array_id, remote_array_id, rdf_group_no, replication_mode, sg_name, service_level, extra_specs, target_sg=None): """"""SRDF protect a storage group. :param array_id: local array serial number :param remote_array_id: remote array serial number :param rdf_group_no: RDF group number :param replication_mode: replication mode :param sg_name: storage group name :param service_level: service level :param extra_specs: extra specifications :param target_sg: target storage group -- optional """""" remote_sg = target_sg if target_sg else sg_name payload = { ""executionOption"": ""ASYNCHRONOUS"", ""replicationMode"": replication_mode, ""remoteSLO"": service_level, ""remoteSymmId"": remote_array_id, ""rdfgNumber"": rdf_group_no, ""remoteStorageGroupName"": remote_sg, ""establish"": ""true""} # Metro specific configuration if replication_mode == utils.REP_METRO: bias = ""true"" if extra_specs.get(utils.METROBIAS) else ""false"" payload.update({ ""replicationMode"": ""Active"", ""metroBias"": bias}) LOG.debug('SRDF Protect Payload: %(pay)s', {'pay': payload}) resource = 'storagegroup/%(sg_name)s/rdf_group' % {'sg_name': sg_name} status_code, job = self.create_resource(array_id, REPLICATION, resource, payload) self.wait_for_job('SRDF Protect Storage Group', status_code, job, extra_specs) def srdf_modify_group(self, array, rdf_group_no, storage_group, payload, extra_specs, msg, async_call=True): """"""Modify RDF enabled storage group replication options. :param array: array serial number :param rdf_group_no: RDF group number :param storage_group: storage group name :param payload: REST request payload dict :param extra_specs: extra specifications :param msg: message to use for logs when waiting on job to complete :param async_call: if the REST call should be run, this only comes into effect when trying to resume replication and interval/retries are a factor. """""" resource = ('storagegroup/%(sg_name)s/rdf_group/%(rdf_group_no)s' % { 'sg_name': storage_group, 'rdf_group_no': rdf_group_no}) if async_call: payload.update({""executionOption"": ""ASYNCHRONOUS""}) status_code, job = self.modify_resource(array, REPLICATION, resource, payload) self.wait_for_job(msg, status_code, job, extra_specs) else: self.modify_resource(array, REPLICATION, resource, payload) def srdf_suspend_replication(self, array_id, storage_group, rdf_group_no, rep_extra_specs): """"""Suspend replication on a RDF group. :param array_id: array serial number :param storage_group: storage group name :param rdf_group_no: RDF group number :param rep_extra_specs: replication extra specifications """""" group_state = self.get_storage_group_rdf_group_state( array_id, storage_group, rdf_group_no) if group_state: group_state = [x.lower() for x in group_state] if len(group_state) == 1 and utils.RDF_SUSPENDED_STATE in group_state: LOG.info('SRDF Group %(grp_num)s is already in a suspended state', {'grp_num': rdf_group_no}) else: self.srdf_modify_group( array_id, rdf_group_no, storage_group, {""suspend"": {""force"": ""true""}, ""action"": ""Suspend""}, rep_extra_specs, 'Suspend SRDF Group Replication') def srdf_resume_replication(self, array_id, storage_group, rdf_group_no, rep_extra_specs, async_call=True): """"""Resume replication on a RDF group. :param array_id: array serial number :param storage_group: storage group name :param rdf_group_no: RDF group number :param rep_extra_specs: replication extra specifications :param async_call: if the REST call should be run, this only comes into effect when trying to resume replication and interval/retries are a factor. """""" if self.get_storage_group(array_id, storage_group): group_state = self.get_storage_group_rdf_group_state( array_id, storage_group, rdf_group_no) if group_state: group_state = [x.lower() for x in group_state] if utils.RDF_SUSPENDED_STATE in group_state: payload = {""action"": ""Resume""} if rep_extra_specs['rep_mode'] == utils.REP_METRO: payload = {""action"": ""Establish""} if rep_extra_specs.get(utils.METROBIAS): payload.update({""establish"": {""metroBias"": ""true""}}) self.srdf_modify_group( array_id, rdf_group_no, storage_group, payload, rep_extra_specs, 'Resume SRDF Group Replication', async_call) else: LOG.debug('SRDF Group %(grp_num)s is already in a resumed ' 'state.', {'grp_num': rdf_group_no}) else: LOG.debug('Storage Group %(sg)s not present on array ' '%(array)s, no resume required.', { 'sg': storage_group, 'array': array_id}) def srdf_establish_replication(self, array_id, storage_group, rdf_group_no, rep_extra_specs): """"""Establish replication on a RDF group. :param array_id: array serial number :param storage_group: storage group name :param rdf_group_no: RDF group number :param rep_extra_specs: replication extra specifications """""" group_state = self.get_storage_group_rdf_group_state( array_id, storage_group, rdf_group_no) if utils.RDF_SUSPENDED_STATE not in group_state: LOG.info('Suspending SRDF Group %(grp_num)s', { 'grp_num': rdf_group_no}) self.srdf_modify_group( array_id, rdf_group_no, storage_group, {""action"": ""Suspend""}, rep_extra_specs, 'Suspend SRDF Group Replication') wait_msg = 'Incremental Establish SRDF Group Replication' LOG.info('Initiating incremental establish on SRDF Group %(grp_num)s', {'grp_num': rdf_group_no}) self.srdf_modify_group( array_id, rdf_group_no, storage_group, {""action"": ""Establish""}, rep_extra_specs, wait_msg) def srdf_failover_group(self, array_id, storage_group, rdf_group_no, rep_extra_specs): """"""Failover a RDFG/SG volume group to replication target. :param array_id: array serial number :param storage_group: storage group name :param rdf_group_no: RDF group number :param rep_extra_specs: replication extra specifications """""" self.srdf_modify_group( array_id, rdf_group_no, storage_group, {""action"": ""Failover""}, rep_extra_specs, 'Failing over SRDF group replication') def srdf_failback_group(self, array_id, storage_group, rdf_group_no, rep_extra_specs): """"""Failback a RDFG/SG volume group from replication target. :param array_id: :param storage_group: :param rdf_group_no: :param rep_extra_specs: """""" self.srdf_modify_group( array_id, rdf_group_no, storage_group, {""action"": ""Failback""}, rep_extra_specs, 'Failing back SRDF group replication') def srdf_remove_device_pair_from_storage_group( self, array_id, storage_group, remote_array_id, device_id, rep_extra_specs): """"""Remove a volume from local and remote storage groups simultaneously. :param array_id: local array serial number :param storage_group: storage group name :param remote_array_id: remote array serial number :param device_id: source device id :param rep_extra_specs: replication extra specifications """""" payload = { ""editStorageGroupActionParam"": { ""removeVolumeParam"": { ""volumeId"": [device_id], ""remoteSymmSGInfoParam"": { ""remote_symmetrix_1_id"": remote_array_id, ""remote_symmetrix_1_sgs"": [storage_group]}}}} status_code, job = self.modify_storage_group(array_id, storage_group, payload) self.wait_for_job('SRDF Group remove device pair', status_code, job, rep_extra_specs) def srdf_delete_device_pair(self, array, rdf_group_no, local_device_id): """"""Delete a RDF device pair. :param array: array serial number :param rdf_group_no: RDF group number :param local_device_id: local device id """""" resource = ('%(rdfg)s/volume/%(dev)s' % { 'rdfg': rdf_group_no, 'dev': local_device_id}) self.delete_resource(array, REPLICATION, 'rdf_group', resource) LOG.debug(""Device Pair successfully deleted."") def srdf_create_device_pair(self, array, rdf_group_no, mode, device_id, rep_extra_specs, next_gen): """"""Create a RDF device pair in an existing RDF group. :param array: array serial number :param rdf_group_no: RDF group number :param mode: replication mode :param device_id: local device ID :param rep_extra_specs: replication extra specifications :param next_gen: if the array is next gen uCode :returns: replication session info -- dict """""" payload = { ""executionOption"": ""ASYNCHRONOUS"", ""rdfMode"": mode, ""localDeviceListCriteriaParam"": {""localDeviceList"": [device_id]}, ""rdfType"": ""RDF1""} if mode == utils.REP_SYNC: payload.update({""establish"": ""true""}) elif mode == utils.REP_ASYNC: payload.update({""invalidateR2"": ""true"", ""exempt"": ""true""}) elif mode.lower() in [utils.REP_METRO.lower(), utils.RDF_ACTIVE.lower()]: payload = self.get_metro_payload_info( array, payload, rdf_group_no, rep_extra_specs, next_gen) LOG.debug('Create Pair Payload: %(pay)s', {'pay': payload}) resource = 'rdf_group/%(rdfg)s/volume' % {'rdfg': rdf_group_no} status_code, job = self.create_resource( array, REPLICATION, resource, payload) self.wait_for_job('SRDF Group remove device pair', status_code, job, rep_extra_specs) session_info = self.get_rdf_pair_volume(array, rdf_group_no, device_id) r2_device_id = session_info['remoteVolumeName'] return {'array': session_info['localSymmetrixId'], 'remote_array': session_info['remoteSymmetrixId'], 'src_device': device_id, 'tgt_device': r2_device_id, 'session_info': session_info} def get_storage_group_rep(self, array, storage_group_name): """"""Given a name, return storage group details wrt replication. :param array: the array serial number :param storage_group_name: the name of the storage group :returns: storage group dict or None """""" return self.get_resource( array, REPLICATION, 'storagegroup', resource_name=storage_group_name) def get_volumes_in_storage_group(self, array, storagegroup_name): """"""Given a volume identifier, find the corresponding device_id. :param array: the array serial number :param storagegroup_name: the storage group name :returns: volume_list """""" params = {""storageGroupId"": storagegroup_name} volume_list = self.get_volume_list(array, params) if not volume_list: LOG.debug(""Cannot find record for storage group %(storageGrpId)s"", {'storageGrpId': storagegroup_name}) return volume_list def create_storagegroup_snap(self, array, source_group, snap_name, extra_specs): """"""Create a snapVx snapshot of a storage group. :param array: the array serial number :param source_group: the source group name :param snap_name: the name of the snapshot :param extra_specs: the extra specifications """""" payload = {""snapshotName"": snap_name} resource_type = ('storagegroup/%(sg_name)s/snapshot' % {'sg_name': source_group}) status_code, job = self.create_resource( array, REPLICATION, resource_type, payload) self.wait_for_job('Create storage group snapVx', status_code, job, extra_specs) def delete_storagegroup_snap(self, array, source_group, snap_name, snap_id): """"""Delete a snapVx snapshot of a storage group. :param array: the array serial number :param source_group: the source group name :param snap_name: the name of the snapshot :param snap_id: the unique snap id of the SnapVX """""" postfix_uri = ""/snapid/%s"" % snap_id if self.is_snap_id else ( ""/generation/%s"" % snap_id) resource_name = (""%(sg_name)s/snapshot/%(snap_name)s"" ""%(postfix_uri)s"" % {'sg_name': source_group, 'snap_name': snap_name, 'postfix_uri': postfix_uri}) self.delete_resource( array, REPLICATION, 'storagegroup', resource_name=resource_name) def get_storage_group_snap_id_list( self, array, source_group, snap_name): """"""Get a snapshot and its snapid count information for an sg. :param array: name of the array -- str :param source_group: name of the storage group -- str :param snap_name: the name of the snapshot -- str :returns: snapids -- list """""" postfix_uri = ""snapid"" if self.is_snap_id else ""generation"" resource_name = (""%(sg_name)s/snapshot/%(snap_name)s/%(postfix_uri)s"" % {'sg_name': source_group, 'snap_name': snap_name, 'postfix_uri': postfix_uri}) response = self.get_resource(array, REPLICATION, 'storagegroup', resource_name=resource_name) if self.is_snap_id: return response.get('snapids', list()) if response else list() else: return response.get('generations', list()) if response else list() def get_storagegroup_rdf_details(self, array, storagegroup_name, rdf_group_num): """"""Get the remote replication details of a storage group. :param array: the array serial number :param storagegroup_name: the storage group name :param rdf_group_num: the rdf group number """""" resource_name = (""%(sg_name)s/rdf_group/%(rdf_num)s"" % {'sg_name': storagegroup_name, 'rdf_num': rdf_group_num}) return self.get_resource(array, REPLICATION, 'storagegroup', resource_name=resource_name) def replicate_group(self, array, storagegroup_name, rdf_group_num, remote_array, extra_specs): """"""Create a target group on the remote array and enable replication. :param array: the array serial number :param storagegroup_name: the name of the group :param rdf_group_num: the rdf group number :param remote_array: the remote array serial number :param extra_specs: the extra specifications """""" resource_name = (""storagegroup/%(sg_name)s/rdf_group"" % {'sg_name': storagegroup_name}) payload = {""executionOption"": ""ASYNCHRONOUS"", ""replicationMode"": utils.REP_SYNC, ""remoteSymmId"": remote_array, ""remoteStorageGroupName"": storagegroup_name, ""rdfgNumber"": rdf_group_num, ""establish"": 'true'} status_code, job = self.create_resource( array, REPLICATION, resource_name, payload) self.wait_for_job('Create storage group rdf', status_code, job, extra_specs) def _verify_rdf_state(self, array, storagegroup_name, rdf_group_num, action): """"""Verify if a storage group requires the requested state change. :param array: the array serial number :param storagegroup_name: the storage group name :param rdf_group_num: the rdf group number :param action: the requested action :returns: bool """""" mod_rqd = False sg_rdf_details = self.get_storagegroup_rdf_details( array, storagegroup_name, rdf_group_num) if sg_rdf_details: state_list = sg_rdf_details['states'] LOG.debug(""RDF state: %(sl)s; Action required: %(action)s"", {'sl': state_list, 'action': action}) for state in state_list: if (action.lower() in [""establish"", ""failback"", ""resume""] and state.lower() in [utils.RDF_SUSPENDED_STATE, utils.RDF_FAILEDOVER_STATE]): mod_rqd = True break elif (action.lower() in [""split"", ""failover"", ""suspend""] and state.lower() in [utils.RDF_SYNC_STATE, utils.RDF_SYNCINPROG_STATE, utils.RDF_CONSISTENT_STATE, utils.RDF_ACTIVE, utils.RDF_ACTIVEACTIVE, utils.RDF_ACTIVEBIAS]): mod_rqd = True break return mod_rqd def delete_storagegroup_rdf(self, array, storagegroup_name, rdf_group_num): """"""Delete the rdf pairs for a storage group. :param array: the array serial number :param storagegroup_name: the name of the storage group :param rdf_group_num: the number of the rdf group """""" resource_name = ('%(sg_name)s/rdf_group/%(rdf_num)s' % {'sg_name': storagegroup_name, 'rdf_num': rdf_group_num}) self.delete_resource( array, REPLICATION, 'storagegroup', resource_name=resource_name) def list_pagination(self, list_info): """"""Process lists under or over the maxPageSize :param list_info: the object list information :returns: the result list """""" result_list = [] try: result_list = list_info['resultList']['result'] iterator_id = list_info['id'] list_count = list_info['count'] max_page_size = list_info['maxPageSize'] start_position = list_info['resultList']['from'] end_position = list_info['resultList']['to'] except (KeyError, TypeError): return list_info if list_count > max_page_size: LOG.info(""More entries exist in the result list, retrieving "" ""remainder of results from iterator."") start_position = end_position + 1 if list_count < (end_position + max_page_size): end_position = list_count else: end_position += max_page_size iterator_response = self.get_iterator_page_list( iterator_id, list_count, start_position, end_position, max_page_size) result_list += iterator_response return result_list def get_iterator_page_list(self, iterator_id, result_count, start_position, end_position, max_page_size): """"""Iterate through response if more than one page available. :param iterator_id: the iterator ID :param result_count: the amount of results in the iterator :param start_position: position to begin iterator from :param end_position: position to stop iterator :param max_page_size: the max page size :returns: list -- merged results from multiple pages """""" LOG.debug('Iterator %(it)s contains %(cnt)s results.', { 'it': iterator_id, 'cnt': result_count}) iterator_result = [] has_more_entries = True while has_more_entries: if start_position <= result_count <= end_position: end_position = result_count has_more_entries = False params = {'to': end_position, 'from': start_position} LOG.debug('Retrieving iterator %(it)s page %(st)s to %(fn)s', { 'it': iterator_id, 'st': start_position, 'fn': end_position}) target_uri = ('/common/Iterator/%(iterator_id)s/page' % { 'iterator_id': iterator_id}) iterator_response = self.get_request(target_uri, 'iterator', params) try: iterator_result += iterator_response['result'] start_position += max_page_size end_position += max_page_size except (KeyError, TypeError): pass LOG.info('All results extracted, deleting iterator %(it)s', { 'it': iterator_id}) self._delete_iterator(iterator_id) return iterator_result def _delete_iterator(self, iterator_id): """"""Delete an iterator containing full request result list. Note: This should only be called once all required results have been extracted from the iterator. :param iterator_id: the iterator ID -- str """""" target_uri = self.build_uri( category='common', resource_level='Iterator', resource_level_id=iterator_id, no_version=True) status_code, message = self.request(target_uri, DELETE) operation = 'delete iterator' self.check_status_code_success(operation, status_code, message) LOG.info('Successfully deleted iterator %(it)s', {'it': iterator_id}) def validate_unisphere_version(self): """"""Validate that the running Unisphere version meets min requirement :returns: unisphere_meets_min_req -- boolean """""" running_version, major_version = self.get_uni_version() minimum_version = MIN_U4P_VERSION unisphere_meets_min_req = False if running_version and (running_version[0].isalpha()): # remove leading letter if running_version.lower()[0] == 'v': version = running_version[1:] unisphere_meets_min_req = ( self.utils.version_meet_req(version, minimum_version)) elif running_version.lower()[0] == 't': LOG.warning(""%(version)s This is not a official release of "" ""Unisphere."", {'version': running_version}) return major_version >= U4V_VERSION if unisphere_meets_min_req: LOG.info(""Unisphere version %(running_version)s meets minimum "" ""requirement of version %(minimum_version)s."", {'running_version': running_version, 'minimum_version': minimum_version}) elif running_version: LOG.error(""Unisphere version %(running_version)s does not meet "" ""minimum requirement for use with this release, please "" ""upgrade to Unisphere %(minimum_version)s at minimum."", {'running_version': running_version, 'minimum_version': minimum_version}) else: LOG.warning(""Unable to validate Unisphere instance meets minimum "" ""requirements."") return unisphere_meets_min_req def get_snap_id(self, array, device_id, snap_name): """"""Get the unique snap id for a particular snap name :param array: the array serial number :param device_id: the source device ID :param snap_name: the user supplied snapVX name :raises: VolumeBackendAPIException :returns: snap_id -- str """""" snapshots = self.get_volume_snaps(array, device_id, snap_name) if not snapshots: exception_message = (_( ""Snapshot %(snap_name)s is not associated with "" ""specified volume %(device_id)s."") % { 'device_id': device_id, 'snap_name': snap_name}) LOG.error(exception_message) raise exception.VolumeBackendAPIException( message=exception_message) elif len(snapshots) > 1: exception_message = (_( ""Snapshot %(snap_name)s is associated with more than "" ""one snap id. No information available to choose "" ""which one."") % { 'device_id': device_id, 'snap_name': snap_name}) LOG.error(exception_message) raise exception.VolumeBackendAPIException( message=exception_message) else: return snapshots[0].get('snap_id') if self.is_snap_id else ( snapshots[0].get('generation')) def get_major_minor_ucode(self, array): """"""Get the major and minor parts of the ucode :param array: the array serial number :returns: ucode_major_level, ucode_minor_level -- str, str """""" array_details = self.get_array_detail(array) ucode_major_level = 0 ucode_minor_level = 0 if array_details: split_ucode_level = array_details['ucode'].split('.') ucode_level = [int(level) for level in split_ucode_level] ucode_major_level = ucode_level[0] ucode_minor_level = ucode_level[1] return ucode_major_level, ucode_minor_level def _is_snapid_enabled(self): """"""Check if array is snap_id enabled :returns: boolean """""" return (self.ucode_major_level >= utils.UCODE_5978 and self.ucode_minor_level >= utils.UCODE_5978_HICKORY)",25828,25842
openstack%2Fcharm-keystone~master~Ib5fe0f25b9f02a0f808b0441d6c2e0f4ea217167,openstack/charm-keystone,master,Ib5fe0f25b9f02a0f808b0441d6c2e0f4ea217167,Review README,MERGED,2020-11-25 00:22:09.000000000,2020-11-27 15:14:33.000000000,2020-11-27 15:14:33.000000000,"[{'_account_id': 20648}, {'_account_id': 22348}, {'_account_id': 31289}]","[{'number': 1, 'created': '2020-11-25 00:22:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-keystone/commit/b327277ce338d455e55b3f262e4ab9d889755467', 'message': 'Review README\n\nGeneral review.\n\nApply REAME template.\n\nMinor correction in config.yaml\n\nChange-Id: Ib5fe0f25b9f02a0f808b0441d6c2e0f4ea217167\n'}, {'number': 2, 'created': '2020-11-25 16:54:33.000000000', 'files': ['config.yaml', 'README.md'], 'web_link': 'https://opendev.org/openstack/charm-keystone/commit/f111b5bdaf6181f30fa39b0a2addd84702a817d6', 'message': 'Review README\n\nGeneral review.\n\nApply REAME template.\n\nMinor correction in config.yaml\n\nChange-Id: Ib5fe0f25b9f02a0f808b0441d6c2e0f4ea217167\n'}]",0,764101,f111b5bdaf6181f30fa39b0a2addd84702a817d6,10,3,2,30561,,,0,"Review README

General review.

Apply REAME template.

Minor correction in config.yaml

Change-Id: Ib5fe0f25b9f02a0f808b0441d6c2e0f4ea217167
",git fetch https://review.opendev.org/openstack/charm-keystone refs/changes/01/764101/1 && git format-patch -1 --stdout FETCH_HEAD,"['config.yaml', 'README.md']",2,b327277ce338d455e55b3f262e4ab9d889755467,apply-template-to-readme,"The keystone charm deploys [Keystone][upstream-keystone], the core OpenStack service that provides API client authentication, service discovery, and distributed multi-tenant authorization. The charm works alongside other Juju-deployed OpenStack services.## Configuration This section covers common and/or important configuration options. See file `config.yaml` for the full list of options, along with their descriptions and default values. See the [Juju documentation][juju-docs-config-apps] for details on configuring applications. #### `openstack-origin` The `openstack-origin` option states the software sources. A common value is an OpenStack UCA release (e.g. 'cloud:bionic-ussuri' or 'cloud:focal-victoria'). See [Ubuntu Cloud Archive][wiki-uca]. The underlying host's existing apt sources will be used if this option is not specified (this behaviour can be explicitly chosen by using the value of 'distro'). ## Deployment Keystone is often containerised. Here a single unit is deployed to a new container on machine '1': juju deploy --to lxd:1 keystone Now connect the keystone application to an existing cloud database. The database application is determined by the series. Prior to focal [percona-cluster][percona-cluster-charm] is used, otherwise it is [mysql-innodb-cluster][mysql-innodb-cluster-charm]. In the example deployment below mysql-innodb-cluster has been chosen. juju deploy mysql-router keystone-mysql-router juju add-relation keystone-mysql-router:db-router mysql-innodb-cluster:db-router juju add-relation keystone-mysql-router:shared-db keystone:shared-db ## Credentials The `keystone:shared-db` relation added at deployment time stores the Keystone admin password in the cloud database. By default this password is generated randomly but, for testing purposes, can be set via the `admin-password` configuration option. This option can also be used to view and change the password post-deployment. ## Actions This section covers Juju [actions][juju-docs-actions] supported by the charm. Actions allow specific operations to be performed on a per-unit basis. To display action descriptions run `juju actions keystone`. If the charm is not deployed then see file `actions.yaml`. * `openstack-upgrade` * `pause` * `resume` * `security-checklist`For general charm questions refer to the [OpenStack Charm Guide][cg].[upstream-keystone]: https://docs.openstack.org/keystone/latest/ [juju-docs-config-apps]: https://juju.is/docs/configuring-applications [wiki-uca]: https://wiki.ubuntu.com/OpenStack/CloudArchive [juju-docs-actions]: https://jaas.ai/docs/actions [percona-cluster-charm]: https://jaas.ai/percona-cluster [mysql-innodb-cluster-charm]: https://jaas.ai/mysql-innodb-cluster","This charm provides Keystone, the OpenStack identity service. Its target platform is (ideally) Ubuntu LTS + OpenStack.## Database Keystone requires a database. The charm supports relation to a shared database server through the `mysql-shared` interface. When a new data store is configured, the charm ensures the minimum administrator credentials exist (as configured in charm configuration)For general charm questions refer to the OpenStack [Charm Guide][cg].",63,9
openstack%2Fnova~master~Ia108a7ac04defe742efcac09e7c0d61b08ab4e6d,openstack/nova,master,Ia108a7ac04defe742efcac09e7c0d61b08ab4e6d,zuul: Skip test_attach_scsi_disk_with_config_drive in nova-ceph-multistore,MERGED,2020-11-27 09:12:38.000000000,2020-11-27 15:10:43.000000000,2020-11-27 13:27:48.000000000,"[{'_account_id': 7166}, {'_account_id': 9708}, {'_account_id': 15334}, {'_account_id': 22348}]","[{'number': 1, 'created': '2020-11-27 09:12:38.000000000', 'files': ['.zuul.yaml'], 'web_link': 'https://opendev.org/openstack/nova/commit/836e13cd5785a9614bcddb98ee2b7367a3dc8541', 'message': 'zuul: Skip test_attach_scsi_disk_with_config_drive in nova-ceph-multistore\n\nRelated-Bug: #1905725\nChange-Id: Ia108a7ac04defe742efcac09e7c0d61b08ab4e6d\n'}]",1,764424,836e13cd5785a9614bcddb98ee2b7367a3dc8541,13,4,1,10135,,,0,"zuul: Skip test_attach_scsi_disk_with_config_drive in nova-ceph-multistore

Related-Bug: #1905725
Change-Id: Ia108a7ac04defe742efcac09e7c0d61b08ab4e6d
",git fetch https://review.opendev.org/openstack/nova refs/changes/24/764424/1 && git format-patch -1 --stdout FETCH_HEAD,['.zuul.yaml'],1,836e13cd5785a9614bcddb98ee2b7367a3dc8541,, # FIXME(lyarwood): test_attach_scsi_disk_with_config_drive attempts to # delete an image that has been cloned by nova ahead of the instance # being removed. Skip this test until it is reworked to remove the server # ahead of the image. tempest_black_regex: .*encrypted_cinder_volumes.*|.*test_attach_scsi_disk_with_config_drive, tempest_black_regex: .*encrypted_cinder_volumes.*,5,1
openstack%2Fcharm-rabbitmq-server~master~Ice83133c2c73532720f33298713267f69e8b4c3a,openstack/charm-rabbitmq-server,master,Ice83133c2c73532720f33298713267f69e8b4c3a,Update NRPE logic to add/remove checks and files,MERGED,2020-10-27 15:31:25.000000000,2020-11-27 15:10:26.000000000,2020-11-27 15:10:26.000000000,"[{'_account_id': 20648}, {'_account_id': 20870}, {'_account_id': 22348}, {'_account_id': 24890}, {'_account_id': 28182}, {'_account_id': 31289}, {'_account_id': 32363}]","[{'number': 1, 'created': '2020-10-27 15:31:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-rabbitmq-server/commit/30eaed3fccd1810637048c37c6850878d388aee0', 'message': 'If stats_cron_schedule is missing, remove the check and scripts\n\n- remove all `.py` scripts\n- remove check for check_rabbitmq_queues.py\n\nChange-Id: Ice83133c2c73532720f33298713267f69e8b4c3a\nCloses-Bug: #1779171\n'}, {'number': 2, 'created': '2020-10-28 11:44:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-rabbitmq-server/commit/4b3f0b3107fc5cce89ea1f132919be318f03ce84', 'message': ""If cronjob is missing, remove check and scripts\n\nThe change removes all the custom NRPE scripts and the NRPE\ncheck 'check_rabbitmq_queues' if `stats_cron_schedule` does not\nconfigured.\n\nCloses-Bug: #1779171\nChange-Id: Ice83133c2c73532720f33298713267f69e8b4c3a\n""}, {'number': 3, 'created': '2020-10-28 15:05:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-rabbitmq-server/commit/71d8ae3473d833cf951d39e771aaa8fb99f7637f', 'message': ""If cronjob is missing, remove check and scripts\n\nThe change removes all the custom NRPE scripts and the NRPE\ncheck 'check_rabbitmq_queues' if `stats_cron_schedule` does not\nconfigured.\n\nCloses-Bug: #1779171\nChange-Id: Ice83133c2c73532720f33298713267f69e8b4c3a\n""}, {'number': 4, 'created': '2020-10-29 20:52:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-rabbitmq-server/commit/bd0a493f1915a886a6b94985e4b4d9fbd910a6c3', 'message': ""If cronjob is missing, remove check and scripts\n\nThe change removes all the custom NRPE scripts and the NRPE\ncheck 'check_rabbitmq_queues' if `stats_cron_schedule` does not\nconfigured.\n\nCloses-Bug: #1779171\nChange-Id: Ice83133c2c73532720f33298713267f69e8b4c3a\n""}, {'number': 5, 'created': '2020-11-03 13:31:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-rabbitmq-server/commit/1f59bd140f28796a24df1df2dbc86a2f9e039959', 'message': 'Update NRPE logic to add/remove checks and files\n\nThe function `update_nrpe_checks` has been changed to remove redundant\nchecks and scripts based on rabbitmq configuration, but the main logic was\nunchanged.\n\nThe function logic is based on these three functions:\n1) copy all the custom NRPE scripts and create cron file\n2) add NRPE checks and remove redundant\n2.a) update the NRPE vhost check for SLL and non-SSL\n2.b) update the NRPE queues check\n2.c) update the NRPE cluster check\n3) remove redundant scripts - this must be done after removing\n                              the relevant check\n\nCloses-Bug: #1779171\nChange-Id: Ice83133c2c73532720f33298713267f69e8b4c3a\n'}, {'number': 6, 'created': '2020-11-03 13:49:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-rabbitmq-server/commit/ff1d820cbcbaaceeef2cbae6969982a47c372956', 'message': 'Update NRPE logic to add/remove checks and files\n\nThe function `update_nrpe_checks` has been changed to remove redundant\nchecks and scripts based on rabbitmq configuration, but the main logic was\nunchanged.\n\nThe function logic is based on these three functions:\n1) copy all the custom NRPE scripts and create cron file\n2) add NRPE checks and remove redundant\n2.a) update the NRPE vhost check for SLL and non-SSL\n2.b) update the NRPE queues check\n2.c) update the NRPE cluster check\n3) remove redundant scripts - this must be done after removing\n                              the relevant check\n\nCloses-Bug: #1779171\nChange-Id: Ice83133c2c73532720f33298713267f69e8b4c3a\n'}, {'number': 7, 'created': '2020-11-04 09:36:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-rabbitmq-server/commit/8da793b95f95366fd84ed760ca1f0fbb1768bdea', 'message': 'Update NRPE logic to add/remove checks and files\n\nThe function `update_nrpe_checks` has been changed to remove redundant\nchecks and scripts based on rabbitmq configuration, but the main logic was\nunchanged.\n\nThe function logic is based on these three functions:\n1) copy all the custom NRPE scripts and create cron file\n2) add NRPE checks and remove redundant\n2.a) update the NRPE vhost check for TLS and non-TLS\n2.b) update the NRPE queues check\n2.c) update the NRPE cluster check\n3) remove redundant scripts - this must be done after removing\n                              the relevant check\n\nCloses-Bug: #1779171\nChange-Id: Ice83133c2c73532720f33298713267f69e8b4c3a\n'}, {'number': 8, 'created': '2020-11-06 13:02:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-rabbitmq-server/commit/e9613da42fb40c0d85346d98fddfe39475f23397', 'message': 'Update NRPE logic to add/remove checks and files\n\nThe function `update_nrpe_checks` has been changed to remove redundant\nchecks and scripts based on rabbitmq configuration, but the main logic was\nunchanged.\n\nThe function logic is based on these three functions:\n1) copy all the custom NRPE scripts and create cron file\n2) add NRPE checks and remove redundant\n2.a) update the NRPE vhost check for TLS and non-TLS\n2.b) update the NRPE queues check\n2.c) update the NRPE cluster check\n3) remove redundant scripts - this must be done after removing\n                              the relevant check\n\nCloses-Bug: #1779171\nChange-Id: Ice83133c2c73532720f33298713267f69e8b4c3a\n'}, {'number': 9, 'created': '2020-11-06 14:35:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-rabbitmq-server/commit/37d65cd3fb63af01f5d209c644dfc793e9762a63', 'message': 'Update NRPE logic to add/remove checks and files\n\nThe function `update_nrpe_checks` has been changed to remove redundant\nchecks and scripts based on rabbitmq configuration, but the main logic was\nunchanged.\n\nThe function logic is based on these three functions:\n1) copy all the custom NRPE scripts and create cron file\n2) add NRPE checks and remove redundant\n2.a) update the NRPE vhost check for TLS and non-TLS\n2.b) update the NRPE queues check\n2.c) update the NRPE cluster check\n3) remove redundant scripts - this must be done after removing\n                              the relevant check\n\nCloses-Bug: #1779171\nChange-Id: Ice83133c2c73532720f33298713267f69e8b4c3a\n'}, {'number': 10, 'created': '2020-11-09 15:36:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-rabbitmq-server/commit/339bd456c882ecef2d47a17bbf4f74296b61bc56', 'message': 'Update NRPE logic to add/remove checks and files\n\nThe function `update_nrpe_checks` has been changed to remove redundant\nchecks and scripts based on rabbitmq configuration, but the main logic was\nunchanged.\n\nThe function logic is based on these three functions:\n1) copy all the custom NRPE scripts and create cron file\n2) add NRPE checks and remove redundant\n2.a) update the NRPE vhost check for TLS and non-TLS\n2.b) update the NRPE queues check\n2.c) update the NRPE cluster check\n3) remove redundant scripts - this must be done after removing\n                              the relevant check\n\nCloses-Bug: #1779171\nChange-Id: Ice83133c2c73532720f33298713267f69e8b4c3a\n'}, {'number': 11, 'created': '2020-11-24 09:05:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-rabbitmq-server/commit/ab53afce9f4ef482b489f1d0eef251445fd5cd61', 'message': 'Update NRPE logic to add/remove checks and files\n\nThe function `update_nrpe_checks` has been changed to remove redundant\nchecks and scripts based on rabbitmq configuration, but the main logic was\nunchanged.\n\nThe function logic is based on these three functions:\n1) copy all the custom NRPE scripts and create cron file\n2) add NRPE checks and remove redundant\n2.a) update the NRPE vhost check for TLS and non-TLS\n2.b) update the NRPE queues check\n2.c) update the NRPE cluster check\n3) remove redundant scripts - this must be done after removing\n                              the relevant check\n\nCloses-Bug: #1779171\nChange-Id: Ice83133c2c73532720f33298713267f69e8b4c3a\n'}, {'number': 12, 'created': '2020-11-25 10:57:33.000000000', 'files': ['unit_tests/test_rabbitmq_server_relations.py', 'unit_tests/test_rabbit_utils.py', 'unit_tests/test_utils.py', 'hooks/rabbitmq_server_relations.py', 'hooks/rabbit_utils.py'], 'web_link': 'https://opendev.org/openstack/charm-rabbitmq-server/commit/60f2f486d050feef720ab1584d18ac220618cade', 'message': 'Update NRPE logic to add/remove checks and files\n\nThe function `update_nrpe_checks` has been changed to remove redundant\nchecks and scripts based on rabbitmq configuration, but the main logic was\nunchanged.\n\nThe function logic is based on these three functions:\n1) copy all the custom NRPE scripts and create cron file\n2) add NRPE checks and remove redundant\n2.a) update the NRPE vhost check for TLS and non-TLS\n2.b) update the NRPE queues check\n2.c) update the NRPE cluster check\n3) remove redundant scripts - this must be done after removing\n                              the relevant check\n\nCloses-Bug: #1779171\nChange-Id: Ice83133c2c73532720f33298713267f69e8b4c3a\n'}]",62,759887,60f2f486d050feef720ab1584d18ac220618cade,75,7,12,32363,,,0,"Update NRPE logic to add/remove checks and files

The function `update_nrpe_checks` has been changed to remove redundant
checks and scripts based on rabbitmq configuration, but the main logic was
unchanged.

The function logic is based on these three functions:
1) copy all the custom NRPE scripts and create cron file
2) add NRPE checks and remove redundant
2.a) update the NRPE vhost check for TLS and non-TLS
2.b) update the NRPE queues check
2.c) update the NRPE cluster check
3) remove redundant scripts - this must be done after removing
                              the relevant check

Closes-Bug: #1779171
Change-Id: Ice83133c2c73532720f33298713267f69e8b4c3a
",git fetch https://review.opendev.org/openstack/charm-rabbitmq-server refs/changes/87/759887/3 && git format-patch -1 --stdout FETCH_HEAD,"['hooks/lib/utils.py', 'hooks/rabbitmq_server_relations.py']",2,30eaed3fccd1810637048c37c6850878d388aee0,bug/1779171,"from hooks.lib.utils import remove_file remove_file(STATS_CRONFILE) remove_file(os.path.join(NAGIOS_PLUGINS, 'check_rabbitmq.py')) remove_file(os.path.join(NAGIOS_PLUGINS, 'check_rabbitmq_queues.py')) remove_file(os.path.join(NAGIOS_PLUGINS, 'check_rabbitmq_cluster.py')) queue_check_cmd = '{}/check_rabbitmq_queues.py{} {}'.format( NAGIOS_PLUGINS, cmd, STATS_DATAFILE) if config('stats_cron_schedule'): nrpe_compat.add_check(shortname=rabbit.RABBIT_USER + '_queue', description='Check RabbitMQ Queues', check_cmd=queue_check_cmd) else: nrpe_compat.remove_check(shortname=rabbit.RABBIT_USER + '_queue', description='Check RabbitMQ Queues', check_cmd=queue_check_cmd) "," os.remove(STATS_CRONFILE) nrpe_compat.add_check( shortname=rabbit.RABBIT_USER + '_queue', description='Check RabbitMQ Queues', check_cmd='{}/check_rabbitmq_queues.py{} {}'.format( NAGIOS_PLUGINS, cmd, STATS_DATAFILE) )",28,8
openstack%2Fdesignate~master~I0df00a826dcaf73c6a078a39585839022b71268a,openstack/designate,master,I0df00a826dcaf73c6a078a39585839022b71268a,Implement secure RBAC for top-level domains,MERGED,2020-11-23 22:49:51.000000000,2020-11-27 15:02:10.000000000,2020-11-27 00:47:09.000000000,"[{'_account_id': 19298}, {'_account_id': 22348}, {'_account_id': 22623}]","[{'number': 1, 'created': '2020-11-23 22:49:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/designate/commit/3253551904c8626861db155770254ebd0cc2c55d', 'message': 'Implement secure RBAC for top-level domains\n\nThis commit updates the policies for top-level domains to understand scope\nchecking and account for a read-only role. This is part of a broader series of\nchanges across OpenStack to provide a consistent RBAC experience and improve\nsecurity.\n\nChange-Id: I0df00a826dcaf73c6a078a39585839022b71268a\n'}, {'number': 2, 'created': '2020-11-24 00:50:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/designate/commit/7c088bae546df39141be524be053b0add66c6d53', 'message': 'Implement secure RBAC for top-level domains\n\nThis commit updates the policies for top-level domains to understand scope\nchecking and account for a read-only role. This is part of a broader series of\nchanges across OpenStack to provide a consistent RBAC experience and improve\nsecurity.\n\nChange-Id: I0df00a826dcaf73c6a078a39585839022b71268a\n'}, {'number': 3, 'created': '2020-11-24 01:04:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/designate/commit/2d7a382a49403ee71f80a1347d56c02763c52734', 'message': 'Implement secure RBAC for top-level domains\n\nThis commit updates the policies for top-level domains to understand\nscope checking and account for a read-only role. This is part of a\nbroader series of changes across OpenStack to provide a consistent\nRBAC experience and improve security.\n\nChange-Id: I0df00a826dcaf73c6a078a39585839022b71268a\n'}, {'number': 4, 'created': '2020-11-24 04:11:24.000000000', 'files': ['designate/common/policies/tld.py'], 'web_link': 'https://opendev.org/openstack/designate/commit/e99f3588f1624f806265b264db1f82bf56fdedb9', 'message': 'Implement secure RBAC for top-level domains\n\nThis commit updates the policies for top-level domains to understand\nscope checking and account for a read-only role. This is part of a\nbroader series of changes across OpenStack to provide a consistent\nRBAC experience and improve security.\n\nChange-Id: I0df00a826dcaf73c6a078a39585839022b71268a\n'}]",4,763878,e99f3588f1624f806265b264db1f82bf56fdedb9,15,3,4,5046,,,0,"Implement secure RBAC for top-level domains

This commit updates the policies for top-level domains to understand
scope checking and account for a read-only role. This is part of a
broader series of changes across OpenStack to provide a consistent
RBAC experience and improve security.

Change-Id: I0df00a826dcaf73c6a078a39585839022b71268a
",git fetch https://review.opendev.org/openstack/designate refs/changes/78/763878/2 && git format-patch -1 --stdout FETCH_HEAD,['designate/common/policies/tld.py'],1,3253551904c8626861db155770254ebd0cc2c55d,secure-rbac,"from oslo_log import versionutilsDEPRECATED_REASON = """""" The top-level domain API now supports system scope and default roles. """""" deprecated_create_tld = policy.DeprecatedRule( name=""create_tld"", check_str=base.RULE_ADMIN ) deprecated_find_tlds = policy.DeprecatedRule( name=""find_tlds"", check_str=base.RULE_ADMIN ) deprecated_get_tld = policy.DeprecatedRule( name=""get_tld"", check_str=base.RULE_ADMIN ) deprecated_update_tld = policy.DeprecatedRule( name=""update_tld"", check_str=base.RULE_ADMIN ) deprecated_delete_tld = policy.DeprecatedRule( name=""delete_tld"", check_str=base.RULE_ADMIN ) check_str=base.SYSTEM_ADMIN, scope_types=['system'], ], deprecated_rule=deprecated_create_tld, deprecated_reason=DEPRECATED_REASON, deprecated_since=versionutils.deprecated.WALLABY check_str=base.SYSTEM_READER, scope_types=['system'], ], deprecated_rule=deprecated_find_tlds, deprecated_reason=DEPRECATED_REASON, deprecated_since=versionutils.deprecated.WALLABY check_str=base.SYSTEM_READER, scope_types=['system'], ], deprecated_rule=deprecated_get_tld, deprecated_reason=DEPRECATED_REASON, deprecated_since=versionutils.deprecated.WALLABY check_str=base.SYSTEM_ADMIN, scope_types=['system'], ], deprecated_rule=deprecated_update_tld, deprecated_reason=DEPRECATED_REASON, deprecated_since=versionutils.deprecated.WALLABY check_str=base.SYSTEM_ADMIN, scope_types=['system'], ], deprecated_rule=deprecated_delete_tld, deprecated_reason=DEPRECATED_REASON, deprecated_since=versionutils.deprecated.WALLABY"," check_str=base.RULE_ADMIN, ] check_str=base.RULE_ADMIN, ] check_str=base.RULE_ADMIN, ] check_str=base.RULE_ADMIN, ] check_str=base.RULE_ADMIN, ]",57,10
openstack%2Fcharm-ironic-api~master~If656e4604128bd85d0862da4d2892ac2b949f691,openstack/charm-ironic-api,master,If656e4604128bd85d0862da4d2892ac2b949f691,Add Victoria to the test gate,MERGED,2020-11-04 13:44:14.000000000,2020-11-27 14:47:01.000000000,2020-11-27 14:47:01.000000000,"[{'_account_id': 12549}, {'_account_id': 20648}, {'_account_id': 22348}, {'_account_id': 31289}]","[{'number': 1, 'created': '2020-11-04 13:44:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-ironic-api/commit/0dbb1522d7581cb0fe49865d1fd874f2b4a0e429', 'message': 'Add Victoria to the test gate\n\nChange-Id: If656e4604128bd85d0862da4d2892ac2b949f691\n'}, {'number': 2, 'created': '2020-11-05 10:11:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-ironic-api/commit/80274f3f20d99b2350996f30bbe3daff0ab2f3dc', 'message': 'Add Victoria to the test gate\n\nChange-Id: If656e4604128bd85d0862da4d2892ac2b949f691\n'}, {'number': 3, 'created': '2020-11-05 10:15:03.000000000', 'files': ['src/tests/bundles/focal-ussuri.yaml', 'src/tests/bundles/focal-victoria.yaml', 'src/tests/bundles/groovy-victoria.yaml', 'src/tests/tests.yaml', 'src/tests/bundles/bionic-train.yaml', 'src/tests/bundles/bionic-ussuri.yaml', 'src/tests/bundles/overlays/groovy-victoria.yaml.j2'], 'web_link': 'https://opendev.org/openstack/charm-ironic-api/commit/a6f44ce5c1ba91fbcbab67af9489da00f1390d29', 'message': 'Add Victoria to the test gate\n\nChange-Id: If656e4604128bd85d0862da4d2892ac2b949f691\n'}]",0,761408,a6f44ce5c1ba91fbcbab67af9489da00f1390d29,35,4,3,31289,,,0,"Add Victoria to the test gate

Change-Id: If656e4604128bd85d0862da4d2892ac2b949f691
",git fetch https://review.opendev.org/openstack/charm-ironic-api refs/changes/08/761408/2 && git format-patch -1 --stdout FETCH_HEAD,"['src/tests/bundles/groovy-victoria.yaml', 'src/tests/tests.yaml', 'src/tests/bundles/overlays/groovy-victoria.yaml.j2']",3,0dbb1522d7581cb0fe49865d1fd874f2b4a0e429,groovy-charm-gate,ironic.j2,,286,2
openstack%2Fironic-python-agent~master~Ib2979a948252296e87dff34f2f0ec99822ba87b5,openstack/ironic-python-agent,master,Ib2979a948252296e87dff34f2f0ec99822ba87b5,Support using LABEL as identifier for rootfs,ABANDONED,2020-11-22 15:12:36.000000000,2020-11-27 14:43:12.000000000,,"[{'_account_id': 10239}, {'_account_id': 22348}]","[{'number': 1, 'created': '2020-11-22 15:12:36.000000000', 'files': ['ironic_python_agent/extensions/image.py'], 'web_link': 'https://opendev.org/openstack/ironic-python-agent/commit/dc10de713502d2ba0d105ce2e8d6e1085ab9375d', 'message': 'Support using LABEL as identifier for rootfs\n\nChange-Id: Ib2979a948252296e87dff34f2f0ec99822ba87b5\n'}]",0,763636,dc10de713502d2ba0d105ce2e8d6e1085ab9375d,4,2,1,17686,,,0,"Support using LABEL as identifier for rootfs

Change-Id: Ib2979a948252296e87dff34f2f0ec99822ba87b5
",git fetch https://review.opendev.org/openstack/ironic-python-agent refs/changes/36/763636/1 && git format-patch -1 --stdout FETCH_HEAD,['ironic_python_agent/extensions/image.py'],1,dc10de713502d2ba0d105ce2e8d6e1085ab9375d,," for key in {""UUID"", ""PARTUUID"", ""LABEL""}: return '/dev/' + part.get('KNAME')"," if key in {""UUID"", ""PARTUUID"", ""LABEL""}: return '/dev/' + part.get('KNAME') ",2,2
openstack%2Fironic-python-agent~master~Idca85ce7f68dc13fa91130042ec321effebd7c65,openstack/ironic-python-agent,master,Idca85ce7f68dc13fa91130042ec321effebd7c65,Support using LABEL as identifier for rootfs,ABANDONED,2020-11-22 12:50:50.000000000,2020-11-27 14:43:02.000000000,,[{'_account_id': 22348}],"[{'number': 1, 'created': '2020-11-22 12:50:50.000000000', 'files': ['releasenotes/notes/software-raid-use-label-as-rootfs-uuid-d9a3827180f1a238.yaml', 'ironic_python_agent/extensions/image.py'], 'web_link': 'https://opendev.org/openstack/ironic-python-agent/commit/ddeb0bd15c7e4ce34498410087fe6fd102e5882f', 'message': 'Support using LABEL as identifier for rootfs\n\nChange-Id: Idca85ce7f68dc13fa91130042ec321effebd7c65\n'}]",2,763631,ddeb0bd15c7e4ce34498410087fe6fd102e5882f,3,1,1,17686,,,0,"Support using LABEL as identifier for rootfs

Change-Id: Idca85ce7f68dc13fa91130042ec321effebd7c65
",git fetch https://review.opendev.org/openstack/ironic-python-agent refs/changes/31/763631/1 && git format-patch -1 --stdout FETCH_HEAD,"['releasenotes/notes/software-raid-use-label-as-rootfs-uuid-d9a3827180f1a238.yaml', 'ironic_python_agent/extensions/image.py']",2,ddeb0bd15c7e4ce34498410087fe6fd102e5882f,uuid_as_label," if key in {""UUID"", ""PARTUUID"", ""LABEL""}: if part.get(key) == uuid: LOG.debug(""Partition %(uuid)s found on device "" ""%(dev)s"", {'uuid': key, 'dev': device}) return '/dev/' + value ",,8,2
openstack%2Fironic-python-agent~master~I246b8b99c0ba5a94af5d324cee31cf4ee59af374,openstack/ironic-python-agent,master,I246b8b99c0ba5a94af5d324cee31cf4ee59af374,Support using LABEL as identifier for rootfs,ABANDONED,2020-11-22 12:55:27.000000000,2020-11-27 14:42:59.000000000,,[{'_account_id': 22348}],"[{'number': 1, 'created': '2020-11-22 12:55:27.000000000', 'files': ['ironic_python_agent/extensions/image.py'], 'web_link': 'https://opendev.org/openstack/ironic-python-agent/commit/4917df669e57f6180661f8ca58e8937213eb0e3d', 'message': 'Support using LABEL as identifier for rootfs\n\nChange-Id: I246b8b99c0ba5a94af5d324cee31cf4ee59af374\n'}]",1,763632,4917df669e57f6180661f8ca58e8937213eb0e3d,3,1,1,17686,,,0,"Support using LABEL as identifier for rootfs

Change-Id: I246b8b99c0ba5a94af5d324cee31cf4ee59af374
",git fetch https://review.opendev.org/openstack/ironic-python-agent refs/changes/32/763632/1 && git format-patch -1 --stdout FETCH_HEAD,['ironic_python_agent/extensions/image.py'],1,4917df669e57f6180661f8ca58e8937213eb0e3d,uuid_as_label, return '/dev/' + part.get('KNAME') ," return '/dev/' + value if part.get('UUID') == uuid: LOG.debug(""Partition %(uuid)s found on device "" ""%(dev)s"", {'uuid': uuid, 'dev': device}) return '/dev/' + part.get('KNAME') if part.get('PARTUUID') == uuid: LOG.debug(""Partition %(uuid)s found on device "" ""%(dev)s"", {'uuid': uuid, 'dev': device}) return '/dev/' + part.get('KNAME') if part.get('LABEL') == uuid: LOG.debug(""Partition %(uuid)s found on device "" ""%(dev)s"", {'uuid': uuid, 'dev': device}) return '/dev/' + part.get('KNAME')",1,14
openstack%2Fcharm-neutron-api-plugin-ironic~master~I09513db77d110fd8acb3bfee7f6d78ae3f053ca3,openstack/charm-neutron-api-plugin-ironic,master,I09513db77d110fd8acb3bfee7f6d78ae3f053ca3,Add Zaza functional tests,MERGED,2020-10-04 19:55:51.000000000,2020-11-27 14:40:27.000000000,2020-11-27 14:40:27.000000000,"[{'_account_id': 12549}, {'_account_id': 20648}, {'_account_id': 22348}, {'_account_id': 31289}]","[{'number': 1, 'created': '2020-10-04 19:55:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-neutron-api-plugin-ironic/commit/f282b287f6d7c2027e7c9776d568c968f24a3f88', 'message': 'Change repo URL in layer.yaml\n\nChange-Id: I09513db77d110fd8acb3bfee7f6d78ae3f053ca3\n'}, {'number': 2, 'created': '2020-10-15 13:57:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-neutron-api-plugin-ironic/commit/633e71ff29cdf6840aacaab778dc3c7693967a8d', 'message': 'Change repo URL in layer.yaml\n\nChange-Id: I09513db77d110fd8acb3bfee7f6d78ae3f053ca3\nCo-authored-by: Aurelien Lourot <aurelien.lourot@canonical.com>\n'}, {'number': 3, 'created': '2020-10-16 13:25:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-neutron-api-plugin-ironic/commit/b7c6c1f1a28af385780fa74c1eee588b18239a7b', 'message': 'Change repo URL in layer.yaml\n\nAlso make linter happy.\n\nChange-Id: I09513db77d110fd8acb3bfee7f6d78ae3f053ca3\nCo-authored-by: Aurelien Lourot <aurelien.lourot@canonical.com>\n'}, {'number': 4, 'created': '2020-11-05 10:40:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-neutron-api-plugin-ironic/commit/d76fa236b948a84853d59dfcfdeeab560ed2b73e', 'message': 'Add Zaza functional tests\n\nAlso change repo URL in layer.yaml and make linter happy.\n\nChange-Id: I09513db77d110fd8acb3bfee7f6d78ae3f053ca3\nCo-authored-by: Aurelien Lourot <aurelien.lourot@canonical.com>\n'}, {'number': 5, 'created': '2020-11-05 12:41:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-neutron-api-plugin-ironic/commit/9f853fdf20403d154402436bf7c698d5802c8cc2', 'message': 'Add Zaza functional tests\n\nAlso change repo URL in layer.yaml and make linter happy.\n\nChange-Id: I09513db77d110fd8acb3bfee7f6d78ae3f053ca3\nCo-authored-by: Aurelien Lourot <aurelien.lourot@canonical.com>\n'}, {'number': 6, 'created': '2020-11-09 12:24:14.000000000', 'files': ['.gitreview', 'src/tests/bundles/overlays/focal-victoria.yaml.j2', 'src/tests/bundles/focal-ussuri.yaml', '.zuul.yaml', 'unit_tests/__init__.py', 'src/metadata.yaml', 'src/tests/bundles/overlays/bionic-train.yaml.j2', 'src/tests/bundles/groovy-victoria.yaml', 'src/tests/tests.yaml', 'src/reactive/neutron_ironic_handlers.py', 'src/layer.yaml', 'src/tests/bundles/bionic-train.yaml', 'src/tests/bundles/bionic-ussuri.yaml', 'src/tests/bundles/overlays/groovy-victoria.yaml.j2', 'unit_tests/test_neutron_ironic_handlers.py', 'src/tests/bundles/overlays/bionic-ussuri.yaml.j2', 'src/tests/bundles/overlays/ironic.j2', 'src/tests/bundles/overlays/focal-ussuri.yaml.j2', 'src/tests/bundles/focal-victoria.yaml', 'src/lib/charm/openstack/neutron_ironic.py'], 'web_link': 'https://opendev.org/openstack/charm-neutron-api-plugin-ironic/commit/70c5d772aa90fff000dab78a9199b0b13162fac5', 'message': 'Add Zaza functional tests\n\nAlso change repo URL in layer.yaml, make linter happy\nand add groovy to the metadata.\n\nChange-Id: I09513db77d110fd8acb3bfee7f6d78ae3f053ca3\nCo-authored-by: Aurelien Lourot <aurelien.lourot@canonical.com>\n'}]",1,755979,70c5d772aa90fff000dab78a9199b0b13162fac5,43,4,6,9426,,,0,"Add Zaza functional tests

Also change repo URL in layer.yaml, make linter happy
and add groovy to the metadata.

Change-Id: I09513db77d110fd8acb3bfee7f6d78ae3f053ca3
Co-authored-by: Aurelien Lourot <aurelien.lourot@canonical.com>
",git fetch https://review.opendev.org/openstack/charm-neutron-api-plugin-ironic refs/changes/79/755979/6 && git format-patch -1 --stdout FETCH_HEAD,"['.gitreview', 'src/tox.ini', 'src/layer.yaml']",3,f282b287f6d7c2027e7c9776d568c968f24a3f88,groovy-charm-gate,repo: https://opendev.org/openstack/charm-neutron-api-plugin-ironic.git,repo: https://github.com/gabriel-samfira/charm-neutron-api-plugin-ironic,6,2
openstack%2Fcharm-percona-cluster~master~I7e16a566531a7faf9d3a960c3df524fd46976a2a,openstack/charm-percona-cluster,master,I7e16a566531a7faf9d3a960c3df524fd46976a2a,Ensure that c.c.unitdata.kv is properly mocked out,MERGED,2020-11-26 20:23:25.000000000,2020-11-27 14:18:05.000000000,2020-11-27 14:18:05.000000000,"[{'_account_id': 20634}, {'_account_id': 20648}, {'_account_id': 22348}, {'_account_id': 32363}]","[{'number': 1, 'created': '2020-11-26 20:23:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-percona-cluster/commit/5eebd32e721afbf921250d8169b8cdf502ac5655', 'message': ""Ensure that c.c.unitdata.kv is properly mocked out\n\nAs unit tests run concurrently, it's important that all tests use a\nmocked out version of the kv() store.  Otherwise, unit tests can race\nand fail due to SQLite lock erros.  See linked bug for details.\n\nChange-Id: I7e16a566531a7faf9d3a960c3df524fd46976a2a\nCloses-Bug: #1905760\n""}, {'number': 2, 'created': '2020-11-27 10:20:40.000000000', 'files': ['unit_tests/test_percona_utils.py', 'unit_tests/test_percona_hooks.py', 'unit_tests/test_utils.py'], 'web_link': 'https://opendev.org/openstack/charm-percona-cluster/commit/2962cc9a9aa768138d9f7e9e534fa75a5520e738', 'message': ""Ensure that c.c.unitdata.kv is properly mocked out\n\nAs unit tests run concurrently, it's important that all tests use a\nmocked out version of the kv() store.  Otherwise, unit tests can race\nand fail due to SQLite lock erros.  See linked bug for details.\n\nChange-Id: I7e16a566531a7faf9d3a960c3df524fd46976a2a\nCloses-Bug: #1905760\n""}]",4,764384,2962cc9a9aa768138d9f7e9e534fa75a5520e738,15,4,2,20870,,,0,"Ensure that c.c.unitdata.kv is properly mocked out

As unit tests run concurrently, it's important that all tests use a
mocked out version of the kv() store.  Otherwise, unit tests can race
and fail due to SQLite lock erros.  See linked bug for details.

Change-Id: I7e16a566531a7faf9d3a960c3df524fd46976a2a
Closes-Bug: #1905760
",git fetch https://review.opendev.org/openstack/charm-percona-cluster refs/changes/84/764384/1 && git format-patch -1 --stdout FETCH_HEAD,"['unit_tests/test_percona_utils.py', 'unit_tests/test_percona_hooks.py', 'unit_tests/test_utils.py']",3,5eebd32e721afbf921250d8169b8cdf502ac5655,bug/1905760,"import sysfrom charmhelpers.core.unitdata import Record class FakeKvStore(): def __init__(self): self._store = {} self._closed = False self._flushed = False def close(self): self._closed = True def get(self, key, default=None, record=False): if key not in self._store: return default if record: return Record(self._store[key]) return self._store[key] def getrange(self, *args, **kwargs): raise NotImplementedError def update(self, mapping, prefix=""""): for k, v in mapping.items(): self.set(""%s%s"" % (prefix, k), v) def unset(self, key): if key in self._store: del self._store[key] def unsetrange(self, keys=None, prefix=""""): raise NotImplementedError def set(self, key, value): self._store[key] = value def delta(self, mapping, prefix): raise NotImplementedError def hook_scope(self, name=""""): raise NotImplementedError def flush(self, save=True): self._flushed = True def gethistory(self, key, deserialize=False): raise NotImplementedError def debug(self, fh=sys.stderr): raise NotImplementedError",,87,11
openstack%2Fnova~master~I8f943ef88051595cb68c75e2c49a8689a69a084c,openstack/nova,master,I8f943ef88051595cb68c75e2c49a8689a69a084c,DNM test test_attach_scsi_disk_with_config_drive fix,ABANDONED,2020-11-26 12:32:24.000000000,2020-11-27 13:35:10.000000000,,[{'_account_id': 22348}],"[{'number': 1, 'created': '2020-11-26 12:32:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/4a772db8880f36a4ae54d87a697af27abfa5c18e', 'message': 'DNM test test_attach_scsi_disk_with_config_drive fix\n\nChange-Id: I8f943ef88051595cb68c75e2c49a8689a69a084c\nRelated-Bug: #1905725\n'}, {'number': 2, 'created': '2020-11-26 14:52:41.000000000', 'files': ['.zuul.yaml'], 'web_link': 'https://opendev.org/openstack/nova/commit/3ee5ac68a825d74056f44a4f5c14acb21a08b41d', 'message': 'DNM test test_attach_scsi_disk_with_config_drive fix\n\nDepends-On: https://review.opendev.org/c/openstack/tempest/+/764337\nChange-Id: I8f943ef88051595cb68c75e2c49a8689a69a084c\nRelated-Bug: #1905725\n'}]",0,764339,3ee5ac68a825d74056f44a4f5c14acb21a08b41d,6,1,2,10135,,,0,"DNM test test_attach_scsi_disk_with_config_drive fix

Depends-On: https://review.opendev.org/c/openstack/tempest/+/764337
Change-Id: I8f943ef88051595cb68c75e2c49a8689a69a084c
Related-Bug: #1905725
",git fetch https://review.opendev.org/openstack/nova refs/changes/39/764339/2 && git format-patch -1 --stdout FETCH_HEAD,['.zuul.yaml'],1,4a772db8880f36a4ae54d87a697af27abfa5c18e,,, # We define our own irrelevant-files so we don't run the job # on things like nova docs-only changes. - ironic-tempest-ipa-wholedisk-bios-agent_ipmitool-tinyipa: voting: false irrelevant-files: *dsvm-irrelevant-files - neutron-tempest-linuxbridge: irrelevant-files: # NOTE(mriedem): This job has its own irrelevant-files section # so that we only run it on changes to networking and libvirt/vif # code; we don't need to run this on all changes. - ^(?!nova/network/.*)(?!nova/virt/libvirt/vif.py).*$ - nova-grenade-multinode - nova-live-migration - nova-lvm - nova-multi-cell - nova-next - nova-tox-functional-py38 - nova-tox-functional-py39: voting: false - tempest-integrated-compute: # NOTE(gmann): Policies changes do not need to run all the # integration test jobs. Running only tempest and grenade # common jobs will be enough along with nova functional # and unit tests. irrelevant-files: &policies-irrelevant-files - ^api-.*$ - ^(test-|)requirements.txt$ - ^.*\.rst$ - ^.git.*$ - ^doc/.*$ - ^nova/hacking/.*$ - ^nova/locale/.*$ - ^nova/tests/.*$ - ^nova/test.py$ - ^releasenotes/.*$ - ^setup.cfg$ - ^tools/.*$ - ^tox.ini$ - grenade: irrelevant-files: *policies-irrelevant-files - tempest-ipv6-only: irrelevant-files: *dsvm-irrelevant-files - openstacksdk-functional-devstack: irrelevant-files: *dsvm-irrelevant-files - cyborg-tempest: irrelevant-files: *dsvm-irrelevant-files voting: false - barbican-tempest-plugin-simple-crypto: irrelevant-files: *dsvm-irrelevant-files voting: false - nova-grenade-multinode - nova-live-migration - nova-tox-functional-py38 - nova-multi-cell - nova-next - neutron-tempest-linuxbridge: irrelevant-files: # NOTE(mriedem): This job has its own irrelevant-files section # so that we only run it on changes to networking and libvirt/vif # code; we don't need to run this on all changes. - ^(?!nova/network/.*)(?!nova/virt/libvirt/vif.py).*$ - tempest-integrated-compute: irrelevant-files: *policies-irrelevant-files - grenade: irrelevant-files: *policies-irrelevant-files - tempest-ipv6-only: irrelevant-files: *dsvm-irrelevant-files - openstacksdk-functional-devstack: irrelevant-files: *dsvm-irrelevant-files,0,69
openstack%2Ftripleo-heat-templates~stable%2Fussuri~I415799279d83ff386c16363fdfab2f7e32e5edc6,openstack/tripleo-heat-templates,stable/ussuri,I415799279d83ff386c16363fdfab2f7e32e5edc6,[ussuri] Migrate to content provider jobs/templates,MERGED,2020-10-12 11:49:42.000000000,2020-11-27 13:19:46.000000000,2020-11-27 13:19:46.000000000,"[{'_account_id': 8175}, {'_account_id': 8449}, {'_account_id': 9592}, {'_account_id': 9976}, {'_account_id': 10969}, {'_account_id': 12393}, {'_account_id': 13861}, {'_account_id': 20172}, {'_account_id': 20182}, {'_account_id': 22348}, {'_account_id': 23181}, {'_account_id': 30750}]","[{'number': 1, 'created': '2020-10-12 11:49:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/e9e31fd8686b460a54812059969e909dc8fd35b9', 'message': 'Migrate to content provider jobs/templates\n\nThis change migrate c8 jobs/templates to content provider\njos so consumer jobs can use resources built by provider\njobs.\n\nChange-Id: I415799279d83ff386c16363fdfab2f7e32e5edc6\nSigned-off-by: Amol Kahat <amolkahat@gmail.com>\n'}, {'number': 2, 'created': '2020-10-23 10:16:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/577f89c9642a6fa6c98dfd6b1641b28592cee5e6', 'message': '[ussuri] Migrate to content provider jobs/templates\n\nThis change migrate c7 and c8 jobs/templates to content provider\njos so consumer jobs can use resources built by provider\njobs.\n\nChange-Id: I415799279d83ff386c16363fdfab2f7e32e5edc6\nSigned-off-by: Amol Kahat <amolkahat@gmail.com>\n'}, {'number': 3, 'created': '2020-10-23 10:20:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/192264e2fa7a74c0a61cc0ee3ed1634a65b416be', 'message': '[ussuri] Migrate to content provider jobs/templates\n\nThis change migrate c7 and c8 jobs/templates to content provider\njos so consumer jobs can use resources built by provider\njobs.\n\nChange-Id: I415799279d83ff386c16363fdfab2f7e32e5edc6\nSigned-off-by: Amol Kahat <amolkahat@gmail.com>\n'}, {'number': 4, 'created': '2020-10-24 06:51:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/86f7bcd7442025c9bdbb98b06935d16a2538325c', 'message': '[ussuri] Migrate to content provider jobs/templates\n\nThis change migrate c7 and c8 jobs/templates to content provider\njos so consumer jobs can use resources built by provider\njobs.\n\nChange-Id: I415799279d83ff386c16363fdfab2f7e32e5edc6\nSigned-off-by: Amol Kahat <amolkahat@gmail.com>\n'}, {'number': 5, 'created': '2020-10-24 06:55:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/5e238b9625ec89b2bb043957ae55c08a35e1dc15', 'message': '[ussuri] Migrate to content provider jobs/templates\n\nThis change migrate c7 and c8 jobs/templates to content provider\njos so consumer jobs can use resources built by provider\njobs.\n\nChange-Id: I415799279d83ff386c16363fdfab2f7e32e5edc6\nSigned-off-by: Amol Kahat <amolkahat@gmail.com>\n'}, {'number': 6, 'created': '2020-10-26 12:22:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/8242b8850c4b2260cbfa3deda9127cebac426748', 'message': '[ussuri] Migrate to content provider jobs/templates\n\nThis change migrate c7 and c8 jobs/templates to content provider\njos so consumer jobs can use resources built by provider\njobs.\n\nChange-Id: I415799279d83ff386c16363fdfab2f7e32e5edc6\nSigned-off-by: Amol Kahat <amolkahat@gmail.com>\n'}, {'number': 7, 'created': '2020-10-27 16:16:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/cdfd91afed92443565175a5814685abedba67a91', 'message': '[ussuri] Migrate to content provider jobs/templates\n\nThis change migrate c7 and c8 jobs/templates to content provider\njos so consumer jobs can use resources built by provider\njobs.\n\nChange-Id: I415799279d83ff386c16363fdfab2f7e32e5edc6\nSigned-off-by: Amol Kahat <amolkahat@gmail.com>\n'}, {'number': 8, 'created': '2020-10-28 12:20:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/c0a63dd42a6a0095076df7e902f6bf54d3323952', 'message': '[ussuri] Migrate to content provider jobs/templates\n\nThis change migrate jobs/templates to content provider\njobs so consumer jobs can use resources built by provider\njobs.\n\nChange-Id: I415799279d83ff386c16363fdfab2f7e32e5edc6\nSigned-off-by: Amol Kahat <amolkahat@gmail.com>\n'}, {'number': 9, 'created': '2020-10-29 10:50:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/a134f6b3794ef0e7fecaad64daa304fa345c1d13', 'message': '[ussuri] Migrate to content provider jobs/templates\n\nThis change migrate jobs/templates to content provider\njobs so consumer jobs can use resources built by provider\njobs.\n\nChange-Id: I415799279d83ff386c16363fdfab2f7e32e5edc6\nSigned-off-by: Amol Kahat <amolkahat@gmail.com>\n'}, {'number': 10, 'created': '2020-10-29 18:54:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/4e4bde942e58d08bbf7f0cdf608d86b35788bcbd', 'message': '[ussuri] Migrate to content provider jobs/templates\n\nThis change migrate jobs/templates to content provider\njobs so consumer jobs can use resources built by provider\njobs.\n\nDepends-On: https://review.opendev.org/#/c/759912/\nChange-Id: I415799279d83ff386c16363fdfab2f7e32e5edc6\nSigned-off-by: Amol Kahat <amolkahat@gmail.com>\n'}, {'number': 11, 'created': '2020-11-01 19:18:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/848dc2157d67273ef62885aeb1a47162a99035f6', 'message': '[ussuri] Migrate to content provider jobs/templates\n\nThis change migrate jobs/templates to content provider\njobs so consumer jobs can use resources built by provider\njobs.\n\nDepends-On: https://review.opendev.org/#/c/759912/\nChange-Id: I415799279d83ff386c16363fdfab2f7e32e5edc6\nSigned-off-by: Amol Kahat <amolkahat@gmail.com>\n'}, {'number': 12, 'created': '2020-11-01 20:13:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/c05015961f54ebbdb29d9ec01b2de7b7292841d8', 'message': '[ussuri] Migrate to content provider jobs/templates\n\nThis change migrate jobs/templates to content provider\njobs so consumer jobs can use resources built by provider\njobs.\n\nDepends-On: https://review.opendev.org/#/c/759912/\nChange-Id: I415799279d83ff386c16363fdfab2f7e32e5edc6\nSigned-off-by: Amol Kahat <amolkahat@gmail.com>\n'}, {'number': 13, 'created': '2020-11-01 23:44:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/e792fc05efff007e0c124a687ea8f0182bbe3f9f', 'message': '[ussuri] Migrate to content provider jobs/templates\n\nThis change migrate jobs/templates to content provider\njobs so consumer jobs can use resources built by provider\njobs.\n\n# the tag for building rpms should be build\nDepends-On: https://review.opendev.org/#/c/759912/\n# delete tempest workspace\nDepends-On: https://review.opendev.org/#/c/760626/\n\nChange-Id: I415799279d83ff386c16363fdfab2f7e32e5edc6\nSigned-off-by: Amol Kahat <amolkahat@gmail.com>\n'}, {'number': 14, 'created': '2020-11-02 03:13:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/dfec896e868dfbe4ffbf40d725fe40fce78297b6', 'message': '[ussuri] Migrate to content provider jobs/templates\n\nThis change migrate jobs/templates to content provider\njobs so consumer jobs can use resources built by provider\njobs.\n\n# the tag for building rpms should be build\nDepends-On: https://review.opendev.org/#/c/759912/\n# delete tempest workspace\nDepends-On: https://review.opendev.org/#/c/760626/\n# yum/dnf package detection\nDepends-On: https://review.opendev.org/#/c/760635\n\nChange-Id: I415799279d83ff386c16363fdfab2f7e32e5edc6\nSigned-off-by: Amol Kahat <amolkahat@gmail.com>\n'}, {'number': 15, 'created': '2020-11-08 18:58:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/c0a56d79a9612da32fbb504fda4852f2fa9d999b', 'message': '[ussuri] Migrate to content provider jobs/templates\n\nThis change migrate jobs/templates to content provider\njobs so consumer jobs can use resources built by provider\njobs.\n\n# the tag for building rpms should be build\nDepends-On: https://review.opendev.org/#/c/759912/\n# delete tempest workspace\nDepends-On: https://review.opendev.org/#/c/760626/\n# yum/dnf package detection\nDepends-On: https://review.opendev.org/#/c/760635\n\nChange-Id: I415799279d83ff386c16363fdfab2f7e32e5edc6\nSigned-off-by: Amol Kahat <amolkahat@gmail.com>\n'}, {'number': 16, 'created': '2020-11-23 10:58:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/62f25b101bae40f43ee4a15585e83a47b156dad7', 'message': '[ussuri] Migrate to content provider jobs/templates\n\nThis change migrate jobs/templates to content provider\njobs so consumer jobs can use resources built by provider\njobs.\n\nDepends-On: https://review.opendev.org/#/c/763633\nChange-Id: I415799279d83ff386c16363fdfab2f7e32e5edc6\nSigned-off-by: Amol Kahat <amolkahat@gmail.com>\n'}, {'number': 17, 'created': '2020-11-24 03:03:39.000000000', 'files': ['zuul.d/layout.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/5b553b611aec5e785746fdf1b0c7be6dae4358c8', 'message': '[ussuri] Migrate to content provider jobs/templates\n\nThis change migrate jobs/templates to content provider\njobs so consumer jobs can use resources built by provider\njobs.\n\nDepends-On: https://review.opendev.org/#/c/763633\nDepends-On: https://review.opendev.org/c/openstack/openstack-tempest-skiplist/+/763864\nChange-Id: I415799279d83ff386c16363fdfab2f7e32e5edc6\nSigned-off-by: Amol Kahat <amolkahat@gmail.com>\n'}]",9,757544,5b553b611aec5e785746fdf1b0c7be6dae4358c8,123,12,17,30750,,,0,"[ussuri] Migrate to content provider jobs/templates

This change migrate jobs/templates to content provider
jobs so consumer jobs can use resources built by provider
jobs.

Depends-On: https://review.opendev.org/#/c/763633
Depends-On: https://review.opendev.org/c/openstack/openstack-tempest-skiplist/+/763864
Change-Id: I415799279d83ff386c16363fdfab2f7e32e5edc6
Signed-off-by: Amol Kahat <amolkahat@gmail.com>
",git fetch https://review.opendev.org/openstack/tripleo-heat-templates refs/changes/44/757544/16 && git format-patch -1 --stdout FETCH_HEAD,['zuul.d/layout.yaml'],1,e9e31fd8686b460a54812059969e909dc8fd35b9,new-ci-job, - tripleo-undercloud-jobs-pipeline - tripleo-multinode-container-minimal-pipeline - tripleo-standalone-scenarios-pipeline - tripleo-standalone-multinode-ipa-pipeline - openstack-tox-tht - tripleo-ci-centos-8-content-provider: - tripleo-ci-centos-8-standalone, - tripleo-undercloud-jobs - tripleo-multinode-container-minimal - tripleo-standalone-scenarios-full - tripleo-standalone-multinode-ipa - tripleo-ci-centos-8-containers-multinode: - tripleo-ci-centos-8-standalone: dependencies: *deps_unit_lint - tripleo-ci-centos-8-scenario001-standalone: dependencies: *deps_unit_lint - tripleo-ci-centos-8-scenario002-standalone: dependencies: *deps_unit_lint - tripleo-ci-centos-8-scenario003-standalone: dependencies: *deps_unit_lint - tripleo-ci-centos-8-scenario004-standalone: dependencies: *deps_unit_lint - tripleo-ci-centos-8-scenario012-standalone: dependencies: *deps_unit_lint - tripleo-ci-centos-8-containers-undercloud-minion: dependencies: *deps_unit_lint - openstack-tox-tht,7,20
openstack%2Ftripleo-heat-templates~master~I7f583d18e558b95922a66eb539cc91de74409c96,openstack/tripleo-heat-templates,master,I7f583d18e558b95922a66eb539cc91de74409c96,Use bind mounts for tls certificates,MERGED,2020-10-30 09:47:34.000000000,2020-11-27 13:17:16.000000000,2020-11-08 00:59:38.000000000,"[{'_account_id': 7353}, {'_account_id': 9914}, {'_account_id': 14985}, {'_account_id': 17216}, {'_account_id': 20172}, {'_account_id': 20733}, {'_account_id': 22348}, {'_account_id': 23181}, {'_account_id': 23811}]","[{'number': 1, 'created': '2020-10-30 09:47:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/15acd448cae5c01901aa791a5a11a10b2d021bde', 'message': 'Handle nbd tls certificates for upgrade path to UseTLSTransportForNbd=True\n\nWith adding UseTLSTransportForNbd feature in stein, UseTLSTransportForNbd\nis enabled per default. If an environment gets upgraded where\nUseTLSTransportForNbd was not enabled will make live migration to fail\nas the required certs are not part of the env of the previously created\nqemu process containers.\nThis change creates the required certificates for UseTLSTransportForNbd even\nif UseTLSTransportForNbd is set to False. With this UseTLSTransportForNbd\ncan be enabled/disabled as the required bind mounts are already present.\nThis change also moves adding certificates into the libvirt container using\nbind mounts instead of kolla merge mechanism. This allows us todo the above\nwithout stop/start of the instances.\n\nChange-Id: I7f583d18e558b95922a66eb539cc91de74409c96\n'}, {'number': 2, 'created': '2020-10-30 09:52:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/03772611aa8c350a199cf6b58fda406fe44cc092', 'message': 'Handle nbd tls certificates for upgrade path to UseTLSTransportForNbd=True\n\nWith adding UseTLSTransportForNbd feature in stein, UseTLSTransportForNbd\nis enabled per default. If an environment gets upgraded where\nUseTLSTransportForNbd was not enabled will make live migration to fail\nas the required certs are not part of the env of the previously created\nqemu process containers.\nThis change creates the required certificates for UseTLSTransportForNbd even\nif UseTLSTransportForNbd is set to False. With this UseTLSTransportForNbd\ncan be enabled/disabled as the required bind mounts are already present.\nThis change also moves adding certificates into the libvirt container using\nbind mounts instead of kolla merge mechanism. This allows us todo the above\nwithout stop/start of the instances.\n\nRelated-Bug: #1900986\nRelated: https://bugzilla.redhat.com/show_bug.cgi?id=1888951\n\nDepends-On: I9538b7e579d4921b14f6ef5eec0300e7e50628d4\n\nChange-Id: I7f583d18e558b95922a66eb539cc91de74409c96\n'}, {'number': 3, 'created': '2020-11-02 08:10:21.000000000', 'files': ['deployment/nova/nova-libvirt-container-puppet.yaml', 'releasenotes/notes/libvirtd_use_bind_mounts_for_certs-64cb88f78538a64b.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/e07e571ba205097a23d9dc4e1fb9a6645351c248', 'message': 'Use bind mounts for tls certificates\n\nCertificates get merged into the containers using kolla_config\nmechanism. If a certificate changes, or e.g. UseTLSTransportForNbd\ngets disabled and enabled at a later point the containers running\nthe qemu process miss the required certificates and live migration\nfails.\nThis change moves to use bind mount for the certificates and in\ncase of UseTLSTransportForNbd ans creates the required certificates even\nif UseTLSTransportForNbd is set to False. With this UseTLSTransportForNbd\ncan be enabled/disabled as the required bind mounts/certificates\nare already present.\n\nRelated-Bug: #1900986\nRelated: https://bugzilla.redhat.com/show_bug.cgi?id=1888951\n\nDepends-On: I9538b7e579d4921b14f6ef5eec0300e7e50628d4\n\nChange-Id: I7f583d18e558b95922a66eb539cc91de74409c96\n'}]",0,760522,e07e571ba205097a23d9dc4e1fb9a6645351c248,22,9,3,17216,,,0,"Use bind mounts for tls certificates

Certificates get merged into the containers using kolla_config
mechanism. If a certificate changes, or e.g. UseTLSTransportForNbd
gets disabled and enabled at a later point the containers running
the qemu process miss the required certificates and live migration
fails.
This change moves to use bind mount for the certificates and in
case of UseTLSTransportForNbd ans creates the required certificates even
if UseTLSTransportForNbd is set to False. With this UseTLSTransportForNbd
can be enabled/disabled as the required bind mounts/certificates
are already present.

Related-Bug: #1900986
Related: https://bugzilla.redhat.com/show_bug.cgi?id=1888951

Depends-On: I9538b7e579d4921b14f6ef5eec0300e7e50628d4

Change-Id: I7f583d18e558b95922a66eb539cc91de74409c96
",git fetch https://review.opendev.org/openstack/tripleo-heat-templates refs/changes/22/760522/1 && git format-patch -1 --stdout FETCH_HEAD,"['deployment/nova/nova-libvirt-container-puppet.yaml', 'releasenotes/notes/libvirtd_handle_nbd_tls_enable-64cb88f78538a64b.yaml']",2,15acd448cae5c01901aa791a5a11a10b2d021bde,1888951-master,--- fixes: - | UseTLSTransportForNbd is enabled per default. If an environment gets upgraded where UseTLSTransportForNbd was not enabled will make live migration to fail as the required certs are not part of the env of the previously created qemu process containers. This change creates the required certificates for UseTLSTransportForNbd even if UseTLSTransportForNbd is set to False. With this UseTLSTransportForNbd can be enabled/disabled as the required bind mounts are already present. This change also moves adding certificates into the libvirt container using bind mounts instead of kolla merge mechanism. This allows us todo the above without stop/start of the instances. ,,79,102
