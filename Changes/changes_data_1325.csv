id,project,branch,change_id,subject,status,created,updated,submitted,reviewers,revisions,total_comment_count,number,current_revision,discussion_messages_count,reviewers_count,revisions_count,owner_account_id,owner_name,owner_username,is_owner_bot,commit_message,git_command,changed_files,files_count,commit_id,topic,added_lines,deleted_lines,insertions,deletions
openstack%2Fswift~master~I133b6ecf16e0ef58425dc9b0afd0fb9d54f58b43,openstack/swift,master,I133b6ecf16e0ef58425dc9b0afd0fb9d54f58b43,fixed mispelling in function call name - accross to across,ABANDONED,2014-03-07 17:44:43.000000000,2014-03-07 17:55:59.000000000,,"[{'_account_id': 3}, {'_account_id': 2622}]","[{'number': 1, 'created': '2014-03-07 17:44:43.000000000', 'files': ['transferred', 'administrator', 'occurred', 'test/unit/proxy/test_server.py', 'bandwidth', 'omitted', 'canonical', ""doesn't"", 'dependent', 'Putting', 'referred'], 'web_link': 'https://opendev.org/openstack/swift/commit/091c4094562aea3f9ab21c112f09b490a8f07995', 'message': 'fixed mispelling in function call name - accross to across\n\nChange-Id: I133b6ecf16e0ef58425dc9b0afd0fb9d54f58b43\n'}]",0,79026,091c4094562aea3f9ab21c112f09b490a8f07995,3,2,1,9335,,,0,"fixed mispelling in function call name - accross to across

Change-Id: I133b6ecf16e0ef58425dc9b0afd0fb9d54f58b43
",git fetch https://review.opendev.org/openstack/swift refs/changes/26/79026/1 && git format-patch -1 --stdout FETCH_HEAD,"['administrator', 'transferred', 'occurred', 'test/unit/proxy/test_server.py', 'bandwidth', 'omitted', 'canonical', ""doesn't"", 'dependent', 'Putting', 'referred']",11,091c4094562aea3f9ab21c112f09b490a8f07995,,,,2,2
openstack%2Fopenstack-manuals~master~Ib33d77fce109b0a4598bd71f501bd3d9f677174e,openstack/openstack-manuals,master,Ib33d77fce109b0a4598bd71f501bd3d9f677174e,Fix spelling errors - commited to committed,MERGED,2014-03-07 17:29:28.000000000,2014-03-07 17:55:01.000000000,2014-03-07 17:55:00.000000000,"[{'_account_id': 3}, {'_account_id': 6547}]","[{'number': 1, 'created': '2014-03-07 17:29:28.000000000', 'files': ['doc/training-guides/operator-editing-code.xml'], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/81babf1736fd94a66b6a2104554d53d2d85c9a16', 'message': 'Fix spelling errors - commited to committed\n\nChange-Id: Ib33d77fce109b0a4598bd71f501bd3d9f677174e\n'}]",0,79019,81babf1736fd94a66b6a2104554d53d2d85c9a16,6,2,1,9335,,,0,"Fix spelling errors - commited to committed

Change-Id: Ib33d77fce109b0a4598bd71f501bd3d9f677174e
",git fetch https://review.opendev.org/openstack/openstack-manuals refs/changes/19/79019/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/training-guides/operator-editing-code.xml'],1,81babf1736fd94a66b6a2104554d53d2d85c9a16,," <para>Build committed changes locally by using <command>tox</command>. As part of the review process, <para>Build committed changes locally using <command>tox</command>. As part of the review process,"," <para>Build commited changes locally by using <command>tox</command>. As part of the review process, <para>Build commited changes locally using <command>tox</command>. As part of the review process,",2,2
openstack%2Fsolum~master~Ia74c955ae94eccd42be43ed4bae26ebfc814bda3,openstack/solum,master,Ia74c955ae94eccd42be43ed4bae26ebfc814bda3,Add the project_id to the app build path,MERGED,2014-03-04 07:07:17.000000000,2014-03-07 17:53:55.000000000,2014-03-07 17:53:55.000000000,"[{'_account_id': 3}, {'_account_id': 668}, {'_account_id': 4715}, {'_account_id': 7858}, {'_account_id': 8334}, {'_account_id': 8443}, {'_account_id': 9095}]","[{'number': 1, 'created': '2014-03-04 07:07:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/solum/commit/34c42499b74bd9f98772d3117dd0126232a661e3', 'message': 'Add the project_id to the app build path\n\nThis is so app ""X"" from two different projects don\'t\nconflict.\n\nChange-Id: Ia74c955ae94eccd42be43ed4bae26ebfc814bda3\n'}, {'number': 2, 'created': '2014-03-07 07:19:05.000000000', 'files': ['contrib/lp-cedarish/docker/README.md', 'contrib/lp-cedarish/docker/build-app'], 'web_link': 'https://opendev.org/openstack/solum/commit/3ccde36c16ee935d02b05b54428561976380160d', 'message': 'Add the project_id to the app build path\n\nThis is so app ""X"" from two different projects don\'t\nconflict.\n\nChange-Id: Ia74c955ae94eccd42be43ed4bae26ebfc814bda3\n'}]",1,77804,3ccde36c16ee935d02b05b54428561976380160d,15,7,2,4715,,,0,"Add the project_id to the app build path

This is so app ""X"" from two different projects don't
conflict.

Change-Id: Ia74c955ae94eccd42be43ed4bae26ebfc814bda3
",git fetch https://review.opendev.org/openstack/solum refs/changes/04/77804/2 && git format-patch -1 --stdout FETCH_HEAD,"['contrib/lp-cedarish/docker/README.md', 'contrib/lp-cedarish/docker/build-app']",2,34c42499b74bd9f98772d3117dd0126232a661e3,buildscripts,"if [[ -z $1 ]] || [[ -z $2 ]] || [[ -z $3 ]]; then echo ""Usage: build git_url appname project_id""PROJ=$3 APP_DIR=/opt/solum/apps/$PROJ/$APP mkdir -p $APP_DIR [[ -d $APP_DIR/build ]] && rm -rf $APP_DIR/build git clone $GIT $APP_DIR/build cd $APP_DIR/buildBUILD_ID=$(git archive master | docker run -i -a stdin \cd $APP_DIR sudo docker cp $BUILD_ID:/tmp/slug.tgz $APP_DIR/rm -rf $APP_DIR/buildcat << EOF > $APP_DIR/Dockerfilecd $APP_DIR","if [[ -z $1 ]] || [[ -z $2 ]]; then echo ""Usage: build git_url appname"" mkdir -p /opt/solum/apps/$APP [[ -d /opt/solum/apps/$APP/build ]] && rm -rf /opt/solum/apps/$APP/build git clone $GIT /opt/solum/apps/$APP/build cd /opt/solum/apps/$APP/buildBUILD_ID=$(git archive master | sudo docker run -i -a stdin \cd /opt/solum/apps/$APP sudo docker cp $BUILD_ID:/tmp/slug.tgz /opt/solum/apps/$APP/rm -rf /opt/solum/apps/$APP/buildcat << EOF > /opt/solum/apps/$APP/Dockerfilecd /opt/solum/apps/$APP ",19,18
openstack%2Fpython-keystoneclient~master~I3499fdf87b49b7499c525465ccd947edfa5cec6d,openstack/python-keystoneclient,master,I3499fdf87b49b7499c525465ccd947edfa5cec6d,improve configuration help text in auth_token,MERGED,2014-03-06 16:23:53.000000000,2014-03-07 17:50:52.000000000,2014-03-07 17:50:52.000000000,"[{'_account_id': 3}, {'_account_id': 4}, {'_account_id': 2218}, {'_account_id': 6486}, {'_account_id': 7191}]","[{'number': 1, 'created': '2014-03-06 16:23:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-keystoneclient/commit/09bd3bf2e754f045a839accffbf683c148028ce2', 'message': 'improve configuration help text in auth_token\n\nRelated-Bug: 1287301\nChange-Id: I3499fdf87b49b7499c525465ccd947edfa5cec6d\n'}, {'number': 2, 'created': '2014-03-06 16:25:33.000000000', 'files': ['keystoneclient/middleware/auth_token.py'], 'web_link': 'https://opendev.org/openstack/python-keystoneclient/commit/813f80cab84b436d42f3d7909957348b25bc34c2', 'message': 'improve configuration help text in auth_token\n\nRelated-Bug: 1287301\nChange-Id: I3499fdf87b49b7499c525465ccd947edfa5cec6d\n'}]",0,78650,813f80cab84b436d42f3d7909957348b25bc34c2,11,5,2,4,,,0,"improve configuration help text in auth_token

Related-Bug: 1287301
Change-Id: I3499fdf87b49b7499c525465ccd947edfa5cec6d
",git fetch https://review.opendev.org/openstack/python-keystoneclient refs/changes/50/78650/1 && git format-patch -1 --stdout FETCH_HEAD,"['keystoneclient/tests/functional/__init__.py', 'keystoneclient/tests/functional/test_auth_token_middleaware.py', 'repro_bug_1287301.py', 'keystoneclient/middleware/auth_token.py']",4,09bd3bf2e754f045a839accffbf683c148028ce2,bug/1287301," help='Optionally specify a list of memcached server(s) to' ' use for caching. If left undefined, tokens will instead be' ' cached in-process.'), help='In order to prevent excessive effort spent validating' ' tokens, the middleware caches previously-seen tokens for a' ' configurable duration (in seconds). Set to -1 to disable' ' caching completely.'), help='Determines the frequency at which the list of revoked' ' tokens is retrieved from the Identity service (in seconds). A' ' high number of revocation events combined with a low cache' ' duration may significantly reduce performance.'),"," help='If defined, the memcache server(s) to use for caching'), help='In order to prevent excessive requests and validations,' ' the middleware uses an in-memory cache for the tokens the' ' Keystone API returns. This is only valid if memcached_servers' ' is defined. Set to -1 to disable caching completely.'), help='Value only used for unit testing'),",183,6
openstack%2Fopenstack-manuals~master~I2ee596f6e40986e33ccbdc606220d755c249c4d3,openstack/openstack-manuals,master,I2ee596f6e40986e33ccbdc606220d755c249c4d3,Fix Spelling Error in documentation,MERGED,2014-03-07 17:27:20.000000000,2014-03-07 17:50:19.000000000,2014-03-07 17:50:18.000000000,"[{'_account_id': 3}, {'_account_id': 6547}]","[{'number': 1, 'created': '2014-03-07 17:27:20.000000000', 'files': ['doc/security-guide/ch020_ssl-everywhere.xml'], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/61c93bd3c712a9f246f7e3798612480864302683', 'message': 'Fix Spelling Error in documentation\n\nChange-Id: I2ee596f6e40986e33ccbdc606220d755c249c4d3\n'}]",0,79017,61c93bd3c712a9f246f7e3798612480864302683,5,2,1,9335,,,0,"Fix Spelling Error in documentation

Change-Id: I2ee596f6e40986e33ccbdc606220d755c249c4d3
",git fetch https://review.opendev.org/openstack/openstack-manuals refs/changes/17/79017/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/security-guide/ch020_ssl-everywhere.xml'],1,61c93bd3c712a9f246f7e3798612480864302683,," <para>No MD5. MD5 is not collision resistant, and thus not acceptable for Message Authentication Codes (MAC) or signatures.</para>"," <para>No MD5. MD5 is not collision resistent, and thus not acceptable for Message Authentication Codes (MAC) or signatures.</para>",1,1
openstack%2Ffuel-docs~master~I35250145cac558c28b882b0f83b73b3ab61991bc,openstack/fuel-docs,master,I35250145cac558c28b882b0f83b73b3ab61991bc,"7 March, xrefs for features, xref format",MERGED,2014-03-06 22:01:02.000000000,2014-03-07 17:46:12.000000000,2014-03-07 17:46:12.000000000,"[{'_account_id': 3}, {'_account_id': 406}, {'_account_id': 8787}, {'_account_id': 8971}, {'_account_id': 10014}]","[{'number': 1, 'created': '2014-03-06 22:01:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-docs/commit/6fec17efc307a6b07b06938c0795edee30ab676a', 'message': '7 March, xrefs for features, xref format\n\nChange-Id: I35250145cac558c28b882b0f83b73b3ab61991bc\n'}, {'number': 2, 'created': '2014-03-07 09:40:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-docs/commit/f9c121a3fc14b0eec0a7bc370f4c14394d0796ad', 'message': '7 March, xrefs for features, xref format\n\nalso changed some quantum strings to neutron\n\nChange-Id: I35250145cac558c28b882b0f83b73b3ab61991bc\n'}, {'number': 3, 'created': '2014-03-07 17:35:02.000000000', 'files': ['pages/release-notes/v4-1/020-new-features.rst', 'pages/release-notes/v4-1/040-resolved-issues.rst', 'pages/reference-architecture/0060-quantum-vs-nova-network.rst', 'pages/reference-architecture/0020-logical-setup.rst', 'pages/install-guide/0000-intro.rst', 'pages/release-notes/v4-1-havana-full.rst'], 'web_link': 'https://opendev.org/openstack/fuel-docs/commit/73dd0ef125af7dad6d776d53b6498df675abcc77', 'message': '7 March, xrefs for features, xref format\n\nalso changed some quantum strings to neutron\nupdated supported software list\n\nChange-Id: I35250145cac558c28b882b0f83b73b3ab61991bc\n'}]",0,78785,73dd0ef125af7dad6d776d53b6498df675abcc77,22,5,3,10014,,,0,"7 March, xrefs for features, xref format

also changed some quantum strings to neutron
updated supported software list

Change-Id: I35250145cac558c28b882b0f83b73b3ab61991bc
",git fetch https://review.opendev.org/openstack/fuel-docs refs/changes/85/78785/1 && git format-patch -1 --stdout FETCH_HEAD,"['pages/release-notes/v4-1/020-new-features.rst', 'pages/release-notes/v4-1/040-resolved-issues.rst', 'pages/release-notes/v4-1-havana-full.rst']",3,6fec17efc307a6b07b06938c0795edee30ab676a,lastmin41,| 4.1 | 07-Mar-2014 | Initial G.A. |,| 4.1 | 04-Mar-2014 | Initial G.A. |,13,5
openstack%2Ffuel-docs~master~I9411b6097918ac431e8c1ebd0a5546b2a110070b,openstack/fuel-docs,master,I9411b6097918ac431e8c1ebd0a5546b2a110070b,correct Ceilometer info for 4.1,MERGED,2014-03-07 17:25:09.000000000,2014-03-07 17:37:03.000000000,2014-03-07 17:37:03.000000000,"[{'_account_id': 3}, {'_account_id': 8787}, {'_account_id': 8971}]","[{'number': 1, 'created': '2014-03-07 17:25:09.000000000', 'files': ['pages/user-guide/ceilometer.rst'], 'web_link': 'https://opendev.org/openstack/fuel-docs/commit/3f2feeb59b6b4e60e8b09f6575f91f360cfc05d9', 'message': 'correct Ceilometer info for 4.1\n\nChange-Id: I9411b6097918ac431e8c1ebd0a5546b2a110070b\n'}]",0,79016,3f2feeb59b6b4e60e8b09f6575f91f360cfc05d9,8,3,1,10014,,,0,"correct Ceilometer info for 4.1

Change-Id: I9411b6097918ac431e8c1ebd0a5546b2a110070b
",git fetch https://review.opendev.org/openstack/fuel-docs refs/changes/16/79016/1 && git format-patch -1 --stdout FETCH_HEAD,['pages/user-guide/ceilometer.rst'],1,3f2feeb59b6b4e60e8b09f6575f91f360cfc05d9,ceilo41,"Fuel can deploy the OpenStack Telemetry component *Ceilometer*. When enabled, Ceilometer collects and shares measurement data gathered from all OpenStack components. This data cam be used for monitoringCeilometer's REST API can also provide data to external monitoring software for a customer's billing system.To install Ceilometer with Fuel, check the appropriate box when configuring your environment.Ceilometer can be configured to collect a large amount of metering data and thus perform a high volume of database writes. For example, with a short polling cycle, one could see up to 13000 writes per hour for an environment with 400 instances inside the cloud. In Fuel 4.x, Ceilometer uses only the common MySQL database, thus we do not recommend deploying standard Ceilometer for large production installations.","Fuel has the ability to deploy OpenStack Telemetry component *Ceilometer*. The main aim of Ceilometer is to collect and share measurement data gathered from all OpenStack components. This data could be used for monitoringCeilometer's REST API could also serve as source of data for external monitoring software of customer's billing system.Ceilometer can be installed in Fuel by checking the appropriate check box when configuring your environment. Ceilometer is supported by CentOS and Ubuntu.Ceilometer collects a number of metering data and performs a high volume of database writes. It could be up to 13000 writes per hour for only 400 resources inside the cloud. In Fuel 4.x, Ceilometer uses only the common MySQL database, thus we do not recommend to deploy standard Ceilometer for large production installations. Also please note that Notification bus support for Ceilometer is not a part of 4.0 release because of a number of issues with the MySQl backend [1]_ [2]_. Implementation is planned in 4.1. Horizon Metering Panel disabled in 4.x. This panel requires the *metadata_query*. Ceilometer feature that is not supported by Ceilometer with MySQL driver [3]_. A significant portion of the Metering panel is removed in the Havana release because this part displays inconsistent data. [4]_. * Official Ceilometer `documentation <http://docs.openstack.org/developer/ceilometer/>`_ can be found here. * Mirantis `blog <http://www.mirantis.com/blog/openstack-metering-using-ceilometer/>`_ about monitoring and Ceilometer. .. [1] https://bugs.launchpad.net/ceilometer/havana/+bug/1255107 .. [2] https://bugs.launchpad.net/ceilometer/+bug/1257908 .. [3] https://github.com/openstack/ceilometer/blob/stable/havana/doc/source/install/dbreco.rst .. [4] https://review.openstack.org/#/c/60317/",14,29
openstack%2Ffuel-docs~master~I1a0d4b26b36abbb4991e951f13aa6bf24db7391a,openstack/fuel-docs,master,I1a0d4b26b36abbb4991e951f13aa6bf24db7391a,update supported software list,ABANDONED,2014-02-25 16:45:59.000000000,2014-03-07 17:36:13.000000000,,"[{'_account_id': 3}, {'_account_id': 406}, {'_account_id': 8787}, {'_account_id': 8789}, {'_account_id': 8967}, {'_account_id': 8971}, {'_account_id': 10014}]","[{'number': 1, 'created': '2014-02-25 16:45:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-docs/commit/d99bb3b6e04ae8457df29e9812722ce1036cb247', 'message': 'update supported software list\n\nChange-Id: I1a0d4b26b36abbb4991e951f13aa6bf24db7391a\n'}, {'number': 2, 'created': '2014-02-25 20:34:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-docs/commit/f06fe6b67502058209fa30b54f8402c0f11b00e4', 'message': 'update supported software list\n\nChange-Id: I1a0d4b26b36abbb4991e951f13aa6bf24db7391a\n'}, {'number': 3, 'created': '2014-03-07 17:33:02.000000000', 'files': ['pages/install-guide/0000-intro.rst'], 'web_link': 'https://opendev.org/openstack/fuel-docs/commit/af46116909d7d1daafdeefda81b1119af433072d', 'message': 'update supported software list\n\nChange-Id: I1a0d4b26b36abbb4991e951f13aa6bf24db7391a\n'}]",2,76255,af46116909d7d1daafdeefda81b1119af433072d,23,7,3,10014,,,0,"update supported software list

Change-Id: I1a0d4b26b36abbb4991e951f13aa6bf24db7391a
",git fetch https://review.opendev.org/openstack/fuel-docs refs/changes/55/76255/3 && git format-patch -1 --stdout FETCH_HEAD,['pages/install-guide/0000-intro.rst'],1,d99bb3b6e04ae8457df29e9812722ce1036cb247,41final,10. index:: Introduction * Havana Release 2013.2.2 * Murano v0.4.1* **mySQL** (v5.5.28) * **Pacemaker** 1.1.10 * **Corosync** 1.4.6* **Ceph Dumpling** (v0.67.5),".. index:: Introduction * RHEL 6.4 (x86_64 architecture only) * Havana Release 2013.2.1 * Murano v0.4* **Pacemaker** 1.1.8 * **Corosync** 1.4.3 (CentOS), 1.4.4 (Ubuntu)* **Ceph Dumpling** (v0.67) * **mySQL** (v5.5.28)",8,9
openstack%2Ffuel-docs~master~I180988a81f19562abad0201e1b6b4fb2ed519249,openstack/fuel-docs,master,I180988a81f19562abad0201e1b6b4fb2ed519249,Removed hardcoded tenant name issue from known issues,MERGED,2014-03-07 16:37:11.000000000,2014-03-07 17:26:00.000000000,2014-03-07 17:26:00.000000000,"[{'_account_id': 3}, {'_account_id': 8787}, {'_account_id': 8971}]","[{'number': 1, 'created': '2014-03-07 16:37:11.000000000', 'files': ['pages/release-notes/v4-1/050-known-issues.rst'], 'web_link': 'https://opendev.org/openstack/fuel-docs/commit/429e118497a1f975d2ff65bb4c7efbe33138ea54', 'message': 'Removed hardcoded tenant name issue from known issues\n\nChange-Id: I180988a81f19562abad0201e1b6b4fb2ed519249\n'}]",0,79004,429e118497a1f975d2ff65bb4c7efbe33138ea54,8,3,1,406,,,0,"Removed hardcoded tenant name issue from known issues

Change-Id: I180988a81f19562abad0201e1b6b4fb2ed519249
",git fetch https://review.opendev.org/openstack/fuel-docs refs/changes/04/79004/1 && git format-patch -1 --stdout FETCH_HEAD,['pages/release-notes/v4-1/050-known-issues.rst'],1,429e118497a1f975d2ff65bb4c7efbe33138ea54,,,"Hardcoded ""admin"" tenant breaks Neutron default networks -------------------------------------------------------- Neutron default networks (net04 and net04-ext) are now properly created if a user changes the name of the default tenant. See `LP12267431 <https://bugs.launchpad.net/fuel/+bug/1267431>`_. ",0,7
openstack%2Fpuppet-neutron~stable%2Fhavana~Id8c116212132b6d75ae14019fc6a65447f226c6d,openstack/puppet-neutron,stable/havana,Id8c116212132b6d75ae14019fc6a65447f226c6d,Don't sync database by default,MERGED,2014-03-07 08:20:05.000000000,2014-03-07 17:20:46.000000000,2014-03-07 17:20:46.000000000,"[{'_account_id': 3}, {'_account_id': 1918}, {'_account_id': 3153}, {'_account_id': 6967}, {'_account_id': 7156}]","[{'number': 1, 'created': '2014-03-07 08:20:05.000000000', 'files': ['spec/classes/neutron_server_spec.rb', 'manifests/server.pp'], 'web_link': 'https://opendev.org/openstack/puppet-neutron/commit/e4e8c6292150585796ebe89788b1597ec7920b37', 'message': ""Don't sync database by default\n\nhttps://review.openstack.org/#/c/76358 introduced a new sync_db\nparameter and set it to true by default.  Unfortunately there\nseem to be many cases where this causes problems.  One is when\nusing the OVS plugin with the [database] section stored in\nneutron.conf rather than in the ovs_neutron_plugin.ini file.\nIn such cases the migration will error out with due to being\nunable to connect.  This is particularly problematic for users\nin that no changes to the composition layer are necessary to\nhit the error since sync_db is set to true by default: to avoid\nthe problem they need to make composition layer change to explicitly\nset it to false.  This patch resolves the problem by setting the\nparameter to false by default rather than true.  This enables\nusers who want the migration to run to do so without impacting\nusers who haven't been expecting the new behavior.\n\nThis patch is based on 0229d358ae45add73a0a8f4658632b54fd56be12\nfrom master but is modified slightly to account for a change\nin the rspec tests to use the havana instead of head during\nthe dbsync.\n\nConflicts:\n\n\tspec/classes/neutron_server_spec.rb\n\nChange-Id: Id8c116212132b6d75ae14019fc6a65447f226c6d\nCloses-Bug: #1288975\n(cherry picked from commit 0229d358ae45add73a0a8f4658632b54fd56be12)\n""}]",0,78898,e4e8c6292150585796ebe89788b1597ec7920b37,8,5,1,6754,,,0,"Don't sync database by default

https://review.openstack.org/#/c/76358 introduced a new sync_db
parameter and set it to true by default.  Unfortunately there
seem to be many cases where this causes problems.  One is when
using the OVS plugin with the [database] section stored in
neutron.conf rather than in the ovs_neutron_plugin.ini file.
In such cases the migration will error out with due to being
unable to connect.  This is particularly problematic for users
in that no changes to the composition layer are necessary to
hit the error since sync_db is set to true by default: to avoid
the problem they need to make composition layer change to explicitly
set it to false.  This patch resolves the problem by setting the
parameter to false by default rather than true.  This enables
users who want the migration to run to do so without impacting
users who haven't been expecting the new behavior.

This patch is based on 0229d358ae45add73a0a8f4658632b54fd56be12
from master but is modified slightly to account for a change
in the rspec tests to use the havana instead of head during
the dbsync.

Conflicts:

	spec/classes/neutron_server_spec.rb

Change-Id: Id8c116212132b6d75ae14019fc6a65447f226c6d
Closes-Bug: #1288975
(cherry picked from commit 0229d358ae45add73a0a8f4658632b54fd56be12)
",git fetch https://review.opendev.org/openstack/puppet-neutron refs/changes/98/78898/1 && git format-patch -1 --stdout FETCH_HEAD,"['spec/classes/neutron_server_spec.rb', 'manifests/server.pp']",2,e4e8c6292150585796ebe89788b1597ec7920b37,,"# Defaults to false $sync_db = false,","# Defaults to true $sync_db = true,",13,13
openstack%2Fceilometer~master~Ib41dcde6e5f32755ababf9227827aa8368399c9a,openstack/ceilometer,master,Ib41dcde6e5f32755ababf9227827aa8368399c9a,Enable monkeypatch for select module,MERGED,2014-03-06 16:31:25.000000000,2014-03-07 17:10:35.000000000,2014-03-07 17:10:35.000000000,"[{'_account_id': 3}, {'_account_id': 1669}, {'_account_id': 2472}, {'_account_id': 2813}, {'_account_id': 6537}]","[{'number': 1, 'created': '2014-03-06 16:31:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/f816a90e4dfa4923926fb4d59b54df366c484fa5', 'message': 'Enable monkeypatch for select module\n\nWhen we use ceilometer with kombu (rabbitmq), sometimes when the server\nis gone and ceilometer tries to reconnect to it, the connection can hang.\n\nThis is because, ceilometer monkeypatch only socket and not select, or\nwhen kombu detect monkeypatching on the socket module, it assume the\nselect is monkeypatched too and use the real select.select on a eventlet\nsocket, and hang.\n\nCeilometer must enable monkeypatch for select too.\n\nChange-Id: Ib41dcde6e5f32755ababf9227827aa8368399c9a\nCloses-bug: 1288844\n'}, {'number': 2, 'created': '2014-03-06 16:49:32.000000000', 'files': ['ceilometer/service.py'], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/10300af4f55b179f7aea909a8d752ed4ac4c2d70', 'message': 'Enable monkeypatch for select module\n\nWhen we use ceilometer with kombu (rabbitmq), sometimes when the server\nis gone and ceilometer tries to reconnect to it, the connection can hang.\n\nThis is because, ceilometer monkeypatch only socket and not select, or\nwhen kombu detect monkeypatching on the socket module, it assume the\nselect is monkeypatched too and use the real select.select on a eventlet\nsocket, and hang.\n\nCeilometer must enable monkeypatch for select too.\n\nChange-Id: Ib41dcde6e5f32755ababf9227827aa8368399c9a\nCloses-bug: 1288844\n'}]",0,78654,10300af4f55b179f7aea909a8d752ed4ac4c2d70,22,5,2,2813,,,0,"Enable monkeypatch for select module

When we use ceilometer with kombu (rabbitmq), sometimes when the server
is gone and ceilometer tries to reconnect to it, the connection can hang.

This is because, ceilometer monkeypatch only socket and not select, or
when kombu detect monkeypatching on the socket module, it assume the
select is monkeypatched too and use the real select.select on a eventlet
socket, and hang.

Ceilometer must enable monkeypatch for select too.

Change-Id: Ib41dcde6e5f32755ababf9227827aa8368399c9a
Closes-bug: 1288844
",git fetch https://review.opendev.org/openstack/ceilometer refs/changes/54/78654/2 && git format-patch -1 --stdout FETCH_HEAD,['ceilometer/service.py'],1,f816a90e4dfa4923926fb4d59b54df366c484fa5,bug/1244698," # NOTE(jd) We need to monkey patch the socket and select module for, # at least, oslo.rpc, otherwise everything's blocked on its first read() # or select() eventlet.monkey_patch(socket=True, select=False)"," # NOTE(jd) We need to monkey patch the socket module for, at least, # oslo.rpc, otherwise everything's blocked on its first read() eventlet.monkey_patch(socket=True)",4,3
openstack%2Fpuppet-heat~stable%2Fhavana~I81fc650606c419d25a2e13dc2093c8e4538fb997,openstack/puppet-heat,stable/havana,I81fc650606c419d25a2e13dc2093c8e4538fb997,Aligns Keystone auth_uri with other OpenStack Services,MERGED,2014-03-07 16:27:58.000000000,2014-03-07 17:05:56.000000000,2014-03-07 17:05:56.000000000,"[{'_account_id': 3}, {'_account_id': 1918}, {'_account_id': 3153}, {'_account_id': 6754}]","[{'number': 1, 'created': '2014-03-07 16:27:58.000000000', 'files': ['manifests/init.pp', 'spec/classes/heat_init_spec.rb'], 'web_link': 'https://opendev.org/openstack/puppet-heat/commit/8be2aff803f06c2e4b7f6050d53b548a00f8ea8b', 'message': 'Aligns Keystone auth_uri with other OpenStack Services\n\nPreviously, auth_uri had a default address of 127.0.0.1 as did\nthe keystone_host parameter.  This caused problems for users that\nuse a different IP address for Keystone.  This can cause issues\nwhere the keystone host is an actual address and the auth_uri still\nuses 127.0.0.1.  Additionally, this patch will allow the auth_uri\nbehavior to be consistent with the other OpenStack modules.\n\nConflicts:\n\n        manifests/init.pp\n        spec/classes/heat_init_spec.rb\n\nChange-Id: I81fc650606c419d25a2e13dc2093c8e4538fb997\n(cherry picked from commit 4a5a5849a5088290bf6a46a1e13406312af0b72c)\n'}]",0,79003,8be2aff803f06c2e4b7f6050d53b548a00f8ea8b,8,4,1,6836,,,0,"Aligns Keystone auth_uri with other OpenStack Services

Previously, auth_uri had a default address of 127.0.0.1 as did
the keystone_host parameter.  This caused problems for users that
use a different IP address for Keystone.  This can cause issues
where the keystone host is an actual address and the auth_uri still
uses 127.0.0.1.  Additionally, this patch will allow the auth_uri
behavior to be consistent with the other OpenStack modules.

Conflicts:

        manifests/init.pp
        spec/classes/heat_init_spec.rb

Change-Id: I81fc650606c419d25a2e13dc2093c8e4538fb997
(cherry picked from commit 4a5a5849a5088290bf6a46a1e13406312af0b72c)
",git fetch https://review.opendev.org/openstack/puppet-heat refs/changes/03/79003/1 && git format-patch -1 --stdout FETCH_HEAD,"['manifests/init.pp', 'spec/classes/heat_init_spec.rb']",2,8be2aff803f06c2e4b7f6050d53b548a00f8ea8b,stable/havana," :sql_connection => 'mysql://user@host/database', :auth_uri => 'http://127.0.0.1:5000/v2.0' it 'configures auth_uri' do should contain_heat_config('keystone_authtoken/auth_uri').with_value( params[:auth_uri] ) end shared_examples_for 'with auth uri set' do before do params.merge!( :auth_uri => 'http://1.2.3.4:35357/v2.0' ) end it do should contain_heat_config('keystone_authtoken/auth_uri').with_value('http://1.2.3.4:35357/v2.0') end end ", :sql_connection => 'mysql://user@host/database',29,3
openstack%2Fpuppet-heat~master~I81fc650606c419d25a2e13dc2093c8e4538fb997,openstack/puppet-heat,master,I81fc650606c419d25a2e13dc2093c8e4538fb997,Aligns Keystone auth_uri with other OpenStack Services,MERGED,2014-02-25 20:49:19.000000000,2014-03-07 17:00:59.000000000,2014-03-07 17:00:58.000000000,"[{'_account_id': 3}, {'_account_id': 1918}, {'_account_id': 3153}, {'_account_id': 6754}, {'_account_id': 6836}, {'_account_id': 6967}, {'_account_id': 7822}]","[{'number': 1, 'created': '2014-02-25 20:49:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-heat/commit/8fa7be6532e7b755089b63da7f1b9d5334c2692e', 'message': 'Aligns Keystone auth_uri with other OpenStack Services\n\nPreviously, auth_uri had a default address of 127.0.0.1 as did\nthe keystone_host parameter.  This caused problems for users that\nuse a different IP address for Keystone.  This can cause issues\nwhere the keystone host is an actual address and the auth_uri still\nuses 127.0.0.1.  Additionally, this patch will allow the auth_uri\nbehavior to be consistent with the other OpenStack modules.\n\nChange-Id: I81fc650606c419d25a2e13dc2093c8e4538fb997\n'}, {'number': 2, 'created': '2014-02-26 17:35:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-heat/commit/e361d7b6f3580567d78bcd4607415fabfcf3736c', 'message': 'Aligns Keystone auth_uri with other OpenStack Services\n\nPreviously, auth_uri had a default address of 127.0.0.1 as did\nthe keystone_host parameter.  This caused problems for users that\nuse a different IP address for Keystone.  This can cause issues\nwhere the keystone host is an actual address and the auth_uri still\nuses 127.0.0.1.  Additionally, this patch will allow the auth_uri\nbehavior to be consistent with the other OpenStack modules.\n\nChange-Id: I81fc650606c419d25a2e13dc2093c8e4538fb997\n'}, {'number': 3, 'created': '2014-03-04 18:37:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-heat/commit/7388f170e743ced662bdb8e02708a779f2b0b86f', 'message': 'Aligns Keystone auth_uri with other OpenStack Services\n\nPreviously, auth_uri had a default address of 127.0.0.1 as did\nthe keystone_host parameter.  This caused problems for users that\nuse a different IP address for Keystone.  This can cause issues\nwhere the keystone host is an actual address and the auth_uri still\nuses 127.0.0.1.  Additionally, this patch will allow the auth_uri\nbehavior to be consistent with the other OpenStack modules.\n\nChange-Id: I81fc650606c419d25a2e13dc2093c8e4538fb997\n'}, {'number': 4, 'created': '2014-03-07 16:04:53.000000000', 'files': ['manifests/init.pp', 'spec/classes/heat_init_spec.rb'], 'web_link': 'https://opendev.org/openstack/puppet-heat/commit/4a5a5849a5088290bf6a46a1e13406312af0b72c', 'message': 'Aligns Keystone auth_uri with other OpenStack Services\n\nPreviously, auth_uri had a default address of 127.0.0.1 as did\nthe keystone_host parameter.  This caused problems for users that\nuse a different IP address for Keystone.  This can cause issues\nwhere the keystone host is an actual address and the auth_uri still\nuses 127.0.0.1.  Additionally, this patch will allow the auth_uri\nbehavior to be consistent with the other OpenStack modules.\n\nConflicts:\n\n        spec/classes/heat_init_spec.rb\n\nChange-Id: I81fc650606c419d25a2e13dc2093c8e4538fb997\n'}]",3,76356,4a5a5849a5088290bf6a46a1e13406312af0b72c,30,7,4,6836,,,0,"Aligns Keystone auth_uri with other OpenStack Services

Previously, auth_uri had a default address of 127.0.0.1 as did
the keystone_host parameter.  This caused problems for users that
use a different IP address for Keystone.  This can cause issues
where the keystone host is an actual address and the auth_uri still
uses 127.0.0.1.  Additionally, this patch will allow the auth_uri
behavior to be consistent with the other OpenStack modules.

Conflicts:

        spec/classes/heat_init_spec.rb

Change-Id: I81fc650606c419d25a2e13dc2093c8e4538fb997
",git fetch https://review.opendev.org/openstack/puppet-heat refs/changes/56/76356/3 && git format-patch -1 --stdout FETCH_HEAD,['manifests/init.pp'],1,8fa7be6532e7b755089b63da7f1b9d5334c2692e,keystone_auth_uri," $auth_uri = false, if $auth_uri { heat_config { 'keystone_authtoken/auth_uri': value => $auth_uri; } } else { heat_config { 'keystone_authtoken/auth_uri': value => ""${keystone_protocol}://${keystone_host}:5000/v2.0""; } } "," $auth_uri = 'http://127.0.0.1:5000/v2.0', 'keystone_authtoken/auth_uri' : value => $auth_uri;",7,2
openstack%2Fsolum~master~I88871112fe01daf10e6804778ca501daf0ee3902,openstack/solum,master,I88871112fe01daf10e6804778ca501daf0ee3902,WIP: Git url validation,ABANDONED,2014-03-07 15:30:17.000000000,2014-03-07 16:53:21.000000000,,"[{'_account_id': 3}, {'_account_id': 2506}, {'_account_id': 9094}]","[{'number': 1, 'created': '2014-03-07 15:30:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/solum/commit/9c92adbc9887034f02d4355e285ed2349f7519f6', 'message': 'WIP: Git url validation\n\n* Checks length and url regex for security\n* Uses Oslo Config to obtain validation rules\n* Adds a new InvalidInput exception for these kinds of checks\n* Still needs unit tests added - seeking early feedback\n\nPartially implements: blueprint solum-input-validation\nhttps://blueprints.launchpad.net/solum/+spec/solum-input-validation\n\nChange-Id: I88871112fe01daf10e6804778ca501daf0ee3902\n'}, {'number': 2, 'created': '2014-03-07 16:51:33.000000000', 'files': ['solum/common/validate.py', 'solum/common/exception.py'], 'web_link': 'https://opendev.org/openstack/solum/commit/bdbc468d1050a828c6c474b0266e6d3a34080c71', 'message': 'WIP: Git url validation\n\n* Checks length and url regex for security\n* Uses Oslo Config to obtain validation rules\n* Adds a new InvalidInput exception for these kinds of checks\n* Still needs unit tests added - seeking early feedback\n\nPartially implements: blueprint solum-input-validation\nhttps://blueprints.launchpad.net/solum/+spec/solum-input-validation\n\nChange-Id: I88871112fe01daf10e6804778ca501daf0ee3902\n'}]",2,78990,bdbc468d1050a828c6c474b0266e6d3a34080c71,8,3,2,9094,,,0,"WIP: Git url validation

* Checks length and url regex for security
* Uses Oslo Config to obtain validation rules
* Adds a new InvalidInput exception for these kinds of checks
* Still needs unit tests added - seeking early feedback

Partially implements: blueprint solum-input-validation
https://blueprints.launchpad.net/solum/+spec/solum-input-validation

Change-Id: I88871112fe01daf10e6804778ca501daf0ee3902
",git fetch https://review.opendev.org/openstack/solum refs/changes/90/78990/1 && git format-patch -1 --stdout FETCH_HEAD,"['solum/common/exception.py', 'solum/common/validate.py']",2,9c92adbc9887034f02d4355e285ed2349f7519f6,bp/solum-input-validation,"# Copyright 2014 - Rackspace # # Licensed under the Apache License, Version 2.0 (the ""License""); you may # not use this file except in compliance with the License. You may obtain # a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT # WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the # License for the specific language governing permissions and limitations # under the License. import re from oslo.config import cfg from solum.common import exception CONF = cfg.CONF # Create Oslo Config input validation configuration in the 'validation' group. # git_url_regex may be configured to something like this to enable only github # urls: '^https?://github.com/[a-z/_-]+$' VALIDATION_OPTS = [ cfg.IntOpt('git_url_max_len', default=255, help='The longest git url acceptable'), cfg.StrOpt('git_url_regex', default='a^', # Reject all URLs by default for security help='The git url validation regex') ] OPT_GROUP = cfg.OptGroup(name='validation', title='User input validation settings') CONF.register_group(OPT_GROUP) CONF.register_opts(VALIDATION_OPTS, OPT_GROUP) def valid_git_url(url): """"""Validate a git url. Checks that the url isn't too long and that it matches a regex for security reasons. """""" if len(url) > CONF.validation.git_url_max_len: raise exception.InvalidInput(data_type='git url', problem='url is too long') if re.match(CONF.validation.git_url_regex, url) is None: raise exception.InvalidInput( data_type='git url', problem='url does not match expected pattern') ",,57,0
openstack%2Fnova~master~Id54f37931e6a8d3024744865f264dfba7ebcd04c,openstack/nova,master,Id54f37931e6a8d3024744865f264dfba7ebcd04c,Add method to shrink disk image,ABANDONED,2014-03-07 13:17:36.000000000,2014-03-07 16:37:09.000000000,,[{'_account_id': 3}],"[{'number': 1, 'created': '2014-03-07 13:17:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/45495a32a825768559cb65b77e14ad8f2a1f52d7', 'message': 'Add shrink mehod to disk.api\n\nChange-Id: Id54f37931e6a8d3024744865f264dfba7ebcd04c\n'}, {'number': 2, 'created': '2014-03-07 15:34:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/1694cde692e96ac05a5d81ccd598e542d85cfd74', 'message': ""Add shrink method to disk.api\n\nAdd a 'shrink' method to disk.api that provides a\nresizing disk down of an image.\n\nRelated to bleuprint libvirt-resize-disk-down\n\nChange-Id: Id54f37931e6a8d3024744865f264dfba7ebcd04c\n""}, {'number': 3, 'created': '2014-03-07 15:39:20.000000000', 'files': ['nova/tests/virt/disk/test_api.py', 'nova/virt/disk/api.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/6deb96f180388b9122e2f642b8309d27d2c257e2', 'message': ""Add method to shrink disk image\n\nAdd a 'shrink' method to disk.api that provides a\nresizing disk down of an image.\n\nRelated to bleuprint libvirt-resize-disk-down\n\nChange-Id: Id54f37931e6a8d3024744865f264dfba7ebcd04c\n""}]",0,78959,6deb96f180388b9122e2f642b8309d27d2c257e2,6,1,3,7730,,,0,"Add method to shrink disk image

Add a 'shrink' method to disk.api that provides a
resizing disk down of an image.

Related to bleuprint libvirt-resize-disk-down

Change-Id: Id54f37931e6a8d3024744865f264dfba7ebcd04c
",git fetch https://review.opendev.org/openstack/nova refs/changes/59/78959/3 && git format-patch -1 --stdout FETCH_HEAD,['nova/virt/disk/api.py'],1,45495a32a825768559cb65b77e14ad8f2a1f52d7,bp/libvirt-resize-disk-down,"def shrink(image, size, use_cow=False): """"""Skink image to size."""""" if (get_disk_size(image) <= size or not is_image_partitionless(image, use_cow)): return if use_cow: mounter = mount.Mount.instance_for_format( image, None, None, 'qcow2') if mounter.get_dev(): safe_resize2fs(mounter.device, size, run_as_root=True, finally_call=mounter.unget_dev) else: safe_resize2fs(mounter.device, size) utils.execute('qemu-img', 'resize', image, size) ",,19,0
openstack%2Fnova~master~I2e36180876872e756b55171e4903ec3cdfa1d1aa,openstack/nova,master,I2e36180876872e756b55171e4903ec3cdfa1d1aa,Make swap_volume code path use BDM objects,MERGED,2014-02-04 19:04:00.000000000,2014-03-07 16:31:04.000000000,2014-03-06 17:29:35.000000000,"[{'_account_id': 3}, {'_account_id': 688}, {'_account_id': 782}, {'_account_id': 4393}, {'_account_id': 4912}, {'_account_id': 5170}, {'_account_id': 5441}, {'_account_id': 5511}, {'_account_id': 9008}, {'_account_id': 9578}, {'_account_id': 9636}]","[{'number': 1, 'created': '2014-02-04 19:04:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/999facb7d1d631b7def57bfd0bc6f29727d45ac2', 'message': ""Make swap_volume code path use BDM objects\n\nThis patch makes the swap_volume compute manager method use new-world\nBDM objects internally. Sine this was the last place that used the\nhelper method _get_instance_volume_bdm, this method is now removed as\nit's functionality is completely supported by the new-world objects\ninterface.\n\nPart of blueprint: icehouse-objects\nPart of bluerprint: clean-up-legacy-block-device-mapping\n\nChange-Id: I2e36180876872e756b55171e4903ec3cdfa1d1aa\n""}, {'number': 2, 'created': '2014-02-06 10:23:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/63c82c3c5e0da4bc4c6febf13a06d4f48c883b89', 'message': ""Make swap_volume code path use BDM objects\n\nThis patch makes the swap_volume compute manager method use new-world\nBDM objects internally. Sine this was the last place that used the\nhelper method _get_instance_volume_bdm, this method is now removed as\nit's functionality is completely supported by the new-world objects\ninterface.\n\nPart of blueprint: icehouse-objects\nPart of bluerprint: clean-up-legacy-block-device-mapping\n\nChange-Id: I2e36180876872e756b55171e4903ec3cdfa1d1aa\n""}, {'number': 3, 'created': '2014-02-06 18:13:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/eb46c0d5bf3f2ae67d0da619a7dacb1455bfa9eb', 'message': ""Make swap_volume code path use BDM objects\n\nThis patch makes the swap_volume compute manager method use new-world\nBDM objects internally. Sine this was the last place that used the\nhelper method _get_instance_volume_bdm, this method is now removed as\nit's functionality is completely supported by the new-world objects\ninterface.\n\nPart of blueprint: icehouse-objects\nPart of bluerprint: clean-up-legacy-block-device-mapping\n\nChange-Id: I2e36180876872e756b55171e4903ec3cdfa1d1aa\n""}, {'number': 4, 'created': '2014-02-10 13:13:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/e58f6cffe58bc704964b325acc23d4e02db60ab1', 'message': ""Make swap_volume code path use BDM objects\n\nThis patch makes the swap_volume compute manager method use new-world\nBDM objects internally. Sine this was the last place that used the\nhelper method _get_instance_volume_bdm, this method is now removed as\nit's functionality is completely supported by the new-world objects\ninterface.\n\nPart of blueprint: icehouse-objects\nPart of bluerprint: clean-up-legacy-block-device-mapping\n\nChange-Id: I2e36180876872e756b55171e4903ec3cdfa1d1aa\n""}, {'number': 5, 'created': '2014-02-10 18:34:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/834ceaf3fa3c9303d128d8008462af6d63a985da', 'message': ""Make swap_volume code path use BDM objects\n\nThis patch makes the swap_volume compute manager method use new-world\nBDM objects internally. Sine this was the last place that used the\nhelper method _get_instance_volume_bdm, this method is now removed as\nit's functionality is completely supported by the new-world objects\ninterface.\n\nPart of blueprint: icehouse-objects\nPart of bluerprint: clean-up-legacy-block-device-mapping\n\nChange-Id: I2e36180876872e756b55171e4903ec3cdfa1d1aa\n""}, {'number': 6, 'created': '2014-02-10 21:08:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/eb4001da316bf1784014702c526fa9117ebfcbad', 'message': ""Make swap_volume code path use BDM objects\n\nThis patch makes the swap_volume compute manager method use new-world\nBDM objects internally. Sine this was the last place that used the\nhelper method _get_instance_volume_bdm, this method is now removed as\nit's functionality is completely supported by the new-world objects\ninterface.\n\nPart of blueprint: icehouse-objects\nPart of bluerprint: clean-up-legacy-block-device-mapping\n\nChange-Id: I2e36180876872e756b55171e4903ec3cdfa1d1aa\n""}, {'number': 7, 'created': '2014-02-17 17:17:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/25e3b29c1070dfc5e5bbe364ba704437d7fbc95b', 'message': ""Make swap_volume code path use BDM objects\n\nThis patch makes the swap_volume compute manager method use new-world\nBDM objects internally. Sine this was the last place that used the\nhelper method _get_instance_volume_bdm, this method is now removed as\nit's functionality is completely supported by the new-world objects\ninterface.\n\nPart of blueprint: icehouse-objects\nPart of bluerprint: clean-up-legacy-block-device-mapping\n\nChange-Id: I2e36180876872e756b55171e4903ec3cdfa1d1aa\n""}, {'number': 8, 'created': '2014-02-20 09:18:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/ef8ee9d9d7c03f9c363766e3b451e37b67e5b9f7', 'message': ""Make swap_volume code path use BDM objects\n\nThis patch makes the swap_volume compute manager method use new-world\nBDM objects internally. Sine this was the last place that used the\nhelper method _get_instance_volume_bdm, this method is now removed as\nit's functionality is completely supported by the new-world objects\ninterface.\n\nPart of blueprint: icehouse-objects\nPart of blueprint: clean-up-legacy-block-device-mapping\n\nChange-Id: I2e36180876872e756b55171e4903ec3cdfa1d1aa\n""}, {'number': 9, 'created': '2014-02-20 16:19:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/f3bbea25b7f540f908c0b74a470aae73b5ce478c', 'message': ""Make swap_volume code path use BDM objects\n\nThis patch makes the swap_volume compute manager method use new-world\nBDM objects internally. Sine this was the last place that used the\nhelper method _get_instance_volume_bdm, this method is now removed as\nit's functionality is completely supported by the new-world objects\ninterface.\n\nPart of blueprint: icehouse-objects\nPart of blueprint: clean-up-legacy-block-device-mapping\n\nChange-Id: I2e36180876872e756b55171e4903ec3cdfa1d1aa\n""}, {'number': 10, 'created': '2014-02-25 13:47:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/011f68a8902873662443c9044779fa08cf5f339b', 'message': ""Make swap_volume code path use BDM objects\n\nThis patch makes the swap_volume compute manager method use new-world\nBDM objects internally. Sine this was the last place that used the\nhelper method _get_instance_volume_bdm, this method is now removed as\nit's functionality is completely supported by the new-world objects\ninterface.\n\nPart of blueprint: icehouse-objects\nPart of blueprint: clean-up-legacy-block-device-mapping\n\nChange-Id: I2e36180876872e756b55171e4903ec3cdfa1d1aa\n""}, {'number': 11, 'created': '2014-02-26 12:01:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/a89b81b11afc4891aafc7deda2a85ed613bd8ca3', 'message': ""Make swap_volume code path use BDM objects\n\nThis patch makes the swap_volume compute manager method use new-world\nBDM objects internally. Sine this was the last place that used the\nhelper method _get_instance_volume_bdm, this method is now removed as\nit's functionality is completely supported by the new-world objects\ninterface.\n\nPart of blueprint: icehouse-objects\nPart of blueprint: clean-up-legacy-block-device-mapping\n\nChange-Id: I2e36180876872e756b55171e4903ec3cdfa1d1aa\n""}, {'number': 12, 'created': '2014-03-04 14:21:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/f6f16ff85191fc19d2a8b269862681794128281a', 'message': ""Make swap_volume code path use BDM objects\n\nThis patch makes the swap_volume compute manager method use new-world\nBDM objects internally. Sine this was the last place that used the\nhelper method _get_instance_volume_bdm, this method is now removed as\nit's functionality is completely supported by the new-world objects\ninterface.\n\nPart of blueprint: icehouse-objects\nPart of blueprint: clean-up-legacy-block-device-mapping\n\nChange-Id: I2e36180876872e756b55171e4903ec3cdfa1d1aa\n""}, {'number': 13, 'created': '2014-03-05 11:06:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/b4d91241984e28b38eafbda1990675e0039b3d60', 'message': ""Make swap_volume code path use BDM objects\n\nThis patch makes the swap_volume compute manager method use new-world\nBDM objects internally. Sine this was the last place that used the\nhelper method _get_instance_volume_bdm, this method is now removed as\nit's functionality is completely supported by the new-world objects\ninterface.\n\nPart of blueprint: icehouse-objects\nPart of blueprint: clean-up-legacy-block-device-mapping\n\nChange-Id: I2e36180876872e756b55171e4903ec3cdfa1d1aa\n""}, {'number': 14, 'created': '2014-03-06 11:18:17.000000000', 'files': ['nova/tests/compute/test_compute_api.py', 'nova/tests/compute/test_compute_mgr.py', 'nova/tests/objects/test_block_device.py', 'nova/objects/block_device.py', 'nova/compute/manager.py', 'nova/compute/api.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/dd23acf27c6dc79bc071a6b5ef1a0c39aca6703d', 'message': ""Make swap_volume code path use BDM objects\n\nThis patch makes the swap_volume compute manager method use new-world\nBDM objects internally. Sine this was the last place that used the\nhelper method _get_instance_volume_bdm, this method is now removed as\nit's functionality is completely supported by the new-world objects\ninterface.\n\nWe also add the instance_uuid parameter to the BlockDeviceMapping\nget_by_volume_id method, so that we can narrow the possible race window\nwhen swapping volumes call RPC is delayed for a long time and the cloud\nadministrator re-assigns the volume. In addition, we clean up calls to\nthis method throughout the codebase to use key word arguments properly.\n\nPart of blueprint: icehouse-objects\nPart of blueprint: clean-up-legacy-block-device-mapping\n\nChange-Id: I2e36180876872e756b55171e4903ec3cdfa1d1aa\n""}]",10,71064,dd23acf27c6dc79bc071a6b5ef1a0c39aca6703d,117,11,14,5511,,,0,"Make swap_volume code path use BDM objects

This patch makes the swap_volume compute manager method use new-world
BDM objects internally. Sine this was the last place that used the
helper method _get_instance_volume_bdm, this method is now removed as
it's functionality is completely supported by the new-world objects
interface.

We also add the instance_uuid parameter to the BlockDeviceMapping
get_by_volume_id method, so that we can narrow the possible race window
when swapping volumes call RPC is delayed for a long time and the cloud
administrator re-assigns the volume. In addition, we clean up calls to
this method throughout the codebase to use key word arguments properly.

Part of blueprint: icehouse-objects
Part of blueprint: clean-up-legacy-block-device-mapping

Change-Id: I2e36180876872e756b55171e4903ec3cdfa1d1aa
",git fetch https://review.opendev.org/openstack/nova refs/changes/64/71064/9 && git format-patch -1 --stdout FETCH_HEAD,"['nova/tests/compute/test_compute_mgr.py', 'nova/compute/manager.py']",2,999facb7d1d631b7def57bfd0bc6f29727d45ac2,bdm_objects_compute," bdm = block_device_obj.BlockDeviceMapping.get_by_volume_id( context, old_volume_id) mountpoint = bdm.device_name old_cinfo = jsonutils.loads(bdm.connection_info) 'source_type': 'volume', 'destination_type': 'volume', bdm.update(values) bdm.save()"," def _get_instance_volume_bdm(self, context, instance, volume_id): bdms = self._get_instance_volume_bdms(context, instance) for bdm in bdms: # NOTE(vish): Comparing as strings because the os_api doesn't # convert to integer and we may wish to support uuids # in the future. if str(bdm['volume_id']) == str(volume_id): return bdm bdm = self._get_instance_volume_bdm(context, instance, old_volume_id) mountpoint = bdm['device_name'] old_cinfo = jsonutils.loads(bdm['connection_info']) 'instance_uuid': instance['uuid'], 'device_name': mountpoint, 'virtual_name': None, self.conductor_api.block_device_mapping_update_or_create(context, values)",17,23
openstack%2Fnova~master~Idf370609e23aff45e18a67c76768ba80511c2801,openstack/nova,master,Idf370609e23aff45e18a67c76768ba80511c2801,Move instance_resize code paths to BDM objects,MERGED,2014-02-04 19:04:01.000000000,2014-03-07 16:22:05.000000000,2014-03-06 17:35:45.000000000,"[{'_account_id': 3}, {'_account_id': 688}, {'_account_id': 1653}, {'_account_id': 4393}, {'_account_id': 4912}, {'_account_id': 5170}, {'_account_id': 5441}, {'_account_id': 5511}, {'_account_id': 7730}, {'_account_id': 9008}, {'_account_id': 9578}, {'_account_id': 9636}]","[{'number': 1, 'created': '2014-02-04 19:04:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/31e49b5e253f882d100c959815cbe9a528942f7c', 'message': 'Move instance_resize code paths to BDM objects\n\nMake both resize_instance and confirm_resize compute manager methods use\nBDM objects. This is achieved by moving the helper method\n_terminate_volume_connections to use BDM objects.\nThis patch also avoids unnecessary calls to conductor as now all helper\nmethods used allow for passing the already dug up BDM list.\n\nPart of blueprint: icehouse-objects\nPart of blueprint: clean-up-legacy-block-device-mapping\n\nChange-Id: Idf370609e23aff45e18a67c76768ba80511c2801\n'}, {'number': 2, 'created': '2014-02-06 10:23:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/404f0c1aa171dd3c6d60bb6d0f3d83814c84c96b', 'message': 'Move instance_resize code paths to BDM objects\n\nMake both resize_instance and confirm_resize compute manager methods use\nBDM objects. This is achieved by moving the helper method\n_terminate_volume_connections to use BDM objects.\nThis patch also avoids unnecessary calls to conductor as now all helper\nmethods used allow for passing the already dug up BDM list.\n\nPart of blueprint: icehouse-objects\nPart of blueprint: clean-up-legacy-block-device-mapping\n\nChange-Id: Idf370609e23aff45e18a67c76768ba80511c2801\n'}, {'number': 3, 'created': '2014-02-06 18:13:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/0214e2654f6430b22c18dfabb10fe36f136f6c7e', 'message': 'Move instance_resize code paths to BDM objects\n\nMake both resize_instance and confirm_resize compute manager methods use\nBDM objects. This is achieved by moving the helper method\n_terminate_volume_connections to use BDM objects.\nThis patch also avoids unnecessary calls to conductor as now all helper\nmethods used allow for passing the already dug up BDM list.\n\nPart of blueprint: icehouse-objects\nPart of blueprint: clean-up-legacy-block-device-mapping\n\nChange-Id: Idf370609e23aff45e18a67c76768ba80511c2801\n'}, {'number': 4, 'created': '2014-02-10 13:13:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/6cafe3eb56d10a23506580ccc10088bd6101fd64', 'message': 'Move instance_resize code paths to BDM objects\n\nMake both resize_instance and confirm_resize compute manager methods use\nBDM objects. This is achieved by moving the helper method\n_terminate_volume_connections to use BDM objects.\nThis patch also avoids unnecessary calls to conductor as now all helper\nmethods used allow for passing the already dug up BDM list.\n\nPart of blueprint: icehouse-objects\nPart of blueprint: clean-up-legacy-block-device-mapping\n\nChange-Id: Idf370609e23aff45e18a67c76768ba80511c2801\n'}, {'number': 5, 'created': '2014-02-10 18:34:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/86c94ce847b07dd8ef32859117c75faa46725412', 'message': 'Move instance_resize code paths to BDM objects\n\nMake both resize_instance and confirm_resize compute manager methods use\nBDM objects. This is achieved by moving the helper method\n_terminate_volume_connections to use BDM objects.\nThis patch also avoids unnecessary calls to conductor as now all helper\nmethods used allow for passing the already dug up BDM list.\n\nPart of blueprint: icehouse-objects\nPart of blueprint: clean-up-legacy-block-device-mapping\n\nChange-Id: Idf370609e23aff45e18a67c76768ba80511c2801\n'}, {'number': 6, 'created': '2014-02-10 21:08:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/988e24cbb03a86e99830e9e03fd4d0e6d983a515', 'message': 'Move instance_resize code paths to BDM objects\n\nMake both resize_instance and confirm_resize compute manager methods use\nBDM objects. This is achieved by moving the helper method\n_terminate_volume_connections to use BDM objects.\nThis patch also avoids unnecessary calls to conductor as now all helper\nmethods used allow for passing the already dug up BDM list.\n\nPart of blueprint: icehouse-objects\nPart of blueprint: clean-up-legacy-block-device-mapping\n\nChange-Id: Idf370609e23aff45e18a67c76768ba80511c2801\n'}, {'number': 7, 'created': '2014-02-17 17:17:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/f93698cda48951d12c797ba8d329d28b2ed9cffb', 'message': 'Move instance_resize code paths to BDM objects\n\nMake both resize_instance and confirm_resize compute manager methods use\nBDM objects. This is achieved by moving the helper method\n_terminate_volume_connections to use BDM objects.\nThis patch also avoids unnecessary calls to conductor as now all helper\nmethods used allow for passing the already dug up BDM list.\n\nPart of blueprint: icehouse-objects\nPart of blueprint: clean-up-legacy-block-device-mapping\n\nChange-Id: Idf370609e23aff45e18a67c76768ba80511c2801\n'}, {'number': 8, 'created': '2014-02-20 09:18:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/02a0aadbf84b7ce4c4f0ac661524ad31fcfac108', 'message': 'Move instance_resize code paths to BDM objects\n\nMake both resize_instance and confirm_resize compute manager methods use\nBDM objects. This is achieved by moving the helper method\n_terminate_volume_connections to use BDM objects.\nThis patch also avoids unnecessary calls to conductor as now all helper\nmethods used allow for passing the already dug up BDM list.\n\nPart of blueprint: icehouse-objects\nPart of blueprint: clean-up-legacy-block-device-mapping\n\nChange-Id: Idf370609e23aff45e18a67c76768ba80511c2801\n'}, {'number': 9, 'created': '2014-02-20 16:19:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/eb6ebd5b2ecbe0bf733d76a8a6a881335604f6d1', 'message': 'Move instance_resize code paths to BDM objects\n\nMake both resize_instance and confirm_resize compute manager methods use\nBDM objects. This is achieved by moving the helper method\n_terminate_volume_connections to use BDM objects.\nThis patch also avoids unnecessary calls to conductor as now all helper\nmethods used allow for passing the already dug up BDM list.\n\nPart of blueprint: icehouse-objects\nPart of blueprint: clean-up-legacy-block-device-mapping\n\nChange-Id: Idf370609e23aff45e18a67c76768ba80511c2801\n'}, {'number': 10, 'created': '2014-02-25 13:47:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/4fce5df6377e8fba39a83d1132e8f92cb87b57a1', 'message': 'Move instance_resize code paths to BDM objects\n\nMake both resize_instance and confirm_resize compute manager methods use\nBDM objects. This is achieved by moving the helper method\n_terminate_volume_connections to use BDM objects.\nThis patch also avoids unnecessary calls to conductor as now all helper\nmethods used allow for passing the already dug up BDM list.\n\nPart of blueprint: icehouse-objects\nPart of blueprint: clean-up-legacy-block-device-mapping\n\nChange-Id: Idf370609e23aff45e18a67c76768ba80511c2801\n'}, {'number': 11, 'created': '2014-02-26 12:01:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/22787455c7c5f077028e9b60f5f95bfddb47186c', 'message': 'Move instance_resize code paths to BDM objects\n\nMake both resize_instance and confirm_resize compute manager methods use\nBDM objects. This is achieved by moving the helper method\n_terminate_volume_connections to use BDM objects.\nThis patch also avoids unnecessary calls to conductor as now all helper\nmethods used allow for passing the already dug up BDM list.\n\nPart of blueprint: icehouse-objects\nPart of blueprint: clean-up-legacy-block-device-mapping\n\nChange-Id: Idf370609e23aff45e18a67c76768ba80511c2801\n'}, {'number': 12, 'created': '2014-03-04 14:21:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/ed5dffc1df9a814eaeeba097c47440459f62ec40', 'message': 'Move instance_resize code paths to BDM objects\n\nMake both resize_instance and confirm_resize compute manager methods use\nBDM objects. This is achieved by moving the helper method\n_terminate_volume_connections to use BDM objects.\nThis patch also avoids unnecessary calls to conductor as now all helper\nmethods used allow for passing the already dug up BDM list.\n\nPart of blueprint: icehouse-objects\nPart of blueprint: clean-up-legacy-block-device-mapping\n\nChange-Id: Idf370609e23aff45e18a67c76768ba80511c2801\n'}, {'number': 13, 'created': '2014-03-05 11:06:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/c1311212433a68100af0162d39e1a9aba81062b5', 'message': 'Move instance_resize code paths to BDM objects\n\nMake both resize_instance and confirm_resize compute manager methods use\nBDM objects. This is achieved by moving the helper method\n_terminate_volume_connections to use BDM objects.\nThis patch also avoids unnecessary calls to conductor as now all helper\nmethods used allow for passing the already dug up BDM list.\n\nPart of blueprint: icehouse-objects\nPart of blueprint: clean-up-legacy-block-device-mapping\n\nChange-Id: Idf370609e23aff45e18a67c76768ba80511c2801\n'}, {'number': 14, 'created': '2014-03-06 11:18:23.000000000', 'files': ['nova/compute/manager.py', 'nova/tests/compute/test_compute.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/85c9337e7883fa3b983ea3bbe02e3538e538f629', 'message': 'Move instance_resize code paths to BDM objects\n\nMake both resize_instance and confirm_resize compute manager methods use\nBDM objects. This is achieved by moving the helper method\n_terminate_volume_connections to use BDM objects.\nThis patch also avoids unnecessary calls to conductor as now all helper\nmethods used allow for passing the already dug up BDM list.\n\nPart of blueprint: icehouse-objects\nPart of blueprint: clean-up-legacy-block-device-mapping\n\nChange-Id: Idf370609e23aff45e18a67c76768ba80511c2801\n'}]",6,71065,85c9337e7883fa3b983ea3bbe02e3538e538f629,109,12,14,5511,,,0,"Move instance_resize code paths to BDM objects

Make both resize_instance and confirm_resize compute manager methods use
BDM objects. This is achieved by moving the helper method
_terminate_volume_connections to use BDM objects.
This patch also avoids unnecessary calls to conductor as now all helper
methods used allow for passing the already dug up BDM list.

Part of blueprint: icehouse-objects
Part of blueprint: clean-up-legacy-block-device-mapping

Change-Id: Idf370609e23aff45e18a67c76768ba80511c2801
",git fetch https://review.opendev.org/openstack/nova refs/changes/65/71065/10 && git format-patch -1 --stdout FETCH_HEAD,['nova/compute/manager.py'],1,31e49b5e253f882d100c959815cbe9a528942f7c,bdm_objects_compute," bdms = (block_device_obj.BlockDeviceMappingList. get_by_instance_uuid(context, instance.uuid)) context, instance, bdms) self._terminate_volume_connections(context, instance, bdms) bdms = (block_device_obj.BlockDeviceMappingList. get_by_instance_uuid(context, instance.uuid)) context, instance, bdms) self._terminate_volume_connections(context, instance, bdms) def _terminate_volume_connections(self, context, instance, bdms=None): if not bdms: bdms = (block_device_obj.BlockDeviceMappingList. get_by_instance_uuid(context, instance.uuid)) connector = self.driver.get_volume_connector(instance) for bdm in bdms: if bdm.is_volume: self.volume_api.terminate_connection(context, bdm.volume_id,"," context, instance) self._terminate_volume_connections(context, instance) context, instance) self._terminate_volume_connections(context, instance) def _terminate_volume_connections(self, context, instance): bdms = self._get_instance_volume_bdms(context, instance) if bdms: connector = self.driver.get_volume_connector(instance) for bdm in bdms: self.volume_api.terminate_connection(context, bdm['volume_id'],",16,10
openstack%2Fmagnetodb~master~I7dace4e3f584188fda02755304c08a460c46e07c,openstack/magnetodb,master,I7dace4e3f584188fda02755304c08a460c46e07c,Fixes tempest tests to fit DynamoDB API,MERGED,2014-03-05 12:33:41.000000000,2014-03-07 16:18:38.000000000,2014-03-07 16:18:38.000000000,"[{'_account_id': 3}, {'_account_id': 8188}, {'_account_id': 8408}, {'_account_id': 8491}, {'_account_id': 8601}, {'_account_id': 8863}, {'_account_id': 9068}, {'_account_id': 10665}]","[{'number': 1, 'created': '2014-03-05 12:33:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/magnetodb/commit/bc2f18c4edf8548121bd41c2e5cd311305827408', 'message': ""Fixes tempest test with response mismatch\n\nAdds fields 'LastDecreaseDateTime' and 'LastIncreaseDateTime'\nin expected response on table creating according to DynamoDB\nAPI reference.\nSets 'ReadCapacityUnits' and 'WriteCapacityUnits' in expected\nresponse to 0.\n\nChange-Id: I7dace4e3f584188fda02755304c08a460c46e07c\nCloses-bug: #1271933\n""}, {'number': 2, 'created': '2014-03-06 18:10:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/magnetodb/commit/2f25ca20eb7de528be10e56f8ab585c20ed7db70', 'message': 'Fixes tempest tests to fit DynamoDB API\n\nFixes error message for ResourseInUseException.\nChanges logic of verifying exception messages.\n\nPartially implements: bp tempest-dynamo-db-api-fit\nChange-Id: I7dace4e3f584188fda02755304c08a460c46e07c\n'}, {'number': 3, 'created': '2014-03-07 13:50:11.000000000', 'files': ['tempest/api/keyvalue/test_tables.py', 'tempest/api/keyvalue/test.py'], 'web_link': 'https://opendev.org/openstack/magnetodb/commit/763434e3f72e07f37682d45f0de4dbddbb18238b', 'message': 'Fixes tempest tests to fit DynamoDB API\n\nAdds ResourseInUseException for duplicate table creating.\nChanges logic of verifying exception messages and error codes.\n\nPartially implements: bp tempest-dynamo-db-api-fit\nChange-Id: I7dace4e3f584188fda02755304c08a460c46e07c\n'}]",3,78184,763434e3f72e07f37682d45f0de4dbddbb18238b,18,8,3,8863,,,0,"Fixes tempest tests to fit DynamoDB API

Adds ResourseInUseException for duplicate table creating.
Changes logic of verifying exception messages and error codes.

Partially implements: bp tempest-dynamo-db-api-fit
Change-Id: I7dace4e3f584188fda02755304c08a460c46e07c
",git fetch https://review.opendev.org/openstack/magnetodb refs/changes/84/78184/1 && git format-patch -1 --stdout FETCH_HEAD,"['tempest/api/keyvalue/test_tables.py', 'tempest/api/keyvalue/base.py']",2,bc2f18c4edf8548121bd41c2e5cd311305827408,bp/tempest-dynamo-db-api-fit," cls.smoke_throughput = {'ReadCapacityUnits': 0, 'WriteCapacityUnits': 0}"," cls.smoke_throughput = {'ReadCapacityUnits': 1, 'WriteCapacityUnits': 1}",5,3
openstack%2Ffuel-docs~master~I2f42f3250669249cc6a2f982c546806c851fa782,openstack/fuel-docs,master,I2f42f3250669249cc6a2f982c546806c851fa782,"LP1285766, LP1287426, fixed Savanna xref",MERGED,2014-03-07 01:33:27.000000000,2014-03-07 16:16:57.000000000,2014-03-07 16:16:57.000000000,"[{'_account_id': 3}, {'_account_id': 406}, {'_account_id': 8411}, {'_account_id': 8971}, {'_account_id': 10014}]","[{'number': 1, 'created': '2014-03-07 01:33:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-docs/commit/17ad65f65d21e36cbb136c89a037f431284d4b7d', 'message': 'LP1285766, LP1287426, fixed Savanna xref\n\nChange-Id: I2f42f3250669249cc6a2f982c546806c851fa782\n'}, {'number': 2, 'created': '2014-03-07 08:09:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-docs/commit/3adb25af236d1ed8f57745266815a1b93e2079d6', 'message': 'LP1285766, LP1287426, fixed Savanna xref\n\nChange-Id: I2f42f3250669249cc6a2f982c546806c851fa782\n'}, {'number': 3, 'created': '2014-03-07 08:31:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-docs/commit/680612026e33e08030f6d09ebc3b75fc0410a31f', 'message': 'LP1285766, LP1287426, fixed Savanna xref\n\nChange-Id: I2f42f3250669249cc6a2f982c546806c851fa782\n'}, {'number': 4, 'created': '2014-03-07 09:06:40.000000000', 'files': ['pages/release-notes/v4-1/050-known-issues.rst', 'pages/user-guide/savanna.rst'], 'web_link': 'https://opendev.org/openstack/fuel-docs/commit/f5b61ddd3c3c0f7b88e277861e429cf773ff7931', 'message': 'LP1285766, LP1287426, fixed Savanna xref\n\nChange-Id: I2f42f3250669249cc6a2f982c546806c851fa782\n'}]",9,78830,f5b61ddd3c3c0f7b88e277861e429cf773ff7931,30,5,4,10014,,,0,"LP1285766, LP1287426, fixed Savanna xref

Change-Id: I2f42f3250669249cc6a2f982c546806c851fa782
",git fetch https://review.opendev.org/openstack/fuel-docs refs/changes/30/78830/4 && git format-patch -1 --stdout FETCH_HEAD,"['pages/release-notes/v4-1/050-known-issues.rst', 'pages/user-guide/savanna.rst']",2,17ad65f65d21e36cbb136c89a037f431284d4b7d,bug/1285766,Savanna requires pre-built Hadoop images and images for hadoop cluster provisioning that are not included in FuelCheck the `documentation of the Savanna 0.3 project <https://savanna.readthedocs.org/en/0.3/>`_ to find out how to,Savanna requires pre-built Hadoop images that are not included in FuelCheck the `documentation of Savanna project <http://docs.openstack.org/developer/savanna/>`_ to find out how to,39,3
openstack%2Fheat-templates~master~Id3d92c4a46b88b1816994c13a2c07dd33709d4d9,openstack/heat-templates,master,Id3d92c4a46b88b1816994c13a2c07dd33709d4d9,Delay creating mongo replica set until other broker hosts available,ABANDONED,2014-03-04 03:39:02.000000000,2014-03-07 16:15:39.000000000,,"[{'_account_id': 3}, {'_account_id': 2834}, {'_account_id': 4328}]","[{'number': 1, 'created': '2014-03-04 03:39:02.000000000', 'files': ['openshift-enterprise/heat/neutron/highly-available/ose_ha_stack.yaml'], 'web_link': 'https://opendev.org/openstack/heat-templates/commit/9eb49fbf4a0958bf2a9837ee127bd19a849ad6db', 'message': 'Delay creating mongo replica set until other broker hosts available\n\nMongoDB requires all members of the replica set be up when\ninitiating the replica set. This change delays the creation of\nthe rs until the other brokers have had a chance to reboot. The\nopenshift.sh script is used by setting the CONF_ACTIONS env var.\n\nChange-Id: Id3d92c4a46b88b1816994c13a2c07dd33709d4d9\n'}]",1,77777,9eb49fbf4a0958bf2a9837ee127bd19a849ad6db,7,3,1,10000,,,0,"Delay creating mongo replica set until other broker hosts available

MongoDB requires all members of the replica set be up when
initiating the replica set. This change delays the creation of
the rs until the other brokers have had a chance to reboot. The
openshift.sh script is used by setting the CONF_ACTIONS env var.

Change-Id: Id3d92c4a46b88b1816994c13a2c07dd33709d4d9
",git fetch https://review.opendev.org/openstack/heat-templates refs/changes/77/77777/1 && git format-patch -1 --stdout FETCH_HEAD,['openshift-enterprise/heat/neutron/highly-available/ose_ha_stack.yaml'],1,9eb49fbf4a0958bf2a9837ee127bd19a849ad6db,ha_updates," export CONF_ACTIONS=do_all_actions,configure_datastore_add_replicants # wait for other brokers for mongo replica set config sleep 60"," export CONF_ACTIONS=do_all_actions,configure_datastore_add_replicants,configure_datastore_add_users",3,1
openstack%2Fopenstack-manuals~master~I5f8d2da39f5740af1963ece36daf04d4af5a3c69,openstack/openstack-manuals,master,I5f8d2da39f5740af1963ece36daf04d4af5a3c69,Remove stop-chunking at chapter level,MERGED,2014-03-07 14:55:51.000000000,2014-03-07 16:12:55.000000000,2014-03-07 16:12:54.000000000,"[{'_account_id': 3}, {'_account_id': 964}, {'_account_id': 2448}, {'_account_id': 6547}]","[{'number': 1, 'created': '2014-03-07 14:55:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/c5693879eb38e50a2b873439d5bc6348638f0322', 'message': 'Remove stop-chunking at chapter level\n\nChange-Id: I5f8d2da39f5740af1963ece36daf04d4af5a3c69\nauthor: diane fleming\n'}, {'number': 2, 'created': '2014-03-07 15:04:13.000000000', 'files': ['doc/common/ch_getstart.xml', 'doc/admin-guide-cloud/ch_blockstorage.xml', 'doc/admin-guide-cloud/ch_dashboard.xml', 'doc/admin-guide-cloud/ch_networking.xml', 'doc/admin-guide-cloud/ch_objectstorage.xml', 'doc/admin-guide-cloud/ch_identity_mgmt.xml', 'doc/admin-guide-cloud/ch_compute.xml'], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/1ffdf6978aa79472fecddeafd0ea198bf07b4a23', 'message': 'Remove stop-chunking at chapter level\n\nChange-Id: I5f8d2da39f5740af1963ece36daf04d4af5a3c69\nauthor: diane fleming\n'}]",0,78978,1ffdf6978aa79472fecddeafd0ea198bf07b4a23,10,4,2,2448,,,0,"Remove stop-chunking at chapter level

Change-Id: I5f8d2da39f5740af1963ece36daf04d4af5a3c69
author: diane fleming
",git fetch https://review.opendev.org/openstack/openstack-manuals refs/changes/78/78978/2 && git format-patch -1 --stdout FETCH_HEAD,"['doc/common/ch_getstart.xml', 'doc/admin-guide-cloud/ch_blockstorage.xml', 'doc/admin-guide-cloud/ch_dashboard.xml', 'doc/admin-guide-cloud/ch_networking.xml', 'doc/admin-guide-cloud/ch_objectstorage.xml', 'doc/admin-guide-cloud/ch_identity_mgmt.xml', 'doc/admin-guide-cloud/ch_compute.xml', 'doc/common/app_support.xml']",8,c5693879eb38e50a2b873439d5bc6348638f0322,remove-chunking,, <?dbhtml stop-chunking?>,0,9
openstack%2Fhorizon~master~Ic9da5f279ee0b49e2da0fa26ed0ef2cdc989c413,openstack/horizon,master,Ic9da5f279ee0b49e2da0fa26ed0ef2cdc989c413,Removes bundled copies of js 3rd party libs,ABANDONED,2014-03-07 14:05:29.000000000,2014-03-07 16:05:49.000000000,,"[{'_account_id': 3}, {'_account_id': 5623}, {'_account_id': 9225}]","[{'number': 1, 'created': '2014-03-07 14:05:29.000000000', 'files': ['horizon/templates/horizon/_conf.html', 'horizon/static/bootstrap/js/bootstrap.js', 'horizon/static/horizon/lib/jquery/jquery-ui-1.9.2.custom.js', 'horizon/templates/horizon/_scripts.html', 'horizon/static/horizon/lib/angular/angular.js', 'horizon/static/horizon/lib/jquery/jquery.js'], 'web_link': 'https://opendev.org/openstack/horizon/commit/0cc8615fe28fa2f6ad5f9121cd96017a6f1047d7', 'message': 'Removes bundled copies of js 3rd party libs\n\nBundles copies of javascript third-party libs were\nremoved from Horizon: jQuery, jQuery-UI, AngularJS\nand Bootstrap. Now they are downloaded from the\nrecommended CDNs\n\nCloses-Bug: #1270063\nChange-Id: Ic9da5f279ee0b49e2da0fa26ed0ef2cdc989c413\n'}]",0,78967,0cc8615fe28fa2f6ad5f9121cd96017a6f1047d7,6,3,1,9225,,,0,"Removes bundled copies of js 3rd party libs

Bundles copies of javascript third-party libs were
removed from Horizon: jQuery, jQuery-UI, AngularJS
and Bootstrap. Now they are downloaded from the
recommended CDNs

Closes-Bug: #1270063
Change-Id: Ic9da5f279ee0b49e2da0fa26ed0ef2cdc989c413
",git fetch https://review.opendev.org/openstack/horizon refs/changes/67/78967/1 && git format-patch -1 --stdout FETCH_HEAD,"['horizon/templates/horizon/_conf.html', 'horizon/static/bootstrap/js/bootstrap.js', 'horizon/static/horizon/lib/jquery/jquery-ui-1.9.2.custom.js', 'horizon/templates/horizon/_scripts.html', 'horizon/static/horizon/lib/angular/angular.js', 'horizon/static/horizon/lib/jquery/jquery.js']",6,0cc8615fe28fa2f6ad5f9121cd96017a6f1047d7,bug/1270063,,"/*! * jQuery JavaScript Library v1.7.2 * http://jquery.com/ * * Copyright 2011, John Resig * Dual licensed under the MIT or GPL Version 2 licenses. * http://jquery.org/license * * Includes Sizzle.js * http://sizzlejs.com/ * Copyright 2011, The Dojo Foundation * Released under the MIT, BSD, and GPL Licenses. * * Date: Wed Mar 21 12:46:34 2012 -0700 */ (function( window, undefined ) { // Use the correct document accordingly with window argument (sandbox) var document = window.document, navigator = window.navigator, location = window.location; var jQuery = (function() { // Define a local copy of jQuery var jQuery = function( selector, context ) { // The jQuery object is actually just the init constructor 'enhanced' return new jQuery.fn.init( selector, context, rootjQuery ); }, // Map over jQuery in case of overwrite _jQuery = window.jQuery, // Map over the $ in case of overwrite _$ = window.$, // A central reference to the root jQuery(document) rootjQuery, // A simple way to check for HTML strings or ID strings // Prioritize #id over <tag> to avoid XSS via location.hash (#9521) quickExpr = /^(?:[^#<]*(<[\w\W]+>)[^>]*$|#([\w\-]*)$)/, // Check if a string has a non-whitespace character in it rnotwhite = /\S/, // Used for trimming whitespace trimLeft = /^\s+/, trimRight = /\s+$/, // Match a standalone tag rsingleTag = /^<(\w+)\s*\/?>(?:<\/\1>)?$/, // JSON RegExp rvalidchars = /^[\],:{}\s]*$/, rvalidescape = /\\(?:[""\\\/bfnrt]|u[0-9a-fA-F]{4})/g, rvalidtokens = /""[^""\\\n\r]*""|true|false|null|-?\d+(?:\.\d*)?(?:[eE][+\-]?\d+)?/g, rvalidbraces = /(?:^|:|,)(?:\s*\[)+/g, // Useragent RegExp rwebkit = /(webkit)[ \/]([\w.]+)/, ropera = /(opera)(?:.*version)?[ \/]([\w.]+)/, rmsie = /(msie) ([\w.]+)/, rmozilla = /(mozilla)(?:.*? rv:([\w.]+))?/, // Matches dashed string for camelizing rdashAlpha = /-([a-z]|[0-9])/ig, rmsPrefix = /^-ms-/, // Used by jQuery.camelCase as callback to replace() fcamelCase = function( all, letter ) { return ( letter + """" ).toUpperCase(); }, // Keep a UserAgent string for use with jQuery.browser userAgent = navigator.userAgent, // For matching the engine and version of the browser browserMatch, // The deferred used on DOM ready readyList, // The ready event handler DOMContentLoaded, // Save a reference to some core methods toString = Object.prototype.toString, hasOwn = Object.prototype.hasOwnProperty, push = Array.prototype.push, slice = Array.prototype.slice, trim = String.prototype.trim, indexOf = Array.prototype.indexOf, // [[Class]] -> type pairs class2type = {}; jQuery.fn = jQuery.prototype = { constructor: jQuery, init: function( selector, context, rootjQuery ) { var match, elem, ret, doc; // Handle $(""""), $(null), or $(undefined) if ( !selector ) { return this; } // Handle $(DOMElement) if ( selector.nodeType ) { this.context = this[0] = selector; this.length = 1; return this; } // The body element only exists once, optimize finding it if ( selector === ""body"" && !context && document.body ) { this.context = document; this[0] = document.body; this.selector = selector; this.length = 1; return this; } // Handle HTML strings if ( typeof selector === ""string"" ) { // Are we dealing with HTML string or an ID? if ( selector.charAt(0) === ""<"" && selector.charAt( selector.length - 1 ) === "">"" && selector.length >= 3 ) { // Assume that strings that start and end with <> are HTML and skip the regex check match = [ null, selector, null ]; } else { match = quickExpr.exec( selector ); } // Verify a match, and that no context was specified for #id if ( match && (match[1] || !context) ) { // HANDLE: $(html) -> $(array) if ( match[1] ) { context = context instanceof jQuery ? context[0] : context; doc = ( context ? context.ownerDocument || context : document ); // If a single string is passed in and it's a single tag // just do a createElement and skip the rest ret = rsingleTag.exec( selector ); if ( ret ) { if ( jQuery.isPlainObject( context ) ) { selector = [ document.createElement( ret[1] ) ]; jQuery.fn.attr.call( selector, context, true ); } else { selector = [ doc.createElement( ret[1] ) ]; } } else { ret = jQuery.buildFragment( [ match[1] ], [ doc ] ); selector = ( ret.cacheable ? jQuery.clone(ret.fragment) : ret.fragment ).childNodes; } return jQuery.merge( this, selector ); // HANDLE: $(""#id"") } else { elem = document.getElementById( match[2] ); // Check parentNode to catch when Blackberry 4.6 returns // nodes that are no longer in the document #6963 if ( elem && elem.parentNode ) { // Handle the case where IE and Opera return items // by name instead of ID if ( elem.id !== match[2] ) { return rootjQuery.find( selector ); } // Otherwise, we inject the element directly into the jQuery object this.length = 1; this[0] = elem; } this.context = document; this.selector = selector; return this; } // HANDLE: $(expr, $(...)) } else if ( !context || context.jquery ) { return ( context || rootjQuery ).find( selector ); // HANDLE: $(expr, context) // (which is just equivalent to: $(context).find(expr) } else { return this.constructor( context ).find( selector ); } // HANDLE: $(function) // Shortcut for document ready } else if ( jQuery.isFunction( selector ) ) { return rootjQuery.ready( selector ); } if ( selector.selector !== undefined ) { this.selector = selector.selector; this.context = selector.context; } return jQuery.makeArray( selector, this ); }, // Start with an empty selector selector: """", // The current version of jQuery being used jquery: ""1.7.2"", // The default length of a jQuery object is 0 length: 0, // The number of elements contained in the matched element set size: function() { return this.length; }, toArray: function() { return slice.call( this, 0 ); }, // Get the Nth element in the matched element set OR // Get the whole matched element set as a clean array get: function( num ) { return num == null ? // Return a 'clean' array this.toArray() : // Return just the object ( num < 0 ? this[ this.length + num ] : this[ num ] ); }, // Take an array of elements and push it onto the stack // (returning the new matched element set) pushStack: function( elems, name, selector ) { // Build a new jQuery matched element set var ret = this.constructor(); if ( jQuery.isArray( elems ) ) { push.apply( ret, elems ); } else { jQuery.merge( ret, elems ); } // Add the old object onto the stack (as a reference) ret.prevObject = this; ret.context = this.context; if ( name === ""find"" ) { ret.selector = this.selector + ( this.selector ? "" "" : """" ) + selector; } else if ( name ) { ret.selector = this.selector + ""."" + name + ""("" + selector + "")""; } // Return the newly-formed element set return ret; }, // Execute a callback for every element in the matched set. // (You can seed the arguments with an array of args, but this is // only used internally.) each: function( callback, args ) { return jQuery.each( this, callback, args ); }, ready: function( fn ) { // Attach the listeners jQuery.bindReady(); // Add the callback readyList.add( fn ); return this; }, eq: function( i ) { i = +i; return i === -1 ? this.slice( i ) : this.slice( i, i + 1 ); }, first: function() { return this.eq( 0 ); }, last: function() { return this.eq( -1 ); }, slice: function() { return this.pushStack( slice.apply( this, arguments ), ""slice"", slice.call(arguments).join("","") ); }, map: function( callback ) { return this.pushStack( jQuery.map(this, function( elem, i ) { return callback.call( elem, i, elem ); })); }, end: function() { return this.prevObject || this.constructor(null); }, // For internal use only. // Behaves like an Array's method, not like a jQuery method. push: push, sort: [].sort, splice: [].splice }; // Give the init function the jQuery prototype for later instantiation jQuery.fn.init.prototype = jQuery.fn; jQuery.extend = jQuery.fn.extend = function() { var options, name, src, copy, copyIsArray, clone, target = arguments[0] || {}, i = 1, length = arguments.length, deep = false; // Handle a deep copy situation if ( typeof target === ""boolean"" ) { deep = target; target = arguments[1] || {}; // skip the boolean and the target i = 2; } // Handle case when target is a string or something (possible in deep copy) if ( typeof target !== ""object"" && !jQuery.isFunction(target) ) { target = {}; } // extend jQuery itself if only one argument is passed if ( length === i ) { target = this; --i; } for ( ; i < length; i++ ) { // Only deal with non-null/undefined values if ( (options = arguments[ i ]) != null ) { // Extend the base object for ( name in options ) { src = target[ name ]; copy = options[ name ]; // Prevent never-ending loop if ( target === copy ) { continue; } // Recurse if we're merging plain objects or arrays if ( deep && copy && ( jQuery.isPlainObject(copy) || (copyIsArray = jQuery.isArray(copy)) ) ) { if ( copyIsArray ) { copyIsArray = false; clone = src && jQuery.isArray(src) ? src : []; } else { clone = src && jQuery.isPlainObject(src) ? src : {}; } // Never move original objects, clone them target[ name ] = jQuery.extend( deep, clone, copy ); // Don't bring in undefined values } else if ( copy !== undefined ) { target[ name ] = copy; } } } } // Return the modified object return target; }; jQuery.extend({ noConflict: function( deep ) { if ( window.$ === jQuery ) { window.$ = _$; } if ( deep && window.jQuery === jQuery ) { window.jQuery = _jQuery; } return jQuery; }, // Is the DOM ready to be used? Set to true once it occurs. isReady: false, // A counter to track how many items to wait for before // the ready event fires. See #6781 readyWait: 1, // Hold (or release) the ready event holdReady: function( hold ) { if ( hold ) { jQuery.readyWait++; } else { jQuery.ready( true ); } }, // Handle when the DOM is ready ready: function( wait ) { // Either a released hold or an DOMready/load event and not yet ready if ( (wait === true && !--jQuery.readyWait) || (wait !== true && !jQuery.isReady) ) { // Make sure body exists, at least, in case IE gets a little overzealous (ticket #5443). if ( !document.body ) { return setTimeout( jQuery.ready, 1 ); } // Remember that the DOM is ready jQuery.isReady = true; // If a normal DOM Ready event fired, decrement, and wait if need be if ( wait !== true && --jQuery.readyWait > 0 ) { return; } // If there are functions bound, to execute readyList.fireWith( document, [ jQuery ] ); // Trigger any bound ready events if ( jQuery.fn.trigger ) { jQuery( document ).trigger( ""ready"" ).off( ""ready"" ); } } }, bindReady: function() { if ( readyList ) { return; } readyList = jQuery.Callbacks( ""once memory"" ); // Catch cases where $(document).ready() is called after the // browser event has already occurred. if ( document.readyState === ""complete"" ) { // Handle it asynchronously to allow scripts the opportunity to delay ready return setTimeout( jQuery.ready, 1 ); } // Mozilla, Opera and webkit nightlies currently support this event if ( document.addEventListener ) { // Use the handy event callback document.addEventListener( ""DOMContentLoaded"", DOMContentLoaded, false ); // A fallback to window.onload, that will always work window.addEventListener( ""load"", jQuery.ready, false ); // If IE event model is used } else if ( document.attachEvent ) { // ensure firing before onload, // maybe late but safe also for iframes document.attachEvent( ""onreadystatechange"", DOMContentLoaded ); // A fallback to window.onload, that will always work window.attachEvent( ""onload"", jQuery.ready ); // If IE and not a frame // continually check to see if the document is ready var toplevel = false; try { toplevel = window.frameElement == null; } catch(e) {} if ( document.documentElement.doScroll && toplevel ) { doScrollCheck(); } } }, // See test/unit/core.js for details concerning isFunction. // Since version 1.3, DOM methods and functions like alert // aren't supported. They return false on IE (#2968). isFunction: function( obj ) { return jQuery.type(obj) === ""function""; }, isArray: Array.isArray || function( obj ) { return jQuery.type(obj) === ""array""; }, isWindow: function( obj ) { return obj != null && obj == obj.window; }, isNumeric: function( obj ) { return !isNaN( parseFloat(obj) ) && isFinite( obj ); }, type: function( obj ) { return obj == null ? String( obj ) : class2type[ toString.call(obj) ] || ""object""; }, isPlainObject: function( obj ) { // Must be an Object. // Because of IE, we also have to check the presence of the constructor property. // Make sure that DOM nodes and window objects don't pass through, as well if ( !obj || jQuery.type(obj) !== ""object"" || obj.nodeType || jQuery.isWindow( obj ) ) { return false; } try { // Not own constructor property must be Object if ( obj.constructor && !hasOwn.call(obj, ""constructor"") && !hasOwn.call(obj.constructor.prototype, ""isPrototypeOf"") ) { return false; } } catch ( e ) { // IE8,9 Will throw exceptions on certain host objects #9897 return false; } // Own properties are enumerated firstly, so to speed up, // if last one is own, then all properties are own. var key; for ( key in obj ) {} return key === undefined || hasOwn.call( obj, key ); }, isEmptyObject: function( obj ) { for ( var name in obj ) { return false; } return true; }, error: function( msg ) { throw new Error( msg ); }, parseJSON: function( data ) { if ( typeof data !== ""string"" || !data ) { return null; } // Make sure leading/trailing whitespace is removed (IE can't handle it) data = jQuery.trim( data ); // Attempt to parse using the native JSON parser first if ( window.JSON && window.JSON.parse ) { return window.JSON.parse( data ); } // Make sure the incoming data is actual JSON // Logic borrowed from http://json.org/json2.js if ( rvalidchars.test( data.replace( rvalidescape, ""@"" ) .replace( rvalidtokens, ""]"" ) .replace( rvalidbraces, """")) ) { return ( new Function( ""return "" + data ) )(); } jQuery.error( ""Invalid JSON: "" + data ); }, // Cross-browser xml parsing parseXML: function( data ) { if ( typeof data !== ""string"" || !data ) { return null; } var xml, tmp; try { if ( window.DOMParser ) { // Standard tmp = new DOMParser(); xml = tmp.parseFromString( data , ""text/xml"" ); } else { // IE xml = new ActiveXObject( ""Microsoft.XMLDOM"" ); xml.async = ""false""; xml.loadXML( data ); } } catch( e ) { xml = undefined; } if ( !xml || !xml.documentElement || xml.getElementsByTagName( ""parsererror"" ).length ) { jQuery.error( ""Invalid XML: "" + data ); } return xml; }, noop: function() {}, // Evaluates a script in a global context // Workarounds based on findings by Jim Driscoll // http://weblogs.java.net/blog/driscoll/archive/2009/09/08/eval-javascript-global-context globalEval: function( data ) { if ( data && rnotwhite.test( data ) ) { // We use execScript on Internet Explorer // We use an anonymous function so that context is window // rather than jQuery in Firefox ( window.execScript || function( data ) { window[ ""eval"" ].call( window, data ); } )( data ); } }, // Convert dashed to camelCase; used by the css and data modules // Microsoft forgot to hump their vendor prefix (#9572) camelCase: function( string ) { return string.replace( rmsPrefix, ""ms-"" ).replace( rdashAlpha, fcamelCase ); }, nodeName: function( elem, name ) { return elem.nodeName && elem.nodeName.toUpperCase() === name.toUpperCase(); }, // args is for internal usage only each: function( object, callback, args ) { var name, i = 0, length = object.length, isObj = length === undefined || jQuery.isFunction( object ); if ( args ) { if ( isObj ) { for ( name in object ) { if ( callback.apply( object[ name ], args ) === false ) { break; } } } else { for ( ; i < length; ) { if ( callback.apply( object[ i++ ], args ) === false ) { break; } } } // A special, fast, case for the most common use of each } else { if ( isObj ) { for ( name in object ) { if ( callback.call( object[ name ], name, object[ name ] ) === false ) { break; } } } else { for ( ; i < length; ) { if ( callback.call( object[ i ], i, object[ i++ ] ) === false ) { break; } } } } return object; }, // Use native String.trim function wherever possible trim: trim ? function( text ) { return text == null ? """" : trim.call( text ); } : // Otherwise use our own trimming functionality function( text ) { return text == null ? """" : text.toString().replace( trimLeft, """" ).replace( trimRight, """" ); }, // results is for internal usage only makeArray: function( array, results ) { var ret = results || []; if ( array != null ) { // The window, strings (and functions) also have 'length' // Tweaked logic slightly to handle Blackberry 4.7 RegExp issues #6930 var type = jQuery.type( array ); if ( array.length == null || type === ""string"" || type === ""function"" || type === ""regexp"" || jQuery.isWindow( array ) ) { push.call( ret, array ); } else { jQuery.merge( ret, array ); } } return ret; }, inArray: function( elem, array, i ) { var len; if ( array ) { if ( indexOf ) { return indexOf.call( array, elem, i ); } len = array.length; i = i ? i < 0 ? Math.max( 0, len + i ) : i : 0; for ( ; i < len; i++ ) { // Skip accessing in sparse arrays if ( i in array && array[ i ] === elem ) { return i; } } } return -1; }, merge: function( first, second ) { var i = first.length, j = 0; if ( typeof second.length === ""number"" ) { for ( var l = second.length; j < l; j++ ) { first[ i++ ] = second[ j ]; } } else { while ( second[j] !== undefined ) { first[ i++ ] = second[ j++ ]; } } first.length = i; return first; }, grep: function( elems, callback, inv ) { var ret = [], retVal; inv = !!inv; // Go through the array, only saving the items // that pass the validator function for ( var i = 0, length = elems.length; i < length; i++ ) { retVal = !!callback( elems[ i ], i ); if ( inv !== retVal ) { ret.push( elems[ i ] ); } } return ret; }, // arg is for internal usage only map: function( elems, callback, arg ) { var value, key, ret = [], i = 0, length = elems.length, // jquery objects are treated as arrays isArray = elems instanceof jQuery || length !== undefined && typeof length === ""number"" && ( ( length > 0 && elems[ 0 ] && elems[ length -1 ] ) || length === 0 || jQuery.isArray( elems ) ) ; // Go through the array, translating each of the items to their if ( isArray ) { for ( ; i < length; i++ ) { value = callback( elems[ i ], i, arg ); if ( value != null ) { ret[ ret.length ] = value; } } // Go through every key on the object, } else { for ( key in elems ) { value = callback( elems[ key ], key, arg ); if ( value != null ) { ret[ ret.length ] = value; } } } // Flatten any nested arrays return ret.concat.apply( [], ret ); }, // A global GUID counter for objects guid: 1, // Bind a function to a context, optionally partially applying any // arguments. proxy: function( fn, context ) { if ( typeof context === ""string"" ) { var tmp = fn[ context ]; context = fn; fn = tmp; } // Quick check to determine if target is callable, in the spec // this throws a TypeError, but we will just return undefined. if ( !jQuery.isFunction( fn ) ) { return undefined; } // Simulated bind var args = slice.call( arguments, 2 ), proxy = function() { return fn.apply( context, args.concat( slice.call( arguments ) ) ); }; // Set the guid of unique handler to the same of original handler, so it can be removed proxy.guid = fn.guid = fn.guid || proxy.guid || jQuery.guid++; return proxy; }, // Mutifunctional method to get and set values to a collection // The value/s can optionally be executed if it's a function access: function( elems, fn, key, value, chainable, emptyGet, pass ) { var exec, bulk = key == null, i = 0, length = elems.length; // Sets many values if ( key && typeof key === ""object"" ) { for ( i in key ) { jQuery.access( elems, fn, i, key[i], 1, emptyGet, value ); } chainable = 1; // Sets one value } else if ( value !== undefined ) { // Optionally, function values get executed if exec is true exec = pass === undefined && jQuery.isFunction( value ); if ( bulk ) { // Bulk operations only iterate when executing function values if ( exec ) { exec = fn; fn = function( elem, key, value ) { return exec.call( jQuery( elem ), value ); }; // Otherwise they run against the entire set } else { fn.call( elems, value ); fn = null; } } if ( fn ) { for (; i < length; i++ ) { fn( elems[i], key, exec ? value.call( elems[i], i, fn( elems[i], key ) ) : value, pass ); } } chainable = 1; } return chainable ? elems : // Gets bulk ? fn.call( elems ) : length ? fn( elems[0], key ) : emptyGet; }, now: function() { return ( new Date() ).getTime(); }, // Use of jQuery.browser is frowned upon. // More details: http://docs.jquery.com/Utilities/jQuery.browser uaMatch: function( ua ) { ua = ua.toLowerCase(); var match = rwebkit.exec( ua ) || ropera.exec( ua ) || rmsie.exec( ua ) || ua.indexOf(""compatible"") < 0 && rmozilla.exec( ua ) || []; return { browser: match[1] || """", version: match[2] || ""0"" }; }, sub: function() { function jQuerySub( selector, context ) { return new jQuerySub.fn.init( selector, context ); } jQuery.extend( true, jQuerySub, this ); jQuerySub.superclass = this; jQuerySub.fn = jQuerySub.prototype = this(); jQuerySub.fn.constructor = jQuerySub; jQuerySub.sub = this.sub; jQuerySub.fn.init = function init( selector, context ) { if ( context && context instanceof jQuery && !(context instanceof jQuerySub) ) { context = jQuerySub( context ); } return jQuery.fn.init.call( this, selector, context, rootjQuerySub ); }; jQuerySub.fn.init.prototype = jQuerySub.fn; var rootjQuerySub = jQuerySub(document); return jQuerySub; }, browser: {} }); // Populate the class2type map jQuery.each(""Boolean Number String Function Array Date RegExp Object"".split("" ""), function(i, name) { class2type[ ""[object "" + name + ""]"" ] = name.toLowerCase(); }); browserMatch = jQuery.uaMatch( userAgent ); if ( browserMatch.browser ) { jQuery.browser[ browserMatch.browser ] = true; jQuery.browser.version = browserMatch.version; } // Deprecated, use jQuery.browser.webkit instead if ( jQuery.browser.webkit ) { jQuery.browser.safari = true; } // IE doesn't match non-breaking spaces with \s if ( rnotwhite.test( ""\xA0"" ) ) { trimLeft = /^[\s\xA0]+/; trimRight = /[\s\xA0]+$/; } // All jQuery objects should point back to these rootjQuery = jQuery(document); // Cleanup functions for the document ready method if ( document.addEventListener ) { DOMContentLoaded = function() { document.removeEventListener( ""DOMContentLoaded"", DOMContentLoaded, false ); jQuery.ready(); }; } else if ( document.attachEvent ) { DOMContentLoaded = function() { // Make sure body exists, at least, in case IE gets a little overzealous (ticket #5443). if ( document.readyState === ""complete"" ) { document.detachEvent( ""onreadystatechange"", DOMContentLoaded ); jQuery.ready(); } }; } // The DOM ready check for Internet Explorer function doScrollCheck() { if ( jQuery.isReady ) { return; } try { // If IE is used, use the trick by Diego Perini // http://javascript.nwbox.com/IEContentLoaded/ document.documentElement.doScroll(""left""); } catch(e) { setTimeout( doScrollCheck, 1 ); return; } // and execute any waiting functions jQuery.ready(); } return jQuery; })(); // String to Object flags format cache var flagsCache = {}; // Convert String-formatted flags into Object-formatted ones and store in cache function createFlags( flags ) { var object = flagsCache[ flags ] = {}, i, length; flags = flags.split( /\s+/ ); for ( i = 0, length = flags.length; i < length; i++ ) { object[ flags[i] ] = true; } return object; } /* * Create a callback list using the following parameters: * * flags: an optional list of space-separated flags that will change how * the callback list behaves * * By default a callback list will act like an event callback list and can be * ""fired"" multiple times. * * Possible flags: * * once: will ensure the callback list can only be fired once (like a Deferred) * * memory: will keep track of previous values and will call any callback added * after the list has been fired right away with the latest ""memorized"" * values (like a Deferred) * * unique: will ensure a callback can only be added once (no duplicate in the list) * * stopOnFalse: interrupt callings when a callback returns false * */ jQuery.Callbacks = function( flags ) { // Convert flags from String-formatted to Object-formatted // (we check in cache first) flags = flags ? ( flagsCache[ flags ] || createFlags( flags ) ) : {}; var // Actual callback list list = [], // Stack of fire calls for repeatable lists stack = [], // Last fire value (for non-forgettable lists) memory, // Flag to know if list was already fired fired, // Flag to know if list is currently firing firing, // First callback to fire (used internally by add and fireWith) firingStart, // End of the loop when firing firingLength, // Index of currently firing callback (modified by remove if needed) firingIndex, // Add one or several callbacks to the list add = function( args ) { var i, length, elem, type, actual; for ( i = 0, length = args.length; i < length; i++ ) { elem = args[ i ]; type = jQuery.type( elem ); if ( type === ""array"" ) { // Inspect recursively add( elem ); } else if ( type === ""function"" ) { // Add if not in unique mode and callback is not in if ( !flags.unique || !self.has( elem ) ) { list.push( elem ); } } } }, // Fire callbacks fire = function( context, args ) { args = args || []; memory = !flags.memory || [ context, args ]; fired = true; firing = true; firingIndex = firingStart || 0; firingStart = 0; firingLength = list.length; for ( ; list && firingIndex < firingLength; firingIndex++ ) { if ( list[ firingIndex ].apply( context, args ) === false && flags.stopOnFalse ) { memory = true; // Mark as halted break; } } firing = false; if ( list ) { if ( !flags.once ) { if ( stack && stack.length ) { memory = stack.shift(); self.fireWith( memory[ 0 ], memory[ 1 ] ); } } else if ( memory === true ) { self.disable(); } else { list = []; } } }, // Actual Callbacks object self = { // Add a callback or a collection of callbacks to the list add: function() { if ( list ) { var length = list.length; add( arguments ); // Do we need to add the callbacks to the // current firing batch? if ( firing ) { firingLength = list.length; // With memory, if we're not firing then // we should call right away, unless previous // firing was halted (stopOnFalse) } else if ( memory && memory !== true ) { firingStart = length; fire( memory[ 0 ], memory[ 1 ] ); } } return this; }, // Remove a callback from the list remove: function() { if ( list ) { var args = arguments, argIndex = 0, argLength = args.length; for ( ; argIndex < argLength ; argIndex++ ) { for ( var i = 0; i < list.length; i++ ) { if ( args[ argIndex ] === list[ i ] ) { // Handle firingIndex and firingLength if ( firing ) { if ( i <= firingLength ) { firingLength--; if ( i <= firingIndex ) { firingIndex--; } } } // Remove the element list.splice( i--, 1 ); // If we have some unicity property then // we only need to do this once if ( flags.unique ) { break; } } } } } return this; }, // Control if a given callback is in the list has: function( fn ) { if ( list ) { var i = 0, length = list.length; for ( ; i < length; i++ ) { if ( fn === list[ i ] ) { return true; } } } return false; }, // Remove all callbacks from the list empty: function() { list = []; return this; }, // Have the list do nothing anymore disable: function() { list = stack = memory = undefined; return this; }, // Is it disabled? disabled: function() { return !list; }, // Lock the list in its current state lock: function() { stack = undefined; if ( !memory || memory === true ) { self.disable(); } return this; }, // Is it locked? locked: function() { return !stack; }, // Call all callbacks with the given context and arguments fireWith: function( context, args ) { if ( stack ) { if ( firing ) { if ( !flags.once ) { stack.push( [ context, args ] ); } } else if ( !( flags.once && memory ) ) { fire( context, args ); } } return this; }, // Call all the callbacks with the given arguments fire: function() { self.fireWith( this, arguments ); return this; }, // To know if the callbacks have already been called at least once fired: function() { return !!fired; } }; return self; }; var // Static reference to slice sliceDeferred = [].slice; jQuery.extend({ Deferred: function( func ) { var doneList = jQuery.Callbacks( ""once memory"" ), failList = jQuery.Callbacks( ""once memory"" ), progressList = jQuery.Callbacks( ""memory"" ), state = ""pending"", lists = { resolve: doneList, reject: failList, notify: progressList }, promise = { done: doneList.add, fail: failList.add, progress: progressList.add, state: function() { return state; }, // Deprecated isResolved: doneList.fired, isRejected: failList.fired, then: function( doneCallbacks, failCallbacks, progressCallbacks ) { deferred.done( doneCallbacks ).fail( failCallbacks ).progress( progressCallbacks ); return this; }, always: function() { deferred.done.apply( deferred, arguments ).fail.apply( deferred, arguments ); return this; }, pipe: function( fnDone, fnFail, fnProgress ) { return jQuery.Deferred(function( newDefer ) { jQuery.each( { done: [ fnDone, ""resolve"" ], fail: [ fnFail, ""reject"" ], progress: [ fnProgress, ""notify"" ] }, function( handler, data ) { var fn = data[ 0 ], action = data[ 1 ], returned; if ( jQuery.isFunction( fn ) ) { deferred[ handler ](function() { returned = fn.apply( this, arguments ); if ( returned && jQuery.isFunction( returned.promise ) ) { returned.promise().then( newDefer.resolve, newDefer.reject, newDefer.notify ); } else { newDefer[ action + ""With"" ]( this === deferred ? newDefer : this, [ returned ] ); } }); } else { deferred[ handler ]( newDefer[ action ] ); } }); }).promise(); }, // Get a promise for this deferred // If obj is provided, the promise aspect is added to the object promise: function( obj ) { if ( obj == null ) { obj = promise; } else { for ( var key in promise ) { obj[ key ] = promise[ key ]; } } return obj; } }, deferred = promise.promise({}), key; for ( key in lists ) { deferred[ key ] = lists[ key ].fire; deferred[ key + ""With"" ] = lists[ key ].fireWith; } // Handle state deferred.done( function() { state = ""resolved""; }, failList.disable, progressList.lock ).fail( function() { state = ""rejected""; }, doneList.disable, progressList.lock ); // Call given func if any if ( func ) { func.call( deferred, deferred ); } // All done! return deferred; }, // Deferred helper when: function( firstParam ) { var args = sliceDeferred.call( arguments, 0 ), i = 0, length = args.length, pValues = new Array( length ), count = length, pCount = length, deferred = length <= 1 && firstParam && jQuery.isFunction( firstParam.promise ) ? firstParam : jQuery.Deferred(), promise = deferred.promise(); function resolveFunc( i ) { return function( value ) { args[ i ] = arguments.length > 1 ? sliceDeferred.call( arguments, 0 ) : value; if ( !( --count ) ) { deferred.resolveWith( deferred, args ); } }; } function progressFunc( i ) { return function( value ) { pValues[ i ] = arguments.length > 1 ? sliceDeferred.call( arguments, 0 ) : value; deferred.notifyWith( promise, pValues ); }; } if ( length > 1 ) { for ( ; i < length; i++ ) { if ( args[ i ] && args[ i ].promise && jQuery.isFunction( args[ i ].promise ) ) { args[ i ].promise().then( resolveFunc(i), deferred.reject, progressFunc(i) ); } else { --count; } } if ( !count ) { deferred.resolveWith( deferred, args ); } } else if ( deferred !== firstParam ) { deferred.resolveWith( deferred, length ? [ firstParam ] : [] ); } return promise; } }); jQuery.support = (function() { var support, all, a, select, opt, input, fragment, tds, events, eventName, i, isSupported, div = document.createElement( ""div"" ), documentElement = document.documentElement; // Preliminary tests div.setAttribute(""className"", ""t""); div.innerHTML = "" <link/><table></table><a href='/a' style='top:1px;float:left;opacity:.55;'>a</a><input type='checkbox'/>""; all = div.getElementsByTagName( ""*"" ); a = div.getElementsByTagName( ""a"" )[ 0 ]; // Can't get basic test support if ( !all || !all.length || !a ) { return {}; } // First batch of supports tests select = document.createElement( ""select"" ); opt = select.appendChild( document.createElement(""option"") ); input = div.getElementsByTagName( ""input"" )[ 0 ]; support = { // IE strips leading whitespace when .innerHTML is used leadingWhitespace: ( div.firstChild.nodeType === 3 ), // Make sure that tbody elements aren't automatically inserted // IE will insert them into empty tables tbody: !div.getElementsByTagName(""tbody"").length, // Make sure that link elements get serialized correctly by innerHTML // This requires a wrapper element in IE htmlSerialize: !!div.getElementsByTagName(""link"").length, // Get the style information from getAttribute // (IE uses .cssText instead) style: /top/.test( a.getAttribute(""style"") ), // Make sure that URLs aren't manipulated // (IE normalizes it by default) hrefNormalized: ( a.getAttribute(""href"") === ""/a"" ), // Make sure that element opacity exists // (IE uses filter instead) // Use a regex to work around a WebKit issue. See #5145 opacity: /^0.55/.test( a.style.opacity ), // Verify style float existence // (IE uses styleFloat instead of cssFloat) cssFloat: !!a.style.cssFloat, // Make sure that if no value is specified for a checkbox // that it defaults to ""on"". // (WebKit defaults to """" instead) checkOn: ( input.value === ""on"" ), // Make sure that a selected-by-default option has a working selected property. // (WebKit defaults to false instead of true, IE too, if it's in an optgroup) optSelected: opt.selected, // Test setAttribute on camelCase class. If it works, we need attrFixes when doing get/setAttribute (ie6/7) getSetAttribute: div.className !== ""t"", // Tests for enctype support on a form(#6743) enctype: !!document.createElement(""form"").enctype, // Makes sure cloning an html5 element does not cause problems // Where outerHTML is undefined, this still works html5Clone: document.createElement(""nav"").cloneNode( true ).outerHTML !== ""<:nav></:nav>"", // Will be defined later submitBubbles: true, changeBubbles: true, focusinBubbles: false, deleteExpando: true, noCloneEvent: true, inlineBlockNeedsLayout: false, shrinkWrapBlocks: false, reliableMarginRight: true, pixelMargin: true }; // jQuery.boxModel DEPRECATED in 1.3, use jQuery.support.boxModel instead jQuery.boxModel = support.boxModel = (document.compatMode === ""CSS1Compat""); // Make sure checked status is properly cloned input.checked = true; support.noCloneChecked = input.cloneNode( true ).checked; // Make sure that the options inside disabled selects aren't marked as disabled // (WebKit marks them as disabled) select.disabled = true; support.optDisabled = !opt.disabled; // Test to see if it's possible to delete an expando from an element // Fails in Internet Explorer try { delete div.test; } catch( e ) { support.deleteExpando = false; } if ( !div.addEventListener && div.attachEvent && div.fireEvent ) { div.attachEvent( ""onclick"", function() { // Cloning a node shouldn't copy over any // bound event handlers (IE does this) support.noCloneEvent = false; }); div.cloneNode( true ).fireEvent( ""onclick"" ); } // Check if a radio maintains its value // after being appended to the DOM input = document.createElement(""input""); input.value = ""t""; input.setAttribute(""type"", ""radio""); support.radioValue = input.value === ""t""; input.setAttribute(""checked"", ""checked""); // #11217 - WebKit loses check when the name is after the checked attribute input.setAttribute( ""name"", ""t"" ); div.appendChild( input ); fragment = document.createDocumentFragment(); fragment.appendChild( div.lastChild ); // WebKit doesn't clone checked state correctly in fragments support.checkClone = fragment.cloneNode( true ).cloneNode( true ).lastChild.checked; // Check if a disconnected checkbox will retain its checked // value of true after appended to the DOM (IE6/7) support.appendChecked = input.checked; fragment.removeChild( input ); fragment.appendChild( div ); // Technique from Juriy Zaytsev // http://perfectionkills.com/detecting-event-support-without-browser-sniffing/ // We only care about the case where non-standard event systems // are used, namely in IE. Short-circuiting here helps us to // avoid an eval call (in setAttribute) which can cause CSP // to go haywire. See: https://developer.mozilla.org/en/Security/CSP if ( div.attachEvent ) { for ( i in { submit: 1, change: 1, focusin: 1 }) { eventName = ""on"" + i; isSupported = ( eventName in div ); if ( !isSupported ) { div.setAttribute( eventName, ""return;"" ); isSupported = ( typeof div[ eventName ] === ""function"" ); } support[ i + ""Bubbles"" ] = isSupported; } } fragment.removeChild( div ); // Null elements to avoid leaks in IE fragment = select = opt = div = input = null; // Run tests that need a body at doc ready jQuery(function() { var container, outer, inner, table, td, offsetSupport, marginDiv, conMarginTop, style, html, positionTopLeftWidthHeight, paddingMarginBorderVisibility, paddingMarginBorder, body = document.getElementsByTagName(""body"")[0]; if ( !body ) { // Return for frameset docs that don't have a body return; } conMarginTop = 1; paddingMarginBorder = ""padding:0;margin:0;border:""; positionTopLeftWidthHeight = ""position:absolute;top:0;left:0;width:1px;height:1px;""; paddingMarginBorderVisibility = paddingMarginBorder + ""0;visibility:hidden;""; style = ""style='"" + positionTopLeftWidthHeight + paddingMarginBorder + ""5px solid #000;""; html = ""<div "" + style + ""display:block;'><div style='"" + paddingMarginBorder + ""0;display:block;overflow:hidden;'></div></div>"" + ""<table "" + style + ""' cellpadding='0' cellspacing='0'>"" + ""<tr><td></td></tr></table>""; container = document.createElement(""div""); container.style.cssText = paddingMarginBorderVisibility + ""width:0;height:0;position:static;top:0;margin-top:"" + conMarginTop + ""px""; body.insertBefore( container, body.firstChild ); // Construct the test element div = document.createElement(""div""); container.appendChild( div ); // Check if table cells still have offsetWidth/Height when they are set // to display:none and there are still other visible table cells in a // table row; if so, offsetWidth/Height are not reliable for use when // determining if an element has been hidden directly using // display:none (it is still safe to use offsets if a parent element is // hidden; don safety goggles and see bug #4512 for more information). // (only IE 8 fails this test) div.innerHTML = ""<table><tr><td style='"" + paddingMarginBorder + ""0;display:none'></td><td>t</td></tr></table>""; tds = div.getElementsByTagName( ""td"" ); isSupported = ( tds[ 0 ].offsetHeight === 0 ); tds[ 0 ].style.display = """"; tds[ 1 ].style.display = ""none""; // Check if empty table cells still have offsetWidth/Height // (IE <= 8 fail this test) support.reliableHiddenOffsets = isSupported && ( tds[ 0 ].offsetHeight === 0 ); // Check if div with explicit width and no margin-right incorrectly // gets computed margin-right based on width of container. For more // info see bug #3333 // Fails in WebKit before Feb 2011 nightlies // WebKit Bug 13343 - getComputedStyle returns wrong value for margin-right if ( window.getComputedStyle ) { div.innerHTML = """"; marginDiv = document.createElement( ""div"" ); marginDiv.style.width = ""0""; marginDiv.style.marginRight = ""0""; div.style.width = ""2px""; div.appendChild( marginDiv ); support.reliableMarginRight = ( parseInt( ( window.getComputedStyle( marginDiv, null ) || { marginRight: 0 } ).marginRight, 10 ) || 0 ) === 0; } if ( typeof div.style.zoom !== ""undefined"" ) { // Check if natively block-level elements act like inline-block // elements when setting their display to 'inline' and giving // them layout // (IE < 8 does this) div.innerHTML = """"; div.style.width = div.style.padding = ""1px""; div.style.border = 0; div.style.overflow = ""hidden""; div.style.display = ""inline""; div.style.zoom = 1; support.inlineBlockNeedsLayout = ( div.offsetWidth === 3 ); // Check if elements with layout shrink-wrap their children // (IE 6 does this) div.style.display = ""block""; div.style.overflow = ""visible""; div.innerHTML = ""<div style='width:5px;'></div>""; support.shrinkWrapBlocks = ( div.offsetWidth !== 3 ); } div.style.cssText = positionTopLeftWidthHeight + paddingMarginBorderVisibility; div.innerHTML = html; outer = div.firstChild; inner = outer.firstChild; td = outer.nextSibling.firstChild.firstChild; offsetSupport = { doesNotAddBorder: ( inner.offsetTop !== 5 ), doesAddBorderForTableAndCells: ( td.offsetTop === 5 ) }; inner.style.position = ""fixed""; inner.style.top = ""20px""; // safari subtracts parent border width here which is 5px offsetSupport.fixedPosition = ( inner.offsetTop === 20 || inner.offsetTop === 15 ); inner.style.position = inner.style.top = """"; outer.style.overflow = ""hidden""; outer.style.position = ""relative""; offsetSupport.subtractsBorderForOverflowNotVisible = ( inner.offsetTop === -5 ); offsetSupport.doesNotIncludeMarginInBodyOffset = ( body.offsetTop !== conMarginTop ); if ( window.getComputedStyle ) { div.style.marginTop = ""1%""; support.pixelMargin = ( window.getComputedStyle( div, null ) || { marginTop: 0 } ).marginTop !== ""1%""; } if ( typeof container.style.zoom !== ""undefined"" ) { container.style.zoom = 1; } body.removeChild( container ); marginDiv = div = container = null; jQuery.extend( support, offsetSupport ); }); return support; })(); var rbrace = /^(?:\{.*\}|\[.*\])$/, rmultiDash = /([A-Z])/g; jQuery.extend({ cache: {}, // Please use with caution uuid: 0, // Unique for each copy of jQuery on the page // Non-digits removed to match rinlinejQuery expando: ""jQuery"" + ( jQuery.fn.jquery + Math.random() ).replace( /\D/g, """" ), // The following elements throw uncatchable exceptions if you // attempt to add expando properties to them. noData: { ""embed"": true, // Ban all objects except for Flash (which handle expandos) ""object"": ""clsid:D27CDB6E-AE6D-11cf-96B8-444553540000"", ""applet"": true }, hasData: function( elem ) { elem = elem.nodeType ? jQuery.cache[ elem[jQuery.expando] ] : elem[ jQuery.expando ]; return !!elem && !isEmptyDataObject( elem ); }, data: function( elem, name, data, pvt /* Internal Use Only */ ) { if ( !jQuery.acceptData( elem ) ) { return; } var privateCache, thisCache, ret, internalKey = jQuery.expando, getByName = typeof name === ""string"", // We have to handle DOM nodes and JS objects differently because IE6-7 // can't GC object references properly across the DOM-JS boundary isNode = elem.nodeType, // Only DOM nodes need the global jQuery cache; JS object data is // attached directly to the object so GC can occur automatically cache = isNode ? jQuery.cache : elem, // Only defining an ID for JS objects if its cache already exists allows // the code to shortcut on the same path as a DOM node with no cache id = isNode ? elem[ internalKey ] : elem[ internalKey ] && internalKey, isEvents = name === ""events""; // Avoid doing any more work than we need to when trying to get data on an // object that has no data at all if ( (!id || !cache[id] || (!isEvents && !pvt && !cache[id].data)) && getByName && data === undefined ) { return; } if ( !id ) { // Only DOM nodes need a new unique ID for each element since their data // ends up in the global cache if ( isNode ) { elem[ internalKey ] = id = ++jQuery.uuid; } else { id = internalKey; } } if ( !cache[ id ] ) { cache[ id ] = {}; // Avoids exposing jQuery metadata on plain JS objects when the object // is serialized using JSON.stringify if ( !isNode ) { cache[ id ].toJSON = jQuery.noop; } } // An object can be passed to jQuery.data instead of a key/value pair; this gets // shallow copied over onto the existing cache if ( typeof name === ""object"" || typeof name === ""function"" ) { if ( pvt ) { cache[ id ] = jQuery.extend( cache[ id ], name ); } else { cache[ id ].data = jQuery.extend( cache[ id ].data, name ); } } privateCache = thisCache = cache[ id ]; // jQuery data() is stored in a separate object inside the object's internal data // cache in order to avoid key collisions between internal data and user-defined // data. if ( !pvt ) { if ( !thisCache.data ) { thisCache.data = {}; } thisCache = thisCache.data; } if ( data !== undefined ) { thisCache[ jQuery.camelCase( name ) ] = data; } // Users should not attempt to inspect the internal events object using jQuery.data, // it is undocumented and subject to change. But does anyone listen? No. if ( isEvents && !thisCache[ name ] ) { return privateCache.events; } // Check for both converted-to-camel and non-converted data property names // If a data property was specified if ( getByName ) { // First Try to find as-is property data ret = thisCache[ name ]; // Test for null|undefined property data if ( ret == null ) { // Try to find the camelCased property ret = thisCache[ jQuery.camelCase( name ) ]; } } else { ret = thisCache; } return ret; }, removeData: function( elem, name, pvt /* Internal Use Only */ ) { if ( !jQuery.acceptData( elem ) ) { return; } var thisCache, i, l, // Reference to internal data cache key internalKey = jQuery.expando, isNode = elem.nodeType, // See jQuery.data for more information cache = isNode ? jQuery.cache : elem, // See jQuery.data for more information id = isNode ? elem[ internalKey ] : internalKey; // If there is already no cache entry for this object, there is no // purpose in continuing if ( !cache[ id ] ) { return; } if ( name ) { thisCache = pvt ? cache[ id ] : cache[ id ].data; if ( thisCache ) { // Support array or space separated string names for data keys if ( !jQuery.isArray( name ) ) { // try the string as a key before any manipulation if ( name in thisCache ) { name = [ name ]; } else { // split the camel cased version by spaces unless a key with the spaces exists name = jQuery.camelCase( name ); if ( name in thisCache ) { name = [ name ]; } else { name = name.split( "" "" ); } } } for ( i = 0, l = name.length; i < l; i++ ) { delete thisCache[ name[i] ]; } // If there is no data left in the cache, we want to continue // and let the cache object itself get destroyed if ( !( pvt ? isEmptyDataObject : jQuery.isEmptyObject )( thisCache ) ) { return; } } } // See jQuery.data for more information if ( !pvt ) { delete cache[ id ].data; // Don't destroy the parent cache unless the internal data object // had been the only thing left in it if ( !isEmptyDataObject(cache[ id ]) ) { return; } } // Browsers that fail expando deletion also refuse to delete expandos on // the window, but it will allow it on all other JS objects; other browsers // don't care // Ensure that `cache` is not a window object #10080 if ( jQuery.support.deleteExpando || !cache.setInterval ) { delete cache[ id ]; } else { cache[ id ] = null; } // We destroyed the cache and need to eliminate the expando on the node to avoid // false lookups in the cache for entries that no longer exist if ( isNode ) { // IE does not allow us to delete expando properties from nodes, // nor does it have a removeAttribute function on Document nodes; // we must handle all of these cases if ( jQuery.support.deleteExpando ) { delete elem[ internalKey ]; } else if ( elem.removeAttribute ) { elem.removeAttribute( internalKey ); } else { elem[ internalKey ] = null; } } }, // For internal use only. _data: function( elem, name, data ) { return jQuery.data( elem, name, data, true ); }, // A method for determining if a DOM node can handle the data expando acceptData: function( elem ) { if ( elem.nodeName ) { var match = jQuery.noData[ elem.nodeName.toLowerCase() ]; if ( match ) { return !(match === true || elem.getAttribute(""classid"") !== match); } } return true; } }); jQuery.fn.extend({ data: function( key, value ) { var parts, part, attr, name, l, elem = this[0], i = 0, data = null; // Gets all values if ( key === undefined ) { if ( this.length ) { data = jQuery.data( elem ); if ( elem.nodeType === 1 && !jQuery._data( elem, ""parsedAttrs"" ) ) { attr = elem.attributes; for ( l = attr.length; i < l; i++ ) { name = attr[i].name; if ( name.indexOf( ""data-"" ) === 0 ) { name = jQuery.camelCase( name.substring(5) ); dataAttr( elem, name, data[ name ] ); } } jQuery._data( elem, ""parsedAttrs"", true ); } } return data; } // Sets multiple values if ( typeof key === ""object"" ) { return this.each(function() { jQuery.data( this, key ); }); } parts = key.split( ""."", 2 ); parts[1] = parts[1] ? ""."" + parts[1] : """"; part = parts[1] + ""!""; return jQuery.access( this, function( value ) { if ( value === undefined ) { data = this.triggerHandler( ""getData"" + part, [ parts[0] ] ); // Try to fetch any internally stored data first if ( data === undefined && elem ) { data = jQuery.data( elem, key ); data = dataAttr( elem, key, data ); } return data === undefined && parts[1] ? this.data( parts[0] ) : data; } parts[1] = value; this.each(function() { var self = jQuery( this ); self.triggerHandler( ""setData"" + part, parts ); jQuery.data( this, key, value ); self.triggerHandler( ""changeData"" + part, parts ); }); }, null, value, arguments.length > 1, null, false ); }, removeData: function( key ) { return this.each(function() { jQuery.removeData( this, key ); }); } }); function dataAttr( elem, key, data ) { // If nothing was found internally, try to fetch any // data from the HTML5 data-* attribute if ( data === undefined && elem.nodeType === 1 ) { var name = ""data-"" + key.replace( rmultiDash, ""-$1"" ).toLowerCase(); data = elem.getAttribute( name ); if ( typeof data === ""string"" ) { try { data = data === ""true"" ? true : data === ""false"" ? false : data === ""null"" ? null : jQuery.isNumeric( data ) ? +data : rbrace.test( data ) ? jQuery.parseJSON( data ) : data; } catch( e ) {} // Make sure we set the data so it isn't changed later jQuery.data( elem, key, data ); } else { data = undefined; } } return data; } // checks a cache object for emptiness function isEmptyDataObject( obj ) { for ( var name in obj ) { // if the public data object is empty, the private is still empty if ( name === ""data"" && jQuery.isEmptyObject( obj[name] ) ) { continue; } if ( name !== ""toJSON"" ) { return false; } } return true; } function handleQueueMarkDefer( elem, type, src ) { var deferDataKey = type + ""defer"", queueDataKey = type + ""queue"", markDataKey = type + ""mark"", defer = jQuery._data( elem, deferDataKey ); if ( defer && ( src === ""queue"" || !jQuery._data(elem, queueDataKey) ) && ( src === ""mark"" || !jQuery._data(elem, markDataKey) ) ) { // Give room for hard-coded callbacks to fire first // and eventually mark/queue something else on the element setTimeout( function() { if ( !jQuery._data( elem, queueDataKey ) && !jQuery._data( elem, markDataKey ) ) { jQuery.removeData( elem, deferDataKey, true ); defer.fire(); } }, 0 ); } } jQuery.extend({ _mark: function( elem, type ) { if ( elem ) { type = ( type || ""fx"" ) + ""mark""; jQuery._data( elem, type, (jQuery._data( elem, type ) || 0) + 1 ); } }, _unmark: function( force, elem, type ) { if ( force !== true ) { type = elem; elem = force; force = false; } if ( elem ) { type = type || ""fx""; var key = type + ""mark"", count = force ? 0 : ( (jQuery._data( elem, key ) || 1) - 1 ); if ( count ) { jQuery._data( elem, key, count ); } else { jQuery.removeData( elem, key, true ); handleQueueMarkDefer( elem, type, ""mark"" ); } } }, queue: function( elem, type, data ) { var q; if ( elem ) { type = ( type || ""fx"" ) + ""queue""; q = jQuery._data( elem, type ); // Speed up dequeue by getting out quickly if this is just a lookup if ( data ) { if ( !q || jQuery.isArray(data) ) { q = jQuery._data( elem, type, jQuery.makeArray(data) ); } else { q.push( data ); } } return q || []; } }, dequeue: function( elem, type ) { type = type || ""fx""; var queue = jQuery.queue( elem, type ), fn = queue.shift(), hooks = {}; // If the fx queue is dequeued, always remove the progress sentinel if ( fn === ""inprogress"" ) { fn = queue.shift(); } if ( fn ) { // Add a progress sentinel to prevent the fx queue from being // automatically dequeued if ( type === ""fx"" ) { queue.unshift( ""inprogress"" ); } jQuery._data( elem, type + "".run"", hooks ); fn.call( elem, function() { jQuery.dequeue( elem, type ); }, hooks ); } if ( !queue.length ) { jQuery.removeData( elem, type + ""queue "" + type + "".run"", true ); handleQueueMarkDefer( elem, type, ""queue"" ); } } }); jQuery.fn.extend({ queue: function( type, data ) { var setter = 2; if ( typeof type !== ""string"" ) { data = type; type = ""fx""; setter--; } if ( arguments.length < setter ) { return jQuery.queue( this[0], type ); } return data === undefined ? this : this.each(function() { var queue = jQuery.queue( this, type, data ); if ( type === ""fx"" && queue[0] !== ""inprogress"" ) { jQuery.dequeue( this, type ); } }); }, dequeue: function( type ) { return this.each(function() { jQuery.dequeue( this, type ); }); }, // Based off of the plugin by Clint Helfers, with permission. // http://blindsignals.com/index.php/2009/07/jquery-delay/ delay: function( time, type ) { time = jQuery.fx ? jQuery.fx.speeds[ time ] || time : time; type = type || ""fx""; return this.queue( type, function( next, hooks ) { var timeout = setTimeout( next, time ); hooks.stop = function() { clearTimeout( timeout ); }; }); }, clearQueue: function( type ) { return this.queue( type || ""fx"", [] ); }, // Get a promise resolved when queues of a certain type // are emptied (fx is the type by default) promise: function( type, object ) { if ( typeof type !== ""string"" ) { object = type; type = undefined; } type = type || ""fx""; var defer = jQuery.Deferred(), elements = this, i = elements.length, count = 1, deferDataKey = type + ""defer"", queueDataKey = type + ""queue"", markDataKey = type + ""mark"", tmp; function resolve() { if ( !( --count ) ) { defer.resolveWith( elements, [ elements ] ); } } while( i-- ) { if (( tmp = jQuery.data( elements[ i ], deferDataKey, undefined, true ) || ( jQuery.data( elements[ i ], queueDataKey, undefined, true ) || jQuery.data( elements[ i ], markDataKey, undefined, true ) ) && jQuery.data( elements[ i ], deferDataKey, jQuery.Callbacks( ""once memory"" ), true ) )) { count++; tmp.add( resolve ); } } resolve(); return defer.promise( object ); } }); var rclass = /[\n\t\r]/g, rspace = /\s+/, rreturn = /\r/g, rtype = /^(?:button|input)$/i, rfocusable = /^(?:button|input|object|select|textarea)$/i, rclickable = /^a(?:rea)?$/i, rboolean = /^(?:autofocus|autoplay|async|checked|controls|defer|disabled|hidden|loop|multiple|open|readonly|required|scoped|selected)$/i, getSetAttribute = jQuery.support.getSetAttribute, nodeHook, boolHook, fixSpecified; jQuery.fn.extend({ attr: function( name, value ) { return jQuery.access( this, jQuery.attr, name, value, arguments.length > 1 ); }, removeAttr: function( name ) { return this.each(function() { jQuery.removeAttr( this, name ); }); }, prop: function( name, value ) { return jQuery.access( this, jQuery.prop, name, value, arguments.length > 1 ); }, removeProp: function( name ) { name = jQuery.propFix[ name ] || name; return this.each(function() { // try/catch handles cases where IE balks (such as removing a property on window) try { this[ name ] = undefined; delete this[ name ]; } catch( e ) {} }); }, addClass: function( value ) { var classNames, i, l, elem, setClass, c, cl; if ( jQuery.isFunction( value ) ) { return this.each(function( j ) { jQuery( this ).addClass( value.call(this, j, this.className) ); }); } if ( value && typeof value === ""string"" ) { classNames = value.split( rspace ); for ( i = 0, l = this.length; i < l; i++ ) { elem = this[ i ]; if ( elem.nodeType === 1 ) { if ( !elem.className && classNames.length === 1 ) { elem.className = value; } else { setClass = "" "" + elem.className + "" ""; for ( c = 0, cl = classNames.length; c < cl; c++ ) { if ( !~setClass.indexOf( "" "" + classNames[ c ] + "" "" ) ) { setClass += classNames[ c ] + "" ""; } } elem.className = jQuery.trim( setClass ); } } } } return this; }, removeClass: function( value ) { var classNames, i, l, elem, className, c, cl; if ( jQuery.isFunction( value ) ) { return this.each(function( j ) { jQuery( this ).removeClass( value.call(this, j, this.className) ); }); } if ( (value && typeof value === ""string"") || value === undefined ) { classNames = ( value || """" ).split( rspace ); for ( i = 0, l = this.length; i < l; i++ ) { elem = this[ i ]; if ( elem.nodeType === 1 && elem.className ) { if ( value ) { className = ("" "" + elem.className + "" "").replace( rclass, "" "" ); for ( c = 0, cl = classNames.length; c < cl; c++ ) { className = className.replace("" "" + classNames[ c ] + "" "", "" ""); } elem.className = jQuery.trim( className ); } else { elem.className = """"; } } } } return this; }, toggleClass: function( value, stateVal ) { var type = typeof value, isBool = typeof stateVal === ""boolean""; if ( jQuery.isFunction( value ) ) { return this.each(function( i ) { jQuery( this ).toggleClass( value.call(this, i, this.className, stateVal), stateVal ); }); } return this.each(function() { if ( type === ""string"" ) { // toggle individual class names var className, i = 0, self = jQuery( this ), state = stateVal, classNames = value.split( rspace ); while ( (className = classNames[ i++ ]) ) { // check each className given, space seperated list state = isBool ? state : !self.hasClass( className ); self[ state ? ""addClass"" : ""removeClass"" ]( className ); } } else if ( type === ""undefined"" || type === ""boolean"" ) { if ( this.className ) { // store className if set jQuery._data( this, ""__className__"", this.className ); } // toggle whole className this.className = this.className || value === false ? """" : jQuery._data( this, ""__className__"" ) || """"; } }); }, hasClass: function( selector ) { var className = "" "" + selector + "" "", i = 0, l = this.length; for ( ; i < l; i++ ) { if ( this[i].nodeType === 1 && ("" "" + this[i].className + "" "").replace(rclass, "" "").indexOf( className ) > -1 ) { return true; } } return false; }, val: function( value ) { var hooks, ret, isFunction, elem = this[0]; if ( !arguments.length ) { if ( elem ) { hooks = jQuery.valHooks[ elem.type ] || jQuery.valHooks[ elem.nodeName.toLowerCase() ]; if ( hooks && ""get"" in hooks && (ret = hooks.get( elem, ""value"" )) !== undefined ) { return ret; } ret = elem.value; return typeof ret === ""string"" ? // handle most common string cases ret.replace(rreturn, """") : // handle cases where value is null/undef or number ret == null ? """" : ret; } return; } isFunction = jQuery.isFunction( value ); return this.each(function( i ) { var self = jQuery(this), val; if ( this.nodeType !== 1 ) { return; } if ( isFunction ) { val = value.call( this, i, self.val() ); } else { val = value; } // Treat null/undefined as """"; convert numbers to string if ( val == null ) { val = """"; } else if ( typeof val === ""number"" ) { val += """"; } else if ( jQuery.isArray( val ) ) { val = jQuery.map(val, function ( value ) { return value == null ? """" : value + """"; }); } hooks = jQuery.valHooks[ this.type ] || jQuery.valHooks[ this.nodeName.toLowerCase() ]; // If set returns undefined, fall back to normal setting if ( !hooks || !(""set"" in hooks) || hooks.set( this, val, ""value"" ) === undefined ) { this.value = val; } }); } }); jQuery.extend({ valHooks: { option: { get: function( elem ) { // attributes.value is undefined in Blackberry 4.7 but // uses .value. See #6932 var val = elem.attributes.value; return !val || val.specified ? elem.value : elem.text; } }, select: { get: function( elem ) { var value, i, max, option, index = elem.selectedIndex, values = [], options = elem.options, one = elem.type === ""select-one""; // Nothing was selected if ( index < 0 ) { return null; } // Loop through all the selected options i = one ? index : 0; max = one ? index + 1 : options.length; for ( ; i < max; i++ ) { option = options[ i ]; // Don't return options that are disabled or in a disabled optgroup if ( option.selected && (jQuery.support.optDisabled ? !option.disabled : option.getAttribute(""disabled"") === null) && (!option.parentNode.disabled || !jQuery.nodeName( option.parentNode, ""optgroup"" )) ) { // Get the specific value for the option value = jQuery( option ).val(); // We don't need an array for one selects if ( one ) { return value; } // Multi-Selects return an array values.push( value ); } } // Fixes Bug #2551 -- select.val() broken in IE after form.reset() if ( one && !values.length && options.length ) { return jQuery( options[ index ] ).val(); } return values; }, set: function( elem, value ) { var values = jQuery.makeArray( value ); jQuery(elem).find(""option"").each(function() { this.selected = jQuery.inArray( jQuery(this).val(), values ) >= 0; }); if ( !values.length ) { elem.selectedIndex = -1; } return values; } } }, attrFn: { val: true, css: true, html: true, text: true, data: true, width: true, height: true, offset: true }, attr: function( elem, name, value, pass ) { var ret, hooks, notxml, nType = elem.nodeType; // don't get/set attributes on text, comment and attribute nodes if ( !elem || nType === 3 || nType === 8 || nType === 2 ) { return; } if ( pass && name in jQuery.attrFn ) { return jQuery( elem )[ name ]( value ); } // Fallback to prop when attributes are not supported if ( typeof elem.getAttribute === ""undefined"" ) { return jQuery.prop( elem, name, value ); } notxml = nType !== 1 || !jQuery.isXMLDoc( elem ); // All attributes are lowercase // Grab necessary hook if one is defined if ( notxml ) { name = name.toLowerCase(); hooks = jQuery.attrHooks[ name ] || ( rboolean.test( name ) ? boolHook : nodeHook ); } if ( value !== undefined ) { if ( value === null ) { jQuery.removeAttr( elem, name ); return; } else if ( hooks && ""set"" in hooks && notxml && (ret = hooks.set( elem, value, name )) !== undefined ) { return ret; } else { elem.setAttribute( name, """" + value ); return value; } } else if ( hooks && ""get"" in hooks && notxml && (ret = hooks.get( elem, name )) !== null ) { return ret; } else { ret = elem.getAttribute( name ); // Non-existent attributes return null, we normalize to undefined return ret === null ? undefined : ret; } }, removeAttr: function( elem, value ) { var propName, attrNames, name, l, isBool, i = 0; if ( value && elem.nodeType === 1 ) { attrNames = value.toLowerCase().split( rspace ); l = attrNames.length; for ( ; i < l; i++ ) { name = attrNames[ i ]; if ( name ) { propName = jQuery.propFix[ name ] || name; isBool = rboolean.test( name ); // See #9699 for explanation of this approach (setting first, then removal) // Do not do this for boolean attributes (see #10870) if ( !isBool ) { jQuery.attr( elem, name, """" ); } elem.removeAttribute( getSetAttribute ? name : propName ); // Set corresponding property to false for boolean attributes if ( isBool && propName in elem ) { elem[ propName ] = false; } } } } }, attrHooks: { type: { set: function( elem, value ) { // We can't allow the type property to be changed (since it causes problems in IE) if ( rtype.test( elem.nodeName ) && elem.parentNode ) { jQuery.error( ""type property can't be changed"" ); } else if ( !jQuery.support.radioValue && value === ""radio"" && jQuery.nodeName(elem, ""input"") ) { // Setting the type on a radio button after the value resets the value in IE6-9 // Reset value to it's default in case type is set after value // This is for element creation var val = elem.value; elem.setAttribute( ""type"", value ); if ( val ) { elem.value = val; } return value; } } }, // Use the value property for back compat // Use the nodeHook for button elements in IE6/7 (#1954) value: { get: function( elem, name ) { if ( nodeHook && jQuery.nodeName( elem, ""button"" ) ) { return nodeHook.get( elem, name ); } return name in elem ? elem.value : null; }, set: function( elem, value, name ) { if ( nodeHook && jQuery.nodeName( elem, ""button"" ) ) { return nodeHook.set( elem, value, name ); } // Does not return so that setAttribute is also used elem.value = value; } } }, propFix: { tabindex: ""tabIndex"", readonly: ""readOnly"", ""for"": ""htmlFor"", ""class"": ""className"", maxlength: ""maxLength"", cellspacing: ""cellSpacing"", cellpadding: ""cellPadding"", rowspan: ""rowSpan"", colspan: ""colSpan"", usemap: ""useMap"", frameborder: ""frameBorder"", contenteditable: ""contentEditable"" }, prop: function( elem, name, value ) { var ret, hooks, notxml, nType = elem.nodeType; // don't get/set properties on text, comment and attribute nodes if ( !elem || nType === 3 || nType === 8 || nType === 2 ) { return; } notxml = nType !== 1 || !jQuery.isXMLDoc( elem ); if ( notxml ) { // Fix name and attach hooks name = jQuery.propFix[ name ] || name; hooks = jQuery.propHooks[ name ]; } if ( value !== undefined ) { if ( hooks && ""set"" in hooks && (ret = hooks.set( elem, value, name )) !== undefined ) { return ret; } else { return ( elem[ name ] = value ); } } else { if ( hooks && ""get"" in hooks && (ret = hooks.get( elem, name )) !== null ) { return ret; } else { return elem[ name ]; } } }, propHooks: { tabIndex: { get: function( elem ) { // elem.tabIndex doesn't always return the correct value when it hasn't been explicitly set // http://fluidproject.org/blog/2008/01/09/getting-setting-and-removing-tabindex-values-with-javascript/ var attributeNode = elem.getAttributeNode(""tabindex""); return attributeNode && attributeNode.specified ? parseInt( attributeNode.value, 10 ) : rfocusable.test( elem.nodeName ) || rclickable.test( elem.nodeName ) && elem.href ? 0 : undefined; } } } }); // Add the tabIndex propHook to attrHooks for back-compat (different case is intentional) jQuery.attrHooks.tabindex = jQuery.propHooks.tabIndex; // Hook for boolean attributes boolHook = { get: function( elem, name ) { // Align boolean attributes with corresponding properties // Fall back to attribute presence where some booleans are not supported var attrNode, property = jQuery.prop( elem, name ); return property === true || typeof property !== ""boolean"" && ( attrNode = elem.getAttributeNode(name) ) && attrNode.nodeValue !== false ? name.toLowerCase() : undefined; }, set: function( elem, value, name ) { var propName; if ( value === false ) { // Remove boolean attributes when set to false jQuery.removeAttr( elem, name ); } else { // value is true since we know at this point it's type boolean and not false // Set boolean attributes to the same name and set the DOM property propName = jQuery.propFix[ name ] || name; if ( propName in elem ) { // Only set the IDL specifically if it already exists on the element elem[ propName ] = true; } elem.setAttribute( name, name.toLowerCase() ); } return name; } }; // IE6/7 do not support getting/setting some attributes with get/setAttribute if ( !getSetAttribute ) { fixSpecified = { name: true, id: true, coords: true }; // Use this for any attribute in IE6/7 // This fixes almost every IE6/7 issue nodeHook = jQuery.valHooks.button = { get: function( elem, name ) { var ret; ret = elem.getAttributeNode( name ); return ret && ( fixSpecified[ name ] ? ret.nodeValue !== """" : ret.specified ) ? ret.nodeValue : undefined; }, set: function( elem, value, name ) { // Set the existing or create a new attribute node var ret = elem.getAttributeNode( name ); if ( !ret ) { ret = document.createAttribute( name ); elem.setAttributeNode( ret ); } return ( ret.nodeValue = value + """" ); } }; // Apply the nodeHook to tabindex jQuery.attrHooks.tabindex.set = nodeHook.set; // Set width and height to auto instead of 0 on empty string( Bug #8150 ) // This is for removals jQuery.each([ ""width"", ""height"" ], function( i, name ) { jQuery.attrHooks[ name ] = jQuery.extend( jQuery.attrHooks[ name ], { set: function( elem, value ) { if ( value === """" ) { elem.setAttribute( name, ""auto"" ); return value; } } }); }); // Set contenteditable to false on removals(#10429) // Setting to empty string throws an error as an invalid value jQuery.attrHooks.contenteditable = { get: nodeHook.get, set: function( elem, value, name ) { if ( value === """" ) { value = ""false""; } nodeHook.set( elem, value, name ); } }; } // Some attributes require a special call on IE if ( !jQuery.support.hrefNormalized ) { jQuery.each([ ""href"", ""src"", ""width"", ""height"" ], function( i, name ) { jQuery.attrHooks[ name ] = jQuery.extend( jQuery.attrHooks[ name ], { get: function( elem ) { var ret = elem.getAttribute( name, 2 ); return ret === null ? undefined : ret; } }); }); } if ( !jQuery.support.style ) { jQuery.attrHooks.style = { get: function( elem ) { // Return undefined in the case of empty string // Normalize to lowercase since IE uppercases css property names return elem.style.cssText.toLowerCase() || undefined; }, set: function( elem, value ) { return ( elem.style.cssText = """" + value ); } }; } // Safari mis-reports the default selected property of an option // Accessing the parent's selectedIndex property fixes it if ( !jQuery.support.optSelected ) { jQuery.propHooks.selected = jQuery.extend( jQuery.propHooks.selected, { get: function( elem ) { var parent = elem.parentNode; if ( parent ) { parent.selectedIndex; // Make sure that it also works with optgroups, see #5701 if ( parent.parentNode ) { parent.parentNode.selectedIndex; } } return null; } }); } // IE6/7 call enctype encoding if ( !jQuery.support.enctype ) { jQuery.propFix.enctype = ""encoding""; } // Radios and checkboxes getter/setter if ( !jQuery.support.checkOn ) { jQuery.each([ ""radio"", ""checkbox"" ], function() { jQuery.valHooks[ this ] = { get: function( elem ) { // Handle the case where in Webkit """" is returned instead of ""on"" if a value isn't specified return elem.getAttribute(""value"") === null ? ""on"" : elem.value; } }; }); } jQuery.each([ ""radio"", ""checkbox"" ], function() { jQuery.valHooks[ this ] = jQuery.extend( jQuery.valHooks[ this ], { set: function( elem, value ) { if ( jQuery.isArray( value ) ) { return ( elem.checked = jQuery.inArray( jQuery(elem).val(), value ) >= 0 ); } } }); }); var rformElems = /^(?:textarea|input|select)$/i, rtypenamespace = /^([^\.]*)?(?:\.(.+))?$/, rhoverHack = /(?:^|\s)hover(\.\S+)?\b/, rkeyEvent = /^key/, rmouseEvent = /^(?:mouse|contextmenu)|click/, rfocusMorph = /^(?:focusinfocus|focusoutblur)$/, rquickIs = /^(\w*)(?:#([\w\-]+))?(?:\.([\w\-]+))?$/, quickParse = function( selector ) { var quick = rquickIs.exec( selector ); if ( quick ) { // 0 1 2 3 // [ _, tag, id, class ] quick[1] = ( quick[1] || """" ).toLowerCase(); quick[3] = quick[3] && new RegExp( ""(?:^|\\s)"" + quick[3] + ""(?:\\s|$)"" ); } return quick; }, quickIs = function( elem, m ) { var attrs = elem.attributes || {}; return ( (!m[1] || elem.nodeName.toLowerCase() === m[1]) && (!m[2] || (attrs.id || {}).value === m[2]) && (!m[3] || m[3].test( (attrs[ ""class"" ] || {}).value )) ); }, hoverHack = function( events ) { return jQuery.event.special.hover ? events : events.replace( rhoverHack, ""mouseenter$1 mouseleave$1"" ); }; /* * Helper functions for managing events -- not part of the public interface. * Props to Dean Edwards' addEvent library for many of the ideas. */ jQuery.event = { add: function( elem, types, handler, data, selector ) { var elemData, eventHandle, events, t, tns, type, namespaces, handleObj, handleObjIn, quick, handlers, special; // Don't attach events to noData or text/comment nodes (allow plain objects tho) if ( elem.nodeType === 3 || elem.nodeType === 8 || !types || !handler || !(elemData = jQuery._data( elem )) ) { return; } // Caller can pass in an object of custom data in lieu of the handler if ( handler.handler ) { handleObjIn = handler; handler = handleObjIn.handler; selector = handleObjIn.selector; } // Make sure that the handler has a unique ID, used to find/remove it later if ( !handler.guid ) { handler.guid = jQuery.guid++; } // Init the element's event structure and main handler, if this is the first events = elemData.events; if ( !events ) { elemData.events = events = {}; } eventHandle = elemData.handle; if ( !eventHandle ) { elemData.handle = eventHandle = function( e ) { // Discard the second event of a jQuery.event.trigger() and // when an event is called after a page has unloaded return typeof jQuery !== ""undefined"" && (!e || jQuery.event.triggered !== e.type) ? jQuery.event.dispatch.apply( eventHandle.elem, arguments ) : undefined; }; // Add elem as a property of the handle fn to prevent a memory leak with IE non-native events eventHandle.elem = elem; } // Handle multiple events separated by a space // jQuery(...).bind(""mouseover mouseout"", fn); types = jQuery.trim( hoverHack(types) ).split( "" "" ); for ( t = 0; t < types.length; t++ ) { tns = rtypenamespace.exec( types[t] ) || []; type = tns[1]; namespaces = ( tns[2] || """" ).split( ""."" ).sort(); // If event changes its type, use the special event handlers for the changed type special = jQuery.event.special[ type ] || {}; // If selector defined, determine special event api type, otherwise given type type = ( selector ? special.delegateType : special.bindType ) || type; // Update special based on newly reset type special = jQuery.event.special[ type ] || {}; // handleObj is passed to all event handlers handleObj = jQuery.extend({ type: type, origType: tns[1], data: data, handler: handler, guid: handler.guid, selector: selector, quick: selector && quickParse( selector ), namespace: namespaces.join(""."") }, handleObjIn ); // Init the event handler queue if we're the first handlers = events[ type ]; if ( !handlers ) { handlers = events[ type ] = []; handlers.delegateCount = 0; // Only use addEventListener/attachEvent if the special events handler returns false if ( !special.setup || special.setup.call( elem, data, namespaces, eventHandle ) === false ) { // Bind the global event handler to the element if ( elem.addEventListener ) { elem.addEventListener( type, eventHandle, false ); } else if ( elem.attachEvent ) { elem.attachEvent( ""on"" + type, eventHandle ); } } } if ( special.add ) { special.add.call( elem, handleObj ); if ( !handleObj.handler.guid ) { handleObj.handler.guid = handler.guid; } } // Add to the element's handler list, delegates in front if ( selector ) { handlers.splice( handlers.delegateCount++, 0, handleObj ); } else { handlers.push( handleObj ); } // Keep track of which events have ever been used, for event optimization jQuery.event.global[ type ] = true; } // Nullify elem to prevent memory leaks in IE elem = null; }, global: {}, // Detach an event or set of events from an element remove: function( elem, types, handler, selector, mappedTypes ) { var elemData = jQuery.hasData( elem ) && jQuery._data( elem ), t, tns, type, origType, namespaces, origCount, j, events, special, handle, eventType, handleObj; if ( !elemData || !(events = elemData.events) ) { return; } // Once for each type.namespace in types; type may be omitted types = jQuery.trim( hoverHack( types || """" ) ).split("" ""); for ( t = 0; t < types.length; t++ ) { tns = rtypenamespace.exec( types[t] ) || []; type = origType = tns[1]; namespaces = tns[2]; // Unbind all events (on this namespace, if provided) for the element if ( !type ) { for ( type in events ) { jQuery.event.remove( elem, type + types[ t ], handler, selector, true ); } continue; } special = jQuery.event.special[ type ] || {}; type = ( selector? special.delegateType : special.bindType ) || type; eventType = events[ type ] || []; origCount = eventType.length; namespaces = namespaces ? new RegExp(""(^|\\.)"" + namespaces.split(""."").sort().join(""\\.(?:.*\\.)?"") + ""(\\.|$)"") : null; // Remove matching events for ( j = 0; j < eventType.length; j++ ) { handleObj = eventType[ j ]; if ( ( mappedTypes || origType === handleObj.origType ) && ( !handler || handler.guid === handleObj.guid ) && ( !namespaces || namespaces.test( handleObj.namespace ) ) && ( !selector || selector === handleObj.selector || selector === ""**"" && handleObj.selector ) ) { eventType.splice( j--, 1 ); if ( handleObj.selector ) { eventType.delegateCount--; } if ( special.remove ) { special.remove.call( elem, handleObj ); } } } // Remove generic event handler if we removed something and no more handlers exist // (avoids potential for endless recursion during removal of special event handlers) if ( eventType.length === 0 && origCount !== eventType.length ) { if ( !special.teardown || special.teardown.call( elem, namespaces ) === false ) { jQuery.removeEvent( elem, type, elemData.handle ); } delete events[ type ]; } } // Remove the expando if it's no longer used if ( jQuery.isEmptyObject( events ) ) { handle = elemData.handle; if ( handle ) { handle.elem = null; } // removeData also checks for emptiness and clears the expando if empty // so use it instead of delete jQuery.removeData( elem, [ ""events"", ""handle"" ], true ); } }, // Events that are safe to short-circuit if no handlers are attached. // Native DOM events should not be added, they may have inline handlers. customEvent: { ""getData"": true, ""setData"": true, ""changeData"": true }, trigger: function( event, data, elem, onlyHandlers ) { // Don't do events on text and comment nodes if ( elem && (elem.nodeType === 3 || elem.nodeType === 8) ) { return; } // Event object or event type var type = event.type || event, namespaces = [], cache, exclusive, i, cur, old, ontype, special, handle, eventPath, bubbleType; // focus/blur morphs to focusin/out; ensure we're not firing them right now if ( rfocusMorph.test( type + jQuery.event.triggered ) ) { return; } if ( type.indexOf( ""!"" ) >= 0 ) { // Exclusive events trigger only for the exact event (no namespaces) type = type.slice(0, -1); exclusive = true; } if ( type.indexOf( ""."" ) >= 0 ) { // Namespaced trigger; create a regexp to match event type in handle() namespaces = type.split("".""); type = namespaces.shift(); namespaces.sort(); } if ( (!elem || jQuery.event.customEvent[ type ]) && !jQuery.event.global[ type ] ) { // No jQuery handlers for this event type, and it can't have inline handlers return; } // Caller can pass in an Event, Object, or just an event type string event = typeof event === ""object"" ? // jQuery.Event object event[ jQuery.expando ] ? event : // Object literal new jQuery.Event( type, event ) : // Just the event type (string) new jQuery.Event( type ); event.type = type; event.isTrigger = true; event.exclusive = exclusive; event.namespace = namespaces.join( ""."" ); event.namespace_re = event.namespace? new RegExp(""(^|\\.)"" + namespaces.join(""\\.(?:.*\\.)?"") + ""(\\.|$)"") : null; ontype = type.indexOf( "":"" ) < 0 ? ""on"" + type : """"; // Handle a global trigger if ( !elem ) { // TODO: Stop taunting the data cache; remove global events and always attach to document cache = jQuery.cache; for ( i in cache ) { if ( cache[ i ].events && cache[ i ].events[ type ] ) { jQuery.event.trigger( event, data, cache[ i ].handle.elem, true ); } } return; } // Clean up the event in case it is being reused event.result = undefined; if ( !event.target ) { event.target = elem; } // Clone any incoming data and prepend the event, creating the handler arg list data = data != null ? jQuery.makeArray( data ) : []; data.unshift( event ); // Allow special events to draw outside the lines special = jQuery.event.special[ type ] || {}; if ( special.trigger && special.trigger.apply( elem, data ) === false ) { return; } // Determine event propagation path in advance, per W3C events spec (#9951) // Bubble up to document, then to window; watch for a global ownerDocument var (#9724) eventPath = [[ elem, special.bindType || type ]]; if ( !onlyHandlers && !special.noBubble && !jQuery.isWindow( elem ) ) { bubbleType = special.delegateType || type; cur = rfocusMorph.test( bubbleType + type ) ? elem : elem.parentNode; old = null; for ( ; cur; cur = cur.parentNode ) { eventPath.push([ cur, bubbleType ]); old = cur; } // Only add window if we got to document (e.g., not plain obj or detached DOM) if ( old && old === elem.ownerDocument ) { eventPath.push([ old.defaultView || old.parentWindow || window, bubbleType ]); } } // Fire handlers on the event path for ( i = 0; i < eventPath.length && !event.isPropagationStopped(); i++ ) { cur = eventPath[i][0]; event.type = eventPath[i][1]; handle = ( jQuery._data( cur, ""events"" ) || {} )[ event.type ] && jQuery._data( cur, ""handle"" ); if ( handle ) { handle.apply( cur, data ); } // Note that this is a bare JS function and not a jQuery handler handle = ontype && cur[ ontype ]; if ( handle && jQuery.acceptData( cur ) && handle.apply( cur, data ) === false ) { event.preventDefault(); } } event.type = type; // If nobody prevented the default action, do it now if ( !onlyHandlers && !event.isDefaultPrevented() ) { if ( (!special._default || special._default.apply( elem.ownerDocument, data ) === false) && !(type === ""click"" && jQuery.nodeName( elem, ""a"" )) && jQuery.acceptData( elem ) ) { // Call a native DOM method on the target with the same name name as the event. // Can't use an .isFunction() check here because IE6/7 fails that test. // Don't do default actions on window, that's where global variables be (#6170) // IE<9 dies on focus/blur to hidden element (#1486) if ( ontype && elem[ type ] && ((type !== ""focus"" && type !== ""blur"") || event.target.offsetWidth !== 0) && !jQuery.isWindow( elem ) ) { // Don't re-trigger an onFOO event when we call its FOO() method old = elem[ ontype ]; if ( old ) { elem[ ontype ] = null; } // Prevent re-triggering of the same event, since we already bubbled it above jQuery.event.triggered = type; elem[ type ](); jQuery.event.triggered = undefined; if ( old ) { elem[ ontype ] = old; } } } } return event.result; }, dispatch: function( event ) { // Make a writable jQuery.Event from the native event object event = jQuery.event.fix( event || window.event ); var handlers = ( (jQuery._data( this, ""events"" ) || {} )[ event.type ] || []), delegateCount = handlers.delegateCount, args = [].slice.call( arguments, 0 ), run_all = !event.exclusive && !event.namespace, special = jQuery.event.special[ event.type ] || {}, handlerQueue = [], i, j, cur, jqcur, ret, selMatch, matched, matches, handleObj, sel, related; // Use the fix-ed jQuery.Event rather than the (read-only) native event args[0] = event; event.delegateTarget = this; // Call the preDispatch hook for the mapped type, and let it bail if desired if ( special.preDispatch && special.preDispatch.call( this, event ) === false ) { return; } // Determine handlers that should run if there are delegated events // Avoid non-left-click bubbling in Firefox (#3861) if ( delegateCount && !(event.button && event.type === ""click"") ) { // Pregenerate a single jQuery object for reuse with .is() jqcur = jQuery(this); jqcur.context = this.ownerDocument || this; for ( cur = event.target; cur != this; cur = cur.parentNode || this ) { // Don't process events on disabled elements (#6911, #8165) if ( cur.disabled !== true ) { selMatch = {}; matches = []; jqcur[0] = cur; for ( i = 0; i < delegateCount; i++ ) { handleObj = handlers[ i ]; sel = handleObj.selector; if ( selMatch[ sel ] === undefined ) { selMatch[ sel ] = ( handleObj.quick ? quickIs( cur, handleObj.quick ) : jqcur.is( sel ) ); } if ( selMatch[ sel ] ) { matches.push( handleObj ); } } if ( matches.length ) { handlerQueue.push({ elem: cur, matches: matches }); } } } } // Add the remaining (directly-bound) handlers if ( handlers.length > delegateCount ) { handlerQueue.push({ elem: this, matches: handlers.slice( delegateCount ) }); } // Run delegates first; they may want to stop propagation beneath us for ( i = 0; i < handlerQueue.length && !event.isPropagationStopped(); i++ ) { matched = handlerQueue[ i ]; event.currentTarget = matched.elem; for ( j = 0; j < matched.matches.length && !event.isImmediatePropagationStopped(); j++ ) { handleObj = matched.matches[ j ]; // Triggered event must either 1) be non-exclusive and have no namespace, or // 2) have namespace(s) a subset or equal to those in the bound event (both can have no namespace). if ( run_all || (!event.namespace && !handleObj.namespace) || event.namespace_re && event.namespace_re.test( handleObj.namespace ) ) { event.data = handleObj.data; event.handleObj = handleObj; ret = ( (jQuery.event.special[ handleObj.origType ] || {}).handle || handleObj.handler ) .apply( matched.elem, args ); if ( ret !== undefined ) { event.result = ret; if ( ret === false ) { event.preventDefault(); event.stopPropagation(); } } } } } // Call the postDispatch hook for the mapped type if ( special.postDispatch ) { special.postDispatch.call( this, event ); } return event.result; }, // Includes some event props shared by KeyEvent and MouseEvent // *** attrChange attrName relatedNode srcElement are not normalized, non-W3C, deprecated, will be removed in 1.8 *** props: ""attrChange attrName relatedNode srcElement altKey bubbles cancelable ctrlKey currentTarget eventPhase metaKey relatedTarget shiftKey target timeStamp view which"".split("" ""), fixHooks: {}, keyHooks: { props: ""char charCode key keyCode"".split("" ""), filter: function( event, original ) { // Add which for key events if ( event.which == null ) { event.which = original.charCode != null ? original.charCode : original.keyCode; } return event; } }, mouseHooks: { props: ""button buttons clientX clientY fromElement offsetX offsetY pageX pageY screenX screenY toElement"".split("" ""), filter: function( event, original ) { var eventDoc, doc, body, button = original.button, fromElement = original.fromElement; // Calculate pageX/Y if missing and clientX/Y available if ( event.pageX == null && original.clientX != null ) { eventDoc = event.target.ownerDocument || document; doc = eventDoc.documentElement; body = eventDoc.body; event.pageX = original.clientX + ( doc && doc.scrollLeft || body && body.scrollLeft || 0 ) - ( doc && doc.clientLeft || body && body.clientLeft || 0 ); event.pageY = original.clientY + ( doc && doc.scrollTop || body && body.scrollTop || 0 ) - ( doc && doc.clientTop || body && body.clientTop || 0 ); } // Add relatedTarget, if necessary if ( !event.relatedTarget && fromElement ) { event.relatedTarget = fromElement === event.target ? original.toElement : fromElement; } // Add which for click: 1 === left; 2 === middle; 3 === right // Note: button is not normalized, so don't use it if ( !event.which && button !== undefined ) { event.which = ( button & 1 ? 1 : ( button & 2 ? 3 : ( button & 4 ? 2 : 0 ) ) ); } return event; } }, fix: function( event ) { if ( event[ jQuery.expando ] ) { return event; } // Create a writable copy of the event object and normalize some properties var i, prop, originalEvent = event, fixHook = jQuery.event.fixHooks[ event.type ] || {}, copy = fixHook.props ? this.props.concat( fixHook.props ) : this.props; event = jQuery.Event( originalEvent ); for ( i = copy.length; i; ) { prop = copy[ --i ]; event[ prop ] = originalEvent[ prop ]; } // Fix target property, if necessary (#1925, IE 6/7/8 & Safari2) if ( !event.target ) { event.target = originalEvent.srcElement || document; } // Target should not be a text node (#504, Safari) if ( event.target.nodeType === 3 ) { event.target = event.target.parentNode; } // For mouse/key events; add metaKey if it's not there (#3368, IE6/7/8) if ( event.metaKey === undefined ) { event.metaKey = event.ctrlKey; } return fixHook.filter? fixHook.filter( event, originalEvent ) : event; }, special: { ready: { // Make sure the ready event is setup setup: jQuery.bindReady }, load: { // Prevent triggered image.load events from bubbling to window.load noBubble: true }, focus: { delegateType: ""focusin"" }, blur: { delegateType: ""focusout"" }, beforeunload: { setup: function( data, namespaces, eventHandle ) { // We only want to do this special case on windows if ( jQuery.isWindow( this ) ) { this.onbeforeunload = eventHandle; } }, teardown: function( namespaces, eventHandle ) { if ( this.onbeforeunload === eventHandle ) { this.onbeforeunload = null; } } } }, simulate: function( type, elem, event, bubble ) { // Piggyback on a donor event to simulate a different one. // Fake originalEvent to avoid donor's stopPropagation, but if the // simulated event prevents default then we do the same on the donor. var e = jQuery.extend( new jQuery.Event(), event, { type: type, isSimulated: true, originalEvent: {} } ); if ( bubble ) { jQuery.event.trigger( e, null, elem ); } else { jQuery.event.dispatch.call( elem, e ); } if ( e.isDefaultPrevented() ) { event.preventDefault(); } } }; // Some plugins are using, but it's undocumented/deprecated and will be removed. // The 1.7 special event interface should provide all the hooks needed now. jQuery.event.handle = jQuery.event.dispatch; jQuery.removeEvent = document.removeEventListener ? function( elem, type, handle ) { if ( elem.removeEventListener ) { elem.removeEventListener( type, handle, false ); } } : function( elem, type, handle ) { if ( elem.detachEvent ) { elem.detachEvent( ""on"" + type, handle ); } }; jQuery.Event = function( src, props ) { // Allow instantiation without the 'new' keyword if ( !(this instanceof jQuery.Event) ) { return new jQuery.Event( src, props ); } // Event object if ( src && src.type ) { this.originalEvent = src; this.type = src.type; // Events bubbling up the document may have been marked as prevented // by a handler lower down the tree; reflect the correct value. this.isDefaultPrevented = ( src.defaultPrevented || src.returnValue === false || src.getPreventDefault && src.getPreventDefault() ) ? returnTrue : returnFalse; // Event type } else { this.type = src; } // Put explicitly provided properties onto the event object if ( props ) { jQuery.extend( this, props ); } // Create a timestamp if incoming event doesn't have one this.timeStamp = src && src.timeStamp || jQuery.now(); // Mark it as fixed this[ jQuery.expando ] = true; }; function returnFalse() { return false; } function returnTrue() { return true; } // jQuery.Event is based on DOM3 Events as specified by the ECMAScript Language Binding // http://www.w3.org/TR/2003/WD-DOM-Level-3-Events-20030331/ecma-script-binding.html jQuery.Event.prototype = { preventDefault: function() { this.isDefaultPrevented = returnTrue; var e = this.originalEvent; if ( !e ) { return; } // if preventDefault exists run it on the original event if ( e.preventDefault ) { e.preventDefault(); // otherwise set the returnValue property of the original event to false (IE) } else { e.returnValue = false; } }, stopPropagation: function() { this.isPropagationStopped = returnTrue; var e = this.originalEvent; if ( !e ) { return; } // if stopPropagation exists run it on the original event if ( e.stopPropagation ) { e.stopPropagation(); } // otherwise set the cancelBubble property of the original event to true (IE) e.cancelBubble = true; }, stopImmediatePropagation: function() { this.isImmediatePropagationStopped = returnTrue; this.stopPropagation(); }, isDefaultPrevented: returnFalse, isPropagationStopped: returnFalse, isImmediatePropagationStopped: returnFalse }; // Create mouseenter/leave events using mouseover/out and event-time checks jQuery.each({ mouseenter: ""mouseover"", mouseleave: ""mouseout"" }, function( orig, fix ) { jQuery.event.special[ orig ] = { delegateType: fix, bindType: fix, handle: function( event ) { var target = this, related = event.relatedTarget, handleObj = event.handleObj, selector = handleObj.selector, ret; // For mousenter/leave call the handler if related is outside the target. // NB: No relatedTarget if the mouse left/entered the browser window if ( !related || (related !== target && !jQuery.contains( target, related )) ) { event.type = handleObj.origType; ret = handleObj.handler.apply( this, arguments ); event.type = fix; } return ret; } }; }); // IE submit delegation if ( !jQuery.support.submitBubbles ) { jQuery.event.special.submit = { setup: function() { // Only need this for delegated form submit events if ( jQuery.nodeName( this, ""form"" ) ) { return false; } // Lazy-add a submit handler when a descendant form may potentially be submitted jQuery.event.add( this, ""click._submit keypress._submit"", function( e ) { // Node name check avoids a VML-related crash in IE (#9807) var elem = e.target, form = jQuery.nodeName( elem, ""input"" ) || jQuery.nodeName( elem, ""button"" ) ? elem.form : undefined; if ( form && !form._submit_attached ) { jQuery.event.add( form, ""submit._submit"", function( event ) { event._submit_bubble = true; }); form._submit_attached = true; } }); // return undefined since we don't need an event listener }, postDispatch: function( event ) { // If form was submitted by the user, bubble the event up the tree if ( event._submit_bubble ) { delete event._submit_bubble; if ( this.parentNode && !event.isTrigger ) { jQuery.event.simulate( ""submit"", this.parentNode, event, true ); } } }, teardown: function() { // Only need this for delegated form submit events if ( jQuery.nodeName( this, ""form"" ) ) { return false; } // Remove delegated handlers; cleanData eventually reaps submit handlers attached above jQuery.event.remove( this, ""._submit"" ); } }; } // IE change delegation and checkbox/radio fix if ( !jQuery.support.changeBubbles ) { jQuery.event.special.change = { setup: function() { if ( rformElems.test( this.nodeName ) ) { // IE doesn't fire change on a check/radio until blur; trigger it on click // after a propertychange. Eat the blur-change in special.change.handle. // This still fires onchange a second time for check/radio after blur. if ( this.type === ""checkbox"" || this.type === ""radio"" ) { jQuery.event.add( this, ""propertychange._change"", function( event ) { if ( event.originalEvent.propertyName === ""checked"" ) { this._just_changed = true; } }); jQuery.event.add( this, ""click._change"", function( event ) { if ( this._just_changed && !event.isTrigger ) { this._just_changed = false; jQuery.event.simulate( ""change"", this, event, true ); } }); } return false; } // Delegated event; lazy-add a change handler on descendant inputs jQuery.event.add( this, ""beforeactivate._change"", function( e ) { var elem = e.target; if ( rformElems.test( elem.nodeName ) && !elem._change_attached ) { jQuery.event.add( elem, ""change._change"", function( event ) { if ( this.parentNode && !event.isSimulated && !event.isTrigger ) { jQuery.event.simulate( ""change"", this.parentNode, event, true ); } }); elem._change_attached = true; } }); }, handle: function( event ) { var elem = event.target; // Swallow native change events from checkbox/radio, we already triggered them above if ( this !== elem || event.isSimulated || event.isTrigger || (elem.type !== ""radio"" && elem.type !== ""checkbox"") ) { return event.handleObj.handler.apply( this, arguments ); } }, teardown: function() { jQuery.event.remove( this, ""._change"" ); return rformElems.test( this.nodeName ); } }; } // Create ""bubbling"" focus and blur events if ( !jQuery.support.focusinBubbles ) { jQuery.each({ focus: ""focusin"", blur: ""focusout"" }, function( orig, fix ) { // Attach a single capturing handler while someone wants focusin/focusout var attaches = 0, handler = function( event ) { jQuery.event.simulate( fix, event.target, jQuery.event.fix( event ), true ); }; jQuery.event.special[ fix ] = { setup: function() { if ( attaches++ === 0 ) { document.addEventListener( orig, handler, true ); } }, teardown: function() { if ( --attaches === 0 ) { document.removeEventListener( orig, handler, true ); } } }; }); } jQuery.fn.extend({ on: function( types, selector, data, fn, /*INTERNAL*/ one ) { var origFn, type; // Types can be a map of types/handlers if ( typeof types === ""object"" ) { // ( types-Object, selector, data ) if ( typeof selector !== ""string"" ) { // && selector != null // ( types-Object, data ) data = data || selector; selector = undefined; } for ( type in types ) { this.on( type, selector, data, types[ type ], one ); } return this; } if ( data == null && fn == null ) { // ( types, fn ) fn = selector; data = selector = undefined; } else if ( fn == null ) { if ( typeof selector === ""string"" ) { // ( types, selector, fn ) fn = data; data = undefined; } else { // ( types, data, fn ) fn = data; data = selector; selector = undefined; } } if ( fn === false ) { fn = returnFalse; } else if ( !fn ) { return this; } if ( one === 1 ) { origFn = fn; fn = function( event ) { // Can use an empty set, since event contains the info jQuery().off( event ); return origFn.apply( this, arguments ); }; // Use same guid so caller can remove using origFn fn.guid = origFn.guid || ( origFn.guid = jQuery.guid++ ); } return this.each( function() { jQuery.event.add( this, types, fn, data, selector ); }); }, one: function( types, selector, data, fn ) { return this.on( types, selector, data, fn, 1 ); }, off: function( types, selector, fn ) { if ( types && types.preventDefault && types.handleObj ) { // ( event ) dispatched jQuery.Event var handleObj = types.handleObj; jQuery( types.delegateTarget ).off( handleObj.namespace ? handleObj.origType + ""."" + handleObj.namespace : handleObj.origType, handleObj.selector, handleObj.handler ); return this; } if ( typeof types === ""object"" ) { // ( types-object [, selector] ) for ( var type in types ) { this.off( type, selector, types[ type ] ); } return this; } if ( selector === false || typeof selector === ""function"" ) { // ( types [, fn] ) fn = selector; selector = undefined; } if ( fn === false ) { fn = returnFalse; } return this.each(function() { jQuery.event.remove( this, types, fn, selector ); }); }, bind: function( types, data, fn ) { return this.on( types, null, data, fn ); }, unbind: function( types, fn ) { return this.off( types, null, fn ); }, live: function( types, data, fn ) { jQuery( this.context ).on( types, this.selector, data, fn ); return this; }, die: function( types, fn ) { jQuery( this.context ).off( types, this.selector || ""**"", fn ); return this; }, delegate: function( selector, types, data, fn ) { return this.on( types, selector, data, fn ); }, undelegate: function( selector, types, fn ) { // ( namespace ) or ( selector, types [, fn] ) return arguments.length == 1? this.off( selector, ""**"" ) : this.off( types, selector, fn ); }, trigger: function( type, data ) { return this.each(function() { jQuery.event.trigger( type, data, this ); }); }, triggerHandler: function( type, data ) { if ( this[0] ) { return jQuery.event.trigger( type, data, this[0], true ); } }, toggle: function( fn ) { // Save reference to arguments for access in closure var args = arguments, guid = fn.guid || jQuery.guid++, i = 0, toggler = function( event ) { // Figure out which function to execute var lastToggle = ( jQuery._data( this, ""lastToggle"" + fn.guid ) || 0 ) % i; jQuery._data( this, ""lastToggle"" + fn.guid, lastToggle + 1 ); // Make sure that clicks stop event.preventDefault(); // and execute the function return args[ lastToggle ].apply( this, arguments ) || false; }; // link all the functions, so any of them can unbind this click handler toggler.guid = guid; while ( i < args.length ) { args[ i++ ].guid = guid; } return this.click( toggler ); }, hover: function( fnOver, fnOut ) { return this.mouseenter( fnOver ).mouseleave( fnOut || fnOver ); } }); jQuery.each( (""blur focus focusin focusout load resize scroll unload click dblclick "" + ""mousedown mouseup mousemove mouseover mouseout mouseenter mouseleave "" + ""change select submit keydown keypress keyup error contextmenu"").split("" ""), function( i, name ) { // Handle event binding jQuery.fn[ name ] = function( data, fn ) { if ( fn == null ) { fn = data; data = null; } return arguments.length > 0 ? this.on( name, null, data, fn ) : this.trigger( name ); }; if ( jQuery.attrFn ) { jQuery.attrFn[ name ] = true; } if ( rkeyEvent.test( name ) ) { jQuery.event.fixHooks[ name ] = jQuery.event.keyHooks; } if ( rmouseEvent.test( name ) ) { jQuery.event.fixHooks[ name ] = jQuery.event.mouseHooks; } }); /*! * Sizzle CSS Selector Engine * Copyright 2011, The Dojo Foundation * Released under the MIT, BSD, and GPL Licenses. * More information: http://sizzlejs.com/ */ (function(){ var chunker = /((?:\((?:\([^()]+\)|[^()]+)+\)|\[(?:\[[^\[\]]*\]|['""][^'""]*['""]|[^\[\]'""]+)+\]|\\.|[^ >+~,(\[\\]+)+|[>+~])(\s*,\s*)?((?:.|\r|\n)*)/g, expando = ""sizcache"" + (Math.random() + '').replace('.', ''), done = 0, toString = Object.prototype.toString, hasDuplicate = false, baseHasDuplicate = true, rBackslash = /\\/g, rReturn = /\r\n/g, rNonWord = /\W/; // Here we check if the JavaScript engine is using some sort of // optimization where it does not always call our comparision // function. If that is the case, discard the hasDuplicate value. // Thus far that includes Google Chrome. [0, 0].sort(function() { baseHasDuplicate = false; return 0; }); var Sizzle = function( selector, context, results, seed ) { results = results || []; context = context || document; var origContext = context; if ( context.nodeType !== 1 && context.nodeType !== 9 ) { return []; } if ( !selector || typeof selector !== ""string"" ) { return results; } var m, set, checkSet, extra, ret, cur, pop, i, prune = true, contextXML = Sizzle.isXML( context ), parts = [], soFar = selector; // Reset the position of the chunker regexp (start from head) do { chunker.exec( """" ); m = chunker.exec( soFar ); if ( m ) { soFar = m[3]; parts.push( m[1] ); if ( m[2] ) { extra = m[3]; break; } } } while ( m ); if ( parts.length > 1 && origPOS.exec( selector ) ) { if ( parts.length === 2 && Expr.relative[ parts[0] ] ) { set = posProcess( parts[0] + parts[1], context, seed ); } else { set = Expr.relative[ parts[0] ] ? [ context ] : Sizzle( parts.shift(), context ); while ( parts.length ) { selector = parts.shift(); if ( Expr.relative[ selector ] ) { selector += parts.shift(); } set = posProcess( selector, set, seed ); } } } else { // Take a shortcut and set the context if the root selector is an ID // (but not if it'll be faster if the inner selector is an ID) if ( !seed && parts.length > 1 && context.nodeType === 9 && !contextXML && Expr.match.ID.test(parts[0]) && !Expr.match.ID.test(parts[parts.length - 1]) ) { ret = Sizzle.find( parts.shift(), context, contextXML ); context = ret.expr ? Sizzle.filter( ret.expr, ret.set )[0] : ret.set[0]; } if ( context ) { ret = seed ? { expr: parts.pop(), set: makeArray(seed) } : Sizzle.find( parts.pop(), parts.length === 1 && (parts[0] === ""~"" || parts[0] === ""+"") && context.parentNode ? context.parentNode : context, contextXML ); set = ret.expr ? Sizzle.filter( ret.expr, ret.set ) : ret.set; if ( parts.length > 0 ) { checkSet = makeArray( set ); } else { prune = false; } while ( parts.length ) { cur = parts.pop(); pop = cur; if ( !Expr.relative[ cur ] ) { cur = """"; } else { pop = parts.pop(); } if ( pop == null ) { pop = context; } Expr.relative[ cur ]( checkSet, pop, contextXML ); } } else { checkSet = parts = []; } } if ( !checkSet ) { checkSet = set; } if ( !checkSet ) { Sizzle.error( cur || selector ); } if ( toString.call(checkSet) === ""[object Array]"" ) { if ( !prune ) { results.push.apply( results, checkSet ); } else if ( context && context.nodeType === 1 ) { for ( i = 0; checkSet[i] != null; i++ ) { if ( checkSet[i] && (checkSet[i] === true || checkSet[i].nodeType === 1 && Sizzle.contains(context, checkSet[i])) ) { results.push( set[i] ); } } } else { for ( i = 0; checkSet[i] != null; i++ ) { if ( checkSet[i] && checkSet[i].nodeType === 1 ) { results.push( set[i] ); } } } } else { makeArray( checkSet, results ); } if ( extra ) { Sizzle( extra, origContext, results, seed ); Sizzle.uniqueSort( results ); } return results; }; Sizzle.uniqueSort = function( results ) { if ( sortOrder ) { hasDuplicate = baseHasDuplicate; results.sort( sortOrder ); if ( hasDuplicate ) { for ( var i = 1; i < results.length; i++ ) { if ( results[i] === results[ i - 1 ] ) { results.splice( i--, 1 ); } } } } return results; }; Sizzle.matches = function( expr, set ) { return Sizzle( expr, null, null, set ); }; Sizzle.matchesSelector = function( node, expr ) { return Sizzle( expr, null, null, [node] ).length > 0; }; Sizzle.find = function( expr, context, isXML ) { var set, i, len, match, type, left; if ( !expr ) { return []; } for ( i = 0, len = Expr.order.length; i < len; i++ ) { type = Expr.order[i]; if ( (match = Expr.leftMatch[ type ].exec( expr )) ) { left = match[1]; match.splice( 1, 1 ); if ( left.substr( left.length - 1 ) !== ""\\"" ) { match[1] = (match[1] || """").replace( rBackslash, """" ); set = Expr.find[ type ]( match, context, isXML ); if ( set != null ) { expr = expr.replace( Expr.match[ type ], """" ); break; } } } } if ( !set ) { set = typeof context.getElementsByTagName !== ""undefined"" ? context.getElementsByTagName( ""*"" ) : []; } return { set: set, expr: expr }; }; Sizzle.filter = function( expr, set, inplace, not ) { var match, anyFound, type, found, item, filter, left, i, pass, old = expr, result = [], curLoop = set, isXMLFilter = set && set[0] && Sizzle.isXML( set[0] ); while ( expr && set.length ) { for ( type in Expr.filter ) { if ( (match = Expr.leftMatch[ type ].exec( expr )) != null && match[2] ) { filter = Expr.filter[ type ]; left = match[1]; anyFound = false; match.splice(1,1); if ( left.substr( left.length - 1 ) === ""\\"" ) { continue; } if ( curLoop === result ) { result = []; } if ( Expr.preFilter[ type ] ) { match = Expr.preFilter[ type ]( match, curLoop, inplace, result, not, isXMLFilter ); if ( !match ) { anyFound = found = true; } else if ( match === true ) { continue; } } if ( match ) { for ( i = 0; (item = curLoop[i]) != null; i++ ) { if ( item ) { found = filter( item, match, i, curLoop ); pass = not ^ found; if ( inplace && found != null ) { if ( pass ) { anyFound = true; } else { curLoop[i] = false; } } else if ( pass ) { result.push( item ); anyFound = true; } } } } if ( found !== undefined ) { if ( !inplace ) { curLoop = result; } expr = expr.replace( Expr.match[ type ], """" ); if ( !anyFound ) { return []; } break; } } } // Improper expression if ( expr === old ) { if ( anyFound == null ) { Sizzle.error( expr ); } else { break; } } old = expr; } return curLoop; }; Sizzle.error = function( msg ) { throw new Error( ""Syntax error, unrecognized expression: "" + msg ); }; /** * Utility function for retreiving the text value of an array of DOM nodes * @param {Array|Element} elem */ var getText = Sizzle.getText = function( elem ) { var i, node, nodeType = elem.nodeType, ret = """"; if ( nodeType ) { if ( nodeType === 1 || nodeType === 9 || nodeType === 11 ) { // Use textContent || innerText for elements if ( typeof elem.textContent === 'string' ) { return elem.textContent; } else if ( typeof elem.innerText === 'string' ) { // Replace IE's carriage returns return elem.innerText.replace( rReturn, '' ); } else { // Traverse it's children for ( elem = elem.firstChild; elem; elem = elem.nextSibling) { ret += getText( elem ); } } } else if ( nodeType === 3 || nodeType === 4 ) { return elem.nodeValue; } } else { // If no nodeType, this is expected to be an array for ( i = 0; (node = elem[i]); i++ ) { // Do not traverse comment nodes if ( node.nodeType !== 8 ) { ret += getText( node ); } } } return ret; }; var Expr = Sizzle.selectors = { order: [ ""ID"", ""NAME"", ""TAG"" ], match: { ID: /#((?:[\w\u00c0-\uFFFF\-]|\\.)+)/, CLASS: /\.((?:[\w\u00c0-\uFFFF\-]|\\.)+)/, NAME: /\[name=['""]*((?:[\w\u00c0-\uFFFF\-]|\\.)+)['""]*\]/, ATTR: /\[\s*((?:[\w\u00c0-\uFFFF\-]|\\.)+)\s*(?:(\S?=)\s*(?:(['""])(.*?)\3|(#?(?:[\w\u00c0-\uFFFF\-]|\\.)*)|)|)\s*\]/, TAG: /^((?:[\w\u00c0-\uFFFF\*\-]|\\.)+)/, CHILD: /:(only|nth|last|first)-child(?:\(\s*(even|odd|(?:[+\-]?\d+|(?:[+\-]?\d*)?n\s*(?:[+\-]\s*\d+)?))\s*\))?/, POS: /:(nth|eq|gt|lt|first|last|even|odd)(?:\((\d*)\))?(?=[^\-]|$)/, PSEUDO: /:((?:[\w\u00c0-\uFFFF\-]|\\.)+)(?:\((['""]?)((?:\([^\)]+\)|[^\(\)]*)+)\2\))?/ }, leftMatch: {}, attrMap: { ""class"": ""className"", ""for"": ""htmlFor"" }, attrHandle: { href: function( elem ) { return elem.getAttribute( ""href"" ); }, type: function( elem ) { return elem.getAttribute( ""type"" ); } }, relative: { ""+"": function(checkSet, part){ var isPartStr = typeof part === ""string"", isTag = isPartStr && !rNonWord.test( part ), isPartStrNotTag = isPartStr && !isTag; if ( isTag ) { part = part.toLowerCase(); } for ( var i = 0, l = checkSet.length, elem; i < l; i++ ) { if ( (elem = checkSet[i]) ) { while ( (elem = elem.previousSibling) && elem.nodeType !== 1 ) {} checkSet[i] = isPartStrNotTag || elem && elem.nodeName.toLowerCase() === part ? elem || false : elem === part; } } if ( isPartStrNotTag ) { Sizzle.filter( part, checkSet, true ); } }, "">"": function( checkSet, part ) { var elem, isPartStr = typeof part === ""string"", i = 0, l = checkSet.length; if ( isPartStr && !rNonWord.test( part ) ) { part = part.toLowerCase(); for ( ; i < l; i++ ) { elem = checkSet[i]; if ( elem ) { var parent = elem.parentNode; checkSet[i] = parent.nodeName.toLowerCase() === part ? parent : false; } } } else { for ( ; i < l; i++ ) { elem = checkSet[i]; if ( elem ) { checkSet[i] = isPartStr ? elem.parentNode : elem.parentNode === part; } } if ( isPartStr ) { Sizzle.filter( part, checkSet, true ); } } }, """": function(checkSet, part, isXML){ var nodeCheck, doneName = done++, checkFn = dirCheck; if ( typeof part === ""string"" && !rNonWord.test( part ) ) { part = part.toLowerCase(); nodeCheck = part; checkFn = dirNodeCheck; } checkFn( ""parentNode"", part, doneName, checkSet, nodeCheck, isXML ); }, ""~"": function( checkSet, part, isXML ) { var nodeCheck, doneName = done++, checkFn = dirCheck; if ( typeof part === ""string"" && !rNonWord.test( part ) ) { part = part.toLowerCase(); nodeCheck = part; checkFn = dirNodeCheck; } checkFn( ""previousSibling"", part, doneName, checkSet, nodeCheck, isXML ); } }, find: { ID: function( match, context, isXML ) { if ( typeof context.getElementById !== ""undefined"" && !isXML ) { var m = context.getElementById(match[1]); // Check parentNode to catch when Blackberry 4.6 returns // nodes that are no longer in the document #6963 return m && m.parentNode ? [m] : []; } }, NAME: function( match, context ) { if ( typeof context.getElementsByName !== ""undefined"" ) { var ret = [], results = context.getElementsByName( match[1] ); for ( var i = 0, l = results.length; i < l; i++ ) { if ( results[i].getAttribute(""name"") === match[1] ) { ret.push( results[i] ); } } return ret.length === 0 ? null : ret; } }, TAG: function( match, context ) { if ( typeof context.getElementsByTagName !== ""undefined"" ) { return context.getElementsByTagName( match[1] ); } } }, preFilter: { CLASS: function( match, curLoop, inplace, result, not, isXML ) { match = "" "" + match[1].replace( rBackslash, """" ) + "" ""; if ( isXML ) { return match; } for ( var i = 0, elem; (elem = curLoop[i]) != null; i++ ) { if ( elem ) { if ( not ^ (elem.className && ("" "" + elem.className + "" "").replace(/[\t\n\r]/g, "" "").indexOf(match) >= 0) ) { if ( !inplace ) { result.push( elem ); } } else if ( inplace ) { curLoop[i] = false; } } } return false; }, ID: function( match ) { return match[1].replace( rBackslash, """" ); }, TAG: function( match, curLoop ) { return match[1].replace( rBackslash, """" ).toLowerCase(); }, CHILD: function( match ) { if ( match[1] === ""nth"" ) { if ( !match[2] ) { Sizzle.error( match[0] ); } match[2] = match[2].replace(/^\+|\s*/g, ''); // parse equations like 'even', 'odd', '5', '2n', '3n+2', '4n-1', '-n+6' var test = /(-?)(\d*)(?:n([+\-]?\d*))?/.exec( match[2] === ""even"" && ""2n"" || match[2] === ""odd"" && ""2n+1"" || !/\D/.test( match[2] ) && ""0n+"" + match[2] || match[2]); // calculate the numbers (first)n+(last) including if they are negative match[2] = (test[1] + (test[2] || 1)) - 0; match[3] = test[3] - 0; } else if ( match[2] ) { Sizzle.error( match[0] ); } // TODO: Move to normal caching system match[0] = done++; return match; }, ATTR: function( match, curLoop, inplace, result, not, isXML ) { var name = match[1] = match[1].replace( rBackslash, """" ); if ( !isXML && Expr.attrMap[name] ) { match[1] = Expr.attrMap[name]; } // Handle if an un-quoted value was used match[4] = ( match[4] || match[5] || """" ).replace( rBackslash, """" ); if ( match[2] === ""~="" ) { match[4] = "" "" + match[4] + "" ""; } return match; }, PSEUDO: function( match, curLoop, inplace, result, not ) { if ( match[1] === ""not"" ) { // If we're dealing with a complex expression, or a simple one if ( ( chunker.exec(match[3]) || """" ).length > 1 || /^\w/.test(match[3]) ) { match[3] = Sizzle(match[3], null, null, curLoop); } else { var ret = Sizzle.filter(match[3], curLoop, inplace, true ^ not); if ( !inplace ) { result.push.apply( result, ret ); } return false; } } else if ( Expr.match.POS.test( match[0] ) || Expr.match.CHILD.test( match[0] ) ) { return true; } return match; }, POS: function( match ) { match.unshift( true ); return match; } }, filters: { enabled: function( elem ) { return elem.disabled === false && elem.type !== ""hidden""; }, disabled: function( elem ) { return elem.disabled === true; }, checked: function( elem ) { return elem.checked === true; }, selected: function( elem ) { // Accessing this property makes selected-by-default // options in Safari work properly if ( elem.parentNode ) { elem.parentNode.selectedIndex; } return elem.selected === true; }, parent: function( elem ) { return !!elem.firstChild; }, empty: function( elem ) { return !elem.firstChild; }, has: function( elem, i, match ) { return !!Sizzle( match[3], elem ).length; }, header: function( elem ) { return (/h\d/i).test( elem.nodeName ); }, text: function( elem ) { var attr = elem.getAttribute( ""type"" ), type = elem.type; // IE6 and 7 will map elem.type to 'text' for new HTML5 types (search, etc) // use getAttribute instead to test this case return elem.nodeName.toLowerCase() === ""input"" && ""text"" === type && ( attr === type || attr === null ); }, radio: function( elem ) { return elem.nodeName.toLowerCase() === ""input"" && ""radio"" === elem.type; }, checkbox: function( elem ) { return elem.nodeName.toLowerCase() === ""input"" && ""checkbox"" === elem.type; }, file: function( elem ) { return elem.nodeName.toLowerCase() === ""input"" && ""file"" === elem.type; }, password: function( elem ) { return elem.nodeName.toLowerCase() === ""input"" && ""password"" === elem.type; }, submit: function( elem ) { var name = elem.nodeName.toLowerCase(); return (name === ""input"" || name === ""button"") && ""submit"" === elem.type; }, image: function( elem ) { return elem.nodeName.toLowerCase() === ""input"" && ""image"" === elem.type; }, reset: function( elem ) { var name = elem.nodeName.toLowerCase(); return (name === ""input"" || name === ""button"") && ""reset"" === elem.type; }, button: function( elem ) { var name = elem.nodeName.toLowerCase(); return name === ""input"" && ""button"" === elem.type || name === ""button""; }, input: function( elem ) { return (/input|select|textarea|button/i).test( elem.nodeName ); }, focus: function( elem ) { return elem === elem.ownerDocument.activeElement; } }, setFilters: { first: function( elem, i ) { return i === 0; }, last: function( elem, i, match, array ) { return i === array.length - 1; }, even: function( elem, i ) { return i % 2 === 0; }, odd: function( elem, i ) { return i % 2 === 1; }, lt: function( elem, i, match ) { return i < match[3] - 0; }, gt: function( elem, i, match ) { return i > match[3] - 0; }, nth: function( elem, i, match ) { return match[3] - 0 === i; }, eq: function( elem, i, match ) { return match[3] - 0 === i; } }, filter: { PSEUDO: function( elem, match, i, array ) { var name = match[1], filter = Expr.filters[ name ]; if ( filter ) { return filter( elem, i, match, array ); } else if ( name === ""contains"" ) { return (elem.textContent || elem.innerText || getText([ elem ]) || """").indexOf(match[3]) >= 0; } else if ( name === ""not"" ) { var not = match[3]; for ( var j = 0, l = not.length; j < l; j++ ) { if ( not[j] === elem ) { return false; } } return true; } else { Sizzle.error( name ); } }, CHILD: function( elem, match ) { var first, last, doneName, parent, cache, count, diff, type = match[1], node = elem; switch ( type ) { case ""only"": case ""first"": while ( (node = node.previousSibling) ) { if ( node.nodeType === 1 ) { return false; } } if ( type === ""first"" ) { return true; } node = elem; /* falls through */ case ""last"": while ( (node = node.nextSibling) ) { if ( node.nodeType === 1 ) { return false; } } return true; case ""nth"": first = match[2]; last = match[3]; if ( first === 1 && last === 0 ) { return true; } doneName = match[0]; parent = elem.parentNode; if ( parent && (parent[ expando ] !== doneName || !elem.nodeIndex) ) { count = 0; for ( node = parent.firstChild; node; node = node.nextSibling ) { if ( node.nodeType === 1 ) { node.nodeIndex = ++count; } } parent[ expando ] = doneName; } diff = elem.nodeIndex - last; if ( first === 0 ) { return diff === 0; } else { return ( diff % first === 0 && diff / first >= 0 ); } } }, ID: function( elem, match ) { return elem.nodeType === 1 && elem.getAttribute(""id"") === match; }, TAG: function( elem, match ) { return (match === ""*"" && elem.nodeType === 1) || !!elem.nodeName && elem.nodeName.toLowerCase() === match; }, CLASS: function( elem, match ) { return ("" "" + (elem.className || elem.getAttribute(""class"")) + "" "") .indexOf( match ) > -1; }, ATTR: function( elem, match ) { var name = match[1], result = Sizzle.attr ? Sizzle.attr( elem, name ) : Expr.attrHandle[ name ] ? Expr.attrHandle[ name ]( elem ) : elem[ name ] != null ? elem[ name ] : elem.getAttribute( name ), value = result + """", type = match[2], check = match[4]; return result == null ? type === ""!="" : !type && Sizzle.attr ? result != null : type === ""="" ? value === check : type === ""*="" ? value.indexOf(check) >= 0 : type === ""~="" ? ("" "" + value + "" "").indexOf(check) >= 0 : !check ? value && result !== false : type === ""!="" ? value !== check : type === ""^="" ? value.indexOf(check) === 0 : type === ""$="" ? value.substr(value.length - check.length) === check : type === ""|="" ? value === check || value.substr(0, check.length + 1) === check + ""-"" : false; }, POS: function( elem, match, i, array ) { var name = match[2], filter = Expr.setFilters[ name ]; if ( filter ) { return filter( elem, i, match, array ); } } } }; var origPOS = Expr.match.POS, fescape = function(all, num){ return ""\\"" + (num - 0 + 1); }; for ( var type in Expr.match ) { Expr.match[ type ] = new RegExp( Expr.match[ type ].source + (/(?![^\[]*\])(?![^\(]*\))/.source) ); Expr.leftMatch[ type ] = new RegExp( /(^(?:.|\r|\n)*?)/.source + Expr.match[ type ].source.replace(/\\(\d+)/g, fescape) ); } // Expose origPOS // ""global"" as in regardless of relation to brackets/parens Expr.match.globalPOS = origPOS; var makeArray = function( array, results ) { array = Array.prototype.slice.call( array, 0 ); if ( results ) { results.push.apply( results, array ); return results; } return array; }; // Perform a simple check to determine if the browser is capable of // converting a NodeList to an array using builtin methods. // Also verifies that the returned array holds DOM nodes // (which is not the case in the Blackberry browser) try { Array.prototype.slice.call( document.documentElement.childNodes, 0 )[0].nodeType; // Provide a fallback method if it does not work } catch( e ) { makeArray = function( array, results ) { var i = 0, ret = results || []; if ( toString.call(array) === ""[object Array]"" ) { Array.prototype.push.apply( ret, array ); } else { if ( typeof array.length === ""number"" ) { for ( var l = array.length; i < l; i++ ) { ret.push( array[i] ); } } else { for ( ; array[i]; i++ ) { ret.push( array[i] ); } } } return ret; }; } var sortOrder, siblingCheck; if ( document.documentElement.compareDocumentPosition ) { sortOrder = function( a, b ) { if ( a === b ) { hasDuplicate = true; return 0; } if ( !a.compareDocumentPosition || !b.compareDocumentPosition ) { return a.compareDocumentPosition ? -1 : 1; } return a.compareDocumentPosition(b) & 4 ? -1 : 1; }; } else { sortOrder = function( a, b ) { // The nodes are identical, we can exit early if ( a === b ) { hasDuplicate = true; return 0; // Fallback to using sourceIndex (in IE) if it's available on both nodes } else if ( a.sourceIndex && b.sourceIndex ) { return a.sourceIndex - b.sourceIndex; } var al, bl, ap = [], bp = [], aup = a.parentNode, bup = b.parentNode, cur = aup; // If the nodes are siblings (or identical) we can do a quick check if ( aup === bup ) { return siblingCheck( a, b ); // If no parents were found then the nodes are disconnected } else if ( !aup ) { return -1; } else if ( !bup ) { return 1; } // Otherwise they're somewhere else in the tree so we need // to build up a full list of the parentNodes for comparison while ( cur ) { ap.unshift( cur ); cur = cur.parentNode; } cur = bup; while ( cur ) { bp.unshift( cur ); cur = cur.parentNode; } al = ap.length; bl = bp.length; // Start walking down the tree looking for a discrepancy for ( var i = 0; i < al && i < bl; i++ ) { if ( ap[i] !== bp[i] ) { return siblingCheck( ap[i], bp[i] ); } } // We ended someplace up the tree so do a sibling check return i === al ? siblingCheck( a, bp[i], -1 ) : siblingCheck( ap[i], b, 1 ); }; siblingCheck = function( a, b, ret ) { if ( a === b ) { return ret; } var cur = a.nextSibling; while ( cur ) { if ( cur === b ) { return -1; } cur = cur.nextSibling; } return 1; }; } // Check to see if the browser returns elements by name when // querying by getElementById (and provide a workaround) (function(){ // We're going to inject a fake input element with a specified name var form = document.createElement(""div""), id = ""script"" + (new Date()).getTime(), root = document.documentElement; form.innerHTML = ""<a name='"" + id + ""'/>""; // Inject it into the root element, check its status, and remove it quickly root.insertBefore( form, root.firstChild ); // The workaround has to do additional checks after a getElementById // Which slows things down for other browsers (hence the branching) if ( document.getElementById( id ) ) { Expr.find.ID = function( match, context, isXML ) { if ( typeof context.getElementById !== ""undefined"" && !isXML ) { var m = context.getElementById(match[1]); return m ? m.id === match[1] || typeof m.getAttributeNode !== ""undefined"" && m.getAttributeNode(""id"").nodeValue === match[1] ? [m] : undefined : []; } }; Expr.filter.ID = function( elem, match ) { var node = typeof elem.getAttributeNode !== ""undefined"" && elem.getAttributeNode(""id""); return elem.nodeType === 1 && node && node.nodeValue === match; }; } root.removeChild( form ); // release memory in IE root = form = null; })(); (function(){ // Check to see if the browser returns only elements // when doing getElementsByTagName(""*"") // Create a fake element var div = document.createElement(""div""); div.appendChild( document.createComment("""") ); // Make sure no comments are found if ( div.getElementsByTagName(""*"").length > 0 ) { Expr.find.TAG = function( match, context ) { var results = context.getElementsByTagName( match[1] ); // Filter out possible comments if ( match[1] === ""*"" ) { var tmp = []; for ( var i = 0; results[i]; i++ ) { if ( results[i].nodeType === 1 ) { tmp.push( results[i] ); } } results = tmp; } return results; }; } // Check to see if an attribute returns normalized href attributes div.innerHTML = ""<a href='#'></a>""; if ( div.firstChild && typeof div.firstChild.getAttribute !== ""undefined"" && div.firstChild.getAttribute(""href"") !== ""#"" ) { Expr.attrHandle.href = function( elem ) { return elem.getAttribute( ""href"", 2 ); }; } // release memory in IE div = null; })(); if ( document.querySelectorAll ) { (function(){ var oldSizzle = Sizzle, div = document.createElement(""div""), id = ""__sizzle__""; div.innerHTML = ""<p class='TEST'></p>""; // Safari can't handle uppercase or unicode characters when // in quirks mode. if ( div.querySelectorAll && div.querySelectorAll("".TEST"").length === 0 ) { return; } Sizzle = function( query, context, extra, seed ) { context = context || document; // Only use querySelectorAll on non-XML documents // (ID selectors don't work in non-HTML documents) if ( !seed && !Sizzle.isXML(context) ) { // See if we find a selector to speed up var match = /^(\w+$)|^\.([\w\-]+$)|^#([\w\-]+$)/.exec( query ); if ( match && (context.nodeType === 1 || context.nodeType === 9) ) { // Speed-up: Sizzle(""TAG"") if ( match[1] ) { return makeArray( context.getElementsByTagName( query ), extra ); // Speed-up: Sizzle("".CLASS"") } else if ( match[2] && Expr.find.CLASS && context.getElementsByClassName ) { return makeArray( context.getElementsByClassName( match[2] ), extra ); } } if ( context.nodeType === 9 ) { // Speed-up: Sizzle(""body"") // The body element only exists once, optimize finding it if ( query === ""body"" && context.body ) { return makeArray( [ context.body ], extra ); // Speed-up: Sizzle(""#ID"") } else if ( match && match[3] ) { var elem = context.getElementById( match[3] ); // Check parentNode to catch when Blackberry 4.6 returns // nodes that are no longer in the document #6963 if ( elem && elem.parentNode ) { // Handle the case where IE and Opera return items // by name instead of ID if ( elem.id === match[3] ) { return makeArray( [ elem ], extra ); } } else { return makeArray( [], extra ); } } try { return makeArray( context.querySelectorAll(query), extra ); } catch(qsaError) {} // qSA works strangely on Element-rooted queries // We can work around this by specifying an extra ID on the root // and working up from there (Thanks to Andrew Dupont for the technique) // IE 8 doesn't work on object elements } else if ( context.nodeType === 1 && context.nodeName.toLowerCase() !== ""object"" ) { var oldContext = context, old = context.getAttribute( ""id"" ), nid = old || id, hasParent = context.parentNode, relativeHierarchySelector = /^\s*[+~]/.test( query ); if ( !old ) { context.setAttribute( ""id"", nid ); } else { nid = nid.replace( /'/g, ""\\$&"" ); } if ( relativeHierarchySelector && hasParent ) { context = context.parentNode; } try { if ( !relativeHierarchySelector || hasParent ) { return makeArray( context.querySelectorAll( ""[id='"" + nid + ""'] "" + query ), extra ); } } catch(pseudoError) { } finally { if ( !old ) { oldContext.removeAttribute( ""id"" ); } } } } return oldSizzle(query, context, extra, seed); }; for ( var prop in oldSizzle ) { Sizzle[ prop ] = oldSizzle[ prop ]; } // release memory in IE div = null; })(); } (function(){ var html = document.documentElement, matches = html.matchesSelector || html.mozMatchesSelector || html.webkitMatchesSelector || html.msMatchesSelector; if ( matches ) { // Check to see if it's possible to do matchesSelector // on a disconnected node (IE 9 fails this) var disconnectedMatch = !matches.call( document.createElement( ""div"" ), ""div"" ), pseudoWorks = false; try { // This should fail with an exception // Gecko does not error, returns false instead matches.call( document.documentElement, ""[test!='']:sizzle"" ); } catch( pseudoError ) { pseudoWorks = true; } Sizzle.matchesSelector = function( node, expr ) { // Make sure that attribute selectors are quoted expr = expr.replace(/\=\s*([^'""\]]*)\s*\]/g, ""='$1']""); if ( !Sizzle.isXML( node ) ) { try { if ( pseudoWorks || !Expr.match.PSEUDO.test( expr ) && !/!=/.test( expr ) ) { var ret = matches.call( node, expr ); // IE 9's matchesSelector returns false on disconnected nodes if ( ret || !disconnectedMatch || // As well, disconnected nodes are said to be in a document // fragment in IE 9, so check for that node.document && node.document.nodeType !== 11 ) { return ret; } } } catch(e) {} } return Sizzle(expr, null, null, [node]).length > 0; }; } })(); (function(){ var div = document.createElement(""div""); div.innerHTML = ""<div class='test e'></div><div class='test'></div>""; // Opera can't find a second classname (in 9.6) // Also, make sure that getElementsByClassName actually exists if ( !div.getElementsByClassName || div.getElementsByClassName(""e"").length === 0 ) { return; } // Safari caches class attributes, doesn't catch changes (in 3.2) div.lastChild.className = ""e""; if ( div.getElementsByClassName(""e"").length === 1 ) { return; } Expr.order.splice(1, 0, ""CLASS""); Expr.find.CLASS = function( match, context, isXML ) { if ( typeof context.getElementsByClassName !== ""undefined"" && !isXML ) { return context.getElementsByClassName(match[1]); } }; // release memory in IE div = null; })(); function dirNodeCheck( dir, cur, doneName, checkSet, nodeCheck, isXML ) { for ( var i = 0, l = checkSet.length; i < l; i++ ) { var elem = checkSet[i]; if ( elem ) { var match = false; elem = elem[dir]; while ( elem ) { if ( elem[ expando ] === doneName ) { match = checkSet[elem.sizset]; break; } if ( elem.nodeType === 1 && !isXML ){ elem[ expando ] = doneName; elem.sizset = i; } if ( elem.nodeName.toLowerCase() === cur ) { match = elem; break; } elem = elem[dir]; } checkSet[i] = match; } } } function dirCheck( dir, cur, doneName, checkSet, nodeCheck, isXML ) { for ( var i = 0, l = checkSet.length; i < l; i++ ) { var elem = checkSet[i]; if ( elem ) { var match = false; elem = elem[dir]; while ( elem ) { if ( elem[ expando ] === doneName ) { match = checkSet[elem.sizset]; break; } if ( elem.nodeType === 1 ) { if ( !isXML ) { elem[ expando ] = doneName; elem.sizset = i; } if ( typeof cur !== ""string"" ) { if ( elem === cur ) { match = true; break; } } else if ( Sizzle.filter( cur, [elem] ).length > 0 ) { match = elem; break; } } elem = elem[dir]; } checkSet[i] = match; } } } if ( document.documentElement.contains ) { Sizzle.contains = function( a, b ) { return a !== b && (a.contains ? a.contains(b) : true); }; } else if ( document.documentElement.compareDocumentPosition ) { Sizzle.contains = function( a, b ) { return !!(a.compareDocumentPosition(b) & 16); }; } else { Sizzle.contains = function() { return false; }; } Sizzle.isXML = function( elem ) { // documentElement is verified for cases where it doesn't yet exist // (such as loading iframes in IE - #4833) var documentElement = (elem ? elem.ownerDocument || elem : 0).documentElement; return documentElement ? documentElement.nodeName !== ""HTML"" : false; }; var posProcess = function( selector, context, seed ) { var match, tmpSet = [], later = """", root = context.nodeType ? [context] : context; // Position selectors must be done after the filter // And so must :not(positional) so we move all PSEUDOs to the end while ( (match = Expr.match.PSEUDO.exec( selector )) ) { later += match[0]; selector = selector.replace( Expr.match.PSEUDO, """" ); } selector = Expr.relative[selector] ? selector + ""*"" : selector; for ( var i = 0, l = root.length; i < l; i++ ) { Sizzle( selector, root[i], tmpSet, seed ); } return Sizzle.filter( later, tmpSet ); }; // EXPOSE // Override sizzle attribute retrieval Sizzle.attr = jQuery.attr; Sizzle.selectors.attrMap = {}; jQuery.find = Sizzle; jQuery.expr = Sizzle.selectors; jQuery.expr["":""] = jQuery.expr.filters; jQuery.unique = Sizzle.uniqueSort; jQuery.text = Sizzle.getText; jQuery.isXMLDoc = Sizzle.isXML; jQuery.contains = Sizzle.contains; })(); var runtil = /Until$/, rparentsprev = /^(?:parents|prevUntil|prevAll)/, // Note: This RegExp should be improved, or likely pulled from Sizzle rmultiselector = /,/, isSimple = /^.[^:#\[\.,]*$/, slice = Array.prototype.slice, POS = jQuery.expr.match.globalPOS, // methods guaranteed to produce a unique set when starting from a unique set guaranteedUnique = { children: true, contents: true, next: true, prev: true }; jQuery.fn.extend({ find: function( selector ) { var self = this, i, l; if ( typeof selector !== ""string"" ) { return jQuery( selector ).filter(function() { for ( i = 0, l = self.length; i < l; i++ ) { if ( jQuery.contains( self[ i ], this ) ) { return true; } } }); } var ret = this.pushStack( """", ""find"", selector ), length, n, r; for ( i = 0, l = this.length; i < l; i++ ) { length = ret.length; jQuery.find( selector, this[i], ret ); if ( i > 0 ) { // Make sure that the results are unique for ( n = length; n < ret.length; n++ ) { for ( r = 0; r < length; r++ ) { if ( ret[r] === ret[n] ) { ret.splice(n--, 1); break; } } } } } return ret; }, has: function( target ) { var targets = jQuery( target ); return this.filter(function() { for ( var i = 0, l = targets.length; i < l; i++ ) { if ( jQuery.contains( this, targets[i] ) ) { return true; } } }); }, not: function( selector ) { return this.pushStack( winnow(this, selector, false), ""not"", selector); }, filter: function( selector ) { return this.pushStack( winnow(this, selector, true), ""filter"", selector ); }, is: function( selector ) { return !!selector && ( typeof selector === ""string"" ? // If this is a positional selector, check membership in the returned set // so $(""p:first"").is(""p:last"") won't return true for a doc with two ""p"". POS.test( selector ) ? jQuery( selector, this.context ).index( this[0] ) >= 0 : jQuery.filter( selector, this ).length > 0 : this.filter( selector ).length > 0 ); }, closest: function( selectors, context ) { var ret = [], i, l, cur = this[0]; // Array (deprecated as of jQuery 1.7) if ( jQuery.isArray( selectors ) ) { var level = 1; while ( cur && cur.ownerDocument && cur !== context ) { for ( i = 0; i < selectors.length; i++ ) { if ( jQuery( cur ).is( selectors[ i ] ) ) { ret.push({ selector: selectors[ i ], elem: cur, level: level }); } } cur = cur.parentNode; level++; } return ret; } // String var pos = POS.test( selectors ) || typeof selectors !== ""string"" ? jQuery( selectors, context || this.context ) : 0; for ( i = 0, l = this.length; i < l; i++ ) { cur = this[i]; while ( cur ) { if ( pos ? pos.index(cur) > -1 : jQuery.find.matchesSelector(cur, selectors) ) { ret.push( cur ); break; } else { cur = cur.parentNode; if ( !cur || !cur.ownerDocument || cur === context || cur.nodeType === 11 ) { break; } } } } ret = ret.length > 1 ? jQuery.unique( ret ) : ret; return this.pushStack( ret, ""closest"", selectors ); }, // Determine the position of an element within // the matched set of elements index: function( elem ) { // No argument, return index in parent if ( !elem ) { return ( this[0] && this[0].parentNode ) ? this.prevAll().length : -1; } // index in selector if ( typeof elem === ""string"" ) { return jQuery.inArray( this[0], jQuery( elem ) ); } // Locate the position of the desired element return jQuery.inArray( // If it receives a jQuery object, the first element is used elem.jquery ? elem[0] : elem, this ); }, add: function( selector, context ) { var set = typeof selector === ""string"" ? jQuery( selector, context ) : jQuery.makeArray( selector && selector.nodeType ? [ selector ] : selector ), all = jQuery.merge( this.get(), set ); return this.pushStack( isDisconnected( set[0] ) || isDisconnected( all[0] ) ? all : jQuery.unique( all ) ); }, andSelf: function() { return this.add( this.prevObject ); } }); // A painfully simple check to see if an element is disconnected // from a document (should be improved, where feasible). function isDisconnected( node ) { return !node || !node.parentNode || node.parentNode.nodeType === 11; } jQuery.each({ parent: function( elem ) { var parent = elem.parentNode; return parent && parent.nodeType !== 11 ? parent : null; }, parents: function( elem ) { return jQuery.dir( elem, ""parentNode"" ); }, parentsUntil: function( elem, i, until ) { return jQuery.dir( elem, ""parentNode"", until ); }, next: function( elem ) { return jQuery.nth( elem, 2, ""nextSibling"" ); }, prev: function( elem ) { return jQuery.nth( elem, 2, ""previousSibling"" ); }, nextAll: function( elem ) { return jQuery.dir( elem, ""nextSibling"" ); }, prevAll: function( elem ) { return jQuery.dir( elem, ""previousSibling"" ); }, nextUntil: function( elem, i, until ) { return jQuery.dir( elem, ""nextSibling"", until ); }, prevUntil: function( elem, i, until ) { return jQuery.dir( elem, ""previousSibling"", until ); }, siblings: function( elem ) { return jQuery.sibling( ( elem.parentNode || {} ).firstChild, elem ); }, children: function( elem ) { return jQuery.sibling( elem.firstChild ); }, contents: function( elem ) { return jQuery.nodeName( elem, ""iframe"" ) ? elem.contentDocument || elem.contentWindow.document : jQuery.makeArray( elem.childNodes ); } }, function( name, fn ) { jQuery.fn[ name ] = function( until, selector ) { var ret = jQuery.map( this, fn, until ); if ( !runtil.test( name ) ) { selector = until; } if ( selector && typeof selector === ""string"" ) { ret = jQuery.filter( selector, ret ); } ret = this.length > 1 && !guaranteedUnique[ name ] ? jQuery.unique( ret ) : ret; if ( (this.length > 1 || rmultiselector.test( selector )) && rparentsprev.test( name ) ) { ret = ret.reverse(); } return this.pushStack( ret, name, slice.call( arguments ).join("","") ); }; }); jQuery.extend({ filter: function( expr, elems, not ) { if ( not ) { expr = "":not("" + expr + "")""; } return elems.length === 1 ? jQuery.find.matchesSelector(elems[0], expr) ? [ elems[0] ] : [] : jQuery.find.matches(expr, elems); }, dir: function( elem, dir, until ) { var matched = [], cur = elem[ dir ]; while ( cur && cur.nodeType !== 9 && (until === undefined || cur.nodeType !== 1 || !jQuery( cur ).is( until )) ) { if ( cur.nodeType === 1 ) { matched.push( cur ); } cur = cur[dir]; } return matched; }, nth: function( cur, result, dir, elem ) { result = result || 1; var num = 0; for ( ; cur; cur = cur[dir] ) { if ( cur.nodeType === 1 && ++num === result ) { break; } } return cur; }, sibling: function( n, elem ) { var r = []; for ( ; n; n = n.nextSibling ) { if ( n.nodeType === 1 && n !== elem ) { r.push( n ); } } return r; } }); // Implement the identical functionality for filter and not function winnow( elements, qualifier, keep ) { // Can't pass null or undefined to indexOf in Firefox 4 // Set to 0 to skip string check qualifier = qualifier || 0; if ( jQuery.isFunction( qualifier ) ) { return jQuery.grep(elements, function( elem, i ) { var retVal = !!qualifier.call( elem, i, elem ); return retVal === keep; }); } else if ( qualifier.nodeType ) { return jQuery.grep(elements, function( elem, i ) { return ( elem === qualifier ) === keep; }); } else if ( typeof qualifier === ""string"" ) { var filtered = jQuery.grep(elements, function( elem ) { return elem.nodeType === 1; }); if ( isSimple.test( qualifier ) ) { return jQuery.filter(qualifier, filtered, !keep); } else { qualifier = jQuery.filter( qualifier, filtered ); } } return jQuery.grep(elements, function( elem, i ) { return ( jQuery.inArray( elem, qualifier ) >= 0 ) === keep; }); } function createSafeFragment( document ) { var list = nodeNames.split( ""|"" ), safeFrag = document.createDocumentFragment(); if ( safeFrag.createElement ) { while ( list.length ) { safeFrag.createElement( list.pop() ); } } return safeFrag; } var nodeNames = ""abbr|article|aside|audio|bdi|canvas|data|datalist|details|figcaption|figure|footer|"" + ""header|hgroup|mark|meter|nav|output|progress|section|summary|time|video"", rinlinejQuery = / jQuery\d+=""(?:\d+|null)""/g, rleadingWhitespace = /^\s+/, rxhtmlTag = /<(?!area|br|col|embed|hr|img|input|link|meta|param)(([\w:]+)[^>]*)\/>/ig, rtagName = /<([\w:]+)/, rtbody = /<tbody/i, rhtml = /<|&#?\w+;/, rnoInnerhtml = /<(?:script|style)/i, rnocache = /<(?:script|object|embed|option|style)/i, rnoshimcache = new RegExp(""<(?:"" + nodeNames + "")[\\s/>]"", ""i""), // checked=""checked"" or checked rchecked = /checked\s*(?:[^=]|=\s*.checked.)/i, rscriptType = /\/(java|ecma)script/i, rcleanScript = /^\s*<!(?:\[CDATA\[|\-\-)/, wrapMap = { option: [ 1, ""<select multiple='multiple'>"", ""</select>"" ], legend: [ 1, ""<fieldset>"", ""</fieldset>"" ], thead: [ 1, ""<table>"", ""</table>"" ], tr: [ 2, ""<table><tbody>"", ""</tbody></table>"" ], td: [ 3, ""<table><tbody><tr>"", ""</tr></tbody></table>"" ], col: [ 2, ""<table><tbody></tbody><colgroup>"", ""</colgroup></table>"" ], area: [ 1, ""<map>"", ""</map>"" ], _default: [ 0, """", """" ] }, safeFragment = createSafeFragment( document ); wrapMap.optgroup = wrapMap.option; wrapMap.tbody = wrapMap.tfoot = wrapMap.colgroup = wrapMap.caption = wrapMap.thead; wrapMap.th = wrapMap.td; // IE can't serialize <link> and <script> tags normally if ( !jQuery.support.htmlSerialize ) { wrapMap._default = [ 1, ""div<div>"", ""</div>"" ]; } jQuery.fn.extend({ text: function( value ) { return jQuery.access( this, function( value ) { return value === undefined ? jQuery.text( this ) : this.empty().append( ( this[0] && this[0].ownerDocument || document ).createTextNode( value ) ); }, null, value, arguments.length ); }, wrapAll: function( html ) { if ( jQuery.isFunction( html ) ) { return this.each(function(i) { jQuery(this).wrapAll( html.call(this, i) ); }); } if ( this[0] ) { // The elements to wrap the target around var wrap = jQuery( html, this[0].ownerDocument ).eq(0).clone(true); if ( this[0].parentNode ) { wrap.insertBefore( this[0] ); } wrap.map(function() { var elem = this; while ( elem.firstChild && elem.firstChild.nodeType === 1 ) { elem = elem.firstChild; } return elem; }).append( this ); } return this; }, wrapInner: function( html ) { if ( jQuery.isFunction( html ) ) { return this.each(function(i) { jQuery(this).wrapInner( html.call(this, i) ); }); } return this.each(function() { var self = jQuery( this ), contents = self.contents(); if ( contents.length ) { contents.wrapAll( html ); } else { self.append( html ); } }); }, wrap: function( html ) { var isFunction = jQuery.isFunction( html ); return this.each(function(i) { jQuery( this ).wrapAll( isFunction ? html.call(this, i) : html ); }); }, unwrap: function() { return this.parent().each(function() { if ( !jQuery.nodeName( this, ""body"" ) ) { jQuery( this ).replaceWith( this.childNodes ); } }).end(); }, append: function() { return this.domManip(arguments, true, function( elem ) { if ( this.nodeType === 1 ) { this.appendChild( elem ); } }); }, prepend: function() { return this.domManip(arguments, true, function( elem ) { if ( this.nodeType === 1 ) { this.insertBefore( elem, this.firstChild ); } }); }, before: function() { if ( this[0] && this[0].parentNode ) { return this.domManip(arguments, false, function( elem ) { this.parentNode.insertBefore( elem, this ); }); } else if ( arguments.length ) { var set = jQuery.clean( arguments ); set.push.apply( set, this.toArray() ); return this.pushStack( set, ""before"", arguments ); } }, after: function() { if ( this[0] && this[0].parentNode ) { return this.domManip(arguments, false, function( elem ) { this.parentNode.insertBefore( elem, this.nextSibling ); }); } else if ( arguments.length ) { var set = this.pushStack( this, ""after"", arguments ); set.push.apply( set, jQuery.clean(arguments) ); return set; } }, // keepData is for internal use only--do not document remove: function( selector, keepData ) { for ( var i = 0, elem; (elem = this[i]) != null; i++ ) { if ( !selector || jQuery.filter( selector, [ elem ] ).length ) { if ( !keepData && elem.nodeType === 1 ) { jQuery.cleanData( elem.getElementsByTagName(""*"") ); jQuery.cleanData( [ elem ] ); } if ( elem.parentNode ) { elem.parentNode.removeChild( elem ); } } } return this; }, empty: function() { for ( var i = 0, elem; (elem = this[i]) != null; i++ ) { // Remove element nodes and prevent memory leaks if ( elem.nodeType === 1 ) { jQuery.cleanData( elem.getElementsByTagName(""*"") ); } // Remove any remaining nodes while ( elem.firstChild ) { elem.removeChild( elem.firstChild ); } } return this; }, clone: function( dataAndEvents, deepDataAndEvents ) { dataAndEvents = dataAndEvents == null ? false : dataAndEvents; deepDataAndEvents = deepDataAndEvents == null ? dataAndEvents : deepDataAndEvents; return this.map( function () { return jQuery.clone( this, dataAndEvents, deepDataAndEvents ); }); }, html: function( value ) { return jQuery.access( this, function( value ) { var elem = this[0] || {}, i = 0, l = this.length; if ( value === undefined ) { return elem.nodeType === 1 ? elem.innerHTML.replace( rinlinejQuery, """" ) : null; } if ( typeof value === ""string"" && !rnoInnerhtml.test( value ) && ( jQuery.support.leadingWhitespace || !rleadingWhitespace.test( value ) ) && !wrapMap[ ( rtagName.exec( value ) || ["""", """"] )[1].toLowerCase() ] ) { value = value.replace( rxhtmlTag, ""<$1></$2>"" ); try { for (; i < l; i++ ) { // Remove element nodes and prevent memory leaks elem = this[i] || {}; if ( elem.nodeType === 1 ) { jQuery.cleanData( elem.getElementsByTagName( ""*"" ) ); elem.innerHTML = value; } } elem = 0; // If using innerHTML throws an exception, use the fallback method } catch(e) {} } if ( elem ) { this.empty().append( value ); } }, null, value, arguments.length ); }, replaceWith: function( value ) { if ( this[0] && this[0].parentNode ) { // Make sure that the elements are removed from the DOM before they are inserted // this can help fix replacing a parent with child elements if ( jQuery.isFunction( value ) ) { return this.each(function(i) { var self = jQuery(this), old = self.html(); self.replaceWith( value.call( this, i, old ) ); }); } if ( typeof value !== ""string"" ) { value = jQuery( value ).detach(); } return this.each(function() { var next = this.nextSibling, parent = this.parentNode; jQuery( this ).remove(); if ( next ) { jQuery(next).before( value ); } else { jQuery(parent).append( value ); } }); } else { return this.length ? this.pushStack( jQuery(jQuery.isFunction(value) ? value() : value), ""replaceWith"", value ) : this; } }, detach: function( selector ) { return this.remove( selector, true ); }, domManip: function( args, table, callback ) { var results, first, fragment, parent, value = args[0], scripts = []; // We can't cloneNode fragments that contain checked, in WebKit if ( !jQuery.support.checkClone && arguments.length === 3 && typeof value === ""string"" && rchecked.test( value ) ) { return this.each(function() { jQuery(this).domManip( args, table, callback, true ); }); } if ( jQuery.isFunction(value) ) { return this.each(function(i) { var self = jQuery(this); args[0] = value.call(this, i, table ? self.html() : undefined); self.domManip( args, table, callback ); }); } if ( this[0] ) { parent = value && value.parentNode; // If we're in a fragment, just use that instead of building a new one if ( jQuery.support.parentNode && parent && parent.nodeType === 11 && parent.childNodes.length === this.length ) { results = { fragment: parent }; } else { results = jQuery.buildFragment( args, this, scripts ); } fragment = results.fragment; if ( fragment.childNodes.length === 1 ) { first = fragment = fragment.firstChild; } else { first = fragment.firstChild; } if ( first ) { table = table && jQuery.nodeName( first, ""tr"" ); for ( var i = 0, l = this.length, lastIndex = l - 1; i < l; i++ ) { callback.call( table ? root(this[i], first) : this[i], // Make sure that we do not leak memory by inadvertently discarding // the original fragment (which might have attached data) instead of // using it; in addition, use the original fragment object for the last // item instead of first because it can end up being emptied incorrectly // in certain situations (Bug #8070). // Fragments from the fragment cache must always be cloned and never used // in place. results.cacheable || ( l > 1 && i < lastIndex ) ? jQuery.clone( fragment, true, true ) : fragment ); } } if ( scripts.length ) { jQuery.each( scripts, function( i, elem ) { if ( elem.src ) { jQuery.ajax({ type: ""GET"", global: false, url: elem.src, async: false, dataType: ""script"" }); } else { jQuery.globalEval( ( elem.text || elem.textContent || elem.innerHTML || """" ).replace( rcleanScript, ""/*$0*/"" ) ); } if ( elem.parentNode ) { elem.parentNode.removeChild( elem ); } }); } } return this; } }); function root( elem, cur ) { return jQuery.nodeName(elem, ""table"") ? (elem.getElementsByTagName(""tbody"")[0] || elem.appendChild(elem.ownerDocument.createElement(""tbody""))) : elem; } function cloneCopyEvent( src, dest ) { if ( dest.nodeType !== 1 || !jQuery.hasData( src ) ) { return; } var type, i, l, oldData = jQuery._data( src ), curData = jQuery._data( dest, oldData ), events = oldData.events; if ( events ) { delete curData.handle; curData.events = {}; for ( type in events ) { for ( i = 0, l = events[ type ].length; i < l; i++ ) { jQuery.event.add( dest, type, events[ type ][ i ] ); } } } // make the cloned public data object a copy from the original if ( curData.data ) { curData.data = jQuery.extend( {}, curData.data ); } } function cloneFixAttributes( src, dest ) { var nodeName; // We do not need to do anything for non-Elements if ( dest.nodeType !== 1 ) { return; } // clearAttributes removes the attributes, which we don't want, // but also removes the attachEvent events, which we *do* want if ( dest.clearAttributes ) { dest.clearAttributes(); } // mergeAttributes, in contrast, only merges back on the // original attributes, not the events if ( dest.mergeAttributes ) { dest.mergeAttributes( src ); } nodeName = dest.nodeName.toLowerCase(); // IE6-8 fail to clone children inside object elements that use // the proprietary classid attribute value (rather than the type // attribute) to identify the type of content to display if ( nodeName === ""object"" ) { dest.outerHTML = src.outerHTML; } else if ( nodeName === ""input"" && (src.type === ""checkbox"" || src.type === ""radio"") ) { // IE6-8 fails to persist the checked state of a cloned checkbox // or radio button. Worse, IE6-7 fail to give the cloned element // a checked appearance if the defaultChecked value isn't also set if ( src.checked ) { dest.defaultChecked = dest.checked = src.checked; } // IE6-7 get confused and end up setting the value of a cloned // checkbox/radio button to an empty string instead of ""on"" if ( dest.value !== src.value ) { dest.value = src.value; } // IE6-8 fails to return the selected option to the default selected // state when cloning options } else if ( nodeName === ""option"" ) { dest.selected = src.defaultSelected; // IE6-8 fails to set the defaultValue to the correct value when // cloning other types of input fields } else if ( nodeName === ""input"" || nodeName === ""textarea"" ) { dest.defaultValue = src.defaultValue; // IE blanks contents when cloning scripts } else if ( nodeName === ""script"" && dest.text !== src.text ) { dest.text = src.text; } // Event data gets referenced instead of copied if the expando // gets copied too dest.removeAttribute( jQuery.expando ); // Clear flags for bubbling special change/submit events, they must // be reattached when the newly cloned events are first activated dest.removeAttribute( ""_submit_attached"" ); dest.removeAttribute( ""_change_attached"" ); } jQuery.buildFragment = function( args, nodes, scripts ) { var fragment, cacheable, cacheresults, doc, first = args[ 0 ]; // nodes may contain either an explicit document object, // a jQuery collection or context object. // If nodes[0] contains a valid object to assign to doc if ( nodes && nodes[0] ) { doc = nodes[0].ownerDocument || nodes[0]; } // Ensure that an attr object doesn't incorrectly stand in as a document object // Chrome and Firefox seem to allow this to occur and will throw exception // Fixes #8950 if ( !doc.createDocumentFragment ) { doc = document; } // Only cache ""small"" (1/2 KB) HTML strings that are associated with the main document // Cloning options loses the selected state, so don't cache them // IE 6 doesn't like it when you put <object> or <embed> elements in a fragment // Also, WebKit does not clone 'checked' attributes on cloneNode, so don't cache // Lastly, IE6,7,8 will not correctly reuse cached fragments that were created from unknown elems #10501 if ( args.length === 1 && typeof first === ""string"" && first.length < 512 && doc === document && first.charAt(0) === ""<"" && !rnocache.test( first ) && (jQuery.support.checkClone || !rchecked.test( first )) && (jQuery.support.html5Clone || !rnoshimcache.test( first )) ) { cacheable = true; cacheresults = jQuery.fragments[ first ]; if ( cacheresults && cacheresults !== 1 ) { fragment = cacheresults; } } if ( !fragment ) { fragment = doc.createDocumentFragment(); jQuery.clean( args, doc, fragment, scripts ); } if ( cacheable ) { jQuery.fragments[ first ] = cacheresults ? fragment : 1; } return { fragment: fragment, cacheable: cacheable }; }; jQuery.fragments = {}; jQuery.each({ appendTo: ""append"", prependTo: ""prepend"", insertBefore: ""before"", insertAfter: ""after"", replaceAll: ""replaceWith"" }, function( name, original ) { jQuery.fn[ name ] = function( selector ) { var ret = [], insert = jQuery( selector ), parent = this.length === 1 && this[0].parentNode; if ( parent && parent.nodeType === 11 && parent.childNodes.length === 1 && insert.length === 1 ) { insert[ original ]( this[0] ); return this; } else { for ( var i = 0, l = insert.length; i < l; i++ ) { var elems = ( i > 0 ? this.clone(true) : this ).get(); jQuery( insert[i] )[ original ]( elems ); ret = ret.concat( elems ); } return this.pushStack( ret, name, insert.selector ); } }; }); function getAll( elem ) { if ( typeof elem.getElementsByTagName !== ""undefined"" ) { return elem.getElementsByTagName( ""*"" ); } else if ( typeof elem.querySelectorAll !== ""undefined"" ) { return elem.querySelectorAll( ""*"" ); } else { return []; } } // Used in clean, fixes the defaultChecked property function fixDefaultChecked( elem ) { if ( elem.type === ""checkbox"" || elem.type === ""radio"" ) { elem.defaultChecked = elem.checked; } } // Finds all inputs and passes them to fixDefaultChecked function findInputs( elem ) { var nodeName = ( elem.nodeName || """" ).toLowerCase(); if ( nodeName === ""input"" ) { fixDefaultChecked( elem ); // Skip scripts, get other children } else if ( nodeName !== ""script"" && typeof elem.getElementsByTagName !== ""undefined"" ) { jQuery.grep( elem.getElementsByTagName(""input""), fixDefaultChecked ); } } // Derived From: http://www.iecss.com/shimprove/javascript/shimprove.1-0-1.js function shimCloneNode( elem ) { var div = document.createElement( ""div"" ); safeFragment.appendChild( div ); div.innerHTML = elem.outerHTML; return div.firstChild; } jQuery.extend({ clone: function( elem, dataAndEvents, deepDataAndEvents ) { var srcElements, destElements, i, // IE<=8 does not properly clone detached, unknown element nodes clone = jQuery.support.html5Clone || jQuery.isXMLDoc(elem) || !rnoshimcache.test( ""<"" + elem.nodeName + "">"" ) ? elem.cloneNode( true ) : shimCloneNode( elem ); if ( (!jQuery.support.noCloneEvent || !jQuery.support.noCloneChecked) && (elem.nodeType === 1 || elem.nodeType === 11) && !jQuery.isXMLDoc(elem) ) { // IE copies events bound via attachEvent when using cloneNode. // Calling detachEvent on the clone will also remove the events // from the original. In order to get around this, we use some // proprietary methods to clear the events. Thanks to MooTools // guys for this hotness. cloneFixAttributes( elem, clone ); // Using Sizzle here is crazy slow, so we use getElementsByTagName instead srcElements = getAll( elem ); destElements = getAll( clone ); // Weird iteration because IE will replace the length property // with an element if you are cloning the body and one of the // elements on the page has a name or id of ""length"" for ( i = 0; srcElements[i]; ++i ) { // Ensure that the destination node is not null; Fixes #9587 if ( destElements[i] ) { cloneFixAttributes( srcElements[i], destElements[i] ); } } } // Copy the events from the original to the clone if ( dataAndEvents ) { cloneCopyEvent( elem, clone ); if ( deepDataAndEvents ) { srcElements = getAll( elem ); destElements = getAll( clone ); for ( i = 0; srcElements[i]; ++i ) { cloneCopyEvent( srcElements[i], destElements[i] ); } } } srcElements = destElements = null; // Return the cloned set return clone; }, clean: function( elems, context, fragment, scripts ) { var checkScriptType, script, j, ret = []; context = context || document; // !context.createElement fails in IE with an error but returns typeof 'object' if ( typeof context.createElement === ""undefined"" ) { context = context.ownerDocument || context[0] && context[0].ownerDocument || document; } for ( var i = 0, elem; (elem = elems[i]) != null; i++ ) { if ( typeof elem === ""number"" ) { elem += """"; } if ( !elem ) { continue; } // Convert html string into DOM nodes if ( typeof elem === ""string"" ) { if ( !rhtml.test( elem ) ) { elem = context.createTextNode( elem ); } else { // Fix ""XHTML""-style tags in all browsers elem = elem.replace(rxhtmlTag, ""<$1></$2>""); // Trim whitespace, otherwise indexOf won't work as expected var tag = ( rtagName.exec( elem ) || ["""", """"] )[1].toLowerCase(), wrap = wrapMap[ tag ] || wrapMap._default, depth = wrap[0], div = context.createElement(""div""), safeChildNodes = safeFragment.childNodes, remove; // Append wrapper element to unknown element safe doc fragment if ( context === document ) { // Use the fragment we've already created for this document safeFragment.appendChild( div ); } else { // Use a fragment created with the owner document createSafeFragment( context ).appendChild( div ); } // Go to html and back, then peel off extra wrappers div.innerHTML = wrap[1] + elem + wrap[2]; // Move to the right depth while ( depth-- ) { div = div.lastChild; } // Remove IE's autoinserted <tbody> from table fragments if ( !jQuery.support.tbody ) { // String was a <table>, *may* have spurious <tbody> var hasBody = rtbody.test(elem), tbody = tag === ""table"" && !hasBody ? div.firstChild && div.firstChild.childNodes : // String was a bare <thead> or <tfoot> wrap[1] === ""<table>"" && !hasBody ? div.childNodes : []; for ( j = tbody.length - 1; j >= 0 ; --j ) { if ( jQuery.nodeName( tbody[ j ], ""tbody"" ) && !tbody[ j ].childNodes.length ) { tbody[ j ].parentNode.removeChild( tbody[ j ] ); } } } // IE completely kills leading whitespace when innerHTML is used if ( !jQuery.support.leadingWhitespace && rleadingWhitespace.test( elem ) ) { div.insertBefore( context.createTextNode( rleadingWhitespace.exec(elem)[0] ), div.firstChild ); } elem = div.childNodes; // Clear elements from DocumentFragment (safeFragment or otherwise) // to avoid hoarding elements. Fixes #11356 if ( div ) { div.parentNode.removeChild( div ); // Guard against -1 index exceptions in FF3.6 if ( safeChildNodes.length > 0 ) { remove = safeChildNodes[ safeChildNodes.length - 1 ]; if ( remove && remove.parentNode ) { remove.parentNode.removeChild( remove ); } } } } } // Resets defaultChecked for any radios and checkboxes // about to be appended to the DOM in IE 6/7 (#8060) var len; if ( !jQuery.support.appendChecked ) { if ( elem[0] && typeof (len = elem.length) === ""number"" ) { for ( j = 0; j < len; j++ ) { findInputs( elem[j] ); } } else { findInputs( elem ); } } if ( elem.nodeType ) { ret.push( elem ); } else { ret = jQuery.merge( ret, elem ); } } if ( fragment ) { checkScriptType = function( elem ) { return !elem.type || rscriptType.test( elem.type ); }; for ( i = 0; ret[i]; i++ ) { script = ret[i]; if ( scripts && jQuery.nodeName( script, ""script"" ) && (!script.type || rscriptType.test( script.type )) ) { scripts.push( script.parentNode ? script.parentNode.removeChild( script ) : script ); } else { if ( script.nodeType === 1 ) { var jsTags = jQuery.grep( script.getElementsByTagName( ""script"" ), checkScriptType ); ret.splice.apply( ret, [i + 1, 0].concat( jsTags ) ); } fragment.appendChild( script ); } } } return ret; }, cleanData: function( elems ) { var data, id, cache = jQuery.cache, special = jQuery.event.special, deleteExpando = jQuery.support.deleteExpando; for ( var i = 0, elem; (elem = elems[i]) != null; i++ ) { if ( elem.nodeName && jQuery.noData[elem.nodeName.toLowerCase()] ) { continue; } id = elem[ jQuery.expando ]; if ( id ) { data = cache[ id ]; if ( data && data.events ) { for ( var type in data.events ) { if ( special[ type ] ) { jQuery.event.remove( elem, type ); // This is a shortcut to avoid jQuery.event.remove's overhead } else { jQuery.removeEvent( elem, type, data.handle ); } } // Null the DOM reference to avoid IE6/7/8 leak (#7054) if ( data.handle ) { data.handle.elem = null; } } if ( deleteExpando ) { delete elem[ jQuery.expando ]; } else if ( elem.removeAttribute ) { elem.removeAttribute( jQuery.expando ); } delete cache[ id ]; } } } }); var ralpha = /alpha\([^)]*\)/i, ropacity = /opacity=([^)]*)/, // fixed for IE9, see #8346 rupper = /([A-Z]|^ms)/g, rnum = /^[\-+]?(?:\d*\.)?\d+$/i, rnumnonpx = /^-?(?:\d*\.)?\d+(?!px)[^\d\s]+$/i, rrelNum = /^([\-+])=([\-+.\de]+)/, rmargin = /^margin/, cssShow = { position: ""absolute"", visibility: ""hidden"", display: ""block"" }, // order is important! cssExpand = [ ""Top"", ""Right"", ""Bottom"", ""Left"" ], curCSS, getComputedStyle, currentStyle; jQuery.fn.css = function( name, value ) { return jQuery.access( this, function( elem, name, value ) { return value !== undefined ? jQuery.style( elem, name, value ) : jQuery.css( elem, name ); }, name, value, arguments.length > 1 ); }; jQuery.extend({ // Add in style property hooks for overriding the default // behavior of getting and setting a style property cssHooks: { opacity: { get: function( elem, computed ) { if ( computed ) { // We should always get a number back from opacity var ret = curCSS( elem, ""opacity"" ); return ret === """" ? ""1"" : ret; } else { return elem.style.opacity; } } } }, // Exclude the following css properties to add px cssNumber: { ""fillOpacity"": true, ""fontWeight"": true, ""lineHeight"": true, ""opacity"": true, ""orphans"": true, ""widows"": true, ""zIndex"": true, ""zoom"": true }, // Add in properties whose names you wish to fix before // setting or getting the value cssProps: { // normalize float css property ""float"": jQuery.support.cssFloat ? ""cssFloat"" : ""styleFloat"" }, // Get and set the style property on a DOM Node style: function( elem, name, value, extra ) { // Don't set styles on text and comment nodes if ( !elem || elem.nodeType === 3 || elem.nodeType === 8 || !elem.style ) { return; } // Make sure that we're working with the right name var ret, type, origName = jQuery.camelCase( name ), style = elem.style, hooks = jQuery.cssHooks[ origName ]; name = jQuery.cssProps[ origName ] || origName; // Check if we're setting a value if ( value !== undefined ) { type = typeof value; // convert relative number strings (+= or -=) to relative numbers. #7345 if ( type === ""string"" && (ret = rrelNum.exec( value )) ) { value = ( +( ret[1] + 1) * +ret[2] ) + parseFloat( jQuery.css( elem, name ) ); // Fixes bug #9237 type = ""number""; } // Make sure that NaN and null values aren't set. See: #7116 if ( value == null || type === ""number"" && isNaN( value ) ) { return; } // If a number was passed in, add 'px' to the (except for certain CSS properties) if ( type === ""number"" && !jQuery.cssNumber[ origName ] ) { value += ""px""; } // If a hook was provided, use that value, otherwise just set the specified value if ( !hooks || !(""set"" in hooks) || (value = hooks.set( elem, value )) !== undefined ) { // Wrapped to prevent IE from throwing errors when 'invalid' values are provided // Fixes bug #5509 try { style[ name ] = value; } catch(e) {} } } else { // If a hook was provided get the non-computed value from there if ( hooks && ""get"" in hooks && (ret = hooks.get( elem, false, extra )) !== undefined ) { return ret; } // Otherwise just get the value from the style object return style[ name ]; } }, css: function( elem, name, extra ) { var ret, hooks; // Make sure that we're working with the right name name = jQuery.camelCase( name ); hooks = jQuery.cssHooks[ name ]; name = jQuery.cssProps[ name ] || name; // cssFloat needs a special treatment if ( name === ""cssFloat"" ) { name = ""float""; } // If a hook was provided get the computed value from there if ( hooks && ""get"" in hooks && (ret = hooks.get( elem, true, extra )) !== undefined ) { return ret; // Otherwise, if a way to get the computed value exists, use that } else if ( curCSS ) { return curCSS( elem, name ); } }, // A method for quickly swapping in/out CSS properties to get correct calculations swap: function( elem, options, callback ) { var old = {}, ret, name; // Remember the old values, and insert the new ones for ( name in options ) { old[ name ] = elem.style[ name ]; elem.style[ name ] = options[ name ]; } ret = callback.call( elem ); // Revert the old values for ( name in options ) { elem.style[ name ] = old[ name ]; } return ret; } }); // DEPRECATED in 1.3, Use jQuery.css() instead jQuery.curCSS = jQuery.css; if ( document.defaultView && document.defaultView.getComputedStyle ) { getComputedStyle = function( elem, name ) { var ret, defaultView, computedStyle, width, style = elem.style; name = name.replace( rupper, ""-$1"" ).toLowerCase(); if ( (defaultView = elem.ownerDocument.defaultView) && (computedStyle = defaultView.getComputedStyle( elem, null )) ) { ret = computedStyle.getPropertyValue( name ); if ( ret === """" && !jQuery.contains( elem.ownerDocument.documentElement, elem ) ) { ret = jQuery.style( elem, name ); } } // A tribute to the ""awesome hack by Dean Edwards"" // WebKit uses ""computed value (percentage if specified)"" instead of ""used value"" for margins // which is against the CSSOM draft spec: http://dev.w3.org/csswg/cssom/#resolved-values if ( !jQuery.support.pixelMargin && computedStyle && rmargin.test( name ) && rnumnonpx.test( ret ) ) { width = style.width; style.width = ret; ret = computedStyle.width; style.width = width; } return ret; }; } if ( document.documentElement.currentStyle ) { currentStyle = function( elem, name ) { var left, rsLeft, uncomputed, ret = elem.currentStyle && elem.currentStyle[ name ], style = elem.style; // Avoid setting ret to empty string here // so we don't default to auto if ( ret == null && style && (uncomputed = style[ name ]) ) { ret = uncomputed; } // From the awesome hack by Dean Edwards // http://erik.eae.net/archives/2007/07/27/18.54.15/#comment-102291 // If we're not dealing with a regular pixel number // but a number that has a weird ending, we need to convert it to pixels if ( rnumnonpx.test( ret ) ) { // Remember the original values left = style.left; rsLeft = elem.runtimeStyle && elem.runtimeStyle.left; // Put in the new values to get a computed value out if ( rsLeft ) { elem.runtimeStyle.left = elem.currentStyle.left; } style.left = name === ""fontSize"" ? ""1em"" : ret; ret = style.pixelLeft + ""px""; // Revert the changed values style.left = left; if ( rsLeft ) { elem.runtimeStyle.left = rsLeft; } } return ret === """" ? ""auto"" : ret; }; } curCSS = getComputedStyle || currentStyle; function getWidthOrHeight( elem, name, extra ) { // Start with offset property var val = name === ""width"" ? elem.offsetWidth : elem.offsetHeight, i = name === ""width"" ? 1 : 0, len = 4; if ( val > 0 ) { if ( extra !== ""border"" ) { for ( ; i < len; i += 2 ) { if ( !extra ) { val -= parseFloat( jQuery.css( elem, ""padding"" + cssExpand[ i ] ) ) || 0; } if ( extra === ""margin"" ) { val += parseFloat( jQuery.css( elem, extra + cssExpand[ i ] ) ) || 0; } else { val -= parseFloat( jQuery.css( elem, ""border"" + cssExpand[ i ] + ""Width"" ) ) || 0; } } } return val + ""px""; } // Fall back to computed then uncomputed css if necessary val = curCSS( elem, name ); if ( val < 0 || val == null ) { val = elem.style[ name ]; } // Computed unit is not pixels. Stop here and return. if ( rnumnonpx.test(val) ) { return val; } // Normalize """", auto, and prepare for extra val = parseFloat( val ) || 0; // Add padding, border, margin if ( extra ) { for ( ; i < len; i += 2 ) { val += parseFloat( jQuery.css( elem, ""padding"" + cssExpand[ i ] ) ) || 0; if ( extra !== ""padding"" ) { val += parseFloat( jQuery.css( elem, ""border"" + cssExpand[ i ] + ""Width"" ) ) || 0; } if ( extra === ""margin"" ) { val += parseFloat( jQuery.css( elem, extra + cssExpand[ i ]) ) || 0; } } } return val + ""px""; } jQuery.each([ ""height"", ""width"" ], function( i, name ) { jQuery.cssHooks[ name ] = { get: function( elem, computed, extra ) { if ( computed ) { if ( elem.offsetWidth !== 0 ) { return getWidthOrHeight( elem, name, extra ); } else { return jQuery.swap( elem, cssShow, function() { return getWidthOrHeight( elem, name, extra ); }); } } }, set: function( elem, value ) { return rnum.test( value ) ? value + ""px"" : value; } }; }); if ( !jQuery.support.opacity ) { jQuery.cssHooks.opacity = { get: function( elem, computed ) { // IE uses filters for opacity return ropacity.test( (computed && elem.currentStyle ? elem.currentStyle.filter : elem.style.filter) || """" ) ? ( parseFloat( RegExp.$1 ) / 100 ) + """" : computed ? ""1"" : """"; }, set: function( elem, value ) { var style = elem.style, currentStyle = elem.currentStyle, opacity = jQuery.isNumeric( value ) ? ""alpha(opacity="" + value * 100 + "")"" : """", filter = currentStyle && currentStyle.filter || style.filter || """"; // IE has trouble with opacity if it does not have layout // Force it by setting the zoom level style.zoom = 1; // if setting opacity to 1, and no other filters exist - attempt to remove filter attribute #6652 if ( value >= 1 && jQuery.trim( filter.replace( ralpha, """" ) ) === """" ) { // Setting style.filter to null, """" & "" "" still leave ""filter:"" in the cssText // if ""filter:"" is present at all, clearType is disabled, we want to avoid this // style.removeAttribute is IE Only, but so apparently is this code path... style.removeAttribute( ""filter"" ); // if there there is no filter style applied in a css rule, we are done if ( currentStyle && !currentStyle.filter ) { return; } } // otherwise, set new filter values style.filter = ralpha.test( filter ) ? filter.replace( ralpha, opacity ) : filter + "" "" + opacity; } }; } jQuery(function() { // This hook cannot be added until DOM ready because the support test // for it is not run until after DOM ready if ( !jQuery.support.reliableMarginRight ) { jQuery.cssHooks.marginRight = { get: function( elem, computed ) { // WebKit Bug 13343 - getComputedStyle returns wrong value for margin-right // Work around by temporarily setting element display to inline-block return jQuery.swap( elem, { ""display"": ""inline-block"" }, function() { if ( computed ) { return curCSS( elem, ""margin-right"" ); } else { return elem.style.marginRight; } }); } }; } }); if ( jQuery.expr && jQuery.expr.filters ) { jQuery.expr.filters.hidden = function( elem ) { var width = elem.offsetWidth, height = elem.offsetHeight; return ( width === 0 && height === 0 ) || (!jQuery.support.reliableHiddenOffsets && ((elem.style && elem.style.display) || jQuery.css( elem, ""display"" )) === ""none""); }; jQuery.expr.filters.visible = function( elem ) { return !jQuery.expr.filters.hidden( elem ); }; } // These hooks are used by animate to expand properties jQuery.each({ margin: """", padding: """", border: ""Width"" }, function( prefix, suffix ) { jQuery.cssHooks[ prefix + suffix ] = { expand: function( value ) { var i, // assumes a single number if not a string parts = typeof value === ""string"" ? value.split("" "") : [ value ], expanded = {}; for ( i = 0; i < 4; i++ ) { expanded[ prefix + cssExpand[ i ] + suffix ] = parts[ i ] || parts[ i - 2 ] || parts[ 0 ]; } return expanded; } }; }); var r20 = /%20/g, rbracket = /\[\]$/, rCRLF = /\r?\n/g, rhash = /#.*$/, rheaders = /^(.*?):[ \t]*([^\r\n]*)\r?$/mg, // IE leaves an \r character at EOL rinput = /^(?:color|date|datetime|datetime-local|email|hidden|month|number|password|range|search|tel|text|time|url|week)$/i, // #7653, #8125, #8152: local protocol detection rlocalProtocol = /^(?:about|app|app\-storage|.+\-extension|file|res|widget):$/, rnoContent = /^(?:GET|HEAD)$/, rprotocol = /^\/\//, rquery = /\?/, rscript = /<script\b[^<]*(?:(?!<\/script>)<[^<]*)*<\/script>/gi, rselectTextarea = /^(?:select|textarea)/i, rspacesAjax = /\s+/, rts = /([?&])_=[^&]*/, rurl = /^([\w\+\.\-]+:)(?:\/\/([^\/?#:]*)(?::(\d+))?)?/, // Keep a copy of the old load method _load = jQuery.fn.load, /* Prefilters * 1) They are useful to introduce custom dataTypes (see ajax/jsonp.js for an example) * 2) These are called: * - BEFORE asking for a transport * - AFTER param serialization (s.data is a string if s.processData is true) * 3) key is the dataType * 4) the catchall symbol ""*"" can be used * 5) execution will start with transport dataType and THEN continue down to ""*"" if needed */ prefilters = {}, /* Transports bindings * 1) key is the dataType * 2) the catchall symbol ""*"" can be used * 3) selection will start with transport dataType and THEN go to ""*"" if needed */ transports = {}, // Document location ajaxLocation, // Document location segments ajaxLocParts, // Avoid comment-prolog char sequence (#10098); must appease lint and evade compression allTypes = [""*/""] + [""*""]; // #8138, IE may throw an exception when accessing // a field from window.location if document.domain has been set try { ajaxLocation = location.href; } catch( e ) { // Use the href attribute of an A element // since IE will modify it given document.location ajaxLocation = document.createElement( ""a"" ); ajaxLocation.href = """"; ajaxLocation = ajaxLocation.href; } // Segment location into parts ajaxLocParts = rurl.exec( ajaxLocation.toLowerCase() ) || []; // Base ""constructor"" for jQuery.ajaxPrefilter and jQuery.ajaxTransport function addToPrefiltersOrTransports( structure ) { // dataTypeExpression is optional and defaults to ""*"" return function( dataTypeExpression, func ) { if ( typeof dataTypeExpression !== ""string"" ) { func = dataTypeExpression; dataTypeExpression = ""*""; } if ( jQuery.isFunction( func ) ) { var dataTypes = dataTypeExpression.toLowerCase().split( rspacesAjax ), i = 0, length = dataTypes.length, dataType, list, placeBefore; // For each dataType in the dataTypeExpression for ( ; i < length; i++ ) { dataType = dataTypes[ i ]; // We control if we're asked to add before // any existing element placeBefore = /^\+/.test( dataType ); if ( placeBefore ) { dataType = dataType.substr( 1 ) || ""*""; } list = structure[ dataType ] = structure[ dataType ] || []; // then we add to the structure accordingly list[ placeBefore ? ""unshift"" : ""push"" ]( func ); } } }; } // Base inspection function for prefilters and transports function inspectPrefiltersOrTransports( structure, options, originalOptions, jqXHR, dataType /* internal */, inspected /* internal */ ) { dataType = dataType || options.dataTypes[ 0 ]; inspected = inspected || {}; inspected[ dataType ] = true; var list = structure[ dataType ], i = 0, length = list ? list.length : 0, executeOnly = ( structure === prefilters ), selection; for ( ; i < length && ( executeOnly || !selection ); i++ ) { selection = list[ i ]( options, originalOptions, jqXHR ); // If we got redirected to another dataType // we try there if executing only and not done already if ( typeof selection === ""string"" ) { if ( !executeOnly || inspected[ selection ] ) { selection = undefined; } else { options.dataTypes.unshift( selection ); selection = inspectPrefiltersOrTransports( structure, options, originalOptions, jqXHR, selection, inspected ); } } } // If we're only executing or nothing was selected // we try the catchall dataType if not done already if ( ( executeOnly || !selection ) && !inspected[ ""*"" ] ) { selection = inspectPrefiltersOrTransports( structure, options, originalOptions, jqXHR, ""*"", inspected ); } // unnecessary when only executing (prefilters) // but it'll be ignored by the caller in that case return selection; } // A special extend for ajax options // that takes ""flat"" options (not to be deep extended) // Fixes #9887 function ajaxExtend( target, src ) { var key, deep, flatOptions = jQuery.ajaxSettings.flatOptions || {}; for ( key in src ) { if ( src[ key ] !== undefined ) { ( flatOptions[ key ] ? target : ( deep || ( deep = {} ) ) )[ key ] = src[ key ]; } } if ( deep ) { jQuery.extend( true, target, deep ); } } jQuery.fn.extend({ load: function( url, params, callback ) { if ( typeof url !== ""string"" && _load ) { return _load.apply( this, arguments ); // Don't do a request if no elements are being requested } else if ( !this.length ) { return this; } var off = url.indexOf( "" "" ); if ( off >= 0 ) { var selector = url.slice( off, url.length ); url = url.slice( 0, off ); } // Default to a GET request var type = ""GET""; // If the second parameter was provided if ( params ) { // If it's a function if ( jQuery.isFunction( params ) ) { // We assume that it's the callback callback = params; params = undefined; // Otherwise, build a param string } else if ( typeof params === ""object"" ) { params = jQuery.param( params, jQuery.ajaxSettings.traditional ); type = ""POST""; } } var self = this; // Request the remote document jQuery.ajax({ url: url, type: type, dataType: ""html"", data: params, // Complete callback (responseText is used internally) complete: function( jqXHR, status, responseText ) { // Store the response as specified by the jqXHR object responseText = jqXHR.responseText; // If successful, inject the HTML into all the matched elements if ( jqXHR.isResolved() ) { // #4825: Get the actual response in case // a dataFilter is present in ajaxSettings jqXHR.done(function( r ) { responseText = r; }); // See if a selector was specified self.html( selector ? // Create a dummy div to hold the results jQuery(""<div>"") // inject the contents of the document in, removing the scripts // to avoid any 'Permission Denied' errors in IE .append(responseText.replace(rscript, """")) // Locate the specified elements .find(selector) : // If not, just inject the full result responseText ); } if ( callback ) { self.each( callback, [ responseText, status, jqXHR ] ); } } }); return this; }, serialize: function() { return jQuery.param( this.serializeArray() ); }, serializeArray: function() { return this.map(function(){ return this.elements ? jQuery.makeArray( this.elements ) : this; }) .filter(function(){ return this.name && !this.disabled && ( this.checked || rselectTextarea.test( this.nodeName ) || rinput.test( this.type ) ); }) .map(function( i, elem ){ var val = jQuery( this ).val(); return val == null ? null : jQuery.isArray( val ) ? jQuery.map( val, function( val, i ){ return { name: elem.name, value: val.replace( rCRLF, ""\r\n"" ) }; }) : { name: elem.name, value: val.replace( rCRLF, ""\r\n"" ) }; }).get(); } }); // Attach a bunch of functions for handling common AJAX events jQuery.each( ""ajaxStart ajaxStop ajaxComplete ajaxError ajaxSuccess ajaxSend"".split( "" "" ), function( i, o ){ jQuery.fn[ o ] = function( f ){ return this.on( o, f ); }; }); jQuery.each( [ ""get"", ""post"" ], function( i, method ) { jQuery[ method ] = function( url, data, callback, type ) { // shift arguments if data argument was omitted if ( jQuery.isFunction( data ) ) { type = type || callback; callback = data; data = undefined; } return jQuery.ajax({ type: method, url: url, data: data, success: callback, dataType: type }); }; }); jQuery.extend({ getScript: function( url, callback ) { return jQuery.get( url, undefined, callback, ""script"" ); }, getJSON: function( url, data, callback ) { return jQuery.get( url, data, callback, ""json"" ); }, // Creates a full fledged settings object into target // with both ajaxSettings and settings fields. // If target is omitted, writes into ajaxSettings. ajaxSetup: function( target, settings ) { if ( settings ) { // Building a settings object ajaxExtend( target, jQuery.ajaxSettings ); } else { // Extending ajaxSettings settings = target; target = jQuery.ajaxSettings; } ajaxExtend( target, settings ); return target; }, ajaxSettings: { url: ajaxLocation, isLocal: rlocalProtocol.test( ajaxLocParts[ 1 ] ), global: true, type: ""GET"", contentType: ""application/x-www-form-urlencoded; charset=UTF-8"", processData: true, async: true, /* timeout: 0, data: null, dataType: null, username: null, password: null, cache: null, traditional: false, headers: {}, */ accepts: { xml: ""application/xml, text/xml"", html: ""text/html"", text: ""text/plain"", json: ""application/json, text/javascript"", ""*"": allTypes }, contents: { xml: /xml/, html: /html/, json: /json/ }, responseFields: { xml: ""responseXML"", text: ""responseText"" }, // List of data converters // 1) key format is ""source_type destination_type"" (a single space in-between) // 2) the catchall symbol ""*"" can be used for source_type converters: { // Convert anything to text ""* text"": window.String, // Text to html (true = no transformation) ""text html"": true, // Evaluate text as a json expression ""text json"": jQuery.parseJSON, // Parse text as xml ""text xml"": jQuery.parseXML }, // For options that shouldn't be deep extended: // you can add your own custom options here if // and when you create one that shouldn't be // deep extended (see ajaxExtend) flatOptions: { context: true, url: true } }, ajaxPrefilter: addToPrefiltersOrTransports( prefilters ), ajaxTransport: addToPrefiltersOrTransports( transports ), // Main method ajax: function( url, options ) { // If url is an object, simulate pre-1.5 signature if ( typeof url === ""object"" ) { options = url; url = undefined; } // Force options to be an object options = options || {}; var // Create the final options object s = jQuery.ajaxSetup( {}, options ), // Callbacks context callbackContext = s.context || s, // Context for global events // It's the callbackContext if one was provided in the options // and if it's a DOM node or a jQuery collection globalEventContext = callbackContext !== s && ( callbackContext.nodeType || callbackContext instanceof jQuery ) ? jQuery( callbackContext ) : jQuery.event, // Deferreds deferred = jQuery.Deferred(), completeDeferred = jQuery.Callbacks( ""once memory"" ), // Status-dependent callbacks statusCode = s.statusCode || {}, // ifModified key ifModifiedKey, // Headers (they are sent all at once) requestHeaders = {}, requestHeadersNames = {}, // Response headers responseHeadersString, responseHeaders, // transport transport, // timeout handle timeoutTimer, // Cross-domain detection vars parts, // The jqXHR state state = 0, // To know if global events are to be dispatched fireGlobals, // Loop variable i, // Fake xhr jqXHR = { readyState: 0, // Caches the header setRequestHeader: function( name, value ) { if ( !state ) { var lname = name.toLowerCase(); name = requestHeadersNames[ lname ] = requestHeadersNames[ lname ] || name; requestHeaders[ name ] = value; } return this; }, // Raw string getAllResponseHeaders: function() { return state === 2 ? responseHeadersString : null; }, // Builds headers hashtable if needed getResponseHeader: function( key ) { var match; if ( state === 2 ) { if ( !responseHeaders ) { responseHeaders = {}; while( ( match = rheaders.exec( responseHeadersString ) ) ) { responseHeaders[ match[1].toLowerCase() ] = match[ 2 ]; } } match = responseHeaders[ key.toLowerCase() ]; } return match === undefined ? null : match; }, // Overrides response content-type header overrideMimeType: function( type ) { if ( !state ) { s.mimeType = type; } return this; }, // Cancel the request abort: function( statusText ) { statusText = statusText || ""abort""; if ( transport ) { transport.abort( statusText ); } done( 0, statusText ); return this; } }; // Callback for when everything is done // It is defined here because jslint complains if it is declared // at the end of the function (which would be more logical and readable) function done( status, nativeStatusText, responses, headers ) { // Called once if ( state === 2 ) { return; } // State is ""done"" now state = 2; // Clear timeout if it exists if ( timeoutTimer ) { clearTimeout( timeoutTimer ); } // Dereference transport for early garbage collection // (no matter how long the jqXHR object will be used) transport = undefined; // Cache response headers responseHeadersString = headers || """"; // Set readyState jqXHR.readyState = status > 0 ? 4 : 0; var isSuccess, success, error, statusText = nativeStatusText, response = responses ? ajaxHandleResponses( s, jqXHR, responses ) : undefined, lastModified, etag; // If successful, handle type chaining if ( status >= 200 && status < 300 || status === 304 ) { // Set the If-Modified-Since and/or If-None-Match header, if in ifModified mode. if ( s.ifModified ) { if ( ( lastModified = jqXHR.getResponseHeader( ""Last-Modified"" ) ) ) { jQuery.lastModified[ ifModifiedKey ] = lastModified; } if ( ( etag = jqXHR.getResponseHeader( ""Etag"" ) ) ) { jQuery.etag[ ifModifiedKey ] = etag; } } // If not modified if ( status === 304 ) { statusText = ""notmodified""; isSuccess = true; // If we have data } else { try { success = ajaxConvert( s, response ); statusText = ""success""; isSuccess = true; } catch(e) { // We have a parsererror statusText = ""parsererror""; error = e; } } } else { // We extract error from statusText // then normalize statusText and status for non-aborts error = statusText; if ( !statusText || status ) { statusText = ""error""; if ( status < 0 ) { status = 0; } } } // Set data for the fake xhr object jqXHR.status = status; jqXHR.statusText = """" + ( nativeStatusText || statusText ); // Success/Error if ( isSuccess ) { deferred.resolveWith( callbackContext, [ success, statusText, jqXHR ] ); } else { deferred.rejectWith( callbackContext, [ jqXHR, statusText, error ] ); } // Status-dependent callbacks jqXHR.statusCode( statusCode ); statusCode = undefined; if ( fireGlobals ) { globalEventContext.trigger( ""ajax"" + ( isSuccess ? ""Success"" : ""Error"" ), [ jqXHR, s, isSuccess ? success : error ] ); } // Complete completeDeferred.fireWith( callbackContext, [ jqXHR, statusText ] ); if ( fireGlobals ) { globalEventContext.trigger( ""ajaxComplete"", [ jqXHR, s ] ); // Handle the global AJAX counter if ( !( --jQuery.active ) ) { jQuery.event.trigger( ""ajaxStop"" ); } } } // Attach deferreds deferred.promise( jqXHR ); jqXHR.success = jqXHR.done; jqXHR.error = jqXHR.fail; jqXHR.complete = completeDeferred.add; // Status-dependent callbacks jqXHR.statusCode = function( map ) { if ( map ) { var tmp; if ( state < 2 ) { for ( tmp in map ) { statusCode[ tmp ] = [ statusCode[tmp], map[tmp] ]; } } else { tmp = map[ jqXHR.status ]; jqXHR.then( tmp, tmp ); } } return this; }; // Remove hash character (#7531: and string promotion) // Add protocol if not provided (#5866: IE7 issue with protocol-less urls) // We also use the url parameter if available s.url = ( ( url || s.url ) + """" ).replace( rhash, """" ).replace( rprotocol, ajaxLocParts[ 1 ] + ""//"" ); // Extract dataTypes list s.dataTypes = jQuery.trim( s.dataType || ""*"" ).toLowerCase().split( rspacesAjax ); // Determine if a cross-domain request is in order if ( s.crossDomain == null ) { parts = rurl.exec( s.url.toLowerCase() ); s.crossDomain = !!( parts && ( parts[ 1 ] != ajaxLocParts[ 1 ] || parts[ 2 ] != ajaxLocParts[ 2 ] || ( parts[ 3 ] || ( parts[ 1 ] === ""http:"" ? 80 : 443 ) ) != ( ajaxLocParts[ 3 ] || ( ajaxLocParts[ 1 ] === ""http:"" ? 80 : 443 ) ) ) ); } // Convert data if not already a string if ( s.data && s.processData && typeof s.data !== ""string"" ) { s.data = jQuery.param( s.data, s.traditional ); } // Apply prefilters inspectPrefiltersOrTransports( prefilters, s, options, jqXHR ); // If request was aborted inside a prefilter, stop there if ( state === 2 ) { return false; } // We can fire global events as of now if asked to fireGlobals = s.global; // Uppercase the type s.type = s.type.toUpperCase(); // Determine if request has content s.hasContent = !rnoContent.test( s.type ); // Watch for a new set of requests if ( fireGlobals && jQuery.active++ === 0 ) { jQuery.event.trigger( ""ajaxStart"" ); } // More options handling for requests with no content if ( !s.hasContent ) { // If data is available, append data to url if ( s.data ) { s.url += ( rquery.test( s.url ) ? ""&"" : ""?"" ) + s.data; // #9682: remove data so that it's not used in an eventual retry delete s.data; } // Get ifModifiedKey before adding the anti-cache parameter ifModifiedKey = s.url; // Add anti-cache in url if needed if ( s.cache === false ) { var ts = jQuery.now(), // try replacing _= if it is there ret = s.url.replace( rts, ""$1_="" + ts ); // if nothing was replaced, add timestamp to the end s.url = ret + ( ( ret === s.url ) ? ( rquery.test( s.url ) ? ""&"" : ""?"" ) + ""_="" + ts : """" ); } } // Set the correct header, if data is being sent if ( s.data && s.hasContent && s.contentType !== false || options.contentType ) { jqXHR.setRequestHeader( ""Content-Type"", s.contentType ); } // Set the If-Modified-Since and/or If-None-Match header, if in ifModified mode. if ( s.ifModified ) { ifModifiedKey = ifModifiedKey || s.url; if ( jQuery.lastModified[ ifModifiedKey ] ) { jqXHR.setRequestHeader( ""If-Modified-Since"", jQuery.lastModified[ ifModifiedKey ] ); } if ( jQuery.etag[ ifModifiedKey ] ) { jqXHR.setRequestHeader( ""If-None-Match"", jQuery.etag[ ifModifiedKey ] ); } } // Set the Accepts header for the server, depending on the dataType jqXHR.setRequestHeader( ""Accept"", s.dataTypes[ 0 ] && s.accepts[ s.dataTypes[0] ] ? s.accepts[ s.dataTypes[0] ] + ( s.dataTypes[ 0 ] !== ""*"" ? "", "" + allTypes + ""; q=0.01"" : """" ) : s.accepts[ ""*"" ] ); // Check for headers option for ( i in s.headers ) { jqXHR.setRequestHeader( i, s.headers[ i ] ); } // Allow custom headers/mimetypes and early abort if ( s.beforeSend && ( s.beforeSend.call( callbackContext, jqXHR, s ) === false || state === 2 ) ) { // Abort if not done already jqXHR.abort(); return false; } // Install callbacks on deferreds for ( i in { success: 1, error: 1, complete: 1 } ) { jqXHR[ i ]( s[ i ] ); } // Get transport transport = inspectPrefiltersOrTransports( transports, s, options, jqXHR ); // If no transport, we auto-abort if ( !transport ) { done( -1, ""No Transport"" ); } else { jqXHR.readyState = 1; // Send global event if ( fireGlobals ) { globalEventContext.trigger( ""ajaxSend"", [ jqXHR, s ] ); } // Timeout if ( s.async && s.timeout > 0 ) { timeoutTimer = setTimeout( function(){ jqXHR.abort( ""timeout"" ); }, s.timeout ); } try { state = 1; transport.send( requestHeaders, done ); } catch (e) { // Propagate exception as error if not done if ( state < 2 ) { done( -1, e ); // Simply rethrow otherwise } else { throw e; } } } return jqXHR; }, // Serialize an array of form elements or a set of // key/values into a query string param: function( a, traditional ) { var s = [], add = function( key, value ) { // If value is a function, invoke it and return its value value = jQuery.isFunction( value ) ? value() : value; s[ s.length ] = encodeURIComponent( key ) + ""="" + encodeURIComponent( value ); }; // Set traditional to true for jQuery <= 1.3.2 behavior. if ( traditional === undefined ) { traditional = jQuery.ajaxSettings.traditional; } // If an array was passed in, assume that it is an array of form elements. if ( jQuery.isArray( a ) || ( a.jquery && !jQuery.isPlainObject( a ) ) ) { // Serialize the form elements jQuery.each( a, function() { add( this.name, this.value ); }); } else { // If traditional, encode the ""old"" way (the way 1.3.2 or older // did it), otherwise encode params recursively. for ( var prefix in a ) { buildParams( prefix, a[ prefix ], traditional, add ); } } // Return the resulting serialization return s.join( ""&"" ).replace( r20, ""+"" ); } }); function buildParams( prefix, obj, traditional, add ) { if ( jQuery.isArray( obj ) ) { // Serialize array item. jQuery.each( obj, function( i, v ) { if ( traditional || rbracket.test( prefix ) ) { // Treat each array item as a scalar. add( prefix, v ); } else { // If array item is non-scalar (array or object), encode its // numeric index to resolve deserialization ambiguity issues. // Note that rack (as of 1.0.0) can't currently deserialize // nested arrays properly, and attempting to do so may cause // a server error. Possible fixes are to modify rack's // deserialization algorithm or to provide an option or flag // to force array serialization to be shallow. buildParams( prefix + ""["" + ( typeof v === ""object"" ? i : """" ) + ""]"", v, traditional, add ); } }); } else if ( !traditional && jQuery.type( obj ) === ""object"" ) { // Serialize object item. for ( var name in obj ) { buildParams( prefix + ""["" + name + ""]"", obj[ name ], traditional, add ); } } else { // Serialize scalar item. add( prefix, obj ); } } // This is still on the jQuery object... for now // Want to move this to jQuery.ajax some day jQuery.extend({ // Counter for holding the number of active queries active: 0, // Last-Modified header cache for next request lastModified: {}, etag: {} }); /* Handles responses to an ajax request: * - sets all responseXXX fields accordingly * - finds the right dataType (mediates between content-type and expected dataType) * - returns the corresponding response */ function ajaxHandleResponses( s, jqXHR, responses ) { var contents = s.contents, dataTypes = s.dataTypes, responseFields = s.responseFields, ct, type, finalDataType, firstDataType; // Fill responseXXX fields for ( type in responseFields ) { if ( type in responses ) { jqXHR[ responseFields[type] ] = responses[ type ]; } } // Remove auto dataType and get content-type in the process while( dataTypes[ 0 ] === ""*"" ) { dataTypes.shift(); if ( ct === undefined ) { ct = s.mimeType || jqXHR.getResponseHeader( ""content-type"" ); } } // Check if we're dealing with a known content-type if ( ct ) { for ( type in contents ) { if ( contents[ type ] && contents[ type ].test( ct ) ) { dataTypes.unshift( type ); break; } } } // Check to see if we have a response for the expected dataType if ( dataTypes[ 0 ] in responses ) { finalDataType = dataTypes[ 0 ]; } else { // Try convertible dataTypes for ( type in responses ) { if ( !dataTypes[ 0 ] || s.converters[ type + "" "" + dataTypes[0] ] ) { finalDataType = type; break; } if ( !firstDataType ) { firstDataType = type; } } // Or just use first one finalDataType = finalDataType || firstDataType; } // If we found a dataType // We add the dataType to the list if needed // and return the corresponding response if ( finalDataType ) { if ( finalDataType !== dataTypes[ 0 ] ) { dataTypes.unshift( finalDataType ); } return responses[ finalDataType ]; } } // Chain conversions given the request and the original response function ajaxConvert( s, response ) { // Apply the dataFilter if provided if ( s.dataFilter ) { response = s.dataFilter( response, s.dataType ); } var dataTypes = s.dataTypes, converters = {}, i, key, length = dataTypes.length, tmp, // Current and previous dataTypes current = dataTypes[ 0 ], prev, // Conversion expression conversion, // Conversion function conv, // Conversion functions (transitive conversion) conv1, conv2; // For each dataType in the chain for ( i = 1; i < length; i++ ) { // Create converters map // with lowercased keys if ( i === 1 ) { for ( key in s.converters ) { if ( typeof key === ""string"" ) { converters[ key.toLowerCase() ] = s.converters[ key ]; } } } // Get the dataTypes prev = current; current = dataTypes[ i ]; // If current is auto dataType, update it to prev if ( current === ""*"" ) { current = prev; // If no auto and dataTypes are actually different } else if ( prev !== ""*"" && prev !== current ) { // Get the converter conversion = prev + "" "" + current; conv = converters[ conversion ] || converters[ ""* "" + current ]; // If there is no direct converter, search transitively if ( !conv ) { conv2 = undefined; for ( conv1 in converters ) { tmp = conv1.split( "" "" ); if ( tmp[ 0 ] === prev || tmp[ 0 ] === ""*"" ) { conv2 = converters[ tmp[1] + "" "" + current ]; if ( conv2 ) { conv1 = converters[ conv1 ]; if ( conv1 === true ) { conv = conv2; } else if ( conv2 === true ) { conv = conv1; } break; } } } } // If we found no converter, dispatch an error if ( !( conv || conv2 ) ) { jQuery.error( ""No conversion from "" + conversion.replace("" "","" to "") ); } // If found converter is not an equivalence if ( conv !== true ) { // Convert with 1 or 2 converters accordingly response = conv ? conv( response ) : conv2( conv1(response) ); } } } return response; } var jsc = jQuery.now(), jsre = /(\=)\?(&|$)|\?\?/i; // Default jsonp settings jQuery.ajaxSetup({ jsonp: ""callback"", jsonpCallback: function() { return jQuery.expando + ""_"" + ( jsc++ ); } }); // Detect, normalize options and install callbacks for jsonp requests jQuery.ajaxPrefilter( ""json jsonp"", function( s, originalSettings, jqXHR ) { var inspectData = ( typeof s.data === ""string"" ) && /^application\/x\-www\-form\-urlencoded/.test( s.contentType ); if ( s.dataTypes[ 0 ] === ""jsonp"" || s.jsonp !== false && ( jsre.test( s.url ) || inspectData && jsre.test( s.data ) ) ) { var responseContainer, jsonpCallback = s.jsonpCallback = jQuery.isFunction( s.jsonpCallback ) ? s.jsonpCallback() : s.jsonpCallback, previous = window[ jsonpCallback ], url = s.url, data = s.data, replace = ""$1"" + jsonpCallback + ""$2""; if ( s.jsonp !== false ) { url = url.replace( jsre, replace ); if ( s.url === url ) { if ( inspectData ) { data = data.replace( jsre, replace ); } if ( s.data === data ) { // Add callback manually url += (/\?/.test( url ) ? ""&"" : ""?"") + s.jsonp + ""="" + jsonpCallback; } } } s.url = url; s.data = data; // Install callback window[ jsonpCallback ] = function( response ) { responseContainer = [ response ]; }; // Clean-up function jqXHR.always(function() { // Set callback back to previous value window[ jsonpCallback ] = previous; // Call if it was a function and we have a response if ( responseContainer && jQuery.isFunction( previous ) ) { window[ jsonpCallback ]( responseContainer[ 0 ] ); } }); // Use data converter to retrieve json after script execution s.converters[""script json""] = function() { if ( !responseContainer ) { jQuery.error( jsonpCallback + "" was not called"" ); } return responseContainer[ 0 ]; }; // force json dataType s.dataTypes[ 0 ] = ""json""; // Delegate to script return ""script""; } }); // Install script dataType jQuery.ajaxSetup({ accepts: { script: ""text/javascript, application/javascript, application/ecmascript, application/x-ecmascript"" }, contents: { script: /javascript|ecmascript/ }, converters: { ""text script"": function( text ) { jQuery.globalEval( text ); return text; } } }); // Handle cache's special case and global jQuery.ajaxPrefilter( ""script"", function( s ) { if ( s.cache === undefined ) { s.cache = false; } if ( s.crossDomain ) { s.type = ""GET""; s.global = false; } }); // Bind script tag hack transport jQuery.ajaxTransport( ""script"", function(s) { // This transport only deals with cross domain requests if ( s.crossDomain ) { var script, head = document.head || document.getElementsByTagName( ""head"" )[0] || document.documentElement; return { send: function( _, callback ) { script = document.createElement( ""script"" ); script.async = ""async""; if ( s.scriptCharset ) { script.charset = s.scriptCharset; } script.src = s.url; // Attach handlers for all browsers script.onload = script.onreadystatechange = function( _, isAbort ) { if ( isAbort || !script.readyState || /loaded|complete/.test( script.readyState ) ) { // Handle memory leak in IE script.onload = script.onreadystatechange = null; // Remove the script if ( head && script.parentNode ) { head.removeChild( script ); } // Dereference the script script = undefined; // Callback if not abort if ( !isAbort ) { callback( 200, ""success"" ); } } }; // Use insertBefore instead of appendChild to circumvent an IE6 bug. // This arises when a base node is used (#2709 and #4378). head.insertBefore( script, head.firstChild ); }, abort: function() { if ( script ) { script.onload( 0, 1 ); } } }; } }); var // #5280: Internet Explorer will keep connections alive if we don't abort on unload xhrOnUnloadAbort = window.ActiveXObject ? function() { // Abort all pending requests for ( var key in xhrCallbacks ) { xhrCallbacks[ key ]( 0, 1 ); } } : false, xhrId = 0, xhrCallbacks; // Functions to create xhrs function createStandardXHR() { try { return new window.XMLHttpRequest(); } catch( e ) {} } function createActiveXHR() { try { return new window.ActiveXObject( ""Microsoft.XMLHTTP"" ); } catch( e ) {} } // Create the request object // (This is still attached to ajaxSettings for backward compatibility) jQuery.ajaxSettings.xhr = window.ActiveXObject ? /* Microsoft failed to properly * implement the XMLHttpRequest in IE7 (can't request local files), * so we use the ActiveXObject when it is available * Additionally XMLHttpRequest can be disabled in IE7/IE8 so * we need a fallback. */ function() { return !this.isLocal && createStandardXHR() || createActiveXHR(); } : // For all other browsers, use the standard XMLHttpRequest object createStandardXHR; // Determine support properties (function( xhr ) { jQuery.extend( jQuery.support, { ajax: !!xhr, cors: !!xhr && ( ""withCredentials"" in xhr ) }); })( jQuery.ajaxSettings.xhr() ); // Create transport if the browser can provide an xhr if ( jQuery.support.ajax ) { jQuery.ajaxTransport(function( s ) { // Cross domain only allowed if supported through XMLHttpRequest if ( !s.crossDomain || jQuery.support.cors ) { var callback; return { send: function( headers, complete ) { // Get a new xhr var xhr = s.xhr(), handle, i; // Open the socket // Passing null username, generates a login popup on Opera (#2865) if ( s.username ) { xhr.open( s.type, s.url, s.async, s.username, s.password ); } else { xhr.open( s.type, s.url, s.async ); } // Apply custom fields if provided if ( s.xhrFields ) { for ( i in s.xhrFields ) { xhr[ i ] = s.xhrFields[ i ]; } } // Override mime type if needed if ( s.mimeType && xhr.overrideMimeType ) { xhr.overrideMimeType( s.mimeType ); } // X-Requested-With header // For cross-domain requests, seeing as conditions for a preflight are // akin to a jigsaw puzzle, we simply never set it to be sure. // (it can always be set on a per-request basis or even using ajaxSetup) // For same-domain requests, won't change header if already provided. if ( !s.crossDomain && !headers[""X-Requested-With""] ) { headers[ ""X-Requested-With"" ] = ""XMLHttpRequest""; } // Need an extra try/catch for cross domain requests in Firefox 3 try { for ( i in headers ) { xhr.setRequestHeader( i, headers[ i ] ); } } catch( _ ) {} // Do send the request // This may raise an exception which is actually // handled in jQuery.ajax (so no try/catch here) xhr.send( ( s.hasContent && s.data ) || null ); // Listener callback = function( _, isAbort ) { var status, statusText, responseHeaders, responses, xml; // Firefox throws exceptions when accessing properties // of an xhr when a network error occured // http://helpful.knobs-dials.com/index.php/Component_returned_failure_code:_0x80040111_(NS_ERROR_NOT_AVAILABLE) try { // Was never called and is aborted or complete if ( callback && ( isAbort || xhr.readyState === 4 ) ) { // Only called once callback = undefined; // Do not keep as active anymore if ( handle ) { xhr.onreadystatechange = jQuery.noop; if ( xhrOnUnloadAbort ) { delete xhrCallbacks[ handle ]; } } // If it's an abort if ( isAbort ) { // Abort it manually if needed if ( xhr.readyState !== 4 ) { xhr.abort(); } } else { status = xhr.status; responseHeaders = xhr.getAllResponseHeaders(); responses = {}; xml = xhr.responseXML; // Construct response list if ( xml && xml.documentElement /* #4958 */ ) { responses.xml = xml; } // When requesting binary data, IE6-9 will throw an exception // on any attempt to access responseText (#11426) try { responses.text = xhr.responseText; } catch( _ ) { } // Firefox throws an exception when accessing // statusText for faulty cross-domain requests try { statusText = xhr.statusText; } catch( e ) { // We normalize with Webkit giving an empty statusText statusText = """"; } // Filter status for non standard behaviors // If the request is local and we have data: assume a success // (success with no data won't get notified, that's the best we // can do given current implementations) if ( !status && s.isLocal && !s.crossDomain ) { status = responses.text ? 200 : 404; // IE - #1450: sometimes returns 1223 when it should be 204 } else if ( status === 1223 ) { status = 204; } } } } catch( firefoxAccessException ) { if ( !isAbort ) { complete( -1, firefoxAccessException ); } } // Call complete if needed if ( responses ) { complete( status, statusText, responses, responseHeaders ); } }; // if we're in sync mode or it's in cache // and has been retrieved directly (IE6 & IE7) // we need to manually fire the callback if ( !s.async || xhr.readyState === 4 ) { callback(); } else { handle = ++xhrId; if ( xhrOnUnloadAbort ) { // Create the active xhrs callbacks list if needed // and attach the unload handler if ( !xhrCallbacks ) { xhrCallbacks = {}; jQuery( window ).unload( xhrOnUnloadAbort ); } // Add to list of active xhrs callbacks xhrCallbacks[ handle ] = callback; } xhr.onreadystatechange = callback; } }, abort: function() { if ( callback ) { callback(0,1); } } }; } }); } var elemdisplay = {}, iframe, iframeDoc, rfxtypes = /^(?:toggle|show|hide)$/, rfxnum = /^([+\-]=)?([\d+.\-]+)([a-z%]*)$/i, timerId, fxAttrs = [ // height animations [ ""height"", ""marginTop"", ""marginBottom"", ""paddingTop"", ""paddingBottom"" ], // width animations [ ""width"", ""marginLeft"", ""marginRight"", ""paddingLeft"", ""paddingRight"" ], // opacity animations [ ""opacity"" ] ], fxNow; jQuery.fn.extend({ show: function( speed, easing, callback ) { var elem, display; if ( speed || speed === 0 ) { return this.animate( genFx(""show"", 3), speed, easing, callback ); } else { for ( var i = 0, j = this.length; i < j; i++ ) { elem = this[ i ]; if ( elem.style ) { display = elem.style.display; // Reset the inline display of this element to learn if it is // being hidden by cascaded rules or not if ( !jQuery._data(elem, ""olddisplay"") && display === ""none"" ) { display = elem.style.display = """"; } // Set elements which have been overridden with display: none // in a stylesheet to whatever the default browser style is // for such an element if ( (display === """" && jQuery.css(elem, ""display"") === ""none"") || !jQuery.contains( elem.ownerDocument.documentElement, elem ) ) { jQuery._data( elem, ""olddisplay"", defaultDisplay(elem.nodeName) ); } } } // Set the display of most of the elements in a second loop // to avoid the constant reflow for ( i = 0; i < j; i++ ) { elem = this[ i ]; if ( elem.style ) { display = elem.style.display; if ( display === """" || display === ""none"" ) { elem.style.display = jQuery._data( elem, ""olddisplay"" ) || """"; } } } return this; } }, hide: function( speed, easing, callback ) { if ( speed || speed === 0 ) { return this.animate( genFx(""hide"", 3), speed, easing, callback); } else { var elem, display, i = 0, j = this.length; for ( ; i < j; i++ ) { elem = this[i]; if ( elem.style ) { display = jQuery.css( elem, ""display"" ); if ( display !== ""none"" && !jQuery._data( elem, ""olddisplay"" ) ) { jQuery._data( elem, ""olddisplay"", display ); } } } // Set the display of the elements in a second loop // to avoid the constant reflow for ( i = 0; i < j; i++ ) { if ( this[i].style ) { this[i].style.display = ""none""; } } return this; } }, // Save the old toggle function _toggle: jQuery.fn.toggle, toggle: function( fn, fn2, callback ) { var bool = typeof fn === ""boolean""; if ( jQuery.isFunction(fn) && jQuery.isFunction(fn2) ) { this._toggle.apply( this, arguments ); } else if ( fn == null || bool ) { this.each(function() { var state = bool ? fn : jQuery(this).is("":hidden""); jQuery(this)[ state ? ""show"" : ""hide"" ](); }); } else { this.animate(genFx(""toggle"", 3), fn, fn2, callback); } return this; }, fadeTo: function( speed, to, easing, callback ) { return this.filter("":hidden"").css(""opacity"", 0).show().end() .animate({opacity: to}, speed, easing, callback); }, animate: function( prop, speed, easing, callback ) { var optall = jQuery.speed( speed, easing, callback ); if ( jQuery.isEmptyObject( prop ) ) { return this.each( optall.complete, [ false ] ); } // Do not change referenced properties as per-property easing will be lost prop = jQuery.extend( {}, prop ); function doAnimation() { // XXX 'this' does not always have a nodeName when running the // test suite if ( optall.queue === false ) { jQuery._mark( this ); } var opt = jQuery.extend( {}, optall ), isElement = this.nodeType === 1, hidden = isElement && jQuery(this).is("":hidden""), name, val, p, e, hooks, replace, parts, start, end, unit, method; // will store per property easing and be used to determine when an animation is complete opt.animatedProperties = {}; // first pass over propertys to expand / normalize for ( p in prop ) { name = jQuery.camelCase( p ); if ( p !== name ) { prop[ name ] = prop[ p ]; delete prop[ p ]; } if ( ( hooks = jQuery.cssHooks[ name ] ) && ""expand"" in hooks ) { replace = hooks.expand( prop[ name ] ); delete prop[ name ]; // not quite $.extend, this wont overwrite keys already present. // also - reusing 'p' from above because we have the correct ""name"" for ( p in replace ) { if ( ! ( p in prop ) ) { prop[ p ] = replace[ p ]; } } } } for ( name in prop ) { val = prop[ name ]; // easing resolution: per property > opt.specialEasing > opt.easing > 'swing' (default) if ( jQuery.isArray( val ) ) { opt.animatedProperties[ name ] = val[ 1 ]; val = prop[ name ] = val[ 0 ]; } else { opt.animatedProperties[ name ] = opt.specialEasing && opt.specialEasing[ name ] || opt.easing || 'swing'; } if ( val === ""hide"" && hidden || val === ""show"" && !hidden ) { return opt.complete.call( this ); } if ( isElement && ( name === ""height"" || name === ""width"" ) ) { // Make sure that nothing sneaks out // Record all 3 overflow attributes because IE does not // change the overflow attribute when overflowX and // overflowY are set to the same value opt.overflow = [ this.style.overflow, this.style.overflowX, this.style.overflowY ]; // Set display property to inline-block for height/width // animations on inline elements that are having width/height animated if ( jQuery.css( this, ""display"" ) === ""inline"" && jQuery.css( this, ""float"" ) === ""none"" ) { // inline-level elements accept inline-block; // block-level elements need to be inline with layout if ( !jQuery.support.inlineBlockNeedsLayout || defaultDisplay( this.nodeName ) === ""inline"" ) { this.style.display = ""inline-block""; } else { this.style.zoom = 1; } } } } if ( opt.overflow != null ) { this.style.overflow = ""hidden""; } for ( p in prop ) { e = new jQuery.fx( this, opt, p ); val = prop[ p ]; if ( rfxtypes.test( val ) ) { // Tracks whether to show or hide based on private // data attached to the element method = jQuery._data( this, ""toggle"" + p ) || ( val === ""toggle"" ? hidden ? ""show"" : ""hide"" : 0 ); if ( method ) { jQuery._data( this, ""toggle"" + p, method === ""show"" ? ""hide"" : ""show"" ); e[ method ](); } else { e[ val ](); } } else { parts = rfxnum.exec( val ); start = e.cur(); if ( parts ) { end = parseFloat( parts[2] ); unit = parts[3] || ( jQuery.cssNumber[ p ] ? """" : ""px"" ); // We need to compute starting value if ( unit !== ""px"" ) { jQuery.style( this, p, (end || 1) + unit); start = ( (end || 1) / e.cur() ) * start; jQuery.style( this, p, start + unit); } // If a +=/-= token was provided, we're doing a relative animation if ( parts[1] ) { end = ( (parts[ 1 ] === ""-="" ? -1 : 1) * end ) + start; } e.custom( start, end, unit ); } else { e.custom( start, val, """" ); } } } // For JS strict compliance return true; } return optall.queue === false ? this.each( doAnimation ) : this.queue( optall.queue, doAnimation ); }, stop: function( type, clearQueue, gotoEnd ) { if ( typeof type !== ""string"" ) { gotoEnd = clearQueue; clearQueue = type; type = undefined; } if ( clearQueue && type !== false ) { this.queue( type || ""fx"", [] ); } return this.each(function() { var index, hadTimers = false, timers = jQuery.timers, data = jQuery._data( this ); // clear marker counters if we know they won't be if ( !gotoEnd ) { jQuery._unmark( true, this ); } function stopQueue( elem, data, index ) { var hooks = data[ index ]; jQuery.removeData( elem, index, true ); hooks.stop( gotoEnd ); } if ( type == null ) { for ( index in data ) { if ( data[ index ] && data[ index ].stop && index.indexOf("".run"") === index.length - 4 ) { stopQueue( this, data, index ); } } } else if ( data[ index = type + "".run"" ] && data[ index ].stop ){ stopQueue( this, data, index ); } for ( index = timers.length; index--; ) { if ( timers[ index ].elem === this && (type == null || timers[ index ].queue === type) ) { if ( gotoEnd ) { // force the next step to be the last timers[ index ]( true ); } else { timers[ index ].saveState(); } hadTimers = true; timers.splice( index, 1 ); } } // start the next in the queue if the last step wasn't forced // timers currently will call their complete callbacks, which will dequeue // but only if they were gotoEnd if ( !( gotoEnd && hadTimers ) ) { jQuery.dequeue( this, type ); } }); } }); // Animations created synchronously will run synchronously function createFxNow() { setTimeout( clearFxNow, 0 ); return ( fxNow = jQuery.now() ); } function clearFxNow() { fxNow = undefined; } // Generate parameters to create a standard animation function genFx( type, num ) { var obj = {}; jQuery.each( fxAttrs.concat.apply([], fxAttrs.slice( 0, num )), function() { obj[ this ] = type; }); return obj; } // Generate shortcuts for custom animations jQuery.each({ slideDown: genFx( ""show"", 1 ), slideUp: genFx( ""hide"", 1 ), slideToggle: genFx( ""toggle"", 1 ), fadeIn: { opacity: ""show"" }, fadeOut: { opacity: ""hide"" }, fadeToggle: { opacity: ""toggle"" } }, function( name, props ) { jQuery.fn[ name ] = function( speed, easing, callback ) { return this.animate( props, speed, easing, callback ); }; }); jQuery.extend({ speed: function( speed, easing, fn ) { var opt = speed && typeof speed === ""object"" ? jQuery.extend( {}, speed ) : { complete: fn || !fn && easing || jQuery.isFunction( speed ) && speed, duration: speed, easing: fn && easing || easing && !jQuery.isFunction( easing ) && easing }; opt.duration = jQuery.fx.off ? 0 : typeof opt.duration === ""number"" ? opt.duration : opt.duration in jQuery.fx.speeds ? jQuery.fx.speeds[ opt.duration ] : jQuery.fx.speeds._default; // normalize opt.queue - true/undefined/null -> ""fx"" if ( opt.queue == null || opt.queue === true ) { opt.queue = ""fx""; } // Queueing opt.old = opt.complete; opt.complete = function( noUnmark ) { if ( jQuery.isFunction( opt.old ) ) { opt.old.call( this ); } if ( opt.queue ) { jQuery.dequeue( this, opt.queue ); } else if ( noUnmark !== false ) { jQuery._unmark( this ); } }; return opt; }, easing: { linear: function( p ) { return p; }, swing: function( p ) { return ( -Math.cos( p*Math.PI ) / 2 ) + 0.5; } }, timers: [], fx: function( elem, options, prop ) { this.options = options; this.elem = elem; this.prop = prop; options.orig = options.orig || {}; } }); jQuery.fx.prototype = { // Simple function for setting a style value update: function() { if ( this.options.step ) { this.options.step.call( this.elem, this.now, this ); } ( jQuery.fx.step[ this.prop ] || jQuery.fx.step._default )( this ); }, // Get the current size cur: function() { if ( this.elem[ this.prop ] != null && (!this.elem.style || this.elem.style[ this.prop ] == null) ) { return this.elem[ this.prop ]; } var parsed, r = jQuery.css( this.elem, this.prop ); // Empty strings, null, undefined and ""auto"" are converted to 0, // complex values such as ""rotate(1rad)"" are returned as is, // simple values such as ""10px"" are parsed to Float. return isNaN( parsed = parseFloat( r ) ) ? !r || r === ""auto"" ? 0 : r : parsed; }, // Start an animation from one number to another custom: function( from, to, unit ) { var self = this, fx = jQuery.fx; this.startTime = fxNow || createFxNow(); this.end = to; this.now = this.start = from; this.pos = this.state = 0; this.unit = unit || this.unit || ( jQuery.cssNumber[ this.prop ] ? """" : ""px"" ); function t( gotoEnd ) { return self.step( gotoEnd ); } t.queue = this.options.queue; t.elem = this.elem; t.saveState = function() { if ( jQuery._data( self.elem, ""fxshow"" + self.prop ) === undefined ) { if ( self.options.hide ) { jQuery._data( self.elem, ""fxshow"" + self.prop, self.start ); } else if ( self.options.show ) { jQuery._data( self.elem, ""fxshow"" + self.prop, self.end ); } } }; if ( t() && jQuery.timers.push(t) && !timerId ) { timerId = setInterval( fx.tick, fx.interval ); } }, // Simple 'show' function show: function() { var dataShow = jQuery._data( this.elem, ""fxshow"" + this.prop ); // Remember where we started, so that we can go back to it later this.options.orig[ this.prop ] = dataShow || jQuery.style( this.elem, this.prop ); this.options.show = true; // Begin the animation // Make sure that we start at a small width/height to avoid any flash of content if ( dataShow !== undefined ) { // This show is picking up where a previous hide or show left off this.custom( this.cur(), dataShow ); } else { this.custom( this.prop === ""width"" || this.prop === ""height"" ? 1 : 0, this.cur() ); } // Start by showing the element jQuery( this.elem ).show(); }, // Simple 'hide' function hide: function() { // Remember where we started, so that we can go back to it later this.options.orig[ this.prop ] = jQuery._data( this.elem, ""fxshow"" + this.prop ) || jQuery.style( this.elem, this.prop ); this.options.hide = true; // Begin the animation this.custom( this.cur(), 0 ); }, // Each step of an animation step: function( gotoEnd ) { var p, n, complete, t = fxNow || createFxNow(), done = true, elem = this.elem, options = this.options; if ( gotoEnd || t >= options.duration + this.startTime ) { this.now = this.end; this.pos = this.state = 1; this.update(); options.animatedProperties[ this.prop ] = true; for ( p in options.animatedProperties ) { if ( options.animatedProperties[ p ] !== true ) { done = false; } } if ( done ) { // Reset the overflow if ( options.overflow != null && !jQuery.support.shrinkWrapBlocks ) { jQuery.each( [ """", ""X"", ""Y"" ], function( index, value ) { elem.style[ ""overflow"" + value ] = options.overflow[ index ]; }); } // Hide the element if the ""hide"" operation was done if ( options.hide ) { jQuery( elem ).hide(); } // Reset the properties, if the item has been hidden or shown if ( options.hide || options.show ) { for ( p in options.animatedProperties ) { jQuery.style( elem, p, options.orig[ p ] ); jQuery.removeData( elem, ""fxshow"" + p, true ); // Toggle data is no longer needed jQuery.removeData( elem, ""toggle"" + p, true ); } } // Execute the complete function // in the event that the complete function throws an exception // we must ensure it won't be called twice. #5684 complete = options.complete; if ( complete ) { options.complete = false; complete.call( elem ); } } return false; } else { // classical easing cannot be used with an Infinity duration if ( options.duration == Infinity ) { this.now = t; } else { n = t - this.startTime; this.state = n / options.duration; // Perform the easing function, defaults to swing this.pos = jQuery.easing[ options.animatedProperties[this.prop] ]( this.state, n, 0, 1, options.duration ); this.now = this.start + ( (this.end - this.start) * this.pos ); } // Perform the next step of the animation this.update(); } return true; } }; jQuery.extend( jQuery.fx, { tick: function() { var timer, timers = jQuery.timers, i = 0; for ( ; i < timers.length; i++ ) { timer = timers[ i ]; // Checks the timer has not already been removed if ( !timer() && timers[ i ] === timer ) { timers.splice( i--, 1 ); } } if ( !timers.length ) { jQuery.fx.stop(); } }, interval: 13, stop: function() { clearInterval( timerId ); timerId = null; }, speeds: { slow: 600, fast: 200, // Default speed _default: 400 }, step: { opacity: function( fx ) { jQuery.style( fx.elem, ""opacity"", fx.now ); }, _default: function( fx ) { if ( fx.elem.style && fx.elem.style[ fx.prop ] != null ) { fx.elem.style[ fx.prop ] = fx.now + fx.unit; } else { fx.elem[ fx.prop ] = fx.now; } } } }); // Ensure props that can't be negative don't go there on undershoot easing jQuery.each( fxAttrs.concat.apply( [], fxAttrs ), function( i, prop ) { // exclude marginTop, marginLeft, marginBottom and marginRight from this list if ( prop.indexOf( ""margin"" ) ) { jQuery.fx.step[ prop ] = function( fx ) { jQuery.style( fx.elem, prop, Math.max(0, fx.now) + fx.unit ); }; } }); if ( jQuery.expr && jQuery.expr.filters ) { jQuery.expr.filters.animated = function( elem ) { return jQuery.grep(jQuery.timers, function( fn ) { return elem === fn.elem; }).length; }; } // Try to restore the default display value of an element function defaultDisplay( nodeName ) { if ( !elemdisplay[ nodeName ] ) { var body = document.body, elem = jQuery( ""<"" + nodeName + "">"" ).appendTo( body ), display = elem.css( ""display"" ); elem.remove(); // If the simple way fails, // get element's real default display by attaching it to a temp iframe if ( display === ""none"" || display === """" ) { // No iframe to use yet, so create it if ( !iframe ) { iframe = document.createElement( ""iframe"" ); iframe.frameBorder = iframe.width = iframe.height = 0; } body.appendChild( iframe ); // Create a cacheable copy of the iframe document on first call. // IE and Opera will allow us to reuse the iframeDoc without re-writing the fake HTML // document to it; WebKit & Firefox won't allow reusing the iframe document. if ( !iframeDoc || !iframe.createElement ) { iframeDoc = ( iframe.contentWindow || iframe.contentDocument ).document; iframeDoc.write( ( jQuery.support.boxModel ? ""<!doctype html>"" : """" ) + ""<html><body>"" ); iframeDoc.close(); } elem = iframeDoc.createElement( nodeName ); iframeDoc.body.appendChild( elem ); display = jQuery.css( elem, ""display"" ); body.removeChild( iframe ); } // Store the correct default display elemdisplay[ nodeName ] = display; } return elemdisplay[ nodeName ]; } var getOffset, rtable = /^t(?:able|d|h)$/i, rroot = /^(?:body|html)$/i; if ( ""getBoundingClientRect"" in document.documentElement ) { getOffset = function( elem, doc, docElem, box ) { try { box = elem.getBoundingClientRect(); } catch(e) {} // Make sure we're not dealing with a disconnected DOM node if ( !box || !jQuery.contains( docElem, elem ) ) { return box ? { top: box.top, left: box.left } : { top: 0, left: 0 }; } var body = doc.body, win = getWindow( doc ), clientTop = docElem.clientTop || body.clientTop || 0, clientLeft = docElem.clientLeft || body.clientLeft || 0, scrollTop = win.pageYOffset || jQuery.support.boxModel && docElem.scrollTop || body.scrollTop, scrollLeft = win.pageXOffset || jQuery.support.boxModel && docElem.scrollLeft || body.scrollLeft, top = box.top + scrollTop - clientTop, left = box.left + scrollLeft - clientLeft; return { top: top, left: left }; }; } else { getOffset = function( elem, doc, docElem ) { var computedStyle, offsetParent = elem.offsetParent, prevOffsetParent = elem, body = doc.body, defaultView = doc.defaultView, prevComputedStyle = defaultView ? defaultView.getComputedStyle( elem, null ) : elem.currentStyle, top = elem.offsetTop, left = elem.offsetLeft; while ( (elem = elem.parentNode) && elem !== body && elem !== docElem ) { if ( jQuery.support.fixedPosition && prevComputedStyle.position === ""fixed"" ) { break; } computedStyle = defaultView ? defaultView.getComputedStyle(elem, null) : elem.currentStyle; top -= elem.scrollTop; left -= elem.scrollLeft; if ( elem === offsetParent ) { top += elem.offsetTop; left += elem.offsetLeft; if ( jQuery.support.doesNotAddBorder && !(jQuery.support.doesAddBorderForTableAndCells && rtable.test(elem.nodeName)) ) { top += parseFloat( computedStyle.borderTopWidth ) || 0; left += parseFloat( computedStyle.borderLeftWidth ) || 0; } prevOffsetParent = offsetParent; offsetParent = elem.offsetParent; } if ( jQuery.support.subtractsBorderForOverflowNotVisible && computedStyle.overflow !== ""visible"" ) { top += parseFloat( computedStyle.borderTopWidth ) || 0; left += parseFloat( computedStyle.borderLeftWidth ) || 0; } prevComputedStyle = computedStyle; } if ( prevComputedStyle.position === ""relative"" || prevComputedStyle.position === ""static"" ) { top += body.offsetTop; left += body.offsetLeft; } if ( jQuery.support.fixedPosition && prevComputedStyle.position === ""fixed"" ) { top += Math.max( docElem.scrollTop, body.scrollTop ); left += Math.max( docElem.scrollLeft, body.scrollLeft ); } return { top: top, left: left }; }; } jQuery.fn.offset = function( options ) { if ( arguments.length ) { return options === undefined ? this : this.each(function( i ) { jQuery.offset.setOffset( this, options, i ); }); } var elem = this[0], doc = elem && elem.ownerDocument; if ( !doc ) { return null; } if ( elem === doc.body ) { return jQuery.offset.bodyOffset( elem ); } return getOffset( elem, doc, doc.documentElement ); }; jQuery.offset = { bodyOffset: function( body ) { var top = body.offsetTop, left = body.offsetLeft; if ( jQuery.support.doesNotIncludeMarginInBodyOffset ) { top += parseFloat( jQuery.css(body, ""marginTop"") ) || 0; left += parseFloat( jQuery.css(body, ""marginLeft"") ) || 0; } return { top: top, left: left }; }, setOffset: function( elem, options, i ) { var position = jQuery.css( elem, ""position"" ); // set position first, in-case top/left are set even on static elem if ( position === ""static"" ) { elem.style.position = ""relative""; } var curElem = jQuery( elem ), curOffset = curElem.offset(), curCSSTop = jQuery.css( elem, ""top"" ), curCSSLeft = jQuery.css( elem, ""left"" ), calculatePosition = ( position === ""absolute"" || position === ""fixed"" ) && jQuery.inArray(""auto"", [curCSSTop, curCSSLeft]) > -1, props = {}, curPosition = {}, curTop, curLeft; // need to be able to calculate position if either top or left is auto and position is either absolute or fixed if ( calculatePosition ) { curPosition = curElem.position(); curTop = curPosition.top; curLeft = curPosition.left; } else { curTop = parseFloat( curCSSTop ) || 0; curLeft = parseFloat( curCSSLeft ) || 0; } if ( jQuery.isFunction( options ) ) { options = options.call( elem, i, curOffset ); } if ( options.top != null ) { props.top = ( options.top - curOffset.top ) + curTop; } if ( options.left != null ) { props.left = ( options.left - curOffset.left ) + curLeft; } if ( ""using"" in options ) { options.using.call( elem, props ); } else { curElem.css( props ); } } }; jQuery.fn.extend({ position: function() { if ( !this[0] ) { return null; } var elem = this[0], // Get *real* offsetParent offsetParent = this.offsetParent(), // Get correct offsets offset = this.offset(), parentOffset = rroot.test(offsetParent[0].nodeName) ? { top: 0, left: 0 } : offsetParent.offset(); // Subtract element margins // note: when an element has margin: auto the offsetLeft and marginLeft // are the same in Safari causing offset.left to incorrectly be 0 offset.top -= parseFloat( jQuery.css(elem, ""marginTop"") ) || 0; offset.left -= parseFloat( jQuery.css(elem, ""marginLeft"") ) || 0; // Add offsetParent borders parentOffset.top += parseFloat( jQuery.css(offsetParent[0], ""borderTopWidth"") ) || 0; parentOffset.left += parseFloat( jQuery.css(offsetParent[0], ""borderLeftWidth"") ) || 0; // Subtract the two offsets return { top: offset.top - parentOffset.top, left: offset.left - parentOffset.left }; }, offsetParent: function() { return this.map(function() { var offsetParent = this.offsetParent || document.body; while ( offsetParent && (!rroot.test(offsetParent.nodeName) && jQuery.css(offsetParent, ""position"") === ""static"") ) { offsetParent = offsetParent.offsetParent; } return offsetParent; }); } }); // Create scrollLeft and scrollTop methods jQuery.each( {scrollLeft: ""pageXOffset"", scrollTop: ""pageYOffset""}, function( method, prop ) { var top = /Y/.test( prop ); jQuery.fn[ method ] = function( val ) { return jQuery.access( this, function( elem, method, val ) { var win = getWindow( elem ); if ( val === undefined ) { return win ? (prop in win) ? win[ prop ] : jQuery.support.boxModel && win.document.documentElement[ method ] || win.document.body[ method ] : elem[ method ]; } if ( win ) { win.scrollTo( !top ? val : jQuery( win ).scrollLeft(), top ? val : jQuery( win ).scrollTop() ); } else { elem[ method ] = val; } }, method, val, arguments.length, null ); }; }); function getWindow( elem ) { return jQuery.isWindow( elem ) ? elem : elem.nodeType === 9 ? elem.defaultView || elem.parentWindow : false; } // Create width, height, innerHeight, innerWidth, outerHeight and outerWidth methods jQuery.each( { Height: ""height"", Width: ""width"" }, function( name, type ) { var clientProp = ""client"" + name, scrollProp = ""scroll"" + name, offsetProp = ""offset"" + name; // innerHeight and innerWidth jQuery.fn[ ""inner"" + name ] = function() { var elem = this[0]; return elem ? elem.style ? parseFloat( jQuery.css( elem, type, ""padding"" ) ) : this[ type ]() : null; }; // outerHeight and outerWidth jQuery.fn[ ""outer"" + name ] = function( margin ) { var elem = this[0]; return elem ? elem.style ? parseFloat( jQuery.css( elem, type, margin ? ""margin"" : ""border"" ) ) : this[ type ]() : null; }; jQuery.fn[ type ] = function( value ) { return jQuery.access( this, function( elem, type, value ) { var doc, docElemProp, orig, ret; if ( jQuery.isWindow( elem ) ) { // 3rd condition allows Nokia support, as it supports the docElem prop but not CSS1Compat doc = elem.document; docElemProp = doc.documentElement[ clientProp ]; return jQuery.support.boxModel && docElemProp || doc.body && doc.body[ clientProp ] || docElemProp; } // Get document width or height if ( elem.nodeType === 9 ) { // Either scroll[Width/Height] or offset[Width/Height], whichever is greater doc = elem.documentElement; // when a window > document, IE6 reports a offset[Width/Height] > client[Width/Height] // so we can't use max, as it'll choose the incorrect offset[Width/Height] // instead we use the correct client[Width/Height] // support:IE6 if ( doc[ clientProp ] >= doc[ scrollProp ] ) { return doc[ clientProp ]; } return Math.max( elem.body[ scrollProp ], doc[ scrollProp ], elem.body[ offsetProp ], doc[ offsetProp ] ); } // Get width or height on the element if ( value === undefined ) { orig = jQuery.css( elem, type ); ret = parseFloat( orig ); return jQuery.isNumeric( ret ) ? ret : orig; } // Set the width or height on the element jQuery( elem ).css( type, value ); }, type, value, arguments.length, null ); }; }); // Expose jQuery to the global object window.jQuery = window.$ = jQuery; // Expose jQuery as an AMD module, but only for AMD loaders that // understand the issues with loading multiple versions of jQuery // in a page that all might call define(). The loader will indicate // they have special allowances for multiple jQuery versions by // specifying define.amd.jQuery = true. Register as a named module, // since jQuery can be concatenated with other files that may use define, // but not use a proper concatenation script that understands anonymous // AMD modules. A named AMD is safest and most robust way to register. // Lowercase jquery is used because AMD module names are derived from // file names, and jQuery is normally delivered in a lowercase file name. // Do this after creating the global so that if an AMD module wants to call // noConflict to hide this version of jQuery, it will work. if ( typeof define === ""function"" && define.amd && define.amd.jQuery ) { define( ""jquery"", [], function () { return jQuery; } ); } })( window ); ",7,35219
openstack%2Frequirements~master~Ic4537e7130b5b438bea4c5c9cce547fbc68f6005,openstack/requirements,master,Ic4537e7130b5b438bea4c5c9cce547fbc68f6005,block cffi 0.8.2,ABANDONED,2014-03-07 15:10:59.000000000,2014-03-07 16:05:20.000000000,,"[{'_account_id': 3}, {'_account_id': 2750}, {'_account_id': 7680}]","[{'number': 1, 'created': '2014-03-07 15:10:59.000000000', 'files': ['global-requirements.txt'], 'web_link': 'https://opendev.org/openstack/requirements/commit/e7def1abc53ab2ab3fc1ad6fea33bfdb6df941d8', 'message': ""block cffi 0.8.2\n\ncffi 0.8.2 breaks when using eventlet. If you pip install it you\ncan no longer 'from eventlet import greenthread'.\n\nChange-Id: Ic4537e7130b5b438bea4c5c9cce547fbc68f6005\n""}]",0,78982,e7def1abc53ab2ab3fc1ad6fea33bfdb6df941d8,4,3,1,2750,,,0,"block cffi 0.8.2

cffi 0.8.2 breaks when using eventlet. If you pip install it you
can no longer 'from eventlet import greenthread'.

Change-Id: Ic4537e7130b5b438bea4c5c9cce547fbc68f6005
",git fetch https://review.opendev.org/openstack/requirements refs/changes/82/78982/1 && git format-patch -1 --stdout FETCH_HEAD,['global-requirements.txt'],1,e7def1abc53ab2ab3fc1ad6fea33bfdb6df941d8,,"# cffi 0.8.2 was rushed out to deal with setuptools issue, it doesn't work cffi!=0.8.2",cffi,2,1
openstack%2Fmanila~master~Ia5aab4c428e93ea431eb8cec6c20aaade07354e1,openstack/manila,master,Ia5aab4c428e93ea431eb8cec6c20aaade07354e1,Enforce function declaration format in bash8,MERGED,2014-03-04 16:26:11.000000000,2014-03-07 15:56:51.000000000,2014-03-07 15:56:51.000000000,"[{'_account_id': 3}, {'_account_id': 6094}, {'_account_id': 7534}, {'_account_id': 8851}]","[{'number': 1, 'created': '2014-03-04 16:26:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/manila/commit/a8c7141d508b558d686bb8bbf9ca0521df4dbb07', 'message': 'Enforce function declaration format in bash8\n\nCheck that function calls look like ^function foo {$ in bash8\nSee commit: https://github.com/openstack-dev/devstack/commit/aee18c749b0e3a1a3a6907a33db76ae83b8d41d9\n\nChange-Id: Ia5aab4c428e93ea431eb8cec6c20aaade07354e1\n'}, {'number': 2, 'created': '2014-03-07 10:19:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/manila/commit/a4270a5960d117c88f76976224c01893bacf157c', 'message': 'Enforce function declaration format in bash8\n\nCheck that function calls look like ^function foo {$ in bash8\nSee commit: https://github.com/openstack-dev/devstack/commit/aee18c749b0e3a1a3a6907a33db76ae83b8d41d9\n\nChange-Id: Ia5aab4c428e93ea431eb8cec6c20aaade07354e1\n'}, {'number': 3, 'created': '2014-03-07 13:15:37.000000000', 'files': ['contrib/devstack/lib/manila'], 'web_link': 'https://opendev.org/openstack/manila/commit/6c5d38b3c7611b290aaf7db1b5d944e46de0f0bc', 'message': 'Enforce function declaration format in bash8\n\nCheck that function calls look like ^function foo {$ in bash8\nSee commit: https://github.com/openstack-dev/devstack/commit/aee18c749b0e3a1a3a6907a33db76ae83b8d41d9\n\nChange-Id: Ia5aab4c428e93ea431eb8cec6c20aaade07354e1\n'}]",0,77933,6c5d38b3c7611b290aaf7db1b5d944e46de0f0bc,27,4,3,8851,,,0,"Enforce function declaration format in bash8

Check that function calls look like ^function foo {$ in bash8
See commit: https://github.com/openstack-dev/devstack/commit/aee18c749b0e3a1a3a6907a33db76ae83b8d41d9

Change-Id: Ia5aab4c428e93ea431eb8cec6c20aaade07354e1
",git fetch https://review.opendev.org/openstack/manila refs/changes/33/77933/1 && git format-patch -1 --stdout FETCH_HEAD,['contrib/devstack/lib/manila'],1,a8c7141d508b558d686bb8bbf9ca0521df4dbb07,master,function _clean_share_group {function _clean_lvm_backing_file {function cleanup_manila {function configure_manila {function create_manila_accounts {function init_manila {function install_manila {function _configure_tgt_for_config_d {function start_manila {function stop_manila {,function _clean_share_group() {function _clean_lvm_backing_file() {function cleanup_manila() {function configure_manila() {function create_manila_accounts() {function init_manila() {function install_manila() {function _configure_tgt_for_config_d() {function start_manila() {function stop_manila() {,10,10
openstack%2Fnova~master~I085fddfbe5872c0b2b044106c0d2507fd4ee32d8,openstack/nova,master,I085fddfbe5872c0b2b044106c0d2507fd4ee32d8,Move _poll_volume_usage periodic task to BDM objects,MERGED,2014-02-04 19:04:03.000000000,2014-03-07 15:45:29.000000000,2014-03-06 17:36:51.000000000,"[{'_account_id': 3}, {'_account_id': 688}, {'_account_id': 1653}, {'_account_id': 2750}, {'_account_id': 4393}, {'_account_id': 4912}, {'_account_id': 5170}, {'_account_id': 5511}, {'_account_id': 7730}, {'_account_id': 8302}, {'_account_id': 9008}, {'_account_id': 9578}, {'_account_id': 9636}]","[{'number': 1, 'created': '2014-02-04 19:04:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/2e58d62b94dae0662493ffd23e41c8006c143f95', 'message': 'Move _poll_volume_usage periodic task to BDM objects\n\nThis patch makes the _poll_volume_usage compute service periodic task\nuse BDM objects internally. It also moves a single instance query to\nobjects as a side effect.\n\nPart of blueprint: icehouse-objects\n\nChange-Id: I085fddfbe5872c0b2b044106c0d2507fd4ee32d8\n'}, {'number': 2, 'created': '2014-02-06 10:22:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/f6d30b49428b0452745ceeca1f540dfcbac45b62', 'message': 'Move _poll_volume_usage periodic task to BDM objects\n\nThis patch makes the _poll_volume_usage compute service periodic task\nuse BDM objects internally. It also moves a single instance query to\nobjects as a side effect.\n\nPart of blueprint: icehouse-objects\n\nChange-Id: I085fddfbe5872c0b2b044106c0d2507fd4ee32d8\n'}, {'number': 3, 'created': '2014-02-06 18:13:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/b54c6589edffe66242b9f539f20ca65e505eea85', 'message': 'Move _poll_volume_usage periodic task to BDM objects\n\nThis patch makes the _poll_volume_usage compute service periodic task\nuse BDM objects internally. It also moves a single instance query to\nobjects as a side effect.\n\nPart of blueprint: icehouse-objects\n\nChange-Id: I085fddfbe5872c0b2b044106c0d2507fd4ee32d8\n'}, {'number': 4, 'created': '2014-02-10 13:12:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/5c96e85608098381181b3a6e867bc32fd457bd3f', 'message': 'Move _poll_volume_usage periodic task to BDM objects\n\nThis patch makes the _poll_volume_usage compute service periodic task\nuse BDM objects internally. It also moves a single instance query to\nobjects as a side effect.\n\nPart of blueprint: icehouse-objects\n\nChange-Id: I085fddfbe5872c0b2b044106c0d2507fd4ee32d8\n'}, {'number': 5, 'created': '2014-02-10 18:34:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/f42a86910e733447cbfe7afcb75fc259df9efea2', 'message': 'Move _poll_volume_usage periodic task to BDM objects\n\nThis patch makes the _poll_volume_usage compute service periodic task\nuse BDM objects internally. It also moves a single instance query to\nobjects as a side effect.\n\nPart of blueprint: icehouse-objects\n\nChange-Id: I085fddfbe5872c0b2b044106c0d2507fd4ee32d8\n'}, {'number': 6, 'created': '2014-02-10 21:07:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/8b6c526a7f3e18bf0145f9eec5e38623ac25ba22', 'message': 'Move _poll_volume_usage periodic task to BDM objects\n\nThis patch makes the _poll_volume_usage compute service periodic task\nuse BDM objects internally. It also moves a single instance query to\nobjects as a side effect.\n\nPart of blueprint: icehouse-objects\n\nChange-Id: I085fddfbe5872c0b2b044106c0d2507fd4ee32d8\n'}, {'number': 7, 'created': '2014-02-17 17:17:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/1654c93edf5cf60319f765cbca90479f6280c183', 'message': 'Move _poll_volume_usage periodic task to BDM objects\n\nThis patch makes the _poll_volume_usage compute service periodic task\nuse BDM objects internally. It also moves a single instance query to\nobjects as a side effect.\n\nPart of blueprint: icehouse-objects\n\nChange-Id: I085fddfbe5872c0b2b044106c0d2507fd4ee32d8\n'}, {'number': 8, 'created': '2014-02-20 09:17:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/f4685ec87b52c05879ecd13d438b0e2ad16f2496', 'message': 'Move _poll_volume_usage periodic task to BDM objects\n\nThis patch makes the _poll_volume_usage compute service periodic task\nuse BDM objects internally. It also moves a single instance query to\nobjects as a side effect.\n\nPart of blueprint: icehouse-objects\n\nChange-Id: I085fddfbe5872c0b2b044106c0d2507fd4ee32d8\n'}, {'number': 9, 'created': '2014-02-20 16:19:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/f454292ca70a756ff250b12bef6bcffcb7b833eb', 'message': 'Move _poll_volume_usage periodic task to BDM objects\n\nThis patch makes the _poll_volume_usage compute service periodic task\nuse BDM objects internally. It also moves a single instance query to\nobjects as a side effect.\n\nPart of blueprint: icehouse-objects\n\nChange-Id: I085fddfbe5872c0b2b044106c0d2507fd4ee32d8\n'}, {'number': 10, 'created': '2014-02-21 17:27:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/e2972bcb1289fd46046986ab50c3dc655c357ff9', 'message': 'Move _poll_volume_usage periodic task to BDM objects\n\nThis patch makes the _poll_volume_usage compute service periodic task\nuse BDM objects internally. It also moves a single instance query to\nobjects as a side effect. Also adds a missing test for the manager\nhelper method _get_host_volume_bdms.\n\nPart of blueprint: icehouse-objects\n\nChange-Id: I085fddfbe5872c0b2b044106c0d2507fd4ee32d8\n'}, {'number': 11, 'created': '2014-02-25 13:47:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/c34157d3e36476e9e337557bad07a1d02f3bb6be', 'message': 'Move _poll_volume_usage periodic task to BDM objects\n\nThis patch makes the _poll_volume_usage compute service periodic task\nuse BDM objects internally. It also moves a single instance query to\nobjects as a side effect. Also adds a missing test for the manager\nhelper method _get_host_volume_bdms.\n\nPart of blueprint: icehouse-objects\n\nChange-Id: I085fddfbe5872c0b2b044106c0d2507fd4ee32d8\n'}, {'number': 12, 'created': '2014-02-26 12:01:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/aefeb54403a0ad6de92a5c97de8b9dafeaeaf61d', 'message': 'Move _poll_volume_usage periodic task to BDM objects\n\nThis patch makes the _poll_volume_usage compute service periodic task\nuse BDM objects internally. It also moves a single instance query to\nobjects as a side effect. Also adds a missing test for the manager\nhelper method _get_host_volume_bdms.\n\nPart of blueprint: icehouse-objects\n\nChange-Id: I085fddfbe5872c0b2b044106c0d2507fd4ee32d8\n'}, {'number': 13, 'created': '2014-03-04 14:21:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/737d4a6373223b6405290d31f541c4f3b516e807', 'message': 'Move _poll_volume_usage periodic task to BDM objects\n\nThis patch makes the _poll_volume_usage compute service periodic task\nuse BDM objects internally. It also moves a single instance query to\nobjects as a side effect. Also adds a missing test for the manager\nhelper method _get_host_volume_bdms.\n\nPart of blueprint: icehouse-objects\n\nChange-Id: I085fddfbe5872c0b2b044106c0d2507fd4ee32d8\n'}, {'number': 14, 'created': '2014-03-05 11:06:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/8e69fe1abbd3b884d422bc8d00b37e9d96d41c94', 'message': 'Move _poll_volume_usage periodic task to BDM objects\n\nThis patch makes the _poll_volume_usage compute service periodic task\nuse BDM objects internally. It also moves a single instance query to\nobjects as a side effect. Also adds a missing test for the manager\nhelper method _get_host_volume_bdms.\n\nPart of blueprint: icehouse-objects\n\nChange-Id: I085fddfbe5872c0b2b044106c0d2507fd4ee32d8\n'}, {'number': 15, 'created': '2014-03-06 08:22:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/d153d2149677174479a4482bdf702f52e003a624', 'message': 'Move _poll_volume_usage periodic task to BDM objects\n\nThis patch makes the _poll_volume_usage compute service periodic task\nuse BDM objects internally. It also moves a single instance query to\nobjects as a side effect. Also adds a missing test for the manager\nhelper method _get_host_volume_bdms.\n\nPart of blueprint: icehouse-objects\n\nChange-Id: I085fddfbe5872c0b2b044106c0d2507fd4ee32d8\n'}, {'number': 16, 'created': '2014-03-06 11:18:08.000000000', 'files': ['nova/compute/manager.py', 'nova/tests/compute/test_compute.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/e832161fbeb77cb8d7dcf42f186ab4a458f5793e', 'message': 'Move _poll_volume_usage periodic task to BDM objects\n\nThis patch makes the _poll_volume_usage compute service periodic task\nuse BDM objects internally. It also moves a single instance query to\nobjects as a side effect. Also adds a missing test for the manager\nhelper method _get_host_volume_bdms.\n\nPart of blueprint: icehouse-objects\n\nChange-Id: I085fddfbe5872c0b2b044106c0d2507fd4ee32d8\n'}]",2,71066,e832161fbeb77cb8d7dcf42f186ab4a458f5793e,126,13,16,5511,,,0,"Move _poll_volume_usage periodic task to BDM objects

This patch makes the _poll_volume_usage compute service periodic task
use BDM objects internally. It also moves a single instance query to
objects as a side effect. Also adds a missing test for the manager
helper method _get_host_volume_bdms.

Part of blueprint: icehouse-objects

Change-Id: I085fddfbe5872c0b2b044106c0d2507fd4ee32d8
",git fetch https://review.opendev.org/openstack/nova refs/changes/66/71066/14 && git format-patch -1 --stdout FETCH_HEAD,['nova/compute/manager.py'],1,2e58d62b94dae0662493ffd23e41c8006c143f95,bdm_objects_compute," instances = instance_obj.InstanceList.get_by_host(context, self.host) for instance in instances: instance_bdms = [bdm for bdm in (block_device_obj.BlockDeviceMappingList. get_by_instance_uuid(context, instance.uuid)) if bdm.is_volume]"," instances = self.conductor_api.instance_get_all_by_host(context, self.host) for instance in instances: instance_bdms = self._get_instance_volume_bdms(context, instance)",5,3
openstack%2Ffuel-web~master~Ia9dd29edc2d9f1a63f2cb50d983d569addc3e95f,openstack/fuel-web,master,Ia9dd29edc2d9f1a63f2cb50d983d569addc3e95f,Fix for lost checked node style,MERGED,2014-03-07 15:13:34.000000000,2014-03-07 15:44:22.000000000,2014-03-07 15:44:21.000000000,"[{'_account_id': 3}, {'_account_id': 8735}, {'_account_id': 8766}, {'_account_id': 8970}, {'_account_id': 8971}]","[{'number': 1, 'created': '2014-03-07 15:13:34.000000000', 'files': ['nailgun/static/css/styles.less', 'nailgun/static/templates/cluster/node.html'], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/4a9e4032f19f9037b21f41107a44fd67cfec9112', 'message': 'Fix for lost checked node style\n\nChange-Id: Ia9dd29edc2d9f1a63f2cb50d983d569addc3e95f\n'}]",0,78983,4a9e4032f19f9037b21f41107a44fd67cfec9112,9,5,1,9091,,,0,"Fix for lost checked node style

Change-Id: Ia9dd29edc2d9f1a63f2cb50d983d569addc3e95f
",git fetch https://review.opendev.org/openstack/fuel-web refs/changes/83/78983/1 && git format-patch -1 --stdout FETCH_HEAD,"['nailgun/static/css/styles.less', 'nailgun/static/templates/cluster/node.html']",2,4a9e4032f19f9037b21f41107a44fd67cfec9112,fix_checked_node_style,"<div class=""node""> <label class=""node-container node-box""> <div class=""custom-tumbler node-checkbox""> <input type=""checkbox"" /> <!-- [if !IE |(gte IE 9)]> --><span>&nbsp;</span><!-- <![endif] --> </div> <div class=""node-content""> <div class=""node-logo <%- node.get('manufacturer') ? 'manufacturer-' + node.get('manufacturer').toLowerCase() : '' %>""></div> <div class=""node-name-roles""> <div class=""name enable-selection""> <% if (renaming) { %> <input type=""text"" value=""<%- node.get('name') || '' %>"" /> <% } else { %> <p class=""<%= renameable ? 'node-renameable' : '' %>"" title=""<%- renameable ? $.t('cluster_page.nodes_tab.node.edit_name') : '' %>""><%- node.get('name') || node.get('mac') %></p> <% } %> </div> <div class=""role-list""></div> <div class=""node-button""> <button class="""" title=""""><i class=""""></i></button> </div> <div class=""node-status""> <div class=""node-status-container""> <div class=""progress""><div class=""bar""></div></div> <i></i> <span class=""node-status-label""></span> </div> </div> <div class=""node-details""></div> <div class=""node-hardware""> <span><%- $.t('node_details.cpu') %>: <%= node.resource('cores') || '?' %></span> <span><%- $.t('node_details.hdd') %>: <%= node.resource('hdd') ? showDiskSize(node.resource('hdd')) : '?' + $.t('common.size.gb') %></span> <span><%- $.t('node_details.ram') %>: <%= node.resource('ram') ? showMemorySize(node.resource('ram')) : '?' + $.t('common.size.gb') %></span> </label> </div>","<label class=""node-container node-box""> <div class=""custom-tumbler node-checkbox""> <input type=""checkbox"" /> <!-- [if !IE |(gte IE 9)]> --><span>&nbsp;</span><!-- <![endif] --> </div> <div class=""node-content""> <div class=""node-logo <%- node.get('manufacturer') ? 'manufacturer-' + node.get('manufacturer').toLowerCase() : '' %>""></div> <div class=""node-name-roles""> <div class=""name enable-selection""> <% if (renaming) { %> <input type=""text"" value=""<%- node.get('name') || '' %>"" /> <% } else { %> <p class=""<%= renameable ? 'node-renameable' : '' %>"" title=""<%- renameable ? $.t('cluster_page.nodes_tab.node.edit_name') : '' %>""><%- node.get('name') || node.get('mac') %></p> <% } %> <div class=""role-list""></div> </div> <div class=""node-button""> <button class="""" title=""""><i class=""""></i></button> </div> <div class=""node-status""> <div class=""node-status-container""> <div class=""progress""><div class=""bar""></div></div> <i></i> <span class=""node-status-label""></span> <div class=""node-details""></div> <div class=""node-hardware""> <span><%- $.t('node_details.cpu') %>: <%= node.resource('cores') || '?' %></span> <span><%- $.t('node_details.hdd') %>: <%= node.resource('hdd') ? showDiskSize(node.resource('hdd')) : '?' + $.t('common.size.gb') %></span> <span><%- $.t('node_details.ram') %>: <%= node.resource('ram') ? showMemorySize(node.resource('ram')) : '?' + $.t('common.size.gb') %></span> </div> </div> </label> ",35,32
openstack%2Fsolum~master~Ic5396890bb2269fb3206fe392aa73d9316676c9f,openstack/solum,master,Ic5396890bb2269fb3206fe392aa73d9316676c9f,make buildpacks only when needed,MERGED,2014-02-17 07:26:07.000000000,2014-03-07 15:38:51.000000000,2014-03-07 15:38:50.000000000,"[{'_account_id': 3}, {'_account_id': 668}, {'_account_id': 2506}, {'_account_id': 4715}, {'_account_id': 7858}, {'_account_id': 8334}, {'_account_id': 8443}, {'_account_id': 9094}, {'_account_id': 9095}, {'_account_id': 9537}, {'_account_id': 9548}, {'_account_id': 9808}]","[{'number': 1, 'created': '2014-02-17 07:26:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/solum/commit/6674a1bc98addbd5bdd900e7ec3f6777190d5c6c', 'message': 'make buildpacks only when needed\n\nChange-Id: Ic5396890bb2269fb3206fe392aa73d9316676c9f\n'}, {'number': 2, 'created': '2014-02-17 09:15:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/solum/commit/6a3c7bd1159d9aaf86d49d24434b9e94307ac811', 'message': 'make buildpacks only when needed\n\nChange-Id: Ic5396890bb2269fb3206fe392aa73d9316676c9f\n'}, {'number': 3, 'created': '2014-02-17 10:19:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/solum/commit/33cac192bc64773c77c0656234d040c9fdcf548c', 'message': 'make buildpacks only when needed\n\nChange-Id: Ic5396890bb2269fb3206fe392aa73d9316676c9f\n'}, {'number': 4, 'created': '2014-02-17 11:20:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/solum/commit/5620d7f9a139e1011c0778ff890213acf2ca249d', 'message': 'make buildpacks only when needed\n\nChange-Id: Ic5396890bb2269fb3206fe392aa73d9316676c9f\n'}, {'number': 5, 'created': '2014-02-18 00:31:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/solum/commit/c781f9cf8e960bcb212a8c9e7e858ad440b69e1e', 'message': 'make buildpacks only when needed\n\nChange-Id: Ic5396890bb2269fb3206fe392aa73d9316676c9f\n'}, {'number': 6, 'created': '2014-02-18 00:36:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/solum/commit/509c5a95bafd85c85e2bf4a74bc48896733e8827', 'message': 'make buildpacks only when needed\n\nChange-Id: Ic5396890bb2269fb3206fe392aa73d9316676c9f\n'}, {'number': 7, 'created': '2014-02-18 06:50:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/solum/commit/5286950b1fc9ad37508b33440e7cc610d2694e8b', 'message': 'make buildpacks only when needed\n\nChange-Id: Ic5396890bb2269fb3206fe392aa73d9316676c9f\n'}, {'number': 8, 'created': '2014-02-18 11:49:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/solum/commit/890c866c7932f1a75766aec0cac5fddc7ba7dc3d', 'message': 'make buildpacks only when needed\n\nChange-Id: Ic5396890bb2269fb3206fe392aa73d9316676c9f\n'}, {'number': 9, 'created': '2014-02-20 08:54:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/solum/commit/5dadb8c89e2b27d8894f18cc639054bc013ef75d', 'message': 'make buildpacks only when needed\n\nThis patch just does not re-clone the buildpacks\nwhen the script is running multiple times.\n\nChange-Id: Ic5396890bb2269fb3206fe392aa73d9316676c9f\n'}, {'number': 10, 'created': '2014-02-27 22:04:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/solum/commit/0d5c37098b54e46c5ebb39f9bae32c3662010725', 'message': 'make buildpacks only when needed\n\nThis patch just does not re-clone the buildpacks\nwhen the script is running multiple times.\n\nChange-Id: Ic5396890bb2269fb3206fe392aa73d9316676c9f\n'}, {'number': 11, 'created': '2014-02-27 23:49:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/solum/commit/5206904adcef3ad49778d0093e4b79f87dfb60bd', 'message': 'make buildpacks only when needed\n\nThis patch just does not re-clone the buildpacks\nwhen the script is running multiple times.\n\nChange-Id: Ic5396890bb2269fb3206fe392aa73d9316676c9f\n'}, {'number': 12, 'created': '2014-02-28 01:48:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/solum/commit/e03ce124e2629fb0d055243970bfdd52648b6450', 'message': 'make buildpacks only when needed\n\nThis patch just does not re-clone the buildpacks\nwhen the script is running multiple times.\n\nChange-Id: Ic5396890bb2269fb3206fe392aa73d9316676c9f\n'}, {'number': 13, 'created': '2014-02-28 07:30:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/solum/commit/958224961052348b4ab045e719ff14035f4af7a1', 'message': 'make buildpacks only when needed\n\nThis patch just does not re-clone the buildpacks\nwhen the script is running multiple times.\n\nChange-Id: Ic5396890bb2269fb3206fe392aa73d9316676c9f\n'}, {'number': 14, 'created': '2014-03-03 00:45:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/solum/commit/b4e357eeb733342062120e4d925380f41d08638e', 'message': 'make buildpacks only when needed\n\nThis patch just does not re-clone the buildpacks\nwhen the script is running multiple times.\n\nChange-Id: Ic5396890bb2269fb3206fe392aa73d9316676c9f\n'}, {'number': 15, 'created': '2014-03-04 07:07:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/solum/commit/1e46c02932f377ec9eb95980bda6ddbafbfb12eb', 'message': 'make buildpacks only when needed\n\nThis patch just does not re-clone the buildpacks\nwhen the script is running multiple times.\n\nChange-Id: Ic5396890bb2269fb3206fe392aa73d9316676c9f\n'}, {'number': 16, 'created': '2014-03-04 12:03:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/solum/commit/a0dff6b3a462fb92bd708cd0548d8d66df1789b4', 'message': 'make buildpacks only when needed\n\nThis patch just does not re-clone the buildpacks\nwhen the script is running multiple times.\n\nChange-Id: Ic5396890bb2269fb3206fe392aa73d9316676c9f\n'}, {'number': 17, 'created': '2014-03-04 12:06:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/solum/commit/1344546234487a69ae592859284d01ac2115556b', 'message': 'make buildpacks only when needed\n\nThis patch just does not re-clone the buildpacks\nwhen the script is running multiple times.\n\nChange-Id: Ic5396890bb2269fb3206fe392aa73d9316676c9f\n'}, {'number': 18, 'created': '2014-03-07 07:19:05.000000000', 'files': ['contrib/lp-cedarish/docker/prepare'], 'web_link': 'https://opendev.org/openstack/solum/commit/bfd107725f4d2ec395b93816c1007af7811e77bc', 'message': 'make buildpacks only when needed\n\nThis patch just does not re-clone the buildpacks\nwhen the script is running multiple times.\n\nChange-Id: Ic5396890bb2269fb3206fe392aa73d9316676c9f\n'}]",7,73950,bfd107725f4d2ec395b93816c1007af7811e77bc,139,12,18,4715,,,0,"make buildpacks only when needed

This patch just does not re-clone the buildpacks
when the script is running multiple times.

Change-Id: Ic5396890bb2269fb3206fe392aa73d9316676c9f
",git fetch https://review.opendev.org/openstack/solum refs/changes/50/73950/16 && git format-patch -1 --stdout FETCH_HEAD,"['contrib/lp-cedarish/docker/prepare', 'contrib/lp-cedarish/docker/build-app']",2,6674a1bc98addbd5bdd900e7ec3f6777190d5c6c,buildscripts,, ,4,5
openstack%2Fpython-novaclient~master~I8e20f54cf592c4e52a2571538c0ef36bceba44a6,openstack/python-novaclient,master,I8e20f54cf592c4e52a2571538c0ef36bceba44a6,fix for bug:1288397 (nova boot fails when glance image nameless),ABANDONED,2014-03-05 20:05:27.000000000,2014-03-07 15:26:26.000000000,,"[{'_account_id': 3}, {'_account_id': 2506}, {'_account_id': 9275}]","[{'number': 1, 'created': '2014-03-05 20:05:27.000000000', 'files': ['novaclient/openstack/common/apiclient/base.py'], 'web_link': 'https://opendev.org/openstack/python-novaclient/commit/5415b60e5c7f90c79ead1eedfe1096d5c34e1679', 'message': 'fix for bug:1288397 (nova boot fails when glance image nameless)\n\ntested in devstack to fix the linked bug.\n\nhttps://bugs.launchpad.net/python-novaclient/+bug/1288397\n\nChange-Id: I8e20f54cf592c4e52a2571538c0ef36bceba44a6\n'}]",1,78398,5415b60e5c7f90c79ead1eedfe1096d5c34e1679,5,3,1,7858,,,0,"fix for bug:1288397 (nova boot fails when glance image nameless)

tested in devstack to fix the linked bug.

https://bugs.launchpad.net/python-novaclient/+bug/1288397

Change-Id: I8e20f54cf592c4e52a2571538c0ef36bceba44a6
",git fetch https://review.opendev.org/openstack/python-novaclient refs/changes/98/78398/1 && git format-patch -1 --stdout FETCH_HEAD,['novaclient/openstack/common/apiclient/base.py'],1,5415b60e5c7f90c79ead1eedfe1096d5c34e1679,bug/1288397," name = getattr(self, self.NAME_ATTR) if name is not None: return strutils.to_slug(name)"," return strutils.to_slug(getattr(self, self.NAME_ATTR))",3,1
openstack%2Fcinder~master~I8361d0dc0d43040e48634ff1aee1324e5e0af466,openstack/cinder,master,I8361d0dc0d43040e48634ff1aee1324e5e0af466,Enable multi-process for API service,MERGED,2014-01-16 08:02:18.000000000,2014-03-07 15:23:03.000000000,2014-01-25 14:23:22.000000000,"[{'_account_id': 3}, {'_account_id': 2243}, {'_account_id': 2759}, {'_account_id': 4355}, {'_account_id': 4428}, {'_account_id': 7198}]","[{'number': 1, 'created': '2014-01-16 08:02:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/d88554bbd737c284f3bbaaea382cd79c2599ad27', 'message': ""Enable multi-process for API service\n\nDue to the limit of Python interpreter, API service of Cinder can't\nreally utilize underlying multi-core architecture even libraries\nlike eventlet has been used. To make API service much more scalable,\nwe'd adopt multi-process (worker) mode that has been used for long\nin Glance/Swift/Nova.\n\nImplement: multi-process-api-service\n\nDocImpact\n\nChange-Id: I8361d0dc0d43040e48634ff1aee1324e5e0af466\n""}, {'number': 2, 'created': '2014-01-16 14:20:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/1b6c9d97e0231bdd3c901f2ad0d3b806189d5a0f', 'message': ""Enable multi-process for API service\n\nDue to the limit of Python interpreter, API service of Cinder can't\nreally utilize underlying multi-core architecture even libraries\nlike eventlet has been used. To make API service much more scalable,\nwe'd adopt multi-process (worker) mode that has been used for long\nin Glance/Swift/Nova.\n\nImplementation wise, a good portion of cinder/service.py has been\nremoved because those content has been merged in Oslo version of\nservice module.  cinder/wsgi.py is also updated to adopt the change\nfor multiple WSGI servers running in separate processes.\n\nImplement: multi-process-api-service\n\nDocImpact\n\nChange-Id: I8361d0dc0d43040e48634ff1aee1324e5e0af466\n""}, {'number': 3, 'created': '2014-01-16 14:38:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/3c3713855304a96ce26a863f485884fe59931a9a', 'message': ""Enable multi-process for API service\n\nDue to the limit of Python interpreter, API service of Cinder can't\nreally utilize underlying multi-core architecture even libraries\nlike eventlet has been used. To make API service much more scalable,\nwe'd adopt multi-process (worker) mode that has been used for long\nin Glance/Swift/Nova.\n\nImplementation wise, a good portion of cinder/service.py has been\nremoved because those content has been merged in Oslo version of\nservice module.  cinder/wsgi.py is also updated to adopt the change\nfor multiple WSGI servers running in separate processes.\n\nImplement: multi-process-api-service\n\nDocImpact: 'New config option osapi_volume_workers is used to specify\nnumber of API service workers (OS processes) to launch for Cinder\nAPI service.  Increasing this config option to a proper value (e.g.\nosapi_volume_workers = # of CPU cores/threads) can greatly improve\nthe total throughput of API service.  The defalut value for this\noption is None, which keeps the same behavior as usual (only one\nprocess).'\n\nChange-Id: I8361d0dc0d43040e48634ff1aee1324e5e0af466\n""}, {'number': 4, 'created': '2014-01-16 14:40:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/064a1b9080a2144a93bc625841165c75103d4747', 'message': ""Enable multi-process for API service\n\nDue to the limit of Python interpreter, API service of Cinder can't\nreally utilize underlying multi-core architecture even libraries\nlike eventlet has been used. To make API service much more scalable,\nwe'd adopt multi-process (worker) mode that has been used for long\nin Glance/Swift/Nova.\n\nImplementation wise, a good portion of cinder/service.py has been\nremoved because those content has been merged in Oslo version of\nservice module.  cinder/wsgi.py is also updated to adopt the change\nfor multiple WSGI servers running in separate processes.\n\nImplement bp: multi-process-api-service\n\nDocImpact: 'New config option osapi_volume_workers is used to specify\nnumber of API service workers (OS processes) to launch for Cinder\nAPI service.  Increasing this config option to a proper value (e.g.\nosapi_volume_workers = # of CPU cores/threads) can greatly improve\nthe total throughput of API service.  The defalut value for this\noption is None, which keeps the same behavior as usual (only one\nprocess).'\n\nChange-Id: I8361d0dc0d43040e48634ff1aee1324e5e0af466\n""}, {'number': 5, 'created': '2014-01-16 14:47:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/bccf32e75f224310de99d5629c77d53f3884d3d4', 'message': ""Enable multi-process for API service\n\nDue to the limit of Python interpreter, API service of Cinder can't\nreally utilize underlying multi-core architecture even libraries\nlike eventlet has been used. To make API service much more scalable,\nwe'd adopt multi-process (worker) mode that has been used for long\nin Glance/Swift/Nova.\n\nThe defalut behavior isn't changed with this patch, Cinder API\nservice with still run in one process (default value of\nosapi_volume_workers is None).\n\nImplementation wise, a good portion of cinder/service.py has been\nremoved because those content has been merged in Oslo version of\nservice module.  cinder/wsgi.py is also updated to adopt the change\nfor multiple WSGI servers running in separate processes.\n\nImplement bp: multi-process-api-service\n\nDocImpact: 'New config option osapi_volume_workers is used to specify\nnumber of API service workers (OS processes) to launch for Cinder\nAPI service.  Setting this config option to a proper value (e.g.\nosapi_volume_workers = # of CPU cores/threads of the machine) can\ngreatly improve the total throughput of API service [# of API\nrequests can be handled per second].'\n\nChange-Id: I8361d0dc0d43040e48634ff1aee1324e5e0af466\n""}, {'number': 6, 'created': '2014-01-17 08:21:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/26bc471182124ff1c16b9cab316c5343a344a6f4', 'message': ""Enable multi-process for API service\n\nDue to the limit of Python interpreter, API service of Cinder can't\nreally utilize underlying multi-core architecture even libraries\nlike eventlet has been used. To make API service much more scalable,\nwe'd adopt multi-process (worker) mode that has been used for long\nin Glance/Swift/Nova.\n\nThe defalut behavior isn't changed with this patch, Cinder API\nservice with still run in one process (default value of\nosapi_volume_workers is None).\n\nImplementation wise, a good portion of cinder/service.py has been\nremoved because those content has been merged in Oslo version of\nservice module.  cinder/wsgi.py is also updated to adopt the change\nfor multiple WSGI servers running in separate processes.\n\nImplement bp: multi-process-api-service\n\nDocImpact: 'New config option osapi_volume_workers is used to specify\nnumber of API service workers (OS processes) to launch for Cinder\nAPI service.  Setting this config option to a proper value (e.g.\nosapi_volume_workers = # of CPU cores/threads of the machine) can\ngreatly improve the total throughput of API service [# of API\nrequests can be handled per second].'\n\nChange-Id: I8361d0dc0d43040e48634ff1aee1324e5e0af466\n""}, {'number': 7, 'created': '2014-01-17 08:27:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/3224eb18ea7d1125086e4b1e17fc5584de23d89d', 'message': ""Enable multi-process for API service\n\nDue to the limit of Python interpreter, API service of Cinder can't\nreally utilize underlying multi-core architecture even libraries\nlike eventlet has been used. To make API service much more scalable,\nwe'd adopt multi-process (worker) mode that has been used for long\nin Glance/Swift/Nova.\n\nThe defalut behavior isn't changed with this patch, Cinder API\nservice with still run in one process (default value of\nosapi_volume_workers is None).\n\nImplementation wise, a good portion of cinder/service.py has been\nremoved because those content has been merged in Oslo version of\nservice module.  cinder/wsgi.py is also updated to adopt the change\nfor multiple WSGI servers running in separate processes.\n\nImplement bp: multi-process-api-service\n\nDocImpact: 'New config option osapi_volume_workers is used to specify\nnumber of API service workers (OS processes) to launch for Cinder\nAPI service.  Setting this config option to a proper value (e.g.\nosapi_volume_workers = # of CPU cores/threads of the machine) can\ngreatly improve the total throughput of API service [# of API\nrequests can be handled per second].'\n\nAlso removed out-dated comments in bin/cinder-api due to the fact\nthat this bug [1] has been fixed in eventlet 0.9.13\n\n[1] https://bitbucket.org/eventlet/eventlet/issue/92/eventletgreen-override-of-oswaitpid\n\nChange-Id: I8361d0dc0d43040e48634ff1aee1324e5e0af466\n""}, {'number': 8, 'created': '2014-01-17 17:32:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/f7a1373e1d77003856873da86939d2db61f68a32', 'message': ""Enable multi-process for API service\n\nDue to the limit of Python interpreter, API service of Cinder can't\nreally utilize underlying multi-core architecture even libraries\nlike eventlet has been used. To make API service much more scalable,\nwe'd adopt multi-process (worker) mode that has been used for long\nin Glance/Swift/Nova.\n\nThe defalut behavior isn't changed with this patch, Cinder API\nservice with still run in one process (default value of\nosapi_volume_workers is None).\n\nImplementation wise, a good portion of cinder/service.py has been\nremoved because those content has been merged in Oslo version of\nservice module.  cinder/wsgi.py is also updated to adopt the change\nfor multiple WSGI servers running in separate processes.\n\nImplement bp: multi-process-api-service\n\nDocImpact: 'New config option osapi_volume_workers is used to specify\nnumber of API service workers (OS processes) to launch for Cinder\nAPI service.  Setting this config option to a proper value (e.g.\nosapi_volume_workers = # of CPU cores/threads of the machine) can\ngreatly improve the total throughput of API service [# of API\nrequests can be handled per second].'\n\nAlso removed out-dated comments in bin/cinder-api due to the fact\nthat this bug [1] has been fixed in eventlet 0.9.13\n\n[1] https://bitbucket.org/eventlet/eventlet/issue/92/eventletgreen-override-of-oswaitpid\n\nChange-Id: I8361d0dc0d43040e48634ff1aee1324e5e0af466\n""}, {'number': 9, 'created': '2014-01-17 17:58:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/07860e30a799a9d6696c029b0a3ed0af11e42975', 'message': ""Enable multi-process for API service\n\nDue to the limit of Python interpreter, API service of Cinder can't\nreally utilize underlying multi-core architecture even libraries\nlike eventlet has been used. To make API service much more scalable,\nwe'd adopt multi-process (worker) mode that has been used for long\nin Glance/Swift/Nova.\n\nThe defalut behavior isn't changed with this patch, Cinder API\nservice with still run in one process (default value of\nosapi_volume_workers is None).\n\nImplementation wise, a good portion of cinder/service.py has been\nremoved because those content has been merged in Oslo version of\nservice module.  cinder/wsgi.py is also updated to adopt the change\nfor multiple WSGI servers running in separate processes.\n\nImplement bp: multi-process-api-service\n\nDocImpact: 'New config option osapi_volume_workers is used to specify\nnumber of API service workers (OS processes) to launch for Cinder\nAPI service.  Setting this config option to a proper value (e.g.\nosapi_volume_workers = # of CPU cores/threads of the machine) can\ngreatly improve the total throughput of API service [# of API\nrequests can be handled per second].'\n\nAlso removed out-dated comments in bin/cinder-api due to the fact\nthat this bug [1] has been fixed in eventlet 0.9.13\n\n[1] https://bitbucket.org/eventlet/eventlet/issue/92/eventletgreen-override-of-oswaitpid\n\nChange-Id: I8361d0dc0d43040e48634ff1aee1324e5e0af466\n""}, {'number': 10, 'created': '2014-01-23 07:42:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/9d487af025a638341354ece63baa4b69bf3c6f2d', 'message': ""Enable multi-process for API service\n\nDue to the limit of Python interpreter, API service of Cinder can't\nreally utilize underlying multi-core architecture even libraries\nlike eventlet has been used. To make API service much more scalable,\nwe'd adopt multi-process (worker) mode that has been used for long\nin Glance/Swift/Nova.\n\nThe defalut behavior isn't changed with this patch, Cinder API\nservice with still run in one process (default value of\nosapi_volume_workers is None).\n\nImplementation wise, a good portion of cinder/service.py has been\nremoved because those content has been merged in Oslo version of\nservice module.  cinder/wsgi.py is also updated to adopt the change\nfor multiple WSGI servers running in separate processes.\n\nImplement bp: multi-process-api-service\n\nDocImpact: 'New config option osapi_volume_workers is used to specify\nnumber of API service workers (OS processes) to launch for Cinder\nAPI service.  Setting this config option to a proper value (e.g.\nosapi_volume_workers = # of CPU cores/threads of the machine) can\ngreatly improve the total throughput of API service [# of API\nrequests can be handled per second].'\n\nAlso removed out-dated comments in bin/cinder-api due to the fact\nthat this bug [1] has been fixed in eventlet 0.9.13\n\n[1] https://bitbucket.org/eventlet/eventlet/issue/92/eventletgreen-override-of-oswaitpid\n\nChange-Id: I8361d0dc0d43040e48634ff1aee1324e5e0af466\n""}, {'number': 11, 'created': '2014-01-23 21:43:40.000000000', 'files': ['bin/cinder-all', 'cinder/service.py', 'etc/cinder/cinder.conf.sample', 'cinder/wsgi.py', 'bin/cinder-volume', 'bin/cinder-backup', 'cinder/tests/test_service.py', 'bin/cinder-api'], 'web_link': 'https://opendev.org/openstack/cinder/commit/4576ca73eae6e2ec554b4e6785b9fd7ef310ac91', 'message': ""Enable multi-process for API service\n\nDue to the limit of Python interpreter, API service of Cinder can't\nreally utilize underlying multi-core architecture even libraries\nlike eventlet has been used. To make API service much more scalable,\nwe'd adopt multi-process (worker) mode that has been used for long\nin Glance/Swift/Nova.\n\nThe default behavior isn't changed with this patch, Cinder API\nservice will still run in one process (default value of\nosapi_volume_workers is None).\n\nImplementation wise, a good portion of cinder/service.py has been\nremoved because those content has been merged in Oslo version of\nservice module.  cinder/wsgi.py is also updated to adopt the change\nfor multiple WSGI servers running in separate processes.\n\nImplement bp: multi-process-api-service\n\nDocImpact: 'New config option osapi_volume_workers is used to specify\nnumber of API service workers (OS processes) to launch for Cinder\nAPI service.  Setting this config option to a proper value (e.g.\nosapi_volume_workers = # of CPU cores/threads of the machine) can\ngreatly improve the total throughput of API service [# of API\nrequests can be handled per second].'\n\nAlso removed out-dated comments in bin/cinder-api due to the fact\nthat this bug [1] has been fixed in eventlet 0.9.13\n\n[1] https://bitbucket.org/eventlet/eventlet/issue/92/eventletgreen-override-of-oswaitpid\n\nChange-Id: I8361d0dc0d43040e48634ff1aee1324e5e0af466\n""}]",12,67031,4576ca73eae6e2ec554b4e6785b9fd7ef310ac91,46,6,11,2759,,,0,"Enable multi-process for API service

Due to the limit of Python interpreter, API service of Cinder can't
really utilize underlying multi-core architecture even libraries
like eventlet has been used. To make API service much more scalable,
we'd adopt multi-process (worker) mode that has been used for long
in Glance/Swift/Nova.

The default behavior isn't changed with this patch, Cinder API
service will still run in one process (default value of
osapi_volume_workers is None).

Implementation wise, a good portion of cinder/service.py has been
removed because those content has been merged in Oslo version of
service module.  cinder/wsgi.py is also updated to adopt the change
for multiple WSGI servers running in separate processes.

Implement bp: multi-process-api-service

DocImpact: 'New config option osapi_volume_workers is used to specify
number of API service workers (OS processes) to launch for Cinder
API service.  Setting this config option to a proper value (e.g.
osapi_volume_workers = # of CPU cores/threads of the machine) can
greatly improve the total throughput of API service [# of API
requests can be handled per second].'

Also removed out-dated comments in bin/cinder-api due to the fact
that this bug [1] has been fixed in eventlet 0.9.13

[1] https://bitbucket.org/eventlet/eventlet/issue/92/eventletgreen-override-of-oswaitpid

Change-Id: I8361d0dc0d43040e48634ff1aee1324e5e0af466
",git fetch https://review.opendev.org/openstack/cinder refs/changes/31/67031/11 && git format-patch -1 --stdout FETCH_HEAD,"['bin/cinder-all', 'cinder/service.py', 'cinder/tests/test_service.py', 'bin/cinder-api']",4,d88554bbd737c284f3bbaaea382cd79c2599ad27,bp/multi-process-api-service," launcher = service.process_launcher() launcher.launch_service(server, workers=server.workers or 1) launcher.wait()", service.serve(server) service.wait(),26,291
openstack%2Fneutron~master~Ie4a57a15ec6ea58a594399b7628ea6a3624f694a,openstack/neutron,master,Ie4a57a15ec6ea58a594399b7628ea6a3624f694a,Implement MidoNet plugin for Icehouse,ABANDONED,2014-02-17 23:26:55.000000000,2014-03-07 15:15:35.000000000,,"[{'_account_id': 3}, {'_account_id': 156}, {'_account_id': 748}, {'_account_id': 841}, {'_account_id': 2592}, {'_account_id': 7962}, {'_account_id': 9008}, {'_account_id': 9681}, {'_account_id': 9732}, {'_account_id': 9845}, {'_account_id': 9925}, {'_account_id': 10116}, {'_account_id': 10117}, {'_account_id': 10119}, {'_account_id': 10153}, {'_account_id': 10184}, {'_account_id': 10192}, {'_account_id': 10294}]","[{'number': 1, 'created': '2014-02-17 23:26:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/8ed5e2885fa020b21848d38ce182b8d7a1f5ce65', 'message': 'Implement MidoNet plugin for Icehouse\n\nUpdate the plugin to reflect the newest MidoNet API that mostly\nmirrors the Neutron API.  Most of the Neutron API can now be\nsimply passed through to MidoNet, making the plugin easier to\nmaintain, and it provides better data synchronization since\nmost of MidoNet API operations are atomic.\n\nAlso included in this patch are support for FWaaS and LBaaS and\nvarious core extensions that were not supported in Havana.\n\nChange-Id: Ie4a57a15ec6ea58a594399b7628ea6a3624f694a\nImplements: blueprint midonet-plugin\n'}, {'number': 2, 'created': '2014-02-18 13:19:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/e19ede1fd74f933b87b077f8839373dc187d7076', 'message': 'Implement MidoNet plugin for Icehouse\n\nUpdate the plugin to reflect the newest MidoNet API that mostly\nmirrors the Neutron API.  Most of the Neutron API can now be\nsimply passed through to MidoNet, making the plugin easier to\nmaintain, and it provides better data synchronization since\nmost of MidoNet API operations are atomic.\n\nAlso included in this patch are support for FWaaS and LBaaS and\nvarious core extensions that were not supported in Havana.\n\nChange-Id: Ie4a57a15ec6ea58a594399b7628ea6a3624f694a\nImplements: blueprint midonet-plugin\n'}, {'number': 3, 'created': '2014-02-18 15:24:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/f67055c29e2a82269f6ddfc138f64448e03c83c6', 'message': 'Implement MidoNet plugin for Icehouse\n\nUpdate the plugin to reflect the newest MidoNet API that mostly\nmirrors the Neutron API.  Most of the Neutron API can now be\nsimply passed through to MidoNet, making the plugin easier to\nmaintain, and it provides better data synchronization since\nmost of MidoNet API operations are atomic.\n\nAlso included in this patch are support for FWaaS and LBaaS and\nvarious core extensions that were not supported in Havana.\n\nChange-Id: Ie4a57a15ec6ea58a594399b7628ea6a3624f694a\nImplements: blueprint midonet-plugin\n'}, {'number': 4, 'created': '2014-02-25 19:30:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/2bb7ceb279606309e5eb590563508139ed8edd2b', 'message': 'Implement MidoNet plugin for Icehouse\n\nUpdate the plugin to reflect the newest MidoNet API that mostly\nmirrors the Neutron API.  Most of the Neutron API can now be\nsimply passed through to MidoNet, making the plugin easier to\nmaintain, and it provides better data synchronization since\nmost of MidoNet API operations are atomic.\n\nAlso included in this patch are support for FWaaS and LBaaS and\nvarious core extensions that were not supported in Havana.\n\nChange-Id: Ie4a57a15ec6ea58a594399b7628ea6a3624f694a\nImplements: blueprint midonet-plugin\n'}, {'number': 5, 'created': '2014-02-25 20:08:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/9f821e9ff2aabfd4418118982f2c2c04ea1418e7', 'message': 'Implement MidoNet plugin for Icehouse\n\nUpdate the plugin to reflect the newest MidoNet API that mostly\nmirrors the Neutron API.  Most of the Neutron API can now be\nsimply passed through to MidoNet, making the plugin easier to\nmaintain, and it provides better data synchronization since\nmost of MidoNet API operations are atomic.\n\nAlso included in this patch are support for FWaaS and LBaaS and\nvarious core extensions that were not supported in Havana.\n\nChange-Id: Ie4a57a15ec6ea58a594399b7628ea6a3624f694a\nImplements: blueprint midonet-plugin\n'}, {'number': 6, 'created': '2014-02-26 04:26:52.000000000', 'files': ['neutron/db/migration/alembic_migrations/versions/1428abfbe9e3_midonet_icehouse.py', 'neutron/plugins/midonet/plugin.py', 'neutron/plugins/midonet/common/net_util.py', 'neutron/tests/unit/midonet/test_midonet_lib.py', 'neutron/plugins/midonet/midonet_lib.py', 'neutron/plugins/midonet/common/config.py', 'neutron/tests/unit/midonet/mock_lib.py', 'neutron/tests/unit/midonet/test_midonet_plugin.py', 'neutron/tests/unit/midonet/etc/midonet.ini.test'], 'web_link': 'https://opendev.org/openstack/neutron/commit/553e9422540b7b42c171cfcd5c864281578397c4', 'message': 'Implement MidoNet plugin for Icehouse\n\nUpdate the plugin to reflect the newest MidoNet API that mostly\nmirrors the Neutron API.  Most of the Neutron API can now be\nsimply passed through to MidoNet, making the plugin easier to\nmaintain, and it provides better data synchronization since\nmost of MidoNet API operations are atomic.\n\nAlso included in this patch are support for FWaaS and LBaaS and\nvarious core extensions that were not supported in Havana.\n\nChange-Id: Ie4a57a15ec6ea58a594399b7628ea6a3624f694a\nImplements: blueprint midonet-plugin\n'}]",35,74193,553e9422540b7b42c171cfcd5c864281578397c4,84,18,6,156,,,0,"Implement MidoNet plugin for Icehouse

Update the plugin to reflect the newest MidoNet API that mostly
mirrors the Neutron API.  Most of the Neutron API can now be
simply passed through to MidoNet, making the plugin easier to
maintain, and it provides better data synchronization since
most of MidoNet API operations are atomic.

Also included in this patch are support for FWaaS and LBaaS and
various core extensions that were not supported in Havana.

Change-Id: Ie4a57a15ec6ea58a594399b7628ea6a3624f694a
Implements: blueprint midonet-plugin
",git fetch https://review.opendev.org/openstack/neutron refs/changes/93/74193/1 && git format-patch -1 --stdout FETCH_HEAD,"['neutron/db/migration/alembic_migrations/versions/53bbd27ec841_extra_dhcp_opts_supp.py', 'neutron/db/migration/alembic_migrations/versions/176a85fc7d79_add_portbindings_db.py', 'neutron/db/migration/alembic_migrations/versions/4692d074d587_agent_scheduler.py', 'neutron/db/migration/alembic_migrations/versions/128e042a2b68_ext_gw_mode.py', 'neutron/db/migration/alembic_migrations/versions/1efb85914233_allowedaddresspairs.py', 'neutron/db/migration/alembic_migrations/versions/511471cc46b_agent_ext_model_supp.py', 'neutron/plugins/midonet/common/net_util.py', 'neutron/db/migration/alembic_migrations/versions/folsom_initial.py', 'neutron/tests/unit/midonet/test_midonet_lib.py', 'neutron/db/migration/alembic_migrations/versions/1149d7de0cfa_port_security.py', 'neutron/db/migration/alembic_migrations/versions/1c33fa3cd1a1_extra_route_config.py', 'neutron/tests/unit/midonet/etc/midonet.ini.test', 'neutron/plugins/midonet/plugin.py', 'neutron/db/migration/alembic_migrations/versions/1fcfc149aca4_agents_unique_by_type_and_host.py', 'neutron/plugins/midonet/midonet_lib.py', 'neutron/plugins/midonet/common/config.py', 'neutron/tests/unit/midonet/mock_lib.py', 'neutron/tests/unit/midonet/test_midonet_plugin.py', 'neutron/db/migration/alembic_migrations/versions/3cb5d900c5de_security_groups.py']",19,8ed5e2885fa020b21848d38ce182b8d7a1f5ce65,bp/midonet-plugin," 'neutron.plugins.midonet.plugin.MidonetPluginV2',",,1021,2303
openstack%2Ffuel-main~master~I278c6c5efd5848f47e7b6ed246aa27a7c49462e8,openstack/fuel-main,master,I278c6c5efd5848f47e7b6ed246aa27a7c49462e8,Fix expected results for huge_enviroment,MERGED,2014-03-07 14:41:10.000000000,2014-03-07 15:10:43.000000000,2014-03-07 15:10:42.000000000,"[{'_account_id': 3}, {'_account_id': 6719}, {'_account_id': 8965}, {'_account_id': 8971}]","[{'number': 1, 'created': '2014-03-07 14:41:10.000000000', 'files': ['fuelweb_test/tests/tests_strength/test_huge_environments.py'], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/abb89558f82efbc16a0fc9ca22bebee32bd9ceef', 'message': 'Fix expected results for huge_enviroment\n\nChange-Id: I278c6c5efd5848f47e7b6ed246aa27a7c49462e8\n'}]",0,78975,abb89558f82efbc16a0fc9ca22bebee32bd9ceef,9,4,1,8882,,,0,"Fix expected results for huge_enviroment

Change-Id: I278c6c5efd5848f47e7b6ed246aa27a7c49462e8
",git fetch https://review.opendev.org/openstack/fuel-main refs/changes/75/78975/1 && git format-patch -1 --stdout FETCH_HEAD,['fuelweb_test/tests/tests_strength/test_huge_environments.py'],1,abb89558f82efbc16a0fc9ca22bebee32bd9ceef,master," test_sets=['ha', 'smoke', 'sanity'], should_fail=1)"," should_fail=1, failed_test_name=['Check stack autoscaling'])",2,2
openstack%2Fopenstack-manuals~master~I7eee6faf0b2a5e5200effba345cc84c9ec259bf5,openstack/openstack-manuals,master,I7eee6faf0b2a5e5200effba345cc84c9ec259bf5,Removed *.ini configuration steps from Nova controller section,MERGED,2014-03-07 00:05:43.000000000,2014-03-07 14:58:37.000000000,2014-03-07 14:58:36.000000000,"[{'_account_id': 3}, {'_account_id': 612}, {'_account_id': 7923}]","[{'number': 1, 'created': '2014-03-07 00:05:43.000000000', 'files': ['doc/install-guide/section_nova-controller.xml'], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/87cd91050800832579cebd3076d6904d18c69bbd', 'message': ""Removed *.ini configuration steps from Nova controller section\n\nNova in Icehouse doesn't seem to require configuration of *.ini files,\nparticularly the [filter:authtoken] section. I removed these steps\nfrom the controller section of the Nova chapter. I also moved the\n'auth_uri' key to the [keystone_authtoken] section in nova.conf.\n\nChange-Id: I7eee6faf0b2a5e5200effba345cc84c9ec259bf5\nCloses-Bug: #1287897\n""}]",0,78818,87cd91050800832579cebd3076d6904d18c69bbd,7,3,1,9515,,,0,"Removed *.ini configuration steps from Nova controller section

Nova in Icehouse doesn't seem to require configuration of *.ini files,
particularly the [filter:authtoken] section. I removed these steps
from the controller section of the Nova chapter. I also moved the
'auth_uri' key to the [keystone_authtoken] section in nova.conf.

Change-Id: I7eee6faf0b2a5e5200effba345cc84c9ec259bf5
Closes-Bug: #1287897
",git fetch https://review.opendev.org/openstack/openstack-manuals refs/changes/18/78818/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/install-guide/section_nova-controller.xml'],1,87cd91050800832579cebd3076d6904d18c69bbd,bug/1287897,<prompt>#</prompt> <userinput>openstack-config --set /etc/nova/nova.conf keystone_authtoken auth_uri http://<replaceable>controller</replaceable>:5000</userinput>auth_uri = http://<replaceable>controller</replaceable>:5000," </step> <step os=""rhel;centos;fedora;opensuse;sles;ubuntu""> <para>Add the credentials to the <filename>/etc/nova/api-paste.ini</filename> file. Add these options to the <literal>[filter:authtoken]</literal> section:</para> <note> <title>Use of .ini files</title> <para>You might sometimes have to edit <filename>.ini</filename> files during initial setup. However, do not edit these files for general configuration tasks.</para> </note> <programlisting language=""ini"">[filter:authtoken] paste.filter_factory = keystoneclient.middleware.auth_token:filter_factory auth_host = <replaceable>controller</replaceable> auth_port = 35357 auth_protocol = http auth_uri = http://<replaceable>controller</replaceable>:5000/v2.0 admin_tenant_name = service admin_user = nova admin_password = <replaceable>NOVA_PASS</replaceable></programlisting>",2,22
openstack%2Fheat-templates~master~I73fc502dfa47feeb510bea3e851cfa4fb44858b8,openstack/heat-templates,master,I73fc502dfa47feeb510bea3e851cfa4fb44858b8,Add session_persistence to LBaaS pool,MERGED,2014-03-04 03:39:02.000000000,2014-03-07 14:42:06.000000000,2014-03-07 14:42:06.000000000,"[{'_account_id': 3}, {'_account_id': 2834}, {'_account_id': 3098}]","[{'number': 1, 'created': '2014-03-04 03:39:02.000000000', 'files': ['openshift-enterprise/heat/neutron/highly-available/ose_ha_stack.yaml'], 'web_link': 'https://opendev.org/openstack/heat-templates/commit/7f61325f1da038b69391adadc3ceec20465bca68', 'message': 'Add session_persistence to LBaaS pool\n\nChange-Id: I73fc502dfa47feeb510bea3e851cfa4fb44858b8\n'}]",0,77775,7f61325f1da038b69391adadc3ceec20465bca68,9,3,1,10000,,,0,"Add session_persistence to LBaaS pool

Change-Id: I73fc502dfa47feeb510bea3e851cfa4fb44858b8
",git fetch https://review.opendev.org/openstack/heat-templates refs/changes/75/77775/1 && git format-patch -1 --stdout FETCH_HEAD,['openshift-enterprise/heat/neutron/highly-available/ose_ha_stack.yaml'],1,7f61325f1da038b69391adadc3ceec20465bca68,ha_updates, session_persistence: type: SOURCE_IP,,2,0
openstack%2Fheat-templates~master~I95a3209ab38a562814bfea97c2ce2b445ca8135e,openstack/heat-templates,master,I95a3209ab38a562814bfea97c2ce2b445ca8135e,Remove openshift-enterprise-yum-validator,MERGED,2014-03-04 03:39:02.000000000,2014-03-07 14:42:04.000000000,2014-03-07 14:42:04.000000000,"[{'_account_id': 3}, {'_account_id': 2834}, {'_account_id': 3098}]","[{'number': 1, 'created': '2014-03-04 03:39:02.000000000', 'files': ['openshift-enterprise/heat/neutron/highly-available/ose_ha_stack.yaml', 'openshift-enterprise/heat/neutron/highly-available/ose_node_stack.yaml'], 'web_link': 'https://opendev.org/openstack/heat-templates/commit/6685d823fc6916d35af1df7ab0ffd75baf2b4166', 'message': 'Remove openshift-enterprise-yum-validator\n\nopenshift-enterprise-yum-validator is a tool that performs a pre-flight\ncheck. The installer performs this test and in some cases the pkg is\nnot availble until the installer is run and registration is done.\nThe validator version param is unnecessary.\n\nChange-Id: I95a3209ab38a562814bfea97c2ce2b445ca8135e\n'}]",0,77774,6685d823fc6916d35af1df7ab0ffd75baf2b4166,9,3,1,10000,,,0,"Remove openshift-enterprise-yum-validator

openshift-enterprise-yum-validator is a tool that performs a pre-flight
check. The installer performs this test and in some cases the pkg is
not availble until the installer is run and registration is done.
The validator version param is unnecessary.

Change-Id: I95a3209ab38a562814bfea97c2ce2b445ca8135e
",git fetch https://review.opendev.org/openstack/heat-templates refs/changes/74/77774/1 && git format-patch -1 --stdout FETCH_HEAD,"['openshift-enterprise/heat/neutron/highly-available/ose_ha_stack.yaml', 'openshift-enterprise/heat/neutron/highly-available/ose_node_stack.yaml']",2,6685d823fc6916d35af1df7ab0ffd75baf2b4166,ha_updates, curl -O https://raw.github.com/openshift/openshift-extras/enterprise-P_OSE_VERSION/enterprise/install-scripts/generic/openshift.sh -k," yum_validator_version: description: An optional version for the oo-yum-validator tool to use type: string default: ""2.0"" allowed_values: [""1.2"", ""2.0""] export CONF_OSE_VERSION=P_OSE_VERSION export CONF_YUM_VALIDATOR_VERSION=P_YUM_VALIDATOR_VERSION yum install -y openshift-enterprise-yum-validator oo-admin-yum-validator wget https://raw.github.com/openshift/openshift-extras/enterprise-P_OSE_VERSION/enterprise/install-scripts/generic/openshift.sh P_YUM_VALIDATOR_VERSION: { get_param: yum_validator_version }",4,34
openstack%2Fheat-templates~master~If4f9d40fc266a33c4fd4ebee351b766fb5aef1f7,openstack/heat-templates,master,If4f9d40fc266a33c4fd4ebee351b766fb5aef1f7,Convert all params from CamelCase to under_score for consistency,MERGED,2014-03-04 03:39:02.000000000,2014-03-07 14:42:02.000000000,2014-03-07 14:42:02.000000000,"[{'_account_id': 3}, {'_account_id': 2834}, {'_account_id': 4328}, {'_account_id': 7193}, {'_account_id': 10000}]","[{'number': 1, 'created': '2014-03-04 03:39:02.000000000', 'files': ['openshift-enterprise/heat/neutron/highly-available/ose_ha_stack.yaml', 'openshift-enterprise/heat/neutron/highly-available/ose_node_env.yaml', 'openshift-enterprise/heat/neutron/highly-available/ose_node_stack.yaml', 'openshift-enterprise/heat/neutron/highly-available/ose_ha_env.yaml'], 'web_link': 'https://opendev.org/openstack/heat-templates/commit/a8ea2d41af161d2712eaabcf373d115f37c97d23', 'message': 'Convert all params from CamelCase to under_score for consistency\n\nChange-Id: If4f9d40fc266a33c4fd4ebee351b766fb5aef1f7\n'}]",10,77773,a8ea2d41af161d2712eaabcf373d115f37c97d23,12,5,1,10000,,,0,"Convert all params from CamelCase to under_score for consistency

Change-Id: If4f9d40fc266a33c4fd4ebee351b766fb5aef1f7
",git fetch https://review.opendev.org/openstack/heat-templates refs/changes/73/77773/1 && git format-patch -1 --stdout FETCH_HEAD,"['openshift-enterprise/heat/neutron/highly-available/ose_ha_stack.yaml', 'openshift-enterprise/heat/neutron/highly-available/ose_node_env.yaml', 'openshift-enterprise/heat/neutron/highly-available/ose_node_stack.yaml', 'openshift-enterprise/heat/neutron/highly-available/ose_ha_env.yaml']",4,a8ea2d41af161d2712eaabcf373d115f37c97d23,ha_updates," hosts_domain: example.com replicants: broker1.example.com,broker2.example.com,broker3.example.com upstream_dns_ip: 10.0.0.1 node_image: RHEL65-x86_64-node broker_image: RHEL65-x86_64-broker activemq_admin_pass: password activemq_user_pass: password mcollective_pass: password mongo_broker_pass: password openshift_pass1: password rh_reg_name: admin rh_reg_pass: password"," hostsDomain: example.com Replicants: broker1.example.com,broker2.example.com,broker3.example.com UpstreamDnsIp: 10.0.0.1 NodeImage: RHEL65-x86_64-node BrokerImage: RHEL65-x86_64-broker ActiveMqAdminPass: password ActiveMqUserPass: password McollectivePass: password MongoDbBrokerPass: password OpenshiftPass1: password ConfRhRegName: admin ConfRhRegPass: password",265,265
openstack%2Fcookbook-openstack-compute~master~I65730f6fd7c96c8a850e66154b2939a349a5b563,openstack/cookbook-openstack-compute,master,I65730f6fd7c96c8a850e66154b2939a349a5b563,Update stub_commands,MERGED,2014-03-07 13:17:00.000000000,2014-03-07 14:11:15.000000000,2014-03-07 14:11:15.000000000,"[{'_account_id': 3}, {'_account_id': 2340}, {'_account_id': 2799}, {'_account_id': 7307}, {'_account_id': 9884}]","[{'number': 1, 'created': '2014-03-07 13:17:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cookbook-openstack-compute/commit/293d96bcea088dc0327eb2bf1037bd1451eb92a6', 'message': ""Update stub_commands\n\nSome spec tests are currently failing due to a change in\nopenstack-network (which this cookbook includes).  This change updates\nthe ovs-vsctl stub_commands to bring them in line with what's actually\nbeing executed in openstack-network.\n\nChange-Id: I65730f6fd7c96c8a850e66154b2939a349a5b563\nCloses-Bug: #1289350\n""}, {'number': 2, 'created': '2014-03-07 13:18:42.000000000', 'files': ['spec/spec_helper.rb'], 'web_link': 'https://opendev.org/openstack/cookbook-openstack-compute/commit/0b8636f3af8d2042f3376acd4541f7eba0e12165', 'message': ""Update stub_commands\n\nSome spec tests are currently failing due to a change in\nopenstack-network (which this cookbook includes).  This change updates\nthe ovs-vsctl stub_commands to bring them in line with what's actually\nbeing executed in openstack-network.\n\nChange-Id: I65730f6fd7c96c8a850e66154b2939a349a5b563\nCloses-Bug: #1289350\n""}]",0,78956,0b8636f3af8d2042f3376acd4541f7eba0e12165,10,5,2,7307,,,0,"Update stub_commands

Some spec tests are currently failing due to a change in
openstack-network (which this cookbook includes).  This change updates
the ovs-vsctl stub_commands to bring them in line with what's actually
being executed in openstack-network.

Change-Id: I65730f6fd7c96c8a850e66154b2939a349a5b563
Closes-Bug: #1289350
",git fetch https://review.opendev.org/openstack/cookbook-openstack-compute refs/changes/56/78956/1 && git format-patch -1 --stdout FETCH_HEAD,['spec/spec_helper.rb'],1,293d96bcea088dc0327eb2bf1037bd1451eb92a6,bug/1289350," stub_command(""ovs-vsctl br-exists br-int"").and_return(true) stub_command(""ovs-vsctl br-exists br-tun"").and_return(true)"," stub_command(""ovs-vsctl show | grep 'Bridge br-int'"").and_return(true) stub_command(""ovs-vsctl show | grep 'Bridge br-tun'"").and_return(true)",2,2
openstack%2Fcinder~master~Ieb69f560f8ed443bc7d3ab0b0cd49e105f256137,openstack/cinder,master,Ieb69f560f8ed443bc7d3ab0b0cd49e105f256137,Test Jenkins error. Don't review it.,ABANDONED,2014-03-07 11:07:55.000000000,2014-03-07 13:21:28.000000000,,[{'_account_id': 3}],"[{'number': 1, 'created': '2014-03-07 11:07:55.000000000', 'files': ['test-requirements.txt'], 'web_link': 'https://opendev.org/openstack/cinder/commit/325feeaa3c18f0c44d88a35f746e9865ddf5c9de', 'message': ""Test Jenkins error. Don't review it.\n\nChange-Id: Ieb69f560f8ed443bc7d3ab0b0cd49e105f256137\n""}]",0,78934,325feeaa3c18f0c44d88a35f746e9865ddf5c9de,3,1,1,2861,,,0,"Test Jenkins error. Don't review it.

Change-Id: Ieb69f560f8ed443bc7d3ab0b0cd49e105f256137
",git fetch https://review.opendev.org/openstack/cinder refs/changes/34/78934/1 && git format-patch -1 --stdout FETCH_HEAD,['test-requirements.txt'],1,325feeaa3c18f0c44d88a35f746e9865ddf5c9de,test-error,,,1,0
openstack%2Fnova~master~I1e9af9be0ea318f568180ddbd6cd0a25e8bb0bfd,openstack/nova,master,I1e9af9be0ea318f568180ddbd6cd0a25e8bb0bfd,Move detach_volume and remove_vol_connection to BDM objects,MERGED,2014-02-04 19:03:58.000000000,2014-03-07 13:14:03.000000000,2014-03-06 12:44:36.000000000,"[{'_account_id': 3}, {'_account_id': 688}, {'_account_id': 782}, {'_account_id': 1653}, {'_account_id': 2750}, {'_account_id': 4393}, {'_account_id': 5170}, {'_account_id': 5441}, {'_account_id': 5511}, {'_account_id': 8302}, {'_account_id': 9008}, {'_account_id': 9578}, {'_account_id': 9636}]","[{'number': 1, 'created': '2014-02-04 19:03:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/ff707f2eb5983cc3be71336ec4464523d119e208', 'message': 'Move detach_volume and remove_vol_connection to BDM objects\n\nThis patch moves detach volume code paths to use BDM objects. Since both\ndetach_volume and remove_volume_connection compute manager methods,\nsince both of them use the _detach_volume method that needed to be\nconverted as well.\n\nPart of blueprint: icehouse-objects\nPart of blueprint: clean-up-legacy-block-device-mapping\n\nChange-Id: I1e9af9be0ea318f568180ddbd6cd0a25e8bb0bfd\n'}, {'number': 2, 'created': '2014-02-06 10:22:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/8f1fa11e29da045ed336336ccc1ec293469034b0', 'message': 'Move detach_volume and remove_vol_connection to BDM objects\n\nThis patch moves detach volume code paths to use BDM objects. Since both\ndetach_volume and remove_volume_connection compute manager methods,\nsince both of them use the _detach_volume method that needed to be\nconverted as well.\n\nPart of blueprint: icehouse-objects\nPart of blueprint: clean-up-legacy-block-device-mapping\n\nChange-Id: I1e9af9be0ea318f568180ddbd6cd0a25e8bb0bfd\n'}, {'number': 3, 'created': '2014-02-06 18:13:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/64bf6c495fc282fc230ec1ee443523bd6eb38b68', 'message': 'Move detach_volume and remove_vol_connection to BDM objects\n\nThis patch moves detach volume code paths to use BDM objects. Since both\ndetach_volume and remove_volume_connection compute manager methods,\nsince both of them use the _detach_volume method that needed to be\nconverted as well.\n\nPart of blueprint: icehouse-objects\nPart of blueprint: clean-up-legacy-block-device-mapping\n\nChange-Id: I1e9af9be0ea318f568180ddbd6cd0a25e8bb0bfd\n'}, {'number': 4, 'created': '2014-02-10 13:12:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/67b71b4a7d48f33593d8ef90d02b276d1470e079', 'message': 'Move detach_volume and remove_vol_connection to BDM objects\n\nThis patch moves detach volume code paths to use BDM objects. Since both\ndetach_volume and remove_volume_connection compute manager methods,\nsince both of them use the _detach_volume method that needed to be\nconverted as well.\n\nPart of blueprint: icehouse-objects\nPart of blueprint: clean-up-legacy-block-device-mapping\n\nChange-Id: I1e9af9be0ea318f568180ddbd6cd0a25e8bb0bfd\n'}, {'number': 5, 'created': '2014-02-10 18:34:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/5e42c644006aaba2176ac1315c41280c72481bf3', 'message': 'Move detach_volume and remove_vol_connection to BDM objects\n\nThis patch moves detach volume code paths to use BDM objects. Since both\ndetach_volume and remove_volume_connection compute manager methods,\nsince both of them use the _detach_volume method that needed to be\nconverted as well.\n\nPart of blueprint: icehouse-objects\nPart of blueprint: clean-up-legacy-block-device-mapping\n\nChange-Id: I1e9af9be0ea318f568180ddbd6cd0a25e8bb0bfd\n'}, {'number': 6, 'created': '2014-02-10 21:07:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/cdabe062306d1483c7316e453e03f2d3e2b35b3a', 'message': 'Move detach_volume and remove_vol_connection to BDM objects\n\nThis patch moves detach volume code paths to use BDM objects. Since both\ndetach_volume and remove_volume_connection compute manager methods,\nsince both of them use the _detach_volume method that needed to be\nconverted as well.\n\nPart of blueprint: icehouse-objects\nPart of blueprint: clean-up-legacy-block-device-mapping\n\nChange-Id: I1e9af9be0ea318f568180ddbd6cd0a25e8bb0bfd\n'}, {'number': 7, 'created': '2014-02-17 17:17:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/f316952c784ec1ad4130d5e391fd87b1932fd494', 'message': 'Move detach_volume and remove_vol_connection to BDM objects\n\nThis patch moves detach volume code paths to use BDM objects. Since both\ndetach_volume and remove_volume_connection compute manager methods,\nsince both of them use the _detach_volume method that needed to be\nconverted as well.\n\nPart of blueprint: icehouse-objects\nPart of blueprint: clean-up-legacy-block-device-mapping\n\nChange-Id: I1e9af9be0ea318f568180ddbd6cd0a25e8bb0bfd\n'}, {'number': 8, 'created': '2014-02-20 09:17:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/b2859874de651e67ff6752a1d4622d64112c8cd6', 'message': 'Move detach_volume and remove_vol_connection to BDM objects\n\nThis patch moves detach volume code paths to use BDM objects. Since both\ndetach_volume and remove_volume_connection compute manager methods,\nsince both of them use the _detach_volume method that needed to be\nconverted as well.\n\nPart of blueprint: icehouse-objects\nPart of blueprint: clean-up-legacy-block-device-mapping\n\nChange-Id: I1e9af9be0ea318f568180ddbd6cd0a25e8bb0bfd\n'}, {'number': 9, 'created': '2014-02-20 16:19:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/5781ef0471e17453cec4dbc9971f5d91ccdecb6f', 'message': 'Move detach_volume and remove_vol_connection to BDM objects\n\nThis patch moves detach volume code paths to use BDM objects. Since both\ndetach_volume and remove_volume_connection compute manager methods,\nsince both of them use the _detach_volume method that needed to be\nconverted as well.\n\nPart of blueprint: icehouse-objects\nPart of blueprint: clean-up-legacy-block-device-mapping\n\nChange-Id: I1e9af9be0ea318f568180ddbd6cd0a25e8bb0bfd\n'}, {'number': 10, 'created': '2014-02-25 13:47:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/e59e5f1b9fc8acfd741338fff55c34654d56208a', 'message': 'Move detach_volume and remove_vol_connection to BDM objects\n\nThis patch moves detach volume code paths to use BDM objects. Since both\ndetach_volume and remove_volume_connection compute manager methods,\nsince both of them use the _detach_volume method that needed to be\nconverted as well.\n\nPart of blueprint: icehouse-objects\nPart of blueprint: clean-up-legacy-block-device-mapping\n\nChange-Id: I1e9af9be0ea318f568180ddbd6cd0a25e8bb0bfd\n'}, {'number': 11, 'created': '2014-02-26 12:01:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/348f143b34ccb3f06d32717822d938b77efabe91', 'message': 'Move detach_volume and remove_vol_connection to BDM objects\n\nThis patch moves detach volume code paths to use BDM objects. Since both\ndetach_volume and remove_volume_connection compute manager methods,\nsince both of them use the _detach_volume method that needed to be\nconverted as well.\n\nPart of blueprint: icehouse-objects\nPart of blueprint: clean-up-legacy-block-device-mapping\n\nChange-Id: I1e9af9be0ea318f568180ddbd6cd0a25e8bb0bfd\n'}, {'number': 12, 'created': '2014-03-03 22:35:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/7222901722f02ac9596867415a2940851a5c9175', 'message': 'Move detach_volume and remove_vol_connection to BDM objects\n\nThis patch moves detach volume code paths to use BDM objects. Since both\ndetach_volume and remove_volume_connection compute manager methods,\nsince both of them use the _detach_volume method that needed to be\nconverted as well.\n\nPart of blueprint: icehouse-objects\nPart of blueprint: clean-up-legacy-block-device-mapping\n\nChange-Id: I1e9af9be0ea318f568180ddbd6cd0a25e8bb0bfd\n'}, {'number': 13, 'created': '2014-03-03 23:02:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/cad7a13e758c670b386cd68509bf4bc89127c779', 'message': 'Move detach_volume and remove_vol_connection to BDM objects\n\nThis patch moves detach volume code paths to use BDM objects. Since both\ndetach_volume and remove_volume_connection compute manager methods,\nsince both of them use the _detach_volume method that needed to be\nconverted as well.\n\nPart of blueprint: icehouse-objects\nPart of blueprint: clean-up-legacy-block-device-mapping\n\nChange-Id: I1e9af9be0ea318f568180ddbd6cd0a25e8bb0bfd\n'}, {'number': 14, 'created': '2014-03-04 14:21:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/de4fa592fa5f9931181ff6138f612dffe752d27a', 'message': 'Move detach_volume and remove_vol_connection to BDM objects\n\nThis patch moves detach volume code paths to use BDM objects. Since both\ndetach_volume and remove_volume_connection compute manager methods,\nsince both of them use the _detach_volume method that needed to be\nconverted as well.\n\nPart of blueprint: icehouse-objects\nPart of blueprint: clean-up-legacy-block-device-mapping\n\nChange-Id: I1e9af9be0ea318f568180ddbd6cd0a25e8bb0bfd\n'}, {'number': 15, 'created': '2014-03-05 11:06:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/bfa0fe1a4dcadc2679bbf54d898032a87064b31a', 'message': 'Move detach_volume and remove_vol_connection to BDM objects\n\nThis patch moves detach volume code paths to use BDM objects. Since both\ndetach_volume and remove_volume_connection compute manager methods,\nsince both of them use the _detach_volume method that needed to be\nconverted as well.\n\nPart of blueprint: icehouse-objects\nPart of blueprint: clean-up-legacy-block-device-mapping\n\nChange-Id: I1e9af9be0ea318f568180ddbd6cd0a25e8bb0bfd\n'}, {'number': 16, 'created': '2014-03-06 08:22:50.000000000', 'files': ['nova/compute/manager.py', 'nova/tests/compute/test_compute.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/87f35cfcc7d26b89dcc084be337d97a213079e77', 'message': 'Move detach_volume and remove_vol_connection to BDM objects\n\nThis patch moves detach volume code paths to use BDM objects. Since both\ndetach_volume and remove_volume_connection compute manager methods,\nsince both of them use the _detach_volume method that needed to be\nconverted as well.\n\nPart of blueprint: icehouse-objects\nPart of blueprint: clean-up-legacy-block-device-mapping\n\nChange-Id: I1e9af9be0ea318f568180ddbd6cd0a25e8bb0bfd\n'}]",0,71063,87f35cfcc7d26b89dcc084be337d97a213079e77,139,13,16,5511,,,0,"Move detach_volume and remove_vol_connection to BDM objects

This patch moves detach volume code paths to use BDM objects. Since both
detach_volume and remove_volume_connection compute manager methods,
since both of them use the _detach_volume method that needed to be
converted as well.

Part of blueprint: icehouse-objects
Part of blueprint: clean-up-legacy-block-device-mapping

Change-Id: I1e9af9be0ea318f568180ddbd6cd0a25e8bb0bfd
",git fetch https://review.opendev.org/openstack/nova refs/changes/63/71063/16 && git format-patch -1 --stdout FETCH_HEAD,"['nova/compute/manager.py', 'nova/tests/compute/test_compute.py']",2,ff707f2eb5983cc3be71336ec4464523d119e208,bdm_objects_compute," db.block_device_mapping_get_by_volume_id(self.context, 1, []).\ AndReturn(bdm) fake_bdm = fake_block_device.FakeDbBlockDeviceDict( {'device_name': '/dev/vdb', 'volume_id': 1, 'source_type': 'snapshot', 'destination_type': 'volume', 'connection_info': '{""test"": ""test""}'}) self.mox.StubOutWithMock(block_device_obj.BlockDeviceMapping, 'get_by_volume_id') block_device_obj.BlockDeviceMapping.get_by_volume_id( self.context, 1).AndReturn(block_device_obj.BlockDeviceMapping( **fake_bdm)) self.mox.ReplayAll() "," self.mox.StubOutWithMock(self.compute, '_get_instance_volume_bdm') self.compute._get_instance_volume_bdm( self.context, instance, 1).AndReturn(legacy_bdm) def fake_get_instance_volume_bdm(*args, **kwargs): return {'device_name': '/dev/vdb', 'volume_id': 1, 'connection_info': '{""test"": ""test""}'} self.stubs.Set(self.compute, ""_get_instance_volume_bdm"", fake_get_instance_volume_bdm)",22,16
openstack%2Fnova~master~Ic63a3afb77362f0797c546a9505fa4bd7a9b986e,openstack/nova,master,Ic63a3afb77362f0797c546a9505fa4bd7a9b986e,Move instance delete to new-world BDM objects,MERGED,2014-02-03 15:30:16.000000000,2014-03-07 13:07:33.000000000,2014-03-06 12:26:39.000000000,"[{'_account_id': 3}, {'_account_id': 688}, {'_account_id': 782}, {'_account_id': 1653}, {'_account_id': 2750}, {'_account_id': 4393}, {'_account_id': 4912}, {'_account_id': 5170}, {'_account_id': 5441}, {'_account_id': 5511}, {'_account_id': 7730}, {'_account_id': 9008}, {'_account_id': 9420}, {'_account_id': 9578}, {'_account_id': 9636}]","[{'number': 1, 'created': '2014-02-03 15:30:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/dbf9ddbe818e60c1bbbe71a15dd4ed97ebd62dc8', 'message': 'Move instance delete to new-world BDM objects\n\nMove all the code paths related to instance deletion to new-world\nobjects. This includes soft- and hard- deletes, instance init on compute\nstartup, as well as the reclaim_queued_deletes periodic task.\n\nPart of blueprint: icehouse-objects\nPart of blueprint: clean-up-legacy-block-device-mapping\n\nChange-Id: Ic63a3afb77362f0797c546a9505fa4bd7a9b986e\n'}, {'number': 2, 'created': '2014-02-05 12:17:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/dd47710289102138dd48309cd95c407ee550d9e8', 'message': 'Move instance delete to new-world BDM objects\n\nMove all the code paths related to instance deletion to new-world\nobjects. This includes soft- and hard- deletes, instance init on compute\nstartup, as well as the reclaim_queued_deletes and\n_cleanup_running_deleted_instances  periodic tasks.\n\nIt introduces an additional database call in the _shutdown_instance\nmethod as there are still paths that call this method but will not pass\nit BDM objects.\n\nPart of blueprint: icehouse-objects\nPart of blueprint: clean-up-legacy-block-device-mapping\n\nChange-Id: Ic63a3afb77362f0797c546a9505fa4bd7a9b986e\n'}, {'number': 3, 'created': '2014-02-05 12:21:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/e8e508d7e666ebedf2e5c83199f62e01a4f3e5a0', 'message': 'Move instance delete to new-world BDM objects\n\nMove all the code paths related to instance deletion to new-world\nobjects. This includes soft- and hard- deletes, instance init on compute\nstartup, as well as the reclaim_queued_deletes and\n_cleanup_running_deleted_instances  periodic tasks.\n\nIt introduces an additional database call in the _shutdown_instance\nmethod as there are still paths that call this method but will not pass\nit BDM objects. This will be removed as soon as _recschedule_on_error\n(basically mening instance spawn) code paths are moved to BDM objects.\n\nPart of blueprint: icehouse-objects\nPart of blueprint: clean-up-legacy-block-device-mapping\n\nChange-Id: Ic63a3afb77362f0797c546a9505fa4bd7a9b986e\n'}, {'number': 4, 'created': '2014-02-05 15:00:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/fcfd7e6459b1a90b4b3aae6196ea52d0a450fc50', 'message': 'Move instance delete to new-world BDM objects\n\nMove all the code paths related to instance deletion to new-world\nobjects. This includes soft- and hard- deletes, instance init on compute\nstartup, as well as the reclaim_queued_deletes and\n_cleanup_running_deleted_instances  periodic tasks.\n\nIt introduces an additional database call in the _shutdown_instance\nmethod as there are still paths that call this method but will not pass\nit BDM objects. This will be removed as soon as _recschedule_on_error\n(basically mening instance spawn) code paths are moved to BDM objects.\n\nPart of blueprint: icehouse-objects\nPart of blueprint: clean-up-legacy-block-device-mapping\n\nChange-Id: Ic63a3afb77362f0797c546a9505fa4bd7a9b986e\n'}, {'number': 5, 'created': '2014-02-06 18:11:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/7845d97a6c3b938ec4c5ef55f85f414b6700e45c', 'message': 'Move instance delete to new-world BDM objects\n\nMove all the code paths related to instance deletion to new-world\nobjects. This includes soft- and hard- deletes, instance init on compute\nstartup, as well as the reclaim_queued_deletes and\n_cleanup_running_deleted_instances  periodic tasks.\n\nIt introduces an additional database call in the _shutdown_instance\nmethod as there are still paths that call this method but will not pass\nit BDM objects. This will be removed as soon as _recschedule_on_error\n(basically mening instance spawn) code paths are moved to BDM objects.\n\nPart of blueprint: icehouse-objects\nPart of blueprint: clean-up-legacy-block-device-mapping\n\nChange-Id: Ic63a3afb77362f0797c546a9505fa4bd7a9b986e\n'}, {'number': 6, 'created': '2014-02-10 13:09:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/edf8230bca21b1cca57a44db8e25d99ef1abfc99', 'message': 'Move instance delete to new-world BDM objects\n\nMove all the code paths related to instance deletion to new-world\nobjects. This includes soft- and hard- deletes, instance init on compute\nstartup, as well as the reclaim_queued_deletes and\n_cleanup_running_deleted_instances  periodic tasks.\n\nIt introduces an additional database call in the _shutdown_instance\nmethod as there are still paths that call this method but will not pass\nit BDM objects. This will be removed as soon as _recschedule_on_error\n(basically mening instance spawn) code paths are moved to BDM objects.\n\nPart of blueprint: icehouse-objects\nPart of blueprint: clean-up-legacy-block-device-mapping\n\nChange-Id: Ic63a3afb77362f0797c546a9505fa4bd7a9b986e\n'}, {'number': 7, 'created': '2014-02-10 18:32:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/f25a22267b111467ca488d802e444b295a23a4a5', 'message': 'Move instance delete to new-world BDM objects\n\nMove all the code paths related to instance deletion to new-world\nobjects. This includes soft- and hard- deletes, instance init on compute\nstartup, as well as the reclaim_queued_deletes and\n_cleanup_running_deleted_instances  periodic tasks.\n\nIt introduces an additional database call in the _shutdown_instance\nmethod as there are still paths that call this method but will not pass\nit BDM objects. This will be removed as soon as _recschedule_on_error\n(basically mening instance spawn) code paths are moved to BDM objects.\n\nPart of blueprint: icehouse-objects\nPart of blueprint: clean-up-legacy-block-device-mapping\n\nChange-Id: Ic63a3afb77362f0797c546a9505fa4bd7a9b986e\n'}, {'number': 8, 'created': '2014-02-10 21:06:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/4894525c12a746f0d50b0e2732aa998aac3dbf7e', 'message': 'Move instance delete to new-world BDM objects\n\nMove all the code paths related to instance deletion to new-world\nobjects. This includes soft- and hard- deletes, instance init on compute\nstartup, as well as the reclaim_queued_deletes and\n_cleanup_running_deleted_instances  periodic tasks.\n\nIt introduces an additional database call in the _shutdown_instance\nmethod as there are still paths that call this method but will not pass\nit BDM objects. This will be removed as soon as _recschedule_on_error\n(basically mening instance spawn) code paths are moved to BDM objects.\n\nPart of blueprint: icehouse-objects\nPart of blueprint: clean-up-legacy-block-device-mapping\n\nChange-Id: Ic63a3afb77362f0797c546a9505fa4bd7a9b986e\n'}, {'number': 9, 'created': '2014-02-12 19:21:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/34bbca6081ad4d825f1fdd2e7fe62c3c660d5ff8', 'message': 'Move instance delete to new-world BDM objects\n\nMove all the code paths related to instance deletion to new-world\nobjects. This includes soft- and hard- deletes, instance init on compute\nstartup, as well as the reclaim_queued_deletes and\n_cleanup_running_deleted_instances  periodic tasks.\n\nIt introduces an additional database call in the _shutdown_instance\nmethod as there are still paths that call this method but will not pass\nit BDM objects. This will be removed as soon as _recschedule_on_error\n(basically mening instance spawn) code paths are moved to BDM objects.\n\nPart of blueprint: icehouse-objects\nPart of blueprint: clean-up-legacy-block-device-mapping\n\nChange-Id: Ic63a3afb77362f0797c546a9505fa4bd7a9b986e\n'}, {'number': 10, 'created': '2014-02-17 09:38:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/c9fba28d75f918898d5dd0aa9f76c917bffc18c0', 'message': 'Move instance delete to new-world BDM objects\n\nMove all the code paths related to instance deletion to new-world\nobjects. This includes soft- and hard- deletes, instance init on compute\nstartup, as well as the reclaim_queued_deletes and\n_cleanup_running_deleted_instances  periodic tasks.\n\nIt introduces an additional database call in the _shutdown_instance\nmethod as there are still paths that call this method but will not pass\nit BDM objects. This will be removed as soon as _reschedule_on_error\n(basically meaning instance spawn) code paths are moved to BDM objects.\n\nPart of blueprint: icehouse-objects\nPart of blueprint: clean-up-legacy-block-device-mapping\n\nChange-Id: Ic63a3afb77362f0797c546a9505fa4bd7a9b986e\n'}, {'number': 11, 'created': '2014-02-17 17:12:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/07d3ee356bbbd365c9640cdea2f2c246c467f978', 'message': 'Move instance delete to new-world BDM objects\n\nMove all the code paths related to instance deletion to new-world\nobjects. This includes soft- and hard- deletes, instance init on compute\nstartup, as well as the reclaim_queued_deletes and\n_cleanup_running_deleted_instances  periodic tasks.\n\nIt introduces an additional database call in the _shutdown_instance\nmethod as there are still paths that call this method but will not pass\nit BDM objects. This will be removed as soon as _reschedule_on_error\n(basically meaning instance spawn) code paths are moved to BDM objects.\n\nPart of blueprint: icehouse-objects\nPart of blueprint: clean-up-legacy-block-device-mapping\n\nChange-Id: Ic63a3afb77362f0797c546a9505fa4bd7a9b986e\n'}, {'number': 12, 'created': '2014-02-20 08:31:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/88aa4a82993002a0b4354637617bb72a177a67c9', 'message': 'Move instance delete to new-world BDM objects\n\nMove all the code paths related to instance deletion to new-world\nobjects. This includes soft- and hard- deletes, instance init on compute\nstartup, as well as the reclaim_queued_deletes and\n_cleanup_running_deleted_instances  periodic tasks.\n\nIt introduces an additional database call in the _shutdown_instance\nmethod as there are still paths that call this method but will not pass\nit BDM objects. This will be removed as soon as _reschedule_on_error\n(basically meaning instance spawn) code paths are moved to BDM objects.\n\nPart of blueprint: icehouse-objects\nPart of blueprint: clean-up-legacy-block-device-mapping\n\nChange-Id: Ic63a3afb77362f0797c546a9505fa4bd7a9b986e\n'}, {'number': 13, 'created': '2014-02-20 09:16:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/8f18a17d240941a075e7a7c8f4082e8a7d7e8873', 'message': 'Move instance delete to new-world BDM objects\n\nMove all the code paths related to instance deletion to new-world\nobjects. This includes soft- and hard- deletes, instance init on compute\nstartup, as well as the reclaim_queued_deletes and\n_cleanup_running_deleted_instances  periodic tasks.\n\nIt introduces an additional database call in the _shutdown_instance\nmethod as there are still paths that call this method but will not pass\nit BDM objects. This will be removed as soon as _reschedule_on_error\n(basically meaning instance spawn) code paths are moved to BDM objects.\n\nPart of blueprint: icehouse-objects\nPart of blueprint: clean-up-legacy-block-device-mapping\n\nChange-Id: Ic63a3afb77362f0797c546a9505fa4bd7a9b986e\n'}, {'number': 14, 'created': '2014-02-20 15:55:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/523585d68f343fd4f3b7e2ca90fdd050cc37d293', 'message': 'Move instance delete to new-world BDM objects\n\nMove all the code paths related to instance deletion to new-world\nobjects. This includes soft- and hard- deletes, instance init on compute\nstartup, as well as the reclaim_queued_deletes and\n_cleanup_running_deleted_instances  periodic tasks.\n\nIt introduces an additional database call in the _shutdown_instance\nmethod as there are still paths that call this method but will not pass\nit BDM objects. This will be removed as soon as _reschedule_on_error\n(basically meaning instance spawn) code paths are moved to BDM objects.\n\nPart of blueprint: icehouse-objects\nPart of blueprint: clean-up-legacy-block-device-mapping\n\nChange-Id: Ic63a3afb77362f0797c546a9505fa4bd7a9b986e\n'}, {'number': 15, 'created': '2014-02-25 13:45:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/ed74f3920c28a1ee35544cdef18834253b66bf3a', 'message': 'Move instance delete to new-world BDM objects\n\nMove all the code paths related to instance deletion to new-world\nobjects. This includes soft- and hard- deletes, instance init on compute\nstartup, as well as the reclaim_queued_deletes and\n_cleanup_running_deleted_instances  periodic tasks.\n\nIt introduces an additional database call in the _shutdown_instance\nmethod as there are still paths that call this method but will not pass\nit BDM objects. This will be removed as soon as _reschedule_on_error\n(basically meaning instance spawn) code paths are moved to BDM objects.\n\nPart of blueprint: icehouse-objects\nPart of blueprint: clean-up-legacy-block-device-mapping\n\nChange-Id: Ic63a3afb77362f0797c546a9505fa4bd7a9b986e\n'}, {'number': 16, 'created': '2014-02-26 10:32:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/16b6d18b577ca1faf89eb13bb9fcae7688117225', 'message': 'Move instance delete to new-world BDM objects\n\nMove all the code paths related to instance deletion to new-world\nobjects. This includes soft- and hard- deletes, instance init on compute\nstartup, as well as the reclaim_queued_deletes and\n_cleanup_running_deleted_instances  periodic tasks.\n\nIt introduces an additional database call in the _shutdown_instance\nmethod as there are still paths that call this method but will not pass\nit BDM objects. This will be removed as soon as _reschedule_on_error\n(basically meaning instance spawn) code paths are moved to BDM objects.\n\nPart of blueprint: icehouse-objects\nPart of blueprint: clean-up-legacy-block-device-mapping\n\nChange-Id: Ic63a3afb77362f0797c546a9505fa4bd7a9b986e\n'}, {'number': 17, 'created': '2014-03-03 22:35:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/da6b513eea1a65aa7105f98f532a2868603e9c2b', 'message': 'Move instance delete to new-world BDM objects\n\nMove all the code paths related to instance deletion to new-world\nobjects. This includes soft- and hard- deletes, instance init on compute\nstartup, as well as the reclaim_queued_deletes and\n_cleanup_running_deleted_instances  periodic tasks.\n\nIt introduces an additional database call in the _shutdown_instance\nmethod as there are still paths that call this method but will not pass\nit BDM objects. This will be removed as soon as _reschedule_on_error\n(basically meaning instance spawn) code paths are moved to BDM objects.\n\nPart of blueprint: icehouse-objects\nPart of blueprint: clean-up-legacy-block-device-mapping\n\nChange-Id: Ic63a3afb77362f0797c546a9505fa4bd7a9b986e\n'}, {'number': 18, 'created': '2014-03-03 23:02:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/0b798136d0546793f61b80cf211cbb8cf034ea74', 'message': 'Move instance delete to new-world BDM objects\n\nMove all the code paths related to instance deletion to new-world\nobjects. This includes soft- and hard- deletes, instance init on compute\nstartup, as well as the reclaim_queued_deletes and\n_cleanup_running_deleted_instances  periodic tasks.\n\nIt introduces an additional database call in the _shutdown_instance\nmethod as there are still paths that call this method but will not pass\nit BDM objects. This will be removed as soon as _reschedule_on_error\n(basically meaning instance spawn) code paths are moved to BDM objects.\n\nPart of blueprint: icehouse-objects\nPart of blueprint: clean-up-legacy-block-device-mapping\n\nChange-Id: Ic63a3afb77362f0797c546a9505fa4bd7a9b986e\n'}, {'number': 19, 'created': '2014-03-04 09:08:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/9f3167606dbba11c64200db655263c3ce2ea2d40', 'message': 'Move instance delete to new-world BDM objects\n\nMove all the code paths related to instance deletion to new-world\nobjects. This includes soft- and hard- deletes, instance init on compute\nstartup, as well as the reclaim_queued_deletes and\n_cleanup_running_deleted_instances  periodic tasks.\n\nIt introduces an additional database call in the _shutdown_instance\nmethod as there are still paths that call this method but will not pass\nit BDM objects. This will be removed as soon as _reschedule_on_error\n(basically meaning instance spawn) code paths are moved to BDM objects.\n\nPart of blueprint: icehouse-objects\nPart of blueprint: clean-up-legacy-block-device-mapping\n\nChange-Id: Ic63a3afb77362f0797c546a9505fa4bd7a9b986e\n'}, {'number': 20, 'created': '2014-03-04 13:41:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/8bd2eb787b1e958e02248adc3d251d68c88d7845', 'message': 'Move instance delete to new-world BDM objects\n\nMove all the code paths related to instance deletion to new-world\nobjects. This includes soft- and hard- deletes, instance init on compute\nstartup, as well as the reclaim_queued_deletes and\n_cleanup_running_deleted_instances  periodic tasks.\n\nIt introduces an additional database call in the _shutdown_instance\nmethod as there are still paths that call this method but will not pass\nit BDM objects. This will be removed as soon as _reschedule_on_error\n(basically meaning instance spawn) code paths are moved to BDM objects.\n\nPart of blueprint: icehouse-objects\nPart of blueprint: clean-up-legacy-block-device-mapping\n\nChange-Id: Ic63a3afb77362f0797c546a9505fa4bd7a9b986e\n'}, {'number': 21, 'created': '2014-03-04 14:16:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/89f10f6d03db8ae3e478c8bafbea07a0c9b4f9e2', 'message': 'Move instance delete to new-world BDM objects\n\nMove all the code paths related to instance deletion to new-world\nobjects. This includes soft- and hard- deletes, instance init on compute\nstartup, as well as the reclaim_queued_deletes and\n_cleanup_running_deleted_instances  periodic tasks.\n\nIt introduces an additional database call in the _shutdown_instance\nmethod as there are still paths that call this method but will not pass\nit BDM objects. This will be removed as soon as _reschedule_on_error\n(basically meaning instance spawn) code paths are moved to BDM objects.\n\nPart of blueprint: icehouse-objects\nPart of blueprint: clean-up-legacy-block-device-mapping\n\nChange-Id: Ic63a3afb77362f0797c546a9505fa4bd7a9b986e\n'}, {'number': 22, 'created': '2014-03-05 09:21:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/9c0fd09c626f147f62fb9eba3ec810bedfe00656', 'message': 'Move instance delete to new-world BDM objects\n\nMove all the code paths related to instance deletion to new-world\nobjects. This includes soft- and hard- deletes, instance init on compute\nstartup, as well as the reclaim_queued_deletes and\n_cleanup_running_deleted_instances  periodic tasks.\n\nIt introduces an additional database call in the _shutdown_instance\nmethod as there are still paths that call this method but will not pass\nit BDM objects. This will be removed as soon as _reschedule_on_error\n(basically meaning instance spawn) code paths are moved to BDM objects.\n\nPart of blueprint: icehouse-objects\nPart of blueprint: clean-up-legacy-block-device-mapping\n\nChange-Id: Ic63a3afb77362f0797c546a9505fa4bd7a9b986e\n'}, {'number': 23, 'created': '2014-03-06 08:20:44.000000000', 'files': ['nova/tests/compute/test_compute_api.py', 'nova/tests/compute/test_compute_mgr.py', 'nova/tests/compute/test_rpcapi.py', 'nova/compute/manager.py', 'nova/compute/rpcapi.py', 'nova/tests/compute/test_compute.py', 'nova/compute/api.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/f5071bd1ac00ed68102d37c8025d36df6777cd9e', 'message': 'Move instance delete to new-world BDM objects\n\nMove all the code paths related to instance deletion to new-world\nobjects. This includes soft- and hard- deletes, instance init on compute\nstartup, as well as the reclaim_queued_deletes and\n_cleanup_running_deleted_instances  periodic tasks.\n\nIt introduces an additional database call in the _shutdown_instance\nmethod as there are still paths that call this method but will not pass\nit BDM objects. This will be removed as soon as _reschedule_on_error\n(basically meaning instance spawn) code paths are moved to BDM objects.\n\nPart of blueprint: icehouse-objects\nPart of blueprint: clean-up-legacy-block-device-mapping\n\nChange-Id: Ic63a3afb77362f0797c546a9505fa4bd7a9b986e\n'}]",19,70747,f5071bd1ac00ed68102d37c8025d36df6777cd9e,169,15,23,5511,,,0,"Move instance delete to new-world BDM objects

Move all the code paths related to instance deletion to new-world
objects. This includes soft- and hard- deletes, instance init on compute
startup, as well as the reclaim_queued_deletes and
_cleanup_running_deleted_instances  periodic tasks.

It introduces an additional database call in the _shutdown_instance
method as there are still paths that call this method but will not pass
it BDM objects. This will be removed as soon as _reschedule_on_error
(basically meaning instance spawn) code paths are moved to BDM objects.

Part of blueprint: icehouse-objects
Part of blueprint: clean-up-legacy-block-device-mapping

Change-Id: Ic63a3afb77362f0797c546a9505fa4bd7a9b986e
",git fetch https://review.opendev.org/openstack/nova refs/changes/47/70747/13 && git format-patch -1 --stdout FETCH_HEAD,"['nova/tests/compute/test_compute_api.py', 'nova/tests/compute/test_compute_mgr.py', 'nova/tests/compute/test_rpcapi.py', 'nova/compute/manager.py', 'nova/compute/rpcapi.py', 'nova/compute/api.py', 'nova/tests/compute/test_compute.py']",7,dbf9ddbe818e60c1bbbe71a15dd4ed97ebd62dc8,bdm_objects_rpc," def fake_terminate_connection(self, context, volume_id, connector): pass def fake_detach(self, context, volume_id): pass bdms = [] bdms.append(bdm) self.stubs.Set(cinder.API, 'terminate_connection', fake_terminate_connection) self.stubs.Set(cinder.API, 'detach', fake_detach) self._objectify(instance), bdms, []) instance.uuid = 'fake-uuid' self.stubs.Set(db, 'block_device_mapping_get_all_by_instance', self.mox.StubOutWithMock(block_device_obj.BlockDeviceMappingList, 'get_by_instance_uuid') block_device_obj.BlockDeviceMappingList.get_by_instance_uuid( ctxt, instance1.uuid).AndReturn([]) block_device_obj.BlockDeviceMappingList.get_by_instance_uuid( ctxt, instance2.uuid).AndReturn([]) 'device_name': '/dev/vda', 'source_type': 'image', 'destination_type': 'local', 'delete_on_termination': False, 'boot_index': 0, 'image_id': 'fake_image'} 'device_name': '/dev/vdc', 'source_type': 'volume', 'destination_type': 'volume', 'delete_on_termination': False, 'volume_id': 'fake_vol'} bdms = [] for bdm in img_bdm, vol_bdm: bdm_obj = block_device_obj.BlockDeviceMapping(**bdm) bdm_obj.create(admin) bdms.append(bdm_obj) self._objectify(instance), bdms, [])"," self._objectify(instance), [], []) self.stubs.Set(self.compute, '_get_instance_volume_bdms', self.mox.StubOutWithMock(self.compute.conductor_api, 'block_device_mapping_get_all_by_instance') self.compute.conductor_api.block_device_mapping_get_all_by_instance( ctxt, instance1).AndReturn(None) self.compute.conductor_api.block_device_mapping_get_all_by_instance( ctxt, instance2).AndReturn(None) 'device_name': '/dev/vda', 'source_type': 'image', 'destination_type': 'local', 'delete_on_termination': False, 'boot_index': 0, 'image_id': 'fake_image'} 'device_name': '/dev/vdc', 'source_type': 'volume', 'destination_type': 'volume', 'delete_on_termination': False, 'volume_id': 'fake_vol'} for bdm in img_bdm, vol_bdm: db.block_device_mapping_create(admin, bdm, legacy=False) self._objectify(instance), [], [])",100,72
openstack%2Fmanila~master~I6e430ee2478a097abaab1b78f12d17fed3895eee,openstack/manila,master,I6e430ee2478a097abaab1b78f12d17fed3895eee,DevStack plugin: make source dirs configurable,MERGED,2014-03-04 14:15:41.000000000,2014-03-07 13:06:49.000000000,2014-03-07 13:06:49.000000000,"[{'_account_id': 3}, {'_account_id': 6094}, {'_account_id': 7534}, {'_account_id': 7917}, {'_account_id': 8851}, {'_account_id': 9521}]","[{'number': 1, 'created': '2014-03-04 14:15:41.000000000', 'files': ['contrib/devstack/lib/manila'], 'web_link': 'https://opendev.org/openstack/manila/commit/fdb1dcb14712164a9c33d740264849de67b74e2d', 'message': 'DevStack plugin: make source dirs configurable\n\nMake source directories of Manila and Manila client configurable such\nthat those of other OpenStack projects are not affected. So the\ndeveloper can conveniently use her own repos with the DevStack setup.\nCurrently the source directories of Manila and Manila client depend on\n$DEST, which is used by other install scripts in the DevStack framework.\n\nChange-Id: I6e430ee2478a097abaab1b78f12d17fed3895eee\n'}]",0,77887,fdb1dcb14712164a9c33d740264849de67b74e2d,10,6,1,8056,,,0,"DevStack plugin: make source dirs configurable

Make source directories of Manila and Manila client configurable such
that those of other OpenStack projects are not affected. So the
developer can conveniently use her own repos with the DevStack setup.
Currently the source directories of Manila and Manila client depend on
$DEST, which is used by other install scripts in the DevStack framework.

Change-Id: I6e430ee2478a097abaab1b78f12d17fed3895eee
",git fetch https://review.opendev.org/openstack/manila refs/changes/87/77887/1 && git format-patch -1 --stdout FETCH_HEAD,['contrib/devstack/lib/manila'],1,fdb1dcb14712164a9c33d740264849de67b74e2d,devstack_plugin,MANILA_DIR=${MANILA_DIR:=$DEST/manila} MANILACLIENT_DIR=${MANILACLIENT_DIR:=$DEST/python-manilaclient},MANILA_DIR=$DEST/manila MANILACLIENT_DIR=$DEST/python-manilaclient,2,2
openstack%2Fmanila~master~I92fa249031e98a38aba721c0f3d1d7489abd562a,openstack/manila,master,I92fa249031e98a38aba721c0f3d1d7489abd562a,Removed swiftclient from dependencies,MERGED,2014-03-03 14:30:25.000000000,2014-03-07 12:55:45.000000000,2014-03-07 12:55:45.000000000,"[{'_account_id': 3}, {'_account_id': 6094}, {'_account_id': 7534}]","[{'number': 1, 'created': '2014-03-03 14:30:25.000000000', 'files': ['doc/source/man/manila-manage.rst', 'requirements.txt', 'doc/source/conf.py', 'manila/exception.py'], 'web_link': 'https://opendev.org/openstack/manila/commit/bc2d20d3bb4d9fb01b3be84c1e76816dc98a502a', 'message': 'Removed swiftclient from dependencies\n\nSwiftclient was in dependencies as artifact after port from cinder.\nRemoved as unnecessary requirement itself and related stuff.\n\nChange-Id: I92fa249031e98a38aba721c0f3d1d7489abd562a\n'}]",0,77600,bc2d20d3bb4d9fb01b3be84c1e76816dc98a502a,9,3,1,8851,,,0,"Removed swiftclient from dependencies

Swiftclient was in dependencies as artifact after port from cinder.
Removed as unnecessary requirement itself and related stuff.

Change-Id: I92fa249031e98a38aba721c0f3d1d7489abd562a
",git fetch https://review.opendev.org/openstack/manila refs/changes/00/77600/1 && git format-patch -1 --stdout FETCH_HEAD,"['doc/source/man/manila-manage.rst', 'requirements.txt', 'doc/source/conf.py', 'manila/exception.py']",4,bc2d20d3bb4d9fb01b3be84c1e76816dc98a502a,master,,"class SwiftConnectionFailed(ManilaException): message = _(""Connection to swift failed"") + "": %(reason)s"" ",1,8
openstack%2Frally~master~I493301b9be0da30859882e2ae6d170ba24218c78,openstack/rally,master,I493301b9be0da30859882e2ae6d170ba24218c78,Use multiprocessing in UserGenerator for creating tenants and users.,ABANDONED,2014-03-04 17:47:32.000000000,2014-03-07 12:17:37.000000000,,[{'_account_id': 3}],"[{'number': 1, 'created': '2014-03-04 17:47:32.000000000', 'files': ['rally/benchmark/context/users.py'], 'web_link': 'https://opendev.org/openstack/rally/commit/af185bb1a27200a687cb3620d8ab16ec2fe4b00b', 'message': '    Use multiprocessing in UserGenerator for creating tenants and users.\n\n    Using of single keystone client within each process to save performance.\n    Also there is a bit of refactoring.\n\n    Note: this commit only works if __getattr__() method is commented out\n    or removed from keystoneclient.base.Resource\n    (https://github.com/openstack/python-keystoneclient/blob/0.6.0/keystoneclient/base.py#L422-L431).\n    This can be related to a bug or requires deeper investigation.\n\n    Blueprint conrurrent-creation-of-users\n\n    Change-Id: I12d3c1a01a579b7e080ab8199b11d2d837f7e71e\n\nChange-Id: I493301b9be0da30859882e2ae6d170ba24218c78\n'}]",0,77948,af185bb1a27200a687cb3620d8ab16ec2fe4b00b,3,1,1,10475,,,0,"    Use multiprocessing in UserGenerator for creating tenants and users.

    Using of single keystone client within each process to save performance.
    Also there is a bit of refactoring.

    Note: this commit only works if __getattr__() method is commented out
    or removed from keystoneclient.base.Resource
    (https://github.com/openstack/python-keystoneclient/blob/0.6.0/keystoneclient/base.py#L422-L431).
    This can be related to a bug or requires deeper investigation.

    Blueprint conrurrent-creation-of-users

    Change-Id: I12d3c1a01a579b7e080ab8199b11d2d837f7e71e

Change-Id: I493301b9be0da30859882e2ae6d170ba24218c78
",git fetch https://review.opendev.org/openstack/rally refs/changes/48/77948/1 && git format-patch -1 --stdout FETCH_HEAD,['rally/benchmark/context/users.py'],1,af185bb1a27200a687cb3620d8ab16ec2fe4b00b,bp/conrurrent-creation-of-users,"from rally import consts, osclientsPATTERN_TENANT = ""temp_%(run_id)s_tenant_%(iter)i"" PATTERN_USER = ""%(tenant_id)s_user_%(uid)d"" client = osclients.Clients(admin_endpoint).get_keystone_client() tenant = client.tenants.create(PATTERN_TENANT % {""run_id"": run_id, ""iter"": i}) username = PATTERN_USER % {""tenant_id"": tenant.id, ""uid"": user_id} user = client.users.create(username, ""password"", ""%s@email.me"" % username, tenant.id) users_endpoints.append(endpoint.Endpoint(client.auth_url, user.name, ""password"", tenant.name, consts.EndpointPermission.USER)) return (tenant, users, users_endpoints)","from rally import consts tenant = UserGenerator._create_tenant(admin_endpoint, run_id, i) auth_url = utils.create_openstack_clients(admin_endpoint)[""keystone""].auth_url user = UserGenerator._create_user(admin_endpoint, user_id, tenant.id) users_endpoints.append(endpoint.Endpoint(auth_url, user.name, ""password"", tenant.name, consts.EndpointPermission.USER)) return tenant, users, users_endpoints PATTERN_TENANT = ""temp_%(run_id)s_tenant_%(iter)i"" PATTERN_USER = ""%(tenant_id)s_user_%(uid)d"" @classmethod def _create_user(cls, admin_endpoint, user_id, tenant_id): name = cls.PATTERN_USER % {""tenant_id"": tenant_id, ""uid"": user_id} email = ""%s@email.me"" % name return utils.create_openstack_clients(admin_endpoint)[""keystone""]\ .users.create(name, ""password"", email, tenant_id) @classmethod def _create_tenant(cls, admin_endpoint, run_id, i): return utils.create_openstack_clients(admin_endpoint)[""keystone""]\ .tenants.create(cls.PATTERN_TENANT % {""run_id"": run_id, ""iter"": i}) ",11,25
openstack%2Ffuel-astute~master~I0998e04ca56ea5da438fe36d0bf13db02921fd9f,openstack/fuel-astute,master,I0998e04ca56ea5da438fe36d0bf13db02921fd9f,Refactoring post deploy action,MERGED,2014-03-07 09:33:49.000000000,2014-03-07 12:16:45.000000000,2014-03-07 12:16:45.000000000,"[{'_account_id': 3}, {'_account_id': 8749}, {'_account_id': 8776}, {'_account_id': 8971}]","[{'number': 1, 'created': '2014-03-07 09:33:49.000000000', 'files': ['spec/unit/upload_cirros_image_hook_spec.rb', 'spec/unit/post_deploy_actions_spec.rb', 'lib/astute/post_deploy_actions/restart_radosgw.rb', 'spec/unit/update_cluster_hosts_info_hook_spec.rb', 'lib/astute/post_deploy_actions/upload_cirros_image.rb', 'lib/astute/post_deploy_actions/update_cluster_hosts_info.rb', 'lib/astute/post_deploy_actions.rb', 'spec/unit/restart_radosgw_hook_spec.rb', 'lib/astute.rb', 'spec/unit/orchestrator_spec.rb', 'lib/astute/orchestrator.rb'], 'web_link': 'https://opendev.org/openstack/fuel-astute/commit/9f0a2a3135ace2e8d9bf7a4c5f661b8326ace285', 'message': 'Refactoring post deploy action\n\nMove post deploy things from orchestrator to specail classes\n\nChange-Id: I0998e04ca56ea5da438fe36d0bf13db02921fd9f\n'}]",0,78914,9f0a2a3135ace2e8d9bf7a4c5f661b8326ace285,9,4,1,8776,,,0,"Refactoring post deploy action

Move post deploy things from orchestrator to specail classes

Change-Id: I0998e04ca56ea5da438fe36d0bf13db02921fd9f
",git fetch https://review.opendev.org/openstack/fuel-astute refs/changes/14/78914/1 && git format-patch -1 --stdout FETCH_HEAD,"['spec/unit/upload_cirros_image_hook_spec.rb', 'spec/unit/post_deploy_actions_spec.rb', 'lib/astute/post_deploy_actions/restart_radosgw.rb', 'spec/unit/update_cluster_hosts_info_hook_spec.rb', 'lib/astute/post_deploy_actions/update_cluster_hosts_info.rb', 'lib/astute/post_deploy_actions/upload_cirros_image.rb', 'lib/astute/post_deploy_actions.rb', 'spec/unit/restart_radosgw_hook_spec.rb', 'lib/astute.rb', 'spec/unit/orchestrator_spec.rb', 'lib/astute/orchestrator.rb']",11,9f0a2a3135ace2e8d9bf7a4c5f661b8326ace285,refactoring," PostDeployActions.new(deployment_info, context).process"," class CirrosError < AstuteError; end upload_cirros_image(deployment_info, context) update_cluster_hosts_info(deployment_info, context) restart_radosgw(deployment_info, context) def update_cluster_hosts_info(deployment_info, context) Astute.logger.info ""Updating /etc/hosts in all cluster nodes"" return if deployment_info.empty? response = nil deployment_info.first['nodes'].each do |node| upload_mclient = Astute::MClient.new(context, ""uploadfile"", Array(node['uid'])) upload_mclient.upload(:path => ""/tmp/astute.yaml"", :content => deployment_info.first['nodes'].to_yaml, :overwrite => true, :parents => true, :permissions => '0600' ) cmd = <<-UPDATE_HOSTS ruby -r 'yaml' -e 'y = YAML.load_file(""/etc/astute.yaml""); y[""nodes""] = YAML.load_file(""/tmp/astute.yaml""); File.open(""/etc/astute.yaml"", ""w"") { |f| f.write y.to_yaml }'; puppet apply --logdest syslog --debug -e '$settings=parseyaml($::astute_settings_yaml) $nodes_hash=$settings[""nodes""] class {""l23network::hosts_file"": nodes => $nodes_hash }' UPDATE_HOSTS cmd.tr!(""\n"","" "") response = run_shell_command(context, Array(node['uid']), cmd) if response[:data][:exit_code] != 0 Astute.logger.warn ""#{context.task_id}: Fail to update /etc/hosts, ""\ ""check the debugging output for node ""\ ""#{node['uid']} for details"" end end Astute.logger.info ""#{context.task_id}: Updating /etc/hosts is done"" end def restart_radosgw(deployment_info, context) ceph_node = deployment_info.find { |n| n['role'] == 'ceph-osd' } objects_ceph = ceph_node && ceph_node.fetch('storage', {}).fetch('objects_ceph') return unless objects_ceph Astute.logger.info ""Start restarting radosgw on controller nodes"" cmd = <<-RESTART_RADOSGW (test -f /etc/init.d/ceph-radosgw && /etc/init.d/ceph-radosgw restart) || (test -f /etc/init.d/radosgw && /etc/init.d/radosgw restart); radosgw-admin region-map get > /dev/null || radosgw-admin region-map update > /dev/null; (test -f /etc/init.d/ceph-radosgw && /etc/init.d/ceph-radosgw restart) || (test -f /etc/init.d/radosgw && /etc/init.d/radosgw restart); RESTART_RADOSGW cmd.tr!(""\n"","" "") controller_nodes = deployment_info.first['nodes'].inject([]) do |c_n, n| c_n << n['uid'] if ['controller', 'primary-controller'].include? n['role'] c_n end response = run_shell_command(context, controller_nodes, cmd) if response[:data][:exit_code] != 0 Astute.logger.warn ""#{context.task_id}: Fail to restart radosgw, ""\ ""check the debugging output for details"" end Astute.logger.info ""#{context.task_id}: Finish restarting radosgw on controller nodes"" end def upload_cirros_image(deployment_info, context) #FIXME: update context status to multirole support: possible situation where one of the # roles of node fail but if last status - success, we try to run code below. if context.status.has_value?('error') Astute.logger.warn ""Disabling the upload of disk image because deploy ended with an error"" return end controller = deployment_info.find { |n| n['role'] == 'primary-controller' } controller = deployment_info.find { |n| n['role'] == 'controller' } unless controller if controller.nil? Astute.logger.debug(""Could not find controller! Possible adding a new node to the existing cluster?"") return end os = { 'os_tenant_name' => Shellwords.escape(""#{controller['access']['tenant']}""), 'os_username' => Shellwords.escape(""#{controller['access']['user']}""), 'os_password' => Shellwords.escape(""#{controller['access']['password']}""), 'os_auth_url' => ""http://#{controller['management_vip'] || '127.0.0.1'}:5000/v2.0/"", 'disk_format' => 'qcow2', 'container_format' => 'bare', 'public' => 'true', 'img_name' => 'TestVM', 'os_name' => 'cirros' } os['img_path'] = case controller['cobbler']['profile'] when 'centos-x86_64' '/opt/vm/cirros-x86_64-disk.img' when 'rhel-x86_64' '/opt/vm/cirros-x86_64-disk.img' when 'ubuntu_1204_x86_64' '/usr/share/cirros-testvm/cirros-x86_64-disk.img' else raise CirrosError, ""Unknown system #{controller['cobbler']['profile']}"" end auth_params = ""-N #{os['os_auth_url']} \ -T #{os['os_tenant_name']} \ -I #{os['os_username']} \ -K #{os['os_password']}"" cmd = ""/usr/bin/glance #{auth_params} \ index && \ (/usr/bin/glance #{auth_params} \ index | grep #{os['img_name']})"" response = run_shell_command(context, Array(controller['uid']), cmd) if response[:data][:exit_code] == 0 Astute.logger.debug ""Image already added to stack"" else cmd = ""/usr/bin/glance #{auth_params} \ image-create \ --name \'#{os['img_name']}\' \ --is-public #{os['public']} \ --container-format=\'#{os['container_format']}\' \ --disk-format=\'#{os['disk_format']}\' \ --property murano_image_info=\'{\""title\"": \""Murano Demo\"", \""type\"": \""cirros.demo\""}\' \ --file \'#{os['img_path']}\' \ "" response = run_shell_command(context, Array(controller['uid']), cmd) if response[:data][:exit_code] == 0 Astute.logger.info(""#{context.task_id}: Upload cirros image is done"") else msg = 'Upload cirros image failed' Astute.logger.error(""#{context.task_id}: #{msg}"") context.report_and_update_status('nodes' => [ {'uid' => controller['uid'], 'status' => 'error', 'error_type' => 'deploy', 'role' => controller['role'] } ] ) raise CirrosError, msg end end end def run_shell_command(context, node_uids, cmd) shell = MClient.new(context, 'execute_shell_command', node_uids, check_result=true, timeout=60, retries=1) #TODO: return result for all nodes not only for first response = shell.execute(:cmd => cmd).first Astute.logger.debug(""#{context.task_id}: cmd: #{cmd} stdout: #{response[:data][:stdout]} stderr: #{response[:data][:stderr]} exit code: #{response[:data][:exit_code]}"") response end ",590,238
openstack%2Ffuel-astute~master~Id5e9ef54e1d43e6c44d14e75cd27640e19aaeb29,openstack/fuel-astute,master,Id5e9ef54e1d43e6c44d14e75cd27640e19aaeb29,Cobbler managment refactoring,MERGED,2014-03-06 07:56:19.000000000,2014-03-07 12:16:44.000000000,2014-03-07 12:16:44.000000000,"[{'_account_id': 3}, {'_account_id': 8749}, {'_account_id': 8776}, {'_account_id': 8971}]","[{'number': 1, 'created': '2014-03-06 07:56:19.000000000', 'files': ['lib/astute/cobbler_manager.rb', 'lib/astute.rb', 'spec/unit/orchestrator_spec.rb', 'lib/astute/orchestrator.rb'], 'web_link': 'https://opendev.org/openstack/fuel-astute/commit/af98bb1017b71c9b007f33880b1fb36819b83ba8', 'message': 'Cobbler managment refactoring\n\nMove all high level cobbler logics from orchestrator\nto the new special class.\n\nChange-Id: Id5e9ef54e1d43e6c44d14e75cd27640e19aaeb29\n'}]",0,78536,af98bb1017b71c9b007f33880b1fb36819b83ba8,12,4,1,8776,,,0,"Cobbler managment refactoring

Move all high level cobbler logics from orchestrator
to the new special class.

Change-Id: Id5e9ef54e1d43e6c44d14e75cd27640e19aaeb29
",git fetch https://review.opendev.org/openstack/fuel-astute refs/changes/36/78536/1 && git format-patch -1 --stdout FETCH_HEAD,"['lib/astute/cobbler_manager.rb', 'lib/astute.rb', 'spec/unit/orchestrator_spec.rb', 'lib/astute/orchestrator.rb']",4,af98bb1017b71c9b007f33880b1fb36819b83ba8,refactoring," cobbler = CobblerManager.new(engine_attrs, reporter) cobbler.add_nodes(nodes) reboot_events = cobbler.reboot_nodes(nodes) failed_nodes = cobbler.check_reboot_nodes(reboot_events) cobbler = CobblerManager.new(engine_attrs, reporter) cobbler.remove_nodes(nodes)"," engine = create_engine(engine_attrs, reporter) add_nodes_to_cobbler(engine, nodes) reboot_events = reboot_nodes(engine, nodes) failed_nodes = check_reboot_nodes(engine, reboot_events) ensure engine.sync engine = create_engine(engine_attrs, reporter) begin remove_nodes_from_cobbler(engine, nodes) ensure Astute.logger.debug(""Cobbler syncing"") engine.sync end def create_engine(engine_attrs, reporter) raise ""Settings for Cobbler must be set"" if engine_attrs.blank? begin Astute.logger.info(""Trying to instantiate cobbler engine: #{engine_attrs.inspect}"") Astute::Provision::Cobbler.new(engine_attrs) rescue => e Astute.logger.error(""Error occured during cobbler initializing"") reporter.report({ 'status' => 'error', 'error' => 'Cobbler can not be initialized', 'progress' => 100 }) raise e end end def add_nodes_to_cobbler(engine, nodes) nodes.each do |node| cobbler_name = node['slave_name'] begin Astute.logger.info(""Adding #{cobbler_name} into cobbler"") engine.item_from_hash('system', cobbler_name, node, :item_preremove => true) rescue RuntimeError => e Astute.logger.error(""Error occured while adding system #{cobbler_name} to cobbler"") raise e end end # end iteration end def remove_nodes_from_cobbler(engine, nodes) nodes.each do |node| cobbler_name = node['slave_name'] if engine.system_exists?(cobbler_name) Astute.logger.info(""Removing system from cobbler: #{cobbler_name}"") engine.remove_system(cobbler_name) if !engine.system_exists?(cobbler_name) Astute.logger.info(""System has been successfully removed from cobbler: #{cobbler_name}"") else Astute.logger.error(""Cannot remove node from cobbler: #{cobbler_name}"") end else Astute.logger.info(""System is not in cobbler: #{cobbler_name}"") end end end def reboot_nodes(engine, nodes) nodes.inject({}) do |reboot_events, node| cobbler_name = node['slave_name'] Astute.logger.debug(""Trying to reboot node: #{cobbler_name}"") reboot_events.merge(cobbler_name => engine.power_reboot(cobbler_name)) end end def check_reboot_nodes(engine, reboot_events) begin Astute.logger.debug(""Waiting for reboot to be complete: nodes: #{reboot_events.keys}"") failed_nodes = [] Timeout::timeout(Astute.config.REBOOT_TIMEOUT) do while not reboot_events.empty? reboot_events.each do |node_name, event_id| event_status = engine.event_status(event_id) Astute.logger.debug(""Reboot task status: node: #{node_name} status: #{event_status}"") if event_status[2] =~ /^failed$/ Astute.logger.error(""Error occured while trying to reboot: #{node_name}"") reboot_events.delete(node_name) failed_nodes << node_name elsif event_status[2] =~ /^complete$/ Astute.logger.debug(""Successfully rebooted: #{node_name}"") reboot_events.delete(node_name) end end sleep(5) end end rescue Timeout::Error => e Astute.logger.debug(""Reboot timeout: reboot tasks not completed for nodes #{reboot_events.keys}"") raise e end failed_nodes end ",120,98
openstack%2Frally~master~I5fedbebd06b3eef691917d0cd9a755476e25ba51,openstack/rally,master,I5fedbebd06b3eef691917d0cd9a755476e25ba51,don't delete network during benchmark,MERGED,2014-03-07 06:36:48.000000000,2014-03-07 12:03:05.000000000,2014-03-07 12:03:05.000000000,"[{'_account_id': 3}, {'_account_id': 6172}, {'_account_id': 7217}, {'_account_id': 8507}]","[{'number': 1, 'created': '2014-03-07 06:36:48.000000000', 'files': ['rally/benchmark/utils.py', 'rally/benchmark/context/cleaner.py'], 'web_link': 'https://opendev.org/openstack/rally/commit/e3d26a6f5a402be14aea0d2040d05cf40cecc855', 'message': ""don't delete network during benchmark\n\nIn scenarios, no users create networks so we don't need delete anyone\nnow.\n\nChange-Id: I5fedbebd06b3eef691917d0cd9a755476e25ba51\nCloses-Bug: #1288762\n""}]",0,78871,e3d26a6f5a402be14aea0d2040d05cf40cecc855,9,4,1,6835,,,0,"don't delete network during benchmark

In scenarios, no users create networks so we don't need delete anyone
now.

Change-Id: I5fedbebd06b3eef691917d0cd9a755476e25ba51
Closes-Bug: #1288762
",git fetch https://review.opendev.org/openstack/rally refs/changes/71/78871/1 && git format-patch -1 --stdout FETCH_HEAD,"['rally/benchmark/utils.py', 'rally/benchmark/context/cleaner.py']",2,e3d26a6f5a402be14aea0d2040d05cf40cecc855,bug/1288762, LOG.warning(_('Unable to fully cleanup the cloud: %s') %, LOG.warning(_('Unable to fully cleanup the cloud: \n%s') %,1,8
openstack%2Frally~master~I90d6acc8764c2873ccb2530cfaa5f886bf25678e,openstack/rally,master,I90d6acc8764c2873ccb2530cfaa5f886bf25678e,Add git branches support in DevstackEngine,MERGED,2014-03-05 14:08:19.000000000,2014-03-07 11:50:27.000000000,2014-03-07 11:50:27.000000000,"[{'_account_id': 3}, {'_account_id': 6172}, {'_account_id': 7217}, {'_account_id': 7369}]","[{'number': 1, 'created': '2014-03-05 14:08:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/05e568854d5cccff1e0173210642ee1c6f8eeeb8', 'message': 'Add git branches support in DevstackEngine\n\nAdd devstack_branch option in configuration file. (devstack_repo is\nalready supported)\n\nChange-Id: I90d6acc8764c2873ccb2530cfaa5f886bf25678e\n'}, {'number': 2, 'created': '2014-03-07 09:38:00.000000000', 'files': ['tests/deploy/engines/test_devstack.py', 'rally/deploy/engines/devstack/install.sh', 'rally/deploy/engines/devstack.py'], 'web_link': 'https://opendev.org/openstack/rally/commit/55fcab0dfab98c71ad3dcdfbf542072a4562b546', 'message': 'Add git branches support in DevstackEngine\n\nAdd devstack_branch option in configuration file. (devstack_repo is\nalready supported)\n\nChange-Id: I90d6acc8764c2873ccb2530cfaa5f886bf25678e\n'}]",0,78225,55fcab0dfab98c71ad3dcdfbf542072a4562b546,12,4,2,7369,,,0,"Add git branches support in DevstackEngine

Add devstack_branch option in configuration file. (devstack_repo is
already supported)

Change-Id: I90d6acc8764c2873ccb2530cfaa5f886bf25678e
",git fetch https://review.opendev.org/openstack/rally refs/changes/25/78225/1 && git format-patch -1 --stdout FETCH_HEAD,"['tests/deploy/engines/test_devstack.py', 'rally/deploy/engines/devstack/install.sh', 'rally/deploy/engines/devstack.py']",3,05e568854d5cccff1e0173210642ee1c6f8eeeb8,devstack-fixes,"DEVSTACK_BRANCH = 'master' 'devstack_branch': {'type': 'string'}, devstack_branch = self.config.get('devstack_branch', DEVSTACK_BRANCH) cmd = '/bin/sh -e -s %s %s' % (devstack_repo, devstack_branch) server.ssh.run(cmd, stdin=get_script('install.sh'))"," server.ssh.run('/bin/sh -e -s %s' % devstack_repo, stdin=get_script('install.sh'))",10,6
openstack%2Fmanila~master~I6f9f7d9b1218825ae143161508d25ea4d1514b31,openstack/manila,master,I6f9f7d9b1218825ae143161508d25ea4d1514b31,Let DevStack plugin get python executable path,MERGED,2014-03-04 07:11:11.000000000,2014-03-07 11:48:24.000000000,2014-03-07 11:48:24.000000000,"[{'_account_id': 3}, {'_account_id': 7534}, {'_account_id': 7917}, {'_account_id': 8851}, {'_account_id': 9521}]","[{'number': 1, 'created': '2014-03-04 07:11:11.000000000', 'files': ['contrib/devstack/lib/manila'], 'web_link': 'https://opendev.org/openstack/manila/commit/7217b770ed7e602f7aeb63d89c2efb5cabdefe27', 'message': ""Let DevStack plugin get python executable path\n\nGet the path of the directory where Manila's python executables are\ninstalled by default in other distros - Fedora and SUSE\n\nChange-Id: I6f9f7d9b1218825ae143161508d25ea4d1514b31\n""}]",0,77806,7217b770ed7e602f7aeb63d89c2efb5cabdefe27,9,5,1,8056,,,0,"Let DevStack plugin get python executable path

Get the path of the directory where Manila's python executables are
installed by default in other distros - Fedora and SUSE

Change-Id: I6f9f7d9b1218825ae143161508d25ea4d1514b31
",git fetch https://review.opendev.org/openstack/manila refs/changes/06/77806/1 && git format-patch -1 --stdout FETCH_HEAD,['contrib/devstack/lib/manila'],1,7217b770ed7e602f7aeb63d89c2efb5cabdefe27,devstack_plugin, MANILA_BIN_DIR=$(get_python_exec_prefix), MANILA_BIN_DIR=/usr/local/bin,1,1
openstack%2Frally~master~I7ca039c91fbeeeb004445848e6834a9925435e63,openstack/rally,master,I7ca039c91fbeeeb004445848e6834a9925435e63,Fix cleanup in DevstackEngine,MERGED,2014-02-03 14:06:58.000000000,2014-03-07 11:47:07.000000000,2014-03-07 11:47:07.000000000,"[{'_account_id': 3}, {'_account_id': 1531}, {'_account_id': 6172}, {'_account_id': 7217}, {'_account_id': 7369}, {'_account_id': 8507}]","[{'number': 1, 'created': '2014-02-03 14:06:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/57c2d0456c28968d6124f5bfd25f3a317dfed1b2', 'message': 'Run ./unstack.sh on cleanup in DevstackEngine\n\nAlso minor code cleanup:\n\n do git pull if ~/devstack directory already exists\n removed methods prepare_server, configure_devstack and start_devstak\n added methods get_script and get_updated_server\n\nFixes bug 1275653\n\nChange-Id: I7ca039c91fbeeeb004445848e6834a9925435e63\n'}, {'number': 2, 'created': '2014-02-03 17:55:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/098f0e7177dc6f10256cbaa97ce6dadd510db4e0', 'message': 'Run ./unstack.sh on cleanup in DevstackEngine\n\nAlso minor code cleanup:\n\n do git pull if ~/devstack directory already exists\n removed methods prepare_server, configure_devstack and start_devstak\n added methods get_script and get_updated_server\n\nFixes bug 1275653\n\nChange-Id: I7ca039c91fbeeeb004445848e6834a9925435e63\n'}, {'number': 3, 'created': '2014-02-04 14:46:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/8c8869952307af345828133365494f79b653b9ec', 'message': 'Run ./unstack.sh on cleanup in DevstackEngine\n\nAlso minor code cleanup:\n\n do git pull if ~/devstack directory already exists\n removed methods prepare_server, configure_devstack and start_devstak\n added methods get_script and get_updated_server\n\nFixes bug 1275653\n\nChange-Id: I7ca039c91fbeeeb004445848e6834a9925435e63\n'}, {'number': 4, 'created': '2014-02-04 15:05:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/1d849eec7019afafca24fb4a2756de49e220bba4', 'message': 'Run ./unstack.sh on cleanup in DevstackEngine\n\nAlso minor code cleanup:\n\n do git pull if ~/devstack directory already exists\n removed methods prepare_server, configure_devstack and start_devstak\n added methods get_script and get_updated_server\n\nFixes bug 1275653\n\nChange-Id: I7ca039c91fbeeeb004445848e6834a9925435e63\n'}, {'number': 5, 'created': '2014-02-17 10:26:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/2ce89bd3780ea6facdc0931c4158995da93a0406', 'message': 'Fix cleanup in DevstackEngine\n\nAlso minor code cleanup:\n\n do git pull if ~/devstack directory already exists\n removed methods prepare_server, configure_devstack and start_devstak\n added methods get_script and get_updated_server\n\nFixes bug 1275653\n\nChange-Id: I7ca039c91fbeeeb004445848e6834a9925435e63\n'}, {'number': 6, 'created': '2014-02-17 10:33:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/3bf5350803fbf7154aaa1ecbbbf5a89fc8ef08b6', 'message': 'Fix cleanup in DevstackEngine\n\nAlso minor code cleanup:\n\n do git pull if ~/devstack directory already exists\n removed methods prepare_server, configure_devstack and start_devstak\n added methods get_script and get_updated_server\n\nFixes bug 1275653\n\nChange-Id: I7ca039c91fbeeeb004445848e6834a9925435e63\n'}, {'number': 7, 'created': '2014-02-17 16:44:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/f8baa63cda275033feb91148d6d1ddb3d3ec110f', 'message': 'Fix cleanup in DevstackEngine\n\nAlso minor code cleanup:\n\n do git pull if ~/devstack directory already exists\n removed methods prepare_server, configure_devstack and start_devstak\n added methods get_script and get_updated_server\n\nFixes bug 1275653\n\nChange-Id: I7ca039c91fbeeeb004445848e6834a9925435e63\n'}, {'number': 8, 'created': '2014-02-18 11:28:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/d854d77f2239d7c45c88172a2c90167bc31f09e8', 'message': 'Fix cleanup in DevstackEngine\n\nAlso minor code cleanup:\n\n do git pull if ~/devstack directory already exists\n removed methods prepare_server, configure_devstack and start_devstak\n added methods get_script and get_updated_server\n\nFixes bug 1275653\n\nChange-Id: I7ca039c91fbeeeb004445848e6834a9925435e63\n'}, {'number': 9, 'created': '2014-02-27 12:25:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/66e0e6b4089f12e855eb1d7b3852d5145ed52637', 'message': 'Fix cleanup in DevstackEngine\n\nAlso minor code cleanup:\n\n do git pull if ~/devstack directory already exists\n removed methods prepare_server, configure_devstack and start_devstak\n added methods get_script and get_updated_server\n\nFixes bug 1275653\n\nChange-Id: I7ca039c91fbeeeb004445848e6834a9925435e63\n'}, {'number': 10, 'created': '2014-03-05 14:08:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/255392ef40adc7ce3779c63a8f2de1279dc7b50f', 'message': 'Fix cleanup in DevstackEngine\n\nAlso minor code cleanup:\n\n do git pull if ~/devstack directory already exists\n removed methods prepare_server, configure_devstack and start_devstak\n added methods get_script and get_updated_server\n\nFixes bug 1275653\n\nChange-Id: I7ca039c91fbeeeb004445848e6834a9925435e63\n'}, {'number': 11, 'created': '2014-03-07 09:38:00.000000000', 'files': ['tests/deploy/engines/test_devstack.py', 'rally/deploy/engines/devstack/install.sh', 'rally/deploy/engines/devstack.py'], 'web_link': 'https://opendev.org/openstack/rally/commit/3472e7c0ab76a80730701e502bba5b861081eeab', 'message': 'Fix cleanup in DevstackEngine\n\nAlso minor code cleanup:\n\n do git pull if ~/devstack directory already exists\n removed methods prepare_server, configure_devstack and start_devstak\n added methods get_script and get_updated_server\n\nFixes bug 1275653\n\nChange-Id: I7ca039c91fbeeeb004445848e6834a9925435e63\n'}]",0,70727,3472e7c0ab76a80730701e502bba5b861081eeab,45,6,11,7369,,,0,"Fix cleanup in DevstackEngine

Also minor code cleanup:

 do git pull if ~/devstack directory already exists
 removed methods prepare_server, configure_devstack and start_devstak
 added methods get_script and get_updated_server

Fixes bug 1275653

Change-Id: I7ca039c91fbeeeb004445848e6834a9925435e63
",git fetch https://review.opendev.org/openstack/rally refs/changes/27/70727/10 && git format-patch -1 --stdout FETCH_HEAD,"['tests/deploy/engines/test_devstack.py', 'rally/deploy/engines/devstack/install.sh', 'rally/deploy/engines/devstack.py']",3,57c2d0456c28968d6124f5bfd25f3a317dfed1b2,devstack-fixes,"def get_script(name): return open(os.path.join(os.path.abspath( os.path.dirname(__file__)), 'devstack', name), 'rb') def get_updated_server(server, **kwargs): credentials = server.get_credentials() credentials.update(kwargs) return provider.Server.from_credentials(credentials) devstack_repo = self.config.get('devstack_repo', DEVSTACK_REPO) localrc = '' for k, v in self.localrc.iteritems(): localrc += '%s=%s\n' % (k, v) for server in self.servers: self.deployment.add_resource(provider_name='DevstackEngine', type='credentials', info=server.get_credentials()) server.ssh.run('/bin/sh -e -s %s' % devstack_repo, stdin=get_script('install.sh')) devstack_server = get_updated_server(server, user=DEVSTACK_USER) devstack_server.ssh.run(""cat > ~/devstack/localrc"", stdin=localrc) devstack_server.ssh.run('~/devstack/stack.sh') for resource in self.deployment.get_resources(type='credentials'): server = provider.Server.from_credentials(resource.info) devstack_server = get_updated_server(server, user=DEVSTACK_USER) devstack_server.ssh.run('~/devstack/unstack.sh') self._vm_provider.destroy_servers() self.deployment.delete_resource(resource.id)","import StringIO @utils.log_deploy_wrapper(LOG.info, _(""Prepare server for devstack"")) def prepare_server(self, server): script_path = os.path.abspath(os.path.join(os.path.dirname(__file__), 'devstack', 'install.sh')) server.ssh.run('/bin/sh -e', stdin=open(script_path, 'rb')) for server in self.servers: self.prepare_server(server) credentials = server.get_credentials() credentials['user'] = DEVSTACK_USER devstack_server = provider.Server.from_credentials(credentials) self.configure_devstack(devstack_server) self.start_devstack(devstack_server) self._vm_provider.destroy_servers() @utils.log_deploy_wrapper(LOG.info, _(""Configure devstack"")) def configure_devstack(self, server): devstack_repo = self.config.get('devstack_repo', DEVSTACK_REPO) server.ssh.run('git clone %s' % devstack_repo) localrc = StringIO.StringIO() for k, v in self.localrc.iteritems(): localrc.write('%s=%s\n' % (k, v)) localrc.seek(0) server.ssh.run(""cat > ~/devstack/localrc"", stdin=localrc) return True @utils.log_deploy_wrapper(LOG.info, _(""Run devstack"")) def start_devstack(self, server): server.ssh.run('~/devstack/stack.sh') return True",70,86
openstack%2Fdjango_openstack_auth~master~I534050b7d90f85b631c066d3596a6238eaa23458,openstack/django_openstack_auth,master,I534050b7d90f85b631c066d3596a6238eaa23458,Replace oslo.sphinx dep with oslosphinx,ABANDONED,2014-03-07 11:35:46.000000000,2014-03-07 11:37:18.000000000,,[{'_account_id': 3}],"[{'number': 1, 'created': '2014-03-07 11:35:46.000000000', 'files': ['test-requirements.txt'], 'web_link': 'https://opendev.org/openstack/django_openstack_auth/commit/13405b99399113607d06e9499cfb19f8fbbfcd52', 'message': 'Replace oslo.sphinx dep with oslosphinx\n\nWas renamed a while ago\n\nChange-Id: I534050b7d90f85b631c066d3596a6238eaa23458\n'}]",0,78940,13405b99399113607d06e9499cfb19f8fbbfcd52,3,1,1,4375,,,0,"Replace oslo.sphinx dep with oslosphinx

Was renamed a while ago

Change-Id: I534050b7d90f85b631c066d3596a6238eaa23458
",git fetch https://review.opendev.org/openstack/django_openstack_auth refs/changes/40/78940/1 && git format-patch -1 --stdout FETCH_HEAD,['test-requirements.txt'],1,13405b99399113607d06e9499cfb19f8fbbfcd52,master-oslosphinx,oslosphinx,oslo.sphinx,1,1
openstack%2Frally~master~I5582144058c1a1db069b5b5f32d13b70ab246cb6,openstack/rally,master,I5582144058c1a1db069b5b5f32d13b70ab246cb6,fix secgroup in benchmark context,ABANDONED,2014-03-07 09:53:45.000000000,2014-03-07 11:34:07.000000000,,[{'_account_id': 3}],"[{'number': 1, 'created': '2014-03-07 09:53:45.000000000', 'files': ['rally/benchmark/context/secgroup.py'], 'web_link': 'https://opendev.org/openstack/rally/commit/885ca8fcb80656c2bfa8b581105df90d47ff7524', 'message': ""fix secgroup in benchmark context\n\nIn origin codes, secgroup context tried to put same rules in one\nsecgroup which caused errors. Actually accourding to entering instance\nvia ssh, we just need one secgroup and one keypair for every\ntenant/project. So this patch doesn't create secgroups depend on users.\n\nChange-Id: I5582144058c1a1db069b5b5f32d13b70ab246cb6\nCloses-Bug: #1288763\n""}]",0,78917,885ca8fcb80656c2bfa8b581105df90d47ff7524,3,1,1,6835,,,0,"fix secgroup in benchmark context

In origin codes, secgroup context tried to put same rules in one
secgroup which caused errors. Actually accourding to entering instance
via ssh, we just need one secgroup and one keypair for every
tenant/project. So this patch doesn't create secgroups depend on users.

Change-Id: I5582144058c1a1db069b5b5f32d13b70ab246cb6
Closes-Bug: #1288763
",git fetch https://review.opendev.org/openstack/rally refs/changes/17/78917/1 && git format-patch -1 --stdout FETCH_HEAD,['rally/benchmark/context/secgroup.py'],1,885ca8fcb80656c2bfa8b581105df90d47ff7524,bug/1288763," self.keypair = None endpoint = self.context['admin']['endpoint'] secgroup, keypair = _prepare_for_instance_ssh(endpoint) self.keypair = keypair self.secgroup.append(secgroup) except Exception as e: LOG.warning(""Unable to delete secgroup %s: %s"" % (secgroup.id, e))"," for user in self.context[""users""]: secgroup, keypair = _prepare_for_instance_ssh(user[""endpoint""]) user[""keypair""] = keypair self.secgroup.append(secgroup) except Exception: LOG.warrning(""Unable to delete secgroup: %s"" % secgroup.id)",8,6
openstack%2Ftaskflow~master~I4572052f63647472367cb69fc02911bbec2bd4cc,openstack/taskflow,master,I4572052f63647472367cb69fc02911bbec2bd4cc,Introduce remote tasks cache for worker-executor,MERGED,2014-03-06 16:49:32.000000000,2014-03-07 11:24:45.000000000,2014-03-07 11:24:45.000000000,"[{'_account_id': 3}, {'_account_id': 1297}, {'_account_id': 7349}, {'_account_id': 7366}, {'_account_id': 8895}]","[{'number': 1, 'created': '2014-03-06 16:49:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/29a135fe438d104ba38f35ba81c9e7c0dc4bbf44', 'message': 'Introduce remote tasks cache for worker-executor\n\nUpdated WorkerTaskExecutor to use cache for remote tasks.\n\nChange-Id: I4572052f63647472367cb69fc02911bbec2bd4cc\n'}, {'number': 2, 'created': '2014-03-07 10:56:26.000000000', 'files': ['taskflow/engines/worker_based/executor.py', 'taskflow/engines/worker_based/cache.py', 'taskflow/tests/unit/worker_based/test_executor.py'], 'web_link': 'https://opendev.org/openstack/taskflow/commit/ae28f0ba4b267bc3addc8978a11f7b686d1fe573', 'message': 'Introduce remote tasks cache for worker-executor\n\nUpdated WorkerTaskExecutor to use cache for remote tasks.\n\nChange-Id: I4572052f63647472367cb69fc02911bbec2bd4cc\n'}]",0,78664,ae28f0ba4b267bc3addc8978a11f7b686d1fe573,14,5,2,8895,,,0,"Introduce remote tasks cache for worker-executor

Updated WorkerTaskExecutor to use cache for remote tasks.

Change-Id: I4572052f63647472367cb69fc02911bbec2bd4cc
",git fetch https://review.opendev.org/openstack/taskflow refs/changes/64/78664/1 && git format-patch -1 --stdout FETCH_HEAD,"['taskflow/engines/worker_based/executor.py', 'taskflow/engines/worker_based/cache.py', 'taskflow/tests/unit/worker_based/test_executor.py']",3,29a135fe438d104ba38f35ba81c9e7c0dc4bbf44,remote-tasks-cache," ex._remote_tasks_cache.set(self.task_uuid, self.remote_task_mock) ex._remote_tasks_cache.set(self.task_uuid, self.remote_task_mock) ex._remote_tasks_cache.set(self.task_uuid, self.remote_task_mock) self.assertEqual(len(ex._remote_tasks_cache._data), 0) ex._remote_tasks_cache.set(self.task_uuid, self.remote_task_mock) ex._remote_tasks_cache.set(self.task_uuid, self.remote_task_mock) ex._remote_tasks_cache.set(self.task_uuid, self.remote_task_mock) ex._remote_tasks_cache.set(self.task_uuid, self.remote_task_mock) def test_on_wait_task_not_expired(self, mocked_time): mocked_time.side_effect = [1, self.timeout] ex._remote_tasks_cache.set(self.task_uuid, self.remote_task()) self.assertEqual(len(ex._remote_tasks_cache._data), 1) self.assertEqual(len(ex._remote_tasks_cache._data), 1) def test_on_wait_task_expired(self, mocked_time): mocked_time.side_effect = [1, self.timeout + 2, self.timeout * 2] ex._remote_tasks_cache.set(self.task_uuid, self.remote_task()) self.assertEqual(len(ex._remote_tasks_cache._data), 1) self.assertEqual(len(ex._remote_tasks_cache._data), 0) ex._remote_tasks_cache.set(self.task_uuid, task) self.assertEqual(len(ex._remote_tasks_cache._data), 1) ex._remote_tasks_cache.delete(self.task_uuid) self.assertEqual(len(ex._remote_tasks_cache._data), 0) ex._remote_tasks_cache.delete(self.task_uuid) self.assertEqual(len(ex._remote_tasks_cache._data), 0)"," ex._store_remote_task(self.remote_task_mock) ex._store_remote_task(self.remote_task_mock) ex._store_remote_task(self.remote_task_mock) self.assertEqual(len(ex._remote_tasks), 0) ex._store_remote_task(self.remote_task_mock) ex._store_remote_task(self.remote_task_mock) ex._store_remote_task(self.remote_task_mock) ex._store_remote_task(self.remote_task_mock) def test_on_wait_task_not_expired(self, mock_time): mock_time.side_effect = [1, self.timeout] ex._store_remote_task(self.remote_task()) self.assertEqual(len(ex._remote_tasks), 1) self.assertEqual(len(ex._remote_tasks), 1) def test_on_wait_task_expired(self, mock_time): mock_time.side_effect = [1, self.timeout + 2, self.timeout * 2] ex._store_remote_task(self.remote_task()) self.assertEqual(len(ex._remote_tasks), 1) self.assertEqual(len(ex._remote_tasks), 0) ex._store_remote_task(task) self.assertEqual(len(ex._remote_tasks), 1) ex._remove_remote_task(task) self.assertEqual(len(ex._remote_tasks), 0) ex._remove_remote_task(task) self.assertEqual(len(ex._remote_tasks), 0)",106,64
openstack%2Ffuel-main~master~I8809e0b332365b77d4b161e4b0fe0dcfe2afb6d0,openstack/fuel-main,master,I8809e0b332365b77d4b161e4b0fe0dcfe2afb6d0,Remove version for rabbitmq-server,MERGED,2014-02-27 16:16:31.000000000,2014-03-07 11:19:15.000000000,2014-03-07 11:19:15.000000000,"[{'_account_id': 3}, {'_account_id': 406}, {'_account_id': 8777}, {'_account_id': 8789}, {'_account_id': 8971}, {'_account_id': 9387}, {'_account_id': 10474}]","[{'number': 1, 'created': '2014-02-27 16:16:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/c9ff824254737ca6d8d0ce61ec3e439fe93fa19e', 'message': 'Remove version for rabbitmq-server\n\nChange-Id: I8809e0b332365b77d4b161e4b0fe0dcfe2afb6d0\n'}, {'number': 2, 'created': '2014-03-02 21:53:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/037c71d5bfdeeb7efecbc297f9c24cae1eb3f895', 'message': ""Remove version for rabbitmq-server\n\nNeed for issue OSCI-1077. it's related to https://bugs.launchpad.net/fuel/+bug/1279594\n\nChange-Id: I8809e0b332365b77d4b161e4b0fe0dcfe2afb6d0\n""}, {'number': 3, 'created': '2014-03-02 22:35:42.000000000', 'files': ['requirements-rpm.txt'], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/44802a6c7c8a9a5e1ea027108a2c069c9d85b793', 'message': 'Remove version for rabbitmq-server\n\nRelated-Bug: #1279594\n\nChange-Id: I8809e0b332365b77d4b161e4b0fe0dcfe2afb6d0\n'}]",0,76906,44802a6c7c8a9a5e1ea027108a2c069c9d85b793,29,7,3,8777,,,0,"Remove version for rabbitmq-server

Related-Bug: #1279594

Change-Id: I8809e0b332365b77d4b161e4b0fe0dcfe2afb6d0
",git fetch https://review.opendev.org/openstack/fuel-main refs/changes/06/76906/1 && git format-patch -1 --stdout FETCH_HEAD,['requirements-rpm.txt'],1,c9ff824254737ca6d8d0ce61ec3e439fe93fa19e,(detached,rabbitmq-server,rabbitmq-server-2.8.7-2.el6,1,1
openstack%2Ftaskflow~master~I8d6fdbf06625daad7a886ff87607b31f369062b8,openstack/taskflow,master,I8d6fdbf06625daad7a886ff87607b31f369062b8,Worker-based engine clean-ups,MERGED,2014-03-06 15:08:09.000000000,2014-03-07 11:18:00.000000000,2014-03-07 11:18:00.000000000,"[{'_account_id': 3}, {'_account_id': 1297}, {'_account_id': 7349}, {'_account_id': 7366}, {'_account_id': 8895}]","[{'number': 1, 'created': '2014-03-06 15:08:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/5d59bc920351f545606a6f8bef62ddbc9865230b', 'message': 'Worker-based engine clean-ups\n\n* Auto-delete queues, redundant proxy logic removed;\n* Updated unit tests;\n* Small fixes in comments.\n\nChange-Id: I8d6fdbf06625daad7a886ff87607b31f369062b8\n'}, {'number': 2, 'created': '2014-03-07 10:32:20.000000000', 'files': ['taskflow/engines/worker_based/proxy.py', 'taskflow/tests/unit/worker_based/test_proxy.py', 'taskflow/engines/worker_based/endpoint.py', 'taskflow/engines/worker_based/protocol.py', 'taskflow/engines/worker_based/worker.py'], 'web_link': 'https://opendev.org/openstack/taskflow/commit/014fc96d5a41d4227484484b055e87ace7e72cf7', 'message': 'Worker-based engine clean-ups\n\n* Auto-delete queues, redundant proxy logic removed;\n* Updated unit tests;\n* Small fixes in comments.\n\nChange-Id: I8d6fdbf06625daad7a886ff87607b31f369062b8\n'}]",0,78623,014fc96d5a41d4227484484b055e87ace7e72cf7,13,5,2,8895,,,0,"Worker-based engine clean-ups

* Auto-delete queues, redundant proxy logic removed;
* Updated unit tests;
* Small fixes in comments.

Change-Id: I8d6fdbf06625daad7a886ff87607b31f369062b8
",git fetch https://review.opendev.org/openstack/taskflow refs/changes/23/78623/2 && git format-patch -1 --stdout FETCH_HEAD,"['taskflow/engines/worker_based/proxy.py', 'taskflow/tests/unit/worker_based/test_proxy.py', 'taskflow/engines/worker_based/endpoint.py', 'taskflow/engines/worker_based/protocol.py', 'taskflow/engines/worker_based/worker.py']",5,5d59bc920351f545606a6f8bef62ddbc9865230b,wbe-cleanups," :keyword transport: transport to be used (e.g. amqp, memory, etc.) :keyword transport_options: transport specific options"," :keyword transport: broker transport to be used (e.g. amqp, memory, etc.) :keyword transport_options: broker transport options",21,113
openstack%2Fmanila~master~I8389bf38868ca9cb69f33dd06f8e7a444d461eba,openstack/manila,master,I8389bf38868ca9cb69f33dd06f8e7a444d461eba,Fix DevStack plugin's source collection issue,MERGED,2014-03-04 12:32:09.000000000,2014-03-07 11:07:36.000000000,2014-03-07 11:07:35.000000000,"[{'_account_id': 3}, {'_account_id': 7534}, {'_account_id': 7917}, {'_account_id': 8851}, {'_account_id': 9521}]","[{'number': 1, 'created': '2014-03-04 12:32:09.000000000', 'files': ['contrib/devstack/lib/manila'], 'web_link': 'https://opendev.org/openstack/manila/commit/39e80deb8d6026897cf9f8d3bc0217b76546195b', 'message': ""Fix DevStack plugin's source collection issue\n\nAllow initial collection of sources even when RECLONE option is not\nset to TRUE in localrc\n\nChange-Id: I8389bf38868ca9cb69f33dd06f8e7a444d461eba\n""}]",0,77870,39e80deb8d6026897cf9f8d3bc0217b76546195b,9,5,1,8056,,,0,"Fix DevStack plugin's source collection issue

Allow initial collection of sources even when RECLONE option is not
set to TRUE in localrc

Change-Id: I8389bf38868ca9cb69f33dd06f8e7a444d461eba
",git fetch https://review.opendev.org/openstack/manila refs/changes/70/77870/1 && git format-patch -1 --stdout FETCH_HEAD,['contrib/devstack/lib/manila'],1,39e80deb8d6026897cf9f8d3bc0217b76546195b,devstack_plugin, git_clone $MANILA_REPO $MANILA_DIR $MANILA_BRANCH git_clone $MANILACLIENT_REPO $MANILACLIENT_DIR $MANILACLIENT_BRANCH," if [[ ""$RECLONE"" = ""True"" ]]; then git_clone $MANILA_REPO $MANILA_DIR $MANILA_BRANCH git_clone $MANILACLIENT_REPO $MANILACLIENT_DIR $MANILACLIENT_BRANCH fi",2,4
openstack%2Fdevstack~master~I01507b142703a1ff66707464b9a743e9d0ca3e01,openstack/devstack,master,I01507b142703a1ff66707464b9a743e9d0ca3e01,Inject all account details in tempest.conf,MERGED,2014-03-05 13:42:28.000000000,2014-03-07 10:48:06.000000000,2014-03-07 01:54:32.000000000,"[{'_account_id': 3}, {'_account_id': 970}, {'_account_id': 1921}, {'_account_id': 2750}, {'_account_id': 5689}]","[{'number': 1, 'created': '2014-03-05 13:42:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack/commit/ef3c448ef689b46daa2e30cd5dd3976910d09ce8', 'message': 'Inject all account details in tempest.conf\n\nThe tempest configuration function did not inject all account\ndetails in tempest.conf. The only reason why it worked, was\nbecause tempest uses default config values which are valid for\nthe current devstack setup.\n\nTo remove this dependency, two patches are needed:\n- this one in devstack, to inject all values\n- https://review.openstack.org/#/c/77602/ in tempest, to change\n  default values to None\n\nPartially fixes bug 1287191\n\nChange-Id: I01507b142703a1ff66707464b9a743e9d0ca3e01\n'}, {'number': 2, 'created': '2014-03-05 22:59:18.000000000', 'files': ['lib/tempest'], 'web_link': 'https://opendev.org/openstack/devstack/commit/d46d9dd8de00d07eee9170365b1a025f0fc01ed9', 'message': 'Inject all account details in tempest.conf\n\nThe tempest configuration function did not inject all account\ndetails in tempest.conf. The only reason why it worked, was\nbecause tempest uses default config values which are valid for\nthe current devstack setup.\n\nTo remove this dependency, two patches are needed:\n- this one in devstack, to inject all values\n- https://review.openstack.org/#/c/77602/ in tempest, to change\n  default values to None\n\nPartially fixes bug 1287191\n\nChange-Id: I01507b142703a1ff66707464b9a743e9d0ca3e01\n'}]",0,78221,d46d9dd8de00d07eee9170365b1a025f0fc01ed9,18,5,2,1921,,,0,"Inject all account details in tempest.conf

The tempest configuration function did not inject all account
details in tempest.conf. The only reason why it worked, was
because tempest uses default config values which are valid for
the current devstack setup.

To remove this dependency, two patches are needed:
- this one in devstack, to inject all values
- https://review.openstack.org/#/c/77602/ in tempest, to change
  default values to None

Partially fixes bug 1287191

Change-Id: I01507b142703a1ff66707464b9a743e9d0ca3e01
",git fetch https://review.opendev.org/openstack/devstack refs/changes/21/78221/2 && git format-patch -1 --stdout FETCH_HEAD,['lib/tempest'],1,ef3c448ef689b46daa2e30cd5dd3976910d09ce8,bug/1287191," # See files/keystone_data.sh and stack.sh where admin, demo and alt_demo # user and tenant are set up... ADMIN_USERNAME=${ADMIN_USERNAME:-admin} ADMIN_TENANT_NAME=${ADMIN_TENANT_NAME:-admin} USERNAME=${USERNAME:-demo} TENANT_NAME=${TENANT_NAME:-demo} iniset $TEMPEST_CONFIG identity username $USERNAME iniset $TEMPEST_CONFIG identity tenant_name $TENANT_NAME iniset $TEMPEST_CONFIG identity admin_username $ADMIN_USERNAME iniset $TEMPEST_CONFIG identity admin_tenant_name $ADMIN_TENANT_NAME iniset $TEMPEST_CONFIG ""compute-admin"" username $USERNAME iniset $TEMPEST_CONFIG ""compute-admin"" tenant_name $TENANT_NAME", # See files/keystone_data.sh where alt_demo user # and tenant are set up...,12,2
openstack%2Ftempest~master~Ia3c82d416962dad446390b82780978ddaf03f1b2,openstack/tempest,master,Ia3c82d416962dad446390b82780978ddaf03f1b2,Skip nova cli tests with volumes if Cinder unavailable,MERGED,2014-03-05 18:12:36.000000000,2014-03-07 10:27:44.000000000,2014-03-07 10:27:43.000000000,"[{'_account_id': 3}, {'_account_id': 159}, {'_account_id': 5803}, {'_account_id': 6167}, {'_account_id': 7139}]","[{'number': 1, 'created': '2014-03-05 18:12:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/696a81839e432e0b53b461758c1000f54ec939c9', 'message': 'Skip nova cli tests with volumes if Cinder unavailable\n\nThe nova cli tests for volumes will fail if Cinder is\nnot being tested. As it is allowable to skip Cinder tests,\nwe should skip these tests in that eventuality.\n\nChange-Id: Ia3c82d416962dad446390b82780978ddaf03f1b2\nCloses-Bug: #1288373\n'}, {'number': 2, 'created': '2014-03-05 18:19:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/fa3e26fca7b518cc0b5272374b8f2227ba975ada', 'message': 'Skip nova cli tests with volumes if Cinder unavailable\n\nThe nova cli tests for volumes will fail if Cinder is\nnot being tested. As it is allowable to skip Cinder tests,\nwe should skip these tests in that eventuality.\n\nChange-Id: Ia3c82d416962dad446390b82780978ddaf03f1b2\nCloses-Bug: #1288373\n'}, {'number': 3, 'created': '2014-03-06 16:27:13.000000000', 'files': ['tempest/cli/simple_read_only/test_nova.py'], 'web_link': 'https://opendev.org/openstack/tempest/commit/36ab3d3efffe5eb174819515403e885949028a08', 'message': 'Skip nova cli tests with volumes if Cinder unavailable\n\nThe nova cli tests for volumes will fail if Cinder is\nnot being tested. As it is allowable to skip Cinder tests,\nwe should skip these tests in that eventuality.\n\nChange-Id: Ia3c82d416962dad446390b82780978ddaf03f1b2\nCloses-Bug: #1288373\n'}]",1,78336,36ab3d3efffe5eb174819515403e885949028a08,16,5,3,159,,,0,"Skip nova cli tests with volumes if Cinder unavailable

The nova cli tests for volumes will fail if Cinder is
not being tested. As it is allowable to skip Cinder tests,
we should skip these tests in that eventuality.

Change-Id: Ia3c82d416962dad446390b82780978ddaf03f1b2
Closes-Bug: #1288373
",git fetch https://review.opendev.org/openstack/tempest refs/changes/36/78336/1 && git format-patch -1 --stdout FETCH_HEAD,['tempest/cli/simple_read_only/test_nova.py'],1,696a81839e432e0b53b461758c1000f54ec939c9,cli-skip-volume," if not CONF.service_available.cinder: msg = (""%s skipped as Cinder is not available"" % cls.__name__) raise cls.skipException(msg) if not CONF.service_available.cinder: msg = (""%s skipped as Cinder is not available"" % cls.__name__) raise cls.skipException(msg) if not CONF.service_available.cinder: msg = (""%s skipped as Cinder is not available"" % cls.__name__) raise cls.skipException(msg)",,9,0
openstack%2Fmanila~master~I4317ed0559564b080ee302929e09d0ce466a72de,openstack/manila,master,I4317ed0559564b080ee302929e09d0ce466a72de,Switched devstack plugin to use generic driver,MERGED,2014-02-19 10:07:19.000000000,2014-03-07 09:50:11.000000000,2014-03-07 09:50:11.000000000,"[{'_account_id': 3}, {'_account_id': 2417}, {'_account_id': 6094}, {'_account_id': 7173}, {'_account_id': 7534}, {'_account_id': 8056}, {'_account_id': 8863}, {'_account_id': 9521}]","[{'number': 1, 'created': '2014-02-19 10:07:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/manila/commit/879b79793aa66eafc1c001c28f6ba979e379db2b', 'message': 'Added support of ssh keys to devstack plugin\n\nOne another step to make devstack plugin closer to port\ndefault installation with multitenant generic driver,\nthat uses ssh keys for connecting to service VMs.\n\nChange-Id: I4317ed0559564b080ee302929e09d0ce466a72de\n'}, {'number': 2, 'created': '2014-02-27 11:28:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/manila/commit/95b63b68ebbbe9a202fcd5fb0c92e0715bac82ba', 'message': 'Switched devstack plugin to use generic driver\n\nCurrently devstack uses lvm driver, this commit switches devstack to use generic\ndriver and creates all dependent by generic driver stuff.\nBut there is blocker bug, that should be fixed before merging\nthis commit: #1285612\n\nChange-Id: I4317ed0559564b080ee302929e09d0ce466a72de\n'}, {'number': 3, 'created': '2014-03-05 13:37:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/manila/commit/3ba06822924d4261553178f0f52c43a402ad4e57', 'message': 'Switched devstack plugin to use generic driver\n\nCurrently devstack uses lvm driver, this commit switches devstack to use generic\ndriver and creates all dependent by generic driver stuff.\n\nChange-Id: I4317ed0559564b080ee302929e09d0ce466a72de\n'}, {'number': 4, 'created': '2014-03-05 15:48:58.000000000', 'files': ['contrib/devstack/extras.d/70-manila.sh', 'contrib/devstack/lib/manila'], 'web_link': 'https://opendev.org/openstack/manila/commit/3c5500cfdb2c2f86b95d4f69e9ca9fb3b8fd9f33', 'message': 'Switched devstack plugin to use generic driver\n\nCurrently devstack uses lvm driver, this commit switches devstack to use generic\ndriver and creates all dependent by generic driver stuff.\n\nChange-Id: I4317ed0559564b080ee302929e09d0ce466a72de\n'}]",0,74647,3c5500cfdb2c2f86b95d4f69e9ca9fb3b8fd9f33,26,8,4,8851,,,0,"Switched devstack plugin to use generic driver

Currently devstack uses lvm driver, this commit switches devstack to use generic
driver and creates all dependent by generic driver stuff.

Change-Id: I4317ed0559564b080ee302929e09d0ce466a72de
",git fetch https://review.opendev.org/openstack/manila refs/changes/47/74647/4 && git format-patch -1 --stdout FETCH_HEAD,['contrib/devstack/lib/manila'],1,879b79793aa66eafc1c001c28f6ba979e379db2b,master,"# These are used by generic driver for ssh'ing to Manila's service VMs PATH_TO_PUBLIC_KEY=${PATH_TO_PUBLIC_KEY:-""~/.ssh/id_rsa.pub""} PATH_TO_PRIVATE_KEY=${PATH_TO_PRIVATE_KEY:-""~/.ssh/id_rsa""} iniset $MANILA_CONF DEFAULT path_to_public_key $PATH_TO_PUBLIC_KEY iniset $MANILA_CONF DEFAULT path_to_private_key $PATH_TO_PRIVATE_KEY", iniset $MANILA_CONF DEFAULT path_to_key /home/stack/.ssh/id_rsa.pub,7,1
openstack%2Frally~master~Ie85a32b87417f34b9852b231a4fb0dfcf303e991,openstack/rally,master,Ie85a32b87417f34b9852b231a4fb0dfcf303e991,Updated from global requirements,MERGED,2014-03-05 19:31:49.000000000,2014-03-07 09:34:42.000000000,2014-03-07 09:34:42.000000000,"[{'_account_id': 3}, {'_account_id': 8507}]","[{'number': 1, 'created': '2014-03-05 19:31:49.000000000', 'files': ['requirements.txt'], 'web_link': 'https://opendev.org/openstack/rally/commit/3f3d62902ed2949814480bb2fcde14b35c293713', 'message': 'Updated from global requirements\n\nChange-Id: Ie85a32b87417f34b9852b231a4fb0dfcf303e991\n'}]",0,78388,3f3d62902ed2949814480bb2fcde14b35c293713,9,2,1,3,,,0,"Updated from global requirements

Change-Id: Ie85a32b87417f34b9852b231a4fb0dfcf303e991
",git fetch https://review.opendev.org/openstack/rally refs/changes/88/78388/1 && git format-patch -1 --stdout FETCH_HEAD,['requirements.txt'],1,3f3d62902ed2949814480bb2fcde14b35c293713,openstack/requirements,python-novaclient>=2.16.0,python-novaclient>=2.15.0,1,1
openstack%2Fcinder~master~I54bd06d94a330d3fca6d627564dbb6129e2bb175,openstack/cinder,master,I54bd06d94a330d3fca6d627564dbb6129e2bb175,Add conversion types in some strings,ABANDONED,2014-03-07 09:33:40.000000000,2014-03-07 09:34:22.000000000,,[{'_account_id': 3}],"[{'number': 1, 'created': '2014-03-07 09:33:40.000000000', 'files': ['cinder/volume/drivers/ibm/gpfs.py', 'cinder/volume/drivers/nexenta/iscsi.py', 'cinder/zonemanager/drivers/brocade/brcd_fc_san_lookup_service.py', 'cinder/brick/iscsi/iscsi.py', 'cinder/volume/drivers/ibm/storwize_svc/helpers.py'], 'web_link': 'https://opendev.org/openstack/cinder/commit/2a40f17f8416e026bd167d8715dee24429631429', 'message': ""Add conversion types in some strings\n\nSome strings have no conversion types for 'String Formatting\nOperations'.\n\nChange-Id: I54bd06d94a330d3fca6d627564dbb6129e2bb175\nCloses-Bug: #1289230\n""}]",0,78913,2a40f17f8416e026bd167d8715dee24429631429,2,1,1,7236,,,0,"Add conversion types in some strings

Some strings have no conversion types for 'String Formatting
Operations'.

Change-Id: I54bd06d94a330d3fca6d627564dbb6129e2bb175
Closes-Bug: #1289230
",git fetch https://review.opendev.org/openstack/cinder refs/changes/13/78913/1 && git format-patch -1 --stdout FETCH_HEAD,"['cinder/volume/drivers/ibm/gpfs.py', 'cinder/volume/drivers/nexenta/iscsi.py', 'cinder/zonemanager/drivers/brocade/brcd_fc_san_lookup_service.py', 'cinder/brick/iscsi/iscsi.py', 'cinder/volume/drivers/ibm/storwize_svc/helpers.py']",5,2a40f17f8416e026bd167d8715dee24429631429,bug/XXX, '%(vol_name)s to host %(host)s found.') %, '%(vol_name)s to host %(host) found.') %,8,8
openstack%2Fopenstack-manuals~master~I8e7ba80124d8409410b03724ac6ab336355935e8,openstack/openstack-manuals,master,I8e7ba80124d8409410b03724ac6ab336355935e8,Removed extraneous packages from Nova controller section,MERGED,2014-03-07 01:44:51.000000000,2014-03-07 09:30:08.000000000,2014-03-07 09:30:08.000000000,"[{'_account_id': 3}, {'_account_id': 612}, {'_account_id': 6547}]","[{'number': 1, 'created': '2014-03-07 01:44:51.000000000', 'files': ['doc/install-guide/section_nova-controller.xml'], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/8c442aef4ae437003ec301509c0e64b77aff2743', 'message': ""Removed extraneous packages from Nova controller section\n\nOn Ubuntu, I removed the following extraneous packages from the list\nof packages to install:\n\nnova-ajax-console-proxy\nnova-doc\nnovnc\n\nI also combined the Ubuntu and Debian steps since they install the\nsame packages.\n\nOn RHEL-style distributions, the 'openstack-nova' meta-package also\ninstalls compute services not necessary on the controller node. I\nreplaced this meta-package with the individual packages containing\nonly the controller services.\n\nChange-Id: I8e7ba80124d8409410b03724ac6ab336355935e8\nCloses-Bug: #1287918\nCloses-Bug: #1287969\n""}]",0,78832,8c442aef4ae437003ec301509c0e64b77aff2743,13,3,1,9515,,,0,"Removed extraneous packages from Nova controller section

On Ubuntu, I removed the following extraneous packages from the list
of packages to install:

nova-ajax-console-proxy
nova-doc
novnc

I also combined the Ubuntu and Debian steps since they install the
same packages.

On RHEL-style distributions, the 'openstack-nova' meta-package also
installs compute services not necessary on the controller node. I
replaced this meta-package with the individual packages containing
only the controller services.

Change-Id: I8e7ba80124d8409410b03724ac6ab336355935e8
Closes-Bug: #1287918
Closes-Bug: #1287969
",git fetch https://review.opendev.org/openstack/openstack-manuals refs/changes/32/78832/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/install-guide/section_nova-controller.xml'],1,8c442aef4ae437003ec301509c0e64b77aff2743,bug/1287918," <para>Install the Compute packages necessary for the controller node.</para> <screen os=""fedora;rhel;centos""><prompt>#</prompt> <userinput>yum install openstack-nova-api openstack-nova-cert openstack-nova-conductor \ openstack-nova-console openstack-nova-novncproxy openstack-nova-scheduler \ <screen os=""ubuntu;debian""><prompt>#</prompt> <userinput>apt-get install nova-api nova-cert nova-conductor nova-consoleauth \ nova-novncproxy nova-scheduler python-novaclient</userinput></screen>"," <para os=""fedora;rhel;centos"">Install the <package>openstack-nova</package> meta-package, which installs various Compute packages that are used on the controller node.</para> <screen os=""fedora;rhel;centos""><prompt>#</prompt> <userinput>yum install openstack-nova python-novaclient</userinput></screen> <para os=""ubuntu;debian;opensuse;sles"">Install these Compute packages, which provide the Compute services that run on the controller node.</para> <screen os=""ubuntu""><prompt>#</prompt> <userinput>apt-get install nova-novncproxy novnc nova-api \ nova-ajax-console-proxy nova-cert nova-conductor \ nova-consoleauth nova-doc nova-scheduler \ <screen os=""debian""><prompt>#</prompt> <userinput>apt-get install nova-consoleproxy nova-api \ nova-cert nova-conductor nova-consoleauth \ nova-scheduler python-novaclient</userinput></screen> ",6,16
openstack%2Frally~master~Ia77e517843711d729ade3c0e232edf1b9a8f725e,openstack/rally,master,Ia77e517843711d729ade3c0e232edf1b9a8f725e,Add count to atomic actions display,MERGED,2014-02-28 17:29:45.000000000,2014-03-07 09:28:39.000000000,2014-03-07 09:28:39.000000000,"[{'_account_id': 3}, {'_account_id': 6172}, {'_account_id': 8507}, {'_account_id': 9556}]","[{'number': 1, 'created': '2014-02-28 17:29:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/28fee7e3b2302b74738bcbb0a915d5acff1d06bb', 'message': 'Add count to atomic actions display\n\nShows how many times each atomic action was executed.\n\nChange-Id: Ia77e517843711d729ade3c0e232edf1b9a8f725e\n'}, {'number': 2, 'created': '2014-02-28 17:29:45.000000000', 'files': ['rally/cmd/commands/task.py'], 'web_link': 'https://opendev.org/openstack/rally/commit/199731d186c7b3e82cf368978e06c9cd39a512b4', 'message': 'Add count to atomic actions display\n\nShows how many times each atomic action was executed.\n\nChange-Id: Ia77e517843711d729ade3c0e232edf1b9a8f725e\n'}]",0,77228,199731d186c7b3e82cf368978e06c9cd39a512b4,20,4,2,7217,,,0,"Add count to atomic actions display

Shows how many times each atomic action was executed.

Change-Id: Ia77e517843711d729ade3c0e232edf1b9a8f725e
",git fetch https://review.opendev.org/openstack/rally refs/changes/28/77228/1 && git format-patch -1 --stdout FETCH_HEAD,['rally/cmd/commands/task.py'],1,28fee7e3b2302b74738bcbb0a915d5acff1d06bb,count_to_atomic_actions," 'count', len(v),",,2,0
openstack%2Ffuel-web~master~I3b3a43ece073e9a7bacd981abe80bdd233236b4a,openstack/fuel-web,master,I3b3a43ece073e9a7bacd981abe80bdd233236b4a,Corrections to architecture doc,MERGED,2014-03-03 11:11:22.000000000,2014-03-07 09:27:16.000000000,2014-03-07 09:27:15.000000000,"[{'_account_id': 3}, {'_account_id': 7195}, {'_account_id': 8789}, {'_account_id': 8971}, {'_account_id': 9037}]","[{'number': 1, 'created': '2014-03-03 11:11:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/78209fad25d62e43f8855a6bc16f2a503f0a5e70', 'message': 'Some corrections to architecture doc\n\nChange-Id: I3b3a43ece073e9a7bacd981abe80bdd233236b4a\n'}, {'number': 2, 'created': '2014-03-03 11:21:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/59265dfc50ce387393a84555b01e865b9da43788', 'message': 'Corrections to architecture doc\n\nChange-Id: I3b3a43ece073e9a7bacd981abe80bdd233236b4a\n'}, {'number': 3, 'created': '2014-03-04 15:20:12.000000000', 'files': ['docs/develop/architecture.rst'], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/6c6ecde08ab754e5f5751a8466930bca1ffa7091', 'message': 'Corrections to architecture doc\n\nChange-Id: I3b3a43ece073e9a7bacd981abe80bdd233236b4a\n'}]",4,77566,6c6ecde08ab754e5f5751a8466930bca1ffa7091,23,5,3,9037,,,0,"Corrections to architecture doc

Change-Id: I3b3a43ece073e9a7bacd981abe80bdd233236b4a
",git fetch https://review.opendev.org/openstack/fuel-web refs/changes/66/77566/1 && git format-patch -1 --stdout FETCH_HEAD,['docs/develop/architecture.rst'],1,78209fad25d62e43f8855a6bc16f2a503f0a5e70,arch,"runs the special script called Nailgun agent. The agent **fencing-agent.rb** collects the server's hardware information and submits it to Nailgun through the REST API.a new environment. The Nailgun service creates a JSON data structure with the environment settings, its nodes and their roles and puts thisservers are started on all bootstrapped nodes and they constantly listen for these messages, when they receive a message they run the requiredthe Puppet process in the background using the **daemonize** tool. The command looks like this: :: daemonize puppet apply /etc/puppet/manifests/site.pp"" Puppet installs **puppet-run** script. Developers can use it if they need to manually synchronize manifests from the Master node and run Puppet process on node again. * During network verification phase **net_verify.py** script.","runs the Nailgun agent. It's a special script that collects the server's hardware information and submits it to Nailgun through the REST API.a new environment. The Nailgun service creates a JSON file with the environment settings, its nodes and their roles and puts thisservers are started on all bootstraped nodes and they constantly listen for these messages, when they recieve a message they run the requiredthe Puppet process in the background using the **daemonize** tool and",18,7
openstack%2Fhorizon~milestone-proposed~I3b9b36e9a6caa8960a6598f13d7f21ddadb9a306,openstack/horizon,milestone-proposed,I3b9b36e9a6caa8960a6598f13d7f21ddadb9a306,Updated from global requirements,ABANDONED,2014-03-06 10:32:52.000000000,2014-03-07 09:24:57.000000000,,"[{'_account_id': 3}, {'_account_id': 841}, {'_account_id': 4978}, {'_account_id': 6610}, {'_account_id': 6914}]","[{'number': 1, 'created': '2014-03-06 10:32:52.000000000', 'files': ['requirements.txt', 'test-requirements.txt'], 'web_link': 'https://opendev.org/openstack/horizon/commit/24bd027d17d5101a8d606db30f51dbc399ebe987', 'message': 'Updated from global requirements\n\nChange-Id: I3b9b36e9a6caa8960a6598f13d7f21ddadb9a306\n(cherry picked from commit 8716814494fe2e1454f7737246a65aa1efb0ebb9)\n'}]",0,78571,24bd027d17d5101a8d606db30f51dbc399ebe987,8,5,1,4978,,,0,"Updated from global requirements

Change-Id: I3b9b36e9a6caa8960a6598f13d7f21ddadb9a306
(cherry picked from commit 8716814494fe2e1454f7737246a65aa1efb0ebb9)
",git fetch https://review.opendev.org/openstack/horizon refs/changes/71/78571/1 && git format-patch -1 --stdout FETCH_HEAD,"['requirements.txt', 'test-requirements.txt']",2,24bd027d17d5101a8d606db30f51dbc399ebe987,requirements-update,"docutils==0.9.1sphinx>=1.1.2,<1.2","docutils==0.9.1 # for bug 1091333, remove after sphinx >1.1.3 is released.sphinx>=1.1.2,<1.2 # Docs Requirements",3,3
openstack%2Ffuel-web~master~I4b5c3f0bab0f670ff6be1e9af54250cf084b28f7,openstack/fuel-web,master,I4b5c3f0bab0f670ff6be1e9af54250cf084b28f7,Development documentation on DB migrations,MERGED,2014-03-04 12:11:48.000000000,2014-03-07 09:16:53.000000000,2014-03-07 09:16:52.000000000,"[{'_account_id': 3}, {'_account_id': 7195}, {'_account_id': 8053}, {'_account_id': 8392}, {'_account_id': 8749}, {'_account_id': 8789}, {'_account_id': 8971}, {'_account_id': 10014}]","[{'number': 1, 'created': '2014-03-04 12:11:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/4c54d968cab9087265f550b8794938f203deaf06', 'message': 'Development documentation on DB migrations\n\nChange-Id: I4b5c3f0bab0f670ff6be1e9af54250cf084b28f7\n'}, {'number': 2, 'created': '2014-03-04 14:30:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/4817171a4841e1bba6569da1bf2705bf92acb1e7', 'message': 'Development documentation on DB migrations\n\nChange-Id: I4b5c3f0bab0f670ff6be1e9af54250cf084b28f7\n'}, {'number': 3, 'created': '2014-03-04 15:06:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/ba31d9fa75f9e6c67ffb58d7fe5dabdb65bc2170', 'message': 'Development documentation on DB migrations\n\nCloses-Bug: #1286126\n\nChange-Id: I4b5c3f0bab0f670ff6be1e9af54250cf084b28f7\n'}, {'number': 4, 'created': '2014-03-07 09:04:00.000000000', 'files': ['docs/develop/env.rst'], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/c42df1f12a66e45bc5e3553a781d94fe74018a66', 'message': 'Development documentation on DB migrations\n\nCloses-Bug: #1286126\n\nChange-Id: I4b5c3f0bab0f670ff6be1e9af54250cf084b28f7\n'}]",16,77866,c42df1f12a66e45bc5e3553a781d94fe74018a66,36,8,4,8053,,,0,"Development documentation on DB migrations

Closes-Bug: #1286126

Change-Id: I4b5c3f0bab0f670ff6be1e9af54250cf084b28f7
",git fetch https://review.opendev.org/openstack/fuel-web refs/changes/66/77866/4 && git format-patch -1 --stdout FETCH_HEAD,['docs/develop/env.rst'],1,4c54d968cab9087265f550b8794938f203deaf06,doc_migrations,"Nailgun database migrations --------------------------- Nailgun uses Alembic (http://alembic.readthedocs.org/en/latest/) for database migrations, so all common Alembic commands are now accessible through ""python manage.py migrate"" subcommand. This command mentioned above creates DB tables for Nailgun service:: python manage.py syncdb This is done by applying one by one a number of database migration files, which are located in nailgun/nailgun/db/migration/alembic_migrations/versions. After that even if you're making some changes in SQLAlchemy models or creating the new ones, this command won't create corresponding DB tables unless you created another migration file or updated an existing one. New migration file may be created by running:: python manage.py migrate revision -m ""Revision message"" --autogenerate There are two important points here: 1) This command always created a ""diff"" between current database state and the one described by your SQLAlchemy models. So if you're running it with an empty database - it will create migration including creation of all tables from the scratch. Thus, it should always be preceded by ""python manage.py syncdb"" 2) There are some changes, for example, adding new value to ENUM field, which may not be detected by ""--autogenerate"" option, so you will need to add them to migration file manually. After creating migration file, you can upgrade database to a new state by using this command:: python manage.py migrate upgrade +1 To merge your migration into an existing one, you can just move lines of code from it's ""upgrade()"" and ""downgrade()"" methods to the bottom of corresponding ones in previous migration file. In current release this migration file is called ""current.py"". For all additional features and needs you may refer to Alembic documentation: http://alembic.readthedocs.org/en/latest/tutorial.html ",,45,0
openstack%2Frally~master~I94e1bd89bdd61e707bb68a880937c7e8bc8dec63,openstack/rally,master,I94e1bd89bdd61e707bb68a880937c7e8bc8dec63,Make lxc ssh port fowarding optional,MERGED,2014-02-13 11:40:21.000000000,2014-03-07 09:10:47.000000000,2014-03-07 09:10:46.000000000,"[{'_account_id': 3}, {'_account_id': 6172}, {'_account_id': 7217}, {'_account_id': 7369}, {'_account_id': 8507}]","[{'number': 1, 'created': '2014-02-13 11:40:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/9697692b7523889e4ce42c05bea3615fdf56cd02', 'message': 'Make lxc ssh port fowarding optional\n\nIf some cases this can lead to non-working deployment e.g. when\ncontroller is deployed in lxc container. In this cases only\ntunneling will work.\n\nAlso LOG.debug stdin data in sshclient.\n\nChange-Id: I94e1bd89bdd61e707bb68a880937c7e8bc8dec63\n'}, {'number': 2, 'created': '2014-02-18 11:28:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/c0babafd0aa12c130023c2440f36b250077d3cf3', 'message': 'Make lxc ssh port fowarding optional\n\nIf some cases this can lead to non-working deployment e.g. when\ncontroller is deployed in lxc container. In this cases only\ntunneling will work.\n\nAlso LOG.debug stdin data in sshclient.\n\nChange-Id: I94e1bd89bdd61e707bb68a880937c7e8bc8dec63\n'}, {'number': 3, 'created': '2014-02-27 12:25:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/08c52bda7cefd764dfef6fff57bfdbb9876c049e', 'message': 'Make lxc ssh port fowarding optional\n\nIf some cases this can lead to non-working deployment e.g. when\ncontroller is deployed in lxc container. In this cases only\ntunneling will work.\n\nAlso LOG.debug stdin data in sshclient.\n\nChange-Id: I94e1bd89bdd61e707bb68a880937c7e8bc8dec63\n'}, {'number': 4, 'created': '2014-03-05 14:40:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/e9f6cc711561426712168be123a9ae13903e73c4', 'message': 'Make lxc ssh port fowarding optional\n\nIf some cases this can lead to non-working deployment e.g. when\ncontroller is deployed in lxc container. In this cases only\ntunneling will work.\n\nAlso LOG.debug stdin data in sshclient.\n\nChange-Id: I94e1bd89bdd61e707bb68a880937c7e8bc8dec63\n'}, {'number': 5, 'created': '2014-03-05 14:40:41.000000000', 'files': ['rally/serverprovider/providers/lxc.py', 'rally/sshutils.py', 'tests/serverprovider/providers/test_lxc.py'], 'web_link': 'https://opendev.org/openstack/rally/commit/055ff920ddfde86ba3dccd41eb0fcc65ef5d8b96', 'message': 'Make lxc ssh port fowarding optional\n\nIf some cases this can lead to non-working deployment e.g. when\ncontroller is deployed in lxc container. In this cases only\ntunneling will work.\n\nAlso LOG.debug stdin data in sshclient.\n\nChange-Id: I94e1bd89bdd61e707bb68a880937c7e8bc8dec63\n'}]",0,73247,055ff920ddfde86ba3dccd41eb0fcc65ef5d8b96,26,5,5,7369,,,0,"Make lxc ssh port fowarding optional

If some cases this can lead to non-working deployment e.g. when
controller is deployed in lxc container. In this cases only
tunneling will work.

Also LOG.debug stdin data in sshclient.

Change-Id: I94e1bd89bdd61e707bb68a880937c7e8bc8dec63
",git fetch https://review.opendev.org/openstack/rally refs/changes/47/73247/2 && git format-patch -1 --stdout FETCH_HEAD,"['rally/serverprovider/providers/lxc.py', 'rally/sshutils.py', 'tests/serverprovider/providers/test_lxc.py']",3,9697692b7523889e4ce42c05bea3615fdf56cd02,bug/1276949," 'forward_ssh': True,",,23,3
openstack%2Fpuppet-neutron~master~Id8c116212132b6d75ae14019fc6a65447f226c6d,openstack/puppet-neutron,master,Id8c116212132b6d75ae14019fc6a65447f226c6d,Don't sync database by default,MERGED,2014-03-06 20:44:53.000000000,2014-03-07 09:04:41.000000000,2014-03-07 08:11:41.000000000,"[{'_account_id': 3}, {'_account_id': 3153}, {'_account_id': 6967}, {'_account_id': 7156}]","[{'number': 1, 'created': '2014-03-06 20:44:53.000000000', 'files': ['spec/classes/neutron_server_spec.rb', 'manifests/server.pp'], 'web_link': 'https://opendev.org/openstack/puppet-neutron/commit/0229d358ae45add73a0a8f4658632b54fd56be12', 'message': ""Don't sync database by default\n\nhttps://review.openstack.org/#/c/76358 introduced a new sync_db\nparameter and set it to true by default.  Unfortunately there\nseem to be many cases where this causes problems.  One is when\nusing the OVS plugin with the [database] section stored in\nneutron.conf rather than in the ovs_neutron_plugin.ini file.\nIn such cases the migration will error out with due to being\nunable to connect.  This is particularly problematic for users\nin that no changes to the composition layer are necessary to\nhit the error since sync_db is set to true by default: to avoid\nthe problem they need to make composition layer change to explicitly\nset it to false.  This patch resolves the problem by setting the\nparameter to false by default rather than true.  This enables\nusers who want the migration to run to do so without impacting\nusers who haven't been expecting the new behavior.\n\nChange-Id: Id8c116212132b6d75ae14019fc6a65447f226c6d\nCloses-Bug: #1288975\n""}]",0,78752,0229d358ae45add73a0a8f4658632b54fd56be12,9,4,1,6754,,,0,"Don't sync database by default

https://review.openstack.org/#/c/76358 introduced a new sync_db
parameter and set it to true by default.  Unfortunately there
seem to be many cases where this causes problems.  One is when
using the OVS plugin with the [database] section stored in
neutron.conf rather than in the ovs_neutron_plugin.ini file.
In such cases the migration will error out with due to being
unable to connect.  This is particularly problematic for users
in that no changes to the composition layer are necessary to
hit the error since sync_db is set to true by default: to avoid
the problem they need to make composition layer change to explicitly
set it to false.  This patch resolves the problem by setting the
parameter to false by default rather than true.  This enables
users who want the migration to run to do so without impacting
users who haven't been expecting the new behavior.

Change-Id: Id8c116212132b6d75ae14019fc6a65447f226c6d
Closes-Bug: #1288975
",git fetch https://review.opendev.org/openstack/puppet-neutron refs/changes/52/78752/1 && git format-patch -1 --stdout FETCH_HEAD,"['spec/classes/neutron_server_spec.rb', 'manifests/server.pp']",2,0229d358ae45add73a0a8f4658632b54fd56be12,bugs/1288975,"# Defaults to false $sync_db = false,","# Defaults to true $sync_db = true,",13,13
openstack%2Ftempest~master~I8448de16d2243bd08db50562eb2714e07b62ea63,openstack/tempest,master,I8448de16d2243bd08db50562eb2714e07b62ea63,"Add ""Nova V3 API test for add-fixed-IP/remove-fixed-IP""",MERGED,2014-02-26 05:10:00.000000000,2014-03-07 08:53:03.000000000,2014-03-04 16:09:17.000000000,"[{'_account_id': 3}, {'_account_id': 5689}, {'_account_id': 5803}, {'_account_id': 6167}, {'_account_id': 8205}, {'_account_id': 8556}]","[{'number': 1, 'created': '2014-02-26 05:10:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/aafc24c0e85088dca7d358853feb7dac9098344b', 'message': 'Add ""V3 API- add-fixed-IP and remove-fixed-IP server action"" tests\n\nThis patch adds ""V3 API - add-fixed-IP and remove-fixed-IP"" tests.\n\nChange-Id: I8448de16d2243bd08db50562eb2714e07b62ea63\n'}, {'number': 2, 'created': '2014-02-27 02:22:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/a1900a8a4b70702468b82bad3b0104ca24637775', 'message': 'Add ""V3 API- add-fixed-IP and remove-fixed-IP server action"" tests\n\nThis patch adds ""V3 API - add-fixed-IP and remove-fixed-IP"" tests.\n\nChange-Id: I8448de16d2243bd08db50562eb2714e07b62ea63\n'}, {'number': 3, 'created': '2014-02-27 03:15:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/a21aa58a504de74306d7009d488addd53ca8868a', 'message': 'Add ""V3 API- add-fixed-IP and remove-fixed-IP server action"" tests\n\nThis patch adds ""V3 API - add-fixed-IP and remove-fixed-IP"" tests.\n\nChange-Id: I8448de16d2243bd08db50562eb2714e07b62ea63\n'}, {'number': 4, 'created': '2014-02-28 05:32:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/235db65296d3a2c0c7e710682d66eaaa8a6618a8', 'message': 'Add ""Nova V3 API test for add-fixed-IP/remove-fixed-IP""\n\nThis patch adds Nova V3 API test for add-fixed-IP/remove-fixed-IP.\n\nChange-Id: I8448de16d2243bd08db50562eb2714e07b62ea63\n'}, {'number': 5, 'created': '2014-02-28 07:07:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/bb55dce535b32d9b180d2f0dcdb171f90c38cce5', 'message': 'Add ""Nova V3 API test for add-fixed-IP/remove-fixed-IP""\n\nThis patch adds Nova V3 API test for add-fixed-IP/remove-fixed-IP.\n\nChange-Id: I8448de16d2243bd08db50562eb2714e07b62ea63\n'}, {'number': 6, 'created': '2014-03-03 02:31:11.000000000', 'files': ['tempest/services/compute/v3/json/interfaces_client.py', 'tempest/api/compute/v3/servers/test_attach_interfaces.py'], 'web_link': 'https://opendev.org/openstack/tempest/commit/60c240251343dcee897a9e98fee7a114efd028b0', 'message': 'Add ""Nova V3 API test for add-fixed-IP/remove-fixed-IP""\n\nThis patch adds Nova V3 API test for add-fixed-IP/remove-fixed-IP.\n\nChange-Id: I8448de16d2243bd08db50562eb2714e07b62ea63\n'}]",4,76435,60c240251343dcee897a9e98fee7a114efd028b0,33,6,6,8556,,,0,"Add ""Nova V3 API test for add-fixed-IP/remove-fixed-IP""

This patch adds Nova V3 API test for add-fixed-IP/remove-fixed-IP.

Change-Id: I8448de16d2243bd08db50562eb2714e07b62ea63
",git fetch https://review.opendev.org/openstack/tempest refs/changes/35/76435/4 && git format-patch -1 --stdout FETCH_HEAD,"['tempest/api/compute/v3/servers/test_server_actions.py', 'tempest/services/compute/v3/json/servers_client.py']",2,aafc24c0e85088dca7d358853feb7dac9098344b,patch_fixed_ip_v3," def add_fixed_ip(self, server_id, network_id): """"""Add a fixed IP to input server instance."""""" post_body = json.dumps({ ""add_fixed_ip"": { ""network_id"": network_id } }) resp, body = self.post('servers/%s/action' % str(server_id), post_body) return resp, body def remove_fixed_ip(self, server_id, ip_address): """"""Remove input fixed IP from input server instance."""""" post_body = json.dumps({ ""remove_fixed_ip"": { ""address"": ip_address } }) resp, body = self.post('servers/%s/action' % str(server_id), post_body) return resp, body",,50,0
openstack-attic%2Fidentity-api~master~Icf20169b50fb2b47b2565107572ba5fdd4dd8dda,openstack-attic/identity-api,master,Icf20169b50fb2b47b2565107572ba5fdd4dd8dda,Cleanup User V3 documentation,MERGED,2014-02-27 16:49:48.000000000,2014-03-07 08:44:38.000000000,2014-03-07 08:44:38.000000000,"[{'_account_id': 3}, {'_account_id': 5046}, {'_account_id': 6482}, {'_account_id': 6547}]","[{'number': 1, 'created': '2014-02-27 16:49:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack-attic/identity-api/commit/386bc6d053c53d55278ade712a20d13f3b4d772f', 'message': 'Cleanup User V3 documentation\n\nUse more realistic examples in the V3 user documentation.\n\nChange-Id: Icf20169b50fb2b47b2565107572ba5fdd4dd8dda\n'}, {'number': 2, 'created': '2014-02-28 18:49:38.000000000', 'files': ['openstack-identity-api/v3/src/markdown/identity-api-v3.md'], 'web_link': 'https://opendev.org/openstack-attic/identity-api/commit/8d0e00975f49e15ae3874067c1e2c126f60e1fe1', 'message': 'Cleanup User V3 documentation\n\nUse more realistic examples in the V3 user documentation.\n\nChange-Id: Icf20169b50fb2b47b2565107572ba5fdd4dd8dda\n'}]",2,76913,8d0e00975f49e15ae3874067c1e2c126f60e1fe1,14,4,2,5046,,,0,"Cleanup User V3 documentation

Use more realistic examples in the V3 user documentation.

Change-Id: Icf20169b50fb2b47b2565107572ba5fdd4dd8dda
",git fetch https://review.opendev.org/openstack-attic/identity-api refs/changes/13/76913/1 && git format-patch -1 --stdout FETCH_HEAD,['openstack-identity-api/v3/src/markdown/identity-api-v3.md'],1,386bc6d053c53d55278ade712a20d13f3b4d772f,user-doc-cleanup," ""default_project_id"": ""263fd9"", ""description"": ""Admin user"", ""email"": ""admin@example.com"", ""id"": ""0ca8f6"", ""links"": { ""self"": ""https://identity:35357/v3/users/0ca8f6"" ""default_project_id"": ""263fd9"", ""description"": ""John Smith's user"", ""email"": ""jsmith@example.com"", ""id"": ""9fe1d3"", ""links"": { ""self"": ""https://identity:35357/v3/users/9fe1d3"" ""name"": ""jsmith"" ""default_project_id"": ""263fd9"", ""description"": ""John Smith's user"", ""email"": ""jsmith@example.com"", ""id"": ""9fe1d3"", ""links"": { ""self"": ""https://identity:35357/v3/users/9fe1d3"" ""name"": ""jsmith"" ""domain_id"": ""1789d1"", ""id"": ""263fd9"", ""links"": { ""self"": ""https://identity:35357/v3/projects/263fd9"" ""name"": ""Project X"" ""domain_id"": ""1789d1"", ""id"": ""50ef01"", ""links"": { ""self"": ""https://identity:35357/v3/projects/50ef01"" ""name"": ""Secret Project Y"" ""self"": ""https://identity:35357/v3/users/9fe1d3/projects"", ""domain_id"": ""1789d1"", ""id"": ""ea167b"", ""links"": { ""self"": ""https://identity:35357/v3/groups/ea167b"" ""domain_id"": ""1789d1"", ""id"": ""a62db1"", ""links"": { ""self"": ""https://identity:35357/v3/groups/a62db1"" ""self"": ""http://identity:35357/v3/users/9fe1d3/groups"",#### Create user: `POST /users` Request: { ""user"": { ""default_project_id"": ""263fd9"", ""description"": ""Jim Doe's user"", ""domain_id"": ""1789d1"", ""email"": ""jdoe@example.com"", ""enabled"": true, ""name"": ""James Doe"", ""password"": ""chang3me"" } } Response: Status: 201 Created { ""user"": { ""default_project_id"": ""263fd9"", ""description"": ""Jim Doe's user"", ""domain_id"": ""1789d1"", ""email"": ""jdoe@example.com"", ""enabled"": true, ""id"": ""ff4e51"", ""links"": { ""self"": ""https://identity:35357/v3/users/ff4e51"" }, ""name"": ""jdoe"" } } #### Update user: `PATCH /users/{user_id}`back-end driver does not allow for the functionality. ""default_project_id"": ""263fd9"", ""description"": ""James Doe's user"", ""email"": ""jamesdoe@example.com"", ""id"": ""ff4e51"", ""links"": { ""self"": ""https://identity:35357/v3/users/ff4e51"" ""name"": ""jamesdoe"" ""password"": ""chang3me"", ""original_password"": ""secrete""","#### Create user: `POST /users` Request: { ""user"": { ""default_project_id"": ""..."", ""description"": ""..."", ""domain_id"": ""--optional--"", ""email"": ""..."", ""enabled"": true, ""name"": ""..."", ""password"": ""--optional--"" } } Response: Status: 201 Created { ""user"": { ""default_project_id"": ""--default-project-id--"", ""description"": ""a user"", ""domain_id"": ""1789d1"", ""email"": ""..."", ""enabled"": true, ""id"": ""--user-id--"", ""links"": { ""self"": ""http://identity:35357/v3/users/--user-id--"" }, ""name"": ""admin"" } } ""default_project_id"": ""--default-project-id--"", ""description"": ""a user"", ""email"": ""..."", ""id"": ""--user-id--"", ""links"": { ""self"": ""http://identity:35357/v3/users/--user-id--"" ""default_project_id"": ""--default-project-id--"", ""description"": ""another user"", ""email"": ""..."", ""id"": ""--user-id--"", ""links"": { ""self"": ""http://identity:35357/v3/users/--user-id--"" ""name"": ""someone"" ""default_project_id"": ""--default-project-id--"", ""description"": ""a user"", ""email"": ""..."", ""id"": ""--user-id--"", ""links"": { ""self"": ""http://identity:35357/v3/users/--user-id--"" ""name"": ""admin"" ""domain_id"": ""--domain-id--"", ""id"": ""--project-id--"", ""links"": { ""self"": ""http://identity:35357/v3/projects/--project-id--"" ""name"": ""a project name"" ""domain_id"": ""--domain-id--"", ""id"": ""--project-id--"", ""links"": { ""self"": ""http://identity:35357/v3/projects/--project-id--"" ""name"": ""another domain"" ""self"": ""http://identity:35357/v3/users/--user-id--/projects"", ""domain_id"": ""--domain-id--"", ""id"": ""--group-id--"", ""links"": { ""self"": ""http://identity:35357/v3/groups/--group-id--"" ""domain_id"": ""--domain-id--"", ""id"": ""--group-id--"", ""links"": { ""self"": ""http://identity:35357/v3/groups/--group-id--"" ""self"": ""http://identity:35357/v3/users/--user-id--/groups"",#### Update user: `PATCH /users/{user_id}` back-end driver doesn't allow for the functionality. ""default_project_id"": ""--default-project-id--"", ""description"": ""a user"", ""email"": ""..."", ""id"": ""--user-id--"", ""links"": { ""self"": ""http://identity:35357/v3/users/--user-id--"" ""name"": ""admin"" ""password"": ""..."", ""original_password"": ""...""",77,78
openstack%2Fopenstack-planet~master~I8a7ec074589186df1f2223648e3c1dbf86a276c7,openstack/openstack-planet,master,I8a7ec074589186df1f2223648e3c1dbf86a276c7,Added Solinea to Planet OpenStack,MERGED,2014-03-06 16:40:51.000000000,2014-03-07 08:43:44.000000000,2014-03-07 08:43:43.000000000,"[{'_account_id': 3}, {'_account_id': 308}]","[{'number': 1, 'created': '2014-03-06 16:40:51.000000000', 'files': ['images/solinea.png', 'planet.ini'], 'web_link': 'https://opendev.org/openstack/openstack-planet/commit/ed6e755f253ea418b2d118a0809240fc5b90e7fe', 'message': 'Added Solinea to Planet OpenStack\n\nChange-Id: I8a7ec074589186df1f2223648e3c1dbf86a276c7\n'}]",0,78661,ed6e755f253ea418b2d118a0809240fc5b90e7fe,6,2,1,2760,,,0,"Added Solinea to Planet OpenStack

Change-Id: I8a7ec074589186df1f2223648e3c1dbf86a276c7
",git fetch https://review.opendev.org/openstack/openstack-planet refs/changes/61/78661/1 && git format-patch -1 --stdout FETCH_HEAD,"['images/solinea.png', 'planet.ini']",2,ed6e755f253ea418b2d118a0809240fc5b90e7fe,, [http://www.solinea.com/blog/topic/openstack/rss.xml] name = Solinea nick = Solinea face = solinea.png ,,6,0
openstack%2Ftaskflow~master~Ic38d41d4f24dcd596cbdff33de78d1a137fb2e8f,openstack/taskflow,master,Ic38d41d4f24dcd596cbdff33de78d1a137fb2e8f,Allow connection string to be just backend name,MERGED,2014-03-03 08:44:05.000000000,2014-03-07 08:23:37.000000000,2014-03-07 08:23:36.000000000,"[{'_account_id': 3}, {'_account_id': 1297}, {'_account_id': 7349}, {'_account_id': 7366}]","[{'number': 1, 'created': '2014-03-03 08:44:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/8ce29f0c870cdb5f14c9d0d05967483fda32a55d', 'message': 'Allow connection string to be just backend name\n\nHaving to specify backend connection as URI is somewhat confusing\nwhen other parts of uri (like host or path) are not used. This commit\nallows to specify just backend name as connection string.\n\nPartially implements blueprint persistence-uris\n\nChange-Id: Ic38d41d4f24dcd596cbdff33de78d1a137fb2e8f\n'}, {'number': 2, 'created': '2014-03-05 07:06:21.000000000', 'files': ['taskflow/tests/unit/persistence/test_memory_persistence.py', 'taskflow/persistence/backends/__init__.py', 'taskflow/tests/unit/persistence/test_dir_persistence.py'], 'web_link': 'https://opendev.org/openstack/taskflow/commit/2807fa7c2e83a907f39c47ee8da2a885fef08689', 'message': 'Allow connection string to be just backend name\n\nHaving to specify backend connection as URI is somewhat confusing\nwhen other parts of uri (like host or path) are not used. This commit\nallows to specify just backend name as connection string.\n\nPartially implements blueprint persistence-uris\n\nChange-Id: Ic38d41d4f24dcd596cbdff33de78d1a137fb2e8f\n'}]",7,77522,2807fa7c2e83a907f39c47ee8da2a885fef08689,19,4,2,7366,,,0,"Allow connection string to be just backend name

Having to specify backend connection as URI is somewhat confusing
when other parts of uri (like host or path) are not used. This commit
allows to specify just backend name as connection string.

Partially implements blueprint persistence-uris

Change-Id: Ic38d41d4f24dcd596cbdff33de78d1a137fb2e8f
",git fetch https://review.opendev.org/openstack/taskflow refs/changes/22/77522/1 && git format-patch -1 --stdout FETCH_HEAD,"['taskflow/tests/unit/persistence/test_memory_persistence.py', 'taskflow/persistence/backends/__init__.py', 'taskflow/tests/unit/persistence/test_dir_persistence.py']",3,8ce29f0c870cdb5f14c9d0d05967483fda32a55d,bp/persistence-uris," def _check_backend(self, conf): def test_dir_backend_entry_point(self): self._check_backend(dict(connection='dir:', path=self.path)) def test_dir_backend_name(self): self._check_backend(dict(connection='dir', # no colon path=self.path)) def test_file_backend_entry_point(self): self._check_backend(dict(connection='file:', path=self.path))"," def test_dir_persistence_entry_point(self): conf = { 'connection': 'dir:', 'path': self.path } backend = backends.fetch(conf) self.assertIsInstance(backend, impl_dir.DirBackend) backend.close() def test_file_persistence_entry_point(self): conf = { 'connection': 'file:', 'path': self.path }",23,16
openstack%2Fpuppet-neutron~master~Icd173d98e3880902f0fa4404198706f51bb46095,openstack/puppet-neutron,master,Icd173d98e3880902f0fa4404198706f51bb46095,Remove check for correct service_plugins.,MERGED,2014-02-18 14:25:48.000000000,2014-03-07 08:19:14.000000000,2014-03-07 08:19:13.000000000,"[{'_account_id': 3}, {'_account_id': 3153}, {'_account_id': 6754}, {'_account_id': 7888}]","[{'number': 1, 'created': '2014-02-18 14:25:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-neutron/commit/41e7e41553977d770038bb2b9ee884de83bfd7b3', 'message': 'Remove check for correct service_plugins.\n\nThis check fails, because\n$::neutron::service_plugins\nis not available in the context of metering.pp\n\nChange-Id: Icd173d98e3880902f0fa4404198706f51bb46095\nbackport: havana\n'}, {'number': 2, 'created': '2014-02-18 14:25:48.000000000', 'files': ['manifests/agents/metering.pp'], 'web_link': 'https://opendev.org/openstack/puppet-neutron/commit/c0d61971156eef804f305b2497d3359bc44891e8', 'message': 'Remove check for correct service_plugins.\n\nThis check fails, because\n$::neutron::service_plugins\nis not available in the context of metering.pp\n\nChange-Id: Icd173d98e3880902f0fa4404198706f51bb46095\nbackport: havana\n'}]",0,74395,c0d61971156eef804f305b2497d3359bc44891e8,14,4,2,7888,,,0,"Remove check for correct service_plugins.

This check fails, because
$::neutron::service_plugins
is not available in the context of metering.pp

Change-Id: Icd173d98e3880902f0fa4404198706f51bb46095
backport: havana
",git fetch https://review.opendev.org/openstack/puppet-neutron refs/changes/95/74395/1 && git format-patch -1 --stdout FETCH_HEAD,['manifests/agents/metering.pp'],1,41e7e41553977d770038bb2b9ee884de83bfd7b3,meter-check,, if $::neutron::service_plugins !~ /neutron\.services\.metering\.metering_plugin\.MeteringPlugin/ { fail('metering_plugin class should be part of service_plugins in neutron.conf') },0,4
openstack%2Fnova~master~I4470f9821f539ac75d93c6d5ef7a76305ae222d2,openstack/nova,master,I4470f9821f539ac75d93c6d5ef7a76305ae222d2,Keep Instance state when resize is not allowed,ABANDONED,2014-03-05 01:17:59.000000000,2014-03-07 08:09:18.000000000,,"[{'_account_id': 3}, {'_account_id': 4601}, {'_account_id': 5170}, {'_account_id': 6062}, {'_account_id': 9008}, {'_account_id': 9578}]","[{'number': 1, 'created': '2014-03-05 01:17:59.000000000', 'files': ['nova/compute/manager.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/01dcc02b2324e8e949b1bff6fbca236adbaa0e63', 'message': ""Keep Instance state when resize is not allowed\n\nWhen a resize operations was performed ,we marked the instance\n'ERROR' when we don't allow the operations to be executed.\nLogically this is not correct since end-user don't know how we\nexecute the resize operation.\n\nChange-Id: I4470f9821f539ac75d93c6d5ef7a76305ae222d2\n""}]",2,78059,01dcc02b2324e8e949b1bff6fbca236adbaa0e63,9,6,1,6062,,,0,"Keep Instance state when resize is not allowed

When a resize operations was performed ,we marked the instance
'ERROR' when we don't allow the operations to be executed.
Logically this is not correct since end-user don't know how we
execute the resize operation.

Change-Id: I4470f9821f539ac75d93c6d5ef7a76305ae222d2
",git fetch https://review.opendev.org/openstack/nova refs/changes/59/78059/1 && git format-patch -1 --stdout FETCH_HEAD,['nova/compute/manager.py'],1,01dcc02b2324e8e949b1bff6fbca236adbaa0e63,resize-samehost-should-not-mark-instance-error,," self._set_instance_error_state(context, instance['uuid']) self._set_instance_error_state(context, instance['uuid'])",0,2
openstack-attic%2Fimage-api~master~Ib1e8fecb045b4c7dcac58be9d65a41f9584ac259,openstack-attic/image-api,master,Ib1e8fecb045b4c7dcac58be9d65a41f9584ac259,"Revert ""Add title to chapter""",MERGED,2014-02-26 18:29:58.000000000,2014-03-07 08:09:01.000000000,2014-03-07 08:09:01.000000000,"[{'_account_id': 3}, {'_account_id': 6547}]","[{'number': 1, 'created': '2014-02-26 18:29:58.000000000', 'files': ['doc/image-api-v2/image-api-v2.0.md'], 'web_link': 'https://opendev.org/openstack-attic/image-api/commit/b1e8fecb045b4c7dcac58be9d65a41f9584ac259', 'message': 'Revert ""Add title to chapter""\n\nThis reverts commit bd14152a3dd35f07d0b02b82f352156c2d295d8f\n\nThis will be handled via our tools now, so this change is not needed.'}]",0,76615,b1e8fecb045b4c7dcac58be9d65a41f9584ac259,11,2,1,6547,,,0,"Revert ""Add title to chapter""

This reverts commit bd14152a3dd35f07d0b02b82f352156c2d295d8f

This will be handled via our tools now, so this change is not needed.",git fetch https://review.opendev.org/openstack-attic/image-api refs/changes/15/76615/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/image-api-v2/image-api-v2.0.md'],1,b1e8fecb045b4c7dcac58be9d65a41f9584ac259,,#OpenStack Image Service API v2 Reference,% OpenStack Image Service API v2 Reference,1,1
openstack%2Fmistral-extra~master~I0d5eacc34de03ca325f0b433948bbd3f27fdf98f,openstack/mistral-extra,master,I0d5eacc34de03ca325f0b433948bbd3f27fdf98f,Rename 'events' to 'triggers',MERGED,2014-03-06 08:30:38.000000000,2014-03-07 08:05:17.000000000,2014-03-07 08:05:17.000000000,"[{'_account_id': 3}, {'_account_id': 7227}, {'_account_id': 8731}, {'_account_id': 9432}, {'_account_id': 10126}, {'_account_id': 10127}]","[{'number': 1, 'created': '2014-03-06 08:30:38.000000000', 'files': ['examples/vm_job/run_vm_job.yaml', 'examples/webhooks/demo.yaml'], 'web_link': 'https://opendev.org/openstack/mistral-extra/commit/ed6b6136a56e17fb70a211950bd740496bf354be', 'message': ""Rename 'events' to 'triggers'\n\nImplements: blueprint mistral-rename-event-to-trigger\n\nChange-Id: I0d5eacc34de03ca325f0b433948bbd3f27fdf98f\n""}]",0,78544,ed6b6136a56e17fb70a211950bd740496bf354be,9,6,1,7700,,,0,"Rename 'events' to 'triggers'

Implements: blueprint mistral-rename-event-to-trigger

Change-Id: I0d5eacc34de03ca325f0b433948bbd3f27fdf98f
",git fetch https://review.opendev.org/openstack/mistral-extra refs/changes/44/78544/1 && git format-patch -1 --stdout FETCH_HEAD,"['examples/vm_job/run_vm_job.yaml', 'examples/webhooks/demo.yaml']",2,ed6b6136a56e17fb70a211950bd740496bf354be,bp/mistral-rename-event-to-trigger,"triggers: execute_backup: type: periodic tasks: execute_backup parameters: cron-pattern: ""*/1 * * * *"""," events: execute_backup: type: periodic tasks: execute_backup parameters: cron-pattern: ""*/1 * * * *""",12,12
openstack%2Fpython-neutronclient~master~I7a7a72db7e8e59c52e6f57d1336e2f69baae69b8,openstack/python-neutronclient,master,I7a7a72db7e8e59c52e6f57d1336e2f69baae69b8,Fix FWaaS operations exceptions,ABANDONED,2014-02-18 12:48:02.000000000,2014-03-07 07:58:32.000000000,,"[{'_account_id': 3}, {'_account_id': 841}, {'_account_id': 6072}, {'_account_id': 7249}]","[{'number': 1, 'created': '2014-02-18 12:48:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-neutronclient/commit/b498a943476d481dc01e45163911caa88c1877f8', 'message': 'Fix FWaaS operations exceptions\n\nSome errors arise non-userfriendly error messages. Printed json\ninstead of message.\n\nChange-Id: I7a7a72db7e8e59c52e6f57d1336e2f69baae69b8\nCloses-bug: #1281550\n'}, {'number': 2, 'created': '2014-02-18 12:52:28.000000000', 'files': ['neutronclient/v2_0/client.py', 'neutronclient/common/exceptions.py'], 'web_link': 'https://opendev.org/openstack/python-neutronclient/commit/f2e5cdd7915d3c898161c70171f8cce16b9ec7e3', 'message': 'Fix FWaaS operations exceptions\n\nSome errors arise non-userfriendly error messages. Printed json\ninstead of message.\n\nCloses-bug: #1281550\n\nChange-Id: I7a7a72db7e8e59c52e6f57d1336e2f69baae69b8\n'}]",0,74357,f2e5cdd7915d3c898161c70171f8cce16b9ec7e3,9,4,2,7249,,,0,"Fix FWaaS operations exceptions

Some errors arise non-userfriendly error messages. Printed json
instead of message.

Closes-bug: #1281550

Change-Id: I7a7a72db7e8e59c52e6f57d1336e2f69baae69b8
",git fetch https://review.opendev.org/openstack/python-neutronclient refs/changes/57/74357/2 && git format-patch -1 --stdout FETCH_HEAD,"['neutronclient/v2_0/client.py', 'neutronclient/common/exceptions.py']",2,b498a943476d481dc01e45163911caa88c1877f8,, class FirewallPolicyInUse(NeutronClientException): pass class FirewallRuleInUse(NeutronClientException): pass class FirewallNotFound(NeutronClientException): pass class FirewallInUse(NeutronClientException): pass class FirewallInPendingState(NeutronClientException): pass class FirewallPolicyNotFound(NeutronClientException): pass class FirewallRuleNotFound(NeutronClientException): pass class FirewallRuleNotAssociatedWithPolicy(NeutronClientException): pass class FirewallRuleInvalidProtocol(NeutronClientException): pass class FirewallRuleInvalidAction(NeutronClientException): pass class FirewallInvalidPortValue(NeutronClientException): pass class FirewallRuleInfoMissing(NeutronClientException): pass class FirewallInternalDriverError(NeutronClientException): pass class FirewallCountExceeded(NeutronClientException): pass,,73,1
openstack%2Ftaskflow~master~Ia7d677df8950effd65a9de20c6166a53f5cfbf40,openstack/taskflow,master,Ia7d677df8950effd65a9de20c6166a53f5cfbf40,Add default retry controllers,ABANDONED,2014-02-18 16:24:34.000000000,2014-03-07 07:48:46.000000000,,"[{'_account_id': 3}, {'_account_id': 7349}, {'_account_id': 7366}]","[{'number': 1, 'created': '2014-02-18 16:24:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/06db94121e9c6350c8e8b533adf1b13acbd405d3', 'message': 'Add default retry controllers\n\n1. RetryCounter accepts a number of attempts to constructor.\n\n2. ConstantIterator iterates through a given collection. Returns one element on\neach try. Accepts collection to constructor.\n\n3. ParameterizedIterator iterates through a given collection. Returns one element\non each try. Accepts collection as a parameter of execute method.\n\nChange-Id: Ia7d677df8950effd65a9de20c6166a53f5cfbf40\n'}, {'number': 2, 'created': '2014-02-19 11:12:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/d8cf628fd5eea7c6ba58088dfde0475b3a6d4ea8', 'message': 'Add default retry controllers\n\n1. Times accepts a number of attempts to constructor.\n\n2. ForEach iterates through a given collection. Returns one element on\neach try. Accepts collection to constructor.\n\n3. ParameterizedForEach iterates through a given collection. Returns one element\non each try. Accepts collection as a parameter of execute method.\n\nChange-Id: Ia7d677df8950effd65a9de20c6166a53f5cfbf40\n'}, {'number': 3, 'created': '2014-02-19 16:07:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/d0c14588cc77a747e97b3bdf05eaea8d32fc238d', 'message': 'Add default retry controllers\n\n1. Times accepts a number of attempts to constructor.\n\n2. ForEach iterates through a given collection. Returns one element on\neach try. Accepts collection to constructor.\n\n3. ParameterizedForEach iterates through a given collection. Returns one element\non each try. Accepts collection as a parameter of execute method.\n\nChange-Id: Ia7d677df8950effd65a9de20c6166a53f5cfbf40\n'}, {'number': 4, 'created': '2014-02-20 11:47:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/c29ec65a2a1b4c1dba71a946935ca05de1708b04', 'message': 'Add default retry controllers\n\n1. Times accepts a number of attempts to constructor.\n\n2. ForEach iterates through a given collection. Returns one element on\neach try. Accepts collection to constructor.\n\n3. ParameterizedForEach iterates through a given collection. Returns one element\non each try. Accepts collection as a parameter of execute method.\n\nChange-Id: Ia7d677df8950effd65a9de20c6166a53f5cfbf40\n'}, {'number': 5, 'created': '2014-02-20 15:09:52.000000000', 'files': ['taskflow/tests/utils.py', 'taskflow/retry.py', 'taskflow/tests/unit/test_retries.py', 'taskflow/tests/unit/worker_based/test_worker.py', 'taskflow/examples/retry_flow.py'], 'web_link': 'https://opendev.org/openstack/taskflow/commit/bc11fd525b099609c30b8359c2295d21451144a0', 'message': 'Add default retry controllers\n\n1. Times accepts a number of attempts to constructor.\n\n2. ForEach iterates through a given collection. Returns one element on\neach try. Accepts collection to constructor.\n\n3. ParameterizedForEach iterates through a given collection. Returns one element\non each try. Accepts collection as a parameter of execute method.\n\nChange-Id: Ia7d677df8950effd65a9de20c6166a53f5cfbf40\n'}]",13,74432,bc11fd525b099609c30b8359c2295d21451144a0,19,3,5,7349,,,0,"Add default retry controllers

1. Times accepts a number of attempts to constructor.

2. ForEach iterates through a given collection. Returns one element on
each try. Accepts collection to constructor.

3. ParameterizedForEach iterates through a given collection. Returns one element
on each try. Accepts collection as a parameter of execute method.

Change-Id: Ia7d677df8950effd65a9de20c6166a53f5cfbf40
",git fetch https://review.opendev.org/openstack/taskflow refs/changes/32/74432/1 && git format-patch -1 --stdout FETCH_HEAD,"['taskflow/tests/utils.py', 'taskflow/retry.py', 'taskflow/tests/unit/test_retries.py', 'taskflow/examples/retry_flow.py']",4,06db94121e9c6350c8e8b533adf1b13acbd405d3,checkpoints,"flow = lf.Flow('retrying-linear', retry=retry.ParameterizedIterator( rebind=['phone_directory'], provides='jim_number')).add(CallJim())","class SelectPhoneNumber(retry.Retry): default_provides = 'jim_number' def execute(self, phone_directory, results_history, failures_history): """"""Select a phone number from the directory."""""" for number in phone_directory: if number not in results_history: return number def revert(self, results_history, failures_history, *args, **kwargs): print (""Jim number hasn't been found in the directory."") def on_failure(self, phone_directory, results_history, failures_history): """"""Checks if any numbers left in the directory."""""" if len(phone_directory) == len(results_history): return retry.REVERT else: return retry.RETRY flow = lf.Flow('retrying-linear', retry=SelectPhoneNumber()).add(CallJim())",140,26
openstack%2Ftaskflow~master~I280d9554a7f33fdb9dbd0d0504f53764b5787374,openstack/taskflow,master,I280d9554a7f33fdb9dbd0d0504f53764b5787374,Resume retrying subflows after flow interruption,ABANDONED,2014-02-18 11:49:40.000000000,2014-03-07 07:48:25.000000000,,"[{'_account_id': 3}, {'_account_id': 7349}, {'_account_id': 7366}]","[{'number': 1, 'created': '2014-02-18 11:49:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/0cf5d7394055f7ce4b74ba64bedb630c3d1d27c7', 'message': 'Resume retrying subflows after flow interruption\n\nChange-Id: I280d9554a7f33fdb9dbd0d0504f53764b5787374\n'}, {'number': 2, 'created': '2014-02-20 11:47:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/513e2fe03454523a75481a7917ca188bd7cfc439', 'message': 'Resume retrying subflows after flow interruption\n\nChange-Id: I280d9554a7f33fdb9dbd0d0504f53764b5787374\n'}, {'number': 3, 'created': '2014-02-20 15:09:52.000000000', 'files': ['taskflow/engines/action_engine/graph_analyzer.py', 'taskflow/persistence/logbook.py', 'taskflow/engines/action_engine/graph_action.py', 'taskflow/tests/unit/test_retries.py'], 'web_link': 'https://opendev.org/openstack/taskflow/commit/772d088f1c8ef4bd3833e1ca6f695b4bb3c24b59', 'message': 'Resume retrying subflows after flow interruption\n\nChange-Id: I280d9554a7f33fdb9dbd0d0504f53764b5787374\n'}]",3,74340,772d088f1c8ef4bd3833e1ca6f695b4bb3c24b59,13,3,3,7349,,,0,"Resume retrying subflows after flow interruption

Change-Id: I280d9554a7f33fdb9dbd0d0504f53764b5787374
",git fetch https://review.opendev.org/openstack/taskflow refs/changes/40/74340/1 && git format-patch -1 --stdout FETCH_HEAD,"['taskflow/engines/action_engine/graph_analyzer.py', 'taskflow/engines/action_engine/graph_action.py', 'taskflow/tests/unit/test_retries.py']",3,0cf5d7394055f7ce4b74ba64bedb630c3d1d27c7,checkpoints," def test_resume_flow_that_had_been_interrupted_during_retrying(self): flow = lf.Flow('flow-1', utils.CounterRetry('r1')).add( utils.SaveOrderTask('t1'), utils.SaveOrderTask('t2'), utils.SaveOrderTask('t3') ) engine = self._make_engine(flow) engine.compile() utils.register_notifiers(engine, self.values) engine.storage.inject({'counter': 3, 'y': 2}) engine.storage.set_task_state('r1', st.RETRYING) engine.storage.set_task_state('t1', st.PENDING) engine.storage.set_task_state('t2', st.REVERTED) engine.storage.set_task_state('t3', st.REVERTED) engine.run() expected = ['flow RUNNING', 't2 PENDING', 't3 PENDING', 'r1 RUNNING', 'r1 SUCCESS', 't1 RUNNING', 't1', 't1 SUCCESS', 't2 RUNNING', 't2', 't2 SUCCESS', 't3 RUNNING', 't3', 't3 SUCCESS', 'flow SUCCESS'] self.assertEqual(self.values, expected) def test_resume_flow_that_should_be_retried(self): flow = lf.Flow('flow-1', utils.CounterRetry('r1')).add( utils.SaveOrderTask('t1'), utils.SaveOrderTask('t2') ) engine = self._make_engine(flow) engine.compile() utils.register_notifiers(engine, self.values) engine.storage.inject({'counter': 3, 'y': 2}) engine.storage.set_atom_intention('r1', st.RETRY) engine.storage.set_task_state('r1', st.SUCCESS) engine.storage.set_task_state('t1', st.REVERTED) engine.storage.set_task_state('t2', st.REVERTED) engine.run() expected = ['flow RUNNING', 'r1 RETRYING', 't1 PENDING', 't2 PENDING', 'r1 RUNNING', 'r1 SUCCESS', 't1 RUNNING', 't1', 't1 SUCCESS', 't2 RUNNING', 't2', 't2 SUCCESS', 'flow SUCCESS'] self.assertEqual(self.values, expected) ",,90,11
openstack%2Foslo-incubator~master~Ic996fdde13b28ebeb750289b81663ac3981d05ac,openstack/oslo-incubator,master,Ic996fdde13b28ebeb750289b81663ac3981d05ac,Return the unicode representation of an object,ABANDONED,2014-02-05 19:53:50.000000000,2014-03-07 06:21:31.000000000,,"[{'_account_id': 3}, {'_account_id': 1297}, {'_account_id': 1669}, {'_account_id': 2472}, {'_account_id': 5046}, {'_account_id': 6601}, {'_account_id': 6928}, {'_account_id': 7198}, {'_account_id': 7366}, {'_account_id': 7491}, {'_account_id': 7996}, {'_account_id': 9107}, {'_account_id': 9656}]","[{'number': 1, 'created': '2014-02-05 19:53:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo-incubator/commit/b483a43e368756e71364f2765ff6a9a6f0d6eaa1', 'message': 'Return the unicode representation of a exception.\n\nException messages in openstack are typically (when translated) unicode\nand for those that want to include the exception message in there own\ntext they need to be careful to handle this inclusion correctly (as just\nusing str() will not work across python2.x and 3.x) so whenever a exception\nmessage is included it should be passed to this function to get a valid\nunicode string from.\n\nChange-Id: Ic996fdde13b28ebeb750289b81663ac3981d05ac\n'}, {'number': 2, 'created': '2014-02-05 19:55:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo-incubator/commit/32b7288b78a7cb039c9d14ffd72221d5c0c2c025', 'message': 'Return the unicode representation of a exception\n\nException messages in openstack are typically (when translated)\nunicode and for those that want to include the exception message\nin there own text they need to be careful to handle this inclusion\ncorrectly (as just using str() will not work across python2.x and\n3.x) so whenever a exception message is included it should be\npassed to this function to get a valid unicode string from.\n\nChange-Id: Ic996fdde13b28ebeb750289b81663ac3981d05ac\n'}, {'number': 3, 'created': '2014-02-05 20:33:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo-incubator/commit/8cc40bed9b09ed043344dd7303772b0ea156d99d', 'message': 'Return the unicode representation of a exception\n\nException messages in openstack are typically (when translated)\nunicode and for those that want to include the exception message\nin there own text they need to be careful to handle this inclusion\ncorrectly (as just using str() will not work across python2.x and\n3.x) so whenever a exception message is included it should be\npassed to this function to get a valid unicode string from.\n\nChange-Id: Ic996fdde13b28ebeb750289b81663ac3981d05ac\n'}, {'number': 4, 'created': '2014-02-05 20:35:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo-incubator/commit/dccf2a7f919e3c7defec6a53218560ff8aea8633', 'message': 'Return the unicode representation of an object\n\nObjects in openstack are typically *safe* to translate to\nunicode but for those that want to ensure that unicode is\nreturned for their object type (str() is not safe to call\nto perform this in python2.x and python3.x) this utility\nfunction will translate a object safely to unicode and\nresort back to safe decoding for when this decoding is\nproblematic.\n\nChange-Id: Ic996fdde13b28ebeb750289b81663ac3981d05ac\n'}, {'number': 5, 'created': '2014-02-05 22:23:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo-incubator/commit/2554512d3ebefe70af4948f3699565e934e8e8ff', 'message': 'Return the unicode representation of an object\n\nObjects in openstack are typically *safe* to translate to\nunicode but for those that want to ensure that unicode is\nreturned for their object type (str() is not safe to call\nto perform this in python2.x and python3.x). This utility\nfunction will translate an object safely to unicode and\nresort back to safe decoding for when this decoding is\nproblematic.\n\nChange-Id: Ic996fdde13b28ebeb750289b81663ac3981d05ac\n'}, {'number': 6, 'created': '2014-02-05 22:38:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo-incubator/commit/7ff0a3a2f94b0d0db8cee7fbd33a85092a82c1b5', 'message': 'Return the unicode representation of an object\n\nObjects in openstack are typically *safe* to translate to\nunicode but for those that want to ensure that unicode is\nreturned for their object type (str() is not safe to call\nto perform this in python2.x and python3.x). This utility\nfunction will translate an object safely to unicode and\nresort back to safe decoding for when this decoding is\nproblematic.\n\nChange-Id: Ic996fdde13b28ebeb750289b81663ac3981d05ac\n'}, {'number': 7, 'created': '2014-02-06 19:58:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo-incubator/commit/f333400ee276cf840975da2543a0de5941c3adcc', 'message': 'Return the unicode representation of an object\n\nObjects in openstack are typically *safe* to translate to\nunicode but for those that want to ensure that unicode is\nreturned for their object type (str() is not safe to call\nto perform this in python2.x and python3.x). This utility\nfunction will translate an object safely to unicode and\nresort back to safe decoding for when this decoding is\nproblematic.\n\nChange-Id: Ic996fdde13b28ebeb750289b81663ac3981d05ac\n'}, {'number': 8, 'created': '2014-02-07 17:02:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo-incubator/commit/a3d66762762aed89c404e96c972ddb8ac5cbffd3', 'message': 'Return the unicode representation of an object\n\nObjects in openstack are typically *safe* to translate to\nunicode but for those that want to ensure that unicode is\nreturned for their object type (str() is not safe to call\nto perform this in python2.x and python3.x). This utility\nfunction will translate an object safely to unicode and\nresort back to safe decoding for when this decoding is\nproblematic.\n\nChange-Id: Ic996fdde13b28ebeb750289b81663ac3981d05ac\n'}, {'number': 9, 'created': '2014-02-07 17:04:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo-incubator/commit/a8d03ce8456d8002847ec67851bc13452e6b995d', 'message': 'Return the unicode representation of an object\n\nObjects in openstack are typically *safe* to translate to\nunicode but for those that want to ensure that unicode is\nreturned for their object type (str() is not safe to call\nto perform this in python2.x and python3.x). This utility\nfunction will translate an object safely to unicode and\nresort back to safe decoding for when this decoding is\nproblematic.\n\nChange-Id: Ic996fdde13b28ebeb750289b81663ac3981d05ac\n'}, {'number': 10, 'created': '2014-02-07 20:48:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo-incubator/commit/db3ec8c3f1f38f735955f09f518715f8b35b0934', 'message': 'Return the unicode representation of an object\n\nObjects in openstack are typically *safe* to translate to\nunicode but for those that want to ensure that unicode is\nreturned for their object type (str() is not safe to call\nto perform this in python2.x and python3.x). This utility\nfunction will translate an object safely to unicode and\nresort back to safe decoding for when this decoding is\nproblematic.\n\nChange-Id: Ic996fdde13b28ebeb750289b81663ac3981d05ac\n'}, {'number': 11, 'created': '2014-02-08 01:00:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo-incubator/commit/cfe07613a6263b9815b9fafd1b67ed152cdb5be8', 'message': 'Return the unicode representation of an object\n\nObjects in openstack are typically *safe* to translate to\nunicode but for those that want to ensure that unicode is\nreturned for their object type (str() is not safe to call\nto perform this in python2.x and python3.x). This utility\nfunction will translate an object safely to unicode and\nresort back to safe decoding for when this decoding is\nproblematic.\n\nChange-Id: Ic996fdde13b28ebeb750289b81663ac3981d05ac\n'}, {'number': 12, 'created': '2014-02-11 23:24:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo-incubator/commit/c06d4cbf0b70eebb09fe28fc73404cae7fb23bfe', 'message': 'Return the unicode representation of an object\n\nObjects in openstack are typically *safe* to translate to\nunicode but for those that want to ensure that unicode is\nreturned for their object type (str() is not safe to call\nto perform this in python2.x and python3.x). This utility\nfunction will translate an object safely to unicode and\nresort back to safe decoding for when this decoding is\nproblematic.\n\nChange-Id: Ic996fdde13b28ebeb750289b81663ac3981d05ac\n'}, {'number': 13, 'created': '2014-02-12 14:47:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo-incubator/commit/65b7943171ea16e59e08a465440f4db169c96a3a', 'message': 'Return the unicode representation of an object\n\nObjects in openstack are typically *safe* to translate to\nunicode but for those that want to ensure that unicode is\nreturned for their object type (str() is not safe to call\nto perform this in python2.x and python3.x). This utility\nfunction will translate an object safely to unicode and\nresort back to safe decoding for when this decoding is\nproblematic.\n\nThis function is being added as a result of work that has\nbeen done to implement translation support for OpenStack\nlogging and exceptions include REST API responses.  This\nfunction serves as a safe replacement for str() in log\nand exception messages.\n\nRelated-bp: i18n-messages\nChange-Id: Ic996fdde13b28ebeb750289b81663ac3981d05ac\n'}, {'number': 14, 'created': '2014-02-12 14:51:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo-incubator/commit/24a907a5e9760a70206d69be90bd4a69328d7835', 'message': 'Return the unicode representation of an object\n\nObjects in openstack are typically *safe* to translate to\nunicode but for those that want to ensure that unicode is\nreturned for their object type (str() is not safe to call\nto perform this in python2.x and python3.x). This utility\nfunction will translate an object safely to unicode and\nresort back to safe decoding for when this decoding is\nproblematic.\n\nThis function is being added as a result of work that has\nbeen done to implement translation support for OpenStack\nlogging and exceptions including REST API responses.  This\nfunction serves as a safe replacement for str() in log\nand exception messages.\n\nRelated-bp: i18n-messages\nChange-Id: Ic996fdde13b28ebeb750289b81663ac3981d05ac\n'}, {'number': 15, 'created': '2014-02-12 15:29:14.000000000', 'files': ['tests/unit/test_strutils.py', 'openstack/common/strutils.py'], 'web_link': 'https://opendev.org/openstack/oslo-incubator/commit/7c023eec132e689f8ca0f249258cd2bfb2f7d197', 'message': 'Return the unicode representation of an object\n\nObjects in openstack are typically *safe* to translate to\nunicode but for those that want to ensure that unicode is\nreturned for their object type (str() is not safe to call\nto perform this in python2.x and python3.x). This utility\nfunction will translate an object safely to unicode and\nresort back to safe decoding for when this decoding is\nproblematic.\n\nThis function is being added as a result of work that has\nbeen done to implement translation support for OpenStack\nlogging and exceptions including REST API responses.  This\nfunction serves as a safe replacement for str() in log\nand exception messages.\n\nRelated-bp: i18n-messages\nChange-Id: Ic996fdde13b28ebeb750289b81663ac3981d05ac\n'}]",30,71362,7c023eec132e689f8ca0f249258cd2bfb2f7d197,96,13,15,1297,,,0,"Return the unicode representation of an object

Objects in openstack are typically *safe* to translate to
unicode but for those that want to ensure that unicode is
returned for their object type (str() is not safe to call
to perform this in python2.x and python3.x). This utility
function will translate an object safely to unicode and
resort back to safe decoding for when this decoding is
problematic.

This function is being added as a result of work that has
been done to implement translation support for OpenStack
logging and exceptions including REST API responses.  This
function serves as a safe replacement for str() in log
and exception messages.

Related-bp: i18n-messages
Change-Id: Ic996fdde13b28ebeb750289b81663ac3981d05ac
",git fetch https://review.opendev.org/openstack/oslo-incubator refs/changes/62/71362/2 && git format-patch -1 --stdout FETCH_HEAD,['openstack/common/excutils.py'],1,b483a43e368756e71364f2765ff6a9a6f0d6eaa1,bp/i18n-messages," def exception_message(exc): """"""Return the unicode representation of a exception. Exception messages in openstack are typically (when translated) unicode and for those that want to include the exception message in there own text they need to be careful to handle this inclusion correctly (as just using str() will not work across python2.x and 3.x) so whenever a exception message is included it should be passed to this function to get a valid unicode string from. """""" try: # Try to directly make it into unicode (usually works). return six.text_type(exc) except UnicodeError: pass for (encoding, errors) in (('utf-8', 'strict'), (""latin-1"", ""strict"")): try: return six.binary_type(exc).decode(encoding, errors) except UnicodeError: pass # Give up, convert the exception message to utf-8 but replace all invalid # characters with the replacement character instead. return six.binary_type(exc).decode(""utf-8"", 'replace')",,25,0
openstack%2Ftrove~master~Ife2822934805e23dae25c03f38d43e847e72c4e2,openstack/trove,master,Ife2822934805e23dae25c03f38d43e847e72c4e2,Updating pep8 command,ABANDONED,2014-02-20 18:51:25.000000000,2014-03-07 06:03:56.000000000,,"[{'_account_id': 3}, {'_account_id': 7092}, {'_account_id': 8214}, {'_account_id': 8415}]","[{'number': 1, 'created': '2014-02-20 18:51:25.000000000', 'files': ['tox.ini'], 'web_link': 'https://opendev.org/openstack/trove/commit/4dc989f3a9b7fb3647e8b410164686be924cafef', 'message': 'Updating pep8 command\n\nReasons:\n - flake8 should check only directories with code;\n\nChanges:\n - adding directories to be checked with flake8;\n\nChange-Id: Ife2822934805e23dae25c03f38d43e847e72c4e2\n'}]",0,75135,4dc989f3a9b7fb3647e8b410164686be924cafef,12,4,1,8415,,,0,"Updating pep8 command

Reasons:
 - flake8 should check only directories with code;

Changes:
 - adding directories to be checked with flake8;

Change-Id: Ife2822934805e23dae25c03f38d43e847e72c4e2
",git fetch https://review.opendev.org/openstack/trove refs/changes/35/75135/1 && git format-patch -1 --stdout FETCH_HEAD,['tox.ini'],1,4dc989f3a9b7fb3647e8b410164686be924cafef,,commands = flake8 trove/ rsdns/ contrib,commands = flake8,1,1
openstack%2Fnova~master~I70ebc64816906d748d3f265a7abac024ddc923fa,openstack/nova,master,I70ebc64816906d748d3f265a7abac024ddc923fa,Using oslo db migration toolkit,ABANDONED,2013-12-06 14:16:05.000000000,2014-03-07 06:03:55.000000000,,"[{'_account_id': 3}, {'_account_id': 1653}, {'_account_id': 1849}, {'_account_id': 2271}, {'_account_id': 4715}, {'_account_id': 8907}, {'_account_id': 9008}, {'_account_id': 9578}]","[{'number': 1, 'created': '2013-12-06 14:16:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/6cfebf218b9f7e67e68629a2e193a91726dc5d94', 'message': 'PROOF OF CONCEPT: Using oslo db migration toolkit\n\nThis is example how code db.sqlalchemy.migration_cli\nfrom oslo_incubator should be implemented in original apps\n\nRefernce oslo branch: https://review.openstack.org/#/c/59433\n\nChange-Id: I70ebc64816906d748d3f265a7abac024ddc923fa\n'}, {'number': 2, 'created': '2013-12-09 12:59:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/e579b7d7545dbbfe8a6587b841d7f3b0c6df8641', 'message': 'PROOF OF CONCEPT: Using oslo db migration toolkit\n\nThis is example how code db.sqlalchemy.migration_cli\nfrom oslo_incubator should be implemented in original apps\n\nRefernce oslo branch: https://review.openstack.org/#/c/59433\n\nChange-Id: I70ebc64816906d748d3f265a7abac024ddc923fa\n'}, {'number': 3, 'created': '2013-12-09 13:34:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/032e047a57cfbf4cef593f789b752467785c19bb', 'message': 'PROOF OF CONCEPT: Using oslo db migration toolkit\n\nThis is example how code db.sqlalchemy.migration_cli\nfrom oslo_incubator should be implemented in original apps\n\nRefernce oslo branch: https://review.openstack.org/#/c/59433\n\nChange-Id: I70ebc64816906d748d3f265a7abac024ddc923fa\n'}, {'number': 4, 'created': '2013-12-11 07:58:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/906ebdf3fbc97565ddc6d57a9b0e1bffb54c398a', 'message': 'PROOF OF CONCEPT: Using oslo db migration toolkit\n\nThis is example how code db.sqlalchemy.migration_cli\nfrom oslo_incubator should be implemented in original apps\n\nRefernce oslo branch: https://review.openstack.org/#/c/59433\n\nChange-Id: I70ebc64816906d748d3f265a7abac024ddc923fa\n'}, {'number': 5, 'created': '2013-12-11 10:20:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/bd423dc21c529b61ffd70772a877a389713cad43', 'message': 'PROOF OF CONCEPT: Using oslo db migration toolkit\n\nThis is example how code db.sqlalchemy.migration_cli\nfrom oslo_incubator should be implemented in original apps\n\nRefernce oslo branch: https://review.openstack.org/#/c/59433\n\nChange-Id: I70ebc64816906d748d3f265a7abac024ddc923fa\n'}, {'number': 7, 'created': '2013-12-26 08:42:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/b3a221a4306bdf4447f5fcda749ee4efd416a7e2', 'message': 'PROOF OF CONCEPT: Using oslo db migration toolkit\n\nThis is example how code db.sqlalchemy.migration_cli\nfrom oslo_incubator should be implemented in original apps\n\nRefernce oslo branch: https://review.openstack.org/#/c/59433\n\nChange-Id: I70ebc64816906d748d3f265a7abac024ddc923fa\n'}, {'number': 6, 'created': '2013-12-26 08:42:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/247fe1ecf9147e1434d4dc5e8b3f666b93794cc2', 'message': 'PROOF OF CONCEPT: Using oslo db migration toolkit\n\nThis is example how code db.sqlalchemy.migration_cli\nfrom oslo_incubator should be implemented in original apps\n\nRefernce oslo branch: https://review.openstack.org/#/c/59433\n\nChange-Id: I70ebc64816906d748d3f265a7abac024ddc923fa\n'}, {'number': 8, 'created': '2014-01-10 14:29:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/4ebd7f1064713d7f3f22ebfa98f05289ca1be49d', 'message': 'PROOF OF CONCEPT: Using oslo db migration toolkit\n\nThis is example how code db.sqlalchemy.migration_cli\nfrom oslo_incubator should be implemented in original apps\n\nRefernce oslo branch: https://review.openstack.org/#/c/59433\n\nChange-Id: I70ebc64816906d748d3f265a7abac024ddc923fa\n'}, {'number': 9, 'created': '2014-01-10 14:31:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/7a7d6c4c1f13adc6e5cd0f6971b39a5209812da6', 'message': 'PROOF OF CONCEPT: Using oslo db migration toolkit\n\nThis is example how code db.sqlalchemy.migration_cli\nfrom oslo_incubator should be implemented in original apps\n\nRefernce oslo branch: https://review.openstack.org/#/c/59433\n\nChange-Id: I70ebc64816906d748d3f265a7abac024ddc923fa\n'}, {'number': 10, 'created': '2014-01-10 15:53:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/5cbbfa63e188a8c13af8dfb311a90aadd59b20e5', 'message': 'PROOF OF CONCEPT: Using oslo db migration toolkit\n\nThis is example how code db.sqlalchemy.migration_cli\nfrom oslo_incubator should be implemented in original apps\n\nRefernce oslo branch: https://review.openstack.org/#/c/59433\n\nChange-Id: I70ebc64816906d748d3f265a7abac024ddc923fa\n'}, {'number': 13, 'created': '2014-01-13 13:59:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/f4a69fc58ec7dbdde75ec1ef2d12c9cd421107f4', 'message': 'PROOF OF CONCEPT: Using oslo db migration toolkit\n\nThis is example how code db.sqlalchemy.migration_cli\nfrom oslo_incubator should be implemented in original apps\n\nRefernce oslo branch: https://review.openstack.org/#/c/59433\n\nChange-Id: I70ebc64816906d748d3f265a7abac024ddc923fa\n'}, {'number': 12, 'created': '2014-01-13 13:59:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/1a72329cf1046a654b224d5031b227750537812d', 'message': 'PROOF OF CONCEPT: Using oslo db migration toolkit\n\nThis is example how code db.sqlalchemy.migration_cli\nfrom oslo_incubator should be implemented in original apps\n\nRefernce oslo branch: https://review.openstack.org/#/c/59433\n\nChange-Id: I70ebc64816906d748d3f265a7abac024ddc923fa\n'}, {'number': 11, 'created': '2014-01-13 13:59:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/a2cd8e160b8dd8835a9c5c2b28a1c4097c9fc38c', 'message': 'PROOF OF CONCEPT: Using oslo db migration toolkit\n\nThis is example how code db.sqlalchemy.migration_cli\nfrom oslo_incubator should be implemented in original apps\n\nRefernce oslo branch: https://review.openstack.org/#/c/59433\n\nChange-Id: I70ebc64816906d748d3f265a7abac024ddc923fa\n'}, {'number': 14, 'created': '2014-01-29 14:15:43.000000000', 'files': ['nova/db/sqlalchemy/alembic.ini', 'nova/openstack/common/db/sqlalchemy/migration_cli/__init__.py', 'nova/db/sqlalchemy/alembic/versions/.gitignore', 'nova/openstack/common/db/sqlalchemy/migration.py', 'nova/db/sqlalchemy/alembic/README', 'nova/cmd/manage.py', 'nova/openstack/common/db/sqlalchemy/migration_cli/ext_alembic.py', 'nova/db/sqlalchemy/alembic/env.py', 'nova/db/sqlalchemy/alembic/script.py.mako', 'nova/openstack/common/db/sqlalchemy/migration_cli/ext_migrate.py', 'requirements.txt', 'nova/openstack/common/db/sqlalchemy/migration_cli/manager.py', 'nova/openstack/common/db/sqlalchemy/test_migrations.py', 'nova/openstack/common/db/sqlalchemy/migration_cli/ext_base.py', 'nova/db/migration.py', 'setup.cfg'], 'web_link': 'https://opendev.org/openstack/nova/commit/7a1a62eb7552cb9f9a328d83b98f99b6af4be452', 'message': 'Using oslo db migration toolkit\n\nThis is example how code db.sqlalchemy.migration_cli\nfrom oslo_incubator should be implemented in original apps\n\nRefernce oslo branch: https://review.openstack.org/#/c/59433\n\nChange-Id: I70ebc64816906d748d3f265a7abac024ddc923fa\n'}]",12,60517,7a1a62eb7552cb9f9a328d83b98f99b6af4be452,65,8,14,8907,,,0,"Using oslo db migration toolkit

This is example how code db.sqlalchemy.migration_cli
from oslo_incubator should be implemented in original apps

Refernce oslo branch: https://review.openstack.org/#/c/59433

Change-Id: I70ebc64816906d748d3f265a7abac024ddc923fa
",git fetch https://review.opendev.org/openstack/nova refs/changes/17/60517/5 && git format-patch -1 --stdout FETCH_HEAD,"['nova/db/sqlalchemy/alembic.ini', 'nova/openstack/common/db/sqlalchemy/migration_cli/__init__.py', 'nova/openstack/common/db/sqlalchemy/migration.py', 'nova/db/sqlalchemy/alembic/versions/6fcc7259c16_.py', 'nova/db/sqlalchemy/alembic/README', 'nova/openstack/common/db/sqlalchemy/migration_cli/ext_alembic.py', 'nova/db/sqlalchemy/alembic/env.py', 'nova/db/sqlalchemy/alembic/script.py.mako', 'nova/openstack/common/db/sqlalchemy/migration_cli/ext_migrate.py', 'requirements.txt', 'nova/openstack/common/db/sqlalchemy/migration_cli/manager.py', 'nova/openstack/common/db/sqlalchemy/test_migrations.py', 'nova/openstack/common/db/sqlalchemy/migration_cli/ext_base.py', 'nova/db/migration.py', 'setup.cfg']",15,6cfebf218b9f7e67e68629a2e193a91726dc5d94,oslo_migration_toolkit, nova-dbmanage = nova.db.migration:db_managenova.openstack.common.migration = alembic = nova.openstack.common.db.sqlalchemy.migration_cli.ext_alembic:AlembicExtension migrate = nova.openstack.common.db.sqlalchemy.migration_cli.ext_migrate:MigrateExtension ,,1113,1
openstack%2Fcinder~master~I6d003200e7d33f658ce9db944d835475994ba41f,openstack/cinder,master,I6d003200e7d33f658ce9db944d835475994ba41f,Enable keep-alive updates for snapshot jobs waiting for Nova,ABANDONED,2014-01-29 00:38:06.000000000,2014-03-07 06:03:54.000000000,,"[{'_account_id': 3}, {'_account_id': 1207}, {'_account_id': 2243}, {'_account_id': 4355}, {'_account_id': 4523}, {'_account_id': 5538}, {'_account_id': 6094}, {'_account_id': 7198}]","[{'number': 1, 'created': '2014-01-29 00:38:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/8300bfb7829ebdd673ef2bbdfc645b3c68a58ae2', 'message': 'Enable keep-alive updates for snapshot jobs waiting for Nova\n\nCurrently, the GlusterFS driver has a hard-coded timeout for\nhow long a create or delete snapshot operation can be run by\nNova before it fails the job.\n\nThis change allows the timeout to be reset when Nova sends an\nupdate_snapshot_status update for that snapshot.\n\nSince the volume service (driver) monitors these operations\nby looking at the snapshot progress field in the database,\nwhen an update is recieved that does not contain a progress entry,\nincrement the progress field.\n\n(Currently Nova does not send any real progress info -- only ""done"",\nand now ""still running"" as of this new work for Icehouse.)\n\nIn the driver, reset the timeout when the progress field changes.\n\nThis change is backward compatible with Havana Nova.\n\nCloses-Bug: 1273894\n\nChange-Id: I6d003200e7d33f658ce9db944d835475994ba41f\n'}, {'number': 2, 'created': '2014-01-29 02:30:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/c83dcf218f3d98e56fd1c81af6fbe5c60d5302d9', 'message': 'Enable keep-alive updates for snapshot jobs waiting for Nova\n\nCurrently, the GlusterFS driver has a hard-coded timeout for\nhow long a create or delete snapshot operation can be run by\nNova before it fails the job.\n\nThis change allows the timeout to be reset when Nova sends an\nupdate_snapshot_status update for that snapshot.\n\nSince the volume service (driver) monitors these operations\nby looking at the snapshot progress field in the database,\nwhen an update is recieved that does not contain a progress entry,\nincrement the progress field.\n\n(Currently Nova does not send any real progress info -- only ""done"",\nand now ""still running"" as of this new work for Icehouse.)\n\nIn the driver, reset the timeout when the progress field changes.\n\nThis change is backward compatible with Havana Nova.\n\nCloses-Bug: 1273894\n\nChange-Id: I6d003200e7d33f658ce9db944d835475994ba41f\n'}, {'number': 3, 'created': '2014-02-07 17:10:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/e01c5bef7b2b3352853b1014aff9b28bfc16b0c2', 'message': 'Enable keep-alive updates for snapshot jobs waiting for Nova\n\nCurrently, the GlusterFS driver has a hard-coded timeout for\nhow long a create or delete snapshot operation can be run by\nNova before it fails the job.\n\nThis change allows the timeout to be reset when Nova sends an\nupdate_snapshot_status update.\n\nSince the volume service (driver) monitors these operations\nby looking at the snapshot progress field in the database,\nwhen an update is recieved that does not contain a progress entry,\nincrement the progress field, allowing the driver to reset the\ntimeout.\n\n(Currently Nova does not send any real progress info -- only ""done"",\nand now ""still running"" as of this new work for Icehouse.)\n\nAlso increases the initial timeout to a more realistic period\nfor larger snapshots.\n\nThis change is backward compatible with Havana Nova.\n\nCloses-Bug: 1273894\n\nChange-Id: I6d003200e7d33f658ce9db944d835475994ba41f\n'}, {'number': 4, 'created': '2014-02-14 21:13:28.000000000', 'files': ['cinder/tests/api/contrib/test_snapshot_actions.py', 'cinder/volume/drivers/glusterfs.py', 'cinder/api/contrib/snapshot_actions.py', 'cinder/tests/test_glusterfs.py'], 'web_link': 'https://opendev.org/openstack/cinder/commit/cf8d58e136495a06ff6286a07788e6270713a09b', 'message': 'Enable keep-alive updates for snapshot jobs waiting for Nova\n\nCurrently, the GlusterFS driver has a hard-coded timeout for\nhow long a create or delete snapshot operation can be run by\nNova before it fails the job.\n\nThis change allows the timeout to be reset when Nova sends an\nupdate_snapshot_status update.\n\nSince the volume service (driver) monitors these operations\nby looking at the snapshot progress field in the database,\nwhen an update is recieved that does not contain a progress entry,\nincrement the progress field, allowing the driver to reset the\ntimeout.\n\n(Currently Nova does not send any real progress info -- only ""done"",\nand now ""still running"" as of this new work for Icehouse.)\n\nAlso increases the initial timeout to a more realistic period\nfor larger snapshots.\n\nThis change is backward compatible with Havana Nova.\n\nCloses-Bug: 1273894\n\nChange-Id: I6d003200e7d33f658ce9db944d835475994ba41f\n'}]",16,69759,cf8d58e136495a06ff6286a07788e6270713a09b,35,8,4,4523,,,0,"Enable keep-alive updates for snapshot jobs waiting for Nova

Currently, the GlusterFS driver has a hard-coded timeout for
how long a create or delete snapshot operation can be run by
Nova before it fails the job.

This change allows the timeout to be reset when Nova sends an
update_snapshot_status update.

Since the volume service (driver) monitors these operations
by looking at the snapshot progress field in the database,
when an update is recieved that does not contain a progress entry,
increment the progress field, allowing the driver to reset the
timeout.

(Currently Nova does not send any real progress info -- only ""done"",
and now ""still running"" as of this new work for Icehouse.)

Also increases the initial timeout to a more realistic period
for larger snapshots.

This change is backward compatible with Havana Nova.

Closes-Bug: 1273894

Change-Id: I6d003200e7d33f658ce9db944d835475994ba41f
",git fetch https://review.opendev.org/openstack/cinder refs/changes/59/69759/4 && git format-patch -1 --stdout FETCH_HEAD,"['cinder/tests/api/contrib/test_snapshot_actions.py', 'cinder/volume/drivers/glusterfs.py', 'cinder/api/contrib/snapshot_actions.py']",3,8300bfb7829ebdd673ef2bbdfc645b3c68a58ae2,bug/1273894," Intended for tracking creation and deletion of snapshots that are being processed remotely, so snapshot state transitions are only allowed between a subset of possible beginning (creating/deleting) and end states. Only updates the 'status' and 'progress' fields. def progress_int(progress_str): # progress_str is expected to be a string like '73%', validate try: p_int = int(progress_str[:-1]) if p_int < 0 or p_int > 100 or progress_str[-1] != '%': return p_int progress = body['os-update_snapshot_status'].get('progress', None) if progress: progress_int(progress) else: # Nova sent an update indicating it is still working, # but we don't know how far along it is. # Update progress so that the volume service knows not to # time out the job. current_progress = current_snapshot['progress'] progress = progress_int(current_progress) if progress >= 80: # We are running out of iterations, but Nova is still # sending updates. Reset progress to keep things running. progress = 1 LOG.info(_('update_snapshot_status: resetting progress.')) progress = str(progress) + '%' update_dict.update({'progress': progress})"," Intended for creation of snapshots, so snapshot state must start as 'creating' and be changed to 'available', 'creating', or 'error'. progress = body['os-update_snapshot_status'].get('progress', None) if progress: # This is expected to be a string like '73%' try: integer = int(progress[:-1]) if integer < 0 or integer > 100 or progress[-1] != '%': update_dict.update({'progress': progress}) ",70,29
openstack%2Fceilometer~master~Iadfed3518b8aff7d9fc7a53174c8f7cb27b50ba3,openstack/ceilometer,master,Iadfed3518b8aff7d9fc7a53174c8f7cb27b50ba3,Support for unauthenticated URL option,ABANDONED,2014-02-25 18:23:14.000000000,2014-03-07 06:03:51.000000000,,"[{'_account_id': 3}, {'_account_id': 1669}, {'_account_id': 6230}]","[{'number': 1, 'created': '2014-02-25 18:23:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/4adbf3b9ecef325c5b311980667dad9bdebf910c', 'message': ""Support for unauthenticated URL option\n\nblueprint support-unauth-urls\n\nThis change adds a facility so that ceilometer-api can expose\nURLs that are not part of REST API but are used for health checking\nfrom external monitoring or load balancer. A follow on commit will\nuse this facility.\n\nThis change adds a new middleware class that handles the delegated\nauthentication from keystone authetication middleware.\n\nExample: The Delegate middleware will allow the URL '/health' if ceilometer.conf contains\ndelay_auth_decision = True\nnoauth_url = /health\n\nChange-Id: Iadfed3518b8aff7d9fc7a53174c8f7cb27b50ba3\n""}, {'number': 2, 'created': '2014-02-25 19:49:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/55d1cac775feac71b00c8ce9092a94baaf368058', 'message': ""Support for unauthenticated URL option\n\nblueprint support-unauth-urls\n\nThis change adds a facility so that ceilometer-api can expose\nURLs that are not part of REST API but are used for health checking\nfrom external monitoring or load balancer. A follow on commit will\nuse this facility.\n\nThis change adds a new middleware class that handles the delegated\nauthentication from keystone authetication middleware.\n\nExample: The Delegate middleware will allow the URL '/health' if ceilometer.conf contains\ndelay_auth_decision = True\nnoauth_url = /health\n\nChange-Id: Iadfed3518b8aff7d9fc7a53174c8f7cb27b50ba3\n""}, {'number': 3, 'created': '2014-02-25 21:48:31.000000000', 'files': ['ceilometer/api/acl.py', 'ceilometer/api/app.py', 'ceilometer/api/middleware.py', 'etc/ceilometer/ceilometer.conf.sample'], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/d38627c94e85a61666c4c2d884408ee51e5669c3', 'message': ""Support for unauthenticated URL option\n\nblueprint support-unauth-urls\n\nThis change adds a facility so that ceilometer-api can expose\nURLs that are not part of REST API but are used for health checking\nfrom external monitoring or load balancer. A follow on commit will\nuse this facility.\n\nThis change adds a new middleware class that handles the delegated\nauthentication from keystone authetication middleware.\n\nExample: The Delegate middleware will allow the URL '/health' if ceilometer.conf contains\ndelay_auth_decision = True\nnoauth_url = /health\n\nChange-Id: Iadfed3518b8aff7d9fc7a53174c8f7cb27b50ba3\n""}]",0,76303,d38627c94e85a61666c4c2d884408ee51e5669c3,15,3,3,6230,,,0,"Support for unauthenticated URL option

blueprint support-unauth-urls

This change adds a facility so that ceilometer-api can expose
URLs that are not part of REST API but are used for health checking
from external monitoring or load balancer. A follow on commit will
use this facility.

This change adds a new middleware class that handles the delegated
authentication from keystone authetication middleware.

Example: The Delegate middleware will allow the URL '/health' if ceilometer.conf contains
delay_auth_decision = True
noauth_url = /health

Change-Id: Iadfed3518b8aff7d9fc7a53174c8f7cb27b50ba3
",git fetch https://review.opendev.org/openstack/ceilometer refs/changes/03/76303/3 && git format-patch -1 --stdout FETCH_HEAD,"['ceilometer/api/acl.py', 'ceilometer/api/app.py', 'ceilometer/api/middleware.py']",3,4adbf3b9ecef325c5b311980667dad9bdebf910c,bp/support-unauth-urls,"from keystoneclient.middleware import auth_token class Delegate(object): """"""Middleware to handle delegated authentication checking """""" def __init__(self, app, conf): self.app = app self.conf = conf def __call__(self, env, start_response): if env['HTTP_X_IDENTITY_STATUS'] == 'Invalid': # check if URL is allowed without authentication if env['PATH_INFO'] in self.conf['noauth_url']: return self.app(env, start_response) else: return self._reject_request(env, start_response) else: return self.app(env, start_response) def _reject_request(self, env, start_response): """"""Redirect client to auth server. :param env: wsgi request environment :param start_response: wsgi response callback :returns HTTPUnauthorized http response """""" headers = [('WWW-Authenticate', 'Keystone uri=\'%s\'' % None)] resp = auth_token.MiniResp('Authentication required', env, headers) start_response('401 Unauthorized', resp.headers) return resp.body",,39,0
openstack%2Fheat~master~Ic6e1794a71c556e772ca66f857e573045d56b3de,openstack/heat,master,Ic6e1794a71c556e772ca66f857e573045d56b3de,Sync log.py from oslo,ABANDONED,2014-02-19 09:09:43.000000000,2014-03-07 06:03:51.000000000,,"[{'_account_id': 3}, {'_account_id': 2834}, {'_account_id': 3098}, {'_account_id': 4257}, {'_account_id': 4328}, {'_account_id': 4330}, {'_account_id': 4571}, {'_account_id': 6488}, {'_account_id': 7253}, {'_account_id': 7256}, {'_account_id': 9323}]","[{'number': 1, 'created': '2014-02-19 09:09:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/02b57f78ad18851f2049a0958b0aa120b03bee8e', 'message': 'Sync log.py from oslo\n\nTo honor RFC5424 add use_syslog_rfc_format config option\n(default False, would be deprecated in J after existing\nsyslog format deprecation) which adds APP-NAME to syslog message\nbefore MSG part to reflect aplication or service name.\nUsable only with use_syslog, otherwise ignored.\n\nDuring J, the default logging format for syslog should be changed\nto always provide APP-NAME, thus use_syslog_rfc_format could be\ndeprecated in J as well.\n\nFixes Bug904307\n\nChange-Id: Ic6e1794a71c556e772ca66f857e573045d56b3de\n'}, {'number': 2, 'created': '2014-02-20 01:05:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/c3c79510c695720266a6bbba97253492594ccd57', 'message': 'Sync log.py from oslo\n\nTo honor RFC5424 add use_syslog_rfc_format config option\n(default False, would be deprecated in J after existing\nsyslog format deprecation) which adds APP-NAME to syslog message\nbefore MSG part to reflect aplication or service name.\nUsable only with use_syslog, otherwise ignored.\n\nDuring J, the default logging format for syslog should be changed\nto always provide APP-NAME, thus use_syslog_rfc_format could be\ndeprecated in J as well.\n\nFixes Bug904307\n\nChange-Id: Ic6e1794a71c556e772ca66f857e573045d56b3de\n'}, {'number': 3, 'created': '2014-02-20 01:32:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/75fe79d5849830b00306b9ed613d9fc9ad60b7fc', 'message': 'Sync log.py from oslo\n\nThis change syncs log.py from oslo-incubator with commit\n79e8a9a08daf563aa8a8d9280c9a6a27dcafc8f2\n\nTo honor RFC5424 add use_syslog_rfc_format config option\n(default False, would be deprecated in J after existing\nsyslog format deprecation) which adds APP-NAME to syslog message\nbefore MSG part to reflect aplication or service name.\nUsable only with use_syslog, otherwise ignored.\n\nDuring J, the default logging format for syslog should be changed\nto always provide APP-NAME, thus use_syslog_rfc_format could be\ndeprecated in J as well.\n\nCloses-bug: 904307\n\nChange-Id: Ic6e1794a71c556e772ca66f857e573045d56b3de\n'}, {'number': 4, 'created': '2014-02-20 02:44:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/ceba3403b2f4fe79778032f584ee279a1f3bb7af', 'message': 'Sync log.py from oslo\n\nThis change syncs log.py from oslo-incubator with commit\n79e8a9a08daf563aa8a8d9280c9a6a27dcafc8f2\n\nTo honor RFC5424 add use_syslog_rfc_format config option\n(default False, would be deprecated in J after existing\nsyslog format deprecation) which adds APP-NAME to syslog message\nbefore MSG part to reflect aplication or service name.\nUsable only with use_syslog, otherwise ignored.\n\nDuring J, the default logging format for syslog should be changed\nto always provide APP-NAME, thus use_syslog_rfc_format could be\ndeprecated in J as well.\n\nCloses-bug: 904307\n\nChange-Id: Ic6e1794a71c556e772ca66f857e573045d56b3de\n'}, {'number': 5, 'created': '2014-02-24 13:12:29.000000000', 'files': ['etc/heat/heat.conf.sample', 'heat/openstack/common/log.py'], 'web_link': 'https://opendev.org/openstack/heat/commit/edeb97c715bb8c5a617b46ba48867936f46e7e5c', 'message': 'Sync log.py from oslo\n\nThis change syncs log.py from oslo-incubator with commit\n79e8a9a08daf563aa8a8d9280c9a6a27dcafc8f2\n\nTo honor RFC5424 add use_syslog_rfc_format config option\n(default False, would be deprecated in J after existing\nsyslog format deprecation) which adds APP-NAME to syslog message\nbefore MSG part to reflect aplication or service name.\nUsable only with use_syslog, otherwise ignored.\n\nDuring J, the default logging format for syslog should be changed\nto always provide APP-NAME, thus use_syslog_rfc_format could be\ndeprecated in J as well.\n\nCloses-bug: 904307\n\nChange-Id: Ic6e1794a71c556e772ca66f857e573045d56b3de\n'}]",1,74635,edeb97c715bb8c5a617b46ba48867936f46e7e5c,32,11,5,9323,,,0,"Sync log.py from oslo

This change syncs log.py from oslo-incubator with commit
79e8a9a08daf563aa8a8d9280c9a6a27dcafc8f2

To honor RFC5424 add use_syslog_rfc_format config option
(default False, would be deprecated in J after existing
syslog format deprecation) which adds APP-NAME to syslog message
before MSG part to reflect aplication or service name.
Usable only with use_syslog, otherwise ignored.

During J, the default logging format for syslog should be changed
to always provide APP-NAME, thus use_syslog_rfc_format could be
deprecated in J as well.

Closes-bug: 904307

Change-Id: Ic6e1794a71c556e772ca66f857e573045d56b3de
",git fetch https://review.opendev.org/openstack/heat refs/changes/35/74635/2 && git format-patch -1 --stdout FETCH_HEAD,"['etc/heat/heat.conf.sample', 'heat/openstack/common/log.py']",2,02b57f78ad18851f2049a0958b0aa120b03bee8e,Bug1283956," help='Use syslog for logging. ' 'Existing syslog format is DEPRECATED during I, ' 'and then will be changed in J to honor RFC5424'), cfg.BoolOpt('use-syslog-rfc-format', # TODO(bogdando) remove or use True after existing # syslog format deprecation in J default=False, help='(Optional) Use syslog rfc5424 format for logging. ' 'If enabled, will add APP-NAME (RFC5424) before the ' 'MSG part of the syslog message. The old format ' 'without APP-NAME is deprecated in I, ' 'and will be removed in J.'),class RFCSysLogHandler(logging.handlers.SysLogHandler): def __init__(self, *args, **kwargs): self.binary_name = _get_binary_name() super(RFCSysLogHandler, self).__init__(*args, **kwargs) def format(self, record): msg = super(RFCSysLogHandler, self).format(record) msg = self.binary_name + ' ' + msg return msg # TODO(bogdando) use the format provided by RFCSysLogHandler # after existing syslog format deprecation in J if CONF.use_syslog_rfc_format: syslog = RFCSysLogHandler(address='/dev/log', facility=facility) else: syslog = logging.handlers.SysLogHandler(address='/dev/log', facility=facility)"," help='Use syslog for logging.'), syslog = logging.handlers.SysLogHandler(address='/dev/log', facility=facility)",40,4
openstack%2Fheat-cfnclient~master~I29c328c17d1e7dfc14980365fd7a706694250333,openstack/heat-cfnclient,master,I29c328c17d1e7dfc14980365fd7a706694250333,Exception message should not be localize,ABANDONED,2014-02-27 09:15:12.000000000,2014-03-07 06:03:49.000000000,,[{'_account_id': 3}],"[{'number': 1, 'created': '2014-02-27 09:15:12.000000000', 'files': ['heat_cfnclient/common/auth.py'], 'web_link': 'https://opendev.org/openstack/heat-cfnclient/commit/dca3b9b9e8ec9ecc3fbbc807c89a9564f6fd4fbb', 'message': 'Exception message should not be localize\n\nException text should not be marked for translation, becuase\nif an exception occurs there is no guarantee that the\ntranslation machinery will be functional.\n\nChange-Id: I29c328c17d1e7dfc14980365fd7a706694250333\nPartial-Bug:  #1285530\n'}]",0,76804,dca3b9b9e8ec9ecc3fbbc807c89a9564f6fd4fbb,4,1,1,7543,,,0,"Exception message should not be localize

Exception text should not be marked for translation, becuase
if an exception occurs there is no guarantee that the
translation machinery will be functional.

Change-Id: I29c328c17d1e7dfc14980365fd7a706694250333
Partial-Bug:  #1285530
",git fetch https://review.opendev.org/openstack/heat-cfnclient refs/changes/04/76804/1 && git format-patch -1 --stdout FETCH_HEAD,['heat_cfnclient/common/auth.py'],1,dca3b9b9e8ec9ecc3fbbc807c89a9564f6fd4fbb,localize," raise Exception(('Unexpected response: %(status)s') raise Exception((""Unknown auth strategy '%s'"") % strategy)"," raise Exception(_('Unexpected response: %(status)s') raise Exception(_(""Unknown auth strategy '%s'"") % strategy)",2,2
openstack%2Foslo.messaging~master~I29c328c17d1e7dfc14980365fd7a706694250333,openstack/oslo.messaging,master,I29c328c17d1e7dfc14980365fd7a706694250333,Exception message should not be localize,ABANDONED,2014-02-27 09:18:23.000000000,2014-03-07 06:03:47.000000000,,[{'_account_id': 3}],"[{'number': 1, 'created': '2014-02-27 09:18:23.000000000', 'files': ['oslo/messaging/_drivers/impl_zmq.py', 'oslo/messaging/openstack/common/sslutils.py'], 'web_link': 'https://opendev.org/openstack/oslo.messaging/commit/f7718ae624f1dfd0d254e0b626e6368d3f4ad421', 'message': 'Exception message should not be localize\n\nException text should not be marked for translation, becuase\nif an exception occurs there is no guarantee that the\ntranslation machinery will be functional.\n\nChange-Id: I29c328c17d1e7dfc14980365fd7a706694250333\nPartial-Bug:  #1285530\n'}]",0,76806,f7718ae624f1dfd0d254e0b626e6368d3f4ad421,4,1,1,7543,,,0,"Exception message should not be localize

Exception text should not be marked for translation, becuase
if an exception occurs there is no guarantee that the
translation machinery will be functional.

Change-Id: I29c328c17d1e7dfc14980365fd7a706694250333
Partial-Bug:  #1285530
",git fetch https://review.opendev.org/openstack/oslo.messaging refs/changes/06/76806/1 && git format-patch -1 --stdout FETCH_HEAD,"['oslo/messaging/_drivers/impl_zmq.py', 'oslo/messaging/openstack/common/sslutils.py']",2,f7718ae624f1dfd0d254e0b626e6368d3f4ad421,localize," raise RuntimeError((""Unable to find cert_file : %s"") % cert_file) raise RuntimeError((""Unable to find ca_file : %s"") % ca_file) raise RuntimeError((""Unable to find key_file : %s"") % key_file) raise RuntimeError((""When running server in SSL mode, you must """," raise RuntimeError(_(""Unable to find cert_file : %s"") % cert_file) raise RuntimeError(_(""Unable to find ca_file : %s"") % ca_file) raise RuntimeError(_(""Unable to find key_file : %s"") % key_file) raise RuntimeError(_(""When running server in SSL mode, you must """,7,7
openstack%2Fpython-neutronclient~master~I29c328c17d1e7dfc14980365fd7a706694250333,openstack/python-neutronclient,master,I29c328c17d1e7dfc14980365fd7a706694250333,Exception message should not be localize,ABANDONED,2014-02-27 09:07:06.000000000,2014-03-07 06:03:47.000000000,,[{'_account_id': 3}],"[{'number': 1, 'created': '2014-02-27 09:07:06.000000000', 'files': ['neutronclient/client.py', 'neutronclient/openstack/common/importutils.py', 'neutronclient/neutron/v2_0/subnet.py', 'neutronclient/v2_0/client.py', 'neutronclient/neutron/client.py', 'neutronclient/openstack/common/strutils.py'], 'web_link': 'https://opendev.org/openstack/python-neutronclient/commit/9e1cc28866457fe79a1c2a1d549706c6cd4516e1', 'message': 'Exception message should not be localize\n\nException text should not be marked for translation, becuase\nif an exception occurs there is no guarantee that the\ntranslation machinery will be functional.\n\nChange-Id: I29c328c17d1e7dfc14980365fd7a706694250333\nPartial-Bug:  #1285530\n'}]",0,76802,9e1cc28866457fe79a1c2a1d549706c6cd4516e1,4,1,1,7543,,,0,"Exception message should not be localize

Exception text should not be marked for translation, becuase
if an exception occurs there is no guarantee that the
translation machinery will be functional.

Change-Id: I29c328c17d1e7dfc14980365fd7a706694250333
Partial-Bug:  #1285530
",git fetch https://review.opendev.org/openstack/python-neutronclient refs/changes/02/76802/1 && git format-patch -1 --stdout FETCH_HEAD,"['neutronclient/client.py', 'neutronclient/neutron/v2_0/subnet.py', 'neutronclient/openstack/common/importutils.py', 'neutronclient/v2_0/client.py', 'neutronclient/neutron/client.py', 'neutronclient/openstack/common/strutils.py']",6,9e1cc28866457fe79a1c2a1d549706c6cd4516e1,master," raise TypeError((""%s can't be encoded"") % type(text).capitalize()) msg = ('Invalid string format: %s') % text msg = ('Unknown byte multiplier: %s') % mult_key_org"," raise TypeError(_(""%s can't be encoded"") % type(text).capitalize()) msg = _('Invalid string format: %s') % text msg = _('Unknown byte multiplier: %s') % mult_key_org",9,9
openstack%2Fnova~master~Ide4041cb1daff9a66210cdf0dbdeaf7cb73b02bc,openstack/nova,master,Ide4041cb1daff9a66210cdf0dbdeaf7cb73b02bc,Xenapi Glance plugin should switch to bufferedhttp,ABANDONED,2014-01-09 06:43:58.000000000,2014-03-07 06:03:43.000000000,,"[{'_account_id': 3}, {'_account_id': 782}, {'_account_id': 1030}, {'_account_id': 1849}, {'_account_id': 2271}, {'_account_id': 7531}, {'_account_id': 9008}, {'_account_id': 9578}]","[{'number': 1, 'created': '2014-01-09 06:43:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/680dc5ff6b3305b3f166f4231e5e3bc13919829b', 'message': ""Xenapi Glance plugin should switch to bufferedhttp\n\nGlance plugin should switch to using bufferedhttp like in\nswift which makes up for missing features in traditional httplib.\nEg. buffering http headers, support for 'Expect: 100-continue' etc.\nThis patch pulls in the bufferedhttp from swift.\n\nRelated to bp: use-buffered-http-in-glance-plugin\nChange-Id: Ide4041cb1daff9a66210cdf0dbdeaf7cb73b02bc\n""}, {'number': 2, 'created': '2014-01-09 10:53:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/30c6cc128523f7ceaa5a939f8799ffe1acbf7d1e', 'message': ""Xenapi Glance plugin should switch to bufferedhttp\n\nGlance plugin should switch to using bufferedhttp like in\nswift which makes up for missing features in traditional httplib.\nEg. buffering http headers, support for 'Expect: 100-continue' etc.\nThis patch pulls in the bufferedhttp from swift.\n\nRelated to bp: use-buffered-http-in-glance-plugin\nChange-Id: Ide4041cb1daff9a66210cdf0dbdeaf7cb73b02bc\n""}, {'number': 3, 'created': '2014-01-09 12:45:20.000000000', 'files': ['nova/tests/test_bufferedhttp.py', 'nova/openstack/common/bufferedhttp.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/6abe8abe90b04afc0e7fcf5c67105596432b2c93', 'message': ""Xenapi Glance plugin should switch to bufferedhttp\n\nGlance plugin should switch to using bufferedhttp like in\nswift which makes up for missing features in traditional httplib.\nEg. buffering http headers, support for 'Expect: 100-continue' etc.\nThis patch pulls in the bufferedhttp from swift.\n\nRelated to bp: use-buffered-http-in-glance-plugin\nChange-Id: Ide4041cb1daff9a66210cdf0dbdeaf7cb73b02bc\n""}]",0,65624,6abe8abe90b04afc0e7fcf5c67105596432b2c93,26,8,3,7531,,,0,"Xenapi Glance plugin should switch to bufferedhttp

Glance plugin should switch to using bufferedhttp like in
swift which makes up for missing features in traditional httplib.
Eg. buffering http headers, support for 'Expect: 100-continue' etc.
This patch pulls in the bufferedhttp from swift.

Related to bp: use-buffered-http-in-glance-plugin
Change-Id: Ide4041cb1daff9a66210cdf0dbdeaf7cb73b02bc
",git fetch https://review.opendev.org/openstack/nova refs/changes/24/65624/1 && git format-patch -1 --stdout FETCH_HEAD,"['nova/tests/test_bufferedhttp.py', 'nova/openstack/common/bufferedhttp.py']",2,680dc5ff6b3305b3f166f4231e5e3bc13919829b,bp/use-buffered-http-in-glance-plugin,"# Copyright 2013 RACKSPACE HOSTING # # Licensed under the Apache License, Version 2.0 (the ""License""); # you may not use this file except in compliance with the License. # You may obtain a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or # implied. # See the License for the specific language governing permissions and # limitations under the License. from six.moves import http_client class BufferedHTTPResponse(http_client.HTTPResponse): """"""HTTPResponse class that buffers reading of headers sock is an eventlet.greenio.GreenSocket. """""" def __init__(self, sock, debuglevel=0, strict=0, method=None): # pragma: no cover self.sock = sock self.fp = sock.makefile('rb') self.debuglevel = debuglevel self.strict = strict self._method = method self.msg = None # from the Status-Line of the response self.version = http_client._UNKNOWN self.status = http_client._UNKNOWN self.reason = http_client._UNKNOWN self.chunked = http_client._UNKNOWN self.chunk_left = http_client._UNKNOWN self.length = http_client._UNKNOWN self.will_close = http_client._UNKNOWN def expect_response(self): if self.fp: self.fp.close() self.fp = None self.fp = self.sock.makefile('rb', 0) version, status, reason = self._read_status() if status != http_client.CONTINUE: self._read_status = lambda: (version, status, reason) self.begin() else: self.status = status self.reason = reason.strip() self.version = 11 self.msg = http_client.HTTPMessage(self.fp, 0) self.msg.fp = None class BufferedHTTPConnection(http_client.HTTPConnection): """"""HTTPConnection class that uses BufferedHTTPResponse."""""" response_class = BufferedHTTPResponse def getexpect(self): response = BufferedHTTPResponse(self.sock, strict=self.strict, method=self._method) response.expect_response() return response class BufferedHTTPSConnection(http_client.HTTPSConnection): """"""HTTPSConnection class that uses BufferedHTTPResponse."""""" response_class = BufferedHTTPResponse def getexpect(self): response = BufferedHTTPResponse(self.sock, strict=self.strict, method=self._method) response.expect_response() return response ",,140,0
openstack%2Fdevstack~master~Ic1e68f58f12ad69083bedcf0b7e50bf07018e80e,openstack/devstack,master,Ic1e68f58f12ad69083bedcf0b7e50bf07018e80e,Update base address of the my_ip in cinder.conf,ABANDONED,2014-02-24 17:46:11.000000000,2014-03-07 06:03:41.000000000,,"[{'_account_id': 3}, {'_account_id': 970}, {'_account_id': 2750}, {'_account_id': 5689}, {'_account_id': 7236}]","[{'number': 1, 'created': '2014-02-24 17:46:11.000000000', 'files': ['lib/cinder'], 'web_link': 'https://opendev.org/openstack/devstack/commit/38884a2246dffe6fe71e33d1fd44cc7c74bd2fa2', 'message': 'Update base address of the my_ip in cinder.conf\n\nUse HOST_IP in default case and $CINDER_SERVICE_HOST\ncan be used for cases when cinder-volume placed in\nanother host\n\nChange-Id: Ic1e68f58f12ad69083bedcf0b7e50bf07018e80e\nCloses-Bug:#1249138\n'}]",0,75939,38884a2246dffe6fe71e33d1fd44cc7c74bd2fa2,8,5,1,7051,,,0,"Update base address of the my_ip in cinder.conf

Use HOST_IP in default case and $CINDER_SERVICE_HOST
can be used for cases when cinder-volume placed in
another host

Change-Id: Ic1e68f58f12ad69083bedcf0b7e50bf07018e80e
Closes-Bug:#1249138
",git fetch https://review.opendev.org/openstack/devstack refs/changes/39/75939/1 && git format-patch -1 --stdout FETCH_HEAD,['lib/cinder'],1,38884a2246dffe6fe71e33d1fd44cc7c74bd2fa2,bug/1249138,CINDER_SERVICE_HOST=${CINDER_SERVICE_HOST:-$HOST_IP},CINDER_SERVICE_HOST=${CINDER_SERVICE_HOST:-$SERVICE_HOST},1,1
openstack%2Fsolum~master~I93bcc582728c2a1ae8c838647c039f42de0f779b,openstack/solum,master,I93bcc582728c2a1ae8c838647c039f42de0f779b,"Provide a ""docker compute vm""",ABANDONED,2014-02-26 12:19:49.000000000,2014-03-07 06:03:37.000000000,,"[{'_account_id': 3}, {'_account_id': 668}, {'_account_id': 7858}, {'_account_id': 9537}, {'_account_id': 9808}]","[{'number': 1, 'created': '2014-02-26 12:19:49.000000000', 'files': ['contrib/docker-compute-vm/elements/docker/install.d/02-install-docker', 'contrib/docker-compute-vm/build-docker-compute-vm.sh'], 'web_link': 'https://opendev.org/openstack/solum/commit/d14c3ff246fff76e45e3db5e0df52f5af98eb59b', 'message': 'Provide a ""docker compute vm""\n\nThe purpose of this image is to prodive a mechanism to be able to\nhave a compute node with a docker driver in a non-docker setup of\nOpenStack.\n\nthe workflow would be\n- disimage-builder : build image\n- glance : upload image\n- nova : boot docker compute vm\n- (Some configuration steps here or maybe in the image building\n  process)\n- nova : boot docker container on the compute vm\n\nThis is a POC/work in progress.\n\nChange-Id: I93bcc582728c2a1ae8c838647c039f42de0f779b\n'}]",2,76512,d14c3ff246fff76e45e3db5e0df52f5af98eb59b,8,5,1,9537,,,0,"Provide a ""docker compute vm""

The purpose of this image is to prodive a mechanism to be able to
have a compute node with a docker driver in a non-docker setup of
OpenStack.

the workflow would be
- disimage-builder : build image
- glance : upload image
- nova : boot docker compute vm
- (Some configuration steps here or maybe in the image building
  process)
- nova : boot docker container on the compute vm

This is a POC/work in progress.

Change-Id: I93bcc582728c2a1ae8c838647c039f42de0f779b
",git fetch https://review.opendev.org/openstack/solum refs/changes/12/76512/1 && git format-patch -1 --stdout FETCH_HEAD,"['contrib/docker-compute-vm/elements/docker/install.d/02-install-docker', 'contrib/docker-compute-vm/build-docker-compute-vm.sh']",2,d14c3ff246fff76e45e3db5e0df52f5af98eb59b,,#!/bin/bash if [ ! -d tripleo-image-elements ]; then git clone https://github.com/openstack/tripleo-image-elements.git fi ELEMENTS_PATH=./elements:./tripleo-image-elements/elements disk-image-create \ --no-tmpfs -a amd64 vm ubuntu -o docker-compute.qcow2 docker nova-compute ,,15,0
openstack%2Ffuel-library~master~I8d9d1d5cba3a370d291db3484627b8c0ea708d47,openstack/fuel-library,master,I8d9d1d5cba3a370d291db3484627b8c0ea708d47,Add filesystem_store_data to glance API conf,ABANDONED,2014-02-25 16:24:51.000000000,2014-03-07 06:03:37.000000000,,"[{'_account_id': 3}, {'_account_id': 6926}, {'_account_id': 7195}, {'_account_id': 8797}, {'_account_id': 8971}]","[{'number': 1, 'created': '2014-02-25 16:24:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/71ffcf52b194e39603749ae2f5cdbb964ba8b25d', 'message': 'Add filesystem_store_data to glance API conf\n\nGlance API requires this option to be\npresent or it reports a non-fatal error.\n\nChange-Id: I8d9d1d5cba3a370d291db3484627b8c0ea708d47\nPartial-Bug: 1284236\n'}, {'number': 2, 'created': '2014-02-27 13:47:06.000000000', 'files': ['deployment/puppet/glance/manifests/backend/file.pp', 'deployment/puppet/glance/manifests/api.pp'], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/2e7a1428d75c2ab58067e483b056ebadfdf24039', 'message': 'Add filesystem_store_data to glance API conf\n\n* Glance API requires this option to be\n  present or it reports a non-fatal error.\n* Removed filesystem_store_data from file\n  backend so it is always present in glance\n  API conf.\n\nChange-Id: I8d9d1d5cba3a370d291db3484627b8c0ea708d47\nPartial-Bug: 1284236\n'}]",1,76252,2e7a1428d75c2ab58067e483b056ebadfdf24039,19,5,2,7195,,,0,"Add filesystem_store_data to glance API conf

* Glance API requires this option to be
  present or it reports a non-fatal error.
* Removed filesystem_store_data from file
  backend so it is always present in glance
  API conf.

Change-Id: I8d9d1d5cba3a370d291db3484627b8c0ea708d47
Partial-Bug: 1284236
",git fetch https://review.opendev.org/openstack/fuel-library refs/changes/52/76252/1 && git format-patch -1 --stdout FETCH_HEAD,['deployment/puppet/glance/manifests/api.pp'],1,71ffcf52b194e39603749ae2f5cdbb964ba8b25d,bug/1284236," 'DEFAULT/filesystem_store_datadir': value => ""/var/lib/glance/images/"";",,1,0
openstack%2Ffuel-web~master~I0381413438183ab51de8afb191ae00e68d29c4dc,openstack/fuel-web,master,I0381413438183ab51de8afb191ae00e68d29c4dc,Removed shotgun python package,ABANDONED,2014-02-27 15:21:04.000000000,2014-03-07 06:03:35.000000000,,"[{'_account_id': 3}, {'_account_id': 8971}]","[{'number': 1, 'created': '2014-02-27 15:21:04.000000000', 'files': ['shotgun/bin/example.py', 'shotgun/shotgun/logger.py', 'shotgun/shotgun/test/test_config.py', 'shotgun/shotgun/__init__.py', 'shotgun/setup.py', 'shotgun/shotgun/driver.py', 'shotgun/shotgun/test/__init__.py', 'shotgun/shotgun/manager.py', 'shotgun/bin/example.json', 'shotgun/shotgun/config.py', 'shotgun/shotgun/utils.py', 'shotgun/shotgun/settings.py', 'shotgun/shotgun/test/test_driver.py'], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/590e3258774caa5fbe2873e4c01213100fc8a434', 'message': 'Removed shotgun python package\n\nThis package is moved into third-party repository\nhttps://github.com/kozhukalov/shotgun.git\nand now it is available on pypi.python.org\n\nChange-Id: I0381413438183ab51de8afb191ae00e68d29c4dc\n'}]",0,76889,590e3258774caa5fbe2873e4c01213100fc8a434,7,2,1,3009,,,0,"Removed shotgun python package

This package is moved into third-party repository
https://github.com/kozhukalov/shotgun.git
and now it is available on pypi.python.org

Change-Id: I0381413438183ab51de8afb191ae00e68d29c4dc
",git fetch https://review.opendev.org/openstack/fuel-web refs/changes/89/76889/1 && git format-patch -1 --stdout FETCH_HEAD,"['shotgun/bin/example.py', 'shotgun/shotgun/logger.py', 'shotgun/shotgun/test/test_config.py', 'shotgun/shotgun/__init__.py', 'shotgun/setup.py', 'shotgun/shotgun/driver.py', 'shotgun/shotgun/test/__init__.py', 'shotgun/shotgun/manager.py', 'shotgun/bin/example.json', 'shotgun/shotgun/config.py', 'shotgun/shotgun/utils.py', 'shotgun/shotgun/settings.py', 'shotgun/shotgun/test/test_driver.py']",13,590e3258774caa5fbe2873e4c01213100fc8a434,master,,"# Copyright 2013 Mirantis, Inc. # # Licensed under the Apache License, Version 2.0 (the ""License""); you may # not use this file except in compliance with the License. You may obtain # a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT # WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the # License for the specific language governing permissions and limitations # under the License. import fnmatch import os try: from unittest.case import TestCase except ImportError: # Runing unit-tests in production environment from unittest2.case import TestCase from mock import call from mock import MagicMock from mock import patch import shotgun.config import shotgun.driver import shotgun.settings class RunOut(object): return_code = None stderr = None stdout = None def __str__(self): return str(self.stdout) class TestDriver(TestCase): def test_driver_factory(self): types = { ""file"": ""File"", ""dir"": ""Dir"", ""subs"": ""Subs"", ""postgres"": ""Postgres"", ""command"": ""Command"" } for t, n in types.iteritems(): with patch(""shotgun.driver.%s"" % n) as mocked: shotgun.driver.Driver.getDriver({""type"": t}, None) mocked.assert_called_with({""type"": t}, None) @patch('shotgun.driver.execute') @patch('shotgun.driver.fabric.api.settings') @patch('shotgun.driver.fabric.api.run') def test_driver_command(self, mfabrun, mfabset, mexecute): out = shotgun.driver.CommandOut() out.stdout = ""STDOUT"" out.return_code = ""RETURN_CODE"" out.stderr = ""STDERR"" runout = RunOut() runout.stdout = ""STDOUT"" runout.return_code = ""RETURN_CODE"" runout.stderr = ""STDERR"" mfabrun.return_value = runout mexecute.return_value = (""RETURN_CODE"", ""STDOUT"", ""STDERR"") command = ""COMMAND"" driver = shotgun.driver.Driver({""host"": ""remote_host""}, None) result = driver.command(command) shotgun.driver.fabric.api.run.assert_called_with(command, pty=True) self.assertEquals(result, out) shotgun.driver.fabric.api.settings.assert_called_with( host_string=""remote_host"", timeout=2, warn_only=True) driver = shotgun.driver.Driver({}, None) result = driver.command(command) shotgun.driver.execute.assert_called_with(command) self.assertEquals(result, out) @patch('shotgun.driver.execute') @patch('shotgun.driver.fabric.api.settings') @patch('shotgun.driver.fabric.api.get') def test_driver_get(self, mfabget, mfabset, mexecute): mexecute.return_value = (""RETURN_CODE"", ""STDOUT"", ""STDERR"") remote_path = ""/remote_dir/remote_file"" target_path = ""/target_dir"" driver = shotgun.driver.Driver({""host"": ""remote_host""}, None) driver.get(remote_path, target_path) mexecute.assert_called_with(""mkdir -p %s"" % target_path) mfabget.assert_called_with(remote_path, target_path) mfabset.assert_called_with( host_string=""remote_host"", timeout=2, warn_only=True) mexecute.reset_mock() driver = shotgun.driver.Driver({}, None) driver.get(remote_path, target_path) assert mexecute.mock_calls == [ call(""mkdir -p %s"" % target_path), call(""cp -r %s %s"" % (remote_path, target_path)) ] class TestFile(TestCase): @patch('shotgun.driver.Driver.get') def test_snapshot(self, mget): data = { ""type"": ""file"", ""path"": ""/remote_dir/remote_file"", ""host"": ""remote_host"" } conf = MagicMock() conf.target = ""/target"" file_driver = shotgun.driver.File(data, conf) target_path = ""/target/remote_host/remote_dir"" file_driver.snapshot() mget.assert_called_with(data[""path""], target_path) class TestSubs(TestCase): def setUp(self): self.data = { ""type"": ""subs"", ""path"": ""/remote_dir/remote_file"", ""host"": ""remote_host"", ""subs"": { ""line0"": ""LINE0"", ""line1"": ""LINE1"" } } self.conf = MagicMock() self.conf.target = ""/target"" self.sedscript = MagicMock() self.sedscript.name = ""SEDSCRIPT"" self.sedscript.write = MagicMock() @patch('shotgun.driver.tempfile.NamedTemporaryFile') @patch('shotgun.driver.Driver.get') @patch('shotgun.driver.execute') def test_sed(self, mexecute, mget, mntemp): mexecute.return_value = (""RETURN_CODE"", ""STDOUT"", ""STDERR"") mntemp.return_value = self.sedscript subs_driver = shotgun.driver.Subs(self.data, self.conf) subs_driver.sed(""from_file"", ""to_file"") assert self.sedscript.write.mock_calls == [ call(""s/%s/%s/g\n"" % (old, new)) for old, new in self.data[""subs""].iteritems()] shotgun.driver.execute.assert_called_with( ""cat from_file | sed -f SEDSCRIPT"", to_filename=""to_file"") subs_driver.sed(""from_file.gz"", ""to_file.gz"") shotgun.driver.execute.assert_called_with( ""cat from_file.gz | gunzip -c | sed -f SEDSCRIPT | gzip -c"", to_filename=""to_file.gz"") subs_driver.sed(""from_file.bz2"", ""to_file.bz2"") shotgun.driver.execute.assert_called_with( ""cat from_file.bz2 | bunzip2 -c | sed -f SEDSCRIPT | bzip2 -c"", to_filename=""to_file.bz2"") @patch('shotgun.driver.os.walk') @patch('shotgun.driver.Subs.sed') @patch('shotgun.driver.Driver.get') @patch('shotgun.driver.execute') def test_snapshot(self, mexecute, mdriverget, msed, mwalk): mexecute.return_value = (""RETURN_CODE"", ""STDOUT"", ""STDERR"") """""" 1. Should get remote (or local) file (or directory) 2. Should put it into /target/host.domain.tld 3. Should walk through and check if files match given path pattern 4. If matched, sed them """""" """"""this return_value corresponds to the following structure /target/remote_host/remote_dir/ /target/remote_host/remote_dir/remote_file /target/remote_host/remote_dir/1 /target/remote_host/remote_dir/2 /target/remote_host/remote_dir/3/ /target/remote_host/remote_dir/3/4 /target/remote_host/remote_dir/3/5 /target/remote_host/remote_dir/3/6/ """""" mock_walk = [ ( '/target/remote_host/remote_dir', ['3'], ['1', '2', 'remote_file'] ), ('/target/remote_host/remote_dir/3', ['6'], ['5', '4']), ('/target/remote_host/remote_dir/3/6', [], []) ] mwalk.return_value = mock_walk subs_driver = shotgun.driver.Subs(self.data, self.conf) subs_driver.snapshot() sed_calls = [] execute_calls = [] for root, _, files in mock_walk: for filename in files: fullfilename = os.path.join(root, filename) # /target/remote_host tgt_host = os.path.join(self.conf.target, self.data[""host""]) rel_tgt_host = os.path.relpath(fullfilename, tgt_host) # /remote_dir/remote_file match_orig_path = os.path.join(""/"", rel_tgt_host) if not fnmatch.fnmatch(match_orig_path, self.data[""path""]): continue tempfilename = ""STDOUT"" execute_calls.append(call(""mktemp"")) sed_calls.append(call(fullfilename, tempfilename)) execute_calls.append( call(""mv %s %s"" % (tempfilename, fullfilename))) assert msed.mock_calls == sed_calls assert mexecute.mock_calls == execute_calls ",0,905
openstack%2Frally~master~Ie3ed560e68dd4f38e8b3b371423840c451cb3909,openstack/rally,master,Ie3ed560e68dd4f38e8b3b371423840c451cb3909,Implement smart scenario args,ABANDONED,2014-02-27 12:59:20.000000000,2014-03-07 06:03:34.000000000,,"[{'_account_id': 3}, {'_account_id': 7217}, {'_account_id': 7369}, {'_account_id': 8507}]","[{'number': 1, 'created': '2014-02-27 12:59:20.000000000', 'files': ['doc/samples/tasks/nova/boot-server-with-reg.json', 'rally/benchmark/runner.py'], 'web_link': 'https://opendev.org/openstack/rally/commit/345a53de82ce4f907a6c8701a2ef1fdff4cfe888', 'message': 'Implement smart scenario args\n\nAdded function image_id_by_reg\n\nWIP\n\nblueprint smart-scenario-args\n\nChange-Id: Ie3ed560e68dd4f38e8b3b371423840c451cb3909\n'}]",11,76855,345a53de82ce4f907a6c8701a2ef1fdff4cfe888,11,4,1,7369,,,0,"Implement smart scenario args

Added function image_id_by_reg

WIP

blueprint smart-scenario-args

Change-Id: Ie3ed560e68dd4f38e8b3b371423840c451cb3909
",git fetch https://review.opendev.org/openstack/rally refs/changes/55/76855/1 && git format-patch -1 --stdout FETCH_HEAD,"['doc/samples/tasks/nova/boot-server-with-reg.json', 'rally/benchmark/runner.py']",2,345a53de82ce4f907a6c8701a2ef1fdff4cfe888,bp/smart-scenario-args," # NOTE(sskripnick): where this should be? def image_id_by_reg(self, reg): import re reg = re.compile(reg, re.IGNORECASE) # NOTE(sskripnick): should be better way to get client client = utils.create_openstack_clients(self.temp_users[0])[""glance""] for image in client.images.list(): if reg.match(image.name): return image.id raise Exception('Image not found') for key, val in args.iteritems(): if isinstance(val, dict) and ""$func"" in val: func = getattr(self, val[""$func""]) func_args = val.get(""$args"", []) func_kwargs = val.get(""$kwargs"", {}) args[key] = func(*func_args, **func_kwargs) ",,31,0
openstack%2Foslo.config~master~I195a814f49be5fc64fd495b9d12b9fbb52b99d9d,openstack/oslo.config,master,I195a814f49be5fc64fd495b9d12b9fbb52b99d9d,Service Validation: Runtime service validation.,ABANDONED,2014-02-04 21:01:49.000000000,2014-03-07 06:03:34.000000000,,"[{'_account_id': 3}, {'_account_id': 2472}, {'_account_id': 6677}, {'_account_id': 7400}, {'_account_id': 7629}, {'_account_id': 8119}]","[{'number': 1, 'created': '2014-02-04 21:01:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.config/commit/ac4e970a11d9e38a799bbc7775fef8879783eda2', 'message': ""Service Validation: Runtime service validation.\n\nThis feature request allows a service to register validators\nto be executed on the service's configuration before the service\nlaunches. It will allow any tier inside the service from driver\nto conductor to register an object implementing the validator\nAPI which the service may then use to run validation tests.\n\nChange-Id: I195a814f49be5fc64fd495b9d12b9fbb52b99d9d\nblueprint: service-validation\n""}, {'number': 2, 'created': '2014-02-08 00:05:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.config/commit/8c5f3679e5fef61da4aa0de8f3066cc7d22fd7ff', 'message': ""Service Validation: Runtime service validation.\n\nThis feature request allows a service to register validators\nto be executed on the service's configuration before the service\nlaunches. It will allow any tier inside the service from driver\nto conductor to register an object implementing the validator\nAPI which the service may then use to run validation tests.\n\nChange-Id: I195a814f49be5fc64fd495b9d12b9fbb52b99d9d\nblueprint: service-validation\n""}, {'number': 3, 'created': '2014-02-10 21:45:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.config/commit/307845bf1bf2f46d791a1cc879ea95f6dca492b9', 'message': ""Service Validation: Runtime service validation.\n\nThis feature request allows a service to register validators\nto be executed on the service's configuration before the service\nlaunches. It will allow any tier inside the service from driver\nto conductor to register an object implementing the validator\nAPI which the service may then use to run validation tests.\n\nChange-Id: I195a814f49be5fc64fd495b9d12b9fbb52b99d9d\nblueprint: service-validation\n""}, {'number': 5, 'created': '2014-02-10 21:50:01.000000000', 'files': ['oslo/config/validator.py', 'tests/test_validator.py'], 'web_link': 'https://opendev.org/openstack/oslo.config/commit/464e7c85814ec6c9c08b45a60802dc679b2dda4e', 'message': ""Service Validation: Runtime service validation.\n\nThis feature request allows a service to register validators\nto be executed on the service's configuration before the service\nlaunches. It will allow any tier inside the service from driver\nto conductor to register an object implementing the validator\nAPI which the service may then use to run validation tests.\n\nChange-Id: I195a814f49be5fc64fd495b9d12b9fbb52b99d9d\nblueprint: service-validation\n""}, {'number': 4, 'created': '2014-02-10 21:50:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.config/commit/12c84903db58b3f3e368fe0b330e3d2b0565c2af', 'message': ""Service Validation: Runtime service validation.\n\nThis feature request allows a service to register validators\nto be executed on the service's configuration before the service\nlaunches. It will allow any tier inside the service from driver\nto conductor to register an object implementing the validator\nAPI which the service may then use to run validation tests.\n\nChange-Id: I195a814f49be5fc64fd495b9d12b9fbb52b99d9d\nblueprint: service-validation\n""}]",28,71100,464e7c85814ec6c9c08b45a60802dc679b2dda4e,26,6,5,7629,,,0,"Service Validation: Runtime service validation.

This feature request allows a service to register validators
to be executed on the service's configuration before the service
launches. It will allow any tier inside the service from driver
to conductor to register an object implementing the validator
API which the service may then use to run validation tests.

Change-Id: I195a814f49be5fc64fd495b9d12b9fbb52b99d9d
blueprint: service-validation
",git fetch https://review.opendev.org/openstack/oslo.config refs/changes/00/71100/3 && git format-patch -1 --stdout FETCH_HEAD,['oslo/config/validator.py'],1,ac4e970a11d9e38a799bbc7775fef8879783eda2,bp/service-validation,"# Copyright 2014 VMware # # Licensed under the Apache License, Version 2.0 (the ""License""); you may # not use this file except in compliance with the License. You may obtain # a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT # WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the # License for the specific language governing permissions and limitations # under the License. """"""Service Validator script for Nova Compute."""""" from oslo.config import cfg class ServiceValidationError(Exception): """"""Base class for Service Validation exceptions."""""" def __init__(self, msg=None): self.msg = msg def __str__(self): return self.msg class NotValidValidator(ServiceValidationError): def __init__(self, validator=None): self.msg = (""validator is of class '%s'"" "" not of class validator.Validator"" % validator.__class__.__name__ ) class ValidationFault(ServiceValidationError): def __init__(self, options, group): self.msg = (""validator failure on options: %s for group %s"" % (options, group)) class Validator(object): def __init__(self, options, group=None, method_handle=None): """"""A base Validator object. A Validator is registered for a list of options in a group you may supply your own method to validate the options. More complex validator objects may be registered by extending this base object. :param options: an iterable set of options this validator operates on :param group: an optional group to look for options inside :param method_handle: an optional method handle :return: a Validator object for use by a ServiceValidator """""" self._options = options self._group = group self._method = method_handle @property def options(self): return self._options @property def group(self): return self._group def validate(self, config): """"""Use the registered method to validate the configuration. If no method_handle was registered with this Validator then this call will raise the NotValidValidator Exception. :param config: an oslo config object to validate :return: boolean True or False for valid or invalid """""" if self._method: return self._method(config) else: raise NotValidValidator(self) class ServiceValidator(object): """""" """""" def __init__(self): self.validators = [] def register(self, validator): if isinstance(Validator, validator): self.validators.append(validator) else: raise NotValidValidator(validator) def validate(self, config): for validator in self.validators: if not validator.validate(config): raise ValidationFault(validator.options, validator.group) VALIDATORS = ServiceValidator() def register(validator): VALIDATORS.register(validator) def register_method(options, group, method_handle): validator = Validator(options, group, method_handle) register(validator) def validate(): VALIDATORS.validate(cfg.CONF) ",,116,0
openstack%2Fnova~master~I709ab04b84dc85c680dbe57ce2de27c9734f24d1,openstack/nova,master,I709ab04b84dc85c680dbe57ce2de27c9734f24d1,"Use ""Expect: 100-continue"" handshake during upload",ABANDONED,2014-01-09 11:05:50.000000000,2014-03-07 06:03:29.000000000,,"[{'_account_id': 3}, {'_account_id': 1561}, {'_account_id': 2271}, {'_account_id': 6735}, {'_account_id': 7531}, {'_account_id': 9578}]","[{'number': 1, 'created': '2014-01-09 11:05:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/8a73e9c52f92452ff88e20e90b0ceb191d05423d', 'message': 'Use ""Expect: 100-continue"" handshake during upload\n\nDuring upload, if the Auth token is expired, the xenapi Glance\nplugin unnecessarily uploads the chunks and fails at the end.\nInstead, we could have a fail fast mechanism using the\n100-continue handshake. Only if the client receives a 100 continue\nfrom swift, it should continue uploading the chunks.\nOtherwise, if a 401 is received, it should fetch a fresh auth\ntoken and retry the request.\n\nImplements bp: should-use-100-continue-header\nChange-Id: I709ab04b84dc85c680dbe57ce2de27c9734f24d1\n'}, {'number': 2, 'created': '2014-01-13 11:27:08.000000000', 'files': ['plugins/xenserver/xenapi/etc/xapi.d/plugins/glance'], 'web_link': 'https://opendev.org/openstack/nova/commit/1f4e8d1ca1b361b7c598c6b232d272c6eb4fbfb7', 'message': 'Use ""Expect: 100-continue"" handshake during upload\n\nDuring upload, if the Auth token is expired, the xenapi Glance\nplugin unnecessarily uploads the chunks and fails at the end.\nInstead, we could have a fail fast mechanism using the\n100-continue handshake. Only if the client receives a 100 continue\nfrom swift, it should continue uploading the chunks.\nOtherwise, if a 401 is received, it should fetch a fresh auth\ntoken and retry the request.\n\nImplements bp: should-use-100-continue-header\nChange-Id: I709ab04b84dc85c680dbe57ce2de27c9734f24d1\n'}]",0,65663,1f4e8d1ca1b361b7c598c6b232d272c6eb4fbfb7,22,6,2,7531,,,0,"Use ""Expect: 100-continue"" handshake during upload

During upload, if the Auth token is expired, the xenapi Glance
plugin unnecessarily uploads the chunks and fails at the end.
Instead, we could have a fail fast mechanism using the
100-continue handshake. Only if the client receives a 100 continue
from swift, it should continue uploading the chunks.
Otherwise, if a 401 is received, it should fetch a fresh auth
token and retry the request.

Implements bp: should-use-100-continue-header
Change-Id: I709ab04b84dc85c680dbe57ce2de27c9734f24d1
",git fetch https://review.opendev.org/openstack/nova refs/changes/63/65663/1 && git format-patch -1 --stdout FETCH_HEAD,['plugins/xenserver/xenapi/etc/xapi.d/plugins/glance'],1,8a73e9c52f92452ff88e20e90b0ceb191d05423d,bp/should-use-100-continue-header,"from nova.openstack.common import bufferedhttpdef is_success(status): """""" Check if HTTP status code is successful. :param status: http status code :returns: True if status is successful, else False """""" return 200 <= status <= 299 def _connect_get_intermediate_resp(conn, image_id, glance_host, glance_port): resp = conn.getexpect() if resp.status == 100: conn.resp = None return conn elif is_success(resp.status): conn.resp = resp return conn else: raise PluginError(""Got Error response [%i] while uploading "" ""image [%s] "" ""to glance host [%s:%s]"" % (resp.status, image_id, glance_host, glance_port)) conn = bufferedhttp.HTTPSConnection(glance_host, glance_port) else: conn = bufferedhttp.HTTPConnection(glance_host, glance_port) 'x-glance-registry-purge-props': 'False', 'Expect': '100-continue'} _connect_get_intermediate_resp(conn, image_id, glance_host, glance_port) "," conn = httplib.HTTPSConnection(glance_host, glance_port) else: conn = httplib.HTTPConnection(glance_host, glance_port) 'x-glance-registry-purge-props': 'False'}",34,4
openstack%2Fnova~master~I92d5626e368638b8fb30258c82e06fdd5fd51eff,openstack/nova,master,I92d5626e368638b8fb30258c82e06fdd5fd51eff,VMware: add instance swap disk support,ABANDONED,2014-01-29 11:49:00.000000000,2014-03-07 06:03:27.000000000,,"[{'_account_id': 3}, {'_account_id': 1653}, {'_account_id': 9008}, {'_account_id': 9046}, {'_account_id': 9578}]","[{'number': 2, 'created': '2014-01-29 11:49:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/356644ea1edba6a325cfb7879af54412f903e258', 'message': 'VMware: add instance swap disk support\n\nVC driver ignores the swap disk specification in\nthe flavor. This patch adds support for swap disk\ncreation.\n\nChange-Id: I92d5626e368638b8fb30258c82e06fdd5fd51eff\nCloses-Bug: 1257683\n'}, {'number': 1, 'created': '2014-01-29 11:49:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/216b04264332a14417106adf2506e6c35c1fcba3', 'message': 'VMware: add instance swap disk support\n\nVC driver ignores the swap disk specification in\nthe flavor. This patch adds support for swap disk\ncreation.\n\nChange-Id: I92d5626e368638b8fb30258c82e06fdd5fd51eff\nCloses-Bug: 1257683\n'}, {'number': 3, 'created': '2014-02-17 04:26:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/6189804bbd8c09906988e483868ca711863970a8', 'message': 'VMware: add instance swap disk support\n\nVC driver ignores the swap disk specification in\nthe flavor. This patch adds support for swap disk\ncreation.\n\nChange-Id: I92d5626e368638b8fb30258c82e06fdd5fd51eff\nCloses-Bug: 1257683\n'}, {'number': 4, 'created': '2014-02-17 04:57:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/de3851e7577cd9d27cbc8a7c57450c095a929296', 'message': 'VMware: add instance swap disk support\n\nVC driver ignores the swap disk specification in\nthe flavor. This patch adds support for swap disk\ncreation.\n\nChange-Id: I92d5626e368638b8fb30258c82e06fdd5fd51eff\nCloses-Bug: 1257683\n'}, {'number': 5, 'created': '2014-02-18 22:56:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/d7f81bc31e45943e735f0230c14294641ad22dad', 'message': 'VMware: add instance swap disk support\n\nVC driver ignores the swap disk specification in\nthe flavor. This patch adds support for swap disk\ncreation.\n\nChange-Id: I92d5626e368638b8fb30258c82e06fdd5fd51eff\nCloses-Bug: 1257683\n'}, {'number': 6, 'created': '2014-02-18 23:10:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/dc23cbb5cfffd435e640dbbbf361971739b9817a', 'message': 'VMware: add instance swap disk support\n\nVC driver ignores the swap disk specification in\nthe flavor. This patch adds support for swap disk\ncreation.\n\nChange-Id: I92d5626e368638b8fb30258c82e06fdd5fd51eff\nCloses-Bug: 1257683\n'}, {'number': 7, 'created': '2014-02-18 23:15:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/d030c9d57119654a00e21b1f7d784420ce69a5dc', 'message': 'VMware: add instance swap disk support\n\nVC driver ignores the swap disk specification in\nthe flavor. This patch adds support for swap disk\ncreation.\n\nChange-Id: I92d5626e368638b8fb30258c82e06fdd5fd51eff\nCloses-Bug: 1257683\n'}, {'number': 8, 'created': '2014-02-18 23:27:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/64657ee9dadfcce77ebbaab38a84ec4fecac88a4', 'message': 'VMware: add instance swap disk support\n\nVC driver ignores the swap disk specification in\nthe flavor. This patch adds support for swap disk\ncreation.\n\nChange-Id: I92d5626e368638b8fb30258c82e06fdd5fd51eff\nCloses-Bug: 1257683\n'}, {'number': 9, 'created': '2014-02-19 00:28:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/4ce614a671041a55c490e5680dd13c20a8077b28', 'message': 'VMware: add instance swap disk support\n\nVC driver ignores the swap disk specification in\nthe flavor. This patch adds support for swap disk\ncreation.\n\nChange-Id: I92d5626e368638b8fb30258c82e06fdd5fd51eff\nCloses-Bug: 1257683\n'}, {'number': 10, 'created': '2014-02-21 07:57:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/f6f0e015bb01c4a7b27ddb4e02e29b8613cbaa25', 'message': 'VMware: add instance swap disk support\n\nVC driver ignores the swap disk specification in\nthe flavor. This patch adds support for swap disk\ncreation.\n\nChange-Id: I92d5626e368638b8fb30258c82e06fdd5fd51eff\nCloses-Bug: 1257683\n'}, {'number': 11, 'created': '2014-02-21 08:04:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/604bbcea28c17f917e86f0077b996b34aaffe90c', 'message': 'VMware: add instance swap disk support\n\nVC driver ignores the swap disk specification in\nthe flavor. This patch adds support for swap disk\ncreation.\n\nChange-Id: I92d5626e368638b8fb30258c82e06fdd5fd51eff\nCloses-Bug: 1257683\n'}, {'number': 12, 'created': '2014-02-24 05:25:44.000000000', 'files': ['nova/virt/vmwareapi/vmops.py', 'nova/tests/virt/vmwareapi/test_configdrive.py', 'nova/tests/virt/vmwareapi/test_driver_api.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/7453fa8e242fb80914261ef6ea0c47d923628680', 'message': 'VMware: add instance swap disk support\n\nVC driver ignores the swap disk specification in\nthe flavor. This patch adds support for swap disk\ncreation.\n\nChange-Id: I92d5626e368638b8fb30258c82e06fdd5fd51eff\nCloses-Bug: 1257683\n'}]",6,69843,7453fa8e242fb80914261ef6ea0c47d923628680,68,5,12,9046,,,0,"VMware: add instance swap disk support

VC driver ignores the swap disk specification in
the flavor. This patch adds support for swap disk
creation.

Change-Id: I92d5626e368638b8fb30258c82e06fdd5fd51eff
Closes-Bug: 1257683
",git fetch https://review.opendev.org/openstack/nova refs/changes/43/69843/3 && git format-patch -1 --stdout FETCH_HEAD,"['nova/virt/vmwareapi/vmops.py', 'nova/tests/virt/vmwareapi/test_driver_api.py']",2,356644ea1edba6a325cfb7879af54412f903e258,bug/1257683,"from nova.compute import flavors with mock.patch.object(flavors, 'extract_flavor', return_value={'swap': 0}): self.conn.spawn(self.context, self.instance, self.image, injected_files=[], admin_password=None, network_info=self.network_info, block_device_info=None) with mock.patch.object(flavors, 'extract_flavor', return_value={'swap': 0}): def fake_attach_disk_to_vm(vm_ref, instance, adapter_type, disk_type, vmdk_path=None, disk_size=None, linked_clone=False, controller_key=None, unit_number=None, device_name=None): info = self.conn.get_info(instance) self._check_vm_info(info, power_state.SHUTDOWN) if config_drive: def fake_create_config_drive(instance, injected_files, password, data_store_name, folder, instance_uuid, cookies): self.assertTrue(uuidutils.is_uuid_like(instance['uuid'])) self.stubs.Set(self.conn._vmops, '_create_config_drive', fake_create_config_drive) self._create_vm() info = self.conn.get_info({'name': 1, 'uuid': self.uuid, 'node': self.instance_node}) self.stubs.Set(self.conn._volumeops, ""attach_disk_to_vm"", fake_attach_disk_to_vm) self.conn.rescue(self.context, self.instance, self.network_info, self.image, 'fake-password') info = self.conn.get_info({'name': '1-rescue', 'uuid': '%s-rescue' % self.uuid, 'node': self.instance_node}) self._check_vm_info(info, power_state.RUNNING) info = self.conn.get_info({'name': 1, 'uuid': self.uuid, 'node': self.instance_node})"," self.conn.spawn(self.context, self.instance, self.image, injected_files=[], admin_password=None, network_info=self.network_info, block_device_info=None) def fake_attach_disk_to_vm(vm_ref, instance, adapter_type, disk_type, vmdk_path=None, disk_size=None, linked_clone=False, controller_key=None, unit_number=None, device_name=None): info = self.conn.get_info(instance) if config_drive: def fake_create_config_drive(instance, injected_files, password, data_store_name, folder, instance_uuid, cookies): self.assertTrue(uuidutils.is_uuid_like(instance['uuid'])) self.stubs.Set(self.conn._vmops, '_create_config_drive', fake_create_config_drive) self._create_vm() info = self.conn.get_info({'name': 1, 'uuid': self.uuid, 'node': self.instance_node}) self.stubs.Set(self.conn._volumeops, ""attach_disk_to_vm"", fake_attach_disk_to_vm) self.conn.rescue(self.context, self.instance, self.network_info, self.image, 'fake-password') info = self.conn.get_info({'name': '1-rescue', 'uuid': '%s-rescue' % self.uuid, 'node': self.instance_node}) self._check_vm_info(info, power_state.RUNNING) info = self.conn.get_info({'name': 1, 'uuid': self.uuid, 'node': self.instance_node}) self._check_vm_info(info, power_state.SHUTDOWN) ",92,34
openstack%2Fsahara~master~Iebe5bc344f4c7132b973f2e45d8bcdc136aa2439,openstack/sahara,master,Iebe5bc344f4c7132b973f2e45d8bcdc136aa2439,Support Qpid as messaging backend,ABANDONED,2014-02-24 14:52:02.000000000,2014-03-07 06:03:24.000000000,,"[{'_account_id': 3}, {'_account_id': 7109}, {'_account_id': 7125}, {'_account_id': 7213}, {'_account_id': 7700}, {'_account_id': 8304}, {'_account_id': 8411}]","[{'number': 1, 'created': '2014-02-24 14:52:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sahara/commit/6d58caae42ec3df04a0f6ceba09c9918eaf48d9a', 'message': ""Support Qpid as messaging backend\n\n * Made backend pluggable\n * Qpid is supported\n * Messaging configuration is copied from Savanna config to the agent's one\n * Messaging lib (kombu, qpid-python) is installed by Savanna\n * Added agent logging level to config\n\nChange-Id: Iebe5bc344f4c7132b973f2e45d8bcdc136aa2439\n""}, {'number': 2, 'created': '2014-02-26 12:45:22.000000000', 'files': ['etc/savanna/savanna.conf.sample', 'savanna/resources/userdata.template', 'savanna/utils/agent_remote.py', 'savanna/utils/remote.py'], 'web_link': 'https://opendev.org/openstack/sahara/commit/b2ddb981f026f1cd48e6596300f1dededd0cae32', 'message': ""Support Qpid as messaging backend\n\n * Made backend pluggable\n * Qpid is supported\n * Messaging configuration is copied from Savanna config to the agent's one\n * Added agent logging level to config\n\nChange-Id: Iebe5bc344f4c7132b973f2e45d8bcdc136aa2439\n""}]",1,75889,b2ddb981f026f1cd48e6596300f1dededd0cae32,17,7,2,7109,,,0,"Support Qpid as messaging backend

 * Made backend pluggable
 * Qpid is supported
 * Messaging configuration is copied from Savanna config to the agent's one
 * Added agent logging level to config

Change-Id: Iebe5bc344f4c7132b973f2e45d8bcdc136aa2439
",git fetch https://review.opendev.org/openstack/sahara refs/changes/89/75889/2 && git format-patch -1 --stdout FETCH_HEAD,"['etc/savanna/savanna.conf.sample', 'savanna/resources/userdata.template', 'savanna/utils/agent_remote.py', 'savanna/utils/remote.py']",4,6d58caae42ec3df04a0f6ceba09c9918eaf48d9a,agent-backends," cfg.StrOpt('agent_log_level', default='warn', help='Log level for agent logs. Valid options are ""warn"", ' '""info"" and ""debug"". Beware that agent logs are not ' 'rotated, so use level lower than ""warn"" for debugging ' 'only.')",,122,13
openstack%2Ftrove~master~I2ff183c2163a3485573cabee1e9029e6820497a6,openstack/trove,master,I2ff183c2163a3485573cabee1e9029e6820497a6,Adds support for Datastore Version Specific Template,ABANDONED,2014-02-19 21:17:58.000000000,2014-03-07 06:03:24.000000000,,"[{'_account_id': 3}, {'_account_id': 1175}, {'_account_id': 5293}, {'_account_id': 7092}, {'_account_id': 7806}, {'_account_id': 8214}, {'_account_id': 8415}]","[{'number': 1, 'created': '2014-02-19 21:17:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/trove/commit/4d7ce7f989a31aaaea6deae8ebc0eb0c5574a897', 'message': 'Datastore Version Specific Template\n\nChange-Id: I2ff183c2163a3485573cabee1e9029e6820497a6\n'}, {'number': 2, 'created': '2014-02-19 22:51:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/trove/commit/8db7258ef9f6ed9dd477c0f74dced6d3847694d1', 'message': 'Adds support for Datastore Version Specific Template\n\nReasons:\n- To support different config parameter list in different datastore\n  versions, we need different config templates.\n- To support a change in database install & configure method with\n  different versions through heat provisioning we need different\n  heat templates for different versions.\n\nChanges:\n- Adds datastore_version_name to template rendering to support the\n  different config templates available as\n  config.template.datastore_version_name\n- Adds datastore_version_name to heat template rendering  to support the\n  different heat templates available as\n  heat.template.datastore_version_name\n- The workflow followed is, if version specific template exists then use\n  it, else use the default ""datastore template"".\n\nChange-Id: I2ff183c2163a3485573cabee1e9029e6820497a6\nImplements: blueprint datastore-version-specific-template\n'}, {'number': 3, 'created': '2014-02-20 23:46:48.000000000', 'files': ['trove/taskmanager/api.py', 'trove/instance/models.py', 'trove/taskmanager/manager.py', 'trove/taskmanager/models.py', 'trove/common/template.py'], 'web_link': 'https://opendev.org/openstack/trove/commit/3726f44bde8b9af3ca0d718ce88190b37c9bc7e9', 'message': 'Adds support for Datastore Version Specific Template\n\nReasons:\n- To support different config parameter list in different datastore\n  versions, we need different config templates.\n- To support a change in database install & configure method with\n  different versions through heat provisioning we need different\n  heat templates for different versions.\n\nChanges:\n- Adds datastore_version_name to template rendering to support the\n  different config templates available as\n  config.template.datastore_version_name\n- Adds datastore_version_name to heat template rendering  to support the\n  different heat templates available as\n  heat.template.datastore_version_name\n- The workflow followed is, if version specific template exists then use\n  it, else use the default ""datastore template"".\n\nChange-Id: I2ff183c2163a3485573cabee1e9029e6820497a6\nImplements: blueprint config-template-per-package-or-datastore-version\n'}]",0,74843,3726f44bde8b9af3ca0d718ce88190b37c9bc7e9,24,7,3,7806,,,0,"Adds support for Datastore Version Specific Template

Reasons:
- To support different config parameter list in different datastore
  versions, we need different config templates.
- To support a change in database install & configure method with
  different versions through heat provisioning we need different
  heat templates for different versions.

Changes:
- Adds datastore_version_name to template rendering to support the
  different config templates available as
  config.template.datastore_version_name
- Adds datastore_version_name to heat template rendering  to support the
  different heat templates available as
  heat.template.datastore_version_name
- The workflow followed is, if version specific template exists then use
  it, else use the default ""datastore template"".

Change-Id: I2ff183c2163a3485573cabee1e9029e6820497a6
Implements: blueprint config-template-per-package-or-datastore-version
",git fetch https://review.opendev.org/openstack/trove refs/changes/43/74843/1 && git format-patch -1 --stdout FETCH_HEAD,"['trove/taskmanager/api.py', 'trove/instance/models.py', 'trove/taskmanager/manager.py', 'trove/taskmanager/models.py', 'trove/common/template.py']",5,4d7ce7f989a31aaaea6deae8ebc0eb0c5574a897,bp/config-template-per-package-or-datastore-version," def __init__(self, datastore_manager, flavor_dict, instance_id, datastore_version_name=None): :param datastore_version_name: trove datastore version name :type: datastore_version_name: str try: # If there exists a datastore version specific template, use it # else switch to default datastore template filename = ""%s/config.template.%s"" % (datastore_manager, datastore_version_name) self.template = ENV.get_template(filename) except jinja2.TemplateError: self.template = ENV.get_template(template_filename) self.config_contents = self.template.render(def load_heat_template(datastore_manager, datastore_version_name=None): try: # If there exists a datastore version specific template, use it # else switch to default datastore template filename = ""%s/config.template.%s"" % (datastore_manager, datastore_version_name) template_obj = ENV.get_template(filename) except jinja2.TemplateError: try: filename = ""%s/heat.template"" % datastore_manager template_obj = ENV.get_template(filename) except jinja2.TemplateNotFound: msg = ""Missing heat template for %s"" % datastore_manager LOG.error(msg) raise exception.TroveError(msg)"," def __init__(self, datastore_manager, flavor_dict, instance_id): self.template = ENV.get_template(template_filename) template = ENV.get_template(self.template_name % self.datastore_manager) self.config_contents = template.render(def load_heat_template(datastore_manager): template_filename = ""%s/heat.template"" % datastore_manager try: template_obj = ENV.get_template(template_filename) except jinja2.TemplateNotFound: msg = ""Missing heat template for %s"" % datastore_manager LOG.error(msg) raise exception.TroveError(msg)",60,34
openstack%2Fcookbook-openstack-common~master~I4f599a4bd2f73108eb6551d935579a9bf7c99bf6,openstack/cookbook-openstack-common,master,I4f599a4bd2f73108eb6551d935579a9bf7c99bf6,add 'notification_topic' attribute for metering,ABANDONED,2014-02-26 00:41:45.000000000,2014-03-07 06:03:23.000000000,,"[{'_account_id': 3}, {'_account_id': 216}, {'_account_id': 1032}, {'_account_id': 2340}, {'_account_id': 9884}, {'_account_id': 9894}]","[{'number': 1, 'created': '2014-02-26 00:41:45.000000000', 'files': ['attributes/messaging.rb'], 'web_link': 'https://opendev.org/openstack/cookbook-openstack-common/commit/78f7c3b0504daabf1e7fbb290e100de654008b93', 'message': ""add 'notification_topic' attribute for metering\n\nChange-Id: I4f599a4bd2f73108eb6551d935579a9bf7c99bf6\n""}]",4,76401,78f7c3b0504daabf1e7fbb290e100de654008b93,11,6,1,9894,,,0,"add 'notification_topic' attribute for metering

Change-Id: I4f599a4bd2f73108eb6551d935579a9bf7c99bf6
",git fetch https://review.opendev.org/openstack/cookbook-openstack-common refs/changes/01/76401/1 && git format-patch -1 --stdout FETCH_HEAD,['attributes/messaging.rb'],1,78f7c3b0504daabf1e7fbb290e100de654008b93,notification_topic_attr," # metering glance_topics = node['openstack']['mq']['image']['notification_topic'] default['openstack']['mq']['metering']['notification_topic'] = ""notifications,#{glance_topics}""",,4,0
openstack%2Fdevstack~master~I2e81eaaa4b81b2eca5134ed8a7030255a4d7c6b9,openstack/devstack,master,I2e81eaaa4b81b2eca5134ed8a7030255a4d7c6b9,Fix quoting of username in polkit auth file,ABANDONED,2014-02-27 16:01:05.000000000,2014-03-07 06:03:22.000000000,,"[{'_account_id': 3}, {'_account_id': 970}]","[{'number': 1, 'created': '2014-02-27 16:01:05.000000000', 'files': ['lib/nova_plugins/hypervisor-libvirt'], 'web_link': 'https://opendev.org/openstack/devstack/commit/6b0eb391e0f78e4398714476c2508458db39d000', 'message': 'Fix quoting of username in polkit auth file\n\nThe username in the polkit auth file only needs to be single\nquoted, not double quoted inside single quotes. The latter\ncauses polkit to fail authorization on Fedora 20 hosts at\nleast.\n\nChange-Id: I2e81eaaa4b81b2eca5134ed8a7030255a4d7c6b9\nCloses-bug: #1285740\n'}]",0,76902,6b0eb391e0f78e4398714476c2508458db39d000,7,2,1,1779,,,0,"Fix quoting of username in polkit auth file

The username in the polkit auth file only needs to be single
quoted, not double quoted inside single quotes. The latter
causes polkit to fail authorization on Fedora 20 hosts at
least.

Change-Id: I2e81eaaa4b81b2eca5134ed8a7030255a4d7c6b9
Closes-bug: #1285740
",git fetch https://review.opendev.org/openstack/devstack refs/changes/02/76902/1 && git format-patch -1 --stdout FETCH_HEAD,['lib/nova_plugins/hypervisor-libvirt'],1,6b0eb391e0f78e4398714476c2508458db39d000,polkit-user, subject.user == '$STACK_USER') {," subject.user == '""$STACK_USER""') {",1,1
openstack%2Fhorizon~master~I893a1d98bc94fb66dcbedc8576e9b6344c8eee20,openstack/horizon,master,I893a1d98bc94fb66dcbedc8576e9b6344c8eee20,Adding a placeholder for object actions,ABANDONED,2014-02-27 15:12:58.000000000,2014-03-07 06:03:21.000000000,,"[{'_account_id': 3}, {'_account_id': 4264}, {'_account_id': 9576}]","[{'number': 1, 'created': '2014-02-27 15:12:58.000000000', 'files': ['horizon/templates/horizon/common/_page_header.html'], 'web_link': 'https://opendev.org/openstack/horizon/commit/ff0eaf11a03bad083d12673fcb11775ebaf42003', 'message': 'Adding a placeholder for object actions\n\nChange-Id: I893a1d98bc94fb66dcbedc8576e9b6344c8eee20\n'}]",0,76885,ff0eaf11a03bad083d12673fcb11775ebaf42003,6,3,1,9157,,,0,"Adding a placeholder for object actions

Change-Id: I893a1d98bc94fb66dcbedc8576e9b6344c8eee20
",git fetch https://review.opendev.org/openstack/horizon refs/changes/85/76885/1 && git format-patch -1 --stdout FETCH_HEAD,['horizon/templates/horizon/common/_page_header.html'],1,ff0eaf11a03bad083d12673fcb11775ebaf42003,, {% block object_actions %} {% endblock %} ,,5,0
openstack%2Fhorizon~master~I701f85d1bfb3ac59cce785c812eb2609641980c9,openstack/horizon,master,I701f85d1bfb3ac59cce785c812eb2609641980c9,fixed the color of instance details and border radius,ABANDONED,2014-02-26 22:47:08.000000000,2014-03-07 06:03:21.000000000,,"[{'_account_id': 3}, {'_account_id': 4264}, {'_account_id': 9576}, {'_account_id': 9622}, {'_account_id': 10112}]","[{'number': 1, 'created': '2014-02-26 22:47:08.000000000', 'files': ['openstack_dashboard/static/dashboard/less/horizon.less'], 'web_link': 'https://opendev.org/openstack/horizon/commit/e5b29a14a191aa1bbf8b331bc16f3fcddee3a2ca', 'message': 'fixed the color of instance details and border radius\n\nChange-Id: I701f85d1bfb3ac59cce785c812eb2609641980c9\n'}]",2,76682,e5b29a14a191aa1bbf8b331bc16f3fcddee3a2ca,7,5,1,9157,,,0,"fixed the color of instance details and border radius

Change-Id: I701f85d1bfb3ac59cce785c812eb2609641980c9
",git fetch https://review.opendev.org/openstack/horizon refs/changes/82/76682/1 && git format-patch -1 --stdout FETCH_HEAD,['openstack_dashboard/static/dashboard/less/horizon.less'],1,e5b29a14a191aa1bbf8b331bc16f3fcddee3a2ca,, margin-top: 5px; color: #4790AE; border-bottom-left-radius :.2em; border-bottom-right-radius :.2em; color: #4790AE; border-bottom-left-radius :.2em; border-bottom-right-radius :.2em; background-color: #4790AE; background-color: #4790AE;, margin-top: 10px; color: #0000FF; color: #0000FF; background-color: #0000FF; background-color: #0000FF;,9,5
openstack%2Fhorizon~master~I95eaec32c9a0338418a15567feba4d89b76d03a8,openstack/horizon,master,I95eaec32c9a0338418a15567feba4d89b76d03a8,Added script for toggable help button,ABANDONED,2014-02-27 18:55:27.000000000,2014-03-07 06:03:17.000000000,,"[{'_account_id': 3}, {'_account_id': 10493}]","[{'number': 1, 'created': '2014-02-27 18:55:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/e924162f2b92a3cc6e53008704df26b3f9539a22', 'message': ""Added script for toggable help button\n\n*** In order to make the description block show or hide on\n    the click action, there's a new function in InitFunction of\n    horizon that handle the events.\n\nChange-Id: I95eaec32c9a0338418a15567feba4d89b76d03a8\nImplements: blueprint horizon-modal-help\n""}, {'number': 2, 'created': '2014-02-27 21:31:57.000000000', 'files': ['horizon/static/horizon/js/horizon.modals.js'], 'web_link': 'https://opendev.org/openstack/horizon/commit/668cd9a1e692d134e316800213d627e444cb27f0', 'message': ""Added script for toggable help button\n\n*** In order to make the description block show or hide on\n    the click action, there's a new function in InitFunction of\n    horizon that handle the events.\n\nChange-Id: I95eaec32c9a0338418a15567feba4d89b76d03a8\nImplements: blueprint horizon-modal-help\n""}]",0,76938,668cd9a1e692d134e316800213d627e444cb27f0,5,2,2,10493,,,0,"Added script for toggable help button

*** In order to make the description block show or hide on
    the click action, there's a new function in InitFunction of
    horizon that handle the events.

Change-Id: I95eaec32c9a0338418a15567feba4d89b76d03a8
Implements: blueprint horizon-modal-help
",git fetch https://review.opendev.org/openstack/horizon refs/changes/38/76938/2 && git format-patch -1 --stdout FETCH_HEAD,['horizon/static/horizon/js/horizon.modals.js'],1,e924162f2b92a3cc6e53008704df26b3f9539a22,bp/horizon-modal-help," /* toggle the help text */ $(document).on('click', "".help"", function() { var helpButton = $(this); var descriptionElement = $('.description'); if (descriptionElement.hasClass(""hide"")) { helpButton.addClass(""selected""); descriptionElement.removeClass(""hide""); descriptionElement.addClass(""show""); } else { helpButton.removeClass(""selected""); descriptionElement.addClass(""hide""); descriptionElement.removeClass(""show""); } }); ",,17,0
openstack%2Fhorizon~master~If8bdd7032441f621dd3fafe97407453347315f7b,openstack/horizon,master,If8bdd7032441f621dd3fafe97407453347315f7b,Added a new tag for passing variable to extends,ABANDONED,2014-02-27 18:55:27.000000000,2014-03-07 06:03:16.000000000,,"[{'_account_id': 3}, {'_account_id': 10493}]","[{'number': 1, 'created': '2014-02-27 18:55:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/af439c5228e62a255866576bcf21344e83de838e', 'message': 'Added a new tag for passing variable to extends\n\n*** The new tag name is xextends.\n\n*** USE:   {% xextends ""base.html"" with key=value %}\n\n*** This tag is used for passing a variable which tell the modal\n    form to hide/show the help button (used for permanent help text)\n\nChange-Id: If8bdd7032441f621dd3fafe97407453347315f7b\nImplements: blueprint horizon-modal-help\n'}, {'number': 2, 'created': '2014-02-27 21:31:58.000000000', 'files': ['horizon/templatetags/horizon.py'], 'web_link': 'https://opendev.org/openstack/horizon/commit/e4394c121bf97f5ceabf840176a5bd47d3a00349', 'message': 'Added a new tag for passing variable to extends\n\n*** The new tag name is xextends.\n\n*** USE:   {% xextends ""base.html"" with key=value %}\n\n*** This tag is used for passing a variable which tell the modal\n    form to hide/show the help button (used for permanent help text)\n\nChange-Id: If8bdd7032441f621dd3fafe97407453347315f7b\nImplements: blueprint horizon-modal-help\n'}]",0,76939,e4394c121bf97f5ceabf840176a5bd47d3a00349,7,2,2,10493,,,0,"Added a new tag for passing variable to extends

*** The new tag name is xextends.

*** USE:   {% xextends ""base.html"" with key=value %}

*** This tag is used for passing a variable which tell the modal
    form to hide/show the help button (used for permanent help text)

Change-Id: If8bdd7032441f621dd3fafe97407453347315f7b
Implements: blueprint horizon-modal-help
",git fetch https://review.opendev.org/openstack/horizon refs/changes/39/76939/2 && git format-patch -1 --stdout FETCH_HEAD,['horizon/templatetags/horizon.py'],1,af439c5228e62a255866576bcf21344e83de838e,bp/horizon-modal-help,"from django.template.loader_tags import do_extends import tokenize import StringIO class XExtendsNode(template.Node): def __init__(self, node, kwargs): self.node = node self.kwargs = kwargs def render(self, context): # TODO: add the values to the bottom of the context stack instead? context.update(self.kwargs) try: return self.node.render(context) finally: context.pop() def do_xextends(parser, token): bits = token.contents.split() kwargs = {} if 'with' in bits: pos = bits.index('with') argslist = bits[pos+1:] bits = bits[:pos] for i in argslist: try: a, b = i.split('=', 1); a = a.strip(); b = b.strip() keys = list(tokenize.generate_tokens(StringIO.StringIO(a).readline)) if keys[0][0] == tokenize.NAME: kwargs[str(a)] = parser.compile_filter(b) else: raise ValueError except ValueError: raise template.TemplateSyntaxError, ""Argument syntax wrong: should be key=value"" # before we are done, remove the argument part from the token contents, # or django's extends tag won't be able to handle it. # TODO: find a better solution that preserves the orginal token including whitespace etc. token.contents = "" "".join(bits) # let the orginal do_extends parse the tag, and wrap the ExtendsNode return XExtendsNode(do_extends(parser, token), kwargs) register.tag('xextends', do_xextends)",,42,0
openstack%2Fneutron~master~Icd5907e7c1692668bcdf3884083e11be17554dec,openstack/neutron,master,Icd5907e7c1692668bcdf3884083e11be17554dec,LBaaS: add routed-service-insertion extension to the plugin,ABANDONED,2014-02-17 08:06:10.000000000,2014-03-07 06:03:15.000000000,,"[{'_account_id': 3}, {'_account_id': 841}, {'_account_id': 2592}, {'_account_id': 4149}, {'_account_id': 5948}, {'_account_id': 6072}, {'_account_id': 9200}, {'_account_id': 9732}, {'_account_id': 9787}, {'_account_id': 9845}, {'_account_id': 9925}, {'_account_id': 10116}, {'_account_id': 10117}, {'_account_id': 10119}, {'_account_id': 10153}, {'_account_id': 10184}, {'_account_id': 10192}, {'_account_id': 10294}]","[{'number': 1, 'created': '2014-02-17 08:06:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/c8e67f5e1d048b5571cea8605e99ede439511b7f', 'message': 'LBaaS: add routed-service-insertion extension to the plugin\n\nThis commit adds the routed-service-insertion extension to the loadbalancer\nplugin, which allows to set the router_id attribute to pools and vips.\nThis change is needed to implement bp lbaas-lvs-driver.\n\nChange-Id: Icd5907e7c1692668bcdf3884083e11be17554dec\nImplements: blueprint lbaas-support-routed-service-insertion.\n'}, {'number': 2, 'created': '2014-02-19 08:50:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/84814b371a47d01bb97f5e17f54281e17b2de8f1', 'message': 'LBaaS: add routed-service-insertion extension to the plugin\n\nThis commit adds the routed-service-insertion extension to the loadbalancer\nplugin, which allows to set the router_id attribute to pools and vips.\nThis change is needed to implement bp lbaas-lvs-driver.\n\nChange-Id: Icd5907e7c1692668bcdf3884083e11be17554dec\nImplements: blueprint lbaas-support-routed-service-insertion.\n'}, {'number': 3, 'created': '2014-02-20 08:46:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/a6a1781777723049dc50ce506513f2a84637cadc', 'message': 'LBaaS: add routed-service-insertion extension to the plugin\n\nThis commit adds the routed-service-insertion extension to the loadbalancer\nplugin, which allows to set the router_id attribute to pools and vips.\nThis change is needed to implement bp lbaas-lvs-driver.\n\nChange-Id: Icd5907e7c1692668bcdf3884083e11be17554dec\nImplements: blueprint lbaas-support-routed-service-insertion.\n'}, {'number': 4, 'created': '2014-02-21 08:53:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/8ae5c2f0c84eef3bf34846b172d97d42feff9d2a', 'message': 'LBaaS: add routed-service-insertion extension to the plugin\n\nThis commit adds the routed-service-insertion extension to the loadbalancer\nplugin, which allows to set the router_id attribute to pools and vips.\nThis change is needed to implement bp lbaas-lvs-driver.\n\nChange-Id: Icd5907e7c1692668bcdf3884083e11be17554dec\nImplements: blueprint lbaas-support-routed-service-insertion.\n'}, {'number': 5, 'created': '2014-02-24 06:12:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/3da9630711b093356b98d720b14c471a90645305', 'message': 'LBaaS: add routed-service-insertion extension to the plugin\n\nThis commit adds the routed-service-insertion extension to the loadbalancer\nplugin, which allows to set the router_id attribute to pools and vips.\nThis change is needed to implement bp lbaas-lvs-driver.\n\nChange-Id: Icd5907e7c1692668bcdf3884083e11be17554dec\nImplements: blueprint lbaas-support-routed-service-insertion.\n'}, {'number': 6, 'created': '2014-02-27 03:55:06.000000000', 'files': ['neutron/services/loadbalancer/drivers/common/agent_driver_base.py', 'neutron/services/loadbalancer/drivers/netscaler/netscaler_driver.py', 'neutron/services/loadbalancer/drivers/abstract_driver.py', 'neutron/services/loadbalancer/drivers/radware/driver.py', 'neutron/services/loadbalancer/plugin.py', 'neutron/tests/unit/db/loadbalancer/test_db_loadbalancer.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/b831e805654dd387a510b0cd9ef751de1583626d', 'message': 'LBaaS: add routed-service-insertion extension to the plugin\n\nThis commit adds the routed-service-insertion extension to the loadbalancer\nplugin, which allows to set the router_id attribute to pools and vips.\nThis change is needed to implement bp lbaas-lvs-driver.\n\nChange-Id: Icd5907e7c1692668bcdf3884083e11be17554dec\nImplements: blueprint lbaas-support-routed-service-insertion\n'}]",28,73962,b831e805654dd387a510b0cd9ef751de1583626d,93,18,6,9200,,,0,"LBaaS: add routed-service-insertion extension to the plugin

This commit adds the routed-service-insertion extension to the loadbalancer
plugin, which allows to set the router_id attribute to pools and vips.
This change is needed to implement bp lbaas-lvs-driver.

Change-Id: Icd5907e7c1692668bcdf3884083e11be17554dec
Implements: blueprint lbaas-support-routed-service-insertion
",git fetch https://review.opendev.org/openstack/neutron refs/changes/62/73962/3 && git format-patch -1 --stdout FETCH_HEAD,"['neutron/services/loadbalancer/drivers/abstract_driver.py', 'neutron/services/loadbalancer/drivers/radware/driver.py', 'neutron/services/loadbalancer/drivers/haproxy/plugin_driver.py', 'neutron/services/loadbalancer/plugin.py', 'neutron/tests/unit/db/loadbalancer/test_db_loadbalancer.py']",5,c8e67f5e1d048b5571cea8605e99ede439511b7f,bp/lbaas-support-routed-service-insertion," def validate_router_id(self, context, router_id, pool=None, pool_id=None, vip=None): pass ",,39,1
openstack%2Fhorizon~master~I7d754eeee621c525094d9ec258480c702aead71e,openstack/horizon,master,I7d754eeee621c525094d9ec258480c702aead71e,Enhanced Layout of Headers,ABANDONED,2014-02-26 22:30:38.000000000,2014-03-07 06:03:13.000000000,,"[{'_account_id': 3}, {'_account_id': 9576}, {'_account_id': 9622}]","[{'number': 1, 'created': '2014-02-26 22:30:38.000000000', 'files': ['horizon/templates/horizon/common/_tab_group.html', 'openstack_dashboard/static/dashboard/less/horizon.less', 'horizon/templates/horizon/common/_page_header.html', 'openstack_dashboard/dashboards/project/instances/templates/instances/detail.html', 'openstack_dashboard/static/bootstrap/less/navs.less', 'horizon/templates/horizon/common/_domain_page_header.html', 'horizon/templates/base.html', 'horizon/templates/horizon/_nav_list.html'], 'web_link': 'https://opendev.org/openstack/horizon/commit/bf3eee44af09e5db1bcbe65c730dc311914c87b3', 'message': 'Enhanced Layout of Headers\n\nConflicts:\n\n\thorizon/templates/base.html\n\nChange-Id: I7d754eeee621c525094d9ec258480c702aead71e\n'}]",3,76676,bf3eee44af09e5db1bcbe65c730dc311914c87b3,9,3,1,9157,,,0,"Enhanced Layout of Headers

Conflicts:

	horizon/templates/base.html

Change-Id: I7d754eeee621c525094d9ec258480c702aead71e
",git fetch https://review.opendev.org/openstack/horizon refs/changes/76/76676/1 && git format-patch -1 --stdout FETCH_HEAD,"['horizon/templates/horizon/common/_tab_group.html', 'openstack_dashboard/static/dashboard/less/horizon.less', 'horizon/templates/horizon/common/_page_header.html', 'openstack_dashboard/dashboards/project/instances/templates/instances/detail.html', 'openstack_dashboard/static/bootstrap/less/navs.less', 'horizon/templates/horizon/common/_domain_page_header.html', 'horizon/templates/base.html', 'horizon/templates/horizon/_nav_list.html']",8,bf3eee44af09e5db1bcbe65c730dc311914c87b3,, {% for component in components %}, {% for component in components %},89,18
openstack%2Fnova~master~I302651d57a1afb90bede3ebb778cfc3024af1204,openstack/nova,master,I302651d57a1afb90bede3ebb778cfc3024af1204,Add Ironic volume driver,ABANDONED,2014-02-04 16:43:51.000000000,2014-03-07 06:03:13.000000000,,"[{'_account_id': 3}, {'_account_id': 1779}, {'_account_id': 2889}, {'_account_id': 5805}, {'_account_id': 6773}, {'_account_id': 8106}, {'_account_id': 9578}]","[{'number': 1, 'created': '2014-02-04 16:43:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/b97502e83bfeef546747ba05489812bf56fa11cb', 'message': 'Add Ironic volume driver\n\nEarly Draft.\n\nimplements bp:deprecate-baremetal-driver\n\nChange-Id: I302651d57a1afb90bede3ebb778cfc3024af1204\nCo-Author: Chris Krelle <nobodycam@gmail.com>\nCo-Author: Devananda van der Veen <devananda.vdv@gmail.com>\n'}, {'number': 2, 'created': '2014-02-04 17:30:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/9513482363c8e2913a9eed6b8a3dbbd75222dc5a', 'message': 'Add Ironic volume driver\n\nEarly Draft.\n\nimplements bp:deprecate-baremetal-driver\n\nCo-Author: Chris Krelle <nobodycam@gmail.com>\nCo-Author: Devananda van der Veen <devananda.vdv@gmail.com>\nChange-Id: I302651d57a1afb90bede3ebb778cfc3024af1204\n'}, {'number': 3, 'created': '2014-02-07 22:41:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/db2ea58cb50d6569079776be4d33759781372c88', 'message': 'Add Ironic volume driver\n\nEarly Draft.\n\nimplements bp:deprecate-baremetal-driver\n\nCo-Author: Chris Krelle <nobodycam@gmail.com>\nCo-Author: Devananda van der Veen <devananda.vdv@gmail.com>\nChange-Id: I302651d57a1afb90bede3ebb778cfc3024af1204\n'}, {'number': 4, 'created': '2014-02-14 23:48:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/64185f146a20779a8ebecf05e6e37b74f6657028', 'message': 'Add Ironic volume driver\n\nEarly Draft.\n\nimplements bp:deprecate-baremetal-driver\n\nCo-Author: Chris Krelle <nobodycam@gmail.com>\nCo-Author: Devananda van der Veen <devananda.vdv@gmail.com>\nChange-Id: I302651d57a1afb90bede3ebb778cfc3024af1204\n'}, {'number': 5, 'created': '2014-02-18 17:07:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/7eec60c86a3995c98760f10af8717725563bdba5', 'message': 'Add Ironic volume driver\n\nThis patch adds a volume driver for the ironic driver.\n\nimplements bp:deprecate-baremetal-driver\n\nCo-Author: Chris Krelle <nobodycam@gmail.com>\nCo-Author: Devananda van der Veen <devananda.vdv@gmail.com>\nChange-Id: I302651d57a1afb90bede3ebb778cfc3024af1204\n'}, {'number': 6, 'created': '2014-02-19 01:09:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/c3b0913a3affa9fb5e53fd82429e498c3afde3a6', 'message': 'Add Ironic volume driver\n\nThis patch adds a volume driver for the ironic driver.\n\nimplements bp:deprecate-baremetal-driver\n\nCo-Author: Chris Krelle <nobodycam@gmail.com>\nCo-Author: Devananda van der Veen <devananda.vdv@gmail.com>\nChange-Id: I302651d57a1afb90bede3ebb778cfc3024af1204\n'}, {'number': 7, 'created': '2014-02-19 21:14:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/7f0baacb96919b424004e0e6a6ea10e5377da421', 'message': 'Add Ironic volume driver\n\nThis patch adds a volume driver for the ironic driver.\n\nimplements bp:deprecate-baremetal-driver\n\nCo-Author: Chris Krelle <nobodycam@gmail.com>\nCo-Author: Devananda van der Veen <devananda.vdv@gmail.com>\nChange-Id: I302651d57a1afb90bede3ebb778cfc3024af1204\n'}, {'number': 8, 'created': '2014-02-19 21:54:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/577413471e5ad3f1d1cb3173e6cb3e82a4b310bd', 'message': 'Add Ironic volume driver\n\nThis patch adds a volume driver for the ironic driver.\n\nimplements bp:deprecate-baremetal-driver\n\nCo-Author: Chris Krelle <nobodycam@gmail.com>\nCo-Author: Devananda van der Veen <devananda.vdv@gmail.com>\nChange-Id: I302651d57a1afb90bede3ebb778cfc3024af1204\n'}, {'number': 9, 'created': '2014-02-19 22:47:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/71e62b7cd1a9ab1f43b099e9237a77c93eee1f15', 'message': 'Add Ironic volume driver\n\nThis patch adds a volume driver for the ironic driver.\n\nimplements bp:deprecate-baremetal-driver\n\nCo-Author: Chris Krelle <nobodycam@gmail.com>\nCo-Author: Devananda van der Veen <devananda.vdv@gmail.com>\nChange-Id: I302651d57a1afb90bede3ebb778cfc3024af1204\n'}, {'number': 10, 'created': '2014-02-21 21:10:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/fe723402b92b31e2298ccd4890ca255f03cc2cc4', 'message': 'Add Ironic volume driver\n\nThis patch adds a volume driver for the ironic driver.\n\nimplements bp:deprecate-baremetal-driver\n\nCo-Author: Chris Krelle <nobodycam@gmail.com>\nCo-Author: Devananda van der Veen <devananda.vdv@gmail.com>\nChange-Id: I302651d57a1afb90bede3ebb778cfc3024af1204\n'}, {'number': 11, 'created': '2014-02-22 01:24:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/118d43dd56f270069115ee9885b35e56be558105', 'message': 'Add Ironic volume driver\n\nThis patch adds a volume driver for the ironic driver.\n\nimplements bp:deprecate-baremetal-driver\n\nCo-Author: Chris Krelle <nobodycam@gmail.com>\nCo-Author: Devananda van der Veen <devananda.vdv@gmail.com>\nChange-Id: I302651d57a1afb90bede3ebb778cfc3024af1204\n'}, {'number': 12, 'created': '2014-02-26 17:33:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/c8d84db3e03c9f7b479d901078495ee2e58bc074', 'message': 'Add Ironic volume driver\n\nThis patch adds a volume driver for the ironic driver.\n\nimplements bp:deprecate-baremetal-driver\n\nCo-Author: Chris Krelle <nobodycam@gmail.com>\nCo-Author: Devananda van der Veen <devananda.vdv@gmail.com>\nChange-Id: I302651d57a1afb90bede3ebb778cfc3024af1204\n'}, {'number': 13, 'created': '2014-02-26 18:39:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/1721a9b14b72b610e9643a50b44a23b21582e41b', 'message': 'Add Ironic volume driver\n\nThis patch adds a volume driver for the ironic driver.\n\nimplements bp:deprecate-baremetal-driver\n\nCo-Author: Chris Krelle <nobodycam@gmail.com>\nCo-Author: Devananda van der Veen <devananda.vdv@gmail.com>\nChange-Id: I302651d57a1afb90bede3ebb778cfc3024af1204\n'}, {'number': 14, 'created': '2014-02-26 18:52:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/3db62d04d0dc18cc51e5c4ab850f5ceb170f1677', 'message': 'Add Ironic volume driver\n\nThis patch adds a volume driver for the ironic driver.\n\nimplements bp:deprecate-baremetal-driver\n\nCo-Author: Chris Krelle <nobodycam@gmail.com>\nCo-Author: Devananda van der Veen <devananda.vdv@gmail.com>\nChange-Id: I302651d57a1afb90bede3ebb778cfc3024af1204\n'}, {'number': 15, 'created': '2014-02-26 23:27:06.000000000', 'files': ['nova/tests/virt/ironic/test_volume_driver.py', 'nova/virt/ironic/driver.py', 'etc/nova/nova.conf.sample', 'nova/tests/virt/ironic/test_driver.py', 'nova/tests/virt/ironic/ironic_tests_fakes.py', 'nova/virt/ironic/volume_driver.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/876016ff92c1841197b50680d153e0b9664641f8', 'message': 'Add Ironic volume driver\n\nThis patch adds a volume driver for the ironic driver.\n\nimplements bp:deprecate-baremetal-driver\n\nCo-Author: Chris Krelle <nobodycam@gmail.com>\nCo-Author: Devananda van der Veen <devananda.vdv@gmail.com>\nChange-Id: I302651d57a1afb90bede3ebb778cfc3024af1204\n'}]",2,71026,876016ff92c1841197b50680d153e0b9664641f8,76,7,15,6773,,,0,"Add Ironic volume driver

This patch adds a volume driver for the ironic driver.

implements bp:deprecate-baremetal-driver

Co-Author: Chris Krelle <nobodycam@gmail.com>
Co-Author: Devananda van der Veen <devananda.vdv@gmail.com>
Change-Id: I302651d57a1afb90bede3ebb778cfc3024af1204
",git fetch https://review.opendev.org/openstack/nova refs/changes/26/71026/8 && git format-patch -1 --stdout FETCH_HEAD,"['nova/virt/ironic/driver.py', 'nova/virt/ironic/volume_driver.py']",2,b97502e83bfeef546747ba05489812bf56fa11cb,bp/deprecate-baremetal-driver,"# vim: tabstop=4 shiftwidth=4 softtabstop=4 # coding=utf-8 # Copyright (c) 2012 NTT DOCOMO, INC. # All Rights Reserved. # # Licensed under the Apache License, Version 2.0 (the ""License""); you may # not use this file except in compliance with the License. You may obtain # a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT # WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the # License for the specific language governing permissions and limitations # under the License. import re from oslo.config import cfg from nova import context as nova_context from nova import exception from nova import network from nova.openstack.common.gettextutils import _ from nova.openstack.common import importutils from nova.openstack.common import log as logging from nova.openstack.common import processutils from nova import utils # FIXME(NobodyCam): Remove need to import libvirt utils from nova.virt.libvirt import utils as libvirt_utils opts = [ cfg.BoolOpt('use_unsafe_iscsi', default=False, help='Do not set this out of dev/test environments. ' 'If a node does not have a fixed PXE IP address, ' 'volumes are exported with globally opened ACL'), cfg.StrOpt('iscsi_iqn_prefix', default='iqn.2010-10.org.openstack.baremetal', help='The iSCSI IQN prefix for baremetal volume connections.'), ] conf_group = cfg.OptGroup(name='ironic', title='Ironic Options') CONF = cfg.CONF CONF.register_group(conf_group) CONF.register_opts(opts, conf_group) CONF.import_opt('host', 'nova.netconf') CONF.import_opt('use_ipv6', 'nova.netconf') CONF.import_opt('volume_drivers', 'nova.virt.libvirt.driver', group='libvirt') LOG = logging.getLogger(__name__) def _create_iscsi_export_tgtadm(path, tid, iqn): utils.execute('tgtadm', '--lld', 'iscsi', '--mode', 'target', '--op', 'new', '--tid', tid, '--targetname', iqn, run_as_root=True) utils.execute('tgtadm', '--lld', 'iscsi', '--mode', 'logicalunit', '--op', 'new', '--tid', tid, '--lun', '1', '--backing-store', path, run_as_root=True) def _allow_iscsi_tgtadm(tid, address): utils.execute('tgtadm', '--lld', 'iscsi', '--mode', 'target', '--op', 'bind', '--tid', tid, '--initiator-address', address, run_as_root=True) def _delete_iscsi_export_tgtadm(tid): try: utils.execute('tgtadm', '--lld', 'iscsi', '--mode', 'logicalunit', '--op', 'delete', '--tid', tid, '--lun', '1', run_as_root=True) except processutils.ProcessExecutionError: pass try: utils.execute('tgtadm', '--lld', 'iscsi', '--mode', 'target', '--op', 'delete', '--tid', tid, run_as_root=True) except processutils.ProcessExecutionError: pass # Check if the tid is deleted, that is, check the tid no longer exists. # If the tid dose not exist, tgtadm returns with exit_code 22. # utils.execute() can check the exit_code if check_exit_code parameter is # passed. But, regardless of whether check_exit_code contains 0 or not, # if the exit_code is 0, the function dose not report errors. So we have to # catch a ProcessExecutionError and test its exit_code is 22. try: utils.execute('tgtadm', '--lld', 'iscsi', '--mode', 'target', '--op', 'show', '--tid', tid, run_as_root=True) except processutils.ProcessExecutionError as e: if e.exit_code == 22: # OK, the tid is deleted return raise raise exception.NovaException(_( 'baremetal driver was unable to delete tid %s') % tid) def _show_tgtadm(): out, _ = utils.execute('tgtadm', '--lld', 'iscsi', '--mode', 'target', '--op', 'show', run_as_root=True) return out def _list_backingstore_path(): out = _show_tgtadm() l = [] for line in out.split('\n'): m = re.search(r'Backing store path: (.*)$', line) if m: if '/' in m.group(1): l.append(m.group(1)) return l def _get_next_tid(): out = _show_tgtadm() last_tid = 0 for line in out.split('\n'): m = re.search(r'^Target (\d+):', line) if m: tid = int(m.group(1)) if last_tid < tid: last_tid = tid return last_tid + 1 def _find_tid(iqn): out = _show_tgtadm() pattern = r'^Target (\d+): *' + re.escape(iqn) for line in out.split('\n'): m = re.search(pattern, line) if m: return int(m.group(1)) return None def _get_iqn(instance_name, mountpoint): mp = mountpoint.replace('/', '-').strip('-') iqn = '%s:%s-%s' % (CONF.ironic.iscsi_iqn_prefix, instance_name, mp) return iqn def _get_fixed_ips(instance): context = nova_context.get_admin_context() nw_info = network.API().get_instance_nw_info(context, instance) ips = nw_info.fixed_ips() return ips class VolumeDriver(object): def __init__(self, virtapi): super(VolumeDriver, self).__init__() self.virtapi = virtapi self._initiator = None def get_volume_connector(self, instance): if not self._initiator: self._initiator = libvirt_utils.get_iscsi_initiator() if not self._initiator: LOG.warn(_('Could not determine iscsi initiator name'), instance=instance) return { 'ip': CONF.my_ip, 'initiator': self._initiator, 'host': CONF.host, } def attach_volume(self, connection_info, instance, mountpoint): raise NotImplementedError() def detach_volume(self, connection_info, instance, mountpoint): raise NotImplementedError() class LibvirtVolumeDriver(VolumeDriver): """"""The VolumeDriver delegates to nova.virt.libvirt.volume."""""" def __init__(self, virtapi): super(LibvirtVolumeDriver, self).__init__(virtapi) self.volume_drivers = {} for driver_str in CONF.libvirt.volume_drivers: driver_type, _sep, driver = driver_str.partition('=') driver_class = importutils.import_class(driver) self.volume_drivers[driver_type] = driver_class(self) def _volume_driver_method(self, method_name, connection_info, *args, **kwargs): driver_type = connection_info.get('driver_volume_type') if driver_type not in self.volume_drivers: raise exception.VolumeDriverNotFound(driver_type=driver_type) driver = self.volume_drivers[driver_type] method = getattr(driver, method_name) return method(connection_info, *args, **kwargs) def attach_volume(self, connection_info, instance, mountpoint): fixed_ips = _get_fixed_ips(instance) if not fixed_ips: if not CONF.ironic.use_unsafe_iscsi: raise exception.NovaException(_( 'No fixed PXE IP is associated to %s') % instance['uuid']) mount_device = mountpoint.rpartition(""/"")[2] disk_info = { 'dev': mount_device, 'bus': 'baremetal', 'type': 'baremetal', } conf = self._connect_volume(connection_info, disk_info) self._publish_iscsi(instance, mountpoint, fixed_ips, conf.source_path) def _connect_volume(self, connection_info, disk_info): return self._volume_driver_method('connect_volume', connection_info, disk_info) def _publish_iscsi(self, instance, mountpoint, fixed_ips, device_path): iqn = _get_iqn(instance['name'], mountpoint) tid = _get_next_tid() _create_iscsi_export_tgtadm(device_path, tid, iqn) if fixed_ips: for ip in fixed_ips: _allow_iscsi_tgtadm(tid, ip['address']) else: # NOTE(NTTdocomo): Since nova-compute does not know the # instance's initiator ip, it allows any initiators # to connect to the volume. This means other bare-metal # instances that are not attached the volume can connect # to the volume. Do not set CONF.ironic.use_unsafe_iscsi # out of dev/test environments. # TODO(NTTdocomo): support CHAP _allow_iscsi_tgtadm(tid, 'ALL') def detach_volume(self, connection_info, instance, mountpoint): mount_device = mountpoint.rpartition(""/"")[2] try: self._depublish_iscsi(instance, mountpoint) finally: self._disconnect_volume(connection_info, mount_device) def _disconnect_volume(self, connection_info, disk_dev): return self._volume_driver_method('disconnect_volume', connection_info, disk_dev) def _depublish_iscsi(self, instance, mountpoint): iqn = _get_iqn(instance['name'], mountpoint) tid = _find_tid(iqn) if tid is not None: _delete_iscsi_export_tgtadm(tid) else: LOG.warn(_('detach volume could not find tid for %s'), iqn, instance=instance) def get_all_block_devices(self): """""" Return all block devices in use on this node. """""" return _list_backingstore_path() def get_hypervisor_version(self): """""" A dummy method for LibvirtBaseVolumeDriver.connect_volume. """""" return 1 ",,316,0
openstack%2Fhorizon~master~I55fbadb4c8c5d6e2ef7e77172bea1e678cf4e46b,openstack/horizon,master,I55fbadb4c8c5d6e2ef7e77172bea1e678cf4e46b,This is the patch To fix the colon and space in horizon.less,ABANDONED,2014-02-27 19:32:55.000000000,2014-03-07 06:03:12.000000000,,"[{'_account_id': 3}, {'_account_id': 9157}, {'_account_id': 9498}]","[{'number': 1, 'created': '2014-02-27 19:32:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/d636036b2c9c5304b9ac478ebeed56c056d36fcf', 'message': 'Closes-Bug: #1285831\n\nChange-Id: I55fbadb4c8c5d6e2ef7e77172bea1e678cf4e46b\n'}, {'number': 2, 'created': '2014-02-27 21:38:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/4f0eb73a61b18481021f221dc7635f70a12aba83', 'message': 'To fix the colon and space in horizon.less\nCloses-Bug: #1285831\n\nChange-Id: I55fbadb4c8c5d6e2ef7e77172bea1e678cf4e46b\n'}, {'number': 3, 'created': '2014-02-27 22:30:46.000000000', 'files': ['openstack_dashboard/static/dashboard/less/horizon.less'], 'web_link': 'https://opendev.org/openstack/horizon/commit/14af0894998d96e20772a49d8552c0666b1385bb', 'message': 'This is the patch To fix the colon and space in horizon.less\n\nTo fix the bug, the space has been removed from border-bottom-left-radius\nand the value of this property has been shifted one space to the right.\nCloses-Bug: #1285831\n\nChange-Id: I55fbadb4c8c5d6e2ef7e77172bea1e678cf4e46b\n'}]",0,76946,14af0894998d96e20772a49d8552c0666b1385bb,14,3,3,9157,,,0,"This is the patch To fix the colon and space in horizon.less

To fix the bug, the space has been removed from border-bottom-left-radius
and the value of this property has been shifted one space to the right.
Closes-Bug: #1285831

Change-Id: I55fbadb4c8c5d6e2ef7e77172bea1e678cf4e46b
",git fetch https://review.opendev.org/openstack/horizon refs/changes/46/76946/1 && git format-patch -1 --stdout FETCH_HEAD,['openstack_dashboard/static/dashboard/less/horizon.less'],1,d636036b2c9c5304b9ac478ebeed56c056d36fcf,bug/1285831, border-bottom-left-radius: .2em; border-bottom-right-radius: .2em; border-bottom-left-radius: .2em; border-bottom-right-radius: .2em;, border-bottom-left-radius :.2em; border-bottom-right-radius :.2em; border-bottom-left-radius :.2em; border-bottom-right-radius :.2em;,4,4
openstack%2Ftempest~master~Iea0b2b645d9ed5b874904bc3b88718c732469b72,openstack/tempest,master,Iea0b2b645d9ed5b874904bc3b88718c732469b72,Minor change: self instead of cls and typo.,ABANDONED,2014-02-24 13:49:36.000000000,2014-03-07 06:03:10.000000000,,"[{'_account_id': 3}, {'_account_id': 5803}]","[{'number': 1, 'created': '2014-02-24 13:49:36.000000000', 'files': ['tempest/test.py'], 'web_link': 'https://opendev.org/openstack/tempest/commit/2bff7f401a8c8fa51f6eec5d138fe36d33e4bb32', 'message': 'Minor change: self instead of cls and typo.\n\nChange-Id: Iea0b2b645d9ed5b874904bc3b88718c732469b72\n'}]",1,75869,2bff7f401a8c8fa51f6eec5d138fe36d33e4bb32,8,2,1,4325,,,0,"Minor change: self instead of cls and typo.

Change-Id: Iea0b2b645d9ed5b874904bc3b88718c732469b72
",git fetch https://review.opendev.org/openstack/tempest refs/changes/69/75869/1 && git format-patch -1 --stdout FETCH_HEAD,['tempest/test.py'],1,2bff7f401a8c8fa51f6eec5d138fe36d33e4bb32,typo," raise RuntimeError(""setUpClass does not call the super's"" def set_network_resources(cls, network=False, router=False, subnet=False,"," raise RuntimeError(""setUpClass does not calls the super's"" def set_network_resources(self, network=False, router=False, subnet=False,",2,2
openstack%2Fswift~master~Ibb94d1d6b8473f38f66ec19a1c34895c415be9c2,openstack/swift,master,Ibb94d1d6b8473f38f66ec19a1c34895c415be9c2,Exception message should not be localize,ABANDONED,2014-02-27 09:02:02.000000000,2014-03-07 06:03:07.000000000,,"[{'_account_id': 3}, {'_account_id': 2649}, {'_account_id': 7543}]","[{'number': 1, 'created': '2014-02-27 09:02:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/78f3fed8f5ca821a63a8ff3f2f2c891d96442355', 'message': 'Exception message should not be localize\n\nException text should not be marked for translation, becuase\nif an exception occurs there is no guarantee that the\ntranslation machinery will be functional.\n\nChange-Id: Ibb94d1d6b8473f38f66ec19a1c34895c415be9c2\nPartial-Bug:  #1285530\n'}, {'number': 2, 'created': '2014-02-28 02:15:42.000000000', 'files': ['swift/common/wsgi.py'], 'web_link': 'https://opendev.org/openstack/swift/commit/dd6d8694d1bc51068d89f422eabbe95c8d8371b8', 'message': 'Exception message should not be localize\n\nException text should not be marked for translation, becuase\nif an exception occurs there is no guarantee that the\ntranslation machinery will be functional.\n\nChange-Id: Ibb94d1d6b8473f38f66ec19a1c34895c415be9c2\nPartial-Bug:  #1285530\n'}]",0,76801,dd6d8694d1bc51068d89f422eabbe95c8d8371b8,8,3,2,7543,,,0,"Exception message should not be localize

Exception text should not be marked for translation, becuase
if an exception occurs there is no guarantee that the
translation machinery will be functional.

Change-Id: Ibb94d1d6b8473f38f66ec19a1c34895c415be9c2
Partial-Bug:  #1285530
",git fetch https://review.opendev.org/openstack/swift refs/changes/01/76801/2 && git format-patch -1 --stdout FETCH_HEAD,['swift/common/wsgi.py'],1,78f3fed8f5ca821a63a8ff3f2f2c891d96442355,localize, raise Exception(('Could not bind to %s:%s ', raise Exception(_('Could not bind to %s:%s ',1,1
openstack%2Fglance~master~Idd43172223d87b9d22441bcd73aeff1277ba4d3c,openstack/glance,master,Idd43172223d87b9d22441bcd73aeff1277ba4d3c,"Fix ""changes-since"" filter for glance API",ABANDONED,2014-01-27 11:23:08.000000000,2014-03-07 06:03:04.000000000,,"[{'_account_id': 3}, {'_account_id': 6167}, {'_account_id': 6484}, {'_account_id': 6549}, {'_account_id': 7884}, {'_account_id': 9520}, {'_account_id': 9533}]","[{'number': 1, 'created': '2014-01-27 11:23:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/9afea4b861247d0ae839f1de3d6dd3f0a430bbda', 'message': 'Fix ""changes-since"" filter for glance API\n\nThis is similar to https://review.openstack.org/#/c/60157/.\n\nOn Glance API(e.g. v1/image/detail)"", ""changes-since"" parameter filters\nout images which have been update at the same date as the specified\ntimestamp.\n\nFor example, the following image is filtered out with\n""changes-since=2013-12-05T15:03:25"":\n\nmysql> select id, updated_at from images;\n+-------------------------------------+---------------------+\n| id                                  | updated_at          |\n+-------------------------------------+---------------------+\n| ca15b4d7-6c8b-4d7e-a4bd-a6186373e4d9| 2013-12-05 15:03:25 |\n+-------------------------------------+---------------------+\n\nthe behavior would be wrong from the viewpoint of its name\nwhich includes ""since"".\n\nIn this patch, I added ""="" operator in  conditional expression about\n""changes-since"".\n\nChange-Id: Idd43172223d87b9d22441bcd73aeff1277ba4d3c\nCloses-bug: #1273171\n'}, {'number': 2, 'created': '2014-01-30 11:20:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/84fd965df4bd5602013d8f011111f467074914e2', 'message': 'Fix ""changes-since"" filter for glance API\n\nThis is similar to https://review.openstack.org/#/c/60157/.\n\nOn Glance API(e.g. v1/image/detail)"", ""changes-since"" parameter filters\nout images which have been update at the same date as the specified\ntimestamp.\n\nFor example, the following image is filtered out with\n""changes-since=2013-12-05T15:03:25"":\n\nmysql> select id, updated_at from images;\n+-------------------------------------+---------------------+\n| id                                  | updated_at          |\n+-------------------------------------+---------------------+\n| ca15b4d7-6c8b-4d7e-a4bd-a6186373e4d9| 2013-12-05 15:03:25 |\n+-------------------------------------+---------------------+\n\nthe behavior would be wrong from the viewpoint of its name\nwhich includes ""since"".\n\nIn this patch, I added ""="" operator in  conditional expression about\n""changes-since"".\n\nChange-Id: Idd43172223d87b9d22441bcd73aeff1277ba4d3c\nCloses-bug: #1273171\n'}, {'number': 3, 'created': '2014-02-21 07:17:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/d901deabb5f8692595afe27174b0993dde1e6201', 'message': 'Fix ""changes-since"" filter for glance API\n\nThis is similar to https://review.openstack.org/#/c/60157/.\n\nOn Glance API(e.g. v1/image/detail)"", ""changes-since"" parameter filters\nout images which have been update at the same date as the specified\ntimestamp.\n\nFor example, the following image is filtered out with\n""changes-since=2013-12-05T15:03:25"":\n\nmysql> select id, updated_at from images;\n+-------------------------------------+---------------------+\n| id                                  | updated_at          |\n+-------------------------------------+---------------------+\n| ca15b4d7-6c8b-4d7e-a4bd-a6186373e4d9| 2013-12-05 15:03:25 |\n+-------------------------------------+---------------------+\n\nthe behavior would be wrong from the viewpoint of its name\nwhich includes ""since"".\n\nIn this patch, I added ""="" operator in  conditional expression about\n""changes-since"".\n\nChange-Id: Idd43172223d87b9d22441bcd73aeff1277ba4d3c\nCloses-bug: #1273171\n'}, {'number': 4, 'created': '2014-02-28 04:57:50.000000000', 'files': ['glance/db/sqlalchemy/api.py', 'glance/tests/functional/db/test_sqlalchemy.py'], 'web_link': 'https://opendev.org/openstack/glance/commit/0dcfa5f4bdcdb6a42f6bc225a029a3a6a0ddeca3', 'message': 'Fix ""changes-since"" filter for glance API\n\nThis is similar to https://review.openstack.org/#/c/60157/.\n\nOn Glance API(e.g. v1/image/detail)"", ""changes-since"" parameter filters\nout images which have been update at the same date as the specified\ntimestamp.\n\nFor example, the following image is filtered out with\n""changes-since=2013-12-05T15:03:25"":\n\nmysql> select id, updated_at from images;\n+-------------------------------------+---------------------+\n| id                                  | updated_at          |\n+-------------------------------------+---------------------+\n| ca15b4d7-6c8b-4d7e-a4bd-a6186373e4d9| 2013-12-05 15:03:25 |\n+-------------------------------------+---------------------+\n\nthe behavior would be wrong from the viewpoint of its name\nwhich includes ""since"".\n\nIn this patch, I added ""="" operator in  conditional expression about\n""changes-since"".\n\nChange-Id: Idd43172223d87b9d22441bcd73aeff1277ba4d3c\nCloses-bug: #1273171\n'}]",10,69328,0dcfa5f4bdcdb6a42f6bc225a029a3a6a0ddeca3,24,7,4,7884,,,0,"Fix ""changes-since"" filter for glance API

This is similar to https://review.openstack.org/#/c/60157/.

On Glance API(e.g. v1/image/detail)"", ""changes-since"" parameter filters
out images which have been update at the same date as the specified
timestamp.

For example, the following image is filtered out with
""changes-since=2013-12-05T15:03:25"":

mysql> select id, updated_at from images;
+-------------------------------------+---------------------+
| id                                  | updated_at          |
+-------------------------------------+---------------------+
| ca15b4d7-6c8b-4d7e-a4bd-a6186373e4d9| 2013-12-05 15:03:25 |
+-------------------------------------+---------------------+

the behavior would be wrong from the viewpoint of its name
which includes ""since"".

In this patch, I added ""="" operator in  conditional expression about
""changes-since"".

Change-Id: Idd43172223d87b9d22441bcd73aeff1277ba4d3c
Closes-bug: #1273171
",git fetch https://review.opendev.org/openstack/glance refs/changes/28/69328/1 && git format-patch -1 --stdout FETCH_HEAD,"['glance/tests/unit/v1/test_registry_api.py', 'glance/db/sqlalchemy/api.py']",2,9afea4b861247d0ae839f1de3d6dd3f0a430bbda,changes-since, image_conditions.append(models.Image.updated_at >= changes_since), image_conditions.append(models.Image.updated_at > changes_since),20,1
openstack%2Fcinder~master~Id5c6c447f44aaa14891826c7a593636bed0309cd,openstack/cinder,master,Id5c6c447f44aaa14891826c7a593636bed0309cd,Skip test_delete_no_dev_fails on OSX,ABANDONED,2014-02-28 01:15:07.000000000,2014-03-07 06:03:02.000000000,,"[{'_account_id': 3}, {'_account_id': 2243}]","[{'number': 1, 'created': '2014-02-28 01:15:07.000000000', 'files': ['cinder/tests/test_volume.py'], 'web_link': 'https://opendev.org/openstack/cinder/commit/0d54d6c88e737e3627364416c0f62859dc2686ef', 'message': ""Skip test_delete_no_dev_fails on OSX\n\nOSx doesn't seem to like the mkdir calls used\nby this test.  I've tried macports as well as brew\nbut have not had any luck.  If somebody konws how to\nfix this to run on OSx it would be great to share\nthe knowledge and remove the skip.\n\nAnybody knows a *real* solution it'd be great\nto update dev env docs.\n\nChange-Id: Id5c6c447f44aaa14891826c7a593636bed0309cd\n""}]",0,77025,0d54d6c88e737e3627364416c0f62859dc2686ef,5,2,1,2243,,,0,"Skip test_delete_no_dev_fails on OSX

OSx doesn't seem to like the mkdir calls used
by this test.  I've tried macports as well as brew
but have not had any luck.  If somebody konws how to
fix this to run on OSx it would be great to share
the knowledge and remove the skip.

Anybody knows a *real* solution it'd be great
to update dev env docs.

Change-Id: Id5c6c447f44aaa14891826c7a593636bed0309cd
",git fetch https://review.opendev.org/openstack/cinder refs/changes/25/77025/1 && git format-patch -1 --stdout FETCH_HEAD,['cinder/tests/test_volume.py'],1,0d54d6c88e737e3627364416c0f62859dc2686ef,OSXskip_test_delete_no_dev_fails,"import platform # NOTE(jgriffith): If somebody has a hack for this lemme know if platform.mac_ver()[0] != '': self.skipTest(""Unable to test on OSX"") ",,6,0
openstack%2Fpython-swiftclient~master~Ieb8acc8277e64633d29c5c77b2afc0c237cb4d2a,openstack/python-swiftclient,master,Ieb8acc8277e64633d29c5c77b2afc0c237cb4d2a,Remove ignore of H501 hacking check,ABANDONED,2014-03-06 21:25:16.000000000,2014-03-07 05:48:59.000000000,,"[{'_account_id': 3}, {'_account_id': 330}, {'_account_id': 1179}]","[{'number': 1, 'created': '2014-03-06 21:25:16.000000000', 'files': ['tox.ini'], 'web_link': 'https://opendev.org/openstack/python-swiftclient/commit/d878af609942a4960a8d72d02337f44e2fb462a2', 'message': ""Remove ignore of H501 hacking check\n\nThis check is ignored even though there aren't any uses of\nlocals().\n\nChange-Id: Ieb8acc8277e64633d29c5c77b2afc0c237cb4d2a\nCloses-Bug: 1288988\n""}]",0,78772,d878af609942a4960a8d72d02337f44e2fb462a2,5,3,1,6601,,,0,"Remove ignore of H501 hacking check

This check is ignored even though there aren't any uses of
locals().

Change-Id: Ieb8acc8277e64633d29c5c77b2afc0c237cb4d2a
Closes-Bug: 1288988
",git fetch https://review.opendev.org/openstack/python-swiftclient refs/changes/72/78772/1 && git format-patch -1 --stdout FETCH_HEAD,['tox.ini'],1,d878af609942a4960a8d72d02337f44e2fb462a2,bug/1288988,"select = H102, H103, H201, H903","# H501 -> don't use locals() for str formattingselect = H102, H103, H201, H501, H903",1,2
openstack%2Fopenstack-manuals~master~I079543d4d47f3660bb18435067cc44ff178bb136,openstack/openstack-manuals,master,I079543d4d47f3660bb18435067cc44ff178bb136,Updates to 'Create and manage images' section in Admin User Guide,MERGED,2014-03-05 05:27:42.000000000,2014-03-07 05:37:32.000000000,2014-03-07 05:37:31.000000000,"[{'_account_id': 3}, {'_account_id': 612}, {'_account_id': 6547}, {'_account_id': 6843}, {'_account_id': 7923}, {'_account_id': 8103}, {'_account_id': 9162}]","[{'number': 1, 'created': '2014-03-05 05:27:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/52687ff99a55d3e59d33f8ce10b49888e282504e', 'message': ""Updates to 'Create and manage images' section in Admin User Guide\n\nUpdates to the Admin User guide section 'Create and manage images' in the\ndashboard chapter to include the changes to the fields in the 'Create Image'\nwindow.\nPartial-Bug: #1279133\n\nChange-Id: I079543d4d47f3660bb18435067cc44ff178bb136\n""}, {'number': 2, 'created': '2014-03-05 23:39:34.000000000', 'files': ['doc/user-guide-admin/section_dashboard_admin_manage_images.xml'], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/5505ad4882b6d2a03dc4d9aa5fc0ef9615405f5a', 'message': ""Updates to 'Create and manage images' section in Admin User Guide\n\nUpdates to the Admin User guide section 'Create and manage images' in the\ndashboard chapter to include the changes to the fields in the 'Create Image'\nwindow.\nPartial-Bug: #1279133\n\nChange-Id: I079543d4d47f3660bb18435067cc44ff178bb136\n""}]",1,78098,5505ad4882b6d2a03dc4d9aa5fc0ef9615405f5a,16,7,2,8103,,,0,"Updates to 'Create and manage images' section in Admin User Guide

Updates to the Admin User guide section 'Create and manage images' in the
dashboard chapter to include the changes to the fields in the 'Create Image'
window.
Partial-Bug: #1279133

Change-Id: I079543d4d47f3660bb18435067cc44ff178bb136
",git fetch https://review.opendev.org/openstack/openstack-manuals refs/changes/98/78098/2 && git format-patch -1 --stdout FETCH_HEAD,['doc/user-guide-admin/section_dashboard_admin_manage_images.xml'],1,52687ff99a55d3e59d33f8ce10b49888e282504e,sect-dashboard-create-images-AUG," <td><para><guilabel>Image Source</guilabel></para></td> <td><para>Choose the image source from the dropdown list. Your choices are <guilabel>Image Location</guilabel> and <guilabel>Image File</guilabel>.</para></td> <td><para><guilabel>Image File</guilabel> or <guilabel>Image Location</guilabel></para></td> <td> <para>Based on your selection, there is an <guilabel>Image File </guilabel> or <guilabel>Image Location</guilabel> field. You can include the location URL or browse to the image file on your file system and add it.</para></td> <guilabel>Minimum Disk (MB)</guilabel></para></td> </tr><tr> <td><para><guilabel>Protected</guilabel></para></td> <td><para>Select this option to ensure that only users with permissions can delete it.</para></td>"," <td><para><guilabel>Image Location</guilabel></para></td> <td><para>Include the URL of the image.</para></td> <td><para><guilabel>Image File</guilabel></para></td> <td><para>Alternatively, browse to find the image file on your machine.</para></td> <guilabel>Maximum Disk (GB)</guilabel></para></td>",16,7
openstack%2Fopenstack-manuals~master~Ie3562a83c0f9c6ff4a786eb899fdbf1e5c6efcf3,openstack/openstack-manuals,master,Ie3562a83c0f9c6ff4a786eb899fdbf1e5c6efcf3,Add docs for NetApp copy offload tool in Cinder,MERGED,2014-02-25 14:06:56.000000000,2014-03-07 05:37:24.000000000,2014-03-07 05:37:23.000000000,"[{'_account_id': 3}, {'_account_id': 612}, {'_account_id': 5162}, {'_account_id': 6547}, {'_account_id': 9162}, {'_account_id': 9186}, {'_account_id': 9190}, {'_account_id': 9366}]","[{'number': 1, 'created': '2014-02-25 14:06:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/c9d3afb7db9365b21156e8e374e44efd84e5dd66', 'message': 'Add docs for NetApp copy offload tool in Cinder\n\nThis change documents the addition of the NetApp copy offload tool into\nthe NetApp unified driver within Cinder. An additional Cinder\nconfiguration option was added and its use in conjunction with the copy\noffload binary is discussed, along with instructions to download and\nconfigure the storage system to support the copy offload workflow.\n\nChange-Id: Ie3562a83c0f9c6ff4a786eb899fdbf1e5c6efcf3\nImplements: blueprint copyoffload\n'}, {'number': 2, 'created': '2014-02-25 14:23:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/1116dc96740483cec173331f278656e3ba31125b', 'message': 'Add docs for NetApp copy offload tool in Cinder\n\nThis change documents the addition of the NetApp copy offload tool into\nthe NetApp unified driver within Cinder. An additional Cinder\nconfiguration option was added and its use in conjunction with the copy\noffload binary is discussed, along with instructions to download and\nconfigure the storage system to support the copy offload workflow.\n\nChange-Id: Ie3562a83c0f9c6ff4a786eb899fdbf1e5c6efcf3\nImplements: blueprint copyoffload\n'}, {'number': 3, 'created': '2014-02-25 15:14:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/a744120916ae982c6293454f2b42b06785925da8', 'message': 'Add docs for NetApp copy offload tool in Cinder\n\nThis change documents the addition of the NetApp copy offload tool into\nthe NetApp unified driver within Cinder. An additional Cinder\nconfiguration option was added and its use in conjunction with the copy\noffload binary is discussed, along with instructions to download and\nconfigure the storage system to support the copy offload workflow.\n\nChange-Id: Ie3562a83c0f9c6ff4a786eb899fdbf1e5c6efcf3\nImplements: blueprint copyoffload\n'}, {'number': 4, 'created': '2014-02-26 15:46:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/1437b79268ba883b1e42c76b4e6716e19151c736', 'message': 'Add docs for NetApp copy offload tool in Cinder\n\nThis change documents the addition of the NetApp copy offload tool into\nthe NetApp unified driver within Cinder. An additional Cinder\nconfiguration option was added and its use in conjunction with the copy\noffload binary is discussed, along with instructions to download and\nconfigure the storage system to support the copy offload workflow.\n\nChange-Id: Ie3562a83c0f9c6ff4a786eb899fdbf1e5c6efcf3\nImplements: blueprint copyoffload\n'}, {'number': 5, 'created': '2014-02-28 13:41:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/64f30914810848d022332eb16af3207dcbeb72b4', 'message': 'Add docs for NetApp copy offload tool in Cinder\n\nThis change documents the addition of the NetApp copy offload tool into\nthe NetApp unified driver within Cinder. An additional Cinder\nconfiguration option was added and its use in conjunction with the copy\noffload binary is discussed, along with instructions to download and\nconfigure the storage system to support the copy offload workflow.\n\nChange-Id: Ie3562a83c0f9c6ff4a786eb899fdbf1e5c6efcf3\nImplements: blueprint copyoffload\n'}, {'number': 6, 'created': '2014-03-06 19:32:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/6de75a912de8520575318e18de7f5e8f2affcab0', 'message': 'Add docs for NetApp copy offload tool in Cinder\n\nThis change documents the addition of the NetApp copy offload tool into\nthe NetApp unified driver within Cinder. An additional Cinder\nconfiguration option was added and its use in conjunction with the copy\noffload binary is discussed, along with instructions to download and\nconfigure the storage system to support the copy offload workflow.\n\nChange-Id: Ie3562a83c0f9c6ff4a786eb899fdbf1e5c6efcf3\nImplements: blueprint copyoffload\n'}, {'number': 7, 'created': '2014-03-06 19:34:13.000000000', 'files': ['doc/common/tables/cinder-netapp_cdot_nfs.xml', 'doc/config-reference/block-storage/drivers/netapp-volume-driver.xml', 'tools/autogenerate-config-flagmappings/cinder.flagmappings'], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/92611dea22f85ddd2960f77c720f453febd16ec1', 'message': 'Add docs for NetApp copy offload tool in Cinder\n\nThis change documents the addition of the NetApp copy offload tool into\nthe NetApp unified driver within Cinder. An additional Cinder\nconfiguration option was added and its use in conjunction with the copy\noffload binary is discussed, along with instructions to download and\nconfigure the storage system to support the copy offload workflow.\n\nChange-Id: Ie3562a83c0f9c6ff4a786eb899fdbf1e5c6efcf3\nImplements: blueprint copyoffload\n'}]",11,76210,92611dea22f85ddd2960f77c720f453febd16ec1,44,8,7,9186,,,0,"Add docs for NetApp copy offload tool in Cinder

This change documents the addition of the NetApp copy offload tool into
the NetApp unified driver within Cinder. An additional Cinder
configuration option was added and its use in conjunction with the copy
offload binary is discussed, along with instructions to download and
configure the storage system to support the copy offload workflow.

Change-Id: Ie3562a83c0f9c6ff4a786eb899fdbf1e5c6efcf3
Implements: blueprint copyoffload
",git fetch https://review.opendev.org/openstack/openstack-manuals refs/changes/10/76210/5 && git format-patch -1 --stdout FETCH_HEAD,"['doc/common/tables/cinder-netapp_cdot_nfs.xml', 'doc/config-reference/block-storage/drivers/netapp-volume-driver.xml', 'tools/autogenerate-config-flagmappings/cinder.flagmappings']",3,c9d3afb7db9365b21156e8e374e44efd84e5dd66,bp/copyoffload,netapp_copyoffload_tool netapp_cdot_nfs,,49,0
openstack%2Fopenstack-manuals~master~I0e966c18f8783cbd04da813175da1e60d9753b2b,openstack/openstack-manuals,master,I0e966c18f8783cbd04da813175da1e60d9753b2b,cleanup module001-ch010-vm-provisioning-indepth,MERGED,2014-02-28 22:15:01.000000000,2014-03-07 05:37:16.000000000,2014-03-07 05:37:15.000000000,"[{'_account_id': 3}, {'_account_id': 612}, {'_account_id': 6547}, {'_account_id': 7923}, {'_account_id': 9162}, {'_account_id': 9382}, {'_account_id': 9383}]","[{'number': 1, 'created': '2014-02-28 22:15:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/a8c4bab247f539d72ab502d40984e230efcbc65f', 'message': 'cleanup module001-ch010-vm-provisioning-indepth\n\nQuantum changed to Neutron\nadded plural receives\nchanged authenticate to plural\nadded the before request\nadded and before authenticates\nadded the before appropriate\nadded the before nova-database\nreturn to plural\nadded the before glance-api\nchanged upload to plural and added the\nchanged to ""so that the"" vs ""such the""\nchanged get to gets plural\nadded the before instance\nadded the before hypervisor driver\ncapitalized api\nchanged in-depth to In Depth\n\nChange-Id: I0e966c18f8783cbd04da813175da1e60d9753b2b\n'}, {'number': 2, 'created': '2014-03-01 08:51:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/1b2e844df8e58080fa3779094644ff96076e2ad0', 'message': 'cleanup module001-ch010-vm-provisioning-indepth\n\nQuantum changed to Neutron\nadded plural receives\nchanged authenticate to plural\nadded the before request\nadded and before authenticates\nadded the before appropriate\nadded the before nova-database\nreturn to plural\nadded the before glance-api\nchanged upload to plural and added the\nchanged to ""so that the"" vs ""such the""\nchanged get to gets plural\nadded the before instance\nadded the before hypervisor driver\ncapitalized api\nchanged in-depth to In Depth\n\nChange-Id: I0e966c18f8783cbd04da813175da1e60d9753b2b\n'}, {'number': 3, 'created': '2014-03-05 18:32:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/0f78b0f532f1a722b5798620c4ba470b851491b8', 'message': 'cleanup module001-ch010-vm-provisioning-indepth\n\nQuantum changed to Neutron\nadded plural receives\nchanged authenticate to plural\nadded the before request\nadded and before authenticates\nadded the before appropriate\nadded the before nova-database\nreturn to plural\nadded the before glance-api\nchanged upload to plural and added the\nchanged to ""so that the"" vs ""such the""\nchanged get to gets plural\nadded the before instance\nadded the before hypervisor driver\ncapitalized api\nchanged in-depth to In Depth\n\nAdd <systemitem> markup\n\nChange-Id: I0e966c18f8783cbd04da813175da1e60d9753b2b\n'}, {'number': 4, 'created': '2014-03-06 16:39:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/436b42d6ac69922663b9866aad3fd521c9706729', 'message': 'cleanup module001-ch010-vm-provisioning-indepth\n\nQuantum changed to Neutron\nadded plural receives\nchanged authenticate to plural\nadded the before request\nadded and before authenticates\nadded the before appropriate\nadded the before nova-database\nreturn to plural\nadded the before glance-api\nchanged upload to plural and added the\nchanged to ""so that the"" vs ""such the""\nchanged get to gets plural\nadded the before instance\nadded the before hypervisor driver\ncapitalized api\nchanged in-depth to In Depth\n\nAdd <systemitem> markup\n\nChange-Id: I0e966c18f8783cbd04da813175da1e60d9753b2b\n'}, {'number': 5, 'created': '2014-03-06 19:22:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/51d0996046de5e294c62a19b0ae9014e41ed315e', 'message': 'cleanup module001-ch010-vm-provisioning-indepth\n\nQuantum changed to Neutron\nadded plural receives\nchanged authenticate to plural\nadded the before request\nadded and before authenticates\nadded the before appropriate\nadded the before nova-database\nreturn to plural\nadded the before glance-api\nchanged upload to plural and added the\nchanged to ""so that the"" vs ""such the""\nchanged get to gets plural\nadded the before instance\nadded the before hypervisor driver\ncapitalized api\nchanged in-depth to In Depth\n\nAdd <systemitem> markup\n\nRework list so that step numbers match the graphic.\n\nCo-Authored-By: Andreas Jaeger <aj@suse.de>\n\nChange-Id: I0e966c18f8783cbd04da813175da1e60d9753b2b\n'}, {'number': 6, 'created': '2014-03-06 19:25:55.000000000', 'files': ['doc/training-guides/module001-ch010-vm-provisioning-indepth.xml', 'doc/training-guides/bk001-ch005-associate-compute-node.xml'], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/2b8aaaed53e3d9ca4a97d5923c135ab171144130', 'message': 'cleanup module001-ch010-vm-provisioning-indepth\n\nQuantum changed to Neutron\nadded plural receives\nchanged authenticate to plural\nadded the before request\nadded and before authenticates\nadded the before appropriate\nadded the before nova-database\nreturn to plural\nadded the before glance-api\nchanged upload to plural and added the\nchanged to ""so that the"" vs ""such the""\nchanged get to gets plural\nadded the before instance\nadded the before hypervisor driver\ncapitalized api\nchanged in-depth to In Depth\n\nAdd <systemitem> markup\n\nRework list so that step numbers match the graphic.\n\nCo-Authored-By: Andreas Jaeger <aj@suse.de>\n\nChange-Id: I0e966c18f8783cbd04da813175da1e60d9753b2b\n'}]",38,77274,2b8aaaed53e3d9ca4a97d5923c135ab171144130,29,7,6,9382,,,0,"cleanup module001-ch010-vm-provisioning-indepth

Quantum changed to Neutron
added plural receives
changed authenticate to plural
added the before request
added and before authenticates
added the before appropriate
added the before nova-database
return to plural
added the before glance-api
changed upload to plural and added the
changed to ""so that the"" vs ""such the""
changed get to gets plural
added the before instance
added the before hypervisor driver
capitalized api
changed in-depth to In Depth

Add <systemitem> markup

Rework list so that step numbers match the graphic.

Co-Authored-By: Andreas Jaeger <aj@suse.de>

Change-Id: I0e966c18f8783cbd04da813175da1e60d9753b2b
",git fetch https://review.opendev.org/openstack/openstack-manuals refs/changes/74/77274/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/training-guides/module001-ch010-vm-provisioning-indepth.xml'],1,a8c4bab247f539d72ab502d40984e230efcbc65f,vmprovisioning_indepth, <title>VM Provisioning In Depth</title> <para>The Dashboard or CLI gets the user credentials and authenticates <para>Keystone authenticates the credentials and generates &amp; send back auth-token which will be used for sending the request to other <para>nova-api receives the request and sends the request for <para>Returns the updated instance entry with the appropriate host ID <para>nova-conductor interacts with the nova-database.</para> <para>Returns the instance information.</para> <para>nova-compute does the REST call by passing auth-token to the uploads the image from image storage.</para> Network API to allocate and configure the network so that the <para>neutron-server validates the auth-token with <para>nova-compute gets the network info.</para> Volume API to attach volumes to the instance.</para> <para>nova-compute generates data for the hypervisor driver and executes the request on the Hypervisor( via libvirt or API).</para>, <title>VM Provisioning Indepth</title> <para>Dashboard or CLI gets the user credentials authenticates <para>Keystone authenticate the credentials and generate &amp; send back auth-token which will be used for sending request to other <para>nova-api receive the request and sends the request for <para>Returns the updated instance entry with appropriate host ID <para>nova-conductor interacts with nova-database.</para> <para>Return the instance information.</para> <para>nova-compute does the REST call by passing auth-token to upload image from image storage.</para> Network API to allocate and configure the network such that <para>quantum-server validates the auth-token with <para>nova-compute get the network info.</para> Volume API to attach volumes to instance.</para> <para>nova-compute generates data for hypervisor driver and executes request on Hypervisor( via libvirt or api).</para>,16,16
openstack%2Fopenstack-manuals~master~I39d9d48669b9b7192814a5e14f0f81a8557d1a44,openstack/openstack-manuals,master,I39d9d48669b9b7192814a5e14f0f81a8557d1a44,Add docs for new HP LeftHand Cinder driver,MERGED,2014-03-03 18:00:57.000000000,2014-03-07 05:37:09.000000000,2014-03-07 05:37:08.000000000,"[{'_account_id': 3}, {'_account_id': 612}, {'_account_id': 6043}, {'_account_id': 6547}, {'_account_id': 7389}, {'_account_id': 7923}, {'_account_id': 9162}]","[{'number': 1, 'created': '2014-03-03 18:00:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/a604f260d52706a1c1b4e76835d92ee188c12139', 'message': 'Add docs for new HP LeftHand Cinder driver\n\nThis change adds the documentation for the new HP LeftHand\ndriver. It documents how to configure the driver in both\nstandard and legacy modes, and describes the functionality\nwhen running in each mode.\n\nClose-Bug # 1279030\nImplements blueprint lefthand-cinder-driver\n\nChange-Id: I39d9d48669b9b7192814a5e14f0f81a8557d1a44\n'}, {'number': 2, 'created': '2014-03-03 23:17:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/3c94be16b5a84eb2abf2a9da8fd342fd283e30a1', 'message': 'Add docs for new HP LeftHand Cinder driver\n\nThis change adds the documentation for the new HP LeftHand\ndriver. It documents how to configure the driver in both\nstandard and legacy modes, and describes the functionality\nwhen running in each mode. When the driver executes in legacy\nmode, it is essentially running the old driver code.\nTherefore, the old LeftHand driver documentation was migrated\ninto the section HP LeftHand/StoreVirtual CLIQ driver legacy mode.\n\nCloses-Bug#1279030\nImplements blueprint lefthand-cinder-driver\n\nChange-Id: I39d9d48669b9b7192814a5e14f0f81a8557d1a44\n'}, {'number': 3, 'created': '2014-03-03 23:20:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/f91d9d47085da95af6fd7b5ba20e93d0fb98e061', 'message': 'Add docs for new HP LeftHand Cinder driver\n\nThis change adds the documentation for the new HP LeftHand\ndriver. It documents how to configure the driver in both\nstandard and legacy modes, and describes the functionality\nwhen running in each mode. When the driver executes in legacy\nmode, it is essentially running the old driver code.\nTherefore, the old LeftHand driver documentation was migrated\ninto the section HP LeftHand/StoreVirtual CLIQ driver legacy mode.\n\nCloses-Bug:#1279030\nImplements blueprint lefthand-cinder-driver\n\nChange-Id: I39d9d48669b9b7192814a5e14f0f81a8557d1a44\n'}, {'number': 4, 'created': '2014-03-04 23:26:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/75a536ac07db9f540705b3871cdf1faac22a703d', 'message': 'Add docs for new HP LeftHand Cinder driver\n\nThis change adds the documentation for the new HP LeftHand\ndriver. It documents how to configure the driver in both\nstandard and legacy modes, and describes the functionality\nwhen running in each mode. When the driver executes in legacy\nmode, it is essentially running the old driver code.\nTherefore, the old LeftHand driver documentation was migrated\ninto the section HP LeftHand/StoreVirtual CLIQ driver legacy mode.\n\nCloses-Bug:#1279030\nImplements blueprint lefthand-cinder-driver\n\nChange-Id: I39d9d48669b9b7192814a5e14f0f81a8557d1a44\n'}, {'number': 5, 'created': '2014-03-05 21:46:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/f7549283c9a78e8311381ae00d969290f9c3ee73', 'message': 'Add docs for new HP LeftHand Cinder driver\n\nThis change adds the documentation for the new HP LeftHand\ndriver. It documents how to configure the driver in both\nstandard and legacy modes, and describes the functionality\nwhen running in each mode. When the driver executes in legacy\nmode, it is essentially running the old driver code.\nTherefore, the old LeftHand driver documentation was migrated\ninto the section HP LeftHand/StoreVirtual CLIQ driver legacy mode.\n\nCloses-Bug:#1279030\nImplements blueprint lefthand-cinder-driver\n\nChange-Id: I39d9d48669b9b7192814a5e14f0f81a8557d1a44\n'}, {'number': 6, 'created': '2014-03-06 22:38:04.000000000', 'files': ['doc/config-reference/block-storage/drivers/hp-lefthand-driver.xml'], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/9fdadc0b178d976179588948683e75b546ff148d', 'message': 'Add docs for new HP LeftHand Cinder driver\n\nThis change adds the documentation for the new HP LeftHand\ndriver. It documents how to configure the driver in both\nstandard and legacy modes, and describes the functionality\nwhen running in each mode. When the driver executes in legacy\nmode, it is essentially running the old driver code.\nTherefore, the old LeftHand driver documentation was migrated\ninto the section HP LeftHand/StoreVirtual CLIQ driver legacy mode.\n\nCloses-Bug:#1279030\nImplements blueprint lefthand-cinder-driver\n\nChange-Id: I39d9d48669b9b7192814a5e14f0f81a8557d1a44\n'}]",64,77659,9fdadc0b178d976179588948683e75b546ff148d,35,7,6,7389,,,0,"Add docs for new HP LeftHand Cinder driver

This change adds the documentation for the new HP LeftHand
driver. It documents how to configure the driver in both
standard and legacy modes, and describes the functionality
when running in each mode. When the driver executes in legacy
mode, it is essentially running the old driver code.
Therefore, the old LeftHand driver documentation was migrated
into the section HP LeftHand/StoreVirtual CLIQ driver legacy mode.

Closes-Bug:#1279030
Implements blueprint lefthand-cinder-driver

Change-Id: I39d9d48669b9b7192814a5e14f0f81a8557d1a44
",git fetch https://review.opendev.org/openstack/openstack-manuals refs/changes/59/77659/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/config-reference/block-storage/drivers/hp-lefthand-driver.xml'],1,a604f260d52706a1c1b4e76835d92ee188c12139,bug/1279030,"<section xml:id=""HP-LeftHand-StoreVirtual-driver"" xmlns=""http://docbook.org/ns/docbook"" xmlns:xi=""http://www.w3.org/2001/XInclude"" xmlns:xlink=""http://www.w3.org/1999/xlink"" version=""5.0""> <title>HP LeftHand/StoreVirtual driver</title> <para> The <filename>HPLeftHandISCSIDriver</filename> driver is based on the Block Storage Service (Cinder) plug-in architecture. Volume operations are run by communicating with the HP LeftHand/StoreVirtual system over HTTPS, or SSH connections. The HTTPS communications use the <package>hplefthandclient</package>, which is part of the Python standard library. </para> <para> The <filename>HPLeftHandISCSIDriver</filename> driver can be configured to run in one of two possible modes, legacy mode which uses SSH/CLIQ to communicate with the HP LeftHand/StoreVirtual array, or standard mode which uses a new REST client to communicate with the array. No new functionality has been, or will be supported in legacy mode. To utilize performance improvements and new functionality, the driver must be configured for standard mode, the <package>hplefthandclient</package> must be downloaded, and Operating System software version 11.5 or higher is required on the HPLeftHand/StoreVirtual array. To configure the driver in standard mode see section <link xlink:href=""hp-lefthand-rest-driver""> HP LeftHand/StoreVirtual REST driver standard mode</link>, to configure the driver in legacy mode, see section <link xlink:href=""hp-lefthand-clix-driver""> HP LeftHand/StoreVirtual CLIQ driver legacy mode</link>. </para> <para>For information about how to manage HP LeftHand/StoreVirtual storage systems, see the HP LeftHand/StoreVirtual user documentation. </para> <section xml:id=""hp-lefthand-rest-driver""> <title>HP LeftHand/StoreVirtual REST driver standard mode</title> <para>This section describes how to configure the HP LeftHand/StoreVirtual Cinder driver in standard mode, and it's functionality. </para> <section xml:id=""hp-lefthand-sys-reqs""> <title>System requirements</title> <para>To use the HP LeftHand/StoreVirtual driver in standard mode, do the following: </para> <itemizedlist> <listitem> <para>Install LeftHand/StoreVirtual Operating System software version 11.5 or higher on the HP LeftHand/StoreVirtual storage system. </para> </listitem> <listitem> <para>Create a cluster group.</para> </listitem> <listitem> <para> Install the <package>hplefthandclient</package> version 1.0.2 from the Python standard library on the system with the enabled Block Storage Service volume drivers. </para> </listitem> </itemizedlist> </section> <section xml:id=""hp-lefthand-supported-ops-rest""> <title>Supported operations</title> <itemizedlist> <listitem> <para>Create volumes.</para> </listitem> <listitem> <para>Delete volumes.</para> </listitem> <listitem> <para>Extend volumes.</para> </listitem> <listitem> <para>Attach volumes.</para> </listitem> <listitem> <para>Detach volumes.</para> </listitem> <listitem> <para>Create snapshots.</para> </listitem> <listitem> <para>Delete snapshots.</para> </listitem> <listitem> <para>Create volumes from snapshots.</para> </listitem> <listitem> <para>Create cloned volumes.</para> </listitem> <listitem> <para>Copy images to volumes.</para> </listitem> <listitem> <para>Copy volumes to images.</para> </listitem> <listitem> <para>Backend assisted volume migrate.</para> <para>When a volume is migrated between clusters in the same HP LeftHand/StoreVirtual management group, the array will use native LeftHand APIs to migrate the volume. The volume cannot be attached or have snapshots to migrate. </para> </listitem> <listitem> <para>Volume retype.</para> </listitem> </itemizedlist> <para> Volume type support for the driver includes the ability to set the following capabilities in the OpenStack Cinder API <filename>cinder.api.contrib.types_extra_specs</filename> volume type extra specs extension module. </para> <itemizedlist> <listitem> <para> <literal>hplh:provisioning</literal> </para> </listitem> <listitem> <para> <literal>hplh:ao</literal> </para> </listitem> <listitem> <para> <literal>hplh:data_pl</literal> </para> </listitem> </itemizedlist> <para> To work with the default filter scheduler, the key values are case sensitive and scoped with <literal>'hplh:'</literal>. For information about how to set the key-value pairs and associate them with a volume type, run the following command: <screen> <prompt>$</prompt><userinput>cinder help type-key</userinput> </screen> </para> <para>The following keys require that the HP LeftHand/StoreVirtual storage array be configured for; </para> <itemizedlist> <listitem> <para> <literal>hplh:ao</literal> - The HP LeftHand/StoreVirtual storage array must be configured for Adaptive Optimization. </para> </listitem> <listitem> <para> <literal>hplh:data_pl</literal> - The HP LeftHand/StoreVirtual storage array must be able to support the Data Protection level specified by the extra spec. </para> </listitem> </itemizedlist> <para>If volume types are not used or a particular key is not set for a volume type, the following defaults are used. </para> <itemizedlist> <listitem> <para> <literal>hplh:provisioning</literal> -Defaults to thin provisioning, the valid values are, <literal>thin</literal> and <literal>full</literal> </para> </listitem> <listitem> <para> <literal>hplh:ao</literal> - Defaults to true, the valid values are <literal>true</literal> and <literal>false.</literal> </para> </listitem> <listitem> <para> <literal>hplh:data_pl</literal> - Defaults to <literal>r-0</literal>, Network RAID-0 (None), the valid values are: </para> <para> <literal>r-0</literal>, Network RAID-0 (None) </para> <para> <literal>r-5</literal>, Network RAID-5 (Single Parity) </para> <para> <literal>r-10-2</literal>, Network RAID-10 (2-Way Mirror) </para> <para> <literal>r-10-3</literal>, Network RAID-10 (3-Way Mirror) </para> <para> <literal>r-10-4</literal>, Network RAID-10 (4-Way Mirror) </para> <para> <literal>r-6</literal>, Network RAID-6 (Dual Parity), </para> </listitem> </itemizedlist> </section> <section xml:id=""enable-hp-lefthand""> <title>Enable the HP LeftHand/StoreVirtual iSCSI driver in standard mode </title> <para> The <filename>HPLeftHandISCSIDriver</filename> is installed with the OpenStack software. </para> <procedure> <step> <para> Install the <filename>hplefthandclient</filename> Python package on the OpenStack Block Storage system. <screen>$sudo pip install 'hplefthandclient &gt;=1.0.2,&lt;2.0'</screen> </para> </step> <step> <para>If you are not using an existing cluster, create a cluster on the HP LeftHand storage system to be used as the cluster for creating volumes. </para> </step> <step> <para> Make the following changes in the <filename>/etc/cinder/cinder.conf</filename> file. </para> <programlisting> <emphasis role=""bold"">## REQUIRED SETTINGS</emphasis> # LeftHand WS API Server URL hplefthand_api_url=https://10.10.0.141:8081/lhos # LeftHand Super user username hplefthand_username=lhuser # LeftHand Super user password hplefthand_password=lhpass # LeftHand cluster to use for volume creation hplefthand_clustername=ClusterLefthand # LeftHand iSCSI driver volume_driver=cinder.volume.drivers.san.hp.hp_lefthand_iscsi.HPLeftHandISCSIDriver <emphasis role=""bold"">## OPTIONAL SETTINGS</emphasis> # Should CHAPS authentication be used (default=false) hplefthand_iscsi_chap_enabled=false # Enable HTTP debugging to LeftHand (default=false) hplefthand_debug=false </programlisting> <para> If the <literal>hplefthand_iscsi_chap_enabled</literal> is set to <literal>true</literal>, the driver will associate randomly-generated CHAP secrets with all hosts on the HP LeftHand/StoreVirtual system. OpenStack compute nodes use these secrets when creating iSCSI connections. <note> <para>CHAP secrets are added to existing hosts as well as newly-created ones. If the CHAP option is enabled, hosts will not be able to access the storage without the generated secrets. </para> </note> <note> <para>CHAP secrets are passed from OpenStack Block Storage to Compute in clear text. This communication should be secured to ensure that CHAP secrets are not discovered. </para> </note> </para> <note> <para>You can enable only one driver on each cinder instance unless you enable multiple back-end support. See the Cinder multiple back-end support instructions to enable this feature. </para> </note> </step> <step> <para> Save the changes to the <filename>cinder.conf</filename> file and restart the <systemitem class=""service"">cinder-volume</systemitem> service. </para> </step> </procedure> <para>The HP LeftHand/StoreVirtual driver is now enabled in standard mode on your OpenStack system. If you experience problems, review the Block Storage Service log files for errors. </para> </section> </section> <section xml:id=""hp-lefthand-clix-driver""> <title>HP LeftHand/StoreVirtual CLIQ driver legacy mode</title> <para>This section describes how to configure the HP LeftHand/StoreVirtual Cinder driver in legacy mode, and its functionality. </para> <para>The <filename>HPLeftHandISCSIDriver</filename> enables you to use a HP Lefthand/StoreVirtual SAN that supports the CLIQ interface. Every supported volume operation translates into a CLIQ call in the back-end. </para> <section xml:id=""hp-lefthand-supported-ops-cliq""> <title>Supported operations</title> <itemizedlist> <listitem> <para>Create volumes.</para> </listitem> <listitem> <para>Delete volumes.</para> </listitem> <listitem> <para>Extend volumes.</para> </listitem> <listitem> <para>Attach volumes.</para> </listitem> <listitem> <para>Detach volumes.</para> </listitem> <listitem> <para>Create snapshots.</para> </listitem> <listitem> <para>Delete snapshots.</para> </listitem> <listitem> <para>Create volumes from snapshots.</para> </listitem> <listitem> <para>Copy images to volumes.</para> </listitem> <listitem> <para>Copy volumes to images.</para> </listitem> </itemizedlist> </section> <section xml:id=""enable-hp-lefthand-cliq""> <title>Enable the HP LeftHand/StoreVirtual iSCSI driver in legacy mode </title> <para> The <filename>HPLeftHandISCSIDriver</filename> is installed with the OpenStack software. </para> <procedure> <step> <para>If you are not using an existing cluster, create a cluster on the HP Lefthand storage system to be used as the cluster for creating volumes. </para> </step> <step> <para> Make the following changes in the <filename>/etc/cinder/cinder.conf</filename> file. </para> <programlisting> <emphasis role=""bold"">## REQUIRED SETTINGS</emphasis> # VIP of your Virtual Storage Appliance (VSA). san_ip=10.10.0.141 # LeftHand Super user username san_login=lhuser # LeftHand Super user password san_password=lhpass # LeftHand ssh port, the default for the VSA is usually 16022. san_ssh_port=16022 # LeftHand cluster to use for volume creation san_clustername=ClusterLefthand # LeftHand iSCSI driver volume_driver=cinder.volume.drivers.san.hp.hp_lefthand_iscsi.HPLeftHandISCSIDriver <emphasis role=""bold"">## OPTIONAL SETTINGS</emphasis> # LeftHand provisioning, to disable thin provisioning, set to # set to False. san_thin_provision=True # Typically, this parameter is set to False, for this driver. # To configure the CLIQ commands to run locally instead of over ssh, # set this parameter to True san_is_local=False </programlisting> </step> <step> <para> Save the changes to the <filename>cinder.conf</filename> file and restart the <systemitem class=""service"">cinder-volume</systemitem> service. </para> </step> </procedure> <para>The HP LeftHand/StoreVirtual driver is now enabled in legacy mode on your OpenStack system. If you experience problems, review the Block Storage Service log files for errors. </para> <para>To configure the VSA</para> <procedure> <step> <para> Configure Chap on each of the <systemitem class=""service"">nova-compute</systemitem> nodes. </para> </step> <step> <para> Add Server associations on the VSA with the associated Chap and initiator information. The name should correspond to the <emphasis role=""italic"">'hostname'</emphasis> of the <systemitem class=""service"">nova-compute</systemitem> node. For Xen, this is the hypervisor host name. To do this, use either CLIQ or the Centralized Management Console. </para> </step> </procedure> </section> </section> </section>","<section xml:id=""HPSan-driver"" xmlns=""http://docbook.org/ns/docbook"" xmlns:xi=""http://www.w3.org/2001/XInclude"" xmlns:xlink=""http://www.w3.org/1999/xlink"" version=""5.0""> <title>HP / LeftHand SAN</title> <para>HP/LeftHand SANs are optimized for virtualized environments with VMware ESX &amp; Microsoft Hyper-V, though the OpenStack integration provides additional support to various other virtualized environments, such as Xen, KVM, and OpenVZ, by exposing the volumes through ISCSI to connect to the instances.</para> <para>The HpSanISCSIDriver enables you to use a HP/Lefthand SAN that supports the Cliq interface. Every supported volume operation translates into a cliq call in the back-end.</para> <para>To use Cinder with HP/Lefthand SAN, you must set the following parameters in the <filename>cinder.conf</filename> file:</para> <itemizedlist> <listitem> <para>Set <parameter>volume_driver=cinder.volume.drivers.san.HpSanISCSIDriver</parameter>.</para> </listitem> <listitem> <para>Set <parameter>san_ip</parameter> flag to the hostname or VIP of your Virtual Storage Appliance (VSA).</para> </listitem> <listitem> <para>Set <parameter>san_login</parameter> and <parameter>san_password</parameter> to the user name and password of the ssh user with all necessary privileges on the appliance.</para> </listitem> <listitem> <para>Set <code>san_ssh_port=16022</code>. The default is 22. However, the default for the VSA is usually 16022.</para> </listitem> <listitem> <para>Set <code>san_clustername</code> to the name of the cluster where the associated volumes are created.</para> </listitem> </itemizedlist> <para>The following optional parameters have the following default values:</para> <itemizedlist> <listitem> <para><code>san_thin_provision=True</code>. To disable thin provisioning, set to <literal>False</literal>. </para> </listitem> <listitem> <para><code>san_is_local=False</code>. Typically, this parameter is set to <literal>False</literal> for this driver. To configure the cliq commands to run locally instead of over ssh, set this parameter to <literal>True</literal>.</para> </listitem> </itemizedlist> <para>In addition to configuring the <systemitem class=""service"" >cinder-volume</systemitem> service, you must configure the VSA to function in an OpenStack environment.</para> <procedure> <title>To configure the VSA</title> <step> <para>Configure Chap on each of the <systemitem class=""service"">nova-compute</systemitem> nodes.</para> </step> <step> <para>Add Server associations on the VSA with the associated Chap and initiator information. The name should correspond to the <emphasis role=""italic"" >'hostname'</emphasis> of the <systemitem class=""service"">nova-compute</systemitem> node. For Xen, this is the hypervisor host name. To do this, use either Cliq or the Centralized Management Console.</para> </step> </procedure> </section> ",467,81
openstack%2Fopenstack-manuals~master~I256fd47cde1d0fd42416914b933152b8d77471bc,openstack/openstack-manuals,master,I256fd47cde1d0fd42416914b933152b8d77471bc,fixes for getting started lab,MERGED,2014-02-25 22:08:56.000000000,2014-03-07 05:37:01.000000000,2014-03-07 05:37:00.000000000,"[{'_account_id': 3}, {'_account_id': 612}, {'_account_id': 964}, {'_account_id': 2448}, {'_account_id': 6547}, {'_account_id': 6676}, {'_account_id': 6923}, {'_account_id': 9382}, {'_account_id': 10281}]","[{'number': 1, 'created': '2014-02-25 22:08:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/536be887249eb698c0dca4fc8e4e4f5997ef4416', 'message': 'fix for bug 1284783\n\nasking user to be in the directory with a pom.xml file\n\nChange-Id: I256fd47cde1d0fd42416914b933152b8d77471bc\n'}, {'number': 2, 'created': '2014-02-25 22:16:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/4d75c919b0ea8a3d76a2b9190e4330851c1120ad', 'message': 'fix for bug 1284783\n\nasking user to be in the directory with a pom.xml file\n\nChange-Id: I256fd47cde1d0fd42416914b933152b8d77471bc\n'}, {'number': 3, 'created': '2014-02-27 19:53:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/2ae044e7681eb4d6dea893de718a16c818607e1e', 'message': 'fixes for getting started lab\n\nasking user to be in the directory with a pom.xml file\nadded instructions on how to run tox after maven\n\nChange-Id: I256fd47cde1d0fd42416914b933152b8d77471bc\n'}, {'number': 4, 'created': '2014-02-28 19:18:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/1a10bcb3de6fdb8a963d553711f48f02d6647676', 'message': 'fixes for getting started lab\n\nasking user to be in the directory with a pom.xml file\nadded instructions on how to run tox after maven\n\nChange-Id: I256fd47cde1d0fd42416914b933152b8d77471bc\n'}, {'number': 5, 'created': '2014-03-04 20:45:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/2b97328bdd0cfdc413e81cbdf7b1aa577e0e542c', 'message': 'fixes for getting started lab\n\nasking user to be in the directory with a pom.xml file\nadded instructions on how to run tox after maven\n\nChange-Id: I256fd47cde1d0fd42416914b933152b8d77471bc\n'}, {'number': 6, 'created': '2014-03-05 17:42:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/1d2e7219f062ba98abeb0b9c939a0351e53a25da', 'message': 'fixes for getting started lab\n\nasking user to be in the directory with a pom.xml file\nadded instructions on how to run tox after maven\n\nChange-Id: I256fd47cde1d0fd42416914b933152b8d77471bc\n'}, {'number': 7, 'created': '2014-03-05 19:52:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/eb1e40cbed6eb238b0072ee4e4fa0e55b70cce77', 'message': 'fixes for getting started lab\n\nasking user to be in the directory with a pom.xml file\nadded instructions on how to run tox after maven\n\nChange-Id: I256fd47cde1d0fd42416914b933152b8d77471bc\n'}, {'number': 8, 'created': '2014-03-06 20:48:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/afbd3bc789e22fa65612943cef9c05001c3dd55b', 'message': 'fixes for getting started lab\n\nasking user to be in the directory with a pom.xml file\nadded instructions on how to run tox after maven\n\nChange-Id: I256fd47cde1d0fd42416914b933152b8d77471bc\n'}, {'number': 9, 'created': '2014-03-06 20:59:06.000000000', 'files': ['doc/training-guides/operator-editing-code.xml'], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/db24ee45fe0ff440eb42e2364436c4bab40a6b24', 'message': 'fixes for getting started lab\n\nasking user to be in the directory with a pom.xml file\nadded instructions on how to run tox after maven\n\nChange-Id: I256fd47cde1d0fd42416914b933152b8d77471bc\n'}]",34,76377,db24ee45fe0ff440eb42e2364436c4bab40a6b24,51,9,9,10281,,,0,"fixes for getting started lab

asking user to be in the directory with a pom.xml file
added instructions on how to run tox after maven

Change-Id: I256fd47cde1d0fd42416914b933152b8d77471bc
",git fetch https://review.opendev.org/openstack/openstack-manuals refs/changes/77/76377/9 && git format-patch -1 --stdout FETCH_HEAD,['doc/training-guides/operator-editing-code.xml'],1,536be887249eb698c0dca4fc8e4e4f5997ef4416,bug/1284783," can be built without errors by running mvn command. To build a specific guide, look for a pom.xml file within a subdirectory, switch to that directory, then run the mvn command in that directory</para>", can be built without errors by running</para>,3,1
openstack%2Fopenstack-manuals~master~Iee2704004fee22bcf11389eba78124d90e9cae42,openstack/openstack-manuals,master,Iee2704004fee22bcf11389eba78124d90e9cae42,Remove unused graphics,MERGED,2014-03-06 19:35:02.000000000,2014-03-07 05:36:54.000000000,2014-03-07 05:36:53.000000000,"[{'_account_id': 3}, {'_account_id': 612}, {'_account_id': 964}]","[{'number': 1, 'created': '2014-03-06 19:35:02.000000000', 'files': ['doc/install-guide/figures/NOVA_compute_nodes.svg', 'doc/common/figures/NOVA_compute_nodes.svg', 'doc/common/figures/NOVA_compute_nodes.png', 'doc/install-guide/figures/NOVA_compute_nodes.png'], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/bb38bafd0cf78ceaac99c25ac674c1d372a6498d', 'message': 'Remove unused graphics\n\nChange-Id: Iee2704004fee22bcf11389eba78124d90e9cae42\n'}]",0,78728,bb38bafd0cf78ceaac99c25ac674c1d372a6498d,7,3,1,6547,,,0,"Remove unused graphics

Change-Id: Iee2704004fee22bcf11389eba78124d90e9cae42
",git fetch https://review.opendev.org/openstack/openstack-manuals refs/changes/28/78728/1 && git format-patch -1 --stdout FETCH_HEAD,"['doc/install-guide/figures/NOVA_compute_nodes.svg', 'doc/common/figures/NOVA_compute_nodes.svg', 'doc/common/figures/NOVA_compute_nodes.png', 'doc/install-guide/figures/NOVA_compute_nodes.png']",4,bb38bafd0cf78ceaac99c25ac674c1d372a6498d,delete-unused-graphs,,,0,23162
openstack%2Fcinder~master~I4002ef9ea14e2d843dd8cbccffa025997a54c738,openstack/cinder,master,I4002ef9ea14e2d843dd8cbccffa025997a54c738,Clean Up EMC VNX Direct Driver in Cinder,MERGED,2014-03-06 21:51:39.000000000,2014-03-07 05:24:24.000000000,2014-03-07 05:24:22.000000000,"[{'_account_id': 3}, {'_account_id': 2243}, {'_account_id': 6491}]","[{'number': 1, 'created': '2014-03-06 21:51:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/b1eb3a2e5bbb865c59a1a9750fe7c467704c6509', 'message': 'Add EMC VNX Direct Driver in Cinder\n\nThis patch implements a driver based on the Cinder iSCSIDrver.\nIt performs volume operations on VNX using the NaviSecCLI command\nline tool.  It supports all required driver features.\n\nImplements blueprint emc-vnx-direct-driver\n\nChange-Id: I4002ef9ea14e2d843dd8cbccffa025997a54c738\n'}, {'number': 2, 'created': '2014-03-06 22:10:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/3ce61e6b1bfacb5826e1eea3cfa9b788de98e1c7', 'message': 'Add EMC VNX Direct Driver in Cinder\n\nThis patch implements a driver based on the Cinder iSCSIDrver.\nIt performs volume operations on VNX using the NaviSecCLI command\nline tool.  It supports all required driver features.\n\nImplements blueprint emc-vnx-direct-driver\n\nChange-Id: I4002ef9ea14e2d843dd8cbccffa025997a54c738\n'}, {'number': 3, 'created': '2014-03-06 22:37:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/0ced0ef368eb1c0f313173cc27e1a5eeea7a073e', 'message': 'Clean Up EMC VNX Direct Driver in Cinder\n\nThis patch cleans up issues discovered during the review of\nEMC VNX Direct Driver.\n\nhttps://review.openstack.org/#/c/73672/\n\nImplements blueprint emc-vnx-direct-driver\nCloses-Bug: #1287944\n\nChange-Id: I4002ef9ea14e2d843dd8cbccffa025997a54c738\n'}, {'number': 4, 'created': '2014-03-07 00:23:22.000000000', 'files': ['cinder/tests/test_emc_vnxdirect.py', 'cinder/volume/drivers/emc/emc_cli_iscsi.py', 'cinder/volume/drivers/emc/emc_vnx_cli.py'], 'web_link': 'https://opendev.org/openstack/cinder/commit/48955e56b886c0da51c1555aca62e099761ad99b', 'message': 'Clean Up EMC VNX Direct Driver in Cinder\n\nThis patch cleans up issues discovered during the review of\nEMC VNX Direct Driver.\n\nhttps://review.openstack.org/#/c/73672/\n\nImplements blueprint emc-vnx-direct-driver\nCloses-Bug: #1287944\n\nChange-Id: I4002ef9ea14e2d843dd8cbccffa025997a54c738\n'}]",0,78782,48955e56b886c0da51c1555aca62e099761ad99b,16,3,4,6491,,,0,"Clean Up EMC VNX Direct Driver in Cinder

This patch cleans up issues discovered during the review of
EMC VNX Direct Driver.

https://review.openstack.org/#/c/73672/

Implements blueprint emc-vnx-direct-driver
Closes-Bug: #1287944

Change-Id: I4002ef9ea14e2d843dd8cbccffa025997a54c738
",git fetch https://review.opendev.org/openstack/cinder refs/changes/82/78782/3 && git format-patch -1 --stdout FETCH_HEAD,"['cinder/tests/test_emc_vnxdirect.py', 'cinder/volume/drivers/emc/emc_cli_iscsi.py', 'cinder/volume/drivers/emc/emc_vnx_cli.py']",3,b1eb3a2e5bbb865c59a1a9750fe7c467704c6509,bp/emc-vnx-direct-driver,"class EMCVnxCli(object): if ""check_exit_code"" not in kwargv: def _wait_for_lun_ready(volumename, start_time): if int(time.time()) - start_time > self.timeout * 60: _wait_for_lun_ready, volumename, int(time.time())) def _wait_for_snap_delete(snapshot, start_time): if int(time.time()) - start_time < \ _wait_for_snap_delete, snapshot, int(time.time())) def _wait_for_sync_status(volumename, start_time): LOG.info(_('Waiting for the update on Sync status of %s'), if int(time.time()) - start_time >= self.timeout * 60: msg = (_('Failed to really migrate %s'), volumename) LOG.error(msg) raise exception.VolumeBackendAPIException(data=msg) _wait_for_sync_status, volumename, int(time.time()))","class EMCVnxCli(): if ""check_exit_code"" not in kwargv.keys(): def _wait_for_lun_ready(volumename): if int(time.time()) - self.start_lun_ready > self.timeout * 60: self.start_lun_ready = int(time.time()) _wait_for_lun_ready, volumename) def _wait_for_snap_delete(snapshot): if int(time.time()) - self.start_snap_delete < \ self.start_snap_delete = int(time.time()) _wait_for_snap_delete, snapshot) self.sync_status = False def _wait_for_sync_status(volumename): self.sync_status = True LOG.info(_('Waiting for the update on Sync status of %s '), if int(time.time()) - self.start_status >= self.timeout * 60: raise loopingcall.LoopingCallDone() self.start_status = int(time.time()) _wait_for_sync_status, volumename) if not self.sync_status: msg = (_('Failed to really migrate %s'), volumename) LOG.error(msg) raise exception.VolumeBackendAPIException(data=msg) ",25,31
openstack%2Fnova~master~I25d03739afc1f3d74d2830e08ccb418e8cfd664e,openstack/nova,master,I25d03739afc1f3d74d2830e08ccb418e8cfd664e,Store neutron port status in VIF model,MERGED,2014-03-06 21:38:23.000000000,2014-03-07 05:23:28.000000000,2014-03-07 05:23:24.000000000,"[{'_account_id': 3}, {'_account_id': 1849}, {'_account_id': 4393}, {'_account_id': 4395}, {'_account_id': 5170}, {'_account_id': 9008}, {'_account_id': 9578}]","[{'number': 1, 'created': '2014-03-06 21:38:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/9c100e506605abf8e0bf44f41d96268e5e1f021c', 'message': ""Store neutron port status in VIF model\n\nThis patch adds a field into the VIF model called status\nwhich is True if a port in neutron has a status of 'ACTIVE' or\nif a port is marked as admin_state_up=Fase (as the user has marked\nthe port to be down). Otherwise this value will be false. This is\nneeded for the admin-event-callback-api work. This allows nova-compute to\ncheck the vif status to determine if it needs to wait on a vif-plugged\nevent before starting a instance.\n\nRelated to blueprint admin-event-callback-api\nChange-Id: I25d03739afc1f3d74d2830e08ccb418e8cfd664e\n""}, {'number': 2, 'created': '2014-03-07 01:00:55.000000000', 'files': ['nova/tests/network/test_neutronv2.py', 'nova/network/neutronv2/api.py', 'nova/tests/network/test_network_info.py', 'nova/network/model.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/12e18219c149b6c7eef79c042b35be7aef7c3cb5', 'message': ""Store neutron port status in VIF model\n\nThis patch adds a field into the VIF model called status\nwhich is True if a port in neutron has a status of 'ACTIVE' or\nif a port is marked as admin_state_up=Fase (as the user has marked\nthe port to be down). Otherwise this value will be false. This is\nneeded for the admin-event-callback-api work. This allows nova-compute to\ncheck the vif status to determine if it needs to wait on a vif-plugged\nevent before starting a instance.\n\nRelated to blueprint admin-event-callback-api\nChange-Id: I25d03739afc1f3d74d2830e08ccb418e8cfd664e\n""}]",2,78777,12e18219c149b6c7eef79c042b35be7aef7c3cb5,19,7,2,4395,,,0,"Store neutron port status in VIF model

This patch adds a field into the VIF model called status
which is True if a port in neutron has a status of 'ACTIVE' or
if a port is marked as admin_state_up=Fase (as the user has marked
the port to be down). Otherwise this value will be false. This is
needed for the admin-event-callback-api work. This allows nova-compute to
check the vif status to determine if it needs to wait on a vif-plugged
event before starting a instance.

Related to blueprint admin-event-callback-api
Change-Id: I25d03739afc1f3d74d2830e08ccb418e8cfd664e
",git fetch https://review.opendev.org/openstack/nova refs/changes/77/78777/2 && git format-patch -1 --stdout FETCH_HEAD,"['nova/tests/network/test_neutronv2.py', 'nova/network/neutronv2/api.py', 'nova/tests/network/test_network_info.py', 'nova/network/model.py']",4,9c100e506605abf8e0bf44f41d96268e5e1f021c,bp/admin-event-callback-api," qbh_params=None, qbg_params=None, active=False, self['active'] = active 'ovs_interfaceid', 'qbh_params', 'qbg_params', 'active']"," qbh_params=None, qbg_params=None, 'ovs_interfaceid', 'qbh_params', 'qbg_params']",80,20
openstack%2Fnova~master~I6d144aecf95725146aa0fc4f4fe5a3f16c434d14,openstack/nova,master,I6d144aecf95725146aa0fc4f4fe5a3f16c434d14,Correct network_model tests and __eq__ operator,MERGED,2013-12-13 23:22:59.000000000,2014-03-07 05:22:16.000000000,2014-03-07 05:22:13.000000000,"[{'_account_id': 3}, {'_account_id': 67}, {'_account_id': 1501}, {'_account_id': 1653}, {'_account_id': 1849}, {'_account_id': 2592}, {'_account_id': 4393}, {'_account_id': 4395}, {'_account_id': 5170}, {'_account_id': 6873}, {'_account_id': 9008}, {'_account_id': 9578}]","[{'number': 1, 'created': '2013-12-13 23:22:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/332a28ef7908b8e114340d380078a4636be1a1f2', 'message': 'Correct network_model tests and __eq__ operator\n\nThe current network_model tests mix IP() with FixedIP()\nin several places. This patch corrects this issue. This was discovered\nwhile adding logic to determine if the network_cache needs to be updated.\nWhile updating the __eq__ operator to check all of the objects fields\nrather than just id there tests started failing.\n\nCloses-bug: # 1260891\nRelated to blueprint: smarter-network-cache-update\n\nChange-Id: I6d144aecf95725146aa0fc4f4fe5a3f16c434d14\n'}, {'number': 2, 'created': '2013-12-14 03:40:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/898e763a4174341df7600e6917c8261737f6840f', 'message': 'Correct network_model tests and __eq__ operator\n\nThe current network_model tests mix IP() with FixedIP()\nin several places. This patch corrects this issue. This was discovered\nwhile adding logic to determine if the network_cache needs to be updated.\nWhile updating the __eq__ operator to check all of the objects fields\nrather than just id there tests started failing.\n\nCloses-bug: # 1260891\nRelated to blueprint: smarter-network-cache-update\n\nChange-Id: I6d144aecf95725146aa0fc4f4fe5a3f16c434d14\n'}, {'number': 3, 'created': '2014-01-07 00:17:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/7f91b316e4b32ee06cb9ffd023afac9c87b68469', 'message': 'Correct network_model tests and __eq__ operator\n\nThe current network_model tests mix IP() with FixedIP()\nin several places. This patch corrects this issue. This was discovered\nwhile adding logic to determine if the network_cache needs to be updated.\nWhile updating the __eq__ operator to check all of the objects fields\nrather than just id there tests started failing.\n\nCloses-bug: # 1260891\nRelated to blueprint: smarter-network-cache-update\n\nChange-Id: I6d144aecf95725146aa0fc4f4fe5a3f16c434d14\n'}, {'number': 4, 'created': '2014-01-07 21:42:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/6f1fabc7e3da5aa0bf636ab6358e088c2c7c1b9f', 'message': 'Correct network_model tests and __eq__ operator\n\nThe current network_model tests mix IP() with FixedIP()\nin several places. This patch corrects this issue. This was discovered\nwhile adding logic to determine if the network_cache needs to be updated.\nWhile updating the __eq__ operator to check all of the objects fields\nrather than just id there tests started failing.\n\nCloses-bug: # 1260891\nRelated to blueprint: smarter-network-cache-update\n\nChange-Id: I6d144aecf95725146aa0fc4f4fe5a3f16c434d14\n'}, {'number': 5, 'created': '2014-01-13 21:30:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/540d82abdf71d59c1b51b855f36ccdef2f14bc9a', 'message': 'Correct network_model tests and __eq__ operator\n\nThe current network_model tests mix IP() with FixedIP()\nin several places. This patch corrects this issue. This was discovered\nwhile adding logic to determine if the network_cache needs to be updated.\nWhile updating the __eq__ operator to check all of the objects fields\nrather than just id there tests started failing.\n\nCloses-bug: # 1260891\nRelated to blueprint: smarter-network-cache-update\n\nChange-Id: I6d144aecf95725146aa0fc4f4fe5a3f16c434d14\n'}, {'number': 6, 'created': '2014-01-21 05:10:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/74ebef3a61b636fd357db4f526d654b1ec518494', 'message': 'Correct network_model tests and __eq__ operator\n\nThe current network_model tests mix IP() with FixedIP()\nin several places. This patch corrects this issue. This was discovered\nwhile adding logic to determine if the network_cache needs to be updated.\nWhile updating the __eq__ operator to check all of the objects fields\nrather than just id there tests started failing.\n\nCloses-bug: # 1260891\nRelated to blueprint: smarter-network-cache-update\n\nChange-Id: I6d144aecf95725146aa0fc4f4fe5a3f16c434d14\n'}, {'number': 7, 'created': '2014-01-21 15:06:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/bae460edb2cdd801ab575d9da03874d8370d3113', 'message': 'Correct network_model tests and __eq__ operator\n\nThe current network_model tests mix IP() with FixedIP()\nin several places. This patch corrects this issue. This was discovered\nwhile adding logic to determine if the network_cache needs to be updated.\nWhile updating the __eq__ operator to check all of the objects fields\nrather than just id there tests started failing.\n\nCloses-bug: # 1260891\nRelated to blueprint: smarter-network-cache-update\n\nChange-Id: I6d144aecf95725146aa0fc4f4fe5a3f16c434d14\n'}, {'number': 8, 'created': '2014-02-03 13:12:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/f11b57a14f2ca26fc8c24ba97a35dc762b72b610', 'message': 'Correct network_model tests and __eq__ operator\n\nThe current network_model tests mix IP() with FixedIP()\nin several places. This patch corrects this issue. This was discovered\nwhile adding logic to determine if the network_cache needs to be updated.\nWhile updating the __eq__ operator to check all of the objects fields\nrather than just id their tests started failing.\n\nCloses-bug: #1260891\nRelated to blueprint: smarter-network-cache-update\n\nChange-Id: I6d144aecf95725146aa0fc4f4fe5a3f16c434d14\n'}, {'number': 9, 'created': '2014-02-03 13:12:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/d29c29ad38fe092fea148e4284018ef4d969aa03', 'message': 'Correct network_model tests and __eq__ operator\n\nThe current network_model tests mix IP() with FixedIP()\nin several places. This patch corrects this issue. This was discovered\nwhile adding logic to determine if the network_cache needs to be updated.\nWhile updating the __eq__ operator to check all of the objects fields\nrather than just id their tests started failing.\n\nCloses-bug: #1260891\nRelated to blueprint: smarter-network-cache-update\n\nChange-Id: I6d144aecf95725146aa0fc4f4fe5a3f16c434d14\n'}, {'number': 10, 'created': '2014-02-11 23:19:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/385f0b2579259074440a38b8d190a47004bae410', 'message': 'Correct network_model tests and __eq__ operator\n\nThe current network_model tests mix IP() with FixedIP()\nin several places. This patch corrects this issue. This was discovered\nwhile adding logic to determine if the network_cache needs to be updated.\nWhile updating the __eq__ operator to check all of the objects fields\nrather than just id there tests started failing.\n\nCloses-bug: # 1260891\nRelated to blueprint: smarter-network-cache-update\n\nChange-Id: I6d144aecf95725146aa0fc4f4fe5a3f16c434d14\n'}, {'number': 11, 'created': '2014-02-13 20:06:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/fef3eee942cdec612948ebf706921eaef3b20836', 'message': 'Correct network_model tests and __eq__ operator\n\nThe current network_model tests mix IP() with FixedIP()\nin several places. This patch corrects this issue. This was discovered\nwhile adding logic to determine if the network_cache needs to be updated.\nWhile updating the __eq__ operator to check all of the objects fields\nrather than just id there tests started failing.\n\nCloses-bug: # 1260891\nRelated to blueprint: smarter-network-cache-update\n\nChange-Id: I6d144aecf95725146aa0fc4f4fe5a3f16c434d14\n'}, {'number': 12, 'created': '2014-02-14 23:24:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/d8e73df63236d40d07ff18df71c2fd57fb72cbe6', 'message': 'Correct network_model tests and __eq__ operator\n\nThe current network_model tests mix IP() with FixedIP()\nin several places. This patch corrects this issue. This was discovered\nwhile adding logic to determine if the network_cache needs to be updated.\nWhile updating the __eq__ operator to check all of the objects fields\nrather than just id there tests started failing.\n\nCloses-bug: # 1260891\nRelated to blueprint: smarter-network-cache-update\n\nChange-Id: I6d144aecf95725146aa0fc4f4fe5a3f16c434d14\n'}, {'number': 13, 'created': '2014-02-28 02:47:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/30f4e786bd93bd03c4bfadc58bd27eac624e4745', 'message': 'Correct network_model tests and __eq__ operator\n\nThe current network_model tests mix IP() with FixedIP()\nin several places. This patch corrects this issue. This was discovered\nwhile adding logic to determine if the network_cache needs to be updated.\nWhile updating the __eq__ operator to check all of the objects fields\nrather than just id there tests started failing.\n\nCloses-bug: # 1260891\nRelated to blueprint: smarter-network-cache-update\n\nChange-Id: I6d144aecf95725146aa0fc4f4fe5a3f16c434d14\n'}, {'number': 14, 'created': '2014-03-06 21:38:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/b9b9019a664385b48f0affe4f18f6dac841d537b', 'message': 'Correct network_model tests and __eq__ operator\n\nThe current network_model tests mix IP() with FixedIP()\nin several places. This patch corrects this issue. This was discovered\nwhile adding logic to determine if the network_cache needs to be updated.\nWhile updating the __eq__ operator to check all of the objects fields\nrather than just id there tests started failing.\n\nCloses-bug: # 1260891\nRelated to blueprint: smarter-network-cache-update\n\nChange-Id: I6d144aecf95725146aa0fc4f4fe5a3f16c434d14\n'}, {'number': 15, 'created': '2014-03-07 01:00:56.000000000', 'files': ['nova/tests/network/test_neutronv2.py', 'nova/tests/fake_network_cache_model.py', 'nova/tests/network/test_network_info.py', 'nova/network/model.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/a86136f8a198933d6099b1dabc007e36c4806e3d', 'message': 'Correct network_model tests and __eq__ operator\n\nThe current network_model tests mix IP() with FixedIP()\nin several places. This patch corrects this issue. This was discovered\nwhile adding logic to determine if the network_cache needs to be updated.\nWhile updating the __eq__ operator to check all of the objects fields\nrather than just id there tests started failing.\n\nCloses-bug: # 1260891\nRelated to blueprint: smarter-network-cache-update\n\nChange-Id: I6d144aecf95725146aa0fc4f4fe5a3f16c434d14\n'}]",17,62104,a86136f8a198933d6099b1dabc007e36c4806e3d,109,12,15,4395,,,0,"Correct network_model tests and __eq__ operator

The current network_model tests mix IP() with FixedIP()
in several places. This patch corrects this issue. This was discovered
while adding logic to determine if the network_cache needs to be updated.
While updating the __eq__ operator to check all of the objects fields
rather than just id there tests started failing.

Closes-bug: # 1260891
Related to blueprint: smarter-network-cache-update

Change-Id: I6d144aecf95725146aa0fc4f4fe5a3f16c434d14
",git fetch https://review.opendev.org/openstack/nova refs/changes/04/62104/10 && git format-patch -1 --stdout FETCH_HEAD,"['nova/tests/network/test_neutronv2.py', 'nova/tests/fake_network_cache_model.py', 'nova/tests/network/test_network_info.py', 'nova/network/model.py']",4,332a28ef7908b8e114340d380078a4636be1a1f2,bp/admin-event-callback-api," keys = ['address', 'type', 'version'] for key in keys: if self[key] != other[key]: return False return True def __eq__(self, other): keys = ['address', 'type', 'version', 'floating_ips'] for key in keys: if self[key] != other[key]: return False return True keys = ['cidr', 'dns', 'gateway', 'ips', 'routes', 'version'] for key in keys: if self[key] != other[key]: return False return True def __eq__(self, other): keys = ['id', 'bridge', 'label', 'subnets'] for key in keys: if self[key] != other[key]: return False return True keys = ['id', 'address', 'network', 'type', 'devname', 'ovs_interfaceid', 'qbh_params', 'qbg_params'] for key in keys: if self[key] != other[key]: return False return True", return self['address'] == other['address'] return self['cidr'] == other['cidr'] return self['id'] == other['id'],67,28
openstack%2Fopenstack-manuals~master~I91733af6fd4e8b1caad55006ac1beab7b0c928bf,openstack/openstack-manuals,master,I91733af6fd4e8b1caad55006ac1beab7b0c928bf,replace a unicode character with a dash,MERGED,2014-03-06 18:42:15.000000000,2014-03-07 05:20:04.000000000,2014-03-07 05:20:04.000000000,"[{'_account_id': 3}, {'_account_id': 612}, {'_account_id': 964}, {'_account_id': 6547}, {'_account_id': 7923}]","[{'number': 1, 'created': '2014-03-06 18:42:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/dff6d3ce0af90d66fb5667d211191f553abf7117', 'message': 'replace a unicode character with a dash\n\nChange-Id: I91733af6fd4e8b1caad55006ac1beab7b0c928bf\n'}, {'number': 2, 'created': '2014-03-06 20:34:50.000000000', 'files': ['doc/common/section_objectstorage-arch.xml', 'doc/install-guide/section_neutron-per-tenant-routers-with-private-networks.xml'], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/169b574661d6b273a7ed3e9be4d5d5928fdd32d3', 'message': 'replace a unicode character with a dash\n\nChange-Id: I91733af6fd4e8b1caad55006ac1beab7b0c928bf\n'}]",3,78703,169b574661d6b273a7ed3e9be4d5d5928fdd32d3,11,5,2,7923,,,0,"replace a unicode character with a dash

Change-Id: I91733af6fd4e8b1caad55006ac1beab7b0c928bf
",git fetch https://review.opendev.org/openstack/openstack-manuals refs/changes/03/78703/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/install-guide/section_neutron-per-tenant-routers-with-private-networks.xml'],1,dff6d3ce0af90d66fb5667d211191f553abf7117,mdash," <para><emphasis role=""bold"">Compute node - Compute </emphasis><procedure>"," <para><emphasis role=""bold"">Compute nodeCompute </emphasis><procedure>",1,1
openstack%2Fnova~master~I961c224d95291727c8614174de07805a0d0a9e46,openstack/nova,master,I961c224d95291727c8614174de07805a0d0a9e46,Make network_cache more robust with neutron,MERGED,2013-12-06 19:20:14.000000000,2014-03-07 05:18:01.000000000,2014-03-07 05:17:58.000000000,"[{'_account_id': 3}, {'_account_id': 67}, {'_account_id': 261}, {'_account_id': 748}, {'_account_id': 1501}, {'_account_id': 1653}, {'_account_id': 1849}, {'_account_id': 2035}, {'_account_id': 2592}, {'_account_id': 4393}, {'_account_id': 4395}, {'_account_id': 5170}, {'_account_id': 5511}, {'_account_id': 6670}, {'_account_id': 6681}, {'_account_id': 6873}, {'_account_id': 7500}, {'_account_id': 7823}, {'_account_id': 7975}, {'_account_id': 9008}, {'_account_id': 9578}]","[{'number': 1, 'created': '2013-12-06 19:20:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/3e5d204c44250ebdb806533d3a71bbaef83248b4', 'message': ""Make network_cache more robust with neutron\n\nCurrently, nova treats neutron as the source of truth for which ports are\nattached to an instance which is a false assumption. Because of this\nif someone creates a port in neutron with a device_id that matches one\nof their existing instance_ids that port will eventually show up in\nnova list (through the periodic heal task).\n\nThis problem usually manifests it's self when nova-compute\ncalls to neutron to create a port and the request timesout (though\nthe port is actually created in neutron). When this occurs the instance\ncan be rescheduled on another compute node which it will call out to\nneutron again to create a port. In this case two ports will show\nup in the network_cache table (since they have the same instance_id) though\nonly one port is attached to the instance.\n\nThis patch addresses this issue by only adding ports to network_cache\nif nova successfully allocated the port (or it was passed in). This\nway these ghost ports are avoided.\n\nCloses-bug: #1258620\nRelated to blueprint nova-api-quantum-create-port\n\nChange-Id: I961c224d95291727c8614174de07805a0d0a9e46\n""}, {'number': 2, 'created': '2013-12-06 20:14:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/7f542f8e466c693400d481f49e1bed2dfab94a19', 'message': ""Make network_cache more robust with neutron\n\nCurrently, nova treats neutron as the source of truth for which ports are\nattached to an instance which is a false assumption. Because of this\nif someone creates a port in neutron with a device_id that matches one\nof their existing instance_ids that port will eventually show up in\nnova list (through the periodic heal task).\n\nThis problem usually manifests it's self when nova-compute\ncalls to neutron to create a port and the request timesout (though\nthe port is actually created in neutron). When this occurs the instance\ncan be rescheduled on another compute node which it will call out to\nneutron again to create a port. In this case two ports will show\nup in the network_cache table (since they have the same instance_id) though\nonly one port is attached to the instance.\n\nThis patch addresses this issue by only adding ports to network_cache\nif nova successfully allocated the port (or it was passed in). This\nway these ghost ports are avoided.\n\nCloses-bug: #1258620\nRelated to blueprint nova-api-quantum-create-port\n\nChange-Id: I961c224d95291727c8614174de07805a0d0a9e46\n""}, {'number': 3, 'created': '2013-12-12 21:13:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/6225b1e7fa9bb782b2c1e0a86bdd86793424c813', 'message': ""Make network_cache more robust with neutron\n\nCurrently, nova treats neutron as the source of truth for which ports are\nattached to an instance which is a false assumption. Because of this\nif someone creates a port in neutron with a device_id that matches one\nof their existing instance_ids that port will eventually show up in\nnova list (through the periodic heal task).\n\nThis problem usually manifests it's self when nova-compute\ncalls to neutron to create a port and the request timesout (though\nthe port is actually created in neutron). When this occurs the instance\ncan be rescheduled on another compute node which it will call out to\nneutron again to create a port. In this case two ports will show\nup in the network_cache table (since they have the same instance_id) though\nonly one port is attached to the instance.\n\nThis patch addresses this issue by only adding ports to network_cache\nif nova successfully allocated the port (or it was passed in). This\nway these ghost ports are avoided.\n\nCloses-bug: #1258620\nRelated to blueprint nova-api-quantum-create-port\n\nChange-Id: I961c224d95291727c8614174de07805a0d0a9e46\n""}, {'number': 4, 'created': '2013-12-13 23:23:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/745eb25dab09a739ad133fa8157e9287ab1c449d', 'message': ""Make network_cache more robust with neutron\n\nCurrently, nova treats neutron as the source of truth for which ports are\nattached to an instance which is a false assumption. Because of this\nif someone creates a port in neutron with a device_id that matches one\nof their existing instance_ids that port will eventually show up in\nnova list (through the periodic heal task).\n\nThis problem usually manifests it's self when nova-compute\ncalls to neutron to create a port and the request timesout (though\nthe port is actually created in neutron). When this occurs the instance\ncan be rescheduled on another compute node which it will call out to\nneutron again to create a port. In this case two ports will show\nup in the network_cache table (since they have the same instance_id) though\nonly one port is attached to the instance.\n\nThis patch addresses this issue by only adding ports to network_cache\nif nova successfully allocated the port (or it was passed in). This\nway these ghost ports are avoided.\n\nCloses-bug: #1258620\nRelated to blueprint nova-api-quantum-create-port\n\nChange-Id: I961c224d95291727c8614174de07805a0d0a9e46\n""}, {'number': 5, 'created': '2013-12-14 03:40:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/29f84e856c032f441822ad948e0591fd541b8bd0', 'message': ""Make network_cache more robust with neutron\n\nCurrently, nova treats neutron as the source of truth for which ports are\nattached to an instance which is a false assumption. Because of this\nif someone creates a port in neutron with a device_id that matches one\nof their existing instance_ids that port will eventually show up in\nnova list (through the periodic heal task).\n\nThis problem usually manifests it's self when nova-compute\ncalls to neutron to create a port and the request timesout (though\nthe port is actually created in neutron). When this occurs the instance\ncan be rescheduled on another compute node which it will call out to\nneutron again to create a port. In this case two ports will show\nup in the network_cache table (since they have the same instance_id) though\nonly one port is attached to the instance.\n\nThis patch addresses this issue by only adding ports to network_cache\nif nova successfully allocated the port (or it was passed in). This\nway these ghost ports are avoided.\n\nCloses-bug: #1258620\nRelated to blueprint nova-api-quantum-create-port\n\nChange-Id: I961c224d95291727c8614174de07805a0d0a9e46\n""}, {'number': 6, 'created': '2014-01-02 21:18:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/143602798c3de8c5b26be91e8941ca94d0b5a218', 'message': ""Make network_cache more robust with neutron\n\nCurrently, nova treats neutron as the source of truth for which ports are\nattached to an instance which is a false assumption. Because of this\nif someone creates a port in neutron with a device_id that matches one\nof their existing instance_ids that port will eventually show up in\nnova list (through the periodic heal task).\n\nThis problem usually manifests it's self when nova-compute\ncalls to neutron to create a port and the request timesout (though\nthe port is actually created in neutron). When this occurs the instance\ncan be rescheduled on another compute node which it will call out to\nneutron again to create a port. In this case two ports will show\nup in the network_cache table (since they have the same instance_id) though\nonly one port is attached to the instance.\n\nThis patch addresses this issue by only adding ports to network_cache\nif nova successfully allocated the port (or it was passed in). This\nway these ghost ports are avoided. A follow up patch will come later\nthat garbage collects these ports.\n\nCloses-bug: #1258620\nRelated to blueprint nova-api-quantum-create-port\n\nChange-Id: I961c224d95291727c8614174de07805a0d0a9e46\n""}, {'number': 7, 'created': '2014-01-03 03:24:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/bd07aca3d1a32665cef9060f79a1dec516f7d323', 'message': ""Make network_cache more robust with neutron\n\nCurrently, nova treats neutron as the source of truth for which ports are\nattached to an instance which is a false assumption. Because of this\nif someone creates a port in neutron with a device_id that matches one\nof their existing instance_ids that port will eventually show up in\nnova list (through the periodic heal task).\n\nThis problem usually manifests it's self when nova-compute\ncalls to neutron to create a port and the request timesout (though\nthe port is actually created in neutron). When this occurs the instance\ncan be rescheduled on another compute node which it will call out to\nneutron again to create a port. In this case two ports will show\nup in the network_cache table (since they have the same instance_id) though\nonly one port is attached to the instance.\n\nThis patch addresses this issue by only adding ports to network_cache\nif nova successfully allocated the port (or it was passed in). This\nway these ghost ports are avoided. A follow up patch will come later\nthat garbage collects these ports.\n\nCloses-bug: #1258620\nRelated to blueprint nova-api-quantum-create-port\n\nChange-Id: I961c224d95291727c8614174de07805a0d0a9e46\n""}, {'number': 8, 'created': '2014-01-06 23:14:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/2761eb853a739332f90d9a36ed85124f8a0475dd', 'message': ""Make network_cache more robust with neutron\n\nCurrently, nova treats neutron as the source of truth for which ports are\nattached to an instance which is a false assumption. Because of this\nif someone creates a port in neutron with a device_id that matches one\nof their existing instance_ids that port will eventually show up in\nnova list (through the periodic heal task).\n\nThis problem usually manifests it's self when nova-compute\ncalls to neutron to create a port and the request timesout (though\nthe port is actually created in neutron). When this occurs the instance\ncan be rescheduled on another compute node which it will call out to\nneutron again to create a port. In this case two ports will show\nup in the network_cache table (since they have the same instance_id) though\nonly one port is attached to the instance.\n\nThis patch addresses this issue by only adding ports to network_cache\nif nova successfully allocated the port (or it was passed in). This\nway these ghost ports are avoided. A follow up patch will come later\nthat garbage collects these ports.\n\nCloses-bug: #1258620\nRelated to blueprint nova-api-quantum-create-port\n\nChange-Id: I961c224d95291727c8614174de07805a0d0a9e46\n""}, {'number': 9, 'created': '2014-01-07 21:42:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/8eb514eb607027a3a97856b39b6248b6f34c87d8', 'message': ""Make network_cache more robust with neutron\n\nCurrently, nova treats neutron as the source of truth for which ports are\nattached to an instance which is a false assumption. Because of this\nif someone creates a port in neutron with a device_id that matches one\nof their existing instance_ids that port will eventually show up in\nnova list (through the periodic heal task).\n\nThis problem usually manifests it's self when nova-compute\ncalls to neutron to create a port and the request timesout (though\nthe port is actually created in neutron). When this occurs the instance\ncan be rescheduled on another compute node which it will call out to\nneutron again to create a port. In this case two ports will show\nup in the network_cache table (since they have the same instance_id) though\nonly one port is attached to the instance.\n\nThis patch addresses this issue by only adding ports to network_cache\nif nova successfully allocated the port (or it was passed in). This\nway these ghost ports are avoided. A follow up patch will come later\nthat garbage collects these ports.\n\nCloses-bug: #1258620\nRelated to blueprint nova-api-quantum-create-port\n\nChange-Id: I961c224d95291727c8614174de07805a0d0a9e46\n""}, {'number': 10, 'created': '2014-01-13 21:30:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/1ca9e46a66f357a8a602fe99dda59e69da3d744d', 'message': ""Make network_cache more robust with neutron\n\nCurrently, nova treats neutron as the source of truth for which ports are\nattached to an instance which is a false assumption. Because of this\nif someone creates a port in neutron with a device_id that matches one\nof their existing instance_ids that port will eventually show up in\nnova list (through the periodic heal task).\n\nThis problem usually manifests it's self when nova-compute\ncalls to neutron to create a port and the request timesout (though\nthe port is actually created in neutron). When this occurs the instance\ncan be rescheduled on another compute node which it will call out to\nneutron again to create a port. In this case two ports will show\nup in the network_cache table (since they have the same instance_id) though\nonly one port is attached to the instance.\n\nThis patch addresses this issue by only adding ports to network_cache\nif nova successfully allocated the port (or it was passed in). This\nway these ghost ports are avoided. A follow up patch will come later\nthat garbage collects these ports.\n\nCloses-bug: #1258620\nRelated to blueprint nova-api-quantum-create-port\n\nChange-Id: I961c224d95291727c8614174de07805a0d0a9e46\n""}, {'number': 11, 'created': '2014-01-21 05:10:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/5576a386d1fa7ce77c251bf6d36f6e0db5854812', 'message': ""Make network_cache more robust with neutron\n\nCurrently, nova treats neutron as the source of truth for which ports are\nattached to an instance which is a false assumption. Because of this\nif someone creates a port in neutron with a device_id that matches one\nof their existing instance_ids that port will eventually show up in\nnova list (through the periodic heal task).\n\nThis problem usually manifests it's self when nova-compute\ncalls to neutron to create a port and the request timesout (though\nthe port is actually created in neutron). When this occurs the instance\ncan be rescheduled on another compute node which it will call out to\nneutron again to create a port. In this case two ports will show\nup in the network_cache table (since they have the same instance_id) though\nonly one port is attached to the instance.\n\nThis patch addresses this issue by only adding ports to network_cache\nif nova successfully allocated the port (or it was passed in). This\nway these ghost ports are avoided. A follow up patch will come later\nthat garbage collects these ports.\n\nCloses-bug: #1258620\nRelated to blueprint nova-api-quantum-create-port\n\nChange-Id: I961c224d95291727c8614174de07805a0d0a9e46\n""}, {'number': 12, 'created': '2014-01-21 15:07:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/704b1426e580c123714689cce19a5e6a4f8f8b5a', 'message': ""Make network_cache more robust with neutron\n\nCurrently, nova treats neutron as the source of truth for which ports are\nattached to an instance which is a false assumption. Because of this\nif someone creates a port in neutron with a device_id that matches one\nof their existing instance_ids that port will eventually show up in\nnova list (through the periodic heal task).\n\nThis problem usually manifests it's self when nova-compute\ncalls to neutron to create a port and the request timesout (though\nthe port is actually created in neutron). When this occurs the instance\ncan be rescheduled on another compute node which it will call out to\nneutron again to create a port. In this case two ports will show\nup in the network_cache table (since they have the same instance_id) though\nonly one port is attached to the instance.\n\nThis patch addresses this issue by only adding ports to network_cache\nif nova successfully allocated the port (or it was passed in). This\nway these ghost ports are avoided. A follow up patch will come later\nthat garbage collects these ports.\n\nCloses-bug: #1258620\nRelated to blueprint nova-api-quantum-create-port\n\nChange-Id: I961c224d95291727c8614174de07805a0d0a9e46\n""}, {'number': 13, 'created': '2014-02-03 12:57:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/809bb59b95fa4f6b78cbebe7d9b08d6a0ecb264f', 'message': ""Make network_cache more robust with neutron\n\nCurrently, nova treats neutron as the source of truth for which ports are\nattached to an instance which is a false assumption. Because of this\nif someone creates a port in neutron with a device_id that matches one\nof their existing instance_ids that port will eventually show up in\nnova list (through the periodic heal task).\n\nThis problem usually manifests it's self when nova-compute\ncalls to neutron to create a port and the request timesout (though\nthe port is actually created in neutron). When this occurs the instance\ncan be rescheduled on another compute node which it will call out to\nneutron again to create a port. In this case two ports will show\nup in the network_cache table (since they have the same instance_id) though\nonly one port is attached to the instance.\n\nThis patch addresses this issue by only adding ports to network_cache\nif nova successfully allocated the port (or it was passed in). This\nway these ghost ports are avoided. A follow up patch will come later\nthat garbage collects these ports.\n\nCloses-bug: #1258620\nRelated to blueprint nova-api-quantum-create-port\n\nChange-Id: I961c224d95291727c8614174de07805a0d0a9e46\n""}, {'number': 14, 'created': '2014-02-11 21:38:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/207b00f00ba2646e5ed926a36602ce37cf5638cd', 'message': ""Make network_cache more robust with neutron\n\nCurrently, nova treats neutron as the source of truth for which ports are\nattached to an instance which is a false assumption. Because of this\nif someone creates a port in neutron with a device_id that matches one\nof their existing instance_ids that port will eventually show up in\nnova list (through the periodic heal task).\n\nThis problem usually manifests it's self when nova-compute\ncalls to neutron to create a port and the request timesout (though\nthe port is actually created in neutron). When this occurs the instance\ncan be rescheduled on another compute node which it will call out to\nneutron again to create a port. In this case two ports will show\nup in the network_cache table (since they have the same instance_id) though\nonly one port is attached to the instance.\n\nThis patch addresses this issue by only adding ports to network_cache\nif nova successfully allocated the port (or it was passed in). This\nway these ghost ports are avoided. A follow up patch will come later\nthat garbage collects these ports.\n\nCloses-bug: #1258620\nRelated to blueprint nova-api-quantum-create-port\n\nChange-Id: I961c224d95291727c8614174de07805a0d0a9e46\n""}, {'number': 15, 'created': '2014-02-13 20:06:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/de9679f65e5017e35f49b1512c138d06e78f043e', 'message': ""Make network_cache more robust with neutron\n\nCurrently, nova treats neutron as the source of truth for which ports are\nattached to an instance which is a false assumption. Because of this\nif someone creates a port in neutron with a device_id that matches one\nof their existing instance_ids that port will eventually show up in\nnova list (through the periodic heal task).\n\nThis problem usually manifests it's self when nova-compute\ncalls to neutron to create a port and the request timesout (though\nthe port is actually created in neutron). When this occurs the instance\ncan be rescheduled on another compute node which it will call out to\nneutron again to create a port. In this case two ports will show\nup in the network_cache table (since they have the same instance_id) though\nonly one port is attached to the instance.\n\nThis patch addresses this issue by only adding ports to network_cache\nif nova successfully allocated the port (or it was passed in). This\nway these ghost ports are avoided. A follow up patch will come later\nthat garbage collects these ports.\n\nCloses-bug: #1258620\nRelated to blueprint nova-api-quantum-create-port\n\nChange-Id: I961c224d95291727c8614174de07805a0d0a9e46\n""}, {'number': 16, 'created': '2014-02-14 23:24:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/914ddc41798ccf233d70420c3af37445088a00c5', 'message': ""Make network_cache more robust with neutron\n\nCurrently, nova treats neutron as the source of truth for which ports are\nattached to an instance which is a false assumption. Because of this\nif someone creates a port in neutron with a device_id that matches one\nof their existing instance_ids that port will eventually show up in\nnova list (through the periodic heal task).\n\nThis problem usually manifests it's self when nova-compute\ncalls to neutron to create a port and the request timesout (though\nthe port is actually created in neutron). When this occurs the instance\ncan be rescheduled on another compute node which it will call out to\nneutron again to create a port. In this case two ports will show\nup in the network_cache table (since they have the same instance_id) though\nonly one port is attached to the instance.\n\nThis patch addresses this issue by only adding ports to network_cache\nif nova successfully allocated the port (or it was passed in). This\nway these ghost ports are avoided. A follow up patch will come later\nthat garbage collects these ports.\n\nCloses-bug: #1258620\nRelated to blueprint nova-api-quantum-create-port\n\nChange-Id: I961c224d95291727c8614174de07805a0d0a9e46\n""}, {'number': 17, 'created': '2014-02-19 00:14:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/a9c4f2f26032ba71167e2c6b7c2606173cc18e55', 'message': ""Make network_cache more robust with neutron\n\nCurrently, nova treats neutron as the source of truth for which ports are\nattached to an instance which is a false assumption. Because of this\nif someone creates a port in neutron with a device_id that matches one\nof their existing instance_ids that port will eventually show up in\nnova list (through the periodic heal task).\n\nThis problem usually manifests it's self when nova-compute\ncalls to neutron to create a port and the request times out (though\nthe port is actually created in neutron). When this occurs the instance\ncan be rescheduled on another compute node which it will call out to\nneutron again to create a port. In this case two ports will show\nup in the network_cache table (since they have the same instance_id) though\nonly one port is attached to the instance.\n\nThis patch addresses this issue by only adding ports to network_cache\nif nova successfully allocated the port (or it was passed in). This\nway these ghost ports are avoided. A follow up patch will come later\nthat garbage collects these ports.\n\nCloses-bug: #1258620\nRelated to blueprint nova-api-quantum-create-port\n\nChange-Id: I961c224d95291727c8614174de07805a0d0a9e46\n""}, {'number': 18, 'created': '2014-02-28 02:47:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/bef5ce26273b05cb455a8429cdbc60de180ee64f', 'message': ""Make network_cache more robust with neutron\n\nCurrently, nova treats neutron as the source of truth for which ports are\nattached to an instance which is a false assumption. Because of this\nif someone creates a port in neutron with a device_id that matches one\nof their existing instance_ids that port will eventually show up in\nnova list (through the periodic heal task).\n\nThis problem usually manifests it's self when nova-compute\ncalls to neutron to create a port and the request times out (though\nthe port is actually created in neutron). When this occurs the instance\ncan be rescheduled on another compute node which it will call out to\nneutron again to create a port. In this case two ports will show\nup in the network_cache table (since they have the same instance_id) though\nonly one port is attached to the instance.\n\nThis patch addresses this issue by only adding ports to network_cache\nif nova successfully allocated the port (or it was passed in). This\nway these ghost ports are avoided. A follow up patch will come later\nthat garbage collects these ports.\n\nCloses-bug: #1258620\nCloses-bug: #1272195\nRelated to blueprint nova-api-quantum-create-port\n\nChange-Id: I961c224d95291727c8614174de07805a0d0a9e46\n""}, {'number': 19, 'created': '2014-03-06 21:38:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/c28df10b5b449b4ab4127891fa9f83b2e1a62696', 'message': ""Make network_cache more robust with neutron\n\nCurrently, nova treats neutron as the source of truth for which ports are\nattached to an instance which is a false assumption. Because of this\nif someone creates a port in neutron with a device_id that matches one\nof their existing instance_ids that port will eventually show up in\nnova list (through the periodic heal task).\n\nThis problem usually manifests it's self when nova-compute\ncalls to neutron to create a port and the request times out (though\nthe port is actually created in neutron). When this occurs the instance\ncan be rescheduled on another compute node which it will call out to\nneutron again to create a port. In this case two ports will show\nup in the network_cache table (since they have the same instance_id) though\nonly one port is attached to the instance.\n\nThis patch addresses this issue by only adding ports to network_cache\nif nova successfully allocated the port (or it was passed in). This\nway these ghost ports are avoided. A follow up patch will come later\nthat garbage collects these ports.\n\nCloses-bug: #1258620\nCloses-bug: #1272195\nRelated to blueprint nova-api-quantum-create-port\n\nChange-Id: I961c224d95291727c8614174de07805a0d0a9e46\n""}, {'number': 20, 'created': '2014-03-07 00:49:24.000000000', 'files': ['nova/tests/network/test_neutronv2.py', 'nova/network/neutronv2/api.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/46922068ac167f492dd303efb359d0c649d69118', 'message': ""Make network_cache more robust with neutron\n\nCurrently, nova treats neutron as the source of truth for which ports are\nattached to an instance which is a false assumption. Because of this\nif someone creates a port in neutron with a device_id that matches one\nof their existing instance_ids that port will eventually show up in\nnova list (through the periodic heal task).\n\nThis problem usually manifests it's self when nova-compute\ncalls to neutron to create a port and the request times out (though\nthe port is actually created in neutron). When this occurs the instance\ncan be rescheduled on another compute node which it will call out to\nneutron again to create a port. In this case two ports will show\nup in the network_cache table (since they have the same instance_id) though\nonly one port is attached to the instance.\n\nThis patch addresses this issue by only adding ports to network_cache\nif nova successfully allocated the port (or it was passed in). This\nway these ghost ports are avoided. A follow up patch will come later\nthat garbage collects these ports.\n\nCloses-bug: #1258620\nCloses-bug: #1272195\n\nChange-Id: I961c224d95291727c8614174de07805a0d0a9e46\n""}]",65,60592,46922068ac167f492dd303efb359d0c649d69118,168,21,20,4395,,,0,"Make network_cache more robust with neutron

Currently, nova treats neutron as the source of truth for which ports are
attached to an instance which is a false assumption. Because of this
if someone creates a port in neutron with a device_id that matches one
of their existing instance_ids that port will eventually show up in
nova list (through the periodic heal task).

This problem usually manifests it's self when nova-compute
calls to neutron to create a port and the request times out (though
the port is actually created in neutron). When this occurs the instance
can be rescheduled on another compute node which it will call out to
neutron again to create a port. In this case two ports will show
up in the network_cache table (since they have the same instance_id) though
only one port is attached to the instance.

This patch addresses this issue by only adding ports to network_cache
if nova successfully allocated the port (or it was passed in). This
way these ghost ports are avoided. A follow up patch will come later
that garbage collects these ports.

Closes-bug: #1258620
Closes-bug: #1272195

Change-Id: I961c224d95291727c8614174de07805a0d0a9e46
",git fetch https://review.opendev.org/openstack/nova refs/changes/92/60592/3 && git format-patch -1 --stdout FETCH_HEAD,"['nova/tests/network/test_neutronv2.py', 'nova/network/neutronv2/api.py']",2,3e5d204c44250ebdb806533d3a71bbaef83248b4,master," ports_in_requested_net_order = [] ports_in_requested_net_order.append(port['id']) ports_in_requested_net_order.append(created_port_ids[-1]) nw_info = self.get_instance_nw_info(context, instance, networks=nets, ports=ports_in_requested_net_order) def get_instance_nw_info(self, context, instance, networks=None, ports=None): result = self._get_instance_nw_info(context, instance, networks, ports) def _get_instance_nw_info(self, context, instance, networks=None, ports=None): nw_info = self._build_network_info_model(context, instance, networks, ports) def _build_network_info_model(self, context, instance, networks=None, ports=None): """"""Return list of ordered VIFs attached to instance. :param instance - instance we are returning network info for. :param networks - value is None when we are just perodically updating the network cache. Otherwise this is the list of networks being attached to the instance. This value is only used so we can return the human readable network name rather than uuid. :param ports - value is None when we are just perodically updating the network cache. Otherwise it is a list of port ids just created that should be attached to the instance in their given order. """""" data = client.list_ports(**search_opts) updated_ports = data.get('ports', []) # This code path is only done when refreshing the network_cache if ports is None: ports = [iface['id'] for iface in ifaces] # an interface was added/removed from instance. else: # Since networks does not contain the existing networks on the # instance we fetch it from the cache and add it. networks = networks + [ dict(id=iface['network']['id'], name=iface['network']['label'], tenant_id=iface['network']['meta']['tenant_id']) for iface in ifaces] ports = [iface['id'] for iface in ifaces] + ports for port in ports: for updated_port in updated_ports: if port == updated_port['id']: network_IPs = self._nw_info_get_ips(client, updated_port) subnets = self._nw_info_get_subnets(context, updated_port, network_IPs) devname = ""tap"" + updated_port['id'] devname = devname[:network_model.NIC_NAME_LEN] network, ovs_interfaceid = ( self._nw_info_build_network(updated_port, networks, subnets)) nw_info.append(network_model.VIF( id=updated_port['id'], address=updated_port['mac_address'], network=network, type=updated_port.get('binding:vif_type'), ovs_interfaceid=ovs_interfaceid, devname=devname)) break "," nw_info = self.get_instance_nw_info(context, instance, networks=nets) def get_instance_nw_info(self, context, instance, networks=None): result = self._get_instance_nw_info(context, instance, networks) def _get_instance_nw_info(self, context, instance, networks=None): nw_info = self._build_network_info_model(context, instance, networks) def _build_network_info_model(self, context, instance, networks=None): # Note(arosen): on interface-attach networks only contains the # network that the interface is being attached to. data = client.list_ports(**search_opts) ports = data.get('ports', []) if networks is None: net_ids = [iface['network']['id'] for iface in ifaces] # ensure ports are in preferred network order, and filter out # those not attached to one of the provided list of networks else: # Needed when interfaces are added to existing instances. for iface in ifaces: nw_info.append(network_model.VIF( id=iface['id'], address=iface['address'], network=iface['network'], type=iface['type'], ovs_interfaceid=iface['ovs_interfaceid'], devname=iface['devname'])) net_ids = [n['id'] for n in networks] ports = [port for port in ports if port['network_id'] in net_ids] _ensure_requested_network_ordering(lambda x: x['network_id'], ports, net_ids) for port in ports: network_IPs = self._nw_info_get_ips(client, port) subnets = self._nw_info_get_subnets(context, port, network_IPs) devname = ""tap"" + port['id'] devname = devname[:network_model.NIC_NAME_LEN] network, ovs_interfaceid = self._nw_info_build_network(port, networks, subnets) nw_info.append(network_model.VIF( id=port['id'], address=port['mac_address'], network=network, type=port.get('binding:vif_type'), ovs_interfaceid=ovs_interfaceid, devname=devname))",202,124
openstack%2Fopenstack-manuals~master~Ic8185bc96b713b24872b5597145768215a89f8b4,openstack/openstack-manuals,master,Ic8185bc96b713b24872b5597145768215a89f8b4,Fix artifacts,MERGED,2014-03-06 18:49:03.000000000,2014-03-07 05:12:09.000000000,2014-03-07 05:12:08.000000000,"[{'_account_id': 3}, {'_account_id': 612}, {'_account_id': 9515}]","[{'number': 1, 'created': '2014-03-06 18:49:03.000000000', 'files': ['doc/training-guides/figures/image02.png'], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/92dad6415d5989df058136888d01d4c725898e4c', 'message': 'Fix artifacts\n\nMy last change had some artificats that I noticed too late. Fixed now.\n\nChange-Id: Ic8185bc96b713b24872b5597145768215a89f8b4\n'}]",0,78707,92dad6415d5989df058136888d01d4c725898e4c,7,3,1,6547,,,0,"Fix artifacts

My last change had some artificats that I noticed too late. Fixed now.

Change-Id: Ic8185bc96b713b24872b5597145768215a89f8b4
",git fetch https://review.opendev.org/openstack/openstack-manuals refs/changes/07/78707/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/training-guides/figures/image02.png'],1,92dad6415d5989df058136888d01d4c725898e4c,cleanup-image,,,0,0
openstack%2Foslo.vmware~master~I85c7f9079c89ba3b65a11741e8b0c8d64f62a3cd,openstack/oslo.vmware,master,I85c7f9079c89ba3b65a11741e8b0c8d64f62a3cd,Enable download of streamOptimized file-like,MERGED,2014-03-02 08:39:34.000000000,2014-03-07 05:09:43.000000000,2014-03-07 05:09:43.000000000,"[{'_account_id': 3}, {'_account_id': 1653}, {'_account_id': 8027}, {'_account_id': 8759}, {'_account_id': 9171}]","[{'number': 1, 'created': '2014-03-02 08:39:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.vmware/commit/1c04c627b0947825b19b15c70cf46ba2dd77d57f', 'message': ""Enable download of file-like of stream optimized file\n\nAdds a new function download_stream_optimized_data, that facilates\nthe transfers of stream-optimized file data obtain via additional\nprocessing of the data from the image server.\nOne use case for it is when image is actually an OVA, which is a tar\narchive containing the VMDK disk of interest, with roughly the\nfollowing code flow:\n\n   image_data = image_service.download(context, image_id)\n   tar = process_image_data_as_tar(image_data)\n   file_obj = tar.extractfile(disk_name)\n   imported_vm = download_stream_optimized_data(ctxt, timeout, file_obj, ...)\n\nAdditionally corrected the FileReadWriteTask to really read in 64k\nchunks like it intended to by passing the size parameter to read().\nThis will prevent the file_obj's data from being slurped in one go.\n\nChange-Id: I85c7f9079c89ba3b65a11741e8b0c8d64f62a3cd\n""}, {'number': 2, 'created': '2014-03-02 08:42:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.vmware/commit/613063210b0857c35328d7498218789a6ee59586', 'message': ""Enable download of streamOptimized file-like\n\nAdds a new function download_stream_optimized_data, that facilates the\ntransfers of stream-optimized file data obtain via additional processing\nof the data from the image server.  One use case for it is when image is\nactually an OVA, which is a tar archive containing the VMDK disk of\ninterest, with roughly the following code flow:\n\n   image_data = image_service.download(context, image_id)\n   tar = process_image_data_as_tar(image_data)\n   file_obj = tar.extractfile(disk_name)\n   imported_vm = download_stream_optimized_data(context, timeout,\n                                                file_obj, ...)\n\nAdditionally corrected the FileReadWriteTask to really read in 64k\nchunks like it intended to by passing the size parameter to read().\nThis will prevent the file_obj's data from being slurped in one go.\n\nChange-Id: I85c7f9079c89ba3b65a11741e8b0c8d64f62a3cd\n""}, {'number': 3, 'created': '2014-03-02 08:46:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.vmware/commit/193da5ea02635b6d471605d18043b41529c3dc21', 'message': ""Enable download of streamOptimized file-like\n\nAdds a new function download_stream_optimized_data, that facilates the\ntransfers of stream-optimized file data obtain via additional processing\nof the data from the image server.  One use case for it is when image is\nactually an OVA, which is a tar archive containing the VMDK disk of\ninterest, with roughly the following code flow:\n\n   image_data = image_service.download(context, image_id)\n   tar = process_image_data_as_tar(image_data)\n   file_obj = tar.extractfile(disk_name)\n   imported_vm = download_stream_optimized_data(context, timeout,\n                                                file_obj, ...)\n\nAdditionally corrected the FileReadWriteTask to really read in 64k\nchunks like it intended to by passing the size parameter to read().\nThis will prevent the file_obj's data from being slurped in one go.\n\nCloses-Bug: #1286708\nChange-Id: I85c7f9079c89ba3b65a11741e8b0c8d64f62a3cd\n""}, {'number': 4, 'created': '2014-03-02 08:51:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.vmware/commit/59c8b2edb8f377dbe94cfebc062c25e4918597d7', 'message': ""Enable download of streamOptimized file-like\n\nAdds a new function download_stream_optimized_data, that facilates the\ntransfers of stream-optimized file data obtained via additional\nprocessing of the data from the image server.  One use case for it is\nwhen image is actually an OVA, which is a tar archive containing the\nVMDK disk of interest, using roughly the following code flow:\n\n   image_data = image_service.download(context, image_id)\n   tar = process_image_data_as_tar(image_data)\n   file_obj = tar.extractfile(disk_name)\n   imported_vm = download_stream_optimized_data(context, timeout,\n                                                file_obj, ...)\n\nIn addition, corrected the FileReadWriteTask to really read in 64k\nchunks like it intended to by passing the size parameter to read().\nThis will prevent the above file_obj's data from being slurped in one\ngo.\n\nCloses-Bug: #1286708\nChange-Id: I85c7f9079c89ba3b65a11741e8b0c8d64f62a3cd\n""}, {'number': 5, 'created': '2014-03-06 19:41:16.000000000', 'files': ['tests/test_image_transfer.py', 'oslo/vmware/image_transfer.py'], 'web_link': 'https://opendev.org/openstack/oslo.vmware/commit/7826d98eda7a861d48688dc05680851df7c76c04', 'message': ""Enable download of streamOptimized file-like\n\nAdds a new function download_stream_optimized_data, that facilates the\ntransfers of stream-optimized file data obtained via additional\nprocessing of the data from the image server.  One use case for it is\nwhen image is actually an OVA, which is a tar archive containing the\nVMDK disk of interest, using roughly the following code flow:\n\n   image_data = image_service.download(context, image_id)\n   tar = process_image_data_as_tar(image_data)\n   file_obj = tar.extractfile(disk_name)\n   imported_vm = download_stream_optimized_data(context, timeout,\n                                                file_obj, ...)\n\nIn addition, corrected the FileReadWriteTask to really read in 64k\nchunks like it intended to by passing the size parameter to read().\nThis will prevent the above file_obj's data from being slurped in one\ngo.\n\nCloses-Bug: #1286708\nChange-Id: I85c7f9079c89ba3b65a11741e8b0c8d64f62a3cd\n""}]",4,77410,7826d98eda7a861d48688dc05680851df7c76c04,29,5,5,8027,,,0,"Enable download of streamOptimized file-like

Adds a new function download_stream_optimized_data, that facilates the
transfers of stream-optimized file data obtained via additional
processing of the data from the image server.  One use case for it is
when image is actually an OVA, which is a tar archive containing the
VMDK disk of interest, using roughly the following code flow:

   image_data = image_service.download(context, image_id)
   tar = process_image_data_as_tar(image_data)
   file_obj = tar.extractfile(disk_name)
   imported_vm = download_stream_optimized_data(context, timeout,
                                                file_obj, ...)

In addition, corrected the FileReadWriteTask to really read in 64k
chunks like it intended to by passing the size parameter to read().
This will prevent the above file_obj's data from being slurped in one
go.

Closes-Bug: #1286708
Change-Id: I85c7f9079c89ba3b65a11741e8b0c8d64f62a3cd
",git fetch https://review.opendev.org/openstack/oslo.vmware refs/changes/10/77410/4 && git format-patch -1 --stdout FETCH_HEAD,"['tests/test_image_transfer.py', 'oslo/vmware/image_transfer.py']",2,1c04c627b0947825b19b15c70cf46ba2dd77d57f,bug/1286708," data = self._input_file.read(rw_handles.READ_CHUNKSIZE)def download_stream_optimized_data(context, timeout_secs, read_handle, **kwargs): """"""Download stream optimized to VMware server. :param context: image service write context :param timeout_secs: time in seconds to wait for the download to complete :param read_handle: handle from which to read the image data :param kwargs: keyword arguments to configure the destination VMDK write handle :returns: managed object reference of the VM created for import to VMware server :raises: VimException, VimFaultException, VimAttributeException, VimSessionOverLoadException, VimConnectionException, ImageTransferException, ValueError """""" file_size = int(kwargs.get('image_size')) write_handle = rw_handles.VmdkWriteHandle(kwargs.get('session'), kwargs.get('host'), kwargs.get('resource_pool'), kwargs.get('vm_folder'), kwargs.get('vm_import_spec'), file_size) _start_transfer(context, timeout_secs, read_handle, file_size, write_file_handle=write_handle) return write_handle.get_imported_vm() imported_vm = download_stream_optimized_data(context, timeout_secs, read_handle, **kwargs) return imported_vm"," data = self._input_file.read(None) file_size = int(kwargs.get('image_size')) write_handle = rw_handles.VmdkWriteHandle(kwargs.get('session'), kwargs.get('host'), kwargs.get('resource_pool'), kwargs.get('vm_folder'), kwargs.get('vm_import_spec'), file_size) _start_transfer(context, timeout_secs, read_handle, file_size, write_file_handle=write_handle) return write_handle.get_imported_vm()",38,16
openstack%2Fpuppet-heat~stable%2Fhavana~Ia297410e61f246b2f5b4788b5d24961f070aa087,openstack/puppet-heat,stable/havana,Ia297410e61f246b2f5b4788b5d24961f070aa087,Adds Support for Database Idle Timeout,MERGED,2014-03-06 19:28:01.000000000,2014-03-07 05:09:03.000000000,2014-03-07 05:09:03.000000000,"[{'_account_id': 3}, {'_account_id': 6754}, {'_account_id': 6836}, {'_account_id': 7156}, {'_account_id': 7822}]","[{'number': 1, 'created': '2014-03-06 19:28:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-heat/commit/e8836bb60923f3d72ba82e97d811d0588ceb53b8', 'message': 'Adds Support for Database Idle Timeout\n\nOther OS services support the idle_timeout parameter that is\nneeded for reaping stale sql connections.  This is important for\nclustered databases.\n\nChange-Id: Ia297410e61f246b2f5b4788b5d24961f070aa087\n'}, {'number': 2, 'created': '2014-03-06 19:55:25.000000000', 'files': ['manifests/init.pp', 'spec/classes/heat_init_spec.rb'], 'web_link': 'https://opendev.org/openstack/puppet-heat/commit/7346c3afda90d06e81086765a5579be1786b055e', 'message': 'Adds Support for Database Idle Timeout\n\nOther OS services support the idle_timeout parameter that is\nneeded for reaping stale sql connections.  This is important for\nclustered databases.\n\nConflicts:\n\n        spec/classes/heat_init_spec.rb\n\nChange-Id: Ia297410e61f246b2f5b4788b5d24961f070aa087\n(cherry picked from commit 49f066e637fe22a25e80449cff8f0936682d7f10)\n'}]",0,78724,7346c3afda90d06e81086765a5579be1786b055e,10,5,2,6836,,,0,"Adds Support for Database Idle Timeout

Other OS services support the idle_timeout parameter that is
needed for reaping stale sql connections.  This is important for
clustered databases.

Conflicts:

        spec/classes/heat_init_spec.rb

Change-Id: Ia297410e61f246b2f5b4788b5d24961f070aa087
(cherry picked from commit 49f066e637fe22a25e80449cff8f0936682d7f10)
",git fetch https://review.opendev.org/openstack/puppet-heat refs/changes/24/78724/1 && git format-patch -1 --stdout FETCH_HEAD,"['manifests/init.pp', 'spec/classes/heat_init_spec.rb']",2,e8836bb60923f3d72ba82e97d811d0588ceb53b8,stable/havana," :package_ensure => 'present', :verbose => 'False', :debug => 'False', :rabbit_host => '127.0.0.1', :rabbit_port => 5672, :rabbit_userid => 'guest', :rabbit_password => '', :rabbit_virtualhost => '/', :log_dir => '/var/log/heat', :database_idle_timeout => 3600, :sql_connection => 'mysql://user@host/database' it 'configures database_idle_timeout' do should contain_heat_config('database/idle_timeout').with_value( params[:database_idle_timeout] ) end shared_examples_for 'with database_idle_timeout modified' do before do params.merge!( :database_idle_timeout => 69 ) end it do should contain_heat_config('database/idle_timeout').with_value(69) end end "," :package_ensure => 'present', :verbose => 'False', :debug => 'False', :rabbit_host => '127.0.0.1', :rabbit_port => 5672, :rabbit_userid => 'guest', :rabbit_password => '', :rabbit_virtualhost => '/', :log_dir => '/var/log/heat', :sql_connection => 'mysql://user@host/database'",33,10
openstack%2Ftempest~master~I35769cf4d18363fad56ed5150b4d01d8a5ad17e7,openstack/tempest,master,I35769cf4d18363fad56ed5150b4d01d8a5ad17e7,Move ipv6 config option into network-feature-enabled,MERGED,2014-03-03 19:31:32.000000000,2014-03-07 05:00:44.000000000,2014-03-07 05:00:43.000000000,"[{'_account_id': 3}, {'_account_id': 748}, {'_account_id': 1192}, {'_account_id': 5196}, {'_account_id': 5689}, {'_account_id': 6524}, {'_account_id': 9008}]","[{'number': 1, 'created': '2014-03-03 19:31:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/8d3fab62b7d852a52bce7f98abff6bf73657f2ae', 'message': 'Move ipv6 config option into network-feature-enabled\n\nThis commit moves the ipv6 option into the proper config group.\nPreviously, there was an ipv6_enabled option under the network group.\nThis was the incorrect location for this type of option since, ipv6\nis an optional feature it should be in the feature enabled group.\n\nChange-Id: I35769cf4d18363fad56ed5150b4d01d8a5ad17e7\n'}, {'number': 3, 'created': '2014-03-03 20:49:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/7798a78bb6d68fe4ecfd8a4c2a1af56dac75150b', 'message': 'Move ipv6 config option into network-feature-enabled\n\nThis commit moves the ipv6 option into the proper config group.\nPreviously, there was an ipv6_enabled option under the network group.\nThis was the incorrect location for this type of option since, ipv6\nis an optional feature it should be in the feature enabled group.\n\nChange-Id: I35769cf4d18363fad56ed5150b4d01d8a5ad17e7\n'}, {'number': 2, 'created': '2014-03-03 20:49:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/f10d72cb233170bc6cd674e73cbe3ea8b4ce7e2a', 'message': 'Move ipv6 config option into network-feature-enabled\n\nThis commit moves the ipv6 option into the proper config group.\nPreviously, there was an ipv6_enabled option under the network group.\nThis was the incorrect location for this type of option since, ipv6\nis an optional feature it should be in the feature enabled group.\n\nChange-Id: I35769cf4d18363fad56ed5150b4d01d8a5ad17e7\n'}, {'number': 5, 'created': '2014-03-03 20:49:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/f2b54a7e3728f8358e16479f53d6e9d86837a2a2', 'message': 'Move ipv6 config option into network-feature-enabled\n\nThis commit moves the ipv6 option into the proper config group.\nPreviously, there was an ipv6_enabled option under the network group.\nThis was the incorrect location for this type of option since, ipv6\nis an optional feature it should be in the feature enabled group.\n\nChange-Id: I35769cf4d18363fad56ed5150b4d01d8a5ad17e7\n'}, {'number': 4, 'created': '2014-03-03 20:49:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/f61d49447a7a083603bc220615d2dd851e3abe14', 'message': 'Move ipv6 config option into network-feature-enabled\n\nThis commit moves the ipv6 option into the proper config group.\nPreviously, there was an ipv6_enabled option under the network group.\nThis was the incorrect location for this type of option since, ipv6\nis an optional feature it should be in the feature enabled group.\n\nChange-Id: I35769cf4d18363fad56ed5150b4d01d8a5ad17e7\n'}, {'number': 6, 'created': '2014-03-03 20:49:47.000000000', 'files': ['tempest/api/network/test_networks.py', 'etc/tempest.conf.sample', 'tempest/config.py'], 'web_link': 'https://opendev.org/openstack/tempest/commit/e2e33cf78ad345865b688d2d537099e1a23ca3b7', 'message': 'Move ipv6 config option into network-feature-enabled\n\nThis commit moves the ipv6 option into the proper config group.\nPreviously, there was an ipv6_enabled option under the network group.\nThis was the incorrect location for this type of option since, ipv6\nis an optional feature it should be in the feature enabled group.\n\nChange-Id: I35769cf4d18363fad56ed5150b4d01d8a5ad17e7\n'}]",3,77678,e2e33cf78ad345865b688d2d537099e1a23ca3b7,42,7,6,5196,,,0,"Move ipv6 config option into network-feature-enabled

This commit moves the ipv6 option into the proper config group.
Previously, there was an ipv6_enabled option under the network group.
This was the incorrect location for this type of option since, ipv6
is an optional feature it should be in the feature enabled group.

Change-Id: I35769cf4d18363fad56ed5150b4d01d8a5ad17e7
",git fetch https://review.opendev.org/openstack/tempest refs/changes/78/77678/1 && git format-patch -1 --stdout FETCH_HEAD,"['tempest/api/network/test_networks.py', 'etc/tempest.conf.sample', 'tempest/config.py']",3,8d3fab62b7d852a52bce7f98abff6bf73657f2ae,stop_config_getattr_import," cfg.BoolOpt('ipv6', default=True, help=""Allow the execution of IPv6 tests""),"," cfg.BoolOpt('ipv6_enabled', default=True, help=""Allow the execution of IPv6 tests""),",7,7
openstack%2Fnova~master~I03816632a4710ac5e9b92707783dfeef096bfc24,openstack/nova,master,I03816632a4710ac5e9b92707783dfeef096bfc24,Make compute manager prune instance events on delete and migrate,MERGED,2014-02-26 22:40:19.000000000,2014-03-07 04:59:44.000000000,2014-03-07 04:59:38.000000000,"[{'_account_id': 3}, {'_account_id': 1561}, {'_account_id': 2271}, {'_account_id': 4393}, {'_account_id': 4395}, {'_account_id': 5170}, {'_account_id': 6681}, {'_account_id': 9008}, {'_account_id': 9578}]","[{'number': 1, 'created': '2014-02-26 22:40:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/5623f189b4766aa4da398aa261cb4b7858b7b386', 'message': 'Make compute manager prune instance events on delete and migrate\n\nThis makes compute manager ensure that any unprocessed instance events\nget removed from the list when an instance is deleted or migrated.\n\nRelated to blueprint admin-event-callback-api\n\nChange-Id: I03816632a4710ac5e9b92707783dfeef096bfc24\n'}, {'number': 2, 'created': '2014-03-03 18:31:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/96eafbbb7eeb268267015be0cf79e37345c90a86', 'message': 'Make compute manager prune instance events on delete and migrate\n\nThis makes compute manager ensure that any unprocessed instance events\nget removed from the list when an instance is deleted or migrated.\n\nRelated to blueprint admin-event-callback-api\n\nChange-Id: I03816632a4710ac5e9b92707783dfeef096bfc24\n'}, {'number': 3, 'created': '2014-03-05 16:39:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/d76adc32316b0b1bd6e3be57db4b56eac47362ce', 'message': 'Make compute manager prune instance events on delete and migrate\n\nThis makes compute manager ensure that any unprocessed instance events\nget removed from the list when an instance is deleted or migrated.\n\nRelated to blueprint admin-event-callback-api\n\nChange-Id: I03816632a4710ac5e9b92707783dfeef096bfc24\n'}, {'number': 4, 'created': '2014-03-05 22:37:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/00d9d22a993c040889bead8f7331f117e275c9ea', 'message': 'Make compute manager prune instance events on delete and migrate\n\nThis makes compute manager ensure that any unprocessed instance events\nget removed from the list when an instance is deleted or migrated.\n\nRelated to blueprint admin-event-callback-api\n\nChange-Id: I03816632a4710ac5e9b92707783dfeef096bfc24\n'}, {'number': 5, 'created': '2014-03-06 00:44:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/baea5d69ef38c470c985744bdcef4ed7aed37560', 'message': 'Make compute manager prune instance events on delete and migrate\n\nThis makes compute manager ensure that any unprocessed instance events\nget removed from the list when an instance is deleted or migrated.\n\nRelated to blueprint admin-event-callback-api\n\nChange-Id: I03816632a4710ac5e9b92707783dfeef096bfc24\n'}, {'number': 6, 'created': '2014-03-06 02:13:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/fa6893a5e473cd4fd76fb4d094da740e7b76abfd', 'message': 'Make compute manager prune instance events on delete and migrate\n\nThis makes compute manager ensure that any unprocessed instance events\nget removed from the list when an instance is deleted or migrated.\n\nRelated to blueprint admin-event-callback-api\n\nChange-Id: I03816632a4710ac5e9b92707783dfeef096bfc24\n'}, {'number': 7, 'created': '2014-03-06 02:59:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/add2b42754c1c6e61a1e5f7383469cb59b12fcb7', 'message': 'Make compute manager prune instance events on delete and migrate\n\nThis makes compute manager ensure that any unprocessed instance events\nget removed from the list when an instance is deleted or migrated.\n\nRelated to blueprint admin-event-callback-api\n\nChange-Id: I03816632a4710ac5e9b92707783dfeef096bfc24\n'}, {'number': 8, 'created': '2014-03-06 15:41:26.000000000', 'files': ['nova/compute/manager.py', 'nova/tests/compute/test_compute.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/272aca6926f50b584dab77fb2d1c29fc8bdbdb9e', 'message': 'Make compute manager prune instance events on delete and migrate\n\nThis makes compute manager ensure that any unprocessed instance events\nget removed from the list when an instance is deleted or migrated.\n\nRelated to blueprint admin-event-callback-api\n\nChange-Id: I03816632a4710ac5e9b92707783dfeef096bfc24\n'}]",1,76680,272aca6926f50b584dab77fb2d1c29fc8bdbdb9e,70,9,8,4393,,,0,"Make compute manager prune instance events on delete and migrate

This makes compute manager ensure that any unprocessed instance events
get removed from the list when an instance is deleted or migrated.

Related to blueprint admin-event-callback-api

Change-Id: I03816632a4710ac5e9b92707783dfeef096bfc24
",git fetch https://review.opendev.org/openstack/nova refs/changes/80/76680/7 && git format-patch -1 --stdout FETCH_HEAD,"['nova/compute/manager.py', 'nova/tests/compute/test_compute.py']",2,5623f189b4766aa4da398aa261cb4b7858b7b386,bp/admin-event-callback-api," instance = self._create_fake_instance_obj() instance=instance, instance = self._create_fake_instance_obj() instance=instance, self.mox.StubOutWithMock(self.compute.instance_events, 'clear_events_for_instance') self.compute.instance_events.clear_events_for_instance( mox.IgnoreArg()) self.mox.StubOutWithMock(self.compute.instance_events, 'clear_events_for_instance') self.compute.instance_events.clear_events_for_instance( mox.IgnoreArg()) 'setup_networks_on_host'), mock.patch.object(self.compute.instance_events, 'clear_events_for_instance') unplug_vifs, setup_networks_on_host, clear_events clear_events.assert_called_once_with(inst_ref)"," instance = self._create_fake_instance() instance=jsonutils.to_primitive(instance), instance = self._create_fake_instance() instance=jsonutils.to_primitive(instance), 'setup_networks_on_host') unplug_vifs, setup_networks_on_host",25,6
openstack%2Fnova~master~I00b2821200f89a04f27963153805280c0063fd57,openstack/nova,master,I00b2821200f89a04f27963153805280c0063fd57,Make compute manager's virtapi support waiting for events,MERGED,2014-02-19 03:19:02.000000000,2014-03-07 04:58:19.000000000,2014-03-07 04:58:16.000000000,"[{'_account_id': 3}, {'_account_id': 191}, {'_account_id': 642}, {'_account_id': 1030}, {'_account_id': 1561}, {'_account_id': 2271}, {'_account_id': 4393}, {'_account_id': 4395}, {'_account_id': 5170}, {'_account_id': 6681}, {'_account_id': 9008}, {'_account_id': 9578}]","[{'number': 1, 'created': '2014-02-19 03:19:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/e185137edd6457e536f00580ff66c1e276f3bc33', 'message': ""WIP Make compute manager's virtapi support waiting for events\n\nThis makes compute manager's virtapi expose a context manager\nthat lets virt drivers do something that doesn't complete until\nan external event is triggered. The libvirt plug_vifs() method\nis used here as an example.\n\nChange-Id: I00b2821200f89a04f27963153805280c0063fd57\n""}, {'number': 2, 'created': '2014-02-19 19:22:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/e154b7a3f717b699493e20183eec32576a287759', 'message': ""WIP Make compute manager's virtapi support waiting for events\n\nThis makes compute manager's virtapi expose a context manager\nthat lets virt drivers do something that doesn't complete until\nan external event is triggered. The libvirt plug_vifs() method\nis used here as an example.\n\nRelated to blueprint admin-event-callback-api\n\nChange-Id: I00b2821200f89a04f27963153805280c0063fd57\n""}, {'number': 3, 'created': '2014-02-19 20:39:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/d4cc038f2f91ef9c40b89a6e8409e74db8566f7e', 'message': ""WIP Make compute manager's virtapi support waiting for events\n\nThis makes compute manager's virtapi expose a context manager\nthat lets virt drivers do something that doesn't complete until\nan external event is triggered.\n\nRelated to blueprint admin-event-callback-api\n\nChange-Id: I00b2821200f89a04f27963153805280c0063fd57\n""}, {'number': 4, 'created': '2014-02-20 01:47:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/162960dcc0cd97bd84d89293396525323901e86f', 'message': ""WIP Make compute manager's virtapi support waiting for events\n\nThis makes compute manager's virtapi expose a context manager\nthat lets virt drivers do something that doesn't complete until\nan external event is triggered.\n\nRelated to blueprint admin-event-callback-api\n\nChange-Id: I00b2821200f89a04f27963153805280c0063fd57\n""}, {'number': 5, 'created': '2014-02-20 19:01:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/3743973a17ecbba2d0a7341ff33e7135ae30fc18', 'message': ""WIP Make compute manager's virtapi support waiting for events\n\nThis makes compute manager's virtapi expose a context manager\nthat lets virt drivers do something that doesn't complete until\nan external event is triggered.\n\nRelated to blueprint admin-event-callback-api\n\nChange-Id: I00b2821200f89a04f27963153805280c0063fd57\n""}, {'number': 6, 'created': '2014-02-20 21:01:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/df7bd0fb4ca169bc6468e5d54b8efab6d4148ac2', 'message': ""WIP Make compute manager's virtapi support waiting for events\n\nThis makes compute manager's virtapi expose a context manager\nthat lets virt drivers do something that doesn't complete until\nan external event is triggered.\n\nRelated to blueprint admin-event-callback-api\n\nChange-Id: I00b2821200f89a04f27963153805280c0063fd57\n""}, {'number': 7, 'created': '2014-02-20 22:27:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/ab3a210ec126259d91aad32f2297b20ee07c3f52', 'message': ""WIP Make compute manager's virtapi support waiting for events\n\nThis makes compute manager's virtapi expose a context manager\nthat lets virt drivers do something that doesn't complete until\nan external event is triggered.\n\nRelated to blueprint admin-event-callback-api\n\nChange-Id: I00b2821200f89a04f27963153805280c0063fd57\n""}, {'number': 8, 'created': '2014-02-20 23:01:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/83ec5abe8fd2db6626960a6576acb023a9674e0e', 'message': ""WIP Make compute manager's virtapi support waiting for events\n\nThis makes compute manager's virtapi expose a context manager\nthat lets virt drivers do something that doesn't complete until\nan external event is triggered.\n\nRelated to blueprint admin-event-callback-api\n\nChange-Id: I00b2821200f89a04f27963153805280c0063fd57\n""}, {'number': 9, 'created': '2014-02-24 16:41:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/d6366ffe46204991a23be3984b3b0657bd6ada66', 'message': ""Make compute manager's virtapi support waiting for events\n\nThis makes compute manager's virtapi expose a context manager\nthat lets virt drivers do something that doesn't complete until\nan external event is triggered.\n\nRelated to blueprint admin-event-callback-api\n\nChange-Id: I00b2821200f89a04f27963153805280c0063fd57\n""}, {'number': 10, 'created': '2014-02-25 16:12:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/b244fe308a540c2303aa687f31876c874ab108d7', 'message': ""Make compute manager's virtapi support waiting for events\n\nThis makes compute manager's virtapi expose a context manager\nthat lets virt drivers do something that doesn't complete until\nan external event is triggered.\n\nRelated to blueprint admin-event-callback-api\n\nChange-Id: I00b2821200f89a04f27963153805280c0063fd57\n""}, {'number': 11, 'created': '2014-02-25 16:47:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/4f9f57a4cfef1e450122441017cd0a21b532c063', 'message': ""Make compute manager's virtapi support waiting for events\n\nThis makes compute manager's virtapi expose a context manager\nthat lets virt drivers do something that doesn't complete until\nan external event is triggered.\n\nRelated to blueprint admin-event-callback-api\n\nChange-Id: I00b2821200f89a04f27963153805280c0063fd57\n""}, {'number': 12, 'created': '2014-02-25 18:09:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/8a3e979be3dbffa261eedb42c336c09276b8243d', 'message': ""Make compute manager's virtapi support waiting for events\n\nThis makes compute manager's virtapi expose a context manager\nthat lets virt drivers do something that doesn't complete until\nan external event is triggered.\n\nRelated to blueprint admin-event-callback-api\n\nChange-Id: I00b2821200f89a04f27963153805280c0063fd57\n""}, {'number': 13, 'created': '2014-02-25 18:40:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/b9b092bfc1b9f16e89a33323bb17e8829971c29e', 'message': ""Make compute manager's virtapi support waiting for events\n\nThis makes compute manager's virtapi expose a context manager\nthat lets virt drivers do something that doesn't complete until\nan external event is triggered.\n\nRelated to blueprint admin-event-callback-api\n\nChange-Id: I00b2821200f89a04f27963153805280c0063fd57\n""}, {'number': 14, 'created': '2014-02-25 20:47:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/542f2e2804b252ba0e2a00f6f195ceeafb34db70', 'message': ""Make compute manager's virtapi support waiting for events\n\nThis makes compute manager's virtapi expose a context manager\nthat lets virt drivers do something that doesn't complete until\nan external event is triggered.\n\nRelated to blueprint admin-event-callback-api\n\nChange-Id: I00b2821200f89a04f27963153805280c0063fd57\n""}, {'number': 15, 'created': '2014-02-25 23:25:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/ff8f8e6a9c27176a3a3839e58fdf5cdd89da7fea', 'message': ""Make compute manager's virtapi support waiting for events\n\nThis makes compute manager's virtapi expose a context manager\nthat lets virt drivers do something that doesn't complete until\nan external event is triggered.\n\nRelated to blueprint admin-event-callback-api\n\nChange-Id: I00b2821200f89a04f27963153805280c0063fd57\n""}, {'number': 16, 'created': '2014-02-26 15:58:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/6075a3c74fd7015c1ea64228142eae27574cf42e', 'message': ""Make compute manager's virtapi support waiting for events\n\nThis makes compute manager's virtapi expose a context manager\nthat lets virt drivers do something that doesn't complete until\nan external event is triggered.\n\nRelated to blueprint admin-event-callback-api\n\nChange-Id: I00b2821200f89a04f27963153805280c0063fd57\n""}, {'number': 17, 'created': '2014-02-26 18:07:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/1cac95159437472ea4e760f913c9cc22827ebf81', 'message': ""Make compute manager's virtapi support waiting for events\n\nThis makes compute manager's virtapi expose a context manager\nthat lets virt drivers do something that doesn't complete until\nan external event is triggered.\n\nRelated to blueprint admin-event-callback-api\n\nChange-Id: I00b2821200f89a04f27963153805280c0063fd57\n""}, {'number': 18, 'created': '2014-03-03 18:31:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/268a620116abef19d159778662fb13670bab011a', 'message': ""Make compute manager's virtapi support waiting for events\n\nThis makes compute manager's virtapi expose a context manager\nthat lets virt drivers do something that doesn't complete until\nan external event is triggered.\n\nRelated to blueprint admin-event-callback-api\n\nChange-Id: I00b2821200f89a04f27963153805280c0063fd57\n""}, {'number': 19, 'created': '2014-03-05 16:39:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/2fc759772b36d791c0233dd564843b0e39217650', 'message': ""Make compute manager's virtapi support waiting for events\n\nThis makes compute manager's virtapi expose a context manager\nthat lets virt drivers do something that doesn't complete until\nan external event is triggered.\n\nRelated to blueprint admin-event-callback-api\n\nChange-Id: I00b2821200f89a04f27963153805280c0063fd57\n""}, {'number': 20, 'created': '2014-03-05 22:37:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/c9d170febcf66d48be1db7ffcae16ba3a41662d4', 'message': ""Make compute manager's virtapi support waiting for events\n\nThis makes compute manager's virtapi expose a context manager\nthat lets virt drivers do something that doesn't complete until\nan external event is triggered.\n\nRelated to blueprint admin-event-callback-api\n\nChange-Id: I00b2821200f89a04f27963153805280c0063fd57\n""}, {'number': 21, 'created': '2014-03-06 00:44:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/82b3c65f3328ec50513cbca86607927fee81f5e1', 'message': ""Make compute manager's virtapi support waiting for events\n\nThis makes compute manager's virtapi expose a context manager\nthat lets virt drivers do something that doesn't complete until\nan external event is triggered.\n\nRelated to blueprint admin-event-callback-api\n\nChange-Id: I00b2821200f89a04f27963153805280c0063fd57\n""}, {'number': 22, 'created': '2014-03-06 02:13:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/245aef8ebc5b11687f5687a0b0686f2b9636dedb', 'message': ""Make compute manager's virtapi support waiting for events\n\nThis makes compute manager's virtapi expose a context manager\nthat lets virt drivers do something that doesn't complete until\nan external event is triggered.\n\nRelated to blueprint admin-event-callback-api\n\nChange-Id: I00b2821200f89a04f27963153805280c0063fd57\n""}, {'number': 23, 'created': '2014-03-06 02:59:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/97b760486de5cfb3c494e2d96bf9be5ec21f1de2', 'message': ""Make compute manager's virtapi support waiting for events\n\nThis makes compute manager's virtapi expose a context manager\nthat lets virt drivers do something that doesn't complete until\nan external event is triggered.\n\nRelated to blueprint admin-event-callback-api\n\nChange-Id: I00b2821200f89a04f27963153805280c0063fd57\n""}, {'number': 24, 'created': '2014-03-06 15:41:25.000000000', 'files': ['nova/virt/fake.py', 'nova/virt/virtapi.py', 'nova/compute/manager.py', 'nova/tests/compute/test_virtapi.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/c51db0fa70d0f195d6296e549e0c999aa1bdfea6', 'message': ""Make compute manager's virtapi support waiting for events\n\nThis makes compute manager's virtapi expose a context manager\nthat lets virt drivers do something that doesn't complete until\nan external event is triggered.\n\nRelated to blueprint admin-event-callback-api\n\nChange-Id: I00b2821200f89a04f27963153805280c0063fd57\n""}]",15,74576,c51db0fa70d0f195d6296e549e0c999aa1bdfea6,157,12,24,4393,,,0,"Make compute manager's virtapi support waiting for events

This makes compute manager's virtapi expose a context manager
that lets virt drivers do something that doesn't complete until
an external event is triggered.

Related to blueprint admin-event-callback-api

Change-Id: I00b2821200f89a04f27963153805280c0063fd57
",git fetch https://review.opendev.org/openstack/nova refs/changes/76/74576/6 && git format-patch -1 --stdout FETCH_HEAD,"['nova/virt/libvirt/driver.py', 'nova/compute/manager.py']",2,e185137edd6457e536f00580ff66c1e276f3bc33,bp/admin-event-callback-api,"from nova.objects import external_event as external_event_obj @contextlib.contextmanager def wait_for_instance_event(self, instance, event_names): """"""Plan to wait for some events, run some code, then wait. This context manager will first create plans to wait for the provided event_names, yield, and then wait for all the scheduled events to complete. :param:instance: The instance for which an event is expected :param:event_names: A list of event names. Each element can be a string event name or tuple of strings to indicate (name, tag). """""" events = [] for event_name in event_names: if isinstance(event_name, tuple): name, tag = event_name event_name = external_event_obj.Event.make_key(name, tag) events.append( self._compute._prepare_for_instance_event(instance, event_name)) yield for event in events: event.wait() ",,31,2
openstack%2Fpython-swiftclient~master~Ia07554250a6aae8f3a6be6a70f83690ec3fc108c,openstack/python-swiftclient,master,Ia07554250a6aae8f3a6be6a70f83690ec3fc108c,"add ""info"" as an alias to ""capabilities""",MERGED,2014-03-06 18:52:07.000000000,2014-03-07 04:58:13.000000000,2014-03-07 04:58:13.000000000,"[{'_account_id': 3}, {'_account_id': 917}, {'_account_id': 1179}, {'_account_id': 2622}]","[{'number': 1, 'created': '2014-03-06 18:52:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-swiftclient/commit/661a706d9799eb74a89bfd56bfe70aa9d7a5b1e1', 'message': 'add ""info"" as an alias to ""capabilities""\n\nChange-Id: Ia07554250a6aae8f3a6be6a70f83690ec3fc108c\n'}, {'number': 2, 'created': '2014-03-06 21:02:02.000000000', 'files': ['bin/swift'], 'web_link': 'https://opendev.org/openstack/python-swiftclient/commit/07dd6680821a9332cd6c8bd7883129988e1bd64e', 'message': 'add ""info"" as an alias to ""capabilities""\n\nChange-Id: Ia07554250a6aae8f3a6be6a70f83690ec3fc108c\n'}]",2,78710,07dd6680821a9332cd6c8bd7883129988e1bd64e,19,4,2,1179,,,0,"add ""info"" as an alias to ""capabilities""

Change-Id: Ia07554250a6aae8f3a6be6a70f83690ec3fc108c
",git fetch https://review.opendev.org/openstack/python-swiftclient refs/changes/10/78710/1 && git format-patch -1 --stdout FETCH_HEAD,['bin/swift'],1,661a706d9799eb74a89bfd56bfe70aa9d7a5b1e1,info-alias,"st_info_options = st_capabilities_options st_info_help = st_capabilities_helpst_info = st_capabilities 'stat', 'upload', 'capabilities', 'info')"," 'stat', 'upload', 'capabilities')",5,1
openstack%2Ftempest~master~I4feb1b89acf8db0e164468d0471aff71ff5c6a77,openstack/tempest,master,I4feb1b89acf8db0e164468d0471aff71ff5c6a77,Raise orchestration build_timeout to 600 seconds,MERGED,2014-03-06 20:49:45.000000000,2014-03-07 04:58:06.000000000,2014-03-07 04:58:05.000000000,"[{'_account_id': 3}, {'_account_id': 1192}, {'_account_id': 2750}, {'_account_id': 4571}, {'_account_id': 5196}, {'_account_id': 9008}]","[{'number': 1, 'created': '2014-03-06 20:49:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/a4735ebd684a9b6a87991f1fa10da0b54035a4a2', 'message': 'Raise orchestration build_timeout to 600 seconds\n\nObserved boot time for a single server has been around 250 seconds\nso a build_timeout default of 300 would explain why ~20% of heat-slow\njobs are failing with stack timeout errors.\n\nCloses-Bug: #1288970\nChange-Id: I4feb1b89acf8db0e164468d0471aff71ff5c6a77\n'}, {'number': 2, 'created': '2014-03-07 00:29:58.000000000', 'files': ['etc/tempest.conf.sample', 'tempest/config.py'], 'web_link': 'https://opendev.org/openstack/tempest/commit/27f02430864443c127dbf4a09a62497c60fd0aa4', 'message': 'Raise orchestration build_timeout to 600 seconds\n\nObserved boot time for a single server has been around 250 seconds\nso a build_timeout default of 300 would explain why ~20% of heat-slow\njobs are failing with stack timeout errors.\n\nCloses-Bug: #1288970\nChange-Id: I4feb1b89acf8db0e164468d0471aff71ff5c6a77\n'}]",0,78756,27f02430864443c127dbf4a09a62497c60fd0aa4,22,6,2,4571,,,0,"Raise orchestration build_timeout to 600 seconds

Observed boot time for a single server has been around 250 seconds
so a build_timeout default of 300 would explain why ~20% of heat-slow
jobs are failing with stack timeout errors.

Closes-Bug: #1288970
Change-Id: I4feb1b89acf8db0e164468d0471aff71ff5c6a77
",git fetch https://review.opendev.org/openstack/tempest refs/changes/56/78756/1 && git format-patch -1 --stdout FETCH_HEAD,['tempest/config.py'],1,a4735ebd684a9b6a87991f1fa10da0b54035a4a2,bug/1288970," default=600,"," default=300,",1,1
openstack%2Fnova~master~I93957840ac251cf6a22474897daf80a164ba35c6,openstack/nova,master,I93957840ac251cf6a22474897daf80a164ba35c6,Add os-server-external-events V3 API,MERGED,2014-02-25 23:25:10.000000000,2014-03-07 04:56:35.000000000,2014-03-07 04:56:31.000000000,"[{'_account_id': 3}, {'_account_id': 1561}, {'_account_id': 1849}, {'_account_id': 2271}, {'_account_id': 4393}, {'_account_id': 4395}, {'_account_id': 5170}, {'_account_id': 5292}, {'_account_id': 9008}, {'_account_id': 9578}]","[{'number': 1, 'created': '2014-02-25 23:25:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/92f473261f105747ebdca2a34c50553b8489b6f9', 'message': 'Add os-server-external-events V3 API\n\nRelated to blueprint admin-event-callback-api\n\nChange-Id: I93957840ac251cf6a22474897daf80a164ba35c6\n'}, {'number': 2, 'created': '2014-02-26 15:58:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/2f8323c48f02c376e84b0c39d05d680a9d548dec', 'message': 'Add os-server-external-events V3 API\n\nRelated to blueprint admin-event-callback-api\n\nChange-Id: I93957840ac251cf6a22474897daf80a164ba35c6\n'}, {'number': 3, 'created': '2014-02-26 18:07:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/e57aede791cb94c271be9c6bc38292f442b1b1b5', 'message': 'Add os-server-external-events V3 API\n\nRelated to blueprint admin-event-callback-api\n\nChange-Id: I93957840ac251cf6a22474897daf80a164ba35c6\n'}, {'number': 4, 'created': '2014-03-03 18:32:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/49e79f2d8117ec99abbc0335dc0f2c49dc3b9fbd', 'message': 'Add os-server-external-events V3 API\n\nRelated to blueprint admin-event-callback-api\n\nChange-Id: I93957840ac251cf6a22474897daf80a164ba35c6\n'}, {'number': 5, 'created': '2014-03-05 16:39:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/8d3d002d4b0f6f2e3fab046d4542df9c98f5c020', 'message': 'Add os-server-external-events V3 API\n\nRelated to blueprint admin-event-callback-api\n\nChange-Id: I93957840ac251cf6a22474897daf80a164ba35c6\n'}, {'number': 6, 'created': '2014-03-05 22:37:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/707a7791143dcdec5e84ab9da852760384abb277', 'message': 'Add os-server-external-events V3 API\n\nRelated to blueprint admin-event-callback-api\n\nChange-Id: I93957840ac251cf6a22474897daf80a164ba35c6\n'}, {'number': 7, 'created': '2014-03-06 02:13:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/6e8537fc4f6b71b88974c2d9758e5d9731c5b9ab', 'message': 'Add os-server-external-events V3 API\n\nRelated to blueprint admin-event-callback-api\n\nChange-Id: I93957840ac251cf6a22474897daf80a164ba35c6\n'}, {'number': 8, 'created': '2014-03-06 15:41:34.000000000', 'files': ['doc/v3/api_samples/os-server-external-events/event-create-resp.json', 'nova/tests/integrated/v3/api_samples/os-server-external-events/server-post-req.json.tpl', 'nova/tests/integrated/v3/api_samples/os-server-external-events/server-post-resp.json.tpl', 'etc/nova/policy.json', 'doc/v3/api_samples/os-server-external-events/server-post-req.json', 'nova/api/openstack/compute/plugins/v3/server_external_events.py', 'nova/tests/integrated/v3/api_samples/os-server-external-events/event-create-req.json.tpl', 'nova/tests/integrated/v3/api_samples/os-server-external-events/event-create-resp.json.tpl', 'doc/v3/api_samples/os-server-external-events/server-post-resp.json', 'nova/tests/fake_policy.py', 'doc/v3/api_samples/os-server-external-events/event-create-req.json', 'setup.cfg', 'nova/tests/api/openstack/compute/plugins/v3/test_server_external_events.py', 'nova/tests/integrated/v3/test_server_external_events.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/388de275cbf6a683666413824d728e8ed114ead5', 'message': 'Add os-server-external-events V3 API\n\nRelated to blueprint admin-event-callback-api\n\nChange-Id: I93957840ac251cf6a22474897daf80a164ba35c6\n'}]",1,76388,388de275cbf6a683666413824d728e8ed114ead5,76,10,8,4393,,,0,"Add os-server-external-events V3 API

Related to blueprint admin-event-callback-api

Change-Id: I93957840ac251cf6a22474897daf80a164ba35c6
",git fetch https://review.opendev.org/openstack/nova refs/changes/88/76388/8 && git format-patch -1 --stdout FETCH_HEAD,"['nova/tests/integrated/v3/api_samples/os-server-external-events/server-post-req.json.tpl', 'nova/api/openstack/compute/plugins/v3/server_external_events.py', 'nova/tests/integrated/v3/api_samples/os-server-external-events/event-create-req.json.tpl', 'doc/v3/api_samples/os-server-external-events/server-post-resp.json', 'nova/tests/integrated/v3/api_samples/os-server-external-events/server-post-resp.json.tpl', 'etc/nova/policy.json', 'nova/tests/fake_policy.py', 'doc/v3/api_samples/os-server-external-events/server-post-req.json', 'doc/v3/api_samples/os-server-external-events/event-create-req.json', 'setup.cfg', 'nova/tests/integrated/v3/test_server_external_events.py']",11,92f473261f105747ebdca2a34c50553b8489b6f9,bp/admin-event-callback-api,"# Copyright 2014 Red Hat, Inc. # # Licensed under the Apache License, Version 2.0 (the ""License""); you may # not use this file except in compliance with the License. You may obtain # a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT # WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the # License for the specific language governing permissions and limitations # under the License. from nova.tests.integrated.v3 import test_servers class ServerExternalEventsSamplesJsonTest(test_servers.ServersSampleBase): extension_name = ""os-server-external-events"" def setUp(self): """"""setUp Method for AdminActions api samples extension This method creates the server that will be used in each tests """""" super(ServerExternalEventsSamplesJsonTest, self).setUp() self.uuid = self._post_server() def test_create_event(self): subs = { 'uuid': self.uuid, 'name': 'network-changed', 'status': 'completed', 'tag': 'foo', } response = self._do_post('os-server-external-events', 'event-create-req', subs) self.assertEqual(response.status, 200) ",,223,0
openstack%2Ftempest~master~I65e9ac5678d17f31de5449017f2193f53c74c535,openstack/tempest,master,I65e9ac5678d17f31de5449017f2193f53c74c535,"Prepare for enabling H302 rule (api/volume,tempest/*)",MERGED,2014-03-04 09:38:56.000000000,2014-03-07 04:56:21.000000000,2014-03-07 04:56:20.000000000,"[{'_account_id': 3}, {'_account_id': 1192}, {'_account_id': 5803}, {'_account_id': 6167}, {'_account_id': 7882}]","[{'number': 1, 'created': '2014-03-04 09:38:56.000000000', 'files': ['tempest/common/rest_client.py', 'tempest/api/volume/admin/test_volumes_actions.py', 'tempest/auth.py', 'tempest/api/volume/admin/test_volume_types_negative.py', 'tempest/api/volume/test_extensions.py', 'tempest/api/volume/v2/test_volumes_list.py', 'tempest/api/volume/admin/test_volume_hosts.py', 'tempest/api/volume/admin/test_volume_types_extra_specs.py', 'tempest/api/volume/test_volumes_negative.py', 'tempest/api/volume/admin/test_volume_types.py', 'tempest/api/volume/admin/test_volumes_backup.py', 'tempest/api/volume/test_volumes_snapshots.py', 'tempest/api/volume/admin/test_volume_types_extra_specs_negative.py', 'tempest/api/volume/admin/test_snapshots_actions.py', 'tempest/api/volume/admin/test_multi_backend.py', 'tempest/api/volume/test_volumes_snapshots_negative.py', 'tempest/api/volume/test_volume_transfers.py'], 'web_link': 'https://opendev.org/openstack/tempest/commit/1edf94f99746218212169f90bfe8b0346994be3e', 'message': ""Prepare for enabling H302 rule (api/volume,tempest/*)\n\nWe can use H302 rule but ignore it now. This commit prepares for\nenabling H302 rule. But this commit modifies a part of Tempest only\nbecause if we fix all of them at one time, it's hard to merge this\ncommit.\n    ---------------\n    tempest/api/compute/admin\n    tempest/api/compute/{c*,f*,i*,s*,t*}\n    tempest/api/compute/{v3,volumes},data_processing\n    tempest/api/identity/admin\n    tempest/api/image\n    tempest/api/{n*,o*,t*}\n    tempest/api/volume,tempest/*     <- This patch\n    tempest/services/compute/json\n    tempest/services/compute/v3/json\n    tempest/services/compute/xml\n    tempest/services/identity\n    tempest/services/{im*,n*,o*,t*}\n    tempest/services/volume\n    tempest/clients.py: TBD\n    ---------------\n\nChange-Id: I65e9ac5678d17f31de5449017f2193f53c74c535\n""}]",0,77830,1edf94f99746218212169f90bfe8b0346994be3e,11,5,1,5689,,,0,"Prepare for enabling H302 rule (api/volume,tempest/*)

We can use H302 rule but ignore it now. This commit prepares for
enabling H302 rule. But this commit modifies a part of Tempest only
because if we fix all of them at one time, it's hard to merge this
commit.
    ---------------
    tempest/api/compute/admin
    tempest/api/compute/{c*,f*,i*,s*,t*}
    tempest/api/compute/{v3,volumes},data_processing
    tempest/api/identity/admin
    tempest/api/image
    tempest/api/{n*,o*,t*}
    tempest/api/volume,tempest/*     <- This patch
    tempest/services/compute/json
    tempest/services/compute/v3/json
    tempest/services/compute/xml
    tempest/services/identity
    tempest/services/{im*,n*,o*,t*}
    tempest/services/volume
    tempest/clients.py: TBD
    ---------------

Change-Id: I65e9ac5678d17f31de5449017f2193f53c74c535
",git fetch https://review.opendev.org/openstack/tempest refs/changes/30/77830/1 && git format-patch -1 --stdout FETCH_HEAD,"['tempest/common/rest_client.py', 'tempest/api/volume/admin/test_volumes_actions.py', 'tempest/auth.py', 'tempest/api/volume/admin/test_volume_types_negative.py', 'tempest/api/volume/test_extensions.py', 'tempest/api/volume/v2/test_volumes_list.py', 'tempest/api/volume/admin/test_volume_hosts.py', 'tempest/api/volume/admin/test_volume_types_extra_specs.py', 'tempest/api/volume/test_volumes_negative.py', 'tempest/api/volume/admin/test_volume_types.py', 'tempest/api/volume/admin/test_volumes_backup.py', 'tempest/api/volume/test_volumes_snapshots.py', 'tempest/api/volume/admin/test_volume_types_extra_specs_negative.py', 'tempest/api/volume/admin/test_snapshots_actions.py', 'tempest/api/volume/admin/test_multi_backend.py', 'tempest/api/volume/test_volumes_snapshots_negative.py', 'tempest/api/volume/test_volume_transfers.py']",17,1edf94f99746218212169f90bfe8b0346994be3e,cleanup-h302-volume-etc,from tempest import test @test.attr(type='gate'),from tempest.test import attr @attr(type='gate'),114,114
openstack%2Ftempest~master~Iffb79e5bb362bfd02b028166ce6ddfa616f2909f,openstack/tempest,master,Iffb79e5bb362bfd02b028166ce6ddfa616f2909f,Fix invalid syntax in HOT templates,MERGED,2014-03-05 08:51:00.000000000,2014-03-07 04:51:20.000000000,2014-03-07 04:51:18.000000000,"[{'_account_id': 3}, {'_account_id': 1192}, {'_account_id': 2750}, {'_account_id': 4257}, {'_account_id': 5196}, {'_account_id': 5803}, {'_account_id': 7385}]","[{'number': 1, 'created': '2014-03-05 08:51:00.000000000', 'files': ['tempest/api/orchestration/stacks/test_swift_resources.py', 'tempest/api/orchestration/stacks/test_neutron_resources.py'], 'web_link': 'https://opendev.org/openstack/tempest/commit/50b62032e44bb49f8498d747dd46ac0e57e4c57a', 'message': ""Fix invalid syntax in HOT templates\n\nThis patch fixes invalid syntax in HOT templates where keywords\nstarting with uppercase characters are used (e.g. 'Type') in\nthe resources section. According to the HOT spec, though, those\nkeywords are all lowercase (e.g. 'type').\n\nChange https://review.openstack.org/#/c/73580 in heat adds\nstricter validation which makes the respective testcases fail.\n\nChange-Id: Iffb79e5bb362bfd02b028166ce6ddfa616f2909f\nCloses-Bug: #1288114\n""}]",0,78136,50b62032e44bb49f8498d747dd46ac0e57e4c57a,12,7,1,7193,,,0,"Fix invalid syntax in HOT templates

This patch fixes invalid syntax in HOT templates where keywords
starting with uppercase characters are used (e.g. 'Type') in
the resources section. According to the HOT spec, though, those
keywords are all lowercase (e.g. 'type').

Change https://review.openstack.org/#/c/73580 in heat adds
stricter validation which makes the respective testcases fail.

Change-Id: Iffb79e5bb362bfd02b028166ce6ddfa616f2909f
Closes-Bug: #1288114
",git fetch https://review.opendev.org/openstack/tempest refs/changes/36/78136/1 && git format-patch -1 --stdout FETCH_HEAD,"['tempest/api/orchestration/stacks/test_swift_resources.py', 'tempest/api/orchestration/stacks/test_neutron_resources.py']",2,50b62032e44bb49f8498d747dd46ac0e57e4c57a,bug/1288114, metadata: depends_on: Server, Metadata: DependsOn: Server,7,7
openstack%2Fnova~master~I98fe496720ad1c4fce44c0c7fea8bfa1c2721812,openstack/nova,master,I98fe496720ad1c4fce44c0c7fea8bfa1c2721812,Fix BDM legacy usage with objects,MERGED,2014-03-06 20:49:22.000000000,2014-03-07 04:50:25.000000000,2014-03-07 04:50:21.000000000,"[{'_account_id': 3}, {'_account_id': 1561}, {'_account_id': 1849}, {'_account_id': 2750}, {'_account_id': 4393}, {'_account_id': 5170}, {'_account_id': 5511}, {'_account_id': 9008}, {'_account_id': 9578}]","[{'number': 1, 'created': '2014-03-06 20:49:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/6222dcb931df851eb96126eba7ffd7710cd69264', 'message': ""Fix BDM legacy usage with objects\n\nWhen we're doing an upgrade against Havana, our backleveled\ncompute RPC version will cause us to run block_device.legacy_mapping(),\nwhich attempts to convert a BlockDeviceMapping object into an old-\nstyle dict. This trips over a common problem with objects where\nthings expecting a list or a dict decide the object is a dict and\ntry to iterate it as such.\n\nThis makes the small tweak necessary and adds a test that verifies\nthat it works.\n\nChange-Id: I98fe496720ad1c4fce44c0c7fea8bfa1c2721812\n""}, {'number': 2, 'created': '2014-03-06 21:40:25.000000000', 'files': ['nova/tests/test_block_device.py', 'nova/block_device.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/31a4ffc49cd3f11adb9e61b2ff70d7e742515e51', 'message': ""Fix BDM legacy usage with objects\n\nWhen we're doing an upgrade against Havana, our backleveled\ncompute RPC version will cause us to run block_device.legacy_mapping(),\nwhich attempts to convert a BlockDeviceMapping object into an old-\nstyle dict. This trips over a common problem with objects where\nthings expecting a list or a dict decide the object is a dict and\ntry to iterate it as such.\n\nThis makes the small tweak necessary and adds a test that verifies\nthat it works.\n\nChange-Id: I98fe496720ad1c4fce44c0c7fea8bfa1c2721812\n""}]",0,78755,31a4ffc49cd3f11adb9e61b2ff70d7e742515e51,16,9,2,4393,,,0,"Fix BDM legacy usage with objects

When we're doing an upgrade against Havana, our backleveled
compute RPC version will cause us to run block_device.legacy_mapping(),
which attempts to convert a BlockDeviceMapping object into an old-
style dict. This trips over a common problem with objects where
things expecting a list or a dict decide the object is a dict and
try to iterate it as such.

This makes the small tweak necessary and adds a test that verifies
that it works.

Change-Id: I98fe496720ad1c4fce44c0c7fea8bfa1c2721812
",git fetch https://review.opendev.org/openstack/nova refs/changes/55/78755/1 && git format-patch -1 --stdout FETCH_HEAD,"['nova/tests/test_block_device.py', 'nova/block_device.py']",2,6222dcb931df851eb96126eba7ffd7710cd69264,fix-bdm-legacy, self.update(bdm_dict.items()), self.update(bdm_dict),14,1
openstack%2Fnova~master~I63e0302cffe33b05722579e7d9c7122f2f257843,openstack/nova,master,I63e0302cffe33b05722579e7d9c7122f2f257843,Fix development environment docs for redhat-based systems,MERGED,2014-03-06 00:13:37.000000000,2014-03-07 04:26:35.000000000,2014-03-06 12:59:13.000000000,"[{'_account_id': 3}, {'_account_id': 1653}, {'_account_id': 1812}, {'_account_id': 2750}, {'_account_id': 9578}]","[{'number': 1, 'created': '2014-03-06 00:13:37.000000000', 'files': ['doc/source/devref/development.environment.rst'], 'web_link': 'https://opendev.org/openstack/nova/commit/226fd5080b1c5262a0b165c9b03a60a269c58c1f', 'message': 'Fix development environment docs for redhat-based systems\n\nThis adds the new libffi-devel dependency to the devref for new\ndevelopment environment creation.\n\nChange-Id: I63e0302cffe33b05722579e7d9c7122f2f257843\n'}]",0,78470,226fd5080b1c5262a0b165c9b03a60a269c58c1f,11,5,1,4393,,,0,"Fix development environment docs for redhat-based systems

This adds the new libffi-devel dependency to the devref for new
development environment creation.

Change-Id: I63e0302cffe33b05722579e7d9c7122f2f257843
",git fetch https://review.opendev.org/openstack/nova refs/changes/70/78470/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/source/devref/development.environment.rst'],1,226fd5080b1c5262a0b165c9b03a60a269c58c1f,fix-fedora-doc, sudo yum install python-devel openssl-devel python-pip git gcc libxslt-devel mysql-devel python-pip postgresql-devel libffi-devel, sudo yum install python-devel openssl-devel python-pip git gcc libxslt-devel mysql-devel python-pip postgresql-devel,1,1
openstack%2Fnova~master~I5092b9cceba37103abf6c6179ddd67f3d1b16ebe,openstack/nova,master,I5092b9cceba37103abf6c6179ddd67f3d1b16ebe,VMware: Add utility method to retrieve remote objects,ABANDONED,2014-02-25 18:53:52.000000000,2014-03-07 04:00:58.000000000,,"[{'_account_id': 3}, {'_account_id': 1653}, {'_account_id': 1779}, {'_account_id': 5170}, {'_account_id': 7693}, {'_account_id': 8027}, {'_account_id': 9008}, {'_account_id': 9578}]","[{'number': 3, 'created': '2014-02-25 18:53:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/a5606b1fddb32f65634e68b268d333bb04c0cfe0', 'message': 'VMware: Add utility method to retrieve remote objects\n\nAdded a utility method that can retrieve the properties of objects\nthat are within a parent object in the vCenter server. With\nexisting utility methods, this is not possible without making multiple\napi calls.\n\nPartial-bug: #1272286\n\nChange-Id: I5092b9cceba37103abf6c6179ddd67f3d1b16ebe\n'}, {'number': 2, 'created': '2014-02-25 18:53:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/9655a1a9db18b5db0499686474fb29dde4d8da33', 'message': 'VMware: Add utility method to retrieve remote objects\n\nAdded a utility method that can retrieve the properties of objects\nthat are within a parent object in the vCenter server. With\nexisting utility methods, this is not possible without making multiple\napi calls.\n\nPartial-bug: #1272286\n\nChange-Id: I5092b9cceba37103abf6c6179ddd67f3d1b16ebe\n'}, {'number': 1, 'created': '2014-02-25 18:53:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/45652d4e9f113c8cac9878d484f52a07bcb35a95', 'message': 'VMware: Add utility method to retrieve remote objects\n\nAdded a utility method that can retrieve the properties of objects\nthat are within a parent object in the vCenter server. With\nexisting utility methods, this is not possible without making multiple\napi calls.\n\nPartial-bug: #1272286\n\nChange-Id: I5092b9cceba37103abf6c6179ddd67f3d1b16ebe\n'}]",1,76317,a5606b1fddb32f65634e68b268d333bb04c0cfe0,28,8,3,7575,,,0,"VMware: Add utility method to retrieve remote objects

Added a utility method that can retrieve the properties of objects
that are within a parent object in the vCenter server. With
existing utility methods, this is not possible without making multiple
api calls.

Partial-bug: #1272286

Change-Id: I5092b9cceba37103abf6c6179ddd67f3d1b16ebe
",git fetch https://review.opendev.org/openstack/nova refs/changes/17/76317/3 && git format-patch -1 --stdout FETCH_HEAD,[],0,a5606b1fddb32f65634e68b268d333bb04c0cfe0,use_inner_objects,,,0,0
openstack%2Fnova~master~If87cc7fdb1ebcfa2a1d33f5e864c43ed0290beb6,openstack/nova,master,If87cc7fdb1ebcfa2a1d33f5e864c43ed0290beb6,Add external_instance_event() method to compute manager,MERGED,2014-02-19 00:28:30.000000000,2014-03-07 03:56:31.000000000,2014-03-07 01:54:40.000000000,"[{'_account_id': 3}, {'_account_id': 642}, {'_account_id': 679}, {'_account_id': 1030}, {'_account_id': 1561}, {'_account_id': 1653}, {'_account_id': 2271}, {'_account_id': 4393}, {'_account_id': 4395}, {'_account_id': 4912}, {'_account_id': 5170}, {'_account_id': 5292}, {'_account_id': 6681}, {'_account_id': 7494}, {'_account_id': 9008}, {'_account_id': 9578}]","[{'number': 1, 'created': '2014-02-19 00:28:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/d5bd248194ed6224f4eaf87ac37029de503c93f9', 'message': 'WIP Add external_instance_event() method to compute manager\n\nThis would allow external services to send notifications in to\nthe compute manager, which could have one or more threads waiting\nto be unblocked. It would also provide a way for us to process\ngeneric events like ""update your instance cache for $instance"".\n\nChange-Id: If87cc7fdb1ebcfa2a1d33f5e864c43ed0290beb6\n'}, {'number': 2, 'created': '2014-02-19 02:30:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/d75fa492f67e8a357f0c7ce35fe81070e2c0e8b3', 'message': 'WIP Add external_instance_event() method to compute manager\n\nThis would allow external services to send notifications in to\nthe compute manager, which could have one or more threads waiting\nto be unblocked. It would also provide a way for us to process\ngeneric events like ""update your instance cache for $instance"".\n\nChange-Id: If87cc7fdb1ebcfa2a1d33f5e864c43ed0290beb6\n'}, {'number': 3, 'created': '2014-02-19 02:33:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/e1fc39d42246a79539dd42f89fcaa0ee02fd2ad3', 'message': 'WIP Add external_instance_event() method to compute manager\n\nThis would allow external services to send notifications in to\nthe compute manager, which could have one or more threads waiting\nto be unblocked. It would also provide a way for us to process\ngeneric events like ""update your instance cache for $instance"".\n\nChange-Id: If87cc7fdb1ebcfa2a1d33f5e864c43ed0290beb6\n'}, {'number': 4, 'created': '2014-02-19 03:19:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/883b329621ebb7839b956a864781167d98a3445b', 'message': 'WIP Add external_instance_event() method to compute manager\n\nThis would allow external services to send notifications in to\nthe compute manager, which could have one or more threads waiting\nto be unblocked. It would also provide a way for us to process\ngeneric events like ""update your instance cache for $instance"".\n\nChange-Id: If87cc7fdb1ebcfa2a1d33f5e864c43ed0290beb6\n'}, {'number': 5, 'created': '2014-02-19 19:22:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/1ab02addd0f8e858b769b8d93cb45e1058b21e15', 'message': 'WIP Add external_instance_event() method to compute manager\n\nThis would allow external services to send notifications in to\nthe compute manager, which could have one or more threads waiting\nto be unblocked. It would also provide a way for us to process\ngeneric events like ""update your instance cache for $instance"".\n\nRelated to blueprint admin-event-callback-api\n\nChange-Id: If87cc7fdb1ebcfa2a1d33f5e864c43ed0290beb6\n'}, {'number': 6, 'created': '2014-02-20 01:47:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/ad8303224356cce539c4abcbd845454b3fc2df05', 'message': 'WIP Add external_instance_event() method to compute manager\n\nThis would allow external services to send notifications in to\nthe compute manager, which could have one or more threads waiting\nto be unblocked. It would also provide a way for us to process\ngeneric events like ""update your instance cache for $instance"".\n\nRelated to blueprint admin-event-callback-api\n\nChange-Id: If87cc7fdb1ebcfa2a1d33f5e864c43ed0290beb6\n'}, {'number': 7, 'created': '2014-02-20 19:01:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/1af145d763591d1e2cd9066157770f25894728c5', 'message': 'WIP Add external_instance_event() method to compute manager\n\nThis would allow external services to send notifications in to\nthe compute manager, which could have one or more threads waiting\nto be unblocked. It would also provide a way for us to process\ngeneric events like ""update your instance cache for $instance"".\n\nRelated to blueprint admin-event-callback-api\n\nChange-Id: If87cc7fdb1ebcfa2a1d33f5e864c43ed0290beb6\n'}, {'number': 8, 'created': '2014-02-20 21:02:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/d80f478aa0f060d666da465dee9258523667b94d', 'message': 'WIP Add external_instance_event() method to compute manager\n\nThis would allow external services to send notifications in to\nthe compute manager, which could have one or more threads waiting\nto be unblocked. It would also provide a way for us to process\ngeneric events like ""update your instance cache for $instance"".\n\nRelated to blueprint admin-event-callback-api\n\nChange-Id: If87cc7fdb1ebcfa2a1d33f5e864c43ed0290beb6\n'}, {'number': 9, 'created': '2014-02-20 22:27:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/5e57d4493e85549f73a3feedbac7a2a8f8501c2e', 'message': 'WIP Add external_instance_event() method to compute manager\n\nThis would allow external services to send notifications in to\nthe compute manager, which could have one or more threads waiting\nto be unblocked. It would also provide a way for us to process\ngeneric events like ""update your instance cache for $instance"".\n\nRelated to blueprint admin-event-callback-api\n\nChange-Id: If87cc7fdb1ebcfa2a1d33f5e864c43ed0290beb6\n'}, {'number': 10, 'created': '2014-02-20 23:01:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/bf56a181202c381eb7b68ce1318e4ae3f5e9f49d', 'message': 'WIP Add external_instance_event() method to compute manager\n\nThis would allow external services to send notifications in to\nthe compute manager, which could have one or more threads waiting\nto be unblocked. It would also provide a way for us to process\ngeneric events like ""update your instance cache for $instance"".\n\nRelated to blueprint admin-event-callback-api\n\nChange-Id: If87cc7fdb1ebcfa2a1d33f5e864c43ed0290beb6\n'}, {'number': 11, 'created': '2014-02-24 16:41:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/24c2113cdc63ef2bc013fec7d4039fb720b89930', 'message': 'Add external_instance_event() method to compute manager\n\nThis would allow external services to send notifications in to\nthe compute manager, which could have one or more threads waiting\nto be unblocked. It would also provide a way for us to process\ngeneric events like ""update your instance cache for $instance"".\n\nRelated to blueprint admin-event-callback-api\n\nChange-Id: If87cc7fdb1ebcfa2a1d33f5e864c43ed0290beb6\n'}, {'number': 12, 'created': '2014-02-25 16:12:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/a03023a30b449f5c18889c8c810ca33b7d70cfc2', 'message': 'Add external_instance_event() method to compute manager\n\nThis would allow external services to send notifications in to\nthe compute manager, which could have one or more threads waiting\nto be unblocked. It would also provide a way for us to process\ngeneric events like ""update your instance cache for $instance"".\n\nRelated to blueprint admin-event-callback-api\n\nChange-Id: If87cc7fdb1ebcfa2a1d33f5e864c43ed0290beb6\n'}, {'number': 13, 'created': '2014-02-25 18:40:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/2017bd65fb17af5d72152ffaf1153232ad3473ec', 'message': 'Add external_instance_event() method to compute manager\n\nThis would allow external services to send notifications in to\nthe compute manager, which could have one or more threads waiting\nto be unblocked. It would also provide a way for us to process\ngeneric events like ""update your instance cache for $instance"".\n\nRelated to blueprint admin-event-callback-api\n\nChange-Id: If87cc7fdb1ebcfa2a1d33f5e864c43ed0290beb6\n'}, {'number': 14, 'created': '2014-02-25 20:47:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/d282f27dad5a7a85701db891e0aaf0c36ad1fb4f', 'message': 'Add external_instance_event() method to compute manager\n\nThis would allow external services to send notifications in to\nthe compute manager, which could have one or more threads waiting\nto be unblocked. It would also provide a way for us to process\ngeneric events like ""update your instance cache for $instance"".\n\nRelated to blueprint admin-event-callback-api\n\nChange-Id: If87cc7fdb1ebcfa2a1d33f5e864c43ed0290beb6\n'}, {'number': 15, 'created': '2014-02-26 15:58:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/f7be7be5405c8edfb627b359f1975c2190fd187a', 'message': 'Add external_instance_event() method to compute manager\n\nThis would allow external services to send notifications in to\nthe compute manager, which could have one or more threads waiting\nto be unblocked. It would also provide a way for us to process\ngeneric events like ""update your instance cache for $instance"".\n\nRelated to blueprint admin-event-callback-api\n\nChange-Id: If87cc7fdb1ebcfa2a1d33f5e864c43ed0290beb6\n'}, {'number': 16, 'created': '2014-02-26 18:07:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/1cfd59341c886ed8c37f24abf2dbd921f538fd2f', 'message': 'Add external_instance_event() method to compute manager\n\nThis would allow external services to send notifications in to\nthe compute manager, which could have one or more threads waiting\nto be unblocked. It would also provide a way for us to process\ngeneric events like ""update your instance cache for $instance"".\n\nRelated to blueprint admin-event-callback-api\n\nChange-Id: If87cc7fdb1ebcfa2a1d33f5e864c43ed0290beb6\n'}, {'number': 17, 'created': '2014-03-03 18:32:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/32fb525eebcb547a3298464393969af6a6777518', 'message': 'Add external_instance_event() method to compute manager\n\nThis would allow external services to send notifications in to\nthe compute manager, which could have one or more threads waiting\nto be unblocked. It would also provide a way for us to process\ngeneric events like ""update your instance cache for $instance"".\n\nRelated to blueprint admin-event-callback-api\n\nChange-Id: If87cc7fdb1ebcfa2a1d33f5e864c43ed0290beb6\n'}, {'number': 18, 'created': '2014-03-05 16:39:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/01efc38a5fa3119fdc5c91dc0fac93c8369ccdd3', 'message': 'Add external_instance_event() method to compute manager\n\nThis would allow external services to send notifications in to\nthe compute manager, which could have one or more threads waiting\nto be unblocked. It would also provide a way for us to process\ngeneric events like ""update your instance cache for $instance"".\n\nRelated to blueprint admin-event-callback-api\n\nChange-Id: If87cc7fdb1ebcfa2a1d33f5e864c43ed0290beb6\n'}, {'number': 19, 'created': '2014-03-05 22:37:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/ccad6fb793ae5f818a0f0ba88c9e49f71c35b65e', 'message': 'Add external_instance_event() method to compute manager\n\nThis would allow external services to send notifications in to\nthe compute manager, which could have one or more threads waiting\nto be unblocked. It would also provide a way for us to process\ngeneric events like ""update your instance cache for $instance"".\n\nRelated to blueprint admin-event-callback-api\n\nChange-Id: If87cc7fdb1ebcfa2a1d33f5e864c43ed0290beb6\n'}, {'number': 20, 'created': '2014-03-06 15:41:39.000000000', 'files': ['nova/tests/compute/test_compute_api.py', 'nova/tests/compute/test_compute_mgr.py', 'nova/tests/objects/test_external_event.py', 'nova/tests/compute/test_rpcapi.py', 'nova/compute/manager.py', 'nova/compute/rpcapi.py', 'nova/compute/api.py', 'nova/objects/external_event.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/a7b5b975a48f132afa0fc8717c72ab3cb1f6545a', 'message': 'Add external_instance_event() method to compute manager\n\nThis would allow external services to send notifications in to\nthe compute manager, which could have one or more threads waiting\nto be unblocked. It would also provide a way for us to process\ngeneric events like ""update your instance cache for $instance"".\n\nRelated to blueprint admin-event-callback-api\n\nChange-Id: If87cc7fdb1ebcfa2a1d33f5e864c43ed0290beb6\n'}]",50,74540,a7b5b975a48f132afa0fc8717c72ab3cb1f6545a,156,16,20,4393,,,0,"Add external_instance_event() method to compute manager

This would allow external services to send notifications in to
the compute manager, which could have one or more threads waiting
to be unblocked. It would also provide a way for us to process
generic events like ""update your instance cache for $instance"".

Related to blueprint admin-event-callback-api

Change-Id: If87cc7fdb1ebcfa2a1d33f5e864c43ed0290beb6
",git fetch https://review.opendev.org/openstack/nova refs/changes/40/74540/20 && git format-patch -1 --stdout FETCH_HEAD,"['nova/tests/compute/test_compute_mgr.py', 'nova/compute/manager.py', 'nova/compute/rpcapi.py', 'nova/compute/api.py']",4,d5bd248194ed6224f4eaf87ac37029de503c93f9,bp/admin-event-callback-api," @wrap_check_policy def external_instance_event(self, context, instance, event): self.compute_rpcapi.external_instance_event(context, instance, event) ",,82,1
openstack%2Ffuel-docs~master~I202de73d6b8b93ee6bad43c9b0906d97df72f4b1,openstack/fuel-docs,master,I202de73d6b8b93ee6bad43c9b0906d97df72f4b1,Move custom distro instructions out of core docs,MERGED,2014-02-27 02:09:36.000000000,2014-03-07 02:42:22.000000000,2014-03-07 02:42:22.000000000,"[{'_account_id': 3}, {'_account_id': 406}, {'_account_id': 8787}, {'_account_id': 8971}, {'_account_id': 9765}, {'_account_id': 10014}]","[{'number': 1, 'created': '2014-02-27 02:09:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-docs/commit/216cdd2f9f778b64371a47116f9ed2777d4e1e75', 'message': 'Remove all Red Hat references\n\nChange-Id: I202de73d6b8b93ee6bad43c9b0906d97df72f4b1\n'}, {'number': 2, 'created': '2014-02-27 08:41:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-docs/commit/aee36be2212cf8d32f22a5c93cd8a739295ccd92', 'message': 'Remove all Red Hat references\n\nChange-Id: I202de73d6b8b93ee6bad43c9b0906d97df72f4b1\n'}, {'number': 3, 'created': '2014-03-07 02:38:47.000000000', 'files': ['_images/deployment-ha-compact-red-hat.svg', 'pages/reference-architecture/0018-red-hat-differences.rst', 'pages/release-notes/v4-1/040-resolved-issues.rst', 'pages/install-guide/install.rst', 'pages/user-guide/red_hat_openstack.rst', 'user-guide.rst', 'reference-architecture.rst', 'pages/release-notes/v4-1/070-support.rst', 'pages/pre-install-guide/0091-glossary.rst', 'pages/release-notes/v4-1/050-known-issues.rst', '_images/deployment-simple-red-hat.svg', 'contents/contents-refarch.rst', 'pages/pre-install-guide/0020-system-requirements.rst', 'pages/pre-install-guide/0031-fuel-configuration.rst', 'pages/reference-architecture/0010-overview.rst', '_images/ha-overview-red-hat.svg', 'contents/contents-user.rst', 'pages/install-guide/0000-intro.rst'], 'web_link': 'https://opendev.org/openstack/fuel-docs/commit/eee9d8442ca4b94f3163c5413502624c31cb3426', 'message': 'Move custom distro instructions out of core docs\n\nChange-Id: I202de73d6b8b93ee6bad43c9b0906d97df72f4b1\n'}]",1,76731,eee9d8442ca4b94f3163c5413502624c31cb3426,26,6,3,10014,,,0,"Move custom distro instructions out of core docs

Change-Id: I202de73d6b8b93ee6bad43c9b0906d97df72f4b1
",git fetch https://review.opendev.org/openstack/fuel-docs refs/changes/31/76731/1 && git format-patch -1 --stdout FETCH_HEAD,"['pages/release-notes/v4-1/040-resolved-issues.rst', 'pages/install-guide/install.rst', 'user-guide.rst', 'reference-architecture.rst', 'pages/release-notes/v4-1/070-support.rst', 'pages/pre-install-guide/0091-glossary.rst', 'pages/release-notes/v4-1/050-known-issues.rst', 'contents/contents-refarch.rst', 'pages/pre-install-guide/0020-system-requirements.rst', 'pages/pre-install-guide/0031-fuel-configuration.rst', 'pages/reference-architecture/0010-overview.rst', 'contents/contents-user.rst', 'pages/install-guide/0000-intro.rst']",13,216cdd2f9f778b64371a47116f9ed2777d4e1e75,distro-cleanup,, * RHEL 6.4 (x86_64 architecture only),11,84
openstack%2Fironic~master~I509a9feefc67f7d7be221abbc2ffa3b7b720b3ea,openstack/ironic,master,I509a9feefc67f7d7be221abbc2ffa3b7b720b3ea,Pin iso8601 logging to WARN,MERGED,2014-03-06 22:00:03.000000000,2014-03-07 02:29:09.000000000,2014-03-07 02:29:09.000000000,"[{'_account_id': 3}, {'_account_id': 2889}, {'_account_id': 6773}]","[{'number': 1, 'created': '2014-03-06 22:00:03.000000000', 'files': ['ironic/common/service.py'], 'web_link': 'https://opendev.org/openstack/ironic/commit/5dbdee5fd97882069c03250e3d24fbef7e40e9f7', 'message': 'Pin iso8601 logging to WARN\n\nAPI logs are filled with iso8601 noise when the log level is set\nto DEBUG. This set it to WARN.\n\nChange-Id: I509a9feefc67f7d7be221abbc2ffa3b7b720b3ea\n'}]",0,78784,5dbdee5fd97882069c03250e3d24fbef7e40e9f7,16,3,1,3099,,,0,"Pin iso8601 logging to WARN

API logs are filled with iso8601 noise when the log level is set
to DEBUG. This set it to WARN.

Change-Id: I509a9feefc67f7d7be221abbc2ffa3b7b720b3ea
",git fetch https://review.opendev.org/openstack/ironic refs/changes/84/78784/1 && git format-patch -1 --stdout FETCH_HEAD,['ironic/common/service.py'],1,5dbdee5fd97882069c03250e3d24fbef7e40e9f7,dev," 'eventlet.wsgi.server=WARN', 'iso8601=WARN'", 'eventlet.wsgi.server=WARN',2,1
openstack%2Fheat~stable%2Fhavana~I5da09aa08a1242c5e356bd8bf532baa9347ce075,openstack/heat,stable/havana,I5da09aa08a1242c5e356bd8bf532baa9347ce075,Raise the default max header to accommodate large tokens,MERGED,2014-02-24 07:56:10.000000000,2014-03-07 02:24:48.000000000,2014-02-28 12:22:23.000000000,"[{'_account_id': 3}, {'_account_id': 4328}, {'_account_id': 4571}, {'_account_id': 10018}]","[{'number': 1, 'created': '2014-02-24 07:56:10.000000000', 'files': ['etc/heat/heat.conf.sample', 'heat/common/wsgi.py'], 'web_link': 'https://opendev.org/openstack/heat/commit/defcf235c158e93938c93f556383939515852c88', 'message': 'Raise the default max header to accommodate large tokens\n\nPKI tokens hit the default limit if there is enough\nservices defined in the keystone catalog.\n\nAlso the v3 catalog is larger than the v2 catalog which would explain\nwhy this bug is being hit just now.\n\nThis change adds the configuration option max_header_line to each of the\nAPI confurations which has a default of 16384.\n\nCloses-Bug: #1190149\nChange-Id: I5da09aa08a1242c5e356bd8bf532baa9347ce075\n(cherry picked from commit 0b02feb20d4485d0c6d486c5a72b814ce3bdf9e5)\n'}]",0,75784,defcf235c158e93938c93f556383939515852c88,15,4,1,10018,,,0,"Raise the default max header to accommodate large tokens

PKI tokens hit the default limit if there is enough
services defined in the keystone catalog.

Also the v3 catalog is larger than the v2 catalog which would explain
why this bug is being hit just now.

This change adds the configuration option max_header_line to each of the
API confurations which has a default of 16384.

Closes-Bug: #1190149
Change-Id: I5da09aa08a1242c5e356bd8bf532baa9347ce075
(cherry picked from commit 0b02feb20d4485d0c6d486c5a72b814ce3bdf9e5)
",git fetch https://review.opendev.org/openstack/heat refs/changes/84/75784/1 && git format-patch -1 --stdout FETCH_HEAD,"['etc/heat/heat.conf.sample', 'heat/common/wsgi.py']",2,defcf235c158e93938c93f556383939515852c88,bug/1190149," cfg.IntOpt('max_header_line', default=16384, help=_('Maximum line size of message headers to be accepted. ' 'max_header_line may need to be increased when using ' 'large tokens (typically those generated by the ' 'Keystone v3 API with big service catalogs')), cfg.IntOpt('max_header_line', default=16384, help=_('Maximum line size of message headers to be accepted. ' 'max_header_line may need to be increased when using ' 'large tokens (typically those generated by the ' 'Keystone v3 API with big service catalogs')), cfg.IntOpt('max_header_line', default=16384, help=_('Maximum line size of message headers to be accepted. ' 'max_header_line may need to be increased when using ' 'large tokens (typically those generated by the ' 'Keystone v3 API with big service catalogs')), eventlet.wsgi.MAX_HEADER_LINE = conf.max_header_line",,34,0
openstack-attic%2Fmelange~master~If9d8a2a26866ab5fce414ca6b48468bce2ab4eb8,openstack-attic/melange,master,If9d8a2a26866ab5fce414ca6b48468bce2ab4eb8,Fix misspellings in melange,ABANDONED,2014-02-07 05:50:54.000000000,2014-03-07 02:24:45.000000000,,[],"[{'number': 1, 'created': '2014-02-07 05:50:54.000000000', 'files': ['melange/tests/unit/test_ipam_service.py', 'melange/tests/unit/test_ipam_models.py', 'melange/tests/unit/test_utils.py', 'melange/tests/unit/test_wsgi.py'], 'web_link': 'https://opendev.org/openstack-attic/melange/commit/543219b9e17c9f890e1b6ddb0231905254897b84', 'message': 'Fix misspellings in melange\n\nFix misspellings detected by:\n* pip install misspellings\n* git ls-files | grep -v locale | misspellings -f -\n\nChange-Id: If9d8a2a26866ab5fce414ca6b48468bce2ab4eb8\nCloses-Bug: #1257295\n'}]",0,71753,543219b9e17c9f890e1b6ddb0231905254897b84,1,0,1,4458,,,0,"Fix misspellings in melange

Fix misspellings detected by:
* pip install misspellings
* git ls-files | grep -v locale | misspellings -f -

Change-Id: If9d8a2a26866ab5fce414ca6b48468bce2ab4eb8
Closes-Bug: #1257295
",git fetch https://review.opendev.org/openstack-attic/melange refs/changes/53/71753/1 && git format-patch -1 --stdout FETCH_HEAD,"['melange/tests/unit/test_ipam_service.py', 'melange/tests/unit/test_ipam_models.py', 'melange/tests/unit/test_utils.py', 'melange/tests/unit/test_wsgi.py']",4,543219b9e17c9f890e1b6ddb0231905254897b84,, def test_delegates_to_urlmapper_for_nonexistent_version_of_app(self):, def test_delegates_to_urlmapper_for_nonexistant_version_of_app(self):,21,21
openstack-attic%2Fpython-melangeclient~master~I1ae479600de842107294e20a079ce67b70513d19,openstack-attic/python-melangeclient,master,I1ae479600de842107294e20a079ce67b70513d19,Fix misspellings in python melangeclient,ABANDONED,2014-02-07 05:39:36.000000000,2014-03-07 02:24:37.000000000,,[],"[{'number': 1, 'created': '2014-02-07 05:39:36.000000000', 'files': ['melange/client/template.py', 'melange/client/tests/unit/test_client.py', 'melange/client/client.py'], 'web_link': 'https://opendev.org/openstack-attic/python-melangeclient/commit/d8a7042bd9e9110988081309403e5f1f5715e5e3', 'message': 'Fix misspellings in python melangeclient\n\nFix misspellings detected by:\n* pip install misspellings\n* git ls-files | grep -v locale | misspellings -f -\n\nChange-Id: I1ae479600de842107294e20a079ce67b70513d19\nCloses-Bug: #1257295\n'}]",0,71748,d8a7042bd9e9110988081309403e5f1f5715e5e3,1,0,1,4458,,,0,"Fix misspellings in python melangeclient

Fix misspellings detected by:
* pip install misspellings
* git ls-files | grep -v locale | misspellings -f -

Change-Id: I1ae479600de842107294e20a079ce67b70513d19
Closes-Bug: #1257295
",git fetch https://review.opendev.org/openstack-attic/python-melangeclient refs/changes/48/71748/1 && git format-patch -1 --stdout FETCH_HEAD,"['melange/client/template.py', 'melange/client/client.py', 'melange/client/tests/unit/test_client.py']",3,d8a7042bd9e9110988081309403e5f1f5715e5e3,," expected_error_msg = (""Error occurred while retrieving token :"""," expected_error_msg = (""Error occured while retrieving token :""",4,4
openstack%2Fsolum~master~I4f67d834931490c95a019c5d399efc3ab913d9dc,openstack/solum,master,I4f67d834931490c95a019c5d399efc3ab913d9dc,Made build-app tenant aware,MERGED,2014-03-05 19:26:24.000000000,2014-03-07 02:24:04.000000000,2014-03-07 02:24:04.000000000,"[{'_account_id': 3}, {'_account_id': 668}, {'_account_id': 2506}, {'_account_id': 4715}, {'_account_id': 7858}, {'_account_id': 8334}, {'_account_id': 8443}, {'_account_id': 9095}, {'_account_id': 9113}]","[{'number': 1, 'created': '2014-03-05 19:26:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/solum/commit/199ecd3c658ed84a93726c391e66804415b9973f', 'message': 'Made build-app tenant aware\n- Mainly the above\n- Plus small bit of refactoring\n\nChange-Id: I4f67d834931490c95a019c5d399efc3ab913d9dc\n'}, {'number': 2, 'created': '2014-03-05 19:49:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/solum/commit/3253a61f4d65df518467d7da03f809a37df509b0', 'message': 'Made build-app tenant aware\n\nChange-Id: I4f67d834931490c95a019c5d399efc3ab913d9dc\n'}, {'number': 3, 'created': '2014-03-06 16:16:10.000000000', 'files': ['contrib/lp-cedarish/vm-slug/build-app'], 'web_link': 'https://opendev.org/openstack/solum/commit/19fe27cb44f3e1dabc66380a2635cc2f27161fcf', 'message': 'Made build-app tenant aware\n\nChange-Id: I4f67d834931490c95a019c5d399efc3ab913d9dc\n'}]",8,78378,19fe27cb44f3e1dabc66380a2635cc2f27161fcf,24,9,3,2506,,,0,"Made build-app tenant aware

Change-Id: I4f67d834931490c95a019c5d399efc3ab913d9dc
",git fetch https://review.opendev.org/openstack/solum refs/changes/78/78378/2 && git format-patch -1 --stdout FETCH_HEAD,['contrib/lp-cedarish/vm-slug/build-app'],1,199ecd3c658ed84a93726c391e66804415b9973f,,TENANT=$1APP_DIR=/opt/solum/apps/$TENANT/$APP[[ -d $APP_DIR/build ]] && rm -rf $APP_DIR/buildcat << EOF > /opt/solum/apps/$TENANT/$APP/user-data.txtPRIV_KEY_PATH=/opt/solum/apps/$TENANT/$APP/key.priv [[ `nova keypair-list | grep $APP | wc -l` == 0 ]] && nova keypair-add ${APP}_key > $PRIV_KEY_PATH chmod 0600 $PRIV_KEY_PATH,APP_DIR=/opt/solum/apps/$APP[[ -d /opt/solum/apps/$APP/build ]] && rm -rf $APP_DIR/buildcat << EOF > /opt/solum/apps/$APP/user-data.txt [[ `nova keypair-list | grep $APP | wc -l` == 0 ]] && nova keypair-add ${APP}_key > /opt/solum/apps/$APP/key.priv chmod 0600 /opt/solum/apps/$APP/key.priv,7,6
openstack%2Fsolum~master~I040d207d57bb7b85082745c2ac9940b5b9c1f441,openstack/solum,master,I040d207d57bb7b85082745c2ac9940b5b9c1f441,Delegate to the handler when a trigger is posted,MERGED,2014-02-05 15:37:09.000000000,2014-03-07 02:22:44.000000000,2014-03-07 02:22:44.000000000,"[{'_account_id': 3}, {'_account_id': 668}, {'_account_id': 4715}, {'_account_id': 8334}, {'_account_id': 8443}, {'_account_id': 9094}, {'_account_id': 9095}, {'_account_id': 9537}, {'_account_id': 9808}]","[{'number': 1, 'created': '2014-02-05 15:37:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/solum/commit/701d5306175d730804e29cbc51111d4fb987a51f', 'message': ""Check plan existence when a trigger is posted\n\nWhen the Trigger endpoint is called, the corresponding plan is\nretrieved using the 'get_by_trigger_id' method. I added a comment\nwhere the zuul workflow should be called\n\nChange-Id: I040d207d57bb7b85082745c2ac9940b5b9c1f441\n""}, {'number': 2, 'created': '2014-02-06 10:19:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/solum/commit/df41e451653ecb5401edc52df8a420b90e3e2319', 'message': ""Check plan existence when a trigger is posted\n\nWhen the Trigger endpoint is called, the corresponding plan is\nretrieved using the 'get_by_trigger_id' method. I added a comment\nwhere the zuul workflow should be called\n\nChange-Id: I040d207d57bb7b85082745c2ac9940b5b9c1f441\n""}, {'number': 3, 'created': '2014-02-07 15:38:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/solum/commit/12e4bc884d0ab5fa5fca48a8db4e94aa61e630f6', 'message': ""Check plan existence when a trigger is posted\n\nWhen the Trigger endpoint is called, the corresponding plan is\nretrieved using the 'get_by_trigger_id' method. I added a comment\nwhere the zuul workflow should be called\n\nChange-Id: I040d207d57bb7b85082745c2ac9940b5b9c1f441\n""}, {'number': 4, 'created': '2014-02-07 15:45:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/solum/commit/897108cce3c8b493dadb5ac0453b67606fcecf46', 'message': ""Check plan existence when a trigger is posted\n\nWhen the Trigger endpoint is called, the corresponding plan is\nretrieved using the 'get_by_trigger_id' method. I added a comment\nwhere the zuul workflow should be called\n\nChange-Id: I040d207d57bb7b85082745c2ac9940b5b9c1f441\n""}, {'number': 5, 'created': '2014-02-07 16:01:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/solum/commit/4247964c2c39d8bfe3969b6bcd09535ec29c0ebf', 'message': ""Check plan existence when a trigger is posted\n\nWhen the Trigger endpoint is called, the corresponding plan is\nretrieved using the 'get_by_trigger_id' method. I added a comment\nwhere the zuul workflow should be called\n\nChange-Id: I040d207d57bb7b85082745c2ac9940b5b9c1f441\n""}, {'number': 6, 'created': '2014-02-10 17:18:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/solum/commit/637773002430b387f455aff683a4ae44f5714d65', 'message': ""Check plan existence when a trigger is posted\n\nWhen the Trigger endpoint is called, the corresponding plan is\nretrieved using the 'get_by_trigger_id' method. I added a comment\nwhere the zuul workflow should be called\n\nChange-Id: I040d207d57bb7b85082745c2ac9940b5b9c1f441\n""}, {'number': 7, 'created': '2014-02-12 09:28:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/solum/commit/c55501c850485003a4d85a40e794110915367a1e', 'message': ""Check plan existence when a trigger is posted\n\nWhen the Trigger endpoint is called, the corresponding plan is\nretrieved using the 'get_by_trigger_id' method. I added a comment\nwhere the zuul workflow should be called\n\nChange-Id: I040d207d57bb7b85082745c2ac9940b5b9c1f441\n""}, {'number': 8, 'created': '2014-02-12 12:56:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/solum/commit/3f212cb5386ffe8619589b0f75ba3d246ccd9a72', 'message': ""Check plan existence when a trigger is posted\n\nWhen the Trigger endpoint is called, the corresponding plan is\nretrieved using the 'get_by_trigger_id' method. I added a comment\nwhere the zuul workflow should be called\n\nChange-Id: I040d207d57bb7b85082745c2ac9940b5b9c1f441\n""}, {'number': 9, 'created': '2014-02-12 14:06:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/solum/commit/76ed1ec9cdf756ff402cc5461e9a95868cd3d89e', 'message': ""Check plan existence when a trigger is posted\n\nWhen the Trigger endpoint is called, the corresponding plan is\nretrieved using the 'get_by_trigger_id' method. I added a comment\nwhere the zuul workflow should be called\n\nChange-Id: I040d207d57bb7b85082745c2ac9940b5b9c1f441\n""}, {'number': 10, 'created': '2014-02-12 14:28:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/solum/commit/22389ac71ee8c6d293e1728151d367dbfd0d51bd', 'message': ""Check plan existence when a trigger is posted\n\nWhen the Trigger endpoint is called, the corresponding plan is\nretrieved using the 'get_by_trigger_id' method. I added a comment\nwhere the zuul workflow should be called\n\nChange-Id: I040d207d57bb7b85082745c2ac9940b5b9c1f441\n""}, {'number': 11, 'created': '2014-02-13 13:58:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/solum/commit/679b32ed146c54e3b6c11bd30a4f74c3ee89ea4c', 'message': ""Check plan existence when a trigger is posted\n\nWhen the Trigger endpoint is called, the corresponding plan is\nretrieved using the 'get_by_trigger_id' method. I added a comment\nwhere the zuul workflow should be called\n\nChange-Id: I040d207d57bb7b85082745c2ac9940b5b9c1f441\n""}, {'number': 12, 'created': '2014-02-17 12:48:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/solum/commit/0cd173c9dd707552585c496f545dfd4629e1e21f', 'message': ""Check plan existence when a trigger is posted\n\nWhen the Trigger endpoint is called, the corresponding plan is\nretrieved using the 'get_by_trigger_id' method. I added a comment\nwhere the zuul workflow should be called\n\nChange-Id: I040d207d57bb7b85082745c2ac9940b5b9c1f441\n""}, {'number': 13, 'created': '2014-02-20 13:42:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/solum/commit/550bca8b22b8eee8aa37819dbb99c71b204a7349', 'message': ""Check if assembly exists when a trigger is posted\n\nWhen the Trigger endpoint is called, the corresponding assembly is\nretrieved using the 'get_by_trigger_id' method. I added a comment\nwhere the zuul/build workflow should be called\n\nChange-Id: I040d207d57bb7b85082745c2ac9940b5b9c1f441\n""}, {'number': 14, 'created': '2014-02-20 14:25:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/solum/commit/423e895b02e510c1a30f6ea15bd3499b14a75ec8', 'message': ""Check if assembly exists when a trigger is posted\n\nWhen the Trigger endpoint is called, the corresponding assembly is\nretrieved using the 'get_by_trigger_id' method. I added a comment\nwhere the zuul/build workflow should be called\n\nChange-Id: I040d207d57bb7b85082745c2ac9940b5b9c1f441\n""}, {'number': 15, 'created': '2014-02-25 10:00:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/solum/commit/f775747e37ac021587ecd514cf8d180cc61ef76e', 'message': ""Check if assembly exists when a trigger is posted\n\nWhen the Trigger endpoint is called, the corresponding assembly is\nretrieved using the 'get_by_trigger_id' method. I added a comment\nwhere the zuul/build workflow should be called\n\nChange-Id: I040d207d57bb7b85082745c2ac9940b5b9c1f441\n""}, {'number': 16, 'created': '2014-02-27 16:43:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/solum/commit/74123ebddb65fc988ffc73067624c2745f414008', 'message': 'Delegate to the handler when a trigger is posted\n\nChange-Id: I040d207d57bb7b85082745c2ac9940b5b9c1f441\n'}, {'number': 17, 'created': '2014-02-28 09:42:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/solum/commit/389aa75a92972c5cb539965dc9ed0a158f81f0ab', 'message': 'Delegate to the handler when a trigger is posted\n\nChange-Id: I040d207d57bb7b85082745c2ac9940b5b9c1f441\n'}, {'number': 18, 'created': '2014-02-28 10:20:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/solum/commit/82e04828e90f0343e27684e28b72bc700e1f01ff', 'message': 'Delegate to the handler when a trigger is posted\n\nChange-Id: I040d207d57bb7b85082745c2ac9940b5b9c1f441\n'}, {'number': 19, 'created': '2014-03-01 12:42:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/solum/commit/1724725dca72ebd59252b756b9211a1e320449cf', 'message': 'Delegate to the handler when a trigger is posted\n\nChange-Id: I040d207d57bb7b85082745c2ac9940b5b9c1f441\n'}, {'number': 20, 'created': '2014-03-03 09:11:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/solum/commit/878e89b6ed24f1810c4c3e057f415973e497b588', 'message': 'Delegate to the handler when a trigger is posted\n\nChange-Id: I040d207d57bb7b85082745c2ac9940b5b9c1f441\n'}, {'number': 21, 'created': '2014-03-03 16:04:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/solum/commit/6f8d4d7996edf9d16cd1c7039edb5eab72eeea7a', 'message': 'Delegate to the handler when a trigger is posted\n\nChange-Id: I040d207d57bb7b85082745c2ac9940b5b9c1f441\n'}, {'number': 22, 'created': '2014-03-03 16:50:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/solum/commit/b5f87a7da7f4eacd80c54068b788e161c59a5414', 'message': 'Delegate to the handler when a trigger is posted\n\nChange-Id: I040d207d57bb7b85082745c2ac9940b5b9c1f441\n'}, {'number': 23, 'created': '2014-03-04 09:47:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/solum/commit/8702639551638e9634ae01bb0ce3592a120ef119', 'message': 'Delegate to the handler when a trigger is posted\n\nChange-Id: I040d207d57bb7b85082745c2ac9940b5b9c1f441\n'}, {'number': 24, 'created': '2014-03-05 09:57:16.000000000', 'files': ['solum/api/controllers/v1/pub/trigger.py', 'functionaltests/api/v1/public/test_trigger.py', 'solum/tests/api/v1/public/test_trigger.py', 'solum/api/handlers/assembly_handler.py'], 'web_link': 'https://opendev.org/openstack/solum/commit/e2e15f498da8a0e364a7850a8de86688a9dfd16e', 'message': 'Delegate to the handler when a trigger is posted\n\nChange-Id: I040d207d57bb7b85082745c2ac9940b5b9c1f441\n'}]",12,71296,e2e15f498da8a0e364a7850a8de86688a9dfd16e,123,9,24,9537,,,0,"Delegate to the handler when a trigger is posted

Change-Id: I040d207d57bb7b85082745c2ac9940b5b9c1f441
",git fetch https://review.opendev.org/openstack/solum refs/changes/96/71296/21 && git format-patch -1 --stdout FETCH_HEAD,"['solum/api/controllers/v1/pub/trigger.py', 'solum/tests/api/v1/public/test_trigger.py', 'solum/api/handlers/plan_handler.py']",3,701d5306175d730804e29cbc51111d4fb987a51f,bp/zuul-endpoint," def get_by_trigger_id(self, id): """"""Return a plan."""""" return objects.registry.Plan.get_by_trigger_id(None, id) ",,19,7
openstack%2Fsolum~master~I4c4f99ec4083f2620abb231f77b3f76ab19da027,openstack/solum,master,I4c4f99ec4083f2620abb231f77b3f76ab19da027,Add trigger_id attribute to the 'assembly' db object,MERGED,2014-02-04 16:39:52.000000000,2014-03-07 02:22:43.000000000,2014-03-07 02:22:43.000000000,"[{'_account_id': 3}, {'_account_id': 668}, {'_account_id': 2506}, {'_account_id': 4715}, {'_account_id': 8334}, {'_account_id': 8443}, {'_account_id': 9095}, {'_account_id': 9113}, {'_account_id': 9537}, {'_account_id': 9808}]","[{'number': 1, 'created': '2014-02-04 16:39:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/solum/commit/f2135ac0ca0536eead6ca0b62a784555f8f3b768', 'message': ""Add trigger_id attribute to the 'plan' db object\n\nAlso impact this changes on API object and add method to get a\nplan by its trigger_id\nAdded migration script also\n\nChange-Id: I4c4f99ec4083f2620abb231f77b3f76ab19da027\n""}, {'number': 2, 'created': '2014-02-04 16:43:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/solum/commit/46cd0cda8936285c518f21cfbf7a76ece6fc98aa', 'message': ""Add trigger_id attribute to the 'plan' db object\n\nAlso impact this changes on API object and add method to get a\nplan by its trigger_id\nAdded migration script also\n\nChange-Id: I4c4f99ec4083f2620abb231f77b3f76ab19da027\n""}, {'number': 3, 'created': '2014-02-04 17:50:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/solum/commit/fea557023316e1923a862009a3c9f90d40b2b34d', 'message': ""Add trigger_id attribute to the 'plan' db object\n\nAlso impact this changes on API object and add method to get a\nplan by its trigger_id\nAdded migration script also\n\nChange-Id: I4c4f99ec4083f2620abb231f77b3f76ab19da027\n""}, {'number': 4, 'created': '2014-02-05 15:37:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/solum/commit/e9d3d850e1d91b5b880fa1c150a41487a59e3835', 'message': ""Add trigger_id attribute to the 'plan' db object\n\nAlso impact this changes on API object and add method to get a\nplan by its trigger_id\nAdded migration script also\n\nChange-Id: I4c4f99ec4083f2620abb231f77b3f76ab19da027\n""}, {'number': 5, 'created': '2014-02-06 10:19:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/solum/commit/b847a97da0712f985bff167e18be7e2c7d805f87', 'message': ""Add trigger_id attribute to the 'plan' db object\n\nAlso impact this changes on API object and add method to get a\nplan by its trigger_id\nAdded migration script also\n\nChange-Id: I4c4f99ec4083f2620abb231f77b3f76ab19da027\n""}, {'number': 6, 'created': '2014-02-07 15:38:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/solum/commit/697ba55b6a135c814f3bc7217f193c5984e20778', 'message': ""Add trigger_id attribute to the 'plan' db object\n\nAlso impact this changes on API object and add method to get a\nplan by its trigger_id\nAdded migration script also\n\nChange-Id: I4c4f99ec4083f2620abb231f77b3f76ab19da027\n""}, {'number': 7, 'created': '2014-02-07 16:01:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/solum/commit/05528e50d5b1229f5e7485333cd56d748ca1a9a7', 'message': ""Add trigger_id attribute to the 'plan' db object\n\nAlso impact this changes on API object and add method to get a\nplan by its trigger_id\nAdded migration script also\n\nChange-Id: I4c4f99ec4083f2620abb231f77b3f76ab19da027\n""}, {'number': 8, 'created': '2014-02-10 17:18:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/solum/commit/e801c7cce906a24b94f1a04d80bd163536c3a8ff', 'message': ""Add trigger_id attribute to the 'plan' db object\n\nAlso impact this changes on API object and add method to get a\nplan by its trigger_id\nAdded migration script also\n\nChange-Id: I4c4f99ec4083f2620abb231f77b3f76ab19da027\n""}, {'number': 9, 'created': '2014-02-12 09:28:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/solum/commit/ea51c3657b9cf43e048cc5c0b1ea0416c09a157e', 'message': ""Add trigger_id attribute to the 'plan' db object\n\nAlso impact this changes on API object and add method to get a\nplan by its trigger_id\nAdded migration script also\n\nChange-Id: I4c4f99ec4083f2620abb231f77b3f76ab19da027\n""}, {'number': 10, 'created': '2014-02-12 12:56:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/solum/commit/16b659999474bbfc9e600cc69f74e262d438579a', 'message': ""Add trigger_id attribute to the 'plan' db object\n\nAlso impact this changes on API object and add method to get a\nplan by its trigger_id\nAdded migration script also\n\nChange-Id: I4c4f99ec4083f2620abb231f77b3f76ab19da027\n""}, {'number': 11, 'created': '2014-02-12 14:06:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/solum/commit/7a98044e7d80b417c8922fbff7fef0b2bf041259', 'message': ""Add trigger_id attribute to the 'plan' db object\n\nAlso impact this changes on API object and add method to get a\nplan by its trigger_id\nAdded migration script also\n\nChange-Id: I4c4f99ec4083f2620abb231f77b3f76ab19da027\n""}, {'number': 12, 'created': '2014-02-13 13:58:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/solum/commit/bbd31b529866b90c4a44906000b0de9d906f5915', 'message': ""Add trigger_id attribute to the 'plan' db object\n\nAlso impact this changes on API object and add method to get a\nplan by its trigger_id\nAdded migration script also\n\nChange-Id: I4c4f99ec4083f2620abb231f77b3f76ab19da027\n""}, {'number': 13, 'created': '2014-02-17 12:48:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/solum/commit/2684af0a39f891de32584eec60111f817c54afcc', 'message': ""Add trigger_id attribute to the 'plan' db object\n\nAlso impact this changes on API object and add method to get a\nplan by its trigger_id\nAdded migration script also\n\nChange-Id: I4c4f99ec4083f2620abb231f77b3f76ab19da027\n""}, {'number': 14, 'created': '2014-02-20 13:42:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/solum/commit/ccb818af6debd88a75acb41aa1949b78958892b6', 'message': ""Add trigger_id attribute to the 'assembly' db object\n\nAlso impact this changes on API object and add method to get an\nassembly by its trigger_id\nAdded migration script also\n\nChange-Id: I4c4f99ec4083f2620abb231f77b3f76ab19da027\n""}, {'number': 15, 'created': '2014-02-25 10:00:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/solum/commit/99f85836f31758b082782b87c3793cad8e0a5c17', 'message': ""Add trigger_id attribute to the 'assembly' db object\n\nAlso impact this changes on API object and add method to get an\nassembly by its trigger_id\nAdded migration script also\n\nChange-Id: I4c4f99ec4083f2620abb231f77b3f76ab19da027\n""}, {'number': 16, 'created': '2014-02-28 09:42:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/solum/commit/05318c88a0b148ccaf55a882d3d03bbb61d24867', 'message': ""Add trigger_id attribute to the 'assembly' db object\n\nAlso impact this changes on API object and add method to get an\nassembly by its trigger_id\nAdded migration script also\n\nChange-Id: I4c4f99ec4083f2620abb231f77b3f76ab19da027\n""}, {'number': 17, 'created': '2014-02-28 10:20:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/solum/commit/4d942b77758e6eff3d0790119505051df9154afd', 'message': ""Add trigger_id attribute to the 'assembly' db object\n\nAlso impact this changes on API object and add method to get an\nassembly by its trigger_id\nAdded migration script also\n\nChange-Id: I4c4f99ec4083f2620abb231f77b3f76ab19da027\n""}, {'number': 18, 'created': '2014-03-01 12:42:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/solum/commit/7e94c5ae32a070a56f08bd5987a3d0a5b00dc0d7', 'message': ""Add trigger_id attribute to the 'assembly' db object\n\nAlso impact this changes on API object and add method to get an\nassembly by its trigger_id\nAdded migration script also\n\nChange-Id: I4c4f99ec4083f2620abb231f77b3f76ab19da027\n""}, {'number': 19, 'created': '2014-03-03 09:11:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/solum/commit/11a87bd7a2db86f0bb47816e83403e1d2334ab20', 'message': ""Add trigger_id attribute to the 'assembly' db object\n\nAlso impact this changes on API object and add method to get an\nassembly by its trigger_id\nAdded migration script also\n\nChange-Id: I4c4f99ec4083f2620abb231f77b3f76ab19da027\n""}, {'number': 20, 'created': '2014-03-03 16:04:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/solum/commit/327575c22b07a5a4054501bd0511b8154202557a', 'message': ""Add trigger_id attribute to the 'assembly' db object\n\nAlso impact this changes on API object and add method to get an\nassembly by its trigger_id\nAdded migration script also\n\nChange-Id: I4c4f99ec4083f2620abb231f77b3f76ab19da027\n""}, {'number': 21, 'created': '2014-03-03 16:50:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/solum/commit/b24266a335cc7efcda94bce98cfcb746a164637d', 'message': ""Add trigger_id attribute to the 'assembly' db object\n\nAlso impact this changes on API object and add method to get an\nassembly by its trigger_id\nAdded migration script also\n\nChange-Id: I4c4f99ec4083f2620abb231f77b3f76ab19da027\n""}, {'number': 22, 'created': '2014-03-04 09:47:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/solum/commit/4136eff1d1960fbfdd2bbdd69a2eae39045ee803', 'message': ""Add trigger_id attribute to the 'assembly' db object\n\nAlso impact this changes on API object and add method to get an\nassembly by its trigger_id\nAdded migration script also\n\nChange-Id: I4c4f99ec4083f2620abb231f77b3f76ab19da027\n""}, {'number': 23, 'created': '2014-03-05 09:57:16.000000000', 'files': ['solum/api/controllers/v1/datamodel/assembly.py', 'solum/objects/sqlalchemy/migration/alembic_migrations/versions/2e60bd23410d_add_trigger_to_assembly.py', 'solum/tests/objects/test_assembly.py', 'solum/objects/sqlalchemy/assembly.py', 'solum/api/handlers/assembly_handler.py'], 'web_link': 'https://opendev.org/openstack/solum/commit/bbec78604c01740906eb7a0530f6f0fe7e7f0176', 'message': ""Add trigger_id attribute to the 'assembly' db object\n\nAlso impact this changes on API object and add method to get an\nassembly by its trigger_id\nAdded migration script also\n\nChange-Id: I4c4f99ec4083f2620abb231f77b3f76ab19da027\n""}]",16,71025,bbec78604c01740906eb7a0530f6f0fe7e7f0176,126,10,23,9537,,,0,"Add trigger_id attribute to the 'assembly' db object

Also impact this changes on API object and add method to get an
assembly by its trigger_id
Added migration script also

Change-Id: I4c4f99ec4083f2620abb231f77b3f76ab19da027
",git fetch https://review.opendev.org/openstack/solum refs/changes/25/71025/21 && git format-patch -1 --stdout FETCH_HEAD,"['solum/common/exception.py', 'solum/api/controllers/v1/datamodel/plan.py', 'solum/objects/sqlalchemy/migration/alembic_migrations/versions/2e60bd23410d_add_trigger_to_plan.py', 'solum/objects/plan.py', 'solum/objects/sqlalchemy/plan.py', 'solum/tests/objects/test_plan.py']",6,f2135ac0ca0536eead6ca0b62a784555f8f3b768,bp/zuul-endpoint," 'trigger_id': 'trigger-uuid-1234', def test_check_data_by_trigger_id(self): pl = plan.Plan().get_by_trigger_id(self.ctx, self.data[0][ 'trigger_id']) for key, value in self.data[0].items(): self.assertEqual(value, getattr(pl, key))",,73,0
openstack%2Ffuel-docs~master~I479480fc38e78c674e176915bc6f0b06eded532d,openstack/fuel-docs,master,I479480fc38e78c674e176915bc6f0b06eded532d,Redraw ref-arch schemes,MERGED,2014-03-06 15:25:00.000000000,2014-03-07 01:57:16.000000000,2014-03-07 01:57:16.000000000,"[{'_account_id': 3}, {'_account_id': 406}, {'_account_id': 7468}, {'_account_id': 8786}, {'_account_id': 8787}, {'_account_id': 8797}, {'_account_id': 8829}, {'_account_id': 8971}, {'_account_id': 9037}, {'_account_id': 10014}]","[{'number': 1, 'created': '2014-03-06 15:25:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-docs/commit/d53ffa4c46eb00467457b080abac6e1e3fdb8c77', 'message': 'Redraw ref-arch schemes\n\nChange-Id: I479480fc38e78c674e176915bc6f0b06eded532d\nCloses-Bug: 1259424\n'}, {'number': 2, 'created': '2014-03-06 17:30:08.000000000', 'files': ['_images/deployment-ha-compact-red-hat.svg', 'pages/reference-architecture/0018-red-hat-differences.rst', 'pages/reference-architecture/0020-logical-setup.rst', '_images/deployment-simple-red-hat.svg', '_images/logical-diagram-compute.svg', '_images/deployment-simple.svg', '_images/logical-diagram-controller.svg', '_images/deployment-ha-full.svg', '_images/deployment-ha-compact.svg', '_images/ha-overview.svg', 'pages/reference-architecture/0030-cluster-sizing.rst'], 'web_link': 'https://opendev.org/openstack/fuel-docs/commit/5b24da50b4108f9a1ab64ffa7cfa2da964a7d66c', 'message': 'Redraw ref-arch schemes\n\nChange-Id: I479480fc38e78c674e176915bc6f0b06eded532d\nCloses-Bug: 1259424\n'}]",0,78631,5b24da50b4108f9a1ab64ffa7cfa2da964a7d66c,13,10,2,9037,,,0,"Redraw ref-arch schemes

Change-Id: I479480fc38e78c674e176915bc6f0b06eded532d
Closes-Bug: 1259424
",git fetch https://review.opendev.org/openstack/fuel-docs refs/changes/31/78631/1 && git format-patch -1 --stdout FETCH_HEAD,"['_images/deployment-ha-compact-red-hat.svg', 'pages/reference-architecture/0018-red-hat-differences.rst', '_images/deployment-simple-red-hat.svg', '_images/deployment-simple.svg', '_images/logical-diagram-compute.svg', '_images/logical-diagram-controller.svg', '_images/deployment-ha-compact.svg', '_images/deployment-ha-full.svg', '_images/ha-overview.svg', 'pages/reference-architecture/0030-cluster-sizing.rst']",10,d53ffa4c46eb00467457b080abac6e1e3fdb8c77,bug/1259424,"If you want to run storage separately from the controllers, you can do that as well by raising the bar to 9 nodes:- 3 Ceph OSD nodes - 1 Cinder node.. note:: Placing Ceph OSD on Controllers is highly unadvisable. It can severely degrade controller prefarmance. Use separate storage nodes if you have enough hardware.",".. image:: /_images/deployment-ha-compact.* :width: 80% :align: center If you want to run storage separately from the controllers, you can do that as well by raising the bar to 9 nodes:- 3 Storage nodes - 2 Swift Proxy nodes.. image:: /_images/deployment-ha-full.* :width: 80% :align: center",1530,1036
openstack%2Ftempest~master~Ic4c43bd42fba96950b26232a37bcf300e1e742d1,openstack/tempest,master,Ic4c43bd42fba96950b26232a37bcf300e1e742d1,Add Trove (database) Flavor API Tests,MERGED,2014-01-27 23:22:49.000000000,2014-03-07 01:57:05.000000000,2014-03-07 01:57:04.000000000,"[{'_account_id': 3}, {'_account_id': 1192}, {'_account_id': 1921}, {'_account_id': 5293}, {'_account_id': 5689}, {'_account_id': 5803}, {'_account_id': 8085}, {'_account_id': 8851}, {'_account_id': 9008}]","[{'number': 1, 'created': '2014-01-27 23:22:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/41b9f3f67cede5c6542fb43fa99666877f840f10', 'message': 'Add Trove (database) Flavor API Tests\n\nAdded Trove (database) service and flavor API tests.\n\nPartially implements blueprint: trove-tempest\nChange-Id: Ic4c43bd42fba96950b26232a37bcf300e1e742d1\n'}, {'number': 2, 'created': '2014-01-29 23:49:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/7c49ec5e09dba3bbfdf440a9ac8e774eb9d85f1b', 'message': 'Add Trove (database) Flavor API Tests\n\nAdded Trove (database) service and flavor API tests.\n\nPartially implements blueprint: trove-tempest\nChange-Id: Ic4c43bd42fba96950b26232a37bcf300e1e742d1\n'}, {'number': 4, 'created': '2014-01-30 00:58:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/0674f4abb5b4ab92198d099042a32a75eebc50de', 'message': 'Add Trove (database) Flavor API Tests\n\nAdded Trove (database) service and flavor API tests.\n\nPartially implements blueprint: trove-tempest\nChange-Id: Ic4c43bd42fba96950b26232a37bcf300e1e742d1\n'}, {'number': 3, 'created': '2014-01-30 00:58:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/3883178ee97f659dc05a6658b388d11a8fca01a2', 'message': 'Add Trove (database) Flavor API Tests\n\nAdded Trove (database) service and flavor API tests.\n\nPartially implements blueprint: trove-tempest\nChange-Id: Ic4c43bd42fba96950b26232a37bcf300e1e742d1\n'}, {'number': 5, 'created': '2014-03-03 09:59:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/ce1236b58f764427c973c98f70ae82e6fcf2338b', 'message': 'Add Trove (database) Flavor API Tests\n\nAdded Trove (database) service and flavor API tests.\n\nPartially implements blueprint: trove-tempest\nChange-Id: Ic4c43bd42fba96950b26232a37bcf300e1e742d1\n'}, {'number': 6, 'created': '2014-03-03 10:56:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/c57f25674d66d9d889df996ce4f74f8f730d0d39', 'message': 'Add Trove (database) Flavor API Tests\n\nAdded Trove (database) service and flavor API tests.\n\nPartially implements blueprint: trove-tempest\nChange-Id: Ic4c43bd42fba96950b26232a37bcf300e1e742d1\n'}, {'number': 7, 'created': '2014-03-04 02:07:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/e6277303aaadf85724c203e6e2237eeeb271c2fd', 'message': 'Add Trove (database) Flavor API Tests\n\nAdded Trove (database) service and flavor API tests.\n\nPartially implements blueprint: trove-tempest\nChange-Id: Ic4c43bd42fba96950b26232a37bcf300e1e742d1\n'}, {'number': 8, 'created': '2014-03-04 02:18:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/d92159bbdee234bedd1f0de9680252747be9e452', 'message': 'Add Trove (database) Flavor API Tests\n\nAdded Trove (database) service and flavor API tests.\n\nPartially implements blueprint: trove-tempest\nChange-Id: Ic4c43bd42fba96950b26232a37bcf300e1e742d1\n'}, {'number': 9, 'created': '2014-03-04 02:50:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/3ec831023bf4fc306e281ae047cc276546755b09', 'message': 'Add Trove (database) Flavor API Tests\n\nAdded Trove (database) service and flavor API tests.\n\nPartially implements blueprint: trove-tempest\nChange-Id: Ic4c43bd42fba96950b26232a37bcf300e1e742d1\n'}, {'number': 10, 'created': '2014-03-04 02:59:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/b3306bfa60d839a3ed367af16a1bde7000f02b6f', 'message': 'Add Trove (database) Flavor API Tests\n\nAdded Trove (database) service and flavor API tests.\n\nPartially implements blueprint: trove-tempest\nChange-Id: Ic4c43bd42fba96950b26232a37bcf300e1e742d1\n'}, {'number': 11, 'created': '2014-03-04 04:13:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/2ee195f734179974a0156b5ddd731e45f3285c7d', 'message': 'Add Trove (database) Flavor API Tests\n\nAdded Trove (database) service and flavor API tests.\n\nPartially implements blueprint: trove-tempest\nChange-Id: Ic4c43bd42fba96950b26232a37bcf300e1e742d1\n'}, {'number': 12, 'created': '2014-03-04 07:39:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/02d1ccdbde5b2e597844d049cd0199eb6e2b3c1a', 'message': 'Add Trove (database) Flavor API Tests\n\nAdded Trove (database) service and flavor API tests.\n\nPartially implements blueprint: trove-tempest\nChange-Id: Ic4c43bd42fba96950b26232a37bcf300e1e742d1\n'}, {'number': 13, 'created': '2014-03-04 08:15:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/04308fd928a9cd977799083f00beaf867edf1d40', 'message': 'Add Trove (database) Flavor API Tests\n\nAdded Trove (database) service and flavor API tests.\n\nPartially implements blueprint: trove-tempest\nChange-Id: Ic4c43bd42fba96950b26232a37bcf300e1e742d1\n'}, {'number': 14, 'created': '2014-03-04 08:42:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/2d6aa4c79f6386bbc92f6592a81aacb41ad47f83', 'message': 'Add Trove (database) Flavor API Tests\n\nAdded Trove (database) service and flavor API tests.\n\nPartially implements blueprint: trove-tempest\nChange-Id: Ic4c43bd42fba96950b26232a37bcf300e1e742d1\n'}, {'number': 15, 'created': '2014-03-04 08:55:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/7bda49b8592ed3abe98044e6f2c26fa5ec193149', 'message': 'Add Trove (database) Flavor API Tests\n\nAdded Trove (database) service and flavor API tests.\n\nPartially implements blueprint: trove-tempest\nChange-Id: Ic4c43bd42fba96950b26232a37bcf300e1e742d1\n'}, {'number': 16, 'created': '2014-03-04 09:09:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/4c092c81f9875c6fee0ede32365b2ebc9cdc9ecb', 'message': 'Add Trove (database) Flavor API Tests\n\nAdded Trove (database) service and flavor API tests.\n\nPartially implements blueprint: trove-tempest\nChange-Id: Ic4c43bd42fba96950b26232a37bcf300e1e742d1\n'}, {'number': 17, 'created': '2014-03-04 10:31:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/9b76fba42be1bc3f45935960d452d2981f176f6e', 'message': 'Add Trove (database) Flavor API Tests\n\nAdded Trove (database) service and flavor API tests.\n\nPartially implements blueprint: trove-tempest\nChange-Id: Ic4c43bd42fba96950b26232a37bcf300e1e742d1\n'}, {'number': 18, 'created': '2014-03-04 20:49:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/fc01c0bb55a3349b72c20ceef42722fdb6d6450e', 'message': 'Add Trove (database) Flavor API Tests\n\nAdded Trove (database) service and flavor API tests.\n\nPartially implements blueprint: trove-tempest\nChange-Id: Ic4c43bd42fba96950b26232a37bcf300e1e742d1\n'}, {'number': 19, 'created': '2014-03-04 20:52:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/6296d9c47a45572bcc344b799ba3305ce76c8e9b', 'message': 'Add Trove (database) Flavor API Tests\n\nAdded Trove (database) service and flavor API tests.\n\nPartially implements blueprint: trove-tempest\nChange-Id: Ic4c43bd42fba96950b26232a37bcf300e1e742d1\n'}, {'number': 20, 'created': '2014-03-05 08:18:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/faeb12353f718ced9819bf07bd2fc210ee272e62', 'message': 'Add Trove (database) Flavor API Tests\n\nAdded Trove (database) service and flavor API tests.\n\nPartially implements blueprint: trove-tempest\nChange-Id: Ic4c43bd42fba96950b26232a37bcf300e1e742d1\n'}, {'number': 21, 'created': '2014-03-06 05:47:16.000000000', 'files': ['etc/tempest.conf.sample', 'tempest/api/database/__init__.py', 'tempest/services/database/json/__init__.py', 'tempest/clients.py', 'tempest/services/database/json/flavors_client.py', 'tempest/config.py', 'tempest/api/database/base.py', 'tempest/services/database/__init__.py', 'tempest/api/database/flavors/test_flavors.py', 'tempest/api/database/flavors/test_flavors_negative.py', 'tempest/api/database/flavors/__init__.py'], 'web_link': 'https://opendev.org/openstack/tempest/commit/dd6886f7c633b2a3a49fef30cde82b7c9dee1512', 'message': 'Add Trove (database) Flavor API Tests\n\nAdded Trove (database) service and flavor API tests.\n\nPartially implements blueprint: trove-tempest\nChange-Id: Ic4c43bd42fba96950b26232a37bcf300e1e742d1\n'}]",66,69501,dd6886f7c633b2a3a49fef30cde82b7c9dee1512,140,9,21,5293,,,0,"Add Trove (database) Flavor API Tests

Added Trove (database) service and flavor API tests.

Partially implements blueprint: trove-tempest
Change-Id: Ic4c43bd42fba96950b26232a37bcf300e1e742d1
",git fetch https://review.opendev.org/openstack/tempest refs/changes/01/69501/15 && git format-patch -1 --stdout FETCH_HEAD,"['etc/tempest.conf.sample', 'tempest/api/database/__init__.py', 'tempest/services/database/json/__init__.py', 'tempest/services/database/json/flavors_client.py', 'tempest/config.py', 'tempest/api/database/base.py', 'tempest/api/database/flavors/test_flavors.py', 'tempest/services/database/__init__.py', 'tempest/api/database/flavors/__init__.py']",9,41b9f3f67cede5c6542fb43fa99666877f840f10,bp/trove-tempest,,,215,2
openstack%2Fnova~master~Ib09d5370622809e4bf1b5825eb9c223a115f7d33,openstack/nova,master,Ib09d5370622809e4bf1b5825eb9c223a115f7d33,Add os-server-external-events API,MERGED,2014-02-19 02:30:39.000000000,2014-03-07 01:56:02.000000000,2014-03-07 01:55:59.000000000,"[{'_account_id': 3}, {'_account_id': 191}, {'_account_id': 1030}, {'_account_id': 1561}, {'_account_id': 4393}, {'_account_id': 4395}, {'_account_id': 4912}, {'_account_id': 5170}, {'_account_id': 5292}, {'_account_id': 6167}, {'_account_id': 9008}, {'_account_id': 9578}]","[{'number': 1, 'created': '2014-02-19 02:30:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/4d6cb30f540835293abe70c445071671f6ac2e35', 'message': 'WIP Add os-instance-external-events API\n\nChange-Id: Ib09d5370622809e4bf1b5825eb9c223a115f7d33\n'}, {'number': 2, 'created': '2014-02-19 02:33:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/f57ce824c88532fcfb77006cc8897d77462ad2ac', 'message': 'WIP Add os-instance-external-events API\n\nChange-Id: Ib09d5370622809e4bf1b5825eb9c223a115f7d33\n'}, {'number': 3, 'created': '2014-02-19 03:19:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/d79b707902991503e3170e74095133f1971499ea', 'message': 'WIP Add os-instance-external-events API\n\nChange-Id: Ib09d5370622809e4bf1b5825eb9c223a115f7d33\n'}, {'number': 4, 'created': '2014-02-19 19:22:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/5579a74f4895523dc48a879c040f09f38c79c0d2', 'message': 'WIP Add os-server-external-events API\n\nRelated to blueprint admin-event-callback-api\n\nChange-Id: Ib09d5370622809e4bf1b5825eb9c223a115f7d33\n'}, {'number': 5, 'created': '2014-02-19 20:39:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/f128b86e334345ef72c23faef5af3a5b2ad5dede', 'message': 'WIP Add os-server-external-events API\n\nRelated to blueprint admin-event-callback-api\n\nChange-Id: Ib09d5370622809e4bf1b5825eb9c223a115f7d33\n'}, {'number': 6, 'created': '2014-02-20 01:47:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/5e86ec414b23aa48ad734d014e99eae4ba7acb09', 'message': 'WIP Add os-server-external-events API\n\nRelated to blueprint admin-event-callback-api\n\nChange-Id: Ib09d5370622809e4bf1b5825eb9c223a115f7d33\n'}, {'number': 7, 'created': '2014-02-20 19:01:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/0b597023337d09e1ed50e9398b947ac1eaa86bbc', 'message': 'WIP Add os-server-external-events API\n\nRelated to blueprint admin-event-callback-api\n\nChange-Id: Ib09d5370622809e4bf1b5825eb9c223a115f7d33\n'}, {'number': 8, 'created': '2014-02-20 21:01:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/7d6c702336cfcc94fb7d0723216f38a632bbe6cc', 'message': 'WIP Add os-server-external-events API\n\nRelated to blueprint admin-event-callback-api\n\nChange-Id: Ib09d5370622809e4bf1b5825eb9c223a115f7d33\n'}, {'number': 9, 'created': '2014-02-20 22:27:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/1c041a3fa8013a829202dc244c906834bd1a2a07', 'message': 'WIP Add os-server-external-events API\n\nRelated to blueprint admin-event-callback-api\n\nChange-Id: Ib09d5370622809e4bf1b5825eb9c223a115f7d33\n'}, {'number': 10, 'created': '2014-02-20 23:01:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/afdf1cd457f354f823dfcde8d1026bb2425b4a1b', 'message': 'WIP Add os-server-external-events API\n\nRelated to blueprint admin-event-callback-api\n\nChange-Id: Ib09d5370622809e4bf1b5825eb9c223a115f7d33\n'}, {'number': 11, 'created': '2014-02-24 16:41:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/d9457ea0e4111657599399deb56712ec2de8cf4a', 'message': 'Add os-server-external-events API\n\nRelated to blueprint admin-event-callback-api\n\nChange-Id: Ib09d5370622809e4bf1b5825eb9c223a115f7d33\n'}, {'number': 12, 'created': '2014-02-25 16:12:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/440260354890f558d0b6f1430dfc53ef86fb973c', 'message': 'Add os-server-external-events API\n\nRelated to blueprint admin-event-callback-api\n\nChange-Id: Ib09d5370622809e4bf1b5825eb9c223a115f7d33\n'}, {'number': 13, 'created': '2014-02-25 16:47:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/17a5ea905c828b63ab075ee3cb32ad2a292b1dfe', 'message': 'Add os-server-external-events API\n\nRelated to blueprint admin-event-callback-api\n\nChange-Id: Ib09d5370622809e4bf1b5825eb9c223a115f7d33\n'}, {'number': 14, 'created': '2014-02-25 18:40:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/7212e374c891866d6475e84e2c5e1c56fd702838', 'message': 'Add os-server-external-events API\n\nRelated to blueprint admin-event-callback-api\n\nChange-Id: Ib09d5370622809e4bf1b5825eb9c223a115f7d33\n'}, {'number': 15, 'created': '2014-02-25 20:47:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/ecf91592b98e0f7e734885f1ab35dba0d83de64f', 'message': 'Add os-server-external-events API\n\nRelated to blueprint admin-event-callback-api\n\nChange-Id: Ib09d5370622809e4bf1b5825eb9c223a115f7d33\n'}, {'number': 16, 'created': '2014-02-26 15:58:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/e91e80ebfb445bdc43f92678076b795fe5baf412', 'message': 'Add os-server-external-events API\n\nRelated to blueprint admin-event-callback-api\n\nChange-Id: Ib09d5370622809e4bf1b5825eb9c223a115f7d33\n'}, {'number': 17, 'created': '2014-02-26 18:07:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/46ce2ce90cf54627201326d5e2d21875900a1069', 'message': 'Add os-server-external-events API\n\nRelated to blueprint admin-event-callback-api\n\nChange-Id: Ib09d5370622809e4bf1b5825eb9c223a115f7d33\n'}, {'number': 18, 'created': '2014-03-03 18:31:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/cac7e62fd4782198d5acdc531a025870089a1f37', 'message': 'Add os-server-external-events API\n\nRelated to blueprint admin-event-callback-api\n\nChange-Id: Ib09d5370622809e4bf1b5825eb9c223a115f7d33\n'}, {'number': 19, 'created': '2014-03-05 16:39:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/cda000cb0813b6bebd0853531d30225cb970b095', 'message': 'Add os-server-external-events API\n\nRelated to blueprint admin-event-callback-api\n\nChange-Id: Ib09d5370622809e4bf1b5825eb9c223a115f7d33\n'}, {'number': 20, 'created': '2014-03-05 22:37:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/f6204946eaf06fbdc19a0c801e53ec4d55a90def', 'message': 'Add os-server-external-events API\n\nRelated to blueprint admin-event-callback-api\n\nChange-Id: Ib09d5370622809e4bf1b5825eb9c223a115f7d33\n'}, {'number': 21, 'created': '2014-03-06 02:13:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/ce3b91a6d0bdcecab9f1603b19e507f4ffcf7994', 'message': 'Add os-server-external-events API\n\nRelated to blueprint admin-event-callback-api\n\nChange-Id: Ib09d5370622809e4bf1b5825eb9c223a115f7d33\n'}, {'number': 22, 'created': '2014-03-06 15:41:29.000000000', 'files': ['doc/api_samples/os-server-external-events/event-create-resp.xml', 'etc/nova/policy.json', 'nova/tests/integrated/api_samples/os-server-external-events/server-post-req.xml.tpl', 'nova/tests/integrated/api_samples/os-server-external-events/event-create-req.json.tpl', 'nova/tests/integrated/api_samples/all_extensions/extensions-get-resp.xml.tpl', 'nova/tests/integrated/api_samples/os-server-external-events/server-post-resp.json.tpl', 'doc/api_samples/all_extensions/extensions-get-resp.xml', 'doc/api_samples/os-server-external-events/event-create-resp.json', 'nova/tests/integrated/test_api_samples.py', 'doc/api_samples/os-server-external-events/server-post-req.json', 'doc/api_samples/os-server-external-events/server-post-resp.json', 'nova/api/openstack/compute/contrib/server_external_events.py', 'doc/api_samples/all_extensions/extensions-get-resp.json', 'nova/tests/integrated/api_samples/os-server-external-events/event-create-req.xml.tpl', 'nova/tests/integrated/api_samples/os-server-external-events/event-create-resp.xml.tpl', 'doc/api_samples/os-server-external-events/event-create-req.json', 'nova/tests/integrated/api_samples/os-server-external-events/server-post-resp.xml.tpl', 'doc/api_samples/os-server-external-events/server-post-resp.xml', 'nova/tests/integrated/api_samples/os-server-external-events/event-create-resp.json.tpl', 'doc/api_samples/os-server-external-events/server-post-req.xml', 'nova/tests/integrated/api_samples/os-server-external-events/server-post-req.json.tpl', 'doc/api_samples/os-server-external-events/event-create-req.xml', 'nova/tests/fake_policy.py', 'nova/tests/api/openstack/compute/contrib/test_server_external_events.py', 'nova/tests/integrated/api_samples/all_extensions/extensions-get-resp.json.tpl'], 'web_link': 'https://opendev.org/openstack/nova/commit/ce936ea5f3ae0b4d3b816a7fe42d5f0100b20fca', 'message': 'Add os-server-external-events API\n\nRelated to blueprint admin-event-callback-api\n\nChange-Id: Ib09d5370622809e4bf1b5825eb9c223a115f7d33\n'}]",49,74565,ce936ea5f3ae0b4d3b816a7fe42d5f0100b20fca,162,12,22,4393,,,0,"Add os-server-external-events API

Related to blueprint admin-event-callback-api

Change-Id: Ib09d5370622809e4bf1b5825eb9c223a115f7d33
",git fetch https://review.opendev.org/openstack/nova refs/changes/65/74565/1 && git format-patch -1 --stdout FETCH_HEAD,"['doc/api_samples/all_extensions/extensions-get-resp.json', 'nova/tests/integrated/api_samples/os-instance-external-events/server-post-req.json.tpl', 'doc/api_samples/os-instance-external-events/server-post-resp.json', 'etc/nova/policy.json', 'nova/tests/integrated/api_samples/os-instance-external-events/server-post-resp.xml.tpl', 'doc/api_samples/os-instance-external-events/server-post-resp.xml', 'doc/api_samples/os-instance-external-events/event-create-req.json', 'nova/tests/integrated/api_samples/all_extensions/extensions-get-resp.xml.tpl', 'doc/api_samples/all_extensions/extensions-get-resp.xml', 'nova/tests/integrated/api_samples/os-instance-external-events/server-post-resp.json.tpl', 'nova/tests/integrated/api_samples/os-instance-external-events/event-create-req.xml.tpl', 'doc/api_samples/os-instance-external-events/event-create-req.xml', 'nova/tests/integrated/api_samples/os-instance-external-events/event-create-req.json.tpl', 'nova/tests/integrated/api_samples/os-instance-external-events/server-post-req.xml.tpl', 'doc/api_samples/os-instance-external-events/server-post-req.json', 'nova/tests/fake_policy.py', 'doc/api_samples/os-instance-external-events/server-post-req.xml', 'nova/api/openstack/compute/contrib/instance_external_events.py', 'nova/tests/integrated/api_samples/all_extensions/extensions-get-resp.json.tpl', 'nova/tests/integrated/test_api_samples.py']",20,4d6cb30f540835293abe70c445071671f6ac2e35,bp/admin-event-callback-api," class InstanceExternalEventsJsonTest(ServersSampleBase): extension_name = ('nova.api.openstack.compute.contrib.' 'instance_external_events.Instance_external_events') def test_create_event(self): instance_uuid = self._post_server() subs = { 'uuid': instance_uuid, 'name': 'test-event', 'tag': 'foo', } response = self._do_post('os-instance-external-events', 'event-create-req', subs) self.assertEqual(response.status, 200) class InstanceExternalEventsXmlTest(InstanceExternalEventsJsonTest): ctype = 'xml'",,285,1
openstack%2Fkeystone~master~Id8355cdc1ab80b57ed18fcb3b16fd92cb7a73ecf,openstack/keystone,master,Id8355cdc1ab80b57ed18fcb3b16fd92cb7a73ecf,Fix docstrings in federation related modules,MERGED,2014-03-05 09:16:25.000000000,2014-03-07 01:54:35.000000000,2014-03-07 01:54:34.000000000,"[{'_account_id': 3}, {'_account_id': 4}, {'_account_id': 792}, {'_account_id': 1916}, {'_account_id': 2218}, {'_account_id': 2903}, {'_account_id': 5707}, {'_account_id': 6460}, {'_account_id': 6482}, {'_account_id': 6486}, {'_account_id': 7191}, {'_account_id': 7725}, {'_account_id': 8978}]","[{'number': 1, 'created': '2014-03-05 09:16:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/1bca0910ba052856a4809be88c831642549b1192', 'message': 'Fix docstrings in federation related modules.\n\nThe docstrings in keystone/auth/plugins/saml2.py and\nkeystone/contrib/federation/routers.py should be updated so they\nproperly describe the code.\n\nChange-Id: Id8355cdc1ab80b57ed18fcb3b16fd92cb7a73ecf\nCloses-Bug: #1288124\n'}, {'number': 2, 'created': '2014-03-05 13:19:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/790db7f43a4eda5559f828de30203bc057208146', 'message': 'Fix docstrings in federation related modules.\n\nThe docstrings in keystone/auth/plugins/saml2.py and\nkeystone/contrib/federation/routers.py should be updated so they\nproperly describe the code.\n\nChange-Id: Id8355cdc1ab80b57ed18fcb3b16fd92cb7a73ecf\nCloses-Bug: #1288124\n'}, {'number': 3, 'created': '2014-03-05 15:41:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/2caf63a0cbafbdd56fb9014a0ec6b299ee3f0c99', 'message': 'Fix docstrings in federation related modules.\n\nThe docstrings in keystone/auth/plugins/saml2.py and\nkeystone/contrib/federation/routers.py should be updated so they\nproperly describe the code.\n\nChange-Id: Id8355cdc1ab80b57ed18fcb3b16fd92cb7a73ecf\nCloses-Bug: #1288124\n'}, {'number': 4, 'created': '2014-03-06 09:59:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/f85379d7aef60674a8042b02b19a94b6710a7eed', 'message': 'Fix docstrings in federation related modules.\n\nThe docstrings in keystone/auth/plugins/saml2.py and\nkeystone/contrib/federation/routers.py should be updated so they\nproperly describe the code.\n\nChange-Id: Id8355cdc1ab80b57ed18fcb3b16fd92cb7a73ecf\nCloses-Bug: #1288124\n'}, {'number': 5, 'created': '2014-03-06 18:38:37.000000000', 'files': ['keystone/contrib/federation/routers.py', 'keystone/auth/plugins/saml2.py'], 'web_link': 'https://opendev.org/openstack/keystone/commit/23b8592137ee64fda502df69bf6268e8ea2f143a', 'message': 'Fix docstrings in federation related modules\n\nUpdated docstrings in keystone/auth/plugins/saml2.py and\nkeystone/contrib/federation/routers.py, included additional\nparameters there was previously missing.\n\nChange-Id: Id8355cdc1ab80b57ed18fcb3b16fd92cb7a73ecf\nCloses-Bug: #1288124\n'}]",8,78142,23b8592137ee64fda502df69bf6268e8ea2f143a,34,13,5,8978,,,0,"Fix docstrings in federation related modules

Updated docstrings in keystone/auth/plugins/saml2.py and
keystone/contrib/federation/routers.py, included additional
parameters there was previously missing.

Change-Id: Id8355cdc1ab80b57ed18fcb3b16fd92cb7a73ecf
Closes-Bug: #1288124
",git fetch https://review.opendev.org/openstack/keystone refs/changes/42/78142/1 && git format-patch -1 --stdout FETCH_HEAD,"['etc/keystone.conf.sample', 'keystone/contrib/federation/routers.py', 'keystone/auth/plugins/saml2.py']",3,1bca0910ba052856a4809be88c831642549b1192,fed_str," In addition to ``user_id`` in ``auth_context``, the ``saml2`` plugin sets ``group_ids``. Also, when handling unscoped token the ``identity_provider`` and ``protocol`` objects are set."," In addition to ``user_id`` in ``auth_context``, the ``saml2`` plugin also sets ``group_ids``, ``identity_provider`` and ``protocol``. These values are required for issuing an unscoped federated token. When scoping the federated tokens, the plugin sets ``federated_token``, this entry stores the unscoped token.",10,5
openstack%2Fpython-openstackclient~master~Ic90d9682a9c15795928c0c5b64c41bd06d74243a,openstack/python-openstackclient,master,Ic90d9682a9c15795928c0c5b64c41bd06d74243a,Updated from global requirements,MERGED,2014-02-26 23:35:06.000000000,2014-03-07 01:54:30.000000000,2014-03-07 01:54:30.000000000,"[{'_account_id': 3}, {'_account_id': 970}, {'_account_id': 8736}]","[{'number': 1, 'created': '2014-02-26 23:35:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-openstackclient/commit/611b03453e90d8ab8a1e37c56a853f2cc4b69204', 'message': 'Updated from global requirements\n\nChange-Id: Ic90d9682a9c15795928c0c5b64c41bd06d74243a\n'}, {'number': 2, 'created': '2014-02-28 08:01:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-openstackclient/commit/8f8a8a2ba10dc16199a4eff9c758ffb65b39e507', 'message': 'Updated from global requirements\n\nChange-Id: Ic90d9682a9c15795928c0c5b64c41bd06d74243a\n'}, {'number': 3, 'created': '2014-03-03 03:35:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-openstackclient/commit/81bb512a4ca4fc4fa263e77f5411f00f4c0e0f41', 'message': 'Updated from global requirements\n\nChange-Id: Ic90d9682a9c15795928c0c5b64c41bd06d74243a\n'}, {'number': 4, 'created': '2014-03-05 19:30:10.000000000', 'files': ['requirements.txt'], 'web_link': 'https://opendev.org/openstack/python-openstackclient/commit/64a33b0aa59a1d22fadc41bffebfab04dd6c2cc7', 'message': 'Updated from global requirements\n\nChange-Id: Ic90d9682a9c15795928c0c5b64c41bd06d74243a\n'}]",0,76701,64a33b0aa59a1d22fadc41bffebfab04dd6c2cc7,19,3,4,3,,,0,"Updated from global requirements

Change-Id: Ic90d9682a9c15795928c0c5b64c41bd06d74243a
",git fetch https://review.opendev.org/openstack/python-openstackclient refs/changes/01/76701/1 && git format-patch -1 --stdout FETCH_HEAD,['requirements.txt'],1,611b03453e90d8ab8a1e37c56a853f2cc4b69204,openstack/requirements,six>=1.5.2,six>=1.4.1,1,1
openstack%2Fnova~master~Id6deccce13698b083af492635ff88533c059fd35,openstack/nova,master,Id6deccce13698b083af492635ff88533c059fd35,Remove run-time dependency on fixtures module by the nova baremetal,MERGED,2014-03-06 12:12:29.000000000,2014-03-07 01:53:12.000000000,2014-03-07 01:53:09.000000000,"[{'_account_id': 3}, {'_account_id': 679}, {'_account_id': 1561}, {'_account_id': 1653}, {'_account_id': 2750}, {'_account_id': 4190}, {'_account_id': 4393}, {'_account_id': 5170}, {'_account_id': 6873}, {'_account_id': 6928}, {'_account_id': 6969}, {'_account_id': 9369}, {'_account_id': 9578}]","[{'number': 1, 'created': '2014-03-06 12:12:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/f076e972402502599ed7dab1ef6e16ef8d77999e', 'message': 'Remove run-time dependency on fixtures module by the nova baremental\n\nTripleo still uses this baremetal driver. The dependency on the python fixutures\nwas introduced by https://review.openstack.org/#/c/71219/\n\nThis dependency is causing devtest to stop working.\n\nChange-Id: Id6deccce13698b083af492635ff88533c059fd35\n'}, {'number': 2, 'created': '2014-03-06 14:37:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/5e0db342edb0909fd980dffbd066d71351566d7a', 'message': 'Remove run-time dependency on fixtures module by the nova baremetal\n\nTripleo still uses this baremetal driver. The dependency on the python fixtures\nwas introduced by https://review.openstack.org/#/c/71219/\n\nThis dependency is causing devtest to stop working.\n\nChange-Id: Id6deccce13698b083af492635ff88533c059fd35\n'}, {'number': 3, 'created': '2014-03-06 17:59:58.000000000', 'files': ['nova/virt/baremetal/driver.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/6218114321b8192bd88d77b895b4585dfb72803a', 'message': 'Remove run-time dependency on fixtures module by the nova baremetal\n\nTripleo still uses this baremetal driver. The dependency on the python fixtures\nwas introduced by https://review.openstack.org/#/c/71219/\n\nThis dependency is causing devtest to stop working.\n\nChange-Id: Id6deccce13698b083af492635ff88533c059fd35\n'}]",4,78588,6218114321b8192bd88d77b895b4585dfb72803a,35,13,3,6969,,,0,"Remove run-time dependency on fixtures module by the nova baremetal

Tripleo still uses this baremetal driver. The dependency on the python fixtures
was introduced by https://review.openstack.org/#/c/71219/

This dependency is causing devtest to stop working.

Change-Id: Id6deccce13698b083af492635ff88533c059fd35
",git fetch https://review.opendev.org/openstack/nova refs/changes/88/78588/1 && git format-patch -1 --stdout FETCH_HEAD,['nova/virt/baremetal/driver.py'],1,f076e972402502599ed7dab1ef6e16ef8d77999e,baremetal-lockutils,"from nova.openstack.common import lockutils with lockutils.lock('nova-baremetal-cache-images', external=True):",from nova.openstack.common.fixture import lockutils with lockutils.LockFixture('nova-baremetal-cache-images'):,2,2
openstack%2Ftripleo-image-elements~master~I994e3939fb0db8029185f1674759ebfa92307e57,openstack/tripleo-image-elements,master,I994e3939fb0db8029185f1674759ebfa92307e57,Use local apt and pypi mirror for tripleo-cd,MERGED,2014-02-24 03:32:25.000000000,2014-03-07 01:45:20.000000000,2014-03-07 01:45:20.000000000,"[{'_account_id': 3}, {'_account_id': 4190}, {'_account_id': 6449}, {'_account_id': 6488}, {'_account_id': 6849}, {'_account_id': 9369}]","[{'number': 1, 'created': '2014-02-24 03:32:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-image-elements/commit/07963e1263832139704997a55f3a56c1cdd01889', 'message': 'Use local apt mirror for tripleo-cd builds.\n\nMore fast is faster.\n\nChange-Id: I994e3939fb0db8029185f1674759ebfa92307e57\n'}, {'number': 2, 'created': '2014-02-24 06:22:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-image-elements/commit/38a60f901c1c09543f0fb54492d7b843ed74e529', 'message': 'Use local apt mirror for tripleo-cd builds.\n\nMore fast is faster.\n\nChange-Id: I994e3939fb0db8029185f1674759ebfa92307e57\n'}, {'number': 3, 'created': '2014-02-25 04:26:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-image-elements/commit/5c2205a22d9e8852c7c4c653dab6eee160d8cec6', 'message': ""Use local apt and pypi mirror for tripleo-cd/\n\nMore fast is faster. Much vrooom. pip-cache is not concurrency-safe,\nso remove that, and pypi-openstack is subject to network vaguaries,\nwhich is why I'm bringing the mirror in.\n\nChange-Id: I994e3939fb0db8029185f1674759ebfa92307e57\n""}, {'number': 4, 'created': '2014-02-26 09:46:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-image-elements/commit/ecf202a162b757feb0493dad882fec2d031ca306', 'message': ""Use local apt and pypi mirror for tripleo-cd/\n\nMore fast is faster. Much vrooom. pip-cache is not concurrency-safe,\nso remove that, and pypi-openstack is subject to network vaguaries,\nwhich is why I'm bringing the mirror in.\n\nChange-Id: I994e3939fb0db8029185f1674759ebfa92307e57\n""}, {'number': 5, 'created': '2014-02-26 09:47:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-image-elements/commit/6a79fa9a7feefaa92d58cd7ed3e7eda6d70596f8', 'message': ""Use local apt and pypi mirror for tripleo-cd/\n\nMore fast is faster. Much vrooom. pip-cache is not concurrency-safe,\nso remove that, and pypi-openstack is subject to network vaguaries,\nwhich is why I'm bringing the mirror in.\n\nChange-Id: I994e3939fb0db8029185f1674759ebfa92307e57\n""}, {'number': 6, 'created': '2014-02-26 11:00:04.000000000', 'files': ['elements/tripleo-cd/bin/tripleo-cd.sh'], 'web_link': 'https://opendev.org/openstack/tripleo-image-elements/commit/511baaf1e291f224877b3c5088a0fce5030ff892', 'message': ""Use local apt and pypi mirror for tripleo-cd\n\nMore fast is faster. Much vrooom. pip-cache is not concurrency-safe,\nso remove that, and pypi-openstack is subject to network vaguaries,\nwhich is why I'm bringing the mirror in.\n\nChange-Id: I994e3939fb0db8029185f1674759ebfa92307e57\n""}]",1,75746,511baaf1e291f224877b3c5088a0fce5030ff892,55,6,6,4190,,,0,"Use local apt and pypi mirror for tripleo-cd

More fast is faster. Much vrooom. pip-cache is not concurrency-safe,
so remove that, and pypi-openstack is subject to network vaguaries,
which is why I'm bringing the mirror in.

Change-Id: I994e3939fb0db8029185f1674759ebfa92307e57
",git fetch https://review.opendev.org/openstack/tripleo-image-elements refs/changes/46/75746/5 && git format-patch -1 --stdout FETCH_HEAD,['elements/tripleo-cd/bin/tripleo-cd.sh'],1,07963e1263832139704997a55f3a56c1cdd01889,,export DIB_DISTRIBUTION_MIRROR=http://10.10.16.169/ubuntu,,1,0
openstack%2Fpython-ironicclient~master~I138b332102a94557f153f8982ec00d493e2472b0,openstack/python-ironicclient,master,I138b332102a94557f153f8982ec00d493e2472b0,Sort requirement files in alphabetical order,MERGED,2014-02-27 11:36:02.000000000,2014-03-07 01:39:59.000000000,2014-03-07 01:39:58.000000000,"[{'_account_id': 3}, {'_account_id': 2889}, {'_account_id': 6773}, {'_account_id': 8125}, {'_account_id': 8968}, {'_account_id': 10556}]","[{'number': 1, 'created': '2014-02-27 11:36:02.000000000', 'files': ['requirements.txt', 'test-requirements.txt', 'tools/requirements_style_check.sh', 'tox.ini'], 'web_link': 'https://opendev.org/openstack/python-ironicclient/commit/07827ed717f94ed05027787cc0c875e0a2e18844', 'message': 'Sort requirement files in alphabetical order\n\nThis makes code more readable, and can check whether specific library\nin the requirement files easily. We also enforce the check in pep8.\n\nChange-Id: I138b332102a94557f153f8982ec00d493e2472b0\nCloses-Bug: #1285478\n'}]",0,76827,07827ed717f94ed05027787cc0c875e0a2e18844,15,6,1,10513,,,0,"Sort requirement files in alphabetical order

This makes code more readable, and can check whether specific library
in the requirement files easily. We also enforce the check in pep8.

Change-Id: I138b332102a94557f153f8982ec00d493e2472b0
Closes-Bug: #1285478
",git fetch https://review.opendev.org/openstack/python-ironicclient refs/changes/27/76827/1 && git format-patch -1 --stdout FETCH_HEAD,"['requirements.txt', 'test-requirements.txt', 'tools/requirements_style_check.sh', 'tox.ini']",4,07827ed717f94ed05027787cc0c875e0a2e18844,check_requirements, {toxinidir}/tools/requirements_style_check.sh requirements.txt test-requirements.txt,,36,3
openstack%2Fironic~master~I0050d956b2df8115540f7cf66a897f8f0c751d56,openstack/ironic,master,I0050d956b2df8115540f7cf66a897f8f0c751d56,Only fetch node once for vif actions,MERGED,2014-03-06 21:02:22.000000000,2014-03-07 01:37:32.000000000,2014-03-07 01:37:32.000000000,"[{'_account_id': 3}, {'_account_id': 2889}, {'_account_id': 5805}]","[{'number': 1, 'created': '2014-03-06 21:02:22.000000000', 'files': ['ironic/nova/virt/ironic/driver.py'], 'web_link': 'https://opendev.org/openstack/ironic/commit/2b283b0ba8697dcbf43caa3f722f75599fd8a213', 'message': ""Only fetch node once for vif actions\n\nThis removes an unneeded refetching of 'node' from Ironic when plugging\nand unplugging vifs.\n\nChange-Id: I0050d956b2df8115540f7cf66a897f8f0c751d56\n""}]",0,78760,2b283b0ba8697dcbf43caa3f722f75599fd8a213,7,3,1,1030,,,0,"Only fetch node once for vif actions

This removes an unneeded refetching of 'node' from Ironic when plugging
and unplugging vifs.

Change-Id: I0050d956b2df8115540f7cf66a897f8f0c751d56
",git fetch https://review.opendev.org/openstack/ironic refs/changes/60/78760/1 && git format-patch -1 --stdout FETCH_HEAD,['ironic/nova/virt/ironic/driver.py'],1,2b283b0ba8697dcbf43caa3f722f75599fd8a213,fetch_node_once_for_vifs," self._unplug_vifs(node, instance, network_info) self._plug_vifs(node, instance, network_info) def _plug_vifs(self, node, instance, network_info): self._unplug_vifs(node, instance, network_info) def _unplug_vifs(self, node, instance, network_info): def plug_vifs(self, instance, network_info): icli = self._get_client() node = icli.node.get(instance['node']) self._plug_vifs(node, instance, network_info) def unplug_vifs(self, instance, network_info): icli = self._get_client() node = icli.node.get(instance['node']) self._unplug_vifs(node, instance, network_info)"," self.unplug_vifs(instance, network_info) self.plug_vifs(instance, network_info) def plug_vifs(self, instance, network_info): self.unplug_vifs(instance, network_info) node = icli.node.get(instance['node']) def unplug_vifs(self, instance, network_info): node = icli.node.get(instance['node'])",15,7
openstack%2Fkeystone~master~I81983b2f63307a873651c5fad961ba08a892a1a7,openstack/keystone,master,I81983b2f63307a873651c5fad961ba08a892a1a7,Auto clean expired tokens,ABANDONED,2013-08-23 17:49:40.000000000,2014-03-07 01:36:04.000000000,,"[{'_account_id': 4}, {'_account_id': 2874}]","[{'number': 1, 'created': '2013-08-23 17:49:40.000000000', 'files': ['keystone/common/config.py', 'keystone/tests/_sql_livetest.py', 'keystone/token/backends/sql.py', 'keystone/tests/tmp/legacy_essex.sqlite.db', 'keystone/tests/tmp/test.db.pristine', 'keystone/tests/tmp/test.db', 'keystone/tests/test_backend_sql.py', 'keystone/tests/tmp/legacy_d5.sqlite.db', 'keystone/tests/tmp/legacy_diablo.sqlite.db', 'keystone/tests/test_backend.py'], 'web_link': 'https://opendev.org/openstack/keystone/commit/0aadcc05e0580e53fb842bc2981a218f58751a03', 'message': 'Auto clean expired tokens\n\nProvides a config option to delete expired tokens upon\ngeneration of the revoked token list\n\nBug 1206972\n\nChange-Id: I81983b2f63307a873651c5fad961ba08a892a1a7\n'}]",0,43510,0aadcc05e0580e53fb842bc2981a218f58751a03,4,2,1,2218,,,0,"Auto clean expired tokens

Provides a config option to delete expired tokens upon
generation of the revoked token list

Bug 1206972

Change-Id: I81983b2f63307a873651c5fad961ba08a892a1a7
",git fetch https://review.opendev.org/openstack/keystone refs/changes/10/43510/1 && git format-patch -1 --stdout FETCH_HEAD,"['keystone/common/config.py', 'keystone/tests/_sql_livetest.py', 'keystone/token/backends/sql.py', 'keystone/tests/tmp/legacy_essex.sqlite.db', 'keystone/tests/tmp/test.db.pristine', 'keystone/tests/tmp/test.db', 'keystone/tests/test_backend_sql.py', 'keystone/tests/tmp/legacy_d5.sqlite.db', 'keystone/tests/tmp/legacy_diablo.sqlite.db', 'keystone/tests/test_backend.py']",10,0aadcc05e0580e53fb842bc2981a218f58751a03,bug/1206972," def create_expired_token(self): data = {'id_hash': token_id, 'id': token_id, 'a': 'b', return token_id def test_expired_token(self): token_id = self.create_expired_token()"," def test_expired_token(self): data = {'id_hash': token_id, 'id': token_id, 'a': 'b',",46,4
openstack%2Fironic~master~I45fd12452069d4c42adff71f07fc68bdafae18e4,openstack/ironic,master,I45fd12452069d4c42adff71f07fc68bdafae18e4,Remove redundant default value None for dict.get,MERGED,2014-03-04 03:37:40.000000000,2014-03-07 01:26:42.000000000,2014-03-07 01:26:42.000000000,"[{'_account_id': 3}, {'_account_id': 2889}, {'_account_id': 3099}, {'_account_id': 10018}]","[{'number': 1, 'created': '2014-03-04 03:37:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/85d808b0b118d76d528731319463eb5eccb3028e', 'message': 'Remove redundant default value None for dict.get\n\nif can not find the key in a dict,dict.get return\nNone alaready,so no need to specify it.\n\nChange-Id: I45fd12452069d4c42adff71f07fc68bdafae18e4\n'}, {'number': 2, 'created': '2014-03-05 09:58:33.000000000', 'files': ['ironic/drivers/modules/ipmitool.py', 'ironic/drivers/modules/ipminative.py'], 'web_link': 'https://opendev.org/openstack/ironic/commit/79198f10fdb35684efc9e1e9b0d5d3561ca1231d', 'message': 'Remove redundant default value None for dict.get\n\nif can not find the key in a dict,dict.get return\nNone alaready,so no need to specify it.\n\nChange-Id: I45fd12452069d4c42adff71f07fc68bdafae18e4\n'}]",0,77771,79198f10fdb35684efc9e1e9b0d5d3561ca1231d,13,4,2,10018,,,0,"Remove redundant default value None for dict.get

if can not find the key in a dict,dict.get return
None alaready,so no need to specify it.

Change-Id: I45fd12452069d4c42adff71f07fc68bdafae18e4
",git fetch https://review.opendev.org/openstack/ironic refs/changes/71/77771/2 && git format-patch -1 --stdout FETCH_HEAD,"['ironic/drivers/modules/seamicro.py', 'ironic/drivers/modules/ipmitool.py', 'ironic/drivers/modules/ipminative.py']",3,85d808b0b118d76d528731319463eb5eccb3028e,rm-dict-get-none, device = kwargs.get('device')," device = kwargs.get('device', None)",6,6
openstack%2Fironic~master~Ic7516ffb5f886a7b7be96d97798161dfeda7b743,openstack/ironic,master,Ic7516ffb5f886a7b7be96d97798161dfeda7b743,Remove jsonutils from test_rpcapi,MERGED,2014-03-03 11:31:24.000000000,2014-03-07 01:19:11.000000000,2014-03-07 01:19:11.000000000,"[{'_account_id': 3}, {'_account_id': 2889}, {'_account_id': 6773}, {'_account_id': 8106}, {'_account_id': 8125}, {'_account_id': 8412}]","[{'number': 1, 'created': '2014-03-03 11:31:24.000000000', 'files': ['ironic/tests/conductor/test_rpcapi.py'], 'web_link': 'https://opendev.org/openstack/ironic/commit/e3691e811b66785e1f74f7235313d83899f17858', 'message': 'Remove jsonutils from test_rpcapi\n\njsonutils.to_primitive() returns dict with the same key:value pairs as\ndbutils.get_test_node() in test_rpcapi, therefore it can be removed.\n\nChange-Id: Ic7516ffb5f886a7b7be96d97798161dfeda7b743\n'}]",0,77568,e3691e811b66785e1f74f7235313d83899f17858,12,6,1,7711,,,0,"Remove jsonutils from test_rpcapi

jsonutils.to_primitive() returns dict with the same key:value pairs as
dbutils.get_test_node() in test_rpcapi, therefore it can be removed.

Change-Id: Ic7516ffb5f886a7b7be96d97798161dfeda7b743
",git fetch https://review.opendev.org/openstack/ironic refs/changes/68/77568/1 && git format-patch -1 --stdout FETCH_HEAD,['ironic/tests/conductor/test_rpcapi.py'],1,e3691e811b66785e1f74f7235313d83899f17858,test-rpcapi-json, self.fake_node = dbutils.get_test_node(driver='fake-driver'),from ironic.openstack.common import jsonutils as json self.fake_node = json.to_primitive(dbutils.get_test_node( driver='fake-driver')),1,3
openstack%2Fironic~master~If068df940313b8d01cec340ddb589ac2ae47aeb3,openstack/ironic,master,If068df940313b8d01cec340ddb589ac2ae47aeb3,Updated from global requirements,MERGED,2014-03-03 16:46:51.000000000,2014-03-07 01:13:26.000000000,2014-03-07 01:13:25.000000000,"[{'_account_id': 3}, {'_account_id': 2889}]","[{'number': 1, 'created': '2014-03-03 16:46:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/aa9987d4be83e31154530cf42a080846fa31f569', 'message': 'Updated from global requirements\n\nChange-Id: If068df940313b8d01cec340ddb589ac2ae47aeb3\n'}, {'number': 2, 'created': '2014-03-05 19:23:44.000000000', 'files': ['requirements.txt'], 'web_link': 'https://opendev.org/openstack/ironic/commit/b4668a585dcfbf3f95de6bb23800980319af3fc4', 'message': 'Updated from global requirements\n\nChange-Id: If068df940313b8d01cec340ddb589ac2ae47aeb3\n'}]",0,77642,b4668a585dcfbf3f95de6bb23800980319af3fc4,12,2,2,3,,,0,"Updated from global requirements

Change-Id: If068df940313b8d01cec340ddb589ac2ae47aeb3
",git fetch https://review.opendev.org/openstack/ironic refs/changes/42/77642/1 && git format-patch -1 --stdout FETCH_HEAD,['requirements.txt'],1,aa9987d4be83e31154530cf42a080846fa31f569,openstack/requirements,"sqlalchemy-migrate>=0.8.2,!=0.8.4",sqlalchemy-migrate>=0.8.2,1,1
openstack%2Fironic~master~Ic2a4f2c03cf92fec29f34f312a03c95ea4cba86f,openstack/ironic,master,Ic2a4f2c03cf92fec29f34f312a03c95ea4cba86f,Imported Translations from Transifex,MERGED,2014-02-05 06:06:28.000000000,2014-03-07 00:37:30.000000000,2014-03-07 00:37:30.000000000,"[{'_account_id': 3}, {'_account_id': 2889}]","[{'number': 1, 'created': '2014-02-05 06:06:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/432e1a0bb53e2c24ec2b7e6eedcd34b88b1a9e8f', 'message': 'Imported Translations from Transifex\n\nChange-Id: Ic2a4f2c03cf92fec29f34f312a03c95ea4cba86f\n'}, {'number': 2, 'created': '2014-02-06 06:06:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/8125cfed4d264435b09c0793a34d246bd755fb75', 'message': 'Imported Translations from Transifex\n\nChange-Id: Ic2a4f2c03cf92fec29f34f312a03c95ea4cba86f\n'}, {'number': 3, 'created': '2014-02-07 06:05:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/b15e92c6eb61221d66dca9f50301d0d3241840d5', 'message': 'Imported Translations from Transifex\n\nChange-Id: Ic2a4f2c03cf92fec29f34f312a03c95ea4cba86f\n'}, {'number': 4, 'created': '2014-02-08 06:07:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/349e87ed5272825f90401a52d8993a7b2ae63744', 'message': 'Imported Translations from Transifex\n\nChange-Id: Ic2a4f2c03cf92fec29f34f312a03c95ea4cba86f\n'}, {'number': 5, 'created': '2014-02-09 06:05:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/21c72adf0d4c1e5a24e7ff22dd1e4193c7bfb8d6', 'message': 'Imported Translations from Transifex\n\nChange-Id: Ic2a4f2c03cf92fec29f34f312a03c95ea4cba86f\n'}, {'number': 6, 'created': '2014-02-10 06:06:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/bd257d22419289ba680ac48e6cc1bc15bb6e9cec', 'message': 'Imported Translations from Transifex\n\nChange-Id: Ic2a4f2c03cf92fec29f34f312a03c95ea4cba86f\n'}, {'number': 7, 'created': '2014-02-11 06:06:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/7cd405d53e9929954aa6ab360c07a3b2378b686a', 'message': 'Imported Translations from Transifex\n\nChange-Id: Ic2a4f2c03cf92fec29f34f312a03c95ea4cba86f\n'}, {'number': 8, 'created': '2014-02-12 06:06:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/3183e9929e99a536ba5d4a6d9af78ee69d8ae3a9', 'message': 'Imported Translations from Transifex\n\nChange-Id: Ic2a4f2c03cf92fec29f34f312a03c95ea4cba86f\n'}, {'number': 9, 'created': '2014-02-13 06:06:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/0d681543f48e02186078d962b81a45c727f07206', 'message': 'Imported Translations from Transifex\n\nChange-Id: Ic2a4f2c03cf92fec29f34f312a03c95ea4cba86f\n'}, {'number': 10, 'created': '2014-02-14 06:06:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/cc2b1dfa5788b2e613b2f6d96d56b1e0c31973b9', 'message': 'Imported Translations from Transifex\n\nChange-Id: Ic2a4f2c03cf92fec29f34f312a03c95ea4cba86f\n'}, {'number': 11, 'created': '2014-02-15 06:06:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/b3616f71e5023895affdf7cac6cdd9e1a39933a7', 'message': 'Imported Translations from Transifex\n\nChange-Id: Ic2a4f2c03cf92fec29f34f312a03c95ea4cba86f\n'}, {'number': 12, 'created': '2014-02-16 06:06:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/48aa76594708e65549fba59119457bd866607f5b', 'message': 'Imported Translations from Transifex\n\nChange-Id: Ic2a4f2c03cf92fec29f34f312a03c95ea4cba86f\n'}, {'number': 13, 'created': '2014-02-17 06:06:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/d956a7dc0e8c19fc77669d61f36d67be1b5c99d3', 'message': 'Imported Translations from Transifex\n\nChange-Id: Ic2a4f2c03cf92fec29f34f312a03c95ea4cba86f\n'}, {'number': 14, 'created': '2014-02-18 06:06:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/528a38afa746cce462f257291f3296efa902afb3', 'message': 'Imported Translations from Transifex\n\nChange-Id: Ic2a4f2c03cf92fec29f34f312a03c95ea4cba86f\n'}, {'number': 15, 'created': '2014-02-19 16:42:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/19561adda132b734dda50fd8487da21a9123f281', 'message': 'Imported Translations from Transifex\n\nChange-Id: Ic2a4f2c03cf92fec29f34f312a03c95ea4cba86f\n'}, {'number': 16, 'created': '2014-02-20 06:07:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/323195bd348d135665f040b9b1596da064fc7d99', 'message': 'Imported Translations from Transifex\n\nChange-Id: Ic2a4f2c03cf92fec29f34f312a03c95ea4cba86f\n'}, {'number': 17, 'created': '2014-02-21 06:06:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/769ce3822480552d066491d88f5b42c74d9ae043', 'message': 'Imported Translations from Transifex\n\nChange-Id: Ic2a4f2c03cf92fec29f34f312a03c95ea4cba86f\n'}, {'number': 18, 'created': '2014-02-22 06:07:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/7b15370d726db4e6512eeed5186efe9d2e336378', 'message': 'Imported Translations from Transifex\n\nChange-Id: Ic2a4f2c03cf92fec29f34f312a03c95ea4cba86f\n'}, {'number': 19, 'created': '2014-02-23 06:05:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/7680d7d9df22c55078e54d7d5895da0c3e04e477', 'message': 'Imported Translations from Transifex\n\nChange-Id: Ic2a4f2c03cf92fec29f34f312a03c95ea4cba86f\n'}, {'number': 20, 'created': '2014-02-24 06:07:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/bd09667b79c75bcf9188e1676efd6769c7c1720d', 'message': 'Imported Translations from Transifex\n\nChange-Id: Ic2a4f2c03cf92fec29f34f312a03c95ea4cba86f\n'}, {'number': 21, 'created': '2014-02-25 06:07:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/1e6df2c2d9fc81af581519d44185cd25633e919e', 'message': 'Imported Translations from Transifex\n\nChange-Id: Ic2a4f2c03cf92fec29f34f312a03c95ea4cba86f\n'}, {'number': 22, 'created': '2014-02-26 06:07:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/dbf64bbe99cb068a102dfcbdce6c7c3be9cac66d', 'message': 'Imported Translations from Transifex\n\nChange-Id: Ic2a4f2c03cf92fec29f34f312a03c95ea4cba86f\n'}, {'number': 23, 'created': '2014-02-27 06:07:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/fd5fd96b2c4f0f8474abdbfa87687e869b015e92', 'message': 'Imported Translations from Transifex\n\nChange-Id: Ic2a4f2c03cf92fec29f34f312a03c95ea4cba86f\n'}, {'number': 24, 'created': '2014-02-28 06:07:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/82c92224ca16942f94ec216ab181317b127e9374', 'message': 'Imported Translations from Transifex\n\nChange-Id: Ic2a4f2c03cf92fec29f34f312a03c95ea4cba86f\n'}, {'number': 25, 'created': '2014-03-01 06:08:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/d2b4fd00f1ffa55447291ae9e166d69369e834f4', 'message': 'Imported Translations from Transifex\n\nChange-Id: Ic2a4f2c03cf92fec29f34f312a03c95ea4cba86f\n'}, {'number': 26, 'created': '2014-03-02 06:07:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/f655e0084838387d05dc428d19e090c3a1f670bd', 'message': 'Imported Translations from Transifex\n\nChange-Id: Ic2a4f2c03cf92fec29f34f312a03c95ea4cba86f\n'}, {'number': 27, 'created': '2014-03-03 06:06:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/44c2252c2886e4e27212a4e4d6b1dfece7c7ddf7', 'message': 'Imported Translations from Transifex\n\nChange-Id: Ic2a4f2c03cf92fec29f34f312a03c95ea4cba86f\n'}, {'number': 28, 'created': '2014-03-04 06:06:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/de1415b4e4acbe4f2489a4b9c931e2de77618b61', 'message': 'Imported Translations from Transifex\n\nChange-Id: Ic2a4f2c03cf92fec29f34f312a03c95ea4cba86f\n'}, {'number': 29, 'created': '2014-03-05 06:06:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/07d0da9d4255ed9c8e0c0f93e88b6eb1ea397430', 'message': 'Imported Translations from Transifex\n\nChange-Id: Ic2a4f2c03cf92fec29f34f312a03c95ea4cba86f\n'}, {'number': 30, 'created': '2014-03-06 06:07:12.000000000', 'files': ['ironic/locale/bs/LC_MESSAGES/ironic.po', 'ironic/locale/tl_PH/LC_MESSAGES/ironic.po', 'ironic/locale/ms/LC_MESSAGES/ironic.po', 'ironic/locale/pl_PL/LC_MESSAGES/ironic.po', 'ironic/locale/he_IL/LC_MESSAGES/ironic.po', 'ironic/locale/bn_IN/LC_MESSAGES/ironic.po', 'ironic/locale/it_IT/LC_MESSAGES/ironic.po', 'ironic/locale/sw_KE/LC_MESSAGES/ironic.po', 'ironic/locale/km/LC_MESSAGES/ironic.po', 'ironic/locale/pt_BR/LC_MESSAGES/ironic.po', 'ironic/locale/eu_ES/LC_MESSAGES/ironic.po', 'ironic/locale/vi_VN/LC_MESSAGES/ironic.po', 'ironic/locale/bg_BG/LC_MESSAGES/ironic.po', 'ironic/locale/en_US/LC_MESSAGES/ironic.po', 'ironic/locale/ru/LC_MESSAGES/ironic.po', 'ironic/locale/kn/LC_MESSAGES/ironic.po', 'ironic/locale/ar/LC_MESSAGES/ironic.po', 'ironic/locale/ru_RU/LC_MESSAGES/ironic.po', 'ironic/locale/fil/LC_MESSAGES/ironic.po', 'ironic/locale/ur/LC_MESSAGES/ironic.po', 'ironic/locale/hr/LC_MESSAGES/ironic.po', 'ironic/locale/cs/LC_MESSAGES/ironic.po', 'ironic/locale/mr_IN/LC_MESSAGES/ironic.po', 'ironic/locale/sv/LC_MESSAGES/ironic.po', 'ironic/locale/da/LC_MESSAGES/ironic.po', 'ironic/locale/zh_CN/LC_MESSAGES/ironic.po', 'ironic/locale/zh_TW/LC_MESSAGES/ironic.po', 'ironic/locale/gl/LC_MESSAGES/ironic.po', 'ironic/locale/ro/LC_MESSAGES/ironic.po', 'ironic/locale/pt/LC_MESSAGES/ironic.po', 'ironic/locale/ko_KR/LC_MESSAGES/ironic.po', 'ironic/locale/ironic.pot', 'ironic/locale/tr_TR/LC_MESSAGES/ironic.po', 'ironic/locale/es_MX/LC_MESSAGES/ironic.po', 'ironic/locale/ne/LC_MESSAGES/ironic.po', 'ironic/locale/ca/LC_MESSAGES/ironic.po', 'ironic/locale/hi/LC_MESSAGES/ironic.po', 'ironic/locale/fi_FI/LC_MESSAGES/ironic.po', 'ironic/locale/en_GB/LC_MESSAGES/ironic.po', 'ironic/locale/is_IS/LC_MESSAGES/ironic.po', 'ironic/locale/zh_HK/LC_MESSAGES/ironic.po', 'ironic/locale/sk/LC_MESSAGES/ironic.po', 'ironic/locale/hu/LC_MESSAGES/ironic.po', 'ironic/locale/id/LC_MESSAGES/ironic.po', 'ironic/locale/tl/LC_MESSAGES/ironic.po', 'ironic/locale/nb/LC_MESSAGES/ironic.po', 'ironic/locale/nl_NL/LC_MESSAGES/ironic.po', 'ironic/locale/it/LC_MESSAGES/ironic.po', 'ironic/locale/fa/LC_MESSAGES/ironic.po', 'ironic/locale/es/LC_MESSAGES/ironic.po', 'ironic/locale/ka_GE/LC_MESSAGES/ironic.po', 'ironic/locale/ja/LC_MESSAGES/ironic.po', 'ironic/locale/he/LC_MESSAGES/ironic.po', 'ironic/locale/de/LC_MESSAGES/ironic.po', 'ironic/locale/pa_IN/LC_MESSAGES/ironic.po', 'ironic/locale/uk/LC_MESSAGES/ironic.po', 'ironic/locale/sl_SI/LC_MESSAGES/ironic.po', 'ironic/locale/en_AU/LC_MESSAGES/ironic.po', 'ironic/locale/fr/LC_MESSAGES/ironic.po', 'ironic/locale/eu/LC_MESSAGES/ironic.po', 'ironic/locale/ml_IN/LC_MESSAGES/ironic.po'], 'web_link': 'https://opendev.org/openstack/ironic/commit/beae2bc4d806a8bf35c7c4d2a563ff1eb5c01303', 'message': 'Imported Translations from Transifex\n\nChange-Id: Ic2a4f2c03cf92fec29f34f312a03c95ea4cba86f\n'}]",0,71192,beae2bc4d806a8bf35c7c4d2a563ff1eb5c01303,95,2,30,3,,,0,"Imported Translations from Transifex

Change-Id: Ic2a4f2c03cf92fec29f34f312a03c95ea4cba86f
",git fetch https://review.opendev.org/openstack/ironic refs/changes/92/71192/10 && git format-patch -1 --stdout FETCH_HEAD,"['ironic/locale/bs/LC_MESSAGES/ironic.po', 'ironic/locale/tl_PH/LC_MESSAGES/ironic.po', 'ironic/locale/ms/LC_MESSAGES/ironic.po', 'ironic/locale/pl_PL/LC_MESSAGES/ironic.po', 'ironic/locale/he_IL/LC_MESSAGES/ironic.po', 'ironic/locale/bn_IN/LC_MESSAGES/ironic.po', 'ironic/locale/it_IT/LC_MESSAGES/ironic.po', 'ironic/locale/sw_KE/LC_MESSAGES/ironic.po', 'ironic/locale/km/LC_MESSAGES/ironic.po', 'ironic/locale/pt_BR/LC_MESSAGES/ironic.po', 'ironic/locale/eu_ES/LC_MESSAGES/ironic.po', 'ironic/locale/vi_VN/LC_MESSAGES/ironic.po', 'ironic/locale/bg_BG/LC_MESSAGES/ironic.po', 'ironic/locale/en_US/LC_MESSAGES/ironic.po', 'ironic/locale/ru/LC_MESSAGES/ironic.po', 'ironic/locale/kn/LC_MESSAGES/ironic.po', 'ironic/locale/ar/LC_MESSAGES/ironic.po', 'ironic/locale/ru_RU/LC_MESSAGES/ironic.po', 'ironic/locale/fil/LC_MESSAGES/ironic.po', 'ironic/locale/ur/LC_MESSAGES/ironic.po', 'ironic/locale/hr/LC_MESSAGES/ironic.po', 'ironic/locale/cs/LC_MESSAGES/ironic.po', 'ironic/locale/mr_IN/LC_MESSAGES/ironic.po', 'ironic/locale/sv/LC_MESSAGES/ironic.po', 'ironic/locale/da/LC_MESSAGES/ironic.po', 'ironic/locale/zh_CN/LC_MESSAGES/ironic.po', 'ironic/locale/zh_TW/LC_MESSAGES/ironic.po', 'ironic/locale/gl/LC_MESSAGES/ironic.po', 'ironic/locale/ro/LC_MESSAGES/ironic.po', 'ironic/locale/pt/LC_MESSAGES/ironic.po', 'ironic/locale/ko_KR/LC_MESSAGES/ironic.po', 'ironic/locale/ironic.pot', 'ironic/locale/tr_TR/LC_MESSAGES/ironic.po', 'ironic/locale/es_MX/LC_MESSAGES/ironic.po', 'ironic/locale/ne/LC_MESSAGES/ironic.po', 'ironic/locale/ca/LC_MESSAGES/ironic.po', 'ironic/locale/hi/LC_MESSAGES/ironic.po', 'ironic/locale/fi_FI/LC_MESSAGES/ironic.po', 'ironic/locale/en_GB/LC_MESSAGES/ironic.po', 'ironic/locale/is_IS/LC_MESSAGES/ironic.po', 'ironic/locale/zh_HK/LC_MESSAGES/ironic.po', 'ironic/locale/sk/LC_MESSAGES/ironic.po', 'ironic/locale/hu/LC_MESSAGES/ironic.po', 'ironic/locale/id/LC_MESSAGES/ironic.po', 'ironic/locale/tl/LC_MESSAGES/ironic.po', 'ironic/locale/nb/LC_MESSAGES/ironic.po', 'ironic/locale/nl_NL/LC_MESSAGES/ironic.po', 'ironic/locale/it/LC_MESSAGES/ironic.po', 'ironic/locale/fa/LC_MESSAGES/ironic.po', 'ironic/locale/es/LC_MESSAGES/ironic.po', 'ironic/locale/ka_GE/LC_MESSAGES/ironic.po', 'ironic/locale/ja/LC_MESSAGES/ironic.po', 'ironic/locale/he/LC_MESSAGES/ironic.po', 'ironic/locale/de/LC_MESSAGES/ironic.po', 'ironic/locale/pa_IN/LC_MESSAGES/ironic.po', 'ironic/locale/uk/LC_MESSAGES/ironic.po', 'ironic/locale/sl_SI/LC_MESSAGES/ironic.po', 'ironic/locale/en_AU/LC_MESSAGES/ironic.po', 'ironic/locale/fr/LC_MESSAGES/ironic.po', 'ironic/locale/eu/LC_MESSAGES/ironic.po', 'ironic/locale/ml_IN/LC_MESSAGES/ironic.po']",61,432e1a0bb53e2c24ec2b7e6eedcd34b88b1a9e8f,transifex/translations,"""POT-Creation-Date: 2014-02-05 06:06+0000\n""#: ironic/openstack/common/db/sqlalchemy/migration.py:191#: ironic/drivers/modules/deploy_utils.py:176#: ironic/drivers/modules/deploy_utils.py:181#: ironic/drivers/modules/deploy_utils.py:184#: ironic/drivers/modules/deploy_utils.py:193#: ironic/drivers/modules/deploy_utils.py:210 #: ironic/drivers/modules/deploy_utils.py:216#: ironic/drivers/modules/deploy_utils.py:211#: ironic/drivers/modules/deploy_utils.py:212#: ironic/drivers/modules/deploy_utils.py:213#: ironic/openstack/common/db/sqlalchemy/migration.py:214 #, python-format msgid """" ""Tables \""%s\"" have non utf8 collation, please make sure all tables are "" ""CHARSET=utf8"" msgstr """" #: ironic/openstack/common/db/sqlalchemy/migration.py:238 msgid """" ""The database is not under version control, but has tables. Please stamp "" ""the current version of the schema manually."" msgstr """" #: ironic/openstack/common/db/sqlalchemy/session.py:596#: ironic/openstack/common/db/sqlalchemy/session.py:665msgid ""Database server has gone away: %s""#: ironic/openstack/common/db/sqlalchemy/session.py:743 msgid """" ""This application has not enabled MySQL traditional mode, which means "" ""silent data corruption may occur. Please encourage the application "" ""developers to enable this mode."" msgstr """" #: ironic/openstack/common/db/sqlalchemy/session.py:767#: ironic/openstack/common/db/sqlalchemy/test_migrations.py:103 #, python-format msgid ""Got lock \""%s\"""" msgstr """" #: ironic/openstack/common/db/sqlalchemy/test_migrations.py:106 #, python-format msgid ""Lock released \""%s\"""" msgstr """" #: ironic/openstack/common/db/sqlalchemy/utils.py:58#: ironic/openstack/common/db/sqlalchemy/utils.py:97#: ironic/openstack/common/db/sqlalchemy/utils.py:119#: ironic/openstack/common/db/sqlalchemy/utils.py:194#: ironic/openstack/common/db/sqlalchemy/utils.py:200#: ironic/openstack/common/db/sqlalchemy/utils.py:280#: ironic/openstack/common/db/sqlalchemy/utils.py:301#: ironic/openstack/common/db/sqlalchemy/migration_cli/ext_migrate.py:58 msgid """" ""Migration number for migrate plugin must be valid integer or empty, if "" ""you want to downgrade to initial state"" msgstr """" #~ msgid ""Got mysql server has gone away: %s"" #~ msgstr """" ","""POT-Creation-Date: 2014-02-04 06:05+0000\n""#: ironic/drivers/modules/deploy_utils.py:180#: ironic/drivers/modules/deploy_utils.py:185#: ironic/drivers/modules/deploy_utils.py:188#: ironic/drivers/modules/deploy_utils.py:197#: ironic/drivers/modules/deploy_utils.py:214 #: ironic/drivers/modules/deploy_utils.py:220#: ironic/drivers/modules/deploy_utils.py:215#: ironic/drivers/modules/deploy_utils.py:216#: ironic/drivers/modules/deploy_utils.py:217#: ironic/openstack/common/db/sqlalchemy/session.py:553#: ironic/openstack/common/db/sqlalchemy/session.py:616msgid ""Got mysql server has gone away: %s""#: ironic/openstack/common/db/sqlalchemy/session.py:697#: ironic/openstack/common/db/sqlalchemy/utils.py:60#: ironic/openstack/common/db/sqlalchemy/utils.py:99#: ironic/openstack/common/db/sqlalchemy/utils.py:121#: ironic/openstack/common/db/sqlalchemy/utils.py:196#: ironic/openstack/common/db/sqlalchemy/utils.py:202#: ironic/openstack/common/db/sqlalchemy/utils.py:282#: ironic/openstack/common/db/sqlalchemy/utils.py:303#~ msgid """" #~ ""Unable to complete the requested action"" #~ "" because node %(node)s is currently "" #~ ""in use by another process."" #~ msgstr """" #~ msgid """" #~ ""Can not change power state because "" #~ ""node %(node)s is not fully configured."" #~ msgstr """" ",3719,1928
openstack%2Fcinder~master~Iec1786612cc19452aca806b41c6be664680a923b,openstack/cinder,master,Iec1786612cc19452aca806b41c6be664680a923b,Add EMC VNX Direct Driver in Cinder,MERGED,2014-02-14 17:31:50.000000000,2014-03-07 00:31:58.000000000,2014-03-05 14:49:51.000000000,"[{'_account_id': 3}, {'_account_id': 170}, {'_account_id': 2243}, {'_account_id': 4355}, {'_account_id': 4523}, {'_account_id': 5538}, {'_account_id': 5997}, {'_account_id': 6043}, {'_account_id': 6094}, {'_account_id': 6491}, {'_account_id': 9624}]","[{'number': 1, 'created': '2014-02-14 17:31:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/b632fac386a970cf8d072c26564491f53522c310', 'message': 'Add EMC VNX Direct Driver in Cinder\n\nThis patch implements a driver based on the Cinder iSCSIDrver.\nIt performs volume operations on VNX using the NaviSecCLI command\nline tool.  It supports all required driver features.\n\nChange-Id: Iec1786612cc19452aca806b41c6be664680a923b\n'}, {'number': 2, 'created': '2014-02-14 17:36:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/52dac99463cc4fe74fbfbf0c3c4de4e076233f63', 'message': 'Add EMC VNX Direct Driver in Cinder\n\nThis patch implements a driver based on the Cinder iSCSIDrver.\nIt performs volume operations on VNX using the NaviSecCLI command\nline tool.  It supports all required driver features.\n\nImplements blueprint emc-vnx-direct-driver\n\nChange-Id: Iec1786612cc19452aca806b41c6be664680a923b\n'}, {'number': 3, 'created': '2014-02-14 21:37:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/15b920447ca2a1960642c87abe61a7d9f56d33fa', 'message': 'Add EMC VNX Direct Driver in Cinder\n\nThis patch implements a driver based on the Cinder iSCSIDrver.\nIt performs volume operations on VNX using the NaviSecCLI command\nline tool.  It supports all required driver features.\n\nImplements blueprint emc-vnx-direct-driver\n\nChange-Id: Iec1786612cc19452aca806b41c6be664680a923b\n'}, {'number': 4, 'created': '2014-02-17 04:34:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/4918e80bc909b90fa1869ff812d59133fc45b7ca', 'message': 'Add EMC VNX Direct Driver in Cinder\n\nThis patch implements a driver based on the Cinder iSCSIDrver.\nIt performs volume operations on VNX using the NaviSecCLI command\nline tool.  It supports all required driver features.\n\nImplements blueprint emc-vnx-direct-driver\n\nChange-Id: Iec1786612cc19452aca806b41c6be664680a923b\n'}, {'number': 5, 'created': '2014-02-17 20:42:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/c9c5163c103ede5f36e0cfe6bba8a58aec7443a5', 'message': 'Add EMC VNX Direct Driver in Cinder\n\nThis patch implements a driver based on the Cinder iSCSIDrver.\nIt performs volume operations on VNX using the NaviSecCLI command\nline tool.  It supports all required driver features.\n\nImplements blueprint emc-vnx-direct-driver\n\nChange-Id: Iec1786612cc19452aca806b41c6be664680a923b\n'}, {'number': 6, 'created': '2014-02-20 17:54:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/59540fa7deba165d7f6bb71b5c4f0b3295a8267e', 'message': 'Add EMC VNX Direct Driver in Cinder\n\nThis patch implements a driver based on the Cinder iSCSIDrver.\nIt performs volume operations on VNX using the NaviSecCLI command\nline tool.  It supports all required driver features.\n\nImplements blueprint emc-vnx-direct-driver\n\nChange-Id: Iec1786612cc19452aca806b41c6be664680a923b\n'}, {'number': 7, 'created': '2014-02-20 18:15:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/ebda27d76b55d2bb20a6ff5d8117fb9a6076ae12', 'message': 'Add EMC VNX Direct Driver in Cinder\n\nThis patch implements a driver based on the Cinder iSCSIDrver.\nIt performs volume operations on VNX using the NaviSecCLI command\nline tool.  It supports all required driver features.\n\nImplements blueprint emc-vnx-direct-driver\n\nChange-Id: Iec1786612cc19452aca806b41c6be664680a923b\n'}, {'number': 8, 'created': '2014-02-21 15:15:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/777c11d3c0f861383817dcc2bb6762119702f9a9', 'message': 'Add EMC VNX Direct Driver in Cinder\n\nThis patch implements a driver based on the Cinder iSCSIDrver.\nIt performs volume operations on VNX using the NaviSecCLI command\nline tool.  It supports all required driver features.\n\nImplements blueprint emc-vnx-direct-driver\n\nChange-Id: Iec1786612cc19452aca806b41c6be664680a923b\n'}, {'number': 9, 'created': '2014-02-22 17:45:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/35ee6dbdba976957d91220c86e665b599fb829d9', 'message': 'Add EMC VNX Direct Driver in Cinder\n\nThis patch implements a driver based on the Cinder iSCSIDrver.\nIt performs volume operations on VNX using the NaviSecCLI command\nline tool.  It supports all required driver features.\n\nImplements blueprint emc-vnx-direct-driver\n\nChange-Id: Iec1786612cc19452aca806b41c6be664680a923b\n'}, {'number': 10, 'created': '2014-02-24 17:25:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/1171e911dda2e30988ba93696e44c8e97e39f498', 'message': 'Add EMC VNX Direct Driver in Cinder\n\nThis patch implements a driver based on the Cinder iSCSIDrver.\nIt performs volume operations on VNX using the NaviSecCLI command\nline tool.  It supports all required driver features.\n\nImplements blueprint emc-vnx-direct-driver\n\nChange-Id: Iec1786612cc19452aca806b41c6be664680a923b\n'}, {'number': 11, 'created': '2014-02-25 13:12:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/fcb2d463ebd44bd016d9881e63188396f40232e9', 'message': 'Add EMC VNX Direct Driver in Cinder\n\nThis patch implements a driver based on the Cinder iSCSIDrver.\nIt performs volume operations on VNX using the NaviSecCLI command\nline tool.  It supports all required driver features.\n\nImplements blueprint emc-vnx-direct-driver\n\nChange-Id: Iec1786612cc19452aca806b41c6be664680a923b\n'}, {'number': 12, 'created': '2014-02-25 18:21:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/c4e6d17f02acbdaff31aee96e75d57f47e458915', 'message': 'Add EMC VNX Direct Driver in Cinder\n\nThis patch implements a driver based on the Cinder iSCSIDrver.\nIt performs volume operations on VNX using the NaviSecCLI command\nline tool.  It supports all required driver features.\n\nImplements blueprint emc-vnx-direct-driver\n\nChange-Id: Iec1786612cc19452aca806b41c6be664680a923b\n'}, {'number': 13, 'created': '2014-02-25 18:44:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/b0cb9a6c7a934d541162ab2ede7227c4f4b69640', 'message': 'Add EMC VNX Direct Driver in Cinder\n\nThis patch implements a driver based on the Cinder iSCSIDrver.\nIt performs volume operations on VNX using the NaviSecCLI command\nline tool.  It supports all required driver features.\n\nImplements blueprint emc-vnx-direct-driver\n\nChange-Id: Iec1786612cc19452aca806b41c6be664680a923b\n'}, {'number': 14, 'created': '2014-02-26 01:58:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/c282c08cc601a1b118593cb28d312fa32ea3ac4a', 'message': 'Add EMC VNX Direct Driver in Cinder\n\nThis patch implements a driver based on the Cinder iSCSIDrver.\nIt performs volume operations on VNX using the NaviSecCLI command\nline tool.  It supports all required driver features.\n\nImplements blueprint emc-vnx-direct-driver\n\nChange-Id: Iec1786612cc19452aca806b41c6be664680a923b\n'}, {'number': 15, 'created': '2014-02-26 22:35:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/945d23342352ac52c7a8d22dd888bd785649df1e', 'message': 'Add EMC VNX Direct Driver in Cinder\n\nThis patch implements a driver based on the Cinder iSCSIDrver.\nIt performs volume operations on VNX using the NaviSecCLI command\nline tool.  It supports all required driver features.\n\nImplements blueprint emc-vnx-direct-driver\n\nChange-Id: Iec1786612cc19452aca806b41c6be664680a923b\n'}, {'number': 16, 'created': '2014-02-27 13:18:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/5cfacfbb22f0b303a73913f6fdfaac5e7f6bdffb', 'message': 'Add EMC VNX Direct Driver in Cinder\n\nThis patch implements a driver based on the Cinder iSCSIDrver.\nIt performs volume operations on VNX using the NaviSecCLI command\nline tool.  It supports all required driver features.\n\nImplements blueprint emc-vnx-direct-driver\n\nChange-Id: Iec1786612cc19452aca806b41c6be664680a923b\n'}, {'number': 17, 'created': '2014-02-27 23:58:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/b3f79ec7f4e1fd48e75ae9db4a3b2ab1c91acba0', 'message': 'Add EMC VNX Direct Driver in Cinder\n\nThis patch implements a driver based on the Cinder iSCSIDrver.\nIt performs volume operations on VNX using the NaviSecCLI command\nline tool.  It supports all required driver features.\n\nImplements blueprint emc-vnx-direct-driver\n\nChange-Id: Iec1786612cc19452aca806b41c6be664680a923b\n'}, {'number': 18, 'created': '2014-02-28 00:27:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/631e4faeb6bd4a897179231ea1a68ed67e62a092', 'message': 'Add EMC VNX Direct Driver in Cinder\n\nThis patch implements a driver based on the Cinder iSCSIDrver.\nIt performs volume operations on VNX using the NaviSecCLI command\nline tool.  It supports all required driver features.\n\nImplements blueprint emc-vnx-direct-driver\n\nChange-Id: Iec1786612cc19452aca806b41c6be664680a923b\n'}, {'number': 19, 'created': '2014-03-03 00:49:16.000000000', 'files': ['etc/cinder/cinder.conf.sample', 'cinder/tests/test_emc_vnxdirect.py', 'cinder/volume/drivers/emc/emc_cli_iscsi.py', 'cinder/volume/drivers/emc/emc_vnx_cli.py'], 'web_link': 'https://opendev.org/openstack/cinder/commit/0c33d1443447e76481fdcc19af1b000d60219d10', 'message': 'Add EMC VNX Direct Driver in Cinder\n\nThis patch implements a driver based on the Cinder iSCSIDrver.\nIt performs volume operations on VNX using the NaviSecCLI command\nline tool.  It supports all required driver features.\n\nImplements blueprint emc-vnx-direct-driver\n\nChange-Id: Iec1786612cc19452aca806b41c6be664680a923b\n'}]",129,73672,0c33d1443447e76481fdcc19af1b000d60219d10,149,11,19,6491,,,0,"Add EMC VNX Direct Driver in Cinder

This patch implements a driver based on the Cinder iSCSIDrver.
It performs volume operations on VNX using the NaviSecCLI command
line tool.  It supports all required driver features.

Implements blueprint emc-vnx-direct-driver

Change-Id: Iec1786612cc19452aca806b41c6be664680a923b
",git fetch https://review.opendev.org/openstack/cinder refs/changes/72/73672/12 && git format-patch -1 --stdout FETCH_HEAD,"['cinder/volume/drivers/emc/emc_cli_iscsi.py', 'cinder/volume/drivers/emc/emc_vnx_cli.py']",2,b632fac386a970cf8d072c26564491f53522c310,bp/emc-vnx-direct-driver,"# Copyright (c) 2012 - 2014 EMC Corporation, Inc. # All Rights Reserved. # # Licensed under the Apache License, Version 2.0 (the ""License""); you may # not use this file except in compliance with the License. You may obtain # a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT # WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the # License for the specific language governing permissions and limitations # under the License. """""" VNX CLI on iSCSI """""" import commands import os import time from oslo.config import cfg from time import sleep from cinder import exception from cinder.openstack.common import log as logging from cinder.volume import volume_types LOG = logging.getLogger(__name__) CONF = cfg.CONF VERSION = '02.00.00' class EMCVnxCli(): """"""This class defines the functions to use the native CLI functionality."""""" stats = {'driver_version': VERSION, 'free_capacity_gb': 'unknown', 'reserved_percentage': 0, 'storage_protocol': None, 'total_capacity_gb': 'unknown', 'vendor_name': 'EMC', 'volume_backend_name': None} def __init__(self, prtcl, configuration=None): loc_opts = [ cfg.StrOpt('storage_vnx_ip_address', default='none', help='VNX ip address'), cfg.StrOpt('storage_vnx_username', default='', help='VNX username'), cfg.StrOpt('storage_vnx_password', default='', help='VNX password'), cfg.StrOpt('naviseccli_path', default='', help='Naviseccli Path'), cfg.StrOpt('storage_vnx_pool_name', default=None, help='ISCSI pool name'), cfg.IntOpt('default_timeout', default=-1, help='Default Time Out For CLI operations'), cfg.IntOpt('max_luns_per_storage_group', default=256, help='Default max number of LUNs in a storage group'), ] CONF.register_opts(loc_opts) self.protocol = prtcl self.configuration = configuration self.configuration.append_config_values(loc_opts) self.storage_ip = self.configuration.storage_vnx_ip_address self.storage_username = self.configuration.storage_vnx_username self.storage_password = self.configuration.storage_vnx_password self.pool_name = self.configuration.storage_vnx_pool_name if not self.pool_name: LOG.error(_('Pool name is not specified ')) raise exception.Error() self.timeout = self.configuration.default_timeout self.max_luns = self.configuration.max_luns_per_storage_group self.navisecclipath = self.configuration.naviseccli_path self.navisecclicmd = (_('%(cli_path)s -address %(ip)s') % {'cli_path': self.navisecclipath, 'ip': self.storage_ip}) #if there is a username/password provided, use those in the cmd line if self.storage_username is not None and \ self.storage_password is not None: self.navisecclicmd += (_(' -user %(username)s ' '-password %(password)s -scope 0') % {'username': self.storage_username, 'password': self.storage_password}) #Checking for existence of naviseccli tool if not os.path.exists(self.navisecclipath): LOG.error(_('Could not find NAVISECCLI tool ')) raise exception.Error() #Testing the naviseccli setup poolname = self._wrap_text_in_quotes(self.pool_name) test_command = (_('%(navisecclicmd)s storagepool -list ' '-name %(poolname)s -state') % {'navisecclicmd': self.navisecclicmd, 'poolname': poolname}) test_command_rc = os.system(test_command) if test_command_rc != 0: LOG.error(_('Command to test Naviseccli Failed')) raise exception.Error() def create_volume(self, volume): """"""Creates a EMC volume."""""" LOG.debug(_('Entering create_volume.')) volumesize = volume['size'] volumename = self._wrap_text_in_quotes(volume['name']) LOG.info(_('Create Volume: %(volume)s Size: %(size)s') % {'volume': volumename, 'size': volumesize}) #defining CLI command thinness = self._get_provisioning_by_volume(volume) poolname = self._wrap_text_in_quotes(self.pool_name) command_to_execute = (_('%(navisecclicmd)s lun -create ' '-type %(thinness)s -capacity ' '%(volumesize)s -sq gb -poolName %(poolname)s ' '-name %(volumename)s') % {'navisecclicmd': self.navisecclicmd, 'thinness': thinness, 'volumesize': volumesize, 'poolname': poolname, 'volumename': volumename}) #executing CLI command to create volume command_rc = os.system(command_to_execute) LOG.debug(_('Create Volume: %(volumename)s Return code: %(rc)lu') % {'volumename': volumename, 'rc': command_rc}) if command_rc == 1024: LOG.warn(_('Volume already exists')) elif command_rc != 0: LOG.error(_('Command to create the specified volume failed')) raise exception.Error() # wait for up to a minute to verify that the LUN has progressed # to Ready state command_to_verify = (_('%(navisecclicmd)s lun -list -name ' '%(volumename)s') % {'navisecclicmd': self.navisecclicmd, 'volumename': volumename}) n = 0 while n < 20: # executing cli command to check volume result_value = commands.getoutput(command_to_verify) if result_value.find(""Ready"") > -1: break sleep(3) n = n + 1 if n == 20: LOG.error(_('LUN failed to become Ready')) raise exception.Error() def delete_volume(self, volume): """"""Deletes an EMC volume."""""" LOG.debug(_('Entering delete_volume.')) volumename = self._wrap_text_in_quotes(volume['name']) #defining CLI command command_to_execute = (_('%(navisecclicmd)s lun -destroy -name ' '%(volumename)s -forceDetach -o ') % {'navisecclicmd': self.navisecclicmd, 'volumename': volumename}) #executing CLI command to delete volume command_rc = os.system(command_to_execute) LOG.debug(_('Delete Volume: %(volumename)s Return code: %(rc)lu') % {'volumename': volumename, 'rc': command_rc}) if command_rc not in [0, 2304]: LOG.error(_('Command to delete the specified volume failed')) raise exception.Error() def extend_volume(self, volume, new_size): """"""Extends an EMC volume."""""" LOG.debug(_('Entering extend_volume.')) volumename = self._wrap_text_in_quotes(volume['name']) #defining CLI command command_to_execute = (_('%(navisecclicmd)s lun -expand -name ' '%(volumename)s -capacity %(newsize)s ' '-sq gb -o -ignoreThresholds ') % {'navisecclicmd': self.navisecclicmd, 'volumename': volumename, 'newsize': new_size}) #executing CLI command to extend volume command_rc = os.system(command_to_execute) LOG.debug(_('Extend Volume: %(volumename)s Return code: %(rc)lu') % {'volumename': volumename, 'rc': command_rc}) if command_rc == 24832: LOG.error(_('The LUN cannot be expanded or shrunk because' 'it has snapshots')) LOG.error(_('Command to extend the specified volume failed')) raise exception.Error() if command_rc != 0: LOG.error(_('Command to extend the specified volume failed')) raise exception.Error() def update_volume_status(self): """"""Retrieve status info."""""" LOG.debug(_(""Updating volume status"")) poolname = self._wrap_text_in_quotes(self.pool_name) command_to_execute = (_('%(navisecclicmd)s storagepool -list -name ' '%(poolname)s -userCap -availableCap') % {'navisecclicmd': self.navisecclicmd, 'poolname': poolname}) pool_details = commands.getoutput(command_to_execute).split('\n') #this output structure is confined with naviseccli commands only. #need to update the steps if the output format for command changes. #command :: storagepool -list self.stats['total_capacity_gb'] = float( pool_details[3].split(':')[1].strip()) self.stats['free_capacity_gb'] = float( pool_details[5].split(':')[1].strip()) return self.stats def create_export(self, context, volume): """"""Driver entry point to get the export info for a new volume."""""" volumename = volume['name'] device_id = self._find_lun_id(volumename) LOG.debug(_('create_export: Volume: %(volume)s Device ID: ' '%(device_id)s') % {'volume': volumename, 'device_id': device_id}) return {'provider_location': device_id} def _find_lun_id(self, volumename): """"""Returns the LUN of a volume."""""" volumename = self._wrap_text_in_quotes(volumename) command_to_execute = (_('%(navisecclicmd)s lun -list -name ' '%(volumename)s') % {'navisecclicmd': self.navisecclicmd, 'volumename': volumename}) vol_details = commands.getoutput(command_to_execute).split('\n') lun = vol_details[0].split(' ')[3] return lun def create_snapshot(self, snapshot): """"""Creates a snapshot."""""" LOG.debug(_('Entering create_snapshot.')) snapshotname = self._wrap_text_in_quotes(snapshot['name']) volumename = snapshot['volume_name'] LOG.info(_('Create snapshot: %(snapshot)s: volume: %(volume)s') % {'snapshot': snapshotname, 'volume': volumename}) volume_lun = self._find_lun_id(volumename) #defining CLI command command_to_execute = (_('%(navisecclicmd)s snap -create -res ' '%(volumelun)s -name %(snapshotname)s ' '-allowReadWrite yes') % {'navisecclicmd': self.navisecclicmd, 'volumelun': volume_lun, 'snapshotname': snapshotname}) #executing CLI command to create snapshot command_rc = os.system(command_to_execute) LOG.debug(_('Create Snapshot: %(snapshotname)s Return code: %(rc)lu') % {'snapshotname': snapshotname, 'rc': command_rc}) if command_rc != 0: LOG.error(_('Command to create the specified Snapshot failed')) raise exception.Error() def delete_snapshot(self, snapshot): """"""Deletes a snapshot."""""" LOG.debug(_('Entering delete_snapshot.')) snapshotname = self._wrap_text_in_quotes(snapshot['name']) volumename = self._wrap_text_in_quotes(snapshot['volume_name']) LOG.info(_('Delete Snapshot: %(snapshot)s: volume: %(volume)s') % {'snapshot': snapshotname, 'volume': volumename}) #defining CLI command command_to_execute = (_('%(navisecclicmd)s snap -destroy -id ' '%(snapshotname)s -o') % {'navisecclicmd': self.navisecclicmd, 'snapshotname': snapshotname}) #executing CLI command command_rc = os.system(command_to_execute) LOG.debug(_('Delete Snapshot: Volume: %(volumename)s Snapshot: ' '%(snapshotname)s Return code: %(rc)lu') % {'volumename': volumename, 'snapshotname': snapshotname, 'rc': command_rc}) if command_rc not in [0, 2304, 1280]: if command_rc == 768: LOG.info(_('Snapshot is in use')) time.sleep(90) self.delete_snapshot(snapshot) else: LOG.error(_('Command to delete the specified snapshot failed')) raise exception.Error() def _verify_sync_status(self, volumename): """"""Returns True if sync is complete else False."""""" total_default_timeout = int(self.timeout) * 60 default_sleep = 60 loop_count = int(total_default_timeout / default_sleep) sync_status = False counter = 0 volumename = self._wrap_text_in_quotes(volumename) command_to_execute = (_('%(navisecclicmd)s lun -list -name ' '%(volumename)s -attachedSnapshot') % {'navisecclicmd': self.navisecclicmd, 'volumename': volumename}) while not sync_status: try: vol_details =\ commands.getoutput(command_to_execute).split('\n') snapshotname = vol_details[2].split(':')[1].strip() except Exception: break if (snapshotname == 'N/A'): sync_status = True break else: LOG.info(_('Waiting to get the update on Sync status .....')) if (counter < loop_count): counter += 1 time.sleep(default_sleep) continue else: break return sync_status def create_volume_from_snapshot(self, volume, snapshot): """"""Creates a volume from a snapshot."""""" LOG.debug(_('Entering create_volume_from_snapshot.')) snapshotname = self._wrap_text_in_quotes(snapshot['name']) source_volume_name = self._wrap_text_in_quotes(snapshot['volume_name']) volumename = self._wrap_text_in_quotes(volume['name']) volumesize = snapshot['volume_size'] #defining CLI command command_to_execute = (_('%(navisecclicmd)s lun -create -type Snap ' '-primaryLunName %(sourcelun)s ' '-name %(volumename)s') % {'navisecclicmd': self.navisecclicmd, 'sourcelun': source_volume_name, 'volumename': volumename}) #executing CLI command command_rc = os.system(command_to_execute) LOG.debug(_('Create mount point : Volume: %(volumename)s ' 'Source Volume: %(sourcevolumename)s Return code: %(rc)lu') % {'volumename': volumename, 'sourcevolumename': source_volume_name, 'rc': command_rc}) if command_rc != 0: LOG.error(_('Command to create the specified mount point failed')) raise exception.Error() #defining CLI command command_to_execute = (_('%(navisecclicmd)s lun -attach -name ' '%(volumename)s -snapName %(snapshotname)s') % {'navisecclicmd': self.navisecclicmd, 'volumename': volumename, 'snapshotname': snapshotname}) #executing CLI command command_rc = os.system(command_to_execute) LOG.debug(_('Attaching mount point Volume: %(volumename)s ' 'with Snapshot: %(snapshotname)s Return code: %(rc)lu') % {'volumename': volumename, 'snapshotname': snapshotname, 'rc': command_rc}) if command_rc != 0: LOG.error(_('Command to attach the specified mount point Volume ' 'with Snapshot failed')) raise exception.Error() tempvolumename = 'openstack-temp-volume' #deleting any existing volume with the same name as of tempvolume LOG.info(_('Deleting Existing Temporary Volume IF present: %s ') % (tempvolumename)) command_to_execute = (_(""%(navisecclicmd)s lun -destroy -name "" ""%(tempvolumename)s -forceDetach -o"") % {'navisecclicmd': self.navisecclicmd, 'tempvolumename': tempvolumename}) os.system(command_to_execute) LOG.info(_('Creating Temporary Volume : %s ') % (tempvolumename)) poolname = self._wrap_text_in_quotes(self.pool_name) thinness = self._get_provisioning_by_volume(volume) #defining CLI command command_to_execute = (_('%(navisecclicmd)s lun -create ' '-type %(thinness)s -capacity %(volumesize)s ' '-sq gb -poolName %(poolname)s -name ' '%(tempvolumename)s') % {'navisecclicmd': self.navisecclicmd, 'thinness': thinness, 'poolname': poolname, 'volumesize': volumesize, 'tempvolumename': tempvolumename}) #executing CLI command command_rc = os.system(command_to_execute) LOG.debug(_('Create temporary Volume: %(volumename)s ' 'Return code : %(rc)lu') % {'volumename': tempvolumename, 'rc': command_rc}) if command_rc != 0: LOG.error(_('Command to create the temporary Volume failed')) raise exception.Error() source_vol_lun = self._find_lun_id(volumename) temp_vol_lun = self._find_lun_id(tempvolumename) LOG.info(_('Migrating Mount Point Volume: %s ') % (volumename)) #defining CLI command command_to_execute = (_('%(navisecclicmd)s migrate -start -source ' '%(source)s -dest %(destination)s -rate ASAP -o') % {'navisecclicmd': self.navisecclicmd, 'source': source_vol_lun, 'destination': temp_vol_lun}) #executing CLI command command_rc = os.system(command_to_execute) LOG.debug(_('Migrate Mount Point Volume: %(volumename)s ' 'Return code : %(rc)lu') % {'volumename': volumename, 'rc': command_rc}) if command_rc != 0: LOG.error(_('Command to migrate mount point Volume failed')) raise exception.Error() sync_status = self._verify_sync_status(volumename) if not sync_status: LOG.error(_('Synchronisation after migration failed.')) raise exception.Error() def create_cloned_volume(self, volume, src_vref): """"""Creates a clone of the specified volume."""""" source_volume_name = self._wrap_text_in_quotes(src_vref['name']) volumename = self._wrap_text_in_quotes(volume['name']) volumesize = src_vref['size'] snapshotname = source_volume_name + '-temp-snapshot' snapshot = { 'name': snapshotname, 'volume_name': source_volume_name, 'volume_size': volumesize, } #Create temp Snapshot self.create_snapshot(snapshot) #Create volume self.create_volume_from_snapshot(volume, snapshot) #Delete temp Snapshot self.delete_snapshot(snapshot) def get_storage_group(self, hostname): """"""Returns the storage group for the host node."""""" storage_groupname = self._wrap_text_in_quotes(hostname) command_to_execute = (_('%(navisecclicmd)s storagegroup -list ' '-gname %(storage_groupname)s') % {'navisecclicmd': self.navisecclicmd, 'storage_groupname': storage_groupname}) command_rc = os.system(command_to_execute) if command_rc != 0: LOG.debug(_('creating new storage group')) command_to_execute = (_('%(navisecclicmd)s storagegroup -create ' '-gname %(storagegrpname)s') % {'navisecclicmd': self.navisecclicmd, 'storagegrpname': storage_groupname}) command_rc = os.system(command_to_execute) LOG.debug(_('Create new storage group : %(storage_groupname)s, ' 'Return Code: %(rc)s') % {'storage_groupname': storage_groupname, 'rc': command_rc}) if command_rc != 0: LOG.error(_('Command to create the storage group failed')) raise exception.Error() #connecting the new storagegroup to the host command_to_execute = (_('%(navisecclicmd)s storagegroup ' '-connecthost -host %(hostname)s ' '-gname %(storagegrpname)s -o') % {'navisecclicmd': self.navisecclicmd, 'hostname': hostname, 'storagegrpname': storage_groupname}) command_rc = os.system(command_to_execute) LOG.debug(_('Connect storage group : %(storage_groupname)s ,' 'To Host : %(hostname)s, Return Code : %(rc)s') % {'storage_groupname': storage_groupname, 'hostname': hostname, 'rc': command_rc}) if command_rc != 0: LOG.error(_('Command to connect with storage group failed')) raise exception.Error() return hostname def find_device_details(self, volume, storage_group): """"""Returns the Host Device number for the volume."""""" volumename = self._wrap_text_in_quotes(volume['name']) storage_group = self._wrap_text_in_quotes(storage_group) allocated_lun_id = self._find_lun_id(volumename) host_lun_id = -1 lun_map = {} command_to_execute = (_('%(navisecclicmd)s storagegroup -list ' '-gname %(storagegrpname)s') % {'navisecclicmd': self.navisecclicmd, 'storagegrpname': storage_group}) output = commands.getoutput(command_to_execute) if output.find('HLU/ALU Pairs') == -1: LOG.info(_('NO LUNs in the storagegroup : %s ') % (storage_group)) else: sg_details = output.split('HLU/ALU Pairs:')[1] sg_lun_details = sg_details.split('Shareable')[0] lun_details = sg_lun_details.split('\n') for data in lun_details: if data not in ['', ' HLU Number ALU Number', ' ---------- ----------']: data = data.strip() items = data.split(' ') lun_map[int(items[len(items) - 1])] = int(items[0]) for lun in lun_map.iterkeys(): if lun == int(allocated_lun_id): host_lun_id = lun_map[lun] LOG.debug(_('Host Lun Id : %s') % (host_lun_id)) break #finding the owner SP for the LUN command_to_execute = (_('%(navisecclicmd)s lun -list -l ' '%(lunid)s -owner') % {'navisecclicmd': self.navisecclicmd, 'lunid': allocated_lun_id}) output = commands.getoutput(command_to_execute).split('\n') owner_sp = output[2].split('Current Owner: SP ')[1] LOG.debug(_('Owner SP : %s') % (owner_sp)) device = { 'hostlunid': host_lun_id, 'ownersp': owner_sp, 'lunmap': lun_map, } return device def _get_host_lun_id(self, host_lun_id_list): """"""Returns the host lun id for the LUN to be added in the storage group. """""" existing_hlu_set = set(host_lun_id_list) smallest_hlu = min(existing_hlu_set) #check for the smallest value of HLU if smallest_hlu != 0: return 0 largest_hlu = max(existing_hlu_set) #check for the largest value of HLU if largest_hlu != (self.max_luns - 1): return (largest_hlu + 1) #Search for an unassigned number full_hlu_set = set(xrange(smallest_hlu, largest_hlu + 1)) missing_hlu_list = sorted(list(full_hlu_set - existing_hlu_set)) if missing_hlu_list: return missing_hlu_list[0] def _add_lun_to_storagegroup(self, volume, storage_group): storage_groupname = self._wrap_text_in_quotes(storage_group) volumename = self._wrap_text_in_quotes(volume['name']) allocated_lun_id = self._find_lun_id(volumename) count = 0 while(count < 5): device_info = self.find_device_details(volume, storage_group) device_number = device_info['hostlunid'] if device_number < 0: lun_map = device_info['lunmap'] if lun_map: host_lun_id_list = lun_map.values() if len(host_lun_id_list) == self.max_luns: LOG.error(_('The storage group has reached the ' 'maximum capacity of LUNs')) LOG.error(_('Command to add LUN for volume - %s ' 'in storagegroup failed') % (volumename)) raise exception.Error() host_lun_id = self._get_host_lun_id(host_lun_id_list) if host_lun_id == None: LOG.error(_('Unable to get new host lun id. Please ' 'check if the storage group can accomodate ' 'new LUN')) LOG.error(_('Command to add LUN for volume - %s ' 'in storagegroup failed') % (volumename)) raise exception.Error() else: host_lun_id = 0 # chenj20 host_lun_id = 1 command_to_execute = (_('%(navisecclicmd)s storagegroup ' '-addhlu -o -gname %(storagegrpname)s ' '-hlu %(hostlunid)s -alu %(lunid)s') % {'navisecclicmd': self.navisecclicmd, 'storagegrpname': storage_groupname, 'hostlunid': host_lun_id, 'lunid': allocated_lun_id}) command_rc = os.system(command_to_execute) LOG.debug(_('Add LUN to storagegroup . Return Code : %s') % (command_rc)) if command_rc == 0: return host_lun_id if command_rc == 16896: LOG.error(_('storagegroup command failed:' 'Requested Host LUN Number already in use')) count += 1 else: LOG.debug(_('LUN was already added in the storage group')) return device_number if count == 5: LOG.error(_('Command to add LUN for volume - %s ' 'in storagegroup failed') % (volumename)) raise exception.Error() def _remove_lun_from_storagegroup(self, device_number, storage_group): storage_groupname = self._wrap_text_in_quotes(storage_group) command_to_execute = (_('%(navisecclicmd)s storagegroup -removehlu ' '-gname %(storagegrpname)s ' '-hlu %(hostlunid)s -o') % {'navisecclicmd': self.navisecclicmd, 'storagegrpname': storage_groupname, 'hostlunid': device_number}) command_rc = os.system(command_to_execute) LOG.debug(_('Remove LUN from storagegroup . Return Code : %s') % (command_rc)) if command_rc != 0: LOG.error(_('Command to remove LUN from storagegroup failed')) raise exception.Error() def initialize_connection(self, volume, connector): """"""Initializes the connection and returns connection info."""""" hostname = connector['host'] storage_group = self.get_storage_group(hostname) device_number = self._add_lun_to_storagegroup(volume, storage_group) return device_number def terminate_connection(self, volume, connector): """"""Disallow connection from connector."""""" hostname = connector['host'] storage_group = self.get_storage_group(hostname) device_info = self.find_device_details(volume, storage_group) device_number = device_info['hostlunid'] if device_number < 0: LOG.error(_('Could not locate the attached volume.')) else: self._remove_lun_from_storagegroup(device_number, storage_group) def _find_iscsi_protocol_endpoints(self, device_sp): """"""Returns the iSCSI initiators for a SP."""""" initiator_address = [] command_to_execute = (_('%(navisecclicmd)s connection -getport ' '-sp %(devicesp)s') % {'navisecclicmd': self.navisecclicmd, 'devicesp': device_sp}) output = commands.getoutput(command_to_execute).split('SP: ') for port in output: port_info = port.split('\n') if port_info[0] == device_sp: port_wwn = port_info[2].split('Port WWN:')[1].strip() initiator_address.append(port_wwn) LOG.debug(_('WWNs found for SP %(devicesp)s ' 'are: %(initiator_address)s') % {'devicesp': device_sp, 'initiator_address': initiator_address}) return initiator_address def _get_volumetype_extraspecs(self, volume): specs = {} type_id = volume['volume_type_id'] if type_id is not None: specs = volume_types.get_volume_type_extra_specs(type_id) return specs def _wrap_text_in_quotes(self, text): QUOTE = '""' if len(text) == 0: text_quoted = QUOTE + text + QUOTE elif len(text) > 0 and not (text[0] == QUOTE and text[-1] == QUOTE): text_quoted = QUOTE + text + QUOTE else: text_quoted = text return text_quoted def _get_provisioning_by_volume(self, volume): # By default, the user can not create thin LUN without thin # provisioning enabler. thinness = 'NonThin' spec_id = 'storagetype:provisioning' specs = self._get_volumetype_extraspecs(volume) if specs and spec_id in specs: provisioning = specs[spec_id].lower() if 'thin' == provisioning: thinness = 'Thin' elif 'thick' != provisioning: LOG.warning(_('Invalid value of extra spec ' '\'storagetype:provisioning\': %(provisioning)s') % {'provisioning': specs[spec_id]}) else: LOG.info(_('No extra spec \'storagetype:provisioning\' exist')) return thinness ",,1052,0
openstack%2Ftempest~master~I04b0516e03eeb8b8f95d72259aa78f573db6ae45,openstack/tempest,master,I04b0516e03eeb8b8f95d72259aa78f573db6ae45,Cleanup subnet creation in network api tests,MERGED,2014-03-03 20:49:45.000000000,2014-03-07 00:08:04.000000000,2014-03-07 00:08:03.000000000,"[{'_account_id': 3}, {'_account_id': 1192}, {'_account_id': 2750}, {'_account_id': 5196}, {'_account_id': 5803}, {'_account_id': 6524}, {'_account_id': 9008}]","[{'number': 1, 'created': '2014-03-03 20:49:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/1af60be7aab7406383c5dd4dd232296b6e88c8ac', 'message': 'Cleanup subnet creation in network api tests\n\nThis commit accomplishes 2 things, first it deduplicates the subnet\ncreation code by changing test_create_update_delete_network_subnet()\nto use the common create_subnet() class method. Secondly the common\ncreate_subnet() method is changed to properly use else after the for\nloop instead of what was done before.\n\nChange-Id: I04b0516e03eeb8b8f95d72259aa78f573db6ae45\n'}, {'number': 2, 'created': '2014-03-03 20:49:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/e407040c341a6c30fd35af70e208d3497fc8b65d', 'message': 'Cleanup subnet creation in network api tests\n\nThis commit accomplishes 2 things, first it deduplicates the subnet\ncreation code by changing test_create_update_delete_network_subnet()\nto use the common create_subnet() class method. Secondly the common\ncreate_subnet() method is changed to properly use else after the for\nloop instead of what was done before.\n\nChange-Id: I04b0516e03eeb8b8f95d72259aa78f573db6ae45\n'}, {'number': 3, 'created': '2014-03-03 22:35:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/6cf6466b221ca345885ff8062ef3e805749e004b', 'message': 'Cleanup subnet creation in network api tests\n\nThis commit accomplishes 2 things, first it deduplicates the subnet\ncreation code by changing test_create_update_delete_network_subnet()\nto use the common create_subnet() class method. Secondly the common\ncreate_subnet() method is changed to properly use else after the for\nloop instead of what was done before.\n\nChange-Id: I04b0516e03eeb8b8f95d72259aa78f573db6ae45\n'}, {'number': 4, 'created': '2014-03-03 23:26:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/a962a2fca5f5d82949c7cb8eee29c46c2483998a', 'message': 'Cleanup subnet creation in network api tests\n\nThis commit accomplishes 2 things, first it deduplicates the subnet\ncreation code by changing test_create_update_delete_network_subnet()\nto use the common create_subnet() class method. Secondly the common\ncreate_subnet() method is changed to properly use else after the for\nloop instead of what was done before.\n\nChange-Id: I04b0516e03eeb8b8f95d72259aa78f573db6ae45\n'}, {'number': 5, 'created': '2014-03-04 01:05:44.000000000', 'files': ['tempest/api/network/test_networks.py', 'tempest/api/network/base.py'], 'web_link': 'https://opendev.org/openstack/tempest/commit/6b8cd2a370210653483996f4ce39d738ed4b03e0', 'message': 'Cleanup subnet creation in network api tests\n\nThis commit accomplishes 2 things, first it deduplicates the subnet\ncreation code by changing test_create_update_delete_network_subnet()\nto use the common create_subnet() class method. Secondly the common\ncreate_subnet() method is changed to properly use else after the for\nloop instead of what was done before.\n\nChange-Id: I04b0516e03eeb8b8f95d72259aa78f573db6ae45\n'}]",2,77699,6b8cd2a370210653483996f4ce39d738ed4b03e0,23,7,5,5196,,,0,"Cleanup subnet creation in network api tests

This commit accomplishes 2 things, first it deduplicates the subnet
creation code by changing test_create_update_delete_network_subnet()
to use the common create_subnet() class method. Secondly the common
create_subnet() method is changed to properly use else after the for
loop instead of what was done before.

Change-Id: I04b0516e03eeb8b8f95d72259aa78f573db6ae45
",git fetch https://review.opendev.org/openstack/tempest refs/changes/99/77699/5 && git format-patch -1 --stdout FETCH_HEAD,"['tempest/api/network/test_networks.py', 'tempest/api/network/base.py']",2,1af60be7aab7406383c5dd4dd232296b6e88c8ac,stop_config_getattr_import, else: message = 'Available CIDR for subnet creation could not be found' raise exceptions.BuildErrorException(message), body = None failure = None # save the failure in case all of the CIDRs are overlapping failure = e if not body and failure: raise failure ,6,27
openstack%2Fnova~master~I1358c36dff47b4ecd07841535aa0653d0f6ba823,openstack/nova,master,I1358c36dff47b4ecd07841535aa0653d0f6ba823,Fix anti-affinity race condition on boot,MERGED,2014-03-04 06:42:12.000000000,2014-03-07 00:07:03.000000000,2014-03-07 00:06:58.000000000,"[{'_account_id': 3}, {'_account_id': 782}, {'_account_id': 1561}, {'_account_id': 1653}, {'_account_id': 1812}, {'_account_id': 4393}, {'_account_id': 5170}, {'_account_id': 5511}, {'_account_id': 8768}, {'_account_id': 9008}, {'_account_id': 9578}]","[{'number': 1, 'created': '2014-03-04 06:42:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/48f6f1156e8d322a41089d976fb5d9139644a957', 'message': ""Fix anti-affinity race condition on boot\n\nThe scheduler enforces anti-affinity policy.  However, since\nscheduling can happen in parallel for more than one instance, it's\npossible for the scheduler to schedule an instance to a host that will\nend up violating anti-affinity.\n\nThis patch updates the instance build code in the compute manager to\ndo an anti-affinity policy sanity check.  If the policy would be\nviolated by spawning the instance locally, an exception is raised so\nthat it gets rescheduled.\n\nPart of blueprint instance-group-api-extension\n\nChange-Id: I1358c36dff47b4ecd07841535aa0653d0f6ba823\n""}, {'number': 2, 'created': '2014-03-04 13:12:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/dab692854efbcc30572073cab49bef8f293efe2e', 'message': ""Fix anti-affinity race condition on boot\n\nThe scheduler enforces anti-affinity policy.  However, since\nscheduling can happen in parallel for more than one instance, it's\npossible for the scheduler to schedule an instance to a host that will\nend up violating anti-affinity.\n\nThis patch updates the instance build code in the compute manager to\ndo an anti-affinity policy sanity check.  If the policy would be\nviolated by spawning the instance locally, an exception is raised so\nthat it gets rescheduled.\n\nPart of blueprint instance-group-api-extension\n\nChange-Id: I1358c36dff47b4ecd07841535aa0653d0f6ba823\n""}, {'number': 3, 'created': '2014-03-04 13:24:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/069cb6989aa9cf54c70b791727d9e00ded43a520', 'message': ""Fix anti-affinity race condition on boot\n\nThe scheduler enforces anti-affinity policy.  However, since\nscheduling can happen in parallel for more than one instance, it's\npossible for the scheduler to schedule an instance to a host that will\nend up violating anti-affinity.\n\nThis patch updates the instance build code in the compute manager to\ndo an anti-affinity policy sanity check.  If the policy would be\nviolated by spawning the instance locally, an exception is raised so\nthat it gets rescheduled.\n\nPart of blueprint instance-group-api-extension\n\nChange-Id: I1358c36dff47b4ecd07841535aa0653d0f6ba823\n""}, {'number': 4, 'created': '2014-03-04 22:14:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/7362c7654ecc0113b2286f780ba11c5ee29f8c34', 'message': ""Fix anti-affinity race condition on boot\n\nThe scheduler enforces anti-affinity policy.  However, since\nscheduling can happen in parallel for more than one instance, it's\npossible for the scheduler to schedule an instance to a host that will\nend up violating anti-affinity.\n\nThis patch updates the instance build code in the compute manager to\ndo an anti-affinity policy sanity check.  If the policy would be\nviolated by spawning the instance locally, an exception is raised so\nthat it gets rescheduled.\n\nPart of blueprint instance-group-api-extension\n\nChange-Id: I1358c36dff47b4ecd07841535aa0653d0f6ba823\n""}, {'number': 5, 'created': '2014-03-06 20:58:08.000000000', 'files': ['nova/compute/manager.py', 'nova/tests/compute/test_compute.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/a79ecbeb7d74ca2a71eaf47e410226833b1c0388', 'message': ""Fix anti-affinity race condition on boot\n\nThe scheduler enforces anti-affinity policy.  However, since\nscheduling can happen in parallel for more than one instance, it's\npossible for the scheduler to schedule an instance to a host that will\nend up violating anti-affinity.\n\nThis patch updates the instance build code in the compute manager to\ndo an anti-affinity policy sanity check.  If the policy would be\nviolated by spawning the instance locally, an exception is raised so\nthat it gets rescheduled.\n\nPart of blueprint instance-group-api-extension\n\nChange-Id: I1358c36dff47b4ecd07841535aa0653d0f6ba823\n""}]",4,77800,a79ecbeb7d74ca2a71eaf47e410226833b1c0388,55,11,5,1561,,,0,"Fix anti-affinity race condition on boot

The scheduler enforces anti-affinity policy.  However, since
scheduling can happen in parallel for more than one instance, it's
possible for the scheduler to schedule an instance to a host that will
end up violating anti-affinity.

This patch updates the instance build code in the compute manager to
do an anti-affinity policy sanity check.  If the policy would be
violated by spawning the instance locally, an exception is raised so
that it gets rescheduled.

Part of blueprint instance-group-api-extension

Change-Id: I1358c36dff47b4ecd07841535aa0653d0f6ba823
",git fetch https://review.opendev.org/openstack/nova refs/changes/00/77800/1 && git format-patch -1 --stdout FETCH_HEAD,"['nova/compute/manager.py', 'nova/tests/compute/test_compute.py']",2,48f6f1156e8d322a41089d976fb5d9139644a957,bp/instance-group-api-extension," def test_run_instance_reschedules_on_anti_affinity_violation(self): group_instance = self._create_fake_instance_obj( params=dict(host=self.compute.host)) instance_group = instance_group_obj.InstanceGroup(self.context) instance_group.uuid = str(uuid.uuid4()) instance_group.members = [group_instance.uuid] instance_group.policies = ['anti-affinity'] instance_group.create() instance = jsonutils.to_primitive(self._create_fake_instance()) filter_properties = {'scheduler_hints': {'group': instance_group.uuid}} self.assertRaises(exception.RescheduledException, self.compute._build_instance, self.context, {}, filter_properties, [], None, None, True, None, instance, None, False) ",,50,0
openstack%2Fnova~master~I539424192727cf2a768d6b24ba9cf36dc56c9304,openstack/nova,master,I539424192727cf2a768d6b24ba9cf36dc56c9304,Initial scheduler support for instance_groups,MERGED,2013-06-21 12:01:09.000000000,2014-03-07 00:06:02.000000000,2014-03-07 00:05:59.000000000,"[{'_account_id': 3}, {'_account_id': 91}, {'_account_id': 782}, {'_account_id': 1501}, {'_account_id': 1561}, {'_account_id': 1653}, {'_account_id': 1812}, {'_account_id': 1849}, {'_account_id': 2166}, {'_account_id': 2667}, {'_account_id': 4393}, {'_account_id': 5170}, {'_account_id': 5511}, {'_account_id': 6062}, {'_account_id': 6447}, {'_account_id': 6495}, {'_account_id': 6507}, {'_account_id': 6509}, {'_account_id': 7040}, {'_account_id': 7138}, {'_account_id': 7166}, {'_account_id': 7317}, {'_account_id': 7494}, {'_account_id': 7629}, {'_account_id': 7758}, {'_account_id': 8125}, {'_account_id': 8478}, {'_account_id': 8768}, {'_account_id': 9008}, {'_account_id': 9578}]","[{'number': 1, 'created': '2013-06-21 12:01:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/ce7816abc52f19aefc117c117fad4ac276802109', 'message': ""Initial scheduler support for instance_groups\n\nScheduler support for blueprint instance-group-api-extension\n\nThe patch set adds the following:\n1. scheduler db access for getting instances via the instance_group uuid\n2. conductor support for removing an instance from the instance_group\n   members\n\nIn addition to this it replaces the 'group' hint with 'instance_group'.\n\nDocImpact\n\nChange-Id: I539424192727cf2a768d6b24ba9cf36dc56c9304\n""}, {'number': 2, 'created': '2013-06-21 12:07:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/69f2aae266e94eecbc32c56dbf1720bdc7430fbf', 'message': ""Initial scheduler support for instance_groups\n\nScheduler support for blueprint instance-group-api-extension\n\nThe patch set adds the following:\n1. scheduler db access for getting instances via the instance_group uuid\n2. conductor support for removing an instance from the instance_group\n   members\n\nIn addition to this it replaces the 'group' hint with 'instance_group'.\n\nDocImpact\n\nChange-Id: I539424192727cf2a768d6b24ba9cf36dc56c9304\n""}, {'number': 3, 'created': '2013-07-10 11:10:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/fa6fedfc5fa79de11f0dda44dfc14607bebb0126', 'message': ""Initial scheduler support for instance_groups\n\nScheduler support for blueprint instance-group-api-extension\n\nThe patch set adds the following:\n1. scheduler db access for getting instances via the instance_group uuid\n2. conductor support for removing an instance from the instance_group\n   members\n\nIn addition to this it replaces the 'group' hint with 'instance_group'.\n\nDocImpact\n\nChange-Id: I539424192727cf2a768d6b24ba9cf36dc56c9304\n""}, {'number': 4, 'created': '2013-07-10 13:32:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/a9e51dbdb194580a8867bdd46bf99201b0e350d8', 'message': ""Initial scheduler support for instance_groups\n\nScheduler support for blueprint instance-group-api-extension\n\nThe patch set adds the following:\n1. scheduler db access for getting instances via the instance_group uuid\n2. conductor support for removing an instance from the instance_group\n   members\n\nIn addition to this it replaces the 'group' hint with 'instance_group'.\n\nDocImpact\n\nChange-Id: I539424192727cf2a768d6b24ba9cf36dc56c9304\n""}, {'number': 5, 'created': '2013-07-10 13:35:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/6daa1f70ea0f2cacd2fabb929c4bd36f4e2e18cc', 'message': ""Initial scheduler support for instance_groups\n\nScheduler support for blueprint instance-group-api-extension\n\nThe patch set adds the following:\n1. scheduler db access for getting instances via the instance_group uuid\n2. conductor support for removing an instance from the instance_group\n   members\n\nIn addition to this it replaces the 'group' hint with 'instance_group'.\n\nDocImpact\n\nChange-Id: I539424192727cf2a768d6b24ba9cf36dc56c9304\n""}, {'number': 6, 'created': '2013-07-10 13:40:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/53742dc304b3365907674433f9f61469f55022e9', 'message': 'Initial scheduler support for instance_groups\n\nScheduler support for blueprint instance-group-api-extension\n\nChange-Id: I539424192727cf2a768d6b24ba9cf36dc56c9304\n'}, {'number': 7, 'created': '2013-08-13 14:00:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/545815817e81eea24e904762ecf8203db87f3182', 'message': 'Initial scheduler support for instance_groups\n\nScheduler support for blueprint instance-group-api-extension\n\nChange-Id: I539424192727cf2a768d6b24ba9cf36dc56c9304\n'}, {'number': 8, 'created': '2013-08-18 16:24:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/cec189a73bef729bab92b4cd94a449f002ea3189', 'message': 'Initial scheduler support for instance_groups\n\nScheduler support for blueprint instance-group-api-extension\n\nChange-Id: I539424192727cf2a768d6b24ba9cf36dc56c9304\n'}, {'number': 9, 'created': '2013-10-27 09:19:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/3665366bf94469d94f0f983a0aa5e0d1a3424482', 'message': 'Initial scheduler support for instance_groups\n\nScheduler support for blueprint instance-group-api-extension\n\nChange-Id: I539424192727cf2a768d6b24ba9cf36dc56c9304\n'}, {'number': 10, 'created': '2013-11-10 15:17:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/7c3a5c1aa8774d4025e8a65a7d403297e79bafd1', 'message': 'Initial scheduler support for instance_groups\n\nScheduler support for blueprint instance-group-api-extension\n\nChange-Id: I539424192727cf2a768d6b24ba9cf36dc56c9304\n'}, {'number': 11, 'created': '2013-11-12 18:33:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/069f679028bd1d35faf2a833fb8c3ba0ff4ec8df', 'message': 'Initial scheduler support for instance_groups\n\nScheduler support for blueprint instance-group-api-extension\n\nIn the event that a member of the instance group was deleted\nthen the instance group members will be updated to exclude that\nmember.\n\nThe scheduling code now uses the instance group object.\n\nChange-Id: I539424192727cf2a768d6b24ba9cf36dc56c9304\n'}, {'number': 12, 'created': '2013-11-12 18:38:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/fb581d497e378bdb7115cba9a16ca463215cc77b', 'message': 'Initial scheduler support for instance_groups\n\nScheduler support for blueprint instance-group-api-extension\n\nIn the event that a member of the instance group was deleted\nthen the instance group members will be updated to exclude that\nmember.\n\nThe scheduling code now uses the instance group object.\n\nChange-Id: I539424192727cf2a768d6b24ba9cf36dc56c9304\n'}, {'number': 13, 'created': '2013-12-26 12:43:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/254636a51e67307514eacfc80a48cce66b1b2657', 'message': 'Initial scheduler support for instance_groups\n\nScheduler support for blueprint instance-group-api-extension\n\nIn the event that a member of the instance group was deleted\nthen the instance group members will be updated to exclude that\nmember.\n\nThe scheduling code now uses the instance group object.\n\nChange-Id: I539424192727cf2a768d6b24ba9cf36dc56c9304\n'}, {'number': 14, 'created': '2014-01-05 13:18:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/201a6c6707f749a4eb1156e6dea2faab5e23522f', 'message': 'Initial scheduler support for instance_groups\n\nScheduler support for blueprint instance-group-api-extension\n\nIn the event that a member of the instance group was deleted\nthen the instance group members will be updated to exclude that\nmember.\n\nThe scheduling code now uses the instance group object.\n\nChange-Id: I539424192727cf2a768d6b24ba9cf36dc56c9304\n'}, {'number': 15, 'created': '2014-01-06 14:42:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/39ff17ed7407f46c5baea310f07fe344238e3fb2', 'message': 'Initial scheduler support for instance_groups\n\nScheduler support for blueprint instance-group-api-extension\n\nIn the event that a member of the instance group was deleted\nthen the instance group members will be updated to exclude that\nmember.\n\nThe scheduling code now uses the instance group object.\n\nChange-Id: I539424192727cf2a768d6b24ba9cf36dc56c9304\n'}, {'number': 16, 'created': '2014-01-08 08:23:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/e35c6a6621b60417109be5bdc2c5eb988d5b2d6c', 'message': 'Initial scheduler support for instance_groups\n\nScheduler support for blueprint instance-group-api-extension\n\nIn the event that a member of the instance group was deleted\nthen the instance group members will be updated to exclude that\nmember.\n\nThe scheduling code now uses the instance group object.\n\nChange-Id: I539424192727cf2a768d6b24ba9cf36dc56c9304\n'}, {'number': 17, 'created': '2014-01-09 08:13:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/af5bfefa1e2db4d0a7334edad6b7fdbeaf5a027a', 'message': 'Initial scheduler support for instance_groups\n\nScheduler support for blueprint instance-group-api-extension\n\nIn the event that a member of the instance group was deleted\nthen the instance group members will be updated to exclude that\nmember.\n\nThe scheduling code now uses the instance group object.\n\nChange-Id: I539424192727cf2a768d6b24ba9cf36dc56c9304\n'}, {'number': 18, 'created': '2014-01-12 09:40:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/5b8f04485cafc1b9b6ff40ca30b6c0fe19de917b', 'message': 'Initial scheduler support for instance_groups\n\nScheduler support for blueprint instance-group-api-extension\n\nIn the event that a member of the instance group was deleted\nthen the instance group members will be updated to exclude that\nmember.\n\nThe scheduling code now uses the instance group object.\n\nChange-Id: I539424192727cf2a768d6b24ba9cf36dc56c9304\n'}, {'number': 19, 'created': '2014-01-29 11:58:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/8829e80ba7b0996acc5d3ae5d7a63e2d2f1b02b5', 'message': 'Initial scheduler support for instance_groups\n\nScheduler support for blueprint instance-group-api-extension\n\nIn the event that a member of the instance group was deleted\nthen the instance group members will be updated to exclude that\nmember.\n\nThe scheduling code now uses the instance group object.\n\nChange-Id: I539424192727cf2a768d6b24ba9cf36dc56c9304\n'}, {'number': 20, 'created': '2014-02-03 13:39:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/4114d281fa575a96e97db705d29b33e3d0ff5fe4', 'message': 'Initial scheduler support for instance_groups\n\nScheduler support for blueprint instance-group-api-extension\n\nIn the event that a member of the instance group was deleted\nthen the instance group members will be updated to exclude that\nmember.\n\nThe scheduling code now uses the instance group object.\n\nChange-Id: I539424192727cf2a768d6b24ba9cf36dc56c9304\n'}, {'number': 21, 'created': '2014-02-10 09:43:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/95deb625645bdfbec872733dc7bf3814531609b3', 'message': 'Initial scheduler support for instance_groups\n\nScheduler support for blueprint instance-group-api-extension\n\nIn the event that a member of the instance group was deleted\nthen the instance group members will be updated to exclude that\nmember.\n\nThe scheduling code now uses the instance group object.\n\nChange-Id: I539424192727cf2a768d6b24ba9cf36dc56c9304\n'}, {'number': 22, 'created': '2014-02-12 09:49:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/07964036b593e039c3b4d712d91af9b3be0b7bf3', 'message': 'Initial scheduler support for instance_groups\n\nScheduler support for blueprint instance-group-api-extension\n\nIn the event that a member of the instance group was deleted\nthen the instance group members will be updated to exclude that\nmember.\n\nThe scheduling code now uses the instance group object.\n\nChange-Id: I539424192727cf2a768d6b24ba9cf36dc56c9304\n'}, {'number': 23, 'created': '2014-02-23 08:21:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/00c2365f492e77b2d901b0c2daff83164e78ba56', 'message': ""Initial scheduler support for instance_groups\n\nScheduler support for blueprint instance-group-api-extension\n\nThe scheduling code now uses the instance group object. This\npatch set adds support for 'anti-affinity' policies.\n\nChange-Id: I539424192727cf2a768d6b24ba9cf36dc56c9304\n""}, {'number': 24, 'created': '2014-02-24 16:05:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/6852255140342ef71e710b1a10843be88ccddf98', 'message': ""Initial scheduler support for instance_groups\n\nScheduler support for blueprint instance-group-api-extension\n\nThe scheduling code now uses the instance group object. This\npatch set adds support for 'anti-affinity' policies.\n\nChange-Id: I539424192727cf2a768d6b24ba9cf36dc56c9304\n""}, {'number': 25, 'created': '2014-02-25 13:56:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/4c8ec34f91eeded07b4383fcd24e7974f4a6c167', 'message': ""Initial scheduler support for instance_groups\n\nScheduler support for blueprint instance-group-api-extension\n\nThe scheduling code now uses the instance group object. This\npatch set adds support for 'anti-affinity' policies.\n\nChange-Id: I539424192727cf2a768d6b24ba9cf36dc56c9304\n""}, {'number': 26, 'created': '2014-02-27 10:10:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/1bad830bfa7e2d200bb95d8f5899ed1e50174112', 'message': ""Initial scheduler support for instance_groups\n\nScheduler support for blueprint instance-group-api-extension\n\nThe scheduling code now uses the instance group object. This\npatch set adds support for 'anti-affinity' policies.\n\nChange-Id: I539424192727cf2a768d6b24ba9cf36dc56c9304\n""}, {'number': 27, 'created': '2014-02-27 11:12:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/e87371e301bc08671d59bca47935b21d301a2466', 'message': ""Initial scheduler support for instance_groups\n\nScheduler support for blueprint instance-group-api-extension\n\nThe scheduling code now uses the instance group object. This\npatch set adds support for 'anti-affinity' policies.\n\nChange-Id: I539424192727cf2a768d6b24ba9cf36dc56c9304\n""}, {'number': 28, 'created': '2014-02-27 17:43:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/fd8c54c4c6f3315b931215aa0eb4b05dc5c50b89', 'message': ""Initial scheduler support for instance_groups\n\nScheduler support for blueprint instance-group-api-extension\n\nThe scheduling code now uses the instance group object. This\npatch set adds support for 'anti-affinity' and 'affinity'\npolicies.\n\nChange-Id: I539424192727cf2a768d6b24ba9cf36dc56c9304\n""}, {'number': 29, 'created': '2014-03-02 08:20:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/9bf82abc7f960ce74ff208fa3cd9b760ab9d190a', 'message': ""Initial scheduler support for instance_groups\n\nScheduler support for blueprint instance-group-api-extension\n\nThe scheduling code now uses the instance group object. This\npatch set adds support for 'anti-affinity' and 'affinity'\npolicies.\n\nChange-Id: I539424192727cf2a768d6b24ba9cf36dc56c9304\n""}, {'number': 30, 'created': '2014-03-03 19:14:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/fd651bd0430e229c26699e696318c203a99bb7fa', 'message': ""Initial scheduler support for instance_groups\n\nScheduler support for blueprint instance-group-api-extension\n\nThe scheduling code now uses the instance group object. This\npatch set adds support for 'anti-affinity' and 'affinity'\npolicies.\n\nChange-Id: I539424192727cf2a768d6b24ba9cf36dc56c9304\n""}, {'number': 31, 'created': '2014-03-03 22:10:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/f07f2aa7c3422f8d07a0992556cd9edca86eee43', 'message': ""Initial scheduler support for instance_groups\n\nScheduler support for blueprint instance-group-api-extension\n\nThe scheduling code now uses the instance group object. This\npatch set adds support for 'anti-affinity' and 'affinity'\npolicies.\n\nChange-Id: I539424192727cf2a768d6b24ba9cf36dc56c9304\n""}, {'number': 32, 'created': '2014-03-04 04:51:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/5f319dfcee9d8082ba6a55acd16b8a21bd106fb3', 'message': ""Initial scheduler support for instance_groups\n\nScheduler support for blueprint instance-group-api-extension\n\nThe scheduling code now uses the instance group object. This\npatch set adds support for 'anti-affinity' and 'affinity'\npolicies.\n\nChange-Id: I539424192727cf2a768d6b24ba9cf36dc56c9304\n""}, {'number': 33, 'created': '2014-03-04 05:21:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/f2c2dd28ff1c061acf4ef54ca8f142895227b1b1', 'message': ""Initial scheduler support for instance_groups\n\nScheduler support for blueprint instance-group-api-extension\n\nThe scheduling code now uses the instance group object. This\npatch set adds support for 'anti-affinity' and 'affinity'\npolicies.\n\nChange-Id: I539424192727cf2a768d6b24ba9cf36dc56c9304\n""}, {'number': 34, 'created': '2014-03-04 13:09:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/842e65abc969a186b58b1b6908f8df1d55007678', 'message': ""Initial scheduler support for instance_groups\n\nScheduler support for blueprint instance-group-api-extension\n\nThe scheduling code now uses the instance group object. This\npatch set adds support for 'anti-affinity' and 'affinity'\npolicies.\n\nChange-Id: I539424192727cf2a768d6b24ba9cf36dc56c9304\n""}, {'number': 35, 'created': '2014-03-04 13:22:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/f0545a9e3da3c9de49debf6bb6f5a68cd292dee5', 'message': ""Initial scheduler support for instance_groups\n\nScheduler support for blueprint instance-group-api-extension\n\nThe scheduling code now uses the instance group object. This\npatch set adds support for 'anti-affinity' and 'affinity'\npolicies.\n\nChange-Id: I539424192727cf2a768d6b24ba9cf36dc56c9304\n""}, {'number': 36, 'created': '2014-03-04 22:14:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/f828c76aeee7282252e9361d3dc1b18ad785cf4a', 'message': ""Initial scheduler support for instance_groups\n\nScheduler support for blueprint instance-group-api-extension\n\nThe scheduling code now uses the instance group object. This\npatch set adds support for 'anti-affinity' and 'affinity'\npolicies.\n\nCo-authored-by: Russell Bryant <rbryant@redhat.com>\nChange-Id: I539424192727cf2a768d6b24ba9cf36dc56c9304\n""}, {'number': 37, 'created': '2014-03-06 20:58:27.000000000', 'files': ['nova/tests/scheduler/test_host_filters.py', 'nova/tests/scheduler/test_filter_scheduler.py', 'nova/scheduler/filter_scheduler.py', 'nova/tests/scheduler/test_scheduler.py', 'nova/scheduler/driver.py', 'nova/scheduler/filters/affinity_filter.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/da7ffe72ef43c8b6aa31cccef84df05394322abb', 'message': ""Initial scheduler support for instance_groups\n\nScheduler support for blueprint instance-group-api-extension\n\nThe scheduling code now uses the instance group object. This\npatch set adds support for 'anti-affinity' and 'affinity'\npolicies.\n\nCo-authored-by: Russell Bryant <rbryant@redhat.com>\nChange-Id: I539424192727cf2a768d6b24ba9cf36dc56c9304\n""}]",140,33956,da7ffe72ef43c8b6aa31cccef84df05394322abb,358,30,37,1653,,,0,"Initial scheduler support for instance_groups

Scheduler support for blueprint instance-group-api-extension

The scheduling code now uses the instance group object. This
patch set adds support for 'anti-affinity' and 'affinity'
policies.

Co-authored-by: Russell Bryant <rbryant@redhat.com>
Change-Id: I539424192727cf2a768d6b24ba9cf36dc56c9304
",git fetch https://review.opendev.org/openstack/nova refs/changes/56/33956/28 && git format-patch -1 --stdout FETCH_HEAD,"['nova/tests/scheduler/test_filter_scheduler.py', 'nova/tests/conductor/test_conductor.py', 'nova/scheduler/filter_scheduler.py', 'nova/scheduler/driver.py', 'nova/conductor/manager.py']",5,ce7816abc52f19aefc117c117fad4ac276802109,bp/instance-group-api-extension," # Delete the instance from the instance_group member data system_meta = self.db.instance_system_metadata_get(context, instance['uuid']) instance_group = system_meta.get('instance_group', None) if instance_group: self.db.instance_group_member_delete(context, instance_group, instance['uuid'])",,76,24
openstack%2Fironic~master~I64c0cc0688bb35e1c387b8881bc1b1c73d7f168b,openstack/ironic,master,I64c0cc0688bb35e1c387b8881bc1b1c73d7f168b,Remove sqlalchemy-migrate from requirements.txt,ABANDONED,2014-03-06 22:55:49.000000000,2014-03-07 00:03:30.000000000,,"[{'_account_id': 3}, {'_account_id': 5805}, {'_account_id': 6773}]","[{'number': 1, 'created': '2014-03-06 22:55:49.000000000', 'files': ['requirements.txt'], 'web_link': 'https://opendev.org/openstack/ironic/commit/e9963f2c9ea92ede372800298130b52b5a5cadda', 'message': 'Remove sqlalchemy-migrate from requirements.txt\n\nWe are now using Alembic, and no longer depend on\nsqlalchemy-migrate.\n\nChange-Id: I64c0cc0688bb35e1c387b8881bc1b1c73d7f168b\n'}]",0,78803,e9963f2c9ea92ede372800298130b52b5a5cadda,4,3,1,2889,,,0,"Remove sqlalchemy-migrate from requirements.txt

We are now using Alembic, and no longer depend on
sqlalchemy-migrate.

Change-Id: I64c0cc0688bb35e1c387b8881bc1b1c73d7f168b
",git fetch https://review.opendev.org/openstack/ironic refs/changes/03/78803/1 && git format-patch -1 --stdout FETCH_HEAD,['requirements.txt'],1,e9963f2c9ea92ede372800298130b52b5a5cadda,remove-sqlamigrate,,sqlalchemy-migrate>=0.8.2,0,1
openstack%2Fnova~master~Iaf27649ac30b4aa59a3d86f997aa30cfc3d29506,openstack/nova,master,Iaf27649ac30b4aa59a3d86f997aa30cfc3d29506,Add get_hosts to InstanceGroup object,MERGED,2014-03-04 04:51:47.000000000,2014-03-06 23:53:54.000000000,2014-03-06 23:53:51.000000000,"[{'_account_id': 3}, {'_account_id': 782}, {'_account_id': 1561}, {'_account_id': 1653}, {'_account_id': 1812}, {'_account_id': 4393}, {'_account_id': 5170}, {'_account_id': 5511}, {'_account_id': 9008}, {'_account_id': 9578}]","[{'number': 1, 'created': '2014-03-04 04:51:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/062f42514c97a13b5f5a137874a514dfed8af6da', 'message': 'Add get_instances to InstanceGroup object\n\nAdd a method to the InstanceGroup object that will return an\nInstanceList of all instances in the group.\n\nTesting this uses a nova.tests.utils method for creating an instance.\nA tweak was needed in this test code to ensure that the user_id and\nproject_id were set on the instance that was created.  Otherwise, this\ntesting this new method on the InstanceGroup object failed since it\nwas filtering on the project_id.\n\nChange-Id: Iaf27649ac30b4aa59a3d86f997aa30cfc3d29506\n'}, {'number': 2, 'created': '2014-03-04 05:21:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/93e4b1d480f1a68f8305d298f28a37388ccd9ceb', 'message': 'Add get_hosts to InstanceGroup object\n\nAdd a method to the InstanceGroup object that will return a list of\nhosts for all non-deleted instances in the group.\n\nTesting this uses a nova.tests.utils method for creating an instance.\nA tweak was needed in this test code to ensure that the user_id and\nproject_id were set on the instance that was created.  Otherwise, this\ntesting this new method on the InstanceGroup object failed since it\nwas filtering on the project_id.\n\nChange-Id: Iaf27649ac30b4aa59a3d86f997aa30cfc3d29506\n'}, {'number': 3, 'created': '2014-03-04 13:21:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/5b20982a16573739467c1e896617420b8c61a162', 'message': 'Add get_hosts to InstanceGroup object\n\nAdd a method to the InstanceGroup object that will return a list of\nhosts for all non-deleted instances in the group.\n\nTesting this uses a nova.tests.utils method for creating an instance.\nA tweak was needed in this test code to ensure that the user_id and\nproject_id were set on the instance that was created.  Otherwise, this\ntesting this new method on the InstanceGroup object failed since it\nwas filtering on the project_id.\n\nChange-Id: Iaf27649ac30b4aa59a3d86f997aa30cfc3d29506\n'}, {'number': 4, 'created': '2014-03-04 22:14:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/bb2d1ef0becdd41b1c79e9e36a277e98586cd880', 'message': 'Add get_hosts to InstanceGroup object\n\nAdd a method to the InstanceGroup object that will return a list of\nhosts for all non-deleted instances in the group.\n\nTesting this uses a nova.tests.utils method for creating an instance.\nA tweak was needed in this test code to ensure that the user_id and\nproject_id were set on the instance that was created.  Otherwise, this\ntesting this new method on the InstanceGroup object failed since it\nwas filtering on the project_id.\n\nChange-Id: Iaf27649ac30b4aa59a3d86f997aa30cfc3d29506\n'}, {'number': 5, 'created': '2014-03-06 20:58:12.000000000', 'files': ['nova/objects/instance_group.py', 'nova/tests/utils.py', 'nova/tests/objects/test_instance_group.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/633f0df0096e56cad36477a760c06a8454337f70', 'message': 'Add get_hosts to InstanceGroup object\n\nAdd a method to the InstanceGroup object that will return a list of\nhosts for all non-deleted instances in the group.\n\nTesting this uses a nova.tests.utils method for creating an instance.\nA tweak was needed in this test code to ensure that the user_id and\nproject_id were set on the instance that was created.  Otherwise, this\ntesting this new method on the InstanceGroup object failed since it\nwas filtering on the project_id.\n\nChange-Id: Iaf27649ac30b4aa59a3d86f997aa30cfc3d29506\n'}]",6,77786,633f0df0096e56cad36477a760c06a8454337f70,63,10,5,1561,,,0,"Add get_hosts to InstanceGroup object

Add a method to the InstanceGroup object that will return a list of
hosts for all non-deleted instances in the group.

Testing this uses a nova.tests.utils method for creating an instance.
A tweak was needed in this test code to ensure that the user_id and
project_id were set on the instance that was created.  Otherwise, this
testing this new method on the InstanceGroup object failed since it
was filtering on the project_id.

Change-Id: Iaf27649ac30b4aa59a3d86f997aa30cfc3d29506
",git fetch https://review.opendev.org/openstack/nova refs/changes/86/77786/5 && git format-patch -1 --stdout FETCH_HEAD,"['nova/objects/instance_group.py', 'nova/tests/utils.py', 'nova/tests/objects/test_instance_group.py']",3,062f42514c97a13b5f5a137874a514dfed8af6da,bp/instance-group-api-extension,"from nova.compute import flavorsfrom nova.tests import utils as tests_utils def test_get_instances(self): instance1 = tests_utils.get_test_instance(self.context, flavor=flavors.get_default_flavor(), obj=True) instance2 = tests_utils.get_test_instance(self.context, flavor=flavors.get_default_flavor(), obj=True) instance_ids = [instance1.uuid, instance2.uuid] values = self._get_default_values() group = self._create_instance_group(self.context, values) instance_group.InstanceGroup.add_members(self.context, group.uuid, instance_ids) group = instance_group.InstanceGroup.get_by_uuid(self.context, group.uuid) instances = group.get_instances(self.context) group_instances_uuids = [instance.uuid for instance in instances] for instance in instance_ids: self.assertIn(instance, group_instances_uuids) ",,35,3
openstack%2Fsolum~master~Iab9b79de1cb1ffa26a84ba7d584e51b6d190ff9c,openstack/solum,master,Iab9b79de1cb1ffa26a84ba7d584e51b6d190ff9c,Fix functinal tests failures,ABANDONED,2014-03-06 23:45:42.000000000,2014-03-06 23:53:41.000000000,,[{'_account_id': 3}],"[{'number': 1, 'created': '2014-03-06 23:45:42.000000000', 'files': ['functionaltests/api/v1/test_service.py', 'functionaltests/api/v1/test_plan.py'], 'web_link': 'https://opendev.org/openstack/solum/commit/b905db72841737c1c607da82b3f7d7ebc5e2979f', 'message': 'Fix functinal tests failures\n\nSome functional tests are broken after Solum\nstarted using actual values from authentication information.\n\nSome test cases relying on sequesnce of execution and expect empty\noutput while the actual tests sequence can be different.\n\nChange-Id: Iab9b79de1cb1ffa26a84ba7d584e51b6d190ff9c\n'}]",0,78811,b905db72841737c1c607da82b3f7d7ebc5e2979f,2,1,1,8443,,,0,"Fix functinal tests failures

Some functional tests are broken after Solum
started using actual values from authentication information.

Some test cases relying on sequesnce of execution and expect empty
output while the actual tests sequence can be different.

Change-Id: Iab9b79de1cb1ffa26a84ba7d584e51b6d190ff9c
",git fetch https://review.opendev.org/openstack/solum refs/changes/11/78811/1 && git format-patch -1 --stdout FETCH_HEAD,"['functionaltests/api/v1/test_service.py', 'functionaltests/api/v1/test_plan.py']",2,b905db72841737c1c607da82b3f7d7ebc5e2979f,fix_functional_tests, self.assertIsNotNone(body_data['user_id']) self.assertIsNotNone(body_data['project_id'])," self.assertEqual(body_data['user_id'], data['user_id']) self.assertEqual(body_data['project_id'], data['project_id']) self.assertEqual(data, [])",4,6
openstack%2Fnova~master~Ibad59412efecbd25c01e190c33da4bf28342e95b,openstack/nova,master,Ibad59412efecbd25c01e190c33da4bf28342e95b,Add instance to instance group in compute.api,MERGED,2014-03-03 22:10:08.000000000,2014-03-06 23:52:36.000000000,2014-03-06 23:52:33.000000000,"[{'_account_id': 3}, {'_account_id': 782}, {'_account_id': 1561}, {'_account_id': 1653}, {'_account_id': 2271}, {'_account_id': 4393}, {'_account_id': 5170}, {'_account_id': 5511}, {'_account_id': 9008}, {'_account_id': 9578}]","[{'number': 1, 'created': '2014-03-03 22:10:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/b8de84a8bc6fecf18e8bc7415f70cebdc015e35d', 'message': 'Add instance to instance group in compute.api\n\nWhen a user specifies an instance group via a scheduler hint, add the\ninstance to the instance group during instance creation in the compute\nAPI.\n\nPart of blueprint instance-group-api-extension\n\nChange-Id: Ibad59412efecbd25c01e190c33da4bf28342e95b\n'}, {'number': 2, 'created': '2014-03-04 04:51:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/153918f5f6a1f386dd96200eac4a77278ad6b603', 'message': 'Add instance to instance group in compute.api\n\nWhen a user specifies an instance group via a scheduler hint, add the\ninstance to the instance group during instance creation in the compute\nAPI.\n\nPart of blueprint instance-group-api-extension\n\nChange-Id: Ibad59412efecbd25c01e190c33da4bf28342e95b\n'}, {'number': 3, 'created': '2014-03-04 22:14:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/cb71abe67a93538efe4aac8318e9c0e4172cac7f', 'message': 'Add instance to instance group in compute.api\n\nWhen a user specifies an instance group via a scheduler hint, add the\ninstance to the instance group during instance creation in the compute\nAPI.\n\nPart of blueprint instance-group-api-extension\n\nChange-Id: Ibad59412efecbd25c01e190c33da4bf28342e95b\n'}, {'number': 4, 'created': '2014-03-06 20:58:17.000000000', 'files': ['nova/tests/compute/test_compute.py', 'nova/compute/api.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/c65c18715ba0ca7a39e539c403e0372a1df692cb', 'message': 'Add instance to instance group in compute.api\n\nWhen a user specifies an instance group via a scheduler hint, add the\ninstance to the instance group during instance creation in the compute\nAPI.\n\nPart of blueprint instance-group-api-extension\n\nChange-Id: Ibad59412efecbd25c01e190c33da4bf28342e95b\n'}]",1,77711,c65c18715ba0ca7a39e539c403e0372a1df692cb,59,10,4,1561,,,0,"Add instance to instance group in compute.api

When a user specifies an instance group via a scheduler hint, add the
instance to the instance group during instance creation in the compute
API.

Part of blueprint instance-group-api-extension

Change-Id: Ibad59412efecbd25c01e190c33da4bf28342e95b
",git fetch https://review.opendev.org/openstack/nova refs/changes/11/77711/4 && git format-patch -1 --stdout FETCH_HEAD,"['nova/compute/api.py', 'nova/tests/compute/test_compute.py']",2,b8de84a8bc6fecf18e8bc7415f70cebdc015e35d,bp/instance-group-api-extension,"from nova.objects import instance_group as instance_group_obj def test_instance_create_adds_to_instance_group(self): self.stubs.Set(fake_image._FakeImageService, 'show', self.fake_show) group = instance_group_obj.InstanceGroup(self.context) group.uuid = str(uuid.uuid4()) group.create() inst_type = flavors.get_default_flavor() (refs, resv_id) = self.compute_api.create( self.context, inst_type, self.fake_image['id'], scheduler_hints={'group': group.uuid}) group = instance_group_obj.InstanceGroup.get_by_uuid(self.context, group.uuid) self.assertIn(refs[0]['uuid'], group.members) db.instance_destroy(self.context, refs[0]['uuid']) ",,33,0
openstack%2Fnova~master~I1b8349a82148bddf5cfbb7be3c8667f292df6602,openstack/nova,master,I1b8349a82148bddf5cfbb7be3c8667f292df6602,Add add_members to InstanceGroup object,MERGED,2014-03-03 22:10:07.000000000,2014-03-06 23:49:14.000000000,2014-03-06 23:49:10.000000000,"[{'_account_id': 3}, {'_account_id': 642}, {'_account_id': 782}, {'_account_id': 1561}, {'_account_id': 1653}, {'_account_id': 1812}, {'_account_id': 1849}, {'_account_id': 2750}, {'_account_id': 4393}, {'_account_id': 4395}, {'_account_id': 5170}, {'_account_id': 5511}, {'_account_id': 9008}, {'_account_id': 9578}, {'_account_id': 9971}]","[{'number': 1, 'created': '2014-03-03 22:10:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/444c82cab4cc8d18fdf4bb09807bfab3eabc49f8', 'message': 'Add add_members to InstanceGroup object\n\nThere is a db API method that safely adds a list of members to an\ninstance using a db session.  Expose it via the InstanceGroup object.\n\nPart of blueprint instance-group-api-extension\n\nChange-Id: I1b8349a82148bddf5cfbb7be3c8667f292df6602\n'}, {'number': 2, 'created': '2014-03-04 04:51:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/f863d8cfed309c12c71f4724d7ba3af4bb1ff637', 'message': 'Add add_members to InstanceGroup object\n\nThere is a db API method that safely adds a list of members to an\ninstance using a db session.  Expose it via the InstanceGroup object.\n\nPart of blueprint instance-group-api-extension\n\nChange-Id: I1b8349a82148bddf5cfbb7be3c8667f292df6602\n'}, {'number': 3, 'created': '2014-03-04 22:14:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/7f17ae59a1e8496458f97d6e346888422051edf6', 'message': 'Add add_members to InstanceGroup object\n\nThere is a db API method that safely adds a list of members to an\ninstance using a db session.  Expose it via the InstanceGroup object.\n\nPart of blueprint instance-group-api-extension\n\nChange-Id: I1b8349a82148bddf5cfbb7be3c8667f292df6602\n'}, {'number': 4, 'created': '2014-03-06 20:55:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/96f1a5e0b1bbefdfd50ca2e48b7caf478e8a8927', 'message': 'Add add_members to InstanceGroup object\n\nThere is a db API method that safely adds a list of members to an\ninstance using a db session.  Expose it via the InstanceGroup object.\n\nPart of blueprint instance-group-api-extension\n\n(kick to check)\n\nChange-Id: I1b8349a82148bddf5cfbb7be3c8667f292df6602\n'}, {'number': 5, 'created': '2014-03-06 20:58:09.000000000', 'files': ['nova/objects/instance_group.py', 'nova/tests/objects/test_instance_group.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/3026098cd03f9ea9946a06bacc73d2d4e12640c7', 'message': 'Add add_members to InstanceGroup object\n\nThere is a db API method that safely adds a list of members to an\ninstance using a db session.  Expose it via the InstanceGroup object.\n\nPart of blueprint instance-group-api-extension\n\nChange-Id: I1b8349a82148bddf5cfbb7be3c8667f292df6602\n'}]",4,77710,3026098cd03f9ea9946a06bacc73d2d4e12640c7,67,15,5,1561,,,0,"Add add_members to InstanceGroup object

There is a db API method that safely adds a list of members to an
instance using a db session.  Expose it via the InstanceGroup object.

Part of blueprint instance-group-api-extension

Change-Id: I1b8349a82148bddf5cfbb7be3c8667f292df6602
",git fetch https://review.opendev.org/openstack/nova refs/changes/10/77710/4 && git format-patch -1 --stdout FETCH_HEAD,"['nova/objects/instance_group.py', 'nova/tests/objects/test_instance_group.py']",2,444c82cab4cc8d18fdf4bb09807bfab3eabc49f8,bp/instance-group-api-extension," def test_add_members(self): instance_ids = ['fakeid1', 'fakeid2'] values = self._get_default_values() group = self._create_instance_group(self.context, values) instance_group.InstanceGroup.add_members(self.context, group.uuid, instance_ids) group = instance_group.InstanceGroup.get_by_uuid(self.context, group.uuid) for instance in instance_ids: self.assertIn(instance, group.members) ",,19,1
openstack%2Fgrenade~master~Ibb89403bbd2239cfbe693c6ae7b2cb398eb31477,openstack/grenade,master,Ibb89403bbd2239cfbe693c6ae7b2cb398eb31477,Fix base processes not stopping,MERGED,2014-03-06 18:21:19.000000000,2014-03-06 23:49:06.000000000,2014-03-06 23:49:06.000000000,"[{'_account_id': 3}, {'_account_id': 970}, {'_account_id': 1849}, {'_account_id': 2750}, {'_account_id': 5293}]","[{'number': 1, 'created': '2014-03-06 18:21:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/grenade/commit/5efc030e9ddc4bce061abf376888b8f9ea4ff405', 'message': 'Fix base processes not stopping\n\nSwitch to calling the base DevStack functions for stopping processes,\nwhich were recently updated to match trunk.\n\nAlso call the base DevStack stop_XXXX() functions to do the actual\nprocess stoppage.\n\nChange-Id: Ibb89403bbd2239cfbe693c6ae7b2cb398eb31477\n'}, {'number': 2, 'created': '2014-03-06 18:23:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/grenade/commit/1c596e3ea74b143100c4d0c3c500911055798244', 'message': 'Fix base processes not stopping\n\nSwitch to calling the base DevStack functions for stopping processes,\nwhich were recently updated to match trunk.\n\nAlso call the base DevStack stop_XXXX() functions to do the actual\nprocess stoppage.\n\nChange-Id: Ibb89403bbd2239cfbe693c6ae7b2cb398eb31477\n'}, {'number': 3, 'created': '2014-03-06 20:36:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/grenade/commit/29ce36ad2ccfe193fc87dccb1dad0dff5e5663fe', 'message': 'Fix base processes not stopping\n\nSwitch to calling the base DevStack functions for stopping processes,\nwhich were recently updated to match trunk.\n\nAlso call the base DevStack stop_XXXX() functions to do the actual\nprocess stoppage.\n\nChange-Id: Ibb89403bbd2239cfbe693c6ae7b2cb398eb31477\n'}, {'number': 4, 'created': '2014-03-06 20:36:43.000000000', 'files': ['stop-base'], 'web_link': 'https://opendev.org/openstack/grenade/commit/b529091ae6fe0f28aab68d850f58cd1f23669f1e', 'message': 'Fix base processes not stopping\n\nSwitch to calling the base DevStack functions for stopping processes,\nwhich were recently updated to match trunk.\n\nAlso call the base DevStack stop_XXXX() functions to do the actual\nprocess stoppage.\n\nChange-Id: Ibb89403bbd2239cfbe693c6ae7b2cb398eb31477\n'}]",0,78697,b529091ae6fe0f28aab68d850f58cd1f23669f1e,16,5,4,970,,,0,"Fix base processes not stopping

Switch to calling the base DevStack functions for stopping processes,
which were recently updated to match trunk.

Also call the base DevStack stop_XXXX() functions to do the actual
process stoppage.

Change-Id: Ibb89403bbd2239cfbe693c6ae7b2cb398eb31477
",git fetch https://review.opendev.org/openstack/grenade refs/changes/97/78697/3 && git format-patch -1 --stdout FETCH_HEAD,"['upgrade-cinder', 'stop-base']",2,5efc030e9ddc4bce061abf376888b8f9ea4ff405,fix-stop-processes,# We need base DevStack functions for this source $BASE_DEVSTACK_DIR/functions source $BASE_DEVSTACK_DIR/lib/keystone source $BASE_DEVSTACK_DIR/lib/glance source $BASE_DEVSTACK_DIR/lib/novaif is_service_enabled nova; then stop_nova fi if is_service_enabled glance; then stop_glance fi if is_service_enabled key; then stop_keystone fi # Swift runs daemons if is_service_enabled s-proxy; then stop_swift cleanup_swift fi SCSI_PERSIST_DIR=$CINDER_STATE_PATH/volumes/* # Get the iSCSI volumes if is_service_enabled cinder; then stop_cinder cleanup_cinder fi ,"# Swift runs daemons if is_service_enabled swift; then stop_swift fi # Handle iSCSI targets here...don't delete, just stop if [[ ""$os_PACKAGE"" = ""deb"" ]]; then stop_service tgt else stop_service tgtd fi ",32,13
openstack%2Fcinder~master~I2f04192e67f80232b4019194f718625dbaf78fa6,openstack/cinder,master,I2f04192e67f80232b4019194f718625dbaf78fa6,Include next link when default limit is reached,MERGED,2014-03-06 17:41:43.000000000,2014-03-06 23:48:59.000000000,2014-03-06 23:48:59.000000000,"[{'_account_id': 3}, {'_account_id': 1207}, {'_account_id': 2243}, {'_account_id': 7198}]","[{'number': 1, 'created': '2014-03-06 17:41:43.000000000', 'files': ['cinder/api/common.py', 'cinder/tests/api/v2/test_volumes.py'], 'web_link': 'https://opendev.org/openstack/cinder/commit/b63c28b7276d4c320fde8f481f61611d28278900', 'message': 'Include next link when default limit is reached\n\nThe /volumes and /volumes/details APIs support pagination and a\n""next"" link should be included when more data is available. When\nthe default ""osapi_max"" limit is reached then the ""next"" link is\nnot included in the API reply. In this case, the caller cannot\ndetermine if there are any more volumes and has no marker value\nsuch that they can retrieve the rest of the volumes.\n\nThe fix for this is to include the ""next"" link when the number of\nvolumes being returned is the maximum limit, even if the ""limit""\nparameter is not supplied.\n\nChange-Id: I2f04192e67f80232b4019194f718625dbaf78fa6\nCloses-bug: 1288429\n'}]",0,78678,b63c28b7276d4c320fde8f481f61611d28278900,8,4,1,10559,,,0,"Include next link when default limit is reached

The /volumes and /volumes/details APIs support pagination and a
""next"" link should be included when more data is available. When
the default ""osapi_max"" limit is reached then the ""next"" link is
not included in the API reply. In this case, the caller cannot
determine if there are any more volumes and has no marker value
such that they can retrieve the rest of the volumes.

The fix for this is to include the ""next"" link when the number of
volumes being returned is the maximum limit, even if the ""limit""
parameter is not supplied.

Change-Id: I2f04192e67f80232b4019194f718625dbaf78fa6
Closes-bug: 1288429
",git fetch https://review.opendev.org/openstack/cinder refs/changes/78/78678/1 && git format-patch -1 --stdout FETCH_HEAD,"['cinder/api/common.py', 'cinder/tests/api/v2/test_volumes.py']",2,b63c28b7276d4c320fde8f481f61611d28278900,bug/1288429," def test_volume_default_limit(self): self.stubs.Set(volume_api.API, 'get', stubs.stub_volume_get) # Number of volumes equals the max, include next link def stub_volume_get_all(context, marker, limit, sort_key, sort_dir): vols = [stubs.stub_volume(i) for i in xrange(CONF.osapi_max_limit)] if limit == None or limit >= len(vols): return vols return vols[:limit] self.stubs.Set(db, 'volume_get_all', stub_volume_get_all) for key in ['volumes', 'volumes/detail']: req = fakes.HTTPRequest.blank('/v2/%s?all_tenants=1' % key, use_admin_context=True) res_dict = self.controller.index(req) self.assertEqual(len(res_dict['volumes']), CONF.osapi_max_limit) volumes_links = res_dict['volumes_links'] self.assertEqual(volumes_links[0]['rel'], 'next') # Number of volumes less then max, do not include def stub_volume_get_all2(context, marker, limit, sort_key, sort_dir): vols = [stubs.stub_volume(i) for i in xrange(100)] if limit == None or limit >= len(vols): return vols return vols[:limit] self.stubs.Set(db, 'volume_get_all', stub_volume_get_all2) for key in ['volumes', 'volumes/detail']: req = fakes.HTTPRequest.blank('/v2/%s?all_tenants=1' % key, use_admin_context=True) res_dict = self.controller.index(req) self.assertEqual(len(res_dict['volumes']), 100) self.assertFalse('volumes_links' in res_dict) # Number of volumes more then the max, include next link def stub_volume_get_all3(context, marker, limit, sort_key, sort_dir): vols = [stubs.stub_volume(i) for i in xrange(CONF.osapi_max_limit + 100)] if limit == None or limit >= len(vols): return vols return vols[:limit] self.stubs.Set(db, 'volume_get_all', stub_volume_get_all3) for key in ['volumes', 'volumes/detail']: req = fakes.HTTPRequest.blank('/v2/%s?all_tenants=1' % key, use_admin_context=True) res_dict = self.controller.index(req) self.assertEqual(len(res_dict['volumes']), CONF.osapi_max_limit) volumes_links = res_dict['volumes_links'] self.assertEqual(volumes_links[0]['rel'], 'next') # Pass a limit that is greater then the max and the total number of # volumes, ensure only the maximum is returned and that the next # link is present for key in ['volumes', 'volumes/detail']: req = fakes.HTTPRequest.blank('/v2/%s?all_tenants=1&limit=%d' % (key, CONF.osapi_max_limit * 2), use_admin_context=True) res_dict = self.controller.index(req) self.assertEqual(len(res_dict['volumes']), CONF.osapi_max_limit) volumes_links = res_dict['volumes_links'] self.assertEqual(volumes_links[0]['rel'], 'next') ",,75,3
openstack%2Fheat~master~I47573812a3f80f3ae5b858cca486ec5826f606fd,openstack/heat,master,I47573812a3f80f3ae5b858cca486ec5826f606fd,Fix AccessPolicy update with added resources,MERGED,2014-03-06 15:11:29.000000000,2014-03-06 23:48:51.000000000,2014-03-06 23:48:50.000000000,"[{'_account_id': 3}, {'_account_id': 4257}, {'_account_id': 4328}, {'_account_id': 4330}]","[{'number': 1, 'created': '2014-03-06 15:11:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/5ac4eef7871dd62be9418dcf224c4392942fbcc2', 'message': ""Fix AccessPolicy update with added resources\n\nThis adds a test exposing bug #1286307 and moves the check for resources being\npresent from AccessPolicy's handle_create to check_create_complete. This defers\nthe check to a later point where the referenced resources are present.\n\nChange-Id: I47573812a3f80f3ae5b858cca486ec5826f606fd\nCloses-Bug: #1286307\n""}, {'number': 2, 'created': '2014-03-06 15:59:40.000000000', 'files': ['heat/tests/test_parser.py', 'heat/engine/resources/user.py', 'heat/tests/test_user.py'], 'web_link': 'https://opendev.org/openstack/heat/commit/b509812ea7bb031b6995be2a5ad5326a6417de50', 'message': ""Fix AccessPolicy update with added resources\n\nThis adds a test exposing bug #1286307 and moves the check for resources being\npresent from AccessPolicy's handle_create to check_create_complete. This defers\nthe check to a later point where the referenced resources are present.\n\nChange-Id: I47573812a3f80f3ae5b858cca486ec5826f606fd\nCloses-Bug: #1286307\n""}]",1,78624,b509812ea7bb031b6995be2a5ad5326a6417de50,12,4,2,4330,,,0,"Fix AccessPolicy update with added resources

This adds a test exposing bug #1286307 and moves the check for resources being
present from AccessPolicy's handle_create to check_create_complete. This defers
the check to a later point where the referenced resources are present.

Change-Id: I47573812a3f80f3ae5b858cca486ec5826f606fd
Closes-Bug: #1286307
",git fetch https://review.opendev.org/openstack/heat refs/changes/24/78624/2 && git format-patch -1 --stdout FETCH_HEAD,"['heat/tests/test_parser.py', 'heat/engine/resources/user.py', 'heat/tests/test_user.py']",3,5ac4eef7871dd62be9418dcf224c4392942fbcc2,bug/1286307, create_result = rsrc.handle_create() self.assertFalse(rsrc.check_create_complete(create_result))," self.assertRaises(exception.ResourceNotFound, rsrc.handle_create)",42,3
openstack%2Fironic~master~I99fd77914bf4673053c3ebde7f5487da89cbc9c5,openstack/ironic,master,I99fd77914bf4673053c3ebde7f5487da89cbc9c5,API: Add sample() method to remaining models,MERGED,2014-03-06 00:39:37.000000000,2014-03-06 23:45:47.000000000,2014-03-06 23:45:47.000000000,"[{'_account_id': 3}, {'_account_id': 2889}, {'_account_id': 6773}]","[{'number': 1, 'created': '2014-03-06 00:39:37.000000000', 'files': ['ironic/api/controllers/v1/driver.py', 'ironic/api/controllers/v1/chassis.py', 'ironic/api/controllers/v1/node.py'], 'web_link': 'https://opendev.org/openstack/ironic/commit/9b1b10b95d7401b44ad1572f292a7064403ae4db', 'message': 'API: Add sample() method to remaining models\n\nDefine sample() method on Chassis\n\nChange-Id: I99fd77914bf4673053c3ebde7f5487da89cbc9c5\nCloses-Bug: #1260337\n'}]",0,78478,9b1b10b95d7401b44ad1572f292a7064403ae4db,7,3,1,7411,,,0,"API: Add sample() method to remaining models

Define sample() method on Chassis

Change-Id: I99fd77914bf4673053c3ebde7f5487da89cbc9c5
Closes-Bug: #1260337
",git fetch https://review.opendev.org/openstack/ironic refs/changes/78/78478/1 && git format-patch -1 --stdout FETCH_HEAD,"['ironic/api/controllers/v1/chassis.py', 'ironic/api/controllers/v1/driver.py', 'ironic/api/controllers/v1/node.py']",3,9b1b10b95d7401b44ad1572f292a7064403ae4db,lp1260337," @classmethod def sample(cls): sample = cls(target_power_state=ir_states.POWER_ON, target_provision_state=ir_states.ACTIVE, last_error=None, console_enabled=False, provision_updated_at=None, power_state=ir_states.POWER_ON, provision_state=None) return sample ",,49,6
openstack%2Fironic~master~I4308d9c994a13f63003ee9426229b51063926c00,openstack/ironic,master,I4308d9c994a13f63003ee9426229b51063926c00,Fix how nova ironic driver gets flavor information,MERGED,2014-03-06 17:53:51.000000000,2014-03-06 23:27:56.000000000,2014-03-06 23:27:56.000000000,"[{'_account_id': 3}, {'_account_id': 2889}, {'_account_id': 5805}]","[{'number': 1, 'created': '2014-03-06 17:53:51.000000000', 'files': ['ironic/nova/virt/ironic/driver.py'], 'web_link': 'https://opendev.org/openstack/ironic/commit/d32d6ab4f5f3cb8b84d69dc1be0424b82eb1a2a4', 'message': 'Fix how nova ironic driver gets flavor information\n\nNova changed the way it access the flavor information, they now use the\nFlavor object instead of getting it throught the VirtAPI.get_flavor()\ncall.\n\nAlso fix the import order in the driver.py\n\nChange-Id: I4308d9c994a13f63003ee9426229b51063926c00\n'}]",0,78686,d32d6ab4f5f3cb8b84d69dc1be0424b82eb1a2a4,7,3,1,6773,,,0,"Fix how nova ironic driver gets flavor information

Nova changed the way it access the flavor information, they now use the
Flavor object instead of getting it throught the VirtAPI.get_flavor()
call.

Also fix the import order in the driver.py

Change-Id: I4308d9c994a13f63003ee9426229b51063926c00
",git fetch https://review.opendev.org/openstack/ironic refs/changes/86/78686/1 && git format-patch -1 --stdout FETCH_HEAD,['ironic/nova/virt/ironic/driver.py'],1,d32d6ab4f5f3cb8b84d69dc1be0424b82eb1a2a4,fix-get_flavor,"from ironic.nova.virt.ironic import ironic_statesfrom nova.objects import flavor as flavor_obj flavor = flavor_obj.Flavor.get_by_id(context, instance['instance_type_id'])","from ironic.nova.virt.ironic import ironic_states flavor = self.virtapi.flavor_get(context, instance['instance_type_id'])",4,2
openstack%2Fnova~master~I9690e4a05368380cdc0b5d71c73b1ad6c1d36d07,openstack/nova,master,I9690e4a05368380cdc0b5d71c73b1ad6c1d36d07,Add fixtures to dependencies,ABANDONED,2014-03-06 21:40:36.000000000,2014-03-06 23:15:16.000000000,,"[{'_account_id': 3}, {'_account_id': 4190}, {'_account_id': 6873}, {'_account_id': 6928}, {'_account_id': 9369}]","[{'number': 1, 'created': '2014-03-06 21:40:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/3489afd522fb38e2e9f07cdc7b28cf2ad643b522', 'message': 'Add fixtures to dependencies\n\n62dbd2c1ca1bae1ac3a32fe17435a60c7df30319 added use of\nlockutils.LockFixture, without adding fixtures to requirements.txt\n\nChange-Id: I9690e4a05368380cdc0b5d71c73b1ad6c1d36d07\n'}, {'number': 2, 'created': '2014-03-06 21:51:06.000000000', 'files': ['requirements.txt'], 'web_link': 'https://opendev.org/openstack/nova/commit/240edd34ba8e688913bb60e2470f5f90e5c90e66', 'message': 'Add fixtures to dependencies\n\n8625766c39f39b8b44bf212be6c2820d6736b6f3 added use of\nlockutils.LockFixture, without adding fixtures to requirements.txt\n\nChange-Id: I9690e4a05368380cdc0b5d71c73b1ad6c1d36d07\n'}]",0,78778,240edd34ba8e688913bb60e2470f5f90e5c90e66,12,5,2,9369,,,0,"Add fixtures to dependencies

8625766c39f39b8b44bf212be6c2820d6736b6f3 added use of
lockutils.LockFixture, without adding fixtures to requirements.txt

Change-Id: I9690e4a05368380cdc0b5d71c73b1ad6c1d36d07
",git fetch https://review.opendev.org/openstack/nova refs/changes/78/78778/2 && git format-patch -1 --stdout FETCH_HEAD,['requirements.txt'],1,3489afd522fb38e2e9f07cdc7b28cf2ad643b522,fixtures-requirements,fixtures>=0.3.14,,1,0
openstack%2Fceilometer~stable%2Fhavana~I967ba080a4011a54b5789ca0fc20cb9a37dafb15,openstack/ceilometer,stable/havana,I967ba080a4011a54b5789ca0fc20cb9a37dafb15,Propogate cacert and insecure flags to glanceclient,MERGED,2014-02-13 17:16:57.000000000,2014-03-06 23:07:26.000000000,2014-03-06 23:07:25.000000000,"[{'_account_id': 3}, {'_account_id': 1669}, {'_account_id': 1812}, {'_account_id': 1955}, {'_account_id': 2284}, {'_account_id': 4491}, {'_account_id': 6159}]","[{'number': 1, 'created': '2014-02-13 17:16:57.000000000', 'files': ['ceilometer/image/glance.py'], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/0ac6942959d52f20a3955c982974d5f15aabcab5', 'message': 'Propogate cacert and insecure flags to glanceclient\n\nFixes bug 1278973\n\nPreviously, the insecure flag was only propagated to the keystoneclient\nwhile the cacert flag was only propagated to the keystoneclient and\nthe ceilometerclient used by alarming.\n\nSince the glanceclient also supports these options, these flags should\nbe propogated to it also to avoid SSL cert verification failures when the\ncentral agent calls out to glance over https.\n\nChange-Id: I967ba080a4011a54b5789ca0fc20cb9a37dafb15\n(cherry picked from commit b000317f670f635b00ca52a4539a0b83b14c8ff4)\n'}]",0,73359,0ac6942959d52f20a3955c982974d5f15aabcab5,23,7,1,2284,,,0,"Propogate cacert and insecure flags to glanceclient

Fixes bug 1278973

Previously, the insecure flag was only propagated to the keystoneclient
while the cacert flag was only propagated to the keystoneclient and
the ceilometerclient used by alarming.

Since the glanceclient also supports these options, these flags should
be propogated to it also to avoid SSL cert verification failures when the
central agent calls out to glance over https.

Change-Id: I967ba080a4011a54b5789ca0fc20cb9a37dafb15
(cherry picked from commit b000317f670f635b00ca52a4539a0b83b14c8ff4)
",git fetch https://review.opendev.org/openstack/ceilometer refs/changes/59/73359/1 && git format-patch -1 --stdout FETCH_HEAD,['ceilometer/image/glance.py'],1,0ac6942959d52f20a3955c982974d5f15aabcab5,," service_credentials = cfg.CONF.service_credentials token=ksclient.auth_token, cacert=service_credentials.os_cacert, insecure=service_credentials.insecure)", token=ksclient.auth_token),4,1
openstack%2Fheat~master~I77291d21b291242684cf42e7143b264521ba113e,openstack/heat,master,I77291d21b291242684cf42e7143b264521ba113e,Allow proper instance with volume suspension,MERGED,2014-02-25 08:49:15.000000000,2014-03-06 23:07:17.000000000,2014-03-06 23:07:16.000000000,"[{'_account_id': 3}, {'_account_id': 4328}, {'_account_id': 6917}, {'_account_id': 7135}, {'_account_id': 7233}, {'_account_id': 9542}, {'_account_id': 9577}, {'_account_id': 9626}]","[{'number': 1, 'created': '2014-02-25 08:49:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/83bfdeaeecd4d753fd0bb9c62cbeb69d80736543', 'message': 'Allow proper instance with volume suspension\n\nWhen suspending a stack that contains an instance with a volume\nattached through the instance\'s ""Volumes"" property, the stack will\ngo into a SUSPEND_COMPLETE state, but the actual instance will still\nbe in an ACTIVE state. This is because check_suspend_complete will\nreturn TRUE without ever starting the instance\'s suspend task.\nThis commit ensures that the instance suspension TaskRunner is\nactually started.\n\nChange-Id: I77291d21b291242684cf42e7143b264521ba113e\nCloses-Bug: #1284306\n'}, {'number': 2, 'created': '2014-02-25 08:49:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/d8786132a4a5a69f575d2781e50c225f14f1ba58', 'message': 'Allow proper instance with volume suspension\n\nWhen suspending a stack that contains an instance with a volume\nattached through the instance\'s ""Volumes"" property, the stack will\ngo into a SUSPEND_COMPLETE state, but the actual instance will still\nbe in an ACTIVE state. This is because check_suspend_complete will\nreturn TRUE without ever starting the instance\'s suspend task.\nThis commit ensures that the instance suspension TaskRunner is\nactually started.\n\nChange-Id: I77291d21b291242684cf42e7143b264521ba113e\nCloses-Bug: #1284306\n'}, {'number': 3, 'created': '2014-03-04 18:39:41.000000000', 'files': ['heat/tests/test_instance.py', 'heat/engine/resources/instance.py'], 'web_link': 'https://opendev.org/openstack/heat/commit/f136980e65823d40a89c29532f244add75ed685b', 'message': 'Allow proper instance with volume suspension\n\nWhen suspending a stack that contains an instance with a volume\nattached through the instance\'s ""Volumes"" property, the stack will\ngo into a SUSPEND_COMPLETE state, but the actual instance will still\nbe in an ACTIVE state. This is because check_suspend_complete will\nreturn TRUE without ever starting the instance\'s suspend task.\nThis commit ensures that the instance suspension TaskRunner is\nactually started.\n\nChange-Id: I77291d21b291242684cf42e7143b264521ba113e\nCloses-Bug: #1284306\n'}]",1,76126,f136980e65823d40a89c29532f244add75ed685b,25,8,3,9626,,,0,"Allow proper instance with volume suspension

When suspending a stack that contains an instance with a volume
attached through the instance's ""Volumes"" property, the stack will
go into a SUSPEND_COMPLETE state, but the actual instance will still
be in an ACTIVE state. This is because check_suspend_complete will
return TRUE without ever starting the instance's suspend task.
This commit ensures that the instance suspension TaskRunner is
actually started.

Change-Id: I77291d21b291242684cf42e7143b264521ba113e
Closes-Bug: #1284306
",git fetch https://review.opendev.org/openstack/heat refs/changes/26/76126/1 && git format-patch -1 --stdout FETCH_HEAD,"['heat/tests/test_instance.py', 'heat/engine/resources/instance.py']",2,83bfdeaeecd4d753fd0bb9c62cbeb69d80736543,bug/1284306, volumes_runner.step() return False, return volumes_runner.step(),36,1
openstack%2Fdiskimage-builder~master~Icfd6dc853d982115c471ecb17f361b9091c60a8c,openstack/diskimage-builder,master,Icfd6dc853d982115c471ecb17f361b9091c60a8c,Add install-pip-packages,ABANDONED,2014-03-06 19:17:10.000000000,2014-03-06 23:02:45.000000000,,[{'_account_id': 3}],"[{'number': 1, 'created': '2014-03-06 19:17:10.000000000', 'files': ['elements/base/install-pip-packages', 'elements/base/pre-install.d/05-install-pip-packages'], 'web_link': 'https://opendev.org/openstack/diskimage-builder/commit/fa4822033eb7fbc281df2d9cd77cb4283800482b', 'message': 'Add install-pip-packages\n\nHelper script to install pip packages. Takes an optional -v\n/path/to/venv argument that if specified, the pip in that venv will be\nused to do the install. Otherwise, the system wide pip is used.\n\nChange-Id: Icfd6dc853d982115c471ecb17f361b9091c60a8c\n'}]",0,78718,fa4822033eb7fbc281df2d9cd77cb4283800482b,4,1,1,7144,,,0,"Add install-pip-packages

Helper script to install pip packages. Takes an optional -v
/path/to/venv argument that if specified, the pip in that venv will be
used to do the install. Otherwise, the system wide pip is used.

Change-Id: Icfd6dc853d982115c471ecb17f361b9091c60a8c
",git fetch https://review.opendev.org/openstack/diskimage-builder refs/changes/18/78718/1 && git format-patch -1 --stdout FETCH_HEAD,"['elements/base/install-pip-packages', 'elements/base/pre-install.d/05-install-pip-packages']",2,fa4822033eb7fbc281df2d9cd77cb4283800482b,pip-packages,#!/bin/bash set -e install -m 0755 -o root -g root $(dirname $0)/../install-pip-packages /usr/bin/ ,,30,0
openstack%2Fdiskimage-builder~master~Ide5370ab99a7a2c073288f84144d5b499c0b9be2,openstack/diskimage-builder,master,Ide5370ab99a7a2c073288f84144d5b499c0b9be2,Add -p to install-packages for pip installs,ABANDONED,2014-03-06 19:17:10.000000000,2014-03-06 23:02:40.000000000,,[{'_account_id': 3}],"[{'number': 1, 'created': '2014-03-06 19:17:10.000000000', 'files': ['elements/opensuse/bin/install-packages', 'elements/dpkg/bin/install-packages', 'elements/yum/bin/install-packages'], 'web_link': 'https://opendev.org/openstack/diskimage-builder/commit/b813cc0ced1dec215cc8617e4d3b46a6c081013b', 'message': 'Add -p to install-packages for pip installs\n\nAdds a -p argument to the 3 install-packages scripts that if specified,\nwill do pip installs (using install-pip-packages) of the packages\nspecified.\n\nChange-Id: Ide5370ab99a7a2c073288f84144d5b499c0b9be2\n'}]",0,78719,b813cc0ced1dec215cc8617e4d3b46a6c081013b,4,1,1,7144,,,0,"Add -p to install-packages for pip installs

Adds a -p argument to the 3 install-packages scripts that if specified,
will do pip installs (using install-pip-packages) of the packages
specified.

Change-Id: Ide5370ab99a7a2c073288f84144d5b499c0b9be2
",git fetch https://review.opendev.org/openstack/diskimage-builder refs/changes/19/78719/1 && git format-patch -1 --stdout FETCH_HEAD,"['elements/opensuse/bin/install-packages', 'elements/dpkg/bin/install-packages', 'elements/yum/bin/install-packages']",3,b813cc0ced1dec215cc8617e4d3b46a6c081013b,pip-packages,"elif [ ""$1"" = ""-p"" ]; then shift install-pip-packages $@ exit 0",,12,0
openstack%2Frally~master~I37e71e2f39a5a27ff7a7a8a7ff0b231a6536923a,openstack/rally,master,I37e71e2f39a5a27ff7a7a8a7ff0b231a6536923a,Unify Context classes and introduce context object,MERGED,2014-03-05 13:09:47.000000000,2014-03-06 22:33:02.000000000,2014-03-06 22:33:02.000000000,"[{'_account_id': 3}, {'_account_id': 6172}, {'_account_id': 6835}, {'_account_id': 7217}, {'_account_id': 8507}]","[{'number': 1, 'created': '2014-03-05 13:09:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/3db48aab5826f7a56693555c601355b3df4725ee', 'message': 'Unify Context classes and introduce context object\n\n* Unify interfaces of context classes\n* Init Context classes only with context object\n* Have 2 method setup and cleanup\n  a) setup   - will be called inside with after __enter__\n  b) cleanup - will be called inside __exit__\n* Add common context object that will be shared between all context\n  and benchmark scenarios\n\nChange-Id: I37e71e2f39a5a27ff7a7a8a7ff0b231a6536923a\n'}, {'number': 2, 'created': '2014-03-05 14:18:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/d93cfb47df74762e64e05515bb7056301d491144', 'message': 'Unify Context classes and introduce context object\n\n* Unify interfaces of context classes\n* Init Context classes only with context object\n* Have 2 method setup and cleanup\n  a) setup   - will be called inside with after __enter__\n  b) cleanup - will be called inside __exit__\n* Add common context object that will be shared between all context\n  and benchmark scenarios\n\nChange-Id: I37e71e2f39a5a27ff7a7a8a7ff0b231a6536923a\n'}, {'number': 3, 'created': '2014-03-05 15:45:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/e5818ca2d104fa2f49d02d7e818211891c41d88c', 'message': 'Unify Context classes and introduce context object\n\n* Unify interfaces of context classes\n* Init Context classes only with context object\n* Have 2 method setup and cleanup\n  a) setup   - will be called inside with after __enter__\n  b) cleanup - will be called inside __exit__\n* Add common context object that will be shared between all context\n  and benchmark scenarios\n\nChange-Id: I37e71e2f39a5a27ff7a7a8a7ff0b231a6536923a\n'}, {'number': 4, 'created': '2014-03-06 01:05:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/429a9615e62ef94ca6112582b0e2b109d5a15115', 'message': 'Unify Context classes and introduce context object\n\n* Unify interfaces of context classes\n* Init Context classes only with context object\n* Have 2 method setup and cleanup\n  a) setup   - will be called inside with after __enter__\n  b) cleanup - will be called inside __exit__\n* Add common context object that will be shared between all context\n  and benchmark scenarios\n\nChange-Id: I37e71e2f39a5a27ff7a7a8a7ff0b231a6536923a\n'}, {'number': 5, 'created': '2014-03-06 01:10:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/68881e387b87a4132505ad81912efd032d5ed8d9', 'message': 'Unify Context classes and introduce context object\n\n* Unify interfaces of context classes\n* Init Context classes only with context object\n* Have 2 method setup and cleanup\n  a) setup   - will be called inside with after __enter__\n  b) cleanup - will be called inside __exit__\n* Add common context object that will be shared between all context\n  and benchmark scenarios\n\nSecond part of blueprint benchmark-context\n\nNext steps:\n1) Switch to new task config format (with minimum changes)\n2) Move validation from benchmark engine to context.base, runner.base,\n   scenario.base classes\n3) Turn on context factory (so you will be able to specify any context\n   from config file) or request by benchmark any context (e.g. ssh access)\n4) Cleanup context object & unit tests\n\nChange-Id: I37e71e2f39a5a27ff7a7a8a7ff0b231a6536923a\n'}, {'number': 6, 'created': '2014-03-06 12:04:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/6908dff76f79ee36ecddff9064761b855e0a48f8', 'message': 'Unify Context classes and introduce context object\n\n* Unify interfaces of context classes\n* Init Context classes only with context object\n* Have 2 method setup and cleanup\n  a) setup   - will be called inside with after __enter__\n  b) cleanup - will be called inside __exit__\n* Add common context object that will be shared between all context\n  and benchmark scenarios\n\nSecond part of blueprint benchmark-context\n\nNext steps:\n1) Switch to new task config format (with minimum changes)\n2) Move validation from benchmark engine to context.base, runner.base,\n   scenario.base classes\n3) Turn on context factory (so you will be able to specify any context\n   from config file) or request by benchmark any context (e.g. ssh access)\n4) Cleanup context object & unit tests\n\nChange-Id: I37e71e2f39a5a27ff7a7a8a7ff0b231a6536923a\n'}, {'number': 7, 'created': '2014-03-06 14:09:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/95663254c5bf0294c111212907e2281feb6adbab', 'message': 'Unify Context classes and introduce context object\n\n* Unify interfaces of context classes\n* Init Context classes only with context object\n* Have 2 method setup and cleanup\n  a) setup   - will be called inside with after __enter__\n  b) cleanup - will be called inside __exit__\n* Add common context object that will be shared between all context\n  and benchmark scenarios\n\nSecond part of blueprint benchmark-context\n\nNext steps:\n1) Switch to new task config format (with minimum changes)\n2) Move validation from benchmark engine to context.base, runner.base,\n   scenario.base classes\n3) Turn on context factory (so you will be able to specify any context\n   from config file) or request by benchmark any context (e.g. ssh access)\n4) Cleanup context object & unit tests\n\nChange-Id: I37e71e2f39a5a27ff7a7a8a7ff0b231a6536923a\n'}, {'number': 8, 'created': '2014-03-06 20:19:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/b1fedac4cffadccf359a8634b36fbb2f50204638', 'message': 'Unify Context classes and introduce context object\n\n* Unify interfaces of context classes\n* Init Context classes only with context object\n* Have 2 method setup and cleanup\n  a) setup   - will be called inside with after __enter__\n  b) cleanup - will be called inside __exit__\n* Add common context object that will be shared between all context\n  and benchmark scenarios\n\nSecond part of blueprint benchmark-context\n\nNext steps:\n1) Switch to new task config format (with minimum changes)\n2) Move validation from benchmark engine to context.base, runner.base,\n   scenario.base classes\n3) Turn on context factory (so you will be able to specify any context\n   from config file) or request by benchmark any context (e.g. ssh access)\n4) Cleanup context object & unit tests\n\nChange-Id: I37e71e2f39a5a27ff7a7a8a7ff0b231a6536923a\n'}, {'number': 9, 'created': '2014-03-06 21:16:22.000000000', 'files': ['tests/benchmark/runners/test_base.py', 'tests/benchmark/context/test_users.py', 'rally/benchmark/scenarios/nova/utils.py', 'tests/benchmark/test_engine.py', 'rally/benchmark/context/base.py', 'rally/benchmark/context/secgroup.py', 'tests/benchmark/context/test_cleaner.py', 'tests/benchmark/runners/test_periodic.py', 'tests/benchmark/context/test_secgroups.py', 'rally/benchmark/utils.py', 'rally/benchmark/engine.py', 'tests/benchmark/runners/test_continuous.py', 'tests/benchmark/test_utils.py', 'rally/benchmark/runners/continuous.py', 'rally/exceptions.py', 'tests/benchmark/context/test_base.py', 'rally/benchmark/runners/base.py', 'rally/benchmark/runners/periodic.py', 'tests/fakes.py', 'rally/benchmark/context/cleaner.py', 'rally/benchmark/context/users.py'], 'web_link': 'https://opendev.org/openstack/rally/commit/92ef55a17a3c39ca23bd1520134d34b892bd01f0', 'message': 'Unify Context classes and introduce context object\n\n* Unify interfaces of context classes\n* Init Context classes only with context object\n* Have 2 method setup and cleanup\n  a) setup   - will be called inside with after __enter__\n  b) cleanup - will be called inside __exit__\n* Add common context object that will be shared between all context\n  and benchmark scenarios\n\nSecond part of blueprint benchmark-context\n\nNext steps:\n1) Switch to new task config format (with minimum changes)\n2) Move validation from benchmark engine to context.base, runner.base,\n   scenario.base classes\n3) Turn on context factory (so you will be able to specify any context\n   from config file) or request by benchmark any context (e.g. ssh access)\n4) Cleanup context object & unit tests\n\nChange-Id: I37e71e2f39a5a27ff7a7a8a7ff0b231a6536923a\n'}]",37,78193,92ef55a17a3c39ca23bd1520134d34b892bd01f0,37,5,9,6172,,,0,"Unify Context classes and introduce context object

* Unify interfaces of context classes
* Init Context classes only with context object
* Have 2 method setup and cleanup
  a) setup   - will be called inside with after __enter__
  b) cleanup - will be called inside __exit__
* Add common context object that will be shared between all context
  and benchmark scenarios

Second part of blueprint benchmark-context

Next steps:
1) Switch to new task config format (with minimum changes)
2) Move validation from benchmark engine to context.base, runner.base,
   scenario.base classes
3) Turn on context factory (so you will be able to specify any context
   from config file) or request by benchmark any context (e.g. ssh access)
4) Cleanup context object & unit tests

Change-Id: I37e71e2f39a5a27ff7a7a8a7ff0b231a6536923a
",git fetch https://review.opendev.org/openstack/rally refs/changes/93/78193/9 && git format-patch -1 --stdout FETCH_HEAD,"['rally/benchmark/runners/continuous.py', 'rally/exceptions.py', 'tests/benchmark/context/test_base.py', 'rally/benchmark/runners/base.py', 'rally/benchmark/runners/periodic.py', 'rally/benchmark/context/base.py', 'rally/benchmark/context/secgroup.py', 'rally/benchmark/utils.py', 'rally/benchmark/context/cleaner.py', 'rally/benchmark/context/users.py']",10,3db48aab5826f7a56693555c601355b3df4725ee,bp/benchmark-context,"from rally import osclients __name__ = ""users"" CONFIG_SCHEMA = { ""type"": ""object"", ""$schema"": ""http://json-schema.org/draft-03/schema"", ""properties"" : { ""tenants"": { ""type"": ""integer"", ""minimum"": 1 }, ""users_per_tenant"": { ""type"": ""integer"", ""minimum"": 1 } }, ""additionalProperties"": False } def __init__(self, context): super(UserGenerator, self).__init__(self, context) self.config.setdefault(""tenants"", 1) self.config.setdefault(""users"", 1) self.context[""users""] = [] self.context[""tenants""] = [] # NOTE(boris-42): I think this is the best place for adding logic when # we are using pre created users or temporary. So we # should rename this class s/UserGenerator/UserContext/ # and change a bit logic of populating lists of users # and tenants clients = osclients.Clients(context[""admin""][""endpoint""]) self.keystone_client = clients.get_keystone_client() def create_users_and_tenants(self): self.context[""tenants""] = [self._create_tenant(run_id, i) for i in range(self.config[""tenants""])] for user_id in range(self.config[""users_per_tenant""]): self.context[""users""].append(user) for user in self.context[""users""]: for tenant in self.context[""tenants""]: def setup(self): return self.create_users_and_tenants() def cleanup(self):","from rally.benchmark import utilsfrom rally.openstack.common.gettextutils import _ def __init__(self, admin_endpoints): self.users = [] self.tenants = [] self.keystone_client = \ utils.create_openstack_clients(admin_endpoints)[""keystone""] def create_users_and_tenants(self, tenants, users_per_tenant): self.tenants = [self._create_tenant(run_id, i) for i in range(tenants)] self.users = [] for user_id in range(users_per_tenant): self.users.append(user) for user in self.users: for tenant in self.tenants: def __enter__(self): return self def __exit__(self, exc_type, exc_value, exc_traceback): if exc_type: LOG.debug(_(""Failed to generate temporary users.""), exc_info=(exc_type, exc_value, exc_traceback)) else: LOG.debug(_(""Completed deleting temporary users and tenants.""))",292,157
openstack%2Fopenstack-manuals~master~I57ac46b845e217c2607cf99dfabcfaab25d84ea5,openstack/openstack-manuals,master,I57ac46b845e217c2607cf99dfabcfaab25d84ea5,Lowercase compute node,MERGED,2014-03-05 19:14:07.000000000,2014-03-06 22:21:01.000000000,2014-03-06 22:21:00.000000000,"[{'_account_id': 3}, {'_account_id': 964}, {'_account_id': 6547}, {'_account_id': 6843}, {'_account_id': 7923}, {'_account_id': 9162}, {'_account_id': 9515}]","[{'number': 1, 'created': '2014-03-05 19:14:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/ab0a5aae60ff6f76a69e0ea906271616866a3f01', 'message': 'Lowercase compute node\n\nIt\'s ""compute node"", not ""Compute node"" (similarly compute host).\n\nChange-Id: I57ac46b845e217c2607cf99dfabcfaab25d84ea5\n'}, {'number': 2, 'created': '2014-03-06 08:06:29.000000000', 'files': ['doc/user-guide/section_cli_nova_config-drive.xml', 'doc/admin-guide-cloud/section_networking_introduction.xml', 'doc/config-reference/block-storage/drivers/huawei-storage-driver.xml', 'doc/admin-guide-cloud/section_ts_vol_attach_miss_sg_scan.xml', 'doc/glossary/glossary-terms.xml', 'doc/training-guides/module001-ch005-vm-provisioning-walk-through.xml', 'doc/config-reference/compute/section_hypervisor_hyper-v.xml', 'doc/install-guide/section_ceilometer-nova.xml', 'doc/admin-guide-cloud/section_networking_adv_features.xml', 'doc/admin-guide-cloud/ch_compute.xml', 'doc/admin-guide-cloud/section_ts_multipath_warn.xml', 'doc/user-guide-admin/section_dashboard_admin_set_quotas.xml', 'doc/common/section_compute_config-firewalls.xml', 'doc/config-reference/block-storage/section_block-storage-overview.xml', 'doc/admin-guide-cloud/section_networking-scenarios.xml', 'doc/common/section_fibrechannel.xml', 'doc/user-guide-admin/section_cli_keystone_set_quotas.xml', 'doc/install-guide/section_nova-compute.xml', 'doc/admin-guide-cloud/section_ts_failed_connect_vol_FC_SAN.xml', 'doc/training-guides/module001-ch011-block-storage.xml', 'doc/config-reference/block-storage/drivers/xenapi-nfs.xml', 'doc/install-guide/section_nova-kvm.xml', 'doc/admin-guide-cloud/section_ts_failed_attach_vol_no_sysfsutils.xml', 'doc/config-reference/block-storage/drivers/emc-volume-driver.xml', 'doc/security-guide/ch055_security-services-for-instances.xml', 'doc/user-guide/section_dashboard_launch_instances_from_image.xml'], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/39ac6cc258e66076a955463a53647888419867b8', 'message': 'Lowercase compute node\n\nIt\'s ""compute node"", not ""Compute node"" (similarly compute host).\n\nAlso, fix capitalization of ""live migration"".\n\nChange-Id: I57ac46b845e217c2607cf99dfabcfaab25d84ea5\n'}]",4,78370,39ac6cc258e66076a955463a53647888419867b8,19,7,2,6547,,,0,"Lowercase compute node

It's ""compute node"", not ""Compute node"" (similarly compute host).

Also, fix capitalization of ""live migration"".

Change-Id: I57ac46b845e217c2607cf99dfabcfaab25d84ea5
",git fetch https://review.opendev.org/openstack/openstack-manuals refs/changes/70/78370/1 && git format-patch -1 --stdout FETCH_HEAD,"['doc/user-guide/section_cli_nova_config-drive.xml', 'doc/admin-guide-cloud/section_networking_introduction.xml', 'doc/config-reference/block-storage/drivers/huawei-storage-driver.xml', 'doc/admin-guide-cloud/section_ts_vol_attach_miss_sg_scan.xml', 'doc/glossary/glossary-terms.xml', 'doc/training-guides/module001-ch005-vm-provisioning-walk-through.xml', 'doc/config-reference/compute/section_hypervisor_hyper-v.xml', 'doc/install-guide/section_ceilometer-nova.xml', 'doc/admin-guide-cloud/section_networking_adv_features.xml', 'doc/admin-guide-cloud/ch_compute.xml', 'doc/admin-guide-cloud/section_ts_multipath_warn.xml', 'doc/user-guide-admin/section_dashboard_admin_set_quotas.xml', 'doc/common/section_compute_config-firewalls.xml', 'doc/config-reference/block-storage/section_block-storage-overview.xml', 'doc/admin-guide-cloud/section_networking-scenarios.xml', 'doc/common/section_fibrechannel.xml', 'doc/user-guide-admin/section_cli_keystone_set_quotas.xml', 'doc/install-guide/section_neutron-per-tenant-routers-with-private-networks.xml', 'doc/install-guide/section_nova-compute.xml', 'doc/admin-guide-cloud/section_ts_failed_connect_vol_FC_SAN.xml', 'doc/training-guides/module001-ch011-block-storage.xml', 'doc/config-reference/block-storage/drivers/xenapi-nfs.xml', 'doc/install-guide/section_nova-kvm.xml', 'doc/admin-guide-cloud/section_ts_failed_attach_vol_no_sysfsutils.xml', 'doc/config-reference/block-storage/drivers/emc-volume-driver.xml', 'doc/security-guide/ch055_security-services-for-instances.xml', 'doc/user-guide/section_dashboard_launch_instances_from_image.xml']",27,ab0a5aae60ff6f76a69e0ea906271616866a3f01,compute-node, a local copy of the image on the compute node where the starts on a compute node in the cloud.</para>, a local copy of the image on the Compute node where the starts on a Compute node in the cloud.</para>,55,52
openstack%2Fnova~master~I3ba16370cbbc5548069a16fe47e85f18a8e69418,openstack/nova,master,I3ba16370cbbc5548069a16fe47e85f18a8e69418,notifier middleware broken by oslo.messaging,ABANDONED,2014-02-28 19:09:59.000000000,2014-03-06 22:15:24.000000000,,"[{'_account_id': 3}, {'_account_id': 964}, {'_account_id': 1849}, {'_account_id': 2750}, {'_account_id': 5170}, {'_account_id': 6537}, {'_account_id': 6873}, {'_account_id': 9578}]","[{'number': 1, 'created': '2014-02-28 19:09:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/60cb337380ad3bc1696aad3383da3defabaebeaa', 'message': 'notifier middleware broken by oslo.messaging\n\naudit middleware in oslo-incubator is incompatible with oslo.messaging.\nan oslo.messaging compatible version is available in pycadf library.\nenable audit by default to better test for integration issues\n\nenable audit middleware to verify in this patch\n\nChange-Id: I3ba16370cbbc5548069a16fe47e85f18a8e69418\nPartial-Bug: #1280327\n'}, {'number': 2, 'created': '2014-02-28 19:19:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/fb2e2550fdf0f0f2778730c2f91c4e126934cd5c', 'message': 'notifier middleware broken by oslo.messaging\n\naudit middleware in oslo-incubator is incompatible with oslo.messaging.\nan oslo.messaging compatible version is available in pycadf library.\nenable audit by default to better test for integration issues\n\nenable audit middleware to verify in this patch\n\nPartial-Bug: #1280327\nChange-Id: I3ba16370cbbc5548069a16fe47e85f18a8e69418\n'}, {'number': 3, 'created': '2014-02-28 19:19:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/e004b9e0da7a6a8472efe4121e2845408bb4660f', 'message': 'notifier middleware broken by oslo.messaging\n\naudit middleware in oslo-incubator is incompatible with oslo.messaging.\nan oslo.messaging compatible version is available in pycadf library.\nenable audit by default to better test for integration issues\n\nenable audit middleware to verify in this patch\n\nPartial-Bug: #1280327\nChange-Id: I3ba16370cbbc5548069a16fe47e85f18a8e69418\n'}, {'number': 4, 'created': '2014-02-28 20:53:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/701606044f1d2faa1bd31ed0b64601a96f3ab025', 'message': 'notifier middleware broken by oslo.messaging\n\naudit middleware in oslo-incubator is incompatible with oslo.messaging.\nan oslo.messaging compatible version is available in pycadf library.\nenable audit by default to better test for integration issues\n\nPartial-Bug: #1280327\nChange-Id: I3ba16370cbbc5548069a16fe47e85f18a8e69418\n'}, {'number': 5, 'created': '2014-02-28 20:53:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/ecf1b1ddd93bbd67421aead53f81830392b3a288', 'message': 'notifier middleware broken by oslo.messaging\n\naudit middleware in oslo-incubator is incompatible with oslo.messaging.\nan oslo.messaging compatible version is available in pycadf library.\nenable audit by default to better test for integration issues\n\nPartial-Bug: #1280327\nChange-Id: I3ba16370cbbc5548069a16fe47e85f18a8e69418\n'}, {'number': 6, 'created': '2014-03-03 21:19:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/2c15756d5a86ee62833f9c0f1842dce546650305', 'message': 'notifier middleware broken by oslo.messaging\n\naudit middleware in oslo-incubator is incompatible with oslo.messaging.\nan oslo.messaging compatible version is available in pycadf library.\ncreate optional audit filter\n\nPartial-Bug: #1280327\nChange-Id: I3ba16370cbbc5548069a16fe47e85f18a8e69418\n'}, {'number': 7, 'created': '2014-03-03 21:19:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/420643c45457253bbd13a75c934adecd43ec11dd', 'message': 'notifier middleware broken by oslo.messaging\n\naudit middleware in oslo-incubator is incompatible with oslo.messaging.\nan oslo.messaging compatible version is available in pycadf library.\ncreate optional audit filter\n\nPartial-Bug: #1280327\nChange-Id: I3ba16370cbbc5548069a16fe47e85f18a8e69418\n'}, {'number': 8, 'created': '2014-03-03 21:19:47.000000000', 'files': ['etc/nova/api-paste.ini'], 'web_link': 'https://opendev.org/openstack/nova/commit/65da706a4c52a8e6512626960119323a8a716815', 'message': 'notifier middleware broken by oslo.messaging\n\naudit middleware in oslo-incubator is incompatible with oslo.messaging.\nan oslo.messaging compatible version is available in pycadf library.\ncreate optional audit filter\n\nPartial-Bug: #1280327\nChange-Id: I3ba16370cbbc5548069a16fe47e85f18a8e69418\n'}]",0,77247,65da706a4c52a8e6512626960119323a8a716815,49,8,8,6537,,,0,"notifier middleware broken by oslo.messaging

audit middleware in oslo-incubator is incompatible with oslo.messaging.
an oslo.messaging compatible version is available in pycadf library.
create optional audit filter

Partial-Bug: #1280327
Change-Id: I3ba16370cbbc5548069a16fe47e85f18a8e69418
",git fetch https://review.opendev.org/openstack/nova refs/changes/47/77247/6 && git format-patch -1 --stdout FETCH_HEAD,"['requirements.txt', 'etc/nova/api-paste.ini']",2,60cb337380ad3bc1696aad3383da3defabaebeaa,audit,keystone = faultwrap sizelimit authtoken keystonecontext ratelimit audit osapi_compute_app_v2 keystone_nolimit = faultwrap sizelimit authtoken keystonecontext audit osapi_compute_app_v2keystone = faultwrap sizelimit authtoken keystonecontext audit osapi_compute_app_v3 [filter:audit] paste.filter_factory = pycadf.middleware.audit:AuditMiddleware.factory,keystone = faultwrap sizelimit authtoken keystonecontext ratelimit osapi_compute_app_v2 keystone_nolimit = faultwrap sizelimit authtoken keystonecontext osapi_compute_app_v2keystone = faultwrap sizelimit authtoken keystonecontext osapi_compute_app_v3,7,4
openstack%2Fopenstack-manuals~master~I30171f00a21687784050fcab9c5b5a43f8823b35,openstack/openstack-manuals,master,I30171f00a21687784050fcab9c5b5a43f8823b35,3PAR: Narrow the focus of required client package,MERGED,2014-03-06 16:54:12.000000000,2014-03-06 22:12:57.000000000,2014-03-06 22:12:56.000000000,"[{'_account_id': 3}, {'_account_id': 964}, {'_account_id': 7923}]","[{'number': 1, 'created': '2014-03-06 16:54:12.000000000', 'files': ['doc/config-reference/block-storage/drivers/hp-3par-driver.xml'], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/1d6b08d8fed0d8a301e3c3699241b0b98e98c681', 'message': '3PAR: Narrow the focus of required client package\n\nThis restricts the range of the supported hp3parclient pypi\npackage to what will actually work with the 3PAR Block Storage\ndriver. This matches the versions specified in the\nglobal-requirements.txt file as part of patch:\nhttps://review.openstack.org/#/c/73727/1/global-requirements.txt\n\nChange-Id: I30171f00a21687784050fcab9c5b5a43f8823b35\n'}]",0,78669,1d6b08d8fed0d8a301e3c3699241b0b98e98c681,7,3,1,6043,,,0,"3PAR: Narrow the focus of required client package

This restricts the range of the supported hp3parclient pypi
package to what will actually work with the 3PAR Block Storage
driver. This matches the versions specified in the
global-requirements.txt file as part of patch:
https://review.openstack.org/#/c/73727/1/global-requirements.txt

Change-Id: I30171f00a21687784050fcab9c5b5a43f8823b35
",git fetch https://review.opendev.org/openstack/openstack-manuals refs/changes/69/78669/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/config-reference/block-storage/drivers/hp-3par-driver.xml'],1,1d6b08d8fed0d8a301e3c3699241b0b98e98c681,3parclient_version," <screen><prompt>$</prompt> <userinput>sudo pip install 'hp3parclient&gt;=3.0,&lt;4.0'</userinput></screen>", <screen><prompt>$</prompt> <userinput>sudo pip install hp3parclient</userinput></screen>,1,1
openstack%2Fcinder~master~Ic48fd62d37d3c85a74b5370d243f8583689cda10,openstack/cinder,master,Ic48fd62d37d3c85a74b5370d243f8583689cda10,"Revert ""Add EMC VNX Direct Driver in Cinder""",ABANDONED,2014-03-06 20:51:22.000000000,2014-03-06 22:05:01.000000000,,[{'_account_id': 3}],"[{'number': 1, 'created': '2014-03-06 20:51:22.000000000', 'files': ['etc/cinder/cinder.conf.sample', 'cinder/tests/test_emc_vnxdirect.py', 'cinder/volume/drivers/emc/emc_cli_iscsi.py', 'cinder/volume/drivers/emc/emc_vnx_cli.py'], 'web_link': 'https://opendev.org/openstack/cinder/commit/c48fd62d37d3c85a74b5370d243f8583689cda10', 'message': 'Revert ""Add EMC VNX Direct Driver in Cinder""\n\nThis reverts commit 0c33d1443447e76481fdcc19af1b000d60219d10'}]",0,78757,c48fd62d37d3c85a74b5370d243f8583689cda10,2,1,1,2243,,,0,"Revert ""Add EMC VNX Direct Driver in Cinder""

This reverts commit 0c33d1443447e76481fdcc19af1b000d60219d10",git fetch https://review.opendev.org/openstack/cinder refs/changes/57/78757/1 && git format-patch -1 --stdout FETCH_HEAD,"['etc/cinder/cinder.conf.sample', 'cinder/tests/test_emc_vnxdirect.py', 'cinder/volume/drivers/emc/emc_cli_iscsi.py', 'cinder/volume/drivers/emc/emc_vnx_cli.py']",4,c48fd62d37d3c85a74b5370d243f8583689cda10,,,"# Copyright (c) 2012 - 2014 EMC Corporation, Inc. # All Rights Reserved. # # Licensed under the Apache License, Version 2.0 (the ""License""); you may # not use this file except in compliance with the License. You may obtain # a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT # WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the # License for the specific language governing permissions and limitations # under the License. """""" VNX CLI on iSCSI. """""" import os import time from oslo.config import cfg from cinder import exception from cinder.openstack.common import log as logging from cinder.openstack.common import loopingcall from cinder.openstack.common import processutils from cinder import utils from cinder.volume.drivers.san import san from cinder.volume import volume_types LOG = logging.getLogger(__name__) CONF = cfg.CONF VERSION = '02.00.00' loc_opts = [ cfg.StrOpt('naviseccli_path', default='', help='Naviseccli Path'), cfg.StrOpt('storage_vnx_pool_name', default=None, help='ISCSI pool name'), cfg.IntOpt('default_timeout', default=20, help='Default Time Out For CLI operations in minutes'), cfg.IntOpt('max_luns_per_storage_group', default=256, help='Default max number of LUNs in a storage group'), ] CONF.register_opts(loc_opts) class EMCVnxCli(): """"""This class defines the functions to use the native CLI functionality."""""" stats = {'driver_version': VERSION, 'free_capacity_gb': 'unknown', 'reserved_percentage': 0, 'storage_protocol': None, 'total_capacity_gb': 'unknown', 'vendor_name': 'EMC', 'volume_backend_name': None} def __init__(self, prtcl, configuration=None): self.protocol = prtcl self.configuration = configuration self.configuration.append_config_values(loc_opts) self.configuration.append_config_values(san.san_opts) self.storage_ip = self.configuration.san_ip self.storage_username = self.configuration.san_login self.storage_password = self.configuration.san_password self.pool_name = self.configuration.storage_vnx_pool_name if not self.pool_name: msg = (_('Pool name is not specified.')) LOG.error(msg) raise exception.VolumeBackendAPIException(data=msg) self.timeout = self.configuration.default_timeout self.max_luns = self.configuration.max_luns_per_storage_group self.hlu_set = set(xrange(1, self.max_luns + 1)) self.navisecclipath = self.configuration.naviseccli_path self.cli_prefix = (self.navisecclipath, '-address', self.storage_ip) self.cli_credentials = () self.wait_interval = 3 # if there is a username/password provided, use those in the cmd line if self.storage_username is not None and \ self.storage_password is not None: self.cli_credentials += ('-user', self.storage_username, '-password', self.storage_password, '-scope', '0') # Checking for existence of naviseccli tool if not os.path.exists(self.navisecclipath): msg = (_('Could not find NAVISECCLI tool.')) LOG.error(msg) raise exception.VolumeBackendAPIException(data=msg) # Testing the naviseccli setup query_list = (""storagepool"", ""-list"", ""-name"", self.pool_name, ""-state"") out, rc = self._cli_execute(*query_list) if rc != 0: LOG.error(_(""Failed to find pool %s""), self.pool_name) raise exception.VolumeBackendAPIException(data=out) def _cli_execute(self, *cmd, **kwargv): if ""check_exit_code"" not in kwargv.keys(): kwargv[""check_exit_code""] = True rc = 0 try: out, _err = utils.execute(*(self.cli_prefix + self.cli_credentials + cmd), **kwargv) except processutils.ProcessExecutionError as pe: rc = pe.exit_code out = pe.stdout + pe.stderr return out, rc def create_volume(self, volume): """"""Creates a EMC volume."""""" LOG.debug(_('Entering create_volume.')) volumesize = volume['size'] volumename = volume['name'] LOG.info(_('Create Volume: %(volume)s Size: %(size)s') % {'volume': volumename, 'size': volumesize}) # defining CLI command thinness = self._get_provisioning_by_volume(volume) # executing CLI command to create volume LOG.debug(_('Create Volume: %(volumename)s') % {'volumename': volumename}) lun_create = ('lun', '-create', '-type', thinness, '-capacity', volumesize, '-sq', 'gb', '-poolName', self.pool_name, '-name', volumename) out, rc = self._cli_execute(*lun_create) LOG.debug(_('Create Volume: %(volumename)s Return code: %(rc)s') % {'volumename': volumename, 'rc': rc}) if rc == 4: LOG.warn(_('Volume %s already exists'), volumename) elif rc != 0: msg = (_('Failed to create %(volumename)s: %(out)s') % {'volumename': volumename, 'out': out}) LOG.error(msg) raise exception.VolumeBackendAPIException(data=msg) # wait for up to a minute to verify that the LUN has progressed # to Ready state def _wait_for_lun_ready(volumename): # executing cli command to check volume command_to_verify = ('lun', '-list', '-name', volumename) out, rc = self._cli_execute(*command_to_verify) if rc == 0 and out.find(""Ready"") > -1: raise loopingcall.LoopingCallDone() if int(time.time()) - self.start_lun_ready > self.timeout * 60: msg = (_('LUN %s failed to become Ready'), volumename) LOG.error(msg) raise exception.VolumeBackendAPIException(data=msg) self.start_lun_ready = int(time.time()) timer = loopingcall.FixedIntervalLoopingCall( _wait_for_lun_ready, volumename) timer.start(interval=self.wait_interval).wait() def delete_volume(self, volume): """"""Deletes an EMC volume."""""" LOG.debug(_('Entering delete_volume.')) volumename = volume['name'] # defining CLI command lun_destroy = ('lun', '-destroy', '-name', volumename, '-forceDetach', '-o') # executing CLI command to delete volume out, rc = self._cli_execute(*lun_destroy) LOG.debug(_('Delete Volume: %(volumename)s Output: %(out)s') % {'volumename': volumename, 'out': out}) if rc not in (0, 9): msg = (_('Failed to destroy %s'), volumename) LOG.error(msg) raise exception.VolumeBackendAPIException(data=msg) def extend_volume(self, volume, new_size): """"""Extends an EMC volume."""""" LOG.debug(_('Entering extend_volume.')) volumename = volume['name'] # defining CLI command lun_expand = ('lun', '-expand', '-name', volumename, '-capacity', new_size, '-sq', 'gb', '-o', '-ignoreThresholds') # executing CLI command to extend volume out, rc = self._cli_execute(*lun_expand) LOG.debug(_('Extend Volume: %(volumename)s Output: %(out)s') % {'volumename': volumename, 'out': out}) if rc == 97: msg = (_('The LUN cannot be expanded or shrunk because ' 'it has snapshots. Command to extend the specified ' 'volume failed.')) LOG.error(msg) raise exception.VolumeBackendAPIException(data=msg) if rc != 0: msg = (_('Failed to expand %s'), volumename) LOG.error(msg) raise exception.VolumeBackendAPIException(data=msg) def update_volume_status(self): """"""Retrieve status info."""""" LOG.debug(_(""Updating volume status"")) poolname = self.pool_name pool_list = ('storagepool', '-list', '-name', poolname, '-userCap', '-availableCap') out, rc = self._cli_execute(*pool_list) if rc == 0: pool_details = out.split('\n') self.stats['total_capacity_gb'] = float( pool_details[3].split(':')[1].strip()) self.stats['free_capacity_gb'] = float( pool_details[5].split(':')[1].strip()) else: msg = (_('Failed to list %s'), poolname) LOG.error(msg) return self.stats def create_export(self, context, volume): """"""Driver entry point to get the export info for a new volume."""""" volumename = volume['name'] device_id = self._find_lun_id(volumename) LOG.debug(_('create_export: Volume: %(volume)s Device ID: ' '%(device_id)s') % {'volume': volumename, 'device_id': device_id}) return {'provider_location': device_id} def _find_lun_id(self, volumename): """"""Returns the LUN of a volume."""""" lun_list = ('lun', '-list', '-name', volumename) out, rc = self._cli_execute(*lun_list) if rc == 0: vol_details = out.split('\n') lun = vol_details[0].split(' ')[3] else: msg = (_('Failed to list %s'), volumename) LOG.error(msg) raise exception.VolumeBackendAPIException(data=msg) return lun def create_snapshot(self, snapshot): """"""Creates a snapshot."""""" LOG.debug(_('Entering create_snapshot.')) snapshotname = snapshot['name'] volumename = snapshot['volume_name'] LOG.info(_('Create snapshot: %(snapshot)s: volume: %(volume)s') % {'snapshot': snapshotname, 'volume': volumename}) volume_lun = self._find_lun_id(volumename) # defining CLI command snap_create = ('snap', '-create', '-res', volume_lun, '-name', snapshotname, '-allowReadWrite', 'yes') # executing CLI command to create snapshot out, rc = self._cli_execute(*snap_create) LOG.debug(_('Create Snapshot: %(snapshotname)s Unity: %(out)s') % {'snapshotname': snapshotname, 'out': out}) if rc != 0: msg = (_('Failed to create snap %s'), snapshotname) LOG.error(msg) raise exception.VolumeBackendAPIException(data=msg) def delete_snapshot(self, snapshot): """"""Deletes a snapshot."""""" LOG.debug(_('Entering delete_snapshot.')) snapshotname = snapshot['name'] volumename = snapshot['volume_name'] LOG.info(_('Delete Snapshot: %(snapshot)s: volume: %(volume)s') % {'snapshot': snapshotname, 'volume': volumename}) def _wait_for_snap_delete(snapshot): # defining CLI command snapshotname = snapshot['name'] volumename = snapshot['volume_name'] snap_destroy = ('snap', '-destroy', '-id', snapshotname, '-o') # executing CLI command out, rc = self._cli_execute(*snap_destroy) LOG.debug(_('Delete Snapshot: Volume: %(volumename)s Snapshot: ' '%(snapshotname)s Output: %(out)s') % {'volumename': volumename, 'snapshotname': snapshotname, 'out': out}) if rc not in [0, 9, 5]: if rc == 13: if int(time.time()) - self.start_snap_delete < \ self.timeout * 60: LOG.info(_('Snapshot %s is in use'), snapshotname) else: msg = (_('Failed to destroy %s ' ' because snapshot is in use.'), snapshotname) LOG.error(msg) raise exception.SnapshotIsBusy(data=msg) else: msg = (_('Failed to destroy %s'), snapshotname) LOG.error(msg) raise exception.VolumeBackendAPIException(data=msg) else: raise loopingcall.LoopingCallDone() self.start_snap_delete = int(time.time()) timer = loopingcall.FixedIntervalLoopingCall( _wait_for_snap_delete, snapshot) timer.start(interval=self.wait_interval).wait() def create_volume_from_snapshot(self, volume, snapshot): """"""Creates a volume from a snapshot."""""" LOG.debug(_('Entering create_volume_from_snapshot.')) snapshotname = snapshot['name'] source_volume_name = snapshot['volume_name'] volumename = volume['name'] volumesize = snapshot['volume_size'] destvolumename = volumename + 'dest' # Create a mount point, migrate data from source (snapshot) to # destination volume. The destination volume is the only new volume # to be created here. LOG.info(_('Creating Destination Volume : %s ') % (destvolumename)) poolname = self.pool_name thinness = self._get_provisioning_by_volume(volume) # defining CLI command lun_create = ('lun', '-create', '-type', thinness, '-capacity', volumesize, '-sq', 'gb', '-poolName', poolname, '-name', destvolumename) # executing CLI command out, rc = self._cli_execute(*lun_create) LOG.debug(_('Create temporary Volume: %(volumename)s ' 'Output : %(out)s') % {'volumename': destvolumename, 'out': out}) if rc != 0: msg = (_('Command to create the destination volume failed')) LOG.error(msg) raise exception.VolumeBackendAPIException(data=msg) # defining CLI command smp_create = ('lun', '-create', '-type', 'Snap', '-primaryLunName', source_volume_name, '-name', volumename) # executing CLI command out, rc = self._cli_execute(*smp_create) LOG.debug(_('Create mount point : Volume: %(volumename)s ' 'Source Volume: %(sourcevolumename)s Output: %(out)s') % {'volumename': volumename, 'sourcevolumename': source_volume_name, 'out': out}) if rc != 0: msg = (_('Failed to create SMP %s'), volumename) LOG.error(msg) raise exception.VolumeBackendAPIException(data=msg) # defining CLI command lun_attach = ('lun', '-attach', '-name', volumename, '-snapName', snapshotname) # executing CLI command out, rc = self._cli_execute(*lun_attach) LOG.debug(_('Attaching mount point Volume: %(volumename)s ' 'with Snapshot: %(snapshotname)s Output: %(out)s') % {'volumename': volumename, 'snapshotname': snapshotname, 'out': out}) if rc != 0: msg = (_('Failed to attach snapshotname %s'), snapshotname) LOG.error(msg) raise exception.VolumeBackendAPIException(data=msg) source_vol_lun = self._find_lun_id(volumename) dest_vol_lun = self._find_lun_id(destvolumename) LOG.info(_('Migrating Mount Point Volume: %s ') % (volumename)) # defining CLI command migrate_start = ('migrate', '-start', '-source', source_vol_lun, '-dest', dest_vol_lun, '-rate', 'ASAP', '-o') # executing CLI command out, rc = self._cli_execute(*migrate_start) LOG.debug(_('Migrate Mount Point Volume: %(volumename)s ' 'Output : %(out)s') % {'volumename': volumename, 'out': out}) if rc != 0: msg = (_('Failed to start migrating SMP %s'), volumename) LOG.error(msg) raise exception.VolumeBackendAPIException(data=msg) self.sync_status = False def _wait_for_sync_status(volumename): lun_list = ('lun', '-list', '-name', volumename, '-attachedSnapshot') out, rc = self._cli_execute(*lun_list) if rc == 0: vol_details = out.split('\n') snapshotname = vol_details[2].split(':')[1].strip() if (snapshotname == 'N/A'): self.sync_status = True raise loopingcall.LoopingCallDone() else: LOG.info(_('Waiting for the update on Sync status of %s '), volumename) if int(time.time()) - self.start_status >= self.timeout * 60: raise loopingcall.LoopingCallDone() self.start_status = int(time.time()) timer = loopingcall.FixedIntervalLoopingCall( _wait_for_sync_status, volumename) timer.start(interval=self.wait_interval).wait() if not self.sync_status: msg = (_('Failed to really migrate %s'), volumename) LOG.error(msg) raise exception.VolumeBackendAPIException(data=msg) def create_cloned_volume(self, volume, src_vref): """"""Creates a clone of the specified volume."""""" source_volume_name = src_vref['name'] volumesize = src_vref['size'] snapshotname = source_volume_name + '-temp-snapshot' snapshot = { 'name': snapshotname, 'volume_name': source_volume_name, 'volume_size': volumesize, } # Create temp Snapshot self.create_snapshot(snapshot) try: # Create volume self.create_volume_from_snapshot(volume, snapshot) except Exception: msg = (_('Failed to create cloned volume %s'), volume['name']) LOG.error(msg) raise exception.VolumeBackendAPIException(data=msg) finally: # Delete temp Snapshot self.delete_snapshot(snapshot) def get_storage_group(self, hostname): """"""Returns the storage group for the host node."""""" storage_groupname = hostname sg_list = ('storagegroup', '-list', '-gname', storage_groupname) out, rc = self._cli_execute(*sg_list) if rc != 0: LOG.debug(_('creating new storage group %s'), storage_groupname) sg_create = ('storagegroup', '-create', '-gname', storage_groupname) out, rc = self._cli_execute(*sg_create) LOG.debug(_('Create new storage group : %(storage_groupname)s, ' 'Output: %(out)s') % {'storage_groupname': storage_groupname, 'out': out}) if rc != 0: msg = (_('Failed to create SG %s'), storage_groupname) LOG.error(msg) raise exception.VolumeBackendAPIException(data=msg) # connecting the new storagegroup to the host connect_host = ('storagegroup', '-connecthost', '-host', hostname, '-gname', storage_groupname, '-o') out, rc = self._cli_execute(*connect_host) LOG.debug(_('Connect storage group : %(storage_groupname)s ,' 'To Host : %(hostname)s, Output : %(out)s') % {'storage_groupname': storage_groupname, 'hostname': hostname, 'out': out}) if rc != 0: msg = (_('Failed to connect %s'), hostname) LOG.error(msg) raise exception.VolumeBackendAPIException(data=msg) return hostname def find_device_details(self, volume, storage_group): """"""Returns the Host Device number for the volume."""""" allocated_lun_id = self._find_lun_id(volume[""name""]) host_lun_id = -1 owner_sp = """" lun_map = {} sg_list = ('storagegroup', '-list', '-gname', storage_group) out, rc = self._cli_execute(*sg_list) if out.find('HLU/ALU Pairs') == -1: LOG.info(_('NO LUNs in the storagegroup : %s ') % (storage_group)) else: sg_details = out.split('HLU/ALU Pairs:')[1] sg_lun_details = sg_details.split('Shareable')[0] lun_details = sg_lun_details.split('\n') for data in lun_details: if data not in ['', ' HLU Number ALU Number', ' ---------- ----------']: data = data.strip() items = data.split(' ') lun_map[int(items[len(items) - 1])] = int(items[0]) for lun in lun_map.iterkeys(): if lun == int(allocated_lun_id): host_lun_id = lun_map[lun] LOG.debug(_('Host Lun Id : %s') % (host_lun_id)) break # finding the owner SP for the LUN lun_list = ('lun', '-list', '-l', allocated_lun_id, '-owner') out, rc = self._cli_execute(*lun_list) if rc == 0: output = out.split('\n') owner_sp = output[2].split('Current Owner: SP ')[1] LOG.debug(_('Owner SP : %s') % (owner_sp)) device = { 'hostlunid': host_lun_id, 'ownersp': owner_sp, 'lunmap': lun_map, } return device def _get_host_lun_id(self, host_lun_id_list): # Returns the host lun id for the LUN to be added # in the storage group. used_hlu_set = set(host_lun_id_list) for hlu in self.hlu_set - used_hlu_set: return hlu return None def _add_lun_to_storagegroup(self, volume, storage_group): storage_groupname = storage_group volumename = volume['name'] allocated_lun_id = self._find_lun_id(volumename) count = 0 while(count < 5): device_info = self.find_device_details(volume, storage_group) device_number = device_info['hostlunid'] if device_number < 0: lun_map = device_info['lunmap'] if lun_map: host_lun_id_list = lun_map.values() if len(host_lun_id_list) >= self.max_luns: msg = (_('The storage group has reached the ' 'maximum capacity of LUNs. ' 'Command to add LUN for volume - %s ' 'in storagegroup failed') % (volumename)) LOG.error(msg) raise exception.VolumeBackendAPIException(data=msg) host_lun_id = self._get_host_lun_id(host_lun_id_list) if host_lun_id is None: msg = (_('Unable to get new host lun id. Please ' 'check if the storage group can accomodate ' 'new LUN. ' 'Command to add LUN for volume - %s ' 'in storagegroup failed') % (volumename)) LOG.error(msg) raise exception.VolumeBackendAPIException(data=msg) else: host_lun_id = 1 addhlu = ('storagegroup', '-addhlu', '-o', '-gname', storage_groupname, '-hlu', host_lun_id, '-alu', allocated_lun_id) out, rc = self._cli_execute(*addhlu) LOG.debug(_('Add ALU %(alu)s to SG %(sg)s as %(hlu)s. ' 'Output: %(out)s') % {'alu': allocated_lun_id, 'sg': storage_groupname, 'hlu': host_lun_id, 'out': out}) if rc == 0: return host_lun_id if rc == 66: LOG.warn(_('Requested Host LUN Number already in use')) count += 1 else: LOG.warn(_('LUN was already added in the storage group')) return device_number if count == 5: msg = (_('Failed to add %s into SG') % (volumename)) LOG.error(msg) raise exception.VolumeBackendAPIException(data=msg) def _remove_lun_from_storagegroup(self, device_number, storage_group): storage_groupname = storage_group removehlu = ('storagegroup', '-removehlu', '-gname', storage_groupname, '-hlu', device_number, '-o') out, rc = self._cli_execute(*removehlu) LOG.debug(_('Remove %(hlu)s from SG %(sg)s. Output: %(out)s') % {'hlu': device_number, 'sg': storage_groupname, 'out': out}) if rc != 0: msg = (_('Failed to remove %(hlu)s from %(sg)s') % {'hlu': device_number, 'sg': storage_groupname}) LOG.error(msg) raise exception.VolumeBackendAPIException(data=msg) def initialize_connection(self, volume, connector): """"""Initializes the connection and returns connection info."""""" hostname = connector['host'] storage_group = self.get_storage_group(hostname) device_number = self._add_lun_to_storagegroup(volume, storage_group) return device_number def terminate_connection(self, volume, connector): """"""Disallow connection from connector."""""" hostname = connector['host'] storage_group = self.get_storage_group(hostname) device_info = self.find_device_details(volume, storage_group) device_number = device_info['hostlunid'] if device_number < 0: LOG.error(_('Could not locate the attached volume.')) else: self._remove_lun_from_storagegroup(device_number, storage_group) def _find_iscsi_protocol_endpoints(self, device_sp): """"""Returns the iSCSI initiators for a SP."""""" initiator_address = [] connection_getport = ('connection', '-getport', '-sp', device_sp) out, _rc = self._cli_execute(*connection_getport) output = out.split('SP: ') for port in output: port_info = port.split('\n') if port_info[0] == device_sp: port_wwn = port_info[2].split('Port WWN:')[1].strip() initiator_address.append(port_wwn) LOG.debug(_('WWNs found for SP %(devicesp)s ' 'are: %(initiator_address)s') % {'devicesp': device_sp, 'initiator_address': initiator_address}) return initiator_address def _get_volumetype_extraspecs(self, volume): specs = {} type_id = volume['volume_type_id'] if type_id is not None: specs = volume_types.get_volume_type_extra_specs(type_id) return specs def _get_provisioning_by_volume(self, volume): # By default, the user can not create thin LUN without thin # provisioning enabler. thinness = 'NonThin' spec_id = 'storagetype:provisioning' specs = self._get_volumetype_extraspecs(volume) if specs and spec_id in specs: provisioning = specs[spec_id].lower() if 'thin' == provisioning: thinness = 'Thin' elif 'thick' != provisioning: LOG.warning(_('Invalid value of extra spec ' '\'storagetype:provisioning\': %(provisioning)s') % {'provisioning': specs[spec_id]}) else: LOG.info(_('No extra spec \'storagetype:provisioning\' exist')) return thinness ",0,1615
openstack%2Fheat~master~I350b2e20e274cce7a0f654cb71f7445632e0e633,openstack/heat,master,I350b2e20e274cce7a0f654cb71f7445632e0e633,Allow getting attributes on suspended resources.,MERGED,2014-03-02 21:52:24.000000000,2014-03-06 21:58:50.000000000,2014-03-06 21:58:49.000000000,"[{'_account_id': 3}, {'_account_id': 2011}, {'_account_id': 3098}, {'_account_id': 4328}, {'_account_id': 4571}, {'_account_id': 6456}]","[{'number': 1, 'created': '2014-03-02 21:52:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/f3d3907474c7078ca90a6bc290d17d070a78e647', 'message': 'Allow getting attributes on suspended resources.\n\nA resource which is suspended can legitimately have attributes returned\nfor it.\n\nPartial-Bug: #1286920\n\nChange-Id: I350b2e20e274cce7a0f654cb71f7445632e0e633\n'}, {'number': 2, 'created': '2014-03-04 07:07:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/9bf7ed54c9e55722d20aa4a4605193fee027a2ad', 'message': 'Allow getting attributes on suspended resources.\n\nA resource which is suspended can legitimately have attributes returned\nfor it.\n\nRelated-Bug: #1286920\n\nChange-Id: I350b2e20e274cce7a0f654cb71f7445632e0e633\n'}, {'number': 3, 'created': '2014-03-04 23:37:39.000000000', 'files': ['heat/tests/test_parser.py', 'heat/engine/cfn/functions.py'], 'web_link': 'https://opendev.org/openstack/heat/commit/835e3047f397a28b4405270c0f659a63a1837a3d', 'message': 'Allow getting attributes on suspended resources.\n\nA resource which is suspended can legitimately have attributes returned\nfor it.\n\nRelated-Bug: #1286920\n\nChange-Id: I350b2e20e274cce7a0f654cb71f7445632e0e633\n'}]",0,77452,835e3047f397a28b4405270c0f659a63a1837a3d,28,6,3,4571,,,0,"Allow getting attributes on suspended resources.

A resource which is suspended can legitimately have attributes returned
for it.

Related-Bug: #1286920

Change-Id: I350b2e20e274cce7a0f654cb71f7445632e0e633
",git fetch https://review.opendev.org/openstack/heat refs/changes/52/77452/3 && git format-patch -1 --stdout FETCH_HEAD,['heat/engine/cfn/functions.py'],1,f3d3907474c7078ca90a6bc290d17d070a78e647,bug/1286920," r.action in (r.CREATE, r.SUSPEND, r.RESUME, r.UPDATE)):"," r.action in (r.CREATE, r.RESUME, r.UPDATE)):",1,1
openstack%2Frequirements~stable%2Fgrizzly~I6bcd4254082d980868e0f2795eb95b8c19be6637,openstack/requirements,stable/grizzly,I6bcd4254082d980868e0f2795eb95b8c19be6637,Set git-review default branch for stable/grizzly,MERGED,2014-02-17 21:54:58.000000000,2014-03-06 21:58:48.000000000,2014-03-06 21:58:48.000000000,"[{'_account_id': 3}, {'_account_id': 1669}, {'_account_id': 1955}, {'_account_id': 5196}, {'_account_id': 6786}]","[{'number': 1, 'created': '2014-02-17 21:54:58.000000000', 'files': ['.gitreview'], 'web_link': 'https://opendev.org/openstack/requirements/commit/e16ff5b6aab6c5edc0843140852aba4bbf1aef2d', 'message': 'Set git-review default branch for stable/grizzly\n\nChange-Id: I6bcd4254082d980868e0f2795eb95b8c19be6637\n'}]",0,74180,e16ff5b6aab6c5edc0843140852aba4bbf1aef2d,19,5,1,5196,,,0,"Set git-review default branch for stable/grizzly

Change-Id: I6bcd4254082d980868e0f2795eb95b8c19be6637
",git fetch https://review.opendev.org/openstack/requirements refs/changes/80/74180/1 && git format-patch -1 --stdout FETCH_HEAD,['.gitreview'],1,e16ff5b6aab6c5edc0843140852aba4bbf1aef2d,git-review-path,defaultbranch=stable/grizzly,,1,0
openstack%2Fkeystone~master~I742cef9dab68d9eed977df0039736cfe67ca493c,openstack/keystone,master,I742cef9dab68d9eed977df0039736cfe67ca493c,"Sync db, db.sqlalchemy, gettextutils from oslo-incubator 6ba44fd",MERGED,2014-02-22 01:08:26.000000000,2014-03-06 21:58:40.000000000,2014-03-06 21:58:39.000000000,"[{'_account_id': 3}, {'_account_id': 4}, {'_account_id': 792}, {'_account_id': 1916}, {'_account_id': 2218}, {'_account_id': 2903}, {'_account_id': 5707}, {'_account_id': 6482}, {'_account_id': 6486}, {'_account_id': 7191}, {'_account_id': 7536}, {'_account_id': 7725}]","[{'number': 1, 'created': '2014-02-22 01:08:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/36a3cbbba383d2b4a1081742f5b8a6c41ac5e4d0', 'message': ""Sync db, db.sqlalchemy, gettextutils from oslo-incubator 0f24d82a\n\nThis change sync's oslo-incubator's db module from commit hash\n0f24d82afc9d8ebfbbd7b2488f00f43ed5314902\n\n $ python update.py --nodeps --base keystone \\\n    --dest-dir ../keystone \\\n    --modules db,db.sqlalchemy,gettextutils\n\n- Config options were moved from db.sqlalchemy.session to db.options\n- db.sqlalchemy.session doesn't provide get_session, get_engine, or\n  cleanup functions.\n- db.sqlalchemy.migration.db_version() requires an engine parameter\n\nChange-Id: I742cef9dab68d9eed977df0039736cfe67ca493c\n""}, {'number': 2, 'created': '2014-02-22 13:42:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/0998cf4d7a8f14d3a5e7034d9fd1a04f8fda58de', 'message': ""Sync db, db.sqlalchemy, gettextutils from oslo-incubator 0f24d82a\n\nThis change sync's oslo-incubator's db module from commit hash\n0f24d82afc9d8ebfbbd7b2488f00f43ed5314902\n\n $ python update.py --nodeps --base keystone \\\n    --dest-dir ../keystone \\\n    --modules db,db.sqlalchemy,gettextutils\n\n- Config options were moved from db.sqlalchemy.session to db.options\n- db.sqlalchemy.session doesn't provide get_session, get_engine, or\n  cleanup functions.\n- db.sqlalchemy.migration.db_version() requires an engine parameter\n\nChange-Id: I742cef9dab68d9eed977df0039736cfe67ca493c\n""}, {'number': 3, 'created': '2014-02-22 14:06:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/07f2c860a64a0f8bee9b741e736ce8d288bcd0fc', 'message': ""Sync db, db.sqlalchemy, gettextutils from oslo-incubator 0f24d82a\n\nThis change sync's oslo-incubator's db module from commit hash\n0f24d82afc9d8ebfbbd7b2488f00f43ed5314902\n\n $ python update.py --nodeps --base keystone \\\n    --dest-dir ../keystone \\\n    --modules db,db.sqlalchemy,gettextutils\n\n- Config options were moved from db.sqlalchemy.session to db.options\n- db.sqlalchemy.session doesn't provide get_session, get_engine, or\n  cleanup functions.\n- db.sqlalchemy.migration.db_version() requires an engine parameter\n\nChange-Id: I742cef9dab68d9eed977df0039736cfe67ca493c\n""}, {'number': 4, 'created': '2014-02-26 19:24:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/d02f558f52e5ea836f82aa5bdf8eb3522d05712b', 'message': ""Sync db, db.sqlalchemy, gettextutils from oslo-incubator 6ba44fd\n\nThis change sync's oslo-incubator's db module from commit hash\n6ba44fd7f9d39a7930defb4e14c37b8b1046cbcb\n\n $ python update.py --nodeps --base keystone \\\n    --dest-dir ../keystone \\\n    --modules db,db.sqlalchemy,gettextutils\n\n- Config options were moved from db.sqlalchemy.session to db.options\n- db.sqlalchemy.session doesn't provide get_session, get_engine, or\n  cleanup functions.\n- db.sqlalchemy.migration.db_version() requires an engine parameter\n\nCloses-Bug: #1227321\n\nChange-Id: I742cef9dab68d9eed977df0039736cfe67ca493c\n""}, {'number': 5, 'created': '2014-02-26 20:52:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/9d6f16d67956a8f62b21625aff173893b03212c6', 'message': ""Sync db, db.sqlalchemy, gettextutils from oslo-incubator 6ba44fd\n\nThis change sync's oslo-incubator's db module from commit hash\n6ba44fd7f9d39a7930defb4e14c37b8b1046cbcb\n\n $ python update.py --nodeps --base keystone \\\n    --dest-dir ../keystone \\\n    --modules db,db.sqlalchemy,gettextutils\n\n- Config options were moved from db.sqlalchemy.session to db.options\n- db.sqlalchemy.session doesn't provide get_session, get_engine, or\n  cleanup functions.\n- db.sqlalchemy.migration.db_version() requires an engine parameter\n\nCloses-Bug: #1227321\n\nChange-Id: I742cef9dab68d9eed977df0039736cfe67ca493c\n""}, {'number': 6, 'created': '2014-02-27 15:14:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/4756a6ded069b2ed54bef0e6d1e001d3f93dc780', 'message': ""Sync db, db.sqlalchemy, gettextutils from oslo-incubator 6ba44fd\n\nThis change sync's oslo-incubator's db module from commit hash\n6ba44fd7f9d39a7930defb4e14c37b8b1046cbcb\n\n $ python update.py --nodeps --base keystone \\\n    --dest-dir ../keystone \\\n    --modules db,db.sqlalchemy,gettextutils\n\n- Config options were moved from db.sqlalchemy.session to db.options\n- db.sqlalchemy.session doesn't provide get_session, get_engine, or\n  cleanup functions.\n- db.sqlalchemy.migration.db_version() requires an engine parameter\n\nCloses-Bug: #1227321\n\nChange-Id: I742cef9dab68d9eed977df0039736cfe67ca493c\n""}, {'number': 7, 'created': '2014-03-04 15:40:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/90475d5136792c94605d396e8cf6969b9d355c5d', 'message': ""Sync db, db.sqlalchemy, gettextutils from oslo-incubator 6ba44fd\n\nThis change sync's oslo-incubator's db module from commit hash\n6ba44fd7f9d39a7930defb4e14c37b8b1046cbcb\n\n $ python update.py --nodeps --base keystone \\\n    --dest-dir ../keystone \\\n    --modules db,db.sqlalchemy,gettextutils\n\n- Config options were moved from db.sqlalchemy.session to db.options\n- db.sqlalchemy.session doesn't provide get_session, get_engine, or\n  cleanup functions.\n- db.sqlalchemy.migration.db_version() requires an engine parameter\n\nCloses-Bug: #1227321\n\nChange-Id: I742cef9dab68d9eed977df0039736cfe67ca493c\n""}, {'number': 8, 'created': '2014-03-04 21:14:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/9162cfe81dc2e8daa54e5eb2d4faca6a446e8b3f', 'message': ""Sync db, db.sqlalchemy, gettextutils from oslo-incubator 6ba44fd\n\nThis change sync's oslo-incubator's db module from commit hash\n6ba44fd7f9d39a7930defb4e14c37b8b1046cbcb\n\n $ python update.py --nodeps --base keystone \\\n    --dest-dir ../keystone \\\n    --modules db,db.sqlalchemy,gettextutils\n\n- Config options were moved from db.sqlalchemy.session to db.options\n- db.sqlalchemy.session doesn't provide get_session, get_engine, or\n  cleanup functions.\n- db.sqlalchemy.migration.db_version() requires an engine parameter\n\nCloses-Bug: #1227321\n\nChange-Id: I742cef9dab68d9eed977df0039736cfe67ca493c\n""}, {'number': 9, 'created': '2014-03-05 19:58:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/dd5206522ec2cb405c9d4f034ef8ea009d9bbc5f', 'message': ""Sync db, db.sqlalchemy, gettextutils from oslo-incubator 6ba44fd\n\nThis change sync's oslo-incubator's db module from commit hash\n6ba44fd7f9d39a7930defb4e14c37b8b1046cbcb\n\n $ python update.py --nodeps --base keystone \\\n    --dest-dir ../keystone \\\n    --modules db,db.sqlalchemy,gettextutils\n\n- Config options were moved from db.sqlalchemy.session to db.options\n- db.sqlalchemy.session doesn't provide get_session, get_engine, or\n  cleanup functions.\n- db.sqlalchemy.migration.db_version() requires an engine parameter\n\nCloses-Bug: #1227321\n\nChange-Id: I742cef9dab68d9eed977df0039736cfe67ca493c\n""}, {'number': 10, 'created': '2014-03-05 20:01:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/41f9b396447e6b83ceff1ed9fca83efb2c298be2', 'message': ""Sync db, db.sqlalchemy, gettextutils from oslo-incubator 6ba44fd\n\nThis change sync's oslo-incubator's db module from commit hash\n6ba44fd7f9d39a7930defb4e14c37b8b1046cbcb\n\n $ python update.py --nodeps --base keystone \\\n    --dest-dir ../keystone \\\n    --modules db,db.sqlalchemy,gettextutils\n\n- Config options were moved from db.sqlalchemy.session to db.options\n- db.sqlalchemy.session doesn't provide get_session, get_engine, or\n  cleanup functions.\n- db.sqlalchemy.migration.db_version() requires an engine parameter\n\nCloses-Bug: #1227321\n\nChange-Id: I742cef9dab68d9eed977df0039736cfe67ca493c\n""}, {'number': 11, 'created': '2014-03-06 17:51:49.000000000', 'files': ['keystone/openstack/common/db/sqlalchemy/provision.py', 'keystone/trust/backends/sql.py', 'keystone/openstack/common/db/sqlalchemy/migration.py', 'keystone/tests/test_v3_federation.py', 'keystone/openstack/common/__init__.py', 'keystone/openstack/common/db/sqlalchemy/session.py', 'keystone/tests/test_associate_project_endpoint_extension.py', 'keystone/policy/backends/sql.py', 'keystone/contrib/federation/backends/sql.py', 'keystone/tests/core.py', 'keystone/common/sql/migration_helpers.py', 'keystone/identity/backends/sql.py', 'keystone/openstack/common/db/api.py', 'keystone/contrib/endpoint_filter/backends/sql.py', 'keystone/openstack/common/db/sqlalchemy/test_migrations.py', 'keystone/catalog/backends/sql.py', 'keystone/credential/backends/sql.py', 'keystone/tests/test_keystoneclient.py', 'keystone/contrib/oauth1/backends/sql.py', 'keystone/tests/test_v3_oauth1.py', 'keystone/assignment/backends/sql.py', 'keystone/openstack/common/db/sqlalchemy/models.py', 'keystone/tests/test_backend_sql.py', 'keystone/openstack/common/gettextutils.py', 'keystone/contrib/revoke/backends/sql.py', 'keystone/openstack/common/db/options.py', 'etc/keystone.conf.sample', 'keystone/openstack/common/db/sqlalchemy/utils.py', 'keystone/token/backends/sql.py', 'keystone/common/sql/core.py', 'keystone/tests/test_sql_upgrade.py', 'keystone/openstack/common/db/sqlalchemy/test_base.py', 'keystone/tests/test_backend_ldap.py'], 'web_link': 'https://opendev.org/openstack/keystone/commit/8f7b87b2a7d79f52a971becd2cd5d071a15d7b6d', 'message': ""Sync db, db.sqlalchemy, gettextutils from oslo-incubator 6ba44fd\n\nThis change sync's oslo-incubator's db module from commit hash\n6ba44fd7f9d39a7930defb4e14c37b8b1046cbcb\n\n $ python update.py --nodeps --base keystone \\\n    --dest-dir ../keystone \\\n    --modules db,db.sqlalchemy,gettextutils\n\n- Config options were moved from db.sqlalchemy.session to db.options\n- db.sqlalchemy.session doesn't provide get_session, get_engine, or\n  cleanup functions.\n- db.sqlalchemy.migration.db_version() requires an engine parameter\n\nCloses-Bug: #1227321\n\nChange-Id: I742cef9dab68d9eed977df0039736cfe67ca493c\n""}]",4,75549,8f7b87b2a7d79f52a971becd2cd5d071a15d7b6d,60,12,11,6486,,,0,"Sync db, db.sqlalchemy, gettextutils from oslo-incubator 6ba44fd

This change sync's oslo-incubator's db module from commit hash
6ba44fd7f9d39a7930defb4e14c37b8b1046cbcb

 $ python update.py --nodeps --base keystone \
    --dest-dir ../keystone \
    --modules db,db.sqlalchemy,gettextutils

- Config options were moved from db.sqlalchemy.session to db.options
- db.sqlalchemy.session doesn't provide get_session, get_engine, or
  cleanup functions.
- db.sqlalchemy.migration.db_version() requires an engine parameter

Closes-Bug: #1227321

Change-Id: I742cef9dab68d9eed977df0039736cfe67ca493c
",git fetch https://review.opendev.org/openstack/keystone refs/changes/49/75549/2 && git format-patch -1 --stdout FETCH_HEAD,"['keystone/openstack/common/db/sqlalchemy/provision.py', 'keystone/contrib/kds/db/sqlalchemy/migration.py', 'keystone/trust/backends/sql.py', 'keystone/openstack/common/db/sqlalchemy/migration.py', 'keystone/tests/test_v3_federation.py', 'keystone/openstack/common/__init__.py', 'keystone/openstack/common/db/sqlalchemy/session.py', 'keystone/tests/test_associate_project_endpoint_extension.py', 'keystone/policy/backends/sql.py', 'keystone/contrib/federation/backends/sql.py', 'keystone/tests/core.py', 'keystone/identity/backends/sql.py', 'keystone/openstack/common/db/api.py', 'keystone/contrib/endpoint_filter/backends/sql.py', 'keystone/openstack/common/db/sqlalchemy/test_migrations.py', 'keystone/catalog/backends/sql.py', 'keystone/cli.py', 'keystone/credential/backends/sql.py', 'keystone/tests/test_keystoneclient.py', 'keystone/contrib/oauth1/backends/sql.py', 'keystone/tests/test_v3_oauth1.py', 'keystone/assignment/backends/sql.py', 'keystone/openstack/common/db/sqlalchemy/models.py', 'keystone/contrib/kds/db/sqlalchemy/api.py', 'keystone/tests/test_backend_sql.py', 'keystone/openstack/common/gettextutils.py', 'keystone/openstack/common/db/exception.py', 'keystone/openstack/common/db/options.py', 'etc/keystone.conf.sample', 'keystone/openstack/common/db/sqlalchemy/utils.py', 'keystone/token/backends/sql.py', 'keystone/common/sql/core.py', 'keystone/tests/test_sql_upgrade.py', 'keystone/openstack/common/db/sqlalchemy/test_base.py', 'keystone/contrib/kds/db/api.py', 'keystone/tests/test_backend_ldap.py']",36,36a3cbbba383d2b4a1081742f5b8a6c41ac5e4d0,oslo.db, self.engine = sql.get_engine() self.addCleanup(sql.cleanup) self.engine = sql.get_engine() self.addCleanup(sql.cleanup),from keystone.openstack.common.db.sqlalchemy import session self.engine = session.get_engine() self.addCleanup(session.cleanup) self.engine = session.get_engine() self.addCleanup(session.cleanup),1189,548
openstack%2Fopenstack-manuals~master~I151d4831a74f92c57cd98b96fb0b405d3061b832,openstack/openstack-manuals,master,I151d4831a74f92c57cd98b96fb0b405d3061b832,Removed single data center restriction for VMware,MERGED,2014-03-05 19:18:50.000000000,2014-03-06 21:44:48.000000000,2014-03-06 06:19:06.000000000,"[{'_account_id': 3}, {'_account_id': 612}, {'_account_id': 1297}, {'_account_id': 5162}, {'_account_id': 6547}, {'_account_id': 6772}, {'_account_id': 7629}, {'_account_id': 9162}]","[{'number': 1, 'created': '2014-03-05 19:18:50.000000000', 'files': ['doc/config-reference/compute/section_hypervisor_vmware.xml'], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/1ec1d80051fd8cbb4ed2b1dfb2cc94a3a889d028', 'message': 'Removed single data center restriction for VMware\n\nThe single data center restriction no longer applies for the VMware\ncompute driver.\n\nChange-Id: I151d4831a74f92c57cd98b96fb0b405d3061b832\nbackport: havana\n'}]",0,78372,1ec1d80051fd8cbb4ed2b1dfb2cc94a3a889d028,11,8,1,6772,,,0,"Removed single data center restriction for VMware

The single data center restriction no longer applies for the VMware
compute driver.

Change-Id: I151d4831a74f92c57cd98b96fb0b405d3061b832
backport: havana
",git fetch https://review.opendev.org/openstack/openstack-manuals refs/changes/72/78372/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/config-reference/compute/section_hypervisor_vmware.xml'],1,1ec1d80051fd8cbb4ed2b1dfb2cc94a3a889d028,,," <para><emphasis role=""bold"">vCenter inventory</emphasis>. Make sure that any vCenter used by OpenStack contains a single data center. A future Havana stable release will address this temporary limitation.</para> </listitem> <listitem>",0,6
openstack%2Fbarbican~master~I0a73aaa61570f19844934cbd9a0cc9c9507d319e,openstack/barbican,master,I0a73aaa61570f19844934cbd9a0cc9c9507d319e,Adding a simple test to verify that the API is running,ABANDONED,2014-03-05 21:23:53.000000000,2014-03-06 21:44:13.000000000,,"[{'_account_id': 3}, {'_account_id': 994}, {'_account_id': 7262}, {'_account_id': 7355}, {'_account_id': 7789}, {'_account_id': 9946}]","[{'number': 1, 'created': '2014-03-05 21:23:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/barbican/commit/7e8b4ae3f79d6da69811e6ac307fcb0ad78c3d9f', 'message': 'Adding a simple test to verify that the API is running\n\nAdds a simple version api test to verify that the service is running\n\nChange-Id: I0a73aaa61570f19844934cbd9a0cc9c9507d319e\n'}, {'number': 2, 'created': '2014-03-05 22:43:47.000000000', 'files': ['functionaltests/api/base.py', 'functionaltests/api/v1/test_version.py', '.testr.conf', 'functionaltests/api/__init__.py', 'functionaltests/api/v1/__init__.py'], 'web_link': 'https://opendev.org/openstack/barbican/commit/88f117ef89dcb650f6b100756d8c8cac5518423e', 'message': ""Adding a simple test to verify that the API is running\n\nAdds a simple version api test to verify that the service is running\n\n:: edit ::\nScoping down .testr.conf to only execute tests in barbican/ as it's\nnot suppose to execute the tests in the functionaltests package and\nbreaks the devstack-gate.\n\nChange-Id: I0a73aaa61570f19844934cbd9a0cc9c9507d319e\n""}]",3,78417,88f117ef89dcb650f6b100756d8c8cac5518423e,15,6,2,7262,,,0,"Adding a simple test to verify that the API is running

Adds a simple version api test to verify that the service is running

:: edit ::
Scoping down .testr.conf to only execute tests in barbican/ as it's
not suppose to execute the tests in the functionaltests package and
breaks the devstack-gate.

Change-Id: I0a73aaa61570f19844934cbd9a0cc9c9507d319e
",git fetch https://review.opendev.org/openstack/barbican refs/changes/17/78417/2 && git format-patch -1 --stdout FETCH_HEAD,"['functionaltests/api/base.py', 'functionaltests/api/v1/test_version.py', 'functionaltests/api/__init__.py', 'functionaltests/api/v1/__init__.py']",4,7e8b4ae3f79d6da69811e6ac307fcb0ad78c3d9f,adding_simple_version_test,,,77,0
openstack%2Fbarbican~master~I6141e665433d418b8cbecc4f065b8a3710310d29,openstack/barbican,master,I6141e665433d418b8cbecc4f065b8a3710310d29,Barbican uWSGI stats server listen on localhost,MERGED,2014-03-06 17:41:51.000000000,2014-03-06 21:39:52.000000000,2014-03-06 21:39:52.000000000,"[{'_account_id': 3}, {'_account_id': 7136}, {'_account_id': 7355}, {'_account_id': 7973}, {'_account_id': 10655}]","[{'number': 1, 'created': '2014-03-06 17:41:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/barbican/commit/4821d25039169ef95bc5e4bf5039e130d0e737ce', 'message': 'Barbican uWSGI stats server listen on localhost\n\nThe current uWSGI Upstart script starts the stats server listening\non all IPs. In order to reduce the attack surface, this patch modifies\nthe Upstart script so that the stats server starts listening on\nlocalhost only.\n\nChange-Id: I6141e665433d418b8cbecc4f065b8a3710310d29\nFixes: bug #1288881\n'}, {'number': 2, 'created': '2014-03-06 17:42:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/barbican/commit/3a7d4f8d3a24c0ae7596e2a621186a06cf636cf0', 'message': 'Barbican uWSGI stats server listen on localhost\n\nThe current uWSGI Upstart script starts the stats server listening\non all IPs. In order to reduce the attack surface, this patch modifies\nthe Upstart script so that the stats server starts listening on\nlocalhost only.\n\nFixes: bug #1288881\nChange-Id: I6141e665433d418b8cbecc4f065b8a3710310d29\n'}, {'number': 3, 'created': '2014-03-06 17:52:20.000000000', 'files': ['debian/barbican-api.upstart', 'etc/init/barbican-api.conf'], 'web_link': 'https://opendev.org/openstack/barbican/commit/c3a41505b7cd95e412db439b7bc66a4a55e3a883', 'message': 'Barbican uWSGI stats server listen on localhost\n\nThe current uWSGI Upstart script starts the stats server listening\non all IPs. In order to reduce the attack surface, this patch modifies\nthe Upstart script so that the stats server starts listening on\nlocalhost only.\n\nCloses-Bug: #1288881\nChange-Id: I6141e665433d418b8cbecc4f065b8a3710310d29\n'}]",0,78679,c3a41505b7cd95e412db439b7bc66a4a55e3a883,14,5,3,10655,,,0,"Barbican uWSGI stats server listen on localhost

The current uWSGI Upstart script starts the stats server listening
on all IPs. In order to reduce the attack surface, this patch modifies
the Upstart script so that the stats server starts listening on
localhost only.

Closes-Bug: #1288881
Change-Id: I6141e665433d418b8cbecc4f065b8a3710310d29
",git fetch https://review.opendev.org/openstack/barbican refs/changes/79/78679/1 && git format-patch -1 --stdout FETCH_HEAD,['etc/init/barbican-api.conf'],1,4821d25039169ef95bc5e4bf5039e130d0e737ce,bug/1288881, uwsgi --master --die-on-term --emperor /etc/barbican/vassals --logto /var/log/barbican/barbican-api.log --stats localhost:9314, uwsgi --master --die-on-term --emperor /etc/barbican/vassals --logto /var/log/barbican/barbican-api.log --stats :9314,1,1
openstack%2Fpython-barbicanclient~master~I6b76585c5fd8adbb21d53c6141a2a8550586f94a,openstack/python-barbicanclient,master,I6b76585c5fd8adbb21d53c6141a2a8550586f94a,Add version to setup.cfg,MERGED,2014-03-06 21:15:53.000000000,2014-03-06 21:35:44.000000000,2014-03-06 21:35:44.000000000,"[{'_account_id': 3}, {'_account_id': 7136}, {'_account_id': 7355}, {'_account_id': 7789}]","[{'number': 1, 'created': '2014-03-06 21:15:53.000000000', 'files': ['setup.cfg'], 'web_link': 'https://opendev.org/openstack/python-barbicanclient/commit/11f54097b7410f0345fe2b5d5d98957e9662a76a', 'message': 'Add version to setup.cfg\n\nChange-Id: I6b76585c5fd8adbb21d53c6141a2a8550586f94a\n'}]",0,78767,11f54097b7410f0345fe2b5d5d98957e9662a76a,8,4,1,7973,,,0,"Add version to setup.cfg

Change-Id: I6b76585c5fd8adbb21d53c6141a2a8550586f94a
",git fetch https://review.opendev.org/openstack/python-barbicanclient refs/changes/67/78767/1 && git format-patch -1 --stdout FETCH_HEAD,['setup.cfg'],1,11f54097b7410f0345fe2b5d5d98957e9662a76a,,version = 2.0,,1,0
openstack%2Fpython-neutronclient~master~I577ce0c009a9a281acdc238d290a22c5e561ff82,openstack/python-neutronclient,master,I577ce0c009a9a281acdc238d290a22c5e561ff82,New exception when auth_url is not specified,MERGED,2013-10-23 21:45:41.000000000,2014-03-06 21:03:46.000000000,2014-03-06 21:03:46.000000000,"[{'_account_id': 3}, {'_account_id': 105}, {'_account_id': 261}, {'_account_id': 841}, {'_account_id': 2166}, {'_account_id': 2592}, {'_account_id': 4656}, {'_account_id': 5638}, {'_account_id': 5948}, {'_account_id': 6788}, {'_account_id': 7128}, {'_account_id': 8190}, {'_account_id': 8449}]","[{'number': 1, 'created': '2013-10-23 21:45:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-neutronclient/commit/29a15b002fb4a3bdd04056ae60a2482d26398238', 'message': 'New exception when auth_url is not specified\n\nCertain scenarios into the neutron client will not specify the\nauth_url.  This is typically when a token is specified.  However, when\nthe token is expired the neutron client will attempt to refresh the\ntoken.  Users of this may not have passed in all of the required\ninformation for this reauthentication to properly occur.\n\nThis code fixes an error that occurs in this flow where the auth_url\n(which is None) is appended to another string.  This results in a core\nPython error.\n\nThe update will provide a more targetted error message specifying to\nthe user that the auth_url needs to be specified.  An associated unit\ntest is also included to validate this behavior.\n\nChange-Id: I577ce0c009a9a281acdc238d290a22c5e561ff82\nCloses-Bug: #1241275\n'}, {'number': 2, 'created': '2013-10-28 16:26:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-neutronclient/commit/4bae20e98fd553997a420730326dae7b465572f1', 'message': 'New exception when auth_url is not specified\n\nCertain scenarios into the neutron client will not specify the\nauth_url.  This is typically when a token is specified.  However, when\nthe token is expired the neutron client will attempt to refresh the\ntoken.  Users of this may not have passed in all of the required\ninformation for this reauthentication to properly occur.\n\nThis code fixes an error that occurs in this flow where the auth_url\n(which is None) is appended to another string.  This results in a core\nPython error.\n\nThe update will provide a more targetted error message specifying to\nthe user that the auth_url needs to be specified.  An associated unit\ntest is also included to validate this behavior.\n\nChange-Id: I577ce0c009a9a281acdc238d290a22c5e561ff82\nCloses-Bug: #1241275\n'}, {'number': 3, 'created': '2013-10-29 15:17:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-neutronclient/commit/c781959c385dd0afd8160ac4702cbec41cc224ff', 'message': 'New exception when auth_url is not specified\n\nCertain scenarios into the neutron client will not specify the\nauth_url.  This is typically when a token is specified.  However, when\nthe token is expired the neutron client will attempt to refresh the\ntoken.  Users of this may not have passed in all of the required\ninformation for this reauthentication to properly occur.\n\nThis code fixes an error that occurs in this flow where the auth_url\n(which is None) is appended to another string.  This results in a core\nPython error.\n\nThe update will provide a more targetted error message specifying to\nthe user that the auth_url needs to be specified.  An associated unit\ntest is also included to validate this behavior.\n\nChange-Id: I577ce0c009a9a281acdc238d290a22c5e561ff82\nCloses-Bug: #1241275\n'}, {'number': 4, 'created': '2014-03-04 19:59:41.000000000', 'files': ['neutronclient/client.py', 'neutronclient/common/exceptions.py', 'neutronclient/tests/unit/test_auth.py'], 'web_link': 'https://opendev.org/openstack/python-neutronclient/commit/e49819caf95fc6985036231b1e5717f0ff7b6c61', 'message': 'New exception when auth_url is not specified\n\nCertain scenarios into the neutron client will not specify the\nauth_url.  This is typically when a token is specified.  However, when\nthe token is expired the neutron client will attempt to refresh the\ntoken.  Users of this may not have passed in all of the required\ninformation for this reauthentication to properly occur.\n\nThis code fixes an error that occurs in this flow where the auth_url\n(which is None) is appended to another string.  This results in a core\nPython error.\n\nThe update will provide a more targetted error message specifying to\nthe user that the auth_url needs to be specified.  An associated unit\ntest is also included to validate this behavior.\n\nChange-Id: I577ce0c009a9a281acdc238d290a22c5e561ff82\nCloses-Bug: #1241275\n'}]",8,53461,e49819caf95fc6985036231b1e5717f0ff7b6c61,41,13,4,8190,,,0,"New exception when auth_url is not specified

Certain scenarios into the neutron client will not specify the
auth_url.  This is typically when a token is specified.  However, when
the token is expired the neutron client will attempt to refresh the
token.  Users of this may not have passed in all of the required
information for this reauthentication to properly occur.

This code fixes an error that occurs in this flow where the auth_url
(which is None) is appended to another string.  This results in a core
Python error.

The update will provide a more targetted error message specifying to
the user that the auth_url needs to be specified.  An associated unit
test is also included to validate this behavior.

Change-Id: I577ce0c009a9a281acdc238d290a22c5e561ff82
Closes-Bug: #1241275
",git fetch https://review.opendev.org/openstack/python-neutronclient refs/changes/61/53461/4 && git format-patch -1 --stdout FETCH_HEAD,"['neutronclient/client.py', 'neutronclient/common/exceptions.py', 'neutronclient/tests/unit/test_auth.py']",3,29a15b002fb4a3bdd04056ae60a2482d26398238,bug/1241275," def test_invalid_auth_url(self): # Handle the case where a client passes in a None for the auth_url self.client.auth_url = None self.assertRaises(exceptions.InvalidAuthURLProvided, self.client._get_endpoint_url) ",,17,0
openstack%2Fcinder~master~I2c8860e3f25a7bcaa2d2efefeffc1c11319f33e2,openstack/cinder,master,I2c8860e3f25a7bcaa2d2efefeffc1c11319f33e2,Fix HP LeftHand Performance issue with AO,MERGED,2014-03-05 00:44:31.000000000,2014-03-06 21:03:38.000000000,2014-03-06 21:03:36.000000000,"[{'_account_id': 3}, {'_account_id': 1773}, {'_account_id': 4523}, {'_account_id': 5997}, {'_account_id': 6043}, {'_account_id': 7198}, {'_account_id': 7389}]","[{'number': 1, 'created': '2014-03-05 00:44:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/fe60532e32b8beef48ce1a5c4befa374e016831e', 'message': 'Fix HP LeftHand Performance issue with AO\n\nSetting AdaptiveOptimization (AO) to true, the default value,\nat volume create time significantly slows down the operation on\nthe LeftHand array. If at create time, AO is set to true, it\nwill result in an update operation following the create operation\nto set this value. Therefore, it is best to not specify the value,\nwhen true, and let it default to true.\n\nChange-Id: I2c8860e3f25a7bcaa2d2efefeffc1c11319f33e2\nCloses-Bug:#1285925\n'}, {'number': 2, 'created': '2014-03-05 17:17:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/331e0e9088fc089ff608948ee905a8ecf4f4eed8', 'message': 'Fix HP LeftHand Performance issue with AO\n\nSetting AdaptiveOptimization (AO) to true, the default value,\nat volume create time significantly slows down the operation on\nthe LeftHand array. If at create time, AO is set to true, it\nwill result in an update operation following the create operation\nto set this value. Therefore, it is best to not specify the value,\nwhen true, and let it default to true.\n\nChange-Id: I2c8860e3f25a7bcaa2d2efefeffc1c11319f33e2\nCloses-Bug:#1285925\n'}, {'number': 3, 'created': '2014-03-05 22:13:01.000000000', 'files': ['cinder/tests/test_hplefthand.py', 'cinder/volume/drivers/san/hp/hp_lefthand_rest_proxy.py'], 'web_link': 'https://opendev.org/openstack/cinder/commit/52a7d601a0c97ab4eb47b9bf10da19a9f61afe25', 'message': 'Fix HP LeftHand Performance issue with AO\n\nSetting AdaptiveOptimization (AO) to true, the default value,\nat volume create time significantly slows down the operation on\nthe LeftHand array. If at create time, AO is set to true, it\nwill result in an update operation following the create operation\nto set this value. Therefore, it is best to not specify the value,\nwhen true, and let it default to true.\n\nChange-Id: I2c8860e3f25a7bcaa2d2efefeffc1c11319f33e2\nCloses-Bug:#1285925\n'}]",14,78055,52a7d601a0c97ab4eb47b9bf10da19a9f61afe25,19,7,3,7389,,,0,"Fix HP LeftHand Performance issue with AO

Setting AdaptiveOptimization (AO) to true, the default value,
at volume create time significantly slows down the operation on
the LeftHand array. If at create time, AO is set to true, it
will result in an update operation following the create operation
to set this value. Therefore, it is best to not specify the value,
when true, and let it default to true.

Change-Id: I2c8860e3f25a7bcaa2d2efefeffc1c11319f33e2
Closes-Bug:#1285925
",git fetch https://review.opendev.org/openstack/cinder refs/changes/55/78055/1 && git format-patch -1 --stdout FETCH_HEAD,"['cinder/tests/test_hplefthand.py', 'cinder/volume/drivers/san/hp/hp_lefthand_rest_proxy.py']",2,fe60532e32b8beef48ce1a5c4befa374e016831e,bug/1285925," 1.0.4 - Fixed bug #1285925, LeftHand AO volume create performance improvement VERSION = ""1.0.4"" # The default for adaptive optimization is true, so if it # set to True, we will just remove it because there is a # performance issue when set. See bug #1285925 if ('isAdaptiveOptimizationEnabled' in optional and optional['isAdaptiveOptimizationEnabled']): del optional['isAdaptiveOptimizationEnabled'] "," VERSION = ""1.0.3""",82,1
openstack%2Fneutron~master~Ic8a0dc0f5950d41b9b253c0d61b6812dbfd161c7,openstack/neutron,master,Ic8a0dc0f5950d41b9b253c0d61b6812dbfd161c7,One Convergence Neutron Plugin Implementation,MERGED,2014-01-27 01:09:55.000000000,2014-03-06 21:03:27.000000000,2014-03-06 21:03:26.000000000,"[{'_account_id': 3}, {'_account_id': 490}, {'_account_id': 841}, {'_account_id': 2035}, {'_account_id': 2592}, {'_account_id': 2711}, {'_account_id': 4395}, {'_account_id': 5170}, {'_account_id': 6072}, {'_account_id': 6659}, {'_account_id': 7776}, {'_account_id': 9008}, {'_account_id': 9681}, {'_account_id': 9722}, {'_account_id': 9732}, {'_account_id': 9787}, {'_account_id': 9845}, {'_account_id': 9925}, {'_account_id': 10116}, {'_account_id': 10117}, {'_account_id': 10119}, {'_account_id': 10153}, {'_account_id': 10184}, {'_account_id': 10192}, {'_account_id': 10294}, {'_account_id': 10387}]","[{'number': 1, 'created': '2014-01-27 01:09:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/78e0b071223055b0c6392feae6dcd8ed9c8a42f4', 'message': 'One Convergence Neutron Plugin Implementation.\n\nOne Convergence Neutron Plugin implements Neutron API to provide a network\nvirtualization solution. The plugin works with One Convergence NVSD controller\nto provide the functionality. This checkin implements the Neutron core APIs\nand the plugin will be extended to support the L3 and service plugin extension\nAPIs.\n\nChange-Id: Ic8a0dc0f5950d41b9b253c0d61b6812dbfd161c7\nImplements: blueprint oc-nvsd-neutron-plugin\n'}, {'number': 2, 'created': '2014-02-01 01:37:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/8550f48b390e4e0aab11be7c2c6bc35e88f97499', 'message': 'One Convergence Neutron Plugin Implementation\n\nOne Convergence Neutron Plugin implements Neutron API to provide a network\nvirtualization solution. The plugin works with One Convergence NVSD controller\nto provide the functionality. This checkin implements the Neutron core APIs\nand the plugin will be extended to support the L3 and service plugin extension\nAPIs.\n\nChange-Id: Ic8a0dc0f5950d41b9b253c0d61b6812dbfd161c7\nImplements: blueprint oc-nvsd-neutron-plugin\n'}, {'number': 3, 'created': '2014-02-02 01:50:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/f0083b0672149d77fb4214a8f54422b5dc2981d9', 'message': 'One Convergence Neutron Plugin Implementation\n\nOne Convergence Neutron Plugin implements Neutron API to provide a network\nvirtualization solution. The plugin works with One Convergence NVSD controller\nto provide the functionality. This checkin implements the Neutron core APIs\nand the plugin will be extended to support the L3 and service plugin extension\nAPIs.\n\nFixes for review comments. Add urllib3 package to requirements.\n\nChange-Id: Ic8a0dc0f5950d41b9b253c0d61b6812dbfd161c7\nImplements: blueprint oc-nvsd-neutron-plugin\n'}, {'number': 4, 'created': '2014-02-09 23:25:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/69894c1efec9d2d448401e7c1726704747925f6c', 'message': 'One Convergence Neutron Plugin Implementation\n\nOne Convergence Neutron Plugin implements Neutron API to provide a network\nvirtualization solution. The plugin works with One Convergence NVSD controller\nto provide the functionality. This checkin implements the Neutron core APIs\nand the plugin will be extended to support the L3 and service plugin extension\nAPIs.\n\nFixes for review comments.\n\nChange-Id: Ic8a0dc0f5950d41b9b253c0d61b6812dbfd161c7\nImplements: blueprint oc-nvsd-neutron-plugin\n'}, {'number': 5, 'created': '2014-02-12 21:33:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/eac8d861c015b44832e1ec11f6e1fbccf9bebe2c', 'message': 'One Convergence Neutron Plugin Implementation\n\nOne Convergence Neutron Plugin implements Neutron API to provide a network\nvirtualization solution. The plugin works with One Convergence NVSD controller\nto provide the functionality. This checkin implements the Neutron core APIs\nand the plugin will be extended to support the L3 and service plugin extension\nAPIs.\n\nFixes for review comments.\n\nChange-Id: Ic8a0dc0f5950d41b9b253c0d61b6812dbfd161c7\nImplements: blueprint oc-nvsd-neutron-plugin\n'}, {'number': 6, 'created': '2014-02-17 04:06:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/1ef8c0acf761561d4681f43c7260bcc561406991', 'message': 'One Convergence Neutron Plugin Implementation\n\nOne Convergence Neutron Plugin implements Neutron API to provide a network\nvirtualization solution. The plugin works with One Convergence NVSD controller\nto provide the functionality. This checkin implements the Neutron core APIs\nand the plugin will be extended to support the L3 and service plugin extension\nAPIs.\n\nFixes for review comments.\n\nChange-Id: Ic8a0dc0f5950d41b9b253c0d61b6812dbfd161c7\nImplements: blueprint oc-nvsd-neutron-plugin\n'}, {'number': 7, 'created': '2014-02-27 03:21:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/7f18d9229aeaa60f30e128ff76df001ba198bc59', 'message': 'One Convergence Neutron Plugin Implementation\n\nOne Convergence Neutron Plugin implements Neutron API to provide a network\nvirtualization solution. The plugin works with One Convergence NVSD controller\nto provide the functionality. This checkin implements the Neutron core APIs\nand the plugin will be extended to support the L3 and service plugin extension\nAPIs.\n\nFixes for review comments.\n\nChange-Id: Ic8a0dc0f5950d41b9b253c0d61b6812dbfd161c7\nImplements: blueprint oc-nvsd-neutron-plugin\n'}, {'number': 8, 'created': '2014-03-04 07:22:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/fc6f33a3ec489ebaf8a8c35067dcb0e6d4a2ecb8', 'message': 'One Convergence Neutron Plugin Implementation\n\nOne Convergence Neutron Plugin implements Neutron API to provide a network\nvirtualization solution. The plugin works with One Convergence NVSD controller\nto provide the functionality. This checkin implements the Neutron core APIs\nand the plugin will be extended to support the L3 and service plugin extension\nAPIs.\n\nFixes for review comments.\n\nChange-Id: Ic8a0dc0f5950d41b9b253c0d61b6812dbfd161c7\nImplements: blueprint oc-nvsd-neutron-plugin\n'}, {'number': 9, 'created': '2014-03-04 10:30:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/550cc1df3990f31f6a2aca0f913e64263c5ba1f8', 'message': 'One Convergence Neutron Plugin Implementation\n\nOne Convergence Neutron Plugin implements Neutron API to provide a network\nvirtualization solution. The plugin works with One Convergence NVSD controller\nto provide the functionality. This checkin implements the Neutron core APIs\nand the plugin will be extended to support the L3 and service plugin extension\nAPIs.\n\nFixes for review comments.\n\nChange-Id: Ic8a0dc0f5950d41b9b253c0d61b6812dbfd161c7\nImplements: blueprint oc-nvsd-neutron-plugin\n'}, {'number': 10, 'created': '2014-03-04 23:20:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/4073a836398a0e75a192d4cd09664ea23a245a45', 'message': 'One Convergence Neutron Plugin Implementation\n\nOne Convergence Neutron Plugin implements Neutron API to provide a network\nvirtualization solution. The plugin works with One Convergence NVSD controller\nto provide the functionality. This checkin implements the Neutron core APIs\nand the plugin will be extended to support the L3 and service plugin extension\nAPIs.\n\nChange-Id: Ic8a0dc0f5950d41b9b253c0d61b6812dbfd161c7\nImplements: blueprint oc-nvsd-neutron-plugin\n'}, {'number': 11, 'created': '2014-03-05 01:29:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/8a02e8dbeddbe483bc03450b0eb8844848aa471e', 'message': 'One Convergence Neutron Plugin Implementation\n\nOne Convergence Neutron Plugin implements Neutron API to provide a network\nvirtualization solution. The plugin works with One Convergence NVSD controller\nto provide the functionality. This checkin implements the Neutron core APIs\nand the plugin will be extended to support the L3 and service plugin extension\nAPIs.\n\nChange-Id: Ic8a0dc0f5950d41b9b253c0d61b6812dbfd161c7\nImplements: blueprint oc-nvsd-neutron-plugin\n'}, {'number': 12, 'created': '2014-03-05 07:25:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/1980a92a238f843d35dcfaf9921e2b8134b1ae66', 'message': 'One Convergence Neutron Plugin Implementation\n\nOne Convergence Neutron Plugin implements Neutron API to provide a network\nvirtualization solution. The plugin works with One Convergence NVSD controller\nto provide the functionality. This checkin implements the Neutron core APIs\nand the plugin will be extended to support the L3 and service plugin extension\nAPIs.\n\nChange-Id: Ic8a0dc0f5950d41b9b253c0d61b6812dbfd161c7\nImplements: blueprint oc-nvsd-neutron-plugin\n'}, {'number': 13, 'created': '2014-03-05 20:36:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/74189228a8f0fdb9384c24e7ea35f75cf2715c41', 'message': 'One Convergence Neutron Plugin Implementation\n\nOne Convergence Neutron Plugin implements Neutron API to provide a network\nvirtualization solution. The plugin works with One Convergence NVSD controller\nto provide the functionality. This checkin implements the Neutron core APIs\nand the plugin will be extended to support the L3 and service plugin extension\nAPIs.\n\nChange-Id: Ic8a0dc0f5950d41b9b253c0d61b6812dbfd161c7\nImplements: blueprint oc-nvsd-neutron-plugin\n'}, {'number': 14, 'created': '2014-03-06 14:58:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/48c17701e236b5e9731fde8f47c10333a2955e03', 'message': 'One Convergence Neutron Plugin Implementation\n\nOne Convergence Neutron Plugin implements Neutron API to provide a network\nvirtualization solution. The plugin works with One Convergence NVSD controller\nto provide the functionality. This checkin implements the Neutron core APIs\nand the plugin will be extended to support the L3 and service plugin extension\nAPIs.\n\nChange-Id: Ic8a0dc0f5950d41b9b253c0d61b6812dbfd161c7\nImplements: blueprint oc-nvsd-neutron-plugin\n'}, {'number': 15, 'created': '2014-03-06 15:51:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/d6e6a58fdb0f9a3c39cfe6a5c017141694454849', 'message': 'One Convergence Neutron Plugin Implementation\n\nOne Convergence Neutron Plugin implements Neutron API to provide a network\nvirtualization solution. The plugin works with One Convergence NVSD controller\nto provide the functionality. This checkin implements the Neutron core APIs\nand the plugin will be extended to support the L3 and service plugin extension\nAPIs.\n\nChange-Id: Ic8a0dc0f5950d41b9b253c0d61b6812dbfd161c7\nImplements: blueprint oc-nvsd-neutron-plugin\n'}, {'number': 16, 'created': '2014-03-06 16:10:49.000000000', 'files': ['etc/neutron/plugins/oneconvergence/nvsdplugin.ini', 'neutron/db/migration/alembic_migrations/versions/176a85fc7d79_add_portbindings_db.py', 'neutron/db/migration/alembic_migrations/versions/2eeaf963a447_floatingip_status.py', 'neutron/db/migration/alembic_migrations/versions/4692d074d587_agent_scheduler.py', 'neutron/db/migration/alembic_migrations/versions/128e042a2b68_ext_gw_mode.py', 'neutron/db/migration/alembic_migrations/versions/511471cc46b_agent_ext_model_supp.py', 'neutron/plugins/oneconvergence/plugin.py', 'neutron/plugins/oneconvergence/README', 'neutron/db/migration/alembic_migrations/versions/folsom_initial.py', 'neutron/plugins/oneconvergence/lib/plugin_helper.py', 'neutron/tests/unit/oneconvergence/test_plugin_helper.py', 'neutron/db/migration/alembic_migrations/versions/1c33fa3cd1a1_extra_route_config.py', 'neutron/plugins/oneconvergence/lib/exception.py', 'neutron/tests/unit/oneconvergence/test_nvsd_plugin.py', 'neutron/db/migration/alembic_migrations/versions/1fcfc149aca4_agents_unique_by_type_and_host.py', 'neutron/plugins/oneconvergence/lib/__init__.py', 'neutron/plugins/oneconvergence/lib/config.py', 'neutron/plugins/oneconvergence/__init__.py', 'neutron/tests/unit/oneconvergence/__init__.py', 'neutron/tests/unit/oneconvergence/test_nvsdlib.py', 'neutron/plugins/oneconvergence/lib/nvsdlib.py', 'setup.cfg', 'neutron/db/migration/alembic_migrations/versions/3cb5d900c5de_security_groups.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/683323f3593a9123a6e87d6b0f50bb0679f13e56', 'message': 'One Convergence Neutron Plugin Implementation\n\nOne Convergence Neutron Plugin implements Neutron API to provide a network\nvirtualization solution. The plugin works with One Convergence NVSD controller\nto provide the functionality. This checkin implements the Neutron core APIs\nand the plugin will be extended to support the L3 and service plugin extension\nAPIs.\n\nChange-Id: Ic8a0dc0f5950d41b9b253c0d61b6812dbfd161c7\nImplements: blueprint oc-nvsd-neutron-plugin\n'}]",299,69246,683323f3593a9123a6e87d6b0f50bb0679f13e56,230,26,16,9722,,,0,"One Convergence Neutron Plugin Implementation

One Convergence Neutron Plugin implements Neutron API to provide a network
virtualization solution. The plugin works with One Convergence NVSD controller
to provide the functionality. This checkin implements the Neutron core APIs
and the plugin will be extended to support the L3 and service plugin extension
APIs.

Change-Id: Ic8a0dc0f5950d41b9b253c0d61b6812dbfd161c7
Implements: blueprint oc-nvsd-neutron-plugin
",git fetch https://review.opendev.org/openstack/neutron refs/changes/46/69246/16 && git format-patch -1 --stdout FETCH_HEAD,"['neutron/plugins/oneconvergence/NeutronPlugin.py', 'etc/neutron/plugins/oneconvergence/nvsdplugin.ini', 'neutron/plugins/oneconvergence/README', 'neutron/plugins/oneconvergence/lib/logging_module.py', 'neutron/plugins/oneconvergence/lib/plugin_helper.py', 'neutron/plugins/oneconvergence/lib/exception.py', 'neutron/tests/unit/oneconvergence/test_nvsd_plugin.py', 'neutron/plugins/oneconvergence/lib/__init__.py', 'neutron/plugins/oneconvergence/lib/config.py', 'neutron/plugins/oneconvergence/lib/credentials.py', 'neutron/plugins/oneconvergence/lib/dummynvsdlib.py', 'neutron/plugins/oneconvergence/__init__.py', 'neutron/tests/unit/oneconvergence/__init__.py', 'neutron/plugins/oneconvergence/lib/nvsdlib.py']",14,78e0b071223055b0c6392feae6dcd8ed9c8a42f4,bp/oc-nvsd-neutron-plugin,"# vim: tabstop=4 shiftwidth=4 softtabstop=4 # # Copyright 2014 OneConvergence, Inc. All Rights Reserved. # # Licensed under the Apache License, Version 2.0 (the ""License""); you may # not use this file except in compliance with the License. You may obtain # a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT # WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the # License for the specific language governing permissions and limitations # under the License. # # @author: Kedar Kulkarni, One Convergence, Inc. """""" Intermidiate NVSD Library """""" import json from oslo.config import cfg from neutron.api.v2 import attributes from neutron.common import exceptions as n_exception import neutron.plugins.oneconvergence.lib.exception as nvsdexception import neutron.plugins.oneconvergence.lib.logging_module as logging_module from neutron.plugins.oneconvergence.lib.plugin_helper import \ initialize_plugin_helper NETWORKS_URI = ""/pluginhandler/ocplugin/tenant/%s/lnetwork/"" NETWORK_URI = NETWORKS_URI + ""%s"" GET_ALL_NETWORKS = ""/pluginhandler/ocplugin/tenant/getallnetworks"" SUBNETS_URI = NETWORK_URI + ""/lsubnet/"" SUBNET_URI = SUBNETS_URI + ""%s"" GET_ALL_SUBNETS = ""/pluginhandler/ocplugin/tenant/getallsubnets"" PORTS_URI = NETWORK_URI + ""/lport/"" PORT_URI = PORTS_URI + ""%s"" class NVSDApi: def __init__(self): pass def set_log_level(self): self.log = logging_module.Logger( app_name=""NVSDPlugin"", module_name=""nvsdlib"", loglevel=cfg.CONF.nvsd.loglevel) def set_connection(self): self.nvsdcontroller = initialize_plugin_helper() self.set_log_level() self.nvsdcontroller.login() def send_request(self, *args): """"""Issue a request to nvsd controller"""""" return self.nvsdcontroller.request(*args) def create_network(self, network): tenant_id = network['tenant_id'] external = network['router:external'] router_external = False if external is True: router_external = True else: router_external = False network_obj = { ""name"": network['name'], ""tenant_id"": tenant_id, ""shared"": network['shared'], ""admin_state_up"": network['admin_state_up'], ""router:external"": router_external } uri = NETWORKS_URI % tenant_id try: response = self.send_request(""POST"", uri, json.dumps(network_obj)) except nvsdexception.NVSDAPIException: self.log.emit('error', tenant_id, ""Exception in create network for"" "" tenant %s "" % tenant_id) raise n_exception.NeutronException() nvsd_net = json.loads(response.body) self.log.emit('debug', tenant_id, ""Network %s created"" ""under tenant %s"" % (nvsd_net['id'], tenant_id)) return nvsd_net def get_network(self, tenant_id, network_id): path = NETWORK_URI % (tenant_id, network_id) try: self.send_request(""GET"", path) except nvsdexception.NotFoundException: self.log.emit('error', tenant_id, ""Network %s not found for tenant"" "" %s"" % (network_id, tenant_id)) raise n_exception.NetworkNotFound(net_id=network_id) except nvsdexception.NVSDAPIException: self.log.emit('error', tenant_id, ""Exception in get network %s"" % network_id) raise n_exception.NeutronException() self.log.emit('debug', tenant_id, ""Network %s retrieved under tenant"" "" %s"" % (network_id, tenant_id)) def update_network(self, network, network_update): tenant_id = network['tenant_id'] network_id = network['id'] uri = NETWORK_URI % (tenant_id, network_id) try: response = self.send_request(""PUT"", uri, json.dumps(network_update)) except nvsdexception.NotFoundException: self.log.emit('error', tenant_id, ""Network %s not found for updation"" ""for tenant %s"" % (network_id, tenant_id)) raise n_exception.NetworkNotFound(net_id=network_id) except nvsdexception.NVSDAPIException: self.log.emit('error', tenant_id, ""Exception in update network %s \ tenant %s"" % (network_id, tenant_id)) raise n_exception.NeutronException() self.log.emit('debug', tenant_id, ""Network %s updated under tenant"" "" %s"" % (network_id, tenant_id)) return json.loads(response.body) def delete_network(self, network, subnets): tenant_id = network['tenant_id'] network_id = network['id'] ports = self._get_ports(tenant_id, network_id) for port in ports: self.delete_port(port['id'], port) for subnet in subnets: self.delete_subnet(subnet) path = NETWORK_URI % (tenant_id, network_id) try: self.send_request(""DELETE"", path) except nvsdexception.NotFoundException: self.log.emit('error', tenant_id, ""Network %s not found for deletion"" "" for tenant %s"" % (network_id, tenant_id)) raise n_exception.NetworkNotFound(net_id=network_id) except nvsdexception.NVSDAPIException: self.log.emit('error', tenant_id, ""Exception in delete network %s"" "" tenant %s"" % (network_id, tenant_id)) raise n_exception.NeutronException() self.log.emit('debug', tenant_id, ""Network %s deleted under tenant %s"" """" % (network_id, tenant_id)) def create_subnet(self, subnet): tenant_id = subnet['tenant_id'] network_id = subnet['network_id'] uri = SUBNETS_URI % (tenant_id, network_id) try: response = self.send_request(""POST"", uri, json.dumps(subnet)) except nvsdexception.NVSDAPIException(): self.log.emit('error', tenant_id, ""Error in creating subnet"") raise nvsdexception.NVSDAPIException() self.log.emit('debug', tenant_id, ""Subnet %s created"" ""under tenant %s"" % (subnet['id'], tenant_id)) return json.loads(response.body) def delete_subnet(self, subnet): tenant_id = subnet['tenant_id'] network_id = subnet['network_id'] subnet_id = subnet['id'] uri = SUBNET_URI % (tenant_id, network_id, subnet_id) try: self.send_request(""DELETE"", uri) except nvsdexception.NotFoundException: self.log.emit('error', tenant_id, ""Resource not found for"" ""delete subnet %s tenant %s"" % (subnet_id, tenant_id)) raise n_exception.SubnetNotFound(subnet_id=subnet_id) except nvsdexception.NVSDAPIException: self.log.emit('error', tenant_id, """") raise n_exception.NeutronException() self.log.emit('debug', tenant_id, ""Subnet %s deleted"" ""under tenant %s"" % (subnet_id, tenant_id)) def update_subnet(self, subnet, subnet_update): tenant_id = subnet['tenant_id'] network_id = subnet['network_id'] subnet_id = subnet['id'] uri = SUBNET_URI % (tenant_id, network_id, subnet_id) try: response = self.send_request(""PUT"", uri, json.dumps(subnet_update)) except nvsdexception.NotFoundException: self.log.emit('error', tenant_id, ""Not found in update Subnet %s \ or Network %s for tenant %s"" % (subnet_id, network_id, tenant_id)) raise n_exception.SubnetNotFound(subnet_id=subnet_id) except nvsdexception.NVSDAPIException: self.log.emit('error', tenant_id, ""Exception in update subnet %s \ for tenant %s"" % (subnet_id, tenant_id)) raise n_exception.NeutronException() self.log.emit('debug', tenant_id, ""Subnet %s updated"" ""under tenant %s"" % (subnet_id, tenant_id)) return json.loads(response.body) def get_subnet(self, subnet): tenant_id = subnet['tenant_id'] network_id = subnet['network_id'] subnet_id = subnet['id'] uri = SUBNET_URI % (tenant_id, network_id, subnet_id) try: response = self.send_request(""GET"", uri) except nvsdexception.NotFoundException: self.log.emit('error', tenant_id, ""Resource not found for"" ""get subnet %s tenant %s"" % (subnet_id, tenant_id)) raise n_exception.SubnetNotFound(subnet_id=subnet_id) except nvsdexception.NVSDAPIException: self.log.emit('error', tenant_id, """") raise n_exception.NeutronException() self.log.emit('debug', tenant_id, ""Subnet is %s fetched"" ""under tenant %s"" % (subnet_id, tenant_id)) return json.loads(response.body) def create_port(self, tenant_id, port): port['tenant_id'] = tenant_id network_id = port[""network_id""] fixed_ips = port.get(""fixed_ips"") ip_address = None subnet_id = None if fixed_ips: ip_address = fixed_ips[0].get(""ip_address"") subnet_id = fixed_ips[0].get(""subnet_id"") lport = { ""id"": port[""id""], ""name"": port[""name""], ""device_id"": port[""device_id""], ""device_owner"": port[""device_owner""], ""mac_address"": port[""mac_address""], ""ip_address"": ip_address, ""subnet_id"": subnet_id, ""admin_state_up"": port[""admin_state_up""], ""network_id"": network_id, ""status"": port[""status""] } path = PORTS_URI % (tenant_id, network_id) try: self.send_request(""POST"", path, json.dumps(lport)) except nvsdexception.NotFoundException: self.log.emit('error', tenant_id, ""Network %s not found in create port"" "" tenant %s"" % (network_id, tenant_id)) raise nvsdexception.NotFoundException() except nvsdexception.NVSDAPIException: self.log.emit('error', tenant_id, ""Exception in create port"" "" tenant %s"" % tenant_id) raise nvsdexception.NVSDAPIException() self.log.emit('debug', tenant_id, ""Port %s created"" ""under tenant %s"" % (port[""id""], tenant_id)) def update_port(self, tenant_id, port, port_update): network_id = port['network_id'] port_id = port['id'] admin_state_up = port_update.get('admin_state_up', None) name = port_update.get('name', None) device_id = port_update.get('device_id', None) device_owner = port_update.get('device_owner', None) fixed_ips = port_update.get('fixed_ips', None) lport = {} if admin_state_up is not None: lport[""admin_state_up""] = admin_state_up if name: lport[""name""] = name if device_id: lport[""device_id""] = device_id if device_owner: lport[""device_owner""] = device_owner if fixed_ips: lport[""ip_address""] = fixed_ips[0].get(""ip_address"") lport[""subnet_id""] = fixed_ips[0].get(""subnet_id"") uri = PORT_URI % (tenant_id, network_id, port_id) try: self.send_request(""PUT"", uri, json.dumps(lport)) except nvsdexception.NotFoundException: self.log.emit('error', tenant_id, ""Not found in update Port %s or \ Network %s for tenant %s"" % (port_id, network_id, tenant_id)) raise n_exception.PortNotFound(port_id=port_id, net_id=network_id) except nvsdexception.NVSDAPIException: self.log.emit('error', tenant_id, ""Exception in update port %s \ for tenant %s"" % (port_id, tenant_id)) raise n_exception.NeutronException() self.log.emit('debug', tenant_id, ""Port %s updated"" ""under tenant %s"" % (port_id, tenant_id)) def delete_port(self, port_id, port): tenant_id = port['tenant_id'] network_id = port['network_id'] uri = PORT_URI % (tenant_id, network_id, port_id) try: self.send_request(""DELETE"", uri) except nvsdexception.NotFoundException: self.log.emit('error', tenant_id, ""Resource not found for"" ""delete port %s tenant %s"" % (port_id, tenant_id)) raise n_exception.PortNotFound(port_id=port_id, net_id=network_id) except nvsdexception.NVSDAPIException: self.log.emit('error', tenant_id, """") raise n_exception.NeutronException() self.log.emit('debug', tenant_id, ""Port %s deleted"" ""under tenant %s"" % (port_id, tenant_id)) def get_port(self, tenant_id, network_id, port_id): uri = PORT_URI % (tenant_id, network_id, port_id) try: response = self.send_request(""GET"", uri) nvsd_port = json.loads(response.body) except nvsdexception.NotFoundException: self.log.emit('error', tenant_id, ""Resource not found for"" ""get port %s, network %s, tenant %s"" % ( port_id, network_id, tenant_id)) raise n_exception.PortNotFound(port_id=nvsd_port, net_id=network_id) except nvsdexception.NVSDAPIException: self.log.emit('error', tenant_id, ""Exception in get port %s"" "" Network- %s tenant- %s"" % ( port_id, network_id, tenant_id)) raise n_exception.NeutronException() self.log.emit('debug', tenant_id, ""Port is %s fetched"" ""under tenant %s"" % (port_id, tenant_id)) return nvsd_port def _get_ports(self, tenant_id, network_id): uri = PORTS_URI % (tenant_id, network_id) try: response = self.send_request(""GET"", uri) except nvsdexception.NotFoundException: self.log.emit('error', tenant_id, ""Resource not found in get ports"" "", Network %s for tenant %s"" % (network_id, tenant_id)) raise n_exception.NetworkNotFound(net_id=network_id) except nvsdexception.NVSDAPIException: self.log.emit('error', tenant_id, ""Exception in get ports, Network %s"" "" for tenant %s"" % (network_id, tenant_id)) raise n_exception.NeutronException() return json.loads(response.body) ",,1529,0
openstack%2Fdevstack~master~I6193a5d78f6cd7283b4e3b1831978883b9e99b06,openstack/devstack,master,I6193a5d78f6cd7283b4e3b1831978883b9e99b06,Fix marconi's storage setting for MongoDB,MERGED,2014-03-05 17:50:00.000000000,2014-03-06 21:03:24.000000000,2014-03-06 21:03:24.000000000,"[{'_account_id': 3}, {'_account_id': 866}, {'_account_id': 970}, {'_account_id': 2750}, {'_account_id': 6159}]","[{'number': 1, 'created': '2014-03-05 17:50:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack/commit/805bc60fdac6358abd1804c7bafcff0190ce9c3d', 'message': ""Fix marconi's storage setting for MongoDB\n\nThe storage driver should be set to mongodb and the driver's uri to the\nmongodb:// uri.\n\nChange-Id: I6193a5d78f6cd7283b4e3b1831978883b9e99b06\n""}, {'number': 2, 'created': '2014-03-05 20:15:07.000000000', 'files': ['lib/marconi'], 'web_link': 'https://opendev.org/openstack/devstack/commit/961328fc4622b16135d6d580429dc3e5db01ded5', 'message': ""Fix marconi's storage setting for MongoDB\n\nThe storage driver should be set to mongodb and the driver's uri to the\nmongodb:// uri.\n\nChange-Id: I6193a5d78f6cd7283b4e3b1831978883b9e99b06\n""}]",1,78327,961328fc4622b16135d6d580429dc3e5db01ded5,18,5,2,6159,,,0,"Fix marconi's storage setting for MongoDB

The storage driver should be set to mongodb and the driver's uri to the
mongodb:// uri.

Change-Id: I6193a5d78f6cd7283b4e3b1831978883b9e99b06
",git fetch https://review.opendev.org/openstack/devstack refs/changes/27/78327/2 && git format-patch -1 --stdout FETCH_HEAD,['lib/marconi'],1,805bc60fdac6358abd1804c7bafcff0190ce9c3d,, iniset $MARCONI_CONF drivers storage mongodb iniset $MARCONI_CONF 'drivers:storage:mongodb' uri mongodb://localhost:27017/marconi, iniset $MARCONI_CONF database connection mongodb://localhost:27017/marconi,2,1
openstack%2Fdevstack~master~Iaa2c822cad581d6b2b4f22f8863daf81e25f8485,openstack/devstack,master,Iaa2c822cad581d6b2b4f22f8863daf81e25f8485,Move heat keystone setup into lib/heat,MERGED,2014-03-03 18:19:01.000000000,2014-03-06 20:54:20.000000000,2014-03-06 20:54:19.000000000,"[{'_account_id': 3}, {'_account_id': 866}, {'_account_id': 970}, {'_account_id': 2750}, {'_account_id': 4328}, {'_account_id': 4571}]","[{'number': 1, 'created': '2014-03-03 18:19:01.000000000', 'files': ['lib/heat', 'files/keystone_data.sh', 'stack.sh'], 'web_link': 'https://opendev.org/openstack/devstack/commit/57d478d87438912e1a33d4a2d00d4a300148e2fc', 'message': 'Move heat keystone setup into lib/heat\n\nMove the heat setup which currently happens in files/keystone_data.sh\nto lib/heat, where we have create_heat_accounts.\n\nMove the user, role, service and endpoint creation as that is consistent\nwith what other services, e.g lib/nova are doing.\n\nChange-Id: Iaa2c822cad581d6b2b4f22f8863daf81e25f8485\n'}]",0,77662,57d478d87438912e1a33d4a2d00d4a300148e2fc,16,6,1,4328,,,0,"Move heat keystone setup into lib/heat

Move the heat setup which currently happens in files/keystone_data.sh
to lib/heat, where we have create_heat_accounts.

Move the user, role, service and endpoint creation as that is consistent
with what other services, e.g lib/nova are doing.

Change-Id: Iaa2c822cad581d6b2b4f22f8863daf81e25f8485
",git fetch https://review.opendev.org/openstack/devstack refs/changes/62/77662/1 && git format-patch -1 --stdout FETCH_HEAD,"['lib/heat', 'files/keystone_data.sh', 'stack.sh']",3,57d478d87438912e1a33d4a2d00d4a300148e2fc,, DEVSTACK_DIR=$TOP_DIR ENABLED_SERVICES=$ENABLED_SERVICES \, DEVSTACK_DIR=$TOP_DIR ENABLED_SERVICES=$ENABLED_SERVICES HEAT_API_CFN_PORT=$HEAT_API_CFN_PORT \ HEAT_API_PORT=$HEAT_API_PORT \,43,38
openstack%2Fheat~milestone-proposed~Ia029d585dfdb2563609725589c41083819a11a3b,openstack/heat,milestone-proposed,Ia029d585dfdb2563609725589c41083819a11a3b,heat_keystoneclient add legacy fallback path,MERGED,2014-03-06 16:55:06.000000000,2014-03-06 20:54:11.000000000,2014-03-06 20:54:10.000000000,"[{'_account_id': 3}, {'_account_id': 308}]","[{'number': 1, 'created': '2014-03-06 16:55:06.000000000', 'files': ['heat/common/heat_keystoneclient.py', 'heat/tests/test_heatclient.py'], 'web_link': 'https://opendev.org/openstack/heat/commit/7953ce1fecd51b26d213c0d80a3d1bce1295c14e', 'message': ""heat_keystoneclient add legacy fallback path\n\nIf users fail to observe the reccomendations in the commit messages\nand/or release notes and use a heat.conf from a previous version of\nheat currently some functionality will fail due to the missing\ndomain configuration in heat.conf.  Instead degrade gracefully with\nwarnings, calling the non-domain functions which are maintained\n(for now) for backwards compatibility.\n\nHopefully we won't have to maintain this huge pile of legacy stuff\nfor too long :(\n\nChange-Id: Ia029d585dfdb2563609725589c41083819a11a3b\nCloses-Bug: #1287980\n""}]",0,78670,7953ce1fecd51b26d213c0d80a3d1bce1295c14e,6,2,1,4328,,,0,"heat_keystoneclient add legacy fallback path

If users fail to observe the reccomendations in the commit messages
and/or release notes and use a heat.conf from a previous version of
heat currently some functionality will fail due to the missing
domain configuration in heat.conf.  Instead degrade gracefully with
warnings, calling the non-domain functions which are maintained
(for now) for backwards compatibility.

Hopefully we won't have to maintain this huge pile of legacy stuff
for too long :(

Change-Id: Ia029d585dfdb2563609725589c41083819a11a3b
Closes-Bug: #1287980
",git fetch https://review.opendev.org/openstack/heat refs/changes/70/78670/1 && git format-patch -1 --stdout FETCH_HEAD,"['heat/common/heat_keystoneclient.py', 'heat/tests/test_heatclient.py']",2,7953ce1fecd51b26d213c0d80a3d1bce1295c14e,bug/1287980_i3," def test_create_stack_domain_user_legacy_fallback(self): """"""Test creating a stack domain user, fallback path."""""" cfg.CONF.clear_override('stack_user_domain') ctx = utils.dummy_context() ctx.trust_id = None # mock keystone client functions self._stubs_v3() self.mock_ks_v3_client.users = self.m.CreateMockAnything() mock_user = self.m.CreateMockAnything() mock_user.id = 'auser123' self.mock_ks_v3_client.users.create(name='auser', password='password', default_project=ctx.tenant_id ).AndReturn(mock_user) self.mock_ks_v3_client.roles = self.m.CreateMockAnything() self.mock_ks_v3_client.roles.list().AndReturn(self._mock_roles_list()) self.mock_ks_v3_client.roles.grant(project=ctx.tenant_id, role='4546', user='auser123').AndReturn(None) self.m.ReplayAll() heat_ks_client = heat_keystoneclient.KeystoneClient(ctx) heat_ks_client.create_stack_domain_user(username='auser', project_id='aproject', password='password') def test_delete_stack_domain_user_legacy_fallback(self): """"""Test deleting a stack domain user, fallback path."""""" cfg.CONF.clear_override('stack_user_domain') ctx = utils.dummy_context() ctx.trust_id = None # mock keystone client functions self._stubs_v3() self.mock_ks_v3_client.users = self.m.CreateMockAnything() self.mock_ks_v3_client.users.delete(user='user123').AndReturn(None) self.m.ReplayAll() heat_ks_client = heat_keystoneclient.KeystoneClient(ctx) heat_ks_client.delete_stack_domain_user(user_id='user123', project_id='aproject') def test_init_domain_cfg_not_set_fallback(self): """"""Test error path when config lacks domain config."""""" cfg.CONF.clear_override('stack_domain_admin') cfg.CONF.clear_override('stack_domain_admin_password') ctx = utils.dummy_context() ctx.username = None ctx.password = None ctx.trust_id = None self.assertIsNotNone(heat_keystoneclient.KeystoneClient(ctx)) def test_init_domain_cfg_not_set_error(self): """"""Test error path when config lacks domain config."""""" cfg.CONF.clear_override('stack_domain_admin') cfg.CONF.clear_override('stack_domain_admin_password') exp_msg = ('heat.conf misconfigured, cannot specify stack_user_domain ' 'without stack_domain_admin and ' 'stack_domain_admin_password') self.assertIn(exp_msg, err) def test_enable_stack_domain_user_legacy_fallback(self): """"""Test enabling a stack domain user, fallback path."""""" cfg.CONF.clear_override('stack_user_domain') ctx = utils.dummy_context() ctx.trust_id = None # mock keystone client functions self._stubs_v3() self.mock_ks_v3_client.users = self.m.CreateMockAnything() self.mock_ks_v3_client.users.update(user='user123', enabled=True ).AndReturn(None) self.m.ReplayAll() heat_ks_client = heat_keystoneclient.KeystoneClient(ctx) heat_ks_client.enable_stack_domain_user(user_id='user123', project_id='aproject') def test_disable_stack_domain_user_legacy_fallback(self): """"""Test enabling a stack domain user, fallback path."""""" cfg.CONF.clear_override('stack_user_domain') ctx = utils.dummy_context() ctx.trust_id = None # mock keystone client functions self._stubs_v3() self.mock_ks_v3_client.users = self.m.CreateMockAnything() self.mock_ks_v3_client.users.update(user='user123', enabled=False ).AndReturn(None) self.m.ReplayAll() heat_ks_client = heat_keystoneclient.KeystoneClient(ctx) heat_ks_client.disable_stack_domain_user(user_id='user123', project_id='aproject') def test_create_stack_domain_user_keypair_legacy_fallback(self): """"""Test creating ec2 credentials for domain user, fallback path."""""" cfg.CONF.clear_override('stack_user_domain') self._stubs_v3() ctx = utils.dummy_context() ctx.trust_id = None ex_data = {'access': 'dummy_access2', 'secret': 'dummy_secret2'} ex_data_json = json.dumps(ex_data) # stub UUID.hex to match ex_data self._stub_uuid(['dummy_access2', 'dummy_secret2']) # mock keystone client credentials functions self.mock_ks_v3_client.credentials = self.m.CreateMockAnything() mock_credential = self.m.CreateMockAnything() mock_credential.id = '1234567' mock_credential.user_id = 'atestuser2' mock_credential.blob = ex_data_json mock_credential.type = 'ec2' # mock keystone client create function self.mock_ks_v3_client.credentials.create( user='atestuser2', type='ec2', data=ex_data_json, project=ctx.tenant_id).AndReturn(mock_credential) self.m.ReplayAll() heat_ks_client = heat_keystoneclient.KeystoneClient(ctx) ec2_cred = heat_ks_client.create_stack_domain_user_keypair( user_id='atestuser2', project_id='aproject') self.assertEqual('1234567', ec2_cred.id) self.assertEqual('dummy_access2', ec2_cred.access) self.assertEqual('dummy_secret2', ec2_cred.secret) def test_create_stack_domain_project_legacy_fallback(self): """"""Test the create_stack_domain_project function, fallback path."""""" cfg.CONF.clear_override('stack_user_domain') ctx = utils.dummy_context() ctx.trust_id = None heat_ks_client = heat_keystoneclient.KeystoneClient(ctx) self.assertEqual(ctx.tenant_id, heat_ks_client.create_stack_domain_project( stack_name='astack')) def test_delete_stack_domain_project_legacy_fallback(self): """"""Test the delete_stack_domain_project function, fallback path."""""" cfg.CONF.clear_override('stack_user_domain') ctx = utils.dummy_context() ctx.trust_id = None heat_ks_client = heat_keystoneclient.KeystoneClient(ctx) self.assertIsNone(heat_ks_client.delete_stack_domain_project( project_id='aprojectid')) "," def test_init_domain_cfg_not_set(self): """"""Test error path when config lacks stack domain ID."""""" self.assertIn('stack_user_domain ID not set in heat.conf', err)",223,15
openstack%2Fironic~master~I3351dee1a4b2dfb50317ce85dffe8012f0feca6c,openstack/ironic,master,I3351dee1a4b2dfb50317ce85dffe8012f0feca6c,"Import Nova ""ironic"" driver",MERGED,2014-03-04 21:22:03.000000000,2014-03-06 20:51:27.000000000,2014-03-06 18:09:01.000000000,"[{'_account_id': 3}, {'_account_id': 2889}, {'_account_id': 5805}, {'_account_id': 6773}]","[{'number': 1, 'created': '2014-03-04 21:22:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/94cb9b9a67cb0bd5d3dd61f3f56e2359e94491e6', 'message': 'Add Ironic Nova driver\n\nAdds Nova Ironic driver and Ironic Host Manager.\n\nChange-Id: I3351dee1a4b2dfb50317ce85dffe8012f0feca6c\n'}, {'number': 2, 'created': '2014-03-04 21:28:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/415ab2066755b37ad06345ab1abfc6bba648f4e2', 'message': 'Add Ironic Nova driver\n\nAdds Nova Ironic driver and Ironic Host Manager.\n\nCo-Author: Lucas Alvares Gomes <lucasagomes@gmail.com>\nCo-Author: Devananda van der Veen <devananda.vdv@gmail.com>\n\nChange-Id: I3351dee1a4b2dfb50317ce85dffe8012f0feca6c\n'}, {'number': 3, 'created': '2014-03-05 15:01:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/a52a3c29d8e195bc35eeb411e97617d7ede46ae4', 'message': 'Import Nova ""ironic"" driver\n\nImport the Nova ""ironic"" driver from the Nova review queue.\nThis Nova driver will not be present in the Icehouse release of Nova,\nbut is required for Ironic functionality and can be installed as an\nout-of-tree driver.\n\nCo-Author: Lucas Alvares Gomes <lucasagomes@gmail.com>\nCo-Author: Devananda van der Veen <devananda.vdv@gmail.com>\n\nChange-Id: I3351dee1a4b2dfb50317ce85dffe8012f0feca6c\n'}, {'number': 4, 'created': '2014-03-05 21:20:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/52e0a47636a82ca092a427c1f68cba418b720348', 'message': 'Import Nova ""ironic"" driver\n\nImport the Nova ""ironic"" driver from the Nova review queue.\nThis Nova driver will not be present in the Icehouse release of Nova,\nbut is required for Ironic functionality and can be installed as an\nout-of-tree driver.\n\nCo-Author: Lucas Alvares Gomes <lucasagomes@gmail.com>\nCo-Author: Devananda van der Veen <devananda.vdv@gmail.com>\n\nChange-Id: I3351dee1a4b2dfb50317ce85dffe8012f0feca6c\n'}, {'number': 5, 'created': '2014-03-06 00:30:23.000000000', 'files': ['ironic/nova/scheduler/ironic_host_manager.py', 'ironic/nova/tests/virt/ironic/__init__.py', 'ironic/nova/tests/scheduler/test_ironic_host_manager.py', 'tools/config/generate_sample.sh', 'ironic/nova/virt/__init__.py', 'ironic/nova/scheduler/__init__.py', 'ironic/nova/tests/virt/ironic/test_driver.py', 'ironic/nova/virt/ironic/ironic_states.py', 'ironic/nova/__init__.py', 'ironic/nova/virt/ironic/ironic_driver_fields.py', 'ironic/nova/virt/ironic/driver.py', 'ironic/nova/tests/scheduler/ironic_fakes.py', 'ironic/nova/virt/ironic/__init__.py'], 'web_link': 'https://opendev.org/openstack/ironic/commit/f616e239c778fb122fdab38b81a3868ccc120338', 'message': 'Import Nova ""ironic"" driver\n\nImport the Nova ""ironic"" driver from the Nova review queue.\nThis Nova driver will not be present in the Icehouse release of Nova,\nbut is required for Ironic functionality and can be installed as an\nout-of-tree driver.\n\nCo-Author: Lucas Alvares Gomes <lucasagomes@gmail.com>\nCo-Author: Devananda van der Veen <devananda.vdv@gmail.com>\n\nChange-Id: I3351dee1a4b2dfb50317ce85dffe8012f0feca6c\n'}]",5,78002,f616e239c778fb122fdab38b81a3868ccc120338,21,4,5,5805,,,0,"Import Nova ""ironic"" driver

Import the Nova ""ironic"" driver from the Nova review queue.
This Nova driver will not be present in the Icehouse release of Nova,
but is required for Ironic functionality and can be installed as an
out-of-tree driver.

Co-Author: Lucas Alvares Gomes <lucasagomes@gmail.com>
Co-Author: Devananda van der Veen <devananda.vdv@gmail.com>

Change-Id: I3351dee1a4b2dfb50317ce85dffe8012f0feca6c
",git fetch https://review.opendev.org/openstack/ironic refs/changes/02/78002/5 && git format-patch -1 --stdout FETCH_HEAD,"['ironic/nova/scheduler/ironic_host_manager.py', 'ironic/nova/tests/virt/ironic/__init__.py', 'ironic/nova/virt/ironic/ironic_driver_fields.py', 'ironic/nova/tests/scheduler/test_ironic_host_manager.py', 'ironic/nova/virt/ironic/driver.py', 'ironic/nova/tests/scheduler/ironic_fakes.py', 'ironic/nova/tests/virt/ironic/test_driver.py', 'ironic/nova/virt/ironic/__init__.py', 'ironic/nova/virt/ironic/ironic_states.py']",9,94cb9b9a67cb0bd5d3dd61f3f56e2359e94491e6,78002,"# coding=utf-8 # # Copyright (c) 2012 NTT DOCOMO, INC. # Copyright 2010 OpenStack Foundation # All Rights Reserved. # # Licensed under the Apache License, Version 2.0 (the ""License""); you may # not use this file except in compliance with the License. You may obtain # a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT # WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the # License for the specific language governing permissions and limitations # under the License. """""" Mapping of bare metal node states. A node may have empty {} `properties` and `driver_info` in which case, it is said to be ""initialized"" but ""not available"", and the state is NOSTATE. When updating `properties`, any data will be rejected if the data fails to be validated by the driver. Any node with non-empty `properties` is said to be ""initialized"", and the state is INIT. When the driver has received both `properties` and `driver_info`, it will check the power status of the node and update the `power_state` accordingly. If the driver fails to read the power state from the node, it will reject the `driver_info` change, and the state will remain as INIT. If the power status check succeeds, `power_state` will change to one of POWER_ON or POWER_OFF, accordingly. At this point, the power state may be changed via the API, a console may be started, and a tenant may be associated. The `power_state` for a node always represents the current power state. Any power operation sets this to the actual state when done (whether successful or not). It is set to ERROR only when unable to get the power state from a node. When `instance_uuid` is set to a non-empty / non-None value, the node is said to be ""associated"" with a tenant. An associated node can not be deleted. The `instance_uuid` field may be unset only if the node is in POWER_OFF or ERROR states. """""" NOSTATE = None INIT = 'initializing' ACTIVE = 'active' BUILDING = 'building' DEPLOYING = 'deploying' DEPLOYFAIL = 'deploy failed' DEPLOYDONE = 'deploy complete' DELETING = 'deleting' DELETED = 'deleted' ERROR = 'error' POWER_ON = 'power on' POWER_OFF = 'power off' REBOOT = 'rebooting' SUSPEND = 'suspended' ",,2176,0
openstack%2Fironic~master~I14c3b823a8b975d5cd097778f3514cfb1abe2e10,openstack/ironic,master,I14c3b823a8b975d5cd097778f3514cfb1abe2e10,Sync common db code from Oslo,MERGED,2014-02-25 13:52:10.000000000,2014-03-06 20:31:41.000000000,2014-03-06 20:31:40.000000000,"[{'_account_id': 3}, {'_account_id': 1849}, {'_account_id': 2889}, {'_account_id': 6623}, {'_account_id': 6773}, {'_account_id': 6849}, {'_account_id': 7491}, {'_account_id': 8106}, {'_account_id': 8968}]","[{'number': 1, 'created': '2014-02-25 13:52:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/1267ef4a55afbb305bd08e254151e325ed23ad1d', 'message': 'WIP: sync oslo.db code\n\nChange-Id: I14c3b823a8b975d5cd097778f3514cfb1abe2e10\n'}, {'number': 2, 'created': '2014-02-26 11:53:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/fb4cfbd4492b6c6f5b8a89cc9505a58561bf5f11', 'message': 'WIP: sync oslo.db code\n\nChange-Id: I14c3b823a8b975d5cd097778f3514cfb1abe2e10\n'}, {'number': 3, 'created': '2014-02-26 12:49:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/86a446ed1238e7b88bf2cbed33820f48393bc5a9', 'message': ""Sync common db code from Oslo\n\nThis sync contain commit - ce69e7f Don't store engine instances in oslo.db\n\nSo, to keep Ironic in working state, we should add code that will work\nwith sqla engines and sessions.\n\nAlso this remove database slave connection and database tpool features.\n\nLatest oslo.db commit - dda24eb4a815914c29e801ad0176630786db8734\n\nChange-Id: I14c3b823a8b975d5cd097778f3514cfb1abe2e10\n""}, {'number': 4, 'created': '2014-02-26 13:33:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/1fbb092c6f254608b053f9b097e354e696ded037', 'message': ""Sync common db code from Oslo\n\nThis sync contain commit - ce69e7f Don't store engine instances in oslo.db -\nwhich removed global engine from oslo.db code. So, we should move code\nfor work with sqla engines and sessions to Ironic - added get_engine()\nand get_session() functions to ironic.db.sqlalchemy.api module.\n\nAlso this remove database slave connection and database tpool features.\n\nLatest oslo.db commit - dda24eb4a815914c29e801ad0176630786db8734\n\nChange-Id: I14c3b823a8b975d5cd097778f3514cfb1abe2e10\n""}, {'number': 5, 'created': '2014-02-26 19:06:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/c02fdaa878aba367ec7818c727ed91dd03bab283', 'message': ""Sync common db code from Oslo\n\nThis sync contains commit - ce69e7f Don't store engine instances in oslo.db -\nwhich removed global engine from oslo.db code. So, added code\nfor work with sqla engines and sessions to Ironic - get_engine()\nand get_session() functions in ironic.db.sqlalchemy.api module.\n\nAlso this remove database slave connection and tpool features, because\nthey was removed from oslo code.\n\nLatest oslo.db commit - 7959826af1f36a4bbc4c466d0d1e0b9efd468649\n\nChange-Id: I14c3b823a8b975d5cd097778f3514cfb1abe2e10\n""}, {'number': 6, 'created': '2014-02-26 19:14:18.000000000', 'files': ['ironic/openstack/common/db/sqlalchemy/migration_cli/ext_alembic.py', 'ironic/db/migration.py', 'ironic/openstack/common/db/options.py', 'ironic/openstack/common/db/sqlalchemy/utils.py', 'ironic/common/config.py', 'ironic/openstack/common/db/sqlalchemy/migration_cli/ext_migrate.py', 'etc/ironic/ironic.conf.sample', 'ironic/db/sqlalchemy/api.py', 'ironic/openstack/common/db/sqlalchemy/test_base.py', 'ironic/openstack/common/db/sqlalchemy/test_migrations.py', 'ironic/openstack/common/db/sqlalchemy/migration.py', 'ironic/openstack/common/db/sqlalchemy/models.py', 'ironic/db/sqlalchemy/alembic/env.py', 'ironic/openstack/common/db/exception.py', 'ironic/openstack/common/__init__.py', 'ironic/openstack/common/db/api.py', 'ironic/db/sqlalchemy/migration.py', 'ironic/tests/db/sqlalchemy/test_migrations.py', 'ironic/openstack/common/context.py', 'ironic/tests/conf_fixture.py', 'ironic/tests/base.py', 'ironic/openstack/common/db/sqlalchemy/session.py', 'ironic/db/sqlalchemy/models.py', 'ironic/db/api.py'], 'web_link': 'https://opendev.org/openstack/ironic/commit/9bbea3bf0040eb1138f9e8a8e719039f79c647de', 'message': ""Sync common db code from Oslo\n\nThis sync contains commit - ce69e7f Don't store engine instances in oslo.db -\nwhich removed global engine from oslo.db code. So, added code\nfor work with sqla engines and sessions to Ironic - get_engine()\nand get_session() functions in ironic.db.sqlalchemy.api module.\n\nAlso this remove database slave connection and tpool features, because\nthey was removed from oslo code.\n\nLatest oslo.db commit - 7959826af1f36a4bbc4c466d0d1e0b9efd468649\n\nChange-Id: I14c3b823a8b975d5cd097778f3514cfb1abe2e10\n""}]",7,76204,9bbea3bf0040eb1138f9e8a8e719039f79c647de,34,9,6,7491,,,0,"Sync common db code from Oslo

This sync contains commit - ce69e7f Don't store engine instances in oslo.db -
which removed global engine from oslo.db code. So, added code
for work with sqla engines and sessions to Ironic - get_engine()
and get_session() functions in ironic.db.sqlalchemy.api module.

Also this remove database slave connection and tpool features, because
they was removed from oslo code.

Latest oslo.db commit - 7959826af1f36a4bbc4c466d0d1e0b9efd468649

Change-Id: I14c3b823a8b975d5cd097778f3514cfb1abe2e10
",git fetch https://review.opendev.org/openstack/ironic refs/changes/04/76204/4 && git format-patch -1 --stdout FETCH_HEAD,"['ironic/openstack/common/db/sqlalchemy/migration_cli/ext_alembic.py', 'ironic/db/sqlalchemy/alembic/env.py', 'ironic/db/migration.py', 'ironic/openstack/common/db/options.py', 'ironic/openstack/common/db/sqlalchemy/utils.py', 'ironic/openstack/common/db/exception.py', 'ironic/openstack/common/__init__.py', 'ironic/openstack/common/db/api.py', 'ironic/common/config.py', 'ironic/db/sqlalchemy/migration.py', 'ironic/tests/db/sqlalchemy/test_migrations.py', 'ironic/openstack/common/context.py', 'ironic/openstack/common/db/sqlalchemy/migration_cli/ext_migrate.py', 'etc/ironic/ironic.conf.sample', 'ironic/db/sqlalchemy/api.py', 'ironic/openstack/common/db/sqlalchemy/test_base.py', 'ironic/tests/base.py', 'ironic/openstack/common/db/sqlalchemy/test_migrations.py', 'ironic/openstack/common/db/sqlalchemy/migration.py', 'ironic/openstack/common/db/sqlalchemy/models.py', 'ironic/openstack/common/db/sqlalchemy/session.py', 'ironic/db/sqlalchemy/models.py', 'ironic/db/api.py']",23,1267ef4a55afbb305bd08e254151e325ed23ad1d,use-oslo-db,"from oslo.config import cfgCONF = cfg.CONF CONF.import_opt('backend', 'ironic.openstack.common.db.options', group='database') IMPL = db_api.DBAPI(CONF.database.backend, backend_mapping=_BACKEND_MAPPING, lazy=True)",IMPL = db_api.DBAPI(backend_mapping=_BACKEND_MAPPING),1060,531
openstack%2Fbarbican~master~I989f042791b1817b10200c3a575f77ce5a5120a7,openstack/barbican,master,I989f042791b1817b10200c3a575f77ce5a5120a7,Adding v1 to the service catalog endpoints,ABANDONED,2014-03-06 19:55:45.000000000,2014-03-06 20:14:04.000000000,,"[{'_account_id': 3}, {'_account_id': 4}, {'_account_id': 7973}]","[{'number': 1, 'created': '2014-03-06 19:55:45.000000000', 'files': ['contrib/devstack/lib/barbican'], 'web_link': 'https://opendev.org/openstack/barbican/commit/3172b7972d092a8bb85e811f17e8b0c4a2fccd68', 'message': 'Adding v1 to the service catalog endpoints\n\nChange-Id: I989f042791b1817b10200c3a575f77ce5a5120a7\n'}]",0,78738,3172b7972d092a8bb85e811f17e8b0c4a2fccd68,4,3,1,7136,,,0,"Adding v1 to the service catalog endpoints

Change-Id: I989f042791b1817b10200c3a575f77ce5a5120a7
",git fetch https://review.opendev.org/openstack/barbican refs/changes/38/78738/1 && git format-patch -1 --stdout FETCH_HEAD,['contrib/devstack/lib/barbican'],1,3172b7972d092a8bb85e811f17e8b0c4a2fccd68,Add-v1-to-catalog," --publicurl ""http://$SERVICE_HOST:9311/v1"" \ --adminurl ""http://$SERVICE_HOST:9312/v1"" \ --internalurl ""http://$SERVICE_HOST:9311/v1"""," --publicurl ""http://$SERVICE_HOST:9311"" \ --adminurl ""http://$SERVICE_HOST:9312"" \ --internalurl ""http://$SERVICE_HOST:9311""",3,3
openstack%2Fcinder~master~I3a03e44aa0984e9b571f4a945c717e07548d0aa2,openstack/cinder,master,I3a03e44aa0984e9b571f4a945c717e07548d0aa2,Fixed nova VM live migration issue with 3PAR,ABANDONED,2014-03-06 19:21:55.000000000,2014-03-06 19:45:37.000000000,,"[{'_account_id': 3}, {'_account_id': 5997}, {'_account_id': 6043}]","[{'number': 1, 'created': '2014-03-06 19:21:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/a5800d3a10d08c74c98c916b76f18089a1b35bad', 'message': 'Fixed nova VM live migration issue\n\nNova bypasses the cinder checks for a volume\nbeing available, when it tries to attach a volume\nto a new host during live migration.  The assumption\nin cinder to this point has been that volumes can only\nbe attached to one host.  The 3PAR driver worked under\nthat assumption.  This assumption fell apart during detach\ntime as the driver was only looking for a VLUN on the\nentire 3PAR, since it assumed it could only exist on one host.\n\nThis patch ensures that the driver looks for the VLUN on the\nhostname it expects.\n\nChange-Id: I3a03e44aa0984e9b571f4a945c717e07548d0aa2\nCloses-Bug: 1288927\n'}, {'number': 2, 'created': '2014-03-06 19:22:28.000000000', 'files': ['cinder/tests/test_hp3par.py', 'cinder/volume/drivers/san/hp/hp_3par_common.py'], 'web_link': 'https://opendev.org/openstack/cinder/commit/07700301dcb90f2adf54acb314241b52c63d0852', 'message': 'Fixed nova VM live migration issue with 3PAR\n\nNova bypasses the cinder checks for a volume\nbeing available, when it tries to attach a volume\nto a new host during live migration.  The assumption\nin cinder to this point has been that volumes can only\nbe attached to one host.  The 3PAR driver worked under\nthat assumption.  This assumption fell apart during detach\ntime as the driver was only looking for a VLUN on the\nentire 3PAR, since it assumed it could only exist on one host.\n\nThis patch ensures that the driver looks for the VLUN on the\nhostname it expects.\n\nChange-Id: I3a03e44aa0984e9b571f4a945c717e07548d0aa2\nCloses-Bug: 1288927\n'}]",0,78722,07700301dcb90f2adf54acb314241b52c63d0852,6,3,2,5997,,,0,"Fixed nova VM live migration issue with 3PAR

Nova bypasses the cinder checks for a volume
being available, when it tries to attach a volume
to a new host during live migration.  The assumption
in cinder to this point has been that volumes can only
be attached to one host.  The 3PAR driver worked under
that assumption.  This assumption fell apart during detach
time as the driver was only looking for a VLUN on the
entire 3PAR, since it assumed it could only exist on one host.

This patch ensures that the driver looks for the VLUN on the
hostname it expects.

Change-Id: I3a03e44aa0984e9b571f4a945c717e07548d0aa2
Closes-Bug: 1288927
",git fetch https://review.opendev.org/openstack/cinder refs/changes/22/78722/2 && git format-patch -1 --stdout FETCH_HEAD,"['cinder/tests/test_hp3par.py', 'cinder/volume/drivers/san/hp/hp_3par_common.py']",2,a5800d3a10d08c74c98c916b76f18089a1b35bad,bug/1288927," vluns = self.client.getHostVLUNs(hostname) vlun = None for vlun in vluns: if vlun['active'] and volume_name in vlun['volumeName']: break if vlun is None: msg = (_(""3PAR Vlun %(name)s not found on host %(host)s"") % {'name': volume_name, 'host': hostname}) raise exception.NotFound(message=msg) ", vlun = self.client.getVLUN(volume_name),21,5
openstack%2Fsolum~master~I7a2d337315bef8a07f82b1f54c5aa7d50992047b,openstack/solum,master,I7a2d337315bef8a07f82b1f54c5aa7d50992047b,Improve readability of for loop,ABANDONED,2014-03-03 19:22:04.000000000,2014-03-06 19:37:36.000000000,,"[{'_account_id': 3}, {'_account_id': 668}, {'_account_id': 2506}, {'_account_id': 4715}, {'_account_id': 8334}, {'_account_id': 9095}]","[{'number': 1, 'created': '2014-03-03 19:22:04.000000000', 'files': ['solum/api/controllers/v1/language_pack.py'], 'web_link': 'https://opendev.org/openstack/solum/commit/46a54e4419740ce9ec0489feb4d5d333702a0ff9', 'message': 'Improve readability of for loop\n\nChange-Id: I7a2d337315bef8a07f82b1f54c5aa7d50992047b\nCloses-Bug: #1285552\n'}]",0,77676,46a54e4419740ce9ec0489feb4d5d333702a0ff9,10,6,1,9113,,,0,"Improve readability of for loop

Change-Id: I7a2d337315bef8a07f82b1f54c5aa7d50992047b
Closes-Bug: #1285552
",git fetch https://review.opendev.org/openstack/solum refs/changes/76/77676/1 && git format-patch -1 --stdout FETCH_HEAD,['solum/api/controllers/v1/language_pack.py'],1,46a54e4419740ce9ec0489feb4d5d333702a0ff9,, pecan.request.host_url) for langpack in self._handler.get_all()], pecan.request.host_url) for langpack in self._handler.get_all()],2,2
openstack%2Ffuel-docs~master~I9c621cc5677bab8a80cf2b86aec8054bae22204e,openstack/fuel-docs,master,I9c621cc5677bab8a80cf2b86aec8054bae22204e,Add note about placing Ceph OSD on controllers,MERGED,2014-03-06 17:27:17.000000000,2014-03-06 19:27:40.000000000,2014-03-06 19:27:40.000000000,"[{'_account_id': 3}, {'_account_id': 8787}, {'_account_id': 8797}, {'_account_id': 8971}]","[{'number': 1, 'created': '2014-03-06 17:27:17.000000000', 'files': ['pages/release-notes/v4-1/050-known-issues.rst'], 'web_link': 'https://opendev.org/openstack/fuel-docs/commit/a2930e066787f31e012872e5c5529aee9c50fcb4', 'message': 'Add note about placing Ceph OSD on controllers\n\nChange-Id: I9c621cc5677bab8a80cf2b86aec8054bae22204e\n'}]",0,78676,a2930e066787f31e012872e5c5529aee9c50fcb4,9,4,1,9037,,,0,"Add note about placing Ceph OSD on controllers

Change-Id: I9c621cc5677bab8a80cf2b86aec8054bae22204e
",git fetch https://review.opendev.org/openstack/fuel-docs refs/changes/76/78676/1 && git format-patch -1 --stdout FETCH_HEAD,['pages/release-notes/v4-1/050-known-issues.rst'],1,a2930e066787f31e012872e5c5529aee9c50fcb4,ceph-i,Placing Ceph OSD on Controller nodes is not recommended ------------------------------------------------------- Placing Ceph OSD on Controllers is highly unadvisable because it can severely degrade controller's performance. It's better to use separate storage nodes if you have enough hardware. ,,7,0
openstack%2Fpuppet-ceilometer~stable%2Fhavana~I8d396131386e5469eb6d7d43d7c6a7354abed31a,openstack/puppet-ceilometer,stable/havana,I8d396131386e5469eb6d7d43d7c6a7354abed31a,fix alarm_package_name for Debian/Ubuntu (only havana),MERGED,2014-02-28 14:30:32.000000000,2014-03-06 19:17:14.000000000,2014-03-06 19:17:14.000000000,"[{'_account_id': 3}, {'_account_id': 6967}, {'_account_id': 7822}, {'_account_id': 7888}]","[{'number': 1, 'created': '2014-02-28 14:30:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-ceilometer/commit/731433ee6c4f185d7597d6a0b02315efbbb1c3e1', 'message': 'fix alarm_package_name for Debian/Ubuntu (only havana)\n\n  - Debian uses separate packages in havana\n  - Ubuntu uses ceilometer-common which conflicts with init.pp\n  - Change-Id: I91098bd3f13ee4391dcf1b870705c0a0c5566acc\n    introduced this troubles.\n\nChange-Id: I8d396131386e5469eb6d7d43d7c6a7354abed31a\n'}, {'number': 2, 'created': '2014-02-28 14:46:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-ceilometer/commit/dc74233acee07c64169255eca5f4233565a910f5', 'message': 'fix alarm_package_name for Debian/Ubuntu (only havana)\n\n  - Debian uses separate packages in havana\n  - Ubuntu uses ceilometer-common which conflicts with init.pp\n  - Change-Id: I91098bd3f13ee4391dcf1b870705c0a0c5566acc\n    introduced this troubles.\n\nChange-Id: I8d396131386e5469eb6d7d43d7c6a7354abed31a\n'}, {'number': 3, 'created': '2014-02-28 15:14:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-ceilometer/commit/eb39be96b4a81197d212155ceb74fbf41f864cdb', 'message': 'fix alarm_package_name for Debian/Ubuntu (only havana)\n\n  - Debian uses separate packages in havana\n  - Ubuntu uses ceilometer-common which conflicts with init.pp\n  - Change-Id: I91098bd3f13ee4391dcf1b870705c0a0c5566acc\n    introduced this troubles.\n\nChange-Id: I8d396131386e5469eb6d7d43d7c6a7354abed31a\n'}, {'number': 4, 'created': '2014-02-28 15:44:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-ceilometer/commit/4434ccca354781010ca7ed236151f3a5b813ab51', 'message': 'fix alarm_package_name for Debian/Ubuntu (only havana)\n\n  - Debian uses separate packages in havana\n  - Ubuntu uses ceilometer-common which conflicts with init.pp\n  - Change-Id: I91098bd3f13ee4391dcf1b870705c0a0c5566acc\n    introduced this troubles.\n\nChange-Id: I8d396131386e5469eb6d7d43d7c6a7354abed31a\n'}, {'number': 5, 'created': '2014-02-28 16:13:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-ceilometer/commit/b86fcb2dc5792070ac1fad4f676c8864c380e7fb', 'message': 'fix alarm_package_name for Debian/Ubuntu (only havana)\n\n  - Debian uses separate packages in havana\n  - Ubuntu uses ceilometer-common which conflicts with init.pp\n  - Change-Id: I91098bd3f13ee4391dcf1b870705c0a0c5566acc\n    introduced this troubles.\n\nChange-Id: I8d396131386e5469eb6d7d43d7c6a7354abed31a\n'}, {'number': 6, 'created': '2014-03-01 10:16:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-ceilometer/commit/3392bae78252651e234368b447fab2bf3e7f2e18', 'message': 'fix alarm_package_name for Debian/Ubuntu (only havana)\n\n  - Debian uses separate packages in havana\n  - Ubuntu uses ceilometer-common which conflicts with init.pp\n  - Change-Id: I91098bd3f13ee4391dcf1b870705c0a0c5566acc\n    introduced this troubles.\n\nChange-Id: I8d396131386e5469eb6d7d43d7c6a7354abed31a\n'}, {'number': 7, 'created': '2014-03-01 10:51:37.000000000', 'files': ['spec/classes/ceilometer_alarm_notifier_spec.rb', 'manifests/alarm/evaluator.pp', 'spec/classes/ceilometer_alarm_evaluator_spec.rb', 'manifests/init.pp', 'manifests/params.pp', 'manifests/alarm/notifier.pp'], 'web_link': 'https://opendev.org/openstack/puppet-ceilometer/commit/7e4f4dc896c1277cc9f9f8fc34486fdd5a69401b', 'message': 'fix alarm_package_name for Debian/Ubuntu (only havana)\n\n  - Debian uses separate packages in havana\n  - Ubuntu uses ceilometer-common which conflicts with init.pp\n  - separate tests for Ubuntu/Debian (for alarm*)\n  - Change-Id: I91098bd3f13ee4391dcf1b870705c0a0c5566acc\n    introduced this troubles.\n\nChange-Id: I8d396131386e5469eb6d7d43d7c6a7354abed31a\n'}]",9,77183,7e4f4dc896c1277cc9f9f8fc34486fdd5a69401b,31,4,7,7888,,,0,"fix alarm_package_name for Debian/Ubuntu (only havana)

  - Debian uses separate packages in havana
  - Ubuntu uses ceilometer-common which conflicts with init.pp
  - separate tests for Ubuntu/Debian (for alarm*)
  - Change-Id: I91098bd3f13ee4391dcf1b870705c0a0c5566acc
    introduced this troubles.

Change-Id: I8d396131386e5469eb6d7d43d7c6a7354abed31a
",git fetch https://review.opendev.org/openstack/puppet-ceilometer refs/changes/83/77183/7 && git format-patch -1 --stdout FETCH_HEAD,"['manifests/alarm/evaluator.pp', 'manifests/params.pp', 'manifests/alarm/notifier.pp']",3,731433ee6c4f185d7597d6a0b02315efbbb1c3e1,package-fix," # Workaround for Ubuntu havana, where alarm_package_name = common_package_name if !( $::ceilometer::params::common_package_name in $::ceilometer::params::common_package_name ) { ensure_packages($::ceilometer::params::alarm_package_name) }", ensure_packages($::ceilometer::params::alarm_package_name),13,5
openstack%2Fneutron~master~I6d20cfd584059befd591c856ec1519450030b4b2,openstack/neutron,master,I6d20cfd584059befd591c856ec1519450030b4b2,Fix typo in migration script,MERGED,2014-03-06 00:41:32.000000000,2014-03-06 19:16:04.000000000,2014-03-06 07:04:58.000000000,"[{'_account_id': 3}, {'_account_id': 261}, {'_account_id': 490}, {'_account_id': 841}, {'_account_id': 2592}, {'_account_id': 4395}, {'_account_id': 9008}, {'_account_id': 9732}, {'_account_id': 9845}, {'_account_id': 10117}, {'_account_id': 10153}, {'_account_id': 10294}, {'_account_id': 10387}]","[{'number': 1, 'created': '2014-03-06 00:41:32.000000000', 'files': ['neutron/db/migration/alembic_migrations/versions/2eeaf963a447_floatingip_status.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/7f6a6cdfc95610cea0a6e4bb01e7de330e1f76d4', 'message': 'Fix typo in migration script\n\nRecently merged migration script for floating ip is missing\na list item separator.\n\nChange-Id: I6d20cfd584059befd591c856ec1519450030b4b2\nCloses-Bug: #1288492\n'}]",0,78479,7f6a6cdfc95610cea0a6e4bb01e7de330e1f76d4,25,13,1,490,,,0,"Fix typo in migration script

Recently merged migration script for floating ip is missing
a list item separator.

Change-Id: I6d20cfd584059befd591c856ec1519450030b4b2
Closes-Bug: #1288492
",git fetch https://review.opendev.org/openstack/neutron refs/changes/79/78479/1 && git format-patch -1 --stdout FETCH_HEAD,['neutron/db/migration/alembic_migrations/versions/2eeaf963a447_floatingip_status.py'],1,7f6a6cdfc95610cea0a6e4bb01e7de330e1f76d4,fix-typo," 'neutron.plugins.ibm.sdnve_neutron_plugin.SdnvePluginV2',", 'neutron.plugins.ibm.sdnve_neutron_plugin.SdnvePluginV2',1,1
openstack%2Fpuppet-nova~master~I58c65d9f0eaa48aee49899c8850482c08320b003,openstack/puppet-nova,master,I58c65d9f0eaa48aee49899c8850482c08320b003,Add support for latest puppetlabs-rabbitmq,MERGED,2014-02-27 15:51:49.000000000,2014-03-06 19:11:04.000000000,2014-03-06 19:11:04.000000000,"[{'_account_id': 3}, {'_account_id': 1607}, {'_account_id': 6754}, {'_account_id': 6994}, {'_account_id': 7822}, {'_account_id': 9978}]","[{'number': 1, 'created': '2014-02-27 15:51:49.000000000', 'files': ['manifests/rabbitmq.pp'], 'web_link': 'https://opendev.org/openstack/puppet-nova/commit/55d7b22d346c090fd4ee6d886cf549e52dbeca5f', 'message': ""Add support for latest puppetlabs-rabbitmq\n\nThis patch adds a new paramter to the rabbitmq class\nthat allows a user to specify the class name. This allows\nselection of 'rabbitmq::server' - the old name, or 'rabbitmq' -\nthe new name changed during the recent rewrite of the\npuppetlabs-rabbitmq module.\n\nChange-Id: I58c65d9f0eaa48aee49899c8850482c08320b003\n""}]",0,76896,55d7b22d346c090fd4ee6d886cf549e52dbeca5f,15,6,1,6994,,,0,"Add support for latest puppetlabs-rabbitmq

This patch adds a new paramter to the rabbitmq class
that allows a user to specify the class name. This allows
selection of 'rabbitmq::server' - the old name, or 'rabbitmq' -
the new name changed during the recent rewrite of the
puppetlabs-rabbitmq module.

Change-Id: I58c65d9f0eaa48aee49899c8850482c08320b003
",git fetch https://review.opendev.org/openstack/puppet-nova refs/changes/96/76896/1 && git format-patch -1 --stdout FETCH_HEAD,['manifests/rabbitmq.pp'],1,55d7b22d346c090fd4ee6d886cf549e52dbeca5f,rabbitmq,"# [*rabbitmq_class*] # (optional) The rabbitmq puppet class to depend on, # which is dependent on the puppet-rabbitmq version. # Use the default for 1.x, use 'rabbitmq' for 3.x # Defaults to 'rabbitmq::server' # $enabled = true, $rabbitmq_class = 'rabbitmq::server' Class[$rabbitmq_class] -> Anchor<| title == 'nova-start' |> require => Class[$rabbitmq_class], class { $rabbitmq_class: class { $rabbitmq_class: require => Class[$rabbitmq_class],"," $enabled = true Class['rabbitmq::service'] -> Anchor<| title == 'nova-start' |> require => Class['rabbitmq::server'], class { 'rabbitmq::server': class { 'rabbitmq::server': require => Class['rabbitmq::server'],",13,6
openstack%2Ftripleo-image-elements~master~I52422002825522e5d1cf495cb8af8d200f5553cf,openstack/tripleo-image-elements,master,I52422002825522e5d1cf495cb8af8d200f5553cf,Setuptools 3.0 breaks cffi,ABANDONED,2014-03-06 19:06:13.000000000,2014-03-06 19:10:55.000000000,,[{'_account_id': 3}],"[{'number': 1, 'created': '2014-03-06 19:06:13.000000000', 'files': ['elements/openstack-clients/bin/install-openstack-client'], 'web_link': 'https://opendev.org/openstack/tripleo-image-elements/commit/72d3f8e21b09ed9ff5a9100f9dfc2ad5ae107b81', 'message': 'Setuptools 3.0 breaks cffi\n\nTemprorary fix of pinning setuptools below 3.0 for openstack-client\nuntil cffi is updated.\n\nChange-Id: I52422002825522e5d1cf495cb8af8d200f5553cf\n'}]",0,78714,72d3f8e21b09ed9ff5a9100f9dfc2ad5ae107b81,3,1,1,10035,,,0,"Setuptools 3.0 breaks cffi

Temprorary fix of pinning setuptools below 3.0 for openstack-client
until cffi is updated.

Change-Id: I52422002825522e5d1cf495cb8af8d200f5553cf
",git fetch https://review.opendev.org/openstack/tripleo-image-elements refs/changes/14/78714/1 && git format-patch -1 --stdout FETCH_HEAD,['elements/openstack-clients/bin/install-openstack-client'],1,72d3f8e21b09ed9ff5a9100f9dfc2ad5ae107b81,setuptools-3-breaks-cffi,"# Need <3.0 due to cffi install error pip install -U 'setuptools>=1.0,<3.0'",pip install -U 'setuptools>=1.0',2,1
openstack%2Ftaskflow~master~Ic697673e1bdee58a299b4cda8669a64a958f9c42,openstack/taskflow,master,Ic697673e1bdee58a299b4cda8669a64a958f9c42,Fix try_clean not getting the job_path,MERGED,2014-02-27 04:22:55.000000000,2014-03-06 19:06:59.000000000,2014-03-06 19:06:59.000000000,"[{'_account_id': 3}, {'_account_id': 1297}, {'_account_id': 7366}]","[{'number': 1, 'created': '2014-02-27 04:22:55.000000000', 'files': ['taskflow/jobs/backends/impl_zookeeper.py', 'taskflow/tests/unit/jobs/test_zk_job.py'], 'web_link': 'https://opendev.org/openstack/taskflow/commit/b70d37c4c10a28b632e6c59382c83f9c2de4f478', 'message': ""Fix try_clean not getting the job_path\n\nWhen a posting failure happens and an exception\nis raised the try_clean method is activated to\nremove the posting in progress from the known\njobs, but only if we pass in the path to remove\nwhich we weren't.\n\nChange-Id: Ic697673e1bdee58a299b4cda8669a64a958f9c42\n""}]",0,76750,b70d37c4c10a28b632e6c59382c83f9c2de4f478,11,3,1,1297,,,0,"Fix try_clean not getting the job_path

When a posting failure happens and an exception
is raised the try_clean method is activated to
remove the posting in progress from the known
jobs, but only if we pass in the path to remove
which we weren't.

Change-Id: Ic697673e1bdee58a299b4cda8669a64a958f9c42
",git fetch https://review.opendev.org/openstack/taskflow refs/changes/50/76750/1 && git format-patch -1 --stdout FETCH_HEAD,"['taskflow/jobs/backends/impl_zookeeper.py', 'taskflow/tests/unit/jobs/test_zk_job.py']",2,b70d37c4c10a28b632e6c59382c83f9c2de4f478,,"import mock def test_posting_no_post(self): def bad_format(job): raise UnicodeError(""Could not format"") with connect_close(self.board): with mock.patch.object(self.board, '_format_job', bad_format): self.assertRaises(UnicodeError, self.board.post, 'test', p_utils.temporary_log_book()) self.assertEqual(0, self.board.job_count) ",,14,2
openstack%2Fpuppet-heat~master~Ia297410e61f246b2f5b4788b5d24961f070aa087,openstack/puppet-heat,master,Ia297410e61f246b2f5b4788b5d24961f070aa087,Adds Support for Database Idle Timeout,MERGED,2014-03-04 21:26:18.000000000,2014-03-06 19:06:36.000000000,2014-03-06 19:06:36.000000000,"[{'_account_id': 3}, {'_account_id': 6754}, {'_account_id': 6836}, {'_account_id': 6924}, {'_account_id': 6967}, {'_account_id': 7822}]","[{'number': 1, 'created': '2014-03-04 21:26:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-heat/commit/8bbf92e9b0b7d85d7bbad6f69c4341c578ce6bd6', 'message': 'Adds Support for Database Idle Timeout\n\nOther OS services support the idle_timeout parameter that is\nneeded for reaping stale sql connections.  This is important for\nclustered databases.  The patch supports backwards compatibility\nby supporting the sql_idle_timeout parameter that is deprecated\nand the database/idle_timeout parameter.\n\nChange-Id: Ia297410e61f246b2f5b4788b5d24961f070aa087\n'}, {'number': 2, 'created': '2014-03-04 22:13:30.000000000', 'files': ['manifests/init.pp', 'spec/classes/heat_init_spec.rb'], 'web_link': 'https://opendev.org/openstack/puppet-heat/commit/49f066e637fe22a25e80449cff8f0936682d7f10', 'message': 'Adds Support for Database Idle Timeout\n\nOther OS services support the idle_timeout parameter that is\nneeded for reaping stale sql connections.  This is important for\nclustered databases.\n\nChange-Id: Ia297410e61f246b2f5b4788b5d24961f070aa087\n'}]",1,78007,49f066e637fe22a25e80449cff8f0936682d7f10,16,6,2,6836,,,0,"Adds Support for Database Idle Timeout

Other OS services support the idle_timeout parameter that is
needed for reaping stale sql connections.  This is important for
clustered databases.

Change-Id: Ia297410e61f246b2f5b4788b5d24961f070aa087
",git fetch https://review.opendev.org/openstack/puppet-heat refs/changes/07/78007/2 && git format-patch -1 --stdout FETCH_HEAD,"['manifests/init.pp', 'spec/classes/heat_init_spec.rb']",2,8bbf92e9b0b7d85d7bbad6f69c4341c578ce6bd6,db_idle_timeout," :package_ensure => 'present', :verbose => 'False', :debug => 'False', :log_dir => '/var/log/heat', :rabbit_host => '127.0.0.1', :rabbit_port => 5672, :rabbit_userid => 'guest', :rabbit_password => '', :rabbit_virtual_host => '/', :sql_connection => 'mysql://user@host/database', :database_idle_timeout => '3600', :keystone_ec2_uri => 'http://127.0.0.1:5000/v2.0/ec2tokens' it 'configures database_idle_timeout' do should contain_heat_config('database/idle_timeout').with_value( params[:database_idle_timeout] ) end shared_examples_for 'with sql_idle_timeout enabled' do before do params.merge!( :database_idle_timeout => false, :sql_idle_timeout => '30' ) end it do should contain_heat_config('DEFAULT/sql_idle_timeout').with_value('30') end end "," :package_ensure => 'present', :verbose => 'False', :debug => 'False', :log_dir => '/var/log/heat', :rabbit_host => '127.0.0.1', :rabbit_port => 5672, :rabbit_userid => 'guest', :rabbit_password => '', :rabbit_virtual_host => '/', :sql_connection => 'mysql://user@host/database', :keystone_ec2_uri => 'http://127.0.0.1:5000/v2.0/ec2tokens'",52,11
openstack%2Ftaskflow~master~Ic1a504ba69c56ba226b1a067b5ade4590c245dd8,openstack/taskflow,master,Ic1a504ba69c56ba226b1a067b5ade4590c245dd8,A few worker-engine cleanups,MERGED,2014-02-22 01:53:41.000000000,2014-03-06 19:03:22.000000000,2014-03-06 19:03:22.000000000,"[{'_account_id': 3}, {'_account_id': 1297}, {'_account_id': 7349}, {'_account_id': 7366}, {'_account_id': 8895}]","[{'number': 1, 'created': '2014-02-22 01:53:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/d0b43c0911be357e1aa34fd049e42182f13a4335', 'message': 'A few worker-engine cleanups\n\n- Remove usage of % with logs, just let the underlying\n  LOG do the interpolation for us if the log level passes.\n- Use LOG.exception instead of LOG.warn and then including\n  the exception as a interpolated variable. Just let the\n  LOG.exception output the exception trace and info.\n- Capture failure_to_dict() before calling into LOG functions\n  which is needed if eventlet is being used and a LOG function\n  causes a greenthread context-switch.\n\nChange-Id: Ic1a504ba69c56ba226b1a067b5ade4590c245dd8\n'}, {'number': 2, 'created': '2014-02-22 01:55:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/d4ad3dea341ebab5695667b0f3649d1c7ecde6be', 'message': 'A few worker-engine cleanups\n\n- Remove usage of % with logs, just let the underlying\n  LOG do the interpolation for us if the log level passes.\n- Use LOG.exception instead of LOG.warn and then including\n  the exception as a interpolated variable. Just let the\n  LOG.exception output the exception trace and info.\n- Capture failure_to_dict() before calling into LOG functions\n  which is needed if eventlet is being used and a LOG function\n  causes a greenthread context-switch.\n\nChange-Id: Ic1a504ba69c56ba226b1a067b5ade4590c245dd8\n'}, {'number': 3, 'created': '2014-02-22 02:10:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/4bbefe1d159099b0794ef3ab75305ed42e2b902d', 'message': 'A few worker-engine cleanups\n\n- Remove usage of % with logs, just let the underlying\n  LOG do the interpolation for us if the log level passes.\n- Use LOG.exception instead of LOG.warn and then including\n  the exception as a interpolated variable. Just let the\n  LOG.exception output the exception trace and info.\n- Capture failure_to_dict() before calling into LOG functions\n  which is needed if eventlet is being used and a LOG function\n  causes a greenthread context-switch.\n\nChange-Id: Ic1a504ba69c56ba226b1a067b5ade4590c245dd8\n'}, {'number': 4, 'created': '2014-02-22 02:25:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/a9d62b9902b5108a7fc66559f56dfd517868f7c4', 'message': 'A few worker-engine cleanups\n\n- Remove usage of % with logs, just let the underlying\n  LOG do the interpolation for us if the log level passes.\n- Use LOG.exception instead of LOG.warn and then including\n  the exception as a interpolated variable. Just let the\n  LOG.exception output the exception trace and info.\n- Capture failure_to_dict() before calling into LOG functions\n  which is needed if eventlet is being used and a LOG function\n  causes a greenthread context-switch.\n\nChange-Id: Ic1a504ba69c56ba226b1a067b5ade4590c245dd8\n'}, {'number': 5, 'created': '2014-02-24 19:06:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/a781dfadc237cec8f3e6581aa9201cb88e87d050', 'message': 'A few worker-engine cleanups\n\n- Remove usage of % with logs, just let the underlying\n  LOG do the interpolation for us if the log level passes.\n- Use LOG.exception instead of LOG.warn and then including\n  the exception as a interpolated variable. Just let the\n  LOG.exception output the exception trace and info.\n- Capture failure_to_dict() before calling into LOG functions\n  which is needed if eventlet is being used and a LOG function\n  causes a greenthread context-switch.\n\nChange-Id: Ic1a504ba69c56ba226b1a067b5ade4590c245dd8\n'}, {'number': 6, 'created': '2014-02-24 21:57:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/4a749f867b28ff2b87e2dfa388535d09c5427c32', 'message': 'A few worker-engine cleanups\n\n- Remove usage of % with logs, just let the underlying\n  LOG do the interpolation for us if the log level passes.\n- Use LOG.exception instead of LOG.warn and then including\n  the exception as a interpolated variable. Just let the\n  LOG.exception output the exception trace and info.\n- Capture failure_to_dict() before calling into LOG functions\n  which is needed if eventlet is being used and a LOG function\n  causes a greenthread context-switch.\n\nChange-Id: Ic1a504ba69c56ba226b1a067b5ade4590c245dd8\n'}, {'number': 7, 'created': '2014-02-25 20:49:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/0adf6dabf5e38eee2b7cfbee4ef41bb842700868', 'message': 'A few worker-engine cleanups\n\n- Remove usage of % with logs, just let the underlying\n  LOG do the interpolation for us if the log level passes.\n- Use LOG.exception instead of LOG.warn and then including\n  the exception as a interpolated variable. Just let the\n  LOG.exception output the exception trace and info.\n- Capture failure_to_dict() before calling into LOG functions\n  which is needed if eventlet is being used and a LOG function\n  causes a greenthread context-switch.\n\nChange-Id: Ic1a504ba69c56ba226b1a067b5ade4590c245dd8\n'}, {'number': 8, 'created': '2014-02-25 20:50:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/cf826d0d24cb7063193458bdbcfa70ca98c344eb', 'message': 'A few worker-engine cleanups\n\n- Remove usage of % with logs, just let the underlying\n  LOG do the interpolation for us if the log level passes.\n- Use LOG.exception instead of LOG.warn and then including\n  the exception as a interpolated variable. Just let the\n  LOG.exception output the exception trace and info.\n- Capture failure_to_dict() before calling into LOG functions\n  which is needed if eventlet is being used and a LOG function\n  causes a greenthread context-switch.\n\nChange-Id: Ic1a504ba69c56ba226b1a067b5ade4590c245dd8\n'}, {'number': 9, 'created': '2014-02-25 20:51:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/4c4937978d78fe907e6a88e082418e2afe778a64', 'message': 'A few worker-engine cleanups\n\n- Remove usage of % with logs, just let the underlying\n  LOG do the interpolation for us if the log level passes.\n- Use LOG.exception instead of LOG.warn and then including\n  the exception as a interpolated variable. Just let the\n  LOG.exception output the exception trace and info.\n- Capture the failure object before doing other work using\n  a new context manager that can yield back a failure object\n  before further code is called (to avoid a context switch\n  happening in eventlet or elsewhere that would clear the\n  exception state).\n\nChange-Id: Ic1a504ba69c56ba226b1a067b5ade4590c245dd8\n'}, {'number': 10, 'created': '2014-02-27 03:37:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/343a0feb33bdd85610cec22fb8ba2d67c31df9c7', 'message': 'A few worker-engine cleanups\n\n- Remove usage of % with logs, just let the underlying\n  LOG do the interpolation for us if the log level passes.\n- Use LOG.exception instead of LOG.warn and then including\n  the exception as a interpolated variable. Just let the\n  LOG.exception output the exception trace and info.\n- Capture the failure object before doing other work using\n  a new context manager that can yield back a failure object\n  before further code is called (to avoid a context switch\n  happening in eventlet or elsewhere that would clear the\n  exception state).\n\nChange-Id: Ic1a504ba69c56ba226b1a067b5ade4590c245dd8\n'}, {'number': 11, 'created': '2014-03-06 18:18:09.000000000', 'files': ['taskflow/engines/worker_based/server.py', 'taskflow/engines/worker_based/proxy.py', 'taskflow/engines/worker_based/executor.py', 'taskflow/tests/unit/worker_based/test_executor.py', 'taskflow/utils/misc.py', 'taskflow/tests/unit/worker_based/test_server.py'], 'web_link': 'https://opendev.org/openstack/taskflow/commit/1cf69b9ec647136367d3b6d016375a652d9b269b', 'message': 'A few worker-engine cleanups\n\n- Remove usage of % with logs, just let the underlying\n  LOG do the interpolation for us if the log level passes.\n- Use LOG.exception instead of LOG.warn and then including\n  the exception as a interpolated variable. Just let the\n  LOG.exception output the exception trace and info.\n- Capture the failure object before doing other work using\n  a new context manager that can yield back a failure object\n  before further code is called (to avoid a context switch\n  happening in eventlet or elsewhere that would clear the\n  exception state).\n\nChange-Id: Ic1a504ba69c56ba226b1a067b5ade4590c245dd8\n'}]",13,75550,1cf69b9ec647136367d3b6d016375a652d9b269b,56,5,11,1297,,,0,"A few worker-engine cleanups

- Remove usage of % with logs, just let the underlying
  LOG do the interpolation for us if the log level passes.
- Use LOG.exception instead of LOG.warn and then including
  the exception as a interpolated variable. Just let the
  LOG.exception output the exception trace and info.
- Capture the failure object before doing other work using
  a new context manager that can yield back a failure object
  before further code is called (to avoid a context switch
  happening in eventlet or elsewhere that would clear the
  exception state).

Change-Id: Ic1a504ba69c56ba226b1a067b5ade4590c245dd8
",git fetch https://review.opendev.org/openstack/taskflow refs/changes/50/75550/10 && git format-patch -1 --stdout FETCH_HEAD,"['taskflow/engines/worker_based/server.py', 'taskflow/engines/worker_based/executor.py', 'taskflow/engines/worker_based/proxy.py']",3,d0b43c0911be357e1aa34fd049e42182f13a4335,," LOG.info(""Starting to consume from the '%s' exchange."", except Exception: LOG.exception(""Failed to delete the '%s' queue"", queue.name) except Exception: LOG.exception(""Failed to delete the '%s' exchange"", self._exchange.name)"," LOG.info(""Starting to consume from the '%s' exchange."" % except Exception as e: LOG.error(""Failed to delete the '%s' queue: %s"" % (queue.name, e)) except Exception as e: LOG.error(""Failed to delete the '%s' exchange: %s"" % (self._exchange.name, e))",48,47
openstack%2Foslo.rootwrap~master~I255a4c40a661d86c76863f2919b36b8d12b77cd6,openstack/oslo.rootwrap,master,I255a4c40a661d86c76863f2919b36b8d12b77cd6,Add Python 3 trove classifiers,MERGED,2014-03-03 17:12:51.000000000,2014-03-06 19:02:57.000000000,2014-03-06 19:02:57.000000000,"[{'_account_id': 3}, {'_account_id': 308}, {'_account_id': 2472}]","[{'number': 1, 'created': '2014-03-03 17:12:51.000000000', 'files': ['setup.cfg'], 'web_link': 'https://opendev.org/openstack/oslo.rootwrap/commit/96992e57312fb9a21a710d561224ae7a70e41458', 'message': 'Add Python 3 trove classifiers\n\nChange-Id: I255a4c40a661d86c76863f2919b36b8d12b77cd6\n'}]",0,77652,96992e57312fb9a21a710d561224ae7a70e41458,10,3,1,8122,,,0,"Add Python 3 trove classifiers

Change-Id: I255a4c40a661d86c76863f2919b36b8d12b77cd6
",git fetch https://review.opendev.org/openstack/oslo.rootwrap refs/changes/52/77652/1 && git format-patch -1 --stdout FETCH_HEAD,['setup.cfg'],1,96992e57312fb9a21a710d561224ae7a70e41458,add_classifiers, Programming Language :: Python :: 3 Programming Language :: Python :: 3.3,,2,0
openstack%2Fzaqar~master~I076ffc171adf02fdb15160b6c7b29646ee3fb280,openstack/zaqar,master,I076ffc171adf02fdb15160b6c7b29646ee3fb280,Reuse the transaction before getting messages,MERGED,2014-03-06 17:13:49.000000000,2014-03-06 18:59:23.000000000,2014-03-06 18:59:23.000000000,"[{'_account_id': 3}, {'_account_id': 6427}, {'_account_id': 6944}]","[{'number': 1, 'created': '2014-03-06 17:13:49.000000000', 'files': ['marconi/queues/storage/sqlalchemy/messages.py', 'marconi/queues/storage/sqlalchemy/claims.py'], 'web_link': 'https://opendev.org/openstack/zaqar/commit/364945f9902302e23cb6164377f5a310a82a2839', 'message': ""Reuse the transaction before getting messages\n\nThe message get helper for claims used its own connection and ran\noutside the transaction where the 'claiming' happened. This caused the\nget to fail at retrieving the messages because the query was being\nexecuted 'before' the transaction.\n\nThis patch fixes the aforementioned issue and also ensures that records\nids are 'int' before calling `message_encode`.\n\nChange-Id: I076ffc171adf02fdb15160b6c7b29646ee3fb280\nCloses-bug: #1288820\n""}]",0,78673,364945f9902302e23cb6164377f5a310a82a2839,10,3,1,6159,,,0,"Reuse the transaction before getting messages

The message get helper for claims used its own connection and ran
outside the transaction where the 'claiming' happened. This caused the
get to fail at retrieving the messages because the query was being
executed 'before' the transaction.

This patch fixes the aforementioned issue and also ensures that records
ids are 'int' before calling `message_encode`.

Change-Id: I076ffc171adf02fdb15160b6c7b29646ee3fb280
Closes-bug: #1288820
",git fetch https://review.opendev.org/openstack/zaqar refs/changes/73/78673/1 && git format-patch -1 --stdout FETCH_HEAD,"['marconi/queues/storage/sqlalchemy/messages.py', 'marconi/queues/storage/sqlalchemy/claims.py']",2,364945f9902302e23cb6164377f5a310a82a2839,," def __get(self, cid, trans): records = trans.execute(sel) 'id': utils.msgid_encode(int(id)), list(self.__get(cid, trans)) return (utils.cid_encode(int(cid)), list(self.__get(cid, trans)))"," def __get(self, cid): records = self.driver.run(sel) 'id': utils.msgid_encode(id), self.__get(cid) return (utils.cid_encode(cid), self.__get(cid))",7,8
openstack%2Fzaqar~master~I2e8415dbb9a6ce19d3a66f3226756094b3e0f6a4,openstack/zaqar,master,I2e8415dbb9a6ce19d3a66f3226756094b3e0f6a4,Set time_zone to UTC on MySQL,MERGED,2014-03-06 17:13:49.000000000,2014-03-06 18:59:00.000000000,2014-03-06 18:58:59.000000000,"[{'_account_id': 3}, {'_account_id': 6159}, {'_account_id': 6427}, {'_account_id': 6944}]","[{'number': 1, 'created': '2014-03-06 17:13:49.000000000', 'files': ['marconi/queues/storage/sqlalchemy/driver.py'], 'web_link': 'https://opendev.org/openstack/zaqar/commit/477bc46bfe1d7e1c056a4bb4aaa72d452315c160', 'message': ""Set time_zone to UTC on MySQL\n\nMySQL uses UTC for all date fields but other operations like `now()` use\nthe timezone of the server. This patch changes the timezone of the\nconnection to UTC when the connection is first established.\n\nThere's space for improvement here. For instance, we could try to avoid\ndoing this for every new connection and let the operator configure it on\nthe server side. We could also use `CONVERT_TZ` on every query using\n`now()`.\n\nChange-Id: I2e8415dbb9a6ce19d3a66f3226756094b3e0f6a4\nPartial-bug: #1288820\n""}]",3,78672,477bc46bfe1d7e1c056a4bb4aaa72d452315c160,10,4,1,6159,,,0,"Set time_zone to UTC on MySQL

MySQL uses UTC for all date fields but other operations like `now()` use
the timezone of the server. This patch changes the timezone of the
connection to UTC when the connection is first established.

There's space for improvement here. For instance, we could try to avoid
doing this for every new connection and let the operator configure it on
the server side. We could also use `CONVERT_TZ` on every query using
`now()`.

Change-Id: I2e8415dbb9a6ce19d3a66f3226756094b3e0f6a4
Partial-bug: #1288820
",git fetch https://review.opendev.org/openstack/zaqar refs/changes/72/78672/1 && git format-patch -1 --stdout FETCH_HEAD,['marconi/queues/storage/sqlalchemy/driver.py'],1,477bc46bfe1d7e1c056a4bb4aaa72d452315c160,," def _mysql_on_connect(self, conn, record): # NOTE(flaper87): This is necesary in order # to ensure that all date operations in mysql # happen in UTC, `now()` for example. conn.query('SET time_zone = ""+0:00""') if uri.startswith('mysql://'): sa.event.listen(engine, 'connect', self._mysql_on_connect) ",,10,0
openstack%2Ffuel-web~master~I623eb226170f0dd77d87aaa2b31bc48b995fb2fd,openstack/fuel-web,master,I623eb226170f0dd77d87aaa2b31bc48b995fb2fd,Settings tab multiple fixes,MERGED,2014-03-05 16:58:37.000000000,2014-03-06 18:52:37.000000000,2014-03-06 09:37:04.000000000,"[{'_account_id': 3}, {'_account_id': 1736}, {'_account_id': 8735}, {'_account_id': 8766}, {'_account_id': 8971}, {'_account_id': 9091}]","[{'number': 1, 'created': '2014-03-05 16:58:37.000000000', 'files': ['nailgun/static/js/views/cluster_page_tabs/settings_tab.js', 'nailgun/static/templates/cluster/settings_group.html'], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/4839f25a64a1141297595db26556e6fa33bd4736', 'message': 'Settings tab multiple fixes\n\n1) Make settings with same names in different groups work properly\n2) Make settings groups without metadata work properly\n3) Name variables in settings_tab.js according to their names in the template\n\nChange-Id: I623eb226170f0dd77d87aaa2b31bc48b995fb2fd\n'}]",0,78303,4839f25a64a1141297595db26556e6fa33bd4736,11,6,1,8735,,,0,"Settings tab multiple fixes

1) Make settings with same names in different groups work properly
2) Make settings groups without metadata work properly
3) Name variables in settings_tab.js according to their names in the template

Change-Id: I623eb226170f0dd77d87aaa2b31bc48b995fb2fd
",git fetch https://review.opendev.org/openstack/fuel-web refs/changes/03/78303/1 && git format-patch -1 --stdout FETCH_HEAD,"['nailgun/static/js/views/cluster_page_tabs/settings_tab.js', 'nailgun/static/templates/cluster/settings_group.html']",2,4839f25a64a1141297595db26556e6fa33bd4736,,"<% if (settings.metadata && settings.metadata.toggleable) { %> <input type=""checkbox"" name=""<%- groupName + '.' + settingName %>"" <%= disabled %> /> <input type=""radio"" name=""<%- groupName + '.' + settingName %>"" value=""<%- option.data %>"" <%= disabled %> /> <input type=""<%= setting.type %>"" class=""<%= setting.type == 'password' ? 'input-append' : '' %>"" name=""<%- groupName + '.' + settingName %>"" value="""" <%= disabled %> />","<% if (settings.metadata.toggleable){ %> <input type=""checkbox"" name=""<%- settingName %>"" <%= disabled %> /> <input type=""radio"" name=""<%- settingName %>"" value=""<%- option['data'] %>"" <%= disabled %> /> <input type=""<%= setting.type %>"" class=""<%= setting.type == 'password' ? 'input-append' : '' %>"" name=""<%- settingName %>"" value="""" <%= disabled %> />",20,22
openstack%2Fnova~stable%2Fgrizzly~Ib806e0f3136e5fbef1141dcb65580524f9eb3899,openstack/nova,stable/grizzly,Ib806e0f3136e5fbef1141dcb65580524f9eb3899,Fix race for stable/grizzly backport of test_reclaim_queued_deletes,MERGED,2014-02-25 16:20:09.000000000,2014-03-06 18:41:20.000000000,2014-03-06 18:41:17.000000000,"[{'_account_id': 3}, {'_account_id': 67}, {'_account_id': 1420}, {'_account_id': 1561}, {'_account_id': 1955}, {'_account_id': 6873}]","[{'number': 1, 'created': '2014-02-25 16:20:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/85a83ba0506fd017e79bf524028e5f28edc540e1', 'message': ""Fix race for stable/grizzly backport of test_reclaim_queued_deletes\n\nCommit c17e0c1d backported a race condition fix from Havana to\nstable/grizzly but the test case added to test_compute doesn't account\nfor needing to stub out the instance_get_all_by_host call to conductor,\nwhich can lead to race failures on stable/grizzly.\n\nWhen comparing test_compute.py on stable/grizzly and stable/havana,\n'instance_get_all_by_host' is stubbed out extensively in grizzly but not\nHavana, so there is probably another change on Havana that removed the\nneed for that which is not back in Grizzly.\n\nCloses-Bug: #1284666\n\nChange-Id: Ib806e0f3136e5fbef1141dcb65580524f9eb3899\n""}, {'number': 2, 'created': '2014-02-25 16:54:00.000000000', 'files': ['nova/tests/compute/test_compute.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/12c19f33bef8754d3742ddad4d4c18e953e3627d', 'message': ""Fix race for stable/grizzly backport of test_reclaim_queued_deletes\n\nCommit c17e0c1d backported a race condition fix from Havana to\nstable/grizzly but the test case added to test_compute doesn't account\nfor needing to stub out the instance_get_all_by_host call to conductor,\nwhich can lead to race failures on stable/grizzly.\n\nWhen comparing test_compute.py on stable/grizzly and stable/havana,\n'instance_get_all_by_host' is stubbed out extensively in grizzly but not\nHavana. Note that in Havana commit dce64683 changed the delete/soft_delete\npaths use objects, so a lot of the conductor API stubs from test_compute\nwere removed in Havana due to that change. Given that Grizzly is not\nusing objects, and we won't backport commit dce64683 to Grizzly, it makes\nsense to just stub out the conductor API DB calls in this patch.\n\nCloses-Bug: #1284666\n\nChange-Id: Ib806e0f3136e5fbef1141dcb65580524f9eb3899\n""}]",0,76250,12c19f33bef8754d3742ddad4d4c18e953e3627d,27,6,2,6873,,,0,"Fix race for stable/grizzly backport of test_reclaim_queued_deletes

Commit c17e0c1d backported a race condition fix from Havana to
stable/grizzly but the test case added to test_compute doesn't account
for needing to stub out the instance_get_all_by_host call to conductor,
which can lead to race failures on stable/grizzly.

When comparing test_compute.py on stable/grizzly and stable/havana,
'instance_get_all_by_host' is stubbed out extensively in grizzly but not
Havana. Note that in Havana commit dce64683 changed the delete/soft_delete
paths use objects, so a lot of the conductor API stubs from test_compute
were removed in Havana due to that change. Given that Grizzly is not
using objects, and we won't backport commit dce64683 to Grizzly, it makes
sense to just stub out the conductor API DB calls in this patch.

Closes-Bug: #1284666

Change-Id: Ib806e0f3136e5fbef1141dcb65580524f9eb3899
",git fetch https://review.opendev.org/openstack/nova refs/changes/50/76250/1 && git format-patch -1 --stdout FETCH_HEAD,['nova/tests/compute/test_compute.py'],1,85a83ba0506fd017e79bf524028e5f28edc540e1,bug/1284666," instances = [] instances.append( self._create_fake_instance(params={'host': CONF.host})) instances.append( self._create_fake_instance(params={ 'host': CONF.host, 'vm_state': vm_states.SOFT_DELETED, 'deleted_at': timeutils.utcnow()})) instances.append(instance) instances.append( self._create_fake_instance( 'task_state': task_states.RESTORING})) def fake_instance_get_all_by_host(*args, **kwargs): return jsonutils.to_primitive(instances) self.stubs.Set(self.compute.conductor_api, 'instance_get_all_by_host', fake_instance_get_all_by_host) instance_ref = jsonutils.to_primitive(instance)"," self._create_fake_instance(params={'host': CONF.host}) self._create_fake_instance(params={'host': CONF.host, 'vm_state': vm_states.SOFT_DELETED, 'deleted_at': timeutils.utcnow()}) self._create_fake_instance( 'task_state': task_states.RESTORING}) instance_ref = jsonutils.to_primitive(db.instance_get_by_uuid( ctxt, instance['uuid']))",19,8
openstack%2Fpython-neutronclient~master~I24869d188b7ecdc2a08ed10e1aafdeee2914d127,openstack/python-neutronclient,master,I24869d188b7ecdc2a08ed10e1aafdeee2914d127,Updated from global requirements,MERGED,2014-02-22 03:35:48.000000000,2014-03-06 18:41:14.000000000,2014-03-06 18:41:14.000000000,"[{'_account_id': 3}, {'_account_id': 841}, {'_account_id': 4395}]","[{'number': 1, 'created': '2014-02-22 03:35:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-neutronclient/commit/d3e0f70d7b675bd7de4e91bf55a7ca086f315900', 'message': 'Updated from global requirements\n\nChange-Id: I24869d188b7ecdc2a08ed10e1aafdeee2914d127\n'}, {'number': 2, 'created': '2014-02-23 09:31:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-neutronclient/commit/f08879167c1f13645abf9d21e34197e42594a889', 'message': 'Updated from global requirements\n\nChange-Id: I24869d188b7ecdc2a08ed10e1aafdeee2914d127\n'}, {'number': 3, 'created': '2014-02-24 22:31:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-neutronclient/commit/eaeef6251cbc6463eec6566cc078cddf06b3c5ce', 'message': 'Updated from global requirements\n\nChange-Id: I24869d188b7ecdc2a08ed10e1aafdeee2914d127\n'}, {'number': 4, 'created': '2014-02-25 06:37:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-neutronclient/commit/15b9c070a700b4cef9589ea12332455e53d805b9', 'message': 'Updated from global requirements\n\nChange-Id: I24869d188b7ecdc2a08ed10e1aafdeee2914d127\n'}, {'number': 5, 'created': '2014-02-26 23:34:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-neutronclient/commit/4f5e6b32ec2392491c27380b6db878c608fe0f79', 'message': 'Updated from global requirements\n\nChange-Id: I24869d188b7ecdc2a08ed10e1aafdeee2914d127\n'}, {'number': 6, 'created': '2014-03-03 16:53:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-neutronclient/commit/b561bfe736185b5a0b3ac4cd411f439e6ff77fcc', 'message': 'Updated from global requirements\n\nChange-Id: I24869d188b7ecdc2a08ed10e1aafdeee2914d127\n'}, {'number': 7, 'created': '2014-03-05 19:29:59.000000000', 'files': ['requirements.txt', 'test-requirements.txt'], 'web_link': 'https://opendev.org/openstack/python-neutronclient/commit/b7d7d56a866238942f7b7aa16a1ee44951087a26', 'message': 'Updated from global requirements\n\nChange-Id: I24869d188b7ecdc2a08ed10e1aafdeee2914d127\n'}]",0,75588,b7d7d56a866238942f7b7aa16a1ee44951087a26,44,3,7,3,,,0,"Updated from global requirements

Change-Id: I24869d188b7ecdc2a08ed10e1aafdeee2914d127
",git fetch https://review.opendev.org/openstack/python-neutronclient refs/changes/88/75588/4 && git format-patch -1 --stdout FETCH_HEAD,"['requirements.txt', 'test-requirements.txt']",2,d3e0f70d7b675bd7de4e91bf55a7ca086f315900,openstack/requirements,"hacking>=0.8.0,<0.9python-subunit>=0.0.18testtools>=0.9.34","hacking>=0.5.6,<0.8python-subunittesttools>=0.9.32",5,5
openstack%2Fpuppet-swift~master~I114d9305ea91baf399ebe7bc09c95c50741fb5b1,openstack/puppet-swift,master,I114d9305ea91baf399ebe7bc09c95c50741fb5b1,Fix test files (address is now removed),MERGED,2014-03-06 00:43:19.000000000,2014-03-06 18:38:43.000000000,2014-03-06 18:38:43.000000000,"[{'_account_id': 3}, {'_account_id': 3153}, {'_account_id': 7822}]","[{'number': 1, 'created': '2014-03-06 00:43:19.000000000', 'files': ['tests/site.pp'], 'web_link': 'https://opendev.org/openstack/puppet-swift/commit/4c86d39972b6d2ea198dfd44cac14f4eec0dd664', 'message': 'Fix test files (address is now removed)\n\nThe new parameter is now public_address.\nrefs: f8fbd8addfe07547666666a8cb2f68f5b1d8aa81\n\nChange-Id: I114d9305ea91baf399ebe7bc09c95c50741fb5b1\n'}]",0,78481,4c86d39972b6d2ea198dfd44cac14f4eec0dd664,7,3,1,7155,,,0,"Fix test files (address is now removed)

The new parameter is now public_address.
refs: f8fbd8addfe07547666666a8cb2f68f5b1d8aa81

Change-Id: I114d9305ea91baf399ebe7bc09c95c50741fb5b1
",git fetch https://review.opendev.org/openstack/puppet-swift refs/changes/81/78481/1 && git format-patch -1 --stdout FETCH_HEAD,['tests/site.pp'],1,4c86d39972b6d2ea198dfd44cac14f4eec0dd664,tests," password => $swift_admin_password, public_address => $swift_proxy_node,"," password => $swift_admin_password, address => $swift_proxy_node,",2,2
openstack%2Fpuppet-ceilometer~stable%2Fhavana~I74a523bcc1acd18532bb9353b70da63c70e8e325,openstack/puppet-ceilometer,stable/havana,I74a523bcc1acd18532bb9353b70da63c70e8e325,Move service polling credentials to service_credentials,MERGED,2014-03-05 21:53:21.000000000,2014-03-06 18:32:10.000000000,2014-03-06 18:32:10.000000000,"[{'_account_id': 3}, {'_account_id': 3153}, {'_account_id': 6967}, {'_account_id': 7822}]","[{'number': 1, 'created': '2014-03-05 21:53:21.000000000', 'files': ['spec/classes/ceilometer_agent_auth_spec.rb', 'manifests/agent/auth.pp'], 'web_link': 'https://opendev.org/openstack/puppet-ceilometer/commit/3e3c021a81b015323c2fe0243f138f90c2cd2eb7', 'message': 'Move service polling credentials to service_credentials\n\nChange-Id: I74a523bcc1acd18532bb9353b70da63c70e8e325\nCloses-bug: #1287939\n(cherry picked from commit 160b5ed239e996e6c18de3f6158c8b0a4e66c175)\n'}]",0,78428,3e3c021a81b015323c2fe0243f138f90c2cd2eb7,8,4,1,7156,,,0,"Move service polling credentials to service_credentials

Change-Id: I74a523bcc1acd18532bb9353b70da63c70e8e325
Closes-bug: #1287939
(cherry picked from commit 160b5ed239e996e6c18de3f6158c8b0a4e66c175)
",git fetch https://review.opendev.org/openstack/puppet-ceilometer refs/changes/28/78428/1 && git format-patch -1 --stdout FETCH_HEAD,"['spec/classes/ceilometer_agent_auth_spec.rb', 'manifests/agent/auth.pp']",2,3e3c021a81b015323c2fe0243f138f90c2cd2eb7,bug/1287939, ceilometer_config { 'service_credentials/os_cacert': ensure => absent } } else { ceilometer_config { 'service_credentials/os_cacert': value => $auth_cacert } 'service_credentials/os_auth_url' : value => $auth_url; 'service_credentials/os_auth_region' : value => $auth_region; 'service_credentials/os_username' : value => $auth_user; 'service_credentials/os_password' : value => $auth_password; 'service_credentials/os_tenant_name' : value => $auth_tenant_name; 'service_credentials/os_tenant_id' : value => $auth_tenant_id;, ceilometer_config { 'DEFAULT/os_cacert': ensure => absent } } else { ceilometer_config { 'DEFAULT/os_cacert': value => $auth_cacert } 'DEFAULT/os_auth_url' : value => $auth_url; 'DEFAULT/os_auth_region' : value => $auth_region; 'DEFAULT/os_username' : value => $auth_user; 'DEFAULT/os_password' : value => $auth_password; 'DEFAULT/os_tenant_name' : value => $auth_tenant_name; 'DEFAULT/os_tenant_id' : value => $auth_tenant_id;,15,15
openstack%2Fsolum~master~I0105c2ff8787f509c87708b3af863ca2042aa444,openstack/solum,master,I0105c2ff8787f509c87708b3af863ca2042aa444,Add a trivial image building implementation,MERGED,2014-02-17 07:26:07.000000000,2014-03-06 18:31:34.000000000,2014-03-06 18:31:34.000000000,"[{'_account_id': 3}, {'_account_id': 668}, {'_account_id': 2506}, {'_account_id': 4715}, {'_account_id': 6427}, {'_account_id': 8334}, {'_account_id': 8443}, {'_account_id': 9537}, {'_account_id': 9548}, {'_account_id': 9808}]","[{'number': 1, 'created': '2014-02-17 07:26:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/solum/commit/81415be9c9b6310ba6b40881cbfc24372d23b98b', 'message': 'Add a trivial implementation\n\nto run this:\n$ sudo usermod -a -G docker $USERNAME\n$ ./contrib/lp-cedarish/docker/prepare\n$ solum-builder-api &\n$ curl -X POST -H ""Content-Type: application/json"" \\\n    -d \'{""name"":""nodejs"", ""source_url"": ""git://github.com/paulczar/example-nodejs-express.git""}\' \\\n    http://127.0.0.1:9778/v1/images\n\nChange-Id: I0105c2ff8787f509c87708b3af863ca2042aa444\n'}, {'number': 2, 'created': '2014-02-17 09:15:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/solum/commit/43be269a54aacd740417b54a833b21134fec756a', 'message': 'Add a trivial implementation\n\nto run this:\n$ sudo usermod -a -G docker $USERNAME\n$ ./contrib/lp-cedarish/docker/prepare\n$ solum-builder-api &\n$ curl -X POST -H ""Content-Type: application/json"" \\\n    -d \'{""name"":""nodejs"", ""source_url"": ""git://github.com/paulczar/example-nodejs-express.git""}\' \\\n    http://127.0.0.1:9778/v1/images\n\nChange-Id: I0105c2ff8787f509c87708b3af863ca2042aa444\n'}, {'number': 3, 'created': '2014-02-17 10:19:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/solum/commit/6e454c02912578ef14224b7d817dd286758794e7', 'message': 'Add a trivial implementation\n\nto run this:\n$ sudo usermod -a -G docker $USERNAME\n$ ./contrib/lp-cedarish/docker/prepare\n$ solum-builder-api &\n$ curl -X POST -H ""Content-Type: application/json"" \\\n    -d \'{""name"":""nodejs"", ""source_url"": ""git://github.com/paulczar/example-nodejs-express.git""}\' \\\n    http://127.0.0.1:9778/v1/images\n\nChange-Id: I0105c2ff8787f509c87708b3af863ca2042aa444\n'}, {'number': 4, 'created': '2014-02-17 11:20:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/solum/commit/5edf69a8d484f0882ab25c1da594e0d90c07c1d2', 'message': 'Add a trivial implementation\n\nto run this:\n$ sudo usermod -a -G docker $USERNAME\n$ ./contrib/lp-cedarish/docker/prepare\n$ solum-builder-api &\n$ curl -X POST -H ""Content-Type: application/json"" \\\n    -d \'{""name"":""nodejs"", ""source_url"": ""git://github.com/paulczar/example-nodejs-express.git""}\' \\\n    http://127.0.0.1:9778/v1/images\n\nChange-Id: I0105c2ff8787f509c87708b3af863ca2042aa444\n'}, {'number': 5, 'created': '2014-02-18 00:31:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/solum/commit/46768eef7ff0ba360dd5bbbf144d9d56b9de6471', 'message': 'Add a trivial implementation\n\nto run this:\n$ sudo usermod -a -G docker $USERNAME\n$ ./contrib/lp-cedarish/docker/prepare\n$ solum-builder-api &\n$ curl -X POST -H ""Content-Type: application/json"" \\\n    -d \'{""name"":""nodejs"", ""source_url"": ""git://github.com/paulczar/example-nodejs-express.git""}\' \\\n    http://127.0.0.1:9778/v1/images\n\nChange-Id: I0105c2ff8787f509c87708b3af863ca2042aa444\n'}, {'number': 6, 'created': '2014-02-18 06:50:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/solum/commit/4d2bb048f1266f988e10c31915d106d1a02c0301', 'message': 'Add a trivial implementation\n\nto run this:\n$ sudo usermod -a -G docker $USERNAME\n$ ./contrib/lp-cedarish/docker/prepare\n$ solum-builder-api &\n$ curl -X POST -H ""Content-Type: application/json"" \\\n    -d \'{""name"":""nodejs"", ""source_url"": ""git://github.com/paulczar/example-nodejs-express.git""}\' \\\n    http://127.0.0.1:9778/v1/images\n\nChange-Id: I0105c2ff8787f509c87708b3af863ca2042aa444\n'}, {'number': 7, 'created': '2014-02-18 11:49:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/solum/commit/e76549ec1c93bcd900d51b27301fc221fdd69360', 'message': 'Add a trivial implementation\n\nto run this:\n$ sudo usermod -a -G docker $USERNAME\n$ ./contrib/lp-cedarish/docker/prepare\n$ solum-builder-api &\n$ curl -X POST -H ""Content-Type: application/json"" \\\n    -d \'{""name"":""nodejs"", ""source_url"": ""git://github.com/paulczar/example-nodejs-express.git""}\' \\\n    http://127.0.0.1:9778/v1/images\n\nChange-Id: I0105c2ff8787f509c87708b3af863ca2042aa444\n'}, {'number': 8, 'created': '2014-02-20 08:54:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/solum/commit/8b9c3319496c73227dc77ce0be5d98b723ff728e', 'message': 'Add a trivial implementation\n\nto run this:\n$ sudo usermod -a -G docker $USERNAME\n$ ./contrib/lp-cedarish/docker/prepare\n$ solum-builder-api &\n$ curl -X POST -H ""Content-Type: application/json"" \\\n    -d \'{""name"":""nodejs"", ""source_url"": ""git://github.com/paulczar/example-nodejs-express.git""}\' \\\n    http://127.0.0.1:9778/v1/images\n\nChange-Id: I0105c2ff8787f509c87708b3af863ca2042aa444\n'}, {'number': 9, 'created': '2014-02-27 22:04:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/solum/commit/c8336de6e06d334faba6dd3f24c59d5f8adbe8df', 'message': 'Add a trivial image building implementation\n\nto run this:\n$ sudo usermod -a -G docker $USERNAME\n$ ./contrib/lp-cedarish/docker/prepare\n$ solum-builder-api &\n$ curl -X POST -H ""Content-Type: application/json"" \\\n    -d \'{""name"":""nodejs"", ""source_url"": ""git://github.com/paulczar/example-nodejs-express.git""}\' \\\n    http://127.0.0.1:9778/v1/images\n\nChange-Id: I0105c2ff8787f509c87708b3af863ca2042aa444\n'}, {'number': 10, 'created': '2014-02-27 23:49:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/solum/commit/8586f7bb4cf956b233ad23127f42854e106ec962', 'message': 'Add a trivial image building implementation\n\nto run this:\n$ sudo usermod -a -G docker $USERNAME\n$ ./contrib/lp-cedarish/docker/prepare\n$ solum-builder-api &\n$ curl -X POST -H ""Content-Type: application/json"" \\\n    -d \'{""name"":""nodejs"", ""source_url"": ""git://github.com/paulczar/example-nodejs-express.git""}\' \\\n    http://127.0.0.1:9778/v1/images\n\nChange-Id: I0105c2ff8787f509c87708b3af863ca2042aa444\n'}, {'number': 11, 'created': '2014-02-28 01:48:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/solum/commit/1f6e233125dbb44ab0ad1fa0887556311104b218', 'message': 'Add a trivial image building implementation\n\nto run this:\n$ sudo usermod -a -G docker $USERNAME\n$ ./contrib/lp-cedarish/docker/prepare\n$ solum-builder-api &\n$ curl -X POST -H ""Content-Type: application/json"" \\\n    -d \'{""name"":""nodejs"", ""source_url"": ""git://github.com/paulczar/example-nodejs-express.git""}\' \\\n    http://127.0.0.1:9778/v1/images\n\nChange-Id: I0105c2ff8787f509c87708b3af863ca2042aa444\n'}, {'number': 12, 'created': '2014-02-28 07:30:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/solum/commit/92acbc4d4ff8001673ee231a71cfcd3ae419db4e', 'message': 'Add a trivial image building implementation\n\nto run this:\n$ sudo usermod -a -G docker $USERNAME\n$ ./contrib/lp-cedarish/docker/prepare\n$ solum-builder-api &\n$ curl -X POST -H ""Content-Type: application/json"" \\\n    -d \'{""name"":""nodejs"", ""source_url"": ""git://github.com/paulczar/example-nodejs-express.git""}\' \\\n    http://127.0.0.1:9778/v1/images\n\nChange-Id: I0105c2ff8787f509c87708b3af863ca2042aa444\n'}, {'number': 13, 'created': '2014-03-03 00:45:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/solum/commit/ea026f6c0af9c955ce5a2ee492951567e94d34f3', 'message': 'Add a trivial image building implementation\n\nto run this:\n$ sudo usermod -a -G docker $USERNAME\n$ ./contrib/lp-cedarish/docker/prepare\n$ solum-builder-api &\n$ curl -X POST -H ""Content-Type: application/json"" \\\n    -d \'{""name"":""nodejs"", ""source_url"": ""git://github.com/paulczar/example-nodejs-express.git""}\' \\\n    http://127.0.0.1:9778/v1/images\n\npart of blueprint lang-pack\nChange-Id: I0105c2ff8787f509c87708b3af863ca2042aa444\n'}, {'number': 14, 'created': '2014-03-04 12:03:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/solum/commit/6a0e13ae9b9c426707b11dfb9bcf925b3f8b6a12', 'message': 'Add a trivial image building implementation\n\nto run this:\n$ sudo usermod -a -G docker $USERNAME\n$ ./contrib/lp-cedarish/docker/prepare\n$ solum-builder-api &\n$ curl -X POST -H ""Content-Type: application/json"" \\\n    -d \'{""name"":""nodejs"", ""source_url"": ""git://github.com/paulczar/example-nodejs-express.git""}\' \\\n    http://127.0.0.1:9778/v1/images\n\npart of blueprint lang-pack\nChange-Id: I0105c2ff8787f509c87708b3af863ca2042aa444\n'}, {'number': 15, 'created': '2014-03-04 12:06:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/solum/commit/012e181d352c0b7965d19d3821ec0fc05bdffc4f', 'message': 'Add a trivial image building implementation\n\nto run this:\n$ sudo usermod -a -G docker $USERNAME\n$ ./contrib/lp-cedarish/docker/prepare\n$ solum-builder-api &\n$ curl -X POST -H ""Content-Type: application/json"" \\\n    -d \'{""name"":""nodejs"", ""source_url"": ""git://github.com/paulczar/example-nodejs-express.git""}\' \\\n    http://127.0.0.1:9778/v1/images\n\npart of blueprint lang-pack\nChange-Id: I0105c2ff8787f509c87708b3af863ca2042aa444\n'}, {'number': 16, 'created': '2014-03-05 20:54:10.000000000', 'files': ['solum/tests/builder/handlers/test_image.py', 'solum/builder/handlers/image_handler.py'], 'web_link': 'https://opendev.org/openstack/solum/commit/f66e9014406348dfa3feb9cb49289189dc0ae7e1', 'message': 'Add a trivial image building implementation\n\nto run this:\n$ sudo usermod -a -G docker $USERNAME\n$ ./contrib/lp-cedarish/docker/prepare\n$ solum-builder-api &\n$ curl -X POST -H ""Content-Type: application/json"" \\\n    -d \'{""name"":""nodejs"", ""source_url"": ""git://github.com/paulczar/example-nodejs-express.git""}\' \\\n    http://127.0.0.1:9778/v1/images\n\npart of blueprint lang-pack\nChange-Id: I0105c2ff8787f509c87708b3af863ca2042aa444\n'}]",12,73949,f66e9014406348dfa3feb9cb49289189dc0ae7e1,83,10,16,4715,,,0,"Add a trivial image building implementation

to run this:
$ sudo usermod -a -G docker $USERNAME
$ ./contrib/lp-cedarish/docker/prepare
$ solum-builder-api &
$ curl -X POST -H ""Content-Type: application/json"" \
    -d '{""name"":""nodejs"", ""source_url"": ""git://github.com/paulczar/example-nodejs-express.git""}' \
    http://127.0.0.1:9778/v1/images

part of blueprint lang-pack
Change-Id: I0105c2ff8787f509c87708b3af863ca2042aa444
",git fetch https://review.opendev.org/openstack/solum refs/changes/49/73949/1 && git format-patch -1 --stdout FETCH_HEAD,['solum/builder/handlers/image_handler.py'],1,81415be9c9b6310ba6b40881cbfc24372d23b98b,image-builder," self._start_build(db_obj) def _start_build(self, image): # we could do this with the docker/git python client. proj_dir = os.path.join(os.path.dirname(__file__), '..', '..', '..') build_app = os.path.join(proj_dir, 'contrib', 'lp-cedarish', 'docker', 'build-app') image.state = 'BUILDING' try: out = subprocess.check_output([build_app, image.source_url, image.name]) except subprocess.CalledProcessError as subex: LOG.exception(subex) image.state = 'ERROR' return LOG.debug(out) image.state = 'COMPLETE'",,18,0
openstack%2Fironic~master~I48c357cdf5d7ef2149b8af0becb517a578def97a,openstack/ironic,master,I48c357cdf5d7ef2149b8af0becb517a578def97a,Remove errors from API documentation,MERGED,2014-03-06 00:12:35.000000000,2014-03-06 18:26:14.000000000,2014-03-06 18:26:13.000000000,"[{'_account_id': 3}, {'_account_id': 2889}, {'_account_id': 6618}, {'_account_id': 6773}]","[{'number': 1, 'created': '2014-03-06 00:12:35.000000000', 'files': ['doc/source/webapi/v1.rst'], 'web_link': 'https://opendev.org/openstack/ironic/commit/d5b7af3294ef4f0d0c8a2aba283f4cec7a5b68df', 'message': 'Remove errors from API documentation\n\nThe API documentation mentions NodePowerState, NodeProvisionState,\nand NodeVendorPassthru. They do not exist in the code, and their\nentries here are error messages. Remove them.\n\nChange-Id: I48c357cdf5d7ef2149b8af0becb517a578def97a\n'}]",0,78469,d5b7af3294ef4f0d0c8a2aba283f4cec7a5b68df,8,4,1,7411,,,0,"Remove errors from API documentation

The API documentation mentions NodePowerState, NodeProvisionState,
and NodeVendorPassthru. They do not exist in the code, and their
entries here are error messages. Remove them.

Change-Id: I48c357cdf5d7ef2149b8af0becb517a578def97a
",git fetch https://review.opendev.org/openstack/ironic refs/changes/69/78469/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/source/webapi/v1.rst'],1,d5b7af3294ef4f0d0c8a2aba283f4cec7a5b68df,fix_doc_crash,,"NodePowerState ============== The 'rest-controller' directive of this resource seems to be crashing sphinxcontrib-pecanwsme with ""CRITICAL ironic [-] list index out of range"" errors. .. autotype:: ironic.api.controllers.v1.node.NodePowerState :members: NodeProvisionState ================== The 'rest-controller' directive of this resource seems to be crashing sphinxcontrib-pecanwsme with ""CRITICAL ironic [-] list index out of range"" errors. .. autotype:: ironic.api.controllers.v1.node.NodeProvisionState :members: NodeVendorPassthru ================== The 'rest-controller' directive of this resource seems to be crashing sphinxcontrib-pecanwsme with ""CRITICAL ironic [-] list index out of range"" errors. ",0,30
openstack%2Fpython-glanceclient~master~Ifb298bbb37a94e1d4f5e537b7f4eb086da4c95a9,openstack/python-glanceclient,master,Ifb298bbb37a94e1d4f5e537b7f4eb086da4c95a9,Updated from global requirements,MERGED,2014-01-24 22:40:29.000000000,2014-03-06 18:22:44.000000000,2014-03-06 18:22:44.000000000,"[{'_account_id': 3}, {'_account_id': 6484}, {'_account_id': 6549}]","[{'number': 1, 'created': '2014-01-24 22:40:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-glanceclient/commit/79bc7f6cafa89ba8219f1b95467e2f516299efce', 'message': 'Updated from global requirements\n\nChange-Id: Ifb298bbb37a94e1d4f5e537b7f4eb086da4c95a9\n'}, {'number': 2, 'created': '2014-02-22 03:35:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-glanceclient/commit/89f5b88f1a1b9548622553028173098ae3d10f77', 'message': 'Updated from global requirements\n\nChange-Id: Ifb298bbb37a94e1d4f5e537b7f4eb086da4c95a9\n'}, {'number': 3, 'created': '2014-02-23 09:31:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-glanceclient/commit/74513bef892606ba92f6c2f5bf29c3047d2d6de4', 'message': 'Updated from global requirements\n\nChange-Id: Ifb298bbb37a94e1d4f5e537b7f4eb086da4c95a9\n'}, {'number': 4, 'created': '2014-02-25 06:37:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-glanceclient/commit/5cbc5fdc19355510f492b918341653257b2ec7b7', 'message': 'Updated from global requirements\n\nChange-Id: Ifb298bbb37a94e1d4f5e537b7f4eb086da4c95a9\n'}, {'number': 5, 'created': '2014-02-26 02:37:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-glanceclient/commit/5e54791d248e83e09a6eea56a7ea1667eff65877', 'message': 'Updated from global requirements\n\nChange-Id: Ifb298bbb37a94e1d4f5e537b7f4eb086da4c95a9\n'}, {'number': 6, 'created': '2014-02-28 08:01:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-glanceclient/commit/114101906e4e8690c9b06bb4d566677391127740', 'message': 'Updated from global requirements\n\nChange-Id: Ifb298bbb37a94e1d4f5e537b7f4eb086da4c95a9\n'}, {'number': 7, 'created': '2014-03-05 19:29:35.000000000', 'files': ['requirements.txt', 'test-requirements.txt'], 'web_link': 'https://opendev.org/openstack/python-glanceclient/commit/c18536eacb65642f6a82ba347917bf4d9ca2ed3b', 'message': 'Updated from global requirements\n\nChange-Id: Ifb298bbb37a94e1d4f5e537b7f4eb086da4c95a9\n'}]",0,69040,c18536eacb65642f6a82ba347917bf4d9ca2ed3b,38,3,7,3,,,0,"Updated from global requirements

Change-Id: Ifb298bbb37a94e1d4f5e537b7f4eb086da4c95a9
",git fetch https://review.opendev.org/openstack/python-glanceclient refs/changes/40/69040/5 && git format-patch -1 --stdout FETCH_HEAD,['requirements.txt'],1,79bc7f6cafa89ba8219f1b95467e2f516299efce,openstack/requirements,python-keystoneclient>=0.4.2,python-keystoneclient>=0.4.1,1,1
openstack%2Fopenstack-manuals~master~I0e9ebb93b5a4829dfbcf41a973c23cecd06e3e12,openstack/openstack-manuals,master,I0e9ebb93b5a4829dfbcf41a973c23cecd06e3e12,Replace Quantum with Neutron in image,MERGED,2014-03-06 16:52:40.000000000,2014-03-06 18:10:44.000000000,2014-03-06 18:10:44.000000000,"[{'_account_id': 3}, {'_account_id': 964}, {'_account_id': 6843}]","[{'number': 1, 'created': '2014-03-06 16:52:40.000000000', 'files': ['doc/training-guides/figures/image02.png'], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/b9791c150f26f9bf28be44cab62e72fa86b0ba96', 'message': 'Replace Quantum with Neutron in image\n\nChange-Id: I0e9ebb93b5a4829dfbcf41a973c23cecd06e3e12\n'}]",0,78668,b9791c150f26f9bf28be44cab62e72fa86b0ba96,7,3,1,6547,,,0,"Replace Quantum with Neutron in image

Change-Id: I0e9ebb93b5a4829dfbcf41a973c23cecd06e3e12
",git fetch https://review.opendev.org/openstack/openstack-manuals refs/changes/68/78668/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/training-guides/figures/image02.png'],1,b9791c150f26f9bf28be44cab62e72fa86b0ba96,neutron-image,,,0,0
openstack%2Fzaqar~master~Idcdd3f6c8027e6d79a4fb6d006e0d85dd81f3cdd,openstack/zaqar,master,Idcdd3f6c8027e6d79a4fb6d006e0d85dd81f3cdd,MySQL requires VARCHARs to have a length,MERGED,2014-03-06 15:17:31.000000000,2014-03-06 18:07:11.000000000,2014-03-06 18:07:10.000000000,"[{'_account_id': 3}, {'_account_id': 6159}, {'_account_id': 6427}, {'_account_id': 6944}]","[{'number': 1, 'created': '2014-03-06 15:17:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/zaqar/commit/aa2cdeac7e42b9394322ce039eeaf1e82c72f64a', 'message': 'MySQL requires VARCHARs to have a length\n\nThis patch adds the length to all the `sa.String` usages in the tables\nmodule. The values chosen are based on the already enforced limits.\n\nChange-Id: Idcdd3f6c8027e6d79a4fb6d006e0d85dd81f3cdd\n'}, {'number': 2, 'created': '2014-03-06 15:22:30.000000000', 'files': ['marconi/queues/storage/sqlalchemy/tables.py'], 'web_link': 'https://opendev.org/openstack/zaqar/commit/b892d6d4e421908e5118b87e1ec79d40d53eeac0', 'message': 'MySQL requires VARCHARs to have a length\n\nThis patch adds the length to all the `sa.String` usages in the tables\nmodule. The values chosen are based on the already enforced limits.\n\nChange-Id: Idcdd3f6c8027e6d79a4fb6d006e0d85dd81f3cdd\n'}]",1,78627,b892d6d4e421908e5118b87e1ec79d40d53eeac0,11,4,2,6159,,,0,"MySQL requires VARCHARs to have a length

This patch adds the length to all the `sa.String` usages in the tables
module. The values chosen are based on the already enforced limits.

Change-Id: Idcdd3f6c8027e6d79a4fb6d006e0d85dd81f3cdd
",git fetch https://review.opendev.org/openstack/zaqar refs/changes/27/78627/1 && git format-patch -1 --stdout FETCH_HEAD,['marconi/queues/storage/sqlalchemy/tables.py'],1,aa2cdeac7e42b9394322ce039eeaf1e82c72f64a,," sa.Column('project', sa.String(64)), sa.Column('name', sa.String(64)), sa.Column('name', sa.String(64), primary_key=True), sa.Column('uri', sa.String(100), nullable=False), sa.Column('shard', sa.String(64), sa.Column('project', sa.String(64), nullable=False), sa.Column('queue', sa.String(64), nullable=False),"," sa.Column('project', sa.String), sa.Column('name', sa.String), sa.Column('name', sa.String, primary_key=True), sa.Column('uri', sa.String, nullable=False), sa.Column('shard', sa.String, sa.Column('project', sa.String, nullable=False), sa.Column('queue', sa.String, nullable=False),",7,7
openstack%2Fironic~master~I397fe3c48ca65a3bed70bb5941c4bf9001aec717,openstack/ironic,master,I397fe3c48ca65a3bed70bb5941c4bf9001aec717,Add libffi-dev(el) dependency to quickstart,MERGED,2014-03-05 23:43:34.000000000,2014-03-06 18:05:47.000000000,2014-03-06 18:05:47.000000000,"[{'_account_id': 3}, {'_account_id': 2889}, {'_account_id': 6773}, {'_account_id': 8968}, {'_account_id': 10342}, {'_account_id': 10343}]","[{'number': 1, 'created': '2014-03-05 23:43:34.000000000', 'files': ['doc/source/dev/dev-quickstart.rst'], 'web_link': 'https://opendev.org/openstack/ironic/commit/70ba1493f947ce7eeaaffa0516c18ef02d1b3714', 'message': 'Add libffi-dev(el) dependency to quickstart\n\nThis is required to build cryptography 0.2.1.\n\nChange-Id: I397fe3c48ca65a3bed70bb5941c4bf9001aec717\n'}]",0,78454,70ba1493f947ce7eeaaffa0516c18ef02d1b3714,10,6,1,10343,,,0,"Add libffi-dev(el) dependency to quickstart

This is required to build cryptography 0.2.1.

Change-Id: I397fe3c48ca65a3bed70bb5941c4bf9001aec717
",git fetch https://review.opendev.org/openstack/ironic refs/changes/54/78454/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/source/dev/dev-quickstart.rst'],1,70ba1493f947ce7eeaaffa0516c18ef02d1b3714,add-libffi-dependency, sudo apt-get install python-dev libssl-dev python-pip libmysqlclient-dev libxml2-dev libxslt-dev libpq-dev git git-review libffi-dev sudo yum install python-devel openssl-devel python-pip mysql-devel libxml2-devel libxslt-devel postgresql-devel git git-review libffi-devel, sudo apt-get install python-dev libssl-dev python-pip libmysqlclient-dev libxml2-dev libxslt-dev libpq-dev git git-review sudo yum install python-devel openssl-devel python-pip mysql-devel libxml2-devel libxslt-devel postgresql-devel git git-review,2,2
openstack%2Fheat~master~I883761a0bb0e73a3fcc7c362d8e6dc5a099806e0,openstack/heat,master,I883761a0bb0e73a3fcc7c362d8e6dc5a099806e0,Server secgroups and network/port together invalid,MERGED,2014-01-24 22:45:56.000000000,2014-03-06 18:05:22.000000000,2014-03-06 18:05:21.000000000,"[{'_account_id': 3}, {'_account_id': 3098}, {'_account_id': 4571}, {'_account_id': 6577}, {'_account_id': 6794}, {'_account_id': 9542}, {'_account_id': 10063}]","[{'number': 1, 'created': '2014-01-24 22:45:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/62745a8f3d7c24c7c93bb56fdd98c18e40f72d71', 'message': ""Disallow security_groups for Servers with neutron Ports assigned to them\n\nNova silently ignore security_groups properties for a Server if the\nServer has a 'networks' property that references a neutron Port, the\nintent being that security groups are assigned to the port(s).\n\nAdds note to Server properties to this effect.\nValidation fails for a Server if security_groups defined AND the\nServer has neutron Ports assigned.\n\nChange-Id: I883761a0bb0e73a3fcc7c362d8e6dc5a099806e0\nCloses-Bug: #1270313\n""}, {'number': 2, 'created': '2014-02-01 00:36:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/5f17b5bbd1158edec5f7c8521907bb0a0c3af059', 'message': ""Server secgroups and network/port together invalid\n\nNova silently ignore security_groups properties for a Server if the\nServer has a 'networks' property that references a neutron Port, the\nintent being that security groups are assigned to the port(s).\n\nAdds note to Server properties to this effect.\nValidation fails for a Server if security_groups defined AND the\nServer has neutron Ports assigned.\n\nChange-Id: I883761a0bb0e73a3fcc7c362d8e6dc5a099806e0\nCloses-Bug: #1270313\n""}, {'number': 3, 'created': '2014-02-01 01:17:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/4ccd3368da703a6f00854cce2b51ffff50654d83', 'message': ""Server secgroups and network/port together invalid\n\nNova silently ignore security_groups properties for a Server if the\nServer has a 'networks' property that references a neutron Port, the\nintent being that security groups are assigned to the port(s).\n\nAdds note to Server properties to this effect.\nValidation fails for a Server if security_groups defined AND the\nServer has neutron Ports assigned.\n\nChange-Id: I883761a0bb0e73a3fcc7c362d8e6dc5a099806e0\nCloses-Bug: #1270313\n""}, {'number': 4, 'created': '2014-02-18 23:42:10.000000000', 'files': ['heat/engine/resources/server.py', 'heat/tests/test_server.py'], 'web_link': 'https://opendev.org/openstack/heat/commit/a60c684b5c8b6bc24520db3dfa95fd0b6f5409e6', 'message': ""Server secgroups and network/port together invalid\n\nNova silently ignores security_groups properties for a server if the\nserver has a 'networks' property that references a neutron port, the\nintent being that security groups are assigned to the port(s).\n\nAdds note to Server properties to this effect.\nValidation fails for a Server if 'security_groups' is defined AND\nthe server has neutron Ports assigned.\n\nChange-Id: I883761a0bb0e73a3fcc7c362d8e6dc5a099806e0\nCloses-Bug: #1270313\n""}]",9,69052,a60c684b5c8b6bc24520db3dfa95fd0b6f5409e6,23,7,4,10063,,,0,"Server secgroups and network/port together invalid

Nova silently ignores security_groups properties for a server if the
server has a 'networks' property that references a neutron port, the
intent being that security groups are assigned to the port(s).

Adds note to Server properties to this effect.
Validation fails for a Server if 'security_groups' is defined AND
the server has neutron Ports assigned.

Change-Id: I883761a0bb0e73a3fcc7c362d8e6dc5a099806e0
Closes-Bug: #1270313
",git fetch https://review.opendev.org/openstack/heat refs/changes/52/69052/1 && git format-patch -1 --stdout FETCH_HEAD,"['heat/engine/resources/server.py', 'heat/tests/test_server.py']",2,62745a8f3d7c24c7c93bb56fdd98c18e40f72d71,bug/1270313," def test_server_validate_net_security_groups(self): # Test that if network 'ports' are assigned security groups are # not, because they'll be ignored stack_name = 'srv_net_secgroups' (t, stack) = self._setup_test_stack(stack_name) t['Resources']['WebServer']['Properties']['networks'] = [ {'port': 'aaaaaaaa-aaaa-aaaa-aaaa-aaaaaaaaaaaa'}] t['Resources']['WebServer']['Properties']['security_groups'] = \ ['my_security_group'] server = servers.Server('server_validate_net_security_groups', t['Resources']['WebServer'], stack) self.m.StubOutWithMock(server, 'nova') server.nova().MultipleTimes().AndReturn(self.fc) self.m.ReplayAll() ex = self.assertRaises(exception.StackValidationFailed, server.validate) self.assertIn(_('Property ""security_groups"" will be ignored ' 'because at least one entry in the ""networks"" ' 'property includes a ""port"". Set ""security_groups"" ' 'on the ""port"" instead.' ''), str(ex)) self.m.VerifyAll() ",,48,1
openstack%2Fnova~master~I7a8ce049461605e02815a1d9d419bf3b11fd5c79,openstack/nova,master,I7a8ce049461605e02815a1d9d419bf3b11fd5c79,Make test computations explicit,ABANDONED,2014-03-05 16:26:34.000000000,2014-03-06 17:55:41.000000000,,"[{'_account_id': 3}, {'_account_id': 1865}, {'_account_id': 7461}, {'_account_id': 9578}]","[{'number': 1, 'created': '2014-03-05 16:26:34.000000000', 'files': ['nova/tests/compute/test_resource_tracker.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/f1d9776f8b4cc73264a2b036b869a86999692eb6', 'message': 'Make test computations explicit\n\nThis test is full of magic numbers, making it very difficult to fix when\nthe underlying code changes. There are some obvious errors, such as an\ninstance having a different memory_mb value than its flavor. This patch\nattempts to sort these issues out, making it easier to alter the\nresource tracker with confidence.\n\nChange-Id: I7a8ce049461605e02815a1d9d419bf3b11fd5c79\n'}]",0,78287,f1d9776f8b4cc73264a2b036b869a86999692eb6,7,4,1,8688,,,0,"Make test computations explicit

This test is full of magic numbers, making it very difficult to fix when
the underlying code changes. There are some obvious errors, such as an
instance having a different memory_mb value than its flavor. This patch
attempts to sort these issues out, making it easier to alter the
resource tracker with confidence.

Change-Id: I7a8ce049461605e02815a1d9d419bf3b11fd5c79
",git fetch https://review.opendev.org/openstack/nova refs/changes/87/78287/1 && git format-patch -1 --stdout FETCH_HEAD,['nova/tests/compute/test_resource_tracker.py'],1,f1d9776f8b4cc73264a2b036b869a86999692eb6,feature/clarify2,"FAKE_VIRT_MEMORY_WITH_OVERHEAD = ( FAKE_VIRT_MEMORY_MB + FAKE_VIRT_MEMORY_OVERHEAD) ROOT_GB = 5 EPHEMERAL_GB = 1 FAKE_VIRT_LOCAL_GB = ROOT_GB + EPHEMERAL_GB def _fake_instance(self, stash=True, flavor=None, **kwargs): flavor = flavor or self._fake_flavor_create() sys_meta = self._fake_instance_system_metadata(flavor) self._fake_instance_system_metadata(flavor, 'new_') + self._fake_instance_system_metadata(flavor, 'old_')) 'instance_type_id': flavor['id'], 'memory_mb': flavor['memory_mb'], 'vcpus': flavor['vcpus'], 'root_gb': flavor['root_gb'], 'ephemeral_gb': flavor['ephemeral_gb'], 'root_gb': ROOT_GB, 'ephemeral_gb': EPHEMERAL_GB, def _limits(self, memory_mb=FAKE_VIRT_MEMORY_WITH_OVERHEAD, disk_gb=FAKE_VIRT_LOCAL_GB, flavor = self._fake_flavor_create() claim_mem = flavor['memory_mb'] + FAKE_VIRT_MEMORY_OVERHEAD claim_gb = flavor['root_gb'] + flavor['ephemeral_gb'] instance = self._fake_instance(flavor=flavor, task_state=None) self._assert(claim_mem, 'memory_mb_used') self._assert(claim_gb, 'local_gb_used') self._assert(claim_mem, 'memory_mb_used') self._assert(claim_gb, 'local_gb_used') claim_mem_total = 3 + FAKE_VIRT_MEMORY_OVERHEAD self.assertEqual(FAKE_VIRT_MEMORY_MB, self.compute[""memory_mb""]) self.assertEqual(claim_mem_total, self.compute[""memory_mb_used""]) self.assertEqual(FAKE_VIRT_MEMORY_MB - claim_mem_total, self.assertEqual(FAKE_VIRT_LOCAL_GB, self.compute[""local_gb""]) self.assertEqual(FAKE_VIRT_LOCAL_GB - claim_disk, self.compute[""free_disk_gb""]) self.assertEqual(claim_mem_total, self.compute['memory_mb_used']) self.assertEqual(FAKE_VIRT_MEMORY_MB - claim_mem_total, self.assertEqual(FAKE_VIRT_LOCAL_GB - claim_disk, self.compute['free_disk_gb']) claim_mem_total = 3 + FAKE_VIRT_MEMORY_OVERHEAD self.assertEqual(claim_mem_total, self.compute[""memory_mb_used""]) self.assertEqual(FAKE_VIRT_MEMORY_MB - claim_mem_total, self.assertEqual(FAKE_VIRT_LOCAL_GB - claim_disk, self.compute[""free_disk_gb""]) self.assertEqual(FAKE_VIRT_MEMORY_MB, self.compute[""free_ram_mb""]) self.assertEqual(FAKE_VIRT_LOCAL_GB, self.compute[""free_disk_gb""]) flavor = self._fake_flavor_create( memory_mb=1, root_gb=1, ephemeral_gb=0) instance = self._fake_instance(flavor=flavor) instance = self._fake_instance(flavor=flavor) self.assertEqual(2 * (flavor['memory_mb'] + FAKE_VIRT_MEMORY_OVERHEAD), self.tracker.compute_node['memory_mb_used']) self.assertEqual(2 * (flavor['root_gb'] + flavor['ephemeral_gb']), self.tracker.compute_node['local_gb_used']) self.assertEqual(2 * flavor['vcpus'], self.tracker.compute_node['vcpus_used']) flavor = self._fake_flavor_create( memory_mb=1, root_gb=2, ephemeral_gb=3) instance = self._fake_instance(flavor=flavor) self.assertEqual(flavor['memory_mb'] + FAKE_VIRT_MEMORY_OVERHEAD, self.assertEqual(flavor['root_gb'] + flavor['ephemeral_gb'], self.tracker.compute_node['local_gb_used']) self.assertEqual(flavor['memory_mb'] + FAKE_VIRT_MEMORY_OVERHEAD, self.assertEqual(flavor['root_gb'] + flavor['ephemeral_gb'], self.compute['local_gb_used']) self.assertEqual(flavor['memory_mb'] + FAKE_VIRT_MEMORY_OVERHEAD, self.assertEqual(flavor['root_gb'] + flavor['ephemeral_gb'], self.tracker.compute_node['local_gb_used']) self.assertEqual(flavor['memory_mb'] + FAKE_VIRT_MEMORY_OVERHEAD, self.assertEqual(flavor['root_gb'] + flavor['ephemeral_gb'], self.compute['local_gb_used']) vcpus = 1 instance = self._fake_instance(vcpus=vcpus) self.assertEqual(vcpus, self.tracker.compute_node['vcpus_used']) self.assertEqual(vcpus, self.tracker.compute_node['vcpus_used']) add_vcpus = 10 vcpus += add_vcpus instance = self._fake_instance(vcpus=add_vcpus) self.assertEqual(vcpus, self.tracker.compute_node['vcpus_used']) vcpus -= add_vcpus self.assertEqual(vcpus, self.tracker.compute_node['vcpus_used']) self._assert(FAKE_VIRT_MEMORY_WITH_OVERHEAD, 'memory_mb_used') limits = self._limits( 2 * FAKE_VIRT_MEMORY_WITH_OVERHEAD, 2 * FAKE_VIRT_LOCAL_GB, 2 * FAKE_VIRT_VCPUS) self._assert(2 * FAKE_VIRT_MEMORY_WITH_OVERHEAD, 'memory_mb_used') self._assert(FAKE_VIRT_MEMORY_WITH_OVERHEAD, 'memory_mb_used') src_dict = { 'memory_mb': 1, 'root_gb': 1, 'ephemeral_gb': 0, 'vcpus': 1} dest_dict = dict((k, v + 1) for (k, v) in src_dict.iteritems()) src_type = self._fake_flavor_create( id=10, name=""srcflavor"", **src_dict) dest_type = self._fake_flavor_create( id=11, name=""destflavor"", **dest_dict) instance = self._fake_instance(flavor=src_type) self._assert(src_dict['memory_mb'] + dest_dict['memory_mb'] + 2 * FAKE_VIRT_MEMORY_OVERHEAD, 'memory_mb_used') self._assert(src_dict['root_gb'] + src_dict['ephemeral_gb'] + dest_dict['root_gb'] + dest_dict['ephemeral_gb'], 'local_gb_used') self._assert(src_dict['vcpus'] + dest_dict['vcpus'], 'vcpus_used') self._assert(src_dict['memory_mb'] + FAKE_VIRT_MEMORY_OVERHEAD, 'memory_mb_used') self._assert(src_dict['root_gb'] + src_dict['ephemeral_gb'], 'local_gb_used') self._assert(src_dict['vcpus'], 'vcpus_used') self._assert(FAKE_VIRT_MEMORY_WITH_OVERHEAD, self._assert(FAKE_VIRT_MEMORY_WITH_OVERHEAD, self._assert(FAKE_VIRT_MEMORY_WITH_OVERHEAD, 'memory_mb_used') '1-2-3-4-5': {'memory_mb': FAKE_VIRT_MEMORY_MB, 'uuid': '1-2-3-4-5'}, '2-3-4-5-6': {'memory_mb': FAKE_VIRT_MEMORY_MB, 'uuid': '2-3-4-5-6'}, self.assertEqual(2 * FAKE_VIRT_MEMORY_WITH_OVERHEAD,","FAKE_VIRT_LOCAL_GB = 6 def _fake_instance(self, stash=True, **kwargs): itype = self._fake_flavor_create() sys_meta = self._fake_instance_system_metadata(itype) self._fake_instance_system_metadata(itype, 'new_') + self._fake_instance_system_metadata(itype, 'old_')) 'memory_mb': 2, 'root_gb': 3, 'ephemeral_gb': 1, 'vcpus': 1, 'instance_type_id': 1, 'root_gb': FAKE_VIRT_LOCAL_GB / 2, 'ephemeral_gb': FAKE_VIRT_LOCAL_GB / 2, def _limits(self, memory_mb=FAKE_VIRT_MEMORY_MB + FAKE_VIRT_MEMORY_OVERHEAD, disk_gb=FAKE_VIRT_LOCAL_GB, instance = self._fake_instance(memory_mb=3, root_gb=1, ephemeral_gb=1, task_state=None) self._assert(3 + FAKE_VIRT_MEMORY_OVERHEAD, 'memory_mb_used') self._assert(2, 'local_gb_used') self._assert(3 + FAKE_VIRT_MEMORY_OVERHEAD, 'memory_mb_used') self._assert(2, 'local_gb_used') self.assertEqual(5, self.compute[""memory_mb""]) self.assertEqual(claim_mem + FAKE_VIRT_MEMORY_OVERHEAD, self.compute[""memory_mb_used""]) self.assertEqual(5 - claim_mem - FAKE_VIRT_MEMORY_OVERHEAD, self.assertEqual(6, self.compute[""local_gb""]) self.assertEqual(6 - claim_disk, self.compute[""free_disk_gb""]) self.assertEqual(claim_mem + FAKE_VIRT_MEMORY_OVERHEAD, self.compute['memory_mb_used']) self.assertEqual(5 - claim_mem - FAKE_VIRT_MEMORY_OVERHEAD, self.assertEqual(6 - claim_disk, self.compute['free_disk_gb']) self.assertEqual(claim_mem + FAKE_VIRT_MEMORY_OVERHEAD, self.compute[""memory_mb_used""]) self.assertEqual(5 - claim_mem - FAKE_VIRT_MEMORY_OVERHEAD, self.assertEqual(6 - claim_disk, self.compute[""free_disk_gb""]) self.assertEqual(5, self.compute[""free_ram_mb""]) self.assertEqual(6, self.compute[""free_disk_gb""]) instance = self._fake_instance(memory_mb=1, root_gb=1, ephemeral_gb=1, vcpus=1) instance = self._fake_instance(memory_mb=1, root_gb=1, ephemeral_gb=1, vcpus=1) self.assertEqual(2 + 2 * FAKE_VIRT_MEMORY_OVERHEAD, self.tracker.compute_node['memory_mb_used']) self.assertEqual(4, self.tracker.compute_node['local_gb_used']) self.assertEqual(2, self.tracker.compute_node['vcpus_used']) instance = self._fake_instance(memory_mb=1, root_gb=1, ephemeral_gb=1) self.assertEqual(1 + FAKE_VIRT_MEMORY_OVERHEAD, self.assertEqual(2, self.tracker.compute_node['local_gb_used']) self.assertEqual(1 + FAKE_VIRT_MEMORY_OVERHEAD, self.assertEqual(2, self.compute['local_gb_used']) self.assertEqual(1 + FAKE_VIRT_MEMORY_OVERHEAD, self.assertEqual(2, self.tracker.compute_node['local_gb_used']) self.assertEqual(1 + FAKE_VIRT_MEMORY_OVERHEAD, self.assertEqual(2, self.compute['local_gb_used']) instance = self._fake_instance(vcpus=1) self.assertEqual(1, self.tracker.compute_node['vcpus_used']) self.assertEqual(1, self.tracker.compute_node['vcpus_used']) instance = self._fake_instance(vcpus=10) self.assertEqual(11, self.tracker.compute_node['vcpus_used']) self.assertEqual(1, self.tracker.compute_node['vcpus_used']) self._assert(FAKE_VIRT_MEMORY_MB + FAKE_VIRT_MEMORY_OVERHEAD, 'memory_mb_used') limits = self._limits(FAKE_VIRT_MEMORY_MB * 2 + FAKE_VIRT_MEMORY_OVERHEAD * 2, FAKE_VIRT_LOCAL_GB * 2, FAKE_VIRT_VCPUS * 2) self._assert(2 * FAKE_VIRT_MEMORY_MB + 2 * FAKE_VIRT_MEMORY_OVERHEAD, 'memory_mb_used') self._assert(FAKE_VIRT_MEMORY_MB + FAKE_VIRT_MEMORY_OVERHEAD, 'memory_mb_used') src_type = self._fake_flavor_create(id=2, memory_mb=1, root_gb=1, ephemeral_gb=0, vcpus=1) dest_type = self._fake_flavor_create(id=2, memory_mb=2, root_gb=2, ephemeral_gb=1, vcpus=2) instance = self._fake_instance(memory_mb=1, root_gb=1, ephemeral_gb=0, vcpus=1, instance_type_id=2) self._assert(3 + FAKE_VIRT_MEMORY_OVERHEAD * 2, 'memory_mb_used') self._assert(4, 'local_gb_used') self._assert(3, 'vcpus_used') self._assert(1 + FAKE_VIRT_MEMORY_OVERHEAD, 'memory_mb_used') self._assert(1, 'local_gb_used') self._assert(1, 'vcpus_used') self._assert(FAKE_VIRT_MEMORY_MB + FAKE_VIRT_MEMORY_OVERHEAD, self._assert(FAKE_VIRT_MEMORY_MB + FAKE_VIRT_MEMORY_OVERHEAD, self._assert(FAKE_VIRT_MEMORY_MB + FAKE_VIRT_MEMORY_OVERHEAD, 'memory_mb_used') self._fake_flavor_create(id=2, memory_mb=1, root_gb=1, ephemeral_gb=1, vcpus=1) '1-2-3-4-5': {'memory_mb': 4, 'uuid': '1-2-3-4-5'}, '2-3-4-5-6': {'memory_mb': 4, 'uuid': '2-3-4-5-6'}, # 2 instances, 4 mb each, plus overhead self.assertEqual(8 + 2 * FAKE_VIRT_MEMORY_OVERHEAD,",115,95
openstack%2Fbarbican~master~I0100b5f68fac663035366a348651a31ba09f1470,openstack/barbican,master,I0100b5f68fac663035366a348651a31ba09f1470,"Adding more msgs, checking admin/non-admin endpoints",MERGED,2014-03-05 17:59:17.000000000,2014-03-06 17:53:08.000000000,2014-03-06 17:53:08.000000000,"[{'_account_id': 3}, {'_account_id': 994}, {'_account_id': 7136}, {'_account_id': 7355}, {'_account_id': 7789}, {'_account_id': 7973}]","[{'number': 1, 'created': '2014-03-05 17:59:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/barbican/commit/260e2fd1246e38e020c377668f7c4a12496d96fc', 'message': 'Adding success message to sanity check and verifying auth in return\n\nChange-Id: I0100b5f68fac663035366a348651a31ba09f1470\n'}, {'number': 2, 'created': '2014-03-05 19:46:22.000000000', 'files': ['functionaltests/run_tests.sh'], 'web_link': 'https://opendev.org/openstack/barbican/commit/3e70c223a3c2fbf40c10d493c23c57a6db99476e', 'message': 'Adding more msgs, checking admin/non-admin endpoints\n\nChange-Id: I0100b5f68fac663035366a348651a31ba09f1470\n'}]",2,78331,3e70c223a3c2fbf40c10d493c23c57a6db99476e,16,6,2,7136,,,0,"Adding more msgs, checking admin/non-admin endpoints

Change-Id: I0100b5f68fac663035366a348651a31ba09f1470
",git fetch https://review.opendev.org/openstack/barbican refs/changes/31/78331/2 && git format-patch -1 --stdout FETCH_HEAD,['functionaltests/run_tests.sh'],1,260e2fd1246e38e020c377668f7c4a12496d96fc,Add-Sanity-Check-Message,"if ! timeout ${API_RESPONDING_TIMEOUT} sh -c ""while ! curl -s http://127.0.0.1:9311/ 2>/dev/null | grep -q 'Auth' ; do sleep 1; done""; then echo ""The Barbican API failed to respond within ${API_RESPONDING_TIMEOUT} seconds""echo ""Successfully contacted the Barbican API"" ","if ! timeout ${API_RESPONDING_TIMEOUT} sh -c ""while ! curl -s -o /dev/null http://127.0.0.1:9311/ ; do sleep 1; done""; then echo ""API failed to respond within ${API_RESPONDING_TIMEOUT} seconds""",4,2
openstack%2Fceilometer~master~Ie5730892c8e83ad5e03a93f0ad65a27fff6b6f21,openstack/ceilometer,master,Ie5730892c8e83ad5e03a93f0ad65a27fff6b6f21,DO NOT MERGE,ABANDONED,2014-03-05 17:32:51.000000000,2014-03-06 17:50:49.000000000,,"[{'_account_id': 3}, {'_account_id': 6537}]","[{'number': 1, 'created': '2014-03-05 17:32:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/ca15723e5520a61d8357a60d53536ee03533fb9f', 'message': 'DO NOT MERGE\n\ntesting notification\n\nChange-Id: Ie5730892c8e83ad5e03a93f0ad65a27fff6b6f21\n'}, {'number': 2, 'created': '2014-03-05 21:26:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/d93822bcee14d0ef966bf8c7d0f7551162c9bd73', 'message': 'DO NOT MERGE\n\ntesting notification\n\nChange-Id: Ie5730892c8e83ad5e03a93f0ad65a27fff6b6f21\n'}, {'number': 3, 'created': '2014-03-05 22:10:04.000000000', 'files': ['ceilometer/storage/impl_sqlalchemy.py', 'ceilometer/notification.py'], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/8305f4e81b5bb5fe9dd45de1b4cedf38098b221b', 'message': 'DO NOT MERGE\n\ntesting notification\n\nChange-Id: Ie5730892c8e83ad5e03a93f0ad65a27fff6b6f21\n'}]",0,78318,8305f4e81b5bb5fe9dd45de1b4cedf38098b221b,8,2,3,6537,,,0,"DO NOT MERGE

testing notification

Change-Id: Ie5730892c8e83ad5e03a93f0ad65a27fff6b6f21
",git fetch https://review.opendev.org/openstack/ceilometer refs/changes/18/78318/3 && git format-patch -1 --stdout FETCH_HEAD,['ceilometer/notification.py'],1,ca15723e5520a61d8357a60d53536ee03533fb9f,test," LOG.audit(_('notification %r'), notification.get('event_type'))"," LOG.debug(_('notification %r'), notification.get('event_type'))",1,1
openstack%2Fneutron~master~Ia38baf018f201f8c1bfac3363e93587d491accb4,openstack/neutron,master,Ia38baf018f201f8c1bfac3363e93587d491accb4,Imported Translations from Transifex,MERGED,2014-03-05 06:28:06.000000000,2014-03-06 17:44:16.000000000,2014-03-06 17:44:15.000000000,"[{'_account_id': 3}, {'_account_id': 748}, {'_account_id': 2592}, {'_account_id': 4395}, {'_account_id': 5170}, {'_account_id': 9008}, {'_account_id': 9845}, {'_account_id': 9846}, {'_account_id': 9925}, {'_account_id': 10116}, {'_account_id': 10117}, {'_account_id': 10153}, {'_account_id': 10184}, {'_account_id': 10294}]","[{'number': 1, 'created': '2014-03-05 06:28:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/cacf6a718a62257e745515e75ffd444685d26046', 'message': 'Imported Translations from Transifex\n\nChange-Id: Ia38baf018f201f8c1bfac3363e93587d491accb4\n'}, {'number': 2, 'created': '2014-03-06 06:29:25.000000000', 'files': ['neutron/locale/fil/LC_MESSAGES/neutron.po', 'neutron/locale/is_IS/LC_MESSAGES/neutron.po', 'neutron/locale/ka_GE/LC_MESSAGES/neutron.po', 'neutron/locale/ar/LC_MESSAGES/neutron.po', 'neutron/locale/cs/LC_MESSAGES/neutron.po', 'neutron/locale/sl_SI/LC_MESSAGES/neutron.po', 'neutron/locale/id/LC_MESSAGES/neutron.po', 'neutron/locale/eu_ES/LC_MESSAGES/neutron.po', 'neutron/locale/zh_CN/LC_MESSAGES/neutron.po', 'neutron/locale/ko/LC_MESSAGES/neutron.po', 'neutron/locale/ja/LC_MESSAGES/neutron.po', 'neutron/locale/ko_KR/LC_MESSAGES/neutron.po', 'neutron/locale/es_MX/LC_MESSAGES/neutron.po', 'neutron/locale/sk/LC_MESSAGES/neutron.po', 'neutron/locale/bn_IN/LC_MESSAGES/neutron.po', 'neutron/locale/ca/LC_MESSAGES/neutron.po', 'neutron/locale/sv/LC_MESSAGES/neutron.po', 'neutron/locale/kn/LC_MESSAGES/neutron.po', 'neutron/locale/fr/LC_MESSAGES/neutron.po', 'neutron/locale/gl/LC_MESSAGES/neutron.po', 'neutron/locale/zh_TW/LC_MESSAGES/neutron.po', 'neutron/locale/hi/LC_MESSAGES/neutron.po', 'neutron/locale/he/LC_MESSAGES/neutron.po', 'neutron/locale/eu/LC_MESSAGES/neutron.po', 'neutron/locale/pl_PL/LC_MESSAGES/neutron.po', 'neutron/locale/tl/LC_MESSAGES/neutron.po', 'neutron/locale/ru/LC_MESSAGES/neutron.po', 'neutron/locale/pt_BR/LC_MESSAGES/neutron.po', 'neutron/locale/it/LC_MESSAGES/neutron.po', 'neutron/locale/nb/LC_MESSAGES/neutron.po', 'neutron/locale/ro/LC_MESSAGES/neutron.po', 'neutron/locale/uk/LC_MESSAGES/neutron.po', 'neutron/locale/tr_TR/LC_MESSAGES/neutron.po', 'neutron/locale/en_GB/LC_MESSAGES/neutron.po', 'neutron/locale/bg_BG/LC_MESSAGES/neutron.po', 'neutron/locale/he_IL/LC_MESSAGES/neutron.po', 'neutron/locale/hr/LC_MESSAGES/neutron.po', 'neutron/locale/hu/LC_MESSAGES/neutron.po', 'neutron/locale/it_IT/LC_MESSAGES/neutron.po', 'neutron/locale/ur/LC_MESSAGES/neutron.po', 'neutron/locale/pa_IN/LC_MESSAGES/neutron.po', 'neutron/locale/neutron.pot', 'neutron/locale/en_AU/LC_MESSAGES/neutron.po', 'neutron/locale/bs/LC_MESSAGES/neutron.po', 'neutron/locale/ml_IN/LC_MESSAGES/neutron.po', 'neutron/locale/km/LC_MESSAGES/neutron.po', 'neutron/locale/en_US/LC_MESSAGES/neutron.po', 'neutron/locale/fi_FI/LC_MESSAGES/neutron.po', 'neutron/locale/fa/LC_MESSAGES/neutron.po', 'neutron/locale/es/LC_MESSAGES/neutron.po', 'neutron/locale/ms/LC_MESSAGES/neutron.po', 'neutron/locale/vi_VN/LC_MESSAGES/neutron.po', 'neutron/locale/zh_HK/LC_MESSAGES/neutron.po', 'neutron/locale/ne/LC_MESSAGES/neutron.po', 'neutron/locale/ru_RU/LC_MESSAGES/neutron.po', 'neutron/locale/de/LC_MESSAGES/neutron.po', 'neutron/locale/pt/LC_MESSAGES/neutron.po', 'neutron/locale/mr_IN/LC_MESSAGES/neutron.po', 'neutron/locale/da/LC_MESSAGES/neutron.po', 'neutron/locale/nl_NL/LC_MESSAGES/neutron.po', 'neutron/locale/tl_PH/LC_MESSAGES/neutron.po', 'neutron/locale/sw_KE/LC_MESSAGES/neutron.po'], 'web_link': 'https://opendev.org/openstack/neutron/commit/ecabc629cc392ce7c31a34b6c6073322c4ed3214', 'message': 'Imported Translations from Transifex\n\nChange-Id: Ia38baf018f201f8c1bfac3363e93587d491accb4\n'}]",0,78114,ecabc629cc392ce7c31a34b6c6073322c4ed3214,32,14,2,3,,,0,"Imported Translations from Transifex

Change-Id: Ia38baf018f201f8c1bfac3363e93587d491accb4
",git fetch https://review.opendev.org/openstack/neutron refs/changes/14/78114/2 && git format-patch -1 --stdout FETCH_HEAD,"['neutron/locale/fil/LC_MESSAGES/neutron.po', 'neutron/locale/is_IS/LC_MESSAGES/neutron.po', 'neutron/locale/ka_GE/LC_MESSAGES/neutron.po', 'neutron/locale/ar/LC_MESSAGES/neutron.po', 'neutron/locale/cs/LC_MESSAGES/neutron.po', 'neutron/locale/sl_SI/LC_MESSAGES/neutron.po', 'neutron/locale/id/LC_MESSAGES/neutron.po', 'neutron/locale/eu_ES/LC_MESSAGES/neutron.po', 'neutron/locale/zh_CN/LC_MESSAGES/neutron.po', 'neutron/locale/ko/LC_MESSAGES/neutron.po', 'neutron/locale/ja/LC_MESSAGES/neutron.po', 'neutron/locale/ko_KR/LC_MESSAGES/neutron.po', 'neutron/locale/es_MX/LC_MESSAGES/neutron.po', 'neutron/locale/sk/LC_MESSAGES/neutron.po', 'neutron/locale/bn_IN/LC_MESSAGES/neutron.po', 'neutron/locale/ca/LC_MESSAGES/neutron.po', 'neutron/locale/sv/LC_MESSAGES/neutron.po', 'neutron/locale/kn/LC_MESSAGES/neutron.po', 'neutron/locale/fr/LC_MESSAGES/neutron.po', 'neutron/locale/gl/LC_MESSAGES/neutron.po', 'neutron/locale/zh_TW/LC_MESSAGES/neutron.po', 'neutron/locale/hi/LC_MESSAGES/neutron.po', 'neutron/locale/he/LC_MESSAGES/neutron.po', 'neutron/locale/eu/LC_MESSAGES/neutron.po', 'neutron/locale/pl_PL/LC_MESSAGES/neutron.po', 'neutron/locale/tl/LC_MESSAGES/neutron.po', 'neutron/locale/ru/LC_MESSAGES/neutron.po', 'neutron/locale/pt_BR/LC_MESSAGES/neutron.po', 'neutron/locale/it/LC_MESSAGES/neutron.po', 'neutron/locale/nb/LC_MESSAGES/neutron.po', 'neutron/locale/ro/LC_MESSAGES/neutron.po', 'neutron/locale/uk/LC_MESSAGES/neutron.po', 'neutron/locale/tr_TR/LC_MESSAGES/neutron.po', 'neutron/locale/en_GB/LC_MESSAGES/neutron.po', 'neutron/locale/bg_BG/LC_MESSAGES/neutron.po', 'neutron/locale/he_IL/LC_MESSAGES/neutron.po', 'neutron/locale/hr/LC_MESSAGES/neutron.po', 'neutron/locale/hu/LC_MESSAGES/neutron.po', 'neutron/locale/it_IT/LC_MESSAGES/neutron.po', 'neutron/locale/ur/LC_MESSAGES/neutron.po', 'neutron/locale/pa_IN/LC_MESSAGES/neutron.po', 'neutron/locale/neutron.pot', 'neutron/locale/en_AU/LC_MESSAGES/neutron.po', 'neutron/locale/bs/LC_MESSAGES/neutron.po', 'neutron/locale/ml_IN/LC_MESSAGES/neutron.po', 'neutron/locale/km/LC_MESSAGES/neutron.po', 'neutron/locale/en_US/LC_MESSAGES/neutron.po', 'neutron/locale/fi_FI/LC_MESSAGES/neutron.po', 'neutron/locale/fa/LC_MESSAGES/neutron.po', 'neutron/locale/es/LC_MESSAGES/neutron.po', 'neutron/locale/ms/LC_MESSAGES/neutron.po', 'neutron/locale/vi_VN/LC_MESSAGES/neutron.po', 'neutron/locale/zh_HK/LC_MESSAGES/neutron.po', 'neutron/locale/ne/LC_MESSAGES/neutron.po', 'neutron/locale/ru_RU/LC_MESSAGES/neutron.po', 'neutron/locale/de/LC_MESSAGES/neutron.po', 'neutron/locale/pt/LC_MESSAGES/neutron.po', 'neutron/locale/mr_IN/LC_MESSAGES/neutron.po', 'neutron/locale/da/LC_MESSAGES/neutron.po', 'neutron/locale/nl_NL/LC_MESSAGES/neutron.po', 'neutron/locale/tl_PH/LC_MESSAGES/neutron.po', 'neutron/locale/sw_KE/LC_MESSAGES/neutron.po']",62,cacf6a718a62257e745515e75ffd444685d26046,transifex/translations,"""POT-Creation-Date: 2014-03-05 06:25+0000\n""#: neutron/plugins/linuxbridge/agent/linuxbridge_neutron_agent.py:797 #: neutron/plugins/mlnx/agent/eswitch_neutron_agent.py:256#: neutron/plugins/linuxbridge/agent/linuxbridge_neutron_agent.py:618#: neutron/plugins/bigswitch/plugin.py:134 neutron/plugins/ml2/db.py:100#: neutron/plugins/mlnx/agent/eswitch_neutron_agent.py:405#: neutron/plugins/linuxbridge/agent/linuxbridge_neutron_agent.py:963#: neutron/plugins/cisco/db/n1kv_db_v2.py:946#: neutron/plugins/cisco/db/n1kv_db_v2.py:963#: neutron/plugins/cisco/db/n1kv_db_v2.py:971#: neutron/plugins/cisco/db/n1kv_db_v2.py:981#: neutron/plugins/cisco/db/n1kv_db_v2.py:988#: neutron/plugins/cisco/db/n1kv_db_v2.py:1002#: neutron/plugins/cisco/db/n1kv_db_v2.py:1226#: neutron/plugins/cisco/db/n1kv_db_v2.py:1236#: neutron/plugins/cisco/db/n1kv_db_v2.py:1245#: neutron/plugins/cisco/db/n1kv_db_v2.py:1251#: neutron/plugins/cisco/db/n1kv_db_v2.py:1258#: neutron/plugins/cisco/db/n1kv_db_v2.py:1265#: neutron/plugins/cisco/db/n1kv_db_v2.py:1296#: neutron/plugins/cisco/db/n1kv_db_v2.py:1313#: neutron/plugins/linuxbridge/agent/linuxbridge_neutron_agent.py:622#: neutron/plugins/mlnx/agent/eswitch_neutron_agent.py:208 #: neutron/plugins/mlnx/agent/eswitch_neutron_agent.py:321#: neutron/plugins/linuxbridge/agent/linuxbridge_neutron_agent.py:937 #: neutron/plugins/mlnx/agent/eswitch_neutron_agent.py:389#: neutron/plugins/linuxbridge/agent/linuxbridge_neutron_agent.py:949#: neutron/plugins/mlnx/agent/eswitch_neutron_agent.py:412#: neutron/plugins/linuxbridge/agent/linuxbridge_neutron_agent.py:988#: neutron/plugins/ml2/rpc.py:171 neutron/plugins/ml2/rpc.py:193#: neutron/plugins/linuxbridge/agent/linuxbridge_neutron_agent.py:85#: neutron/plugins/linuxbridge/agent/linuxbridge_neutron_agent.py:108#: neutron/plugins/linuxbridge/agent/linuxbridge_neutron_agent.py:115#: neutron/plugins/linuxbridge/agent/linuxbridge_neutron_agent.py:122#: neutron/plugins/linuxbridge/agent/linuxbridge_neutron_agent.py:131#: neutron/plugins/linuxbridge/agent/linuxbridge_neutron_agent.py:192#: neutron/plugins/linuxbridge/agent/linuxbridge_neutron_agent.py:224#: neutron/plugins/linuxbridge/agent/linuxbridge_neutron_agent.py:237#: neutron/plugins/linuxbridge/agent/linuxbridge_neutron_agent.py:244#: neutron/plugins/linuxbridge/agent/linuxbridge_neutron_agent.py:259#: neutron/plugins/linuxbridge/agent/linuxbridge_neutron_agent.py:294#: neutron/plugins/linuxbridge/agent/linuxbridge_neutron_agent.py:309#: neutron/plugins/linuxbridge/agent/linuxbridge_neutron_agent.py:331#: neutron/plugins/linuxbridge/agent/linuxbridge_neutron_agent.py:344#: neutron/plugins/linuxbridge/agent/linuxbridge_neutron_agent.py:351#: neutron/plugins/linuxbridge/agent/linuxbridge_neutron_agent.py:360#: neutron/plugins/linuxbridge/agent/linuxbridge_neutron_agent.py:372#: neutron/plugins/linuxbridge/agent/linuxbridge_neutron_agent.py:390#: neutron/plugins/linuxbridge/agent/linuxbridge_neutron_agent.py:399#: neutron/plugins/linuxbridge/agent/linuxbridge_neutron_agent.py:437#: neutron/plugins/linuxbridge/agent/linuxbridge_neutron_agent.py:444#: neutron/plugins/linuxbridge/agent/linuxbridge_neutron_agent.py:447#: neutron/plugins/linuxbridge/agent/linuxbridge_neutron_agent.py:461#: neutron/plugins/linuxbridge/agent/linuxbridge_neutron_agent.py:468#: neutron/plugins/linuxbridge/agent/linuxbridge_neutron_agent.py:474#: neutron/plugins/linuxbridge/agent/linuxbridge_neutron_agent.py:482#: neutron/plugins/linuxbridge/agent/linuxbridge_neutron_agent.py:489#: neutron/plugins/linuxbridge/agent/linuxbridge_neutron_agent.py:493#: neutron/plugins/linuxbridge/agent/linuxbridge_neutron_agent.py:498#: neutron/plugins/linuxbridge/agent/linuxbridge_neutron_agent.py:534#: neutron/plugins/linuxbridge/agent/linuxbridge_neutron_agent.py:538#: neutron/plugins/linuxbridge/agent/linuxbridge_neutron_agent.py:540#: neutron/plugins/linuxbridge/agent/linuxbridge_neutron_agent.py:615#: neutron/plugins/linuxbridge/agent/linuxbridge_neutron_agent.py:672 #: neutron/plugins/mlnx/agent/eswitch_neutron_agent.py:206#: neutron/plugins/linuxbridge/agent/linuxbridge_neutron_agent.py:675#: neutron/plugins/linuxbridge/agent/linuxbridge_neutron_agent.py:697#: neutron/plugins/linuxbridge/agent/linuxbridge_neutron_agent.py:719#: neutron/plugins/linuxbridge/agent/linuxbridge_neutron_agent.py:744#: neutron/plugins/linuxbridge/agent/linuxbridge_neutron_agent.py:807#: neutron/plugins/linuxbridge/agent/linuxbridge_neutron_agent.py:811 #: neutron/plugins/mlnx/agent/eswitch_neutron_agent.py:260#: neutron/plugins/linuxbridge/agent/linuxbridge_neutron_agent.py:860#: neutron/plugins/linuxbridge/agent/linuxbridge_neutron_agent.py:866#: neutron/plugins/linuxbridge/agent/linuxbridge_neutron_agent.py:872#: neutron/plugins/linuxbridge/agent/linuxbridge_neutron_agent.py:904 #: neutron/plugins/linuxbridge/agent/linuxbridge_neutron_agent.py:924 #: neutron/plugins/mlnx/agent/eswitch_neutron_agent.py:375#: neutron/plugins/linuxbridge/agent/linuxbridge_neutron_agent.py:911#: neutron/plugins/linuxbridge/agent/linuxbridge_neutron_agent.py:918#: neutron/plugins/linuxbridge/agent/linuxbridge_neutron_agent.py:922 #: neutron/plugins/mlnx/agent/eswitch_neutron_agent.py:373#: neutron/plugins/linuxbridge/agent/linuxbridge_neutron_agent.py:932#: neutron/plugins/linuxbridge/agent/linuxbridge_neutron_agent.py:944#: neutron/plugins/linuxbridge/agent/linuxbridge_neutron_agent.py:955#: neutron/plugins/linuxbridge/agent/linuxbridge_neutron_agent.py:978 #: neutron/plugins/mlnx/agent/eswitch_neutron_agent.py:427#: neutron/plugins/linuxbridge/agent/linuxbridge_neutron_agent.py:981 #: neutron/plugins/mlnx/agent/eswitch_neutron_agent.py:430#: neutron/plugins/ml2/db.py:91 #, python-format msgid ""get_port_from_device_mac() called for mac %s"" msgstr """" #: neutron/plugins/ml2/db.py:133#: neutron/plugins/ml2/rpc.py:93#: neutron/plugins/ml2/rpc.py:102#: neutron/plugins/ml2/rpc.py:109#: neutron/plugins/ml2/rpc.py:119#: neutron/plugins/ml2/rpc.py:130#: neutron/plugins/ml2/rpc.py:150#: neutron/plugins/ml2/rpc.py:164#: neutron/plugins/ml2/rpc.py:188#: neutron/plugins/ml2/drivers/mlnx/config.py:24 #: neutron/plugins/mlnx/common/config.py:50 msgid ""Type of VM network interface: mlnx_direct or hostdev"" msgstr """" #: neutron/plugins/ml2/drivers/mlnx/mech_mlnx.py:54 #, python-format msgid ""Checking segment: %(segment)s for mappings: %(mappings)s "" msgstr """" #: neutron/plugins/mlnx/agent/eswitch_neutron_agent.py:298#: neutron/plugins/mlnx/agent/eswitch_neutron_agent.py:301#: neutron/plugins/mlnx/agent/eswitch_neutron_agent.py:326#: neutron/plugins/mlnx/agent/eswitch_neutron_agent.py:333#: neutron/plugins/mlnx/agent/eswitch_neutron_agent.py:339#: neutron/plugins/mlnx/agent/eswitch_neutron_agent.py:340#: neutron/plugins/mlnx/agent/eswitch_neutron_agent.py:353#: neutron/plugins/mlnx/agent/eswitch_neutron_agent.py:360#: neutron/plugins/mlnx/agent/eswitch_neutron_agent.py:368#: neutron/plugins/mlnx/agent/eswitch_neutron_agent.py:383#: neutron/plugins/mlnx/agent/eswitch_neutron_agent.py:396#: neutron/plugins/mlnx/agent/eswitch_neutron_agent.py:401#: neutron/plugins/mlnx/agent/eswitch_neutron_agent.py:435#: neutron/plugins/mlnx/agent/eswitch_neutron_agent.py:440msgid ""Logical switch for neutron network %s not found on NSX.""msgid ""Logical router for neutron router %s not found on NSX.""msgid ""Logical switch port for neutron port %s not found on NSX.""""%(num_requests)d round-trips to NSX for fetching data. Please tune sync ""msgid ""Fetching up to %s resources from NSX backend""""An error occurred while communicating with NSX backend. Will retry ""msgid ""Time elapsed querying NSX: %s""#: neutron/plugins/vmware/nsxlib/__init__.py:78#: neutron/plugins/vmware/nsxlib/__init__.py:82#~ msgid ""_get_profile_binding"" #~ msgstr """" #~ msgid ""Logical switch for neutron network %s not found on NVP."" #~ msgstr """" #~ msgid ""Logical router for neutron router %s not found on NVP."" #~ msgstr """" #~ msgid ""Logical switch port for neutron port %s not found on NVP.""#~ ""Requested page size is %(cur_chunk_size)d.It"" #~ "" might be necessary to do "" #~ ""%(num_requests)d round-trips to NVP for"" #~ "" fetching data. Please tune sync "" #~ ""parameters to ensure chunk size is "" #~ ""less than %(max_page_size)d"" #~ msgstr """" #~ msgid ""Fetching up to %s resources from NVP backend""#~ ""An error occurred while communicating "" #~ ""with NVP backend. Will retry "" #~ ""synchronization in %d seconds""#~ msgid ""Time elapsed querying NVP: %s""","""POT-Creation-Date: 2014-03-04 06:25+0000\n""#: neutron/plugins/linuxbridge/agent/linuxbridge_neutron_agent.py:809 #: neutron/plugins/mlnx/agent/eswitch_neutron_agent.py:253#: neutron/plugins/linuxbridge/agent/linuxbridge_neutron_agent.py:630#: neutron/plugins/bigswitch/plugin.py:134 neutron/plugins/ml2/db.py:93#: neutron/plugins/mlnx/agent/eswitch_neutron_agent.py:401#: neutron/plugins/linuxbridge/agent/linuxbridge_neutron_agent.py:975#: neutron/plugins/cisco/db/n1kv_db_v2.py:945#: neutron/plugins/cisco/db/n1kv_db_v2.py:961#: neutron/plugins/cisco/db/n1kv_db_v2.py:968 msgid ""_get_profile_binding"" msgstr """" #: neutron/plugins/cisco/db/n1kv_db_v2.py:976#: neutron/plugins/cisco/db/n1kv_db_v2.py:985#: neutron/plugins/cisco/db/n1kv_db_v2.py:992#: neutron/plugins/cisco/db/n1kv_db_v2.py:1006#: neutron/plugins/cisco/db/n1kv_db_v2.py:1220#: neutron/plugins/cisco/db/n1kv_db_v2.py:1230#: neutron/plugins/cisco/db/n1kv_db_v2.py:1239#: neutron/plugins/cisco/db/n1kv_db_v2.py:1245#: neutron/plugins/cisco/db/n1kv_db_v2.py:1252#: neutron/plugins/cisco/db/n1kv_db_v2.py:1259#: neutron/plugins/cisco/db/n1kv_db_v2.py:1288#: neutron/plugins/cisco/db/n1kv_db_v2.py:1305#: neutron/plugins/linuxbridge/agent/linuxbridge_neutron_agent.py:634#: neutron/plugins/mlnx/agent/eswitch_neutron_agent.py:206 #: neutron/plugins/mlnx/agent/eswitch_neutron_agent.py:318#: neutron/plugins/linuxbridge/agent/linuxbridge_neutron_agent.py:949 #: neutron/plugins/mlnx/agent/eswitch_neutron_agent.py:385#: neutron/plugins/linuxbridge/agent/linuxbridge_neutron_agent.py:961#: neutron/plugins/mlnx/agent/eswitch_neutron_agent.py:408#: neutron/plugins/linuxbridge/agent/linuxbridge_neutron_agent.py:1000#: neutron/plugins/ml2/rpc.py:164 neutron/plugins/ml2/rpc.py:186#: neutron/plugins/linuxbridge/agent/linuxbridge_neutron_agent.py:86#: neutron/plugins/linuxbridge/agent/linuxbridge_neutron_agent.py:113#: neutron/plugins/linuxbridge/agent/linuxbridge_neutron_agent.py:120#: neutron/plugins/linuxbridge/agent/linuxbridge_neutron_agent.py:127#: neutron/plugins/linuxbridge/agent/linuxbridge_neutron_agent.py:136#: neutron/plugins/linuxbridge/agent/linuxbridge_neutron_agent.py:197#: neutron/plugins/linuxbridge/agent/linuxbridge_neutron_agent.py:229#: neutron/plugins/linuxbridge/agent/linuxbridge_neutron_agent.py:242#: neutron/plugins/linuxbridge/agent/linuxbridge_neutron_agent.py:249#: neutron/plugins/linuxbridge/agent/linuxbridge_neutron_agent.py:264#: neutron/plugins/linuxbridge/agent/linuxbridge_neutron_agent.py:299#: neutron/plugins/linuxbridge/agent/linuxbridge_neutron_agent.py:314#: neutron/plugins/linuxbridge/agent/linuxbridge_neutron_agent.py:336#: neutron/plugins/linuxbridge/agent/linuxbridge_neutron_agent.py:349#: neutron/plugins/linuxbridge/agent/linuxbridge_neutron_agent.py:356#: neutron/plugins/linuxbridge/agent/linuxbridge_neutron_agent.py:365#: neutron/plugins/linuxbridge/agent/linuxbridge_neutron_agent.py:377#: neutron/plugins/linuxbridge/agent/linuxbridge_neutron_agent.py:395#: neutron/plugins/linuxbridge/agent/linuxbridge_neutron_agent.py:404#: neutron/plugins/linuxbridge/agent/linuxbridge_neutron_agent.py:442#: neutron/plugins/linuxbridge/agent/linuxbridge_neutron_agent.py:449#: neutron/plugins/linuxbridge/agent/linuxbridge_neutron_agent.py:452#: neutron/plugins/linuxbridge/agent/linuxbridge_neutron_agent.py:466#: neutron/plugins/linuxbridge/agent/linuxbridge_neutron_agent.py:473#: neutron/plugins/linuxbridge/agent/linuxbridge_neutron_agent.py:479#: neutron/plugins/linuxbridge/agent/linuxbridge_neutron_agent.py:487#: neutron/plugins/linuxbridge/agent/linuxbridge_neutron_agent.py:494#: neutron/plugins/linuxbridge/agent/linuxbridge_neutron_agent.py:498#: neutron/plugins/linuxbridge/agent/linuxbridge_neutron_agent.py:503#: neutron/plugins/linuxbridge/agent/linuxbridge_neutron_agent.py:546#: neutron/plugins/linuxbridge/agent/linuxbridge_neutron_agent.py:550#: neutron/plugins/linuxbridge/agent/linuxbridge_neutron_agent.py:552#: neutron/plugins/linuxbridge/agent/linuxbridge_neutron_agent.py:627#: neutron/plugins/linuxbridge/agent/linuxbridge_neutron_agent.py:684 #: neutron/plugins/mlnx/agent/eswitch_neutron_agent.py:204#: neutron/plugins/linuxbridge/agent/linuxbridge_neutron_agent.py:687#: neutron/plugins/linuxbridge/agent/linuxbridge_neutron_agent.py:709#: neutron/plugins/linuxbridge/agent/linuxbridge_neutron_agent.py:731#: neutron/plugins/linuxbridge/agent/linuxbridge_neutron_agent.py:756#: neutron/plugins/linuxbridge/agent/linuxbridge_neutron_agent.py:819#: neutron/plugins/linuxbridge/agent/linuxbridge_neutron_agent.py:823 #: neutron/plugins/mlnx/agent/eswitch_neutron_agent.py:257#: neutron/plugins/linuxbridge/agent/linuxbridge_neutron_agent.py:872#: neutron/plugins/linuxbridge/agent/linuxbridge_neutron_agent.py:878#: neutron/plugins/linuxbridge/agent/linuxbridge_neutron_agent.py:884#: neutron/plugins/linuxbridge/agent/linuxbridge_neutron_agent.py:916 #: neutron/plugins/linuxbridge/agent/linuxbridge_neutron_agent.py:936 #: neutron/plugins/mlnx/agent/eswitch_neutron_agent.py:371#: neutron/plugins/linuxbridge/agent/linuxbridge_neutron_agent.py:923#: neutron/plugins/linuxbridge/agent/linuxbridge_neutron_agent.py:930#: neutron/plugins/linuxbridge/agent/linuxbridge_neutron_agent.py:934 #: neutron/plugins/mlnx/agent/eswitch_neutron_agent.py:369#: neutron/plugins/linuxbridge/agent/linuxbridge_neutron_agent.py:944#: neutron/plugins/linuxbridge/agent/linuxbridge_neutron_agent.py:956#: neutron/plugins/linuxbridge/agent/linuxbridge_neutron_agent.py:967#: neutron/plugins/linuxbridge/agent/linuxbridge_neutron_agent.py:990 #: neutron/plugins/mlnx/agent/eswitch_neutron_agent.py:423#: neutron/plugins/linuxbridge/agent/linuxbridge_neutron_agent.py:993 #: neutron/plugins/mlnx/agent/eswitch_neutron_agent.py:426#: neutron/plugins/ml2/db.py:126#: neutron/plugins/ml2/rpc.py:86#: neutron/plugins/ml2/rpc.py:95#: neutron/plugins/ml2/rpc.py:102#: neutron/plugins/ml2/rpc.py:112#: neutron/plugins/ml2/rpc.py:123#: neutron/plugins/ml2/rpc.py:143#: neutron/plugins/ml2/rpc.py:157#: neutron/plugins/ml2/rpc.py:181#: neutron/plugins/mlnx/agent/eswitch_neutron_agent.py:295#: neutron/plugins/mlnx/agent/eswitch_neutron_agent.py:298#: neutron/plugins/mlnx/agent/eswitch_neutron_agent.py:323#: neutron/plugins/mlnx/agent/eswitch_neutron_agent.py:330#: neutron/plugins/mlnx/agent/eswitch_neutron_agent.py:336#: neutron/plugins/mlnx/agent/eswitch_neutron_agent.py:337#: neutron/plugins/mlnx/agent/eswitch_neutron_agent.py:350#: neutron/plugins/mlnx/agent/eswitch_neutron_agent.py:357#: neutron/plugins/mlnx/agent/eswitch_neutron_agent.py:364#: neutron/plugins/mlnx/agent/eswitch_neutron_agent.py:379#: neutron/plugins/mlnx/agent/eswitch_neutron_agent.py:392#: neutron/plugins/mlnx/agent/eswitch_neutron_agent.py:397#: neutron/plugins/mlnx/agent/eswitch_neutron_agent.py:431#: neutron/plugins/mlnx/agent/eswitch_neutron_agent.py:436#: neutron/plugins/mlnx/common/config.py:50 msgid ""Type of VM network interface: mlnx_direct or hostdev"" msgstr """" msgid ""Logical switch for neutron network %s not found on NVP.""msgid ""Logical router for neutron router %s not found on NVP.""msgid ""Logical switch port for neutron port %s not found on NVP.""""%(num_requests)d round-trips to NVP for fetching data. Please tune sync ""msgid ""Fetching up to %s resources from NVP backend""""An error occurred while communicating with NVP backend. Will retry ""msgid ""Time elapsed querying NVP: %s""#: neutron/plugins/vmware/nsxlib/__init__.py:80#: neutron/plugins/vmware/nsxlib/__init__.py:84#~ msgid """" #~ ""Failed userspace version check for Open"" #~ "" vSwitch with VXLAN support. To use"" #~ "" VXLAN tunnels with OVS, please "" #~ ""ensure the OVS version is %s or"" #~ "" newer!""#~ ""Failed kernel version check for Open "" #~ ""vSwitch with VXLAN support. To use "" #~ ""VXLAN tunnels with OVS, please ensure"" #~ "" the OVS version is %s or "" #~ ""newer!""#~ ""Cannot determine kernel Open vSwitch "" #~ ""version, please ensure your Open vSwitch"" #~ "" kernel module is at least version"" #~ "" %s to support VXLAN tunnels.""#~ msgid """" #~ ""Unable to determine Open vSwitch "" #~ ""version. Please ensure that its version"" #~ "" is %s or newer to use VXLAN"" #~ "" tunnels with OVS.""",9837,9220
openstack%2Fheat~master~Ic9f1df06df25205f864b2f0138d2821089608b88,openstack/heat,master,Ic9f1df06df25205f864b2f0138d2821089608b88,Add test for StackUser._create_keypair,MERGED,2014-02-11 20:26:19.000000000,2014-03-06 17:44:08.000000000,2014-03-06 17:44:07.000000000,"[{'_account_id': 3}, {'_account_id': 4328}, {'_account_id': 4571}, {'_account_id': 7385}]","[{'number': 1, 'created': '2014-02-11 20:26:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/48cdc15b92785aa6ba8e6504e855142892076ac2', 'message': 'Add test for StackUser._create_keypair\n\nCurrently _create_keypair is only indirectly tested via SignalResponder\nso add a base-class-specific test.\n\nChange-Id: Ic9f1df06df25205f864b2f0138d2821089608b88\nblueprint: instance-users\n'}, {'number': 2, 'created': '2014-02-17 09:15:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/e0a5f496e81f5860d2ee1966674b9d0ca7a64670', 'message': 'Add test for StackUser._create_keypair\n\nCurrently _create_keypair is only indirectly tested via SignalResponder\nso add a base-class-specific test.\n\nChange-Id: Ic9f1df06df25205f864b2f0138d2821089608b88\nblueprint: instance-users\n'}, {'number': 3, 'created': '2014-02-18 19:31:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/8b917de7ad22a535606ea8e66ff309af6be8842a', 'message': 'Add test for StackUser._create_keypair\n\nCurrently _create_keypair is only indirectly tested via SignalResponder\nso add a base-class-specific test.\n\nChange-Id: Ic9f1df06df25205f864b2f0138d2821089608b88\nblueprint: instance-users\n'}, {'number': 4, 'created': '2014-02-24 23:12:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/1cc5e2b8f1fddde39ef5f238f77c79dda6319aeb', 'message': 'Add test for StackUser._create_keypair\n\nCurrently _create_keypair is only indirectly tested via SignalResponder\nso add a base-class-specific test.\n\nChange-Id: Ic9f1df06df25205f864b2f0138d2821089608b88\nblueprint: instance-users\n'}, {'number': 5, 'created': '2014-02-24 23:22:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/735749effa24e32cd1a28c6d5ee629112113b15f', 'message': 'Add test for StackUser._create_keypair\n\nCurrently _create_keypair is only indirectly tested via SignalResponder\nso add a base-class-specific test.\n\nChange-Id: Ic9f1df06df25205f864b2f0138d2821089608b88\nblueprint: instance-users\n'}, {'number': 6, 'created': '2014-02-25 11:24:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/b9e63e87b517aacc2dfdd791affbdcf6465a1c4b', 'message': 'Add test for StackUser._create_keypair\n\nCurrently _create_keypair is only indirectly tested via SignalResponder\nso add a base-class-specific test.\n\nChange-Id: Ic9f1df06df25205f864b2f0138d2821089608b88\nblueprint: instance-users\n'}, {'number': 7, 'created': '2014-02-25 13:49:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/6fe1bdcf61d561859b66b39e4cbddeee227a1319', 'message': 'Add test for StackUser._create_keypair\n\nCurrently _create_keypair is only indirectly tested via SignalResponder\nso add a base-class-specific test.\n\nChange-Id: Ic9f1df06df25205f864b2f0138d2821089608b88\nblueprint: instance-users\n'}, {'number': 8, 'created': '2014-02-27 13:09:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/e92e1fc5ae9e4c211a22277d41c8e4fa4875207a', 'message': 'Add test for StackUser._create_keypair\n\nCurrently _create_keypair is only indirectly tested via SignalResponder\nso add a base-class-specific test.\n\nChange-Id: Ic9f1df06df25205f864b2f0138d2821089608b88\nblueprint: instance-users\n'}, {'number': 9, 'created': '2014-02-28 08:29:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/7755c88aea6aa37df86724e7ad3584d26ec1746a', 'message': 'Add test for StackUser._create_keypair\n\nCurrently _create_keypair is only indirectly tested via SignalResponder\nso add a base-class-specific test.\n\nChange-Id: Ic9f1df06df25205f864b2f0138d2821089608b88\nblueprint: instance-users\n'}, {'number': 10, 'created': '2014-03-03 22:28:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/919192b2ee4e99191aacf98a89aeb1cd3bcf73b2', 'message': 'Add test for StackUser._create_keypair\n\nCurrently _create_keypair is only indirectly tested via SignalResponder\nso add a base-class-specific test.\n\nChange-Id: Ic9f1df06df25205f864b2f0138d2821089608b88\nblueprint: instance-users\n'}, {'number': 11, 'created': '2014-03-04 15:57:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/5808f7f0dff8a2387e2ad499251e1a3bc6494d3f', 'message': 'Add test for StackUser._create_keypair\n\nCurrently _create_keypair is only indirectly tested via SignalResponder\nso add a base-class-specific test.\n\nChange-Id: Ic9f1df06df25205f864b2f0138d2821089608b88\nblueprint: instance-users\n'}, {'number': 12, 'created': '2014-03-05 17:14:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/ab068556b0d012c7f4c336044dd0fdb165821afb', 'message': 'Add test for StackUser._create_keypair\n\nCurrently _create_keypair is only indirectly tested via SignalResponder\nso add a base-class-specific test.\n\nChange-Id: Ic9f1df06df25205f864b2f0138d2821089608b88\nblueprint: instance-users\n'}, {'number': 13, 'created': '2014-03-05 17:19:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/906cbf63b81c0429f692ac66fb2d48ab119613e0', 'message': 'Add test for StackUser._create_keypair\n\nCurrently _create_keypair is only indirectly tested via SignalResponder\nso add a base-class-specific test.\n\nChange-Id: Ic9f1df06df25205f864b2f0138d2821089608b88\nblueprint: instance-users\n'}, {'number': 14, 'created': '2014-03-05 17:48:03.000000000', 'files': ['heat/tests/test_stack_user.py'], 'web_link': 'https://opendev.org/openstack/heat/commit/117198442e7b31108ac251fb41df3d209ff5d79d', 'message': 'Add test for StackUser._create_keypair\n\nCurrently _create_keypair is only indirectly tested via SignalResponder\nso add a base-class-specific test.\n\nChange-Id: Ic9f1df06df25205f864b2f0138d2821089608b88\nblueprint: instance-users\n'}]",0,72761,117198442e7b31108ac251fb41df3d209ff5d79d,58,4,14,4328,,,0,"Add test for StackUser._create_keypair

Currently _create_keypair is only indirectly tested via SignalResponder
so add a base-class-specific test.

Change-Id: Ic9f1df06df25205f864b2f0138d2821089608b88
blueprint: instance-users
",git fetch https://review.opendev.org/openstack/heat refs/changes/61/72761/3 && git format-patch -1 --stdout FETCH_HEAD,['heat/tests/test_stack_user.py'],1,48cdc15b92785aa6ba8e6504e855142892076ac2,bug/1089261,"from heat.common import exception def test_create_keypair(self): rsrc = self._user_create(stack_name='user_testdel', project_id='aprojectdel', user_id='auserdel') # create_stack_domain_user_keypair(self, user_id, project_id): self.m.StubOutWithMock(fakes.FakeKeystoneClient, 'create_stack_domain_user_keypair') fakes.FakeKeystoneClient.create_stack_domain_user_keypair( user_id='auserdel', project_id='aprojectdel').AndReturn( self.fc.creds) self.m.ReplayAll() with utils.UUIDStub(self.resource_id): scheduler.TaskRunner(rsrc.create)() self.assertEqual((rsrc.CREATE, rsrc.COMPLETE), rsrc.state) kp = rsrc._create_keypair() self.assertEqual(self.fc.credential_id, kp.id) self.assertEqual(self.fc.access, kp.access) self.assertEqual(self.fc.secret, kp.secret) rs_data = db_api.resource_data_get_all(rsrc) self.assertEqual(self.fc.credential_id, rs_data['credential_id']) self.assertEqual(self.fc.access, rs_data['access_key']) self.assertEqual(self.fc.secret, rs_data['secret_key']) self.m.VerifyAll() def test_create_keypair_error(self): rsrc = self._user_create(stack_name='user_testdel', project_id='aprojectdel', user_id='auserdel') # create_stack_domain_user_keypair(self, user_id, project_id): self.m.StubOutWithMock(fakes.FakeKeystoneClient, 'create_stack_domain_user_keypair') fakes.FakeKeystoneClient.create_stack_domain_user_keypair( user_id='auserdel', project_id='aprojectdel').AndReturn(None) self.m.ReplayAll() with utils.UUIDStub(self.resource_id): scheduler.TaskRunner(rsrc.create)() self.assertEqual((rsrc.CREATE, rsrc.COMPLETE), rsrc.state) self.assertRaises(exception.Error, rsrc._create_keypair) self.m.VerifyAll()",,45,0
openstack%2Fheat~master~I3607ef71bfcd863b08879b3856baa92e7aeeef10,openstack/heat,master,I3607ef71bfcd863b08879b3856baa92e7aeeef10,StackUser add suspend/resume support,MERGED,2014-02-07 15:51:29.000000000,2014-03-06 17:43:59.000000000,2014-03-06 17:43:58.000000000,"[{'_account_id': 3}, {'_account_id': 3098}, {'_account_id': 4328}, {'_account_id': 4571}, {'_account_id': 7385}]","[{'number': 1, 'created': '2014-02-07 15:51:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/81a2f5376f922db0585c0f4f7406a5008cdd78cc', 'message': 'StackUser add suspend/resume support\n\nAdds suspend resume support which will be required to migrate the\nUser resource to this base class without losing functionality\n\nChange-Id: I3607ef71bfcd863b08879b3856baa92e7aeeef10\nblueprint: instance-users\n'}, {'number': 2, 'created': '2014-02-07 16:04:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/8929e0707d02ae9a9d452e0d1c184a0b1425500f', 'message': 'StackUser add suspend/resume support\n\nAdds suspend resume support which will be required to migrate the\nUser resource to this base class without losing functionality\n\nChange-Id: I3607ef71bfcd863b08879b3856baa92e7aeeef10\nblueprint: instance-users\n'}, {'number': 3, 'created': '2014-02-10 19:09:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/836a675d32a75a8383174e80b0c006a0caa19340', 'message': 'StackUser add suspend/resume support\n\nAdds suspend resume support which will be required to migrate the\nUser resource to this base class without losing functionality\n\nChange-Id: I3607ef71bfcd863b08879b3856baa92e7aeeef10\nblueprint: instance-users\n'}, {'number': 4, 'created': '2014-02-11 20:26:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/f05d5b620d06f882172a0f89dbd93d0a4d9f1cec', 'message': 'StackUser add suspend/resume support\n\nAdds suspend resume support which will be required to migrate the\nUser resource to this base class without losing functionality\n\nChange-Id: I3607ef71bfcd863b08879b3856baa92e7aeeef10\nblueprint: instance-users\n'}, {'number': 5, 'created': '2014-02-17 09:15:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/9bcaf36da28b49633374b7ad7baaea84997f998d', 'message': 'StackUser add suspend/resume support\n\nAdds suspend resume support which will be required to migrate the\nUser resource to this base class without losing functionality\n\nChange-Id: I3607ef71bfcd863b08879b3856baa92e7aeeef10\nblueprint: instance-users\n'}, {'number': 6, 'created': '2014-02-18 19:31:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/6c2f1ae8de777932c67dfc5e3441a5d88d699adf', 'message': 'StackUser add suspend/resume support\n\nAdds suspend resume support which will be required to migrate the\nUser resource to this base class without losing functionality\n\nChange-Id: I3607ef71bfcd863b08879b3856baa92e7aeeef10\nblueprint: instance-users\n'}, {'number': 7, 'created': '2014-02-24 23:12:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/70b5abc692fdd22e932e52d6c4dbc7c53c2d0155', 'message': 'StackUser add suspend/resume support\n\nAdds suspend resume support which will be required to migrate the\nUser resource to this base class without losing functionality\n\nChange-Id: I3607ef71bfcd863b08879b3856baa92e7aeeef10\nblueprint: instance-users\n'}, {'number': 8, 'created': '2014-02-24 23:22:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/4a5c1e160666518a0c887b574308155fd137cda8', 'message': 'StackUser add suspend/resume support\n\nAdds suspend resume support which will be required to migrate the\nUser resource to this base class without losing functionality\n\nChange-Id: I3607ef71bfcd863b08879b3856baa92e7aeeef10\nblueprint: instance-users\n'}, {'number': 9, 'created': '2014-02-25 11:24:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/93a592849d74f7c227d0ff0c9804d3c04f1778fd', 'message': 'StackUser add suspend/resume support\n\nAdds suspend resume support which will be required to migrate the\nUser resource to this base class without losing functionality\n\nChange-Id: I3607ef71bfcd863b08879b3856baa92e7aeeef10\nblueprint: instance-users\n'}, {'number': 10, 'created': '2014-02-25 13:49:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/26288cd42306b259a6a18910443432832ee88103', 'message': 'StackUser add suspend/resume support\n\nAdds suspend resume support which will be required to migrate the\nUser resource to this base class without losing functionality\n\nChange-Id: I3607ef71bfcd863b08879b3856baa92e7aeeef10\nblueprint: instance-users\n'}, {'number': 11, 'created': '2014-02-27 13:09:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/bcfd5d201a849ae3df972df1c0540d3c42f81b8c', 'message': 'StackUser add suspend/resume support\n\nAdds suspend resume support which will be required to migrate the\nUser resource to this base class without losing functionality\n\nChange-Id: I3607ef71bfcd863b08879b3856baa92e7aeeef10\nblueprint: instance-users\n'}, {'number': 12, 'created': '2014-02-28 08:29:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/e921350543b499b14dba587523cedeee56cb4613', 'message': 'StackUser add suspend/resume support\n\nAdds suspend resume support which will be required to migrate the\nUser resource to this base class without losing functionality\n\nChange-Id: I3607ef71bfcd863b08879b3856baa92e7aeeef10\nblueprint: instance-users\n'}, {'number': 13, 'created': '2014-03-03 22:28:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/e81d0c7644812652bca6619e0e44272febe837fd', 'message': 'StackUser add suspend/resume support\n\nAdds suspend resume support which will be required to migrate the\nUser resource to this base class without losing functionality\n\nChange-Id: I3607ef71bfcd863b08879b3856baa92e7aeeef10\nblueprint: instance-users\n'}, {'number': 14, 'created': '2014-03-04 15:57:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/6ed7f634225540d626108a750d06c6231a906fcb', 'message': 'StackUser add suspend/resume support\n\nAdds suspend resume support which will be required to migrate the\nUser resource to this base class without losing functionality\n\nChange-Id: I3607ef71bfcd863b08879b3856baa92e7aeeef10\nblueprint: instance-users\n'}, {'number': 15, 'created': '2014-03-05 17:14:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/bde04f167d723f815605304f443653ddd39d8e3c', 'message': 'StackUser add suspend/resume support\n\nAdds suspend resume support which will be required to migrate the\nUser resource to this base class without losing functionality\n\nChange-Id: I3607ef71bfcd863b08879b3856baa92e7aeeef10\nblueprint: instance-users\n'}, {'number': 16, 'created': '2014-03-05 17:19:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/310ba58ce4b1da56cf518d9c1dc3a3a7ec284db4', 'message': 'StackUser add suspend/resume support\n\nAdds suspend resume support which will be required to migrate the\nUser resource to this base class without losing functionality\n\nChange-Id: I3607ef71bfcd863b08879b3856baa92e7aeeef10\nblueprint: instance-users\n'}, {'number': 17, 'created': '2014-03-05 17:48:04.000000000', 'files': ['heat/engine/stack_user.py', 'heat/tests/fakes.py', 'heat/tests/test_stack_user.py'], 'web_link': 'https://opendev.org/openstack/heat/commit/9411c0ccd7ac873b9e260dcc237f6a72abc0048d', 'message': 'StackUser add suspend/resume support\n\nAdds suspend resume support which will be required to migrate the\nUser resource to this base class without losing functionality\n\nChange-Id: I3607ef71bfcd863b08879b3856baa92e7aeeef10\nblueprint: instance-users\n'}]",1,71930,9411c0ccd7ac873b9e260dcc237f6a72abc0048d,82,5,17,4328,,,0,"StackUser add suspend/resume support

Adds suspend resume support which will be required to migrate the
User resource to this base class without losing functionality

Change-Id: I3607ef71bfcd863b08879b3856baa92e7aeeef10
blueprint: instance-users
",git fetch https://review.opendev.org/openstack/heat refs/changes/30/71930/17 && git format-patch -1 --stdout FETCH_HEAD,"['heat/engine/stack_user.py', 'heat/tests/fakes.py', 'heat/tests/test_stack_user.py']",3,81a2f5376f922db0585c0f4f7406a5008cdd78cc,bug/1089261," def test_handle_suspend(self): rsrc = self._user_create(stack_name='user_testdel', project_id='aprojectdel', user_id='auserdel') self.m.StubOutWithMock(fakes.FakeKeystoneClient, 'disable_stack_domain_user') fakes.FakeKeystoneClient.disable_stack_domain_user( user_id='auserdel', project_id='aprojectdel').AndReturn(None) self.m.ReplayAll() with utils.UUIDStub(self.resource_id): scheduler.TaskRunner(rsrc.create)() self.assertEqual((rsrc.CREATE, rsrc.COMPLETE), rsrc.state) scheduler.TaskRunner(rsrc.suspend)() self.assertEqual((rsrc.SUSPEND, rsrc.COMPLETE), rsrc.state) self.m.VerifyAll() def test_handle_suspend_legacy(self): rsrc = self._user_create(stack_name='user_testdel', project_id='aprojectdel', user_id='auserdel') self.m.StubOutWithMock(fakes.FakeKeystoneClient, 'disable_stack_domain_user') fakes.FakeKeystoneClient.disable_stack_domain_user( user_id='auserdel', project_id='aprojectdel').AndRaise(ValueError) self.m.StubOutWithMock(fakes.FakeKeystoneClient, 'disable_stack_user') fakes.FakeKeystoneClient.disable_stack_user( user_id='auserdel').AndReturn(None) self.m.ReplayAll() with utils.UUIDStub(self.resource_id): scheduler.TaskRunner(rsrc.create)() self.assertEqual((rsrc.CREATE, rsrc.COMPLETE), rsrc.state) scheduler.TaskRunner(rsrc.suspend)() self.assertEqual((rsrc.SUSPEND, rsrc.COMPLETE), rsrc.state) self.m.VerifyAll() def test_handle_resume(self): rsrc = self._user_create(stack_name='user_testdel', project_id='aprojectdel', user_id='auserdel') self.m.StubOutWithMock(fakes.FakeKeystoneClient, 'enable_stack_domain_user') fakes.FakeKeystoneClient.enable_stack_domain_user( user_id='auserdel', project_id='aprojectdel').AndReturn(None) self.m.ReplayAll() with utils.UUIDStub(self.resource_id): scheduler.TaskRunner(rsrc.create)() self.assertEqual((rsrc.CREATE, rsrc.COMPLETE), rsrc.state) rsrc.state_set(rsrc.SUSPEND, rsrc.COMPLETE) scheduler.TaskRunner(rsrc.resume)() self.assertEqual((rsrc.RESUME, rsrc.COMPLETE), rsrc.state) self.m.VerifyAll() def test_handle_resume_legacy(self): rsrc = self._user_create(stack_name='user_testdel', project_id='aprojectdel', user_id='auserdel') self.m.StubOutWithMock(fakes.FakeKeystoneClient, 'enable_stack_domain_user') fakes.FakeKeystoneClient.enable_stack_domain_user( user_id='auserdel', project_id='aprojectdel').AndRaise(ValueError) self.m.StubOutWithMock(fakes.FakeKeystoneClient, 'enable_stack_user') fakes.FakeKeystoneClient.enable_stack_user( user_id='auserdel').AndReturn(None) self.m.ReplayAll() with utils.UUIDStub(self.resource_id): scheduler.TaskRunner(rsrc.create)() self.assertEqual((rsrc.CREATE, rsrc.COMPLETE), rsrc.state) rsrc.state_set(rsrc.SUSPEND, rsrc.COMPLETE) scheduler.TaskRunner(rsrc.resume)() self.assertEqual((rsrc.RESUME, rsrc.COMPLETE), rsrc.state) self.m.VerifyAll()",,110,0
openstack%2Fneutron~master~Ic1612cd3e8efd39e74a7ed8cff28e91b1f388971,openstack/neutron,master,Ic1612cd3e8efd39e74a7ed8cff28e91b1f388971,Add OpenDaylight ML2 MechanismDriver,MERGED,2014-01-29 03:10:19.000000000,2014-03-06 17:43:49.000000000,2014-03-06 17:43:48.000000000,"[{'_account_id': 3}, {'_account_id': 55}, {'_account_id': 105}, {'_account_id': 107}, {'_account_id': 261}, {'_account_id': 333}, {'_account_id': 841}, {'_account_id': 1689}, {'_account_id': 2592}, {'_account_id': 5170}, {'_account_id': 6524}, {'_account_id': 6659}, {'_account_id': 6694}, {'_account_id': 6788}, {'_account_id': 7448}, {'_account_id': 7823}, {'_account_id': 7916}, {'_account_id': 8499}, {'_account_id': 9008}, {'_account_id': 9681}, {'_account_id': 9682}, {'_account_id': 9732}, {'_account_id': 9787}, {'_account_id': 9845}, {'_account_id': 9925}, {'_account_id': 10116}, {'_account_id': 10117}, {'_account_id': 10119}, {'_account_id': 10153}, {'_account_id': 10184}, {'_account_id': 10192}, {'_account_id': 10294}, {'_account_id': 10386}, {'_account_id': 10387}]","[{'number': 1, 'created': '2014-01-29 03:10:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/7a7cf4960c18c290d10bc8f863395a79abb06f33', 'message': 'Add OpenDaylight ML2 MechanismDriver\n\nThis commit adds support for OpenDaylight as an ML2 MechanismDriver. The\nODL MechanismDriver does not need an agent since ODL itself handles\nprogramming bridges, tunnels, and ports on the host.\n\nImplements bp ml2-opendaylight-mechanism-driver\n\nChange-Id: Ic1612cd3e8efd39e74a7ed8cff28e91b1f388971\n'}, {'number': 2, 'created': '2014-02-05 00:07:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/06990aec961733063109f4528b925df1504b109f', 'message': 'Add OpenDaylight ML2 MechanismDriver\n\nThis commit adds support for OpenDaylight as an ML2 MechanismDriver. The\nODL MechanismDriver does not need an agent since ODL itself handles\nprogramming bridges, tunnels, and ports on the host.\n\nImplements bp ml2-opendaylight-mechanism-driver\n\nChange-Id: Ic1612cd3e8efd39e74a7ed8cff28e91b1f388971\n'}, {'number': 3, 'created': '2014-02-10 16:50:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/79f6ae3f5c6f39a149b2c65f3989e894c2bbc783', 'message': 'Add OpenDaylight ML2 MechanismDriver\n\nThis commit adds support for OpenDaylight as an ML2 MechanismDriver. The\nODL MechanismDriver does not need an agent since ODL itself handles\nprogramming bridges, tunnels, and ports on the host.\n\nImplements bp ml2-opendaylight-mechanism-driver\n\nChange-Id: Ic1612cd3e8efd39e74a7ed8cff28e91b1f388971\n'}, {'number': 4, 'created': '2014-02-12 19:46:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/1052d3adfc25b3850889e3576d1cbf32d8c46e5b', 'message': 'Add OpenDaylight ML2 MechanismDriver\n\nThis commit adds support for OpenDaylight as an ML2 MechanismDriver. The\nODL MechanismDriver does not need an agent since ODL itself handles\nprogramming bridges, tunnels, and ports on the host.\n\nImplements bp ml2-opendaylight-mechanism-driver\n\nChange-Id: Ic1612cd3e8efd39e74a7ed8cff28e91b1f388971\n'}, {'number': 5, 'created': '2014-02-12 20:53:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/77fe4c17d7ea7ca335d064934da78af1e11785e2', 'message': 'Add OpenDaylight ML2 MechanismDriver\n\nThis commit adds support for OpenDaylight as an ML2 MechanismDriver. The\nODL MechanismDriver does not need an agent since ODL itself handles\nprogramming bridges, tunnels, and ports on the host.\n\nImplements bp ml2-opendaylight-mechanism-driver\n\nChange-Id: Ic1612cd3e8efd39e74a7ed8cff28e91b1f388971\n'}, {'number': 6, 'created': '2014-02-13 20:05:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/696d571b7e99900df21ad4ddff7ecfcfa195febf', 'message': 'Add OpenDaylight ML2 MechanismDriver\n\nThis commit adds support for OpenDaylight as an ML2 MechanismDriver. The\nODL MechanismDriver does not need an agent since ODL itself handles\nprogramming bridges, tunnels, and ports on the host.\n\nImplements bp ml2-opendaylight-mechanism-driver\n\nChange-Id: Ic1612cd3e8efd39e74a7ed8cff28e91b1f388971\n'}, {'number': 7, 'created': '2014-02-14 03:14:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/1d3f53ed40f0e851f368b0f2afcd3241992a68ca', 'message': 'Add OpenDaylight ML2 MechanismDriver\n\nThis commit adds support for OpenDaylight as an ML2 MechanismDriver. The\nODL MechanismDriver does not need an agent since ODL itself handles\nprogramming bridges, tunnels, and ports on the host.\n\nImplements bp ml2-opendaylight-mechanism-driver\n\nChange-Id: Ic1612cd3e8efd39e74a7ed8cff28e91b1f388971\n'}, {'number': 8, 'created': '2014-02-17 02:46:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/4f8470c1bb4f2b80e7ff1bb4a8838b0c58bf9068', 'message': 'Add OpenDaylight ML2 MechanismDriver\n\nThis commit adds support for OpenDaylight as an ML2 MechanismDriver. The\nODL MechanismDriver does not need an agent since ODL itself handles\nprogramming bridges, tunnels, and ports on the host.\n\nImplements bp ml2-opendaylight-mechanism-driver\n\nChange-Id: Ic1612cd3e8efd39e74a7ed8cff28e91b1f388971\n'}, {'number': 9, 'created': '2014-02-18 15:35:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/86bb44fe339bbc364e2503bddcb37478de928536', 'message': 'Add OpenDaylight ML2 MechanismDriver\n\nThis commit adds support for OpenDaylight as an ML2 MechanismDriver. The\nODL MechanismDriver does not need an agent since ODL itself handles\nprogramming bridges, tunnels, and ports on the host.\n\nImplements bp ml2-opendaylight-mechanism-driver\n\nChange-Id: Ic1612cd3e8efd39e74a7ed8cff28e91b1f388971\n'}, {'number': 10, 'created': '2014-02-19 15:09:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/23e3655022d07e44e2175b5ce0a8141dc15a2eee', 'message': 'Add OpenDaylight ML2 MechanismDriver\n\nThis commit adds support for OpenDaylight as an ML2 MechanismDriver. The\nODL MechanismDriver does not need an agent since ODL itself handles\nprogramming bridges, tunnels, and ports on the host.\n\nImplements bp ml2-opendaylight-mechanism-driver\n\nChange-Id: Ic1612cd3e8efd39e74a7ed8cff28e91b1f388971\n'}, {'number': 11, 'created': '2014-02-20 18:32:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/4040b04b6a9476f3c691fa6227f40f7de1ef0951', 'message': 'Add OpenDaylight ML2 MechanismDriver\n\nThis commit adds support for OpenDaylight as an ML2 MechanismDriver. The\nODL MechanismDriver does not need an agent since ODL itself handles\nprogramming bridges, tunnels, and ports on the host.\n\nImplements bp ml2-opendaylight-mechanism-driver\n\nChange-Id: Ic1612cd3e8efd39e74a7ed8cff28e91b1f388971\n'}, {'number': 12, 'created': '2014-02-24 16:32:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/f1f583d9f65a87ca41f07ca0d0bfe70a746339be', 'message': 'Add OpenDaylight ML2 MechanismDriver\n\nThis commit adds support for OpenDaylight as an ML2 MechanismDriver. The\nODL MechanismDriver does not need an agent since ODL itself handles\nprogramming bridges, tunnels, and ports on the host.\n\nImplements bp ml2-opendaylight-mechanism-driver\n\nChange-Id: Ic1612cd3e8efd39e74a7ed8cff28e91b1f388971\n'}, {'number': 13, 'created': '2014-02-24 21:48:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/88ac61cd6144024d9ad925166c97c216e51c52eb', 'message': 'Add OpenDaylight ML2 MechanismDriver\n\nThis commit adds support for OpenDaylight as an ML2 MechanismDriver. The\nODL MechanismDriver does not need an agent since ODL itself handles\nprogramming bridges, tunnels, and ports on the host.\n\nImplements bp ml2-opendaylight-mechanism-driver\n\nChange-Id: Ic1612cd3e8efd39e74a7ed8cff28e91b1f388971\n'}, {'number': 14, 'created': '2014-02-25 15:00:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/6f1ce9330683e287a94cd84fe8f5fbab3db1647f', 'message': 'Add OpenDaylight ML2 MechanismDriver\n\nThis commit adds support for OpenDaylight as an ML2 MechanismDriver. The\nODL MechanismDriver does not need an agent since ODL itself handles\nprogramming bridges, tunnels, and ports on the host.\n\nImplements bp ml2-opendaylight-mechanism-driver\n\nChange-Id: Ic1612cd3e8efd39e74a7ed8cff28e91b1f388971\n'}, {'number': 15, 'created': '2014-02-25 19:29:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/17834696dbd074fdc9bbf971c215eb0d795fd2a1', 'message': 'Add OpenDaylight ML2 MechanismDriver\n\nThis commit adds support for OpenDaylight as an ML2 MechanismDriver. The\nODL MechanismDriver does not need an agent since ODL itself handles\nprogramming bridges, tunnels, and ports on the host.\n\nImplements bp ml2-opendaylight-mechanism-driver\n\nChange-Id: Ic1612cd3e8efd39e74a7ed8cff28e91b1f388971\n'}, {'number': 16, 'created': '2014-03-04 19:44:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/1d1e1e19a0b02c2340d3a35ba2d91e581935354f', 'message': 'Add OpenDaylight ML2 MechanismDriver\n\nThis commit adds support for OpenDaylight as an ML2 MechanismDriver. The\nODL MechanismDriver does not need an agent since ODL itself handles\nprogramming bridges, tunnels, and ports on the host.\n\nImplements bp ml2-opendaylight-mechanism-driver\n\nChange-Id: Ic1612cd3e8efd39e74a7ed8cff28e91b1f388971\n'}, {'number': 17, 'created': '2014-03-05 20:44:09.000000000', 'files': ['neutron/plugins/ml2/drivers/README.odl', 'neutron/plugins/ml2/drivers/mechanism_odl.py', 'neutron/tests/unit/ml2/test_mechanism_odl.py', 'setup.cfg', 'etc/neutron/plugins/ml2/ml2_conf_odl.ini'], 'web_link': 'https://opendev.org/openstack/neutron/commit/791256cb671630ff70c941272df89717a7216eeb', 'message': 'Add OpenDaylight ML2 MechanismDriver\n\nThis commit adds support for OpenDaylight as an ML2 MechanismDriver. The\nODL MechanismDriver does not need an agent since ODL itself handles\nprogramming bridges, tunnels, and ports on the host.\n\nImplements bp ml2-opendaylight-mechanism-driver\n\nChange-Id: Ic1612cd3e8efd39e74a7ed8cff28e91b1f388971\n'}]",217,69775,791256cb671630ff70c941272df89717a7216eeb,310,34,17,105,,,0,"Add OpenDaylight ML2 MechanismDriver

This commit adds support for OpenDaylight as an ML2 MechanismDriver. The
ODL MechanismDriver does not need an agent since ODL itself handles
programming bridges, tunnels, and ports on the host.

Implements bp ml2-opendaylight-mechanism-driver

Change-Id: Ic1612cd3e8efd39e74a7ed8cff28e91b1f388971
",git fetch https://review.opendev.org/openstack/neutron refs/changes/75/69775/1 && git format-patch -1 --stdout FETCH_HEAD,"['neutron/db/migration/alembic_migrations/versions/4692d074d587_agent_scheduler.py', 'neutron/db/migration/alembic_migrations/versions/511471cc46b_agent_ext_model_supp.py', 'neutron/plugins/ml2/drivers/mechanism_odl.py', 'neutron/tests/unit/ml2/test_mechanism_odl.py', 'setup.cfg', 'etc/neutron/plugins/ml2/ml2_conf_odl.ini']",6,7a7cf4960c18c290d10bc8f863395a79abb06f33,bp/ml2-opendaylight-mechanism-driver,"# Configuration for the OpenDaylight MechanismDriver [ml2_odl] # (StrOpt) OpenDaylight REST URL # If this is not set then no HTTP requests will be made. # # url = # Example: url = http://192.168.56.1:8080/controller/nb/v2/neutron # (StrOpt) Username for HTTP basic authentication to ODL. # # username = # Example: username = admin # (StrOpt) Password for HTTP basic authentication to ODL. # # password = # Example: password = admin # (IntOpt) Timeout in seconds to wait for ODL HTTP request completion. # This is an optional parameter, default value is 10 seconds. # # timeout = # Example: timeout = 15 ",,522,0
openstack%2Fheat~master~I82eeeef0c3c626f0ec3df5a827a7ec049929538f,openstack/heat,master,I82eeeef0c3c626f0ec3df5a827a7ec049929538f,Fix resolving for Ref function,MERGED,2014-03-04 16:03:07.000000000,2014-03-06 17:38:21.000000000,2014-03-06 17:38:20.000000000,"[{'_account_id': 3}, {'_account_id': 4257}, {'_account_id': 4571}, {'_account_id': 6577}, {'_account_id': 7256}]","[{'number': 1, 'created': '2014-03-04 16:03:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/5b5e9bb50edb8ab74fe97b12e26dab262e96c556', 'message': ""Fix resolving for Ref function\n\nFix problem with incorrect choicing of Ref class during update.\nWhen we call reparse function in __setitem__ method we use,\nold version of stack template. So Ref function cann't find\nnew 'Resouces' in template.\n\nCloses-bug: #1285067\nChange-Id: I82eeeef0c3c626f0ec3df5a827a7ec049929538f\n""}, {'number': 2, 'created': '2014-03-05 13:57:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/eea421cd5896c49992e4edfefc85109426987588', 'message': ""Fix resolving for Ref function\n\nFix problem with incorrect choicing of Ref class during update.\nWhen we call reparse function in __setitem__ method we use,\nold version of stack template. So Ref function cann't find\nnew 'Resouces' in template.\n\nCloses-bug: #1285067\nChange-Id: I82eeeef0c3c626f0ec3df5a827a7ec049929538f\n""}, {'number': 3, 'created': '2014-03-06 07:12:16.000000000', 'files': ['heat/engine/parser.py', 'heat/tests/test_parser.py', 'heat/engine/cfn/functions.py'], 'web_link': 'https://opendev.org/openstack/heat/commit/7aeeab13450f8b16874ff310f4026482b9592dfa', 'message': ""Fix resolving for Ref function\n\nFix problem with incorrect choicing of Ref class during update.\nWhen we call reparse function in __setitem__ method we use,\nold version of stack template. So Ref function cann't find\nnew 'Resouces' in template.\n\nCloses-bug: #1285067\nChange-Id: I82eeeef0c3c626f0ec3df5a827a7ec049929538f\n""}]",9,77923,7aeeab13450f8b16874ff310f4026482b9592dfa,22,5,3,6577,,,0,"Fix resolving for Ref function

Fix problem with incorrect choicing of Ref class during update.
When we call reparse function in __setitem__ method we use,
old version of stack template. So Ref function cann't find
new 'Resouces' in template.

Closes-bug: #1285067
Change-Id: I82eeeef0c3c626f0ec3df5a827a7ec049929538f
",git fetch https://review.opendev.org/openstack/heat refs/changes/23/77923/3 && git format-patch -1 --stdout FETCH_HEAD,"['heat/tests/test_parser.py', 'heat/engine/cfn/functions.py']",2,5b5e9bb50edb8ab74fe97b12e26dab262e96c556,bug_1285067, if ((stack._resources and args in stack._resources) or args in stack.t[stack.t.RESOURCES]):, if args in stack.t[stack.t.RESOURCES]:,54,1
openstack%2Ftempest~master~I3943e57c040f4a5f7c36d42fa100bbc324097159,openstack/tempest,master,I3943e57c040f4a5f7c36d42fa100bbc324097159,Assign floating ip to a server in load balancer scenario,MERGED,2014-02-07 13:30:23.000000000,2014-03-06 17:38:13.000000000,2014-03-06 17:38:12.000000000,"[{'_account_id': 3}, {'_account_id': 261}, {'_account_id': 1192}, {'_account_id': 5196}, {'_account_id': 5689}, {'_account_id': 5803}, {'_account_id': 5948}, {'_account_id': 6072}, {'_account_id': 6167}, {'_account_id': 6683}, {'_account_id': 6788}, {'_account_id': 7293}, {'_account_id': 8576}]","[{'number': 1, 'created': '2014-02-07 13:30:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/1b9158183e2654ad58e12e0affd235f613783437', 'message': ""Add skip exception in load balancer scenario for isolated tests\n\nIn isolated jobs tenant network is being created for each test\nand host doesn't have direct access to it. So we need to skip\nthe test in cases like this.\n\nAlso fix inconsistent ssh timeout used in loadbalancer scenario.\n\nChange-Id: I3943e57c040f4a5f7c36d42fa100bbc324097159\nCloses-Bug: #1277381\n""}, {'number': 2, 'created': '2014-02-07 14:46:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/c720ed051546d7218ecbfc87598f9e6ce3503e7e', 'message': ""Add skip exception in load balancer scenario for isolated tests\n\nIn isolated jobs tenant network is being created for each test\nand host doesn't have direct access to it. So we need to skip\nthe test in cases like this.\n\nAlso fix inconsistent ssh timeout used in loadbalancer scenario.\n\nChange-Id: I3943e57c040f4a5f7c36d42fa100bbc324097159\nCloses-Bug: #1277381\n""}, {'number': 3, 'created': '2014-02-07 15:41:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/78564540fcfcfb7b482964d8d4d47d025350d92c', 'message': ""Assign floating ip to a server in load balancer scenario\n\nIn isolated jobs tenant network is being created for each test\nand host doesn't have direct access to it. To solve this problem\nwe need to assign a floating ip to the server and use it unstead.\n\nAlso fix inconsistent ssh timeout used in loadbalancer scenario.\n\nChange-Id: I3943e57c040f4a5f7c36d42fa100bbc324097159\nCloses-Bug: #1277381\n""}, {'number': 4, 'created': '2014-02-07 15:57:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/b1dab0262d870337358130f9176f97c8bcc2c766', 'message': ""Assign floating ip to a server in load balancer scenario\n\nIn isolated jobs tenant network is being created for each test\nand host doesn't have direct access to it. To solve this problem\nwe need to assign a floating ip to the server and use it unstead.\n\nAlso fix inconsistent ssh timeout used in loadbalancer scenario.\n\nChange-Id: I3943e57c040f4a5f7c36d42fa100bbc324097159\nCloses-Bug: #1277381\n""}, {'number': 5, 'created': '2014-02-07 18:00:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/5c44ecb332d2be4a07a43807026387a6876bdb0f', 'message': ""Assign floating ip to a server in load balancer scenario\n\nIn isolated jobs tenant network is being created for each test\nand host doesn't have direct access to it. To solve this problem\nwe need to assign a floating ip to the server and use it instead.\n\nAlso fix inconsistent ssh timeout used in loadbalancer scenario.\n\nChange-Id: I3943e57c040f4a5f7c36d42fa100bbc324097159\nCloses-Bug: #1277381\n""}, {'number': 6, 'created': '2014-02-18 10:57:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/6e83941ccda4efbac8934d0802d54b34f308905e', 'message': ""Assign floating ip to a server in load balancer scenario\n\nIn isolated jobs tenant network is being created for each test\nand host doesn't have direct access to it. To solve this problem\nwe need to assign a floating ip to the server and use it instead.\n\nAlso fix inconsistent ssh timeout used in loadbalancer scenario.\n\nChange-Id: I3943e57c040f4a5f7c36d42fa100bbc324097159\nCloses-Bug: #1277381\n""}, {'number': 7, 'created': '2014-02-21 17:37:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/b89d766f7d7668914424e53953b698cafefd859e', 'message': ""Assign floating ip to a server in load balancer scenario\n\nIn isolated jobs tenant network is being created for each test\nand host doesn't have direct access to it. To solve this problem\nwe need to assign a floating ip to the server and use it instead.\n\nA floating ip is assigned only in case public_network_id is defined\nand tenant_networks_reachable is False. If tenant_networks_reachable\nis True use direct addressing.\n\nAlso fix inconsistent ssh timeout used in loadbalancer scenario.\n\nChange-Id: I3943e57c040f4a5f7c36d42fa100bbc324097159\nCloses-Bug: #1277381\n""}, {'number': 8, 'created': '2014-02-26 14:36:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/f743ca17c1902e83f4276c82c204ab069ce8a5ec', 'message': ""Assign floating ip to a server in load balancer scenario\n\nIn isolated jobs tenant network is being created for each test\nand host doesn't have direct access to it. To solve this problem\nwe need to assign a floating ip to the server and use it instead.\n\nA floating ip is assigned only in case public_network_id is defined\nand tenant_networks_reachable is False. If tenant_networks_reachable\nis True use direct addressing.\n\nAlso fix inconsistent ssh timeout used in loadbalancer scenario.\n\nChange-Id: I3943e57c040f4a5f7c36d42fa100bbc324097159\nCloses-Bug: #1277381\n""}, {'number': 9, 'created': '2014-02-26 14:45:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/1a426f60f24c3edfbf2710d51fdc72c503836e6f', 'message': ""Assign floating ip to a server in load balancer scenario\n\nIn isolated jobs tenant network is being created for each test\nand host doesn't have direct access to it. To solve this problem\nwe need to assign a floating ip to the server and use it instead.\n\nA floating ip is assigned only in case public_network_id is defined\nand tenant_networks_reachable is False. If tenant_networks_reachable\nis True use direct addressing.\n\nAlso fix inconsistent ssh timeout used in loadbalancer scenario.\n\nChange-Id: I3943e57c040f4a5f7c36d42fa100bbc324097159\nCloses-Bug: #1277381\n""}, {'number': 10, 'created': '2014-02-26 15:30:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/129f3e81ced9bc5dfb79d49deb5da526054b28b0', 'message': ""Assign floating ip to a server in load balancer scenario\n\nIn isolated jobs tenant network is being created for each test\nand host doesn't have direct access to it. To solve this problem\nwe need to assign a floating ip to the server and use it instead.\n\nA floating ip is assigned only in case public_network_id is defined\nand tenant_networks_reachable is False. If tenant_networks_reachable\nis True use direct addressing.\n\nAlso fix inconsistent ssh timeout used in loadbalancer scenario.\n\nChange-Id: I3943e57c040f4a5f7c36d42fa100bbc324097159\nCloses-Bug: #1277381\n""}, {'number': 11, 'created': '2014-02-27 13:25:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/41addfe3c9155c35d274e25d0c4336a72d33911f', 'message': ""Assign floating ip to a server in load balancer scenario\n\nIn isolated jobs tenant network is being created for each test\nand host doesn't have direct access to it. To solve this problem\nwe need to assign a floating ip to the server and use it instead.\n\nA floating ip is assigned only in case public_network_id is defined\nand tenant_networks_reachable is False. If tenant_networks_reachable\nis True use direct addressing.\n\nChange-Id: I3943e57c040f4a5f7c36d42fa100bbc324097159\nCloses-Bug: #1277381\n""}, {'number': 12, 'created': '2014-02-28 13:05:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/f3de9a9cb410e0023911048735bb5b821dcc4bfb', 'message': ""Assign floating ip to a server in load balancer scenario\n\nIn isolated jobs tenant network is being created for each test\nand host doesn't have direct access to it. To solve this problem\nwe need to assign a floating ip to the server and use it instead.\n\nA floating ip is assigned only in case public_network_id is defined\nand tenant_networks_reachable is False. If tenant_networks_reachable\nis True use direct addressing.\n\nAlso fix inconsistent ssh timeout used in loadbalancer scenario.\n\nChange-Id: I3943e57c040f4a5f7c36d42fa100bbc324097159\nCloses-Bug: #1277381\n""}, {'number': 13, 'created': '2014-02-28 13:38:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/f03b7be682afb52ac6e902305770eda9a0fb39f9', 'message': ""Assign floating ip to a server in load balancer scenario\n\nIn isolated jobs tenant network is being created for each test\nand host doesn't have direct access to it. To solve this problem\nwe need to assign a floating ip to the server and use it instead.\n\nA floating ip is assigned only in case public_network_id is defined\nand tenant_networks_reachable is False. If tenant_networks_reachable\nis True use direct addressing.\n\nChange-Id: I3943e57c040f4a5f7c36d42fa100bbc324097159\nCloses-Bug: #1277381\n""}, {'number': 14, 'created': '2014-03-03 13:52:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/f59357d31eab97625224efb5c5917073f7eefb7a', 'message': ""Assign floating ip to a server in load balancer scenario\n\nIn isolated jobs tenant network is being created for each test\nand host doesn't have direct access to it. To solve this problem\nwe need to assign a floating ip to the server and use it instead.\n\nA floating ip is assigned only in case public_network_id is defined\nand tenant_networks_reachable is False. If tenant_networks_reachable\nis True use direct addressing.\n\nChange-Id: I3943e57c040f4a5f7c36d42fa100bbc324097159\nCloses-Bug: #1277381\n""}, {'number': 15, 'created': '2014-03-04 10:55:49.000000000', 'files': ['tempest/scenario/test_load_balancer_basic.py'], 'web_link': 'https://opendev.org/openstack/tempest/commit/915311004ab43ddf593fccdb29e99f88057b75a9', 'message': ""Assign floating ip to a server in load balancer scenario\n\nIn isolated jobs tenant network is being created for each test\nand host doesn't have direct access to it. To solve this problem\nwe need to assign a floating ip to the server and use it instead.\n\nA floating ip is assigned only in case public_network_id is defined\nand tenant_networks_reachable is False. If tenant_networks_reachable\nis True use direct addressing.\n\nChange-Id: I3943e57c040f4a5f7c36d42fa100bbc324097159\nCloses-Bug: #1277381\n""}]",23,71898,915311004ab43ddf593fccdb29e99f88057b75a9,129,13,15,7293,,,0,"Assign floating ip to a server in load balancer scenario

In isolated jobs tenant network is being created for each test
and host doesn't have direct access to it. To solve this problem
we need to assign a floating ip to the server and use it instead.

A floating ip is assigned only in case public_network_id is defined
and tenant_networks_reachable is False. If tenant_networks_reachable
is True use direct addressing.

Change-Id: I3943e57c040f4a5f7c36d42fa100bbc324097159
Closes-Bug: #1277381
",git fetch https://review.opendev.org/openstack/tempest refs/changes/98/71898/9 && git format-patch -1 --stdout FETCH_HEAD,['tempest/scenario/test_load_balancer_basic.py'],1,1b9158183e2654ad58e12e0affd235f613783437,71898," if config.compute.allow_tenant_isolation and \ (not config.network.tenant_networks_reachable): msg = ('Tenant networks must configured to be reachable ' 'for isolated tests.') cls.enabled = False raise cls.skipException(msg) ssh_client = ssh.Client( ip_address, ssh_login, pkey=private_key, timeout=config.compute.ssh_timeout, channel_timeout=config.compute.ssh_channel_timeout)"," ssh_client = ssh.Client(ip_address, ssh_login, pkey=private_key, timeout=100)",11,3
openstack%2Fkeystone~master~Idb54ee271cfb09e8523e357674b598b11704742c,openstack/keystone,master,Idb54ee271cfb09e8523e357674b598b11704742c,Handle exception messages with six.text_type,MERGED,2014-02-03 11:23:06.000000000,2014-03-06 17:38:07.000000000,2014-03-06 17:38:06.000000000,"[{'_account_id': 3}, {'_account_id': 4}, {'_account_id': 5046}, {'_account_id': 6460}, {'_account_id': 6486}, {'_account_id': 7536}]","[{'number': 1, 'created': '2014-02-03 11:23:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/0f2ce464b53e434c78a028de43f3fed62866bc83', 'message': 'Handle exception messages with `gettextutils`\n\nHandle exception messages with `gettextutils` tools instead of using\nstring message as is. This is necessary becase a message can contain\nnon-ascii characters and it can cause the unicode error:\n""UnicodeError: Message objects do not support str() because they may\ncontain non-ascii characters. Please use unicode() or translate()\ninstead.""\n\nChange-Id: Idb54ee271cfb09e8523e357674b598b11704742c\nFixes-Bug: 1275686\n'}, {'number': 2, 'created': '2014-02-03 12:53:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/68184aa9f17df7a95376dbc3737bd74567638de1', 'message': 'Handle exception messages with `gettextutils`\n\nHandle exception messages with `gettextutils` tools instead of using\nstring message as is. This is necessary becase a message can contain\nnon-ascii characters and it can cause the unicode error:\n""UnicodeError: Message objects do not support str() because they may\ncontain non-ascii characters. Please use unicode() or translate()\ninstead.""\n\nChange-Id: Idb54ee271cfb09e8523e357674b598b11704742c\nFixes-Bug: 1275686\n'}, {'number': 3, 'created': '2014-02-03 15:05:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/a8754730c242afb2afc411d5841e7930168c5bfe', 'message': 'Handle exception messages with `gettextutils`\n\nHandle exception messages with `gettextutils` tools instead of using\nstring message as is. This is necessary becase a message can contain\nnon-ascii characters and it can cause the unicode error:\n""UnicodeError: Message objects do not support str() because they may\ncontain non-ascii characters. Please use unicode() or translate()\ninstead.""\n\nChange-Id: Idb54ee271cfb09e8523e357674b598b11704742c\nFixes-Bug: 1275686\n'}, {'number': 4, 'created': '2014-02-04 09:23:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/45e4e9f413a05c60c1f08c5b7f35b0b4831587d6', 'message': 'Handle exception messages with `gettextutils`\n\nHandle exception messages with `gettextutils` tools instead of using\nstring message as is. This is necessary becase a message can contain\nnon-ascii characters and it can cause the unicode error:\n""UnicodeError: Message objects do not support str() because they may\ncontain non-ascii characters. Please use unicode() or translate()\ninstead.""\n\nChange-Id: Idb54ee271cfb09e8523e357674b598b11704742c\nFixes-Bug: 1275686\n'}, {'number': 5, 'created': '2014-02-04 09:43:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/f8bdabfb14affc0ee942012c03748ff71341209b', 'message': 'Handle exception messages with `gettextutils`\n\nHandle exception messages with `gettextutils` tools instead of using\nstring message as is. This is necessary because a message can contain\nnon-ascii characters and it can cause the unicode error:\n""UnicodeError: Message objects do not support str() because they may\ncontain non-ascii characters. Please use unicode() or translate()\ninstead.""\n\nChange-Id: Idb54ee271cfb09e8523e357674b598b11704742c\nFixes-Bug: 1275686\n'}, {'number': 6, 'created': '2014-02-04 16:46:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/1a6d023cd405303c876fcb682f18107e6e0848e5', 'message': 'Handle exception messages with `gettextutils`\n\nHandle exception messages with `gettextutils` tools instead of using\nstring message as is. This is necessary because a message can contain\nnon-ascii characters and it can cause the unicode error:\n""UnicodeError: Message objects do not support str() because they may\ncontain non-ascii characters. Please use unicode() or translate()\ninstead.""\n\nChange-Id: Idb54ee271cfb09e8523e357674b598b11704742c\nFixes-Bug: 1275686\n'}, {'number': 7, 'created': '2014-02-04 16:48:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/cdd684264c510888f2ff1f411d57154b903e4e74', 'message': 'Handle exception messages with `gettextutils`\n\nHandle exception messages with `gettextutils` tools instead of using\nstring message as is. This is necessary because a message can contain\nnon-ascii characters and it can cause the unicode error:\n""UnicodeError: Message objects do not support str() because they may\ncontain non-ascii characters. Please use unicode() or translate()\ninstead.""\n\nChange-Id: Idb54ee271cfb09e8523e357674b598b11704742c\nFixes-Bug: #1273301\n'}, {'number': 8, 'created': '2014-02-04 16:55:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/b31bbbddb85c0c7a4452b09243f651fff8019d56', 'message': 'Handle exception messages with six.test_type\n\nHandle exception messages with six.test_type tools instead of using\nstring message. This is necessary because a message can contain\nnon-ascii characters and it can cause the unicode error:\n""UnicodeError: Message objects do not support str() because they may\ncontain non-ascii characters. Please use unicode() or translate()\ninstead.""\n\nChange-Id: Idb54ee271cfb09e8523e357674b598b11704742c\nCloses-Bug: #1273301\n'}, {'number': 9, 'created': '2014-02-06 14:12:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/41f8c16d32d03ce3fc8d26dbd83531f87c01288c', 'message': 'Handle exception messages with six.test_type\n\nHandle exception messages with six.test_type tools instead of using\nstring message. This is necessary because a message can contain\nnon-ascii characters and it can cause the unicode error:\n""UnicodeError: Message objects do not support str() because they may\ncontain non-ascii characters. Please use unicode() or translate()\ninstead.""\n\nChange-Id: Idb54ee271cfb09e8523e357674b598b11704742c\nCloses-Bug: #1273301\n'}, {'number': 10, 'created': '2014-02-08 09:46:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/7aab08abed43fc884b766360c1619171ccf51822', 'message': 'Handle exception messages with six.test_type\n\nHandle exception messages with six.test_type tools instead of using\nstring message. This is necessary because a message can contain\nnon-ascii characters and it can cause the unicode error:\n""UnicodeError: Message objects do not support str() because they may\ncontain non-ascii characters. Please use unicode() or translate()\ninstead.""\n\nChange-Id: Idb54ee271cfb09e8523e357674b598b11704742c\nCloses-Bug: #1273301\n'}, {'number': 11, 'created': '2014-02-08 21:59:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/cf3f9d1804a69ceb8663f0fbfa8ca6ffe7f20445', 'message': 'Handle exception messages with six.test_type\n\nHandle exception messages with six.test_type tools instead of using\nstring message. This is necessary because a message can contain\nnon-ascii characters and it can cause the unicode error:\n""UnicodeError: Message objects do not support str() because they may\ncontain non-ascii characters. Please use unicode() or translate()\ninstead.""\n\nChange-Id: Idb54ee271cfb09e8523e357674b598b11704742c\nCloses-Bug: #1273301\n'}, {'number': 12, 'created': '2014-02-11 10:36:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/818fa1ae0294c3d732bc2d7bae7f1b723727caa8', 'message': 'Handle exception messages with six.test_type\n\nHandle exception messages with six.test_type tools instead of using\nstring message. This is necessary because a message can contain\nnon-ascii characters and it can cause the unicode error:\n""UnicodeError: Message objects do not support str() because they may\ncontain non-ascii characters. Please use unicode() or translate()\ninstead.""\n\nChange-Id: Idb54ee271cfb09e8523e357674b598b11704742c\nCloses-Bug: #1273301\n'}, {'number': 13, 'created': '2014-02-17 16:39:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/c3347e48e83b5a31a3ee932ea8b573e511efd1dd', 'message': 'Handle exception messages with six.test_type\n\nHandle exception messages with six.test_type tools instead of using\nstring message. This is necessary because a message can contain\nnon-ascii characters and it can cause the unicode error:\n""UnicodeError: Message objects do not support str() because they may\ncontain non-ascii characters. Please use unicode() or translate()\ninstead.""\n\nChange-Id: Idb54ee271cfb09e8523e357674b598b11704742c\nCloses-Bug: #1273301\n'}, {'number': 14, 'created': '2014-02-19 16:33:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/aad61a66f3120accfa37a33815a0c1757926a49e', 'message': 'Handle exception messages with six.text_type\n\nHandle exception messages with six.text_type tools instead of using\n`str()` message. `str()` doesn\'t care about ancoding and returns bytes as\nis, if bites was passed.\n\nIn [2]: str("""")\nOut[2]: \'\\xd0\\xbf\\xd1\\x80\\xd0\\xb8\\xd0\\xb2\\xd0\\xb5\\xd1\\x82\'\n\n`unicode` (six.text_type) tryes decode a string as ascii by default or if an\nencoding is provided, as the provided encoding string. If was an attempt to\nwrite non-utf-8 chracters as a model data UnicodeDecodeError must be raised to\n prevent uiexpected database and database driver behavior.\n\n`gettextutils` prevents non-unicode strings usage with the error:\n""UnicodeError: Message objects do not support str() because they may\ncontain non-ascii characters. Please use unicode() or translate()\ninstead."" But it is works ok if utf-8 was passed.\n\nChange-Id: Idb54ee271cfb09e8523e357674b598b11704742c\nCloses-Bug: #1273301\n'}, {'number': 15, 'created': '2014-02-19 17:00:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/92a7b5a3a4d735e1b955fa5335f02b8c24b1b25e', 'message': 'Handle exception messages with six.text_type\n\nHandle exception messages with six.text_type instead of using\n`str`. This is required to prevent of entering bytes to a database and\nprevent unexpected behavior of database and database driver.\n\nChange-Id: Idb54ee271cfb09e8523e357674b598b11704742c\nCloses-Bug: #1273301\n'}, {'number': 16, 'created': '2014-02-19 17:00:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/82ef30e185f6c3f350e3bd50097ee49b8e7baa28', 'message': 'Handle exception messages with six.text_type\n\nHandle exception messages with six.text_type instead of using\n`str`. This is required to prevent of entering bytes to a database and\nprevent unexpected behavior of database and database driver.\n\nChange-Id: Idb54ee271cfb09e8523e357674b598b11704742c\nCloses-Bug: #1273301\n'}, {'number': 18, 'created': '2014-02-24 10:08:48.000000000', 'files': ['keystone/common/sql/core.py', 'keystone/tests/test_backend_sql.py'], 'web_link': 'https://opendev.org/openstack/keystone/commit/29d9c270d4e3dde044e8d27d888455e423c31b20', 'message': 'Handle exception messages with six.text_type\n\nHandle exception messages with six.text_type instead of using\n`str`. This is required to prevent of entering bytes to a database and\nprevent unexpected behavior of database and database driver.\n\nChange-Id: Idb54ee271cfb09e8523e357674b598b11704742c\nCloses-Bug: #1273301\n'}, {'number': 17, 'created': '2014-02-24 10:08:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/19b575c31e4ddbcd72de67e2ab8c92d74afa8ee2', 'message': 'Handle exception messages with six.text_type\n\nHandle exception messages with six.text_type instead of using\n`str`. This is required to prevent of entering bytes to a database and\nprevent unexpected behavior of database and database driver.\n\nChange-Id: Idb54ee271cfb09e8523e357674b598b11704742c\nCloses-Bug: #1273301\n'}]",27,70696,29d9c270d4e3dde044e8d27d888455e423c31b20,87,6,18,7536,,,0,"Handle exception messages with six.text_type

Handle exception messages with six.text_type instead of using
`str`. This is required to prevent of entering bytes to a database and
prevent unexpected behavior of database and database driver.

Change-Id: Idb54ee271cfb09e8523e357674b598b11704742c
Closes-Bug: #1273301
",git fetch https://review.opendev.org/openstack/keystone refs/changes/96/70696/10 && git format-patch -1 --stdout FETCH_HEAD,"['keystone/common/sql/core.py', 'keystone/openstack/common/db/exception.py']",2,0f2ce464b53e434c78a028de43f3fed62866bc83,unicode_error_messages," super(DBError, self).__init__(_(inner_exception)) super(DbMigrationError, self).__init__(_(message))"," super(DBError, self).__init__(str(inner_exception)) super(DbMigrationError, self).__init__(str(message))",5,5
openstack%2Fdevstack-gate~master~I7395ee907326c5fe6588064ec478a582a4a49d0c,openstack/devstack-gate,master,I7395ee907326c5fe6588064ec478a582a4a49d0c,Rename tempest.conf so it is gz'ed properly,MERGED,2014-02-26 19:14:03.000000000,2014-03-06 17:38:05.000000000,2014-03-06 17:38:05.000000000,"[{'_account_id': 3}, {'_account_id': 2750}, {'_account_id': 5263}]","[{'number': 1, 'created': '2014-02-26 19:14:03.000000000', 'files': ['functions.sh'], 'web_link': 'https://opendev.org/openstack/devstack-gate/commit/c259617dcdb31a3c886a2585301ac47a33ccdc3f', 'message': ""Rename tempest.conf so it is gz'ed properly\n\nChange-Id: I7395ee907326c5fe6588064ec478a582a4a49d0c\n""}]",0,76622,c259617dcdb31a3c886a2585301ac47a33ccdc3f,9,3,1,1192,,,0,"Rename tempest.conf so it is gz'ed properly

Change-Id: I7395ee907326c5fe6588064ec478a582a4a49d0c
",git fetch https://review.opendev.org/openstack/devstack-gate refs/changes/22/76622/1 && git format-patch -1 --stdout FETCH_HEAD,['functions.sh'],1,c259617dcdb31a3c886a2585301ac47a33ccdc3f,master, sudo cp $BASE/old/tempest/etc/tempest.conf $BASE/logs/old/tempest.conf.txt sudo cp $BASE/new/tempest/etc/tempest.conf $NEWLOGTARGET/tempest.conf.txt, sudo cp $BASE/old/tempest/etc/tempest.conf $BASE/logs/old/ sudo cp $BASE/new/tempest/etc/tempest.conf $NEWLOGTARGET/,2,2
openstack%2Fceilometer~master~I77eab59023fa23c5879b05c948bd4cb1db7fa177,openstack/ceilometer,master,I77eab59023fa23c5879b05c948bd4cb1db7fa177,Ensure user metadata mapped for instance notifications,MERGED,2014-03-04 18:56:16.000000000,2014-03-06 17:38:03.000000000,2014-03-06 17:38:02.000000000,"[{'_account_id': 3}, {'_account_id': 1669}, {'_account_id': 2284}, {'_account_id': 2813}, {'_account_id': 2860}, {'_account_id': 4491}, {'_account_id': 6537}, {'_account_id': 9562}, {'_account_id': 9684}, {'_account_id': 9708}]","[{'number': 1, 'created': '2014-03-04 18:56:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/f14dae19a2b31be5ce7d053002a35128b225bad3', 'message': 'Ensure user metadata mapped for instance notifications\n\nFixes bug 1284073\n\nFor pollster-originated samples related to instances, we apply a\nmapping to the user metadata so as to ensure that there are no\nembedded periods in metadata keys and also to exclude any metadata\nnot matching the configured reserved namespace.\n\nNow this logic is also applied to user metadata for samples derived\nfrom instance-related notifications in order to avoid failures when\npersisting these data in mongodb.\n\nChange-Id: I77eab59023fa23c5879b05c948bd4cb1db7fa177\n'}, {'number': 2, 'created': '2014-03-04 20:29:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/e12eb7a2daffbe721e9c222a83a46a552940a2e0', 'message': 'Ensure user metadata mapped for instance notifications\n\nFixes bug 1284073\n\nFor pollster-originated samples related to instances, we apply a\nmapping to the user metadata so as to ensure that there are no\nembedded periods in metadata keys and also to exclude any metadata\nnot matching the configured reserved namespace.\n\nNow this logic is also applied to user metadata for samples derived\nfrom instance-related notifications in order to avoid failures when\npersisting these data in mongodb.\n\nChange-Id: I77eab59023fa23c5879b05c948bd4cb1db7fa177\n'}, {'number': 3, 'created': '2014-03-05 16:25:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/da276dc9753dceb9f7c41354114002629eb63bad', 'message': 'Ensure user metadata mapped for instance notifications\n\nFixes bug 1284073\n\nFor pollster-originated samples related to instances, we apply a\nmapping to the user metadata so as to ensure that there are no\nembedded periods in metadata keys and also to exclude any metadata\nnot matching the configured reserved namespace.\n\nNow this logic is also applied to user metadata for samples derived\nfrom instance-related notifications in order to avoid failures when\npersisting these data in mongodb.\n\nChange-Id: I77eab59023fa23c5879b05c948bd4cb1db7fa177\n'}, {'number': 4, 'created': '2014-03-05 16:48:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/25f8c95bc65b078f98a6c84f25a70db8e2bc747b', 'message': 'Ensure user metadata mapped for instance notifications\n\nFixes bug 1284073\n\nFor pollster-originated samples related to instances, we apply a\nmapping to the user metadata so as to ensure that there are no\nembedded periods in metadata keys and also to exclude any metadata\nnot matching the configured reserved namespace.\n\nNow this logic is also applied to user metadata for samples derived\nfrom instance-related notifications in order to avoid failures when\npersisting these data in mongodb.\n\nChange-Id: I77eab59023fa23c5879b05c948bd4cb1db7fa177\n'}, {'number': 5, 'created': '2014-03-05 16:56:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/5c6fcf9012176ce84b113809b94988b706269496', 'message': 'Ensure user metadata mapped for instance notifications\n\nFixes bug 1284073\n\nFor pollster-originated samples related to instances, we apply a\nmapping to the user metadata so as to ensure that there are no\nembedded periods in metadata keys and also to exclude any metadata\nnot matching the configured reserved namespace.\n\nNow this logic is also applied to user metadata for samples derived\nfrom instance-related notifications in order to avoid failures when\npersisting these data in mongodb.\n\nChange-Id: I77eab59023fa23c5879b05c948bd4cb1db7fa177\n'}, {'number': 6, 'created': '2014-03-05 17:06:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/5a82f20c01bc03cc67730b583b5222b27d7cba5b', 'message': 'Ensure user metadata mapped for instance notifications\n\nFixes bug 1284073\n\nFor pollster-originated samples related to instances, we apply a\nmapping to the user metadata so as to ensure that there are no\nembedded periods in metadata keys and also to exclude any metadata\nnot matching the configured reserved namespace.\n\nNow this logic is also applied to user metadata for samples derived\nfrom instance-related notifications in order to avoid failures when\npersisting these data in mongodb.\n\nChange-Id: I77eab59023fa23c5879b05c948bd4cb1db7fa177\n'}, {'number': 7, 'created': '2014-03-05 17:55:18.000000000', 'files': ['ceilometer/compute/util.py', 'ceilometer/tests/compute/notifications/test_instance.py', 'ceilometer/compute/pollsters/util.py', 'etc/ceilometer/ceilometer.conf.sample', 'ceilometer/compute/notifications/instance.py'], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/ddeb54bb0d2c4203332a5ecc09a4aedfce353a4c', 'message': 'Ensure user metadata mapped for instance notifications\n\nFixes bug 1284073\n\nFor pollster-originated samples related to instances, we apply a\nmapping to the user metadata so as to ensure that there are no\nembedded periods in metadata keys and also to exclude any metadata\nnot matching the configured reserved namespace.\n\nNow this logic is also applied to user metadata for samples derived\nfrom instance-related notifications in order to avoid failures when\npersisting these data in mongodb.\n\nChange-Id: I77eab59023fa23c5879b05c948bd4cb1db7fa177\n'}]",13,77959,ddeb54bb0d2c4203332a5ecc09a4aedfce353a4c,39,10,7,2284,,,0,"Ensure user metadata mapped for instance notifications

Fixes bug 1284073

For pollster-originated samples related to instances, we apply a
mapping to the user metadata so as to ensure that there are no
embedded periods in metadata keys and also to exclude any metadata
not matching the configured reserved namespace.

Now this logic is also applied to user metadata for samples derived
from instance-related notifications in order to avoid failures when
persisting these data in mongodb.

Change-Id: I77eab59023fa23c5879b05c948bd4cb1db7fa177
",git fetch https://review.opendev.org/openstack/ceilometer refs/changes/59/77959/6 && git format-patch -1 --stdout FETCH_HEAD,"['ceilometer/compute/util.py', 'ceilometer/tests/compute/notifications/test_instance.py', 'ceilometer/compute/pollsters/util.py', 'ceilometer/compute/notifications/instance.py', 'etc/ceilometer/ceilometer.conf.sample']",5,f14dae19a2b31be5ce7d053002a35128b225bad3,,# Options defined in ceilometer.compute.util,# Options defined in ceilometer.compute.pollsters.util,94,43
openstack%2Fbarbican~master~Ic3fd85ce066cd9b15fec95316afe38974e8f19cb,openstack/barbican,master,Ic3fd85ce066cd9b15fec95316afe38974e8f19cb,Minor changes to make the bash8 check happy,MERGED,2014-03-05 23:16:53.000000000,2014-03-06 17:34:45.000000000,2014-03-06 17:34:45.000000000,"[{'_account_id': 3}, {'_account_id': 7355}, {'_account_id': 7789}, {'_account_id': 7973}]","[{'number': 1, 'created': '2014-03-05 23:16:53.000000000', 'files': ['contrib/devstack/lib/barbican', 'contrib/devstack/extras.d/70-barbican.sh'], 'web_link': 'https://opendev.org/openstack/barbican/commit/53af996600e62baf0569e9ec8a0d320d67c1027a', 'message': 'Minor changes to make the bash8 check happy\n\nChange-Id: Ic3fd85ce066cd9b15fec95316afe38974e8f19cb\n'}]",0,78447,53af996600e62baf0569e9ec8a0d320d67c1027a,8,4,1,7136,,,0,"Minor changes to make the bash8 check happy

Change-Id: Ic3fd85ce066cd9b15fec95316afe38974e8f19cb
",git fetch https://review.opendev.org/openstack/barbican refs/changes/47/78447/1 && git format-patch -1 --stdout FETCH_HEAD,"['contrib/devstack/lib/barbican', 'contrib/devstack/extras.d/70-barbican.sh']",2,53af996600e62baf0569e9ec8a0d320d67c1027a,Make-Bash8-Happy,fi ,fi,18,18
openstack%2Foslo.messaging~master~I6a164121d0149b015ba4506f60f91c273d6afde8,openstack/oslo.messaging,master,I6a164121d0149b015ba4506f60f91c273d6afde8,"Revert ""Slow down Kombu reconnect attempts""",ABANDONED,2014-03-06 10:41:23.000000000,2014-03-06 17:34:10.000000000,,"[{'_account_id': 3}, {'_account_id': 1247}, {'_account_id': 1669}, {'_account_id': 2472}, {'_account_id': 2813}, {'_account_id': 5280}, {'_account_id': 5638}]","[{'number': 1, 'created': '2014-03-06 10:41:23.000000000', 'files': ['oslo/messaging/_drivers/impl_rabbit.py'], 'web_link': 'https://opendev.org/openstack/oslo.messaging/commit/7b66d450b8729ae087634b88e9fb2e27b571339b', 'message': 'Revert ""Slow down Kombu reconnect attempts""\n\nThis reverts commit fcd51a67d18a9e947ae5f57eafa43ac756d1a5a8.\n\nwith eventlet the time.sleep() do a eventlet task switch\n\nbroken scenario:\n\ntask A: block to time.sleep() in _connect method eventlet task switch occur\ntask B: block to time.sleep() in _connect method eventlet task switch occur\ntask A: sleep finish, connection.release() closes and cleans the kombu\n        connection object. And task A establish a new connection to rabbitmq\n        kombu do some IO -> eventlet switch task\ntask B: sleep finish, connection.release() closes and cleans the kombu\n        connection object. And task B establish a new connection to rabbitmq\n        kombu do some IO -> eventlet switch task\ntask A: connection.connect() raise a exception because task B have\n        close the connection during the establishment\n\nIn this case, the connection can never come back.\n\nCloses-bug #1288654\n\nChange-Id: I6a164121d0149b015ba4506f60f91c273d6afde8\n'}]",0,78574,7b66d450b8729ae087634b88e9fb2e27b571339b,8,7,1,2813,,,0,"Revert ""Slow down Kombu reconnect attempts""

This reverts commit fcd51a67d18a9e947ae5f57eafa43ac756d1a5a8.

with eventlet the time.sleep() do a eventlet task switch

broken scenario:

task A: block to time.sleep() in _connect method eventlet task switch occur
task B: block to time.sleep() in _connect method eventlet task switch occur
task A: sleep finish, connection.release() closes and cleans the kombu
        connection object. And task A establish a new connection to rabbitmq
        kombu do some IO -> eventlet switch task
task B: sleep finish, connection.release() closes and cleans the kombu
        connection object. And task B establish a new connection to rabbitmq
        kombu do some IO -> eventlet switch task
task A: connection.connect() raise a exception because task B have
        close the connection during the establishment

In this case, the connection can never come back.

Closes-bug #1288654

Change-Id: I6a164121d0149b015ba4506f60f91c273d6afde8
",git fetch https://review.opendev.org/openstack/oslo.messaging refs/changes/74/78574/1 && git format-patch -1 --stdout FETCH_HEAD,['oslo/messaging/_drivers/impl_rabbit.py'],1,7b66d450b8729ae087634b88e9fb2e27b571339b,bug/1288654,," cfg.FloatOpt('kombu_reconnect_delay', default=1.0, help='How long to wait before reconnecting in response to an ' 'AMQP consumer cancel notification.'), # XXX(nic): when reconnecting to a RabbitMQ cluster # with mirrored queues in use, the attempt to release the # connection can hang ""indefinitely"" somewhere deep down # in Kombu. Blocking the thread for a bit prior to # release seems to kludge around the problem where it is # otherwise reproduceable. if self.conf.kombu_reconnect_delay > 0: LOG.info(_(""Delaying reconnect for %1.1f seconds..."") % self.conf.kombu_reconnect_delay) time.sleep(self.conf.kombu_reconnect_delay) ",0,15
openstack%2Fcookbook-openstack-network~master~I95d60fe1dfabd734b950e02e3238ce10414a2385,openstack/cookbook-openstack-network,master,I95d60fe1dfabd734b950e02e3238ce10414a2385,Don't restart neutron-openvswitch-switch at each chef run,MERGED,2014-03-05 18:02:11.000000000,2014-03-06 17:31:26.000000000,2014-03-06 17:31:25.000000000,"[{'_account_id': 3}, {'_account_id': 2340}, {'_account_id': 6526}, {'_account_id': 7128}, {'_account_id': 9884}, {'_account_id': 10269}]","[{'number': 1, 'created': '2014-03-05 18:02:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cookbook-openstack-network/commit/04f94e6cffa388e4e2dbebc618cd4efa4894950a', 'message': ""Don't restart neutron-openvswitch-switch at each chef run\n\nI don't know/understand why it was set like this in the first place.\nBut it's not what we want.\n\nChange-Id: I95d60fe1dfabd734b950e02e3238ce10414a2385\nCloses-Bug: #1266558\n""}, {'number': 2, 'created': '2014-03-05 19:31:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cookbook-openstack-network/commit/2e33803f43c9c188ea3198b8ef849dcca9fbe835', 'message': ""Don't restart neutron-openvswitch-switch at each chef run\n\nI don't know/understand why it was set like this in the first place.\nBut it's not what we want.\n\nChange-Id: I95d60fe1dfabd734b950e02e3238ce10414a2385\nCloses-Bug: #1266558\n""}, {'number': 3, 'created': '2014-03-06 16:21:51.000000000', 'files': ['spec/openvswitch_spec.rb', 'recipes/openvswitch.rb'], 'web_link': 'https://opendev.org/openstack/cookbook-openstack-network/commit/c77f3c49493bb887cec3b100f7f915d709c37d3f', 'message': ""Don't restart neutron-openvswitch-switch at each chef run\n\nI don't know/understand why it was set like this in the first place.\nBut it's not what we want.\n\nChange-Id: I95d60fe1dfabd734b950e02e3238ce10414a2385\nCloses-Bug: #1288366\n""}]",0,78332,c77f3c49493bb887cec3b100f7f915d709c37d3f,21,6,3,10269,,,0,"Don't restart neutron-openvswitch-switch at each chef run

I don't know/understand why it was set like this in the first place.
But it's not what we want.

Change-Id: I95d60fe1dfabd734b950e02e3238ce10414a2385
Closes-Bug: #1288366
",git fetch https://review.opendev.org/openstack/cookbook-openstack-network refs/changes/32/78332/3 && git format-patch -1 --stdout FETCH_HEAD,['recipes/openvswitch.rb'],1,04f94e6cffa388e4e2dbebc618cd4efa4894950a,bug/1288366," action [:enable, :start]"," action [:enable, :restart]",1,1
openstack%2Fnova~stable%2Fgrizzly~I264540de736c2bcb92567826fe5ba672e1244ba2,openstack/nova,stable/grizzly,I264540de736c2bcb92567826fe5ba672e1244ba2,Fail quickly if file injection for boot volume,MERGED,2013-10-30 02:04:10.000000000,2014-03-06 17:28:34.000000000,2014-03-06 17:28:31.000000000,"[{'_account_id': 3}, {'_account_id': 1501}, {'_account_id': 1561}, {'_account_id': 1653}, {'_account_id': 1779}, {'_account_id': 1812}, {'_account_id': 1955}, {'_account_id': 2271}, {'_account_id': 5170}, {'_account_id': 5511}, {'_account_id': 5652}, {'_account_id': 7069}, {'_account_id': 8125}]","[{'number': 1, 'created': '2013-10-30 02:04:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/d6aa68de0aa7a3a4ca996492b6beb092f9509123', 'message': 'Fail quickly if file injection for boot volume\n\nPreviously if the user attempted file injection on a booted volume it\nwould fail and retry several times, which slowed down the instance\nspawning.  Instead of attempting file injection, fail quickly, and\nlog a warning\n\nBackport to stable/grizzy\n\nFix bug 1188543\n\nChange-Id: I264540de736c2bcb92567826fe5ba672e1244ba2\n(cherry picked from commit f59c2d64ac8f0523c587e23b2d1c59fdfe7ea131)\n\nConflicts:\n\tnova/virt/libvirt/driver.py\n\nChange-Id: I264540de736c2bcb92567826fe5ba672e1244ba2\n'}, {'number': 2, 'created': '2013-10-30 04:45:40.000000000', 'files': ['nova/virt/libvirt/driver.py', 'nova/tests/test_virt_disk.py', 'nova/virt/disk/api.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/a28aa07789e3b71c702657db12825b23716a4bf6', 'message': 'Fail quickly if file injection for boot volume\n\nPreviously if the user attempted file injection on a booted volume it\nwould fail and retry several times, which slowed down the instance\nspawning.  Instead of attempting file injection, fail quickly, and\nlog a warning\n\nBackport to stable/grizzy\n\nFix bug 1188543\n\nConflicts:\n\tnova/virt/libvirt/driver.py\n\nChange-Id: I264540de736c2bcb92567826fe5ba672e1244ba2\n(cherry picked from commit f59c2d64ac8f0523c587e23b2d1c59fdfe7ea131)\n'}]",1,54460,a28aa07789e3b71c702657db12825b23716a4bf6,32,13,2,8125,,,0,"Fail quickly if file injection for boot volume

Previously if the user attempted file injection on a booted volume it
would fail and retry several times, which slowed down the instance
spawning.  Instead of attempting file injection, fail quickly, and
log a warning

Backport to stable/grizzy

Fix bug 1188543

Conflicts:
	nova/virt/libvirt/driver.py

Change-Id: I264540de736c2bcb92567826fe5ba672e1244ba2
(cherry picked from commit f59c2d64ac8f0523c587e23b2d1c59fdfe7ea131)
",git fetch https://review.opendev.org/openstack/nova refs/changes/60/54460/1 && git format-patch -1 --stdout FETCH_HEAD,"['nova/virt/libvirt/driver.py', 'nova/tests/test_virt_disk.py', 'nova/virt/disk/api.py']",3,d6aa68de0aa7a3a4ca996492b6beb092f9509123,bug/1188543, # Note(mrda): Test if the image exists first to short circuit errors os.stat(image),,25,0
openstack%2Fheat~master~Id965e1f872ebf63a510242c7c76a4f105dcb4a17,openstack/heat,master,Id965e1f872ebf63a510242c7c76a4f105dcb4a17,"Revert ""Showing member list for nested resources""",MERGED,2014-03-05 19:06:28.000000000,2014-03-06 17:28:22.000000000,2014-03-06 17:28:21.000000000,"[{'_account_id': 3}, {'_account_id': 4257}, {'_account_id': 4328}, {'_account_id': 6577}, {'_account_id': 7253}]","[{'number': 1, 'created': '2014-03-05 19:06:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/6889285553782548cb3f5d58bee92144d45b8c9a', 'message': 'Revert ""Showing member list for nested resources""\n\nThis reverts commit 5e883e94d73cb7fd6737c262f25cd7c6be56ffe5.\n\nConflicts:\n\n\theat/tests/test_engine_service.py\n\nChange-Id: Id965e1f872ebf63a510242c7c76a4f105dcb4a17\n'}, {'number': 2, 'created': '2014-03-05 19:29:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/ae1b3fb253fd9c625a8e5548cc043292649b081c', 'message': 'Revert ""Showing member list for nested resources""\n\nThis reverts commit 5e883e94d73cb7fd6737c262f25cd7c6be56ffe5.\n\nReverted patch not fully resolve problem that was mentioned in bug\ndescription, since presented in resource show ids are owned nested stack\nand it doesn\'t allow use only resource-show command for displaying\ninformation of these resources.\nAlso this code affects not only resource group resource, but other\nnested resources too. So it leads to displaying some unwanted\ninformation.\n\nConflicts:\n\n\theat/tests/test_engine_service.py\n\nChange-Id: Id965e1f872ebf63a510242c7c76a4f105dcb4a17\n'}, {'number': 3, 'created': '2014-03-05 19:48:39.000000000', 'files': ['heat/tests/test_engine_service.py', 'heat/engine/api.py', 'heat/rpc/api.py', 'heat/tests/test_api_openstack_v1.py'], 'web_link': 'https://opendev.org/openstack/heat/commit/b57401e5028611b53e6412efa225b0c03e8c89ac', 'message': 'Revert ""Showing member list for nested resources""\n\nThis reverts commit 5e883e94d73cb7fd6737c262f25cd7c6be56ffe5.\n\nReverted patch not fully resolve problem that was mentioned in bug\ndescription, since presented in resource show ids are owned nested stack\nand it doesn\'t allow use only resource-show command for displaying\ninformation of these resources.\nAlso this code affects not only resource group resource, but other\nnested resources too. So it leads to displaying some unwanted\ninformation.\n\nConflicts:\n\n\theat/tests/test_engine_service.py\n\nCloses-bug: #1280391\nChange-Id: Id965e1f872ebf63a510242c7c76a4f105dcb4a17\n'}]",2,78363,b57401e5028611b53e6412efa225b0c03e8c89ac,18,5,3,6577,,,0,"Revert ""Showing member list for nested resources""

This reverts commit 5e883e94d73cb7fd6737c262f25cd7c6be56ffe5.

Reverted patch not fully resolve problem that was mentioned in bug
description, since presented in resource show ids are owned nested stack
and it doesn't allow use only resource-show command for displaying
information of these resources.
Also this code affects not only resource group resource, but other
nested resources too. So it leads to displaying some unwanted
information.

Conflicts:

	heat/tests/test_engine_service.py

Closes-bug: #1280391
Change-Id: Id965e1f872ebf63a510242c7c76a4f105dcb4a17
",git fetch https://review.opendev.org/openstack/heat refs/changes/63/78363/1 && git format-patch -1 --stdout FETCH_HEAD,"['heat/tests/test_engine_service.py', 'heat/engine/api.py', 'heat/rpc/api.py', 'heat/tests/test_api_openstack_v1.py']",4,6889285553782548cb3f5d58bee92144d45b8c9a,,," def test_show_nested(self, mock_enforce): self._mock_enforce_setup(mock_enforce, 'show', True) res_name = 'ServerGroup' stack_identity = identifier.HeatIdentifier(self.tenant, 'nested_resource', '6') res_identity = identifier.ResourceIdentifier(resource_name=res_name, **stack_identity) req = self._get(stack_identity._tenant_path()) engine_resp = { u'description': u'', u'resource_identity': dict(res_identity), u'stack_name': stack_identity.stack_name, u'resource_name': res_name, u'resource_status_reason': None, u'updated_time': u'2012-07-23T13:06:00Z', u'stack_identity': dict(stack_identity), u'resource_action': u'CREATE', u'resource_status': u'COMPLETE', u'physical_resource_id': u'a3455d8c-9f88-404d-a85b-5315293e67de', u'resource_type': u'OS::Heat::ResourceGroup', u'metadata': {u'ensureRunning': u'true'}, u'members': [u'2bf47h48-45u4-4z47-371h-j2k4v236l562', u'a3455d8c-9f88-404d-a85b-5315293e67de'] } self.m.StubOutWithMock(rpc, 'call') rpc.call(req.context, self.topic, {'namespace': None, 'method': 'describe_stack_resource', 'args': {'stack_identity': stack_identity, 'resource_name': res_name}, 'version': self.api_version}, None).AndReturn(engine_resp) self.m.ReplayAll() result = self.controller.show(req, tenant_id=self.tenant, stack_name=stack_identity.stack_name, stack_id=stack_identity.stack_id, resource_name=res_name) expected = { 'resource': { 'links': [ {'href': self._url(res_identity), 'rel': 'self'}, {'href': self._url(stack_identity), 'rel': 'stack'}, ], u'description': u'', u'resource_name': res_name, u'logical_resource_id': res_name, u'resource_status_reason': None, u'updated_time': u'2012-07-23T13:06:00Z', u'resource_status': u'CREATE_COMPLETE', u'physical_resource_id': u'a3455d8c-9f88-404d-a85b-5315293e67de', u'resource_type': u'OS::Heat::ResourceGroup', u'members': [u'2bf47h48-45u4-4z47-371h-j2k4v236l562', u'a3455d8c-9f88-404d-a85b-5315293e67de'] } } self.assertEqual(result, expected) self.m.VerifyAll() ",2,165
openstack%2Ffuel-docs~master~Ie7ac583ada3062204d5a61d60e14aa88f57723e2,openstack/fuel-docs,master,Ie7ac583ada3062204d5a61d60e14aa88f57723e2,Resize pictures in ref-arch,ABANDONED,2014-03-06 15:39:49.000000000,2014-03-06 17:28:17.000000000,,"[{'_account_id': 3}, {'_account_id': 8971}]","[{'number': 1, 'created': '2014-03-06 15:39:49.000000000', 'files': ['pages/reference-architecture/0020-logical-setup.rst'], 'web_link': 'https://opendev.org/openstack/fuel-docs/commit/f7d65f644b34b8017ac9e36a44365884b05853ea', 'message': 'Resize pictures in ref-arch\n\nChange-Id: Ie7ac583ada3062204d5a61d60e14aa88f57723e2\n'}]",0,78637,f7d65f644b34b8017ac9e36a44365884b05853ea,5,2,1,9037,,,0,"Resize pictures in ref-arch

Change-Id: Ie7ac583ada3062204d5a61d60e14aa88f57723e2
",git fetch https://review.opendev.org/openstack/fuel-docs refs/changes/37/78637/1 && git format-patch -1 --stdout FETCH_HEAD,['pages/reference-architecture/0020-logical-setup.rst'],1,f7d65f644b34b8017ac9e36a44365884b05853ea,redraw-ref-schemes, :width: 40% :width: 40%, :width: 80% :width: 80%,2,2
openstack%2Fcookbook-openstack-identity~master~I1042c5b6d602dc100719e4b2e48e0aafce7facf9,openstack/cookbook-openstack-identity,master,I1042c5b6d602dc100719e4b2e48e0aafce7facf9,Fixed the typo in the condition to check for valid user_uuid instead of the tenant_uuid in create_ec2_credentials action,MERGED,2014-03-06 16:03:52.000000000,2014-03-06 17:21:06.000000000,2014-03-06 17:21:06.000000000,"[{'_account_id': 3}, {'_account_id': 2340}, {'_account_id': 7128}, {'_account_id': 9884}, {'_account_id': 10250}]","[{'number': 1, 'created': '2014-03-06 16:03:52.000000000', 'files': ['providers/register.rb'], 'web_link': 'https://opendev.org/openstack/cookbook-openstack-identity/commit/aabaabfa1fa8b4255289a9268b9d2f6f06cb1d59', 'message': 'Fixed the typo in the condition to check for valid user_uuid\ninstead of the tenant_uuid in create_ec2_credentials action\n\nChange-Id: I1042c5b6d602dc100719e4b2e48e0aafce7facf9\n'}]",0,78645,aabaabfa1fa8b4255289a9268b9d2f6f06cb1d59,10,5,1,10379,,,0,"Fixed the typo in the condition to check for valid user_uuid
instead of the tenant_uuid in create_ec2_credentials action

Change-Id: I1042c5b6d602dc100719e4b2e48e0aafce7facf9
",git fetch https://review.opendev.org/openstack/cookbook-openstack-identity refs/changes/45/78645/1 && git format-patch -1 --stdout FETCH_HEAD,['providers/register.rb'],1,aabaabfa1fa8b4255289a9268b9d2f6f06cb1d59,Typo_Fix_EC2_Credentials_Action, unless user_uuid, unless tenant_uuid,1,1
openstack%2Ffuel-web~master~I74d67f1b2b13f8a94d9cdc9c14d0a1e2298a5182,openstack/fuel-web,master,I74d67f1b2b13f8a94d9cdc9c14d0a1e2298a5182,Add rst2pdf build option and tocdepth correction,ABANDONED,2014-03-06 14:39:36.000000000,2014-03-06 17:18:33.000000000,,"[{'_account_id': 3}, {'_account_id': 8971}, {'_account_id': 9037}]","[{'number': 1, 'created': '2014-03-06 14:39:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/b9d1c4f41ee402c8ea3d84c419ae8e94281743d2', 'message': 'Add rst2pdf build option and tocdepth correction\n\nChange-Id: I74d67f1b2b13f8a94d9cdc9c14d0a1e2298a5182\n'}, {'number': 2, 'created': '2014-03-06 14:41:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/f183f33cb93b30c2b9077d52bf816d5538a6c11f', 'message': 'Add rst2pdf build option and tocdepth correction\n\nChange-Id: I74d67f1b2b13f8a94d9cdc9c14d0a1e2298a5182\n'}, {'number': 3, 'created': '2014-03-06 14:43:16.000000000', 'files': ['docs/common_conf.py', 'docs/conf.py', 'docs/develop.rst', 'docs/develop/env.rst', 'docs/index.rst', 'build_docs.sh', 'nailgun/test-requirements.txt', 'docs/Makefile'], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/bfb212be48f44860b49a9cb23319eb79f42595bf', 'message': 'Add rst2pdf build option and tocdepth correction\n\nChange-Id: I74d67f1b2b13f8a94d9cdc9c14d0a1e2298a5182\n'}]",0,78618,bfb212be48f44860b49a9cb23319eb79f42595bf,12,3,3,9037,,,0,"Add rst2pdf build option and tocdepth correction

Change-Id: I74d67f1b2b13f8a94d9cdc9c14d0a1e2298a5182
",git fetch https://review.opendev.org/openstack/fuel-web refs/changes/18/78618/1 && git format-patch -1 --stdout FETCH_HEAD,"['docs/common_conf.py', 'docs/conf.py', 'docs/develop.rst', 'build_docs.sh', 'docs/develop/env.rst', 'docs/index.rst', 'nailgun/test-requirements.txt', 'docs/Makefile']",8,b9d1c4f41ee402c8ea3d84c419ae8e94281743d2,build_docs," @echo "" pdf to make PDF using rst2pdf""pdf: $(SPHINXBUILD) -b pdf $(ALLSPHINXOPTS) $(BUILDDIR)/pdf @echo @echo ""Build finished; the PDF file is in $(BUILDDIR)/pdf."" ",,39,21
openstack%2Ffuel-web~master~Iaafe6e7378a8951af71e4b6fb40e87b6597ed3fd,openstack/fuel-web,master,Iaafe6e7378a8951af71e4b6fb40e87b6597ed3fd,Rename project from scaffold to fuel,ABANDONED,2014-03-06 16:34:38.000000000,2014-03-06 17:18:17.000000000,,"[{'_account_id': 3}, {'_account_id': 8971}, {'_account_id': 9037}]","[{'number': 1, 'created': '2014-03-06 16:34:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/692a53a1d7870b9d652676bd1ae1906fcffa8392', 'message': 'Rename project from scuffold to fuel\n\nAnd some other corrections and fixes\n\nChange-Id: Iaafe6e7378a8951af71e4b6fb40e87b6597ed3fd\n'}, {'number': 2, 'created': '2014-03-06 16:42:08.000000000', 'files': ['docs/make.bat', 'docs/common_conf.py', 'docs/conf.py', 'build_docs.sh', 'docs/Makefile'], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/85814e91d35ae01754351b4f3823e7cddb837970', 'message': 'Rename project from scaffold to fuel\n\nAnd some other corrections and fixes\n\nChange-Id: Iaafe6e7378a8951af71e4b6fb40e87b6597ed3fd\n'}]",0,78657,85814e91d35ae01754351b4f3823e7cddb837970,12,3,2,9037,,,0,"Rename project from scaffold to fuel

And some other corrections and fixes

Change-Id: Iaafe6e7378a8951af71e4b6fb40e87b6597ed3fd
",git fetch https://review.opendev.org/openstack/fuel-web refs/changes/57/78657/1 && git format-patch -1 --stdout FETCH_HEAD,"['docs/common_conf.py', 'docs/make.bat', 'docs/conf.py', 'build_docs.sh', 'docs/Makefile']",5,692a53a1d7870b9d652676bd1ae1906fcffa8392,build_docs," @echo ""# qcollectiongenerator $(BUILDDIR)/qthelp/fuel.qhcp"" @echo ""# assistant -collectionFile $(BUILDDIR)/qthelp/fuel.qhc"" @echo ""# mkdir -p $$HOME/.local/share/devhelp/fuel"" @echo ""# ln -s $(BUILDDIR)/devhelp $$HOME/.local/share/devhelp/fuel"""," @echo ""# qcollectiongenerator $(BUILDDIR)/qthelp/scaffold.qhcp"" @echo ""# assistant -collectionFile $(BUILDDIR)/qthelp/scaffold.qhc"" @echo ""# mkdir -p $$HOME/.local/share/devhelp/scaffold"" @echo ""# ln -s $(BUILDDIR)/devhelp $$HOME/.local/share/devhelp/scaffold""",35,26
openstack%2Fpuppet-neutron~stable%2Fhavana~If95c20e3c4a07e09ee6d98c3b8076f9ead7d84f6,openstack/puppet-neutron,stable/havana,If95c20e3c4a07e09ee6d98c3b8076f9ead7d84f6,ml2: fix wrong package dependency for Debian/Ubuntu,MERGED,2014-03-06 16:51:27.000000000,2014-03-06 17:15:18.000000000,2014-03-06 17:15:18.000000000,"[{'_account_id': 3}, {'_account_id': 6754}, {'_account_id': 7156}]","[{'number': 1, 'created': '2014-03-06 16:51:27.000000000', 'files': ['manifests/plugins/ml2.pp'], 'web_link': 'https://opendev.org/openstack/puppet-neutron/commit/fcb9eb8fc150ff0ace470149686c650a89155335', 'message': 'ml2: fix wrong package dependency for Debian/Ubuntu\n\nIn a previous commit, I introduced a wrong package dependency on ML2\nplugin.\nSince there is not specific package for ml2 plugin on Debian plateforms,\nthe configuration would just require the neutron-common package.\n\nCloses-bug #1288741\nSigned-off-by: Emilien Macchi <emilien.macchi@enovance.com>\nChange-Id: If95c20e3c4a07e09ee6d98c3b8076f9ead7d84f6\n(cherry picked from commit efb77ecc2cae5bed4d8c9add9c53c9f0147ac5b1)\n'}]",0,78666,fcb9eb8fc150ff0ace470149686c650a89155335,7,3,1,3153,,,0,"ml2: fix wrong package dependency for Debian/Ubuntu

In a previous commit, I introduced a wrong package dependency on ML2
plugin.
Since there is not specific package for ml2 plugin on Debian plateforms,
the configuration would just require the neutron-common package.

Closes-bug #1288741
Signed-off-by: Emilien Macchi <emilien.macchi@enovance.com>
Change-Id: If95c20e3c4a07e09ee6d98c3b8076f9ead7d84f6
(cherry picked from commit efb77ecc2cae5bed4d8c9add9c53c9f0147ac5b1)
",git fetch https://review.opendev.org/openstack/puppet-neutron refs/changes/66/78666/1 && git format-patch -1 --stdout FETCH_HEAD,['manifests/plugins/ml2.pp'],1,fcb9eb8fc150ff0ace470149686c650a89155335,bug/1288741, require => Package['neutron'], require => Package['openstack-neutron'],1,1
openstack%2Foslo-incubator~master~I4be81718399393d817185abe36f4cc4d3da15000,openstack/oslo-incubator,master,I4be81718399393d817185abe36f4cc4d3da15000,Get mysql_sql_mode parameter from config,MERGED,2014-03-06 10:25:23.000000000,2014-03-06 17:02:15.000000000,2014-03-06 17:02:14.000000000,"[{'_account_id': 3}, {'_account_id': 2472}, {'_account_id': 6928}]","[{'number': 1, 'created': '2014-03-06 10:25:23.000000000', 'files': ['tests/unit/db/sqlalchemy/test_sqlalchemy.py', 'openstack/common/db/sqlalchemy/session.py'], 'web_link': 'https://opendev.org/openstack/oslo-incubator/commit/9933bdd9a225f0c61a3d7e2791da07e8e1c81550', 'message': ""Get mysql_sql_mode parameter from config\n\nPatch Ia527e850671ab9542db5864617384cee21e91bf6 added mysql_sql_mode\noption to config, so we should get it's value from CONF object, not\nfrom function argument.\n\nCloses-Bug: #1288445\n\nChange-Id: I4be81718399393d817185abe36f4cc4d3da15000\n""}]",0,78569,9933bdd9a225f0c61a3d7e2791da07e8e1c81550,7,3,1,7491,,,0,"Get mysql_sql_mode parameter from config

Patch Ia527e850671ab9542db5864617384cee21e91bf6 added mysql_sql_mode
option to config, so we should get it's value from CONF object, not
from function argument.

Closes-Bug: #1288445

Change-Id: I4be81718399393d817185abe36f4cc4d3da15000
",git fetch https://review.opendev.org/openstack/oslo-incubator refs/changes/69/78569/1 && git format-patch -1 --stdout FETCH_HEAD,"['tests/unit/db/sqlalchemy/test_sqlalchemy.py', 'openstack/common/db/sqlalchemy/session.py']",2,9933bdd9a225f0c61a3d7e2791da07e8e1c81550,fix-mysql_sql_mode," sqlite_fk=False, autocommit=True, expire_on_commit=False, **kwargs): :keyword mysql_sql_mode: the SQL mode to be used for MySQL sessions. (defaults to TRADITIONAL) mysql_sql_mode=kwargs.get('mysql_sql_mode', 'TRADITIONAL'), sqlite_fk=False, autocommit=True, expire_on_commit=False):"," sqlite_fk=False, mysql_sql_mode=None, autocommit=True, expire_on_commit=False, **kwargs): :param mysql_sql_mode: set SQL mode in MySQL :type mysql_sql_mode: string mysql_sql_mode=mysql_sql_mode, sqlite_fk=False, mysql_sql_mode=None, autocommit=True, expire_on_commit=False): :param mysql_sql_mode: set SQL mode in MySQL :type mysql_sql_mode: string mysql_sql_mode=mysql_sql_mode,",9,15
openstack%2Fpuppet-neutron~master~If95c20e3c4a07e09ee6d98c3b8076f9ead7d84f6,openstack/puppet-neutron,master,If95c20e3c4a07e09ee6d98c3b8076f9ead7d84f6,ml2: fix wrong package dependency for Debian/Ubuntu,MERGED,2014-03-06 13:48:26.000000000,2014-03-06 16:48:23.000000000,2014-03-06 16:48:23.000000000,"[{'_account_id': 3}, {'_account_id': 1918}, {'_account_id': 6754}, {'_account_id': 6967}, {'_account_id': 7156}, {'_account_id': 7616}, {'_account_id': 7822}]","[{'number': 1, 'created': '2014-03-06 13:48:26.000000000', 'files': ['manifests/plugins/ml2.pp'], 'web_link': 'https://opendev.org/openstack/puppet-neutron/commit/efb77ecc2cae5bed4d8c9add9c53c9f0147ac5b1', 'message': 'ml2: fix wrong package dependency for Debian/Ubuntu\n\nIn a previous commit, I introduced a wrong package dependency on ML2\nplugin.\nSince there is not specific package for ml2 plugin on Debian plateforms,\nthe configuration would just require the neutron-common package.\n\nCloses-bug #1288741\nSigned-off-by: Emilien Macchi <emilien.macchi@enovance.com>\n\nChange-Id: If95c20e3c4a07e09ee6d98c3b8076f9ead7d84f6\n'}]",0,78603,efb77ecc2cae5bed4d8c9add9c53c9f0147ac5b1,8,7,1,3153,,,0,"ml2: fix wrong package dependency for Debian/Ubuntu

In a previous commit, I introduced a wrong package dependency on ML2
plugin.
Since there is not specific package for ml2 plugin on Debian plateforms,
the configuration would just require the neutron-common package.

Closes-bug #1288741
Signed-off-by: Emilien Macchi <emilien.macchi@enovance.com>

Change-Id: If95c20e3c4a07e09ee6d98c3b8076f9ead7d84f6
",git fetch https://review.opendev.org/openstack/puppet-neutron refs/changes/03/78603/1 && git format-patch -1 --stdout FETCH_HEAD,['manifests/plugins/ml2.pp'],1,efb77ecc2cae5bed4d8c9add9c53c9f0147ac5b1,bug/1288741, require => Package['neutron'], require => Package['openstack-neutron'],1,1
openstack%2Fnova~master~Idd899ec2c177c9b5695b6908bc897fe3e759beca,openstack/nova,master,Idd899ec2c177c9b5695b6908bc897fe3e759beca,Address the comments of the merged image handler patch,MERGED,2014-03-05 11:28:43.000000000,2014-03-06 16:38:29.000000000,2014-03-06 00:51:31.000000000,"[{'_account_id': 3}, {'_account_id': 679}, {'_account_id': 1653}, {'_account_id': 1812}, {'_account_id': 5170}, {'_account_id': 6549}, {'_account_id': 6873}, {'_account_id': 7730}, {'_account_id': 9578}]","[{'number': 1, 'created': '2014-03-05 11:28:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/4ac5e7bcd154fb99d4a5c718437ebbd566fbce0f', 'message': 'Address the comments of the merged image handler patch\n\nThree minor things which was commented in change:\nIdce8d21ae37bfdbb28a2567120a83d1061061904\n\nChange-Id: Idd899ec2c177c9b5695b6908bc897fe3e759beca\nSigned-off-by: Zhi Yan Liu <zhiyanl@cn.ibm.com>'}, {'number': 2, 'created': '2014-03-05 15:39:46.000000000', 'files': ['nova/virt/imagehandler/__init__.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/9e8513e6fe4bf8a8759ad0c1d71594f952d920ad', 'message': 'Address the comments of the merged image handler patch\n\nThree minor things which was commented in change:\nIdce8d21ae37bfdbb28a2567120a83d1061061904\n\nChange-Id: Idd899ec2c177c9b5695b6908bc897fe3e759beca\nSigned-off-by: Zhi Yan Liu <zhiyanl@cn.ibm.com>\n'}]",3,78166,9e8513e6fe4bf8a8759ad0c1d71594f952d920ad,21,9,2,6549,,,0,"Address the comments of the merged image handler patch

Three minor things which was commented in change:
Idce8d21ae37bfdbb28a2567120a83d1061061904

Change-Id: Idd899ec2c177c9b5695b6908bc897fe3e759beca
Signed-off-by: Zhi Yan Liu <zhiyanl@cn.ibm.com>
",git fetch https://review.opendev.org/openstack/nova refs/changes/66/78166/1 && git format-patch -1 --stdout FETCH_HEAD,"['nova/virt/libvirt/imagecache.py', 'nova/virt/imagehandler/__init__.py']",2,4ac5e7bcd154fb99d4a5c718437ebbd566fbce0f,," CinderImageHandler will need to re-prepare iscsi/fc link for volumes LOG.error(_(""Can not handle image: %(image_id)s %(target_path)s""),"," CinderImageHandler will need to re-preapre iscsi/fc link for volumes LOG.error(_(""Can't handle image: %(image_id)s %(target_path)s""),",4,3
openstack%2Fdevstack~master~Idb56b87349a5a84d5d255715cfb7191341363118,openstack/devstack,master,Idb56b87349a5a84d5d255715cfb7191341363118,Use cat instead of read<file,MERGED,2014-03-01 05:23:16.000000000,2014-03-06 16:24:13.000000000,2014-03-06 16:24:12.000000000,"[{'_account_id': 3}, {'_account_id': 159}, {'_account_id': 970}, {'_account_id': 1177}, {'_account_id': 2750}, {'_account_id': 5689}, {'_account_id': 6493}, {'_account_id': 6786}, {'_account_id': 7838}, {'_account_id': 9173}, {'_account_id': 9907}]","[{'number': 1, 'created': '2014-03-01 05:23:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack/commit/69805afaeed20f4b2091a6c05b4fd25ee54bdf70', 'message': ""Allow exit 1 from 'read < file'\n\nWhen reading a file, it is expected that\nthe read process will exit 1 as this is\nexpected whenever the input reaches an EOF.\n\nChange-Id: Idb56b87349a5a84d5d255715cfb7191341363118\nCloses-Bug: 1286441\n""}, {'number': 2, 'created': '2014-03-04 16:35:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack/commit/95189bdf8ac16f72f79564b1929043d38421997c', 'message': ""Use cat instead od read<file\n\nWhen reading a file, it is expected that\nthe read process will exit 1 as this is\nexpected whenever the input reaches an EOF.\n\nBecause it is not clear if the 'exit 1' is\nfrom a successful read or a more serious error,\nand as this edge-case of 'read' is not well-known,\nwe instead change this code to read the file using\n'cat'.\n\nFurthermore, we now quote the variables and check\nfor the existance of the pid file for better and safer\nerror handling.\n\nChange-Id: Idb56b87349a5a84d5d255715cfb7191341363118\nCloses-Bug: 1286441\n""}, {'number': 3, 'created': '2014-03-04 16:49:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack/commit/74bedbbbc6041963f3a0550e360aacf288f3df18', 'message': ""Use cat instead od read<file\n\nWhen reading a file, it is expected that\nthe read process will exit 1 as this is\nexpected whenever the input reaches an EOF.\n\nBecause it is not clear if the 'exit 1' is\nfrom a successful read or a more serious error,\nand as this edge-case of 'read' is not well-known,\nwe instead change this code to read the file using\n'cat'.\n\nThe new code is moved into a function, is_docker_running.\n\nFurthermore, we now quote the variables and check\nfor the existance of the pid file for better and safer\nerror handling.\n\nChange-Id: Idb56b87349a5a84d5d255715cfb7191341363118\nCloses-Bug: 1286441\n""}, {'number': 4, 'created': '2014-03-04 17:48:58.000000000', 'files': ['lib/nova_plugins/hypervisor-docker'], 'web_link': 'https://opendev.org/openstack/devstack/commit/3d2bdf50bc0110c718de39606c8b803696a31285', 'message': ""Use cat instead of read<file\n\nWhen reading a file, it is expected that\nthe read process will exit 1 as this is\nexpected whenever the input reaches an EOF.\n\nBecause it is not clear if the 'exit 1' is\nfrom a successful read or a more serious error,\nand as this edge-case of 'read' is not well-known,\nwe instead change this code to read the file using\n'cat'.\n\nThe new code is moved into a function, is_docker_running.\n\nFurthermore, we now quote the variables and check\nfor the existance of the pid file for better and safer\nerror handling.\n\nChange-Id: Idb56b87349a5a84d5d255715cfb7191341363118\nCloses-Bug: 1286441\n""}]",1,77332,3d2bdf50bc0110c718de39606c8b803696a31285,31,11,4,159,,,0,"Use cat instead of read<file

When reading a file, it is expected that
the read process will exit 1 as this is
expected whenever the input reaches an EOF.

Because it is not clear if the 'exit 1' is
from a successful read or a more serious error,
and as this edge-case of 'read' is not well-known,
we instead change this code to read the file using
'cat'.

The new code is moved into a function, is_docker_running.

Furthermore, we now quote the variables and check
for the existance of the pid file for better and safer
error handling.

Change-Id: Idb56b87349a5a84d5d255715cfb7191341363118
Closes-Bug: 1286441
",git fetch https://review.opendev.org/openstack/devstack refs/changes/32/77332/1 && git format-patch -1 --stdout FETCH_HEAD,['lib/nova_plugins/hypervisor-docker'],1,69805afaeed20f4b2091a6c05b4fd25ee54bdf70,bug/1286441, read docker_pid <$DOCKER_PID_FILE || : read docker_pid <$DOCKER_PID_FILE || :, read docker_pid <$DOCKER_PID_FILE read docker_pid <$DOCKER_PID_FILE,2,2
openstack%2Fheat~master~Ie0430a86ef4e5088873c5779b94e812feeb3c5be,openstack/heat,master,Ie0430a86ef4e5088873c5779b94e812feeb3c5be,Decorate StackNotFound exceptions for a variety of RPC calls,ABANDONED,2014-03-05 05:45:24.000000000,2014-03-06 16:18:35.000000000,,"[{'_account_id': 3}, {'_account_id': 2834}, {'_account_id': 4257}, {'_account_id': 4571}]","[{'number': 1, 'created': '2014-03-05 05:45:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/2310a4f30e40296fe1d1b12b2b30c5fa317ff40d', 'message': 'Ensure StackNotFound is properly returned to the user\n\nStackNotFound is not properly wrapped in a variety of RPC calls.\n\nChange-Id: Ie0430a86ef4e5088873c5779b94e812feeb3c5be\nblueprint: oslo-messaging\nCloses-bug: 1287445\n'}, {'number': 2, 'created': '2014-03-05 05:51:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/2d5b1b6d17299f5ca70e8764733e925706081343', 'message': 'Decorate StackNotFound exceptions for a variety of RPC calls\n\nStackNotFound is not properly wrapped in a variety of RPC calls.\n\nChange-Id: Ie0430a86ef4e5088873c5779b94e812feeb3c5be\nblueprint: oslo-messaging\nCloses-bug: 1287445\n'}, {'number': 3, 'created': '2014-03-06 01:31:54.000000000', 'files': ['heat/tests/test_engine_service.py', 'heat/engine/service.py'], 'web_link': 'https://opendev.org/openstack/heat/commit/c2d2b2c003914655ac41d9ed7cd588562cf07f2e', 'message': 'Decorate StackNotFound exceptions for a variety of RPC calls\n\nStackNotFound is not properly wrapped in a variety of RPC calls.\n\nChange-Id: Ie0430a86ef4e5088873c5779b94e812feeb3c5be\nblueprint: oslo-messaging\nCloses-bug: 1287445\n'}]",0,78101,c2d2b2c003914655ac41d9ed7cd588562cf07f2e,18,4,3,2834,,,0,"Decorate StackNotFound exceptions for a variety of RPC calls

StackNotFound is not properly wrapped in a variety of RPC calls.

Change-Id: Ie0430a86ef4e5088873c5779b94e812feeb3c5be
blueprint: oslo-messaging
Closes-bug: 1287445
",git fetch https://review.opendev.org/openstack/heat refs/changes/01/78101/1 && git format-patch -1 --stdout FETCH_HEAD,"['heat/tests/test_engine_service.py', 'heat/engine/service.py']",2,2310a4f30e40296fe1d1b12b2b30c5fa317ff40d,bp/oslo-messaging, @rpc_common.client_exceptions(exception.StackNotFound) @rpc_common.client_exceptions(exception.StackNotFound) @rpc_common.client_exceptions(exception.StackNotFound) @rpc_common.client_exceptions(exception.StackNotFound) @rpc_common.client_exceptions(exception.StackNotFound) @rpc_common.client_exceptions(exception.StackNotFound) @rpc_common.client_exceptions(exception.StackNotFound) @rpc_common.client_exceptions(exception.StackNotFound) @rpc_common.client_exceptions(exception.StackNotFound) @rpc_common.client_exceptions(exception.StackNotFound) @rpc_common.client_exceptions(exception.StackNotFound) @rpc_common.client_exceptions(exception.StackNotFound) @rpc_common.client_exceptions(exception.StackNotFound),,51,27
openstack%2Fdevstack~master~Ie43e376f42f14c46d21df7dbb19db923521f438b,openstack/devstack,master,Ie43e376f42f14c46d21df7dbb19db923521f438b,Fix typo in ironic configure function,MERGED,2014-03-04 14:45:21.000000000,2014-03-06 16:17:27.000000000,2014-03-06 16:17:26.000000000,"[{'_account_id': 3}, {'_account_id': 970}, {'_account_id': 2750}, {'_account_id': 8003}]","[{'number': 1, 'created': '2014-03-04 14:45:21.000000000', 'files': ['lib/ironic'], 'web_link': 'https://opendev.org/openstack/devstack/commit/a67cb1af4df6b5c758c319e0590a3188d951e68d', 'message': 'Fix typo in ironic configure function\n\nIRONIC_CONF should be replaced by IRONIC_CONF_FILE\n\nChange-Id: Ie43e376f42f14c46d21df7dbb19db923521f438b\n'}]",0,77896,a67cb1af4df6b5c758c319e0590a3188d951e68d,14,4,1,8003,,,0,"Fix typo in ironic configure function

IRONIC_CONF should be replaced by IRONIC_CONF_FILE

Change-Id: Ie43e376f42f14c46d21df7dbb19db923521f438b
",git fetch https://review.opendev.org/openstack/devstack refs/changes/96/77896/1 && git format-patch -1 --stdout FETCH_HEAD,['lib/ironic'],1,a67cb1af4df6b5c758c319e0590a3188d951e68d,ironic_conf_typo, iniset $IRONIC_CONF_FILE DEFAULT rootwrap_config $IRONIC_ROOTWRAP_CONF, iniset $IRONIC_CONF DEFAULT rootwrap_config $IRONIC_ROOTWRAP_CONF,1,1
openstack%2Frally~master~I1a6bcda26de03f6f0daf56dd687f857c029d6b54,openstack/rally,master,I1a6bcda26de03f6f0daf56dd687f857c029d6b54,added decorator-based mocks declaration to,MERGED,2014-03-06 12:15:19.000000000,2014-03-06 16:12:19.000000000,2014-03-06 16:12:18.000000000,"[{'_account_id': 3}, {'_account_id': 6172}, {'_account_id': 7217}, {'_account_id': 8507}, {'_account_id': 10352}]","[{'number': 1, 'created': '2014-03-06 12:15:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/20dad10cde60735a17781d01f86ebb1252f70cf2', 'message': 'added decorator-based mocks declaration to\n\n    * test_openstack_provider_init\n    * test_openstack_provider_init_no_glance\n    * test_openstack_provider_init_with_invalid_conf_no_user\n    * test_openstack_provider_init_with_invalid_conf_no_url\n    * test_openstack_provider_init_with_invalid_conf_extra_key\n    * test_openstack_provider_init_with_invalid_conf_flavor_\n    * test_openstack_provider_with_valid_config\n    * test_openstack_provider_with_valid_config_uuid\n    * test_openstack_provider_with_valid_config_checksum\n\nChange-Id: I1a6bcda26de03f6f0daf56dd687f857c029d6b54\n'}, {'number': 2, 'created': '2014-03-06 14:37:00.000000000', 'files': ['tests/serverprovider/providers/test_openstack.py'], 'web_link': 'https://opendev.org/openstack/rally/commit/9070b851d582aebf273bafb0ecc32a7111d33c8d', 'message': 'added decorator-based mocks declaration to\n\n    * test_openstack_provider_init\n    * test_openstack_provider_init_no_glance\n    * test_openstack_provider_init_with_invalid_conf_no_user\n    * test_openstack_provider_init_with_invalid_conf_no_url\n    * test_openstack_provider_init_with_invalid_conf_extra_key\n    * test_openstack_provider_init_with_invalid_conf_flavor_\n    * test_openstack_provider_with_valid_config\n    * test_openstack_provider_with_valid_config_uuid\n    * test_openstack_provider_with_valid_config_checksum\n\nChange-Id: I1a6bcda26de03f6f0daf56dd687f857c029d6b54\n'}]",1,78589,9070b851d582aebf273bafb0ecc32a7111d33c8d,11,5,2,10352,,,0,"added decorator-based mocks declaration to

    * test_openstack_provider_init
    * test_openstack_provider_init_no_glance
    * test_openstack_provider_init_with_invalid_conf_no_user
    * test_openstack_provider_init_with_invalid_conf_no_url
    * test_openstack_provider_init_with_invalid_conf_extra_key
    * test_openstack_provider_init_with_invalid_conf_flavor_
    * test_openstack_provider_with_valid_config
    * test_openstack_provider_with_valid_config_uuid
    * test_openstack_provider_with_valid_config_checksum

Change-Id: I1a6bcda26de03f6f0daf56dd687f857c029d6b54
",git fetch https://review.opendev.org/openstack/rally refs/changes/89/78589/2 && git format-patch -1 --stdout FETCH_HEAD,['tests/serverprovider/providers/test_openstack.py'],1,20dad10cde60735a17781d01f86ebb1252f70cf2,develop3," return_value=self.glance_client) return_value=self.instance) return_value=self.nova_client) @mock.patch(""rally.serverprovider.providers.openstack.osclients"") def test_openstack_provider_init(self, os_cli): os_cli.Clients = mock.MagicMock(return_value=FakeOSClients()) os_provider = OSProvider(mock.MagicMock(), cfg) @mock.patch(""rally.serverprovider.providers.openstack.osclients"") def test_openstack_provider_init_with_invalid_conf_no_user(self, mock_osclient): self.assertRaises(jsonschema.ValidationError, OSProvider, mock.MagicMock(), cfg) @mock.patch(""rally.serverprovider.providers.openstack.osclients"") def test_openstack_provider_init_with_invalid_conf_no_url(self, mock_osclient): self.assertRaises(jsonschema.ValidationError, OSProvider, mock.MagicMock(), cfg) @mock.patch(""rally.serverprovider.providers.openstack.osclients"") def test_openstack_provider_init_with_invalid_conf_extra_key(self, mock_osclnt): self.assertRaises(jsonschema.ValidationError, OSProvider, mock.MagicMock(), cfg) @mock.patch(""rally.serverprovider.providers.openstack.osclients"") def test_openstack_provider_init_with_invalid_conf_flavor_(self, mock_osclient): self.assertRaises(jsonschema.ValidationError, OSProvider, mock.MagicMock(), cfg) @mock.patch(""rally.serverprovider.providers.openstack.osclients"") def test_openstack_provider_with_valid_config(self, mock_osclient): OSProvider(mock.MagicMock(), cfg) @mock.patch(""rally.serverprovider.providers.openstack.osclients"") def test_openstack_provider_with_valid_config_uuid(self, mock_osclient): OSProvider(mock.MagicMock(), cfg) @mock.patch(""rally.serverprovider.providers.openstack.osclients"") def test_openstack_provider_with_valid_config_checksum(self, mock_osclient): OSProvider(mock.MagicMock(), cfg) '35FC0503-FED6-419F-B6EE-B704198CE642')"," return_value=self.glance_client) return_value=self.instance) return_value=self.nova_client) def test_openstack_provider_init(self): mod = ""rally.serverprovider.providers.openstack."" with mock.patch(mod + ""osclients"") as os_cli: os_cli.Clients = mock.MagicMock(return_value=FakeOSClients()) os_provider = OSProvider(mock.MagicMock(), cfg) def test_openstack_provider_init_with_invalid_conf_no_user(self): with mock.patch(""rally.serverprovider.providers.openstack.osclients""): self.assertRaises(jsonschema.ValidationError, OSProvider, mock.MagicMock(), cfg) def test_openstack_provider_init_with_invalid_conf_no_url(self): with mock.patch(""rally.serverprovider.providers.openstack.osclients""): self.assertRaises(jsonschema.ValidationError, OSProvider, mock.MagicMock(), cfg) def test_openstack_provider_init_with_invalid_conf_extra_key(self): with mock.patch(""rally.serverprovider.providers.openstack.osclients""): self.assertRaises(jsonschema.ValidationError, OSProvider, mock.MagicMock(), cfg) def test_openstack_provider_init_with_invalid_conf_flavor_(self): with mock.patch(""rally.serverprovider.providers.openstack.osclients""): self.assertRaises(jsonschema.ValidationError, OSProvider, mock.MagicMock(), cfg) def test_openstack_provider_with_valid_config(self): with mock.patch(""rally.serverprovider.providers.openstack.osclients""): OSProvider(mock.MagicMock(), cfg) def test_openstack_provider_with_valid_config_uuid(self): with mock.patch(""rally.serverprovider.providers.openstack.osclients""): OSProvider(mock.MagicMock(), cfg) def test_openstack_provider_with_valid_config_checksum(self): with mock.patch(""rally.serverprovider.providers.openstack.osclients""): OSProvider(mock.MagicMock(), cfg) '35FC0503-FED6-419F-B6EE-B704198CE642')",39,35
openstack%2Foslo-incubator~master~Ie9df3aaa5f48d992b61a9ea480d1e17519f16422,openstack/oslo-incubator,master,Ie9df3aaa5f48d992b61a9ea480d1e17519f16422,"Drop special case for MySQL traditional mode, update unit tests",MERGED,2014-01-24 22:12:15.000000000,2014-03-06 16:04:10.000000000,2014-03-06 16:04:09.000000000,"[{'_account_id': 3}, {'_account_id': 1994}, {'_account_id': 2463}, {'_account_id': 2472}, {'_account_id': 5638}, {'_account_id': 5652}, {'_account_id': 6172}, {'_account_id': 6849}, {'_account_id': 6928}, {'_account_id': 7491}, {'_account_id': 9397}]","[{'number': 1, 'created': '2014-01-24 22:12:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo-incubator/commit/0a1e6ba7aa55cc279f191ac087f106ec23f7a0f6', 'message': ""Drop special case for MySQL traditional mode, update unit tests\n\nSince there are no users of the special-case TRADITIONAL mode set,\nit's OK to drop those references and use only the more flexible\none tuned via a config option.\n\nUpdate the TRADITIONAL mode unit test, and also add one for\nSTRICT_ALL_TABLES mode.\n\nChange-Id: Ie9df3aaa5f48d992b61a9ea480d1e17519f16422\n""}, {'number': 2, 'created': '2014-01-24 22:25:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo-incubator/commit/7b9d5e65af524a21ee24507b8be69dcc139089f1', 'message': ""Drop special case for MySQL traditional mode, update unit tests\n\nSince there are no users of the special-case TRADITIONAL mode set,\nit's OK to drop those references and use only the more flexible\none tuned via a config option.\n\nUpdate the TRADITIONAL mode unit test, and also add one for\nSTRICT_ALL_TABLES mode.\n\nChange-Id: Ie9df3aaa5f48d992b61a9ea480d1e17519f16422\n""}, {'number': 3, 'created': '2014-01-24 22:37:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo-incubator/commit/ff6bce67a622f69fa11005bc18e80f31ba151090', 'message': ""Drop special case for MySQL traditional mode, update unit tests\n\nSince there are no users of the special-case TRADITIONAL mode set,\nit's OK to drop those references and use only the more flexible\none tuned via a config option.\n\nUpdate the TRADITIONAL mode unit test, and also add one for\nSTRICT_ALL_TABLES mode.\n\nChange-Id: Ie9df3aaa5f48d992b61a9ea480d1e17519f16422\n""}, {'number': 4, 'created': '2014-01-27 08:35:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo-incubator/commit/103246186272a7be4ac390e7f177faf6b49f0a46', 'message': ""Drop special case for MySQL traditional mode, update unit tests\n\nSince there are no users of the special-case TRADITIONAL mode set,\nit's OK to drop those references and use only the more flexible\none tuned via a config option.\n\nUpdate the TRADITIONAL mode unit test, and also add one for\nSTRICT_ALL_TABLES mode.\n\nChange-Id: Ie9df3aaa5f48d992b61a9ea480d1e17519f16422\n""}, {'number': 5, 'created': '2014-01-28 14:33:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo-incubator/commit/ff82880e78e684de3182fa42276637b08eec5283', 'message': ""Drop special case for MySQL traditional mode, update unit tests\n\nSince there are no users of the special-case TRADITIONAL mode set,\nit's OK to drop those references and use only the more flexible\none tuned via a config option.\n\nUpdate the TRADITIONAL mode unit test, and also add one for\nSTRICT_ALL_TABLES mode.\n\nChange-Id: Ie9df3aaa5f48d992b61a9ea480d1e17519f16422\n""}, {'number': 6, 'created': '2014-01-28 14:45:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo-incubator/commit/af1adefb3d2dc809b65a1df4c81a50afdafc54e2', 'message': ""Drop special case for MySQL traditional mode, update unit tests\n\nSince there are no users of the special-case TRADITIONAL mode set,\nit's OK to drop those references and use only the more flexible\none tuned via a config option.\n\nUpdate the TRADITIONAL mode unit test, and also add one for\nSTRICT_ALL_TABLES mode.\n\nChange-Id: Ie9df3aaa5f48d992b61a9ea480d1e17519f16422\n""}, {'number': 7, 'created': '2014-01-28 14:52:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo-incubator/commit/912a1e9232934dbe104b1c5111f07638cb2a98a2', 'message': ""Drop special case for MySQL traditional mode, update unit tests\n\nSince there are no users of the special-case TRADITIONAL mode set,\nit's OK to drop those references and use only the more flexible\none tuned via a config option.\n\nUpdate the TRADITIONAL mode unit test, and also add one for\nSTRICT_ALL_TABLES mode.\n\nChange-Id: Ie9df3aaa5f48d992b61a9ea480d1e17519f16422\n""}, {'number': 8, 'created': '2014-01-28 15:28:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo-incubator/commit/ae7053d2f020649dd31f986de1ed640405658a12', 'message': ""Drop special case for MySQL traditional mode, update unit tests\n\nSince there are no users of the special-case TRADITIONAL mode set,\nit's OK to drop those references and use only the more flexible\none tuned via a config option.\n\nUpdate the TRADITIONAL mode unit test, and also add one for\nSTRICT_ALL_TABLES mode.\n\nChange-Id: Ie9df3aaa5f48d992b61a9ea480d1e17519f16422\n""}, {'number': 9, 'created': '2014-01-28 15:57:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo-incubator/commit/db49abb9b263e20561ae573e1f13138d7075c323', 'message': ""Drop special case for MySQL traditional mode, update unit tests\n\nSince there are no users of the special-case TRADITIONAL mode set,\nit's OK to drop those references and use only the more flexible\none tuned via a config option.\n\nUpdate the TRADITIONAL mode unit test, and also add one for\nSTRICT_ALL_TABLES mode.\n\nChange-Id: Ie9df3aaa5f48d992b61a9ea480d1e17519f16422\n""}, {'number': 10, 'created': '2014-01-28 18:04:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo-incubator/commit/e7e4167c13739de72fecb36444d4fcf3d95d3904', 'message': ""Drop special case for MySQL traditional mode, update unit tests\n\nSince there are no users of the special-case TRADITIONAL mode set,\nit's OK to drop those references and use only the more flexible\none tuned via a config option.\n\nUpdate the TRADITIONAL mode unit test, and also add one for\nSTRICT_ALL_TABLES mode.\n\nChange-Id: Ie9df3aaa5f48d992b61a9ea480d1e17519f16422\n""}, {'number': 11, 'created': '2014-01-28 19:35:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo-incubator/commit/5f7151ca4ce552aa299ca2b805d4d5d377f6439c', 'message': ""Drop special case for MySQL traditional mode, update unit tests\n\nSince there are no users of the special-case TRADITIONAL mode set,\nit's OK to drop those references and use only the more flexible\none tuned via a config option.\n\nUpdate the TRADITIONAL mode unit test, and also add one for\nSTRICT_ALL_TABLES mode.\n\nChange-Id: Ie9df3aaa5f48d992b61a9ea480d1e17519f16422\n""}, {'number': 12, 'created': '2014-01-28 20:00:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo-incubator/commit/679a14622306e8859f38685069cd81aefcffe7a3', 'message': ""Drop special case for MySQL traditional mode, update unit tests\n\nSince there are no users of the special-case TRADITIONAL mode set,\nit's OK to drop those references and use only the more flexible\none tuned via a config option.\n\nUpdate the TRADITIONAL mode unit test, and also add one for\nSTRICT_ALL_TABLES mode.\n\nChange-Id: Ie9df3aaa5f48d992b61a9ea480d1e17519f16422\n""}, {'number': 13, 'created': '2014-01-29 16:22:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo-incubator/commit/11e5dd04bcaeb460a06cf5d9433d9d07b4e9e193', 'message': ""Drop special case for MySQL traditional mode, update unit tests\n\nSince there are no users of the special-case TRADITIONAL mode set,\nit's OK to drop those references and use only the more flexible\none tuned via a config option.\n\nUpdate the TRADITIONAL mode unit test, and also add one for\nSTRICT_ALL_TABLES mode.\n\nChange-Id: Ie9df3aaa5f48d992b61a9ea480d1e17519f16422\n""}, {'number': 14, 'created': '2014-01-29 16:29:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo-incubator/commit/baf8bd9f8a20cb53d2481d24fa26bfc76c0d6396', 'message': ""Drop special case for MySQL traditional mode, update unit tests\n\nSince there are no users of the special-case TRADITIONAL mode set,\nit's OK to drop those references and use only the more flexible\none tuned via a config option.\n\nUpdate the TRADITIONAL mode unit test, and also add one for\nSTRICT_ALL_TABLES mode.\n\nChange-Id: Ie9df3aaa5f48d992b61a9ea480d1e17519f16422\n""}, {'number': 15, 'created': '2014-02-04 18:41:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo-incubator/commit/f26af5e355e6881a68f8f3a02371e6198fb1e9a4', 'message': ""Drop special case for MySQL traditional mode, update unit tests\n\nSince there are no users of the special-case TRADITIONAL mode set,\nit's OK to drop those references and use only the more flexible\none tuned via a config option.\n\nUpdate the TRADITIONAL mode unit test, and also add one for\nSTRICT_ALL_TABLES mode.\n\nChange-Id: Ie9df3aaa5f48d992b61a9ea480d1e17519f16422\n""}, {'number': 16, 'created': '2014-02-20 18:09:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo-incubator/commit/aaaf6b45189ba758954f5d7f8f5efae7ac0c79e7', 'message': ""Drop special case for MySQL traditional mode, update unit tests\n\nSince there are no users of the special-case TRADITIONAL mode set,\nit's OK to drop those references and use only the more flexible\none tuned via a config option.\n\nUpdate the TRADITIONAL mode unit test, and also add one for\nSTRICT_ALL_TABLES mode.\n\nChange-Id: Ie9df3aaa5f48d992b61a9ea480d1e17519f16422\n""}, {'number': 17, 'created': '2014-02-20 21:05:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo-incubator/commit/ef5c7a6d65e5552fc6240b9cde08e3e172cf6642', 'message': ""Drop special case for MySQL traditional mode, update unit tests\n\nSince there are no users of the special-case TRADITIONAL mode set,\nit's OK to drop those references and use only the more flexible\none tuned via a config option.\n\nUpdate the TRADITIONAL mode unit test, and also add one for\nSTRICT_ALL_TABLES mode.\n\nChange-Id: Ie9df3aaa5f48d992b61a9ea480d1e17519f16422\n""}, {'number': 18, 'created': '2014-02-24 15:06:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo-incubator/commit/a44ce3076922f22a977aae0f34a8526acd6c44a6', 'message': ""Drop special case for MySQL traditional mode, update unit tests\n\nSince there are no users of the special-case TRADITIONAL mode set,\nit's OK to drop those references and use only the more flexible\none tuned via a config option.\n\nUpdate the TRADITIONAL mode unit test, and also add one for\nSTRICT_ALL_TABLES mode.\n\nChange-Id: Ie9df3aaa5f48d992b61a9ea480d1e17519f16422\n""}, {'number': 19, 'created': '2014-02-24 15:40:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo-incubator/commit/f08db30762b3d3f4c6eb2c4d5d7c544d6c5434fd', 'message': ""Drop special case for MySQL traditional mode, update unit tests\n\nSince there are no users of the special-case TRADITIONAL mode set,\nit's OK to drop those references and use only the more flexible\none tuned via a config option.\n\nUpdate the TRADITIONAL mode unit test, and also add one for\nSTRICT_ALL_TABLES mode.\n\nChange-Id: Ie9df3aaa5f48d992b61a9ea480d1e17519f16422\n""}, {'number': 20, 'created': '2014-02-26 13:35:33.000000000', 'files': ['tests/unit/db/sqlalchemy/test_sqlalchemy.py', 'openstack/common/db/sqlalchemy/session.py'], 'web_link': 'https://opendev.org/openstack/oslo-incubator/commit/fea119ec2d45e912ef1215345de9d6a61e50ba22', 'message': ""Drop special case for MySQL traditional mode, update unit tests\n\nSince there are no users of the special-case TRADITIONAL mode set,\nit's OK to drop those references and use only the more flexible\none tuned via a config option.\n\nUpdate the TRADITIONAL mode unit test, and also add one for\nSTRICT_ALL_TABLES mode.\n\nChange-Id: Ie9df3aaa5f48d992b61a9ea480d1e17519f16422\n""}]",5,69032,fea119ec2d45e912ef1215345de9d6a61e50ba22,90,11,20,2463,,,0,"Drop special case for MySQL traditional mode, update unit tests

Since there are no users of the special-case TRADITIONAL mode set,
it's OK to drop those references and use only the more flexible
one tuned via a config option.

Update the TRADITIONAL mode unit test, and also add one for
STRICT_ALL_TABLES mode.

Change-Id: Ie9df3aaa5f48d992b61a9ea480d1e17519f16422
",git fetch https://review.opendev.org/openstack/oslo-incubator refs/changes/32/69032/19 && git format-patch -1 --stdout FETCH_HEAD,"['tests/unit/db/sqlalchemy/test_sqlalchemy.py', 'openstack/common/db/sqlalchemy/session.py']",2,0a1e6ba7aa55cc279f191ac087f106ec23f7a0f6,bug-1271706," slave_session=False): engine = get_engine(sqlite_fk=sqlite_fk, slave_engine=slave_session)def get_engine(sqlite_fk=False, slave_engine=False): engine = create_engine(db_uri, sqlite_fk=sqlite_fk)def create_engine(sql_connection, sqlite_fk=False):"," slave_session=False, mysql_traditional_mode=False): engine = get_engine(sqlite_fk=sqlite_fk, slave_engine=slave_session, mysql_traditional_mode=mysql_traditional_mode)def get_engine(sqlite_fk=False, slave_engine=False, mysql_traditional_mode=False): engine = create_engine(db_uri, sqlite_fk=sqlite_fk, mysql_traditional_mode=mysql_traditional_mode)def _set_mode_traditional(dbapi_con, connection_rec, connection_proxy): """"""Set engine mode to 'traditional'. Required to prevent silent truncates at insert or update operations under MySQL. By default MySQL truncates inserted string if it longer than a declared field just with warning. That is fraught with data corruption. """""" _set_session_sql_mode(dbapi_con, connection_rec, connection_proxy, 'TRADITIONAL') def create_engine(sql_connection, sqlite_fk=False, mysql_traditional_mode=False): if mysql_traditional_mode: mysql_sql_mode = 'TRADITIONAL'",27,26
openstack%2Fnova~master~Iac4e2cf6e9d80a34ebaeee7f966971c8ea040f31,openstack/nova,master,Iac4e2cf6e9d80a34ebaeee7f966971c8ea040f31,WIP XenAPI support for VirtProperties,ABANDONED,2014-02-28 01:54:57.000000000,2014-03-06 16:02:42.000000000,,"[{'_account_id': 3}, {'_account_id': 4393}, {'_account_id': 5170}, {'_account_id': 7750}, {'_account_id': 9578}]","[{'number': 1, 'created': '2014-02-28 01:54:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/92e18e730d1699a96dcb23c0f97b37ed92a99691', 'message': 'WIP XenAPI support for VirtProperties\n\nChange-Id: Iac4e2cf6e9d80a34ebaeee7f966971c8ea040f31\n'}, {'number': 2, 'created': '2014-02-28 15:17:28.000000000', 'files': ['nova/virt/xenapi/image/glance.py', 'nova/virt/xenapi/agent.py', 'nova/virt/xenapi/vm_utils.py', 'nova/virt/xenapi/vmops.py', 'nova/tests/virt/xenapi/image/test_glance.py', 'nova/tests/virt/xenapi/test_vmops.py', 'nova/tests/virt/xenapi/test_agent.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/d3e4e361dacb4424f1ebaae66f43fa11275d40bf', 'message': 'WIP XenAPI support for VirtProperties\n\nChange-Id: Iac4e2cf6e9d80a34ebaeee7f966971c8ea040f31\n'}]",0,77032,d3e4e361dacb4424f1ebaae66f43fa11275d40bf,13,5,2,4393,,,0,"WIP XenAPI support for VirtProperties

Change-Id: Iac4e2cf6e9d80a34ebaeee7f966971c8ea040f31
",git fetch https://review.opendev.org/openstack/nova refs/changes/32/77032/2 && git format-patch -1 --stdout FETCH_HEAD,"['nova/virt/xenapi/image/glance.py', 'nova/virt/xenapi/agent.py', 'nova/virt/xenapi/vm_utils.py', 'nova/virt/xenapi/vmops.py', 'nova/tests/virt/xenapi/image/test_glance.py', 'nova/tests/virt/xenapi/test_vmops.py', 'nova/tests/virt/xenapi/test_agent.py']",7,92e18e730d1699a96dcb23c0f97b37ed92a99691,bp/convert-image-meta-into-nova-object,,"class SysMetaKeyTestBase(): key = None def _create_agent_with_value(self, value): kwargs = {self.key: value} instance = _get_fake_instance(**kwargs) return self._create_agent(instance) def test_get_sys_meta_key_true(self): agent = self._create_agent_with_value(""true"") self.assertTrue(agent._get_sys_meta_key(self.key)) def test_get_sys_meta_key_false(self): agent = self._create_agent_with_value(""False"") self.assertFalse(agent._get_sys_meta_key(self.key)) def test_get_sys_meta_key_invalid_is_false(self): agent = self._create_agent_with_value(""invalid"") self.assertFalse(agent._get_sys_meta_key(self.key)) def test_get_sys_meta_key_missing_is_false(self): instance = _get_fake_instance() agent = self._create_agent(instance) self.assertFalse(agent._get_sys_meta_key(self.key)) ",45,79
openstack%2Ftempest~master~I4a8b4e9d7cecf2c760b4c26d61a97cfafac25461,openstack/tempest,master,I4a8b4e9d7cecf2c760b4c26d61a97cfafac25461,Test to update neutron security group,MERGED,2014-01-28 09:28:39.000000000,2014-03-06 15:58:56.000000000,2014-03-06 15:58:56.000000000,"[{'_account_id': 3}, {'_account_id': 1192}, {'_account_id': 1687}, {'_account_id': 1795}, {'_account_id': 2238}, {'_account_id': 4694}, {'_account_id': 5689}, {'_account_id': 5803}, {'_account_id': 6455}, {'_account_id': 7249}, {'_account_id': 7293}, {'_account_id': 8085}, {'_account_id': 8205}, {'_account_id': 9008}]","[{'number': 1, 'created': '2014-01-28 09:28:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/fdf3090468ff94ee706ea26a94ce13b911083190', 'message': 'Test to update neutron security group\n\nAdding update_security_group functionality to existingmethod\n""test_create_show_delete_security_group"" in test_security_groups.py.\nVerifying if name and description of security group are updated.\nAlso using updater method from network_client_base.py for\n\'update_security_group\' function  call.\n\nChange-Id: I4a8b4e9d7cecf2c760b4c26d61a97cfafac25461\n'}, {'number': 2, 'created': '2014-01-28 11:48:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/ef593ed5047e60e1f31f563ab5e5a536a80a3843', 'message': 'Test to update neutron security group\n\nAdding update_security_group functionality to existing method\n""test_create_show_delete_security_group"" in test_security_groups.py.\nVerifying if name and description of security group are updated.\nAlso using updater method from network_client_base.py for\n\'update_security_group\' function  call.\n\nChange-Id: I4a8b4e9d7cecf2c760b4c26d61a97cfafac25461\n'}, {'number': 3, 'created': '2014-01-28 13:15:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/8eeae179a182ce15d519097995161b06b8c303de', 'message': 'Test to update neutron security group\n\nAdding update_security_group functionality to existing method\n""test_create_show_delete_security_group"" in test_security_groups.py.\nVerifying if name and description of security group are updated.\nAlso using updater method from network_client_base.py for\n\'update_security_group\' function  call.\n\nChange-Id: I4a8b4e9d7cecf2c760b4c26d61a97cfafac25461\n'}, {'number': 4, 'created': '2014-01-29 05:33:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/5e523213ddfd052acf3a08570964728924a214f7', 'message': 'Test to update neutron security group\n\nAdding update_security_group functionality to existing method\n""test_create_show_delete_security_group"" in test_security_groups.py.\nVerifying if name and description of security group are updated.\nAlso using updater method from network_client_base.py for\n\'update_security_group\' function  call.\n\nChange-Id: I4a8b4e9d7cecf2c760b4c26d61a97cfafac25461\n'}, {'number': 5, 'created': '2014-01-30 05:05:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/6c9fcabb9c97303ce0191664710146d408be3447', 'message': 'Test to update neutron security group\n\nAdding update_security_group functionality to existing method\n""test_create_show_delete_security_group"" in test_security_groups.py.\nVerifying if name and description of security group are updated.\nAlso using updater method from network_client_base.py for\n\'update_security_group\' function  call.\n\nChange-Id: I4a8b4e9d7cecf2c760b4c26d61a97cfafac25461\n'}, {'number': 6, 'created': '2014-02-18 08:32:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/f4c8f897a59c3437563bb73b527d96f90e46726e', 'message': 'Test to update neutron security group\n\nAdding update_security_group functionality to existing method\n""test_create_show_delete_security_group"" in test_security_groups.py.\nVerifying if name and description of security group are updated.\nAlso using updater method from network_client_base.py for\n\'update_security_group\' function  call.\n\nChange-Id: I4a8b4e9d7cecf2c760b4c26d61a97cfafac25461\n'}, {'number': 7, 'created': '2014-02-26 14:04:49.000000000', 'files': ['tempest/api/network/test_security_groups.py'], 'web_link': 'https://opendev.org/openstack/tempest/commit/1c76bc9c1f3ed8ee2959f6cfae93dc35d55c19a5', 'message': 'Test to update neutron security group\n\nAdding update_security_group functionality to existing method\n""test_create_show_delete_security_group"" in test_security_groups.py.\nVerifying if name and description of security group are updated.\nAlso using updater method from network_client_base.py for\n\'update_security_group\' function  call.\n\nChange-Id: I4a8b4e9d7cecf2c760b4c26d61a97cfafac25461\n'}]",10,69561,1c76bc9c1f3ed8ee2959f6cfae93dc35d55c19a5,69,14,7,1687,,,0,"Test to update neutron security group

Adding update_security_group functionality to existing method
""test_create_show_delete_security_group"" in test_security_groups.py.
Verifying if name and description of security group are updated.
Also using updater method from network_client_base.py for
'update_security_group' function  call.

Change-Id: I4a8b4e9d7cecf2c760b4c26d61a97cfafac25461
",git fetch https://review.opendev.org/openstack/tempest refs/changes/61/69561/1 && git format-patch -1 --stdout FETCH_HEAD,['tempest/api/network/test_security_groups.py'],1,fdf3090468ff94ee706ea26a94ce13b911083190,separate/update_neutron_security_group,"from tempest.common.utils import data_utils def test_create_show_update_delete_security_group(self): # Update the security group new_name = data_utils.rand_name('security-') new_description = data_utils.rand_name('security-description') resp, update_body = self.client.update_security_group( group_create_body['security_group']['id'], name=new_name, description=new_description) self.assertEqual('200', resp['status']) self.assertEqual(update_body['security_group']['name'], new_name) self.assertEqual(update_body['security_group']['description'], new_description) # Show and verify details of the updated security group resp, show_body = self.client.show_security_group( group_create_body['security_group']['id']) self.assertEqual(show_body['security_group']['name'], new_name) self.assertEqual(show_body['security_group']['description'], new_description) protocol=protocol)", def test_create_show_delete_security_group(self): protocol=protocol ),20,3
openstack-attic%2Fvolume-api~master~I5e79f4a09e93e458acfe7000f2e5703548f965e6,openstack-attic/volume-api,master,I5e79f4a09e93e458acfe7000f2e5703548f965e6,Remove trailing comma from sample JSON,MERGED,2014-02-27 06:58:13.000000000,2014-03-06 15:51:27.000000000,2014-03-06 15:51:26.000000000,"[{'_account_id': 3}, {'_account_id': 964}, {'_account_id': 6547}, {'_account_id': 7543}, {'_account_id': 9162}]","[{'number': 1, 'created': '2014-02-27 06:58:13.000000000', 'files': ['v1/src/samples/volume_type_show_response.json', 'v1/src/samples/volume_update_request.json', 'v1/src/samples/snapshot_update_request.json'], 'web_link': 'https://opendev.org/openstack-attic/volume-api/commit/354222a980383c9c65a85794622ac91b1c1f04f7', 'message': 'Remove trailing comma from sample JSON\n\nThe json sample configuration file contains a trailing comma on\nsome elements. This is a syntax error, this change corrects the\nproblem.\n\nChange-Id: I5e79f4a09e93e458acfe7000f2e5703548f965e6\nCloses-bug: #1283718\n'}]",0,76778,354222a980383c9c65a85794622ac91b1c1f04f7,10,5,1,7543,,,0,"Remove trailing comma from sample JSON

The json sample configuration file contains a trailing comma on
some elements. This is a syntax error, this change corrects the
problem.

Change-Id: I5e79f4a09e93e458acfe7000f2e5703548f965e6
Closes-bug: #1283718
",git fetch https://review.opendev.org/openstack-attic/volume-api refs/changes/78/76778/1 && git format-patch -1 --stdout FETCH_HEAD,"['v1/src/samples/volume_type_show_response.json', 'v1/src/samples/volume_update_request.json', 'v1/src/samples/snapshot_update_request.json']",3,354222a980383c9c65a85794622ac91b1c1f04f7,json-check," ""display_description"": ""This is yet, another snapshot."" } } "," ""display_description"": ""This is yet, another snapshot."", } }",6,6
openstack%2Fpython-zaqarclient~master~I48781f016f47f9b626410638271ce55fac3d39db,openstack/python-zaqarclient,master,I48781f016f47f9b626410638271ce55fac3d39db,Added API version to URL,MERGED,2014-03-06 15:00:20.000000000,2014-03-06 15:47:33.000000000,2014-03-06 15:47:33.000000000,"[{'_account_id': 3}, {'_account_id': 6159}, {'_account_id': 6944}, {'_account_id': 10476}]","[{'number': 1, 'created': '2014-03-06 15:00:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-zaqarclient/commit/d53e7081335ed7461465d547526e20547af1bbd3', 'message': 'Added API version to URL\n\nChange-Id: I48781f016f47f9b626410638271ce55fac3d39db\n'}, {'number': 2, 'created': '2014-03-06 15:04:54.000000000', 'files': ['examples/simple.py', 'examples/management.py', 'tests/unit/transport/test_http.py', 'examples/claims.py', 'marconiclient/transport/http.py'], 'web_link': 'https://opendev.org/openstack/python-zaqarclient/commit/7ed5591012f104403559a7b0796a1adaeb5f5060', 'message': 'Added API version to URL\n\nCloses-Bug: 1287933\nChange-Id: I48781f016f47f9b626410638271ce55fac3d39db\n'}]",0,78621,7ed5591012f104403559a7b0796a1adaeb5f5060,12,4,2,10476,,,0,"Added API version to URL

Closes-Bug: 1287933
Change-Id: I48781f016f47f9b626410638271ce55fac3d39db
",git fetch https://review.opendev.org/openstack/python-zaqarclient refs/changes/21/78621/2 && git format-patch -1 --stdout FETCH_HEAD,"['examples/simple.py', 'examples/management.py', 'tests/unit/transport/test_http.py', 'examples/claims.py', 'marconiclient/transport/http.py']",5,d53e7081335ed7461465d547526e20547af1bbd3,bug/1287933," url = '{0}/{1}/{2}'.format(request.endpoint.rstrip('/'), request.api.label, ref.format(**ref_params))"," url = '{0}/{1}'.format(request.endpoint.rstrip('/'), ref.format(**ref_params))",7,6
openstack%2Fopenstack-manuals~master~Iff1e73e0f3db80c11a56a08abd67dd6c050c1aa1,openstack/openstack-manuals,master,Iff1e73e0f3db80c11a56a08abd67dd6c050c1aa1,"correctly handle doc urls containing ""//""",MERGED,2014-03-06 04:41:40.000000000,2014-03-06 15:41:56.000000000,2014-03-06 15:41:55.000000000,"[{'_account_id': 3}, {'_account_id': 964}, {'_account_id': 6772}]","[{'number': 1, 'created': '2014-03-06 04:41:40.000000000', 'files': ['www/.htaccess'], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/27802f81f4b0ebb7eeee385e5c8071b10ddd4683', 'message': 'correctly handle doc urls containing ""//""\n\nA doc generation bug resulted in Google indexing links containing ""//"", which cause\nproblems with linked content (images/css/etc).  This rule generates a 301 redirect\nfor these links.\n\nChange-Id: Iff1e73e0f3db80c11a56a08abd67dd6c050c1aa1\nPartial-bug: 1288513\n'}]",0,78518,27802f81f4b0ebb7eeee385e5c8071b10ddd4683,7,3,1,8745,,,0,"correctly handle doc urls containing ""//""

A doc generation bug resulted in Google indexing links containing ""//"", which cause
problems with linked content (images/css/etc).  This rule generates a 301 redirect
for these links.

Change-Id: Iff1e73e0f3db80c11a56a08abd67dd6c050c1aa1
Partial-bug: 1288513
",git fetch https://review.opendev.org/openstack/openstack-manuals refs/changes/18/78518/1 && git format-patch -1 --stdout FETCH_HEAD,['www/.htaccess'],1,27802f81f4b0ebb7eeee385e5c8071b10ddd4683,bug/1288513,"# A doc generation bug resulted in Google indexing links containing ""//"", which cause # problems with linked content (images/css/etc). This rule generates a 301 redirect # for these links. # # details: https://bugs.launchpad.net/openstack-manuals/+bug/1288513 redirectmatch 301 (.*)//(.*) $1/$2 ",,7,0
openstack%2Ffuel-docs~master~If0936ccb3af247b89493d6bf3d6f149613cede95,openstack/fuel-docs,master,If0936ccb3af247b89493d6bf3d6f149613cede95,Reference schemes refactoring,ABANDONED,2014-03-03 15:40:59.000000000,2014-03-06 15:40:22.000000000,,"[{'_account_id': 3}, {'_account_id': 8797}, {'_account_id': 8829}, {'_account_id': 8971}]","[{'number': 1, 'created': '2014-03-03 15:40:59.000000000', 'files': ['_images/deployment-ha-compact-red-hat.svg', 'pages/reference-architecture/0018-red-hat-differences.rst', 'pages/reference-architecture/0014-compact.rst', '_images/deployment-simple-red-hat.svg', '_images/logical-diagram-compute.svg', '_images/deployment-simple.svg', '_images/logical-diagram-controller.svg', '_images/deployment-ha-full.svg', '_images/deployment-ha-compact.svg', '_images/ha-overview.svg', 'pages/reference-architecture/0030-cluster-sizing.rst'], 'web_link': 'https://opendev.org/openstack/fuel-docs/commit/e0c9d28d9b3450be29271a70edacf17d07c7ec0c', 'message': 'Reference schemes refactoring\n\nChange-Id: If0936ccb3af247b89493d6bf3d6f149613cede95\nCloses-Bug: 1259424\n'}]",0,77619,e0c9d28d9b3450be29271a70edacf17d07c7ec0c,8,4,1,9037,,,0,"Reference schemes refactoring

Change-Id: If0936ccb3af247b89493d6bf3d6f149613cede95
Closes-Bug: 1259424
",git fetch https://review.opendev.org/openstack/fuel-docs refs/changes/19/77619/1 && git format-patch -1 --stdout FETCH_HEAD,"['_images/deployment-ha-compact-red-hat.svg', 'pages/reference-architecture/0018-red-hat-differences.rst', 'pages/reference-architecture/0014-compact.rst', '_images/deployment-simple-red-hat.svg', '_images/deployment-simple.svg', '_images/logical-diagram-compute.svg', '_images/logical-diagram-controller.svg', '_images/deployment-ha-compact.svg', '_images/deployment-ha-full.svg', '_images/ha-overview.svg', 'pages/reference-architecture/0030-cluster-sizing.rst']",11,e0c9d28d9b3450be29271a70edacf17d07c7ec0c,bug/1259424,"If you want to run storage separately from the controllers, you can do that as well by raising the bar to 9 nodes:- 3 Ceph OSD nodes - 1 Cinder node.. note:: Placing Ceph OSD on Controllers is highly unadvisable. It can severely degrade controller prefarmance. Use separate storage nodes if you have enough hardware.",".. image:: /_images/deployment-ha-compact.* :width: 80% :align: center If you want to run storage separately from the controllers, you can do that as well by raising the bar to 9 nodes:- 3 Storage nodes - 2 Swift Proxy nodes.. image:: /_images/deployment-ha-full.* :width: 80% :align: center",1519,1018
openstack%2Fmagnetodb~master~I883c24b7f56b11d586eb7d307444396a2d5aae05,openstack/magnetodb,master,I883c24b7f56b11d586eb7d307444396a2d5aae05,Timeouts for cassandra storage backend tests increased,MERGED,2014-03-06 12:25:49.000000000,2014-03-06 15:35:54.000000000,2014-03-06 15:35:54.000000000,"[{'_account_id': 3}, {'_account_id': 8408}, {'_account_id': 8415}, {'_account_id': 8601}]","[{'number': 1, 'created': '2014-03-06 12:25:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/magnetodb/commit/36a6ae8167ce3013792d57ccc7060cc67a0ca3f8', 'message': 'Timeouts for cassandra storage backend tests increased\n\n Some changes merged from new python driver release\n\nChange-Id: I883c24b7f56b11d586eb7d307444396a2d5aae05\n'}, {'number': 2, 'created': '2014-03-06 12:59:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/magnetodb/commit/72b7b340dd92d11efc4aa259273230e6a02df890', 'message': 'Timeouts for cassandra storage backend tests increased\n\nSome changes merged from new python driver release\n\nFixes bug: cassandra-storage-backend-tests-floating-failure\n\nChange-Id: I883c24b7f56b11d586eb7d307444396a2d5aae05\n'}, {'number': 3, 'created': '2014-03-06 13:16:56.000000000', 'files': ['magnetodb/tests/storage/test_cassandra_impl.py', 'magnetodb/storage/impl/cassandra_impl.py', 'magnetodb/common/cassandra/cluster.py'], 'web_link': 'https://opendev.org/openstack/magnetodb/commit/a4c6381d4b2cf6cb5d88decd4c00f5066272f001', 'message': 'Timeouts for cassandra storage backend tests increased\n\nSome changes merged from new python driver release\n\nCloses-Bug: #1288725\n\nChange-Id: I883c24b7f56b11d586eb7d307444396a2d5aae05\n'}]",9,78592,a4c6381d4b2cf6cb5d88decd4c00f5066272f001,16,4,3,8601,,,0,"Timeouts for cassandra storage backend tests increased

Some changes merged from new python driver release

Closes-Bug: #1288725

Change-Id: I883c24b7f56b11d586eb7d307444396a2d5aae05
",git fetch https://review.opendev.org/openstack/magnetodb refs/changes/92/78592/2 && git format-patch -1 --stdout FETCH_HEAD,"['magnetodb/tests/storage/test_cassandra_impl.py', 'magnetodb/storage/impl/cassandra_impl.py', 'magnetodb/common/cassandra/cluster.py']",3,36a6ae8167ce3013792d57ccc7060cc67a0ca3f8,bug/cassandra-storage-backend-tests-floating-failure," Gets the minimum number of connections per Session that will be opened for each host with :class:`~.HostDistance` equal to `host_distance`. The default is 2 for :attr:`~HostDistance.LOCAL` and 1 for Sets the minimum number of connections per Session that will be opened for each host with :class:`~.HostDistance` equal to `host_distance`. The default is 2 for :attr:`~HostDistance.LOCAL` and 1 for Gets the maximum number of connections per Session that will be opened for each host with :class:`~.HostDistance` equal to `host_distance`. The default is 8 for :attr:`~HostDistance.LOCAL` and 2 for Gets the maximum number of connections per Session that will be opened for each host with :class:`~.HostDistance` equal to `host_distance`. The default is 2 for :attr:`~HostDistance.LOCAL` and 1 for except OperationTimedOut as timeout: log.warn(""Timed out trying to prepare all statements on host %s: %s"", host, timeout) future = self._create_response_future(query, parameters, trace) future.send_request() return future def _create_response_future(self, query, parameters, trace): """""" Returns the ResponseFuture before calling send_request() on it """""" return ResponseFuture( except OperationTimedOut as timeout: log.debug(""[control connection] Timed out waiting for "" \ ""response during schema agreement check: %s"", timeout) raise OperationTimedOut(errors=self._errors, last_host=self._current_host)"," Gets the minimum number of connections that will be opened for each host with :class:`~.HostDistance` equal to `host_distance`. The default is 2 for :attr:`~HostDistance.LOCAL` and 1 for Sets the minimum number of connections that will be opened for each host with :class:`~.HostDistance` equal to `host_distance`. The default is 2 for :attr:`~HostDistance.LOCAL` and 1 for Gets the maximum number of connections that will be opened for each host with :class:`~.HostDistance` equal to `host_distance`. The default is 8 for :attr:`~HostDistance.LOCAL` and 2 for Gets the maximum number of connections that will be opened for each host with :class:`~.HostDistance` equal to `host_distance`. The default is 2 for :attr:`~HostDistance.LOCAL` and 1 for except OperationTimedOut: log.warn(""Timed out trying to prepare all statements on host %s"", host) future = ResponseFuture( future.send_request() return future except OperationTimedOut: log.debug(""[control connection] Timed out waiting for response during schema agreement check"") raise OperationTimedOut()",31,26
openstack%2Fheat~master~Ifc288938f6000c911563a0600aad099e4e7ea491,openstack/heat,master,Ifc288938f6000c911563a0600aad099e4e7ea491,Don't include a default HOT version for unit tests,ABANDONED,2014-03-04 16:01:26.000000000,2014-03-06 15:31:50.000000000,,"[{'_account_id': 3}, {'_account_id': 4257}, {'_account_id': 4328}, {'_account_id': 7193}, {'_account_id': 7253}, {'_account_id': 7385}]","[{'number': 1, 'created': '2014-03-04 16:01:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/6239be65a3d901a0f246671472dba993f713509d', 'message': ""Don't include a default HOT version for unit tests\n\nSince a HOT version string is required, it is better to make sure all of\nthe unit tests are using a complete template.\n\nChange-Id: Ifc288938f6000c911563a0600aad099e4e7ea491\n""}, {'number': 2, 'created': '2014-03-05 20:42:42.000000000', 'files': ['heat/engine/hot/__init__.py'], 'web_link': 'https://opendev.org/openstack/heat/commit/3f48fbf51ea1b2463c5014af9ccef959d26fde50', 'message': ""Don't include a default HOT version for unit tests\n\nSince a HOT version string is required, it is better to make sure all of\nthe unit tests are using a complete template.\n\nChange-Id: Ifc288938f6000c911563a0600aad099e4e7ea491\n""}]",0,77922,3f48fbf51ea1b2463c5014af9ccef959d26fde50,17,6,2,7253,,,0,"Don't include a default HOT version for unit tests

Since a HOT version string is required, it is better to make sure all of
the unit tests are using a complete template.

Change-Id: Ifc288938f6000c911563a0600aad099e4e7ea491
",git fetch https://review.opendev.org/openstack/heat refs/changes/22/77922/1 && git format-patch -1 --stdout FETCH_HEAD,['heat/engine/hot/__init__.py'],1,6239be65a3d901a0f246671472dba993f713509d,typeless-function-plugins, version = template.get(self.VERSION)," # All user templates are forced to include a version string. This is # just a convenient default for unit tests. version = template.get(self.VERSION, '2013-05-23')",1,3
openstack%2Ftempest~master~I648011acd142171d88c33644cb26078146120ce4,openstack/tempest,master,I648011acd142171d88c33644cb26078146120ce4,Add parametric tests of Swift account API,MERGED,2014-01-16 08:52:59.000000000,2014-03-06 15:29:28.000000000,2014-03-06 15:29:27.000000000,"[{'_account_id': 3}, {'_account_id': 2750}, {'_account_id': 5689}, {'_account_id': 5803}, {'_account_id': 6847}, {'_account_id': 6968}, {'_account_id': 8859}]","[{'number': 1, 'created': '2014-01-16 08:52:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/bb105b99876bbcd894e7f1b907800cbe4c9c6089', 'message': 'Add parametric tests of Swift account API\n\nAdd and reorganize positive tests of Swift account API from the viewpoint of\ncompleteness of HTTP methods and query parameters.\n\nChange-Id: I648011acd142171d88c33644cb26078146120ce4\n'}, {'number': 2, 'created': '2014-01-30 02:56:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/306c116427b0215a6aab8d1e56cf5d350b768124', 'message': 'Add parametric tests of Swift account API\n\nAdd and reorganize positive tests of Swift account API from the viewpoint of\ncompleteness of HTTP methods and query parameters.\n\nChange-Id: I648011acd142171d88c33644cb26078146120ce4\n'}, {'number': 3, 'created': '2014-02-10 11:02:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/4007c4bb80b883e73fa08bc367ded002d84d07b6', 'message': 'Add parametric tests of Swift account API\n\nAdd and reorganize positive tests of Swift account API from the viewpoint of\ncompleteness of HTTP methods and query parameters.\n\nChange-Id: I648011acd142171d88c33644cb26078146120ce4\n'}, {'number': 4, 'created': '2014-02-21 09:21:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/32daeba2d3f90adac94607263e540db31648f868', 'message': 'Add parametric tests of Swift account API\n\nAdd and reorganize positive tests of Swift account API from the viewpoint of\ncompleteness of HTTP methods and query parameters.\n\nChange-Id: I648011acd142171d88c33644cb26078146120ce4\n'}, {'number': 5, 'created': '2014-03-03 11:44:51.000000000', 'files': ['tempest/services/object_storage/account_client.py', 'tempest/api/object_storage/test_object_temp_url.py', 'tempest/api/object_storage/test_account_services.py'], 'web_link': 'https://opendev.org/openstack/tempest/commit/8344128890e148522592df0e6f397049a2872fb3', 'message': 'Add parametric tests of Swift account API\n\nAdd and reorganize positive tests of Swift account API from the viewpoint of\ncompleteness of HTTP methods and query parameters.\n\nChange-Id: I648011acd142171d88c33644cb26078146120ce4\n'}]",2,67071,8344128890e148522592df0e6f397049a2872fb3,37,7,5,8859,,,0,"Add parametric tests of Swift account API

Add and reorganize positive tests of Swift account API from the viewpoint of
completeness of HTTP methods and query parameters.

Change-Id: I648011acd142171d88c33644cb26078146120ce4
",git fetch https://review.opendev.org/openstack/tempest refs/changes/71/67071/4 && git format-patch -1 --stdout FETCH_HEAD,"['tempest/services/object_storage/account_client.py', 'tempest/api/object_storage/test_object_temp_url.py', 'tempest/api/object_storage/test_account_services.py']",3,bb105b99876bbcd894e7f1b907800cbe4c9c6089,swift-parametric-account,"from tempest import clients from tempest.common import custom_matchers cls.data.teardown_all() resp, container_list = self.account_client.list_account_containers() for container_name in self.containers: self.assertIn(container_name, container_list) @attr(type='smoke') def test_list_no_containers(self): # List request to empty account # To test listing no containers, create new user other than # the base user of this instance. self.data.setup_test_user() os_test_user = clients.Manager( self.data.test_user, self.data.test_password, self.data.test_tenant) # Retrieve the id of an operator role of object storage test_role_id = None swift_role = self.config.object_storage.operator_role try: _, roles = self.os_admin.identity_client.list_roles() test_role_id = next(r['id'] for r in roles if r['name'] == swift_role) except StopIteration: msg = ""%s role found"" % swift_role raise exceptions.NotFound(msg) # Retrieve the test_user id _, users = self.os_admin.identity_client.get_users() test_user_id = next(usr['id'] for usr in users if usr['name'] == self.data.test_user) # Retrieve the test_tenant id _, tenants = self.os_admin.identity_client.list_tenants() test_tenant_id = next(tnt['id'] for tnt in tenants if tnt['name'] == self.data.test_tenant) # Assign the newly created user the appropriate operator role self.os_admin.identity_client.assign_user_role( test_tenant_id, test_user_id, test_role_id) resp, container_list = \ os_test_user.account_client.list_account_containers() self.assertIn(int(resp['status']), HTTP_SUCCESS) # When sending a request to an account which has not received a PUT # container request, the response does not contain 'accept-ranges' # header. This is a special case, therefore the existence of response # headers is checked without custom matcher. self.assertIn('content-length', resp) self.assertIn('x-timestamp', resp) self.assertIn('x-account-bytes-used', resp) self.assertIn('x-account-container-count', resp) self.assertIn('x-account-object-count', resp) self.assertIn('content-type', resp) self.assertIn('x-trans-id', resp) self.assertIn('date', resp) # Check only the format of common headers with custom matcher self.assertThat(resp, custom_matchers.AreAllWellFormatted()) self.assertEqual(len(container_list), 0) @attr(type='smoke') def test_list_containers_with_format_json(self): # list containers setting format parameter to 'json' params = {'format': 'json'} resp, container_list = self.account_client.list_account_containers( params=params) self.assertIn(int(resp['status']), HTTP_SUCCESS) self.assertHeaders(resp, 'Account', 'GET') self.assertIsNotNone(container_list) self.assertTrue([c['name'] for c in container_list]) self.assertTrue([c['count'] for c in container_list]) self.assertTrue([c['bytes'] for c in container_list]) @attr(type='smoke') def test_list_containers_with_format_xml(self): # list containers setting format parameter to 'xml' params = {'format': 'xml'} resp, container_list = self.account_client.list_account_containers( params=params) self.assertIn(int(resp['status']), HTTP_SUCCESS) self.assertHeaders(resp, 'Account', 'GET') self.assertIsNotNone(container_list) self.assertEqual(container_list.tag, 'account') self.assertTrue('name' in container_list.keys()) self.assertEqual(container_list.find("".//container"").tag, 'container') self.assertEqual(container_list.find("".//name"").tag, 'name') self.assertEqual(container_list.find("".//count"").tag, 'count') self.assertEqual(container_list.find("".//bytes"").tag, 'bytes') def test_list_containers_with_marker_and_end_marker(self): # list containers combining marker and end_marker param params = {'marker': self.containers[0], 'end_marker': self.containers[self.containers_count - 1]} resp, container_list = self.account_client.list_account_containers( params=params) self.assertIn(int(resp['status']), HTTP_SUCCESS) self.assertHeaders(resp, 'Account', 'GET') self.assertEqual(len(container_list), self.containers_count - 2) @attr(type='smoke') def test_list_containers_with_limit_and_end_marker(self): # list containers combining limit and end_marker param limit = random.randint(1, self.containers_count) params = {'limit': limit, 'end_marker': self.containers[self.containers_count / 2]} resp, container_list = self.account_client.list_account_containers( params=params) self.assertHeaders(resp, 'Account', 'GET') self.assertEqual(len(container_list), min(limit, self.containers_count / 2)) def test_list_containers_with_limit_and_marker_and_end_marker(self): # list containers combining limit, marker and end_marker param limit = random.randint(1, self.containers_count) params = {'limit': limit, 'marker': self.containers[0], 'end_marker': self.containers[self.containers_count - 1]} resp, container_list = self.account_client.list_account_containers( params=params) self.assertHeaders(resp, 'Account', 'GET') self.assertEqual(len(container_list), min(limit, self.containers_count - 2)) @attr(type='smoke') def test_list_account_metadata(self): # list all account metadata # set metadata to account metadata = {'test-account-meta1': 'Meta1', 'test-account-meta2': 'Meta2'} resp, _ = self.account_client.create_account_metadata(metadata) self.assertIn('x-account-meta-test-account-meta1', resp) self.assertIn('x-account-meta-test-account-meta2', resp) self.account_client.delete_account_metadata(metadata) @attr(type='smoke') def test_list_no_account_metadata(self): # list no account metadata resp, _ = self.account_client.list_account_metadata() self.assertIn(int(resp['status']), HTTP_SUCCESS) self.assertHeaders(resp, 'Account', 'HEAD') self.assertNotIn('x-account-meta-', str(resp)) resp, body = self.token_client.auth(self.data.test_user, self.data.test_password, self.data.test_tenant) new_token = self.token_client.get_token(self.data.test_user, self.data.test_password, self.data.test_tenant) @attr(type='smoke') def test_update_account_metadata_with_create_metadata(self): # add metadata to account metadata = {'test-account-meta1': 'Meta1'} resp, _ = self.account_client.create_account_metadata(metadata) self.assertIn(int(resp['status']), HTTP_SUCCESS) self.assertHeaders(resp, 'Account', 'POST') resp, body = self.account_client.list_account_metadata() self.assertIn('x-account-meta-test-account-meta1', resp) self.assertEqual(resp['x-account-meta-test-account-meta1'], metadata['test-account-meta1']) self.account_client.delete_account_metadata(metadata) @attr(type='smoke') def test_update_account_metadata_with_delete_matadata(self): # delete metadata from account metadata = {'test-account-meta1': 'Meta1'} self.account_client.create_account_metadata(metadata) resp, _ = self.account_client.delete_account_metadata(metadata) self.assertIn(int(resp['status']), HTTP_SUCCESS) self.assertHeaders(resp, 'Account', 'POST') resp, _ = self.account_client.list_account_metadata() self.assertNotIn('x-account-meta-test-account-meta1', resp) @attr(type='smoke') def test_update_account_metadata_with_create_matadata_key(self): # if the value of metadata is not set, the metadata is not # registered at a server metadata = {'test-account-meta1': ''} resp, _ = self.account_client.create_account_metadata(metadata) self.assertIn(int(resp['status']), HTTP_SUCCESS) self.assertHeaders(resp, 'Account', 'POST') resp, _ = self.account_client.list_account_metadata() self.assertNotIn('x-account-meta-test-account-meta1', resp) @attr(type='smoke') def test_update_account_metadata_with_delete_matadata_key(self): # Although the value of metadata is not set, the feature of # deleting metadata is valid metadata_1 = {'test-account-meta1': 'Meta1'} self.account_client.create_account_metadata(metadata_1) metadata_2 = {'test-account-meta1': ''} resp, _ = self.account_client.delete_account_metadata(metadata_2) self.assertIn(int(resp['status']), HTTP_SUCCESS) self.assertHeaders(resp, 'Account', 'POST') resp, _ = self.account_client.list_account_metadata() self.assertNotIn('x-account-meta-test-account-meta1', resp) @attr(type='smoke') def test_update_account_metadata_with_create_and_delete_metadata(self): # Send a request adding and deleting metadata requests simultaneously metadata_1 = {'test-account-meta1': 'Meta1'} self.account_client.create_account_metadata(metadata_1) metadata_2 = {'test-account-meta2': 'Meta2'} resp, body = self.account_client.create_and_delete_account_metadata( metadata_2, metadata_1) self.assertIn(int(resp['status']), HTTP_SUCCESS) self.assertHeaders(resp, 'Account', 'POST') resp, _ = self.account_client.list_account_metadata() self.assertNotIn('x-account-meta-test-account-meta1', resp) self.assertIn('x-account-meta-test-account-meta2', resp) self.assertEqual(resp['x-account-meta-test-account-meta2'], metadata_2['test-account-meta2']) self.account_client.delete_account_metadata(metadata_2)"," params = {'format': 'json'} resp, container_list = \ self.account_client.list_account_containers(params=params) container_names = [c['name'] for c in container_list] for container_name in self.containers: self.assertIn(container_name, container_names) def test_list_account_metadata(self): # list all account metadata resp, metadata = self.account_client.list_account_metadata() self.assertHeaders(resp, 'Account', 'HEAD') def test_create_and_delete_account_metadata(self): header = 'test-account-meta' data = 'Meta!' # add metadata to account resp, _ = self.account_client.create_account_metadata( metadata={header: data}) self.assertHeaders(resp, 'Account', 'POST') self.assertHeaders(resp, 'Account', 'HEAD') self.assertIn('x-account-meta-' + header, resp) self.assertEqual(resp['x-account-meta-' + header], data) # delete metadata from account resp, _ = \ self.account_client.delete_account_metadata(metadata=[header]) self.assertHeaders(resp, 'Account', 'POST') resp, _ = self.account_client.list_account_metadata() self.assertNotIn('x-account-meta-' + header, resp) resp, body = \ self.token_client.auth(self.data.test_user, self.data.test_password, self.data.test_tenant) new_token = \ self.token_client.get_token(self.data.test_user, self.data.test_password, self.data.test_tenant) # delete the user which was created self.data.teardown_all()",261,52
openstack%2Fpython-zaqarclient~master~I265e6da73205b747b3f50c6f2bbf23e02ccdb64d,openstack/python-zaqarclient,master,I265e6da73205b747b3f50c6f2bbf23e02ccdb64d,Fixed url in examples,ABANDONED,2014-03-06 00:08:32.000000000,2014-03-06 15:24:55.000000000,,"[{'_account_id': 3}, {'_account_id': 6159}]","[{'number': 1, 'created': '2014-03-06 00:08:32.000000000', 'files': ['examples/simple.py', 'examples/management.py', 'tests/unit/transport/test_http.py', 'examples/claims.py', 'marconiclient/transport/http.py'], 'web_link': 'https://opendev.org/openstack/python-zaqarclient/commit/55524be88694f7fb70148ca2c6df275e0f1245d7', 'message': 'Fixed url in examples\n\nChange-Id: I265e6da73205b747b3f50c6f2bbf23e02ccdb64d\nCloses-Bug: 1287933\n'}]",1,78466,55524be88694f7fb70148ca2c6df275e0f1245d7,6,2,1,10476,,,0,"Fixed url in examples

Change-Id: I265e6da73205b747b3f50c6f2bbf23e02ccdb64d
Closes-Bug: 1287933
",git fetch https://review.opendev.org/openstack/python-zaqarclient refs/changes/66/78466/1 && git format-patch -1 --stdout FETCH_HEAD,"['examples/simple.py', 'examples/management.py', 'tests/unit/transport/test_http.py', 'examples/claims.py', 'marconiclient/transport/http.py']",5,55524be88694f7fb70148ca2c6df275e0f1245d7,bug/1287933," url = '{0}/{1}/{2}'.format(request.endpoint.rstrip('/'), request.api.label, ref.format(**ref_params))"," url = '{0}/{1}'.format(request.endpoint.rstrip('/'), ref.format(**ref_params))",7,6
openstack%2Ftempest~master~Iaa2e9144f337be783b0498d64ab691dac4fc7aef,openstack/tempest,master,Iaa2e9144f337be783b0498d64ab691dac4fc7aef,Nova V3 API test for resetNetwork/injectNetworkInfo,MERGED,2014-03-04 10:45:56.000000000,2014-03-06 15:12:25.000000000,2014-03-06 15:12:24.000000000,"[{'_account_id': 3}, {'_account_id': 5689}, {'_account_id': 5803}, {'_account_id': 6167}, {'_account_id': 7139}, {'_account_id': 8556}]","[{'number': 1, 'created': '2014-03-04 10:45:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/262d69d872f8d3edf92df23922356d247b112f93', 'message': 'Nova V3 API test for resetNetwork/injectNetworkInfo\n\nThis Patch adds the Nova V3 tests for resetting the server network and\ninjecting the network info of server.\n\nChange-Id: Iaa2e9144f337be783b0498d64ab691dac4fc7aef\n'}, {'number': 2, 'created': '2014-03-04 12:06:34.000000000', 'files': ['tempest/api/compute/v3/admin/test_servers.py', 'tempest/services/compute/v3/json/servers_client.py'], 'web_link': 'https://opendev.org/openstack/tempest/commit/0549f7bcf56c9b2d1bdef758b94ae57b8913fd00', 'message': 'Nova V3 API test for resetNetwork/injectNetworkInfo\n\nThis Patch add the Nova V3 tests for resetting the server network and\ninjecting the network info of server.\n\nChange-Id: Iaa2e9144f337be783b0498d64ab691dac4fc7aef\n'}]",0,77848,0549f7bcf56c9b2d1bdef758b94ae57b8913fd00,15,6,2,8556,,,0,"Nova V3 API test for resetNetwork/injectNetworkInfo

This Patch add the Nova V3 tests for resetting the server network and
injecting the network info of server.

Change-Id: Iaa2e9144f337be783b0498d64ab691dac4fc7aef
",git fetch https://review.opendev.org/openstack/tempest refs/changes/48/77848/1 && git format-patch -1 --stdout FETCH_HEAD,"['tempest/api/compute/v3/admin/test_servers.py', 'tempest/services/compute/v3/json/servers_client.py']",2,262d69d872f8d3edf92df23922356d247b112f93,Test_V3_reset_inject_network," def reset_network(self, server_id, **kwargs): """"""Resets the Network of a server"""""" return self.action(server_id, 'reset_network', None, **kwargs) def inject_network_info(self, server_id, **kwargs): """"""Inject the Network Info into server"""""" return self.action(server_id, 'inject_network_info', None, **kwargs)",,18,0
openstack%2Fpython-neutronclient~master~Iefbd7db094267fe3799ebf4713e142e62c63174c,openstack/python-neutronclient,master,Iefbd7db094267fe3799ebf4713e142e62c63174c,Print human friendly string as an error message,MERGED,2013-10-30 11:35:30.000000000,2014-03-06 15:12:22.000000000,2014-03-06 15:12:22.000000000,"[{'_account_id': 3}, {'_account_id': 490}, {'_account_id': 748}, {'_account_id': 841}, {'_account_id': 4395}, {'_account_id': 6316}, {'_account_id': 9560}]","[{'number': 1, 'created': '2013-10-30 11:35:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-neutronclient/commit/bbe28a52bc57356df412c367a956bfe26d236e2f', 'message': ""Print human friendly string as an error message\n\nThis commit also removes a blank line displayed\nwhen error_dict['detail'] is empty.\n\nChange-Id: Iefbd7db094267fe3799ebf4713e142e62c63174c\nCloses-Bug: #1246271\n""}, {'number': 2, 'created': '2014-03-02 17:03:42.000000000', 'files': ['neutronclient/client.py', 'neutronclient/tests/unit/test_cli20.py', 'neutronclient/tests/unit/test_http.py', 'neutronclient/v2_0/client.py'], 'web_link': 'https://opendev.org/openstack/python-neutronclient/commit/abfc6b6ae9647a3ca1a323caa07a9d370233f03c', 'message': ""Print human friendly string as an error message\n\nThis commit also removes a blank line displayed\nwhen error_dict['detail'] is empty.\n\nWhen 403 is returned, Forbidden exception is raised from\nHTTPClient (neutronclient/client.py). There is no reason\nthis exception is raised by it. By this commit v2_0.client\nnow handles 403 response to show human friendly message\nby parsing Neutron 2.0 -specific error format.\n\nChange-Id: Iefbd7db094267fe3799ebf4713e142e62c63174c\nCloses-Bug: #1246271\n""}]",0,54525,abfc6b6ae9647a3ca1a323caa07a9d370233f03c,23,7,2,841,,,0,"Print human friendly string as an error message

This commit also removes a blank line displayed
when error_dict['detail'] is empty.

When 403 is returned, Forbidden exception is raised from
HTTPClient (neutronclient/client.py). There is no reason
this exception is raised by it. By this commit v2_0.client
now handles 403 response to show human friendly message
by parsing Neutron 2.0 -specific error format.

Change-Id: Iefbd7db094267fe3799ebf4713e142e62c63174c
Closes-Bug: #1246271
",git fetch https://review.opendev.org/openstack/python-neutronclient refs/changes/25/54525/1 && git format-patch -1 --stdout FETCH_HEAD,['neutronclient/v2_0/client.py'],1,bbe28a52bc57356df412c367a956bfe26d236e2f,bug/1246271," error_message = error_dict['message'] if error_dict['detail']: error_message += ""\n"" + error_dict['detail'] ex = exceptions.NeutronClientException(status_code=status_code, message=error_message)"," error_message = (error_dict['message'] + ""\n"" + error_dict['detail']) pass",5,3
openstack%2Ftempest~master~I4546cb540d328c77a44933e975d827f1505386d8,openstack/tempest,master,I4546cb540d328c77a44933e975d827f1505386d8,Prepare for enabling H302 rule(services/identity),MERGED,2014-03-04 11:19:07.000000000,2014-03-06 15:09:16.000000000,2014-03-06 15:09:15.000000000,"[{'_account_id': 3}, {'_account_id': 5689}, {'_account_id': 5803}, {'_account_id': 6348}]","[{'number': 1, 'created': '2014-03-04 11:19:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/4e9fc4698af09460f73a6b067b209d087360507d', 'message': 'Prepare for enabling H302 rule(services/identity)\n\nCurrently H302 rule is ignored by tox. However, this rule should\nbe enabled. This patch partially fixes this problem to prepare for\nH302 rule.\n\nChange-Id: I4546cb540d328c77a44933e975d827f1505386d8\n'}, {'number': 2, 'created': '2014-03-05 05:08:18.000000000', 'files': ['tempest/services/identity/v3/json/policy_client.py', 'tempest/services/identity/v3/xml/policy_client.py', 'tempest/services/identity/v3/json/service_client.py', 'tempest/services/identity/v3/xml/service_client.py', 'tempest/services/identity/v3/json/endpoints_client.py', 'tempest/services/identity/v3/json/credentials_client.py', 'tempest/services/identity/v3/json/identity_client.py', 'tempest/services/identity/v3/xml/credentials_client.py', 'tempest/services/identity/v3/xml/identity_client.py', 'tempest/services/identity/v3/xml/endpoints_client.py'], 'web_link': 'https://opendev.org/openstack/tempest/commit/aad85db2fe8f85fe2347aa6b297c2e688b6a2714', 'message': 'Prepare for enabling H302 rule(services/identity)\n\nCurrently H302 rule is ignored by tox. However, this rule should\nbe enabled. This patch partially fixes this problem to prepare for\nH302 rule.\n\nChange-Id: I4546cb540d328c77a44933e975d827f1505386d8\n'}]",0,77857,aad85db2fe8f85fe2347aa6b297c2e688b6a2714,14,4,2,6348,,,0,"Prepare for enabling H302 rule(services/identity)

Currently H302 rule is ignored by tox. However, this rule should
be enabled. This patch partially fixes this problem to prepare for
H302 rule.

Change-Id: I4546cb540d328c77a44933e975d827f1505386d8
",git fetch https://review.opendev.org/openstack/tempest refs/changes/57/77857/1 && git format-patch -1 --stdout FETCH_HEAD,"['tempest/services/identity/v3/json/policy_client.py', 'tempest/services/identity/v3/json/service_client.py', 'tempest/services/identity/v3/json/credentials_client.py', 'tempest/services/identity/v3/json/endpoints_client.py', 'tempest/services/identity/v3/json/identity_client.py']",5,4e9fc4698af09460f73a6b067b209d087360507d,fix_H302_services_identity,from tempest.common import rest_clientclass IdentityV3ClientJSON(rest_client.RestClient):class V3TokenClientJSON(rest_client.RestClient):,from tempest.common.rest_client import RestClientclass IdentityV3ClientJSON(RestClient):class V3TokenClientJSON(RestClient):,11,11
openstack%2Fkeystone~master~I9c8aa3bcb99ea5cb5e4e4d3306d8d222c6f074d1,openstack/keystone,master,I9c8aa3bcb99ea5cb5e4e4d3306d8d222c6f074d1,v3 endpoint create should require url,MERGED,2014-02-26 01:30:39.000000000,2014-03-06 15:08:48.000000000,2014-03-06 15:08:47.000000000,"[{'_account_id': 3}, {'_account_id': 4}, {'_account_id': 1916}, {'_account_id': 9101}]","[{'number': 1, 'created': '2014-02-26 01:30:39.000000000', 'files': ['keystone/tests/test_v3_catalog.py', 'keystone/catalog/controllers.py'], 'web_link': 'https://opendev.org/openstack/keystone/commit/aabf0b525edc2e5063bdba72a33ea6db919423b6', 'message': 'v3 endpoint create should require url\n\nThe url parameter of endpoint object is not nullable in db, but we\ndo not have a null check in api. So, when create a endpoint if I\ndo not specify url parameter I will get a 500 reponse.\nThis patch will add an attribute require check to url parameter.\n\nChange-Id: I9c8aa3bcb99ea5cb5e4e4d3306d8d222c6f074d1\nCloses-Bug: #1284422\n'}]",0,76409,aabf0b525edc2e5063bdba72a33ea6db919423b6,20,4,1,9101,,,0,"v3 endpoint create should require url

The url parameter of endpoint object is not nullable in db, but we
do not have a null check in api. So, when create a endpoint if I
do not specify url parameter I will get a 500 reponse.
This patch will add an attribute require check to url parameter.

Change-Id: I9c8aa3bcb99ea5cb5e4e4d3306d8d222c6f074d1
Closes-Bug: #1284422
",git fetch https://review.opendev.org/openstack/keystone refs/changes/09/76409/1 && git format-patch -1 --stdout FETCH_HEAD,"['keystone/tests/test_v3_catalog.py', 'keystone/catalog/controllers.py']",2,aabf0b525edc2e5063bdba72a33ea6db919423b6,bug/1284422," self._require_attribute(ref, 'url')",,7,0
openstack%2Ftempest~master~Ie29b0f5c2d676cbe3b061ad88e459dc6c6209c80,openstack/tempest,master,Ie29b0f5c2d676cbe3b061ad88e459dc6c6209c80,Separate negative tests for test_images,MERGED,2014-02-21 09:22:14.000000000,2014-03-06 15:08:39.000000000,2014-03-06 15:08:38.000000000,"[{'_account_id': 3}, {'_account_id': 5803}, {'_account_id': 6167}, {'_account_id': 7882}, {'_account_id': 8851}, {'_account_id': 9533}]","[{'number': 1, 'created': '2014-02-21 09:22:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/0177f6b04c73e6924d7f6925c3f1dfe2238ec0ce', 'message': 'Separate negative tests for test_images\n\nMove negative tests from test_images.py to test_images_negative.py\n\nPartially implements blueprint negative-test-files\n\nChange-Id: Ie29b0f5c2d676cbe3b061ad88e459dc6c6209c80\n'}, {'number': 2, 'created': '2014-02-25 08:09:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/356d5e866f61a8f686d061d30f43496b1bab55e3', 'message': 'Separate negative tests for test_images\n\nMove negative tests from test_images.py to test_images_negative.py\n\nPartially implements blueprint negative-test-files\n\nChange-Id: Ie29b0f5c2d676cbe3b061ad88e459dc6c6209c80\n'}, {'number': 3, 'created': '2014-02-27 06:41:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/0681a620f396361fc54d067c8c0ca75e11474ea8', 'message': 'Separate negative tests for test_images\n\nMove negative tests from test_images.py to test_images_negative.py\n\nPartially implements blueprint negative-test-files\n\nChange-Id: Ie29b0f5c2d676cbe3b061ad88e459dc6c6209c80\n'}, {'number': 4, 'created': '2014-03-03 03:00:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/bf7c836a901f7ece7dec39e774a09c602968f97f', 'message': 'Separate negative tests for test_images\n\nMove negative tests from test_images.py to test_images_negative.py\n\nPartially implements blueprint negative-test-files\n\nChange-Id: Ie29b0f5c2d676cbe3b061ad88e459dc6c6209c80\n'}, {'number': 5, 'created': '2014-03-04 01:47:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/0b9d93347e435f456acab92645c45c517e87b8f0', 'message': 'Separate negative tests for test_images\n\nMove negative tests from test_images.py to test_images_negative.py\n\nPartially implements blueprint negative-test-files\n\nChange-Id: Ie29b0f5c2d676cbe3b061ad88e459dc6c6209c80\n'}, {'number': 6, 'created': '2014-03-04 11:04:05.000000000', 'files': ['tempest/api/compute/v3/images/test_images_negative.py', 'tempest/api/compute/v3/images/test_images.py'], 'web_link': 'https://opendev.org/openstack/tempest/commit/5381f548ddbea3bcd5d5756ead3b50632eff3cdb', 'message': 'Separate negative tests for test_images\n\nMove negative tests from test_images.py to test_images_negative.py\n\nPartially implements blueprint negative-test-files\n\nChange-Id: Ie29b0f5c2d676cbe3b061ad88e459dc6c6209c80\n'}]",14,75345,5381f548ddbea3bcd5d5756ead3b50632eff3cdb,45,6,6,7882,,,0,"Separate negative tests for test_images

Move negative tests from test_images.py to test_images_negative.py

Partially implements blueprint negative-test-files

Change-Id: Ie29b0f5c2d676cbe3b061ad88e459dc6c6209c80
",git fetch https://review.opendev.org/openstack/tempest refs/changes/45/75345/6 && git format-patch -1 --stdout FETCH_HEAD,"['tempest/api/compute/v3/images/test_images_negative.py', 'tempest/api/compute/v3/images/test_images.py']",2,0177f6b04c73e6924d7f6925c3f1dfe2238ec0ce,bp/negative-test-files,from tempest import test @test.attr(type='gate'),"from tempest import exceptions from tempest.test import attr def __create_image__(self, server_id, name, meta=None): resp, body = self.servers_client.create_image(server_id, name, meta) image_id = data_utils.parse_image_id(resp['location']) self.addCleanup(self.client.delete_image, image_id) self.client.wait_for_image_status(image_id, 'ACTIVE') return resp, body @attr(type=['negative', 'gate']) def test_create_image_from_deleted_server(self): # An image should not be created if the server instance is removed resp, server = self.create_test_server(wait_until='ACTIVE') # Delete server before trying to create server self.servers_client.delete_server(server['id']) self.servers_client.wait_for_server_termination(server['id']) # Create a new image after server is deleted name = data_utils.rand_name('image') meta = {'image_type': 'test'} self.assertRaises(exceptions.NotFound, self.__create_image__, server['id'], name, meta) @attr(type=['negative', 'gate']) def test_create_image_from_invalid_server(self): # An image should not be created with invalid server id # Create a new image with invalid server id name = data_utils.rand_name('image') meta = {'image_type': 'test'} resp = {} resp['status'] = None self.assertRaises(exceptions.NotFound, self.__create_image__, '!@#$%^&*()', name, meta) @attr(type=['negative', 'gate']) def test_create_image_from_stopped_server(self): resp, server = self.create_test_server(wait_until='ACTIVE') self.servers_client.stop(server['id']) self.servers_client.wait_for_server_status(server['id'], 'SHUTOFF') self.addCleanup(self.servers_client.delete_server, server['id']) snapshot_name = data_utils.rand_name('test-snap-') resp, image = self.create_image_from_server(server['id'], name=snapshot_name, wait_until='active') self.addCleanup(self.client.delete_image, image['id']) self.assertEqual(snapshot_name, image['name']) @attr(type='gate') @attr(type=['negative', 'gate']) def test_create_image_specify_uuid_35_characters_or_less(self): # Return an error if Image ID passed is 35 characters or less snapshot_name = data_utils.rand_name('test-snap-') test_uuid = ('a' * 35) self.assertRaises(exceptions.NotFound, self.servers_client.create_image, test_uuid, snapshot_name) @attr(type=['negative', 'gate']) def test_create_image_specify_uuid_37_characters_or_more(self): # Return an error if Image ID passed is 37 characters or more snapshot_name = data_utils.rand_name('test-snap-') test_uuid = ('a' * 37) self.assertRaises(exceptions.NotFound, self.servers_client.create_image, test_uuid, snapshot_name)",114,68
openstack%2Fdesignate~master~If5ba284320e0e72ca25d7b288ddf0f169cc297a1,openstack/designate,master,If5ba284320e0e72ca25d7b288ddf0f169cc297a1,Introduce nameservers endpoint for zones,MERGED,2014-03-05 10:51:19.000000000,2014-03-06 15:06:44.000000000,2014-03-06 15:06:44.000000000,"[{'_account_id': 3}, {'_account_id': 395}, {'_account_id': 741}, {'_account_id': 8094}, {'_account_id': 10240}]","[{'number': 1, 'created': '2014-03-05 10:51:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/designate/commit/6d86173ef1995dc2add076a1e51cf49c99d453ab', 'message': 'Introduce nameservers endpoint for zones\n\nThis adds /zones/<uuid>/nameservers according the the bug report and\nwill later support server-pools in Juno.\n\nCloses-Bug: #1281839\n\nChange-Id: If5ba284320e0e72ca25d7b288ddf0f169cc297a1\n'}, {'number': 2, 'created': '2014-03-05 10:57:04.000000000', 'files': ['designate/api/v2/controllers/zones.py', 'designate/api/v2/views/nameservers.py', 'designate/tests/test_api/test_v2/test_nameservers.py', 'designate/api/v2/controllers/nameservers.py'], 'web_link': 'https://opendev.org/openstack/designate/commit/490d6b36361b6980d29d2a927fa2596602338dcc', 'message': 'Introduce nameservers endpoint for zones\n\nThis adds /zones/<uuid>/nameservers according the the bug report and\nwill later support server-pools in Juno.\n\nCloses-Bug: #1281839\n\nChange-Id: If5ba284320e0e72ca25d7b288ddf0f169cc297a1\n'}]",8,78156,490d6b36361b6980d29d2a927fa2596602338dcc,14,5,2,395,,,0,"Introduce nameservers endpoint for zones

This adds /zones/<uuid>/nameservers according the the bug report and
will later support server-pools in Juno.

Closes-Bug: #1281839

Change-Id: If5ba284320e0e72ca25d7b288ddf0f169cc297a1
",git fetch https://review.opendev.org/openstack/designate refs/changes/56/78156/1 && git format-patch -1 --stdout FETCH_HEAD,"['designate/api/v2/controllers/zones.py', 'designate/api/v2/views/nameservers.py', 'designate/api/v2/controllers/nameservers.py']",3,6d86173ef1995dc2add076a1e51cf49c99d453ab,bug/1281839,"# Copyright 2013 Hewlett-Packard Development Company, L.P. # # Author: Kiall Mac Innes <kiall@hp.com> # # Licensed under the Apache License, Version 2.0 (the ""License""); you may # not use this file except in compliance with the License. You may obtain # a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT # WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the # License for the specific language governing permissions and limitations # under the License. import pecan from designate import utils from designate.central import rpcapi as central_rpcapi from designate.openstack.common import log as logging from designate.api.v2.controllers import rest from designate.api.v2.views import nameservers as nameservers_view LOG = logging.getLogger(__name__) central_api = central_rpcapi.CentralAPI() class NameServersController(rest.RestController): _view = nameservers_view.NameServerView() @pecan.expose(template='json:', content_type='application/json') @utils.validate_uuid('zone_id') def get_all(self, zone_id): request = pecan.request context = pecan.request.environ['context'] servers = central_api.get_domain_servers(context, zone_id) return self._view.list(context, request, servers, [zone_id]) ",,83,0
openstack%2Ftempest~master~Ifec43c1a978838d953b0f3d87ab12e20881a937f,openstack/tempest,master,Ifec43c1a978838d953b0f3d87ab12e20881a937f,Seperate negative tests for V3 test_server_rescue,MERGED,2014-02-27 10:14:03.000000000,2014-03-06 15:01:09.000000000,2014-03-06 15:01:08.000000000,"[{'_account_id': 3}, {'_account_id': 5803}, {'_account_id': 6167}, {'_account_id': 6348}, {'_account_id': 7139}, {'_account_id': 7882}, {'_account_id': 8851}]","[{'number': 1, 'created': '2014-02-27 10:14:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/5dabab0fbcf205b90b5eb57c4731cfce512a2cfc', 'message': 'Seperate negative tests for V3 test_server_rescue\n\nMove negative tests from test_server_rescue.py to\ntest_server_rescue_negative.py\n\nPartially implements blueprint negative-test-files\n\nChange-Id: Ifec43c1a978838d953b0f3d87ab12e20881a937f\n'}, {'number': 2, 'created': '2014-02-28 00:24:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/dc774c4a2152d1c28b3c6637f22a99854d435cb4', 'message': 'Seperate negative tests for V3 test_server_rescue\n\nMove negative tests from test_server_rescue.py to\ntest_server_rescue_negative.py\n\nPartially implements blueprint negative-test-files\n\nChange-Id: Ifec43c1a978838d953b0f3d87ab12e20881a937f\n'}, {'number': 3, 'created': '2014-03-03 01:01:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/cf5d43d3fff74e66eae69abef78cc632d0bac8e2', 'message': 'Seperate negative tests for V3 test_server_rescue\n\nMove negative tests from test_server_rescue.py to\ntest_server_rescue_negative.py\n\nPartially implements blueprint negative-test-files\n\nChange-Id: Ifec43c1a978838d953b0f3d87ab12e20881a937f\n'}, {'number': 4, 'created': '2014-03-03 05:47:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/c1890404113d4ca640e5fa3c99c38a578073d112', 'message': 'Seperate negative tests for V3 test_server_rescue\n\nMove negative tests from test_server_rescue.py to\ntest_server_rescue_negative.py\n\nPartially implements blueprint negative-test-files\n\nChange-Id: Ifec43c1a978838d953b0f3d87ab12e20881a937f\n'}, {'number': 5, 'created': '2014-03-03 07:21:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/f0857c0daea46e3d9424c42106654d08535ecd9c', 'message': 'Seperate negative tests for V3 test_server_rescue\n\nMove negative tests from test_server_rescue.py to\ntest_server_rescue_negative.py\n\nPartially implements blueprint negative-test-files\n\nChange-Id: Ifec43c1a978838d953b0f3d87ab12e20881a937f\n'}, {'number': 6, 'created': '2014-03-03 07:59:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/6972c0c3dc28c39dae730213504915820707a538', 'message': 'Seperate negative tests for V3 test_server_rescue\n\nMove negative tests from test_server_rescue.py to\ntest_server_rescue_negative.py\n\nPartially implements blueprint negative-test-files\n\nChange-Id: Ifec43c1a978838d953b0f3d87ab12e20881a937f\n'}, {'number': 7, 'created': '2014-03-03 08:23:09.000000000', 'files': ['tempest/api/compute/v3/servers/test_server_rescue.py', 'tempest/api/compute/v3/servers/test_server_rescue_negative.py'], 'web_link': 'https://opendev.org/openstack/tempest/commit/4bbd42158bd55615fd2dd48e6025cbfe33c10eca', 'message': 'Seperate negative tests for V3 test_server_rescue\n\nMove negative tests from test_server_rescue.py to\ntest_server_rescue_negative.py\n\nPartially implements blueprint negative-test-files\n\nChange-Id: Ifec43c1a978838d953b0f3d87ab12e20881a937f\n'}]",22,76816,4bbd42158bd55615fd2dd48e6025cbfe33c10eca,47,7,7,6348,,,0,"Seperate negative tests for V3 test_server_rescue

Move negative tests from test_server_rescue.py to
test_server_rescue_negative.py

Partially implements blueprint negative-test-files

Change-Id: Ifec43c1a978838d953b0f3d87ab12e20881a937f
",git fetch https://review.opendev.org/openstack/tempest refs/changes/16/76816/2 && git format-patch -1 --stdout FETCH_HEAD,"['tempest/api/compute/v3/servers/test_server_rescue.py', 'tempest/api/compute/v3/servers/test_server_rescue_negative.py']",2,5dabab0fbcf205b90b5eb57c4731cfce512a2cfc,bp/negative-test-files,"# Copyright 2013 Hewlett-Packard Development Company, L.P. # Copyright 2014 NEC Corporation. All rights reserved. # # Licensed under the Apache License, Version 2.0 (the ""License""); you may # not use this file except in compliance with the License. You may obtain # a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT # WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the # License for the specific language governing permissions and limitations # under the License. from tempest.api.compute import base from tempest.common.utils import data_utils from tempest import exceptions from tempest import test class ServerRescueV3Test(base.BaseV3ComputeTest): _interface = 'json' @classmethod def setUpClass(cls): super(ServerRescueV3Test, cls).setUpClass() cls.device = 'vdf' # Create a volume and wait for it to become ready for attach resp, cls.volume = cls.volumes_client.create_volume( 1, display_name=data_utils.rand_name(cls.__name__ + '_volume')) cls.volumes_client.wait_for_volume_status( cls.volume['id'], 'available') # Server for negative tests resp, server = cls.create_test_server(wait_until='BUILD') resp, resc_server = cls.create_test_server(wait_until='ACTIVE') cls.rescue_id = resc_server['id'] cls.rescue_password = resc_server['admin_password'] cls.servers_client.rescue_server( cls.rescue_id, admin_password=cls.rescue_password) cls.servers_client.wait_for_server_status(cls.rescue_id, 'RESCUE') def _detach(self, server_id, volume_id): self.servers_client.detach_volume(server_id, volume_id) self.volumes_client.wait_for_volume_status(volume_id, 'available') def _unrescue(self, server_id): resp, body = self.servers_client.unrescue_server(server_id) self.assertEqual(202, resp.status) self.servers_client.wait_for_server_status(server_id, 'ACTIVE') def _unpause(self, server_id): resp, body = self.servers_client.unpause_server(server_id) self.assertEqual(202, resp.status) self.servers_client.wait_for_server_status(server_id, 'ACTIVE') @test.attr(type=['negative', 'gate']) def test_rescue_paused_instance(self): # Rescue a paused server resp, body = self.servers_client.pause_server( self.server_id) self.addCleanup(self._unpause, self.server_id) self.assertEqual(202, resp.status) self.servers_client.wait_for_server_status(self.server_id, 'PAUSED') self.assertRaises(exceptions.Conflict, self.servers_client.rescue_server, self.server_id) @test.attr(type=['negative', 'gate']) def test_rescued_vm_reboot(self): self.assertRaises(exceptions.Conflict, self.servers_client.reboot, self.rescue_id, 'HARD') @test.attr(type=['negative', 'gate']) def test_rescue_non_existent_server(self): # Rescue a non-existing server self.assertRaises(exceptions.NotFound, self.servers_client.rescue_server, '999erra43') @test.attr(type=['negative', 'gate']) def test_rescued_vm_rebuild(self): self.assertRaises(exceptions.Conflict, self.servers_client.rebuild, self.rescue_id, self.image_ref_alt) @test.attr(type=['negative', 'gate']) def test_rescued_vm_attach_volume(self): # Rescue the server self.servers_client.rescue_server(self.server_id, admin_password=self.password) self.servers_client.wait_for_server_status(self.server_id, 'RESCUE') self.addCleanup(self._unrescue, self.server_id) # Attach the volume to the server self.assertRaises(exceptions.Conflict, self.servers_client.attach_volume, self.server_id, self.volume['id'], device='/dev/%s' % self.device) @test.attr(type=['negative', 'gate']) def test_rescued_vm_detach_volume(self): # Attach the volume to the server self.servers_client.attach_volume(self.server_id, self.volume['id'], device='/dev/%s' % self.device) self.volumes_client.wait_for_volume_status(self.volume['id'], 'in-use') # Rescue the server self.servers_client.rescue_server(self.server_id, admin_password=self.password) self.servers_client.wait_for_server_status(self.server_id, 'RESCUE') # addCleanup is a LIFO queue self.addCleanup(self._detach, self.server_id, self.volume['id']) self.addCleanup(self._unrescue, self.server_id) # Detach the volume from the server expecting failure self.assertRaises(exceptions.Conflict, self.servers_client.detach_volume, self.server_id, self.volume['id']) ",,129,90
openstack%2Fnova~master~I8ec441e7815855a94a28c4566790d5144deff16f,openstack/nova,master,I8ec441e7815855a94a28c4566790d5144deff16f,Ignore the image name when booting from volume,MERGED,2014-03-03 09:10:55.000000000,2014-03-06 14:53:50.000000000,2014-03-05 23:45:33.000000000,"[{'_account_id': 3}, {'_account_id': 2750}, {'_account_id': 5170}, {'_account_id': 5511}, {'_account_id': 7808}, {'_account_id': 9008}, {'_account_id': 9578}]","[{'number': 1, 'created': '2014-03-03 09:10:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/0c0e01bb3d31f64ee1a3c94e04b014b7cfdf4f21', 'message': ""Ignore the image name when booting from volume\n\nIn 0185d2445 the _run_instance method was changed to acquire the image\nmetadata from the request_spec instead of glance. This was needed to be\nable to get the image_metadata attached to a volume, when booting from\nit. That change didn't consider that the image name key is not inherited\nwhen creating a volume from an image and introduced a bug when creating\nthe usage_info for volume booted instances.\n\nThis change fixes this by only attaching the image to the usage_info\nwhen really booting from an image and not when booting from a volume.\n\nRelated-Bug: 1281973\nChange-Id: I8ec441e7815855a94a28c4566790d5144deff16f\n""}, {'number': 2, 'created': '2014-03-03 09:48:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/430b0a23a0e0fdc91e6e118fa0946bc68740e153', 'message': ""Ignore the image name when booting from volume\n\nIn 0185d2445 the _run_instance method was changed to acquire the image\nmetadata from the request_spec instead of glance. This was needed to be\nable to get the image_metadata attached to a volume, when booting from\nit. That change didn't consider that the image name key is not inherited\nwhen creating a volume from an image and introduced a bug when creating\nthe usage_info for volume booted instances.\n\nThis change fixes this by only attaching the image name to the usage_info\nonly when booting from an image and not when booting from a volume.\n\nRelated-Bug: 1281973\nChange-Id: I8ec441e7815855a94a28c4566790d5144deff16f\n""}, {'number': 3, 'created': '2014-03-05 12:26:56.000000000', 'files': ['nova/compute/manager.py', 'nova/tests/compute/test_compute.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/43aaf80942a0afb7471e803e57a3db851dab608b', 'message': ""Ignore the image name when booting from volume\n\nIn 0185d2445 the _run_instance method was changed to acquire the image\nmetadata from the request_spec instead of glance. This was needed to be\nable to get the image_metadata attached to a volume, when booting from\nit. That change didn't consider that the image name key is not inherited\nwhen creating a volume from an image and introduced a bug when creating\nthe usage_info for volume booted instances.\n\nThis change fixes this by only attaching the image name to the usage_info\nonly when booting from an image and not when booting from a volume.\n\nRelated-Bug: 1281973\nChange-Id: I8ec441e7815855a94a28c4566790d5144deff16f\n""}]",2,77528,43aaf80942a0afb7471e803e57a3db851dab608b,23,7,3,7808,,,0,"Ignore the image name when booting from volume

In 0185d2445 the _run_instance method was changed to acquire the image
metadata from the request_spec instead of glance. This was needed to be
able to get the image_metadata attached to a volume, when booting from
it. That change didn't consider that the image name key is not inherited
when creating a volume from an image and introduced a bug when creating
the usage_info for volume booted instances.

This change fixes this by only attaching the image name to the usage_info
only when booting from an image and not when booting from a volume.

Related-Bug: 1281973
Change-Id: I8ec441e7815855a94a28c4566790d5144deff16f
",git fetch https://review.opendev.org/openstack/nova refs/changes/28/77528/2 && git format-patch -1 --stdout FETCH_HEAD,"['nova/compute/manager.py', 'nova/tests/compute/test_compute.py']",2,0c0e01bb3d31f64ee1a3c94e04b014b7cfdf4f21,bug/1281973," def test_run_instance_usage_notification(self, request_spec={}): # image_name will only be present when booting from a real image if 'name' in request_spec.get('image', {}): self.assertEqual(payload['image_name'], request_spec['image']['name']) def test_run_instance_image_usage_notification(self): request_spec = {'image': {'name': 'fake_name', 'key': 'value'}} self.test_run_instance_usage_notification(request_spec=request_spec) def test_run_instance_usage_notification_volume_meta(self): # Volume's image metadata won't contain the image name request_spec = {'image': {'key': 'value'}} self.test_run_instance_usage_notification(request_spec=request_spec) "," def test_run_instance_usage_notification(self): request_spec = {'image': {'name': 'fake_name'}} self.assertEqual(msg.payload['image_name'], 'fake_name') self.assertEqual(payload['image_name'], 'fake_name')",17,5
openstack%2Fmurano~master~I7b7bfeab896cda0fa9a290475f5f86f17fccca91,openstack/murano,master,I7b7bfeab896cda0fa9a290475f5f86f17fccca91,Fixed issue with requirements,MERGED,2014-03-04 12:09:49.000000000,2014-03-06 14:50:29.000000000,2014-03-06 14:50:29.000000000,"[{'_account_id': 3}, {'_account_id': 7225}, {'_account_id': 7226}, {'_account_id': 7549}, {'_account_id': 7562}, {'_account_id': 7600}, {'_account_id': 7821}, {'_account_id': 8040}, {'_account_id': 8127}]","[{'number': 1, 'created': '2014-03-04 12:09:49.000000000', 'files': ['requirements.txt'], 'web_link': 'https://opendev.org/openstack/murano/commit/d7abc167ba765a0cb8e94ba7d5d93c73428cf806', 'message': 'Fixed issue with requirements\n\nChange-Id: I7b7bfeab896cda0fa9a290475f5f86f17fccca91\nCloses-Bug: #1287679\n'}]",0,77865,d7abc167ba765a0cb8e94ba7d5d93c73428cf806,12,9,1,7227,,,0,"Fixed issue with requirements

Change-Id: I7b7bfeab896cda0fa9a290475f5f86f17fccca91
Closes-Bug: #1287679
",git fetch https://review.opendev.org/openstack/murano refs/changes/65/77865/1 && git format-patch -1 --stdout FETCH_HEAD,['requirements.txt'],1,d7abc167ba765a0cb8e94ba7d5d93c73428cf806,,"pbr>=0.6,<1.0SQLAlchemy>=0.7.8,<=0.8.99WebOb>=1.2.3boto>=2.12.0,!=2.13.0 sqlalchemy-migrate>=0.8.2,!=0.8.4 httplib2>=0.7.5six>=1.5.2 netaddr>=0.7.6jsonschema>=2.0.0,<3.0.0 python-keystoneclient>=0.6.0","pbr>=0.5.21,<1.0SQLAlchemy>=0.7.8,<=0.7.99WebOb>=1.2.3,<1.3boto>=2.4.0,!=2.13.0 sqlalchemy-migrate>=0.7.2 httplib2six>=1.4.1 netaddrjsonschema>=1.3.0,!=1.4.0 python-keystoneclient>=0.3.2",10,10
openstack%2Fpython-muranoclient~master~Ide0cc4d1bb953c4e3f2956a3af609ce0d7a70158,openstack/python-muranoclient,master,Ide0cc4d1bb953c4e3f2956a3af609ce0d7a70158,Fixed issue with requirements,MERGED,2014-03-04 13:11:02.000000000,2014-03-06 14:46:48.000000000,2014-03-06 14:46:48.000000000,"[{'_account_id': 3}, {'_account_id': 7225}, {'_account_id': 7226}, {'_account_id': 7549}, {'_account_id': 7562}, {'_account_id': 7600}, {'_account_id': 8040}, {'_account_id': 8127}]","[{'number': 1, 'created': '2014-03-04 13:11:02.000000000', 'files': ['requirements.txt'], 'web_link': 'https://opendev.org/openstack/python-muranoclient/commit/a35e2c6ac1eed1d5773c7c8b60b0dfbffe733267', 'message': 'Fixed issue with requirements\n\nChange-Id: Ide0cc4d1bb953c4e3f2956a3af609ce0d7a70158\nCloses-Bug: #1287695\n'}]",0,77876,a35e2c6ac1eed1d5773c7c8b60b0dfbffe733267,11,8,1,7227,,,0,"Fixed issue with requirements

Change-Id: Ide0cc4d1bb953c4e3f2956a3af609ce0d7a70158
Closes-Bug: #1287695
",git fetch https://review.opendev.org/openstack/python-muranoclient refs/changes/76/77876/1 && git format-patch -1 --stdout FETCH_HEAD,['requirements.txt'],1,a35e2c6ac1eed1d5773c7c8b60b0dfbffe733267,,"pbr>=0.6,<1.0PrettyTable>=0.7,<0.8 python-keystoneclient>=0.6.0 httplib2>=0.7.5six>=1.5.2pyOpenSSL>=0.11","pbr>=0.5.21,<1.0PrettyTable>=0.6,<0.8 python-keystoneclient>=0.3.2 httplib2six>=1.4.1pyOpenSSL ",6,7
openstack%2Fceilometer~master~I7c8564ce88d048e5b7d6d1e3c7109c5cb08e48f3,openstack/ceilometer,master,I7c8564ce88d048e5b7d6d1e3c7109c5cb08e48f3,Adds doc string to query validate functions in V2 API,MERGED,2014-02-20 18:46:30.000000000,2014-03-06 14:46:23.000000000,2014-03-06 14:46:23.000000000,"[{'_account_id': 3}, {'_account_id': 7}, {'_account_id': 1669}, {'_account_id': 2284}, {'_account_id': 9562}]","[{'number': 1, 'created': '2014-02-20 18:46:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/1a741435a858a367c1201ad907c985d9937c12cc', 'message': 'Adds doc string to query validate functions in V2 API\n\nRename is_timestamp_valid parameter to allow_timestamps and add\ndoc string to _validate_query and _validate_timestamp_fields\nfunctions, related to the bugfix of bug 1280975.\n\nChange-Id: I7c8564ce88d048e5b7d6d1e3c7109c5cb08e48f3\n'}, {'number': 2, 'created': '2014-02-20 18:49:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/1348d9e2ef37ecb090cc39b6c50c0cf74947a8e6', 'message': 'Adds doc string to query validate functions in V2 API\n\nRename is_timestamp_valid parameter to allow_timestamps and add\ndoc string to _validate_query and _validate_timestamp_fields\nfunctions, related to the bugfix of bug 1280975.\n\nChange-Id: I7c8564ce88d048e5b7d6d1e3c7109c5cb08e48f3\n'}, {'number': 3, 'created': '2014-02-20 20:24:02.000000000', 'files': ['ceilometer/api/controllers/v2.py'], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/bd3997c088710c741d3438a2cd98658f18e69e68', 'message': 'Adds doc string to query validate functions in V2 API\n\nRename is_timestamp_valid parameter to allow_timestamps and add\ndoc string to _validate_query and _validate_timestamp_fields\nfunctions, related to the bugfix of bug 1280975.\n\nChange-Id: I7c8564ce88d048e5b7d6d1e3c7109c5cb08e48f3\n'}]",8,75131,bd3997c088710c741d3438a2cd98658f18e69e68,22,5,3,9562,,,0,"Adds doc string to query validate functions in V2 API

Rename is_timestamp_valid parameter to allow_timestamps and add
doc string to _validate_query and _validate_timestamp_fields
functions, related to the bugfix of bug 1280975.

Change-Id: I7c8564ce88d048e5b7d6d1e3c7109c5cb08e48f3
",git fetch https://review.opendev.org/openstack/ceilometer refs/changes/31/75131/2 && git format-patch -1 --stdout FETCH_HEAD,['ceilometer/api/controllers/v2.py'],1,1a741435a858a367c1201ad907c985d9937c12cc,," allow_timestamps=True): """"""Validates the syntax of the query and verifies that the query request is authorized for the included project. :param query: Query expression that should be validated :param db_func: the function on the storage level, of which arguments will form the valid_keys list, which defines the valid field for a query expression :param internal_keys: internally used field names, that should not be used for querying :param allow_timestamps: defines whether the timestamp-based constraint is applicable for this query or not :returns: None, if the query is valid :raises InvalidInput: if an operator is not supported for a given field :raises InvalidInput: if timestamp constraints are allowed, but search_offset was included without timestamp constraint :raises: UnknownArgument: if a field name is not a timestamp field, nor in the list of valid keys """""" allow_timestamps) allow_timestamps) allow_timestamps): """"""Validates the timestamp related constraints in a query expression, if there is any. :param query: query expression that contains the timestamp fields :param field_name: timestamp name, which should be checked (timestamp, search_offset) :param operator_list: list of operators that are supported for that timestamp, which was specified in the parameter field_name :param allow_timestamps: defines whether the timestamp-based constraint is applicable for this query or not :returns: True, if there was a timestamp constraint, containing a timestamp field named as defined in field_name, in the query and it was allowed and syntactically correct. :returns: False, if there wasn't timestamp constraint, containing a timestamp field named as defined in field_name, in the query :raises InvalidInput: if an operator is unsupported for a given timestamp field :raises UnknownArgument: if the timestamp constraint is not allowed in the query """""" if not allow_timestamps: allow_timestamps=True): allow_timestamps=allow_timestamps) allow_timestamps=False) allow_timestamps=False) allow_timestamps=False)", is_timestamp_valid=True): is_timestamp_valid) is_timestamp_valid) is_timestamp_valid): if not is_timestamp_valid: is_timestamp_valid=True): is_timestamp_valid=is_timestamp_valid) is_timestamp_valid=False) is_timestamp_valid=False) is_timestamp_valid=False),56,10
openstack%2Fnova~master~I58149e57d2ffc6b3d5441aa976e64536df74b271,openstack/nova,master,I58149e57d2ffc6b3d5441aa976e64536df74b271,"Sync imageutils, strutils from oslo-incubator",ABANDONED,2014-03-01 03:20:58.000000000,2014-03-06 14:43:58.000000000,,"[{'_account_id': 3}, {'_account_id': 5170}, {'_account_id': 6928}, {'_account_id': 9008}, {'_account_id': 9578}, {'_account_id': 9796}]","[{'number': 1, 'created': '2014-03-01 03:20:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/2b82943f9161e25ebb147c6edd605d1e5310783f', 'message': 'Sync imageutils, strutils from oslo-incubator\n\nSynced patches:\n\nimageutils:\nbec3a5e Implements SI/IEC unit system conversion to bytes\n8b2b0b7 Use hacking import_exceptions for gettextutils._\naad179d Fixing misspelled encryption key in QemuImgInfo\n12bcdb7 Remove vim header\n2bd46eb Refactors byte size extraction logic\n\nstrutils:\nbec3a5e Implements SI/IEC unit system conversion to bytes\ne53fe85 strutils bool_from_string, allow specified default\n8b2b0b7 Use hacking import_exceptions for gettextutils._\n84d461e Fix a bug in safe_encode where it returns a bytes object in py3\n12bcdb7 Remove vim header\n3970d46 Fix typos in oslo\n1a2df89 Enable H302 hacking check\n67bd769 python3: Fix traceback while running python3.\nb0c51ec Refactors to_bytes\n\nChange-Id: I58149e57d2ffc6b3d5441aa976e64536df74b271\n'}, {'number': 2, 'created': '2014-03-01 06:19:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/392d473976edb2e0d134ebdcfc8f06c68c7d518d', 'message': 'Sync imageutils, strutils from oslo-incubator\n\nSynced patches:\n\nimageutils:\nbec3a5e Implements SI/IEC unit system conversion to bytes\n8b2b0b7 Use hacking import_exceptions for gettextutils._\naad179d Fixing misspelled encryption key in QemuImgInfo\n12bcdb7 Remove vim header\n2bd46eb Refactors byte size extraction logic\n\nstrutils:\nbec3a5e Implements SI/IEC unit system conversion to bytes\ne53fe85 strutils bool_from_string, allow specified default\n8b2b0b7 Use hacking import_exceptions for gettextutils._\n84d461e Fix a bug in safe_encode where it returns a bytes object in py3\n12bcdb7 Remove vim header\n3970d46 Fix typos in oslo\n1a2df89 Enable H302 hacking check\n67bd769 python3: Fix traceback while running python3.\nb0c51ec Refactors to_bytes\n\nChange-Id: I58149e57d2ffc6b3d5441aa976e64536df74b271\n'}, {'number': 3, 'created': '2014-03-01 09:01:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/f155a292df430cde389eb7d733efa63e43e23213', 'message': 'Sync imageutils, strutils from oslo-incubator\n\nSynced patches:\n\nimageutils:\nbec3a5e Implements SI/IEC unit system conversion to bytes\n8b2b0b7 Use hacking import_exceptions for gettextutils._\naad179d Fixing misspelled encryption key in QemuImgInfo\n12bcdb7 Remove vim header\n2bd46eb Refactors byte size extraction logic\n\nstrutils:\nbec3a5e Implements SI/IEC unit system conversion to bytes\ne53fe85 strutils bool_from_string, allow specified default\n8b2b0b7 Use hacking import_exceptions for gettextutils._\n84d461e Fix a bug in safe_encode where it returns a bytes object in py3\n12bcdb7 Remove vim header\n3970d46 Fix typos in oslo\n1a2df89 Enable H302 hacking check\n67bd769 python3: Fix traceback while running python3.\nb0c51ec Refactors to_bytes\n\nAlso adjust test case to pass the jenkins.\n\nChange-Id: I58149e57d2ffc6b3d5441aa976e64536df74b271\n'}, {'number': 4, 'created': '2014-03-03 06:42:59.000000000', 'files': ['nova/tests/virt/libvirt/test_libvirt.py', 'nova/openstack/common/strutils.py', 'nova/openstack/common/imageutils.py', 'nova/virt/libvirt/utils.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/f052f484aad6cfcec8bc21b87d6a90897a669ce9', 'message': 'Sync imageutils, strutils from oslo-incubator\n\nSynced patches:\n\nimageutils:\nbec3a5e Implements SI/IEC unit system conversion to bytes\n8b2b0b7 Use hacking import_exceptions for gettextutils._\naad179d Fixing misspelled encryption key in QemuImgInfo\n12bcdb7 Remove vim header\n2bd46eb Refactors byte size extraction logic\n\nstrutils:\nbec3a5e Implements SI/IEC unit system conversion to bytes\ne53fe85 strutils bool_from_string, allow specified default\n8b2b0b7 Use hacking import_exceptions for gettextutils._\n84d461e Fix a bug in safe_encode where it returns a bytes object in py3\n12bcdb7 Remove vim header\n3970d46 Fix typos in oslo\n1a2df89 Enable H302 hacking check\n67bd769 python3: Fix traceback while running python3.\nb0c51ec Refactors to_bytes\n\nAlso adjust test case to pass the jenkins.\n\nChange-Id: I58149e57d2ffc6b3d5441aa976e64536df74b271\n'}]",3,77327,f052f484aad6cfcec8bc21b87d6a90897a669ce9,37,6,4,9796,,,0,"Sync imageutils, strutils from oslo-incubator

Synced patches:

imageutils:
bec3a5e Implements SI/IEC unit system conversion to bytes
8b2b0b7 Use hacking import_exceptions for gettextutils._
aad179d Fixing misspelled encryption key in QemuImgInfo
12bcdb7 Remove vim header
2bd46eb Refactors byte size extraction logic

strutils:
bec3a5e Implements SI/IEC unit system conversion to bytes
e53fe85 strutils bool_from_string, allow specified default
8b2b0b7 Use hacking import_exceptions for gettextutils._
84d461e Fix a bug in safe_encode where it returns a bytes object in py3
12bcdb7 Remove vim header
3970d46 Fix typos in oslo
1a2df89 Enable H302 hacking check
67bd769 python3: Fix traceback while running python3.
b0c51ec Refactors to_bytes

Also adjust test case to pass the jenkins.

Change-Id: I58149e57d2ffc6b3d5441aa976e64536df74b271
",git fetch https://review.opendev.org/openstack/nova refs/changes/27/77327/2 && git format-patch -1 --stdout FETCH_HEAD,"['nova/openstack/common/strutils.py', 'nova/openstack/common/imageutils.py']",2,2b82943f9161e25ebb147c6edd605d1e5310783f,sync_cliutils,"from nova.openstack.common.gettextutils import _ SIZE_RE = re.compile(r""(\d+)(\w+)?(\s*\(\s*(\d+)\s+bytes\s*\))?"", re.I) self.encrypted = details.get('encrypted') if self.encrypted: lines.append(""encrypted: %s"" % self.encrypted) if not real_size: raise ValueError(_('Invalid input value ""%s"".') % details) magnitude = real_size.group(1) unit_of_measure = real_size.group(2) bytes_info = real_size.group(3) if bytes_info: return int(real_size.group(4)) elif not unit_of_measure: return int(magnitude) return strutils.string_to_bytes('%s%sB' % (magnitude, unit_of_measure), return_int=True) if root_details == 'None': real_details = 0 else: real_details = self._extract_bytes(root_details)","# vim: tabstop=4 shiftwidth=4 softtabstop=4 from nova.openstack.common.gettextutils import _ # noqa SIZE_RE = re.compile(r""\(\s*(\d+)\s+bytes\s*\)"", re.I) self.encryption = details.get('encryption') if real_size: details = real_size.group(1) try: details = strutils.to_bytes(details) except TypeError: pass return details real_details = self._extract_bytes(root_details)",93,58
openstack%2Foslo-incubator~master~I01a5312700be80f353725fdf13de6413c4eb86f3,openstack/oslo-incubator,master,I01a5312700be80f353725fdf13de6413c4eb86f3,"strutils: Allow safe_{encode,decode} to take bytes as input",MERGED,2014-03-04 21:29:55.000000000,2014-03-06 14:36:23.000000000,2014-03-06 14:36:22.000000000,"[{'_account_id': 3}, {'_account_id': 1669}, {'_account_id': 2813}, {'_account_id': 5638}, {'_account_id': 9107}]","[{'number': 1, 'created': '2014-03-04 21:29:55.000000000', 'files': ['tests/unit/test_strutils.py', 'openstack/common/strutils.py'], 'web_link': 'https://opendev.org/openstack/oslo-incubator/commit/302c7c80b503b8090e8118e45061e8903b5339a9', 'message': 'strutils: Allow safe_{encode,decode} to take bytes as input\n\nIn Python 3, passing ""b\'foo\'"" to safe_{encode,decode} currently fails. This\npatch fixes this issue.\n\nChange-Id: I01a5312700be80f353725fdf13de6413c4eb86f3\n'}]",0,78010,302c7c80b503b8090e8118e45061e8903b5339a9,10,5,1,8122,,,0,"strutils: Allow safe_{encode,decode} to take bytes as input

In Python 3, passing ""b'foo'"" to safe_{encode,decode} currently fails. This
patch fixes this issue.

Change-Id: I01a5312700be80f353725fdf13de6413c4eb86f3
",git fetch https://review.opendev.org/openstack/oslo-incubator refs/changes/10/78010/1 && git format-patch -1 --stdout FETCH_HEAD,"['tests/unit/test_strutils.py', 'openstack/common/strutils.py']",2,302c7c80b503b8090e8118e45061e8903b5339a9,fix_safe_encode_decode," """"""Decodes incoming text/bytes string using `incoming` if they're not already unicode. if not isinstance(text, (six.string_types, six.binary_type)): """"""Encodes incoming text/bytes string using `encoding`. if not isinstance(text, (six.string_types, six.binary_type)):"," """"""Decodes incoming str using `incoming` if they're not already unicode. if not isinstance(text, six.string_types): """"""Encodes incoming str/unicode using `encoding`. if not isinstance(text, six.string_types):",8,4
openstack%2Ftooz~master~I2be0a6a0b8249dc76296552ab2ee05d4b9fb6c7c,openstack/tooz,master,I2be0a6a0b8249dc76296552ab2ee05d4b9fb6c7c,Add pbr generated and testr files to gitignore,MERGED,2014-03-05 14:56:31.000000000,2014-03-06 14:28:46.000000000,2014-03-06 14:28:45.000000000,"[{'_account_id': 3}, {'_account_id': 1669}, {'_account_id': 2813}, {'_account_id': 7450}, {'_account_id': 8122}, {'_account_id': 9107}]","[{'number': 1, 'created': '2014-03-05 14:56:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tooz/commit/99cc54ee7a659b2d4f29e1d21338ae1567e5652e', 'message': 'Add pbr generated and testr files to gitignore\n\nThese files are either generated by pbr on build or used by the test\nsuite. Ignore them.\n\nChange-Id: I2be0a6a0b8249dc76296552ab2ee05d4b9fb6c7c\n'}, {'number': 2, 'created': '2014-03-06 10:54:43.000000000', 'files': ['.gitignore'], 'web_link': 'https://opendev.org/openstack/tooz/commit/df43a0f626fae01f2cbe1a8b02421c8c5e8907e3', 'message': 'Add pbr generated and testr files to gitignore\n\nThese files are either generated by pbr on build or used by the test\nsuite. Ignore them.\n\nChange-Id: I2be0a6a0b8249dc76296552ab2ee05d4b9fb6c7c\n'}]",3,78246,df43a0f626fae01f2cbe1a8b02421c8c5e8907e3,11,6,2,1669,,,0,"Add pbr generated and testr files to gitignore

These files are either generated by pbr on build or used by the test
suite. Ignore them.

Change-Id: I2be0a6a0b8249dc76296552ab2ee05d4b9fb6c7c
",git fetch https://review.opendev.org/openstack/tooz refs/changes/46/78246/1 && git format-patch -1 --stdout FETCH_HEAD,['.gitignore'],1,99cc54ee7a659b2d4f29e1d21338ae1567e5652e,jd/gitignore,AUTHORS ChangeLog .testrepository,,3,0
openstack%2Fceilometer~stable%2Fhavana~I2aaef54354926f9afe3bb1d4fae8f8aa0ae600ab,openstack/ceilometer,stable/havana,I2aaef54354926f9afe3bb1d4fae8f8aa0ae600ab,Refactor timestamp existence validation in V2 API,MERGED,2014-02-20 14:54:42.000000000,2014-03-06 14:14:23.000000000,2014-03-06 14:14:23.000000000,"[{'_account_id': 3}, {'_account_id': 1669}, {'_account_id': 2284}]","[{'number': 1, 'created': '2014-02-20 14:54:42.000000000', 'files': ['tests/api/v2/test_alarm_scenarios.py', 'ceilometer/api/controllers/v2.py', 'tests/api/v2/test_list_meters_scenarios.py'], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/2c6a84f17dff2e0eb3970e0f89d8ea3e1d21cde5', 'message': ""Refactor timestamp existence validation in V2 API\n\nThere was a bug in AlarmThresholdRule in v2.py, the timestamp_keys\nwere defined with a missing comma:\n['timestamp', 'start', 'start_timestamp' 'end', 'end_timestamp'].\n\nThe validation, if the timestamp field is used or not, was unclear\nin the current implementation. A new parameter, 'timestamp_is_valid',\nwas added to the validation functions to show, if the timestamp is\nallowed to use or not in the validated query.\n\nFixes bug 1280975\n\n(cherry picked from commit b1834e55fce08f1536c7d9392ae035b9583be8ed)\n\nChange-Id: I2aaef54354926f9afe3bb1d4fae8f8aa0ae600ab\n""}]",0,75058,2c6a84f17dff2e0eb3970e0f89d8ea3e1d21cde5,9,3,1,9562,,,0,"Refactor timestamp existence validation in V2 API

There was a bug in AlarmThresholdRule in v2.py, the timestamp_keys
were defined with a missing comma:
['timestamp', 'start', 'start_timestamp' 'end', 'end_timestamp'].

The validation, if the timestamp field is used or not, was unclear
in the current implementation. A new parameter, 'timestamp_is_valid',
was added to the validation functions to show, if the timestamp is
allowed to use or not in the validated query.

Fixes bug 1280975

(cherry picked from commit b1834e55fce08f1536c7d9392ae035b9583be8ed)

Change-Id: I2aaef54354926f9afe3bb1d4fae8f8aa0ae600ab
",git fetch https://review.opendev.org/openstack/ceilometer refs/changes/58/75058/1 && git format-patch -1 --stdout FETCH_HEAD,"['tests/api/v2/test_alarm_scenarios.py', 'ceilometer/api/controllers/v2.py', 'tests/api/v2/test_list_meters_scenarios.py']",3,2c6a84f17dff2e0eb3970e0f89d8ea3e1d21cde5,bug/1280975,"import json as jsonutils def test_list_meters_query_with_timestamp(self): date_time = datetime.datetime(2012, 7, 2, 10, 41) isotime = date_time.isoformat() resp = self.get_json('/meters', q=[{'field': 'timestamp', 'op': 'gt', 'value': isotime}], expect_errors=True) self.assertEqual(resp.status_code, 400) self.assertEqual(jsonutils.loads(resp.body)['error_message'] ['faultstring'], 'Unknown argument: ""timestamp"": ' 'not valid for this resource') def test_query_samples_with_search_offset(self): resp = self.get_json('/meters/meter.mine', q=[{'field': 'search_offset', 'op': 'eq', 'value': 42}], expect_errors=True) self.assertEqual(resp.status_code, 400) self.assertEqual(jsonutils.loads(resp.body)['error_message'] ['faultstring'], ""Invalid input for field/attribute field. "" ""Value: 'search_offset'. "" ""search_offset cannot be used without timestamp"") ",,121,26
openstack%2Fceilometer~master~Id4d67fa5ee679fe1c8d86b8575a99bfb89e384fa,openstack/ceilometer,master,Id4d67fa5ee679fe1c8d86b8575a99bfb89e384fa,Rename id to alarm_id of Alarm in SqlAlchemy,MERGED,2014-02-20 17:48:07.000000000,2014-03-06 14:14:16.000000000,2014-03-06 14:14:16.000000000,"[{'_account_id': 3}, {'_account_id': 1669}, {'_account_id': 2284}, {'_account_id': 6537}, {'_account_id': 6676}, {'_account_id': 9708}]","[{'number': 1, 'created': '2014-02-20 17:48:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/6ad86576ade6b3fcaca3b7d8795b2257e06ab316', 'message': 'Fix alarm_id querying in /v2/query/alarms API\n\nIn SQL backend the alarm_id field of the Alarm model stored as\nin the id column so the complex query code needs to map between\nthese two names\n\nCloses-Bug: #1282667\n\nChange-Id: Id4d67fa5ee679fe1c8d86b8575a99bfb89e384fa\n'}, {'number': 2, 'created': '2014-02-21 15:56:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/a027936f607a65c54c081aa4cf3ad79b46b9ad81', 'message': 'Rename id to alarm_id of Alarm in SqlAlchemy\n\nThis change makes the schema more consistent.\n\nIt also fixes a bug preventig querying alarm_id\non /v2/query/alarms API.\n\nCloses-Bug: #1282667\n\nChange-Id: Id4d67fa5ee679fe1c8d86b8575a99bfb89e384fa\n'}, {'number': 3, 'created': '2014-02-21 17:22:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/36aa286708f9fc8da59b1177d9d755895cb95c54', 'message': 'Rename id to alarm_id of Alarm in SqlAlchemy\n\nThis change makes the schema more consistent.\n\nIt also fixes a bug preventig querying alarm_id\non /v2/query/alarms API.\n\nCloses-Bug: #1282667\n\nChange-Id: Id4d67fa5ee679fe1c8d86b8575a99bfb89e384fa\n'}, {'number': 4, 'created': '2014-02-25 21:10:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/64aef81e01e929a8d8444ab7dced1d54bfd296cb', 'message': 'Rename id to alarm_id of Alarm in SqlAlchemy\n\nThis change makes the schema more consistent.\n\nIt also fixes a bug preventig querying alarm_id\non /v2/query/alarms API.\n\nCloses-Bug: #1282667\n\nChange-Id: Id4d67fa5ee679fe1c8d86b8575a99bfb89e384fa\n'}, {'number': 5, 'created': '2014-03-06 09:59:18.000000000', 'files': ['ceilometer/tests/storage/test_storage_scenarios.py', 'ceilometer/storage/sqlalchemy/migrate_repo/versions/033_alarm_id_rename.py', 'ceilometer/storage/impl_sqlalchemy.py', 'ceilometer/storage/sqlalchemy/models.py'], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/5f329a912ec83f75f23a7bc55457fd4e51ce1ddf', 'message': 'Rename id to alarm_id of Alarm in SqlAlchemy\n\nThis change makes the schema more consistent.\n\nIt also fixes a bug preventig querying alarm_id\non /v2/query/alarms API.\n\nCloses-Bug: #1282667\n\nChange-Id: Id4d67fa5ee679fe1c8d86b8575a99bfb89e384fa\n'}]",0,75116,5f329a912ec83f75f23a7bc55457fd4e51ce1ddf,37,6,5,9708,,,0,"Rename id to alarm_id of Alarm in SqlAlchemy

This change makes the schema more consistent.

It also fixes a bug preventig querying alarm_id
on /v2/query/alarms API.

Closes-Bug: #1282667

Change-Id: Id4d67fa5ee679fe1c8d86b8575a99bfb89e384fa
",git fetch https://review.opendev.org/openstack/ceilometer refs/changes/16/75116/2 && git format-patch -1 --stdout FETCH_HEAD,"['ceilometer/tests/storage/test_storage_scenarios.py', 'ceilometer/storage/impl_sqlalchemy.py']",2,6ad86576ade6b3fcaca3b7d8795b2257e06ab316,bug/1282667," def _retrieve_data(self, filter_expr, orderby, limit, table, field_name_mapping={}): table, field_name_mapping) def _transform_expression(self, expression_tree, table, field_name_mapping={}): field_name = field_name_mapping.get(nodes.keys()[0], nodes.keys()[0]) return op(getattr(table, field_name), nodes.values()[0]) return self._retrieve_data(filter_expr, orderby, limit, models.Alarm, field_name_mapping={""alarm_id"": ""id""})"," def _retrieve_data(self, filter_expr, orderby, limit, table): table) def _transform_expression(self, expression_tree, table): return op(getattr(table, nodes.keys()[0]), nodes.values()[0]) return self._retrieve_data(filter_expr, orderby, limit, models.Alarm)",21,5
openstack%2Foslo-incubator~master~I0a15bf4a90b0aea5fa715027d13d8af816f9e72d,openstack/oslo-incubator,master,I0a15bf4a90b0aea5fa715027d13d8af816f9e72d,Prevent incorrect usage of _wrap_db_error(),MERGED,2014-02-18 10:12:43.000000000,2014-03-06 14:08:47.000000000,2014-03-06 14:08:46.000000000,"[{'_account_id': 3}, {'_account_id': 2813}, {'_account_id': 5638}, {'_account_id': 6849}, {'_account_id': 6928}, {'_account_id': 7491}, {'_account_id': 9796}]","[{'number': 1, 'created': '2014-02-18 10:12:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo-incubator/commit/2f7c04601f7ba4fc60fa0a3cc20eb8db2ecc0117', 'message': ""Prevent incorrect usage of _wrap_db_error()\n\n_wrap_db_error() has an implicit contract that it can be applied only\nto methods of SQLAlchemy Session subclasses. This seems to be a good\ntask for an assert statement (as it's something we want to check\nduring development and debugging, but not something that an end user\ncan trigger, which would require a general runtime check).\n\nChange-Id: I0a15bf4a90b0aea5fa715027d13d8af816f9e72d\n""}, {'number': 2, 'created': '2014-03-05 19:14:21.000000000', 'files': ['openstack/common/db/sqlalchemy/session.py'], 'web_link': 'https://opendev.org/openstack/oslo-incubator/commit/96a22178cc7853a97cf00f12d4ff4f0b4fa169a7', 'message': ""Prevent incorrect usage of _wrap_db_error()\n\n_wrap_db_error() has an implicit contract that it can be applied only\nto methods of SQLAlchemy Session subclasses. This seems to be a good\ntask for an assert statement (as it's something we want to check\nduring development and debugging, but not something that an end user\ncan trigger, which would require a general runtime check).\n\nChange-Id: I0a15bf4a90b0aea5fa715027d13d8af816f9e72d\n""}]",4,74314,96a22178cc7853a97cf00f12d4ff4f0b4fa169a7,22,7,2,6849,,,0,"Prevent incorrect usage of _wrap_db_error()

_wrap_db_error() has an implicit contract that it can be applied only
to methods of SQLAlchemy Session subclasses. This seems to be a good
task for an assert statement (as it's something we want to check
during development and debugging, but not something that an end user
can trigger, which would require a general runtime check).

Change-Id: I0a15bf4a90b0aea5fa715027d13d8af816f9e72d
",git fetch https://review.opendev.org/openstack/oslo-incubator refs/changes/14/74314/2 && git format-patch -1 --stdout FETCH_HEAD,['openstack/common/db/sqlalchemy/session.py'],1,2f7c04601f7ba4fc60fa0a3cc20eb8db2ecc0117,wrap_db_error," assert issubclass( self.__class__, sqlalchemy.orm.session.Session ), _('_wrap_db_error() can only be applied to methods of ' 'subclasses of sqlalchemy.orm.session.Session') ", #TODO(rpodolyaka): in a subsequent commit make this a class decorator to # ensure it can only applied to Session subclasses instances (as we use # Session instance bind attribute below) ,5,4
openstack%2Foslo-incubator~master~Ifcaf60f5c54d74e8fc317be6808363bce7429cc8,openstack/oslo-incubator,master,Ifcaf60f5c54d74e8fc317be6808363bce7429cc8,Enable decimal value input in imageutils.QemuImgInfo,MERGED,2014-02-18 08:46:23.000000000,2014-03-06 14:07:14.000000000,2014-03-06 14:07:14.000000000,"[{'_account_id': 3}, {'_account_id': 1994}, {'_account_id': 5638}, {'_account_id': 6928}, {'_account_id': 9796}]","[{'number': 1, 'created': '2014-02-18 08:46:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo-incubator/commit/549e1a023b9b2f4f5987f3b305d3743397363003', 'message': 'tmp\n\nChange-Id: Ifcaf60f5c54d74e8fc317be6808363bce7429cc8\n'}, {'number': 2, 'created': '2014-02-27 03:16:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo-incubator/commit/89ed786b16146efa20f4cf097a88f979e43d73e2', 'message': 'Enable decimal value input in imageutils.QemuImgInfo\n\nNova has test cases where it image sizes are in float value.\nHowever imageutils has errors when given float values.\nThis patch enhances the regex to handle float values.\nTest cases were added accordingly.\n\nChange-Id: Ifcaf60f5c54d74e8fc317be6808363bce7429cc8\n'}, {'number': 3, 'created': '2014-02-28 00:57:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo-incubator/commit/57dcc97c558ae19ab8bfaabf219dcd3a858fdcb3', 'message': 'Enable decimal value input in imageutils.QemuImgInfo\n\nNova has test cases where it image sizes are in float value.\nHowever imageutils has errors when given float values.\nThis patch enhances the regex to handle float values.\nTest cases were added accordingly.\n\nChange-Id: Ifcaf60f5c54d74e8fc317be6808363bce7429cc8\n'}, {'number': 4, 'created': '2014-02-28 00:57:00.000000000', 'files': ['openstack/common/imageutils.py', 'tests/unit/test_imageutils.py'], 'web_link': 'https://opendev.org/openstack/oslo-incubator/commit/b455fac281de37aa883b39e8a7c47a2a176e4d99', 'message': 'Enable decimal value input in imageutils.QemuImgInfo\n\nNova has test cases where it image sizes are in float value.\nHowever imageutils has errors when given float values.\nThis patch enhances the regex to handle float values.\nTest cases were added accordingly.\n\nChange-Id: Ifcaf60f5c54d74e8fc317be6808363bce7429cc8\n'}]",0,74295,b455fac281de37aa883b39e8a7c47a2a176e4d99,25,5,4,1994,,,0,"Enable decimal value input in imageutils.QemuImgInfo

Nova has test cases where it image sizes are in float value.
However imageutils has errors when given float values.
This patch enhances the regex to handle float values.
Test cases were added accordingly.

Change-Id: Ifcaf60f5c54d74e8fc317be6808363bce7429cc8
",git fetch https://review.opendev.org/openstack/oslo-incubator refs/changes/95/74295/2 && git format-patch -1 --stdout FETCH_HEAD,['openstack/common/imageutils.py'],1,549e1a023b9b2f4f5987f3b305d3743397363003,float_imageutils," SIZE_RE = re.compile(r""(\d*\.?\d+)(\w+)?(\s*\(\s*(\d+)\s+bytes\s*\))?"", re.I)"," SIZE_RE = re.compile(r""(\d+)(\w+)?(\s*\(\s*(\d+)\s+bytes\s*\))?"", re.I)",2,1
openstack%2Fsolum~master~I5afd014bb0e55c3e10ba5451c3dbc30c6ded90c9,openstack/solum,master,I5afd014bb0e55c3e10ba5451c3dbc30c6ded90c9,Move language pack handler test file,MERGED,2014-02-28 21:23:19.000000000,2014-03-06 14:07:10.000000000,2014-03-06 14:07:10.000000000,"[{'_account_id': 3}, {'_account_id': 668}, {'_account_id': 2506}, {'_account_id': 4715}, {'_account_id': 8334}, {'_account_id': 9113}, {'_account_id': 9548}]","[{'number': 1, 'created': '2014-02-28 21:23:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/solum/commit/bf81a7a5e9cdec8fecdf10840b9a187b008994de', 'message': 'Move language pack handler test file\n\nMoved language pack handler test file from tests/api/v1/ directory\nto tests/api/handlers/ directory.\n\nChange-Id: I5afd014bb0e55c3e10ba5451c3dbc30c6ded90c9\n'}, {'number': 2, 'created': '2014-02-28 23:47:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/solum/commit/c929ef6288cf1da2d0dc7b2933147b6159566bc1', 'message': 'Move language pack handler test file\n\nMoved language pack handler test file from tests/api/v1/ directory\nto tests/api/handlers/ directory.\n\nChange-Id: I5afd014bb0e55c3e10ba5451c3dbc30c6ded90c9\n'}, {'number': 3, 'created': '2014-03-06 02:57:28.000000000', 'files': ['solum/tests/api/handlers/test_lp_handler.py'], 'web_link': 'https://opendev.org/openstack/solum/commit/86a126ee6a8be41059b7b89d90f5f74b7b135423', 'message': 'Move language pack handler test file\n\nMoved language pack handler test file from tests/api/v1/ directory\nto tests/api/handlers/ directory.\n\nChange-Id: I5afd014bb0e55c3e10ba5451c3dbc30c6ded90c9\n'}]",0,77270,86a126ee6a8be41059b7b89d90f5f74b7b135423,24,7,3,9113,,,0,"Move language pack handler test file

Moved language pack handler test file from tests/api/v1/ directory
to tests/api/handlers/ directory.

Change-Id: I5afd014bb0e55c3e10ba5451c3dbc30c6ded90c9
",git fetch https://review.opendev.org/openstack/solum refs/changes/70/77270/1 && git format-patch -1 --stdout FETCH_HEAD,['solum/tests/api/handlers/test_lp_handler.py'],1,bf81a7a5e9cdec8fecdf10840b9a187b008994de,file-rename,,,0,0
openstack%2Ftooz~master~I1c3c56e405d7cce2edfdedfe4e129c9c366a5afe,openstack/tooz,master,I1c3c56e405d7cce2edfdedfe4e129c9c366a5afe,coordination: enhance MemberAlreadyExist exception,MERGED,2014-02-28 12:07:15.000000000,2014-03-06 14:04:33.000000000,2014-03-06 14:04:33.000000000,"[{'_account_id': 3}, {'_account_id': 1669}, {'_account_id': 7450}, {'_account_id': 8122}]","[{'number': 1, 'created': '2014-02-28 12:07:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tooz/commit/77524556d60220baeea162c7ecd00769b6aed305', 'message': 'coordination: enhance MemberAlreadyExist exception\n\nChange-Id: I1c3c56e405d7cce2edfdedfe4e129c9c366a5afe\n'}, {'number': 2, 'created': '2014-03-05 15:01:14.000000000', 'files': ['tooz/drivers/zookeeper.py', 'tooz/coordination.py'], 'web_link': 'https://opendev.org/openstack/tooz/commit/1be98d3df106cd59d0484346eee007a626c091cc', 'message': 'coordination: enhance MemberAlreadyExist exception\n\nChange-Id: I1c3c56e405d7cce2edfdedfe4e129c9c366a5afe\n'}]",0,77145,1be98d3df106cd59d0484346eee007a626c091cc,19,4,2,1669,,,0,"coordination: enhance MemberAlreadyExist exception

Change-Id: I1c3c56e405d7cce2edfdedfe4e129c9c366a5afe
",git fetch https://review.opendev.org/openstack/tooz refs/changes/45/77145/1 && git format-patch -1 --stdout FETCH_HEAD,"['tooz/drivers/zookeeper.py', 'tooz/coordination.py']",2,77524556d60220baeea162c7ecd00769b6aed305,jd/memcached," def __init__(self, group_id, member_id): self.group_id = group_id self.member_id = member_id super(MemberAlreadyExist, self).__init__( ""Member %s has already joined %s"" % (member_id, group_id))",,7,1
openstack%2Ftooz~master~I98194d4c236faa9005324b3d70cd97d1a732cdda,openstack/tooz,master,I98194d4c236faa9005324b3d70cd97d1a732cdda,coordination: enhance GroupNotCreated exception,MERGED,2014-02-28 12:07:15.000000000,2014-03-06 14:04:25.000000000,2014-03-06 14:04:25.000000000,"[{'_account_id': 3}, {'_account_id': 1669}, {'_account_id': 7450}]","[{'number': 1, 'created': '2014-02-28 12:07:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tooz/commit/5fb5d5e30373fe1791f3aec7161106d8cafe3fe6', 'message': 'coordination: enhance GroupNotCreated exception\n\nChange-Id: I98194d4c236faa9005324b3d70cd97d1a732cdda\n'}, {'number': 2, 'created': '2014-03-05 15:01:14.000000000', 'files': ['tooz/drivers/zookeeper.py', 'tooz/coordination.py'], 'web_link': 'https://opendev.org/openstack/tooz/commit/709317c78b93b7cf3bb3e8d6a0cd2d35e6947a81', 'message': 'coordination: enhance GroupNotCreated exception\n\nChange-Id: I98194d4c236faa9005324b3d70cd97d1a732cdda\n'}]",0,77144,709317c78b93b7cf3bb3e8d6a0cd2d35e6947a81,12,3,2,1669,,,0,"coordination: enhance GroupNotCreated exception

Change-Id: I98194d4c236faa9005324b3d70cd97d1a732cdda
",git fetch https://review.opendev.org/openstack/tooz refs/changes/44/77144/2 && git format-patch -1 --stdout FETCH_HEAD,"['tooz/drivers/zookeeper.py', 'tooz/coordination.py']",2,5fb5d5e30373fe1791f3aec7161106d8cafe3fe6,jd/memcached," def __init__(self, group_id): self.group_id = group_id super(GroupNotCreated, self).__init__( ""Group %s does not exist"" % group_id)",,6,4
openstack%2Ftooz~master~I51d599abee283ff8ba29ad68f157218966ac6ead,openstack/tooz,master,I51d599abee283ff8ba29ad68f157218966ac6ead,coordination: enhance MemberNotJoined,MERGED,2014-02-28 12:07:15.000000000,2014-03-06 14:04:24.000000000,2014-03-06 14:04:24.000000000,"[{'_account_id': 3}, {'_account_id': 1669}, {'_account_id': 7450}, {'_account_id': 8122}]","[{'number': 1, 'created': '2014-02-28 12:07:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tooz/commit/339979cc50f30a58ae201c5acb71828bea55726d', 'message': 'coordination: enhance MemberNotJoined\n\nChange-Id: I51d599abee283ff8ba29ad68f157218966ac6ead\n'}, {'number': 2, 'created': '2014-03-05 15:01:15.000000000', 'files': ['tooz/drivers/zookeeper.py', 'tooz/coordination.py'], 'web_link': 'https://opendev.org/openstack/tooz/commit/debbf5998dbc115918f59331c2b3989855890977', 'message': 'coordination: enhance MemberNotJoined\n\nChange-Id: I51d599abee283ff8ba29ad68f157218966ac6ead\n'}]",0,77143,debbf5998dbc115918f59331c2b3989855890977,16,4,2,1669,,,0,"coordination: enhance MemberNotJoined

Change-Id: I51d599abee283ff8ba29ad68f157218966ac6ead
",git fetch https://review.opendev.org/openstack/tooz refs/changes/43/77143/1 && git format-patch -1 --stdout FETCH_HEAD,"['tooz/drivers/zookeeper.py', 'tooz/coordination.py']",2,339979cc50f30a58ae201c5acb71828bea55726d,jd/memcached," def __init__(self, group_id, member_id): self.group_id = group_id self.member_id = member_id super(MemberNotJoined, self).__init__(""Member %s has not joined %s"" % (member_id, group_id))",,8,12
openstack%2Ftooz~master~Iff02e1d1562ed01672a82327e8a06baa9fce1183,openstack/tooz,master,Iff02e1d1562ed01672a82327e8a06baa9fce1183,coordination: enhance GroupAlreadyExist exception,MERGED,2014-02-28 12:07:15.000000000,2014-03-06 14:04:24.000000000,2014-03-06 14:04:24.000000000,"[{'_account_id': 3}, {'_account_id': 1669}, {'_account_id': 7450}]","[{'number': 1, 'created': '2014-02-28 12:07:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tooz/commit/93a8706efe6a73d0ccd462c1465d6608e824d585', 'message': 'coordination: enhance GroupAlreadyExist exception\n\nChange-Id: Iff02e1d1562ed01672a82327e8a06baa9fce1183\n'}, {'number': 2, 'created': '2014-03-05 15:01:15.000000000', 'files': ['tooz/drivers/zookeeper.py', 'tooz/coordination.py'], 'web_link': 'https://opendev.org/openstack/tooz/commit/1eaaf96efe81b0cf596eba4414e60157ded1bf7a', 'message': 'coordination: enhance GroupAlreadyExist exception\n\nChange-Id: Iff02e1d1562ed01672a82327e8a06baa9fce1183\n'}]",0,77142,1eaaf96efe81b0cf596eba4414e60157ded1bf7a,12,3,2,1669,,,0,"coordination: enhance GroupAlreadyExist exception

Change-Id: Iff02e1d1562ed01672a82327e8a06baa9fce1183
",git fetch https://review.opendev.org/openstack/tooz refs/changes/42/77142/2 && git format-patch -1 --stdout FETCH_HEAD,"['tooz/drivers/zookeeper.py', 'tooz/coordination.py']",2,93a8706efe6a73d0ccd462c1465d6608e824d585,jd/memcached," def __init__(self, group_id): self.group_id = group_id super(GroupAlreadyExist, self).__init__( ""Group %s already exists"" % group_id)",,5,1
openstack%2Ftooz~master~I11d1ed137f94d3a025aa736fe5c9abcab3838980,openstack/tooz,master,I11d1ed137f94d3a025aa736fe5c9abcab3838980,tests: test capabilities on non existent group/member,MERGED,2014-02-28 12:07:15.000000000,2014-03-06 14:03:23.000000000,2014-03-06 14:03:23.000000000,"[{'_account_id': 3}, {'_account_id': 1669}, {'_account_id': 2813}, {'_account_id': 7450}, {'_account_id': 8122}, {'_account_id': 9107}]","[{'number': 1, 'created': '2014-02-28 12:07:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tooz/commit/284943258204462d245118922291cefda34c74ce', 'message': 'tests: test capabilities on non existent group/member\n\nChange-Id: I11d1ed137f94d3a025aa736fe5c9abcab3838980\n'}, {'number': 2, 'created': '2014-03-05 15:01:15.000000000', 'files': ['tooz/tests/test_coordination.py'], 'web_link': 'https://opendev.org/openstack/tooz/commit/7d10a838b9a3e79d3931441ce6dc1d72ddee080d', 'message': 'tests: test capabilities on non existent group/member\n\nChange-Id: I11d1ed137f94d3a025aa736fe5c9abcab3838980\n'}]",3,77141,7d10a838b9a3e79d3931441ce6dc1d72ddee080d,13,6,2,1669,,,0,"tests: test capabilities on non existent group/member

Change-Id: I11d1ed137f94d3a025aa736fe5c9abcab3838980
",git fetch https://review.opendev.org/openstack/tooz refs/changes/41/77141/2 && git format-patch -1 --stdout FETCH_HEAD,['tooz/tests/test_coordination.py'],1,284943258204462d245118922291cefda34c74ce,jd/memcached," def test_get_member_capabilities_nonexistent_group(self): capa = self._coord.get_member_capabilities(self.group_id, self.member_id) try: capa.get() # Drivers raise one of those depending on their capability except (tooz.coordination.MemberNotJoined, tooz.coordination.GroupNotCreated): pass else: self.fail(""Exception not raised"") def test_get_member_capabilities_nonjoined_member(self): self._coord.create_group(self.group_id).get() capa = self._coord.get_member_capabilities(self.group_id, self.member_id) self.assertRaises(tooz.coordination.MemberNotJoined, capa.get) ",,19,0
openstack%2Ftooz~master~I1993784769303eb206d8102dcd353d2e8d4102bb,openstack/tooz,master,I1993784769303eb206d8102dcd353d2e8d4102bb,tests: add a test for group already existing,MERGED,2014-02-28 12:07:15.000000000,2014-03-06 14:03:18.000000000,2014-03-06 14:03:18.000000000,"[{'_account_id': 3}, {'_account_id': 1669}, {'_account_id': 7450}, {'_account_id': 8122}, {'_account_id': 9107}]","[{'number': 1, 'created': '2014-02-28 12:07:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tooz/commit/db0c1042d0090c7833ecaec1464c3768440da41b', 'message': 'tests: add a test for group already existing\n\nChange-Id: I1993784769303eb206d8102dcd353d2e8d4102bb\n'}, {'number': 2, 'created': '2014-03-05 15:01:15.000000000', 'files': ['tooz/tests/test_coordination.py'], 'web_link': 'https://opendev.org/openstack/tooz/commit/06bce6b14575fa123bd46dfbf741795adf06a6c5', 'message': 'tests: add a test for group already existing\n\nChange-Id: I1993784769303eb206d8102dcd353d2e8d4102bb\n'}]",0,77140,06bce6b14575fa123bd46dfbf741795adf06a6c5,13,5,2,1669,,,0,"tests: add a test for group already existing

Change-Id: I1993784769303eb206d8102dcd353d2e8d4102bb
",git fetch https://review.opendev.org/openstack/tooz refs/changes/40/77140/2 && git format-patch -1 --stdout FETCH_HEAD,['tooz/tests/test_coordination.py'],1,db0c1042d0090c7833ecaec1464c3768440da41b,jd/memcached," def test_create_group_already_exist(self): self._coord.create_group(self.group_id).get() create_group = self._coord.create_group(self.group_id) self.assertRaises(tooz.coordination.GroupAlreadyExist, create_group.get) ",,6,0
openstack%2Fceilometer~stable%2Fhavana~Id28a0838330296fe030fa7c4a35a216dd3e64bad,openstack/ceilometer,stable/havana,Id28a0838330296fe030fa7c4a35a216dd3e64bad,cacert is not picked up correctly by alarm services,MERGED,2014-02-10 12:53:06.000000000,2014-03-06 13:56:21.000000000,2014-03-06 13:56:21.000000000,"[{'_account_id': 3}, {'_account_id': 1669}, {'_account_id': 1812}, {'_account_id': 1955}, {'_account_id': 2284}, {'_account_id': 2813}, {'_account_id': 2860}, {'_account_id': 6537}, {'_account_id': 6924}, {'_account_id': 8279}, {'_account_id': 9562}]","[{'number': 1, 'created': '2014-02-10 12:53:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/3e09d5631a6d8097d64f5aee651968077b40a5f5', 'message': 'cacert is not picked up correctly by alarm services\n\nrelated to bug 1266472 which changes client to look only at os_cacert arg.\nupdate alarm services to use just os_cacert as well.\n\nChange-Id: Id28a0838330296fe030fa7c4a35a216dd3e64bad\nCloses-Bug: #1266477\n(cherry picked from commit 89f9b3049ac7a395c470f8d323b44e8128e5b1b2)\n'}, {'number': 2, 'created': '2014-02-10 13:30:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/ad5a1a191104453f585f4c7630604a3a512b0d78', 'message': 'cacert is not picked up correctly by alarm services\n\nrelated to bug 1266472 which changes client to look only at os_cacert arg.\nupdate alarm services to use just os_cacert as well.\n\nChange-Id: Id28a0838330296fe030fa7c4a35a216dd3e64bad\nCloses-Bug: #1266477\n(cherry picked from commit 89f9b3049ac7a395c470f8d323b44e8128e5b1b2)\n'}, {'number': 3, 'created': '2014-02-13 17:14:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/a9051df00c5974782b064758262b94797a35ea2f', 'message': 'cacert is not picked up correctly by alarm services\n\nrelated to bug 1266472 which changes client to look only at os_cacert arg.\nupdate alarm services to use just os_cacert as well.\n\nChange-Id: Id28a0838330296fe030fa7c4a35a216dd3e64bad\nCloses-Bug: #1266477\n(cherry picked from commit 89f9b3049ac7a395c470f8d323b44e8128e5b1b2)\n'}, {'number': 4, 'created': '2014-02-14 09:07:57.000000000', 'files': ['ceilometer/alarm/evaluator/__init__.py', 'ceilometer/alarm/service.py'], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/ff0375c6935d3a84173d1fe159be6064015300fd', 'message': 'cacert is not picked up correctly by alarm services\n\nrelated to bug 1266472 which changes client to look only at os_cacert arg.\nupdate alarm services to use just os_cacert as well.\n\nChange-Id: Id28a0838330296fe030fa7c4a35a216dd3e64bad\nCloses-Bug: #1266477\n(cherry picked from commit 89f9b3049ac7a395c470f8d323b44e8128e5b1b2)\n'}]",0,72333,ff0375c6935d3a84173d1fe159be6064015300fd,48,11,4,2284,,,0,"cacert is not picked up correctly by alarm services

related to bug 1266472 which changes client to look only at os_cacert arg.
update alarm services to use just os_cacert as well.

Change-Id: Id28a0838330296fe030fa7c4a35a216dd3e64bad
Closes-Bug: #1266477
(cherry picked from commit 89f9b3049ac7a395c470f8d323b44e8128e5b1b2)
",git fetch https://review.opendev.org/openstack/ceilometer refs/changes/33/72333/2 && git format-patch -1 --stdout FETCH_HEAD,"['ceilometer/alarm/evaluator/__init__.py', 'ceilometer/alarm/service.py']",2,3e09d5631a6d8097d64f5aee651968077b40a5f5,," os_cacert=auth_config.os_cacert,"," cacert=auth_config.os_cacert,",2,2
openstack%2Fceilometer~stable%2Fhavana~I05cea4c79ad89d2c55008ea0d7ba9eefa5908fa2,openstack/ceilometer,stable/havana,I05cea4c79ad89d2c55008ea0d7ba9eefa5908fa2,Add an insecure option for Keystone client,MERGED,2014-02-10 12:53:06.000000000,2014-03-06 13:56:19.000000000,2014-03-06 13:56:19.000000000,"[{'_account_id': 3}, {'_account_id': 1669}, {'_account_id': 1812}, {'_account_id': 1955}, {'_account_id': 2284}, {'_account_id': 2860}, {'_account_id': 4491}, {'_account_id': 6537}, {'_account_id': 9562}]","[{'number': 1, 'created': '2014-02-10 12:53:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/90c01e753c50980814fb9e72b300f32564ea903f', 'message': 'Add an insecure option for Keystone client\n\nChange-Id: I05cea4c79ad89d2c55008ea0d7ba9eefa5908fa2\nCloses-Bug: #1232437\n(cherry picked from commit d48b4a3a4e5d0b80c3644844e0f1c8e3806c78d6)\n'}, {'number': 2, 'created': '2014-02-10 13:30:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/f587643f75ff7a46ae280c08731e4f8bf31b853a', 'message': 'Add an insecure option for Keystone client\n\nChange-Id: I05cea4c79ad89d2c55008ea0d7ba9eefa5908fa2\nCloses-Bug: #1232437\n(cherry picked from commit d48b4a3a4e5d0b80c3644844e0f1c8e3806c78d6)\n'}, {'number': 3, 'created': '2014-02-14 09:07:57.000000000', 'files': ['ceilometer/central/manager.py', 'ceilometer/service.py', 'etc/ceilometer/ceilometer.conf.sample'], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/0a85f225f7067e77ba7f24516e20a35588a280e5', 'message': 'Add an insecure option for Keystone client\n\nChange-Id: I05cea4c79ad89d2c55008ea0d7ba9eefa5908fa2\nCloses-Bug: #1232437\n(cherry picked from commit d48b4a3a4e5d0b80c3644844e0f1c8e3806c78d6)\n'}]",4,72332,0a85f225f7067e77ba7f24516e20a35588a280e5,43,9,3,2284,,,0,"Add an insecure option for Keystone client

Change-Id: I05cea4c79ad89d2c55008ea0d7ba9eefa5908fa2
Closes-Bug: #1232437
(cherry picked from commit d48b4a3a4e5d0b80c3644844e0f1c8e3806c78d6)
",git fetch https://review.opendev.org/openstack/ceilometer refs/changes/32/72332/2 && git format-patch -1 --stdout FETCH_HEAD,"['ceilometer/central/manager.py', 'ceilometer/service.py', 'etc/ceilometer/ceilometer.conf.sample']",3,90c01e753c50980814fb9e72b300f32564ea903f,,# Does not perform X.509 certificate validation # whenestablishing SSL connection with identity service. # (boolean value) #insecure=false ,,11,1
openstack%2Fnova~master~I788e33dbcb3dedc41831b976137607274b1c02ca,openstack/nova,master,I788e33dbcb3dedc41831b976137607274b1c02ca,VMware: create datastore utility functions,MERGED,2013-12-24 14:58:13.000000000,2014-03-06 13:50:02.000000000,2014-03-06 13:49:58.000000000,"[{'_account_id': 3}, {'_account_id': 1653}, {'_account_id': 1779}, {'_account_id': 1849}, {'_account_id': 2750}, {'_account_id': 4393}, {'_account_id': 4395}, {'_account_id': 5170}, {'_account_id': 5511}, {'_account_id': 7400}, {'_account_id': 7575}, {'_account_id': 7629}, {'_account_id': 8027}, {'_account_id': 8119}, {'_account_id': 9008}, {'_account_id': 9172}, {'_account_id': 9555}, {'_account_id': 9578}]","[{'number': 1, 'created': '2013-12-24 14:58:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/04c112647f32206d04f7d99a2ea547672ff2e533', 'message': 'VMware: create datastore utility functions\n\nThe patch moves datastore interfaces from vmops and vm_util\nto a separate file - ds_util.\n\nThis is part of the blueprint vmware-image-cache-management.\n\nChange-Id: I788e33dbcb3dedc41831b976137607274b1c02ca\n'}, {'number': 2, 'created': '2013-12-25 15:42:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/64ad7024e5093528a7b67c3abf3800497baa9dc9', 'message': 'VMware: create datastore utility functions\n\nThe patch moves datastore interfaces from vmops and vm_util\nto a separate file - ds_util.\n\nThis is part of the blueprint vmware-image-cache-management.\n\nChange-Id: I788e33dbcb3dedc41831b976137607274b1c02ca\n'}, {'number': 3, 'created': '2013-12-26 10:53:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/25f602bf1714355e22700d35306e000d45ef8966', 'message': 'VMware: create datastore utility functions\n\nThe patch moves datastore interfaces from vmops and vm_util\nto a separate file - ds_util.\n\nThis is part of the blueprint vmware-image-cache-management.\n\nThe patch set also solves the following bugs:\n\nCloses-bug: 1230047\nCloses-bug: 1254128\n\nChange-Id: I788e33dbcb3dedc41831b976137607274b1c02ca\n'}, {'number': 4, 'created': '2013-12-26 11:45:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/266735007121b4821881d53b067f1b400369fb98', 'message': 'VMware: create datastore utility functions\n\nThe patch moves datastore interfaces from vmops and vm_util\nto a separate file - ds_util.\n\nThis is part of the blueprint vmware-image-cache-management.\n\nThe patch set also solves the following bugs:\n\nCloses-bug: 1230047\nCloses-bug: 1254128\n\nChange-Id: I788e33dbcb3dedc41831b976137607274b1c02ca\n'}, {'number': 5, 'created': '2014-01-08 11:44:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/b41ecbe35b561c72380c64122f8a17f2785152ec', 'message': 'VMware: create datastore utility functions\n\nThe patch moves datastore interfaces from vmops and vm_util\nto a separate file - ds_util.\n\nThis is part of the blueprint vmware-image-cache-management.\n\nThe patch set also solves the following bugs:\n\nCloses-bug: 1230047\nCloses-bug: 1254128\n\nChange-Id: I788e33dbcb3dedc41831b976137607274b1c02ca\n'}, {'number': 6, 'created': '2014-01-08 12:40:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/a33c27e1b543f80cfe28fd07e6a7ec3e684e0152', 'message': 'VMware: create datastore utility functions\n\nThe patch moves datastore interfaces from vmops and vm_util\nto a separate file - ds_util.\n\nThis is part of the blueprint vmware-image-cache-management.\n\nThe patch set also solves the following bugs:\n\nCloses-bug: 1230047\nCloses-bug: 1254128\n\nChange-Id: I788e33dbcb3dedc41831b976137607274b1c02ca\n'}, {'number': 7, 'created': '2014-01-08 12:40:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/91ff1d9e90275888dc4e5a3f863909ca3450409d', 'message': 'VMware: create datastore utility functions\n\nThe patch moves datastore interfaces from vmops and vm_util\nto a separate file - ds_util.\n\nThis is part of the blueprint vmware-image-cache-management.\n\nThe patch set also solves the following bugs:\n\nCloses-bug: 1230047\nCloses-bug: 1254128\n\nChange-Id: I788e33dbcb3dedc41831b976137607274b1c02ca\n'}, {'number': 8, 'created': '2014-01-16 11:16:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/e9cfb60ac40051a6651f2be2f4ae9db029dafeef', 'message': 'VMware: create datastore utility functions\n\nThe patch moves datastore interfaces from vmops and vm_util\nto a separate file - ds_util.\n\nThis is part of the blueprint vmware-image-cache-management.\n\nThe patch set also solves the following bugs:\n\nCloses-bug: 1230047\nCloses-bug: 1254128\n\nChange-Id: I788e33dbcb3dedc41831b976137607274b1c02ca\n'}, {'number': 9, 'created': '2014-01-16 11:16:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/5a4b756d5a1b3806ac35fc9980b3067eb2760366', 'message': 'VMware: create datastore utility functions\n\nThe patch moves datastore interfaces from vmops and vm_util\nto a separate file - ds_util.\n\nThis is part of the blueprint vmware-image-cache-management.\n\nThe patch set also solves the following bugs:\n\nCloses-bug: 1230047\nCloses-bug: 1254128\n\nChange-Id: I788e33dbcb3dedc41831b976137607274b1c02ca\n'}, {'number': 10, 'created': '2014-02-03 08:13:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/f9d5e7bde37fc6a3f617a309bb404bf663b8fc28', 'message': 'VMware: create datastore utility functions\n\nThe patch moves datastore interfaces from vmops and vm_util\nto a separate file - ds_util.\n\nThis is part of the blueprint vmware-image-cache-management.\n\nThe patch set also solves the following bugs:\n\nCloses-bug: 1230047\nCloses-bug: 1254128\n\nChange-Id: I788e33dbcb3dedc41831b976137607274b1c02ca\n'}, {'number': 11, 'created': '2014-02-05 10:35:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/369ccdd6cba18f9a21e4ab70d4c08f18c5c261bc', 'message': 'VMware: create datastore utility functions\n\nThe patch moves datastore interfaces from vmops and vm_util\nto a separate file - ds_util.\n\nThis is part of the blueprint vmware-image-cache-management.\n\nThe patch set also solves the following bugs:\n\nCloses-bug: 1230047\nCloses-bug: 1254128\n\nChange-Id: I788e33dbcb3dedc41831b976137607274b1c02ca\n'}, {'number': 12, 'created': '2014-02-05 11:21:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/22269d532094fc33cf67fb4b9973fb134fce76d9', 'message': 'VMware: create datastore utility functions\n\nThe patch moves datastore interfaces from vmops and vm_util\nto a separate file - ds_util.\n\nThis is part of the blueprint vmware-image-cache-management.\n\nThe patch set also solves the following bugs:\n\nCloses-bug: 1230047\nCloses-bug: 1254128\n\nChange-Id: I788e33dbcb3dedc41831b976137607274b1c02ca\n'}, {'number': 13, 'created': '2014-02-05 11:43:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/1af2036c6125d957c987269b35d8c7b357f0c39e', 'message': 'VMware: create datastore utility functions\n\nThe patch moves datastore interfaces from vmops and vm_util\nto a separate file - ds_util.\n\nThis is part of the blueprint vmware-image-cache-management.\n\nThe patch set also solves the following bugs:\n\nCloses-bug: 1230047\nCloses-bug: 1254128\n\nChange-Id: I788e33dbcb3dedc41831b976137607274b1c02ca\n'}, {'number': 14, 'created': '2014-02-05 12:42:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/004bcb2daf769b9460503d39a456effe004f1b91', 'message': 'VMware: create datastore utility functions\n\nThe patch moves datastore interfaces from vmops and vm_util\nto a separate file - ds_util.\n\nThis is part of the blueprint vmware-image-cache-management.\n\nThe patch set also solves the following bugs:\n\nCloses-bug: 1230047\nCloses-bug: 1254128\n\nChange-Id: I788e33dbcb3dedc41831b976137607274b1c02ca\n'}, {'number': 15, 'created': '2014-02-06 07:51:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/17db7cbb86b34228579b8703be75ed6b00f88e3c', 'message': 'VMware: create datastore utility functions\n\nThe patch moves datastore interfaces from vmops and vm_util\nto a separate file - ds_util.\n\nThis is part of the blueprint vmware-image-cache-management.\n\nThe patch set also solves the following bugs:\n\nCloses-bug: 1230047\nCloses-bug: 1254128\n\nChange-Id: I788e33dbcb3dedc41831b976137607274b1c02ca\n'}, {'number': 16, 'created': '2014-02-06 14:44:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/86e56a5de6a950cfc8743a5fe7806bdf9b288085', 'message': 'VMware: create datastore utility functions\n\nThe patch moves datastore interfaces from vmops and vm_util\nto a separate file - ds_util.\n\nThis is part of the blueprint vmware-image-cache-management.\n\nThe patch set also solves the following bugs:\n\nCloses-bug: 1230047\nCloses-bug: 1254128\n\nChange-Id: I788e33dbcb3dedc41831b976137607274b1c02ca\n'}, {'number': 17, 'created': '2014-02-06 15:01:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/65099774851b998b154692f5f045a2cb9348c183', 'message': 'VMware: create datastore utility functions\n\nThe patch moves datastore interfaces from vmops and vm_util\nto a separate file - ds_util.\n\nThis is part of the blueprint vmware-image-cache-management.\n\nThe patch set also solves the following bugs:\n\nCloses-bug: 1230047\nCloses-bug: 1254128\n\nChange-Id: I788e33dbcb3dedc41831b976137607274b1c02ca\n'}, {'number': 18, 'created': '2014-02-07 13:43:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/99348c4ef03950c72d14de4498e9543755bf7a6d', 'message': 'VMware: create datastore utility functions\n\nThe patch moves datastore interfaces from vmops and vm_util\nto a separate file - ds_util.\n\nThis is part of the blueprint vmware-image-cache-management.\n\nThe patch set also solves the following bugs:\n\nCloses-bug: 1230047\nCloses-bug: 1254128\n\nChange-Id: I788e33dbcb3dedc41831b976137607274b1c02ca\n'}, {'number': 19, 'created': '2014-02-09 07:32:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/3b94fa9c3306c5b0d98893ffea899bdb1b83a523', 'message': 'VMware: create datastore utility functions\n\nThe patch moves datastore interfaces from vmops and vm_util\nto a separate file - ds_util.\n\nThis is part of the blueprint vmware-image-cache-management.\n\nThe patch set also solves the following bugs:\n\nCloses-bug: 1230047\nCloses-bug: 1254128\n\nChange-Id: I788e33dbcb3dedc41831b976137607274b1c02ca\n'}, {'number': 20, 'created': '2014-02-09 12:38:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/e516376878e4ee6b917a66a8edf79356c3367f26', 'message': 'VMware: create datastore utility functions\n\nThe patch moves datastore interfaces from vmops and vm_util\nto a separate file - ds_util.\n\nThis is part of the blueprint vmware-image-cache-management.\n\nThe patch set also solves the following bugs:\n\nCloses-bug: 1230047\nCloses-bug: 1254128\n\nChange-Id: I788e33dbcb3dedc41831b976137607274b1c02ca\n'}, {'number': 21, 'created': '2014-02-09 13:53:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/b6b362ed24361531568adbecbc82d7e2f57cdc16', 'message': 'VMware: create datastore utility functions\n\nThe patch moves datastore interfaces from vmops and vm_util\nto a separate file - ds_util.\n\nThis is part of the blueprint vmware-image-cache-management.\n\nThe patch set also solves the following bugs:\n\nCloses-bug: 1230047\nCloses-bug: 1254128\n\nChange-Id: I788e33dbcb3dedc41831b976137607274b1c02ca\n'}, {'number': 22, 'created': '2014-02-11 09:32:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/8509646fbcacdc93606c580d87984596eff044ff', 'message': 'VMware: create datastore utility functions\n\nThe patch moves datastore interfaces from vmops and vm_util\nto a separate file - ds_util.\n\nThis is part of the blueprint vmware-image-cache-management.\n\nThe patch set also solves the following bugs:\n\nCloses-bug: 1230047\nCloses-bug: 1254128\n\nChange-Id: I788e33dbcb3dedc41831b976137607274b1c02ca\n'}, {'number': 23, 'created': '2014-02-11 09:35:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/b5cd6ce589703eef6bf8804027bb6e8a926da7e8', 'message': 'VMware: create datastore utility functions\n\nThe patch moves datastore interfaces from vmops and vm_util\nto a separate file - ds_util.\n\nThis is part of the blueprint vmware-image-cache-management.\n\nThe patch set also solves the following bugs:\n\nCloses-bug: 1230047\nCloses-bug: 1254128\n\nChange-Id: I788e33dbcb3dedc41831b976137607274b1c02ca\n'}, {'number': 24, 'created': '2014-02-11 15:57:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/39ecaf22435f77dfcaad7c0c9e59098d23b8f9ed', 'message': 'VMware: create datastore utility functions\n\nThe patch moves datastore interfaces from vmops and vm_util\nto a separate file - ds_util.\n\nThis is part of the blueprint vmware-image-cache-management.\n\nThe patch set also solves the following bugs:\n\nCloses-bug: 1230047\nCloses-bug: 1254128\n\nChange-Id: I788e33dbcb3dedc41831b976137607274b1c02ca\n'}, {'number': 25, 'created': '2014-02-12 10:17:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/e77cb3cb6558f6629d1a83f4bf2db782248bee86', 'message': 'VMware: create datastore utility functions\n\nThe patch moves datastore interfaces from vmops and vm_util\nto a separate file - ds_util.\n\nThis is part of the blueprint vmware-image-cache-management.\n\nThe patch set also solves the following bugs:\n\nCloses-bug: 1230047\nCloses-bug: 1254128\n\nChange-Id: I788e33dbcb3dedc41831b976137607274b1c02ca\n'}, {'number': 26, 'created': '2014-02-14 08:18:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/3c8c46fd41ea8c2130d1bbb550a31b7694b9a13e', 'message': 'VMware: create datastore utility functions\n\nThe patch moves datastore interfaces from vmops and vm_util\nto a separate file - ds_util.\n\nThis is part of the blueprint vmware-image-cache-management.\n\nThe patch set also solves the following bugs:\n\nCloses-bug: 1230047\nCloses-bug: 1254128\n\nChange-Id: I788e33dbcb3dedc41831b976137607274b1c02ca\n'}, {'number': 27, 'created': '2014-02-15 12:13:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/211e2bc7c9c2f4ada9d317b934a732180796532e', 'message': 'VMware: create datastore utility functions\n\nThe patch moves datastore interfaces from vmops and vm_util\nto a separate file - ds_util.\n\nThis is part of the blueprint vmware-image-cache-management.\n\nThe patch set also solves the following bugs:\n\nCloses-bug: 1230047\nCloses-bug: 1254128\n\nChange-Id: I788e33dbcb3dedc41831b976137607274b1c02ca\n'}, {'number': 28, 'created': '2014-02-17 08:37:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/045a31c600b7c1f379053f0461d8823c49ed42ba', 'message': 'VMware: create datastore utility functions\n\nThe patch moves datastore interfaces from vmops and vm_util\nto a separate file - ds_util.\n\nThis is part of the blueprint vmware-image-cache-management.\n\nThe patch set also solves the following bugs:\n\nCloses-bug: 1230047\nCloses-bug: 1254128\n\nChange-Id: I788e33dbcb3dedc41831b976137607274b1c02ca\n'}, {'number': 29, 'created': '2014-02-18 07:44:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/193410443e39cb951076af040da22be890632d96', 'message': 'VMware: create datastore utility functions\n\nThe patch moves datastore interfaces from vmops and vm_util\nto a separate file - ds_util.\n\nThis is part of the blueprint vmware-image-cache-management.\n\nIn the past the datastore methods would poll the task\nto deteremine that it had completed. This has beem addressed by\nmaking the driver _poll_task return the task information.\n\nThe patch set also solves the following bugs by checking if\nthe FileAlreadyExistsException exception is raised. The could be\ndue to another process or thread creating the file.\n\nCloses-bug: 1230047\nCloses-bug: 1254128\n\nChange-Id: I788e33dbcb3dedc41831b976137607274b1c02ca\n'}, {'number': 30, 'created': '2014-02-18 12:59:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/cff7cbf89c9a43fcd37401b95d559ddcd1b27894', 'message': 'VMware: create datastore utility functions\n\nThe patch moves datastore interfaces from vmops and vm_util\nto a separate file - ds_util.\n\nThis is part of the blueprint vmware-image-cache-management.\n\nIn the past the datastore methods would poll the task\nto deteremine that it had completed. This has beem addressed by\nmaking the driver _poll_task return the task information.\n\nThe patch set also solves the following bugs by checking if\nthe FileAlreadyExistsException exception is raised. The could be\ndue to another process or thread creating the file.\n\nCloses-bug: 1230047\nCloses-bug: 1254128\n\nChange-Id: I788e33dbcb3dedc41831b976137607274b1c02ca\n'}, {'number': 31, 'created': '2014-02-18 14:26:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/2c094290fbbb22c258f08d26eaa6b10db5e39909', 'message': 'VMware: create datastore utility functions\n\nThe patch moves datastore interfaces from vmops and vm_util\nto a separate file - ds_util.\n\nThis is part of the blueprint vmware-image-cache-management.\n\nIn the past the datastore methods would poll the task\nto deteremine that it had completed. This has beem addressed by\nmaking the driver _poll_task return the task information.\n\nThe patch set also solves the following bugs by checking if\nthe FileAlreadyExistsException exception is raised. The could be\ndue to another process or thread creating the file.\n\nCloses-bug: 1230047\nCloses-bug: 1254128\n\nChange-Id: I788e33dbcb3dedc41831b976137607274b1c02ca\n'}, {'number': 32, 'created': '2014-02-23 09:21:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/b8114ec369509c8bd884ca368db437e8d416ef27', 'message': 'VMware: create datastore utility functions\n\nThe patch moves datastore interfaces from vmops and vm_util\nto a separate file - ds_util.\n\nThis is part of the blueprint vmware-image-cache-management.\n\nIn the past the datastore methods would poll the task\nto determine that it had completed. This has beem addressed by\nmaking the driver _poll_task return the task information.\n\nThe patch set also solves the following bugs by checking if\nthe FileAlreadyExistsException exception is raised. The could be\ndue to another process or thread creating the file.\n\nCloses-bug: 1230047\nCloses-bug: 1254128\n\nChange-Id: I788e33dbcb3dedc41831b976137607274b1c02ca\n'}, {'number': 33, 'created': '2014-02-24 10:16:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/4e3c146e61d70fb640d660cffa12fdc8b84f6e97', 'message': 'VMware: create datastore utility functions\n\nThe patch moves datastore interfaces from vmops and vm_util\nto a separate file - ds_util.\n\nThis is part of the blueprint vmware-image-cache-management.\n\nIn the past the datastore methods would poll the task\nto determine that it had completed. This has beem addressed by\nmaking the driver _poll_task return the task information.\n\nThe patch set also solves the following bugs by checking if\nthe FileAlreadyExistsException exception is raised. The could be\ndue to another process or thread creating the file.\n\nCloses-bug: 1230047\nCloses-bug: 1254128\n\nChange-Id: I788e33dbcb3dedc41831b976137607274b1c02ca\n'}, {'number': 34, 'created': '2014-02-24 16:34:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/7683a872cbd43a970d5a53f435ff581b5068647a', 'message': 'VMware: create datastore utility functions\n\nThe patch moves datastore interfaces from vmops and vm_util\nto a separate file - ds_util.\n\nThis is part of the blueprint vmware-image-cache-management.\n\nIn the past the datastore methods would poll the task\nto determine that it had completed. This has beem addressed by\nmaking the driver _poll_task return the task information.\n\nThe patch set also solves the following bugs by checking if\nthe FileAlreadyExistsException exception is raised. The could be\ndue to another process or thread creating the file.\n\nCloses-bug: 1230047\nCloses-bug: 1254128\n\nChange-Id: I788e33dbcb3dedc41831b976137607274b1c02ca\n'}, {'number': 35, 'created': '2014-02-25 09:53:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/6329765f585d59eb8c45c0651d13194e7d790ed7', 'message': 'VMware: create datastore utility functions\n\nThe patch moves datastore interfaces from vmops and vm_util\nto a separate file - ds_util.\n\nThis is part of the blueprint vmware-image-cache-management.\n\nIn the past the datastore methods would poll the task\nto determine that it had completed. This has beem addressed by\nmaking the driver _poll_task return the task information.\n\nThe patch set also solves the following bugs by checking if\nthe FileAlreadyExistsException exception is raised. The could be\ndue to another process or thread creating the file.\n\nCloses-bug: 1230047\nCloses-bug: 1254128\n\nChange-Id: I788e33dbcb3dedc41831b976137607274b1c02ca\n'}, {'number': 36, 'created': '2014-02-25 09:59:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/d4e18ba75673a53a67f1a692c3a8551c191d9690', 'message': 'VMware: create datastore utility functions\n\nThe patch moves datastore interfaces from vmops and vm_util\nto a separate file - ds_util.\n\nThis is part of the blueprint vmware-image-cache-management.\n\nIn the past the datastore methods would poll the task\nto determine that it had completed. This has beem addressed by\nmaking the driver _poll_task return the task information.\n\nThe patch set also solves the following bugs by checking if\nthe FileAlreadyExistsException exception is raised. The could be\ndue to another process or thread creating the file.\n\nCloses-bug: 1230047\nCloses-bug: 1254128\n\nChange-Id: I788e33dbcb3dedc41831b976137607274b1c02ca\n'}, {'number': 37, 'created': '2014-02-25 14:24:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/492f86ab50f549298b8c1242df35d90145987657', 'message': 'VMware: create datastore utility functions\n\nThe patch moves datastore interfaces from vmops and vm_util\nto a separate file - ds_util.\n\nThis is part of the blueprint vmware-image-cache-management.\n\nIn the past the datastore methods would poll the task\nto determine that it had completed. This has beem addressed by\nmaking the driver _poll_task return the task information.\n\nThe patch set also solves the following bugs by checking if\nthe FileAlreadyExistsException exception is raised. The could be\ndue to another process or thread creating the file.\n\nCloses-bug: 1230047\nCloses-bug: 1254128\n\nChange-Id: I788e33dbcb3dedc41831b976137607274b1c02ca\n'}, {'number': 38, 'created': '2014-02-27 09:20:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/12fb466e496bf6ccd02ce3ab8112640d7775a021', 'message': 'VMware: create datastore utility functions\n\nThe patch moves datastore interfaces from vmops and vm_util\nto a separate file - ds_util.\n\nThis is part of the blueprint vmware-image-cache-management.\n\nIn the past the datastore methods would poll the task\nto determine that it had completed. This has beem addressed by\nmaking the driver _poll_task return the task information.\n\nThe patch set also solves the following bugs by checking if\nthe FileAlreadyExistsException exception is raised. The could be\ndue to another process or thread creating the file.\n\nCloses-bug: 1230047\nCloses-bug: 1254128\n\nChange-Id: I788e33dbcb3dedc41831b976137607274b1c02ca\n'}, {'number': 39, 'created': '2014-02-27 09:26:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/d97c6c32b633f978ff9f834e1aa95e77d2cd790c', 'message': 'VMware: create datastore utility functions\n\nThe patch moves datastore interfaces from vmops and vm_util\nto a separate file - ds_util.\n\nThis is part of the blueprint vmware-image-cache-management.\n\nIn the past the datastore methods would poll the task\nto determine that it had completed. This has beem addressed by\nmaking the driver _poll_task return the task information.\n\nThe patch set also solves the following bugs by checking if\nthe FileAlreadyExistsException exception is raised. The could be\ndue to another process or thread creating the file.\n\nCloses-bug: 1230047\nCloses-bug: 1254128\n\nChange-Id: I788e33dbcb3dedc41831b976137607274b1c02ca\n'}, {'number': 40, 'created': '2014-02-27 09:37:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/a20d739acad3a1ba46e10d84c6db7e93a5d5f467', 'message': 'VMware: create datastore utility functions\n\nThe patch moves datastore interfaces from vmops and vm_util\nto a separate file - ds_util.\n\nThis is part of the blueprint vmware-image-cache-management.\n\nIn the past the datastore methods would poll the task\nto determine that it had completed. This has beem addressed by\nmaking the driver _poll_task return the task information.\n\nThe patch set also solves the following bugs by checking if\nthe FileAlreadyExistsException exception is raised. The could be\ndue to another process or thread creating the file.\n\nCloses-bug: 1230047\nCloses-bug: 1254128\n\nChange-Id: I788e33dbcb3dedc41831b976137607274b1c02ca\n'}, {'number': 41, 'created': '2014-02-27 09:49:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/71e6e4a6d9df36711a962ce4d42351bcf9beb8ab', 'message': 'VMware: create datastore utility functions\n\nThe patch moves datastore interfaces from vmops and vm_util\nto a separate file - ds_util.\n\nThis is part of the blueprint vmware-image-cache-management.\n\nIn the past the datastore methods would poll the task\nto determine that it had completed. This has beem addressed by\nmaking the driver _poll_task return the task information.\n\nThe patch set also solves the following bugs by checking if\nthe FileAlreadyExistsException exception is raised. This could\nbe due to another process or thread creating the file.\n\nCloses-bug: 1230047\nCloses-bug: 1254128\n\nChange-Id: I788e33dbcb3dedc41831b976137607274b1c02ca\n'}, {'number': 42, 'created': '2014-02-27 10:38:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/e97510acf78931f37ce3ac01b8a0184ba3907375', 'message': 'VMware: create datastore utility functions\n\nThe patch moves datastore interfaces from vmops and vm_util\nto a separate file - ds_util.\n\nThis is part of the blueprint vmware-image-cache-management.\n\nIn the past the datastore methods would poll the task\nto determine that it had completed. This has beem addressed by\nmaking the driver _poll_task return the task information.\n\nThe patch set also solves the following bugs by checking if\nthe FileAlreadyExistsException exception is raised. This could\nbe due to another process or thread creating the file.\n\nCloses-bug: 1230047\nCloses-bug: 1254128\n\nChange-Id: I788e33dbcb3dedc41831b976137607274b1c02ca\n'}, {'number': 43, 'created': '2014-02-27 15:22:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/c29ca52444820c5a6ce641ecdf2c2f316117ebf5', 'message': 'VMware: create datastore utility functions\n\nThe patch moves datastore interfaces from vmops and vm_util\nto a separate file - ds_util.\n\nThis is part of the blueprint vmware-image-cache-management.\n\nIn the past the datastore methods would poll the task\nto determine that it had completed. This has beem addressed by\nmaking the driver _poll_task return the task information.\n\nThe patch set also solves the following bugs by checking if\nthe FileAlreadyExistsException exception is raised. This could\nbe due to another process or thread creating the file.\n\nCloses-bug: 1230047\nCloses-bug: 1254128\n\nChange-Id: I788e33dbcb3dedc41831b976137607274b1c02ca\n'}, {'number': 44, 'created': '2014-02-27 15:29:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/fc9173920ae86e8e589ad79c601e2fa7ae00cbd4', 'message': 'VMware: create datastore utility functions\n\nThe patch moves datastore interfaces from vmops and vm_util\nto a separate file - ds_util.\n\nThis is part of the blueprint vmware-image-cache-management.\n\nIn the past the datastore methods would poll the task\nto determine that it had completed. This has beem addressed by\nmaking the driver _poll_task return the task information.\n\nThe patch set also solves the following bugs by checking if\nthe FileAlreadyExistsException exception is raised. This could\nbe due to another process or thread creating the file.\n\nCloses-bug: 1230047\nCloses-bug: 1254128\n\nChange-Id: I788e33dbcb3dedc41831b976137607274b1c02ca\n'}, {'number': 45, 'created': '2014-03-01 06:31:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/b526fc5318af435d802543e1d69b3404c7c06760', 'message': 'VMware: create datastore utility functions\n\nThe patch moves datastore interfaces from vmops and vm_util\nto a separate file - ds_util.\n\nThis is part of the blueprint vmware-image-cache-management.\n\nIn the past the datastore methods would poll the task\nto determine that it had completed. This has beem addressed by\nmaking the driver _poll_task return the task information.\n\nThe patch set also solves the following bugs by checking if\nthe FileAlreadyExistsException exception is raised. This could\nbe due to another process or thread creating the file.\n\nCloses-bug: 1230047\nCloses-bug: 1254128\n\nChange-Id: I788e33dbcb3dedc41831b976137607274b1c02ca\n'}, {'number': 46, 'created': '2014-03-03 19:28:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/4ae9447c5429068c22f4c49a8a975e0537c1fd51', 'message': 'VMware: create datastore utility functions\n\nThe patch moves datastore interfaces from vmops and vm_util\nto a separate file - ds_util.\n\nThis is part of the blueprint vmware-image-cache-management.\n\nIn the past the datastore methods would poll the task\nto determine that it had completed. This has beem addressed by\nmaking the driver _poll_task return the task information.\n\nThe patch set also solves the following bugs by checking if\nthe FileAlreadyExistsException exception is raised. This could\nbe due to another process or thread creating the file.\n\nCloses-bug: 1230047\nCloses-bug: 1254128\n\nChange-Id: I788e33dbcb3dedc41831b976137607274b1c02ca\n'}, {'number': 47, 'created': '2014-03-04 20:33:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/5892476174cccdb71bcda540b3adafd1bd5c2ea5', 'message': 'VMware: create datastore utility functions\n\nThe patch moves datastore interfaces from vmops and vm_util\nto a separate file - ds_util.\n\nThis is part of the blueprint vmware-image-cache-management.\n\nIn the past the datastore methods would poll the task\nto determine that it had completed. This has beem addressed by\nmaking the driver _poll_task return the task information.\n\nThe patch set also solves the following bugs by checking if\nthe FileAlreadyExistsException exception is raised. This could\nbe due to another process or thread creating the file.\n\nCloses-bug: 1230047\nCloses-bug: 1254128\n\nChange-Id: I788e33dbcb3dedc41831b976137607274b1c02ca\n'}, {'number': 48, 'created': '2014-03-04 22:52:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/277bf33d3045111df15ca478dfe812e6fa1ddfb2', 'message': 'VMware: create datastore utility functions\n\nThe patch moves datastore interfaces from vmops and vm_util\nto a separate file - ds_util.\n\nThis is part of the blueprint vmware-image-cache-management.\n\nIn the past the datastore methods would poll the task\nto determine that it had completed. This has beem addressed by\nmaking the driver _poll_task return the task information.\n\nThe patch set also solves the following bugs by checking if\nthe FileAlreadyExistsException exception is raised. This could\nbe due to another process or thread creating the file.\n\nCloses-bug: 1230047\nCloses-bug: 1254128\n\nChange-Id: I788e33dbcb3dedc41831b976137607274b1c02ca\n'}, {'number': 49, 'created': '2014-03-05 00:06:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/e5d92952cbc2f290673871efb0e32d1681854010', 'message': 'VMware: create datastore utility functions\n\nThe patch moves datastore interfaces from vmops and vm_util\nto a separate file - ds_util.\n\nThis is part of the blueprint vmware-image-cache-management.\n\nIn the past the datastore methods would poll the task\nto determine that it had completed. This has beem addressed by\nmaking the driver _poll_task return the task information.\n\nThe patch set also solves the following bugs by checking if\nthe FileAlreadyExistsException exception is raised. This could\nbe due to another process or thread creating the file.\n\nCloses-bug: 1230047\nCloses-bug: 1254128\n\nChange-Id: I788e33dbcb3dedc41831b976137607274b1c02ca\n'}, {'number': 50, 'created': '2014-03-05 17:09:19.000000000', 'files': ['nova/virt/vmwareapi/vmops.py', 'nova/virt/vmwareapi/ds_util.py', 'nova/tests/virt/vmwareapi/test_ds_util.py', 'nova/virt/vmwareapi/driver.py', 'nova/tests/virt/vmwareapi/test_vmops.py', 'nova/virt/vmwareapi/fake.py', 'nova/virt/vmwareapi/vm_util.py', 'nova/tests/virt/vmwareapi/test_driver_api.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/bf882fbc4aa68cf0191bce70e622d81969617c02', 'message': 'VMware: create datastore utility functions\n\nThe patch moves datastore interfaces from vmops and vm_util\nto a separate file - ds_util.\n\nThis is part of the blueprint vmware-image-cache-management.\n\nIn the past the datastore methods would poll the task\nto determine that it had completed. This has beem addressed by\nmaking the driver _poll_task return the task information.\n\nThe patch set also solves the following bugs by checking if\nthe FileAlreadyExistsException exception is raised. This could\nbe due to another process or thread creating the file.\n\nCloses-bug: 1230047\nCloses-bug: 1254128\n\nChange-Id: I788e33dbcb3dedc41831b976137607274b1c02ca\n'}]",109,63933,bf882fbc4aa68cf0191bce70e622d81969617c02,335,18,50,1653,,,0,"VMware: create datastore utility functions

The patch moves datastore interfaces from vmops and vm_util
to a separate file - ds_util.

This is part of the blueprint vmware-image-cache-management.

In the past the datastore methods would poll the task
to determine that it had completed. This has beem addressed by
making the driver _poll_task return the task information.

The patch set also solves the following bugs by checking if
the FileAlreadyExistsException exception is raised. This could
be due to another process or thread creating the file.

Closes-bug: 1230047
Closes-bug: 1254128

Change-Id: I788e33dbcb3dedc41831b976137607274b1c02ca
",git fetch https://review.opendev.org/openstack/nova refs/changes/33/63933/1 && git format-patch -1 --stdout FETCH_HEAD,"['nova/virt/vmwareapi/vmops.py', 'nova/virt/vmwareapi/ds_util.py', 'nova/tests/virt/vmwareapi/test_vmwareapi.py', 'nova/tests/virt/vmwareapi/test_ds_util.py', 'nova/virt/vmwareapi/vm_util.py']",5,04c112647f32206d04f7d99a2ea547672ff2e533,bp/vmware-image-cache-management,,"def build_datastore_path(datastore_name, path): """"""Build the datastore compliant path."""""" return ""[%s] %s"" % (datastore_name, path) def split_datastore_path(datastore_path): """""" Split the VMware style datastore path to get the Datastore name and the entity path. """""" spl = datastore_path.split('[', 1)[1].split(']', 1) path = """" if len(spl) == 1: datastore_url = spl[0] else: datastore_url, path = spl return datastore_url, path.strip() ",415,157
openstack%2Fheat~master~Ie15958f91b6b80b4a3f0b73943345b7d27566077,openstack/heat,master,Ie15958f91b6b80b4a3f0b73943345b7d27566077,heat_keystoneclient add delete_stack_domain_user_keypair,MERGED,2014-02-07 15:51:29.000000000,2014-03-06 13:06:03.000000000,2014-03-06 13:06:02.000000000,"[{'_account_id': 3}, {'_account_id': 3098}, {'_account_id': 4328}, {'_account_id': 4330}, {'_account_id': 4571}, {'_account_id': 7135}, {'_account_id': 7385}]","[{'number': 1, 'created': '2014-02-07 15:51:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/608cf605408d84aa6988f4d3547413af1b7be389', 'message': 'heat_keystoneclient add delete_stack_domain_user_keypair\n\nAdds function to delete a credential containing a keypair, since we\ndo this as admin we also sanity check to ensure the user associated\nis a stack domain user, if not we should fall back to the non-admin\npath\n\nChange-Id: Ie15958f91b6b80b4a3f0b73943345b7d27566077\nblueprint: instance-users\n'}, {'number': 2, 'created': '2014-02-07 16:04:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/f024546a33b9ab83671d0a62158cf272d8be53e9', 'message': 'heat_keystoneclient add delete_stack_domain_user_keypair\n\nAdds function to delete a credential containing a keypair, since we\ndo this as admin we also sanity check to ensure the user associated\nis a stack domain user, if not we should fall back to the non-admin\npath\n\nChange-Id: Ie15958f91b6b80b4a3f0b73943345b7d27566077\nblueprint: instance-users\n'}, {'number': 3, 'created': '2014-02-10 19:09:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/9a1f900376c26db5f6df099a541973f788e7dcfa', 'message': 'heat_keystoneclient add delete_stack_domain_user_keypair\n\nAdds function to delete a credential containing a keypair, since we\ndo this as admin we also sanity check to ensure the user associated\nis a stack domain user, if not we should fall back to the non-admin\npath\n\nChange-Id: Ie15958f91b6b80b4a3f0b73943345b7d27566077\nblueprint: instance-users\n'}, {'number': 4, 'created': '2014-02-11 20:26:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/1e0328faf481ddc716bd900d06454001b3dd8f40', 'message': 'heat_keystoneclient add delete_stack_domain_user_keypair\n\nAdds function to delete a credential containing a keypair, since we\ndo this as admin we also sanity check to ensure the user associated\nis a stack domain user, if not we should fall back to the non-admin\npath\n\nChange-Id: Ie15958f91b6b80b4a3f0b73943345b7d27566077\nblueprint: instance-users\n'}, {'number': 5, 'created': '2014-02-17 09:15:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/4ff5282554aeef1d779d3ba98da69c5935796844', 'message': 'heat_keystoneclient add delete_stack_domain_user_keypair\n\nAdds function to delete a credential containing a keypair, since we\ndo this as admin we also sanity check to ensure the user associated\nis a stack domain user, if not we should fall back to the non-admin\npath\n\nChange-Id: Ie15958f91b6b80b4a3f0b73943345b7d27566077\nblueprint: instance-users\n'}, {'number': 6, 'created': '2014-02-18 19:31:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/9d0b08359aee9fcbc5bbd728db1a30b718445dbc', 'message': 'heat_keystoneclient add delete_stack_domain_user_keypair\n\nAdds function to delete a credential containing a keypair, since we\ndo this as admin we also sanity check to ensure the user associated\nis a stack domain user, if not we should fall back to the non-admin\npath\n\nChange-Id: Ie15958f91b6b80b4a3f0b73943345b7d27566077\nblueprint: instance-users\n'}, {'number': 7, 'created': '2014-02-24 23:12:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/10727f7dbdae9e0a7976536ba86373324350ea80', 'message': 'heat_keystoneclient add delete_stack_domain_user_keypair\n\nAdds function to delete a credential containing a keypair, since we\ndo this as admin we also sanity check to ensure the user associated\nis a stack domain user, if not we should fall back to the non-admin\npath\n\nChange-Id: Ie15958f91b6b80b4a3f0b73943345b7d27566077\nblueprint: instance-users\n'}, {'number': 8, 'created': '2014-02-24 23:22:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/0bf213992de7d933ccb42391943652daf524d0a6', 'message': 'heat_keystoneclient add delete_stack_domain_user_keypair\n\nAdds function to delete a credential containing a keypair, since we\ndo this as admin we also sanity check to ensure the user associated\nis a stack domain user, if not we should fall back to the non-admin\npath\n\nChange-Id: Ie15958f91b6b80b4a3f0b73943345b7d27566077\nblueprint: instance-users\n'}, {'number': 9, 'created': '2014-02-25 11:24:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/7726135a33a9761d480dcb55332f77d5d83a65ef', 'message': 'heat_keystoneclient add delete_stack_domain_user_keypair\n\nAdds function to delete a credential containing a keypair, since we\ndo this as admin we also sanity check to ensure the user associated\nis a stack domain user, if not we should fall back to the non-admin\npath\n\nChange-Id: Ie15958f91b6b80b4a3f0b73943345b7d27566077\nblueprint: instance-users\n'}, {'number': 10, 'created': '2014-02-25 13:49:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/10a5517b72038790d276e8b183773185a543eee7', 'message': 'heat_keystoneclient add delete_stack_domain_user_keypair\n\nAdds function to delete a credential containing a keypair, since we\ndo this as admin we also sanity check to ensure the user associated\nis a stack domain user, if not we should fall back to the non-admin\npath\n\nChange-Id: Ie15958f91b6b80b4a3f0b73943345b7d27566077\nblueprint: instance-users\n'}, {'number': 11, 'created': '2014-02-27 13:09:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/51fe8734aa7f6fdb6aedd4514d4fac838b6c2878', 'message': 'heat_keystoneclient add delete_stack_domain_user_keypair\n\nAdds function to delete a credential containing a keypair, since we\ndo this as admin we also sanity check to ensure the user associated\nis a stack domain user, if not we should fall back to the non-admin\npath\n\nChange-Id: Ie15958f91b6b80b4a3f0b73943345b7d27566077\nblueprint: instance-users\n'}, {'number': 12, 'created': '2014-02-28 08:29:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/b60dc7140312361978b3fbc426570563ff8a3839', 'message': 'heat_keystoneclient add delete_stack_domain_user_keypair\n\nAdds function to delete a credential containing a keypair, since we\ndo this as admin we also sanity check to ensure the user associated\nis a stack domain user, if not we should fall back to the non-admin\npath\n\nChange-Id: Ie15958f91b6b80b4a3f0b73943345b7d27566077\nblueprint: instance-users\n'}, {'number': 13, 'created': '2014-03-03 22:28:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/f5c8455d315154a7f3bae427d77564196c8224a5', 'message': 'heat_keystoneclient add delete_stack_domain_user_keypair\n\nAdds function to delete a credential containing a keypair, since we\ndo this as admin we also sanity check to ensure the user associated\nis a stack domain user, if not we should fall back to the non-admin\npath\n\nChange-Id: Ie15958f91b6b80b4a3f0b73943345b7d27566077\nblueprint: instance-users\n'}, {'number': 14, 'created': '2014-03-04 15:57:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/ee2d49c3bdea6d4e324a35f893c877518136142f', 'message': 'heat_keystoneclient add delete_stack_domain_user_keypair\n\nAdds function to delete a credential containing a keypair, since we\ndo this as admin we also sanity check to ensure the user associated\nis a stack domain user, if not we should fall back to the non-admin\npath\n\nChange-Id: Ie15958f91b6b80b4a3f0b73943345b7d27566077\nblueprint: instance-users\n'}, {'number': 15, 'created': '2014-03-05 17:14:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/4b4689404964b056f9be58f058b54d7c0ea25f29', 'message': 'heat_keystoneclient add delete_stack_domain_user_keypair\n\nAdds function to delete a credential containing a keypair, since we\ndo this as admin we also sanity check to ensure the user associated\nis a stack domain user, if not we should fall back to the non-admin\npath\n\nChange-Id: Ie15958f91b6b80b4a3f0b73943345b7d27566077\nblueprint: instance-users\n'}, {'number': 16, 'created': '2014-03-05 17:19:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/739b33f241b5d11237dd44ede524aaa3c37bdaf3', 'message': 'heat_keystoneclient add delete_stack_domain_user_keypair\n\nAdds function to delete a credential containing a keypair, since we\ndo this as admin we also sanity check to ensure the user associated\nis a stack domain user, if not we should fall back to the non-admin\npath\n\nChange-Id: Ie15958f91b6b80b4a3f0b73943345b7d27566077\nblueprint: instance-users\n'}, {'number': 17, 'created': '2014-03-05 17:48:06.000000000', 'files': ['heat/common/heat_keystoneclient.py', 'heat/tests/test_heatclient.py'], 'web_link': 'https://opendev.org/openstack/heat/commit/117f97c682faa6ee5353a47770d2d397c33ab5ce', 'message': 'heat_keystoneclient add delete_stack_domain_user_keypair\n\nAdds function to delete a credential containing a keypair, since we\ndo this as admin we also sanity check to ensure the user associated\nis a stack domain user, if not we should fall back to the non-admin\npath\n\nChange-Id: Ie15958f91b6b80b4a3f0b73943345b7d27566077\nblueprint: instance-users\n'}]",0,71929,117f97c682faa6ee5353a47770d2d397c33ab5ce,75,7,17,4328,,,0,"heat_keystoneclient add delete_stack_domain_user_keypair

Adds function to delete a credential containing a keypair, since we
do this as admin we also sanity check to ensure the user associated
is a stack domain user, if not we should fall back to the non-admin
path

Change-Id: Ie15958f91b6b80b4a3f0b73943345b7d27566077
blueprint: instance-users
",git fetch https://review.opendev.org/openstack/heat refs/changes/29/71929/17 && git format-patch -1 --stdout FETCH_HEAD,"['heat/common/heat_keystoneclient.py', 'heat/tests/test_heatclient.py']",2,608cf605408d84aa6988f4d3547413af1b7be389,bug/1089261," def test_delete_stack_domain_user_keypair(self): ctx = utils.dummy_context() ctx.trust_id = None # mock keystone client functions self._stub_domain(ret_id='adomain123') self._stub_admin_user_get('duser123', 'adomain123', 'aproject') self.mock_admin_client.credentials = self.m.CreateMockAnything() self.mock_admin_client.credentials.delete( 'acredentialid').AndReturn(None) self.m.ReplayAll() heat_ks_client = heat_keystoneclient.KeystoneClient(ctx) heat_ks_client.delete_stack_domain_user_keypair( user_id='duser123', project_id='aproject', credential_id='acredentialid') def test_delete_stack_domain_user_keypair_error_project(self): ctx = utils.dummy_context() ctx.trust_id = None # mock keystone client functions self._stub_domain(ret_id='adomain123') self._stub_admin_user_get('duser123', 'adomain123', 'notaproject') self.m.ReplayAll() heat_ks_client = heat_keystoneclient.KeystoneClient(ctx) self.assertRaises(ValueError, heat_ks_client.delete_stack_domain_user_keypair, user_id='duser123', project_id='aproject', credential_id='acredentialid') def test_delete_stack_domain_user_keypair_error_domain(self): ctx = utils.dummy_context() ctx.trust_id = None # mock keystone client functions self._stub_domain(ret_id='adomain123') self._stub_admin_user_get('duser123', 'notadomain123', 'aproject') self.m.ReplayAll() heat_ks_client = heat_keystoneclient.KeystoneClient(ctx) self.assertRaises(ValueError, heat_ks_client.delete_stack_domain_user_keypair, user_id='duser123', project_id='aproject', credential_id='acredentialid') ",,52,0
openstack%2Ftripleo-image-elements~master~I3e0ec12e3817b16c40a51da9dd45a4f3813cc545,openstack/tripleo-image-elements,master,I3e0ec12e3817b16c40a51da9dd45a4f3813cc545,Linking to debian apache site config more like debian,MERGED,2014-02-25 17:46:10.000000000,2014-03-06 12:38:49.000000000,2014-03-06 12:38:49.000000000,"[{'_account_id': 3}, {'_account_id': 4190}, {'_account_id': 6488}, {'_account_id': 7419}, {'_account_id': 10277}]","[{'number': 1, 'created': '2014-02-25 17:46:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-image-elements/commit/54fd26ff9cd5e7d57ab8bfa54e49b86055aac4f9', 'message': 'linking to debian apache site config more like debian\n\nUbuntu/Debian users expect symlinks in sites-enabled to\npoint at config files in sites-available.  This simple\nchange keeps site configs for Redhat and Ubuntu where\nusers expect to find them.\n\nChange-Id: I3e0ec12e3817b16c40a51da9dd45a4f3813cc545\n'}, {'number': 2, 'created': '2014-02-28 00:26:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-image-elements/commit/8b842d340d383e624ceec32a3e15d7c0a015668e', 'message': 'Linking to debian apache site config more like debian\n\nUbuntu/Debian users expect symlinks in sites-enabled to\npoint at config files in sites-available.  This simple\nchange keeps site configs for Redhat and Ubuntu where\nusers expect to find them.\n\nChange-Id: I3e0ec12e3817b16c40a51da9dd45a4f3813cc545\n'}, {'number': 3, 'created': '2014-02-28 00:48:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-image-elements/commit/425d3cd6e702dd3c8d910ea1667578b104588cb0', 'message': 'Linking to debian apache site config more like debian\n\nUbuntu/Debian users expect symlinks in sites-enabled to\npoint at config files in sites-available.  This simple\nchange keeps site configs for Redhat and Ubuntu where\nusers expect to find them.\n\nChange-Id: I3e0ec12e3817b16c40a51da9dd45a4f3813cc545\n'}, {'number': 4, 'created': '2014-02-28 00:51:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-image-elements/commit/799f7af989aac8bf7b53dae6ffc3e49126cd7a6d', 'message': 'Linking to debian apache site config more like debian\n\nUbuntu/Debian users expect symlinks in sites-enabled to\npoint at config files in sites-available.  This simple\nchange keeps site configs for Redhat and Ubuntu where\nusers expect to find them.\n\nChange-Id: I3e0ec12e3817b16c40a51da9dd45a4f3813cc545\n'}, {'number': 5, 'created': '2014-02-28 04:05:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-image-elements/commit/bfe294c924eb2620634b2f13f7a8bb4d2747260e', 'message': 'Linking to debian apache site config more like debian\n\nUbuntu/Debian users expect symlinks in sites-enabled to\npoint at config files in sites-available.  This simple\nchange keeps site configs for Redhat and Ubuntu where\nusers expect to find them.\n\nChange-Id: I3e0ec12e3817b16c40a51da9dd45a4f3813cc545\n'}, {'number': 6, 'created': '2014-02-28 19:31:26.000000000', 'files': ['elements/horizon/files/horizon.conf', 'elements/horizon/install.d/horizon-source-install/100-horizon'], 'web_link': 'https://opendev.org/openstack/tripleo-image-elements/commit/069986ffd83d5072d758183eefa5a0f3a18d1f0c', 'message': 'Linking to debian apache site config more like debian\n\nUbuntu/Debian users expect symlinks in sites-enabled to\npoint at config files in sites-available.  This simple\nchange keeps site configs for Redhat and Ubuntu where\nusers expect to find them.\n\nChange-Id: I3e0ec12e3817b16c40a51da9dd45a4f3813cc545\n'}]",5,76281,069986ffd83d5072d758183eefa5a0f3a18d1f0c,29,5,6,10277,,,0,"Linking to debian apache site config more like debian

Ubuntu/Debian users expect symlinks in sites-enabled to
point at config files in sites-available.  This simple
change keeps site configs for Redhat and Ubuntu where
users expect to find them.

Change-Id: I3e0ec12e3817b16c40a51da9dd45a4f3813cc545
",git fetch https://review.opendev.org/openstack/tripleo-image-elements refs/changes/81/76281/4 && git format-patch -1 --stdout FETCH_HEAD,['elements/horizon/install.d/horizon-source-install/100-horizon'],1,54fd26ff9cd5e7d57ab8bfa54e49b86055aac4f9,master, cp /etc/httpd/conf.d/horizon.conf /etc/apache2/sites-available/horizon.conf ln -s /etc/apache2/sites-available/horizon.conf /etc/apache2/sites-enabled/horizon.conf, ln -s /etc/httpd/conf.d/horizon.conf /etc/apache2/sites-available/horizon.conf ln -s /etc/httpd/conf.d/horizon.conf /etc/apache2/sites-enabled/horizon.conf,2,2
openstack%2Fneutron~master~I1a075564f2548764de15b85b2970b5f360412eb2,openstack/neutron,master,I1a075564f2548764de15b85b2970b5f360412eb2,NSX: passing wrong security_group id mapping to nsx backend,MERGED,2014-03-03 23:34:14.000000000,2014-03-06 12:30:31.000000000,2014-03-06 12:30:30.000000000,"[{'_account_id': 3}, {'_account_id': 261}, {'_account_id': 748}, {'_account_id': 4395}, {'_account_id': 5170}, {'_account_id': 9008}, {'_account_id': 9732}, {'_account_id': 9787}, {'_account_id': 9845}, {'_account_id': 9925}, {'_account_id': 10116}, {'_account_id': 10184}]","[{'number': 1, 'created': '2014-03-03 23:34:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/48ae89a90ad41f065d060f0b4fd1034c55797da3', 'message': 'NSX: passing wrong security_group id mapping to nsx backend\n\nWhen the async secgroup work was added the update_port() code was not changed\nto pass in the nsx security_group uuids. This patch fixes that so that the\nnsx uuids are passed in instead of neutron.\n\nCloses-bug: #1287419\n\nChange-Id: I1a075564f2548764de15b85b2970b5f360412eb2\n'}, {'number': 2, 'created': '2014-03-04 19:16:45.000000000', 'files': ['neutron/plugins/vmware/plugins/base.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/6c91bdfe24e275ede65df369d714ca119d5ce5f2', 'message': 'NSX: passing wrong security_group id mapping to nsx backend\n\nWhen the async secgroup work was added the update_port() code was not changed\nto pass in the nsx security_group uuids. This patch fixes that so that the\nnsx uuids are passed in instead of neutron.\n\nCloses-bug: #1287419\n\nChange-Id: I1a075564f2548764de15b85b2970b5f360412eb2\n'}]",0,77727,6c91bdfe24e275ede65df369d714ca119d5ce5f2,27,12,2,4395,,,0,"NSX: passing wrong security_group id mapping to nsx backend

When the async secgroup work was added the update_port() code was not changed
to pass in the nsx security_group uuids. This patch fixes that so that the
nsx uuids are passed in instead of neutron.

Closes-bug: #1287419

Change-Id: I1a075564f2548764de15b85b2970b5f360412eb2
",git fetch https://review.opendev.org/openstack/neutron refs/changes/27/77727/2 && git format-patch -1 --stdout FETCH_HEAD,['neutron/plugins/vmware/plugins/base.py'],1,48ae89a90ad41f065d060f0b4fd1034c55797da3,bp/nova-event-callback," # Convert Neutron security groups identifiers into NSX security # profiles identifiers nsx_sec_profile_ids = [ nsx_utils.get_nsx_security_group_id( context.session, self.cluster, neutron_sg_id) for neutron_sg_id in (ret_port[ext_sg.SECURITYGROUPS] or [])] nsx_sec_profile_ids,"," ret_port[ext_sg.SECURITYGROUPS],",8,1
openstack%2Fnova~stable%2Fhavana~I45a24af11534911be68fd0964b79fdf726d88de6,openstack/nova,stable/havana,I45a24af11534911be68fd0964b79fdf726d88de6,Remove unneeded call to conductor in network interface,MERGED,2014-02-13 21:36:30.000000000,2014-03-06 12:29:08.000000000,2014-03-06 12:29:04.000000000,"[{'_account_id': 3}, {'_account_id': 1653}, {'_account_id': 4395}]","[{'number': 1, 'created': '2014-02-13 21:36:30.000000000', 'files': ['nova/tests/network/test_neutronv2.py', 'nova/network/neutronv2/api.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/d3c8757dfc59a30ca4a8bf2ab8c1d610b4fd8a2a', 'message': 'Remove unneeded call to conductor in network interface\n\nThe following patch removes an unneeded call to conductor to retrieve\ndata already available in instance.\n\nNote: six.text_type() was added and wrapped around info_cache in some of\nthe tests. This was done because values from the db are in unicode\n(text_type). The reason the test changed is because previously we\ndid not check the type of string from what the conductor was returning.\n\nCloses-bug: #1258360\n\nConflicts:\n\n\tnova/tests/network/test_neutronv2.py\n\nChange-Id: I45a24af11534911be68fd0964b79fdf726d88de6\n(cherry picked from commit 10004672ad1476c55deaad53684a50358da6f656)\n'}]",0,73422,d3c8757dfc59a30ca4a8bf2ab8c1d610b4fd8a2a,12,3,1,4395,,,0,"Remove unneeded call to conductor in network interface

The following patch removes an unneeded call to conductor to retrieve
data already available in instance.

Note: six.text_type() was added and wrapped around info_cache in some of
the tests. This was done because values from the db are in unicode
(text_type). The reason the test changed is because previously we
did not check the type of string from what the conductor was returning.

Closes-bug: #1258360

Conflicts:

	nova/tests/network/test_neutronv2.py

Change-Id: I45a24af11534911be68fd0964b79fdf726d88de6
(cherry picked from commit 10004672ad1476c55deaad53684a50358da6f656)
",git fetch https://review.opendev.org/openstack/nova refs/changes/22/73422/1 && git format-patch -1 --stdout FETCH_HEAD,"['nova/tests/network/test_neutronv2.py', 'nova/network/neutronv2/api.py']",2,d3c8757dfc59a30ca4a8bf2ab8c1d610b4fd8a2a,,"import six # Unfortunately, this is sometimes in unicode and sometimes not if isinstance(instance['info_cache']['network_info'], six.text_type): ifaces = jsonutils.loads(instance['info_cache']['network_info']) else: ifaces = instance['info_cache']['network_info'] if networks is None: net_ids = [iface['network']['id'] for iface in ifaces]"," if networks is None: # retrieve networks from info_cache to get correct nic order network_cache = self.conductor_api.instance_get_by_uuid( context, instance['uuid'])['info_cache']['network_info'] network_cache = jsonutils.loads(network_cache) net_ids = [iface['network']['id'] for iface in network_cache] # Unfortunately, this is sometimes in unicode and sometimes not if isinstance(instance['info_cache']['network_info'], unicode): ifaces = jsonutils.loads( instance['info_cache']['network_info']) else: ifaces = instance['info_cache']['network_info'] ",26,35
openstack%2Fnova~stable%2Fhavana~Id8f0241d1c6609cf4e064ee6855228ae7de250e2,openstack/nova,stable/havana,Id8f0241d1c6609cf4e064ee6855228ae7de250e2,Remove reduntant call to update_instance_info_cache,MERGED,2014-02-13 21:36:28.000000000,2014-03-06 12:27:47.000000000,2014-03-06 12:27:43.000000000,"[{'_account_id': 3}, {'_account_id': 748}, {'_account_id': 1653}, {'_account_id': 4395}]","[{'number': 1, 'created': '2014-02-13 21:36:28.000000000', 'files': ['nova/network/neutronv2/api.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/b047eaa9d96dc7c8f7a2f4311277090ce9d21d89', 'message': 'Remove reduntant call to update_instance_info_cache\n\nget_instance_nw_info calls _get_instance_nw_info,\nwhich is decorated with @refresh_cache. This in\nturn calls update_instance_info_cache, again. This\nis both expensive and more importantly dangerous because\nthe method update_instance_info_cache may call\n_get_instance_nw_info itself, thus causing an infinite\nloop.\n\nChange-Id: Id8f0241d1c6609cf4e064ee6855228ae7de250e2\nPartial-bug: 1235435\n(cherry picked from commit 651fac3d5d250d42e640c3ac113084bf0d2fa3b4)\n'}]",0,73421,b047eaa9d96dc7c8f7a2f4311277090ce9d21d89,13,4,1,4395,,,0,"Remove reduntant call to update_instance_info_cache

get_instance_nw_info calls _get_instance_nw_info,
which is decorated with @refresh_cache. This in
turn calls update_instance_info_cache, again. This
is both expensive and more importantly dangerous because
the method update_instance_info_cache may call
_get_instance_nw_info itself, thus causing an infinite
loop.

Change-Id: Id8f0241d1c6609cf4e064ee6855228ae7de250e2
Partial-bug: 1235435
(cherry picked from commit 651fac3d5d250d42e640c3ac113084bf0d2fa3b4)
",git fetch https://review.opendev.org/openstack/nova refs/changes/21/73421/1 && git format-patch -1 --stdout FETCH_HEAD,['nova/network/neutronv2/api.py'],1,b047eaa9d96dc7c8f7a2f4311277090ce9d21d89,,," update_instance_info_cache(self, context, instance, result, update_cells=False)",0,2
openstack%2Ftripleo-incubator~master~I2dcfa9915dfec9f675114486498a611200cfe076,openstack/tripleo-incubator,master,I2dcfa9915dfec9f675114486498a611200cfe076,Make the TE_DATAFILE check self documenting,MERGED,2014-02-20 16:20:39.000000000,2014-03-06 12:24:12.000000000,2014-03-06 12:24:12.000000000,"[{'_account_id': 3}, {'_account_id': 7144}, {'_account_id': 7419}, {'_account_id': 7471}, {'_account_id': 7582}, {'_account_id': 9369}, {'_account_id': 9552}]","[{'number': 1, 'created': '2014-02-20 16:20:39.000000000', 'files': ['scripts/devtest_overcloud.sh'], 'web_link': 'https://opendev.org/openstack/tripleo-incubator/commit/5032940f3826bc8e0ad05eb5dafb7177be2dbc41', 'message': 'Make the TE_DATAFILE check self documenting\n\nChange-Id: I2dcfa9915dfec9f675114486498a611200cfe076\n'}]",0,75084,5032940f3826bc8e0ad05eb5dafb7177be2dbc41,17,7,1,360,,,0,"Make the TE_DATAFILE check self documenting

Change-Id: I2dcfa9915dfec9f675114486498a611200cfe076
",git fetch https://review.opendev.org/openstack/tripleo-incubator refs/changes/84/75084/1 && git format-patch -1 --stdout FETCH_HEAD,['scripts/devtest_overcloud.sh'],1,5032940f3826bc8e0ad05eb5dafb7177be2dbc41,cleanup_TE_DATAFILE_check,"TE_DATAFILE=${TE_DATAFILE:?""TE_DATAFILE must be defined before calling this script!""}",# We really need to get this into a parameter ! # This line causes an early error if TE_DATAFILE is not exported. TE_DATAFILE=$TE_DATAFILE,1,3
openstack%2Ftripleo-incubator~master~I2a61330a26a7bea6abc458781c83ec96f4b604e6,openstack/tripleo-incubator,master,I2a61330a26a7bea6abc458781c83ec96f4b604e6,Use baremetal element to extract kernel and initrd for undercloud,MERGED,2014-02-07 14:32:02.000000000,2014-03-06 12:22:00.000000000,2014-03-06 12:21:59.000000000,"[{'_account_id': 3}, {'_account_id': 2062}, {'_account_id': 4190}, {'_account_id': 6449}, {'_account_id': 6488}, {'_account_id': 7144}, {'_account_id': 7419}, {'_account_id': 7471}, {'_account_id': 8532}, {'_account_id': 9369}]","[{'number': 1, 'created': '2014-02-07 14:32:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-incubator/commit/7e3212f9ad9afcd9eaccfad8403442dc41377f99', 'message': 'Use baremetal element to extract kernel and initrd for undercloud\n\nThe ""disk-image-get-kernel"" is deprecated\n\nChange-Id: I2a61330a26a7bea6abc458781c83ec96f4b604e6\n'}, {'number': 2, 'created': '2014-02-07 14:33:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-incubator/commit/28173ae524b58da9e6f67a0007da4e29ab8f2d62', 'message': 'Use baremetal element to extract kernel and initrd for undercloud\n\nThe ""disk-image-get-kernel"" tool is deprecated\n\nChange-Id: I2a61330a26a7bea6abc458781c83ec96f4b604e6\n'}, {'number': 3, 'created': '2014-02-07 15:30:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-incubator/commit/79fd9b49662f87a7f334d0ed3b36830edfecf722', 'message': 'Use baremetal element to extract kernel and initrd for undercloud\n\nThe ""disk-image-get-kernel"" tool is deprecated\n\nChange-Id: I2a61330a26a7bea6abc458781c83ec96f4b604e6\n'}, {'number': 4, 'created': '2014-02-07 15:32:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-incubator/commit/6d84225ee0f0a4b0226a740b377cd53108f0e6d7', 'message': 'Use baremetal element to extract kernel and initrd for undercloud\n\nThe ""disk-image-get-kernel"" tool is deprecated\n\nChange-Id: I2a61330a26a7bea6abc458781c83ec96f4b604e6\n'}, {'number': 5, 'created': '2014-02-13 14:44:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-incubator/commit/eee2233b57b8b64dd568e992e0c8aa44b05ebf91', 'message': 'Use baremetal element to extract kernel and initrd for undercloud\n\nThe ""disk-image-get-kernel"" tool is deprecated\n\nChange-Id: I2a61330a26a7bea6abc458781c83ec96f4b604e6\n'}, {'number': 6, 'created': '2014-02-19 09:17:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-incubator/commit/9cbd9a9c675c7a4a96c1537cead39be3d93fb92d', 'message': 'Use baremetal element to extract kernel and initrd for undercloud\n\nThe ""disk-image-get-kernel"" tool is deprecated\n\nChange-Id: I2a61330a26a7bea6abc458781c83ec96f4b604e6\n'}, {'number': 7, 'created': '2014-02-21 16:08:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-incubator/commit/31415f0a5a6eeef9cdab3e1ae5f67e8fb3125d2d', 'message': 'Use baremetal element to extract kernel and initrd for undercloud\n\nThe ""disk-image-get-kernel"" tool is deprecated\n\nChange-Id: I2a61330a26a7bea6abc458781c83ec96f4b604e6\n'}, {'number': 8, 'created': '2014-02-28 04:42:34.000000000', 'files': ['scripts/load-image', 'scripts/devtest_undercloud.sh', 'scripts/devtest_overcloud.sh'], 'web_link': 'https://opendev.org/openstack/tripleo-incubator/commit/9a67ec3637b82f15e79313229618a5eea5c7f05d', 'message': 'Use baremetal element to extract kernel and initrd for undercloud\n\nThe ""disk-image-get-kernel"" tool is deprecated\n\nChange-Id: I2a61330a26a7bea6abc458781c83ec96f4b604e6\n'}]",3,71912,9a67ec3637b82f15e79313229618a5eea5c7f05d,65,10,8,2062,,,0,"Use baremetal element to extract kernel and initrd for undercloud

The ""disk-image-get-kernel"" tool is deprecated

Change-Id: I2a61330a26a7bea6abc458781c83ec96f4b604e6
",git fetch https://review.opendev.org/openstack/tripleo-incubator refs/changes/12/71912/5 && git format-patch -1 --stdout FETCH_HEAD,"['scripts/load-image', 'scripts/devtest_undercloud.sh']",2,7e3212f9ad9afcd9eaccfad8403442dc41377f99,undercloud-use-baremetal, baremetal boot-stack nova-baremetal os-collect-config dhcp-all-interfaces \, boot-stack nova-baremetal os-collect-config dhcp-all-interfaces \,13,17
openstack%2Fneutron~master~I7dae6b728ab9e10f1dc5d63418a69ee4c26354ea,openstack/neutron,master,I7dae6b728ab9e10f1dc5d63418a69ee4c26354ea,NEC plugin: delete old OFC ID mapping tables,MERGED,2014-03-02 08:04:19.000000000,2014-03-06 11:58:25.000000000,2014-03-06 11:58:24.000000000,"[{'_account_id': 3}, {'_account_id': 490}, {'_account_id': 841}, {'_account_id': 2031}, {'_account_id': 2592}, {'_account_id': 5170}, {'_account_id': 6788}, {'_account_id': 9008}, {'_account_id': 9681}, {'_account_id': 9732}, {'_account_id': 9845}, {'_account_id': 9925}, {'_account_id': 10116}, {'_account_id': 10117}, {'_account_id': 10153}, {'_account_id': 10184}, {'_account_id': 10192}, {'_account_id': 10294}, {'_account_id': 10387}]","[{'number': 1, 'created': '2014-03-02 08:04:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/6cf921bcec96ff43c83cf305bd859372160ef9ce', 'message': 'NEC plugin: delete old OFC ID mapping tables\n\nBefore Grizzly release, data format of OFC ID mapping tables was changed\nand there are two types of ID mapping tables for old and new format.\nThis commit migrate data from old mapping tables into new tables,\ndrop old mapping tables and remove the logic handling the old tables.\n\nIn the db migration scripts, built-in compiler of sqlalchemy does not\nsupport ""INSERT INTO table (col1, col2,...) (SELECT ....)"" format,\nso a custom sqlalchemy.expression compiling method is defined.\n\nCloses-Bug: #1286733\nChange-Id: I7dae6b728ab9e10f1dc5d63418a69ee4c26354ea\n'}, {'number': 3, 'created': '2014-03-02 08:56:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/0de2d7054e4198d4eb785ba2b8d911ca4148ef98', 'message': 'NEC plugin: delete old OFC ID mapping tables\n\nBefore Grizzly release, data format of OFC ID mapping tables was changed\nand there are two types of ID mapping tables for old and new format.\nThis commit migrate data from old mapping tables into new tables,\ndrop old mapping tables and remove the logic handling the old tables.\n\nIn the db migration scripts, built-in compiler of sqlalchemy does not\nsupport ""INSERT INTO table (col1, col2,...) (SELECT ....)"" format,\nso a custom sqlalchemy.expression compiling method is defined.\n\nCloses-Bug: #1286733\nChange-Id: I7dae6b728ab9e10f1dc5d63418a69ee4c26354ea\n'}, {'number': 2, 'created': '2014-03-02 08:56:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/bdaee34bab8b4a76d93912a1e9c1ae7b7a710775', 'message': 'NEC plugin: delete old OFC ID mapping tables\n\nBefore Grizzly release, data format of OFC ID mapping tables was changed\nand there are two types of ID mapping tables for old and new format.\nThis commit migrate data from old mapping tables into new tables,\ndrop old mapping tables and remove the logic handling the old tables.\n\nIn the db migration scripts, built-in compiler of sqlalchemy does not\nsupport ""INSERT INTO table (col1, col2,...) (SELECT ....)"" format,\nso a custom sqlalchemy.expression compiling method is defined.\n\nCloses-Bug: #1286733\nChange-Id: I7dae6b728ab9e10f1dc5d63418a69ee4c26354ea\n'}, {'number': 4, 'created': '2014-03-03 07:29:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/6440b3c47352b44e310032dbdcd613a71153a2d7', 'message': 'NEC plugin: delete old OFC ID mapping tables\n\nBefore Grizzly release, data format of OFC ID mapping tables was changed\nand there are two types of ID mapping tables for old and new format.\nThis commit migrate data from old mapping tables into new tables,\ndrop old mapping tables and remove the logic handling the old tables.\n\nIn the db migration scripts, built-in compiler of sqlalchemy does not\nsupport ""INSERT INTO table (col1, col2,...) (SELECT ....)"" format,\nso a custom sqlalchemy.expression compiling method is defined.\n\nCloses-Bug: #1286733\nChange-Id: I7dae6b728ab9e10f1dc5d63418a69ee4c26354ea\n'}, {'number': 5, 'created': '2014-03-04 00:04:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/cdc3fa3f02a6d466b66aebca4e156b97c17b7c0e', 'message': 'NEC plugin: delete old OFC ID mapping tables\n\nBefore Grizzly release, data format of OFC ID mapping tables was changed\nand there are two types of ID mapping tables for old and new format.\nThis commit migrate data from old mapping tables into new tables,\ndrop old mapping tables and remove the logic handling the old tables.\n\nIn the db migration scripts, built-in compiler of sqlalchemy does not\nsupport ""INSERT INTO table (col1, col2,...) (SELECT ....)"" format,\nso a custom sqlalchemy.expression compiling method is defined.\n\nCloses-Bug: #1286733\nChange-Id: I7dae6b728ab9e10f1dc5d63418a69ee4c26354ea\n'}, {'number': 6, 'created': '2014-03-04 02:58:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/d1f7936748b74b7ab8ae8f5a7896f879027db447', 'message': 'NEC plugin: delete old OFC ID mapping tables\n\nBefore Grizzly release, data format of OFC ID mapping tables was changed\nand there are two types of ID mapping tables for old and new format.\nThis commit migrate data from old mapping tables into new tables,\ndrop old mapping tables and remove the logic handling the old tables.\n\nIn the db migration scripts, built-in compiler of sqlalchemy does not\nsupport ""INSERT INTO table (col1, col2,...) (SELECT ....)"" format,\nso a custom sqlalchemy.expression compiling method is defined.\n\nCloses-Bug: #1286733\nChange-Id: I7dae6b728ab9e10f1dc5d63418a69ee4c26354ea\n'}, {'number': 7, 'created': '2014-03-05 05:35:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/f71f514c582fbaef280daf552ec5668587774292', 'message': 'NEC plugin: delete old OFC ID mapping tables\n\nBefore Grizzly release, data format of OFC ID mapping tables was changed\nand there are two types of ID mapping tables for old and new format.\nThis commit migrate data from old mapping tables into new tables,\ndrop old mapping tables and remove the logic handling the old tables.\n\nIn the db migration scripts, built-in compiler of sqlalchemy does not\nsupport ""INSERT INTO table (col1, col2,...) (SELECT ....)"" format,\nso a custom sqlalchemy.expression compiling method is defined.\n\nCloses-Bug: #1286733\nChange-Id: I7dae6b728ab9e10f1dc5d63418a69ee4c26354ea\n'}, {'number': 9, 'created': '2014-03-06 00:01:03.000000000', 'files': ['neutron/plugins/nec/db/models.py', 'neutron/plugins/nec/ofc_manager.py', 'neutron/plugins/nec/drivers/pfc.py', 'neutron/db/migration/alembic_migrations/versions/117643811bca_nec_delete_ofc_mapping.py', 'neutron/tests/unit/nec/test_db.py', 'neutron/tests/unit/nec/test_pfc_driver.py', 'neutron/plugins/nec/ofc_driver_base.py', 'neutron/tests/unit/nec/test_trema_driver.py', 'neutron/plugins/nec/db/api.py', 'neutron/tests/unit/nec/test_ofc_manager.py', 'neutron/plugins/nec/drivers/trema.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/142c55e82a4d36af887439a94054617a5a0ede9c', 'message': 'NEC plugin: delete old OFC ID mapping tables\n\nBefore Grizzly release, data format of OFC ID mapping tables was changed\nand there are two types of ID mapping tables for old and new format.\nThis commit migrate data from old mapping tables into new tables,\ndrop old mapping tables and remove the logic handling the old tables.\n\nIn the db migration scripts, built-in compiler of sqlalchemy does not\nsupport ""INSERT INTO table (col1, col2,...) (SELECT ....)"" format,\nso a custom sqlalchemy.expression compiling method is defined.\n\nCloses-Bug: #1286733\nChange-Id: I7dae6b728ab9e10f1dc5d63418a69ee4c26354ea\n'}, {'number': 8, 'created': '2014-03-06 00:01:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/60a6bb5251b0dbcafc9ad2f4dace186bbf15c766', 'message': 'NEC plugin: delete old OFC ID mapping tables\n\nBefore Grizzly release, data format of OFC ID mapping tables was changed\nand there are two types of ID mapping tables for old and new format.\nThis commit migrate data from old mapping tables into new tables,\ndrop old mapping tables and remove the logic handling the old tables.\n\nIn the db migration scripts, built-in compiler of sqlalchemy does not\nsupport ""INSERT INTO table (col1, col2,...) (SELECT ....)"" format,\nso a custom sqlalchemy.expression compiling method is defined.\n\nCloses-Bug: #1286733\nChange-Id: I7dae6b728ab9e10f1dc5d63418a69ee4c26354ea\n'}]",5,77407,142c55e82a4d36af887439a94054617a5a0ede9c,126,19,9,841,,,0,"NEC plugin: delete old OFC ID mapping tables

Before Grizzly release, data format of OFC ID mapping tables was changed
and there are two types of ID mapping tables for old and new format.
This commit migrate data from old mapping tables into new tables,
drop old mapping tables and remove the logic handling the old tables.

In the db migration scripts, built-in compiler of sqlalchemy does not
support ""INSERT INTO table (col1, col2,...) (SELECT ....)"" format,
so a custom sqlalchemy.expression compiling method is defined.

Closes-Bug: #1286733
Change-Id: I7dae6b728ab9e10f1dc5d63418a69ee4c26354ea
",git fetch https://review.opendev.org/openstack/neutron refs/changes/07/77407/9 && git format-patch -1 --stdout FETCH_HEAD,"['neutron/plugins/nec/db/models.py', 'neutron/plugins/nec/ofc_manager.py', 'neutron/plugins/nec/drivers/pfc.py', 'neutron/db/migration/alembic_migrations/versions/117643811bca_nec_delete_ofc_mapping.py', 'neutron/tests/unit/nec/test_db.py', 'neutron/tests/unit/nec/test_pfc_driver.py', 'neutron/plugins/nec/ofc_driver_base.py', 'neutron/tests/unit/nec/test_trema_driver.py', 'neutron/plugins/nec/db/api.py', 'neutron/plugins/nec/drivers/trema.py', 'neutron/tests/unit/nec/test_ofc_manager.py']",11,6cf921bcec96ff43c83cf305bd859372160ef9ce,fix_migrations,," class OFCManagerTestWithOldMapping(OFCManagerTestBase): def setUp(self): super(OFCManagerTestWithOldMapping, self).setUp() # NOTE(amotoki): In OldMapping tests, DB entries are directly modified # to create a case where the old mapping tables are used intentionally. self.ofc.driver.disable_autocheck() def test_exists_ofc_tenant(self): t, n, p, f, none = self.get_random_params() ofc_t, ofc_n, ofc_p, ofc_f, ofc_none = self.get_random_params() self.assertFalse(self.ofc.exists_ofc_tenant(self.ctx, t)) session = self.ctx.session ndb.add_ofc_item(session, 'ofc_tenant', t, ofc_t, old_style=True) self.assertTrue(self.ofc.exists_ofc_tenant(self.ctx, t)) def test_delete_ofc_tenant(self): t, n, p, f, none = self.get_random_params() ofc_t, ofc_n, ofc_p, ofc_f, ofc_none = self.get_random_params() self.assertFalse(self.ofc.exists_ofc_tenant(self.ctx, t)) session = self.ctx.session ndb.add_ofc_item(session, 'ofc_tenant', t, ofc_t, old_style=True) self.assertTrue(self.ofc.exists_ofc_tenant(self.ctx, t)) self.ofc.delete_ofc_tenant(self.ctx, t) self.assertFalse(self.ofc.exists_ofc_tenant(self.ctx, t)) def test_exists_ofc_network(self): t, n, p, f, none = self.get_random_params() ofc_t, ofc_n, ofc_p, ofc_f, ofc_none = self.get_random_params() self.assertFalse(self.ofc.exists_ofc_network(self.ctx, n)) session = self.ctx.session ndb.add_ofc_item(session, 'ofc_network', n, ofc_n, old_style=True) self.assertTrue(self.ofc.exists_ofc_network(self.ctx, n)) def test_delete_ofc_network(self): t, n, p, f, none = self.get_random_params() ofc_t, ofc_n, ofc_p, ofc_f, ofc_none = self.get_random_params() self.assertFalse(self.ofc.exists_ofc_network(self.ctx, n)) session = self.ctx.session ndb.add_ofc_item(session, 'ofc_network', n, ofc_n, old_style=True) self.assertTrue(self.ofc.exists_ofc_network(self.ctx, n)) net = {'tenant_id': t} self.ofc.delete_ofc_network(self.ctx, n, net) self.assertFalse(self.ofc.exists_ofc_network(self.ctx, n)) def test_exists_ofc_port(self): t, n, p, f, none = self.get_random_params() ofc_t, ofc_n, ofc_p, ofc_f, ofc_none = self.get_random_params() self.assertFalse(self.ofc.exists_ofc_port(self.ctx, p)) session = self.ctx.session ndb.add_ofc_item(session, 'ofc_port', p, ofc_p, old_style=True) self.assertTrue(self.ofc.exists_ofc_port(self.ctx, p)) def test_delete_ofc_port(self): t, n, p, f, none = self.get_random_params() ofc_t, ofc_n, ofc_p, ofc_f, ofc_none = self.get_random_params() self.assertFalse(self.ofc.exists_ofc_port(self.ctx, p)) session = self.ctx.session ndb.add_ofc_item(session, 'ofc_port', p, ofc_p, old_style=True) self.assertTrue(self.ofc.exists_ofc_port(self.ctx, p)) port = {'tenant_id': t, 'network_id': n} self.ofc.delete_ofc_port(self.ctx, p, port) self.assertFalse(self.ofc.exists_ofc_port(self.ctx, p)) def test_exists_ofc_packet_filter(self): t, n, p, f, none = self.get_random_params() ofc_t, ofc_n, ofc_p, ofc_f, ofc_none = self.get_random_params() self.assertFalse(self.ofc.exists_ofc_packet_filter(self.ctx, f)) session = self.ctx.session ndb.add_ofc_item(session, 'ofc_packet_filter', f, ofc_f, old_style=True) self.assertTrue(self.ofc.exists_ofc_packet_filter(self.ctx, f)) def test_delete_ofc_packet_filter(self): t, n, p, f, none = self.get_random_params() ofc_t, ofc_n, ofc_p, ofc_f, ofc_none = self.get_random_params() self.assertFalse(self.ofc.exists_ofc_packet_filter(self.ctx, f)) session = self.ctx.session ndb.add_ofc_item(session, 'ofc_packet_filter', f, ofc_f, old_style=True) self.assertTrue(self.ofc.exists_ofc_packet_filter(self.ctx, f)) self.ofc.delete_ofc_packet_filter(self.ctx, f) self.assertFalse(self.ofc.exists_ofc_packet_filter(self.ctx, f))",266,746
openstack%2Fsahara~master~Ib7d94d0363708e685b6675df5bdc4bd752491c8e,openstack/sahara,master,Ib7d94d0363708e685b6675df5bdc4bd752491c8e,Enable use of rootwrap for neutron private IP interactions,ABANDONED,2014-02-13 20:22:06.000000000,2014-03-06 11:53:53.000000000,,"[{'_account_id': 3}, {'_account_id': 6786}, {'_account_id': 7213}, {'_account_id': 7555}, {'_account_id': 7737}, {'_account_id': 8091}, {'_account_id': 8411}]","[{'number': 1, 'created': '2014-02-13 20:22:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sahara/commit/dd76d04c94f16a231cfe78dd7c1a23ecc6c52f8d', 'message': ""Enable use of rootwrap for neutron private IP interactions\n\nIn situations where the savanna server can not be started\nby the 'root' user, there is a need to provide selective access\nfor a non-root user to the 'ip netns exec' facility required\nfor namespace-based communication. The rootwrap facility is\nprovides such access.\n\nThe facility has been configured as an option controlled by\nentries in savanna.conf.  The reason for this is that if it\nwas used as the default mechanism, even in situations where\nthe root user was being leveraged the complete rootwrap\nconfiguration (outlined in the features.rst file and also\navailable at https://wiki.openstack.org/wiki/Rootwrap) would\nbe required for neutron private IP scenarios.\n\nThe specific commands being invoked with root authority by a\nnon-root user are:\n\nip netns exec\nnc (netcat)\nkill\n\nThe latter is utilized to kill the 'nc' subprocess when the\nsocket is terminated.  There is a specific KillFilter that\ncan be leveraged but I could not get it to work.\n\nFixes bug #1271349\n\nChange-Id: Ib7d94d0363708e685b6675df5bdc4bd752491c8e\n""}, {'number': 2, 'created': '2014-02-13 21:18:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sahara/commit/105df47d62e3ae96ebb47e24932961e3c6d8bb07', 'message': ""Enable use of rootwrap for neutron private IP interactions\n\nIn situations where the savanna server can not be started\nby the 'root' user, there is a need to provide selective access\nfor a non-root user to the 'ip netns exec' facility required\nfor namespace-based communication. The rootwrap facility\nprovides such access.\n\nThe facility has been configured as an option controlled by\nentries in savanna.conf.  The reason for this is that if it\nwas used as the default mechanism, even in situations where\nthe root user was being leveraged the complete rootwrap\nconfiguration (outlined in the features.rst file and also\navailable at https://wiki.openstack.org/wiki/Rootwrap) would\nbe required for neutron private IP scenarios.\n\nThe specific commands being invoked with root authority by a\nnon-root user are:\n\nip netns exec\nnc (netcat)\nkill\n\nThe latter is utilized to kill the 'nc' subprocess when the\nsocket is terminated.  There is a specific KillFilter that\ncan be leveraged but I could not get it to work.\n\nFixes bug #1271349\n\nChange-Id: Ib7d94d0363708e685b6675df5bdc4bd752491c8e\n""}, {'number': 3, 'created': '2014-02-13 22:30:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sahara/commit/a9f9f461cf3160142a1fe000975845664787bade', 'message': ""Enable use of rootwrap for neutron private IP interactions\n\nIn situations where the savanna server can not be started\nby the 'root' user, there is a need to provide selective access\nfor a non-root user to the 'ip netns exec' facility required\nfor namespace-based communication. The rootwrap facility\nprovides such access.\n\nThe facility has been configured as an option controlled by\nentries in savanna.conf.  The reason for this is that if it\nwas used as the default mechanism, even in situations where\nthe root user was being leveraged the complete rootwrap\nconfiguration (outlined in the features.rst file and also\navailable at https://wiki.openstack.org/wiki/Rootwrap) would\nbe required for neutron private IP scenarios.\n\nThe specific commands being invoked with root authority by a\nnon-root user are:\n\nip netns exec\nnc (netcat)\nkill\n\nThe latter is utilized to kill the 'nc' subprocess when the\nsocket is terminated.  There is a specific KillFilter that\ncan be leveraged but I could not get it to work.\n\nFixes bug #1271349\n\nChange-Id: Ib7d94d0363708e685b6675df5bdc4bd752491c8e\n""}, {'number': 4, 'created': '2014-02-17 15:52:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sahara/commit/bed77def407ac04307af44c0a773254d92429456', 'message': ""Enable use of rootwrap for neutron private IP interactions\n\nIn situations where the savanna server can not be started\nby the 'root' user, there is a need to provide selective access\nfor a non-root user to the 'ip netns exec' facility required\nfor namespace-based communication. The rootwrap facility\nprovides such access.\n\nThe facility has been configured as an option controlled by\nentries in savanna.conf.  The reason for this is that if it\nwas used as the default mechanism, even in situations where\nthe root user was being leveraged the complete rootwrap\nconfiguration (outlined in the features.rst file and also\navailable at https://wiki.openstack.org/wiki/Rootwrap) would\nbe required for neutron private IP scenarios.\n\nThe specific commands being invoked with root authority by a\nnon-root user are:\n\nip netns exec\nnc (netcat)\nkill\n\nThe latter is utilized to kill the 'nc' subprocess when the\nsocket is terminated.  There is a specific KillFilter that\ncan be leveraged but I could not get it to work.\n\nFixes bug #1271349\n\nChange-Id: Ib7d94d0363708e685b6675df5bdc4bd752491c8e\n""}, {'number': 5, 'created': '2014-02-24 16:41:16.000000000', 'files': ['etc/savanna/savanna.conf.sample', 'doc/source/userdoc/features.rst', 'savanna/utils/openstack/neutron.py', 'savanna/utils/ssh_remote.py', 'savanna/config.py'], 'web_link': 'https://opendev.org/openstack/sahara/commit/692c05c1f81b575bf55fdbdd4cb03af678c6a6c5', 'message': ""Enable use of rootwrap for neutron private IP interactions\n\nIn situations where the savanna server can not be started\nby the 'root' user, there is a need to provide selective access\nfor a non-root user to the 'ip netns exec' facility required\nfor namespace-based communication. The rootwrap facility\nprovides such access.\n\nThe facility has been configured as an option controlled by\nentries in savanna.conf.  The reason for this is that if it\nwas used as the default mechanism, even in situations where\nthe root user was being leveraged the complete rootwrap\nconfiguration (outlined in the features.rst file and also\navailable at https://wiki.openstack.org/wiki/Rootwrap) would\nbe required for neutron private IP scenarios.\n\nThe specific commands being invoked with root authority by a\nnon-root user are:\n\nip netns exec\nnc (netcat)\nkill\n\nThe latter is utilized to kill the 'nc' subprocess when the\nsocket is terminated.  There is a specific KillFilter that\ncan be leveraged but I could not get it to work.\n\nFixes bug #1271349\n\nChange-Id: Ib7d94d0363708e685b6675df5bdc4bd752491c8e\n""}]",40,73396,692c05c1f81b575bf55fdbdd4cb03af678c6a6c5,58,7,5,7737,,,0,"Enable use of rootwrap for neutron private IP interactions

In situations where the savanna server can not be started
by the 'root' user, there is a need to provide selective access
for a non-root user to the 'ip netns exec' facility required
for namespace-based communication. The rootwrap facility
provides such access.

The facility has been configured as an option controlled by
entries in savanna.conf.  The reason for this is that if it
was used as the default mechanism, even in situations where
the root user was being leveraged the complete rootwrap
configuration (outlined in the features.rst file and also
available at https://wiki.openstack.org/wiki/Rootwrap) would
be required for neutron private IP scenarios.

The specific commands being invoked with root authority by a
non-root user are:

ip netns exec
nc (netcat)
kill

The latter is utilized to kill the 'nc' subprocess when the
socket is terminated.  There is a specific KillFilter that
can be leveraged but I could not get it to work.

Fixes bug #1271349

Change-Id: Ib7d94d0363708e685b6675df5bdc4bd752491c8e
",git fetch https://review.opendev.org/openstack/sahara refs/changes/96/73396/5 && git format-patch -1 --stdout FETCH_HEAD,"['tools/conf/whitelist.txt', 'etc/savanna/savanna.conf.sample', 'doc/source/userdoc/features.rst', 'savanna/utils/openstack/neutron.py', 'savanna/utils/ssh_remote.py', 'etc/savanna/savanna.conf.sample-full', 'savanna/config.py']",7,dd76d04c94f16a231cfe78dd7c1a23ecc6c52f8d,bug/1271349," ""use in conjunction with use_neutron=True)""), cfg.BoolOpt('use_rootwrap', default=False, help=""Use rootwrap facility to allow non-root users to run "" ""the savanna-api server instance and access private "" ""network IPs (only valid to use in conjunction with "" ""use_namespaces=True)""), cfg.StrOpt('rootwrap_command', default='sudo quantum-rootwrap /etc/quantum/rootwrap.conf', help=""Rootwrap command to leverage. User in conjunction with "" ""use_rootwrap=True""),"," ""use in conjunction with use_neutron=True)"")",103,14
openstack%2Fneutron~master~I67f4e18e9c8dd9817662e04787eb7eb04217151b,openstack/neutron,master,I67f4e18e9c8dd9817662e04787eb7eb04217151b,Test (don't review),ABANDONED,2014-03-06 10:58:52.000000000,2014-03-06 11:36:40.000000000,,"[{'_account_id': 3}, {'_account_id': 6788}, {'_account_id': 9925}, {'_account_id': 10116}, {'_account_id': 10117}, {'_account_id': 10153}]","[{'number': 1, 'created': '2014-03-06 10:58:52.000000000', 'files': ['neutron/openstack/common/notifier/rpc_notifier2.py', 'neutron/plugins/linuxbridge/lb_neutron_plugin.py', 'neutron/plugins/vmware/dhcpmeta_modes.py', 'neutron/db/db_base_plugin_v2.py', 'neutron/agent/l3_agent.py', 'neutron/tests/unit/test_agent_rpc.py', 'neutron/cmd/usage_audit.py', 'neutron/plugins/openvswitch/agent/ovs_neutron_agent.py', 'neutron/agent/securitygroups_rpc.py', 'neutron/openstack/common/rpc/__init__.py', 'neutron/services/metering/metering_plugin.py', 'neutron/tests/unit/openvswitch/test_ovs_rpcapi.py', 'neutron/services/vpn/device_drivers/ipsec.py', 'neutron/plugins/ml2/drivers/l2pop/rpc.py', 'neutron/plugins/cisco/n1kv/n1kv_neutron_plugin.py', 'neutron/service.py', 'neutron/tests/unit/services/loadbalancer/agent/test_api.py', 'neutron/tests/unit/services/vpn/device_drivers/test_ipsec.py', 'neutron/plugins/vmware/plugins/service.py', 'neutron/tests/unit/services/metering/test_metering_agent.py', 'neutron/openstack/common/rpc/service.py', 'neutron/tests/unit/services/loadbalancer/drivers/test_agent_driver_base.py', 'neutron/openstack/common/rpc/impl_qpid.py', 'neutron/plugins/brocade/NeutronPlugin.py', 'neutron/plugins/midonet/plugin.py', 'neutron/common/config.py', 'neutron/plugins/bigswitch/agent/restproxy_agent.py', 'neutron/tests/unit/mlnx/test_rpcapi.py', 'neutron/plugins/ryu/ryu_neutron_plugin.py', 'neutron/tests/unit/ryu/test_ryu_security_group.py', 'neutron/openstack/common/rpc/matchmaker.py', 'neutron/tests/unit/bigswitch/test_restproxy_agent.py', 'neutron/tests/unit/ryu/test_ryu_agent.py', 'neutron/plugins/mlnx/agent/eswitch_neutron_agent.py', 'neutron/tests/unit/test_extension_extraroute.py', 'neutron/plugins/vmware/dhcp_meta/rpc.py', 'neutron/services/loadbalancer/drivers/common/agent_driver_base.py', 'requirements.txt', 'neutron/tests/unit/services/firewall/agents/test_firewall_agent_api.py', 'neutron/api/rpc/agentnotifiers/metering_rpc_agent_api.py', 'neutron/db/servicetype_db.py', 'neutron/openstack/common/notifier/no_op_notifier.py', 'neutron/api/rpc/agentnotifiers/l3_rpc_agent_api.py', 'neutron/openstack/common/rpc/amqp.py', 'neutron/tests/unit/ofagent/test_ofa_neutron_agent.py', 'neutron/tests/unit/services/firewall/test_fwaas_plugin.py', 'neutron/tests/unit/test_l3_plugin.py', 'neutron/api/rpc/agentnotifiers/dhcp_rpc_agent_api.py', 'neutron/openstack/common/notifier/rpc_notifier.py', 'neutron/plugins/nec/nec_plugin.py', 'neutron/services/firewall/agents/l3reference/firewall_l3_agent.py', 'neutron/openstack/common/notifier/api.py', 'neutron/tests/fake_notifier.py', 'neutron/openstack/common/notifier/rabbit_notifier.py', 'neutron/plugins/ryu/agent/ryu_neutron_agent.py', 'neutron/openstack/common/rpc/impl_fake.py', 'neutron/tests/unit/services/metering/test_metering_plugin.py', 'neutron/openstack/common/rpc/dispatcher.py', 'neutron/tests/unit/ml2/test_security_group.py', 'neutron/openstack/common/rpc/zmq_receiver.py', 'neutron/services/l3_router/l3_router_plugin.py', 'neutron/openstack/common/service.py', 'neutron/plugins/mlnx/rpc_callbacks.py', 'neutron/tests/unit/test_api_v2.py', 'neutron/plugins/ibm/sdnve_neutron_plugin.py', 'neutron/db/vpn/vpn_db.py', 'neutron/services/loadbalancer/agent/agent_api.py', 'neutron/tests/unit/openvswitch/test_ovs_security_group.py', 'neutron/tests/unit/ml2/test_rpcapi.py', 'neutron/openstack/common/notifier/__init__.py', 'neutron/tests/unit/ml2/test_port_binding.py', 'neutron/plugins/mlnx/agent_notify_api.py', 'neutron/tests/unit/linuxbridge/test_lb_neutron_agent.py', 'neutron/tests/unit/services/vpn/service_drivers/test_ipsec.py', 'neutron/services/loadbalancer/agent/agent.py', 'neutron/services/firewall/fwaas_plugin.py', 'neutron/openstack/common/notifier/test_notifier.py', 'neutron/plugins/hyperv/hyperv_neutron_plugin.py', 'neutron/common/rpc.py', 'neutron/tests/unit/openvswitch/test_agent_scheduler.py', 'openstack-common.conf', 'neutron/openstack/common/notifier/log_notifier.py', 'neutron/tests/unit/test_dhcp_agent.py', 'neutron/plugins/mlnx/mlnx_plugin.py', 'neutron/api/v2/base.py', 'neutron/plugins/ml2/rpc.py', 'neutron/tests/unit/ml2/test_ml2_plugin.py', 'neutron/services/metering/agents/metering_agent.py', 'neutron/plugins/vmware/vshield/edge_appliance_driver.py', 'neutron/openstack/common/log_handler.py', 'neutron/db/l3_db.py', 'neutron/plugins/ml2/drivers/type_tunnel.py', 'neutron/agent/rpc.py', 'neutron/services/firewall/agents/firewall_agent_api.py', 'neutron/tests/unit/services/loadbalancer/agent/test_agent.py', 'neutron/plugins/nec/agent/nec_neutron_agent.py', 'neutron/plugins/bigswitch/plugin.py', 'neutron/openstack/common/rpc/matchmaker_redis.py', 'neutron/plugins/hyperv/rpc_callbacks.py', 'neutron/tests/unit/bigswitch/test_restproxy_plugin.py', 'neutron/openstack/common/rpc/serializer.py', 'neutron/tests/unit/hyperv/test_hyperv_rpcapi.py', 'setup.cfg', 'neutron/openstack/common/rpc/impl_zmq.py', 'neutron/tests/unit/linuxbridge/test_rpcapi.py', 'neutron/openstack/common/rpc/proxy.py', 'neutron/tests/unit/test_security_groups_rpc.py', 'neutron/plugins/openvswitch/ovs_neutron_plugin.py', 'neutron/services/vpn/service_drivers/__init__.py', 'neutron/openstack/common/rpc/common.py', 'neutron/plugins/ibm/agent/sdnve_neutron_agent.py', 'neutron/plugins/ml2/plugin.py', 'neutron/tests/unit/api/rpc/agentnotifiers/test_dhcp_rpc_agent_api.py', 'neutron/plugins/ofagent/agent/ofa_neutron_agent.py', 'neutron/agent/dhcp_agent.py', 'neutron/plugins/linuxbridge/agent/linuxbridge_neutron_agent.py', 'neutron/tests/unit/vmware/vshield/test_vcns_driver.py', 'neutron/openstack/common/rpc/impl_kombu.py', 'neutron/plugins/hyperv/agent/hyperv_neutron_agent.py', 'neutron/plugins/nec/common/config.py', 'neutron/plugins/hyperv/agent_notifier_api.py', 'neutron/openstack/common/rpc/matchmaker_ring.py', 'neutron/tests/base.py', 'neutron/agent/metadata/agent.py', 'neutron/tests/unit/nec/test_nec_agent.py', 'neutron/services/vpn/service_drivers/cisco_ipsec.py', 'neutron/services/vpn/service_drivers/ipsec.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/9c3fdd42933a220ce0ca667d215f695fd1e29e65', 'message': ""Test (don't review)\n\nChange-Id: I67f4e18e9c8dd9817662e04787eb7eb04217151b\n""}]",0,78580,9c3fdd42933a220ce0ca667d215f695fd1e29e65,8,6,1,9656,,,0,"Test (don't review)

Change-Id: I67f4e18e9c8dd9817662e04787eb7eb04217151b
",git fetch https://review.opendev.org/openstack/neutron refs/changes/80/78580/1 && git format-patch -1 --stdout FETCH_HEAD,"['neutron/openstack/common/notifier/rpc_notifier2.py', 'neutron/plugins/linuxbridge/lb_neutron_plugin.py', 'neutron/plugins/vmware/dhcpmeta_modes.py', 'neutron/db/db_base_plugin_v2.py', 'neutron/agent/l3_agent.py', 'neutron/tests/unit/test_agent_rpc.py', 'neutron/cmd/usage_audit.py', 'neutron/plugins/openvswitch/agent/ovs_neutron_agent.py', 'neutron/agent/securitygroups_rpc.py', 'neutron/openstack/common/rpc/__init__.py', 'neutron/services/metering/metering_plugin.py', 'neutron/tests/unit/openvswitch/test_ovs_rpcapi.py', 'neutron/services/vpn/device_drivers/ipsec.py', 'neutron/plugins/ml2/drivers/l2pop/rpc.py', 'neutron/plugins/cisco/n1kv/n1kv_neutron_plugin.py', 'neutron/service.py', 'neutron/tests/unit/services/loadbalancer/agent/test_api.py', 'neutron/tests/unit/services/vpn/device_drivers/test_ipsec.py', 'neutron/plugins/vmware/plugins/service.py', 'neutron/tests/unit/services/metering/test_metering_agent.py', 'neutron/openstack/common/rpc/service.py', 'neutron/tests/unit/services/loadbalancer/drivers/test_agent_driver_base.py', 'neutron/openstack/common/rpc/impl_qpid.py', 'neutron/plugins/brocade/NeutronPlugin.py', 'neutron/plugins/midonet/plugin.py', 'neutron/common/config.py', 'neutron/plugins/bigswitch/agent/restproxy_agent.py', 'neutron/tests/unit/mlnx/test_rpcapi.py', 'neutron/plugins/ryu/ryu_neutron_plugin.py', 'neutron/tests/unit/ryu/test_ryu_security_group.py', 'neutron/openstack/common/rpc/matchmaker.py', 'neutron/tests/unit/bigswitch/test_restproxy_agent.py', 'neutron/tests/unit/ryu/test_ryu_agent.py', 'neutron/plugins/mlnx/agent/eswitch_neutron_agent.py', 'neutron/tests/unit/test_extension_extraroute.py', 'neutron/plugins/vmware/dhcp_meta/rpc.py', 'neutron/services/loadbalancer/drivers/common/agent_driver_base.py', 'requirements.txt', 'neutron/tests/unit/services/firewall/agents/test_firewall_agent_api.py', 'neutron/api/rpc/agentnotifiers/metering_rpc_agent_api.py', 'neutron/db/servicetype_db.py', 'neutron/openstack/common/notifier/no_op_notifier.py', 'neutron/api/rpc/agentnotifiers/l3_rpc_agent_api.py', 'neutron/openstack/common/rpc/amqp.py', 'neutron/tests/unit/ofagent/test_ofa_neutron_agent.py', 'neutron/tests/unit/services/firewall/test_fwaas_plugin.py', 'neutron/tests/unit/test_l3_plugin.py', 'neutron/api/rpc/agentnotifiers/dhcp_rpc_agent_api.py', 'neutron/openstack/common/notifier/rpc_notifier.py', 'neutron/plugins/nec/nec_plugin.py', 'neutron/services/firewall/agents/l3reference/firewall_l3_agent.py', 'neutron/openstack/common/notifier/api.py', 'neutron/tests/fake_notifier.py', 'neutron/openstack/common/notifier/rabbit_notifier.py', 'neutron/plugins/ryu/agent/ryu_neutron_agent.py', 'neutron/openstack/common/rpc/impl_fake.py', 'neutron/tests/unit/services/metering/test_metering_plugin.py', 'neutron/openstack/common/rpc/dispatcher.py', 'neutron/tests/unit/ml2/test_security_group.py', 'neutron/openstack/common/rpc/zmq_receiver.py', 'neutron/services/l3_router/l3_router_plugin.py', 'neutron/openstack/common/service.py', 'neutron/plugins/mlnx/rpc_callbacks.py', 'neutron/tests/unit/test_api_v2.py', 'neutron/plugins/ibm/sdnve_neutron_plugin.py', 'neutron/db/vpn/vpn_db.py', 'neutron/services/loadbalancer/agent/agent_api.py', 'neutron/tests/unit/openvswitch/test_ovs_security_group.py', 'neutron/tests/unit/ml2/test_rpcapi.py', 'neutron/openstack/common/notifier/__init__.py', 'neutron/tests/unit/ml2/test_port_binding.py', 'neutron/plugins/mlnx/agent_notify_api.py', 'neutron/tests/unit/linuxbridge/test_lb_neutron_agent.py', 'neutron/tests/unit/services/vpn/service_drivers/test_ipsec.py', 'neutron/services/loadbalancer/agent/agent.py', 'neutron/services/firewall/fwaas_plugin.py', 'neutron/openstack/common/notifier/test_notifier.py', 'neutron/plugins/hyperv/hyperv_neutron_plugin.py', 'neutron/common/rpc.py', 'neutron/tests/unit/openvswitch/test_agent_scheduler.py', 'openstack-common.conf', 'neutron/openstack/common/notifier/log_notifier.py', 'neutron/tests/unit/test_dhcp_agent.py', 'neutron/plugins/mlnx/mlnx_plugin.py', 'neutron/api/v2/base.py', 'neutron/plugins/ml2/rpc.py', 'neutron/tests/unit/ml2/test_ml2_plugin.py', 'neutron/services/metering/agents/metering_agent.py', 'neutron/plugins/vmware/vshield/edge_appliance_driver.py', 'neutron/openstack/common/log_handler.py', 'neutron/db/l3_db.py', 'neutron/plugins/ml2/drivers/type_tunnel.py', 'neutron/agent/rpc.py', 'neutron/services/firewall/agents/firewall_agent_api.py', 'neutron/tests/unit/services/loadbalancer/agent/test_agent.py', 'neutron/plugins/nec/agent/nec_neutron_agent.py', 'neutron/plugins/bigswitch/plugin.py', 'neutron/openstack/common/rpc/matchmaker_redis.py', 'neutron/plugins/hyperv/rpc_callbacks.py', 'neutron/tests/unit/bigswitch/test_restproxy_plugin.py', 'neutron/openstack/common/rpc/serializer.py', 'neutron/tests/unit/hyperv/test_hyperv_rpcapi.py', 'setup.cfg', 'neutron/openstack/common/rpc/impl_zmq.py', 'neutron/tests/unit/linuxbridge/test_rpcapi.py', 'neutron/openstack/common/rpc/proxy.py', 'neutron/tests/unit/test_security_groups_rpc.py', 'neutron/plugins/openvswitch/ovs_neutron_plugin.py', 'neutron/services/vpn/service_drivers/__init__.py', 'neutron/openstack/common/rpc/common.py', 'neutron/plugins/ibm/agent/sdnve_neutron_agent.py', 'neutron/plugins/ml2/plugin.py', 'neutron/tests/unit/api/rpc/agentnotifiers/test_dhcp_rpc_agent_api.py', 'neutron/plugins/ofagent/agent/ofa_neutron_agent.py', 'neutron/agent/dhcp_agent.py', 'neutron/plugins/linuxbridge/agent/linuxbridge_neutron_agent.py', 'neutron/tests/unit/vmware/vshield/test_vcns_driver.py', 'neutron/openstack/common/rpc/impl_kombu.py', 'neutron/plugins/hyperv/agent/hyperv_neutron_agent.py', 'neutron/plugins/nec/common/config.py', 'neutron/plugins/hyperv/agent_notifier_api.py', 'neutron/openstack/common/rpc/matchmaker_ring.py', 'neutron/tests/base.py', 'neutron/agent/metadata/agent.py', 'neutron/tests/unit/nec/test_nec_agent.py', 'neutron/services/vpn/service_drivers/cisco_ipsec.py', 'neutron/services/vpn/service_drivers/ipsec.py']",127,9c3fdd42933a220ce0ca667d215f695fd1e29e65,bp/oslo-messaging,"from oslo.config import cfg from oslo import messaging from neutron.common import rpc super(IPsecVpnAgentApi, self).__init__() target = messaging.Target(topic=topics.IPSEC_AGENT_TOPIC, version=default_version) self.client = rpc.get_client(target) self.callbacks = [IPsecVpnDriverCallBack(self)] target = messaging.Target(server=cfg.CONF.host, topic=topics.IPSEC_DRIVER_TOPIC) self.rpc_server = rpc.get_server(target, endpoints=self.callbacks) self.rpc_server.start() ","from neutron.common import rpc as n_rpcfrom neutron.openstack.common import rpc def create_rpc_dispatcher(self): return n_rpc.PluginRpcDispatcher([self]) super(IPsecVpnAgentApi, self).__init__( topics.IPSEC_AGENT_TOPIC, topic, default_version) self.callbacks = IPsecVpnDriverCallBack(self) self.conn = rpc.create_connection(new=True) self.conn.create_consumer( topics.IPSEC_DRIVER_TOPIC, self.callbacks.create_rpc_dispatcher(), fanout=False) self.conn.consume_in_thread()",1582,7425
openstack%2Fneutron~master~I149cc0ab7bde08ea83057e6c0697f668edbe29db,openstack/neutron,master,I149cc0ab7bde08ea83057e6c0697f668edbe29db,Replaces network:* strings by constants,MERGED,2014-01-20 16:00:43.000000000,2014-03-06 11:33:26.000000000,2014-03-06 11:33:24.000000000,"[{'_account_id': 3}, {'_account_id': 55}, {'_account_id': 261}, {'_account_id': 841}, {'_account_id': 2592}, {'_account_id': 4727}, {'_account_id': 5170}, {'_account_id': 5948}, {'_account_id': 6072}, {'_account_id': 6316}, {'_account_id': 6524}, {'_account_id': 6598}, {'_account_id': 6659}, {'_account_id': 7141}, {'_account_id': 9008}, {'_account_id': 9681}, {'_account_id': 9682}, {'_account_id': 9732}, {'_account_id': 9787}, {'_account_id': 9845}, {'_account_id': 9925}, {'_account_id': 10116}, {'_account_id': 10117}, {'_account_id': 10153}, {'_account_id': 10184}, {'_account_id': 10192}, {'_account_id': 10294}, {'_account_id': 10387}]","[{'number': 1, 'created': '2014-01-20 16:00:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/01092dd12e968fabf90052136f63afb2a355313f', 'message': 'Replaces network:dhcp by the constant DEVICE_OWNER_DHCP\n\nThis patch replaces all occurences of the string\nnetwork:dhcp by the constant DEVICE_OWNER_DHCP\n\nCloses-bug: #1270863\nChange-Id: I149cc0ab7bde08ea83057e6c0697f668edbe29db\n'}, {'number': 2, 'created': '2014-01-20 23:16:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/2ecf4958aba8bf2d8288f3c4685cae2ff02a395e', 'message': 'Replaces network:dhcp by the constant DEVICE_OWNER_DHCP\n\nThis patch replaces all occurences of the string\nnetwork:dhcp by the constant DEVICE_OWNER_DHCP\n\nCloses-bug: #1270863\nChange-Id: I149cc0ab7bde08ea83057e6c0697f668edbe29db\n'}, {'number': 3, 'created': '2014-01-22 10:42:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/3d0e44a8f7881cd07227eb321a30dd058ce51afc', 'message': 'Replaces network:* strings by constants\n\nThis patch replaces all occurences of the strings\nprefixed by network:* by their constant equivalent.\n\nCloses-bug: #1270863\nChange-Id: I149cc0ab7bde08ea83057e6c0697f668edbe29db\n'}, {'number': 4, 'created': '2014-01-24 10:00:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/a81b9747dae7df2216662f1376e72a4455e954b7', 'message': 'Replaces network:* strings by constants\n\nThis patch replaces all occurences of the strings\nprefixed by network:* by their constant equivalent.\n\nCloses-bug: #1270863\nChange-Id: I149cc0ab7bde08ea83057e6c0697f668edbe29db\n'}, {'number': 5, 'created': '2014-02-23 21:55:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/085b9bf624474c9270172e08a9c9454ea0133dbd', 'message': 'Replaces network:* strings by constants\n\nThis patch replaces all occurences of the strings\nprefixed by network:* by their constant equivalent.\n\nCloses-bug: #1270863\nChange-Id: I149cc0ab7bde08ea83057e6c0697f668edbe29db\n'}, {'number': 6, 'created': '2014-03-03 13:48:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/0e6878f098cb5d88da49743e7e080bd171295060', 'message': 'Replaces network:* strings by constants\n\nThis patch replaces all occurences of the strings\nprefixed by network:* by their constant equivalent.\n\nCloses-bug: #1270863\nChange-Id: I149cc0ab7bde08ea83057e6c0697f668edbe29db\n'}, {'number': 7, 'created': '2014-03-04 07:57:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/516ab956cef368afa9f928e2246a68ea8ed59716', 'message': 'Replaces network:* strings by constants\n\nThis patch replaces all occurences of the strings\nprefixed by network:* by their constant equivalent.\n\nCloses-bug: #1270863\nChange-Id: I149cc0ab7bde08ea83057e6c0697f668edbe29db\n'}, {'number': 8, 'created': '2014-03-05 09:00:44.000000000', 'files': ['neutron/tests/unit/vmware/test_dhcpmeta.py', 'neutron/tests/unit/test_l3_plugin.py', 'neutron/tests/unit/nec/test_nec_plugin.py', 'neutron/tests/unit/test_db_plugin.py', 'neutron/db/db_base_plugin_v2.py', 'neutron/tests/unit/vmware/test_nsx_plugin.py', 'neutron/tests/unit/test_extension_extraroute.py', 'neutron/agent/linux/dhcp.py', 'neutron/plugins/embrane/common/utils.py', 'neutron/plugins/midonet/plugin.py', 'neutron/plugins/bigswitch/plugin.py', 'neutron/plugins/plumgrid/plumgrid_plugin/plumgrid_plugin.py', 'neutron/tests/unit/test_db_rpc_base.py', 'neutron/plugins/vmware/plugins/base.py', 'neutron/agent/metadata/agent.py', 'neutron/plugins/cisco/n1kv/n1kv_neutron_plugin.py', 'neutron/tests/unit/test_metadata_agent.py', 'neutron/db/dhcp_rpc_base.py', 'neutron/plugins/embrane/l2base/openvswitch/openvswitch_support.py', 'neutron/tests/unit/test_linux_dhcp.py', 'neutron/plugins/embrane/l2base/fake/fakeplugin_support.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/fbf0e621399027d5004bbc8c888d67a3c2851686', 'message': 'Replaces network:* strings by constants\n\nThis patch replaces all occurences of the strings\nprefixed by network:* by their constant equivalent.\n\nCloses-bug: #1270863\nChange-Id: I149cc0ab7bde08ea83057e6c0697f668edbe29db\n'}]",3,67862,fbf0e621399027d5004bbc8c888d67a3c2851686,151,28,8,7141,,,0,"Replaces network:* strings by constants

This patch replaces all occurences of the strings
prefixed by network:* by their constant equivalent.

Closes-bug: #1270863
Change-Id: I149cc0ab7bde08ea83057e6c0697f668edbe29db
",git fetch https://review.opendev.org/openstack/neutron refs/changes/62/67862/5 && git format-patch -1 --stdout FETCH_HEAD,"['neutron/plugins/midonet/plugin.py', 'neutron/tests/unit/nec/test_nec_plugin.py', 'neutron/plugins/bigswitch/plugin.py', 'neutron/tests/unit/nicira/test_nicira_plugin.py', 'neutron/tests/unit/test_db_rpc_base.py', 'neutron/tests/unit/test_db_plugin.py', 'neutron/db/db_base_plugin_v2.py', 'neutron/plugins/cisco/n1kv/n1kv_neutron_plugin.py', 'neutron/db/dhcp_rpc_base.py', 'neutron/tests/unit/nicira/test_dhcpmeta.py']",10,01092dd12e968fabf90052136f63afb2a355313f,bug/1270863,"from neutron.common import constants 'device_owner': constants.DEVICE_OWNER_DHCP, 'device_owner': constants.DEVICE_OWNER_DHCP, 'device_owner': [constants.DEVICE_OWNER_DHCP] 'device_owner': constants.DEVICE_OWNER_DHCP, 'device_owner': constants.DEVICE_OWNER_DHCP, constants.DEVICE_OWNER_DHCP, [{'subnet_id': 'foo_subnet'}]) constants.DEVICE_OWNER_DHCP, '')"," 'device_owner': 'network:dhcp', 'device_owner': 'network:dhcp', 'device_owner': ['network:dhcp'] 'device_owner': 'network:dhcp', 'device_owner': 'network:dhcp', 'network:dhcp', [{'subnet_id': 'foo_subnet'}]) 'network:dhcp', '')",24,20
openstack%2Fopenstack-planet~master~Ia706775977d5de7e43da978749c11307c8719e2c,openstack/openstack-planet,master,Ia706775977d5de7e43da978749c11307c8719e2c,Added maishsk to Planet OpenStack Change-Id: Ia706775977d5de7e43da978749c11307c8719e2c,MERGED,2014-03-06 10:32:10.000000000,2014-03-06 11:06:40.000000000,2014-03-06 11:06:39.000000000,"[{'_account_id': 3}, {'_account_id': 308}]","[{'number': 1, 'created': '2014-03-06 10:32:10.000000000', 'files': ['images/maishsk.png', 'planet.ini'], 'web_link': 'https://opendev.org/openstack/openstack-planet/commit/07fc8dc3b9abf2c1fd0b0e685d7be2bd0f480461', 'message': 'Added maishsk to Planet OpenStack\nChange-Id: Ia706775977d5de7e43da978749c11307c8719e2c\n'}]",0,78570,07fc8dc3b9abf2c1fd0b0e685d7be2bd0f480461,6,2,1,10348,,,0,"Added maishsk to Planet OpenStack
Change-Id: Ia706775977d5de7e43da978749c11307c8719e2c
",git fetch https://review.opendev.org/openstack/openstack-planet refs/changes/70/78570/1 && git format-patch -1 --stdout FETCH_HEAD,"['images/maishsk.png', 'planet.ini']",2,07fc8dc3b9abf2c1fd0b0e685d7be2bd0f480461,, [http://technodrone.blogspot.com/feeds/posts/default/-/OpenStack] name = Maish Saidel-Keesing face = maishsk.png nick = maishsk,,5,0
openstack%2Fnova~stable%2Fhavana~I31d74f4267eaa33e798de926069d1a0f63006a59,openstack/nova,stable/havana,I31d74f4267eaa33e798de926069d1a0f63006a59,Retry reservation commit and rollback on deadlock,MERGED,2014-02-11 03:51:06.000000000,2014-03-06 10:58:40.000000000,2014-03-06 10:58:36.000000000,"[{'_account_id': 3}, {'_account_id': 67}, {'_account_id': 1313}, {'_account_id': 1653}, {'_account_id': 1678}, {'_account_id': 5170}, {'_account_id': 8021}]","[{'number': 1, 'created': '2014-02-11 03:51:06.000000000', 'files': ['nova/db/sqlalchemy/api.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/0d3d7c94b34468980469f412739c5a2aaf633c79', 'message': 'Retry reservation commit and rollback on deadlock\n\nReservations can deadlock when concurrent commits are run from\nmultiple hosts on the same project. This fixes the issue by using\nour convienient retry on deadlock feature.\n\nChange-Id: I31d74f4267eaa33e798de926069d1a0f63006a59\nCloses-bug: #1274341\n(cherry picked from commit 9c556d1557a7056d6056b25d3b91ff4abcb97971)\n'}]",0,72546,0d3d7c94b34468980469f412739c5a2aaf633c79,35,7,1,1313,,,0,"Retry reservation commit and rollback on deadlock

Reservations can deadlock when concurrent commits are run from
multiple hosts on the same project. This fixes the issue by using
our convienient retry on deadlock feature.

Change-Id: I31d74f4267eaa33e798de926069d1a0f63006a59
Closes-bug: #1274341
(cherry picked from commit 9c556d1557a7056d6056b25d3b91ff4abcb97971)
",git fetch https://review.opendev.org/openstack/nova refs/changes/46/72546/1 && git format-patch -1 --stdout FETCH_HEAD,['nova/db/sqlalchemy/api.py'],1,0d3d7c94b34468980469f412739c5a2aaf633c79,,@_retry_on_deadlock@_retry_on_deadlock,,2,0
openstack%2Frally~master~Ib8ee8378c1ec19a95931cb5f4f65052cfc9b1a8b,openstack/rally,master,Ib8ee8378c1ec19a95931cb5f4f65052cfc9b1a8b,added decorator-based mocks declaration to,MERGED,2014-03-06 05:05:55.000000000,2014-03-06 10:16:34.000000000,2014-03-06 10:16:34.000000000,"[{'_account_id': 3}, {'_account_id': 6172}, {'_account_id': 7369}, {'_account_id': 10352}]","[{'number': 1, 'created': '2014-03-06 05:05:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/b9b5647fa104b2953aed2a8252b4b259c5314beb', 'message': 'added decorator-based mocks declaration to\n    * test_abort\n    * test_list\n\nChange-Id: Ib8ee8378c1ec19a95931cb5f4f65052cfc9b1a8b\n'}, {'number': 2, 'created': '2014-03-06 08:00:48.000000000', 'files': ['tests/cmd/commands/test_task.py'], 'web_link': 'https://opendev.org/openstack/rally/commit/113e246df76276b9f8bdb9a293aa9591ba0f308e', 'message': 'added decorator-based mocks declaration to\n\n    * test_abort\n    * test_list\n\nChange-Id: Ib8ee8378c1ec19a95931cb5f4f65052cfc9b1a8b\n'}]",0,78520,113e246df76276b9f8bdb9a293aa9591ba0f308e,11,4,2,10352,,,0,"added decorator-based mocks declaration to

    * test_abort
    * test_list

Change-Id: Ib8ee8378c1ec19a95931cb5f4f65052cfc9b1a8b
",git fetch https://review.opendev.org/openstack/rally refs/changes/20/78520/2 && git format-patch -1 --stdout FETCH_HEAD,['tests/cmd/commands/test_task.py'],1,b9b5647fa104b2953aed2a8252b4b259c5314beb,develop2," @mock.patch(""rally.cmd.commands.task.api"") def test_abort(self, mock_api): mock_api.abort_task = mock.MagicMock() self.task.abort(test_uuid) task.api.abort_task.assert_called_once_with(test_uuid) @mock.patch(""rally.cmd.commands.task.db"") def test_list(self, mock_db): mock_db.task_list = mock.MagicMock(return_value=db_response) self.task.list() mock_db.task_list.assert_called_once_with()"," def test_abort(self): with mock.patch(""rally.cmd.commands.task.api"") as mock_api: mock_api.abort_task = mock.MagicMock() self.task.abort(test_uuid) task.api.abort_task.assert_called_once_with(test_uuid) def test_list(self): with mock.patch(""rally.cmd.commands.task.db"") as mock_db: mock_db.task_list = mock.MagicMock(return_value=db_response) self.task.list() mock_db.task_list.assert_called_once_with()",10,10
openstack%2Fmagnetodb~master~Ic1445603eb4fcc476d1b3d2ee72c13307ebaebcc,openstack/magnetodb,master,Ic1445603eb4fcc476d1b3d2ee72c13307ebaebcc,Test discovering logic fixed,MERGED,2014-03-05 20:48:22.000000000,2014-03-06 10:12:25.000000000,2014-03-06 10:12:25.000000000,"[{'_account_id': 3}, {'_account_id': 8188}]","[{'number': 1, 'created': '2014-03-05 20:48:22.000000000', 'files': ['.testr.conf', 'tox.ini'], 'web_link': 'https://opendev.org/openstack/magnetodb/commit/3cd4c85845db255f508087f7f383d132f3fb72ff', 'message': 'Test discovering logic fixed\n\nDefault discovering folder set to magnetodb/tests\ndefault tox filter set to magnetodb/tests/unittests\n\nChange-Id: Ic1445603eb4fcc476d1b3d2ee72c13307ebaebcc\n'}]",0,78407,3cd4c85845db255f508087f7f383d132f3fb72ff,7,2,1,8601,,,0,"Test discovering logic fixed

Default discovering folder set to magnetodb/tests
default tox filter set to magnetodb/tests/unittests

Change-Id: Ic1445603eb4fcc476d1b3d2ee72c13307ebaebcc
",git fetch https://review.opendev.org/openstack/magnetodb refs/changes/07/78407/1 && git format-patch -1 --stdout FETCH_HEAD,"['.testr.conf', 'tox.ini']",2,3cd4c85845db255f508087f7f383d132f3fb72ff,master, python setup.py testr --slowest --testr-args='{posargs:magnetodb.tests.unittests}', python setup.py testr --slowest --testr-args='{posargs}',2,2
openstack%2Fmagnetodb~master~I46cc5f2689862c25680700495ca5721518e16890,openstack/magnetodb,master,I46cc5f2689862c25680700495ca5721518e16890,Fixing a couple spelling mistakes,MERGED,2014-03-06 03:58:09.000000000,2014-03-06 10:01:03.000000000,2014-03-06 10:01:03.000000000,"[{'_account_id': 3}, {'_account_id': 8491}, {'_account_id': 8601}]","[{'number': 1, 'created': '2014-03-06 03:58:09.000000000', 'files': ['doc/deploy_magnetodb_howto.rst'], 'web_link': 'https://opendev.org/openstack/magnetodb/commit/056308b78f46093b1da570bb824a0be47a495cc3', 'message': 'Fixing a couple spelling mistakes\n\nChange-Id: I46cc5f2689862c25680700495ca5721518e16890\n'}]",0,78512,056308b78f46093b1da570bb824a0be47a495cc3,7,3,1,7136,,,0,"Fixing a couple spelling mistakes

Change-Id: I46cc5f2689862c25680700495ca5721518e16890
",git fetch https://review.opendev.org/openstack/magnetodb refs/changes/12/78512/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/deploy_magnetodb_howto.rst'],1,056308b78f46093b1da570bb824a0be47a495cc3,Fix-Spelling,Steps to deploy MagnetoDB are:On example above MagnetoDB is accessible via URL http://172.18.169.205:8080/,Steps to deploy MagnetDB are:On example above MagnetoDB is accessable via URL http://172.18.169.205:8080/,2,2
openstack%2Fpython-keystoneclient~master~Iea570669f054ee98f0a385d7136d2fe57e9dbfb6,openstack/python-keystoneclient,master,Iea570669f054ee98f0a385d7136d2fe57e9dbfb6,Don't provide several scope keys in v3 tokens,ABANDONED,2014-03-05 13:52:34.000000000,2014-03-06 09:59:17.000000000,,"[{'_account_id': 3}, {'_account_id': 4}, {'_account_id': 2218}, {'_account_id': 4328}, {'_account_id': 7191}]","[{'number': 1, 'created': '2014-03-05 13:52:34.000000000', 'files': ['keystoneclient/tests/auth/test_identity_v3.py', 'keystoneclient/auth/identity/v3.py'], 'web_link': 'https://opendev.org/openstack/python-keystoneclient/commit/747d50284527454d445123930ebcb7e3c0a82789', 'message': ""Don't provide several scope keys in v3 tokens\n\nThe patch removes other entries in the auth scope when a trust is\nspecified, instead of adding the entry. The server otherwise fails as it's\nonly able to handle one auth scope key.\n\nChange-Id: Iea570669f054ee98f0a385d7136d2fe57e9dbfb6\nCloses-Bug: #1288223\n""}]",3,78224,747d50284527454d445123930ebcb7e3c0a82789,9,5,1,7385,,,0,"Don't provide several scope keys in v3 tokens

The patch removes other entries in the auth scope when a trust is
specified, instead of adding the entry. The server otherwise fails as it's
only able to handle one auth scope key.

Change-Id: Iea570669f054ee98f0a385d7136d2fe57e9dbfb6
Closes-Bug: #1288223
",git fetch https://review.opendev.org/openstack/python-keystoneclient refs/changes/24/78224/1 && git format-patch -1 --stdout FETCH_HEAD,"['keystoneclient/tests/auth/test_identity_v3.py', 'keystoneclient/auth/identity/v3.py']",2,747d50284527454d445123930ebcb7e3c0a82789,bug/1288223, body['auth']['scope'] = {'OS-TRUST:trust': {'id': self.trust_id}}," scope = body['auth'].setdefault('scope', {}) scope['OS-TRUST:trust'] = {'id': self.trust_id}",16,2
openstack%2Fhorizon~master~I959e5eb9789a83cee20e28e3e3504d8b193454a3,openstack/horizon,master,I959e5eb9789a83cee20e28e3e3504d8b193454a3,Remove copyright in empty __init__ file,MERGED,2014-03-05 06:21:39.000000000,2014-03-06 09:55:49.000000000,2014-03-06 09:55:49.000000000,"[{'_account_id': 3}, {'_account_id': 4264}, {'_account_id': 6914}, {'_account_id': 7642}]","[{'number': 1, 'created': '2014-03-05 06:21:39.000000000', 'files': ['horizon/test/jasmine/__init__.py'], 'web_link': 'https://opendev.org/openstack/horizon/commit/9240b0c13893b7bce5ce0e239bb1e4b9f2770fd4', 'message': 'Remove copyright in empty __init__ file\n\nCloses-Bug: #1288070\n\nChange-Id: I959e5eb9789a83cee20e28e3e3504d8b193454a3\n'}]",0,78112,9240b0c13893b7bce5ce0e239bb1e4b9f2770fd4,10,4,1,7642,,,0,"Remove copyright in empty __init__ file

Closes-Bug: #1288070

Change-Id: I959e5eb9789a83cee20e28e3e3504d8b193454a3
",git fetch https://review.opendev.org/openstack/horizon refs/changes/12/78112/1 && git format-patch -1 --stdout FETCH_HEAD,['horizon/test/jasmine/__init__.py'],1,9240b0c13893b7bce5ce0e239bb1e4b9f2770fd4,bug/1288070,,"# vim: tabstop=4 shiftwidth=4 softtabstop=4 # # Licensed under the Apache License, Version 2.0 (the ""License""); you may # not use this file except in compliance with the License. You may obtain # a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT # WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the # License for the specific language governing permissions and limitations # under the License. ",0,13
openstack%2Frally~master~I4fa5566b7698b6a9285f01fa47a2fd1f179a7502,openstack/rally,master,I4fa5566b7698b6a9285f01fa47a2fd1f179a7502,use CONF in glance benchmark,MERGED,2014-03-05 17:47:44.000000000,2014-03-06 09:34:42.000000000,2014-03-06 09:34:41.000000000,"[{'_account_id': 3}, {'_account_id': 6172}, {'_account_id': 6835}, {'_account_id': 7369}]","[{'number': 1, 'created': '2014-03-05 17:47:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/ef52b7d98f99ce64a49625ceedbaa774bbd8b406', 'message': 'use CONF in glance benchmark\n\nUsing CONF instead of hard codes is a more consistent way in\nbenchmark scenarios.\n\nChange-Id: I4fa5566b7698b6a9285f01fa47a2fd1f179a7502\n'}, {'number': 2, 'created': '2014-03-05 18:23:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/beeb227a56aaf9e8825ffc0fa4cc502ef63e1a7c', 'message': 'use CONF in glance benchmark\n\nUsing CONF instead of hard codes is a more consistent way in\nbenchmark scenarios.\n\nChange-Id: I4fa5566b7698b6a9285f01fa47a2fd1f179a7502\n'}, {'number': 3, 'created': '2014-03-05 18:46:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/c3c2e7fde6ac62e50799ece2b2cb4ad6221100a7', 'message': 'use CONF in glance benchmark\n\nUsing CONF instead of hard codes is a more consistent way in\nbenchmark scenarios.\n\nChange-Id: I4fa5566b7698b6a9285f01fa47a2fd1f179a7502\n'}, {'number': 4, 'created': '2014-03-06 01:20:02.000000000', 'files': ['.gitignore', 'tests/benchmark/scenarios/glance/test_utils.py', 'rally/benchmark/scenarios/glance/utils.py'], 'web_link': 'https://opendev.org/openstack/rally/commit/1a0f3f1ca89aab6e7a929607f8c3685802b9f449', 'message': 'use CONF in glance benchmark\n\nUsing CONF instead of hard codes is a more consistent way in\nbenchmark scenarios.\n\nChange-Id: I4fa5566b7698b6a9285f01fa47a2fd1f179a7502\n'}]",3,78325,1a0f3f1ca89aab6e7a929607f8c3685802b9f449,18,4,4,6835,,,0,"use CONF in glance benchmark

Using CONF instead of hard codes is a more consistent way in
benchmark scenarios.

Change-Id: I4fa5566b7698b6a9285f01fa47a2fd1f179a7502
",git fetch https://review.opendev.org/openstack/rally refs/changes/25/78325/3 && git format-patch -1 --stdout FETCH_HEAD,['rally/benchmark/scenarios/glance/utils.py'],1,ef52b7d98f99ce64a49625ceedbaa774bbd8b406,use_CONF_in_glance_benchmark,"from oslo.config import cfgglance_benchmark_opts = [ cfg.FloatOpt('glance_image_create_prepoll_delay', default=5, help='Time to sleep after creating a resource before ' 'polling for it status'), cfg.FloatOpt('glance_image_create_timeout', default=120, help='Time to wait for glance image to be created.'), cfg.FloatOpt('glance_image_create_poll_interval', default=3, help='Interval between checks when waiting for image ' 'creation.'), cfg.FloatOpt('glance_image_delete_timeout', default=120, help='Time to wait for glance image to be deleted.'), cfg.FloatOpt('glance_image_delete_poll_interval', default=5, help='Interval between checks when waiting for image ' 'deletion.') ] CONF = cfg.CONF benchmark_group = cfg.OptGroup(name='benchmark', title='benchmark options') CONF.register_opts(glance_benchmark_opts, group=benchmark_group) time.sleep(CONF.benchmark.glance_image_create_prepoll_delay) timeout=CONF.benchmark.glance_image_create_timeout, check_interval=CONF.benchmark.glance_image_create_poll_interval) timeout=CONF.benchmark.glance_image_delete_timeout, check_interval=CONF.benchmark.glance_image_delete_poll_interval)"," time.sleep(5) timeout=120, check_interval=3) timeout=120, check_interval=3)",33,3
openstack%2Fhorizon~master~I3b9b36e9a6caa8960a6598f13d7f21ddadb9a306,openstack/horizon,master,I3b9b36e9a6caa8960a6598f13d7f21ddadb9a306,Updated from global requirements,MERGED,2014-03-05 19:23:27.000000000,2014-03-06 09:31:26.000000000,2014-03-06 09:31:25.000000000,"[{'_account_id': 3}, {'_account_id': 4264}, {'_account_id': 4978}, {'_account_id': 6610}, {'_account_id': 6914}]","[{'number': 1, 'created': '2014-03-05 19:23:27.000000000', 'files': ['requirements.txt', 'test-requirements.txt'], 'web_link': 'https://opendev.org/openstack/horizon/commit/8716814494fe2e1454f7737246a65aa1efb0ebb9', 'message': 'Updated from global requirements\n\nChange-Id: I3b9b36e9a6caa8960a6598f13d7f21ddadb9a306\n'}]",0,78376,8716814494fe2e1454f7737246a65aa1efb0ebb9,10,5,1,3,,,0,"Updated from global requirements

Change-Id: I3b9b36e9a6caa8960a6598f13d7f21ddadb9a306
",git fetch https://review.opendev.org/openstack/horizon refs/changes/76/78376/1 && git format-patch -1 --stdout FETCH_HEAD,"['requirements.txt', 'test-requirements.txt']",2,8716814494fe2e1454f7737246a65aa1efb0ebb9,openstack/requirements,"docutils==0.9.1sphinx>=1.1.2,<1.2","docutils==0.9.1 # for bug 1091333, remove after sphinx >1.1.3 is released.sphinx>=1.1.2,<1.2 # Docs Requirements",3,3
openstack%2Frally~master~Ib0c511816f298e805187eb1644e2a5a204169835,openstack/rally,master,Ib0c511816f298e805187eb1644e2a5a204169835,ignore build dir in tox.ini,MERGED,2014-03-06 04:23:59.000000000,2014-03-06 09:25:38.000000000,2014-03-06 09:25:38.000000000,"[{'_account_id': 3}, {'_account_id': 6172}, {'_account_id': 7369}]","[{'number': 1, 'created': '2014-03-06 04:23:59.000000000', 'files': ['tox.ini'], 'web_link': 'https://opendev.org/openstack/rally/commit/bc29a093c921df60099c3e7aa421034bf11a6345', 'message': ""ignore build dir in tox.ini\n\nThere'll be some temporary source codes of pip package in build\ndirectory. The file .gitignore has already ingored it, but tox.ini\ndidn't exclude it and maybe fail in pep8 checking for these source\ncodes. So just ingore it.\n\nChange-Id: Ib0c511816f298e805187eb1644e2a5a204169835\n""}]",0,78516,bc29a093c921df60099c3e7aa421034bf11a6345,7,3,1,6835,,,0,"ignore build dir in tox.ini

There'll be some temporary source codes of pip package in build
directory. The file .gitignore has already ingored it, but tox.ini
didn't exclude it and maybe fail in pep8 checking for these source
codes. So just ingore it.

Change-Id: Ib0c511816f298e805187eb1644e2a5a204169835
",git fetch https://review.opendev.org/openstack/rally refs/changes/16/78516/1 && git format-patch -1 --stdout FETCH_HEAD,['tox.ini'],1,bc29a093c921df60099c3e7aa421034bf11a6345,ignore_build_dir_in_tox,"exclude=.venv,.git,.tox,dist,doc,*lib/python*,*egg,tools,*rally/verification/verifiers/tempest/openstack-tempest*,build","exclude=.venv,.git,.tox,dist,doc,*lib/python*,*egg,tools,*rally/verification/verifiers/tempest/openstack-tempest*",1,1
openstack%2Fopenstack-doc-tools~master~I4ea72b3e352d7a79fbf9280ab55b5db82303546a,openstack/openstack-doc-tools,master,I4ea72b3e352d7a79fbf9280ab55b5db82303546a,Check for <th> inside <thead>,ABANDONED,2014-03-03 20:26:08.000000000,2014-03-06 09:19:38.000000000,,"[{'_account_id': 3}, {'_account_id': 964}, {'_account_id': 1441}, {'_account_id': 2448}, {'_account_id': 6547}, {'_account_id': 7472}, {'_account_id': 7923}]","[{'number': 1, 'created': '2014-03-03 20:26:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-doc-tools/commit/fc123834cc5638edf1b10d3ace84e6519383b903', 'message': 'Check for <td> inside <thead>\n\nInside <thead> we should use <th> and not <td>. Check for these\ncases as part of the syntax check.\n\nChange-Id: I4ea72b3e352d7a79fbf9280ab55b5db82303546a\n'}, {'number': 2, 'created': '2014-03-03 21:00:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-doc-tools/commit/b47bdae7c60cb7defb6aec900ff7b050f76ab6bf', 'message': 'Check for <th> inside <thead>\n\nInside <thead> we should use <td> and not <th>. Check for these\ncases as part of the syntax check.\n\nChange-Id: I4ea72b3e352d7a79fbf9280ab55b5db82303546a\n'}, {'number': 3, 'created': '2014-03-03 21:01:01.000000000', 'files': ['os_doc_tools/doctest.py', 'README.rst'], 'web_link': 'https://opendev.org/openstack/openstack-doc-tools/commit/dffba7a5f94f016c734a05ef502d86ff32b23892', 'message': 'Check for <th> inside <thead>\n\nInside <thead> we should use <td> and not <th>. Check for these\ncases as part of the syntax check.\n\nChange-Id: I4ea72b3e352d7a79fbf9280ab55b5db82303546a\n'}]",1,77690,dffba7a5f94f016c734a05ef502d86ff32b23892,24,7,3,6547,,,0,"Check for <th> inside <thead>

Inside <thead> we should use <td> and not <th>. Check for these
cases as part of the syntax check.

Change-Id: I4ea72b3e352d7a79fbf9280ab55b5db82303546a
",git fetch https://review.opendev.org/openstack/openstack-doc-tools refs/changes/90/77690/1 && git format-patch -1 --stdout FETCH_HEAD,"['os_doc_tools/doctest.py', 'README.rst']",2,fc123834cc5638edf1b10d3ace84e6519383b903,check-th, * Check for wrong usage of <td> instead of <th> inside <thead>.,,20,0
openstack%2Fpuppet-neutron~stable%2Fhavana~I174cf06b9e8355bfe499b23f390d4078dc670e72,openstack/puppet-neutron,stable/havana,I174cf06b9e8355bfe499b23f390d4078dc670e72,Fix FWaaS race condition,MERGED,2014-03-05 21:36:22.000000000,2014-03-06 09:00:28.000000000,2014-03-06 09:00:28.000000000,"[{'_account_id': 3}, {'_account_id': 3153}, {'_account_id': 6967}, {'_account_id': 6994}, {'_account_id': 7822}]","[{'number': 1, 'created': '2014-03-05 21:36:22.000000000', 'files': ['spec/classes/neutron_services_fwaas_spec.rb', 'manifests/services/fwaas.pp'], 'web_link': 'https://opendev.org/openstack/puppet-neutron/commit/a56f2d6b64e2e8f3cdd20192d99024b8d11b5dcf', 'message': ""Fix FWaaS race condition\n\nThe current FWaaS manifest suffers from a race condition: it may\nattempt to configure the FWaaS service before the Neutron packages\non which it depends has been installed, and before the\n/etc/neutron directory exists.  This leads to errors on the first\ncatalog run, and the FWaaS service doesn't start.  The errors\ngo away on the second catalog run since by then the requisite\ndirectory exists.  This patch adds ordering such that the packages\non which the FWaaS service relies are installed before the FWaaS\nservice is configured.\n\nChange-Id: I174cf06b9e8355bfe499b23f390d4078dc670e72\nCloses-Bug: #1287554\n(cherry picked from commit cfedc81cb60cabdbb31f3809e9d56a54d771458b)\n""}]",0,78423,a56f2d6b64e2e8f3cdd20192d99024b8d11b5dcf,8,5,1,6754,,,0,"Fix FWaaS race condition

The current FWaaS manifest suffers from a race condition: it may
attempt to configure the FWaaS service before the Neutron packages
on which it depends has been installed, and before the
/etc/neutron directory exists.  This leads to errors on the first
catalog run, and the FWaaS service doesn't start.  The errors
go away on the second catalog run since by then the requisite
directory exists.  This patch adds ordering such that the packages
on which the FWaaS service relies are installed before the FWaaS
service is configured.

Change-Id: I174cf06b9e8355bfe499b23f390d4078dc670e72
Closes-Bug: #1287554
(cherry picked from commit cfedc81cb60cabdbb31f3809e9d56a54d771458b)
",git fetch https://review.opendev.org/openstack/puppet-neutron refs/changes/23/78423/1 && git format-patch -1 --stdout FETCH_HEAD,"['spec/classes/neutron_services_fwaas_spec.rb', 'manifests/services/fwaas.pp']",2,a56f2d6b64e2e8f3cdd20192d99024b8d11b5dcf,," include neutron::params if $::neutron::params::l3_agent_package { ensure_resource( 'package', $::neutron::params::l3_agent_package, { 'ensure' => $neutron::package_ensure }) Package[$::neutron::params::l3_agent_package] -> Neutron_fwaas_service_config<||> } else { ensure_resource( 'package', $::neutron::params::package_name, { 'ensure' => $neutron::package_ensure }) Package[$::neutron::params::package_name] -> Neutron_fwaas_service_config<||> } ",,33,7
openstack%2Fneutron~master~I19a24a85a23029dd42a1377c9c8987ef69dc7105,openstack/neutron,master,I19a24a85a23029dd42a1377c9c8987ef69dc7105,Add script for populating loadbalancer table after migration,ABANDONED,2014-03-05 16:36:36.000000000,2014-03-06 08:59:45.000000000,,"[{'_account_id': 3}, {'_account_id': 5170}, {'_account_id': 5948}, {'_account_id': 6072}, {'_account_id': 6788}, {'_account_id': 8655}, {'_account_id': 9787}, {'_account_id': 9845}, {'_account_id': 9925}, {'_account_id': 10116}, {'_account_id': 10117}, {'_account_id': 10153}, {'_account_id': 10184}, {'_account_id': 10294}, {'_account_id': 10387}]","[{'number': 1, 'created': '2014-03-05 16:36:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/bf3933021e8a72677b4db03f4b94efd7708a8196', 'message': 'Add script for populating LB table after migration\n\nThere is a new table for loadbalancer called\nproviderresourceassociations which is empty after upgrade from grizzly.\nThis scripts populates this table which prevents neutron-server start to\nfail.\n\nChange-Id: I19a24a85a23029dd42a1377c9c8987ef69dc7105\nCloses-bug: #1288321\n'}, {'number': 2, 'created': '2014-03-06 07:10:27.000000000', 'files': ['tools/associate_lbaas_provider.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/c3ef25c9e8a5d915607f6c4ebf92d462e8414c05', 'message': 'Add script for populating loadbalancer table after migration\n\nThere is a new table for loadbalancer called\nproviderresourceassociations which is empty after upgrade from grizzly.\nThis scripts associates this table with pools table in order to fix\nfailure during neutron-server start.\n\nChange-Id: I19a24a85a23029dd42a1377c9c8987ef69dc7105\nCloses-bug: #1288321\n'}]",2,78293,c3ef25c9e8a5d915607f6c4ebf92d462e8414c05,26,15,2,8655,,,0,"Add script for populating loadbalancer table after migration

There is a new table for loadbalancer called
providerresourceassociations which is empty after upgrade from grizzly.
This scripts associates this table with pools table in order to fix
failure during neutron-server start.

Change-Id: I19a24a85a23029dd42a1377c9c8987ef69dc7105
Closes-bug: #1288321
",git fetch https://review.opendev.org/openstack/neutron refs/changes/93/78293/1 && git format-patch -1 --stdout FETCH_HEAD,['tools/populate_lb_provider.py'],1,bf3933021e8a72677b4db03f4b94efd7708a8196,bug/1288321,"#!/usr/bin/env python # # Copyright (C) 2014, Red Hat, Inc. # # Licensed under the Apache License, Version 2.0 (the ""License""); you may # not use this file except in compliance with the License. You may obtain # a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT # WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the # License for the specific language governing permissions and limitations # under the License. """""" This script populates providerresourceassociations table needed by loadbalancer. This table was introduced in havana and is empty after db migration from grizzly to havana causing neutron-server fail to start. Script should be run after issuing neutron-db-manage from grizzly and before neutron-server is started. Example usage: ./populate_lb_table.py mysql://login:pass@127.0.0.1/neutron """""" import argparse import sqlalchemy as sa import neutron # noqa def populate_empty_table(connection_url, provider): engine = sa.create_engine(connection_url) engine.execute(""INSERT INTO providerresourceassociations "" ""(resource_id, provider_name)"" "" SELECT id, '%s' FROM pools"" % provider) def main(): description = _(""Tool for populating providerresourceassociations table "" ""which is empty after upgrade from grizzly to havana. "" ""This table is used only when loadbalancer is used."") parser = argparse.ArgumentParser(description=description) parser.add_argument('connection', help=_('the connection url to database')) parser.add_argument('-p', '--provider', default='haproxy', help=_(""which provider is used for load balancer"")) args = parser.parse_args() populate_empty_table(args.connection, args.provider) if __name__ == '__main__': main() ",,58,0
openstack%2Fopenstack-manuals~master~I8ea4ef7d856cecc136fb1207353c905f17e4b6ee,openstack/openstack-manuals,master,I8ea4ef7d856cecc136fb1207353c905f17e4b6ee,Added note for decommissioning block storage nodes,MERGED,2014-02-18 04:36:09.000000000,2014-03-06 08:54:31.000000000,2014-03-06 08:54:30.000000000,"[{'_account_id': 3}, {'_account_id': 612}, {'_account_id': 2448}, {'_account_id': 6547}, {'_account_id': 6772}, {'_account_id': 7244}, {'_account_id': 7923}, {'_account_id': 9355}]","[{'number': 1, 'created': '2014-02-18 04:36:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/7fe9fea6cc97591afbd7ce2bea2697bf804b2c6e', 'message': 'Added note for decommissioning block storage nodes\n\nWhen decommissioning a block storage node, it is advisable to prevent\nany volumes from being allocated there before migrating volumes out of\nthe node. Added a recommendation in volume migration instructions.\n\nChange-Id: I8ea4ef7d856cecc136fb1207353c905f17e4b6ee\nPartial-Bug: #1279179\n'}, {'number': 2, 'created': '2014-02-20 06:42:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/57dca85c9b694d373453b572be23d764acb71452', 'message': 'Added note for decommissioning block storage nodes\n\nWhen decommissioning a block storage node, it is advisable to prevent\nany volumes from being allocated there before migrating volumes out of\nthe node. Added a recommendation in volume migration instructions.\n\nChange-Id: I8ea4ef7d856cecc136fb1207353c905f17e4b6ee\nPartial-Bug: #1279179\n'}, {'number': 3, 'created': '2014-02-21 00:00:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/9da5cf73699f317d5adf839bf1a031152bee9292', 'message': 'Added note for decommissioning block storage nodes\n\nWhen decommissioning a block storage node, it is advisable to prevent\nany volumes from being allocated there before migrating volumes out of\nthe node. Added a recommendation in volume migration instructions for\nRed Hat Enterprise Linux/Fedora/CentOS and Debian/Ubuntu.\n\nChange-Id: I8ea4ef7d856cecc136fb1207353c905f17e4b6ee\nPartial-Bug: #1279179\n'}, {'number': 4, 'created': '2014-02-24 01:14:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/4ff3386d26309dd0d966171335de8d3f0e29cd6f', 'message': 'Added note for decommissioning block storage nodes\n\nWhen decommissioning a block storage node, it is advisable to prevent\nany volumes from being allocated there before migrating volumes out of\nthe node. Added a recommendation in volume migration instructions for\nRed Hat Enterprise Linux/Fedora/CentOS and Debian/Ubuntu.\n\nChange-Id: I8ea4ef7d856cecc136fb1207353c905f17e4b6ee\nPartial-Bug: #1279179\n'}, {'number': 5, 'created': '2014-03-06 00:09:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/139175db5ab158c195e86f3a1e1d7d5ca1b39d91', 'message': 'Added note for decommissioning block storage nodes\n\nWhen decommissioning a block storage node, it is advisable to prevent\nany volumes from being allocated there before migrating volumes out of\nthe node. Added a recommendation in volume migration instructions for\nRed Hat Enterprise Linux/Fedora/CentOS and Debian/Ubuntu.\n\nChange-Id: I8ea4ef7d856cecc136fb1207353c905f17e4b6ee\nPartial-Bug: #1279179\n'}, {'number': 6, 'created': '2014-03-06 01:43:19.000000000', 'files': ['doc/admin-guide-cloud/section_volume-migration.xml'], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/ce9f00625d6d7b4e863e0d13c7e4b9866725cd5f', 'message': 'Added note for decommissioning block storage nodes\n\nWhen decommissioning a block storage node, it is advisable to prevent\nany volumes from being allocated there before migrating volumes out of\nthe node. Added a recommendation in volume migration instructions for\nRed Hat Enterprise Linux/Fedora/CentOS and Debian/Ubuntu.\n\nChange-Id: I8ea4ef7d856cecc136fb1207353c905f17e4b6ee\nPartial-Bug: #1279179\n'}]",12,74262,ce9f00625d6d7b4e863e0d13c7e4b9866725cd5f,34,8,6,9355,,,0,"Added note for decommissioning block storage nodes

When decommissioning a block storage node, it is advisable to prevent
any volumes from being allocated there before migrating volumes out of
the node. Added a recommendation in volume migration instructions for
Red Hat Enterprise Linux/Fedora/CentOS and Debian/Ubuntu.

Change-Id: I8ea4ef7d856cecc136fb1207353c905f17e4b6ee
Partial-Bug: #1279179
",git fetch https://review.opendev.org/openstack/openstack-manuals refs/changes/62/74262/5 && git format-patch -1 --stdout FETCH_HEAD,['doc/admin-guide-cloud/section_volume-migration.xml'],1,7fe9fea6cc97591afbd7ce2bea2697bf804b2c6e,1279179_stop-allocation-of-volumes," <note> <para>If you are decommissioning a block storage node, it is advisable that you stop the <systemitem class=""service"">cinder-volume</systemitem> service on the node first before performing any migration:</para> <screen><prompt>#</prompt> service cinder-volume stop</screen> <para>Doing so will prevent any other volumes from being allocated to the node.</para></note>",,8,0
openstack%2Foperations-guide~master~I6a8cb178c777e64769b6e2406fe74509a213acfc,openstack/operations-guide,master,I6a8cb178c777e64769b6e2406fe74509a213acfc,Cleanup of pom.xml,MERGED,2014-03-04 20:21:12.000000000,2014-03-06 08:47:32.000000000,2014-03-06 08:47:31.000000000,"[{'_account_id': 3}, {'_account_id': 612}, {'_account_id': 6547}, {'_account_id': 6772}]","[{'number': 1, 'created': '2014-03-04 20:21:12.000000000', 'files': ['doc/openstack-ops/pom.xml'], 'web_link': 'https://opendev.org/openstack/operations-guide/commit/ad104b8ab040983a3733b0bda87cb9f6e453330d', 'message': 'Cleanup of pom.xml\n\nThis patch works thanks to a fix in clouddocs-maven-plugin 1.14.\n\n* Remove targetDirectory variable, the default is fine\n* Properly set webhelpDirname\n* Remove cleanup section that is not needed anymore due to the\n  above changes\n\nChange-Id: I6a8cb178c777e64769b6e2406fe74509a213acfc\n'}]",0,77992,ad104b8ab040983a3733b0bda87cb9f6e453330d,12,4,1,6547,,,0,"Cleanup of pom.xml

This patch works thanks to a fix in clouddocs-maven-plugin 1.14.

* Remove targetDirectory variable, the default is fine
* Properly set webhelpDirname
* Remove cleanup section that is not needed anymore due to the
  above changes

Change-Id: I6a8cb178c777e64769b6e2406fe74509a213acfc
",git fetch https://review.opendev.org/openstack/operations-guide refs/changes/92/77992/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/openstack-ops/pom.xml'],1,ad104b8ab040983a3733b0bda87cb9f6e453330d,improve-pom, <webhelpDirname>${release.path.name}/openstack-ops</webhelpDirname>," <targetDirectory>target/docbkx/webhelp/${release.path.name}</targetDirectory> <webhelpDirname>openstack-ops</webhelpDirname> <execution> <id>cleanup</id> <goals> <goal>generate-webhelp</goal> </goals> <phase>generate-sources</phase> <configuration> <includes>dummy.xml</includes> <postProcess> <delete includeemptydirs=""true"" verbose=""true""> <fileset dir=""${basedir}/target/docbkx/webhelp/${release.path.name}"" > <include name=""**/*""/> <exclude name=""openstack-ops/**""/> </fileset> </delete> </postProcess> </configuration> </execution>",1,20
openstack%2Fopenstack-manuals~stable%2Fgrizzly~I035198446a433305f951a9e520c461cc6bc47da5,openstack/openstack-manuals,stable/grizzly,I035198446a433305f951a9e520c461cc6bc47da5,"For grizzly, these pom.xml files were causing incorrect canonical url",MERGED,2014-03-06 03:16:36.000000000,2014-03-06 08:47:25.000000000,2014-03-06 08:47:24.000000000,"[{'_account_id': 3}, {'_account_id': 612}, {'_account_id': 6547}]","[{'number': 1, 'created': '2014-03-06 03:16:36.000000000', 'files': ['doc/src/docbkx/openstack-block-storage-admin/pom.xml', 'doc/src/docbkx/openstack-ha/pom.xml', 'doc/src/docbkx/openstack-network-connectivity-admin/pom.xml', 'doc/src/docbkx/openstack-object-storage-admin/pom.xml', 'doc/src/docbkx/openstack-compute-admin/pom.xml', 'doc/src/docbkx/cli-guide/pom.xml', 'doc/src/docbkx/common/glossary/pom.xml'], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/251f691aee98589591721c2c0fa1e3d2d8ecfa73', 'message': 'For grizzly, these pom.xml files were causing incorrect canonical url\n\nChange-Id: I035198446a433305f951a9e520c461cc6bc47da5\nPartial-bug: 1288513\n'}]",0,78508,251f691aee98589591721c2c0fa1e3d2d8ecfa73,7,3,1,964,,,0,"For grizzly, these pom.xml files were causing incorrect canonical url

Change-Id: I035198446a433305f951a9e520c461cc6bc47da5
Partial-bug: 1288513
",git fetch https://review.opendev.org/openstack/openstack-manuals refs/changes/08/78508/1 && git format-patch -1 --stdout FETCH_HEAD,"['doc/src/docbkx/openstack-block-storage-admin/pom.xml', 'doc/src/docbkx/openstack-ha/pom.xml', 'doc/src/docbkx/openstack-network-connectivity-admin/pom.xml', 'doc/src/docbkx/openstack-object-storage-admin/pom.xml', 'doc/src/docbkx/cli-guide/pom.xml', 'doc/src/docbkx/openstack-compute-admin/pom.xml', 'doc/src/docbkx/common/glossary/pom.xml']",7,251f691aee98589591721c2c0fa1e3d2d8ecfa73,bug/1288513, <canonicalUrlBase>http://docs.openstack.org/openstack-glossary/content</canonicalUrlBase>, <canonicalUrlBase>http://docs.openstack.org/openstack-glossary/content/</canonicalUrlBase>,6,7
openstack%2Foperations-guide~master~Ica8bda1cd93f6c10a40ecf2428d53e1d51e48df2,openstack/operations-guide,master,Ica8bda1cd93f6c10a40ecf2428d53e1d51e48df2,Update to clouddocs-maven-plugin 1.14.0,MERGED,2014-03-04 19:27:16.000000000,2014-03-06 08:47:02.000000000,2014-03-06 08:47:02.000000000,"[{'_account_id': 3}, {'_account_id': 612}, {'_account_id': 6547}, {'_account_id': 9162}]","[{'number': 1, 'created': '2014-03-04 19:27:16.000000000', 'files': ['doc/openstack-ops/pom.xml'], 'web_link': 'https://opendev.org/openstack/operations-guide/commit/ef2a90706de3e94d9b6876f4622a1529e8fe756f', 'message': 'Update to clouddocs-maven-plugin 1.14.0\n\nChange-Id: Ica8bda1cd93f6c10a40ecf2428d53e1d51e48df2\n'}]",0,77976,ef2a90706de3e94d9b6876f4622a1529e8fe756f,14,4,1,6547,,,0,"Update to clouddocs-maven-plugin 1.14.0

Change-Id: Ica8bda1cd93f6c10a40ecf2428d53e1d51e48df2
",git fetch https://review.opendev.org/openstack/operations-guide refs/changes/76/77976/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/openstack-ops/pom.xml'],1,ef2a90706de3e94d9b6876f4622a1529e8fe756f,clouddocs-1.14.0, <version>1.14.0</version>, <version>1.13.0</version>,1,1
openstack%2Fneutron~master~Ic5f77808cc10f885d67f5a9cf3b3836283692850,openstack/neutron,master,Ic5f77808cc10f885d67f5a9cf3b3836283692850,Fix DetachedInstanceError for Agent instance,MERGED,2014-02-20 08:39:48.000000000,2014-03-06 08:25:27.000000000,2014-03-06 08:25:26.000000000,"[{'_account_id': 3}, {'_account_id': 748}, {'_account_id': 841}, {'_account_id': 1653}, {'_account_id': 4395}, {'_account_id': 6072}, {'_account_id': 9682}, {'_account_id': 9732}, {'_account_id': 9787}, {'_account_id': 9845}, {'_account_id': 9925}, {'_account_id': 10116}, {'_account_id': 10117}, {'_account_id': 10119}, {'_account_id': 10153}, {'_account_id': 10184}, {'_account_id': 10192}, {'_account_id': 10294}, {'_account_id': 10387}]","[{'number': 1, 'created': '2014-02-20 08:39:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/d5e922915a38737ada205332c40364d594b6a1ea', 'message': ""Fix DetachedInstanceError for Agent instance\n\nThe stacktrace observed seems to hint to a\nsituation where a session is not properly\nrolled back when duplicate agent entries are\nfound.\n\nSince it is ok to deal with duplicates, the\naddition of agents to the DB must be done\none by one, otherwise we go against the\nATOMICITY property of a transaction of all\nor none. It's either that or I am barking at\nthe wrong tree.\n\nCloses-bug: 1282421\n\nChange-Id: Ic5f77808cc10f885d67f5a9cf3b3836283692850\n""}, {'number': 2, 'created': '2014-02-21 18:23:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/6543009425e022b568f179889df408d37739a14a', 'message': ""Fix DetachedInstanceError for Agent instance\n\nThe stacktrace observed seems to hint to a\nsituation where a session is not properly\nrolled back when duplicate agent entries are\nfound.\n\nSince it is ok to deal with duplicates, the\naddition of agents to the DB must be done\none by one, otherwise we go against the\nATOMICITY property of a transaction of all\nor none. It's either that or I am barking at\nthe wrong tree.\n\nCloses-bug: 1282421\n\nChange-Id: Ic5f77808cc10f885d67f5a9cf3b3836283692850\n""}, {'number': 3, 'created': '2014-02-22 06:25:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/40159654e350f3334b949531cd0b0bce5d21e8c6', 'message': ""Fix DetachedInstanceError for Agent instance\n\nThe stacktrace observed seems to hint to a\nsituation where a session is not properly\nrolled back when duplicate agent entries are\nfound.\n\nSince it is ok to deal with duplicates, the\naddition of agents to the DB must be done\none by one, otherwise we go against the\nATOMICITY property of a transaction of all\nor none. It's either that or I am barking at\nthe wrong tree.\n\nCloses-bug: 1282421\n\nChange-Id: Ic5f77808cc10f885d67f5a9cf3b3836283692850\n""}, {'number': 4, 'created': '2014-02-24 22:15:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/92725509031b04b0863bf9a615b07a6a3910448e', 'message': ""Fix DetachedInstanceError for Agent instance\n\nThe stacktrace observed seems to hint to a\nsituation where a session is not properly\nrolled back when duplicate agent entries are\nfound.\n\nSince it is ok to deal with duplicates, the\naddition of agents to the DB must be done\none by one, otherwise we go against the\nATOMICITY property of a transaction of all\nor none. It's either that or I am barking at\nthe wrong tree.\n\nThis patch also added UT to cover affected\ncode.\n\nCloses-bug: 1282421\nRelated-bug: 1282253\n\nChange-Id: Ic5f77808cc10f885d67f5a9cf3b3836283692850\n""}, {'number': 6, 'created': '2014-02-24 23:18:18.000000000', 'files': ['neutron/tests/unit/test_dhcp_scheduler.py', 'neutron/scheduler/dhcp_agent_scheduler.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/237746a6d63c96726e7966770a602b62205ee333', 'message': ""Fix DetachedInstanceError for Agent instance\n\nThe stacktrace observed seems to hint to a\nsituation where a session is not properly\nrolled back when duplicate agent entries are\nfound.\n\nSince it is ok to deal with duplicates, the\naddition of agents to the DB must be done\none by one, otherwise we go against the\nATOMICITY property of a transaction of all\nor none. It's either that or I am barking at\nthe wrong tree.\n\nThis patch also added UT to cover affected\ncode.\n\nCloses-bug: 1282421\nRelated-bug: 1282253\n\nChange-Id: Ic5f77808cc10f885d67f5a9cf3b3836283692850\n""}, {'number': 5, 'created': '2014-02-24 23:18:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/f234516c1633e2e8e90c84596c0364e08fc49b06', 'message': ""Fix DetachedInstanceError for Agent instance\n\nThe stacktrace observed seems to hint to a\nsituation where a session is not properly\nrolled back when duplicate agent entries are\nfound.\n\nSince it is ok to deal with duplicates, the\naddition of agents to the DB must be done\none by one, otherwise we go against the\nATOMICITY property of a transaction of all\nor none. It's either that or I am barking at\nthe wrong tree.\n\nThis patch also added UT to cover affected\ncode.\n\nCloses-bug: 1282421\nRelated-bug: 1282253\n\nChange-Id: Ic5f77808cc10f885d67f5a9cf3b3836283692850\n""}]",6,74962,237746a6d63c96726e7966770a602b62205ee333,109,19,6,748,,,0,"Fix DetachedInstanceError for Agent instance

The stacktrace observed seems to hint to a
situation where a session is not properly
rolled back when duplicate agent entries are
found.

Since it is ok to deal with duplicates, the
addition of agents to the DB must be done
one by one, otherwise we go against the
ATOMICITY property of a transaction of all
or none. It's either that or I am barking at
the wrong tree.

This patch also added UT to cover affected
code.

Closes-bug: 1282421
Related-bug: 1282253

Change-Id: Ic5f77808cc10f885d67f5a9cf3b3836283692850
",git fetch https://review.opendev.org/openstack/neutron refs/changes/62/74962/6 && git format-patch -1 --stdout FETCH_HEAD,['neutron/scheduler/dhcp_agent_scheduler.py'],1,d5e922915a38737ada205332c40364d594b6a1ea,bug/1282421," def _schedule_bind_network(self, context, agents, network_id): for agent in agents: context.session.begin(subtransactions=True) try: binding = agentschedulers_db.NetworkDhcpAgentBinding() binding.dhcp_agent = agent binding.network_id = network_id context.session.add(binding) # try to actually write the changes and catch integrity # DBDuplicateEntry context.session.commit() except db_exc.DBDuplicateEntry: # it's totally ok, someone just did our job! LOG.warn(_('Agent %s already present'), agent) context.session.rollback() LOG.debug(_('Network %(network_id)s is scheduled to be ' 'hosted by DHCP agent %(agent_id)s'), {'network_id': network_id, 'agent_id': agent}) self._schedule_bind_network(context, chosen_agents, network['id'])"," def _schedule_bind_network(self, context, agent, network_id): try: binding = agentschedulers_db.NetworkDhcpAgentBinding() binding.dhcp_agent = agent binding.network_id = network_id context.session.add(binding) # try to actually write the changes and catch integrity # DBDuplicateEntry context.session.flush() except db_exc.DBDuplicateEntry: # it's totally ok, someone just did our job! pass LOG.debug(_('Network %(network_id)s is scheduled to be hosted by ' 'DHCP agent %(agent_id)s'), {'network_id': network_id, 'agent_id': agent}) for agent in chosen_agents: self._schedule_bind_network(context, agent, network['id'])",20,18
openstack%2Fhorizon~master~I3ad24d837dd5e9046aa8a91cce33b954b7a8e5d9,openstack/horizon,master,I3ad24d837dd5e9046aa8a91cce33b954b7a8e5d9,Fixing heat stack status column,MERGED,2014-02-13 22:31:03.000000000,2014-03-06 08:25:24.000000000,2014-03-06 08:25:23.000000000,"[{'_account_id': 3}, {'_account_id': 1941}, {'_account_id': 5623}, {'_account_id': 6914}, {'_account_id': 8429}, {'_account_id': 9576}]","[{'number': 1, 'created': '2014-02-13 22:31:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/11164a8ca9f57582c4f7dd97d1d9d0e5d9e99c5e', 'message': 'Fixing heat stack status column\n\nStatus column on stack table was using stack_status instead of status\nStatus is a little more vague, but keeps Horizon from having to know\nabout all of the various Heat statuses (it was incorrectly displaying\nprogress meters for several of them before this fix)\n\nUpdated topology view with the same fix.\n\nImplements: blueprint heat-fix-status-column\nChange-Id: I3ad24d837dd5e9046aa8a91cce33b954b7a8e5d9\n'}, {'number': 2, 'created': '2014-02-14 19:13:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/0b0e12f66bbf7db10bea106ff7e7d1103cb423a8', 'message': 'Fixing heat stack status column\n\nStatus column on stack table was using stack_status instead of status\nStatus is a little more vague, but keeps Horizon from having to know\nabout all of the various Heat statuses (it was incorrectly displaying\nprogress meters for several of them before this fix)\n\nUpdated topology view with the same fix.\n\nImplements: blueprint heat-fix-status-column\nChange-Id: I3ad24d837dd5e9046aa8a91cce33b954b7a8e5d9\n'}, {'number': 3, 'created': '2014-03-04 16:38:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/68f1b55f02090dca91a31a38ac9bd5a596d8ff29', 'message': 'Fixing heat stack status column\n\nStatus column on stack table was using stack_status instead of status\nStatus is a little more vague, but keeps Horizon from having to know\nabout all of the various Heat statuses (it was incorrectly displaying\nprogress meters for several of them before this fix)\n\nUpdated topology view with the same fix.\n\nImplements: blueprint heat-fix-status-column\nChange-Id: I3ad24d837dd5e9046aa8a91cce33b954b7a8e5d9\n'}, {'number': 4, 'created': '2014-03-04 19:17:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/1a54e70d3886a080d99d91b6f273744648e18c79', 'message': 'Fixing heat stack status column\n\nStatus column on stack table was using stack_status instead of status\nStatus is a little more vague, but keeps Horizon from having to know\nabout all of the various Heat statuses (it was incorrectly displaying\nprogress meters for several of them before this fix)\n\nUpdated topology view with the same fix.\n\nImplements: blueprint heat-fix-status-column\nChange-Id: I3ad24d837dd5e9046aa8a91cce33b954b7a8e5d9\n'}, {'number': 5, 'created': '2014-03-05 15:32:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/7b693d65fe8a71aa48716234b57b40d734831e09', 'message': 'Fixing heat stack status column\n\nStatus column on stack table was using stack_status instead of status\nStatus is a little more vague, but keeps Horizon from having to know\nabout all of the various Heat statuses (it was incorrectly displaying\nprogress meters for several of them before this fix)\n\nUpdated topology view with the same fix.\n\nImplements: blueprint heat-fix-status-column\nChange-Id: I3ad24d837dd5e9046aa8a91cce33b954b7a8e5d9\n'}, {'number': 6, 'created': '2014-03-05 19:12:50.000000000', 'files': ['openstack_dashboard/dashboards/project/stacks/api.py', 'openstack_dashboard/dashboards/project/stacks/tables.py'], 'web_link': 'https://opendev.org/openstack/horizon/commit/e6ea72b0b0ac53e4eba8d2ee5fbc9388ccfefcf2', 'message': 'Fixing heat stack status column\n\nStatus column on stack table was using stack_status instead of status\nStatus is a little more vague, but keeps Horizon from having to know\nabout all of the various Heat statuses (it was incorrectly displaying\nprogress meters for several of them before this fix)\n\nUpdated topology view with the same fix.\n\nImplements: blueprint heat-fix-status-column\nChange-Id: I3ad24d837dd5e9046aa8a91cce33b954b7a8e5d9\n'}]",0,73433,e6ea72b0b0ac53e4eba8d2ee5fbc9388ccfefcf2,44,6,6,8429,,,0,"Fixing heat stack status column

Status column on stack table was using stack_status instead of status
Status is a little more vague, but keeps Horizon from having to know
about all of the various Heat statuses (it was incorrectly displaying
progress meters for several of them before this fix)

Updated topology view with the same fix.

Implements: blueprint heat-fix-status-column
Change-Id: I3ad24d837dd5e9046aa8a91cce33b954b7a8e5d9
",git fetch https://review.opendev.org/openstack/horizon refs/changes/33/73433/5 && git format-patch -1 --stdout FETCH_HEAD,"['openstack_dashboard/dashboards/project/stacks/api.py', 'openstack_dashboard/dashboards/project/stacks/tables.py']",2,11164a8ca9f57582c4f7dd97d1d9d0e5d9e99c5e,bp/heat-fix-status-column," (""Complete"", True), (""Failed"", False), status = tables.Column(""status"","," (""Create Complete"", True), (""Update Complete"", True), (""Create Failed"", False), (""Update Failed"", False), status = tables.Column(""stack_status"",",4,8
openstack%2Fopenstack-manuals~master~I6a5f01bef8ffebb1d1471f35804c153ab5f6025e,openstack/openstack-manuals,master,I6a5f01bef8ffebb1d1471f35804c153ab5f6025e,Update cli commands to latest *released* version,MERGED,2014-03-05 20:01:20.000000000,2014-03-06 07:35:55.000000000,2014-03-06 07:35:54.000000000,"[{'_account_id': 3}, {'_account_id': 612}, {'_account_id': 6547}, {'_account_id': 7923}]","[{'number': 1, 'created': '2014-03-05 20:01:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/50486ddf5d105e27435e8d9ca5f5d424ac9f171f', 'message': ""Update cli commands to latest *released* version\n\nPreviously I've created the files with the latest git versions of the\npython packages. Now I've created them with the latest released\nversions:\npython-ceilometerclient 1.0.9\npython-cinderclient 1.0.8\npython-glanceclient 0.12.0\npython-heatclient 0.2.8\npython-keystoneclient  0.6.0\npython-neutronclient 2.3.4\npython-novaclient 2.9.0\npython-swiftclient 2.0.3\n\nAlso, change permissions of section_cli_cinder_manage_volumes.xml.\n\nChange-Id: I6a5f01bef8ffebb1d1471f35804c153ab5f6025e\n""}, {'number': 2, 'created': '2014-03-05 20:39:50.000000000', 'files': ['doc/common/ch_cli_nova_commands.xml', 'doc/common/section_cli_cinder_manage_volumes.xml', 'doc/common/ch_cli_heat_commands.xml', 'doc/common/ch_cli_cinder_commands.xml', 'doc/common/ch_cli_glance_commands.xml', 'doc/common/ch_cli_neutron_commands.xml', 'doc/common/ch_cli_swift_commands.xml', 'doc/common/ch_cli_ceilometer_commands.xml', 'doc/common/ch_cli_keystone_commands.xml'], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/95310dfc9429e833d3295f10f835652188260af1', 'message': ""Update cli commands to latest *released* version\n\nPreviously I've created the files with the latest git versions of the\npython packages. Now I've created them with the latest released\nversions:\npython-ceilometerclient 1.0.9\npython-cinderclient 1.0.8\npython-glanceclient 0.12.0\npython-heatclient 0.2.8\npython-keystoneclient  0.6.0\npython-neutronclient 2.3.4\npython-novaclient 2.16.0\npython-swiftclient 2.0.3\n\nAlso, change permissions of section_cli_cinder_manage_volumes.xml.\n\nChange-Id: I6a5f01bef8ffebb1d1471f35804c153ab5f6025e\n""}]",0,78396,95310dfc9429e833d3295f10f835652188260af1,9,4,2,6547,,,0,"Update cli commands to latest *released* version

Previously I've created the files with the latest git versions of the
python packages. Now I've created them with the latest released
versions:
python-ceilometerclient 1.0.9
python-cinderclient 1.0.8
python-glanceclient 0.12.0
python-heatclient 0.2.8
python-keystoneclient  0.6.0
python-neutronclient 2.3.4
python-novaclient 2.16.0
python-swiftclient 2.0.3

Also, change permissions of section_cli_cinder_manage_volumes.xml.

Change-Id: I6a5f01bef8ffebb1d1471f35804c153ab5f6025e
",git fetch https://review.opendev.org/openstack/openstack-manuals refs/changes/96/78396/2 && git format-patch -1 --stdout FETCH_HEAD,"['doc/common/ch_cli_nova_commands.xml', 'doc/common/section_cli_cinder_manage_volumes.xml', 'doc/common/ch_cli_heat_commands.xml', 'doc/common/ch_cli_cinder_commands.xml', 'doc/common/ch_cli_glance_commands.xml', 'doc/common/ch_cli_neutron_commands.xml', 'doc/common/ch_cli_swift_commands.xml']",7,50486ddf5d105e27435e8d9ca5f5d424ac9f171f,python-clients, <varlistentry> <term><command>--skip-identical</command></term> <listitem> <para> Skip downloading files that are identical on both sides </para> </listitem> </varlistentry> <term><command>--skip-identical</command></term> <listitem> <para> Skip uploading files that are identical on both sides </para> </listitem> </varlistentry> <varlistentry>,,533,417
openstack%2Fopenstack-manuals~master~I73f823190913acb755b3362e73db70d09e5b3426,openstack/openstack-manuals,master,I73f823190913acb755b3362e73db70d09e5b3426,Apply review edits to GlusterFS+NFS backend setup,MERGED,2014-03-05 02:03:49.000000000,2014-03-06 07:28:24.000000000,2014-03-06 07:28:23.000000000,"[{'_account_id': 3}, {'_account_id': 612}, {'_account_id': 2448}, {'_account_id': 6547}, {'_account_id': 6772}, {'_account_id': 9162}, {'_account_id': 9355}]","[{'number': 1, 'created': '2014-03-05 02:03:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/bf2e8e949d7a3a1b9fcee24cb4bf6198e36406d2', 'message': 'Single-source+edit backend setup sections\n\nThis patch applies several editorial fixes to the GlusterFS and NFS\nbackend setup sections. These fixes were part of the editorial review\nprocess in https://review.openstack.org/#/c/74553/ and\nhttps://review.openstack.org/#/c/73931/ (both of which are merged).\n\nIn addition, this patch also single-sources the following os-specific\nitems:\n\n- note on the name of the cinder volume service\n- step for restarting the cinder volume service\n\nChange-Id: I73f823190913acb755b3362e73db70d09e5b3426\nRelated-Bug: #1281444\nRelated-Bug: #1280951\n'}, {'number': 2, 'created': '2014-03-05 04:22:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/2262c689d42580160155663ff29c8bf656af37ae', 'message': 'Apply review edits to GlusterFS+NFS backend setup\n\nThis patch applies several editorial fixes to the GlusterFS and NFS\nbackend setup sections. These fixes were part of the editorial review\nprocess in https://review.openstack.org/#/c/74553/ and\nhttps://review.openstack.org/#/c/73931/ (both of which are merged).\n\nChange-Id: I73f823190913acb755b3362e73db70d09e5b3426\nRelated-Bug: #1281444\nRelated-Bug: #1280951\n'}, {'number': 3, 'created': '2014-03-05 23:39:22.000000000', 'files': ['doc/admin-guide-cloud/section_nfs_backend.xml', 'doc/admin-guide-cloud/section_glusterfs_backend.xml'], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/cbdf37be29dc3eee00c374b5266337ef1040c06d', 'message': 'Apply review edits to GlusterFS+NFS backend setup\n\nThis patch applies several editorial fixes to the GlusterFS and NFS\nbackend setup sections. These fixes were part of the editorial review\nprocess in https://review.openstack.org/#/c/74553/ and\nhttps://review.openstack.org/#/c/73931/ (both of which are merged).\n\nChange-Id: I73f823190913acb755b3362e73db70d09e5b3426\nRelated-Bug: #1281444\nRelated-Bug: #1280951\n'}]",3,78064,cbdf37be29dc3eee00c374b5266337ef1040c06d,18,7,3,9355,,,0,"Apply review edits to GlusterFS+NFS backend setup

This patch applies several editorial fixes to the GlusterFS and NFS
backend setup sections. These fixes were part of the editorial review
process in https://review.openstack.org/#/c/74553/ and
https://review.openstack.org/#/c/73931/ (both of which are merged).

Change-Id: I73f823190913acb755b3362e73db70d09e5b3426
Related-Bug: #1281444
Related-Bug: #1280951
",git fetch https://review.opendev.org/openstack/openstack-manuals refs/changes/64/78064/1 && git format-patch -1 --stdout FETCH_HEAD,"['doc/admin-guide-cloud/section_glusterfs_backend.xml', 'doc/admin-guide-cloud/section_nfs_backend.xml', 'doc/common/step_restart-cinder-volume.xml', 'doc/common/note_cinder-volume-service-name.xml']",4,bf2e8e949d7a3a1b9fcee24cb4bf6198e36406d2,1280951-1281444_minor-edits-backend-setup-gluster-nfs,"<?xml version=""1.0"" encoding=""UTF-8""?> <note xmlns=""http://docbook.org/ns/docbook"" xmlns:xi=""http://www.w3.org/2001/XInclude"" xmlns:xlink=""http://www.w3.org/1999/xlink"" version=""1.0""> <para os=""rhel;centos;fedora;opensuse;sles"">The <systemitem class=""service"">cinder</systemitem> volume service is named <literal>openstack-cinder-volume</literal> on the following distributions:</para> <itemizedlist os=""rhel;centos;fedora;opensuse;sles""> <listitem os=""rhel;centos;fedora""><para>CentOS</para></listitem> <listitem os=""rhel;centos;fedora""><para>Fedora</para></listitem> <listitem os=""opensuse;sles""><para>openSUSE</para></listitem> <listitem os=""rhel;centos;fedora""><para>Red Hat Enterprise Linux</para></listitem> <listitem os=""opensuse;sles""><para>SUSE Linux Enterprise </para></listitem> </itemizedlist> <para>In Ubuntu and Debian distributions, the <systemitem class=""service"">cinder</systemitem> volume service is named <literal>cinder-volume</literal>.</para> </note> ",,70,63
openstack%2Fopenstack-doc-tools~master~I2644348952d1e119920aaabbad00c5dcdc317059,openstack/openstack-doc-tools,master,I2644348952d1e119920aaabbad00c5dcdc317059,Add client version number,MERGED,2014-03-05 20:33:55.000000000,2014-03-06 07:25:50.000000000,2014-03-06 07:25:50.000000000,"[{'_account_id': 3}, {'_account_id': 612}, {'_account_id': 6547}, {'_account_id': 7923}]","[{'number': 1, 'created': '2014-03-05 20:33:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-doc-tools/commit/eb13509efb38f8e06e1297f0d72bc5bfbc6459b4', 'message': 'Add client version number\n\nOutput the version number of the client package in the generated\ndocbook.\n\nChange-Id: I2644348952d1e119920aaabbad00c5dcdc317059\n'}, {'number': 2, 'created': '2014-03-05 21:12:46.000000000', 'files': ['README.rst', 'os_doc_tools/commands.py'], 'web_link': 'https://opendev.org/openstack/openstack-doc-tools/commit/1083e40d21d4fda3647e2d2f90f47e70de5d7345', 'message': 'Add client version number\n\nOutput the version number of the client package in the generated\ndocbook.\n\nChange-Id: I2644348952d1e119920aaabbad00c5dcdc317059\n'}]",1,78401,1083e40d21d4fda3647e2d2f90f47e70de5d7345,11,4,2,6547,,,0,"Add client version number

Output the version number of the client package in the generated
docbook.

Change-Id: I2644348952d1e119920aaabbad00c5dcdc317059
",git fetch https://review.opendev.org/openstack/openstack-doc-tools refs/changes/01/78401/1 && git format-patch -1 --stdout FETCH_HEAD,"['README.rst', 'os_doc_tools/commands.py']",2,eb13509efb38f8e06e1297f0d72bc5bfbc6459b4,auto-commands-version," version = check_output([os_command, ""--version""], stderr=subprocess.STDOUT) # Extract version from ""swift 0.3"" version = version.strip().rpartition(' ')[2] print(""Documenting '%s help (version %s)'"" % (os_command, version)) (CLI) for the {1} and its extensions. This chapter documents <command>{0}</command> version {3}. os_file.write(header.format(os_command, api_name, title, version)) help=""OpenStack command to document."") parser.add_argument(""--all"", help=""Document all clients"","," print(""Documenting '%s help'"" % os_command) (CLI) for the {1} and its extensions. os_file.write(header.format(os_command, api_name, title)) help=""OpenStack command to document"") parser.add_argument(""--all"", help=""Document all clients "",",57,49
openstack%2Fneutron~master~If0bab196495c4944a53e0e394c956cca36269883,openstack/neutron,master,If0bab196495c4944a53e0e394c956cca36269883,BigSwitch: Add SSL Certificate Validation,MERGED,2014-02-04 03:53:07.000000000,2014-03-06 07:12:26.000000000,2014-03-06 07:12:25.000000000,"[{'_account_id': 3}, {'_account_id': 105}, {'_account_id': 490}, {'_account_id': 704}, {'_account_id': 841}, {'_account_id': 1653}, {'_account_id': 1689}, {'_account_id': 2592}, {'_account_id': 5170}, {'_account_id': 6072}, {'_account_id': 7591}, {'_account_id': 7787}, {'_account_id': 7909}, {'_account_id': 9732}, {'_account_id': 9787}, {'_account_id': 9845}, {'_account_id': 9925}, {'_account_id': 10116}, {'_account_id': 10117}, {'_account_id': 10119}, {'_account_id': 10153}, {'_account_id': 10180}, {'_account_id': 10184}, {'_account_id': 10192}, {'_account_id': 10294}, {'_account_id': 10310}, {'_account_id': 10387}]","[{'number': 1, 'created': '2014-02-04 03:53:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/a6c4637f2b54d6ada4a551e61f78aa9f1cd9c409', 'message': 'BigSwitch: Add SSL Certificate Validation\n\nThis patch adds the option to use SSL certificate\nvalidation on the backend controller using SSH-style\nsticky authentication, individual trusted\ncertificates, and/or certificate authorities.\n\nImplements: blueprint bsn-certificate-enforcement\nChange-Id: If0bab196495c4944a53e0e394c956cca36269883\n'}, {'number': 2, 'created': '2014-02-04 08:05:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/fb833376c1e470f0a604120ceafd8014e1e75f11', 'message': 'BigSwitch: Add SSL Certificate Validation\n\nThis patch adds the option to use SSL certificate\nvalidation on the backend controller using SSH-style\nsticky authentication, individual trusted\ncertificates, and/or certificate authorities.\n\nImplements: blueprint bsn-certificate-enforcement\nChange-Id: If0bab196495c4944a53e0e394c956cca36269883\n'}, {'number': 3, 'created': '2014-02-04 08:18:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/2a3d3e0bc56dc9df713c8d659ea6166da8086a38', 'message': 'BigSwitch: Add SSL Certificate Validation\n\nThis patch adds the option to use SSL certificate\nvalidation on the backend controller using SSH-style\nsticky authentication, individual trusted\ncertificates, and/or certificate authorities.\n\nImplements: blueprint bsn-certificate-enforcement\nChange-Id: If0bab196495c4944a53e0e394c956cca36269883\n'}, {'number': 4, 'created': '2014-02-04 08:24:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/93b702d5b90e146cbac61356e5a6ba2005624707', 'message': 'BigSwitch: Add SSL Certificate Validation\n\nThis patch adds the option to use SSL certificate\nvalidation on the backend controller using SSH-style\nsticky authentication, individual trusted\ncertificates, and/or certificate authorities.\n\nImplements: blueprint bsn-certificate-enforcement\nChange-Id: If0bab196495c4944a53e0e394c956cca36269883\n'}, {'number': 5, 'created': '2014-02-04 09:01:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/129130aa7a29123f0fa3e9788fe9b68980e8324e', 'message': 'BigSwitch: Add SSL Certificate Validation\n\nThis patch adds the option to use SSL certificate\nvalidation on the backend controller using SSH-style\nsticky authentication, individual trusted\ncertificates, and/or certificate authorities.\n\nImplements: blueprint bsn-certificate-enforcement\nChange-Id: If0bab196495c4944a53e0e394c956cca36269883\n'}, {'number': 6, 'created': '2014-02-05 00:52:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/7d39b87f9140240b8ebfae90c00dbf975032ec3d', 'message': 'BigSwitch: Add SSL Certificate Validation\n\nThis patch adds the option to use SSL certificate\nvalidation on the backend controller using SSH-style\nsticky authentication, individual trusted\ncertificates, and/or certificate authorities.\n\nImplements: blueprint bsn-certificate-enforcement\nChange-Id: If0bab196495c4944a53e0e394c956cca36269883\n'}, {'number': 8, 'created': '2014-02-05 01:03:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/b00af87205eb79a5e0bf7edd5ef007ae00c50932', 'message': 'BigSwitch: Add SSL Certificate Validation\n\nThis patch adds the option to use SSL certificate\nvalidation on the backend controller using SSH-style\nsticky authentication, individual trusted\ncertificates, and/or certificate authorities.\n\nImplements: blueprint bsn-certificate-enforcement\nChange-Id: If0bab196495c4944a53e0e394c956cca36269883\n'}, {'number': 7, 'created': '2014-02-05 01:03:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/ba09bf5d85637dac9c6fa32faf3bf75e3d4258f5', 'message': 'BigSwitch: Add SSL Certificate Validation\n\nThis patch adds the option to use SSL certificate\nvalidation on the backend controller using SSH-style\nsticky authentication, individual trusted\ncertificates, and/or certificate authorities.\n\nImplements: blueprint bsn-certificate-enforcement\nChange-Id: If0bab196495c4944a53e0e394c956cca36269883\n'}, {'number': 9, 'created': '2014-02-05 18:59:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/69c5c2dc8b5956c6fec66a2a8e377eef04425366', 'message': 'BigSwitch: Add SSL Certificate Validation\n\nThis patch adds the option to use SSL certificate\nvalidation on the backend controller using SSH-style\nsticky authentication, individual trusted\ncertificates, and/or certificate authorities.\n\nImplements: blueprint bsn-certificate-enforcement\nChange-Id: If0bab196495c4944a53e0e394c956cca36269883\n'}, {'number': 10, 'created': '2014-02-05 21:48:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/0e9cec91de302b83b3fe049d51e52f47c5f81812', 'message': 'BigSwitch: Add SSL Certificate Validation\n\nThis patch adds the option to use SSL certificate\nvalidation on the backend controller using SSH-style\nsticky authentication, individual trusted\ncertificates, and/or certificate authorities.\n\nImplements: blueprint bsn-certificate-enforcement\nChange-Id: If0bab196495c4944a53e0e394c956cca36269883\n'}, {'number': 11, 'created': '2014-02-06 01:11:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/666f1d0018b4ef3fc5eb341cfec0fdb898ef8b3b', 'message': 'BigSwitch: Add SSL Certificate Validation\n\nThis patch adds the option to use SSL certificate\nvalidation on the backend controller using SSH-style\nsticky authentication, individual trusted\ncertificates, and/or certificate authorities.\n\nImplements: blueprint bsn-certificate-enforcement\nChange-Id: If0bab196495c4944a53e0e394c956cca36269883\n'}, {'number': 12, 'created': '2014-02-11 00:45:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/2b05ea569221fa066496c983b51d2c1886d81290', 'message': 'BigSwitch: Add SSL Certificate Validation\n\nThis patch adds the option to use SSL certificate\nvalidation on the backend controller using SSH-style\nsticky authentication, individual trusted\ncertificates, and/or certificate authorities.\n\nImplements: blueprint bsn-certificate-enforcement\nChange-Id: If0bab196495c4944a53e0e394c956cca36269883\n'}, {'number': 13, 'created': '2014-02-11 03:44:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/26bf196e77d704df3febfb9819bc65c4bd27c964', 'message': 'BigSwitch: Add SSL Certificate Validation\n\nThis patch adds the option to use SSL certificate\nvalidation on the backend controller using SSH-style\nsticky authentication, individual trusted\ncertificates, and/or certificate authorities.\n\nImplements: blueprint bsn-certificate-enforcement\nChange-Id: If0bab196495c4944a53e0e394c956cca36269883\n'}, {'number': 14, 'created': '2014-02-14 03:20:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/32ea1a1a46a704c0fd26f862b800b4bd3fb968a5', 'message': 'BigSwitch: Add SSL Certificate Validation\n\nThis patch adds the option to use SSL certificate\nvalidation on the backend controller using SSH-style\nsticky authentication, individual trusted\ncertificates, and/or certificate authorities.\n\nImplements: blueprint bsn-certificate-enforcement\nChange-Id: If0bab196495c4944a53e0e394c956cca36269883\n'}, {'number': 16, 'created': '2014-02-14 07:26:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/516f2fa360801d2a1903692fc2bfe26116c1404e', 'message': 'BigSwitch: Add SSL Certificate Validation\n\nThis patch adds the option to use SSL certificate\nvalidation on the backend controller using SSH-style\nsticky authentication, individual trusted\ncertificates, and/or certificate authorities.\n\nImplements: blueprint bsn-certificate-enforcement\nChange-Id: If0bab196495c4944a53e0e394c956cca36269883\n'}, {'number': 15, 'created': '2014-02-14 07:26:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/4760bff10474790027a1973ca165a95e0e9b8498', 'message': 'BigSwitch: Add SSL Certificate Validation\n\nThis patch adds the option to use SSL certificate\nvalidation on the backend controller using SSH-style\nsticky authentication, individual trusted\ncertificates, and/or certificate authorities.\n\nImplements: blueprint bsn-certificate-enforcement\nChange-Id: If0bab196495c4944a53e0e394c956cca36269883\n'}, {'number': 17, 'created': '2014-02-18 20:20:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/899914aa5d0b629becf7777c5fce8d0585c108fa', 'message': 'BigSwitch: Add SSL Certificate Validation\n\nThis patch adds the option to use SSL certificate\nvalidation on the backend controller using SSH-style\nsticky authentication, individual trusted\ncertificates, and/or certificate authorities.\n\nImplements: blueprint bsn-certificate-enforcement\nChange-Id: If0bab196495c4944a53e0e394c956cca36269883\n'}, {'number': 18, 'created': '2014-02-19 19:43:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/342198ac4c718c31fbd11e2c7a2ee9a52d66f4ee', 'message': 'BigSwitch: Add SSL Certificate Validation\n\nThis patch adds the option to use SSL certificate\nvalidation on the backend controller using SSH-style\nsticky authentication, individual trusted\ncertificates, and/or certificate authorities.\n\nImplements: blueprint bsn-certificate-enforcement\nChange-Id: If0bab196495c4944a53e0e394c956cca36269883\n'}, {'number': 19, 'created': '2014-02-19 19:47:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/a3d9a9db724527fd040eddd4d842735e2b8f294e', 'message': 'BigSwitch: Add SSL Certificate Validation\n\nThis patch adds the option to use SSL certificate\nvalidation on the backend controller using SSH-style\nsticky authentication, individual trusted\ncertificates, and/or certificate authorities.\n\nImplements: blueprint bsn-certificate-enforcement\nChange-Id: If0bab196495c4944a53e0e394c956cca36269883\n'}, {'number': 20, 'created': '2014-02-21 04:30:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/253162b544aa84cffbda3fbda09240a3f4f3c5ad', 'message': 'BigSwitch: Add SSL Certificate Validation\n\nThis patch adds the option to use SSL certificate\nvalidation on the backend controller using SSH-style\nsticky authentication, individual trusted\ncertificates, and/or certificate authorities.\n\nImplements: blueprint bsn-certificate-enforcement\nChange-Id: If0bab196495c4944a53e0e394c956cca36269883\n'}, {'number': 21, 'created': '2014-02-24 20:42:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/28385d10ee6e11e3ae0da74e426fa151877dfa1d', 'message': 'BigSwitch: Add SSL Certificate Validation\n\nThis patch adds the option to use SSL certificate\nvalidation on the backend controller using SSH-style\nsticky authentication, individual trusted\ncertificates, and/or certificate authorities.\n\nImplements: blueprint bsn-certificate-enforcement\nChange-Id: If0bab196495c4944a53e0e394c956cca36269883\n'}, {'number': 22, 'created': '2014-02-26 06:45:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/98967c4fdf9a1c09746b088cfa6f1242848f2a18', 'message': 'BigSwitch: Add SSL Certificate Validation\n\nThis patch adds the option to use SSL certificate\nvalidation on the backend controller using SSH-style\nsticky authentication, individual trusted\ncertificates, and/or certificate authorities.\nAlso adds caching of connections to deal with\nincreased overhead of TLS/SSL handshake.\n\nImplements: blueprint bsn-certificate-enforcement\nChange-Id: If0bab196495c4944a53e0e394c956cca36269883\n'}, {'number': 23, 'created': '2014-02-28 03:49:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/5597c87b387b776adaffe9885a851529658869f5', 'message': 'BigSwitch: Add SSL Certificate Validation\n\nThis patch adds the option to use SSL certificate\nvalidation on the backend controller using SSH-style\nsticky authentication, individual trusted\ncertificates, and/or certificate authorities.\nAlso adds caching of connections to deal with\nincreased overhead of TLS/SSL handshake.\n\nImplements: blueprint bsn-certificate-enforcement\nChange-Id: If0bab196495c4944a53e0e394c956cca36269883\n'}, {'number': 24, 'created': '2014-02-28 15:55:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/60e4ff9eb673f325fdca19b8b600d49b300ecb2b', 'message': 'BigSwitch: Add SSL Certificate Validation\n\nThis patch adds the option to use SSL certificate\nvalidation on the backend controller using SSH-style\nsticky authentication, individual trusted\ncertificates, and/or certificate authorities.\nAlso adds caching of connections to deal with\nincreased overhead of TLS/SSL handshake.\n\nImplements: blueprint bsn-certificate-enforcement\nChange-Id: If0bab196495c4944a53e0e394c956cca36269883\n'}, {'number': 25, 'created': '2014-02-28 17:01:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/fbab4a22cfad16aff42c1f04da915ab2fdea734b', 'message': 'BigSwitch: Add SSL Certificate Validation\n\nThis patch adds the option to use SSL certificate\nvalidation on the backend controller using SSH-style\nsticky authentication, individual trusted\ncertificates, and/or certificate authorities.\nAlso adds caching of connections to deal with\nincreased overhead of TLS/SSL handshake.\n\nImplements: blueprint bsn-certificate-enforcement\nChange-Id: If0bab196495c4944a53e0e394c956cca36269883\n'}, {'number': 26, 'created': '2014-03-01 18:28:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/b8855747aa948bdb20d55a5e17f6c330b20cff82', 'message': 'BigSwitch: Add SSL Certificate Validation\n\nThis patch adds the option to use SSL certificate\nvalidation on the backend controller using SSH-style\nsticky authentication, individual trusted\ncertificates, and/or certificate authorities.\nAlso adds caching of connections to deal with\nincreased overhead of TLS/SSL handshake.\n\nImplements: blueprint bsn-certificate-enforcement\nChange-Id: If0bab196495c4944a53e0e394c956cca36269883\n'}, {'number': 27, 'created': '2014-03-02 00:52:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/9fd376b0e0d62cbc2f26eecad46aff9ddd866107', 'message': 'BigSwitch: Add SSL Certificate Validation\n\nThis patch adds the option to use SSL certificate\nvalidation on the backend controller using SSH-style\nsticky authentication, individual trusted\ncertificates, and/or certificate authorities.\nAlso adds caching of connections to deal with\nincreased overhead of TLS/SSL handshake.\n\nDefault is now sticky-style enforcement.\n\nImplements: blueprint bsn-certificate-enforcement\nPartial-Bug: 1188189\nChange-Id: If0bab196495c4944a53e0e394c956cca36269883\n'}, {'number': 28, 'created': '2014-03-03 05:44:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/cd24d780505d32675f2d45ecad07c8d8ce5515ed', 'message': 'BigSwitch: Add SSL Certificate Validation\n\nThis patch adds the option to use SSL certificate\nvalidation on the backend controller using SSH-style\nsticky authentication, individual trusted\ncertificates, and/or certificate authorities.\nAlso adds caching of connections to deal with\nincreased overhead of TLS/SSL handshake.\n\nDefault is now sticky-style enforcement.\n\nPartial-Bug: 1188189\nImplements: blueprint bsn-certificate-enforcement\nChange-Id: If0bab196495c4944a53e0e394c956cca36269883\n'}, {'number': 29, 'created': '2014-03-04 06:03:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/695d23f176adbb10ffbed6df62df0d7a29b7b016', 'message': 'BigSwitch: Add SSL Certificate Validation\n\nThis patch adds the option to use SSL certificate\nvalidation on the backend controller using SSH-style\nsticky authentication, individual trusted\ncertificates, and/or certificate authorities.\nAlso adds caching of connections to deal with\nincreased overhead of TLS/SSL handshake.\n\nDefault is now sticky-style enforcement.\n\nPartial-Bug: 1188189\nImplements: blueprint bsn-certificate-enforcement\nChange-Id: If0bab196495c4944a53e0e394c956cca36269883\n'}, {'number': 30, 'created': '2014-03-04 21:07:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/f544a5505841f9719312b7283558efad15a3c45e', 'message': 'BigSwitch: Add SSL Certificate Validation\n\nThis patch adds the option to use SSL certificate\nvalidation on the backend controller using SSH-style\nsticky authentication, individual trusted\ncertificates, and/or certificate authorities.\nAlso adds caching of connections to deal with\nincreased overhead of TLS/SSL handshake.\n\nDefault is now sticky-style enforcement.\n\nPartial-Bug: 1188189\nImplements: blueprint bsn-certificate-enforcement\nChange-Id: If0bab196495c4944a53e0e394c956cca36269883\n'}, {'number': 31, 'created': '2014-03-04 21:52:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/3c536cc58a2ea171d959cf28881c37f890158ca6', 'message': 'BigSwitch: Add SSL Certificate Validation\n\nThis patch adds the option to use SSL certificate\nvalidation on the backend controller using SSH-style\nsticky authentication, individual trusted\ncertificates, and/or certificate authorities.\nAlso adds caching of connections to deal with\nincreased overhead of TLS/SSL handshake.\n\nDefault is now sticky-style enforcement.\n\nPartial-Bug: 1188189\nImplements: blueprint bsn-certificate-enforcement\nChange-Id: If0bab196495c4944a53e0e394c956cca36269883\n'}, {'number': 32, 'created': '2014-03-04 22:15:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/9d432f9443d632791889a1178d4db23244eb87da', 'message': 'BigSwitch: Add SSL Certificate Validation\n\nThis patch adds the option to use SSL certificate\nvalidation on the backend controller using SSH-style\nsticky authentication, individual trusted\ncertificates, and/or certificate authorities.\nAlso adds caching of connections to deal with\nincreased overhead of TLS/SSL handshake.\n\nDefault is now sticky-style enforcement.\n\nPartial-Bug: 1188189\nImplements: blueprint bsn-certificate-enforcement\nChange-Id: If0bab196495c4944a53e0e394c956cca36269883\n'}, {'number': 33, 'created': '2014-03-04 23:17:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/6a912451f3e2c5b22f7f893d68f7f1a1005e5a34', 'message': 'BigSwitch: Add SSL Certificate Validation\n\nThis patch adds the option to use SSL certificate\nvalidation on the backend controller using SSH-style\nsticky authentication, individual trusted\ncertificates, and/or certificate authorities.\nAlso adds caching of connections to deal with\nincreased overhead of TLS/SSL handshake.\n\nDefault is now sticky-style enforcement.\n\nPartial-Bug: 1188189\nImplements: blueprint bsn-certificate-enforcement\nChange-Id: If0bab196495c4944a53e0e394c956cca36269883\n'}, {'number': 34, 'created': '2014-03-05 20:08:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/1268b1d0877e672939010aae6465966dc442b8bc', 'message': 'BigSwitch: Add SSL Certificate Validation\n\nThis patch adds the option to use SSL certificate\nvalidation on the backend controller using SSH-style\nsticky authentication, individual trusted\ncertificates, and/or certificate authorities.\nAlso adds caching of connections to deal with\nincreased overhead of TLS/SSL handshake.\n\nDefault is now sticky-style enforcement.\n\nPartial-Bug: 1188189\nImplements: blueprint bsn-certificate-enforcement\nChange-Id: If0bab196495c4944a53e0e394c956cca36269883\n'}, {'number': 35, 'created': '2014-03-06 00:01:05.000000000', 'files': ['etc/neutron/plugins/bigswitch/ssl/host_certs/README', 'neutron/tests/unit/bigswitch/etc/ssl/combined/README', 'neutron/tests/unit/bigswitch/test_ssl.py', 'etc/neutron/plugins/bigswitch/ssl/ca_certs/README', 'neutron/plugins/bigswitch/servermanager.py', 'etc/neutron/plugins/bigswitch/restproxy.ini', 'neutron/plugins/bigswitch/config.py', 'neutron/tests/unit/bigswitch/fake_server.py', 'neutron/tests/unit/bigswitch/test_base.py', 'neutron/tests/unit/bigswitch/etc/ssl/ca_certs/README', 'neutron/tests/unit/bigswitch/etc/ssl/host_certs/README', 'setup.cfg'], 'web_link': 'https://opendev.org/openstack/neutron/commit/7255e056092f034daaeb4246a812900645d46911', 'message': 'BigSwitch: Add SSL Certificate Validation\n\nThis patch adds the option to use SSL certificate\nvalidation on the backend controller using SSH-style\nsticky authentication, individual trusted\ncertificates, and/or certificate authorities.\nAlso adds caching of connections to deal with\nincreased overhead of TLS/SSL handshake.\n\nDefault is now sticky-style enforcement.\n\nPartial-Bug: 1188189\nImplements: blueprint bsn-certificate-enforcement\nChange-Id: If0bab196495c4944a53e0e394c956cca36269883\n'}]",30,70906,7255e056092f034daaeb4246a812900645d46911,435,27,35,7787,,,0,"BigSwitch: Add SSL Certificate Validation

This patch adds the option to use SSL certificate
validation on the backend controller using SSH-style
sticky authentication, individual trusted
certificates, and/or certificate authorities.
Also adds caching of connections to deal with
increased overhead of TLS/SSL handshake.

Default is now sticky-style enforcement.

Partial-Bug: 1188189
Implements: blueprint bsn-certificate-enforcement
Change-Id: If0bab196495c4944a53e0e394c956cca36269883
",git fetch https://review.opendev.org/openstack/neutron refs/changes/06/70906/32 && git format-patch -1 --stdout FETCH_HEAD,"['etc/neutron/plugins/bigswitch/ssl/host_certs/README', 'neutron/plugins/bigswitch/plugin.py', 'etc/neutron/plugins/bigswitch/ssl/ca_certs/README', 'etc/neutron/plugins/bigswitch/restproxy.ini']",4,a6c4637f2b54d6ada4a551e61f78aa9f1cd9c409,fix_migrations,# Directory which contains the ca_certs and host_certs to be used to validate # controller certificates. # Default: # server_ssl_directory = ,,45,1
openstack%2Fneutron~master~I07c92b011453f6bf81b8ee12661170817287cdd7,openstack/neutron,master,I07c92b011453f6bf81b8ee12661170817287cdd7,BigSwitch: Auto re-sync on backend inconsistencies,MERGED,2014-02-14 11:34:27.000000000,2014-03-06 07:09:17.000000000,2014-03-06 07:09:16.000000000,"[{'_account_id': 3}, {'_account_id': 105}, {'_account_id': 490}, {'_account_id': 704}, {'_account_id': 841}, {'_account_id': 1689}, {'_account_id': 2035}, {'_account_id': 2592}, {'_account_id': 5170}, {'_account_id': 6598}, {'_account_id': 7591}, {'_account_id': 7787}, {'_account_id': 7962}, {'_account_id': 9008}, {'_account_id': 9681}, {'_account_id': 9682}, {'_account_id': 9732}, {'_account_id': 9787}, {'_account_id': 9845}, {'_account_id': 9925}, {'_account_id': 10116}, {'_account_id': 10117}, {'_account_id': 10153}, {'_account_id': 10184}, {'_account_id': 10192}, {'_account_id': 10294}, {'_account_id': 10310}, {'_account_id': 10387}]","[{'number': 1, 'created': '2014-02-14 11:34:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/a15646179c59c894444f7933af2286c5062304cb', 'message': 'BigSwitch: Auto re-sync on backend inconsistencies\n\nTrigger a background synchronization of all data\nif the plugin tries to create a port and receives\na 404 error.\n\nImplements: blueprint bsn-auto-resync\nChange-Id: I07c92b011453f6bf81b8ee12661170817287cdd7\n'}, {'number': 2, 'created': '2014-02-19 21:57:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/4868fb7df6a5ac964950b503f5e65be517f5b70a', 'message': 'BigSwitch: Auto re-sync on backend inconsistencies\n\nTrigger a background synchronization of all data\nif the plugin tries to create a port and receives\na 404 error.\n\nImplements: blueprint bsn-auto-resync\nChange-Id: I07c92b011453f6bf81b8ee12661170817287cdd7\n'}, {'number': 3, 'created': '2014-02-20 19:19:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/2b17bd708c8e0c2f0680378e26476a9fad008db2', 'message': 'BigSwitch: Auto re-sync on backend inconsistencies\n\nTrigger a background synchronization of all data\nif the plugin tries to create a port and receives\na 404 error.\n\nImplements: blueprint bsn-auto-resync\nChange-Id: I07c92b011453f6bf81b8ee12661170817287cdd7\n'}, {'number': 4, 'created': '2014-02-21 04:37:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/7de8ac54371c46c538a6c6e5103f16ab5fb1d45b', 'message': 'BigSwitch: Auto re-sync on backend inconsistencies\n\nTrigger a background synchronization of all data\nif the plugin tries to create a port and receives\na 404 error.\n\nImplements: blueprint bsn-auto-resync\nChange-Id: I07c92b011453f6bf81b8ee12661170817287cdd7\n'}, {'number': 5, 'created': '2014-02-24 06:00:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/082c7b53eeac8ddf648cd0b758a59ef8245f8bd6', 'message': 'BigSwitch: Auto re-sync on backend inconsistencies\n\nTrigger a background synchronization of all data\nif the plugin tries to create a port and receives\na 404 error.\n\nImplements: blueprint bsn-auto-resync\nChange-Id: I07c92b011453f6bf81b8ee12661170817287cdd7\n'}, {'number': 6, 'created': '2014-02-24 21:10:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/32a1a5dbe6d52d67e5d1a8e6d5a3f68b1fc3b988', 'message': 'BigSwitch: Auto re-sync on backend inconsistencies\n\nTrigger a background synchronization of all data\nif the plugin tries to create a port and receives\na 404 error.\n\nImplements: blueprint bsn-auto-resync\nChange-Id: I07c92b011453f6bf81b8ee12661170817287cdd7\n'}, {'number': 7, 'created': '2014-02-26 04:35:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/d3d468fbe0151b52267ff13f20169f3a0de08cfa', 'message': 'BigSwitch: Auto re-sync on backend inconsistencies\n\nTrigger a background synchronization of all data\nif the plugin tries to create a port and receives\na 404 error.\n\nImplements: blueprint bsn-auto-resync\nChange-Id: I07c92b011453f6bf81b8ee12661170817287cdd7\n'}, {'number': 8, 'created': '2014-02-26 08:53:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/e58fa2385b9a21c7a4a3a35ed56431725536bc23', 'message': ""BigSwitch: Auto re-sync on backend inconsistencies\n\nIf the controller supports it, pass a hash to the\ncontroller indicating the expected state that a\nREST transaction is updating. If the state is\ninconsistent, the controller will return a 409\nand the plugin will trigger a full synchronization.\n\nFor controllers that don't support the consistency\nhash, trigger a full background synchronization\nif the plugin tries to create a port and receives\na 404 error.\n\nImplements: blueprint bsn-auto-resync\nChange-Id: I07c92b011453f6bf81b8ee12661170817287cdd7\n""}, {'number': 9, 'created': '2014-02-26 19:25:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/9b9c74dc15e28b085d857e3bca1d36dd78193e18', 'message': ""BigSwitch: Auto re-sync on backend inconsistencies\n\nIf the controller supports it, pass a hash to the\ncontroller indicating the expected state that a\nREST transaction is updating. If the state is\ninconsistent, the controller will return a 409\nand the plugin will trigger a full synchronization.\n\nFor controllers that don't support the consistency\nhash, trigger a full background synchronization\nif the plugin tries to create a port and receives\na 404 error.\n\nImplements: blueprint bsn-auto-resync\nChange-Id: I07c92b011453f6bf81b8ee12661170817287cdd7\n""}, {'number': 10, 'created': '2014-02-26 19:31:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/6214a3328c83e5f98079a9f0a469873e312007d2', 'message': ""BigSwitch: Auto re-sync on backend inconsistencies\n\nIf the controller supports it, pass a hash to the\ncontroller indicating the expected state that a\nREST transaction is updating. If the state is\ninconsistent, the controller will return a 409\nand the plugin will trigger a full synchronization.\n\nFor controllers that don't support the consistency\nhash, trigger a full background synchronization\nif the plugin tries to create a port and receives\na 404 error.\n\nImplements: blueprint bsn-auto-resync\nChange-Id: I07c92b011453f6bf81b8ee12661170817287cdd7\n""}, {'number': 11, 'created': '2014-02-28 06:51:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/2bd9d7ba61b54d02dd6d95534d87cabff6dd063e', 'message': ""BigSwitch: Auto re-sync on backend inconsistencies\n\nIf the controller supports it, pass a hash to the\ncontroller indicating the expected state that a\nREST transaction is updating. If the state is\ninconsistent, the controller will return a 409\nand the plugin will trigger a full synchronization.\n\nFor controllers that don't support the consistency\nhash, trigger a full background synchronization\nif the plugin tries to create a port and receives\na 404 error.\n\nImplements: blueprint bsn-auto-resync\nChange-Id: I07c92b011453f6bf81b8ee12661170817287cdd7\n""}, {'number': 12, 'created': '2014-02-28 07:13:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/a333b33f0c7002aaf36ae7b358acd33e38bbee08', 'message': ""BigSwitch: Auto re-sync on backend inconsistencies\n\nIf the controller supports it, pass a hash to the\ncontroller indicating the expected state that a\nREST transaction is updating. If the state is\ninconsistent, the controller will return a 409\nand the plugin will trigger a full synchronization.\n\nFor controllers that don't support the consistency\nhash, trigger a full background synchronization\nif the plugin tries to create a port and receives\na 404 error.\n\nImplements: blueprint bsn-auto-resync\nChange-Id: I07c92b011453f6bf81b8ee12661170817287cdd7\n""}, {'number': 13, 'created': '2014-03-02 02:24:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/3fc677fb66f7cde2fe6148a98225342f7633fc96', 'message': ""BigSwitch: Auto re-sync on backend inconsistencies\n\nIf the controller supports it, pass a hash to the\ncontroller indicating the expected state that a\nREST transaction is updating. If the state is\ninconsistent, the controller will return a 409\nand the plugin will trigger a full synchronization.\n\nFor controllers that don't support the consistency\nhash, trigger a full background synchronization\nif the plugin tries to create a port and receives\na 404 error.\n\nImplements: blueprint bsn-auto-resync\nChange-Id: I07c92b011453f6bf81b8ee12661170817287cdd7\n""}, {'number': 14, 'created': '2014-03-02 09:09:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/682dce1c8b06efe6549a7894ac59061429918fd5', 'message': ""BigSwitch: Auto re-sync on backend inconsistencies\n\nIf the controller supports it, pass a hash to the\ncontroller indicating the expected state that a\nREST transaction is updating. If the state is\ninconsistent, the controller will return a 409\nand the plugin will trigger a full synchronization.\n\nFor controllers that don't support the consistency\nhash, trigger a full background synchronization\nif the plugin tries to create a port and receives\na 404 error.\n\nImplements: blueprint bsn-auto-resync\nChange-Id: I07c92b011453f6bf81b8ee12661170817287cdd7\n""}, {'number': 15, 'created': '2014-03-02 19:41:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/16729307c605fadd3f4b36104cf0bcdee984c625', 'message': ""BigSwitch: Auto re-sync on backend inconsistencies\n\nIf the controller supports it, pass a hash to the\ncontroller indicating the expected state that a\nREST transaction is updating. If the state is\ninconsistent, the controller will return a 409\nand the plugin will trigger a full synchronization.\n\nFor controllers that don't support the consistency\nhash, trigger a full background synchronization\nif the plugin tries to create a port and receives\na 404 error.\n\nImplements: blueprint bsn-auto-resync\nChange-Id: I07c92b011453f6bf81b8ee12661170817287cdd7\n""}, {'number': 16, 'created': '2014-03-03 08:21:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/6360402ae06b17a0496dcb0ae4709fb72b69ba39', 'message': ""BigSwitch: Auto re-sync on backend inconsistencies\n\nIf the controller supports it, pass a hash to the\ncontroller indicating the expected state that a\nREST transaction is updating. If the state is\ninconsistent, the controller will return a 409\nand the plugin will trigger a full synchronization.\n\nFor controllers that don't support the consistency\nhash, trigger a full background synchronization\nif the plugin tries to create a port and receives\na 404 error.\n\nImplements: blueprint bsn-auto-resync\nChange-Id: I07c92b011453f6bf81b8ee12661170817287cdd7\n""}, {'number': 17, 'created': '2014-03-03 10:32:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/9cdb925791b7f8fea53a9fcdb6d5e80d5ec1e956', 'message': ""BigSwitch: Auto re-sync on backend inconsistencies\n\nIf the controller supports it, pass a hash to the\ncontroller indicating the expected state that a\nREST transaction is updating. If the state is\ninconsistent, the controller will return a 409\nand the plugin will trigger a full synchronization.\n\nFor controllers that don't support the consistency\nhash, trigger a full background synchronization\nif the plugin tries to create a port and receives\na 404 error.\n\nImplements: blueprint bsn-auto-resync\nChange-Id: I07c92b011453f6bf81b8ee12661170817287cdd7\n""}, {'number': 18, 'created': '2014-03-03 21:30:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/0275707d5d05944c26208fe553503cbf0f40d21b', 'message': ""BigSwitch: Auto re-sync on backend inconsistencies\n\nIf the controller supports it, pass a hash to the\ncontroller indicating the expected state that a\nREST transaction is updating. If the state is\ninconsistent, the controller will return a 409\nand the plugin will trigger a full synchronization.\n\nFor controllers that don't support the consistency\nhash, trigger a full background synchronization\nif the plugin tries to create a port and receives\na 404 error.\n\nImplements: blueprint bsn-auto-resync\nChange-Id: I07c92b011453f6bf81b8ee12661170817287cdd7\n""}, {'number': 19, 'created': '2014-03-04 01:18:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/7da646852c85800f05ba56e94e838969cecfa1d4', 'message': ""BigSwitch: Auto re-sync on backend inconsistencies\n\nIf the controller supports it, pass a hash to the\ncontroller indicating the expected state that a\nREST transaction is updating. If the state is\ninconsistent, the controller will return a 409\nand the plugin will trigger a full synchronization.\n\nFor controllers that don't support the consistency\nhash, trigger a full background synchronization\nif the plugin tries to create a port and receives\na 404 error.\n\nImplements: blueprint bsn-auto-resync\nChange-Id: I07c92b011453f6bf81b8ee12661170817287cdd7\n""}, {'number': 20, 'created': '2014-03-04 18:39:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/4628ac47b41ae28008866df36e8588947a78f204', 'message': ""BigSwitch: Auto re-sync on backend inconsistencies\n\nIf the controller supports it, pass a hash to the\ncontroller indicating the expected state that a\nREST transaction is updating. If the state is\ninconsistent, the controller will return an error\nindicating a conflict and the plugin/driver will\ntrigger a full synchronization.\n\nFor controllers that don't support the consistency\nhash, trigger a full background synchronization\nif the plugin tries to create a port and receives\na 404 error due to the parent network not existing.\n\nImplements: blueprint bsn-auto-resync\nChange-Id: I07c92b011453f6bf81b8ee12661170817287cdd7\n""}, {'number': 21, 'created': '2014-03-05 19:39:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/6a0ced13aaef1942f1912d364913e2ab4efe5678', 'message': ""BigSwitch: Auto re-sync on backend inconsistencies\n\nIf the controller supports it, pass a hash to the\ncontroller indicating the expected state that a\nREST transaction is updating. If the state is\ninconsistent, the controller will return an error\nindicating a conflict and the plugin/driver will\ntrigger a full synchronization.\n\nFor controllers that don't support the consistency\nhash, trigger a full background synchronization\nif the plugin tries to create a port and receives\na 404 error due to the parent network not existing.\n\nImplements: blueprint bsn-auto-resync\nChange-Id: I07c92b011453f6bf81b8ee12661170817287cdd7\n""}, {'number': 22, 'created': '2014-03-06 00:01:07.000000000', 'files': ['neutron/tests/unit/ml2/drivers/test_bigswitch_mech.py', 'neutron/tests/unit/bigswitch/test_base.py', 'neutron/plugins/bigswitch/plugin.py', 'neutron/db/migration/alembic_migrations/versions/81c553f3776c_bsn_consistencyhashes.py', 'neutron/tests/unit/bigswitch/test_restproxy_plugin.py', 'neutron/plugins/bigswitch/servermanager.py', 'neutron/plugins/ml2/drivers/mech_bigswitch/driver.py', 'neutron/plugins/bigswitch/db/consistency_db.py', 'etc/neutron/plugins/bigswitch/restproxy.ini', 'neutron/plugins/bigswitch/config.py', 'neutron/tests/unit/bigswitch/fake_server.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/eb7de12defaa30624141f27631228f49ab8befc9', 'message': ""BigSwitch: Auto re-sync on backend inconsistencies\n\nIf the controller supports it, pass a hash to the\ncontroller indicating the expected state that a\nREST transaction is updating. If the state is\ninconsistent, the controller will return an error\nindicating a conflict and the plugin/driver will\ntrigger a full synchronization.\n\nFor controllers that don't support the consistency\nhash, trigger a full background synchronization\nif the plugin tries to create a port and receives\na 404 error due to the parent network not existing.\n\nImplements: blueprint bsn-auto-resync\nChange-Id: I07c92b011453f6bf81b8ee12661170817287cdd7\n""}]",34,73575,eb7de12defaa30624141f27631228f49ab8befc9,339,28,22,7787,,,0,"BigSwitch: Auto re-sync on backend inconsistencies

If the controller supports it, pass a hash to the
controller indicating the expected state that a
REST transaction is updating. If the state is
inconsistent, the controller will return an error
indicating a conflict and the plugin/driver will
trigger a full synchronization.

For controllers that don't support the consistency
hash, trigger a full background synchronization
if the plugin tries to create a port and receives
a 404 error due to the parent network not existing.

Implements: blueprint bsn-auto-resync
Change-Id: I07c92b011453f6bf81b8ee12661170817287cdd7
",git fetch https://review.opendev.org/openstack/neutron refs/changes/75/73575/17 && git format-patch -1 --stdout FETCH_HEAD,"['neutron/tests/unit/ml2/drivers/test_bigswitch_mech.py', 'neutron/plugins/bigswitch/plugin.py', 'neutron/tests/unit/bigswitch/test_restproxy_plugin.py', 'neutron/plugins/bigswitch/servermanager.py', 'neutron/plugins/ml2/drivers/mech_bigswitch/driver.py', 'etc/neutron/plugins/bigswitch/restproxy.ini', 'neutron/plugins/bigswitch/config.py', 'neutron/tests/unit/bigswitch/fake_server.py']",8,a15646179c59c894444f7933af2286c5062304cb,fix_migrations,"class HTTPConnectionMock404(HTTPConnectionMock): def __init__(self, server, port, timeout): self.response = HTTPResponseMock404(None) self.broken = True ",,130,17
openstack%2Fneutron~master~I58caf54219130159525b5a6492eaa451062c2ff5,openstack/neutron,master,I58caf54219130159525b5a6492eaa451062c2ff5,ovs-agent: use hexadecimal IP address in tunnel port name,MERGED,2014-02-18 17:12:05.000000000,2014-03-06 07:03:12.000000000,2014-03-06 07:03:11.000000000,"[{'_account_id': 3}, {'_account_id': 105}, {'_account_id': 1689}, {'_account_id': 2592}, {'_account_id': 2733}, {'_account_id': 2888}, {'_account_id': 4395}, {'_account_id': 5170}, {'_account_id': 6788}, {'_account_id': 6820}, {'_account_id': 6854}, {'_account_id': 6876}, {'_account_id': 8788}, {'_account_id': 9682}, {'_account_id': 9732}, {'_account_id': 9845}, {'_account_id': 9925}, {'_account_id': 10116}, {'_account_id': 10117}, {'_account_id': 10119}, {'_account_id': 10153}, {'_account_id': 10184}, {'_account_id': 10192}, {'_account_id': 10294}, {'_account_id': 10387}]","[{'number': 1, 'created': '2014-02-18 17:12:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/68261fa8b27cc1ca6be4726e20aaa606068b660c', 'message': ""ovs-agent: use hex ip addresses in tunnel port names\n\nWith some OVS/Linux combinations there is a 15 charactor limit on port\nnames, so a name like 'gre-192.168.10.10' does not work.\nThis fix uses the hexidecimal representation of the ip address instead.\n\nChange-Id: I58caf54219130159525b5a6492eaa451062c2ff5\nCloses-Bug: 1281098\n""}, {'number': 2, 'created': '2014-02-20 07:54:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/af6a2d97cfd83265c1594df0ec3d37ddb4b6c4ca', 'message': ""ovs-agent: use hexidecimal ip address in tunnel port name\n\nWith some OVS/Linux combinations there is a 15 charactor limit on port\nnames, so a name like 'gre-192.168.10.10' does not work.\nThis fix uses the hexidecimal representation of the ip address instead.\n\nChange-Id: I58caf54219130159525b5a6492eaa451062c2ff5\nCloses-Bug: 1281098\n""}, {'number': 3, 'created': '2014-02-21 10:09:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/76b06b3dee5f5aaa7868b0002dbbadd2b14ff6e1', 'message': ""ovs-agent: use hexidecimal ip address in tunnel port name\n\nWith some OVS/Linux combinations there is a 15 charactor limit on port\nnames, so a name like 'gre-192.168.10.10' does not work.\nThis fix uses the hexidecimal representation of the ip address instead.\n\nChange-Id: I58caf54219130159525b5a6492eaa451062c2ff5\nCloses-Bug: 1281098\n""}, {'number': 4, 'created': '2014-02-24 11:29:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/af751b1530937875ff009d83aed1f39bd355f6b7', 'message': ""ovs-agent: use hexidecimal ip address in tunnel port name\n\nWith some OVS/Linux combinations there is a 15 charactor limit on port\nnames, so a name like 'gre-192.168.10.10' does not work.\nThis fix uses the hexidecimal representation of the ip address instead.\n\nChange-Id: I58caf54219130159525b5a6492eaa451062c2ff5\nCloses-Bug: 1281098\n""}, {'number': 5, 'created': '2014-02-26 13:29:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/bc078e860636a2222f3af5ecec4e7c52ac35ca29', 'message': ""ovs-agent: use hexidecimal ip address in tunnel port name\n\nWith some OVS/Linux combinations there is a 15 charactor limit on port\nnames, so a name like 'gre-192.168.10.10' does not work.\nThis fix uses the hexidecimal representation of the ip address instead.\n\nChange-Id: I58caf54219130159525b5a6492eaa451062c2ff5\nCloses-Bug: 1281098\n""}, {'number': 6, 'created': '2014-02-27 07:45:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/1c3f71b89f0cd8019258665e8d068c5655820e2f', 'message': ""ovs-agent: use hexidecimal ip address in tunnel port name\n\nWith some OVS/Linux combinations there is a 15 charactor limit on port\nnames, so a name like 'gre-192.168.10.10' does not work.\nThis fix uses the hexidecimal representation of the ip address instead.\n\nChange-Id: I58caf54219130159525b5a6492eaa451062c2ff5\nCloses-Bug: 1281098\n""}, {'number': 7, 'created': '2014-02-27 15:06:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/c12f9c1033b7d326da7dfc1432aaa50213d78bf1', 'message': ""ovs-agent: use hexidecimal ip address in tunnel port name\n\nWith some OVS/Linux combinations there is a 15 charactor limit on port\nnames, so a name like 'gre-192.168.10.10' does not work.\nThis fix uses the hexidecimal representation of the ip address instead.\n\nChange-Id: I58caf54219130159525b5a6492eaa451062c2ff5\nCloses-Bug: 1281098\n""}, {'number': 8, 'created': '2014-02-28 08:11:47.000000000', 'files': ['neutron/tests/unit/openvswitch/test_ovs_neutron_agent.py', 'neutron/plugins/openvswitch/agent/ovs_neutron_agent.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/3d8ab7964ace4e96539cfbc0587c8f04c81ac3b3', 'message': ""ovs-agent: use hexadecimal IP address in tunnel port name\n\nThe remote IP address is used to form the tunnel port name when\nthe ovs-agent is used with the ML2 plugin. With some OVS/Linux\ncombinations there is a 15 character limit on port names, so a\nname like 'gre-192.168.10.10' does not work. This fix uses the\nshorter hexadecimal representation of the IP address instead.\n\nChange-Id: I58caf54219130159525b5a6492eaa451062c2ff5\nCloses-Bug: 1281098\n""}]",11,74442,3d8ab7964ace4e96539cfbc0587c8f04c81ac3b3,136,25,8,2733,,,0,"ovs-agent: use hexadecimal IP address in tunnel port name

The remote IP address is used to form the tunnel port name when
the ovs-agent is used with the ML2 plugin. With some OVS/Linux
combinations there is a 15 character limit on port names, so a
name like 'gre-192.168.10.10' does not work. This fix uses the
shorter hexadecimal representation of the IP address instead.

Change-Id: I58caf54219130159525b5a6492eaa451062c2ff5
Closes-Bug: 1281098
",git fetch https://review.opendev.org/openstack/neutron refs/changes/42/74442/4 && git format-patch -1 --stdout FETCH_HEAD,"['neutron/plugins/openvswitch/agent/ovs_neutron_agent.py', 'neutron/tests/unit/openvswitch/test_ovs_tunnel.py']",2,68261fa8b27cc1ca6be4726e20aaa606068b660c,bug/1281098," def test_tunnel_sync_with_ovs_plugin(self): a = ovs_neutron_agent.OVSNeutronAgent(self.INT_BRIDGE, self.TUN_BRIDGE, '10.0.0.1', self.NET_MAPPING, 'sudo', 2, ['gre'], self.VETH_MTU) a.plugin_rpc = mock.Mock() fake_tunnel_details = {'tunnels': [{'id': '42', 'ip_address': '100.101.102.103'}]} a.plugin_rpc.tunnel_sync.return_value = fake_tunnel_details a.setup_tunnel_port = mock.Mock() a.tunnel_sync() expected_calls = [mock.call('gre-42', '100.101.102.103', 'gre')] a.setup_tunnel_port.assert_has_calls(expected_calls) def test_tunnel_sync_with_ml2_plugin(self): a = ovs_neutron_agent.OVSNeutronAgent(self.INT_BRIDGE, self.TUN_BRIDGE, '10.0.0.1', self.NET_MAPPING, 'sudo', 2, ['gre'], self.VETH_MTU) a.plugin_rpc = mock.Mock() fake_tunnel_details = {'tunnels': [{'ip_address': '100.101.31.15'}]} a.plugin_rpc.tunnel_sync.return_value = fake_tunnel_details a.setup_tunnel_port = mock.Mock() a.tunnel_sync() expected_calls = [mock.call('gre-64651f0f', '100.101.31.15', 'gre')] a.setup_tunnel_port.assert_has_calls(expected_calls) ",,40,2
openstack%2Fnova~master~I53b7cc001b1253d60e9955bb1fa35a916d2d9c52,openstack/nova,master,I53b7cc001b1253d60e9955bb1fa35a916d2d9c52,vmwareapi: add image_transfer_timeout_secs config,ABANDONED,2014-01-30 20:16:36.000000000,2014-03-06 07:01:33.000000000,,"[{'_account_id': 3}, {'_account_id': 782}, {'_account_id': 1653}, {'_account_id': 2271}, {'_account_id': 8027}, {'_account_id': 9008}, {'_account_id': 9578}]","[{'number': 1, 'created': '2014-01-30 20:16:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/ebe8289a056a3e9162a80fe9bd0fc8c1e6a3c32c', 'message': 'vmwareapi: add image_transfer_timeout_secs config\n\nThis integer configuration option image_transfer_timeout_secs\nconfigures the maximum amount of time to wait for image tranfers\nto complete when the driver switches to use the oslo vmwarepi code\nfor image transfers.\n\nChange-Id: I53b7cc001b1253d60e9955bb1fa35a916d2d9c52\n'}, {'number': 2, 'created': '2014-01-31 08:27:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/b6902a28dce96ffdcce2fa0ae1c2c6fb818eca70', 'message': 'vmwareapi: add image_transfer_timeout_secs config\n\nThis integer configuration option image_transfer_timeout_secs\nconfigures the maximum amount of time to wait for image tranfers\nto complete when the driver switches to use the oslo vmwarepi code\nfor image transfers.\n\nChange-Id: I53b7cc001b1253d60e9955bb1fa35a916d2d9c52\n'}, {'number': 3, 'created': '2014-02-09 23:42:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/cd79c66a85b14f55bcffa542a6faba3cecd18fe5', 'message': 'vmwareapi: add image_transfer_timeout_secs config\n\nThis integer configuration option image_transfer_timeout_secs\nconfigures the maximum amount of time to wait for image tranfers\nto complete when the driver switches to use the oslo vmwarepi code\nfor image transfers.\n\nChange-Id: I53b7cc001b1253d60e9955bb1fa35a916d2d9c52\n'}, {'number': 4, 'created': '2014-02-10 05:09:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/74462c899d9d8bc67bbcd00064d21f5af9b83f17', 'message': 'vmwareapi: add image_transfer_timeout_secs config\n\nThis integer configuration option image_transfer_timeout_secs\nconfigures the maximum amount of time to wait for image tranfers\nto complete when the driver switches to use the oslo vmwarepi code\nfor image transfers.\n\nDocImpact - new option to configure timeout on image transfers\n\nChange-Id: I53b7cc001b1253d60e9955bb1fa35a916d2d9c52\n'}, {'number': 5, 'created': '2014-02-10 09:33:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/eebbef8982783ee2cb0bb05858b79f79c89a3231', 'message': 'vmwareapi: add image_transfer_timeout_secs config\n\nThis integer configuration option image_transfer_timeout_secs\nconfigures the maximum amount of time to wait for image tranfers\nto complete when the driver switches to use the oslo vmwarepi code\nfor image transfers.\n\nDocImpact - new option to configure timeout on image transfers\n\nChange-Id: I53b7cc001b1253d60e9955bb1fa35a916d2d9c52\n'}, {'number': 6, 'created': '2014-02-11 08:57:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/12f3f455d019659ebfd0f9298a6b8b3dbc1be5d2', 'message': 'vmwareapi: add image_transfer_timeout_secs config\n\nThis integer configuration option image_transfer_timeout_secs\nconfigures the maximum amount of time to wait for image tranfers\nto complete when the driver switches to use the oslo vmwarepi code\nfor image transfers.\n\nDocImpact - new option to configure timeout on image transfers\n\nChange-Id: I53b7cc001b1253d60e9955bb1fa35a916d2d9c52\n'}, {'number': 7, 'created': '2014-02-15 07:25:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/a8ac2839ed7b453ba66e67ca0d39b9e9a6a3b7d5', 'message': 'vmwareapi: add image_transfer_timeout_secs config\n\nThis integer configuration option image_transfer_timeout_secs\nconfigures the maximum amount of time to wait for image tranfers\nto complete when the driver switches to use the oslo vmwarepi code\nfor image transfers.\n\nDocImpact - new option to configure timeout on image transfers\n\nChange-Id: I53b7cc001b1253d60e9955bb1fa35a916d2d9c52\n'}, {'number': 8, 'created': '2014-02-17 06:53:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/dd661dca712bd8b1572c6df8c3659e461ab684e6', 'message': 'vmwareapi: add image_transfer_timeout_secs config\n\nThis integer configuration option image_transfer_timeout_secs\nconfigures the maximum amount of time to wait for image tranfers\nto complete when the driver switches to use the oslo vmwarepi code\nfor image transfers.\n\nDocImpact - new option to configure timeout on image transfers\n\nChange-Id: I53b7cc001b1253d60e9955bb1fa35a916d2d9c52\n'}, {'number': 9, 'created': '2014-02-17 07:02:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/be35696669dee7b8f6f33dd53232ce5ef21855cc', 'message': 'vmwareapi: add image_transfer_timeout_secs config\n\nThis integer configuration option image_transfer_timeout_secs\nconfigures the maximum amount of time to wait for image tranfers\nto complete when the driver switches to use the oslo vmwarepi code\nfor image transfers.\n\nDocImpact - new option to configure timeout on image transfers\n\nChange-Id: I53b7cc001b1253d60e9955bb1fa35a916d2d9c52\n'}, {'number': 10, 'created': '2014-02-18 07:41:27.000000000', 'files': ['nova/virt/vmwareapi/vmops.py', 'etc/nova/nova.conf.sample'], 'web_link': 'https://opendev.org/openstack/nova/commit/1e3a9a16081e987c82cd8d0c09fd2a20a80e42d6', 'message': 'vmwareapi: add image_transfer_timeout_secs config\n\nThis integer configuration option image_transfer_timeout_secs\nconfigures the maximum amount of time to wait for image tranfers\nto complete when the driver switches to use the oslo vmwarepi code\nfor image transfers.\n\nDocImpact - new option to configure timeout on image transfers\n\nChange-Id: I53b7cc001b1253d60e9955bb1fa35a916d2d9c52\n'}]",1,70212,1e3a9a16081e987c82cd8d0c09fd2a20a80e42d6,75,7,10,8027,,,0,"vmwareapi: add image_transfer_timeout_secs config

This integer configuration option image_transfer_timeout_secs
configures the maximum amount of time to wait for image tranfers
to complete when the driver switches to use the oslo vmwarepi code
for image transfers.

DocImpact - new option to configure timeout on image transfers

Change-Id: I53b7cc001b1253d60e9955bb1fa35a916d2d9c52
",git fetch https://review.opendev.org/openstack/nova refs/changes/12/70212/5 && git format-patch -1 --stdout FETCH_HEAD,"['nova/virt/vmwareapi/vmops.py', 'etc/nova/nova.conf.sample']",2,ebe8289a056a3e9162a80fe9bd0fc8c1e6a3c32c,bp/vmware-vsan-support,# Whether to use linked clone (integer value) #image_transfer_timeout_secs=7200 ,,9,2
openstack%2Fneutron~stable%2Fhavana~I4fcf19fa84f178348abfb3563bbfd52f0dfcc095,openstack/neutron,stable/havana,I4fcf19fa84f178348abfb3563bbfd52f0dfcc095,Fix a typo in log exception in the metering agent,MERGED,2013-12-10 11:22:05.000000000,2014-03-06 06:51:41.000000000,2014-03-06 06:51:38.000000000,"[{'_account_id': 3}, {'_account_id': 55}, {'_account_id': 704}, {'_account_id': 748}, {'_account_id': 841}, {'_account_id': 2592}, {'_account_id': 2711}, {'_account_id': 4395}, {'_account_id': 6316}, {'_account_id': 6659}, {'_account_id': 7141}, {'_account_id': 7781}, {'_account_id': 9787}, {'_account_id': 10387}]","[{'number': 1, 'created': '2013-12-10 11:22:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/050108cd3dc2990c87d452ddf092d9bedc4ffb9e', 'message': 'Fix a typo in log exception in the metering agent\n\nThis patch fixes a typo when there is a exception\nwhen the agent try to invoke a method of the driver.\n\nChange-Id: I4fcf19fa84f178348abfb3563bbfd52f0dfcc095\nCloses-bug: #1256041\n(cherry picked from commit 272912b6d82af00a6f7bafc26d8ce7a79b09ef26)\n'}, {'number': 2, 'created': '2013-12-17 09:40:01.000000000', 'files': ['neutron/services/metering/agents/metering_agent.py', 'neutron/tests/unit/services/metering/test_metering_agent.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/c0586c419f23cb46ee7952f860cb7273de07f8d8', 'message': 'Fix a typo in log exception in the metering agent\n\nThis patch fixes a typo when there is a exception\nwhen the agent try to invoke a method of the driver.\nThis patch also improves exceptions handling of\ndriver method calls.\n\nChange-Id: I4fcf19fa84f178348abfb3563bbfd52f0dfcc095\nCloses-bug: #1256041\n(cherry picked from commit 272912b6d82af00a6f7bafc26d8ce7a79b09ef26)\n'}]",0,61085,c0586c419f23cb46ee7952f860cb7273de07f8d8,58,14,2,7141,,,0,"Fix a typo in log exception in the metering agent

This patch fixes a typo when there is a exception
when the agent try to invoke a method of the driver.
This patch also improves exceptions handling of
driver method calls.

Change-Id: I4fcf19fa84f178348abfb3563bbfd52f0dfcc095
Closes-bug: #1256041
(cherry picked from commit 272912b6d82af00a6f7bafc26d8ce7a79b09ef26)
",git fetch https://review.opendev.org/openstack/neutron refs/changes/85/61085/2 && git format-patch -1 --stdout FETCH_HEAD,"['neutron/services/metering/agents/metering_agent.py', 'neutron/tests/unit/services/metering/test_metering_agent.py']",2,050108cd3dc2990c87d452ddf092d9bedc4ffb9e,havana-bug/1256041," class TestMeteringDriver(base.BaseTestCase): def setUp(self): super(TestMeteringDriver, self).setUp() cfg.CONF.register_opts(metering_agent.MeteringAgent.Opts) config.register_root_helper(cfg.CONF) self.noop_driver = ('neutron.services.metering.drivers.noop.' 'noop_driver.NoopMeteringDriver') cfg.CONF.set_override('driver', self.noop_driver) self.agent = metering_agent.MeteringAgent('my agent', cfg.CONF) self.driver = mock.Mock() self.agent.metering_driver = self.driver self.addCleanup(mock.patch.stopall) def test_add_metering_label_with_bad_driver_impl(self): del self.driver.add_metering_label with mock.patch.object(metering_agent, 'LOG') as log: self.agent.add_metering_label(None, ROUTERS) log.exception.assert_called_with(mock.ANY, {'driver': self.noop_driver, 'func': 'add_metering_label'}) def test_add_metering_label_runtime_error(self): self.driver.add_metering_label.side_effect = RuntimeError with mock.patch.object(metering_agent, 'LOG') as log: self.agent.add_metering_label(None, ROUTERS) log.exception.assert_called_with(mock.ANY, {'driver': self.noop_driver, 'func': 'add_metering_label'})",,42,2
openstack%2Fpuppet-horizon~master~Id73b9986e561f1dc7557ae725518ec7694fc0da2,openstack/puppet-horizon,master,Id73b9986e561f1dc7557ae725518ec7694fc0da2,Parameterize OPENSTACK_HYPERVISOR_FEATURES settings,MERGED,2014-01-22 16:43:03.000000000,2014-03-06 06:49:57.000000000,2014-03-06 06:49:57.000000000,"[{'_account_id': 3}, {'_account_id': 1918}, {'_account_id': 3153}, {'_account_id': 6754}, {'_account_id': 6984}, {'_account_id': 6994}, {'_account_id': 7155}, {'_account_id': 7156}, {'_account_id': 7822}, {'_account_id': 8083}, {'_account_id': 9268}]","[{'number': 1, 'created': '2014-01-22 16:43:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-horizon/commit/529a2259d4c886bd7e08dbe6a8d0d0a5f89347ca', 'message': ""local_settings: Allow to manage can_set_password option\n\nWhen using KVM and not XEN, we can't offer to the users to set a root\npassword to their VM so we should simply hide this panel to avoid\nconfusion.\nSince puppet-nova installs KVM by default, can_set_password is at False\nby default.\n\nCloses-bug: #1271635\n\nChange-Id: Id73b9986e561f1dc7557ae725518ec7694fc0da2\nSigned-off-by: Emilien Macchi <emilien.macchi@enovance.com>\n""}, {'number': 2, 'created': '2014-01-22 16:44:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-horizon/commit/2bf6ada90fa23b3b141e20ffdfbb56e7fbd0fbb9', 'message': ""local_settings: Allow to manage can_set_password option\n\nWhen using KVM and not XEN, we can't offer to the users to set a root\npassword to their VM so we should simply hide this panel to avoid\nconfusion.\nSince puppet-nova installs KVM by default, can_set_password is at False\nby default.\n\nCloses-bug: #1271635\n\nChange-Id: Id73b9986e561f1dc7557ae725518ec7694fc0da2\nSigned-off-by: Emilien Macchi <emilien.macchi@enovance.com>\n""}, {'number': 3, 'created': '2014-01-31 15:05:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-horizon/commit/10cbdabced0bbdc44c293b7aee98677ce88228d2', 'message': ""local_settings: Allow to manage can_set_password option\n\nWhen using KVM and not XEN, we can't offer to the users to set a root\npassword to their VM so we should simply hide this panel to avoid\nconfusion.\nSince puppet-nova installs KVM by default, can_set_password is at False\nby default.\n\nCloses-bug: #1271635\n\nChange-Id: Id73b9986e561f1dc7557ae725518ec7694fc0da2\nSigned-off-by: Emilien Macchi <emilien.macchi@enovance.com>\n""}, {'number': 4, 'created': '2014-02-04 09:40:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-horizon/commit/6ac3a838671819233cf334756686f0c15f8d08c9', 'message': ""local_settings: Allow to manage can_set_password option\n\nWhen using KVM and not XEN, we can't offer to the users to set a root\npassword to their VM so we should simply hide this panel to avoid\nconfusion.\nSince puppet-nova installs KVM by default, can_set_password is at False\nby default.\nAlso deprecate can_set_mount_point parameter.\n\nCloses-bug: #1271635\n\nChange-Id: Id73b9986e561f1dc7557ae725518ec7694fc0da2\nSigned-off-by: Emilien Macchi <emilien.macchi@enovance.com>\n""}, {'number': 5, 'created': '2014-02-17 16:51:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-horizon/commit/43cbc014f03c6073d09c212de5935bd4af7dabc6', 'message': ""local_settings: Allow to manage can_set_password option\n\nWhen using KVM and not XEN, we can't offer to the users to set a root\npassword to their VM so we should simply hide this panel to avoid\nconfusion.\nSince puppet-nova installs KVM by default, can_set_password is at False\nby default.\n\nCloses-bug: #1271635\n\nChange-Id: Id73b9986e561f1dc7557ae725518ec7694fc0da2\nSigned-off-by: Emilien Macchi <emilien.macchi@enovance.com>\n""}, {'number': 6, 'created': '2014-02-17 16:59:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-horizon/commit/245509ee001e5c6755c8e492ee319b6ec77b9be1', 'message': ""local_settings: Allow to manage can_set_password option\n\nWhen using KVM and not XEN, we can't offer to the users to set a root\npassword to their VM so we should simply hide this panel to avoid\nconfusion.\nSince puppet-nova installs KVM by default, can_set_password is at False\nby default.\n\nCloses-bug: #1271635\n\nChange-Id: Id73b9986e561f1dc7557ae725518ec7694fc0da2\nSigned-off-by: Emilien Macchi <emilien.macchi@enovance.com>\n""}, {'number': 7, 'created': '2014-02-19 09:46:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-horizon/commit/6bd158bbca4e9a62d5f9fc1b652f82bc01cd208e', 'message': ""local_settings: Allow to manage can_set_password option\n\nWhen using KVM and not XEN, we can't offer to the users to set a root\npassword to their VM so we should simply hide this panel to avoid\nconfusion.\nSince puppet-nova installs KVM by default, can_set_password is at False\nby default.\n\nCloses-bug: #1271635\n\nChange-Id: Id73b9986e561f1dc7557ae725518ec7694fc0da2\nSigned-off-by: Emilien Macchi <emilien.macchi@enovance.com>\n""}, {'number': 8, 'created': '2014-02-20 00:00:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-horizon/commit/5fc7409693407bcef1c7e0a3e24356762d77a77a', 'message': 'Parameterize OPENSTACK_HYPERVISOR_FEATURES settings\n\nHorizon can provide GUI support for some hypervisor specific features.\nHowever the setting to enable can_set_moint_point is currently hardcoded\nin the local_settings.py.erb template rather than being\nparameterized, making it impossible for users to enable support for\nthese functions. This patch adds a parameter hash to enable users to\nselect how they want to configure Hypervisor features and sets default\nvalues to match the old hardcoded settings to maintain backward\ncompatibility.\n\nCloses-bug: #1271635\n\nChange-Id: Id73b9986e561f1dc7557ae725518ec7694fc0da2\nSigned-off-by: Emilien Macchi <emilien.macchi@enovance.com>\n'}, {'number': 9, 'created': '2014-02-20 09:31:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-horizon/commit/ca3bd42bf36c9eb4aef03e24cee47749e4d89c95', 'message': 'Parameterize OPENSTACK_HYPERVISOR_FEATURES settings\n\nHorizon can provide GUI support for some hypervisor specific features.\nHowever the setting to enable can_set_moint_point is currently hardcoded\nin the local_settings.py.erb template rather than being\nparameterized, making it impossible for users to enable support for\nthese functions. This patch adds a parameter hash to enable users to\nselect how they want to configure Hypervisor features and sets default\nvalues to match the old hardcoded settings to maintain backward\ncompatibility.\n\nCloses-bug: #1271635\n\nChange-Id: Id73b9986e561f1dc7557ae725518ec7694fc0da2\nSigned-off-by: Emilien Macchi <emilien.macchi@enovance.com>\n'}, {'number': 10, 'created': '2014-03-05 21:48:48.000000000', 'files': ['templates/local_settings.py.erb', 'manifests/init.pp', 'spec/classes/horizon_init_spec.rb'], 'web_link': 'https://opendev.org/openstack/puppet-horizon/commit/8018baf22f5fe9efa3e57962510c80527fb9e7d5', 'message': 'Parameterize OPENSTACK_HYPERVISOR_FEATURES settings\n\nHorizon can provide GUI support for some hypervisor specific features.\nHowever the setting to enable can_set_moint_point is currently hardcoded\nin the local_settings.py.erb template rather than being\nparameterized, making it impossible for users to enable support for\nthese functions. This patch adds a parameter hash to enable users to\nselect how they want to configure Hypervisor features and sets default\nvalues to match the old hardcoded settings to maintain backward\ncompatibility.\n\nCloses-bug: #1271635\n\nChange-Id: Id73b9986e561f1dc7557ae725518ec7694fc0da2\nSigned-off-by: Emilien Macchi <emilien.macchi@enovance.com>\n'}]",10,68433,8018baf22f5fe9efa3e57962510c80527fb9e7d5,60,11,10,3153,,,0,"Parameterize OPENSTACK_HYPERVISOR_FEATURES settings

Horizon can provide GUI support for some hypervisor specific features.
However the setting to enable can_set_moint_point is currently hardcoded
in the local_settings.py.erb template rather than being
parameterized, making it impossible for users to enable support for
these functions. This patch adds a parameter hash to enable users to
select how they want to configure Hypervisor features and sets default
values to match the old hardcoded settings to maintain backward
compatibility.

Closes-bug: #1271635

Change-Id: Id73b9986e561f1dc7557ae725518ec7694fc0da2
Signed-off-by: Emilien Macchi <emilien.macchi@enovance.com>
",git fetch https://review.opendev.org/openstack/puppet-horizon refs/changes/33/68433/8 && git format-patch -1 --stdout FETCH_HEAD,"['templates/local_settings.py.erb', 'manifests/init.pp', 'spec/classes/horizon_init_spec.rb']",3,529a2259d4c886bd7e08dbe6a8d0d0a5f89347ca,bug-1271635-clean," "" 'can_set_password': False,"", :can_set_password => true "" 'can_set_password': True,"", "" 'can_set_password': False,"",",,11,0
openstack%2Fneutron~master~I69fe9cff4b550240215329e1082a63cd11617faf,openstack/neutron,master,I69fe9cff4b550240215329e1082a63cd11617faf,Query for port before calling l3plugin.disassociate_floatingips(),ABANDONED,2014-03-05 19:40:40.000000000,2014-03-06 06:44:24.000000000,,"[{'_account_id': 3}, {'_account_id': 5170}, {'_account_id': 9732}, {'_account_id': 9787}, {'_account_id': 9845}, {'_account_id': 10294}, {'_account_id': 10387}]","[{'number': 1, 'created': '2014-03-05 19:40:40.000000000', 'files': ['neutron/plugins/ml2/plugin.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/7c1edd0f65e82f6cc90fa5c4766544366d12b2e3', 'message': 'Query for port before calling l3plugin.disassociate_floatingips()\n\nThe call to l3plugin.disassociate_floatingips() trigggers several events\nthat could cause a timeout to occur trying to query the db for the port\ntherefore this patch changes the code to query first for the port.\n\nChange-Id: I69fe9cff4b550240215329e1082a63cd11617faf\n'}]",0,78393,7c1edd0f65e82f6cc90fa5c4766544366d12b2e3,10,7,1,4395,,,0,"Query for port before calling l3plugin.disassociate_floatingips()

The call to l3plugin.disassociate_floatingips() trigggers several events
that could cause a timeout to occur trying to query the db for the port
therefore this patch changes the code to query first for the port.

Change-Id: I69fe9cff4b550240215329e1082a63cd11617faf
",git fetch https://review.opendev.org/openstack/neutron refs/changes/93/78393/1 && git format-patch -1 --stdout FETCH_HEAD,['neutron/plugins/ml2/plugin.py'],1,7c1edd0f65e82f6cc90fa5c4766544366d12b2e3,master," if l3plugin: l3plugin.disassociate_floatingips(context, id) "," if l3plugin: l3plugin.disassociate_floatingips(context, id)",4,2
openstack%2Fcinder~stable%2Fhavana~I483d27b72de26e4d652c3162e1df2db75c553230,openstack/cinder,stable/havana,I483d27b72de26e4d652c3162e1df2db75c553230,Allow operators to customize max header size,ABANDONED,2014-02-24 01:19:12.000000000,2014-03-06 06:37:48.000000000,,"[{'_account_id': 3}, {'_account_id': 308}, {'_account_id': 1955}, {'_account_id': 6732}, {'_account_id': 8874}, {'_account_id': 8996}, {'_account_id': 10321}]","[{'number': 1, 'created': '2014-02-24 01:19:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/6d067069f1f413a10aeeaa46a1936716ecb44dfb', 'message': ""Allow operators to customize max header size\n\nHTTP messages max header line size has been increased from 8K to 16K\nby default to allow using tokens including up to 14-15 catalog\nentries.  The same issue\n(https://bugs.launchpad.net/swift/+bug/1190149) may occur again in\nthe future, if keystone's catalog grows further.\n\nAllowing operators to customize the max header size, will allow them\nto have Cinder working whatever the size of the catalog (if the option\nis properly set).\n\nRelated-Bug: #1190149\nDocImpact\n(cherry picked from commit be163cf1028aff50413a89060bb8badfa7d51ad5)\n\nChange-Id: I483d27b72de26e4d652c3162e1df2db75c553230\n""}, {'number': 2, 'created': '2014-02-28 03:59:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/3638bfbcff7ee91be3e98c42cc39f81abe69c39e', 'message': ""Allow operators to customize max header size\n\nHTTP messages max header line size has been increased from 8K to 16K\nby default to allow using tokens including up to 14-15 catalog\nentries.  The same issue\n(https://bugs.launchpad.net/swift/+bug/1190149) may occur again in\nthe future, if keystone's catalog grows further.\n\nAllowing operators to customize the max header size, will allow them\nto have Cinder working whatever the size of the catalog (if the option\nis properly set).\n\nRelated-Bug: #1190149\nDocImpact\n(cherry picked from commit be163cf1028aff50413a89060bb8badfa7d51ad5)\n\nChange-Id: I483d27b72de26e4d652c3162e1df2db75c553230\n""}, {'number': 3, 'created': '2014-02-28 12:10:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/5583be8c0d2dd648911390f505091f42134a50a1', 'message': ""Allow operators to customize max header size\n\nHTTP messages max header line size has been increased from 8K to 16K\nby default to allow using tokens including up to 14-15 catalog\nentries.  The same issue\n(https://bugs.launchpad.net/swift/+bug/1190149) may occur again in\nthe future, if keystone's catalog grows further.\n\nAllowing operators to customize the max header size, will allow them\nto have Cinder working whatever the size of the catalog (if the option\nis properly set).\n\nRelated-Bug: #1190149\nDocImpact\n(cherry picked from commit be163cf1028aff50413a89060bb8badfa7d51ad5)\n\nChange-Id: I483d27b72de26e4d652c3162e1df2db75c553230\n""}, {'number': 4, 'created': '2014-02-28 12:10:55.000000000', 'files': ['etc/cinder/cinder.conf.sample', 'cinder/wsgi.py'], 'web_link': 'https://opendev.org/openstack/cinder/commit/60d820a27d23422a7de04627bc822e28f08adcc4', 'message': ""Allow operators to customize max header size\n\nHTTP messages max header line size has been increased from 8K to 16K\nby default to allow using tokens including up to 14-15 catalog\nentries.  The same issue\n(https://bugs.launchpad.net/swift/+bug/1190149) may occur again in\nthe future, if keystone's catalog grows further.\n\nAllowing operators to customize the max header size, will allow them\nto have Cinder working whatever the size of the catalog (if the option\nis properly set).\n\nRelated-Bug: #1190149\nDocImpact\n(cherry picked from commit be163cf1028aff50413a89060bb8badfa7d51ad5)\n\nChange-Id: I483d27b72de26e4d652c3162e1df2db75c553230\n""}]",0,75732,60d820a27d23422a7de04627bc822e28f08adcc4,41,7,4,8874,,,0,"Allow operators to customize max header size

HTTP messages max header line size has been increased from 8K to 16K
by default to allow using tokens including up to 14-15 catalog
entries.  The same issue
(https://bugs.launchpad.net/swift/+bug/1190149) may occur again in
the future, if keystone's catalog grows further.

Allowing operators to customize the max header size, will allow them
to have Cinder working whatever the size of the catalog (if the option
is properly set).

Related-Bug: #1190149
DocImpact
(cherry picked from commit be163cf1028aff50413a89060bb8badfa7d51ad5)

Change-Id: I483d27b72de26e4d652c3162e1df2db75c553230
",git fetch https://review.opendev.org/openstack/cinder refs/changes/32/75732/2 && git format-patch -1 --stdout FETCH_HEAD,"['etc/cinder/cinder.conf.sample', 'cinder/wsgi.py']",2,6d067069f1f413a10aeeaa46a1936716ecb44dfb,custom-max-header-size,"eventlet_opts = [ cfg.IntOpt('max_header_line', default=16384, help=""Maximum line size of message headers to be accepted. "" ""max_header_line may need to be increased when using "" ""large tokens (typically those generated by the "" ""Keystone v3 API with big service catalogs).""), ] CONF.register_opts(eventlet_opts) # Allow operators to customize http requests max header line size. eventlet.wsgi.MAX_HEADER_LINE = CONF.max_header_line",,18,0
openstack%2Fopenstack-manuals~master~I05e5b5cbe90531fd4e829ca3e200f9542261dfa8,openstack/openstack-manuals,master,I05e5b5cbe90531fd4e829ca3e200f9542261dfa8,3PAR: Update docs to reflect backend assisted volume migrate support,MERGED,2014-03-06 04:38:32.000000000,2014-03-06 06:18:59.000000000,2014-03-06 06:18:58.000000000,"[{'_account_id': 3}, {'_account_id': 612}, {'_account_id': 6043}]","[{'number': 1, 'created': '2014-03-06 04:38:32.000000000', 'files': ['doc/config-reference/block-storage/drivers/hp-3par-driver.xml'], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/bf9d32c49e43965349140fdc50b4dfe1c861ae0b', 'message': '3PAR: Update docs to reflect backend assisted volume migrate support\n\nThis change updates the 3PAR documentation to reflect new support\nfor backend assisted volume migrate, which was added in change Ia42503d4\n\nChange-Id: I05e5b5cbe90531fd4e829ca3e200f9542261dfa8\n'}]",0,78517,bf9d32c49e43965349140fdc50b4dfe1c861ae0b,7,3,1,10362,,,0,"3PAR: Update docs to reflect backend assisted volume migrate support

This change updates the 3PAR documentation to reflect new support
for backend assisted volume migrate, which was added in change Ia42503d4

Change-Id: I05e5b5cbe90531fd4e829ca3e200f9542261dfa8
",git fetch https://review.opendev.org/openstack/openstack-manuals refs/changes/17/78517/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/config-reference/block-storage/drivers/hp-3par-driver.xml'],1,bf9d32c49e43965349140fdc50b4dfe1c861ae0b,native-3par-migrate-volume-docs, <listitem> <para>Volume migration(backend assisted).</para> </listitem>,,3,0
openstack%2Fopenstack-manuals~master~Ib6c4df9a518c8637b36ca1dff67fbbbdc2eb78e5,openstack/openstack-manuals,master,Ib6c4df9a518c8637b36ca1dff67fbbbdc2eb78e5,Change Nova configuration key 'libvirt_type' to 'virt_type',MERGED,2014-03-06 00:28:10.000000000,2014-03-06 06:18:52.000000000,2014-03-06 06:18:51.000000000,"[{'_account_id': 3}, {'_account_id': 612}, {'_account_id': 6772}, {'_account_id': 9515}]","[{'number': 1, 'created': '2014-03-06 00:28:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/f7b0a2444da63ecf179c5fcb434ba0d82fc2d5a8', 'message': ""Change Nova configuration key 'libvirt_type' to 'virt_type'\n\nThe configuration key 'libvirt_type' became 'virt_type' in nova.conf\non Icehouse.\n\nChange-Id: Ib6c4df9a518c8637b36ca1dff67fbbbdc2eb78e5\nCloses-Bug: #1287878\n""}, {'number': 2, 'created': '2014-03-06 01:03:51.000000000', 'files': ['doc/install-guide/section_nova-compute.xml'], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/f0ba613c095aff0d78e88024b17127c41743918c', 'message': ""Change Nova configuration key 'libvirt_type' to 'virt_type'\n\nThe configuration key 'libvirt_type' became 'virt_type' under the\n[libvirt] section in nova.conf on Icehouse.\n\nChange-Id: Ib6c4df9a518c8637b36ca1dff67fbbbdc2eb78e5\nCloses-Bug: #1287878\n""}]",2,78474,f0ba613c095aff0d78e88024b17127c41743918c,11,4,2,9515,,,0,"Change Nova configuration key 'libvirt_type' to 'virt_type'

The configuration key 'libvirt_type' became 'virt_type' under the
[libvirt] section in nova.conf on Icehouse.

Change-Id: Ib6c4df9a518c8637b36ca1dff67fbbbdc2eb78e5
Closes-Bug: #1287878
",git fetch https://review.opendev.org/openstack/openstack-manuals refs/changes/74/78474/2 && git format-patch -1 --stdout FETCH_HEAD,['doc/install-guide/section_nova-compute.xml'],1,f7b0a2444da63ecf179c5fcb434ba0d82fc2d5a8,bug/1287878,"virt_type = qemu</programlisting> <screen os=""rhel;centos;fedora;sles;opensuse""><prompt>#</prompt> <userinput>openstack-config --set /etc/nova/nova.conf DEFAULT virt_type qemu</userinput></screen>","libvirt_type = qemu</programlisting> <screen os=""rhel;centos;fedora;sles;opensuse""><prompt>#</prompt> <userinput>openstack-config --set /etc/nova/nova.conf DEFAULT libvirt_type qemu</userinput></screen>",2,2
openstack%2Fpuppet-keystone~stable%2Fhavana~Ib14edf152c1d208418f101ed48cdc38b18f840a2,openstack/puppet-keystone,stable/havana,Ib14edf152c1d208418f101ed48cdc38b18f840a2,Don't set keystone endpoint by default,MERGED,2014-03-05 21:27:29.000000000,2014-03-06 06:04:48.000000000,2014-03-06 06:04:48.000000000,"[{'_account_id': 3}, {'_account_id': 6754}, {'_account_id': 6967}, {'_account_id': 6994}, {'_account_id': 7156}, {'_account_id': 7822}]","[{'number': 1, 'created': '2014-03-05 21:27:29.000000000', 'files': ['spec/classes/keystone_spec.rb', 'manifests/init.pp'], 'web_link': 'https://opendev.org/openstack/puppet-keystone/commit/9802add6566646dc1e4a2812d19c2ab4724ff594', 'message': ""Don't set keystone endpoint by default\n\nIn the current version of the keystone::init class, the default\nvalues for keystone endpoint URLs are unversioned, which can lead\nto problems connecting to the endpoint.  This patch reverts to\nthe old behavior of not setting them at all by default, and includes\nsample values with versioned URL's both in the header and tests\nso that users know to use versioned URL's if they choose to\noverride the defaults.  It also updates the documentation in the\nheader accordingly and tidies it up a bit.\n\nConflicts:\n\n\tmanifests/init.pp\n\nChange-Id: Ib14edf152c1d208418f101ed48cdc38b18f840a2\nCloses-Bug: #1287520\n(cherry picked from commit Ib14edf152c1d208418f101ed48cdc38b18f840a2)\n""}]",0,78419,9802add6566646dc1e4a2812d19c2ab4724ff594,13,6,1,6754,,,0,"Don't set keystone endpoint by default

In the current version of the keystone::init class, the default
values for keystone endpoint URLs are unversioned, which can lead
to problems connecting to the endpoint.  This patch reverts to
the old behavior of not setting them at all by default, and includes
sample values with versioned URL's both in the header and tests
so that users know to use versioned URL's if they choose to
override the defaults.  It also updates the documentation in the
header accordingly and tidies it up a bit.

Conflicts:

	manifests/init.pp

Change-Id: Ib14edf152c1d208418f101ed48cdc38b18f840a2
Closes-Bug: #1287520
(cherry picked from commit Ib14edf152c1d208418f101ed48cdc38b18f840a2)
",git fetch https://review.opendev.org/openstack/puppet-keystone refs/changes/19/78419/1 && git format-patch -1 --stdout FETCH_HEAD,"['spec/classes/keystone_spec.rb', 'manifests/init.pp']",2,9802add6566646dc1e4a2812d19c2ab4724ff594,bugs/1287520,"# [*public_endpoint*] # (optional) The base public endpoint URL for keystone that are # advertised to clients (NOTE: this does NOT affect how # keystone listens for connections) (string value) # If set to false, no public_endpoint will be defined in keystone.conf. # Sample value: 'http://localhost:5000/v2.0/' # Defaults to false # # [*admin_endpoint*] # (optional) The base admin endpoint URL for keystone that are # advertised to clients (NOTE: this does NOT affect how keystone listens # for connections) (string value) # If set to false, no admin_endpoint will be defined in keystone.conf. # Sample value: 'http://localhost:35357/v2.0/' # Defaults to false # # [*enable_ssl*] # (optional) Toggle for SSL support on the keystone eventlet servers.# Defaults to false # # [*ssl_certfile*] # (optional) Path of the certfile for SSL. (string value) # Defaults to '/etc/keystone/ssl/certs/keystone.pem' # # [*ssl_keyfile*] # (optional) Path of the keyfile for SSL. (string value) # Defaults to '/etc/keystone/ssl/private/keystonekey.pem' # # [*ssl_ca_certs*] # (optional) Path of the ca cert file for SSL. (string value) # Defaults to '/etc/keystone/ssl/certs/ca.pem' # # [*ssl_ca_key*] # (optional) Path of the CA key file for SSL (string value) # Defaults to '/etc/keystone/ssl/private/cakey.pem' # # [*ssl_cert_subject*] # (optional) SSL Certificate Subject (auto generated certificate) # (string value) # Defaults to '/C=US/ST=Unset/L=Unset/O=Unset/CN=localhost' $public_endpoint = false, $admin_endpoint = false, 'DEFAULT/verbose': value => $verbose; 'DEFAULT/debug': value => $debug; } # Endpoint configuration if $public_endpoint { keystone_config { 'DEFAULT/public_endpoint': value => $public_endpoint; } } else { keystone_config { 'DEFAULT/public_endpoint': ensure => absent; } } if $admin_endpoint { keystone_config { 'DEFAULT/admin_endpoint': value => $admin_endpoint; } } else { keystone_config { 'DEFAULT/admin_endpoint': ensure => absent; }","# [public_endpoint] The base public endpoint URL for keystone that are # advertised to clients (NOTE: this does NOT affect how # keystone listens for connections) (string value) # [admin_endpoint] The base admin endpoint URL for keystone that are advertised # to clients (NOTE: this does NOT affect how keystone listens # for connections) (string value) # [ssl_enable] Toggle for SSL support on the keystone eventlet servers.# [certfile] Path of the certfile for SSL. (string value) # [keyfile] Path of the keyfile for SSL. (string value) # [ca_certs] Path of the ca cert file for SSL. (string value) # [ca_key] Path of the CA key file for SSL (string value) # [cert_subject] SSL Certificate Subject (auto generated certificate) (string value) $public_endpoint = 'http://localhost:5000', $admin_endpoint = 'http://localhost:35357', 'DEFAULT/public_endpoint': value => $public_endpoint; 'DEFAULT/admin_endpoint': value => $admin_endpoint; 'DEFAULT/verbose': value => $verbose; 'DEFAULT/debug': value => $debug;",85,26
openstack%2Fpuppet-glance~master~I846491a00ac3be3b7cd3b3442943afa492b3f927,openstack/puppet-glance,master,I846491a00ac3be3b7cd3b3442943afa492b3f927,Add known_stores option in class glance::api,ABANDONED,2013-12-10 06:05:35.000000000,2014-03-06 06:03:55.000000000,,"[{'_account_id': 3}, {'_account_id': 1607}, {'_account_id': 3153}, {'_account_id': 7156}, {'_account_id': 7822}]","[{'number': 1, 'created': '2013-12-10 06:05:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-glance/commit/b6cdb6ad6ed9adb252c1ab1f7d733cee105f06c2', 'message': ""Add known_stores option in class glance::api\n\nIn glance-api, if you use known_stores's default value and didn't use\nall of the stores listed in known_stores, then glance-api service will\nthrow an error to point out which store missing, see more description\nin related bug link.\nThis patchset adds known_stores option in glance::api, so that users\ncan configure it by their own needs.\n\nChange-Id: I846491a00ac3be3b7cd3b3442943afa492b3f927\nCloses-bug: #1259403\n""}, {'number': 2, 'created': '2013-12-17 09:44:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-glance/commit/0312d3275946fa53e9e5e486ec3672b212aed40c', 'message': ""Add known_stores option in class glance::api\n\nIn glance-api, if you use known_stores's default value and didn't use\nall of the stores listed in known_stores, then glance-api service will\nthrow an error to point out which store missing, see more description\nin related bug link.\nThis patchset adds known_stores option in glance::api, so that users\ncan configure it by their own needs.\n\nChange-Id: I846491a00ac3be3b7cd3b3442943afa492b3f927\nCloses-bug: #1259403\n""}, {'number': 3, 'created': '2013-12-18 09:06:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-glance/commit/e3682e949d209c703e48153f26fe23b0d2b7b694', 'message': ""Add known_stores option in class glance::api\n\nIn glance-api, if you use known_stores's default value and didn't use\nall of the stores listed in known_stores, then glance-api service will\nthrow an error to point out which store missing, see more description\nin related bug link.\nThis patchset adds known_stores option in glance::api, so that users\ncan configure it by their own needs.\n\nChange-Id: I846491a00ac3be3b7cd3b3442943afa492b3f927\nCloses-bug: #1259403\n""}, {'number': 4, 'created': '2013-12-20 03:12:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-glance/commit/449d63e7232275bc47fae26ef5a628ce75422349', 'message': ""Add known_stores option in class glance::api\n\nIn glance-api, if you use known_stores's default value and didn't use\nall of the stores listed in known_stores, then glance-api service will\nthrow an error to point out which store missing, see more description\nin related bug link.\nThis patchset adds known_stores option in glance::api, so that users\ncan configure it by their own needs.\n\nChange-Id: I846491a00ac3be3b7cd3b3442943afa492b3f927\nCloses-bug: #1259403\n""}, {'number': 5, 'created': '2014-02-08 08:24:35.000000000', 'files': ['manifests/api.pp', 'spec/classes/glance_api_spec.rb'], 'web_link': 'https://opendev.org/openstack/puppet-glance/commit/9607f95f46d94c161c650bca0ab77914c287b3e0', 'message': ""Add known_stores option in class glance::api\n\nIn glance-api, if you use known_stores's default value and didn't use\nall of the stores listed in known_stores, then glance-api service will\nthrow an error to point out which store missing, see more description\nin related bug link.\nThis patchset adds known_stores option in glance::api, so that users\ncan configure it by their own needs.\n\nChange-Id: I846491a00ac3be3b7cd3b3442943afa492b3f927\nCloses-bug: #1259403\n""}]",0,61018,9607f95f46d94c161c650bca0ab77914c287b3e0,41,5,5,1607,,,0,"Add known_stores option in class glance::api

In glance-api, if you use known_stores's default value and didn't use
all of the stores listed in known_stores, then glance-api service will
throw an error to point out which store missing, see more description
in related bug link.
This patchset adds known_stores option in glance::api, so that users
can configure it by their own needs.

Change-Id: I846491a00ac3be3b7cd3b3442943afa492b3f927
Closes-bug: #1259403
",git fetch https://review.opendev.org/openstack/puppet-glance refs/changes/18/61018/1 && git format-patch -1 --stdout FETCH_HEAD,"['manifests/api.pp', 'spec/classes/glance_api_spec.rb']",2,b6cdb6ad6ed9adb252c1ab1f7d733cee105f06c2,bug/1259403," :sql_connection => 'sqlite:///var/lib/glance/glance.sqlite', :known_stores => ['filesystem','http','rbd','s3','swift','sheepdog','cinder'] :sql_connection => 'mysql:///var:lib@glance/glance', describe 'with known_stores by default' do let :params do default_params end it { should contain_glance_api_config('DEFAULT/known_stores').with_value(""glance.store.filesystem.Store,\nglance.store.http.Store,\nglance.store.rbd.Store,\nglance.store.s3.Store,\nglance.store.swift.Store,\nglance.store.sheepdog.Store,\nglance.store.cinder.Store"") } end describe 'with known_stores override' do let :params do default_params.merge({ :known_stores => ['filesystem','http'], }) end it { should contain_glance_api_config('DEFAULT/known_stores').with_value(""glance.store.filesystem.Store,\nglance.store.http.Store"") } end ", :sql_connection => 'sqlite:///var/lib/glance/glance.sqlite' :sql_connection => 'mysql:///var:lib@glance/glance',34,2
openstack%2Fdevstack~master~Ieda7c63c16751551b362dcf24e116d1cb8be489f,openstack/devstack,master,Ieda7c63c16751551b362dcf24e116d1cb8be489f,Cinder driver plugin for IBM Storwize/SVC,ABANDONED,2014-02-11 18:06:47.000000000,2014-03-06 06:03:54.000000000,,"[{'_account_id': 3}, {'_account_id': 2750}, {'_account_id': 4355}]","[{'number': 1, 'created': '2014-02-11 18:06:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack/commit/dd214a7715bc70d8cc621e9acfdcdd428ca8c637', 'message': 'Cinder driver plugin for IBM Storwize/SVC\n\nAdd cinder plugin file to allow for easily configuring IBM Storwize/SVC\nwith devstack.\n\nChange-Id: Ieda7c63c16751551b362dcf24e116d1cb8be489f\n'}, {'number': 2, 'created': '2014-02-11 19:18:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack/commit/6b1e02aa2ac3a5b07dbe6e3c84621ec6db16b314', 'message': 'Cinder driver plugin for IBM Storwize/SVC\n\nAdd cinder plugin file to allow for easily configuring IBM Storwize/SVC\nwith devstack.\n\nChange-Id: Ieda7c63c16751551b362dcf24e116d1cb8be489f\n'}, {'number': 3, 'created': '2014-02-12 06:24:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack/commit/3c19aa5dc83ca39afbfed77b60b8d5e4cbad3423', 'message': 'Cinder driver plugin for IBM Storwize/SVC\n\nAdd cinder plugin file to allow for easily configuring IBM Storwize/SVC\nwith devstack.\n\nChange-Id: Ieda7c63c16751551b362dcf24e116d1cb8be489f\n'}, {'number': 4, 'created': '2014-02-16 08:02:47.000000000', 'files': ['lib/cinder_plugins/ibm-storwize_svc'], 'web_link': 'https://opendev.org/openstack/devstack/commit/b61b5ab3ec14c50ec199a206361be676138fc547', 'message': 'Cinder driver plugin for IBM Storwize/SVC\n\nAdd cinder plugin file to allow for easily configuring IBM Storwize/SVC\nwith devstack.\n\nChange-Id: Ieda7c63c16751551b362dcf24e116d1cb8be489f\n'}]",0,72720,b61b5ab3ec14c50ec199a206361be676138fc547,24,3,4,4355,,,0,"Cinder driver plugin for IBM Storwize/SVC

Add cinder plugin file to allow for easily configuring IBM Storwize/SVC
with devstack.

Change-Id: Ieda7c63c16751551b362dcf24e116d1cb8be489f
",git fetch https://review.opendev.org/openstack/devstack refs/changes/20/72720/4 && git format-patch -1 --stdout FETCH_HEAD,['lib/cinder_plugins/ibm-storwize_svc'],1,dd214a7715bc70d8cc621e9acfdcdd428ca8c637,lib-ibm-storwize_svc,"# lib/cinder_plugins/ibm-storwize_svc # Configure the IBM Storwize/SVC driver # Enable with: # # CINDER_DRIVER=ibm-storwize_svc # Dependencies: # # - ``functions`` file # - ``cinder`` configurations # configure_cinder_driver - make configuration changes, including those to other services # Save trace setting MY_XTRACE=$(set +o | grep xtrace) set +o xtrace # Defaults # -------- # Set up default directories # Entry Points # ------------ # configure_cinder_driver - Set config files, create data dirs, etc function configure_cinder_driver() { # To use IBM Storwize/SVC, set the following in localrc: # CINDER_DRIVER=storwize # And any variables from those below (any variable not specified will not # be added to the conf file, and its default value will be used): for var in SAN_IP SAN_LOGIN SAN_PASSWORD STORWIZE_SVC_VOLPOOL_NAME \ STORWIZE_SVC_VOL_RSIZE STORWIZE_SVC_VOL_WARNING \ STORWIZE_SVC_VOL_AUTOEXPAND STORWIZE_SVC_VOL_GRAINSIZE \ STORWIZE_SVC_VOL_COMPRESSION STORWIZE_SVC_VOL_EASYTIER \ STORWIZE_SVC_VOL_IOGRP STORWIZE_SVC_FLASHCOPY_TIMEOUT \ STORWIZE_SVC_CONNECTION_PROTOCOL \ STORWIZE_SVC_ISCSI_CHAP_ENABLED STORWIZE_SVC_MULTIPATH_ENABLED \ STORWIZE_SVC_MULTIHOSTMAP_ENABLED do value=$(echo $(eval echo \$${var})) opt=`echo ${var,,}` if [[ -n ""$value"" ]]; then iniset $CINDER_CONF DEFAULT $opt ""$value"" fi done } # Restore xtrace $MY_XTRACE # Local variables: # mode: shell-script # End: ",,57,0
openstack-attic%2Fidentity-api~master~I7250e42d1c976f5abfee63cf30336eea73ddb0e4,openstack-attic/identity-api,master,I7250e42d1c976f5abfee63cf30336eea73ddb0e4,add docs for federated tokens,ABANDONED,2014-02-10 17:49:57.000000000,2014-03-06 06:03:54.000000000,,"[{'_account_id': 3}, {'_account_id': 6482}, {'_account_id': 6486}, {'_account_id': 9162}]","[{'number': 1, 'created': '2014-02-10 17:49:57.000000000', 'files': ['openstack-identity-api/v3/src/markdown/identity-api-v3-os-federation-ext.md'], 'web_link': 'https://opendev.org/openstack-attic/identity-api/commit/93c40c76d1784fb187cdbc42dfdb1220a746a3d5', 'message': 'add docs for federated tokens\n\nChange-Id: I7250e42d1c976f5abfee63cf30336eea73ddb0e4\nImplements: bp saml-id\n'}]",3,72431,93c40c76d1784fb187cdbc42dfdb1220a746a3d5,16,4,1,4,,,0,"add docs for federated tokens

Change-Id: I7250e42d1c976f5abfee63cf30336eea73ddb0e4
Implements: bp saml-id
",git fetch https://review.opendev.org/openstack-attic/identity-api refs/changes/31/72431/1 && git format-patch -1 --stdout FETCH_HEAD,['openstack-identity-api/v3/src/markdown/identity-api-v3-os-federation-ext.md'],1,93c40c76d1784fb187cdbc42dfdb1220a746a3d5,bp/saml-id,"Token API --------- ### Token issuance: `POST /OS-FEDERATION/identity_providers/{idp_id}/protocols/{protocol_id}` When a federated authentication request reaches an endpoint identifying both the remote identity provider and the protocol in use (thus identifying the specific mapping to apply to the federated attributes), a standard token is issued identifying the ephemeral `user` and the available authorization attributes (using `groups`). In addition, tokens produced as a result of `OS-FEDERATION` do not have the conventional `self` link on the `user` object, as the identity service itself is not identity provider. Instead, the identity provider of the ephemeral `user` is indicated by a link to the `protocol` employed by the `identity_provider`. - `OS-FEDERATION:groups` (list of objects) - `id` (string) Identifies a `group` by `id` to which the ephemeral `user` is a member. - `links` - `OS-FEDERATION:protocol` (url) Identifies the `identity_provider` and `protocol` used to produce the ephemeral `user`. Example `user` object in a ""federated"" token: { ""token"": { ""user"": { ""OS-FEDERATION:groups"": [ { ""id"": ""b31044"" } ], ""links"": { ""OS-FEDERATION:protocol"": ""http://localhost:35357/v3/OS-FEDERATION/identity_providers/CERN/protocols/saml2"" } } } } ",,47,0
openstack%2Frally~master~I4369604099bcadcbc33938f567ce53c30307369b,openstack/rally,master,I4369604099bcadcbc33938f567ce53c30307369b,Removed unnecessary security group API call from _prepare_for_instance_ssh,ABANDONED,2014-02-26 00:45:12.000000000,2014-03-06 06:03:51.000000000,,"[{'_account_id': 3}, {'_account_id': 7217}]","[{'number': 1, 'created': '2014-02-26 00:45:12.000000000', 'files': ['rally/benchmark/utils.py'], 'web_link': 'https://opendev.org/openstack/rally/commit/35b8fc5805215be9c0fe5cbd316ed4ed202c1212', 'message': 'Removed unnecessary security group API call from _prepare_for_instance_ssh\n\nThe current code does a double lookup for the security group ""rally_open"",\nonce on L129-130, and once on L134. There is no need for the second lookup\non L134, as the creation of the new security group on L131 also returns the\nsecurity group. We can thus just replace L129-130 with L134.\nRemoving this API call results in a measurable speedup in case of many\nusers.\n\nChange-Id: I4369604099bcadcbc33938f567ce53c30307369b\nCloses-bug: #1284902\n'}]",1,76402,35b8fc5805215be9c0fe5cbd316ed4ed202c1212,5,2,1,8861,,,0,"Removed unnecessary security group API call from _prepare_for_instance_ssh

The current code does a double lookup for the security group ""rally_open"",
once on L129-130, and once on L134. There is no need for the second lookup
on L134, as the creation of the new security group on L131 also returns the
security group. We can thus just replace L129-130 with L134.
Removing this API call results in a measurable speedup in case of many
users.

Change-Id: I4369604099bcadcbc33938f567ce53c30307369b
Closes-bug: #1284902
",git fetch https://review.opendev.org/openstack/rally refs/changes/02/76402/1 && git format-patch -1 --stdout FETCH_HEAD,['rally/benchmark/utils.py'],1,35b8fc5805215be9c0fe5cbd316ed4ed202c1212,bug/1284902, rally_open = nova_client.security_groups.find(name='rally_open') if not rally_open:, if 'rally_open' not in [sg.name for sg in nova_client.security_groups.list()]: rally_open = nova_client.security_groups.find(name='rally_open') ,2,4
openstack%2Fswift~master~If0c8d8d1037d595fad87122279b5ad0abf75331b,openstack/swift,master,If0c8d8d1037d595fad87122279b5ad0abf75331b,Add list-containers access level to account ACLs in tempauth.,ABANDONED,2014-01-09 02:14:35.000000000,2014-03-06 06:03:50.000000000,,"[{'_account_id': 3}, {'_account_id': 2696}, {'_account_id': 6968}, {'_account_id': 7847}, {'_account_id': 8262}]","[{'number': 1, 'created': '2014-01-09 02:14:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/230b218c7e84d3d5211acb9d64aa83f1703dd103', 'message': 'Add list-containers access level to account ACLs in tempauth.\n\nSupplementing the existing access levels ""admin"", ""read-write"", and\n""read-only"", the new ""list-containers"" access level allows GET and HEAD\noperations on the account, but no operations on containers or objects.  This\nallows users with this access to get a list of the containers in an account.\nFurther access within an individual container may be granted via container\nACLs, if desired.\n\nDoc-Impact: Updated overview-auth.rst with the new access level.\n\nChange-Id: If0c8d8d1037d595fad87122279b5ad0abf75331b\n'}, {'number': 2, 'created': '2014-01-17 20:24:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/894a09a625396e67f7c74d0b5df554990aa47829', 'message': 'Add list-containers access level to account ACLs in tempauth.\n\nSupplementing the existing access levels ""admin"", ""read-write"", and\n""read-only"", the new ""list-containers"" access level allows GET and HEAD\noperations on the account, but no operations on containers or objects.  This\nallows users with this access to get a list of the containers in an account.\nFurther access within an individual container may be granted via container\nACLs, if desired.\n\nAlso updated TempAuth to reject syntactically valid ACLs with unknown keys.\nAll auth systems should update env[\'account_acl_allowed_keys\'] and append\nnames of keys they recognize, in __call__().  Then in authorize(), all auth\nsystems can verify that all keys in the ACL are recognized by at least one\nof the auth systems in the pipeline.\n\nDoc-Impact: Updated overview-auth.rst with the new access level.\n\nChange-Id: If0c8d8d1037d595fad87122279b5ad0abf75331b\n'}, {'number': 3, 'created': '2014-02-03 23:25:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/081a16557e49813ef3089113fa3636afca368e2e', 'message': 'Add list-containers access level to account ACLs in tempauth.\n\nSupplementing the existing access levels ""admin"", ""read-write"", and\n""read-only"", the new ""list-containers"" access level allows GET and HEAD\noperations on the account, but no operations on containers or objects.  This\nallows users with this access to get a list of the containers in an account.\nFurther access within an individual container may be granted via container\nACLs, if desired.\n\nDoc-Impact: Updated overview-auth.rst with the new access level.\n\nChange-Id: If0c8d8d1037d595fad87122279b5ad0abf75331b\n'}, {'number': 4, 'created': '2014-02-07 18:19:10.000000000', 'files': ['test/unit/common/middleware/test_tempauth.py', 'swift/common/middleware/tempauth.py', 'test/unit/common/middleware/test_acl.py', 'swift/common/middleware/acl.py', 'doc/source/overview_auth.rst'], 'web_link': 'https://opendev.org/openstack/swift/commit/5ce7362afffb3d741ae806e2f3012baaf1d24fe2', 'message': 'Add list-containers access level to account ACLs in tempauth.\n\nSupplementing the existing access levels ""admin"", ""read-write"", and\n""read-only"", the new ""list-containers"" access level allows GET and HEAD\noperations on the account, but no operations on containers or objects.  This\nallows users with this access to get a list of the containers in an account.\nFurther access within an individual container may be granted via container\nACLs, if desired.\n\nDoc-Impact: Updated overview-auth.rst with the new access level.\n\nChange-Id: If0c8d8d1037d595fad87122279b5ad0abf75331b\n'}]",1,65596,5ce7362afffb3d741ae806e2f3012baaf1d24fe2,22,5,4,8262,,,0,"Add list-containers access level to account ACLs in tempauth.

Supplementing the existing access levels ""admin"", ""read-write"", and
""read-only"", the new ""list-containers"" access level allows GET and HEAD
operations on the account, but no operations on containers or objects.  This
allows users with this access to get a list of the containers in an account.
Further access within an individual container may be granted via container
ACLs, if desired.

Doc-Impact: Updated overview-auth.rst with the new access level.

Change-Id: If0c8d8d1037d595fad87122279b5ad0abf75331b
",git fetch https://review.opendev.org/openstack/swift refs/changes/96/65596/2 && git format-patch -1 --stdout FETCH_HEAD,"['test/unit/common/middleware/test_tempauth.py', 'swift/common/middleware/tempauth.py', 'test/unit/common/middleware/test_acl.py', 'swift/common/middleware/acl.py', 'doc/source/overview_auth.rst']",5,230b218c7e84d3d5211acb9d64aa83f1703dd103,list-containers,"named ""admin"", ""read-write"", ""read-only"", and ""list-containers"". (Note the case sensitivity.) An example value for the ``X-Account-Access-Control`` header looks like this:--------------- ------------------------------------------------------------- Access Level Description --------------- ------------------------------------------------------------- list-containers These identities can perform a GET or HEAD on the account itself, in order to get a list of containers. These responses contain all the usual (unprivileged) account metadata, as well as the list of containers. No permissions are granted on any containers or objects. (To grant certain permissions on certain containers, it may be useful to combine the use of container ACLs.) read-only These identities can read *everything* (except privileged headers) in the account. Specifically, a user with read-only account access can get a list of containers in the account, list the contents of any container, retrieve any object, and see the (non-privileged) headers of the account, any container, or any object. read-write These identities can read or write (or create) any container. A user with read-write account access can create new containers, set any unprivileged container headers, overwrite objects, delete containers, etc. A read-write user can NOT set account headers (or perform any PUT/POST/DELETE requests on the account). admin These identities have ""swift_owner"" privileges. A user with admin account access can do anything the account owner can, including setting account headers and any privileged headers -- and thus granting read-only, read-write, or admin access to other users. ------------ -------------------------------------------------------------","named ""admin"", ""read-write"", and ""read-only"". (Note the case sensitivity.) An example value for the ``X-Account-Access-Control`` header looks like this:------------ ------------------------------------------------------------- Access Level Description ------------ ------------------------------------------------------------- read-only These identities can read *everything* (except privileged headers) in the account. Specifically, a user with read-only account access can get a list of containers in the account, list the contents of any container, retrieve any object, and see the (non-privileged) headers of the account, any container, or any object. read-write These identities can read or write (or create) any container. A user with read-write account access can create new containers, set any unprivileged container headers, overwrite objects, delete containers, etc. A read-write user can NOT set account headers (or perform any PUT/POST/DELETE requests on the account). admin These identities have ""swift_owner"" privileges. A user with admin account access can do anything the account owner can, including setting account headers and any privileged headers -- and thus granting read-only, read-write, or admin access to other users. ------------ -------------------------------------------------------------",83,27
openstack%2Ftempest~master~I2d6caea43ba0b05efb1cb8b7797e538926d89d6d,openstack/tempest,master,I2d6caea43ba0b05efb1cb8b7797e538926d89d6d,Add the test to create volume with az,ABANDONED,2014-01-13 10:21:55.000000000,2014-03-06 06:03:46.000000000,,"[{'_account_id': 3}, {'_account_id': 5803}, {'_account_id': 6983}, {'_account_id': 9008}]","[{'number': 1, 'created': '2014-01-13 10:21:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/32d821d82463136fc2967beaaec6f017316d0b46', 'message': 'Add the test to create volume with az\n\nadd the test to create volume with default\navailability zone.\n\nChange-Id: I2d6caea43ba0b05efb1cb8b7797e538926d89d6d\n'}, {'number': 2, 'created': '2014-01-14 02:15:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/a459e3183491635998aa89977408f04d53cc097f', 'message': 'Add the test to create volume with az\n\nadd the test to create volume with default\navailability zone.\n\nChange-Id: I2d6caea43ba0b05efb1cb8b7797e538926d89d6d\n'}, {'number': 3, 'created': '2014-01-14 02:18:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/b2ea9c5351f71d8e604332a1af7a2f6892c02240', 'message': 'Add the test to create volume with az\n\nadd the test to create volume with default\navailability zone.\n\nChange-Id: I2d6caea43ba0b05efb1cb8b7797e538926d89d6d\n'}, {'number': 4, 'created': '2014-01-14 04:37:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/817804474d84be13ec85523fc95fa59b4cc6e585', 'message': 'Add the test to create volume with az\n\nadd the test to create volume with default\navailability zone.\n\nChange-Id: I2d6caea43ba0b05efb1cb8b7797e538926d89d6d\n'}, {'number': 5, 'created': '2014-01-16 08:53:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/cabd432eb8a24029bdff2bf0a8d4d706a75075d5', 'message': 'Add the test to create volume with az\n\nadd the test to create volume with default\navailability zone.\n\nChange-Id: I2d6caea43ba0b05efb1cb8b7797e538926d89d6d\n'}, {'number': 6, 'created': '2014-02-26 09:42:53.000000000', 'files': ['tempest/services/compute/xml/volumes_extensions_client.py', 'tempest/api/compute/volumes/test_volumes_get.py', 'etc/tempest.conf.sample', 'tempest/services/compute/json/volumes_extensions_client.py', 'tempest/config.py'], 'web_link': 'https://opendev.org/openstack/tempest/commit/8600d597fc790bf27ca7d3f0e795ed4026e7868a', 'message': 'Add the test to create volume with az\n\nadd the test to create volume with default\navailability zone.\n\nChange-Id: I2d6caea43ba0b05efb1cb8b7797e538926d89d6d\n'}]",1,66299,8600d597fc790bf27ca7d3f0e795ed4026e7868a,26,4,6,6983,,,0,"Add the test to create volume with az

add the test to create volume with default
availability zone.

Change-Id: I2d6caea43ba0b05efb1cb8b7797e538926d89d6d
",git fetch https://review.opendev.org/openstack/tempest refs/changes/99/66299/4 && git format-patch -1 --stdout FETCH_HEAD,['tempest/api/compute/volumes/test_volumes_get.py'],1,32d821d82463136fc2967beaaec6f017316d0b46,create_volume_with_az," _default_az = 'nova' def test_volume_create_with_az(self): # CREATE, DELETE v_name = data_utils.rand_name('Volume-') # Create volume resp, volume = self.client.create_volume(size=1, display_name=v_name, availability_zone=_default_az) self.addCleanup(self._delete_volume, volume) self.assertEqual(200, resp.status) self.assertIn('availability_zone', volume) self.assertEqual(_default_az, volume['availability_zone'], 'The created volume availability_zone is not equal ' 'to the requested availability_zone') @attr(type='gate')",,17,0
openstack%2Fceilometer~master~I90c5aafd46297009f318e059213a13432a0bb56b,openstack/ceilometer,master,I90c5aafd46297009f318e059213a13432a0bb56b,* OSLO db.session fix,ABANDONED,2014-02-12 21:04:25.000000000,2014-03-06 06:03:45.000000000,,"[{'_account_id': 3}, {'_account_id': 1669}, {'_account_id': 2813}, {'_account_id': 7763}]","[{'number': 1, 'created': '2014-02-12 21:04:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/bb25c4d42f2d2c9f00ea089f69970d9bd42dc867', 'message': '* OSLO db.session fix\n\nThis is a temporary workaround needed until similar fix from incubator.\n\nRelated to blueprint sql-unit-tests-on-real-backend\n\nChange-Id: I90c5aafd46297009f318e059213a13432a0bb56b\n'}, {'number': 2, 'created': '2014-02-12 23:42:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/3b5b03cd9f292cd3eb2b83f81a271622ddcf3f1d', 'message': '* OSLO db.session fix\n\nThis is a temporary workaround needed until similar fix from incubator.\n\nRelated to blueprint sql-unit-tests-on-real-backend\n\nChange-Id: I90c5aafd46297009f318e059213a13432a0bb56b\n'}, {'number': 3, 'created': '2014-02-13 14:27:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/ad54b07e0b3283c2916a0825e2e69089d77125c8', 'message': '* OSLO db.session fix\n\nThis is a temporary workaround needed until similar fix from incubator.\n\nRelated to blueprint sql-unit-tests-on-real-backend\n\nChange-Id: I90c5aafd46297009f318e059213a13432a0bb56b\n'}, {'number': 4, 'created': '2014-02-25 23:31:33.000000000', 'files': ['ceilometer/openstack/common/db/sqlalchemy/session.py'], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/4317d8c8287a7c8e75119cfbe799e60ec9166162', 'message': '* OSLO db.session fix\n\nThis is a temporary workaround needed until similar fix from incubator.\n\nRelated to blueprint sql-unit-tests-on-real-backend\n\nChange-Id: I90c5aafd46297009f318e059213a13432a0bb56b\n'}]",0,73063,4317d8c8287a7c8e75119cfbe799e60ec9166162,19,4,4,7763,,,0,"* OSLO db.session fix

This is a temporary workaround needed until similar fix from incubator.

Related to blueprint sql-unit-tests-on-real-backend

Change-Id: I90c5aafd46297009f318e059213a13432a0bb56b
",git fetch https://review.opendev.org/openstack/ceilometer refs/changes/63/73063/4 && git format-patch -1 --stdout FETCH_HEAD,['ceilometer/openstack/common/db/sqlalchemy/session.py'],1,bb25c4d42f2d2c9f00ea089f69970d9bd42dc867,bp/sql-unit-tests-on-real-backend," session = args[0] # Save session for future use _raise_if_deadlock_error(e, session.get_bind().name) _raise_if_duplicate_entry_error(e, session.get_bind().name)"," _raise_if_deadlock_error(e, get_engine().name) _raise_if_duplicate_entry_error(e, get_engine().name)",3,2
openstack%2Fnova~master~I47e2d0a40c565ba4cd1dbc172448800c72bf6bb9,openstack/nova,master,I47e2d0a40c565ba4cd1dbc172448800c72bf6bb9,Add PowerManager for VMware ESXi,ABANDONED,2013-11-28 08:12:17.000000000,2014-03-06 06:03:44.000000000,,"[{'_account_id': 3}, {'_account_id': 1653}, {'_account_id': 1779}, {'_account_id': 1849}, {'_account_id': 2889}, {'_account_id': 3068}, {'_account_id': 4190}, {'_account_id': 5805}, {'_account_id': 7575}, {'_account_id': 7948}, {'_account_id': 9046}, {'_account_id': 9578}]","[{'number': 1, 'created': '2013-11-28 08:12:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/dad3a692dc8698c430f647335e7e2eb7c3d09e0a', 'message': 'Add PowerManager for VMware ESXi\n\nVMwareSSHPowerManager is to use VMs on ESXi as baremetal nodes.\nIt controls the VMs by running vim-cmd on the ESXi via SSH. So\nSSH service on the ESXi have to be enabled.\n\nNote that pm_address holds ESXi\'s address and VM\'s name. They\nare separated by a comma (e.g. ""192.168.1.10,baremetal-vm"").\npm_user and pm_password specifies a user (typically root) on\nthe ESXi.\n\nThis power manager is only for test and development.\n\nChange-Id: I47e2d0a40c565ba4cd1dbc172448800c72bf6bb9\n'}, {'number': 2, 'created': '2013-11-29 04:23:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/e08a2f03146de2e627cf1578636cc7ce8ce10c7e', 'message': 'Add PowerManager for VMware ESXi\n\nVMwareSSHPowerManager is to use VMs on ESXi as baremetal nodes.\nIt controls the VMs by running vim-cmd on the ESXi via SSH. So\nSSH service on the ESXi has to be enabled.\n\nNote that pm_address holds ESXi\'s address and VM\'s name. They\nare separated by a comma (e.g. ""192.168.1.10,baremetal-vm"").\npm_user and pm_password specifies a user (typically root) on\nthe ESXi.\n\nThis power manager is only for test and development.\n\nChange-Id: I47e2d0a40c565ba4cd1dbc172448800c72bf6bb9\n'}, {'number': 3, 'created': '2013-12-03 11:15:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/8998c8c759ca2d7843ca3b23d9ed314c5e2e5d62', 'message': 'Add PowerManager for VMware ESXi\n\nAdd a new virtual_power_type ""vmware"", which controls VMware\nESXi using vim-cmd.\n\nNote that SSH service on the ESXi has to be enabled.\n\nChange-Id: I47e2d0a40c565ba4cd1dbc172448800c72bf6bb9\n'}, {'number': 4, 'created': '2013-12-03 12:29:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/7af0df3ba89c88a87a7d08509e749073bbc6d682', 'message': 'Add PowerManager for VMware ESXi\n\nAdd a new virtual_power_type ""vmware"", which controls VMware\nESXi using vim-cmd.\n\nNote that SSH service on the ESXi has to be enabled.\n\nChange-Id: I47e2d0a40c565ba4cd1dbc172448800c72bf6bb9\n'}, {'number': 5, 'created': '2013-12-04 13:09:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/9def0feb2f8c61ae8980480e0cc8dc372448d141', 'message': 'Add PowerManager for VMware ESXi\n\nAdd a new virtual_power_type ""vmware"", which controls VMware\nESXi using vim-cmd.\n\nNote that SSH service on the ESXi has to be enabled.\n\nChange-Id: I47e2d0a40c565ba4cd1dbc172448800c72bf6bb9\n'}, {'number': 6, 'created': '2013-12-16 09:02:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/a5e65c668f71068ffd2e27a2459466b6d8f33ed0', 'message': 'Add PowerManager for VMware ESXi\n\nAdd a new virtual_power_type ""vmware"", which controls VMware\nESXi using vim-cmd.\n\nNote that SSH service on the ESXi has to be enabled.\n\nChange-Id: I47e2d0a40c565ba4cd1dbc172448800c72bf6bb9\n'}, {'number': 7, 'created': '2014-01-06 07:47:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/94973184ca4dd0c78f0b05b1e23a084d55d1ab59', 'message': 'Add PowerManager for VMware ESXi\n\nAdd a new virtual_power_type ""vmware"", which controls VMware\nESXi using vim-cmd.\n\nNote that SSH service on the ESXi has to be enabled.\n\nChange-Id: I47e2d0a40c565ba4cd1dbc172448800c72bf6bb9\n'}, {'number': 8, 'created': '2014-01-10 12:17:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/0d923d319bf2aa4a4c7e787230d1449ad32114d5', 'message': 'Add PowerManager for VMware ESXi\n\nAdd a new virtual_power_type ""vmware"", which controls VMware\nESXi using vim-cmd.\n\nNote that SSH service on the ESXi has to be enabled.\n\nChange-Id: I47e2d0a40c565ba4cd1dbc172448800c72bf6bb9\n'}, {'number': 9, 'created': '2014-02-12 06:41:50.000000000', 'files': ['etc/nova/nova.conf.sample', 'nova/virt/baremetal/virtual_power_driver_settings.py', 'nova/virt/baremetal/virtual_power_driver.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/0b2ec637eb5131775c30edf212340fff8ea1b80e', 'message': 'Add PowerManager for VMware ESXi\n\nAdd a new virtual_power_type ""vmware"", which controls VMware\nESXi using vim-cmd.\n\nNote that SSH service on the ESXi has to be enabled.\n\nChange-Id: I47e2d0a40c565ba4cd1dbc172448800c72bf6bb9\n'}]",18,58940,0b2ec637eb5131775c30edf212340fff8ea1b80e,58,12,9,3068,,,0,"Add PowerManager for VMware ESXi

Add a new virtual_power_type ""vmware"", which controls VMware
ESXi using vim-cmd.

Note that SSH service on the ESXi has to be enabled.

Change-Id: I47e2d0a40c565ba4cd1dbc172448800c72bf6bb9
",git fetch https://review.opendev.org/openstack/nova refs/changes/40/58940/9 && git format-patch -1 --stdout FETCH_HEAD,"['nova/tests/virt/baremetal/test_vmware_ssh.py', 'nova/virt/baremetal/vmware_ssh.py']",2,dad3a692dc8698c430f647335e7e2eb7c3d09e0a,vmware_pm,"# Copyright 2013 VirtualTech Japan Inc. # All Rights Reserved. # # Licensed under the Apache License, Version 2.0 (the ""License""); you may # not use this file except in compliance with the License. You may obtain # a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT # WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the # License for the specific language governing permissions and limitations # under the License. from nova import exception from nova.openstack.common.gettextutils import _ from nova.openstack.common import log as logging from nova.openstack.common import processutils from nova.virt.baremetal import baremetal_states from nova.virt.baremetal import base from nova.virt.baremetal import common as conn LOG = logging.getLogger(__name__) class VMwareSSHPowerManager(base.PowerManager): def __init__(self, **kwargs): node = kwargs.pop('node', {}) pm_address, vm_name = node['pm_address'].split(',', 2) self._ssh_host = pm_address self._ssh_user = node.get('pm_user') self._ssh_pass = node.get('pm_password') self._vm_name = vm_name self._vm_id = None def _run_ssh(self, cmd): stdout = '' data = conn.Connection(self._ssh_host, self._ssh_user, self._ssh_pass) ssh = conn.ssh_connect(data) try: stdout, _stderr = processutils.ssh_execute(ssh, cmd) except processutils.ProcessExecutionError: LOG.exception(_(""Error running command: %s""), cmd) finally: ssh.close() return stdout def _run_command(self, cmd, replace_vm_id=True): if replace_vm_id: cmd = cmd.replace('{_VmId_}', self._get_vm_id()) stdout = self._run_ssh(cmd) return stdout.strip().splitlines() def _get_vm_id(self): LOG.debug(_(""Looking up ID for name %s.""), self._vm_name) if not self._vm_id: cmd = 'vim-cmd vmsvc/getallvms' lines = self._run_command(cmd, replace_vm_id=False) for line in lines: if line.startswith('Vmid'): # This is a header continue # The lines are assumed to be in the format: # vm_id vm_name [datastore_name] file_path ... # Find the beginning of ""datastore_name"" # NOTE(arata): Name containing "" ["" is incorrectly parsed. # Please don't use such a name. end_of_name = line.find(' [') if end_of_name == -1: LOG.warn(_('An unexpected line from getallvms: %s'), line) continue vm_id, _sep, vm_name = line[0:end_of_name].partition(' ') vm_name = vm_name.strip() if vm_name == self._vm_name: self._vm_id = vm_id break if not self._vm_id: raise exception.NodeNotFound(node_id=self._vm_name) return self._vm_id def activate_node(self): LOG.info(_(""activate_node name %s""), self._vm_name) cmd = 'vim-cmd vmsvc/power.on ""{_VmId_}""' self._run_command(cmd) if self.is_power_on(): self.state = baremetal_states.ACTIVE else: self.state = baremetal_states.ERROR return self.state def deactivate_node(self): LOG.info(_(""deactivate_node name %s""), self._vm_name) cmd = 'vim-cmd vmsvc/power.off ""{_VmId_}""' self._run_command(cmd) if self.is_power_on(): self.state = baremetal_states.ERROR else: self.state = baremetal_states.DELETED return self.state def reboot_node(self): LOG.info(_(""reset node: %s""), self._vm_name) cmd = 'vim-cmd vmsvc/power.reboot ""{_VmId_}""' self._run_command(cmd) if self.is_power_on(): self.state = baremetal_states.ACTIVE else: self.state = baremetal_states.ERROR return self.state def is_power_on(self): LOG.debug(_(""Checking if %s is running""), self._vm_name) cmd = 'vim-cmd vmsvc/power.getstate ""{_VmId_}""' result = self._run_command(cmd) return 'Powered on' in result ",,309,0
openstack%2Ffuel-ostf~master~I3deecb629644bfd4a8aadf2610fd8e7c8600afa5,openstack/fuel-ostf,master,I3deecb629644bfd4a8aadf2610fd8e7c8600afa5,Fix for additional statuses for test processing,ABANDONED,2014-02-19 14:45:32.000000000,2014-03-06 06:03:43.000000000,,"[{'_account_id': 3}, {'_account_id': 6719}, {'_account_id': 8839}, {'_account_id': 8907}, {'_account_id': 8931}, {'_account_id': 8971}]","[{'number': 1, 'created': '2014-02-19 14:45:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-ostf/commit/4ea3bbf6f6e124ef001f95547f63beea02cc02bf', 'message': ""Fix for additional statuses for test processing\n\nNow 'skipped' test status is processing in StoragePlugin by type\ncomparison with nose.plugins.skip.SkipTest class. This should work for\nboth variants of SkipTest raising: either skipTest() method of TestCase\n (of unittest or unittest2 modules) class or by directly rising SkipTest\nexception from unittest2 module.\n\nChange-Id: I3deecb629644bfd4a8aadf2610fd8e7c8600afa5\n""}, {'number': 2, 'created': '2014-02-19 14:50:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-ostf/commit/e023380f285421ba5434c41c623ba3b3809472c2', 'message': ""Fix for additional statuses for test processing\n\nNow 'skipped' test status is processing in StoragePlugin by type\ncomparison with nose.plugins.skip.SkipTest class. This should work for\nboth variants of SkipTest raising: either skipTest() method of TestCase\n (of unittest or unittest2 modules) class or by directly rising SkipTest\nexception from unittest2 module.\n\nCloses-Bug:  #1282106\nChange-Id: I3deecb629644bfd4a8aadf2610fd8e7c8600afa5\n""}, {'number': 3, 'created': '2014-02-21 11:36:52.000000000', 'files': ['fuel_plugin/ostf_adapter/nose_plugin/nose_storage_plugin.py', 'fuel_plugin/testing/tests/__init__.py'], 'web_link': 'https://opendev.org/openstack/fuel-ostf/commit/1e01be340b2942d253da7429f5ecf41f2d906167', 'message': ""Fix for additional statuses for test processing\n\nNow 'skipped' test status is processing in StoragePlugin by type\ncomparison with nose.plugins.skip.SkipTest class. This should work for\nboth variants of SkipTest raising: either skipTest() method of TestCase\n (of unittest or unittest2 modules) class or by directly rising SkipTest\nexception from unittest2 module.\n\nCloses-Bug: #1282106\nChange-Id: I3deecb629644bfd4a8aadf2610fd8e7c8600afa5\n""}]",0,74738,1e01be340b2942d253da7429f5ecf41f2d906167,22,6,3,8931,,,0,"Fix for additional statuses for test processing

Now 'skipped' test status is processing in StoragePlugin by type
comparison with nose.plugins.skip.SkipTest class. This should work for
both variants of SkipTest raising: either skipTest() method of TestCase
 (of unittest or unittest2 modules) class or by directly rising SkipTest
exception from unittest2 module.

Closes-Bug: #1282106
Change-Id: I3deecb629644bfd4a8aadf2610fd8e7c8600afa5
",git fetch https://review.opendev.org/openstack/fuel-ostf refs/changes/38/74738/1 && git format-patch -1 --stdout FETCH_HEAD,"['fuel_plugin/ostf_adapter/nose_plugin/nose_storage_plugin.py', 'fuel_plugin/testing/tests/__init__.py']",2,4ea3bbf6f6e124ef001f95547f63beea02cc02bf,fix/proper_SkipTest_treating," stdout=serverlogs, stderr=serverlogs"," stdout=devnull, stderr=devnull",4,4
openstack%2Fnova~master~I05e7979fc31fe46910b8a53318b707f62b71b516,openstack/nova,master,I05e7979fc31fe46910b8a53318b707f62b71b516,Limit number of consoles for an instance,ABANDONED,2014-02-12 09:34:44.000000000,2014-03-06 06:03:42.000000000,,"[{'_account_id': 3}, {'_account_id': 1561}, {'_account_id': 1779}, {'_account_id': 5511}, {'_account_id': 6873}, {'_account_id': 9008}, {'_account_id': 9303}, {'_account_id': 9578}]","[{'number': 1, 'created': '2014-02-12 09:34:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/2487879633f041e44360091b35cecc2531bf5170', 'message': 'Limit number of consoles for an instance\n\nAllowing spawning multiple consoles for an instance on\nnoVNC server can lead to service interruption or disruption.\n\nMaximum number of consoles that can be open for any instance is\nconfigurable using console_max_count and enable_console_max_count\ncan be used to enable/disable the console limit feature.\nAdministartor can set enable_console_max_count to True and\nconsole_max_count in nova.conf.\n\nThis change is applicable only for noVNC console and not for\nspice console as SPICE uses multiple TCP connections per open console.\nA typical SPICE connection would have 6 connections, but it may be\neven more if other non-default features are used.\nPlease refer https://bugs.launchpad.net/nova/+bug/1227575/comments/18\n\nFormat for console_max_count and enable_console_max_count in nova.conf:\n----------------------------------------------------------------------\nconsole_max_count = <count>\nenable_console_max_count = <True/False>\n\nExample:\nconsole_max_count = 4\nenable_console_max_count = True\n\nNote\n----\n1. If enable_console_max_count is not specified then default will\nbe considered as False.\n2. Limiting the console will only works if enable_console_max_count\nis set to True.\n3. If console_max_count is not specified then default will be\nconsidered as 3.\n4. If count of open console sessions exceeds console_max_count then\n""ConsoleMaxCountExceeded"" exception will be raised.\n\nDocImpact: Adds console_max_count flag to limit number of\n           consoles for an instance (default=3).\n           Adds enable_console_max_count flag to enable\n           the limit of consoles (default=False).\nCloses-Bug: #1227575\n\nChange-Id: I05e7979fc31fe46910b8a53318b707f62b71b516\n'}, {'number': 2, 'created': '2014-02-13 07:42:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/f2701c5829db128118042c60884052689d1bc63b', 'message': 'Limit number of consoles for an instance\n\nAllowing spawning multiple consoles for an instance on\nnoVNC server can lead to service interruption or disruption.\n\nMaximum number of consoles that can be open for any instance is\nconfigurable using console_max_count and enable_console_max_count\ncan be used to enable/disable the console limit feature.\nAdministartor can set enable_console_max_count to True and\nconsole_max_count in nova.conf.\n\nThis change is applicable only for noVNC console and not for\nspice console as SPICE uses multiple TCP connections per open console.\nA typical SPICE connection would have 6 connections, but it may be\neven more if other non-default features are used.\nPlease refer https://bugs.launchpad.net/nova/+bug/1227575/comments/18\n\nFormat for console_max_count and enable_console_max_count in nova.conf:\n----------------------------------------------------------------------\nconsole_max_count = <count>\nenable_console_max_count = <True/False>\n\nExample:\nconsole_max_count = 4\nenable_console_max_count = True\n\nNote\n----\n1. If enable_console_max_count is not specified then default will\nbe considered as False.\n2. Limiting the console will only works if enable_console_max_count\nis set to True.\n3. If console_max_count is not specified then default will be\nconsidered as 3.\n4. If count of open console sessions exceeds console_max_count then\n""ConsoleMaxCountExceeded"" exception will be raised.\n\nDocImpact: Adds console_max_count flag to limit number of\n           consoles for an instance (default=3).\n           Adds enable_console_max_count flag to enable\n           the limit of consoles (default=False).\nCloses-Bug: #1227575\n\nChange-Id: I05e7979fc31fe46910b8a53318b707f62b71b516\n'}, {'number': 3, 'created': '2014-02-13 10:56:09.000000000', 'files': ['nova/exception.py', 'etc/nova/nova.conf.sample', 'nova/console/websocketproxy.py', 'nova/cmd/novncproxy.py', 'nova/tests/db/test_db_api.py', 'nova/db/api.py', 'nova/db/sqlalchemy/api.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/025dfe364388a2a58dd5b3a49f1039c393a23050', 'message': 'Limit number of consoles for an instance\n\nAllowing spawning multiple consoles for an instance on\nnoVNC server can lead to service interruption or disruption.\n\nMaximum number of consoles that can be open for any instance is\nconfigurable using console_max_count and enable_console_max_count\ncan be used to enable/disable the console limit feature.\nAdministartor can set enable_console_max_count to True and\nconsole_max_count in nova.conf.\n\nThis change is applicable only for noVNC console and not for\nspice console as SPICE uses multiple TCP connections per open console.\nA typical SPICE connection would have 6 connections, but it may be\neven more if other non-default features are used.\nPlease refer https://bugs.launchpad.net/nova/+bug/1227575/comments/18\n\nFormat for console_max_count and enable_console_max_count in nova.conf:\n----------------------------------------------------------------------\nconsole_max_count = <count>\nenable_console_max_count = <True/False>\n\nExample:\nconsole_max_count = 4\nenable_console_max_count = True\n\nNote\n----\n1. If enable_console_max_count is not specified then default will\nbe considered as False.\n2. Limiting the console will only works if enable_console_max_count\nis set to True.\n3. If console_max_count is not specified then default will be\nconsidered as 3.\n4. If count of open console sessions exceeds console_max_count then\n""ConsoleMaxCountExceeded"" exception will be raised.\n\nDocImpact: Adds console_max_count flag to limit number of\n           consoles for an instance (default=3).\n           Adds enable_console_max_count flag to enable\n           the limit of consoles (default=False).\nCloses-Bug: #1227575\n\nChange-Id: I05e7979fc31fe46910b8a53318b707f62b71b516\n'}]",1,72894,025dfe364388a2a58dd5b3a49f1039c393a23050,29,8,3,9303,,,0,"Limit number of consoles for an instance

Allowing spawning multiple consoles for an instance on
noVNC server can lead to service interruption or disruption.

Maximum number of consoles that can be open for any instance is
configurable using console_max_count and enable_console_max_count
can be used to enable/disable the console limit feature.
Administartor can set enable_console_max_count to True and
console_max_count in nova.conf.

This change is applicable only for noVNC console and not for
spice console as SPICE uses multiple TCP connections per open console.
A typical SPICE connection would have 6 connections, but it may be
even more if other non-default features are used.
Please refer https://bugs.launchpad.net/nova/+bug/1227575/comments/18

Format for console_max_count and enable_console_max_count in nova.conf:
----------------------------------------------------------------------
console_max_count = <count>
enable_console_max_count = <True/False>

Example:
console_max_count = 4
enable_console_max_count = True

Note
----
1. If enable_console_max_count is not specified then default will
be considered as False.
2. Limiting the console will only works if enable_console_max_count
is set to True.
3. If console_max_count is not specified then default will be
considered as 3.
4. If count of open console sessions exceeds console_max_count then
""ConsoleMaxCountExceeded"" exception will be raised.

DocImpact: Adds console_max_count flag to limit number of
           consoles for an instance (default=3).
           Adds enable_console_max_count flag to enable
           the limit of consoles (default=False).
Closes-Bug: #1227575

Change-Id: I05e7979fc31fe46910b8a53318b707f62b71b516
",git fetch https://review.opendev.org/openstack/nova refs/changes/94/72894/3 && git format-patch -1 --stdout FETCH_HEAD,"['nova/exception.py', 'nova/console/websocketproxy.py', 'nova/cmd/novncproxy.py', 'nova/tests/db/test_db_api.py', 'nova/db/api.py', 'nova/db/sqlalchemy/api.py']",6,2487879633f041e44360091b35cecc2531bf5170,lp/57224,"def console_pool_get_by_public_hostname(context, public_hostname): result = model_query(context, models.ConsolePool).\ filter_by(public_hostname=public_hostname).\ options(joinedload('consoles')).\ all() if not result: raise exception.ConsolePoolsNotFoundForPublicHostname( public_hostname=public_hostname) return result def console_delete_all_by_pool_id(context, pool_id): session = get_session() with session.begin(): session.query(models.Console).\ filter_by(pool_id=pool_id).\ delete() ",,287,34
openstack%2Fpython-manilaclient~master~Ifece600c8a61c3b2fd2f7a811b904e0841b68075,openstack/python-manilaclient,master,Ifece600c8a61c3b2fd2f7a811b904e0841b68075,Migrate to pbr,ABANDONED,2014-02-18 15:49:51.000000000,2014-03-06 06:03:41.000000000,,"[{'_account_id': 3}, {'_account_id': 7534}, {'_account_id': 8851}, {'_account_id': 8863}]","[{'number': 1, 'created': '2014-02-18 15:49:51.000000000', 'files': ['manilaclient/openstack/common/version.py', 'setup.py', 'openstack-common.conf', 'tools/pip-requires', 'setup.cfg', 'manilaclient/__init__.py'], 'web_link': 'https://opendev.org/openstack/python-manilaclient/commit/33e3153b61e5bf4c7c87bfc2fa7a94ffaca10954', 'message': 'Migrate to pbr\n\nMigrate to pbr.\n\nChange-Id: Ifece600c8a61c3b2fd2f7a811b904e0841b68075\nSigned-off-by: Chuck Short <chuck.short@canonical.com>\n'}]",2,74415,33e3153b61e5bf4c7c87bfc2fa7a94ffaca10954,8,4,1,24,,,0,"Migrate to pbr

Migrate to pbr.

Change-Id: Ifece600c8a61c3b2fd2f7a811b904e0841b68075
Signed-off-by: Chuck Short <chuck.short@canonical.com>
",git fetch https://review.opendev.org/openstack/python-manilaclient refs/changes/15/74415/1 && git format-patch -1 --stdout FETCH_HEAD,"['manilaclient/openstack/common/version.py', 'openstack-common.conf', 'setup.py', 'tools/pip-requires', 'setup.cfg', 'manilaclient/__init__.py']",6,33e3153b61e5bf4c7c87bfc2fa7a94ffaca10954,, import pbr.version version_info = pbr.version.VersionInfo('python-glanceclient'),from manilaclient.openstack.common import version version_info = version.VersionInfo('python-manilaclient'),39,141
openstack%2Foslo.messaging~master~I57567f39c35e47fa79dad51a58e4136963cf906c,openstack/oslo.messaging,master,I57567f39c35e47fa79dad51a58e4136963cf906c,notify: add schema validation system,ABANDONED,2014-02-04 17:20:20.000000000,2014-03-06 06:03:40.000000000,,"[{'_account_id': 3}, {'_account_id': 688}, {'_account_id': 1669}, {'_account_id': 2472}, {'_account_id': 2813}]","[{'number': 1, 'created': '2014-02-04 17:20:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.messaging/commit/90277533ff509d14b2179a1dcfd79f1ff3193806', 'message': 'notify: add schema validation system\n\nThis adds a schema validation system based on Voluptuous. It loads the\nschema based on entry points in the oslo.messaging.notify.schemas\nnamespace. Once found this schema is used to validate the data passed in\nbefore sending them.\n\nChange-Id: I57567f39c35e47fa79dad51a58e4136963cf906c\nBlueprint: notification-structured\n'}, {'number': 2, 'created': '2014-02-07 13:59:50.000000000', 'files': ['oslo/messaging/notify/schema.py', 'requirements.txt', 'oslo/messaging/notify/notifier.py', 'setup.cfg', 'tests/test_notifier.py'], 'web_link': 'https://opendev.org/openstack/oslo.messaging/commit/e41cc3c4b31c77876a02ab4812a6271aced2203c', 'message': 'notify: add schema validation system\n\nThis adds a schema validation system based on Voluptuous. It loads the\nschema based on entry points in the oslo.messaging.notify.schemas\nnamespace. Once found this schema is used to validate the data passed in\nbefore sending them.\n\nChange-Id: I57567f39c35e47fa79dad51a58e4136963cf906c\nBlueprint: notification-structured\n'}]",8,71032,e41cc3c4b31c77876a02ab4812a6271aced2203c,19,5,2,1669,,,0,"notify: add schema validation system

This adds a schema validation system based on Voluptuous. It loads the
schema based on entry points in the oslo.messaging.notify.schemas
namespace. Once found this schema is used to validate the data passed in
before sending them.

Change-Id: I57567f39c35e47fa79dad51a58e4136963cf906c
Blueprint: notification-structured
",git fetch https://review.opendev.org/openstack/oslo.messaging refs/changes/32/71032/1 && git format-patch -1 --stdout FETCH_HEAD,"['oslo/messaging/notify/schema.py', 'requirements.txt', 'oslo/messaging/notify/notifier.py', 'setup.cfg', 'tests/test_notifier.py']",5,90277533ff509d14b2179a1dcfd79f1ff3193806,bp/notification-structured," 'event_type': 'oslo.messaging.test', method(self.ctxt, 'oslo.messaging.test', self.payload) @mock.patch('oslo.messaging.openstack.common.timeutils.utcnow') def test_notifier_unknown_event_type(self, mock_utcnow): drivers = [] if self.v1: drivers.append('messaging') if self.v2: drivers.append('messagingv2') self.config(notification_driver=drivers) self.config(notification_topics=self.topics) transport = _FakeTransport(self.conf) if hasattr(self, 'ctor_pub_id'): notifier = messaging.Notifier(transport, publisher_id=self.ctor_pub_id) else: notifier = messaging.Notifier(transport) if hasattr(self, 'prep_pub_id'): notifier = notifier.prepare(publisher_id=self.prep_pub_id) method = getattr(notifier, self.priority) self.assertRaises(RuntimeError, method, self.ctxt, 'oslo.messaging.dont.exists', self.payload) serializer.serialize_entity(dict(user='bob'), {'foo': 'bar'}).AndReturn({'foo': 'sbar'}) notifier.info(dict(user='bob'), 'oslo.messaging.test', {'foo': 'bar'}) 'event_type': 'oslo.messaging.test', 'payload': {'foo': 'sbar'}, 'event_type': 'oslo.messaging.test', 'payload': {'foo': 'bar'}, logging.getLogger('oslo.messaging.notification.oslo.messaging.test').\ notifier.info({}, 'oslo.messaging.test', {'foo': 'bar'})"," 'event_type': 'test.notify', method(self.ctxt, 'test.notify', self.payload) serializer.serialize_entity(dict(user='bob'), 'bar').AndReturn('sbar') notifier.info(dict(user='bob'), 'test.notify', 'bar') 'event_type': 'test.notify', 'payload': 'sbar', 'event_type': 'test.notify', 'payload': 'bar', logging.getLogger('oslo.messaging.notification.test.notify').\ notifier.info({}, 'test.notify', 'bar')",90,10
openstack%2Fnova~master~I7a4f4b0dc8a769095784cf6802df30e119b24eaf,openstack/nova,master,I7a4f4b0dc8a769095784cf6802df30e119b24eaf,Add REST API for server group (instance group) extension for v3 api,ABANDONED,2014-02-01 14:56:02.000000000,2014-03-06 06:03:39.000000000,,"[{'_account_id': 3}, {'_account_id': 681}, {'_account_id': 782}, {'_account_id': 1653}, {'_account_id': 5292}, {'_account_id': 7494}, {'_account_id': 7641}, {'_account_id': 8514}, {'_account_id': 8888}, {'_account_id': 8890}, {'_account_id': 9008}, {'_account_id': 9578}]","[{'number': 1, 'created': '2014-02-01 14:56:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/ab58194207ad231e75183c9636dc8c3dee07cc25', 'message': 'Add REST API for instance group extension for v3 api\n\nSupport the Creation, Read, Update, Delete, and List of instance group\n\nPartially implements: blueprint instance-group-api-extension\n\nChange-Id: I7a4f4b0dc8a769095784cf6802df30e119b24eaf\n'}, {'number': 2, 'created': '2014-02-02 04:46:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/93006c59560a55cc95e7d3c990c98bd153255a7c', 'message': 'Add REST API for instance group extension for v3 api\n\nSupport the Creation, Read, Update, Delete, and List of instance group\n\nPartially implements: blueprint instance-group-api-extension\n\nChange-Id: I7a4f4b0dc8a769095784cf6802df30e119b24eaf\n'}, {'number': 3, 'created': '2014-02-03 08:42:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/07f06ca0b0317e2cb3e8802d1c7709bdefe0ce9f', 'message': 'Add REST API for instance group extension for v3 api\n\nSupport the Creation, Read, Update, Delete, and List of instance group\n\nPartially implements: blueprint instance-group-api-extension\n\nChange-Id: I7a4f4b0dc8a769095784cf6802df30e119b24eaf\n'}, {'number': 4, 'created': '2014-02-05 21:57:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/1cc736654217907e061a44db935bab18fc4b3a73', 'message': 'Add REST API for instance group extension for v3 api\n\nSupport the Creation, Read, Update, Delete, and List of instance group\n\nPartially implements: blueprint instance-group-api-extension\n\nChange-Id: I7a4f4b0dc8a769095784cf6802df30e119b24eaf\n'}, {'number': 5, 'created': '2014-02-10 22:27:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/36e20e14151e83c07489fda7c2af5e01b5007094', 'message': 'Add REST API for instance group extension for v3 api\n\nSupport the Creation, Read, Update, Delete, and List of instance group\n\nPartially implements: blueprint instance-group-api-extension\n\nChange-Id: I7a4f4b0dc8a769095784cf6802df30e119b24eaf\n'}, {'number': 6, 'created': '2014-02-11 05:15:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/d9f95fdef3656c6e59555a9b1321b2ff6d223840', 'message': 'Add REST API for instance group extension for v3 api\n\nSupport the Creation, Read, Update, Delete, and List of instance group\n\nPartially implements: blueprint instance-group-api-extension\n\nChange-Id: I7a4f4b0dc8a769095784cf6802df30e119b24eaf\n'}, {'number': 7, 'created': '2014-02-18 11:06:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/d3058478df6795810f82f24832284729c44b6435', 'message': 'Add REST API for instance group extension for v3 api\n\nSupport the Creation, Read, Update, Delete, and List of instance group\n\nPartially implements: blueprint instance-group-api-extension\n\nChange-Id: I7a4f4b0dc8a769095784cf6802df30e119b24eaf\n'}, {'number': 8, 'created': '2014-02-24 07:15:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/9836c3f5628d7b34c7296eb2a2a02cb99972da99', 'message': 'Add REST API for instance group extension for v3 api\n\nSupport the Creation, Read, Update, Delete, and List of server group.\nRenamed from ""instance group"" to ""server group"".\n\nPartially implements: blueprint instance-group-api-extension\n\nChange-Id: I7a4f4b0dc8a769095784cf6802df30e119b24eaf\n'}, {'number': 9, 'created': '2014-02-25 08:59:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/880baf9072305d7bf299d4988934c4b8b02a2869', 'message': 'Add REST API for instance group extension for v3 api\n\nSupport the Creation, Read, Update, Delete, and List of server group.\nRenamed from ""instance group"" to ""server group"".\n\nPartially implements: blueprint instance-group-api-extension\n\nChange-Id: I7a4f4b0dc8a769095784cf6802df30e119b24eaf\n'}, {'number': 10, 'created': '2014-02-25 19:27:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/0614505c1c7512957996f2c80e0d6ee92fa04255', 'message': 'Add REST API for server group (instance group) extension for v3 api\n\nSupport the Creation, Read, Update, Delete, and List of server group.\nRenamed from ""instance group"" to ""server group"".\n\nPartially implements: blueprint instance-group-api-extension\n\nChange-Id: I7a4f4b0dc8a769095784cf6802df30e119b24eaf\n'}, {'number': 11, 'created': '2014-02-26 08:48:37.000000000', 'files': ['nova/tests/integrated/v3/api_samples/os-server-groups/server-group-metadata-post-resp.json.tpl', 'doc/v3/api_samples/os-server-groups/server-group-remove-members-post-resp.json', 'doc/v3/api_samples/os-server-groups/server-group-remove-policies-post-req.json', 'doc/v3/api_samples/os-server-groups/server-groups-post-resp.json', 'nova/tests/integrated/v3/api_samples/os-server-groups/server-groups-update-resp.json.tpl', 'etc/nova/policy.json', 'doc/v3/api_samples/os-server-groups/server-group-metadata-update-resp.json', 'nova/tests/integrated/v3/api_samples/os-server-groups/server-group-remove-policies-post-resp.json.tpl', 'doc/v3/api_samples/os-server-groups/server-groups-list-resp.json', 'doc/v3/api_samples/os-server-groups/server-groups-update-req.json', 'doc/v3/api_samples/os-server-groups/server-group-add-members-post-req.json', 'nova/tests/integrated/v3/api_samples/os-server-groups/server-group-add-policies-post-resp.json.tpl', 'nova/tests/integrated/v3/api_samples/os-server-groups/server-groups-post-req.json.tpl', 'doc/v3/api_samples/os-server-groups/server-groups-get-resp.json', 'nova/tests/integrated/v3/api_samples/os-server-groups/server-group-remove-policies-post-req.json.tpl', 'nova/tests/api/openstack/compute/plugins/v3/test_server_groups.py', 'doc/v3/api_samples/os-server-groups/server-group-add-policies-post-resp.json', 'nova/tests/integrated/v3/api_samples/os-server-groups/server-groups-update-req.json.tpl', 'nova/api/openstack/compute/plugins/v3/server_groups.py', 'nova/tests/integrated/v3/api_samples/os-server-groups/server-group-remove-members-post-resp.json.tpl', 'nova/tests/integrated/v3/api_samples/os-server-groups/server-groups-list-resp.json.tpl', 'doc/v3/api_samples/os-server-groups/server-group-metadata-remove-req.json', 'nova/tests/integrated/v3/api_samples/os-server-groups/server-groups-post-resp.json.tpl', 'doc/v3/api_samples/os-server-groups/server-group-metadata-remove-resp.json', 'nova/tests/integrated/v3/api_samples/os-server-groups/server-group-metadata-remove-resp.json.tpl', 'nova/tests/integrated/v3/api_samples/os-server-groups/server-group-remove-members-post-req.json.tpl', 'nova/tests/integrated/v3/api_samples/os-server-groups/server-groups-get-resp.json.tpl', 'nova/api/openstack/compute/schemas/v3/server_groups.py', 'doc/v3/api_samples/os-server-groups/server-group-metadata-post-resp.json', 'nova/tests/integrated/v3/api_samples/os-server-groups/server-group-add-policies-post-req.json.tpl', 'doc/v3/api_samples/os-server-groups/server-group-remove-policies-post-resp.json', 'nova/tests/integrated/v3/test_server_groups.py', 'nova/tests/integrated/v3/api_samples/os-server-groups/server-group-metadata-update-resp.json.tpl', 'nova/tests/integrated/v3/api_samples/os-server-groups/server-group-metadata-post-req.json.tpl', 'nova/tests/integrated/v3/api_samples/os-server-groups/server-group-add-members-post-resp.json.tpl', 'doc/v3/api_samples/os-server-groups/server-group-remove-members-post-req.json', 'doc/v3/api_samples/os-server-groups/server-groups-update-resp.json', 'doc/v3/api_samples/os-server-groups/server-group-metadata-update-req.json', 'nova/tests/fake_policy.py', 'nova/tests/integrated/v3/api_samples/os-server-groups/server-group-metadata-update-req.json.tpl', 'doc/v3/api_samples/os-server-groups/server-group-add-members-post-resp.json', 'doc/v3/api_samples/os-server-groups/server-group-metadata-post-req.json', 'doc/v3/api_samples/os-server-groups/server-group-add-policies-post-req.json', 'nova/tests/integrated/v3/api_samples/os-server-groups/server-group-metadata-remove-req.json.tpl', 'nova/tests/integrated/v3/api_samples/os-server-groups/server-group-add-members-post-req.json.tpl', 'setup.cfg', 'doc/v3/api_samples/os-server-groups/server-groups-post-req.json'], 'web_link': 'https://opendev.org/openstack/nova/commit/20a2830410dee2ff8fae48c3e6d9a2fe02d61bf2', 'message': 'Add REST API for server group (instance group) extension for v3 api\n\nSupport the Creation, Read, Update, Delete, and List of server group.\nRenamed from ""instance group"" to ""server group"".\n\nPartially implements: blueprint instance-group-api-extension\n\nChange-Id: I7a4f4b0dc8a769095784cf6802df30e119b24eaf\n'}]",20,70533,20a2830410dee2ff8fae48c3e6d9a2fe02d61bf2,81,12,11,8890,,,0,"Add REST API for server group (instance group) extension for v3 api

Support the Creation, Read, Update, Delete, and List of server group.
Renamed from ""instance group"" to ""server group"".

Partially implements: blueprint instance-group-api-extension

Change-Id: I7a4f4b0dc8a769095784cf6802df30e119b24eaf
",git fetch https://review.opendev.org/openstack/nova refs/changes/33/70533/4 && git format-patch -1 --stdout FETCH_HEAD,"['doc/v3/api_samples/os-instance-groups/instance-group-metadata-remove-req.json', 'doc/v3/api_samples/os-instance-groups/instance-group-add-members-post-req.json', 'doc/v3/api_samples/os-instance-groups/instance-group-remove-members-post-req.json', 'nova/tests/integrated/v3/api_samples/os-instance-groups/instance-groups-post-resp.json.tpl', 'nova/tests/integrated/v3/api_samples/os-instance-groups/instance-group-metadata-update-resp.json.tpl', 'nova/tests/integrated/v3/api_samples/os-instance-groups/instance-groups-list-resp.json.tpl', 'nova/tests/integrated/v3/api_samples/os-instance-groups/instance-group-add-policies-post-req.json.tpl', 'etc/nova/policy.json', 'doc/v3/api_samples/os-instance-groups/instance-group-add-policies-post-resp.json', 'doc/v3/api_samples/os-instance-groups/instance-group-remove-members-post-resp.json', 'doc/v3/api_samples/os-instance-groups/instance-group-remove-policies-post-resp.json', 'nova/tests/api/openstack/compute/plugins/v3/test_instance_groups.py', 'nova/tests/integrated/v3/api_samples/os-instance-groups/instance-group-add-members-post-resp.json.tpl', 'doc/v3/api_samples/os-instance-groups/instance-group-remove-policies-post-req.json', 'doc/v3/api_samples/os-instance-groups/instance-groups-post-resp.json', 'nova/tests/integrated/v3/api_samples/os-instance-groups/instance-group-metadata-post-resp.json.tpl', 'doc/v3/api_samples/os-instance-groups/instance-group-metadata-remove-resp.json', 'nova/tests/integrated/v3/api_samples/os-instance-groups/instance-groups-update-req.json.tpl', 'doc/v3/api_samples/os-instance-groups/instance-group-metadata-post-resp.json', 'nova/tests/integrated/v3/api_samples/os-instance-groups/instance-group-remove-policies-post-resp.json.tpl', 'nova/tests/integrated/v3/api_samples/os-instance-groups/instance-group-add-members-post-req.json.tpl', 'nova/tests/integrated/v3/api_samples/os-instance-groups/instance-groups-update-resp.json.tpl', 'nova/tests/integrated/v3/test_instance_groups.py', 'nova/tests/integrated/v3/api_samples/os-instance-groups/instance-group-remove-policies-post-req.json.tpl', 'nova/tests/integrated/v3/api_samples/os-instance-groups/instance-group-metadata-post-req.json.tpl', 'nova/api/openstack/compute/plugins/v3/instance_groups.py', 'nova/tests/integrated/v3/api_samples/os-instance-groups/instance-group-metadata-update-req.json.tpl', 'doc/v3/api_samples/os-instance-groups/instance-group-metadata-update-resp.json', 'nova/tests/integrated/v3/api_samples/os-instance-groups/instance-group-add-policies-post-resp.json.tpl', 'doc/v3/api_samples/os-instance-groups/instance-groups-post-req.json', 'doc/v3/api_samples/os-instance-groups/instance-groups-update-req.json', 'doc/v3/api_samples/os-instance-groups/instance-groups-list-resp.json', 'doc/v3/api_samples/os-instance-groups/instance-group-add-members-post-resp.json', 'nova/tests/integrated/v3/api_samples/os-instance-groups/instance-group-remove-members-post-resp.json.tpl', 'doc/v3/api_samples/os-instance-groups/instance-group-add-policies-post-req.json', 'nova/tests/integrated/v3/api_samples/os-instance-groups/instance-groups-post-req.json.tpl', 'doc/v3/api_samples/os-instance-groups/instance-groups-get-resp.json', 'nova/tests/fake_policy.py', 'nova/tests/integrated/v3/api_samples/os-instance-groups/instance-group-metadata-remove-req.json.tpl', 'nova/tests/integrated/v3/api_samples/os-instance-groups/instance-groups-get-resp.json.tpl', 'setup.cfg', 'nova/tests/integrated/v3/api_samples/os-instance-groups/instance-group-metadata-remove-resp.json.tpl', 'nova/tests/integrated/v3/api_samples/os-instance-groups/instance-group-remove-members-post-req.json.tpl', 'nova/tests/integrated/v3/api_samples/os-instance-groups/instance-groups-add-policies-post-req.json.tpl', 'doc/v3/api_samples/os-instance-groups/instance-groups-update-resp.json']",45,ab58194207ad231e75183c9636dc8c3dee07cc25,bp/instance-group-api-extension,"{ ""instance_group"": { ""id"": ""5bbcc3c4-1da2-4437-a48a-66f15b1b13f9"", ""name"": ""new_name"", ""policies"": [{""name"": ""anti-affinity""}], ""members"": [{""instance_id"": ""a00456d5-6f1b-44e6-8467-af28f0f6cd4f""}], ""metadata"": {} } } ",,1414,0
openstack%2Fcinder~master~Ib69f5bbd975fcb437ccaea74fbf7a282c5836500,openstack/cinder,master,Ib69f5bbd975fcb437ccaea74fbf7a282c5836500,WIP: Cinder Astute NFS driver,ABANDONED,2014-02-11 14:10:38.000000000,2014-03-06 06:03:37.000000000,,"[{'_account_id': 3}, {'_account_id': 1207}, {'_account_id': 2243}, {'_account_id': 4355}, {'_account_id': 4523}, {'_account_id': 6094}, {'_account_id': 7887}, {'_account_id': 10321}]","[{'number': 1, 'created': '2014-02-11 14:10:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/01c1c8bd08118dfb65078b3be172c03af377f5a3', 'message': 'WIP: Cinder Astute NFS driver\n\nAstute NFS driver with following,\n\nVolume Create/Delete - Complete\nVolume Attach/Detach - Complete\nSnapshot Create/Delete - Complete\nCreate Volume from Snapshot - Complete\nGet Volume Stats - Complete\nCopy Image to Volume - Complete\nCopy Volume to Image - WIP\nClone Volume - Complete\nExtend Volume - Complete\n\nExecute Run_tests.sh - WIP\n\nimplements bp : astute-nfs\n\nChange-Id: Ib69f5bbd975fcb437ccaea74fbf7a282c5836500\n'}, {'number': 2, 'created': '2014-02-20 07:55:25.000000000', 'files': ['cinder/volume/drivers/astutenfs.py'], 'web_link': 'https://opendev.org/openstack/cinder/commit/8e8d1f1c6789e6c1f96a3dae72e8b641b4b98e5a', 'message': 'WIP: Cinder Astute NFS driver\n\nAstute NFS driver with following,\n\nVolume Create/Delete - Complete\nVolume Attach/Detach - Complete\nSnapshot Create/Delete - Complete\nCreate Volume from Snapshot - Complete\nGet Volume Stats - Complete\nCopy Image to Volume - Complete\nCopy Volume to Image - WIP\nClone Volume - Complete\nExtend Volume - Complete\n\nExecute Run_tests.sh - WIP\n\nimplements bp : astute-nfs\n\nChange-Id: Ib69f5bbd975fcb437ccaea74fbf7a282c5836500\n'}]",30,72662,8e8d1f1c6789e6c1f96a3dae72e8b641b4b98e5a,20,8,2,7887,,,0,"WIP: Cinder Astute NFS driver

Astute NFS driver with following,

Volume Create/Delete - Complete
Volume Attach/Detach - Complete
Snapshot Create/Delete - Complete
Create Volume from Snapshot - Complete
Get Volume Stats - Complete
Copy Image to Volume - Complete
Copy Volume to Image - WIP
Clone Volume - Complete
Extend Volume - Complete

Execute Run_tests.sh - WIP

implements bp : astute-nfs

Change-Id: Ib69f5bbd975fcb437ccaea74fbf7a282c5836500
",git fetch https://review.opendev.org/openstack/cinder refs/changes/62/72662/2 && git format-patch -1 --stdout FETCH_HEAD,"['cinder/volume/drivers/astutenfs.py', 'cinder/volume/manager.py']",2,01c1c8bd08118dfb65078b3be172c03af377f5a3,bp/astute-nfs," 'cinder.volume.drivers.huawei.HuaweiVolumeDriver', 'cinder.volume.drivers.AstuteNFSDriver': 'cinder.volume.drivers.nfs.NfsDriver'}", 'cinder.volume.drivers.huawei.HuaweiVolumeDriver'},1025,1
openstack%2Fpython-neutronclient~master~I8fdf68a4aff8fcb1da8f302f0e551c4859dba535,openstack/python-neutronclient,master,I8fdf68a4aff8fcb1da8f302f0e551c4859dba535,Python3: fix print syntax,ABANDONED,2014-02-19 22:46:10.000000000,2014-03-06 06:03:30.000000000,,"[{'_account_id': 3}, {'_account_id': 490}, {'_account_id': 748}, {'_account_id': 841}, {'_account_id': 2592}, {'_account_id': 6072}, {'_account_id': 8122}, {'_account_id': 9107}, {'_account_id': 9656}]","[{'number': 1, 'created': '2014-02-19 22:46:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-neutronclient/commit/0f467ac220e354d73df76c2cebda29d713c07f83', 'message': 'Python3: fix print syntax\n\nIn Python 3, print() is a function, not a statement. Also, enable H233\n(Python 3.x incompatible use of print operator) in flake8.\n\nChange-Id: I8fdf68a4aff8fcb1da8f302f0e551c4859dba535\n'}, {'number': 2, 'created': '2014-02-25 21:23:11.000000000', 'files': ['neutronclient/neutron/v2_0/router.py', 'neutronclient/neutron/v2_0/__init__.py', 'neutronclient/neutron/v2_0/floatingip.py', 'neutronclient/neutron/v2_0/nsx/networkgateway.py', 'neutronclient/neutron/v2_0/networkprofile.py', 'neutronclient/neutron/v2_0/fw/firewallpolicy.py', 'neutronclient/neutron/v2_0/policyprofile.py', 'neutronclient/neutron/v2_0/agentscheduler.py', 'neutronclient/tests/unit/test_ssl.py', 'neutronclient/shell.py', 'tox.ini', 'neutronclient/neutron/v2_0/lb/healthmonitor.py', 'neutronclient/neutron/v2_0/quota.py'], 'web_link': 'https://opendev.org/openstack/python-neutronclient/commit/fb53f88a9048449aff9e02905e57f06e8aecb0f7', 'message': 'Python3: fix print syntax\n\nIn Python 3, print() is a function, not a statement. Also, enable H233\n(Python 3.x incompatible use of print operator) in flake8.\n\nCloses-Bug: #1284851\nChange-Id: I8fdf68a4aff8fcb1da8f302f0e551c4859dba535\n'}]",2,74862,fb53f88a9048449aff9e02905e57f06e8aecb0f7,17,9,2,8122,,,0,"Python3: fix print syntax

In Python 3, print() is a function, not a statement. Also, enable H233
(Python 3.x incompatible use of print operator) in flake8.

Closes-Bug: #1284851
Change-Id: I8fdf68a4aff8fcb1da8f302f0e551c4859dba535
",git fetch https://review.opendev.org/openstack/python-neutronclient refs/changes/62/74862/1 && git format-patch -1 --stdout FETCH_HEAD,"['neutronclient/neutron/v2_0/router.py', 'neutronclient/neutron/v2_0/__init__.py', 'neutronclient/neutron/v2_0/floatingip.py', 'neutronclient/neutron/v2_0/nsx/networkgateway.py', 'neutronclient/neutron/v2_0/networkprofile.py', 'neutronclient/neutron/v2_0/fw/firewallpolicy.py', 'neutronclient/neutron/v2_0/policyprofile.py', 'neutronclient/neutron/v2_0/agentscheduler.py', 'neutronclient/tests/unit/test_ssl.py', 'neutronclient/shell.py', 'tox.ini', 'neutronclient/neutron/v2_0/lb/healthmonitor.py', 'neutronclient/neutron/v2_0/quota.py']",13,0f467ac220e354d73df76c2cebda29d713c07f83,bug/1284851,"from __future__ import print_function print(_('Deleted %(resource)s: %(tenant_id)s') % {'tenant_id': tenant_id, 'resource': self.resource}, file=self.app.stdout)"," print >>self.app.stdout, (_('Deleted %(resource)s: %(tenant_id)s') % {'tenant_id': tenant_id, 'resource': self.resource})",65,52
openstack%2Ftempest~stable%2Fhavana~I8d41a568ac4c9fc7330077e6643b40eddc071f91,openstack/tempest,stable/havana,I8d41a568ac4c9fc7330077e6643b40eddc071f91,Avoid using assertGreater,ABANDONED,2014-01-25 06:23:01.000000000,2014-03-06 06:03:29.000000000,,"[{'_account_id': 3}, {'_account_id': 1192}, {'_account_id': 4460}, {'_account_id': 5174}, {'_account_id': 5196}, {'_account_id': 5803}, {'_account_id': 6167}, {'_account_id': 6547}]","[{'number': 1, 'created': '2014-01-25 06:23:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/0933f9e261510fb74d347fdcc7469c8d4a0955d1', 'message': ""Avoid using assertGreater\n\nThis doesn't exist in python 2.6.\n\nChange-Id: I8d41a568ac4c9fc7330077e6643b40eddc071f91\n""}, {'number': 2, 'created': '2014-02-11 07:31:05.000000000', 'files': ['tempest/api/compute/servers/test_server_actions.py'], 'web_link': 'https://opendev.org/openstack/tempest/commit/264354cfa5e73c6041672cd8cc9099d63ee78f62', 'message': ""Avoid using assertGreater\n\nThis doesn't exist in python 2.6.\n\nChange-Id: I8d41a568ac4c9fc7330077e6643b40eddc071f91\n(cherry picked from commit 32173d1cc5b5300c04ffd4da988827354bd07fa3)\n""}]",0,69102,264354cfa5e73c6041672cd8cc9099d63ee78f62,36,8,2,4460,,,0,"Avoid using assertGreater

This doesn't exist in python 2.6.

Change-Id: I8d41a568ac4c9fc7330077e6643b40eddc071f91
(cherry picked from commit 32173d1cc5b5300c04ffd4da988827354bd07fa3)
",git fetch https://review.opendev.org/openstack/tempest refs/changes/02/69102/2 && git format-patch -1 --stdout FETCH_HEAD,['tempest/api/compute/servers/test_server_actions.py'],1,0933f9e261510fb74d347fdcc7469c8d4a0955d1,py26," self.assertTrue(new_boot_time > boot_time, '%s > %s' % (new_boot_time, boot_time)) self.assertTrue(new_boot_time > boot_time, '%s > %s' % (new_boot_time, boot_time))"," self.assertGreater(new_boot_time, boot_time) self.assertGreater(new_boot_time, boot_time)",4,2
openstack%2Fneutron~master~I3375d7005214dbc536daaec1d224c4b3686fe3bf,openstack/neutron,master,I3375d7005214dbc536daaec1d224c4b3686fe3bf,Fix alembic migration for postgresql,ABANDONED,2014-01-23 11:27:01.000000000,2014-03-06 06:03:25.000000000,,"[{'_account_id': 3}, {'_account_id': 748}, {'_account_id': 2592}, {'_account_id': 4460}, {'_account_id': 6476}, {'_account_id': 9008}, {'_account_id': 9681}, {'_account_id': 9732}, {'_account_id': 9845}, {'_account_id': 9925}, {'_account_id': 10116}]","[{'number': 1, 'created': '2014-01-23 11:27:01.000000000', 'files': ['neutron/db/migration/alembic_migrations/versions/128e042a2b68_ext_gw_mode.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/4d8aab8b6dc16e1f5e869826ab0e01b4c658aa3a', 'message': 'Fix alembic migration for postgresql\n\nOne part of bug  #1241577 is not sqlite-specific, but also applies to\npostgresql.\n\nChange-Id: I3375d7005214dbc536daaec1d224c4b3686fe3bf\n'}]",5,68611,4d8aab8b6dc16e1f5e869826ab0e01b4c658aa3a,50,11,1,4460,,,0,"Fix alembic migration for postgresql

One part of bug  #1241577 is not sqlite-specific, but also applies to
postgresql.

Change-Id: I3375d7005214dbc536daaec1d224c4b3686fe3bf
",git fetch https://review.opendev.org/openstack/neutron refs/changes/11/68611/1 && git format-patch -1 --stdout FETCH_HEAD,['neutron/db/migration/alembic_migrations/versions/128e042a2b68_ext_gw_mode.py'],1,4d8aab8b6dc16e1f5e869826ab0e01b4c658aa3a,bug/1241577," nullable=False, server_default='1')) op.execute(""UPDATE routers SET enable_snat='True'"")"," nullable=False, default=True)) op.execute(""UPDATE routers SET enable_snat=True"")",2,2
openstack%2Foslo-incubator~master~Ide08e859465caf32bdc3a53ed07b24737a368d25,openstack/oslo-incubator,master,Ide08e859465caf32bdc3a53ed07b24737a368d25,Scrub passwords in the config section of GMRs,ABANDONED,2014-02-18 21:06:56.000000000,2014-03-06 06:03:24.000000000,,"[{'_account_id': 3}, {'_account_id': 1779}, {'_account_id': 1994}, {'_account_id': 2271}, {'_account_id': 7677}]","[{'number': 1, 'created': '2014-02-18 21:06:56.000000000', 'files': ['tests/unit/reports/test_openstack_generators.py', 'openstack/common/report/models/conf.py', 'openstack/common/report/generators/conf.py'], 'web_link': 'https://opendev.org/openstack/oslo-incubator/commit/0de98448d4fbf1b18b2eaa7eca8ae2d50e73d1d1', 'message': 'Scrub passwords in the config section of GMRs\n\nCurrently, the config section of the Guru Meditation Reports\ndisplays all the configuration options verbatim.  This means\nthat passwords will be dumped.  This can present a security risk\n(as someone could potentially not have access to the config files,\nbut be allowed to dump/view the Guru Meditation Reports).\n\nErgo, a new parameter has been added to the Config generator and\nmodel, scrub_passwords, which defaults to True.  When enabled,\nany key of the form /^\\w+_(password|token|key)$/ will have its\nvalue masked with stars in the GMR.\n\nChange-Id: Ide08e859465caf32bdc3a53ed07b24737a368d25\n'}]",2,74497,0de98448d4fbf1b18b2eaa7eca8ae2d50e73d1d1,8,5,1,7677,,,0,"Scrub passwords in the config section of GMRs

Currently, the config section of the Guru Meditation Reports
displays all the configuration options verbatim.  This means
that passwords will be dumped.  This can present a security risk
(as someone could potentially not have access to the config files,
but be allowed to dump/view the Guru Meditation Reports).

Ergo, a new parameter has been added to the Config generator and
model, scrub_passwords, which defaults to True.  When enabled,
any key of the form /^\w+_(password|token|key)$/ will have its
value masked with stars in the GMR.

Change-Id: Ide08e859465caf32bdc3a53ed07b24737a368d25
",git fetch https://review.opendev.org/openstack/oslo-incubator refs/changes/97/74497/1 && git format-patch -1 --stdout FETCH_HEAD,"['tests/unit/reports/test_openstack_generators.py', 'openstack/common/report/models/conf.py', 'openstack/common/report/generators/conf.py']",3,0de98448d4fbf1b18b2eaa7eca8ae2d50e73d1d1,," def __init__(self, cnf=cfg.CONF, scrub_passwords=True): self.scrub_passwords = scrub_passwords return cm.ConfigModel(self.conf_obj, scrub_passwords=self.scrub_passwords)"," def __init__(self, cnf=cfg.CONF): return cm.ConfigModel(self.conf_obj)",69,12
openstack%2Fnova~master~I963b1c55950f7d29e0e272d81d037bf1d4e41829,openstack/nova,master,I963b1c55950f7d29e0e272d81d037bf1d4e41829,Pass os-region-name to neutron if set,ABANDONED,2014-02-26 01:46:35.000000000,2014-03-06 06:03:23.000000000,,"[{'_account_id': 3}, {'_account_id': 261}, {'_account_id': 748}, {'_account_id': 1653}, {'_account_id': 1849}, {'_account_id': 2592}, {'_account_id': 4393}, {'_account_id': 4395}, {'_account_id': 9008}, {'_account_id': 9578}]","[{'number': 1, 'created': '2014-02-26 01:46:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/80a7c3d9803076d38fff5032b722e82270c0ad06', 'message': ""Pass os-region-name to neutron if set\n\nNeutron needs to know the region that a particular port lives on when\nmultiple nova regions exists backed by the same neutron endpoint. This is\nneeded for metadata to work in addtion for the blueprint\nadmin-event-callback-api as neutron needs to call to nova and if\nmultiple nova regions exist neutron won't know which one to send the request.\n\nThis patch just passes along the region name as part of the port to neutron.\n\nImplements blueprint: pass-region-to-neutron\n\nChange-Id: I963b1c55950f7d29e0e272d81d037bf1d4e41829\n""}, {'number': 2, 'created': '2014-02-26 02:53:16.000000000', 'files': ['nova/tests/network/test_neutronv2.py', 'nova/network/neutronv2/api.py', 'etc/nova/nova.conf.sample', 'nova/volume/cinder.py', 'nova/compute/manager.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/04bdf0f56e2749a4dce7f4b28d61e2e23d369ff4', 'message': ""Pass os-region-name to neutron if set\n\nNeutron needs to know the region that a particular port lives on when\nmultiple nova regions exists backed by the same neutron endpoint. This is\nneeded for metadata to work in addtion for the blueprint\nadmin-event-callback-api as neutron needs to call to nova and if\nmultiple nova regions exist neutron won't know which one to send the request.\n\nThis patch just passes along the region name as part of the port to neutron.\n\nImplements blueprint: pass-region-to-neutron\n\nChange-Id: I963b1c55950f7d29e0e272d81d037bf1d4e41829\n""}]",0,76411,04bdf0f56e2749a4dce7f4b28d61e2e23d369ff4,17,10,2,4395,,,0,"Pass os-region-name to neutron if set

Neutron needs to know the region that a particular port lives on when
multiple nova regions exists backed by the same neutron endpoint. This is
needed for metadata to work in addtion for the blueprint
admin-event-callback-api as neutron needs to call to nova and if
multiple nova regions exist neutron won't know which one to send the request.

This patch just passes along the region name as part of the port to neutron.

Implements blueprint: pass-region-to-neutron

Change-Id: I963b1c55950f7d29e0e272d81d037bf1d4e41829
",git fetch https://review.opendev.org/openstack/nova refs/changes/11/76411/2 && git format-patch -1 --stdout FETCH_HEAD,"['nova/tests/network/test_neutronv2.py', 'nova/network/neutronv2/api.py', 'nova/volume/cinder.py', 'nova/compute/manager.py']",4,80a7c3d9803076d38fff5032b722e82270c0ad06,bp/admin-event-callback-api," cfg.StrOpt('os_region_name', help='Region name of this node'),",,39,3
openstack%2Fhacking~master~Ifedd7b4e61f5e0494b693e15357dd958424b7c22,openstack/hacking,master,Ifedd7b4e61f5e0494b693e15357dd958424b7c22,Add H308 rule,ABANDONED,2014-02-26 15:26:19.000000000,2014-03-06 06:03:22.000000000,,"[{'_account_id': 3}, {'_account_id': 1849}, {'_account_id': 5652}]","[{'number': 1, 'created': '2014-02-26 15:26:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/hacking/commit/ce6189483b88a0f63c09d9641bf78488c25d8c1d', 'message': 'Add H308 rule.\n\nWe previously enforced import groups and having at least one blank line\nbetween them.  H308 strengthens this to requiring exactly one blank line\nbetween import groups.  PEP8 flags for extra newlines in various places,\nbut misses this one.\n\nChange-Id: Ifedd7b4e61f5e0494b693e15357dd958424b7c22\nCloses-bug: #1285189\n'}, {'number': 2, 'created': '2014-02-26 15:34:43.000000000', 'files': ['hacking/core.py', 'setup.cfg'], 'web_link': 'https://opendev.org/openstack/hacking/commit/b855655d95e174197c0b88c473367a7a40ffa2f2', 'message': 'Add H308 rule\n\nWe previously enforced import groups and having at least one blank line\nbetween them.  H308 strengthens this to requiring exactly one blank line\nbetween import groups.  PEP8 flags for extra newlines in various places,\nbut misses this one.\n\nChange-Id: Ifedd7b4e61f5e0494b693e15357dd958424b7c22\nCloses-bug: #1285189\n'}]",1,76559,b855655d95e174197c0b88c473367a7a40ffa2f2,11,3,2,5652,,,0,"Add H308 rule

We previously enforced import groups and having at least one blank line
between them.  H308 strengthens this to requiring exactly one blank line
between import groups.  PEP8 flags for extra newlines in various places,
but misses this one.

Change-Id: Ifedd7b4e61f5e0494b693e15357dd958424b7c22
Closes-bug: #1285189
",git fetch https://review.opendev.org/openstack/hacking refs/changes/59/76559/1 && git format-patch -1 --stdout FETCH_HEAD,"['hacking/core.py', 'setup.cfg']",2,ce6189483b88a0f63c09d9641bf78488c25d8c1d,import_groups_excess_newlines, H308 = hacking.core:hacking_import_groups_excess_newlines,,30,0
openstack%2Fpython-swiftclient~master~I1994b9793fe2d0306a4d4586ca821b193ed534f0,openstack/python-swiftclient,master,I1994b9793fe2d0306a4d4586ca821b193ed534f0,Use six.moves.http_client rather than httplib,ABANDONED,2013-12-19 17:22:41.000000000,2014-03-06 06:03:21.000000000,,"[{'_account_id': 3}, {'_account_id': 866}, {'_account_id': 2622}, {'_account_id': 7020}]","[{'number': 1, 'created': '2013-12-19 17:22:41.000000000', 'files': ['requirements.txt', 'swiftclient/client.py'], 'web_link': 'https://opendev.org/openstack/python-swiftclient/commit/b2a267d9bcd88ad741a84a517d64c2e4e8fe5585', 'message': 'Use six.moves.http_client rather than httplib\n\nThis make the related code work with both Python 2 and Python 3.\n\nChange-Id: I1994b9793fe2d0306a4d4586ca821b193ed534f0\n'}]",0,63179,b2a267d9bcd88ad741a84a517d64c2e4e8fe5585,7,4,1,8122,,,0,"Use six.moves.http_client rather than httplib

This make the related code work with both Python 2 and Python 3.

Change-Id: I1994b9793fe2d0306a4d4586ca821b193ed534f0
",git fetch https://review.opendev.org/openstack/python-swiftclient refs/changes/79/63179/1 && git format-patch -1 --stdout FETCH_HEAD,"['requirements.txt', 'swiftclient/client.py']",2,b2a267d9bcd88ad741a84a517d64c2e4e8fe5585,fix_httplib,from six.moves import http_clientHTTPException = http_client.HTTPException HTTPConnection = http_client.HTTPConnection HTTPSConnection = http_client.HTTPSConnection ,"from httplib import HTTPException, HTTPConnection, HTTPSConnection",6,1
openstack%2Foslo-incubator~master~I56745128a6d5409b78eac616afe08a426c99d5cd,openstack/oslo-incubator,master,I56745128a6d5409b78eac616afe08a426c99d5cd,Add class ModelsObjectComparatorMixin,ABANDONED,2013-12-12 09:45:55.000000000,2014-03-06 06:03:21.000000000,,"[{'_account_id': 3}, {'_account_id': 2271}, {'_account_id': 5652}, {'_account_id': 6849}, {'_account_id': 7491}, {'_account_id': 8054}]","[{'number': 1, 'created': '2013-12-12 09:45:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo-incubator/commit/33fbf4167ed5a2b0a57d851c1e7c39c988e746e7', 'message': 'Add class ModelsObjectComparatorMixin.\n  Move class ModelsObjectComparatorMixin from nova.tests.db.test_db_api\nto oslo-incubator, so we could reuse it in other projects.\n\nChange-Id: I56745128a6d5409b78eac616afe08a426c99d5cd\n'}, {'number': 2, 'created': '2013-12-12 09:47:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo-incubator/commit/3c34d62849419c796f724035cfc4c22ba0c4067b', 'message': 'Add class ModelsObjectComparatorMixin.\n\nMove class ModelsObjectComparatorMixin from nova.tests.db.test_db_api\nto oslo-incubator, so we could reuse it in other projects.\n\nChange-Id: I56745128a6d5409b78eac616afe08a426c99d5cd\n'}, {'number': 3, 'created': '2013-12-13 09:33:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo-incubator/commit/6d7a92314968f10c9305e9f40d1ac8e56f44da87', 'message': 'Add class ModelsObjectComparatorMixin.\n\n  Move class ModelsObjectComparatorMixin from nova.tests.db.test_db_api\nto oslo-incubator, so we could reuse it in other projects.\n\nChange-Id: I56745128a6d5409b78eac616afe08a426c99d5cd\n'}, {'number': 4, 'created': '2013-12-13 10:44:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo-incubator/commit/c0d8513a4c7043d21033c28e7aaa4c8e90aecbf5', 'message': 'Add class ModelsObjectComparatorMixin.\n\n  Move class ModelsObjectComparatorMixin from nova.tests.db.test_db_api\nto oslo-incubator, so we could reuse it in other projects.\n\nChange-Id: I56745128a6d5409b78eac616afe08a426c99d5cd\n'}, {'number': 5, 'created': '2013-12-13 11:49:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo-incubator/commit/32665805e5f49260ab0eefe87cb72aee45d22ade', 'message': 'Add class ModelsObjectComparatorMixin.\n\n  Move class ModelsObjectComparatorMixin from nova.tests.db.test_db_api\nto oslo-incubator, so we could reuse it in other projects.\n\nChange-Id: I56745128a6d5409b78eac616afe08a426c99d5cd\n'}, {'number': 6, 'created': '2013-12-13 12:03:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo-incubator/commit/82c68dc83ef1c5f5597645c1f93a8be5e59a2d68', 'message': 'Add class ModelsObjectComparatorMixin.\n\n  Move class ModelsObjectComparatorMixin from nova.tests.db.test_db_api\nto oslo-incubator, so we could reuse it in other projects.\n\nChange-Id: I56745128a6d5409b78eac616afe08a426c99d5cd\n'}, {'number': 7, 'created': '2013-12-13 12:21:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo-incubator/commit/31091abdada791e87023b7028521076065779774', 'message': 'Add class ModelsObjectComparatorMixin.\n\n  Move class ModelsObjectComparatorMixin from nova.tests.db.test_db_api\nto oslo-incubator, so we could reuse it in other projects.\n\nChange-Id: I56745128a6d5409b78eac616afe08a426c99d5cd\n'}, {'number': 8, 'created': '2013-12-16 08:14:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo-incubator/commit/5d5969e749f6cc1c265f2638800ae93c1251b8cb', 'message': 'Add class ModelsObjectComparatorMixin.\n\n  Move class ModelsObjectComparatorMixin from nova.tests.db.test_db_api\nto oslo-incubator, so we could reuse it in other projects.\n\nChange-Id: I56745128a6d5409b78eac616afe08a426c99d5cd\n'}, {'number': 9, 'created': '2013-12-17 11:14:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo-incubator/commit/a567c46deb6d2c526394aa0d489191bb18acd0b1', 'message': 'Add class ModelsObjectComparatorMixin.\n\n  Move class ModelsObjectComparatorMixin from nova.tests.db.test_db_api\nto oslo-incubator, so we could reuse it in other projects.\n\nChange-Id: I56745128a6d5409b78eac616afe08a426c99d5cd\n'}, {'number': 10, 'created': '2013-12-17 11:41:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo-incubator/commit/da8e58b3437023385a732dd285b5fe8a2380e516', 'message': 'Add class ModelsObjectComparatorMixin.\n\n  Move class ModelsObjectComparatorMixin from nova.tests.db.test_db_api\nto oslo-incubator, so we could reuse it in other projects.\n\nChange-Id: I56745128a6d5409b78eac616afe08a426c99d5cd\n'}, {'number': 11, 'created': '2013-12-17 12:00:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo-incubator/commit/06dab6fa942cd2aaf1a1cd3ff32e6e26293e577d', 'message': 'Add class ModelsObjectComparatorMixin.\n\n  Move class ModelsObjectComparatorMixin from nova.tests.db.test_db_api\nto oslo-incubator, so we could reuse it in other projects.\n\nChange-Id: I56745128a6d5409b78eac616afe08a426c99d5cd\n'}, {'number': 12, 'created': '2013-12-17 14:43:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo-incubator/commit/b9949021d1cccd11afad17416797073dc9f5689d', 'message': ""Add class ModelsObjectComparatorMixin.\n\n  Move class ModelsObjectComparatorMixin from nova.tests.db.test_db_api\nto oslo-incubator, so we could reuse it in other projects.\n\nThis class have following methods:\n  - assertEqualObjects: check equal of the two dictionary, possible\n  exception of some key.\n  - assertEqualListsOfObjects: check equal of the two lists. Object's\n  list is dictionary.\n  - assertEqualListsOfPrimitivesAsSets: check equal of the two sets.\n  Object's set is dictionary.\n\nChange-Id: I56745128a6d5409b78eac616afe08a426c99d5cd\n""}, {'number': 13, 'created': '2013-12-17 14:58:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo-incubator/commit/b248bcad3eabb3ff41df7b8af8740d9b16ffea58', 'message': ""Add class ModelsObjectComparatorMixin.\n\n  Move class ModelsObjectComparatorMixin from nova.tests.db.test_db_api\nto oslo-incubator, so we could reuse it in other projects.\n\nThis class have following methods:\n- assertEqualObjects: check equal of the two dictionary, possible\nexception of some key.\n- assertEqualListsOfObjects: check equal of the two lists. List's\nobject is dictionary.\n- assertEqualListsOfPrimitivesAsSets: check equal of the two sets.\nSet's object is dictionary.\n\nChange-Id: I56745128a6d5409b78eac616afe08a426c99d5cd\n""}, {'number': 14, 'created': '2013-12-20 12:57:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo-incubator/commit/57025665c87fcbae95e3aa44bfc910cdb5d8f7a3', 'message': ""Add class ModelsObjectComparatorMixin.\n\n  Move class ModelsObjectComparatorMixin from nova.tests.db.test_db_api\nto oslo-incubator, so we could reuse it in other projects.\n\nThis class have following methods:\n- assertEqualObjects: check equal of the two dictionary, possible\nexception of some key.\n- assertEqualListsOfObjects: check equal of the two lists. List's\nobject is dictionary.\n- assertEqualListsOfPrimitivesAsSets: check equal of the two sets.\nSet's object is dictionary.\n\nChange-Id: I56745128a6d5409b78eac616afe08a426c99d5cd\n""}, {'number': 15, 'created': '2013-12-23 13:22:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo-incubator/commit/3e5b9257c8ddd8067b015cd778d3b307efcaad49', 'message': ""Add class ModelsObjectComparatorMixin\n\nMove class ModelsObjectComparatorMixin from nova.tests.db.test_db_api\nto oslo-incubator, so we could reuse it in other projects.\n\nThis class have following methods:\n- assertEqualObjects: check equal of the two dict, possible\nexception of some keys.\n- assertEqualListsOfObjects: check equal of the two lists. List's\nobject is dict.\n- assertEqualListsOfPrimitivesAsSets: check equal of the two dict,\nwhose values are set.\n\nChange-Id: I56745128a6d5409b78eac616afe08a426c99d5cd\n""}, {'number': 16, 'created': '2013-12-23 13:28:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo-incubator/commit/91c4ec56a88ce8b7d0f8fe0df0565c33212a14fb', 'message': ""Add class ModelsObjectComparatorMixin\n\nMove class ModelsObjectComparatorMixin from nova.tests.db.test_db_api\nto oslo-incubator, so we could reuse it in other projects.\n\nThis class have following methods:\n- assertEqualObjects: check equal of the two dict, possible\nexception of some keys.\n- assertEqualListsOfObjects: check equal of the two lists. List's\nobject is dict.\n- assertEqualListsOfPrimitivesAsSets: check equal of the two dict,\nwhose values are set.\n\nChange-Id: I56745128a6d5409b78eac616afe08a426c99d5cd\n""}, {'number': 17, 'created': '2013-12-25 08:28:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo-incubator/commit/b149cddc760ab0b167d6bac8b8654d9fca1cb0eb', 'message': ""Add class ModelsObjectComparatorMixin\n\nMove class ModelsObjectComparatorMixin from nova.tests.db.test_db_api\nto oslo-incubator, so we could reuse it in other projects.\n\nThis class have following methods:\n- assertEqualObjects: check equal of the two dict, possible\nexception of some keys.\n- assertEqualListsOfObjects: check equal of the two lists. List's\nobject is dict.\n- assertEqualListsOfPrimitivesAsSets: check equal of the two dict,\nwhose values are set.\n\nChange-Id: I56745128a6d5409b78eac616afe08a426c99d5cd\n""}, {'number': 18, 'created': '2013-12-25 10:07:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo-incubator/commit/4d063956c5833a7283a8e80bd2a37a3df60e9f44', 'message': ""Add class ModelsObjectComparatorMixin\n\nMove class ModelsObjectComparatorMixin from nova.tests.db.test_db_api\nto oslo-incubator, so we could reuse it in other projects.\n\nThis class have following methods:\n- assertEqualObjects: check equal of the two dict, possible\nexception of some keys.\n- assertEqualListsOfObjects: check equal of the two lists. List's\nobject is dict.\n- assertEqualListsOfPrimitivesAsSets: check equal of the two dict,\nwhose values are set.\n\nChange-Id: I56745128a6d5409b78eac616afe08a426c99d5cd\n""}, {'number': 19, 'created': '2013-12-26 12:46:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo-incubator/commit/2a0c9839db14470cdc0cbb53f5d5f31292328fca', 'message': 'Add class ModelsObjectComparatorMixin\n\nMove class ModelsObjectComparatorMixin from nova.tests.db.test_db_api\nto oslo-incubator, so we could reuse it in other projects.\n\nObjet is model istances.\n\nThis class has following methods:\n- assertEqualObjects: check equal of the two objects, possible\nexception of some keys.\n- assertEqualListsOfObjects: check equal of the two lists.\n- assertEqualListsOfPrimitivesAsSets: check equal of the two sets.\n\nChange-Id: I56745128a6d5409b78eac616afe08a426c99d5cd\n'}, {'number': 20, 'created': '2013-12-27 10:32:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo-incubator/commit/a0682420135e96a3851f60170796cfa4af5fb1ce', 'message': 'Add class ModelsObjectComparatorMixin\n\nMove class ModelsObjectComparatorMixin from nova.tests.db.test_db_api\nto oslo-incubator, so we could reuse it in other projects.\n\nThe class provides helper methods for checking equality of objects\n(ModelBase instances) and lists of objects.\n\nChange-Id: I56745128a6d5409b78eac616afe08a426c99d5cd\n'}, {'number': 21, 'created': '2013-12-27 16:28:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo-incubator/commit/0d9e9740023797cd885587d37283563c6e554c48', 'message': 'Add class ModelsObjectComparatorMixin\n\nMove class ModelsObjectComparatorMixin from nova.tests.db.test_db_api\nto oslo-incubator, so we could reuse it in other projects.\n\nThe class provides helper methods for checking equality of objects\n(ModelBase instances) and lists of objects.\n\nChange-Id: I56745128a6d5409b78eac616afe08a426c99d5cd\n'}, {'number': 22, 'created': '2014-01-02 16:36:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo-incubator/commit/c05dab3091b316c61f339be1ff104417edc77322', 'message': 'Add class ModelsObjectComparatorMixin\n\nMove class ModelsObjectComparatorMixin from nova.tests.db.test_db_api\nto oslo-incubator, so we could reuse it in other projects.\n\nThe class provides helper methods for checking equality of objects\n(ModelBase instances) and lists of objects.\n\nChange-Id: I56745128a6d5409b78eac616afe08a426c99d5cd\n'}, {'number': 23, 'created': '2014-01-20 13:48:09.000000000', 'files': ['openstack/common/test.py', 'tests/unit/test_base.py'], 'web_link': 'https://opendev.org/openstack/oslo-incubator/commit/d6659774cc1aace75042225a9f6d755d5103d29e', 'message': 'Add class ModelsObjectComparatorMixin\n\nMove class ModelsObjectComparatorMixin from nova.tests.db.test_db_api\nto oslo-incubator, so we could reuse it in other projects.\n\nThe class provides helper methods for checking equality of objects\n(ModelBase instances) and lists of objects.\n\nChange-Id: I56745128a6d5409b78eac616afe08a426c99d5cd\n'}]",104,61685,d6659774cc1aace75042225a9f6d755d5103d29e,91,6,23,8054,,,0,"Add class ModelsObjectComparatorMixin

Move class ModelsObjectComparatorMixin from nova.tests.db.test_db_api
to oslo-incubator, so we could reuse it in other projects.

The class provides helper methods for checking equality of objects
(ModelBase instances) and lists of objects.

Change-Id: I56745128a6d5409b78eac616afe08a426c99d5cd
",git fetch https://review.opendev.org/openstack/oslo-incubator refs/changes/85/61685/6 && git format-patch -1 --stdout FETCH_HEAD,['openstack/common/test.py'],1,33fbf4167ed5a2b0a57d851c1e7c39c988e746e7,master," class ModelsObjectComparatorMixin(testtools.TestCase): def setUp(self): super(BaseTestCase, self).setUp() def _dict_from_object(self, obj, ignored_keys): if ignored_keys is None: ignored_keys = [] return dict([(k, v) for k, v in obj.iteritems() if k not in ignored_keys]) def _assertEqualObjects(self, obj1, obj2, ignored_keys=None): obj1 = self._dict_from_object(obj1, ignored_keys) obj2 = self._dict_from_object(obj2, ignored_keys) self.assertEqual(len(obj1), len(obj2), ""Keys mismatch: %s"" % str(set(obj1.keys()) ^ set(obj2.keys()))) for key, value in obj1.iteritems(): self.assertEqual(value, obj2[key]) def _assertEqualListsOfObjects(self, objs1, objs2, ignored_keys=None): obj_to_dict = lambda o: self._dict_from_object(o, ignored_keys) sort_key = lambda d: [d[k] for k in sorted(d)] conv_and_sort = lambda obj: sorted(map(obj_to_dict, obj), key=sort_key) self.assertEqual(conv_and_sort(objs1), conv_and_sort(objs2)) def _assertEqualListsOfPrimitivesAsSets(self, primitives1, primitives2): self.assertEqual(len(primitives1), len(primitives2)) for primitive in primitives1: self.assertIn(primitive, primitives2) for primitive in primitives2: self.assertIn(primitive, primitives1)",,38,0
openstack%2Fceilometer~master~Ief7aa762f6747f5f2def0e48b81a884ffa485e77,openstack/ceilometer,master,Ief7aa762f6747f5f2def0e48b81a884ffa485e77,Fix misspellings in ceilometer,ABANDONED,2014-02-07 05:16:15.000000000,2014-03-06 06:03:19.000000000,,"[{'_account_id': 3}, {'_account_id': 1669}, {'_account_id': 2860}, {'_account_id': 4458}, {'_account_id': 4491}, {'_account_id': 6676}]","[{'number': 1, 'created': '2014-02-07 05:16:15.000000000', 'files': ['ceilometer/tests/storage/test_storage_scenarios.py', 'ceilometer/api/v1/static/jquery-1.8.3.js'], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/aa87dfc7eca5a5de52ab15004b1ccaa72357bff1', 'message': 'Fix misspellings in ceilometer\n\nFix misspellings detected by:\n* pip install misspellings\n* git ls-files | grep -v locale | misspellings -f -\n\nChange-Id: Ief7aa762f6747f5f2def0e48b81a884ffa485e77\nCloses-Bug: #1257295\n'}]",0,71741,aa87dfc7eca5a5de52ab15004b1ccaa72357bff1,17,6,1,4458,,,0,"Fix misspellings in ceilometer

Fix misspellings detected by:
* pip install misspellings
* git ls-files | grep -v locale | misspellings -f -

Change-Id: Ief7aa762f6747f5f2def0e48b81a884ffa485e77
Closes-Bug: #1257295
",git fetch https://review.opendev.org/openstack/ceilometer refs/changes/41/71741/1 && git format-patch -1 --stdout FETCH_HEAD,"['ceilometer/tests/storage/test_storage_scenarios.py', 'ceilometer/api/v1/static/jquery-1.8.3.js']",2,aa87dfc7eca5a5de52ab15004b1ccaa72357bff1,, // This is to test IE's treatment of not explicitly , // This is to test IE's treatment of not explictly ,3,3
openstack%2Fswift~master~I7406dee5d8d9ae59ce5aa5cff863fba1ec4e8770,openstack/swift,master,I7406dee5d8d9ae59ce5aa5cff863fba1ec4e8770,Split up object-server async update method.,ABANDONED,2013-12-09 08:03:11.000000000,2014-03-06 06:03:16.000000000,,"[{'_account_id': 3}, {'_account_id': 597}, {'_account_id': 1179}, {'_account_id': 6198}, {'_account_id': 7652}, {'_account_id': 9625}]","[{'number': 1, 'created': '2013-12-09 08:03:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/ac4f45bc3c598c353d793a657708347ec059822f', 'message': 'Split up object-server async update method.\n\nThe new ObjectController.save_async_update method should provide a better\nbarrier for implementation specific storage of failed container updates for\npost-processing retry.\n\nThe async_update work is an attempt to pre-empt a similar problem we had with\nDiskFileExpired in the mem_diskfile implementation by making unnessecary for\nsubclasses to reimplement ObjectController.async_update.\n\nThis change does not remove the duplication of DiskFileReader.app_iter_range\nand .app_iter_ranges.\n\nChange-Id: I7406dee5d8d9ae59ce5aa5cff863fba1ec4e8770\n'}, {'number': 2, 'created': '2014-01-09 23:36:38.000000000', 'files': ['swift/obj/server.py', 'swift/obj/mem_server.py', 'swift/obj/diskfile.py'], 'web_link': 'https://opendev.org/openstack/swift/commit/9ab6901f7e3923835ed4e8d2bd1bafaf35729084', 'message': 'Split up object-server async update method.\n\nThe new ObjectController.save_async_update method should provide a better\nbarrier for implementation specific storage of failed container updates for\npost-processing retry.\n\nThe async_update work is an attempt to pre-empt a similar problem we had with\nDiskFileExpired in the mem_diskfile implementation by making unnessecary for\nsubclasses to reimplement ObjectController.async_update.\n\nThis change does not remove the duplication of DiskFileReader.app_iter_range\nand .app_iter_ranges.\n\nChange-Id: I7406dee5d8d9ae59ce5aa5cff863fba1ec4e8770\n'}]",2,60763,9ab6901f7e3923835ed4e8d2bd1bafaf35729084,11,6,2,1179,,,0,"Split up object-server async update method.

The new ObjectController.save_async_update method should provide a better
barrier for implementation specific storage of failed container updates for
post-processing retry.

The async_update work is an attempt to pre-empt a similar problem we had with
DiskFileExpired in the mem_diskfile implementation by making unnessecary for
subclasses to reimplement ObjectController.async_update.

This change does not remove the duplication of DiskFileReader.app_iter_range
and .app_iter_ranges.

Change-Id: I7406dee5d8d9ae59ce5aa5cff863fba1ec4e8770
",git fetch https://review.opendev.org/openstack/swift refs/changes/63/60763/1 && git format-patch -1 --stdout FETCH_HEAD,"['swift/obj/server.py', 'swift/obj/mem_server.py', 'swift/obj/diskfile.py']",3,ac4f45bc3c598c353d793a657708347ec059822f,fixasync," def _construct_async_update_path(self, account, container, obj, device, timestamp, **kwargs): return os.path.join( self.devices, device, ASYNCDIR, ohash[-3:], '%s-%s' % (ohash, normalize_timestamp(timestamp)), ) def _write_async_update(self, data, path, device, **kwargs): tmp_path = os.path.join(self.devices, device, 'tmp') write_pickle, data, path, tmp_path) def save_async_update(self, op, account, container, obj, headers, **kwargs): """""" In the event that the Swift container server(s) are not able to be updated about the successful creation or deletion of an object in the underlying storage a record of the failed update will be saved for post-processing. The following pertinent information about the failed request will be needed to update the container servers: :param op: operation performed (ex: 'PUT', or 'DELETE') :param headers_out: dictionary of headers to send in the container request (including x-timestamp) :param account: account name for the object :param container: container name for the object :param obj: object name The following additional information is provided from the object server: :keyword device: device name that the object is in """""" data = {'op': op, 'account': account, 'container': container, 'obj': obj, 'headers': headers} timestamp = headers['x-timestamp'] update_path = self._construct_async_update_path( account, container, obj, timestamp=timestamp, **kwargs) self._write_async_update(data, update_path, **kwargs)"," def construct_dev_path(self, device): """""" Construct the path to a device without checking if it is mounted. :param device: name of target device :returns: full path to the device """""" return os.path.join(self.devices, device) def pickle_async_update(self, device, account, container, obj, data, timestamp): device_path = self.construct_dev_path(device) async_dir = os.path.join(device_path, ASYNCDIR) write_pickle, data, os.path.join(async_dir, ohash[-3:], ohash + '-' + normalize_timestamp(timestamp)), os.path.join(device_path, 'tmp'))",59,72
openstack%2Fcinder~master~I472361c6e04c2d7e1a03282e3015bfd6280019d4,openstack/cinder,master,I472361c6e04c2d7e1a03282e3015bfd6280019d4,scheduling for local storage,ABANDONED,2014-01-15 00:18:56.000000000,2014-03-06 06:03:07.000000000,,"[{'_account_id': 3}, {'_account_id': 170}, {'_account_id': 1207}, {'_account_id': 2243}, {'_account_id': 2759}, {'_account_id': 4355}, {'_account_id': 8263}]","[{'number': 1, 'created': '2014-01-15 00:18:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/7dd6eab086e09f1d4632a833c1c060005030d663', 'message': 'In some use case (e.g. hadoop cluster), we need create local volume in the same host in which vm instance was created.\n\ncli version 2 example) cinder create [--hint instance_uuid=<instance_uuid>] size\n\nThis volume only can be attached the specific vm instance.\n\n(Restrictions) cinder-volume has to running in the computer server which want to be using local storage.\n\nChange-Id: I472361c6e04c2d7e1a03282e3015bfd6280019d4\nImplements: blueprint local-storage-volume-scheduling\n'}, {'number': 2, 'created': '2014-01-16 05:18:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/d368b7b234a19ba92a163b69da68cbe0bf0a7d7e', 'message': 'scheduling for local storage\n\nIn some use case (e.g. hadoop cluster), we need create\nlocal volume in the same host in which vm instance was created.\n\n(cli version 2 example)\ncinder create [--hint instance_uuid=<instance_uuid>] size\n\nThis volume only can be attached the specific vm instance.\n\n(Restrictions)\ncinder-volume has to running in the computer server\nwhich want to be using local storage.\n\nChange-Id: I472361c6e04c2d7e1a03282e3015bfd6280019d4\nImplements: blueprint local-storage-volume-scheduling\n'}, {'number': 3, 'created': '2014-02-05 08:20:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/0374bbcd927e7c8f5282e5288383c91655f6a0dc', 'message': 'scheduling for local storage\n\nIn some use case (e.g. hadoop cluster), we need create\nlocal volume in the same host in which vm instance was created.\n\n(cli version 2 example)\ncinder create [--hint instance_uuid=<instance_uuid>] size\n\nThis volume only can be attached the specific vm instance.\n\n(Restrictions)\ncinder-volume has to running in the computer server\nwhich want to be using local storage.\n\nDocImpact\n\nChange-Id: I472361c6e04c2d7e1a03282e3015bfd6280019d4\nImplements: blueprint local-storage-volume-scheduling\n'}, {'number': 4, 'created': '2014-02-06 11:27:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/3902e976ff9705ca3b2a61ed2ec6fa156f49306b', 'message': 'scheduling for local storage\n\nIn some use case (e.g. hadoop cluster), we need create\nlocal volume in the same host in which vm instance was created.\n\n(cli version 2 example)\ncinder create [--hint instance_uuid=<instance_uuid>] size\n\nThis volume only can be attached the specific vm instance.\n\n(Restrictions)\ncinder-volume has to running in the computer server\nwhich want to be using local storage.\n\nDocImpact\n\nChange-Id: I472361c6e04c2d7e1a03282e3015bfd6280019d4\nImplements: blueprint local-storage-volume-scheduling\n'}, {'number': 5, 'created': '2014-02-06 11:48:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/2f6d68f198d5959879d98ea179a5a4a1de6540d2', 'message': 'scheduling for local storage\n\nIn some use case (e.g. hadoop cluster), we need create\nlocal volume in the same host in which vm instance was created.\n\n(cli version 2 example)\ncinder create [--hint instance_uuid=<instance_uuid>] size\n\nThis volume only can be attached the specific vm instance.\n\n(Restrictions)\ncinder-volume has to running in the computer server\nwhich want to be using local storage.\n\nDocImpact\n\nChange-Id: I472361c6e04c2d7e1a03282e3015bfd6280019d4\nImplements: blueprint local-storage-volume-scheduling\n'}, {'number': 6, 'created': '2014-02-13 06:19:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/7c2ecbdc47eddb1b58f0e246df734b828102dcfc', 'message': 'scheduling for local storage\n\nIn some use case (e.g. hadoop cluster), we need create\nlocal volume in the same host in which vm instance was created.\n\n(cli version 2 example)\ncinder create [--hint instance_uuid=<instance_uuid>] size\n\nThis volume only can be attached the specific vm instance.\n\nHintFilter has to be added in cinder.conf\n(cinder.conf)\nscheduler_default_filters=AvailabilityZoneFilter,CapacityFilter,\nCapabilitiesFilter,HintFilter\n\nfix hint bug to Cinder client.\nCinder code: https://review.openstack.org/#/c/72059/\n\n(Restrictions)\ncinder-volume has to running in the computer server\nwhich want to be using local storage.\n\nDocImpact\n\nChange-Id: I472361c6e04c2d7e1a03282e3015bfd6280019d4\nImplements: blueprint local-storage-volume-scheduling\n'}, {'number': 7, 'created': '2014-02-14 00:51:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/f3383937384f18da41e656366386817bd9f1e6da', 'message': 'scheduling for local storage\n\nIn some use case (e.g. hadoop cluster), we need create\nlocal volume in the same host in which vm instance was created.\nThis option is very useful for Hadoop Cluster.\n(e.g. Savannah Project, Self Services for Hadoop)\n\n(cli version 2 example)\ncinder create [--hint instance_uuid=<instance_uuid>] size\n\nHintFilter has to be added in cinder.conf\n(cinder.conf)\nscheduler_default_filters=AvailabilityZoneFilter,CapacityFilter,\nCapabilitiesFilter,HintFilter\n\nfix hint bug to Cinder client.\nCinder code: https://review.openstack.org/#/c/72059/\n\n(Restrictions)\ncinder-volume has to running in the computer server\nwhich want to be using local storage.\n\nDocImpact\n\nChange-Id: I472361c6e04c2d7e1a03282e3015bfd6280019d4\nImplements: blueprint local-storage-volume-scheduling\n'}, {'number': 8, 'created': '2014-02-14 06:28:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/bd9c21df151e981dcebede44ad984e9cd1b293e1', 'message': 'scheduling for local storage\n\nIn some use case (e.g. hadoop cluster), we need create\nlocal volume in the same host in which vm instance was created.\nThis option is very useful for Hadoop Cluster.\n(e.g. Savannah Project, Self Services for Hadoop)\n\n(cli version 2 example)\ncinder create [--hint instance_uuid=<instance_uuid>] size\n\nHintFilter has to be added in cinder.conf\n(cinder.conf)\nscheduler_default_filters=AvailabilityZoneFilter,CapacityFilter,\nCapabilitiesFilter,HintFilter\n\nfix hint bug to Cinder client.\nCinder code: https://review.openstack.org/#/c/72059/\n\n(Restrictions)\ncinder-volume has to running in the computer server\nwhich want to be using local storage.\n\nDocImpact\n\nChange-Id: I472361c6e04c2d7e1a03282e3015bfd6280019d4\nImplements: blueprint local-storage-volume-scheduling\n'}, {'number': 9, 'created': '2014-02-17 05:27:17.000000000', 'files': ['cinder/scheduler/filters/hint_filter.py', 'cinder/tests/scheduler/test_host_filters.py', 'cinder/tests/api/v2/stubs.py', 'cinder/volume/flows/api/create_volume.py', 'cinder/compute/nova.py', 'cinder/exception.py', '.mailmap', 'cinder/tests/test_create_volume_flow.py', 'setup.cfg'], 'web_link': 'https://opendev.org/openstack/cinder/commit/23500517af80d4d455a8a9eef58652561716ab57', 'message': 'scheduling for local storage\n\nIn some use case (e.g. hadoop cluster), we need create\nlocal volume in the same host in which vm instance was created.\nThis option is very useful for Hadoop Cluster.\n(e.g. Savannah Project, Self Services for Hadoop)\n\n(cli version 2 example)\ncinder create [--hint instance_uuid=<instance_uuid>] size\n\nHintFilter has to be added in cinder.conf\n(cinder.conf)\nscheduler_default_filters=AvailabilityZoneFilter,CapacityFilter,\nCapabilitiesFilter,HintFilter\n\nfix hint bug to Cinder client.\nCinder code: https://review.openstack.org/#/c/72059/\n\n(Restrictions)\ncinder-volume has to running in the computer server\nwhich want to be using local storage.\n\nDocImpact\n\nChange-Id: I472361c6e04c2d7e1a03282e3015bfd6280019d4\nImplements: blueprint local-storage-volume-scheduling\n'}]",20,66737,23500517af80d4d455a8a9eef58652561716ab57,49,7,9,8263,,,0,"scheduling for local storage

In some use case (e.g. hadoop cluster), we need create
local volume in the same host in which vm instance was created.
This option is very useful for Hadoop Cluster.
(e.g. Savannah Project, Self Services for Hadoop)

(cli version 2 example)
cinder create [--hint instance_uuid=<instance_uuid>] size

HintFilter has to be added in cinder.conf
(cinder.conf)
scheduler_default_filters=AvailabilityZoneFilter,CapacityFilter,
CapabilitiesFilter,HintFilter

fix hint bug to Cinder client.
Cinder code: https://review.openstack.org/#/c/72059/

(Restrictions)
cinder-volume has to running in the computer server
which want to be using local storage.

DocImpact

Change-Id: I472361c6e04c2d7e1a03282e3015bfd6280019d4
Implements: blueprint local-storage-volume-scheduling
",git fetch https://review.opendev.org/openstack/cinder refs/changes/37/66737/9 && git format-patch -1 --stdout FETCH_HEAD,"['cinder/tests/api/v2/stubs.py', 'cinder/volume/flows/create_volume/__init__.py', 'cinder/compute/nova.py', '.mailmap', 'cinder/tests/test_create_volume_flow.py']",5,7dd6eab086e09f1d4632a833c1c060005030d663,bp/local-storage-volume-scheduling,"from cinder import exceptionfrom cinder.tests.api.v2 import stubsclass fake_nova_api(object): def get_server(self, context, server): instance = stubs.stub_instance_create(self, context, None) if server == instance['uuid']: return instance else: return None props = {'scheduler_hints': {'instance_uuid': 'aaaaaaaa-aaaa-aaaa-aaaa-aaaaaaaaaaaa'}} task.nova_api = fake_nova_api() task._cast_create_volume(self.ctxt, spec, props) props = {'scheduler_hints': {'instance_uuid': 'a'}} self.assertRaises(exception.InstanceNotFound, task._cast_create_volume, self.ctxt, spec, props) props = {'scheduler_hints': None} task._cast_create_volume(self.ctxt, spec, props) props = {}",,75,1
openstack%2Fnova~master~Ida1f00259c4997f41584fb49bf89191bec83cc32,openstack/nova,master,Ida1f00259c4997f41584fb49bf89191bec83cc32,check if an image file is located on a NFS export,ABANDONED,2014-02-20 14:37:38.000000000,2014-03-06 06:03:05.000000000,,"[{'_account_id': 3}, {'_account_id': 167}, {'_account_id': 1779}, {'_account_id': 2271}, {'_account_id': 9578}]","[{'number': 1, 'created': '2014-02-20 14:37:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/5745de817b0cdb9dd159cc0cd292886436340763', 'message': ""check if an image file is located on a NFS export\n\nAt the moment a volume provided by the LibvirtNFSVolumeDriver\nis detected as a local disk by the method get_instance_disk_info.\n\nThis results in the exception InvalidSharedStorage when trying\nto initiate a live migration of an instance only using volumes\nprovided by the LibvirtNFSVolumeDriver.\n\nThis patch simply checks if an image is located on a NFS export\nand if that's the case it suggests that it's a volume.\n\nfixes bug #1282506\n\nChange-Id: Ida1f00259c4997f41584fb49bf89191bec83cc32\n""}, {'number': 2, 'created': '2014-02-21 07:51:03.000000000', 'files': ['nova/virt/libvirt/driver.py', 'etc/nova/rootwrap.d/compute.filters'], 'web_link': 'https://opendev.org/openstack/nova/commit/e9fb7082388ec4bac458e2cdb1d0519ed547322e', 'message': ""check if an image file is located on a NFS export\n\nAt the moment a volume provided by the LibvirtNFSVolumeDriver\nis detected as a local disk by the method get_instance_disk_info.\n\nThis results in the exception InvalidSharedStorage when trying\nto initiate a live migration of an instance only using volumes\nprovided by the LibvirtNFSVolumeDriver.\n\nThis patch simply checks if an image is located on a NFS export\nand if that's the case it suggests that it's a volume.\n\nfixes bug #1282506\n\nChange-Id: Ida1f00259c4997f41584fb49bf89191bec83cc32\n""}]",2,75051,e9fb7082388ec4bac458e2cdb1d0519ed547322e,15,5,2,167,,,0,"check if an image file is located on a NFS export

At the moment a volume provided by the LibvirtNFSVolumeDriver
is detected as a local disk by the method get_instance_disk_info.

This results in the exception InvalidSharedStorage when trying
to initiate a live migration of an instance only using volumes
provided by the LibvirtNFSVolumeDriver.

This patch simply checks if an image is located on a NFS export
and if that's the case it suggests that it's a volume.

fixes bug #1282506

Change-Id: Ida1f00259c4997f41584fb49bf89191bec83cc32
",git fetch https://review.opendev.org/openstack/nova refs/changes/51/75051/2 && git format-patch -1 --stdout FETCH_HEAD,"['nova/virt/libvirt/driver.py', 'etc/nova/rootwrap.d/compute.filters']",2,5745de817b0cdb9dd159cc0cd292886436340763,bug/1282506,"# nova/virt/libvirt/driver.py: stat: CommandFilter, stat, root",,9,0
openstack%2Ftrove~master~I2cdebe342e9a8c69444001e4265d0eb562675d08,openstack/trove,master,I2cdebe342e9a8c69444001e4265d0eb562675d08,The /var/lib/mongodb/* are removed during guest prepare(),ABANDONED,2014-02-25 01:38:48.000000000,2014-03-06 06:03:04.000000000,,"[{'_account_id': 3}, {'_account_id': 7092}, {'_account_id': 8136}, {'_account_id': 8214}, {'_account_id': 8415}]","[{'number': 1, 'created': '2014-02-25 01:38:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/trove/commit/f859000270c0e5212cfe679e2ffd8af44a499604', 'message': 'The /var/lib/mongodb/* are removed during guest prepare()\n\nInitial Baseline commit\nRight before the /var/lib/mongodb/* are to be migrated over to the\nvolume device and remounting the device on an empty /var/lib/mongodb\nhappens, the code now first deletes the contents of that dir so that\nrsync can finish faster(it needs to now sync only an empty dir!)\n. This is not a problem since mongod at the next startup will\nrecreate the prealloc files and other content in that dir if it\nfinds them missing.\n\nCloses-Bug: #1276863\nChange-Id: I2cdebe342e9a8c69444001e4265d0eb562675d08\n'}, {'number': 2, 'created': '2014-02-25 17:16:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/trove/commit/e40a9e8c9ad1e44433c8e875a47dfa4cf12690a1', 'message': 'The /var/lib/mongodb/* are removed during guest prepare()\n\nRight before the /var/lib/mongodb/* are to be migrated over to the\nvolume device and remounting the device on an empty /var/lib/mongodb\nhappens, the code now first deletes the contents of that dir so that\nrsync can finish faster(it needs to now sync only an empty dir!)\n. This is not a problem since mongod at the next startup will\nrecreate the prealloc files and other content in that dir if it\nfinds them missing.\n\nCloses-Bug: #1276863\nChange-Id: I2cdebe342e9a8c69444001e4265d0eb562675d08\n'}, {'number': 3, 'created': '2014-02-25 19:58:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/trove/commit/1b16c03fbec5769476f0ed38b4979a08726aa639', 'message': 'The /var/lib/mongodb/* are removed during guest prepare()\n\nRight before the /var/lib/mongodb/* are to be migrated over to the\nvolume device and remounting the device on an empty /var/lib/mongodb\nhappens, the code now first deletes the contents of that dir so that\nrsync can finish faster(it needs to now sync only an empty dir!)\n. This is not a problem since mongod at the next startup will\nrecreate the prealloc files and other content in that dir if it\nfinds them missing.\n\nCloses-Bug: #1276863\nChange-Id: I2cdebe342e9a8c69444001e4265d0eb562675d08\n'}, {'number': 4, 'created': '2014-02-25 20:54:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/trove/commit/2e2021577a9cae8209c9a8737da3b7b3de56442e', 'message': 'The /var/lib/mongodb/* are removed during guest prepare()\n\nRight before the /var/lib/mongodb/* are to be migrated over to the\nvolume device and remounting the device on an empty /var/lib/mongodb\nhappens, the code now first deletes the contents of that dir so that\nrsync can finish faster(it needs to now sync only an empty dir!).\nThis is not a problem since mongod at the next startup will\nrecreate the prealloc files and other content in that dir if it\nfinds them missing.\n\nCloses-Bug: #1276863\nChange-Id: I2cdebe342e9a8c69444001e4265d0eb562675d08\n'}, {'number': 5, 'created': '2014-02-26 01:02:45.000000000', 'files': ['trove/guestagent/datastore/mongodb/system.py', 'trove/guestagent/datastore/mongodb/manager.py', 'etc/trove/trove-guestagent.conf.sample', 'trove/tests/unittests/guestagent/test_manager.py', 'trove/common/cfg.py', 'etc/trove/trove-taskmanager.conf.sample'], 'web_link': 'https://opendev.org/openstack/trove/commit/466899cd3d3b90e6950d947160ae4ee58a2b4eff', 'message': 'The /var/lib/mongodb/* are removed during guest prepare()\n\nRight before the /var/lib/mongodb/* are to be migrated over to the\nvolume device and remounting the device on an empty /var/lib/mongodb\nhappens, the code now first deletes the contents of that dir so that\nrsync can finish faster(it needs to now sync only an empty dir!).\nThis is not a problem since mongod at the next startup will\nrecreate the prealloc files and other content in that dir if it\nfinds them missing.\n\nCloses-Bug: #1276863\nChange-Id: I2cdebe342e9a8c69444001e4265d0eb562675d08\n'}]",0,76066,466899cd3d3b90e6950d947160ae4ee58a2b4eff,34,5,5,8136,,,0,"The /var/lib/mongodb/* are removed during guest prepare()

Right before the /var/lib/mongodb/* are to be migrated over to the
volume device and remounting the device on an empty /var/lib/mongodb
happens, the code now first deletes the contents of that dir so that
rsync can finish faster(it needs to now sync only an empty dir!).
This is not a problem since mongod at the next startup will
recreate the prealloc files and other content in that dir if it
finds them missing.

Closes-Bug: #1276863
Change-Id: I2cdebe342e9a8c69444001e4265d0eb562675d08
",git fetch https://review.opendev.org/openstack/trove refs/changes/66/76066/1 && git format-patch -1 --stdout FETCH_HEAD,"['trove/guestagent/datastore/mongodb/service.py', 'trove/guestagent/datastore/mongodb/system.py', 'trove/guestagent/datastore/mongodb/manager.py', 'trove/guestagent/common/operating_system.py', 'trove/templates/mongodb/config.template', 'trove/templates/mongodb/heat.template', 'trove/guestagent/datastore/mongodb/__init__.py', 'trove/guestagent/dbaas.py', 'trove/tests/unittests/guestagent/test_manager.py', 'trove/tests/unittests/guestagent/test_dbaas.py', 'trove/common/cfg.py', 'trove/tests/unittests/common/test_template.py', 'trove/templates/mongodb/override.config.template']",13,f859000270c0e5212cfe679e2ffd8af44a499604,bug/1276863,,,932,73
openstack%2Ftrove~master~I818c604391238dbfe3298bf2fcd049dbdb8dcd3e,openstack/trove,master,I818c604391238dbfe3298bf2fcd049dbdb8dcd3e,use duck-typing instead of hasattr,ABANDONED,2014-02-19 12:44:10.000000000,2014-03-06 06:03:02.000000000,,"[{'_account_id': 3}, {'_account_id': 7092}, {'_account_id': 8214}, {'_account_id': 8415}]","[{'number': 1, 'created': '2014-02-19 12:44:10.000000000', 'files': ['trove/instance/models.py'], 'web_link': 'https://opendev.org/openstack/trove/commit/1190e5a1c2a2e989c27184e753bf9831f8044281', 'message': 'use duck-typing instead of hasattr\n\nChange-Id: I818c604391238dbfe3298bf2fcd049dbdb8dcd3e\n'}]",0,74691,1190e5a1c2a2e989c27184e753bf9831f8044281,10,4,1,2340,,,0,"use duck-typing instead of hasattr

Change-Id: I818c604391238dbfe3298bf2fcd049dbdb8dcd3e
",git fetch https://review.opendev.org/openstack/trove refs/changes/91/74691/1 && git format-patch -1 --stdout FETCH_HEAD,['trove/instance/models.py'],1,1190e5a1c2a2e989c27184e753bf9831f8044281,ducks, try: except AttributeError:," if hasattr(self.db_info, 'addresses'): else:",2,2
openstack%2Ftaskflow~master~I191fcef543aa0879913fd965ebef0496b0163336,openstack/taskflow,master,I191fcef543aa0879913fd965ebef0496b0163336,Rename uuid to topic,MERGED,2014-02-26 02:32:59.000000000,2014-03-06 06:01:51.000000000,2014-03-06 06:01:51.000000000,"[{'_account_id': 3}, {'_account_id': 6648}, {'_account_id': 7366}, {'_account_id': 8895}]","[{'number': 1, 'created': '2014-02-26 02:32:59.000000000', 'files': ['taskflow/engines/worker_based/server.py', 'taskflow/engines/worker_based/proxy.py', 'taskflow/tests/unit/worker_based/test_proxy.py', 'taskflow/tests/unit/worker_based/test_server.py'], 'web_link': 'https://opendev.org/openstack/taskflow/commit/92aa862b08f97ff04582cd52043c673c30f0f7e4', 'message': 'Rename uuid to topic\n\nThis appears to be the topic and not a uuid.\n\nChange-Id: I191fcef543aa0879913fd965ebef0496b0163336\n'}]",0,76414,92aa862b08f97ff04582cd52043c673c30f0f7e4,12,4,1,1297,,,0,"Rename uuid to topic

This appears to be the topic and not a uuid.

Change-Id: I191fcef543aa0879913fd965ebef0496b0163336
",git fetch https://review.opendev.org/openstack/taskflow refs/changes/14/76414/1 && git format-patch -1 --stdout FETCH_HEAD,"['taskflow/engines/worker_based/server.py', 'taskflow/engines/worker_based/proxy.py', 'taskflow/tests/unit/worker_based/test_proxy.py', 'taskflow/tests/unit/worker_based/test_server.py']",4,92aa862b08f97ff04582cd52043c673c30f0f7e4,," self.server_topic = 'server-topic' server_kwargs = dict(topic=self.server_topic, mock.call.Proxy(self.server_topic, self.server_exchange, mock.call.Proxy(self.server_topic, self.server_exchange,"," self.server_uuid = 'server-uuid' server_kwargs = dict(uuid=self.server_uuid, mock.call.Proxy(self.server_uuid, self.server_exchange, mock.call.Proxy(self.server_uuid, self.server_exchange,",15,15
openstack%2Ftaskflow~master~I092c69716f300b3ac95cc320c96243966eb982ba,openstack/taskflow,master,I092c69716f300b3ac95cc320c96243966eb982ba,Fixups for threads_count usage and logging,MERGED,2014-02-26 00:31:49.000000000,2014-03-06 06:01:25.000000000,2014-03-06 06:01:25.000000000,"[{'_account_id': 3}, {'_account_id': 1297}, {'_account_id': 7366}, {'_account_id': 8895}]","[{'number': 1, 'created': '2014-02-26 00:31:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/c675fefa4aeaf407a6adde3c4f4d905de388600a', 'message': 'Fixups for threads_count usage and logging\n\nIn the cases where threads_count is not applicable (when a\ncustom executor is provided) we should not log a message that\nsays the number of threads being used (since it will likely\nnot be an accurate message of what the provided executor is\nreally using).\n\nChange-Id: I092c69716f300b3ac95cc320c96243966eb982ba\n'}, {'number': 2, 'created': '2014-02-26 00:43:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/cc198704c3c90b42df76e80bc9f45fe17f6c475a', 'message': 'Fixups for threads_count usage and logging\n\nIn the cases where threads_count is not applicable (when a\ncustom executor is provided) we should not log a message that\nsays the number of threads being used (since it will likely\nnot be an accurate message of what the provided executor is\nreally using).\n\nChange-Id: I092c69716f300b3ac95cc320c96243966eb982ba\n'}, {'number': 3, 'created': '2014-02-26 00:45:29.000000000', 'files': ['taskflow/engines/worker_based/worker.py'], 'web_link': 'https://opendev.org/openstack/taskflow/commit/3b1aab64d28da7439bc8fb8e207d6f85df563048', 'message': 'Fixups for threads_count usage and logging\n\nIn the cases where threads_count is not applicable (when a\ncustom executor is provided) we should not log a message that\nsays the number of threads being used (since it will likely\nnot be an accurate message of what the provided executor is\nreally using).\n\nChange-Id: I092c69716f300b3ac95cc320c96243966eb982ba\n'}]",0,76400,3b1aab64d28da7439bc8fb8e207d6f85df563048,15,4,3,1297,,,0,"Fixups for threads_count usage and logging

In the cases where threads_count is not applicable (when a
custom executor is provided) we should not log a message that
says the number of threads being used (since it will likely
not be an accurate message of what the provided executor is
really using).

Change-Id: I092c69716f300b3ac95cc320c96243966eb982ba
",git fetch https://review.opendev.org/openstack/taskflow refs/changes/00/76400/2 && git format-patch -1 --stdout FETCH_HEAD,['taskflow/engines/worker_based/worker.py'],1,c675fefa4aeaf407a6adde3c4f4d905de388600a,,"# vim: tabstop=4 shiftwidth=4 softtabstop=4 self._threads_count = -1 if self._executor is None: if 'threads_count' in kwargs: self._threads_count = int(kwargs['threads_count']) if self._threads_count <= 0: raise ValueError(""threads_count provided must be > 0"") else: self._threads_count = tu.get_optimal_thread_count() if self._threads_count != -1: LOG.info(""Starting the '%s' topic worker in %s threads."", self._topic, self._threads_count) else: LOG.info(""Starting the '%s' topic worker using a %s."", self._topic, self._executor) LOG.info(""|-- %s"", endpoint)"," self._threads_count = kwargs.pop('threads_count', tu.get_optimal_thread_count()) if self._executor is None: LOG.info(""Starting the '%s' topic worker in %s threads."" % (self._topic, self._threads_count)) LOG.info(""|-- %s"" % endpoint)",16,5
openstack%2Fopenstack-manuals~master~Id952913729677078b47b276a37fc88734a9b2e3f,openstack/openstack-manuals,master,Id952913729677078b47b276a37fc88734a9b2e3f,Removed *.ini configuration steps from Glance chapter,MERGED,2014-03-06 00:50:26.000000000,2014-03-06 05:56:14.000000000,2014-03-06 05:56:13.000000000,"[{'_account_id': 3}, {'_account_id': 6843}, {'_account_id': 7923}, {'_account_id': 9162}]","[{'number': 1, 'created': '2014-03-06 00:50:26.000000000', 'files': ['doc/install-guide/section_glance-install.xml'], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/97a59d19101ac0c3d11e153dd91b3b19194c5d72', 'message': 'Removed *.ini configuration steps from Glance chapter\n\nI removed steps involving configuration of *.ini files since Glance\nin Icehouse no longer requires editing the latter.\n\nChange-Id: Id952913729677078b47b276a37fc88734a9b2e3f\nCloses-Bug: #1287895\n'}]",0,78484,97a59d19101ac0c3d11e153dd91b3b19194c5d72,8,4,1,9515,,,0,"Removed *.ini configuration steps from Glance chapter

I removed steps involving configuration of *.ini files since Glance
in Icehouse no longer requires editing the latter.

Change-Id: Id952913729677078b47b276a37fc88734a9b2e3f
Closes-Bug: #1287895
",git fetch https://review.opendev.org/openstack/openstack-manuals refs/changes/84/78484/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/install-guide/section_glance-install.xml'],1,97a59d19101ac0c3d11e153dd91b3b19194c5d72,bug/1287895,," <para>Add the credentials to the <filename>/etc/glance/glance-api-paste.ini</filename> and <filename>/etc/glance/glance-registry-paste.ini</filename> files.</para> <para os=""centos"">On CentOS, you may need to copy these files to the correct location.</para> <screen os=""centos""> <prompt>#</prompt> <userinput>cp /usr/share/glance/glance-api-dist-paste.ini /etc/glance/glance-api-paste.ini</userinput> <prompt>#</prompt> <userinput>cp /usr/share/glance/glance-registry-dist-paste.ini /etc/glance/glance-registry-paste.ini</userinput> </screen> <para>Edit each file to set the following options in the <literal>[filter:authtoken]</literal> section and leave any other existing option as it is.</para> <programlisting language=""ini"">[filter:authtoken] paste.filter_factory=keystoneclient.middleware.auth_token:filter_factory auth_host=controller admin_user=glance admin_tenant_name=service admin_password=<replaceable>GLANCE_PASS</replaceable></programlisting> </step> <step os=""rhel;centos;fedora;opensuse;sles;ubuntu"">",0,21
openstack%2Fdevstack-gate~master~I4496d3381a0d82ede20fad0b2693f770aa1e77e4,openstack/devstack-gate,master,I4496d3381a0d82ede20fad0b2693f770aa1e77e4,Enable q-fwaas service,ABANDONED,2013-12-05 04:53:58.000000000,2014-03-06 05:07:51.000000000,,"[{'_account_id': 1}, {'_account_id': 2}, {'_account_id': 3}, {'_account_id': 490}, {'_account_id': 4146}, {'_account_id': 5263}, {'_account_id': 5803}, {'_account_id': 6316}]","[{'number': 1, 'created': '2013-12-05 04:53:58.000000000', 'files': ['devstack-vm-gate.sh'], 'web_link': 'https://opendev.org/openstack/devstack-gate/commit/ceeb237b4591cacc82ad628f7e82455008cf042e', 'message': 'Enable q-fwaas service\n\nTo test neutron firewall api using devstack environment it is\nrecommended to enable q-fwaas service.\n\nChange-Id: I4496d3381a0d82ede20fad0b2693f770aa1e77e4\n'}]",2,60149,ceeb237b4591cacc82ad628f7e82455008cf042e,13,8,1,8205,,,0,"Enable q-fwaas service

To test neutron firewall api using devstack environment it is
recommended to enable q-fwaas service.

Change-Id: I4496d3381a0d82ede20fad0b2693f770aa1e77e4
",git fetch https://review.opendev.org/openstack/devstack-gate refs/changes/49/60149/1 && git format-patch -1 --stdout FETCH_HEAD,['devstack-vm-gate.sh'],1,ceeb237b4591cacc82ad628f7e82455008cf042e,," MY_ENABLED_SERVICES=$MY_ENABLED_SERVICES,quantum,q-svc,q-agt,q-dhcp,q-l3,q-meta,q-lbaas,q-vpn,q-fwaas MY_ENABLED_SERVICES=$MY_ENABLED_SERVICES,quantum,q-svc,q-agt,q-dhcp,q-l3,q-meta,q-lbaas,q-vpn,q-fwaas"," MY_ENABLED_SERVICES=$MY_ENABLED_SERVICES,quantum,q-svc,q-agt,q-dhcp,q-l3,q-meta,q-lbaas,q-vpn MY_ENABLED_SERVICES=$MY_ENABLED_SERVICES,quantum,q-svc,q-agt,q-dhcp,q-l3,q-meta,q-lbaas,q-vpn",2,2
openstack%2Fnova~master~I4fc8399c9a8b6a141ac489e8fb92117ec03ca42f,openstack/nova,master,I4fc8399c9a8b6a141ac489e8fb92117ec03ca42f,VMware: refactor _get_volume_uuid,MERGED,2014-02-11 14:19:01.000000000,2014-03-06 05:06:25.000000000,2014-03-06 01:44:27.000000000,"[{'_account_id': 3}, {'_account_id': 1653}, {'_account_id': 1779}, {'_account_id': 2271}, {'_account_id': 5170}, {'_account_id': 7400}, {'_account_id': 8027}, {'_account_id': 9008}, {'_account_id': 9172}, {'_account_id': 9555}, {'_account_id': 9578}]","[{'number': 1, 'created': '2014-02-11 14:19:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/9cd915cba64a6919f4affaa22df5cf74c332315c', 'message': 'VMware: refactor _get_volume_uuid\n\nIt is more efficient to ask vCenter for specific extraConfig property instead\ngetting all properties and then manually searching the one which is\nneeded.\n\nCloses-Bug: #1257726\nChange-Id: I4fc8399c9a8b6a141ac489e8fb92117ec03ca42f\n'}, {'number': 2, 'created': '2014-03-04 08:47:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/580ce48ced7c985660cab47097760e3230cc7256', 'message': 'VMware: refactor _get_volume_uuid\n\nIt is more efficient to ask vCenter for specific extraConfig property instead\ngetting all properties and then manually searching the one which is\nneeded.\n\nCloses-Bug: #1257726\nChange-Id: I4fc8399c9a8b6a141ac489e8fb92117ec03ca42f\n'}, {'number': 3, 'created': '2014-03-05 08:11:30.000000000', 'files': ['nova/virt/vmwareapi/volumeops.py', 'nova/virt/vmwareapi/fake.py', 'nova/tests/virt/vmwareapi/test_volumeops.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/b48bd3c0cf1f4ccfada24a6aebc7ced308d44927', 'message': 'VMware: refactor _get_volume_uuid\n\nIt is more efficient to ask vCenter for specific extraConfig property instead\ngetting all properties and then manually searching the one which is\nneeded.\n\nCloses-Bug: #1257726\nChange-Id: I4fc8399c9a8b6a141ac489e8fb92117ec03ca42f\n'}]",2,72663,b48bd3c0cf1f4ccfada24a6aebc7ced308d44927,52,11,3,9172,,,0,"VMware: refactor _get_volume_uuid

It is more efficient to ask vCenter for specific extraConfig property instead
getting all properties and then manually searching the one which is
needed.

Closes-Bug: #1257726
Change-Id: I4fc8399c9a8b6a141ac489e8fb92117ec03ca42f
",git fetch https://review.opendev.org/openstack/nova refs/changes/63/72663/1 && git format-patch -1 --stdout FETCH_HEAD,"['nova/virt/vmwareapi/volumeops.py', 'nova/virt/vmwareapi/fake.py', 'nova/tests/virt/vmwareapi/test_volumeops.py']",3,9cd915cba64a6919f4affaa22df5cf74c332315c,bug/1257726," def _fake_call_get_dynamic_property(self, uuid, result): def fake_call_method(vim, method, vm_ref, type, prop): expected_prop = 'config.extraConfig[""volume-%s""]' % uuid self.assertEqual('VirtualMachine', type) self.assertEqual(expected_prop, prop) return result return fake_call_method def test_get_volume_uuid(self): vm_ref = mock.Mock() uuid = '1234' opt_val = vmwareapi_fake.OptionValue('volume-%s' % uuid, 'volume-val') fake_call = self._fake_call_get_dynamic_property(uuid, opt_val) with mock.patch.object(self._session, ""_call_method"", fake_call): val = self._volumeops._get_volume_uuid(vm_ref, uuid) self.assertEqual('volume-val', val) def test_get_volume_uuid_not_found(self): vm_ref = mock.Mock() uuid = '1234' fake_call = self._fake_call_get_dynamic_property(uuid, None) with mock.patch.object(self._session, ""_call_method"", fake_call): val = self._volumeops._get_volume_uuid(vm_ref, uuid) self.assertIsNone(val)",,41,10
openstack%2Fsahara~master~I89ecb3ec8d39addf62481717b492a7ca1ace6d72,openstack/sahara,master,I89ecb3ec8d39addf62481717b492a7ca1ace6d72,[DO NOT MERGE] Test updated requests,ABANDONED,2014-03-05 14:41:50.000000000,2014-03-06 04:50:57.000000000,,"[{'_account_id': 3}, {'_account_id': 7213}]","[{'number': 1, 'created': '2014-03-05 14:41:50.000000000', 'files': ['requirements.txt'], 'web_link': 'https://opendev.org/openstack/sahara/commit/aeb8216c46aee9a37aa48223161a9fc720063ea3', 'message': '[DO NOT MERGE] Test updated requests\n\nChange-Id: I89ecb3ec8d39addf62481717b492a7ca1ace6d72\n'}]",0,78235,aeb8216c46aee9a37aa48223161a9fc720063ea3,5,2,1,6786,,,0,"[DO NOT MERGE] Test updated requests

Change-Id: I89ecb3ec8d39addf62481717b492a7ca1ace6d72
",git fetch https://review.opendev.org/openstack/sahara refs/changes/35/78235/1 && git format-patch -1 --stdout FETCH_HEAD,['requirements.txt'],1,aeb8216c46aee9a37aa48223161a9fc720063ea3,,requests>=2.1.0,requests>=1.1,1,1
openstack%2Fneutron~master~Iefa121b5c3a60ed804bf3927d91e64d843a28fd1,openstack/neutron,master,Iefa121b5c3a60ed804bf3927d91e64d843a28fd1,Adds the missing migration for gw_ext_mode,MERGED,2014-03-05 21:28:58.000000000,2014-03-06 04:49:09.000000000,2014-03-06 04:49:08.000000000,"[{'_account_id': 3}, {'_account_id': 105}, {'_account_id': 490}, {'_account_id': 1923}, {'_account_id': 5170}, {'_account_id': 9008}, {'_account_id': 9732}, {'_account_id': 9845}, {'_account_id': 10153}, {'_account_id': 10184}, {'_account_id': 10294}, {'_account_id': 10387}]","[{'number': 1, 'created': '2014-03-05 21:28:58.000000000', 'files': ['neutron/db/migration/alembic_migrations/versions/128e042a2b68_ext_gw_mode.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/c9226a858201a6c3691390259b46a643e8dc8b2f', 'message': 'Adds the missing migration for gw_ext_mode\n\nRequires adding the plugin to the script for\ndb migration for the ext_gw_mode in routers table.\n\nChange-Id: Iefa121b5c3a60ed804bf3927d91e64d843a28fd1\nCloses-Bug: #1288420\n'}]",0,78421,c9226a858201a6c3691390259b46a643e8dc8b2f,20,12,1,1923,,,0,"Adds the missing migration for gw_ext_mode

Requires adding the plugin to the script for
db migration for the ext_gw_mode in routers table.

Change-Id: Iefa121b5c3a60ed804bf3927d91e64d843a28fd1
Closes-Bug: #1288420
",git fetch https://review.opendev.org/openstack/neutron refs/changes/21/78421/1 && git format-patch -1 --stdout FETCH_HEAD,['neutron/db/migration/alembic_migrations/versions/128e042a2b68_ext_gw_mode.py'],1,c9226a858201a6c3691390259b46a643e8dc8b2f,sdnve_db_ext," 'neutron.plugins.embrane.plugins.embrane_ovs_plugin.EmbraneOvsPlugin', 'neutron.plugins.ibm.sdnve_neutron_plugin.SdnvePluginV2'", 'neutron.plugins.embrane.plugins.embrane_ovs_plugin.EmbraneOvsPlugin',2,1
openstack%2Fcinder~master~I0847d47cecdec8be2ade06d0ea944cc3fa6f476b,openstack/cinder,master,I0847d47cecdec8be2ade06d0ea944cc3fa6f476b,NetApp implementation for copy offload in clustered nfs driver,MERGED,2014-02-27 08:02:58.000000000,2014-03-06 04:49:01.000000000,2014-03-06 04:49:00.000000000,"[{'_account_id': 3}, {'_account_id': 170}, {'_account_id': 177}, {'_account_id': 2417}, {'_account_id': 2759}, {'_account_id': 6094}, {'_account_id': 9186}, {'_account_id': 9366}]","[{'number': 1, 'created': '2014-02-27 08:02:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/9199cb084d589940e6cc44c34264c7d60f53f56e', 'message': 'NetApp copy offload implementation for clustered nfs driver\n\nCopy offload is a special RPC implemented in Ontap that\nallows NFS clients to ask the server to copy data between\nvolumes in the same cluster efficiently. The special\nbinary will be developed by NetApp and distributed to its customers.\nIt will address two copy cases after efficient image clone failed.\nFirst when image cache file is present in a different share than\nthe one holding volume. Second when glance is backed by nfs share\nwhich is on the same cluster as nfs driver backend. Instead\nof regular http download the copy offload workflow will be used to copy\nimage to share and volume. Resubmitting it as there was a problem\nwith build in previous submission.\n\nChange-Id: I0847d47cecdec8be2ade06d0ea944cc3fa6f476b\nImplements: blueprint copyoffload\n'}, {'number': 2, 'created': '2014-02-27 08:06:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/2aef9d9a4b5bb74be61d7a4d197dc09cde638b74', 'message': 'NetApp copy offload implementation for clustered nfs driver\n\nCopy offload is a special RPC implemented in Ontap that\nallows NFS clients to ask the server to copy data between\nvolumes in the same cluster efficiently. The special\nbinary will be developed by NetApp and distributed to its customers.\nIt will address two copy cases after efficient image clone failed.\nFirst when image cache file is present in a different share than\nthe one holding volume. Second when glance is backed by nfs share\nwhich is on the same cluster as nfs driver backend. Instead\nof regular http download the copy offload workflow will be used to copy\nimage to share and volume. Resubmitting it as there was a problem\nwith build in previous submission.\n\nChange-Id: I0847d47cecdec8be2ade06d0ea944cc3fa6f476b\nImplements: blueprint copyoffload\n'}, {'number': 3, 'created': '2014-02-27 09:07:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/97f6ff715ff668f2f5d99df423e332a2d241391d', 'message': 'NetApp implementation for copy offload in for clustered nfs driver\n\nThe Copy offload binary is a special RPC implemented in Ontap that\nallows NFS clients to ask the server to copy data between\nvolumes in the same cluster efficiently. The special\nbinary will be developed by NetApp and distributed to its customers.\nIt will address two copy cases after efficient image clone failed.\nFirst when image cache file is present in a different share than\nthe one holding volume. Second when glance is backed by nfs share\nwhich is on the same cluster as nfs driver backend. Instead\nof regular http download the copy offload workflow will be used to copy\nimage to share and volume. Resubmitting it as there was a problem\nwith build in previous submission.\n\nChange-Id: I0847d47cecdec8be2ade06d0ea944cc3fa6f476b\nImplements: blueprint copyoffload\n'}, {'number': 4, 'created': '2014-02-27 09:08:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/231a01730b39449c14bfa06322d55920bfb8a851', 'message': 'NetApp implementation for copy offload in clustered nfs driver\n\nThe Copy offload binary is a special RPC implemented in Ontap that\nallows NFS clients to ask the server to copy data between\nvolumes in the same cluster efficiently. The special\nbinary will be developed by NetApp and distributed to its customers.\nIt will address two copy cases after efficient image clone failed.\nFirst when image cache file is present in a different share than\nthe one holding volume. Second when glance is backed by nfs share\nwhich is on the same cluster as nfs driver backend. Instead\nof regular http download the copy offload workflow will be used to copy\nimage to share and volume. Resubmitting it as there was a problem\nwith build in previous submission.\n\nChange-Id: I0847d47cecdec8be2ade06d0ea944cc3fa6f476b\nImplements: blueprint copyoffload\n'}, {'number': 5, 'created': '2014-02-27 17:22:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/c7324a61652488ca039d24de9f6bc02ffd1569dc', 'message': 'NetApp implementation for copy offload in clustered nfs driver\n\nThe Copy offload binary is a special RPC implemented in Ontap that\nallows NFS clients to ask the server to copy data between\nvolumes in the same cluster efficiently. The special\nbinary will be developed by NetApp and distributed to its customers.\nIt will address two copy cases after efficient image clone failed.\nFirst when image cache file is present in a different share than\nthe one holding volume. Second when glance is backed by nfs share\nwhich is on the same cluster as nfs driver backend. Instead\nof regular http download the copy offload workflow will be used to copy\nimage to share and volume. Resubmitting it as there was a problem\nwith build in previous submission.\n\nChange-Id: I0847d47cecdec8be2ade06d0ea944cc3fa6f476b\nImplements: blueprint copyoffload\n'}, {'number': 6, 'created': '2014-02-27 18:35:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/8ec92e241ab95b9c2f8d7412bcb77104edd5f97e', 'message': 'NetApp implementation for copy offload in clustered nfs driver\n\nThe Copy offload binary is a special RPC implemented in Ontap that\nallows NFS clients to ask the server to copy data between\nvolumes in the same cluster efficiently. The special\nbinary will be developed by NetApp and distributed to its customers.\nIt will address two copy cases after efficient image clone failed.\nFirst when image cache file is present in a different share than\nthe one holding volume. Second when glance is backed by nfs share\nwhich is on the same cluster as nfs driver backend. Instead\nof regular http download the copy offload workflow will be used to copy\nimage to share and volume. Resubmitting it as there was a problem\nwith build in previous submission.\n\nChange-Id: I0847d47cecdec8be2ade06d0ea944cc3fa6f476b\nImplements: blueprint copyoffload\n'}, {'number': 7, 'created': '2014-03-05 19:31:20.000000000', 'files': ['etc/cinder/cinder.conf.sample', 'cinder/tests/test_netapp_nfs.py', 'cinder/volume/drivers/netapp/nfs.py', 'cinder/volume/drivers/netapp/options.py'], 'web_link': 'https://opendev.org/openstack/cinder/commit/f888e412b0d0fdb0426045a9c55e0be0390f842c', 'message': 'NetApp implementation for copy offload in clustered nfs driver\n\nThe Copy offload binary is a special RPC implemented in Ontap that\nallows NFS clients to ask the server to copy data between\nvolumes in the same cluster efficiently. The special\nbinary will be developed by NetApp and distributed to its customers.\nIt will address two copy cases after efficient image clone failed.\nFirst when image cache file is present in a different share than\nthe one holding volume. Second when glance is backed by nfs share\nwhich is on the same cluster as nfs driver backend. Instead\nof regular http download the copy offload workflow will be used to copy\nimage to share and volume. Resubmitting it as there was a problem\nwith build in previous submission.\n\nChange-Id: I0847d47cecdec8be2ade06d0ea944cc3fa6f476b\nImplements: blueprint copyoffload\n'}]",3,76790,f888e412b0d0fdb0426045a9c55e0be0390f842c,37,8,7,6094,,,0,"NetApp implementation for copy offload in clustered nfs driver

The Copy offload binary is a special RPC implemented in Ontap that
allows NFS clients to ask the server to copy data between
volumes in the same cluster efficiently. The special
binary will be developed by NetApp and distributed to its customers.
It will address two copy cases after efficient image clone failed.
First when image cache file is present in a different share than
the one holding volume. Second when glance is backed by nfs share
which is on the same cluster as nfs driver backend. Instead
of regular http download the copy offload workflow will be used to copy
image to share and volume. Resubmitting it as there was a problem
with build in previous submission.

Change-Id: I0847d47cecdec8be2ade06d0ea944cc3fa6f476b
Implements: blueprint copyoffload
",git fetch https://review.opendev.org/openstack/cinder refs/changes/90/76790/7 && git format-patch -1 --stdout FETCH_HEAD,"['cinder/volume/drivers/netapp/utils.py', 'etc/cinder/cinder.conf.sample', 'cinder/tests/test_netapp_nfs.py', 'cinder/volume/drivers/netapp/nfs.py', 'cinder/volume/drivers/netapp/options.py']",5,9199cb084d589940e6cc44c34264c7d60f53f56e,bp/copyoffload,"netapp_nfs_extra_opts = [ cfg.StrOpt('netapp_copyoffload_tool_path', default=None, help=('This option specifies the path of the NetApp copy ' 'offload tool binary. Ensure that the binary has execute ' 'permissions set which allow the effective user of the ' 'cinder-volume process to execute the file.')), ] CONF.register_opts(netapp_nfs_extra_opts)",,446,35
openstack%2Fopenstack-manuals~stable%2Fhavana~Id952f146204feeeb732ac7f50e313fd96298a2cb,openstack/openstack-manuals,stable/havana,Id952f146204feeeb732ac7f50e313fd96298a2cb,"For Havana, these pom.xml files were causing an incorrect canonical url",MERGED,2014-03-06 03:19:02.000000000,2014-03-06 04:37:04.000000000,2014-03-06 04:37:03.000000000,"[{'_account_id': 3}, {'_account_id': 7472}, {'_account_id': 9515}]","[{'number': 1, 'created': '2014-03-06 03:19:02.000000000', 'files': ['doc/glossary/pom.xml', 'doc/admin-guide-cloud/pom.xml', 'doc/high-availability-guide/pom.xml', 'doc/security-guide/pom.xml', 'doc/training-guides/pom.xml', 'doc/config-reference/pom.xml'], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/6e9d3a5ab4eae8cf9b14362e8449211ce78f3e38', 'message': 'For Havana, these pom.xml files were causing an incorrect canonical url\n\nChange-Id: Id952f146204feeeb732ac7f50e313fd96298a2cb\nPartial-bug: 1288513\n'}]",0,78509,6e9d3a5ab4eae8cf9b14362e8449211ce78f3e38,7,3,1,964,,,0,"For Havana, these pom.xml files were causing an incorrect canonical url

Change-Id: Id952f146204feeeb732ac7f50e313fd96298a2cb
Partial-bug: 1288513
",git fetch https://review.opendev.org/openstack/openstack-manuals refs/changes/09/78509/1 && git format-patch -1 --stdout FETCH_HEAD,"['doc/glossary/pom.xml', 'doc/admin-guide-cloud/pom.xml', 'doc/high-availability-guide/pom.xml', 'doc/security-guide/pom.xml', 'doc/training-guides/pom.xml', 'doc/config-reference/pom.xml']",6,6e9d3a5ab4eae8cf9b14362e8449211ce78f3e38,bug/1288513, <canonicalUrlBase>http://docs.openstack.org/${release.path.name}/config-reference/content</canonicalUrlBase>, <canonicalUrlBase>http://docs.openstack.org/${release.path.name}/config-reference/content/</canonicalUrlBase>,6,6
openstack%2Fopenstack-manuals~master~I5f5ce9f0e4bf2e9541143f2a76b6a145d8794b2e,openstack/openstack-manuals,master,I5f5ce9f0e4bf2e9541143f2a76b6a145d8794b2e,All these pom.xml files were causing an incorrect canonical url,MERGED,2014-03-06 03:10:41.000000000,2014-03-06 04:01:34.000000000,2014-03-06 04:01:33.000000000,"[{'_account_id': 3}, {'_account_id': 964}, {'_account_id': 7472}, {'_account_id': 9515}]","[{'number': 1, 'created': '2014-03-06 03:10:41.000000000', 'files': ['doc/glossary/pom.xml', 'doc/admin-guide-cloud/pom.xml', 'doc/high-availability-guide/pom.xml', 'doc/security-guide/pom.xml', 'doc/image-guide/pom.xml', 'doc/user-guide-admin/pom.xml', 'doc/user-guide/pom.xml', 'doc/training-guides/pom.xml', 'doc/install-guide/pom.xml', 'doc/config-reference/pom.xml', 'doc/cli-reference/pom.xml'], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/4555b0edadeee56360852391c7a9ee5dd8ae4653', 'message': 'All these pom.xml files were causing an incorrect canonical url\n\nChange-Id: I5f5ce9f0e4bf2e9541143f2a76b6a145d8794b2e\nPartial-bug: 1288513\n'}]",0,78505,4555b0edadeee56360852391c7a9ee5dd8ae4653,8,4,1,964,,,0,"All these pom.xml files were causing an incorrect canonical url

Change-Id: I5f5ce9f0e4bf2e9541143f2a76b6a145d8794b2e
Partial-bug: 1288513
",git fetch https://review.opendev.org/openstack/openstack-manuals refs/changes/05/78505/1 && git format-patch -1 --stdout FETCH_HEAD,"['doc/glossary/pom.xml', 'doc/admin-guide-cloud/pom.xml', 'doc/high-availability-guide/pom.xml', 'doc/image-guide/pom.xml', 'doc/security-guide/pom.xml', 'doc/user-guide-admin/pom.xml', 'doc/user-guide/pom.xml', 'doc/training-guides/pom.xml', 'doc/install-guide/pom.xml', 'doc/config-reference/pom.xml', 'doc/cli-reference/pom.xml']",11,4555b0edadeee56360852391c7a9ee5dd8ae4653,bug/1288513, <canonicalUrlBase>http://docs.openstack.org/cli-reference/content</canonicalUrlBase>, <canonicalUrlBase>http://docs.openstack.org/cli-reference/content/</canonicalUrlBase>,11,11
openstack%2Fnova~master~I217f43227c099f17ab9a225b1ef7377d3de28114,openstack/nova,master,I217f43227c099f17ab9a225b1ef7377d3de28114,Ensure MTU is set when the OVS vif driver is used,MERGED,2013-12-15 09:16:03.000000000,2014-03-06 04:01:13.000000000,2014-01-22 15:20:57.000000000,"[{'_account_id': 3}, {'_account_id': 128}, {'_account_id': 642}, {'_account_id': 1653}, {'_account_id': 1779}, {'_account_id': 2271}, {'_account_id': 7040}, {'_account_id': 7102}, {'_account_id': 7730}, {'_account_id': 7823}, {'_account_id': 7909}, {'_account_id': 9008}, {'_account_id': 9578}]","[{'number': 1, 'created': '2013-12-15 09:16:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/b29886f57217320c0a74eadad5bcbbf1abc1a083', 'message': 'Ensure MTU is set when the OVS vif driver is used\n\nSet the MTU on the relevant devices when the OVS vif driver\nis used:\n    - veth devices\n    - ovs vif device\n\nChange-Id: I217f43227c099f17ab9a225b1ef7377d3de28114\nCloses-bug: 1260697\n'}, {'number': 2, 'created': '2014-01-02 18:08:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/677a8fd3adeaf17efaf160ac668fd7aa1320e1b1', 'message': 'Ensure MTU is set when the OVS vif driver is used\n\nSet the MTU on the relevant devices when the OVS vif driver\nis used:\n    - veth devices\n    - ovs vif device\n\nChange-Id: I217f43227c099f17ab9a225b1ef7377d3de28114\nCloses-bug: 1260697\n'}, {'number': 3, 'created': '2014-01-02 18:08:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/885718cd92c983dad84317affc6f77010892b65b', 'message': 'Ensure MTU is set when the OVS vif driver is used\n\nSet the MTU on the relevant devices when the OVS vif driver\nis used:\n    - veth devices\n    - ovs vif device\n\nChange-Id: I217f43227c099f17ab9a225b1ef7377d3de28114\nCloses-bug: 1260697\n'}, {'number': 4, 'created': '2014-01-19 12:33:09.000000000', 'files': ['nova/network/linux_net.py', 'nova/tests/network/test_linux_net.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/e34a085f7a524747dd93e9645c6e0e69631075d4', 'message': 'Ensure MTU is set when the OVS vif driver is used\n\nSet the MTU on the relevant devices when the OVS vif driver\nis used:\n    - veth devices\n    - ovs vif device\n\nChange-Id: I217f43227c099f17ab9a225b1ef7377d3de28114\nCloses-bug: 1260697\n'}]",1,62221,e34a085f7a524747dd93e9645c6e0e69631075d4,39,13,4,1653,,,0,"Ensure MTU is set when the OVS vif driver is used

Set the MTU on the relevant devices when the OVS vif driver
is used:
    - veth devices
    - ovs vif device

Change-Id: I217f43227c099f17ab9a225b1ef7377d3de28114
Closes-bug: 1260697
",git fetch https://review.opendev.org/openstack/nova refs/changes/21/62221/4 && git format-patch -1 --stdout FETCH_HEAD,"['nova/network/linux_net.py', 'nova/tests/network/test_linux_net.py']",2,b29886f57217320c0a74eadad5bcbbf1abc1a083,bug/1260697," def _ovs_vif_port(self, calls): with mock.patch.object(utils, 'execute', return_value=('', '')) as ex: linux_net.create_ovs_vif_port('fake-bridge', 'fake-dev', 'fake-iface-id', 'fake-mac', 'fake-instance-uuid') ex.assert_has_calls(calls) def test_ovs_vif_port(self): calls = [ mock.call('ovs-vsctl', '--', '--may-exist', 'add-port', 'fake-bridge', 'fake-dev', '--', 'set', 'Interface', 'fake-dev', 'external-ids:iface-id=fake-iface-id', 'external-ids:iface-status=active', 'external-ids:attached-mac=fake-mac', 'external-ids:vm-uuid=fake-instance-uuid', run_as_root=True) ] self._ovs_vif_port(calls) def test_ovs_vif_port_with_mtu(self): self.flags(network_device_mtu=10000) calls = [ mock.call('ovs-vsctl', '--', '--may-exist', 'add-port', 'fake-bridge', 'fake-dev', '--', 'set', 'Interface', 'fake-dev', 'external-ids:iface-id=fake-iface-id', 'external-ids:iface-status=active', 'external-ids:attached-mac=fake-mac', 'external-ids:vm-uuid=fake-instance-uuid', run_as_root=True), mock.call('ip', 'link', 'set', 'fake-dev', 'mtu', 10000, run_as_root=True, check_exit_code=[0, 2, 254]) ] self._ovs_vif_port(calls) def _create_veth_pair(self, calls): with mock.patch.object(utils, 'execute', return_value=('', '')) as ex: linux_net._create_veth_pair('fake-dev1', 'fake-dev2') ex.assert_has_calls(calls) def test_create_veth_pair(self): calls = [ mock.call('ip', 'link', 'delete', 'fake-dev1', run_as_root=True, check_exit_code=[0, 2, 254]), mock.call('ip', 'link', 'delete', 'fake-dev2', run_as_root=True, check_exit_code=[0, 2, 254]), mock.call('ip', 'link', 'add', 'fake-dev1', 'type', 'veth', 'peer', 'name', 'fake-dev2', run_as_root=True), mock.call('ip', 'link', 'set', 'fake-dev1', 'up', run_as_root=True), mock.call('ip', 'link', 'set', 'fake-dev1', 'promisc', 'on', run_as_root=True), mock.call('ip', 'link', 'set', 'fake-dev2', 'up', run_as_root=True), mock.call('ip', 'link', 'set', 'fake-dev2', 'promisc', 'on', run_as_root=True) ] self._create_veth_pair(calls) def test_create_veth_pair_with_mtu(self): self.flags(network_device_mtu=10000) calls = [ mock.call('ip', 'link', 'delete', 'fake-dev1', run_as_root=True, check_exit_code=[0, 2, 254]), mock.call('ip', 'link', 'delete', 'fake-dev2', run_as_root=True, check_exit_code=[0, 2, 254]), mock.call('ip', 'link', 'add', 'fake-dev1', 'type', 'veth', 'peer', 'name', 'fake-dev2', run_as_root=True), mock.call('ip', 'link', 'set', 'fake-dev1', 'up', run_as_root=True), mock.call('ip', 'link', 'set', 'fake-dev1', 'promisc', 'on', run_as_root=True), mock.call('ip', 'link', 'set', 'fake-dev1', 'mtu', 10000, run_as_root=True, check_exit_code=[0, 2, 254]), mock.call('ip', 'link', 'set', 'fake-dev2', 'up', run_as_root=True), mock.call('ip', 'link', 'set', 'fake-dev2', 'promisc', 'on', run_as_root=True), mock.call('ip', 'link', 'set', 'fake-dev2', 'mtu', 10000, run_as_root=True, check_exit_code=[0, 2, 254]) ] self._create_veth_pair(calls)",,97,1
openstack%2Fneutron~master~I39b1475c992b594256f5a28be0caa1ee9398050e,openstack/neutron,master,I39b1475c992b594256f5a28be0caa1ee9398050e,VPNaaS Service Driver for Cisco CSR,MERGED,2014-02-17 20:08:07.000000000,2014-03-06 03:59:30.000000000,2014-03-06 03:59:29.000000000,"[{'_account_id': 3}, {'_account_id': 105}, {'_account_id': 107}, {'_account_id': 748}, {'_account_id': 841}, {'_account_id': 2031}, {'_account_id': 2592}, {'_account_id': 4395}, {'_account_id': 5170}, {'_account_id': 6524}, {'_account_id': 6659}, {'_account_id': 7317}, {'_account_id': 9008}, {'_account_id': 9681}, {'_account_id': 9682}, {'_account_id': 9732}, {'_account_id': 9787}, {'_account_id': 9845}, {'_account_id': 9925}, {'_account_id': 10116}, {'_account_id': 10117}, {'_account_id': 10119}, {'_account_id': 10153}, {'_account_id': 10184}, {'_account_id': 10192}, {'_account_id': 10294}, {'_account_id': 10387}]","[{'number': 1, 'created': '2014-02-17 20:08:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/4861a4150c0f67d961d1f9a030fb5f88a29dac29', 'message': ""VPNaaS Service Driver for Cisco CSR\n\nThis has the service driver part of the vendor specific VPNaaS plugin.\nThe changes rely on the Service Type Framework code, which is presently\nunder review (client 53602, server 41827). The device driver will be\nunder a separate review.\n\nThere is some test code commented out, until device driver support is\nin place (a later enhancement planned - didn't want to loose the change).\n\nWith this set, there is currently a problem with TOX runs and some of\nthe unit tests that exercise a database table.\n\nChange-Id: I39b1475c992b594256f5a28be0caa1ee9398050e\nPartially-implements: blueprint vpnaas-cisco-driver\n""}, {'number': 2, 'created': '2014-02-18 20:42:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/1d7550cdeb6ab9d61faace7eef92f98b5c2cde06', 'message': ""VPNaaS Service Driver for Cisco CSR\n\nThis has the service driver part of the vendor specific VPNaaS plugin.\nThe changes rely on the Service Type Framework code, which is presently\nunder review (client 53602, server 41827). The device driver will be\nunder a separate review.\n\nThere is some test code commented out, until device driver support is\nin place (a later enhancement planned - didn't want to loose the change).\n\nChange-Id: I39b1475c992b594256f5a28be0caa1ee9398050e\nPartially-implements: blueprint vpnaas-cisco-driver\n""}, {'number': 3, 'created': '2014-02-20 14:24:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/5b0ad705343549b91ded8dd15110a86350b05c4a', 'message': ""VPNaaS Service Driver for Cisco CSR\n\nThis has the service driver part of the vendor specific VPNaaS plugin.\nThe changes rely on the Service Type Framework code, which is presently\nunder review (client 53602, server 41827). The device driver will be\nunder a separate review.\n\nThere is some test code commented out, until device driver support is\nin place (a later enhancement planned - didn't want to loose the change).\n\nRev 2 has fixes for tox errors.\nRev 3 will be a rebase to get latest 41827 changes.\n\nChange-Id: I39b1475c992b594256f5a28be0caa1ee9398050e\nPartially-implements: blueprint vpnaas-cisco-driver\n""}, {'number': 4, 'created': '2014-02-21 12:20:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/d04accf252155afaceb4cded7945a55b28f31466', 'message': 'VPNaaS Service Driver for Cisco CSR\n\nThis has the service driver part of the vendor specific VPNaaS plugin.\nThe changes rely on the Service Type Framework code, which is presently\nunder review (client 53602, server 41827). The device driver will be\nunder a separate review.\n\nNote: The Cisco plugin will require an out-of-band CSR setup and\n      running for operation.\n\nRev 2 has fixes for tox errors.\nRev 3 has rebase to get latest 41827 changes.\nRev 4 has code review comments, moving vendor config file chgs to 74156\n      review.\n\nChange-Id: I39b1475c992b594256f5a28be0caa1ee9398050e\nPartially-implements: blueprint vpnaas-cisco-driver\n'}, {'number': 5, 'created': '2014-02-22 15:07:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/d01544132e28bcac969068cdb00076810aeb2ffc', 'message': 'VPNaaS Service Driver for Cisco CSR\n\nThis has the service driver part of the vendor specific VPNaaS plugin.\nThe changes rely on the Service Type Framework code, which is presently\nunder review (client 53602, server 41827). The device driver will be\nunder a separate review.\n\nNote: The Cisco plugin will require an out-of-band CSR setup and\n      running for operation.\n\nRev 2 has fixes for tox errors.\nRev 3 has rebase to get latest 41827 changes.\nRev 4 has code review comments, moving vendor config file chgs to 74156\n      review.\nRev 5 (temp) selects Cisco service driver so UTs run with that driver.\n\nChange-Id: I39b1475c992b594256f5a28be0caa1ee9398050e\nPartially-implements: blueprint vpnaas-cisco-driver\n'}, {'number': 6, 'created': '2014-02-22 16:20:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/2507023af4e96655f580d07c2dc00c9f8e8df0d5', 'message': 'VPNaaS Service Driver for Cisco CSR\n\nThis has the service driver part of the vendor specific VPNaaS plugin.\nThe changes rely on the Service Type Framework code, which is presently\nunder review (client 53602, server 41827). The device driver will be\nunder a separate review.\n\nNote: The Cisco plugin will require an out-of-band CSR setup and\n      running for operation.\n\nRev 2 has fixes for tox errors.\nRev 3 has rebase to get latest 41827 changes.\nRev 4 has code review comments, moving vendor config file chgs to 74156\n      review.\nRev 5 (temp) selects Cisco service driver so UTs run with that driver.\nRev 6 (temp) fixed last commit so that the Cisco SERVICE driver is\n      enabled and not the DEVICE driver.\n\nChange-Id: I39b1475c992b594256f5a28be0caa1ee9398050e\nPartially-implements: blueprint vpnaas-cisco-driver\n'}, {'number': 7, 'created': '2014-02-22 16:53:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/313e2d79d9186fcd11154fedd4309372c1a7910d', 'message': 'VPNaaS Service Driver for Cisco CSR\n\nThis has the service driver part of the vendor specific VPNaaS plugin.\nThe changes rely on the Service Type Framework code, which is presently\nunder review (client 53602, server 41827). The device driver will be\nunder a separate review.\n\nNote: The Cisco plugin will require an out-of-band CSR setup and\n      running for operation.\n\nRev 2 has fixes for tox errors.\nRev 3 has rebase to get latest 41827 changes.\nRev 4 has code review comments, moving vendor config file chgs to 74156\n      review.\nRev 5 (temp) selects Cisco service driver so UTs run with that driver.\nRev 6 (temp) fixed last commit so that the Cisco SERVICE driver is\n      enabled and not the DEVICE driver.\nRev 7 Updated down revision.\n\nChange-Id: I39b1475c992b594256f5a28be0caa1ee9398050e\nPartially-implements: blueprint vpnaas-cisco-driver\n'}, {'number': 8, 'created': '2014-02-24 23:13:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/e9f2989c51d474fe8808b5e9ceecdb692fe8c415', 'message': 'VPNaaS Service Driver for Cisco CSR\n\nThis has the service driver part of the vendor specific VPNaaS plugin.\nThe changes rely on the Service Type Framework code, which is presently\nunder review (client 53602, server 41827). The device driver will be\nunder a separate review.\n\nNote: The Cisco plugin will require an out-of-band CSR setup and\n      running for operation.\n\nNote: See review 74156 for more details on device driver portion of\n      this blueprint.\n\nChange-Id: I39b1475c992b594256f5a28be0caa1ee9398050e\nPartially-implements: blueprint vpnaas-cisco-driver\n'}, {'number': 9, 'created': '2014-02-25 04:23:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/f3c6c0fec697c31ca3f58b35b44309bc2e7cf890', 'message': 'VPNaaS Service Driver for Cisco CSR\n\nThis has the service driver part of the vendor specific VPNaaS plugin.\nThe changes rely on the Service Type Framework code, which is presently\nunder review (client 53602, server 41827). The device driver will be\nunder a separate review.\n\nNote: The Cisco plugin will require an out-of-band CSR setup and\n      running for operation.\n\nNote: See review 74156 for more details on device driver portion of\n      this blueprint.\n\nChange-Id: I39b1475c992b594256f5a28be0caa1ee9398050e\nPartially-implements: blueprint vpnaas-cisco-driver\n'}, {'number': 10, 'created': '2014-02-25 19:43:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/1e45bcd06b2c476107891db3c523dc430c073ac7', 'message': 'VPNaaS Service Driver for Cisco CSR\n\nThis has the service driver part of the vendor specific VPNaaS plugin.\nThe changes rely on the Service Type Framework code, which is presently\nunder review (client 53602, server 41827). The device driver will be\nunder a separate review.\n\nNote: The Cisco plugin will require an out-of-band CSR setup and\n      running for operation.\n\nNote: See review 74156 for more details on device driver portion of\n      this blueprint.\n\nChange-Id: I39b1475c992b594256f5a28be0caa1ee9398050e\nPartially-implements: blueprint vpnaas-cisco-driver\n'}, {'number': 11, 'created': '2014-02-26 02:16:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/0f59717102c34962895f554d9ff713beefefce16', 'message': 'VPNaaS Service Driver for Cisco CSR\n\nThis has the service driver part of the vendor specific VPNaaS plugin.\nThe changes rely on the Service Type Framework code, which is presently\nunder review (client 53602, server 41827). The device driver will be\nunder a separate review.\n\nNote: The Cisco plugin will require an out-of-band CSR setup and\n      running for operation.\n\nNote: See review 74156 for more details on device driver portion of\n      this blueprint.\n\nChange-Id: I39b1475c992b594256f5a28be0caa1ee9398050e\nPartially-implements: blueprint vpnaas-cisco-driver\n'}, {'number': 12, 'created': '2014-02-26 02:58:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/8eeec332e8cb35e498dd84278a10e39c49c051fe', 'message': 'VPNaaS Service Driver for Cisco CSR\n\nThis has the service driver part of the vendor specific VPNaaS plugin.\nThe changes rely on the Service Type Framework code, which is presently\nunder review (client 53602, server 41827). The device driver will be\nunder a separate review.\n\nNote: The Cisco plugin will require an out-of-band CSR setup and\n      running for operation.\n\nNote: See review 74156 for more details on device driver portion of\n      this blueprint.\n\nChange-Id: I39b1475c992b594256f5a28be0caa1ee9398050e\nPartially-implements: blueprint vpnaas-cisco-driver\n'}, {'number': 13, 'created': '2014-02-26 15:05:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/3f7751dff351cbc44b0d24d22ac4c1f00214d102', 'message': 'VPNaaS Service Driver for Cisco CSR\n\nThis has the service driver part of the vendor specific VPNaaS plugin.\nThe changes rely on the Service Type Framework code, which is presently\nunder review (client 53602, server 41827). The device driver will be\nunder a separate review.\n\nNote: The Cisco plugin will require an out-of-band CSR setup and\n      running for operation.\n\nNote: See review 74156 for more details on device driver portion of\n      this blueprint.\n\nChange-Id: I39b1475c992b594256f5a28be0caa1ee9398050e\nPartially-implements: blueprint vpnaas-cisco-driver\n'}, {'number': 14, 'created': '2014-02-27 18:31:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/8029e386ed5276a4d9a3b924aebd1839d71070a9', 'message': 'VPNaaS Service Driver for Cisco CSR\n\nThis has the service driver part of the vendor specific VPNaaS plugin.\nThe changes rely on the Service Type Framework code, which is presently\nunder review (client 53602, server 41827). The device driver will be\nunder a separate review.\n\nNote: The Cisco plugin will require an out-of-band CSR setup and\n      running for operation.\n\nNote: See review 74156 for more details on device driver portion of\n      this blueprint.\n\nChange-Id: I39b1475c992b594256f5a28be0caa1ee9398050e\nPartially-implements: blueprint vpnaas-cisco-driver\n'}, {'number': 15, 'created': '2014-02-27 19:22:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/3ed77026298a78bd4338ee7db7301e979e807e6c', 'message': 'VPNaaS Service Driver for Cisco CSR\n\nThis has the service driver part of the vendor specific VPNaaS plugin.\nThe changes rely on the Service Type Framework code, which is presently\nunder review (client 53602, server 41827). The device driver will be\nunder a separate review.\n\nNote: The Cisco plugin will require an out-of-band CSR setup and\n      running for operation.\n\nNote: See review 74156 for more details on device driver portion of\n      this blueprint.\n\nChange-Id: I39b1475c992b594256f5a28be0caa1ee9398050e\nPartially-implements: blueprint vpnaas-cisco-driver\n'}, {'number': 16, 'created': '2014-03-01 23:28:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/96191b048f2bb970ef3fa0679a6957e3fc29fb79', 'message': 'VPNaaS Service Driver for Cisco CSR\n\nThis has the service driver part of the vendor specific VPNaaS plugin.\nThe changes rely on the Service Type Framework code, which is presently\nunder review (client 53602, server 41827). The device driver will be\nunder a separate review.\n\nNote: The Cisco plugin will require an out-of-band CSR setup and\n      running for operation.\n\nNote: See review 74156 for more details on device driver portion of\n      this blueprint.\n\nChange-Id: I39b1475c992b594256f5a28be0caa1ee9398050e\nPartially-implements: blueprint vpnaas-cisco-driver\n'}, {'number': 17, 'created': '2014-03-03 16:18:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/e9ca2a95a380914cd3bfed6645e41fff5ebd897c', 'message': 'VPNaaS Service Driver for Cisco CSR\n\nThis has the service driver part of the vendor specific VPNaaS plugin.\nThe changes rely on the Service Type Framework code, which is presently\nunder review (client 53602, server 41827). The device driver will be\nunder a separate review.\n\nNote: The Cisco plugin will require an out-of-band CSR setup and\n      running for operation.\n\nNote: See review 74156 for more details on device driver portion of\n      this blueprint.\n\nChange-Id: I39b1475c992b594256f5a28be0caa1ee9398050e\nPartially-implements: blueprint vpnaas-cisco-driver\n'}, {'number': 18, 'created': '2014-03-03 18:08:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/92d9f896597be52d2f8dfdd1393c54613e44e25b', 'message': 'VPNaaS Service Driver for Cisco CSR\n\nThis has the service driver part of the vendor specific VPNaaS plugin.\nThe changes rely on the Service Type Framework code, which is presently\nunder review (client 53602, server 41827). The device driver will be\nunder a separate review.\n\nNote: The Cisco plugin will require an out-of-band CSR setup and\n      running for operation.\n\nNote: See review 74156 for more details on device driver portion of\n      this blueprint.\n\nChange-Id: I39b1475c992b594256f5a28be0caa1ee9398050e\nPartially-implements: blueprint vpnaas-cisco-driver\n'}, {'number': 19, 'created': '2014-03-03 21:03:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/5cdc83cb0a00fcaab6891a3b5229a5ebeb041e72', 'message': 'VPNaaS Service Driver for Cisco CSR\n\nThis has the service driver part of the vendor specific VPNaaS plugin.\nThis version DOES NOT rely on the Service Type Framework code, which is\npresently under review (client 53602, server 41827) and on hold due to\ndiscussion over flavors. As a result, this changeset has modifications\nso that the service driver is not hard-coded in the VPN plugin.\n\nThe device driver will be under a separate review and has the REST\nclient that talks to the Cisco CSR (running out-of-band).\n\nNote: See review 74156 for more details on device driver portion of\n      this blueprint.\n\nChange-Id: I39b1475c992b594256f5a28be0caa1ee9398050e\nPartially-implements: blueprint vpnaas-cisco-driver\n'}, {'number': 20, 'created': '2014-03-04 05:23:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/b3100951c83f9e66995e02d00c34fa956407cb24', 'message': 'VPNaaS Service Driver for Cisco CSR\n\nISSUE: I am currently unable to get UT to pass, with changes to the\nplugin.py that loads the service driver from neutron.conf. With the\ncurrently commented out code enabled, tests fail (even just the tests\nfor reference code!). If someone has ideas on how to resolve the\nservice driver plugin loading (or why there is a test interaction\nbetween test_vpnaas_driver_plugin.py and the service driver tests),\nplease let me know. If STF is used, or the service driver is hard\ncoded to the reference driver, it passes all tests. As it stands now,\nthough, the Cisco service driver cannot be loaded.\n\nPosted the code as is, in case someone sees what is wrong with plugin.py\n\nThis has the service driver part of the vendor specific VPNaaS plugin.\nThis version DOES NOT rely on the Service Type Framework code, which is\npresently under review (client 53602, server 41827) and on hold due to\ndiscussion over flavors. As a result, this changeset has modifications\nso that the service driver is not hard-coded in the VPN plugin.\n\nThe device driver will be under a separate review and has the REST\nclient that talks to the Cisco CSR (running out-of-band).\n\nNote: See review 74156 for more details on device driver portion of\n      this blueprint.\n\nChange-Id: I39b1475c992b594256f5a28be0caa1ee9398050e\nPartially-implements: blueprint vpnaas-cisco-driver\n'}, {'number': 21, 'created': '2014-03-04 17:13:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/1a987ed871c705aa34d17f26e25321388fecda95', 'message': 'VPNaaS Service Driver for Cisco CSR\n\nThis has the service driver part of the vendor specific VPNaaS plugin.\nThis version DOES NOT rely on the Service Type Framework code, which is\npresently under review (client 53602, server 41827) and on hold due to\ndiscussion over flavors. As a result, this changeset has modifications\nso that the service driver is not hard-coded in the VPN plugin.\n\nNote: There is a test interaction between LB and VPN, where VPN sets up\nconfig, and before the VPN plugin is started, LB has changed the config\nthat the Service Type Manager (used to parse out the service drivers)\nloads. Since the STM is a singleton, the tests run in parallel, and\nNeutron loads LB before VPN plugin, I suspect LB is always winning the\nrace war, when there is one. The workaround is to have the VPN plugin\nforce the re-parsing of config, at startup.\n\nThe device driver will be under a separate review and has the REST\nclient that talks to the Cisco CSR (running out-of-band).\n\nNote: See review 74156 for more details on device driver portion of\n      this blueprint.\n\nChange-Id: I39b1475c992b594256f5a28be0caa1ee9398050e\nPartially-implements: blueprint vpnaas-cisco-driver\n'}, {'number': 22, 'created': '2014-03-05 02:07:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/c8c9cb5f8c2ba547265b4812abe6a0da2a90ee49', 'message': 'VPNaaS Service Driver for Cisco CSR\n\nThis has the service driver part of the vendor specific VPNaaS plugin.\nThis version DOES NOT rely on the Service Type Framework code, which is\npresently under review (client 53602, server 41827) and on hold due to\ndiscussion over flavors. As a result, this changeset has modifications\nso that the service driver is not hard-coded in the VPN plugin.\n\nThe device driver will be under a separate review and has the REST\nclient that talks to the Cisco CSR (running out-of-band).\n\nNote: See review 74156 for more details on device driver portion of\n      this blueprint.\n\nChange-Id: I39b1475c992b594256f5a28be0caa1ee9398050e\nPartially-implements: blueprint vpnaas-cisco-driver\n'}, {'number': 23, 'created': '2014-03-05 19:39:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/63f536eecdebf662e0bb17a3ea44c746d9492852', 'message': 'VPNaaS Service Driver for Cisco CSR\n\nThis has the service driver part of the vendor specific VPNaaS plugin.\nThis version DOES NOT rely on the Service Type Framework code, which is\npresently under review (client 53602, server 41827) and on hold due to\ndiscussion over flavors. As a result, this changeset has modifications\nso that the service driver is not hard-coded in the VPN plugin.\n\nThe device driver will be under a separate review and has the REST\nclient that talks to the Cisco CSR (running out-of-band).\n\nNote: See review 74156 for more details on device driver portion of\n      this blueprint.\n\nChange-Id: I39b1475c992b594256f5a28be0caa1ee9398050e\nPartially-implements: blueprint vpnaas-cisco-driver\n'}, {'number': 24, 'created': '2014-03-06 00:01:03.000000000', 'files': ['etc/neutron.conf', 'neutron/db/vpn/vpn_db.py', 'neutron/services/vpn/common/topics.py', 'etc/vpn_agent.ini', 'neutron/tests/unit/db/vpn/test_db_vpnaas.py', 'neutron/services/vpn/service_drivers/__init__.py', 'neutron/services/vpn/service_drivers/cisco_csr_db.py', 'neutron/services/vpn/plugin.py', 'neutron/tests/unit/services/vpn/service_drivers/test_cisco_ipsec.py', 'neutron/db/migration/alembic_migrations/versions/24c7ea5160d7_cisco_csr_vpnaas.py', 'neutron/services/vpn/service_drivers/cisco_ipsec.py', 'neutron/services/vpn/service_drivers/ipsec.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/8a1d02194324ac564c060412d85e924f5dc86a89', 'message': 'VPNaaS Service Driver for Cisco CSR\n\nThis has the service driver part of the vendor specific VPNaaS plugin.\nThis version DOES NOT rely on the Service Type Framework code, which is\npresently under review (client 53602, server 41827) and on hold due to\ndiscussion over flavors. As a result, this changeset has modifications\nso that the service driver is not hard-coded in the VPN plugin.\n\nThe device driver will be under a separate review and has the REST\nclient that talks to the Cisco CSR (running out-of-band).\n\nNote: See review 74156 for more details on device driver portion of\n      this blueprint.\n\nChange-Id: I39b1475c992b594256f5a28be0caa1ee9398050e\nPartially-implements: blueprint vpnaas-cisco-driver\n'}]",104,74144,8a1d02194324ac564c060412d85e924f5dc86a89,387,27,24,6659,,,0,"VPNaaS Service Driver for Cisco CSR

This has the service driver part of the vendor specific VPNaaS plugin.
This version DOES NOT rely on the Service Type Framework code, which is
presently under review (client 53602, server 41827) and on hold due to
discussion over flavors. As a result, this changeset has modifications
so that the service driver is not hard-coded in the VPN plugin.

The device driver will be under a separate review and has the REST
client that talks to the Cisco CSR (running out-of-band).

Note: See review 74156 for more details on device driver portion of
      this blueprint.

Change-Id: I39b1475c992b594256f5a28be0caa1ee9398050e
Partially-implements: blueprint vpnaas-cisco-driver
",git fetch https://review.opendev.org/openstack/neutron refs/changes/44/74144/23 && git format-patch -1 --stdout FETCH_HEAD,"['neutron/services/vpn/service_drivers/cisco_csr_db.py', 'neutron/tests/unit/services/vpn/service_drivers/test_cisco_ipsec.py', 'neutron/services/vpn/common/topics.py', 'etc/vpn_agent.ini', 'neutron/db/migration/alembic_migrations/versions/24c7ea5160d7_cisco_csr_vpnaas.py', 'neutron/services/vpn/service_drivers/cisco_ipsec.py']",6,4861a4150c0f67d961d1f9a030fb5f88a29dac29,fix_migrations,"# Copyright 2014 Cisco Systems, Inc. All rights reserved. # # Licensed under the Apache License, Version 2.0 (the ""License""); you may # not use this file except in compliance with the License. You may obtain # a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT # WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the # License for the specific language governing permissions and limitations # under the License. import netaddr from neutron.common import exceptions from neutron.common import rpc as n_rpc from neutron import manager from neutron.openstack.common import log as logging from neutron.openstack.common import rpc from neutron.openstack.common.rpc import proxy from neutron.plugins.common import constants from neutron.services.vpn.common import topics from neutron.services.vpn import service_drivers from neutron.services.vpn.service_drivers import cisco_csr_db as csr_id_map LOG = logging.getLogger(__name__) IPSEC = 'ipsec' BASE_IPSEC_VERSION = '1.0' LIFETIME_LIMITS = {'IKE Policy': {'min': 60, 'max': 86400}, 'IPSec Policy': {'min': 120, 'max': 2592000}} MIN_CSR_MTU = 1500 MAX_CSR_MTU = 9192 class CsrValidationFailure(exceptions.NeutronException): message = _(""Cisco CSR does not support %(resource)s attribute %(key)s "" ""with value '%(value)s'"") class CsrUnsupportedError(exceptions.NeutronException): message = _(""Cisco CSR does not currently support %(capability)s"") class CiscoCsrIPsecVpnDriverCallBack(object): """"""Handler for agent to plugin RPC messaging."""""" # history # 1.0 Initial version RPC_API_VERSION = BASE_IPSEC_VERSION def __init__(self, driver): self.driver = driver def create_rpc_dispatcher(self): return n_rpc.PluginRpcDispatcher([self]) def get_vpn_services_on_host(self, context, host=None): """"""Retuns info on the vpnservices on the host."""""" plugin = self.driver.service_plugin vpnservices = plugin._get_agent_hosting_vpn_services( context, host) return [self.driver._make_vpnservice_dict(vpnservice, context) for vpnservice in vpnservices] def update_status(self, context, status): """"""Update status of all vpnservices."""""" plugin = self.driver.service_plugin plugin.update_status_by_agent(context, status) class CiscoCsrIPsecVpnAgentApi(proxy.RpcProxy): """"""API and handler for plugin to agent RPC messaging."""""" RPC_API_VERSION = BASE_IPSEC_VERSION def _agent_notification(self, context, method, router_id, version=None, **kwargs): """"""Notify update for the agent. This method will find where is the router, and dispatch notification for the agent. """""" adminContext = context.is_admin and context or context.elevated() plugin = manager.NeutronManager.get_service_plugins().get( constants.L3_ROUTER_NAT) if not version: version = self.RPC_API_VERSION l3_agents = plugin.get_l3_agents_hosting_routers( adminContext, [router_id], admin_state_up=True, active=True) for l3_agent in l3_agents: LOG.debug(_('Notify agent at %(topic)s.%(host)s the message ' '%(method)s'), {'topic': topics.CISCO_IPSEC_AGENT_TOPIC, 'host': l3_agent.host, 'method': method, 'args': kwargs}) self.cast( context, self.make_msg(method, **kwargs), version=version, topic='%s.%s' % (topics.CISCO_IPSEC_AGENT_TOPIC, l3_agent.host)) def vpnservice_updated(self, context, router_id): """"""Send update event of vpnservices."""""" method = 'vpnservice_updated' self._agent_notification(context, method, router_id) class CiscoCsrIPsecVPNDriver(service_drivers.VpnDriver): """"""Cisco CSR VPN Service Driver class for IPsec."""""" def __init__(self, service_plugin): self.callbacks = CiscoCsrIPsecVpnDriverCallBack(self) self.service_plugin = service_plugin self.conn = rpc.create_connection(new=True) self.conn.create_consumer( topics.CISCO_IPSEC_DRIVER_TOPIC, self.callbacks.create_rpc_dispatcher(), fanout=False) self.conn.consume_in_thread() self.agent_rpc = CiscoCsrIPsecVpnAgentApi( topics.CISCO_IPSEC_AGENT_TOPIC, BASE_IPSEC_VERSION) @property def service_type(self): return IPSEC def validate_lifetime(self, for_policy, policy_info): """"""Ensure lifetime in secs and value is supported, based on policy."""""" units = policy_info['lifetime']['units'] if units != 'seconds': raise CsrValidationFailure(resource=for_policy, key='lifetime:units', value=units) value = policy_info['lifetime']['value'] if (value < LIFETIME_LIMITS[for_policy]['min'] or value > LIFETIME_LIMITS[for_policy]['max']): raise CsrValidationFailure(resource=for_policy, key='lifetime:value', value=value) def validate_ike_version(self, policy_info): """"""Ensure IKE policy is v1 for current REST API."""""" version = policy_info['ike_version'] if version != 'v1': raise CsrValidationFailure(resource='IKE Policy', key='ike_version', value=version) def validate_mtu(self, conn_info): """"""Ensure the MTU value is supported."""""" mtu = conn_info['mtu'] if mtu < MIN_CSR_MTU or mtu > MAX_CSR_MTU: raise CsrValidationFailure(resource='IPSec Connection', key='mtu', value=mtu) def validate_public_ip_present(self, vpn_service): """"""Ensure there is one gateway IP specified for the router used."""""" gw_port = vpn_service.router.gw_port if not gw_port or len(gw_port.fixed_ips) != 1: raise CsrValidationFailure(resource='IPSec Connection', key='router:gw_port:ip_address', value='missing') def validate_peer_id(self, ipsec_conn): """"""Ensure that an IP address is specified for peer ID."""""" # TODO(pcm) Should we check peer_address too? peer_id = ipsec_conn['peer_id'] try: netaddr.IPAddress(peer_id) except netaddr.core.AddrFormatError: raise CsrValidationFailure(resource='IPSec Connection', key='peer_id', value=peer_id) def validate_ipsec_connection(self, context, ipsec_conn, vpn_service): """"""Validate attributes w.r.t. Cisco CSR capabilities."""""" ike_policy = self.service_plugin.get_ikepolicy( context, ipsec_conn['ikepolicy_id']) ipsec_policy = self.service_plugin.get_ipsecpolicy( context, ipsec_conn['ipsecpolicy_id']) self.validate_lifetime('IKE Policy', ike_policy) self.validate_lifetime('IPSec Policy', ipsec_policy) self.validate_ike_version(ike_policy) self.validate_mtu(ipsec_conn) self.validate_public_ip_present(vpn_service) self.validate_peer_id(ipsec_conn) LOG.debug(_(""IPSec connection %s validated for Cisco CSR""), ipsec_conn['id']) def create_ipsec_site_connection(self, context, ipsec_site_connection): vpnservice = self.service_plugin._get_vpnservice( context, ipsec_site_connection['vpnservice_id']) self.validate_ipsec_connection(context, ipsec_site_connection, vpnservice) csr_id_map.create_tunnel_mapping(context, ipsec_site_connection) self.agent_rpc.vpnservice_updated(context, vpnservice['router_id']) def update_ipsec_site_connection( self, context, old_ipsec_site_connection, ipsec_site_connection): capability = _(""update of IPSec connections. You can delete and "" ""re-add, as a workaround."") raise CsrUnsupportedError(capability=capability) # TODO(pcm): FUTURE - Uncomment, once device driver supports # vpnservice = self.service_plugin._get_vpnservice( # context, ipsec_site_connection['vpnservice_id']) # self.agent_rpc.vpnservice_updated(context, vpnservice['router_id']) def delete_ipsec_site_connection(self, context, ipsec_site_connection): vpnservice = self.service_plugin._get_vpnservice( context, ipsec_site_connection['vpnservice_id']) csr_id_map.delete_tunnel_mapping(context, ipsec_site_connection) self.agent_rpc.vpnservice_updated(context, vpnservice['router_id']) def create_ikepolicy(self, context, ikepolicy): pass def delete_ikepolicy(self, context, ikepolicy): pass def update_ikepolicy(self, context, old_ikepolicy, ikepolicy): pass def create_ipsecpolicy(self, context, ipsecpolicy): pass def delete_ipsecpolicy(self, context, ipsecpolicy): pass def update_ipsecpolicy(self, context, old_ipsec_policy, ipsecpolicy): pass def create_vpnservice(self, context, vpnservice): pass def update_vpnservice(self, context, old_vpnservice, vpnservice): self.agent_rpc.vpnservice_updated(context, vpnservice['router_id']) def delete_vpnservice(self, context, vpnservice): self.agent_rpc.vpnservice_updated(context, vpnservice['router_id']) def get_cisco_connection_mappings(self, conn_id, context): """"""Obtain persisted mappings for IDs related to connection."""""" tunnel_id, ike_id, ipsec_id = csr_id_map.get_tunnel_mapping_for( conn_id, context.session) return {'site_conn_id': u'Tunnel%d' % tunnel_id, 'ike_policy_id': u'%d' % ike_id, 'ipsec_policy_id': u'%s' % ipsec_id} def _make_vpnservice_dict(self, vpnservice, context): """"""Collect all info on service, including Cisco info per IPSec conn."""""" vpnservice_dict = dict(vpnservice) vpnservice_dict['ipsec_conns'] = [] vpnservice_dict['subnet'] = dict( vpnservice.subnet) vpnservice_dict['external_ip'] = vpnservice.router.gw_port[ 'fixed_ips'][0]['ip_address'] for ipsec_conn in vpnservice.ipsec_site_connections: ipsec_conn_dict = dict(ipsec_conn) ipsec_conn_dict['ike_policy'] = dict(ipsec_conn.ikepolicy) ipsec_conn_dict['ipsec_policy'] = dict(ipsec_conn.ipsecpolicy) ipsec_conn_dict['peer_cidrs'] = [ peer_cidr.cidr for peer_cidr in ipsec_conn.peer_cidrs] ipsec_conn_dict['cisco'] = self.get_cisco_connection_mappings( ipsec_conn['id'], context) vpnservice_dict['ipsec_conns'].append(ipsec_conn_dict) return vpnservice_dict ",,1226,4
openstack%2Foslo-incubator~master~I4aa71034a5f1e83724efb49ceec3054726e87233,openstack/oslo-incubator,master,I4aa71034a5f1e83724efb49ceec3054726e87233,Apply testscenarios to imageutils test scripts,MERGED,2014-02-26 08:54:07.000000000,2014-03-06 03:51:32.000000000,2014-03-06 03:51:32.000000000,"[{'_account_id': 3}, {'_account_id': 1994}, {'_account_id': 5638}, {'_account_id': 6928}, {'_account_id': 9366}, {'_account_id': 9796}]","[{'number': 1, 'created': '2014-02-26 08:54:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo-incubator/commit/920f1d921bb55976f2758f37971dcefd28f04f36', 'message': 'tmp\n\nChange-Id: I4aa71034a5f1e83724efb49ceec3054726e87233\n'}, {'number': 2, 'created': '2014-02-26 14:58:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo-incubator/commit/b2283180ae6d583c26ddfee6f4e4ae27cd2854f2', 'message': 'testscenarios imageutils\n\nChange-Id: I4aa71034a5f1e83724efb49ceec3054726e87233\n'}, {'number': 3, 'created': '2014-02-27 02:50:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo-incubator/commit/fa1f9d7752340bf6de822ab10e8c2c0ec395ee35', 'message': 'Apply testscenarios to imageutils test scripts\n\nThere are some corner cases such as processing floating values\nin imageutils.QemuImgInfo. Rather than copy and pasting test scripts,\nit would be better to have testscenarios applied for ease of addiing\ntest cases.\n\nThe original test case was not removed to prove the new test script\ncovers the original tests.\n\nChange-Id: I4aa71034a5f1e83724efb49ceec3054726e87233\n'}, {'number': 4, 'created': '2014-02-27 11:46:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo-incubator/commit/483bd21145946bc8614abc0aade6705e43c7bbbc', 'message': 'Apply testscenarios to imageutils test scripts\n\nThere are some corner cases such as processing floating values\nin imageutils.QemuImgInfo. Rather than copy and pasting test scripts,\nit would be better to have testscenarios applied for ease of addiing\ntest cases.\n\nThe original test case was not removed to prove the new test script\ncovers the original tests.\n\nChange-Id: I4aa71034a5f1e83724efb49ceec3054726e87233\n'}, {'number': 5, 'created': '2014-02-27 12:13:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo-incubator/commit/26c2aed94bf09afdf4d8df373ba00a81711fc575', 'message': 'Apply testscenarios to imageutils test scripts\n\nThere are some corner cases such as processing floating values\nin imageutils.QemuImgInfo. Rather than copy and pasting test scripts,\nit would be better to have testscenarios applied for ease of addiing\ntest cases.\n\nThe original test case was not removed to prove the new test script\ncovers the original tests.\n\nChange-Id: I4aa71034a5f1e83724efb49ceec3054726e87233\n'}, {'number': 6, 'created': '2014-02-27 14:00:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo-incubator/commit/91ba3190f497475e2e44593819727f91aa0e041c', 'message': 'Apply testscenarios to imageutils test scripts\n\nThere are some corner cases that need to be tested such as\nprocessing floating values in imageutils.QemuImgInfo.\nRather than copy and pasting test scripts, it would be better\nto have testscenarios applied for ease of addiing test cases.\n\nThe original test case was not removed to prove the new test script\ncovers the original tests.\n\nChange-Id: I4aa71034a5f1e83724efb49ceec3054726e87233\n'}, {'number': 7, 'created': '2014-02-28 00:55:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo-incubator/commit/a2b7679797f29e98f7077c9011b7b36acfd466f0', 'message': 'Apply testscenarios to imageutils test scripts\n\nThere are some corner cases that need to be tested such as\nprocessing floating values in imageutils.QemuImgInfo.\nRather than copy and pasting test scripts, it would be better\nto have testscenarios applied for ease of addiing test cases.\n\nThe original test case was not removed to prove the new test script\ncovers the original tests.\nThe test_imageutils module was removed from py33 tests due to\ntestscenarios incompatibility.\n\nChange-Id: I4aa71034a5f1e83724efb49ceec3054726e87233\n'}, {'number': 8, 'created': '2014-02-28 00:55:23.000000000', 'files': ['tests/unit/test_imageutils.py', 'tox.ini'], 'web_link': 'https://opendev.org/openstack/oslo-incubator/commit/c71f8ab984fc19b2799d52d21d48910dc47c4ac9', 'message': 'Apply testscenarios to imageutils test scripts\n\nThere are some corner cases that need to be tested such as\nprocessing floating values in imageutils.QemuImgInfo.\nRather than copy and pasting test scripts, it would be better\nto have testscenarios applied for ease of addiing test cases.\n\nThe original test case was not removed to prove the new test script\ncovers the original tests.\nThe test_imageutils module was removed from py33 tests due to\ntestscenarios incompatibility.\n\nChange-Id: I4aa71034a5f1e83724efb49ceec3054726e87233\n'}]",1,76468,c71f8ab984fc19b2799d52d21d48910dc47c4ac9,38,6,8,1994,,,0,"Apply testscenarios to imageutils test scripts

There are some corner cases that need to be tested such as
processing floating values in imageutils.QemuImgInfo.
Rather than copy and pasting test scripts, it would be better
to have testscenarios applied for ease of addiing test cases.

The original test case was not removed to prove the new test script
covers the original tests.
The test_imageutils module was removed from py33 tests due to
testscenarios incompatibility.

Change-Id: I4aa71034a5f1e83724efb49ceec3054726e87233
",git fetch https://review.opendev.org/openstack/oslo-incubator refs/changes/68/76468/1 && git format-patch -1 --stdout FETCH_HEAD,['tests/unit/test_imageutils.py'],1,920f1d921bb55976f2758f37971dcefd28f04f36,imageutils_ts,"import testscenarios from openstack.common import test load_tests = testscenarios.load_tests_apply_scenarios class ImageUtilsTestCase(test.BaseTestCase): """""" _template = '\n'.join([ """""" _image_name = [ ('disk_config', dict(image_name='disk.config')), ] _file_format = [ ('raw', dict(file_format='raw')), ('qcow2', dict(file_format='qcow2')), ] _virtual_size = [ ('64M', dict(virtual_size='64M', exp_virtual_size=67108864)), ('64M_with_byte_hint', dict(virtual_size='64M (67108864 bytes)', exp_virtual_size=67108864)), ('64M_byte', dict(virtual_size='67108844', exp_virtual_size=67108844)), ('2K', dict(virtual_size='2K', exp_virtual_size=2048)), ('2K_with_byte_hint', dict(virtual_size='2K (2048 bytes)', exp_virtual_size=2048)), ] _disk_size = [ ('96K', dict(disk_size='96K', exp_disk_size=98304)), ('96K_byte', dict(disk_size='963434', exp_disk_size=963434)), ] _garbage_before_snapshot = [ ('no_garbage', dict(garbage_before_snapshot=None)), ('garbage_before_snapshot_list', dict(garbage_before_snapshot=False)), ('garbage_after_snapshot_list', dict(garbage_before_snapshot=True)), ] _snapshot_count = [ ('no_snapshots', dict(snapshot_count=None)), ('one_snapshots', dict(snapshot_count=1)), ('three_snapshots', dict(snapshot_count=3)), ] _qcow2_cluster_size = [ ('65536', dict(cluster_size='65536', exp_cluster_size=65536)), ] _qcow2_encrypted = [ ('no_encryption', dict(encrypted=None)), ('encrypted', dict(encrypted='yes')), ] _qcow2_backing_file = [ ('no_backing_file', dict(backing_file=None)), ('backing_file_path', dict(backing_file='/var/lib/nova/a328c7998805951a_2', exp_backing_file='/var/lib/nova/a328c7998805951a_2')), ('backing_file_path_with_actual_path', dict(backing_file='/var/lib/nova/a328c7998805951a_2 ' '(actual path: /b/3a988059e51a_2)', exp_backing_file='/b/3a988059e51a_2')), ] @classmethod def generate_scenarios(cls): cls.scenarios = testscenarios.multiply_scenarios( cls._image_name, cls._file_format, cls._virtual_size, cls._disk_size, cls._snapshot_count, cls._garbage_before_snapshot, cls._qcow2_cluster_size, cls._qcow2_encrypted, cls._qcow2_backing_file) def test_qemu_img_info(self): img_info = ('image: %s' % self.image_name, 'file_format: %s' % self.file_format, 'virtual_size: %s' % self.virtual_size, 'disk_size: %s' % self.disk_size) if self.file_format == 'qcow2': img_info = img_info + ('cluster_size: %s' % self.cluster_size,) if self.encrypted is not None: img_info = img_info + ('encrypted: %s' % self.encrypted,) if self.backing_file is not None: img_info = img_info + ('backing file: %s' % self.backing_file,) if self.garbage_before_snapshot is True: img_info = img_info + ('blah BLAH: bb',) if self.snapshot_count is not None: img_info = img_info + ('Snapshot list:',) img_info = img_info + ('ID ' 'TAG ' 'VM SIZE ' 'DATE ' 'VM CLOCK',) for i in range(self.snapshot_count): img_info = img_info + ('%d ' 'd9a9784a500742a7bb95627bb3aace38 ' '0 2012-08-20 10:52:46 00:00:00.000' % (i + 1),) if self.garbage_before_snapshot is False: img_info = img_info + ('junk stuff: bbb',) example_output = '\n'.join(img_info) image_info = imageutils.QemuImgInfo(example_output) self.assertEqual(image_info.image, self.image_name) self.assertEqual(image_info.file_format, self.file_format) self.assertEqual(image_info.virtual_size, self.exp_virtual_size) self.assertEqual(image_info.disk_size, self.exp_disk_size) if self.snapshot_count is not None: self.assertEqual(len(image_info.snapshots), self.snapshot_count) if self.file_format == 'qcow2': self.assertEqual(image_info.cluster_size, self.exp_cluster_size) if self.backing_file is not None: self.assertEqual(image_info.backing_file, self.exp_backing_file) if self.encrypted is not None: self.assertEqual(image_info.encrypted, self.encrypted) ImageUtilsTestCase.generate_scenarios() class ImageUtilsTestCase2(test.BaseTestCase):",from tests import utils as utils_test class ImageUtilsTestCase(utils_test.BaseTestCase):,131,2
openstack%2Fcinder~master~I902b10343b8b83729ccdae28bdc84271efc26411,openstack/cinder,master,I902b10343b8b83729ccdae28bdc84271efc26411,Add user id information when getting a volume with cinder show Closes-Bug: #1286005,ABANDONED,2014-03-03 09:53:42.000000000,2014-03-06 03:45:05.000000000,,"[{'_account_id': 3}, {'_account_id': 7051}, {'_account_id': 7198}, {'_account_id': 10569}]","[{'number': 1, 'created': '2014-03-03 09:53:42.000000000', 'files': ['cinder/api/v2/volumes.py', 'cinder/api/v1/volumes.py'], 'web_link': 'https://opendev.org/openstack/cinder/commit/af6c599ab62b489d0c61fdc06c970d0585760ea0', 'message': 'Add user id information when getting a volume with cinder show\nCloses-Bug: #1286005\n\nChange-Id: I902b10343b8b83729ccdae28bdc84271efc26411\n'}]",2,77545,af6c599ab62b489d0c61fdc06c970d0585760ea0,6,4,1,10569,,,0,"Add user id information when getting a volume with cinder show
Closes-Bug: #1286005

Change-Id: I902b10343b8b83729ccdae28bdc84271efc26411
",git fetch https://review.opendev.org/openstack/cinder refs/changes/45/77545/1 && git format-patch -1 --stdout FETCH_HEAD,"['cinder/api/v2/volumes.py', 'cinder/api/v1/volumes.py']",2,af6c599ab62b489d0c61fdc06c970d0585760ea0,Bug1286005, d['user_id'] = vol['user_id'] elem.set('user_id'),,3,0
openstack%2Fneutron~master~I6ef9c27de8583105bb736c363af14490cfc99f80,openstack/neutron,master,I6ef9c27de8583105bb736c363af14490cfc99f80,<WIP> Keystone endpoint stuff....,ABANDONED,2014-02-28 03:05:44.000000000,2014-03-06 03:33:14.000000000,,"[{'_account_id': 3}, {'_account_id': 5170}, {'_account_id': 9787}, {'_account_id': 9925}, {'_account_id': 10116}, {'_account_id': 10117}, {'_account_id': 10153}, {'_account_id': 10294}]","[{'number': 1, 'created': '2014-02-28 03:05:44.000000000', 'files': ['neutron/common/service_catalog.py', 'neutron/auth.py', 'neutron/common/utils.py', 'neutron/context.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/145c481aca0207d2af5952462779b660141f8d92', 'message': '<WIP> Keystone endpoint stuff....\n\nChange-Id: I6ef9c27de8583105bb736c363af14490cfc99f80\n'}]",0,77049,145c481aca0207d2af5952462779b660141f8d92,11,8,1,4395,,,0,"<WIP> Keystone endpoint stuff....

Change-Id: I6ef9c27de8583105bb736c363af14490cfc99f80
",git fetch https://review.opendev.org/openstack/neutron refs/changes/49/77049/1 && git format-patch -1 --stdout FETCH_HEAD,"['neutron/common/service_catalog.py', 'neutron/auth.py', 'neutron/common/utils.py', 'neutron/context.py']",4,145c481aca0207d2af5952462779b660141f8d92,master,"from neutron.common import utils overwrite=True, service_catalog=None, **kwargs): self.service_catalog = service_catalog or [] 'service_catalog': self.service_catalog,"," overwrite=True, **kwargs):",42,2
openstack%2Fdevstack~master~I42db0b3f7a4bbf5d1d053e3da8b4fbb67d47de94,openstack/devstack,master,I42db0b3f7a4bbf5d1d053e3da8b4fbb67d47de94,NCCLIENT_REPO is using the wrong url,MERGED,2014-03-03 21:46:17.000000000,2014-03-06 03:20:55.000000000,2014-03-06 03:20:54.000000000,"[{'_account_id': 1}, {'_account_id': 3}, {'_account_id': 105}, {'_account_id': 866}, {'_account_id': 970}, {'_account_id': 1269}, {'_account_id': 2750}, {'_account_id': 6524}, {'_account_id': 6754}, {'_account_id': 6967}]","[{'number': 1, 'created': '2014-03-03 21:46:17.000000000', 'files': ['lib/neutron_plugins/cisco'], 'web_link': 'https://opendev.org/openstack/devstack/commit/de3b82037d863b55cc245c343a8697b5cf4b1904', 'message': 'NCCLIENT_REPO is using the wrong url\n\nNCCLIENT_REPO value in lib/neutron_plugins/cisco is pointing to a repo\nthat does not exist. This fix corrects the url.\n\nCloses-Bug #1286302\n\nChange-Id: I42db0b3f7a4bbf5d1d053e3da8b4fbb67d47de94\n'}]",0,77707,de3b82037d863b55cc245c343a8697b5cf4b1904,18,10,1,1269,,,0,"NCCLIENT_REPO is using the wrong url

NCCLIENT_REPO value in lib/neutron_plugins/cisco is pointing to a repo
that does not exist. This fix corrects the url.

Closes-Bug #1286302

Change-Id: I42db0b3f7a4bbf5d1d053e3da8b4fbb67d47de94
",git fetch https://review.opendev.org/openstack/devstack refs/changes/07/77707/1 && git format-patch -1 --stdout FETCH_HEAD,['lib/neutron_plugins/cisco'],1,de3b82037d863b55cc245c343a8697b5cf4b1904,bug/1286302,NCCLIENT_REPO=${NCCLIENT_REPO:-git://github.com/CiscoSystems/ncclient.git},NCCLIENT_REPO=${NCCLIENT_REPO:-${GIT_BASE}/CiscoSystems/ncclient.git},1,1
openstack%2Fheat~master~If9755cf20c9f78cf1c93ac571ec1d4b3fdc320dc,openstack/heat,master,If9755cf20c9f78cf1c93ac571ec1d4b3fdc320dc,Move HOT parameters code to a separate module,MERGED,2014-03-04 02:11:36.000000000,2014-03-06 03:18:44.000000000,2014-03-06 03:18:43.000000000,"[{'_account_id': 3}, {'_account_id': 4257}, {'_account_id': 4571}, {'_account_id': 7193}, {'_account_id': 7253}, {'_account_id': 7256}, {'_account_id': 7385}]","[{'number': 1, 'created': '2014-03-04 02:11:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/f7b0aa61b60e92a63fe9b86e437180e13b78d153', 'message': 'Move HOT parameters code to a separate module\n\nChange-Id: If9755cf20c9f78cf1c93ac571ec1d4b3fdc320dc\n'}, {'number': 2, 'created': '2014-03-05 16:14:26.000000000', 'files': ['heat/engine/hot/__init__.py', 'heat/db/sqlalchemy/migrate_repo/versions/037_migrate_hot_template.py', 'heat/tests/test_properties.py', 'heat/engine/hot/parameters.py', 'heat/tests/test_hot.py'], 'web_link': 'https://opendev.org/openstack/heat/commit/0187d01eb8a008a3cbd523ded8192785c22df712', 'message': 'Move HOT parameters code to a separate module\n\nChange-Id: If9755cf20c9f78cf1c93ac571ec1d4b3fdc320dc\n'}]",0,77752,0187d01eb8a008a3cbd523ded8192785c22df712,22,7,2,4257,,,0,"Move HOT parameters code to a separate module

Change-Id: If9755cf20c9f78cf1c93ac571ec1d4b3fdc320dc
",git fetch https://review.opendev.org/openstack/heat refs/changes/52/77752/1 && git format-patch -1 --stdout FETCH_HEAD,"['heat/engine/hot/__init__.py', 'heat/db/sqlalchemy/migrate_repo/versions/037_migrate_hot_template.py', 'heat/tests/test_properties.py', 'heat/engine/hot/parameters.py', 'heat/tests/test_hot.py']",5,f7b0aa61b60e92a63fe9b86e437180e13b78d153,typeless-function-plugins,"from heat.engine.hot import parameters as hot_param hot_param.HOTParamSchema.from_dict(schema).validate(name, value) hot_param.HOTParamSchema.from_dict(schema).validate(name, value) hot_param.HOTParamSchema.from_dict(schema).validate(name, value) hot_param.HOTParamSchema.from_dict, schema)"," hot.HOTParamSchema.from_dict(schema).validate(name, value) hot.HOTParamSchema.from_dict(schema).validate(name, value) hot.HOTParamSchema.from_dict(schema).validate(name, value) hot.HOTParamSchema.from_dict, schema)",138,114
openstack%2Fneutron~master~I442f64cf82f95bfa99d7765eb09db1ce2ecf602e,openstack/neutron,master,I442f64cf82f95bfa99d7765eb09db1ce2ecf602e,Add OVS cleanup utility,MERGED,2012-12-24 16:54:59.000000000,2014-03-06 03:17:06.000000000,2012-12-24 16:54:59.000000000,"[{'_account_id': 3}, {'_account_id': 105}, {'_account_id': 490}, {'_account_id': 841}, {'_account_id': 1653}, {'_account_id': 1994}, {'_account_id': 2035}, {'_account_id': 2166}, {'_account_id': 2592}, {'_account_id': 5754}, {'_account_id': 7823}]","[{'number': 8, 'created': '2012-12-24 16:54:59.000000000', 'files': ['quantum/agent/linux/ovs_lib.py', 'quantum/tests/unit/test_agent_ovs_cleanup.py', 'setup.py', 'quantum/agent/ovs_cleanup_util.py', 'quantum/tests/unit/openvswitch/test_ovs_lib.py', 'bin/quantum-ovs-cleanup'], 'web_link': 'https://opendev.org/openstack/neutron/commit/767859ddb947f281c4ada930ccc21cc6f0ba6806', 'message': 'Add OVS cleanup utility\n\nFixes bug 1091605\n\nThe utility should be called after rebooting an appliance. This\nwill purge the openvswicth of configured tap devices.\n\nA configuration variable quantum_ports has been added. This is\nby default True which indicates that only Quantum ports will be\ndeleted from the OVS. If this is set as False then all ports on the\nbridge will be deleted.\n\nChange-Id: I442f64cf82f95bfa99d7765eb09db1ce2ecf602e\n'}, {'number': 1, 'created': '2012-12-24 16:54:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/6d34d14ec3c130578500508866d03d651f7ebf20', 'message': 'Add OVS cleanup utility\n\nFixes bug 1091605\n\nThe utility should be called after rebooting an appliance. This\nwill purge the openvswicth of configured tap devices.\n\nChange-Id: I442f64cf82f95bfa99d7765eb09db1ce2ecf602e\n'}, {'number': 3, 'created': '2012-12-24 16:54:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/380ad4d4fd6af09b37f6a7b2f6c7e78196e3128c', 'message': 'Add OVS cleanup utility\n\nFixes bug 1091605\n\nThe utility should be called after rebooting an appliance. This\nwill purge the openvswicth of configured tap devices.\n\nA configuration variable quantum_ports has been added. This is\nby default True which indicates that only Quantum ports will be\ndeleted from the OVS. If this is set as False then all ports on the\nbridge will be deleted.\n\nChange-Id: I442f64cf82f95bfa99d7765eb09db1ce2ecf602e\n'}, {'number': 2, 'created': '2012-12-24 16:54:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/773de821ac6e96378bf3b62c04dfdd08e618493e', 'message': 'Add OVS cleanup utility\n\nFixes bug 1091605\n\nThe utility should be called after rebooting an appliance. This\nwill purge the openvswicth of configured tap devices.\n\nChange-Id: I442f64cf82f95bfa99d7765eb09db1ce2ecf602e\n'}, {'number': 5, 'created': '2012-12-24 16:54:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/53b56310a90d7020b6b0138d7c6c8ce0f5446de1', 'message': 'Add OVS cleanup utility\n\nFixes bug 1091605\n\nThe utility should be called after rebooting an appliance. This\nwill purge the openvswicth of configured tap devices.\n\nA configuration variable quantum_ports has been added. This is\nby default True which indicates that only Quantum ports will be\ndeleted from the OVS. If this is set as False then all ports on the\nbridge will be deleted.\n\nChange-Id: I442f64cf82f95bfa99d7765eb09db1ce2ecf602e\n'}, {'number': 4, 'created': '2012-12-24 16:54:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/656e72fa8d0ad4447f56b216646cf443523682be', 'message': 'Add OVS cleanup utility\n\nFixes bug 1091605\n\nThe utility should be called after rebooting an appliance. This\nwill purge the openvswicth of configured tap devices.\n\nA configuration variable quantum_ports has been added. This is\nby default True which indicates that only Quantum ports will be\ndeleted from the OVS. If this is set as False then all ports on the\nbridge will be deleted.\n\nChange-Id: I442f64cf82f95bfa99d7765eb09db1ce2ecf602e\n'}, {'number': 7, 'created': '2012-12-24 16:54:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/53314e1d80f5729962172f6a5bd7b35aee2b2b5e', 'message': 'Add OVS cleanup utility\n\nFixes bug 1091605\n\nThe utility should be called after rebooting an appliance. This\nwill purge the openvswicth of configured tap devices.\n\nA configuration variable quantum_ports has been added. This is\nby default True which indicates that only Quantum ports will be\ndeleted from the OVS. If this is set as False then all ports on the\nbridge will be deleted.\n\nChange-Id: I442f64cf82f95bfa99d7765eb09db1ce2ecf602e\n'}, {'number': 6, 'created': '2012-12-24 16:54:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/e26cd1e8e7b03085dd3329bb288fb8f8a386e66b', 'message': 'Add OVS cleanup utility\n\nFixes bug 1091605\n\nThe utility should be called after rebooting an appliance. This\nwill purge the openvswicth of configured tap devices.\n\nA configuration variable quantum_ports has been added. This is\nby default True which indicates that only Quantum ports will be\ndeleted from the OVS. If this is set as False then all ports on the\nbridge will be deleted.\n\nChange-Id: I442f64cf82f95bfa99d7765eb09db1ce2ecf602e\n'}]",12,18302,767859ddb947f281c4ada930ccc21cc6f0ba6806,43,11,8,1653,,,0,"Add OVS cleanup utility

Fixes bug 1091605

The utility should be called after rebooting an appliance. This
will purge the openvswicth of configured tap devices.

A configuration variable quantum_ports has been added. This is
by default True which indicates that only Quantum ports will be
deleted from the OVS. If this is set as False then all ports on the
bridge will be deleted.

Change-Id: I442f64cf82f95bfa99d7765eb09db1ce2ecf602e
",git fetch https://review.opendev.org/openstack/neutron refs/changes/02/18302/8 && git format-patch -1 --stdout FETCH_HEAD,"['quantum/agent/linux/ovs_lib.py', 'quantum/tests/unit/test_agent_ovs_cleanup.py', 'setup.py', 'quantum/agent/ovs_cleanup_util.py', 'quantum/tests/unit/openvswitch/test_ovs_lib.py', 'bin/quantum-ovs-cleanup']",6,767859ddb947f281c4ada930ccc21cc6f0ba6806,bug/1091605,"#!/usr/bin/env python # vim: tabstop=4 shiftwidth=4 softtabstop=4 # Copyright (c) 2012 Openstack, LLC. # All Rights Reserved. # # Licensed under the Apache License, Version 2.0 (the ""License""); you may # not use this file except in compliance with the License. You may obtain # a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT # WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the # License for the specific language governing permissions and limitations # under the License. import os import sys sys.path.insert(0, os.getcwd()) from quantum.agent.ovs_cleanup_util import main main() ",,197,0
openstack%2Fkeystone~master~I2a92733c506da90a27cb882bc9e9bd8498510084,openstack/keystone,master,I2a92733c506da90a27cb882bc9e9bd8498510084,Update Oslo wiki link in README,MERGED,2014-03-03 03:38:06.000000000,2014-03-06 03:13:59.000000000,2014-03-06 03:13:58.000000000,"[{'_account_id': 3}, {'_account_id': 4}, {'_account_id': 2903}, {'_account_id': 8229}, {'_account_id': 9598}]","[{'number': 1, 'created': '2014-03-03 03:38:06.000000000', 'files': ['keystone/openstack/common/README'], 'web_link': 'https://opendev.org/openstack/keystone/commit/24bbb05c20a807af71ca8b760b4af851facaba0f', 'message': 'Update Oslo wiki link in README\n\nUse lastest Oslo wiki link.\n\nChange-Id: I2a92733c506da90a27cb882bc9e9bd8498510084\n'}]",0,77494,24bbb05c20a807af71ca8b760b4af851facaba0f,13,5,1,8229,,,0,"Update Oslo wiki link in README

Use lastest Oslo wiki link.

Change-Id: I2a92733c506da90a27cb882bc9e9bd8498510084
",git fetch https://review.opendev.org/openstack/keystone refs/changes/94/77494/1 && git format-patch -1 --stdout FETCH_HEAD,['keystone/openstack/common/README'],1,24bbb05c20a807af71ca8b760b4af851facaba0f,update_readme, https://wiki.openstack.org/wiki/Oslo#Syncing_Code_from_Incubator, http://wiki.openstack.org/CommonLibrary#Incubation,1,1
openstack%2Fironic~master~Ic5f13f247d835707ab16b2cc6579c00504744fa8,openstack/ironic,master,Ic5f13f247d835707ab16b2cc6579c00504744fa8,PXE clean_up() to remove the pxe_deploy_key parameter,MERGED,2014-02-07 12:13:56.000000000,2014-03-06 03:13:50.000000000,2014-03-06 03:13:49.000000000,"[{'_account_id': 3}, {'_account_id': 2889}, {'_account_id': 5805}, {'_account_id': 6623}, {'_account_id': 6773}, {'_account_id': 7711}, {'_account_id': 8125}, {'_account_id': 8412}, {'_account_id': 8968}, {'_account_id': 10486}]","[{'number': 1, 'created': '2014-02-07 12:13:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/0334d209c7053c2e0c192703946ad48706f92840', 'message': ""PXE clean_up() to remove the pxe_deploy_key parameter\n\nThe pxe_deploy_key is an internal attribute used by the PXE driver to\nbuild the pxe configuration files, it's added to the node's driver_info\nin the moment that the configuration files are being generated but it's\nnot being removed after the node's unprovisioned. So this patch is making\nsure that the pxe_deploy_key is removed from the driver's parameters at\nthe clean_up() method of the pxe driver.\n\nChange-Id: Ic5f13f247d835707ab16b2cc6579c00504744fa8\n""}, {'number': 2, 'created': '2014-02-07 14:06:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/40bccfacac48ba5079bf2e2a727e6d3cb32a2394', 'message': ""PXE clean_up() to remove the pxe_deploy_key parameter\n\nThe pxe_deploy_key is an internal attribute used by the PXE driver to\nbuild the pxe configuration files, it's added to the node's driver_info\nin the moment that the configuration files are being generated but it's\nnot being removed after the node's unprovisioned. So this patch is making\nsure that the pxe_deploy_key is removed from the driver's parameters at\nthe clean_up() method of the pxe driver.\n\nChange-Id: Ic5f13f247d835707ab16b2cc6579c00504744fa8\n""}, {'number': 3, 'created': '2014-02-07 14:19:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/d8958d00b7bfa41cac6da1bc9bc9f510042c2b6a', 'message': ""PXE clean_up() to remove the pxe_deploy_key parameter\n\nThe pxe_deploy_key is an internal attribute used by the PXE driver to\nbuild the pxe configuration files, it's added to the node's driver_info\nin the moment that the configuration files are being generated but it's\nnot being removed after the node's unprovisioned. So this patch is making\nsure that the pxe_deploy_key is removed from the driver's parameters at\nthe clean_up() method of the pxe driver.\n\nChange-Id: Ic5f13f247d835707ab16b2cc6579c00504744fa8\n""}, {'number': 4, 'created': '2014-02-17 17:02:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/896e47e225bda0b85d19542c75b96ae598e3a880', 'message': ""PXE clean_up() to remove the pxe_deploy_key parameter\n\nThe pxe_deploy_key is an internal attribute used by the PXE driver to\nbuild the pxe configuration files, it's added to the node's driver_info\nin the moment that the configuration files are being generated but it's\nnot being removed after the node's unprovisioned. So this patch is making\nsure that the pxe_deploy_key is removed from the driver's parameters at\nthe clean_up() method of the pxe driver.\n\nChange-Id: Ic5f13f247d835707ab16b2cc6579c00504744fa8\n""}, {'number': 5, 'created': '2014-02-17 17:03:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/24fbb98a49de0da37969409da9e9b21a1da67d79', 'message': ""PXE clean_up() to remove the pxe_deploy_key parameter\n\nThe pxe_deploy_key is an internal attribute used by the PXE driver to\nbuild the pxe configuration files, it's added to the node's driver_info\nin the moment that the configuration files are being generated but it's\nnot being removed after the node's unprovisioned. So this patch is making\nsure that the pxe_deploy_key is removed from the driver's parameters at\nthe clean_up() method of the pxe driver.\n\nChange-Id: Ic5f13f247d835707ab16b2cc6579c00504744fa8\n""}, {'number': 6, 'created': '2014-02-26 17:05:38.000000000', 'files': ['ironic/drivers/modules/pxe.py', 'ironic/tests/drivers/test_pxe.py'], 'web_link': 'https://opendev.org/openstack/ironic/commit/4b73f7e4e7e09c1d6b87e298d30ff00b9436d389', 'message': ""PXE clean_up() to remove the pxe_deploy_key parameter\n\nThe pxe_deploy_key is an internal attribute used by the PXE driver to\nbuild the pxe configuration files, it's added to the node's driver_info\nin the moment that the configuration files are being generated but it's\nnot being removed after the node's unprovisioned. So this patch is making\nsure that the pxe_deploy_key is removed from the driver's parameters at\nthe clean_up() method of the pxe driver.\n\nChange-Id: Ic5f13f247d835707ab16b2cc6579c00504744fa8\n""}]",8,71879,4b73f7e4e7e09c1d6b87e298d30ff00b9436d389,51,10,6,6773,,,0,"PXE clean_up() to remove the pxe_deploy_key parameter

The pxe_deploy_key is an internal attribute used by the PXE driver to
build the pxe configuration files, it's added to the node's driver_info
in the moment that the configuration files are being generated but it's
not being removed after the node's unprovisioned. So this patch is making
sure that the pxe_deploy_key is removed from the driver's parameters at
the clean_up() method of the pxe driver.

Change-Id: Ic5f13f247d835707ab16b2cc6579c00504744fa8
",git fetch https://review.opendev.org/openstack/ironic refs/changes/79/71879/1 && git format-patch -1 --stdout FETCH_HEAD,"['ironic/drivers/modules/pxe.py', 'ironic/tests/drivers/test_pxe.py']",2,0334d209c7053c2e0c192703946ad48706f92840,rm-pxe_deploy_key, assert 'pxe_deploy_key' not in self.node.driver_info ,,6,0
openstack%2Fzaqar~master~I94f6aaa1e608e34717bd1d3f2b5b0c9a606aa8bc,openstack/zaqar,master,I94f6aaa1e608e34717bd1d3f2b5b0c9a606aa8bc,Replace `Sqlite` with `Sqlalchemy` in test names,MERGED,2014-03-05 15:36:10.000000000,2014-03-06 03:12:46.000000000,2014-03-06 03:12:46.000000000,"[{'_account_id': 3}, {'_account_id': 6159}, {'_account_id': 6413}, {'_account_id': 6484}, {'_account_id': 6944}]","[{'number': 1, 'created': '2014-03-05 15:36:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/zaqar/commit/d65fc9896f1b35d50ca6345967f3d995827497ab', 'message': 'Replace `Sqlite` with `Sqlalchemy` in test names\n\nChange-Id: I94f6aaa1e608e34717bd1d3f2b5b0c9a606aa8bc\n'}, {'number': 2, 'created': '2014-03-05 20:53:47.000000000', 'files': ['marconi/tests/queues/transport/wsgi/test_messages.py', 'marconi/tests/queues/transport/wsgi/test_queue_lifecycle.py', 'tests/unit/queues/transport/wsgi/test_v1_0.py', 'marconi/tests/queues/transport/wsgi/test_claims.py', 'tests/unit/queues/transport/wsgi/test_v1_1.py', 'marconi/tests/queues/transport/wsgi/__init__.py'], 'web_link': 'https://opendev.org/openstack/zaqar/commit/bf055a485b610e0aed73917b54a535737a07f33e', 'message': 'Replace `Sqlite` with `Sqlalchemy` in test names\n\nChange-Id: I94f6aaa1e608e34717bd1d3f2b5b0c9a606aa8bc\n'}]",0,78267,bf055a485b610e0aed73917b54a535737a07f33e,12,5,2,6159,,,0,"Replace `Sqlite` with `Sqlalchemy` in test names

Change-Id: I94f6aaa1e608e34717bd1d3f2b5b0c9a606aa8bc
",git fetch https://review.opendev.org/openstack/zaqar refs/changes/67/78267/2 && git format-patch -1 --stdout FETCH_HEAD,"['marconi/tests/queues/transport/wsgi/test_messages.py', 'marconi/tests/queues/transport/wsgi/test_queue_lifecycle.py', 'tests/unit/queues/transport/wsgi/test_v1_0.py', 'marconi/tests/queues/transport/wsgi/test_claims.py', 'tests/unit/queues/transport/wsgi/test_v1_1.py', 'marconi/tests/queues/transport/wsgi/__init__.py']",6,d65fc9896f1b35d50ca6345967f3d995827497ab,,TestClaimsSqlalchemy = test_claims.TestClaimsSqlalchemyTestMessagesSqlalchemy = test_messages.TestMessagesSqlalchemyTestQueueLifecycleSqlalchemy = test_queue_lifecycle.TestQueueLifecycleSqlalchemy,TestClaimsSQLite = test_claims.TestClaimsSQLiteTestMessagesSQLite = test_messages.TestMessagesSQLiteTestQueueLifecycleSQLite = test_queue_lifecycle.TestQueueLifecycleSQLite,12,12
openstack%2Fpuppet-nova~stable%2Fhavana~I17890a3e9e49572d989ad01383417b7256ef7e14,openstack/puppet-nova,stable/havana,I17890a3e9e49572d989ad01383417b7256ef7e14,compute: RBD backend support,MERGED,2014-02-26 08:20:26.000000000,2014-03-06 03:10:47.000000000,2014-03-06 03:10:47.000000000,"[{'_account_id': 3}, {'_account_id': 1918}, {'_account_id': 3153}, {'_account_id': 6754}, {'_account_id': 6967}, {'_account_id': 6994}, {'_account_id': 7156}, {'_account_id': 7822}]","[{'number': 1, 'created': '2014-02-26 08:20:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-nova/commit/18d5d76fd77252979748a43a9ca2eb8790fa0ac8', 'message': 'compute: RBD backend support\n\nSince Havana, Nova is able to store VMs on RBD backend (ceph).\n\nChange-Id: I17890a3e9e49572d989ad01383417b7256ef7e14\nSigned-off-by: Emilien Macchi <emilien.macchi@enovance.com>\n(cherry picked from commit 076d415ba560206ef1299b090c4eb474ffc2bdc4)\n'}, {'number': 2, 'created': '2014-02-27 12:30:19.000000000', 'files': ['manifests/compute/rbd.pp', 'templates/secret.xml-compute.erb', 'spec/classes/nova_compute_rbd_spec.rb'], 'web_link': 'https://opendev.org/openstack/puppet-nova/commit/49d16945dd01ba5fea8b2ca72d3e2df552ecdc78', 'message': 'compute: RBD backend support\n\nSince Havana, Nova is able to store VMs on RBD backend (ceph).\n\nChange-Id: I17890a3e9e49572d989ad01383417b7256ef7e14\nSigned-off-by: Emilien Macchi <emilien.macchi@enovance.com>\n(cherry picked from commit 076d415ba560206ef1299b090c4eb474ffc2bdc4)\n'}]",5,76462,49d16945dd01ba5fea8b2ca72d3e2df552ecdc78,18,8,2,3153,,,0,"compute: RBD backend support

Since Havana, Nova is able to store VMs on RBD backend (ceph).

Change-Id: I17890a3e9e49572d989ad01383417b7256ef7e14
Signed-off-by: Emilien Macchi <emilien.macchi@enovance.com>
(cherry picked from commit 076d415ba560206ef1299b090c4eb474ffc2bdc4)
",git fetch https://review.opendev.org/openstack/puppet-nova refs/changes/62/76462/2 && git format-patch -1 --stdout FETCH_HEAD,"['manifests/compute/rbd.pp', 'templates/secret.xml-compute.erb', 'spec/classes/nova_compute_rbd_spec.rb']",3,18d5d76fd77252979748a43a9ca2eb8790fa0ac8,backport-rbd,"# # Copyright (C) 2014 eNovance SAS <licensing@enovance.com> # # Author: Emilien Macchi <emilien.macchi@enovance.com> # # Licensed under the Apache License, Version 2.0 (the ""License""); you may # not use this file except in compliance with the License. You may obtain # a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT # WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the # License for the specific language governing permissions and limitations # under the License. # # Unit tests for nova::compute::rbd class # require 'spec_helper' describe 'nova::compute::rbd' do let :params do { :libvirt_rbd_user => 'nova', :libvirt_rbd_secret_uuid => false, :libvirt_images_rbd_pool => 'rbd', :libvirt_images_rbd_ceph_conf => '/etc/ceph/ceph.conf' } end shared_examples_for 'nova compute rbd' do it { should contain_class('nova::params') } it 'configure nova.conf with default parameters' do should contain_nova_config('libvirt/images_type').with_value('rbd') should contain_nova_config('libvirt/images_rbd_pool').with_value('rbd') should contain_nova_config('libvirt/images_rbd_ceph_conf').with_value('/etc/ceph/ceph.conf') should contain_nova_config('libvirt/rbd_user').with_value('nova') end context 'when overriding default parameters' do before :each do params.merge!( :libvirt_rbd_user => 'joe', :libvirt_rbd_secret_uuid => false, :libvirt_images_rbd_pool => 'AnotherPool', :libvirt_images_rbd_ceph_conf => '/tmp/ceph.conf' ) end it 'configure nova.conf with overriden parameters' do should contain_nova_config('libvirt/images_type').with_value('rbd') should contain_nova_config('libvirt/images_rbd_pool').with_value('AnotherPool') should contain_nova_config('libvirt/images_rbd_ceph_conf').with_value('/tmp/ceph.conf') should contain_nova_config('libvirt/rbd_user').with_value('joe') end end context 'when using cephx' do before :each do params.merge!( :libvirt_rbd_secret_uuid => 'UUID' ) end it 'configure nova.conf with RBD secret UUID' do should contain_nova_config('libvirt/rbd_secret_uuid').with_value('UUID') end it 'configure ceph on compute nodes' do verify_contents(subject, '/etc/nova/secret.xml', [ ""<secret ephemeral=\'no\' private=\'no\'>"", "" <usage type=\'ceph\'>"", "" <name>client.nova secret</name>"", "" </usage>"", "" <uuid>UUID</uuid>"", ""</secret>"" ]) should contain_exec('get-or-set virsh secret').with( :command => '/usr/bin/virsh secret-define --file /etc/ceph/secret.xml | /usr/bin/awk \'{print $2}\' | sed \'/^$/d\' > /etc/ceph/virsh.secret', :creates => '/etc/ceph/virsh.secret' ) should contain_exec('set-secret-value virsh').with( :command => ""/usr/bin/virsh secret-set-value --secret $(cat /etc/ceph/virsh.secret) --base64 $(ceph auth get-key client.nova)"" ) end end end context 'on Debian platforms' do let :facts do { :osfamily => 'Debian' } end it_configures 'nova compute rbd' end context 'on RedHat platforms' do let :facts do { :osfamily => 'RedHat' } end it_configures 'nova compute rbd' end end ",,200,0
openstack%2Fsolum~master~I1cccdb03694d1678ecd358fa29c27a5f8b25d6d5,openstack/solum,master,I1cccdb03694d1678ecd358fa29c27a5f8b25d6d5,DB objects have destroy() not delete(),MERGED,2014-03-03 05:37:47.000000000,2014-03-06 02:37:26.000000000,2014-03-06 02:37:26.000000000,"[{'_account_id': 3}, {'_account_id': 668}, {'_account_id': 2506}, {'_account_id': 4715}, {'_account_id': 8334}, {'_account_id': 8443}, {'_account_id': 9095}, {'_account_id': 9537}, {'_account_id': 9548}]","[{'number': 1, 'created': '2014-03-03 05:37:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/solum/commit/b3e3ccf180d90e3dc40036e2fb9cce3ec79a9d0f', 'message': 'DB objects have destroy() not delete()\n\nsensors and extensions were calling delete instead of destroy\n\nChange-Id: I1cccdb03694d1678ecd358fa29c27a5f8b25d6d5\n'}, {'number': 2, 'created': '2014-03-03 06:16:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/solum/commit/035ee350c0900fa20d6f63a3f6ecb2e248baa548', 'message': 'DB objects have destroy() not delete()\n\nsensors and extensions were calling delete instead of destroy\n\nChange-Id: I1cccdb03694d1678ecd358fa29c27a5f8b25d6d5\n'}, {'number': 3, 'created': '2014-03-05 23:44:47.000000000', 'files': ['solum/tests/api/handlers/test_extension.py', 'solum/tests/api/handlers/test_sensor.py', 'solum/api/handlers/sensor_handler.py', 'solum/api/handlers/extension_handler.py'], 'web_link': 'https://opendev.org/openstack/solum/commit/76f3c12acbc03acf501f990808560c6ad29115d7', 'message': 'DB objects have destroy() not delete()\n\nsensors and extensions were calling delete instead of destroy\n\nChange-Id: I1cccdb03694d1678ecd358fa29c27a5f8b25d6d5\n'}]",3,77501,76f3c12acbc03acf501f990808560c6ad29115d7,25,9,3,4715,,,0,"DB objects have destroy() not delete()

sensors and extensions were calling delete instead of destroy

Change-Id: I1cccdb03694d1678ecd358fa29c27a5f8b25d6d5
",git fetch https://review.opendev.org/openstack/solum refs/changes/01/77501/1 && git format-patch -1 --stdout FETCH_HEAD,"['solum/tests/api/handlers/test_extension.py', 'solum/tests/api/handlers/test_sensor.py', 'solum/api/handlers/sensor_handler.py', 'solum/api/handlers/extension_handler.py']",4,b3e3ccf180d90e3dc40036e2fb9cce3ec79a9d0f,destroy, db_obj.destroy(None) db_obj.create(None), db_obj.delete() db_obj.create(),5,5
openstack%2Fkeystone~stable%2Fhavana~I3e19e4a8fc1e11cef6db51d364e80061e97befa7,openstack/keystone,stable/havana,I3e19e4a8fc1e11cef6db51d364e80061e97befa7,Ensure tokens are added to both Trustor and Trustee indexes,MERGED,2014-02-21 21:36:49.000000000,2014-03-06 02:26:54.000000000,2014-03-06 02:26:53.000000000,"[{'_account_id': 3}, {'_account_id': 4}, {'_account_id': 1955}, {'_account_id': 2903}, {'_account_id': 7725}, {'_account_id': 9311}]","[{'number': 1, 'created': '2014-02-21 21:36:49.000000000', 'files': ['keystone/token/backends/kvs.py', 'keystone/tests/test_backend_kvs.py', 'keystone/tests/test_backend_memcache.py', 'keystone/token/backends/memcache.py', 'keystone/tests/test_backend.py'], 'web_link': 'https://opendev.org/openstack/keystone/commit/b6f0e26da0e2ab0892a5658da281a065e668637b', 'message': 'Ensure tokens are added to both Trustor and Trustee indexes\n\nTokens are now added to both the Trustor and Trustee user-token-index\nso that bulk token revocations (e.g. password change) of the trustee\nwill work as expected. This is a backport of the basic code that was\nused in the Icehouse-vintage Dogpile Token KVS backend that resolves\nthis issue by merging the handling of memcache and KVS backends into\nthe same logic.\n\nChange-Id: I3e19e4a8fc1e11cef6db51d364e80061e97befa7\nCloses-Bug: #1260080\n'}]",2,75521,b6f0e26da0e2ab0892a5658da281a065e668637b,33,6,1,2903,,,0,"Ensure tokens are added to both Trustor and Trustee indexes

Tokens are now added to both the Trustor and Trustee user-token-index
so that bulk token revocations (e.g. password change) of the trustee
will work as expected. This is a backport of the basic code that was
used in the Icehouse-vintage Dogpile Token KVS backend that resolves
this issue by merging the handling of memcache and KVS backends into
the same logic.

Change-Id: I3e19e4a8fc1e11cef6db51d364e80061e97befa7
Closes-Bug: #1260080
",git fetch https://review.opendev.org/openstack/keystone refs/changes/21/75521/1 && git format-patch -1 --stdout FETCH_HEAD,"['keystone/token/backends/kvs.py', 'keystone/tests/test_backend_kvs.py', 'keystone/tests/test_backend_memcache.py', 'keystone/token/backends/memcache.py', 'keystone/tests/test_backend.py']",5,b6f0e26da0e2ab0892a5658da281a065e668637b,bug/1260080,"from keystone.token import provider user_id='testuserid', trustee_user_id='testuserid2'): data.setdefault('access', {}).setdefault('trust', {}) # Testuserid2 is used here since a trustee will be different in # the cases of impersonation and therefore should not match the # token's user_id. data['access']['trust']['trustee_user_id'] = trustee_user_id data['token_version'] = provider.V2 # Issue token stores a copy of all token data at token['token_data']. # This emulates that assumption as part of the test. data['token_data'] = copy.deepcopy(data) def test_token_in_trustee_and_trustor_token_list(self): self.opt_in_group('trust', enabled=True) trustor = self.user_foo trustee = self.user_two trust_id = uuid.uuid4().hex trust_info = {'trustor_user_id': trustor['id'], 'trustee_user_id': trustee['id'], 'project_id': self.tenant_bar['id'], 'expires_at': timeutils. parse_isotime('2031-02-18T18:10:00Z'), 'impersonation': True} self.trust_api.create_trust(trust_id, trust_info, roles=[{'id': 'member'}, {'id': 'other'}, {'id': 'browser'}]) token_id = self.create_token_sample_data( tenant_id=self.tenant_bar['id'], trust_id=trust_id, user_id=trustor['id'], trustee_user_id=trustee['id']) # Ensure the token id exists in both the trustor and trustee token # lists self.assertIn(token_id, self.token_api.list_tokens(self.user_two['id'], trust_id=trust_id)) self.assertIn(token_id, self.token_api.list_tokens(self.user_foo['id'], trust_id=trust_id)) "," user_id=""testuserid""):",77,7
openstack%2Fkeystone~stable%2Fgrizzly~I3e19e4a8fc1e11cef6db51d364e80061e97befa7,openstack/keystone,stable/grizzly,I3e19e4a8fc1e11cef6db51d364e80061e97befa7,Ensure tokens are added to both Trustor and Trustee indexes,MERGED,2014-02-21 22:15:25.000000000,2014-03-06 02:23:44.000000000,2014-03-06 02:23:43.000000000,"[{'_account_id': 3}, {'_account_id': 4}, {'_account_id': 1955}, {'_account_id': 2903}, {'_account_id': 6460}, {'_account_id': 7725}]","[{'number': 1, 'created': '2014-02-21 22:15:25.000000000', 'files': ['tests/test_backend_memcache.py', 'tests/test_backend_kvs.py', 'keystone/token/backends/memcache.py', 'tests/test_backend.py'], 'web_link': 'https://opendev.org/openstack/keystone/commit/a411c944af78c36f2fdb87d305ba452dc52d7ed3', 'message': 'Ensure tokens are added to both Trustor and Trustee indexes\n\nTokens are now added to both the Trustor and Trustee user-token-index\nso that bulk token revocations (e.g. password change) of the trustee\nwill work as expected. This is a backport of the basic code that was\nused in the Icehouse-vintage Dogpile Token KVS backend that resolves\nthis issue by merging the handling of memcache and KVS backends into\nthe same logic.\n\nChange-Id: I3e19e4a8fc1e11cef6db51d364e80061e97befa7\nCloses-Bug: #1260080\n'}]",10,75526,a411c944af78c36f2fdb87d305ba452dc52d7ed3,18,6,1,2903,,,0,"Ensure tokens are added to both Trustor and Trustee indexes

Tokens are now added to both the Trustor and Trustee user-token-index
so that bulk token revocations (e.g. password change) of the trustee
will work as expected. This is a backport of the basic code that was
used in the Icehouse-vintage Dogpile Token KVS backend that resolves
this issue by merging the handling of memcache and KVS backends into
the same logic.

Change-Id: I3e19e4a8fc1e11cef6db51d364e80061e97befa7
Closes-Bug: #1260080
",git fetch https://review.opendev.org/openstack/keystone refs/changes/26/75526/1 && git format-patch -1 --stdout FETCH_HEAD,"['tests/test_backend_memcache.py', 'tests/test_backend_kvs.py', 'keystone/token/backends/memcache.py', 'tests/test_backend.py']",4,a411c944af78c36f2fdb87d305ba452dc52d7ed3,bug/1260080," user_id='testuserid', trustee_user_id='testuserid2'): data.setdefault('access', {}).setdefault('trust', {}) # Testuserid2 is used here since a trustee will be different in # the cases of impersonation and therefore should not match the # token's user_id. data['access']['trust']['trustee_user_id'] = trustee_user_id def test_token_in_trustee_and_trustor_token_list(self): self.opt_in_group('trust', enabled=True) trustor = self.user_foo trustee = self.user_two trust_id = uuid.uuid4().hex trust_info = {'trustor_user_id': trustor['id'], 'trustee_user_id': trustee['id'], 'project_id': self.tenant_bar['id'], 'expires_at': timeutils. parse_isotime('2031-02-18T18:10:00Z'), 'impersonation': True} self.trust_api.create_trust(trust_id, trust_info, roles=[{'id': 'member'}, {'id': 'other'}, {'id': 'browser'}]) token_id = self.create_token_sample_data( tenant_id=self.tenant_bar['id'], trust_id=trust_id, user_id=trustor['id'], trustee_user_id=trustee['id']) # Ensure the token id exists in both the trustor and trustee token # lists self.assertIn(token_id, self.token_api.list_tokens(self.user_two['id'], trust_id=trust_id)) self.assertIn(token_id, self.token_api.list_tokens(self.user_foo['id'], trust_id=trust_id)) "," user_id=""testuserid""):",65,8
openstack%2Fsolum~master~Id42c31895edf226a53044d59dd8ec1e9ee137458,openstack/solum,master,Id42c31895edf226a53044d59dd8ec1e9ee137458,Add more assertEqual checks to test_plan.py,MERGED,2014-03-05 19:33:56.000000000,2014-03-06 02:22:24.000000000,2014-03-06 02:22:24.000000000,"[{'_account_id': 3}, {'_account_id': 668}, {'_account_id': 2506}, {'_account_id': 4715}, {'_account_id': 8443}]","[{'number': 1, 'created': '2014-03-05 19:33:56.000000000', 'files': ['solum/tests/api/handlers/test_plan.py'], 'web_link': 'https://opendev.org/openstack/solum/commit/4ddf032f4ed4e8902698bc27ac9897f1248038fe', 'message': 'Add more assertEqual checks to test_plan.py\n\nChange-Id: Id42c31895edf226a53044d59dd8ec1e9ee137458\nCloses-Bug: #1285480\n'}]",0,78390,4ddf032f4ed4e8902698bc27ac9897f1248038fe,10,5,1,9113,,,0,"Add more assertEqual checks to test_plan.py

Change-Id: Id42c31895edf226a53044d59dd8ec1e9ee137458
Closes-Bug: #1285480
",git fetch https://review.opendev.org/openstack/solum refs/changes/90/78390/1 && git format-patch -1 --stdout FETCH_HEAD,['solum/tests/api/handlers/test_plan.py'],1,4ddf032f4ed4e8902698bc27ac9897f1248038fe,bug/1285480," data = {'user_id': 'new_user_id', 'name': 'new_name', 'project_id': 'new_proj_id', 'uuid': 'new_uuid'} self.assertEqual(db_obj.name, res.name) self.assertEqual(db_obj.project_id, res.project_id) self.assertEqual(db_obj.uuid, res.uuid)", data = {'user_id': 'new_user_id'},5,1
openstack%2Fsolum~master~Idabcb7dc48520398949ba098a66bc2f6f35333a8,openstack/solum,master,Idabcb7dc48520398949ba098a66bc2f6f35333a8,Use create_all instead of alembic upgrade in the tests,MERGED,2014-03-05 23:22:37.000000000,2014-03-06 02:20:20.000000000,2014-03-06 02:20:20.000000000,"[{'_account_id': 3}, {'_account_id': 668}, {'_account_id': 8334}]","[{'number': 1, 'created': '2014-03-05 23:22:37.000000000', 'files': ['solum/tests/utils.py'], 'web_link': 'https://opendev.org/openstack/solum/commit/691c442e56ecd437c725d3215ed1c5f39bb39aab', 'message': 'Use create_all instead of alembic upgrade in the tests\n\nWe use sqlite in the tests and sqlite does not support\nalter column type for an existing table -\nhttp://sqlite.org/lang_altertable.html\n\ncreate_all flatterns the schema and applies in one (no alter columns)\n\nChange-Id: Idabcb7dc48520398949ba098a66bc2f6f35333a8\n'}]",1,78451,691c442e56ecd437c725d3215ed1c5f39bb39aab,7,3,1,4715,,,0,"Use create_all instead of alembic upgrade in the tests

We use sqlite in the tests and sqlite does not support
alter column type for an existing table -
http://sqlite.org/lang_altertable.html

create_all flatterns the schema and applies in one (no alter columns)

Change-Id: Idabcb7dc48520398949ba098a66bc2f6f35333a8
",git fetch https://review.opendev.org/openstack/solum refs/changes/51/78451/1 && git format-patch -1 --stdout FETCH_HEAD,['solum/tests/utils.py'],1,691c442e56ecd437c725d3215ed1c5f39bb39aab,test-sqlite,from solum.objects.sqlalchemy import models models.Base.metadata.create_all(self.engine),"import os.pathfrom solum.openstack.common.db.sqlalchemy.migration_cli \ import manager as migration_manager self.upgrade() def upgrade(self): alembic_path = os.path.join(os.path.dirname(__file__), '..', 'objects', 'sqlalchemy', 'migration', 'alembic.ini') migrate_path = os.path.join(os.path.dirname(__file__), '..', 'objects', 'sqlalchemy', 'migration', 'alembic_migrations') migration_config = {'alembic_ini_path': alembic_path, 'migration_repo_path': migrate_path, 'alembic_repo_path': migrate_path} manager = migration_manager.MigrationManager(migration_config) manager.upgrade('head') ",2,18
openstack%2Fsolum~master~Id1b8629721494c3850c0030982b21a5d0458461a,openstack/solum,master,Id1b8629721494c3850c0030982b21a5d0458461a,Connect Language Pack API to DB,MERGED,2014-02-21 16:30:08.000000000,2014-03-06 02:12:24.000000000,2014-03-06 02:12:24.000000000,"[{'_account_id': 3}, {'_account_id': 668}, {'_account_id': 2506}, {'_account_id': 4715}, {'_account_id': 6427}, {'_account_id': 8334}, {'_account_id': 8443}, {'_account_id': 9095}, {'_account_id': 9113}, {'_account_id': 9537}, {'_account_id': 9548}, {'_account_id': 9808}]","[{'number': 1, 'created': '2014-02-21 16:30:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/solum/commit/5bdd96c69a072acbc824fa197a700a0bb589dca5', 'message': 'Connect Language Pack API to DB\n\nChange-Id: Id1b8629721494c3850c0030982b21a5d0458461a\n'}, {'number': 2, 'created': '2014-02-26 01:15:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/solum/commit/af16790b396c41e7f04d686e635702badec9e2de', 'message': 'Connect Language Pack API to DB\n\nChange-Id: Id1b8629721494c3850c0030982b21a5d0458461a\n'}, {'number': 3, 'created': '2014-02-27 18:37:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/solum/commit/4b5d673930cdbf270cd2b2a685380fa5589ebff1', 'message': 'Connect Language Pack API to DB\n\nChange-Id: Id1b8629721494c3850c0030982b21a5d0458461a\n'}, {'number': 4, 'created': '2014-02-27 18:38:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/solum/commit/c4be53d2fe20f844fb4f10a0f6c50c510eabe31a', 'message': 'Connect Language Pack API to DB\n\nChange-Id: Id1b8629721494c3850c0030982b21a5d0458461a\n'}, {'number': 5, 'created': '2014-02-27 21:18:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/solum/commit/60cc3b0ab8eca47f14c93f8952453f1fe0314534', 'message': 'Connect Language Pack API to DB\n\nChange-Id: Id1b8629721494c3850c0030982b21a5d0458461a\n'}, {'number': 6, 'created': '2014-02-28 23:41:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/solum/commit/e352ef9202c297f8a8ed0e7623457d27d256533d', 'message': 'Connect Language Pack API to DB\n\nChange-Id: Id1b8629721494c3850c0030982b21a5d0458461a\n'}, {'number': 7, 'created': '2014-03-03 17:14:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/solum/commit/65c90938dbe7298bbe4ca4df9231e1fac81bf61b', 'message': 'Connect Language Pack API to DB\n\nChange-Id: Id1b8629721494c3850c0030982b21a5d0458461a\n'}, {'number': 8, 'created': '2014-03-04 17:47:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/solum/commit/d514cc12b8df1be4ff8200201433e42295d08f5f', 'message': 'Connect Language Pack API to DB\n\nChange-Id: Id1b8629721494c3850c0030982b21a5d0458461a\n'}, {'number': 9, 'created': '2014-03-05 19:11:13.000000000', 'files': ['solum/tests/api/v1/test_lp_handler.py', 'solum/tests/api/v1/test_language_pack.py', 'solum/api/controllers/v1/language_pack.py', 'solum/tests/fakes.py', 'solum/api/handlers/language_pack_handler.py'], 'web_link': 'https://opendev.org/openstack/solum/commit/b436465c8cacb7b54af4372beed68fc6ff507e12', 'message': 'Connect Language Pack API to DB\n\nChange-Id: Id1b8629721494c3850c0030982b21a5d0458461a\n'}]",26,75452,b436465c8cacb7b54af4372beed68fc6ff507e12,70,12,9,9113,,,0,"Connect Language Pack API to DB

Change-Id: Id1b8629721494c3850c0030982b21a5d0458461a
",git fetch https://review.opendev.org/openstack/solum refs/changes/52/75452/9 && git format-patch -1 --stdout FETCH_HEAD,"['solum/tests/api/v1/test_language_pack.py', 'solum/tests/api/handlers/test_lp_handler.py', 'solum/api/controllers/v1/language_pack.py', 'solum/objects/sqlalchemy/language_pack.py', 'solum/tests/fakes.py', 'solum/api/handlers/language_pack_handler.py']",6,5bdd96c69a072acbc824fa197a700a0bb589dca5,75452,"from solum import objects def __init__(self): super(LanguagePackHandler, self).__init__() objects.load() def get(self, id): """"""Return a language pack."""""" return objects.registry.LanguagePack.get_by_uuid(None, id) return objects.registry.LanguagePackList.get_all(None)","from solum.api.controllers.v1.datamodel import language_pack def get(self, id): response = language_pack.LanguagePack.sample() return response response = [] return response",93,26
openstack%2Fswift~master~I4880e0a790dabb84e8c55fe11c36df41aeb0c739,openstack/swift,master,I4880e0a790dabb84e8c55fe11c36df41aeb0c739,sanity check copy tests,MERGED,2014-03-04 07:38:47.000000000,2014-03-06 02:06:30.000000000,2014-03-06 02:06:30.000000000,"[{'_account_id': 3}, {'_account_id': 917}, {'_account_id': 995}]","[{'number': 1, 'created': '2014-03-04 07:38:47.000000000', 'files': ['test/unit/proxy/test_server.py', 'test/unit/__init__.py'], 'web_link': 'https://opendev.org/openstack/swift/commit/20466d80fa9adbe0cc6f90c075577feaefe417db', 'message': 'sanity check copy tests\n\nChange-Id: I4880e0a790dabb84e8c55fe11c36df41aeb0c739\n'}]",0,77811,20466d80fa9adbe0cc6f90c075577feaefe417db,9,3,1,1179,,,0,"sanity check copy tests

Change-Id: I4880e0a790dabb84e8c55fe11c36df41aeb0c739
",git fetch https://review.opendev.org/openstack/swift refs/changes/11/77811/1 && git format-patch -1 --stdout FETCH_HEAD,"['test/unit/proxy/test_server.py', 'test/unit/__init__.py']",2,20466d80fa9adbe0cc6f90c075577feaefe417db,bug/667956, connect.code_iter = code_iter ,,271,252
openstack%2Foslo.messaging~master~I0c056efd9fb8b48d02a11dfb969ee98b736ba017,openstack/oslo.messaging,master,I0c056efd9fb8b48d02a11dfb969ee98b736ba017,Adds unit test cases to impl_qpid,MERGED,2014-02-24 12:36:30.000000000,2014-03-06 02:06:29.000000000,2014-03-06 02:06:28.000000000,"[{'_account_id': 3}, {'_account_id': 1247}, {'_account_id': 2472}, {'_account_id': 2813}, {'_account_id': 6928}, {'_account_id': 9107}, {'_account_id': 10237}]","[{'number': 1, 'created': '2014-02-24 12:36:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.messaging/commit/b2d7160f64dac09efe835bedfc7a45da938bb925', 'message': 'Adds unit test cases to impl_qpid\n\nChange-Id: I0c056efd9fb8b48d02a11dfb969ee98b736ba017\nPartial-Bug: #1255239\n'}, {'number': 2, 'created': '2014-02-26 18:14:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.messaging/commit/d1be3521a1489569b720447735a717c6d58d3e78', 'message': 'Adds unit test cases to impl_qpid\n\nChange-Id: I0c056efd9fb8b48d02a11dfb969ee98b736ba017\nPartial-Bug: #1255239\n'}, {'number': 3, 'created': '2014-02-28 15:08:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.messaging/commit/dc58b9f369c5181474c7ef44130104cfdcecefec', 'message': 'Adds unit test cases to impl_qpid\n\nChange-Id: I0c056efd9fb8b48d02a11dfb969ee98b736ba017\nCloses-Bug: #1255239\n'}, {'number': 4, 'created': '2014-03-03 15:31:39.000000000', 'files': ['tests/test_qpid.py', 'test-requirements.txt'], 'web_link': 'https://opendev.org/openstack/oslo.messaging/commit/c872f8d67045fb287850d8cdc1ba4b865c84c19c', 'message': 'Adds unit test cases to impl_qpid\n\nChange-Id: I0c056efd9fb8b48d02a11dfb969ee98b736ba017\nCloses-Bug: #1255239\n'}]",79,75853,c872f8d67045fb287850d8cdc1ba4b865c84c19c,32,7,4,10237,,,0,"Adds unit test cases to impl_qpid

Change-Id: I0c056efd9fb8b48d02a11dfb969ee98b736ba017
Closes-Bug: #1255239
",git fetch https://review.opendev.org/openstack/oslo.messaging refs/changes/53/75853/3 && git format-patch -1 --stdout FETCH_HEAD,"['tests/test_qpid.py', 'test-requirements.txt']",2,b2d7160f64dac09efe835bedfc7a45da938bb925,bug/1255239,qpid-python ,,742,0
openstack%2Foslo.messaging~master~I5c8ddaf451f7c977d8c400fe920512cdafbc7fdf,openstack/oslo.messaging,master,I5c8ddaf451f7c977d8c400fe920512cdafbc7fdf,Expose PublishErrorsHandler through oslo.messaging,MERGED,2014-03-03 23:04:38.000000000,2014-03-06 02:06:28.000000000,2014-03-06 02:06:28.000000000,"[{'_account_id': 3}, {'_account_id': 2472}, {'_account_id': 5046}, {'_account_id': 5638}, {'_account_id': 6928}]","[{'number': 1, 'created': '2014-03-03 23:04:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.messaging/commit/a75cc84d495cd901c32e1d98d2641d4f91e2b40d', 'message': 'Expose PublishErrorsHandler through oslo.messaging\n\nFix up the imports so that the log handler for publishing\nerror messages is available through the oslo.messaging\npackage instead of users having to know the full path\ninside the sub-module.\n\nChange-Id: I5c8ddaf451f7c977d8c400fe920512cdafbc7fdf\n'}, {'number': 2, 'created': '2014-03-03 23:21:49.000000000', 'files': ['oslo/messaging/notify/__init__.py', 'oslo/messaging/notify/log_handler.py'], 'web_link': 'https://opendev.org/openstack/oslo.messaging/commit/7a6f5054fd41def1b935ddf86c1b4a62433a02d4', 'message': 'Expose PublishErrorsHandler through oslo.messaging\n\nFix up the imports so that the log handler for publishing\nerror messages is available through the oslo.messaging\npackage instead of users having to know the full path\ninside the sub-module.\n\nChange-Id: I5c8ddaf451f7c977d8c400fe920512cdafbc7fdf\n'}]",0,77724,7a6f5054fd41def1b935ddf86c1b4a62433a02d4,12,5,2,2472,,,0,"Expose PublishErrorsHandler through oslo.messaging

Fix up the imports so that the log handler for publishing
error messages is available through the oslo.messaging
package instead of users having to know the full path
inside the sub-module.

Change-Id: I5c8ddaf451f7c977d8c400fe920512cdafbc7fdf
",git fetch https://review.opendev.org/openstack/oslo.messaging refs/changes/24/77724/1 && git format-patch -1 --stdout FETCH_HEAD,"['oslo/messaging/notify/__init__.py', 'oslo/messaging/notify/log_handler.py']",2,a75cc84d495cd901c32e1d98d2641d4f91e2b40d,doc-log-handler, # NOTE(dhellmann): Avoid a cyclical import by doing this one # at runtime. from oslo import messaging,from oslo import messaging,4,1
openstack%2Fneutron~master~I9ae28b6f84f1914fc4d53f7ad1f7742baa50dea9,openstack/neutron,master,I9ae28b6f84f1914fc4d53f7ad1f7742baa50dea9,Updated from global requirements,MERGED,2014-03-05 19:24:59.000000000,2014-03-06 01:56:22.000000000,2014-03-06 01:56:21.000000000,"[{'_account_id': 3}, {'_account_id': 2592}, {'_account_id': 5170}, {'_account_id': 9008}, {'_account_id': 9787}, {'_account_id': 9845}, {'_account_id': 9846}, {'_account_id': 10294}, {'_account_id': 10387}]","[{'number': 1, 'created': '2014-03-05 19:24:59.000000000', 'files': ['requirements.txt'], 'web_link': 'https://opendev.org/openstack/neutron/commit/58437d384a800100a4ecce38fb4fc9fc344f1632', 'message': 'Updated from global requirements\n\nChange-Id: I9ae28b6f84f1914fc4d53f7ad1f7742baa50dea9\n'}]",0,78377,58437d384a800100a4ecce38fb4fc9fc344f1632,17,9,1,3,,,0,"Updated from global requirements

Change-Id: I9ae28b6f84f1914fc4d53f7ad1f7742baa50dea9
",git fetch https://review.opendev.org/openstack/neutron refs/changes/77/78377/1 && git format-patch -1 --stdout FETCH_HEAD,['requirements.txt'],1,58437d384a800100a4ecce38fb4fc9fc344f1632,openstack/requirements,python-novaclient>=2.16.0,python-novaclient>=2.15.0,1,1
openstack%2Fdevstack~stable%2Fhavana~I860cb27a33a4147765b75f0b130782cbc19af9ce,openstack/devstack,stable/havana,I860cb27a33a4147765b75f0b130782cbc19af9ce,Backport screen_stop to help with Grenade,MERGED,2014-03-04 23:11:28.000000000,2014-03-06 01:56:14.000000000,2014-03-06 01:56:13.000000000,"[{'_account_id': 3}, {'_account_id': 970}, {'_account_id': 2750}]","[{'number': 1, 'created': '2014-03-04 23:11:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack/commit/25b681b83ddee59497dc94885256d3be70e2d6f2', 'message': 'backports\n\n* https://github.com/openstack-dev/devstack/commit/9fc8792b0ac7525b4c353b0a55b8b80eabf76e2a\n  https://review.openstack.org/66080\n* https://github.com/openstack-dev/devstack/commit/579af5d6786f62008807a473749600e88cea21fc\n  https://review.openstack.org/68699\n\nChange-Id: I860cb27a33a4147765b75f0b130782cbc19af9ce\n'}, {'number': 2, 'created': '2014-03-04 23:12:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack/commit/1270dd67c9606e9f51168ef0f7fa8d47bd3add9f', 'message': 'Backport screen_stop to help with Grenade\n\nBack port these commits to stable/havana:\n* https://github.com/openstack-dev/devstack/commit/9fc8792b0ac7525b4c353b0a55b8b80eabf76e2a\n  https://review.openstack.org/66080\n* https://github.com/openstack-dev/devstack/commit/579af5d6786f62008807a473749600e88cea21fc\n  https://review.openstack.org/68699\n\nChange-Id: I860cb27a33a4147765b75f0b130782cbc19af9ce\n'}, {'number': 3, 'created': '2014-03-05 04:41:19.000000000', 'files': ['lib/ceilometer', 'lib/cinder', 'functions', 'lib/nova', 'lib/heat', 'lib/keystone', 'lib/glance', 'unstack.sh', 'stackrc', 'lib/trove'], 'web_link': 'https://opendev.org/openstack/devstack/commit/4cc3983443a697d61c97ba15584ceb85f3d154e5', 'message': 'Backport screen_stop to help with Grenade\n\nBack port these commits to stable/havana:\n* https://github.com/openstack-dev/devstack/commit/9fc8792b0ac7525b4c353b0a55b8b80eabf76e2a\n  https://review.openstack.org/66080\n* https://github.com/openstack-dev/devstack/commit/579af5d6786f62008807a473749600e88cea21fc\n  https://review.openstack.org/68699\n\nChange-Id: I860cb27a33a4147765b75f0b130782cbc19af9ce\n'}]",0,78036,4cc3983443a697d61c97ba15584ceb85f3d154e5,14,3,3,970,,,0,"Backport screen_stop to help with Grenade

Back port these commits to stable/havana:
* https://github.com/openstack-dev/devstack/commit/9fc8792b0ac7525b4c353b0a55b8b80eabf76e2a
  https://review.openstack.org/66080
* https://github.com/openstack-dev/devstack/commit/579af5d6786f62008807a473749600e88cea21fc
  https://review.openstack.org/68699

Change-Id: I860cb27a33a4147765b75f0b130782cbc19af9ce
",git fetch https://review.opendev.org/openstack/devstack refs/changes/36/78036/2 && git format-patch -1 --stdout FETCH_HEAD,"['lib/ceilometer', 'lib/cinder', 'functions', 'lib/nova', 'lib/heat', 'lib/keystone', 'lib/glance', 'unstack.sh', 'stackrc', 'lib/trove']",10,25b681b83ddee59497dc94885256d3be70e2d6f2,st-screen-stop, screen_stop $serv, screen -S $SCREEN_NAME -p $serv -X kill,79,23
openstack%2Fnova~master~I665144b256da0b04267cac754324e5779512e65d,openstack/nova,master,I665144b256da0b04267cac754324e5779512e65d,notifier middleware broken by oslo.messaging,MERGED,2014-02-21 15:03:00.000000000,2014-03-06 01:55:20.000000000,2014-03-06 01:55:16.000000000,"[{'_account_id': 3}, {'_account_id': 1849}, {'_account_id': 2750}, {'_account_id': 5170}, {'_account_id': 6537}, {'_account_id': 6873}, {'_account_id': 9008}, {'_account_id': 9578}]","[{'number': 1, 'created': '2014-02-21 15:03:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/fdcd6503e314f68f74bb7c88089f076decd7842f', 'message': 'POC middleware\n\ntest out pycadf middleware\n\nChange-Id: I665144b256da0b04267cac754324e5779512e65d\n'}, {'number': 2, 'created': '2014-02-24 00:53:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/365d85f93e6d72e9b6eb1cd327e61a55b7504be7', 'message': 'POC middleware\n\ntest out pycadf middleware\n\nChange-Id: I665144b256da0b04267cac754324e5779512e65d\n'}, {'number': 3, 'created': '2014-02-24 15:54:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/4c1652ffeaef58c3fdc86f46478f19b8bc12c1ac', 'message': 'notifier middleware broken by oslo.messaging\n\naudit middleware in oslo-incubator is incompatible with oslo.messaging.\nan oslo.messaging compatible version is available in pycadf library.\nenable audit by default to better test for integration issues\n\nCloses-Bug: #1280327\nChange-Id: I665144b256da0b04267cac754324e5779512e65d\n'}, {'number': 4, 'created': '2014-02-24 16:01:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/ad8a7a4159c01066650fc06486f0be6731d518b7', 'message': 'notifier middleware broken by oslo.messaging\n\naudit middleware in oslo-incubator is incompatible with oslo.messaging.\nan oslo.messaging compatible version is available in pycadf library.\nenable audit by default to better test for integration issues\n\nCloses-Bug: #1280327\nChange-Id: I665144b256da0b04267cac754324e5779512e65d\n'}, {'number': 5, 'created': '2014-02-28 19:06:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/21a5e8abb218abfac834a4ffb239abd369a145ed', 'message': 'notifier middleware broken by oslo.messaging\n\naudit middleware in oslo-incubator is incompatible with oslo.messaging.\nan oslo.messaging compatible version is available in pycadf library.\nenable audit by default to better test for integration issues\n\nremove middleware in this patch\n\nPartial-Bug: #1280327\nChange-Id: I665144b256da0b04267cac754324e5779512e65d\n'}, {'number': 6, 'created': '2014-02-28 19:28:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/904bddf48022bbfa8237aacaddc10641830515ea', 'message': 'notifier middleware broken by oslo.messaging\n\naudit middleware in oslo-incubator is incompatible with oslo.messaging.\nan oslo.messaging compatible version is available in pycadf library.\nenable audit by default to better test for integration issues\n\nremove broken oslo-incubator code in this patch\n\nPartial-Bug: #1280327\nChange-Id: I665144b256da0b04267cac754324e5779512e65d\n'}, {'number': 7, 'created': '2014-02-28 20:48:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/f2df65e91f45e59c1f38940fb7cf0ef5892709af', 'message': 'notifier middleware broken by oslo.messaging\n\naudit middleware in oslo-incubator is incompatible with oslo.messaging.\nan oslo.messaging compatible version is available in pycadf library.\nremove broken oslo-incubator code in this patch\n\nPartial-Bug: #1280327\nChange-Id: I665144b256da0b04267cac754324e5779512e65d\n'}, {'number': 8, 'created': '2014-02-28 20:53:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/fea8d81ebe60077e8373b5d0671b93636ad734b8', 'message': 'notifier middleware broken by oslo.messaging\n\naudit middleware in oslo-incubator is incompatible with oslo.messaging.\nan oslo.messaging compatible version is available in pycadf library.\nenable audit by default to better test for integration issues\n\nremove broken oslo-incubator code in this patch\n\nPartial-Bug: #1280327\nChange-Id: I665144b256da0b04267cac754324e5779512e65d\n'}, {'number': 9, 'created': '2014-02-28 20:56:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/144a64a8b624e65a695e90bddce2dd0c850639d4', 'message': 'notifier middleware broken by oslo.messaging\n\naudit middleware in oslo-incubator is incompatible with oslo.messaging.\nan oslo.messaging compatible version is available in pycadf library.\nremove broken oslo-incubator code in this patch.\n\nPartial-Bug: #1280327\nChange-Id: I665144b256da0b04267cac754324e5779512e65d\n'}, {'number': 10, 'created': '2014-03-03 21:19:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/2fe38cf19686716ae4349d0a504598efeb103afd', 'message': 'notifier middleware broken by oslo.messaging\n\naudit middleware in oslo-incubator is incompatible with oslo.messaging.\nan oslo.messaging compatible version is available in pycadf library.\nremove broken oslo-incubator code in this patch.\n\nPartial-Bug: #1280327\nChange-Id: I665144b256da0b04267cac754324e5779512e65d\n'}, {'number': 11, 'created': '2014-03-04 21:29:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/513c38d5bc696f810279b6f0e9f9a7a5dda305eb', 'message': 'notifier middleware broken by oslo.messaging\n\naudit middleware in oslo-incubator is incompatible with oslo.messaging.\nan oslo.messaging compatible version is available in pycadf library.\nremove broken oslo-incubator code in this patch.\n\nPartial-Bug: #1280327\nChange-Id: I665144b256da0b04267cac754324e5779512e65d\n'}, {'number': 12, 'created': '2014-03-04 22:04:28.000000000', 'files': ['nova/openstack/common/middleware/audit.py', 'nova/openstack/common/middleware/notifier.py', 'openstack-common.conf'], 'web_link': 'https://opendev.org/openstack/nova/commit/784372985907dd88771e4ee1ff32305022b49e78', 'message': 'notifier middleware broken by oslo.messaging\n\naudit middleware in oslo-incubator is incompatible with oslo.messaging.\nan oslo.messaging compatible version is available in pycadf library.\nremove broken oslo-incubator code in this patch.\n\nalso add middleware/request_id to openstack-common.conf so we continue\nto pull in request_id middleware but not audit/notifier.\n\nPartial-Bug: #1280327\nChange-Id: I665144b256da0b04267cac754324e5779512e65d\n'}]",15,75426,784372985907dd88771e4ee1ff32305022b49e78,110,8,12,6537,,,0,"notifier middleware broken by oslo.messaging

audit middleware in oslo-incubator is incompatible with oslo.messaging.
an oslo.messaging compatible version is available in pycadf library.
remove broken oslo-incubator code in this patch.

also add middleware/request_id to openstack-common.conf so we continue
to pull in request_id middleware but not audit/notifier.

Partial-Bug: #1280327
Change-Id: I665144b256da0b04267cac754324e5779512e65d
",git fetch https://review.opendev.org/openstack/nova refs/changes/26/75426/6 && git format-patch -1 --stdout FETCH_HEAD,['etc/nova/api-paste.ini'],1,fdcd6503e314f68f74bb7c88089f076decd7842f,audit,keystone = faultwrap sizelimit authtoken keystonecontext ratelimit audit osapi_compute_app_v2 keystone_nolimit = faultwrap sizelimit authtoken keystonecontext audit osapi_compute_app_v2keystone = faultwrap sizelimit authtoken keystonecontext audit osapi_compute_app_v3 [filter:audit] paste.filter_factory = pycadf.middleware.audit:AuditMiddleware.factory,keystone = faultwrap sizelimit authtoken keystonecontext ratelimit osapi_compute_app_v2 keystone_nolimit = faultwrap sizelimit authtoken keystonecontext osapi_compute_app_v2keystone = faultwrap sizelimit authtoken keystonecontext osapi_compute_app_v3,6,3
openstack%2Fneutron~master~I8907f52c07f9be04e022a17265e9ad8a51d0acec,openstack/neutron,master,I8907f52c07f9be04e022a17265e9ad8a51d0acec,Optimize the use of sqlalchemy's query,ABANDONED,2014-03-03 09:50:25.000000000,2014-03-06 01:48:18.000000000,,"[{'_account_id': 3}, {'_account_id': 841}, {'_account_id': 2592}, {'_account_id': 6072}, {'_account_id': 9681}, {'_account_id': 9732}, {'_account_id': 9787}, {'_account_id': 9925}, {'_account_id': 10116}, {'_account_id': 10192}, {'_account_id': 10294}]","[{'number': 1, 'created': '2014-03-03 09:50:25.000000000', 'files': ['neutron/db/l3_db.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/9faf53bb9426e94c011a68a323bbda91977781b1', 'message': ""Optimize the use of sqlalchemy's query\n\nThe filter is separated from query witch will affect the\nefficiency of the query.\nsuch as:\nrport_qry = context.session.query(models_v2.Port)\nrports = rport_qry.filter_by(device_id=router_id)\nThere will do as two steps:\n1, select * from table\n2, filter the query result\nbut rports = context.session.query(models_v2.Port).\n    filter_by(device_id=router_id)\njust do one step:\nselect * from table where device_id=router_id\n\nChange-Id: I8907f52c07f9be04e022a17265e9ad8a51d0acec\nCloses-Bug: #1287077\n""}]",0,77542,9faf53bb9426e94c011a68a323bbda91977781b1,14,11,1,9560,,,0,"Optimize the use of sqlalchemy's query

The filter is separated from query witch will affect the
efficiency of the query.
such as:
rport_qry = context.session.query(models_v2.Port)
rports = rport_qry.filter_by(device_id=router_id)
There will do as two steps:
1, select * from table
2, filter the query result
but rports = context.session.query(models_v2.Port).
    filter_by(device_id=router_id)
just do one step:
select * from table where device_id=router_id

Change-Id: I8907f52c07f9be04e022a17265e9ad8a51d0acec
Closes-Bug: #1287077
",git fetch https://review.opendev.org/openstack/neutron refs/changes/42/77542/1 && git format-patch -1 --stdout FETCH_HEAD,['neutron/db/l3_db.py'],1,9faf53bb9426e94c011a68a323bbda91977781b1,bug/1287077, rports = (context.session.query(models_v2.Port). filter_by(device_id=router_id)), rport_qry = context.session.query(models_v2.Port) rports = rport_qry.filter_by(device_id=router_id),2,2
openstack%2Fopenstack-manuals~master~I1910dc00104fc3eaf26055623c4611c42bdb5338,openstack/openstack-manuals,master,I1910dc00104fc3eaf26055623c4611c42bdb5338,Clarify VMware ephemeral disks expectations.,MERGED,2014-03-05 20:04:30.000000000,2014-03-06 01:46:19.000000000,2014-03-06 01:46:18.000000000,"[{'_account_id': 3}, {'_account_id': 6547}, {'_account_id': 6843}, {'_account_id': 9162}]","[{'number': 1, 'created': '2014-03-05 20:04:30.000000000', 'files': ['doc/config-reference/compute/section_hypervisor_vmware.xml'], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/04ae05f26523d40eb62dcf0b0b8093e49cefff23', 'message': ""Clarify VMware ephemeral disks expectations.\n\nThe previous text indicated that ephemeral disk support was expected in\nan upcoming stable release and the lack of such support was temporary in\nnature.\n\nAs this looks to have been the case for the life of this driver, and\nthe fix recently pushed out to Juno, I'm updating to clarify\nexpectations.\n\nIn particular:\n\n* The fix is expected in an upcoming major release, not a stable branch\n  update.\n* Given the above the situation is not temporary.\n\nChange-Id: I1910dc00104fc3eaf26055623c4611c42bdb5338\n""}]",0,78397,04ae05f26523d40eb62dcf0b0b8093e49cefff23,7,4,1,6772,,,0,"Clarify VMware ephemeral disks expectations.

The previous text indicated that ephemeral disk support was expected in
an upcoming stable release and the lack of such support was temporary in
nature.

As this looks to have been the case for the life of this driver, and
the fix recently pushed out to Juno, I'm updating to clarify
expectations.

In particular:

* The fix is expected in an upcoming major release, not a stable branch
  update.
* Given the above the situation is not temporary.

Change-Id: I1910dc00104fc3eaf26055623c4611c42bdb5338
",git fetch https://review.opendev.org/openstack/openstack-manuals refs/changes/97/78397/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/config-reference/compute/section_hypervisor_vmware.xml'],1,04ae05f26523d40eb62dcf0b0b8093e49cefff23,, Ephemeral disks are not supported. A future major release will address this limitation.</para>, Ephemeral disks are not supported. A future stable release will address this temporary limitation.</para>,2,2
openstack%2Ftripleo-heat-templates~master~Ibea723d4c763f593d934a9d2acfd31ce369f6408,openstack/tripleo-heat-templates,master,Ibea723d4c763f593d934a9d2acfd31ce369f6408,Fix Merge::Map for scatter-gather in Configs.,MERGED,2014-03-05 22:03:48.000000000,2014-03-06 01:45:46.000000000,2014-03-06 01:45:46.000000000,"[{'_account_id': 3}, {'_account_id': 4190}, {'_account_id': 6488}, {'_account_id': 7144}, {'_account_id': 10035}]","[{'number': 1, 'created': '2014-03-05 22:03:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/d181f119a2a7c7192f62daab4752daa331d05198', 'message': 'Fix Merge::Map for scatter-gather in Configs.\n\nWhen Merge::Map was used like so:\n\nNovaCompute0Config:\n  Merge::Map:\n    NovaCompute0:\n      Fn:....\n\nWe were adjusting the inner NovaCompute0 to the current scaling loop\nposition rather than exploding it out as part of the map. For now, we\nwany maps to be global in context so the fix is fortunately simple.\n\nChange-Id: Ibea723d4c763f593d934a9d2acfd31ce369f6408\n'}, {'number': 2, 'created': '2014-03-05 23:38:58.000000000', 'files': ['examples/scale_map_result.yaml', 'tripleo_heat_merge/merge.py'], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/1879dc0800e8015e201f4698c1214a0e525f7ee3', 'message': 'Fix Merge::Map for scatter-gather in Configs.\n\nWhen Merge::Map was used like so:\n\nNovaCompute0Config:\n  Merge::Map:\n    NovaCompute0:\n      Fn:....\n\nWe were adjusting the inner NovaCompute0 to the current scaling loop\nposition rather than exploding it out as part of the map. For now, we\nwant maps to be global in context so the fix is fortunately simple.\n\nChange-Id: Ibea723d4c763f593d934a9d2acfd31ce369f6408\n'}]",1,78436,1879dc0800e8015e201f4698c1214a0e525f7ee3,16,5,2,4190,,,0,"Fix Merge::Map for scatter-gather in Configs.

When Merge::Map was used like so:

NovaCompute0Config:
  Merge::Map:
    NovaCompute0:
      Fn:....

We were adjusting the inner NovaCompute0 to the current scaling loop
position rather than exploding it out as part of the map. For now, we
want maps to be global in context so the fix is fortunately simple.

Change-Id: Ibea723d4c763f593d934a9d2acfd31ce369f6408
",git fetch https://review.opendev.org/openstack/tripleo-heat-templates refs/changes/36/78436/1 && git format-patch -1 --stdout FETCH_HEAD,"['examples/scale_map_result.yaml', 'tripleo_heat_merge/merge.py']",2,d181f119a2a7c7192f62daab4752daa331d05198,, Keys in dicts are copied per the scaling rule. in_copies is reset to None when a dict {'Merge::Map': someobject} is encountered. if 'Merge::Map' in template: in_copies = None, Keys in dicts are always copied per the scaling rule.,138,1
openstack%2Ftripleo-heat-templates~master~Idf5bb882f798d22d4513756b5273d4ae19caa5c0,openstack/tripleo-heat-templates,master,Idf5bb882f798d22d4513756b5273d4ae19caa5c0,Add a check target.,MERGED,2014-03-05 21:42:07.000000000,2014-03-06 01:45:46.000000000,2014-03-06 01:45:46.000000000,"[{'_account_id': 3}, {'_account_id': 4190}, {'_account_id': 6488}, {'_account_id': 7144}, {'_account_id': 9369}, {'_account_id': 10035}]","[{'number': 1, 'created': '2014-03-05 21:42:07.000000000', 'files': ['Makefile'], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/9df35c186f14d3b3b76a3946981ad6ec5cf9336f', 'message': ""Add a check target.\n\nJust developer convenience - I'm used to autotools 'make check'\nenvironments.\n\nChange-Id: Idf5bb882f798d22d4513756b5273d4ae19caa5c0\n""}]",0,78425,9df35c186f14d3b3b76a3946981ad6ec5cf9336f,11,6,1,4190,,,0,"Add a check target.

Just developer convenience - I'm used to autotools 'make check'
environments.

Change-Id: Idf5bb882f798d22d4513756b5273d4ae19caa5c0
",git fetch https://review.opendev.org/openstack/tripleo-heat-templates refs/changes/25/78425/1 && git format-patch -1 --stdout FETCH_HEAD,['Makefile'],1,9df35c186f14d3b3b76a3946981ad6ec5cf9336f,,check: test .PHONY: clean overcloud.yaml check,.PHONY: clean overcloud.yaml,3,1
openstack%2Fkeystone~master~I6cda3c5f36c9754ab84e28ff9a9289887d6c9b77,openstack/keystone,master,I6cda3c5f36c9754ab84e28ff9a9289887d6c9b77,allow create credential with the system admin token,MERGED,2014-02-03 21:28:09.000000000,2014-03-06 01:44:18.000000000,2014-03-06 01:44:17.000000000,"[{'_account_id': 3}, {'_account_id': 4}, {'_account_id': 1916}, {'_account_id': 2903}, {'_account_id': 6486}]","[{'number': 1, 'created': '2014-02-03 21:28:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/4ed4d1974c34e43cc111f772827d1369583eff6d', 'message': ""allow create credential with the system admin token\n\nWe are looking up trust_id during create credential, which means caller must\nuse a Keystone-issued token. This is unrealistic as create credential are\noften done as part of bootstrap, using the static system admin token.\nFurthermore, deployments which using external authorization will break as it\nmay not have a token_id in the request context.\n\nFor the above reasons, we'll skip trust_id lookup if the request token_id is\neither absent or it is the static system admin token.\n\ncloses bug 1275145\n\nChange-Id: I6cda3c5f36c9754ab84e28ff9a9289887d6c9b77\n""}, {'number': 2, 'created': '2014-03-05 03:13:02.000000000', 'files': ['keystone/common/wsgi.py', 'keystone/tests/test_v3_credential.py'], 'web_link': 'https://opendev.org/openstack/keystone/commit/b5ab8fe9d63dd65786dd13adee2a6dd25b7c483a', 'message': ""allow create credential with the system admin token\n\nWe are looking up trust_id during create credential, which means caller must\nuse a Keystone-issued token. This is unrealistic as create credential are\noften done as part of bootstrap, using the static system admin token.\nFurthermore, deployments which using external authorization will break as it\nmay not have a token_id in the request context.\n\nFor the above reasons, we'll skip trust_id lookup if the request token_id is\neither absent or it is the static system admin token.\n\ncloses bug 1275145\ncloses bug 1263804\n\nChange-Id: I6cda3c5f36c9754ab84e28ff9a9289887d6c9b77\n""}]",3,70847,b5ab8fe9d63dd65786dd13adee2a6dd25b7c483a,18,5,2,1916,,,0,"allow create credential with the system admin token

We are looking up trust_id during create credential, which means caller must
use a Keystone-issued token. This is unrealistic as create credential are
often done as part of bootstrap, using the static system admin token.
Furthermore, deployments which using external authorization will break as it
may not have a token_id in the request context.

For the above reasons, we'll skip trust_id lookup if the request token_id is
either absent or it is the static system admin token.

closes bug 1275145
closes bug 1263804

Change-Id: I6cda3c5f36c9754ab84e28ff9a9289887d6c9b77
",git fetch https://review.opendev.org/openstack/keystone refs/changes/47/70847/2 && git format-patch -1 --stdout FETCH_HEAD,"['keystone/common/wsgi.py', 'keystone/tests/test_v3_credential.py']",2,4ed4d1974c34e43cc111f772827d1369583eff6d,bug/1275145,"from keystone import configCONF = config.CONF def test_create_credential_with_admin_token(self): # Make sure we can create credential with the static admin token ref = self.new_credential_ref(user_id=self.user['id']) r = self.post( '/credentials', body={'credential': ref}, token=CONF.admin_token) self.assertValidCredentialResponse(r, ref) ",,19,0
openstack%2Fnova~master~I6d5ee97ffdbd497802379b13e70b84d70d8ded57,openstack/nova,master,I6d5ee97ffdbd497802379b13e70b84d70d8ded57,Prevent thrashing when deploying many bm instances,MERGED,2014-02-05 10:00:02.000000000,2014-03-06 01:43:18.000000000,2014-03-06 01:43:14.000000000,"[{'_account_id': 3}, {'_account_id': 360}, {'_account_id': 1726}, {'_account_id': 1821}, {'_account_id': 1849}, {'_account_id': 2271}, {'_account_id': 2750}, {'_account_id': 2889}, {'_account_id': 4190}, {'_account_id': 5170}, {'_account_id': 9369}, {'_account_id': 9578}]","[{'number': 1, 'created': '2014-02-05 10:00:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/b20dda8cb446567fee3d431eedf9ae100ab940c7', 'message': 'Prevent thrashing when deploying many bm instances\n\nNova BM is easily overwhelmed at the moment because it has to convert\nevery disk image to raw - simply deploying 2 instances at once exceeds\nthe IOPS on most single disk servers. Avoid this by serialising the\nimage conversion (which leads to a lower average-time-to-deploy in\nnearly all situations).\n\nChange-Id: I6d5ee97ffdbd497802379b13e70b84d70d8ded57\n'}, {'number': 2, 'created': '2014-02-05 21:00:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/8468a016908717a2ce31e6a5b471ebf75aea4091', 'message': 'Prevent thrashing when deploying many bm instances\n\nNova BM is easily overwhelmed at the moment because it has to convert\nevery disk image to raw - simply deploying 2 instances at once exceeds\nthe IOPS on most single disk servers. Avoid this by serialising the\nimage conversion (which leads to a lower average-time-to-deploy in\nnearly all situations).\n\nChange-Id: I6d5ee97ffdbd497802379b13e70b84d70d8ded57\n'}, {'number': 3, 'created': '2014-02-13 00:58:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/be7c9ba5a6de6e4625c92aedb36d57659abee5ca', 'message': 'Prevent thrashing when deploying many bm instances\n\nNova BM is easily overwhelmed at the moment because it has to convert\nevery disk image to raw - simply deploying 2 instances at once exceeds\nthe IOPS on most single disk servers. Avoid this by serialising the\nimage conversion (which leads to a lower average-time-to-deploy in\nnearly all situations).\n\nChange-Id: I6d5ee97ffdbd497802379b13e70b84d70d8ded57\n'}, {'number': 4, 'created': '2014-02-19 05:42:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/7f1bc793cfc7160119a24a0d882a0d90bd7c1c37', 'message': 'Prevent thrashing when deploying many bm instances\n\nNova BM is easily overwhelmed at the moment because it has to convert\nevery disk image to raw - simply deploying 2 instances at once exceeds\nthe IOPS on most single disk servers. Avoid this by serialising the\nimage conversion (which leads to a lower average-time-to-deploy in\nnearly all situations).\n\nChange-Id: I6d5ee97ffdbd497802379b13e70b84d70d8ded57\n'}, {'number': 5, 'created': '2014-03-02 22:48:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/da83b6d6530808934d2ec36ec8d3f1aede5803c8', 'message': 'Prevent thrashing when deploying many bm instances\n\nNova BM is easily overwhelmed at the moment because it has to convert\nevery disk image to raw - simply deploying 2 instances at once exceeds\nthe IOPS on most single disk servers. Avoid this by serialising the\nimage conversion (which leads to a lower average-time-to-deploy in\nnearly all situations).\n\nChange-Id: I6d5ee97ffdbd497802379b13e70b84d70d8ded57\nCo-Authored-By: Steve Kowalik <steven@wedontsleep.org>\n'}, {'number': 6, 'created': '2014-03-03 20:39:28.000000000', 'files': ['nova/virt/baremetal/driver.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/8625766c39f39b8b44bf212be6c2820d6736b6f3', 'message': 'Prevent thrashing when deploying many bm instances\n\nNova BM is easily overwhelmed at the moment because it has to convert\nevery disk image to raw - simply deploying 2 instances at once exceeds\nthe IOPS on most single disk servers. Avoid this by serialising the\nimage conversion (which leads to a lower average-time-to-deploy in\nnearly all situations).\n\nChange-Id: I6d5ee97ffdbd497802379b13e70b84d70d8ded57\nCo-Authored-By: Steve Kowalik <steven@wedontsleep.org>\n'}]",0,71219,8625766c39f39b8b44bf212be6c2820d6736b6f3,75,12,6,4190,,,0,"Prevent thrashing when deploying many bm instances

Nova BM is easily overwhelmed at the moment because it has to convert
every disk image to raw - simply deploying 2 instances at once exceeds
the IOPS on most single disk servers. Avoid this by serialising the
image conversion (which leads to a lower average-time-to-deploy in
nearly all situations).

Change-Id: I6d5ee97ffdbd497802379b13e70b84d70d8ded57
Co-Authored-By: Steve Kowalik <steven@wedontsleep.org>
",git fetch https://review.opendev.org/openstack/nova refs/changes/19/71219/6 && git format-patch -1 --stdout FETCH_HEAD,['nova/virt/baremetal/driver.py'],1,b20dda8cb446567fee3d431eedf9ae100ab940c7,block-migrate-defaults,"import threading cache_semaphore = threading.Semaphore() # Caching images is both CPU and I/O expensive. When running many # machines from a single nova-compute server, deploys of multiple # machines can easily thrash the nova-compute server - unlike a # virt hypervisor which is limited by CPU for VMs, baremetal only # uses CPU and I/O when deploying. By only downloading one image # at a time we serialise rather than thrashing, which leads to a # lower average time-to-complete during overload situations, and # a (relatively) insignificant delay for compute servers which # have sufficient IOPS to handle multiple concurrent image # conversions. cache_semaphore.acquire() try: self.driver.cache_images( context, node, instance, admin_password=admin_password, image_meta=image_meta, injected_files=injected_files, network_info=network_info, ) finally: cache_semaphore.release()"," self.driver.cache_images( context, node, instance, admin_password=admin_password, image_meta=image_meta, injected_files=injected_files, network_info=network_info, )",25,8
openstack%2Fkeystone~master~Ib5db4752b6c764e11587126d2285aa0af79b2cc6,openstack/keystone,master,Ib5db4752b6c764e11587126d2285aa0af79b2cc6,Imported Translations from Transifex,MERGED,2014-03-03 06:07:28.000000000,2014-03-06 01:40:12.000000000,2014-03-06 01:40:11.000000000,"[{'_account_id': 3}, {'_account_id': 4}, {'_account_id': 2903}]","[{'number': 1, 'created': '2014-03-03 06:07:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/a2810a5878ac4dbdd60e99dc10c6c9822cee9d81', 'message': 'Imported Translations from Transifex\n\nChange-Id: Ib5db4752b6c764e11587126d2285aa0af79b2cc6\n'}, {'number': 2, 'created': '2014-03-04 06:00:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/f5c7f1e4b330d50941f0ddbe524c9df3e9c6171a', 'message': 'Imported Translations from Transifex\n\nChange-Id: Ib5db4752b6c764e11587126d2285aa0af79b2cc6\n'}, {'number': 3, 'created': '2014-03-05 06:00:39.000000000', 'files': ['keystone/locale/ml_IN/LC_MESSAGES/keystone.po', 'keystone/locale/sw_KE/LC_MESSAGES/keystone.po', 'keystone/locale/pa_IN/LC_MESSAGES/keystone.po', 'keystone/locale/ru/LC_MESSAGES/keystone.po', 'keystone/locale/bn_IN/LC_MESSAGES/keystone.po', 'keystone/locale/eu/LC_MESSAGES/keystone.po', 'keystone/locale/fa/LC_MESSAGES/keystone.po', 'keystone/locale/ms/LC_MESSAGES/keystone.po', 'keystone/locale/bs/LC_MESSAGES/keystone.po', 'keystone/locale/kn/LC_MESSAGES/keystone.po', 'keystone/locale/eu_ES/LC_MESSAGES/keystone.po', 'keystone/locale/ne/LC_MESSAGES/keystone.po', 'keystone/locale/he_IL/LC_MESSAGES/keystone.po', 'keystone/locale/bg_BG/LC_MESSAGES/keystone.po', 'keystone/locale/en_US/LC_MESSAGES/keystone.po', 'keystone/locale/ur/LC_MESSAGES/keystone.po', 'keystone/locale/da/LC_MESSAGES/keystone.po', 'keystone/locale/es/LC_MESSAGES/keystone.po', 'keystone/locale/ko_KR/LC_MESSAGES/keystone.po', 'keystone/locale/mr_IN/LC_MESSAGES/keystone.po', 'keystone/locale/ka_GE/LC_MESSAGES/keystone.po', 'keystone/locale/zh_CN/LC_MESSAGES/keystone.po', 'keystone/locale/ja/LC_MESSAGES/keystone.po', 'keystone/locale/sl_SI/LC_MESSAGES/keystone.po', 'keystone/locale/hi/LC_MESSAGES/keystone.po', 'keystone/locale/uk/LC_MESSAGES/keystone.po', 'keystone/locale/nb/LC_MESSAGES/keystone.po', 'keystone/locale/es_MX/LC_MESSAGES/keystone.po', 'keystone/locale/ar/LC_MESSAGES/keystone.po', 'keystone/locale/ko/LC_MESSAGES/keystone.po', 'keystone/locale/tl/LC_MESSAGES/keystone.po', 'keystone/locale/en_GB/LC_MESSAGES/keystone.po', 'keystone/locale/id/LC_MESSAGES/keystone.po', 'keystone/locale/is_IS/LC_MESSAGES/keystone.po', 'keystone/locale/pt/LC_MESSAGES/keystone.po', 'keystone/locale/de/LC_MESSAGES/keystone.po', 'keystone/locale/hu/LC_MESSAGES/keystone.po', 'keystone/locale/sk/LC_MESSAGES/keystone.po', 'keystone/locale/it/LC_MESSAGES/keystone.po', 'keystone/locale/ro/LC_MESSAGES/keystone.po', 'keystone/locale/ca/LC_MESSAGES/keystone.po', 'keystone/locale/gl/LC_MESSAGES/keystone.po', 'keystone/locale/cs/LC_MESSAGES/keystone.po', 'keystone/locale/hr/LC_MESSAGES/keystone.po', 'keystone/locale/ru_RU/LC_MESSAGES/keystone.po', 'keystone/locale/tl_PH/LC_MESSAGES/keystone.po', 'keystone/locale/zh_TW/LC_MESSAGES/keystone.po', 'keystone/locale/fi_FI/LC_MESSAGES/keystone.po', 'keystone/locale/keystone.pot', 'keystone/locale/pl_PL/LC_MESSAGES/keystone.po', 'keystone/locale/en_AU/LC_MESSAGES/keystone.po', 'keystone/locale/sv/LC_MESSAGES/keystone.po', 'keystone/locale/km/LC_MESSAGES/keystone.po', 'keystone/locale/pt_BR/LC_MESSAGES/keystone.po', 'keystone/locale/fr/LC_MESSAGES/keystone.po', 'keystone/locale/fil/LC_MESSAGES/keystone.po', 'keystone/locale/vi_VN/LC_MESSAGES/keystone.po', 'keystone/locale/it_IT/LC_MESSAGES/keystone.po', 'keystone/locale/nl_NL/LC_MESSAGES/keystone.po', 'keystone/locale/tr_TR/LC_MESSAGES/keystone.po', 'keystone/locale/zh_HK/LC_MESSAGES/keystone.po', 'keystone/locale/he/LC_MESSAGES/keystone.po'], 'web_link': 'https://opendev.org/openstack/keystone/commit/caf996f3ef1c7157bf6232f1f2d262c148bf509f', 'message': 'Imported Translations from Transifex\n\nChange-Id: Ib5db4752b6c764e11587126d2285aa0af79b2cc6\n'}]",0,77505,caf996f3ef1c7157bf6232f1f2d262c148bf509f,16,3,3,3,,,0,"Imported Translations from Transifex

Change-Id: Ib5db4752b6c764e11587126d2285aa0af79b2cc6
",git fetch https://review.opendev.org/openstack/keystone refs/changes/05/77505/1 && git format-patch -1 --stdout FETCH_HEAD,"['keystone/locale/ml_IN/LC_MESSAGES/keystone.po', 'keystone/locale/sw_KE/LC_MESSAGES/keystone.po', 'keystone/locale/pa_IN/LC_MESSAGES/keystone.po', 'keystone/locale/ru/LC_MESSAGES/keystone.po', 'keystone/locale/bn_IN/LC_MESSAGES/keystone.po', 'keystone/locale/eu/LC_MESSAGES/keystone.po', 'keystone/locale/fa/LC_MESSAGES/keystone.po', 'keystone/locale/ms/LC_MESSAGES/keystone.po', 'keystone/locale/bs/LC_MESSAGES/keystone.po', 'keystone/locale/kn/LC_MESSAGES/keystone.po', 'keystone/locale/eu_ES/LC_MESSAGES/keystone.po', 'keystone/locale/ne/LC_MESSAGES/keystone.po', 'keystone/locale/he_IL/LC_MESSAGES/keystone.po', 'keystone/locale/bg_BG/LC_MESSAGES/keystone.po', 'keystone/locale/en_US/LC_MESSAGES/keystone.po', 'keystone/locale/ur/LC_MESSAGES/keystone.po', 'keystone/locale/da/LC_MESSAGES/keystone.po', 'keystone/locale/es/LC_MESSAGES/keystone.po', 'keystone/locale/ko_KR/LC_MESSAGES/keystone.po', 'keystone/locale/mr_IN/LC_MESSAGES/keystone.po', 'keystone/locale/ka_GE/LC_MESSAGES/keystone.po', 'keystone/locale/zh_CN/LC_MESSAGES/keystone.po', 'keystone/locale/ja/LC_MESSAGES/keystone.po', 'keystone/locale/sl_SI/LC_MESSAGES/keystone.po', 'keystone/locale/hi/LC_MESSAGES/keystone.po', 'keystone/locale/uk/LC_MESSAGES/keystone.po', 'keystone/locale/nb/LC_MESSAGES/keystone.po', 'keystone/locale/es_MX/LC_MESSAGES/keystone.po', 'keystone/locale/ar/LC_MESSAGES/keystone.po', 'keystone/locale/ko/LC_MESSAGES/keystone.po', 'keystone/locale/tl/LC_MESSAGES/keystone.po', 'keystone/locale/en_GB/LC_MESSAGES/keystone.po', 'keystone/locale/id/LC_MESSAGES/keystone.po', 'keystone/locale/is_IS/LC_MESSAGES/keystone.po', 'keystone/locale/pt/LC_MESSAGES/keystone.po', 'keystone/locale/de/LC_MESSAGES/keystone.po', 'keystone/locale/hu/LC_MESSAGES/keystone.po', 'keystone/locale/sk/LC_MESSAGES/keystone.po', 'keystone/locale/it/LC_MESSAGES/keystone.po', 'keystone/locale/ro/LC_MESSAGES/keystone.po', 'keystone/locale/ca/LC_MESSAGES/keystone.po', 'keystone/locale/gl/LC_MESSAGES/keystone.po', 'keystone/locale/cs/LC_MESSAGES/keystone.po', 'keystone/locale/hr/LC_MESSAGES/keystone.po', 'keystone/locale/ru_RU/LC_MESSAGES/keystone.po', 'keystone/locale/tl_PH/LC_MESSAGES/keystone.po', 'keystone/locale/zh_TW/LC_MESSAGES/keystone.po', 'keystone/locale/fi_FI/LC_MESSAGES/keystone.po', 'keystone/locale/keystone.pot', 'keystone/locale/pl_PL/LC_MESSAGES/keystone.po', 'keystone/locale/en_AU/LC_MESSAGES/keystone.po', 'keystone/locale/sv/LC_MESSAGES/keystone.po', 'keystone/locale/km/LC_MESSAGES/keystone.po', 'keystone/locale/pt_BR/LC_MESSAGES/keystone.po', 'keystone/locale/fr/LC_MESSAGES/keystone.po', 'keystone/locale/fil/LC_MESSAGES/keystone.po', 'keystone/locale/vi_VN/LC_MESSAGES/keystone.po', 'keystone/locale/it_IT/LC_MESSAGES/keystone.po', 'keystone/locale/nl_NL/LC_MESSAGES/keystone.po', 'keystone/locale/tr_TR/LC_MESSAGES/keystone.po', 'keystone/locale/zh_HK/LC_MESSAGES/keystone.po', 'keystone/locale/he/LC_MESSAGES/keystone.po']",62,a2810a5878ac4dbdd60e99dc10c6c9822cee9d81,transifex/translations,"""POT-Creation-Date: 2014-03-03 06:07+0000\n""#: keystone/catalog/controllers.py:153 #, python-format msgid ""Conflicting region IDs specified: \""%(url_id)s\"" != \""%(ref_id)s\"""" msgstr """" #: keystone/common/controller.py:54 keystone/middleware/core.py:240#: keystone/common/wsgi.py:66#: keystone/common/wsgi.py:70#: keystone/common/wsgi.py:77#: keystone/common/wsgi.py:81#: keystone/common/wsgi.py:84#: keystone/common/wsgi.py:87#: keystone/common/wsgi.py:91#: keystone/common/wsgi.py:180#: keystone/common/wsgi.py:208#: keystone/common/wsgi.py:281#: keystone/common/wsgi.py:293#: keystone/common/wsgi.py:472 keystone/tests/test_wsgi.py:252#: keystone/middleware/core.py:245#: keystone/middleware/core.py:250#: keystone/middleware/core.py:255#: keystone/tests/core.py:147","""POT-Creation-Date: 2014-03-02 06:00+0000\n""#: keystone/common/controller.py:54 keystone/middleware/core.py:231#: keystone/common/wsgi.py:72#: keystone/common/wsgi.py:76#: keystone/common/wsgi.py:83#: keystone/common/wsgi.py:87#: keystone/common/wsgi.py:90#: keystone/common/wsgi.py:93#: keystone/common/wsgi.py:97#: keystone/common/wsgi.py:186#: keystone/common/wsgi.py:214#: keystone/common/wsgi.py:287#: keystone/common/wsgi.py:299#: keystone/common/wsgi.py:478 keystone/tests/test_wsgi.py:252#: keystone/middleware/core.py:236#: keystone/middleware/core.py:241#: keystone/middleware/core.py:246#: keystone/tests/core.py:146",1427,6588
openstack-attic%2Fnetconn-api~master~I894172a4f15dd0771efd96f13d1d3e888d097979,openstack-attic/netconn-api,master,I894172a4f15dd0771efd96f13d1d3e888d097979,Changed v2.0/samples/routers-show-res.json to show the correct output.,MERGED,2014-02-08 18:00:01.000000000,2014-03-06 01:33:14.000000000,2014-03-06 01:33:14.000000000,"[{'_account_id': 3}, {'_account_id': 261}, {'_account_id': 2592}, {'_account_id': 9162}, {'_account_id': 10208}, {'_account_id': 10254}]","[{'number': 1, 'created': '2014-02-08 18:00:01.000000000', 'files': ['v2.0/samples/routers-show-res.json'], 'web_link': 'https://opendev.org/openstack-attic/netconn-api/commit/a6f9080872190507c5b43515135d44184601396d', 'message': 'Changed v2.0/samples/routers-show-res.json to show the correct output.\n\nThe routers-show-res.json file was changed to match the output of the\nneutron router-show command.\n\nChange-Id: I894172a4f15dd0771efd96f13d1d3e888d097979\nCloses-Bug: #1276690\n'}]",0,72100,a6f9080872190507c5b43515135d44184601396d,17,6,1,10253,,,0,"Changed v2.0/samples/routers-show-res.json to show the correct output.

The routers-show-res.json file was changed to match the output of the
neutron router-show command.

Change-Id: I894172a4f15dd0771efd96f13d1d3e888d097979
Closes-Bug: #1276690
",git fetch https://review.opendev.org/openstack-attic/netconn-api refs/changes/00/72100/1 && git format-patch -1 --stdout FETCH_HEAD,['v2.0/samples/routers-show-res.json'],1,a6f9080872190507c5b43515135d44184601396d,fix-bug-1276690," ""router"": { }"," ""routers"": [{ }]",3,3
openstack%2Fheat~master~Ia029d585dfdb2563609725589c41083819a11a3b,openstack/heat,master,Ia029d585dfdb2563609725589c41083819a11a3b,heat_keystoneclient add legacy fallback path,MERGED,2014-03-05 17:14:05.000000000,2014-03-06 01:18:30.000000000,2014-03-06 01:18:29.000000000,"[{'_account_id': 3}, {'_account_id': 4257}, {'_account_id': 4328}, {'_account_id': 6488}, {'_account_id': 6969}, {'_account_id': 7256}]","[{'number': 1, 'created': '2014-03-05 17:14:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/491d3b133eb26eed6d3f23b61353ae4b46d4d5e6', 'message': ""heat_keystoneclient add legacy fallback path\n\nIf users fail to observe the reccomendations in the commit messages\nand/or release notes and use a heat.conf from a previous version of\nheat currently some functionality will fail due to the missing\ndomain configuration in heat.conf.  Instead degrade gracefully with\nwarnings, calling the non-domain functions which are maintained\n(for now) for backwards compatibility.\n\nHopefully we won't have to maintain this huge pile of legacy stuff\nfor too long :(\n\nChange-Id: Ia029d585dfdb2563609725589c41083819a11a3b\nCloses-Bug: #1287980\n""}, {'number': 2, 'created': '2014-03-05 17:19:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/dbf4cbea260c695074236bb6c90bb3444fdd3a0b', 'message': ""heat_keystoneclient add legacy fallback path\n\nIf users fail to observe the reccomendations in the commit messages\nand/or release notes and use a heat.conf from a previous version of\nheat currently some functionality will fail due to the missing\ndomain configuration in heat.conf.  Instead degrade gracefully with\nwarnings, calling the non-domain functions which are maintained\n(for now) for backwards compatibility.\n\nHopefully we won't have to maintain this huge pile of legacy stuff\nfor too long :(\n\nChange-Id: Ia029d585dfdb2563609725589c41083819a11a3b\nCloses-Bug: #1287980\n""}, {'number': 3, 'created': '2014-03-05 17:48:07.000000000', 'files': ['heat/common/heat_keystoneclient.py', 'heat/tests/test_heatclient.py'], 'web_link': 'https://opendev.org/openstack/heat/commit/252faed5f567880f30066ecd27a62c88f66bfa67', 'message': ""heat_keystoneclient add legacy fallback path\n\nIf users fail to observe the reccomendations in the commit messages\nand/or release notes and use a heat.conf from a previous version of\nheat currently some functionality will fail due to the missing\ndomain configuration in heat.conf.  Instead degrade gracefully with\nwarnings, calling the non-domain functions which are maintained\n(for now) for backwards compatibility.\n\nHopefully we won't have to maintain this huge pile of legacy stuff\nfor too long :(\n\nChange-Id: Ia029d585dfdb2563609725589c41083819a11a3b\nCloses-Bug: #1287980\n""}]",9,78310,252faed5f567880f30066ecd27a62c88f66bfa67,18,6,3,4328,,,0,"heat_keystoneclient add legacy fallback path

If users fail to observe the reccomendations in the commit messages
and/or release notes and use a heat.conf from a previous version of
heat currently some functionality will fail due to the missing
domain configuration in heat.conf.  Instead degrade gracefully with
warnings, calling the non-domain functions which are maintained
(for now) for backwards compatibility.

Hopefully we won't have to maintain this huge pile of legacy stuff
for too long :(

Change-Id: Ia029d585dfdb2563609725589c41083819a11a3b
Closes-Bug: #1287980
",git fetch https://review.opendev.org/openstack/heat refs/changes/10/78310/1 && git format-patch -1 --stdout FETCH_HEAD,"['heat/common/heat_keystoneclient.py', 'heat/tests/test_heatclient.py']",2,491d3b133eb26eed6d3f23b61353ae4b46d4d5e6,bug/1089261," def test_create_stack_domain_user_legacy_fallback(self): """"""Test creating a stack domain user, fallback path."""""" cfg.CONF.clear_override('stack_user_domain') ctx = utils.dummy_context() ctx.trust_id = None # mock keystone client functions self._stubs_v3() self.mock_ks_v3_client.users = self.m.CreateMockAnything() mock_user = self.m.CreateMockAnything() mock_user.id = 'auser123' self.mock_ks_v3_client.users.create(name='auser', password='password', default_project=ctx.tenant_id ).AndReturn(mock_user) self.mock_ks_v3_client.roles = self.m.CreateMockAnything() self.mock_ks_v3_client.roles.list().AndReturn(self._mock_roles_list()) self.mock_ks_v3_client.roles.grant(project=ctx.tenant_id, role='4546', user='auser123').AndReturn(None) self.m.ReplayAll() heat_ks_client = heat_keystoneclient.KeystoneClient(ctx) heat_ks_client.create_stack_domain_user(username='auser', project_id='aproject', password='password') def test_delete_stack_domain_user_legacy_fallback(self): """"""Test deleting a stack domain user, fallback path."""""" cfg.CONF.clear_override('stack_user_domain') ctx = utils.dummy_context() ctx.trust_id = None # mock keystone client functions self._stubs_v3() self.mock_ks_v3_client.users = self.m.CreateMockAnything() self.mock_ks_v3_client.users.delete(user='user123').AndReturn(None) self.m.ReplayAll() heat_ks_client = heat_keystoneclient.KeystoneClient(ctx) heat_ks_client.delete_stack_domain_user(user_id='user123', project_id='aproject') def test_init_domain_cfg_not_set_fallback(self): """"""Test error path when config lacks domain config."""""" cfg.CONF.clear_override('stack_domain_admin') cfg.CONF.clear_override('stack_domain_admin_password') ctx = utils.dummy_context() ctx.username = None ctx.password = None ctx.trust_id = None self.assertIsNotNone(heat_keystoneclient.KeystoneClient(ctx)) def test_init_domain_cfg_not_set_error(self): """"""Test error path when config lacks domain config."""""" cfg.CONF.clear_override('stack_domain_admin') cfg.CONF.clear_override('stack_domain_admin_password') exp_msg = ('heat.conf misconfigured, cannot specify stack_user_domain ' 'without stack_domain_admin and ' 'stack_domain_admin_password') self.assertIn(exp_msg, err) def test_enable_stack_domain_user_legacy_fallback(self): """"""Test enabling a stack domain user, fallback path."""""" cfg.CONF.clear_override('stack_user_domain') ctx = utils.dummy_context() ctx.trust_id = None # mock keystone client functions self._stubs_v3() self.mock_ks_v3_client.users = self.m.CreateMockAnything() self.mock_ks_v3_client.users.update(user='user123', enabled=True ).AndReturn(None) self.m.ReplayAll() heat_ks_client = heat_keystoneclient.KeystoneClient(ctx) heat_ks_client.enable_stack_domain_user(user_id='user123', project_id='aproject') def test_disable_stack_domain_user_legacy_fallback(self): """"""Test enabling a stack domain user, fallback path."""""" cfg.CONF.clear_override('stack_user_domain') ctx = utils.dummy_context() ctx.trust_id = None # mock keystone client functions self._stubs_v3() self.mock_ks_v3_client.users = self.m.CreateMockAnything() self.mock_ks_v3_client.users.update(user='user123', enabled=False ).AndReturn(None) self.m.ReplayAll() heat_ks_client = heat_keystoneclient.KeystoneClient(ctx) heat_ks_client.disable_stack_domain_user(user_id='user123', project_id='aproject') def test_create_stack_domain_user_keypair_legacy_fallback(self): """"""Test creating ec2 credentials for domain user, fallback path."""""" cfg.CONF.clear_override('stack_user_domain') self._stubs_v3() ctx = utils.dummy_context() ctx.trust_id = None ex_data = {'access': 'dummy_access2', 'secret': 'dummy_secret2'} ex_data_json = json.dumps(ex_data) # stub UUID.hex to match ex_data self._stub_uuid(['dummy_access2', 'dummy_secret2']) # mock keystone client credentials functions self.mock_ks_v3_client.credentials = self.m.CreateMockAnything() mock_credential = self.m.CreateMockAnything() mock_credential.id = '1234567' mock_credential.user_id = 'atestuser2' mock_credential.blob = ex_data_json mock_credential.type = 'ec2' # mock keystone client create function self.mock_ks_v3_client.credentials.create( user='atestuser2', type='ec2', data=ex_data_json, project=ctx.tenant_id).AndReturn(mock_credential) self.m.ReplayAll() heat_ks_client = heat_keystoneclient.KeystoneClient(ctx) ec2_cred = heat_ks_client.create_stack_domain_user_keypair( user_id='atestuser2', project_id='aproject') self.assertEqual('1234567', ec2_cred.id) self.assertEqual('dummy_access2', ec2_cred.access) self.assertEqual('dummy_secret2', ec2_cred.secret) def test_create_stack_domain_project_legacy_fallback(self): """"""Test the create_stack_domain_project function, fallback path."""""" cfg.CONF.clear_override('stack_user_domain') ctx = utils.dummy_context() ctx.trust_id = None heat_ks_client = heat_keystoneclient.KeystoneClient(ctx) self.assertEqual(ctx.tenant_id, heat_ks_client.create_stack_domain_project( stack_name='astack')) def test_delete_stack_domain_project_legacy_fallback(self): """"""Test the delete_stack_domain_project function, fallback path."""""" cfg.CONF.clear_override('stack_user_domain') ctx = utils.dummy_context() ctx.trust_id = None heat_ks_client = heat_keystoneclient.KeystoneClient(ctx) self.assertIsNone(heat_ks_client.delete_stack_domain_project( project_id='aprojectid')) "," def test_init_domain_cfg_not_set(self): """"""Test error path when config lacks stack domain ID."""""" self.assertIn('stack_user_domain ID not set in heat.conf', err)",247,14
openstack%2Fheat~master~Ia456425384d52b3983b8d1d387f56e57e8b559ee,openstack/heat,master,Ia456425384d52b3983b8d1d387f56e57e8b559ee,Fixup uuid stubbing in test_stack_user.py,MERGED,2014-03-04 15:57:45.000000000,2014-03-06 01:05:42.000000000,2014-03-06 01:05:42.000000000,"[{'_account_id': 3}, {'_account_id': 4328}, {'_account_id': 4571}, {'_account_id': 7256}, {'_account_id': 7385}]","[{'number': 1, 'created': '2014-03-04 15:57:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/6c2e5e30a0aef131be4a86e1a2526fd0fc01fe9e', 'message': 'Fixup uuid stubbing in test_stack_user.py\n\nAs noted in https://review.openstack.org/#/c/71930/13  there is an issue\nwith using the utils.UUIDStub method to stub the resource ID, because\nany events stored also get the same uuid, which can cause sqlalchemy\nwarnings to be output.  Instead store the resource before setting up the\nkeystoneclient stub so we know the expected ID to use.\n\nChange-Id: Ia456425384d52b3983b8d1d387f56e57e8b559ee\n'}, {'number': 2, 'created': '2014-03-05 17:14:09.000000000', 'files': ['heat/tests/test_stack_user.py'], 'web_link': 'https://opendev.org/openstack/heat/commit/4470628a13972396590292c7f2f804a884e6a00f', 'message': 'Fixup uuid stubbing in test_stack_user.py\n\nAs noted in https://review.openstack.org/#/c/71930/13  there is an issue\nwith using the utils.UUIDStub method to stub the resource ID, because\nany events stored also get the same uuid, which can cause sqlalchemy\nwarnings to be output.  Instead store the resource before setting up the\nkeystoneclient stub so we know the expected ID to use.\n\nChange-Id: Ia456425384d52b3983b8d1d387f56e57e8b559ee\n'}]",0,77920,4470628a13972396590292c7f2f804a884e6a00f,15,5,2,4328,,,0,"Fixup uuid stubbing in test_stack_user.py

As noted in https://review.openstack.org/#/c/71930/13  there is an issue
with using the utils.UUIDStub method to stub the resource ID, because
any events stored also get the same uuid, which can cause sqlalchemy
warnings to be output.  Instead store the resource before setting up the
keystoneclient stub so we know the expected ID to use.

Change-Id: Ia456425384d52b3983b8d1d387f56e57e8b559ee
",git fetch https://review.opendev.org/openstack/heat refs/changes/20/77920/1 && git format-patch -1 --stdout FETCH_HEAD,['heat/tests/test_stack_user.py'],1,6c2e5e30a0aef131be4a86e1a2526fd0fc01fe9e,bug/1089261, rsrc._store() short_id.get_id(rsrc.id).AndReturn('aabbcc') scheduler.TaskRunner(rsrc.create)() scheduler.TaskRunner(rsrc.create)() scheduler.TaskRunner(rsrc.create)() scheduler.TaskRunner(rsrc.create)() scheduler.TaskRunner(rsrc.create)(),import uuid self.resource_id = str(uuid.uuid4()) short_id.get_id(self.resource_id).AndReturn('aabbcc') with utils.UUIDStub(self.resource_id): scheduler.TaskRunner(rsrc.create)() with utils.UUIDStub(self.resource_id): scheduler.TaskRunner(rsrc.create)() with utils.UUIDStub(self.resource_id): scheduler.TaskRunner(rsrc.create)() with utils.UUIDStub(self.resource_id): scheduler.TaskRunner(rsrc.create)() with utils.UUIDStub(self.resource_id): scheduler.TaskRunner(rsrc.create)(),7,14
openstack%2Fkeystone~master~I9b9379f4531c298c14508418dbfb629bdd6c2850,openstack/keystone,master,I9b9379f4531c298c14508418dbfb629bdd6c2850,Always include 'enabled' field in endpoint response,MERGED,2014-02-23 23:24:22.000000000,2014-03-06 01:02:43.000000000,2014-03-06 01:02:42.000000000,"[{'_account_id': 3}, {'_account_id': 4}, {'_account_id': 1916}, {'_account_id': 5046}, {'_account_id': 6460}, {'_account_id': 6482}, {'_account_id': 6486}, {'_account_id': 7191}, {'_account_id': 7725}]","[{'number': 1, 'created': '2014-02-23 23:24:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/e5114d7ae35e6f4ab4c120bd6b0c3f4bbd5793ea', 'message': ""Always include 'enabled' field in endpoint response\n\nThe 'enabled' field wasn't always returned in an endpoint response.\n\nThe 'enabled' attribute for endpoints was stored in the 'extra'\ncolumn as part of a JSON string. Now the 'enabled' attribute is in\nits own column so that it's easier to filter on it, for example.\n\nCloses-Bug: #1273867\n\nChange-Id: I9b9379f4531c298c14508418dbfb629bdd6c2850\n""}, {'number': 2, 'created': '2014-02-23 23:32:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/25179ca48b855b6c4232d0050034013658127d02', 'message': ""Always include 'enabled' field in endpoint response\n\nThe 'enabled' field wasn't always returned in an endpoint response.\n\nThe 'enabled' attribute for endpoints was stored in the 'extra'\ncolumn as part of a JSON string. Now the 'enabled' attribute is in\nits own column so that it's easier to filter on it, for example.\n\nCloses-Bug: #1282266\n\nChange-Id: I9b9379f4531c298c14508418dbfb629bdd6c2850\n""}, {'number': 3, 'created': '2014-02-24 00:06:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/665e975fdacb004229214a49859c2bccca421dc5', 'message': ""Always include 'enabled' field in endpoint response\n\nThe 'enabled' field wasn't always returned in an endpoint response.\n\nThe 'enabled' attribute for endpoints was stored in the 'extra'\ncolumn as part of a JSON string. Now the 'enabled' attribute is in\nits own column. It will also be easier to filter out disabled\nendpoints now that enabled is a separate column.\n\nCloses-Bug: #1282266\n\nChange-Id: I9b9379f4531c298c14508418dbfb629bdd6c2850\n""}, {'number': 4, 'created': '2014-02-28 00:08:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/113ced0b2d816f048d67ecf4c8b506eb3ed940d5', 'message': ""Always include 'enabled' field in endpoint response\n\nThe 'enabled' field wasn't always returned in an endpoint response.\n\nThe 'enabled' attribute for endpoints was stored in the 'extra'\ncolumn as part of a JSON string. Now the 'enabled' attribute is in\nits own column. It will also be easier to filter out disabled\nendpoints now that enabled is a separate column.\n\nWith the 'enabled' field being a Boolean column in the database,\nthe server also needs to validate that the value is a Boolean (if\nit's present). This is done in the same way that the server checks\nthe type of the 'enabled' value when creating users.\n\nCloses-Bug: #1282266\n\nChange-Id: I9b9379f4531c298c14508418dbfb629bdd6c2850\n""}, {'number': 5, 'created': '2014-02-28 02:25:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/3d92bad55c5e9340bdaf6b00c664888043fc8c20', 'message': ""Always include 'enabled' field in endpoint response\n\nThe 'enabled' field wasn't always returned in an endpoint response.\n\nThe 'enabled' attribute for endpoints was stored in the 'extra'\ncolumn as part of a JSON string. Now the 'enabled' attribute is in\nits own column. It will also be easier to filter out disabled\nendpoints now that enabled is a separate column.\n\nWith the 'enabled' field being a Boolean column in the database,\nthe server also needs to validate that the value is a Boolean (if\nit's present). This is done in the same way that the server checks\nthe type of the 'enabled' value when creating users.\n\nCloses-Bug: #1282266\n\nChange-Id: I9b9379f4531c298c14508418dbfb629bdd6c2850\n""}, {'number': 6, 'created': '2014-02-28 23:57:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/c85c785c912ce326418d9620bc49f65546b07207', 'message': ""Always include 'enabled' field in endpoint response\n\nThe 'enabled' field wasn't always returned in an endpoint response.\n\nThe 'enabled' attribute for endpoints was stored in the 'extra'\ncolumn as part of a JSON string. Now the 'enabled' attribute is in\nits own column. It will also be easier to filter out disabled\nendpoints now that enabled is a separate column.\n\nWith the 'enabled' field being a Boolean column in the database,\nthe server also needs to validate that the value is a Boolean (if\nit's present). This is done in the same way that the server checks\nthe type of the 'enabled' value when creating users.\n\nCloses-Bug: #1282266\n\nChange-Id: I9b9379f4531c298c14508418dbfb629bdd6c2850\n""}, {'number': 7, 'created': '2014-03-02 18:15:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/6e517d0571f969c4bfc6d5ed4fb78275aa5c2d3d', 'message': ""Always include 'enabled' field in endpoint response\n\nThe 'enabled' field wasn't always returned in an endpoint response.\n\nThe 'enabled' attribute for endpoints was stored in the 'extra'\ncolumn as part of a JSON string. Now the 'enabled' attribute is in\nits own column. It will also be easier to filter out disabled\nendpoints now that enabled is a separate column.\n\nWith the 'enabled' field being a Boolean column in the database,\nthe server also needs to validate that the value is a Boolean (if\nit's present). This is done in the same way that the server checks\nthe type of the 'enabled' value when creating users.\n\nCloses-Bug: #1282266\n\nChange-Id: I9b9379f4531c298c14508418dbfb629bdd6c2850\n""}, {'number': 8, 'created': '2014-03-02 18:55:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/4a652e2e38c301a74f5dc78feb9507f8de772638', 'message': ""Always include 'enabled' field in endpoint response\n\nThe 'enabled' field wasn't always returned in an endpoint response.\n\nThe 'enabled' attribute for endpoints was stored in the 'extra'\ncolumn as part of a JSON string. Now the 'enabled' attribute is in\nits own column. It will also be easier to filter out disabled\nendpoints now that enabled is a separate column.\n\nWith the 'enabled' field being a Boolean column in the database,\nthe server also needs to validate that the value is a Boolean (if\nit's present). This is done in the same way that the server checks\nthe type of the 'enabled' value when creating users.\n\nCloses-Bug: #1282266\n\nChange-Id: I9b9379f4531c298c14508418dbfb629bdd6c2850\n""}, {'number': 9, 'created': '2014-03-04 15:11:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/a37cc0bfaa8e5555ebda673659b97e49c5584b0c', 'message': ""Always include 'enabled' field in endpoint response\n\nThe 'enabled' field wasn't always returned in an endpoint response.\n\nThe 'enabled' attribute for endpoints was stored in the 'extra'\ncolumn as part of a JSON string. Now the 'enabled' attribute is in\nits own column. It will also be easier to filter out disabled\nendpoints now that enabled is a separate column.\n\nWith the 'enabled' field being a Boolean column in the database,\nthe server also needs to validate that the value is a Boolean (if\nit's present). This is done in the same way that the server checks\nthe type of the 'enabled' value when creating users.\n\nCloses-Bug: #1282266\n\nChange-Id: I9b9379f4531c298c14508418dbfb629bdd6c2850\n""}, {'number': 10, 'created': '2014-03-04 16:31:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/0ffc1a92ab48a4c8b1048402fe0ebaf509e3b875', 'message': ""Always include 'enabled' field in endpoint response\n\nThe 'enabled' field wasn't always returned in an endpoint response.\n\nThe 'enabled' attribute for endpoints was stored in the 'extra'\ncolumn as part of a JSON string. Now the 'enabled' attribute is in\nits own column. It will also be easier to filter out disabled\nendpoints now that enabled is a separate column.\n\nWith the 'enabled' field being a Boolean column in the database,\nthe server also needs to validate that the value is a Boolean (if\nit's present). This is done in the same way that the server checks\nthe type of the 'enabled' value when creating users.\n\nCloses-Bug: #1282266\n\nChange-Id: I9b9379f4531c298c14508418dbfb629bdd6c2850\n""}, {'number': 11, 'created': '2014-03-04 20:37:09.000000000', 'files': ['keystone/tests/test_v3_catalog.py', 'keystone/catalog/backends/sql.py', 'keystone/tests/test_sql_upgrade.py', 'keystone/tests/test_v3.py', 'keystone/common/sql/migrate_repo/versions/042_endpoint_enabled.py', 'keystone/catalog/controllers.py'], 'web_link': 'https://opendev.org/openstack/keystone/commit/ed635f9fbb99f856e0c543105790a1e578858cc2', 'message': ""Always include 'enabled' field in endpoint response\n\nThe 'enabled' field wasn't always returned in an endpoint response.\n\nThe 'enabled' attribute for endpoints was stored in the 'extra'\ncolumn as part of a JSON string. Now the 'enabled' attribute is in\nits own column. It will also be easier to filter out disabled\nendpoints now that enabled is a separate column.\n\nWith the 'enabled' field being a Boolean column in the database,\nthe server also needs to validate that the value is a Boolean (if\nit's present). This is done in the same way that the server checks\nthe type of the 'enabled' value when creating users.\n\nCloses-Bug: #1282266\n\nChange-Id: I9b9379f4531c298c14508418dbfb629bdd6c2850\n""}]",25,75727,ed635f9fbb99f856e0c543105790a1e578858cc2,63,9,11,6486,,,0,"Always include 'enabled' field in endpoint response

The 'enabled' field wasn't always returned in an endpoint response.

The 'enabled' attribute for endpoints was stored in the 'extra'
column as part of a JSON string. Now the 'enabled' attribute is in
its own column. It will also be easier to filter out disabled
endpoints now that enabled is a separate column.

With the 'enabled' field being a Boolean column in the database,
the server also needs to validate that the value is a Boolean (if
it's present). This is done in the same way that the server checks
the type of the 'enabled' value when creating users.

Closes-Bug: #1282266

Change-Id: I9b9379f4531c298c14508418dbfb629bdd6c2850
",git fetch https://review.opendev.org/openstack/keystone refs/changes/27/75727/8 && git format-patch -1 --stdout FETCH_HEAD,"['keystone/catalog/backends/sql.py', 'keystone/tests/test_sql_upgrade.py', 'keystone/common/sql/migrate_repo/versions/041_endpoint_enabled.py']",3,e5114d7ae35e6f4ab4c120bd6b0c3f4bbd5793ea,bug/1282266," # Copyright 2014 IBM Corp. # # Licensed under the Apache License, Version 2.0 (the ""License""); you may # not use this file except in compliance with the License. You may obtain # a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT # WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the # License for the specific language governing permissions and limitations # under the License. """"""Adds an `enabled` column to the `endpoint` table. The enabled value for the `endpoint` table was stored in the `extra` column as part of a JSON string. To upgrade, the `enabled` column is added with a default value of ``true``, then we check all the `extra` JSON for disabled and set the value to ``false`` for those. Downgrade is essentially the opposite -- we update the JSON with ``""enabled"": false`` for any endpoints that are disabled and drop the `enabled` column. """""" import json from sqlalchemy.orm import sessionmaker import sqlalchemy as sql from keystone.openstack.common import strutils def _migrate_enabled_from_extra(migrate_engine, endpoint_table): """"""Remove `enabled` from `extra`, put it in the `enabled` column."""""" eps = list(endpoint_table.select().execute()) for ep in eps: extra_dict = json.loads(ep.extra) if not 'enabled' in extra_dict: # `enabled` and `extra` are already as expected. continue enabled = extra_dict.pop('enabled') if enabled is None: enabled = True else: enabled = strutils.bool_from_string(enabled, default=True) new_values = { 'enabled': enabled, 'extra': json.dumps(extra_dict), } f = endpoint_table.c.id == ep.id update = endpoint_table.update().where(f).values(new_values) migrate_engine.execute(update) def _migrate_enabled_to_extra(migrate_engine, endpoint_table): """"""Get enabled value from 'enabled' column and put it in 'extra' JSON. Only put the enabled value to the 'extra' JSON if it's False, since the default is True. """""" eps = list(endpoint_table.select().execute()) for ep in eps: if ep.enabled: # Nothing to do since the endpoint is enabled. continue extra_dict = json.loads(ep.extra) extra_dict['enabled'] = False new_values = { 'extra': json.dumps(extra_dict), } f = endpoint_table.c.id == ep.id update = endpoint_table.update().where(f).values(new_values) migrate_engine.execute(update) def upgrade(migrate_engine): meta = sql.MetaData() meta.bind = migrate_engine endpoint_table = sql.Table('endpoint', meta, autoload=True) enabled_column = sql.Column('enabled', sql.Boolean, nullable=False, default=True, server_default='1') enabled_column.create(endpoint_table) _migrate_enabled_from_extra(migrate_engine, endpoint_table) def _downgrade_endpoint_table_with_copy(meta, migrate_engine): # Used with databases that don't support dropping a column (e.g., sqlite). maker = sessionmaker(bind=migrate_engine) session = maker() session.execute('ALTER TABLE endpoint RENAME TO orig_endpoint;') # Need to load the metadata for the service table since it's used as # foreign key. sql.Table('service', meta, autoload=True) endpoint_table = sql.Table( 'endpoint', meta, sql.Column('id', sql.String(64), primary_key=True), sql.Column('legacy_endpoint_id', sql.String(64)), sql.Column('interface', sql.String(8), nullable=False), sql.Column('region', sql.String(255)), sql.Column('service_id', sql.String(64), sql.ForeignKey('service.id'), nullable=False), sql.Column('url', sql.Text(), nullable=False), sql.Column('extra', sql.Text())) endpoint_table.create(migrate_engine, checkfirst=True) orig_endpoint_table = sql.Table('orig_endpoint', meta, autoload=True) for endpoint in session.query(orig_endpoint_table): session.execute('insert into endpoint (id, legacy_endpoint_id, ' 'interface, region, service_id, url, extra) ' 'values ( :id, :legacy_endpoint_id, :interface, ' ':region, :service_id, :url, :extra);', {'id': endpoint.id, 'legacy_endpoint_id': endpoint.legacy_endpoint_id, 'interface': endpoint.interface, 'region': endpoint.region, 'service_id': endpoint.service_id, 'url': endpoint.url, 'extra': endpoint.extra, }) session.execute('drop table orig_endpoint;') session.close() def downgrade(migrate_engine): meta = sql.MetaData() meta.bind = migrate_engine endpoint_table = sql.Table('endpoint', meta, autoload=True) _migrate_enabled_to_extra(migrate_engine, endpoint_table) if migrate_engine.name == 'sqlite': meta.clear() _downgrade_endpoint_table_with_copy(meta, migrate_engine) return endpoint_table.c.enabled.drop() ",,347,1
openstack%2Fpython-neutronclient~master~Icfda1a02e9b81cbf84bbbe477b539676a21b122a,openstack/python-neutronclient,master,Icfda1a02e9b81cbf84bbbe477b539676a21b122a,Add way to clear routes from router,ABANDONED,2014-03-05 18:20:57.000000000,2014-03-06 01:02:39.000000000,,"[{'_account_id': 3}, {'_account_id': 7317}]","[{'number': 1, 'created': '2014-03-05 18:20:57.000000000', 'files': ['neutronclient/neutron/v2_0/router.py', 'neutronclient/tests/unit/test_cli20_router.py'], 'web_link': 'https://opendev.org/openstack/python-neutronclient/commit/db4ad7cf15348f5642a799ea7ae7fa4cdfceb3df', 'message': 'Add way to clear routes from router\n\nThis patch adds the option --no-routes to update router which allows\none to clear the routes from a router.\n\nChange-Id: Icfda1a02e9b81cbf84bbbe477b539676a21b122a\nCloses-bug: #1288377\n'}]",0,78340,db4ad7cf15348f5642a799ea7ae7fa4cdfceb3df,3,2,1,4395,,,0,"Add way to clear routes from router

This patch adds the option --no-routes to update router which allows
one to clear the routes from a router.

Change-Id: Icfda1a02e9b81cbf84bbbe477b539676a21b122a
Closes-bug: #1288377
",git fetch https://review.opendev.org/openstack/python-neutronclient refs/changes/40/78340/1 && git format-patch -1 --stdout FETCH_HEAD,"['neutronclient/neutron/v2_0/router.py', 'neutronclient/tests/unit/test_cli20_router.py']",2,db4ad7cf15348f5642a799ea7ae7fa4cdfceb3df,master," def test_update_router_remove_routes(self): """"""Remove routes from router."""""" resource = 'router' cmd = router.UpdateRouter(test_cli20.MyApp(sys.stdout), None) self._test_update_resource(resource, cmd, 'myid', ['myid', '--no-routes'], {'routes': []}) ",,21,0
openstack%2Fkeystone~master~Iebe0358a19f645220eb7b3dfca0dc868716f5bc8,openstack/keystone,master,Iebe0358a19f645220eb7b3dfca0dc868716f5bc8,Add the last of the outstanding helpstrings to config,MERGED,2014-03-02 07:23:00.000000000,2014-03-06 01:02:35.000000000,2014-03-06 01:02:34.000000000,"[{'_account_id': 3}, {'_account_id': 4}, {'_account_id': 1916}, {'_account_id': 2218}, {'_account_id': 2903}, {'_account_id': 5707}, {'_account_id': 6482}, {'_account_id': 6486}, {'_account_id': 7191}, {'_account_id': 7725}]","[{'number': 1, 'created': '2014-03-02 07:23:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/d15a50ba1f37071aceb2c564c9ab072f83feff80', 'message': 'Add the last of the outstanding helpstrings to config\n\nAdd the last of the outstanding help strings to the options defined\nin keystone.common.config.\n\nRelated-Bug: #1229941\nChange-Id: Iebe0358a19f645220eb7b3dfca0dc868716f5bc8\n'}, {'number': 2, 'created': '2014-03-02 07:54:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/390d6e979bb06e83aee193707343632f9f0a19ec', 'message': 'Add the last of the outstanding helpstrings to config\n\nAdd the last of the outstanding help strings to the options defined\nin keystone.common.config.\n\nDocImpact\n\nRelated-Bug: #1229941\nChange-Id: Iebe0358a19f645220eb7b3dfca0dc868716f5bc8\n'}, {'number': 3, 'created': '2014-03-04 06:09:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/6ef26e86e7c85c906f92f51541470fe5a1c577db', 'message': 'Add the last of the outstanding helpstrings to config\n\nAdd the last of the outstanding help strings to the options defined\nin keystone.common.config.\n\nDocImpact\n\nRelated-Bug: #1229941\nChange-Id: Iebe0358a19f645220eb7b3dfca0dc868716f5bc8\n'}, {'number': 4, 'created': '2014-03-04 06:11:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/e02ac0bdd054fbb02ad800e1e7e4f9643c5fe3e6', 'message': 'Add the last of the outstanding helpstrings to config\n\nAdd the last of the outstanding help strings to the options defined\nin keystone.common.config.\n\nDocImpact\n\nRelated-Bug: #1229941\nChange-Id: Iebe0358a19f645220eb7b3dfca0dc868716f5bc8\n'}, {'number': 5, 'created': '2014-03-04 06:11:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/a1a177a7233cdae473e3ed2314fc40ac4ae62b22', 'message': 'Add the last of the outstanding helpstrings to config\n\nAdd the last of the outstanding help strings to the options defined\nin keystone.common.config.\n\nDocImpact\n\nRelated-Bug: #1229941\nChange-Id: Iebe0358a19f645220eb7b3dfca0dc868716f5bc8\n'}, {'number': 6, 'created': '2014-03-04 20:15:47.000000000', 'files': ['etc/keystone.conf.sample', 'keystone/common/config.py'], 'web_link': 'https://opendev.org/openstack/keystone/commit/81c49af0bdad830ec43431b529caf4a102902b39', 'message': 'Add the last of the outstanding helpstrings to config\n\nAdd the last of the outstanding help strings to the options defined\nin keystone.common.config.\n\nAdds in periods to the end of the helpstrings that were missing\nproper ending punctuation.\n\nDocImpact\n\nRelated-Bug: #1229941\nChange-Id: Iebe0358a19f645220eb7b3dfca0dc868716f5bc8\n'}]",15,77404,81c49af0bdad830ec43431b529caf4a102902b39,34,10,6,2903,,,0,"Add the last of the outstanding helpstrings to config

Add the last of the outstanding help strings to the options defined
in keystone.common.config.

Adds in periods to the end of the helpstrings that were missing
proper ending punctuation.

DocImpact

Related-Bug: #1229941
Change-Id: Iebe0358a19f645220eb7b3dfca0dc868716f5bc8
",git fetch https://review.opendev.org/openstack/keystone refs/changes/04/77404/2 && git format-patch -1 --stdout FETCH_HEAD,"['etc/keystone.conf.sample', 'keystone/common/config.py']",2,d15a50ba1f37071aceb2c564c9ab072f83feff80,auto_gen_config," cfg.BoolOpt('cert_required', default=False, help='Require client certificate.'), cfg.BoolOpt('use_dumb_member', default=False, help='Toggle use of the ""dumb_member"" in the ""member"" ' 'attribute on ""groupOfNames"" objectClasses.'), cfg.StrOpt('dumb_member', default='cn=dumb,dc=nonexistent', help='DN of the ""dumb_member"" to use when ' '""use_dumb_member"" is enabled'), cfg.IntOpt('user_enabled_mask', default=0, help='Bitmask integer to indicate the bit that the enabled ' 'value is stored in if the LDAP server represents ' '""enabled"" as a bit on an integer rather than a ' 'boolean.'), cfg.StrOpt('user_enabled_default', default='True', help='Default value to enable users. This should match an ' 'appropriate int value if the LDAP server uses ' 'non-boolean (bitmask) values to indicate if a user ' 'is enabled or disabled.'), cfg.BoolOpt('user_enabled_emulation', default=False, help='Enable support for emulating a mechanism to ' 'determine the enabled/disabled status of users ' 'for LDAP servers that do not provide any ""enabled"" ' 'attributes natively.'), cfg.StrOpt('user_enabled_emulation_dn', default=None, help='DN used to support user_enabled_emulation, must be ' 'a DN referencing a ""groupOfNames"". See the Keystone ' 'configuration documentation for more information.'), cfg.BoolOpt('tenant_enabled_emulation', default=False, help='Enable support for emulating a mechanism to ' 'determine the enabled/disabled status of projects ' 'for LDAP servers that do not provide any ""enabled"" ' 'attributes natively.'), cfg.StrOpt('tenant_enabled_emulation_dn', default=None, help='DN used to support tenant_enabled_emulation, must be ' 'a DN referencing a ""groupOfNames"". See the Keystone ' 'configuration documentation for more information.'), cfg.StrOpt('role_member_attribute', default='roleOccupant', help='LDAP attribute mapped to show role membership'),"," cfg.BoolOpt('cert_required', default=False,), cfg.BoolOpt('use_dumb_member', default=False), cfg.StrOpt('dumb_member', default='cn=dumb,dc=nonexistent'), cfg.IntOpt('user_enabled_mask', default=0), cfg.StrOpt('user_enabled_default', default='True'), cfg.BoolOpt('user_enabled_emulation', default=False), cfg.StrOpt('user_enabled_emulation_dn', default=None), cfg.BoolOpt('tenant_enabled_emulation', default=False), cfg.StrOpt('tenant_enabled_emulation_dn', default=None), cfg.StrOpt('role_member_attribute', default='roleOccupant'),",65,20
openstack%2Ftempest~master~I5c50affba0fce721583a6d56216e56c94ec3b188,openstack/tempest,master,I5c50affba0fce721583a6d56216e56c94ec3b188,Implement pluggability for tempest (exceptions),MERGED,2013-12-16 17:40:03.000000000,2014-03-06 01:02:27.000000000,2014-03-06 01:02:26.000000000,"[{'_account_id': 2}, {'_account_id': 3}, {'_account_id': 7}, {'_account_id': 1192}, {'_account_id': 1921}, {'_account_id': 5586}, {'_account_id': 5689}, {'_account_id': 5803}, {'_account_id': 6796}, {'_account_id': 7872}, {'_account_id': 8851}]","[{'number': 1, 'created': '2013-12-16 17:40:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/1bb4b4932652e62d6a20fc6e8139db213c064dfd', 'message': 'This patch adds to Tempest pluggable functionality for\napi (clients, config and exceptions) and cli tests.\n\nAdding of some new service client and tests that use it,\ncan be done just with placing it in appropriate directories.\n\nIt is very usefull for new projects, who can store their\ntempest code as plugins in their projects.\n\nImplements bp make-tempest-pluggable\n\nChange-Id: I5c50affba0fce721583a6d56216e56c94ec3b188\n'}, {'number': 2, 'created': '2013-12-16 17:42:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/b114f573a845aad9226134acc2e3677d76f5f052', 'message': 'Add pluggable functionality for api and cli tests\n\nThis patch adds to Tempest pluggable functionality for\napi (clients, config and exceptions) and cli tests.\n\nAdding of some new service client and tests that use it,\ncan be done just with placing it in appropriate directories.\n\nIt is very usefull for new projects, who can store their\ntempest code as plugins in their projects.\n\nImplements bp make-tempest-pluggable\n\nChange-Id: I5c50affba0fce721583a6d56216e56c94ec3b188\n'}, {'number': 3, 'created': '2013-12-17 15:33:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/6b47ceae37d107b04c802cdb69d1386a72f38f5b', 'message': 'Add pluggable functionality for api and cli tests\n\nThis patch adds to Tempest pluggable functionality for\napi (clients, config and exceptions) and cli tests.\n\nAdding of some new service client and tests that use it,\ncan be done just with placing it in appropriate directories.\n\nIt is very usefull for new projects, who can store their\ntempest code as plugins in their projects.\n\nImplements bp make-tempest-pluggable\n\nChange-Id: I5c50affba0fce721583a6d56216e56c94ec3b188\n'}, {'number': 4, 'created': '2013-12-18 10:18:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/918b1e2501bfa2a99e672a9ce87580b0c310b264', 'message': 'Add pluggable functionality for api and cli tests\n\nThis patch adds to Tempest pluggable functionality for\napi (clients, config and exceptions) and cli tests.\n\nAdding of some new service client and tests that use it,\ncan be done just with placing it in appropriate directories.\n\nIt is very usefull for new projects, who can store their\ntempest code as plugins in their projects.\n\nImplements bp make-tempest-pluggable\n\nChange-Id: I5c50affba0fce721583a6d56216e56c94ec3b188\n'}, {'number': 5, 'created': '2013-12-20 09:04:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/20e485f3622d402e775ea1caf0e3539619e3f0d2', 'message': 'Add pluggable functionality for api and cli tests\n\nThis patch adds to Tempest pluggable functionality for\napi (clients, config and exceptions) and cli tests.\n\nAdding of some new service client and tests that use it,\ncan be done just with placing it in appropriate directories.\n\nIt is very usefull for new projects, who can store their\ntempest code as plugins in their projects.\n\nAdded examples of external stuff:\n- for api without using real service\n- for cli used external method for keystone\n\nTo test it by yourself, you can run next tests:\ntempest/api/ext_example/test_ext.py\nand\ntempest/cli/simple_read_only/test_keystone_ext_example.py\n\nImplements bp make-tempest-pluggable\n\nChange-Id: I5c50affba0fce721583a6d56216e56c94ec3b188\n'}, {'number': 6, 'created': '2013-12-20 10:12:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/a6fcb0c38cb59308ed9e92af6f1be91c2da2ed1c', 'message': 'Add pluggable functionality for api and cli tests\n\nThis patch adds to Tempest pluggable functionality for\napi (clients, config and exceptions) and cli tests.\n\nAdding of some new service client and tests that use it,\ncan be done just with placing it in appropriate directories.\n\nIt is very usefull for new projects, who can store their\ntempest code as plugins in their projects.\n\nAdded examples of external stuff:\n- for api without using real service\n- for cli used external method for keystone\n\nTo test it by yourself, you can run next tests:\ntempest/api/ext_example/test_ext.py\nand\ntempest/cli/simple_read_only/test_keystone_ext_example.py\n\nImplements bp make-tempest-pluggable\n\nChange-Id: I5c50affba0fce721583a6d56216e56c94ec3b188\n'}, {'number': 7, 'created': '2013-12-20 11:08:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/782036ff344bff43d1aeffae150a1fc686c9d16a', 'message': 'Add pluggable functionality for api and cli tests\n\nThis patch adds to Tempest pluggable functionality for\napi (clients, config and exceptions) and cli tests.\n\nAdding of some new service client and tests that use it,\ncan be done just with placing it in appropriate directories.\n\nIt is very usefull for new projects, who can store their\ntempest code as plugins in their projects.\n\nAdded examples of external stuff:\n- for api without using real service\n- for cli used external method for keystone\n\nTo test it by yourself, you can run next tests:\ntempest/api/ext_example/test_ext.py\nand\ntempest/cli/simple_read_only/test_keystone_ext_example.py\n\nImplements bp make-tempest-pluggable\n\nChange-Id: I5c50affba0fce721583a6d56216e56c94ec3b188\n'}, {'number': 8, 'created': '2013-12-23 11:00:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/3b8b697a54d0996bd8eb3855ed94aad5db1620bf', 'message': 'Add pluggable functionality for api and cli tests\n\nThis patch adds to Tempest pluggable functionality for\napi (clients, config and exceptions) and cli tests.\n\nAdding of some new service client and tests that use it,\ncan be done just with placing it in appropriate directories.\n\nIt is very usefull for new projects, who can store their\ntempest code as plugins in their projects.\n\nAdded examples of external stuff:\n- for api without using real service\n- for cli used external method for keystone\n\nTo test it by yourself, you can run next tests:\ntempest/api/ext_example/test_ext.py\nand\ntempest/cli/simple_read_only/test_keystone_ext_example.py\n\nImplements bp make-tempest-pluggable\n\nChange-Id: I5c50affba0fce721583a6d56216e56c94ec3b188\n'}, {'number': 9, 'created': '2013-12-31 09:37:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/3ba8d0cde955d8eee4c7e577026d80a8c69132f2', 'message': 'Add pluggable functionality for api and cli tests\n\nThis patch adds to Tempest pluggable functionality for\napi (clients, config and exceptions) and cli tests.\n\nAdding of some new service client and tests that use it,\ncan be done just with placing it in appropriate directories.\n\nIt is very usefull for new projects, who can store their\ntempest code as plugins in their projects.\n\nAdded examples of external stuff:\n- for api without using real service\n- for cli used external method for keystone\n\nTo test it by yourself, you can run next tests:\ntempest/api/ext_example/test_ext.py\nand\ntempest/cli/simple_read_only/test_keystone_ext_example.py\n\nAlso, exceptions.py were separated to two files,\none with base classes and one with final exception classes.\n\nImplements bp make-tempest-pluggable\n\nChange-Id: I5c50affba0fce721583a6d56216e56c94ec3b188\n'}, {'number': 10, 'created': '2014-01-07 13:02:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/4e479bf9485b74d68642a5d2480aa543dafd7641', 'message': 'Make clients, config and exceptions pluggable\n\nThis patch adds, to Tempest, pluggable functionality for\nclients, config and exceptions.\n\nIt is very useful for new projects, who can just place\nneeded files into appropriate dirs without changing\ntempest core files, to run tests againt new project.\n\nAlso, existing files can be separated to different\nfiles, as it done in this patch.\n\nImplements bp make-tempest-pluggable\n\nChange-Id: I5c50affba0fce721583a6d56216e56c94ec3b188\n'}, {'number': 11, 'created': '2014-01-07 13:12:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/85ab826b92a930546898bced5bf8e4d0af3e0939', 'message': 'Make clients, config and exceptions pluggable\n\nThis patch adds, to Tempest, pluggable functionality for\nclients, config and exceptions.\n\nIt is very useful for new projects, who can just place\nneeded files into appropriate dirs without changing\ntempest core files, to run tests againt new project.\n\nAlso, existing files can be separated to different\nfiles, as it done in this patch.\n\nImplements bp make-tempest-pluggable\n\nChange-Id: I5c50affba0fce721583a6d56216e56c94ec3b188\n'}, {'number': 12, 'created': '2014-01-16 18:02:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/ebaada6521cf45410213e195b505755615c71637', 'message': 'Make clients, config and exceptions pluggable\n\nThis patch adds, to Tempest, pluggable functionality for\nclients, config and exceptions.\n\nIt is very useful for new projects, who can just place\nneeded files into appropriate dirs without changing\ntempest core files, to run tests againt new project.\n\nAlso, existing files can be separated to different\nfiles, as it done in this patch.\n\nImplements bp make-tempest-pluggable\n\nChange-Id: I5c50affba0fce721583a6d56216e56c94ec3b188\n'}, {'number': 13, 'created': '2014-01-21 10:08:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/4e834a1bb476d3a92ef4d8178625d77bb05beb62', 'message': 'Make clients, config and exceptions pluggable\n\nThis patch adds, to Tempest, pluggable functionality for\nclients, config and exceptions.\n\nIt is very useful for new projects, who can just place\nneeded files into appropriate dirs without changing\ntempest core files, to run tests againt new project.\n\nAlso, existing files can be separated to different\nfiles, as it done in this patch.\n\nImplements bp make-tempest-pluggable\n\nChange-Id: I5c50affba0fce721583a6d56216e56c94ec3b188\n'}, {'number': 14, 'created': '2014-01-21 10:10:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/a79fd6df97e219f21fcfb7d4e038444cb863bfd3', 'message': 'Make clients, config and exceptions pluggable\n\nThis patch adds, to Tempest, pluggable functionality for\nclients, config and exceptions.\n\nIt is very useful for new projects, who can just place\nneeded files into appropriate dirs without changing\ntempest core files, to run tests against new project.\n\nAlso, existing files can be separated to different\nfiles, as it done in this patch.\n\nImplements bp make-tempest-pluggable\n\nChange-Id: I5c50affba0fce721583a6d56216e56c94ec3b188\n'}, {'number': 15, 'created': '2014-01-21 13:41:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/943bc2741c931bcab0601f4e024a958667a8ccf3', 'message': 'Make clients, config and exceptions pluggable\n\nThis patch adds, to Tempest, pluggable functionality for\nclients, config and exceptions.\n\nIt is very useful for new projects, who can just place\nneeded files into appropriate dirs without changing\ntempest core files, to run tests against new project.\n\nAlso, existing files can be separated to different\nfiles, as it done in this patch.\n\nImplements bp make-tempest-pluggable\n\nChange-Id: I5c50affba0fce721583a6d56216e56c94ec3b188\n'}, {'number': 16, 'created': '2014-01-21 17:41:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/3b30ef17c89f2542b436d7599f8b506b7e8d95b8', 'message': 'Make clients, config and exceptions pluggable\n\nThis patch adds, to Tempest, pluggable functionality for\nclients, config and exceptions.\n\nIt is very useful for new projects, who can just place\nneeded files into appropriate dirs without changing\ntempest core files, to run tests against new project.\n\nAlso, existing files can be separated to different\nfiles, as it done in this patch.\n\nImplements bp make-tempest-pluggable\n\nChange-Id: I5c50affba0fce721583a6d56216e56c94ec3b188\n'}, {'number': 17, 'created': '2014-01-25 08:37:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/515aa9ee05564708cb4684281094ee3af520d0b6', 'message': 'Make clients, config and exceptions pluggable\n\nThis patch adds, to Tempest, pluggable functionality for\nclients, config and exceptions.\n\nIt is very useful for new projects, who can just place\nneeded files into appropriate dirs without changing\ntempest core files, to run tests against new project.\n\nAlso, existing files can be separated to different\nfiles, as it done in this patch.\n\nPlugged configs with be automatically added to config-proxy\nLook at the example of cli config in this patch.\n\nImplements bp make-tempest-pluggable\n\nChange-Id: I5c50affba0fce721583a6d56216e56c94ec3b188\n'}, {'number': 18, 'created': '2014-01-25 08:44:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/8c08ebb81f9e3f648aabd3c5e6aeb38618f9ff7e', 'message': 'Make clients, config and exceptions pluggable\n\nThis patch adds, to Tempest, pluggable functionality for\nclients, config and exceptions.\n\nIt is very useful for new projects, who can just place\nneeded files into appropriate dirs without changing\ntempest core files, to run tests against new project.\n\nAlso, existing files can be separated to different\nfiles, as it done in this patch.\n\nPlugged configs will be automatically added to config-proxy\nLook at the example of cli config in this patch.\n\nImplements bp make-tempest-pluggable\n\nChange-Id: I5c50affba0fce721583a6d56216e56c94ec3b188\n'}, {'number': 19, 'created': '2014-01-29 20:56:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/a2bb27eacc2b9f37b538052d65456720caf67fb7', 'message': 'Implement pluggability for tempest (exceptions)\n\nFirst patch of three patches:\n->1. exceptions (+ module_utils.py)\n  2. clients\n  3. config\n\nIt is very useful for new projects, who can just place\nneeded files into appropriate dirs without changing\ntempest core files.\nMuch less merge conflicts and separation of base classes and\nchild classes.\n\nPartially-implements: bp make-tempest-pluggable\n\nChange-Id: I5c50affba0fce721583a6d56216e56c94ec3b188\n'}, {'number': 20, 'created': '2014-02-04 07:33:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/ae5a4a15bb0959fb368a44c7681d43088759f65d', 'message': 'Implement pluggability for tempest (exceptions)\n\nFirst patch of three patches:\n->1. exceptions\n  2. clients\n  3. config\n\nIt is very useful for new projects(old too), who can just place\nneeded files into appropriate dirs without changing\ntempest core files.\nMuch less merge conflicts and separation of base classes and\nchild classes.\n\nPartially-implements: bp make-tempest-pluggable\n\nChange-Id: I5c50affba0fce721583a6d56216e56c94ec3b188\n'}, {'number': 21, 'created': '2014-02-23 07:57:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/b25aac595dd2a40f0f0225dc03cee29ed99daf94', 'message': ""Implement pluggability for tempest (exceptions)\n\nFirst patch of three patches:\n->1. exceptions\n  2. config (+ module_utils.py)\n  3. clients\n\nThe main intend is in moving currently existed single 'exceptions' module in\nexceptions tree.\nIt allows separate exceptions by differencies:\n- base\n- main/common\n- project-specific\n\nIt also allows to simplify search and using of exceptions, merge changes into\nTempest with minimized amount of merge conflicts.\n\nPartially-implements: bp make-tempest-pluggable\n\nChange-Id: I5c50affba0fce721583a6d56216e56c94ec3b188\n""}, {'number': 22, 'created': '2014-02-24 15:38:09.000000000', 'files': ['tempest/exceptions/README.rst', 'tempest/exceptions/base.py', 'tempest/exceptions/__init__.py', 'tempest/exceptions.py'], 'web_link': 'https://opendev.org/openstack/tempest/commit/82411edb9c1089cac53572e7720559b927b59fbd', 'message': ""Implement pluggability for tempest (exceptions)\n\nFirst patch of three patches:\n->1. exceptions\n  2. config (+ module_utils.py)\n  3. clients\n\nThe main intend is in moving currently existed single 'exceptions' module in\nexceptions tree.\nIt allows separate exceptions by differencies:\n- base\n- main/common\n- project-specific\n\nIt also allows to simplify search and using of exceptions, merge changes into\nTempest with minimized amount of merge conflicts.\n\nPartially-implements: bp make-tempest-pluggable\n\nChange-Id: I5c50affba0fce721583a6d56216e56c94ec3b188\n""}]",45,62429,82411edb9c1089cac53572e7720559b927b59fbd,120,11,22,8851,,,0,"Implement pluggability for tempest (exceptions)

First patch of three patches:
->1. exceptions
  2. config (+ module_utils.py)
  3. clients

The main intend is in moving currently existed single 'exceptions' module in
exceptions tree.
It allows separate exceptions by differencies:
- base
- main/common
- project-specific

It also allows to simplify search and using of exceptions, merge changes into
Tempest with minimized amount of merge conflicts.

Partially-implements: bp make-tempest-pluggable

Change-Id: I5c50affba0fce721583a6d56216e56c94ec3b188
",git fetch https://review.opendev.org/openstack/tempest refs/changes/29/62429/6 && git format-patch -1 --stdout FETCH_HEAD,"['tempest/cli/__init__.py', 'tempest/external/cli/__init__.py', 'tempest/clients.py', 'tempest/config.py', 'tempest/external/__init__.py', 'tempest/exceptions.py', 'tempest/external/clients/__init__.py', 'tempest/external/exceptions/__init__.py', 'tempest/external/config/__init__.py']",9,1bb4b4932652e62d6a20fc6e8139db213c064dfd,bp/make-tempest-pluggable,"# Copyright 2013 Mirantis Inc. # All Rights Reserved # # Licensed under the Apache License, Version 2.0 (the ""License""); you may # not use this file except in compliance with the License. You may obtain # a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT # WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the # License for the specific language governing permissions and limitations # under the License. # Place in this module submodules, where # you register some new groups or options # to oslo.config import sys from tempest.external import import_submodules import_submodules(sys.modules[__name__]) del import_submodules del sys ",,192,0
openstack%2Fkeystone~master~Iaad8c7c5a32bc6cff38c938dd36365cddd6741cb,openstack/keystone,master,Iaad8c7c5a32bc6cff38c938dd36365cddd6741cb,Update curl api example to specify tenant,MERGED,2014-02-28 23:17:04.000000000,2014-03-06 00:59:47.000000000,2014-03-06 00:59:46.000000000,"[{'_account_id': 3}, {'_account_id': 4}, {'_account_id': 494}, {'_account_id': 2903}, {'_account_id': 5046}, {'_account_id': 6287}, {'_account_id': 6460}, {'_account_id': 6482}, {'_account_id': 10434}, {'_account_id': 10435}]","[{'number': 1, 'created': '2014-02-28 23:17:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/d481df9e224e6aeb9235289aae1e66b65bf38bb6', 'message': 'Update curl api example to specify tenant\n\nIn the keystone api_curl_examples document, the curl example for\n""POST /tokens"" did not specify a tenant. This example utilized\nthe default tenant, which is not commonly used. Changed the\nexample to include ""tenantName"" as part of the example to prevent\nfuture confusion.\n\nDocImpact\n\nCloses-Bug: #1269739\n\nChange-Id: Iaad8c7c5a32bc6cff38c938dd36365cddd6741cb\n'}, {'number': 2, 'created': '2014-03-03 17:29:41.000000000', 'files': ['doc/source/api_curl_examples.rst'], 'web_link': 'https://opendev.org/openstack/keystone/commit/ae34f84f271f8965b248ffbc9860506a8a7e6951', 'message': 'Update curl api example to specify tenant\n\nIn the keystone api_curl_examples document, the curl example for\n""POST /tokens"" did not specify a tenant. This example utilized\nthe default tenant, which is not commonly used. Changed the\nexample to include ""tenantName"" as part of the example to prevent\nfuture confusion.\n\nDocImpact\n\nCloses-Bug: #1269739\n\nChange-Id: Iaad8c7c5a32bc6cff38c938dd36365cddd6741cb\n'}]",7,77294,ae34f84f271f8965b248ffbc9860506a8a7e6951,26,10,2,10434,,,0,"Update curl api example to specify tenant

In the keystone api_curl_examples document, the curl example for
""POST /tokens"" did not specify a tenant. This example utilized
the default tenant, which is not commonly used. Changed the
example to include ""tenantName"" as part of the example to prevent
future confusion.

DocImpact

Closes-Bug: #1269739

Change-Id: Iaad8c7c5a32bc6cff38c938dd36365cddd6741cb
",git fetch https://review.opendev.org/openstack/keystone refs/changes/94/77294/2 && git format-patch -1 --stdout FETCH_HEAD,['doc/source/api_curl_examples.rst'],1,d481df9e224e6aeb9235289aae1e66b65bf38bb6,api_curl_doc_update," $ curl -d '{""auth"":{""tenantName"": ""desired_tenant"", ""passwordCredentials"": {""username"": ""joeuser"", ""password"": ""secrete""}}}' -H ""Content-type: application/json"" http://localhost:35357/v2.0/tokens"," $ curl -d '{""auth"":{""passwordCredentials"":{""username"": ""joeuser"", ""password"": ""secrete""}}}' -H ""Content-type: application/json"" http://localhost:35357/v2.0/tokens",1,1
openstack%2Fkeystone~master~Id0872daa159c58b502060ece9748d01da59519ea,openstack/keystone,master,Id0872daa159c58b502060ece9748d01da59519ea,Mark revoke as experimental,MERGED,2014-03-05 01:17:07.000000000,2014-03-06 00:57:18.000000000,2014-03-06 00:57:17.000000000,"[{'_account_id': 3}, {'_account_id': 4}, {'_account_id': 792}, {'_account_id': 1916}, {'_account_id': 2218}, {'_account_id': 2903}, {'_account_id': 5707}, {'_account_id': 6460}, {'_account_id': 6482}, {'_account_id': 6486}, {'_account_id': 7191}, {'_account_id': 7725}]","[{'number': 1, 'created': '2014-03-05 01:17:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/2fb807b5ec75e069b3681000b04171886ef7be33', 'message': 'Mark revoke as experimental\n\nChange-Id: Id0872daa159c58b502060ece9748d01da59519ea\n'}, {'number': 2, 'created': '2014-03-05 17:14:45.000000000', 'files': ['doc/source/extensions/revoke-configuration.rst'], 'web_link': 'https://opendev.org/openstack/keystone/commit/01a538e2d79f911cdf5b886cce23433f74661e32', 'message': 'Mark revoke as experimental\n\nChange-Id: Id0872daa159c58b502060ece9748d01da59519ea\n'}]",1,78058,01a538e2d79f911cdf5b886cce23433f74661e32,23,12,2,2218,,,0,"Mark revoke as experimental

Change-Id: Id0872daa159c58b502060ece9748d01da59519ea
",git fetch https://review.opendev.org/openstack/keystone refs/changes/58/78058/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/source/extensions/revoke-configuration.rst'],1,2fb807b5ec75e069b3681000b04171886ef7be33,78058,WARNING: The OS-REVOKE Extension is still considered experimental and will continue to see improvement over the next development cycle. ,,3,0
openstack%2Fpython-swiftclient~master~I67a47bdd5681b4b221baf55933a175568aa8e16d,openstack/python-swiftclient,master,I67a47bdd5681b4b221baf55933a175568aa8e16d,Help string format persistent,MERGED,2014-02-26 19:31:47.000000000,2014-03-06 00:57:16.000000000,2014-03-06 00:57:16.000000000,"[{'_account_id': 3}, {'_account_id': 917}, {'_account_id': 2622}, {'_account_id': 6198}, {'_account_id': 6968}, {'_account_id': 10378}]","[{'number': 1, 'created': '2014-02-26 19:31:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-swiftclient/commit/cd4c91dd44b1150b6781880ea7d781c2f367317a', 'message': 'Help string format persistent\n\nKeep the format of these strings constant through all options and commands.\n\nChange-Id: I67a47bdd5681b4b221baf55933a175568aa8e16d\n'}, {'number': 2, 'created': '2014-02-26 20:14:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-swiftclient/commit/205ff1d6a9ca47cf5c94d34e04d612adcc74dc3c', 'message': 'Help string format persistent\n\nKeep the format of these strings constant through all options and commands.\n\nChange-Id: I67a47bdd5681b4b221baf55933a175568aa8e16d\n'}, {'number': 3, 'created': '2014-02-26 20:53:22.000000000', 'files': ['bin/swift'], 'web_link': 'https://opendev.org/openstack/python-swiftclient/commit/25a0e636193b8662fdfcfc498c1f4bbdb6048308', 'message': 'Help string format persistent\n\nKeep the format of these strings constant through all options and commands.\n\nChange-Id: I67a47bdd5681b4b221baf55933a175568aa8e16d\n'}]",2,76630,25a0e636193b8662fdfcfc498c1f4bbdb6048308,23,6,3,10378,,,0,"Help string format persistent

Keep the format of these strings constant through all options and commands.

Change-Id: I67a47bdd5681b4b221baf55933a175568aa8e16d
",git fetch https://review.opendev.org/openstack/python-swiftclient refs/changes/30/76630/2 && git format-patch -1 --stdout FETCH_HEAD,['bin/swift'],1,cd4c91dd44b1150b6781880ea7d781c2f367317a,help-consistency," <container> Name of container to delete from. for multiple objects. --all Delete all containers and objects. --leave-segments Do not delete segments of manifest objects. 'might have meant %r instead of %r.' % \ (args[0].replace('/', ' ', 1), args[0]) --all Indicates that you really want to download everything in the account. download. --prefix <prefix> Only download items beginning with <prefix>. redirect to stdout. to disk. --skip-identical Skip downloading files that are identical on both sides. 'everything in the account.') 'account download.') default=10, help='Number of threads to use for downloading objects. ' 'Default is 10') help='Number of threads to use for downloading containers. ' 'Default is 10') help=""Perform download(s), but don't actually write anything to disk."") 'both sides.') [container] Name of container to list object in. --long Long listing format, similar to ls -l. --lh Report sizes in human readable format similar to ls -lh. --totals Used with -l or --lh, only report totals. --prefix Only list items beginning with the prefix. '-t', '--totals', dest='totals', action='store_true', default=False, help='Used with -l or --lh, only report totals.') [container] Name of container to stat from. for multiple objects. --lh Report sizes in human readable format similar to ls -lh. [container] Name of container to post to. for multiple objects. --sync-to <sync-to> Sync To for containers, for multi-cluster replication. --sync-key <sync-key> Sync Key for containers, for multi-cluster replication. '-r', '--read-acl', dest='read_acl', help='Read ACL for containers. ' 'Quick summary of ACL syntax: .r:*, .r:-.example.com, ' '.r:www.example.com, account1, account2:user2') '-w', '--write-acl', dest='write_acl', help='Write ACL for ' 'containers. Quick summary of ACL syntax: account1, ' <container> Name of container to upload to. times for multiple uploads. upload. --skip-identical Skip uploading files that are identical on both sides. the segments as if it were the original file. objects left alone (in the case of overwrites). --use-slo When used in conjunction with --segment-size it will folder name. 'both sides.') '-S', '--segment-size', dest='segment_size', help='Upload files ' 'in segments no larger than <size> and then create a ""manifest"" ' 'file that will download all the segments as if it were the original ' 'file.') 'overwrites).') help='When used in conjunction with --segment-size it will ' delete Delete a container or objects within a container. download Download objects from containers. for a container. or object; creates containers if not present. or object. capabilities List cluster capabilities. 'by the system SSL library.')"," <container> Name of container to delete from for multiple objects --all Delete all containers and objects --leave-segments Do not delete segments of manifest objects 'might have meant %r instead of %r.' % ( args[0].replace('/', ' ', 1), args[0]) --all Indicates that you really want to download everything in the account download --prefix <prefix> Only download items beginning with <prefix> redirect to stdout to disk --skip-identical Skip downloading files that are identical on both sides 'everything in the account') 'account download') default=10, help='Number of threads to use for downloading objects') help='Number of threads to use for downloading containers') help=""Perform download(s), but don't actually write anything to disk"") 'both sides') [container] Name of container to list object in --long Long listing format, similar to ls -l --lh Report sizes in human readable format similar to ls -lh --totals Used with -l or --lh, only report totals --prefix Only list items beginning with the prefix '-t', '--totals', dest='totals', help='used with -l or --lh, ' 'only report totals', action='store_true', default=False) [container] Name of container to stat from for multiple objects --lh Report sizes in human readable format similar to ls -lh [container] Name of container to post to for multiple objects --sync-to <sync-to> Sync To for containers, for multi-cluster replication --sync-key <sync-key> Sync Key for containers, for multi-cluster replication '-r', '--read-acl', dest='read_acl', help='Sets the ' 'Read ACL for containers. Quick summary of ACL syntax: .r:*, ' '.r:-.example.com, .r:www.example.com, account1, account2:user2') '-w', '--write-acl', dest='write_acl', help='Sets the ' 'Write ACL for containers. Quick summary of ACL syntax: account1, ' <container> Name of container to upload to times for multiple uploads upload --skip-identical Skip uploading files that are identical on both sides the segments as if it were the original file objects left alone (in the case of overwrites) --use-slo When used in conjunction with --segment-size will folder name 'both sides') '-S', '--segment-size', dest='segment_size', help='Will ' 'upload files in segments no larger than <size> and then create a ' '""manifest"" file that will download all the segments as if it were ' 'the original file.') 'overwrites)') help='When used in conjunction with --segment-size will ' delete Delete a container or objects within a container download Download objects from containers for a container or object; creates containers if not present or object capabilities List cluster capabilities 'by the system SSL library')",65,61
openstack%2Fnova~master~Ia649eab824d336c5dc1bf50889efc91e3692145b,openstack/nova,master,Ia649eab824d336c5dc1bf50889efc91e3692145b,Make compute manager use Quota objects,ABANDONED,2014-03-03 02:26:09.000000000,2014-03-06 00:55:36.000000000,,"[{'_account_id': 3}, {'_account_id': 782}, {'_account_id': 1849}, {'_account_id': 6062}, {'_account_id': 6450}, {'_account_id': 9008}, {'_account_id': 9578}]","[{'number': 1, 'created': '2014-03-03 02:26:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/6f383a6c563a317f1671eaa22fc0789c49642f7c', 'message': ""Make compute manager use Quota objects\n\nThis patch makes compute manager use the Quota objects.\nAlso, update test cases that didn't use objects in compute test.\n\nRelated to blueprint compute-manager-objects\n\nChange-Id: Ia649eab824d336c5dc1bf50889efc91e3692145b\n""}, {'number': 2, 'created': '2014-03-03 06:54:10.000000000', 'files': ['nova/tests/compute/test_compute_api.py', 'nova/scheduler/manager.py', 'nova/tests/conductor/test_conductor.py', 'nova/tests/scheduler/test_scheduler.py', 'nova/conductor/manager.py', 'nova/compute/manager.py', 'nova/tests/compute/test_compute.py', 'nova/compute/api.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/ced442b9614025df71dd47ef1273742687331e92', 'message': ""Make compute manager use Quota objects\n\nThis patch makes compute manager use the Quota objects.\nAlso, update test cases that didn't use objects in compute test.\n\nRelated to blueprint compute-manager-objects\n\nChange-Id: Ia649eab824d336c5dc1bf50889efc91e3692145b\n""}]",7,77475,ced442b9614025df71dd47ef1273742687331e92,19,7,2,6062,,,0,"Make compute manager use Quota objects

This patch makes compute manager use the Quota objects.
Also, update test cases that didn't use objects in compute test.

Related to blueprint compute-manager-objects

Change-Id: Ia649eab824d336c5dc1bf50889efc91e3692145b
",git fetch https://review.opendev.org/openstack/nova refs/changes/75/77475/2 && git format-patch -1 --stdout FETCH_HEAD,"['nova/tests/compute/test_compute_api.py', 'nova/scheduler/manager.py', 'nova/tests/conductor/test_conductor.py', 'nova/tests/scheduler/test_scheduler.py', 'nova/conductor/manager.py', 'nova/compute/manager.py', 'nova/compute/api.py', 'nova/tests/compute/test_compute.py']",8,6f383a6c563a317f1671eaa22fc0789c49642f7c,bp/compute-manager-objects," reservations = quotas_obj.Quotas() reservations._context = self.context reservations.reservations = list('fake-res') nova.quota.QUOTAS.commit(mox.IgnoreArg(), reservations.reservations, project_id = reservations.project_id, user_id = reservations.user_id) reservations = quotas_obj.Quotas() nova.quota.QUOTAS.rollback(mox.IgnoreArg(), reservations.reservations, project_id = reservations.project_id, user_id = reservations.user_id)"," reservations = list('fake_res') nova.quota.QUOTAS.commit(mox.IgnoreArg(), reservations, project_id=(expect_project and self.context.project_id or None), user_id=(expect_user and self.context.user_id or None)) reservations = list('fake_res') nova.quota.QUOTAS.rollback(mox.IgnoreArg(), reservations, project_id=(expect_project and self.context.project_id or None), user_id=(expect_user and self.context.user_id or None))",113,130
openstack%2Fpython-swiftclient~master~I575a71769600f95c33cc4bbc9904b313f890e997,openstack/python-swiftclient,master,I575a71769600f95c33cc4bbc9904b313f890e997,Make the help strings constant,MERGED,2014-02-19 03:24:11.000000000,2014-03-06 00:54:36.000000000,2014-03-06 00:54:36.000000000,"[{'_account_id': 3}, {'_account_id': 330}, {'_account_id': 2622}, {'_account_id': 6198}, {'_account_id': 6968}, {'_account_id': 10378}]","[{'number': 1, 'created': '2014-02-19 03:24:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-swiftclient/commit/d597bb30392307b935707789d379cd6301bd985e', 'message': 'make the help strings constant\n\nMake the option help string match the usage text for each command.\nKeep the format of these strings constant through all options and commands.\n\nChange-Id: I575a71769600f95c33cc4bbc9904b313f890e997\n'}, {'number': 2, 'created': '2014-02-19 15:41:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-swiftclient/commit/defe19f11df9e8fb15df2cecee95cf719ceda4f1', 'message': 'make the help strings constant\n\nMake the option help string match the usage text for each command.\nKeep the format of these strings constant through all options and commands.\n\nChange-Id: I575a71769600f95c33cc4bbc9904b313f890e997\n'}, {'number': 3, 'created': '2014-02-23 22:12:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-swiftclient/commit/39361af1068813997900207ae3f508ed9dcc6ff5', 'message': 'make the help strings constant\n\nMake the option help string match the usage text for each command.\nKeep the format of these strings constant through all options and commands.\n\nChange-Id: I575a71769600f95c33cc4bbc9904b313f890e997\n'}, {'number': 4, 'created': '2014-02-26 19:31:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-swiftclient/commit/10a557e47af0bd4468111445d1266864f4685841', 'message': 'Make the help strings constant\n\nHave all the option help strinsg match the usage text for that command.\n\nChange-Id: I575a71769600f95c33cc4bbc9904b313f890e997\n'}, {'number': 5, 'created': '2014-02-26 20:06:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-swiftclient/commit/f43afcb0220eb23f083cb71bf4833a1e885af888', 'message': 'Make the help strings constant\n\nHave all the option help strinsg match the usage text for that command.\n\nChange-Id: I575a71769600f95c33cc4bbc9904b313f890e997\n'}, {'number': 6, 'created': '2014-02-26 20:53:22.000000000', 'files': ['bin/swift'], 'web_link': 'https://opendev.org/openstack/python-swiftclient/commit/f2cd140ccda932933cbaffdfdf05aab36c29e292', 'message': 'Make the help strings constant\n\nHave all the option help strinsg match the usage text for that command.\n\nChange-Id: I575a71769600f95c33cc4bbc9904b313f890e997\n'}]",14,74578,f2cd140ccda932933cbaffdfdf05aab36c29e292,39,6,6,10378,,,0,"Make the help strings constant

Have all the option help strinsg match the usage text for that command.

Change-Id: I575a71769600f95c33cc4bbc9904b313f890e997
",git fetch https://review.opendev.org/openstack/python-swiftclient refs/changes/78/74578/3 && git format-patch -1 --stdout FETCH_HEAD,['bin/swift'],1,d597bb30392307b935707789d379cd6301bd985e,help-consistency," --all Delete all containers and objects. --leave-segments Do not delete segments of manifest objects. default=False, help='Delete all containers and objects.') help='Do not delete segments of manifest objects.') default=10, help='Number of threads to use for deleting objects. ' 'Default is 10') 'deleting containers. ' 'Default is 10') everything in the account. download. --prefix <prefix> Only download items beginning with <prefix>. redirect to stdout. to disk. --skip-identical Skip downloading files that are identical on both sides. 'everything in the account.') 'account download.') help='Only download items beginning with the <prefix>.') 'For a single file download, stream the output to <out_file>. ' 'Specifying ""-"" as <out_file> will redirect to stdout.') default=10, help='Number of threads to use for downloading objects. ' 'Default is 10') help='Number of threads to use for downloading containers. ' 'Default is 10') help=""Perform download(s), but don't actually write anything to disk."") help='Adds a customized request header to the query, like ""Range"" or ' '""If-Match"". This argument is repeatable. ' 'Example --header ""content-type:text/plain""') 'both sides.') --long Long listing format, similar to ls -l. --lh Report sizes in human readable format similar to ls -lh. --totals Used with -l or --lh, only report totals. --prefix Only list items beginning with the prefix. '-l', '--long', dest='long', action='store_true', default=False, help='Long listing format, similar to ls -l.') '--lh', dest='human', action='store_true', default=False, help='Report sizes in human readable format ' ""similar to ls -lh."") '-t', '--totals', dest='totals', action='store_true', default=False, help='Used with -l or --lh, only report totals.') help='Only list items beginning with the prefix.') help='Roll up items with the given delimiter. ' 'For containers only. Ssee OpenStack Swift API documentation for ' 'what this means)') --lh Report sizes in human readable format similar to ls -lh. '--lh', dest='human', action='store_true', default=False, help='Report sizes in human readable format similar to ls -lh.') --sync-to <sync-to> Sync To for containers, for multi-cluster replication. --sync-key <sync-key> Sync Key for containers, for multi-cluster replication. '-r', '--read-acl', dest='read_acl', help='Read ACL for containers. ' 'Quick summary of ACL syntax: .r:*, .r:-.example.com, ' '.r:www.example.com, account1, account2:user2') '-w', '--write-acl', dest='write_acl', help='Write ACL for containers. ' 'Quick summary of ACL syntax: account1, ' help='Sets a meta data item. This option may be repeated. ' 'Example: -m Color:Blue -m Size:Large') default=[], help='Set request headers. This option may be repeated. ' 'Example -H ""content-type:text/plain"" ' upload. --skip-identical Skip uploading files that are identical on both sides. the segments as if it were the original file. objects left alone (in the case of overwrites). --use-slo When used in conjunction with --segment-size it will folder name. default=False, help='Only upload files that have changed since ' 'the last upload.') 'both sides.') '-S', '--segment-size', dest='segment_size', help='Upload files ' 'in segments no larger than <size> and then create a ""manifest"" ' 'file that will download all the segments as if it were the original ' 'file.') help='Upload the segments into the specified container. ' 'If not specified, the segments will be uploaded to a ' 'overwrites).') help='Number of threads to use for uploading full objects. ' 'Default is 10.') help='Number of threads to use for uploading object segments. ' 'Default is 10.') help='When used in conjunction with --segment-size it will ' help='Upload file and name object to <object-name> or upload dir and ' 'use <object-name> as object prefix instead of folder name.')"," --all Delete all containers and objects --leave-segments Do not delete segments of manifest objects default=False, help='Indicates that you really want to delete ' 'everything in the account') help='Indicates that you want the segments of manifest' 'objects left alone') default=10, help='Number of threads to use for deleting objects') 'deleting containers') everything in the account download --prefix <prefix> Only download items beginning with <prefix> redirect to stdout to disk --skip-identical Skip downloading files that are identical on both sides 'everything in the account') 'account download') help='Will only download items beginning with the prefix') 'file download, stream the output to an alternate location ') default=10, help='Number of threads to use for downloading objects') help='Number of threads to use for downloading containers') help=""Perform download(s), but don't actually write anything to disk"") help='Specify a request header, as --header NAME:VALUE. ' 'Adds a customized request header to the query, like ""Range"" or ' '""If-Match"". This argument is repeatable. Example' ' --header ""content-type:text/plain""') 'both sides') --long Long listing format, similar to ls -l --lh Report sizes in human readable format similar to ls -lh --totals Used with -l or --lh, only report totals --prefix Only list items beginning with the prefix '-l', '--long', dest='long', help='Long listing ' 'similar to ls -l command', action='store_true', default=False) '--lh', dest='human', help='report sizes as human ' ""similar to ls -lh switch, but -h taken"", action='store_true', default=False) '-t', '--totals', dest='totals', help='used with -l or --lh, ' 'only report totals', action='store_true', default=False) help='Will only list items beginning with the prefix') help='Will roll up items with the given delimiter' ' (see OpenStack Swift API documentation for what this means)') --lh Report sizes in human readable format similar to ls -lh '--lh', dest='human', help=""report totals like 'list --lh'"", action='store_true', default=False) --sync-to <sync-to> Sync To for containers, for multi-cluster replication --sync-key <sync-key> Sync Key for containers, for multi-cluster replication '-r', '--read-acl', dest='read_acl', help='Sets the ' 'Read ACL for containers. Quick summary of ACL syntax: .r:*, ' '.r:-.example.com, .r:www.example.com, account1, account2:user2') '-w', '--write-acl', dest='write_acl', help='Sets the ' 'Write ACL for containers. Quick summary of ACL syntax: account1, ' help='Sets a meta data item with the syntax name:value. This option ' 'may be repeated. Example: -m Color:Blue -m Size:Large') default=[], help='Set request headers with the syntax header:value. ' ' This option may be repeated. Example -H ""content-type:text/plain"" ' upload --skip-identical Skip uploading files that are identical on both sides the segments as if it were the original file objects left alone (in the case of overwrites) --use-slo When used in conjunction with --segment-size will folder name default=False, help='Will only upload files that have changed since ' 'the last upload') 'both sides') '-S', '--segment-size', dest='segment_size', help='Will ' 'upload files in segments no larger than <size> and then create a ' '""manifest"" file that will download all the segments as if it were ' 'the original file.') help='Will upload the segments into the specified container.' 'If not specified, the segments will be uploaded to ' 'overwrites)') help='Number of threads to use for uploading full objects') help='Number of threads to use for uploading object segments') help='When used in conjunction with --segment-size will ' help='Upload file and name object to the name specified')",80,75
openstack%2Fkeystone~master~I1db293978493868b6f7972b316fb6847c945ee30,openstack/keystone,master,I1db293978493868b6f7972b316fb6847c945ee30,Lazy gettextutils behavior,MERGED,2014-02-28 10:48:45.000000000,2014-03-06 00:53:17.000000000,2014-03-06 00:53:16.000000000,"[{'_account_id': 3}, {'_account_id': 4}, {'_account_id': 6486}, {'_account_id': 7536}]","[{'number': 1, 'created': '2014-02-28 10:48:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/6803fe2cff8ff54393169d6b5d0d1acee29f835f', 'message': 'Lazy gettextutils behavior\n\ngettextutils.enable_lazy() must be called before gettextutils._() is called to\nensure it has the desired lazy lookup behavior. This includes cases, like\nkeystone.exceptions, where gettextutils._() is called at import time.\n\nChange-Id: I1db293978493868b6f7972b316fb6847c945ee30\nCo-Authored-By: David Stanek <dstanek@dstanek.com>\n'}, {'number': 2, 'created': '2014-02-28 16:34:09.000000000', 'files': ['keystone/tests/__init__.py'], 'web_link': 'https://opendev.org/openstack/keystone/commit/f9e98e5eb942b22f8db269b2fa3d4fc9e040750e', 'message': 'Lazy gettextutils behavior\n\ngettextutils.enable_lazy() must be called before gettextutils._() is called to\nensure it has the desired lazy lookup behavior. This includes cases, like\nkeystone.exceptions, where gettextutils._() is called at import time.\n\nChange-Id: I1db293978493868b6f7972b316fb6847c945ee30\nCo-Authored-By: David Stanek <dstanek@dstanek.com>\n'}]",0,77127,f9e98e5eb942b22f8db269b2fa3d4fc9e040750e,17,4,2,7536,,,0,"Lazy gettextutils behavior

gettextutils.enable_lazy() must be called before gettextutils._() is called to
ensure it has the desired lazy lookup behavior. This includes cases, like
keystone.exceptions, where gettextutils._() is called at import time.

Change-Id: I1db293978493868b6f7972b316fb6847c945ee30
Co-Authored-By: David Stanek <dstanek@dstanek.com>
",git fetch https://review.opendev.org/openstack/keystone refs/changes/27/77127/1 && git format-patch -1 --stdout FETCH_HEAD,['keystone/tests/__init__.py'],1,6803fe2cff8ff54393169d6b5d0d1acee29f835f,explicit_,"# NOTE(dstanek): gettextutils.enable_lazy() must be called before # gettextutils._() is called to ensure it has the desired lazy lookup # behavior. This includes cases, like keystone.exceptions, where # gettextutils._() is called at import time. from keystone.openstack.common import gettextutils as _gettextutils _gettextutils.enable_lazy() ",,8,0
openstack%2Fswift~master~I2052ffaea3a74cdca9596b08273b7120570b1375,openstack/swift,master,I2052ffaea3a74cdca9596b08273b7120570b1375,Make internal client work with conf.d,MERGED,2014-03-05 08:36:30.000000000,2014-03-06 00:53:14.000000000,2014-03-06 00:53:14.000000000,"[{'_account_id': 3}, {'_account_id': 1179}, {'_account_id': 2622}]","[{'number': 1, 'created': '2014-03-05 08:36:30.000000000', 'files': ['test/unit/common/test_internal_client.py', 'swift/common/wsgi.py', 'swift/common/internal_client.py'], 'web_link': 'https://opendev.org/openstack/swift/commit/59ad30ce8c9d9eb4297c0cf80482f962f50f9f4a', 'message': ""Make internal client work with conf.d\n\nCopied from Clay's patch in LP\n\nFixes bug #1277046\n\nChange-Id: I2052ffaea3a74cdca9596b08273b7120570b1375\n""}]",0,78133,59ad30ce8c9d9eb4297c0cf80482f962f50f9f4a,9,3,1,5189,,,0,"Make internal client work with conf.d

Copied from Clay's patch in LP

Fixes bug #1277046

Change-Id: I2052ffaea3a74cdca9596b08273b7120570b1375
",git fetch https://review.opendev.org/openstack/swift refs/changes/33/78133/1 && git format-patch -1 --stdout FETCH_HEAD,"['test/unit/common/test_internal_client.py', 'swift/common/wsgi.py', 'swift/common/internal_client.py']",3,59ad30ce8c9d9eb4297c0cf80482f962f50f9f4a,bug/1277046,"from swift.common.wsgi import loadapp self.app = loadapp(conf_path,","from paste.deploy import loadapp self.app = loadapp('config:' + conf_path,",5,4
openstack%2Fswift~master~I9d63e9b52162dfccd72488655f61842e7723718f,openstack/swift,master,I9d63e9b52162dfccd72488655f61842e7723718f,Fix a couple typos,MERGED,2014-02-28 02:44:54.000000000,2014-03-06 00:53:12.000000000,2014-03-06 00:53:12.000000000,"[{'_account_id': 3}, {'_account_id': 597}, {'_account_id': 917}, {'_account_id': 1179}, {'_account_id': 7847}]","[{'number': 1, 'created': '2014-02-28 02:44:54.000000000', 'files': ['swift/common/internal_client.py'], 'web_link': 'https://opendev.org/openstack/swift/commit/3860e553ba32b725fbe3f39888156544a0efa8fb', 'message': 'Fix a couple typos\n\nChange-Id: I9d63e9b52162dfccd72488655f61842e7723718f\n'}]",0,77041,3860e553ba32b725fbe3f39888156544a0efa8fb,14,5,1,2622,,,0,"Fix a couple typos

Change-Id: I9d63e9b52162dfccd72488655f61842e7723718f
",git fetch https://review.opendev.org/openstack/swift refs/changes/41/77041/1 && git format-patch -1 --stdout FETCH_HEAD,['swift/common/internal_client.py'],1,3860e553ba32b725fbe3f39888156544a0efa8fb,topy, :param obj: The object. # Used in swift-dispersion-populate # Used in swift-dispersion-populate # Used in swift-dispersion-populate # Used in swift-dispersion-populate, :param objec_namet: The object. # Used in swift-dispertion-populate # Used in swift-dispertion-populate # Used in swift-dispertion-populate # Used in swift-dispertion-populate,5,5
openstack%2Ftempest~master~I10110b92ed9a34eedef210ad8408f78d64ba4ee6,openstack/tempest,master,I10110b92ed9a34eedef210ad8408f78d64ba4ee6,Cleanup _interface class variables in compute,MERGED,2014-03-05 11:35:34.000000000,2014-03-06 00:52:36.000000000,2014-03-06 00:52:35.000000000,"[{'_account_id': 3}, {'_account_id': 1192}, {'_account_id': 6167}]","[{'number': 1, 'created': '2014-03-05 11:35:34.000000000', 'files': ['tempest/api/compute/servers/test_list_servers_negative.py', 'tempest/api/compute/test_authorization.py', 'tempest/api/compute/servers/test_server_metadata.py', 'tempest/api/compute/admin/test_hypervisor_negative.py', 'tempest/api/compute/servers/test_instance_actions.py', 'tempest/api/compute/admin/test_fixed_ips_negative.py', 'tempest/api/compute/admin/test_instance_usage_audit_log_negative.py', 'tempest/api/compute/admin/test_hosts_negative.py', 'tempest/api/compute/admin/test_quotas.py', 'tempest/api/compute/servers/test_instance_actions_negative.py', 'tempest/api/compute/base.py', 'tempest/api/compute/floating_ips/test_floating_ips_actions.py', 'tempest/api/compute/servers/test_virtual_interfaces_negative.py', 'tempest/api/compute/admin/test_fixed_ips.py', 'tempest/api/compute/images/test_image_metadata_negative.py', 'tempest/api/compute/servers/test_servers_negative_new.py', 'tempest/api/compute/certificates/test_certificates.py', 'tempest/api/compute/servers/test_server_rescue_negative.py', 'tempest/api/compute/images/test_list_image_filters_negative.py', 'tempest/api/compute/limits/test_absolute_limits.py', 'tempest/api/compute/servers/test_multiple_create.py', 'tempest/api/compute/images/test_list_images.py', 'tempest/api/compute/flavors/test_flavors_negative.py', 'tempest/api/compute/servers/test_server_addresses_negative.py', 'tempest/api/compute/admin/test_services_negative.py', 'tempest/api/compute/servers/test_list_server_filters.py', 'tempest/api/compute/v3/admin/test_quotas_negative.py', 'tempest/api/compute/images/test_image_metadata.py', 'tempest/api/compute/admin/test_flavors_negative.py', 'tempest/api/compute/servers/test_server_password.py', 'tempest/api/compute/volumes/test_attach_volume.py', 'tempest/api/compute/servers/test_server_actions.py', 'tempest/api/compute/servers/test_attach_interfaces.py', 'tempest/api/compute/images/test_images_oneserver_negative.py', 'tempest/api/compute/admin/test_security_groups.py', 'tempest/api/compute/admin/test_hypervisor.py', 'tempest/api/compute/admin/test_services.py', 'tempest/api/compute/security_groups/test_security_group_rules.py', 'tempest/api/compute/admin/test_quotas_negative.py', 'tempest/api/compute/admin/test_instance_usage_audit_log.py', 'tempest/api/compute/admin/test_simple_tenant_usage_negative.py', 'tempest/api/compute/v3/servers/test_availability_zone.py', 'tempest/api/compute/v3/servers/test_instance_actions_negative.py', 'tempest/api/compute/security_groups/test_security_group_rules_negative.py', 'tempest/api/compute/volumes/test_volumes_list.py', 'tempest/api/compute/servers/test_servers_negative.py', 'tempest/api/compute/admin/test_flavors_access_negative.py', 'tempest/api/compute/v3/servers/test_multiple_create_negative.py', 'tempest/api/compute/servers/test_virtual_interfaces.py', 'tempest/api/compute/servers/test_delete_server.py', 'tempest/api/compute/security_groups/test_security_groups_negative.py', 'tempest/api/compute/admin/test_availability_zone.py', 'tempest/api/compute/admin/test_flavors_extra_specs.py', 'tempest/api/compute/images/test_list_image_filters.py', 'tempest/api/compute/floating_ips/test_floating_ips_actions_negative.py', 'tempest/api/compute/servers/test_servers.py', 'tempest/api/compute/admin/test_availability_zone_negative.py', 'tempest/api/compute/admin/test_aggregates.py', 'tempest/api/compute/admin/test_servers_negative.py', 'tempest/api/compute/flavors/test_flavors.py', 'tempest/api/compute/limits/test_absolute_limits_negative.py', 'tempest/api/compute/floating_ips/test_list_floating_ips_negative.py', 'tempest/api/compute/test_extensions.py', 'tempest/api/compute/admin/test_servers.py', 'tempest/api/compute/admin/test_flavors_access.py', 'tempest/api/compute/servers/test_server_personality.py', 'tempest/api/compute/test_quotas.py', 'tempest/api/compute/floating_ips/test_list_floating_ips.py', 'tempest/api/compute/servers/test_server_addresses.py', 'tempest/api/compute/servers/test_create_server.py', 'tempest/api/compute/admin/test_hosts.py', 'tempest/api/compute/security_groups/test_security_groups.py', 'tempest/api/compute/images/test_images.py', 'tempest/api/compute/keypairs/test_keypairs_negative.py', 'tempest/api/compute/servers/test_server_metadata_negative.py', 'tempest/api/compute/servers/test_disk_config.py', 'tempest/api/compute/test_live_block_migration_negative.py', 'tempest/api/compute/volumes/test_volumes_negative.py', 'tempest/api/compute/admin/test_flavors_extra_specs_negative.py', 'tempest/api/compute/admin/test_aggregates_negative.py', 'tempest/api/compute/admin/test_simple_tenant_usage.py', 'tempest/api/compute/keypairs/test_keypairs.py', 'tempest/api/compute/servers/test_server_rescue.py', 'tempest/api/compute/volumes/test_volumes_get.py', 'tempest/api/compute/servers/test_availability_zone.py', 'tempest/api/compute/v3/servers/test_delete_server.py', 'tempest/api/compute/test_live_block_migration.py', 'tempest/api/compute/images/test_images_oneserver.py', 'tempest/api/compute/servers/test_multiple_create_negative.py', 'tempest/api/compute/admin/test_flavors.py'], 'web_link': 'https://opendev.org/openstack/tempest/commit/dfabaf20130993db6617ddc5b7ea2b42f7259254', 'message': ""Cleanup _interface class variables in compute\n\nWe've already removed these variables in Nova v3 tests.\n  Change-Id: Ie9ad2242d20ce90fca74ca7a5390e0971f830caa\nBut we can remove these not only v3 tests but also v2 tests. This commit\nsets _interface = 'json' to BaseV2ComputeTest and removes redundancy.\n\nChange-Id: I10110b92ed9a34eedef210ad8408f78d64ba4ee6\n""}]",0,78173,dfabaf20130993db6617ddc5b7ea2b42f7259254,9,3,1,5689,,,0,"Cleanup _interface class variables in compute

We've already removed these variables in Nova v3 tests.
  Change-Id: Ie9ad2242d20ce90fca74ca7a5390e0971f830caa
But we can remove these not only v3 tests but also v2 tests. This commit
sets _interface = 'json' to BaseV2ComputeTest and removes redundancy.

Change-Id: I10110b92ed9a34eedef210ad8408f78d64ba4ee6
",git fetch https://review.opendev.org/openstack/tempest refs/changes/73/78173/1 && git format-patch -1 --stdout FETCH_HEAD,"['tempest/api/compute/servers/test_list_servers_negative.py', 'tempest/api/compute/test_authorization.py', 'tempest/api/compute/servers/test_server_metadata.py', 'tempest/api/compute/admin/test_hypervisor_negative.py', 'tempest/api/compute/servers/test_instance_actions.py', 'tempest/api/compute/admin/test_fixed_ips_negative.py', 'tempest/api/compute/admin/test_instance_usage_audit_log_negative.py', 'tempest/api/compute/admin/test_hosts_negative.py', 'tempest/api/compute/admin/test_quotas.py', 'tempest/api/compute/servers/test_instance_actions_negative.py', 'tempest/api/compute/base.py', 'tempest/api/compute/floating_ips/test_floating_ips_actions.py', 'tempest/api/compute/servers/test_virtual_interfaces_negative.py', 'tempest/api/compute/admin/test_fixed_ips.py', 'tempest/api/compute/images/test_image_metadata_negative.py', 'tempest/api/compute/servers/test_servers_negative_new.py', 'tempest/api/compute/certificates/test_certificates.py', 'tempest/api/compute/servers/test_server_rescue_negative.py', 'tempest/api/compute/images/test_list_image_filters_negative.py', 'tempest/api/compute/limits/test_absolute_limits.py', 'tempest/api/compute/servers/test_multiple_create.py', 'tempest/api/compute/images/test_list_images.py', 'tempest/api/compute/flavors/test_flavors_negative.py', 'tempest/api/compute/servers/test_server_addresses_negative.py', 'tempest/api/compute/admin/test_services_negative.py', 'tempest/api/compute/servers/test_list_server_filters.py', 'tempest/api/compute/v3/admin/test_quotas_negative.py', 'tempest/api/compute/images/test_image_metadata.py', 'tempest/api/compute/admin/test_flavors_negative.py', 'tempest/api/compute/servers/test_server_password.py', 'tempest/api/compute/volumes/test_attach_volume.py', 'tempest/api/compute/servers/test_server_actions.py', 'tempest/api/compute/servers/test_attach_interfaces.py', 'tempest/api/compute/images/test_images_oneserver_negative.py', 'tempest/api/compute/admin/test_security_groups.py', 'tempest/api/compute/admin/test_hypervisor.py', 'tempest/api/compute/admin/test_services.py', 'tempest/api/compute/security_groups/test_security_group_rules.py', 'tempest/api/compute/admin/test_quotas_negative.py', 'tempest/api/compute/admin/test_instance_usage_audit_log.py', 'tempest/api/compute/admin/test_simple_tenant_usage_negative.py', 'tempest/api/compute/v3/servers/test_availability_zone.py', 'tempest/api/compute/v3/servers/test_instance_actions_negative.py', 'tempest/api/compute/security_groups/test_security_group_rules_negative.py', 'tempest/api/compute/volumes/test_volumes_list.py', 'tempest/api/compute/servers/test_servers_negative.py', 'tempest/api/compute/admin/test_flavors_access_negative.py', 'tempest/api/compute/v3/servers/test_multiple_create_negative.py', 'tempest/api/compute/servers/test_virtual_interfaces.py', 'tempest/api/compute/servers/test_delete_server.py', 'tempest/api/compute/security_groups/test_security_groups_negative.py', 'tempest/api/compute/admin/test_availability_zone.py', 'tempest/api/compute/admin/test_flavors_extra_specs.py', 'tempest/api/compute/images/test_list_image_filters.py', 'tempest/api/compute/floating_ips/test_floating_ips_actions_negative.py', 'tempest/api/compute/servers/test_servers.py', 'tempest/api/compute/admin/test_availability_zone_negative.py', 'tempest/api/compute/admin/test_aggregates.py', 'tempest/api/compute/admin/test_servers_negative.py', 'tempest/api/compute/flavors/test_flavors.py', 'tempest/api/compute/limits/test_absolute_limits_negative.py', 'tempest/api/compute/floating_ips/test_list_floating_ips_negative.py', 'tempest/api/compute/test_extensions.py', 'tempest/api/compute/admin/test_servers.py', 'tempest/api/compute/admin/test_flavors_access.py', 'tempest/api/compute/servers/test_server_personality.py', 'tempest/api/compute/test_quotas.py', 'tempest/api/compute/floating_ips/test_list_floating_ips.py', 'tempest/api/compute/servers/test_server_addresses.py', 'tempest/api/compute/servers/test_create_server.py', 'tempest/api/compute/admin/test_hosts.py', 'tempest/api/compute/security_groups/test_security_groups.py', 'tempest/api/compute/images/test_images.py', 'tempest/api/compute/keypairs/test_keypairs_negative.py', 'tempest/api/compute/servers/test_server_metadata_negative.py', 'tempest/api/compute/servers/test_disk_config.py', 'tempest/api/compute/test_live_block_migration_negative.py', 'tempest/api/compute/volumes/test_volumes_negative.py', 'tempest/api/compute/admin/test_flavors_extra_specs_negative.py', 'tempest/api/compute/admin/test_aggregates_negative.py', 'tempest/api/compute/admin/test_simple_tenant_usage.py', 'tempest/api/compute/keypairs/test_keypairs.py', 'tempest/api/compute/servers/test_server_rescue.py', 'tempest/api/compute/volumes/test_volumes_get.py', 'tempest/api/compute/servers/test_availability_zone.py', 'tempest/api/compute/v3/servers/test_delete_server.py', 'tempest/api/compute/test_live_block_migration.py', 'tempest/api/compute/images/test_images_oneserver.py', 'tempest/api/compute/servers/test_multiple_create_negative.py', 'tempest/api/compute/admin/test_flavors.py']",90,dfabaf20130993db6617ddc5b7ea2b42f7259254,cleanup-interface-json,, _interface = 'json' ,2,117
openstack%2Fneutron~stable%2Fhavana~I9969e556acecf7a9e77d873371cc2ec2647be011,openstack/neutron,stable/havana,I9969e556acecf7a9e77d873371cc2ec2647be011,Add support for managing async processes,MERGED,2014-01-09 22:53:38.000000000,2014-03-06 00:52:27.000000000,2014-03-06 00:52:25.000000000,"[{'_account_id': 3}, {'_account_id': 1955}, {'_account_id': 2035}, {'_account_id': 2592}, {'_account_id': 2711}, {'_account_id': 5170}, {'_account_id': 5756}, {'_account_id': 6316}, {'_account_id': 6659}, {'_account_id': 7448}, {'_account_id': 8449}, {'_account_id': 9787}, {'_account_id': 9845}, {'_account_id': 10387}]","[{'number': 1, 'created': '2014-01-09 22:53:38.000000000', 'files': ['neutron/tests/unit/agent/__init__.py', 'neutron/tests/unit/agent/linux/test_async_process.py', 'neutron/tests/functional/agent/linux/test_async_process.py', 'neutron/tests/functional/agent/linux/__init__.py', 'neutron/tests/functional/agent/__init__.py', 'neutron/agent/linux/async_process.py', 'neutron/tests/functional/__init__.py', 'neutron/tests/unit/test_agent_linux_utils.py', 'TESTING', '.testr.conf', 'neutron/tests/unit/agent/linux/__init__.py', 'neutron/agent/linux/utils.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/2e9f5a7a3156ad91c901099f7577179f0c588a9c', 'message': 'Add support for managing async processes\n\nInteracting with a long-running asynchronous process requires the\nuse of non-blocking io.  This change adds a helper class that can\nlaunch a long-running process and read stdout and stderr in a\nnon-blocking fashion via eventlet.\n\nThis functionality is intended to support monitoring ovsdb via\na long-running and root-privileged invocation of ovsdb-client.\n\nThe complexity of the system interaction in this patch suggested\nthe addition of a functional test that validated actual behaviour.\nThe test was added under the neutron/tests/functional path which\nis now included in the testr search path.\n\nPartial-Bug: #1177973\n\nChange-Id: I9969e556acecf7a9e77d873371cc2ec2647be011\n(cherry picked from commit acf0209b28e21eed60158967fab77468eb195e7c)\n'}]",11,65808,2e9f5a7a3156ad91c901099f7577179f0c588a9c,52,14,1,5756,,,0,"Add support for managing async processes

Interacting with a long-running asynchronous process requires the
use of non-blocking io.  This change adds a helper class that can
launch a long-running process and read stdout and stderr in a
non-blocking fashion via eventlet.

This functionality is intended to support monitoring ovsdb via
a long-running and root-privileged invocation of ovsdb-client.

The complexity of the system interaction in this patch suggested
the addition of a functional test that validated actual behaviour.
The test was added under the neutron/tests/functional path which
is now included in the testr search path.

Partial-Bug: #1177973

Change-Id: I9969e556acecf7a9e77d873371cc2ec2647be011
(cherry picked from commit acf0209b28e21eed60158967fab77468eb195e7c)
",git fetch https://review.opendev.org/openstack/neutron refs/changes/08/65808/1 && git format-patch -1 --stdout FETCH_HEAD,"['neutron/tests/unit/agent/__init__.py', 'neutron/tests/unit/agent/linux/test_async_process.py', 'neutron/tests/functional/agent/linux/test_async_process.py', 'neutron/tests/functional/agent/linux/__init__.py', 'neutron/tests/functional/agent/__init__.py', 'neutron/agent/linux/async_process.py', 'neutron/tests/functional/__init__.py', 'neutron/tests/unit/test_agent_linux_utils.py', 'TESTING', '.testr.conf', 'neutron/tests/unit/agent/linux/__init__.py', 'neutron/agent/linux/utils.py']",12,2e9f5a7a3156ad91c901099f7577179f0c588a9c,bug/1243867,"def create_process(cmd, root_helper=None, addl_env=None): """"""Create a process object for the given command. The return value will be a tuple of the process object and the list of command arguments used to create it. """""" obj = utils.subprocess_popen(cmd, shell=False, stdin=subprocess.PIPE, stdout=subprocess.PIPE, stderr=subprocess.PIPE, env=env) return obj, cmd def execute(cmd, root_helper=None, process_input=None, addl_env=None, check_exit_code=True, return_stderr=False): try: obj, cmd = create_process(cmd, root_helper=root_helper, addl_env=addl_env) def find_child_pids(pid): """"""Retrieve a list of the pids of child processes of the given pid."""""" try: raw_pids = execute(['ps', '--ppid', pid, '-o', 'pid=']) except RuntimeError as e: # Exception has already been logged by execute no_children_found = 'Exit code: 1' in str(e) if no_children_found: return [] # Unexpected errors are the responsibility of the caller raise return [x.strip() for x in raw_pids.split('\n') if x.strip()]","def execute(cmd, root_helper=None, process_input=None, addl_env=None, check_exit_code=True, return_stderr=False): try: obj = utils.subprocess_popen(cmd, shell=False, stdin=subprocess.PIPE, stdout=subprocess.PIPE, stderr=subprocess.PIPE, env=env)",681,18
openstack%2Fsolum~master~Ibea5ec69cff67829fc1096ed1301803f004d6529,openstack/solum,master,Ibea5ec69cff67829fc1096ed1301803f004d6529,Log configuration options at startup,MERGED,2014-02-27 22:04:16.000000000,2014-03-06 00:47:10.000000000,2014-03-06 00:47:10.000000000,"[{'_account_id': 3}, {'_account_id': 668}, {'_account_id': 2506}, {'_account_id': 4715}, {'_account_id': 8334}, {'_account_id': 8443}, {'_account_id': 9094}, {'_account_id': 9095}, {'_account_id': 9537}]","[{'number': 1, 'created': '2014-02-27 22:04:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/solum/commit/0ab2295510c6cebced96f9210a1523f010c3a404', 'message': 'Log configuration options at startup\n\nChange-Id: Ibea5ec69cff67829fc1096ed1301803f004d6529\n'}, {'number': 2, 'created': '2014-02-27 23:49:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/solum/commit/6561a9e1fd0b84fda4fe5a51bf1182ed9236a3c6', 'message': 'Log configuration options at startup\n\nChange-Id: Ibea5ec69cff67829fc1096ed1301803f004d6529\n'}, {'number': 3, 'created': '2014-02-28 01:48:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/solum/commit/9349b06bc1e2b0dbcdcd0b0d1ad02120aacc4f96', 'message': 'Log configuration options at startup\n\nChange-Id: Ibea5ec69cff67829fc1096ed1301803f004d6529\n'}, {'number': 4, 'created': '2014-02-28 07:30:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/solum/commit/1fe78b76c5dd1e971225616fc76e27c0957993ec', 'message': 'Log configuration options at startup\n\nChange-Id: Ibea5ec69cff67829fc1096ed1301803f004d6529\n'}, {'number': 5, 'created': '2014-03-03 00:45:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/solum/commit/20981b2074b43f4c637f75add77175dd04b441bd', 'message': 'Log configuration options at startup\n\nAlso neaten up the startup logs.\n\nChange-Id: Ibea5ec69cff67829fc1096ed1301803f004d6529\n'}, {'number': 6, 'created': '2014-03-04 12:03:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/solum/commit/6198be73733616cb6563972f3e14b79e12d6679a', 'message': 'Log configuration options at startup\n\nAlso neaten up the startup logs.\n\nChange-Id: Ibea5ec69cff67829fc1096ed1301803f004d6529\n'}, {'number': 7, 'created': '2014-03-04 12:06:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/solum/commit/7478052ca64748cd2b52b3bbe969cb3ce5ad0097', 'message': 'Log configuration options at startup\n\nAlso neaten up the startup logs.\n\nChange-Id: Ibea5ec69cff67829fc1096ed1301803f004d6529\n'}, {'number': 8, 'created': '2014-03-05 20:54:10.000000000', 'files': ['solum/cmd/builder.py', 'solum/cmd/api.py'], 'web_link': 'https://opendev.org/openstack/solum/commit/6d606417309c628e697c14abdfda07f7637c7e2b', 'message': 'Log configuration options at startup\n\nAlso neaten up the startup logs.\n\nChange-Id: Ibea5ec69cff67829fc1096ed1301803f004d6529\n'}]",5,76984,6d606417309c628e697c14abdfda07f7637c7e2b,43,9,8,4715,,,0,"Log configuration options at startup

Also neaten up the startup logs.

Change-Id: Ibea5ec69cff67829fc1096ed1301803f004d6529
",git fetch https://review.opendev.org/openstack/solum refs/changes/84/76984/6 && git format-patch -1 --stdout FETCH_HEAD,"['solum/cmd/builder.py', 'solum/cmd/api.py']",2,0ab2295510c6cebced96f9210a1523f010c3a404,image-builder,"import logging as std_loggingfrom solum.openstack.common.gettextutils import _ LOG.info(_('Starting server in PID %s') % os.getpid()) LOG.info(_(""Configuration:"")) cfg.CONF.log_opt_values(LOG, std_logging.INFO)", LOG.info('Starting server in PID %s' % os.getpid()),10,2
openstack%2Fswift~feature%2Fec~I776ff8b519a7bef441466d199137d8a315600973,openstack/swift,feature/ec,I776ff8b519a7bef441466d199137d8a315600973,Send policy index to container on sync update,MERGED,2014-02-07 01:27:10.000000000,2014-03-06 00:42:57.000000000,2014-03-06 00:42:57.000000000,"[{'_account_id': 3}, {'_account_id': 330}, {'_account_id': 2622}, {'_account_id': 6198}, {'_account_id': 7479}]","[{'number': 1, 'created': '2014-02-07 01:27:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/e7d616f1facd4ac87fcb8581d63c1e07bf36882f', 'message': ""Send policy index to container on sync update\n\nWe're sending the policy index to the container on async update, so we\nreally should send it on synchronous update (object-server ==>\ncontainer-server) as well.\n\nAlso cleaned up a couple of unrelated test mocks to use the 'mock'\nlibrary instead of hand-patching.\n\nChange-Id: I776ff8b519a7bef441466d199137d8a315600973\n""}, {'number': 2, 'created': '2014-02-11 02:57:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/4296c28297a49fb2656521ac52489638e74f2bb9', 'message': ""Send policy index to container on sync update\n\nWe're sending the policy index to the container on async update, so we\nreally should send it on synchronous update (object-server ==>\ncontainer-server) as well.\n\nAlso cleaned up a couple of unrelated test mocks to use the 'mock'\nlibrary instead of hand-patching.\n\nChange-Id: I776ff8b519a7bef441466d199137d8a315600973\n""}, {'number': 3, 'created': '2014-02-11 17:45:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/5cef147992a4567ede30f782606f8c9fa0cce318', 'message': ""Send policy index to container on sync update\n\nWe're sending the policy index to the container on async update, so we\nreally should send it on synchronous update (object-server ==>\ncontainer-server) as well.\n\nAlso cleaned up a couple of unrelated test mocks to use the 'mock'\nlibrary instead of hand-patching.\n\nChange-Id: I776ff8b519a7bef441466d199137d8a315600973\n""}, {'number': 4, 'created': '2014-02-16 22:16:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/d9cca39bf53a9928895ac4586b49b7d012809273', 'message': ""Send policy index to container on sync update\n\nWe're sending the policy index to the container on async update, so we\nreally should send it on synchronous update (object-server ==>\ncontainer-server) as well.\n\nAlso cleaned up a couple of unrelated test mocks to use the 'mock'\nlibrary instead of hand-patching.\n\nChange-Id: I776ff8b519a7bef441466d199137d8a315600973\n""}, {'number': 5, 'created': '2014-03-04 22:32:22.000000000', 'files': ['swift/obj/server.py', 'test/unit/obj/test_server.py'], 'web_link': 'https://opendev.org/openstack/swift/commit/888e7b330de91ddb16688e5179d337bc72099b02', 'message': ""Send policy index to container on sync update\n\nWe're sending the policy index to the container on async update, so we\nreally should send it on synchronous update (object-server ==>\ncontainer-server) as well.\n\nAlso cleaned up a couple of unrelated test mocks to use the 'mock'\nlibrary instead of hand-patching.\n\nChange-Id: I776ff8b519a7bef441466d199137d8a315600973\n""}]",2,71703,888e7b330de91ddb16688e5179d337bc72099b02,26,5,5,2622,,,0,"Send policy index to container on sync update

We're sending the policy index to the container on async update, so we
really should send it on synchronous update (object-server ==>
container-server) as well.

Also cleaned up a couple of unrelated test mocks to use the 'mock'
library instead of hand-patching.

Change-Id: I776ff8b519a7bef441466d199137d8a315600973
",git fetch https://review.opendev.org/openstack/swift refs/changes/03/71703/5 && git format-patch -1 --stdout FETCH_HEAD,"['swift/obj/server.py', 'test/unit/obj/test_server.py']",2,e7d616f1facd4ac87fcb8581d63c1e07bf36882f,sp2," 'X-Storage-Policy-Index': '37', policies = [storage_policy.StoragePolicy(0, 'zero', True), storage_policy.StoragePolicy(1, 'one'), storage_policy.StoragePolicy(37, 'fantastico')] with patch_policies(policies): with mock.patch.object(object_server, 'http_connect', fake_http_connect): resp = req.get_response(self.object_controller) 'x-storage-policy-index': '37', 'X-Storage-Policy-Index': '26', policies = [storage_policy.StoragePolicy(0, 'zero', True), storage_policy.StoragePolicy(1, 'one'), storage_policy.StoragePolicy(26, 'twice thirteen')] with patch_policies(policies): with mock.patch.object(object_server, 'http_connect', fake_http_connect): req.get_response(self.object_controller) 'x-storage-policy-index': '26', 'x-storage-policy-index': '26', 'x-storage-policy-index': '0', # default when not given with mock.patch.object(self.object_controller, 'async_update', fake_async_update): self.object_controller.container_update( 'PUT', 'a', 'c', 'o', req, { 'x-size': '0', 'x-etag': 'd41d8cd98f00b204e9800998ecf8427e', 'x-content-type': 'text/plain', 'x-timestamp': '1'}, 'sda1', 0) with mock.patch.object(self.object_controller, 'async_update', fake_async_update): self.object_controller.delete_at_update( 'DELETE', 2, 'a', 'c', 'o', req, 'sda1')"," orig_http_connect = object_server.http_connect try: object_server.http_connect = fake_http_connect resp = req.get_response(self.object_controller) finally: object_server.http_connect = orig_http_connect orig_http_connect = object_server.http_connect try: object_server.http_connect = fake_http_connect req.get_response(self.object_controller) finally: object_server.http_connect = orig_http_connect self.object_controller.async_update = fake_async_update self.object_controller.container_update( 'PUT', 'a', 'c', 'o', req, { 'x-size': '0', 'x-etag': 'd41d8cd98f00b204e9800998ecf8427e', 'x-content-type': 'text/plain', 'x-timestamp': '1'}, 'sda1', 0) self.object_controller.async_update = fake_async_update self.object_controller.delete_at_update( 'DELETE', 2, 'a', 'c', 'o', req, 'sda1')",33,21
openstack%2Fswift~feature%2Fec~Ic645ac3426e18adfc8c46613c8aadcf765d6d0e2,openstack/swift,feature/ec,Ic645ac3426e18adfc8c46613c8aadcf765d6d0e2,Send policy index on async update,MERGED,2014-02-07 01:27:10.000000000,2014-03-06 00:42:50.000000000,2014-03-06 00:42:49.000000000,"[{'_account_id': 3}, {'_account_id': 330}, {'_account_id': 2622}, {'_account_id': 6198}, {'_account_id': 7479}]","[{'number': 1, 'created': '2014-02-07 01:27:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/b34059f7661ad5f013be11bfc8e6a6125a6cc0f9', 'message': 'Send policy index on async update\n\nAlso clean up a couple little things in the object updater. Now it\nwon\'t abort processing when it encounters a file (not directory) named\n""async_pending-\\d+"", and it won\'t process updates in a directory that\ndoes not correspond to a storage policy.\n\nThat is, if you have policies 1, 2, and 3, but there\'s a directory on\nyour disk named ""async_pending-5"", the updater will now skip over that\nentirely. It won\'t even bother doing directory listings at all. This\nis a good idea, believe it or not, because there\'s nothing good that\nthe container server can do with an update from some unknown storage\npolicy. It can\'t update the listing, it can\'t move the object if it\'s\nmisplaced... all it can do is ignore the request, so it\'s better to\njust not send it in the first place. Plus, if this is due to a\nmisconfiguration on one storage node, then the updates will get\nprocessed once the configuration is fixed.\n\nChange-Id: Ic645ac3426e18adfc8c46613c8aadcf765d6d0e2\n'}, {'number': 2, 'created': '2014-02-11 02:57:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/6dd45150cd5a85d8a3bffb2a5f47e23745cd1488', 'message': 'Send policy index on async update\n\nAlso clean up a couple little things in the object updater. Now it\nwon\'t abort processing when it encounters a file (not directory) named\n""async_pending-\\d+"", and it won\'t process updates in a directory that\ndoes not correspond to a storage policy.\n\nThat is, if you have policies 1, 2, and 3, but there\'s a directory on\nyour disk named ""async_pending-5"", the updater will now skip over that\nentirely. It won\'t even bother doing directory listings at all. This\nis a good idea, believe it or not, because there\'s nothing good that\nthe container server can do with an update from some unknown storage\npolicy. It can\'t update the listing, it can\'t move the object if it\'s\nmisplaced... all it can do is ignore the request, so it\'s better to\njust not send it in the first place. Plus, if this is due to a\nmisconfiguration on one storage node, then the updates will get\nprocessed once the configuration is fixed.\n\nChange-Id: Ic645ac3426e18adfc8c46613c8aadcf765d6d0e2\n'}, {'number': 3, 'created': '2014-02-11 17:45:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/1363245d86bc14f362869e3f19883d542beeca68', 'message': 'Send policy index on async update\n\nAlso clean up a couple little things in the object updater. Now it\nwon\'t abort processing when it encounters a file (not directory) named\n""async_pending-\\d+"", and it won\'t process updates in a directory that\ndoes not correspond to a storage policy.\n\nThat is, if you have policies 1, 2, and 3, but there\'s a directory on\nyour disk named ""async_pending-5"", the updater will now skip over that\nentirely. It won\'t even bother doing directory listings at all. This\nis a good idea, believe it or not, because there\'s nothing good that\nthe container server can do with an update from some unknown storage\npolicy. It can\'t update the listing, it can\'t move the object if it\'s\nmisplaced... all it can do is ignore the request, so it\'s better to\njust not send it in the first place. Plus, if this is due to a\nmisconfiguration on one storage node, then the updates will get\nprocessed once the configuration is fixed.\n\nChange-Id: Ic645ac3426e18adfc8c46613c8aadcf765d6d0e2\n'}, {'number': 4, 'created': '2014-02-16 22:16:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/1753b48513af78e06369647aec16bef0f7bd517d', 'message': 'Send policy index on async update\n\nAlso clean up a couple little things in the object updater. Now it\nwon\'t abort processing when it encounters a file (not directory) named\n""async_pending-\\d+"", and it won\'t process updates in a directory that\ndoes not correspond to a storage policy.\n\nThat is, if you have policies 1, 2, and 3, but there\'s a directory on\nyour disk named ""async_pending-5"", the updater will now skip over that\nentirely. It won\'t even bother doing directory listings at all. This\nis a good idea, believe it or not, because there\'s nothing good that\nthe container server can do with an update from some unknown storage\npolicy. It can\'t update the listing, it can\'t move the object if it\'s\nmisplaced... all it can do is ignore the request, so it\'s better to\njust not send it in the first place. Plus, if this is due to a\nmisconfiguration on one storage node, then the updates will get\nprocessed once the configuration is fixed.\n\nChange-Id: Ic645ac3426e18adfc8c46613c8aadcf765d6d0e2\n'}, {'number': 5, 'created': '2014-03-04 22:32:23.000000000', 'files': ['swift/obj/updater.py', 'test/unit/obj/test_updater.py'], 'web_link': 'https://opendev.org/openstack/swift/commit/f818e0b0ddc3628bd84dd03c2dd620d674e76196', 'message': 'Send policy index on async update\n\nAlso clean up a couple little things in the object updater. Now it\nwon\'t abort processing when it encounters a file (not directory) named\n""async_pending-\\d+"", and it won\'t process updates in a directory that\ndoes not correspond to a storage policy.\n\nThat is, if you have policies 1, 2, and 3, but there\'s a directory on\nyour disk named ""async_pending-5"", the updater will now skip over that\nentirely. It won\'t even bother doing directory listings at all. This\nis a good idea, believe it or not, because there\'s nothing good that\nthe container server can do with an update from some unknown storage\npolicy. It can\'t update the listing, it can\'t move the object if it\'s\nmisplaced... all it can do is ignore the request, so it\'s better to\njust not send it in the first place. Plus, if this is due to a\nmisconfiguration on one storage node, then the updates will get\nprocessed once the configuration is fixed.\n\nChange-Id: Ic645ac3426e18adfc8c46613c8aadcf765d6d0e2\n'}]",6,71702,f818e0b0ddc3628bd84dd03c2dd620d674e76196,31,5,5,2622,,,0,"Send policy index on async update

Also clean up a couple little things in the object updater. Now it
won't abort processing when it encounters a file (not directory) named
""async_pending-\d+"", and it won't process updates in a directory that
does not correspond to a storage policy.

That is, if you have policies 1, 2, and 3, but there's a directory on
your disk named ""async_pending-5"", the updater will now skip over that
entirely. It won't even bother doing directory listings at all. This
is a good idea, believe it or not, because there's nothing good that
the container server can do with an update from some unknown storage
policy. It can't update the listing, it can't move the object if it's
misplaced... all it can do is ignore the request, so it's better to
just not send it in the first place. Plus, if this is due to a
misconfiguration on one storage node, then the updates will get
processed once the configuration is fixed.

Change-Id: Ic645ac3426e18adfc8c46613c8aadcf765d6d0e2
",git fetch https://review.opendev.org/openstack/swift refs/changes/02/71702/2 && git format-patch -1 --stdout FETCH_HEAD,"['swift/obj/updater.py', 'test/unit/obj/test_updater.py']",2,b34059f7661ad5f013be11bfc8e6a6125a6cc0f9,sp2," def check_with_idx(index, warn, should_skip): if int(index) > 0: asyncdir = os.path.join(self.sda1, ASYNCDIR_BASE + ""-"" + index) else: asyncdir = os.path.join(self.sda1, ASYNCDIR_BASE) prefix_dir = os.path.join(asyncdir, 'abc') # A non-directory where directory is expected should just be # skipped, but should not stop processing of subsequent # directories. not_dirs = ( os.path.join(self.sda1, 'not_a_dir'), os.path.join(self.sda1, ASYNCDIR_BASE + '-' + 'twentington'), os.path.join(self.sda1, ASYNCDIR_BASE + '-' + str(int(index) - 1)), os.path.join(self.sda1, ASYNCDIR_BASE + '-' + str(int(index) + 1))) for not_dir in not_dirs: with open(not_dir, 'w'): pass expected.add((o_path, int(index))) def process_object_update(self, update_path, device, idx): seen.add((update_path, idx)) self.assert_(os.path.exists(os.path.join(self.sda1, 'not_a_dir'))) if should_skip: # if we were supposed to skip over the dir, we didn't process # anything at all self.assertTrue(os.path.exists(prefix_dir)) self.assertEqual(set(), seen) else: self.assert_(not os.path.exists(prefix_dir)) self.assertEqual(expected, seen) # test cleanup: the tempdir gets cleaned up between runs, but this # way we can be called multiple times in a single test method for not_dir in not_dirs: os.unlink(not_dir) check_with_idx(str(pol.idx), 0, should_skip=False) # now check with a bogus async dir policy and make sure we get check_with_idx('99', 1, should_skip=True) self.assertTrue('x-container-timestamp' in headers) self.assertTrue('x-storage-policy-index' in headers)"," def check_with_idx(index, warn): prefix_dir = os.path.join(self.sda1, ASYNCDIR_BASE + ""-"" + index, 'abc') # A non-directory where directory is expected should # just be skipped... not_a_dir_path = os.path.join(self.sda1, ASYNCDIR_BASE + ""-"" + index, 'not_a_dir') with open(not_a_dir_path, 'w'): pass expected.add(o_path) def process_object_update(self, update_path, device): seen.add(update_path) self.assert_(not os.path.exists(prefix_dir)) self.assert_(os.path.exists(not_a_dir_path)) self.assertEqual(expected, seen) check_with_idx(str(pol.idx), 0) # now check with a bogus asyn dir policy and make sure we get check_with_idx('99', 1) self.assert_('x-container-timestamp' in headers)",74,37
openstack%2Fpython-solumclient~master~Ib71d6cd11895a5f7ed746dc210ef3b5ebdfff300,openstack/python-solumclient,master,Ib71d6cd11895a5f7ed746dc210ef3b5ebdfff300,Sync oslo modules from oslo-incubator,MERGED,2014-03-05 16:34:12.000000000,2014-03-06 00:40:06.000000000,2014-03-06 00:40:06.000000000,"[{'_account_id': 3}, {'_account_id': 668}, {'_account_id': 4715}, {'_account_id': 9095}]","[{'number': 1, 'created': '2014-03-05 16:34:12.000000000', 'files': ['solumclient/openstack/common/strutils.py', 'solumclient/openstack/common/apiclient/auth.py', 'solumclient/openstack/common/jsonutils.py', 'solumclient/openstack/common/importutils.py', 'solumclient/openstack/common/gettextutils.py', 'solumclient/openstack/common/apiclient/fake_client.py', 'solumclient/openstack/common/log.py', 'solumclient/openstack/common/test.py', 'solumclient/openstack/common/__init__.py', 'solumclient/openstack/common/apiclient/base.py', 'solumclient/openstack/common/apiclient/exceptions.py', 'solumclient/openstack/common/timeutils.py'], 'web_link': 'https://opendev.org/openstack/python-solumclient/commit/878075169ff449eb97e26a3ff33d4ed87ca10083', 'message': 'Sync oslo modules from oslo-incubator\n\nSynced from commit c6a57ffea475e9712fd15a456b465fdb6ac5073e\n\nChange-Id: Ib71d6cd11895a5f7ed746dc210ef3b5ebdfff300\n'}]",0,78292,878075169ff449eb97e26a3ff33d4ed87ca10083,8,4,1,8334,,,0,"Sync oslo modules from oslo-incubator

Synced from commit c6a57ffea475e9712fd15a456b465fdb6ac5073e

Change-Id: Ib71d6cd11895a5f7ed746dc210ef3b5ebdfff300
",git fetch https://review.opendev.org/openstack/python-solumclient refs/changes/92/78292/1 && git format-patch -1 --stdout FETCH_HEAD,"['solumclient/openstack/common/strutils.py', 'solumclient/openstack/common/apiclient/auth.py', 'solumclient/openstack/common/jsonutils.py', 'solumclient/openstack/common/importutils.py', 'solumclient/openstack/common/gettextutils.py', 'solumclient/openstack/common/apiclient/fake_client.py', 'solumclient/openstack/common/log.py', 'solumclient/openstack/common/test.py', 'solumclient/openstack/common/__init__.py', 'solumclient/openstack/common/apiclient/base.py', 'solumclient/openstack/common/apiclient/exceptions.py', 'solumclient/openstack/common/timeutils.py']",12,878075169ff449eb97e26a3ff33d4ed87ca10083,," """"""Returns a iso8601 formatted date from timestamp."""""""," """"""Returns a iso8601 formated date from timestamp.""""""",550,272
openstack%2Ftripleo-heat-templates~master~I0a8f22607be9db89c09120d87d76cbb2d73f6ace,openstack/tripleo-heat-templates,master,I0a8f22607be9db89c09120d87d76cbb2d73f6ace,Scale items under Merge::Map,ABANDONED,2014-03-06 00:07:45.000000000,2014-03-06 00:38:34.000000000,,"[{'_account_id': 3}, {'_account_id': 10035}]","[{'number': 1, 'created': '2014-03-06 00:07:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/37c114f72cc9011f804fcac0f4f11927617aa132', 'message': 'Merge::Map resets scaling sentinel in_copies\n\nWe need to be able to scale maps of hosts in host metadata. This is\nprevented by the in_copies sentinel.\n\nChange-Id: I0a8f22607be9db89c09120d87d76cbb2d73f6ace\n'}, {'number': 2, 'created': '2014-03-06 00:10:31.000000000', 'files': ['examples/scale_map_result.yaml', 'tripleo_heat_merge/merge.py'], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/fe6f44c8e554e2553059481f1b525b0cfea543c2', 'message': 'Scale items under Merge::Map\n\nWe need to be able to scale maps of hosts in host metadata. This is\nprevented by the in_copies sentinel.\n\nChange-Id: I0a8f22607be9db89c09120d87d76cbb2d73f6ace\n'}]",0,78465,fe6f44c8e554e2553059481f1b525b0cfea543c2,7,2,2,10035,,,0,"Scale items under Merge::Map

We need to be able to scale maps of hosts in host metadata. This is
prevented by the in_copies sentinel.

Change-Id: I0a8f22607be9db89c09120d87d76cbb2d73f6ace
",git fetch https://review.opendev.org/openstack/tripleo-heat-templates refs/changes/65/78465/2 && git format-patch -1 --stdout FETCH_HEAD,"['examples/scale_map_result.yaml', 'tripleo_heat_merge/merge.py']",2,37c114f72cc9011f804fcac0f4f11927617aa132,merge-map-scaling, if key == 'Merge::Map': in_copies = {},,134,0
openstack%2Fsahara-image-elements~master~I592aec1d3d539231db7b2ca421d58b01cd7101de,openstack/sahara-image-elements,master,I592aec1d3d539231db7b2ca421d58b01cd7101de,Fix DIB_HADOOP_VERSION checks of hadoop-cdh element,MERGED,2014-03-05 14:33:31.000000000,2014-03-06 00:38:31.000000000,2014-03-06 00:38:31.000000000,"[{'_account_id': 3}, {'_account_id': 6786}, {'_account_id': 7125}, {'_account_id': 7213}, {'_account_id': 7555}, {'_account_id': 8411}]","[{'number': 1, 'created': '2014-03-05 14:33:31.000000000', 'files': ['elements/hadoop-cdh/root.d/0-check', 'elements/hadoop-cdh/post-install.d/40-setup-hadoop'], 'web_link': 'https://opendev.org/openstack/sahara-image-elements/commit/d3e3182517e4f8f00e704a9c89399aaca9853655', 'message': ""Fix DIB_HADOOP_VERSION checks of hadoop-cdh element\n\nWe shouldn't begin to build image if specified hadoop version\nis not supported for CDH\n\nChange-Id: I592aec1d3d539231db7b2ca421d58b01cd7101de\n""}]",0,78230,d3e3182517e4f8f00e704a9c89399aaca9853655,8,6,1,7732,,,0,"Fix DIB_HADOOP_VERSION checks of hadoop-cdh element

We shouldn't begin to build image if specified hadoop version
is not supported for CDH

Change-Id: I592aec1d3d539231db7b2ca421d58b01cd7101de
",git fetch https://review.opendev.org/openstack/sahara-image-elements refs/changes/30/78230/1 && git format-patch -1 --stdout FETCH_HEAD,"['elements/hadoop-cdh/root.d/0-check', 'elements/hadoop-cdh/post-install.d/40-setup-hadoop']",2,d3e3182517e4f8f00e704a9c89399aaca9853655,master,,"if [ $DIB_HADOOP_VERSION != ""2.0.0-mr1-cdh4.5.0"" ]; then echo ""CDH version $DIB_HADOOP_VERSION not supported. Exiting."" fi ",2,9
openstack%2Fsolum~master~I7c35a8511dd80c8e23765a4d7ce5180abe741808,openstack/solum,master,I7c35a8511dd80c8e23765a4d7ce5180abe741808,fix scripts for newer docker version,MERGED,2014-03-05 20:36:47.000000000,2014-03-06 00:32:48.000000000,2014-03-06 00:32:48.000000000,"[{'_account_id': 3}, {'_account_id': 668}, {'_account_id': 4715}, {'_account_id': 7858}, {'_account_id': 8443}]","[{'number': 1, 'created': '2014-03-05 20:36:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/solum/commit/139d3f92fdf6e38cf28e4cd205039e0d04a3ecbc', 'message': 'fix scripts for newer docker version\n\nChange-Id: I7c35a8511dd80c8e23765a4d7ce5180abe741808\n'}, {'number': 2, 'created': '2014-03-05 20:37:59.000000000', 'files': ['contrib/lp-cedarish/docker/prepare', 'contrib/lp-cedarish/docker/build-app'], 'web_link': 'https://opendev.org/openstack/solum/commit/af677c8d6980e36703f667135243dc5c7e0657c4', 'message': 'fix scripts for newer docker version\n\ndocker will auto-untar the slug.tgz\nuse repo controlled by solum member for slugbuilder/runner\n\nChange-Id: I7c35a8511dd80c8e23765a4d7ce5180abe741808\n'}]",0,78403,af677c8d6980e36703f667135243dc5c7e0657c4,12,5,2,7858,,,0,"fix scripts for newer docker version

docker will auto-untar the slug.tgz
use repo controlled by solum member for slugbuilder/runner

Change-Id: I7c35a8511dd80c8e23765a4d7ce5180abe741808
",git fetch https://review.opendev.org/openstack/solum refs/changes/03/78403/2 && git format-patch -1 --stdout FETCH_HEAD,"['contrib/lp-cedarish/docker/prepare', 'contrib/lp-cedarish/docker/build-app']",2,139d3f92fdf6e38cf28e4cd205039e0d04a3ecbc,,ADD slug.tgz /app,ADD slug.tgz /tmp/slug.tgz,2,2
openstack%2Ftripleo-image-elements~master~I2ffb6683f51c70d67da043a4907ba84330e75b9f,openstack/tripleo-image-elements,master,I2ffb6683f51c70d67da043a4907ba84330e75b9f,Work around missing kombu requirement for keystone,MERGED,2014-03-05 21:43:59.000000000,2014-03-06 00:28:22.000000000,2014-03-06 00:28:21.000000000,"[{'_account_id': 3}, {'_account_id': 4190}, {'_account_id': 6488}, {'_account_id': 6928}, {'_account_id': 7144}]","[{'number': 1, 'created': '2014-03-05 21:43:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-image-elements/commit/543b205b1dbebed3f3077aa2a6c8f5954094b1a3', 'message': 'Work around missing kombu requirement for keystone\n\nKeystone has switched to oslo.messaging and thus is missing a\nrequirement for the backend drivers.\n\nWe only use kombu, so we can force it in until oslo.messaging is fixed.\n\nChange-Id: I2ffb6683f51c70d67da043a4907ba84330e75b9f\nCloses-Bug: #1288425\n'}, {'number': 2, 'created': '2014-03-05 22:24:07.000000000', 'files': ['elements/keystone/install.d/keystone-source-install/05-keystone'], 'web_link': 'https://opendev.org/openstack/tripleo-image-elements/commit/1105e565a0917feada1a7e74bf5fe49d8fb3a161', 'message': 'Work around missing kombu requirement for keystone\n\nKeystone has switched to oslo.messaging and thus is missing a\nrequirement for the backend drivers.\n\nWe only use kombu, so we can force it in until oslo.messaging is fixed.\n\nChange-Id: I2ffb6683f51c70d67da043a4907ba84330e75b9f\nCloses-Bug: #1288425\n'}]",0,78426,1105e565a0917feada1a7e74bf5fe49d8fb3a161,21,5,2,6488,,,0,"Work around missing kombu requirement for keystone

Keystone has switched to oslo.messaging and thus is missing a
requirement for the backend drivers.

We only use kombu, so we can force it in until oslo.messaging is fixed.

Change-Id: I2ffb6683f51c70d67da043a4907ba84330e75b9f
Closes-Bug: #1288425
",git fetch https://review.opendev.org/openstack/tripleo-image-elements refs/changes/26/78426/2 && git format-patch -1 --stdout FETCH_HEAD,['elements/keystone/install.d/keystone-source-install/05-keystone'],1,543b205b1dbebed3f3077aa2a6c8f5954094b1a3,, # Workaround for https://bugs.launchpad.net/tripleo/+bug/1288425 /opt/stack/venvs/keystone/bin/pip install -U kombu,,3,0
openstack%2Ftripleo-heat-templates~master~I559855887349bf2bbab87788ef9baa216bde60d8,openstack/tripleo-heat-templates,master,I559855887349bf2bbab87788ef9baa216bde60d8,Fix bad indentation,MERGED,2014-03-05 23:52:52.000000000,2014-03-06 00:24:02.000000000,2014-03-06 00:24:02.000000000,"[{'_account_id': 3}, {'_account_id': 6488}]","[{'number': 1, 'created': '2014-03-05 23:52:52.000000000', 'files': ['undercloud-source.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/fa06cba2e40e84133452673728ca208348bb64a6', 'message': 'Fix bad indentation\n\nLines for notifier-strategy and log-file had 1 level too much of\nidentation causing an error in the available metadata.\n\nChange-Id: I559855887349bf2bbab87788ef9baa216bde60d8\n'}]",0,78460,fa06cba2e40e84133452673728ca208348bb64a6,7,2,1,7144,,,0,"Fix bad indentation

Lines for notifier-strategy and log-file had 1 level too much of
identation causing an error in the available metadata.

Change-Id: I559855887349bf2bbab87788ef9baa216bde60d8
",git fetch https://review.opendev.org/openstack/tripleo-heat-templates refs/changes/60/78460/1 && git format-patch -1 --stdout FETCH_HEAD,['undercloud-source.yaml'],1,fa06cba2e40e84133452673728ca208348bb64a6,, notifier-strategy: Ref: GlanceNotifierStrategy log-file: Ref: GlanceLogFile, notifier-strategy: Ref: GlanceNotifierStrategy log-file: Ref: GlanceLogFile,4,4
openstack%2Fheat~master~Iad13fd25e3697e3462753dc53ae25418969da8a5,openstack/heat,master,Iad13fd25e3697e3462753dc53ae25418969da8a5,Load functions from plugins,MERGED,2014-02-19 05:10:41.000000000,2014-03-06 00:15:11.000000000,2014-03-06 00:15:11.000000000,"[{'_account_id': 3}, {'_account_id': 2834}, {'_account_id': 4257}, {'_account_id': 4571}, {'_account_id': 7385}]","[{'number': 1, 'created': '2014-02-19 05:10:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/7d459cab00b25c82f66a4202d42e03d43d9b9013', 'message': 'Load functions from plugins\n\nImplements blueprint function-plugins\n\nChange-Id: Iad13fd25e3697e3462753dc53ae25418969da8a5\n'}, {'number': 2, 'created': '2014-02-25 19:02:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/7deecc013be58e51ad85e09deec9822c49932d77', 'message': 'Load functions from plugins\n\nImplements blueprint function-plugins\n\nChange-Id: Iad13fd25e3697e3462753dc53ae25418969da8a5\n'}, {'number': 3, 'created': '2014-03-04 02:11:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/3e358ddd8b6bb6dd0d08cb85200afedcb3b0831a', 'message': 'Load functions from plugins\n\nImplements blueprint function-plugins\n\nChange-Id: Iad13fd25e3697e3462753dc53ae25418969da8a5\n'}, {'number': 4, 'created': '2014-03-05 16:14:21.000000000', 'files': ['heat/engine/hot/__init__.py', 'heat/engine/template.py', 'heat/engine/cfn/template.py', 'heat/tests/test_template.py'], 'web_link': 'https://opendev.org/openstack/heat/commit/715222234f0b0f7047eed431deec51a0b35962da', 'message': 'Load functions from plugins\n\nImplements blueprint function-plugins\n\nChange-Id: Iad13fd25e3697e3462753dc53ae25418969da8a5\n'}]",0,74592,715222234f0b0f7047eed431deec51a0b35962da,24,5,4,4257,,,0,"Load functions from plugins

Implements blueprint function-plugins

Change-Id: Iad13fd25e3697e3462753dc53ae25418969da8a5
",git fetch https://review.opendev.org/openstack/heat refs/changes/92/74592/3 && git format-patch -1 --stdout FETCH_HEAD,"['heat/engine/hot/__init__.py', 'heat/engine/template.py', 'heat/engine/cfn/template.py']",3,7d459cab00b25c82f66a4202d42e03d43d9b9013,typeless-function-plugins,from heat.engine import plugin_manager _plugins = plugin_manager.PluginManager('heat.engine.cfn') ,from heat.engine.cfn import functions def functions(self): return functions.function_mapping(*self.version()),21,10
openstack%2Fheat~master~If682ca26f9d214a4cfc1b86baa29f87242373f04,openstack/heat,master,If682ca26f9d214a4cfc1b86baa29f87242373f04,Use PluginManager to load resources,MERGED,2014-02-19 05:10:39.000000000,2014-03-06 00:15:04.000000000,2014-03-06 00:15:03.000000000,"[{'_account_id': 3}, {'_account_id': 2834}, {'_account_id': 4257}, {'_account_id': 4571}, {'_account_id': 7385}, {'_account_id': 9062}, {'_account_id': 9189}]","[{'number': 1, 'created': '2014-02-19 05:10:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/8b18db0be02b82c39a94b5118b0601b6d2bb1d20', 'message': 'Use PluginManager to load resources\n\nChange-Id: If682ca26f9d214a4cfc1b86baa29f87242373f04\n'}, {'number': 2, 'created': '2014-02-25 19:02:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/aa2038b8bb049fba4855a85febec4fc0613da809', 'message': 'Use PluginManager to load resources\n\nChange-Id: If682ca26f9d214a4cfc1b86baa29f87242373f04\n'}, {'number': 3, 'created': '2014-03-04 02:11:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/3c7b8dfefb2ecc7e1389e540a4d047c8db5c2b78', 'message': 'Use PluginManager to load resources\n\nChange-Id: If682ca26f9d214a4cfc1b86baa29f87242373f04\n'}, {'number': 4, 'created': '2014-03-05 16:14:27.000000000', 'files': ['heat/engine/resources/__init__.py'], 'web_link': 'https://opendev.org/openstack/heat/commit/98e03d7a16d1a080184d6c909442f5b9169a76db', 'message': 'Use PluginManager to load resources\n\nChange-Id: If682ca26f9d214a4cfc1b86baa29f87242373f04\n'}]",0,74591,98e03d7a16d1a080184d6c909442f5b9169a76db,27,7,4,4257,,,0,"Use PluginManager to load resources

Change-Id: If682ca26f9d214a4cfc1b86baa29f87242373f04
",git fetch https://review.opendev.org/openstack/heat refs/changes/91/74591/4 && git format-patch -1 --stdout FETCH_HEAD,['heat/engine/resources/__init__.py'],1,8b18db0be02b82c39a94b5118b0601b6d2bb1d20,typeless-function-plugins,"from heat.engine import plugin_managerdef _load_global_resources(env): manager = plugin_manager.PluginManager(__name__) resource_mapping = plugin_manager.PluginMapping(['available_resource', 'resource']) constraint_mapping = plugin_manager.PluginMapping('constraint') _register_resources(env, resource_mapping.load_all(manager)) _register_constraints(env, constraint_mapping.load_all(manager))","import itertoolsdef _get_all_module_resources(module): '''Returns all resource in `module`.''' if callable(getattr(module, 'resource_mapping', None)): try: return module.resource_mapping().iteritems() except Exception: LOG.info(_('Failed to list resources from %s') % str(module)) else: return {} def _get_available_module_resources(module): ''' Returns resources in `module` available for registration Sometimes resources should not be available for registration in Heat due to unsatisfied dependencies. This function will look for a function called `available_resource_mapping` and, if present, return the resources the can be properly loaded. If this is not present, it'll look for the regular `resource_mapping` and return all resources from there. ''' try: if callable(getattr(module, 'available_resource_mapping', None)): return module.available_resource_mapping().iteritems() elif callable(getattr(module, 'resource_mapping', None)): return module.resource_mapping().iteritems() except Exception: LOG.error(_('Failed to load resources from %s') % str(module)) return {} def _get_module_constraints(module): if callable(getattr(module, 'constraint_mapping', None)): return module.constraint_mapping().iteritems() else: return [] def _register_modules(env, modules): data_lists = [(_get_available_module_resources(m), _get_module_constraints(m)) for m in modules] if data_lists: resource_lists, constraint_lists = zip(*data_lists) _register_resources(env, itertools.chain.from_iterable(resource_lists)) _register_constraints( env, itertools.chain.from_iterable(constraint_lists)) def _global_modules(): ''' Returns all core and plugin resource modules in Heat. Core resource modules are yielded first to allow plugin modules to override them if desired. ''' import sys from heat.common import plugin_loader cfg.CONF.import_opt('plugin_dirs', 'heat.common.config') plugin_pkg = plugin_loader.create_subpackage(cfg.CONF.plugin_dirs, 'heat.engine') yield __name__, plugin_loader.load_modules(sys.modules[__name__]) yield plugin_pkg.__name__, plugin_loader.load_modules(plugin_pkg, True) def _load_global_resources(env): for package, modules in _global_modules(): _register_modules(env, modules)",9,72
openstack%2Fapi-site~master~I4f230e2f8084bdfba2c02095f2cb8bb90678a7ea,openstack/api-site,master,I4f230e2f8084bdfba2c02095f2cb8bb90678a7ea,"Add ""shelve a server"" API description",MERGED,2014-02-27 02:44:25.000000000,2014-03-06 00:14:44.000000000,2014-03-05 20:09:09.000000000,"[{'_account_id': 3}, {'_account_id': 2448}, {'_account_id': 6167}]","[{'number': 1, 'created': '2014-02-27 02:44:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/api-site/commit/cf25306f0a67a58db67aae6649144e11d657c1cc', 'message': 'Add ""shelve a server"" API description\n\nNow ""shelve a server"" API of Nova has been implemented since Havana,\nand this patch adds the API description.\n\nChange-Id: I4f230e2f8084bdfba2c02095f2cb8bb90678a7ea\n'}, {'number': 2, 'created': '2014-03-05 16:09:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/api-site/commit/a809c3ab999663bda866e0239d166d0efa55fbed', 'message': 'Add ""shelve a server"" API description\n\nNow ""shelve a server"" API of Nova has been implemented since Havana,\nand this patch adds the API description.\n\nChange-Id: I4f230e2f8084bdfba2c02095f2cb8bb90678a7ea\n'}, {'number': 3, 'created': '2014-03-05 16:11:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/api-site/commit/065044ad3cac8d7f05ecbe5ce57c620f100179d6', 'message': 'Add ""shelve a server"" API description\n\nNow ""shelve a server"" API of Nova has been implemented since Havana,\nand this patch adds the API description.\n\nChange-Id: I4f230e2f8084bdfba2c02095f2cb8bb90678a7ea\n'}, {'number': 4, 'created': '2014-03-05 19:23:32.000000000', 'files': ['api-ref/src/wadls/compute-api/src/v2/ext/os-server-shelve.wadl', 'api-ref/src/wadls/compute-api/src/v2/api_samples/os-shelve/os-shelve.xml', 'api-ref/src/docbkx/ch_compute-v2-ext.xml', 'api-ref/src/wadls/compute-api/src/v2/api_samples/os-shelve/os-shelve.json'], 'web_link': 'https://opendev.org/openstack/api-site/commit/c8914056afa5c3ebced2fb4de2f1e325248e8eca', 'message': 'Add ""shelve a server"" API description\n\nNow ""shelve a server"" API of Nova has been implemented since Havana,\nand this patch adds the API description.\n\nChange-Id: I4f230e2f8084bdfba2c02095f2cb8bb90678a7ea\n'}]",1,76738,c8914056afa5c3ebced2fb4de2f1e325248e8eca,23,3,4,6167,,,0,"Add ""shelve a server"" API description

Now ""shelve a server"" API of Nova has been implemented since Havana,
and this patch adds the API description.

Change-Id: I4f230e2f8084bdfba2c02095f2cb8bb90678a7ea
",git fetch https://review.opendev.org/openstack/api-site refs/changes/38/76738/2 && git format-patch -1 --stdout FETCH_HEAD,"['api-ref/src/wadls/compute-api/src/v2/ext/os-server-shelve.wadl', 'api-ref/src/docbkx/ch_compute-v2-ext.xml']",2,cf25306f0a67a58db67aae6649144e11d657c1cc,shelve," <section xml:id=""ext-os-shelve""> <title>Server shelve (os-server-shelve)</title> <para>Shelve a running server.</para> <wadl:resources href=""../wadls/compute-api/src/v2/ext/os-server-shelve.wadl"" xmlns:wadl=""http://wadl.dev.java.net/2009/02""/> </section>",,77,0
openstack%2Fneutron~master~I9ecff4a4e044920ed2dde709c89aeb9bc773220d,openstack/neutron,master,I9ecff4a4e044920ed2dde709c89aeb9bc773220d,ML2 mechanism driver access to binding details,MERGED,2014-02-25 21:09:23.000000000,2014-03-06 00:14:42.000000000,2014-03-06 00:14:39.000000000,"[{'_account_id': 3}, {'_account_id': 105}, {'_account_id': 841}, {'_account_id': 1689}, {'_account_id': 2592}, {'_account_id': 6524}, {'_account_id': 6598}, {'_account_id': 6694}, {'_account_id': 6854}, {'_account_id': 9732}, {'_account_id': 9787}, {'_account_id': 9845}, {'_account_id': 10116}, {'_account_id': 10117}, {'_account_id': 10153}, {'_account_id': 10184}, {'_account_id': 10192}, {'_account_id': 10294}, {'_account_id': 10387}]","[{'number': 1, 'created': '2014-02-25 21:09:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/be5f97c8735defe610658e7e432c9a486e966af2', 'message': 'ML2 mechanism driver access to binding details.\n\nThe following properties are added to the PortContext object passed to\nML2 mechanism drivers for port operations:\n\n* bound_driver - name of current bound driver\n* original_bound_driver - name previously bound driver in an update\n* original_bound_segment - network segment used in previous binding\n\nSome issues with the existing ML2 port binding unit tests were also\nfixed.\n\nPartial-Bug: #1276395\nChange-Id: I9ecff4a4e044920ed2dde709c89aeb9bc773220d\n'}, {'number': 2, 'created': '2014-02-26 15:57:22.000000000', 'files': ['neutron/plugins/ml2/driver_context.py', 'neutron/tests/unit/ml2/drivers/mechanism_logger.py', 'neutron/plugins/ml2/driver_api.py', 'neutron/tests/unit/ml2/_test_mech_agent.py', 'neutron/tests/unit/ml2/drivers/mechanism_test.py', 'neutron/tests/unit/ml2/test_port_binding.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/d1472deed5bf7b4cec7363e64fd4746cb278fcfb', 'message': 'ML2 mechanism driver access to binding details\n\nThe following properties are added to the PortContext object passed to\nML2 mechanism drivers for port operations:\n\n* bound_driver - name of current bound driver\n* original_bound_driver - name previously bound driver in an update\n* original_bound_segment - network segment used in previous binding\n\nSome issues with the existing ML2 port binding unit tests were also\nfixed.\n\nThe remainder of the fix for bug 1276395, making these binding details\navailable to mechanism drivers when a port is deleted, will be\naddressed as part of the fix for bug 1276391.\n\nPartial-Bug: #1276395\nChange-Id: I9ecff4a4e044920ed2dde709c89aeb9bc773220d\n'}]",8,76363,d1472deed5bf7b4cec7363e64fd4746cb278fcfb,45,19,2,1689,,,0,"ML2 mechanism driver access to binding details

The following properties are added to the PortContext object passed to
ML2 mechanism drivers for port operations:

* bound_driver - name of current bound driver
* original_bound_driver - name previously bound driver in an update
* original_bound_segment - network segment used in previous binding

Some issues with the existing ML2 port binding unit tests were also
fixed.

The remainder of the fix for bug 1276395, making these binding details
available to mechanism drivers when a port is deleted, will be
addressed as part of the fix for bug 1276391.

Partial-Bug: #1276395
Change-Id: I9ecff4a4e044920ed2dde709c89aeb9bc773220d
",git fetch https://review.opendev.org/openstack/neutron refs/changes/63/76363/2 && git format-patch -1 --stdout FETCH_HEAD,"['neutron/plugins/ml2/driver_context.py', 'neutron/plugins/ml2/driver_api.py', 'neutron/tests/unit/ml2/drivers/mechanism_logger.py', 'neutron/tests/unit/ml2/_test_mech_agent.py', 'neutron/tests/unit/ml2/drivers/mechanism_test.py', 'neutron/tests/unit/ml2/test_port_binding.py']",6,be5f97c8735defe610658e7e432c9a486e966af2,bug/1276395," self._test_update_port_binding('host-ovs-no_filter', self._test_update_port_binding('host-ovs-no_filter', 'host-ovs-no_filter') self._test_update_port_binding('host-ovs-no_filter') self._test_update_port_binding('', 'host-ovs-no_filter') self._test_update_port_binding('host-ovs-no_filter', '')"," self._test_update_port_binding('host-ovs-no-filter', self._test_update_port_binding('host-ovs-no-filter', 'host-ovs-no-filter') self._test_update_port_binding('host-ovs-no-filter') self._test_update_port_binding('', 'host-ovs-no-filter') self._test_update_port_binding('host-ovs-no-filter', '')",116,12
openstack%2Fkeystone~master~I448aac133060fe7a4793ed5d92d7698db9984401,openstack/keystone,master,I448aac133060fe7a4793ed5d92d7698db9984401,Update Oslo wiki link in README,MERGED,2014-02-28 12:26:22.000000000,2014-03-06 00:14:29.000000000,2014-03-06 00:14:26.000000000,"[{'_account_id': 3}, {'_account_id': 4}, {'_account_id': 5046}, {'_account_id': 6460}, {'_account_id': 6486}, {'_account_id': 9796}]","[{'number': 1, 'created': '2014-02-28 12:26:22.000000000', 'files': ['keystone/openstack/common/README'], 'web_link': 'https://opendev.org/openstack/keystone/commit/69c347ce19160b7f75e3a8f74fea2d46b2df48db', 'message': 'Update Oslo wiki link in README\n\nUse lastest Oslo wiki link.\n\nChange-Id: I448aac133060fe7a4793ed5d92d7698db9984401\n'}]",0,77157,69c347ce19160b7f75e3a8f74fea2d46b2df48db,17,6,1,9796,,,0,"Update Oslo wiki link in README

Use lastest Oslo wiki link.

Change-Id: I448aac133060fe7a4793ed5d92d7698db9984401
",git fetch https://review.opendev.org/openstack/keystone refs/changes/57/77157/1 && git format-patch -1 --stdout FETCH_HEAD,['keystone/openstack/common/README'],1,69c347ce19160b7f75e3a8f74fea2d46b2df48db,update_oslo_wiki, https://wiki.openstack.org/wiki/Oslo#Syncing_Code_from_Incubator, http://wiki.openstack.org/CommonLibrary#Incubation,1,1
openstack%2Fpython-zaqarclient~master~I526ff1104b21fba1398b09f36a68d2925aa69be9,openstack/python-zaqarclient,master,I526ff1104b21fba1398b09f36a68d2925aa69be9,Added API version to URL,ABANDONED,2014-03-05 16:29:32.000000000,2014-03-06 00:14:04.000000000,,"[{'_account_id': 3}, {'_account_id': 6159}, {'_account_id': 6427}, {'_account_id': 6944}, {'_account_id': 7498}, {'_account_id': 10476}]","[{'number': 1, 'created': '2014-03-05 16:29:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-zaqarclient/commit/f8f839fa417f2c11ac469ee86d3f62e988f0c306', 'message': 'Added API version to URL.\n\nCloses-Bug: 1287933\nChange-Id: I526ff1104b21fba1398b09f36a68d2925aa69be9\n'}, {'number': 2, 'created': '2014-03-05 18:29:48.000000000', 'files': ['tests/unit/transport/test_http.py', 'marconiclient/transport/http.py'], 'web_link': 'https://opendev.org/openstack/python-zaqarclient/commit/da1b7bc00fcfe8bcf81c06a7abe809876f70113e', 'message': 'Added API version to URL\n\nCloses-Bug: 1287933\nChange-Id: I526ff1104b21fba1398b09f36a68d2925aa69be9\n'}]",2,78290,da1b7bc00fcfe8bcf81c06a7abe809876f70113e,14,6,2,10476,,,0,"Added API version to URL

Closes-Bug: 1287933
Change-Id: I526ff1104b21fba1398b09f36a68d2925aa69be9
",git fetch https://review.opendev.org/openstack/python-zaqarclient refs/changes/90/78290/1 && git format-patch -1 --stdout FETCH_HEAD,"['tests/unit/transport/test_http.py', 'marconiclient/transport/http.py']",2,f8f839fa417f2c11ac469ee86d3f62e988f0c306,bug/1287933," url = '{0}/{1}/{2}'.format(request.endpoint.rstrip('/'), request.api.label, ref.format(**ref_params)) "," url = '{0}/{1}'.format(request.endpoint.rstrip('/'), ref.format(**ref_params))",6,3
openstack%2Fnova~master~I02619164176a723e313ae274e527948d45fa6cad,openstack/nova,master,I02619164176a723e313ae274e527948d45fa6cad,Fix incorrect kwargs 'reason' for HTTPBadRequest,MERGED,2013-12-27 12:52:05.000000000,2014-03-06 00:13:23.000000000,2014-03-06 00:13:19.000000000,"[{'_account_id': 3}, {'_account_id': 360}, {'_account_id': 1653}, {'_account_id': 1779}, {'_account_id': 2271}, {'_account_id': 2750}, {'_account_id': 2835}, {'_account_id': 6062}, {'_account_id': 6676}, {'_account_id': 6873}, {'_account_id': 7494}, {'_account_id': 9008}, {'_account_id': 9578}]","[{'number': 1, 'created': '2013-12-27 12:52:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/a2617d724207f301438d859add15ef04e4a9de7a', 'message': ""Fix incorrect kwargs 'reason' for HTTPBadRequest\n\nwebob.exc.HTTPBadRequest doesn't have attribute 'reason', and its\n__init__ method doesn't have such parameter too, so if we use such\nkwargs, it will not be accepted by constructor of base class\nWSGIHTTPException, then the http response body will format message\nusing default explanation instead of what we expected.\n\nWe should use kwargs 'explanation' instead of wrong 'reason'.\n\nChange-Id: I02619164176a723e313ae274e527948d45fa6cad\nCloses-Bug: #1264223\n""}, {'number': 2, 'created': '2014-01-17 03:05:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/d0f2e7c80fe09369038219c955f7d2e704aadcfb', 'message': ""Fix incorrect kwargs 'reason' for HTTPBadRequest\n\nwebob.exc.HTTPBadRequest doesn't have attribute 'reason', and its\n__init__ method doesn't have such parameter too, so if we use such\nkwargs, it will not be accepted by constructor of base class\nWSGIHTTPException, then the http response body will format message\nusing default explanation instead of what we expected.\n\nWe should use kwargs 'explanation' instead of wrong 'reason'.\n\nChange-Id: I02619164176a723e313ae274e527948d45fa6cad\nCloses-Bug: #1264223\n""}, {'number': 3, 'created': '2014-02-18 01:30:01.000000000', 'files': ['nova/api/openstack/compute/contrib/scheduler_hints.py', 'nova/api/openstack/compute/plugins/v3/scheduler_hints.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/c049f99a1016083af598362983d4335f210f7f0e', 'message': ""Fix incorrect kwargs 'reason' for HTTPBadRequest\n\nwebob.exc.HTTPBadRequest doesn't have attribute 'reason', and its\n__init__ method doesn't have such parameter too, so if we use such\nkwargs, it will not be accepted by constructor of base class\nWSGIHTTPException, then the http response body will format message\nusing default explanation instead of what we expected.\n\nWe should use kwargs 'explanation' instead of wrong 'reason'.\n\nChange-Id: I02619164176a723e313ae274e527948d45fa6cad\nCloses-Bug: #1264223\n""}]",5,64264,c049f99a1016083af598362983d4335f210f7f0e,41,13,3,6676,,,0,"Fix incorrect kwargs 'reason' for HTTPBadRequest

webob.exc.HTTPBadRequest doesn't have attribute 'reason', and its
__init__ method doesn't have such parameter too, so if we use such
kwargs, it will not be accepted by constructor of base class
WSGIHTTPException, then the http response body will format message
using default explanation instead of what we expected.

We should use kwargs 'explanation' instead of wrong 'reason'.

Change-Id: I02619164176a723e313ae274e527948d45fa6cad
Closes-Bug: #1264223
",git fetch https://review.opendev.org/openstack/nova refs/changes/64/64264/1 && git format-patch -1 --stdout FETCH_HEAD,"['nova/api/openstack/compute/contrib/scheduler_hints.py', 'nova/tests/api/openstack/compute/contrib/test_scheduler_hints.py', 'nova/tests/api/openstack/compute/plugins/v3/test_scheduler_hints.py', 'nova/api/openstack/compute/plugins/v3/scheduler_hints.py']",4,a2617d724207f301438d859add15ef04e4a9de7a,bug/1264223, raise webob.exc.HTTPBadRequest(explanation=msg), raise webob.exc.HTTPBadRequest(reason=msg),7,2
openstack%2Fpython-neutronclient~master~Id9f51f0d630ef0c92fc315253c45d3abba356cd1,openstack/python-neutronclient,master,Id9f51f0d630ef0c92fc315253c45d3abba356cd1,Python 3: fix a call to ugettext(),MERGED,2013-12-17 12:43:00.000000000,2014-03-05 23:57:01.000000000,2014-03-05 23:57:01.000000000,"[{'_account_id': 3}, {'_account_id': 490}, {'_account_id': 841}, {'_account_id': 2592}, {'_account_id': 7020}, {'_account_id': 8122}, {'_account_id': 9107}]","[{'number': 1, 'created': '2013-12-17 12:43:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-neutronclient/commit/327e8e17fe54c009d12bcf24de468294b1afa6e2', 'message': 'Python 3: fix a call to ugettext()\n\nIn Python 3, ugettext() does not exist and gettext() should be used instead.\n\nChange-Id: Id9f51f0d630ef0c92fc315253c45d3abba356cd1\n'}, {'number': 2, 'created': '2014-02-20 15:15:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-neutronclient/commit/75a952634d890680bfa40f6cfaa9f51842b15dd6', 'message': 'Python 3: fix a call to ugettext()\n\nIn Python 3, ugettext() does not exist and gettext() should be used instead.\n\nChange-Id: Id9f51f0d630ef0c92fc315253c45d3abba356cd1\n'}, {'number': 3, 'created': '2014-02-27 01:18:20.000000000', 'files': ['neutronclient/common/__init__.py'], 'web_link': 'https://opendev.org/openstack/python-neutronclient/commit/e193d829d13f3e39977b0f842aebee921bdaed30', 'message': 'Python 3: fix a call to ugettext()\n\nIn Python 3, ugettext() does not exist and gettext() should be used instead.\n\nCloses-Bug: 128485\nChange-Id: Id9f51f0d630ef0c92fc315253c45d3abba356cd1\n'}]",2,62626,e193d829d13f3e39977b0f842aebee921bdaed30,46,7,3,8122,,,0,"Python 3: fix a call to ugettext()

In Python 3, ugettext() does not exist and gettext() should be used instead.

Closes-Bug: 128485
Change-Id: Id9f51f0d630ef0c92fc315253c45d3abba356cd1
",git fetch https://review.opendev.org/openstack/python-neutronclient refs/changes/26/62626/1 && git format-patch -1 --stdout FETCH_HEAD,['neutronclient/common/__init__.py'],1,327e8e17fe54c009d12bcf24de468294b1afa6e2,bug/128485, try: return t.ugettext(msg) except AttributeError: return t.gettext(msg), return t.ugettext(msg),4,1
openstack%2Fpuppet-ceilometer~master~Iccc660814991e30b12a884a6e6ffd4f581c768c4,openstack/puppet-ceilometer,master,Iccc660814991e30b12a884a6e6ffd4f581c768c4,Implement notification agent service,MERGED,2014-01-24 15:38:43.000000000,2014-03-05 23:53:40.000000000,2014-03-05 23:53:39.000000000,"[{'_account_id': 3}, {'_account_id': 1669}, {'_account_id': 1918}, {'_account_id': 3153}, {'_account_id': 6994}, {'_account_id': 7156}, {'_account_id': 7822}, {'_account_id': 8083}]","[{'number': 1, 'created': '2014-01-24 15:38:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-ceilometer/commit/a3b4332ecfb8dc8e97a2fb6d1bf69218aae910fc', 'message': 'Implement notification agent service\n\nIn Icehouse, ceilometer-agent-notification is a new service which splits\nceilometer-collector responsibilites.\n\nimplement blueprint ceilometer-agent-notification\nChange-Id: Iccc660814991e30b12a884a6e6ffd4f581c768c4\nSigned-off-by: Emilien Macchi <emilien.macchi@enovance.com>\n'}, {'number': 2, 'created': '2014-01-24 15:40:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-ceilometer/commit/a5267d7075b5dff43aa70f1d455ad7db63e06bae', 'message': 'Implement notification agent service\n\nIn Icehouse, ceilometer-agent-notification is a new service which splits\nceilometer-collector responsibilites.\n\nimplement blueprint ceilometer-agent-notification\nChange-Id: Iccc660814991e30b12a884a6e6ffd4f581c768c4\nSigned-off-by: Emilien Macchi <emilien.macchi@enovance.com>\n'}, {'number': 3, 'created': '2014-02-05 16:56:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-ceilometer/commit/62382ceb090efb193c367cc443de4f1747abfa8f', 'message': 'Implement notification agent service\n\nIn Icehouse, ceilometer-agent-notification is a new service which splits\nceilometer-collector responsibilites.\n\nimplement blueprint ceilometer-agent-notification\nChange-Id: Iccc660814991e30b12a884a6e6ffd4f581c768c4\nSigned-off-by: Emilien Macchi <emilien.macchi@enovance.com>\n'}, {'number': 4, 'created': '2014-03-03 10:40:34.000000000', 'files': ['manifests/agent/notification.pp', 'spec/classes/ceilometer_agent_notification_spec.rb', 'examples/site.pp', 'manifests/params.pp', 'spec/classes/ceilometer_collector_spec.rb', 'manifests/collector.pp'], 'web_link': 'https://opendev.org/openstack/puppet-ceilometer/commit/db81d776f1e0b3e7ecbb8ae98d74e55e6d773bb1', 'message': 'Implement notification agent service\n\nIn Icehouse, ceilometer-agent-notification is a new service which splits\nceilometer-collector responsibilites.\n\nimplement blueprint ceilometer-agent-notification\nChange-Id: Iccc660814991e30b12a884a6e6ffd4f581c768c4\nSigned-off-by: Emilien Macchi <emilien.macchi@enovance.com>\n'}]",4,68940,db81d776f1e0b3e7ecbb8ae98d74e55e6d773bb1,29,8,4,3153,,,0,"Implement notification agent service

In Icehouse, ceilometer-agent-notification is a new service which splits
ceilometer-collector responsibilites.

implement blueprint ceilometer-agent-notification
Change-Id: Iccc660814991e30b12a884a6e6ffd4f581c768c4
Signed-off-by: Emilien Macchi <emilien.macchi@enovance.com>
",git fetch https://review.opendev.org/openstack/puppet-ceilometer refs/changes/40/68940/4 && git format-patch -1 --stdout FETCH_HEAD,"['manifests/agent/notification.pp', 'spec/classes/ceilometer_agent_notification_spec.rb', 'examples/site.pp', 'manifests/params.pp']",4,a3b4332ecfb8dc8e97a2fb6d1bf69218aae910fc,bp/ceilometer-agent-notification, # notification agent is included in collector package: $notification_package_name = 'openstack-ceilometer-collector' $notification_service_name = 'openstack-ceilometer-agent-notification' $notification_package_name = 'ceilometer-agent-notification' $notification_service_name = 'ceilometer-agent-notification',,173,0
openstack%2Fsolum~master~I3584943af0b78c310ebcb47d6d2839b6cbb03e0d,openstack/solum,master,I3584943af0b78c310ebcb47d6d2839b6cbb03e0d,Added request context to image handler,ABANDONED,2014-03-05 20:56:31.000000000,2014-03-05 23:53:20.000000000,,"[{'_account_id': 3}, {'_account_id': 668}, {'_account_id': 4715}, {'_account_id': 9095}, {'_account_id': 9113}]","[{'number': 1, 'created': '2014-03-05 20:56:31.000000000', 'files': ['solum/tests/builder/handlers/test_image.py', 'solum/builder/controllers/v1/image.py', 'solum/builder/handlers/image_handler.py'], 'web_link': 'https://opendev.org/openstack/solum/commit/8cbb16c2c1e6f312cce858425ad8f50161837bc6', 'message': 'Added request context to image handler\n\nChange-Id: I3584943af0b78c310ebcb47d6d2839b6cbb03e0d\n'}]",2,78413,8cbb16c2c1e6f312cce858425ad8f50161837bc6,6,5,1,2506,,,0,"Added request context to image handler

Change-Id: I3584943af0b78c310ebcb47d6d2839b6cbb03e0d
",git fetch https://review.opendev.org/openstack/solum refs/changes/13/78413/1 && git format-patch -1 --stdout FETCH_HEAD,"['solum/tests/builder/handlers/test_image.py', 'solum/builder/controllers/v1/image.py', 'solum/builder/handlers/image_handler.py']",3,8cbb16c2c1e6f312cce858425ad8f50161837bc6,," # TODO(devkulkarni) - remove this once Angus's patch # gets merged (https://review.openstack.org/#/c/77534/) def __init__(self, context): self.context = context ",,14,4
openstack%2Fopenstack-planet~master~If4a1b227e7fc5cad0caab36541b56161f1682b64,openstack/openstack-planet,master,If4a1b227e7fc5cad0caab36541b56161f1682b64,Removed Oren Katz tumblr feed as it seems to be hacked and hosting spam posts. Resubmit once cleaned.,MERGED,2014-03-05 23:02:22.000000000,2014-03-05 23:52:05.000000000,2014-03-05 23:52:05.000000000,"[{'_account_id': 3}, {'_account_id': 287}]","[{'number': 1, 'created': '2014-03-05 23:02:22.000000000', 'files': ['planet.ini'], 'web_link': 'https://opendev.org/openstack/openstack-planet/commit/a081cd47351f5a53c536c9e37049c74ce02373e3', 'message': 'Removed Oren Katz tumblr feed as it seems to be hacked\nand hosting spam posts. Resubmit once cleaned.\n\nChange-Id: If4a1b227e7fc5cad0caab36541b56161f1682b64\n'}]",0,78443,a081cd47351f5a53c536c9e37049c74ce02373e3,6,2,1,287,,,0,"Removed Oren Katz tumblr feed as it seems to be hacked
and hosting spam posts. Resubmit once cleaned.

Change-Id: If4a1b227e7fc5cad0caab36541b56161f1682b64
",git fetch https://review.opendev.org/openstack/openstack-planet refs/changes/43/78443/1 && git format-patch -1 --stdout FETCH_HEAD,['planet.ini'],1,a081cd47351f5a53c536c9e37049c74ce02373e3,nospam,,[http://orenscloudplatformthoughts.tumblr.com/rss] name = Oren Katz face = orenkatz.png nick = orenkatz ,0,5
openstack%2Fneutron~master~I55e8f4f3523ec7a7c5a6f082addf918952a05741,openstack/neutron,master,I55e8f4f3523ec7a7c5a6f082addf918952a05741,Refactor netns.execute so that it is not necessary to check namespace,MERGED,2014-03-04 05:03:22.000000000,2014-03-05 23:50:56.000000000,2014-03-05 23:50:55.000000000,"[{'_account_id': 3}, {'_account_id': 105}, {'_account_id': 841}, {'_account_id': 1131}, {'_account_id': 2592}, {'_account_id': 5170}, {'_account_id': 7448}, {'_account_id': 9681}, {'_account_id': 9732}, {'_account_id': 9845}, {'_account_id': 9925}, {'_account_id': 10116}, {'_account_id': 10184}, {'_account_id': 10294}]","[{'number': 1, 'created': '2014-03-04 05:03:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/63cc72b117bd261806a419c1d799266d7b1849a7', 'message': 'Refactor netns.execute so that it is not necessary to check namespace\n\nI saw some code in a couple of reviews today that check whether a\nnamespace is set and run it under ""ip netns exec ..."" if it is.\nOtherwise, it runs the command without it in the default namespace.\n\nChange-Id: I55e8f4f3523ec7a7c5a6f082addf918952a05741\nCloses-Bug: #1287524\n'}, {'number': 2, 'created': '2014-03-04 16:16:13.000000000', 'files': ['neutron/agent/linux/ip_lib.py', 'neutron/tests/unit/test_linux_external_process.py', 'neutron/agent/linux/external_process.py', 'neutron/agent/l3_agent.py', 'neutron/agent/linux/dhcp.py', 'neutron/tests/unit/test_l3_agent.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/40390598c5a440d1bbfa4f229130eeedf5cd4dba', 'message': 'Refactor netns.execute so that it is not necessary to check namespace\n\nI saw some code in a couple of reviews today that check whether a\nnamespace is set and run it under ""ip netns exec ..."" if it is.\nOtherwise, it runs the command without it in the default namespace.\n\nChange-Id: I55e8f4f3523ec7a7c5a6f082addf918952a05741\nCloses-Bug: #1287524\n'}]",1,77788,40390598c5a440d1bbfa4f229130eeedf5cd4dba,37,14,2,7448,,,0,"Refactor netns.execute so that it is not necessary to check namespace

I saw some code in a couple of reviews today that check whether a
namespace is set and run it under ""ip netns exec ..."" if it is.
Otherwise, it runs the command without it in the default namespace.

Change-Id: I55e8f4f3523ec7a7c5a6f082addf918952a05741
Closes-Bug: #1287524
",git fetch https://review.opendev.org/openstack/neutron refs/changes/88/77788/2 && git format-patch -1 --stdout FETCH_HEAD,"['neutron/agent/linux/external_process.py', 'neutron/agent/linux/ip_lib.py', 'neutron/agent/l3_agent.py', 'neutron/agent/linux/dhcp.py', 'neutron/tests/unit/test_l3_agent.py']",5,63cc72b117bd261806a419c1d799266d7b1849a7,77788," self.mock_ip.netns.execute.assert_any_call( arping_cmd, check_exit_code=True) self.mock_ip.netns.execute.assert_has_calls( [mock.call(call, check_exit_code=False) for call in calls], any_order=True)"," if self.conf.use_namespaces: self.mock_ip.netns.execute.assert_any_call( arping_cmd, check_exit_code=True) else: self.utils_exec.assert_any_call(arping_cmd, check_exit_code=True, root_helper=self.conf.root_helper) if namespace: self.mock_ip.netns.execute.assert_has_calls( [mock.call(call, check_exit_code=False) for call in calls], any_order=True) else: self.utils_exec.assert_has_calls([ mock.call(call, root_helper='sudo', check_exit_code=False) for call in calls], any_order=True)",34,71
openstack%2Fnova~master~Ie90247195181189d22e727a855145313397550ca,openstack/nova,master,Ie90247195181189d22e727a855145313397550ca,Fixing host_ip configuration help message,MERGED,2014-02-18 19:34:45.000000000,2014-03-05 23:49:52.000000000,2014-03-05 23:49:49.000000000,"[{'_account_id': 3}, {'_account_id': 475}, {'_account_id': 1653}, {'_account_id': 1779}, {'_account_id': 2750}, {'_account_id': 5170}, {'_account_id': 6167}, {'_account_id': 7400}, {'_account_id': 7575}, {'_account_id': 7629}, {'_account_id': 8119}, {'_account_id': 8574}, {'_account_id': 9533}, {'_account_id': 9578}, {'_account_id': 10179}]","[{'number': 1, 'created': '2014-02-18 19:34:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/e679d7dce1c2128ad911e32c02d4e7b4dec7f44d', 'message': 'Fixing host_ip configuration help message\n\nThe vCenter/ESXi client can only accept a hostname or IP address\nand not a URL.  Fix the help message to accurately describe what\nkind of address is accepted.\n\nChange-Id: Ie90247195181189d22e727a855145313397550ca\nCloses-Bug: #1274294\n'}, {'number': 2, 'created': '2014-02-19 04:09:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/6d4f373f0bf92bf13c61b7223f91290f7411e938', 'message': 'Fixing host_ip configuration help message\n\nThe vCenter/ESXi client can only accept a hostname or IP address\nand not a URL.  Fix the help message to accurately describe what\nkind of address is accepted.\n\nChange-Id: Ie90247195181189d22e727a855145313397550ca\nCloses-Bug: #1274294\n'}, {'number': 3, 'created': '2014-02-19 04:09:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/a3301b7a57e74d36edf146f1b768709722fb8aeb', 'message': 'Fixing host_ip configuration help message\n\nThe vCenter/ESXi client can only accept a hostname or IP address\nand not a URL.  Fix the help message to accurately describe what\nkind of address is accepted.\n\nChange-Id: Ie90247195181189d22e727a855145313397550ca\nCloses-Bug: #1274294\n'}, {'number': 4, 'created': '2014-02-19 15:17:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/bf5db816759800c0ed9352a816886ca3c8366371', 'message': 'Fixing host_ip configuration help message\n\nThe vCenter/ESXi client can only accept a hostname or IP address\nand not a URL.  Fix the help message to accurately describe what\nkind of address is accepted.\n\nChange-Id: Ie90247195181189d22e727a855145313397550ca\nCloses-Bug: #1274294\n'}, {'number': 5, 'created': '2014-02-19 15:17:56.000000000', 'files': ['etc/nova/nova.conf.sample', 'nova/virt/vmwareapi/driver.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/e498373b26d3fa05274429bcf958ea86eb4e3af2', 'message': 'Fixing host_ip configuration help message\n\nThe vCenter/ESXi client can only accept a hostname or IP address\nand not a URL.  Fix the help message to accurately describe what\nkind of address is accepted.\n\nChange-Id: Ie90247195181189d22e727a855145313397550ca\nCloses-Bug: #1274294\n'}]",0,74476,e498373b26d3fa05274429bcf958ea86eb4e3af2,66,15,5,8119,,,0,"Fixing host_ip configuration help message

The vCenter/ESXi client can only accept a hostname or IP address
and not a URL.  Fix the help message to accurately describe what
kind of address is accepted.

Change-Id: Ie90247195181189d22e727a855145313397550ca
Closes-Bug: #1274294
",git fetch https://review.opendev.org/openstack/nova refs/changes/76/74476/4 && git format-patch -1 --stdout FETCH_HEAD,"['etc/nova/nova.conf.sample', 'nova/virt/vmwareapi/driver.py']",2,e679d7dce1c2128ad911e32c02d4e7b4dec7f44d,bug/1274294," help='Hostname or IP address for connection to VMware ESX/VC ' 'host.'),"," help='URL for connection to VMware ESX/VC host.'),",3,2
openstack%2Ftempest~stable%2Fhavana~I7bb651497dfa3ce43ed2c5ac483360829ad4ee3f,openstack/tempest,stable/havana,I7bb651497dfa3ce43ed2c5ac483360829ad4ee3f,Add aggregates scenario test,MERGED,2014-02-07 17:10:18.000000000,2014-03-05 23:47:10.000000000,2014-03-05 23:47:09.000000000,"[{'_account_id': 3}, {'_account_id': 2750}, {'_account_id': 5174}, {'_account_id': 5196}]","[{'number': 1, 'created': '2014-02-07 17:10:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/8dc0357f86bf229468639dd4a6cc1ff9b98bc648', 'message': ""Add aggregates scenario test\n\nThe basic scenario for aggregates consists in the follow steps:\n- Creates an aggregate within an availability zone\n- Adds a host to the aggregate\n- Checks aggregate details\n- Updates aggregate's name\n- Removes host from aggregate\n- Deletes aggregate\n\ncherry-picked from I7a11b11468a5bbe85da4f6154308f7a5336c6919 with one change\nin the admin credentials provider method (credentials() method).\n\nRelated to bug: #1023131\n\nChange-Id: I7bb651497dfa3ce43ed2c5ac483360829ad4ee3f\n""}, {'number': 3, 'created': '2014-02-07 19:47:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/965fb341d5acdd06ea032d9038e941fba03fce0b', 'message': ""Add aggregates scenario test\n\nThe basic scenario for aggregates consists in the follow steps:\n- Creates an aggregate within an availability zone\n- Adds a host to the aggregate\n- Checks aggregate details\n- Updates aggregate's name\n- Removes host from aggregate\n- Deletes aggregate\n\ncherry-picked from I7a11b11468a5bbe85da4f6154308f7a5336c6919 with one change\nin the admin credentials provider method (credentials() method).\n\nRelated to bug: #1023131\n\nChange-Id: I7bb651497dfa3ce43ed2c5ac483360829ad4ee3f\n""}, {'number': 2, 'created': '2014-02-07 19:47:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/a5e8ca13ed10a6f5a399a728d7c8a89e5b457e00', 'message': ""Add aggregates scenario test\n\nThe basic scenario for aggregates consists in the follow steps:\n- Creates an aggregate within an availability zone\n- Adds a host to the aggregate\n- Checks aggregate details\n- Updates aggregate's name\n- Removes host from aggregate\n- Deletes aggregate\n\ncherry-picked from I7a11b11468a5bbe85da4f6154308f7a5336c6919 with one change\nin the admin credentials provider method (credentials() method).\n\nRelated to bug: #1023131\n\nChange-Id: I7bb651497dfa3ce43ed2c5ac483360829ad4ee3f\n""}, {'number': 4, 'created': '2014-02-07 19:47:33.000000000', 'files': ['tempest/scenario/test_aggregates_basic_ops.py'], 'web_link': 'https://opendev.org/openstack/tempest/commit/7e992f46af22a2bcd88782f9d1cee6c6879fc6f7', 'message': ""Add aggregates scenario test\n\nThe basic scenario for aggregates consists in the follow steps:\n- Creates an aggregate within an availability zone\n- Adds a host to the aggregate\n- Checks aggregate details\n- Updates aggregate's name\n- Removes host from aggregate\n- Deletes aggregate\n\ncherry-picked from I7a11b11468a5bbe85da4f6154308f7a5336c6919 with one change\nin the admin credentials provider method (credentials() method).\n\nRelated to bug: #1023131\n\nChange-Id: I7bb651497dfa3ce43ed2c5ac483360829ad4ee3f\n""}]",1,71950,7e992f46af22a2bcd88782f9d1cee6c6879fc6f7,49,4,4,5174,,,0,"Add aggregates scenario test

The basic scenario for aggregates consists in the follow steps:
- Creates an aggregate within an availability zone
- Adds a host to the aggregate
- Checks aggregate details
- Updates aggregate's name
- Removes host from aggregate
- Deletes aggregate

cherry-picked from I7a11b11468a5bbe85da4f6154308f7a5336c6919 with one change
in the admin credentials provider method (credentials() method).

Related to bug: #1023131

Change-Id: I7bb651497dfa3ce43ed2c5ac483360829ad4ee3f
",git fetch https://review.opendev.org/openstack/tempest refs/changes/50/71950/3 && git format-patch -1 --stdout FETCH_HEAD,['tempest/scenario/test_aggregates_basic_ops.py'],1,8dc0357f86bf229468639dd4a6cc1ff9b98bc648,,"# Copyright 2013 IBM Corp. # All Rights Reserved. # # Licensed under the Apache License, Version 2.0 (the ""License""); you may # not use this file except in compliance with the License. You may obtain # a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT # WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the # License for the specific language governing permissions and limitations # under the License. from tempest.common import tempest_fixtures as fixtures from tempest.common.utils.data_utils import rand_name from tempest.openstack.common import log as logging from tempest.scenario import manager from tempest import test LOG = logging.getLogger(__name__) class TestAggregatesBasicOps(manager.OfficialClientTest): """""" Creates an aggregate within an availability zone Adds a host to the aggregate Checks aggregate details Updates aggregate's name Removes host from aggregate Deletes aggregate """""" @classmethod def credentials(cls): username = cls.config.identity.admin_username password = cls.config.identity.admin_password tenant_name = cls.config.identity.tenant_name return username, tenant_name, password def _create_aggregate(self, **kwargs): aggregate = self.compute_client.aggregates.create(**kwargs) aggregate_name = kwargs['name'] availability_zone = kwargs['availability_zone'] self.assertEqual(aggregate.name, aggregate_name) self.assertEqual(aggregate.availability_zone, availability_zone) self.set_resource(aggregate.id, aggregate) LOG.debug(""Aggregate %s created."" % (aggregate.name)) return aggregate def _delete_aggregate(self, aggregate): self.compute_client.aggregates.delete(aggregate.id) self.remove_resource(aggregate.id) LOG.debug(""Aggregate %s deleted. "" % (aggregate.name)) def _get_host_name(self): hosts = self.compute_client.hosts.list() self.assertTrue(len(hosts) >= 1) hostname = hosts[0].host_name return hostname def _add_host(self, aggregate_name, host): aggregate = self.compute_client.aggregates.add_host(aggregate_name, host) self.assertIn(host, aggregate.hosts) LOG.debug(""Host %s added to Aggregate %s."" % (host, aggregate.name)) def _remove_host(self, aggregate_name, host): aggregate = self.compute_client.aggregates.remove_host(aggregate_name, host) self.assertNotIn(host, aggregate.hosts) LOG.debug(""Host %s removed to Aggregate %s."" % (host, aggregate.name)) def _check_aggregate_details(self, aggregate, aggregate_name, azone, hosts, metadata): aggregate = self.compute_client.aggregates.get(aggregate.id) self.assertEqual(aggregate_name, aggregate.name) self.assertEqual(azone, aggregate.availability_zone) self.assertEqual(aggregate.hosts, hosts) for meta_key in metadata.keys(): self.assertIn(meta_key, aggregate.metadata) self.assertEqual(metadata[meta_key], aggregate.metadata[meta_key]) LOG.debug(""Aggregate %s details match."" % aggregate.name) def _set_aggregate_metadata(self, aggregate, meta): aggregate = self.compute_client.aggregates.set_metadata(aggregate.id, meta) for key, value in meta.items(): self.assertEqual(meta[key], aggregate.metadata[key]) LOG.debug(""Aggregate %s metadata updated successfully."" % aggregate.name) def _update_aggregate(self, aggregate, aggregate_name, availability_zone): values = {} if aggregate_name: values.update({'name': aggregate_name}) if availability_zone: values.update({'availability_zone': availability_zone}) if values.keys(): aggregate = self.compute_client.aggregates.update(aggregate.id, values) for key, values in values.items(): self.assertEqual(getattr(aggregate, key), values) return aggregate @test.services('compute') def test_aggregate_basic_ops(self): self.useFixture(fixtures.LockFixture('availability_zone')) az = 'foo_zone' aggregate_name = rand_name('aggregate-scenario') aggregate = self._create_aggregate(name=aggregate_name, availability_zone=az) metadata = {'meta_key': 'meta_value'} self._set_aggregate_metadata(aggregate, metadata) host = self._get_host_name() self._add_host(aggregate, host) self._check_aggregate_details(aggregate, aggregate_name, az, [host], metadata) aggregate_name = rand_name('renamed-aggregate-scenario') aggregate = self._update_aggregate(aggregate, aggregate_name, None) additional_metadata = {'foo': 'bar'} self._set_aggregate_metadata(aggregate, additional_metadata) metadata.update(additional_metadata) self._check_aggregate_details(aggregate, aggregate.name, az, [host], metadata) self._remove_host(aggregate, host) self._delete_aggregate(aggregate) ",,137,0
openstack%2Fheat~master~I0e02174c43be65a647358a2047da8213635f85d8,openstack/heat,master,I0e02174c43be65a647358a2047da8213635f85d8,Return None when get_attr cannot resolve a value,MERGED,2014-03-03 22:22:04.000000000,2014-03-05 23:47:01.000000000,2014-03-05 23:47:00.000000000,"[{'_account_id': 3}, {'_account_id': 3098}, {'_account_id': 4257}, {'_account_id': 6577}, {'_account_id': 7230}, {'_account_id': 7253}, {'_account_id': 7256}, {'_account_id': 7395}, {'_account_id': 9189}]","[{'number': 1, 'created': '2014-03-03 22:22:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/57231825335c8142e47d47b0b11e82ff5f500c55', 'message': 'Return None when get_attr cannot resolve a value\n\nTo prevent validation failures prior to resource creation, get_attr\nreturns None if the attribute or the sub-value cannot be resolved.\nThis returns this function to consistency with prior behavior and allows\nnon-string attribute values to be resolved to their proper default\n""empty"" data types during initial template validation.\n\nChange-Id: I0e02174c43be65a647358a2047da8213635f85d8\nCloses-Bug: 1287397\n'}, {'number': 2, 'created': '2014-03-04 00:02:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/e83522af9b927f6b66a91c995662538a847c09d7', 'message': 'Return None when get_attr cannot resolve a value\n\nTo prevent validation failures prior to resource creation, get_attr\nreturns None if the attribute or the sub-value cannot be resolved.\nThis returns this function to consistency with prior behavior and allows\nnon-string attribute values to be resolved to their proper default\n""empty"" data types during initial template validation.\n\nChange-Id: I0e02174c43be65a647358a2047da8213635f85d8\nCloses-Bug: 1287397\n'}, {'number': 3, 'created': '2014-03-04 18:27:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/ad7a202ed8184ccd3f64d666b300b05f072887df', 'message': 'Return None when get_attr cannot resolve a value\n\nTo prevent validation failures prior to resource creation, get_attr\nreturns None if the attribute or the sub-value cannot be resolved.\nThis returns this function to consistency with prior behavior and allows\nnon-string attribute values to be resolved to their proper default\n""empty"" data types during initial template validation.\n\nChange-Id: I0e02174c43be65a647358a2047da8213635f85d8\nCloses-Bug: 1287397\n'}, {'number': 4, 'created': '2014-03-04 19:35:47.000000000', 'files': ['heat/engine/hot/functions.py', 'heat/tests/generic_resource.py', 'heat/tests/test_hot.py'], 'web_link': 'https://opendev.org/openstack/heat/commit/f5fcfb45cfc79405e5cc5628047720ac0ce418a8', 'message': 'Return None when get_attr cannot resolve a value\n\nTo prevent validation failures prior to resource creation, get_attr\nreturns None if the attribute or the sub-value cannot be resolved.\nThis returns this function to consistency with prior behavior and allows\nnon-string attribute values to be resolved to their proper default\n""empty"" data types during initial template validation.\n\nChange-Id: I0e02174c43be65a647358a2047da8213635f85d8\nCloses-Bug: 1287397\n'}]",7,77713,f5fcfb45cfc79405e5cc5628047720ac0ce418a8,37,9,4,7256,,,0,"Return None when get_attr cannot resolve a value

To prevent validation failures prior to resource creation, get_attr
returns None if the attribute or the sub-value cannot be resolved.
This returns this function to consistency with prior behavior and allows
non-string attribute values to be resolved to their proper default
""empty"" data types during initial template validation.

Change-Id: I0e02174c43be65a647358a2047da8213635f85d8
Closes-Bug: 1287397
",git fetch https://review.opendev.org/openstack/heat refs/changes/13/77713/2 && git format-patch -1 --stdout FETCH_HEAD,"['heat/engine/hot/functions.py', 'heat/tests/test_hot.py']",2,57231825335c8142e47d47b0b11e82ff5f500c55,bug/1287397, expected={'Value': None})), expected={'Value': ''})),3,3
openstack%2Fopenstack-manuals~master~I6568a961a667fad1ddefe7322d833837693457ba,openstack/openstack-manuals,master,I6568a961a667fad1ddefe7322d833837693457ba,Fix whitespace issues,MERGED,2014-03-05 21:01:59.000000000,2014-03-05 23:33:50.000000000,2014-03-05 23:33:49.000000000,"[{'_account_id': 3}, {'_account_id': 7923}, {'_account_id': 9515}]","[{'number': 1, 'created': '2014-03-05 21:01:59.000000000', 'files': ['doc/training-guides/module003-ch004-swift-building-blocks.xml', 'doc/config-reference/compute/section_hypervisor_vmware.xml'], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/adb67fede21675831ca3f0fa59081256a6f2b83d', 'message': 'Fix whitespace issues\n\nRemove extra space and tabs.\n\nChange-Id: I6568a961a667fad1ddefe7322d833837693457ba\n'}]",0,78415,adb67fede21675831ca3f0fa59081256a6f2b83d,7,3,1,6547,,,0,"Fix whitespace issues

Remove extra space and tabs.

Change-Id: I6568a961a667fad1ddefe7322d833837693457ba
",git fetch https://review.opendev.org/openstack/openstack-manuals refs/changes/15/78415/1 && git format-patch -1 --stdout FETCH_HEAD,"['doc/training-guides/module003-ch004-swift-building-blocks.xml', 'doc/config-reference/compute/section_hypervisor_vmware.xml']",2,adb67fede21675831ca3f0fa59081256a6f2b83d,niceness, name as the <literal>vmware.integration_bridge</literal>, name as the <literal>vmware.integration_bridge</literal> ,4,4
openstack%2Fsolum~master~I2d852640cf184cc1aec15da55e96e24f1e8f3f48,openstack/solum,master,I2d852640cf184cc1aec15da55e96e24f1e8f3f48,Add CRUD functionnal tests to plan,MERGED,2014-03-01 00:09:49.000000000,2014-03-05 23:00:06.000000000,2014-03-05 23:00:06.000000000,"[{'_account_id': 3}, {'_account_id': 668}, {'_account_id': 2506}, {'_account_id': 4715}, {'_account_id': 8334}, {'_account_id': 8443}, {'_account_id': 9095}, {'_account_id': 9537}, {'_account_id': 9548}]","[{'number': 1, 'created': '2014-03-01 00:09:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/solum/commit/dc9ffd15f99583c737945ada6ff324d627897c22', 'message': 'Add CRUD functionnal tests to plan\n\nChange-Id: I2d852640cf184cc1aec15da55e96e24f1e8f3f48\n'}, {'number': 2, 'created': '2014-03-03 12:16:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/solum/commit/265f3af6074f7d752cb9fb1d127188b8c5c3bf2a', 'message': 'Add CRUD functionnal tests to plan\n\nChange-Id: I2d852640cf184cc1aec15da55e96e24f1e8f3f48\n'}, {'number': 3, 'created': '2014-03-03 13:52:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/solum/commit/3f081db9807a6b6195dd417d76996916e0079fc9', 'message': 'Add CRUD functionnal tests to plan\n\nChange-Id: I2d852640cf184cc1aec15da55e96e24f1e8f3f48\n'}, {'number': 4, 'created': '2014-03-04 15:27:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/solum/commit/d8f546053fdc37e02c9df3ec148864fe1384d54d', 'message': 'Add CRUD functionnal tests to plan\n\nChange-Id: I2d852640cf184cc1aec15da55e96e24f1e8f3f48\n'}, {'number': 5, 'created': '2014-03-04 16:56:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/solum/commit/2112b04cfef129aa80dd5aee94e0d7b086e81261', 'message': 'Add CRUD functionnal tests to plan\n\nChange-Id: I2d852640cf184cc1aec15da55e96e24f1e8f3f48\n'}, {'number': 6, 'created': '2014-03-05 16:09:43.000000000', 'files': ['functionaltests/api/v1/test_plan.py'], 'web_link': 'https://opendev.org/openstack/solum/commit/e0e615b4d87111d7efbaa390525293e3385b3660', 'message': 'Add CRUD functionnal tests to plan\n\nChange-Id: I2d852640cf184cc1aec15da55e96e24f1e8f3f48\n'}]",2,77303,e0e615b4d87111d7efbaa390525293e3385b3660,32,9,6,9537,,,0,"Add CRUD functionnal tests to plan

Change-Id: I2d852640cf184cc1aec15da55e96e24f1e8f3f48
",git fetch https://review.opendev.org/openstack/solum refs/changes/03/77303/4 && git format-patch -1 --stdout FETCH_HEAD,['functionaltests/api/v1/test_plan.py'],1,dc9ffd15f99583c737945ada6ff324d627897c22,functionaltests/component,"sample_data = {""name"": ""test_plan"", ""description"": ""A test to create plan"", ""project_id"": ""project_id"", ""user_id"": ""user_id""} def _assert_output_expected(self, body_data, data): self.assertEqual(body_data['user_id'], data['user_id']) self.assertEqual(body_data['project_id'], data['project_id']) #TODO(julienvey) description is missing in the db, add assertion later self.assertEqual(body_data['name'], data['name']) self.assertIsNotNone(body_data['uuid']) def _delete_plan(self, uuid): resp, _ = self.client.delete('v1/plans/%s' % uuid) self.assertEqual(resp.status, 204) def _create_plan(self): jsondata = json.dumps(sample_data) resp, body = self.client.post('v1/plans', jsondata) self.assertEqual(resp.status, 201) out_data = json.loads(body) uuid = out_data['uuid'] self.assertIsNotNone(uuid) return uuid def test_plans_create(self): sample_json = json.dumps(sample_data) resp, body = self.client.post('v1/plans', sample_json) self.assertEqual(resp.status, 201) json_data = json.loads(body) self._assert_output_expected(json_data, sample_data) self._delete_plan(json_data['uuid']) def test_plans_get(self): uuid = self._create_plan() resp, body = self.client.get('v1/plans/%s' % uuid) self.assertEqual(resp.status, 200) json_data = json.loads(body) self._assert_output_expected(json_data, sample_data) self._delete_plan(uuid) def test_plans_put(self): uuid = self._create_plan() updated_data = {""name"": ""test_plan updated"", ""description"": ""A test to create plan updated"", ""project_id"": ""project_id updated"", ""user_id"": ""user_id updated""} updated_json = json.dumps(updated_data) resp, body = self.client.put('v1/plans/%s' % uuid, updated_json) self.assertEqual(resp.status, 200) json_data = json.loads(body) self._assert_output_expected(json_data, updated_data) self._delete_plan(uuid) def test_plans_delete(self): uuid = self._create_plan() resp, body = self.client.delete('v1/plans/%s' % uuid) self.assertEqual(resp.status, 204) self.assertEqual(body, '')",,60,0
openstack%2Fneutron~master~Ifde13323b1435fc84c6cb24ab6a71de5d67f6b9f,openstack/neutron,master,Ifde13323b1435fc84c6cb24ab6a71de5d67f6b9f,Reset the policy after loading extensions,MERGED,2014-02-16 09:37:03.000000000,2014-03-05 22:40:18.000000000,2014-03-05 22:40:17.000000000,"[{'_account_id': 3}, {'_account_id': 261}, {'_account_id': 841}, {'_account_id': 2592}, {'_account_id': 2711}, {'_account_id': 4460}, {'_account_id': 6072}, {'_account_id': 6953}, {'_account_id': 9681}, {'_account_id': 9682}, {'_account_id': 9732}, {'_account_id': 9787}, {'_account_id': 9845}, {'_account_id': 9925}, {'_account_id': 10117}, {'_account_id': 10119}, {'_account_id': 10153}, {'_account_id': 10184}, {'_account_id': 10192}]","[{'number': 1, 'created': '2014-02-16 09:37:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/2f049745fefd58339c37c327345649f5524a3abe', 'message': 'Reset the policy after loading extensions\n\nThe loading of extensions might impact how rules are interpreted in the\npolicies; for instance, the external-net extension specifies how to\nconvert the router:external field of a network (to a boolean). So we\nneed to make sure that the policy is recreated afterwards.\n\nChange-Id: Ifde13323b1435fc84c6cb24ab6a71de5d67f6b9f\nCloses-Bug: lp#1280738\n'}, {'number': 2, 'created': '2014-02-17 08:28:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/6037abda016799ae3d8c97f8572f3df802eb3274', 'message': 'Reset the policy after loading extensions\n\nThe loading of extensions might impact how rules are interpreted in the\npolicies; for instance, the external-net extension specifies how to\nconvert the router:external field of a network (to a boolean). So we\nneed to make sure that the policy is recreated afterwards.\n\nChange-Id: Ifde13323b1435fc84c6cb24ab6a71de5d67f6b9f\nCloses-Bug: #1280738\n'}, {'number': 3, 'created': '2014-02-17 21:14:31.000000000', 'files': ['neutron/api/extensions.py', 'neutron/tests/unit/test_api_v2.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/d8f8d3af706ded5d6d16fc86e0de89f5c7db581c', 'message': 'Reset the policy after loading extensions\n\nThe loading of extensions might impact how rules are interpreted in the\npolicies; for instance, the external-net extension specifies how to\nconvert the router:external field of a network (to a boolean). So we\nneed to make sure that the policy is recreated afterwards.\n\nWe also need to fix a unit test that assumes that the policy is loaded.\n\nChange-Id: Ifde13323b1435fc84c6cb24ab6a71de5d67f6b9f\nCloses-Bug: #1280738\n'}]",1,73866,d8f8d3af706ded5d6d16fc86e0de89f5c7db581c,65,19,3,4460,,,0,"Reset the policy after loading extensions

The loading of extensions might impact how rules are interpreted in the
policies; for instance, the external-net extension specifies how to
convert the router:external field of a network (to a boolean). So we
need to make sure that the policy is recreated afterwards.

We also need to fix a unit test that assumes that the policy is loaded.

Change-Id: Ifde13323b1435fc84c6cb24ab6a71de5d67f6b9f
Closes-Bug: #1280738
",git fetch https://review.opendev.org/openstack/neutron refs/changes/66/73866/3 && git format-patch -1 --stdout FETCH_HEAD,['neutron/api/extensions.py'],1,2f049745fefd58339c37c327345649f5524a3abe,reset-policy-after-extensions-master,from neutron import policy policy.reset(),,2,0
openstack%2Fhorizon~master~Iaa509fbdeacb83c97f5073c44d63f8ac0f520c96,openstack/horizon,master,Iaa509fbdeacb83c97f5073c44d63f8ac0f520c96,Sort with 1st column by default,ABANDONED,2012-12-25 11:26:41.000000000,2014-03-05 22:31:33.000000000,,"[{'_account_id': 3}, {'_account_id': 2230}, {'_account_id': 2455}, {'_account_id': 5689}, {'_account_id': 9576}]","[{'number': 1, 'created': '2012-12-25 11:26:41.000000000', 'files': ['horizon/static/horizon/js/horizon.tables.js'], 'web_link': 'https://opendev.org/openstack/horizon/commit/15b975ece0643e858216fdb84bf1e861083cdfdd', 'message': ""Sort with 1st column by default\n\nHorizon's table list order is random now. This is difficult to identify\na data for human. So this patch sort with 1st column by default.\n\nFixes bug 1093623\n\nChange-Id: Iaa509fbdeacb83c97f5073c44d63f8ac0f520c96\n""}]",0,18643,15b975ece0643e858216fdb84bf1e861083cdfdd,6,5,1,5689,,,0,"Sort with 1st column by default

Horizon's table list order is random now. This is difficult to identify
a data for human. So this patch sort with 1st column by default.

Fixes bug 1093623

Change-Id: Iaa509fbdeacb83c97f5073c44d63f8ac0f520c96
",git fetch https://review.opendev.org/openstack/horizon refs/changes/43/18643/1 && git format-patch -1 --stdout FETCH_HEAD,['horizon/static/horizon/js/horizon.tables.js'],1,15b975ece0643e858216fdb84bf1e861083cdfdd,bug/1093623," header_options = {}, sort_col_idx_set = false; sort_col_idx = 0; if (!sort_col_idx_set && $th.hasClass('sortable') && !$th.hasClass('hide')) { sort_col_idx = i - 1; sort_col_idx_set = true } else if (!$th.hasClass('sortable')) { sortList: [[sort_col_idx, 0]],", header_options = {}; if (!$th.hasClass('sortable')) {,8,2
openstack%2Foslo-incubator~master~I9e7a6748a95fe75bde8dfc8e0df59b2a9492454c,openstack/oslo-incubator,master,I9e7a6748a95fe75bde8dfc8e0df59b2a9492454c,Add -p to check_uptodate.sh help text,ABANDONED,2014-03-05 21:35:18.000000000,2014-03-05 22:27:10.000000000,,"[{'_account_id': 3}, {'_account_id': 6928}]","[{'number': 1, 'created': '2014-03-05 21:35:18.000000000', 'files': ['tools/config/check_uptodate.sh'], 'web_link': 'https://opendev.org/openstack/oslo-incubator/commit/4b24b3ce77169e7ca70055b68b4d84826866b51f', 'message': ""Add -p to check_uptodate.sh help text\n\nThe help text for check_uptodate.sh doesn't\nindicate that you need to do -p <project name> .\nNow that that appears to be a required argument, I\nam adding it to the help text.\n\nChange-Id: I9e7a6748a95fe75bde8dfc8e0df59b2a9492454c\nCloses-bug: 1288417\n""}]",0,78422,4b24b3ce77169e7ca70055b68b4d84826866b51f,3,2,1,7198,,,0,"Add -p to check_uptodate.sh help text

The help text for check_uptodate.sh doesn't
indicate that you need to do -p <project name> .
Now that that appears to be a required argument, I
am adding it to the help text.

Change-Id: I9e7a6748a95fe75bde8dfc8e0df59b2a9492454c
Closes-bug: 1288417
",git fetch https://review.opendev.org/openstack/oslo-incubator refs/changes/22/78422/1 && git format-patch -1 --stdout FETCH_HEAD,['tools/config/check_uptodate.sh'],1,4b24b3ce77169e7ca70055b68b4d84826866b51f,bug/1288417," echo ""${0##*/}: Please run ${0%%${0##*/}}generate_sample.sh -p ${PROJECT_NAME}."""," echo ""${0##*/}: Please run ${0%%${0##*/}}generate_sample.sh.""",1,1
openstack%2Fsolum~master~I94491e72514d53745da98c0dfb4b09f295e196d9,openstack/solum,master,I94491e72514d53745da98c0dfb4b09f295e196d9,inject slug into vm-image during build,MERGED,2014-03-03 19:49:05.000000000,2014-03-05 22:03:46.000000000,2014-03-05 22:03:45.000000000,"[{'_account_id': 3}, {'_account_id': 668}, {'_account_id': 2506}, {'_account_id': 4715}, {'_account_id': 7858}, {'_account_id': 8443}, {'_account_id': 9113}]","[{'number': 1, 'created': '2014-03-03 19:49:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/solum/commit/971dc322313a6d70f5d8267d3d62be4c20e77f60', 'message': 'WIP: inject slug into vm-image during build\n\nChange-Id: I94491e72514d53745da98c0dfb4b09f295e196d9\n'}, {'number': 2, 'created': '2014-03-04 19:58:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/solum/commit/756cdc91c0ff91fe34a8f1b18d1ba9e71d11bb07', 'message': 'WIP: inject slug into vm-image during build\n\nChange-Id: I94491e72514d53745da98c0dfb4b09f295e196d9\n'}, {'number': 3, 'created': '2014-03-04 20:38:19.000000000', 'files': ['contrib/lp-cedarish/vm-slug/build-slug', 'contrib/lp-cedarish/vm-slug/prepare', 'contrib/lp-cedarish/vm-slug/build-app', 'contrib/lp-cedarish/docker/prepare', 'contrib/lp-cedarish/vm-slug/download-cedarish'], 'web_link': 'https://opendev.org/openstack/solum/commit/b15aba6b7b368155ae4ca964c8ad03c1b640f565', 'message': 'inject slug into vm-image during build\n\nChange-Id: I94491e72514d53745da98c0dfb4b09f295e196d9\n'}]",11,77682,b15aba6b7b368155ae4ca964c8ad03c1b640f565,19,7,3,7858,,,0,"inject slug into vm-image during build

Change-Id: I94491e72514d53745da98c0dfb4b09f295e196d9
",git fetch https://review.opendev.org/openstack/solum refs/changes/82/77682/2 && git format-patch -1 --stdout FETCH_HEAD,"['contrib/lp-cedarish/vm-slug/build-slug', 'contrib/lp-cedarish/vm-slug/prepare', 'contrib/lp-cedarish/vm-slug/build-app', 'contrib/lp-cedarish/docker/prepare', 'contrib/lp-cedarish/vm-slug/download-cedarish']",5,971dc322313a6d70f5d8267d3d62be4c20e77f60,feature/inject-slug-into-vm,#glance image-list 2> /dev/null > /dev/null #if [[ $? == 0 ]]; then # echo it would appear I know how to talk to glance # echo therefore I will attempt to upload your image # glance image-delete cedarish # glance image-create --name cedarish --disk-format qcow2 --container-format bare --file $IMAGE_DIR/cedarish.qcow2 #else # echo I cannot talk to glance your image is here: $IMAGE_DIR/$ID.qcow2 # echo Try this: glance image-create --name cedarish --disk-format qcow2 --container-format bare --file $IMAGE_DIR/cedarish.qcow2 # exit 1 #fi,glance image-list 2> /dev/null > /dev/null if [[ $? == 0 ]]; then echo it would appear I know how to talk to glance echo therefore I will attempt to upload your image glance image-delete cedarish glance image-create --name cedarish --disk-format qcow2 --container-format bare --file $IMAGE_DIR/cedarish.qcow2 else echo I cannot talk to glance your image is here: $IMAGE_DIR/$ID.qcow2 echo Try this: glance image-create --name cedarish --disk-format qcow2 --container-format bare --file $IMAGE_DIR/cedarish.qcow2 exit 1 fi,47,94
openstack%2Fironic~master~I28eac0c9e49b1568342a65eb4424dae0149e94a1,openstack/ironic,master,I28eac0c9e49b1568342a65eb4424dae0149e94a1,Fix leaking DB details to API on error,ABANDONED,2014-03-05 21:58:41.000000000,2014-03-05 21:59:51.000000000,,[{'_account_id': 3}],"[{'number': 1, 'created': '2014-03-05 21:58:41.000000000', 'files': ['ironic/api/controllers/v1/port.py', 'ironic/tests/api/test_nodes.py', 'ironic/common/exception.py', 'ironic/api/controllers/v1/chassis.py', 'ironic/tests/api/test_ports.py', 'ironic/tests/api/test_chassis.py', 'ironic/api/controllers/v1/node.py'], 'web_link': 'https://opendev.org/openstack/ironic/commit/111535e8f121a6c0d6142e92cfe2a6b7ab3caa23', 'message': ""Fix leaking DB details to API on error\n\nMost of the DB exceptions contain DB details which aren't caught by the\ntraceback hook. The cleanest way to ensure the proper error codes and\nmessages are being sent is to catch the DBErrors and wrap them as\nIronicExceptions. This patch will show the DB details if debug is enabled,\nbut hides them behind a generic message if debug is False.\n\nChange-Id: I28eac0c9e49b1568342a65eb4424dae0149e94a1\nPartial-Bug: #1277555\n""}]",0,78431,111535e8f121a6c0d6142e92cfe2a6b7ab3caa23,2,1,1,10380,,,0,"Fix leaking DB details to API on error

Most of the DB exceptions contain DB details which aren't caught by the
traceback hook. The cleanest way to ensure the proper error codes and
messages are being sent is to catch the DBErrors and wrap them as
IronicExceptions. This patch will show the DB details if debug is enabled,
but hides them behind a generic message if debug is False.

Change-Id: I28eac0c9e49b1568342a65eb4424dae0149e94a1
Partial-Bug: #1277555
",git fetch https://review.opendev.org/openstack/ironic refs/changes/31/78431/1 && git format-patch -1 --stdout FETCH_HEAD,"['ironic/api/controllers/v1/port.py', 'ironic/tests/api/test_nodes.py', 'ironic/common/exception.py', 'ironic/api/controllers/v1/chassis.py', 'ironic/tests/api/test_chassis.py', 'ironic/tests/api/test_ports.py', 'ironic/api/controllers/v1/node.py']",7,111535e8f121a6c0d6142e92cfe2a6b7ab3caa23,bug/1277555,from ironic.openstack.common.db import exception as db_exceptions except db_exceptions.DBError as e: with excutils.save_and_reraise_exception(): exc = exception.IronicDBError(e) LOG.exception(exc) raise exc,,95,0
openstack%2Fpuppet-neutron~master~I174cf06b9e8355bfe499b23f390d4078dc670e72,openstack/puppet-neutron,master,I174cf06b9e8355bfe499b23f390d4078dc670e72,Fix FWaaS race condition,MERGED,2014-03-04 07:08:38.000000000,2014-03-05 21:59:01.000000000,2014-03-05 21:59:01.000000000,"[{'_account_id': 3}, {'_account_id': 1269}, {'_account_id': 2652}, {'_account_id': 3153}, {'_account_id': 6754}, {'_account_id': 6967}, {'_account_id': 6994}, {'_account_id': 7822}]","[{'number': 1, 'created': '2014-03-04 07:08:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-neutron/commit/d87729cc25d8ff058b087270189df74118f14043', 'message': ""Fix FWaaS race condition\n\nThe current FWaaS manifest suffers from a race condition: it may\nattempt to configure the FWaaS service before the Neutron L3 agent\npackage on which it depends has been installed, and before the\n/etc/neutron directory exists.  This leads to errors on the first\ncatalog run, and the FWaaS service doesn't start.  The errors\ngo away on the second catalog run since by then the requisite\ndirectory exists.  This patch adds ordering such that the L3\nagent package gets installed before the FWaaS service is configured.\n\nChange-Id: I174cf06b9e8355bfe499b23f390d4078dc670e72\nCloses-Bug: #1287554\n""}, {'number': 2, 'created': '2014-03-04 07:48:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-neutron/commit/ac468ee8cc05a92464a610ef6686691070c018d9', 'message': ""Fix FWaaS race condition\n\nThe current FWaaS manifest suffers from a race condition: it may\nattempt to configure the FWaaS service before the Neutron packages\non which it depends has been installed, and before the\n/etc/neutron directory exists.  This leads to errors on the first\ncatalog run, and the FWaaS service doesn't start.  The errors\ngo away on the second catalog run since by then the requisite\ndirectory exists.  This patch adds ordering such that the packages\non which the FWaaS service relies are installed before the FWaaS\nservice is configured.\n\nChange-Id: I174cf06b9e8355bfe499b23f390d4078dc670e72\nCloses-Bug: #1287554\n""}, {'number': 3, 'created': '2014-03-04 07:48:44.000000000', 'files': ['spec/classes/neutron_services_fwaas_spec.rb', 'manifests/services/fwaas.pp'], 'web_link': 'https://opendev.org/openstack/puppet-neutron/commit/cfedc81cb60cabdbb31f3809e9d56a54d771458b', 'message': ""Fix FWaaS race condition\n\nThe current FWaaS manifest suffers from a race condition: it may\nattempt to configure the FWaaS service before the Neutron packages\non which it depends has been installed, and before the\n/etc/neutron directory exists.  This leads to errors on the first\ncatalog run, and the FWaaS service doesn't start.  The errors\ngo away on the second catalog run since by then the requisite\ndirectory exists.  This patch adds ordering such that the packages\non which the FWaaS service relies are installed before the FWaaS\nservice is configured.\n\nChange-Id: I174cf06b9e8355bfe499b23f390d4078dc670e72\nCloses-Bug: #1287554\n""}]",0,77805,cfedc81cb60cabdbb31f3809e9d56a54d771458b,16,8,3,6754,,,0,"Fix FWaaS race condition

The current FWaaS manifest suffers from a race condition: it may
attempt to configure the FWaaS service before the Neutron packages
on which it depends has been installed, and before the
/etc/neutron directory exists.  This leads to errors on the first
catalog run, and the FWaaS service doesn't start.  The errors
go away on the second catalog run since by then the requisite
directory exists.  This patch adds ordering such that the packages
on which the FWaaS service relies are installed before the FWaaS
service is configured.

Change-Id: I174cf06b9e8355bfe499b23f390d4078dc670e72
Closes-Bug: #1287554
",git fetch https://review.opendev.org/openstack/puppet-neutron refs/changes/05/77805/2 && git format-patch -1 --stdout FETCH_HEAD,['manifests/services/fwaas.pp'],1,d87729cc25d8ff058b087270189df74118f14043,bugs/1287554," include neutron::params Package[$::neutron::params::l3_agent_package] -> Neutron_fwaas_service_config<||> ensure_resource( 'package', $::neutron::params::l3_agent_package, { 'ensure' => $neutron::package_ensure }) ",,7,0
openstack%2Fpuppet-keystone~master~Ib14edf152c1d208418f101ed48cdc38b18f840a2,openstack/puppet-keystone,master,Ib14edf152c1d208418f101ed48cdc38b18f840a2,Don't set keystone endpoint by default,MERGED,2014-03-04 04:43:04.000000000,2014-03-05 21:52:30.000000000,2014-03-05 21:52:30.000000000,"[{'_account_id': 3}, {'_account_id': 3153}, {'_account_id': 6754}, {'_account_id': 6967}, {'_account_id': 6994}, {'_account_id': 7156}, {'_account_id': 7822}, {'_account_id': 9978}]","[{'number': 1, 'created': '2014-03-04 04:43:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-keystone/commit/99f10d54a7fb372fb7392666ead421db42c0a070', 'message': 'Use versioned keystone endpoint\n\nIn the current version of the keystone::init class, the default\nvalues for keystone endpoint URLs are unversioned, which can lead\nto problems connecting to the endpoint.  This patch makes a\nversioned endpoint the default value and updates tests accordingly.\nIt also updates the documentation in the header accordingly and\ntidies it up a bit.\n\nChange-Id: Ib14edf152c1d208418f101ed48cdc38b18f840a2\nCloses-Bug: #1287520\n'}, {'number': 2, 'created': '2014-03-04 04:44:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-keystone/commit/81a48394c267e3efb68e5f4da5d0e6b587f095c3', 'message': 'Use versioned keystone endpoint\n\nIn the current version of the keystone::init class, the default\nvalues for keystone endpoint URLs are unversioned, which can lead\nto problems connecting to the endpoint.  This patch makes a\nversioned endpoint the default value and updates tests accordingly.\nIt also updates the documentation in the header accordingly and\ntidies it up a bit.\n\nChange-Id: Ib14edf152c1d208418f101ed48cdc38b18f840a2\nCloses-Bug: #1287520\n'}, {'number': 3, 'created': '2014-03-04 19:55:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-keystone/commit/81ccb7883b63473210db5aba4e092c14e8de5116', 'message': ""Don't set keystone endpoint by default\n\nIn the current version of the keystone::init class, the default\nvalues for keystone endpoint URLs are unversioned, which can lead\nto problems connecting to the endpoint.  This patch reverts to\nthe old behavior of not setting them at all by default, and includes\nsample values with versioned URL's both in the header and tests\nso that users know to use versioned URL's if they choose to\noverride the defaults.  It also updates the documentation in the\nheader accordingly and tidies it up a bit.\n\nChange-Id: Ib14edf152c1d208418f101ed48cdc38b18f840a2\nCloses-Bug: #1287520\n""}, {'number': 4, 'created': '2014-03-04 19:56:46.000000000', 'files': ['spec/classes/keystone_spec.rb', 'manifests/init.pp'], 'web_link': 'https://opendev.org/openstack/puppet-keystone/commit/b72da2814d67ff4cdb90cfef47c6319e9137c9c1', 'message': ""Don't set keystone endpoint by default\n\nIn the current version of the keystone::init class, the default\nvalues for keystone endpoint URLs are unversioned, which can lead\nto problems connecting to the endpoint.  This patch reverts to\nthe old behavior of not setting them at all by default, and includes\nsample values with versioned URL's both in the header and tests\nso that users know to use versioned URL's if they choose to\noverride the defaults.  It also updates the documentation in the\nheader accordingly and tidies it up a bit.\n\nChange-Id: Ib14edf152c1d208418f101ed48cdc38b18f840a2\nCloses-Bug: #1287520\n""}]",0,77785,b72da2814d67ff4cdb90cfef47c6319e9137c9c1,20,8,4,6754,,,0,"Don't set keystone endpoint by default

In the current version of the keystone::init class, the default
values for keystone endpoint URLs are unversioned, which can lead
to problems connecting to the endpoint.  This patch reverts to
the old behavior of not setting them at all by default, and includes
sample values with versioned URL's both in the header and tests
so that users know to use versioned URL's if they choose to
override the defaults.  It also updates the documentation in the
header accordingly and tidies it up a bit.

Change-Id: Ib14edf152c1d208418f101ed48cdc38b18f840a2
Closes-Bug: #1287520
",git fetch https://review.opendev.org/openstack/puppet-keystone refs/changes/85/77785/4 && git format-patch -1 --stdout FETCH_HEAD,"['spec/classes/keystone_spec.rb', 'manifests/init.pp']",2,99f10d54a7fb372fb7392666ead421db42c0a070,,"# [*public_endpoint*] # (optional) The base public endpoint URL for keystone that are # advertised to clients (NOTE: this does NOT affect how # keystone listens for connections) (string value) # Defaults to 'http://localhost:5000/v2.0' # # [*admin_endpoint*] # (optional) The base admin endpoint URL for keystone that are # advertised to clients (NOTE: this does NOT affect how keystone listens # for connections) (string value) # Defaults to 'http://localhost:35357/v2.0' # # [*enable_ssl*] # (optional) Toggle for SSL support on the keystone eventlet servers.# Defaults to false # # [*ssl_certfile*] # (optional) Path of the certfile for SSL. (string value) # Defaults to '/etc/keystone/ssl/certs/keystone.pem' # # [*ssl_keyfile*] # (optional) Path of the keyfile for SSL. (string value) # Defaults to '/etc/keystone/ssl/private/keystonekey.pem' # # [*ssl_ca_certs*] # (optional) Path of the ca cert file for SSL. (string value) # Defaults to '/etc/keystone/ssl/certs/ca.pem' # # [*ssl_ca_key*] # (optional) Path of the CA key file for SSL (string value) # Defaults to '/etc/keystone/ssl/private/cakey.pem' # # [*ssl_cert_subject*] # (optional) SSL Certificate Subject (auto generated certificate) # (string value) # Defaults to '/C=US/ST=Unset/L=Unset/O=Unset/CN=localhost' $public_endpoint = 'http://localhost:5000/v2.0/', $admin_endpoint = 'http://localhost:35357/v2.0/',","# [public_endpoint] The base public endpoint URL for keystone that are # advertised to clients (NOTE: this does NOT affect how # keystone listens for connections) (string value) # [admin_endpoint] The base admin endpoint URL for keystone that are advertised # to clients (NOTE: this does NOT affect how keystone listens # for connections) (string value) # [ssl_enable] Toggle for SSL support on the keystone eventlet servers.# [certfile] Path of the certfile for SSL. (string value) # [keyfile] Path of the keyfile for SSL. (string value) # [ca_certs] Path of the ca cert file for SSL. (string value) # [ca_key] Path of the CA key file for SSL (string value) # [cert_subject] SSL Certificate Subject (auto generated certificate) (string value) $public_endpoint = 'http://localhost:5000', $admin_endpoint = 'http://localhost:35357',",46,22
openstack%2Fopenstack-manuals~master~Ifaf279bbc965fdd8bff6d2a55ffe824fdc6e2d0f,openstack/openstack-manuals,master,Ifaf279bbc965fdd8bff6d2a55ffe824fdc6e2d0f,Updates to 'Manage Volumes' section,MERGED,2014-03-04 03:52:20.000000000,2014-03-05 21:46:13.000000000,2014-03-05 21:46:12.000000000,"[{'_account_id': 3}, {'_account_id': 964}, {'_account_id': 6547}, {'_account_id': 6843}, {'_account_id': 7923}, {'_account_id': 8103}]","[{'number': 1, 'created': '2014-03-04 03:52:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/1c79813d4d4f52c9683f8fc325ec4f5a85878a4c', 'message': ""Updates to 'Manage Volumes' section\n\nUpdated the procedure in the 'Manage volumes' section of the dashboard\nchapter of the End User guide.\nPartial-Bug: #1279133\n\nChange-Id: Ifaf279bbc965fdd8bff6d2a55ffe824fdc6e2d0f\n""}, {'number': 2, 'created': '2014-03-05 00:05:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/2f9873266c305cd9a30ec07f310470becf91e9b5', 'message': ""Updates to 'Manage Volumes' section\n\nUpdated the procedure in the 'Manage volumes' section of the dashboard\nchapter of the End User guide.\nPartial-Bug: #1279133\n\nChange-Id: Ifaf279bbc965fdd8bff6d2a55ffe824fdc6e2d0f\n""}, {'number': 3, 'created': '2014-03-05 20:47:29.000000000', 'files': ['doc/user-guide/section_dashboard_manage_volumes.xml'], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/2fc55d1f80600ac5577d188449f5cd2ee6e6bb8a', 'message': ""Updates to 'Manage Volumes' section\n\nUpdated the procedure in the 'Manage volumes' section of the dashboard\nchapter of the End User guide.\nPartial-Bug: #1279133\n\nChange-Id: Ifaf279bbc965fdd8bff6d2a55ffe824fdc6e2d0f\n""}]",6,77780,2fc55d1f80600ac5577d188449f5cd2ee6e6bb8a,18,6,3,8103,,,0,"Updates to 'Manage Volumes' section

Updated the procedure in the 'Manage volumes' section of the dashboard
chapter of the End User guide.
Partial-Bug: #1279133

Change-Id: Ifaf279bbc965fdd8bff6d2a55ffe824fdc6e2d0f
",git fetch https://review.opendev.org/openstack/openstack-manuals refs/changes/80/77780/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/user-guide/section_dashboard_manage_volumes.xml'],1,1c79813d4d4f52c9683f8fc325ec4f5a85878a4c,sect-dashboard-manage-volumes," <para>Click <guibutton>Create Volume</guibutton>.</para> <para>In the window that opens, enter or select the following values.</para> <informaltable rules=""all"" width=""75%""> <col width=""30%""/> <col width=""70%""/> <!-- <thead> <tr> <th colspan=""2"" align=""center"" > <guilabel>Network</guilabel> tab</th> </tr> </thead>--> <tbody> <tr> <td> <para> <guilabel>Volume Name</guilabel> </para> </td> <td> <para>A name to identify the volume.</para> </td> </tr> <tr> <td> <para> <guilabel>Description</guilabel> </para> </td> <td> <para>A brief description for the volume.</para> </td> </tr> <tr> <td> <para> <guilabel>Type</guilabel> </para> </td> <td> <para>Leave this field blank.</para> </td> </tr> <tr> <td> <para> <guilabel>Size (GB)</guilabel> </para> </td> <td> <para>The size of the volume.</para> </td> </tr> <tr> <td> <para> <guilabel>Volume Source</guilabel> </para> </td> <td> <para>Your options are:</para> <itemizedlist> <listitem> <para><guilabel>No source, empty volume</guilabel> - You can create an empty volume using this option.</para> </listitem> <listitem> <para><guilabel>Image</guilabel> - On choosing this option, a new field, <guilabel>Use image as a source</guilabel> with a dropdown list of all images is displayed.</para> </listitem> </itemizedlist> </td> </tr> </tbody> </informaltable> <para>Click the <guibutton>Create Volume</guibutton> button to confirm your changes.</para> <para>The dashboard shows the volume in the <guilabel>Volumes</guilabel> category.</para> <guilabel>Volumes</guilabel> category of the dashboard. The volume is either available or In-Use.</para> click the <guilabel>Volumes</guilabel> category.</para> <para>From the <guilabel>More</guilabel> drop-down and a brief description.</para>"," <para>Click <guibutton>Create Volume</guibutton>.</para> <para>In the window that opens, enter a name, an optional description, and the size in GBs for the volume.</para> <para>Click <guibutton>Create Volume</guibutton> to confirm your changes.</para> <para>The dashboard shows the volume in the <guilabel>Volumes</guilabel> category.</para> <guilabel>Instances &amp; Volumes</guilabel> category of the dashboard. The volume is either available or In-Use.</para> click the <guilabel>Instances &amp; Volumes</guilabel> category.</para> <para>From the <guilabel>Actions</guilabel> drop-down and a description.</para>",85,16
openstack%2Fopenstack-manuals~master~I30c5c5a02af58141359fb7634dbf82d9c18e2181,openstack/openstack-manuals,master,I30c5c5a02af58141359fb7634dbf82d9c18e2181,cleanup of operator-editing-code,MERGED,2014-02-24 05:42:03.000000000,2014-03-05 21:46:05.000000000,2014-03-05 21:46:04.000000000,"[{'_account_id': 3}, {'_account_id': 612}, {'_account_id': 964}, {'_account_id': 2448}, {'_account_id': 6547}, {'_account_id': 7244}, {'_account_id': 9162}, {'_account_id': 9382}, {'_account_id': 9383}]","[{'number': 1, 'created': '2014-02-24 05:42:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/a12c4515fba6e53f0e40c337b06d8420bcf6dc93', 'message': 'cleanup of operator-editing-code\n\nadded commas and joined sentences\ncorrected sentence formats\ncapitalized before sentence\n\nChange-Id: I30c5c5a02af58141359fb7634dbf82d9c18e2181\n'}, {'number': 2, 'created': '2014-02-26 06:07:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/d657fc6a593b414e1dec1c2f3064518d06e4af13', 'message': 'cleanup of operator-editing-code\n\nadded commas and joined sentences\ncorrected sentence formats\ncapitalized before sentence\nremoved capitals that were extra in sentence\n\nChange-Id: I30c5c5a02af58141359fb7634dbf82d9c18e2181\nConflicts:\n\tdoc/training-guides/operator-editing-code.xml\n'}, {'number': 3, 'created': '2014-02-26 21:06:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/107d2e08617904ff7cd54219f42c4df52a6f5bb9', 'message': 'cleanup of operator-editing-code\n\nadded commas and joined sentences\ncorrected sentence formats\ncapitalized before sentence\nremoved capitals that were extra in sentence\n\nChange-Id: I30c5c5a02af58141359fb7634dbf82d9c18e2181\nConflicts:\n\tdoc/training-guides/operator-editing-code.xml\n'}, {'number': 4, 'created': '2014-02-28 17:51:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/2bbb0763e50383b8d3807f59cb064d37280f1428', 'message': 'cleanup of operator-editing-code\n\nadded commas and joined sentences\ncorrected sentence formats\ncapitalized before sentence\nremoved capitals that were extra in sentence\n\nChange-Id: I30c5c5a02af58141359fb7634dbf82d9c18e2181\nConflicts:\n\tdoc/training-guides/operator-editing-code.xml\n'}, {'number': 5, 'created': '2014-02-28 19:15:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/4f4dc5cc864a65b25f3aed18af117e90295c67ae', 'message': 'cleanup of operator-editing-code\n\nadded commas and joined sentences\ncorrected sentence formats\ncapitalized before sentence\nremoved capitals that were extra in sentence\nchanged para tag location\nreomved ""show"" per comments\ncapitalized a in Agreement\n\nChange-Id: I30c5c5a02af58141359fb7634dbf82d9c18e2181\nConflicts:\n\tdoc/training-guides/operator-editing-code.xml\n'}, {'number': 6, 'created': '2014-02-28 20:28:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/59a0de3c305038773a06db5688bfe96add6b671f', 'message': 'cleanup of operator-editing-code\n\nadded commas and joined sentences\ncorrected sentence formats\ncapitalized before sentence\nremoved capitals that were extra in sentence\nchanged para tag location\nreomved ""show"" per comments\ncapitalized a in Agreement\n\nChange-Id: I30c5c5a02af58141359fb7634dbf82d9c18e2181\nConflicts:\n\tdoc/training-guides/operator-editing-code.xml\n'}, {'number': 7, 'created': '2014-02-28 22:06:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/722638737e0528bb2fb4cb3eda76e83c82d27364', 'message': 'cleanup of operator-editing-code\n\nadded commas and joined sentences\ncorrected sentence formats\ncapitalized before sentence\nremoved capitals that were extra in sentence\nchanged para tag location\nreomved ""show"" per comments\ncapitalized a in Agreement\n\nChange-Id: I30c5c5a02af58141359fb7634dbf82d9c18e2181\nConflicts:\n\tdoc/training-guides/operator-editing-code.xml\n'}, {'number': 8, 'created': '2014-03-05 18:41:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/0098a84a56832a8062238b33168b41379270ead6', 'message': 'cleanup of operator-editing-code\n\nadded commas and joined sentences\ncorrected sentence formats\ncapitalized before sentence\nremoved capitals that were extra in sentence\nchanged para tag location\nreomved ""show"" per comments\ncapitalized a in Agreement\n\nChange-Id: I30c5c5a02af58141359fb7634dbf82d9c18e2181\nConflicts:\n\tdoc/training-guides/operator-editing-code.xml\n'}, {'number': 9, 'created': '2014-03-05 19:29:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/86a40417c48261665f308dfe0204030bcf799d9f', 'message': 'cleanup of operator-editing-code\n\nadded commas and joined sentences\ncorrected sentence formats\ncapitalized before sentence\nremoved capitals that were extra in sentence\nchanged para tag location\nreomved ""show"" per comments\ncapitalized a in Agreement\n\nChange-Id: I30c5c5a02af58141359fb7634dbf82d9c18e2181\n'}, {'number': 10, 'created': '2014-03-05 19:55:30.000000000', 'files': ['doc/training-guides/operator-editing-code.xml'], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/4d24385fc677562c370ddd4c7155ecb3eedc7986', 'message': 'cleanup of operator-editing-code\n\nadded commas and joined sentences\ncorrected sentence formats\ncapitalized before sentence\nremoved capitals that were extra in sentence\nchanged para tag location\nreomved ""show"" per comments\ncapitalized a in Agreement\n\nChange-Id: I30c5c5a02af58141359fb7634dbf82d9c18e2181\n'}]",16,75765,4d24385fc677562c370ddd4c7155ecb3eedc7986,45,9,10,9382,,,0,"cleanup of operator-editing-code

added commas and joined sentences
corrected sentence formats
capitalized before sentence
removed capitals that were extra in sentence
changed para tag location
reomved ""show"" per comments
capitalized a in Agreement

Change-Id: I30c5c5a02af58141359fb7634dbf82d9c18e2181
",git fetch https://review.opendev.org/openstack/openstack-manuals refs/changes/65/75765/10 && git format-patch -1 --stdout FETCH_HEAD,['doc/training-guides/operator-editing-code.xml'],1,a12c4515fba6e53f0e40c337b06d8420bcf6dc93,opera_editingcode," you will use for code contributions, since the Primary Email Address in <para>The CLA: Every developer and contributor needs to <para>When your editing is complete, double check Oxygen doesn't have show any unexpected errors.</para> <para>Commit the changes with good syntax. After entering the commit command, VI syntax applies, use ""i"" to insert and Esc to break out. "":wq"" to write and quit.<programlisting>git commit -a <para>The last step is to go to the review page listed after you submitted your review <step><para><emphasis role=""bold"">Getting Accounts and Tools:</emphasis> We cannot do from the Sprint Backlog to yourself. If you do not have a Trello account, no"," you'll use for code contributions, since the Primary Email Address in <para>the CLA: Every developer and contributor needs to <para>When your editing is completed. Double check Oxygen doesn't have any errors you are not expecting.</para> <para>Commit the changes with good syntax. After entering the commit command, VI syntax applies. Use ""i"" to insert and Esc to break out. "":wq"" to write and quit.<programlisting>git commit -a <para>One last step. Go to the review page listed after you submitted your review <step><para><emphasis role=""bold"">Getting Accounts and Tools:</emphasis> We can't do from the Sprint Backlog to yourself. If you don't have a Trello account, no",7,8
openstack%2Fceilometer~master~I154d757f9719f949fcacb56ee2d6b42e36212526,openstack/ceilometer,master,I154d757f9719f949fcacb56ee2d6b42e36212526,Per pipeline pluggable resource discovery,MERGED,2014-02-24 19:42:34.000000000,2014-03-05 21:44:48.000000000,2014-03-05 21:44:47.000000000,"[{'_account_id': 3}, {'_account_id': 1669}, {'_account_id': 2284}, {'_account_id': 2860}, {'_account_id': 4491}, {'_account_id': 6537}, {'_account_id': 9562}]","[{'number': 1, 'created': '2014-02-24 19:42:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/9d1c675d01142115030a4575055ec0c6fdc77f35', 'message': 'Per pipeline plubbale resource discovery\n\nAddresses: BP decoupled-source-sink-discoverable-resources\n\nAdd the concept of per-pipeline resource discovery extensions\nloaded via stevedore entry points. These are enabled via a\npipeline source \'discovery\' element, for example:\n\n  sources:\n      - name: host_cpu_source\n        interval: 120\n        meters:\n             - ""cpu.util.*min""\n        discovery:\n             - ""file_loader""\n        resources:\n             - ""snmp://ip1""\n             - ""snmp://ip2""\n        sinks:\n            - meter_sink\n\nThe named discovery extensions are loaded from a global namespace\n""ceilometer.discover"". Per-pipeline dynamically discovered and\nstatically configured resources are combined, overridding any\nper-agent discovery extensions. An amalgamated resource list for\na set of pipelines with a common interval is passed to individual\npollsters matching those pipelines (matching the pre-existing\nlogic for statically configured per-pipeline resources).\n\nChange-Id: I154d757f9719f949fcacb56ee2d6b42e36212526\n'}, {'number': 2, 'created': '2014-02-24 20:19:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/d5ed90e1ce5d6e62a62fd67d07b0d8a125b30fbd', 'message': 'Per pipeline pluggable resource discovery\n\nAddresses: BP decoupled-source-sink-discoverable-resources\n\nAdd the concept of per-pipeline resource discovery extensions\nloaded via stevedore entry points. These are enabled via a\npipeline source \'discovery\' element, for example:\n\n  sources:\n      - name: host_cpu_source\n        interval: 120\n        meters:\n             - ""cpu.util.*min""\n        discovery:\n             - ""file_loader""\n        resources:\n             - ""snmp://ip1""\n             - ""snmp://ip2""\n        sinks:\n            - meter_sink\n\nThe named discovery extensions are loaded from a global namespace\n""ceilometer.discover"". Per-pipeline dynamically discovered and\nstatically configured resources are combined, overridding any\nper-agent discovery extensions. An amalgamated resource list for\na set of pipelines with a common interval is passed to individual\npollsters matching those pipelines (matching the pre-existing\nlogic for statically configured per-pipeline resources).\n\nChange-Id: I154d757f9719f949fcacb56ee2d6b42e36212526\n'}, {'number': 3, 'created': '2014-02-26 15:04:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/440a69e8b1401bad5d32cd6c6f75c865d063a912', 'message': 'Per pipeline pluggable resource discovery\n\nAddresses: BP decoupled-source-sink-discoverable-resources\n\nAdd the concept of per-pipeline resource discovery extensions\nloaded via stevedore entry points. These are enabled via a\npipeline source \'discovery\' element, for example:\n\n  sources:\n      - name: host_cpu_source\n        interval: 120\n        meters:\n             - ""cpu.util.*min""\n        discovery:\n             - ""file_loader""\n        resources:\n             - ""snmp://ip1""\n             - ""snmp://ip2""\n        sinks:\n            - meter_sink\n\nThe named discovery extensions are loaded from a global namespace\n""ceilometer.discover"". Per-pipeline dynamically discovered and\nstatically configured resources are combined, overridding any\nper-agent discovery extensions. An amalgamated resource list for\na set of pipelines with a common interval is passed to individual\npollsters matching those pipelines (matching the pre-existing\nlogic for statically configured per-pipeline resources).\n\nChange-Id: I154d757f9719f949fcacb56ee2d6b42e36212526\n'}, {'number': 4, 'created': '2014-02-26 15:46:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/7ca4baf2f67268eebd3e978f3daed702cb7b305f', 'message': 'Per pipeline pluggable resource discovery\n\nAddresses: BP decoupled-source-sink-discoverable-resources\n\nAdd the concept of per-pipeline resource discovery extensions\nloaded via stevedore entry points. These are enabled via a\npipeline source \'discovery\' element, for example:\n\n  sources:\n      - name: host_cpu_source\n        interval: 120\n        meters:\n             - ""cpu.util.*min""\n        discovery:\n             - ""file_loader""\n        resources:\n             - ""snmp://ip1""\n             - ""snmp://ip2""\n        sinks:\n            - meter_sink\n\nThe named discovery extensions are loaded from a global namespace\n""ceilometer.discover"". Per-pipeline dynamically discovered and\nstatically configured resources are combined, overridding any\nper-agent discovery extensions. An amalgamated resource list for\na set of pipelines with a common interval is passed to individual\npollsters matching those pipelines (matching the pre-existing\nlogic for statically configured per-pipeline resources).\n\nChange-Id: I154d757f9719f949fcacb56ee2d6b42e36212526\n'}, {'number': 5, 'created': '2014-02-27 10:39:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/022eb933c51c50caabcf26c7ffa89ed342e9aa58', 'message': 'Per pipeline pluggable resource discovery\n\nAddresses: BP decoupled-source-sink-discoverable-resources\n\nAdd the concept of per-pipeline resource discovery extensions\nloaded via stevedore entry points. These are enabled via a\npipeline source \'discovery\' element, for example:\n\n  sources:\n      - name: host_cpu_source\n        interval: 120\n        meters:\n             - ""cpu.util.*min""\n        discovery:\n             - ""file_loader""\n        resources:\n             - ""snmp://ip1""\n             - ""snmp://ip2""\n        sinks:\n            - meter_sink\n\nThe named discovery extensions are loaded from a global namespace\n""ceilometer.discover"". Per-pipeline dynamically discovered and\nstatically configured resources are combined, overridding any\nper-agent discovery extensions. An amalgamated resource list for\na set of pipelines with a common interval is passed to individual\npollsters matching those pipelines (matching the pre-existing\nlogic for statically configured per-pipeline resources).\n\nChange-Id: I154d757f9719f949fcacb56ee2d6b42e36212526\n'}, {'number': 6, 'created': '2014-03-03 22:01:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/6ee386ade8b4a82f3a71a318ce8c34f74aaed013', 'message': 'Per pipeline pluggable resource discovery\n\nAddresses: BP decoupled-source-sink-discoverable-resources\n\nAdd the concept of per-pipeline resource discovery extensions\nloaded via stevedore entry points. These are enabled via a\npipeline source \'discovery\' element, for example:\n\n  sources:\n      - name: host_cpu_source\n        interval: 120\n        meters:\n             - ""cpu.util.*min""\n        discovery:\n             - ""file_loader""\n        resources:\n             - ""snmp://ip1""\n             - ""snmp://ip2""\n        sinks:\n            - meter_sink\n\nThe named discovery extensions are loaded from a global namespace\n""ceilometer.discover"". Per-pipeline dynamically discovered and\nstatically configured resources are combined, overridding any\nper-agent discovery extensions. An amalgamated resource list for\na set of pipelines with a common interval is passed to individual\npollsters matching those pipelines (matching the pre-existing\nlogic for statically configured per-pipeline resources).\n\nChange-Id: I154d757f9719f949fcacb56ee2d6b42e36212526\n'}, {'number': 7, 'created': '2014-03-04 07:35:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/d1692bf81126653305d559df8de9ce33340c43ae', 'message': 'Per pipeline pluggable resource discovery\n\nAddresses: BP decoupled-source-sink-discoverable-resources\n\nAdd the concept of per-pipeline resource discovery extensions\nloaded via stevedore entry points. These are enabled via a\npipeline source \'discovery\' element, for example:\n\n  sources:\n      - name: host_cpu_source\n        interval: 120\n        meters:\n             - ""cpu.util.*min""\n        discovery:\n             - ""file_loader""\n        resources:\n             - ""snmp://ip1""\n             - ""snmp://ip2""\n        sinks:\n            - meter_sink\n\nThe named discovery extensions are loaded from a global namespace\n""ceilometer.discover"". Per-pipeline dynamically discovered and\nstatically configured resources are combined, overridding any\nper-agent discovery extensions. An amalgamated resource list for\na set of pipelines with a common interval is passed to individual\npollsters matching those pipelines (matching the pre-existing\nlogic for statically configured per-pipeline resources).\n\nChange-Id: I154d757f9719f949fcacb56ee2d6b42e36212526\n'}, {'number': 8, 'created': '2014-03-04 17:47:03.000000000', 'files': ['ceilometer/pipeline.py', 'ceilometer/tests/agentbase.py', 'ceilometer/agent.py'], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/d011ec00970e4da6aee41d61b069265cc79f88b5', 'message': 'Per pipeline pluggable resource discovery\n\nAddresses: BP decoupled-source-sink-discoverable-resources\n\nAdd the concept of per-pipeline resource discovery extensions\nloaded via stevedore entry points. These are enabled via a\npipeline source \'discovery\' element, for example:\n\n  sources:\n      - name: host_cpu_source\n        interval: 120\n        meters:\n             - ""cpu.util.*min""\n        discovery:\n             - ""file_loader""\n        resources:\n             - ""snmp://ip1""\n             - ""snmp://ip2""\n        sinks:\n            - meter_sink\n\nThe named discovery extensions are loaded from a global namespace\n""ceilometer.discover"". Per-pipeline dynamically discovered and\nstatically configured resources are combined, overridding any\nper-agent discovery extensions. An amalgamated resource list for\na set of pipelines with a common interval is passed to individual\npollsters matching those pipelines (matching the pre-existing\nlogic for statically configured per-pipeline resources).\n\nChange-Id: I154d757f9719f949fcacb56ee2d6b42e36212526\n'}]",12,75970,d011ec00970e4da6aee41d61b069265cc79f88b5,43,7,8,2284,,,0,"Per pipeline pluggable resource discovery

Addresses: BP decoupled-source-sink-discoverable-resources

Add the concept of per-pipeline resource discovery extensions
loaded via stevedore entry points. These are enabled via a
pipeline source 'discovery' element, for example:

  sources:
      - name: host_cpu_source
        interval: 120
        meters:
             - ""cpu.util.*min""
        discovery:
             - ""file_loader""
        resources:
             - ""snmp://ip1""
             - ""snmp://ip2""
        sinks:
            - meter_sink

The named discovery extensions are loaded from a global namespace
""ceilometer.discover"". Per-pipeline dynamically discovered and
statically configured resources are combined, overridding any
per-agent discovery extensions. An amalgamated resource list for
a set of pipelines with a common interval is passed to individual
pollsters matching those pipelines (matching the pre-existing
logic for statically configured per-pipeline resources).

Change-Id: I154d757f9719f949fcacb56ee2d6b42e36212526
",git fetch https://review.opendev.org/openstack/ceilometer refs/changes/70/75970/8 && git format-patch -1 --stdout FETCH_HEAD,"['ceilometer/pipeline.py', 'ceilometer/tests/agentbase.py', 'ceilometer/agent.py']",3,9d1c675d01142115030a4575055ec0c6fdc77f35,,"class Resources(object): def __init__(self, agent_manager): self.agent_manager = agent_manager self.discovery_manager = agent_manager.global_discovery_manager self._resources = [] self._discovery = [] def extend(self, pipeline): self._resources.extend(pipeline.resources) self._discovery.extend(pipeline.discovery) @property def resources(self): discovery_extensions = [d for d in self.discovery_manager if d.name in self._discovery] return (self._resources + self.agent_manager.discover(discovery_extensions)) # we extend the amalgation of all static resources for this set # of pollsters with a common interval, so as to also include any # dynamically discovered resources specific to the matching pipelines # (if either is present, the per-agent discovery is overridden) resource_factory = lambda: Resources(agent_manager) self.resources = collections.defaultdict(resource_factory) self.resources[pollster.name].extend(pipeline) key = pollster.name LOG.info(_(""Polling pollster %s""), key) source_resources = list(self.resources[key].resources) self.agent_discovery_manager = self._extensions('discover', namespace) self.global_discovery_manager = self._extensions('discover') def _extensions(category, agent_ns=None): namespace = ('ceilometer.%s.%s' % (category, agent_ns) if agent_ns else 'ceilometer.%s' % category) namespace=namespace, def discover(self, discovery_extensions=None): discoverers = (discovery_extensions if discovery_extensions is not None else self.agent_discovery_manager) for discoverer in discoverers:"," # Resource definitions are indexed by the pollster # Use dict of set here to remove the duplicated resource definitions # for each pollster. self.resources = collections.defaultdict(set) self.resources[pollster.name].update(pipeline.resources) LOG.info(_(""Polling pollster %s""), pollster.name) source_resources = list(self.resources[pollster.name]) self.discovery_manager = self._extensions('discover', namespace) def _extensions(category, namespace): namespace='ceilometer.%s.%s' % (category, namespace), def discover(self): for discoverer in self.discovery_manager:",102,17
openstack%2Fpuppet-ceilometer~master~I74a523bcc1acd18532bb9353b70da63c70e8e325,openstack/puppet-ceilometer,master,I74a523bcc1acd18532bb9353b70da63c70e8e325,Move service polling credentials to service_credentials,MERGED,2014-03-04 21:58:13.000000000,2014-03-05 21:42:07.000000000,2014-03-05 21:42:07.000000000,"[{'_account_id': 3}, {'_account_id': 6754}, {'_account_id': 6967}, {'_account_id': 7822}]","[{'number': 1, 'created': '2014-03-04 21:58:13.000000000', 'files': ['spec/classes/ceilometer_agent_auth_spec.rb', 'manifests/agent/auth.pp'], 'web_link': 'https://opendev.org/openstack/puppet-ceilometer/commit/160b5ed239e996e6c18de3f6158c8b0a4e66c175', 'message': 'Move service polling credentials to service_credentials\n\nChange-Id: I74a523bcc1acd18532bb9353b70da63c70e8e325\nCloses-bug: #1287939\n'}]",0,78021,160b5ed239e996e6c18de3f6158c8b0a4e66c175,8,4,1,7156,,,0,"Move service polling credentials to service_credentials

Change-Id: I74a523bcc1acd18532bb9353b70da63c70e8e325
Closes-bug: #1287939
",git fetch https://review.opendev.org/openstack/puppet-ceilometer refs/changes/21/78021/1 && git format-patch -1 --stdout FETCH_HEAD,"['spec/classes/ceilometer_agent_auth_spec.rb', 'manifests/agent/auth.pp']",2,160b5ed239e996e6c18de3f6158c8b0a4e66c175,bug/1287939, ceilometer_config { 'service_credentials/os_cacert': ensure => absent } } else { ceilometer_config { 'service_credentials/os_cacert': value => $auth_cacert } 'service_credentials/os_auth_url' : value => $auth_url; 'service_credentials/os_auth_region' : value => $auth_region; 'service_credentials/os_username' : value => $auth_user; 'service_credentials/os_password' : value => $auth_password; 'service_credentials/os_tenant_name' : value => $auth_tenant_name; 'service_credentials/os_tenant_id' : value => $auth_tenant_id;, ceilometer_config { 'DEFAULT/os_cacert': ensure => absent } } else { ceilometer_config { 'DEFAULT/os_cacert': value => $auth_cacert } 'DEFAULT/os_auth_url' : value => $auth_url; 'DEFAULT/os_auth_region' : value => $auth_region; 'DEFAULT/os_username' : value => $auth_user; 'DEFAULT/os_password' : value => $auth_password; 'DEFAULT/os_tenant_name' : value => $auth_tenant_name; 'DEFAULT/os_tenant_id' : value => $auth_tenant_id;,15,15
openstack%2Fpuppet-neutron~stable%2Fhavana~If320b4fa5682245ac2cc9b4a9f05cf02dadc84c0,openstack/puppet-neutron,stable/havana,If320b4fa5682245ac2cc9b4a9f05cf02dadc84c0,Ensure Neutron DB is populated,MERGED,2014-02-25 20:58:08.000000000,2014-03-05 21:36:14.000000000,2014-03-05 21:36:14.000000000,"[{'_account_id': 3}, {'_account_id': 3153}, {'_account_id': 7156}, {'_account_id': 7822}]","[{'number': 1, 'created': '2014-02-25 20:58:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-neutron/commit/85826401070e4cee3ce1e0ef5c8d1430648c9bdf', 'message': 'Ensure Neutron DB is populated\n\n- Create symbolic link to have /etc/neutron/plugin.ini\n- This file is used to synchronize the database\n\nIn that way, the command to populate database is generic to all plugins.\n\nFixes-Bug #1275688\n\nChange-Id: If320b4fa5682245ac2cc9b4a9f05cf02dadc84c0\nSigned-off-by: Emilien Macchi <emilien.macchi@enovance.com>\n(cherry picked from commit fea38195c6ede5d33b935701396534ef4757dffc)\n'}, {'number': 2, 'created': '2014-03-05 16:48:37.000000000', 'files': ['spec/classes/neutron_plugins_ml2_spec.rb', 'spec/classes/neutron_plugins_nvp_spec.rb', 'spec/classes/neutron_plugins_linuxbridge_spec.rb', 'manifests/plugins/cisco.pp', 'manifests/plugins/nvp.pp', 'spec/classes/neutron_plugins_cisco_spec.rb', 'spec/classes/neutron_plugins_ovs_spec.rb', 'manifests/plugins/ml2.pp', 'spec/classes/neutron_server_spec.rb', 'manifests/plugins/linuxbridge.pp', 'manifests/plugins/ovs.pp', 'manifests/server.pp'], 'web_link': 'https://opendev.org/openstack/puppet-neutron/commit/4be69d2cdde185a241ecb34361ab6a473191e975', 'message': 'Ensure Neutron DB is populated\n\n- Create symbolic link to have /etc/neutron/plugin.ini\n- This file is used to synchronize the database\n\nIn that way, the command to populate database is generic to all plugins.\n\nFixes-Bug #1275688\n\nChange-Id: If320b4fa5682245ac2cc9b4a9f05cf02dadc84c0\nSigned-off-by: Emilien Macchi <emilien.macchi@enovance.com>\n(cherry picked from commit fea38195c6ede5d33b935701396534ef4757dffc)\n'}]",0,76358,4be69d2cdde185a241ecb34361ab6a473191e975,11,4,2,3153,,,0,"Ensure Neutron DB is populated

- Create symbolic link to have /etc/neutron/plugin.ini
- This file is used to synchronize the database

In that way, the command to populate database is generic to all plugins.

Fixes-Bug #1275688

Change-Id: If320b4fa5682245ac2cc9b4a9f05cf02dadc84c0
Signed-off-by: Emilien Macchi <emilien.macchi@enovance.com>
(cherry picked from commit fea38195c6ede5d33b935701396534ef4757dffc)
",git fetch https://review.opendev.org/openstack/puppet-neutron refs/changes/58/76358/1 && git format-patch -1 --stdout FETCH_HEAD,"['spec/classes/neutron_plugins_ml2_spec.rb', 'spec/classes/neutron_plugins_nvp_spec.rb', 'spec/classes/neutron_plugins_linuxbridge_spec.rb', 'manifests/plugins/cisco.pp', 'manifests/plugins/nvp.pp', 'spec/classes/neutron_plugins_cisco_spec.rb', 'spec/classes/neutron_plugins_ovs_spec.rb', 'manifests/plugins/ml2.pp', 'spec/classes/neutron_server_spec.rb', 'manifests/plugins/linuxbridge.pp', 'manifests/plugins/ovs.pp', 'manifests/server.pp']",12,85826401070e4cee3ce1e0ef5c8d1430648c9bdf,bug/1275688,"# [*sync_db*] # (optional) Run neutron-db-manage on api nodes after installing the package. # Defaults to true # $sync_db = true, if $sync_db { if ($::neutron::params::server_package) { # Debian platforms Package<| title == 'neutron-server' |> ~> Exec['neutron-db-sync'] } else { # RH platforms Package<| title == 'neutron' |> ~> Exec['neutron-db-sync'] } exec { 'neutron-db-sync': command => 'neutron-db-manage --config-file /etc/neutron/neutron.conf --config-file /etc/neutron/plugin.ini upgrade head', path => '/usr/bin', before => Service['neutron-server'], require => Neutron_config['database/connection'], refreshonly => true } } ",,123,41
openstack%2Fpuppet-swift~stable%2Fhavana~I7704bf42db4554566d27b510bbbedb8afe0fe7b3,openstack/puppet-swift,stable/havana,I7704bf42db4554566d27b510bbbedb8afe0fe7b3,swift classes need to include swift::params,MERGED,2014-03-05 17:48:37.000000000,2014-03-05 21:34:41.000000000,2014-03-05 21:34:41.000000000,"[{'_account_id': 3}, {'_account_id': 6754}, {'_account_id': 7156}, {'_account_id': 7822}]","[{'number': 1, 'created': '2014-03-05 17:48:37.000000000', 'files': ['manifests/storage/container.pp', 'manifests/storage/account.pp', 'manifests/storage/object.pp'], 'web_link': 'https://opendev.org/openstack/puppet-swift/commit/9b60581a1c8fd2c1a98adafc1bcdc53796859e23', 'message': 'swift classes need to include swift::params\n\nSome of the swift classes use parameterized settings defined in\nswift::params but do not include the swift::params class.\n\nChange-Id: I7704bf42db4554566d27b510bbbedb8afe0fe7b3\nCloses-Bug: #1288252\n(cherry picked from commit 2cce66ef44b011ba695dbc3e1586b2e0b8570666)\n'}]",0,78326,9b60581a1c8fd2c1a98adafc1bcdc53796859e23,7,4,1,6967,,,0,"swift classes need to include swift::params

Some of the swift classes use parameterized settings defined in
swift::params but do not include the swift::params class.

Change-Id: I7704bf42db4554566d27b510bbbedb8afe0fe7b3
Closes-Bug: #1288252
(cherry picked from commit 2cce66ef44b011ba695dbc3e1586b2e0b8570666)
",git fetch https://review.opendev.org/openstack/puppet-swift refs/changes/26/78326/1 && git format-patch -1 --stdout FETCH_HEAD,"['manifests/storage/container.pp', 'manifests/storage/account.pp', 'manifests/storage/object.pp']",3,9b60581a1c8fd2c1a98adafc1bcdc53796859e23,backports/1288252, include swift::params ,,8,0
openstack%2Fopenstack-manuals~master~I0fe859439e119c921526c92d878f3778c81366aa,openstack/openstack-manuals,master,I0fe859439e119c921526c92d878f3778c81366aa,changes to lab001-control-node,MERGED,2014-02-28 23:00:23.000000000,2014-03-05 21:32:24.000000000,2014-03-05 21:32:23.000000000,"[{'_account_id': 3}, {'_account_id': 6547}, {'_account_id': 7923}, {'_account_id': 9382}, {'_account_id': 9383}]","[{'number': 1, 'created': '2014-02-28 23:00:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/4722861b0eb7a970afa2c9968694fcea0424ebc0', 'message': 'changes to lab001-control-node\n\nchanged provide to be\nremoved extra :\nno comma needed after debug\nchanged provide to be\ncanonical to caps\nweb based hyphen added\n\nChange-Id: I0fe859439e119c921526c92d878f3778c81366aa\n'}, {'number': 2, 'created': '2014-03-01 09:30:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/9df088e81e8b349c5d61387d89fd97de576a8097', 'message': 'changes to lab001-control-node\n\nchanged provide to be\nremoved extra :\nno comma needed after debug\nchanged provide to be\ncanonical to caps\nweb based hyphen added\n\nChange-Id: I0fe859439e119c921526c92d878f3778c81366aa\n'}, {'number': 3, 'created': '2014-03-05 18:17:44.000000000', 'files': ['doc/training-guides/lab001-control-node.xml'], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/46084dc2e557d209c10215eae1894d5194adf783', 'message': 'changes to lab001-control-node\n\nchanged provide to be\nremoved extra :\nno comma needed after debug\nchanged provide to be\ncanonical to caps\nweb based hyphen added\n\nChange-Id: I0fe859439e119c921526c92d878f3778c81366aa\n'}]",4,77291,46084dc2e557d209c10215eae1894d5194adf783,15,5,3,9382,,,0,"changes to lab001-control-node

changed provide to be
removed extra :
no comma needed after debug
changed provide to be
canonical to caps
web based hyphen added

Change-Id: I0fe859439e119c921526c92d878f3778c81366aa
",git fetch https://review.opendev.org/openstack/openstack-manuals refs/changes/91/77291/3 && git format-patch -1 --stdout FETCH_HEAD,['doc/training-guides/lab001-control-node.xml'],1,4722861b0eb7a970afa2c9968694fcea0424ebc0,lab001-controlnode," <para>API Compatibility: Nova strives to be API-compatible with popular systems like Amazon EC2 <para>Check for the smiling faces on nova-* services to confirm your installation:</para> <para>Recoverable: Failures should be easy to diagnose, debug and rectify</para> <para>API Compatibility: Cinder strives to be API-compatible with popular systems like Amazon EC2 <para>Horizon is the Canonical implementation of OpenStacks dashboard, which provides a web-based user interface to OpenStack services including Nova, Swift, Keystone, etc.</para>"," <para>API Compatibility: Nova strives to provide API-compatible with popular systems like Amazon EC2 <para>Check for the smiling faces on nova-* services to confirm your installation::</para> <para>Recoverable: Failures should be easy to diagnose, debug, and rectify</para> <para>API Compatibility: Cinder strives to provide API-compatible with popular systems like Amazon EC2 <para>Horizon is the canonical implementation of OpenStacks dashboard, which provides a web based user interface to OpenStack services including Nova, Swift, Keystone, etc.</para>",5,5
openstack%2Fneutron~stable%2Fhavana~I9a37bae92dc12a8a78ea2d1b9fc5e995321ca322,openstack/neutron,stable/havana,I9a37bae92dc12a8a78ea2d1b9fc5e995321ca322,Fix metering iptables driver doesn't read root_helper param,MERGED,2013-12-06 11:23:05.000000000,2014-03-05 21:15:11.000000000,2014-03-05 21:15:10.000000000,"[{'_account_id': 3}, {'_account_id': 55}, {'_account_id': 1420}, {'_account_id': 1955}, {'_account_id': 2592}, {'_account_id': 2711}, {'_account_id': 5170}, {'_account_id': 7141}, {'_account_id': 7781}, {'_account_id': 8279}, {'_account_id': 9787}, {'_account_id': 9845}, {'_account_id': 9925}, {'_account_id': 10117}]","[{'number': 2, 'created': '2013-12-06 11:23:05.000000000', 'files': ['neutron/tests/unit/services/metering/drivers/test_iptables_driver.py', 'neutron/services/metering/drivers/iptables/iptables_driver.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/99339a9dc2aaf71bb72cf19419c3f454fdd38304', 'message': ""Fix metering iptables driver doesn't read root_helper param\n\nWith this patch the iptables driver instantiates the\niptables_manager with the correct root_helper value.\n\nChange-Id: I9a37bae92dc12a8a78ea2d1b9fc5e995321ca322\nCloses-bug: #1256036\n(cherry picked from commit 35f64f8026f7607c749727ac6b3ee93c956bdfd2)\n""}, {'number': 1, 'created': '2013-12-06 11:23:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/411ca4df9ed0d1a81478b66347453c562724c0ca', 'message': ""Fix metering iptables driver doesn't read root_helper param\n\nWith this patch the iptables driver instantiates the\niptables_manager with the correct root_helper value.\n\nChange-Id: I9a37bae92dc12a8a78ea2d1b9fc5e995321ca322\nCloses-bug: #1256036\n(cherry picked from commit 35f64f8026f7607c749727ac6b3ee93c956bdfd2)\n""}]",0,60480,99339a9dc2aaf71bb72cf19419c3f454fdd38304,76,14,2,7141,,,0,"Fix metering iptables driver doesn't read root_helper param

With this patch the iptables driver instantiates the
iptables_manager with the correct root_helper value.

Change-Id: I9a37bae92dc12a8a78ea2d1b9fc5e995321ca322
Closes-bug: #1256036
(cherry picked from commit 35f64f8026f7607c749727ac6b3ee93c956bdfd2)
",git fetch https://review.opendev.org/openstack/neutron refs/changes/80/60480/2 && git format-patch -1 --stdout FETCH_HEAD,"['neutron/tests/unit/services/metering/drivers/test_iptables_driver.py', 'neutron/services/metering/drivers/iptables/iptables_driver.py']",2,99339a9dc2aaf71bb72cf19419c3f454fdd38304,bug/1256036," root_helper=self.root_helper,"," root_helper=self.conf.root_helper,",22,6
openstack%2Fopenstack-manuals~master~I35e0907d87b34dcd09863176b80ff434c3df171b,openstack/openstack-manuals,master,I35e0907d87b34dcd09863176b80ff434c3df171b,Reversing a change that incorrectly describes OVS configuration.,MERGED,2014-02-27 23:52:06.000000000,2014-03-05 20:58:58.000000000,2014-03-05 20:58:57.000000000,"[{'_account_id': 3}, {'_account_id': 612}, {'_account_id': 964}, {'_account_id': 2448}, {'_account_id': 5162}, {'_account_id': 6547}, {'_account_id': 9454}]","[{'number': 1, 'created': '2014-02-27 23:52:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/5ac5676cd557e0c22d370b775b2fcdfc87c96054', 'message': 'Removing inaccurate paragraph re OVS\n\nReversing a change that incorrectly describes OVS configuration.\nThis is incorrect since with the suggested OVS configuratione,\nall VMs would be placed in a single port group and any Neutron\nconfiguration would not function properly.\n\nChange-Id: I35e0907d87b34dcd09863176b80ff434c3df171b\nbackport: havana\nCloses-Bug: #1285448\n'}, {'number': 2, 'created': '2014-02-28 18:46:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/35902aa43a1b826cffe1cac15ff2706c833570c6', 'message': 'Removing inaccurate paragraph re OVS\n\nReversing a change that incorrectly describes OVS configuration.\nThis is incorrect since with the suggested OVS configuratione,\nall VMs would be placed in a single port group and any Neutron\nconfiguration would not function properly. Patch Set 2: tweaking\nlanguage as prompted by Anne Gentle.\n\nChange-Id: I35e0907d87b34dcd09863176b80ff434c3df171b\nbackport: havana\nCloses-Bug: #1285448\n'}, {'number': 3, 'created': '2014-03-05 18:43:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/2824dded127add24c71325eead60672c4d8267de', 'message': 'Removing inaccurate paragraph re OVS\n\nPartial reversion of change 40ec040797b98444d6a1d7eb0bd614f7bd9338c2\nsince it incorrectly describes OVS configuration.\nThis is incorrect since with the suggested OVS configuratione,\nall VMs would be placed in a single port group and any Neutron\nconfiguration would not function properly.\n\nAlso, some language tweaking.\n\nChange-Id: I35e0907d87b34dcd09863176b80ff434c3df171b\nbackport: havana\nCloses-Bug: #1285448\n'}, {'number': 4, 'created': '2014-03-05 19:45:38.000000000', 'files': ['doc/config-reference/compute/section_hypervisor_vmware.xml'], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/0090f3864decb4146cd6781350457764e9363861', 'message': 'Reversing a change that incorrectly describes OVS configuration.\n\nThis reverts part of commit I9430afa843cc44694b7aca11793ec0fb640b49c6,\nspecifically removing lines 485-495 and reinstating lines\n486-492 that they replaced. The suggested OVS configuration causes\nall VMs to be placed in a single port group, in which case, no\nNeutron configuration would function properly.\n\nChange-Id: I35e0907d87b34dcd09863176b80ff434c3df171b\nbackport: havana\nCloses-Bug: #1285448\n'}]",7,77011,0090f3864decb4146cd6781350457764e9363861,26,7,4,9454,,,0,"Reversing a change that incorrectly describes OVS configuration.

This reverts part of commit I9430afa843cc44694b7aca11793ec0fb640b49c6,
specifically removing lines 485-495 and reinstating lines
486-492 that they replaced. The suggested OVS configuration causes
all VMs to be placed in a single port group, in which case, no
Neutron configuration would function properly.

Change-Id: I35e0907d87b34dcd09863176b80ff434c3df171b
backport: havana
Closes-Bug: #1285448
",git fetch https://review.opendev.org/openstack/openstack-manuals refs/changes/11/77011/3 && git format-patch -1 --stdout FETCH_HEAD,['doc/config-reference/compute/section_hypervisor_vmware.xml'],1,5ac5676cd557e0c22d370b775b2fcdfc87c96054,bug/1285448," <para>If using the OpenStack Networking Service, before provisioning VMs, create a port group with the same name as the <literal>vmware.integration_bridge</literal> value in <filename>nova.conf</filename> (default is <literal>br-int</literal>). All VM NICs will be attached to this port group for management by the OpenStack Networking plug-in.</para>"," <para><emphasis role=""bold"">The OpenStack Networking Service</emphasis>. If you use <acronym>OVS</acronym> as the l2 agent, create a port group with the same name as the <literal>DEFAULT.neutron_ovs_bridge</literal> value in the <filename>nova.conf</filename> file. Otherwise, create a port group with the same name as the <literal>vmware.integration_bridge</literal> value in the <filename>nova.conf</filename> file. In both cases, the default value is <literal>br-int</literal>.</para> <para>All VM NICs are attached to this port group for management by the OpenStack Networking plug-in.</para>",7,11
openstack%2Fzaqar~master~I92ebe4cc31fe916d117118996070b3d1e9069cf2,openstack/zaqar,master,I92ebe4cc31fe916d117118996070b3d1e9069cf2,Use `sqlite` as the scheme instead of `sqlalchemy`,ABANDONED,2014-03-05 15:36:11.000000000,2014-03-05 20:57:36.000000000,,"[{'_account_id': 3}, {'_account_id': 6944}]","[{'number': 1, 'created': '2014-03-05 15:36:11.000000000', 'files': ['marconi/tests/queues/transport/wsgi/test_shards.py'], 'web_link': 'https://opendev.org/openstack/zaqar/commit/f4729b534842239faadb4b7b72b57a148f5fe189', 'message': 'Use `sqlite` as the scheme instead of `sqlalchemy`\n\nUsing `sqlalchemy` will cause the sqlalchemy to be loaded twice and fail\nat registering the configuration options.\n\nChange-Id: I92ebe4cc31fe916d117118996070b3d1e9069cf2\n'}]",0,78268,f4729b534842239faadb4b7b72b57a148f5fe189,4,2,1,6159,,,0,"Use `sqlite` as the scheme instead of `sqlalchemy`

Using `sqlalchemy` will cause the sqlalchemy to be loaded twice and fail
at registering the configuration options.

Change-Id: I92ebe4cc31fe916d117118996070b3d1e9069cf2
",git fetch https://review.opendev.org/openstack/zaqar refs/changes/68/78268/1 && git format-patch -1 --stdout FETCH_HEAD,['marconi/tests/queues/transport/wsgi/test_shards.py'],1,f4729b534842239faadb4b7b72b57a148f5fe189,," expect = {'weight': 20, 'uri': 'sqlite://other'}"," expect = {'weight': 20, 'uri': 'sqlalchemy://other'}",1,1
openstack-attic%2Fcompute-api~master~I81a9287f629efb2b4005b60a80351b74e020e67c,openstack-attic/compute-api,master,I81a9287f629efb2b4005b60a80351b74e020e67c,Updated from global requirements,MERGED,2014-03-03 03:27:59.000000000,2014-03-05 20:37:29.000000000,2014-03-05 20:37:28.000000000,"[{'_account_id': 3}, {'_account_id': 6547}]","[{'number': 1, 'created': '2014-03-03 03:27:59.000000000', 'files': ['test-requirements.txt'], 'web_link': 'https://opendev.org/openstack-attic/compute-api/commit/82893eec6ee86ab3d42d4d7a027a194a585b4f7f', 'message': 'Updated from global requirements\n\nChange-Id: I81a9287f629efb2b4005b60a80351b74e020e67c\n'}]",0,77482,82893eec6ee86ab3d42d4d7a027a194a585b4f7f,10,2,1,3,,,0,"Updated from global requirements

Change-Id: I81a9287f629efb2b4005b60a80351b74e020e67c
",git fetch https://review.opendev.org/openstack-attic/compute-api refs/changes/82/77482/1 && git format-patch -1 --stdout FETCH_HEAD,['test-requirements.txt'],1,82893eec6ee86ab3d42d4d7a027a194a585b4f7f,openstack/requirements,openstack-doc-tools>=0.8.2,openstack-doc-tools>=0.7.1,1,1
openstack%2Ftempest~master~I5552b44998cd85c39221b8de298629e0b77f99cb,openstack/tempest,master,I5552b44998cd85c39221b8de298629e0b77f99cb,Improve tempest auth tests,MERGED,2014-02-26 13:12:30.000000000,2014-03-05 20:32:49.000000000,2014-03-05 20:32:48.000000000,"[{'_account_id': 3}, {'_account_id': 1921}, {'_account_id': 5174}, {'_account_id': 5196}, {'_account_id': 5689}]","[{'number': 1, 'created': '2014-02-26 13:12:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/fd9b5f1e245014b4f283da095bfbe4d098c42dd3', 'message': 'Improve tempest auth tests.\n\nAdded tests to base_url method.\n\nAlso include general improves to make the fake api response look different\navoiding false positives.\n\nPartially implements bp unit-tests\n\nChange-Id: I5552b44998cd85c39221b8de298629e0b77f99cb\n'}, {'number': 2, 'created': '2014-02-26 13:15:57.000000000', 'files': ['tempest/tests/test_auth.py', 'tempest/tests/fake_identity.py'], 'web_link': 'https://opendev.org/openstack/tempest/commit/4e23c4528a884d1887a0e95beff0aa35fd4196d3', 'message': 'Improve tempest auth tests\n\nAdded tests to base_url method.\n\nAlso include general improves to make the fake api response look different\navoiding false positives.\n\nPartially implements bp unit-tests\n\nChange-Id: I5552b44998cd85c39221b8de298629e0b77f99cb\n'}]",4,76531,4e23c4528a884d1887a0e95beff0aa35fd4196d3,17,5,2,5174,,,0,"Improve tempest auth tests

Added tests to base_url method.

Also include general improves to make the fake api response look different
avoiding false positives.

Partially implements bp unit-tests

Change-Id: I5552b44998cd85c39221b8de298629e0b77f99cb
",git fetch https://review.opendev.org/openstack/tempest refs/changes/31/76531/1 && git format-patch -1 --stdout FETCH_HEAD,"['tempest/tests/test_auth.py', 'tempest/tests/fake_identity.py']",2,fd9b5f1e245014b4f283da095bfbe4d098c42dd3,bp/unit-tests," ""adminURL"": ""http://fake_url/v2/first_endpoint/admin"", ""internalURL"": ""http://fake_url/v2/first_endpoint/internal"", ""publicURL"": ""http://fake_url/v2/first_endpoint/public"" ""adminURL"": ""http://fake_url/v2/second_endpoint/admin"", ""internalURL"": ""http://fake_url/v2/second_endpoint/internal"", ""publicURL"": ""http://fake_url/v2/second_endpoint/public"" ""id"": ""first_compute_fake_service"", ""url"": ""http://fake_url/v3/first_endpoint/api"" ""id"": ""second_fake_service"", ""url"": ""http://fake_url/v3/second_endpoint/api"" }, { ""id"": ""third_fake_service"", ""interface"": ""admin"", ""region"": ""MiddleEarthRegion"", ""url"": ""http://fake_url/v3/third_endpoint/api"" } "," ""adminURL"": ""http://fake_url/api/admin"", ""internalURL"": ""http://fake_url/api/internal"", ""publicURL"": ""http://fake_url/api/public"" ""adminURL"": ""http://fake_url/api/admin"", ""internalURL"": ""http://fake_url/api/internal"", ""publicURL"": ""http://fake_url/api/public"" ""id"": ""fake_service"", ""url"": ""http://fake_url/v3"" ""id"": ""another_fake_service"", ""url"": ""http://fake_url/v3"" }",160,31
openstack%2Fapi-site~master~I61ddc56504e27ebc72ff04cc9bc5cc6f1b8549c8,openstack/api-site,master,I61ddc56504e27ebc72ff04cc9bc5cc6f1b8549c8,Fix validate template path,MERGED,2014-02-28 02:31:32.000000000,2014-03-05 20:27:33.000000000,2014-03-05 20:27:32.000000000,"[{'_account_id': 3}, {'_account_id': 2448}, {'_account_id': 4571}, {'_account_id': 6577}, {'_account_id': 8976}]","[{'number': 1, 'created': '2014-02-28 02:31:32.000000000', 'files': ['api-ref/src/wadls/orchestration-api/src/v1/orchestration-api.wadl'], 'web_link': 'https://opendev.org/openstack/api-site/commit/0ecb80824f1c69bc5b39d44b79eeabb3d9179033', 'message': ""Fix validate template path\n\nfix validate template path,it should be '/validate'\n\nChange-Id: I61ddc56504e27ebc72ff04cc9bc5cc6f1b8549c8\n""}]",0,77039,0ecb80824f1c69bc5b39d44b79eeabb3d9179033,12,5,1,10018,,,0,"Fix validate template path

fix validate template path,it should be '/validate'

Change-Id: I61ddc56504e27ebc72ff04cc9bc5cc6f1b8549c8
",git fetch https://review.opendev.org/openstack/api-site refs/changes/39/77039/1 && git format-patch -1 --stdout FETCH_HEAD,['api-ref/src/wadls/orchestration-api/src/v1/orchestration-api.wadl'],1,0ecb80824f1c69bc5b39d44b79eeabb3d9179033,heat-api-wadl," path=""validate"">"," path=""validate_template"">",1,1
openstack%2Fapi-site~master~I53156eedee5996051bef2cf58e5c06704b222f15,openstack/api-site,master,I53156eedee5996051bef2cf58e5c06704b222f15,Cleaning not implemented credentials methods in in OS-KSADM extension,MERGED,2014-03-03 09:19:47.000000000,2014-03-05 20:22:39.000000000,2014-03-05 20:22:39.000000000,"[{'_account_id': 3}, {'_account_id': 2448}, {'_account_id': 3153}]","[{'number': 1, 'created': '2014-03-03 09:19:47.000000000', 'files': ['api-ref/src/wadls/identity-api/src/v2.0/OS-KSADM/samples/passwordcredentials.xml', 'api-ref/src/wadls/identity-api/src/v2.0/wadl/OS-KSADM-admin.wadl', 'api-ref/src/wadls/identity-api/src/v2.0/OS-KSADM/samples/passwordcredentials.json'], 'web_link': 'https://opendev.org/openstack/api-site/commit/c2514aadbdce383e56738b86f63a87d9f161a19e', 'message': 'Cleaning not implemented credentials methods in in OS-KSADM extension\n\nChange-Id: I53156eedee5996051bef2cf58e5c06704b222f15\nCloses-Bug: #1278847\n'}]",0,77531,c2514aadbdce383e56738b86f63a87d9f161a19e,9,3,1,752,,,0,"Cleaning not implemented credentials methods in in OS-KSADM extension

Change-Id: I53156eedee5996051bef2cf58e5c06704b222f15
Closes-Bug: #1278847
",git fetch https://review.opendev.org/openstack/api-site refs/changes/31/77531/1 && git format-patch -1 --stdout FETCH_HEAD,"['api-ref/src/wadls/identity-api/src/v2.0/OS-KSADM/samples/passwordcredentials.xml', 'api-ref/src/wadls/identity-api/src/v2.0/OS-KSADM/samples/passwordcredentials.json', 'api-ref/src/wadls/identity-api/src/v2.0/wadl/OS-KSADM-admin.wadl']",3,c2514aadbdce383e56738b86f63a87d9f161a19e,bug/1278847,," <resource id=""user-OS-KSADM-v2.0"" path=""OS-KSADM""> <resource id=""enabled-v2.0"" path=""enabled""> <method href=""#setUserEnabled""/> </resource> <resource id=""userCredentials-v2.0"" path=""credentials""> <method href=""#addUserCredential-KSADM""/> <method href=""#listCredentials-KSADM""/> <resource id=""credential-type-v2.0"" path=""{credential-type}""> <param name=""credentialType"" style=""template"" type=""extensibleCredentialsType"" required=""true""> <wadl:doc xmlns=""http://docbook.org/ns/docbook"" xml:lang=""EN""><para>The credential type.</para></wadl:doc> </param> <method href=""#updateUserCredential""/> <method href=""#deleteUserCredential""/> <method href=""#getUserCredential""/> </resource> </resource> </resource> <!-- User Credentials --> <method name=""POST"" id=""addUserCredential-KSADM""> <wadl:doc xmlns=""http://docbook.org/ns/docbook"" xml:lang=""EN"" title=""Add User Credentials""> <para role=""shortdesc"">Adds a credential to a user.</para> </wadl:doc> <request> <representation mediaType=""application/xml"" element=""identity:credential""> <wadl:doc xmlns=""http://docbook.org/ns/docbook"" xml:lang=""EN""> <xsdxt:code href=""../OS-KSADM/samples/passwordcredentials.xml"" /> </wadl:doc> </representation> <representation mediaType=""application/json""> <wadl:doc xmlns=""http://docbook.org/ns/docbook"" xml:lang=""EN""> <xsdxt:code href=""../OS-KSADM/samples/passwordcredentials.json"" /> </wadl:doc> </representation> </request> <response status=""201""> <representation mediaType=""application/xml"" element=""identity:credential""> <wadl:doc xmlns=""http://docbook.org/ns/docbook"" xml:lang=""EN""> <xsdxt:code href=""../OS-KSADM/samples/passwordcredentials.xml"" /> </wadl:doc> </representation> <representation mediaType=""application/json""> <wadl:doc xmlns=""http://docbook.org/ns/docbook"" xml:lang=""EN""> <xsdxt:code href=""../OS-KSADM/samples/passwordcredentials.json"" /> </wadl:doc> </representation> </response> &commonFaults; &postPutFaults; &getFaults; </method> <method name=""GET"" id=""listCredentials-KSADM""> <wadl:doc xmlns=""http://docbook.org/ns/docbook"" xml:lang=""EN"" title=""List Credentials""> <para role=""shortdesc"">Lists credentials.</para> </wadl:doc> <response status=""200 203""> <representation mediaType=""application/xml"" element=""identity:credentials""> <wadl:doc xmlns=""http://docbook.org/ns/docbook"" xml:lang=""EN""> <xsdxt:code href=""../OS-KSADM/samples/credentials.xml""/> </wadl:doc> </representation> <representation mediaType=""application/json""> <wadl:doc xmlns=""http://docbook.org/ns/docbook"" xml:lang=""EN""> <xsdxt:code href=""../OS-KSADM/samples/credentials.json""/> </wadl:doc> </representation> </response> &commonFaults; &getFaults; </method> <method name=""POST"" id=""updateUserCredential""> <wadl:doc xmlns=""http://docbook.org/ns/docbook"" xml:lang=""EN"" title=""Update User Credentials""> <para role=""shortdesc"">Updates credentials for a specified user.</para> </wadl:doc> <request> <representation mediaType=""application/xml"" element=""identity:credential""> <wadl:doc xmlns=""http://docbook.org/ns/docbook"" xml:lang=""EN""> <xsdxt:code href=""../OS-KSADM/samples/passwordcredentials.xml"" /> </wadl:doc> </representation> <representation mediaType=""application/json""> <wadl:doc xmlns=""http://docbook.org/ns/docbook"" xml:lang=""EN""> <xsdxt:code href=""../OS-KSADM/samples/passwordcredentials.json"" /> </wadl:doc> </representation> </request> <response status=""200""> <representation mediaType=""application/xml"" element=""identity:credential""> <wadl:doc xmlns=""http://docbook.org/ns/docbook"" xml:lang=""EN""> <xsdxt:code href=""../OS-KSADM/samples/passwordcredentials.xml"" /> </wadl:doc> </representation> <representation mediaType=""application/json""> <wadl:doc xmlns=""http://docbook.org/ns/docbook"" xml:lang=""EN""> <xsdxt:code href=""../OS-KSADM/samples/passwordcredentials.json"" /> </wadl:doc> </representation> </response> &commonFaults; &postPutFaults; &getFaults; </method> <method name=""DELETE"" id=""deleteUserCredential""> <wadl:doc xmlns=""http://docbook.org/ns/docbook"" xml:lang=""EN"" title=""Delete User Credentials""> <para role=""shortdesc"">Deletes credentials for a specified user.</para> </wadl:doc> <response status=""204""/> &commonFaults; &postPutFaults; &getFaults; </method> <method name=""GET"" id=""getUserCredential""> <wadl:doc xmlns=""http://docbook.org/ns/docbook"" xml:lang=""EN"" title=""Get User Credentials""> <para role=""shortdesc"">Gets user credentials.</para> </wadl:doc> <response status=""200 203""> <representation mediaType=""application/xml"" element=""identity:credential""> <wadl:doc xmlns=""http://docbook.org/ns/docbook"" xml:lang=""EN""> <xsdxt:code href=""../OS-KSADM/samples/passwordcredentials.xml"" /> </wadl:doc> </representation> <representation mediaType=""application/json""> <wadl:doc xmlns=""http://docbook.org/ns/docbook"" xml:lang=""EN""> <xsdxt:code href=""../OS-KSADM/samples/passwordcredentials.json"" /> </wadl:doc> </representation> </response> &commonFaults; &getFaults; </method> ",0,177
openstack%2Fapi-site~master~I3922210426e68f837b629febfa2d48e1d7885a23,openstack/api-site,master,I3922210426e68f837b629febfa2d48e1d7885a23,Fix orchestration WADL for template validate,MERGED,2014-02-27 20:50:38.000000000,2014-03-05 20:21:14.000000000,2014-03-05 20:21:14.000000000,"[{'_account_id': 3}, {'_account_id': 2448}, {'_account_id': 4571}, {'_account_id': 7256}]","[{'number': 1, 'created': '2014-02-27 20:50:38.000000000', 'files': ['api-ref/src/wadls/orchestration-api/src/v1/orchestration-api.wadl'], 'web_link': 'https://opendev.org/openstack/api-site/commit/03fdda48e45634873b674a653b3b63dc320b9ff9', 'message': 'Fix orchestration WADL for template validate\n\ncorrecting the Heat template validate url.\n\nCloses-Bug: #1285856\nChange-Id: I3922210426e68f837b629febfa2d48e1d7885a23\n'}]",0,76961,03fdda48e45634873b674a653b3b63dc320b9ff9,9,4,1,7230,,,0,"Fix orchestration WADL for template validate

correcting the Heat template validate url.

Closes-Bug: #1285856
Change-Id: I3922210426e68f837b629febfa2d48e1d7885a23
",git fetch https://review.opendev.org/openstack/api-site refs/changes/61/76961/1 && git format-patch -1 --stdout FETCH_HEAD,['api-ref/src/wadls/orchestration-api/src/v1/orchestration-api.wadl'],1,03fdda48e45634873b674a653b3b63dc320b9ff9,template_validate," path=""validate"">"," path=""validate_template"">",1,1
openstack-attic%2Fidentity-api~master~Ia26291498b58af40d9598233e69038b1051d3227,openstack-attic/identity-api,master,Ia26291498b58af40d9598233e69038b1051d3227,Updated from global requirements,MERGED,2014-03-03 03:28:55.000000000,2014-03-05 20:19:30.000000000,2014-03-05 20:19:30.000000000,"[{'_account_id': 3}, {'_account_id': 6547}]","[{'number': 1, 'created': '2014-03-03 03:28:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack-attic/identity-api/commit/77669a4544ef8afa9a5193b8693367968a8e02cf', 'message': 'Updated from global requirements\n\nChange-Id: Ia26291498b58af40d9598233e69038b1051d3227\n'}, {'number': 2, 'created': '2014-03-05 19:23:32.000000000', 'files': ['test-requirements.txt'], 'web_link': 'https://opendev.org/openstack-attic/identity-api/commit/0cc8544e285aba94ca72ea9dbf0cf08766149ce0', 'message': 'Updated from global requirements\n\nChange-Id: Ia26291498b58af40d9598233e69038b1051d3227\n'}]",0,77484,0cc8544e285aba94ca72ea9dbf0cf08766149ce0,12,2,2,3,,,0,"Updated from global requirements

Change-Id: Ia26291498b58af40d9598233e69038b1051d3227
",git fetch https://review.opendev.org/openstack-attic/identity-api refs/changes/84/77484/2 && git format-patch -1 --stdout FETCH_HEAD,['test-requirements.txt'],1,77669a4544ef8afa9a5193b8693367968a8e02cf,openstack/requirements,openstack-doc-tools>=0.8.2,openstack-doc-tools>=0.7.1,1,1
openstack-attic%2Fvolume-api~master~Ic8af63b4aeb04c849aeb9a62b07eeccaf911c12a,openstack-attic/volume-api,master,Ic8af63b4aeb04c849aeb9a62b07eeccaf911c12a,Updated from global requirements,MERGED,2014-03-03 03:36:16.000000000,2014-03-05 20:18:20.000000000,2014-03-05 20:18:20.000000000,"[{'_account_id': 3}, {'_account_id': 6547}]","[{'number': 1, 'created': '2014-03-03 03:36:16.000000000', 'files': ['test-requirements.txt'], 'web_link': 'https://opendev.org/openstack-attic/volume-api/commit/7598a945ee3e4ede9173fbea1774602e76ad8d0c', 'message': 'Updated from global requirements\n\nChange-Id: Ic8af63b4aeb04c849aeb9a62b07eeccaf911c12a\n'}]",0,77493,7598a945ee3e4ede9173fbea1774602e76ad8d0c,10,2,1,3,,,0,"Updated from global requirements

Change-Id: Ic8af63b4aeb04c849aeb9a62b07eeccaf911c12a
",git fetch https://review.opendev.org/openstack-attic/volume-api refs/changes/93/77493/1 && git format-patch -1 --stdout FETCH_HEAD,['test-requirements.txt'],1,7598a945ee3e4ede9173fbea1774602e76ad8d0c,openstack/requirements,openstack-doc-tools>=0.8.2,openstack-doc-tools>=0.7.1,1,1
openstack%2Fneutron~master~I9395fea531365b82a0cd16f29d6392199e2d9c22,openstack/neutron,master,I9395fea531365b82a0cd16f29d6392199e2d9c22,Remove unused method update_fixed_ip_lease_expiration,MERGED,2014-03-03 22:53:43.000000000,2014-03-05 20:17:12.000000000,2014-03-05 20:17:11.000000000,"[{'_account_id': 3}, {'_account_id': 841}, {'_account_id': 2592}, {'_account_id': 5170}, {'_account_id': 7823}, {'_account_id': 9681}, {'_account_id': 9732}, {'_account_id': 9787}, {'_account_id': 9845}, {'_account_id': 9925}, {'_account_id': 10116}, {'_account_id': 10184}, {'_account_id': 10192}]","[{'number': 1, 'created': '2014-03-03 22:53:43.000000000', 'files': ['neutron/tests/unit/test_db_plugin.py', 'neutron/db/db_base_plugin_v2.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/17624e21f4812be80ca535a1f119127c021db54e', 'message': 'Remove unused method update_fixed_ip_lease_expiration\n\nThis should have been log removed here:\n\tIfcb4f093c92904ceb896438987d53e692eb7fb26\n\nChange-Id: I9395fea531365b82a0cd16f29d6392199e2d9c22\nCloses-bug: #1287407\n'}]",0,77719,17624e21f4812be80ca535a1f119127c021db54e,20,13,1,4395,,,0,"Remove unused method update_fixed_ip_lease_expiration

This should have been log removed here:
	Ifcb4f093c92904ceb896438987d53e692eb7fb26

Change-Id: I9395fea531365b82a0cd16f29d6392199e2d9c22
Closes-bug: #1287407
",git fetch https://review.opendev.org/openstack/neutron refs/changes/19/77719/1 && git format-patch -1 --stdout FETCH_HEAD,"['neutron/tests/unit/test_db_plugin.py', 'neutron/db/db_base_plugin_v2.py']",2,17624e21f4812be80ca535a1f119127c021db54e,master,,"import datetimefrom neutron.openstack.common import timeutils def update_fixed_ip_lease_expiration(self, context, network_id, ip_address, lease_remaining): expiration = (timeutils.utcnow() + datetime.timedelta(seconds=lease_remaining)) query = context.session.query(models_v2.IPAllocation) query = query.filter_by(network_id=network_id, ip_address=ip_address) try: with context.session.begin(subtransactions=True): fixed_ip = query.one() fixed_ip.expiration = expiration except exc.NoResultFound: LOG.debug(_(""No fixed IP found that matches the network "" ""%(network_id)s and ip address %(ip_address)s.""), {'network_id': network_id, 'ip_address': ip_address}) ",0,37
openstack-attic%2Fimage-api~master~Ib07b647a3a9a12d4f65b99312a5c1f6b7dbdaa8e,openstack-attic/image-api,master,Ib07b647a3a9a12d4f65b99312a5c1f6b7dbdaa8e,Updated from global requirements,MERGED,2014-03-03 03:28:59.000000000,2014-03-05 20:16:59.000000000,2014-03-05 20:16:59.000000000,"[{'_account_id': 3}, {'_account_id': 6547}]","[{'number': 1, 'created': '2014-03-03 03:28:59.000000000', 'files': ['test-requirements.txt'], 'web_link': 'https://opendev.org/openstack-attic/image-api/commit/eeda073a552e7fd2006dc811aa358b50c55fa071', 'message': 'Updated from global requirements\n\nChange-Id: Ib07b647a3a9a12d4f65b99312a5c1f6b7dbdaa8e\n'}]",0,77485,eeda073a552e7fd2006dc811aa358b50c55fa071,10,2,1,3,,,0,"Updated from global requirements

Change-Id: Ib07b647a3a9a12d4f65b99312a5c1f6b7dbdaa8e
",git fetch https://review.opendev.org/openstack-attic/image-api refs/changes/85/77485/1 && git format-patch -1 --stdout FETCH_HEAD,['test-requirements.txt'],1,eeda073a552e7fd2006dc811aa358b50c55fa071,openstack/requirements,openstack-doc-tools>=0.8.2,openstack-doc-tools>=0.7.1,1,1
openstack%2Fapi-site~master~If8315c7b91f3478e6335cedc2d8013ed9a53289e,openstack/api-site,master,If8315c7b91f3478e6335cedc2d8013ed9a53289e,Fix ochestration WADL for resource event,MERGED,2014-02-27 20:33:17.000000000,2014-03-05 20:16:05.000000000,2014-03-05 20:16:05.000000000,"[{'_account_id': 3}, {'_account_id': 2448}, {'_account_id': 7230}, {'_account_id': 7256}]","[{'number': 1, 'created': '2014-02-27 20:33:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/api-site/commit/fabe8a3c184c003e7415d995cf8158a913c2a28b', 'message': 'Fix ochestration WADL for resource event\n\nResource event endpoint url does not contain resource name.\n\nCloses-Bug: #1285849\nChange-Id: If8315c7b91f3478e6335cedc2d8013ed9a53289e\n'}, {'number': 2, 'created': '2014-02-27 20:39:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/api-site/commit/6b2c3a6e6c99d600a010fc1fc0e3a9a4087bd023', 'message': 'Fix ochestration WADL for resource event\n\nThis change adds resource name to the Heat resource event endpoint url.\n\nCloses-Bug: #1285849\nChange-Id: If8315c7b91f3478e6335cedc2d8013ed9a53289e\n'}, {'number': 3, 'created': '2014-02-27 20:41:38.000000000', 'files': ['api-ref/src/wadls/orchestration-api/src/v1/orchestration-api.wadl'], 'web_link': 'https://opendev.org/openstack/api-site/commit/9e428185ff36a00ce05e749bea4fc6e91d0664f0', 'message': 'Fix ochestration WADL for resource event\n\nThis change adds resource name to the Heat resource event endpoint url.\n\nCloses-Bug: #1285849\nChange-Id: If8315c7b91f3478e6335cedc2d8013ed9a53289e\n'}]",0,76960,9e428185ff36a00ce05e749bea4fc6e91d0664f0,16,4,3,7230,,,0,"Fix ochestration WADL for resource event

This change adds resource name to the Heat resource event endpoint url.

Closes-Bug: #1285849
Change-Id: If8315c7b91f3478e6335cedc2d8013ed9a53289e
",git fetch https://review.opendev.org/openstack/api-site refs/changes/60/76960/3 && git format-patch -1 --stdout FETCH_HEAD,['api-ref/src/wadls/orchestration-api/src/v1/orchestration-api.wadl'],1,fabe8a3c184c003e7415d995cf8158a913c2a28b,res_event_data," <resource path=""events"" id=""events3""> <resource path=""{event_id}"" id=""event_id""> <param name=""event_id"" style=""template"" required=""true""> <wadl:doc xmlns=""http://docbook.org/ns/docbook"" xml:lang=""EN""><para>The unique identifier of an event related to the resource in the stack.</para></wadl:doc> </param> <method href=""#event_show""/> </resource>"," </resource> <resource path=""events"" id=""events3""> <resource path=""{event_id}"" id=""event_id""> <param name=""event_id"" style=""template"" required=""true""> <wadl:doc xmlns=""http://docbook.org/ns/docbook"" xml:lang=""EN""><para>The unique identifier of an event related to the resource in the stack.</para></wadl:doc> </param> <method href=""#event_show""/>",14,14
openstack-attic%2Fobject-api~master~I1aca0da594de16837d8cb031074e59307dbf34b2,openstack-attic/object-api,master,I1aca0da594de16837d8cb031074e59307dbf34b2,Updated from global requirements,MERGED,2014-03-03 03:32:55.000000000,2014-03-05 20:14:36.000000000,2014-03-05 20:14:36.000000000,"[{'_account_id': 3}, {'_account_id': 6547}]","[{'number': 1, 'created': '2014-03-03 03:32:55.000000000', 'files': ['test-requirements.txt'], 'web_link': 'https://opendev.org/openstack-attic/object-api/commit/befcd430c32e0c852b2c6a774a9f26d7d3220fae', 'message': 'Updated from global requirements\n\nChange-Id: I1aca0da594de16837d8cb031074e59307dbf34b2\n'}]",0,77486,befcd430c32e0c852b2c6a774a9f26d7d3220fae,10,2,1,3,,,0,"Updated from global requirements

Change-Id: I1aca0da594de16837d8cb031074e59307dbf34b2
",git fetch https://review.opendev.org/openstack-attic/object-api refs/changes/86/77486/1 && git format-patch -1 --stdout FETCH_HEAD,['test-requirements.txt'],1,befcd430c32e0c852b2c6a774a9f26d7d3220fae,openstack/requirements,openstack-doc-tools>=0.8.2,openstack-doc-tools>=0.7.1,1,1
openstack%2Fopenstack-manuals~master~Ieb7a8e097184e5ed60e17f5f29de13efe5ba6239,openstack/openstack-manuals,master,Ieb7a8e097184e5ed60e17f5f29de13efe5ba6239,Added an additional Glance installation verification example.,MERGED,2014-03-05 06:27:20.000000000,2014-03-05 20:07:49.000000000,2014-03-05 20:07:49.000000000,"[{'_account_id': 3}, {'_account_id': 964}, {'_account_id': 6547}, {'_account_id': 7472}]","[{'number': 1, 'created': '2014-03-05 06:27:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/b502b84104f42cc0206e366f126636c790bcf589', 'message': 'Added an additional Glance installation verification example.\n\nAdded an addition of uploading an instance with the --copy-from\noption for Glance, which allows for downloading from the URL\nspecified and also upload to Glance at the same time.\n\nChange-Id: Ieb7a8e097184e5ed60e17f5f29de13efe5ba6239\n'}, {'number': 2, 'created': '2014-03-05 07:29:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/825be3f8ea96fea4662ba01ddad20a82e0c2f23e', 'message': 'Added an additional Glance installation verification example.\n\nAdded an addition of uploading an instance with the --copy-from\noption for Glance, which allows for downloading from the URL\nspecified and also upload to Glance at the same time.\n\nMade a couple small changes.\n\nChange-Id: Ieb7a8e097184e5ed60e17f5f29de13efe5ba6239\n'}, {'number': 3, 'created': '2014-03-05 18:54:48.000000000', 'files': ['doc/install-guide/section_glance-verify.xml'], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/70b3c2951b870e2b80a384cbe2f793bc821f522c', 'message': 'Added an additional Glance installation verification example.\n\nAdded an addition of uploading an instance with the --copy-from\noption for Glance, which allows for downloading from the URL\nspecified and also upload to Glance at the same time.\n\nMade a couple small changes.\n\nChange-Id: Ieb7a8e097184e5ed60e17f5f29de13efe5ba6239\n'}]",2,78113,70b3c2951b870e2b80a384cbe2f793bc821f522c,16,4,3,7472,,,0,"Added an additional Glance installation verification example.

Added an addition of uploading an instance with the --copy-from
option for Glance, which allows for downloading from the URL
specified and also upload to Glance at the same time.

Made a couple small changes.

Change-Id: Ieb7a8e097184e5ed60e17f5f29de13efe5ba6239
",git fetch https://review.opendev.org/openstack/openstack-manuals refs/changes/13/78113/2 && git format-patch -1 --stdout FETCH_HEAD,['doc/install-guide/section_glance-verify.xml'],1,b502b84104f42cc0206e366f126636c790bcf589,78113," <para>Alternatively, the upload to Glance can be done without having to use local disk space to store the file, by use of the <literal>--copy-from</literal> parameter.</para> <para>For example:</para> <screen><prompt>#</prompt> <userinput>glance image-create --name=""CirrOS 0.3.1"" --disk-format=qcow2 \ --container-format=bare --is-public=true --copy-from http://cdn.download.cirros-cloud.net/0.3.1/cirros-0.3.1-x86_64-disk.img</userinput></screen> <screen><computeroutput>+------------------+--------------------------------------+ | Property | Value | +------------------+--------------------------------------+ | checksum | d972013792949d0d3ba628fbe8685bce | | container_format | bare | | created_at | 2014-03-05T06:13:18 | | deleted | False | | disk_format | qcow2 | | id | 3cce1e32-0971-4958-9719-1f92064d4f54 | | is_public | True | | min_disk | 0 | | min_ram | 0 | | name | CirrOS 0.3.1 | | owner | e519b772cb43474582fa303da62559e5 | | protected | False | | size | 13147648 | | status | active | | updated_at | 2014-03-05T06:13:20 | +------------------+--------------------------------------+</computeroutput></screen>",,25,0
openstack%2Fopenstack-manuals~master~Id14ba5a152f6f64e946c7c6e85ae6567a5a65ad0,openstack/openstack-manuals,master,Id14ba5a152f6f64e946c7c6e85ae6567a5a65ad0,updated module001-ch004-openstack-architecture.xml,MERGED,2014-02-28 19:01:03.000000000,2014-03-05 20:07:42.000000000,2014-03-05 20:07:41.000000000,"[{'_account_id': 3}, {'_account_id': 964}, {'_account_id': 4656}, {'_account_id': 6547}, {'_account_id': 6616}, {'_account_id': 6772}, {'_account_id': 9382}, {'_account_id': 9383}]","[{'number': 1, 'created': '2014-02-28 19:01:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/9283f5cab27d7765950a45f47cd6485412c75d6e', 'message': 'updated module001-ch004-openstack-architecture.xml\n\nrenamed all Quantum references to Neutron\nrenamed all quantum-server references to neutron-server\nfixed capitalization/spacing of Open vSwitch\n\nChange-Id: Id14ba5a152f6f64e946c7c6e85ae6567a5a65ad0\n'}, {'number': 2, 'created': '2014-02-28 19:33:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/df7bac5baf33cc683c49208997a9168aad173e26', 'message': ""updated module001-ch004-openstack-architecture.xml\n\nrenamed all Quantum references to Neutron\nrenamed all quantum-server references to neutron-server\nfixed capitalization/spacing of Open vSwitch\nchanged occurrences of it's to its\n\nChange-Id: Id14ba5a152f6f64e946c7c6e85ae6567a5a65ad0\n""}, {'number': 3, 'created': '2014-03-03 18:30:41.000000000', 'files': ['doc/training-guides/module001-ch004-openstack-architecture.xml'], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/55162d0f9b0f922442d3d74cfecc58be16499273', 'message': ""updated module001-ch004-openstack-architecture.xml\n\nrenamed all Quantum references to Neutron\nrenamed all quantum-server references to neutron-server\nchanged a service reference to project reference\nfixed capitalization/spacing of Open vSwitch\nchanged occurrences of it's to its\n\nChange-Id: Id14ba5a152f6f64e946c7c6e85ae6567a5a65ad0\n""}]",1,77243,55162d0f9b0f922442d3d74cfecc58be16499273,26,8,3,9383,,,0,"updated module001-ch004-openstack-architecture.xml

renamed all Quantum references to Neutron
renamed all quantum-server references to neutron-server
changed a service reference to project reference
fixed capitalization/spacing of Open vSwitch
changed occurrences of it's to its

Change-Id: Id14ba5a152f6f64e946c7c6e85ae6567a5a65ad0
",git fetch https://review.opendev.org/openstack/openstack-manuals refs/changes/43/77243/3 && git format-patch -1 --stdout FETCH_HEAD,['doc/training-guides/module001-ch004-openstack-architecture.xml'],1,9283f5cab27d7765950a45f47cd6485412c75d6e,module001-ch004-openstack-architecture," <para>Network (""Neutron"") provides virtual networking for migrated to Neutron, a separate OpenStack service. In the duplicated between nova-network and Neutron.</para> <para>Neutron provides ""network connectivity as a service"" Like many of the OpenStack services, Neutron is highly <para>neutron-server accepts API requests and then routes them to the appropriate Neutron plugin for action.</para> <para>Neutron plugins and agents perform the actual actions the particular cloud. Neutron ships with plugins and OpenFlow products, Open vSwitch, Linux bridging, the Ryu <para>Most Neutron installations will also make use of a neutron-server and various agents as well as a database to <para>Neutron will interact mainly with Nova, where it will <para>Like Neutron, Cinder will mainly interact with Nova,"," <para>Network (""Quantum"") provides virtual networking for migrated to Quantum, a separate OpenStack service. In the duplicated between nova-network and Quantum.</para> <para>Quantum provides ""network connectivity as a service"" Like many of the OpenStack services, Quantum is highly <para>quantum-server accepts API requests and then routes them to the appropriate quantum plugin for action.</para> <para>Quantum plugins and agents perform the actual actions the particular cloud. Quantum ships with plugins and OpenFlow products, Openvswitch, Linux bridging, the Ryu <para>Most Quantum installations will also make use of a quantum-server and various agents as well as a database to <para>Quantum will interact mainly with Nova, where it will <para>Like Quantum, Cinder will mainly interact with Nova,",14,14
openstack%2Fopenstack-manuals~master~I7b53fa7cb9bdd51430e708bedeedb8316488e962,openstack/openstack-manuals,master,I7b53fa7cb9bdd51430e708bedeedb8316488e962,VMware driver now supports ephemeral disks,ABANDONED,2014-03-05 19:43:31.000000000,2014-03-05 19:58:07.000000000,,"[{'_account_id': 3}, {'_account_id': 6547}, {'_account_id': 6772}]","[{'number': 1, 'created': '2014-03-05 19:43:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/8f9ff8e2190a8b62a103ff5fcfb0d431594b58b9', 'message': 'VMware driver now supports ephemeral disks\n\nThe VMware driver now supports ephemeral disks, the limitation listed in\nthe documentation no longer applies.\n\nChange-Id: I7b53fa7cb9bdd51430e708bedeedb8316488e962\nCloses-Bug: #1275033\nbackport: havana\n'}, {'number': 2, 'created': '2014-03-05 19:44:59.000000000', 'files': ['doc/config-reference/compute/section_hypervisor_vmware.xml'], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/630e4612212ebcee12eeeeb536a467dfe365a3f1', 'message': 'VMware driver now supports ephemeral disks\n\nThe VMware driver now supports ephemeral disks, the limitation listed in\nthe documentation no longer applies.\n\nChange-Id: I7b53fa7cb9bdd51430e708bedeedb8316488e962\nCloses-Bug: #1275033\nbackport: havana\n'}]",2,78394,630e4612212ebcee12eeeeb536a467dfe365a3f1,6,3,2,6772,,,0,"VMware driver now supports ephemeral disks

The VMware driver now supports ephemeral disks, the limitation listed in
the documentation no longer applies.

Change-Id: I7b53fa7cb9bdd51430e708bedeedb8316488e962
Closes-Bug: #1275033
backport: havana
",git fetch https://review.opendev.org/openstack/openstack-manuals refs/changes/94/78394/2 && git format-patch -1 --stdout FETCH_HEAD,['doc/config-reference/compute/section_hypervisor_vmware.xml'],1,8f9ff8e2190a8b62a103ff5fcfb0d431594b58b9,,," <listitem> <para><emphasis role=""bold"">Ephemeral Disks</emphasis>. Ephemeral disks are not supported. A future stable release will address this temporary limitation.</para> </listitem>",0,5
openstack%2Fcookbook-openstack-object-storage~master~I1fd8c9ae413f497820bdac7212ce35340f838ec5,openstack/cookbook-openstack-object-storage,master,I1fd8c9ae413f497820bdac7212ce35340f838ec5,remove duplicate attributes from attributes/default.rb,MERGED,2014-03-05 13:07:18.000000000,2014-03-05 19:49:09.000000000,2014-03-05 19:49:09.000000000,"[{'_account_id': 3}, {'_account_id': 216}, {'_account_id': 2340}, {'_account_id': 7128}, {'_account_id': 9884}, {'_account_id': 10479}]","[{'number': 1, 'created': '2014-03-05 13:07:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cookbook-openstack-object-storage/commit/95efaa63abc072e592f3cb25c1e760f001ad3fb4', 'message': 'remove duplicate attributes from attributes/default.rb\n\nWe should be testing with the default attributes, not setting our own,\nfor the default scenario. These were mostly duplicates from the default\nattributes file and none of them require any changes to the tests, so it\nseems they were pretty useless.\n\nChange-Id: I1fd8c9ae413f497820bdac7212ce35340f838ec5\n'}, {'number': 2, 'created': '2014-03-05 13:12:19.000000000', 'files': ['spec/account_spec.rb', 'spec/common_spec.rb', 'spec/proxy_spec.rb', 'spec/management_spec.rb', 'spec/storage-common_spec.rb', 'spec/object_spec.rb', 'spec/rsync_spec.rb', 'spec/ring-repo_spec.rb', 'spec/container_spec.rb', 'spec/disks_spec.rb'], 'web_link': 'https://opendev.org/openstack/cookbook-openstack-object-storage/commit/50300f7df0ea4b2fd84c62b40b1e6a34117fe23d', 'message': 'remove duplicate attributes from attributes/default.rb\n\nWe should be testing with the default attributes, not setting our own,\nfor the default scenario. These were mostly duplicates from the default\nattributes file and none of them require any changes to the tests, so it\nseems they were pretty useless.\n\nImplements: blueprint object-storage-cleanup\nChange-Id: I1fd8c9ae413f497820bdac7212ce35340f838ec5\n'}]",0,78192,50300f7df0ea4b2fd84c62b40b1e6a34117fe23d,12,6,2,2340,,,0,"remove duplicate attributes from attributes/default.rb

We should be testing with the default attributes, not setting our own,
for the default scenario. These were mostly duplicates from the default
attributes file and none of them require any changes to the tests, so it
seems they were pretty useless.

Implements: blueprint object-storage-cleanup
Change-Id: I1fd8c9ae413f497820bdac7212ce35340f838ec5
",git fetch https://review.opendev.org/openstack/cookbook-openstack-object-storage refs/changes/92/78192/2 && git format-patch -1 --stdout FETCH_HEAD,"['spec/account_spec.rb', 'spec/common_spec.rb', 'spec/proxy_spec.rb', 'spec/management_spec.rb', 'spec/object_spec.rb', 'spec/storage-common_spec.rb', 'spec/rsync_spec.rb', 'spec/ring-repo_spec.rb', 'spec/container_spec.rb', 'spec/disks_spec.rb']",10,95efaa63abc072e592f3cb25c1e760f001ad3fb4,bp/object-storage-cleanup,, #------------------- # UBUNTU #------------------- @node.set['platform_family'] = 'debian' @node.set['lsb']['codename'] = 'precise' @node.set['openstack']['object-storage']['release'] = 'havana' @node.set['openstack']['object-storage']['authmode'] = 'swauth' @node.set['openstack']['object-storage']['git_builder_ip'] = '10.0.0.10',0,96
openstack%2Fironic~master~I0ce3cb15796faa9135228145755748fee6f3d6de,openstack/ironic,master,I0ce3cb15796faa9135228145755748fee6f3d6de,Set boot device to PXE when deploying,ABANDONED,2014-02-05 18:32:17.000000000,2014-03-05 19:32:22.000000000,,"[{'_account_id': 3}, {'_account_id': 1726}, {'_account_id': 2889}, {'_account_id': 5805}, {'_account_id': 6773}, {'_account_id': 7711}, {'_account_id': 8106}, {'_account_id': 8968}]","[{'number': 1, 'created': '2014-02-05 18:32:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/0d3d4e28cb634085bae4e52b1a17adc3701b9621', 'message': ""Set boot device to PXE when deploying\n\nWhen deploying a node using the PXE driver, we set the boot device to\n'pxe' (both ipminative and ipmitool understand it), and set it as persistent,\nso after the deployment, the node boots using the PXE selected kernel\n\nPartial-Bug: #1264596\n\nChange-Id: I0ce3cb15796faa9135228145755748fee6f3d6de\n""}, {'number': 2, 'created': '2014-02-06 07:40:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/24193b87846b1a29e239a8e1e4309e305d91fd56', 'message': ""Set boot device to PXE when deploying\n\nWhen deploying a node using the PXE driver, we set the boot device to\n'pxe' (both ipminative and ipmitool understand it), and set it as persistent,\nso after the deployment, the node boots using the PXE selected kernel\n\nPartial-Bug: #1264596\n\nChange-Id: I0ce3cb15796faa9135228145755748fee6f3d6de\n""}, {'number': 3, 'created': '2014-02-17 10:30:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/114df3b523ddfbd418548e212b9c9ae6d0bb30dc', 'message': ""Set boot device to PXE when deploying\n\nWhen deploying a node using the PXE driver, we set the boot device to\n'pxe' (both ipminative and ipmitool understand it), and set it as persistent,\nso after the deployment, the node boots using the PXE selected kernel\n\nPartial-Bug: #1264596\n\nChange-Id: I0ce3cb15796faa9135228145755748fee6f3d6de\n""}, {'number': 4, 'created': '2014-02-18 20:50:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/91bb26c13d11806c9a669c31aabf221f3831810f', 'message': ""Set boot device to PXE when deploying\n\nWhen deploying a node using the PXE driver, we set the boot device to\n'pxe' (both ipminative and ipmitool understand it), and set it as persistent,\nso after the deployment, the node boots using the PXE selected kernel\n\nPartial-Bug: #1264596\n\nChange-Id: I0ce3cb15796faa9135228145755748fee6f3d6de\n""}, {'number': 5, 'created': '2014-02-18 21:05:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/4933b64f90e34b0a2629e3feab1e612797e90b22', 'message': ""Set boot device to PXE when deploying\n\nWhen deploying a node using the PXE driver, we set the boot device to\n'pxe' (both ipminative and ipmitool understand it), and set it as persistent,\nso after the deployment, the node boots using the PXE selected kernel\n\nPartial-Bug: #1264596\n\nChange-Id: I0ce3cb15796faa9135228145755748fee6f3d6de\n""}, {'number': 6, 'created': '2014-02-20 16:20:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/5e61f6af3e270354f062da426513e986d582d082', 'message': ""Set boot device to PXE when deploying\n\nWhen deploying a node using the PXE driver, we set the boot device to\n'pxe' (both ipminative and ipmitool understand it), and set it as persistent,\nso after the deployment, the node boots using the PXE selected kernel\n\nCloses-Bug: #1264596\n\nChange-Id: I0ce3cb15796faa9135228145755748fee6f3d6de\n""}, {'number': 7, 'created': '2014-02-20 19:28:02.000000000', 'files': ['ironic/drivers/modules/pxe.py', 'ironic/conductor/utils.py', 'ironic/drivers/modules/ipmitool.py', 'ironic/drivers/modules/ipminative.py', 'ironic/tests/drivers/test_pxe.py', 'ironic/tests/conductor/test_conductor_utils.py', 'ironic/drivers/pxe.py'], 'web_link': 'https://opendev.org/openstack/ironic/commit/aefaaa0e6e76951be6b4edd7ca8f404d4ebda54d', 'message': ""Set boot device to PXE when deploying\n\nWhen deploying a node using the PXE driver, we set the boot device to\n'pxe' (both ipminative and ipmitool understand it), and set it as persistent,\nso after the deployment, the node boots using the PXE selected kernel\n\nCloses-Bug: #1264596\n\nChange-Id: I0ce3cb15796faa9135228145755748fee6f3d6de\n""}]",22,71332,aefaaa0e6e76951be6b4edd7ca8f404d4ebda54d,52,8,7,1726,,,0,"Set boot device to PXE when deploying

When deploying a node using the PXE driver, we set the boot device to
'pxe' (both ipminative and ipmitool understand it), and set it as persistent,
so after the deployment, the node boots using the PXE selected kernel

Closes-Bug: #1264596

Change-Id: I0ce3cb15796faa9135228145755748fee6f3d6de
",git fetch https://review.opendev.org/openstack/ironic refs/changes/32/71332/7 && git format-patch -1 --stdout FETCH_HEAD,"['ironic/drivers/modules/pxe.py', 'ironic/conductor/utils.py', 'ironic/tests/drivers/test_pxe.py']",3,0d3d4e28cb634085bae4e52b1a17adc3701b9621,set_boot_device," with mock.patch.object(manager_utils, 'node_set_boot_device') as node_set_boot_mock: with task_manager.acquire(self.context, self.node['uuid'], shared=False) as task: state = task.driver.deploy.deploy(task, self.node) self.assertEqual(state, states.DEPLOYING) update_neutron_mock.assert_called_once_with(task, self.node) node_set_boot_mock.assert_calletd_once_with(task, self.node, 'pxe', True) node_power_mock.assert_called_once_with(task, self.node, states.REBOOT) # ensure token file created t_path = pxe._get_token_file_path(self.node['uuid']) token = open(t_path, 'r').read() self.assertEqual(self.context.auth_token, token)"," with task_manager.acquire(self.context, self.node['uuid'], shared=False) as task: state = task.driver.deploy.deploy(task, self.node) self.assertEqual(state, states.DEPLOYING) update_neutron_mock.assert_called_once_with(task, self.node) node_power_mock.assert_called_once_with(task, self.node, states.REBOOT) # ensure token file created t_path = pxe._get_token_file_path(self.node['uuid']) token = open(t_path, 'r').read() self.assertEqual(self.context.auth_token, token)",43,11
openstack%2Fopenstack-manuals~master~I1e3b543f89200b0c04303b8f68ffe1a5b9b1cf3e,openstack/openstack-manuals,master,I1e3b543f89200b0c04303b8f68ffe1a5b9b1cf3e,Install memcached at appropriate times,MERGED,2014-02-28 20:22:59.000000000,2014-03-05 19:31:19.000000000,2014-03-05 19:31:17.000000000,"[{'_account_id': 3}, {'_account_id': 6547}, {'_account_id': 6772}, {'_account_id': 10492}]","[{'number': 1, 'created': '2014-02-28 20:22:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/37a8de556e65cf58ffb3e8f680626d4217e78938', 'message': ""Install memcached at appropriate times\n\nFor yum only, memcached was listed in the 'yum install' along with qpid,\nbut not listed for keystone (which needs it).  It's also used by the\ndashboard, but the docs specify an install there.  This changes the\ndocs to specify installing memcached when it's needed.\n\nChange-Id: I1e3b543f89200b0c04303b8f68ffe1a5b9b1cf3e\n""}, {'number': 2, 'created': '2014-02-28 21:09:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/29b2b5b0a0b8a7f91fefa8c022592cbef2b1ff99', 'message': ""Install memcached at appropriate times\n\nFor yum only, memcached was listed in the 'yum install' along with qpid,\nbut not listed for keystone (which needs it).  It's also used by the\ndashboard, but the docs specify an install there.  This changes the\ndocs to specify installing memcached when it's needed.\n\nChange-Id: I1e3b543f89200b0c04303b8f68ffe1a5b9b1cf3e\n""}, {'number': 3, 'created': '2014-03-05 18:45:10.000000000', 'files': ['doc/install-guide/ch_basics.xml'], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/c02266244f0865fb6ed91b0ba15d232191876bd7', 'message': ""Install memcached at appropriate times\n\nFor yum only, memcached was listed in the 'yum install' along with qpid\nbut not needed there. Thus remove the extra install.\n\nChange-Id: I1e3b543f89200b0c04303b8f68ffe1a5b9b1cf3e\n""}]",1,77263,c02266244f0865fb6ed91b0ba15d232191876bd7,22,4,3,10492,,,0,"Install memcached at appropriate times

For yum only, memcached was listed in the 'yum install' along with qpid
but not needed there. Thus remove the extra install.

Change-Id: I1e3b543f89200b0c04303b8f68ffe1a5b9b1cf3e
",git fetch https://review.opendev.org/openstack/openstack-manuals refs/changes/63/77263/2 && git format-patch -1 --stdout FETCH_HEAD,"['doc/install-guide/ch_basics.xml', 'doc/install-guide/section_keystone-install.xml']",2,37a8de556e65cf58ffb3e8f680626d4217e78938,memcached-usage," <screen os=""rhel;centos;fedora""><prompt>#</prompt> <userinput>yum install openstack-keystone python-keystoneclient memcached</userinput></screen>"," <screen os=""rhel;centos;fedora""><prompt>#</prompt> <userinput>yum install openstack-keystone python-keystoneclient</userinput></screen>",2,2
openstack%2Ftempest~master~I5946134de7038a3a7da236dac7018c211cbcce97,openstack/tempest,master,I5946134de7038a3a7da236dac7018c211cbcce97,Adds scenario for hotplug nic in network_basic_ops,MERGED,2014-01-27 13:06:55.000000000,2014-03-05 19:31:09.000000000,2014-03-05 19:31:08.000000000,"[{'_account_id': 3}, {'_account_id': 7}, {'_account_id': 105}, {'_account_id': 261}, {'_account_id': 490}, {'_account_id': 704}, {'_account_id': 748}, {'_account_id': 841}, {'_account_id': 1192}, {'_account_id': 1653}, {'_account_id': 1689}, {'_account_id': 2031}, {'_account_id': 2035}, {'_account_id': 2592}, {'_account_id': 2874}, {'_account_id': 4395}, {'_account_id': 4694}, {'_account_id': 5689}, {'_account_id': 5803}, {'_account_id': 6316}, {'_account_id': 6683}, {'_account_id': 6796}, {'_account_id': 8576}, {'_account_id': 9008}]","[{'number': 1, 'created': '2014-01-27 13:06:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/a95af686d2bc34c7338c53540fff8aa70a882b67', 'message': 'Scenario for hotplug nic\n\nTests attaching new network to a live VM\n\nChange-Id: I5946134de7038a3a7da236dac7018c211cbcce97\n'}, {'number': 2, 'created': '2014-01-27 13:11:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/b6d1347ec65a56b56d0c360be9286ef35a9ff8b0', 'message': 'Scenario for hotplug nic\n\nTests attaching new network to a live VM\n\nChange-Id: I5946134de7038a3a7da236dac7018c211cbcce97\n'}, {'number': 3, 'created': '2014-02-17 13:01:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/36c17abf496ae299c9ee38a1256e26fb6c7cc2a2', 'message': 'Adds scenario for hotplug nic in network_basic_ops\n\nNew scenario test verifying add network to an active VM.\n\nTest is added to network_basic_ops module as most of the code already exists\nthere.\n\nPartially Implements: blueprint neutron-advanced-scenarios\n\nChange-Id: I5946134de7038a3a7da236dac7018c211cbcce97\n'}, {'number': 4, 'created': '2014-02-17 13:05:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/0dc3e35c61bd62c08a1ccb36b498f33ec3c0c372', 'message': 'Adds scenario for hotplug nic in network_basic_ops\n\nNew scenario test verifying add network to an active VM.\n\nTest is added to network_basic_ops module as most of the code already exists\nthere.\n\nPartially Implements: blueprint neutron-advanced-scenarios\n\nChange-Id: I5946134de7038a3a7da236dac7018c211cbcce97\n'}, {'number': 5, 'created': '2014-02-17 16:21:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/0a0f35232ebb25031a9d5aa6b6f1993551472a4a', 'message': 'Adds scenario for hotplug nic in network_basic_ops\n\nNew scenario test verifying add network to an active VM.\n\nTest is added to network_basic_ops module as most of the code already exists\nthere.\n\nPartially Implements: blueprint neutron-advanced-scenarios\n\nChange-Id: I5946134de7038a3a7da236dac7018c211cbcce97\n'}, {'number': 6, 'created': '2014-02-17 20:31:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/b59adf68add52baadb3a619b292f861b1ee357cf', 'message': 'Adds scenario for hotplug nic in network_basic_ops\n\nNew scenario test verifying add network to an active VM.\n\nTest is added to network_basic_ops module as most of the code already exists\nthere.\n\nPartially Implements: blueprint neutron-advanced-scenarios\n\nChange-Id: I5946134de7038a3a7da236dac7018c211cbcce97\n'}, {'number': 7, 'created': '2014-02-17 23:14:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/4d1900f13642ea69518177a3b16d3b95decd0e94', 'message': 'Adds scenario for hotplug nic in network_basic_ops\n\nNew scenario test verifying add network to an active VM.\n\nTest is added to network_basic_ops module as most of the code already exists\nthere.\n\nPartially Implements: blueprint neutron-advanced-scenarios\n\nChange-Id: I5946134de7038a3a7da236dac7018c211cbcce97\n'}, {'number': 8, 'created': '2014-02-18 06:23:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/0a547f4a6d0e940129bf8c879c43e6ebad08524e', 'message': 'Adds scenario for hotplug nic in network_basic_ops\n\nNew scenario test verifying add network to an active VM.\n\nTest is added to network_basic_ops module as most of the code already exists\nthere.\n\nPartially Implements: blueprint neutron-advanced-scenarios\n\nChange-Id: I5946134de7038a3a7da236dac7018c211cbcce97\n'}, {'number': 9, 'created': '2014-02-18 07:36:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/d0da32bcf88b2663385659539946a3205d14f779', 'message': 'Adds scenario for hotplug nic in network_basic_ops\n\nNew scenario test verifying add network to an active VM.\n\nTest is added to network_basic_ops module as most of the code already exists\nthere.\n\nPartially Implements: blueprint neutron-advanced-scenarios\n\nChange-Id: I5946134de7038a3a7da236dac7018c211cbcce97\n'}, {'number': 10, 'created': '2014-02-19 20:27:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/794ed59c80b5d25e6037dbcff74d37d78d47b001', 'message': 'Adds scenario for hotplug nic in network_basic_ops\n\nNew scenario test verifying add network to an active VM.\n\nTest is added to network_basic_ops module as most of the code already exists\nthere.\n\nPartially Implements: blueprint neutron-advanced-scenarios\n\nChange-Id: I5946134de7038a3a7da236dac7018c211cbcce97\n'}, {'number': 11, 'created': '2014-02-20 08:02:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/2bdd3d8c401be1f19257618a04e4f0ccf5fb2031', 'message': 'Adds scenario for hotplug nic in network_basic_ops\n\nNew scenario test verifying add network to an active VM.\n\nTest is added to network_basic_ops module as most of the code already exists\nthere.\n\nPartially Implements: blueprint neutron-advanced-scenarios\n\nChange-Id: I5946134de7038a3a7da236dac7018c211cbcce97\n'}, {'number': 12, 'created': '2014-02-23 08:23:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/4194bec73a9b10f07a9053bdca6d068d49285697', 'message': 'Adds scenario for hotplug nic in network_basic_ops\n\nNew scenario test verifying add network to an active VM.\n\nTest is added to network_basic_ops module as most of the code already exists\nthere.\n\nPartially Implements: blueprint neutron-advanced-scenarios\n\nChange-Id: I5946134de7038a3a7da236dac7018c211cbcce97\n'}, {'number': 13, 'created': '2014-02-24 14:50:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/180e65eb26e0cc7038d7652b920dd4aaed1ee9f7', 'message': 'Adds scenario for hotplug nic in network_basic_ops\n\nNew scenario test verifying add network to an active VM.\n\nTest is added to network_basic_ops module as most of the code already exists\nthere.\n\nPartially Implements: blueprint neutron-advanced-scenarios\n\nChange-Id: I5946134de7038a3a7da236dac7018c211cbcce97\n'}, {'number': 14, 'created': '2014-02-24 18:46:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/bafa1f020442361b431b7542ee3d668c25b9ba6f', 'message': 'Adds scenario for hotplug nic in network_basic_ops\n\nNew scenario test verifying add network to an active VM.\n\nTest is added to network_basic_ops module as most of the code already exists\nthere.\n\nPartially Implements: blueprint neutron-advanced-scenarios\n\nChange-Id: I5946134de7038a3a7da236dac7018c211cbcce97\n'}, {'number': 15, 'created': '2014-02-24 19:22:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/a83c3c0802bab25ad58701e4765b0b2a9f740a62', 'message': 'Adds scenario for hotplug nic in network_basic_ops\n\nNew scenario test verifying add network to an active VM.\n\nTest is added to network_basic_ops module as most of the code already exists\nthere.\n\nPartially Implements: blueprint neutron-advanced-scenarios\n\nChange-Id: I5946134de7038a3a7da236dac7018c211cbcce97\n'}, {'number': 16, 'created': '2014-02-24 20:38:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/550b87ea53a306fa7f99c58ff7bd8d90fd717c13', 'message': 'Adds scenario for hotplug nic in network_basic_ops\n\nNew scenario test verifying add network to an active VM.\n\nTest is added to network_basic_ops module as most of the code already exists\nthere.\n\nPartially Implements: blueprint neutron-advanced-scenarios\n\nChange-Id: I5946134de7038a3a7da236dac7018c211cbcce97\n'}, {'number': 17, 'created': '2014-02-25 08:19:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/f6fb1d20d54cb665a5834a7948659674cd2f70b1', 'message': 'Adds scenario for hotplug nic in network_basic_ops\n\nNew scenario test verifying add network to an active VM.\n\nTest is added to network_basic_ops module as most of the code already exists\nthere.\n\nPartially Implements: blueprint neutron-advanced-scenarios\n\nChange-Id: I5946134de7038a3a7da236dac7018c211cbcce97\n'}, {'number': 18, 'created': '2014-02-26 08:18:07.000000000', 'files': ['tempest/scenario/manager.py', 'tempest/common/utils/linux/remote_client.py', 'tempest/scenario/test_network_basic_ops.py', 'tempest/scenario/test_security_groups_basic_ops.py'], 'web_link': 'https://opendev.org/openstack/tempest/commit/3097dc1262f560d59e9bea9ffd8f94b148b1c843', 'message': 'Adds scenario for hotplug nic in network_basic_ops\n\nNew scenario test verifying add network to an active VM.\n\nTest is added to network_basic_ops module as most of the code already exists\nthere.\n\nPartially Implements: blueprint neutron-advanced-scenarios\n\nChange-Id: I5946134de7038a3a7da236dac7018c211cbcce97\n'}]",19,69361,3097dc1262f560d59e9bea9ffd8f94b148b1c843,117,24,18,8576,,,0,"Adds scenario for hotplug nic in network_basic_ops

New scenario test verifying add network to an active VM.

Test is added to network_basic_ops module as most of the code already exists
there.

Partially Implements: blueprint neutron-advanced-scenarios

Change-Id: I5946134de7038a3a7da236dac7018c211cbcce97
",git fetch https://review.opendev.org/openstack/tempest refs/changes/61/69361/18 && git format-patch -1 --stdout FETCH_HEAD,"['tempest/common/utils/linux/remote_client.py', 'tempest/scenario/manager.py', 'tempest/scenario/test_hotplug_nic.py']",3,a95af686d2bc34c7338c53540fff8aa70a882b67,bp/neutron-advanced-scenarios,"# Licensed under the Apache License, Version 2.0 (the ""License""); you may # not use this file except in compliance with the License. You may obtain # a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT # WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the # License for the specific language governing permissions and limitations # under the License. import re import tempest from tempest.api.network import common as net_common from tempest.common import debug from tempest.common.utils import data_utils from tempest import config from tempest.openstack.common import log as logging from tempest.scenario import manager from tempest.test import attr from tempest.test import services CONF = config.CONF LOG = logging.getLogger(__name__) class TestHotplugNic(manager.NetworkScenarioTest): """""" This smoke test suite assumes that Nova has been configured to boot VM's with Neutron-managed networking, and attempts to add network interface to VM: 1. boot a VM with floating ip 2. check connectivity to VM 3. create a new network, with no GW (to prevent overwriting VM's GW) 4. connect VM to new network 5. get dhcp for new interface 6. attach Floating IP to new interface 7. check connectivity to new interface """""" @classmethod def check_preconditions(cls): super(TestHotplugNic, cls).check_preconditions() cfg = cls.config.network if not (cfg.tenant_networks_reachable or cfg.public_network_id): msg = ('Either tenant_networks_reachable must be ""true"", or ' 'public_network_id must be defined.') cls.enabled = False raise cls.skipException(msg) @classmethod def setUpClass(cls): super(TestHotplugNic, cls).setUpClass() cls.check_preconditions() # TODO(mnewby) Consider looking up entities as needed instead # of storing them as collections on the class. cls.security_groups = {} cls.networks = [] cls.subnets = [] cls.routers = [] cls.servers = {} cls.floating_ips = {} def _create_security_groups(self): self.security_groups[self.tenant_id] =\ self._create_security_group_neutron(tenant_id=self.tenant_id) def _check_networks(self): # Checks that we see the newly created network/subnet/router via # checking the result of list_[networks,routers,subnets] seen_nets = self._list_networks() seen_names = [n['name'] for n in seen_nets] seen_ids = [n['id'] for n in seen_nets] for mynet in self.networks: self.assertIn(mynet.name, seen_names) self.assertIn(mynet.id, seen_ids) seen_subnets = self._list_subnets() seen_net_ids = [n['network_id'] for n in seen_subnets] seen_subnet_ids = [n['id'] for n in seen_subnets] for mynet in self.networks: self.assertIn(mynet.id, seen_net_ids) for mysubnet in self.subnets: self.assertIn(mysubnet.id, seen_subnet_ids) seen_routers = self._list_routers() seen_router_ids = [n['id'] for n in seen_routers] seen_router_names = [n['name'] for n in seen_routers] for myrouter in self.routers: self.assertIn(myrouter.name, seen_router_names) self.assertIn(myrouter.id, seen_router_ids) def _create_server(self, name, network): tenant_id = network.tenant_id keypair = self.create_keypair(name='keypair-%s' % name) security_groups = [self.security_groups[tenant_id].name] create_kwargs = { 'nics': [ {'net-id': network.id}, ], 'key_name': keypair.name, 'security_groups': security_groups, } server = self.create_server(name=name, create_kwargs=create_kwargs) self.servers[server] = keypair return server def _create_servers(self): name = data_utils.rand_name('server-smoke') self._create_server(name, self.networks[0]) def _create_and_associate_floating_ips(self): public_network_id = CONF.network.public_network_id for server in self.servers.keys(): floating_ip = self._create_floating_ip(server, public_network_id) self.floating_ips[floating_ip] = server def _check_public_network_connectivity(self, should_connect=True): # The target login is assumed to have been configured for # key-based authentication by cloud-init. ssh_login = CONF.compute.image_ssh_user LOG.debug('checking network connections') try: for floating_ip, server in self.floating_ips.iteritems(): ip_address = floating_ip.floating_ip_address private_key = None if should_connect: private_key = self.servers[server].private_key self._check_vm_connectivity(ip_address, ssh_login, private_key, should_connect=should_connect) except Exception: LOG.exception('Public network connectivity check failed') self._log_console_output( servers=[server for server in self.servers]) debug.log_ip_ns() raise def _create_networks(self, tenant_id=None): super(TestHotplugNic, self)._create_networks(tenant_id) self.new_net = self._create_network(self.tenant_id) self.networks.append(self.new_net) self.new_subnet = self._create_subnet( network=self.new_net, cidr_list=(s.cidr for s in self.subnets), gateway_ip=None) self.subnets.append(self.new_subnet) def _hotplug_server(self): [old_floating_ip] = self.floating_ips server = self.floating_ips[old_floating_ip] ip_address = old_floating_ip.floating_ip_address private_key = self.servers[server].private_key ssh_client = self.get_remote_client(ip_address, private_key=private_key) old_nic_list = self._get_server_nics(ssh_client) server = self.servers.keys()[0] [old_port] = self._list_ports(device_id=server.id) self.compute_client.servers.interface_attach(server=server, net_id=self.new_net.id, port_id=None, fixed_ip=None) def check_ports(): port_list = [p for p in self._list_ports(device_id=server.id) if p != old_port] return len(port_list) == 1 tempest.test.call_until_true(check_ports, 60, 1) [new_port] = [p for p in self._list_ports(device_id=server.id) if p != old_port] new_port = net_common.DeletablePort(client=self.network_client, **new_port) new_nic_list = self._get_server_nics(ssh_client) [(num, new_nic)] = [n for n in new_nic_list if n not in old_nic_list] ssh_client.assign_static_ip(nic=new_nic, addr=new_port.fixed_ips[0]['ip_address']) ssh_client.turn_nic_on(nic=new_nic) def _get_server_nics(self, ssh_client): reg = re.compile(r'(?P<num>\d+): (?P<nic_name>\w+):') ipatxt = ssh_client.get_ip_list() return reg.findall(ipatxt) def _check_remote_connectivity(self, source, dest): """"""Check ping server via source ssh source must be remote_client :returns: whether pinging the remote host succeeds """""" def ping_remote(): try: source.ping_host(dest) except tempest.exceptions.SSHExecCommandFailed: LOG.exception('SSH error in invoking command') return False return True return tempest.test.call_until_true(ping_remote, self.config.compute.ping_timeout, 1) def _check_network_internal_connectivity(self): """""" via ssh check VM internal connectivity: - ping internal DHCP port, implying in-tenant connectivty """""" for floating_ip, server in self.floating_ips.iteritems(): # get internal ports' ips: # get all network ports in the new network internal_ips = (p['fixed_ips'][0]['ip_address'] for p in self._list_ports(tenant_id=server.tenant_id, network_id=self.new_net.id) if p['device_owner'].startswith('network')) ip_address = floating_ip.floating_ip_address private_key = self.servers[server].private_key ssh_source = self._ssh_to_server(ip_address, private_key) for remote_ip in internal_ips: try: self.assertTrue(self._check_remote_connectivity(ssh_source, remote_ip), ""Timed out waiting for %s to become "" ""reachable"" % remote_ip) except Exception as exc: LOG.exception(""Unable to access {dest} via ssh to "" ""floating-ip {src}"".format(dest=remote_ip, src=floating_ip)) debug.log_ip_ns() raise exc @attr(type='smoke') @services('compute', 'network') def test_hotplug_nic(self): self._create_security_groups() self._create_networks() self._check_networks() self._create_servers() self._create_and_associate_floating_ips() self._check_public_network_connectivity(should_connect=True) self._hotplug_server() self._check_network_internal_connectivity() ",,294,22
openstack%2Fpython-neutronclient~master~I9c2c2474b2bfe8c8f8c3c3cc1513d2b999643d14,openstack/python-neutronclient,master,I9c2c2474b2bfe8c8f8c3c3cc1513d2b999643d14,Adds delete of extra-dhcp-opt to the client,MERGED,2013-10-01 15:13:00.000000000,2014-03-05 19:31:06.000000000,2014-03-05 19:31:06.000000000,"[{'_account_id': 3}, {'_account_id': 2592}, {'_account_id': 4395}, {'_account_id': 5572}, {'_account_id': 7882}, {'_account_id': 8449}]","[{'number': 4, 'created': '2013-10-01 15:13:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-neutronclient/commit/7864d62de19badb7a89a772247d855ae0452c8b1', 'message': 'Adds delete of extra-dhcp-opt to the client\n\nAdd support to delete existing extra-dhcp-opt(s) for a port\nvia the port-update operation.\n\nChange-Id: I9c2c2474b2bfe8c8f8c3c3cc1513d2b999643d14\nCloses-Bug: 1228008\n'}, {'number': 1, 'created': '2013-10-01 15:13:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-neutronclient/commit/2553c82751c4571e91192c51b86a3b42444007c9', 'message': 'Adds delete of extra-dhcp-opt to the client\n\nAdd support to delete existing extra-dhcp-opt(s) for a port\nvia the port-update operation.\n\nChange-Id: I9c2c2474b2bfe8c8f8c3c3cc1513d2b999643d14\nCloses-Bug: 1228008\n'}, {'number': 3, 'created': '2013-10-01 15:13:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-neutronclient/commit/5064ff9daf92d53e2fcca6b20e2b26c40d8b3979', 'message': 'Adds delete of extra-dhcp-opt to the client\n\nAdd support to delete existing extra-dhcp-opt(s) for a port\nvia the port-update operation.\n\nChange-Id: I9c2c2474b2bfe8c8f8c3c3cc1513d2b999643d14\nCloses-Bug: 1228008\n'}, {'number': 2, 'created': '2013-10-01 15:13:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-neutronclient/commit/4d7f1b3fb14246ee4c915daf8dce571605d9f233', 'message': 'Adds delete of extra-dhcp-opt to the client\n\nAdd support to delete existing extra-dhcp-opt(s) for a port\nvia the port-update operation.\n\nChange-Id: I9c2c2474b2bfe8c8f8c3c3cc1513d2b999643d14\nCloses-Bug: 1228008\n'}, {'number': 5, 'created': '2013-12-24 16:21:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-neutronclient/commit/210b72c0da7e9f3fd07b279f5d60d763dca0730e', 'message': 'Adds delete of extra-dhcp-opt to the client\n\nAdd support to delete existing extra-dhcp-opt(s) for a port\nvia the port-update operation. To use it, set the opt_value=null\nof the opt_name that you want deleted (i.e. neutron port-update\n--extra-dhcp-opt opt_name=tftp-server,opt_value=null), which will\ndelete this DHCP option from the port.\n\nChange-Id: I9c2c2474b2bfe8c8f8c3c3cc1513d2b999643d14\nCloses-Bug: 1228008\n'}, {'number': 6, 'created': '2014-02-20 17:23:10.000000000', 'files': ['neutronclient/tests/unit/test_cli20_port.py', 'neutronclient/neutron/v2_0/port.py'], 'web_link': 'https://opendev.org/openstack/python-neutronclient/commit/3a9bd27f338b57f913cf61bb3df48dbc7ee5215c', 'message': 'Adds delete of extra-dhcp-opt to the client\n\nAdd support to delete existing extra-dhcp-opt(s) for a port\nvia the port-update operation. To use it, set the opt_value=null\nof the opt_name that you want deleted (i.e. neutron port-update\n--extra-dhcp-opt opt_name=tftp-server,opt_value=null), which will\ndelete this DHCP option from the port.\n\nChange-Id: I9c2c2474b2bfe8c8f8c3c3cc1513d2b999643d14\nCloses-Bug: 1228008\n'}]",6,49166,3a9bd27f338b57f913cf61bb3df48dbc7ee5215c,65,6,6,5572,,,0,"Adds delete of extra-dhcp-opt to the client

Add support to delete existing extra-dhcp-opt(s) for a port
via the port-update operation. To use it, set the opt_value=null
of the opt_name that you want deleted (i.e. neutron port-update
--extra-dhcp-opt opt_name=tftp-server,opt_value=null), which will
delete this DHCP option from the port.

Change-Id: I9c2c2474b2bfe8c8f8c3c3cc1513d2b999643d14
Closes-Bug: 1228008
",git fetch https://review.opendev.org/openstack/python-neutronclient refs/changes/66/49166/5 && git format-patch -1 --stdout FETCH_HEAD,['neutronclient/neutron/v2_0/port.py'],1,7864d62de19badb7a89a772247d855ae0452c8b1,bug/1228008, if opt_ele['opt_value'] == 'null': opt_ele['opt_value'] = None,,2,0
openstack%2Fneutron~master~I4a48a13202a4125f032a3e80aa567f7979d2c335,openstack/neutron,master,I4a48a13202a4125f032a3e80aa567f7979d2c335,Do fip_status migration only for l3-capable plugins,MERGED,2014-03-04 16:15:46.000000000,2014-03-05 19:30:58.000000000,2014-03-05 19:30:56.000000000,"[{'_account_id': 3}, {'_account_id': 261}, {'_account_id': 490}, {'_account_id': 841}, {'_account_id': 2592}, {'_account_id': 4727}, {'_account_id': 5170}, {'_account_id': 9008}, {'_account_id': 9732}, {'_account_id': 9845}, {'_account_id': 9925}, {'_account_id': 10116}, {'_account_id': 10153}, {'_account_id': 10184}, {'_account_id': 10294}]","[{'number': 1, 'created': '2014-03-04 16:15:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/2aa7cf4838e425f83c32fc37acdc325fffd42c21', 'message': 'Do fip_status migration only for l3-capable plugins\n\nThe migration was initially performed for all plugins, causing\nfailures for plugins for which the initial L3 migration was\nnot performed.\n\nChange-Id: I4a48a13202a4125f032a3e80aa567f7979d2c335\nCloses-Bug: 1287630\n'}, {'number': 2, 'created': '2014-03-04 19:41:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/1128ea324784fc3067bb1c8a4638831128d28c3f', 'message': 'Do fip_status migration only for l3-capable plugins\n\nThe migration was initially performed for all plugins, causing\nfailures for plugins for which the initial L3 migration was\nnot performed.\n\nChange-Id: I4a48a13202a4125f032a3e80aa567f7979d2c335\nCloses-Bug: 1287630\n'}, {'number': 3, 'created': '2014-03-05 06:20:04.000000000', 'files': ['neutron/db/migration/alembic_migrations/versions/2eeaf963a447_floatingip_status.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/e0f8e3e36f460c19e12987098e025705b3049c85', 'message': 'Do fip_status migration only for l3-capable plugins\n\nThe migration was initially performed for all plugins, causing\nfailures for plugins for which the initial L3 migration was\nnot performed.\n\nChange-Id: I4a48a13202a4125f032a3e80aa567f7979d2c335\nCloses-Bug: 1287630\n'}]",0,77927,e0f8e3e36f460c19e12987098e025705b3049c85,41,15,3,261,,,0,"Do fip_status migration only for l3-capable plugins

The migration was initially performed for all plugins, causing
failures for plugins for which the initial L3 migration was
not performed.

Change-Id: I4a48a13202a4125f032a3e80aa567f7979d2c335
Closes-Bug: 1287630
",git fetch https://review.opendev.org/openstack/neutron refs/changes/27/77927/2 && git format-patch -1 --stdout FETCH_HEAD,['neutron/db/migration/alembic_migrations/versions/2eeaf963a447_floatingip_status.py'],1,2aa7cf4838e425f83c32fc37acdc325fffd42c21,bug/1287630,"# This migration is applied to all L3 capable plugins 'neutron.plugins.bigswitch.plugin.NeutronRestProxyV2', 'neutron.plugins.brocade.NeutronPlugin.BrocadePluginV2', 'neutron.plugins.hyperv.hyperv_neutron_plugin.HyperVNeutronPlugin', 'neutron.plugins.ibm.sdnve_neutron_plugin.SdnvePluginV2' 'neutron.plugins.linuxbridge.lb_neutron_plugin.LinuxBridgePluginV2', 'neutron.plugins.metaplugin.meta_neutron_plugin.MetaPluginV2', 'neutron.plugins.midonet.plugin.MidonetPluginV2', 'neutron.plugins.nec.nec_plugin.NECPluginV2', 'neutron.plugins.nicira.NeutronPlugin.NvpPluginV2', 'neutron.plugins.nicira.NeutronServicePlugin.NvpAdvancedPlugin', 'neutron.plugins.openvswitch.ovs_neutron_plugin.OVSNeutronPluginV2', 'neutron.plugins.plumgrid.plumgrid_plugin.plumgrid_plugin.' 'NeutronPluginPLUMgridV2', 'neutron.plugins.ryu.ryu_neutron_plugin.RyuNeutronPluginV2', 'neutron.plugins.vmware.plugin.NsxPlugin', 'neutron.plugins.vmware.plugin.NsxServicePlugin',",# Change to ['*'] if this migration applies to all plugins '*',17,2
openstack%2Fceilometer~master~I445bcdb3f8ac240d1799bfd31f8b888982d7d97f,openstack/ceilometer,master,I445bcdb3f8ac240d1799bfd31f8b888982d7d97f,VMware vSphere support: Performance Mgr APIs,MERGED,2014-02-15 14:18:12.000000000,2014-03-05 19:30:51.000000000,2014-03-05 19:30:50.000000000,"[{'_account_id': 3}, {'_account_id': 1653}, {'_account_id': 1669}, {'_account_id': 2284}, {'_account_id': 2813}, {'_account_id': 4491}, {'_account_id': 6537}, {'_account_id': 7992}, {'_account_id': 8155}, {'_account_id': 9046}, {'_account_id': 9171}, {'_account_id': 9172}, {'_account_id': 9562}, {'_account_id': 10106}, {'_account_id': 10356}]","[{'number': 1, 'created': '2014-02-15 14:18:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/67c0165f8ddb99fcfde16b69ccafc4e26fe28d6a', 'message': ""VMware vSphere support\n\n(*) Copied the following utility files to execute vSphere queries from\n'cinder'. These common utility files are going to be converted to a\nlibrary as a part of blueprint 'vmware-api' but till then these files\nwill be used as it is.\n\n   api.py,\n   error_util.py,\n   vim.py,\n   vim_util.py\n\n(*) Using the above mentioned utilities, implemented a wrapper class for\nquerying performance stats from VC.\n\nChange-Id: I445bcdb3f8ac240d1799bfd31f8b888982d7d97f\nImplements: blueprint vmware-vcenter-server\n""}, {'number': 2, 'created': '2014-02-15 15:14:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/bca0e45dff2fca657c2626a4bf9677bcd07d4c2c', 'message': ""VMware vSphere support\n\n(*) Copied the following utility files to execute vSphere queries from\n'cinder'. These common utility files are going to be converted to a\nlibrary as a part of blueprint 'vmware-api' but till then these files\nwill be used as it is.\n\n   api.py,\n   error_util.py,\n   vim.py,\n   vim_util.py\n\n(*) Using the above mentioned utilities, implemented a wrapper class for\nquerying performance stats from VC.\n\nChange-Id: I445bcdb3f8ac240d1799bfd31f8b888982d7d97f\nImplements: blueprint vmware-vcenter-server\n""}, {'number': 3, 'created': '2014-02-15 15:22:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/08abf38be3598e039f160384af1ec176b2e8e625', 'message': ""VMware vSphere support\n\n(*) Copied the following utility files to execute vSphere queries from\n'cinder'. These common utility files are going to be converted to a\nlibrary as a part of blueprint 'vmware-api' but till then these files\nwill be used as it is.\n\n   api.py,\n   error_util.py,\n   vim.py,\n   vim_util.py\n\n(*) Using the above mentioned utilities, implemented a wrapper class for\nquerying performance stats from VC.\n\nChange-Id: I445bcdb3f8ac240d1799bfd31f8b888982d7d97f\nImplements: blueprint vmware-vcenter-server\n""}, {'number': 4, 'created': '2014-02-18 16:33:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/ed39d233b0c429cba226e1b879e7bc827431e1f4', 'message': ""VMware vSphere support\n\n(*) Copied the following utility files to execute vSphere queries from\ncommon 'vmware-api' library. These common utility files are going to be\nconverted to a library as a part of blueprint 'vmware-api', but till\nthen these files will be used as it is. The library might not be ready\nfor consumption for ice-house release.\n\n   api.py,\n   exceptions.py,\n   vim.py,\n   vim_util.py\n\n(*) Using the above mentioned utilities, implemented a wrapper class -\nVsphereOperations - for querying performance stats from VC.\n\n(*) Wrote unit test cases for VsphereOperations.\n\nChange-Id: I445bcdb3f8ac240d1799bfd31f8b888982d7d97f\nImplements: blueprint vmware-vcenter-server\n""}, {'number': 5, 'created': '2014-02-18 17:00:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/2f01cffe170a247c25d9095df2b419304e3cf7cb', 'message': ""VMware vSphere support\n\n(*) Copied the following utility files to execute vSphere queries from\ncommon 'vmware-api' library. These common utility files are going to be\nconverted to a library as a part of blueprint 'vmware-api', but till\nthen these files will be used as it is. The library might not be ready\nfor consumption for ice-house release.\n\n   api.py,\n   exceptions.py,\n   vim.py,\n   vim_util.py\n\n(*) Using the above mentioned utilities, implemented a wrapper class -\nVsphereOperations - for querying performance stats from VC.\n\n(*) Wrote unit test cases for VsphereOperations.\n\nChange-Id: I445bcdb3f8ac240d1799bfd31f8b888982d7d97f\nImplements: blueprint vmware-vcenter-server\n""}, {'number': 6, 'created': '2014-02-19 13:10:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/bac4ad53d6566533b1bf270e8b74c734963475df', 'message': ""VMware vSphere support\n\n(*) Copied the following utility files to execute vSphere queries from\ncommon 'vmware-api' library. These common utility files are going to be\nconverted to a library as a part of blueprint 'vmware-api', but till\nthen these files will be used as it is. The library might not be ready\nfor consumption for ice-house release.\n\n   api.py,\n   exceptions.py,\n   vim.py,\n   vim_util.py\n\n(*) Using the above mentioned utilities, implemented a wrapper class -\nVsphereOperations - for querying performance stats from VC.\n\n(*) Wrote unit test cases for VsphereOperations.\n\nChange-Id: I445bcdb3f8ac240d1799bfd31f8b888982d7d97f\nImplements: blueprint vmware-vcenter-server\n""}, {'number': 7, 'created': '2014-02-24 14:12:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/92270945257130b4548d0dae63c115d89346df56', 'message': ""VMware vSphere support\n\n(*) Copied the following utility files to execute vSphere queries from\ncommon 'vmware-api' library. These common utility files are going to be\nconverted to a library as a part of blueprint 'vmware-api', but till\nthen these files will be used as it is. The library might not be ready\nfor consumption for ice-house release.\n\n   api.py,\n   exceptions.py,\n   vim.py,\n   vim_util.py\n\n(*) Using the above mentioned utilities, implemented a wrapper class -\nVsphereOperations - for querying performance stats from VC.\n\n(*) Wrote unit test cases for VsphereOperations.\n\nChange-Id: I445bcdb3f8ac240d1799bfd31f8b888982d7d97f\nImplements: blueprint vmware-vcenter-server\n""}, {'number': 8, 'created': '2014-02-24 14:45:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/be43d5b8f29443ff6416bfc7f9c6eb88692414eb', 'message': ""VMware vSphere support\n\n(*) Copied the following utility files to execute vSphere queries from\ncommon 'vmware-api' library (https://github.com/openstack/oslo.vmware).\nThese common utility files are going to be converted to a library as a\npart of blueprint 'vmware-api', but till then these files will be used\nas it is. The library might not be ready for consumption for ice-house\nrelease.\n\n   api.py,\n   exceptions.py,\n   vim.py,\n   vim_util.py\n\n(*) Using the above mentioned utilities, implemented a wrapper class -\nVsphereOperations - for querying performance stats from VC.\n\n(*) Wrote unit test cases for VsphereOperations.\n\nChange-Id: I445bcdb3f8ac240d1799bfd31f8b888982d7d97f\nImplements: blueprint vmware-vcenter-server\n""}, {'number': 9, 'created': '2014-02-24 20:32:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/67315cb4657bbf9a95b211e7ba5711e19c0663e1', 'message': ""VMware vSphere support\n\n(*) Copied the following utility files to execute vSphere queries from\ncommon 'vmware-api' library (https://github.com/openstack/oslo.vmware).\nThese common utility files are going to be converted to a library as a\npart of blueprint 'vmware-api', but till then these files will be used\nas it is. The library might not be ready for consumption for ice-house\nrelease.\n\n   api.py,\n   exceptions.py,\n   vim.py,\n   vim_util.py\n\n(*) Using the above mentioned utilities, implemented a wrapper class -\nVsphereOperations - for querying performance stats from VC.\n\n(*) Wrote unit test cases for VsphereOperations.\n\nChange-Id: I445bcdb3f8ac240d1799bfd31f8b888982d7d97f\nImplements: blueprint vmware-vcenter-server\n""}, {'number': 10, 'created': '2014-02-27 15:36:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/773c30411a7059048fee055863daa181203ac2d8', 'message': ""VMware vSphere support: Performance Mgr APIs\n\n(*) Added a dependency on 'oslo.vmware' library, in requirements.txt.\n\n(*) Using the vmware library, implemented a wrapper class -\nVsphereOperations - for querying performance stats from VC.\n\n(*) Wrote unit test cases for VsphereOperations.\n\nChange-Id: I445bcdb3f8ac240d1799bfd31f8b888982d7d97f\nImplements: blueprint vmware-vcenter-server\n""}, {'number': 11, 'created': '2014-02-28 12:31:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/d9735341416003d81f464a9b7292a988ccbe115e', 'message': ""VMware vSphere support: Performance Mgr APIs\n\n(*) Added a dependency on 'oslo.vmware' library, in requirements.txt.\n\n(*) Using the vmware library, implemented a wrapper class -\nVsphereOperations - for querying performance stats from VC.\n\n(*) Wrote unit test cases for VsphereOperations.\n\nChange-Id: I445bcdb3f8ac240d1799bfd31f8b888982d7d97f\nImplements: blueprint vmware-vcenter-server\n""}, {'number': 12, 'created': '2014-03-03 15:06:40.000000000', 'files': ['ceilometer/compute/virt/vmware/vsphere_operations.py', 'requirements.txt', 'ceilometer/tests/compute/virt/vmware/test_vsphere_operations.py', 'ceilometer/compute/virt/vmware/__init__.py', 'ceilometer/tests/compute/virt/vmware/__init__.py'], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/f4e2ab85ebf3a38a29501178958e54fc7b7bdc6a', 'message': ""VMware vSphere support: Performance Mgr APIs\n\n(*) Added a dependency on 'oslo.vmware' library, in requirements.txt.\n\n(*) Using the vmware library, implemented a wrapper class -\nVsphereOperations - for querying performance stats from VC.\n\n(*) Wrote unit test cases for VsphereOperations.\n\nChange-Id: I445bcdb3f8ac240d1799bfd31f8b888982d7d97f\nImplements: blueprint vmware-vcenter-server\n""}]",51,73809,f4e2ab85ebf3a38a29501178958e54fc7b7bdc6a,80,15,12,10356,,,0,"VMware vSphere support: Performance Mgr APIs

(*) Added a dependency on 'oslo.vmware' library, in requirements.txt.

(*) Using the vmware library, implemented a wrapper class -
VsphereOperations - for querying performance stats from VC.

(*) Wrote unit test cases for VsphereOperations.

Change-Id: I445bcdb3f8ac240d1799bfd31f8b888982d7d97f
Implements: blueprint vmware-vcenter-server
",git fetch https://review.opendev.org/openstack/ceilometer refs/changes/09/73809/12 && git format-patch -1 --stdout FETCH_HEAD,"['ceilometer/compute/virt/vmware/vsphere_operations.py', 'requirements.txt', 'ceilometer/compute/virt/vmware/vim.py', 'ceilometer/compute/virt/vmware/__init__.py', 'ceilometer/compute/virt/vmware/error_util.py', 'ceilometer/compute/virt/vmware/vim_util.py', 'ceilometer/compute/virt/vmware/api.py']",7,67c0165f8ddb99fcfde16b69ccafc4e26fe28d6a,bp/vmware-vcenter-server,"# vim: expandtab tabstop=4 shiftwidth=4 softtabstop=4 # Copyright (c) 2013 VMware, Inc. # All Rights Reserved. # # Licensed under the Apache License, Version 2.0 (the ""License""); you may # not use this file except in compliance with the License. You may obtain # a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT # WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the # License for the specific language governing permissions and limitations # under the License. """""" Session and API call management for VMware ESX/VC server. Provides abstraction over cinder.volume.drivers.vmware.vim.Vim SOAP calls. """""" from ceilometer.openstack.common.gettextutils import _ # noqa from ceilometer.compute.virt.vmware import error_util from ceilometer.compute.virt.vmware import vim from ceilometer.compute.virt.vmware import vim_util from ceilometer.openstack.common import log as logging from ceilometer.openstack.common import loopingcall from eventlet import event LOG = logging.getLogger(__name__) class Retry(object): """"""Decorator for retrying a function upon suggested exceptions. The method retries for given number of times and the sleep time increments till the max sleep time is reached. If max retries is set to -1, then the decorated function is invoked indefinitely till no exception is thrown or if the caught exception is not in the list of suggested exceptions. """""" def __init__(self, max_retry_count=-1, inc_sleep_time=10, max_sleep_time=60, exceptions=()): """"""Initialize retry object based on input params. :param max_retry_count: Max number of times, a function must be retried when one of input 'exceptions' is caught. The default -1 will always retry the function till a non-exception case, or an un-wanted error case arises. :param inc_sleep_time: Incremental time in seconds for sleep time between retrial :param max_sleep_time: Max sleep time beyond which the sleep time will not be incremented using param inc_sleep_time and max_sleep_time will be used as sleep time :param exceptions: Suggested exceptions for which the function must be retried """""" self._max_retry_count = max_retry_count self._inc_sleep_time = inc_sleep_time self._max_sleep_time = max_sleep_time self._exceptions = exceptions self._retry_count = 0 self._sleep_time = 0 def __call__(self, f): def _func(done, *args, **kwargs): try: result = f(*args, **kwargs) done.send(result) except self._exceptions as excep: LOG.exception(_(""Failure while invoking function: "" ""%(func)s. Error: %(excep)s."") % {'func': f.__name__, 'excep': excep}) if (self._max_retry_count != -1 and self._retry_count >= self._max_retry_count): done.send_exception(excep) else: self._retry_count += 1 self._sleep_time += self._inc_sleep_time return self._sleep_time except Exception as excep: done.send_exception(excep) return 0 def func(*args, **kwargs): done = event.Event() loop = loopingcall.DynamicLoopingCall(_func, done, *args, **kwargs) loop.start(periodic_interval_max=self._max_sleep_time) result = done.wait() loop.stop() return result return func class VMwareAPISession(object): """"""Sets up a session with the server and handles all calls made to it."""""" @Retry(exceptions=(Exception)) def __init__(self, server_ip, server_username, server_password, api_retry_count, task_poll_interval, scheme='https', create_session=True, wsdl_loc=None): """"""Constructs session object. :param server_ip: IP address of ESX/VC server :param server_username: Username of ESX/VC server admin user :param server_password: Password for param server_username :param api_retry_count: Number of times an API must be retried upon session/connection related errors :param task_poll_interval: Sleep time in seconds for polling an on-going async task as part of the API call :param scheme: http or https protocol :param create_session: Boolean whether to set up connection at the time of instance creation :param wsdl_loc: WSDL file location for invoking SOAP calls on server using suds """""" self._server_ip = server_ip self._server_username = server_username self._server_password = server_password self._wsdl_loc = wsdl_loc self._api_retry_count = api_retry_count self._task_poll_interval = task_poll_interval self._scheme = scheme self._session_id = None self._vim = None if create_session: self.create_session() @property def vim(self): if not self._vim: self._vim = vim.Vim(protocol=self._scheme, host=self._server_ip, wsdl_loc=self._wsdl_loc) return self._vim def create_session(self): """"""Establish session with the server."""""" # Login and setup the session with the server for making # API calls session_manager = self.vim.service_content.sessionManager session = self.vim.Login(session_manager, userName=self._server_username, password=self._server_password) # Terminate the earlier session, if possible (For the sake of # preserving sessions as there is a limit to the number of # sessions we can have) if self._session_id: try: self.vim.TerminateSession(session_manager, sessionId=[self._session_id]) except Exception as excep: # This exception is something we can live with. It is # just an extra caution on our side. The session may # have been cleared. We could have made a call to # SessionIsActive, but that is an overhead because we # anyway would have to call TerminateSession. LOG.exception(_(""Error while terminating session: %s."") % excep) self._session_id = session.key LOG.info(_(""Successfully established connection to the server."")) def __del__(self): """"""Logs-out the session."""""" try: self.vim.Logout(self.vim.service_content.sessionManager) except Exception as excep: LOG.exception(_(""Error while logging out the user: %s."") % excep) def invoke_api(self, module, method, *args, **kwargs): """"""Wrapper method for invoking APIs. Here we retry the API calls for exceptions which may come because of session overload. Make sure if a Vim instance is being passed here, this session's Vim (self.vim) instance is used, as we retry establishing session in case of session timedout. :param module: Module invoking the VI SDK calls :param method: Method in the module that invokes the VI SDK call :param args: Arguments to the method :param kwargs: Keyword arguments to the method :return: Response of the API call """""" @Retry(max_retry_count=self._api_retry_count, exceptions=(error_util.VimException)) def _invoke_api(module, method, *args, **kwargs): last_fault_list = [] while True: try: api_method = getattr(module, method) return api_method(*args, **kwargs) except error_util.VimFaultException as excep: if error_util.NOT_AUTHENTICATED not in excep.fault_list: raise excep # If it is a not-authenticated fault, we re-authenticate # the user and retry the API invocation. # Because of the idle session returning an empty # RetrieveProperties response and also the same is # returned when there is an empty answer to a query # (e.g. no VMs on the host), we have no way to # differentiate. # So if the previous response was also an empty # response and after creating a new session, we get # the same empty response, then we are sure of the # response being an empty response. if error_util.NOT_AUTHENTICATED in last_fault_list: return [] last_fault_list = excep.fault_list LOG.exception(_(""Not authenticated error occurred. "" ""Will create session and try "" ""API call again: %s."") % excep) self.create_session() return _invoke_api(module, method, *args, **kwargs) def wait_for_task(self, task): """"""Return a deferred that will give the result of the given task. The task is polled until it completes. The method returns the task information upon successful completion. :param task: Managed object reference of the task :return: Task info upon successful completion of the task """""" done = event.Event() loop = loopingcall.FixedIntervalLoopingCall(self._poll_task, task, done) loop.start(self._task_poll_interval) task_info = done.wait() loop.stop() return task_info def _poll_task(self, task, done): """"""Poll the given task. If the task completes successfully then returns task info. In case of error sends back appropriate error. :param task: Managed object reference of the task :param event: Event that captures task status """""" try: task_info = self.invoke_api(vim_util, 'get_object_property', self.vim, task, 'info') if task_info.state in ['queued', 'running']: # If task already completed on server, it will not return # the progress. if hasattr(task_info, 'progress'): LOG.debug(_(""Task: %(task)s progress: %(prog)s."") % {'task': task, 'prog': task_info.progress}) return elif task_info.state == 'success': LOG.debug(_(""Task %s status: success."") % task) done.send(task_info) else: error_msg = str(task_info.error.localizedMessage) LOG.exception(_(""Task: %(task)s failed with error: %(err)s."") % {'task': task, 'err': error_msg}) done.send_exception(error_util.VimFaultException([], error_msg)) except Exception as excep: LOG.exception(_(""Task: %(task)s failed with error: %(err)s."") % {'task': task, 'err': excep}) done.send_exception(excep) def wait_for_lease_ready(self, lease): done = event.Event() loop = loopingcall.FixedIntervalLoopingCall(self._poll_lease, lease, done) loop.start(self._task_poll_interval) done.wait() loop.stop() def _poll_lease(self, lease, done): try: state = self.invoke_api(vim_util, 'get_object_property', self.vim, lease, 'state') if state == 'ready': # done LOG.debug(_(""Lease is ready."")) done.send() return elif state == 'initializing': LOG.debug(_(""Lease initializing..."")) return elif state == 'error': error_msg = self.invoke_api(vim_util, 'get_object_property', self.vim, lease, 'error') LOG.exception(error_msg) excep = error_util.VimFaultException([], error_msg) done.send_exception(excep) else: # unknown state - complain error_msg = _(""Error: unknown lease state %s."") % state raise error_util.VimFaultException([], error_msg) except Exception as excep: LOG.exception(excep) done.send_exception(excep) ",,1071,0
openstack%2Frequirements~master~I44a0ba108c9272bd6ef7ab71d587367c0eddaaac,openstack/requirements,master,I44a0ba108c9272bd6ef7ab71d587367c0eddaaac,Sets the min python-novaclient version to 2.16.0,MERGED,2014-03-04 19:50:08.000000000,2014-03-05 19:20:56.000000000,2014-03-05 19:20:56.000000000,"[{'_account_id': 3}, {'_account_id': 4978}, {'_account_id': 5623}, {'_account_id': 6786}, {'_account_id': 7680}]","[{'number': 1, 'created': '2014-03-04 19:50:08.000000000', 'files': ['global-requirements.txt'], 'web_link': 'https://opendev.org/openstack/requirements/commit/2d9c3c98ba6ec0e39dadca179ab0bc5c7b22a61f', 'message': 'Sets the min python-novaclient version to 2.16.0\n\npython-novaclient 2.16.0 introduces RDP support required\nby Horizon for the ""hyper-v-rdp-console"" BP.\n\nChange-Id: I44a0ba108c9272bd6ef7ab71d587367c0eddaaac\n'}]",0,77981,2d9c3c98ba6ec0e39dadca179ab0bc5c7b22a61f,9,5,1,3185,,,0,"Sets the min python-novaclient version to 2.16.0

python-novaclient 2.16.0 introduces RDP support required
by Horizon for the ""hyper-v-rdp-console"" BP.

Change-Id: I44a0ba108c9272bd6ef7ab71d587367c0eddaaac
",git fetch https://review.opendev.org/openstack/requirements refs/changes/81/77981/1 && git format-patch -1 --stdout FETCH_HEAD,['global-requirements.txt'],1,2d9c3c98ba6ec0e39dadca179ab0bc5c7b22a61f,,python-novaclient>=2.16.0,python-novaclient>=2.15.0,1,1
openstack%2Fneutron~stable%2Fhavana~I8e298468fb730f11a66fbd4211121ee7d3e2a548,openstack/neutron,stable/havana,I8e298468fb730f11a66fbd4211121ee7d3e2a548,Fix request timeout errors during calls to NSX controller,MERGED,2014-02-21 19:04:03.000000000,2014-03-05 19:11:03.000000000,2014-03-05 19:11:01.000000000,"[{'_account_id': 3}, {'_account_id': 748}, {'_account_id': 2592}, {'_account_id': 4395}, {'_account_id': 7317}, {'_account_id': 9925}, {'_account_id': 10117}, {'_account_id': 10153}, {'_account_id': 10294}]","[{'number': 1, 'created': '2014-02-21 19:04:03.000000000', 'files': ['neutron/plugins/nicira/api_client/request_eventlet.py', 'neutron/plugins/nicira/api_client/request.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/c1942623a5ac0be5df83d9511b56bb6009b64e69', 'message': 'Fix request timeout errors during calls to NSX controller\n\nSometimes two correlated exception traces are observed in\nthe server log for the Neutron Server backed by NSX:\nRequestTimeout (The nsx request has timed out) and\nOperationalError (Lock wait timeout exceeded). This is\ngenerally described by Guru Salvatore Orlando as the,\nand I quote, the ""infamous eventlet-mysql deadlock"".\n\nThis patch tries to address the issue by adding a\ncooperative yield in the nsx client code (its a good idea\nto call sleep(0) occasionally in any case) and also by\navoiding the unnecessary spawning of another Greenthread\nwithin a call that is already executed in Greenthred\nitself.\n\nCloses-bug: #1267101\nRelated-bug: #1279497\n\nChange-Id: I8e298468fb730f11a66fbd4211121ee7d3e2a548\n(cherry picked from commit 85ddbde058d8bda0b938eb7a45ef73519a831b3b)\n'}]",0,75484,c1942623a5ac0be5df83d9511b56bb6009b64e69,26,9,1,748,,,0,"Fix request timeout errors during calls to NSX controller

Sometimes two correlated exception traces are observed in
the server log for the Neutron Server backed by NSX:
RequestTimeout (The nsx request has timed out) and
OperationalError (Lock wait timeout exceeded). This is
generally described by Guru Salvatore Orlando as the,
and I quote, the ""infamous eventlet-mysql deadlock"".

This patch tries to address the issue by adding a
cooperative yield in the nsx client code (its a good idea
to call sleep(0) occasionally in any case) and also by
avoiding the unnecessary spawning of another Greenthread
within a call that is already executed in Greenthred
itself.

Closes-bug: #1267101
Related-bug: #1279497

Change-Id: I8e298468fb730f11a66fbd4211121ee7d3e2a548
(cherry picked from commit 85ddbde058d8bda0b938eb7a45ef73519a831b3b)
",git fetch https://review.opendev.org/openstack/neutron refs/changes/84/75484/1 && git format-patch -1 --stdout FETCH_HEAD,"['neutron/plugins/nicira/api_client/request_eventlet.py', 'neutron/plugins/nicira/api_client/request.py']",2,c1942623a5ac0be5df83d9511b56bb6009b64e69,bug/1267101-stable,"import eventlet # yield here, just in case we are not out of the loop yet eventlet.greenthread.sleep(0)",,5,2
openstack%2Fneutron~master~Ic1649f7cee73a41f286e12d8ba6ca30be6261cfe,openstack/neutron,master,Ic1649f7cee73a41f286e12d8ba6ca30be6261cfe,Implementaion of Mechanism driver for Brocade VDX cluster of switches,MERGED,2013-12-05 02:13:07.000000000,2014-03-05 19:10:53.000000000,2014-03-05 19:10:52.000000000,"[{'_account_id': 3}, {'_account_id': 105}, {'_account_id': 490}, {'_account_id': 704}, {'_account_id': 748}, {'_account_id': 1689}, {'_account_id': 2592}, {'_account_id': 5170}, {'_account_id': 5217}, {'_account_id': 6072}, {'_account_id': 9008}, {'_account_id': 9681}, {'_account_id': 9682}, {'_account_id': 9732}, {'_account_id': 9787}, {'_account_id': 9845}, {'_account_id': 9925}, {'_account_id': 10116}, {'_account_id': 10117}, {'_account_id': 10119}, {'_account_id': 10153}, {'_account_id': 10184}, {'_account_id': 10192}, {'_account_id': 10294}]","[{'number': 1, 'created': '2013-12-05 02:13:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/6948fa2831098f97e143329a68259e7a9b3e4bfd', 'message': 'Implementaion of Mechanism driver for Brocade VDX\ncluster of switches.\n\nChange-Id: Ic1649f7cee73a41f286e12d8ba6ca30be6261cfe\nImplements: blueprint Brocade Mechanism Driver for ML2\n'}, {'number': 2, 'created': '2013-12-05 20:59:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/b9db88ebe345f61ecd4e6df6a12875aaaeb0f775', 'message': 'Implementaion of Mechanism driver for Brocade VDX\ncluster of switches\n\nChange-Id: Ic1649f7cee73a41f286e12d8ba6ca30be6261cfe\nImplements: blueprint Brocade Mechanism Driver for ML2\n'}, {'number': 3, 'created': '2013-12-09 22:53:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/41ac3434d0277a663280119b8bff070eaefe34b8', 'message': 'Implementaion of Mechanism driver for Brocade VDX\ncluster of switches\n\nChange-Id: Ic1649f7cee73a41f286e12d8ba6ca30be6261cfe\nImplements: blueprint Brocade Mechanism Driver for ML2\n'}, {'number': 4, 'created': '2014-01-17 19:22:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/e17029a230cf1a47f1e251f4a754aaf4b4724e02', 'message': 'Implementaion of Mechanism driver for Brocade VDX\ncluster of switches\n\nChange-Id: Ic1649f7cee73a41f286e12d8ba6ca30be6261cfe\nImplements: blueprint Brocade Mechanism Driver for ML2\n'}, {'number': 5, 'created': '2014-01-17 22:00:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/ca933cafabf378d256c28622b4722f2140d086f4', 'message': 'Implementaion of Mechanism driver for Brocade VDX\ncluster of switches\n\nChange-Id: Ic1649f7cee73a41f286e12d8ba6ca30be6261cfe\nImplements: blueprint Brocade Mechanism Driver for ML2\n'}, {'number': 6, 'created': '2014-01-17 23:47:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/d312ba1d1f751dc2e6b9f6ebe5d1bc448596db22', 'message': 'Implementaion of Mechanism driver for Brocade VDX\ncluster of switches\n\nChange-Id: Ic1649f7cee73a41f286e12d8ba6ca30be6261cfe\nImplements: blueprint brocade-ml2-mechanism-driver\n'}, {'number': 7, 'created': '2014-01-21 01:08:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/000b1ab49303c83a4b8ccf55956518d3ed97638b', 'message': 'Implementaion of Mechanism driver for Brocade VDX\ncluster of switches\n\nChange-Id: Ic1649f7cee73a41f286e12d8ba6ca30be6261cfe\nImplements: blueprint brocade-ml2-mechanism-driver\n'}, {'number': 8, 'created': '2014-02-12 18:50:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/692ca5f3abb3e1a882d8902eb75cb06407926b9f', 'message': 'Implementaion of Mechanism driver for Brocade VDX\ncluster of switches\n\nChange-Id: Ic1649f7cee73a41f286e12d8ba6ca30be6261cfe\nImplements: blueprint brocade-ml2-mechanism-driver\n'}, {'number': 9, 'created': '2014-02-22 01:22:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/3132b25b540c3fdc7cd9549c171e3022aab8a78a', 'message': 'Implementaion of Mechanism driver for Brocade VDX\ncluster of switches\n\nChange-Id: Ic1649f7cee73a41f286e12d8ba6ca30be6261cfe\nImplements: blueprint brocade-ml2-mechanism-driver\n'}, {'number': 10, 'created': '2014-02-22 17:43:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/2158d4cf11f9742fa22ac766ceacb14b12bd2be4', 'message': 'Implementaion of Mechanism driver for Brocade VDX\ncluster of switches\n\nChange-Id: Ic1649f7cee73a41f286e12d8ba6ca30be6261cfe\nImplements: blueprint brocade-ml2-mechanism-driver\n'}, {'number': 11, 'created': '2014-02-23 04:21:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/5e2c7cc0ba6fd093289233fdf7f63a41d9153d6f', 'message': 'Implementaion of Mechanism driver for Brocade VDX\ncluster of switches\n\nChange-Id: Ic1649f7cee73a41f286e12d8ba6ca30be6261cfe\nImplements: blueprint brocade-ml2-mechanism-driver\n'}, {'number': 12, 'created': '2014-02-24 16:05:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/140435d2aecd5a4ca90c5bed4d34213c334d5928', 'message': 'Implementaion of Mechanism driver for Brocade VDX\ncluster of switches\n\nChange-Id: Ic1649f7cee73a41f286e12d8ba6ca30be6261cfe\nImplements: blueprint brocade-ml2-mechanism-driver\n'}, {'number': 13, 'created': '2014-02-24 16:12:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/f53df17abc2c0cb7ac3dd30d99dd1690f3cba32d', 'message': 'Implementaion of Mechanism driver for Brocade VDX\ncluster of switches\n\nChange-Id: Ic1649f7cee73a41f286e12d8ba6ca30be6261cfe\nImplements: blueprint brocade-ml2-mechanism-driver\n'}, {'number': 14, 'created': '2014-02-24 17:14:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/5f8f9298395bb37623719fc7f1ca37264ec46f7e', 'message': 'Implementaion of Mechanism driver for Brocade VDX\ncluster of switches\n\nChange-Id: Ic1649f7cee73a41f286e12d8ba6ca30be6261cfe\nImplements: blueprint brocade-ml2-mechanism-driver\n'}, {'number': 15, 'created': '2014-03-04 00:04:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/163297de7240c42914c8bf108e0b072cc4fd526c', 'message': 'Implementaion of Mechanism driver for Brocade VDX\ncluster of switches\n\nChange-Id: Ic1649f7cee73a41f286e12d8ba6ca30be6261cfe\nImplements: blueprint brocade-ml2-mechanism-driver\n'}, {'number': 16, 'created': '2014-03-04 00:28:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/51f6c9e99936f0195fee225ca1924cce49d4f63c', 'message': 'Implementaion of Mechanism driver for\nBrocade VDX cluster of switches\n\nChange-Id: Ic1649f7cee73a41f286e12d8ba6ca30be6261cfe\nImplements: blueprint brocade-ml2-mechanism-driver\n'}, {'number': 17, 'created': '2014-03-04 18:14:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/f3b0cb120a2e038ae2d4ed876d3ac276bfe1e8d6', 'message': 'Implementaion of Mechanism driver for\nBrocade VDX cluster of switches\n\nChange-Id: Ic1649f7cee73a41f286e12d8ba6ca30be6261cfe\nImplements: blueprint brocade-ml2-mechanism-driver\n'}, {'number': 18, 'created': '2014-03-04 18:37:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/c54bc39e8bdb2e142829e2f77f5ea23ce51f857e', 'message': 'Implementaion of Mechanism driver for\nBrocade VDX cluster of switches\n\nChange-Id: Ic1649f7cee73a41f286e12d8ba6ca30be6261cfe\nImplements: blueprint brocade-ml2-mechanism-driver\n'}, {'number': 19, 'created': '2014-03-04 18:57:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/6533d03d4ffdbcfa8eba760c965a26aa3fb71a7f', 'message': 'Implementaion of Mechanism driver for\nBrocade VDX cluster of switches\n\nChange-Id: Ic1649f7cee73a41f286e12d8ba6ca30be6261cfe\nImplements: blueprint brocade-ml2-mechanism-driver\n'}, {'number': 20, 'created': '2014-03-04 20:25:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/44d5756a2f4709c9e706d1cf60fdbb53988a0ec1', 'message': 'Implementaion of Mechanism driver for\nBrocade VDX cluster of switches\n\nChange-Id: Ic1649f7cee73a41f286e12d8ba6ca30be6261cfe\nImplements: blueprint brocade-ml2-mechanism-driver\n'}, {'number': 21, 'created': '2014-03-04 20:28:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/00229f488b2bcf2e528916c714aa19b4da1129be', 'message': 'Implementaion of Mechanism driver for\nBrocade VDX cluster of switches\n\nChange-Id: Ic1649f7cee73a41f286e12d8ba6ca30be6261cfe\nImplements: blueprint brocade-ml2-mechanism-driver\n'}, {'number': 22, 'created': '2014-03-04 22:54:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/1f36df32f84b2b4fcce0c055022b9545dacb08ab', 'message': 'Implementaion of Mechanism driver for\nBrocade VDX cluster of switches\n\nChange-Id: Ic1649f7cee73a41f286e12d8ba6ca30be6261cfe\nImplements: blueprint brocade-ml2-mechanism-driver\n'}, {'number': 23, 'created': '2014-03-04 23:21:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/5ba8aba160ec99a426bf44a243b5d1eaa8687dcc', 'message': 'Implementaion of Mechanism driver for\nBrocade VDX cluster of switches\n\nChange-Id: Ic1649f7cee73a41f286e12d8ba6ca30be6261cfe\nImplements: blueprint brocade-ml2-mechanism-driver\n'}, {'number': 24, 'created': '2014-03-04 23:23:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/0a2f26912237c4bc265bf74f35fd75af92090d5e', 'message': 'Implementaion of Mechanism driver for\nBrocade VDX cluster of switches\n\nChange-Id: Ic1649f7cee73a41f286e12d8ba6ca30be6261cfe\nImplements: blueprint brocade-ml2-mechanism-driver\n'}, {'number': 25, 'created': '2014-03-04 23:37:17.000000000', 'files': ['neutron/plugins/ml2/drivers/brocade/README.md', 'neutron/tests/unit/ml2/drivers/brocade/test_brocade_mechanism_driver.py', 'etc/neutron/plugins/ml2/ml2_conf.ini', 'neutron/plugins/ml2/drivers/brocade/__init__.py', 'neutron/plugins/ml2/drivers/brocade/nos/nosdriver.py', 'neutron/plugins/ml2/drivers/brocade/db/__init__.py', 'neutron/plugins/ml2/drivers/brocade/db/models.py', 'etc/neutron/plugins/ml2/ml2_conf_brocade.ini', 'neutron/plugins/ml2/drivers/brocade/mechanism_brocade.py', 'neutron/plugins/ml2/drivers/brocade/nos/nctemplates.py', 'neutron/tests/unit/ml2/drivers/brocade/__init__.py', 'neutron/plugins/ml2/drivers/brocade/nos/__init__.py', 'setup.cfg', 'neutron/db/migration/alembic_migrations/versions/492a106273f8_brocade_ml2_mech_dri.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/0b5a2fac5d0f7898ac89f64d11b263dd98dc2a50', 'message': 'Implementaion of Mechanism driver for\nBrocade VDX cluster of switches\n\nChange-Id: Ic1649f7cee73a41f286e12d8ba6ca30be6261cfe\nImplements: blueprint brocade-ml2-mechanism-driver\n'}]",213,60129,0b5a2fac5d0f7898ac89f64d11b263dd98dc2a50,235,24,25,5217,,,0,"Implementaion of Mechanism driver for
Brocade VDX cluster of switches

Change-Id: Ic1649f7cee73a41f286e12d8ba6ca30be6261cfe
Implements: blueprint brocade-ml2-mechanism-driver
",git fetch https://review.opendev.org/openstack/neutron refs/changes/29/60129/25 && git format-patch -1 --stdout FETCH_HEAD,"['neutron/plugins/ml2/drivers/brocade/README.md', 'neutron/tests/unit/ml2/drivers/test_brocade_mechanism_driver.py', 'etc/neutron/plugins/ml2/ml2_conf.ini', 'neutron/plugins/ml2/drivers/brocade/__init__.py', 'neutron/plugins/ml2/drivers/brocade/nos/nosdriver.py', 'neutron/plugins/ml2/drivers/brocade/db/__init__.py', 'neutron/plugins/ml2/drivers/brocade/db/models.py', 'etc/neutron/plugins/ml2/ml2_conf_brocade.ini', 'neutron/plugins/ml2/drivers/brocade/mechanism_brocade.py', 'neutron/plugins/ml2/plugin.py', 'neutron/plugins/ml2/drivers/brocade/nos/nctemplates.py', 'neutron/plugins/ml2/db.py', 'neutron/plugins/ml2/drivers/brocade/nos/__init__.py', 'neutron/plugins/ml2/drivers/brocade/nos/fake_nosdriver.py', 'setup.cfg']",15,6948fa2831098f97e143329a68259e7a9b3e4bfd,bp/brocade-ml2-mechanism-driver, etc/neutron/plugins/ml2/ml2_conf_brocade.ini brocade = neutron.plugins.ml2.drivers.brocade.mechanism_brocade:BrocadeMechanism,,1591,2
openstack%2Fneutron~master~Idf03fda75ccd147673169c24e79921ca6d8fe754,openstack/neutron,master,Idf03fda75ccd147673169c24e79921ca6d8fe754,Fix race condition in update_floatingip_statuses,MERGED,2014-03-05 03:21:16.000000000,2014-03-05 19:10:44.000000000,2014-03-05 19:10:43.000000000,"[{'_account_id': 3}, {'_account_id': 261}, {'_account_id': 748}, {'_account_id': 2592}, {'_account_id': 2874}, {'_account_id': 4395}, {'_account_id': 5170}, {'_account_id': 9732}, {'_account_id': 9787}, {'_account_id': 9845}, {'_account_id': 9925}, {'_account_id': 10116}, {'_account_id': 10184}, {'_account_id': 10192}, {'_account_id': 10294}]","[{'number': 1, 'created': '2014-03-05 03:21:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/fa214b461c34d8870d42cfbb252f493f5ae7d043', 'message': 'Fix race condition in update_floatingip_statuses\n\nIf a floatingip is deleted before update_floatingip_statuses() is processed\nFloatingIPNotFound is raised.\n\nChange-Id: Idf03fda75ccd147673169c24e79921ca6d8fe754\nCloses-bug: #1288036\n'}, {'number': 2, 'created': '2014-03-05 04:28:11.000000000', 'files': ['neutron/db/l3_rpc_base.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/31f4046323839d6c0aaa885fe7bd5920845eab30', 'message': 'Fix race condition in update_floatingip_statuses\n\nIf a floatingip is deleted before update_floatingip_statuses() is processed\nFloatingIPNotFound is raised.\n\nChange-Id: Idf03fda75ccd147673169c24e79921ca6d8fe754\nCloses-bug: #1288036\n'}]",0,78077,31f4046323839d6c0aaa885fe7bd5920845eab30,24,15,2,4395,,,0,"Fix race condition in update_floatingip_statuses

If a floatingip is deleted before update_floatingip_statuses() is processed
FloatingIPNotFound is raised.

Change-Id: Idf03fda75ccd147673169c24e79921ca6d8fe754
Closes-bug: #1288036
",git fetch https://review.opendev.org/openstack/neutron refs/changes/77/78077/2 && git format-patch -1 --stdout FETCH_HEAD,['neutron/db/l3_rpc_base.py'],1,fa214b461c34d8870d42cfbb252f493f5ae7d043,(detached,"from neutron.extensions import l3 try: l3_plugin.update_floatingip_status(context, floatingip_id, status) except l3.FloatingIPNotFound: LOG.debug(_(""Floating IP: %s no longer present.""), floatingip_id)"," l3_plugin.update_floatingip_status(context, floatingip_id, status)",8,3
openstack%2Fneutron~master~I40bbbf6233131ea5d40122ef9495fd3cb7dc823a,openstack/neutron,master,I40bbbf6233131ea5d40122ef9495fd3cb7dc823a,L3 agent fetches the external network id once,MERGED,2014-01-15 20:21:19.000000000,2014-03-05 19:10:35.000000000,2014-03-05 19:10:33.000000000,"[{'_account_id': 3}, {'_account_id': 841}, {'_account_id': 2592}, {'_account_id': 2874}, {'_account_id': 4395}, {'_account_id': 5948}, {'_account_id': 6659}, {'_account_id': 7141}, {'_account_id': 7183}, {'_account_id': 7448}, {'_account_id': 8873}, {'_account_id': 9681}, {'_account_id': 9732}, {'_account_id': 9787}, {'_account_id': 9845}, {'_account_id': 9925}, {'_account_id': 10116}, {'_account_id': 10117}, {'_account_id': 10119}, {'_account_id': 10153}, {'_account_id': 10184}, {'_account_id': 10192}]","[{'number': 1, 'created': '2014-01-15 20:21:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/f2c0cb2fa6c760ab62696bdfe00cd69d94180661', 'message': 'L3 agent fetches the external network id once\n\nRather than fetching the id of the external network each time that\n_process_routers is called, get it once on startup and remember it.\n\nChange-Id: I40bbbf6233131ea5d40122ef9495fd3cb7dc823a\nCloses-Bug: #1269567\n'}, {'number': 2, 'created': '2014-01-16 15:19:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/3a5de189eeb78c4c8370562b043d7a40133fe5d1', 'message': 'L3 agent fetches the external network id once\n\nRather than fetching the id of the external network each time that\n_process_routers is called, get it once and remember it.\n\nChange-Id: I40bbbf6233131ea5d40122ef9495fd3cb7dc823a\nCloses-Bug: #1269567\n'}, {'number': 3, 'created': '2014-01-21 17:59:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/bd6d91d7109c0c190d8526b45bf091f9c4319df1', 'message': 'L3 agent fetches the external network id once\n\nRather than fetching the id of the external network each time that\n_process_routers is called, get it once and remember it.\n\nChange-Id: I40bbbf6233131ea5d40122ef9495fd3cb7dc823a\nCloses-Bug: #1269567\n'}, {'number': 4, 'created': '2014-01-23 20:41:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/de53e2e6c1719dcb2e34e1b5d63a8d51bf785bd3', 'message': 'L3 agent fetches the external network id once\n\nRather than fetching the id of the external network each time that\n_process_routers is called, get it once and remember it.  If the agent\nis ever requested to connect to a different ext-net then it will fetch\nthe current ext-net to double check for the unlikely event that the\next-net has changed.  If it has then it will remember the new ext-net.\n\nThis is only applicable in the case where there is only one ext-net\nthat has not been configured explicitly in the config file.  That was\nthe only case that would cause an RPC message in the first place.\n\nChange-Id: I40bbbf6233131ea5d40122ef9495fd3cb7dc823a\nCloses-Bug: #1269567\n'}, {'number': 5, 'created': '2014-01-28 21:32:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/62c42dbe16ba81ad21fdd5e7c90a99814bc90175', 'message': 'L3 agent fetches the external network id once\n\nRather than fetching the id of the external network each time that\n_process_routers is called, get it once and remember it.  If the agent\nis ever requested to connect to a different ext-net then it will fetch\nthe current ext-net to double check for the unlikely event that the\next-net has changed.  If it has then it will remember the new ext-net.\n\nThis is only applicable in the case where there is only one ext-net\nthat has not been configured explicitly in the config file.  That was\nthe only case that would cause an RPC message in the first place.\n\nChange-Id: I40bbbf6233131ea5d40122ef9495fd3cb7dc823a\nCloses-Bug: #1269567\n'}, {'number': 6, 'created': '2014-02-06 22:59:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/6e739fe6b8def6491dc33d299cfcb540cd7c0d96', 'message': 'L3 agent fetches the external network id once\n\nRather than fetching the id of the external network each time that\n_process_routers is called, get it once and remember it.  If the agent\nis ever requested to connect to a different ext-net then it will fetch\nthe current ext-net to double check for the unlikely event that the\next-net has changed.  If it has then it will remember the new ext-net.\n\nThis is only applicable in the case where there is only one ext-net\nthat has not been configured explicitly in the config file.  That was\nthe only case that would cause an RPC message in the first place.\n\nChange-Id: I40bbbf6233131ea5d40122ef9495fd3cb7dc823a\nCloses-Bug: #1269567\n'}, {'number': 7, 'created': '2014-02-14 00:29:09.000000000', 'files': ['neutron/agent/l3_agent.py', 'neutron/tests/unit/test_l3_agent.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/702e1fbf7ad5dd961dfd35cd6a0e54d4d6da5e34', 'message': 'L3 agent fetches the external network id once\n\nRather than fetching the id of the external network each time that\n_process_routers is called, get it once and remember it.  If the agent\nis ever requested to connect to a different ext-net then it will fetch\nthe current ext-net to double check for the unlikely event that the\next-net has changed.  If it has then it will remember the new ext-net.\n\nThis is only applicable in the case where there is only one ext-net\nthat has not been configured explicitly in the config file.  That was\nthe only case that would cause an RPC message in the first place.\n\nChange-Id: I40bbbf6233131ea5d40122ef9495fd3cb7dc823a\nCloses-Bug: #1269567\n'}]",4,66928,702e1fbf7ad5dd961dfd35cd6a0e54d4d6da5e34,104,22,7,7448,,,0,"L3 agent fetches the external network id once

Rather than fetching the id of the external network each time that
_process_routers is called, get it once and remember it.  If the agent
is ever requested to connect to a different ext-net then it will fetch
the current ext-net to double check for the unlikely event that the
ext-net has changed.  If it has then it will remember the new ext-net.

This is only applicable in the case where there is only one ext-net
that has not been configured explicitly in the config file.  That was
the only case that would cause an RPC message in the first place.

Change-Id: I40bbbf6233131ea5d40122ef9495fd3cb7dc823a
Closes-Bug: #1269567
",git fetch https://review.opendev.org/openstack/neutron refs/changes/28/66928/3 && git format-patch -1 --stdout FETCH_HEAD,"['neutron/agent/l3_agent.py', 'neutron/tests/unit/test_l3_agent.py']",2,f2c0cb2fa6c760ab62696bdfe00cd69d94180661,66928," self.plugin_api.get_external_network_id.reset_mock() self.assertFalse(self.plugin_api.get_external_network_id.called) agent = l3_agent.L3NATAgent(HOSTNAME, self.conf) l3_agent.L3NATAgent, HOSTNAME, self.conf) agent = l3_agent.L3NATAgent(HOSTNAME, self.conf) self.conf.set_override('external_network_bridge', '') agent = l3_agent.L3NATAgent(HOSTNAME, self.conf)"," self.plugin_api.get_external_network_id.return_value = None agent = l3_agent.L3NATAgent(HOSTNAME, self.conf) agent = l3_agent.L3NATAgent(HOSTNAME, self.conf) routers = [ {'id': _uuid(), 'routes': [], 'admin_state_up': True, 'external_gateway_info': {'network_id': 'aaa'}}] agent.router_info = {} agent._process_routers, routers) self.assertNotIn(routers[0]['id'], agent.router_info) agent = l3_agent.L3NATAgent(HOSTNAME, self.conf) agent = l3_agent.L3NATAgent(HOSTNAME, self.conf) self.conf.set_override('external_network_bridge', '')",12,20
openstack%2Fpython-keystoneclient~master~I3e70c795be357ceab8e5a1d12202c04fd88a02b8,openstack/python-keystoneclient,master,I3e70c795be357ceab8e5a1d12202c04fd88a02b8,Atomic write of certificate files and revocation list,MERGED,2014-02-28 16:29:02.000000000,2014-03-05 19:10:32.000000000,2014-03-05 19:10:32.000000000,"[{'_account_id': 3}, {'_account_id': 4}, {'_account_id': 792}, {'_account_id': 1916}, {'_account_id': 2218}, {'_account_id': 2472}, {'_account_id': 2750}, {'_account_id': 2903}, {'_account_id': 5707}, {'_account_id': 6482}, {'_account_id': 6486}, {'_account_id': 7191}, {'_account_id': 7725}]","[{'number': 1, 'created': '2014-02-28 16:29:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-keystoneclient/commit/15d71e7b4e1413f5c6cee5f1fd72ff992746137f', 'message': 'Atomic write of certificate files\n\nUsing a rename from a temporary file to avoid having partial writes.\n\nbug #1285981\n\nChange-Id: I3e70c795be357ceab8e5a1d12202c04fd88a02b8\n'}, {'number': 2, 'created': '2014-03-04 03:12:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-keystoneclient/commit/be9d098c1fa275d8361d761e993c6d46d3e687a9', 'message': 'Atomic write of certificate files\n\nUsing a rename from a temporary file to avoid having partial writes.\n\nCloses-Bug: #1285833\n\nChange-Id: I3e70c795be357ceab8e5a1d12202c04fd88a02b8\n'}, {'number': 3, 'created': '2014-03-04 15:40:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-keystoneclient/commit/4f0a6b2a8dfb2ed82637fb9934288d36d4d04d3d', 'message': 'Atomic write of certificate files and revocation list\n\nUsing a rename from a temporary file to avoid having partial writes.\n\nCloses-Bug: #1285833\n\nChange-Id: I3e70c795be357ceab8e5a1d12202c04fd88a02b8\n'}, {'number': 4, 'created': '2014-03-04 15:51:41.000000000', 'files': ['keystoneclient/middleware/auth_token.py'], 'web_link': 'https://opendev.org/openstack/python-keystoneclient/commit/b935741f6c93abae1c7aac41da92b475bbe14815', 'message': 'Atomic write of certificate files and revocation list\n\nUsing a rename from a temporary file to avoid having partial writes.\n\nCloses-Bug: #1285833\n\nChange-Id: I3e70c795be357ceab8e5a1d12202c04fd88a02b8\n'}]",10,77215,b935741f6c93abae1c7aac41da92b475bbe14815,38,13,4,2218,,,0,"Atomic write of certificate files and revocation list

Using a rename from a temporary file to avoid having partial writes.

Closes-Bug: #1285833

Change-Id: I3e70c795be357ceab8e5a1d12202c04fd88a02b8
",git fetch https://review.opendev.org/openstack/python-keystoneclient refs/changes/15/77215/4 && git format-patch -1 --stdout FETCH_HEAD,['keystoneclient/middleware/auth_token.py'],1,15d71e7b4e1413f5c6cee5f1fd72ff992746137f,atomic-write," def _atomic_write_to_signing_dir(self, file_name, value): with tempfile.NamedTemporaryFile(dir=self.signing_dirname, delete=False) as f: # In Python2, encoding is slow so the following check avoids it if # it is not absolutely necessary. if isinstance(value, six.text_type): value = value.encode('utf-8') f.write(value) os.rename(f.name, file_name) self._atomic_write_to_signing_dir(self.revoked_file_name, value) self._atomic_write_to_signing_dir(self.signing_cert_file_name, response.text) self._atomic_write_to_signing_dir(self.signing_ca_file_name, response.text) "," with tempfile.NamedTemporaryFile(dir=self.signing_dirname, delete=False) as f: # In Python2, encoding is slow so the following check avoids it if # it is not absolutely necessary. if isinstance(value, six.text_type): value = value.encode('utf-8') f.write(value) os.rename(f.name, self.revoked_file_name) def write_cert_file(data): with open(self.signing_cert_file_name, 'w') as certfile: certfile.write(data) write_cert_file(response.text) with open(self.signing_ca_file_name, 'w') as certfile: certfile.write(response.text)",16,15
openstack%2Fhorizon~master~I4ef2d87c33981db36d4ebd3de2f4841cdfa9dbfd,openstack/horizon,master,I4ef2d87c33981db36d4ebd3de2f4841cdfa9dbfd,Host aggregates panel.,MERGED,2014-02-04 18:57:30.000000000,2014-03-05 19:10:30.000000000,2014-03-05 19:10:29.000000000,"[{'_account_id': 3}, {'_account_id': 4264}, {'_account_id': 4978}, {'_account_id': 5623}, {'_account_id': 6610}, {'_account_id': 8746}, {'_account_id': 9275}, {'_account_id': 9313}, {'_account_id': 9331}, {'_account_id': 9412}, {'_account_id': 9450}, {'_account_id': 10179}, {'_account_id': 10247}, {'_account_id': 10275}]","[{'number': 1, 'created': '2014-02-04 18:57:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/f7ad6fbfd2de0624aa4117569fe3bde7e0de450d', 'message': 'This patch is a work in progress of the implementation\nof the host aggregate panel. From this panel, aggregates\ncould be added, deleted and edited.\nAnother panel will be added to manage availability zones.\nAny sugestion and feedback are welcome.\n\nChange-Id: I4ef2d87c33981db36d4ebd3de2f4841cdfa9dbfd\nCloses-Bug: #1261932\nImplements: blueprint manage-host-aggregates\n'}, {'number': 2, 'created': '2014-02-04 19:01:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/7f98a5bbfa297e67c8b923a3d96af452249026b8', 'message': 'This patch is a work in progress of the implementation of the host aggregate panel. From this panel, aggregates could be added, deleted and edited. Another panel will be added to manage availability zones. Any sugestion and feedback are welcome.\n\nChange-Id: I4ef2d87c33981db36d4ebd3de2f4841cdfa9dbfd\nCloses-Bug: #1261932\n'}, {'number': 3, 'created': '2014-02-04 21:06:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/f493010daf84f8bb2404763258e0611414016fb1', 'message': 'This patch is a work in progress of the\nimplementation of the host aggregate panel.\nFrom this panel, aggregates could be added,\ndeleted and edited. Another panel will be\nadded to manage availability zones.\nAny sugestion and feedback are welcome.\n\nChange-Id: I4ef2d87c33981db36d4ebd3de2f4841cdfa9dbfd\nCloses-Bug: #1261932\nImplements: blueprint manage-host-aggregates\n'}, {'number': 4, 'created': '2014-02-07 21:08:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/c68c82266ca1b0f47f127197bc9271169cdb1834', 'message': 'Host aggregates panel.\n\nOn this panel, aggregates could be added, deleted and edited.\nThis patch takes the aggregates panel out of System Info and\nputs it back in the main admin panel list, as now, aggregates\nare not static information. Any sugestion and feedback are\nwelcome.\n\nChange-Id: I4ef2d87c33981db36d4ebd3de2f4841cdfa9dbfd\nCloses-Bug: #1261932\nImplements: blueprint manage-host-aggregates\n'}, {'number': 5, 'created': '2014-02-20 17:44:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/4f76a972f4aa1e627a47adc81f0dd6de7fc6a018', 'message': 'Host aggregates panel.\n\nChanges were made on the code based on comments. Still\nmissing some tests in which we are working on.\n\nChange-Id: I4ef2d87c33981db36d4ebd3de2f4841cdfa9dbfd\nCloses-Bug: #1261932\nImplements: blueprint manage-host-aggregates\n'}, {'number': 6, 'created': '2014-02-21 18:00:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/91d06b41e2b060cef328ebb0fd464724793d58c9', 'message': 'Host aggregates panel.\n\nOn this panel, aggregates could be added, deleted and edited.\nThis patch takes the aggregates panel out of System Info and\nputs it back in the main admin panel list, as now, aggregates\nare not static information. The host can be associated to a\nhost aggregate on this panel as well.\n\nChange-Id: I4ef2d87c33981db36d4ebd3de2f4841cdfa9dbfd\nCloses-Bug: #1261932\nImplements: blueprint manage-host-aggregates\nCo-Authored-By: Santiago Baldassin <santiago.b.baldassin@intel.com>\nCo-Authored-By: Alejandro Paredes <alejandro.e.paredes@intel.com>\n'}, {'number': 7, 'created': '2014-02-23 15:14:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/d1d7568c4838db4894e7c4282f833636a18901b4', 'message': 'Host aggregates panel.\n\nOn this panel, aggregates could be added, deleted and edited.\nThis patch takes the aggregates panel out of System Info and\nputs it back in the main admin panel list, as now, aggregates\nare not static information. The host can be associated to a\nhost aggregate on this panel as well.\n\nChange-Id: I4ef2d87c33981db36d4ebd3de2f4841cdfa9dbfd\nCloses-Bug: #1261932\nImplements: blueprint manage-host-aggregates\nCo-Authored-By: Santiago Baldassin <santiago.b.baldassin@intel.com>\nCo-Authored-By: Alejandro Paredes <alejandro.e.paredes@intel.com>\n'}, {'number': 8, 'created': '2014-02-24 14:20:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/a46c47b5b81ef387c0188be0c6590207b62f77ac', 'message': 'Host aggregates panel.\n\nOn this panel, aggregates could be added, deleted and edited.\nThis patch takes the aggregates panel out of System Info and\nputs it back in the main admin panel list, as now, aggregates\nare not static information. The host can be associated to a\nhost aggregate on this panel as well.\n\nChange-Id: I4ef2d87c33981db36d4ebd3de2f4841cdfa9dbfd\nCloses-Bug: #1261932\nImplements: blueprint manage-host-aggregates\nCo-Authored-By: Santiago Baldassin <santiago.b.baldassin@intel.com>\nCo-Authored-By: Alejandro Paredes <alejandro.e.paredes@intel.com>\n'}, {'number': 9, 'created': '2014-02-27 21:25:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/002bc2e6a4c297269e156b1e3bb3661b1f34aabe', 'message': 'Host aggregates panel.\n\nOn this panel, aggregates could be added, deleted and edited.\nThis patch takes the aggregates panel out of System Info and\nputs it back in the main admin panel list, as now, aggregates\nare not static information. The host can be associated to a\nhost aggregate on this panel as well.\n\nChange-Id: I4ef2d87c33981db36d4ebd3de2f4841cdfa9dbfd\nCloses-Bug: #1261932\nImplements: blueprint manage-host-aggregates\nCo-Authored-By: Santiago Baldassin <santiago.b.baldassin@intel.com>\nCo-Authored-By: Alejandro Paredes <alejandro.e.paredes@intel.com>\n'}, {'number': 10, 'created': '2014-02-28 13:24:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/4e82ce54fa6aacb4a6a240a8826dd9f55e82893f', 'message': 'Host aggregates panel.\n\nOn this panel, aggregates could be added, deleted and edited.\nThis patch takes the aggregates panel out of System Info and\nputs it back in the main admin panel list, as now, aggregates\nare not static information. The host can be associated to a\nhost aggregate on this panel as well.\n\nChange-Id: I4ef2d87c33981db36d4ebd3de2f4841cdfa9dbfd\nCloses-Bug: #1261932\nImplements: blueprint manage-host-aggregates\nCo-Authored-By: Santiago Baldassin <santiago.b.baldassin@intel.com>\nCo-Authored-By: Alejandro Paredes <alejandro.e.paredes@intel.com>\n'}, {'number': 11, 'created': '2014-02-28 18:24:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/d31f931435c3585a83c44241e6dca3559c7dccf0', 'message': 'Host aggregates panel.\n\nOn this panel, aggregates could be added, deleted and edited.\nThis patch takes the aggregates panel out of System Info and\nputs it back in the main admin panel list, as now, aggregates\nare not static information. The host can be associated to a\nhost aggregate on this panel as well.\n\nChange-Id: I4ef2d87c33981db36d4ebd3de2f4841cdfa9dbfd\nCloses-Bug: #1261932\nImplements: blueprint manage-host-aggregates\nCo-Authored-By: Santiago Baldassin <santiago.b.baldassin@intel.com>\nCo-Authored-By: Alejandro Paredes <alejandro.e.paredes@intel.com>\n'}, {'number': 12, 'created': '2014-02-28 20:31:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/1bae6298d6542af8241797b7f6ea39157de4457d', 'message': 'Host aggregates panel.\n\nOn this panel, aggregates could be added, deleted and edited.\nThis patch takes the aggregates panel out of System Info and\nputs it back in the main admin panel list, as now, aggregates\nare not static information. The host can be associated to a\nhost aggregate on this panel as well.\n\nChange-Id: I4ef2d87c33981db36d4ebd3de2f4841cdfa9dbfd\nCloses-Bug: #1261932\nImplements: blueprint manage-host-aggregates\nCo-Authored-By: Santiago Baldassin <santiago.b.baldassin@intel.com>\nCo-Authored-By: Alejandro Paredes <alejandro.e.paredes@intel.com>\n'}, {'number': 13, 'created': '2014-03-03 14:14:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/2060a7d7e5ba4232f05d136ddee74645997db047', 'message': 'Host aggregates panel.\n\nOn this panel, aggregates could be added, deleted and edited.\nThis patch takes the aggregates panel out of System Info and\nputs it back in the main admin panel list, as now, aggregates\nare not static information. The host can be associated to a\nhost aggregate on this panel as well.\n\nChange-Id: I4ef2d87c33981db36d4ebd3de2f4841cdfa9dbfd\nCloses-Bug: #1261932\nImplements: blueprint manage-host-aggregates\nCo-Authored-By: Santiago Baldassin <santiago.b.baldassin@intel.com>\nCo-Authored-By: Alejandro Paredes <alejandro.e.paredes@intel.com>\n'}, {'number': 14, 'created': '2014-03-03 17:39:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/c4d898f75896deca2789a193ffebce34a8c18d79', 'message': 'Host aggregates panel.\n\nOn this panel, aggregates could be added, deleted and edited.\nThis patch takes the aggregates panel out of System Info and\nputs it back in the main admin panel list, as now, aggregates\nare not static information. The host can be associated to a\nhost aggregate on this panel as well.\n\nChange-Id: I4ef2d87c33981db36d4ebd3de2f4841cdfa9dbfd\nCloses-Bug: #1261932\nImplements: blueprint manage-host-aggregates\nCo-Authored-By: Santiago Baldassin <santiago.b.baldassin@intel.com>\nCo-Authored-By: Alejandro Paredes <alejandro.e.paredes@intel.com>\n'}, {'number': 15, 'created': '2014-03-04 15:31:22.000000000', 'files': ['openstack_dashboard/dashboards/admin/aggregates/forms.py', 'openstack_dashboard/dashboards/admin/aggregates/urls.py', 'openstack_dashboard/dashboards/admin/aggregates/templates/aggregates/create.html', 'openstack_dashboard/dashboards/admin/aggregates/tests.py', 'openstack_dashboard/dashboards/admin/aggregates/workflows.py', 'openstack_dashboard/dashboards/admin/aggregates/panel.py', 'openstack_dashboard/dashboards/admin/aggregates/templates/aggregates/index.html', 'openstack_dashboard/dashboards/admin/info/views.py', 'openstack_dashboard/dashboards/admin/aggregates/views.py', 'openstack_dashboard/dashboards/admin/aggregates/templates/aggregates/update.html', 'openstack_dashboard/dashboards/admin/dashboard.py', 'openstack_dashboard/dashboards/admin/aggregates/tables.py', 'openstack_dashboard/dashboards/admin/aggregates/__init__.py', 'openstack_dashboard/dashboards/admin/info/tabs.py', 'openstack_dashboard/dashboards/admin/aggregates/templates/aggregates/_manage_hosts.html', 'openstack_dashboard/dashboards/admin/aggregates/templates/aggregates/manage_hosts.html', 'openstack_dashboard/dashboards/admin/aggregates/constants.py', 'openstack_dashboard/dashboards/admin/aggregates/templates/aggregates/_update.html', 'openstack_dashboard/dashboards/admin/info/tables.py', 'openstack_dashboard/test/test_data/nova_data.py', 'openstack_dashboard/dashboards/admin/info/constants.py', 'openstack_dashboard/dashboards/admin/info/tests.py', 'openstack_dashboard/api/nova.py'], 'web_link': 'https://opendev.org/openstack/horizon/commit/ed1525bc91e1ca68a33117f0dbef4a241f33971f', 'message': 'Host aggregates panel.\n\nOn this panel, aggregates could be added, deleted and edited.\nThis patch takes the aggregates panel out of System Info and\nputs it back in the main admin panel list, as now, aggregates\nare not static information. The host can be associated to a\nhost aggregate on this panel as well.\n\nChange-Id: I4ef2d87c33981db36d4ebd3de2f4841cdfa9dbfd\nCloses-Bug: #1261932\nImplements: blueprint manage-host-aggregates\nCo-Authored-By: Santiago Baldassin <santiago.b.baldassin@intel.com>\nCo-Authored-By: Alejandro Paredes <alejandro.e.paredes@intel.com>\n'}]",154,71061,ed1525bc91e1ca68a33117f0dbef4a241f33971f,92,14,15,9313,,,0,"Host aggregates panel.

On this panel, aggregates could be added, deleted and edited.
This patch takes the aggregates panel out of System Info and
puts it back in the main admin panel list, as now, aggregates
are not static information. The host can be associated to a
host aggregate on this panel as well.

Change-Id: I4ef2d87c33981db36d4ebd3de2f4841cdfa9dbfd
Closes-Bug: #1261932
Implements: blueprint manage-host-aggregates
Co-Authored-By: Santiago Baldassin <santiago.b.baldassin@intel.com>
Co-Authored-By: Alejandro Paredes <alejandro.e.paredes@intel.com>
",git fetch https://review.opendev.org/openstack/horizon refs/changes/61/71061/11 && git format-patch -1 --stdout FETCH_HEAD,"['openstack_dashboard/dashboards/admin/aggregates/urls.py', 'openstack_dashboard/dashboards/admin/aggregates/templates/aggregates/create.html', 'openstack_dashboard/dashboards/admin/aggregates/workflows.py', 'openstack_dashboard/dashboards/admin/aggregates/panel.py', 'openstack_dashboard/dashboards/admin/aggregates/templates/aggregates/index.html', 'openstack_dashboard/dashboards/admin/aggregates/views.py', 'openstack_dashboard/dashboards/admin/aggregates/templates/aggregates/update.html', 'openstack_dashboard/dashboards/admin/dashboard.py', 'openstack_dashboard/dashboards/admin/aggregates/tables.py', 'openstack_dashboard/dashboards/admin/aggregates/__init__.py', 'openstack_dashboard/dashboards/admin/aggregates/templates/aggregates/_update.html', 'openstack_dashboard/api/nova.py']",12,f7ad6fbfd2de0624aa4117569fe3bde7e0de450d,bp/manage-host-aggregates,"def aggregate_create(request, name, availability_zone='auto'): aggregate = novaclient(request).aggregates.create(name, availability_zone) return aggregate def aggregate_delete(request, aggregate_id): novaclient(request).aggregates.delete(aggregate_id) def aggregate_get(request, aggregate_id): return novaclient(request).aggregates.get(aggregate_id) ",,464,2
openstack%2Fneutron~master~I494a6f95c2321befc3c0bfedc719e18a1826d9d5,openstack/neutron,master,I494a6f95c2321befc3c0bfedc719e18a1826d9d5,NSX: make sync backend run more often,MERGED,2014-02-26 18:31:45.000000000,2014-03-05 19:09:39.000000000,2014-03-05 19:09:38.000000000,"[{'_account_id': 3}, {'_account_id': 261}, {'_account_id': 748}, {'_account_id': 1653}, {'_account_id': 2592}, {'_account_id': 4395}, {'_account_id': 5170}, {'_account_id': 9008}, {'_account_id': 9732}, {'_account_id': 9787}, {'_account_id': 9845}, {'_account_id': 9925}, {'_account_id': 10116}, {'_account_id': 10117}, {'_account_id': 10153}, {'_account_id': 10184}, {'_account_id': 10192}, {'_account_id': 10294}]","[{'number': 1, 'created': '2014-02-26 18:31:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/e64aa07d84fe3fdaffa0220250dc646eb5fb4598', 'message': 'WIP DO NO MERGE test bumping the sync interval..\n\nChange-Id: I494a6f95c2321befc3c0bfedc719e18a1826d9d5\n'}, {'number': 2, 'created': '2014-02-26 20:34:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/5177255e92baa2a9ff97ebdbff7d59fe4c90965e', 'message': ""NSX: make sync backend run more often\n\nThis patch bumps the state_sync_interval from 120 seconds to 10 seconds\nso that resource's operation status are synced to the db quicker. This cuts\nthe amount of time that tempest takes to run by half.\n\nCloses-bug: 1285338\n\nChange-Id: I494a6f95c2321befc3c0bfedc719e18a1826d9d5\n""}, {'number': 3, 'created': '2014-02-26 23:00:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/20f774c88d98588076f744579dbd02b4936ef86d', 'message': ""NSX: make sync backend run more often\n\nThis patch bumps the state_sync_interval from 120 seconds to 10 seconds\nso that resource's operation status are synced to the db quicker. This cuts\nthe amount of time that tempest takes to run by half.\n\nCloses-bug: 1285338\nCo-Authored-By: Salvatore Orlando <salv.orlando@gmail.com>\nChange-Id: I494a6f95c2321befc3c0bfedc719e18a1826d9d5\n""}, {'number': 4, 'created': '2014-02-28 04:49:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/e514112c7d47f948e689370da2ba7dfee717f218', 'message': ""NSX: make sync backend run more often\n\nThis patch bumps the state_sync_interval from 120 seconds to 10 seconds\nso that resource's operation status are synced to the db quicker. This cuts\nthe amount of time that tempest takes to run by half.\n\nCloses-bug: 1285338\nCo-Authored-By: Salvatore Orlando <salv.orlando@gmail.com>\nChange-Id: I494a6f95c2321befc3c0bfedc719e18a1826d9d5\n""}, {'number': 5, 'created': '2014-02-28 16:11:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/53cf122501084d3b955116b6670c51c9aa694e58', 'message': ""NSX: make sync backend run more often\n\nThis patch bumps the state_sync_interval from 120 seconds to 10 seconds\nso that resource's operation status are synced to the db quicker. This cuts\nthe amount of time that tempest takes to run by half.\n\nCloses-bug: 1285338\nCo-Authored-By: Salvatore Orlando <salv.orlando@gmail.com>\nChange-Id: I494a6f95c2321befc3c0bfedc719e18a1826d9d5\n""}, {'number': 6, 'created': '2014-03-03 19:53:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/45fb6228122c5589239daa873593140206d0b011', 'message': ""NSX: make sync backend run more often\n\nThis patch bumps the state_sync_interval from 120 seconds to 10 seconds\nso that resource's operation status are synced to the db quicker. This cuts\nthe amount of time that tempest takes to run by half.\n\nCloses-bug: 1285338\nCo-Authored-By: Salvatore Orlando <salv.orlando@gmail.com>\nChange-Id: I494a6f95c2321befc3c0bfedc719e18a1826d9d5\n""}, {'number': 7, 'created': '2014-03-03 22:22:32.000000000', 'files': ['neutron/plugins/vmware/common/config.py', 'etc/neutron/plugins/vmware/nsx.ini'], 'web_link': 'https://opendev.org/openstack/neutron/commit/eef7efb5c83688a29822451de58400b0b57c0a56', 'message': ""NSX: make sync backend run more often\n\nThis patch bumps the state_sync_interval from 120 seconds to 10 seconds\nso that resource's operation status are synced to the db quicker. This cuts\nthe amount of time that tempest takes to run by half.\n\nCloses-bug: 1285338\nCo-Authored-By: Salvatore Orlando <salv.orlando@gmail.com>\nChange-Id: I494a6f95c2321befc3c0bfedc719e18a1826d9d5\n""}]",5,76617,eef7efb5c83688a29822451de58400b0b57c0a56,155,18,7,4395,,,0,"NSX: make sync backend run more often

This patch bumps the state_sync_interval from 120 seconds to 10 seconds
so that resource's operation status are synced to the db quicker. This cuts
the amount of time that tempest takes to run by half.

Closes-bug: 1285338
Co-Authored-By: Salvatore Orlando <salv.orlando@gmail.com>
Change-Id: I494a6f95c2321befc3c0bfedc719e18a1826d9d5
",git fetch https://review.opendev.org/openstack/neutron refs/changes/17/76617/5 && git format-patch -1 --stdout FETCH_HEAD,['neutron/plugins/nicira/common/config.py'],1,e64aa07d84fe3fdaffa0220250dc646eb5fb4598,master," cfg.IntOpt('state_sync_interval', default=10,"," cfg.IntOpt('state_sync_interval', default=120,",1,1
openstack%2Fheat~master~I5731ba72491dcf515c5d230b55056d9263341c54,openstack/heat,master,I5731ba72491dcf515c5d230b55056d9263341c54,Add tools/create_heat_domain helper script,MERGED,2014-03-05 00:12:55.000000000,2014-03-05 19:09:31.000000000,2014-03-05 19:09:30.000000000,"[{'_account_id': 3}, {'_account_id': 4571}, {'_account_id': 6488}]","[{'number': 1, 'created': '2014-03-05 00:12:55.000000000', 'files': ['tools/create_heat_domain'], 'web_link': 'https://opendev.org/openstack/heat/commit/c05dc06f0b437460627180312cbb949bf6e3a0b4', 'message': ""Add tools/create_heat_domain helper script\n\nFor users who don't yet have python-openstackclient, or who require\na more automated way of creating the heat domain and domain-admin\nuser, provide a simple wrapper for the keystoneclient python API\nwhich will create the domain and user, then print a helpful cut/paste\nmessage to allow heat.conf to be easily updated.\n\nIt requires a cloud-admin users credentials to be sourced in the\nenvironment, OS_USERNAME/OS_PASSWORD/OS_AUTH_URL and also a script\nspecific variable HEAT_DOMAIN_PASSWORD which specifies the password\nfor the domain-admin user.  Other values may be overridden by the\nenvironment but default to sane values.\n\nChange-Id: I5731ba72491dcf515c5d230b55056d9263341c54\nPartial-Bug: #1287980\n""}]",1,78048,c05dc06f0b437460627180312cbb949bf6e3a0b4,7,3,1,4328,,,0,"Add tools/create_heat_domain helper script

For users who don't yet have python-openstackclient, or who require
a more automated way of creating the heat domain and domain-admin
user, provide a simple wrapper for the keystoneclient python API
which will create the domain and user, then print a helpful cut/paste
message to allow heat.conf to be easily updated.

It requires a cloud-admin users credentials to be sourced in the
environment, OS_USERNAME/OS_PASSWORD/OS_AUTH_URL and also a script
specific variable HEAT_DOMAIN_PASSWORD which specifies the password
for the domain-admin user.  Other values may be overridden by the
environment but default to sane values.

Change-Id: I5731ba72491dcf515c5d230b55056d9263341c54
Partial-Bug: #1287980
",git fetch https://review.opendev.org/openstack/heat refs/changes/48/78048/1 && git format-patch -1 --stdout FETCH_HEAD,['tools/create_heat_domain'],1,c05dc06f0b437460627180312cbb949bf6e3a0b4,bug/1287980,"#!/usr/bin/env python # # Licensed under the Apache License, Version 2.0 (the ""License""); you may # not use this file except in compliance with the License. You may obtain # a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT # WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the # License for the specific language governing permissions and limitations # under the License. import logging import os import sys from keystoneclient.v3 import client import keystoneclient.exceptions as kc_exception logger = logging.getLogger(__name__) DEBUG = False USERNAME=os.environ.get('OS_USERNAME', None) PASSWORD=os.environ.get('OS_PASSWORD', None) AUTH_URL=os.environ.get('OS_AUTH_URL', '').replace('v2.0', 'v3') HEAT_DOMAIN_NAME=os.environ.get('HEAT_DOMAIN', 'heat') HEAT_DOMAIN_ADMIN=os.environ.get('HEAT_DOMAIN_ADMIN', 'heat_domain_admin') HEAT_DOMAIN_PASSWORD=os.environ.get('HEAT_DOMAIN_PASSWORD', None) HEAT_DOMAIN_DESCRIPTION='Contains users and projects created by heat' logger.debug(""USERNAME=%s"" % USERNAME) logger.debug(""PASSWORD=%s"" % PASSWORD) logger.debug(""AUTH_URL=%s"" % AUTH_URL) def main(): log_lvl = logging.DEBUG if DEBUG else logging.INFO logging.basicConfig( format=""%(levelname)s (%(module)s:%(lineno)d) %(message)s"", level=log_lvl) c = client.Client(debug=DEBUG, username=USERNAME, password=PASSWORD, auth_url=AUTH_URL, endpoint=AUTH_URL) ret = c.authenticate() # Create the heat domain logger.info(""Creating domain %s"" % HEAT_DOMAIN_NAME) try: heat_domain = c.domains.create(name=HEAT_DOMAIN_NAME, description=HEAT_DOMAIN_DESCRIPTION) except kc_exception.Conflict: logger.warning(""Domain %s already exists"" % HEAT_DOMAIN_NAME) heat_domain = c.domains.list(name=HEAT_DOMAIN_NAME)[0] if heat_domain.name != HEAT_DOMAIN_NAME: logger.error(""Unexpected filtered list response, please upgrade "" ""keystoneclient to >= 0.5"") sys.exit(1) # Create heat domain admin user if not HEAT_DOMAIN_PASSWORD: logger.error(""Must export HEAT_DOMAIN_PASSWORD for domain admin user"") sys.exit(1) try: domain_admin = c.users.create(name=HEAT_DOMAIN_ADMIN, password=HEAT_DOMAIN_PASSWORD, domain=heat_domain, description=""Heat domain admin"") except kc_exception.Conflict: logger.warning(""User %s already exists"" % HEAT_DOMAIN_ADMIN) domain_admin = c.users.list(name=HEAT_DOMAIN_ADMIN)[0] # Make the user a domain admin roles_list = c.roles.list() # FIXME(shardy): seems filtering roles by name currently doesn't work admin_role = [r for r in roles_list if r.name == 'admin'][0] c.roles.grant(role=admin_role, user=domain_admin, domain=heat_domain) print ""\nPlease update your heat.conf with the following in [DEFAULT]\n"" print ""stack_user_domain=%s"" % heat_domain.id print ""stack_domain_admin=%s"" % HEAT_DOMAIN_ADMIN print ""stack_domain_admin_password=%s"" % HEAT_DOMAIN_PASSWORD if __name__ == ""__main__"": main() ",,92,0
openstack%2Fopenstack-manuals~master~I842ccea9fdb0c6d721f5742c6848d02b277d5c73,openstack/openstack-manuals,master,I842ccea9fdb0c6d721f5742c6848d02b277d5c73,Add list of service log files used by dashboard,MERGED,2014-02-27 07:10:12.000000000,2014-03-05 19:04:49.000000000,2014-03-05 19:04:48.000000000,"[{'_account_id': 3}, {'_account_id': 612}, {'_account_id': 964}, {'_account_id': 6547}, {'_account_id': 6772}, {'_account_id': 9355}]","[{'number': 1, 'created': '2014-02-27 07:10:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/11ffcc1fa4f1d806a6d8b8b0aaf9e3336c0f39b7', 'message': 'Add list of service log files used by dashboard\n\nThis patch adds the list of log files used by the dashboard / httpd\nservices, along with a description of each.\n\nChange-Id: I842ccea9fdb0c6d721f5742c6848d02b277d5c73\nPartial-Bug: #1282882\n'}, {'number': 2, 'created': '2014-03-03 01:05:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/114615f07b5554577c613fa4a336aef4603a3cb1', 'message': 'Add list of service log files used by dashboard\n\nThis patch adds the list of log files used by the dashboard / httpd\nservices, along with a description of each.\n\nChange-Id: I842ccea9fdb0c6d721f5742c6848d02b277d5c73\nPartial-Bug: #1282882\n'}, {'number': 3, 'created': '2014-03-04 00:04:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/e1881bca61bc329b2afb7a7e9b7e3f6999aa20b5', 'message': 'Add list of service log files used by dashboard\n\nThis patch adds the list of log files used by the dashboard / httpd\nservices, along with a description of each.\n\nChange-Id: I842ccea9fdb0c6d721f5742c6848d02b277d5c73\nPartial-Bug: #1282882\n'}, {'number': 4, 'created': '2014-03-04 23:45:25.000000000', 'files': ['doc/config-reference/dashboard/section_dashboard-log-files.xml', 'doc/config-reference/ch_dashboardconfigure.xml'], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/6ec12953bf300c1d2f2bd91432fbbbc18415997b', 'message': 'Add list of service log files used by dashboard\n\nThis patch adds the list of log files used by the dashboard / httpd\nservices, along with a description of each.\n\nChange-Id: I842ccea9fdb0c6d721f5742c6848d02b277d5c73\nPartial-Bug: #1282882\n'}]",7,76782,6ec12953bf300c1d2f2bd91432fbbbc18415997b,22,6,4,9355,,,0,"Add list of service log files used by dashboard

This patch adds the list of log files used by the dashboard / httpd
services, along with a description of each.

Change-Id: I842ccea9fdb0c6d721f5742c6848d02b277d5c73
Partial-Bug: #1282882
",git fetch https://review.opendev.org/openstack/openstack-manuals refs/changes/82/76782/1 && git format-patch -1 --stdout FETCH_HEAD,"['doc/config-reference/dashboard/section_dashboard-log-files.xml', 'doc/config-reference/ch_dashboardconfigure.xml']",2,11ffcc1fa4f1d806a6d8b8b0aaf9e3336c0f39b7,1282882_horizon-service-logs," <xi:include href=""dashboard/section_dashboard-log-files.xml""/>",,47,0
openstack%2Fheat~master~I1f51e7fbdd4816842ceefeeee1a804e0fc671c45,openstack/heat,master,I1f51e7fbdd4816842ceefeeee1a804e0fc671c45,Native ScalingPolicy resource,MERGED,2014-03-03 09:15:37.000000000,2014-03-05 18:58:37.000000000,2014-03-05 18:58:36.000000000,"[{'_account_id': 3}, {'_account_id': 4328}, {'_account_id': 4571}, {'_account_id': 4715}, {'_account_id': 6800}, {'_account_id': 7385}]","[{'number': 1, 'created': '2014-03-03 09:15:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/51e38fbcfeae41fe35f400619cf381ba6e2fe3a1', 'message': 'Native ScalingPolicy resource\n\nImplement a native scaling policy resource providing the same interface\nas the AWS one.\n\nblueprint as-intermediate-resources\nCo-Authored-By: cedric.soulas@cloudwatt.com\nChange-Id: I1f51e7fbdd4816842ceefeeee1a804e0fc671c45\n'}, {'number': 2, 'created': '2014-03-03 17:40:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/656a9241ef0dd8bd473e8ae7cdcc1cf32a0c39d4', 'message': 'Native ScalingPolicy resource\n\nImplement a native scaling policy resource providing the same interface\nas the AWS one.\n\nblueprint as-intermediate-resources\nCo-Authored-By: cedric.soulas@cloudwatt.com\nChange-Id: I1f51e7fbdd4816842ceefeeee1a804e0fc671c45\n'}, {'number': 3, 'created': '2014-03-04 15:00:46.000000000', 'files': ['heat/engine/resources/autoscaling.py', 'heat/tests/test_heat_autoscaling_group.py'], 'web_link': 'https://opendev.org/openstack/heat/commit/d7b519ecb32c0291e18c9adb91ced498ed8ba0bc', 'message': 'Native ScalingPolicy resource\n\nImplement a native scaling policy resource providing the same interface\nas the AWS one.\n\nblueprint as-intermediate-resources\nCo-Authored-By: cedric.soulas@cloudwatt.com\nChange-Id: I1f51e7fbdd4816842ceefeeee1a804e0fc671c45\n'}]",4,77529,d7b519ecb32c0291e18c9adb91ced498ed8ba0bc,18,6,3,7385,,,0,"Native ScalingPolicy resource

Implement a native scaling policy resource providing the same interface
as the AWS one.

blueprint as-intermediate-resources
Co-Authored-By: cedric.soulas@cloudwatt.com
Change-Id: I1f51e7fbdd4816842ceefeeee1a804e0fc671c45
",git fetch https://review.opendev.org/openstack/heat refs/changes/29/77529/1 && git format-patch -1 --stdout FETCH_HEAD,"['heat/engine/resources/autoscaling.py', 'heat/tests/test_heat_autoscaling_group.py']",2,51e38fbcfeae41fe35f400619cf381ba6e2fe3a1,bp/as-intermediate-resources,"import datetimefrom heat.openstack.common import timeutils class ScalingPolicyTest(HeatTestCase): as_template = ''' heat_template_version: 2013-05-23 resources: my-policy: type: OS::Heat::ScalingPolicy properties: auto_scaling_group_id: {get_resource: my-group} adjustment_type: ChangeInCapacity scaling_adjustment: 1 my-group: type: OS::Heat::AutoScalingGroup properties: max_size: 5 min_size: 1 resource: type: ResourceWithProps properties: Foo: hello ''' def setUp(self): super(ScalingPolicyTest, self).setUp() utils.setup_dummy_db() resource._register_class('ResourceWithProps', generic_resource.ResourceWithProps) self.fc = fakes.FakeKeystoneClient() client = self.patchobject(clients.OpenStackClients, ""keystone"") client.return_value = self.fc self.parsed = template_format.parse(self.as_template) def test_signal(self): stack = utils.parse_stack(self.parsed) stack.create() self.assertEqual((stack.CREATE, stack.COMPLETE), stack.state) policy = stack['my-policy'] group = stack['my-group'] self.assertEqual(""1234"", policy.FnGetRefId()) self.assertEqual(1, len(group.get_instance_names())) policy.signal() self.assertEqual(2, len(group.get_instance_names())) def test_signal_with_cooldown(self): self.parsed['resources']['my-policy']['properties']['cooldown'] = 60 stack = utils.parse_stack(self.parsed) stack.create() policy = stack['my-policy'] group = stack['my-group'] self.assertEqual(1, len(group.get_instance_names())) policy.signal() self.assertEqual(2, len(group.get_instance_names())) policy.signal() # The second signal shouldn't have changed it because of cooldown self.assertEqual(2, len(group.get_instance_names())) past = timeutils.strtime(timeutils.utcnow() - datetime.timedelta(seconds=65)) policy.metadata = {past: 'ChangeInCapacity : 1'} policy.signal() self.assertEqual(3, len(group.get_instance_names()))",,117,0
openstack%2Fglance~master~I389103574fc52feed96c592cbafbb52faccda939,openstack/glance,master,I389103574fc52feed96c592cbafbb52faccda939,Document for API message localization,MERGED,2014-02-22 07:07:52.000000000,2014-03-05 18:54:38.000000000,2014-03-05 18:54:37.000000000,"[{'_account_id': 3}, {'_account_id': 616}, {'_account_id': 6484}, {'_account_id': 6549}, {'_account_id': 8646}, {'_account_id': 9382}]","[{'number': 1, 'created': '2014-02-22 07:07:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/44973784b138df557d5cc5b542e79d742c2cdbc0', 'message': 'Document for API message localization\n\nThis patch will add document about how to use the\nAPI message localization.\n\nPartially implements bp i18n-messages\n\nChange-Id: I389103574fc52feed96c592cbafbb52faccda939\n'}, {'number': 3, 'created': '2014-02-27 10:51:08.000000000', 'files': ['doc/source/glanceapi.rst'], 'web_link': 'https://opendev.org/openstack/glance/commit/efb8df7f2ca8b37a0f44a8744b8d31f396c007c9', 'message': 'Document for API message localization\n\nThis patch will add document about how to use the\nAPI message localization.\n\nPartially implements bp i18n-messages\n\nChange-Id: I389103574fc52feed96c592cbafbb52faccda939\n'}, {'number': 2, 'created': '2014-02-27 10:51:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/0b226faed807cf4f50733cb1f122dd3aa97ad838', 'message': 'Document for API message localization\n\nThis patch will add document about how to use the\nAPI message localization.\n\nPartially implements bp i18n-messages\n\nChange-Id: I389103574fc52feed96c592cbafbb52faccda939\n'}]",3,75623,efb8df7f2ca8b37a0f44a8744b8d31f396c007c9,27,6,3,6484,,,0,"Document for API message localization

This patch will add document about how to use the
API message localization.

Partially implements bp i18n-messages

Change-Id: I389103574fc52feed96c592cbafbb52faccda939
",git fetch https://review.opendev.org/openstack/glance refs/changes/23/75623/3 && git format-patch -1 --stdout FETCH_HEAD,['doc/source/glanceapi.rst'],1,44973784b138df557d5cc5b542e79d742c2cdbc0,bp/i18n-messages," API Message Localization --------------------------------------- Currently, Glance supports REST API message localization, no matter the language that Glance is running on. For example, user can get Chinese API message even though the locale language on target Glance server is English. How to use it ************* Except the normal HTTP headers, user need to specify the **Accept-Language** to indicate what kind of language will be used to translate the message. For more info about Accept-Language, please refer http://www.w3.org/Protocols/rfc2616/rfc2616-sec14.html A typical curl API request will be like below:: curl -i -X GET -H 'Accept-Language: zh' -H 'Content-Type: application/json' http://127.0.0.1:9292/v2/images/aaa Then the response will be like the following:: HTTP/1.1 404 Not Found Content-Length: 234 Content-Type: text/html; charset=UTF-8 X-Openstack-Request-Id: req-54d403a0-064e-4544-8faf-4aeef086f45a Date: Sat, 22 Feb 2014 06:26:26 GMT <html> <head> <title>404 Not Found</title> </head> <body> <h1>404 Not Found</h1> &#25214;&#19981;&#21040;&#20219;&#20309;&#20855;&#26377;&#26631;&#35782; aaa &#30340;&#26144;&#20687;<br /><br /> </body> </html> .. note:: Be sure there is the language package under /usr/share/locale-langpack/ on the target Glance server.",,40,0
openstack%2Fopenstack-manuals~master~I5410cf4b214800f9be433a513a320d69bc303208,openstack/openstack-manuals,master,I5410cf4b214800f9be433a513a320d69bc303208,Minor edits for the Config Ref Guide.,MERGED,2014-03-01 13:00:35.000000000,2014-03-05 18:53:18.000000000,2014-03-05 18:53:17.000000000,"[{'_account_id': 3}, {'_account_id': 964}, {'_account_id': 6547}, {'_account_id': 7264}, {'_account_id': 7923}]","[{'number': 1, 'created': '2014-03-01 13:00:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/b38ea60f0259db960b995f57684559c558400d3f', 'message': 'Minor edits for the Config Ref Guide.\n\nMinor edits (found in the last release), including link and case correction, and service-name updates.\n\nChange-Id: I5410cf4b214800f9be433a513a320d69bc303208\nPartial-Bug: #1121866\n'}, {'number': 2, 'created': '2014-03-01 13:09:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/474c263def7055b507358df3eb33805c91fcc9d3', 'message': 'Minor edits for the Config Ref Guide.\n\nMinor edits (found in the last release), including link and case correction, and service-name updates.\n\nChange-Id: I5410cf4b214800f9be433a513a320d69bc303208\nPartial-Bug: #1121866\n'}, {'number': 3, 'created': '2014-03-02 23:58:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/93648f22978973013dd0de44d568e2beeead8c04', 'message': 'Minor edits for the Config Ref Guide.\n\nMinor edits (found in the last release), including link and case correction, and service-name updates.\n\nChange-Id: I5410cf4b214800f9be433a513a320d69bc303208\nPartial-Bug: #1121866\n'}, {'number': 4, 'created': '2014-03-05 06:10:58.000000000', 'files': ['doc/config-reference/block-storage/drivers/huawei-storage-driver.xml', 'doc/common/section_compute_config-api.xml', 'doc/config-reference/block-storage/section_block-storage-overview.xml', 'doc/common/section_cli_nova_quotas.xml', 'doc/common/section_identity-configure.xml', 'doc/config-reference/object-storage/section_object-storage-features.xml', 'doc/config-reference/block-storage/drivers/nexenta-volume-driver.xml', 'doc/config-reference/block-storage/drivers/solidfire-volume-driver.xml', 'doc/config-reference/block-storage/drivers/ibm-storwize-svc-driver.xml', 'doc/config-reference/block-storage/drivers/ibm-gpfs-volume-driver.xml', 'doc/config-reference/compute/section_hypervisor_kvm.xml', 'doc/config-reference/block-storage/drivers/emc-volume-driver.xml', 'doc/config-reference/block-storage/drivers/ceph-rbd-volume-driver.xml', 'doc/config-reference/compute/section_hypervisor_baremetal.xml', 'doc/config-reference/compute/section_hypervisor_lxc.xml', 'doc/config-reference/compute/section_hypervisor_qemu.xml', 'doc/config-reference/object-storage/section_object-storage-cors.xml', 'doc/config-reference/compute/section_compute-hypervisors.xml', 'doc/config-reference/compute/section_hypervisor_docker.xml', 'doc/config-reference/object-storage/section_configure_s3.xml', 'doc/config-reference/block-storage/drivers/glusterfs-driver.xml', 'doc/config-reference/object-storage/section_object-storage-listendpoints.xml'], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/100441efe6df61d2b8d4bba02f8dc50133bb5301', 'message': 'Minor edits for the Config Ref Guide.\n\nMinor edits (found in the last release), including link and case correction, and service-name updates.\n\nChange-Id: I5410cf4b214800f9be433a513a320d69bc303208\nPartial-Bug: #1121866\n'}]",12,77349,100441efe6df61d2b8d4bba02f8dc50133bb5301,21,5,4,7264,,,0,"Minor edits for the Config Ref Guide.

Minor edits (found in the last release), including link and case correction, and service-name updates.

Change-Id: I5410cf4b214800f9be433a513a320d69bc303208
Partial-Bug: #1121866
",git fetch https://review.opendev.org/openstack/openstack-manuals refs/changes/49/77349/1 && git format-patch -1 --stdout FETCH_HEAD,"['doc/config-reference/block-storage/drivers/huawei-storage-driver.xml', 'doc/common/section_compute_config-api.xml', 'doc/config-reference/block-storage/section_block-storage-overview.xml', 'doc/common/section_cli_nova_quotas.xml', 'doc/common/section_identity-configure.xml', 'doc/config-reference/object-storage/section_object-storage-features.xml', 'doc/config-reference/block-storage/drivers/nexenta-volume-driver.xml', 'doc/config-reference/block-storage/drivers/solidfire-volume-driver.xml', 'doc/config-reference/block-storage/drivers/ibm-storwize-svc-driver.xml', 'doc/config-reference/block-storage/drivers/ibm-gpfs-volume-driver.xml', 'doc/config-reference/compute/section_hypervisor_kvm.xml', 'doc/config-reference/block-storage/drivers/emc-volume-driver.xml', 'doc/config-reference/block-storage/drivers/hp-3par-driver.xml', 'doc/config-reference/block-storage/drivers/ceph-rbd-volume-driver.xml', 'doc/config-reference/compute/section_hypervisor_baremetal.xml', 'doc/config-reference/compute/section_hypervisor_lxc.xml', 'doc/config-reference/compute/section_hypervisor_qemu.xml', 'doc/config-reference/object-storage/section_object-storage-cors.xml', 'doc/config-reference/compute/section_compute-hypervisors.xml', 'doc/config-reference/compute/section_hypervisor_docker.xml', 'doc/config-reference/object-storage/section_configure_s3.xml', 'doc/config-reference/block-storage/drivers/glusterfs-driver.xml', 'doc/config-reference/object-storage/section_object-storage-listendpoints.xml']",23,b38ea60f0259db960b995f57684559c558400d3f,fixLinks, <para>The endpoint listing middleware enables third-party services that use data locality information to integrate with OpenStack Object Storage. This middleware reduces network overhead and is designed for third-party services that run inside the firewall. Deploy this middleware on a proxy server because usage of this middleware is not authenticated.</para>, <para>The endpoint listing middleware enables third-party services that use data locality information to integrate with swift. This middleware reduces network overhead and is designed for third-party services that run inside the firewall. Deploy this middleware on a proxy server because usage of this middleware is not authenticated.</para>,254,316
