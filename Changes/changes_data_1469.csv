id,project,branch,change_id,subject,status,created,updated,submitted,reviewers,revisions,total_comment_count,number,current_revision,discussion_messages_count,reviewers_count,revisions_count,owner_account_id,owner_name,owner_username,is_owner_bot,commit_message,git_command,changed_files,files_count,commit_id,topic,added_lines,deleted_lines,insertions,deletions
openstack%2Fkeystone~874846,openstack/keystone,stable/ussuri,I59ebf0fa77391d49b2349e918fc55f96318c42a6,[PooledLDAPHandler] Ensure result3() invokes message.clean(),MERGED,2023-02-24 07:12:03.000000000,2023-07-13 11:45:04.000000000,2023-07-13 11:43:54.000000000,"[{'_account_id': 7414}, {'_account_id': 14250}, {'_account_id': 22348}]","[{'number': 1, 'created': '2023-02-24 07:12:03.000000000', 'files': ['keystone/tests/unit/test_backend_ldap_pool.py', 'keystone/identity/backends/ldap/common.py', 'keystone/tests/unit/fakeldap.py'], 'web_link': 'https://opendev.org/openstack/keystone/commit/9680ee771b3b6ed93cee712aad8a0b9e19592d56', 'message': '[PooledLDAPHandler] Ensure result3() invokes message.clean()\n\nresult3 does not invoke message.clean() when an exception is thrown\nby `message.connection.result3()` call, causing pool connection\nassociated with the message to be marked active forever. This causes\na denial-of-service on ldappool.\n\nThe fix ensures message.clean() is invoked by wrapping the offending\ncall in try-except-finally and putting the message.clean() in finally\nblock.\n\nCloses-Bug: #1998789\n\nChange-Id: I59ebf0fa77391d49b2349e918fc55f96318c42a6\nSigned-off-by: Mustafa Kemal Gilor <mustafa.gilor@canonical.com>\n(cherry picked from commit ff632a81fb09e6d9f3298e494d53eb6df50269cf)\n'}]",0,874846,9680ee771b3b6ed93cee712aad8a0b9e19592d56,9,3,1,34980,,,0,"[PooledLDAPHandler] Ensure result3() invokes message.clean()

result3 does not invoke message.clean() when an exception is thrown
by `message.connection.result3()` call, causing pool connection
associated with the message to be marked active forever. This causes
a denial-of-service on ldappool.

The fix ensures message.clean() is invoked by wrapping the offending
call in try-except-finally and putting the message.clean() in finally
block.

Closes-Bug: #1998789

Change-Id: I59ebf0fa77391d49b2349e918fc55f96318c42a6
Signed-off-by: Mustafa Kemal Gilor <mustafa.gilor@canonical.com>
(cherry picked from commit ff632a81fb09e6d9f3298e494d53eb6df50269cf)
",git fetch https://review.opendev.org/openstack/keystone refs/changes/46/874846/1 && git format-patch -1 --stdout FETCH_HEAD,"['keystone/tests/unit/test_backend_ldap_pool.py', 'keystone/identity/backends/ldap/common.py', 'keystone/tests/unit/fakeldap.py']",3,9680ee771b3b6ed93cee712aad8a0b9e19592d56,, self.connected = True self.who = who self.cred = cred self.connected = False self.who = None self.cred = None if serverctrls and len(serverctrls) > 1: self._uri = uri, if len(serverctrls) > 1:,138,10
openstack%2Fcyborg~887553,openstack/cyborg,master,I3567c7d74db8292c5728af7864cee5b8c23a6f6b,Follow pep8,NEW,2023-07-04 13:03:27.000000000,2023-07-13 11:41:07.000000000,,"[{'_account_id': 22348}, {'_account_id': 26458}, {'_account_id': 31412}]","[{'number': 1, 'created': '2023-07-04 13:03:27.000000000', 'files': ['cyborg/objects/extarq/ext_arq_job.py'], 'web_link': 'https://opendev.org/openstack/cyborg/commit/4b54eb5036abc01fb0fed77df2ee3785aab7753a', 'message': 'Follow pep8\n\nChange-Id: I3567c7d74db8292c5728af7864cee5b8c23a6f6b\n'}]",3,887553,4b54eb5036abc01fb0fed77df2ee3785aab7753a,5,3,1,35067,,,0,"Follow pep8

Change-Id: I3567c7d74db8292c5728af7864cee5b8c23a6f6b
",git fetch https://review.opendev.org/openstack/cyborg refs/changes/53/887553/1 && git format-patch -1 --stdout FETCH_HEAD,['cyborg/objects/extarq/ext_arq_job.py'],1,4b54eb5036abc01fb0fed77df2ee3785aab7753a,, elif state in constants.ARQ_OUFOF_BIND_FLOW + \ [constants.ARQ_BIND_FAILED]:, elif state in constants.ARQ_OUFOF_BIND_FLOW + [ constants.ARQ_BIND_FAILED]:,2,2
openstack%2Fopenstack-ansible~888332,openstack/openstack-ansible,stable/2023.1,I5932e8b66bb4674fb1b39442fea467c075b30989,Pin version of setuptools,MERGED,2023-07-12 20:29:35.000000000,2023-07-13 11:04:01.000000000,2023-07-13 11:01:56.000000000,"[{'_account_id': 22348}, {'_account_id': 25023}, {'_account_id': 28619}]","[{'number': 1, 'created': '2023-07-12 20:29:35.000000000', 'files': ['global-requirement-pins.txt'], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/400b89e921c65dd68a78e35f981a66ed66787348', 'message': 'Pin version of setuptools\n\nWe used to pin version of setuptools in global-requirements-pins\nuntil it got defined in upper-constraints. Since setuptools no longer\nkept in u-c since Zed, it makes sense to return pinning back.\n\nOn top of that a major setuptools version was released recently with\nbreaking changes, that affect gnocchi at least [1]\n\n[1] https://github.com/gnocchixyz/gnocchi/issues/1304\n\nChange-Id: I5932e8b66bb4674fb1b39442fea467c075b30989\n(cherry picked from commit aa558cc368bb9e34d62c4d6c736d0aca9ea874a8)\n'}]",0,888332,400b89e921c65dd68a78e35f981a66ed66787348,8,3,1,28619,,,0,"Pin version of setuptools

We used to pin version of setuptools in global-requirements-pins
until it got defined in upper-constraints. Since setuptools no longer
kept in u-c since Zed, it makes sense to return pinning back.

On top of that a major setuptools version was released recently with
breaking changes, that affect gnocchi at least [1]

[1] https://github.com/gnocchixyz/gnocchi/issues/1304

Change-Id: I5932e8b66bb4674fb1b39442fea467c075b30989
(cherry picked from commit aa558cc368bb9e34d62c4d6c736d0aca9ea874a8)
",git fetch https://review.opendev.org/openstack/openstack-ansible refs/changes/32/888332/1 && git format-patch -1 --stdout FETCH_HEAD,['global-requirement-pins.txt'],1,400b89e921c65dd68a78e35f981a66ed66787348,,setuptools==67.8.0,,1,0
openstack%2Fopenstack-ansible~887683,openstack/openstack-ansible,stable/2023.1,I1553ba549ba36ab23f999cb256e731520cbb5d09,Adjust default value for *_backend_ssl,MERGED,2023-07-06 09:58:08.000000000,2023-07-13 11:03:04.000000000,2023-07-13 11:01:53.000000000,"[{'_account_id': 22348}, {'_account_id': 25023}, {'_account_id': 28619}, {'_account_id': 32666}]","[{'number': 1, 'created': '2023-07-06 09:58:08.000000000', 'files': ['inventory/group_vars/horizon_all/haproxy_service.yml', 'inventory/group_vars/blazar_all/haproxy_service.yml'], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/a4a5925e5b2b8cd173cb8636c47dfc55267fd959', 'message': 'Adjust default value for *_backend_ssl\n\nI forgot to set a proper(openstack_service_backend_ssl) default value\nfor *_backend_ssl variables in a few places.\nThis patch fixes my mistake.\n\nChange-Id: I1553ba549ba36ab23f999cb256e731520cbb5d09\n'}]",1,887683,a4a5925e5b2b8cd173cb8636c47dfc55267fd959,10,4,1,32666,,,0,"Adjust default value for *_backend_ssl

I forgot to set a proper(openstack_service_backend_ssl) default value
for *_backend_ssl variables in a few places.
This patch fixes my mistake.

Change-Id: I1553ba549ba36ab23f999cb256e731520cbb5d09
",git fetch https://review.opendev.org/openstack/openstack-ansible refs/changes/83/887683/1 && git format-patch -1 --stdout FETCH_HEAD,"['inventory/group_vars/horizon_all/haproxy_service.yml', 'inventory/group_vars/blazar_all/haproxy_service.yml']",2,a4a5925e5b2b8cd173cb8636c47dfc55267fd959,tls-backend-stable/2023.1," haproxy_backend_ssl: ""{{ blazar_backend_ssl | default(openstack_service_backend_ssl) }}"""," haproxy_backend_ssl: ""{{ blazar_backend_ssl | default(False) }}""",2,2
openstack%2Ftripleo-upgrade~886280,openstack/tripleo-upgrade,stable/wallaby,I39683f157dd2e36667edb2567364a11df069aa9c,[update] Do not fail on faulty services start in certain edge cases.,MERGED,2023-06-16 15:11:21.000000000,2023-07-13 10:44:52.000000000,2023-06-20 23:48:26.000000000,"[{'_account_id': 6816}, {'_account_id': 8297}, {'_account_id': 11090}, {'_account_id': 22348}, {'_account_id': 29307}, {'_account_id': 32432}, {'_account_id': 33080}]","[{'number': 1, 'created': '2023-06-16 15:11:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-upgrade/commit/cd0c5c3a8133e44c7bbbd69c280974b4b7ef80a0', 'message': '[update] Do not fail on faulty services start in certain edge cases.\n\nCurrently we have random issues when starting services from images in\ncomposable setup in CI.\n\nUntil and if we sort this out entirely, do no fail on those edge\ncases.\n\nChange-Id: I39683f157dd2e36667edb2567364a11df069aa9c\n'}, {'number': 2, 'created': '2023-06-19 12:28:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-upgrade/commit/232dd08a2741ab0ad7201e1a491460d32de0e6a9', 'message': '[update] Do not fail on faulty services start in certain edge cases.\n\nCurrently we have random issues when starting services from images in\ncomposable setup in CI.\n\nUntil and if we sort this out entirely, do no fail on those edge\ncases.\n\nChange-Id: I39683f157dd2e36667edb2567364a11df069aa9c\n'}, {'number': 3, 'created': '2023-06-19 12:29:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-upgrade/commit/1cdf1f2bb6cc5102c330922d39e641e1ada76785', 'message': '[update] Do not fail on faulty services start in certain edge cases.\n\nCurrently we have random issues when starting services from images in\ncomposable setup in CI.\n\nUntil and if we sort this out entirely, do no fail on those edge\ncases.\n\nChange-Id: I39683f157dd2e36667edb2567364a11df069aa9c\n'}, {'number': 4, 'created': '2023-06-19 17:31:01.000000000', 'files': ['templates/collect_logs.yaml.j2'], 'web_link': 'https://opendev.org/openstack/tripleo-upgrade/commit/372c12b0bd6916e8190abba4d58c3b37d2238683', 'message': '[update] Do not fail on faulty services start in certain edge cases.\n\nCurrently we have random issues when starting services from images in\ncomposable setup in CI.\n\nUntil and if we sort this out entirely, do no fail on those edge\ncases.\n\nChange-Id: I39683f157dd2e36667edb2567364a11df069aa9c\n'}]",9,886280,372c12b0bd6916e8190abba4d58c3b37d2238683,23,7,4,8297,,,0,"[update] Do not fail on faulty services start in certain edge cases.

Currently we have random issues when starting services from images in
composable setup in CI.

Until and if we sort this out entirely, do no fail on those edge
cases.

Change-Id: I39683f157dd2e36667edb2567364a11df069aa9c
",git fetch https://review.opendev.org/openstack/tripleo-upgrade refs/changes/80/886280/1 && git format-patch -1 --stdout FETCH_HEAD,['templates/collect_logs.yaml.j2'],1,cd0c5c3a8133e44c7bbbd69c280974b4b7ef80a0,, register: systemctl_cmd failed_when: - systemctl_cmd.rc != 0 - systemctl_cmd.rc != 2 register: systemctl_cmd failed_when: - systemctl_cmd.rc != 0 - systemctl_cmd.rc != 2,,8,0
openstack%2Fopenstack-ansible-galera_server~887139,openstack/openstack-ansible-galera_server,stable/2023.1,I28c6a0e0b41d4d29c3e79e601de45ea373dee4fb,Add optional compression to mariabackup,MERGED,2023-06-28 07:44:29.000000000,2023-07-13 10:44:40.000000000,2023-07-13 10:43:43.000000000,"[{'_account_id': 22348}, {'_account_id': 25023}, {'_account_id': 28619}, {'_account_id': 34150}]","[{'number': 1, 'created': '2023-06-28 07:44:29.000000000', 'files': ['tasks/galera_server_backups.yml', 'defaults/main.yml', 'releasenotes/notes/mariabackup-compression-337b04c68f370c1d.yaml', 'templates/mariabackup_script.py.j2'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-galera_server/commit/41801ab04d3c64d61b881d410691e05e0312114d', 'message': 'Add optional compression to mariabackup\n\nAs database backups can grow substantially in size, compressing backups\nhelps to preserve disk space.\nWhile the mariabackup utility offers no compression by itself, we can\nstream the backup into a compression tool to create an archive [1].\nThe xtrabackup_checkpoints file, which contains metadata on a backup,\ngets stored alongside the archive, allowing to create incremental\nbackups from non-compressed backups and vice-versa [2].\nOne thing to note, is that compressed backups cannot be prepared in\nadvance, this step must be manually carried out by the user.\nBackup compression is disabled by default and different compressors\ncan be chosen (zstd, xz, ...), with gzip being the default.\n\n[1] https://mariadb.com/kb/en/using-encryption-and-compression-tools-with-mariabackup/\n[2] https://mariadb.com/kb/en/incremental-backup-and-restore-with-mariabackup/#combining-with-stream-output\n\nChange-Id: I28c6a0e0b41d4d29c3e79e601de45ea373dee4fb\nSigned-off-by: Simon Hensel <simon.hensel@inovex.de>\n(cherry picked from commit 60009ed7cebe9c082592fd564b1577068ef94b6c)\n'}]",4,887139,41801ab04d3c64d61b881d410691e05e0312114d,12,4,1,32755,,,0,"Add optional compression to mariabackup

As database backups can grow substantially in size, compressing backups
helps to preserve disk space.
While the mariabackup utility offers no compression by itself, we can
stream the backup into a compression tool to create an archive [1].
The xtrabackup_checkpoints file, which contains metadata on a backup,
gets stored alongside the archive, allowing to create incremental
backups from non-compressed backups and vice-versa [2].
One thing to note, is that compressed backups cannot be prepared in
advance, this step must be manually carried out by the user.
Backup compression is disabled by default and different compressors
can be chosen (zstd, xz, ...), with gzip being the default.

[1] https://mariadb.com/kb/en/using-encryption-and-compression-tools-with-mariabackup/
[2] https://mariadb.com/kb/en/incremental-backup-and-restore-with-mariabackup/#combining-with-stream-output

Change-Id: I28c6a0e0b41d4d29c3e79e601de45ea373dee4fb
Signed-off-by: Simon Hensel <simon.hensel@inovex.de>
(cherry picked from commit 60009ed7cebe9c082592fd564b1577068ef94b6c)
",git fetch https://review.opendev.org/openstack/openstack-ansible-galera_server refs/changes/39/887139/1 && git format-patch -1 --stdout FETCH_HEAD,"['tasks/galera_server_backups.yml', 'defaults/main.yml', 'releasenotes/notes/mariabackup-compression-337b04c68f370c1d.yaml', 'templates/mariabackup_script.py.j2']",4,41801ab04d3c64d61b881d410691e05e0312114d,,"from subprocess import Popen, PIPE, check_output, run ""--compress"", dest=""compress_flag"", default=False, type=eval, choices=[True, False], help=""Flag to compress created backups"", ) parser.add_argument( ""--compressor"", dest=""compressor"", default=""gzip"", type=str, help=""The compressor to use when compressing backups (default: gzip)"", ) parser.add_argument(def create_full_backup(dest, curtime, full_backup_filename, extra_mariabackup_args, compress, compressor): if compress: #Creating compressed full backup os.makedirs(dest+""/""+full_backup_filename+curtime, exist_ok=True) mariabackup_run = Popen( [""/usr/bin/mariabackup""] + extra_mariabackup_args + [""--backup"", ""--stream=xbstream"", ""--extra-lsndir=""+os.path.normpath(dest+""/""+full_backup_filename+curtime)], stdout=PIPE, stderr=err ) compressed_backup = open(os.path.normpath(dest+""/""+full_backup_filename+curtime+""/""+full_backup_filename+curtime), ""wb"") run([compressor], stdin=mariabackup_run.stdout, stdout=compressed_backup) mariabackup_run.wait() mariabackup_res = mariabackup_run.communicate() if mariabackup_run.returncode: print(mariabackup_res[1]) compressed_backup.close() else: #Creating full backup mariabackup_run = Popen( [""/usr/bin/mariabackup""] + extra_mariabackup_args + [""--backup"", ""--target-dir=""+os.path.normpath(dest+""/""+full_backup_filename+curtime)], stdout=None, stderr=err ) mariabackup_run.wait() mariabackup_res = mariabackup_run.communicate() if mariabackup_run.returncode: print(mariabackup_res[1]) #Preparing full backup err_p = open(os.path.normpath(dest+""/prepare.log""), ""w"") mariabackup_prep = Popen( [""/usr/bin/mariabackup""] + extra_mariabackup_args + [""--prepare"", ""--target-dir=""+os.path.normpath(dest+""/""+full_backup_filename+curtime)], stdout=None, stderr=err_p ) mariabackup_prep.wait() mariabackup_prep_res = mariabackup_prep.communicate() if mariabackup_prep.returncode: print(mariabackup_prep_res[1]) err_p.close()def create_increment_backup(dest, curtime, increment_backup_filename, extra_mariabackup_args, compress, compressor): if compress: #Creating compressed incremental backup os.makedirs(dest+""/""+increment_backup_filename+curtime, exist_ok=True) mariabackup_run = Popen( [""/usr/bin/mariabackup""] + extra_mariabackup_args + [""--backup"", ""--stream=xbstream"", ""--incremental-basedir=""+basedir, ""--extra-lsndir=""+os.path.normpath(dest+""/""+increment_backup_filename+curtime)], stdout=PIPE, stderr=err ) compressed_backup = open(os.path.normpath(dest+""/""+increment_backup_filename+curtime+""/""+increment_backup_filename+curtime), ""wb"") run([compressor], stdin=mariabackup_run.stdout, stdout=compressed_backup) mariabackup_run.wait() mariabackup_res = mariabackup_run.communicate() if mariabackup_run.returncode: print(mariabackup_res[1]) compressed_backup.close() else: #Creating incremental backup mariabackup_run = Popen( [""/usr/bin/mariabackup""] + extra_mariabackup_args + [""--backup"", ""--target-dir=""+os.path.normpath(dest+""/""+increment_backup_filename+curtime), ""--incremental-basedir=""+basedir], stdout=None, stderr=err ) mariabackup_run.wait() mariabackup_res = mariabackup_run.communicate() if mariabackup_run.returncode: print(mariabackup_res[1]) create_full_backup(opts.destdir, curtime, full_backup_filename, extra_mariabackup_args, opts.compress_flag, opts.compressor) create_increment_backup(opts.destdir, curtime, increment_backup_filename, extra_mariabackup_args, opts.compress_flag, opts.compressor)","from subprocess import Popen, PIPEimport socketdef create_full_backup(dest, curtime, full_backup_filename, extra_mariabackup_args): #Creating full backup mariabackup_run = Popen( [""/usr/bin/mariabackup""] + extra_mariabackup_args + [""--backup"", ""--target-dir=""+os.path.normpath(dest+""/""+full_backup_filename+curtime)], stdout=None, stderr=err ) mariabackup_run.wait() mariabackup_res = mariabackup_run.communicate() if mariabackup_run.returncode: print(mariabackup_res[1]) #Preparing full backup err_p = open(os.path.normpath(dest+""/prepare.log""), ""w"") mariabackup_prep = Popen( [""/usr/bin/mariabackup""] + extra_mariabackup_args + [""--prepare"", ""--target-dir=""+os.path.normpath(dest+""/""+full_backup_filename+curtime)], stdout=None, stderr=err_p ) mariabackup_prep.wait() mariabackup_prep_res = mariabackup_prep.communicate() if mariabackup_prep.returncode: print(mariabackup_prep_res[1]) err_p.close()def create_increment_backup(dest, curtime, increment_backup_filename, extra_mariabackup_args): #Creating incremental backup mariabackup_run = Popen( [""/usr/bin/mariabackup""] + extra_mariabackup_args + [""--backup"", ""--target-dir=""+os.path.normpath(dest+""/""+increment_backup_filename+curtime), ""--incremental-basedir=""+basedir], stdout=None, stderr=err ) mariabackup_run.wait() mariabackup_res = mariabackup_run.communicate() if mariabackup_run.returncode: print(mariabackup_res[1]) create_full_backup(opts.destdir, curtime, full_backup_filename, extra_mariabackup_args) create_increment_backup(opts.destdir, curtime, increment_backup_filename, extra_mariabackup_args)",106,32
openstack%2Fopenstack-ansible-os_nova~887878,openstack/openstack-ansible-os_nova,stable/2023.1,I56aee80180804b8a3e3316cffc6fa8115513b8f1,Apply always tag to nova_virt_detect.yml,MERGED,2023-07-07 10:13:54.000000000,2023-07-13 10:31:59.000000000,2023-07-13 10:31:07.000000000,"[{'_account_id': 22348}, {'_account_id': 25023}, {'_account_id': 32666}]","[{'number': 1, 'created': '2023-07-07 10:13:54.000000000', 'files': ['tasks/main.yml'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_nova/commit/b8863c62b7b6b08ce4a56b8d2de62a92c8e4c0fb', 'message': ""Apply always tag to nova_virt_detect.yml\n\nRunning nova playbook with tag limit may lead to an error:\n\nThe conditional check 'nova_virt_type != 'ironic'' failed. The error\nwas: error while evaluating conditional (nova_virt_type != 'ironic'):\n'nova_virt_type' is undefined\\n\\nThe error appears to be in\n'/etc/ansible/roles/os_nova/tasks/main.yml': line 289, column 3, but\nmay be elsewhere in the file depending on the exact syntax problem.\n\nIt can be easily fixed by applying always tag to tasks from\nnova_virt_detect.yml\n\nChange-Id: I56aee80180804b8a3e3316cffc6fa8115513b8f1\n(cherry picked from commit c90a5c2b927b955aaa82d78e65548423b24f2ecc)\n""}]",0,887878,b8863c62b7b6b08ce4a56b8d2de62a92c8e4c0fb,8,3,1,28619,,,0,"Apply always tag to nova_virt_detect.yml

Running nova playbook with tag limit may lead to an error:

The conditional check 'nova_virt_type != 'ironic'' failed. The error
was: error while evaluating conditional (nova_virt_type != 'ironic'):
'nova_virt_type' is undefined\n\nThe error appears to be in
'/etc/ansible/roles/os_nova/tasks/main.yml': line 289, column 3, but
may be elsewhere in the file depending on the exact syntax problem.

It can be easily fixed by applying always tag to tasks from
nova_virt_detect.yml

Change-Id: I56aee80180804b8a3e3316cffc6fa8115513b8f1
(cherry picked from commit c90a5c2b927b955aaa82d78e65548423b24f2ecc)
",git fetch https://review.opendev.org/openstack/openstack-ansible-os_nova refs/changes/78/887878/1 && git format-patch -1 --stdout FETCH_HEAD,['tasks/main.yml'],1,b8863c62b7b6b08ce4a56b8d2de62a92c8e4c0fb,tls-backend-stable/2023.1, args: apply: tags: - always,,4,0
openstack%2Fopenstack-ansible-os_keystone~888158,openstack/openstack-ansible-os_keystone,stable/2023.1,I81b66a7388c335958badf7135f4289c3423cb229,Fix SSL logic in keystone-httpd.conf.j2,MERGED,2023-07-11 18:23:45.000000000,2023-07-13 10:29:10.000000000,2023-07-13 10:28:08.000000000,"[{'_account_id': 22348}, {'_account_id': 25023}, {'_account_id': 28619}]","[{'number': 1, 'created': '2023-07-11 18:23:45.000000000', 'files': ['templates/keystone-httpd.conf.j2'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_keystone/commit/94a202e230f93791409260dbca6bd511b519581a', 'message': 'Fix SSL logic in keystone-httpd.conf.j2\n\nDefining SSL parameters has nothing to do with\nkeystone_service_internaluri_proto. It should not be taken into\nconsideration there.\nTheoretically speaking, environment can have TLS disabled on frontend\nbut enabled on backend.\n\nChange-Id: I81b66a7388c335958badf7135f4289c3423cb229\n(cherry picked from commit b73bcd9981255dfa6eb39fb8ef25a5f852b00b17)\n'}]",0,888158,94a202e230f93791409260dbca6bd511b519581a,8,3,1,32666,,,0,"Fix SSL logic in keystone-httpd.conf.j2

Defining SSL parameters has nothing to do with
keystone_service_internaluri_proto. It should not be taken into
consideration there.
Theoretically speaking, environment can have TLS disabled on frontend
but enabled on backend.

Change-Id: I81b66a7388c335958badf7135f4289c3423cb229
(cherry picked from commit b73bcd9981255dfa6eb39fb8ef25a5f852b00b17)
",git fetch https://review.opendev.org/openstack/openstack-ansible-os_keystone refs/changes/58/888158/1 && git format-patch -1 --stdout FETCH_HEAD,['templates/keystone-httpd.conf.j2'],1,94a202e230f93791409260dbca6bd511b519581a,tls-backend-stable/2023.1, {% if keystone_backend_ssl | bool -%}," {% if keystone_backend_ssl | bool and keystone_service_internaluri_proto == ""https"" -%}",1,1
openstack%2Ftacker~879235,openstack/tacker,master,Idb6afbf44cb9b6326d024f7c6d41814274ec8ea9,Fix missing import for i18n,MERGED,2023-04-03 01:12:50.000000000,2023-07-13 10:29:07.000000000,2023-07-13 10:28:00.000000000,"[{'_account_id': 17255}, {'_account_id': 22348}, {'_account_id': 25701}, {'_account_id': 31857}, {'_account_id': 32102}, {'_account_id': 33455}]","[{'number': 1, 'created': '2023-04-03 01:12:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tacker/commit/0608a8354809268b795201abc56d4ccc05082cb6', 'message': '[WIP]Import i18n Library to Fix Bug that __ is not defined\n\nThis patch fix bug that __ is not defined.\nThis bug coused by i18n library is not imported.\n\nChange-Id: Idb6afbf44cb9b6326d024f7c6d41814274ec8ea9\n'}, {'number': 2, 'created': '2023-04-03 01:15:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tacker/commit/70e5263aebd097787bcbef3e832dadfa1fd8ba41', 'message': '[WIP]Import i18n Library to Fix Bug that __ is not defined\n\nThis patch fix bug that __ is not defined.\nThis bug coused by i18n library is not imported.\n\nCloses-Bug: #2013427\nChange-Id: Idb6afbf44cb9b6326d024f7c6d41814274ec8ea9\n'}, {'number': 3, 'created': '2023-04-03 01:16:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tacker/commit/9a54ea8ef5741748b2cb70e155d597c8377c439e', 'message': 'Import i18n Library to Fix Bug that __ is not defined\n\nThis patch fix bug that __ is not defined.\nThis bug coused by i18n library is not imported.\n\nCloses-Bug: #2013427\nChange-Id: Idb6afbf44cb9b6326d024f7c6d41814274ec8ea9\n'}, {'number': 4, 'created': '2023-04-24 05:34:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tacker/commit/5b5cd158451ee773460c1c239640ea96ba1ebf8b', 'message': 'Fix missing import for i18n\n\nThis patch fixes bug that _ is not defined.\nIn general, Tacker uses _ as an alias for i18n.\nTherefore, this bug caused by i18n library is not imported.\n\nCloses-Bug: #2013427\nChange-Id: Idb6afbf44cb9b6326d024f7c6d41814274ec8ea9\n'}, {'number': 5, 'created': '2023-04-25 06:43:56.000000000', 'files': ['tacker/db/db_sqlalchemy/api.py', 'tacker/plugins/fenix.py', 'tacker/tests/unit/vnfm/infra_drivers/kubernetes/fakes.py', 'tacker/tests/unit/vnfm/infra_drivers/kubernetes/test_kubernetes_driver.py', 'tacker/tests/unit/vnfm/mgmt_drivers/fakes.py', 'tacker/tests/unit/sol_refactored/infra_drivers/kubernetes/fakes.py', 'tacker/tests/unit/vnflcm/test_controller.py', 'tacker/conf/vnf_package.py', 'tacker/conf/conductor.py', 'tacker/api/validation/validators.py', 'tacker/conf/policy.py', 'tacker/objects/vnf_package_vnfd.py', 'tacker/objects/vnf_deployment_flavour.py', 'tacker/api/common/_filters.py', 'tacker/api/v1/resource.py', 'tacker/tests/unit/vnflcm/test_vnflcm_driver.py', 'tacker/tests/unit/vnfm/infra_drivers/kubernetes/test_kubernetes_driver_helm.py', 'tacker/objects/vnf_software_image.py', 'tacker/tests/unit/vnfpkgm/test_controller.py', 'tacker/vnfm/lcm_user_data/abstract_user_data.py', 'tacker/api/validation/__init__.py', 'tacker/conductor/conductor_server.py', 'tacker/vnflcm/vnflcm_driver.py', 'tacker/tests/etc/samples/etsi/nfv/user_data_sample_userdata_invalid_script/UserData/lcm_user_data_invalid_script.py'], 'web_link': 'https://opendev.org/openstack/tacker/commit/83e61aeef2339db36b2362431620a59bb9c2eeda', 'message': 'Fix missing import for i18n\n\nThis patch fixes bug that _ is not defined.\nIn general, Tacker uses _ as an alias for i18n.\nTherefore, this bug caused by i18n library is not imported.\n\nCloses-Bug: #2013427\nChange-Id: Idb6afbf44cb9b6326d024f7c6d41814274ec8ea9\n'}]",22,879235,83e61aeef2339db36b2362431620a59bb9c2eeda,22,6,5,32707,,,0,"Fix missing import for i18n

This patch fixes bug that _ is not defined.
In general, Tacker uses _ as an alias for i18n.
Therefore, this bug caused by i18n library is not imported.

Closes-Bug: #2013427
Change-Id: Idb6afbf44cb9b6326d024f7c6d41814274ec8ea9
",git fetch https://review.opendev.org/openstack/tacker refs/changes/35/879235/1 && git format-patch -1 --stdout FETCH_HEAD,"['tacker/db/db_sqlalchemy/api.py', 'tacker/plugins/fenix.py', 'tacker/tests/unit/vnfm/infra_drivers/kubernetes/fakes.py', 'tacker/tests/unit/vnfm/infra_drivers/kubernetes/test_kubernetes_driver.py', 'tacker/tests/unit/vnfm/mgmt_drivers/fakes.py', 'tacker/tests/unit/sol_refactored/infra_drivers/kubernetes/fakes.py', 'tacker/tests/unit/vnflcm/test_controller.py', 'tacker/conf/vnf_package.py', 'tacker/conf/conductor.py', 'tacker/api/validation/validators.py', 'tacker/conf/policy.py', 'tacker/objects/vnf_package_vnfd.py', 'tacker/objects/vnf_deployment_flavour.py', 'tacker/api/common/_filters.py', 'tacker/api/v1/resource.py', 'tacker/tests/unit/vnflcm/test_vnflcm_driver.py', 'tacker/tests/unit/vnfm/infra_drivers/kubernetes/test_kubernetes_driver_helm.py', 'tacker/objects/vnf_software_image.py', 'tacker/tests/unit/vnfpkgm/test_controller.py', 'tacker/vnfm/lcm_user_data/abstract_user_data.py', 'tacker/api/validation/__init__.py', 'tacker/conductor/conductor_server.py', 'tacker/vnflcm/vnflcm_driver.py', 'tacker/tests/etc/samples/etsi/nfv/user_data_sample_userdata_invalid_script/UserData/lcm_user_data_invalid_script.py']",24,0608a8354809268b795201abc56d4ccc05082cb6,bug/2013427,from tacker._i18n import _,,27,2
openstack%2Fopenstack-ansible-os_rally~887679,openstack/openstack-ansible-os_rally,stable/2023.1,I016e457c0e4b7819d6d65af3bc35e06061f92d1c,Include proper commit in rally_upper_constraints_url,MERGED,2023-07-06 09:35:38.000000000,2023-07-13 10:28:48.000000000,2023-07-13 10:27:51.000000000,"[{'_account_id': 22348}, {'_account_id': 25023}, {'_account_id': 28619}]","[{'number': 1, 'created': '2023-07-06 09:35:38.000000000', 'files': ['defaults/main.yml'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_rally/commit/7c57ab2aa6680109b52b454f12c3f4f8186d09b8', 'message': 'Include proper commit in rally_upper_constraints_url\n\nCurrently, rally_upper_constraints_url always points to master branch.\nIt is not a valid behavior because u-c from master may not work for\nstable branches.\nThis change fixes rally_upper_constraints_url.\n\nDepends-On: https://review.opendev.org/c/openstack/openstack-ansible-rabbitmq_server/+/887592\n\nChange-Id: I016e457c0e4b7819d6d65af3bc35e06061f92d1c\n(cherry picked from commit c65b91b4900292fb5c4a07dd4473fcf4554b111e)\n'}]",0,887679,7c57ab2aa6680109b52b454f12c3f4f8186d09b8,8,3,1,32666,,,0,"Include proper commit in rally_upper_constraints_url

Currently, rally_upper_constraints_url always points to master branch.
It is not a valid behavior because u-c from master may not work for
stable branches.
This change fixes rally_upper_constraints_url.

Depends-On: https://review.opendev.org/c/openstack/openstack-ansible-rabbitmq_server/+/887592

Change-Id: I016e457c0e4b7819d6d65af3bc35e06061f92d1c
(cherry picked from commit c65b91b4900292fb5c4a07dd4473fcf4554b111e)
",git fetch https://review.opendev.org/openstack/openstack-ansible-os_rally refs/changes/79/887679/1 && git format-patch -1 --stdout FETCH_HEAD,['defaults/main.yml'],1,7c57ab2aa6680109b52b454f12c3f4f8186d09b8,,"rally_upper_constraints_url: ""{{ rally_openstack_git_repo }}/raw/{{ rally_openstack_git_install_branch }}/upper-constraints.txt""","rally_upper_constraints_url: ""{{ rally_openstack_git_repo }}/raw/branch/master/upper-constraints.txt""",1,1
openstack%2Fopenstack-ansible-plugins~888152,openstack/openstack-ansible-plugins,stable/2023.1,I11b1046ea91cef7de0b2f6433baabbb144e07700,Skip updating service password by default,MERGED,2023-07-11 12:07:34.000000000,2023-07-13 10:28:06.000000000,2023-07-13 10:27:15.000000000,"[{'_account_id': 22348}, {'_account_id': 25023}, {'_account_id': 28619}]","[{'number': 1, 'created': '2023-07-11 12:07:34.000000000', 'files': ['releasenotes/notes/service_password_update-3bdd2bb5ed3a99b5.yaml', 'roles/service_setup/tasks/main.yml'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-plugins/commit/88a8bfcd62fe7bb027ca7a8636fbe943bfda88c1', 'message': 'Skip updating service password by default\n\nAt the moment we always do attempt to reset passwords for the\nkeystone services, which in some cases leads to race conditions in\nservices. Thus, running a role is not idempotent which we fix by\nintroducing a `service_update_password` variable. So whenever password\nneeds to be reseted/updated, the variable should be supplied for that.\n\nChange-Id: I11b1046ea91cef7de0b2f6433baabbb144e07700\nCloses-Bug: #2023370\n(cherry picked from commit f35126af68e17d76be00f1cb70cd42fab15f2f4e)\n'}]",0,888152,88a8bfcd62fe7bb027ca7a8636fbe943bfda88c1,8,3,1,28619,,,0,"Skip updating service password by default

At the moment we always do attempt to reset passwords for the
keystone services, which in some cases leads to race conditions in
services. Thus, running a role is not idempotent which we fix by
introducing a `service_update_password` variable. So whenever password
needs to be reseted/updated, the variable should be supplied for that.

Change-Id: I11b1046ea91cef7de0b2f6433baabbb144e07700
Closes-Bug: #2023370
(cherry picked from commit f35126af68e17d76be00f1cb70cd42fab15f2f4e)
",git fetch https://review.opendev.org/openstack/openstack-ansible-plugins refs/changes/52/888152/1 && git format-patch -1 --stdout FETCH_HEAD,"['releasenotes/notes/service_password_update-3bdd2bb5ed3a99b5.yaml', 'roles/service_setup/tasks/main.yml']",2,88a8bfcd62fe7bb027ca7a8636fbe943bfda88c1,," update_password: ""{{ (service_update_password | default(False) | bool) | ternary('always', omit) }}""", update_password: always,15,1
openstack%2Ftempest~888334,openstack/tempest,master,I5fdae16ecb8969c9f7500e68b496a8908f5963a6,"Revert ""Revert ""Mark ""test_live_migration_with_trunk"" as unstable""""",MERGED,2023-07-13 01:54:53.000000000,2023-07-13 10:04:45.000000000,2023-07-13 10:03:44.000000000,"[{'_account_id': 7166}, {'_account_id': 8313}, {'_account_id': 8556}, {'_account_id': 9708}, {'_account_id': 16688}, {'_account_id': 22348}, {'_account_id': 22873}, {'_account_id': 31291}]","[{'number': 1, 'created': '2023-07-13 01:54:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/0bae6ac024414fa9f38c2f7a04138565b2c4662a', 'message': 'Revert ""Revert ""Mark ""test_live_migration_with_trunk"" as unstable""""\n\nThis reverts commit dd49b3ee3e4215d598a4a6ffc5b09dcee329bbd9.\n\nReason for revert:\n\nDue to new bug: https://bugs.launchpad.net/neutron/+bug/2027605\n\nIt is failing 48 times after it was unskipped\n\nhttps://opensearch.logs.openstack.org/_dashboards/app/discover?security_tenant=global#/?_g=(filters:!(),refreshInterval:(pause:!t,value:0),time:(from:\'2023-06-10T17:30:00.000Z\',to:now))&_a=(columns:!(build_branch,build_change,build_name,project,build_status,build_queue),filters:!((\'$state\':(store:appState),meta:(alias:!n,disabled:!f,index:\'94869730-aea8-11ec-9e6a-83741af3fdcd\',key:build_status,negate:!f,params:(query:FAILURE),type:phrase),query:(match_phrase:(build_status:FAILURE)))),index:\'94869730-aea8-11ec-9e6a-83741af3fdcd\',interval:d,query:(language:lucene,query:\'message:%22test_live_migration.py,%20line%20292,%20in%20test_live_migration_with_trunk%22%20\'),sort:!())\n\nChange-Id: I5fdae16ecb8969c9f7500e68b496a8908f5963a6\n'}, {'number': 2, 'created': '2023-07-13 01:55:57.000000000', 'files': ['tempest/api/compute/admin/test_live_migration.py'], 'web_link': 'https://opendev.org/openstack/tempest/commit/14399c08a3fa37d510434d1774826b88af16ceb0', 'message': 'Revert ""Revert ""Mark ""test_live_migration_with_trunk"" as unstable""""\n\nThis reverts commit dd49b3ee3e4215d598a4a6ffc5b09dcee329bbd9.\n\nReason for revert:\n\nDue to new bug: https://bugs.launchpad.net/neutron/+bug/2027605\n\nIt is failing 48 times after it was unskipped\n\nhttps://opensearch.logs.openstack.org/_dashboards/app/discover?security_tenant=global#/?_g=(filters:!(),refreshInterval:(pause:!t,value:0),time:(from:\'2023-06-10T17:30:00.000Z\',to:now))&_a=(columns:!(build_branch,build_change,build_name,project,build_status,build_queue),filters:!((\'$state\':(store:appState),meta:(alias:!n,disabled:!f,index:\'94869730-aea8-11ec-9e6a-83741af3fdcd\',key:build_status,negate:!f,params:(query:FAILURE),type:phrase),query:(match_phrase:(build_status:FAILURE)))),index:\'94869730-aea8-11ec-9e6a-83741af3fdcd\',interval:d,query:(language:lucene,query:\'message:%22test_live_migration.py,%20line%20292,%20in%20test_live_migration_with_trunk%22%20\'),sort:!())\n\nChange-Id: I5fdae16ecb8969c9f7500e68b496a8908f5963a6\n'}]",1,888334,14399c08a3fa37d510434d1774826b88af16ceb0,11,8,2,8556,,,0,"Revert ""Revert ""Mark ""test_live_migration_with_trunk"" as unstable""""

This reverts commit dd49b3ee3e4215d598a4a6ffc5b09dcee329bbd9.

Reason for revert:

Due to new bug: https://bugs.launchpad.net/neutron/+bug/2027605

It is failing 48 times after it was unskipped

https://opensearch.logs.openstack.org/_dashboards/app/discover?security_tenant=global#/?_g=(filters:!(),refreshInterval:(pause:!t,value:0),time:(from:'2023-06-10T17:30:00.000Z',to:now))&_a=(columns:!(build_branch,build_change,build_name,project,build_status,build_queue),filters:!(('$state':(store:appState),meta:(alias:!n,disabled:!f,index:'94869730-aea8-11ec-9e6a-83741af3fdcd',key:build_status,negate:!f,params:(query:FAILURE),type:phrase),query:(match_phrase:(build_status:FAILURE)))),index:'94869730-aea8-11ec-9e6a-83741af3fdcd',interval:d,query:(language:lucene,query:'message:%22test_live_migration.py,%20line%20292,%20in%20test_live_migration_with_trunk%22%20'),sort:!())

Change-Id: I5fdae16ecb8969c9f7500e68b496a8908f5963a6
",git fetch https://review.opendev.org/openstack/tempest refs/changes/34/888334/1 && git format-patch -1 --stdout FETCH_HEAD,['tempest/api/compute/admin/test_live_migration.py'],1,0bae6ac024414fa9f38c2f7a04138565b2c4662a,bug/2024160, @decorators.unstable_test(bug='2024160'),,1,0
openstack%2Fkeystone~874847,openstack/keystone,stable/victoria,I59ebf0fa77391d49b2349e918fc55f96318c42a6,[PooledLDAPHandler] Ensure result3() invokes message.clean(),MERGED,2023-02-24 07:12:14.000000000,2023-07-13 09:40:49.000000000,2023-07-13 09:39:05.000000000,"[{'_account_id': 7414}, {'_account_id': 14250}, {'_account_id': 22348}]","[{'number': 1, 'created': '2023-02-24 07:12:14.000000000', 'files': ['keystone/tests/unit/test_backend_ldap_pool.py', 'keystone/identity/backends/ldap/common.py', 'keystone/tests/unit/fakeldap.py'], 'web_link': 'https://opendev.org/openstack/keystone/commit/e865f9bc179d0b007eda6c14f1206d4f00f59748', 'message': '[PooledLDAPHandler] Ensure result3() invokes message.clean()\n\nresult3 does not invoke message.clean() when an exception is thrown\nby `message.connection.result3()` call, causing pool connection\nassociated with the message to be marked active forever. This causes\na denial-of-service on ldappool.\n\nThe fix ensures message.clean() is invoked by wrapping the offending\ncall in try-except-finally and putting the message.clean() in finally\nblock.\n\nCloses-Bug: #1998789\n\nChange-Id: I59ebf0fa77391d49b2349e918fc55f96318c42a6\nSigned-off-by: Mustafa Kemal Gilor <mustafa.gilor@canonical.com>\n(cherry picked from commit ff632a81fb09e6d9f3298e494d53eb6df50269cf)\n'}]",0,874847,e865f9bc179d0b007eda6c14f1206d4f00f59748,9,3,1,34980,,,0,"[PooledLDAPHandler] Ensure result3() invokes message.clean()

result3 does not invoke message.clean() when an exception is thrown
by `message.connection.result3()` call, causing pool connection
associated with the message to be marked active forever. This causes
a denial-of-service on ldappool.

The fix ensures message.clean() is invoked by wrapping the offending
call in try-except-finally and putting the message.clean() in finally
block.

Closes-Bug: #1998789

Change-Id: I59ebf0fa77391d49b2349e918fc55f96318c42a6
Signed-off-by: Mustafa Kemal Gilor <mustafa.gilor@canonical.com>
(cherry picked from commit ff632a81fb09e6d9f3298e494d53eb6df50269cf)
",git fetch https://review.opendev.org/openstack/keystone refs/changes/47/874847/1 && git format-patch -1 --stdout FETCH_HEAD,"['keystone/tests/unit/test_backend_ldap_pool.py', 'keystone/identity/backends/ldap/common.py', 'keystone/tests/unit/fakeldap.py']",3,e865f9bc179d0b007eda6c14f1206d4f00f59748,, self.connected = True self.who = who self.cred = cred self.connected = False self.who = None self.cred = None if serverctrls and len(serverctrls) > 1: self._uri = uri, if len(serverctrls) > 1:,138,10
openstack%2Fneutron~888363,openstack/neutron,master,Id19d5edf6c2dd8ed481076065ffe2fbcdd1d2723,[fullstack] Use metadata host IP for the haproxy listen addr,ABANDONED,2023-07-13 02:14:06.000000000,2023-07-13 09:24:51.000000000,,"[{'_account_id': 9845}, {'_account_id': 22348}]","[{'number': 1, 'created': '2023-07-13 02:14:06.000000000', 'files': ['neutron/agent/l2/extensions/metadata/host_metadata_proxy.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/bba27842b570cae61e378b3dd663c2a4dc91b886', 'message': '[fullstack] Use metadata host IP for the haproxy listen addr\n\nDue to the upstream CI fullstack host has server listen on\n0.0.0.0:80, we change the host haproxy to metadata_host_ip:80.\n\nChange-Id: Id19d5edf6c2dd8ed481076065ffe2fbcdd1d2723\n'}]",0,888363,bba27842b570cae61e378b3dd663c2a4dc91b886,5,2,1,9531,,,0,"[fullstack] Use metadata host IP for the haproxy listen addr

Due to the upstream CI fullstack host has server listen on
0.0.0.0:80, we change the host haproxy to metadata_host_ip:80.

Change-Id: Id19d5edf6c2dd8ed481076065ffe2fbcdd1d2723
",git fetch https://review.opendev.org/openstack/neutron refs/changes/63/888363/1 && git format-patch -1 --stdout FETCH_HEAD,['neutron/agent/l2/extensions/metadata/host_metadata_proxy.py'],1,bba27842b570cae61e378b3dd663c2a4dc91b886,distributed_metadata_data_path,"import netaddr bind {{ metadata_host_ip }}:80 name clear metadata_host_ip = str(netaddr.IPAddress( netaddr.IPNetwork(cfg.CONF.METADATA.provider_cidr).first + 1)) metadata_host_ip=metadata_host_ip,", bind *:80 name clear,6,1
openstack%2Fcharm-zuul-jobs~888441,openstack/charm-zuul-jobs,master,I84c608116fcdd82794d100481059418dfac02120,Allow failure when collecting pod logs,MERGED,2023-07-13 08:50:36.000000000,2023-07-13 09:15:25.000000000,2023-07-13 09:15:25.000000000,"[{'_account_id': 10366}, {'_account_id': 22348}]","[{'number': 1, 'created': '2023-07-13 08:50:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-zuul-jobs/commit/46c949f4534d682e4489abf8bff20c7dfa6fab7a', 'message': 'Allow failure when collecting pod logs\n\nIf collect-run-data runs before a pod is initialized, the `kubectl logs`\ncommand will fail with `pod is waiting to start: PodInitializing`.\n\nChange-Id: I84c608116fcdd82794d100481059418dfac02120\n'}, {'number': 2, 'created': '2023-07-13 08:52:03.000000000', 'files': ['roles/collect-run-data/tasks/main.yaml'], 'web_link': 'https://opendev.org/openstack/charm-zuul-jobs/commit/3a0ab0a87fe437a21367fc312d4f48c459664c86', 'message': 'Allow failure when collecting pod logs\n\nIf collect-run-data runs before a pod is initialized, the `kubectl logs`\ncommand will fail with `pod is waiting to start: PodInitializing`.\n\nChange-Id: I84c608116fcdd82794d100481059418dfac02120\n'}]",1,888441,3a0ab0a87fe437a21367fc312d4f48c459664c86,7,2,2,35761,,,0,"Allow failure when collecting pod logs

If collect-run-data runs before a pod is initialized, the `kubectl logs`
command will fail with `pod is waiting to start: PodInitializing`.

Change-Id: I84c608116fcdd82794d100481059418dfac02120
",git fetch https://review.opendev.org/openstack/charm-zuul-jobs refs/changes/41/888441/1 && git format-patch -1 --stdout FETCH_HEAD,['roles/collect-run-data/tasks/main.yaml'],1,46c949f4534d682e4489abf8bff20c7dfa6fab7a,fix/logs-collect, microk8s.kubectl logs -n $MODEL_NAME --all-containers $pod > $LOG_FOLDER/$pod.log || true, microk8s.kubectl logs -n $MODEL_NAME --all-containers $pod > $LOG_FOLDER/$pod.log,1,1
openstack%2Fkeystone~887035,openstack/keystone,master,I754b0eb9eb74cd31f22440c64187d292c19ce4fa,doc: Add minimal documentation on generating migrations,MERGED,2023-06-27 12:33:38.000000000,2023-07-13 09:04:22.000000000,2023-07-03 14:23:44.000000000,"[{'_account_id': 7414}, {'_account_id': 14250}, {'_account_id': 22348}]","[{'number': 1, 'created': '2023-06-27 12:33:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/046675f51b7806fa0a59e35647ed3ba6496ffc9c', 'message': 'doc: Add minimal documentation on generating migrations\n\nWe can now auto-generate migrations. Document how this is done.\n\nChange-Id: I754b0eb9eb74cd31f22440c64187d292c19ce4fa\nSigned-off-by: Stephen Finucane <sfinucan@redhat.com>\n'}, {'number': 2, 'created': '2023-06-28 10:14:32.000000000', 'files': ['doc/source/contributor/database-migrations.rst'], 'web_link': 'https://opendev.org/openstack/keystone/commit/66d289f033c3e6067150c2731d2d3b2853a16f29', 'message': 'doc: Add minimal documentation on generating migrations\n\nWe can now auto-generate migrations. Document how this is done.\n\nChange-Id: I754b0eb9eb74cd31f22440c64187d292c19ce4fa\nSigned-off-by: Stephen Finucane <sfinucan@redhat.com>\n'}]",5,887035,66d289f033c3e6067150c2731d2d3b2853a16f29,18,3,2,15334,,,0,"doc: Add minimal documentation on generating migrations

We can now auto-generate migrations. Document how this is done.

Change-Id: I754b0eb9eb74cd31f22440c64187d292c19ce4fa
Signed-off-by: Stephen Finucane <sfinucan@redhat.com>
",git fetch https://review.opendev.org/openstack/keystone refs/changes/35/887035/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/source/contributor/database-migrations.rst'],1,046675f51b7806fa0a59e35647ed3ba6496ffc9c,sqlalchemy-20,".. versionchanged:: 24.0.0 (Bobcat) Added support for auto-generation of migrations using the ``keystone.common.sql.migrations.manage`` script. Writing your own migrations --------------------------- Because Keystone uses the expand-contract pattern for database migrations, it is not possible to use the standard ``alembic`` CLI tool. Instead, Keystone provides its own tool which provides a similar UX to the ``alembic`` tool but which auto-configures alembic (the library) for this pattern. To create a new *expand* branch migration: .. code-block:: bash python -m keystone.common.sql.migrations.manage --expand \ -m ""My expand migration"" To create a new *contract* branch migration: .. code-block:: bash python -m keystone.common.sql.migrations.manage --expand \ -m ""My contract migration"" To auto-generate an *expand* and/or *contract* branch migration: .. code-block:: bash python -m keystone.common.sql.migrations.manage --autogenerate \ -m ""My auto-generated migration"" .. important:: Because of discrepancies between the migrations and models which are yet to be ironed out, a number of columns are intentionally ignored. You can view these by inspecting the ``env.py`` file in ``keystone/common/sql/migrations``. To view the help page: .. code-block:: bash python -m keystone.common.sql.migrations.manage --help For information on how this tool works, refer to `this blog post`_. For more information on writing migration scripts in general refer to the `Alembic`_ documentation. .. _this blog post: https://that.guru/blog/zero-downtime-upgrades-with-alembic-and-sqlalchemy/",For more information on writing individual migration scripts refer to `Alembic`_. ,51,2
openstack%2Ftripleo-heat-templates~886851,openstack/tripleo-heat-templates,stable/train,Id5decf5a2ed9207920828eebf7cb0056ea60bc39,[Train Only] Run glance cron only when glance cache is enabled.,MERGED,2023-06-23 14:42:18.000000000,2023-07-13 09:02:19.000000000,2023-06-26 12:53:14.000000000,"[{'_account_id': 8297}, {'_account_id': 21129}, {'_account_id': 22348}, {'_account_id': 33080}]","[{'number': 1, 'created': '2023-06-23 14:42:18.000000000', 'files': ['deployment/glance/glance-api-container-puppet.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/3758df618bfe9d4d3824f3f37b698c46ae6e2933', 'message': '[Train Only] Run glance cron only when glance cache is enabled.\n\nGlance db purge was added after train, so without glance cache, the\nglance cron has nothing to execute and just fail at start.\n\nCloses-Bug: #2024555\n\nChange-Id: Id5decf5a2ed9207920828eebf7cb0056ea60bc39\nCo-Authored-By: Mikolaj Ciecierski <mciecier@redhat.com>\n'}]",4,886851,3758df618bfe9d4d3824f3f37b698c46ae6e2933,10,4,1,8297,,,0,"[Train Only] Run glance cron only when glance cache is enabled.

Glance db purge was added after train, so without glance cache, the
glance cron has nothing to execute and just fail at start.

Closes-Bug: #2024555

Change-Id: Id5decf5a2ed9207920828eebf7cb0056ea60bc39
Co-Authored-By: Mikolaj Ciecierski <mciecier@redhat.com>
",git fetch https://review.opendev.org/openstack/tripleo-heat-templates refs/changes/51/886851/1 && git format-patch -1 --stdout FETCH_HEAD,['deployment/glance/glance-api-container-puppet.yaml'],1,3758df618bfe9d4d3824f3f37b698c46ae6e2933,," - if: - glance_cache_enabled - glance_api_cron: start_order: 2 image: *glance_api_image net: host user: root privileged: false restart: always healthcheck: test: '/usr/share/openstack-tripleo-common/healthcheck/cron glance' volumes: list_concat: - {get_attr: [ContainersCommon, volumes]} - {get_attr: [GlanceLogging, volumes]} - - /var/lib/kolla/config_files/glance_api_cron.json:/var/lib/kolla/config_files/config.json - /var/lib/config-data/puppet-generated/glance_api:/var/lib/kolla/config_files/src:ro - /var/lib/glance:/var/lib/glance:shared environment: KOLLA_CONFIG_STRATEGY: COPY_ALWAYS - {} "," - glance_api_cron: start_order: 2 image: *glance_api_image net: host user: root privileged: false restart: always healthcheck: test: '/usr/share/openstack-tripleo-common/healthcheck/cron glance' volumes: list_concat: - {get_attr: [ContainersCommon, volumes]} - {get_attr: [GlanceLogging, volumes]} - - /var/lib/kolla/config_files/glance_api_cron.json:/var/lib/kolla/config_files/config.json - /var/lib/config-data/puppet-generated/glance_api:/var/lib/kolla/config_files/src:ro - /var/lib/glance:/var/lib/glance:shared environment: KOLLA_CONFIG_STRATEGY: COPY_ALWAYS",23,19
openstack%2Fkolla~887642,openstack/kolla,stable/yoga,I42e7c4bfd6865388603a0fccaf29f2850a3a481e,rabbitmq: use erlang-25 ppa on Debian/Ubuntu,ABANDONED,2023-07-04 19:55:38.000000000,2023-07-13 08:16:52.000000000,,"[{'_account_id': 14200}, {'_account_id': 22348}, {'_account_id': 29873}, {'_account_id': 32029}, {'_account_id': 34405}, {'_account_id': 34437}, {'_account_id': 34579}, {'_account_id': 34585}, {'_account_id': 36151}]","[{'number': 1, 'created': '2023-07-04 19:55:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla/commit/592017183eed8d63cb4e8a30b360be62e1576cb3', 'message': 'rabbitmq: use erlang-25 ppa on Debian/Ubuntu\n\nRMQ team is now maintaining erlang-24, erlang-25 ppas, see [1].\n\nThis allows to solve compatibility issues between erlang and\nrabbitmq versions.\n\n[1]: https://github.com/rabbitmq/erlang-debian-package/discussions/33\n\nCloses-Bug: #2023668\nChange-Id: I42e7c4bfd6865388603a0fccaf29f2850a3a481e\nSigned-off-by: agarciaws <agarcia@whitestack.com>\n'}, {'number': 2, 'created': '2023-07-04 21:06:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla/commit/1b87820e65588ce592ff890331bdb0ac71c62c7c', 'message': 'rabbitmq: use erlang-25 ppa on Debian/Ubuntu\n\nRMQ team is now maintaining erlang-24, erlang-25 ppas, see [1].\n\nThis allows solving compatibility issues between erlang and\nrabbitmq versions.\n\n[1]: https://github.com/rabbitmq/erlang-debian-package/discussions/33\n\nCloses-Bug: #2023668\nChange-Id: I42e7c4bfd6865388603a0fccaf29f2850a3a481e\nSigned-off-by: agarciaws <agarcia@whitestack.com>\n'}, {'number': 3, 'created': '2023-07-13 08:07:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla/commit/4523f272702c8f45f0e6b70765247e3895db9a21', 'message': 'rabbitmq: use erlang-25 ppa on Debian/Ubuntu\n\nRMQ team is now maintaining erlang-24, erlang-25 ppas, see [1].\n\n[1]: https://github.com/rabbitmq/erlang-debian-package/discussions/33\n\nCloses-Bug: #2023668\nChange-Id: I42e7c4bfd6865388603a0fccaf29f2850a3a481e\nSigned-off-by: agarciaws <agarcia@whitestack.com>\n(cherry picked from commit 0e881148d0036f27b95c5a27459e527fb3b0476d)\n'}, {'number': 4, 'created': '2023-07-13 08:07:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla/commit/722ada394b69fd8a68f70133b90ecfc92c8c6fee', 'message': 'rabbitmq: use erlang-25 ppa on Debian/Ubuntu\n\nRMQ team is now maintaining erlang-24, erlang-25 ppas, see [1].\n\n[1]: https://github.com/rabbitmq/erlang-debian-package/discussions/33\n\nCloses-Bug: #2023668\nChange-Id: I42e7c4bfd6865388603a0fccaf29f2850a3a481e\n(cherry picked from commit 0e881148d0036f27b95c5a27459e527fb3b0476d)\nSigned-off-by: agarciaws <agarcia@whitestack.com>\n'}, {'number': 5, 'created': '2023-07-13 08:08:25.000000000', 'files': ['docker/base/apt_preferences.ubuntu', 'docker/base/apt_preferences.debian', 'kolla/template/repos.yaml'], 'web_link': 'https://opendev.org/openstack/kolla/commit/a2d1901d694255e7f6e7a529e638a6bdb63a2100', 'message': 'rabbitmq: use erlang-25 ppa on Debian/Ubuntu\n\nRMQ team is now maintaining erlang-24, erlang-25 ppas, see [1].\n\n[1]: https://github.com/rabbitmq/erlang-debian-package/discussions/33\n\nCloses-Bug: #2023668\nChange-Id: I42e7c4bfd6865388603a0fccaf29f2850a3a481e\n(cherry picked from commit 0e881148d0036f27b95c5a27459e527fb3b0476d)\n'}]",8,887642,a2d1901d694255e7f6e7a529e638a6bdb63a2100,22,9,5,34437,,,0,"rabbitmq: use erlang-25 ppa on Debian/Ubuntu

RMQ team is now maintaining erlang-24, erlang-25 ppas, see [1].

[1]: https://github.com/rabbitmq/erlang-debian-package/discussions/33

Closes-Bug: #2023668
Change-Id: I42e7c4bfd6865388603a0fccaf29f2850a3a481e
(cherry picked from commit 0e881148d0036f27b95c5a27459e527fb3b0476d)
",git fetch https://review.opendev.org/openstack/kolla refs/changes/42/887642/1 && git format-patch -1 --stdout FETCH_HEAD,"['docker/base/apt_preferences.ubuntu', 'docker/base/apt_preferences.debian', 'kolla/template/repos.yaml']",3,592017183eed8d63cb4e8a30b360be62e1576cb3,bug/2023668," url: ""https://ppa.launchpadcontent.net/rabbitmq/rabbitmq-erlang-25/ubuntu"" url: ""https://ppa.launchpadcontent.net/rabbitmq/rabbitmq-erlang-25/ubuntu"" url: ""https://ppa.launchpadcontent.net/rabbitmq/rabbitmq-erlang-25/ubuntu"" url: ""https://launchpad.net/~rabbitmq/+archive/ubuntu/rabbitmq-erlang-25"""," url: ""https://ppa.launchpadcontent.net/rabbitmq/rabbitmq-erlang/ubuntu"" url: ""https://ppa.launchpadcontent.net/rabbitmq/rabbitmq-erlang/ubuntu"" url: ""https://ppa.launchpadcontent.net/rabbitmq/rabbitmq-erlang/ubuntu"" url: ""https://ppa.launchpadcontent.net/rabbitmq/rabbitmq-erlang/ubuntu""",4,12
openstack%2Fkolla-ansible~888435,openstack/kolla-ansible,master,Ifed325fbe5f6f8efc67656155bea848af1c6a573,Fix,ABANDONED,2023-07-13 08:10:27.000000000,2023-07-13 08:12:21.000000000,,[],"[{'number': 1, 'created': '2023-07-13 08:10:27.000000000', 'files': ['ansible/roles/keystone/templates/keystone.conf.j2', 'ansible/roles/keystone/defaults/main.yml'], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/c973df21d4b9c87cee614866c7e558498784233e', 'message': 'Fix\n\nChange-Id: Ifed325fbe5f6f8efc67656155bea848af1c6a573\n'}]",0,888435,c973df21d4b9c87cee614866c7e558498784233e,2,0,1,35887,,,0,"Fix

Change-Id: Ifed325fbe5f6f8efc67656155bea848af1c6a573
",git fetch https://review.opendev.org/openstack/kolla-ansible refs/changes/35/888435/1 && git format-patch -1 --stdout FETCH_HEAD,"['ansible/roles/keystone/templates/keystone.conf.j2', 'ansible/roles/keystone/defaults/main.yml']",2,c973df21d4b9c87cee614866c7e558498784233e,fix/fix-sso,"# These variables are used to define multiple trusted Horizon and Skyline dashboards. # keystone_horizon_trusted_dashboards: ['<https://dashboardServerOne/auth/websso/>', '<https://dashboardServerTwo/auth/websso/>', '<https://dashboardServerN/auth/websso/>'] # keystone_skyline_trusted_dashboards: ['https://skyline/api/openstack/skyline/api/v1/websso'] keystone_horizon_trusted_dashboards: ""{{ ['%s://%s/auth/websso/' % (public_protocol, kolla_external_fqdn), '%s/auth/websso/' % (horizon_public_endpoint)] if enable_horizon | bool else [] }}"" keystone_skyline_trusted_dashboards: ""{{ ['%s://%s/auth/websso/' % (public_protocol, kolla_external_fqdn), '%s/auth/websso/' % (skyline_public_endpoint)] if enable_skyline | bool else [] }}""","# These variables are used to define multiple trusted Horizon dashboards. # keystone_trusted_dashboards: ['<https://dashboardServerOne/auth/websso/>', '<https://dashboardServerTwo/auth/websso/>', '<https://dashboardServerN/auth/websso/>'] keystone_trusted_dashboards: ""{{ ['%s://%s/auth/websso/' % (public_protocol, kolla_external_fqdn), '%s/auth/websso/' % (horizon_public_endpoint)] if enable_horizon | bool else [] }}""",9,4
openstack%2Fskyline-console~888421,openstack/skyline-console,master,I83fab09327942dd454d6c36c2d570ebfd27a7a6e,fix: fix virtual resources data display,MERGED,2023-07-13 06:03:02.000000000,2023-07-13 08:03:14.000000000,2023-07-13 08:01:12.000000000,"[{'_account_id': 22348}, {'_account_id': 28706}]","[{'number': 1, 'created': '2023-07-13 06:03:02.000000000', 'files': ['src/pages/base/containers/AdminOverview/style.less'], 'web_link': 'https://opendev.org/openstack/skyline-console/commit/e0e0a49e8e07517fdc6dfa52d229ad74df7a4b6e', 'message': 'fix: fix virtual resources data display\n\nfix the virtual resources used display in the administrator overview page\n\nChange-Id: I83fab09327942dd454d6c36c2d570ebfd27a7a6e\n'}]",0,888421,e0e0a49e8e07517fdc6dfa52d229ad74df7a4b6e,7,2,1,30434,,,0,"fix: fix virtual resources data display

fix the virtual resources used display in the administrator overview page

Change-Id: I83fab09327942dd454d6c36c2d570ebfd27a7a6e
",git fetch https://review.opendev.org/openstack/skyline-console refs/changes/21/888421/1 && git format-patch -1 --stdout FETCH_HEAD,['src/pages/base/containers/AdminOverview/style.less'],1,e0e0a49e8e07517fdc6dfa52d229ad74df7a4b6e,styles, margin-right: 20px;, margin-right: 200px;,1,1
openstack%2Fcharm-neutron-api-plugin-ovn~888056,openstack/charm-neutron-api-plugin-ovn,stable/victoria,I24ac22973af2a393ab65804058d051dc0cb60a6b,Add 'ovn-source' config option.,ABANDONED,2023-07-10 16:04:19.000000000,2023-07-13 07:49:20.000000000,,"[{'_account_id': 20648}, {'_account_id': 22348}]","[{'number': 1, 'created': '2023-07-10 16:04:19.000000000', 'files': ['src/config.yaml', 'unit_tests/test_lib_charm_openstack_ovn.py', 'src/tests/bundles/focal-ussuri.yaml', 'src/reactive/neutron_api_plugin_ovn_handlers.py', 'src/tests/bundles/focal-victoria.yaml', 'src/build.lock', 'src/lib/charm/openstack/neutron_api_plugin_ovn.py', 'unit_tests/test_reactive_neutron_api_plugin_ovn_handlers.py'], 'web_link': 'https://opendev.org/openstack/charm-neutron-api-plugin-ovn/commit/51dba56d710c3de46fd772978d08f5edd8f9814a', 'message': 'Add \'ovn-source\' config option.\n\nThis option enables configuration of overlay package\nrepository for installation of OVN packages that are\nnot available in default distribution repository.\n\nExpected behavior:\n* New deployments will use default overlay for\n  their series.\n* Setting this option to ""distro"" allows new\n  deployment that does not use overlay repository\n* Existing deployments that are upgraded to this\n  version of the charm won\'t automatically apply\n  repository overlay and will keep using their\n  current defaults.\n\n(cherry picked from commit 412885acc9aeb94de910757d1fee5658a8de9a10)\n\nCloses-Bug: #1992770\nChange-Id: I24ac22973af2a393ab65804058d051dc0cb60a6b\n'}]",1,888056,51dba56d710c3de46fd772978d08f5edd8f9814a,6,2,1,32288,,,0,"Add 'ovn-source' config option.

This option enables configuration of overlay package
repository for installation of OVN packages that are
not available in default distribution repository.

Expected behavior:
* New deployments will use default overlay for
  their series.
* Setting this option to ""distro"" allows new
  deployment that does not use overlay repository
* Existing deployments that are upgraded to this
  version of the charm won't automatically apply
  repository overlay and will keep using their
  current defaults.

(cherry picked from commit 412885acc9aeb94de910757d1fee5658a8de9a10)

Closes-Bug: #1992770
Change-Id: I24ac22973af2a393ab65804058d051dc0cb60a6b
",git fetch https://review.opendev.org/openstack/charm-neutron-api-plugin-ovn refs/changes/56/888056/1 && git format-patch -1 --stdout FETCH_HEAD,"['src/config.yaml', 'unit_tests/test_lib_charm_openstack_ovn.py', 'src/tests/bundles/focal-ussuri.yaml', 'src/reactive/neutron_api_plugin_ovn_handlers.py', 'src/tests/bundles/focal-victoria.yaml', 'src/build.lock', 'src/lib/charm/openstack/neutron_api_plugin_ovn.py', 'unit_tests/test_reactive_neutron_api_plugin_ovn_handlers.py']",8,51dba56d710c3de46fd772978d08f5edd8f9814a,," 'stamp_fresh_deployment': ( 'charm.installed', 'leadership.set.install_stamp', ), 'stamp_upgraded_deployment': ( 'is-update-status-hook', 'leadership.set.install_stamp', 'leadership.set.upgrade_stamp' ), 'enable_install': ( 'charm.installed', 'is-update-status-hook', ), 'ovn_source_changed': ('config.changed.ovn-source',), 'stamp_fresh_deployment': ('leadership.is_leader',), 'stamp_upgraded_deployment': ( 'charm.installed', 'leadership.is_leader' ), 'when_any': { 'enable_install': ( 'leadership.set.install_stamp', 'leadership.set.upgrade_stamp'), }, 'when_not': { 'ovn_source_changed': ('config.default.ovn-source',) } def test_ovn_source_config_changed(self): """"""Test that changing 'ovn-source' config triggers package upgrade."""""" config = {'ovn-source': 'cloud:focal-ovn-22.03'} handlers.ch_core.hookenv.config.return_value = config handlers.ovn_source_changed() self.charm.upgrade_ovn.assert_called_once_with()",,309,6
openstack%2Felection~886787,openstack/election,master,Id8d5e4689ad2374a197e63e7fb41c6b5c265ff5c,Fix the tag to be used for setting election config,MERGED,2023-06-22 20:41:16.000000000,2023-07-13 07:42:11.000000000,2023-07-13 07:41:16.000000000,"[{'_account_id': 12898}, {'_account_id': 14482}, {'_account_id': 15993}, {'_account_id': 22348}]","[{'number': 1, 'created': '2023-06-22 20:41:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/election/commit/298dee94fc83481184490ac99fcb5c09af96290b', 'message': 'Fix the tag to be used for setting election config\n\nWhen we start the election configuration for dates and\nother deadlines, we use the dummy tag generated with election\nmonth and which gets updated once governance release the\nactual tag of semver. It is confusing that initial tag\ngenerated by setup_election_config cmd is actual tag or just\na placeholder.\n\nThis commit make it clear to use a placeholder tag so that we\nknow that we need to get new tag in governance at the email_deadline\nand update here.\n\nChange-Id: Id8d5e4689ad2374a197e63e7fb41c6b5c265ff5c\n'}, {'number': 2, 'created': '2023-06-22 21:40:46.000000000', 'files': ['openstack_election/cmds/setup_election_config.py'], 'web_link': 'https://opendev.org/openstack/election/commit/3021ebe674d8defb1c3c633487d7c86ef8428b8e', 'message': 'Fix the tag to be used for setting election config\n\nWhen we start the election configuration for dates and\nother deadlines, we use the dummy tag generated with election\nmonth and which gets updated once governance release the\nactual tag of semver. It is confusing that initial tag\ngenerated by setup_election_config cmd is actual tag or just\na placeholder.\n\nGovernance repo has switched to semver type tag since 2018\n- https://github.com/openstack/governance/tags?after=oct-2017-elections\n\nElection repo started the below process since 2019:\n1. Add placeholder/dummy tag in election config (election month tag generated by script)\n- https://review.opendev.org/c/openstack/election/+/661673\n2. On email_deadline, release a new tag of governance repo\n- https://review.opendev.org/c/openstack/releases/+/680691\n3. Update the released tag in election config\n- https://review.opendev.org/c/openstack/election/+/681274\n\nThis commit does not change the existing process and make the placeholder tag more\nclear so that we know that we need to release a new tag in governance at the email_deadline\nand update here.\n\nChange-Id: Id8d5e4689ad2374a197e63e7fb41c6b5c265ff5c\n'}]",1,886787,3021ebe674d8defb1c3c633487d7c86ef8428b8e,12,4,2,8556,,,0,"Fix the tag to be used for setting election config

When we start the election configuration for dates and
other deadlines, we use the dummy tag generated with election
month and which gets updated once governance release the
actual tag of semver. It is confusing that initial tag
generated by setup_election_config cmd is actual tag or just
a placeholder.

Governance repo has switched to semver type tag since 2018
- https://github.com/openstack/governance/tags?after=oct-2017-elections

Election repo started the below process since 2019:
1. Add placeholder/dummy tag in election config (election month tag generated by script)
- https://review.opendev.org/c/openstack/election/+/661673
2. On email_deadline, release a new tag of governance repo
- https://review.opendev.org/c/openstack/releases/+/680691
3. Update the released tag in election config
- https://review.opendev.org/c/openstack/election/+/681274

This commit does not change the existing process and make the placeholder tag more
clear so that we know that we need to release a new tag in governance at the email_deadline
and update here.

Change-Id: Id8d5e4689ad2374a197e63e7fb41c6b5c265ff5c
",git fetch https://review.opendev.org/openstack/election refs/changes/87/886787/1 && git format-patch -1 --stdout FETCH_HEAD,['openstack_election/cmds/setup_election_config.py'],1,298dee94fc83481184490ac99fcb5c09af96290b,," tag='to-be-released',"," tag=args.date.strftime('%b-%Y-elections').lower(),",1,1
openstack%2Fcharm-neutron-api-plugin-ovn~888053,openstack/charm-neutron-api-plugin-ovn,stable/wallaby,Ifbf2f50f70b54cc558cb76c1edd076f91c839930,Add 'ovn-source' config option.,ABANDONED,2023-07-10 15:44:01.000000000,2023-07-13 07:39:19.000000000,,"[{'_account_id': 20648}, {'_account_id': 22348}]","[{'number': 1, 'created': '2023-07-10 15:44:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-neutron-api-plugin-ovn/commit/eaf9d52fe88e6ad10da720a4bef6b42a3cafa668', 'message': 'Add \'ovn-source\' config option.\n\nThis option enables configuration of overlay package\nrepository for installation of OVN packages that are\nnot available in default distribution repository.\n\nExpected behavior:\n* New deployments will use default overlay for\n  their series.\n* Setting this option to ""distro"" allows new\n  deployment that does not use overlay repository\n* Existing deployments that are upgraded to this\n  version of the charm won\'t automatically apply\n  repository overlay and will keep using their\n  current defaults.\n\nCloses-Bug: #1992770\nChange-Id: I20789f637c9443bd274df5f91522f9e2ce973164\n\n(cherry picked from commit 412885acc9aeb94de910757d1fee5658a8de9a10)\nChange-Id: Ifbf2f50f70b54cc558cb76c1edd076f91c839930\n'}, {'number': 2, 'created': '2023-07-10 15:45:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-neutron-api-plugin-ovn/commit/baf1822963a2da37623eb8cdeda71dfa471c7fbd', 'message': 'Add \'ovn-source\' config option.\n\nThis option enables configuration of overlay package\nrepository for installation of OVN packages that are\nnot available in default distribution repository.\n\nExpected behavior:\n* New deployments will use default overlay for\n  their series.\n* Setting this option to ""distro"" allows new\n  deployment that does not use overlay repository\n* Existing deployments that are upgraded to this\n  version of the charm won\'t automatically apply\n  repository overlay and will keep using their\n  current defaults.\n\n(cherry picked from commit 412885acc9aeb94de910757d1fee5658a8de9a10)\n\nCloses-Bug: #1992770\nChange-Id: Ifbf2f50f70b54cc558cb76c1edd076f91c839930\n'}, {'number': 3, 'created': '2023-07-10 16:11:11.000000000', 'files': ['src/config.yaml', 'src/tests/bundles/focal-wallaby-ovn-22.03.yaml', 'src/tests/bundles/focal-wallaby.yaml', 'unit_tests/test_lib_charm_openstack_ovn.py', 'src/reactive/neutron_api_plugin_ovn_handlers.py', 'src/tests/bundles/focal-victoria.yaml', 'src/build.lock', 'src/lib/charm/openstack/neutron_api_plugin_ovn.py', 'src/tests/bundles/focal-victoria-ovn-22.03.yaml', 'unit_tests/test_reactive_neutron_api_plugin_ovn_handlers.py'], 'web_link': 'https://opendev.org/openstack/charm-neutron-api-plugin-ovn/commit/b397ea0b9301d4b7f611c75464491026725fc50d', 'message': 'Add \'ovn-source\' config option.\n\nThis option enables configuration of overlay package\nrepository for installation of OVN packages that are\nnot available in default distribution repository.\n\nExpected behavior:\n* New deployments will use default overlay for\n  their series.\n* Setting this option to ""distro"" allows new\n  deployment that does not use overlay repository\n* Existing deployments that are upgraded to this\n  version of the charm won\'t automatically apply\n  repository overlay and will keep using their\n  current defaults.\n\nCloses-Bug: #1992770\nChange-Id: Ifbf2f50f70b54cc558cb76c1edd076f91c839930\n(cherry picked from commit 412885acc9aeb94de910757d1fee5658a8de9a10)\n'}]",1,888053,b397ea0b9301d4b7f611c75464491026725fc50d,10,2,3,32288,,,0,"Add 'ovn-source' config option.

This option enables configuration of overlay package
repository for installation of OVN packages that are
not available in default distribution repository.

Expected behavior:
* New deployments will use default overlay for
  their series.
* Setting this option to ""distro"" allows new
  deployment that does not use overlay repository
* Existing deployments that are upgraded to this
  version of the charm won't automatically apply
  repository overlay and will keep using their
  current defaults.

Closes-Bug: #1992770
Change-Id: Ifbf2f50f70b54cc558cb76c1edd076f91c839930
(cherry picked from commit 412885acc9aeb94de910757d1fee5658a8de9a10)
",git fetch https://review.opendev.org/openstack/charm-neutron-api-plugin-ovn refs/changes/53/888053/1 && git format-patch -1 --stdout FETCH_HEAD,"['src/config.yaml', 'src/tests/bundles/focal-wallaby-ovn-22.03.yaml', 'src/tests/bundles/focal-wallaby.yaml', 'unit_tests/test_lib_charm_openstack_ovn.py', 'src/reactive/neutron_api_plugin_ovn_handlers.py', 'src/tests/bundles/focal-victoria.yaml', 'src/build.lock', 'src/lib/charm/openstack/neutron_api_plugin_ovn.py', 'src/tests/bundles/focal-victoria-ovn-22.03.yaml', 'unit_tests/test_reactive_neutron_api_plugin_ovn_handlers.py']",10,eaf9d52fe88e6ad10da720a4bef6b42a3cafa668,," 'stamp_fresh_deployment': ( 'charm.installed', 'leadership.set.install_stamp', ), 'stamp_upgraded_deployment': ( 'is-update-status-hook', 'leadership.set.install_stamp', 'leadership.set.upgrade_stamp' ), 'enable_install': ( 'charm.installed', 'is-update-status-hook', ), 'ovn_source_changed': ('config.changed.ovn-source',), 'stamp_fresh_deployment': ('leadership.is_leader',), 'stamp_upgraded_deployment': ( 'charm.installed', 'leadership.is_leader' ), 'when_any': { 'enable_install': ( 'leadership.set.install_stamp', 'leadership.set.upgrade_stamp'), }, 'when_not': { 'ovn_source_changed': ('config.default.ovn-source',) } def test_ovn_source_config_changed(self): """"""Test that changing 'ovn-source' config triggers package upgrade."""""" config = {'ovn-source': 'cloud:focal-ovn-22.03'} handlers.ch_core.hookenv.config.return_value = config handlers.ovn_source_changed() self.charm.upgrade_ovn.assert_called_once_with()",,311,8
openstack%2Fcharm-placement-k8s~888432,openstack/charm-placement-k8s,main,I1654463b2b3df47795a8dd89f53d4c703cb13689,Use admin interface for intra-cluster communication,ABANDONED,2023-07-13 07:35:20.000000000,2023-07-13 07:35:48.000000000,,[],"[{'number': 1, 'created': '2023-07-13 07:35:20.000000000', 'files': ['src/templates/parts/section-identity', 'src/templates/parts/section-service-user'], 'web_link': 'https://opendev.org/openstack/charm-placement-k8s/commit/797811f3477086e07b8187ec73661e5ffb1fd9cc', 'message': 'Use admin interface for intra-cluster communication\n\nInternal interface is currently implemented to go through a loadbalancer endpoint that will be used for all communication. This adds an unnecessary hop as kubernetes services are able to load balance internally.\n\nChange-Id: I1654463b2b3df47795a8dd89f53d4c703cb13689\n'}]",0,888432,797811f3477086e07b8187ec73661e5ffb1fd9cc,2,0,1,35761,,,0,"Use admin interface for intra-cluster communication

Internal interface is currently implemented to go through a loadbalancer endpoint that will be used for all communication. This adds an unnecessary hop as kubernetes services are able to load balance internally.

Change-Id: I1654463b2b3df47795a8dd89f53d4c703cb13689
",git fetch https://review.opendev.org/openstack/charm-placement-k8s refs/changes/32/888432/1 && git format-patch -1 --stdout FETCH_HEAD,"['src/templates/parts/section-identity', 'src/templates/parts/section-service-user']",2,797811f3477086e07b8187ec73661e5ffb1fd9cc,use-auth-interface,{% if identity_service.admin_auth_url -%} auth_url = {{ identity_service.admin_auth_url }} {% elif identity_service.internal_auth_url -%},{% if identity_service.internal_auth_url -%},10,2
openstack%2Ftempest~873706,openstack/tempest,master,I7c9588212a05347f9b20016aff028df6c48dafa1,Add a tempest test to verify lack of cgroupsv2 support for cpu controller.,NEW,2023-02-14 11:59:42.000000000,2023-07-13 07:35:48.000000000,,"[{'_account_id': 8313}, {'_account_id': 8556}, {'_account_id': 8864}, {'_account_id': 22348}, {'_account_id': 22873}, {'_account_id': 30674}]","[{'number': 1, 'created': '2023-02-14 11:59:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/dbe8f9ce97a930b0dc17ada84a22da722e78450f', 'message': 'WIP: Create a tempest test to verify bz#2118968\n\nChange-Id: I7c9588212a05347f9b20016aff028df6c48dafa1\n'}, {'number': 2, 'created': '2023-02-15 13:54:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/16cacd9b9bbb5cb66828409ca5506f1bcac3d7c0', 'message': 'WIP: Create a tempest test to verify bz#2118968\n\nChange-Id: I7c9588212a05347f9b20016aff028df6c48dafa1\n'}, {'number': 3, 'created': '2023-02-15 14:05:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/cc82a3b58e9e38cfa9ce6593227145ed36e1a608', 'message': 'WIP: Create a tempest test to verify bz#2118968\n\nChange-Id: I7c9588212a05347f9b20016aff028df6c48dafa1\n'}, {'number': 4, 'created': '2023-02-15 15:08:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/21b60cc88c781efdb8769737fa83c4c3dbd60a95', 'message': 'WIP: Create a tempest test to verify bz#2118968\n\nChange-Id: I7c9588212a05347f9b20016aff028df6c48dafa1\n'}, {'number': 5, 'created': '2023-02-15 16:33:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/785135f78665285165c79c14f13ab52e98a35eba', 'message': 'WIP: Create a tempest test to verify bz#2118968\n\nChange-Id: I7c9588212a05347f9b20016aff028df6c48dafa1\n'}, {'number': 6, 'created': '2023-02-16 11:30:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/24308bdaa0da641eee6437e78f1332ebde54faf6', 'message': 'WIP: Create a tempest test to verify bz#2118968\n\nChange-Id: I7c9588212a05347f9b20016aff028df6c48dafa1\n'}, {'number': 7, 'created': '2023-02-16 11:57:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/edaab5b58b00f177c118c15e014f5a06b634094f', 'message': 'WIP: Create a tempest test to verify bz#2118968\n\nChange-Id: I7c9588212a05347f9b20016aff028df6c48dafa1\n'}, {'number': 8, 'created': '2023-02-16 12:01:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/d6cf9322a71136fc1eddadb1843c32cd56058ee2', 'message': 'WIP: Create a tempest test to verify bz#2118968\n\nChange-Id: I7c9588212a05347f9b20016aff028df6c48dafa1\n'}, {'number': 9, 'created': '2023-02-16 12:05:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/9616880b9ec104f946a80f61913fe4a75ff21be8', 'message': 'WIP: Create a tempest test to verify bz#2118968\n\nChange-Id: I7c9588212a05347f9b20016aff028df6c48dafa1\n'}, {'number': 10, 'created': '2023-02-16 13:28:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/ff021c4f12240dd8c038e379b00523102962bb67', 'message': 'WIP: Create a tempest test to verify bz#2118968\n\nChange-Id: I7c9588212a05347f9b20016aff028df6c48dafa1\n'}, {'number': 11, 'created': '2023-02-16 13:57:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/1079122ca7801effc8c87929b40040c0a4d4390f', 'message': 'WIP: Create a tempest test to verify bz#2118968\n\nChange-Id: I7c9588212a05347f9b20016aff028df6c48dafa1\n'}, {'number': 12, 'created': '2023-02-16 14:01:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/9664d574379b4f67fb3945f5e8d17874bbd8f452', 'message': 'Create a tempest test to verify bz#2118968\n\nDepends-On: I99b57c27c8a4425389bec2b7f05af660bab85610\nChange-Id: I7c9588212a05347f9b20016aff028df6c48dafa1\n'}, {'number': 13, 'created': '2023-02-21 15:20:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/b82cfa08f1cc91346b9548969b115e201062ae50', 'message': 'Create a tempest test to verify bz#2118968\n\nDepends-On: I99b57c27c8a4425389bec2b7f05af660bab85610\nChange-Id: I7c9588212a05347f9b20016aff028df6c48dafa1\n'}, {'number': 14, 'created': '2023-02-22 14:11:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/3952b0be7a5927680a41f28c7512db6eb227d09d', 'message': 'Add a tempest test to verify lack of cgroupsv2 support for cpu controller.\n\nCreated a test that goes through the steps of the bug ticket and verifies that an error occurs when trying to create a flavor with cpu quota on a system running cgroupsv2.\n\nPartial-Bug: #2008102\nResolves: rhbz#2118968\nDepends-On: I99b57c27c8a4425389bec2b7f05af660bab85610\nChange-Id: I7c9588212a05347f9b20016aff028df6c48dafa1\n'}, {'number': 15, 'created': '2023-02-23 11:57:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/5ea0909b09220d3034bb43c15f50bad4dcb311ca', 'message': 'Add a tempest test to verify lack of cgroupsv2 support for cpu controller.\n\nCreated a tempest test that builds a flavor enriched with the\n""quota:cpu_quota"" property. Then, it builds a server based on that flavor\nand checks that it reaches the ""ACTIVE"" state. The server could fail to do so though,\nbecause under systems that operate under cgroups v2, such as ""RHEL-9"" or\n""Ubuntu 22.04"", the host is not capable of determining if it has support\nfor the cpu controller, even when the kernel does so. The test result\nrelies then on the underlying os that it is run on.\n\nPartial-Bug: #2008102\nDepends-On: I99b57c27c8a4425389bec2b7f05af660bab85610\nChange-Id: I7c9588212a05347f9b20016aff028df6c48dafa1\n'}, {'number': 16, 'created': '2023-02-28 14:01:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/2b96cdf491caf6aab77f9a341f78ee2c6f766c3b', 'message': 'Add a tempest test to verify lack of cgroupsv2 support for cpu controller.\n\nCreated a tempest test that builds a flavor enriched with the\n""quota:cpu_quota"" property. Then, it builds a server based on that flavor\nand checks that it reaches the ""ACTIVE"" state. The server could fail to do so though,\nbecause under systems that operate under cgroups v2, such as ""RHEL-9"" or\n""Ubuntu 22.04"", the host is not capable of determining if it has support\nfor the cpu controller, even when the kernel does so. The test result\nrelies then on the underlying os that it is run on.\n\nPartial-Bug: #2008102\nDepends-On: I99b57c27c8a4425389bec2b7f05af660bab85610\nChange-Id: I7c9588212a05347f9b20016aff028df6c48dafa1\n'}, {'number': 17, 'created': '2023-04-10 10:54:04.000000000', 'files': ['tempest/api/compute/admin/test_servers.py'], 'web_link': 'https://opendev.org/openstack/tempest/commit/85cb3d96cc7837cb14c1c00de0623d3c9bd44e3d', 'message': 'Add a tempest test to verify lack of cgroupsv2 support for cpu controller.\n\nCreated a tempest test that builds a flavor enriched with the\n""quota:cpu_quota"" property. Then, it builds a server based on that flavor\nand checks that it reaches the ""ACTIVE"" state. The server could fail to do so though,\nbecause under systems that operate under cgroups v2, such as ""RHEL-9"" or\n""Ubuntu 22.04"", the host is not capable of determining if it has support\nfor the cpu controller, even when the kernel does so. The test result\nrelies then on the underlying os that it is run on.\n\nPartial-Bug: #2008102\nDepends-On: I99b57c27c8a4425389bec2b7f05af660bab85610\nChange-Id: I7c9588212a05347f9b20016aff028df6c48dafa1\n'}]",21,873706,85cb3d96cc7837cb14c1c00de0623d3c9bd44e3d,45,6,17,34443,,,0,"Add a tempest test to verify lack of cgroupsv2 support for cpu controller.

Created a tempest test that builds a flavor enriched with the
""quota:cpu_quota"" property. Then, it builds a server based on that flavor
and checks that it reaches the ""ACTIVE"" state. The server could fail to do so though,
because under systems that operate under cgroups v2, such as ""RHEL-9"" or
""Ubuntu 22.04"", the host is not capable of determining if it has support
for the cpu controller, even when the kernel does so. The test result
relies then on the underlying os that it is run on.

Partial-Bug: #2008102
Depends-On: I99b57c27c8a4425389bec2b7f05af660bab85610
Change-Id: I7c9588212a05347f9b20016aff028df6c48dafa1
",git fetch https://review.opendev.org/openstack/tempest refs/changes/06/873706/1 && git format-patch -1 --stdout FETCH_HEAD,['tempest/api/compute/flavors/test_flavors.py'],1,dbe8f9ce97a930b0dc17ada84a22da722e78450f,#2008102," def test_cgroupsv2(self): flavor = self.flavors_client.create_flavor( flavor={ ""name"": ""flavor_cpu"", ""id"": 101, ""ram"": 2048, ""disk"": 10, ""vcpus"": 2 } )",,11,0
openstack%2Ftripleo-heat-templates~888159,openstack/tripleo-heat-templates,stable/wallaby,I274c7f5144c07287a909a2f51fd755727b9f27bc,Fix designate sRBAC overrides,MERGED,2023-07-11 21:06:20.000000000,2023-07-13 04:16:51.000000000,2023-07-13 04:16:51.000000000,"[{'_account_id': 6681}, {'_account_id': 9816}, {'_account_id': 22348}, {'_account_id': 32029}]","[{'number': 1, 'created': '2023-07-11 21:06:20.000000000', 'files': ['environments/enable-secure-rbac.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/21d91563716010ffc59f23a2cc6023cd5e5799c0', 'message': 'Fix designate sRBAC overrides\n\nThe enable-secure-rbac.yaml overrides for designate have some bugs.\nThis patch corrects those to be more in line with the defaults in code for\nnew defaults and no scoped tokens.\n\nChange-Id: I274c7f5144c07287a909a2f51fd755727b9f27bc\n'}]",1,888159,21d91563716010ffc59f23a2cc6023cd5e5799c0,12,4,1,11628,,,0,"Fix designate sRBAC overrides

The enable-secure-rbac.yaml overrides for designate have some bugs.
This patch corrects those to be more in line with the defaults in code for
new defaults and no scoped tokens.

Change-Id: I274c7f5144c07287a909a2f51fd755727b9f27bc
",git fetch https://review.opendev.org/openstack/tripleo-heat-templates refs/changes/59/888159/1 && git format-patch -1 --stdout FETCH_HEAD,['environments/enable-secure-rbac.yaml'],1,21d91563716010ffc59f23a2cc6023cd5e5799c0,," value: ""role:admin"" value: ""(role:reader and project_id:%(project_id)s) or role:admin"" value: ""(role:reader and project_id:%(project_id)s) or role:admin"" value: ""(role:reader and project_id:%(project_id)s) or role:admin"" value: ""(role:reader and project_id:%(project_id)s) or role:admin"""," value: ""role:reader"" value: ""(role:reader and project_id:%(project_id)s) or (True:%(all_tenants)s and role:reader)"" value: ""(role:reader and project_id:%(project_id)s) or (True:%(all_tenants)s and role:reader)"" value: ""(role:reader and project_id:%(project_id)s) or (True:%(all_tenants)s and role:reader)"" value: ""(role:reader and project_id:%(project_id)s) or (True:%(all_tenants)s and role:reader)""",5,5
openstack%2Fpuppet-glance~888258,openstack/puppet-glance,master,I4fc9a34db162b6c85a5f4bcf50c3fb77b1b6640d,authtoken: Make password required,MERGED,2023-07-12 12:56:16.000000000,2023-07-13 04:12:30.000000000,2023-07-13 04:12:30.000000000,"[{'_account_id': 14985}, {'_account_id': 21129}, {'_account_id': 22348}]","[{'number': 1, 'created': '2023-07-12 12:56:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-glance/commit/6e140d6aca49f111ec07124d6e30962b778a790a', 'message': 'authtoken: Make password required\n\nThe password parameter is not really optional. This makes it\na required parameter to give more sensible validation error.\n\nChange-Id: I4fc9a34db162b6c85a5f4bcf50c3fb77b1b6640d\n'}, {'number': 2, 'created': '2023-07-12 12:57:59.000000000', 'files': ['manifests/api/authtoken.pp'], 'web_link': 'https://opendev.org/openstack/puppet-glance/commit/6b846d600af7f1704f46302fe4a3f9858e9c2cdb', 'message': 'authtoken: Make password required\n\nThe password parameter is not really optional. This makes it\na required parameter to give more sensible validation error.\n\nChange-Id: I4fc9a34db162b6c85a5f4bcf50c3fb77b1b6640d\n'}]",1,888258,6b846d600af7f1704f46302fe4a3f9858e9c2cdb,12,3,2,9816,,,0,"authtoken: Make password required

The password parameter is not really optional. This makes it
a required parameter to give more sensible validation error.

Change-Id: I4fc9a34db162b6c85a5f4bcf50c3fb77b1b6640d
",git fetch https://review.opendev.org/openstack/puppet-glance refs/changes/58/888258/1 && git format-patch -1 --stdout FETCH_HEAD,['manifests/api/authtoken.pp'],1,6e140d6aca49f111ec07124d6e30962b778a790a,at-password,"# [*password*] # (Required) Password to create for the service user # $password,","# [*password*] # (Optional) Password to create for the service user # Defaults to $facts['os_service_default'] # $password = $facts['os_service_default'], if is_service_default($password) { fail('Please set password for Glance service user') } ",4,9
openstack%2Ftempest~887682,openstack/tempest,master,Ib1ea68fd1a82afedd9c6263ec6bf49cceec99238,"Revert ""Mark ""test_live_migration_with_trunk"" as unstable""",MERGED,2023-07-06 09:40:54.000000000,2023-07-13 01:54:53.000000000,2023-07-10 16:14:57.000000000,"[{'_account_id': 7166}, {'_account_id': 8313}, {'_account_id': 8556}, {'_account_id': 9708}, {'_account_id': 16688}, {'_account_id': 22348}]","[{'number': 1, 'created': '2023-07-06 09:40:54.000000000', 'files': ['tempest/api/compute/admin/test_live_migration.py'], 'web_link': 'https://opendev.org/openstack/tempest/commit/dd49b3ee3e4215d598a4a6ffc5b09dcee329bbd9', 'message': 'Revert ""Mark ""test_live_migration_with_trunk"" as unstable""\n\nThis reverts commit 0c953a7c100a8eced9158402106eec99f64a5378.\n\nReason for revert: The related bug has been resolved\n\nChange-Id: Ib1ea68fd1a82afedd9c6263ec6bf49cceec99238\nRelated-Bug: #2024160\n'}]",7,887682,dd49b3ee3e4215d598a4a6ffc5b09dcee329bbd9,20,6,1,31291,,,0,"Revert ""Mark ""test_live_migration_with_trunk"" as unstable""

This reverts commit 0c953a7c100a8eced9158402106eec99f64a5378.

Reason for revert: The related bug has been resolved

Change-Id: Ib1ea68fd1a82afedd9c6263ec6bf49cceec99238
Related-Bug: #2024160
",git fetch https://review.opendev.org/openstack/tempest refs/changes/82/887682/1 && git format-patch -1 --stdout FETCH_HEAD,['tempest/api/compute/admin/test_live_migration.py'],1,dd49b3ee3e4215d598a4a6ffc5b09dcee329bbd9,bug/2024160,, @decorators.unstable_test(bug='2024160'),0,1
openstack%2Fopenstack-helm-infra~887730,openstack/openstack-helm-infra,master,I5a9f1828d7c2f36e14de89323868c4a1dbebba64,Disable libvirt cgroup functionality for cgroup v2,MERGED,2023-07-05 17:47:59.000000000,2023-07-13 00:02:30.000000000,2023-07-13 00:00:53.000000000,"[{'_account_id': 3009}, {'_account_id': 8898}, {'_account_id': 22348}]","[{'number': 1, 'created': '2023-07-05 17:47:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/56311817fd1d8e1b37e098205c6bcc94a9758482', 'message': 'Disable libvirt cgroup functionality for cgroup v2\n\nChange-Id: I5a9f1828d7c2f36e14de89323868c4a1dbebba64\n'}, {'number': 2, 'created': '2023-07-08 06:49:16.000000000', 'files': ['libvirt/Chart.yaml', 'libvirt/templates/bin/_libvirt.sh.tpl', 'releasenotes/notes/libvirt.yaml'], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/4fc46f1808e5188c830a2ac5f55360e67aa78cd3', 'message': 'Disable libvirt cgroup functionality for cgroup v2\n\nChange-Id: I5a9f1828d7c2f36e14de89323868c4a1dbebba64\n'}]",3,887730,4fc46f1808e5188c830a2ac5f55360e67aa78cd3,12,3,2,35691,,,0,"Disable libvirt cgroup functionality for cgroup v2

Change-Id: I5a9f1828d7c2f36e14de89323868c4a1dbebba64
",git fetch https://review.opendev.org/openstack/openstack-helm-infra refs/changes/30/887730/1 && git format-patch -1 --stdout FETCH_HEAD,"['libvirt/Chart.yaml', 'libvirt/templates/bin/_libvirt.sh.tpl', 'releasenotes/notes/libvirt.yaml']",3,56311817fd1d8e1b37e098205c6bcc94a9758482,libvirt-cgroup-v2, - 0.1.21 Disable libvirt cgroup functionality for cgroup-v2,,61,41
openstack%2Fopenstack-helm-infra~887524,openstack/openstack-helm-infra,master,I84c38c7210217718339c0b1ef059bbad9854b2cc,Add OVN bridge-mapping,MERGED,2023-07-03 16:36:12.000000000,2023-07-13 00:01:48.000000000,2023-07-13 00:00:51.000000000,"[{'_account_id': 3009}, {'_account_id': 8898}, {'_account_id': 22348}]","[{'number': 1, 'created': '2023-07-03 16:36:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/3c98e69bbef9ac751deeea21b3d486bda2050c59', 'message': 'Add OVN bridge-mapping\n\nChange-Id: I84c38c7210217718339c0b1ef059bbad9854b2cc\n'}, {'number': 2, 'created': '2023-07-04 10:17:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/ec5f9de83f9d5f0327e79ec8c691536657799c4e', 'message': 'Add OVN bridge-mapping\n\nChange-Id: I84c38c7210217718339c0b1ef059bbad9854b2cc\n'}, {'number': 3, 'created': '2023-07-05 18:11:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/21e047fbe64c26040ecc23b6d4643e27b0478714', 'message': 'Add OVN bridge-mapping\n\nChange-Id: I84c38c7210217718339c0b1ef059bbad9854b2cc\n'}, {'number': 4, 'created': '2023-07-09 04:58:02.000000000', 'files': ['releasenotes/notes/ovn.yaml', 'ovn/templates/bin/_ovn-setup-bridges-init.sh.tpl', 'ovn/templates/configmap-bin.yaml', 'ovn/templates/configmap-etc.yaml', 'ovn/values.yaml', 'ovn/templates/bin/_ovn.sh.tpl', 'ovn/templates/daemonset-controller.yaml', 'ovn/Chart.yaml'], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/8c41205b580f09eaee3e753926a22836c95b43b8', 'message': 'Add OVN bridge-mapping\n\nChange-Id: I84c38c7210217718339c0b1ef059bbad9854b2cc\n'}]",5,887524,8c41205b580f09eaee3e753926a22836c95b43b8,18,3,4,35691,,,0,"Add OVN bridge-mapping

Change-Id: I84c38c7210217718339c0b1ef059bbad9854b2cc
",git fetch https://review.opendev.org/openstack/openstack-helm-infra refs/changes/24/887524/1 && git format-patch -1 --stdout FETCH_HEAD,"['ovn/templates/bin/_ovn-setup-bridges-init.sh.tpl', 'ovn/templates/configmap-bin.yaml', 'ovn/templates/configmap-etc.yaml', 'ovn/values.yaml', 'ovn/templates/bin/_ovn.sh.tpl', 'ovn/templates/daemonset-controller.yaml']",6,3c98e69bbef9ac751deeea21b3d486bda2050c59,ovn-bridge-mapping,"{{- $configMapName := ""ovn-etc"" }} - name: ovn-setup-bridge {{ tuple $envAll ""ovn_controller"" | include ""helm-toolkit.snippets.image"" | indent 10 }} command: - /tmp/ovn-setup-bridges-init.sh volumeMounts: - name: ovn-bin mountPath: /tmp/ovn-setup-bridges-init.sh subPath: ovn-setup-bridges-init.sh readOnly: true - name: run-openvswitch mountPath: /run/openvswitch - name: ovn-etc mountPath: /tmp/auto_bridge_add subPath: auto_bridge_add readOnly: true defaultMode: 0777 - name: ovn-etc secret: secretName: {{ $configMapName }} defaultMode: 0444", defaultMode: 0555,100,4
openstack%2Fdevstack~887660,openstack/devstack,stable/2023.1,Ie2663b951acb0c1a65597a39e032948764e6ae6a,nova: Bump timeout-per-gb for BFV rebuild ops,MERGED,2023-07-05 09:21:55.000000000,2023-07-12 23:37:39.000000000,2023-07-12 23:36:40.000000000,"[{'_account_id': 4393}, {'_account_id': 8556}, {'_account_id': 22348}]","[{'number': 1, 'created': '2023-07-05 09:21:55.000000000', 'files': ['lib/nova'], 'web_link': 'https://opendev.org/openstack/devstack/commit/6767465bc5d349a886614e3c7a49fe092584c67b', 'message': 'nova: Bump timeout-per-gb for BFV rebuild ops\n\nThis increases the timeout we use to wait for cinder to perform a\nvolume reimage. Since devstack is often running on a single machine\nwith non-production IO performance, we should bump this limit to avoid\nhitting it before the rebuild completes.\n\nChange-Id: Ie2663b951acb0c1a65597a39e032948764e6ae6a\n(cherry picked from commit 58c80b2424623096e4a1f7a901f424be0ce6cb3f)\n'}]",6,887660,6767465bc5d349a886614e3c7a49fe092584c67b,17,3,1,17685,,,0,"nova: Bump timeout-per-gb for BFV rebuild ops

This increases the timeout we use to wait for cinder to perform a
volume reimage. Since devstack is often running on a single machine
with non-production IO performance, we should bump this limit to avoid
hitting it before the rebuild completes.

Change-Id: Ie2663b951acb0c1a65597a39e032948764e6ae6a
(cherry picked from commit 58c80b2424623096e4a1f7a901f424be0ce6cb3f)
",git fetch https://review.opendev.org/openstack/devstack refs/changes/60/887660/1 && git format-patch -1 --stdout FETCH_HEAD,['lib/nova'],1,6767465bc5d349a886614e3c7a49fe092584c67b,reimage-timeout, # Set rebuild timeout longer for BFV instances because we likely have # slower disk than expected. Default is 20s/GB iniset $NOVA_CPU_CONF DEFAULT reimage_timeout_per_gb 60 ,,4,0
openstack%2Floci~858820,openstack/loci,master,Id92d1d6bd11acfbdd748073931b7b8f63d698368,Fix requirements build failures,ABANDONED,2022-09-21 21:20:44.000000000,2023-07-12 23:08:21.000000000,,"[{'_account_id': 8898}, {'_account_id': 22348}]","[{'number': 1, 'created': '2022-09-21 21:20:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/loci/commit/f3fe0197d7d88e01a703ca5e6341f3e8f111b173', 'message': 'Fix requirements build failures\n\nChange contains the following cleanup:\n  * remove build variable for cassandra-driver\n    - this is a whl in pypi for arm64 and aarch64 since Xena\n  * allow scipy packages\n    - these packages are whl in pypi for arm64 and aarch64 since Wallaby\n  * remove suds-jurko and anyjson\n    - these packages use 2to3 which is now removed\n  * remove python-nss\n    - this breaks with python3.10 and libnss>=3.58\n  * remove enum-compat\n    - this was a python2/3 compat lib. It is noop on python>=3.4\n\nChange-Id: Id92d1d6bd11acfbdd748073931b7b8f63d698368\n'}, {'number': 2, 'created': '2022-09-21 21:22:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/loci/commit/30b8f3bcbfa7794915cfd5ae3253140e369203fd', 'message': 'Fix requirements build failures\n\nChange contains the following cleanup:\n  * remove build variable for cassandra-driver\n    - this is a whl in pypi for arm64 and aarch64 since Xena\n  * allow scipy packages\n    - these packages are whl in pypi for amd4 and aarch64 since Wallaby\n  * remove suds-jurko and anyjson\n    - these packages use 2to3 which is now removed\n  * remove python-nss\n    - this breaks with python3.10 and libnss>=3.58\n  * remove enum-compat\n    - this was a python2/3 compat lib. It is noop on python>=3.4\n  * readd python-qpid-proton\n    - this has pypi whls for amd64 and aarch64 since Victoria\n\nChange-Id: Id92d1d6bd11acfbdd748073931b7b8f63d698368\n'}, {'number': 3, 'created': '2022-09-21 23:21:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/loci/commit/8b6493fef77bc667740af51f45d780832863aa1e', 'message': 'Fix requirements build failures\n\nChange contains the following cleanup:\n  * remove build variable for cassandra-driver\n    - this is a whl in pypi for arm64 and aarch64 since Xena\n  * allow scipy packages\n    - these packages are whl in pypi for amd4 and aarch64 since Wallaby\n  * remove suds-jurko and anyjson\n    - these packages use 2to3 which is now removed\n  * remove python-nss\n    - this breaks with python3.10 and libnss>=3.58\n  * remove enum-compat\n    - this was a python2/3 compat lib. It is noop on python>=3.4\n  * readd python-qpid-proton\n    - this has pypi whls for amd64 and aarch64 since Victoria\n\nChange-Id: Id92d1d6bd11acfbdd748073931b7b8f63d698368\n'}, {'number': 4, 'created': '2022-09-21 23:30:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/loci/commit/7c86a8d52b8c08735f96498b679bc50c0eac1ca2', 'message': 'Fix requirements build failures\n\nChange contains the following cleanup:\n  * remove build variable for cassandra-driver\n    - this is a whl in pypi for arm64 and aarch64 since Xena\n  * allow scipy packages\n    - these packages are whl in pypi for amd4 and aarch64 since Wallaby\n  * remove suds-jurko and anyjson\n    - these packages use 2to3 which is now removed\n  * remove python-nss\n    - this breaks with python3.10 and libnss>=3.58\n  * remove enum-compat\n    - this was a python2/3 compat lib. It is noop on python>=3.4\n  * readd python-qpid-proton\n    - this has pypi whls for amd64 and aarch64 since Victoria\n\nChange-Id: Id92d1d6bd11acfbdd748073931b7b8f63d698368\n'}, {'number': 5, 'created': '2022-09-22 01:28:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/loci/commit/3b60213769173b336333e440cf8bc218f33cd50b', 'message': 'Fix requirements build failures\n\nChange contains the following cleanup:\n  * remove build variable for cassandra-driver\n    - this is a whl in pypi for arm64 and aarch64 since Xena\n  * allow scipy packages\n    - these packages are whl in pypi for amd4 and aarch64 since Wallaby\n  * remove suds-jurko and anyjson\n    - these packages use 2to3 which is now removed\n  * remove python-nss\n    - this breaks with python3.10 and libnss>=3.58\n  * remove enum-compat\n    - this was a python2/3 compat lib. It is noop on python>=3.4\n  * readd python-qpid-proton\n    - this has pypi whls for amd64 and aarch64 since Victoria\n\nChange-Id: Id92d1d6bd11acfbdd748073931b7b8f63d698368\n'}, {'number': 6, 'created': '2022-11-06 17:53:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/loci/commit/4b31248d922ffb07934ddbdacb7eca145eb5d0a3', 'message': 'Fix requirements build failures\n\nChange contains the following cleanup:\n  * remove build variable for cassandra-driver\n    - this is a whl in pypi for arm64 and aarch64 since Xena\n  * allow scipy packages\n    - these packages are whl in pypi for amd4 and aarch64 since Wallaby\n  * remove suds-jurko and anyjson\n    - these packages use 2to3 which is now removed\n  * remove python-nss\n    - this breaks with python3.10 and libnss>=3.58\n  * remove enum-compat\n    - this was a python2/3 compat lib. It is noop on python>=3.4\n  * readd python-qpid-proton\n    - this has pypi whls for amd64 and aarch64 since Victoria\n\nChange-Id: Id92d1d6bd11acfbdd748073931b7b8f63d698368\n'}, {'number': 7, 'created': '2022-11-18 16:46:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/loci/commit/f1644e5328dc0b767d53056f696c273aae40c5da', 'message': 'Fix requirements build failures\n\nChange contains the following cleanup:\n  * remove build variable for cassandra-driver\n    - this is a whl in pypi for arm64 and aarch64 since Xena\n  * allow scipy packages\n    - these packages are whl in pypi for amd4 and aarch64 since Wallaby\n  * remove suds-jurko and anyjson\n    - these packages use 2to3 which is now removed\n  * remove python-nss\n    - this breaks with python3.10 and libnss>=3.58\n  * remove enum-compat\n    - this was a python2/3 compat lib. It is noop on python>=3.4\n  * readd python-qpid-proton\n    - this has pypi whls for amd64 and aarch64 since Victoria\n\nChange-Id: Id92d1d6bd11acfbdd748073931b7b8f63d698368\n'}, {'number': 8, 'created': '2022-11-19 19:44:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/loci/commit/4d14cbd458329736fae974840258f7f1c1e4bb43', 'message': 'Fix requirements build failures\n\nChange contains the following cleanup:\n  * remove build variable for cassandra-driver\n    - this is a whl in pypi for arm64 and aarch64 since Xena\n  * allow scipy packages\n    - these packages are whl in pypi for amd4 and aarch64 since Wallaby\n  * remove suds-jurko and anyjson\n    - these packages use 2to3 which is now removed\n  * remove python-nss\n    - this breaks with python3.10 and libnss>=3.58\n  * remove enum-compat\n    - this was a python2/3 compat lib. It is noop on python>=3.4\n  * readd python-qpid-proton\n    - this has pypi whls for amd64 and aarch64 since Victoria\n\nChange-Id: Id92d1d6bd11acfbdd748073931b7b8f63d698368\n'}, {'number': 9, 'created': '2022-11-22 22:19:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/loci/commit/06c6b8652875c88e06a8f265a711fd4185c29ea6', 'message': 'Fix requirements build failures\n\nChange contains the following cleanup:\n  * remove build variable for cassandra-driver\n    - this is a whl in pypi for arm64 and aarch64 since Xena\n  * allow scipy packages\n    - these packages are whl in pypi for amd4 and aarch64 since Wallaby\n  * remove suds-jurko and anyjson\n    - these packages use 2to3 which is now removed\n  * remove python-nss\n    - this breaks with python3.10 and libnss>=3.58\n  * remove enum-compat\n    - this was a python2/3 compat lib. It is noop on python>=3.4\n  * readd python-qpid-proton\n    - this has pypi whls for amd64 and aarch64 since Victoria\n\nChange-Id: Id92d1d6bd11acfbdd748073931b7b8f63d698368\n'}, {'number': 10, 'created': '2022-12-18 18:32:36.000000000', 'files': ['scripts/requirements.sh'], 'web_link': 'https://opendev.org/openstack/loci/commit/8beb554ad2a8c74ad24f66ddcb135ffcaa4bc5ba', 'message': 'Fix requirements build failures\n\nChange contains the following cleanup:\n  * remove build variable for cassandra-driver\n    - this is a whl in pypi for arm64 and aarch64 since Xena\n  * allow scipy packages\n    - these packages are whl in pypi for amd4 and aarch64 since Wallaby\n  * remove suds-jurko and anyjson\n    - these packages use 2to3 which is now removed\n  * remove python-nss\n    - this breaks with python3.10 and libnss>=3.58\n  * remove enum-compat\n    - this was a python2/3 compat lib. It is noop on python>=3.4\n  * readd python-qpid-proton\n    - this has pypi whls for amd64 and aarch64 since Victoria\n\nChange-Id: Id92d1d6bd11acfbdd748073931b7b8f63d698368\n'}]",1,858820,8beb554ad2a8c74ad24f66ddcb135ffcaa4bc5ba,22,2,10,14119,,,0,"Fix requirements build failures

Change contains the following cleanup:
  * remove build variable for cassandra-driver
    - this is a whl in pypi for arm64 and aarch64 since Xena
  * allow scipy packages
    - these packages are whl in pypi for amd4 and aarch64 since Wallaby
  * remove suds-jurko and anyjson
    - these packages use 2to3 which is now removed
  * remove python-nss
    - this breaks with python3.10 and libnss>=3.58
  * remove enum-compat
    - this was a python2/3 compat lib. It is noop on python>=3.4
  * readd python-qpid-proton
    - this has pypi whls for amd64 and aarch64 since Victoria

Change-Id: Id92d1d6bd11acfbdd748073931b7b8f63d698368
",git fetch https://review.opendev.org/openstack/loci refs/changes/20/858820/1 && git format-patch -1 --stdout FETCH_HEAD,['scripts/requirements.sh'],1,f3fe0197d7d88e01a703ca5e6341f3e8f111b173,dnm_all_fixes,"# Soften upper-constraints to match our expected build env # - suds-jurko===0.6 -- need version update: ERROR: use_2to3 is invalid # - anyjson===0.3.3 -- need version update: ERROR: use_2to3 is invalid # - python-nss===1.0.1 -- need version update: build broken with libnss>=3.58 # - futures -- futures has no effect on python3 # - setuptools -- setuptools should not constrained anymore sed -i \ -e '/suds-jurko===0.6/d' \ -e '/anyjson===0.3.3/d' \ -e '/python-nss===1.0.1/d' \ -e '/futures/d' \ -e '/setuptools/d' \ /upper-constraints.txt sed -i -e '/confluent-kafka/d' /upper-constraints.txtif [[ ! -z ""${PIP_PACKAGES}"" ]]; thenecho uwsgi ${PIP_PACKAGES} | xargs -n1 | split -l1 -a3","# TODO: Make python-qpid-proton build here (possibly patch it) # or remove when python-qpid-proton is updated with build fix. # https://issues.apache.org/jira/browse/PROTON-1381 if (( $(openssl version | awk -F'[ .]' '{print $3}') >= 1 )); then sed -i '/python-qpid-proton/d' /upper-constraints.txt fi # Remove python-qpid-proton 0.14.0 as this old version cannot be built in CI # anymore sed -i '/python-qpid-proton===0.14.0/d' /upper-constraints.txt # Setuptools from constraints is not compatible with other constrainted packages [[ ""${PROJECT_REF}"" == ""master"" ]] && sed -i '/setuptools/d' /upper-constraints.txt # https://review.opendev.org/c/openstack/requirements/+/813693 sed -i '/^futures===/d' /upper-constraints.txt sed -i '/confluent-kafka/d' /upper-constraints.txt fi # Remove any pylxd before 2.2.7 as the old versions cannot be built in CI. lxd_constraint=$(grep pylxd /upper-constraints.txt) # This removes (##) everything (*) from the lxd_constraint until the last =, # and removes all '.' to look like a number. if (( $(echo ${lxd_constraint##*=} | sed 's#\.##g') < 227 )); then sed -i '/pylxd/d' /upper-constraints.txtexport CASS_DRIVER_BUILD_CONCURRENCY=8 # Drop python packages requested by monasca_analytics. Their # build time is huge and on !x86 we do not get binaries from Pypi. egrep -v ""(scipy|scikit-learn)"" /upper-constraints.txt | split -l1 if [ ! -z ""${PIP_PACKAGES}"" ]; thenecho uwsgi enum-compat ${PIP_PACKAGES} | xargs -n1 | split -l1 -a3",16,32
openstack%2Floci~882275,openstack/loci,master,I5a084fd245a974f546fcebe0d104e4f0e0ded62b,Add ubuntu jammy base to dockerfiles,ABANDONED,2023-05-04 11:34:00.000000000,2023-07-12 23:08:20.000000000,,[{'_account_id': 22348}],"[{'number': 1, 'created': '2023-05-04 11:34:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/loci/commit/6482784c204195c67d98b7013feca365e796b578', 'message': 'Add ubuntu jammy base to dockerfiles\n\nThis change adds in the base for Ubuntu 22.04 Jammy release\nunder dockerfiles.\n\nChange-Id: I5a084fd245a974f546fcebe0d104e4f0e0ded62b\n'}, {'number': 2, 'created': '2023-05-04 13:10:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/loci/commit/5d776cb17d4934329d304ce402d7943b48b98ad3', 'message': 'Add ubuntu jammy base to dockerfiles\n\nThis change adds in the base for Ubuntu 22.04 Jammy release\nunder dockerfiles.\n\nChange-Id: I5a084fd245a974f546fcebe0d104e4f0e0ded62b\n'}, {'number': 3, 'created': '2023-05-04 16:39:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/loci/commit/ecb068c588c77cd4739858d45adb2dc7a4de43e9', 'message': 'Add ubuntu jammy base to dockerfiles\n\nThis change adds in the base for Ubuntu 22.04 Jammy release\nunder dockerfiles.\n\nChange-Id: I5a084fd245a974f546fcebe0d104e4f0e0ded62b\n'}, {'number': 4, 'created': '2023-05-04 19:30:03.000000000', 'files': ['dockerfiles/ubuntu_jammy/cloud-archive.gpg', 'dockerfiles/ubuntu_jammy/Dockerfile', 'playbooks/vars.yaml', 'dockerfiles/ubuntu_jammy/sources.list'], 'web_link': 'https://opendev.org/openstack/loci/commit/a96d73b4aac27c60ea2e1fab5878542da027d736', 'message': 'Add ubuntu jammy base to dockerfiles\n\nThis change adds in the base for Ubuntu 22.04 Jammy release\nunder dockerfiles.\n\nChange-Id: I5a084fd245a974f546fcebe0d104e4f0e0ded62b\n'}]",1,882275,a96d73b4aac27c60ea2e1fab5878542da027d736,11,1,4,9373,,,0,"Add ubuntu jammy base to dockerfiles

This change adds in the base for Ubuntu 22.04 Jammy release
under dockerfiles.

Change-Id: I5a084fd245a974f546fcebe0d104e4f0e0ded62b
",git fetch https://review.opendev.org/openstack/loci refs/changes/75/882275/1 && git format-patch -1 --stdout FETCH_HEAD,"['dockerfiles/ubuntu_jammy/ceph.gpg', 'dockerfiles/ubuntu_jammy/cloud-archive.gpg', 'dockerfiles/ubuntu_jammy/Dockerfile', 'playbooks/vars.yaml', 'dockerfiles/ubuntu_jammy/sources.list']",5,6482784c204195c67d98b7013feca365e796b578,ubuntu_jammy,deb %%UBUNTU_URL%% jammy main universe deb %%UBUNTU_URL%% jammy-updates main universe deb %%UBUNTU_URL%% jammy-backports main universe deb %%UBUNTU_URL%% jammy-security main universe deb %%CEPH_URL%% focal main deb %%CLOUD_ARCHIVE_URL%% jammy-updates/yoga main ,,49,0
openstack%2Floci~858831,openstack/loci,master,I0cd3ef78415688dffb5e06cdf2d363412becc5f1,Redo venv setup,ABANDONED,2022-09-21 22:31:53.000000000,2023-07-12 23:08:20.000000000,,"[{'_account_id': 8898}, {'_account_id': 22348}]","[{'number': 1, 'created': '2022-09-21 22:31:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/loci/commit/80a57d587993f0df32520e837f32a75c06cb2163', 'message': 'Redo venv setup\n\nInstalling `virtualenv` also pulls in all the build tooling (including a\ncompiler). We can use venv with `--upgrade-deps` to download the latest\npip and setuptools, quickly followed by wheel which we leverage heavily.\n\nAdditionally, using `--symlinks` we ensure we dont copy the python3\nbinary and the venv points directly to the host. No PIP_BOOTSTRAP\nanymore.\n\nThe `--upgrade-deps` option is only available in python>=3.9\n\nChange-Id: I0cd3ef78415688dffb5e06cdf2d363412becc5f1\n'}, {'number': 2, 'created': '2022-09-21 22:57:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/loci/commit/0b3d6199b8cd2c8ace7dc5904def443bb49a1e30', 'message': 'Redo venv setup\n\nInstalling `virtualenv` also pulls in all the build tooling (including a\ncompiler). We can use venv with `--upgrade-deps` to download the latest\npip and setuptools, quickly followed by wheel which we leverage heavily.\n\nAdditionally, using `--symlinks` we ensure we dont copy the python3\nbinary and the venv points directly to the host. No PIP_BOOTSTRAP\nanymore.\n\nThe `--upgrade-deps` option is only available in python>=3.9\n\nChange-Id: I0cd3ef78415688dffb5e06cdf2d363412becc5f1\n'}, {'number': 3, 'created': '2022-09-21 23:20:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/loci/commit/42a58623f6ebf09085e35a939cba68b065a81971', 'message': 'Redo venv setup\n\nInstalling `virtualenv` also pulls in all the build tooling (including a\ncompiler). We can use venv with `--upgrade-deps` to download the latest\npip and setuptools, quickly followed by wheel which we leverage heavily.\n\nAdditionally, using `--symlinks` we ensure we dont copy the python3\nbinary and the venv points directly to the host. No PIP_BOOTSTRAP\nanymore.\n\nThe `--upgrade-deps` option is only available in python>=3.9\n\nChange-Id: I0cd3ef78415688dffb5e06cdf2d363412becc5f1\n'}, {'number': 4, 'created': '2022-09-21 23:30:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/loci/commit/aca325bd09e4ca51fff1d6bde7d2c08a09dcdfe2', 'message': 'Redo venv setup\n\nInstalling `virtualenv` also pulls in all the build tooling (including a\ncompiler). We can use venv with `--upgrade-deps` to download the latest\npip and setuptools, quickly followed by wheel which we leverage heavily.\n\nAdditionally, using `--symlinks` we ensure we dont copy the python3\nbinary and the venv points directly to the host. No PIP_BOOTSTRAP\nanymore.\n\nThe `--upgrade-deps` option is only available in python>=3.9\n\nChange-Id: I0cd3ef78415688dffb5e06cdf2d363412becc5f1\n'}, {'number': 5, 'created': '2022-09-22 01:28:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/loci/commit/c86383e0a504f0d635e58e10c1494b06b3891e0e', 'message': 'Redo venv setup\n\nInstalling `virtualenv` also pulls in all the build tooling (including a\ncompiler). We can use venv with `--upgrade-deps` to download the latest\npip and setuptools, quickly followed by wheel which we leverage heavily.\n\nAdditionally, using `--symlinks` we ensure we dont copy the python3\nbinary and the venv points directly to the host. No PIP_BOOTSTRAP\nanymore.\n\nThe `--upgrade-deps` option is only available in python>=3.9\n\nChange-Id: I0cd3ef78415688dffb5e06cdf2d363412becc5f1\n'}, {'number': 6, 'created': '2022-11-06 17:53:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/loci/commit/0716d67e57c8500fa4b78d98c2be5157eb60a460', 'message': 'Redo venv setup\n\nInstalling `virtualenv` also pulls in all the build tooling (including a\ncompiler). We can use venv with `--upgrade-deps` to download the latest\npip and setuptools, quickly followed by wheel which we leverage heavily.\n\nAdditionally, using `--symlinks` we ensure we dont copy the python3\nbinary and the venv points directly to the host. No PIP_BOOTSTRAP\nanymore.\n\nThe `--upgrade-deps` option is only available in python>=3.9\n\nChange-Id: I0cd3ef78415688dffb5e06cdf2d363412becc5f1\n'}, {'number': 7, 'created': '2022-11-18 16:47:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/loci/commit/f8c50fb22b0f4bd3e0e54b7c1066bbb841b1e20a', 'message': 'Redo venv setup\n\nInstalling `virtualenv` also pulls in all the build tooling (including a\ncompiler). We can use venv with `--upgrade-deps` to download the latest\npip and setuptools, quickly followed by wheel which we leverage heavily.\n\nAdditionally, using `--symlinks` we ensure we dont copy the python3\nbinary and the venv points directly to the host. No PIP_BOOTSTRAP\nanymore.\n\nThe `--upgrade-deps` option is only available in python>=3.9\n\nChange-Id: I0cd3ef78415688dffb5e06cdf2d363412becc5f1\n'}, {'number': 8, 'created': '2022-11-22 22:19:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/loci/commit/e2934a55092e8e739eccb9c7324d9044987a93f0', 'message': 'Redo venv setup\n\nInstalling `virtualenv` also pulls in all the build tooling (including a\ncompiler). We can use venv with `--upgrade-deps` to download the latest\npip and setuptools, quickly followed by wheel which we leverage heavily.\n\nAdditionally, using `--symlinks` we ensure we dont copy the python3\nbinary and the venv points directly to the host. No PIP_BOOTSTRAP\nanymore.\n\nThe `--upgrade-deps` option is only available in python>=3.9\n\nChange-Id: I0cd3ef78415688dffb5e06cdf2d363412becc5f1\n'}, {'number': 9, 'created': '2022-12-18 18:32:49.000000000', 'files': ['scripts/install.sh', 'scripts/setup_pip.sh'], 'web_link': 'https://opendev.org/openstack/loci/commit/ad82c9eab2705afb5587f6325dc8bf59a20fff81', 'message': 'Redo venv setup\n\nInstalling `virtualenv` also pulls in all the build tooling (including a\ncompiler). We can use venv with `--upgrade-deps` to download the latest\npip and setuptools, quickly followed by wheel which we leverage heavily.\n\nAdditionally, using `--symlinks` we ensure we dont copy the python3\nbinary and the venv points directly to the host. No PIP_BOOTSTRAP\nanymore.\n\nThe `--upgrade-deps` option is only available in python>=3.9\n\nChange-Id: I0cd3ef78415688dffb5e06cdf2d363412becc5f1\n'}]",0,858831,ad82c9eab2705afb5587f6325dc8bf59a20fff81,19,2,9,14119,,,0,"Redo venv setup

Installing `virtualenv` also pulls in all the build tooling (including a
compiler). We can use venv with `--upgrade-deps` to download the latest
pip and setuptools, quickly followed by wheel which we leverage heavily.

Additionally, using `--symlinks` we ensure we dont copy the python3
binary and the venv points directly to the host. No PIP_BOOTSTRAP
anymore.

The `--upgrade-deps` option is only available in python>=3.9

Change-Id: I0cd3ef78415688dffb5e06cdf2d363412becc5f1
",git fetch https://review.opendev.org/openstack/loci refs/changes/31/858831/1 && git format-patch -1 --stdout FETCH_HEAD,"['scripts/install.sh', 'scripts/setup_pip.sh']",2,80a57d587993f0df32520e837f32a75c06cb2163,dnm_all_fixes,"VENV_SETUP_OPTS=""--symlinks"" if [[ ""$(python3 -c 'import sys; print(sys.version_info.minor);')"" -ge 9 ]]; then VENV_SETUP_OPTS=""${VENV_SETUP_OPTS} --upgrade-deps""python3 -m venv ${VENV_SETUP_OPTS} /var/lib/openstackhash -r # If python>=3.9 then we already have the latest pip and setuptools, not wheel pip install --upgrade ${PIP_ARGS} pip setuptools wheel"," if [[ ""${PYTHON3}"" == ""no"" ]]; then TMP_VIRTUALENV=""virtualenv"" else TMP_VIRTUALENV=""python3 -m virtualenv --python=python3""# This little dance allows us to install the latest pip # without get_pip.py or the python-pip package (in epel on centos) if (( $(${TMP_VIRTUALENV} --version | grep -Po '[0-9]+\.[0-9]+\.[0-9]+' | cut -d. -f1) >= 14 )); then SETUPTOOLS=""--no-setuptools"" fi if (( $(${TMP_VIRTUALENV} --version | grep -Po '[0-9]+\.[0-9]+\.[0-9]+' | cut -d. -f1) >= 20 )); then SETUPTOOLS=""--seed pip --download"" fi # virtualenv 16.4.0 fixed symlink handling. The interaction of the new # corrected behavior with legacy bugs in packaged virtualenv releases in # distributions means we need to hold on to the pip bootstrap installation # chain to preserve symlinks. As distributions upgrade their default # installations we may not need this workaround in the future PIPBOOTSTRAP=/var/lib/pipbootstrap # Create the boostrap environment so we can get pip from virtualenv ${TMP_VIRTUALENV} ${SETUPTOOLS} ${PIPBOOTSTRAP} source ${PIPBOOTSTRAP}/bin/activate # Install setuptools explicitly required for virtualenv > 20 installation pip install --upgrade setuptools # Upgrade to the latest version of virtualenv pip install --upgrade ${PIP_ARGS} virtualenv==20.7.2 # Forget the cached locations of python binaries hash -r # Create the virtualenv with the updated toolchain for openstack service virtualenv --seed pip --download /var/lib/openstack # Deactivate the old bootstrap virtualenv and switch to the new one deactivate",11,46
openstack%2Fopenstack-helm-infra~883789,openstack/openstack-helm-infra,master,Ic0057793992c90881b276d3b77657eaa2425f76c,Add openEuler 22.03 LTS support,ABANDONED,2023-05-22 06:27:39.000000000,2023-07-12 23:08:19.000000000,,[{'_account_id': 22348}],"[{'number': 1, 'created': '2023-05-22 06:27:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/40686c692e5cbcac02f1de054406a07887573ac2', 'message': 'openEuler 22.03 LTS  support\n\nopenEuler is an open-source Linux based operating system. The current\nopenEuler kernel is based on Linux and supports multi arch, such as X86_64\nand aarch64. It fully unleashes the potential of computing chips. As an\nefficient, stable, and secure open-source OS built by global open-source\ncontributors, openEuler applies to database, big data, cloud computing,\nand AI scenarios. openEuler is using RPM for package management.\n\nChange-Id: Ic0057793992c90881b276d3b77657eaa2425f76c\n'}, {'number': 2, 'created': '2023-05-22 06:37:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/02b9147d040465dfc61d7d2bd1c099557f5060d2', 'message': 'openEuler 22.03 LTS  support\n\nopenEuler is an open-source Linux based operating system. The current\nopenEuler kernel is based on Linux and supports multi arch, such as X86_64\nand aarch64. It fully unleashes the potential of computing chips. As an\nefficient, stable, and secure open-source OS built by global open-source\ncontributors, openEuler applies to database, big data, cloud computing,\nand AI scenarios. openEuler is using RPM for package management.\n\nChange-Id: Ic0057793992c90881b276d3b77657eaa2425f76c\n'}, {'number': 3, 'created': '2023-05-22 07:17:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/1b2a1169302a33f36180452a0abdd6f4d25e6b19', 'message': 'openEuler 22.03 LTS  support\n\nopenEuler is an open-source Linux based operating system. The current\nopenEuler kernel is based on Linux and supports multi arch, such as X86_64\nand aarch64. It fully unleashes the potential of computing chips. As an\nefficient, stable, and secure open-source OS built by global open-source\ncontributors, openEuler applies to database, big data, cloud computing,\nand AI scenarios. openEuler is using RPM for package management.\n\nChange-Id: Ic0057793992c90881b276d3b77657eaa2425f76c\n'}, {'number': 4, 'created': '2023-05-22 07:37:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/db05fafeea2fbc6b7a9e5938355b526fef30db69', 'message': 'openEuler 22.03 LTS  support\n\nopenEuler is an open-source Linux based operating system. The current\nopenEuler kernel is based on Linux and supports multi arch, such as X86_64\nand aarch64. It fully unleashes the potential of computing chips. As an\nefficient, stable, and secure open-source OS built by global open-source\ncontributors, openEuler applies to database, big data, cloud computing,\nand AI scenarios. openEuler is using RPM for package management.\n\nChange-Id: Ic0057793992c90881b276d3b77657eaa2425f76c\n'}, {'number': 5, 'created': '2023-05-22 07:56:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/ac83f6a016ff243004d10731d62094da487f5606', 'message': 'openEuler 22.03 LTS  support\n\nopenEuler is an open-source Linux based operating system. The current\nopenEuler kernel is based on Linux and supports multi arch, such as X86_64\nand aarch64. It fully unleashes the potential of computing chips. As an\nefficient, stable, and secure open-source OS built by global open-source\ncontributors, openEuler applies to database, big data, cloud computing,\nand AI scenarios. openEuler is using RPM for package management.\n\nChange-Id: Ic0057793992c90881b276d3b77657eaa2425f76c\n'}, {'number': 6, 'created': '2023-05-22 08:19:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/bbf6ef4332ee8b64eee37cbc2af84cb4969e09db', 'message': 'openEuler 22.03 LTS  support\n\nopenEuler is an open-source Linux based operating system. The current\nopenEuler kernel is based on Linux and supports multi arch, such as X86_64\nand aarch64. It fully unleashes the potential of computing chips. As an\nefficient, stable, and secure open-source OS built by global open-source\ncontributors, openEuler applies to database, big data, cloud computing,\nand AI scenarios. openEuler is using RPM for package management.\n\nChange-Id: Ic0057793992c90881b276d3b77657eaa2425f76c\n'}, {'number': 7, 'created': '2023-05-22 08:35:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/3b8f55efb3d87b5c15c61c0fd4b64388c7d176f3', 'message': 'openEuler 22.03 LTS  support\n\nopenEuler is an open-source Linux based operating system. The current\nopenEuler kernel is based on Linux and supports multi arch, such as X86_64\nand aarch64. It fully unleashes the potential of computing chips. As an\nefficient, stable, and secure open-source OS built by global open-source\ncontributors, openEuler applies to database, big data, cloud computing,\nand AI scenarios. openEuler is using RPM for package management.\n\nChange-Id: Ic0057793992c90881b276d3b77657eaa2425f76c\n'}, {'number': 8, 'created': '2023-05-22 09:27:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/66dcbd5b0b7bc64e3b023b6b19474b8c1b578db1', 'message': 'openEuler 22.03 LTS  support\n\nopenEuler is an open-source Linux based operating system. The current\nopenEuler kernel is based on Linux and supports multi arch, such as X86_64\nand aarch64. It fully unleashes the potential of computing chips. As an\nefficient, stable, and secure open-source OS built by global open-source\ncontributors, openEuler applies to database, big data, cloud computing,\nand AI scenarios. openEuler is using RPM for package management.\n\nChange-Id: Ic0057793992c90881b276d3b77657eaa2425f76c\n'}, {'number': 9, 'created': '2023-05-22 10:05:52.000000000', 'files': ['ceph-osd/values.yaml', 'tools/gate/deploy-k8s.sh', 'tools/gate/devel/start.sh', 'tools/gate/deploy-k8s-kubeadm.sh', 'zuul.d/project.yaml', 'tools/deployment/common/000-install-packages.sh', 'zuul.d/nodesets.yaml', 'zuul.d/jobs.yaml'], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/6b5263823bc92b6342b71799c583a909cb6eab34', 'message': 'Add openEuler 22.03 LTS support\n\nopenEuler is an open-source Linux based operating system. The current\nopenEuler kernel is based on Linux and supports multi arch, such as\nX86_64 and aarch64. It fully unleashes the potential of computing chips.\nAs an efficient, stable, and secure open-source OS built by global\nopen-source contributors, openEuler applies to database, big data, cloud\ncomputing, and AI scenarios. openEuler is using RPM for package\nmanagement.\n\nThis Patch add the openEuler distro support. And add the related\nCI job to make sure its works well.\n\nWebsite: https://www.openeuler.org/en/\n\nChange-Id: Ic0057793992c90881b276d3b77657eaa2425f76c\n'}]",1,883789,6b5263823bc92b6342b71799c583a909cb6eab34,12,1,9,36021,,,0,"Add openEuler 22.03 LTS support

openEuler is an open-source Linux based operating system. The current
openEuler kernel is based on Linux and supports multi arch, such as
X86_64 and aarch64. It fully unleashes the potential of computing chips.
As an efficient, stable, and secure open-source OS built by global
open-source contributors, openEuler applies to database, big data, cloud
computing, and AI scenarios. openEuler is using RPM for package
management.

This Patch add the openEuler distro support. And add the related
CI job to make sure its works well.

Website: https://www.openeuler.org/en/

Change-Id: Ic0057793992c90881b276d3b77657eaa2425f76c
",git fetch https://review.opendev.org/openstack/openstack-helm-infra refs/changes/89/883789/1 && git format-patch -1 --stdout FETCH_HEAD,"['ceph-osd/values.yaml', 'tools/gate/deploy-k8s.sh', 'tools/gate/devel/start.sh', 'tools/gate/deploy-k8s-kubeadm.sh', 'zuul.d/project.yaml', 'tools/deployment/common/000-install-packages.sh', 'zuul.d/nodesets.yaml', 'zuul.d/jobs.yaml']",8,40686c692e5cbcac02f1de054406a07887573ac2,, name: openstack-helm-lint run: playbooks/lint.yml nodeset: openeuler-22.03-lts # NOTE(aostapenko) Required if job is run against another project required-projects: - openstack/openstack-helm-infra irrelevant-files: - ^.*\.rst$ - ^doc/.*$ - ^releasenotes/.*$ - job: name: openstack-helm-infra-deploy-openeuler parent: openstack-helm-infra-functional timeout: 7200 roles: - zuul: zuul/zuul-jobs pre-run: playbooks/osh-infra-upgrade-host.yaml post-run: playbooks/osh-infra-collect-logs.yaml nodeset: openstack-helm-single-node-openeuler vars: osh_params: openstack_release: xena container_distro_name: ubuntu container_distro_version: focal gate_scripts_relative_path: ../openstack-helm-infra gate_scripts: - ./tools/deployment/common/000-install-packages.sh - ./tools/gate/deploy-k8s.sh - job:,,313,82
openstack%2Fopenstack-helm-images~880015,openstack/openstack-helm-images,master,I75ed446549e2cfbde149f7f85a52051dfeff6ffc,Jammy Overrides and ubuntu-bionic-dpdk Fixes bionic build as well,ABANDONED,2023-04-11 05:18:14.000000000,2023-07-12 23:08:19.000000000,,"[{'_account_id': 3009}, {'_account_id': 22348}]","[{'number': 1, 'created': '2023-04-11 05:18:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-images/commit/a03ccae9e56446d8ce87b4e9612235479207298b', 'message': 'Jammy Overrides and ubuntu-bionic-dpdk\n\nChange-Id: I75ed446549e2cfbde149f7f85a52051dfeff6ffc\n'}, {'number': 2, 'created': '2023-04-12 22:57:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-images/commit/41965cf8d7697ff233a96815611e57705097dba4', 'message': 'Jammy Overrides and ubuntu-bionic-dpdk\n\nChange-Id: I75ed446549e2cfbde149f7f85a52051dfeff6ffc\n'}, {'number': 3, 'created': '2023-04-12 23:35:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-images/commit/befc5b5cf2cadee0ea5d07d9288c8d7e81c1a98d', 'message': 'Jammy Overrides and ubuntu-bionic-dpdk\n\nChange-Id: I75ed446549e2cfbde149f7f85a52051dfeff6ffc\n'}, {'number': 4, 'created': '2023-05-03 06:38:34.000000000', 'files': ['libvirt/ubuntu-install-libvirt-jammy-override.sh', 'openvswitch/Dockerfile.ubuntu_bionic-dpdk', 'libvirt/Dockerfile.ubuntu_jammy', 'openvswitch/Dockerfile.ubuntu_focal-dpdk', 'zuul.d/openvswitch.yaml'], 'web_link': 'https://opendev.org/openstack/openstack-helm-images/commit/7e20cd721bdc6d22888b95cea8466729ef155934', 'message': 'Jammy Overrides and ubuntu-bionic-dpdk\nFixes bionic build as well\n\nChange-Id: I75ed446549e2cfbde149f7f85a52051dfeff6ffc\n'}]",8,880015,7e20cd721bdc6d22888b95cea8466729ef155934,17,2,4,33330,,,0,"Jammy Overrides and ubuntu-bionic-dpdk
Fixes bionic build as well

Change-Id: I75ed446549e2cfbde149f7f85a52051dfeff6ffc
",git fetch https://review.opendev.org/openstack/openstack-helm-images refs/changes/15/880015/1 && git format-patch -1 --stdout FETCH_HEAD,"['libvirt/ubuntu-install-libvirt-jammy-override.sh', 'openvswitch/Dockerfile.ubuntu_bionic-dpdk', 'libvirt/Dockerfile.ubuntu_jammy']",3,a03ccae9e56446d8ce87b4e9612235479207298b,,"ARG FROM=docker.io/ubuntu:jammy FROM ${FROM} LABEL maintainer=""kkloppenborg@rwts.com.au"" ARG UBUNTU_RELEASE=jammy ARG CEPH_RELEASE=pacific ARG CEPH_RELEASE_TAG="""" ARG PROJECT=nova ARG UID=42424 ARG GID=42424 ARG CEPH_REPO=http://download.ceph.com/debian-${CEPH_RELEASE}/ ARG CEPH_KEY=http://download.ceph.com/keys/release.asc ADD ${CEPH_KEY} /etc/apt/ceph-${CEPH_RELEASE}.key COPY ./ubuntu-install-libvirt-jammy-override.sh /tmp/ubuntu-install-libvirt.sh RUN set -ex ;\ export DEBIAN_FRONTEND=noninteractive ;\ apt-get update ;\ apt-get install --no-install-recommends -y \ apt-transport-https \ ca-certificates \ gnupg ;\ /tmp/ubuntu-install-libvirt.sh ;\ rm -rf /tmp/* ",,66,3
openstack%2Frequirements~888145,openstack/requirements,master,I2a52c853b2f90d92d954bd99b914eccbbd0ae91c,update constraint for horizon to new release 23.2.0,MERGED,2023-07-11 17:06:56.000000000,2023-07-12 22:38:08.000000000,2023-07-12 22:37:14.000000000,"[{'_account_id': 11904}, {'_account_id': 14288}, {'_account_id': 22348}, {'_account_id': 29313}]","[{'number': 1, 'created': '2023-07-11 17:06:56.000000000', 'files': ['upper-constraints.txt'], 'web_link': 'https://opendev.org/openstack/requirements/commit/665481bbadd6b586a593d93e9bc223b369427923', 'message': 'update constraint for horizon to new release 23.2.0\n\nmeta: version: 23.2.0\nmeta: diff-start: -\nmeta: series: bobcat\nmeta: branch: master\nmeta: release-type: release\nmeta: pypi: no\nmeta: first: yes\nmeta: release:Author: manchandavishal <manchandavishal143@gmail.com>\nmeta: release:Commit: manchandavishal <manchandavishal143@gmail.com>\nmeta: release:Change-Id: I5ce388ff43e4ee951e56a2461cc1a959dde64426\nmeta: release:Code-Review+2: Elod Illes <elod.illes@est.tech>\nmeta: release:Code-Review+2: Hervé Beraud <herveberaud.pro@gmail.com>\nmeta: release:Workflow+1: Hervé Beraud <herveberaud.pro@gmail.com>\nChange-Id: I2a52c853b2f90d92d954bd99b914eccbbd0ae91c\n'}]",6,888145,665481bbadd6b586a593d93e9bc223b369427923,20,4,1,11131,,,0,"update constraint for horizon to new release 23.2.0

meta: version: 23.2.0
meta: diff-start: -
meta: series: bobcat
meta: branch: master
meta: release-type: release
meta: pypi: no
meta: first: yes
meta: release:Author: manchandavishal <manchandavishal143@gmail.com>
meta: release:Commit: manchandavishal <manchandavishal143@gmail.com>
meta: release:Change-Id: I5ce388ff43e4ee951e56a2461cc1a959dde64426
meta: release:Code-Review+2: Elod Illes <elod.illes@est.tech>
meta: release:Code-Review+2: Hervé Beraud <herveberaud.pro@gmail.com>
meta: release:Workflow+1: Hervé Beraud <herveberaud.pro@gmail.com>
Change-Id: I2a52c853b2f90d92d954bd99b914eccbbd0ae91c
",git fetch https://review.opendev.org/openstack/requirements refs/changes/45/888145/1 && git format-patch -1 --stdout FETCH_HEAD,['upper-constraints.txt'],1,665481bbadd6b586a593d93e9bc223b369427923,new-release,horizon===23.2.0,horizon===23.1.0,1,1
openstack%2Floci~888351,openstack/loci,master,I5211aac7b6a3bbc1f1b74e8662170dc8932525f9,Fix building python-nss on Ubuntu Jammy,MERGED,2023-07-12 19:27:59.000000000,2023-07-12 22:13:53.000000000,2023-07-12 22:13:53.000000000,"[{'_account_id': 22348}, {'_account_id': 33330}]","[{'number': 1, 'created': '2023-07-12 19:27:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/loci/commit/4d6f09506d9b5624e420d05fedef952930ab469b', 'message': 'Fix building python-nss on Ubuntu Jammy\n\nThe libnss3 headers in Ubuntu Jammy are compatible\nwith python-nss===1.0.1. Ubuntu Jammy itself\nprovides the binary package python-nss and\nthey apply the patch that renames RSAPublicKey/DSAPublicKey\ntypes into PyRSAPublicKey/PyDSAPublicKey.\n\nThis change applies the same patch before\nbuilding python-nss wheel.\n\nChange-Id: I5211aac7b6a3bbc1f1b74e8662170dc8932525f9\n'}, {'number': 2, 'created': '2023-07-12 19:45:30.000000000', 'files': ['scripts/python-nss-1.0.1-fix-ftbfs.diff', 'scripts/requirements.sh'], 'web_link': 'https://opendev.org/openstack/loci/commit/ce9fea8fe62180dab0a778dfcc4c89116a945be5', 'message': 'Fix building python-nss on Ubuntu Jammy\n\nThe libnss3 headers in Ubuntu Jammy are compatible\nwith python-nss===1.0.1. Ubuntu Jammy itself\nprovides the binary package python-nss and\nthey apply the patch that renames RSAPublicKey/DSAPublicKey\ntypes into PyRSAPublicKey/PyDSAPublicKey.\n\nThis change applies the same patch before\nbuilding python-nss wheel.\n\nChange-Id: I5211aac7b6a3bbc1f1b74e8662170dc8932525f9\n'}]",2,888351,ce9fea8fe62180dab0a778dfcc4c89116a945be5,8,2,2,3009,,,0,"Fix building python-nss on Ubuntu Jammy

The libnss3 headers in Ubuntu Jammy are compatible
with python-nss===1.0.1. Ubuntu Jammy itself
provides the binary package python-nss and
they apply the patch that renames RSAPublicKey/DSAPublicKey
types into PyRSAPublicKey/PyDSAPublicKey.

This change applies the same patch before
building python-nss wheel.

Change-Id: I5211aac7b6a3bbc1f1b74e8662170dc8932525f9
",git fetch https://review.opendev.org/openstack/loci refs/changes/51/888351/1 && git format-patch -1 --stdout FETCH_HEAD,"['scripts/python-nss-1.0.1-fix-ftbfs.diff', 'scripts/requirements.sh']",2,4d6f09506d9b5624e420d05fedef952930ab469b,,"if [[ ${distro} == ""ubuntu"" ]] && [[ ${distro_version} == ""jammy"" ]] && grep -q ""python-nss===1.0.1"" /upper-constraints.txt; then sed -i '/python-nss/d' /upper-constraints.txt pip download python-nss===1.0.1 tar jxf python-nss-1.0.1.tar.bz2 && rm -f python-nss-1.0.1.tar.bz2 pushd python-nss-1.0.1 patch -p1 < $(dirname $0)/python-nss-1.0.1-fix-ftbfs.diff pip wheel ${PIP_WHEEL_ARGS} --find-links /source-wheels -c /upper-constraints.txt . && mv *.whl / || echo ""python-nss===1.0.1"" >> /failure popd && rm -r python-nss-1.0.1 fi ",,559,0
openstack%2Fnova~883014,openstack/nova,stable/xena,Icbf3bdd944f9a6c38f25ddea0b521ca48ee87a7f,Remove deleted projects from flavor access list,MERGED,2023-05-12 09:48:54.000000000,2023-07-12 21:59:24.000000000,2023-07-12 21:58:28.000000000,"[{'_account_id': 4393}, {'_account_id': 4690}, {'_account_id': 7166}, {'_account_id': 9708}, {'_account_id': 11604}, {'_account_id': 17685}, {'_account_id': 22348}, {'_account_id': 34860}]","[{'number': 1, 'created': '2023-05-12 09:48:54.000000000', 'files': ['nova/api/openstack/compute/flavor_access.py', 'nova/tests/unit/api/openstack/compute/test_flavor_access.py', 'nova/api/openstack/identity.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/61c14bd332b7a2e4ee1aa85226065b9c7a8f8a7e', 'message': ""Remove deleted projects from flavor access list\n\nPreviously Nova was unable to remove deleted projects from flavor's\naccess lists. This patch lifts described limitation and improves\nlogic of nova/api/openstack/identity.py library by introducing two\nseparate kinds of exceptions:\n\n- webob.exc.HTTPInternalServerError is raised when Keystone identity\n  service version 3.0 was not found.\n- webob.exc.HTTPBadRequest is raised when specified project is not\n  found.\n\nCloses-bug: #1980845\nChange-Id: Icbf3bdd944f9a6c38f25ddea0b521ca48ee87a7f\n(cherry picked from commit 8c6daaacbedc33e738ce85aec0ead5f6947d60bf)\n(cherry picked from commit 2ea2b556da5f10d662641bd96b0a07735d2b9607)\n(cherry picked from commit 6c1b862274546a32a43e1184f24101ebb6c30680)\n""}]",5,883014,61c14bd332b7a2e4ee1aa85226065b9c7a8f8a7e,22,8,1,19234,,,0,"Remove deleted projects from flavor access list

Previously Nova was unable to remove deleted projects from flavor's
access lists. This patch lifts described limitation and improves
logic of nova/api/openstack/identity.py library by introducing two
separate kinds of exceptions:

- webob.exc.HTTPInternalServerError is raised when Keystone identity
  service version 3.0 was not found.
- webob.exc.HTTPBadRequest is raised when specified project is not
  found.

Closes-bug: #1980845
Change-Id: Icbf3bdd944f9a6c38f25ddea0b521ca48ee87a7f
(cherry picked from commit 8c6daaacbedc33e738ce85aec0ead5f6947d60bf)
(cherry picked from commit 2ea2b556da5f10d662641bd96b0a07735d2b9607)
(cherry picked from commit 6c1b862274546a32a43e1184f24101ebb6c30680)
",git fetch https://review.opendev.org/openstack/nova refs/changes/14/883014/1 && git format-patch -1 --stdout FETCH_HEAD,"['nova/api/openstack/compute/flavor_access.py', 'nova/tests/unit/api/openstack/compute/test_flavor_access.py', 'nova/api/openstack/identity.py']",3,61c14bd332b7a2e4ee1aa85226065b9c7a8f8a7e,bug/1980845," an HTTPBadRequest is emitted. Also HTTPBadRequest is emitted if Keystone identity service version 3.0 is not found. ""Keystone identity service version 3.0 was not found. This "" ""might be caused by Nova misconfiguration or Keystone "" ""problems."") msg = _(""Nova was unable to find Keystone service endpoint."") # TODO(astupnik). It may be reasonable to switch to HTTP 503 # (HTTP Service Unavailable) instead of HTTP Bad Request here. # If proper Keystone servie is inaccessible, then technially # this is a server side error and not an error in Nova. raise webob.exc.HTTPBadRequest(explanation=msg) msg = _(""Project ID %s is not a valid project."") % project_id raise webob.exc.HTTPBadRequest(explanation=msg)"," an HTTPBadRequest is emitted. failure = webob.exc.HTTPBadRequest( explanation=_(""Project ID %s is not a valid project."") % project_id) ""Keystone identity service version 3.0 was not found. This might "" ""be because your endpoint points to the v2.0 versioned endpoint "" ""which is not supported. Please fix this."") raise failure raise failure",45,11
openstack%2Fkeystone~874844,openstack/keystone,stable/wallaby,I59ebf0fa77391d49b2349e918fc55f96318c42a6,[PooledLDAPHandler] Ensure result3() invokes message.clean(),MERGED,2023-02-24 07:11:38.000000000,2023-07-12 21:31:46.000000000,2023-07-12 21:30:33.000000000,"[{'_account_id': 7973}, {'_account_id': 14250}, {'_account_id': 22348}]","[{'number': 1, 'created': '2023-02-24 07:11:38.000000000', 'files': ['keystone/tests/unit/test_backend_ldap_pool.py', 'keystone/identity/backends/ldap/common.py', 'keystone/tests/unit/fakeldap.py'], 'web_link': 'https://opendev.org/openstack/keystone/commit/ec0ad6913307668e84b917bb8c2d8ac732006fab', 'message': '[PooledLDAPHandler] Ensure result3() invokes message.clean()\n\nresult3 does not invoke message.clean() when an exception is thrown\nby `message.connection.result3()` call, causing pool connection\nassociated with the message to be marked active forever. This causes\na denial-of-service on ldappool.\n\nThe fix ensures message.clean() is invoked by wrapping the offending\ncall in try-except-finally and putting the message.clean() in finally\nblock.\n\nCloses-Bug: #1998789\n\nChange-Id: I59ebf0fa77391d49b2349e918fc55f96318c42a6\nSigned-off-by: Mustafa Kemal Gilor <mustafa.gilor@canonical.com>\n(cherry picked from commit ff632a81fb09e6d9f3298e494d53eb6df50269cf)\n'}]",5,874844,ec0ad6913307668e84b917bb8c2d8ac732006fab,24,3,1,34980,,,0,"[PooledLDAPHandler] Ensure result3() invokes message.clean()

result3 does not invoke message.clean() when an exception is thrown
by `message.connection.result3()` call, causing pool connection
associated with the message to be marked active forever. This causes
a denial-of-service on ldappool.

The fix ensures message.clean() is invoked by wrapping the offending
call in try-except-finally and putting the message.clean() in finally
block.

Closes-Bug: #1998789

Change-Id: I59ebf0fa77391d49b2349e918fc55f96318c42a6
Signed-off-by: Mustafa Kemal Gilor <mustafa.gilor@canonical.com>
(cherry picked from commit ff632a81fb09e6d9f3298e494d53eb6df50269cf)
",git fetch https://review.opendev.org/openstack/keystone refs/changes/44/874844/1 && git format-patch -1 --stdout FETCH_HEAD,"['keystone/tests/unit/test_backend_ldap_pool.py', 'keystone/identity/backends/ldap/common.py', 'keystone/tests/unit/fakeldap.py']",3,ec0ad6913307668e84b917bb8c2d8ac732006fab,, self.connected = True self.who = who self.cred = cred self.connected = False self.who = None self.cred = None if serverctrls and len(serverctrls) > 1: self._uri = uri, if len(serverctrls) > 1:,138,10
openstack%2Fpython-openstackclient~888168,openstack/python-openstackclient,stable/zed,Ib5c3b7f86acf1dfe7cc76dfa99fa4c118388bd71,"Fix ""access rule"" commands to only use ID",MERGED,2023-07-12 14:10:43.000000000,2023-07-12 21:04:16.000000000,2023-07-12 21:02:35.000000000,"[{'_account_id': 15334}, {'_account_id': 22348}]","[{'number': 1, 'created': '2023-07-12 14:10:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-openstackclient/commit/457d29c5153bd6b2c0e9197773166bd4d8e87e7b', 'message': 'Fix ""access rule"" commands to only use ID\n\nThis patch modifies the access rule commands to use only the resource\nID.  The previous logic incorrectly assumed that access rules have a\n""name"" property, which resulted in unexpected behaviors.\n\nFor example, ""access rule delete {non-existent-id}"" now results in a\n""not found"" error instead of sometimes deleting an unrelated rule.\n\nStory: 2010775\nTask: 48163\nChange-Id: Ib5c3b7f86acf1dfe7cc76dfa99fa4c118388bd71\n(cherry picked from commit a03e3dbf75c55561bc3575c53db445868be87a3b)\n'}, {'number': 2, 'created': '2023-07-12 15:44:47.000000000', 'files': ['openstackclient/tests/unit/identity/v3/test_access_rule.py', 'openstackclient/identity/v3/access_rule.py', 'openstackclient/identity/common.py', 'releasenotes/notes/fix-story-2010775-953dbdf03b2b6746.yaml'], 'web_link': 'https://opendev.org/openstack/python-openstackclient/commit/48148e7a1197c92febdb3ab1e72085c4eb3d6bf7', 'message': 'Fix ""access rule"" commands to only use ID\n\nThis patch modifies the access rule commands to use only the resource\nID.  The previous logic incorrectly assumed that access rules have a\n""name"" property, which resulted in unexpected behaviors.\n\nFor example, ""access rule delete {non-existent-id}"" now results in a\n""not found"" error instead of sometimes deleting an unrelated rule.\n\nStory: 2010775\nTask: 48163\nChange-Id: Ib5c3b7f86acf1dfe7cc76dfa99fa4c118388bd71\n(cherry picked from commit a03e3dbf75c55561bc3575c53db445868be87a3b)\n'}]",3,888168,48148e7a1197c92febdb3ab1e72085c4eb3d6bf7,12,2,2,7973,,,0,"Fix ""access rule"" commands to only use ID

This patch modifies the access rule commands to use only the resource
ID.  The previous logic incorrectly assumed that access rules have a
""name"" property, which resulted in unexpected behaviors.

For example, ""access rule delete {non-existent-id}"" now results in a
""not found"" error instead of sometimes deleting an unrelated rule.

Story: 2010775
Task: 48163
Change-Id: Ib5c3b7f86acf1dfe7cc76dfa99fa4c118388bd71
(cherry picked from commit a03e3dbf75c55561bc3575c53db445868be87a3b)
",git fetch https://review.opendev.org/openstack/python-openstackclient refs/changes/68/888168/1 && git format-patch -1 --stdout FETCH_HEAD,"['openstackclient/tests/unit/identity/v3/test_access_rule.py', 'openstackclient/identity/v3/access_rule.py', 'openstackclient/identity/common.py', 'releasenotes/notes/fix-story-2010775-953dbdf03b2b6746.yaml']",4,457d29c5153bd6b2c0e9197773166bd4d8e87e7b,story/2010775-stable/zed,"--- fixes: - | Fixed a bug in ""access rule"" subcommands where the client logic incorrectly assumed that access rules have a ""name"" property which resulted in unpredictable behaviors. e.g. ""access rule delete {non-existent-id}"" now results in a not-found error instead of sometimes deleting an unrelated rule. ",,39,17
openstack%2Fcinder~884253,openstack/cinder,master,I8dc9147d84daaadcfb4720beeb042316c468f469,Tests: Provide filter arg to VolumeAttachmentNotFound(),MERGED,2023-05-24 16:43:31.000000000,2023-07-12 21:03:59.000000000,2023-07-12 21:02:41.000000000,"[{'_account_id': 5314}, {'_account_id': 9535}, {'_account_id': 9542}, {'_account_id': 22348}, {'_account_id': 32238}, {'_account_id': 32761}, {'_account_id': 35075}]","[{'number': 1, 'created': '2023-05-24 16:43:31.000000000', 'files': ['cinder/tests/unit/attachments/test_attachments_api.py'], 'web_link': 'https://opendev.org/openstack/cinder/commit/5edef212e2dc81917ef4727e7170890b6d17e060', 'message': ""Tests: Provide filter arg to VolumeAttachmentNotFound()\n\nThis parameter being absent results in\nCinderException._log_exception() logging an\n'Exception in string format operation:' error when running\nunit tests.\n\nChange-Id: I8dc9147d84daaadcfb4720beeb042316c468f469\n""}]",2,884253,5edef212e2dc81917ef4727e7170890b6d17e060,32,7,1,4523,,,0,"Tests: Provide filter arg to VolumeAttachmentNotFound()

This parameter being absent results in
CinderException._log_exception() logging an
'Exception in string format operation:' error when running
unit tests.

Change-Id: I8dc9147d84daaadcfb4720beeb042316c468f469
",git fetch https://review.opendev.org/openstack/cinder refs/changes/53/884253/1 && git format-patch -1 --stdout FETCH_HEAD,['cinder/tests/unit/attachments/test_attachments_api.py'],1,5edef212e2dc81917ef4727e7170890b6d17e060,, side_effect=exception.VolumeAttachmentNotFound(filter='')), side_effect=exception.VolumeAttachmentNotFound()),1,1
openstack%2Fdevstack~887810,openstack/devstack,stable/2023.1,I6aacac94f9697088338b3d2f99d8eaa22c2be67b,Add 10 second buffer for uwsgi service stop,MERGED,2023-07-06 11:18:42.000000000,2023-07-12 21:03:30.000000000,2023-07-12 21:02:32.000000000,"[{'_account_id': 8556}, {'_account_id': 13252}, {'_account_id': 22348}, {'_account_id': 22873}]","[{'number': 1, 'created': '2023-07-06 11:18:42.000000000', 'files': ['stackrc'], 'web_link': 'https://opendev.org/openstack/devstack/commit/dc5b0dd161978903ef1a24f2b511773447b2d350', 'message': 'Add 10 second buffer for uwsgi service stop\n\nDefault for systemd TimeoutStopSec is 90 seconds\nand that is same for default graceful shutdown of\nuwsgi service(WORKER_TIMEOUT).\n\nDue to the Related-Bug graceful stop attempt\nfails and there is no room for force shutdown.\nThis patch reduces default for WORKER_TIMEOUT by\n10 seconds so there is a buffer to force stop the\nservice.\n\nCloses-Bug: #2020643\nRelated-Bug: #2015065\nChange-Id: I6aacac94f9697088338b3d2f99d8eaa22c2be67b\n(cherry picked from commit 7288df34f8513caf6f3985c75855feb572f6b004)\n'}]",3,887810,dc5b0dd161978903ef1a24f2b511773447b2d350,14,4,1,13861,,,0,"Add 10 second buffer for uwsgi service stop

Default for systemd TimeoutStopSec is 90 seconds
and that is same for default graceful shutdown of
uwsgi service(WORKER_TIMEOUT).

Due to the Related-Bug graceful stop attempt
fails and there is no room for force shutdown.
This patch reduces default for WORKER_TIMEOUT by
10 seconds so there is a buffer to force stop the
service.

Closes-Bug: #2020643
Related-Bug: #2015065
Change-Id: I6aacac94f9697088338b3d2f99d8eaa22c2be67b
(cherry picked from commit 7288df34f8513caf6f3985c75855feb572f6b004)
",git fetch https://review.opendev.org/openstack/devstack refs/changes/10/887810/1 && git format-patch -1 --stdout FETCH_HEAD,['stackrc'],1,dc5b0dd161978903ef1a24f2b511773447b2d350,bug/2020643-stable/2023.1,WORKER_TIMEOUT=${WORKER_TIMEOUT:-80},WORKER_TIMEOUT=${WORKER_TIMEOUT:-90},1,1
openstack%2Fpython-openstackclient~888169,openstack/python-openstackclient,stable/zed,I716f6a1496fc552b32809c7eb744283f3a3cd5a4,Fix pep issue in the network service provider,MERGED,2023-07-12 15:44:27.000000000,2023-07-12 21:03:27.000000000,2023-07-12 21:02:34.000000000,"[{'_account_id': 15334}, {'_account_id': 22348}]","[{'number': 1, 'created': '2023-07-12 15:44:27.000000000', 'files': ['openstackclient/network/v2/network_service_provider.py'], 'web_link': 'https://opendev.org/openstack/python-openstackclient/commit/fc80188e5f053ec0e909ce64461864d7e4709ea7', 'message': 'Fix pep issue in the network service provider\n\npep gods started complaining (correctfully) about spacing in the old\ncommand. Apply `black -l 79` on the file to make it looking nice and\npassing checks.\n\nChange-Id: I716f6a1496fc552b32809c7eb744283f3a3cd5a4\n(cherry picked from commit 07c5a26fe56a6374fcbcfaa61f9c340f9c0fdc10)\n'}]",0,888169,fc80188e5f053ec0e909ce64461864d7e4709ea7,7,2,1,7973,,,0,"Fix pep issue in the network service provider

pep gods started complaining (correctfully) about spacing in the old
command. Apply `black -l 79` on the file to make it looking nice and
passing checks.

Change-Id: I716f6a1496fc552b32809c7eb744283f3a3cd5a4
(cherry picked from commit 07c5a26fe56a6374fcbcfaa61f9c340f9c0fdc10)
",git fetch https://review.opendev.org/openstack/python-openstackclient refs/changes/69/888169/1 && git format-patch -1 --stdout FETCH_HEAD,['openstackclient/network/v2/network_service_provider.py'],1,fc80188e5f053ec0e909ce64461864d7e4709ea7,," ""service_type"", ""name"", ""is_default"", ""Service Type"", ""Name"", ""Default"", return ( column_headers, ( utils.get_item_properties( s, columns, ) for s in data ), )"," 'service_type', 'name', 'is_default', 'Service Type', 'Name', 'Default', return(column_headers, (utils.get_item_properties( s, columns, ) for s in data))",16,10
openstack%2Fpuppet-glance~887817,openstack/puppet-glance,stable/2023.1,I83d3ff31083dd687c5b2d76c8297b5e74a7caa1a,Add per module policy service refresh,MERGED,2023-07-06 19:13:31.000000000,2023-07-12 20:43:57.000000000,2023-07-12 20:43:57.000000000,"[{'_account_id': 9816}, {'_account_id': 21129}, {'_account_id': 22348}]","[{'number': 1, 'created': '2023-07-06 19:13:31.000000000', 'files': ['spec/classes/glance_policy_spec.rb', 'manifests/deps.pp', 'manifests/policy.pp'], 'web_link': 'https://opendev.org/openstack/puppet-glance/commit/dcacc06e303c75c368040bfbaf91752d97b1a5b6', 'message': 'Add per module policy service refresh\n\nUpdating the policies for this project should only\nrefresh the services that reads it.\n\nChange-Id: I83d3ff31083dd687c5b2d76c8297b5e74a7caa1a\n(cherry picked from commit 8d4873a3af5e515769c7b87ce5d36cc49b773707)\n'}]",1,887817,dcacc06e303c75c368040bfbaf91752d97b1a5b6,13,3,1,16137,,,0,"Add per module policy service refresh

Updating the policies for this project should only
refresh the services that reads it.

Change-Id: I83d3ff31083dd687c5b2d76c8297b5e74a7caa1a
(cherry picked from commit 8d4873a3af5e515769c7b87ce5d36cc49b773707)
",git fetch https://review.opendev.org/openstack/puppet-glance refs/changes/17/887817/1 && git format-patch -1 --stdout FETCH_HEAD,"['spec/classes/glance_policy_spec.rb', 'manifests/deps.pp', 'manifests/policy.pp']",3,dcacc06e303c75c368040bfbaf91752d97b1a5b6,per-module-policy-refresh-stable/2023.1," tag => 'glance',",,4,1
openstack%2Fproject-config~888353,openstack/project-config,master,Ib32ce190a43ce0b2a0fefc4fef29a58c53d01ad4,Add missing NebulOuS repos to Zuul,MERGED,2023-07-12 20:17:41.000000000,2023-07-12 20:41:22.000000000,2023-07-12 20:35:55.000000000,"[{'_account_id': 5263}, {'_account_id': 22348}]","[{'number': 1, 'created': '2023-07-12 20:17:41.000000000', 'files': ['zuul/main.yaml'], 'web_link': 'https://opendev.org/openstack/project-config/commit/e23ee24eeeb045e000d626501892891d8cd6f647', 'message': 'Add missing NebulOuS repos to Zuul\n\nChange-Id: Ib32ce190a43ce0b2a0fefc4fef29a58c53d01ad4\n'}]",0,888353,e23ee24eeeb045e000d626501892891d8cd6f647,7,2,1,30491,,,0,"Add missing NebulOuS repos to Zuul

Change-Id: Ib32ce190a43ce0b2a0fefc4fef29a58c53d01ad4
",git fetch https://review.opendev.org/openstack/project-config refs/changes/53/888353/1 && git format-patch -1 --stdout FETCH_HEAD,['zuul/main.yaml'],1,e23ee24eeeb045e000d626501892891d8cd6f647,nebulous-zuul-add-missing," # Templates. - nebulous/library-template # Sandboxes. - nebulous/nebulous-sandbox - nebulous/component-sandbox # Pilots, alphabetically. - nebulous/pilot-1-1-windmill - nebulous/pilot-1-2-city - nebulous/pilot-2-1-intralogistics - nebulous/pilot-2-2-last-mile - nebulous/pilot-3-1-agriculture - nebulous/pilot-4-1-emergency # Helpers, alphabetically. - nebulous/asyncapi # Components, alphabetically. - nebulous/iot-dpp-orchestrator",,16,0
openstack%2Fpuppet-cinder~887815,openstack/puppet-cinder,stable/2023.1,I22618ef8528d0e8dafd1d3483a2d02a15b30c816,Add per module policy service refresh,MERGED,2023-07-06 19:12:48.000000000,2023-07-12 20:41:05.000000000,2023-07-12 20:41:05.000000000,"[{'_account_id': 9816}, {'_account_id': 21129}, {'_account_id': 22348}]","[{'number': 1, 'created': '2023-07-06 19:12:48.000000000', 'files': ['spec/classes/cinder_policy_spec.rb', 'manifests/deps.pp', 'manifests/policy.pp'], 'web_link': 'https://opendev.org/openstack/puppet-cinder/commit/c667fd34513628148aeec6921be566b2cbef5e29', 'message': 'Add per module policy service refresh\n\nUpdating the policies for this project should only\nrefresh the services that reads it.\n\nChange-Id: I22618ef8528d0e8dafd1d3483a2d02a15b30c816\n(cherry picked from commit f755731f77d537e5cbb9d776448bd1927d8f5110)\n'}]",1,887815,c667fd34513628148aeec6921be566b2cbef5e29,13,3,1,16137,,,0,"Add per module policy service refresh

Updating the policies for this project should only
refresh the services that reads it.

Change-Id: I22618ef8528d0e8dafd1d3483a2d02a15b30c816
(cherry picked from commit f755731f77d537e5cbb9d776448bd1927d8f5110)
",git fetch https://review.opendev.org/openstack/puppet-cinder refs/changes/15/887815/1 && git format-patch -1 --stdout FETCH_HEAD,"['spec/classes/cinder_policy_spec.rb', 'manifests/deps.pp', 'manifests/policy.pp']",3,c667fd34513628148aeec6921be566b2cbef5e29,per-module-policy-refresh-stable/2023.1," tag => 'cinder',",,4,1
openstack%2Fkolla-ansible~869593,openstack/kolla-ansible,master,Ie9fdcf7e98add90ce56f387b2a563f2086c78bac,ceilometer: clarify ceilometer precheck,NEW,2023-01-09 18:47:33.000000000,2023-07-12 20:16:25.000000000,,"[{'_account_id': 14200}, {'_account_id': 14826}, {'_account_id': 22348}, {'_account_id': 22629}, {'_account_id': 25600}, {'_account_id': 32029}, {'_account_id': 34585}]","[{'number': 1, 'created': '2023-01-09 18:47:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/c6a29a7aaf3c1c4064c85c7b935d317ee61a26e8', 'message': ""ceilometer: Use assert on checks for readability\n\nassert will also fail when we're not meeting the conditions, makes\nclear what we're actually testing, and isn't listed as a skipped task\nwhen the condition is ok.\n\nChanges after I9fd32f63913a534c59e2d17703702074eea5dd76 enabled an\nadditional storage engine for ceilometer. So rephrasing check and\nfail_msg, Setting changed_when not required for asserts.\n\nChange-Id: Ie9fdcf7e98add90ce56f387b2a563f2086c78bac\n""}, {'number': 2, 'created': '2023-01-09 20:44:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/03e45fc7b187811e77081be816f2cf61860ab52b', 'message': ""ceilometer: Use assert on checks for readability\n\nassert will also fail when we're not meeting the conditions, makes\nclear what we're actually testing, and isn't listed as a skipped task\nwhen the condition is ok.\n\nChanges after I9fd32f63913a534c59e2d17703702074eea5dd76 enabled an\nadditional storage engine for ceilometer. So rephrasing check and\nfail_msg, Setting changed_when not required for asserts.\n\nChange-Id: Ie9fdcf7e98add90ce56f387b2a563f2086c78bac\n""}, {'number': 3, 'created': '2023-07-11 21:22:18.000000000', 'files': ['ansible/roles/ceilometer/tasks/precheck.yml'], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/aa2ea60246666781f59919db58195b3461eaae73', 'message': 'ceilometer: clarify ceilometer precheck\n\nChanges after I9fd32f63913a534c59e2d17703702074eea5dd76 enabled an\nadditional storage engine for ceilometer.\n\nChanges after I8c4b0053f2f16b6d243462c4b8117748d26143a0 replaced the\nfail with an assert which is super, but missed the mark as to _when_\nthe assert should be performed.\n\nChange-Id: Ie9fdcf7e98add90ce56f387b2a563f2086c78bac\n'}]",3,869593,aa2ea60246666781f59919db58195b3461eaae73,27,7,3,25600,,,0,"ceilometer: clarify ceilometer precheck

Changes after I9fd32f63913a534c59e2d17703702074eea5dd76 enabled an
additional storage engine for ceilometer.

Changes after I8c4b0053f2f16b6d243462c4b8117748d26143a0 replaced the
fail with an assert which is super, but missed the mark as to _when_
the assert should be performed.

Change-Id: Ie9fdcf7e98add90ce56f387b2a563f2086c78bac
",git fetch https://review.opendev.org/openstack/kolla-ansible refs/changes/93/869593/1 && git format-patch -1 --stdout FETCH_HEAD,['ansible/roles/ceilometer/tasks/precheck.yml'],1,c6a29a7aaf3c1c4064c85c7b935d317ee61a26e8,kolla_assert,"- name: Checking valid backend for ceilometer assert: that: - enable_gnocchi | bool or enable_ceilometer_prometheus_pushgateway | bool fail_msg: ""gnocchi or prometheus are required but not enabled""","- name: Checking gnocchi backend for ceilometer fail: msg: ""gnocchi is required but not enabled"" changed_when: false - not (enable_gnocchi | bool or enable_ceilometer_prometheus_pushgateway | bool)",6,5
openstack%2Fironic~886863,openstack/ironic,master,I8f229fa6e738a69a668d4b891723431b2da362fa,Disable spanning tree,MERGED,2023-06-23 17:12:14.000000000,2023-07-12 19:56:37.000000000,2023-07-12 19:55:24.000000000,"[{'_account_id': 10342}, {'_account_id': 15519}, {'_account_id': 22348}]","[{'number': 1, 'created': '2023-06-23 17:12:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/0cd050c12da2e25121edd03480ce04342eda105e', 'message': ""Disable spanning tree\n\nSo, I've long wondered if we still have some spanning tree behavior\ngoing on in CI. Turns out we might, but we just rely upon the defaults\nwhich creates a variable.\n\nAnyway, regardless, I found some details in the ovs-vsctl manual[0], and\nwell, lets set the options!\n\n[0]: http://www.openvswitch.org/support/dist-docs/ovs-vsctl.8.html\n\nChange-Id: I8f229fa6e738a69a668d4b891723431b2da362fa\n""}, {'number': 2, 'created': '2023-07-06 17:16:33.000000000', 'files': ['devstack/tools/ironic/scripts/setup-network.sh'], 'web_link': 'https://opendev.org/openstack/ironic/commit/6d3c4ced5f4b263cee2f2e6e45292dd40e789187', 'message': ""Disable spanning tree\n\nSo, I've long wondered if we still have some spanning tree behavior\ngoing on in CI. Turns out we might, but we just rely upon the defaults\nwhich creates a variable.\n\nAnyway, regardless, I found some details in the ovs-vsctl manual[0], and\nwell, lets set the options!\n\n[0]: http://www.openvswitch.org/support/dist-docs/ovs-vsctl.8.html\n\nChange-Id: I8f229fa6e738a69a668d4b891723431b2da362fa\n""}]",2,886863,6d3c4ced5f4b263cee2f2e6e45292dd40e789187,19,3,2,11655,,,0,"Disable spanning tree

So, I've long wondered if we still have some spanning tree behavior
going on in CI. Turns out we might, but we just rely upon the defaults
which creates a variable.

Anyway, regardless, I found some details in the ovs-vsctl manual[0], and
well, lets set the options!

[0]: http://www.openvswitch.org/support/dist-docs/ovs-vsctl.8.html

Change-Id: I8f229fa6e738a69a668d4b891723431b2da362fa
",git fetch https://review.opendev.org/openstack/ironic refs/changes/63/886863/1 && git format-patch -1 --stdout FETCH_HEAD,['devstack/tools/ironic/scripts/setup-network.sh'],1,0cd050c12da2e25121edd03480ce04342eda105e,,(sudo ovs-vsctl list-br | grep ${BRIDGE_NAME}) || sudo ovs-vsctl add-br ${BRIDGE_NAME} && ovs-vsctl set Bridge ${BRIDGE_NAME} stp_enable=False && ovs-vsctl set Bridge ${BRIDGE_NAME} rstp_enable=false,(sudo ovs-vsctl list-br | grep ${BRIDGE_NAME}) || sudo ovs-vsctl add-br ${BRIDGE_NAME},1,1
openstack%2Fcharm-cinder-purestorage~888330,openstack/charm-cinder-purestorage,stable/yoga,I440b8acad52fb10ea25cc9e055d805e9663f3112,[DNM] Testing 3rd party CI,NEW,2023-07-12 18:46:30.000000000,2023-07-12 19:39:48.000000000,,"[{'_account_id': 20648}, {'_account_id': 22348}]","[{'number': 1, 'created': '2023-07-12 18:46:30.000000000', 'files': ['README.md'], 'web_link': 'https://opendev.org/openstack/charm-cinder-purestorage/commit/56f62fa3e76963b537807d7bba82aaa0b66b843a', 'message': '[DNM] Testing 3rd party CI\n\nChange-Id: I440b8acad52fb10ea25cc9e055d805e9663f3112\n'}]",1,888330,56f62fa3e76963b537807d7bba82aaa0b66b843a,4,2,1,13425,,,0,"[DNM] Testing 3rd party CI

Change-Id: I440b8acad52fb10ea25cc9e055d805e9663f3112
",git fetch https://review.opendev.org/openstack/charm-cinder-purestorage refs/changes/30/888330/1 && git format-patch -1 --stdout FETCH_HEAD,['README.md'],1,56f62fa3e76963b537807d7bba82aaa0b66b843a,dnm_1-stable/yoga,tox -e py310,tox -e py35 # or py36,1,1
openstack%2Fneutron~887951,openstack/neutron,master,I933cfd66c22aeb0048e1a7c4717ffdf499f5b63c,Add unit tests periodic jobs to the experimental queue,MERGED,2023-07-07 12:31:11.000000000,2023-07-12 19:38:50.000000000,2023-07-12 19:36:13.000000000,"[{'_account_id': 1131}, {'_account_id': 13861}, {'_account_id': 16688}, {'_account_id': 22348}, {'_account_id': 32029}]","[{'number': 1, 'created': '2023-07-07 12:31:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/ebaf825f4b5e037b58ab5fdf1a81488774b5607c', 'message': 'Add unit tests periodic jobs to the experimental queue\n\nWe agreed to have all periodic jobs in the experimental queue also to be\nable to run them quickly if needed. And it was like that for most of the\njobs but jobs which came to the periodic queue from templates defined in\n[1] were missing in the experimental queue.\nThis patch adds them to the experimental queue too.\n\nRelated-bug: #2025753\n\n[1] https://opendev.org/openstack/openstack-zuul-jobs/src/branch/master/zuul.d/project-templates.yaml\n\nChange-Id: I933cfd66c22aeb0048e1a7c4717ffdf499f5b63c\n'}, {'number': 2, 'created': '2023-07-10 07:57:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/12d5a9c9f7e1b27bf270e0cfc649b5813438e653', 'message': 'Add unit tests periodic jobs to the experimental queue\n\nWe agreed to have all periodic jobs in the experimental queue also to be\nable to run them quickly if needed. And it was like that for most of the\njobs but jobs which came to the periodic queue from templates defined in\n[1] were missing in the experimental queue.\nThis patch adds them to the experimental queue too.\n\nRelated-bug: #2025753\n\n[1] https://opendev.org/openstack/openstack-zuul-jobs/src/branch/master/zuul.d/project-templates.yaml\n\nChange-Id: I933cfd66c22aeb0048e1a7c4717ffdf499f5b63c\n'}, {'number': 3, 'created': '2023-07-12 05:22:04.000000000', 'files': ['zuul.d/job-templates.yaml'], 'web_link': 'https://opendev.org/openstack/neutron/commit/32121ee63817ee7617397d7d58493a0b718b4bb4', 'message': 'Add unit tests periodic jobs to the experimental queue\n\nWe agreed to have all periodic jobs in the experimental queue also to be\nable to run them quickly if needed. And it was like that for most of the\njobs but jobs which came to the periodic queue from templates defined in\n[1] were missing in the experimental queue.\nThis patch adds them to the experimental queue too.\n\nAlso added irrelevant-files to tox-py311 as it was\nmissing.\n\nRelated-bug: #2025753\n[1] https://opendev.org/openstack/openstack-zuul-jobs/src/branch/master/zuul.d/project-templates.yaml\n\nChange-Id: I933cfd66c22aeb0048e1a7c4717ffdf499f5b63c\n'}]",11,887951,32121ee63817ee7617397d7d58493a0b718b4bb4,27,5,3,11975,,,0,"Add unit tests periodic jobs to the experimental queue

We agreed to have all periodic jobs in the experimental queue also to be
able to run them quickly if needed. And it was like that for most of the
jobs but jobs which came to the periodic queue from templates defined in
[1] were missing in the experimental queue.
This patch adds them to the experimental queue too.

Also added irrelevant-files to tox-py311 as it was
missing.

Related-bug: #2025753
[1] https://opendev.org/openstack/openstack-zuul-jobs/src/branch/master/zuul.d/project-templates.yaml

Change-Id: I933cfd66c22aeb0048e1a7c4717ffdf499f5b63c
",git fetch https://review.opendev.org/openstack/neutron refs/changes/51/887951/1 && git format-patch -1 --stdout FETCH_HEAD,['zuul.d/job-templates.yaml'],1,ebaf825f4b5e037b58ab5fdf1a81488774b5607c,bug/2025753, # Jobs added to the periodic queue by templates defined in # https://opendev.org/openstack/openstack-zuul-jobs/src/branch/master/zuul.d/project-templates.yaml - openstack-tox-py310-with-neutron-lib-master - openstack-tox-py310-with-oslo-master - openstack-tox-py310-with-ovsdbapp-master - openstack-tox-py39-with-oslo-master,,6,0
openstack%2Fpuppet-neutron~887828,openstack/puppet-neutron,stable/2023.1,I541a7dbb11580155cf2bb3af0ffbf6ebc5b1220b,Add per module policy service refresh,MERGED,2023-07-06 19:15:57.000000000,2023-07-12 19:31:38.000000000,2023-07-12 19:31:38.000000000,"[{'_account_id': 9816}, {'_account_id': 14985}, {'_account_id': 22348}]","[{'number': 1, 'created': '2023-07-06 19:15:57.000000000', 'files': ['spec/classes/neutron_policy_spec.rb', 'manifests/deps.pp', 'manifests/policy.pp'], 'web_link': 'https://opendev.org/openstack/puppet-neutron/commit/d76f4b4dfd6ee9d4f641c726c0da86b2a7373d61', 'message': 'Add per module policy service refresh\n\nUpdating the policies for this project should only\nrefresh the services that reads it.\n\nChange-Id: I541a7dbb11580155cf2bb3af0ffbf6ebc5b1220b\n(cherry picked from commit f7f43194782035c58c6fd799fe08136068a4dedc)\n'}]",1,887828,d76f4b4dfd6ee9d4f641c726c0da86b2a7373d61,9,3,1,16137,,,0,"Add per module policy service refresh

Updating the policies for this project should only
refresh the services that reads it.

Change-Id: I541a7dbb11580155cf2bb3af0ffbf6ebc5b1220b
(cherry picked from commit f7f43194782035c58c6fd799fe08136068a4dedc)
",git fetch https://review.opendev.org/openstack/puppet-neutron refs/changes/28/887828/1 && git format-patch -1 --stdout FETCH_HEAD,"['spec/classes/neutron_policy_spec.rb', 'manifests/deps.pp', 'manifests/policy.pp']",3,d76f4b4dfd6ee9d4f641c726c0da86b2a7373d61,per-module-policy-refresh-stable/2023.1," tag => 'neutron',",,4,1
openstack%2Fpuppet-aodh~887813,openstack/puppet-aodh,stable/2023.1,I7dc9f4a9849043624359eb97775af20d1885103a,Add per module policy service refresh,MERGED,2023-07-06 19:11:40.000000000,2023-07-12 19:24:46.000000000,2023-07-12 19:24:46.000000000,"[{'_account_id': 9816}, {'_account_id': 14985}, {'_account_id': 22348}]","[{'number': 1, 'created': '2023-07-06 19:11:40.000000000', 'files': ['spec/classes/aodh_policy_spec.rb', 'manifests/deps.pp', 'manifests/policy.pp'], 'web_link': 'https://opendev.org/openstack/puppet-aodh/commit/1f21b55553d0e5d8d49b888716eb402039826eed', 'message': 'Add per module policy service refresh\n\nUpdating the policies for this project should only\nrefresh the services that reads it.\n\nChange-Id: I7dc9f4a9849043624359eb97775af20d1885103a\n(cherry picked from commit 366abb9ccd04396334feb947b82b71ee99a102dc)\n'}]",1,887813,1f21b55553d0e5d8d49b888716eb402039826eed,9,3,1,16137,,,0,"Add per module policy service refresh

Updating the policies for this project should only
refresh the services that reads it.

Change-Id: I7dc9f4a9849043624359eb97775af20d1885103a
(cherry picked from commit 366abb9ccd04396334feb947b82b71ee99a102dc)
",git fetch https://review.opendev.org/openstack/puppet-aodh refs/changes/13/887813/1 && git format-patch -1 --stdout FETCH_HEAD,"['spec/classes/aodh_policy_spec.rb', 'manifests/deps.pp', 'manifests/policy.pp']",3,1f21b55553d0e5d8d49b888716eb402039826eed,per-module-policy-refresh-stable/2023.1," tag => 'aodh',",,4,1
openstack%2Fpuppet-keystone~887877,openstack/puppet-keystone,stable/2023.1,I80117d1c7ab1bd9642a6c3d416c6683ae024894a,Add per module policy service refresh,MERGED,2023-07-06 19:17:52.000000000,2023-07-12 19:23:54.000000000,2023-07-12 19:23:54.000000000,"[{'_account_id': 9816}, {'_account_id': 14985}, {'_account_id': 22348}]","[{'number': 1, 'created': '2023-07-06 19:17:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-keystone/commit/7b26b2dd5dc2b6a8c6154499c2eb7b38464c19d9', 'message': 'Add per module policy service refresh\n\nUpdating the policies for this project should only\nrefresh the services that reads it.\n\nChange-Id: I80117d1c7ab1bd9642a6c3d416c6683ae024894a\n'}, {'number': 2, 'created': '2023-07-12 06:48:44.000000000', 'files': ['spec/classes/keystone_policy_spec.rb', 'manifests/deps.pp', 'manifests/policy.pp'], 'web_link': 'https://opendev.org/openstack/puppet-keystone/commit/74468f0c675005b3791d14f0e7eeb678fd0c413a', 'message': 'Add per module policy service refresh\n\nUpdating the policies for this project should only\nrefresh the services that reads it.\n\nChange-Id: I80117d1c7ab1bd9642a6c3d416c6683ae024894a\n(cherry picked from commit 9fee3031a3f7bcb3427d2570cca5f150d9068db5)\n'}]",1,887877,74468f0c675005b3791d14f0e7eeb678fd0c413a,10,3,2,16137,,,0,"Add per module policy service refresh

Updating the policies for this project should only
refresh the services that reads it.

Change-Id: I80117d1c7ab1bd9642a6c3d416c6683ae024894a
(cherry picked from commit 9fee3031a3f7bcb3427d2570cca5f150d9068db5)
",git fetch https://review.opendev.org/openstack/puppet-keystone refs/changes/77/887877/1 && git format-patch -1 --stdout FETCH_HEAD,"['spec/classes/keystone_policy_spec.rb', 'manifests/deps.pp', 'manifests/policy.pp']",3,7b26b2dd5dc2b6a8c6154499c2eb7b38464c19d9,per-module-policy-refresh-stable/2023.1," tag => 'keystone',",,4,1
openstack%2Fpuppet-openstack-integration~887436,openstack/puppet-openstack-integration,master,Ia0efddda3a29164f79637556ac02c31efea6a1f3,Updated from Puppet OpenStack modules constraints,MERGED,2023-07-01 02:18:29.000000000,2023-07-12 19:19:38.000000000,2023-07-12 19:19:38.000000000,"[{'_account_id': 9816}, {'_account_id': 14985}, {'_account_id': 22348}]","[{'number': 1, 'created': '2023-07-01 02:18:29.000000000', 'files': ['Puppetfile'], 'web_link': 'https://opendev.org/openstack/puppet-openstack-integration/commit/d1b87e5c2199c6825882e997e5145a01850b0f03', 'message': 'Updated from Puppet OpenStack modules constraints\n\nChange-Id: Ia0efddda3a29164f79637556ac02c31efea6a1f3\n'}]",2,887436,d1b87e5c2199c6825882e997e5145a01850b0f03,10,3,1,11131,,,0,"Updated from Puppet OpenStack modules constraints

Change-Id: Ia0efddda3a29164f79637556ac02c31efea6a1f3
",git fetch https://review.opendev.org/openstack/puppet-openstack-integration refs/changes/36/887436/1 && git format-patch -1 --stdout FETCH_HEAD,['Puppetfile'],1,d1b87e5c2199c6825882e997e5145a01850b0f03,openstack/puppet/constraints, :ref => 'v10.1.1', :ref => 'v10.1.0',1,1
openstack%2Fpuppet-gnocchi~887827,openstack/puppet-gnocchi,stable/2023.1,I5b7504bc02b2576a8921d1a70bc1bd07b19c1023,Add per module policy service refresh,MERGED,2023-07-06 19:15:46.000000000,2023-07-12 19:18:47.000000000,2023-07-12 19:18:47.000000000,"[{'_account_id': 9816}, {'_account_id': 14985}, {'_account_id': 22348}]","[{'number': 1, 'created': '2023-07-06 19:15:46.000000000', 'files': ['spec/classes/gnocchi_policy_spec.rb', 'manifests/deps.pp', 'manifests/policy.pp'], 'web_link': 'https://opendev.org/openstack/puppet-gnocchi/commit/841e19d5a203d864ae92dc4c013f54004f2d4483', 'message': 'Add per module policy service refresh\n\nUpdating the policies for this project should only\nrefresh the services that reads it.\n\nChange-Id: I5b7504bc02b2576a8921d1a70bc1bd07b19c1023\n(cherry picked from commit fea62d44e918fb5f944882ef01fa02e5687c7f31)\n'}]",1,887827,841e19d5a203d864ae92dc4c013f54004f2d4483,9,3,1,16137,,,0,"Add per module policy service refresh

Updating the policies for this project should only
refresh the services that reads it.

Change-Id: I5b7504bc02b2576a8921d1a70bc1bd07b19c1023
(cherry picked from commit fea62d44e918fb5f944882ef01fa02e5687c7f31)
",git fetch https://review.opendev.org/openstack/puppet-gnocchi refs/changes/27/887827/1 && git format-patch -1 --stdout FETCH_HEAD,"['spec/classes/gnocchi_policy_spec.rb', 'manifests/deps.pp', 'manifests/policy.pp']",3,841e19d5a203d864ae92dc4c013f54004f2d4483,per-module-policy-refresh-stable/2023.1," tag => 'gnocchi',",,4,1
openstack%2Fpuppet-watcher~887873,openstack/puppet-watcher,stable/2023.1,I9c4804116384465fbefa419c1158a87ab8b2c872,Add per module policy service refresh,MERGED,2023-07-06 19:17:09.000000000,2023-07-12 19:16:00.000000000,2023-07-12 19:16:00.000000000,"[{'_account_id': 9816}, {'_account_id': 14985}, {'_account_id': 22348}]","[{'number': 1, 'created': '2023-07-06 19:17:09.000000000', 'files': ['spec/classes/watcher_policy_spec.rb', 'manifests/deps.pp', 'manifests/policy.pp'], 'web_link': 'https://opendev.org/openstack/puppet-watcher/commit/d661961d356f6cb13a219275ee971380c21951e0', 'message': 'Add per module policy service refresh\n\nUpdating the policies for this project should only\nrefresh the services that reads it.\n\nChange-Id: I9c4804116384465fbefa419c1158a87ab8b2c872\n(cherry picked from commit df8733d486a9c87ad5e8103c45d5b7011e41935e)\n'}]",1,887873,d661961d356f6cb13a219275ee971380c21951e0,9,3,1,16137,,,0,"Add per module policy service refresh

Updating the policies for this project should only
refresh the services that reads it.

Change-Id: I9c4804116384465fbefa419c1158a87ab8b2c872
(cherry picked from commit df8733d486a9c87ad5e8103c45d5b7011e41935e)
",git fetch https://review.opendev.org/openstack/puppet-watcher refs/changes/73/887873/1 && git format-patch -1 --stdout FETCH_HEAD,"['spec/classes/watcher_policy_spec.rb', 'manifests/deps.pp', 'manifests/policy.pp']",3,d661961d356f6cb13a219275ee971380c21951e0,per-module-policy-refresh-stable/2023.1," tag => 'watcher',",,4,1
openstack%2Fpuppet-horizon~887816,openstack/puppet-horizon,stable/2023.1,I94e1120013aa6e15bbf3aa48a9c29d9943985440,Add per module policy service refresh,MERGED,2023-07-06 19:13:16.000000000,2023-07-12 19:15:19.000000000,2023-07-12 19:15:19.000000000,"[{'_account_id': 9816}, {'_account_id': 14985}, {'_account_id': 22348}]","[{'number': 1, 'created': '2023-07-06 19:13:16.000000000', 'files': ['spec/defines/horizon_policy_base_spec.rb', 'manifests/deps.pp', 'manifests/policy/base.pp'], 'web_link': 'https://opendev.org/openstack/puppet-horizon/commit/6baab951c67169d9ad05e55bb0a5b6e11ffb76c1', 'message': 'Add per module policy service refresh\n\nUpdating the policies for this project should only\nrefresh the services that reads it.\n\nChange-Id: I94e1120013aa6e15bbf3aa48a9c29d9943985440\n(cherry picked from commit 7c0c3e4d453b4967ddc74b98d322a61a81305a3a)\n'}]",1,887816,6baab951c67169d9ad05e55bb0a5b6e11ffb76c1,9,3,1,16137,,,0,"Add per module policy service refresh

Updating the policies for this project should only
refresh the services that reads it.

Change-Id: I94e1120013aa6e15bbf3aa48a9c29d9943985440
(cherry picked from commit 7c0c3e4d453b4967ddc74b98d322a61a81305a3a)
",git fetch https://review.opendev.org/openstack/puppet-horizon refs/changes/16/887816/1 && git format-patch -1 --stdout FETCH_HEAD,"['spec/defines/horizon_policy_base_spec.rb', 'manifests/deps.pp', 'manifests/policy/base.pp']",3,6baab951c67169d9ad05e55bb0a5b6e11ffb76c1,per-module-policy-refresh-stable/2023.1," purge_config => $purge_config, tag => 'horizon',", purge_config => $purge_config,5,2
openstack%2Fpuppet-heat~887822,openstack/puppet-heat,stable/2023.1,Ie190999dfdce7fe75bbc1889ec11feda796e226c,Add per module policy service refresh,MERGED,2023-07-06 19:14:37.000000000,2023-07-12 19:12:53.000000000,2023-07-12 19:12:53.000000000,"[{'_account_id': 9816}, {'_account_id': 14985}, {'_account_id': 16137}, {'_account_id': 22348}]","[{'number': 1, 'created': '2023-07-06 19:14:37.000000000', 'files': ['spec/classes/heat_policy_spec.rb', 'manifests/deps.pp', 'manifests/policy.pp'], 'web_link': 'https://opendev.org/openstack/puppet-heat/commit/a9a0182f59128b222a9e5913d1019453d17fa5bc', 'message': 'Add per module policy service refresh\n\nUpdating the policies for this project should only\nrefresh the services that reads it.\n\nChange-Id: Ie190999dfdce7fe75bbc1889ec11feda796e226c\n(cherry picked from commit 41dae27b094581a0037cdf1b5193572e04defdd5)\n'}]",1,887822,a9a0182f59128b222a9e5913d1019453d17fa5bc,11,4,1,16137,,,0,"Add per module policy service refresh

Updating the policies for this project should only
refresh the services that reads it.

Change-Id: Ie190999dfdce7fe75bbc1889ec11feda796e226c
(cherry picked from commit 41dae27b094581a0037cdf1b5193572e04defdd5)
",git fetch https://review.opendev.org/openstack/puppet-heat refs/changes/22/887822/1 && git format-patch -1 --stdout FETCH_HEAD,"['spec/classes/heat_policy_spec.rb', 'manifests/deps.pp', 'manifests/policy.pp']",3,a9a0182f59128b222a9e5913d1019453d17fa5bc,per-module-policy-refresh-stable/2023.1," tag => 'heat',",,4,1
openstack%2Fpuppet-manila~888263,openstack/puppet-manila,master,I36d065587938f7fb49df591c21d0267545d069b3,authtoken: Make password required,MERGED,2023-07-12 13:02:13.000000000,2023-07-12 19:02:59.000000000,2023-07-12 19:02:59.000000000,"[{'_account_id': 14985}, {'_account_id': 21129}, {'_account_id': 22348}]","[{'number': 1, 'created': '2023-07-12 13:02:13.000000000', 'files': ['manifests/keystone/authtoken.pp'], 'web_link': 'https://opendev.org/openstack/puppet-manila/commit/997733a765339c412480620213737ee1ab228ded', 'message': 'authtoken: Make password required\n\nThe password parameter is not really optional. This makes it\na required parameter to give more sensible validation error.\n\nChange-Id: I36d065587938f7fb49df591c21d0267545d069b3\n'}]",0,888263,997733a765339c412480620213737ee1ab228ded,7,3,1,9816,,,0,"authtoken: Make password required

The password parameter is not really optional. This makes it
a required parameter to give more sensible validation error.

Change-Id: I36d065587938f7fb49df591c21d0267545d069b3
",git fetch https://review.opendev.org/openstack/puppet-manila refs/changes/63/888263/1 && git format-patch -1 --stdout FETCH_HEAD,['manifests/keystone/authtoken.pp'],1,997733a765339c412480620213737ee1ab228ded,at-password,"# (Required) Password to create for the service user String[1] $password,","# (Optional) Password to create for the service user # Defaults to $facts['os_service_default'] $password = $facts['os_service_default'], if is_service_default($password) { fail('Please set password for manila service user') } ",2,7
openstack%2Fpuppet-octavia~887823,openstack/puppet-octavia,stable/2023.1,I6cf1abb1645a47eb3afdcdf4d659cea8eb780f68,Add per module policy service refresh,MERGED,2023-07-06 19:14:53.000000000,2023-07-12 19:02:04.000000000,2023-07-12 19:02:04.000000000,"[{'_account_id': 9816}, {'_account_id': 14985}, {'_account_id': 22348}]","[{'number': 1, 'created': '2023-07-06 19:14:53.000000000', 'files': ['spec/classes/octavia_policy_spec.rb', 'manifests/deps.pp', 'manifests/policy.pp'], 'web_link': 'https://opendev.org/openstack/puppet-octavia/commit/1faed322e7ac62f6c989fc9b232fdc95592b1819', 'message': 'Add per module policy service refresh\n\nUpdating the policies for this project should only\nrefresh the services that reads it.\n\nChange-Id: I6cf1abb1645a47eb3afdcdf4d659cea8eb780f68\n(cherry picked from commit 6e17904d674a28f518da18d538ca5c37b15ac52f)\n'}]",2,887823,1faed322e7ac62f6c989fc9b232fdc95592b1819,10,3,1,16137,,,0,"Add per module policy service refresh

Updating the policies for this project should only
refresh the services that reads it.

Change-Id: I6cf1abb1645a47eb3afdcdf4d659cea8eb780f68
(cherry picked from commit 6e17904d674a28f518da18d538ca5c37b15ac52f)
",git fetch https://review.opendev.org/openstack/puppet-octavia refs/changes/23/887823/1 && git format-patch -1 --stdout FETCH_HEAD,"['spec/classes/octavia_policy_spec.rb', 'manifests/deps.pp', 'manifests/policy.pp']",3,1faed322e7ac62f6c989fc9b232fdc95592b1819,per-module-policy-refresh-stable/2023.1," tag => 'octavia',",,4,1
openstack%2Fpuppet-vitrage~887824,openstack/puppet-vitrage,stable/2023.1,Ib1f41d2dcce7c7cd095ac589fbd15cd020c69af3,Add per module policy service refresh,MERGED,2023-07-06 19:15:06.000000000,2023-07-12 18:58:24.000000000,2023-07-12 18:58:24.000000000,"[{'_account_id': 9816}, {'_account_id': 14985}, {'_account_id': 22348}]","[{'number': 1, 'created': '2023-07-06 19:15:06.000000000', 'files': ['manifests/deps.pp', 'spec/classes/vitrage_policy_spec.rb', 'manifests/policy.pp'], 'web_link': 'https://opendev.org/openstack/puppet-vitrage/commit/3edb10323ad65aef24a1b6a96231ef4e9823e776', 'message': 'Add per module policy service refresh\n\nUpdating the policies for this project should only\nrefresh the services that reads it.\n\nChange-Id: Ib1f41d2dcce7c7cd095ac589fbd15cd020c69af3\n(cherry picked from commit a23ca78f52072271de8b3fde16ab280dcf3f938e)\n'}]",2,887824,3edb10323ad65aef24a1b6a96231ef4e9823e776,10,3,1,16137,,,0,"Add per module policy service refresh

Updating the policies for this project should only
refresh the services that reads it.

Change-Id: Ib1f41d2dcce7c7cd095ac589fbd15cd020c69af3
(cherry picked from commit a23ca78f52072271de8b3fde16ab280dcf3f938e)
",git fetch https://review.opendev.org/openstack/puppet-vitrage refs/changes/24/887824/1 && git format-patch -1 --stdout FETCH_HEAD,"['manifests/deps.pp', 'spec/classes/vitrage_policy_spec.rb', 'manifests/policy.pp']",3,3edb10323ad65aef24a1b6a96231ef4e9823e776,per-module-policy-refresh-stable/2023.1," tag => 'vitrage',",,4,1
openstack%2Fcharm-cinder-purestorage~873074,openstack/charm-cinder-purestorage,master,I440b8acad52fb10ea25cc9e055d805e9663f3112,[DNM] Testing 3rd party CI,NEW,2023-02-08 17:44:04.000000000,2023-07-12 18:52:25.000000000,,"[{'_account_id': 13425}, {'_account_id': 20648}, {'_account_id': 22348}]","[{'number': 1, 'created': '2023-02-08 17:44:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-cinder-purestorage/commit/b146c9b69a91f9af01ca87dd6dafb7b74b5b47d8', 'message': '[DNM] Testing 3rd party CI\n\nChange-Id: I440b8acad52fb10ea25cc9e055d805e9663f3112\n'}, {'number': 2, 'created': '2023-02-08 17:51:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-cinder-purestorage/commit/d17c3ad652c1412888c38acef6144a3a3bf35d6e', 'message': '[DNM] Testing 3rd party CI\n\nChange-Id: I440b8acad52fb10ea25cc9e055d805e9663f3112\n'}, {'number': 3, 'created': '2023-05-31 18:17:32.000000000', 'files': ['README.md'], 'web_link': 'https://opendev.org/openstack/charm-cinder-purestorage/commit/650ac4afbedb5fb29449357fd7b42c62a3cd85ef', 'message': '[DNM] Testing 3rd party CI\n\nChange-Id: I440b8acad52fb10ea25cc9e055d805e9663f3112\n'}]",66,873074,650ac4afbedb5fb29449357fd7b42c62a3cd85ef,119,3,3,13425,,,0,"[DNM] Testing 3rd party CI

Change-Id: I440b8acad52fb10ea25cc9e055d805e9663f3112
",git fetch https://review.opendev.org/openstack/charm-cinder-purestorage refs/changes/74/873074/1 && git format-patch -1 --stdout FETCH_HEAD,['README.md'],1,b146c9b69a91f9af01ca87dd6dafb7b74b5b47d8,dnm_1,tox -e py36 # or py36,tox -e py35 # or py36,1,1
openstack%2Fironic~885065,openstack/ironic,stable/train,Ib258bc9650496da989fc93b759b112d279c8b217,Fix Cinder Integration fallout from CVE-2023-2088,MERGED,2023-06-01 15:26:36.000000000,2023-07-12 18:21:09.000000000,2023-07-12 18:17:23.000000000,"[{'_account_id': 10342}, {'_account_id': 11655}, {'_account_id': 22348}]","[{'number': 1, 'created': '2023-06-01 15:26:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/c02fc9ffb40513be471569eedc36fa115541a5b3', 'message': 'Fix Cinder Integration fallout from CVE-2023-2088\n\nIn the recent change to cinder, to address CVE-2023-2088,\ncinder changed the policy rules and behavior for unbinding,\nor ""detaching"" a volume. This was because of a vulnerability\nin compute nodes where a volume which was in use by a VM\ncould be detached outside of Nova, and nova wouldn\'t become\naware the volume was detached, and the volume could be accessible\nto the next VM.\n\nThis vulnerability doesn\'t apply to bare metal operations as\nvolumes are attached to whole baremetal nodes with Ironic.\n\nWe now generate and use a service token when interacting with\nCinder which allows cinder to recognize ""this request is\ncoming from a fellow OpenStack service"", and by-pass\nchecking with Nova if the ""instance"" is managed by Nova,\nor Not. This allows the volumes to be attached, and detached\nas needed as part of the power operation flow and overall\nset of lifecycle operations.\n\nNote: This change is modified from the original upstream chnage\nbecuse that change leverages the ability for a project_id value\nto no longer be required in the cinder URL for interactions with\ncinder, which was a requirement removed in Yoga.\n\nAdditional note: Disables the rescue testing on one of the wallaby\nbranch jobs. Essentially is is a tempest branching, or lack their\nof issue. Master branch ironic-tempest-plugin has a fix\nwhich doesn\'t exist on tempest 29.0.0.\n\nRelated-Bug: 2004555\nCloses-Bug: 2019892\n\nChange-Id: Ib258bc9650496da989fc93b759b112d279c8b217\n(cherry picked from commit 9c0b4c90a19fc1db262a942a1b6a1baafc881ccc)\n(cherry picked from commit cb38746f71f5dfa346371bf06985bbbb2208af6e)\n(cherry picked from commit 9603b8612ee22dffae6e44ef380465e6d1376aed)\n(cherry picked from commit a697f26270389050bf4d2b8eb24d75a80ee50db7)\n'}, {'number': 2, 'created': '2023-06-06 15:28:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/0ddbf12a425806494c3d601743e856f43ffbed22', 'message': 'Fix Cinder Integration fallout from CVE-2023-2088\n\nIn the recent change to cinder, to address CVE-2023-2088,\ncinder changed the policy rules and behavior for unbinding,\nor ""detaching"" a volume. This was because of a vulnerability\nin compute nodes where a volume which was in use by a VM\ncould be detached outside of Nova, and nova wouldn\'t become\naware the volume was detached, and the volume could be accessible\nto the next VM.\n\nThis vulnerability doesn\'t apply to bare metal operations as\nvolumes are attached to whole baremetal nodes with Ironic.\n\nWe now generate and use a service token when interacting with\nCinder which allows cinder to recognize ""this request is\ncoming from a fellow OpenStack service"", and by-pass\nchecking with Nova if the ""instance"" is managed by Nova,\nor Not. This allows the volumes to be attached, and detached\nas needed as part of the power operation flow and overall\nset of lifecycle operations.\n\nNote: This change is modified from the original upstream chnage\nbecuse that change leverages the ability for a project_id value\nto no longer be required in the cinder URL for interactions with\ncinder, which was a requirement removed in Yoga.\n\nAdditional note: Disables the rescue testing on one of the wallaby\nbranch jobs. Essentially is is a tempest branching, or lack their\nof issue. Master branch ironic-tempest-plugin has a fix\nwhich doesn\'t exist on tempest 29.0.0.\n\nAlso fixes an additional unit test for legacy options which did\nnot exist in newer branches.\n\nAlso, also, disables one of the functional API tests since we\'re\nnot making any api changes and it appears time has just resulted\nin them no longer working reliablely in regards to job setup.\n\nRelated-Bug: 2004555\nCloses-Bug: 2019892\n\nChange-Id: Ib258bc9650496da989fc93b759b112d279c8b217\n(cherry picked from commit 9c0b4c90a19fc1db262a942a1b6a1baafc881ccc)\n(cherry picked from commit cb38746f71f5dfa346371bf06985bbbb2208af6e)\n(cherry picked from commit 9603b8612ee22dffae6e44ef380465e6d1376aed)\n(cherry picked from commit 53f933c7fa08b358a2fb15fe25b99fd31ceea627)\n'}, {'number': 3, 'created': '2023-06-07 16:15:50.000000000', 'files': ['ironic/common/keystone.py', 'zuul.d/ironic-jobs.yaml', 'devstack/lib/ironic', 'ironic/common/cinder.py', 'ironic/tests/unit/common/test_cinder.py', 'releasenotes/notes/cinder-2019892-6b5a9de5c5f05aa6.yaml'], 'web_link': 'https://opendev.org/openstack/ironic/commit/d10fd5c4f5c38ad12f9d7cde13c7a06f75942315', 'message': 'Fix Cinder Integration fallout from CVE-2023-2088\n\nIn the recent change to cinder, to address CVE-2023-2088,\ncinder changed the policy rules and behavior for unbinding,\nor ""detaching"" a volume. This was because of a vulnerability\nin compute nodes where a volume which was in use by a VM\ncould be detached outside of Nova, and nova wouldn\'t become\naware the volume was detached, and the volume could be accessible\nto the next VM.\n\nThis vulnerability doesn\'t apply to bare metal operations as\nvolumes are attached to whole baremetal nodes with Ironic.\n\nWe now generate and use a service token when interacting with\nCinder which allows cinder to recognize ""this request is\ncoming from a fellow OpenStack service"", and by-pass\nchecking with Nova if the ""instance"" is managed by Nova,\nor Not. This allows the volumes to be attached, and detached\nas needed as part of the power operation flow and overall\nset of lifecycle operations.\n\nNote: This change is modified from the original upstream chnage\nbecuse that change leverages the ability for a project_id value\nto no longer be required in the cinder URL for interactions with\ncinder, which was a requirement removed in Yoga.\n\nAdditional note: Disables the rescue testing on one of the wallaby\nbranch jobs. Essentially is is a tempest branching, or lack their\nof issue. Master branch ironic-tempest-plugin has a fix\nwhich doesn\'t exist on tempest 29.0.0.\n\nAlso fixes an additional unit test for legacy options which did\nnot exist in newer branches.\n\nRelated-Bug: 2004555\nCloses-Bug: 2019892\n\nChange-Id: Ib258bc9650496da989fc93b759b112d279c8b217\n(cherry picked from commit 9c0b4c90a19fc1db262a942a1b6a1baafc881ccc)\n(cherry picked from commit cb38746f71f5dfa346371bf06985bbbb2208af6e)\n(cherry picked from commit 9603b8612ee22dffae6e44ef380465e6d1376aed)\n(cherry picked from commit 53f933c7fa08b358a2fb15fe25b99fd31ceea627)\n'}]",1,885065,d10fd5c4f5c38ad12f9d7cde13c7a06f75942315,17,3,3,11655,,,0,"Fix Cinder Integration fallout from CVE-2023-2088

In the recent change to cinder, to address CVE-2023-2088,
cinder changed the policy rules and behavior for unbinding,
or ""detaching"" a volume. This was because of a vulnerability
in compute nodes where a volume which was in use by a VM
could be detached outside of Nova, and nova wouldn't become
aware the volume was detached, and the volume could be accessible
to the next VM.

This vulnerability doesn't apply to bare metal operations as
volumes are attached to whole baremetal nodes with Ironic.

We now generate and use a service token when interacting with
Cinder which allows cinder to recognize ""this request is
coming from a fellow OpenStack service"", and by-pass
checking with Nova if the ""instance"" is managed by Nova,
or Not. This allows the volumes to be attached, and detached
as needed as part of the power operation flow and overall
set of lifecycle operations.

Note: This change is modified from the original upstream chnage
becuse that change leverages the ability for a project_id value
to no longer be required in the cinder URL for interactions with
cinder, which was a requirement removed in Yoga.

Additional note: Disables the rescue testing on one of the wallaby
branch jobs. Essentially is is a tempest branching, or lack their
of issue. Master branch ironic-tempest-plugin has a fix
which doesn't exist on tempest 29.0.0.

Also fixes an additional unit test for legacy options which did
not exist in newer branches.

Related-Bug: 2004555
Closes-Bug: 2019892

Change-Id: Ib258bc9650496da989fc93b759b112d279c8b217
(cherry picked from commit 9c0b4c90a19fc1db262a942a1b6a1baafc881ccc)
(cherry picked from commit cb38746f71f5dfa346371bf06985bbbb2208af6e)
(cherry picked from commit 9603b8612ee22dffae6e44ef380465e6d1376aed)
(cherry picked from commit 53f933c7fa08b358a2fb15fe25b99fd31ceea627)
",git fetch https://review.opendev.org/openstack/ironic refs/changes/65/885065/1 && git format-patch -1 --stdout FETCH_HEAD,"['ironic/common/keystone.py', 'devstack/lib/ironic', 'ironic/common/cinder.py', 'ironic/tests/unit/common/test_cinder.py', 'releasenotes/notes/cinder-2019892-6b5a9de5c5f05aa6.yaml']",5,c02fc9ffb40513be471569eedc36fa115541a5b3,,"--- fixes: - | Fixes Ironic integration with Cinder because of changes which resulted as part of the recent Security related fix in `bug 2004555 <https://launchpad.net/bugs/2004555>`_. The work in Ironic to track this fix was logged in `bug 2019892 <https://bugs.launchpad.net/ironic/+bug/2019892>`_. Ironic now sends a service token to Cinder, which allows for access restrictions added as part of the original CVE-2023-2088 fix to be appropriately bypassed. Ironic was not vulnerable, but the restrictions added as a result did impact Ironic's usage. This is because Ironic volume attachments are not on a shared ""compute node"", but instead mapped to the physical machines and Ironic handles the attachment life-cycle after initial attachment. ",,121,43
openstack%2Fironic~885063,openstack/ironic,stable/ussuri,Ib258bc9650496da989fc93b759b112d279c8b217,Fix Cinder Integration fallout from CVE-2023-2088,MERGED,2023-06-01 15:23:39.000000000,2023-07-12 18:20:40.000000000,2023-07-12 18:17:21.000000000,"[{'_account_id': 10342}, {'_account_id': 11655}, {'_account_id': 22348}]","[{'number': 1, 'created': '2023-06-01 15:23:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/a0768a479793e867abb45bd8be07325cae8fd265', 'message': 'Fix Cinder Integration fallout from CVE-2023-2088\n\nIn the recent change to cinder, to address CVE-2023-2088,\ncinder changed the policy rules and behavior for unbinding,\nor ""detaching"" a volume. This was because of a vulnerability\nin compute nodes where a volume which was in use by a VM\ncould be detached outside of Nova, and nova wouldn\'t become\naware the volume was detached, and the volume could be accessible\nto the next VM.\n\nThis vulnerability doesn\'t apply to bare metal operations as\nvolumes are attached to whole baremetal nodes with Ironic.\n\nWe now generate and use a service token when interacting with\nCinder which allows cinder to recognize ""this request is\ncoming from a fellow OpenStack service"", and by-pass\nchecking with Nova if the ""instance"" is managed by Nova,\nor Not. This allows the volumes to be attached, and detached\nas needed as part of the power operation flow and overall\nset of lifecycle operations.\n\nNote: This change is modified from the original upstream chnage\nbecuse that change leverages the ability for a project_id value\nto no longer be required in the cinder URL for interactions with\ncinder, which was a requirement removed in Yoga.\n\nAdditional note: Disables the rescue testing on one of the wallaby\nbranch jobs. Essentially is is a tempest branching, or lack their\nof issue. Master branch ironic-tempest-plugin has a fix\nwhich doesn\'t exist on tempest 29.0.0.\n\nRelated-Bug: 2004555\nCloses-Bug: 2019892\n\nChange-Id: Ib258bc9650496da989fc93b759b112d279c8b217\n(cherry picked from commit 9c0b4c90a19fc1db262a942a1b6a1baafc881ccc)\n(cherry picked from commit cb38746f71f5dfa346371bf06985bbbb2208af6e)\n(cherry picked from commit 9603b8612ee22dffae6e44ef380465e6d1376aed)\n'}, {'number': 2, 'created': '2023-06-01 15:24:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/a697f26270389050bf4d2b8eb24d75a80ee50db7', 'message': 'Fix Cinder Integration fallout from CVE-2023-2088\n\nIn the recent change to cinder, to address CVE-2023-2088,\ncinder changed the policy rules and behavior for unbinding,\nor ""detaching"" a volume. This was because of a vulnerability\nin compute nodes where a volume which was in use by a VM\ncould be detached outside of Nova, and nova wouldn\'t become\naware the volume was detached, and the volume could be accessible\nto the next VM.\n\nThis vulnerability doesn\'t apply to bare metal operations as\nvolumes are attached to whole baremetal nodes with Ironic.\n\nWe now generate and use a service token when interacting with\nCinder which allows cinder to recognize ""this request is\ncoming from a fellow OpenStack service"", and by-pass\nchecking with Nova if the ""instance"" is managed by Nova,\nor Not. This allows the volumes to be attached, and detached\nas needed as part of the power operation flow and overall\nset of lifecycle operations.\n\nNote: This change is modified from the original upstream chnage\nbecuse that change leverages the ability for a project_id value\nto no longer be required in the cinder URL for interactions with\ncinder, which was a requirement removed in Yoga.\n\nAdditional note: Disables the rescue testing on one of the wallaby\nbranch jobs. Essentially is is a tempest branching, or lack their\nof issue. Master branch ironic-tempest-plugin has a fix\nwhich doesn\'t exist on tempest 29.0.0.\n\nRelated-Bug: 2004555\nCloses-Bug: 2019892\n\nChange-Id: Ib258bc9650496da989fc93b759b112d279c8b217\n(cherry picked from commit 9c0b4c90a19fc1db262a942a1b6a1baafc881ccc)\n(cherry picked from commit cb38746f71f5dfa346371bf06985bbbb2208af6e)\n(cherry picked from commit 9603b8612ee22dffae6e44ef380465e6d1376aed)\n'}, {'number': 3, 'created': '2023-06-02 18:10:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/f5d6f834cac7876a8c736435d42b6f55f61517e9', 'message': 'Fix Cinder Integration fallout from CVE-2023-2088\n\nIn the recent change to cinder, to address CVE-2023-2088,\ncinder changed the policy rules and behavior for unbinding,\nor ""detaching"" a volume. This was because of a vulnerability\nin compute nodes where a volume which was in use by a VM\ncould be detached outside of Nova, and nova wouldn\'t become\naware the volume was detached, and the volume could be accessible\nto the next VM.\n\nThis vulnerability doesn\'t apply to bare metal operations as\nvolumes are attached to whole baremetal nodes with Ironic.\n\nWe now generate and use a service token when interacting with\nCinder which allows cinder to recognize ""this request is\ncoming from a fellow OpenStack service"", and by-pass\nchecking with Nova if the ""instance"" is managed by Nova,\nor Not. This allows the volumes to be attached, and detached\nas needed as part of the power operation flow and overall\nset of lifecycle operations.\n\nNote: This change is modified from the original upstream chnage\nbecuse that change leverages the ability for a project_id value\nto no longer be required in the cinder URL for interactions with\ncinder, which was a requirement removed in Yoga.\n\nAdditional note: Disables the rescue testing on one of the wallaby\nbranch jobs. Essentially is is a tempest branching, or lack their\nof issue. Master branch ironic-tempest-plugin has a fix\nwhich doesn\'t exist on tempest 29.0.0.\n\nAlso fixes an additional unit test for legacy options which did\nnot exist in newer branches.\n\nRelated-Bug: 2004555\nCloses-Bug: 2019892\n\nChange-Id: Ib258bc9650496da989fc93b759b112d279c8b217\n(cherry picked from commit 9c0b4c90a19fc1db262a942a1b6a1baafc881ccc)\n(cherry picked from commit cb38746f71f5dfa346371bf06985bbbb2208af6e)\n(cherry picked from commit 9603b8612ee22dffae6e44ef380465e6d1376aed)\n'}, {'number': 4, 'created': '2023-06-06 15:18:52.000000000', 'files': ['ironic/common/keystone.py', 'zuul.d/ironic-jobs.yaml', 'devstack/lib/ironic', 'ironic/common/cinder.py', 'zuul.d/project.yaml', 'ironic/tests/unit/common/test_cinder.py', 'releasenotes/notes/cinder-2019892-6b5a9de5c5f05aa6.yaml'], 'web_link': 'https://opendev.org/openstack/ironic/commit/53f933c7fa08b358a2fb15fe25b99fd31ceea627', 'message': 'Fix Cinder Integration fallout from CVE-2023-2088\n\nIn the recent change to cinder, to address CVE-2023-2088,\ncinder changed the policy rules and behavior for unbinding,\nor ""detaching"" a volume. This was because of a vulnerability\nin compute nodes where a volume which was in use by a VM\ncould be detached outside of Nova, and nova wouldn\'t become\naware the volume was detached, and the volume could be accessible\nto the next VM.\n\nThis vulnerability doesn\'t apply to bare metal operations as\nvolumes are attached to whole baremetal nodes with Ironic.\n\nWe now generate and use a service token when interacting with\nCinder which allows cinder to recognize ""this request is\ncoming from a fellow OpenStack service"", and by-pass\nchecking with Nova if the ""instance"" is managed by Nova,\nor Not. This allows the volumes to be attached, and detached\nas needed as part of the power operation flow and overall\nset of lifecycle operations.\n\nNote: This change is modified from the original upstream chnage\nbecuse that change leverages the ability for a project_id value\nto no longer be required in the cinder URL for interactions with\ncinder, which was a requirement removed in Yoga.\n\nAdditional note: Disables the rescue testing on one of the wallaby\nbranch jobs. Essentially is is a tempest branching, or lack their\nof issue. Master branch ironic-tempest-plugin has a fix\nwhich doesn\'t exist on tempest 29.0.0.\n\nAlso fixes an additional unit test for legacy options which did\nnot exist in newer branches.\n\nAlso, also, disables one of the functional API tests since we\'re\nnot making any api changes and it appears time has just resulted\nin them no longer working reliablely in regards to job setup.\n\nRelated-Bug: 2004555\nCloses-Bug: 2019892\n\nChange-Id: Ib258bc9650496da989fc93b759b112d279c8b217\n(cherry picked from commit 9c0b4c90a19fc1db262a942a1b6a1baafc881ccc)\n(cherry picked from commit cb38746f71f5dfa346371bf06985bbbb2208af6e)\n(cherry picked from commit 9603b8612ee22dffae6e44ef380465e6d1376aed)\n'}]",1,885063,53f933c7fa08b358a2fb15fe25b99fd31ceea627,18,3,4,11655,,,0,"Fix Cinder Integration fallout from CVE-2023-2088

In the recent change to cinder, to address CVE-2023-2088,
cinder changed the policy rules and behavior for unbinding,
or ""detaching"" a volume. This was because of a vulnerability
in compute nodes where a volume which was in use by a VM
could be detached outside of Nova, and nova wouldn't become
aware the volume was detached, and the volume could be accessible
to the next VM.

This vulnerability doesn't apply to bare metal operations as
volumes are attached to whole baremetal nodes with Ironic.

We now generate and use a service token when interacting with
Cinder which allows cinder to recognize ""this request is
coming from a fellow OpenStack service"", and by-pass
checking with Nova if the ""instance"" is managed by Nova,
or Not. This allows the volumes to be attached, and detached
as needed as part of the power operation flow and overall
set of lifecycle operations.

Note: This change is modified from the original upstream chnage
becuse that change leverages the ability for a project_id value
to no longer be required in the cinder URL for interactions with
cinder, which was a requirement removed in Yoga.

Additional note: Disables the rescue testing on one of the wallaby
branch jobs. Essentially is is a tempest branching, or lack their
of issue. Master branch ironic-tempest-plugin has a fix
which doesn't exist on tempest 29.0.0.

Also fixes an additional unit test for legacy options which did
not exist in newer branches.

Also, also, disables one of the functional API tests since we're
not making any api changes and it appears time has just resulted
in them no longer working reliablely in regards to job setup.

Related-Bug: 2004555
Closes-Bug: 2019892

Change-Id: Ib258bc9650496da989fc93b759b112d279c8b217
(cherry picked from commit 9c0b4c90a19fc1db262a942a1b6a1baafc881ccc)
(cherry picked from commit cb38746f71f5dfa346371bf06985bbbb2208af6e)
(cherry picked from commit 9603b8612ee22dffae6e44ef380465e6d1376aed)
",git fetch https://review.opendev.org/openstack/ironic refs/changes/63/885063/1 && git format-patch -1 --stdout FETCH_HEAD,"['ironic/common/keystone.py', 'zuul.d/ironic-jobs.yaml', 'devstack/lib/ironic', 'ironic/common/cinder.py', 'ironic/tests/unit/common/test_cinder.py', 'releasenotes/notes/cinder-2019892-6b5a9de5c5f05aa6.yaml']",6,a0768a479793e867abb45bd8be07325cae8fd265,,"--- fixes: - | Fixes Ironic integration with Cinder because of changes which resulted as part of the recent Security related fix in `bug 2004555 <https://launchpad.net/bugs/2004555>`_. The work in Ironic to track this fix was logged in `bug 2019892 <https://bugs.launchpad.net/ironic/+bug/2019892>`_. Ironic now sends a service token to Cinder, which allows for access restrictions added as part of the original CVE-2023-2088 fix to be appropriately bypassed. Ironic was not vulnerable, but the restrictions added as a result did impact Ironic's usage. This is because Ironic volume attachments are not on a shared ""compute node"", but instead mapped to the physical machines and Ironic handles the attachment life-cycle after initial attachment. ",,129,46
openstack%2Fnova~797725,openstack/nova,master,Ifef629d1c79a4fd2b4c864080bd7a37c2fbd69bf,WIP compute: Avoid calling detach with src connection_info during LM rollback,NEW,2021-06-23 17:19:12.000000000,2023-07-12 18:15:42.000000000,,"[{'_account_id': 10135}, {'_account_id': 22348}]","[{'number': 1, 'created': '2021-06-23 17:19:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/d8975b80433373da71bc0d506dfd64bd62e3da69', 'message': 'WIP compute: Avoid calling detach with src connection_info during LM rollback\n\nWhen rolling back from an early pre_live_migration failure Nova would\npreviously attempt to detach volumes from the destination using the\nconnection_info associated with the source.\n\nThis can lead to failures being logged (and ignored since ) by certain\nvirt drivers as this connection_info could point to a different\nunderlying volume on the destination.\n\nThis change seeks to avoid such attempts by nulling out the\nconnection_info of the block device mapping records *after* stashing a\ncopy to use if we rollback but *before* calling pre_live_migration on\nthe destination. This allows us to later check if any connection_info is\nset in the block device mapping record before attempting to detach\nduring a rollback, before the original connection info is then restored.\n\nThe previously written functional test is extended to assert that\nthe original connection_info is restored after the rollback.\n\nCloses-Bug: #1899835\nChange-Id: Ifef629d1c79a4fd2b4c864080bd7a37c2fbd69bf\n'}, {'number': 2, 'created': '2021-06-24 09:38:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/c29817c162babe30b9a6dc14bde6ffbd407f09e9', 'message': 'compute: Avoid calling detach with src connection_info during LM rollback\n\nWhen rolling back from an early pre_live_migration failure Nova would\npreviously attempt to detach volumes from the destination using the\nconnection_info associated with the source.\n\nThis can lead to failures being logged (and ignored since ) by certain\nvirt drivers as this connection_info could point to a different\nunderlying volume on the destination.\n\nThis change seeks to avoid such attempts by nulling out the\nconnection_info of the block device mapping records *after* stashing a\ncopy to use if we rollback but *before* calling pre_live_migration on\nthe destination. This allows us to later check if any connection_info is\nset in the block device mapping record before attempting to detach\nduring a rollback, before the original connection info is then restored.\n\nThe previously written functional test is extended to assert that\nthe original connection_info is restored after the rollback.\n\nCloses-Bug: #1899835\nChange-Id: Ifef629d1c79a4fd2b4c864080bd7a37c2fbd69bf\n'}, {'number': 3, 'created': '2021-06-24 09:42:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/f80832e2608b0e02a90fce98c7d275d87f4d74b3', 'message': 'compute: Avoid calling detach with src connection_info during LM rollback\n\nWhen rolling back from an early pre_live_migration failure Nova would\npreviously attempt to detach volumes from the destination using the\nconnection_info associated with the source.\n\nThis can lead to failures being logged (and ignored since\nI6bc73e8c8f98d9955f33f309beb8a7c56981b553) by certain virt drivers and\nvolume backends as this connection_info could either point to a\ndifferent underlying volume on the destination when compared to the\nsource or nothing at all on the destination.\n\nThis change seeks to avoid such attempts by nulling out the\nconnection_info of the block device mapping records *after* stashing a\ncopy to use if we rollback but *before* calling pre_live_migration on\nthe destination. This allows us to later check if any connection_info is\nset in the block device mapping record before attempting to detach on\nthe destination during a rollback, before the original connection info\nis then restored for use on the source.\n\nThe previously written functional test is extended to assert that\nthe original connection_info is restored after the rollback.\n\nCloses-Bug: #1899835\nChange-Id: Ifef629d1c79a4fd2b4c864080bd7a37c2fbd69bf\n'}, {'number': 4, 'created': '2021-06-25 09:00:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/c18c01b041b0eb47ac7f36e0d9cd39845ebcd571', 'message': ""compute: Avoid calling detach with src connection_info during LM rollback\n\nWhen rolling back from an early pre_live_migration failure Nova would\npreviously attempt to detach volumes from the destination using the\nconnection_info associated with the source.\n\nThis can lead to failures being logged (and ignored since\nI6bc73e8c8f98d9955f33f309beb8a7c56981b553) by certain virt drivers and\nvolume backends as this connection_info could either point to a\ndifferent underlying volume on the destination when compared to the\nsource or nothing at all on the destination.\n\nThis change seeks to avoid such attempts by nulling out the\nconnection_info of the block device mapping records *after* stashing a\ncopy to use if we rollback but *before* calling pre_live_migration on\nthe destination. This allows us to later check if any connection_info is\nset in the block device mapping record before attempting to detach on\nthe destination during a rollback, before the original connection_info\nis then restored for use on the source.\n\nTo allow this we need to remove an old untested optimisation added by\nIf961329061e5413824d891eada645dd8dd9cb6dd within the\nrefresh_connection_info method of the DriverVolumeBlockDevice class that\nwould skip a refresh when connection_info is unset. We obviously need\nthis to happen still during pre_live_migration to ensure the fresh\nconnection_info for the destination is used to initially connect any\nvolumes. The removal of this optimisation shouldn't have any knock on\neffects as all callers expect connection_info to already be set aside\nfrom pre_live_migration with the newly introduced logic above.\n\nFinally, the previously written functional test is extended to assert\nthat the original connection_info is restored after the rollback.\n\nCloses-Bug: #1899835\nChange-Id: Ifef629d1c79a4fd2b4c864080bd7a37c2fbd69bf\n""}, {'number': 5, 'created': '2021-08-12 14:06:36.000000000', 'files': ['nova/objects/migrate_data.py', 'nova/tests/functional/regressions/test_bug_1899835.py', 'nova/tests/unit/compute/test_compute_mgr.py', 'nova/virt/libvirt/driver.py', 'nova/compute/manager.py', 'nova/virt/block_device.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/723f357c059c6075f38d339b586f5322987c91b7', 'message': ""WIP compute: Avoid calling detach with src connection_info during LM rollback\n\nWhen rolling back from an early pre_live_migration failure Nova would\npreviously attempt to detach volumes from the destination using the\nconnection_info associated with the source.\n\nThis can lead to failures being logged (and ignored since\nI6bc73e8c8f98d9955f33f309beb8a7c56981b553) by certain virt drivers and\nvolume backends as this connection_info could either point to a\ndifferent underlying volume on the destination when compared to the\nsource or nothing at all on the destination.\n\nThis change seeks to avoid such attempts by nulling out the\nconnection_info of the block device mapping records *after* stashing a\ncopy to use if we rollback but *before* calling pre_live_migration on\nthe destination. This allows us to later check if any connection_info is\nset in the block device mapping record before attempting to detach on\nthe destination during a rollback, before the original connection_info\nis then restored for use on the source.\n\nTo allow this we need to remove an old untested optimisation added by\nIf961329061e5413824d891eada645dd8dd9cb6dd within the\nrefresh_connection_info method of the DriverVolumeBlockDevice class that\nwould skip a refresh when connection_info is unset. We obviously need\nthis to happen still during pre_live_migration to ensure the fresh\nconnection_info for the destination is used to initially connect any\nvolumes. The removal of this optimisation shouldn't have any knock on\neffects as all callers expect connection_info to already be set aside\nfrom pre_live_migration with the newly introduced logic above.\n\nLibvirtLiveMigrateData is extended to allow the destination host of a\nlive migration to indicate if it supports the above logic, otherwise the\nconnection_info will not be unset and the previous behaviour will be\nused. This is required in order to support live migrations between N and\nN-1 computes where the latter doesn't support the new behaviour.\n\nFinally, the previously written functional test is extended to assert\nthat the original connection_info is restored after the rollback.\n\nCloses-Bug: #1899835\nChange-Id: Ifef629d1c79a4fd2b4c864080bd7a37c2fbd69bf\n""}]",2,797725,723f357c059c6075f38d339b586f5322987c91b7,32,2,5,10135,,,0,"WIP compute: Avoid calling detach with src connection_info during LM rollback

When rolling back from an early pre_live_migration failure Nova would
previously attempt to detach volumes from the destination using the
connection_info associated with the source.

This can lead to failures being logged (and ignored since
I6bc73e8c8f98d9955f33f309beb8a7c56981b553) by certain virt drivers and
volume backends as this connection_info could either point to a
different underlying volume on the destination when compared to the
source or nothing at all on the destination.

This change seeks to avoid such attempts by nulling out the
connection_info of the block device mapping records *after* stashing a
copy to use if we rollback but *before* calling pre_live_migration on
the destination. This allows us to later check if any connection_info is
set in the block device mapping record before attempting to detach on
the destination during a rollback, before the original connection_info
is then restored for use on the source.

To allow this we need to remove an old untested optimisation added by
If961329061e5413824d891eada645dd8dd9cb6dd within the
refresh_connection_info method of the DriverVolumeBlockDevice class that
would skip a refresh when connection_info is unset. We obviously need
this to happen still during pre_live_migration to ensure the fresh
connection_info for the destination is used to initially connect any
volumes. The removal of this optimisation shouldn't have any knock on
effects as all callers expect connection_info to already be set aside
from pre_live_migration with the newly introduced logic above.

LibvirtLiveMigrateData is extended to allow the destination host of a
live migration to indicate if it supports the above logic, otherwise the
connection_info will not be unset and the previous behaviour will be
used. This is required in order to support live migrations between N and
N-1 computes where the latter doesn't support the new behaviour.

Finally, the previously written functional test is extended to assert
that the original connection_info is restored after the rollback.

Closes-Bug: #1899835
Change-Id: Ifef629d1c79a4fd2b4c864080bd7a37c2fbd69bf
",git fetch https://review.opendev.org/openstack/nova refs/changes/25/797725/1 && git format-patch -1 --stdout FETCH_HEAD,"['nova/tests/functional/regressions/test_bug_1899835.py', 'nova/compute/manager.py']",2,d8975b80433373da71bc0d506dfd64bd62e3da69,bug/1899835," # NOTE(lyarwood): We might be calling this during # _rollback_live_migration after an early failure in # pre_live_migration *before* the destination has populated the bdm # with fresh connection_info, in that case the volume isn't # attached on the dest so we can skip this. if bdm.connection_info is None: return # NOTE(lyarwood): Now that we have a copy of the original bdms we can # null out the connection_info of the records in the database to ensure # any rollback does not attempt to use the connection_info of the # source on the destination. bdms = objects.BlockDeviceMappingList.get_by_instance_uuid( context, instance.uuid) for bdm in bdms: if bdm.is_volume: bdm.connection_info = None bdm.save() ",,27,6
openstack%2Fpyeclib~888175,openstack/pyeclib,master,I298000d12dbf3e702e00c9e8d754c86ee077cd32,Test under py311,MERGED,2023-07-11 19:35:46.000000000,2023-07-12 17:59:12.000000000,2023-07-12 17:59:12.000000000,"[{'_account_id': 15343}, {'_account_id': 22348}]","[{'number': 1, 'created': '2023-07-11 19:35:46.000000000', 'files': ['.zuul.yaml'], 'web_link': 'https://opendev.org/openstack/pyeclib/commit/41ae583b1e6108b3100ecb8ed40651d5f0a49a77', 'message': 'Test under py311\n\nChange-Id: I298000d12dbf3e702e00c9e8d754c86ee077cd32\n'}]",1,888175,41ae583b1e6108b3100ecb8ed40651d5f0a49a77,12,2,1,15343,,,0,"Test under py311

Change-Id: I298000d12dbf3e702e00c9e8d754c86ee077cd32
",git fetch https://review.opendev.org/openstack/pyeclib refs/changes/75/888175/1 && git format-patch -1 --stdout FETCH_HEAD,['.zuul.yaml'],1,41ae583b1e6108b3100ecb8ed40651d5f0a49a77,, - pyeclib-tox-py311 - pyeclib-tox-py311- job: name: pyeclib-tox-py311 parent: openstack-tox-py310 vars: tox_envlist: py311 bindep_profile: test py311 python_version: '3.11' ,,10,0
openstack%2Fbarbican~880817,openstack/barbican,master,Iabb28d3c5acfe3cfba88cfd650cb0ab97a2368fa,tests: Enable SQLAlchemy 2.0 deprecation warnings,ABANDONED,2023-04-19 11:41:48.000000000,2023-07-12 17:30:43.000000000,,[{'_account_id': 22348}],"[{'number': 1, 'created': '2023-04-19 11:41:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/barbican/commit/f27acb2dade0dd29085fd75361b05528fe0ee213', 'message': ""tests: Enable SQLAlchemy 2.0 deprecation warnings\n\nSo we can prepare for it. We disable the ones we're currently hitting.\n\nChange-Id: Iabb28d3c5acfe3cfba88cfd650cb0ab97a2368fa\nSigned-off-by: Stephen Finucane <stephenfin@redhat.com>\n""}, {'number': 2, 'created': '2023-06-27 10:29:15.000000000', 'files': ['barbican/tests/fixture.py', 'tox.ini'], 'web_link': 'https://opendev.org/openstack/barbican/commit/756794dfe8b416779a8ef6de5c80b4f7e84dbd97', 'message': ""tests: Enable SQLAlchemy 2.0 deprecation warnings\n\nSo we can prepare for it. We disable the ones we're currently hitting.\n\nChange-Id: Iabb28d3c5acfe3cfba88cfd650cb0ab97a2368fa\nSigned-off-by: Stephen Finucane <stephenfin@redhat.com>\n""}]",2,880817,756794dfe8b416779a8ef6de5c80b4f7e84dbd97,5,1,2,15334,,,0,"tests: Enable SQLAlchemy 2.0 deprecation warnings

So we can prepare for it. We disable the ones we're currently hitting.

Change-Id: Iabb28d3c5acfe3cfba88cfd650cb0ab97a2368fa
Signed-off-by: Stephen Finucane <stephenfin@redhat.com>
",git fetch https://review.opendev.org/openstack/barbican refs/changes/17/880817/1 && git format-patch -1 --stdout FETCH_HEAD,"['barbican/tests/fixture.py', 'tox.ini']",2,f27acb2dade0dd29085fd75361b05528fe0ee213,sqlalchemy-20,# TODO(stephenfin): Remove once we bump our upper-constraint to SQLAlchemy 2.0 SQLALCHEMY_WARN_20=1,,36,0
openstack%2Fdiskimage-builder~881298,openstack/diskimage-builder,master,I2dd1c60e3bfd9c823a7382b1390b1d40c52a5c97,Extend the checksum files generation procedure,MERGED,2023-04-23 19:44:07.000000000,2023-07-12 17:23:58.000000000,2023-07-12 17:22:57.000000000,"[{'_account_id': 4146}, {'_account_id': 4571}, {'_account_id': 7118}, {'_account_id': 11655}, {'_account_id': 14200}, {'_account_id': 22348}]","[{'number': 1, 'created': '2023-04-23 19:44:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/diskimage-builder/commit/aaf46a142bbcd2571ca1f40a706f6bf6579a8518', 'message': 'Extend the DIB_CHECKSUM variable usage\n\nThe usage of the ``DIB_CHECKSUM`` variable is extended. Now to be more\nspecific the variable can be set tp the ``sha256`` or ``md5`` value to\ngenerate the only one checksum file specified.\n\nChange-Id: I2dd1c60e3bfd9c823a7382b1390b1d40c52a5c97\nSigned-off-by: Maksim Malchuk <maksim.malchuk@gmail.com>\n'}, {'number': 2, 'created': '2023-04-23 19:57:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/diskimage-builder/commit/179fc456291dfe9376418f7a0bf0ee765b8e4d83', 'message': 'Extend the DIB_CHECKSUM variable usage\n\nThe usage of the ``DIB_CHECKSUM`` variable is extended. Now to be more\nspecific the variable can be set tp the ``sha256`` or ``md5`` value to\ngenerate the only one checksum file specified.\n\nChange-Id: I2dd1c60e3bfd9c823a7382b1390b1d40c52a5c97\nSigned-off-by: Maksim Malchuk <maksim.malchuk@gmail.com>\n'}, {'number': 3, 'created': '2023-04-23 22:33:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/diskimage-builder/commit/056bab5eeed3b992390adde765397ea83f661289', 'message': 'Extend the DIB_CHECKSUM variable usage\n\nThe usage of the ``DIB_CHECKSUM`` variable is extended. Now to be more\nspecific the variable can be set tp the ``sha256`` or ``md5`` value to\ngenerate the only one checksum file specified.\n\nChange-Id: I2dd1c60e3bfd9c823a7382b1390b1d40c52a5c97\nSigned-off-by: Maksim Malchuk <maksim.malchuk@gmail.com>\n'}, {'number': 4, 'created': '2023-04-26 11:38:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/diskimage-builder/commit/b0376aa7a1b42c768e7f9734d70590e25df24eb9', 'message': 'Extend the checksum files generation procedure\n\nThe usage of the ``DIB_CHECKSUM`` variable is extended. Now to be more\nspecific the variable can be set tp the ``sha256`` or ``md5`` value to\ngenerate the only one checksum file specified. Also the corresponding\ncommand line options ``--checksum-sha256`` and ``--checksum-md5`` are\nadded.\n\nChange-Id: I2dd1c60e3bfd9c823a7382b1390b1d40c52a5c97\nSigned-off-by: Maksim Malchuk <maksim.malchuk@gmail.com>\n'}, {'number': 5, 'created': '2023-05-24 20:34:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/diskimage-builder/commit/e2651ff88170631782dcee6f3e9042fbc5b4bb60', 'message': 'Extend the checksum files generation procedure\n\nThe usage of the ``DIB_CHECKSUM`` variable is extended. Now to be more\nspecific the variable can be set to the ``sha256`` or ``md5`` value to\ngenerate only one checksum file. There also can be provided a\ncomma-separated list of the values, but only ``sha256`` and ``md5``\nsupported. For backward compatibility using ``DIB_CHECKSUM=1`` or option\n``--checksum`` in the command line still can be used to generate all\nsupported checksums.\n\nChange-Id: I2dd1c60e3bfd9c823a7382b1390b1d40c52a5c97\nSigned-off-by: Maksim Malchuk <maksim.malchuk@gmail.com>\n'}, {'number': 6, 'created': '2023-05-24 20:43:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/diskimage-builder/commit/14faaee7766211de57a15786bc35b0ee34a08b01', 'message': 'Extend the checksum files generation procedure\n\nThe usage of the ``DIB_CHECKSUM`` variable is extended. Now to be more\nspecific the variable can be set to the ``sha256`` or ``md5`` value to\ngenerate only one checksum file. There also can be provided a\ncomma-separated list of the values, but only ``sha256`` and ``md5``\nsupported. For backward compatibility using ``DIB_CHECKSUM=1`` or option\n``--checksum`` in the command line still can be used to generate all\nsupported checksums.\n\nChange-Id: I2dd1c60e3bfd9c823a7382b1390b1d40c52a5c97\nSigned-off-by: Maksim Malchuk <maksim.malchuk@gmail.com>\n'}, {'number': 7, 'created': '2023-05-27 20:50:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/diskimage-builder/commit/9dabe73df2b4b39a54326b1bbb958b74857dcb09', 'message': 'Extend the checksum files generation procedure\n\nThe usage of the ``DIB_CHECKSUM`` variable is extended. Now to be more\nspecific the variable can be set to the ``sha256`` or ``md5`` value to\ngenerate only one checksum file. There also can be provided a\ncomma-separated list of the values, but only ``sha256`` and ``md5``\nsupported. For backward compatibility using ``DIB_CHECKSUM=1`` or option\n``--checksum`` in the command line still can be used to generate all\nsupported checksums.\n\nChange-Id: I2dd1c60e3bfd9c823a7382b1390b1d40c52a5c97\nSigned-off-by: Maksim Malchuk <maksim.malchuk@gmail.com>\n'}, {'number': 8, 'created': '2023-05-28 07:38:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/diskimage-builder/commit/b25d7377c155907e1b3302f82026877ce7f44581', 'message': 'Extend the checksum files generation procedure\n\nThe usage of the ``DIB_CHECKSUM`` variable is extended. Now to be more\nspecific the variable can be set to the ``sha256`` or ``md5`` value to\ngenerate only one checksum file. There also can be provided a\ncomma-separated list of the values, but only ``sha256`` and ``md5``\nsupported. For backward compatibility using ``DIB_CHECKSUM=1`` or option\n``--checksum`` in the command line still can be used to generate all\nsupported checksums.\n\nChange-Id: I2dd1c60e3bfd9c823a7382b1390b1d40c52a5c97\nSigned-off-by: Maksim Malchuk <maksim.malchuk@gmail.com>\n'}, {'number': 9, 'created': '2023-05-29 11:00:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/diskimage-builder/commit/f0487411a8cb7c83df4aff0851ac7cb394ba4355', 'message': 'Extend the checksum files generation procedure\n\nThe usage of the ``DIB_CHECKSUM`` variable is extended. Now to be more\nspecific the variable can be set to the ``sha256`` or ``md5`` value to\ngenerate only one checksum file. There also can be provided a\ncomma-separated list of the values, but only ``sha256`` and ``md5``\nsupported. For backward compatibility using ``DIB_CHECKSUM=1`` or option\n``--checksum`` in the command line still can be used to generate all\nsupported checksums.\n\nChange-Id: I2dd1c60e3bfd9c823a7382b1390b1d40c52a5c97\nSigned-off-by: Maksim Malchuk <maksim.malchuk@gmail.com>\n'}, {'number': 10, 'created': '2023-05-29 12:58:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/diskimage-builder/commit/ac0ec76013962f911a004208d8c00e7480176536', 'message': 'Extend the checksum files generation procedure\n\nThe usage of the ``DIB_CHECKSUM`` variable is extended. Now to be more\nspecific the variable can be set to the ``sha256`` or ``md5`` value to\ngenerate only one checksum file. There also can be provided a\ncomma-separated list of the values, but only ``sha256`` and ``md5``\nsupported. For backward compatibility using ``DIB_CHECKSUM=1`` or option\n``--checksum`` in the command line still can be used to generate all\nsupported checksums.\n\nChange-Id: I2dd1c60e3bfd9c823a7382b1390b1d40c52a5c97\nSigned-off-by: Maksim Malchuk <maksim.malchuk@gmail.com>\n'}, {'number': 11, 'created': '2023-05-30 15:37:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/diskimage-builder/commit/4c99fcf90fee6f0137ef9ccd70cbfd2c5df8554f', 'message': 'Extend the checksum files generation procedure\n\nThe usage of the ``DIB_CHECKSUM`` variable is extended. Now to be more\nspecific the variable can be set to the ``sha256`` or ``md5`` value to\ngenerate only one checksum file. There also can be provided a\ncomma-separated list of the values, but only ``sha256`` and ``md5``\nsupported. For backward compatibility using ``DIB_CHECKSUM=1`` or option\n``--checksum`` in the command line still can be used to generate all\nsupported checksums.\n\nChange-Id: I2dd1c60e3bfd9c823a7382b1390b1d40c52a5c97\nSigned-off-by: Maksim Malchuk <maksim.malchuk@gmail.com>\n'}, {'number': 12, 'created': '2023-05-30 19:31:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/diskimage-builder/commit/246a1ba74fa7e00949e02df277ee7463f3de7590', 'message': 'Extend the checksum files generation procedure\n\nThe usage of the ``DIB_CHECKSUM`` variable is extended. Now to be more\nspecific the variable can be set to the ``sha256`` or ``md5`` value to\ngenerate only one checksum file. There also can be provided a\ncomma-separated list of the values, but only ``sha256`` and ``md5``\nsupported. For backward compatibility using ``DIB_CHECKSUM=1`` or option\n``--checksum`` in the command line still can be used to generate all\nsupported checksums.\n\nChange-Id: I2dd1c60e3bfd9c823a7382b1390b1d40c52a5c97\nSigned-off-by: Maksim Malchuk <maksim.malchuk@gmail.com>\n'}, {'number': 13, 'created': '2023-05-30 20:02:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/diskimage-builder/commit/9d261bd9192e3acfd1b62e4d5366a56f47f4451a', 'message': 'Extend the checksum files generation procedure\n\nThe usage of the ``DIB_CHECKSUM`` variable is extended. Now to be more\nspecific the variable can be set to the ``sha256`` or ``md5`` value to\ngenerate only one checksum file. There also can be provided a\ncomma-separated list of the values, but only ``sha256`` and ``md5``\nsupported. For backward compatibility using ``DIB_CHECKSUM=1`` or option\n``--checksum`` in the command line still can be used to generate all\nsupported checksums.\n\nChange-Id: I2dd1c60e3bfd9c823a7382b1390b1d40c52a5c97\nSigned-off-by: Maksim Malchuk <maksim.malchuk@gmail.com>\n'}, {'number': 14, 'created': '2023-07-08 17:20:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/diskimage-builder/commit/25806bdbfc4d8dd1c630350399dfa062a0753bf6', 'message': 'Extend the checksum files generation procedure\n\nThe usage of the ``DIB_CHECKSUM`` variable is extended to have an ability\ngenerate the only one checksum file, for example only ``sha256`` (by setting\nan environment variable ``DIB_CHECKSUM=sha256``), and to retain the backward\ncompatibility (``DIB_CHECKSUM=1`` will generate both ``sha256`` and ``md5``\nsupported at this moment). As an additional feature we have the simple way to\ncompletely deprecate ``md5`` later, and add new methods, for example,\n``sha512`` etc.\n\nChange-Id: I2dd1c60e3bfd9c823a7382b1390b1d40c52a5c97\nSigned-off-by: Maksim Malchuk <maksim.malchuk@gmail.com>\n'}, {'number': 15, 'created': '2023-07-08 17:21:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/diskimage-builder/commit/4178c9441c7fbeff29c3be9d4e34b5a9943f70e9', 'message': 'Extend the checksum files generation procedure\n\nThe usage of the ``DIB_CHECKSUM`` variable is extended to have an\nability generate the only one checksum file, for example only ``sha256``\n(by setting an environment variable ``DIB_CHECKSUM=sha256``), and to retain\nthe backward compatibility (``DIB_CHECKSUM=1`` will generate both ``sha256``\nand ``md5`` supported at this moment). As an additional feature we have the\nsimple way to completely deprecate ``md5`` later, and add new methods,\nfor example, ``sha512`` etc.\n\nChange-Id: I2dd1c60e3bfd9c823a7382b1390b1d40c52a5c97\nSigned-off-by: Maksim Malchuk <maksim.malchuk@gmail.com>\n'}, {'number': 16, 'created': '2023-07-08 17:23:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/diskimage-builder/commit/27593c37f2f2f37a07cf16917ae1bec3aada9c12', 'message': 'Extend the checksum files generation procedure\n\nThe usage of the ``DIB_CHECKSUM`` variable is extended to have an\nability generate the only one checksum file, for example only ``sha256``\n(by setting an environment variable ``DIB_CHECKSUM=sha256``), and to\nretain the backward compatibility (``DIB_CHECKSUM=1`` will generate\nboth ``sha256`` and ``md5`` supported at this moment). As an additional\nfeature we have the simple way to completely deprecate ``md5`` later, and\nadd new methods, for example, ``sha512`` etc.\n\nChange-Id: I2dd1c60e3bfd9c823a7382b1390b1d40c52a5c97\nSigned-off-by: Maksim Malchuk <maksim.malchuk@gmail.com>\n'}, {'number': 17, 'created': '2023-07-08 17:23:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/diskimage-builder/commit/f9d617fd807eea784c0e3b05a76a3547ba1b8928', 'message': 'Extend the checksum files generation procedure\n\nThe usage of the ``DIB_CHECKSUM`` variable is extended to have an\nability generate the only one checksum file, for example only ``sha256``\n(by setting an environment variable ``DIB_CHECKSUM=sha256``), and to\nretain the backward compatibility (``DIB_CHECKSUM=1`` will generate\nboth ``sha256`` and ``md5`` supported at this moment). As an additional\nfeature we have the simple way to completely deprecate ``md5`` later,\nand add new methods, for example, ``sha512`` etc.\n\nChange-Id: I2dd1c60e3bfd9c823a7382b1390b1d40c52a5c97\nSigned-off-by: Maksim Malchuk <maksim.malchuk@gmail.com>\n'}, {'number': 18, 'created': '2023-07-08 17:25:23.000000000', 'files': ['releasenotes/notes/dib-checksum-3d0d9af8778176be.yaml', 'diskimage_builder/lib/common-functions'], 'web_link': 'https://opendev.org/openstack/diskimage-builder/commit/43e47f1912ce07e65181355d4f5c52298a8fba28', 'message': ""Extend the checksum files generation procedure\n\nThe usage of the DIB_CHECKSUM variable is extended to have an\nability generate the only one checksum file, for example only 'sha256'\n(by setting an environment variable DIB_CHECKSUM='sha256'), and to\nretain the backward compatibility (DIB_CHECKSUM=1 will generate\nboth 'sha256' and 'md5' supported at this moment). As an additional\nfeature we have the simple way to completely deprecate 'md5' later,\nand add new methods, for example, 'sha512' etc.\n\nChange-Id: I2dd1c60e3bfd9c823a7382b1390b1d40c52a5c97\nSigned-off-by: Maksim Malchuk <maksim.malchuk@gmail.com>\n""}]",36,881298,43e47f1912ce07e65181355d4f5c52298a8fba28,110,6,18,14200,,,0,"Extend the checksum files generation procedure

The usage of the DIB_CHECKSUM variable is extended to have an
ability generate the only one checksum file, for example only 'sha256'
(by setting an environment variable DIB_CHECKSUM='sha256'), and to
retain the backward compatibility (DIB_CHECKSUM=1 will generate
both 'sha256' and 'md5' supported at this moment). As an additional
feature we have the simple way to completely deprecate 'md5' later,
and add new methods, for example, 'sha512' etc.

Change-Id: I2dd1c60e3bfd9c823a7382b1390b1d40c52a5c97
Signed-off-by: Maksim Malchuk <maksim.malchuk@gmail.com>
",git fetch https://review.opendev.org/openstack/diskimage-builder refs/changes/98/881298/1 && git format-patch -1 --stdout FETCH_HEAD,"['releasenotes/notes/dib-checksum-3d0d9af8778176be.yaml', 'diskimage_builder/lib/common-functions']",2,aaf46a142bbcd2571ca1f40a706f6bf6579a8518,extend-dib-checksum," if [ -n ""$DIB_CHECKSUM"" ]; then [ ""$DIB_CHECKSUM"" == ""sha256"" ] || md5sum $1 > $1.md5 & wait_for+=($!) [ ""$DIB_CHECKSUM"" == ""md5""] || sha256sum $1 > $1.sha256 & wait_for+=($!)"," if [ ""$DIB_CHECKSUM"" == ""1"" ]; then md5sum $1 > $1.md5 & wait_for+=($!) sha256sum $1 > $1.sha256 & wait_for+=($!)",11,3
openstack%2Foctavia~887482,openstack/octavia,stable/wallaby,Ie611ba9fde7b399989d847dd0c61dd3a158652bc,Fix TCP HMs on UDP pools with SELinux,MERGED,2023-07-03 08:27:29.000000000,2023-07-12 17:19:01.000000000,2023-07-12 17:17:27.000000000,"[{'_account_id': 11628}, {'_account_id': 22348}]","[{'number': 1, 'created': '2023-07-03 08:27:29.000000000', 'files': ['elements/amphora-selinux/post-install.d/50-selinux-policies', 'releasenotes/notes/fix-selinux-tcp-hm-on-udp-pools-89c3b8db89e359ba.yaml'], 'web_link': 'https://opendev.org/openstack/octavia/commit/168a04ef3033f3b50af2d223bd9a5cb055cea49d', 'message': 'Fix TCP HMs on UDP pools with SELinux\n\nSELinux denied some specific TCP ports when using TCP-based HMs in UDP\npools (keepalived).\nEnable a SELinux boolean keepalived_connect_any which allows keepalived\nto connect to any port.\n\nCloses-Bug: #2023751\nChange-Id: Ie611ba9fde7b399989d847dd0c61dd3a158652bc\n(cherry picked from commit 294bd406f312984ee3029b301727d78caf7aea1d)\n(cherry picked from commit c0ceebebbfcf254e5f7b58f18208392260795259)\n(cherry picked from commit 4d52ce9c5c82c57690fdeacc44462e4822b80aea)\n(cherry picked from commit da9dc1230ea5eee46a13a0367bdf53ab1f34f917)\n(cherry picked from commit 3f1dc2012dabc718ca7833fdbb2c7a4ad5d65b1a)\n'}]",1,887482,168a04ef3033f3b50af2d223bd9a5cb055cea49d,7,2,1,29244,,,0,"Fix TCP HMs on UDP pools with SELinux

SELinux denied some specific TCP ports when using TCP-based HMs in UDP
pools (keepalived).
Enable a SELinux boolean keepalived_connect_any which allows keepalived
to connect to any port.

Closes-Bug: #2023751
Change-Id: Ie611ba9fde7b399989d847dd0c61dd3a158652bc
(cherry picked from commit 294bd406f312984ee3029b301727d78caf7aea1d)
(cherry picked from commit c0ceebebbfcf254e5f7b58f18208392260795259)
(cherry picked from commit 4d52ce9c5c82c57690fdeacc44462e4822b80aea)
(cherry picked from commit da9dc1230ea5eee46a13a0367bdf53ab1f34f917)
(cherry picked from commit 3f1dc2012dabc718ca7833fdbb2c7a4ad5d65b1a)
",git fetch https://review.opendev.org/openstack/octavia refs/changes/82/887482/1 && git format-patch -1 --stdout FETCH_HEAD,"['elements/amphora-selinux/post-install.d/50-selinux-policies', 'releasenotes/notes/fix-selinux-tcp-hm-on-udp-pools-89c3b8db89e359ba.yaml']",2,168a04ef3033f3b50af2d223bd9a5cb055cea49d,,"--- fixes: - | Fixed an SELinux issues with TCP-based health-monitor on UDP pools, some specific monitoring ports were denied by SELinux. The Amphora image now enables the ``keepalived_connect_any`` SELinux boolean that allows connections to any ports. ",,10,0
openstack%2Foctavia~887480,openstack/octavia,stable/yoga,Ie611ba9fde7b399989d847dd0c61dd3a158652bc,Fix TCP HMs on UDP pools with SELinux,MERGED,2023-07-03 08:26:57.000000000,2023-07-12 17:18:49.000000000,2023-07-12 17:17:26.000000000,"[{'_account_id': 11628}, {'_account_id': 22348}]","[{'number': 1, 'created': '2023-07-03 08:26:57.000000000', 'files': ['elements/amphora-selinux/post-install.d/50-selinux-policies', 'releasenotes/notes/fix-selinux-tcp-hm-on-udp-pools-89c3b8db89e359ba.yaml'], 'web_link': 'https://opendev.org/openstack/octavia/commit/da9dc1230ea5eee46a13a0367bdf53ab1f34f917', 'message': 'Fix TCP HMs on UDP pools with SELinux\n\nSELinux denied some specific TCP ports when using TCP-based HMs in UDP\npools (keepalived).\nEnable a SELinux boolean keepalived_connect_any which allows keepalived\nto connect to any port.\n\nCloses-Bug: #2023751\nChange-Id: Ie611ba9fde7b399989d847dd0c61dd3a158652bc\n(cherry picked from commit 294bd406f312984ee3029b301727d78caf7aea1d)\n(cherry picked from commit c0ceebebbfcf254e5f7b58f18208392260795259)\n(cherry picked from commit 4d52ce9c5c82c57690fdeacc44462e4822b80aea)\n'}]",1,887480,da9dc1230ea5eee46a13a0367bdf53ab1f34f917,7,2,1,29244,,,0,"Fix TCP HMs on UDP pools with SELinux

SELinux denied some specific TCP ports when using TCP-based HMs in UDP
pools (keepalived).
Enable a SELinux boolean keepalived_connect_any which allows keepalived
to connect to any port.

Closes-Bug: #2023751
Change-Id: Ie611ba9fde7b399989d847dd0c61dd3a158652bc
(cherry picked from commit 294bd406f312984ee3029b301727d78caf7aea1d)
(cherry picked from commit c0ceebebbfcf254e5f7b58f18208392260795259)
(cherry picked from commit 4d52ce9c5c82c57690fdeacc44462e4822b80aea)
",git fetch https://review.opendev.org/openstack/octavia refs/changes/80/887480/1 && git format-patch -1 --stdout FETCH_HEAD,"['elements/amphora-selinux/post-install.d/50-selinux-policies', 'releasenotes/notes/fix-selinux-tcp-hm-on-udp-pools-89c3b8db89e359ba.yaml']",2,da9dc1230ea5eee46a13a0367bdf53ab1f34f917,,"--- fixes: - | Fixed an SELinux issues with TCP-based health-monitor on UDP pools, some specific monitoring ports were denied by SELinux. The Amphora image now enables the ``keepalived_connect_any`` SELinux boolean that allows connections to any ports. ",,10,0
openstack%2Foctavia~887478,openstack/octavia,stable/2023.1,Ie611ba9fde7b399989d847dd0c61dd3a158652bc,Fix TCP HMs on UDP pools with SELinux,MERGED,2023-07-03 08:26:31.000000000,2023-07-12 17:18:43.000000000,2023-07-12 17:17:21.000000000,"[{'_account_id': 11628}, {'_account_id': 22348}]","[{'number': 1, 'created': '2023-07-03 08:26:31.000000000', 'files': ['elements/amphora-selinux/post-install.d/50-selinux-policies', 'releasenotes/notes/fix-selinux-tcp-hm-on-udp-pools-89c3b8db89e359ba.yaml'], 'web_link': 'https://opendev.org/openstack/octavia/commit/c0ceebebbfcf254e5f7b58f18208392260795259', 'message': 'Fix TCP HMs on UDP pools with SELinux\n\nSELinux denied some specific TCP ports when using TCP-based HMs in UDP\npools (keepalived).\nEnable a SELinux boolean keepalived_connect_any which allows keepalived\nto connect to any port.\n\nCloses-Bug: #2023751\nChange-Id: Ie611ba9fde7b399989d847dd0c61dd3a158652bc\n(cherry picked from commit 294bd406f312984ee3029b301727d78caf7aea1d)\n'}]",1,887478,c0ceebebbfcf254e5f7b58f18208392260795259,7,2,1,29244,,,0,"Fix TCP HMs on UDP pools with SELinux

SELinux denied some specific TCP ports when using TCP-based HMs in UDP
pools (keepalived).
Enable a SELinux boolean keepalived_connect_any which allows keepalived
to connect to any port.

Closes-Bug: #2023751
Change-Id: Ie611ba9fde7b399989d847dd0c61dd3a158652bc
(cherry picked from commit 294bd406f312984ee3029b301727d78caf7aea1d)
",git fetch https://review.opendev.org/openstack/octavia refs/changes/78/887478/1 && git format-patch -1 --stdout FETCH_HEAD,"['elements/amphora-selinux/post-install.d/50-selinux-policies', 'releasenotes/notes/fix-selinux-tcp-hm-on-udp-pools-89c3b8db89e359ba.yaml']",2,c0ceebebbfcf254e5f7b58f18208392260795259,,"--- fixes: - | Fixed an SELinux issues with TCP-based health-monitor on UDP pools, some specific monitoring ports were denied by SELinux. The Amphora image now enables the ``keepalived_connect_any`` SELinux boolean that allows connections to any ports. ",,10,0
openstack%2Foctavia~887481,openstack/octavia,stable/xena,Ie611ba9fde7b399989d847dd0c61dd3a158652bc,Fix TCP HMs on UDP pools with SELinux,MERGED,2023-07-03 08:27:10.000000000,2023-07-12 17:18:41.000000000,2023-07-12 17:17:24.000000000,"[{'_account_id': 11628}, {'_account_id': 22348}]","[{'number': 1, 'created': '2023-07-03 08:27:10.000000000', 'files': ['elements/amphora-selinux/post-install.d/50-selinux-policies', 'releasenotes/notes/fix-selinux-tcp-hm-on-udp-pools-89c3b8db89e359ba.yaml'], 'web_link': 'https://opendev.org/openstack/octavia/commit/3f1dc2012dabc718ca7833fdbb2c7a4ad5d65b1a', 'message': 'Fix TCP HMs on UDP pools with SELinux\n\nSELinux denied some specific TCP ports when using TCP-based HMs in UDP\npools (keepalived).\nEnable a SELinux boolean keepalived_connect_any which allows keepalived\nto connect to any port.\n\nCloses-Bug: #2023751\nChange-Id: Ie611ba9fde7b399989d847dd0c61dd3a158652bc\n(cherry picked from commit 294bd406f312984ee3029b301727d78caf7aea1d)\n(cherry picked from commit c0ceebebbfcf254e5f7b58f18208392260795259)\n(cherry picked from commit 4d52ce9c5c82c57690fdeacc44462e4822b80aea)\n(cherry picked from commit da9dc1230ea5eee46a13a0367bdf53ab1f34f917)\n'}]",1,887481,3f1dc2012dabc718ca7833fdbb2c7a4ad5d65b1a,7,2,1,29244,,,0,"Fix TCP HMs on UDP pools with SELinux

SELinux denied some specific TCP ports when using TCP-based HMs in UDP
pools (keepalived).
Enable a SELinux boolean keepalived_connect_any which allows keepalived
to connect to any port.

Closes-Bug: #2023751
Change-Id: Ie611ba9fde7b399989d847dd0c61dd3a158652bc
(cherry picked from commit 294bd406f312984ee3029b301727d78caf7aea1d)
(cherry picked from commit c0ceebebbfcf254e5f7b58f18208392260795259)
(cherry picked from commit 4d52ce9c5c82c57690fdeacc44462e4822b80aea)
(cherry picked from commit da9dc1230ea5eee46a13a0367bdf53ab1f34f917)
",git fetch https://review.opendev.org/openstack/octavia refs/changes/81/887481/1 && git format-patch -1 --stdout FETCH_HEAD,"['elements/amphora-selinux/post-install.d/50-selinux-policies', 'releasenotes/notes/fix-selinux-tcp-hm-on-udp-pools-89c3b8db89e359ba.yaml']",2,3f1dc2012dabc718ca7833fdbb2c7a4ad5d65b1a,,"--- fixes: - | Fixed an SELinux issues with TCP-based health-monitor on UDP pools, some specific monitoring ports were denied by SELinux. The Amphora image now enables the ``keepalived_connect_any`` SELinux boolean that allows connections to any ports. ",,10,0
openstack%2Foctavia~887479,openstack/octavia,stable/zed,Ie611ba9fde7b399989d847dd0c61dd3a158652bc,Fix TCP HMs on UDP pools with SELinux,MERGED,2023-07-03 08:26:44.000000000,2023-07-12 17:18:39.000000000,2023-07-12 17:17:22.000000000,"[{'_account_id': 11628}, {'_account_id': 22348}]","[{'number': 1, 'created': '2023-07-03 08:26:44.000000000', 'files': ['elements/amphora-selinux/post-install.d/50-selinux-policies', 'releasenotes/notes/fix-selinux-tcp-hm-on-udp-pools-89c3b8db89e359ba.yaml'], 'web_link': 'https://opendev.org/openstack/octavia/commit/4d52ce9c5c82c57690fdeacc44462e4822b80aea', 'message': 'Fix TCP HMs on UDP pools with SELinux\n\nSELinux denied some specific TCP ports when using TCP-based HMs in UDP\npools (keepalived).\nEnable a SELinux boolean keepalived_connect_any which allows keepalived\nto connect to any port.\n\nCloses-Bug: #2023751\nChange-Id: Ie611ba9fde7b399989d847dd0c61dd3a158652bc\n(cherry picked from commit 294bd406f312984ee3029b301727d78caf7aea1d)\n(cherry picked from commit c0ceebebbfcf254e5f7b58f18208392260795259)\n'}]",1,887479,4d52ce9c5c82c57690fdeacc44462e4822b80aea,7,2,1,29244,,,0,"Fix TCP HMs on UDP pools with SELinux

SELinux denied some specific TCP ports when using TCP-based HMs in UDP
pools (keepalived).
Enable a SELinux boolean keepalived_connect_any which allows keepalived
to connect to any port.

Closes-Bug: #2023751
Change-Id: Ie611ba9fde7b399989d847dd0c61dd3a158652bc
(cherry picked from commit 294bd406f312984ee3029b301727d78caf7aea1d)
(cherry picked from commit c0ceebebbfcf254e5f7b58f18208392260795259)
",git fetch https://review.opendev.org/openstack/octavia refs/changes/79/887479/1 && git format-patch -1 --stdout FETCH_HEAD,"['elements/amphora-selinux/post-install.d/50-selinux-policies', 'releasenotes/notes/fix-selinux-tcp-hm-on-udp-pools-89c3b8db89e359ba.yaml']",2,4d52ce9c5c82c57690fdeacc44462e4822b80aea,,"--- fixes: - | Fixed an SELinux issues with TCP-based health-monitor on UDP pools, some specific monitoring ports were denied by SELinux. The Amphora image now enables the ``keepalived_connect_any`` SELinux boolean that allows connections to any ports. ",,10,0
openstack%2Fironic-specs~882760,openstack/ironic-specs,master,Ic8b3b371488d97396f413168dd1720d4ec47c73c,Follow-up on DPU Management Change,MERGED,2023-05-09 21:25:09.000000000,2023-07-12 16:44:38.000000000,2023-07-12 16:43:21.000000000,"[{'_account_id': 10342}, {'_account_id': 11655}, {'_account_id': 22348}, {'_account_id': 32761}]","[{'number': 1, 'created': '2023-05-09 21:25:09.000000000', 'files': ['specs/approved/smartnics-to-dpus.rst'], 'web_link': 'https://opendev.org/openstack/ironic-specs/commit/c2de25bb237d104f2d6214394044b6ebfcfa6f34', 'message': 'Follow-up on DPU Management Change\n\nFixing a few typos and make some changes which I noted in the\nspecification as it was being reviewed.\n\nNothing major, just clean-up.\n\nChange-Id: Ic8b3b371488d97396f413168dd1720d4ec47c73c\n'}]",1,882760,c2de25bb237d104f2d6214394044b6ebfcfa6f34,10,4,1,11655,,,0,"Follow-up on DPU Management Change

Fixing a few typos and make some changes which I noted in the
specification as it was being reviewed.

Nothing major, just clean-up.

Change-Id: Ic8b3b371488d97396f413168dd1720d4ec47c73c
",git fetch https://review.opendev.org/openstack/ironic-specs refs/changes/60/882760/1 && git format-patch -1 --stdout FETCH_HEAD,['specs/approved/smartnics-to-dpus.rst'],1,c2de25bb237d104f2d6214394044b6ebfcfa6f34,,"https://bugs.launchpad.net/ironic/+bug/2019043 The ideas behind ""Smart NICs"" have evolved as time has progressed.The phrase ""Composible Hardware"" is unfortunately overloaded. This is bestoffer some interesting capabilities towards Composible Hardware, however it is inherently not full configuration as the underlying host is still protocol/signal translation. They may, or may not be able to have2) Then you would apply BMC firmware updates, to the card's BMC can be submitted. The default value is False. Steps which return CLEANWAIT, i.e. steps which expect asynchronous return will not be permitted under normal conditions, however this will be avaiable via a configuration option. * Introduction of a new step field value, ``limit_child_node_execution``, which accepts a list of node UUIDs to allow filtering and constraint of steps on some nodes. Sepcifically, this is largely separate from the ``execute_on_child_nodes`` field due to JSON Schema restrictions.operator to orchestrate management actions across an single node to extend further into distinct devices within the whole of the system."," https://storyboard.openstack.org/#!/story/XXXXXXX The ideas behind ""Smart NICs"" has evolved as time has progressed.The phrase ""Composible Hardware"" is unfortuantely overloaded. This is bestoffer some interesting capabilities towards Compisible Hardware, however it is inhernetly not full configuration as the underlying host is still protocol/signal translation. They may, or may not be able to have a2) Then you would apply BMC firmware updates, to the card's BMC/ can be submitted, which includes a list of child nodes, or a value of ``true`` which would result on the defined step to execute upon all child nodes.operator to orchustrate management actions across an singleGET /v1/nodes/?is_child_node=True Returns a list of only nodes with a parent node defined. Standard /v1/nodes access contstraints and behaivors will still apply. ",17,17
openstack%2Fpuppet-nova~886608,openstack/puppet-nova,stable/yoga,I41783e8697e3d9d43f2ca5c5d91cb91a74917aea,Fix restart of modular libvirt daemons after config change,MERGED,2023-06-21 11:47:53.000000000,2023-07-12 16:35:10.000000000,2023-07-12 16:35:10.000000000,"[{'_account_id': 9816}, {'_account_id': 14985}, {'_account_id': 22348}]","[{'number': 1, 'created': '2023-06-21 11:47:53.000000000', 'files': ['manifests/compute/libvirt/services.pp', 'manifests/params.pp', 'manifests/deps.pp'], 'web_link': 'https://opendev.org/openstack/puppet-nova/commit/7d8e2a6f1bb166ba73c85b60d52746a0ab900d10', 'message': ""Fix restart of modular libvirt daemons after config change\n\nThis fixes the regression caused by [1]. A socket can't be restarted\nif the associated service is already started, so we should restart\nthe service instead of the socket.\n\n[1] ef8a070e853f88b8a7fde4eba0f9cd8db109d893\n\nChange-Id: I41783e8697e3d9d43f2ca5c5d91cb91a74917aea\n(cherry picked from commit 4161c48f2ce9e4c6c4b8556710cb26855dce1b48)\n(cherry picked from commit 56aeeb0365c9a6e74a51353eefd7dd4ecfc83f19)\n(cherry picked from commit ac4d1e1717b2290ea8a82f311a2f9052d9f62c94)\n""}]",0,886608,7d8e2a6f1bb166ba73c85b60d52746a0ab900d10,7,3,1,16137,,,0,"Fix restart of modular libvirt daemons after config change

This fixes the regression caused by [1]. A socket can't be restarted
if the associated service is already started, so we should restart
the service instead of the socket.

[1] ef8a070e853f88b8a7fde4eba0f9cd8db109d893

Change-Id: I41783e8697e3d9d43f2ca5c5d91cb91a74917aea
(cherry picked from commit 4161c48f2ce9e4c6c4b8556710cb26855dce1b48)
(cherry picked from commit 56aeeb0365c9a6e74a51353eefd7dd4ecfc83f19)
(cherry picked from commit ac4d1e1717b2290ea8a82f311a2f9052d9f62c94)
",git fetch https://review.opendev.org/openstack/puppet-nova refs/changes/08/886608/1 && git format-patch -1 --stdout FETCH_HEAD,"['manifests/compute/libvirt/services.pp', 'manifests/params.pp', 'manifests/deps.pp']",3,7d8e2a6f1bb166ba73c85b60d52746a0ab900d10,, -> Exec<| tag == 'libvirt-service'|>,,83,20
openstack%2Fbifrost~883117,openstack/bifrost,stable/yoga,I27ccc12b9f408d510710d5ba82ad04135169827a,Skip unnecessary SDK get_machine calls,MERGED,2023-05-15 19:26:46.000000000,2023-07-12 16:33:15.000000000,2023-07-12 16:32:16.000000000,"[{'_account_id': 14826}, {'_account_id': 22348}]","[{'number': 1, 'created': '2023-05-15 19:26:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/bifrost/commit/aa4cf7a9033e37b31d0dcb1275887b04dfb88b37', 'message': 'Skip unnecessary SDK get_machine calls\n\nThe _process_sdk function starts by calling cloud.list_machines() which\nreturns all nodes including their names. There is no need to call\ncloud.get_machine individually for each node just to get its name\nattribute when we might be skipping this node.\n\nThis speeds up execution of the Bifrost inventory module when\nBIFROST_NODE_NAMES is used.\n\nChange-Id: I27ccc12b9f408d510710d5ba82ad04135169827a\n(cherry picked from commit 7979498316762b51759ef056fabd517c1f0909cd)\n'}, {'number': 2, 'created': '2023-07-10 13:00:29.000000000', 'files': ['bifrost/inventory.py'], 'web_link': 'https://opendev.org/openstack/bifrost/commit/d094d5de0ca584ae16d1bcd4cd99d69622ad5b71', 'message': 'Skip unnecessary SDK get_machine calls\n\nThe _process_sdk function starts by calling cloud.list_machines() which\nreturns all nodes including their names. There is no need to call\ncloud.get_machine individually for each node just to get its name\nattribute when we might be skipping this node.\n\nThis speeds up execution of the Bifrost inventory module when\nBIFROST_NODE_NAMES is used.\n\nChange-Id: I27ccc12b9f408d510710d5ba82ad04135169827a\n(cherry picked from commit 64fd2a86c571ea02b0758a6cac9a0e203a754b54)\n'}]",0,883117,d094d5de0ca584ae16d1bcd4cd99d69622ad5b71,9,2,2,15197,,,0,"Skip unnecessary SDK get_machine calls

The _process_sdk function starts by calling cloud.list_machines() which
returns all nodes including their names. There is no need to call
cloud.get_machine individually for each node just to get its name
attribute when we might be skipping this node.

This speeds up execution of the Bifrost inventory module when
BIFROST_NODE_NAMES is used.

Change-Id: I27ccc12b9f408d510710d5ba82ad04135169827a
(cherry picked from commit 64fd2a86c571ea02b0758a6cac9a0e203a754b54)
",git fetch https://review.opendev.org/openstack/bifrost refs/changes/17/883117/1 && git format-patch -1 --stdout FETCH_HEAD,['bifrost/inventory.py'],1,aa4cf7a9033e37b31d0dcb1275887b04dfb88b37,, machine = cloud.get_machine(machine['uuid']), machine = cloud.get_machine(machine['uuid']),1,1
openstack%2Fbifrost~883116,openstack/bifrost,stable/zed,I27ccc12b9f408d510710d5ba82ad04135169827a,Skip unnecessary SDK get_machine calls,MERGED,2023-05-15 19:26:37.000000000,2023-07-12 16:33:12.000000000,2023-07-12 16:32:14.000000000,"[{'_account_id': 10239}, {'_account_id': 14826}, {'_account_id': 22348}]","[{'number': 1, 'created': '2023-05-15 19:26:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/bifrost/commit/66694e5a0edd588bd3387641f1322bd2fe313611', 'message': 'Skip unnecessary SDK get_machine calls\n\nThe _process_sdk function starts by calling cloud.list_machines() which\nreturns all nodes including their names. There is no need to call\ncloud.get_machine individually for each node just to get its name\nattribute when we might be skipping this node.\n\nThis speeds up execution of the Bifrost inventory module when\nBIFROST_NODE_NAMES is used.\n\nChange-Id: I27ccc12b9f408d510710d5ba82ad04135169827a\n(cherry picked from commit 7979498316762b51759ef056fabd517c1f0909cd)\n'}, {'number': 2, 'created': '2023-07-10 11:52:25.000000000', 'files': ['bifrost/inventory.py'], 'web_link': 'https://opendev.org/openstack/bifrost/commit/64fd2a86c571ea02b0758a6cac9a0e203a754b54', 'message': 'Skip unnecessary SDK get_machine calls\n\nThe _process_sdk function starts by calling cloud.list_machines() which\nreturns all nodes including their names. There is no need to call\ncloud.get_machine individually for each node just to get its name\nattribute when we might be skipping this node.\n\nThis speeds up execution of the Bifrost inventory module when\nBIFROST_NODE_NAMES is used.\n\nChange-Id: I27ccc12b9f408d510710d5ba82ad04135169827a\n(cherry picked from commit 3017112fe9d6fd010be4743e947a3a603edf4d7d)\n'}]",0,883116,64fd2a86c571ea02b0758a6cac9a0e203a754b54,10,3,2,15197,,,0,"Skip unnecessary SDK get_machine calls

The _process_sdk function starts by calling cloud.list_machines() which
returns all nodes including their names. There is no need to call
cloud.get_machine individually for each node just to get its name
attribute when we might be skipping this node.

This speeds up execution of the Bifrost inventory module when
BIFROST_NODE_NAMES is used.

Change-Id: I27ccc12b9f408d510710d5ba82ad04135169827a
(cherry picked from commit 3017112fe9d6fd010be4743e947a3a603edf4d7d)
",git fetch https://review.opendev.org/openstack/bifrost refs/changes/16/883116/1 && git format-patch -1 --stdout FETCH_HEAD,['bifrost/inventory.py'],1,66694e5a0edd588bd3387641f1322bd2fe313611,, machine = cloud.get_machine(machine['uuid']), machine = cloud.get_machine(machine['uuid']),1,1
openstack%2Fbifrost~883115,openstack/bifrost,stable/2023.1,I27ccc12b9f408d510710d5ba82ad04135169827a,Skip unnecessary SDK get_machine calls,MERGED,2023-05-15 19:26:28.000000000,2023-07-12 16:17:15.000000000,2023-07-12 16:16:06.000000000,"[{'_account_id': 10239}, {'_account_id': 14826}, {'_account_id': 22348}]","[{'number': 1, 'created': '2023-05-15 19:26:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/bifrost/commit/b41ce71455d85f6cb100bfb9e4e2542bb75ce283', 'message': 'Skip unnecessary SDK get_machine calls\n\nThe _process_sdk function starts by calling cloud.list_machines() which\nreturns all nodes including their names. There is no need to call\ncloud.get_machine individually for each node just to get its name\nattribute when we might be skipping this node.\n\nThis speeds up execution of the Bifrost inventory module when\nBIFROST_NODE_NAMES is used.\n\nChange-Id: I27ccc12b9f408d510710d5ba82ad04135169827a\n(cherry picked from commit 7979498316762b51759ef056fabd517c1f0909cd)\n'}, {'number': 2, 'created': '2023-07-06 18:52:45.000000000', 'files': ['bifrost/inventory.py'], 'web_link': 'https://opendev.org/openstack/bifrost/commit/3017112fe9d6fd010be4743e947a3a603edf4d7d', 'message': 'Skip unnecessary SDK get_machine calls\n\nThe _process_sdk function starts by calling cloud.list_machines() which\nreturns all nodes including their names. There is no need to call\ncloud.get_machine individually for each node just to get its name\nattribute when we might be skipping this node.\n\nThis speeds up execution of the Bifrost inventory module when\nBIFROST_NODE_NAMES is used.\n\nChange-Id: I27ccc12b9f408d510710d5ba82ad04135169827a\n(cherry picked from commit 7979498316762b51759ef056fabd517c1f0909cd)\n'}]",1,883115,3017112fe9d6fd010be4743e947a3a603edf4d7d,12,3,2,15197,,,0,"Skip unnecessary SDK get_machine calls

The _process_sdk function starts by calling cloud.list_machines() which
returns all nodes including their names. There is no need to call
cloud.get_machine individually for each node just to get its name
attribute when we might be skipping this node.

This speeds up execution of the Bifrost inventory module when
BIFROST_NODE_NAMES is used.

Change-Id: I27ccc12b9f408d510710d5ba82ad04135169827a
(cherry picked from commit 7979498316762b51759ef056fabd517c1f0909cd)
",git fetch https://review.opendev.org/openstack/bifrost refs/changes/15/883115/1 && git format-patch -1 --stdout FETCH_HEAD,['bifrost/inventory.py'],1,b41ce71455d85f6cb100bfb9e4e2542bb75ce283,, machine = cloud.get_machine(machine['uuid']), machine = cloud.get_machine(machine['uuid']),1,1
openstack%2Fnova~885756,openstack/nova,master,Iaf4a9182b79ec4d1c2d3436b3dc9a6c760cd48f9,Refactor CinderFixture,MERGED,2023-06-09 12:59:17.000000000,2023-07-12 16:12:47.000000000,2023-07-12 16:11:31.000000000,"[{'_account_id': 4393}, {'_account_id': 11604}, {'_account_id': 22348}]","[{'number': 1, 'created': '2023-06-09 12:59:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/ad68ebbeac3bfe266253515b4a045cbf5fc6af64', 'message': 'WIP: Refactor CinderFixture\n\nChange-Id: Iaf4a9182b79ec4d1c2d3436b3dc9a6c760cd48f9\n'}, {'number': 2, 'created': '2023-06-11 16:19:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/91b3fe44ba7a42e47e9276fee155419d25a08c61', 'message': 'WIP: Refactor CinderFixture\n\nChange-Id: Iaf4a9182b79ec4d1c2d3436b3dc9a6c760cd48f9\n'}, {'number': 3, 'created': '2023-07-03 13:23:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/2e8218e3e73b69dfc20a6379c6406523bf085624', 'message': 'Refactor CinderFixture\n\nChange-Id: Iaf4a9182b79ec4d1c2d3436b3dc9a6c760cd48f9\n'}, {'number': 4, 'created': '2023-07-03 14:29:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/3d592dc8901fdc9f7a9db8d48c72ba8331455e16', 'message': 'Refactor CinderFixture\n\nChange-Id: Iaf4a9182b79ec4d1c2d3436b3dc9a6c760cd48f9\n'}, {'number': 5, 'created': '2023-07-05 10:28:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/9240b00e73cd4a9d9f34075bca6bbb270475f927', 'message': 'Refactor CinderFixture\n\nreplaced stub with MockPatch\n\nChange-Id: Iaf4a9182b79ec4d1c2d3436b3dc9a6c760cd48f9\n'}, {'number': 6, 'created': '2023-07-05 10:41:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/3d1ab95827a5516c82b53d3cb0869775feab902a', 'message': 'Refactor CinderFixture\n\nreplaced stub with MockPatch\n\nChange-Id: Iaf4a9182b79ec4d1c2d3436b3dc9a6c760cd48f9\n'}, {'number': 7, 'created': '2023-07-10 16:24:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/63f08ebd5750e33ede6e6c94a1361ed421fb9d4e', 'message': 'Refactor CinderFixture\n\nreplaced stub with MockPatch\n\nChange-Id: Iaf4a9182b79ec4d1c2d3436b3dc9a6c760cd48f9\n'}, {'number': 8, 'created': '2023-07-11 06:21:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/68378519b09f3ebfa7fb7024084d7b9b06ec0e48', 'message': 'Refactor CinderFixture\n\nreplaced stub with MockPatch\n\nChange-Id: Iaf4a9182b79ec4d1c2d3436b3dc9a6c760cd48f9\n'}, {'number': 9, 'created': '2023-07-12 13:04:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/c8f46ca2227f74efbe57bb1cdc4fc57e2d0f9e98', 'message': 'Refactor CinderFixture\n\nreplaced stub with MockPatch.\nCommented out a few stubs that were not used.\nDid not delete for future reference.\n\n\nChange-Id: Iaf4a9182b79ec4d1c2d3436b3dc9a6c760cd48f9\n'}, {'number': 10, 'created': '2023-07-12 13:21:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/61fe9ba6af6588acee2f39a19f1bbbecd352c7a2', 'message': 'Refactor CinderFixture\n\nReplaced stub with MockPatch.\nCommented out a few stubs that were not used, but did not delete for future reference.\n\nChange-Id: Iaf4a9182b79ec4d1c2d3436b3dc9a6c760cd48f9\n'}, {'number': 11, 'created': '2023-07-12 14:20:00.000000000', 'files': ['nova/tests/functional/regressions/test_bug_1899835.py', 'nova/tests/functional/test_nova_manage.py', 'nova/tests/functional/regressions/test_bug_1937084.py', 'nova/tests/functional/notification_sample_tests/test_instance.py', 'nova/tests/fixtures/cinder.py', 'nova/tests/functional/test_servers.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/f7ce4df51c080ff3b5a6280771f30a8488c7c2df', 'message': 'Refactor CinderFixture\n\nReplaced stub with MockPatch.\n\nChange-Id: Iaf4a9182b79ec4d1c2d3436b3dc9a6c760cd48f9\n'}]",12,885756,f7ce4df51c080ff3b5a6280771f30a8488c7c2df,48,3,11,34860,,,0,"Refactor CinderFixture

Replaced stub with MockPatch.

Change-Id: Iaf4a9182b79ec4d1c2d3436b3dc9a6c760cd48f9
",git fetch https://review.opendev.org/openstack/nova refs/changes/56/885756/1 && git format-patch -1 --stdout FETCH_HEAD,['nova/tests/fixtures/cinder.py'],1,ad68ebbeac3bfe266253515b4a045cbf5fc6af64,dangling-volumes,# Refactor ,,2,0
openstack%2Fproject-config~887561,openstack/project-config,master,Ib6409cf8913423b473cc349e26d82805beb5bc1d,Add nebulous/iot-dpp-orchestrator,MERGED,2023-07-12 15:15:05.000000000,2023-07-12 15:42:53.000000000,2023-07-12 15:37:07.000000000,"[{'_account_id': 5263}, {'_account_id': 22348}]","[{'number': 1, 'created': '2023-07-12 15:15:05.000000000', 'files': ['gerrit/projects.yaml'], 'web_link': 'https://opendev.org/openstack/project-config/commit/96207488ad4c1f04276c2bfbfd523e21d17d34c3', 'message': 'Add nebulous/iot-dpp-orchestrator\n\nChange-Id: Ib6409cf8913423b473cc349e26d82805beb5bc1d\n'}]",0,887561,96207488ad4c1f04276c2bfbfd523e21d17d34c3,7,2,1,30491,,,0,"Add nebulous/iot-dpp-orchestrator

Change-Id: Ib6409cf8913423b473cc349e26d82805beb5bc1d
",git fetch https://review.opendev.org/openstack/project-config refs/changes/61/887561/1 && git format-patch -1 --stdout FETCH_HEAD,['gerrit/projects.yaml'],1,96207488ad4c1f04276c2bfbfd523e21d17d34c3,new-project,- project: nebulous/iot-dpp-orchestrator description: >- IoT data processing pipelines orchestration tool of the NebulOuS project. https://www.nebulouscloud.eu/ acl-config: /home/gerrit2/acls/nebulous/nebulous.config,,5,0
openstack%2Fcloudkitty-dashboard~884339,openstack/cloudkitty-dashboard,master,Ieb8a53a32ea17a1fcf9e9c96ef9ddf228fb4045c,Cleanup py27 support,MERGED,2023-05-26 06:13:53.000000000,2023-07-12 15:41:23.000000000,2023-07-12 15:40:17.000000000,"[{'_account_id': 15197}, {'_account_id': 22348}, {'_account_id': 25277}, {'_account_id': 28356}]","[{'number': 1, 'created': '2023-05-26 06:13:53.000000000', 'files': ['setup.py'], 'web_link': 'https://opendev.org/openstack/cloudkitty-dashboard/commit/2c5edadb4c43438a45dd59c5f40217ef3e09cde0', 'message': ""Cleanup py27 support\n\nThis repo is now testing only with Python 3, so let's make\na few cleanups:\n- Remove python 2.7 stanza from setup.py\n\nChange-Id: Ieb8a53a32ea17a1fcf9e9c96ef9ddf228fb4045c\n""}]",2,884339,2c5edadb4c43438a45dd59c5f40217ef3e09cde0,9,4,1,35058,,,0,"Cleanup py27 support

This repo is now testing only with Python 3, so let's make
a few cleanups:
- Remove python 2.7 stanza from setup.py

Change-Id: Ieb8a53a32ea17a1fcf9e9c96ef9ddf228fb4045c
",git fetch https://review.opendev.org/openstack/cloudkitty-dashboard refs/changes/39/884339/1 && git format-patch -1 --stdout FETCH_HEAD,['setup.py'],1,2c5edadb4c43438a45dd59c5f40217ef3e09cde0,,,"# THIS FILE IS MANAGED BY THE GLOBAL REQUIREMENTS REPO - DO NOT EDIT# In python < 2.7.4, a lazy loading of package `pbr` will break # setuptools if some other modules registered functions in `atexit`. # solution from: http://bugs.python.org/issue15881#msg170215 try: import multiprocessing # noqa except ImportError: pass ",0,9
openstack%2Fcharm-ironic-conductor~887903,openstack/charm-ironic-conductor,stable/ussuri,I06d0fc3be2065adaa05db1ed019b79295ee7198d,Use service_domain in [service_user] section,MERGED,2023-07-06 20:07:27.000000000,2023-07-12 15:22:21.000000000,2023-07-12 15:22:21.000000000,"[{'_account_id': 12549}, {'_account_id': 20648}, {'_account_id': 20870}, {'_account_id': 22348}, {'_account_id': 31203}]","[{'number': 1, 'created': '2023-07-06 20:07:27.000000000', 'files': ['src/build.lock'], 'web_link': 'https://opendev.org/openstack/charm-ironic-conductor/commit/4af7e6b3293f2c67ec7d46cc3ad4c3ed3f17d486', 'message': 'Use service_domain in [service_user] section\n\nRebuild to update [service_user] config to use the service domain.\nThis was fixed in charm-helpers.\n\nThe keystone charm currently creates two service users, one for the\nservice domain (for v3 authentication), and the other for the default\ndomain (for v2 authentication). The [service_user] config needs to\nuse the service domain.\n\nCloses-Bug: #2026202\nChange-Id: I06d0fc3be2065adaa05db1ed019b79295ee7198d\n'}]",0,887903,4af7e6b3293f2c67ec7d46cc3ad4c3ed3f17d486,9,5,1,11805,,,0,"Use service_domain in [service_user] section

Rebuild to update [service_user] config to use the service domain.
This was fixed in charm-helpers.

The keystone charm currently creates two service users, one for the
service domain (for v3 authentication), and the other for the default
domain (for v2 authentication). The [service_user] config needs to
use the service domain.

Closes-Bug: #2026202
Change-Id: I06d0fc3be2065adaa05db1ed019b79295ee7198d
",git fetch https://review.opendev.org/openstack/charm-ironic-conductor refs/changes/03/887903/1 && git format-patch -1 --stdout FETCH_HEAD,['src/build.lock'],1,4af7e6b3293f2c67ec7d46cc3ad4c3ed3f17d486,bug/2026202," ""version"": ""cc9851608d58c6ee1f22a968c5ba481d6b74c31b"","," ""version"": ""87f9a8df625ce6cd0c2a04da2d718ab7f9c1aad3"",",1,1
openstack%2Fcharm-cinder~887832,openstack/charm-cinder,stable/xena,I9e3882c095fcc42736a05b6e6fd264128d67a0a5,Use service_domain in [service_user] section,MERGED,2023-07-06 13:11:43.000000000,2023-07-12 15:21:40.000000000,2023-07-12 15:21:40.000000000,"[{'_account_id': 12549}, {'_account_id': 20648}, {'_account_id': 20870}, {'_account_id': 22348}, {'_account_id': 31203}]","[{'number': 1, 'created': '2023-07-06 13:11:43.000000000', 'files': ['charmhelpers/contrib/openstack/utils.py', 'charmhelpers/contrib/openstack/templates/section-service-user'], 'web_link': 'https://opendev.org/openstack/charm-cinder/commit/9d69e71d0c66220887e4d37d5e04b208d1242485', 'message': 'Use service_domain in [service_user] section\n\nSync from charm-helpers to update [service_user] config to use the\nservice domain.\n\nThe keystone charm currently creates two service users, one for the\nservice domain (for v3 authentication), and the other for the default\ndomain (for v2 authentication). The [service_user] config needs to\nuse the service domain.\n\nCloses-Bug: #2026202\nChange-Id: I9e3882c095fcc42736a05b6e6fd264128d67a0a5\n'}]",0,887832,9d69e71d0c66220887e4d37d5e04b208d1242485,9,5,1,11805,,,0,"Use service_domain in [service_user] section

Sync from charm-helpers to update [service_user] config to use the
service domain.

The keystone charm currently creates two service users, one for the
service domain (for v3 authentication), and the other for the default
domain (for v2 authentication). The [service_user] config needs to
use the service domain.

Closes-Bug: #2026202
Change-Id: I9e3882c095fcc42736a05b6e6fd264128d67a0a5
",git fetch https://review.opendev.org/openstack/charm-cinder refs/changes/32/887832/1 && git format-patch -1 --stdout FETCH_HEAD,"['charmhelpers/contrib/openstack/utils.py', 'charmhelpers/contrib/openstack/templates/section-service-user']",2,9d69e71d0c66220887e4d37d5e04b208d1242485,bug/2026202,project_domain_name = service_domain user_domain_name = service_domain,project_domain_id = default user_domain_id = default,19,2
openstack%2Fcharm-nova-compute~887840,openstack/charm-nova-compute,stable/victoria,I428bc061acdfb8205972b54e8c39eb1b20dc9c59,Use service_domain in [service_user] section,MERGED,2023-07-06 13:16:53.000000000,2023-07-12 15:21:28.000000000,2023-07-12 15:21:28.000000000,"[{'_account_id': 12549}, {'_account_id': 20648}, {'_account_id': 20870}, {'_account_id': 22348}, {'_account_id': 31203}]","[{'number': 1, 'created': '2023-07-06 13:16:53.000000000', 'files': ['hooks/charmhelpers/contrib/openstack/templates/section-service-user'], 'web_link': 'https://opendev.org/openstack/charm-nova-compute/commit/bd0edbbca82a3b65f58dc950f643ec9467209f65', 'message': 'Use service_domain in [service_user] section\n\nSync from charm-helpers to update [service_user] config to use the\nservice domain.\n\nThe keystone charm currently creates two service users, one for the\nservice domain (for v3 authentication), and the other for the default\ndomain (for v2 authentication). The [service_user] config needs to\nuse the service domain.\n\nCloses-Bug: #2026202\nChange-Id: I428bc061acdfb8205972b54e8c39eb1b20dc9c59\n'}]",1,887840,bd0edbbca82a3b65f58dc950f643ec9467209f65,11,5,1,11805,,,0,"Use service_domain in [service_user] section

Sync from charm-helpers to update [service_user] config to use the
service domain.

The keystone charm currently creates two service users, one for the
service domain (for v3 authentication), and the other for the default
domain (for v2 authentication). The [service_user] config needs to
use the service domain.

Closes-Bug: #2026202
Change-Id: I428bc061acdfb8205972b54e8c39eb1b20dc9c59
",git fetch https://review.opendev.org/openstack/charm-nova-compute refs/changes/40/887840/1 && git format-patch -1 --stdout FETCH_HEAD,['hooks/charmhelpers/contrib/openstack/templates/section-service-user'],1,bd0edbbca82a3b65f58dc950f643ec9467209f65,bug/2026202,project_domain_name = service_domain user_domain_name = service_domain,project_domain_id = default user_domain_id = default,2,2
openstack%2Fcharm-ironic-api~887902,openstack/charm-ironic-api,stable/ussuri,I5e2315f4f94bc3ee836fa21fd34bce342a842bc0,Use service_domain in [service_user] section,MERGED,2023-07-06 20:05:32.000000000,2023-07-12 15:19:30.000000000,2023-07-12 15:19:30.000000000,"[{'_account_id': 12549}, {'_account_id': 20648}, {'_account_id': 20870}, {'_account_id': 22348}, {'_account_id': 31203}]","[{'number': 1, 'created': '2023-07-06 20:05:32.000000000', 'files': ['src/build.lock'], 'web_link': 'https://opendev.org/openstack/charm-ironic-api/commit/2618143ca316f3752ad60df750d8596b5d8f6f90', 'message': 'Use service_domain in [service_user] section\n\nRebuild to update [service_user] config to use the service domain.\nThis was fixed in charm-helpers.\n\nThe keystone charm currently creates two service users, one for the\nservice domain (for v3 authentication), and the other for the default\ndomain (for v2 authentication). The [service_user] config needs to\nuse the service domain.\n\nCloses-Bug: #2026202\nChange-Id: I5e2315f4f94bc3ee836fa21fd34bce342a842bc0\n'}]",0,887902,2618143ca316f3752ad60df750d8596b5d8f6f90,9,5,1,11805,,,0,"Use service_domain in [service_user] section

Rebuild to update [service_user] config to use the service domain.
This was fixed in charm-helpers.

The keystone charm currently creates two service users, one for the
service domain (for v3 authentication), and the other for the default
domain (for v2 authentication). The [service_user] config needs to
use the service domain.

Closes-Bug: #2026202
Change-Id: I5e2315f4f94bc3ee836fa21fd34bce342a842bc0
",git fetch https://review.opendev.org/openstack/charm-ironic-api refs/changes/02/887902/1 && git format-patch -1 --stdout FETCH_HEAD,['src/build.lock'],1,2618143ca316f3752ad60df750d8596b5d8f6f90,bug/2026202," ""version"": ""cc9851608d58c6ee1f22a968c5ba481d6b74c31b"","," ""version"": ""87f9a8df625ce6cd0c2a04da2d718ab7f9c1aad3"",",1,1
openstack%2Fcharm-ironic-api~887900,openstack/charm-ironic-api,stable/victoria,I9803358ae7a38e333b563aea8ecabbad24513232,Use service_domain in [service_user] section,MERGED,2023-07-06 20:03:02.000000000,2023-07-12 15:17:53.000000000,2023-07-12 15:17:53.000000000,"[{'_account_id': 12549}, {'_account_id': 20648}, {'_account_id': 20870}, {'_account_id': 22348}, {'_account_id': 31203}]","[{'number': 1, 'created': '2023-07-06 20:03:02.000000000', 'files': ['src/build.lock'], 'web_link': 'https://opendev.org/openstack/charm-ironic-api/commit/25fcc0d50f67ace6de94692a34ee9ffeb68c1f1c', 'message': 'Use service_domain in [service_user] section\n\nRebuild to update [service_user] config to use the service domain.\nThis was fixed in charm-helpers.\n\nThe keystone charm currently creates two service users, one for the\nservice domain (for v3 authentication), and the other for the default\ndomain (for v2 authentication). The [service_user] config needs to\nuse the service domain.\n\nCloses-Bug: #2026202\nChange-Id: I9803358ae7a38e333b563aea8ecabbad24513232\n'}]",1,887900,25fcc0d50f67ace6de94692a34ee9ffeb68c1f1c,11,5,1,11805,,,0,"Use service_domain in [service_user] section

Rebuild to update [service_user] config to use the service domain.
This was fixed in charm-helpers.

The keystone charm currently creates two service users, one for the
service domain (for v3 authentication), and the other for the default
domain (for v2 authentication). The [service_user] config needs to
use the service domain.

Closes-Bug: #2026202
Change-Id: I9803358ae7a38e333b563aea8ecabbad24513232
",git fetch https://review.opendev.org/openstack/charm-ironic-api refs/changes/00/887900/1 && git format-patch -1 --stdout FETCH_HEAD,['src/build.lock'],1,25fcc0d50f67ace6de94692a34ee9ffeb68c1f1c,bug/2026202," ""version"": ""e8c021f99d1a6fdb795ae5a869ef8241ab2b79ba"","," ""version"": ""7d2e709dc443b24177db524eb6b0c44639532479"",",1,1
openstack%2Fcharm-ironic-api~887898,openstack/charm-ironic-api,stable/wallaby,I438f67161a3b3680d40c9eb759c211f1f4c335eb,Use service_domain in [service_user] section,MERGED,2023-07-06 20:02:10.000000000,2023-07-12 15:17:27.000000000,2023-07-12 15:17:27.000000000,"[{'_account_id': 12549}, {'_account_id': 20648}, {'_account_id': 20870}, {'_account_id': 22348}, {'_account_id': 31203}]","[{'number': 1, 'created': '2023-07-06 20:02:10.000000000', 'files': ['src/build.lock'], 'web_link': 'https://opendev.org/openstack/charm-ironic-api/commit/976da07f4d7ec2ed44ddf3e9c8c7daf1e85074e5', 'message': 'Use service_domain in [service_user] section\n\nRebuild to update [service_user] config to use the service domain.\nThis was fixed in charm-helpers.\n\nThe keystone charm currently creates two service users, one for the\nservice domain (for v3 authentication), and the other for the default\ndomain (for v2 authentication). The [service_user] config needs to\nuse the service domain.\n\nCloses-Bug: #2026202\nChange-Id: I438f67161a3b3680d40c9eb759c211f1f4c335eb\n'}]",1,887898,976da07f4d7ec2ed44ddf3e9c8c7daf1e85074e5,11,5,1,11805,,,0,"Use service_domain in [service_user] section

Rebuild to update [service_user] config to use the service domain.
This was fixed in charm-helpers.

The keystone charm currently creates two service users, one for the
service domain (for v3 authentication), and the other for the default
domain (for v2 authentication). The [service_user] config needs to
use the service domain.

Closes-Bug: #2026202
Change-Id: I438f67161a3b3680d40c9eb759c211f1f4c335eb
",git fetch https://review.opendev.org/openstack/charm-ironic-api refs/changes/98/887898/1 && git format-patch -1 --stdout FETCH_HEAD,['src/build.lock'],1,976da07f4d7ec2ed44ddf3e9c8c7daf1e85074e5,bug/2026202," ""version"": ""0330c6814eb84ee8531445ec2a41e8f26004e442"","," ""version"": ""77f25c49dfd08ac16c7a1cc018b008aa704bd313"",",1,1
openstack%2Fcharm-ironic-api~887896,openstack/charm-ironic-api,stable/xena,I281afe835c8d30280fcd6993944525deb7ac88fa,Use service_domain in [service_user] section,MERGED,2023-07-06 20:01:25.000000000,2023-07-12 15:17:26.000000000,2023-07-12 15:17:26.000000000,"[{'_account_id': 12549}, {'_account_id': 20648}, {'_account_id': 20870}, {'_account_id': 22348}, {'_account_id': 31203}]","[{'number': 1, 'created': '2023-07-06 20:01:25.000000000', 'files': ['src/build.lock'], 'web_link': 'https://opendev.org/openstack/charm-ironic-api/commit/0c9a166423802e1cf15963d80f64122dffb49086', 'message': 'Use service_domain in [service_user] section\n\nRebuild to update [service_user] config to use the service domain.\nThis was fixed in charm-helpers.\n\nThe keystone charm currently creates two service users, one for the\nservice domain (for v3 authentication), and the other for the default\ndomain (for v2 authentication). The [service_user] config needs to\nuse the service domain.\n\nCloses-Bug: #2026202\nChange-Id: I281afe835c8d30280fcd6993944525deb7ac88fa\n'}]",0,887896,0c9a166423802e1cf15963d80f64122dffb49086,9,5,1,11805,,,0,"Use service_domain in [service_user] section

Rebuild to update [service_user] config to use the service domain.
This was fixed in charm-helpers.

The keystone charm currently creates two service users, one for the
service domain (for v3 authentication), and the other for the default
domain (for v2 authentication). The [service_user] config needs to
use the service domain.

Closes-Bug: #2026202
Change-Id: I281afe835c8d30280fcd6993944525deb7ac88fa
",git fetch https://review.opendev.org/openstack/charm-ironic-api refs/changes/96/887896/1 && git format-patch -1 --stdout FETCH_HEAD,['src/build.lock'],1,0c9a166423802e1cf15963d80f64122dffb49086,bug/2026202," ""version"": ""0cdd983ca2f2cb8ab7aec58d3b955953f5ef9ddf"","," ""version"": ""5f8dacee1a7583d3927d39887bd5460ff2e2f812"",",1,1
openstack%2Fcharm-nova-cloud-controller~887837,openstack/charm-nova-cloud-controller,stable/wallaby,I90173fb089aae8fa0ee53fbb1d3566eb8209c96a,Use service_domain in [service_user] section,MERGED,2023-07-06 13:15:15.000000000,2023-07-12 15:17:02.000000000,2023-07-12 15:17:02.000000000,"[{'_account_id': 12549}, {'_account_id': 20648}, {'_account_id': 20870}, {'_account_id': 22348}, {'_account_id': 31203}]","[{'number': 1, 'created': '2023-07-06 13:15:15.000000000', 'files': ['charmhelpers/contrib/openstack/templates/section-service-user'], 'web_link': 'https://opendev.org/openstack/charm-nova-cloud-controller/commit/4fc5070d5c3a32782db74a4d2d7ae59e7f7c3c2c', 'message': 'Use service_domain in [service_user] section\n\nSync from charm-helpers to update [service_user] config to use the\nservice domain.\n\nThe keystone charm currently creates two service users, one for the\nservice domain (for v3 authentication), and the other for the default\ndomain (for v2 authentication). The [service_user] config needs to\nuse the service domain.\n\nCloses-Bug: #2026202\nChange-Id: I90173fb089aae8fa0ee53fbb1d3566eb8209c96a\n'}]",1,887837,4fc5070d5c3a32782db74a4d2d7ae59e7f7c3c2c,11,5,1,11805,,,0,"Use service_domain in [service_user] section

Sync from charm-helpers to update [service_user] config to use the
service domain.

The keystone charm currently creates two service users, one for the
service domain (for v3 authentication), and the other for the default
domain (for v2 authentication). The [service_user] config needs to
use the service domain.

Closes-Bug: #2026202
Change-Id: I90173fb089aae8fa0ee53fbb1d3566eb8209c96a
",git fetch https://review.opendev.org/openstack/charm-nova-cloud-controller refs/changes/37/887837/1 && git format-patch -1 --stdout FETCH_HEAD,['charmhelpers/contrib/openstack/templates/section-service-user'],1,4fc5070d5c3a32782db74a4d2d7ae59e7f7c3c2c,bug/2026202,project_domain_name = service_domain user_domain_name = service_domain,project_domain_id = default user_domain_id = default,2,2
openstack%2Fcharm-nova-cloud-controller~887833,openstack/charm-nova-cloud-controller,stable/xena,I6755706f192642a5454d92d257dec81bb5f74e40,Use service_domain in [service_user] section,MERGED,2023-07-06 13:11:59.000000000,2023-07-12 15:17:01.000000000,2023-07-12 15:17:01.000000000,"[{'_account_id': 12549}, {'_account_id': 20648}, {'_account_id': 20870}, {'_account_id': 22348}, {'_account_id': 31203}]","[{'number': 1, 'created': '2023-07-06 13:11:59.000000000', 'files': ['charmhelpers/contrib/openstack/utils.py', 'charmhelpers/contrib/openstack/templates/section-service-user'], 'web_link': 'https://opendev.org/openstack/charm-nova-cloud-controller/commit/02fb0057482e14508c3a7ec3dbe0fe2840e7dd50', 'message': 'Use service_domain in [service_user] section\n\nSync from charm-helpers to update [service_user] config to use the\nservice domain.\n\nThe keystone charm currently creates two service users, one for the\nservice domain (for v3 authentication), and the other for the default\ndomain (for v2 authentication). The [service_user] config needs to\nuse the service domain.\n\nCloses-Bug: #2026202\nChange-Id: I6755706f192642a5454d92d257dec81bb5f74e40\n'}]",0,887833,02fb0057482e14508c3a7ec3dbe0fe2840e7dd50,9,5,1,11805,,,0,"Use service_domain in [service_user] section

Sync from charm-helpers to update [service_user] config to use the
service domain.

The keystone charm currently creates two service users, one for the
service domain (for v3 authentication), and the other for the default
domain (for v2 authentication). The [service_user] config needs to
use the service domain.

Closes-Bug: #2026202
Change-Id: I6755706f192642a5454d92d257dec81bb5f74e40
",git fetch https://review.opendev.org/openstack/charm-nova-cloud-controller refs/changes/33/887833/1 && git format-patch -1 --stdout FETCH_HEAD,"['charmhelpers/contrib/openstack/utils.py', 'charmhelpers/contrib/openstack/templates/section-service-user']",2,02fb0057482e14508c3a7ec3dbe0fe2840e7dd50,bug/2026202,project_domain_name = service_domain user_domain_name = service_domain,project_domain_id = default user_domain_id = default,19,2
openstack%2Fcharm-nova-cloud-controller~887808,openstack/charm-nova-cloud-controller,stable/zed,If54928aca61a400dbb864d02e3807f28123b8517,Use service_domain in [service_user] section,MERGED,2023-07-06 13:01:48.000000000,2023-07-12 15:17:00.000000000,2023-07-12 15:17:00.000000000,"[{'_account_id': 12549}, {'_account_id': 20648}, {'_account_id': 20870}, {'_account_id': 22348}, {'_account_id': 31203}]","[{'number': 1, 'created': '2023-07-06 13:01:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-nova-cloud-controller/commit/d82b574e56c0b6657a8a519aca5736191aedb069', 'message': 'Use service_domain in [service_user] section\n\nSync from charm-helpers to update [service_user] config to use the\nservice domain.\n\nThe keystone charm currently creates two service users, one for the\nservice domain (for v3 authentication), and the other for the default\ndomain (for v2 authentication). The [service_user] config needs to\nuse the service domain.\n\nCloses-Bug: #2026202\nChange-Id: If54928aca61a400dbb864d02e3807f28123b8517\n'}, {'number': 2, 'created': '2023-07-06 16:24:37.000000000', 'files': ['test-requirements.txt', 'charmhelpers/contrib/openstack/templates/section-service-user'], 'web_link': 'https://opendev.org/openstack/charm-nova-cloud-controller/commit/0985cf0a58a9389361910fc61a9420190960e34e', 'message': 'Use service_domain in [service_user] section\n\nSync from charm-helpers to update [service_user] config to use the\nservice domain.\n\nThe keystone charm currently creates two service users, one for the\nservice domain (for v3 authentication), and the other for the default\ndomain (for v2 authentication). The [service_user] config needs to\nuse the service domain.\n\nCloses-Bug: #2026202\nChange-Id: If54928aca61a400dbb864d02e3807f28123b8517\n'}]",0,887808,0985cf0a58a9389361910fc61a9420190960e34e,11,5,2,11805,,,0,"Use service_domain in [service_user] section

Sync from charm-helpers to update [service_user] config to use the
service domain.

The keystone charm currently creates two service users, one for the
service domain (for v3 authentication), and the other for the default
domain (for v2 authentication). The [service_user] config needs to
use the service domain.

Closes-Bug: #2026202
Change-Id: If54928aca61a400dbb864d02e3807f28123b8517
",git fetch https://review.opendev.org/openstack/charm-nova-cloud-controller refs/changes/08/887808/1 && git format-patch -1 --stdout FETCH_HEAD,['charmhelpers/contrib/openstack/templates/section-service-user'],1,d82b574e56c0b6657a8a519aca5736191aedb069,bug/2026202,project_domain_name = service_domain user_domain_name = service_domain,project_domain_id = default user_domain_id = default,2,2
openstack%2Fcharm-nova-cloud-controller~887805,openstack/charm-nova-cloud-controller,stable/2023.1,I3d1e0c14bfe91261f53675fb8afdbff294400904,Use service_domain in [service_user] section,MERGED,2023-07-06 13:00:49.000000000,2023-07-12 15:16:58.000000000,2023-07-12 15:16:58.000000000,"[{'_account_id': 12549}, {'_account_id': 20648}, {'_account_id': 20870}, {'_account_id': 22348}, {'_account_id': 31203}]","[{'number': 1, 'created': '2023-07-06 13:00:49.000000000', 'files': ['charmhelpers/contrib/openstack/templates/section-service-user'], 'web_link': 'https://opendev.org/openstack/charm-nova-cloud-controller/commit/ee7deb23f2eb4b10599031494a8fb3b6848863c3', 'message': 'Use service_domain in [service_user] section\n\nSync from charm-helpers to update [service_user] config to use the\nservice domain.\n\nThe keystone charm currently creates two service users, one for the\nservice domain (for v3 authentication), and the other for the default\ndomain (for v2 authentication). The [service_user] config needs to\nuse the service domain.\n\nCloses-Bug: #2026202\nChange-Id: I3d1e0c14bfe91261f53675fb8afdbff294400904\n'}]",0,887805,ee7deb23f2eb4b10599031494a8fb3b6848863c3,9,5,1,11805,,,0,"Use service_domain in [service_user] section

Sync from charm-helpers to update [service_user] config to use the
service domain.

The keystone charm currently creates two service users, one for the
service domain (for v3 authentication), and the other for the default
domain (for v2 authentication). The [service_user] config needs to
use the service domain.

Closes-Bug: #2026202
Change-Id: I3d1e0c14bfe91261f53675fb8afdbff294400904
",git fetch https://review.opendev.org/openstack/charm-nova-cloud-controller refs/changes/05/887805/1 && git format-patch -1 --stdout FETCH_HEAD,['charmhelpers/contrib/openstack/templates/section-service-user'],1,ee7deb23f2eb4b10599031494a8fb3b6848863c3,bug/2026202,project_domain_name = service_domain user_domain_name = service_domain,project_domain_id = default user_domain_id = default,2,2
openstack%2Fcharm-ironic-conductor~887899,openstack/charm-ironic-conductor,stable/wallaby,Iba684eef4fa638d4321171decdc5d079eac7aa6a,Use service_domain in [service_user] section,MERGED,2023-07-06 20:02:24.000000000,2023-07-12 15:16:45.000000000,2023-07-12 15:16:45.000000000,"[{'_account_id': 12549}, {'_account_id': 20648}, {'_account_id': 20870}, {'_account_id': 22348}, {'_account_id': 31203}]","[{'number': 1, 'created': '2023-07-06 20:02:24.000000000', 'files': ['src/build.lock'], 'web_link': 'https://opendev.org/openstack/charm-ironic-conductor/commit/f9d02e3d8362649cc487f0a5fa3204428a298299', 'message': 'Use service_domain in [service_user] section\n\nRebuild to update [service_user] config to use the service domain.\nThis was fixed in charm-helpers.\n\nThe keystone charm currently creates two service users, one for the\nservice domain (for v3 authentication), and the other for the default\ndomain (for v2 authentication). The [service_user] config needs to\nuse the service domain.\n\nCloses-Bug: #2026202\nChange-Id: Iba684eef4fa638d4321171decdc5d079eac7aa6a\n'}]",1,887899,f9d02e3d8362649cc487f0a5fa3204428a298299,11,5,1,11805,,,0,"Use service_domain in [service_user] section

Rebuild to update [service_user] config to use the service domain.
This was fixed in charm-helpers.

The keystone charm currently creates two service users, one for the
service domain (for v3 authentication), and the other for the default
domain (for v2 authentication). The [service_user] config needs to
use the service domain.

Closes-Bug: #2026202
Change-Id: Iba684eef4fa638d4321171decdc5d079eac7aa6a
",git fetch https://review.opendev.org/openstack/charm-ironic-conductor refs/changes/99/887899/1 && git format-patch -1 --stdout FETCH_HEAD,['src/build.lock'],1,f9d02e3d8362649cc487f0a5fa3204428a298299,bug/2026202," ""version"": ""0330c6814eb84ee8531445ec2a41e8f26004e442"","," ""version"": ""77f25c49dfd08ac16c7a1cc018b008aa704bd313"",",1,1
openstack%2Fcharm-ironic-conductor~887897,openstack/charm-ironic-conductor,stable/xena,I6cb98e6a74437efccd028b27d2e6aa5cd547a340,Use service_domain in [service_user] section,MERGED,2023-07-06 20:01:33.000000000,2023-07-12 15:16:44.000000000,2023-07-12 15:16:44.000000000,"[{'_account_id': 12549}, {'_account_id': 20648}, {'_account_id': 20870}, {'_account_id': 22348}, {'_account_id': 31203}]","[{'number': 1, 'created': '2023-07-06 20:01:33.000000000', 'files': ['src/build.lock'], 'web_link': 'https://opendev.org/openstack/charm-ironic-conductor/commit/12ef5684af95eadb3080ca2c99c4495418f1f74d', 'message': 'Use service_domain in [service_user] section\n\nRebuild to update [service_user] config to use the service domain.\nThis was fixed in charm-helpers.\n\nThe keystone charm currently creates two service users, one for the\nservice domain (for v3 authentication), and the other for the default\ndomain (for v2 authentication). The [service_user] config needs to\nuse the service domain.\n\nCloses-Bug: #2026202\nChange-Id: I6cb98e6a74437efccd028b27d2e6aa5cd547a340\n'}]",1,887897,12ef5684af95eadb3080ca2c99c4495418f1f74d,11,5,1,11805,,,0,"Use service_domain in [service_user] section

Rebuild to update [service_user] config to use the service domain.
This was fixed in charm-helpers.

The keystone charm currently creates two service users, one for the
service domain (for v3 authentication), and the other for the default
domain (for v2 authentication). The [service_user] config needs to
use the service domain.

Closes-Bug: #2026202
Change-Id: I6cb98e6a74437efccd028b27d2e6aa5cd547a340
",git fetch https://review.opendev.org/openstack/charm-ironic-conductor refs/changes/97/887897/1 && git format-patch -1 --stdout FETCH_HEAD,['src/build.lock'],1,12ef5684af95eadb3080ca2c99c4495418f1f74d,bug/2026202," ""version"": ""0cdd983ca2f2cb8ab7aec58d3b955953f5ef9ddf"","," ""version"": ""5f8dacee1a7583d3927d39887bd5460ff2e2f812"",",1,1
openstack%2Fcharm-nova-compute~887834,openstack/charm-nova-compute,stable/xena,If2e2b102e37c21fd16c6de88144b0ec8e477306b,Use service_domain in [service_user] section,MERGED,2023-07-06 13:12:21.000000000,2023-07-12 15:14:24.000000000,2023-07-12 15:14:24.000000000,"[{'_account_id': 12549}, {'_account_id': 20648}, {'_account_id': 20870}, {'_account_id': 22348}, {'_account_id': 31203}]","[{'number': 1, 'created': '2023-07-06 13:12:21.000000000', 'files': ['hooks/charmhelpers/contrib/openstack/templates/section-service-user'], 'web_link': 'https://opendev.org/openstack/charm-nova-compute/commit/27d98cdf55e33b44719074e89d606a0c21ab933c', 'message': 'Use service_domain in [service_user] section\n\nSync from charm-helpers to update [service_user] config to use the\nservice domain.\n\nThe keystone charm currently creates two service users, one for the\nservice domain (for v3 authentication), and the other for the default\ndomain (for v2 authentication). The [service_user] config needs to\nuse the service domain.\n\nCloses-Bug: #2026202\nChange-Id: If2e2b102e37c21fd16c6de88144b0ec8e477306b\n'}]",0,887834,27d98cdf55e33b44719074e89d606a0c21ab933c,9,5,1,11805,,,0,"Use service_domain in [service_user] section

Sync from charm-helpers to update [service_user] config to use the
service domain.

The keystone charm currently creates two service users, one for the
service domain (for v3 authentication), and the other for the default
domain (for v2 authentication). The [service_user] config needs to
use the service domain.

Closes-Bug: #2026202
Change-Id: If2e2b102e37c21fd16c6de88144b0ec8e477306b
",git fetch https://review.opendev.org/openstack/charm-nova-compute refs/changes/34/887834/1 && git format-patch -1 --stdout FETCH_HEAD,['hooks/charmhelpers/contrib/openstack/templates/section-service-user'],1,27d98cdf55e33b44719074e89d606a0c21ab933c,bug/2026202,project_domain_name = service_domain user_domain_name = service_domain,project_domain_id = default user_domain_id = default,2,2
openstack%2Fcharm-nova-compute~887804,openstack/charm-nova-compute,stable/2023.1,I2663b2f6b05f82602d84b7be10b8b5435803c234,Use service_domain in [service_user] section,MERGED,2023-07-06 13:00:39.000000000,2023-07-12 15:14:23.000000000,2023-07-12 15:14:23.000000000,"[{'_account_id': 12549}, {'_account_id': 20648}, {'_account_id': 20870}, {'_account_id': 22348}, {'_account_id': 31203}]","[{'number': 1, 'created': '2023-07-06 13:00:39.000000000', 'files': ['hooks/charmhelpers/contrib/openstack/templates/section-service-user'], 'web_link': 'https://opendev.org/openstack/charm-nova-compute/commit/ec6db4c3bd02867524ef0c292f0dec4f0f6e4f0a', 'message': 'Use service_domain in [service_user] section\n\nSync from charm-helpers to update [service_user] config to use the\nservice domain.\n\nThe keystone charm currently creates two service users, one for the\nservice domain (for v3 authentication), and the other for the default\ndomain (for v2 authentication). The [service_user] config needs to\nuse the service domain.\n\nCloses-Bug: #2026202\nChange-Id: I2663b2f6b05f82602d84b7be10b8b5435803c234\n'}]",0,887804,ec6db4c3bd02867524ef0c292f0dec4f0f6e4f0a,9,5,1,11805,,,0,"Use service_domain in [service_user] section

Sync from charm-helpers to update [service_user] config to use the
service domain.

The keystone charm currently creates two service users, one for the
service domain (for v3 authentication), and the other for the default
domain (for v2 authentication). The [service_user] config needs to
use the service domain.

Closes-Bug: #2026202
Change-Id: I2663b2f6b05f82602d84b7be10b8b5435803c234
",git fetch https://review.opendev.org/openstack/charm-nova-compute refs/changes/04/887804/1 && git format-patch -1 --stdout FETCH_HEAD,['hooks/charmhelpers/contrib/openstack/templates/section-service-user'],1,ec6db4c3bd02867524ef0c292f0dec4f0f6e4f0a,bug/2026202,project_domain_name = service_domain user_domain_name = service_domain,project_domain_id = default user_domain_id = default,2,2
openstack%2Fcharm-cinder~887830,openstack/charm-cinder,stable/yoga,I65ec151d56520471b7fc4b02f2e1d7e48a219faf,Use service_domain in [service_user] section,MERGED,2023-07-06 13:08:53.000000000,2023-07-12 15:13:58.000000000,2023-07-12 15:13:58.000000000,"[{'_account_id': 12549}, {'_account_id': 20648}, {'_account_id': 20870}, {'_account_id': 22348}, {'_account_id': 31203}]","[{'number': 1, 'created': '2023-07-06 13:08:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-cinder/commit/020ca2027224040912abdc3714fdd21d61fba65a', 'message': 'Use service_domain in [service_user] section\n\nSync from charm-helpers to update [service_user] config to use the\nservice domain.\n\nThe keystone charm currently creates two service users, one for the\nservice domain (for v3 authentication), and the other for the default\ndomain (for v2 authentication). The [service_user] config needs to\nuse the service domain.\n\nCloses-Bug: #2026202\nChange-Id: I65ec151d56520471b7fc4b02f2e1d7e48a219faf\n'}, {'number': 2, 'created': '2023-07-06 16:21:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-cinder/commit/254d60eb4ba860f15f1432c2a81b9e26c3461d86', 'message': 'Use service_domain in [service_user] section\n\nSync from charm-helpers to update [service_user] config to use the\nservice domain.\n\nThe keystone charm currently creates two service users, one for the\nservice domain (for v3 authentication), and the other for the default\ndomain (for v2 authentication). The [service_user] config needs to\nuse the service domain.\n\nCloses-Bug: #2026202\nChange-Id: I65ec151d56520471b7fc4b02f2e1d7e48a219faf\n'}, {'number': 3, 'created': '2023-07-06 16:23:56.000000000', 'files': ['charmhelpers/contrib/openstack/templates/section-service-user'], 'web_link': 'https://opendev.org/openstack/charm-cinder/commit/c4007b5a8b30b04425b530bb7ccedf96da6c986e', 'message': 'Use service_domain in [service_user] section\n\nSync from charm-helpers to update [service_user] config to use the\nservice domain.\n\nThe keystone charm currently creates two service users, one for the\nservice domain (for v3 authentication), and the other for the default\ndomain (for v2 authentication). The [service_user] config needs to\nuse the service domain.\n\nCloses-Bug: #2026202\nChange-Id: I65ec151d56520471b7fc4b02f2e1d7e48a219faf\n'}]",1,887830,c4007b5a8b30b04425b530bb7ccedf96da6c986e,15,5,3,11805,,,0,"Use service_domain in [service_user] section

Sync from charm-helpers to update [service_user] config to use the
service domain.

The keystone charm currently creates two service users, one for the
service domain (for v3 authentication), and the other for the default
domain (for v2 authentication). The [service_user] config needs to
use the service domain.

Closes-Bug: #2026202
Change-Id: I65ec151d56520471b7fc4b02f2e1d7e48a219faf
",git fetch https://review.opendev.org/openstack/charm-cinder refs/changes/30/887830/1 && git format-patch -1 --stdout FETCH_HEAD,['charmhelpers/contrib/openstack/templates/section-service-user'],1,020ca2027224040912abdc3714fdd21d61fba65a,bug/2026202,project_domain_name = service_domain user_domain_name = service_domain,project_domain_id = default user_domain_id = default,2,2
openstack%2Fcharm-cinder~887806,openstack/charm-cinder,stable/2023.1,Iec65f1ff082fd59c962671bfa367d593c20b3bd2,Use service_domain in [service_user] section,MERGED,2023-07-06 13:00:58.000000000,2023-07-12 15:13:57.000000000,2023-07-12 15:13:57.000000000,"[{'_account_id': 12549}, {'_account_id': 20648}, {'_account_id': 20870}, {'_account_id': 22348}, {'_account_id': 31203}]","[{'number': 1, 'created': '2023-07-06 13:00:58.000000000', 'files': ['charmhelpers/contrib/openstack/templates/section-service-user'], 'web_link': 'https://opendev.org/openstack/charm-cinder/commit/1515cbc8c749c1cee7601f53aad9bc3126f1f69a', 'message': 'Use service_domain in [service_user] section\n\nSync from charm-helpers to update [service_user] config to use the\nservice domain.\n\nThe keystone charm currently creates two service users, one for the\nservice domain (for v3 authentication), and the other for the default\ndomain (for v2 authentication). The [service_user] config needs to\nuse the service domain.\n\nCloses-Bug: #2026202\nChange-Id: Iec65f1ff082fd59c962671bfa367d593c20b3bd2\n'}]",0,887806,1515cbc8c749c1cee7601f53aad9bc3126f1f69a,9,5,1,11805,,,0,"Use service_domain in [service_user] section

Sync from charm-helpers to update [service_user] config to use the
service domain.

The keystone charm currently creates two service users, one for the
service domain (for v3 authentication), and the other for the default
domain (for v2 authentication). The [service_user] config needs to
use the service domain.

Closes-Bug: #2026202
Change-Id: Iec65f1ff082fd59c962671bfa367d593c20b3bd2
",git fetch https://review.opendev.org/openstack/charm-cinder refs/changes/06/887806/1 && git format-patch -1 --stdout FETCH_HEAD,['charmhelpers/contrib/openstack/templates/section-service-user'],1,1515cbc8c749c1cee7601f53aad9bc3126f1f69a,bug/2026202,project_domain_name = service_domain user_domain_name = service_domain,project_domain_id = default user_domain_id = default,2,2
openstack%2Fcharm-ironic-api~887894,openstack/charm-ironic-api,stable/yoga,Iea73c43664edc593c75a1ef3da5e7e8d7fab664c,Use service_domain in [service_user] section,MERGED,2023-07-06 20:00:43.000000000,2023-07-12 15:13:37.000000000,2023-07-12 15:13:37.000000000,"[{'_account_id': 12549}, {'_account_id': 20648}, {'_account_id': 20870}, {'_account_id': 22348}, {'_account_id': 31203}]","[{'number': 1, 'created': '2023-07-06 20:00:43.000000000', 'files': ['src/build.lock'], 'web_link': 'https://opendev.org/openstack/charm-ironic-api/commit/25f1ebe6c13df2fa7444ecb6b32540306b919b8d', 'message': 'Use service_domain in [service_user] section\n\nRebuild to update [service_user] config to use the service domain.\nThis was fixed in charm-helpers.\n\nThe keystone charm currently creates two service users, one for the\nservice domain (for v3 authentication), and the other for the default\ndomain (for v2 authentication). The [service_user] config needs to\nuse the service domain.\n\nCloses-Bug: #2026202\nChange-Id: Iea73c43664edc593c75a1ef3da5e7e8d7fab664c\n'}]",1,887894,25f1ebe6c13df2fa7444ecb6b32540306b919b8d,11,5,1,11805,,,0,"Use service_domain in [service_user] section

Rebuild to update [service_user] config to use the service domain.
This was fixed in charm-helpers.

The keystone charm currently creates two service users, one for the
service domain (for v3 authentication), and the other for the default
domain (for v2 authentication). The [service_user] config needs to
use the service domain.

Closes-Bug: #2026202
Change-Id: Iea73c43664edc593c75a1ef3da5e7e8d7fab664c
",git fetch https://review.opendev.org/openstack/charm-ironic-api refs/changes/94/887894/1 && git format-patch -1 --stdout FETCH_HEAD,['src/build.lock'],1,25f1ebe6c13df2fa7444ecb6b32540306b919b8d,bug/2026202," ""version"": ""4ca4691acdc17cfd99082afb6d07b924ddd455bd"","," ""version"": ""32772ff502e179027f46daaa04729a2f5d49f5e5"",",1,1
openstack%2Fnova~879405,openstack/nova,stable/wallaby,I7606d6eb3e08548c1df9dc245ab39cced7de1fb5,Add debug log for scheduler weight calculation,MERGED,2023-04-04 12:24:24.000000000,2023-07-12 15:13:22.000000000,2023-07-12 15:12:05.000000000,"[{'_account_id': 4393}, {'_account_id': 4690}, {'_account_id': 7166}, {'_account_id': 17685}, {'_account_id': 20733}, {'_account_id': 22348}, {'_account_id': 34860}]","[{'number': 1, 'created': '2023-04-04 12:24:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/45bfb1bfd3d5dc9fd284c9d3fc462ad50cfe6486', 'message': 'Add debug log for scheduler weight calculation\n\nWe have all the weighers enabled by default and each can have its own\nmultiplier making the final compute node order calculation pretty\ncomplex. This patch adds some debug logging that helps understanding how\nthe final ordering was reached.\n\nChange-Id: I7606d6eb3e08548c1df9dc245ab39cced7de1fb5\n(cherry picked from commit 154ab7b2f9ad80fe432d2c036d5e8c4ee171897b)\n'}, {'number': 2, 'created': '2023-04-09 19:35:07.000000000', 'files': ['nova/weights.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/cf8e81699c90c396b76e3252579acfc5cb722621', 'message': 'Add debug log for scheduler weight calculation\n\nWe have all the weighers enabled by default and each can have its own\nmultiplier making the final compute node order calculation pretty\ncomplex. This patch adds some debug logging that helps understanding how\nthe final ordering was reached.\n\nChange-Id: I7606d6eb3e08548c1df9dc245ab39cced7de1fb5\n(cherry picked from commit 154ab7b2f9ad80fe432d2c036d5e8c4ee171897b)\n(cherry picked from commit 30c7180e1e655176952609e80f1f21cf8b6d13a0)\n'}]",9,879405,cf8e81699c90c396b76e3252579acfc5cb722621,38,7,2,19234,,,0,"Add debug log for scheduler weight calculation

We have all the weighers enabled by default and each can have its own
multiplier making the final compute node order calculation pretty
complex. This patch adds some debug logging that helps understanding how
the final ordering was reached.

Change-Id: I7606d6eb3e08548c1df9dc245ab39cced7de1fb5
(cherry picked from commit 154ab7b2f9ad80fe432d2c036d5e8c4ee171897b)
(cherry picked from commit 30c7180e1e655176952609e80f1f21cf8b6d13a0)
",git fetch https://review.opendev.org/openstack/nova refs/changes/05/879405/1 && git format-patch -1 --stdout FETCH_HEAD,['nova/weights.py'],1,45bfb1bfd3d5dc9fd284c9d3fc462ad50cfe6486,,"from oslo_log import log as logging LOG = logging.getLogger(__name__) LOG.debug( ""%s: raw weights %s"", weigher.__class__.__name__, {(obj.obj.host, obj.obj.nodename): weight for obj, weight in zip(weighed_objs, weights)} ) weights = list( normalize( weights, minval=weigher.minval, maxval=weigher.maxval)) LOG.debug( ""%s: normalized weights %s"", weigher.__class__.__name__, {(obj.obj.host, obj.obj.nodename): weight for obj, weight in zip(weighed_objs, weights)} ) log_data = {} multiplier = weigher.weight_multiplier(obj.obj) weigher_score = multiplier * weight obj.weight += weigher_score log_data[(obj.obj.host, obj.obj.nodename)] = ( f""{multiplier} * {weight}"") LOG.debug( ""%s: score (multiplier * weight) %s"", weigher.__class__.__name__, {name: log for name, log in log_data.items()} )"," weights = normalize(weights, minval=weigher.minval, maxval=weigher.maxval) obj.weight += weigher.weight_multiplier(obj.obj) * weight",36,4
openstack%2Fcharm-ironic-conductor~887895,openstack/charm-ironic-conductor,stable/yoga,Ib9f3f724634ff183e137ee2c85614ce4933112bd,Use service_domain in [service_user] section,MERGED,2023-07-06 20:00:46.000000000,2023-07-12 15:11:52.000000000,2023-07-12 15:11:52.000000000,"[{'_account_id': 12549}, {'_account_id': 20648}, {'_account_id': 20870}, {'_account_id': 22348}, {'_account_id': 31203}]","[{'number': 1, 'created': '2023-07-06 20:00:46.000000000', 'files': ['src/build.lock'], 'web_link': 'https://opendev.org/openstack/charm-ironic-conductor/commit/f609c3b582a61e49c9469da8de6c9246c4c48e46', 'message': 'Use service_domain in [service_user] section\n\nRebuild to update [service_user] config to use the service domain.\nThis was fixed in charm-helpers.\n\nThe keystone charm currently creates two service users, one for the\nservice domain (for v3 authentication), and the other for the default\ndomain (for v2 authentication). The [service_user] config needs to\nuse the service domain.\n\nCloses-Bug: #2026202\nChange-Id: Ib9f3f724634ff183e137ee2c85614ce4933112bd\n'}]",1,887895,f609c3b582a61e49c9469da8de6c9246c4c48e46,11,5,1,11805,,,0,"Use service_domain in [service_user] section

Rebuild to update [service_user] config to use the service domain.
This was fixed in charm-helpers.

The keystone charm currently creates two service users, one for the
service domain (for v3 authentication), and the other for the default
domain (for v2 authentication). The [service_user] config needs to
use the service domain.

Closes-Bug: #2026202
Change-Id: Ib9f3f724634ff183e137ee2c85614ce4933112bd
",git fetch https://review.opendev.org/openstack/charm-ironic-conductor refs/changes/95/887895/1 && git format-patch -1 --stdout FETCH_HEAD,['src/build.lock'],1,f609c3b582a61e49c9469da8de6c9246c4c48e46,bug/2026202," ""version"": ""4ca4691acdc17cfd99082afb6d07b924ddd455bd"","," ""version"": ""32772ff502e179027f46daaa04729a2f5d49f5e5"",",1,1
openstack%2Fpuppet-nova~886571,openstack/puppet-nova,master,I5a1caed433a87e4cf7cdc6c18b6a68e54d03577c,Ensure correct type for client_extraparams,MERGED,2023-06-21 07:02:00.000000000,2023-07-12 15:07:38.000000000,2023-07-12 15:07:38.000000000,"[{'_account_id': 14985}, {'_account_id': 16137}, {'_account_id': 22348}]","[{'number': 1, 'created': '2023-06-21 07:02:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-nova/commit/30644608b0f4032daeb6da8fe8e83a430862e9ec', 'message': 'Ensure correct type for client_extraparams\n\nThis parameter accepts only a hash value. This change defines\nthe parameter type at the interface level to validate the given\nvalue.\n\nChange-Id: I5a1caed433a87e4cf7cdc6c18b6a68e54d03577c\n'}, {'number': 2, 'created': '2023-06-21 08:37:53.000000000', 'files': ['manifests/migration/libvirt.pp'], 'web_link': 'https://opendev.org/openstack/puppet-nova/commit/f3d6d880d7b812289f95ff62cf6748293b3f0a35', 'message': 'Ensure correct type for client_extraparams\n\nThis parameter accepts only a hash value. This change defines\nthe parameter type at the interface level to validate the given\nvalue.\n\nChange-Id: I5a1caed433a87e4cf7cdc6c18b6a68e54d03577c\n'}]",5,886571,f3d6d880d7b812289f95ff62cf6748293b3f0a35,25,3,2,9816,,,0,"Ensure correct type for client_extraparams

This parameter accepts only a hash value. This change defines
the parameter type at the interface level to validate the given
value.

Change-Id: I5a1caed433a87e4cf7cdc6c18b6a68e54d03577c
",git fetch https://review.opendev.org/openstack/puppet-nova refs/changes/71/886571/1 && git format-patch -1 --stdout FETCH_HEAD,['manifests/migration/libvirt.pp'],1,30644608b0f4032daeb6da8fe8e83a430862e9ec,," Hash $client_extraparams = {}, if empty($client_extraparams) { $extra_params ='' } else {"," $client_extraparams = {}, if $client_extraparams != {} { } else { $extra_params =''",4,4
openstack%2Fpuppet-nova~886607,openstack/puppet-nova,stable/yoga,I7627a5a6233b3d157d930e5b62e612ce9defe1f2,Drop modular libvirt daemon names for Debian/Ubuntu,MERGED,2023-06-21 11:47:53.000000000,2023-07-12 15:00:51.000000000,2023-07-12 15:00:51.000000000,"[{'_account_id': 9816}, {'_account_id': 14985}, {'_account_id': 22348}]","[{'number': 1, 'created': '2023-06-21 11:47:53.000000000', 'files': ['manifests/params.pp'], 'web_link': 'https://opendev.org/openstack/puppet-nova/commit/7e0ce3b02fc21a21a018ca8382f88b1a6107a596', 'message': 'Drop modular libvirt daemon names for Debian/Ubuntu\n\nThese distributions do not support modular libvirt daemons and now\nthe module prohibit usage of that architecture. So these definitions\nare no longer used.\n\nChange-Id: I7627a5a6233b3d157d930e5b62e612ce9defe1f2\n(cherry picked from commit fe2b1c8255f4dc8777c3578f5361a0880f0986e1)\n(cherry picked from commit 510698dc0af64a962e63387729c2fa0a8be8c41e)\n(cherry picked from commit 2ec38244eb510fe72deb2e1c2194f137b897d445)\n'}]",0,886607,7e0ce3b02fc21a21a018ca8382f88b1a6107a596,7,3,1,16137,,,0,"Drop modular libvirt daemon names for Debian/Ubuntu

These distributions do not support modular libvirt daemons and now
the module prohibit usage of that architecture. So these definitions
are no longer used.

Change-Id: I7627a5a6233b3d157d930e5b62e612ce9defe1f2
(cherry picked from commit fe2b1c8255f4dc8777c3578f5361a0880f0986e1)
(cherry picked from commit 510698dc0af64a962e63387729c2fa0a8be8c41e)
(cherry picked from commit 2ec38244eb510fe72deb2e1c2194f137b897d445)
",git fetch https://review.opendev.org/openstack/puppet-nova refs/changes/07/886607/1 && git format-patch -1 --stdout FETCH_HEAD,['manifests/params.pp'],1,7e0ce3b02fc21a21a018ca8382f88b1a6107a596,, $virtsecret_service_name = undef $virtnodedev_service_name = undef $virtqemu_service_name = undef $virtproxy_service_name = undef $virtstorage_service_name = undef $virtsecret_service_name = undef $virtnodedev_service_name = undef $virtqemu_service_name = undef $virtproxy_service_name = undef $virtstorage_service_name = undef, $virtsecret_service_name = 'virtsecretd.socket' $virtnodedev_service_name = 'virtnodedevd.socket' $virtqemu_service_name = 'virtqemud.socket' $virtproxy_service_name = 'virtproxyd.socket' $virtstorage_service_name = 'virtstoraged.socket' $virtsecret_service_name = 'virtsecretd' $virtnodedev_service_name = 'virtnodedevd' $virtqemu_service_name = 'virtqemud' $virtproxy_service_name = 'virtproxyd' $virtstorage_service_name = 'virtstoraged',10,10
openstack%2Foslo.versionedobjects~883677,openstack/oslo.versionedobjects,master,I3da9745c8f9f4b5832f41933af6f177b0f876bb5,Bump bandit and make oslo.versionedobjects compatible with latest rules,MERGED,2023-05-19 14:27:28.000000000,2023-07-12 14:01:09.000000000,2023-07-12 13:59:55.000000000,"[{'_account_id': 9816}, {'_account_id': 15334}, {'_account_id': 22348}]","[{'number': 1, 'created': '2023-05-19 14:27:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.versionedobjects/commit/c34889562e2b337c1cb83aa0877e8ae2f483a464', 'message': 'Bump bandit and make oslo.versionedobjects compatible with latest rules\n\nFix B324 [1] by passing `usedforsecurity=False` to the hashing algorythmes.\nThose are called in testing context they are not used in\nsecurity context [2].\n\n[1] https://bandit.readthedocs.io/en/1.7.5/plugins/b324_hashlib.html\n[2] https: //docs.python.org/3/library/hashlib.html#hash-algorithms\nChange-Id: Ic186e1e68d3fc293762c250f83979f3147768585\n\nChange-Id: I3da9745c8f9f4b5832f41933af6f177b0f876bb5\n'}, {'number': 2, 'created': '2023-06-22 09:32:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.versionedobjects/commit/0bfc73f9585f5c9bdea26b4e56e020fb2ad170ad', 'message': 'Bump bandit and make oslo.versionedobjects compatible with latest rules\n\nChange-Id: Ic186e1e68d3fc293762c250f83979f3147768585\n\nChange-Id: I3da9745c8f9f4b5832f41933af6f177b0f876bb5\n'}, {'number': 3, 'created': '2023-07-12 10:32:07.000000000', 'files': ['test-requirements.txt', 'oslo_versionedobjects/tests/test_fixture.py'], 'web_link': 'https://opendev.org/openstack/oslo.versionedobjects/commit/f78601fd8e8c09380c10e27176d54428479ace5b', 'message': 'Bump bandit and make oslo.versionedobjects compatible with latest rules\n\nChange-Id: I3da9745c8f9f4b5832f41933af6f177b0f876bb5\n'}]",2,883677,f78601fd8e8c09380c10e27176d54428479ace5b,14,3,3,28522,,,0,"Bump bandit and make oslo.versionedobjects compatible with latest rules

Change-Id: I3da9745c8f9f4b5832f41933af6f177b0f876bb5
",git fetch https://review.opendev.org/openstack/oslo.versionedobjects refs/changes/77/883677/1 && git format-patch -1 --stdout FETCH_HEAD,"['test-requirements.txt', 'oslo_versionedobjects/tests/test_fixture.py']",2,c34889562e2b337c1cb83aa0877e8ae2f483a464,oslo-bump-bandit," expected_relevant_data).encode()), usedforsecurity=False).hexdigest() exp_relevant_data).encode()), usedforsecurity=False).hexdigest() exp_relevant_data).encode()), usedforsecurity=False).hexdigest()", expected_relevant_data).encode())).hexdigest() exp_relevant_data).encode())).hexdigest() exp_relevant_data).encode())).hexdigest(),7,4
openstack%2Fpuppet-neutron~886301,openstack/puppet-neutron,master,Ib124f05394b5f53cace06cd062ee2079afb311af,replace validate_legacy with proper data types,MERGED,2023-06-17 12:44:07.000000000,2023-07-12 13:53:26.000000000,2023-07-12 13:53:26.000000000,"[{'_account_id': 14985}, {'_account_id': 16137}, {'_account_id': 22348}]","[{'number': 1, 'created': '2023-06-17 12:44:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-neutron/commit/fbd3af4c344e7d06746c8f463ad275251de220c9', 'message': 'replace validate_legacy with proper data types\n\nthe validate_legacy function is marked for deprecation in\nv9.0.0 from puppetlabs-stdlib.\n\nChange-Id: Ib124f05394b5f53cace06cd062ee2079afb311af\n'}, {'number': 2, 'created': '2023-06-17 13:32:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-neutron/commit/54bf3c563185e4f92a5d9f579d82ac28c5901883', 'message': 'replace validate_legacy with proper data types\n\nthe validate_legacy function is marked for deprecation in\nv9.0.0 from puppetlabs-stdlib.\n\nChange-Id: Ib124f05394b5f53cace06cd062ee2079afb311af\n'}, {'number': 3, 'created': '2023-06-17 15:01:05.000000000', 'files': ['manifests/agents/ml2/linuxbridge.pp', 'manifests/agents/ml2/networking_baremetal.pp', 'manifests/db/mysql.pp', 'manifests/agents/ml2/ovn.pp', 'manifests/agents/l3.pp', 'manifests/agents/bgp_dragent.pp', 'manifests/agents/ml2/sriov.pp', 'manifests/services/bgpvpn.pp', 'manifests/agents/dhcp.pp', 'manifests/agents/ml2/mlnx.pp', 'manifests/agents/metering.pp', 'manifests/plugins/ml2/ovs_driver.pp', 'manifests/agents/ovn_metadata.pp', 'manifests/services/l2gw.pp', 'manifests/services/sfc.pp', 'manifests/agents/ml2/ovs.pp', 'manifests/config.pp', 'manifests/agents/ml2/macvtap.pp', 'manifests/plugins/ovs/opendaylight.pp', 'manifests/agents/bagpipe.pp', 'manifests/agents/l2gw.pp', 'manifests/plugins/ml2/sriov_driver.pp', 'manifests/agents/metadata.pp', 'manifests/policy.pp', 'manifests/server.pp'], 'web_link': 'https://opendev.org/openstack/puppet-neutron/commit/be045c24794d750821a962e1a8f21828073df3f6', 'message': 'replace validate_legacy with proper data types\n\nthe validate_legacy function is marked for deprecation in\nv9.0.0 from puppetlabs-stdlib.\n\nChange-Id: Ib124f05394b5f53cace06cd062ee2079afb311af\n'}]",5,886301,be045c24794d750821a962e1a8f21828073df3f6,26,3,3,7888,,,0,"replace validate_legacy with proper data types

the validate_legacy function is marked for deprecation in
v9.0.0 from puppetlabs-stdlib.

Change-Id: Ib124f05394b5f53cace06cd062ee2079afb311af
",git fetch https://review.opendev.org/openstack/puppet-neutron refs/changes/01/886301/1 && git format-patch -1 --stdout FETCH_HEAD,"['manifests/agents/ml2/linuxbridge.pp', 'manifests/agents/ml2/networking_baremetal.pp', 'manifests/db/mysql.pp', 'manifests/agents/ml2/ovn.pp', 'manifests/agents/l3.pp', 'manifests/agents/bgp_dragent.pp', 'manifests/agents/ml2/sriov.pp', 'manifests/services/bgpvpn.pp', 'manifests/agents/dhcp.pp', 'manifests/agents/ml2/mlnx.pp', 'manifests/agents/metering.pp', 'manifests/plugins/ml2/ovs_driver.pp', 'manifests/agents/ovn_metadata.pp', 'manifests/services/l2gw.pp', 'manifests/services/sfc.pp', 'manifests/agents/ml2/ovs.pp', 'manifests/config.pp', 'manifests/agents/ml2/macvtap.pp', 'manifests/plugins/ovs/opendaylight.pp', 'manifests/agents/bagpipe.pp', 'manifests/agents/l2gw.pp', 'manifests/plugins/ml2/sriov_driver.pp', 'manifests/agents/metadata.pp', 'manifests/policy.pp', 'manifests/server.pp']",25,fbd3af4c344e7d06746c8f463ad275251de220c9,replace-validate_legacy," Boolean $enabled = true, Boolean $manage_service = true, Boolean $sync_db = false, Boolean $ensure_vpnaas_package = false, Boolean $ensure_dr_package = false,"," $enabled = true, $manage_service = true, $sync_db = false, $ensure_vpnaas_package = false, $ensure_dr_package = false, validate_legacy(Boolean, 'validate_bool', $enabled) validate_legacy(Boolean, 'validate_bool', $manage_service) validate_legacy(Boolean, 'validate_bool', $sync_db) validate_legacy(Boolean, 'validate_bool', $ensure_vpnaas_package) validate_legacy(Boolean, 'validate_bool', $ensure_dr_package) ",134,237
openstack%2Fpuppet-nova~886606,openstack/puppet-nova,stable/yoga,I8eefc65e206bdb0532b6c5d08eee0d35d764a2b9,Prohibit modular libvirt in non RedHat distributions,MERGED,2023-06-21 11:47:53.000000000,2023-07-12 13:37:37.000000000,2023-07-12 13:37:37.000000000,"[{'_account_id': 9816}, {'_account_id': 14985}, {'_account_id': 22348}]","[{'number': 1, 'created': '2023-06-21 11:47:53.000000000', 'files': ['manifests/compute/libvirt/services.pp', 'manifests/migration/libvirt.pp', 'manifests/params.pp', 'spec/classes/nova_migration_libvirt_spec.rb', 'spec/classes/nova_compute_libvirt_services_spec.rb'], 'web_link': 'https://opendev.org/openstack/puppet-nova/commit/c40a9be0477bc33049681282548b378b74d72792', 'message': 'Prohibit modular libvirt in non RedHat distributions\n\nCurrently modular libvirt daemons are supported only by CentOS and\nRHEL. This makes sure the deployment fails in case the architecture is\nrequested in distros which do not support it.\n\nConflicts:\n\tspec/classes/nova_migration_libvirt_spec.rb\n\nChange-Id: I8eefc65e206bdb0532b6c5d08eee0d35d764a2b9\n(cherry picked from commit 0fe7de9b7710859c08428687ee6e35e1ef5fb822)\n(cherry picked from commit 861bef82b554f0d1003af2e26cbc49a7b33ac333)\n(cherry picked from commit 8b60d6ba8325cdc6447f91ce3a4231b0698dbeea)\n'}]",1,886606,c40a9be0477bc33049681282548b378b74d72792,9,3,1,16137,,,0,"Prohibit modular libvirt in non RedHat distributions

Currently modular libvirt daemons are supported only by CentOS and
RHEL. This makes sure the deployment fails in case the architecture is
requested in distros which do not support it.

Conflicts:
	spec/classes/nova_migration_libvirt_spec.rb

Change-Id: I8eefc65e206bdb0532b6c5d08eee0d35d764a2b9
(cherry picked from commit 0fe7de9b7710859c08428687ee6e35e1ef5fb822)
(cherry picked from commit 861bef82b554f0d1003af2e26cbc49a7b33ac333)
(cherry picked from commit 8b60d6ba8325cdc6447f91ce3a4231b0698dbeea)
",git fetch https://review.opendev.org/openstack/puppet-nova refs/changes/06/886606/1 && git format-patch -1 --stdout FETCH_HEAD,"['manifests/compute/libvirt/services.pp', 'manifests/migration/libvirt.pp', 'manifests/params.pp', 'spec/classes/nova_migration_libvirt_spec.rb', 'spec/classes/nova_compute_libvirt_services_spec.rb']",5,c40a9be0477bc33049681282548b378b74d72792,, end shared_examples_for 'nova compute libvirt services with modular libvirt' do context 'with default parameters' do if facts['osfamily'] == 'RedHat' it_configures 'nova compute libvirt services with modular libvirt' end, context 'with default parameters and modular-libvirt true' do,150,183
openstack%2Fpuppet-nova~886605,openstack/puppet-nova,stable/yoga,Ifac9cb6f0c47e18bc152ee6744b3572c8d33373a,Enable only sockets for modular libvirt daemons,MERGED,2023-06-21 11:47:53.000000000,2023-07-12 13:34:09.000000000,2023-07-12 13:34:09.000000000,"[{'_account_id': 9816}, {'_account_id': 14985}, {'_account_id': 22348}]","[{'number': 1, 'created': '2023-06-21 11:47:53.000000000', 'files': ['manifests/params.pp'], 'web_link': 'https://opendev.org/openstack/puppet-nova/commit/3ac5bff61a25c46bc47badbc2ef60a9430084a17', 'message': 'Enable only sockets for modular libvirt daemons\n\nIt seems some of the modular libvirt daemons are automatically stopped\nif these are unused, and that causes broken idempotency. According to\nthe libvirt doc[1], we have to enable only sockets and services are\nstarted automatically when these are required.\n\n[1] https://libvirt.org/daemons.html#switching-to-modular-daemons\n\nCloses-Bug: #2012423\nChange-Id: Ifac9cb6f0c47e18bc152ee6744b3572c8d33373a\n(cherry picked from commit ef8a070e853f88b8a7fde4eba0f9cd8db109d893)\n(cherry picked from commit e29196040a772140217200b013045c0306740e91)\n'}]",0,886605,3ac5bff61a25c46bc47badbc2ef60a9430084a17,7,3,1,16137,,,0,"Enable only sockets for modular libvirt daemons

It seems some of the modular libvirt daemons are automatically stopped
if these are unused, and that causes broken idempotency. According to
the libvirt doc[1], we have to enable only sockets and services are
started automatically when these are required.

[1] https://libvirt.org/daemons.html#switching-to-modular-daemons

Closes-Bug: #2012423
Change-Id: Ifac9cb6f0c47e18bc152ee6744b3572c8d33373a
(cherry picked from commit ef8a070e853f88b8a7fde4eba0f9cd8db109d893)
(cherry picked from commit e29196040a772140217200b013045c0306740e91)
",git fetch https://review.opendev.org/openstack/puppet-nova refs/changes/05/886605/1 && git format-patch -1 --stdout FETCH_HEAD,['manifests/params.pp'],1,3ac5bff61a25c46bc47badbc2ef60a9430084a17,, $virtsecret_service_name = 'virtsecretd.socket' $virtnodedev_service_name = 'virtnodedevd.socket' $virtqemu_service_name = 'virtqemud.socket' $virtproxy_service_name = 'virtproxyd.socket' $virtstorage_service_name = 'virtstoraged.socket' $virtsecret_service_name = 'virtsecretd.socket' $virtnodedev_service_name = 'virtnodedevd.socket' $virtqemu_service_name = 'virtqemud.socket' $virtproxy_service_name = 'virtproxyd.socket' $virtstorage_service_name = 'virtstoraged.socket', $virtsecret_service_name = 'virtsecretd' $virtnodedev_service_name = 'virtnodedevd' $virtqemu_service_name = 'virtqemud' $virtproxy_service_name = 'virtproxyd' $virtstorage_service_name = 'virtstoraged' $virtsecret_service_name = 'virtsecretd' $virtnodedev_service_name = 'virtnodedevd' $virtqemu_service_name = 'virtqemud' $virtproxy_service_name = 'virtproxyd' $virtstorage_service_name = 'virtstoraged',10,10
openstack%2Foslo.rootwrap~883672,openstack/oslo.rootwrap,master,I17944faf6c7b60c5844315c716dd69e2f32679f9,Bump bandit,MERGED,2023-05-19 13:46:40.000000000,2023-07-12 13:31:36.000000000,2023-07-12 13:30:22.000000000,"[{'_account_id': 308}, {'_account_id': 15334}, {'_account_id': 22348}]","[{'number': 1, 'created': '2023-05-19 13:46:40.000000000', 'files': ['test-requirements.txt'], 'web_link': 'https://opendev.org/openstack/oslo.rootwrap/commit/0660a66e3b3c8f5d79a63845df8996a7f6aae340', 'message': 'Bump bandit\n\nChange-Id: I17944faf6c7b60c5844315c716dd69e2f32679f9\n'}]",1,883672,0660a66e3b3c8f5d79a63845df8996a7f6aae340,12,3,1,28522,,,0,"Bump bandit

Change-Id: I17944faf6c7b60c5844315c716dd69e2f32679f9
",git fetch https://review.opendev.org/openstack/oslo.rootwrap refs/changes/72/883672/1 && git format-patch -1 --stdout FETCH_HEAD,['test-requirements.txt'],1,0660a66e3b3c8f5d79a63845df8996a7f6aae340,oslo-bump-bandit,"bandit>=1.7.0,<1.8.0 # Apache-2.0","bandit>=1.6.0,<1.7.0 # Apache-2.0",1,1
openstack%2Ftripleo-common~877916,openstack/tripleo-common,stable/zed,I10a1b24915bc214f1a2d228dfe4f8a786a96ac96,do not merge: test,ABANDONED,2023-03-20 13:37:09.000000000,2023-07-12 13:10:26.000000000,,"[{'_account_id': 6926}, {'_account_id': 11166}, {'_account_id': 22348}, {'_account_id': 22954}]","[{'number': 1, 'created': '2023-03-20 13:37:09.000000000', 'files': ['container-images/tripleo_containers.yaml.j2'], 'web_link': 'https://opendev.org/openstack/tripleo-common/commit/89121e0ffa9c03675844e7ece1c2eaeec6f23f73', 'message': 'do not merge: test\n\nChange-Id: I10a1b24915bc214f1a2d228dfe4f8a786a96ac96\n'}]",1,877916,89121e0ffa9c03675844e7ece1c2eaeec6f23f73,4,4,1,14287,,,0,"do not merge: test

Change-Id: I10a1b24915bc214f1a2d228dfe4f8a786a96ac96
",git fetch https://review.opendev.org/openstack/tripleo-common refs/changes/16/877916/1 && git format-patch -1 --stdout FETCH_HEAD,['container-images/tripleo_containers.yaml.j2'],1,89121e0ffa9c03675844e7ece1c2eaeec6f23f73,, - ContainerNovaLibvirtConfigImage - OS::TripleO::Services::NovaLibvirtLegacy,,2,0
openstack%2Fcharm-neutron-api-plugin-ovn~888057,openstack/charm-neutron-api-plugin-ovn,stable/ussuri,I26939ef7eed5eb6b58d6860b3a409657aec6b3f3,Add 'ovn-source' config option.,ABANDONED,2023-07-10 16:16:06.000000000,2023-07-12 12:42:44.000000000,,"[{'_account_id': 20648}, {'_account_id': 22348}]","[{'number': 1, 'created': '2023-07-10 16:16:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-neutron-api-plugin-ovn/commit/f28a22426181c93ee9910e26f4131bfa65f3e657', 'message': 'Add \'ovn-source\' config option.\n\nThis option enables configuration of overlay package\nrepository for installation of OVN packages that are\nnot available in default distribution repository.\n\nExpected behavior:\n* New deployments will use default overlay for\n  their series.\n* Setting this option to ""distro"" allows new\n  deployment that does not use overlay repository\n* Existing deployments that are upgraded to this\n  version of the charm won\'t automatically apply\n  repository overlay and will keep using their\n  current defaults.\n\nCloses-Bug: #1992770\n\n(cherry picked from commit 412885acc9aeb94de910757d1fee5658a8de9a10)\nChange-Id: I26939ef7eed5eb6b58d6860b3a409657aec6b3f3\n'}, {'number': 2, 'created': '2023-07-10 16:42:37.000000000', 'files': ['src/config.yaml', 'unit_tests/test_lib_charm_openstack_ovn.py', 'src/tests/bundles/focal-ussuri.yaml', 'src/reactive/neutron_api_plugin_ovn_handlers.py', 'src/build.lock', 'src/lib/charm/openstack/neutron_api_plugin_ovn.py', 'unit_tests/test_reactive_neutron_api_plugin_ovn_handlers.py'], 'web_link': 'https://opendev.org/openstack/charm-neutron-api-plugin-ovn/commit/c2a1e2dba21c9094c21150bd1965108d079adc1f', 'message': 'Add \'ovn-source\' config option.\n\nThis option enables configuration of overlay package\nrepository for installation of OVN packages that are\nnot available in default distribution repository.\n\nExpected behavior:\n* New deployments will use default overlay for\n  their series.\n* Setting this option to ""distro"" allows new\n  deployment that does not use overlay repository\n* Existing deployments that are upgraded to this\n  version of the charm won\'t automatically apply\n  repository overlay and will keep using their\n  current defaults.\n\nCloses-Bug: #1992770\n\n(cherry picked from commit 412885acc9aeb94de910757d1fee5658a8de9a10)\nChange-Id: I26939ef7eed5eb6b58d6860b3a409657aec6b3f3\n'}]",2,888057,c2a1e2dba21c9094c21150bd1965108d079adc1f,9,2,2,32288,,,0,"Add 'ovn-source' config option.

This option enables configuration of overlay package
repository for installation of OVN packages that are
not available in default distribution repository.

Expected behavior:
* New deployments will use default overlay for
  their series.
* Setting this option to ""distro"" allows new
  deployment that does not use overlay repository
* Existing deployments that are upgraded to this
  version of the charm won't automatically apply
  repository overlay and will keep using their
  current defaults.

Closes-Bug: #1992770

(cherry picked from commit 412885acc9aeb94de910757d1fee5658a8de9a10)
Change-Id: I26939ef7eed5eb6b58d6860b3a409657aec6b3f3
",git fetch https://review.opendev.org/openstack/charm-neutron-api-plugin-ovn refs/changes/57/888057/1 && git format-patch -1 --stdout FETCH_HEAD,"['src/config.yaml', 'unit_tests/test_lib_charm_openstack_ovn.py', 'src/tests/bundles/focal-ussuri.yaml', 'src/reactive/neutron_api_plugin_ovn_handlers.py', 'src/build.lock', 'src/lib/charm/openstack/neutron_api_plugin_ovn.py', 'unit_tests/test_reactive_neutron_api_plugin_ovn_handlers.py']",7,f28a22426181c93ee9910e26f4131bfa65f3e657,," 'stamp_fresh_deployment': ( 'charm.installed', 'leadership.set.install_stamp', ), 'stamp_upgraded_deployment': ( 'is-update-status-hook', 'leadership.set.install_stamp', 'leadership.set.upgrade_stamp' ), 'enable_install': ( 'charm.installed', 'is-update-status-hook', ), 'ovn_source_changed': ('config.changed.ovn-source',), 'stamp_fresh_deployment': ('leadership.is_leader',), 'stamp_upgraded_deployment': ( 'charm.installed', 'leadership.is_leader' ), 'when_any': { 'enable_install': ( 'leadership.set.install_stamp', 'leadership.set.upgrade_stamp'), }, 'when_not': { 'ovn_source_changed': ('config.default.ovn-source',) } def test_ovn_source_config_changed(self): """"""Test that changing 'ovn-source' config triggers package upgrade."""""" config = {'ovn-source': 'cloud:focal-ovn-22.03'} handlers.ch_core.hookenv.config.return_value = config handlers.ovn_source_changed() self.charm.upgrade_ovn.assert_called_once_with()",,307,5
openstack%2Fmanila~888141,openstack/manila,stable/2023.1,I58dcd9716cf95d0d696c13a4c831df787726bcda,Fix duplicate entries in share_server_backend_details,MERGED,2023-07-11 16:28:42.000000000,2023-07-12 12:42:37.000000000,2023-07-12 12:41:27.000000000,"[{'_account_id': 16643}, {'_account_id': 22348}, {'_account_id': 29632}]","[{'number': 1, 'created': '2023-07-11 16:28:42.000000000', 'files': ['manila/tests/db/sqlalchemy/test_api.py', 'manila/db/sqlalchemy/api.py', 'manila/exception.py', 'releasenotes/notes/bug-2024658-fix-duplicate-entries-of-share-server-backend-details-adf45b417d45b437.yaml'], 'web_link': 'https://opendev.org/openstack/manila/commit/5fddd2db19c138bdb4057a58f1e631e97ba9c8f2', 'message': 'Fix duplicate entries in share_server_backend_details\n\nshare_server_backend_details_set() add entries in db table without\nchecking existing entries with given combinaton of share_server_id\nand key. This causes duplicate records. Fix it by validating presence\nof share server id and key.\n\nCloses-bug: #2024658\nChange-Id: I58dcd9716cf95d0d696c13a4c831df787726bcda\n(cherry picked from commit 37278df338ab4d2753ca004e556a197f847be0ce)\n'}]",3,888141,5fddd2db19c138bdb4057a58f1e631e97ba9c8f2,11,3,1,32919,,,0,"Fix duplicate entries in share_server_backend_details

share_server_backend_details_set() add entries in db table without
checking existing entries with given combinaton of share_server_id
and key. This causes duplicate records. Fix it by validating presence
of share server id and key.

Closes-bug: #2024658
Change-Id: I58dcd9716cf95d0d696c13a4c831df787726bcda
(cherry picked from commit 37278df338ab4d2753ca004e556a197f847be0ce)
",git fetch https://review.opendev.org/openstack/manila refs/changes/41/888141/1 && git format-patch -1 --stdout FETCH_HEAD,"['manila/tests/db/sqlalchemy/test_api.py', 'manila/db/sqlalchemy/api.py', 'manila/exception.py', 'releasenotes/notes/bug-2024658-fix-duplicate-entries-of-share-server-backend-details-adf45b417d45b437.yaml']",4,5fddd2db19c138bdb4057a58f1e631e97ba9c8f2,bug/2024658,--- fixes: - | Share server backend details set function adds db records without checking existing entries. This results in duplicate records for the combination of given share server id and key. Fixed it by updating records if already exist else creating new. See the `launchpad bug 2024658 <https://bugs.launchpad.net/manila/+bug/2024658>`_ for more details. ,,52,10
openstack%2Foslo.vmware~883680,openstack/oslo.vmware,master,Id1faa9227415884d15c737ace5a0e0e5de3afa81,Bump bandit and make oslo.messaging compatible with latest rules,MERGED,2023-05-19 15:20:24.000000000,2023-07-12 11:50:20.000000000,2023-07-12 11:49:23.000000000,"[{'_account_id': 9816}, {'_account_id': 15334}, {'_account_id': 22348}]","[{'number': 1, 'created': '2023-05-19 15:20:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.vmware/commit/f8e73e2e233565bbe698a567de61a4cd215261da', 'message': 'Bump bandit and make oslo.messaging compatible with latest rules\n\nMove from lxml lib direct usage to defusedxml lib [1] to fix B320 [2]\n\n[1] https://pypi.org/project/defusedxml/0.7.1/\n[2] https://bandit.readthedocs.io/en/1.7.5/blacklists/blacklist_calls.html#b313-b320-xml\n\nChange-Id: Id1faa9227415884d15c737ace5a0e0e5de3afa81\n'}, {'number': 2, 'created': '2023-06-22 08:20:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.vmware/commit/f65164db595944f07bc16edc675d394a3f321c85', 'message': 'Bump bandit and make oslo.messaging compatible with latest rules\n\n- Move from lxml lib direct usage to defusedxml lib [1] to fix B320 [2]\n\n- Apply a timeout to requests calls to avoid uncontrolled\n  resource consumption (CWE-400) [3].\n\n[1] https://pypi.org/project/defusedxml/0.7.1/\n[2] https://bandit.readthedocs.io/en/1.7.5/blacklists/blacklist_calls.html#b313-b320-xml\n[3] https://cwe.mitre.org/data/definitions/400.html\n\nChange-Id: Id1faa9227415884d15c737ace5a0e0e5de3afa81\n'}, {'number': 3, 'created': '2023-06-22 13:23:10.000000000', 'files': ['requirements.txt', 'test-requirements.txt', 'oslo_vmware/image_util.py', 'oslo_vmware/service.py'], 'web_link': 'https://opendev.org/openstack/oslo.vmware/commit/4f58211e7ab26ed5739398cea5a072734b58e59b', 'message': 'Bump bandit and make oslo.messaging compatible with latest rules\n\n- Move from lxml lib direct usage to defusedxml lib [1] to fix B320 [2]\n\n[1] https://pypi.org/project/defusedxml/0.7.1/\n[2] https://bandit.readthedocs.io/en/1.7.5/blacklists/blacklist_calls.html#b313-b320-xml\n\nChange-Id: Id1faa9227415884d15c737ace5a0e0e5de3afa81\n'}]",1,883680,4f58211e7ab26ed5739398cea5a072734b58e59b,14,3,3,28522,,,0,"Bump bandit and make oslo.messaging compatible with latest rules

- Move from lxml lib direct usage to defusedxml lib [1] to fix B320 [2]

[1] https://pypi.org/project/defusedxml/0.7.1/
[2] https://bandit.readthedocs.io/en/1.7.5/blacklists/blacklist_calls.html#b313-b320-xml

Change-Id: Id1faa9227415884d15c737ace5a0e0e5de3afa81
",git fetch https://review.opendev.org/openstack/oslo.vmware refs/changes/80/883680/1 && git format-patch -1 --stdout FETCH_HEAD,"['requirements.txt', 'test-requirements.txt', 'oslo_vmware/image_util.py']",3,f8e73e2e233565bbe698a567de61a4cd215261da,oslo-bump-bandit,from defusedxml.lxml import parse return _get_vmdk_name_from_ovf(parse(ovf_handle).getroot()),from lxml import etree # nosec (bandit bug 1582516) return _get_vmdk_name_from_ovf(etree.parse(ovf_handle).getroot()),4,3
openstack%2Foslo.policy~886692,openstack/oslo.policy,master,I1d4337f9120cd39cfdd144ceee78c5d5e6a3ec95,Imported Translations from Zanata,MERGED,2023-06-22 03:28:26.000000000,2023-07-12 11:00:35.000000000,2023-07-12 10:59:41.000000000,"[{'_account_id': 9816}, {'_account_id': 22348}, {'_account_id': 28522}]","[{'number': 1, 'created': '2023-06-22 03:28:26.000000000', 'files': ['releasenotes/source/locale/en_GB/LC_MESSAGES/releasenotes.po'], 'web_link': 'https://opendev.org/openstack/oslo.policy/commit/37de6f3ef08c6521031e8c7f54737d331bf57f22', 'message': 'Imported Translations from Zanata\n\nFor more information about this automatic import see:\nhttps://docs.openstack.org/i18n/latest/reviewing-translation-import.html\n\nChange-Id: I1d4337f9120cd39cfdd144ceee78c5d5e6a3ec95\n'}]",0,886692,37de6f3ef08c6521031e8c7f54737d331bf57f22,8,3,1,11131,,,0,"Imported Translations from Zanata

For more information about this automatic import see:
https://docs.openstack.org/i18n/latest/reviewing-translation-import.html

Change-Id: I1d4337f9120cd39cfdd144ceee78c5d5e6a3ec95
",git fetch https://review.opendev.org/openstack/oslo.policy refs/changes/92/886692/1 && git format-patch -1 --stdout FETCH_HEAD,['releasenotes/source/locale/en_GB/LC_MESSAGES/releasenotes.po'],1,37de6f3ef08c6521031e8c7f54737d331bf57f22,zanata/translations,"# Andi Chandler <andi@gowling.com>, 2023. #zanata""POT-Creation-Date: 2023-05-08 11:38+0000\n""""PO-Revision-Date: 2023-06-21 08:56+0000\n""msgid ""1.25.3"" msgstr ""1.25.3"" msgid ""1.33.2"" msgstr ""1.33.2"" msgid ""1.33.2-3"" msgstr ""1.33.2-3"" msgid ""1.38.1-6"" msgstr ""1.38.1-6"" msgid ""1.41.0"" msgstr ""1.41.0"" msgid ""2.1.0"" msgstr ""2.1.0"" msgid ""2.1.3"" msgstr ""2.1.3"" msgid ""2.3.3"" msgstr ""2.3.3"" msgid ""2.3.4"" msgstr ""2.3.4"" msgid ""2.4.0"" msgstr ""2.4.0"" msgid ""2023.1 Series Release Notes"" msgstr ""2023.1 Series Release Notes"" msgid ""3.0.0"" msgstr ""3.0.0"" msgid ""3.1.0"" msgstr ""3.1.0"" msgid ""3.1.1"" msgstr ""3.1.1"" msgid ""3.1.2"" msgstr ""3.1.2"" msgid ""3.10.0"" msgstr ""3.10.0"" msgid ""3.10.1"" msgstr ""3.10.1"" msgid ""3.12.0"" msgstr ""3.12.0"" msgid ""3.12.1"" msgstr ""3.12.1"" msgid ""3.2.1"" msgstr ""3.2.1"" msgid ""3.3.0"" msgstr ""3.3.0"" msgid ""3.4.0"" msgstr ""3.4.0"" msgid ""3.6.1"" msgstr ""3.6.1"" msgid ""3.6.2"" msgstr ""3.6.2"" msgid ""3.7.0"" msgstr ""3.7.0"" msgid ""3.7.1"" msgstr ""3.7.1"" msgid ""3.8.3"" msgstr ""3.8.3"" msgid ""3.9.0"" msgstr ""3.9.0"" msgid """" ""A new configuration option ``enforce_new_defaults`` has been added to the "" ""``[oslo_policy]`` group to control whether or not to use the old deprecated "" ""defaults. If ``True``, the old deprecated defaults are not going to be "" ""evaluated which means if any existing token is allowed for old defaults but "" ""disallowed for new defaults it will be disallowed. It is encouraged to "" ""enable this flag along with the ``enforce_scope`` flag so that you can get "" ""the benefits of new defaults and ``scope_type`` together. This way operators "" ""can switch to new defaults without overwriting the rules in the policy file."" msgstr """" ""A new configuration option ``enforce_new_defaults`` has been added to the "" ""``[oslo_policy]`` group to control whether or not to use the old deprecated "" ""defaults. If ``True``, the old deprecated defaults are not going to be "" ""evaluated which means if any existing token is allowed for old defaults but "" ""disallowed for new defaults it will be disallowed. It is encouraged to "" ""enable this flag along with the ``enforce_scope`` flag so that you can get "" ""the benefits of new defaults and ``scope_type`` together. This way operators "" ""can switch to new defaults without overwriting the rules in the policy file."" ""A new tool, ``oslopolicy-validator``, has been added. It allows deployers to "" ""easily run basic sanity checks against their policy files. See the "" ""documentation for full details."" msgstr """" ""A new tool, ``oslopolicy-validator``, has been added. It allows deployers to "" ""easily run basic sanity checks against their policy files. See the "" ""documentation for full details."" msgid """" ""Add ``oslopolicy-convert-json-to-yaml`` tool to convert the json formatted "" ""policy file to yaml format in compatible way. Refer to `this document "" ""<https://docs.openstack.org/oslo.policy/latest/cli/oslopolicy-convert-json-"" ""to-yaml.html>`_ for details."" msgstr """" ""Add ``oslopolicy-convert-json-to-yaml`` tool to convert the JSON formatted "" ""policy file to YAML format in a compatible way. Refer to `this document "" ""<https://docs.openstack.org/oslo.policy/latest/cli/oslopolicy-convert-json-"" ""to-yaml.html>`_ for details."" msgid """" ""Add ``oslopolicy-policy-upgrade`` command to help operators upgrade their "" ""self-defined policy file to new release format. It will upgrade the "" ""deprected policy name with the new name."" msgstr """" ""Add ``oslopolicy-policy-upgrade`` command to help operators upgrade their "" ""self-defined policy file to a new release format. It will upgrade the "" ""deprecated policy name with the new name."" msgid """"""Adds the ability to exclude deprecated policies from generated samples by "" ""utilizing the ``--exclude-deprecated`` setting when generating YAML example "" ""files. The Spinx generator can also be controlled using the "" ""``exclude_deprecated`` environment variable. By default, these rules will be "" ""included, but operators and projects may not desire these deprecated rules "" ""to exist in latest documentation, espescially when considering the number of "" ""policy rules projects have made in the Secure RBAC effort."" msgstr """" ""Adds the ability to exclude deprecated policies from generated samples by "" ""utilizing the ``--exclude-deprecated`` setting when generating YAML example "" ""files. The Spinx generator can also be controlled using the "" ""``exclude_deprecated`` environment variable. By default, these rules will be "" ""included, but operators and projects may not desire these deprecated rules "" ""to exist in the latest documentation, especially when considering the number "" ""of policy rules projects have made in the Secure RBAC effort."" msgid """"msgid """" ""Deprecated policy warnings are now suppressed in the ``oslopolicy-list-"" ""redundant`` tool so that they don't overwhelm the relevant output."" msgstr """" ""Deprecated policy warnings are now suppressed in the ``oslopolicy-list-"" ""redundant`` tool so that they don't overwhelm the relevant output."" msgid ""Deprecation Notes"" msgstr ""Deprecation Notes"" msgid """" ""Fixed passing ``--exclude-deprecated`` boolean value to sphinx-build "" ""command. Now ``--exclude-deprecated`` is only passed when it is True without "" ""bool True/False value."" msgstr """" ""Fixed passing ``--exclude-deprecated`` boolean value to sphinx-build "" ""command. Now ``--exclude-deprecated`` is only passed when it is True without "" ""bool True/False value."" msgid """" ""Fixes handling of deprecated rules when generating sample policy files such "" ""that legacy rules are no longer automatically aliased in the resulting "" ""output. Previously, the behavior led to operator confusion when attempting "" ""to evaluate the output to determine if customized rules were required, as "" ""the aliases were always added as active rules. A warning is now also added "" ""to the generated output. For more information, please see `launchpad bug "" ""#1945336 <https://bugs.launchpad.net/oslo.policy/+bug/1945336>`_."" msgstr """" ""Fixes handling of deprecated rules when generating sample policy files such "" ""that legacy rules are no longer automatically aliased in the resulting "" ""output. Previously, the behaviour led to operator confusion when attempting "" ""to evaluate the output to determine if customised rules were required, as "" ""the aliases were always added as active rules. A warning is now also added "" ""to the generated output. For more information, please see `launchpad bug "" ""#1945336 <https://bugs.launchpad.net/oslo.policy/+bug/1945336>`_."" msgid """" ""Fixes the mapping of 'system_scope' to 'system' when enforce is called with "" ""a 'creds' dictionary instead of a RequestContext."" msgstr """" ""Fixes the mapping of 'system_scope' to 'system' when enforce is called with "" ""a 'creds' dictionary instead of a RequestContext."" msgid """" ""JSON format support and ``--format`` option in ``oslopolicy-sample-"" ""generator`` and ``oslopolicy-policy-upgrade`` tools are also deprecated. In "" ""future release, ``--format`` option will be removed."" msgstr """" ""JSON format support and ``--format`` option in ``oslopolicy-sample-"" ""generator`` and ``oslopolicy-policy-upgrade`` tools are also deprecated. In "" ""future release, ``--format`` option will be removed."" msgid """" ""Scope check is enforced for all rules, registered ones as well as the ones "" ""which are subclasses of the ``BaseCheck`` class if rule has ``scope_types`` "" ""set."" msgstr """" ""Scope check is enforced for all rules, registered ones as well as the ones "" ""which are subclasses of the ``BaseCheck`` class if rule has ``scope_types`` "" ""set."" msgid ""Stein Series Release Notes"" msgstr ""Stein Series Release Notes"" msgid """" ""Support for Python 2.7 has been dropped. The minimum version of Python now "" ""supported is Python 3.6."" msgstr """" ""Support for Python 2.7 has been dropped. The minimum version of Python now "" ""supported is Python 3.6."" msgid """" ""This fixes the Bug# 1914095. Policy engine has bug of modifying the "" ""registered rule original object which caused issue when there are multiple "" ""policy objects are processing rules in parallel. With this fix. policy "" ""engine will make copies of all the registered rules and process accordingly."" msgstr """" ""This fixes Bug #1914095. Policy engine has a bug of modifying the registered "" ""rule original object which caused issue when there are multiple policy "" ""objects processing rules in parallel. With this fix. the policy engine will "" ""make copies of all the registered rules and process them accordingly."" msgid ""Train Series Release Notes"" msgstr ""Train Series Release Notes"" msgid ""Upgrade Notes"" msgstr ""Upgrade Notes"" msgid """" ""Users with a ``RuleDefault`` or ``DocumentedRuleDefault`` that have "" ""configured a ``deprecated_rule`` should move the ``deprecated_reason`` and "" ""``deprecated_since`` parameters to this ``DeprecatedRule``."" msgstr """" ""Users with a ``RuleDefault`` or ``DocumentedRuleDefault`` that have "" ""configured a ``deprecated_rule`` should move the ``deprecated_reason`` and "" ""``deprecated_since`` parameters to this ``DeprecatedRule``."" msgid ""Ussuri Series Release Notes"" msgstr ""Ussuri Series Release Notes"" msgid ""Victoria Series Release Notes"" msgstr ""Victoria Series Release Notes"" msgid ""Wallaby Series Release Notes"" msgstr ""Wallaby Series Release Notes"" msgid ""Xena Series Release Notes"" msgstr ""Xena Series Release Notes"" msgid ""Yoga Series Release Notes"" msgstr ""Yoga Series Release Notes"" msgid ""Zed Series Release Notes"" msgstr ""Zed Series Release Notes"" msgid """" ""[`bug 1880959 <https://bugs.launchpad.net/keystone/+bug/1880959>`_] The "" ""behavior of policy file reloading from policy directories was fixed. "" ""Previously the rules from policy files located in the directories specified "" ""in the ``policy_dirs`` option were not reapplied after the rules from the "" ""primary policy file have been reapplied due to a change."" msgstr """" ""[`bug 1880959 <https://bugs.launchpad.net/keystone/+bug/1880959>`_] The "" ""behaviour of policy file reloading from policy directories was fixed. "" ""Previously the rules from policy files located in the directories specified "" ""in the ``policy_dirs`` option were not reapplied after the rules from the "" ""primary policy file have been reapplied due to a change."" msgid """" ""[`bug 1913718 <https://launchpad.net/bugs/1913718>`_] The `Enforcer()` "" ""object now only processes deprecated rules once at load or enforcement time, "" ""improving performance for users that make extensive use of policy "" ""enforcement."" msgstr """" ""[`bug 1913718 <https://launchpad.net/bugs/1913718>`_] The `Enforcer()` "" ""object now only processes deprecated rules once at load or enforcement time, "" ""improving performance for users that make extensive use of policy "" ""enforcement."" msgid """" ""[`bug 1943584 <https://bugs.launchpad.net/oslo.policy/+bug/1943584>`_] If "" ""file in policy directory was emptied, rules were not re-calculated. The only "" ""workaround was to restart an application. Now rules are re-calculated \""on "" ""the fly\"", without app restart."" msgstr """" ""[`bug 1943584 <https://bugs.launchpad.net/oslo.policy/+bug/1943584>`_] If "" ""file in policy directory was emptied, rules were not re-calculated. The only "" ""workaround was to restart an application. Now rules are re-calculated \""on "" ""the fly\"", without app restart."" msgid """" ""``DeprecatedRule`` now accepts two new parameters: ``deprecated_reason`` and "" ""``deprecated_since``. These should be used in place of the equivalent "" ""parameters on the rule that is replacing this rule in order to avoid "" ""confusion."" msgstr """" ""``DeprecatedRule`` now accepts two new parameters: ``deprecated_reason`` and "" ""``deprecated_since``. These should be used in place of the equivalent "" ""parameters on the rule that is replacing this rule in order to avoid "" ""confusion."" msgid """" ""``policy_file`` support for JSON formatted file is deprecated. Use YAML "" ""formatted file which will be default in future. Use `oslopolicy-convert-json-"" ""to-yaml <https://docs.openstack.org/oslo.policy/latest/cli/oslopolicy-"" ""convert-json-to-yaml.html>`_ tool to convert the existing JSON to YAML "" ""formatted policy file in backward compatible way."" msgstr """" ""``policy_file`` support for JSON formatted files is deprecated. Use YAML "" ""formatted file which will be the default in future. Use `oslopolicy-convert-"" ""json-to-yaml <https://docs.openstack.org/oslo.policy/latest/cli/oslopolicy-"" ""convert-json-to-yaml.html>`_ tool to convert the existing JSON to YAML "" ""formatted policy file in a backwards-compatible way."" msgid """" ""oslopolicy-checker was added the ability to accept a file containing a hash "" ""that represents the target. This makes it possible to check policies that "" ""have non-conventional targets such as barbican."" msgstr """" ""oslopolicy-checker has added the ability to accept a file containing a hash "" ""that represents the target. This makes it possible to check policies that "" ""have non-conventional targets such as Barbican.""","""POT-Creation-Date: 2022-09-09 16:02+0000\n""""PO-Revision-Date: 2018-08-08 09:50+0000\n""",335,2
openstack%2Ftrove~888214,openstack/trove,master,I2ffd53cafc40d488f986a1f96ceb717aa41d6045,update config parameters,NEW,2023-07-12 07:52:02.000000000,2023-07-12 10:56:10.000000000,,[{'_account_id': 22348}],"[{'number': 1, 'created': '2023-07-12 07:52:02.000000000', 'files': ['trove/templates/mysql/validation-rules.json'], 'web_link': 'https://opendev.org/openstack/trove/commit/c863f632f6c4a8e1c38d747165d82a29e5d7b757', 'message': 'update config parameters\n\n[1] https://dev.mysql.com/doc/refman/8.0/en/innodb-parameters.html\n\nChange-Id: I2ffd53cafc40d488f986a1f96ceb717aa41d6045\n'}]",0,888214,c863f632f6c4a8e1c38d747165d82a29e5d7b757,3,1,1,32029,,,0,"update config parameters

[1] https://dev.mysql.com/doc/refman/8.0/en/innodb-parameters.html

Change-Id: I2ffd53cafc40d488f986a1f96ceb717aa41d6045
",git fetch https://review.opendev.org/openstack/trove refs/changes/14/888214/1 && git format-patch -1 --stdout FETCH_HEAD,['trove/templates/mysql/validation-rules.json'],1,c863f632f6c4a8e1c38d747165d82a29e5d7b757,template," ""max"": 4294967295, ""min"": 1048576, ""max"": 65536, ""max"": 10000000, ""max"": 2147483647,} "," ""min"": 262144, ""max"": 4294967295,}",6,3
openstack%2Fheat~886566,openstack/heat,master,I40348bc16900e73e83c48dadef35cfa3cdd8ff8d,Imported Translations from Zanata,MERGED,2023-06-21 04:10:07.000000000,2023-07-12 10:48:07.000000000,2023-07-12 10:47:05.000000000,"[{'_account_id': 9816}, {'_account_id': 22348}]","[{'number': 1, 'created': '2023-06-21 04:10:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/7c6fc0252d9cea9890f8389438294b00187f1ef8', 'message': 'Imported Translations from Zanata\n\nFor more information about this automatic import see:\nhttps://docs.openstack.org/i18n/latest/reviewing-translation-import.html\n\nChange-Id: I40348bc16900e73e83c48dadef35cfa3cdd8ff8d\n'}, {'number': 2, 'created': '2023-06-22 04:14:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/21869e0d1765cacef59c116959fd3672174b4cf5', 'message': 'Imported Translations from Zanata\n\nFor more information about this automatic import see:\nhttps://docs.openstack.org/i18n/latest/reviewing-translation-import.html\n\nChange-Id: I40348bc16900e73e83c48dadef35cfa3cdd8ff8d\n'}, {'number': 3, 'created': '2023-06-23 03:48:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/fdea31680cdfb05beaf355a5854194d29c868057', 'message': 'Imported Translations from Zanata\n\nFor more information about this automatic import see:\nhttps://docs.openstack.org/i18n/latest/reviewing-translation-import.html\n\nChange-Id: I40348bc16900e73e83c48dadef35cfa3cdd8ff8d\n'}, {'number': 4, 'created': '2023-07-04 02:14:15.000000000', 'files': ['releasenotes/source/locale/en_GB/LC_MESSAGES/releasenotes.po'], 'web_link': 'https://opendev.org/openstack/heat/commit/a4ac653e35f16a5787bc5a2c934736656294b9b6', 'message': 'Imported Translations from Zanata\n\nFor more information about this automatic import see:\nhttps://docs.openstack.org/i18n/latest/reviewing-translation-import.html\n\nChange-Id: I40348bc16900e73e83c48dadef35cfa3cdd8ff8d\n'}]",0,886566,a4ac653e35f16a5787bc5a2c934736656294b9b6,13,2,4,11131,,,0,"Imported Translations from Zanata

For more information about this automatic import see:
https://docs.openstack.org/i18n/latest/reviewing-translation-import.html

Change-Id: I40348bc16900e73e83c48dadef35cfa3cdd8ff8d
",git fetch https://review.opendev.org/openstack/heat refs/changes/66/886566/1 && git format-patch -1 --stdout FETCH_HEAD,['releasenotes/source/locale/en_GB/LC_MESSAGES/releasenotes.po'],1,7c6fc0252d9cea9890f8389438294b00187f1ef8,zanata/translations,"""POT-Creation-Date: 2023-06-21 00:20+0000\n""""PO-Revision-Date: 2023-06-20 11:23+0000\n""msgid ""15.1.0-18"" msgstr ""15.1.0-18"" msgid ""17.0.2"" msgstr ""17.0.2"" msgid ""18.0.1"" msgstr ""18.0.1"" msgid ""19.0.1"" msgstr ""19.0.1"" ","""POT-Creation-Date: 2023-05-31 05:59+0000\n""""PO-Revision-Date: 2023-05-08 10:19+0000\n""",14,2
openstack%2Foslo.cache~886667,openstack/oslo.cache,master,I03e5a01dc4785470f07155e8cf923fd3f46b4cb8,Imported Translations from Zanata,MERGED,2023-06-22 02:20:56.000000000,2023-07-12 10:45:58.000000000,2023-07-12 10:44:58.000000000,"[{'_account_id': 9816}, {'_account_id': 22348}, {'_account_id': 28522}]","[{'number': 1, 'created': '2023-06-22 02:20:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.cache/commit/c8fa8e16d167bd42ef749839ea83368532159573', 'message': 'Imported Translations from Zanata\n\nFor more information about this automatic import see:\nhttps://docs.openstack.org/i18n/latest/reviewing-translation-import.html\n\nChange-Id: I03e5a01dc4785470f07155e8cf923fd3f46b4cb8\n'}, {'number': 2, 'created': '2023-06-28 02:53:40.000000000', 'files': ['releasenotes/source/locale/en_GB/LC_MESSAGES/releasenotes.po'], 'web_link': 'https://opendev.org/openstack/oslo.cache/commit/06f76e582c96de0597d2a93efdc15dd75c7666c3', 'message': 'Imported Translations from Zanata\n\nFor more information about this automatic import see:\nhttps://docs.openstack.org/i18n/latest/reviewing-translation-import.html\n\nChange-Id: I03e5a01dc4785470f07155e8cf923fd3f46b4cb8\n'}]",0,886667,06f76e582c96de0597d2a93efdc15dd75c7666c3,11,3,2,11131,,,0,"Imported Translations from Zanata

For more information about this automatic import see:
https://docs.openstack.org/i18n/latest/reviewing-translation-import.html

Change-Id: I03e5a01dc4785470f07155e8cf923fd3f46b4cb8
",git fetch https://review.opendev.org/openstack/oslo.cache refs/changes/67/886667/1 && git format-patch -1 --stdout FETCH_HEAD,['releasenotes/source/locale/en_GB/LC_MESSAGES/releasenotes.po'],1,c8fa8e16d167bd42ef749839ea83368532159573,zanata/translations,"""POT-Creation-Date: 2023-06-20 10:18+0000\n""""PO-Revision-Date: 2023-06-21 08:15+0000\n""msgid ""3.4.0"" msgstr ""3.4.0""","""POT-Creation-Date: 2023-05-08 10:56+0000\n""""PO-Revision-Date: 2023-05-09 12:01+0000\n""msgid ""3.3.1-5"" msgstr ""3.3.1-5""",4,4
openstack%2Foslo.service~886690,openstack/oslo.service,master,Iaf9b4202906d53e2ae6ae59293df4fd8c2bfd466,Imported Translations from Zanata,MERGED,2023-06-22 03:16:44.000000000,2023-07-12 10:45:05.000000000,2023-07-12 10:44:05.000000000,"[{'_account_id': 9816}, {'_account_id': 22348}, {'_account_id': 28522}]","[{'number': 1, 'created': '2023-06-22 03:16:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.service/commit/ff9f04b02dc6c92f41b08e643a91c2cacaa2ac3d', 'message': 'Imported Translations from Zanata\n\nFor more information about this automatic import see:\nhttps://docs.openstack.org/i18n/latest/reviewing-translation-import.html\n\nChange-Id: Iaf9b4202906d53e2ae6ae59293df4fd8c2bfd466\n'}, {'number': 2, 'created': '2023-06-28 04:30:41.000000000', 'files': ['releasenotes/source/locale/en_GB/LC_MESSAGES/releasenotes.po'], 'web_link': 'https://opendev.org/openstack/oslo.service/commit/e94d47a9647799d29a41890d620d02d27369a282', 'message': 'Imported Translations from Zanata\n\nFor more information about this automatic import see:\nhttps://docs.openstack.org/i18n/latest/reviewing-translation-import.html\n\nChange-Id: Iaf9b4202906d53e2ae6ae59293df4fd8c2bfd466\n'}]",0,886690,e94d47a9647799d29a41890d620d02d27369a282,10,3,2,11131,,,0,"Imported Translations from Zanata

For more information about this automatic import see:
https://docs.openstack.org/i18n/latest/reviewing-translation-import.html

Change-Id: Iaf9b4202906d53e2ae6ae59293df4fd8c2bfd466
",git fetch https://review.opendev.org/openstack/oslo.service refs/changes/90/886690/1 && git format-patch -1 --stdout FETCH_HEAD,['releasenotes/source/locale/en_GB/LC_MESSAGES/releasenotes.po'],1,ff9f04b02dc6c92f41b08e643a91c2cacaa2ac3d,zanata/translations,"# Andi Chandler <andi@gowling.com>, 2023. #zanata""POT-Creation-Date: 2023-05-08 10:53+0000\n""""PO-Revision-Date: 2023-06-21 08:13+0000\n""msgid ""1.35.0"" msgstr ""1.35.0"" msgid ""1.37.0"" msgstr ""1.37.0"" msgid ""1.40.0"" msgstr ""1.40.0"" msgid ""1.40.2"" msgstr ""1.40.2"" msgid ""2.0.0"" msgstr ""2.0.0"" msgid ""2.4.1"" msgstr ""2.4.1"" msgid ""2.5.1"" msgstr ""2.5.1"" msgid ""2.6.1"" msgstr ""2.6.1"" msgid ""2.6.2"" msgstr ""2.6.2"" msgid ""2.7.0"" msgstr ""2.7.0"" msgid ""2.8.0"" msgstr ""2.8.0"" msgid ""2023.1 Series Release Notes"" msgstr ""2023.1 Series Release Notes"" msgid """" ""A new config options, ``[DEFAULT] wsgi_server_debug``, has been added. This "" ""allows admins to configure whether the server should send exception "" ""tracebacks to the clients on HTTP 500 errors. This defaults to ``False``, "" ""preserving previous behavior."" msgstr """" ""A new config options, ``[DEFAULT] wsgi_server_debug``, has been added. This "" ""allows admins to configure whether the server should send exception "" ""tracebacks to the clients on HTTP 500 errors. This defaults to ``False``, "" ""preserving previous behaviour."" msgid """" ""Add support for profiling (capture function calltrace) service's worker "" ""processes."" msgstr """" ""Add support for profiling (capture function calltrace) service's worker "" ""processes."" msgid ""Bug Fixes"" msgstr ""Bug Fixes"" msgid ""Deprecation Notes"" msgstr ""Deprecation Notes"" msgid """" ""Fix the backdoor helper method fo() to also work when there are objects "" ""present in the current python instance that do not have a __class__ "" ""attribute."" msgstr """" ""Fix the backdoor helper method fo() to also work when there are objects "" ""present in the current Python instance that do not have a __class__ "" ""attribute."" msgid ""Rocky Series Release Notes"" msgstr ""Rocky Series Release Notes"" msgid ""Stein Series Release Notes"" msgstr ""Stein Series Release Notes"" msgid """" ""Support for Python 2.7 has been dropped. The minimum version of Python now "" ""supported is Python 3.6."" msgstr """" ""Support for Python 2.7 has been dropped. The minimum version of Python now "" ""supported is Python 3.6."" msgid """" ""The API of the ThreadGroup add_timer() and add_dynamic_timer() methods has "" ""been identified as error-prone when passing arguments intended for the "" ""callback function. Passing callback arguments in this way is now deprecated. "" ""Callers should use the new add_timer_args() or add_dynamic_timer_args() "" ""methods (respectively) instead when it is necessary to pass arguments to the "" ""timer callback function."" msgstr """" ""The API of the ThreadGroup add_timer() and add_dynamic_timer() methods has "" ""been identified as error-prone when passing arguments intended for the "" ""callback function. Passing callback arguments in this way is now deprecated. "" ""Callers should use the new add_timer_args() or add_dynamic_timer_args() "" ""methods (respectively) instead when it is necessary to pass arguments to the "" ""timer callback function."" msgid """" ""The ThreadGroup add_timer_args() and add_dynamic_timer_args() methods now "" ""support passing a stop_on_exception=False argument to allow the timer to "" ""keep running even when an exception is raised by the callback function."" msgstr """" ""The ThreadGroup add_timer_args() and add_dynamic_timer_args() methods now "" ""support passing a stop_on_exception=False argument to allow the timer to "" ""keep running even when an exception is raised by the callback function."" msgid """" ""The ThreadGroup class has new add_timer_args() and add_dynamic_timer_args() "" ""methods to create timers passing the positional and keyword arguments to the "" ""callback as a sequence and a mapping. This API provides more flexibility for "" ""the addition of timer control options in the future."" msgstr """" ""The ThreadGroup class has new add_timer_args() and add_dynamic_timer_args() "" ""methods to create timers passing the positional and keyword arguments to the "" ""callback as a sequence and a mapping. This API provides more flexibility for "" ""the addition of timer control options in the future."" msgid """" ""The ``ThreadGroup.cancel()`` method is deprecated and will be removed in a "" ""future major release."" msgstr """" ""The ``ThreadGroup.cancel()`` method is deprecated and will be removed in a "" ""future major release."" msgid """" ""The config option backdoor_socket_path now is a format string that supports "" ""{pid}, which will be replaced with the PID of the current process. This "" ""makes the eventlet backdoor accessible when spawning multiple processes with "" ""the same backdoor_socket_path inside the configuration."" msgstr """" ""The config option backdoor_socket_path now is a format string that supports "" ""{pid}, which will be replaced with the PID of the current process. This "" ""makes the eventlet backdoor accessible when spawning multiple processes with "" ""the same backdoor_socket_path inside the configuration."" msgid ""Train Series Release Notes"" msgstr ""Train Series Release Notes"" msgid ""Upgrade Notes"" msgstr ""Upgrade Notes"" msgid ""Ussuri Series Release Notes"" msgstr ""Ussuri Series Release Notes"" msgid ""Victoria Series Release Notes"" msgstr ""Victoria Series Release Notes"" msgid ""Wallaby Series Release Notes"" msgstr ""Wallaby Series Release Notes"" msgid ""Xena Series Release Notes"" msgstr ""Xena Series Release Notes"" msgid ""Yoga Series Release Notes"" msgstr ""Yoga Series Release Notes"" msgid ""Zed Series Release Notes"" msgstr ""Zed Series Release Notes"" msgid """" ""``SIGHUP`` is now handled properly with ``restart_method='mutate'``, no "" ""longer restarting child processes. See `bug 1794708`_ for details. In "" ""conjunction with the fix for `bug 1715374`_ in oslo.privsep, the nova-"" ""compute service now behaves correctly when it receives ``SIGHUP``."" msgstr """" ""``SIGHUP`` is now handled properly with ``restart_method='mutate'``, no "" ""longer restarting child processes. See `bug 1794708`_ for details. In "" ""conjunction with the fix for `bug 1715374`_ in oslo.privsep, the nova-"" ""compute service now behaves correctly when it receives ``SIGHUP``."" ","""POT-Creation-Date: 2018-03-01 11:24+0000\n""""PO-Revision-Date: 2018-01-27 01:26+0000\n""",173,2
openstack%2Foslo.middleware~886669,openstack/oslo.middleware,master,Ic894b6117cdb9d16ee10073d47c469ef7594cf23,Imported Translations from Zanata,MERGED,2023-06-22 03:15:02.000000000,2023-07-12 10:43:55.000000000,2023-07-12 10:43:02.000000000,"[{'_account_id': 9816}, {'_account_id': 22348}, {'_account_id': 28522}]","[{'number': 1, 'created': '2023-06-22 03:15:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.middleware/commit/53b96b5bca860199c67bb097962b095729d7c5da', 'message': 'Imported Translations from Zanata\n\nFor more information about this automatic import see:\nhttps://docs.openstack.org/i18n/latest/reviewing-translation-import.html\n\nChange-Id: Ic894b6117cdb9d16ee10073d47c469ef7594cf23\n'}, {'number': 2, 'created': '2023-06-28 04:09:48.000000000', 'files': ['oslo_middleware/locale/en_GB/LC_MESSAGES/oslo_middleware.po', 'oslo_middleware/locale/de/LC_MESSAGES/oslo_middleware.po', 'releasenotes/source/locale/en_GB/LC_MESSAGES/releasenotes.po', 'oslo_middleware/locale/fr/LC_MESSAGES/oslo_middleware.po'], 'web_link': 'https://opendev.org/openstack/oslo.middleware/commit/4153ffef5333657c23486eb0543ab1d6b3de5069', 'message': 'Imported Translations from Zanata\n\nFor more information about this automatic import see:\nhttps://docs.openstack.org/i18n/latest/reviewing-translation-import.html\n\nChange-Id: Ic894b6117cdb9d16ee10073d47c469ef7594cf23\n'}]",0,886669,4153ffef5333657c23486eb0543ab1d6b3de5069,10,3,2,11131,,,0,"Imported Translations from Zanata

For more information about this automatic import see:
https://docs.openstack.org/i18n/latest/reviewing-translation-import.html

Change-Id: Ic894b6117cdb9d16ee10073d47c469ef7594cf23
",git fetch https://review.opendev.org/openstack/oslo.middleware refs/changes/69/886669/1 && git format-patch -1 --stdout FETCH_HEAD,"['oslo_middleware/locale/en_GB/LC_MESSAGES/oslo_middleware.po', 'oslo_middleware/locale/de/LC_MESSAGES/oslo_middleware.po', 'releasenotes/source/locale/en_GB/LC_MESSAGES/releasenotes.po', 'oslo_middleware/locale/fr/LC_MESSAGES/oslo_middleware.po']",4,53b96b5bca860199c67bb097962b095729d7c5da,zanata/translations,,"# Translations template for oslo.middleware. # Copyright (C) 2015 ORGANIZATION # This file is distributed under the same license as the oslo.middleware # project. # # Translators: # Maxime COQUEREL <max.coquerel@gmail.com>, 2014 # Andreas Jaeger <jaegerandi@gmail.com>, 2016. #zanata msgid """" msgstr """" ""Project-Id-Version: oslo.middleware 3.7.1.dev18\n"" ""Report-Msgid-Bugs-To: https://bugs.launchpad.net/openstack-i18n/\n"" ""POT-Creation-Date: 2016-04-19 23:53+0000\n"" ""MIME-Version: 1.0\n"" ""Content-Type: text/plain; charset=UTF-8\n"" ""Content-Transfer-Encoding: 8bit\n"" ""PO-Revision-Date: 2014-09-17 09:06+0000\n"" ""Last-Translator: Maxime COQUEREL <max.coquerel@gmail.com>\n"" ""Language: fr\n"" ""Plural-Forms: nplurals=2; plural=(n > 1);\n"" ""Generated-By: Babel 2.0\n"" ""X-Generator: Zanata 3.7.3\n"" ""Language-Team: French\n"" msgid ""Request is too large."" msgstr ""Demande trop importante."" ",88,61
openstack%2Foslo.utils~886697,openstack/oslo.utils,master,I3525e493d197644c4d2c70a93eafecf877ba6933,Imported Translations from Zanata,MERGED,2023-06-22 04:01:33.000000000,2023-07-12 10:42:45.000000000,2023-07-12 10:41:49.000000000,"[{'_account_id': 9816}, {'_account_id': 22348}, {'_account_id': 28522}]","[{'number': 1, 'created': '2023-06-22 04:01:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.utils/commit/e09de59d30a8a38328b92f13293a12a5e03f180f', 'message': 'Imported Translations from Zanata\n\nFor more information about this automatic import see:\nhttps://docs.openstack.org/i18n/latest/reviewing-translation-import.html\n\nChange-Id: I3525e493d197644c4d2c70a93eafecf877ba6933\n'}, {'number': 2, 'created': '2023-06-23 03:43:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.utils/commit/e3efd188b6b338bc9f3b8aabb3b7437335b8f5d2', 'message': 'Imported Translations from Zanata\n\nFor more information about this automatic import see:\nhttps://docs.openstack.org/i18n/latest/reviewing-translation-import.html\n\nChange-Id: I3525e493d197644c4d2c70a93eafecf877ba6933\n'}, {'number': 3, 'created': '2023-06-28 04:48:44.000000000', 'files': ['releasenotes/source/locale/en_GB/LC_MESSAGES/releasenotes.po'], 'web_link': 'https://opendev.org/openstack/oslo.utils/commit/a5941e8f845534e3604dacf2dfa9a87d224eeef8', 'message': 'Imported Translations from Zanata\n\nFor more information about this automatic import see:\nhttps://docs.openstack.org/i18n/latest/reviewing-translation-import.html\n\nChange-Id: I3525e493d197644c4d2c70a93eafecf877ba6933\n'}]",0,886697,a5941e8f845534e3604dacf2dfa9a87d224eeef8,13,3,3,11131,,,0,"Imported Translations from Zanata

For more information about this automatic import see:
https://docs.openstack.org/i18n/latest/reviewing-translation-import.html

Change-Id: I3525e493d197644c4d2c70a93eafecf877ba6933
",git fetch https://review.opendev.org/openstack/oslo.utils refs/changes/97/886697/1 && git format-patch -1 --stdout FETCH_HEAD,['releasenotes/source/locale/en_GB/LC_MESSAGES/releasenotes.po'],1,e09de59d30a8a38328b92f13293a12a5e03f180f,zanata/translations,"# Andi Chandler <andi@gowling.com>, 2023. #zanata""POT-Creation-Date: 2023-06-09 05:15+0000\n""""PO-Revision-Date: 2023-06-21 08:09+0000\n""msgid ""2023.1 Series Release Notes"" msgstr ""2023.1 Series Release Notes"" msgid ""3.41.6-4"" msgstr ""3.41.6-4""msgid ""4.1.2-4"" msgstr ""4.1.2-4""msgid ""6.1.0-9"" msgstr ""6.1.0-9"" ""Implement zoneinfo to allow us to remove pytz's dependency for Python 3.9 "" ""and 3.10."" msgstr """" ""Implement zoneinfo to allow us to remove pytz's dependency for Python 3.9 "" ""and 3.10."" msgid """"msgid """" ""New method ``netutils.get_my_ipv6()`` returns the IPv6 address of the local "" ""machine."" msgstr """" ""New method ``netutils.get_my_ipv6()`` returns the IPv6 address of the local "" ""machine."" msgid ""Zed Series Release Notes"" msgstr ""Zed Series Release Notes"" ","""POT-Creation-Date: 2022-09-09 15:52+0000\n""""PO-Revision-Date: 2022-08-14 12:25+0000\n""msgid ""3.41.6-3"" msgstr ""3.41.6-3""msgid ""4.1.2-3"" msgstr ""4.1.2-3""",30,6
openstack%2Foslo.privsep~886700,openstack/oslo.privsep,master,I3f263194f71469ca9ca67f3d99b10dc75c448e20,Imported Translations from Zanata,MERGED,2023-06-22 04:16:45.000000000,2023-07-12 10:40:53.000000000,2023-07-12 10:40:00.000000000,"[{'_account_id': 9816}, {'_account_id': 22348}, {'_account_id': 28522}]","[{'number': 1, 'created': '2023-06-22 04:16:45.000000000', 'files': ['oslo_privsep/locale/en_GB/LC_MESSAGES/oslo_privsep.po', 'releasenotes/source/locale/en_GB/LC_MESSAGES/releasenotes.po'], 'web_link': 'https://opendev.org/openstack/oslo.privsep/commit/1f9d71260e4ad42ad0082b2c44e88b256c8c87dc', 'message': 'Imported Translations from Zanata\n\nFor more information about this automatic import see:\nhttps://docs.openstack.org/i18n/latest/reviewing-translation-import.html\n\nChange-Id: I3f263194f71469ca9ca67f3d99b10dc75c448e20\n'}]",0,886700,1f9d71260e4ad42ad0082b2c44e88b256c8c87dc,8,3,1,11131,,,0,"Imported Translations from Zanata

For more information about this automatic import see:
https://docs.openstack.org/i18n/latest/reviewing-translation-import.html

Change-Id: I3f263194f71469ca9ca67f3d99b10dc75c448e20
",git fetch https://review.opendev.org/openstack/oslo.privsep refs/changes/00/886700/1 && git format-patch -1 --stdout FETCH_HEAD,"['oslo_privsep/locale/en_GB/LC_MESSAGES/oslo_privsep.po', 'releasenotes/source/locale/en_GB/LC_MESSAGES/releasenotes.po']",2,1f9d71260e4ad42ad0082b2c44e88b256c8c87dc,zanata/translations,"# Andi Chandler <andi@gowling.com>, 2023. #zanata""Project-Id-Version: oslo.privsep\n""""POT-Creation-Date: 2023-05-08 11:10+0000\n""""PO-Revision-Date: 2023-06-21 09:00+0000\n""msgid ""1.31.0"" msgstr ""1.31.0"" msgid ""1.33.3"" msgstr ""1.33.3"" msgid ""1.33.4"" msgstr ""1.33.4"" msgid ""2.0.0"" msgstr ""2.0.0"" msgid ""2.1.2"" msgstr ""2.1.2"" msgid ""2.3.0"" msgstr ""2.3.0"" msgid ""2.6.0"" msgstr ""2.6.0"" msgid ""2023.1 Series Release Notes"" msgstr ""2023.1 Series Release Notes"" msgid """" ""Add ``timeout`` as parameter to ``PrivContext`` and add "" ""``entrypoint_with_timeout`` decorator to cover the issues with commands "" ""which take random time to finish. ``PrivsepTimeout`` is raised if timeout is "" ""reached."" msgstr """" ""Add ``timeout`` as a parameter to ``PrivContext`` and add "" ""``entrypoint_with_timeout`` decorator to cover the issues with commands "" ""which take random time to finish. ``PrivsepTimeout`` is raised if a timeout "" ""is reached."" msgid ""Bug Fixes"" msgstr ""Bug Fixes"" msgid """" ""By default all contexts use ``oslo_privsep.daemon``, but in some cases we "" ""may need finer grained log levels, for example nova running in debug mode "" ""could log its own privsep calls on INFO level regardless, but leave all "" ""libraries' privsep calls, such as os-brick's, to be logged in the normal "" ""DEBUG level."" msgstr """" ""By default all contexts use ``oslo_privsep.daemon``, but in some cases, we "" ""may need finer-grained log levels, for example, Nova running in debug mode "" ""could log its own privsep calls on INFO level regardless, but leave all "" ""libraries' privsep calls, such as os-brick's, to be logged in the normal "" ""DEBUG level."" msgid ""New Features"" msgstr ""New Features"" msgid """" ""Privsep now uses multithreading to allow concurrency in executing privileged "" ""commands. The number of concurrent threads defaults to the available CPU "" ""cores, but can be adjusted by the new ``thread_pool_size`` config option."" msgstr """" ""Privsep now uses multithreading to allow concurrency in executing privileged "" ""commands. The number of concurrent threads defaults to the available CPU "" ""cores but can be adjusted by the new ``thread_pool_size`` config option."" msgid ""Rocky Series Release Notes"" msgstr ""Rocky Series Release Notes"" msgid ""See `bug 1922052`_."" msgstr ""See `bug 1922052`_."" msgid ""Stein Series Release Notes"" msgstr ""Stein Series Release Notes"" msgid """" ""Support for Python 2.7 has been dropped. The minimum version of Python now "" ""supported is Python 3.6."" msgstr """" ""Support for Python 2.7 has been dropped. The minimum version of Python now "" ""supported is Python 3.6."" msgid """" ""The ``oslo.privsep`` client can be called from a program using eventlet. If "" ""``eventlet.monkey_patch``, some libraries will be patched, for example "" ""``threading`` or ``os``. When the root daemon is forked from the client "" ""process, those libraries remain patched. Now, when the daemon is forked from "" ""the client process, those libraries and methods are restored to the original "" ""values. The goal is to prevent some timeouts when using eventlet threads "" ""(user threads); system threads are preemptive and the code does not need to "" ""care about the executor token."" msgstr """" ""The ``oslo.privsep`` client can be called from a program using eventlet. If "" ""``eventlet.monkey_patch``, some libraries will be patched, for example "" ""``threading`` or ``os``. When the root daemon is forked from the client "" ""process, those libraries remain patched. Now, when the daemon is forked from "" ""the client process, those libraries and methods are restored to the original "" ""values. The goal is to prevent some timeouts when using eventlet threads "" ""(user threads); system threads are preemptive and the code does not need to "" ""care about the executor token."" msgid """" ""This only works for the ``ROOTWRAP`` method of starting the daemon. With the "" ""``FORK`` method we've dropped privileges and no longer have the ability to "" ""restart the daemon in privileged mode."" msgstr """" ""This only works for the ``ROOTWRAP`` method of starting the daemon. With the "" ""``FORK`` method we've dropped privileges and no longer have the ability to "" ""restart the daemon in privileged mode."" msgid ""Train Series Release Notes"" msgstr ""Train Series Release Notes"" msgid ""Upgrade Notes"" msgstr ""Upgrade Notes"" msgid ""Ussuri Series Release Notes"" msgstr ""Ussuri Series Release Notes"" msgid ""Victoria Series Release Notes"" msgstr ""Victoria Series Release Notes"" msgid ""Wallaby Series Release Notes"" msgstr ""Wallaby Series Release Notes"" msgid """" ""When the privsep helper dies, the client side PrivContext now restarts the "" ""client channel and the helper so that privileged commands can continue to be "" ""processed. See `bug 1715374`_ for details. In conjunction with the fix for "" ""`bug 1794708`_ in oslo.service, the nova-compute service now behaves "" ""correctly when it receives ``SIGHUP``."" msgstr """" ""When the privsep helper dies, the client side PrivContext now restarts the "" ""client channel and the helper so that privileged commands can continue to be "" ""processed. See `bug 1715374`_ for details. In conjunction with the fix for "" ""`bug 1794708`_ in oslo.service, the nova-compute service now behaves "" ""correctly when it receives ``SIGHUP``."" msgid ""Xena Series Release Notes"" msgstr ""Xena Series Release Notes"" msgid ""Yoga Series Release Notes"" msgstr ""Yoga Series Release Notes"" msgid ""Zed Series Release Notes"" msgstr ""Zed Series Release Notes"" msgid """" ""``PrivContext`` accepts a new string parameter called ``logger_name`` to "" ""define the logger we want to use for the daemon logs of this context."" msgstr """" ""``PrivContext`` accepts a new string parameter called ``logger_name`` to "" ""define the logger we want to use for the daemon logs of this context."" msgid """" ""``Warning``: The daemon (the root process) task won't stop when timeout is "" ""reached. That means we'll have less available threads if the related thread "" ""never finishes."" msgstr """" ""``Warning``: The daemon (the root process) task won't stop when the timeout "" ""is reached. That means we'll have fewer available threads if the related "" ""thread never finishes."" ","""Project-Id-Version: oslo.privsep Release Notes\n""""POT-Creation-Date: 2018-02-08 23:11+0000\n""""PO-Revision-Date: 2018-02-06 11:25+0000\n""",181,5
openstack%2Foslo.messaging~886695,openstack/oslo.messaging,master,If124c09bfa878585b89dee7578a97c12c42497f8,Imported Translations from Zanata,MERGED,2023-06-22 03:45:16.000000000,2023-07-12 10:40:34.000000000,2023-07-12 10:39:26.000000000,"[{'_account_id': 9816}, {'_account_id': 22348}, {'_account_id': 28522}]","[{'number': 1, 'created': '2023-06-22 03:45:16.000000000', 'files': ['releasenotes/source/locale/en_GB/LC_MESSAGES/releasenotes.po'], 'web_link': 'https://opendev.org/openstack/oslo.messaging/commit/ec1c99d562659f1ca246ecdd75e810c9ece0140d', 'message': 'Imported Translations from Zanata\n\nFor more information about this automatic import see:\nhttps://docs.openstack.org/i18n/latest/reviewing-translation-import.html\n\nChange-Id: If124c09bfa878585b89dee7578a97c12c42497f8\n'}]",0,886695,ec1c99d562659f1ca246ecdd75e810c9ece0140d,8,3,1,11131,,,0,"Imported Translations from Zanata

For more information about this automatic import see:
https://docs.openstack.org/i18n/latest/reviewing-translation-import.html

Change-Id: If124c09bfa878585b89dee7578a97c12c42497f8
",git fetch https://review.opendev.org/openstack/oslo.messaging refs/changes/95/886695/1 && git format-patch -1 --stdout FETCH_HEAD,['releasenotes/source/locale/en_GB/LC_MESSAGES/releasenotes.po'],1,ec1c99d562659f1ca246ecdd75e810c9ece0140d,zanata/translations,"# Andi Chandler <andi@gowling.com>, 2023. #zanata""POT-Creation-Date: 2023-05-18 14:34+0000\n""""PO-Revision-Date: 2023-06-21 08:39+0000\n""msgid ""10.2.4"" msgstr ""10.2.4"" msgid ""12.1.4"" msgstr ""12.1.4"" msgid ""12.1.6"" msgstr ""12.1.6"" msgid ""12.11.0"" msgstr ""12.11.0"" msgid ""12.12.0"" msgstr ""12.12.0"" msgid ""12.13.0"" msgstr ""12.13.0"" msgid ""12.14.0"" msgstr ""12.14.0"" msgid ""12.3.0"" msgstr ""12.3.0"" msgid ""12.4.0"" msgstr ""12.4.0"" msgid ""12.5.2"" msgstr ""12.5.2"" msgid ""12.6.0"" msgstr ""12.6.0"" msgid ""12.7.0"" msgstr ""12.7.0"" msgid ""12.7.1"" msgstr ""12.7.1"" msgid ""12.7.3"" msgstr ""12.7.3"" msgid ""12.9.0"" msgstr ""12.9.0"" msgid ""12.9.3"" msgstr ""12.9.3"" msgid ""13.0.0"" msgstr ""13.0.0"" msgid ""14.0.0"" msgstr ""14.0.0"" msgid ""14.1.0"" msgstr ""14.1.0"" msgid ""14.2.0"" msgstr ""14.2.0"" msgid ""14.3.0"" msgstr ""14.3.0"" msgid ""14.3.0-1"" msgstr ""14.3.0-1"" msgid ""2023.1 Series Release Notes"" msgstr ""2023.1 Series Release Notes"" msgid ""9.5.2-4"" msgstr ""9.5.2-4"" ""Add a new option `enable_cancel_on_failover` for rabbitmq driver which when "" ""enabled, will cancel consumers when queue appears to be down."" msgstr """" ""Add a new option `enable_cancel_on_failover` for RabbitMQ driver which when "" ""enabled, will cancel consumers when the queue appears to be down."" msgid """"msgid """" ""Add quorum configuration x-max-in-memory-length, x-max-in-memory-bytes, x-"" ""delivery-limit which control the quorum queue memory usage and handle the "" ""message poisoning problem"" msgstr """" ""Add quorum configuration x-max-in-memory-length, x-max-in-memory-bytes, x-"" ""delivery-limit which control the quorum queue memory usage and handle the "" ""message poisoning problem"" msgid """" ""Added new ``get_rpc_client`` function to instantiate the RPCClient class"" msgstr """" ""Added new ``get_rpc_client`` function to instantiate the RPCClient class"" msgid """" ""Adding a new option, ``[oslo_messaging_rabbit] ssl_enforce_fips_mode``, to "" ""the rabbitmq driver to enforce the OpenSSL FIPS mode if supported by the "" ""version of Python."" msgstr """" ""Adding a new option, ``[oslo_messaging_rabbit] ssl_enforce_fips_mode``, to "" ""the rabbitmq driver to enforce the OpenSSL FIPS mode if supported by the "" ""version of Python."" msgid """" ""Adding retry strategy based on the mandatory flag. Missing exchanges and "" ""queues are now identified separately for logging purposes."" msgstr """" ""Adding retry strategy based on the mandatory flag. Missing exchanges and "" ""queues are now identified separately for logging purposes."" msgid """" ""Adding support for quorum queues. Quorum queues are enabled if the "" ""``rabbit_quorum_queue`` parameter is sets (``x-queue-type: quorum``). "" ""Setting x-queue-type to quorum means that replicated FIFO queue based on the "" ""Raft consensus algorithm will be used. It is available as of RabbitMQ 3.8.0. "" ""The quorum queues are durable by default (``amqp_durable_queues``) will be "" ""ignored. when enabled the HA queues (``rabbit_ha_queues``) aka mirrored "" ""queues should be disabled since the queue can't be both types at the same "" ""time"" msgstr """" ""Adding support for quorum queues. Quorum queues are enabled if the "" ""``rabbit_quorum_queue`` parameter is sets (``x-queue-type: quorum``). "" ""Setting x-queue-type to quorum means that replicated FIFO queue based on the "" ""Raft consensus algorithm will be used. It is available as of RabbitMQ 3.8.0. "" ""The quorum queues are durable by default (``amqp_durable_queues``) will be "" ""ignored. when enabled the HA queues (``rabbit_ha_queues``) aka mirrored "" ""queues should be disabled since the queue can't be both types at the same "" ""time"" msgid """" ""As a fix for `bug 1917645 <https://launchpad.net/bugs/1917645>`_ the rabbit "" ""backend is changed to use the ``[oslo_messaging_notifications]retry`` "" ""parameter when driver tries to connect to the message bus during "" ""notification sending. Before this fix the rabbit backend retried the "" ""connection forever blocking the caller thread."" msgstr """" ""As a fix for `bug 1917645 <https://launchpad.net/bugs/1917645>`_ the rabbit "" ""backend is changed to use the ``[oslo_messaging_notifications]retry`` "" ""parameter when the driver tries to connect to the message bus during "" ""notification sending. Before this fix the rabbit backend retried the "" ""connection forever blocking the caller thread."" msgid """" ""Deprecating the ``direct_mandatory_flag``. It will not be possible to "" ""deactivate this functionality anymore."" msgstr """" ""Deprecating the ``direct_mandatory_flag``. It will not be possible to "" ""deactivate this functionality anymore."" msgid """" ""Fixed typo in variable names ``rabbit_quorum_max_memory_length`` and "" ""``rabbit_quorum_max_memory_bytes``. Please make changes in your config files "" ""to correspond correct variables."" msgstr """" ""Fixed typo in variable names ``rabbit_quorum_max_memory_length`` and "" ""``rabbit_quorum_max_memory_bytes``. Please make changes in your config files "" ""to correspond correct variables."" msgid """" ""Force creating non durable control exchange when a precondition failed "" ""related to config that differ occuring."" msgstr """" ""Force creating non-durable control exchange when a precondition failed "" ""related to config that differs occurring."" ""If kombu_reconnect_delay is specified in the [oslo_messaging_rabbit] "" ""section, ensure that it is less than 5.0, the value of "" ""ACK_REQUEUE_EVERY_SECONDS_MAX"" msgstr """" ""If kombu_reconnect_delay is specified in the [oslo_messaging_rabbit] "" ""section, ensure that it is less than 5.0, the value of "" ""ACK_REQUEUE_EVERY_SECONDS_MAX"" msgid """"""Increased ACK_REQUEUE_EVERY_SECONDS_MAX to resolve issues with rabbitmq HA "" ""failover."" msgstr """" ""Increased ACK_REQUEUE_EVERY_SECONDS_MAX to resolve issues with RabbitMQ HA "" ""failover."" msgid """" ""Instantiating the RPCClient class directly is deprecated in favor of using "" ""the new ``get_rpc_client`` function to expose a more common API similar to "" ""existing functions such as ``get_rpc_server`` and ``get_rpc_transport``"" msgstr """" ""Instantiating the RPCClient class directly is deprecated in favour of using "" ""the new ``get_rpc_client`` function to expose a more common API similar to "" ""existing functions such as ``get_rpc_server`` and ``get_rpc_transport``"" msgid ""Introduce support for sending rpc client metrics to oslo.metrics."" msgstr ""Introduce support for sending RPC client metrics to oslo.metrics."" msgid """"""RPC dispatcher can have an extra endpoint named ping. This endpoint can be "" ""enabled thanks to a specific configuration parameter: [DEFAULT] "" ""rpc_ping_enabled=true # default is false"" msgstr """" ""RPC dispatcher can have an extra endpoint named ping. This endpoint can be "" ""enabled thanks to a specific configuration parameter: [DEFAULT] "" ""rpc_ping_enabled=true # default is false"" msgid """"msgid ""Security Issues"" msgstr ""Security Issues"" ""The ``[oslo_messaging_rabbit] heartbeat_in_pthread`` config option defaults "" ""to ``False`` again. For wsgi applications it is recommended to set this "" ""value to ``True`` but enabling it for non-wsgi services may break such "" ""service. Please check https://bugs.launchpad.net/oslo.messaging/+bug/1934937 "" ""for more details."" msgstr """" ""The ``[oslo_messaging_rabbit] heartbeat_in_pthread`` config option defaults "" ""to ``False`` again. For wsgi applications it is recommended to set this "" ""value to ``True`` but enabling it for non-wsgi services may break such "" ""service. Please check https://bugs.launchpad.net/oslo.messaging/+bug/1934937 "" ""for more details."" msgid """" ""The ``[oslo_messaging_rabbit] heartbeat_in_pthread`` config option now "" ""defaults to ``True``. Applications will run RabbitMQ heartbeat in a Python "" ""thread by default."" msgstr """" ""The ``[oslo_messaging_rabbit] heartbeat_in_pthread`` config option now "" ""defaults to ``True``. Applications will run RabbitMQ heartbeat in a Python "" ""thread by default."" msgid """" ""The ``get_rpc_transport``, ``get_rpc_server`` and ``get_rpc_client`` helper "" ""functions now have support for overriding the class that is instantiated."" msgstr """" ""The ``get_rpc_transport``, ``get_rpc_server`` and ``get_rpc_client`` helper "" ""functions now have support for overriding the class that is instantiated."" msgid """"""The purpose of this new endpoint is to help operators do a RPC call (a ping) "" ""toward a specific RPC callback (e.g. a nova-compute, or a neutron-agent). "" ""This is helping a lot for monitoring agents (for example, if agents are "" ""deployed in a kubernetes pod)."" msgstr """" ""The purpose of this new endpoint is to help operators do a RPC call (a ping) "" ""toward a specific RPC callback (e.g. a nova-compute, or a neutron agent). "" ""This is helping a lot with monitoring agents (for example, if agents are "" ""deployed in a Kubernetes pod)."" msgid """"msgid ""This feature can be enabled by setting a configuration parameter:"" msgstr ""This feature can be enabled by setting a configuration parameter:"" msgid ""Victoria Series Release Notes"" msgstr ""Victoria Series Release Notes"" msgid ""Wallaby Series Release Notes"" msgstr ""Wallaby Series Release Notes"" msgid """" ""We are now able to enforce the OpenSSL FIPS mode by using "" ""``[oslo_messaging_rabbit] ssl_enforce_fips_mode``."" msgstr """" ""We are now able to enforce the OpenSSL FIPS mode by using "" ""``[oslo_messaging_rabbit] ssl_enforce_fips_mode``."" msgid """" ""We undeprecated the ``heartbeat_in_pthread`` option. This option will remain "" ""available to allow customers to run the rabbitmq heartbeat in python thread "" ""or not."" msgstr """" ""We un-deprecated the ``heartbeat_in_pthread`` option. This option will "" ""remain available to allow customers to run the RabbitMQ heartbeat in Python "" ""thread or not."" msgid ""Xena Series Release Notes"" msgstr ""Xena Series Release Notes"" msgid ""Yoga Series Release Notes"" msgstr ""Yoga Series Release Notes"" msgid ""Zed Series Release Notes"" msgstr ""Zed Series Release Notes"" msgid """" ""[`bug 1981093 <https://bugs.launchpad.net/oslo.messaging/+bug/1981093>`_] "" ""Pulls calls to logging functions out of ``impl_kafka._produce_message``. "" ""Since ``_produce_message`` is called through tpool.execute, calling logging "" ""functions inside ``_produce_message`` could cause subsequent calls to "" ""logging functions to deadlock."" msgstr """" ""[`bug 1981093 <https://bugs.launchpad.net/oslo.messaging/+bug/1981093>`_] "" ""Pulls calls to logging functions out of ``impl_kafka._produce_message``. "" ""Since ``_produce_message`` is called through tpool.execute, calling logging "" ""functions inside ``_produce_message`` could cause subsequent calls to "" ""logging functions to deadlock."" msgid ""[oslo_messaging_metrics] metrics_enabled = True # default is false"" msgstr ""[oslo_messaging_metrics] metrics_enabled = True # default is false"" msgid """" ""``heartbeat_in_pthread`` has been deprecated and will be removed in a future "" ""release. If configured, this option should be unset."" msgstr """" ""``heartbeat_in_pthread`` has been deprecated and will be removed in a future "" ""release. If configured, this option should be unset."" ","""POT-Creation-Date: 2020-04-15 22:07+0000\n""""PO-Revision-Date: 2020-04-16 12:41+0000\n""",304,2
openstack%2Foslo.versionedobjects~886703,openstack/oslo.versionedobjects,master,I0a85370e6afb1c2875b687067d294d6ada6a96d1,Imported Translations from Zanata,MERGED,2023-06-22 04:36:32.000000000,2023-07-12 10:39:57.000000000,2023-07-12 10:38:59.000000000,"[{'_account_id': 9816}, {'_account_id': 22348}, {'_account_id': 28522}]","[{'number': 1, 'created': '2023-06-22 04:36:32.000000000', 'files': ['releasenotes/source/locale/en_GB/LC_MESSAGES/releasenotes.po'], 'web_link': 'https://opendev.org/openstack/oslo.versionedobjects/commit/efe0cdc8cb16033a61d7f84d0acc7bd6fa5e1be3', 'message': 'Imported Translations from Zanata\n\nFor more information about this automatic import see:\nhttps://docs.openstack.org/i18n/latest/reviewing-translation-import.html\n\nChange-Id: I0a85370e6afb1c2875b687067d294d6ada6a96d1\n'}]",0,886703,efe0cdc8cb16033a61d7f84d0acc7bd6fa5e1be3,8,3,1,11131,,,0,"Imported Translations from Zanata

For more information about this automatic import see:
https://docs.openstack.org/i18n/latest/reviewing-translation-import.html

Change-Id: I0a85370e6afb1c2875b687067d294d6ada6a96d1
",git fetch https://review.opendev.org/openstack/oslo.versionedobjects refs/changes/03/886703/1 && git format-patch -1 --stdout FETCH_HEAD,['releasenotes/source/locale/en_GB/LC_MESSAGES/releasenotes.po'],1,efe0cdc8cb16033a61d7f84d0acc7bd6fa5e1be3,zanata/translations,"# Andi Chandler <andi@gowling.com>, 2023. #zanata""POT-Creation-Date: 2023-05-08 11:19+0000\n""""PO-Revision-Date: 2023-06-21 08:08+0000\n""msgid ""2023.1 Series Release Notes"" msgstr ""2023.1 Series Release Notes"" ","""POT-Creation-Date: 2022-09-09 15:40+0000\n""""PO-Revision-Date: 2022-09-30 10:47+0000\n""",6,2
openstack%2Foslo.reports~886693,openstack/oslo.reports,master,I02a2d3a21282df29723105853b636d28aaffb91f,Imported Translations from Zanata,MERGED,2023-06-22 03:35:03.000000000,2023-07-12 10:38:51.000000000,2023-07-12 10:37:47.000000000,"[{'_account_id': 9816}, {'_account_id': 22348}, {'_account_id': 28522}]","[{'number': 1, 'created': '2023-06-22 03:35:03.000000000', 'files': ['releasenotes/source/locale/en_GB/LC_MESSAGES/releasenotes.po'], 'web_link': 'https://opendev.org/openstack/oslo.reports/commit/ec934c26b7e74e985b746b5c7a8719d7e25d7ea8', 'message': 'Imported Translations from Zanata\n\nFor more information about this automatic import see:\nhttps://docs.openstack.org/i18n/latest/reviewing-translation-import.html\n\nChange-Id: I02a2d3a21282df29723105853b636d28aaffb91f\n'}]",0,886693,ec934c26b7e74e985b746b5c7a8719d7e25d7ea8,8,3,1,11131,,,0,"Imported Translations from Zanata

For more information about this automatic import see:
https://docs.openstack.org/i18n/latest/reviewing-translation-import.html

Change-Id: I02a2d3a21282df29723105853b636d28aaffb91f
",git fetch https://review.opendev.org/openstack/oslo.reports refs/changes/93/886693/1 && git format-patch -1 --stdout FETCH_HEAD,['releasenotes/source/locale/en_GB/LC_MESSAGES/releasenotes.po'],1,ec934c26b7e74e985b746b5c7a8719d7e25d7ea8,zanata/translations,"# Andi Chandler <andi@gowling.com>, 2023. #zanata""POT-Creation-Date: 2023-05-05 13:27+0000\n""""PO-Revision-Date: 2023-06-21 08:13+0000\n""msgid ""2023.1 Series Release Notes"" msgstr ""2023.1 Series Release Notes"" ","""POT-Creation-Date: 2022-05-11 15:48+0000\n""""PO-Revision-Date: 2022-06-13 07:39+0000\n""",6,2
openstack%2Fneutron~885240,openstack/neutron,master,Ia7937390867e45af34ebcd65bd76fc89b6adafe9,[neutron-api] remove leader_only for sb connection,MERGED,2023-06-05 09:23:39.000000000,2023-07-12 10:31:13.000000000,2023-07-12 10:29:57.000000000,"[{'_account_id': 5756}, {'_account_id': 6773}, {'_account_id': 9845}, {'_account_id': 16688}, {'_account_id': 22348}]","[{'number': 1, 'created': '2023-06-05 09:23:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/c6af1d07f6a479cca8c9a7db608f7e43bfa324f9', 'message': 'fix sb leader only for maintenance worker\n\nThe maintenance worker is only using the sb to get stuff and is not\npushing something into it.\nThats why i remove the leader_only flag for the maintenance worker. This\nshould also enable the neutron api to connect to relays instead of the\nsb directly.\n\nChange-Id: Ia7937390867e45af34ebcd65bd76fc89b6adafe9\n'}, {'number': 2, 'created': '2023-06-05 09:25:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/78140825edbcc3f62231fc4366600b96ba071273', 'message': 'fix sb leader only for maintenance worker\n\nThe maintenance worker is only using the sb to get stuff and is not\npushing something into it.\nThats why i remove the leader_only flag for the maintenance worker. This\nshould also enable the neutron api to connect to relays instead of the\nsb directly.\n\nChange-Id: Ia7937390867e45af34ebcd65bd76fc89b6adafe9\nSigned-off-by: maximkorezkij <maxim.korezkij@mail.schwarz>\n'}, {'number': 3, 'created': '2023-06-05 10:25:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/801c0735f069aeef2726cbeadb3ee137e27ac881', 'message': '[neutron-api] remove leader_only for sb connection\n\nThe maintenance worker from the neutron-api uses a southbound\nconnection. This task is using the southbound only to get data.\n\nThis commit removes the leader_only flag for the maintenance worker. This\nshould also enable the neutron api to connect to relays instead of only\nthe sb directly.\n\nCloses-Bug: #2022914\nChange-Id: Ia7937390867e45af34ebcd65bd76fc89b6adafe9\nSigned-off-by: maximkorezkij <maxim.korezkij@mail.schwarz>\n'}, {'number': 4, 'created': '2023-06-05 10:25:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/0ce4d9ae5d958899c0e0645372cdd4bcd5be3c6d', 'message': '[neutron-api] remove leader_only for sb connection\n\nThe maintenance worker from the neutron-api uses a southbound\nconnection. This task is using the southbound only to get data.\n\nThis commit removes the leader_only flag for the maintenance worker.\nThis should also enable the neutron api to connect to relays instead of only\nthe sb directly.\n\nCloses-Bug: #2022914\nChange-Id: Ia7937390867e45af34ebcd65bd76fc89b6adafe9\nSigned-off-by: maximkorezkij <maxim.korezkij@mail.schwarz>\n'}, {'number': 5, 'created': '2023-06-06 07:07:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/a0ae83097b1d0b76dd1b0af5c76b400f8e5b93ba', 'message': '[neutron-api] remove leader_only for sb connection\n\nThe maintenance worker from the neutron-api uses a southbound\nconnection. This task is using the southbound only to get data.\n\nThis commit removes the leader_only flag for the maintenance worker.\nThis should also enable the neutron api to connect to relays instead of only\nthe sb directly.\n\nCloses-Bug: #2022914\nChange-Id: Ia7937390867e45af34ebcd65bd76fc89b6adafe9\nSigned-off-by: maximkorezkij <maxim.korezkij@mail.schwarz>\n'}, {'number': 6, 'created': '2023-07-12 06:16:22.000000000', 'files': ['neutron/plugins/ml2/drivers/ovn/mech_driver/ovsdb/ovsdb_monitor.py', 'releasenotes/notes/bug-2022914-edbf1ea3514596b8.yaml'], 'web_link': 'https://opendev.org/openstack/neutron/commit/a9c8bf5c069d3324828294e3e36b5374d5a828fe', 'message': '[neutron-api] remove leader_only for sb connection\n\nThe maintenance worker from the neutron-api uses a southbound\nconnection. Since the southbound does not use any locking and all the\novsdb locking is used for the northbound this changes should not have a\nbig impact.\n\nThis commit removes the leader_only flag for the maintenance worker.\nThis should also enable the neutron api to connect to relays instead of only\nthe sb directly.\n\nCloses-Bug: #2022914\nChange-Id: Ia7937390867e45af34ebcd65bd76fc89b6adafe9\nSigned-off-by: maximkorezkij <maxim.korezkij@mail.schwarz>\n'}]",13,885240,a9c8bf5c069d3324828294e3e36b5374d5a828fe,34,5,6,33237,,,0,"[neutron-api] remove leader_only for sb connection

The maintenance worker from the neutron-api uses a southbound
connection. Since the southbound does not use any locking and all the
ovsdb locking is used for the northbound this changes should not have a
big impact.

This commit removes the leader_only flag for the maintenance worker.
This should also enable the neutron api to connect to relays instead of only
the sb directly.

Closes-Bug: #2022914
Change-Id: Ia7937390867e45af34ebcd65bd76fc89b6adafe9
Signed-off-by: maximkorezkij <maxim.korezkij@mail.schwarz>
",git fetch https://review.opendev.org/openstack/neutron refs/changes/40/885240/1 && git format-patch -1 --stdout FETCH_HEAD,['neutron/plugins/ml2/drivers/ovn/mech_driver/ovsdb/ovsdb_monitor.py'],1,c6af1d07f6a479cca8c9a7db608f7e43bfa324f9,fix_sb_leader_only," return cls(connection_string, helper, leader_only=False)"," return cls(connection_string, helper, leader_only=True)",1,1
openstack%2Fnova~888221,openstack/nova,master,I3e961861885cc1fac54657d9fe7eae755ee57dda,Workaround to fix the issue in resize with ephemeral disk named disk.local. Add a condition to ensure the backing file is present on target host.,ABANDONED,2023-07-12 09:42:01.000000000,2023-07-12 09:43:36.000000000,,[],"[{'number': 1, 'created': '2023-07-12 09:42:01.000000000', 'files': ['nova/virt/libvirt/driver.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/ca8f2c50dc0e84446b8a07be65b9b9fdcc0fd77a', 'message': 'Workaround to fix the issue in resize with ephemeral disk named disk.local.\nAdd a condition to ensure the backing file is present on target host.\n\nCloses-bug: https://bugs.launchpad.net/nova/+bug/2027553\nChange-Id: I3e961861885cc1fac54657d9fe7eae755ee57dda\n'}]",0,888221,ca8f2c50dc0e84446b8a07be65b9b9fdcc0fd77a,3,0,1,33952,,,0,"Workaround to fix the issue in resize with ephemeral disk named disk.local.
Add a condition to ensure the backing file is present on target host.

Closes-bug: https://bugs.launchpad.net/nova/+bug/2027553
Change-Id: I3e961861885cc1fac54657d9fe7eae755ee57dda
",git fetch https://review.opendev.org/openstack/nova refs/changes/21/888221/1 && git format-patch -1 --stdout FETCH_HEAD,['nova/virt/libvirt/driver.py'],1,ca8f2c50dc0e84446b8a07be65b9b9fdcc0fd77a,bug/2027553,,,1,0
openstack%2Fpuppet-nova~886569,openstack/puppet-nova,master,I7a66cba32f00851e0c93b8ef6e5a620fb474f111,replace validate_legacy with proper data types,MERGED,2023-06-21 05:32:11.000000000,2023-07-12 09:42:20.000000000,2023-07-12 09:42:20.000000000,"[{'_account_id': 9816}, {'_account_id': 14985}, {'_account_id': 16137}, {'_account_id': 22348}]","[{'number': 1, 'created': '2023-06-21 05:32:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-nova/commit/1457d582f21d5a01947bf9243e548eea6d6f42a5', 'message': 'replace validate_legacy with proper data types\n\nthe validate_legacy function is marked for deprecation in\nv9.0.0 from puppetlabs-stdlib.\n\nChange-Id: I7a66cba32f00851e0c93b8ef6e5a620fb474f111\n'}, {'number': 2, 'created': '2023-06-21 06:57:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-nova/commit/53ef45ce829311c15bd65464b616690a22c15667', 'message': 'replace validate_legacy with proper data types\n\nthe validate_legacy function is marked for deprecation in\nv9.0.0 from puppetlabs-stdlib.\n\nChange-Id: I7a66cba32f00851e0c93b8ef6e5a620fb474f111\n'}, {'number': 3, 'created': '2023-06-21 06:58:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-nova/commit/68479a3215a12b50db2a3ef123a653c58f2c6a71', 'message': 'replace validate_legacy with proper data types\n\nthe validate_legacy function is marked for deprecation in\nv9.0.0 from puppetlabs-stdlib.\n\nChange-Id: I7a66cba32f00851e0c93b8ef6e5a620fb474f111\n'}, {'number': 4, 'created': '2023-06-21 08:37:53.000000000', 'files': ['manifests/conductor.pp', 'manifests/api.pp', 'manifests/compute/libvirt_guests.pp', 'manifests/cron/purge_shadow_tables.pp', 'manifests/db/mysql.pp', 'manifests/compute/mdev.pp', 'manifests/compute.pp', 'manifests/migration/qemu.pp', 'manifests/compute/libvirt/networks.pp', 'manifests/compute/libvirt/config.pp', 'manifests/serialproxy.pp', 'manifests/compute/rbd.pp', 'manifests/scheduler/filter.pp', 'manifests/spicehtml5proxy.pp', 'manifests/generic_service.pp', 'manifests/db/sync_api.pp', 'manifests/db/postgresql.pp', 'manifests/init.pp', 'manifests/migration/libvirt.pp', 'manifests/compute/libvirt.pp', 'manifests/config.pp', 'manifests/compute/spice.pp', 'manifests/scheduler.pp', 'manifests/vncproxy.pp', 'manifests/cron/archive_deleted_rows.pp', 'manifests/vendordata.pp', 'manifests/compute/libvirt/qemu.pp', 'manifests/policy.pp'], 'web_link': 'https://opendev.org/openstack/puppet-nova/commit/f0cb20a86a485910018b42fa43cbed883d3ae7fc', 'message': 'replace validate_legacy with proper data types\n\nthe validate_legacy function is marked for deprecation in\nv9.0.0 from puppetlabs-stdlib.\n\nChange-Id: I7a66cba32f00851e0c93b8ef6e5a620fb474f111\n'}]",8,886569,f0cb20a86a485910018b42fa43cbed883d3ae7fc,33,4,4,9816,,,0,"replace validate_legacy with proper data types

the validate_legacy function is marked for deprecation in
v9.0.0 from puppetlabs-stdlib.

Change-Id: I7a66cba32f00851e0c93b8ef6e5a620fb474f111
",git fetch https://review.opendev.org/openstack/puppet-nova refs/changes/69/886569/1 && git format-patch -1 --stdout FETCH_HEAD,"['manifests/conductor.pp', 'manifests/api.pp', 'manifests/compute/libvirt_guests.pp', 'manifests/cron/purge_shadow_tables.pp', 'manifests/db/mysql.pp', 'manifests/compute/mdev.pp', 'manifests/compute.pp', 'manifests/migration/qemu.pp', 'manifests/compute/libvirt/networks.pp', 'manifests/compute/libvirt/config.pp', 'manifests/serialproxy.pp', 'manifests/compute/rbd.pp', 'manifests/scheduler/filter.pp', 'manifests/spicehtml5proxy.pp', 'manifests/generic_service.pp', 'manifests/db/sync_api.pp', 'manifests/db/postgresql.pp', 'manifests/init.pp', 'manifests/migration/libvirt.pp', 'manifests/compute/libvirt.pp', 'manifests/config.pp', 'manifests/compute/spice.pp', 'manifests/scheduler.pp', 'manifests/vncproxy.pp', 'manifests/cron/archive_deleted_rows.pp', 'manifests/vendordata.pp', 'manifests/compute/libvirt/qemu.pp', 'manifests/policy.pp']",28,1457d582f21d5a01947bf9243e548eea6d6f42a5,replace-validate_legacy," Hash $policies = {},"," $policies = {}, validate_legacy(Hash, 'validate_hash', $policies) ",150,269
openstack%2Fpuppet-sahara~887874,openstack/puppet-sahara,stable/2023.1,I72b2d29962e82e9c254c2254663865da2b747e3b,Add per module policy service refresh,MERGED,2023-07-06 19:17:21.000000000,2023-07-12 09:33:45.000000000,2023-07-12 09:33:45.000000000,"[{'_account_id': 9816}, {'_account_id': 14985}, {'_account_id': 22348}]","[{'number': 1, 'created': '2023-07-06 19:17:21.000000000', 'files': ['spec/classes/sahara_policy_spec.rb', 'manifests/deps.pp', 'manifests/policy.pp'], 'web_link': 'https://opendev.org/openstack/puppet-sahara/commit/d6c970f4c80c23e04764f2ec6d287a0ecff92c3c', 'message': 'Add per module policy service refresh\n\nUpdating the policies for this project should only\nrefresh the services that reads it.\n\nChange-Id: I72b2d29962e82e9c254c2254663865da2b747e3b\n(cherry picked from commit e2b1d99501500991b2ddfd9cf115b33fbd2dc2ea)\n'}]",0,887874,d6c970f4c80c23e04764f2ec6d287a0ecff92c3c,7,3,1,16137,,,0,"Add per module policy service refresh

Updating the policies for this project should only
refresh the services that reads it.

Change-Id: I72b2d29962e82e9c254c2254663865da2b747e3b
(cherry picked from commit e2b1d99501500991b2ddfd9cf115b33fbd2dc2ea)
",git fetch https://review.opendev.org/openstack/puppet-sahara refs/changes/74/887874/1 && git format-patch -1 --stdout FETCH_HEAD,"['spec/classes/sahara_policy_spec.rb', 'manifests/deps.pp', 'manifests/policy.pp']",3,d6c970f4c80c23e04764f2ec6d287a0ecff92c3c,per-module-policy-refresh-stable/2023.1," tag => 'sahara',",,4,1
openstack%2Ftripleo-validations~887918,openstack/tripleo-validations,master,I7328009ad8d8526ebe69830a28b2dd8862bb0565,Removing check for nova config files on undercloud,ABANDONED,2023-07-07 08:00:46.000000000,2023-07-12 09:33:34.000000000,,"[{'_account_id': 16515}, {'_account_id': 22348}, {'_account_id': 27427}]","[{'number': 1, 'created': '2023-07-07 08:00:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-validations/commit/d9b800c37b8303e2839f63c756b5da825f0fbefa', 'message': 'Removing check for nova config files on undercloud\n\nFollowing 17.0 the undercloud no longer has nova,\nchecking for it just breaks validation.\n\nResolves: rhbz@2218422\n\nSigned-off-by: Jiri Podivin <jpodivin@redhat.com>\nChange-Id: I7328009ad8d8526ebe69830a28b2dd8862bb0565\n'}, {'number': 2, 'created': '2023-07-11 06:51:22.000000000', 'files': ['roles/undercloud_debug/defaults/main.yml'], 'web_link': 'https://opendev.org/openstack/tripleo-validations/commit/bc9f45b1fda237fd752948daf40d939ac20eea10', 'message': 'Removing check for nova config files on undercloud\n\nFollowing wallaby the undercloud no longer has nova,\nchecking for it just breaks validation.\n\nResolves: rhbz@2218422\n\nSigned-off-by: Jiri Podivin <jpodivin@redhat.com>\nChange-Id: I7328009ad8d8526ebe69830a28b2dd8862bb0565\n'}]",2,887918,bc9f45b1fda237fd752948daf40d939ac20eea10,9,3,2,32926,,,0,"Removing check for nova config files on undercloud

Following wallaby the undercloud no longer has nova,
checking for it just breaks validation.

Resolves: rhbz@2218422

Signed-off-by: Jiri Podivin <jpodivin@redhat.com>
Change-Id: I7328009ad8d8526ebe69830a28b2dd8862bb0565
",git fetch https://review.opendev.org/openstack/tripleo-validations refs/changes/18/887918/1 && git format-patch -1 --stdout FETCH_HEAD,['roles/undercloud_debug/defaults/main.yml'],1,d9b800c37b8303e2839f63c756b5da825f0fbefa,no-nova-on-undercloud,, - /var/lib/config-data/puppet-generated/nova/etc/nova/nova.conf,0,1
openstack%2Ftripleo-validations~887919,openstack/tripleo-validations,stable/wallaby,I7328009ad8d8526ebe69830a28b2dd8862bb0565,Removing check for nova config files on undercloud,ABANDONED,2023-07-07 08:01:38.000000000,2023-07-12 09:33:27.000000000,,"[{'_account_id': 16515}, {'_account_id': 22348}, {'_account_id': 27427}]","[{'number': 1, 'created': '2023-07-07 08:01:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-validations/commit/5494e69fbef2dcec27455143ce52cf94d732078c', 'message': 'Removing check for nova config files on undercloud\n\nFollowing 17.0 the undercloud no longer has nova,\nchecking for it just breaks validation.\n\nResolves: rhbz@2218422\n\nSigned-off-by: Jiri Podivin <jpodivin@redhat.com>\nChange-Id: I7328009ad8d8526ebe69830a28b2dd8862bb0565\n(cherry picked from commit d9b800c37b8303e2839f63c756b5da825f0fbefa)\n'}, {'number': 2, 'created': '2023-07-07 08:04:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-validations/commit/5d090f5bb314faff016fdf790be515b7956d9999', 'message': 'Removing check for nova config files on undercloud\n\nFollowing 17.0 the undercloud no longer has nova,\nchecking for it just breaks validation.\n\nResolves: rhbz#2218422\n\nSigned-off-by: Jiri Podivin <jpodivin@redhat.com>\nChange-Id: I7328009ad8d8526ebe69830a28b2dd8862bb0565\n(cherry picked from commit d9b800c37b8303e2839f63c756b5da825f0fbefa)\n'}, {'number': 3, 'created': '2023-07-11 06:57:01.000000000', 'files': ['roles/undercloud_debug/defaults/main.yml'], 'web_link': 'https://opendev.org/openstack/tripleo-validations/commit/347e5aaea2b6e6d9bed348d0b1d5fec5d134727e', 'message': 'Removing check for nova config files on undercloud\n\nFollowing wallaby the undercloud no longer has nova,\nchecking for it just breaks validation.\n\nResolves: rhbz#2218422\n\nSigned-off-by: Jiri Podivin <jpodivin@redhat.com>\nChange-Id: I7328009ad8d8526ebe69830a28b2dd8862bb0565\n'}]",12,887919,347e5aaea2b6e6d9bed348d0b1d5fec5d134727e,8,3,3,32926,,,0,"Removing check for nova config files on undercloud

Following wallaby the undercloud no longer has nova,
checking for it just breaks validation.

Resolves: rhbz#2218422

Signed-off-by: Jiri Podivin <jpodivin@redhat.com>
Change-Id: I7328009ad8d8526ebe69830a28b2dd8862bb0565
",git fetch https://review.opendev.org/openstack/tripleo-validations refs/changes/19/887919/1 && git format-patch -1 --stdout FETCH_HEAD,['roles/undercloud_debug/defaults/main.yml'],1,5494e69fbef2dcec27455143ce52cf94d732078c,,, - /var/lib/config-data/puppet-generated/nova/etc/nova/nova.conf,0,1
openstack%2Fpuppet-keystone~886922,openstack/puppet-keystone,master,I80117d1c7ab1bd9642a6c3d416c6683ae024894a,Add per module policy service refresh,MERGED,2023-06-25 22:05:07.000000000,2023-07-12 09:27:40.000000000,2023-07-12 09:27:40.000000000,"[{'_account_id': 9816}, {'_account_id': 14985}, {'_account_id': 22348}, {'_account_id': 32029}]","[{'number': 1, 'created': '2023-06-25 22:05:07.000000000', 'files': ['spec/classes/keystone_policy_spec.rb', 'manifests/deps.pp', 'manifests/policy.pp'], 'web_link': 'https://opendev.org/openstack/puppet-keystone/commit/9fee3031a3f7bcb3427d2570cca5f150d9068db5', 'message': 'Add per module policy service refresh\n\nUpdating the policies for this project should only\nrefresh the services that reads it.\n\nChange-Id: I80117d1c7ab1bd9642a6c3d416c6683ae024894a\n'}]",6,886922,9fee3031a3f7bcb3427d2570cca5f150d9068db5,21,4,1,16137,,,0,"Add per module policy service refresh

Updating the policies for this project should only
refresh the services that reads it.

Change-Id: I80117d1c7ab1bd9642a6c3d416c6683ae024894a
",git fetch https://review.opendev.org/openstack/puppet-keystone refs/changes/22/886922/1 && git format-patch -1 --stdout FETCH_HEAD,"['spec/classes/keystone_policy_spec.rb', 'manifests/deps.pp', 'manifests/policy.pp']",3,9fee3031a3f7bcb3427d2570cca5f150d9068db5,per-module-policy-refresh," tag => 'keystone',",,4,1
openstack%2Fpuppet-nova~885748,openstack/puppet-nova,stable/zed,I41783e8697e3d9d43f2ca5c5d91cb91a74917aea,Fix restart of modular libvirt daemons after config change,MERGED,2023-06-09 12:01:00.000000000,2023-07-12 09:25:26.000000000,2023-07-12 09:25:26.000000000,"[{'_account_id': 9816}, {'_account_id': 14985}, {'_account_id': 22348}]","[{'number': 1, 'created': '2023-06-09 12:01:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-nova/commit/5b3b8ec760b7f16a89c24afa4550673375ed7758', 'message': ""Fix restart of modular libvirt daemons after config change\n\nThis fixes the regression caused by [1]. A socket can't be restarted\nif the associated service is already started, so we should restart\nthe service instead of the socket.\n\n[1] ef8a070e853f88b8a7fde4eba0f9cd8db109d893\n\nChange-Id: I41783e8697e3d9d43f2ca5c5d91cb91a74917aea\n(cherry picked from commit 4161c48f2ce9e4c6c4b8556710cb26855dce1b48)\n(cherry picked from commit 56aeeb0365c9a6e74a51353eefd7dd4ecfc83f19)\n""}, {'number': 2, 'created': '2023-06-21 08:14:50.000000000', 'files': ['manifests/compute/libvirt/services.pp', 'manifests/params.pp', 'manifests/deps.pp'], 'web_link': 'https://opendev.org/openstack/puppet-nova/commit/ac4d1e1717b2290ea8a82f311a2f9052d9f62c94', 'message': ""Fix restart of modular libvirt daemons after config change\n\nThis fixes the regression caused by [1]. A socket can't be restarted\nif the associated service is already started, so we should restart\nthe service instead of the socket.\n\n[1] ef8a070e853f88b8a7fde4eba0f9cd8db109d893\n\nChange-Id: I41783e8697e3d9d43f2ca5c5d91cb91a74917aea\n(cherry picked from commit 4161c48f2ce9e4c6c4b8556710cb26855dce1b48)\n(cherry picked from commit 56aeeb0365c9a6e74a51353eefd7dd4ecfc83f19)\n""}]",4,885748,ac4d1e1717b2290ea8a82f311a2f9052d9f62c94,21,3,2,16137,,,0,"Fix restart of modular libvirt daemons after config change

This fixes the regression caused by [1]. A socket can't be restarted
if the associated service is already started, so we should restart
the service instead of the socket.

[1] ef8a070e853f88b8a7fde4eba0f9cd8db109d893

Change-Id: I41783e8697e3d9d43f2ca5c5d91cb91a74917aea
(cherry picked from commit 4161c48f2ce9e4c6c4b8556710cb26855dce1b48)
(cherry picked from commit 56aeeb0365c9a6e74a51353eefd7dd4ecfc83f19)
",git fetch https://review.opendev.org/openstack/puppet-nova refs/changes/48/885748/1 && git format-patch -1 --stdout FETCH_HEAD,"['manifests/compute/libvirt/services.pp', 'manifests/params.pp', 'manifests/deps.pp']",3,5b3b8ec760b7f16a89c24afa4550673375ed7758,, -> Exec<| tag == 'libvirt-service'|>,,83,20
openstack%2Fpuppet-ironic~887870,openstack/puppet-ironic,stable/2023.1,I9020ae48dc0e6b91c069fa56fc05daaed2494d97,Fix missing dependency about policy config,MERGED,2023-07-06 19:16:32.000000000,2023-07-12 09:17:37.000000000,2023-07-12 09:17:37.000000000,"[{'_account_id': 9816}, {'_account_id': 14985}, {'_account_id': 22348}]","[{'number': 1, 'created': '2023-07-06 19:16:32.000000000', 'files': ['manifests/deps.pp'], 'web_link': 'https://opendev.org/openstack/puppet-ironic/commit/4b02e17738d5ef3e190617d500686dfda8320243', 'message': 'Fix missing dependency about policy config\n\nChange-Id: I9020ae48dc0e6b91c069fa56fc05daaed2494d97\n(cherry picked from commit b341ddf504c0c12280be0832c7085efecd66c9b7)\n'}]",0,887870,4b02e17738d5ef3e190617d500686dfda8320243,7,3,1,16137,,,0,"Fix missing dependency about policy config

Change-Id: I9020ae48dc0e6b91c069fa56fc05daaed2494d97
(cherry picked from commit b341ddf504c0c12280be0832c7085efecd66c9b7)
",git fetch https://review.opendev.org/openstack/puppet-ironic refs/changes/70/887870/1 && git format-patch -1 --stdout FETCH_HEAD,['manifests/deps.pp'],1,4b02e17738d5ef3e190617d500686dfda8320243,, # policy config should occur in the config block also. Anchor['ironic::config::begin'] -> Openstacklib::Policy<||> ~> Anchor['ironic::config::end'] Anchor['ironic-inspector::config::begin'] -> Openstacklib::Policy<||> ~> Anchor['ironic-inspector::config::end'] ,,9,0
openstack%2Fpuppet-designate~887820,openstack/puppet-designate,stable/2023.1,Ie848a4ead3c493f01bf941e57741616d4c4cda47,Add per module policy service refresh,MERGED,2023-07-06 19:14:12.000000000,2023-07-12 09:12:40.000000000,2023-07-12 09:12:40.000000000,"[{'_account_id': 9816}, {'_account_id': 14985}, {'_account_id': 22348}]","[{'number': 1, 'created': '2023-07-06 19:14:12.000000000', 'files': ['spec/classes/designate_policy_spec.rb', 'manifests/deps.pp', 'manifests/policy.pp'], 'web_link': 'https://opendev.org/openstack/puppet-designate/commit/90b0d06326c49858877668be577ba85fc561a639', 'message': 'Add per module policy service refresh\n\nUpdating the policies for this project should only\nrefresh the services that reads it.\n\nChange-Id: Ie848a4ead3c493f01bf941e57741616d4c4cda47\n(cherry picked from commit 133dd8b13d22342906940beb35582e8ccfa6cf12)\n'}]",0,887820,90b0d06326c49858877668be577ba85fc561a639,7,3,1,16137,,,0,"Add per module policy service refresh

Updating the policies for this project should only
refresh the services that reads it.

Change-Id: Ie848a4ead3c493f01bf941e57741616d4c4cda47
(cherry picked from commit 133dd8b13d22342906940beb35582e8ccfa6cf12)
",git fetch https://review.opendev.org/openstack/puppet-designate refs/changes/20/887820/1 && git format-patch -1 --stdout FETCH_HEAD,"['spec/classes/designate_policy_spec.rb', 'manifests/deps.pp', 'manifests/policy.pp']",3,90b0d06326c49858877668be577ba85fc561a639,per-module-policy-refresh-stable/2023.1," tag => 'designate',",,4,1
openstack%2Fpuppet-mistral~887825,openstack/puppet-mistral,stable/2023.1,I5a30077b83dacc901bbad38ecf58095780a7233d,Add per module policy service refresh,MERGED,2023-07-06 19:15:17.000000000,2023-07-12 09:05:48.000000000,2023-07-12 09:05:48.000000000,"[{'_account_id': 9816}, {'_account_id': 14985}, {'_account_id': 22348}]","[{'number': 1, 'created': '2023-07-06 19:15:17.000000000', 'files': ['spec/classes/mistral_policy_spec.rb', 'manifests/deps.pp', 'manifests/policy.pp'], 'web_link': 'https://opendev.org/openstack/puppet-mistral/commit/5dfb8046bcb053ea371962a5f10c6a5a507bd350', 'message': 'Add per module policy service refresh\n\nUpdating the policies for this project should only\nrefresh the services that reads it.\n\nChange-Id: I5a30077b83dacc901bbad38ecf58095780a7233d\n(cherry picked from commit d6f55e497f1d455c357c32cbc3a879addb778739)\n'}]",0,887825,5dfb8046bcb053ea371962a5f10c6a5a507bd350,7,3,1,16137,,,0,"Add per module policy service refresh

Updating the policies for this project should only
refresh the services that reads it.

Change-Id: I5a30077b83dacc901bbad38ecf58095780a7233d
(cherry picked from commit d6f55e497f1d455c357c32cbc3a879addb778739)
",git fetch https://review.opendev.org/openstack/puppet-mistral refs/changes/25/887825/1 && git format-patch -1 --stdout FETCH_HEAD,"['spec/classes/mistral_policy_spec.rb', 'manifests/deps.pp', 'manifests/policy.pp']",3,5dfb8046bcb053ea371962a5f10c6a5a507bd350,per-module-policy-refresh-stable/2023.1," tag => 'mistral',",,4,1
openstack%2Ftempest~858885,openstack/tempest,master,Ie600837f66edfaa215d405c753108c49fbca3da4,Adds test for resize server swap to 0,NEW,2022-09-22 10:48:53.000000000,2023-07-12 09:00:22.000000000,,"[{'_account_id': 4690}, {'_account_id': 7166}, {'_account_id': 8367}, {'_account_id': 8556}, {'_account_id': 11604}, {'_account_id': 19234}, {'_account_id': 20733}, {'_account_id': 22348}, {'_account_id': 22873}, {'_account_id': 30674}, {'_account_id': 31033}, {'_account_id': 34860}]","[{'number': 1, 'created': '2022-09-22 10:48:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/9c950b6f61012180b317ce35ff34b0eef25b0268', 'message': 'Adds test for resize server swap to 0\n\nAdded a scenario test to resize server swap\nfrom non-zero to zero\n\nRelated-Bug: #1552777\nChange-Id: Ie600837f66edfaa215d405c753108c49fbca3da4\n'}, {'number': 2, 'created': '2022-09-22 10:56:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/25721ed1abb9c78b423c16f592daf6ad80f10436', 'message': 'Adds test for resize server swap to 0\n\nAdded a scenario test to resize server swap\nfrom non-zero to zero\n\nRelated-Bug: #1552777\nChange-Id: Ie600837f66edfaa215d405c753108c49fbca3da4\n'}, {'number': 3, 'created': '2022-09-22 11:39:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/03d573490a20d5942df78760c19def0165a6aa77', 'message': 'Adds test for resize server swap to 0\n\nAdded a scenario test to resize server swap\nfrom non-zero to zero\n\nRelated-Bug: #1552777\nChange-Id: Ie600837f66edfaa215d405c753108c49fbca3da4\n'}, {'number': 4, 'created': '2022-09-22 11:46:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/74c3f372822cf99ca7ca9c4a083db63d332186d0', 'message': 'Adds test for resize server swap to 0\n\nAdded a scenario test to resize server swap\nfrom non-zero to zero\n\nRelated-Bug: #1552777\nChange-Id: Ie600837f66edfaa215d405c753108c49fbca3da4\n'}, {'number': 5, 'created': '2022-09-22 12:31:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/ac475c1d1bc005e21622fba90521f072c0af8048', 'message': 'Adds test for resize server swap to 0\n\nAdded a scenario test to resize server swap\nfrom non-zero to zero\n\nRelated-Bug: #1552777\nChange-Id: Ie600837f66edfaa215d405c753108c49fbca3da4\n'}, {'number': 6, 'created': '2022-09-26 16:02:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/5029490399ea05075d8b91901a1281674b6fdad7', 'message': 'Adds test for resize server swap to 0\n\nAdded a scenario test to resize server swap\nfrom non-zero to zero\n\nDepends-on: https://review.opendev.org/c/openstack/nova/+/857339\n\nRelated-Bug: #1552777\nChange-Id: Ie600837f66edfaa215d405c753108c49fbca3da4\n'}, {'number': 7, 'created': '2022-09-27 09:54:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/4355e035f8431cdb0a1e6567f9dec2c302e21acd', 'message': 'Adds test for resize server swap to 0\n\nAdded a scenario test to resize server swap\nfrom non-zero to zero\n\nDepends-on: https://review.opendev.org/c/openstack/nova/+/857339\nDepends-on: https://review.opendev.org/c/openstack/nova/+/859246\nDepends-on: https://review.opendev.org/c/openstack/nova/+/859247\n\nRelated-Bug: #1552777\nChange-Id: Ie600837f66edfaa215d405c753108c49fbca3da4\n'}, {'number': 8, 'created': '2022-11-02 09:33:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/67f1e145de49e72cd7d9b0783cbc87c3337a785b', 'message': 'WIP: Adds test for resize server swap to 0\n\nAdded a scenario test to resize server swap\nfrom non-zero to zero\n\nDepends-on: https://review.opendev.org/c/openstack/nova/+/857339\n\nRelated-Bug: #1552777\nChange-Id: Ie600837f66edfaa215d405c753108c49fbca3da4\n'}, {'number': 9, 'created': '2022-11-02 09:57:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/13c5da5aca8263c4d011339b1b98fd3754bba9d6', 'message': 'WIP: Adds test for resize server swap to 0\n\nAdded a scenario test to resize server swap\nfrom non-zero to zero\n\nDepends-on: https://review.opendev.org/c/openstack/nova/+/857339\n\nRelated-Bug: #1552777\nChange-Id: Ie600837f66edfaa215d405c753108c49fbca3da4\n'}, {'number': 10, 'created': '2022-11-02 10:19:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/57215d30ea8a6f7453b74a185a5d31f3a177f71a', 'message': 'WIP: Adds test for resize server swap to 0\n\nAdded a scenario test to resize server swap\nfrom non-zero to zero\n\nDepends-on: https://review.opendev.org/c/openstack/nova/+/857339\n\nRelated-Bug: #1552777\nChange-Id: Ie600837f66edfaa215d405c753108c49fbca3da4\n'}, {'number': 11, 'created': '2023-02-03 07:16:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/2dfb8cda4c678dd166702244480b168640b7c473', 'message': 'WIP: Adds test for resize server swap to 0\n\nAdded a scenario test to resize server swap\nfrom non-zero to zero\n\nDepends-on: https://review.opendev.org/c/openstack/nova/+/857339\n\nRelated-Bug: #1552777\nChange-Id: Ie600837f66edfaa215d405c753108c49fbca3da4\n'}, {'number': 12, 'created': '2023-02-03 07:21:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/eb85bf88ba8b345fc0065bf1b7cf83866d066f01', 'message': 'WIP: Adds test for resize server swap to 0\n\nAdded a scenario test to resize server swap\nfrom non-zero to zero\n\nDepends-on: https://review.opendev.org/c/openstack/nova/+/857339\n\nRelated-Bug: #1552777\nChange-Id: Ie600837f66edfaa215d405c753108c49fbca3da4\n'}, {'number': 13, 'created': '2023-02-03 09:45:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/5cb0ae0ea5f58961c99479efd78bd11b6ecb7fa6', 'message': 'WIP: Adds test for resize server swap to 0\n\nAdded a scenario test to resize server swap\nfrom non-zero to zero\n\nDepends-on: https://review.opendev.org/c/openstack/nova/+/857339\n\nRelated-Bug: #1552777\nChange-Id: Ie600837f66edfaa215d405c753108c49fbca3da4\n'}, {'number': 14, 'created': '2023-02-21 06:01:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/d54b8d92dd6f4c5a6bec3dd6cac87cee012d5322', 'message': 'Adds test for resize server swap to 0\n\nAdded a scenario test to resize server swap\nfrom non-zero to zero with hard reboot\n\nDepends-on: https://review.opendev.org/c/openstack/nova/+/857339\n\nRelated-Bug: #1552777\nChange-Id: Ie600837f66edfaa215d405c753108c49fbca3da4\n'}, {'number': 15, 'created': '2023-02-23 06:31:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/251d6268325a4b5917ed27a2c1186d557acd4f51', 'message': 'Adds test for resize server swap to 0\n\nAdded tests to resize server swap\nfrom non-zero to zero with hard reboot\n\nDepends-on: https://review.opendev.org/c/openstack/nova/+/857339\n\nRelated-Bug: #1552777\nChange-Id: Ie600837f66edfaa215d405c753108c49fbca3da4\n'}, {'number': 16, 'created': '2023-03-30 10:33:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/d72a7aa4d68210ef41c38e54bf9beed31e569101', 'message': 'Adds test for resize server swap to 0\n\nAdded tests to resize server swap\nfrom non-zero to zero with hard reboot\n\nDepends-on: https://review.opendev.org/c/openstack/nova/+/857339\n\nRelated-Bug: #1552777\nChange-Id: Ie600837f66edfaa215d405c753108c49fbca3da4\n'}, {'number': 17, 'created': '2023-05-03 08:24:00.000000000', 'files': ['tempest/api/compute/admin/test_create_server.py', 'tempest/common/utils/linux/remote_client.py'], 'web_link': 'https://opendev.org/openstack/tempest/commit/f7b96b5a4f49772ec0ae641adfd166febaf41fcb', 'message': 'Adds test for resize server swap to 0\n\nAdded tests to resize server swap\nfrom non-zero to zero with hard reboot\n\nDepends-on: https://review.opendev.org/c/openstack/nova/+/857339\n\nRelated-Bug: #1552777\nChange-Id: Ie600837f66edfaa215d405c753108c49fbca3da4\n'}]",27,858885,f7b96b5a4f49772ec0ae641adfd166febaf41fcb,54,12,17,34860,,,0,"Adds test for resize server swap to 0

Added tests to resize server swap
from non-zero to zero with hard reboot

Depends-on: https://review.opendev.org/c/openstack/nova/+/857339

Related-Bug: #1552777
Change-Id: Ie600837f66edfaa215d405c753108c49fbca3da4
",git fetch https://review.opendev.org/openstack/tempest refs/changes/85/858885/1 && git format-patch -1 --stdout FETCH_HEAD,"['tempest/scenario/manager.py', 'tempest/scenario/test_server_basic_ops.py']",2,9c950b6f61012180b317ce35ff34b0eef25b0268,bug/1552777," self.flavors_client = self.os_adm.flavors_client def verify_have_swap(self): cmd = 'blkid' data = self.ssh_client.exec_command(cmd) devs = [dev for dev in data.splitlines() if 'TYPE=""swap""' in dev] return True if len(devs) > 0 else False def test_resize_server_shrink_swap(self): """""" Test if server can be resized to swap zero """""" keypair = self.create_keypair() security_group = self.create_security_group() flavor1 = self.flavors_client.create_flavor(**{ 'ram': 1024, 'vcpus': 1, 'disk': 1, 'name': 'flavor1-' + 'extra-%s' % data_utils.rand_int_id(), 'swap': 1024 })['flavor'] flavor2 = self.flavors_client.create_flavor(**{ 'ram': 1024, 'vcpus': 1, 'disk': 1, 'name': 'flavor2-' + 'extra-%s' % data_utils.rand_int_id(), 'swap': 0 })['flavor'] self.instance = self.create_server( key_name=keypair['name'], security_groups=[{'name': security_group['name']}], flavor=flavor1['id'], wait_until='ACTIVE') self.verify_ssh(keypair) self.assertTrue(self.verify_have_swap()) self.resize_and_confim_resize_server(self.instance['id'], flavor2['id']) self.assertFalse(self.verify_have_swap())",,47,0
openstack%2Fpuppet-barbican~887814,openstack/puppet-barbican,stable/2023.1,I42153ec891feb569a9614166104be5382d893f96,Add per module policy service refresh,MERGED,2023-07-06 19:12:28.000000000,2023-07-12 08:59:24.000000000,2023-07-12 08:59:24.000000000,"[{'_account_id': 9816}, {'_account_id': 14985}, {'_account_id': 22348}]","[{'number': 1, 'created': '2023-07-06 19:12:28.000000000', 'files': ['spec/classes/barbican_policy_spec.rb', 'manifests/deps.pp', 'manifests/policy.pp'], 'web_link': 'https://opendev.org/openstack/puppet-barbican/commit/dbd8e47e31b25a0bf2422f3d523468a45549b0c3', 'message': 'Add per module policy service refresh\n\nUpdating the policies for this project should only\nrefresh the services that reads it.\n\nChange-Id: I42153ec891feb569a9614166104be5382d893f96\n(cherry picked from commit c38323518bbff0395b16c00a1a4640aba2231cef)\n'}]",0,887814,dbd8e47e31b25a0bf2422f3d523468a45549b0c3,7,3,1,16137,,,0,"Add per module policy service refresh

Updating the policies for this project should only
refresh the services that reads it.

Change-Id: I42153ec891feb569a9614166104be5382d893f96
(cherry picked from commit c38323518bbff0395b16c00a1a4640aba2231cef)
",git fetch https://review.opendev.org/openstack/puppet-barbican refs/changes/14/887814/1 && git format-patch -1 --stdout FETCH_HEAD,"['spec/classes/barbican_policy_spec.rb', 'manifests/deps.pp', 'manifests/policy.pp']",3,dbd8e47e31b25a0bf2422f3d523468a45549b0c3,per-module-policy-refresh-stable/2023.1," tag => 'barbican',",,4,1
openstack%2Fpuppet-ec2api~887821,openstack/puppet-ec2api,stable/2023.1,I306233bb64b1070f722d7897063a700050be0058,Add per module policy service refresh,MERGED,2023-07-06 19:14:24.000000000,2023-07-12 08:58:21.000000000,2023-07-12 08:58:21.000000000,"[{'_account_id': 9816}, {'_account_id': 14985}, {'_account_id': 22348}]","[{'number': 1, 'created': '2023-07-06 19:14:24.000000000', 'files': ['spec/classes/ec2api_policy_spec.rb', 'manifests/deps.pp', 'manifests/policy.pp'], 'web_link': 'https://opendev.org/openstack/puppet-ec2api/commit/95e2bae8f59ece79d6e85c14c2481f0a1267328e', 'message': 'Add per module policy service refresh\n\nUpdating the policies for this project should only\nrefresh the services that reads it.\n\nChange-Id: I306233bb64b1070f722d7897063a700050be0058\n(cherry picked from commit 8d522ae1f264364dd2fac3a16b92390ba69de08e)\n'}]",0,887821,95e2bae8f59ece79d6e85c14c2481f0a1267328e,7,3,1,16137,,,0,"Add per module policy service refresh

Updating the policies for this project should only
refresh the services that reads it.

Change-Id: I306233bb64b1070f722d7897063a700050be0058
(cherry picked from commit 8d522ae1f264364dd2fac3a16b92390ba69de08e)
",git fetch https://review.opendev.org/openstack/puppet-ec2api refs/changes/21/887821/1 && git format-patch -1 --stdout FETCH_HEAD,"['spec/classes/ec2api_policy_spec.rb', 'manifests/deps.pp', 'manifests/policy.pp']",3,95e2bae8f59ece79d6e85c14c2481f0a1267328e,per-module-policy-refresh-stable/2023.1," tag => 'ec2api',",,4,1
openstack%2Fpuppet-zaqar~887872,openstack/puppet-zaqar,stable/2023.1,Id77056322ad610006ac0f216870d679b250ab702,Add per module policy service refresh,MERGED,2023-07-06 19:16:59.000000000,2023-07-12 08:57:53.000000000,2023-07-12 08:57:53.000000000,"[{'_account_id': 9816}, {'_account_id': 14985}, {'_account_id': 22348}]","[{'number': 1, 'created': '2023-07-06 19:16:59.000000000', 'files': ['spec/classes/zaqar_policy_spec.rb', 'manifests/deps.pp', 'manifests/policy.pp'], 'web_link': 'https://opendev.org/openstack/puppet-zaqar/commit/f1606e475bed920bee89bfc358c278500961033e', 'message': 'Add per module policy service refresh\n\nUpdating the policies for this project should only\nrefresh the services that reads it.\n\nChange-Id: Id77056322ad610006ac0f216870d679b250ab702\n(cherry picked from commit 7d5258c9a9182e7789d25e6524dfbad4f32d7f26)\n'}]",0,887872,f1606e475bed920bee89bfc358c278500961033e,7,3,1,16137,,,0,"Add per module policy service refresh

Updating the policies for this project should only
refresh the services that reads it.

Change-Id: Id77056322ad610006ac0f216870d679b250ab702
(cherry picked from commit 7d5258c9a9182e7789d25e6524dfbad4f32d7f26)
",git fetch https://review.opendev.org/openstack/puppet-zaqar refs/changes/72/887872/1 && git format-patch -1 --stdout FETCH_HEAD,"['spec/classes/zaqar_policy_spec.rb', 'manifests/deps.pp', 'manifests/policy.pp']",3,f1606e475bed920bee89bfc358c278500961033e,per-module-policy-refresh-stable/2023.1," tag => 'zaqar',",,4,1
openstack%2Fpuppet-trove~887826,openstack/puppet-trove,stable/2023.1,I4733a5d445621ff1cb270fa3be3811b531b9a7b8,Add per module policy service refresh,MERGED,2023-07-06 19:15:33.000000000,2023-07-12 08:56:58.000000000,2023-07-12 08:56:58.000000000,"[{'_account_id': 9816}, {'_account_id': 14985}, {'_account_id': 22348}]","[{'number': 1, 'created': '2023-07-06 19:15:33.000000000', 'files': ['spec/classes/trove_policy_spec.rb', 'manifests/deps.pp', 'manifests/policy.pp'], 'web_link': 'https://opendev.org/openstack/puppet-trove/commit/b5c621fbea68f44656b3da5c7457f259aa5f75ee', 'message': 'Add per module policy service refresh\n\nUpdating the policies for this project should only\nrefresh the services that reads it.\n\nChange-Id: I4733a5d445621ff1cb270fa3be3811b531b9a7b8\n(cherry picked from commit 160b0b18d173351a91e6dde051d802e0affc88a2)\n'}]",0,887826,b5c621fbea68f44656b3da5c7457f259aa5f75ee,7,3,1,16137,,,0,"Add per module policy service refresh

Updating the policies for this project should only
refresh the services that reads it.

Change-Id: I4733a5d445621ff1cb270fa3be3811b531b9a7b8
(cherry picked from commit 160b0b18d173351a91e6dde051d802e0affc88a2)
",git fetch https://review.opendev.org/openstack/puppet-trove refs/changes/26/887826/1 && git format-patch -1 --stdout FETCH_HEAD,"['spec/classes/trove_policy_spec.rb', 'manifests/deps.pp', 'manifests/policy.pp']",3,b5c621fbea68f44656b3da5c7457f259aa5f75ee,per-module-policy-refresh-stable/2023.1," tag => 'trove',",,4,1
openstack%2Fpuppet-magnum~887829,openstack/puppet-magnum,stable/2023.1,Ied6c7759af242021ed83e3c60197e74c947bf811,Add per module policy service refresh,MERGED,2023-07-06 19:16:08.000000000,2023-07-12 08:49:51.000000000,2023-07-12 08:49:51.000000000,"[{'_account_id': 9816}, {'_account_id': 14985}, {'_account_id': 22348}]","[{'number': 1, 'created': '2023-07-06 19:16:08.000000000', 'files': ['spec/classes/magnum_policy_spec.rb', 'manifests/deps.pp', 'manifests/policy.pp'], 'web_link': 'https://opendev.org/openstack/puppet-magnum/commit/93c2557cac8bd7166cc03797e734b7b4bd824d5a', 'message': 'Add per module policy service refresh\n\nUpdating the policies for this project should only\nrefresh the services that reads it.\n\nChange-Id: Ied6c7759af242021ed83e3c60197e74c947bf811\n(cherry picked from commit f42642bd61205cb8ed6968ae9cf2180eb772099a)\n'}]",0,887829,93c2557cac8bd7166cc03797e734b7b4bd824d5a,7,3,1,16137,,,0,"Add per module policy service refresh

Updating the policies for this project should only
refresh the services that reads it.

Change-Id: Ied6c7759af242021ed83e3c60197e74c947bf811
(cherry picked from commit f42642bd61205cb8ed6968ae9cf2180eb772099a)
",git fetch https://review.opendev.org/openstack/puppet-magnum refs/changes/29/887829/1 && git format-patch -1 --stdout FETCH_HEAD,"['spec/classes/magnum_policy_spec.rb', 'manifests/deps.pp', 'manifests/policy.pp']",3,93c2557cac8bd7166cc03797e734b7b4bd824d5a,per-module-policy-refresh-stable/2023.1," tag => 'magnum',",,4,1
openstack%2Fpuppet-manila~887875,openstack/puppet-manila,stable/2023.1,I2364aed9cadceaa9b71b570357975b93634f71a2,Add per module policy service refresh,MERGED,2023-07-06 19:17:31.000000000,2023-07-12 08:45:49.000000000,2023-07-12 08:45:49.000000000,"[{'_account_id': 9816}, {'_account_id': 14985}, {'_account_id': 22348}]","[{'number': 1, 'created': '2023-07-06 19:17:31.000000000', 'files': ['spec/classes/manila_policy_spec.rb', 'manifests/deps.pp', 'manifests/policy.pp'], 'web_link': 'https://opendev.org/openstack/puppet-manila/commit/56e4f87456f69b800f3abdebf9657cd6603b1aa5', 'message': 'Add per module policy service refresh\n\nUpdating the policies for this project should only\nrefresh the services that reads it.\n\nChange-Id: I2364aed9cadceaa9b71b570357975b93634f71a2\n(cherry picked from commit fd90649c82116148bd474a57544ce5a345de5ac5)\n'}]",0,887875,56e4f87456f69b800f3abdebf9657cd6603b1aa5,7,3,1,16137,,,0,"Add per module policy service refresh

Updating the policies for this project should only
refresh the services that reads it.

Change-Id: I2364aed9cadceaa9b71b570357975b93634f71a2
(cherry picked from commit fd90649c82116148bd474a57544ce5a345de5ac5)
",git fetch https://review.opendev.org/openstack/puppet-manila refs/changes/75/887875/1 && git format-patch -1 --stdout FETCH_HEAD,"['spec/classes/manila_policy_spec.rb', 'manifests/deps.pp', 'manifests/policy.pp']",3,56e4f87456f69b800f3abdebf9657cd6603b1aa5,per-module-policy-refresh-stable/2023.1," tag => 'manila',",,4,1
openstack%2Ftacker-specs~878823,openstack/tacker-specs,master,Idddaa1f3c95f057736c8d2da24d292e8be1f1150,Kubernetes Custom Resources for Cluster API,MERGED,2023-03-29 09:23:42.000000000,2023-07-12 08:38:11.000000000,2023-07-12 08:38:11.000000000,"[{'_account_id': 17255}, {'_account_id': 22348}, {'_account_id': 25701}, {'_account_id': 31857}, {'_account_id': 32102}, {'_account_id': 33453}, {'_account_id': 35240}]","[{'number': 1, 'created': '2023-03-29 09:23:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tacker-specs/commit/d7ec73e571dfabf326ce1a4e44f5523517138b03', 'message': 'Kubernetes Custom Resources for Cluster API\n\nThis specification describes the enhancement of Kubernetes infra-driver\nin Tacker to support LCM operation of Kubernetes Custom Resources (CR)\nas CNF, using Kubernetes Cluster API (CAPI) as an example CR. The scope\nof the present document includes instantiation, termination, scale and\nupdate of CNFs including CRs for CAPI.\n\nChange-Id: Idddaa1f3c95f057736c8d2da24d292e8be1f1150\n'}, {'number': 2, 'created': '2023-07-10 02:10:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tacker-specs/commit/e26b7bb1c76a12fba33890b420fd18b68ba94252', 'message': 'Kubernetes Custom Resources for Cluster API\n\nThis specification describes the enhancement of Kubernetes infra-driver\nin Tacker to support LCM operation of Kubernetes Custom Resources (CR)\nas CNF, using Kubernetes Cluster API (CAPI) as an example CR. The scope\nof the present document includes instantiation, termination, scale and\nupdate of CNFs including CRs for CAPI.\n\nImplements: blueprint support-k8s-cr\nChange-Id: Idddaa1f3c95f057736c8d2da24d292e8be1f1150\n'}, {'number': 3, 'created': '2023-07-10 02:48:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tacker-specs/commit/4e6265bf28926bbc76300a10860fb32bb0d96d74', 'message': 'Kubernetes Custom Resources for Cluster API\n\nThis specification describes the enhancement of Kubernetes infra-driver\nin Tacker to support LCM operation of Kubernetes Custom Resources (CR)\nas CNF, using Kubernetes Cluster API (CAPI) as an example CR. The scope\nof the present document includes instantiation, termination, scale and\nupdate of CNFs including CRs for CAPI.\n\nImplements: blueprint support-k8s-cr\nChange-Id: Idddaa1f3c95f057736c8d2da24d292e8be1f1150\n'}, {'number': 4, 'created': '2023-07-10 08:33:27.000000000', 'files': ['specs/2023.2/support-k8s-cr.rst'], 'web_link': 'https://opendev.org/openstack/tacker-specs/commit/13fe5c7dfe0e87ac99175b4e2b1216680277cc1d', 'message': 'Kubernetes Custom Resources for Cluster API\n\nThis specification describes the enhancement of Kubernetes infra-driver\nin Tacker to support LCM operation of Kubernetes Custom Resources (CR)\nas CNF, using Kubernetes Cluster API (CAPI) as an example CR. The scope\nof the present document includes instantiation, termination, scale and\nupdate of CNFs including CRs for CAPI.\n\nImplements: blueprint support-k8s-cr\nChange-Id: Idddaa1f3c95f057736c8d2da24d292e8be1f1150\n'}]",40,878823,13fe5c7dfe0e87ac99175b4e2b1216680277cc1d,16,7,4,33455,,,0,"Kubernetes Custom Resources for Cluster API

This specification describes the enhancement of Kubernetes infra-driver
in Tacker to support LCM operation of Kubernetes Custom Resources (CR)
as CNF, using Kubernetes Cluster API (CAPI) as an example CR. The scope
of the present document includes instantiation, termination, scale and
update of CNFs including CRs for CAPI.

Implements: blueprint support-k8s-cr
Change-Id: Idddaa1f3c95f057736c8d2da24d292e8be1f1150
",git fetch https://review.opendev.org/openstack/tacker-specs refs/changes/23/878823/1 && git format-patch -1 --stdout FETCH_HEAD,['specs/2023.2/support-k8s-cr.rst'],1,d7ec73e571dfabf326ce1a4e44f5523517138b03,bp/support-k8s-cr,".. This work is licensed under a Creative Commons Attribution 3.0 Unported License. http://creativecommons.org/licenses/by/3.0/legalcode ====================================================================== Support Kubernetes Custom Resources for Cluster API Provider OpenStack ====================================================================== This specification describes the enhancement of Kubernetes infra-driver in Tacker to support LCM operation of Kubernetes Custom Resources (CR) as CNF, using Kubernetes Cluster API (CAPI) [#capi]_ as an example CR. The scope of the present document includes instantiation, termination, scale and update of CNFs including CRs for CAPI. https://blueprints.launchpad.net/tacker/+spec/support-k8s-cr Problem description =================== Tacker only allows specific types (a.k.a., kind) of Kubernetes resources and CR, which is user-defined kinds complying with the Kubernetes API, is not included yet. However, CRs are already widely used to instruct Kubernetes to manage more than just containers. For example, CAPI enables users to manage Kubernetes clusters as Kubernetes resources by defining some CRs, such as Cluster, Machine, etc, corresponding to the components composing Kubernetes clusters. By supporting CAPI CRs, Tacker can create Kubernetes Cluster with Kubernetes infra-driver, which is much simpler than existing Tacker's management drivers for similar use cases [#tacker_k8s_cluster1]_, [#tacker_k8s_cluster2]_. As described above, the limited supported resources in Tacker may prevent a better implementation. In this sense, adding base classes and utilities for handling CRs in Kubernetes infra-driver helps other developers to extend the supported CRs in the future, such as some prerequisites (e.g., drivers, device plugins, etc) to use GPU from containers [#nvidia_gpu]_. Proposed change =============== This spec proposes to support CRs of CAPI, including enhancement of the Kubernetes infra-driver to handle LCM operations for CRs. CAPI is a set of CRs to bring declarative, Kubernetes-style APIs to cluster creation, configuration, and management. Using CAPI as an example of CNF consisting of CRs, creating the basic utilities and classes to add more CRs in the future. For this to happen, the following items have to be implemented. * Instantiation of CNF including CRs (using Cluster API as an example) * Termination of CNF including CRs (using Cluster API as an example) * Scaling of CNF including CRs (using Cluster API as an example) * Updating of CNF including CRs (using Cluster API as an example) * Sample VNF (i.e., CNF) packages with manifests of CRs for CAPI * Updating user document Kubernetes Custom Resources --------------------------- Custom resources are extensions of the Kubernetes API. This feature allows users to define new resource types, beyond the built-in resources of Kubernetes, such as Pods, Services, and Deployments. Once a custom resource is installed, users can create and access its objects using Kubernetes APIs, just as they do for built-in resources. Some examples for popular custom resources for projects are: * Cluster API: Cluster, MachineDeployment, MachineSet, Machine, etc * Istio: irtualService, DestinationRule, and Gateway. * Prometheus: ServiceMonitor * Elasticsearch: Elasticsearch * Kubernetes Operators: Kubernetes Operators are a way to automate the deployment and management of complex applications on Kubernetes. Examples include the Nvidia GPU operator, the PostgreSQL operator, and the MongoDB operator. In general, to use custom resources, users have to install CR Definition (CRD) and CR controller to Kubernetes cluster. Cluster API ----------- We picked CAPI as the first CR Tacker support because Tacker already covered a similar use case. Tacker has supported deploying a Kubernetes cluster by using management drivers. CAPI enables users to manage Kubernetes clusters as Kubernetes resources by defining some CRs, such as Cluster, Machine, etc, corresponding to the components composing Kubernetes clusters. Therefore, by supporting CAPI CRs we can create Kubernetes Cluster with Kubernetes infra-driver. The following are the characteristics of CAPI: #. Management Cluster and Workload Cluster CAPI is also a Kubernetes resource and must be deployed on a cluster. Therefore, when using CAPI, there are two types of clusters: clusters where CAPI is installed and clusters that are created by CAPI. In CAPI, the former is called a Management Cluster and the latter a Workload Cluster. #. Providers CAPI consists of a number of CR called Providers and their controllers. Among them, the infrastructure provider is particularly unique. There are many providers and each provider supports different cloud platforms. For example, CAPI Provider OpenStack (CAPO) is used to build a Kubernetes cluster on OpenStack. The role of an infrastructure provider is to prepare nodes (in most case, creating VMs) for Kubernetes clusters and install/configure Kubernetes components (e.g., etcd, kube-api server) on those nodes. This figure shows the overview of the operation of CAPI. .. uml:: @startuml actor User package manifest component ManagementCluster { component ""ClusterAPI"" as capi component ""KubernetesAPI"" as kapi1 } component Infrastructure { component WorkloadCluster { component ""KubernetesAPI"" as kapi2 } } User --> manifest: 2. create User -> kapi1: 3. apply manifest kapi1->capi capi -> WorkloadCluster: 4. create User -> ManagementCluster: 1. create @enduml Officially supported providers (i.e., cloud platforms) [#capi_providers]_ are: * AWS * Azure * Azure Stack HCI * BYOH * CloudStack * CoxEdge * DigitalOcean * Equinix Metal (formerly Packet) * GCP * Hetzner * IBM Cloud * KubeKey * KubeVirt * MAAS * Metal3 * Microvm * Nested * Nutanix * OCI * OpenStack * Outscale * Sidero * Tinkerbell * vcluster * Virtink * VMware Cloud Director * vSphere Among them, we choose OpenStack (i.e., CAPO) for the first step. This is simply because it is easier to test and matches the previous use cases supported by management drivers. Enhancement of Kubernetes Infra-driver for CAPI ----------------------------------------------- In this section, we describe the enhancement of Kubernetes Infra-driver to create Kubernetes clusters with CAPI. As described in the previous section, we need to create two kinds of Kubernetes clusters: i) Management Cluster and ii) Workload Cluster. We first explain the steps to create those two Kubernetes clusters, then we also describe scaling and changing current VNF package operations of the Workload Cluster. Creating Management Cluster ``````````````````````````` This figure shows an overview of creating Management Cluster with Kubernetes infra-driver supporting CRs of CAPI. As CAPI itself consist of Kubernetes resources, creating Management Cluster can be the same operation as Instantiate CNF. Terminate CNF is omitted as it is almost the same as the Instantiate CNF. Also, LCM operations other than instantiation/termination are out of the scope of this specification. #. Request create CNF Users request create CNF with a VNF package that contains CAPI CRDs. #. Request instantiate VNF Users request instantiate VNF with an instantiate parameters. #. Call Kubernetes API Kubernetes infra-driver calls Kubernetes APIs to create a set of CRs of CAPI as a CNF. #. Create a set of CRs for CAPI Kubernetes Control Plane creates a set of CRs according to the contents of the VNF package. Upon CRs successfully deployed, CAPI is available on Kubernetes VIM (i.e., Kubernetes VIM becomes Management Cluster). .. uml:: @startuml frame ""python-tackerclient"" { component ""tacker-client"" as client { package ""VNF Package"" as vnfpkg { file ""VNFD"" as vnfd file ""CNF (Cluster API)\nDefinition"" as cnfd } file ""Instantiate\nparameters"" as inst_param } } frame ""tacker"" { component ""tacker-server"" { component ""server"" as serv } component ""tacker-conductor"" { component ""conductor"" as cond component ""Kubernetes\ninfra-driver"" as infra } } frame ""Kubernetes Cluster"" as k8s { node ""Control Plane"" as k8s_m { node ""Cluster API"" as capi } node ""Worker"" as k8s_w } '# Relationships vnfpkg --> serv: 1. Request\n create VNF inst_param --> serv: 2. Request\n instantiate VNF serv --> cond cond --> infra infra -right-> k8s_m: 3. Call Kubernetes\n API k8s_m -> capi: 4. Create a CRs\n for Cluster API capi -[hidden]-> k8s_w @enduml Creating Workload Cluster ````````````````````````` This figure shows an overview of creating Workload Cluster with Kubernetes infra-driver supporting CRs of CAPO. As CAPI defines Kubernetes cluster as Kubernetes resources, creating Workload Cluster corresponds can be the same operation as Instantiate CNF. Terminate CNF is omitted as it is almost the same as the Instantiate CNF. #. Request create VNF Users request create VNF with a VNF package that contains CAPI CRDs. #. Request instantiate VNF Users request instantiate VNF with an instantiate parameters. #. Call Kubernetes API Kubernetes infra-driver calls Kubernetes APIs to create a set of CRs of CAPI as a CNF. #. Create a Cluster resource Kubernetes Control Plane creates a Cluster resource. In general, several sub resources are also created which are omitted in the figure. #. Create a Workload Cluster CAPI creates Workload Cluster according to the contents of VNF Package. #. Execute the management driver Kubernetes infra-driver executes management driver contained in VNF Package. #. Get credentials for Workload Cluster The management driver obtains credentials for Workload Cluster which is automatically stored as Secret on Management Cluster by CAPI. #. Send the credentials The management driver sends obtained credentials to the web server according to the pre-configured URL. The web server must be managed by users to receive credentials. .. note:: In order to use the Workload Cluster as VIM, users have to register VIM with the credentials sent by the management driver. .. uml:: @startuml component ""Web Server"" as w frame ""python-tackerclient"" { component ""tacker-client"" as client { package ""VNF Package"" as vnfpkg { file ""VNFD"" as vnfd file ""CNF (k8s Cluster)\nDefinition"" as cnfd file ""Scripts for\n Management Driver\n(Credentials Sender)"" as mgmtd } file ""Instantiate\nparameters"" as inst_param } } vnfd -[hidden]> cnfd cnfd -[hidden]> mgmtd frame ""tacker"" { component ""tacker-server"" { component ""server"" as serv } component ""tacker-conductor"" { component ""conductor"" as cond component ""Kubernetes\ninfra-driver"" as infra } } frame ""Management Cluster"" as mgmt { node ""Control Plane"" as k8s_m_m { node ""Cluster API"" as capi } node ""Worker"" as k8s_m_w { node ""Cluster"" as cluster } } component ""Management Driver\n(Credentials Sender)"" as mgmtdi cloud ""Hardware Resources"" as hw_w { frame ""Workload Cluster"" as wkld { node ""Control Plane"" as k8s_w_m node ""Worker"" as k8s_w_w { } } } '# Relationships vnfpkg --> serv: 1. Request\n create VNF inst_param --> serv: 2. Request\n instantiate VNF serv --> cond cond --> infra infra -right-> k8s_m_m: 3. Call Kubernetes\n API capi --> cluster: 4. Create a Cluster Resource cluster --> wkld: 5. Create a Workload Cluster k8s_w_m -[hidden]-> k8s_w_w infra -right-> mgmtdi: 6. Execute management driver mgmtdi <-- mgmt: 7. Get credentials for Workload Cluster mgmtdi -> w: 8. Send credentials @enduml Scale Workload Cluster `````````````````````` This figure shows an overview of scaling Workload Cluster with Kubernetes infra-driver supporting CRs of CAPO. #. Request scale VNF Users request scale VNF #. Call Kubernetes API Kubernetes infra-driver calls Kubernetes APIs to change a parameter that represents the number of worker nodes in the Workload Cluster which must be ``replicas``. #. Change a parameter for the number of worker nodes CAPI in Kubernetes Control Plane changes the parameter for the number of worker nodes according to the API calls. #. Change the number of worker nodes CAPI changes the number of worker nodes according to the Cluster resource. .. uml:: @startuml frame ""python-tackerclient"" { component ""tacker-client"" as client { } } frame ""tacker"" { component ""tacker-server"" { component ""server"" as serv } component ""tacker-conductor"" { component ""conductor"" as cond component ""Kubernetes\ninfra-driver"" as infra } } frame ""Management Cluster"" as mgmt { node ""Control Plane"" as k8s_m_m { node ""Cluster API"" as capi } node ""Worker"" as k8s_m_w { node ""Cluster"" as cluster } } cloud ""Hardware Resources"" as hw_w { frame ""Workload Cluster"" as wkld { node ""Control Plane"" as k8s_w_m node ""Worker"" as k8s_w_w node ""Worker"" as k8s_w_w2 } } '# Relationships client --> serv: 1. Request\n scale VNF serv --> cond cond --> infra infra -right-> k8s_m_m: 2. Call Kubernetes\n API capi --> cluster: 3. Change a parameter\n for the number of worker nodes cluster --> wkld: 4. Change a the number of worker nodes k8s_w_m -[hidden]-> k8s_w_w k8s_w_m -[hidden]-> k8s_w_w2 @enduml Update Workload Cluster ``````````````````````` This figure shows an overview of updating Workload Cluster with Kubernetes infra-driver supporting CRs of CAPO. Similar to the other Kubernetes resources, CRs of CAPI (e.g., Cluster) can be updated by applying the updated version of manifest. This operation can be covered by the change current VNF package in Tacker. #. Request update VNF Users request change current VNF package #. Call Kubernetes API Kubernetes infra-driver calls Kubernetes APIs to override Cluster resource. #. Change a parameter for the number of worker nodes CAPI in Kubernetes Control Plane changes the Cluster resource according to the API calls. #. Change the number of worker nodes CAPI changes worker nodes according to the Cluster resource. .. uml:: @startuml frame ""python-tackerclient"" { component ""tacker-client"" as client { } } frame ""tacker"" { component ""tacker-server"" { component ""server"" as serv } component ""tacker-conductor"" { component ""conductor"" as cond component ""Kubernetes\ninfra-driver"" as infra } } frame ""Management Cluster"" as mgmt { node ""Control Plane"" as k8s_m_m { node ""Cluster API"" as capi } node ""Worker"" as k8s_m_w { node ""Cluster"" as cluster } } cloud ""Hardware Resources"" as hw_w { frame ""Workload Cluster"" as wkld { node ""Control Plane"" as k8s_w_m node ""Worker"" as k8s_w_w node ""Worker"" as k8s_w_w2 } } '# Relationships client --> serv: 1. Request\n change current VNF package serv --> cond cond --> infra infra -right-> k8s_m_m: 2. Call Kubernetes\n API capi --> cluster: 3. Update the resources cluster --> wkld: 4. Change a the resources of worker nodes k8s_w_m -[hidden]-> k8s_w_w k8s_w_m -[hidden]-> k8s_w_w2 @enduml Alternatives ------------ Supporting Helm can be an alternative. However, the custom resources are not always provided as Helm charts. For example, CAPI does not have Helm charts. Data model impact ----------------- None. REST API impact --------------- None. Security impact --------------- None. However, we have to carefully manage credentials for created Workload Cluster. CAPI stores those credentials as Secret of Management CLuster. Therefore, unless the security of Management Cluster is violated, the credentials are safe. Such security management is the out of scope of Tacker. Notifications impact -------------------- None. Other end user impact --------------------- None. Performance Impact ------------------ None. Other deployer impact --------------------- * Deployer who uses this feature may have to create a server to receive credentials for Workload Cluster and may have to create script to register those credentials as VIM. * Deployer who uses this feature may have to prepare VNF packages containing appropriate CAPI CRs and cluster definitions. Developer impact ---------------- * VNF package developers need to contain the management driver to obtain the credentials of Workload Cluster or alternative scripts to do the same thing. * VNF package developers may need to update the packages according to the update of CAPI. * VNF package developers may need to fix bugs of the package caused by CAPI. * Tacker developers may need to fix bugs of Kubernetes infra-driver caused by CAPI. * Developers may need to be careful to change components of Tacker, especially when they want to support additional CRs in Kubernetes infra-driver so that it compiles with implementation of the present document. Implementation ============== Assignee(s) ----------- Primary assignee: * Reina Yoshitani <yoshitanir@intellilink.co.jp> Other contributors: * Shun Higuchi <higuchis@intellilink.co.jp> * Hiromu Asahina (h-asahina) <hiromu.asahina@ntt.com> <hiromu.a5a@gmail.com> Work Items ---------- * Instantiation of CNF including CRs (using Cluster API as an example) * Termination of CNF including CRs (using Cluster API as an example) * Scaling of CNF including CRs (using Cluster API as an example) * Updating of CNF including CRs (using Cluster API as an example) * Sample VNF (i.e., CNF) packages with manifests of CRs for CAPI * Updating user document Dependencies ============ * Kubernetes v1.25.0 or later Testing ======= We can enhance an existing functional tests for Kubernetes VIM by adding test cases for CRs. Those CRs do not necessarily have to be CAPI as the main scope of the present document is to support CRs. Documentation Impact ==================== Need to explain the use cases of the enhanced Kubernetes infra-driver. References ========== .. [#capi] https://cluster-api.sigs.k8s.io/ .. [#nvidia_gpu] https://docs.nvidia.com/datacenter/cloud-native/gpu-operator/getting-started.html#install-nvidia-gpu-operator .. [#tacker_k8s_cluster1] https://docs.openstack.org/tacker/latest/user/mgmt_driver_deploy_k8s_usage_guide.html .. [#tacker_k8s_cluster2] https://docs.openstack.org/tacker/latest/user/mgmt_driver_deploy_k8s_kubespary_usage_guide.html .. [#capi_providers] https://cluster-api.sigs.k8s.io/reference/providers.html ",,597,0
openstack%2Fdesignate~888157,openstack/designate,stable/yoga,Ie9e86199ce9d6b3746637156a47b46b686e12437,Remove designate-tox-dnspython-latest from stable,MERGED,2023-07-11 16:04:53.000000000,2023-07-12 08:33:31.000000000,2023-07-12 08:31:39.000000000,"[{'_account_id': 13252}, {'_account_id': 22348}, {'_account_id': 22623}]","[{'number': 1, 'created': '2023-07-11 16:04:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/designate/commit/faa56c53bbcaf81f9ec041f594eae6fa35ef9874', 'message': 'Remove designate-tox-dnspython-latest from stable\n\nThis patch removes the non-voting designate-tox-dnspython-latest from the\nZed branch of designate. It is really just useful for the master branch\nas the stable branches have upper-constraints restrictions.\n\nChange-Id: Ie9e86199ce9d6b3746637156a47b46b686e12437\n'}, {'number': 2, 'created': '2023-07-11 16:05:08.000000000', 'files': ['.zuul.yaml'], 'web_link': 'https://opendev.org/openstack/designate/commit/b55b5de0f0ad3dfaca47fada3c1714c940d14df2', 'message': 'Remove designate-tox-dnspython-latest from stable\n\nThis patch removes the non-voting designate-tox-dnspython-latest from the\nYoga branch of designate. It is really just useful for the master branch\nas the stable branches have upper-constraints restrictions.\n\nChange-Id: Ie9e86199ce9d6b3746637156a47b46b686e12437\n'}]",1,888157,b55b5de0f0ad3dfaca47fada3c1714c940d14df2,12,3,2,11628,,,0,"Remove designate-tox-dnspython-latest from stable

This patch removes the non-voting designate-tox-dnspython-latest from the
Yoga branch of designate. It is really just useful for the master branch
as the stable branches have upper-constraints restrictions.

Change-Id: Ie9e86199ce9d6b3746637156a47b46b686e12437
",git fetch https://review.opendev.org/openstack/designate refs/changes/57/888157/1 && git format-patch -1 --stdout FETCH_HEAD,['.zuul.yaml'],1,faa56c53bbcaf81f9ec041f594eae6fa35ef9874,,, - designate-tox-dnspython-latest: voting: false,0,2
openstack%2Fdesignate~888156,openstack/designate,stable/zed,Ie9e86199ce9d6b3746637156a47b46b686e12437,Remove designate-tox-dnspython-latest from stable,MERGED,2023-07-11 16:04:01.000000000,2023-07-12 08:32:26.000000000,2023-07-12 08:28:47.000000000,"[{'_account_id': 13252}, {'_account_id': 22348}, {'_account_id': 22623}]","[{'number': 1, 'created': '2023-07-11 16:04:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/designate/commit/5abc680d8563605e6ae20efe63f9eaf0950e4388', 'message': 'Remove designate-tox-dnspython-latest from stable\n\nThis patch removes the non-voting designate-tox-dnspython-latest from the\nAntelope branch of designate. It is really just useful for the master branch\nas the stable branches have upper-constraints restrictions.\n\nChange-Id: Ie9e86199ce9d6b3746637156a47b46b686e12437\n'}, {'number': 2, 'created': '2023-07-11 16:04:25.000000000', 'files': ['.zuul.yaml'], 'web_link': 'https://opendev.org/openstack/designate/commit/2537aedfb5ca68aae5fba210fe6d3d9e3767eb90', 'message': 'Remove designate-tox-dnspython-latest from stable\n\nThis patch removes the non-voting designate-tox-dnspython-latest from the\nZed branch of designate. It is really just useful for the master branch\nas the stable branches have upper-constraints restrictions.\n\nChange-Id: Ie9e86199ce9d6b3746637156a47b46b686e12437\n'}]",0,888156,2537aedfb5ca68aae5fba210fe6d3d9e3767eb90,10,3,2,11628,,,0,"Remove designate-tox-dnspython-latest from stable

This patch removes the non-voting designate-tox-dnspython-latest from the
Zed branch of designate. It is really just useful for the master branch
as the stable branches have upper-constraints restrictions.

Change-Id: Ie9e86199ce9d6b3746637156a47b46b686e12437
",git fetch https://review.opendev.org/openstack/designate refs/changes/56/888156/1 && git format-patch -1 --stdout FETCH_HEAD,['.zuul.yaml'],1,5abc680d8563605e6ae20efe63f9eaf0950e4388,,, - designate-tox-dnspython-latest: voting: false,0,2
openstack%2Fdesignate~888138,openstack/designate,stable/2023.1,Ie9e86199ce9d6b3746637156a47b46b686e12437,Remove designate-tox-dnspython-latest from stable,MERGED,2023-07-11 16:03:19.000000000,2023-07-12 08:31:41.000000000,2023-07-12 08:28:46.000000000,"[{'_account_id': 13252}, {'_account_id': 22348}, {'_account_id': 22623}]","[{'number': 1, 'created': '2023-07-11 16:03:19.000000000', 'files': ['.zuul.yaml'], 'web_link': 'https://opendev.org/openstack/designate/commit/1b570518c379a5b3dd0b3116a4ce9555219c6b22', 'message': 'Remove designate-tox-dnspython-latest from stable\n\nThis patch removes the non-voting designate-tox-dnspython-latest from the\nAntelope branch of designate. It is really just useful for the master branch\nas the stable branches have upper-constraints restrictions.\n\nChange-Id: Ie9e86199ce9d6b3746637156a47b46b686e12437\n'}]",0,888138,1b570518c379a5b3dd0b3116a4ce9555219c6b22,9,3,1,11628,,,0,"Remove designate-tox-dnspython-latest from stable

This patch removes the non-voting designate-tox-dnspython-latest from the
Antelope branch of designate. It is really just useful for the master branch
as the stable branches have upper-constraints restrictions.

Change-Id: Ie9e86199ce9d6b3746637156a47b46b686e12437
",git fetch https://review.opendev.org/openstack/designate refs/changes/38/888138/1 && git format-patch -1 --stdout FETCH_HEAD,['.zuul.yaml'],1,1b570518c379a5b3dd0b3116a4ce9555219c6b22,,, - designate-tox-dnspython-latest: voting: false,0,2
openstack%2Fbifrost~874855,openstack/bifrost,master,I2e7d0310a0be961bb9ac5b133676f235fb1f0f5c,Fix schema[meta] linter warnings,MERGED,2023-02-23 09:19:51.000000000,2023-07-12 08:25:22.000000000,2023-07-12 08:24:20.000000000,"[{'_account_id': 4571}, {'_account_id': 10239}, {'_account_id': 10342}, {'_account_id': 22348}, {'_account_id': 25600}]","[{'number': 1, 'created': '2023-02-23 09:19:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/bifrost/commit/4a56dbf554e721728493a3a7fd223ee2ad1c35d6', 'message': ""Fix schema[meta] linter warnings\n\nOrder platforms by name, and update to versions we test against in zuul\n\ncategories has probably been replaced with galaxy_tags in the schema[1]\n\nQuote numbers, so they're interpreted as strings.\n\n[1] https://galaxy.ansible.com/docs/contributing/creating_role.html#role-metadata\n\nChange-Id: I2e7d0310a0be961bb9ac5b133676f235fb1f0f5c\n""}, {'number': 2, 'created': '2023-03-12 20:50:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/bifrost/commit/40c0b1a2c58a18294052a50202ed369dc527b8f7', 'message': ""Fix schema[meta] linter warnings\n\nOrder platforms by name, and update to versions we test against in zuul\n\ncategories has probably been replaced with galaxy_tags in the schema[1]\n\nQuote numbers, so they're interpreted as strings.\n\n[1] https://galaxy.ansible.com/docs/contributing/creating_role.html#role-metadata\n\nChange-Id: I2e7d0310a0be961bb9ac5b133676f235fb1f0f5c\n""}, {'number': 3, 'created': '2023-07-11 06:46:49.000000000', 'files': ['playbooks/roles/bifrost-keystone-install/meta/main.yml', 'playbooks/roles/bifrost-test-vm/meta/main.yml', 'playbooks/roles/bifrost-ironic-install/meta/main.yml', 'playbooks/roles/bifrost-keystone-client-config/meta/main.yml', 'playbooks/roles/ironic-enroll-dynamic/meta/main.yml', 'playbooks/roles/bifrost-deploy-nodes-dynamic/meta/main.yml', 'playbooks/roles/bifrost-prep-for-install/meta/main.yml', 'playbooks/roles/ironic-inspect-node/meta/main.yml', 'playbooks/roles/bifrost-test-inspection/meta/main.yml', '.ansible-lint', 'playbooks/roles/bifrost-create-vm-nodes/meta/main.yml', 'playbooks/roles/bifrost-unprovision-node-dynamic/meta/main.yml', 'playbooks/roles/bifrost-create-dib-image/meta/main.yml', 'playbooks/roles/bifrost-test-dhcp/meta/main.yml', 'playbooks/roles/ironic-delete-dynamic/meta/main.yml', 'playbooks/roles/bifrost-configdrives-dynamic/meta/main.yml', 'playbooks/roles/bifrost-prepare-for-test-dynamic/meta/main.yml'], 'web_link': 'https://opendev.org/openstack/bifrost/commit/815a0bf6830ea12110fd99a898b4eee7cbd0b225', 'message': ""Fix schema[meta] linter warnings\n\nOrder platforms by name, and update to versions we test against in zuul\n\ncategories has probably been replaced with galaxy_tags in the schema[1]\n\nQuote numbers, so they're interpreted as strings.\n\n[1] https://galaxy.ansible.com/docs/contributing/creating_role.html#role-metadata\n\nChange-Id: I2e7d0310a0be961bb9ac5b133676f235fb1f0f5c\n""}]",2,874855,815a0bf6830ea12110fd99a898b4eee7cbd0b225,18,5,3,25600,,,0,"Fix schema[meta] linter warnings

Order platforms by name, and update to versions we test against in zuul

categories has probably been replaced with galaxy_tags in the schema[1]

Quote numbers, so they're interpreted as strings.

[1] https://galaxy.ansible.com/docs/contributing/creating_role.html#role-metadata

Change-Id: I2e7d0310a0be961bb9ac5b133676f235fb1f0f5c
",git fetch https://review.opendev.org/openstack/bifrost refs/changes/55/874855/1 && git format-patch -1 --stdout FETCH_HEAD,"['playbooks/roles/bifrost-keystone-install/meta/main.yml', 'playbooks/roles/bifrost-test-vm/meta/main.yml', 'playbooks/roles/bifrost-ironic-install/meta/main.yml', 'playbooks/roles/bifrost-keystone-client-config/meta/main.yml', 'playbooks/roles/ironic-enroll-dynamic/meta/main.yml', 'playbooks/roles/bifrost-deploy-nodes-dynamic/meta/main.yml', 'playbooks/roles/bifrost-prep-for-install/meta/main.yml', 'playbooks/roles/ironic-inspect-node/meta/main.yml', 'playbooks/roles/bifrost-test-inspection/meta/main.yml', 'playbooks/roles/bifrost-create-vm-nodes/meta/main.yml', 'playbooks/roles/bifrost-unprovision-node-dynamic/meta/main.yml', 'playbooks/roles/bifrost-create-dib-image/meta/main.yml', 'playbooks/roles/bifrost-test-dhcp/meta/main.yml', 'playbooks/roles/ironic-delete-dynamic/meta/main.yml', 'playbooks/roles/bifrost-configdrives-dynamic/meta/main.yml', 'playbooks/roles/bifrost-prepare-for-test-dynamic/meta/main.yml']",16,4a56dbf554e721728493a3a7fd223ee2ad1c35d6,linters," min_ansible_version: ""1.9"" platforms: - bullseye - name: EL versions: - ""9"" - focal - jammy galaxy_tags:", min_ansible_version: 1.9 platforms: - name: EL versions: - 7 - wheezy - trusty - utopic categories:,130,322
openstack%2Fpuppet-murano~887819,openstack/puppet-murano,stable/2023.1,I88b405e207b7aafe60781877c85f659e096ba48d,Add per module policy service refresh,MERGED,2023-07-06 19:14:00.000000000,2023-07-12 08:22:16.000000000,2023-07-12 08:22:16.000000000,"[{'_account_id': 9816}, {'_account_id': 14985}, {'_account_id': 22348}]","[{'number': 1, 'created': '2023-07-06 19:14:00.000000000', 'files': ['manifests/deps.pp', 'manifests/policy.pp', 'spec/classes/murano_policy_spec.rb'], 'web_link': 'https://opendev.org/openstack/puppet-murano/commit/eff0621fc7481a401e08b5cecd24ec058efd8acb', 'message': 'Add per module policy service refresh\n\nUpdating the policies for this project should only\nrefresh the services that reads it.\n\nChange-Id: I88b405e207b7aafe60781877c85f659e096ba48d\n(cherry picked from commit 652f721f37b565d58862f690f6b23983cd641954)\n'}]",0,887819,eff0621fc7481a401e08b5cecd24ec058efd8acb,7,3,1,16137,,,0,"Add per module policy service refresh

Updating the policies for this project should only
refresh the services that reads it.

Change-Id: I88b405e207b7aafe60781877c85f659e096ba48d
(cherry picked from commit 652f721f37b565d58862f690f6b23983cd641954)
",git fetch https://review.opendev.org/openstack/puppet-murano refs/changes/19/887819/1 && git format-patch -1 --stdout FETCH_HEAD,"['manifests/deps.pp', 'manifests/policy.pp', 'spec/classes/murano_policy_spec.rb']",3,eff0621fc7481a401e08b5cecd24ec058efd8acb,per-module-policy-refresh-stable/2023.1," :tag => 'murano', :tag => 'murano',",,4,1
openstack%2Floci~888090,openstack/loci,master,I639588a618816f6ff70a7736963589977bb36eb1,Build jammy images,MERGED,2023-07-10 22:24:57.000000000,2023-07-12 08:12:45.000000000,2023-07-11 18:42:27.000000000,"[{'_account_id': 22348}, {'_account_id': 29974}, {'_account_id': 35691}]","[{'number': 1, 'created': '2023-07-10 22:24:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/loci/commit/2caf3363b04ccac37d662410f32b3ad09fb84243', 'message': 'Build jammy images\n\nChange-Id: I639588a618816f6ff70a7736963589977bb36eb1\n'}, {'number': 2, 'created': '2023-07-10 23:07:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/loci/commit/e31181c8c9b8838bb964dd4687e8a2968ffe6dc7', 'message': 'Build jammy images\n\nChange-Id: I639588a618816f6ff70a7736963589977bb36eb1\n'}, {'number': 3, 'created': '2023-07-10 23:16:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/loci/commit/94dfdad1915c9e8705255d322c8d85a0ec355dc4', 'message': 'Build jammy images\n\nChange-Id: I639588a618816f6ff70a7736963589977bb36eb1\n'}, {'number': 4, 'created': '2023-07-11 16:34:25.000000000', 'files': ['dockerfiles/ubuntu_jammy/ceph.gpg', 'dockerfiles/ubuntu_jammy/cloud-archive.gpg', 'bindep.txt', 'scripts/install_packages.sh', 'dockerfiles/ubuntu_jammy/Dockerfile', 'playbooks/vars.yaml', 'scripts/install.sh', 'dockerfiles/ubuntu_jammy/sources.list'], 'web_link': 'https://opendev.org/openstack/loci/commit/ec70407d68c433863aadcd2b19a65862e0976b88', 'message': 'Build jammy images\n\nChange-Id: I639588a618816f6ff70a7736963589977bb36eb1\n'}]",5,888090,ec70407d68c433863aadcd2b19a65862e0976b88,16,3,4,3009,,,0,"Build jammy images

Change-Id: I639588a618816f6ff70a7736963589977bb36eb1
",git fetch https://review.opendev.org/openstack/loci refs/changes/90/888090/1 && git format-patch -1 --stdout FETCH_HEAD,"['dockerfiles/ubuntu_jammy/ceph.gpg', 'dockerfiles/ubuntu_jammy/cloud-archive.gpg', 'bindep.txt', 'dockerfiles/ubuntu_jammy/Dockerfile', 'playbooks/vars.yaml', 'dockerfiles/ubuntu_jammy/sources.list']",6,2caf3363b04ccac37d662410f32b3ad09fb84243,,deb %%UBUNTU_URL%% jammy main universe deb %%UBUNTU_URL%% jammy-updates main universe deb %%UBUNTU_URL%% jammy-backports main universe deb %%UBUNTU_URL%% jammy-security main universe deb %%CEPH_URL%% jammy main deb %%CLOUD_ARCHIVE_URL%% jammy-updates/antelope main ,,53,43
openstack%2Fpuppet-cloudkitty~887818,openstack/puppet-cloudkitty,stable/2023.1,I7eda28c684af2def0d4acacfa5ba453ef02b42a3,Add per module policy service refresh,MERGED,2023-07-06 19:13:47.000000000,2023-07-12 08:11:00.000000000,2023-07-12 08:11:00.000000000,"[{'_account_id': 9816}, {'_account_id': 14985}, {'_account_id': 22348}]","[{'number': 1, 'created': '2023-07-06 19:13:47.000000000', 'files': ['spec/classes/cloudkitty_policy_spec.rb', 'manifests/deps.pp', 'manifests/policy.pp'], 'web_link': 'https://opendev.org/openstack/puppet-cloudkitty/commit/9ff18740fb82b0f8d45f153ec4fe13fc20ed1bcd', 'message': 'Add per module policy service refresh\n\nUpdating the policies for this project should only\nrefresh the services that reads it.\n\nChange-Id: I7eda28c684af2def0d4acacfa5ba453ef02b42a3\n(cherry picked from commit 2abda4f574fe9b152f45af67ddefe75b20459aa3)\n'}]",0,887818,9ff18740fb82b0f8d45f153ec4fe13fc20ed1bcd,7,3,1,16137,,,0,"Add per module policy service refresh

Updating the policies for this project should only
refresh the services that reads it.

Change-Id: I7eda28c684af2def0d4acacfa5ba453ef02b42a3
(cherry picked from commit 2abda4f574fe9b152f45af67ddefe75b20459aa3)
",git fetch https://review.opendev.org/openstack/puppet-cloudkitty refs/changes/18/887818/1 && git format-patch -1 --stdout FETCH_HEAD,"['spec/classes/cloudkitty_policy_spec.rb', 'manifests/deps.pp', 'manifests/policy.pp']",3,9ff18740fb82b0f8d45f153ec4fe13fc20ed1bcd,per-module-policy-refresh-stable/2023.1," tag => 'cloudkitty',",,4,1
openstack%2Ftacker-specs~878824,openstack/tacker-specs,master,I4df1f8f241742b07784751b507466509693c7a8a,Terraform Infra-driver for Insta/Termi,MERGED,2023-03-29 09:34:43.000000000,2023-07-12 06:20:47.000000000,2023-07-12 06:20:47.000000000,"[{'_account_id': 17255}, {'_account_id': 22348}, {'_account_id': 25701}, {'_account_id': 31730}, {'_account_id': 31857}, {'_account_id': 32102}]","[{'number': 1, 'created': '2023-03-29 09:34:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tacker-specs/commit/b21bec33ff461ed7f4d46a8dc7e9a89e9a899e63', 'message': 'Terraform Infra-driver for Insta/Termi\n\nThis specification describes Terraform Infra-driver in Tacker. The\nscope of the present document includes VNF instantiation and\ntermination with this new infra-driver, using AWS as an example NFVI.\n\nChange-Id: I4df1f8f241742b07784751b507466509693c7a8a\n'}, {'number': 2, 'created': '2023-07-09 13:18:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tacker-specs/commit/41561331d457a963b474dfc538e4163a456b7cb9', 'message': 'Terraform Infra-driver for Insta/Termi\n\nThis specification describes Terraform Infra-driver in Tacker. The\nscope of the present document includes VNF instantiation and\ntermination with this new infra-driver, using AWS as an example NFVI.\n\nImplements: blueprint terraform-infra-driver\nChange-Id: I4df1f8f241742b07784751b507466509693c7a8a\n'}, {'number': 3, 'created': '2023-07-09 14:17:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tacker-specs/commit/c6307019e5b8706e11898745cc5a1e1c96b48500', 'message': 'Terraform Infra-driver for Insta/Termi\n\nThis specification describes Terraform Infra-driver in Tacker. The\nscope of the present document includes VNF instantiation and\ntermination with this new infra-driver, using AWS as an example NFVI.\n\nImplements: blueprint terraform-infra-driver\nChange-Id: I4df1f8f241742b07784751b507466509693c7a8a\n'}, {'number': 4, 'created': '2023-07-10 02:10:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tacker-specs/commit/2d5ea776626f21c84e0fd4487a1a09d5312f30f2', 'message': 'Terraform Infra-driver for Insta/Termi\n\nThis specification describes Terraform Infra-driver in Tacker. The\nscope of the present document includes VNF instantiation and\ntermination with this new infra-driver, using AWS as an example NFVI.\n\nImplements: blueprint support-k8s-cr\nChange-Id: I4df1f8f241742b07784751b507466509693c7a8a\n'}, {'number': 5, 'created': '2023-07-10 02:10:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tacker-specs/commit/a0c51f7018b037396f4fcbf03074530e125c8e23', 'message': 'Terraform Infra-driver for Insta/Termi\n\nThis specification describes Terraform Infra-driver in Tacker. The\nscope of the present document includes VNF instantiation and\ntermination with this new infra-driver, using AWS as an example NFVI.\n\nImplements: blueprint terraform-infra-driver\nChange-Id: I4df1f8f241742b07784751b507466509693c7a8a\n'}, {'number': 6, 'created': '2023-07-10 08:32:47.000000000', 'files': ['specs/2023.2/terraform-infra-driver.rst'], 'web_link': 'https://opendev.org/openstack/tacker-specs/commit/69b9f99f96ea4d8a2a3a0b561cff7217c0bdc63d', 'message': 'Terraform Infra-driver for Insta/Termi\n\nThis specification describes Terraform Infra-driver in Tacker. The\nscope of the present document includes VNF instantiation and\ntermination with this new infra-driver, using AWS as an example NFVI.\n\nImplements: blueprint terraform-infra-driver\nChange-Id: I4df1f8f241742b07784751b507466509693c7a8a\n'}]",23,878824,69b9f99f96ea4d8a2a3a0b561cff7217c0bdc63d,21,6,6,33455,,,0,"Terraform Infra-driver for Insta/Termi

This specification describes Terraform Infra-driver in Tacker. The
scope of the present document includes VNF instantiation and
termination with this new infra-driver, using AWS as an example NFVI.

Implements: blueprint terraform-infra-driver
Change-Id: I4df1f8f241742b07784751b507466509693c7a8a
",git fetch https://review.opendev.org/openstack/tacker-specs refs/changes/24/878824/1 && git format-patch -1 --stdout FETCH_HEAD,['specs/2023.2/terraform-infra-driver.rst'],1,b21bec33ff461ed7f4d46a8dc7e9a89e9a899e63,bp/terraform-infra-driver,".. This work is licensed under a Creative Commons Attribution 3.0 Unported License. http://creativecommons.org/licenses/by/3.0/legalcode ============================================================ Terraform Infra-driver for VNF Instantiation and Termination ============================================================ This specification describes Terraform Infra-driver in Tacker. The scope of the present document includes VNF instantiation and termination with this new infra-driver, using AWS as an example NFVI. https://blueprints.launchpad.net/tacker/+spec/terraform-infra-driver Problem description =================== Tacker is designed as a G-VNFM that supports both VNF and CNF LCM. However, OpenStack is the only platform where Tacker can deploy VNF among the variety of cloud platforms. Given the recent multi-cloud trends in cloud computing, Tacker have to overcome this potential disadvantage by implementing additional infra-driver. Proposed change =============== This spec proposes to support Terraform infra-driver. Terraform [#terraform]_ is the de-facto standard in the IaC area, it's platform-agnostic, declarative and open source. Using Terraform as a backend tool enables Tacker to create virtual resources on several platforms that Terraform has already supported, such as AWS. Terraform has its own configuration language to define virtual resources, like manifest in Kubernetes or Helm chart in Helm. Users can easily create VNF packages for Terraform infra-driver by including the configuration. For this to happen, the following items have to be implemented. * VNF Instantiation with Terraform Infra-driver * VNF Termination with Terraform Infra-driver * Adding DB table/field to store Terraform state (optional) * Sample VNF packages for Terraform infra-driver * Updating user document Terraform --------- HashiCorp Terraform is an infrastructure as code tool that lets you define both cloud and on-prem resources in human-readable configuration files that you can version, reuse, and share. Put simply, you can see Terraform as generic OpenStack Heat that can be used among several cloud platforms. Terraform supports a number of cloud infrastructure providers such as: * Amazon Web Services * Cloudflare * Microsoft Azure * IBM Cloud * Serverspace * Google Cloud Platform * DigitalOcean * Oracle Cloud Infrastructure * Yandex.Cloud * VMware vSphere * OpenStack * Kubernetes * Helm Terraform uses declarative configuration to describe the desired final state and its client-side is provided only a CLI tool, similar to Helm. Therefore, the basic architecture of Terraform infra-driver can be similar to Helm infra-driver. The following are the characteristics of Terraform: #. Configuration file Terraform has its own language HCL for the resource definition. The files containing Terraform code are often called configuration files. These files correspond to the Helm chart in Helm. #. Variables Terraform allows users to define variables in configuration files. Variables can be set as a file or parameters of Terraform CLI. This is a similar mechanism to the values in Helm. #. State file and state lock file Terraform creates a state file and a state lock file [#tf_state]_ when Terraform creates actual resources. This might be the biggest difference from Helm. This state file records the information of resources created by Terraform. The state lock file prevents others from acquiring the lock and potentially corrupting your state in the case where multiple users manage the same resources with Terraform in different places. .. note:: In Kubernetes, the state file corresponds to the resources on Kubernetes worker nodes which store all information of actual resources managed by Kubernetes. As there's no entity corresponding to the worker nodes, Terraform creates state files. This figure shows the overview of the operation of Terraform, and input/output files. .. uml:: @startuml actor ""User"" as user component ""Terraform CLI"" as cli component ""Terraform"" as tf component ""Configuration file"" as config component ""Variables file"" as vars component ""Target Service"" as svc file ""State file"" as state file ""State lock file"" as statelock '# Relationships user --> config: 1. Create Configuration file user --> vars: 1. Create Variables file user -> cli cli -> tf: 2. Init Terraform\n with configuration file\n and variables file tf --> statelock: 3. Create state lock file cli -> tf: 4. Apply Configuration file tf -> svc: 5. Call APIs tf --> state: 6. Create state file @enduml Terraform Infra-driver ---------------------- This figure shows an overview of Instantiate VNF with the Terraform infra-driver. Terminate VNF is omitted as it is almost the same as the Instantiate VNF. Instantiate VNF consist of the following steps: #. Request create VNF Users request create VNF with a VNF package that contains Terraform config and variable files in addition to VNFD. #. Request instantiate VNF Users request instantiate VNF with an instantiate parameters that can overrides variables defined in Terraform variables file. #. Execute Terraform command Terraform infra-driver executes terraform command to apply configuration files to Terraform. #. Call target service API Terraform calls target service APIs according to the configuration file #. Create VM(s) Target service (e.g., OpenStack Nova, AWS EC2, etc) creates VM(s). .. uml:: @startuml frame ""python-tackerclient"" { component ""tacker-client"" as client { package ""VNF Package"" as vnfpkg { file ""VNFD"" as vnfd file ""Terraform\nconfiguration"" as tffile file ""Terraform\nvariables\nfile"" as tfvar } file ""Instantiate\nparameters"" as inst_param } } vnfd -[hidden]> tffile tffile-[hidden]> tfvar frame ""tacker"" { component ""tacker-server"" { component ""server"" as serv } component ""tacker-conductor"" { component ""conductor"" as cond component ""Terraform\ninfra-driver"" as infra } } node ""Terraform"" node ""Target Service"" as ts cloud ""Hardware Resources"" as hw { node ""VM"" as ins1 } '# Relationships vnfpkg --> serv: 1. Request\n create VNF inst_param --> serv: 2. Request\n instantiate VNF serv --> cond cond --> infra infra --> Terraform: 3. Execute Terraform command Terraform -right-> ts: 4. Call target\n service API ts --> ins1: 5. Create VM(s) @enduml State file management ````````````````````` Given that terraform config file is located in VNF packages, state files are created and managed for each VNF package. Terraform provides several options (i.e., backend) to store the state file [#tf_state_backend]_. Based on the available backend, the available options for Tacker is the following: #. Store state files as a local file #. Store state files in InstantiatedVnfInfo #. Store state files in a new DB table/field #. Store state files in Kubernetes Secret #. Store state files in PostgresDB The first option is the easiest way and most feasible. As Tacker extracts a VNF package into a local directory, we can place a state file in that local directory. If the first option is not possible, for example such local directory is not persistent and there is no way to create temporal directories, we can manage state files on the InstantiatedVnfInfo field. Since the data type of this field is structure [#sol003]_ and the state file is written in JSON, we can directly store the state file in that field. This field is also suitable in the sense that the lifecycle of the state file matches that of VNF Instance. The rest of options are not recommended as it incurs changes on the data model of Tacker or requires another component to manage the state file. This figure shows the basic idea of the first option. .. uml:: @startuml left to right direction component ""Terraform infra-driver"" as tfid folder ""VNF Package A"" as pkga folder ""VNF Package B"" as pkgb folder ""Directory A"" as da { file ""Configuration"" as ca file ""Variables"" as va file ""State file A"" as statea file ""State lock file A"" as statelocka } folder ""Directory B"" as db { file ""State lock file B"" as statelockb file ""State file B"" as stateb file ""Configuration"" as cb file ""Variables"" as vb } db -[hidden]> da component ""Terraform"" as tf '# Relationships tfid <-up- pkga: Download tfid <-up- pkgb: Download tfid -down-> da: Extract VNF Package A tfid -down-> db: Extract VNF Package B tf --> statea: Create tf --> statelocka: Create tf --> stateb: Create tf --> statelockb: Create tfid -> tf: Execute @enduml State lock file management `````````````````````````` Ideally, we can disable generating state lock files [#tf_lock]_ as Tacker is only the entity that manages the resources associated with the instantiated VNF. If we need to use the lock file, we have the similar options as the state file as follows: #. Store state files as a local file #. Store state files in InstantiatedVnfInfo #. Store state files in a new DB table/field Alternatives ------------ Implementing infra-driver for individual platform can be an alternative. Data model impact ----------------- None. One possible reason for data model changes is to make new table/field to store state and state lock files. As described in the State file management section, we have several alternative ways. REST API impact --------------- None. Security impact --------------- Terraform uses sensitive data in some scenes. For example, Terraform requires credentials to make API requests. In general, we can avoid exposure of sensitive data by using environment variables. However, at the same time, we need to carefully make configuration files. Potential risks are listed as follows, but there can be more: * Hardcoded credentials for the target services * Hardcoded credentials for the backend of the state file [#tf_state_sec]_ See the best practice for details [#tf_sec]_ Notifications impact -------------------- None. However, if state files are stored in InstantiatedVnfInfo, they can be omitted from LcmOpOccNotification. Other end user impact --------------------- None. Performance Impact ------------------ None. Terraform itself and the state file (might be located on DB) might use storage, but it is negligibly small. As the infra-drivers are abstracted by Tacker's VNF LCM driver, Terraform infra-driver does not affect to the overall performance. Other deployer impact --------------------- After merging this feature, the following points must be considered: * Users need to install Terraform when using Terraform infra-driver * Tacker community should add installation of Terraform in Zuul to tests Terraform infra-driver No effects on existing deployments as this is a new feature independent of the existing ones. Developer impact ---------------- * Developers may need to update Terraform infra-driver according to the update of Terraform. * Developers may need to fix bugs of Terraform infra-driver caused by the Terraform. * Developers may need to be careful to change other components than Terraform infra-driver, such as VNF package format, controllers, conductor, etc, so that it works in Terraform infra-driver. Implementation ============== Assignee(s) ----------- Primary assignee: * Hiromu Asahina (h-asahina) <hiromu.asahina@ntt.com> <hiromu.a5a@gmail.com> Other contributors: * TBD Work Items ---------- * VNF Instantiation with Terraform Infra-driver * VNF Termination with Terraform Infra-driver * Adding DB table/field to store Terraform state (optional) * Sample VNF packages for Terraform infra-driver * Updating user document Dependencies ============ * Terraform v1.4.0 or later Testing ======= Terraform supports several providers including OpenStack [#tf_os]_, Kubernetes [#tf_k8s]_, Docker [#tf_local]_ and local files [#tf_docker]_. The easiest way is to use OpenStack in the functional tests. As terraform infra-driver is transparent for VNF packages, its normality must not be affected by the difference of used providers. In this sense, we can tests its normality with other available providers, such as Kubernetes, docker or local provider. Documentation Impact ==================== Need to explain the use cases of Terraform infra-driver. References ========== .. [#terraform] https://www.terraform.io/ .. [#tf_state] https://developer.hashicorp.com/terraform/language/state .. [#tf_state_backend] https://developer.hashicorp.com/terraform/language/settings/backends/configuration#available-backends .. [#sol003] https://www.etsi.org/deliver/etsi_gs/NFV-SOL/001_099/003/03.05.01_60/gs_NFV-SOL003v030501p.pdf .. [#tf_lock] https://developer.hashicorp.com/terraform/language/state/locking .. [#tf_os] https://registry.terraform.io/providers/terraform-provider-openstack/openstack/latest .. [#tf_k8s] https://registry.terraform.io/providers/hashicorp/kubernetes/latest .. [#tf_docker] https://registry.terraform.io/providers/kreuzwerker/docker/latest .. [#tf_local] https://registry.terraform.io/providers/hashicorp/local/latest .. [#tf_state_sec] https://developer.hashicorp.com/terraform/language/settings/backends/configuration#credentials-and-sensitive-data .. [#tf_sec] https://cycode.com/7-terraform-security-best-practices/ ",,411,0
openstack%2Fpuppet-openstack-integration~888038,openstack/puppet-openstack-integration,master,I9fdd375663f4f9eea1b96e7b9a99e50837def0f1,c9s: Switch to Ceph Reef,ABANDONED,2023-07-10 13:40:50.000000000,2023-07-12 04:28:16.000000000,,[{'_account_id': 22348}],"[{'number': 1, 'created': '2023-07-10 13:40:50.000000000', 'files': ['configure_facts.sh'], 'web_link': 'https://opendev.org/openstack/puppet-openstack-integration/commit/1553e7c8b0253ca8b46b76c194f871df432fa51f', 'message': 'c9s: Switch to Ceph Reef\n\nCurrently installation of ceph fails because of conflicting requirement\nabout the liburing package. ceph-osd from quincy requires liburing 0.7\nbut the recent qemu-kvm package in CentOS Stream 9 requires liburing\n2.3.\n\nThis bumps the ceph version to resolve that conflict.\n\nChange-Id: I9fdd375663f4f9eea1b96e7b9a99e50837def0f1\n'}]",0,888038,1553e7c8b0253ca8b46b76c194f871df432fa51f,3,1,1,9816,,,0,"c9s: Switch to Ceph Reef

Currently installation of ceph fails because of conflicting requirement
about the liburing package. ceph-osd from quincy requires liburing 0.7
but the recent qemu-kvm package in CentOS Stream 9 requires liburing
2.3.

This bumps the ceph version to resolve that conflict.

Change-Id: I9fdd375663f4f9eea1b96e7b9a99e50837def0f1
",git fetch https://review.opendev.org/openstack/puppet-openstack-integration refs/changes/38/888038/1 && git format-patch -1 --stdout FETCH_HEAD,['configure_facts.sh'],1,1553e7c8b0253ca8b46b76c194f871df432fa51f,,export CEPH_VERSION=${CEPH_VERSION:-reef},export CEPH_VERSION=${CEPH_VERSION:-quincy},1,1
openstack%2Fironic-python-agent~882367,openstack/ironic-python-agent,master,I4b578c4319354001cbbd3b3856af96b30fd25555,Allow md5 to be disabled from the conductor,MERGED,2023-05-05 01:13:06.000000000,2023-07-12 03:54:18.000000000,2023-07-12 03:53:14.000000000,"[{'_account_id': 4571}, {'_account_id': 10342}, {'_account_id': 22348}]","[{'number': 1, 'created': '2023-05-05 01:13:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic-python-agent/commit/0a76077f9c1714654a9e5f0568cdff68edda1767', 'message': ""Allow md5 to be disabled from the conductor\n\nAlso fixes my use of set_override, as it is not on the actual\nconfig object. You'd think I'd remember that, since I've done\nthat before...\n\nChange-Id: I4b578c4319354001cbbd3b3856af96b30fd25555\n""}, {'number': 2, 'created': '2023-05-25 14:59:15.000000000', 'files': ['ironic_python_agent/agent.py', 'ironic_python_agent/tests/unit/test_agent.py'], 'web_link': 'https://opendev.org/openstack/ironic-python-agent/commit/e6fd7e753e3895ba420801099a380717b2100862', 'message': ""Allow md5 to be disabled from the conductor\n\nAlso fixes my use of set_override, as it is not on the actual\nconfig object. You'd think I'd remember that, since I've done\nthat before...\n\nChange-Id: I4b578c4319354001cbbd3b3856af96b30fd25555\n""}]",8,882367,e6fd7e753e3895ba420801099a380717b2100862,33,3,2,11655,,,0,"Allow md5 to be disabled from the conductor

Also fixes my use of set_override, as it is not on the actual
config object. You'd think I'd remember that, since I've done
that before...

Change-Id: I4b578c4319354001cbbd3b3856af96b30fd25555
",git fetch https://review.opendev.org/openstack/ironic-python-agent refs/changes/67/882367/1 && git format-patch -1 --stdout FETCH_HEAD,"['ironic_python_agent/agent.py', 'ironic_python_agent/tests/unit/test_agent.py']",2,0a76077f9c1714654a9e5f0568cdff68edda1767,," 'heartbeat_timeout': 300, 'agent_md5_checksum_enable': False self.assertFalse(CONF.md5_enabled) CONF.set_override('md5_enabled', False) 'heartbeat_timeout': 300, 'agent_md5_checksum_enable': True self.assertTrue(CONF.md5_enabled)", 'heartbeat_timeout': 300 'heartbeat_timeout': 300,13,5
openstack%2Fskyline-console~883364,openstack/skyline-console,master,I421469265e6f12f1583456bc20f8cafa7c48536e,feat: Update i18n Korean translation,MERGED,2023-05-17 12:07:35.000000000,2023-07-12 01:59:17.000000000,2023-07-12 01:58:20.000000000,"[{'_account_id': 6282}, {'_account_id': 14482}, {'_account_id': 22348}, {'_account_id': 23279}, {'_account_id': 28706}, {'_account_id': 30434}]","[{'number': 1, 'created': '2023-05-17 12:07:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/skyline-console/commit/33e84dc3cb471a288bbcb42095ae155552eed4df', 'message': 'Translated into Korean\n\nChange-Id: I421469265e6f12f1583456bc20f8cafa7c48536e\n'}, {'number': 2, 'created': '2023-05-17 12:24:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/skyline-console/commit/559833547dd93f4defdcdedb32bf47c8b9ccd3aa', 'message': 'Translated into Korean\n\nChange-Id: I421469265e6f12f1583456bc20f8cafa7c48536e\n'}, {'number': 3, 'created': '2023-05-24 02:21:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/skyline-console/commit/7c5a84cb351b382a8d7a23f4c71a42b347d0d314', 'message': 'Translated into Korean\n\nChange-Id: I421469265e6f12f1583456bc20f8cafa7c48536e\n'}, {'number': 4, 'created': '2023-05-24 10:48:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/skyline-console/commit/431a74eeec638fce57b1322a40f875814c512e23', 'message': 'Translated into Korean\n\nChange-Id: I421469265e6f12f1583456bc20f8cafa7c48536e\n'}, {'number': 5, 'created': '2023-05-24 10:54:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/skyline-console/commit/1cb2f840e6d85cb36c2bc3a0421acbecc12ca1af', 'message': 'Translated into Korean\n\nChange-Id: I421469265e6f12f1583456bc20f8cafa7c48536e\n'}, {'number': 6, 'created': '2023-05-24 10:55:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/skyline-console/commit/b711aa415faaa2dec2b9ffd770c168a0f6e9a2da', 'message': 'Translated into Korean\n\nChange-Id: I421469265e6f12f1583456bc20f8cafa7c48536e\n'}, {'number': 7, 'created': '2023-05-24 11:12:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/skyline-console/commit/4e8428239c3b82a9b9395c2d21d18e4ff6700595', 'message': 'Translated into Korean\n\nChange-Id: I421469265e6f12f1583456bc20f8cafa7c48536e\n'}, {'number': 8, 'created': '2023-05-24 11:16:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/skyline-console/commit/81288a5c0ffc87e6ebe4a366dfde86316a8ee217', 'message': 'Translated into Korean\n\nChange-Id: I421469265e6f12f1583456bc20f8cafa7c48536e\n'}, {'number': 9, 'created': '2023-05-24 12:03:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/skyline-console/commit/c38c1341a9dac060d78ec81c2d0cd6629112f1e5', 'message': 'Translated into Korean\n\nChange-Id: I421469265e6f12f1583456bc20f8cafa7c48536e\n'}, {'number': 10, 'created': '2023-05-24 12:04:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/skyline-console/commit/895427db5f916efda5a8eb8ef97431d753ca43d5', 'message': 'Translated into Korean\n\nChange-Id: I421469265e6f12f1583456bc20f8cafa7c48536e\n'}, {'number': 11, 'created': '2023-05-24 12:05:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/skyline-console/commit/e9af71a7f45d01e1e75ff47865fccf50d57577e2', 'message': 'Translated into Korean\n\nCo-authored-by: Yoon Soo Lim <msdbtjd123@naver.com>\nCo-authored-by: Youngju Lee <leeyj7141@gmail.com>\nCo-authored-by: Young-Tae Han <han0tae@gmail.com>\nCo-authored-by: Daewon Kim <prudentcircle@outlook.com>\nCo-authored-by: Jihye Park <nina3909@naver.com>\nCo-authored-by: hojin kim <dncs0725@gmail.com>\nCo-authored-by: Hocheol Shin <shingoon7@gmail.com>\nCo-authored-by: Seungho Lee <fashionday2@gmail.com>\n\nChange-Id: I421469265e6f12f1583456bc20f8cafa7c48536e\n'}, {'number': 12, 'created': '2023-05-24 12:07:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/skyline-console/commit/986fc6c29dc117e321ba33d39ac7e9a27c222d0a', 'message': 'Translated into Korean\n\nCo-authored-by: Yoon Soo Lim <msdbtjd123@naver.com>\nCo-authored-by: Youngju Lee <leeyj7141@gmail.com>\nCo-authored-by: Young-Tae Han <han0tae@gmail.com>\nCo-authored-by: Daewon Kim <prudentcircle@outlook.com>\nCo-authored-by: Jihye Park <nina3909@naver.com>\nCo-authored-by: hojin kim <dncs0725@gmail.com>\nCo-authored-by: Hocheol Shin <shingoon7@gmail.com>\nCo-authored-by: Seungho Lee <fashionday2@gmail.com>\n\nChange-Id: I421469265e6f12f1583456bc20f8cafa7c48536e\n'}, {'number': 13, 'created': '2023-05-25 20:07:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/skyline-console/commit/b3eff40e26e8231857a97eca4b53e516ad26bb0c', 'message': 'feat: Update i18n Korean translation\n\nNote: all of the co-authors collaborated the translation artifact together.\n\nCo-authored-by: Yoon Soo Lim <msdbtjd123@naver.com>\nCo-authored-by: Youngju Lee <leeyj7141@gmail.com>\nCo-authored-by: Young-Tae Han <han0tae@gmail.com>\nCo-authored-by: Daewon Kim <prudentcircle@outlook.com>\nCo-authored-by: Jihye Park <nina3909@naver.com>\nCo-authored-by: hojin kim <dncs0725@gmail.com>\nCo-authored-by: Hocheol Shin <shingoon7@gmail.com>\nCo-authored-by: Seungho Lee <fashionday2@gmail.com>\n\nChange-Id: I421469265e6f12f1583456bc20f8cafa7c48536e\n'}, {'number': 14, 'created': '2023-05-30 11:27:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/skyline-console/commit/94ff007c6b12da53c1fe718f15af6b0f1a78e7d3', 'message': 'feat: Update i18n Korean translation\n\nNote: all of the co-authors collaborated the translation artifact together.\n\nCo-authored-by: Yoon Soo Lim <msdbtjd123@naver.com>\nCo-authored-by: Youngju Lee <leeyj7141@gmail.com>\nCo-authored-by: Young-Tae Han <han0tae@gmail.com>\nCo-authored-by: Daewon Kim <prudentcircle@outlook.com>\nCo-authored-by: Jihye Park <nina3909@naver.com>\nCo-authored-by: hojin kim <dncs0725@gmail.com>\nCo-authored-by: Hocheol Shin <shingoon7@gmail.com>\nCo-authored-by: Seungho Lee <fashionday2@gmail.com>\nCo-authored-by: Jaeseong Shin <rornfl916@gmail.com>\n\nChange-Id: I421469265e6f12f1583456bc20f8cafa7c48536e\n'}, {'number': 15, 'created': '2023-05-30 11:28:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/skyline-console/commit/ac9dd5795d17472e9e3e2e8f83b1044098869e40', 'message': 'feat: Update i18n Korean translation\n\nNote: all of the co-authors collaborated the translation artifact together.\n\nCo-authored-by: Yoon Soo Lim <msdbtjd123@naver.com>\nCo-authored-by: Youngju Lee <leeyj7141@gmail.com>\nCo-authored-by: Young-Tae Han <han0tae@gmail.com>\nCo-authored-by: Daewon Kim <prudentcircle@outlook.com>\nCo-authored-by: Jihye Park <nina3909@naver.com>\nCo-authored-by: hojin kim <dncs0725@gmail.com>\nCo-authored-by: Hocheol Shin <shingoon7@gmail.com>\nCo-authored-by: Seungho Lee <fashionday2@gmail.com>\nCo-authored-by: Jaeseong-Shin <rornfl916@gmail.com>\n\nChange-Id: I421469265e6f12f1583456bc20f8cafa7c48536e\n'}, {'number': 16, 'created': '2023-06-27 02:10:02.000000000', 'files': ['src/locales/ko-kr.json'], 'web_link': 'https://opendev.org/openstack/skyline-console/commit/dad25eeb8fc8919eda2f272d3b73930945993a1f', 'message': 'feat: Update i18n Korean translation\n\nNote: all of the co-authors collaborated the translation artifact together.\n\nCo-authored-by: Yoon Soo Lim <msdbtjd123@naver.com>\nCo-authored-by: Youngju Lee <leeyj7141@gmail.com>\nCo-authored-by: Young-Tae Han <han0tae@gmail.com>\nCo-authored-by: Daewon Kim <prudentcircle@outlook.com>\nCo-authored-by: Jihye Park <nina3909@naver.com>\nCo-authored-by: hojin kim <dncs0725@gmail.com>\nCo-authored-by: Hocheol Shin <shingoon7@gmail.com>\nCo-authored-by: Seungho Lee <fashionday2@gmail.com>\nCo-authored-by: Jaeseong-Shin <rornfl916@gmail.com>\n\nChange-Id: I421469265e6f12f1583456bc20f8cafa7c48536e\n'}]",9,883364,dad25eeb8fc8919eda2f272d3b73930945993a1f,42,6,16,35517,,,0,"feat: Update i18n Korean translation

Note: all of the co-authors collaborated the translation artifact together.

Co-authored-by: Yoon Soo Lim <msdbtjd123@naver.com>
Co-authored-by: Youngju Lee <leeyj7141@gmail.com>
Co-authored-by: Young-Tae Han <han0tae@gmail.com>
Co-authored-by: Daewon Kim <prudentcircle@outlook.com>
Co-authored-by: Jihye Park <nina3909@naver.com>
Co-authored-by: hojin kim <dncs0725@gmail.com>
Co-authored-by: Hocheol Shin <shingoon7@gmail.com>
Co-authored-by: Seungho Lee <fashionday2@gmail.com>
Co-authored-by: Jaeseong-Shin <rornfl916@gmail.com>

Change-Id: I421469265e6f12f1583456bc20f8cafa7c48536e
",git fetch https://review.opendev.org/openstack/skyline-console refs/changes/64/883364/1 && git format-patch -1 --stdout FETCH_HEAD,['src/locales/ko-kr.json'],1,33e84dc3cb471a288bbcb42095ae155552eed4df,," ""3600"": ""3600"", "" You can go to the console to "": ""콘솔로 이동"", ""\""Shared\"" volume can be mounted on multiple instances"": ""\""공유된\"" 볼륨은 다수의 인스턴스에서 마운트가 가능합니다."", ""'ip' rule represents IPv4 or IPv6 address, 'cert' rule represents TLS certificate, 'user' rule represents username or usergroup, 'cephx' rule represents ceph auth ID."": ""‘ip’ 룰은 IPv4 또는 IPv6 주소를 나타내며 ’cert’ 룰은 TLS 인증서를 ‘user’ 룰은 사용자 이름과 사용자 그룹을 ’cephx’ 룰은 ceph auth ID 를 나타냅니다."", ""-1 means no connection limit"": ""-1은 연결 제한이 없는 것을 의미합니다."", ""."": ""."", ""1. The backup can only capture the data that has been written to the volume at the beginning of the backup task, excluding the data in the cache at that time."": ""백업 테스트 시작시 볼륨에 작성된 데이터 수집만 백업 가능하며 캐쉬에 저장된 데이터는 제외됩니다."", ""1. The name of the custom resource class property should start with CUSTOM_, can only contain uppercase letters A ~ Z, numbers 0 ~ 9 or underscores, and the length should not exceed 255 characters (for example: CUSTOM_BAREMETAL_SMALL)."": ""사용자 리소스 클래스 속성의 이름은 CUSTOM_으로 시작되며, A ~ Z 대문자만 포함, 0 ~ 9 숫자 또는 언더스코어, 길이는 255자를 초과하지 않아야 합니다. (예: CUSTOM_BAREMETAL_SMALL)."", ""1. The name of the trait should start with CUSTOM_, can only contain uppercase letters A ~ Z, numbers 0 ~ 9 or underscores, and the length should not exceed 255 characters (for example: CUSTOM_TRAIT1)."": ""트레인 이름은 CUSTOM으로 시작되며 A ~ Z 대문자만 포함, 0 ~ 9 숫자 또는 언더스코어, 길이는 255자를 초과하지 않아야 합니다.(예: CUSTOM_TRAIT1)"", ""1. The volume associated with the backup is available."": ""백업과 결합된 볼륨이 사용가능합니다."", ""1. You can create {resources} using ports or port ranges."": ""포트 또는 포트 범위로 {resource}를 생성 가능합니다."", ""10s"": ""10s"", ""1D"": ""1D"", ""1H"": ""1H"", ""1min"": ""1min"", ""2. In the same protocol, you cannot create multiple {resources} for the same source port or source port range."": ""동일한 프로토콜내에서 포트 또는 포트 범위로 다수의 {resource}를 생성 가능합니다."", ""2. The trait of the scheduled node needs to correspond to the trait of the flavor used by the ironic instance; by injecting the necessary traits into the ironic instance, the computing service will only schedule the instance to the bare metal node with all the necessary traits (for example, the ironic instance which use the flavor that has CUSTOM_TRAIT1 as a necessary trait, can be scheduled to the node which has the trait of CUSTOM_TRAIT1)."": ""예약된 노드의 trait는 ironic 인스턴스에 사용하는 플레이버의 trait와 일치해야 합니다. 필요한 trait를 베어메탈 노드에 주입함으로써 컴퓨팅 서비스는 필요로 하는 모든 trait로 가진 상태로 컴퓨팅 서비스는 예약됩니다(예를 들면 필요한 trait를 가진 CUSTOM_TRAIT1 flavor를 사용하는 ironic 인스턴스는 CUSTOM_TRAIT1 trait를 가진 노드에 예약될 수 있습니다. "", ""2. The volume associated with the backup has been mounted, and the instance is shut down."": ""백업과 결합된 볼륨이 마운트 되었으며 인스턴스는 종료합니다."", ""2. To ensure the integrity of the data, it is recommended that you suspend the write operation of all files when creating a backup."": ""데이터 무결성을 검사하기 위해 백업 생성시 모든 파일에 대한 쓰기 동작을 중단하는 것을 권장합니다."", ""2. You can customize the resource class name of the flavor, but it needs to correspond to the resource class of the scheduled node (for example, the resource class name of the scheduling node is baremetal.with-GPU, and the custom resource class name of the flavor is CUSTOM_BAREMETAL_WITH_GPU=1)."": ""플레이버의 리소스 클래스 이름에 대한 사용자화가 가능하지만 예약된 노드의 리소스 클레스에 대한 응답(?)이 필요합니다. (예를 들면 스케쥴링 노드의 리소스 클래스 이름은 baremetal.with-GPU이며 플레이버의 커스텀 리소스 클래스 이름은 CUSTOM_BAREMETAL_WITH_GPU=1)"", ""3. When using a port range to create a port mapping, the size of the external port range is required to be the same as the size of the internal port range. For example, the external port range is 80:90 and the internal port range is 8080:8090."": ""포트 범위를 사용하여 포트 매핑을 생성할 때 외부 포트 범위의 크기는 내부 포트 범위의 크기와 동일해야 합니다. 예를 들어 외부 포트 범위가 80:90이면 내부 포트 범위는 8080:8090입니다."", ""4. When you use a port range to create {resources}, multiple {resources} will be created in batches. "": "" {resources} 생성을 위해 포트 범위를 사용하면 배치로 다수의 {resources}가 생성됩니다."", ""5min"": ""5분"", ""8 to 16 characters, at least one uppercase letter, one lowercase letter, one number and one special character."": ""8 ~ 16 문자, 최소 대문자 한개, 소문자 한개, 숫자 한개, 특수 문자 한개"", ""8 to 16 characters, at least one uppercase letter, one lowercase letter, one number."": ""8 ~ 16 문자, 최소 대문자 한개, 소문자 한개, 숫자 한개, 특수 문자 한개"", ""A command that will be sent to the container"": ""컨테이너로 전송될 명령어"", ""A container with the same name already exists"": ""동일한 이름의 컨테이너가 존재합니다."", ""A dynamic scheduling algorithm that estimates the server load based on the number of currently active connections. The system allocates new connection requests to the server with the least number of current connections. Commonly used for long connection services, such as database connections and other services."": ""동적 스케쥴링 알고리즘은 현재 연결된 커넥션 수로 서버 로드를 예측합니다. 시스템은 최소 연결을 가진 서버로 새로운 연결을 할당합니다. 데이터베이스 연결 및 다른 서비스 처럼 오래 지속되는 연결을 갖는 서비스에 활용됩니다."", ""A host aggregate can be associated with at most one AZ. Once the association is established, the AZ cannot be disassociated."": ""호스트 집합은 한개의 AZ와 결합될 수 있습니다. 결합되고 나면 AZ는 분리될 수 없습니다."", ""A public container will allow anyone to use the objects in your container through a public URL."": ""퍼블릭 컨테이너는 퍼블릭 URL을 통해 컨테이너 내부의 객체를 사용할 수 있습니다."", ""A snapshot is an image which preserves the disk state of a running instance, which can be used to start a new instance."": ""스냅샷은 실행중인 인스턴의 디스크 상태를 보존하거나 새로운 인스턴스를 시작할 수 있는 이미지입니다."", ""A template is a YAML file that contains configuration information, please enter the correct format."": ""템플릿은 설정 정보를 포함한 YAML 파일입니다. 올바른 형식으로 입력해주세요."", ""A template is a YAML file that contains configuration information."": ""템플릿은 설정 정보를 포한한 YAML 파일입니다."", ""ADMINISTRATOR"": ""ADMINISTRATOR"", ""ADOPT COMPLETE"": ""적용 완료"", ""AH"": ""AH"", ""AKI - Amazon kernel image format"": ""AKI - 아마존 커널 이미지 형식"", ""AMI - Amazon server image format"": ""AMI - 아마존 서버 이미지 형식"", ""ANY"": ""ANY"", ""API Address"": ""API 주소"", ""ARI - Amazon ramdisk image format"": ""ARI - Amazon 램디스크 이미지 형식"", ""ARM Architecture"": ""ARM 아키텍처"", ""Abandon Stack"": ""스택"", ""Abandoning this stack will preserve the resources deployed by the stack."": ""스택을 중지하면 스택에 의해 배포된 리소들은 보존됩니다."", ""Abort Upload"": ""업로드 중지"", ""Access Control"": ""액세스 제어"", ""Access Key"": ""액세스 키"", ""Access Level"": ""액세스 수준"", ""Access Rules Status"": ""접근 규칙 상태"", ""Access To"": ""접근"", ""Access Type"": ""접근 유형"", ""Access Type Setting"": ""접근 유형 설정"", ""Add Access Rule"": ""접근 규칙 추가"", ""Add Custom Metadata"": ""사용자 메타데이터 추가"", ""Add Data Disks"": ""데이터 디스크 추가"", ""Add Environment Variable"": ""환경 변수 추가"", ""Add Exposed Ports"": ""노출 포트 추가"", ""Add External Members"": ""외부 멤버 추가"", ""Add Extra Info"": ""추가 사양 정보"", ""Add Extra Spec"": ""추가 사양 추가"", ""Add IP"": ""IP 추가"", ""Add Label"": ""라벨 추가"", ""Add NUMA Node"": ""NUMA 노드 추가"", ""Add Property"": ""속성 추가"", ""Add Virtual LAN"": ""가상 LAN 추가"", ""Add hosts to the aggregate or remove hosts from it. Hosts can be in multiple aggregates."": ""집합(Aggregate)에 호스트를 추가하거나 제거한다. 호스트는 여러 집합(Aggregate)에 존재할 수 있다."", ""Add scheduler hints"": ""스케쥴러 힌트 추가"", ""Additional Labels"": ""추가 레이블"", ""Additional routes announced to the instance, one entry per line(e.g. 192.168.200.0/24,10.56.1.254)"": ""인스턴스에 추가적인 경로가 알림됨. 라인당 한개의 엔트리(예. 192.168.200.0/24,10.56.1.254)"", ""Additional routes announced to the instance, one entry per line(e.g. {ip})"": ""인스턴스에 추가적인 경로가 알림됨. 라인당 한개의 엔트리(예. {ip})"", ""Address"": ""주소"", ""Address Record"": ""주소 레코드"", ""Admin State Up"": ""관리자 상태 활성화"", ""Admin Status"": ""관리자 상태"", ""Administrator"": ""관리자"", ""Adopt Complete"": ""적용 완료"", ""Adopt Failed"": ""적용 실패"", ""Adopt In Progress"": ""적용 진행중"", ""Advanced"": ""고급"", ""Advanced Params"": ""고급 매개변수"", ""Affiliated Domain"": ""제휴 도메인"", ""Affinity"": ""어피니티"", ""Affinity (mandatory):"": ""어피니티 (필수)"", ""Affinity (not mandatory):"": ""어피니티 (필수 아님)"", ""Afghanistan"": ""아프가니스탄"", ""After attaching interface, you may need to login the instance to update the network interface configuration and restart the network service."": ""인스턴스를 결합 후 네트워크 인터페이스 설정을 수정하기 위해 인스턴스에 로그인 후 네트워크 서비스를 재시작해야 합니다."", ""After disable the compute service, the new instance will not schedule to the compute node."": ""컴퓨트 서비스를 비활성화 후 새로운 인스턴스는 컴퓨트 노드에 스케쥴되지 않습니다"", ""After shelving, the instance will be shut down, resources will be released, and the snapshot will be saved to Glance. This will take about a few minutes, please be patient. You also can choose to unshelve to restore the instance."": ""보류(shelving)하게되면 인스턴스는 종료되고 자원은 해제되며 글랜스에 스냅샷이 저장됩니다. 몇분이 소요될 수 있습니다. 잠시만 기다려 주세요. 인스턴스를 복원하기 위해 보류를 해제할 수 있습니다."", ""After the share is expanded, the share cannot be reduced."": ""쉐어가 확장된 후 쉐어를 줄일 수 없습니다."", ""After the volume is expanded, the volume cannot be reduced."": ""볼륨이 확장된 후 볼륨을 줄일 수 없습니다."", ""Agree to force shutdown"": ""강제 종료 동의"", ""Albania"": ""알바니아"", ""Algeria"": ""알제리"", ""All data downloaded."": ""모든 데이터가 다운로드 되었습니다."", ""All network segments are indicated by \""*\"", not \""0.0.0.0/0\"""": ""모든 네트워크 세그먼트는 \""0.0.0.0/0\""이 아닌 \""*\""로 표시됩니다."", ""Always"": ""항상"", ""American Samoa"": ""미국령 사모아"", ""An object with the same name already exists"": ""동일한 이름의 객체가 이미 존재합니다."", ""Andorra"": ""안도라"", ""Angola"": ""앙골라"", ""Anguilla"": ""안굴라"", ""Anti-Affinity"": ""안티 어피니티"", ""Anti-affinity (mandatory):"": ""안티 어피니티(필수)"", ""Anti-affinity (not mandatory):"": ""안티 어피니티(필수 아님))"", ""Antigua and Barbuda"": ""안티구아와 바르부다"", ""Any"": ""Any"", ""Any(Random)"": ""Any(랜덤)"", ""Application Credentials"": ""애플리케이션 크레덴셜"", ""Application Template"": ""애플리케이션 템플릿"", ""Apply Latency(ms)"": ""지연 적용"", ""Applying"": ""적용중"", ""Arch"": ""아키텍처"", ""Are you sure to cancel transfer volume { name }? "": ""볼륨 { name } 전송을 취소합니까?"", ""Are you sure to delete instance { name }? "": ""인스턴스 { name }를 삭제 하시겠습니까?"", ""Are you sure to delete volume { name }? "": ""볼륨 { name }을 삭제 하시겠습니까?"", ""Are you sure to download data?"": ""데이터를 다운르도 하시겠습니까?"", ""Are you sure to forbidden domain { name }? Forbidden the domain will have negative effect, and users associated with the domain will not be able to log in if they are only assigned to the domain"": ""{ name } 도메인을 차단 하시겠습니까? 도메인을 차단하면 부정적인 영향을 줄 수 있으며 도메인에 할당된 사용자라면 로그인 할 수 없게 됩니다."", ""Are you sure to forbidden project { name }? Forbidden the project will have negative effect, and users associated with the project will not be able to log in if they are only assigned to the project"": ""{ name } 프로젝트를 차단하시겠습니까? 프로젝트를 차단하면 부정적인 영향을 줄 수 있으며 프로젝트에 할당된 사용자라면 로그인 할 수 없게 됩니다."", ""Are you sure to forbidden user { name }? Forbidden the user will not allow login in "": ""{ name } 사용자를 차단하시겠습니까? 사용자를 차단하면 로그인이 허용되지 않습니다."", ""Are you sure to jump directly to the console? The console will open in a new page later."": ""콘솔로 이동하시겠습니까? 콘솔은 새 창에서 열리게됩니다."", ""Are you sure to shelve instance { name }? "": ""{ name } 인스턴스를 보관하시겠습니까?"", ""Are you sure to { action } {name}?"": ""{ action } { name}을(를) 진행하시겠습니까?"", ""Are you sure to {action} (instance: {name})?"": ""{ action } (인스턴스: { name })을(를) 진행하시겠습니까?"", ""Are you sure to {action}?"": ""{ action } 을 실행하시겠습니까?="", ""Are you sure to {action}? (Record Set: {name} - {id})"": ""{ action }을(를) 진행하시겠습니까? (레코드 셋: { name } - { id })"", ""Are you sure to {action}? (Zone: {name})"": ""{ action }을(를) 진행하시겠습니까? (존: { name })"", ""Argentina"": ""아르헨티나"", ""Armenia"": ""아르메니아"", ""Aruba"": ""아루바"", ""Associate Network"": ""네트워크 연결"", ""Associations"": ""결합"", ""Attach Instance"": ""인스턴스 연결"", ""Attach Network"": ""네트워크 연결"", ""Attach USB"": ""USB 연결"", ""Attached Device"": ""연결된 디바이스"", ""Attachments Info"": ""첨부 정보"", ""Attributes"": ""속성"", ""Australia"": ""호주"", ""Austria"": ""오스트리아"", ""Auth Algorithm"": ""인증 알고리즘"", ""Auth Key"": ""인증 키"", ""Auto"": ""자동"", ""Auto Healing"": ""자동 힐링"", ""Auto Inspect"": ""자동 검사"", ""Auto Scaling"": ""자동 확장"", ""Auto allocate mac address"": ""MAC 주소 자동 할당"", ""Auto scaling feature will be enabled"": ""자동 확장 기능 활성화됩니다."", ""Automatically Assigned Address"": ""자동 할당된 주소"", ""Automatically repair unhealhty nodes"": ""비정상 노드 자동 복구"", ""Availability Zone"": ""가용 영역"", ""Availability Zone Hints"": ""가용 영역 힌트"", ""Availability Zone Info"": ""가용 영역 정보"", ""Availability Zone Name"": ""가용 영역 명"", ""Availability Zones"": ""가용 영역"", ""Availability zone refers to a physical area where power and network are independent of each other in the same area. In the same region, the availability zone and the availability zone can communicate with each other in the intranet, and the available zones can achieve fault isolation."": ""가용영역은 동일한 지역에서 서로 다른 전원 및 네트워크를 가진 물리적인 영역을 의미합니다. 동일한 영역에서 가용 영역과 가용 영역은 인터넷을 통해 연결될 수 있으며 가용영역은 장애를 격리 시킬수 있습니다. "", ""Available Zone"": ""가용 영역"", ""Average PGs per OSD"": ""OSD당 평균 PG"", ""Awaiting Transfer"": ""전송 대기 중"", ""Azerbaijan"": ""아제르바이젠"", ""BLOCK I/O(B)"": ""BLOCK I/O(B)"", ""Back End"": ""끝으로 가기"", ""Backend"": ""백엔드"", ""Backend Name"": ""백엔드 명"", ""Backing Up"": ""백업 중"", ""Backup Detail"": ""백업 파일 상세"", ""Backup File"": ""백업 파일"", ""Backup File Location"": ""백업 파일 위치"", ""Backup Mode"": ""백업 모드"", ""Backups"": ""백업"", ""Bad Gateway (code: 502) "": ""잘못된 게이트웨이(코드: 502)"", ""Bahamas"": ""바하마제도"", ""Bahrain"": ""바레인"", ""BandWidth Limit Egress"": ""이그레스 대역폭 제한"", ""BandWidth Limit Ingress"": ""인그레스 대역폭 제한"", ""Bandwidth limit"": ""대역폭 제한"", ""Bangladesh"": ""방글라데시"", ""Barbados"": ""바베이도스"", ""Bare Metal Enroll"": ""베어 메탈 등록"", ""Bare Metal Node Detail"": ""베어메탈 노드 상세"", ""Bare Metal Nodes"": ""베어메탈 노드"", ""BareMetal Parameters"": ""베어메탈 파라미터"", ""Basic Parameters"": ""기본 파라미터"", ""Batch Allocate"": ""배치 할당"", ""Belarus"": ""벨라루스"", ""Belgium"": ""벨기에"", ""Belize"": ""벨리즈"", ""Benin"": ""베냉"", ""Bermuda"": ""버뮤다"", ""Bhutan"": ""부탄"", ""Big Data"": ""빅 데이터"", ""Bind Device"": ""디바이스 결합"", ""Bind Device Type"": ""디바이스 유형 결합"", ""Bind Resource"": ""리소스 결합"", ""Bind Resource Name"": ""리소스 명 결합"", ""Binding"": ""결합"", ""Binding Groups"": ""그룹 결합"", ""Binding Instance"": ""인스턴스 결합"", ""Binding Profile"": ""프로파일 결합"", ""Binding Users"": ""사용자 결합"", ""Blank Volume"": ""빈 볼륨"", ""Block Device Mapping"": ""블록 디바이스 매핑"", ""Block Migrate"": ""블록 마이그레션"", ""Block Storage Services"": ""블록 스토리지 서비스"", ""Blocked"": ""차단"", ""Bolivia"": ""볼리비아"", ""Boot Device"": ""부트 디바이스"", ""Boot Interface"": ""부트 인터페이스"", ""Bosnia and Herzegovina"": ""보스니아 및 헤르체고비나"", ""Both of Frontend and Backend"": ""프론트엔드 및 백엔드"", ""Botswana"": ""보트스와나"", ""Brazil"": ""브라질"", ""British Indian Ocean Territory"": ""영국령 인도양 식민지"", ""Brunei Darussalam"": ""브루나이 다루살람"", ""Build"": ""빌드"", ""Building"": ""빌딩"", ""Bulgaria"": ""불가리아"", ""Burkina Faso"": ""부르키나 파소"", ""Burst limit"": ""버스티 제한"", ""Burundi"": ""부룬디"", ""CA Certificate"": ""CA 인증서"", ""CA Certificates"": ""CA 인증서"", ""CHECK COMPLETE"": ""검사 완료"", ""CIDR"": ""CIDR"", ""CIDR Format Error(e.g. 192.168.0.0/24, 2001:DB8::/48)"": ""CIDR 형식 오류(예. 192.168.0.0/24, 2001:DB8::/48)"", ""CIFS"": ""CIFS"", ""CMD"": ""CMD"", ""COE"": ""COE"", ""CPU"": ""CPU"", ""CPU %"": ""CPU %"", ""CPU (Core)"": ""CPU (Core)"", ""CPU Arch"": ""CPU 아키텍처"", ""CPU Cores"": ""CPU 코어"", ""CPU Thread Policy"": ""CPU 쓰레드 정책"", ""CPU Usage(%)"": ""CPU 사용량(%)"", ""CPU Usages (Core)"": ""CPU 사용량 (Core)"", ""CPU value is { cpu }, NUMA CPU value is { totalCpu }, need to be equal. "": ""CPU 값은 { cpu }, NUMA CPU 값은 { totalCpu }, 동일해야 합니다."", ""CPU(Core)"": ""CPU(Core)"", ""CREATE COMPLETE"": ""생성 완료"", ""CREATE FAILED"": ""생성 실패"", ""CREATE IN PROGRESS"": ""생성 진행중"", ""Cache Service"": ""캐시서비스"", ""Cameroon"": ""Cameroon"", ""Can add { number } {name}"": ""{number} {name}을 추가"", ""Canada"": ""Canada"", ""Cancel"": ""취소"", ""Cancel Download"": ""다운로드 취소"", ""Cancel Select"": ""선택 취소"", ""Cancel Transfer"": ""전송 취소"", ""Cancel download successfully."": ""다운로드를 취소했습니다."", ""Cancel upload successfully."": ""업로드를 취소했습니다."", ""Canonical Name Record"": ""CNAME 레코드"", ""Capacity & Type"": ""용량 & 유형"", ""Capacity (GiB)"": ""용량 (GiB)"", ""Cape Verde"": ""Cape Verde"", ""Capsule Detail"": ""캡슐 세부 정보"", ""Capsule Type"": ""캡슐 유형"", ""Capsules"": ""캡슐"", ""Cascading deletion"": ""연쇄 삭제"", ""Cast Rules To Read Only"": ""읽기 전용 규칙 정하기"", ""Category"": ""카테고리"", ""Cayman Islands"": ""Cayman Islands"", ""CentOS"": ""CentOS"", ""Central African Republic"": ""Central African Republic"", ""CephFS"": ""CephFS"", ""Cephx"": ""Cephx"", ""Cert"": ""인증서"", ""Certificate Authority Authorization Record"": ""CAA 레코드"", ""Certificate Content"": ""인증서 내용"", ""Certificate Detail"": ""인증서 세부 정보"", ""Certificate Name"": ""인증서 이름"", ""Certificate Type"": ""인증서 유형"", ""Certificates"": ""인증서"", ""Chad"": ""Chad"", ""Change Password"": ""비밀번호 변경"", ""Change Type"": ""유형 변경"", ""Change password"": ""비밀번호 변경"", ""Change type"": ""유형 변경"", ""Changed Node Count"": ""변경된 노드 수"", ""Channel"": ""채널"", ""Chassis ID"": ""섀시 ID"", ""Check Can Live Migrate Destination"": ""목적지의 라이브 마이그레이션 가능 여부 확인"", ""Check Can Live Migrate Source"": ""출발지의 라이브 마이그레이션 가능 여부 확인"", ""Check Complete"": ""완료 확인"", ""Check Failed"": ""실패 확인"", ""Check In Progress"": ""진행중 확인"", ""Checksum"": ""체크섬"", ""Chile"": ""Chile"", ""China"": ""China"", ""Choose a Network Driver"": ""네트워크 드라이버 선택"", ""Choose a host to live migrate instance to. If not selected, the scheduler will auto select target host."": ""인스턴스를 라이브 마이그레이션할 호스트를 선택합니다. 선택하지 않으면, 스케줄러가 대상 호스트를 자동으로 선택합니다."", ""Choose a host to migrate instance to. If not selected, the scheduler will auto select target host."": ""인스턴스를 마이그레이션할 호스트를 선택합니다. 선택하지 않으면, 스케줄러가 대상 호스트를 자동으로 선택합니다."", ""Choosing a QoS policy can limit bandwidth and DSCP"": ""QoS 정책을 선택하면 대역폭과 DSCP가 제한될 수 있습니다."", ""Christmas Island"": ""Christmas Island"", ""Cidr"": ""CIDR"", ""Cinder Service"": ""Cinder 서비스"", ""Cipher"": ""암호"", ""Clean Failed"": ""실패 정리"", ""Clean Wait"": ""대기 정리"", ""Cleaning"": ""정리"", ""Clear Gateway"": ""게이트웨이 지우기"", ""Clear selected"": ""선택 지우기"", ""Click To View"": ""보려면 클릭"", ""Click here for filters."": ""필터를 보려면 여기를 클릭하세요."", ""Click to Upload"": ""업로드하려면 클릭"", ""Click to show detail"": ""세부 정보를 보려면 클릭"", ""Close External Gateway"": ""외부 게이트웨이 닫기"", ""Close all notifications."": ""모든 알림 닫습니다."", ""Close external gateway"": ""외부 게이트웨이 닫기"", ""Cloud"": ""클라우드"", ""Cluster Detail"": ""클러스터 세부 정보"", ""Cluster Distro"": ""클러스터 배포판"", ""Cluster Info"": ""클러스터 정보"", ""Cluster Management"": ""클러스터 관리"", ""Cluster Name"": ""클러스터 이름"", ""Cluster Network"": ""클러스터 네트워크"", ""Cluster Template"": ""클러스터 템플릿"", ""Cluster Template Detail"": ""클러스터 템플릿 세부 정보"", ""Cluster Template Name"": ""클러스터 템플릿 이름"", ""Cluster Templates"": ""클러스터 템플릿"", ""Cluster Type"": ""클러스터 유형"", ""Clusters"": ""클러스터"", ""Clusters Management"": ""클러스터 관리"", ""Cocos (Keeling) Islands"": ""Cocos (Keeling) Islands"", ""Code"": ""코드"", ""Cold Migrate"": ""콜드 마이그레이션"", ""Colombia"": ""Colombia"", ""Command"": ""명령어"", ""Command to run to check health"": ""health 체크를 위해 실행할 명령어"", ""Command was successfully executed at container {name}."": ""명령어가 {name} 컨테이너에서 성공적으로 실행되었습니다."", ""Commas ‘,’ are not allowed to be in a tag name in order to simplify requests that specify lists of tags"": ""쉼표 ','는 태그 목록을 지정하는 요청을 단순화하기 위해 태그 이름에 포함될 수 없습니다."", ""Commit Latency(ms)"": ""커밋 지연 시간(ms)"", ""Common Server"": ""공용 서버"", ""Comoros"": ""Comoros"", ""Compute"": ""Compute"", ""Compute Hosts"": ""Compute 호스트"", ""Compute Live Migration"": ""Compute 라이브 마이그레이션"", ""Compute Live Resize Instance"": ""Compute 인스턴스 라이브 크기 조정"", ""Compute Node status"": ""Compute 노드 상태"", ""Compute Optimized"": ""Compute 최적화"", ""Compute Optimized Info"": ""Compute 최적화 정보"", ""Compute Optimized Type"": ""Compute 최적화 유형"", ""Compute Optimized Type with GPU"": ""Compute 최적화 GPU 유형"", ""Compute Pause Instance"": ""Compute 인스턴스 중지"", ""Compute Reboot Instance"": ""Compute 인스턴스 재부팅"", ""Compute Resume Instance"": ""Compute 인스턴스 재개"", ""Compute Service"": ""Compute 서비스"", ""Compute Services"": ""Compute 서비스"", ""Compute Start Instance"": ""Compute 인스턴스 시작"", ""Compute Stop Instance"": ""Compute 인스턴스 정지"", ""Compute Suspend Instance"": ""Compute 인스턴스 중지"", ""Compute Unpause Instance"": ""Compute 인스턴스 재개"", ""Conductor Live Migrate Instance"": ""Conductor 인스턴스 라이브 마이그레이션"", ""Conductor Live Resize Instance"": ""Conductor 인스턴스 라이브 크기 조정"", ""Conductor Migrate Server"": ""Conductor 서버 마이그레이션"", ""Config Overview"": ""설정 개요"", ""Configuration"": ""설정"", ""Configuration Detail"": ""설정 세부 정보"", ""Configuration Group"": ""설정 그룹"", ""Configuration Group ID/Name"": ""설정 그룹 ID/이름"", ""Configuration Groups"": ""설정 그룹"", ""Configuration Update"": ""설정 업데이트"", ""Configured Disk (GiB)"": ""설정된 디스크 (GiB)"", ""Configured Memory (GiB)"": ""설정된 메모리 (GiB)"", ""Confirm Config"": ""설정 확인"", ""Confirm Resize or Migrate"": ""크기 조정 또는 마이그레이션 확인"", ""Confirm Shared Key"": ""공유 키 확인"", ""Confirming Resize or Migrate"": ""크기 조정 또는 마이그레이션 확인"", ""Connect Subnet"": ""서브넷 연결"", ""Connect router"": ""라우터 연결"", ""Connected Threads"": ""연결된 스레드"", ""Connection Examples"": ""연결 예시"", ""Connection Information"": ""연결 정보"", ""Connection Limit"": ""연결 제한"", ""Consecutive failures needed to report unhealthy"": ""unhealthy 보고를 위한 연속적인 실패 횟수"", ""Console Interface"": ""콘솔 인터페이스"", ""Consumer"": ""소비자"", ""Container Creating"": ""컨테이너 생성"", ""Container Deleting"": ""컨테이너 삭제"", ""Container Detail"": ""컨테이너 세부 정보"", ""Container Format"": ""컨테이너 포맷"", ""Container Killing"": ""컨테이너 종료"", ""Container Pausing"": ""컨테이너 중지"", ""Container Rebooting"": ""컨테이너 재부팅"", ""Container Rebuilding"": ""컨테이너 리빌딩"", ""Container Restarting"": ""컨테이너 재시작"", ""Container Starting"": ""컨테이너 시작"", ""Container Status"": ""컨테이너 상태"", ""Container Stopping"": ""컨테이너 정지"", ""Container Unpausing"": ""컨테이너 재개"", ""Container Version"": ""컨테이너 버전"", ""Containers CPU"": ""컨테이너 CPU"", ""Containers Disk (GiB)"": ""컨테이너 디스크 (GiB)"", ""Containers Info"": ""컨테이너 정보"", ""Containers Management"": ""컨테이너 관리"", ""Containers Memory (MiB)"": ""컨테이너 메모리 (MiB)"", ""Content Type"": ""내용 유형"", ""Control Location"": ""컨트롤 위치"", ""Cook Islands"": ""Cook Islands"", ""CoreOS"": ""CoreOS"", ""Costa Rica"": ""Costa Rica"", ""Cote D'Ivoire"": ""Cote D'Ivoire"", ""Crashed"": ""충돌됨"", ""Create Allowed Address Pair"": ""허용된 주소 쌍 생성"", ""Create Application Credentials"": ""애플리케이션 인증서 생성"", ""Create Bandwidth Limit Rule"": ""대역폭 제한 규칙 생성"", ""Create Bare Metal Node"": ""베어메탈 노드 생성"", ""Create Capsule"": ""캡슐 생성"", ""Create Certificate"": ""인증서 생성"", ""Create Cluster"": ""클러스터 생성"", ""Create Cluster Template"": ""클러스터 템플릿 생성"", ""Create Complete"": ""생성 완료"", ""Create Configurations"": ""설정 생성"", ""Create DSCP Marking Rule"": ""DSCP 표시 규칙 생성"", ""Create Database"": ""데이터베이스 생성"", ""Create Database Backup"": ""데이터베이스 백업 생성"", ""Create Database Instance"": ""데이터베이스 인스턴스 생성"", ""Create Default Pool"": ""디폴트 풀 생성"", ""Create Encryption"": ""암호화 생성"", ""Create Extra Spec"": ""추가 사양 생성"", ""Create Failed"": ""생성 실패"", ""Create Host Aggregate"": ""호스트 집계 생성"", ""Create IPsec Site Connection"": ""IPsec 사이트 연결 생성"", ""Create In Progress"": ""생성 진행중"", ""Create Ironic Instance"": ""Ironic 인스턴스 생성"", ""Create Keypair"": ""키페어 생성"", ""Create Listener"": ""리스너 생성"", ""Create Loadbalancer"": ""로드밸런서 생성"", ""Create New Network"": ""새로운 네트워크 생성"", ""Create Node"": ""노드 생성"", ""Create Port Forwarding"": ""포트 포워딩 생성"", ""Create Port Group"": ""포트 그룹 생성"", ""Create Record Set"": ""레코드셋 생성"", ""Create Share"": ""공유 생성"", ""Create Share Group"": ""공유 그룹 생성"", ""Create Share Group Type"": ""공유 그룹 유형 생성"", ""Create Share Metadata"": ""공유 메타데이터 생성"", ""Create Share Network"": ""공유 네트워크 생성"", ""Create Share Type"": ""공유 유형 생성"", ""Create Stack"": ""스택 생성"", ""Create Static Route"": ""정적 경로 생성"", ""Create Time"": ""시간 생성"", ""Create Transfer"": ""전송 생성"", ""Create VPN Endpoint Group"": ""VPN 엔드포인트 그룹 생성"", ""Create Virtual Adapter"": ""가상 어댑터 생성"", ""Create Volume Type"": ""볼륨 유형 생성 "", ""Create Zone"": ""Zone 생성"", ""Create a full backup, the system will automatically create a new backup chain, the full backup name is the backup chain name; Create an incremental backup, the system will automatically create an incremental backup under the newly created backup chain."": ""전체 백업을 생성하면, 시스템이 새 백업 체인을 자동으로 생성하고, 전체 백업 이름은 백업 체인 이름입니다. 증분 백업을 생성하면, 시스템이 새로 생성된 백업 체인 아래에 증분 백업을 자동으로 생성합니다."", ""Create host aggregate"": ""호스트 집계 생성"", ""Create ironic instance"": ""ironic 인스턴스 생성"", ""Create new AZ"": ""새로운 AZ 생성"", ""Create static route"": ""정적 경로 생성"", ""Create volume backup"": ""볼륨 백업 생성"", ""Created At"": ""생성된 위치"", ""Created Time"": ""생성된 시간"", ""Created Volumes"": ""생성된 볼륨"", ""Creating"": ""생성중"", ""Creating From Snapshot"": ""스냅샷에서 생성"", ""Creation Timeout (Minutes)"": ""생성 타임아웃 (분)"", ""Credential Type"": ""인증서 유형"", ""Croatia (local name: Hrvatska)"": ""Croatia (local name: Hrvatska)"", ""Cuba"": ""Cuba"", ""Current Availability Zones"": ""현재 AZ"", ""Current Compute Host"": ""현재 Compute 호스트"", ""Current Connections"": ""현재 연결"", ""Current Disk (GiB)"": ""현재 디스크 (GiB)"", ""Current Flavor"": ""현재 Flavor"", ""Current Host"": ""현재 호스트"", ""Current Interface"": ""현재 인터페이스"", ""Current Master Node Count"": ""현재 마스터 노드 수"", ""Current Node Count"": ""현재 노드 수"", ""Current Password"": ""현재 비밀번호"", ""Current Path: "": ""현재 경로"", ""Current Project"": ""현재 프로젝트"", ""Current Project Images"": ""현재 프로젝트 이미지"", ""Current Project Networks"": ""현재 프로젝트 네트워크"", ""Current Project QoS Policies"": ""현재 프로젝트 QoS 정책"", ""Current QoS policy name"": ""현재 QoS 정책 이름"", ""Current Status"": ""현재 상태"", ""Current Storage Backend"": ""현재 스토리지 백엔드"", ""Current data downloaded."": ""현재 데이터가 다운로드되었습니다."", ""Custom Properties Info"": ""사용자 정의 속성 정보"", ""Cut"": ""잘라내기"", ""Cut File"": ""파일 잘라내기"", ""Cyprus"": ""Cyprus"", ""Enabled Load Balancer for Master Nodes"": ""마스터 노드에 대해 로드밸런서 사용"", ""Enabled Network"": ""활성화된 네트워크"", ""Encapsulation Mode"": ""캡슐화 모드"", ""Encrypted"": ""암호화 됨"", ""Encryption"": ""암호화"", ""Encryption Algorithm"": ""암호화 알고리즘"", ""Encryption Info"": ""암호화 정보"", ""End Time"": ""종료 시간"", ""Endpoint Counts"": ""Endpoint 개수"", ""Engine ID"": ""엔진 ID"", ""Enroll"": ""등록"", ""Enter an integer value between 1 and 65535."": ""1과 65535 사이의 정수를 입력하세요."", ""Enter query conditions to filter"": ""필터링할 쿼리 조건을 입력하세요."", ""Entered: {length, plural, =1 {one character} other {# characters} }(maximum {maxCount} characters)"": ""입력됨: {length, plural, =1 {one character} other {# characters} }(최대 {maxCount} 글자수)"", ""Environment"": ""환경"", ""Environment Variable"": ""환경 변수"", ""Environment Variables"": ""환경 변수"", ""Error Extending"": ""확장 에러"", ""Event Time"": ""이벤트 시각"", ""Execute Command"": ""실행 명령어"", ""Execution Result"": ""실행 결과"", ""Existing Volume"": ""존재하는 볼륨"", ""Exit Policy"": ""종료 정책"", ""Expand"": ""확장"", ""Expand Advanced Options"": ""고급 옵션 보기"", ""Expired Time"": ""만료 시간"", ""Expires At"": ""만료 예정"", ""Export Location"": ""위치 내보내기"", ""Export Locations"": ""위치 내보내기"", ""Exposed Ports"": ""노출된 포트"", ""Extend Root Volume"": ""root 볼륨 확장"", ""Extend Share"": ""Share 확장"", ""Extending"": ""확장"", ""Extending Error"": ""확장 에러"", ""External Fixed IP"": ""외부 고정 아이피"", ""External Fixed IPs"": ""외부 고정 아이피"", ""External Network Info"": ""외부 네트워크 정보"", ""External Port/Port Range"": ""외부 포트 범위"", ""Extra Infos"": ""추가 정보"", ""Fail Rollback"": ""실패 롤백"", ""Failed"": ""실패함"", ""Fault"": ""장애"", ""File"": ""파일"", ""File System Free Space"": ""파일 시스템 Free 공간"", ""File URL"": ""파일 URL"", ""Files: {names}"": ""파일: {names}"", ""Fill In The Parameters"": ""매개 변수 입력"", ""Finish Resize"": ""Resize 완료"", ""First time edit automatically creates health monitor When pool does not have a health monitor"": ""Pool에 Heath monitor가 없을 때 처음 편집하면 Heath monitor가 자동으로 생성됩니다."", ""Fixed IP"": ""고정 IP"", ""Fixed Network"": ""고정 네트워크"", ""Fixed Subnet"": ""고정 서브넷"", ""Flavor of Master Nodes"": ""마스터 노드 Flavor"", ""Flavor of Nodes"": ""노드 Flavor"", ""Floating IP"": """", ""Floating IP Address"": ""Floating IP 주소"", ""Floating IP Enabled"": ""Floating IP 활성화됨"", ""Floating IPs"": ""Floating IP"", ""Floating Ip"": ""Floating IP"", ""Floating Ip Address"": ""Floating IP 주소"", ""Floating Ip Detail"": ""Floating IP 세부 정보"", ""Floating ip has already been associate, Please check Force release"": ""Floating ip가 이미 할당되었습니다. 강제 해제를 확인해 주세요."", ""Folder Detail"": ""폴더 세부 정보"", ""Folder Name"": ""폴더 이름"", ""For GPU type, you need to install GPU drivers in the instance operating system."": ""GPU 타입의 경우, 인스턴스 운영치제에 GPU 드라이버를 설치해야 합니다."", ""For GRE networks, valid segmentation IDs are 1 to 4294967295"": ""GRE 네트워크의 경우, 유효한 segmentation ID는 1에서 4294967295까지 입니다."", ""For VLAN networks, valid segmentation IDs are 1 to 4094"": ""VLAN 네트워크의 경우, 유효한 segmentation ID는 1에서 4094까지 입니다."", ""For VXLAN networks, valid segmentation IDs are 1 to 16777215"": ""VXLAN 네트워크의 경우, 유효한 segmentation ID는 1에서 16777215까지 입니다."", ""Forbidden"": ""금지된"", ""Forbidden Domain"": ""금지된 Domain"", ""Forbidden Project"": ""금지된 Project"", ""Forbidden User"": ""금지된 User"", ""Forbidden the domain will have a negative impact, all project and user in domain will be forbidden"": ""도메인이 금지되면 부정적인 영향을 미치고 도메인의 모든 프로젝트와 사용자가 제한됩니다."", ""Force Delete"": ""강제 삭제"", ""Force Delete Container"": ""강제 컨테이너 삭제"", ""Force Delete Share Instance"": ""강제 공유 인스턴스 삭제"", ""Force release"": ""강제 해제"", ""Forced Down"": ""강제 Down"", ""Forced Shutdown"": ""강제 Shutdown"", ""Forced shutdown may result in data loss or file system damage. You can also take the initiative to shut down and perform operations."": ""강제 종료 시 데이터가 손실되거나 파일 시스템이 손상될 수 있습니다. 주도적으로 종료하고 작업을 수행할 수도 있습니다."", ""Forgot your password?"": ""패스워드를 분실 하셨나요?"", ""Forward Slash ‘/’ is not allowed to be in a tag name"": ""슬래시 ‘/’는 태그 이름에 포함될 수 없습니다."", ""Frequent login failure will cause the account to be temporarily locked, please operate after 5 minutes"": ""로그인 실패가 잦으면 계정이 일시적으로 잠깁니다. 5분 후에 시도하세요."", ""GPU Count"": ""GPU 개수"", ""GPU Info"": ""GPU 정보"", ""GPU Model"": ""GPU 모델"", ""GPU Parameters"": ""GPU 파라미터"", ""GPU Type"": ""GPU 타입"", ""GPU pass-through will load GPU devices directly to the instance for use. VGPU is a GPU virtualization solution. GPU resources will be segmented and distributed to multiple instances for shared use."": ""GPU pass-through는 GPU 디바이스를 인스턴스에 직접 로드하여 사용합니다. VGPU는 GPU 가상화 솔루션입니다. GPU 리소스는 공유 사용을 위해 여러 인스턴스로 분할 및 분배됩니다."", ""Gateway Time-out (code: 504) "": ""Gateway 타임아웃 (code: 504)"", ""Gateway ip {gateway_ip} conflicts with allocation pool {pool}"": ""Gateway ip {gateway_ip}가 할당 pool {pool}과 충돌됩니다"", ""Get OpenRC file"": ""OpenRC 파일 받기"", ""Get Token"": ""토큰 받기"", ""Global Setting"": ""전역 세팅"", ""Grant Databases Access"": ""데이터베이스 접근 허용"", ""HTTP Version not supported (code: 505) "": ""HTTP 버전이 지원되지 않습니다. (code: 505} "", ""Hard Reboot"": ""강제 재부팅"", ""Hard Rebooting"": ""강제 재부팅"", ""Health Check Interval"": ""Health Check 간격"", ""Health Check Retries"": ""Health Check 재시도"", ""Health Check Timeout"": ""Health Check 타임아웃"", ""Health Checking Log"": ""Health Check 로그"", ""Health Monitor Delay"": ""Health Monitor 지연시간"", ""Health Monitor Detail"": ""Health Monitor 세부 정보"", ""Health Monitor Max Retries"": ""Health Monitor 최대 재시도 횟수"", ""Health Monitor Name"": ""Health Monitor 이름"", ""Health Monitor Timeout"": ""Health Monitor 타임아웃"", ""Health Monitor Type"": ""Health Monitor 타입"", ""HealthMonitor Type"": ""HealthMonitor 타입"", ""Healthy"": ""정상"", ""Heartbeat Timestamp"": ""Heartbeat 타임스템프"", ""Hello, {name}"": ""{name}, 안녕하세요"", ""Hidden"": ""숨겨짐"", ""Hide Advanced Options"": ""고급 옵션 숨기기"", ""Host Aggregate"": ""Host 집합"", ""Host Aggregates"": ""Host 집합"", ""Host Average Network IO"": ""Host 평균 네트워크 IO"", ""Host CPU Usage"": ""Host CPU 사용률"", ""Host Detail"": ""Host 상세 정보"", ""Host Disk Average IOPS"": ""Host 디스크 평균 IOPS"", ""Host Memory Usage"": ""HOST 메모리 사용률"", ""Host Routes Format Error(e.g. 192.168.200.0/24,10.56.1.254)"": ""Host Routes 형식 에러(e.g. 192.168.200.0/24,10.56.1.254)"", ""Host Routes Format Error(e.g. ::0a38:01fe/24,::0a38:01fe)"": ""Host Routes 형식 에러(e.g. ::0a38:01fe/24,::0a38:01fe)"", ""Hosts Detail"": ""Hosts 상세 정보"", ""Hypervisor Detail"": ""Hypervisor 상세 정보"", ""ICMP Code"": ""ICMP 코드"", ""ICMP Type/ICMP Code"": ""ICMP 타입/ICMP 코드"", ""IP Usage"": ""IP 사용률"", ""IP address allocation polls, one enter per line(e.g. 192.168.1.2,192.168.1.200)"": ""IP 주소 할당 풀, 한 줄에 하나씩 입력하세요. (e.g. 192.168.1.2,192.168.1.200)"", ""IP address allocation polls, one enter per line(e.g. {ip})"": ""IP 주소 할당 풀, 한 줄에 하나씩 입력하세요.(e.g. {ip})"", ""IPMI Address"": ""IPMI 주소"", ""IPMI Password"": ""IPMI 패스워드"", ""IPMI Privilege Level"": ""IPMI 권한 레벨"", ""IPMI Protocol Version"": ""IPMI 프로토콜 버전"", ""IPMI Username"": ""IPMI 계정명"", ""IPv4 Address"": ""IPv4 주소"", ""IPv6 Address"": ""IPv6 주소"", ""IPv6 Address Record"": ""IPv6 주소 레코드"", ""ISO - Optical disc image format"": ""ISO - 광디스크 이미지 포멧"", ""Identifier of the physical port on the switch to which node’s port is connected to"": ""노드의 포트가 연결된 스위치의 물리 포트 식별자"", ""If \""Enable\"" fails to roll back, the resource will be deleted after the creation fails; if \""Disable\"" fails to roll back, the resource will be retained after the creation fails."": ""만약 \""사용\""이 롤백에 실패하면 리소스는 생성 실패 후 삭제되고 \""사용 안 함\""이 롤백에 실패하면 리소스는 생성 실패 후에도 보존됩니다."", ""If OS is Linux, system will reset root password, if OS is Windows, system will reset Administrator password."": ""OS가 Linux인 경우 시스템은 루트 암호를 재설정하고, OS가 Windows인 경우 시스템은 관리자 암호를 재설정합니다."", ""If an instance is using this flavor, deleting it will cause the instance's flavor data to be missing. Are you sure to delete {name}?"": ""인스턴스가 해당 flavor를 사용하는 경우, 삭제하면 인스턴스의 flavor 정보가 유실됩니다. {name}을(를) 삭제하시겠습니까?"", ""If checked, the network will be enable."": ""이 옵션을 체크하면 네트워크가 활성화됩니다."", ""If exposed port is specified, this parameter will be ignored."": ""노출된 포트가 지정된 경우 이 매개 변수는 무시됩니다."", ""If it is an SNI type certificate, a domain name needs to be specified"": ""SNI 유형의 인증서인 경우 도메인 이름을 지정해야 합니다."", ""If it’s not set, the value of this in template will be used."": ""설정되지 않은 경우 템플릿의 값이 사용됩니다."", ""If no gateway is specified, the first IP address will be defaulted."": ""게이트웨이를 지정하지 않으면 첫 번째 IP 주소가 기본값이 됩니다."", ""If not provided, the roles assigned to the application credential will be the same as the roles in the current token."": ""제공되지 않은 경우 응용프로그램 자격 증명에 할당된 역할은 현재 토큰의 역할과 동일합니다."", ""If nova-compute on the host is disabled, it will be forbidden to be selected as the target host."": ""호스트에서 nova-compute가 비활성화되어 있으면 대상 호스트로 선택하는 것이 금지됩니다."", ""If set then all tenants will be able to see this share."": ""설정하면 모든 tenant가 이 share를 조회할 수 있습니다."", ""If the capacity of the disk is large,the type modify operation may takes several hours. Please be cautious."": ""디스크 용량이 큰 경우 유형 수정 작업이 몇 시간 걸릴 수 있습니다. 신중하세요."", ""If the listener has an SNI certificate installed, it cannot be removed. Please delete the listener or replace the SNI certificate"": ""listener에 SNI 인증서가 설치되어 있으면 삭제할 수 없습니다. listener를 삭제하거나 SNI 인증서를 교체하세요."", ""If the value is set to 0, it means unlimited"": ""값이 0으로 설정되어 있으면 무제한임을 의미합니다."", ""If the volume associated with the snapshot has changed the volume type, please modify this option manually; if the volume associated with the snapshot keeps the volume type unchanged, please ignore this option. (no need to change)."": ""스냅샷과 연결된 볼륨의 볼륨 유형이 변경된 경우, 이 옵션을 수동으로 수정하세요. 만약 스냅샷과 연결된 볼륨의 볼륨 유형이 변경되지 않는 경우 이 옵션을 무시하세요. (변경할 필요 없음)."", ""If this parameter is specified, Zun will create a security group with a set of rules to open the ports that should be exposed, and associate the security group to the container."": ""이 매개 변수가 지정된 경우 Zun은 노출되어야 하는 포트를 허용하는 rule을 포함한 Security Group을 생성하고, 해당 Security Group을 컨테이너에 연결합니다."", ""If you are not authorized to access any project, or if the project you are involved in has been deleted or disabled, contact the platform administrator to reassign the project"": ""프로젝트에 엑세스할 권한이 없거나 기존의 프로젝트가 삭제 또는 비활성화된 경우, 플랫폼 관리자에게 프로젝트 재할당을 문의하세요."", ""If you choose a port which subnet is different from the subnet of LB, please ensure connectivity between the two."": ""LB의 Subnet과 다른 Subnet의 포트를 선택할 경우, 두 서브넷 간의 연결 여부를 확인하세요."", ""If you do not fill in parameters such as cpus, memory_mb, local_gb, cpu_arch, etc., you can automatically inject the configuration and Mac address of the physical machine by performing the \""Auto Inspect\"" operation."": ""CPU, memory, local_gb, cpu_arch 등의 매개 변수를 입력하지 않으면 \""자동 검사\"" 작업을 수행하여 물리적 시스템의 구성 및 MAC 주소를 자동으로 넣을 수 있습니다."", ""If you still want to keep the disk data, it is recommended that you create a snapshot for the disk before deleting."": ""디스크의 데이터를 보존하려면 삭제하기 전에 디스크의 스냅샷을 생성하는 것을 권장합니다."", ""Image"": """", ""Image Backup"": ""Image 백업"", ""Image Detail"": ""Image 상세 정보"", ""Image Driver"": ""Image 드라이버"", ""Image Info"": ""Image 정보"", ""Image Name"": ""Image 이름"", ""Image Pulling"": ""Image 다운로드"", ""Image Size"": ""Image 크기"", ""Please input port and protocol"": ""포트와 프로토콜을 입력하세요."", ""Please input prefix"": ""접두사를 입력하세요."", ""Please input protocol number if it absent in select list."": ""선택 목록에 없으면 프로토콜 번호를 입력하세요."", ""Please input provider"": ""제공자를 입력하세요."", ""Please input snapshot name"": ""snapshot 이름을 입력하세요."", ""Please input transfer id"": ""전송 ID를 입력하세요."", ""Please input user name"": ""사용자 이름을 입력하세요."", ""Please input value"": ""값을 입력하세요."", ""Please input your Password!"": ""암호를 입력하세요!"", ""Please input your Username!"": ""사용자 이름을 입력하세요!"", ""Please input your current password!"": ""현재 암호를 입력하세요!"", ""Please input your password!"": ""암호를 입력하세요!"", ""Please input {label}"": ""{label}을(를) 입력하세요."", ""Please input {label}!"": ""{label}을(를) 입력하세요!"", ""Please make sure this IP address be available to avoid creating VM failure."": ""VM 생성 실패를 피하기 위해 IP 주소가 사용 가능한지 확인하세요."", ""Please make sure this IP address be available."": ""IP 주소가 사용 가능한지 확인하세요."", ""Please reasonably plan the network and subnet to which the virtual network card belongs."": ""가상 네트워크 카드가 속한 네트워크와 서브넷을 합리적으로 계획하세요."", ""Please save your token properly and it will be valid for {left}."": ""토큰을 적절히 저장하고 {left} 동안 유효합니다."", ""Please select"": ""선택하세요."", ""Please select a file"": ""파일을 선택하세요."", ""Please select a file with the suffix {types}"": ""{types} 확장자를 가진 파일을 선택하세요."", ""Please select a network!"": ""네트워크를 선택하세요!"", ""Please select a subnet!"": ""서브넷을 선택하세요!"", ""Please select a type!"": ""유형을 선택하세요!"", ""Please select availability zone"": ""가용 영역을 선택하세요."", ""Please select image driver"": ""이미지 드라이버를 선택하세요."", ""Please select item!"": ""항목을 선택하세요!"", ""Please select key"": ""키를 선택하세요."", ""Please select login type!"": ""로그인 유형을 선택하세요!"", ""Please select policy"": ""정책을 선택하세요."", ""Please select source"": ""소스를 선택하세요."", ""Please select type"": ""유형을 선택하세요."", ""Please select volume type"": ""볼륨 유형을 선택하세요."", ""Please select your Domain!"": ""도메인을 선택하세요!"", ""Please select your Region!"": ""지역을 선택하세요!"", ""Please select {label}!"": ""{label}을(를) 선택하세요!"", ""Please select {name} first"": ""{name}을(를) 먼저 선택하세요."", ""Please set CPU && Ram first."": ""먼저 CPU와 RAM을 설정하세요."", ""Please set MUNA"": ""MUNA를 설정하세요."", ""Please upload files smaller than { size }GiB on the page. It is recommended to upload files over { size }GiB using API."": ""페이지에서 { size }GiB보다 작은 파일을 업로드하세요. { size }GiB 이상의 파일은 API를 사용하여 업로드하는 것이 권장됩니다."", ""Pointer Record"": ""포인터 레코드"", ""Pool Algorithm"": ""풀 알고리즘"", ""Pool Description"": ""풀 설명"", ""Pool Detail"": ""풀 상세"", ""Pool ID"": ""풀 ID"", ""Pool Info"": ""풀 정보"", ""Pool Name"": ""풀 이름"", ""Pool Protocol"": ""풀 프로토콜"", ""Port Count"": ""포트 개수"", ""Port Detail"": ""포트 상세"", ""Port Forwardings"": ""포트 포워딩"", ""Port Group"": ""포트 그룹"", ""Port Groups"": ""포트 그룹"", ""Port Info"": ""포트 정보"", ""Port Range"": ""포트 범위"", ""Port Security"": ""포트 보안"", ""Port Security Enabled"": ""포트 보안 활성화됨"", ""Port Type"": ""포트 유형"", ""Ports are either single values or ranges"": ""포트는 단일 값 또는 범위일 수 있습니다."", ""Ports provide extra communication channels to your containers. You can select ports instead of networks or a mix of both, If the terminal port and the network are selected at the same time, note that the terminal port is not a terminal port of the selected network, and the container under the same network will only be assigned one IP address (The port executes its own security group rules by default)."": ""포트는 컨테이너에 추가 통신 채널을 제공합니다. 네트워크 대신 포트를 선택하거나 둘을 혼합하여 선택할 수 있습니다. 동시에 터미널 포트와 네트워크를 선택하면, 선택된 네트워크의 터미널 포트는 해당 네트워크의 터미널 포트가 아니며, 동일한 네트워크에 속한 컨테이너에는 하나의 IP 주소만 할당됩니다 (포트는 기본적으로 자체 보안 그룹 규칙을 실행합니다)."", ""Ports provide extra communication channels to your instances. You can select ports instead of networks or a mix of both (The port executes its own security group rules by default)."": ""포트는 인스턴스에 추가 통신 채널을 제공합니다. 네트워크 대신 포트를 선택하거나 둘을 혼합하여 선택할 수 있습니다 (포트는 기본적으로 자체 보안 그룹 규칙을 실행합니다)."", ""Power Off"": ""전원 끄기"", ""Power On"": ""전원 켜기"", ""Power State"": ""전원 상태"", ""Powering Off"": ""전원 끄는 중"", ""Powering On"": ""전원 켜는 중"", ""Pre Live Migration"": ""실시간 migration"", ""Pre-Shared Key must be the same with Confirm Shared Key."": ""사전 공유 키는 확인된 공유 키와 동일해야 합니다."", ""Pre-Shared Key(PSK) String"": ""사전 공유 키(PSK) 문자열"", ""Prefer"": ""선호"", ""Prefer(Thread siblings are preferred)"": ""선호(동일 스레드 그룹이 선호됩니다)"", ""Preferred"": ""선호됨"", ""Prefix"": ""접두사"", ""Prep Resize"": ""크기조정 준비"", ""Prepare Template"": ""템플릿 준비"", ""Previous"": ""이전"", ""Primary"": ""기본"", ""Progress"": ""진행"", ""Project Detail"": ""프로젝트 상세"", ""Project Scope (Project Name: Role Names)"": ""소속 프로젝트 (프로젝트 이름: 역할 이름)"", ""Promote"": ""확인필요"", ""Properties"": ""속성"", ""Protocol Type"": ""프로토콜 유형"", ""Provider"": ""제공자"", ""Provider Network Type"": ""제공자 네트워크 유형"", ""Provider Physical Network"": ""제공자 물리 네트워크"", ""Provision State"": ""프로비저닝 상태"", ""Provisioning Status"": ""프로비저닝 상태"", ""Public Access"": ""공개 접근"", ""Public Address"": ""공용 주소"", ""Published In"": ""발행 위치"", ""Published Out"": ""발행 외부"", ""QoS Detail"": ""QoS 상세"", ""QoS Policy Detail"": ""QoS 정책 상세"", ""QoS Spec"": ""QoS 스펙"", ""QoS Spec ID"": ""QoS 스펙 ID"", ""QoS Specs"": ""QoS 스펙"", ""Queued"": ""대기 중"", ""Queued To Apply"": ""적용 대기 중"", ""Queued To Deny"": ""거부 대기 중"", ""Quota exceeded"": ""할당량 초과"", ""Quota is not enough for extend share."": ""공유 확장에 충분한 할당량이 없습니다."", ""Quota is not enough for extend volume."": ""볼륨 확장에 충분한 할당량이 없습니다."", ""Quota of key pair means: the number of allowed key pairs for each user."": ""키 쌍의 할당량은 각 사용자에게 허용되는 키 쌍의 수를 의미합니다."", ""Quota: Insufficient quota to create resources, please adjust resource quantity or quota(left { quota }, input { input })."": ""리소스를 생성하기에 충분한 할당량이 없습니다. 리소스 수량이나 할당량을 조정해주세요 (남은 할당량: { quota }, 입력: { input })."", ""Quota: Insufficient { name } quota to create resources, please adjust resource quantity or quota(left { left }, input { input })."": ""{ name } 할당량이 부족하여 리소스를 생성할 수 없습니다. 리소스 수량이나 할당량을 조정해주세요 (남은 할당량: { left }, 입력: { input })."", ""Quota: Insufficient { name } quota to create resources."": ""{ name } 할당량이 부족하여 리소스를 생성할 수 없습니다."", ""Quota: Project quotas sufficient resources can be created"": ""프로젝트 할당량으로는 충분한 리소스를 생성할 수 있습니다."", ""RESTORE COMPLETE"": ""복원 완료"", ""RESUME COMPLETE"": ""재개 완료"", ""RESUME FAILED"": ""재개 실패"", ""ROLLBACK COMPLETE"": ""롤백 완료"", ""ROLLBACK FAILED"": ""롤백 실패"", ""ROLLBACK IN PROGRESS"": ""롤백 진행 중"", ""Raid Interface"": ""RAID 인터페이스"", ""Ram Size (GiB)"": ""RAM 크기 (GiB)"", ""Ram value is { ram }, NUMA RAM value is { totalRam }, need to be equal. "": ""Ram 값은 { ram }이며, NUMA RAM 값은 { totalRam }이어야 합니다. "", ""Ramdisk ID"": ""램디스크 ID"", ""Ramdisk Image"": ""램디스크 이미지"", ""Read and write"": ""읽기 및 쓰기"", ""Real Name"": ""실제 이름"", ""Reboot"": ""재부팅"", ""Reboot Container"": ""컨테이너 재부팅"", ""Reboot Database Instance"": ""데이터베이스 인스턴스 재부팅"", ""Reboot Instance"": ""인스턴스 재부팅"", ""Rebooting"": ""재부팅 중"", ""Rebuild"": ""재구성"", ""Rebuild Block Device Mapping"": ""블록 디바이스 매핑 재구성"", ""Rebuild Container"": ""컨테이너 재구성"", ""Rebuild Instance"": ""인스턴스 재구성"", ""Rebuild Spawning"": ""확인필요"", ""Rebuilding"": ""재구성 중"", ""Rebuilt"": ""재구성됨"", ""Recently a day"": ""최근 1일"", ""Record Sets"": ""레코드 세트"", ""Records"": ""레코드"", ""Recordset Detail"": ""레코드 세트 상세"", ""Recordsets Detail"": ""레코드 세트 상세"", ""Recover"": ""복구"", ""Recovering"": ""복구 중"", ""Recycle Bin"": ""휴지통"", ""Region"": ""지역"", ""Registry Enabled"": ""레지스트리 활성화됨"", ""Related Resources"": ""관련 리소스"", ""Release"": ""릴리스"", ""Release Fixed IP"": ""고정 IP 해제"", ""Remote Group Id"": ""원격 그룹 ID"", ""Remote IP Prefix"": ""원격 IP 접두사"", ""Remote Security Group"": ""원격 보안 그룹"", ""Remote Type"": ""원격 유형"", ""Remove"": ""제거"", ""Remove Network"": ""네트워크 제거"", ""Remove Router"": ""라우터 제거"", ""Rename"": ""이름 변경"", ""Rename is to copy the current file to the new file address and delete the current file, which will affect the creation time of the file."": ""이름 변경은 현재 파일을 새 파일 주소로 복사한 후 현재 파일을 삭제하는 것을 의미하며, 파일의 생성 시간에 영향을 줍니다."", ""Replication Change"": ""복제 변경"", ""Report Count"": ""보고서 수"", ""Request ID"": ""요청 ID"", ""Require"": ""필요"", ""Require(Need multithreading)"": ""필요 (다중 스레딩 필요)"", ""Required Data Disk"": ""필수 데이터 디스크"", ""Rescue"": ""복구"", ""Rescued"": ""복구됨"", ""Rescuing"": ""복구 중"", ""Reserved"": ""예약됨"", ""Reset Status"": ""상태 재설정"", ""Reset To Initial Value"": ""초기 값으로 재설정"", ""Reset failed, please retry"": ""재설정 실패, 다시 시도하세요"", ""Resize"": ""크기 조정"", ""Resize Cluster"": ""클러스터 크기 조정"", ""Resize Instance"": ""인스턴스 크기 조정"", ""Resize Volume"": ""볼륨 크기 조정"", ""Resized"": ""크기 조정됨"", ""Resizing or Migrating"": ""크기 조정 또는 마이그레이션 중"", ""Resource Class"": ""리소스 클래스"", ""Resource Class Properties"": ""리소스 클래스 속성"", ""Resource Not Found"": ""리소스를 찾을 수 없음"", ""Resource Pool"": ""리소스 풀"", ""Resource Status"": ""리소스 상태"", ""Resource Status Reason"": ""리소스 상태 이유"", ""Resource Type"": ""리소스 유형"", ""Resource Types"": ""리소스 유형"", ""Resources Synced"": ""동기화된 리소스"", ""Restart"": ""재시작"", ""Restart Container"": ""컨테이너 재시작"", ""Restart Database Service"": ""데이터베이스 서비스 재시작"", ""Restarting"": ""재시작 중"", ""Restore Backup"": ""백업 복원"", ""Restore From Snapshot"": ""스냅샷에서 복원"", ""Restore backup"": ""백업 복원"", ""Restore from snapshot"": ""스냅샷에서 복원"", ""Restoring"": ""복원 중"", ""Restoring Backup"": ""백업 복원 중"", ""Resume"": ""재개"", ""Resume Complete"": ""재개 완료"", ""Resume Failed"": ""재개 실패"", ""Resume In Progress"": ""재개 진행 중"", ""Resume Instance"": ""인스턴스 재개"", ""Resuming"": ""재개 중"", ""Retry times for restart on failure policy"": ""실패 정책에 따른 재시작 시도 횟수"", ""Retyping"": ""재입력"", ""Reunion"": ""재통합"", ""Reverse DNS Detail"": ""역 DNS 상세"", ""Reverse Detail"": ""확인필요"", ""Reverse Dns"": ""역 DNS"", ""Revert Resize or Migrate"": ""크기 조정 또는 마이그레이션 되돌리기"", ""Revert Resize/Migrate"": ""크기 조정 또는 마이그레이션 되돌리기"", ""Reverting"": ""되돌리는 중"", ""Reverting Error"": ""되돌리기 오류"", ""Reverting Resize or Migrate"": ""크기 조정 또는 마이그레이션 되돌리는 중"", ""Role Detail"": ""역할 상세"", ""Rollback Complete"": ""롤백 완료"", ""Rollback Failed"": ""롤백 실패"", ""Rollback In Progress"": ""롤백 진행 중"", ""Root Disk"": ""루트 디스크"", ""Root Disk (GiB)"": ""루트 디스크 (GiB)"", ""Root directory"": ""루트 디렉터리"", ""Router"": ""라우터"", ""Router Advertisements Mode"": ""확인필요"", ""Router Detail"": ""라우터 상세"", ""Router External"": ""라우터 외부"", ""Router ID"": ""라우터 ID"", ""Running"": ""실행 중"", ""Running Threads"": ""실행 중인 스레드"", ""Running Time"": ""실행 시간"", ""Runtime"": ""런타임"", ""SNAPSHOT COMPLETE"": ""스냅샷 완료"", ""SNAT Enabled"": ""SNAT 활성화됨"", ""SNI Certificate"": ""SNI 인증서"", ""SNI Enabled"": ""SNI 활성화됨"", ""SOURCE_IP"": ""소스 IP"", ""SSH Public Key Fingerprint"": ""SSH 공개 키 지문"", ""SSL Parsing Method"": ""SSL 구문 분석 방법"", ""Same subnet with LB"": ""로드 밸런서와 동일한 서브넷"", ""The instance architecture diagram mainly shows the overall architecture composition of the instance. If you need to view the network topology of the instance, please go to: "": ""인스턴스 아키텍처 다이어그램은 주로 인스턴스의 전체 아키텍처 구성을 보여줍니다. 인스턴스의 네트워크 토폴로지를 보려면 다음으로 이동하십시오: "", ""The instance deleted immediately cannot be restored"": ""즉시 삭제된 인스턴스는 복구할 수 없습니다"", ""The instance has been locked. If you want to do more, please unlock it first."": ""인스턴스가 잠겼습니다. 추가적인 작업을 위해 먼저 잠금을 해제 해 주세요."", ""The instance is not shut down, unable to restore."": ""인스턴스가 종료되지 않아, 복구할 수 없습니다."", ""The instance which is boot from volume will create snapshots for each mounted volumes."": ""볼륨에서 부팅되는 인스턴스는 마운트된 각 볼륨에 대한 스냅샷을 생성합니다."", ""The instances in the affinity group are allocated to the same physical machine as much as possible, and when there are no more physical machines to allocate, the normal allocation strategy is returned."": ""\""affinity group\""의 인스턴스는 가능한 한 동일한 물리적 시스템에 할당되며, 할당할 물리적 시스템이 더 이상 없을 경우 일반적인 할당 전략을 따르게 됩니다."", ""The instances in the affinity group are strictly allocated to the same physical machine. When there are no more physical machines to allocate, the allocation fails."": ""\""affinity group\""의 인스턴스는 동일한 물리적 시스템에만 할당됩니다. 할당할 물리적 시스템이 더 이상 없으면 할당이 실패합니다."", ""The instances in the anti-affinity group are allocated to different physical machines as much as possible. When there are no more physical machines to allocate, the normal allocation strategy is returned."": ""\""anti-affinity group\""의 인스턴스는 가능한 한 서로 다른 물리적 시스템에 할당됩니다. 할당할 물리적 시스템이 더 이상 없으면 일반적인 할당 전략을 따르게 됩니다."", ""The instances in the anti-affinity group are strictly allocated to different physical machines. When there are no more physical machines to allocate, the allocation fails."": ""\""anti-affinity group\""의 인스턴스는 서로 다른 물리적 시스템에만 할당됩니다. 할당할 물리적 시스템이 더 이상 없으면 할당이 실패합니다."", ""The ip is not within the allocated pool!"": ""해당 ip는 할당된 pool 안에 없습니다!"", ""The ip of external members can be any, including the public network ip."": ""외부 구성원의 IP 주소는 공용 네트워크 IP를 포함하여 어떤 것이든 가능합니다."", ""The key pair allows you to SSH into your newly created instance. You can select an existing key pair, import a key pair, or generate a new key pair."": ""key-pair는 새로 생성한 인스턴스에 SSH로 접속할 수 있도록 해줍니다. 기존의 key-pair를 선택하거나, key-pair를 가져오거나, 새로운 key-pair를 생성할 수 있습니다."", ""The kill signal to send"": ""전송 할 Kill 신호"", ""The limit of cluster instance greater than or equal to 1."": ""클러스터 인스턴스의 한도는 하나 이상입니다."", ""The maximum batch size is {size}, that is, the size of the port range cannot exceed {size}."": ""최대 batch 크기는 {size}입니다. 즉, 포트 범위의 크기는 {size}를 초과할 수 없습니다."", ""The maximum transmission unit (MTU) value to address fragmentation. Minimum value is 68 for IPv4, and 1280 for IPv6."": ""분할을 처리하기 위한 최대 전송 단위(MTU) 값입니다. IPv4의 경우 최소값은 68이며, IPv6의 경우 최소값은 1280입니다."", ""The min size is {size} GiB"": ""최소 크기는 {size} GiB입니다."", ""The name cannot be modified after creation"": ""생성 후에는 이름을 수정할 수 없습니다."", ""The name of the physical network to which a port is connected"": ""포트가 연결된 물리 네트워크의 이름"", ""The name should contain letter or number, the length is 1 to 16, characters can only contain \""0-9, a-z, A-Z, -, _.\"""": ""이름은 문자나 숫자를 포함해야 하고, 길이는 1~16자 사이여야 하며, 문자는 \""0-9, a-z, A-Z, -, _.\""만 포함할 수 있습니다."", ""The name should contain letter or number, the length is 2 to 64, characters can only contain \""0-9, a-z, A-Z, -, _.\"""": ""이름은 문자나 숫자를 포함해야 하고, 길이는 2~64자 사이여야 하며, 문자는 \""0-9, a-z, A-Z, -, _.\""만 포함할 수 있습니다."", ""The name should start with letter or number, and be a string of 2 to 255, characters can only contain \""0-9, a-z, A-Z, -, _, .\"""": ""이름은 문자나 숫자로 시작해야 하고, 2~255자 사이의 문자열이어야 하며, 문자는 \""0-9, a-z, A-Z, -, _, .\""만 포함할 수 있습니다."", ""The name should start with upper letter or lower letter, and be a string of 1 to 128, characters can only contain \""0-9, a-z, A-Z, \""-'_()[].:^\""."": ""이름은 대문자나 소문자로 시작해야 하고, 1~128자 사이의 문자열이어야 하며, 문자는 \""0-9, a-z, A-Z, \""-'_()[].:^\""만 포함할 수 있습니다."", ""The name should start with upper letter or lower letter, characters can only contain \""0-9, a-z, A-Z, -, _, .\"""": ""이름은 대문자나 소문자로 시작해야 하며, 문자는 \""0-9, a-z, A-Z, \""-'_()[].:^\""만 포함할 수 있습니다."", ""The name should start with upper letter, lower letter or chinese, and be a string of 1 to 128, characters can only contain \""0-9, a-z, A-Z, \""-'_()[].\""."": ""이름은 대문자, 소문자 또는 chinese로 시작해야하며, 1~128자의 문자열이어야합니다. 이름에 사용되는 문자는 \""0-9, a-z, A-Z, -, _, .\""만 포함할 수 있습니다."", ""The name should start with upper letter, lower letter or chinese, and be a string of 1 to 128, characters can only contain \""0-9, a-z, A-Z, \""-'_()[].:^\""."": ""이름은 대문자, 소문자 또는 chinese로 시작해야하며, 1~128자의 문자열이어야합니다. 이름에 사용되는 문자는 \""0-9, a-z, A-Z, \""-'_()[].:^\""만 포함할 수 있습니다."", ""The name should start with upper letter, lower letter or chinese, and be a string of 1 to 128, characters can only contain \""0-9, a-z, A-Z, \""-'_.\""."": ""이름은 대문자, 소문자 또는 chinese로 시작해야하며, 1~128자의 문자열이어야합니다. 이름에 사용되는 문자는 \""0-9, a-z, A-Z, \""-'_.\""만 포함할 수 있습니다."", ""The name should start with upper letter, lower letter or chinese, and be a string of 1 to 64, characters can only contain \""0-9, a-z, A-Z, \""-'_()[].^\""."": ""이름은 chinese, 대문자, 소문자로 시작해야 하고, 1~64자 사이의 문자열이어야 하며, 문자는 \""0-9, a-z, A-Z, \""-'_()[].^\""만 포함할 수 있습니다."", ""The name should start with upper letter, lower letter or chinese, and be a string of 3 to 63, characters can only contain \""0-9, a-z, A-Z, chinese, -, .\""."": ""이름은 대문자, 소문자, 또는 chinese로 시작해야 하며, 3~63자 사이의 문자열이어야 하며, 문자는 \""0-9, a-z, A-Z, chinese, -, .\""만 포함할 수 있습니다."", ""The name should start with upper letter, lower letter, and be a string of 1 to 128, characters can only contain \""0-9, a-z, A-Z, -, _\""."": ""이름은 대문자 또는 소문자로 시작해야 하며, 1~128자의 문자열이어야 합니다. 이름에 사용되는 문자는 \""0-9, a-z, A-Z, -, _\""만 가능합니다."", ""The name should start with upper letter, lower letter, and be a string of 2 to 255, characters can only contain \""0-9, a-z, A-Z, -, ., _\""."": ""이름은 대문자 또는 소문자로 시작해야 하며, 2~255자의 문자열이어야 합니다. 이름에 사용되는 문자는 \""0-9, a-z, A-Z, -, ., _\""만 가능합니다."", ""The name should start with upper letter, lower letter, and be a string of 3 to 63, characters can only contain \""0-9, a-z, A-Z, -\""."": ""이름은 대문자 또는 소문자로 시작해야 하며, 3~63자의 문자열이어야 합니다. 이름에 사용되는 문자는 \""0-9, a-z, A-Z, -\""만 가능합니다."", ""The new password cannot be identical to the current password."": ""새 비밀번호는 현재 비밀번호와 동일할 수 없습니다."", ""The no_proxy address to use for nodes in cluster"": ""클러스터의 노드에서 사용할 no_proxy 주소입니다."", ""The number of allowed key pairs for each user."": ""각 사용자별 허용되는 키 쌍(key pair) 수입니다."", ""The number of vCPU cores should not exceed the maximum number of CPU cores of the physical node. Otherwise it will cause fail to schedule to any physical node when creating instance."": ""vCPU 코어의 수는 물리적 노드의 최대 CPU 코어 수를 초과해서는 안 됩니다. 그렇지 않으면 인스턴스 생성 시 어떤 물리적 노드에도 스케줄링할 수 없는 문제가 발생합니다."", ""The number of virtual cpu for this container"": ""이 컨테이너의 가상 CPU 수"", ""The password must not be the same as the previous"": ""이전 비밀번호와 중복되지 않아야 합니다."", ""The password must not be the same as the previous two"": ""이전 두 개의 비밀번호와 중복되지 않아야 합니다."", ""The password must not be the same as the previous {num}"": ""이전 {num}개의 비밀번호와 중복되지 않아야 합니다."", ""The port created here will be automatically deleted when detach. If you need a reusable port, please go to the Virtual Adapter page to create and attach the port to instance."": ""여기서 생성된 포트는 분리될 때 자동으로 삭제됩니다. 재사용 가능한 포트가 필요한 경우 가상 어댑터 페이지로 이동하여 인스턴스에 연결하여 생성하십시오."", ""The private key content format is: with \""-----BEGIN RSA PRIVATE KEY-----\"" as the beginning,\""-----END RSA PRIVATE KEY-----\"" as the end, 64 characters per line, the last line does not exceed 64 characters, and there cannot be blank lines."": ""개인 키의 형식은 다음과 같습니다: 시작점으로 \""-----BEGIN RSA PRIVATE KEY-----\""를 사용하고 끝점으로 \""-----END RSA PRIVATE KEY-----\""를 사용하며, 한 줄당 64자로 구성되며 마지막 줄은 64자를 초과하지 않아야 하며, 빈 줄이 있으면 안 됩니다."", ""The private key of the certificate, the extension of the private key is \""key\"", you can directly enter the content of the private key file or upload a private key that conforms to the format document."": ""인증서의 개인 키는 확장자가 \""key\""인 개인 키입니다. 개인 키 파일의 내용을 직접 입력하거나 형식 문서에 맞는 개인 키를 업로드할 수 있습니다."", ""The resource class of the scheduled node needs to correspond to the resource class name of the flavor used by the ironic instance (for example, the resource class name of the scheduling node is baremetal.with-GPU, and the custom resource class name of the flavor is CUSTOM_BAREMETAL_WITH_GPU=1)."": ""예약된 노드의 자원 클래스는 ironic 인스턴스에서 사용하는 flavor의 자원 클래스 이름과 일치해야 합니다 (예: 예약된 노드의 자원 클래스 이름이 baremetal.with-GPU이고 플레이버의 사용자 정의 자원 클래스 이름이 CUSTOM_BAREMETAL_WITH_GPU=1인 경우)."", ""The resource has been deleted"": ""이 리소스는 삭제되었습니다."", ""The root and os_admin are default users and cannot be created!"": ""root와 os_admin은 기본 사용자로, 생성할 수 없습니다!"", ""The security group is similar to the firewall function and is used to set up network access control. "": ""security group은 방화벽 기능과 유사하며 네트워크 액세스 제어를 설정하는 데 사용됩니다."", ""The security group is similar to the firewall function for setting up network access control, or you can go to the console and create a new security group. (Note: The security group you selected will work on all virtual LANS on the instances.)"": ""security group은 방화벽 기능과 유사하며 네트워크 액세스 제어를 설정하는 데 사용됩니다. 또는 콘솔로 이동하여 새 security group을 만들 수 있습니다. (참고: 선택한 security group은 인스턴스의 모든 가상 LAN에서 작동합니다.)"", ""The selected VPC/ subnet does not have IPv6 enabled."": ""선택한 VPC/subnet에는 IPv6가 활성화되어 있지 않습니다."", ""The selected network has no subnet"": ""선택한 네트워크엔 서브넷이 존재하지 않습니다."", ""The selected project is different from the project to which the network belongs. That is, the subnet to be created is not under the same project as the network. Please do not continue unless you are quit sure what you are doing."": ""선택한 프로젝트가 네트워크가 속한 프로젝트와 다릅니다. 즉, 생성할 서브넷이 네트워크와 동일한 프로젝트에 속하지 않습니다. 확실하지 않은 경우 진행하지 마십시오."", ""The session has expired, please log in again."": ""세션이 만료되었습니다. 다시 로그인해주세요."", ""The shelved offloaded instance only supports immediate deletion"": ""저장된 인스턴스는 즉시 삭제만 지원합니다."", ""The size of the external port range is required to be the same as the size of the internal port range"": ""내부 포트 범위의 크기와 외부 포트 범위의 크기는 동일해야 합니다."", ""The start source is a template used to create an instance. You can choose an image or a bootable volume."": ""start source는 인스턴스를 생성하는 데 사용되는 템플릿입니다. 이미지나 부팅 가능한 볼륨을 선택할 수 있습니다."", ""The starting number must be less than the ending number"": ""시작 번호는 끝 번호보다 작아야 합니다."", ""The timeout for cluster creation in minutes."": ""클러스터 생성 제한 시간(분)입니다."", ""The timeout period of waiting for the return of the health check request, the check timeout will be judged as a check failure"": ""health check 요청의 반환을 기다리는 제한 시간. 점검 시간 초과는 점검 실패로 간주됩니다."", ""The total amount of data is { total }, and the interface can support downloading { totalMax } pieces of data. If you need to download all the data, please contact the administrator."": ""모든 데이터의 총량은 { total }이며, 인터페이스는 { totalMax }개의 데이터 다운로드를 지원합니다. 모든 데이터를 다운로드해야 하는 경우 관리자에게 문의하십시오."", ""The trait name of the flavor needs to correspond to the trait of the scheduling node; by injecting the necessary traits into the ironic instance, the computing service will only schedule the instance to the bare metal node with all necessary traits (for example: the trait of the scheduling node has HW_CPU_X86_VMX trait, and the flavor adds HW_CPU_X86_VMX, it can be scheduled to this node for necessary traits)."": ""스케줄링 노드의 특성 이름과 flavor의 특성 이름이 일치해야 합니다. Ironic 인스턴스에 필요한 특성을 삽입함으로써, 컴퓨팅 서비스는 모든 필요한 특성을 갖춘 베어메탈 노드로 인스턴스를 스케줄링합니다. (예: 스케줄링 노드의 특성에는 HW_CPU_X86_VMX 특성이 있고, flavor에 HW_CPU_X86_VMX를 추가하면 이 노드로 필요한 특성을 갖춘 인스턴스를 스케줄링할 수 있습니다)."", ""The trait of the scheduled node needs to correspond to the trait of the flavor used by the ironic instance; by injecting the necessary traits into the ironic instance, the computing service will only schedule the instance to the bare metal node with all the necessary traits (for example, the ironic instance which use the flavor that has HW_CPU_X86_VMX as a necessary trait, can be scheduled to the node which has the trait of HW_CPU_X86_VMX)."": ""예약된 노드의 특성은 Ironic 인스턴스에서 사용하는 flavor의 특성과 일치해야 합니다. 필요한 특성을 Ironic 인스턴스에 삽입함으로써, 컴퓨팅 서비스는 필요한 모든 특성을 갖춘 베어메탈 노드로만 인스턴스를 스케줄링합니다. 예를 들어, HW_CPU_X86_VMX를 필수 특성으로 가진 flavor를 사용하는 Ironic 인스턴스는 HW_CPU_X86_VMX 특성을 가진 노드로 스케줄링될 수 있습니다."", ""The unit suffix must be one of the following: Kb(it), Kib(it), Mb(it), Mib(it), Gb(it), Gib(it), Tb(it), Tib(it), KB, KiB, MB, MiB, GB, GiB, TB, TiB. If the unit suffix is not provided, it is assumed to be KB."": ""단위는 다음 중 하나여야 합니다: Kb(it), Kib(it), Mb(it), Mib(it), Gb(it), Gib(it), Tb(it), Tib(it), KB, KiB, MB, MiB, GB, GiB, TB, TiB. 단위가 제공되지 않으면 KB로 간주됩니다."", ""The user has been disabled, please contact the administrator"": ""사용자가 비활성화되었습니다. 관리자에게 문의하십시오."", ""The user needs to ensure that the input is a shell script that can run completely and normally."": ""사용자는 정상적으로 실행될 수 있는 셸 스크립트임을 보장해야 합니다."", ""The value of the upper limit of the range must be greater than the value of the lower limit of the range."": ""범위 상한값은 범위 하한값보다 커야합니다."", ""The volume associated with the backup is not available, unable to restore."": ""해당 백업과 연결된 볼륨을 사용할 수 없어 복원할 수 없습니다."", ""The volume status can be reset to in-use only when the previous status is in-use."": ""이전 상태가 in-use일 때에만, 볼륨 상태를 in-use로 재설정할 수 있습니다."", ""The volume type needs to be consistent with the volume type when the snapshot is created."": ""볼륨 타입은 스냅샷 생성 시의 볼륨 타입과 일치해야 합니다."", ""The volume type needs to set \""multiattach\"" in the metadata to support shared volume attributes."": ""공유 볼륨 속성을 지원하려면 메타데이터에 \""multiattach\""를 설정해야 합니다."", ""The working directory for commands to run in"": ""실행할 명령의 작업 디렉토리"", ""The {action} instruction has been issued, instance: {name}. \n You can wait for a few seconds to follow the changes of the list data or manually refresh the data to get the final display result."": ""{action} 명령이 {name} 인스턴스에 대해 실행되었습니다. 목록 데이터의 변경 사항을 확인하기 위해 몇 초를 기다리거나 수동으로 데이터를 새로 고쳐 최종 결과를 얻을 수 있습니다."", ""The {action} instruction has been issued. \n You can wait for a few seconds to follow the changes of the list data or manually refresh the data to get the final display result."": ""{action} 명령이 실행되었습니다. 목록 데이터의 변경 사항을 확인하려면 몇 초 기다리거나 수동으로 데이터를 새로 고쳐 최종 표시 결과를 얻을 수 있습니다."", ""The {name} has already been used by other {resource}({content}), please change."": ""{name}은(는) 이미 다른 {resource}({content})에서 사용 중입니다. 다른 이름으로 변경해주세요."", ""The {name} {ports} have already been used, please change."": ""해당 {name} {ports}는 이미 사용 중입니다. 변경해주세요."", ""There are resources that cannot {action} in the selected resources, such as:"": ""선택한 자원 중에서 {action}할 수 없는 자원이 있습니다. 예):"", ""There are resources that cannot {action} in the selected resources."": ""선택한 리소스 중에서 {action} 할 수 없는 리소스가 있습니다."", ""There are resources under the project and cannot be deleted."": ""프로젝트에 속한 리소스가 있어서 삭제할 수 없습니다."", ""There is currently no file to paste."": ""현재 파일을 붙여넣을 대상이 없습니다."", ""This operation creates a security group with default security group rules for the IPv4 and IPv6 ether types."": ""이 작업은 IPv4 및 IPv6 이더넷 유형에 대한 기본 보안 그룹 규칙이 포함된 보안 그룹을 만듭니다."", ""This service will automatically query the configuration (CPU, memory, etc.) and mac address of the physical machine, and the ironic-inspector service will automatically register this information in the node information."": ""이 서비스는 자동으로 물리적 머신의 구성(CPU, 메모리 등)과 MAC 주소를 쿼리하며, ironic-inspector 서비스는 이 정보를 노드 정보에 자동으로 등록합니다."", ""This will delete all child objects of the load balancer."": ""이 작업은 로드 밸런서의 모든 하위 객체를 삭제합니다."", ""Threads Activity Trends"": ""Thread Activity Trends"", ""Time Interval: "": ""Time Interval"", ""Time To Live"": ""Time To Live"", ""Time To Live in seconds."": ""Time To Live(초)."", ""Time between running the check in seconds"": ""검사 간격(초)"", ""Timeout(Minute)"": ""타임아웃(분)"", ""Timeout(s)"": ""타임아웃(초)"", ""To open"": ""열기"", ""Today CPU usage > 80% alert"": ""오늘 CPU 사용량 > 80% 경고"", ""Today Memory usage > 80% alert"": ""오늘 메모리 사용량 > 80% 경고"", ""Togo"": ""Togo"", ""Tokelau"": ""Tokelau"", ""Tonga"": ""Tonga"", ""Too many disks mounted on the instance will affect the read and write performance. It is recommended not to exceed 16 disks."": ""인스턴스에 마운트된 디스크가 많을수록 읽기/쓰기 성능에 영향을 미칩니다. 16개 이상의 디스크를 사용하지 않는 것이 좋습니다."", ""Topic"": ""Topic"", ""Total"": ""전체"", ""Total Capacity"": ""전체 용량"", ""Total Connections"": ""전체 연결"", ""Total Consumers"": ""전체 고객"", ""Total Containers"": ""전체 컨테이너"", ""Total Exchanges"": ""전체 교환"", ""Total IPs"": ""전체 IP"", ""Total Queues"": ""전체 큐"", ""Total Ram"": ""전체 RAM"", ""Total {total} items"": ""전체 {total} 항목"", ""Trait Properties"": ""Trait Properties"", ""Traits"": ""Traits"", ""Transfer Name"": ""이전 이름"", ""Transferred"": ""전송됨"", ""Transform Protocol"": ""프로토콜 변환"", ""Trinidad and Tobago"": ""Trinidad and Tobago"", ""True"": ""True"", ""Tunisia"": ""Tunisia"", ""Turkey"": ""Turkey"", ""Turkmenistan"": ""Turkmenistan"", ""Turks and Caicos Islands"": ""Turks and Caicos Islands"", ""Tuvalu"": ""Tuvalu"", ""Two-way authentication"": ""Two-way authentication"", ""UDP"": ""UDP"", ""UDPLite"": ""UDPLite"", ""UNHEALTHY"": ""UNHEALTHY"", ""UNKNOWN"": ""UNKNOWN"", ""UPDATE COMPLETE"": ""UPDATE COMPLETE"", ""UPDATE FAILED"": ""UPDATE FAILED"", ""UPDATE IN PROGRESS"": ""UPDATE IN PROGRESS"", ""USB Info"": ""USB Info"", ""USB Parameters"": ""USB Parameters"", ""USER"": ""USER"", ""UUID"": ""UUID"", ""Ubuntu"": ""Ubuntu"", ""Uganda"": ""Uganda"", ""Ukraine"": ""Ukraine"", ""Unable to create instance: batch creation is not supported when specifying IP."": ""인스턴스를 생성하지 못했습니다: IP를 지정할 때 일괄 생성은 지원되지 않습니다."", ""Unable to create instance: insufficient quota to create resources."": ""인스턴스를 생성하지 못했습니다: 생성할 자원의 할당량이 충분하지 않습니다."", ""Unable to create volume: insufficient quota to create resources."": ""볼륨을 생성하지 못했습니다: 생성할 자원의 할당량이 충분하지 않습니다."", ""Unable to delete router \""{ name }\"". External gateway is opened, please clear external gateway first."": ""\""{ name }\"" 라우터를 삭제할 수 없습니다. 외부 게이트웨이가 열려 있으므로, 먼저 외부 게이트웨이를 삭제해야 합니다."", ""Unable to get {name} detail."": ""{name}의 세부 정보를 가져올 수 없습니다."", ""Unable to get {name}."": ""{name}을 가져올 수 없습니다."", ""Unable to get {title}, please go back to "": ""{title}을 가져올 수 없습니다, 로 돌아가십시오."", ""Unable to get {title}, please go to "": ""{title}을 가져올 수 없습니다, 로 가십시오."", ""Unable to paste into the same folder."": ""같은 폴더에 붙여넣을 수 없습니다."", ""Unable to render form"": ""양식을 렌더링할 수 없습니다"", ""Unable to {action} {name}."": ""{name}을(를) {action}할 수 없습니다."", ""Unable to {action}, because : {reason}, instance: {name}."": ""{reason}때문에 {action}할 수 없습니다, 인스턴스: {instance}"", ""Unable to {action}, instance: {name}."": ""{action}할 수 없습니다, 인스턴스: {instance}"", ""Unable to {action}."": ""{action} 할 수 없습니다."", ""Unable to {title}, please go back to "": ""{title} 할 수 없습니다, 로 돌아가십시오"", ""Unattached"": ""연결되지 않음"", ""Unavailable"": ""사용할 수 없음"", ""Unbootable"": ""부팅 불가능"", ""Unbounded"": ""제한 없음"", ""United Arab Emirates"": ""United Arab Emirates"", ""United Kingdom"": ""United Kingdom"", ""United States"": ""United States"", ""Unless Stopped"": ""중지되지 않음"", ""Unless you know clearly which AZ to create the volume in, you don not need to fill in here."": ""만약 볼륨을 생성할 Availability Zone을 명확히 알고 있다면, 여기에 입력하셔야 합니다."", ""Unlimit"": ""무제한"", ""Unmanage Error"": ""관리 중지 오류"", ""Unmanage Starting"": ""관리 중지 시작"", ""Unmanaged"": ""관리되지 않음"", ""Unpause"": ""일시 중지 해제"", ""Unpause Container"": ""컨테이너 일시 중지 해제"", ""Unpause Instance"": ""인스턴스 일시 중지 해제"", ""Unrescuing"": ""인스턴스 구조"", ""Unset"": ""해제"", ""Unshelve"": ""복원"", ""Unshelve Instance"": ""복원 인스턴스"", ""Unshelving"": ""복원 대기 중"", ""Unused"": ""미사용"", ""Up"": ""위"", ""Update Access"": ""액세스 업데이트"", ""Update At"": ""업데이트 시간"", ""Update Cluster Template"": ""클러스터 템플릿 업데이트"", ""Update Complete"": ""업데이트 완료"", ""Update Failed"": ""업데이트 실패"", ""Update In Progress"": ""업데이트 진행 중"", ""Update Record Set"": ""레코드 셋 업데이트"", ""Update Zone"": ""업데이트 존"", ""Updated"": ""업데이트 완료"", ""Updating Password"": ""비밀번호 업데이트 중"", ""Upgrade Cluster"": ""클러스터 업그레이드"", ""Uruguay"": ""Uruguay"", ""Usb Controller"": ""USB 컨트롤러"", ""Used"": ""사용중"", ""Used IPs"": ""사용중인 IP"", ""Used by tunnel(s): {names}. ID(s): {ids}"": ""Tunnel(s) {names}에 의해 사용 중입니다. ID(s): {ids}"", ""User name can not be duplicated"": ""사용자 이름은 중복될 수 없습니다"", ""User need to change password"": ""사용자 암호를 변경해야 합니다"", ""Using cascading deletion, when the volume has snapshots, the associated snapshot will be automatically deleted first, and then the volume will be deleted, thereby improving the success rate of deleting the volume."": ""cascading 삭제 기능을 사용하면, 볼륨에 스냅샷이 있을 경우 연관된 스냅샷이 먼저 자동으로 삭제되고, 그 다음에 볼륨이 삭제됩니다. 이를 통해 볼륨 삭제의 성공률을 높일 수 있습니다."", ""Using server groups, you can create cloud hosts on the same/different physical nodes as much as possible to meet the affinity/non-affinity requirements of business applications."": ""서버 그룹을 사용하면 비즈니스 애플리케이션의 선호도/비선호도 요구 사항을 충족하기 위해 최대한 동일하거나 다른 물리적 노드에 클라우드 호스트를 생성할 수 있습니다."", ""Uzbekistan"": ""Uzbekistan"", ""VCPU (Core)"": ""VCPU (Core)"", ""VCPUs"": ""VCPUs"", ""VDI - VirtualBox compatible image format"": ""VDI - VirtualBox 호환 이미지 포맷"", ""VGPU"": ""VGPU"", ""VGPU (Core)"": ""VGPU (Core)"", ""VHD - VirtualPC compatible image format"": ""VHD - VirtualPC 호환 이미지 포맷"", ""VIF Details"": ""VIF 상세"", ""VIF Type"": ""VIF 타입"", ""VMDK - Hyper-V compatible image format"": ""VMDK - Hyper-V 호환 이미지 포맷"", ""VNC"": ""VNC"", ""VNIC Type"": ""VNIC 타입"", ""VPN"": ""VPN"", ""VPN EndPoint Groups"": ""VPN 엔드포인트 그룹"", ""VPN Gateways"": ""VPN 게이트웨이"", ""VRRP"": ""VRRP"", ""Valid"": ""유효"", ""Value"": ""값"", ""Values"": ""값"", ""Vanuatu"": ""Vanuatu"", ""Vatican City State (Holy See)"": ""Vatican City State (Holy See)"", ""Vendor Interface"": ""벤더 인터페이스"", ""Venezuela"": ""Venezuela"", ""Verifying"": ""확인 중"", ""Vietnam"": ""Vietnam"", ""View"": ""보기"", ""View Rules"": ""룰 보기"", ""View virtual adapters"": ""가상 어댑터 보기"", ""Virgin Islands (U.S.)"": ""Virgin Islands (U.S.)"", ""Virtual Adapter"": ""가상 어댑터"", ""Virtual Adapter ID"": ""가상 어댑터 ID"", ""Virtual LAN"": ""가상 LAN"", ""Virtual LANs"": ""가상 LAN"", ""Virtual Resource Overview"": ""가상 리소스 개요"", ""Virtual Resources Used"": ""가상 리소스"", ""Virtual adapter mainly used for binding instance and other operations, occupying the quota of the port."": ""주로 바인딩 인스턴스 및 기타 작업에 사용되는 가상 어댑터로, 포트의 할당량을 차지합니다."", ""Visualization Compute Optimized Type with GPU"": ""GPU를 사용한 시각화 컴퓨팅 최적화 유형"", ""Wallis And Futuna Islands"": ""Wallis And Futuna Islands"","," ""3600"": """", "" You can go to the console to "": """", ""\""Shared\"" volume can be mounted on multiple instances"": """", ""'ip' rule represents IPv4 or IPv6 address, 'cert' rule represents TLS certificate, 'user' rule represents username or usergroup, 'cephx' rule represents ceph auth ID."": """", ""-1 means no connection limit"": """", ""."": """", ""1. The backup can only capture the data that has been written to the volume at the beginning of the backup task, excluding the data in the cache at that time."": """", ""1. The name of the custom resource class property should start with CUSTOM_, can only contain uppercase letters A ~ Z, numbers 0 ~ 9 or underscores, and the length should not exceed 255 characters (for example: CUSTOM_BAREMETAL_SMALL)."": """", ""1. The name of the trait should start with CUSTOM_, can only contain uppercase letters A ~ Z, numbers 0 ~ 9 or underscores, and the length should not exceed 255 characters (for example: CUSTOM_TRAIT1)."": """", ""1. The volume associated with the backup is available."": """", ""1. You can create {resources} using ports or port ranges."": """", ""10s"": """", ""1D"": """", ""1H"": """", ""1min"": """", ""2. In the same protocol, you cannot create multiple {resources} for the same source port or source port range."": """", ""2. The trait of the scheduled node needs to correspond to the trait of the flavor used by the ironic instance; by injecting the necessary traits into the ironic instance, the computing service will only schedule the instance to the bare metal node with all the necessary traits (for example, the ironic instance which use the flavor that has CUSTOM_TRAIT1 as a necessary trait, can be scheduled to the node which has the trait of CUSTOM_TRAIT1)."": """", ""2. The volume associated with the backup has been mounted, and the instance is shut down."": """", ""2. To ensure the integrity of the data, it is recommended that you suspend the write operation of all files when creating a backup."": """", ""2. You can customize the resource class name of the flavor, but it needs to correspond to the resource class of the scheduled node (for example, the resource class name of the scheduling node is baremetal.with-GPU, and the custom resource class name of the flavor is CUSTOM_BAREMETAL_WITH_GPU=1)."": """", ""3. When using a port range to create a port mapping, the size of the external port range is required to be the same as the size of the internal port range. For example, the external port range is 80:90 and the internal port range is 8080:8090."": """", ""4. When you use a port range to create {resources}, multiple {resources} will be created in batches. "": """", ""5min"": """", ""8 to 16 characters, at least one uppercase letter, one lowercase letter, one number and one special character."": """", ""8 to 16 characters, at least one uppercase letter, one lowercase letter, one number."": """", ""A command that will be sent to the container"": """", ""A container with the same name already exists"": """", ""A dynamic scheduling algorithm that estimates the server load based on the number of currently active connections. The system allocates new connection requests to the server with the least number of current connections. Commonly used for long connection services, such as database connections and other services."": """", ""A host aggregate can be associated with at most one AZ. Once the association is established, the AZ cannot be disassociated."": """", ""A public container will allow anyone to use the objects in your container through a public URL."": """", ""A snapshot is an image which preserves the disk state of a running instance, which can be used to start a new instance."": """", ""A template is a YAML file that contains configuration information, please enter the correct format."": """", ""A template is a YAML file that contains configuration information."": """", ""ADMINISTRATOR"": """", ""ADOPT COMPLETE"": """", ""AH"": """", ""AKI - Amazon kernel image format"": """", ""AMI - Amazon server image format"": """", ""ANY"": """", ""API Address"": """", ""ARI - Amazon ramdisk image format"": """", ""ARM Architecture"": """", ""Abandon Stack"": """", ""Abandoning this stack will preserve the resources deployed by the stack."": """", ""Abort Upload"": """", ""Access Control"": """", ""Access Key"": """", ""Access Level"": """", ""Access Rules Status"": """", ""Access To"": """", ""Access Type"": """", ""Access Type Setting"": """", ""Add Access Rule"": """", ""Add Custom Metadata"": """", ""Add Data Disks"": """", ""Add Environment Variable"": """", ""Add Exposed Ports"": """", ""Add External Members"": """", ""Add Extra Info"": """", ""Add Extra Spec"": """", ""Add IP"": """", ""Add Label"": """", ""Add NUMA Node"": """", ""Add Property"": """", ""Add Virtual LAN"": """", ""Add hosts to the aggregate or remove hosts from it. Hosts can be in multiple aggregates."": """", ""Add scheduler hints"": """", ""Additional Labels"": """", ""Additional routes announced to the instance, one entry per line(e.g. 192.168.200.0/24,10.56.1.254)"": """", ""Additional routes announced to the instance, one entry per line(e.g. {ip})"": """", ""Address"": """", ""Address Record"": """", ""Admin State Up"": """", ""Admin Status"": """", ""Administrator"": """", ""Adopt Complete"": """", ""Adopt Failed"": """", ""Adopt In Progress"": """", ""Advanced"": """", ""Advanced Params"": """", ""Affiliated Domain"": """", ""Affinity"": """", ""Affinity (mandatory):"": """", ""Affinity (not mandatory):"": """", ""Afghanistan"": """", ""After attaching interface, you may need to login the instance to update the network interface configuration and restart the network service."": """", ""After disable the compute service, the new instance will not schedule to the compute node."": """", ""After shelving, the instance will be shut down, resources will be released, and the snapshot will be saved to Glance. This will take about a few minutes, please be patient. You also can choose to unshelve to restore the instance."": """", ""After the share is expanded, the share cannot be reduced."": """", ""After the volume is expanded, the volume cannot be reduced."": """", ""Agree to force shutdown"": """", ""Albania"": """", ""Algeria"": """", ""All data downloaded."": """", ""All network segments are indicated by \""*\"", not \""0.0.0.0/0\"""": """", ""Always"": """", ""American Samoa"": """", ""An object with the same name already exists"": """", ""Andorra"": """", ""Angola"": """", ""Anguilla"": """", ""Anti-Affinity"": """", ""Anti-affinity (mandatory):"": """", ""Anti-affinity (not mandatory):"": """", ""Antigua and Barbuda"": """", ""Any"": """", ""Any(Random)"": """", ""Application Credentials"": """", ""Application Template"": """", ""Apply Latency(ms)"": """", ""Applying"": """", ""Arch"": """", ""Are you sure to cancel transfer volume { name }? "": """", ""Are you sure to delete instance { name }? "": """", ""Are you sure to delete volume { name }? "": """", ""Are you sure to download data?"": """", ""Are you sure to forbidden domain { name }? Forbidden the domain will have negative effect, and users associated with the domain will not be able to log in if they are only assigned to the domain"": """", ""Are you sure to forbidden project { name }? Forbidden the project will have negative effect, and users associated with the project will not be able to log in if they are only assigned to the project"": """", ""Are you sure to forbidden user { name }? Forbidden the user will not allow login in "": """", ""Are you sure to jump directly to the console? The console will open in a new page later."": """", ""Are you sure to shelve instance { name }? "": """", ""Are you sure to { action } {name}?"": """", ""Are you sure to {action} (instance: {name})?"": """", ""Are you sure to {action}?"": """", ""Are you sure to {action}? (Record Set: {name} - {id})"": """", ""Are you sure to {action}? (Zone: {name})"": """", ""Argentina"": """", ""Armenia"": """", ""Aruba"": """", ""Associate Network"": """", ""Associations"": """", ""Attach Instance"": """", ""Attach Network"": """", ""Attach USB"": """", ""Attached Device"": """", ""Attachments Info"": """", ""Attributes"": """", ""Australia"": """", ""Austria"": """", ""Auth Algorithm"": """", ""Auth Key"": """", ""Auto"": """", ""Auto Healing"": """", ""Auto Inspect"": """", ""Auto Scaling"": """", ""Auto allocate mac address"": """", ""Auto scaling feature will be enabled"": """", ""Automatically Assigned Address"": """", ""Automatically repair unhealhty nodes"": """", ""Availability Zone"": """", ""Availability Zone Hints"": """", ""Availability Zone Info"": """", ""Availability Zone Name"": """", ""Availability Zones"": """", ""Availability zone refers to a physical area where power and network are independent of each other in the same area. In the same region, the availability zone and the availability zone can communicate with each other in the intranet, and the available zones can achieve fault isolation."": """", ""Available Zone"": """", ""Average PGs per OSD"": """", ""Awaiting Transfer"": ""전송을 기다리는 중"", ""Azerbaijan"": """", ""BLOCK I/O(B)"": """", ""Back End"": """", ""Backend"": """", ""Backend Name"": """", ""Backing Up"": """", ""Backup Detail"": """", ""Backup File"": """", ""Backup File Location"": """", ""Backup Mode"": """", ""Backups"": """", ""Bad Gateway (code: 502) "": """", ""Bahamas"": """", ""Bahrain"": """", ""BandWidth Limit Egress"": """", ""BandWidth Limit Ingress"": """", ""Bandwidth limit"": """", ""Bangladesh"": """", ""Barbados"": """", ""Bare Metal Enroll"": """", ""Bare Metal Node Detail"": """", ""Bare Metal Nodes"": """", ""BareMetal Parameters"": """", ""Basic Parameters"": """", ""Batch Allocate"": """", ""Belarus"": """", ""Belgium"": """", ""Belize"": """", ""Benin"": """", ""Bermuda"": """", ""Bhutan"": """", ""Big Data"": """", ""Bind Device"": """", ""Bind Device Type"": """", ""Bind Resource"": """", ""Bind Resource Name"": """", ""Binding"": """", ""Binding Groups"": """", ""Binding Instance"": """", ""Binding Profile"": """", ""Binding Users"": """", ""Blank Volume"": """", ""Block Device Mapping"": """", ""Block Migrate"": """", ""Block Storage Services"": """", ""Blocked"": """", ""Bolivia"": """", ""Boot Device"": """", ""Boot Interface"": """", ""Bosnia and Herzegovina"": """", ""Both of Frontend and Backend"": """", ""Botswana"": """", ""Brazil"": """", ""British Indian Ocean Territory"": """", ""Brunei Darussalam"": """", ""Build"": """", ""Building"": """", ""Bulgaria"": """", ""Burkina Faso"": """", ""Burst limit"": """", ""Burundi"": """", ""CA Certificate"": """", ""CA Certificates"": """", ""CHECK COMPLETE"": """", ""CIDR"": """", ""CIDR Format Error(e.g. 192.168.0.0/24, 2001:DB8::/48)"": """", ""CIFS"": """", ""CMD"": """", ""COE"": """", ""CPU"": """", ""CPU %"": """", ""CPU (Core)"": """", ""CPU Arch"": """", ""CPU Cores"": """", ""CPU Thread Policy"": """", ""CPU Usage(%)"": """", ""CPU Usages (Core)"": """", ""CPU value is { cpu }, NUMA CPU value is { totalCpu }, need to be equal. "": """", ""CPU(Core)"": """", ""CREATE COMPLETE"": """", ""CREATE FAILED"": """", ""CREATE IN PROGRESS"": """", ""Cache Service"": """", ""Cameroon"": """", ""Can add { number } {name}"": """", ""Canada"": """", ""Cancel"": """", ""Cancel Download"": """", ""Cancel Select"": """", ""Cancel Transfer"": ""이전 취소"", ""Cancel download successfully."": """", ""Cancel upload successfully."": """", ""Canonical Name Record"": """", ""Capacity & Type"": ""용량 과 종류"", ""Capacity (GiB)"": """", ""Cape Verde"": """", ""Capsule Detail"": """", ""Capsule Type"": """", ""Capsules"": """", ""Cascading deletion"": """", ""Cast Rules To Read Only"": """", ""Category"": """", ""Cayman Islands"": """", ""CentOS"": """", ""Central African Republic"": """", ""CephFS"": """", ""Cephx"": """", ""Cert"": """", ""Certificate Authority Authorization Record"": """", ""Certificate Content"": """", ""Certificate Detail"": """", ""Certificate Name"": """", ""Certificate Type"": """", ""Certificates"": """", ""Chad"": """", ""Change Password"": ""암호 변경"", ""Change Type"": ""변화 유형"", ""Change password"": ""암호 변경"", ""Change type"": ""변화 유형"", ""Changed Node Count"": """", ""Channel"": """", ""Chassis ID"": """", ""Check Can Live Migrate Destination"": """", ""Check Can Live Migrate Source"": """", ""Check Complete"": """", ""Check Failed"": """", ""Check In Progress"": """", ""Checksum"": """", ""Chile"": """", ""China"": """", ""Choose a Network Driver"": """", ""Choose a host to live migrate instance to. If not selected, the scheduler will auto select target host."": """", ""Choose a host to migrate instance to. If not selected, the scheduler will auto select target host."": """", ""Choosing a QoS policy can limit bandwidth and DSCP"": """", ""Christmas Island"": """", ""Cidr"": """", ""Cinder Service"": """", ""Cipher"": """", ""Clean Failed"": """", ""Clean Wait"": """", ""Cleaning"": """", ""Clear Gateway"": """", ""Clear selected"": ""선택 비우기"", ""Click To View"": """", ""Click here for filters."": """", ""Click to Upload"": """", ""Click to show detail"": """", ""Close External Gateway"": """", ""Close all notifications."": """", ""Close external gateway"": """", ""Cloud"": """", ""Cluster Detail"": """", ""Cluster Distro"": """", ""Cluster Info"": """", ""Cluster Management"": """", ""Cluster Name"": """", ""Cluster Network"": """", ""Cluster Template"": """", ""Cluster Template Detail"": """", ""Cluster Template Name"": """", ""Cluster Templates"": """", ""Cluster Type"": """", ""Clusters"": """", ""Clusters Management"": """", ""Cocos (Keeling) Islands"": """", ""Code"": """", ""Cold Migrate"": """", ""Colombia"": """", ""Command"": """", ""Command to run to check health"": """", ""Command was successfully executed at container {name}."": """", ""Commas ‘,’ are not allowed to be in a tag name in order to simplify requests that specify lists of tags"": """", ""Commit Latency(ms)"": """", ""Common Server"": """", ""Comoros"": """", ""Compute"": ""계산"", ""Compute Hosts"": """", ""Compute Live Migration"": """", ""Compute Live Resize Instance"": """", ""Compute Node status"": """", ""Compute Optimized"": """", ""Compute Optimized Info"": """", ""Compute Optimized Type"": """", ""Compute Optimized Type with GPU"": """", ""Compute Pause Instance"": """", ""Compute Reboot Instance"": ""Compute 인스턴스 다시 시작"", ""Compute Resume Instance"": ""Compute 인스턴스 재시작"", ""Compute Service"": """", ""Compute Services"": """", ""Compute Start Instance"": """", ""Compute Stop Instance"": """", ""Compute Suspend Instance"": """", ""Compute Unpause Instance"": """", ""Conductor Live Migrate Instance"": """", ""Conductor Live Resize Instance"": """", ""Conductor Migrate Server"": """", ""Config Overview"": """", ""Configuration"": """", ""Configuration Detail"": """", ""Configuration Group"": """", ""Configuration Group ID/Name"": """", ""Configuration Groups"": """", ""Configuration Update"": ""설정 변경"", ""Configured Disk (GiB)"": """", ""Configured Memory (GiB)"": """", ""Confirm Config"": """", ""Confirm Resize or Migrate"": ""크기 변경 / 이전 확인"", ""Confirm Shared Key"": """", ""Confirming Resize or Migrate"": """", ""Connect Subnet"": """", ""Connect router"": """", ""Connected Threads"": """", ""Connection Examples"": """", ""Connection Information"": """", ""Connection Limit"": """", ""Consecutive failures needed to report unhealthy"": """", ""Console Interface"": """", ""Consumer"": ""사용자"", ""Container Creating"": """", ""Container Deleting"": """", ""Container Detail"": """", ""Container Format"": ""컨테이너 포멧"", ""Container Killing"": """", ""Container Pausing"": """", ""Container Rebooting"": """", ""Container Rebuilding"": """", ""Container Restarting"": """", ""Container Starting"": """", ""Container Status"": """", ""Container Stopping"": """", ""Container Unpausing"": """", ""Container Version"": """", ""Containers CPU"": """", ""Containers Disk (GiB)"": """", ""Containers Info"": """", ""Containers Management"": """", ""Containers Memory (MiB)"": """", ""Content Type"": """", ""Control Location"": """", ""Cook Islands"": """", ""CoreOS"": """", ""Costa Rica"": """", ""Cote D'Ivoire"": """", ""Crashed"": """", ""Create Allowed Address Pair"": """", ""Create Application Credentials"": """", ""Create Bandwidth Limit Rule"": """", ""Create Bare Metal Node"": """", ""Create Capsule"": """", ""Create Certificate"": """", ""Create Cluster"": """", ""Create Cluster Template"": """", ""Create Complete"": """", ""Create Configurations"": """", ""Create DSCP Marking Rule"": """", ""Create Database"": """", ""Create Database Backup"": """", ""Create Database Instance"": """", ""Create Default Pool"": """", ""Create Encryption"": """", ""Create Extra Spec"": """", ""Create Failed"": """", ""Create Host Aggregate"": ""호스트 집합 생성"", ""Create IPsec Site Connection"": """", ""Create In Progress"": """", ""Create Ironic Instance"": """", ""Create Keypair"": ""캐 페어 생성"", ""Create Listener"": """", ""Create Loadbalancer"": """", ""Create New Network"": """", ""Create Node"": """", ""Create Port Forwarding"": """", ""Create Port Group"": """", ""Create Record Set"": """", ""Create Share"": """", ""Create Share Group"": """", ""Create Share Group Type"": """", ""Create Share Metadata"": """", ""Create Share Network"": """", ""Create Share Type"": """", ""Create Stack"": ""Stack 생성"", ""Create Static Route"": """", ""Create Time"": ""만들 시간"", ""Create Transfer"": ""이전 생성"", ""Create VPN Endpoint Group"": """", ""Create Virtual Adapter"": """", ""Create Volume Type"": ""볼륨 타입 생성 "", ""Create Zone"": """", ""Create a full backup, the system will automatically create a new backup chain, the full backup name is the backup chain name; Create an incremental backup, the system will automatically create an incremental backup under the newly created backup chain."": """", ""Create host aggregate"": ""호스트 집합 생성"", ""Create ironic instance"": """", ""Create new AZ"": """", ""Create static route"": """", ""Create volume backup"": """", ""Created At"": ""생성 시점"", ""Created Time"": ""생성 시점"", ""Created Volumes"": """", ""Creating"": ""만드는 중"", ""Creating From Snapshot"": """", ""Creation Timeout (Minutes)"": """", ""Credential Type"": """", ""Croatia (local name: Hrvatska)"": """", ""Cuba"": """", ""Current Availability Zones"": """", ""Current Compute Host"": """", ""Current Connections"": """", ""Current Disk (GiB)"": """", ""Current Flavor"": """", ""Current Host"": """", ""Current Interface"": """", ""Current Master Node Count"": """", ""Current Node Count"": """", ""Current Password"": """", ""Current Path: "": """", ""Current Project"": """", ""Current Project Images"": """", ""Current Project Networks"": """", ""Current Project QoS Policies"": """", ""Current QoS policy name"": """", ""Current Status"": """", ""Current Storage Backend"": """", ""Current data downloaded."": """", ""Custom Properties Info"": ""사용자 정의 속성"", ""Cut"": """", ""Cut File"": """", ""Cyprus"": """", ""Enabled Load Balancer for Master Nodes"": """", ""Enabled Network"": """", ""Encapsulation Mode"": """", ""Encrypted"": """", ""Encryption"": """", ""Encryption Algorithm"": """", ""Encryption Info"": """", ""End Time"": """", ""Endpoint Counts"": """", ""Engine ID"": """", ""Enroll"": """", ""Enter an integer value between 1 and 65535."": """", ""Enter query conditions to filter"": """", ""Entered: {length, plural, =1 {one character} other {# characters} }(maximum {maxCount} characters)"": """", ""Environment"": """", ""Environment Variable"": """", ""Environment Variables"": """", ""Error Extending"": """", ""Event Time"": """", ""Execute Command"": """", ""Execution Result"": """", ""Existing Volume"": """", ""Exit Policy"": """", ""Expand"": """", ""Expand Advanced Options"": """", ""Expired Time"": """", ""Expires At"": """", ""Export Location"": """", ""Export Locations"": """", ""Exposed Ports"": """", ""Extend Root Volume"": """", ""Extend Share"": """", ""Extending"": """", ""Extending Error"": """", ""External Fixed IP"": """", ""External Fixed IPs"": """", ""External Network Info"": """", ""External Port/Port Range"": """", ""Extra Infos"": """", ""Fail Rollback"": ""실패 롤 백"", ""Failed"": """", ""Fault"": """", ""File"": """", ""File System Free Space"": """", ""File URL"": """", ""Files: {names}"": """", ""Fill In The Parameters"": """", ""Finish Resize"": """", ""First time edit automatically creates health monitor When pool does not have a health monitor"": """", ""Fixed IP"": """", ""Fixed Network"": """", ""Fixed Subnet"": """", ""Flavor of Master Nodes"": """", ""Flavor of Nodes"": """", ""Floating IP"": ""유동 IP"", ""Floating IP Address"": ""유동 IP 주소"", ""Floating IP Enabled"": """", ""Floating IPs"": ""유동 IP"", ""Floating Ip"": ""유동 IP"", ""Floating Ip Address"": ""유동 IP 주소"", ""Floating Ip Detail"": ""유동 IP 세부 정보"", ""Floating ip has already been associate, Please check Force release"": """", ""Folder Detail"": """", ""Folder Name"": """", ""For GPU type, you need to install GPU drivers in the instance operating system."": """", ""For GRE networks, valid segmentation IDs are 1 to 4294967295"": """", ""For VLAN networks, valid segmentation IDs are 1 to 4094"": """", ""For VXLAN networks, valid segmentation IDs are 1 to 16777215"": """", ""Forbidden"": """", ""Forbidden Domain"": """", ""Forbidden Project"": """", ""Forbidden User"": """", ""Forbidden the domain will have a negative impact, all project and user in domain will be forbidden"": """", ""Force Delete"": """", ""Force Delete Container"": """", ""Force Delete Share Instance"": """", ""Force release"": """", ""Forced Down"": """", ""Forced Shutdown"": """", ""Forced shutdown may result in data loss or file system damage. You can also take the initiative to shut down and perform operations."": """", ""Forgot your password?"": """", ""Forward Slash ‘/’ is not allowed to be in a tag name"": """", ""Frequent login failure will cause the account to be temporarily locked, please operate after 5 minutes"": """", ""GPU Count"": """", ""GPU Info"": """", ""GPU Model"": """", ""GPU Parameters"": """", ""GPU Type"": """", ""GPU pass-through will load GPU devices directly to the instance for use. VGPU is a GPU virtualization solution. GPU resources will be segmented and distributed to multiple instances for shared use."": """", ""Gateway Time-out (code: 504) "": """", ""Gateway ip {gateway_ip} conflicts with allocation pool {pool}"": """", ""Get OpenRC file"": """", ""Get Token"": """", ""Global Setting"": """", ""Grant Databases Access"": """", ""HTTP Version not supported (code: 505) "": """", ""Hard Reboot"": """", ""Hard Rebooting"": """", ""Health Check Interval"": """", ""Health Check Retries"": """", ""Health Check Timeout"": """", ""Health Checking Log"": """", ""Health Monitor Delay"": """", ""Health Monitor Detail"": """", ""Health Monitor Max Retries"": """", ""Health Monitor Name"": """", ""Health Monitor Timeout"": """", ""Health Monitor Type"": """", ""HealthMonitor Type"": """", ""Healthy"": """", ""Heartbeat Timestamp"": """", ""Hello, {name}"": """", ""Hidden"": """", ""Hide Advanced Options"": """", ""Host Aggregate"": ""호스트 집합"", ""Host Aggregates"": ""호스트 집합"", ""Host Average Network IO"": """", ""Host CPU Usage"": """", ""Host Detail"": """", ""Host Disk Average IOPS"": """", ""Host Memory Usage"": """", ""Host Routes Format Error(e.g. 192.168.200.0/24,10.56.1.254)"": """", ""Host Routes Format Error(e.g. ::0a38:01fe/24,::0a38:01fe)"": """", ""Hosts Detail"": """", ""Hypervisor Detail"": """", ""ICMP Code"": """", ""ICMP Type/ICMP Code"": """", ""IP Usage"": """", ""IP address allocation polls, one enter per line(e.g. 192.168.1.2,192.168.1.200)"": """", ""IP address allocation polls, one enter per line(e.g. {ip})"": """", ""IPMI Address"": """", ""IPMI Password"": """", ""IPMI Privilege Level"": """", ""IPMI Protocol Version"": """", ""IPMI Username"": """", ""IPv4 Address"": """", ""IPv6 Address"": """", ""IPv6 Address Record"": """", ""ISO - Optical disc image format"": """", ""Identifier of the physical port on the switch to which node’s port is connected to"": """", ""If \""Enable\"" fails to roll back, the resource will be deleted after the creation fails; if \""Disable\"" fails to roll back, the resource will be retained after the creation fails."": """", ""If OS is Linux, system will reset root password, if OS is Windows, system will reset Administrator password."": """", ""If an instance is using this flavor, deleting it will cause the instance's flavor data to be missing. Are you sure to delete {name}?"": """", ""If checked, the network will be enable."": """", ""If exposed port is specified, this parameter will be ignored."": """", ""If it is an SNI type certificate, a domain name needs to be specified"": """", ""If it’s not set, the value of this in template will be used."": """", ""If no gateway is specified, the first IP address will be defaulted."": """", ""If not provided, the roles assigned to the application credential will be the same as the roles in the current token."": """", ""If nova-compute on the host is disabled, it will be forbidden to be selected as the target host."": """", ""If set then all tenants will be able to see this share."": """", ""If the capacity of the disk is large,the type modify operation may takes several hours. Please be cautious."": """", ""If the listener has an SNI certificate installed, it cannot be removed. Please delete the listener or replace the SNI certificate"": """", ""If the value is set to 0, it means unlimited"": """", ""If the volume associated with the snapshot has changed the volume type, please modify this option manually; if the volume associated with the snapshot keeps the volume type unchanged, please ignore this option. (no need to change)."": """", ""If this parameter is specified, Zun will create a security group with a set of rules to open the ports that should be exposed, and associate the security group to the container."": """", ""If you are not authorized to access any project, or if the project you are involved in has been deleted or disabled, contact the platform administrator to reassign the project"": """", ""If you choose a port which subnet is different from the subnet of LB, please ensure connectivity between the two."": """", ""If you do not fill in parameters such as cpus, memory_mb, local_gb, cpu_arch, etc., you can automatically inject the configuration and Mac address of the physical machine by performing the \""Auto Inspect\"" operation."": """", ""If you still want to keep the disk data, it is recommended that you create a snapshot for the disk before deleting."": """", ""Image"": ""이미지"", ""Image Backup"": """", ""Image Detail"": ""이미지 상세 정보"", ""Image Driver"": """", ""Image Info"": ""이미지 정보"", ""Image Name"": ""이미지 이름"", ""Image Pulling"": """", ""Image Size"": ""이미지 크기"", ""Please input port and protocol"": """", ""Please input prefix"": """", ""Please input protocol number if it absent in select list."": """", ""Please input provider"": """", ""Please input snapshot name"": """", ""Please input transfer id"": """", ""Please input user name"": """", ""Please input value"": """", ""Please input your Password!"": ""암호를 입력하십시오!"", ""Please input your Username!"": ""사용자 이름을 입력하십시오!"", ""Please input your current password!"": """", ""Please input your password!"": """", ""Please input {label}"": """", ""Please input {label}!"": """", ""Please make sure this IP address be available to avoid creating VM failure."": """", ""Please make sure this IP address be available."": """", ""Please reasonably plan the network and subnet to which the virtual network card belongs."": """", ""Please save your token properly and it will be valid for {left}."": """", ""Please select"": """", ""Please select a file"": """", ""Please select a file with the suffix {types}"": """", ""Please select a network!"": """", ""Please select a subnet!"": """", ""Please select a type!"": """", ""Please select availability zone"": """", ""Please select image driver"": """", ""Please select item!"": """", ""Please select key"": """", ""Please select login type!"": """", ""Please select policy"": """", ""Please select source"": """", ""Please select type"": """", ""Please select volume type"": """", ""Please select your Domain!"": """", ""Please select your Region!"": """", ""Please select {label}!"": """", ""Please select {name} first"": """", ""Please set CPU && Ram first."": """", ""Please set MUNA"": """", ""Please upload files smaller than { size }GiB on the page. It is recommended to upload files over { size }GiB using API."": """", ""Pointer Record"": """", ""Pool Algorithm"": """", ""Pool Description"": """", ""Pool Detail"": """", ""Pool ID"": """", ""Pool Info"": """", ""Pool Name"": """", ""Pool Protocol"": """", ""Port Count"": """", ""Port Detail"": """", ""Port Forwardings"": """", ""Port Group"": """", ""Port Groups"": """", ""Port Info"": """", ""Port Range"": """", ""Port Security"": """", ""Port Security Enabled"": """", ""Port Type"": """", ""Ports are either single values or ranges"": """", ""Ports provide extra communication channels to your containers. You can select ports instead of networks or a mix of both, If the terminal port and the network are selected at the same time, note that the terminal port is not a terminal port of the selected network, and the container under the same network will only be assigned one IP address (The port executes its own security group rules by default)."": """", ""Ports provide extra communication channels to your instances. You can select ports instead of networks or a mix of both (The port executes its own security group rules by default)."": """", ""Power Off"": """", ""Power On"": """", ""Power State"": """", ""Powering Off"": """", ""Powering On"": """", ""Pre Live Migration"": """", ""Pre-Shared Key must be the same with Confirm Shared Key."": """", ""Pre-Shared Key(PSK) String"": """", ""Prefer"": """", ""Prefer(Thread siblings are preferred)"": """", ""Preferred"": """", ""Prefix"": """", ""Prep Resize"": """", ""Prepare Template"": """", ""Previous"": """", ""Primary"": """", ""Progress"": """", ""Project Detail"": ""프로젝트 세부 정보"", ""Project Scope (Project Name: Role Names)"": """", ""Promote"": """", ""Properties"": """", ""Protocol Type"": """", ""Provider"": """", ""Provider Network Type"": """", ""Provider Physical Network"": """", ""Provision State"": """", ""Provisioning Status"": """", ""Public Access"": ""공개 방문"", ""Public Address"": ""공통 주소"", ""Published In"": """", ""Published Out"": """", ""QoS Detail"": ""QoS 세부 정보"", ""QoS Policy Detail"": ""QoS 정책 세부 정보"", ""QoS Spec"": ""QOS 스펙"", ""QoS Spec ID"": ""QOS 스펙 ID"", ""QoS Specs"": ""QOS 스펙"", ""Queued"": """", ""Queued To Apply"": """", ""Queued To Deny"": """", ""Quota exceeded"": ""할당량 소진되다"", ""Quota is not enough for extend share."": """", ""Quota is not enough for extend volume."": """", ""Quota of key pair means: the number of allowed key pairs for each user."": """", ""Quota: Insufficient quota to create resources, please adjust resource quantity or quota(left { quota }, input { input })."": """", ""Quota: Insufficient { name } quota to create resources, please adjust resource quantity or quota(left { left }, input { input })."": """", ""Quota: Insufficient { name } quota to create resources."": """", ""Quota: Project quotas sufficient resources can be created"": """", ""RESTORE COMPLETE"": """", ""RESUME COMPLETE"": """", ""RESUME FAILED"": """", ""ROLLBACK COMPLETE"": ""원복 완료"", ""ROLLBACK FAILED"": ""원복 실패"", ""ROLLBACK IN PROGRESS"": ""원복진행 중"", ""Raid Interface"": """", ""Ram Size (GiB)"": ""Ram 크기 (GiB)"", ""Ram value is { ram }, NUMA RAM value is { totalRam }, need to be equal. "": """", ""Ramdisk ID"": """", ""Ramdisk Image"": """", ""Read and write"": ""읽고 쓸 수도 있다"", ""Real Name"": ""진짜 이름"", ""Reboot"": ""재부 팅"", ""Reboot Container"": ""컨테이너 다시 시작"", ""Reboot Database Instance"": """", ""Reboot Instance"": ""인스턴스 다시 시작"", ""Rebooting"": """", ""Rebuild"": """", ""Rebuild Block Device Mapping"": """", ""Rebuild Container"": """", ""Rebuild Instance"": """", ""Rebuild Spawning"": """", ""Rebuilding"": """", ""Rebuilt"": """", ""Recently a day"": """", ""Record Sets"": """", ""Records"": """", ""Recordset Detail"": """", ""Recordsets Detail"": """", ""Recover"": """", ""Recovering"": """", ""Recycle Bin"": """", ""Region"": """", ""Registry Enabled"": """", ""Related Resources"": ""관련리 소스"", ""Release"": """", ""Release Fixed IP"": """", ""Remote Group Id"": """", ""Remote IP Prefix"": """", ""Remote Security Group"": """", ""Remote Type"": """", ""Remove"": """", ""Remove Network"": """", ""Remove Router"": """", ""Rename"": """", ""Rename is to copy the current file to the new file address and delete the current file, which will affect the creation time of the file."": """", ""Replication Change"": """", ""Report Count"": """", ""Request ID"": """", ""Require"": """", ""Require(Need multithreading)"": """", ""Required Data Disk"": """", ""Rescue"": """", ""Rescued"": """", ""Rescuing"": """", ""Reserved"": """", ""Reset Status"": """", ""Reset To Initial Value"": """", ""Reset failed, please retry"": """", ""Resize"": ""크기 변경"", ""Resize Cluster"": """", ""Resize Instance"": ""인스턴스 크기 변경"", ""Resize Volume"": ""볼륨 크기 변경"", ""Resized"": """", ""Resizing or Migrating"": """", ""Resource Class"": """", ""Resource Class Properties"": """", ""Resource Not Found"": """", ""Resource Pool"": """", ""Resource Status"": """", ""Resource Status Reason"": """", ""Resource Type"": ""리소스 타입"", ""Resource Types"": ""리소스 타입"", ""Resources Synced"": """", ""Restart"": """", ""Restart Container"": """", ""Restart Database Service"": """", ""Restarting"": """", ""Restore Backup"": """", ""Restore From Snapshot"": """", ""Restore backup"": """", ""Restore from snapshot"": """", ""Restoring"": """", ""Restoring Backup"": """", ""Resume"": ""재시작"", ""Resume Complete"": """", ""Resume Failed"": """", ""Resume In Progress"": """", ""Resume Instance"": ""인스턴스 재시작"", ""Resuming"": """", ""Retry times for restart on failure policy"": """", ""Retyping"": """", ""Reunion"": """", ""Reverse DNS Detail"": """", ""Reverse Detail"": """", ""Reverse Dns"": """", ""Revert Resize or Migrate"": """", ""Revert Resize/Migrate"": """", ""Reverting"": """", ""Reverting Error"": """", ""Reverting Resize or Migrate"": """", ""Role Detail"": ""역할 세부 정보"", ""Rollback Complete"": ""원복 완료"", ""Rollback Failed"": ""원복 실패"", ""Rollback In Progress"": ""원복진행 중"", ""Root Disk"": """", ""Root Disk (GiB)"": """", ""Root directory"": """", ""Router"": """", ""Router Advertisements Mode"": """", ""Router Detail"": """", ""Router External"": """", ""Router ID"": """", ""Running"": """", ""Running Threads"": """", ""Running Time"": """", ""Runtime"": """", ""SNAPSHOT COMPLETE"": """", ""SNAT Enabled"": """", ""SNI Certificate"": """", ""SNI Enabled"": """", ""SOURCE_IP"": """", ""SSH Public Key Fingerprint"": """", ""SSL Parsing Method"": """", ""Same subnet with LB"": """", ""The instance architecture diagram mainly shows the overall architecture composition of the instance. If you need to view the network topology of the instance, please go to: "": """", ""The instance deleted immediately cannot be restored"": """", ""The instance has been locked. If you want to do more, please unlock it first."": """", ""The instance is not shut down, unable to restore."": """", ""The instance which is boot from volume will create snapshots for each mounted volumes."": """", ""The instances in the affinity group are allocated to the same physical machine as much as possible, and when there are no more physical machines to allocate, the normal allocation strategy is returned."": """", ""The instances in the affinity group are strictly allocated to the same physical machine. When there are no more physical machines to allocate, the allocation fails."": """", ""The instances in the anti-affinity group are allocated to different physical machines as much as possible. When there are no more physical machines to allocate, the normal allocation strategy is returned."": """", ""The instances in the anti-affinity group are strictly allocated to different physical machines. When there are no more physical machines to allocate, the allocation fails."": """", ""The ip is not within the allocated pool!"": """", ""The ip of external members can be any, including the public network ip."": """", ""The key pair allows you to SSH into your newly created instance. You can select an existing key pair, import a key pair, or generate a new key pair."": """", ""The kill signal to send"": """", ""The limit of cluster instance greater than or equal to 1."": """", ""The maximum batch size is {size}, that is, the size of the port range cannot exceed {size}."": """", ""The maximum transmission unit (MTU) value to address fragmentation. Minimum value is 68 for IPv4, and 1280 for IPv6."": """", ""The min size is {size} GiB"": """", ""The name cannot be modified after creation"": """", ""The name of the physical network to which a port is connected"": """", ""The name should contain letter or number, the length is 1 to 16, characters can only contain \""0-9, a-z, A-Z, -, _.\"""": """", ""The name should contain letter or number, the length is 2 to 64, characters can only contain \""0-9, a-z, A-Z, -, _.\"""": """", ""The name should start with letter or number, and be a string of 2 to 255, characters can only contain \""0-9, a-z, A-Z, -, _, .\"""": """", ""The name should start with upper letter or lower letter, and be a string of 1 to 128, characters can only contain \""0-9, a-z, A-Z, \""-'_()[].:^\""."": """", ""The name should start with upper letter or lower letter, characters can only contain \""0-9, a-z, A-Z, -, _, .\"""": """", ""The name should start with upper letter, lower letter or chinese, and be a string of 1 to 128, characters can only contain \""0-9, a-z, A-Z, \""-'_()[].\""."": """", ""The name should start with upper letter, lower letter or chinese, and be a string of 1 to 128, characters can only contain \""0-9, a-z, A-Z, \""-'_()[].:^\""."": """", ""The name should start with upper letter, lower letter or chinese, and be a string of 1 to 128, characters can only contain \""0-9, a-z, A-Z, \""-'_.\""."": """", ""The name should start with upper letter, lower letter or chinese, and be a string of 1 to 64, characters can only contain \""0-9, a-z, A-Z, \""-'_()[].^\""."": """", ""The name should start with upper letter, lower letter or chinese, and be a string of 3 to 63, characters can only contain \""0-9, a-z, A-Z, chinese, -, .\""."": """", ""The name should start with upper letter, lower letter, and be a string of 1 to 128, characters can only contain \""0-9, a-z, A-Z, -, _\""."": """", ""The name should start with upper letter, lower letter, and be a string of 2 to 255, characters can only contain \""0-9, a-z, A-Z, -, ., _\""."": """", ""The name should start with upper letter, lower letter, and be a string of 3 to 63, characters can only contain \""0-9, a-z, A-Z, -\""."": """", ""The new password cannot be identical to the current password."": """", ""The no_proxy address to use for nodes in cluster"": """", ""The number of allowed key pairs for each user."": """", ""The number of vCPU cores should not exceed the maximum number of CPU cores of the physical node. Otherwise it will cause fail to schedule to any physical node when creating instance."": """", ""The number of virtual cpu for this container"": """", ""The password must not be the same as the previous"": """", ""The password must not be the same as the previous two"": """", ""The password must not be the same as the previous {num}"": """", ""The port created here will be automatically deleted when detach. If you need a reusable port, please go to the Virtual Adapter page to create and attach the port to instance."": """", ""The private key content format is: with \""-----BEGIN RSA PRIVATE KEY-----\"" as the beginning,\""-----END RSA PRIVATE KEY-----\"" as the end, 64 characters per line, the last line does not exceed 64 characters, and there cannot be blank lines."": """", ""The private key of the certificate, the extension of the private key is \""key\"", you can directly enter the content of the private key file or upload a private key that conforms to the format document."": """", ""The resource class of the scheduled node needs to correspond to the resource class name of the flavor used by the ironic instance (for example, the resource class name of the scheduling node is baremetal.with-GPU, and the custom resource class name of the flavor is CUSTOM_BAREMETAL_WITH_GPU=1)."": """", ""The resource has been deleted"": """", ""The root and os_admin are default users and cannot be created!"": """", ""The security group is similar to the firewall function and is used to set up network access control. "": """", ""The security group is similar to the firewall function for setting up network access control, or you can go to the console and create a new security group. (Note: The security group you selected will work on all virtual LANS on the instances.)"": """", ""The selected VPC/ subnet does not have IPv6 enabled."": """", ""The selected network has no subnet"": """", ""The selected project is different from the project to which the network belongs. That is, the subnet to be created is not under the same project as the network. Please do not continue unless you are quit sure what you are doing."": """", ""The session has expired, please log in again."": """", ""The shelved offloaded instance only supports immediate deletion"": """", ""The size of the external port range is required to be the same as the size of the internal port range"": """", ""The start source is a template used to create an instance. You can choose an image or a bootable volume."": """", ""The starting number must be less than the ending number"": """", ""The timeout for cluster creation in minutes."": """", ""The timeout period of waiting for the return of the health check request, the check timeout will be judged as a check failure"": """", ""The total amount of data is { total }, and the interface can support downloading { totalMax } pieces of data. If you need to download all the data, please contact the administrator."": """", ""The trait name of the flavor needs to correspond to the trait of the scheduling node; by injecting the necessary traits into the ironic instance, the computing service will only schedule the instance to the bare metal node with all necessary traits (for example: the trait of the scheduling node has HW_CPU_X86_VMX trait, and the flavor adds HW_CPU_X86_VMX, it can be scheduled to this node for necessary traits)."": """", ""The trait of the scheduled node needs to correspond to the trait of the flavor used by the ironic instance; by injecting the necessary traits into the ironic instance, the computing service will only schedule the instance to the bare metal node with all the necessary traits (for example, the ironic instance which use the flavor that has HW_CPU_X86_VMX as a necessary trait, can be scheduled to the node which has the trait of HW_CPU_X86_VMX)."": """", ""The unit suffix must be one of the following: Kb(it), Kib(it), Mb(it), Mib(it), Gb(it), Gib(it), Tb(it), Tib(it), KB, KiB, MB, MiB, GB, GiB, TB, TiB. If the unit suffix is not provided, it is assumed to be KB."": """", ""The user has been disabled, please contact the administrator"": """", ""The user needs to ensure that the input is a shell script that can run completely and normally."": """", ""The value of the upper limit of the range must be greater than the value of the lower limit of the range."": """", ""The volume associated with the backup is not available, unable to restore."": """", ""The volume status can be reset to in-use only when the previous status is in-use."": """", ""The volume type needs to be consistent with the volume type when the snapshot is created."": """", ""The volume type needs to set \""multiattach\"" in the metadata to support shared volume attributes."": """", ""The working directory for commands to run in"": """", ""The {action} instruction has been issued, instance: {name}. \n You can wait for a few seconds to follow the changes of the list data or manually refresh the data to get the final display result."": """", ""The {action} instruction has been issued. \n You can wait for a few seconds to follow the changes of the list data or manually refresh the data to get the final display result."": """", ""The {name} has already been used by other {resource}({content}), please change."": """", ""The {name} {ports} have already been used, please change."": """", ""There are resources that cannot {action} in the selected resources, such as:"": """", ""There are resources that cannot {action} in the selected resources."": """", ""There are resources under the project and cannot be deleted."": """", ""There is currently no file to paste."": """", ""This operation creates a security group with default security group rules for the IPv4 and IPv6 ether types."": """", ""This service will automatically query the configuration (CPU, memory, etc.) and mac address of the physical machine, and the ironic-inspector service will automatically register this information in the node information."": """", ""This will delete all child objects of the load balancer."": """", ""Threads Activity Trends"": """", ""Time Interval: "": """", ""Time To Live"": """", ""Time To Live in seconds."": """", ""Time between running the check in seconds"": """", ""Timeout(Minute)"": """", ""Timeout(s)"": """", ""To open"": """", ""Today CPU usage > 80% alert"": """", ""Today Memory usage > 80% alert"": """", ""Togo"": """", ""Tokelau"": """", ""Tonga"": """", ""Too many disks mounted on the instance will affect the read and write performance. It is recommended not to exceed 16 disks."": """", ""Topic"": """", ""Total"": """", ""Total Capacity"": """", ""Total Connections"": """", ""Total Consumers"": """", ""Total Containers"": """", ""Total Exchanges"": """", ""Total IPs"": """", ""Total Queues"": """", ""Total Ram"": ""모든 RAM"", ""Total {total} items"": """", ""Trait Properties"": """", ""Traits"": """", ""Transfer Name"": ""전송 이름"", ""Transferred"": """", ""Transform Protocol"": """", ""Trinidad and Tobago"": """", ""True"": """", ""Tunisia"": """", ""Turkey"": """", ""Turkmenistan"": """", ""Turks and Caicos Islands"": """", ""Tuvalu"": """", ""Two-way authentication"": """", ""UDP"": """", ""UDPLite"": """", ""UNHEALTHY"": """", ""UNKNOWN"": """", ""UPDATE COMPLETE"": """", ""UPDATE FAILED"": """", ""UPDATE IN PROGRESS"": """", ""USB Info"": """", ""USB Parameters"": """", ""USER"": """", ""UUID"": """", ""Ubuntu"": """", ""Uganda"": """", ""Ukraine"": """", ""Unable to create instance: batch creation is not supported when specifying IP."": """", ""Unable to create instance: insufficient quota to create resources."": """", ""Unable to create volume: insufficient quota to create resources."": """", ""Unable to delete router \""{ name }\"". External gateway is opened, please clear external gateway first."": """", ""Unable to get {name} detail."": """", ""Unable to get {name}."": """", ""Unable to get {title}, please go back to "": """", ""Unable to get {title}, please go to "": """", ""Unable to paste into the same folder."": """", ""Unable to render form"": """", ""Unable to {action} {name}."": """", ""Unable to {action}, because : {reason}, instance: {name}."": """", ""Unable to {action}, instance: {name}."": """", ""Unable to {action}."": ""{action} 수 없습니다."", ""Unable to {title}, please go back to "": """", ""Unattached"": """", ""Unavailable"": """", ""Unbootable"": """", ""Unbounded"": """", ""United Arab Emirates"": """", ""United Kingdom"": """", ""United States"": """", ""Unless Stopped"": """", ""Unless you know clearly which AZ to create the volume in, you don not need to fill in here."": """", ""Unlimit"": """", ""Unmanage Error"": """", ""Unmanage Starting"": """", ""Unmanaged"": """", ""Unpause"": """", ""Unpause Container"": """", ""Unpause Instance"": """", ""Unrescuing"": """", ""Unset"": """", ""Unshelve"": """", ""Unshelve Instance"": """", ""Unshelving"": """", ""Unused"": """", ""Up"": """", ""Update Access"": """", ""Update At"": """", ""Update Cluster Template"": """", ""Update Complete"": """", ""Update Failed"": """", ""Update In Progress"": """", ""Update Record Set"": """", ""Update Zone"": """", ""Updating Password"": """", ""Upgrade Cluster"": """", ""Uruguay"": """", ""Usb Controller"": """", ""Used"": ""사용된"", ""Used IPs"": ""사용된 IP"", ""Used by tunnel(s): {names}. ID(s): {ids}"": """", ""User name can not be duplicated"": ""사용자 이름을 중복할 수 없습니다"", ""User need to change password"": ""사용자가 암호를 변경해야 합니다"", ""Using cascading deletion, when the volume has snapshots, the associated snapshot will be automatically deleted first, and then the volume will be deleted, thereby improving the success rate of deleting the volume."": """", ""Using server groups, you can create cloud hosts on the same/different physical nodes as much as possible to meet the affinity/non-affinity requirements of business applications."": """", ""Uzbekistan"": """", ""VCPU (Core)"": """", ""VCPUs"": """", ""VDI - VirtualBox compatible image format"": """", ""VGPU"": """", ""VGPU (Core)"": """", ""VHD - VirtualPC compatible image format"": """", ""VIF Details"": """", ""VIF Type"": """", ""VMDK - Hyper-V compatible image format"": """", ""VNC"": """", ""VNIC Type"": """", ""VPN"": """", ""VPN EndPoint Groups"": """", ""VPN Gateways"": """", ""VRRP"": """", ""Valid"": """", ""Value"": """", ""Values"": """", ""Vanuatu"": """", ""Vatican City State (Holy See)"": """", ""Vendor Interface"": """", ""Venezuela"": """", ""Verifying"": """", ""Vietnam"": """", ""View"": """", ""View Rules"": """", ""View virtual adapters"": """", ""Virgin Islands (U.S.)"": """", ""Virtual Adapter"": """", ""Virtual Adapter ID"": """", ""Virtual LAN"": """", ""Virtual LANs"": """", ""Virtual Resource Overview"": """", ""Virtual Resources Used"": """", ""Virtual adapter mainly used for binding instance and other operations, occupying the quota of the port."": """", ""Visualization Compute Optimized Type with GPU"": """", ""Wallis And Futuna Islands"": """",",1115,1114
openstack%2Ftripleo-heat-templates~880530,openstack/tripleo-heat-templates,stable/wallaby,Iec12fbaec6655754bc965277978459c40f596365,Run TLS-E in pre_deploy_step_tasks,MERGED,2023-04-14 13:50:16.000000000,2023-07-12 00:51:10.000000000,2023-07-12 00:51:10.000000000,"[{'_account_id': 6926}, {'_account_id': 7414}, {'_account_id': 9816}, {'_account_id': 9914}, {'_account_id': 14250}, {'_account_id': 22348}, {'_account_id': 30073}]","[{'number': 1, 'created': '2023-04-14 13:50:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/034cc3b0d6d87fcab99783aba9f7ab97b176f359', 'message': 'WIP: Run TLS-E in pre_deploy_step_tasks\n\nRunning the TLS-E tasks in the pre_deploy_step_tasks allows us to\nparallelize the ipa_client_install on each node to significantly\nreduce the deployment time.\n\nIn this first iteration, we set a throttle of 20 to try not to\noverwhelm the IPA server.  We might try to add this as a variable\nwith a default.\n\nWe should also make sure that the FRR stuff completes first.\n\nChange-Id: Iec12fbaec6655754bc965277978459c40f596365\n'}, {'number': 2, 'created': '2023-04-17 09:44:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/e32e7ce721c1f624eccbd59d339ce8f894e550af', 'message': 'WIP: Run TLS-E in pre_deploy_step_tasks\n\nRunning the TLS-E tasks in the pre_deploy_step_tasks allows us to\nparallelize the ipa_client_install on each node to significantly\nreduce the deployment time.\n\nIn this first iteration, we set a throttle of 20 to try not to\noverwhelm the IPA server.  We might try to add this as a variable\nwith a default.\n\nWe should also make sure that the FRR stuff completes first.\n\nChange-Id: Iec12fbaec6655754bc965277978459c40f596365\n'}, {'number': 3, 'created': '2023-04-18 09:40:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/80583f2fd63bb03fb716e7e10e571c22ca5e1a74', 'message': 'WIP: Run TLS-E in pre_deploy_step_tasks\n\nRunning the TLS-E tasks in the pre_deploy_step_tasks allows us to\nparallelize the ipa_client_install on each node to significantly\nreduce the deployment time.\n\nIn this first iteration, we set a throttle of 20 to try not to\noverwhelm the IPA server.  We might try to add this as a variable\nwith a default.\n\nWe should also make sure that the FRR stuff completes first.\n\nChange-Id: Iec12fbaec6655754bc965277978459c40f596365\n'}, {'number': 4, 'created': '2023-04-19 14:43:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/16267a3358dc4bd9e3fff6c89c2016c7bb8ceaae', 'message': 'WIP: Run TLS-E in pre_deploy_step_tasks\n\nRunning the TLS-E tasks in the pre_deploy_step_tasks allows us to\nparallelize the ipa_client_install on each node to significantly\nreduce the deployment time.\n\nIn this first iteration, we set a throttle of 20 to try not to\noverwhelm the IPA server.  We might try to add this as a variable\nwith a default.\n\nWe should also make sure that the FRR stuff completes first.\n\nChange-Id: Iec12fbaec6655754bc965277978459c40f596365\n'}, {'number': 5, 'created': '2023-04-20 08:00:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/2963d2c5341a27c5f5625ad0edad457a0c1e9e06', 'message': 'WIP: Run TLS-E in pre_deploy_step_tasks\n\nRunning the TLS-E tasks in the pre_deploy_step_tasks allows us to\nparallelize the ipa_client_install on each node to significantly\nreduce the deployment time.\n\nIn this first iteration, we set a throttle of 20 to try not to\noverwhelm the IPA server.  We might try to add this as a variable\nwith a default.\n\nWe should also make sure that the FRR stuff completes first.\n\nChange-Id: Iec12fbaec6655754bc965277978459c40f596365\n'}, {'number': 6, 'created': '2023-04-21 07:38:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/581c437cdfc7a0fdb1348ce58d51341c4341098f', 'message': 'WIP: Run TLS-E in pre_deploy_step_tasks\n\nRunning the TLS-E tasks in the pre_deploy_step_tasks allows us to\nparallelize the ipa_client_install on each node to significantly\nreduce the deployment time.\n\nIn this first iteration, we set a throttle of 20 to try not to\noverwhelm the IPA server.  We might try to add this as a variable\nwith a default.\n\nWe should also make sure that the FRR stuff completes first.\n\nChange-Id: Iec12fbaec6655754bc965277978459c40f596365\n'}, {'number': 7, 'created': '2023-04-21 10:02:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/ec9eada57cb76d16522ba69ff47f23c3b9d36cd8', 'message': 'WIP: Run TLS-E in pre_deploy_step_tasks\n\nRunning the TLS-E tasks in the pre_deploy_step_tasks allows us to\nparallelize the ipa_client_install on each node to significantly\nreduce the deployment time.\n\nIn this first iteration, we set a throttle of 20 to try not to\noverwhelm the IPA server.  We might try to add this as a variable\nwith a default.\n\nWe should also make sure that the FRR stuff completes first.\n\nChange-Id: Iec12fbaec6655754bc965277978459c40f596365\n'}, {'number': 8, 'created': '2023-04-21 10:12:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/6ab29b2167214388afa1e54df0d24fc854754bb1', 'message': 'WIP: Run TLS-E in pre_deploy_step_tasks\n\nRunning the TLS-E tasks in the pre_deploy_step_tasks allows us to\nparallelize the ipa_client_install on each node to significantly\nreduce the deployment time.\n\nIn this first iteration, we set a throttle of 20 to try not to\noverwhelm the IPA server.  We might try to add this as a variable\nwith a default.\n\nWe should also make sure that the FRR stuff completes first.\n\nChange-Id: Iec12fbaec6655754bc965277978459c40f596365\n'}, {'number': 9, 'created': '2023-04-21 12:24:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/fd3d57f39c746e2aad9937567944eaa2c1ac9b36', 'message': 'WIP: Run TLS-E in pre_deploy_step_tasks\n\nRunning the TLS-E tasks in the pre_deploy_step_tasks allows us to\nparallelize the ipa_client_install on each node to significantly\nreduce the deployment time.\n\nIn this first iteration, we set a throttle of 20 to try not to\noverwhelm the IPA server.  We might try to add this as a variable\nwith a default.\n\nWe should also make sure that the FRR stuff completes first.\n\nChange-Id: Iec12fbaec6655754bc965277978459c40f596365\n'}, {'number': 10, 'created': '2023-05-30 12:30:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/925fd5dd8b56948d18dc4d2a74ca708eea1e9a12', 'message': 'WIP: Run TLS-E in pre_deploy_step_tasks\n\nRunning the TLS-E tasks in the pre_deploy_step_tasks allows us to\nparallelize the ipa_client_install on each node to significantly\nreduce the deployment time.\n\nIn this first iteration, we set a throttle of 20 to try not to\noverwhelm the IPA server.  We might try to add this as a variable\nwith a default.\n\nTODO: We should also make sure that the FRR stuff completes first.\n\nChange-Id: Iec12fbaec6655754bc965277978459c40f596365\n'}, {'number': 11, 'created': '2023-05-30 16:22:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/7ea8f9ab3a1cdb22b98d1067f28cb009c86e664c', 'message': 'WIP: Run TLS-E in pre_deploy_step_tasks\n\nRunning the TLS-E tasks in the pre_deploy_step_tasks allows us to\nparallelize the ipa_client_install on each node to significantly\nreduce the deployment time.\n\nIn this first iteration, we set a throttle of 20 to try not to\noverwhelm the IPA server.  We might try to add this as a variable\nwith a default.\n\nTODO: We should also make sure that the FRR stuff completes first.\n\nChange-Id: Iec12fbaec6655754bc965277978459c40f596365\n'}, {'number': 12, 'created': '2023-05-31 10:57:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/89ec64aeb33203909f49a5a281b13cdc72e8c046', 'message': 'Run TLS-E in pre_deploy_step_tasks\n\nRunning the TLS-E tasks in the pre_deploy_step_tasks allows us to\nparallelize the ipa_client_install on each node to significantly\nreduce the deployment time.\n\nWe also make sure that the FRR, which is also started in\npre_deploy_step_tasks, completes first.\n\nIn this first iteration, we set a throttle of 20 to try not to\noverwhelm the IPA server.  We might try to add this as a variable\nwith a default.\n\nChange-Id: Iec12fbaec6655754bc965277978459c40f596365\n'}, {'number': 13, 'created': '2023-05-31 10:59:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/fde4038f0628c35332dd30df2a7b24a771311704', 'message': 'Run TLS-E in pre_deploy_step_tasks\n\nRunning the TLS-E tasks in the pre_deploy_step_tasks allows us to\nparallelize the ipa_client_install on each node to significantly\nreduce the deployment time.\n\nWe also make sure that the FRR, which is also started in\npre_deploy_step_tasks, completes first.\n\nIn this first iteration, we set a throttle of 20 to try not to\noverwhelm the IPA server.  We might try to add this as a variable\nwith a default.\n\nCo-authored-By: Grzegorz Grasza <xek@redhat.com>\nChange-Id: Iec12fbaec6655754bc965277978459c40f596365\n'}, {'number': 14, 'created': '2023-06-27 16:21:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/0a0df86357ae7e7aadad341aab0833ecf3a7662a', 'message': 'Run TLS-E in pre_deploy_step_tasks\n\nRunning the TLS-E tasks in the pre_deploy_step_tasks allows us to\nparallelize the ipa_client_install on each node to significantly\nreduce the deployment time.\n\nWe also make sure that the FRR, which is also started in\npre_deploy_step_tasks, completes first.\n\nIn this first iteration, we set a throttle of 20 to try not to\noverwhelm the IPA server.  We might try to add this as a variable\nwith a default.\n\nChange-Id: Iec12fbaec6655754bc965277978459c40f596365\n'}, {'number': 15, 'created': '2023-07-10 07:31:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/cba3e38aa7221f8842a98af2dc1a809940526a22', 'message': 'Run TLS-E in pre_deploy_step_tasks\n\nRunning the TLS-E tasks in the pre_deploy_step_tasks allows us to\nparallelize the ipa_client_install on each node to significantly\nreduce the deployment time.\n\nWe also make sure that the FRR, which is also started in\npre_deploy_step_tasks, completes first.\n\nChange-Id: Iec12fbaec6655754bc965277978459c40f596365\n'}, {'number': 16, 'created': '2023-07-10 07:31:54.000000000', 'files': ['deployment/ipa/ipaservices-baremetal-ansible.yaml', 'common/services/role.role.j2.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/09e149f7f2ad0157f3158e77f97ce54699d19c8a', 'message': 'Run TLS-E in pre_deploy_step_tasks\n\nRunning the TLS-E tasks in the pre_deploy_step_tasks allows us to\nparallelize the ipa_client_install on each node to significantly\nreduce the deployment time.\n\nWe also make sure that the FRR, which is also started in\npre_deploy_step_tasks, completes first.\n\nCo-Authored-By: Grzegorz Grasza <xek@redhat.com>\nChange-Id: Iec12fbaec6655754bc965277978459c40f596365\n'}]",17,880530,09e149f7f2ad0157f3158e77f97ce54699d19c8a,44,7,16,9914,,,0,"Run TLS-E in pre_deploy_step_tasks

Running the TLS-E tasks in the pre_deploy_step_tasks allows us to
parallelize the ipa_client_install on each node to significantly
reduce the deployment time.

We also make sure that the FRR, which is also started in
pre_deploy_step_tasks, completes first.

Co-Authored-By: Grzegorz Grasza <xek@redhat.com>
Change-Id: Iec12fbaec6655754bc965277978459c40f596365
",git fetch https://review.opendev.org/openstack/tripleo-heat-templates refs/changes/30/880530/1 && git format-patch -1 --stdout FETCH_HEAD,"['deployment/ipa/ipaservices-baremetal-ansible-undercloud-tasks.yaml', 'deployment/ipa/ipaservices-baremetal-ansible.yaml']",2,034cc3b0d6d87fcab99783aba9f7ab97b176f359,test_parallelizing_tls_e," pre_deploy_step_tasks: - name: add the ipa services for all nodes on the undercloud delegate_to: undercloud import_tasks: file: ipaservices-baremetal-ansible-undercloud-tasks.yaml vars: tripleo_ipa_enroll_base_server: {get_param: IdMEnrollBaseServer} tripleo_ipa_ptr_zone_split_ipv4: {get_param: IdMZoneSplitIPv4} tripleo_ipa_ptr_zone_split_ipv6: {get_param: IdMZoneSplitIPv6} idm_modify_dns: {get_param: IdMModifyDNS} # TODO(alee) make sure this next bit executes on on nodes in # {{ groups['ipaservice'] | difference(groups['excluded_overcloud']) }} throttle: 20 ipaclient_otp: ""{{ hostvars['ipa_host_otp'] }}"" ipaclient_hostname: ""{{ hostvars['fqdn_canonical'] }}"" - ipaclient_hostname # TODO(alee) still needed? - not ipa_conf_exists.stat.exists - not ipa_conf_exists.stat.exists"," external_deploy_tasks: - name: add the ipa services for this node in step 1 when: step|int == 1 block: - name: Ensure ansible_fqdn is defined set_fact: ansible_fqdn: ""{{ ansible_facts['fqdn'] }}"" - include_role: name: tripleo_ipa_registration vars: tripleo_ipa_enroll_base_server: {get_param: IdMEnrollBaseServer} tripleo_ipa_delegate_server: ""{{ item }}"" tripleo_ipa_base_server_fqdn: ""{{ hostvars[item]['fqdn_canonical'] }}"" tripleo_ipa_server_metadata: ""{{ hostvars[item]['service_metadata_settings'] | to_json }}"" loop: ""{{ groups['ipaservice'] | difference(groups['excluded_overcloud']) }}"" - include_role: name: tripleo_ipa_dns vars: tripleo_ipa_ptr_zone_split_ipv4: {get_param: IdMZoneSplitIPv4} tripleo_ipa_ptr_zone_split_ipv6: {get_param: IdMZoneSplitIPv6} when: {get_param: IdMModifyDNS} - IPA_USER: ""nova/{{ ansible_facts['fqdn'] }}"" #NOTE(xek): this is moved to external_deploy_tasks to make sure this happens before certificates are requested from certmonger when: step|int == 1 delegate_to: ""{{ item }}"" loop: ""{{ groups['ipaservice'] | difference(groups['excluded_overcloud']) }}"" delegate_to: ""{{ item }}"" loop: ""{{ groups['ipaservice'] | difference(groups['excluded_overcloud']) }}"" delegate_to: ""{{ outer_item.0 }}"" ipaclient_otp: ""{{ hostvars[outer_item.0]['ipa_host_otp'] }}"" ipaclient_hostname: ""{{ hostvars[outer_item.0]['fqdn_canonical'] }}"" - ""{{ outer_item.0 }}"" - not outer_item.1.stat.exists loop: ""{{ groups['ipaservice']|zip(ipa_conf_exists.results)|list | difference(groups['excluded_overcloud']) }}"" loop_control: loop_var: outer_item delegate_to: ""{{ item.0 }}"" - not item.1.stat.exists loop: ""{{ groups['ipaservice']|zip(ipa_conf_exists.results)|list | difference(groups['excluded_overcloud']) }}"" delegate_to: ""{{ item }}"" delegate_facts: true loop: ""{{ groups['ipaservice'] | difference(groups['excluded_overcloud']) }}""",36,42
openstack%2Fkolla-ansible~888191,openstack/kolla-ansible,master,I6a02bf978b4c89d974944ea3d2bd5dc412a65bdb,ceilometer: clarify ceilometer precheck,ABANDONED,2023-07-11 21:18:48.000000000,2023-07-11 21:23:44.000000000,,[],"[{'number': 1, 'created': '2023-07-11 21:18:48.000000000', 'files': ['ansible/roles/ceilometer/tasks/precheck.yml'], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/c6f024a99a092f4b1f7633549adae740dd193835', 'message': 'ceilometer: clarify ceilometer precheck\n\nChanges after I9fd32f63913a534c59e2d17703702074eea5dd76 enabled an\nadditional storage engine for ceilometer.\n\nChanges after I8c4b0053f2f16b6d243462c4b8117748d26143a0 replaced the\nfail with an assert which is super, but missed the mark as to _when_\nthe assert should be performed.\n\nChange-Id: I6a02bf978b4c89d974944ea3d2bd5dc412a65bdb\n'}]",0,888191,c6f024a99a092f4b1f7633549adae740dd193835,2,0,1,25600,,,0,"ceilometer: clarify ceilometer precheck

Changes after I9fd32f63913a534c59e2d17703702074eea5dd76 enabled an
additional storage engine for ceilometer.

Changes after I8c4b0053f2f16b6d243462c4b8117748d26143a0 replaced the
fail with an assert which is super, but missed the mark as to _when_
the assert should be performed.

Change-Id: I6a02bf978b4c89d974944ea3d2bd5dc412a65bdb
",git fetch https://review.opendev.org/openstack/kolla-ansible refs/changes/91/888191/1 && git format-patch -1 --stdout FETCH_HEAD,['ansible/roles/ceilometer/tasks/precheck.yml'],1,c6f024a99a092f4b1f7633549adae740dd193835,," - enable_gnocchi | bool or enable_ceilometer_prometheus_pushgateway | bool fail_msg: ""At least one Ceilometer publisher must be enabled"" when: - enable_ceilometer | bool"," - not (enable_ceilometer | bool) or enable_gnocchi | bool or enable_ceilometer_prometheus_pushgateway | bool msg: ""At least one Ceilometer publisher must be enabled"" changed_when: false",5,3
openstack%2Fpython-openstackclient~887742,openstack/python-openstackclient,stable/2023.1,Ib5c3b7f86acf1dfe7cc76dfa99fa4c118388bd71,"Fix ""access rule"" commands to only use ID",MERGED,2023-07-05 21:08:59.000000000,2023-07-11 21:19:34.000000000,2023-07-11 21:18:20.000000000,"[{'_account_id': 15334}, {'_account_id': 22348}]","[{'number': 1, 'created': '2023-07-05 21:08:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-openstackclient/commit/7124848f8e4d66449fc7574b7d42b76b5c58ccb7', 'message': 'Fix ""access rule"" commands to only use ID\n\nThis patch modifies the access rule commands to use only the resource\nID.  The previous logic incorrectly assumed that access rules have a\n""name"" property, which resulted in unexpected behaviors.\n\nFor example, ""access rule delete {non-existent-id}"" now results in a\n""not found"" error instead of sometimes deleting an unrelated rule.\n\nStory: 2010775\nTask: 48163\nChange-Id: Ib5c3b7f86acf1dfe7cc76dfa99fa4c118388bd71\n(cherry picked from commit bc60e3bb908a7f10c87993d791184bfe46784d6c)\n'}, {'number': 2, 'created': '2023-07-06 15:46:17.000000000', 'files': ['openstackclient/tests/unit/identity/v3/test_access_rule.py', 'openstackclient/identity/v3/access_rule.py', 'openstackclient/identity/common.py', 'releasenotes/notes/fix-story-2010775-953dbdf03b2b6746.yaml'], 'web_link': 'https://opendev.org/openstack/python-openstackclient/commit/a03e3dbf75c55561bc3575c53db445868be87a3b', 'message': 'Fix ""access rule"" commands to only use ID\n\nThis patch modifies the access rule commands to use only the resource\nID.  The previous logic incorrectly assumed that access rules have a\n""name"" property, which resulted in unexpected behaviors.\n\nFor example, ""access rule delete {non-existent-id}"" now results in a\n""not found"" error instead of sometimes deleting an unrelated rule.\n\nStory: 2010775\nTask: 48163\nChange-Id: Ib5c3b7f86acf1dfe7cc76dfa99fa4c118388bd71\n(cherry picked from commit bc60e3bb908a7f10c87993d791184bfe46784d6c)\n'}]",2,887742,a03e3dbf75c55561bc3575c53db445868be87a3b,15,2,2,7973,,,0,"Fix ""access rule"" commands to only use ID

This patch modifies the access rule commands to use only the resource
ID.  The previous logic incorrectly assumed that access rules have a
""name"" property, which resulted in unexpected behaviors.

For example, ""access rule delete {non-existent-id}"" now results in a
""not found"" error instead of sometimes deleting an unrelated rule.

Story: 2010775
Task: 48163
Change-Id: Ib5c3b7f86acf1dfe7cc76dfa99fa4c118388bd71
(cherry picked from commit bc60e3bb908a7f10c87993d791184bfe46784d6c)
",git fetch https://review.opendev.org/openstack/python-openstackclient refs/changes/42/887742/1 && git format-patch -1 --stdout FETCH_HEAD,"['openstackclient/tests/unit/identity/v3/test_access_rule.py', 'openstackclient/identity/v3/access_rule.py', 'openstackclient/identity/common.py', 'releasenotes/notes/fix-story-2010775-953dbdf03b2b6746.yaml']",4,7124848f8e4d66449fc7574b7d42b76b5c58ccb7,story/2010775,"--- fixes: - | Fixed a bug in ""access rule"" subcommands where the client logic incorrectly assumed that access rules have a ""name"" property which resulted in unpredictable behaviors. e.g. ""access rule delete {non-existent-id}"" now results in a not-found error instead of sometimes deleting an unrelated rule. ",,39,17
openstack%2Ftripleo-heat-templates~888003,openstack/tripleo-heat-templates,master,I274c7f5144c07287a909a2f51fd755727b9f27bc,Fix designate sRBAC overrides,ABANDONED,2023-07-07 23:19:05.000000000,2023-07-11 21:06:42.000000000,,"[{'_account_id': 6681}, {'_account_id': 22348}]","[{'number': 1, 'created': '2023-07-07 23:19:05.000000000', 'files': ['environments/enable-secure-rbac.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/26f379407e8cafb8499edaabb4ba9528f5c08706', 'message': 'Fix designate sRBAC overrides\n\nThe enable-secure-rbac.yaml overrides for designate have some bugs.\nThis patch corrects those to be more in line with the defaults in code for\nnew defaults and no scoped tokens.\n\nChange-Id: I274c7f5144c07287a909a2f51fd755727b9f27bc\n'}]",3,888003,26f379407e8cafb8499edaabb4ba9528f5c08706,7,2,1,11628,,,0,"Fix designate sRBAC overrides

The enable-secure-rbac.yaml overrides for designate have some bugs.
This patch corrects those to be more in line with the defaults in code for
new defaults and no scoped tokens.

Change-Id: I274c7f5144c07287a909a2f51fd755727b9f27bc
",git fetch https://review.opendev.org/openstack/tripleo-heat-templates refs/changes/03/888003/1 && git format-patch -1 --stdout FETCH_HEAD,['environments/enable-secure-rbac.yaml'],1,26f379407e8cafb8499edaabb4ba9528f5c08706,," value: ""role:admin"" value: ""(role:reader and project_id:%(project_id)s) or role:admin"" value: ""(role:reader and project_id:%(project_id)s) or role:admin"" value: ""(role:reader and project_id:%(project_id)s) or role:admin"" value: ""(role:reader and project_id:%(project_id)s) or role:admin"""," value: ""role:reader"" value: ""(role:reader and project_id:%(project_id)s) or (True:%(all_tenants)s and role:reader)"" value: ""(role:reader and project_id:%(project_id)s) or (True:%(all_tenants)s and role:reader)"" value: ""(role:reader and project_id:%(project_id)s) or (True:%(all_tenants)s and role:reader)"" value: ""(role:reader and project_id:%(project_id)s) or (True:%(all_tenants)s and role:reader)""",5,5
openstack%2Fbifrost~855806,openstack/bifrost,master,I2a8e2c7f9118912ff4c5c02ad131f5f792f5e750,Use a more traditional ansible approach to include_vars,ABANDONED,2022-09-04 07:10:43.000000000,2023-07-11 20:34:46.000000000,,"[{'_account_id': 10239}, {'_account_id': 11655}, {'_account_id': 14826}, {'_account_id': 22348}, {'_account_id': 25600}]","[{'number': 1, 'created': '2022-09-04 07:10:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/bifrost/commit/374f79390620a1c18e17b4b3759484dd6fb89ffc', 'message': 'Use a more traditional ansible approach to include_vars\n\nMove all these os-default files to vars directory, where the\ninclude_vars expects them to be.\n\nUse a single lookup, given there are no special distro requirements\nanymore, this ends up being much simpler.\n\nThe lookup order was taken from the openstack-ansible project, and\ncan be extended by copying the family vars file to a more specific\ndistro or versioned file and making necessary the changes, should\nthe need to complicate things ever arise again.\n\nChange-Id: I2a8e2c7f9118912ff4c5c02ad131f5f792f5e750\n'}, {'number': 2, 'created': '2022-09-04 07:17:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/bifrost/commit/595f18b406d47a44b033dffbc220deeffe69b5a1', 'message': 'Use a more traditional ansible approach to include_vars\n\nMove all these os-default files to vars directory, where the\ninclude_vars expects them to be.\n\nUse a single lookup, given there are no special distro requirements\nanymore, this ends up being much simpler.\n\nThe lookup order was taken from the openstack-ansible project, and\ncan be extended by copying the family vars file to a more specific\ndistro or versioned file and making necessary the changes, should\nthe need to complicate things ever arise again.\n\nChange-Id: I2a8e2c7f9118912ff4c5c02ad131f5f792f5e750\n'}, {'number': 3, 'created': '2022-09-14 12:44:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/bifrost/commit/9f34fb2a9b71c3f5fcf083c5d63b2eebd6dcaf1b', 'message': 'Use a more traditional ansible approach to include_vars\n\nMove all these os-default files to vars directory, where the\ninclude_vars expects them to be.\n\nUse a single lookup, given there are no special distro requirements\nanymore, this ends up being much simpler.\n\nThe lookup order was taken from the openstack-ansible project, and\ncan be extended by copying the family vars file to a more specific\ndistro or versioned file and making necessary the changes, should\nthe need to complicate things ever arise again.\n\nChange-Id: I2a8e2c7f9118912ff4c5c02ad131f5f792f5e750\n'}, {'number': 4, 'created': '2022-09-20 06:22:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/bifrost/commit/d97567c3613bd90a44faa7911783a1f2364c4ad9', 'message': 'Use a more traditional ansible approach to include_vars\n\nMove all these os-default files to vars directory, where the\ninclude_vars expects them to be.\n\nUse a single lookup, given there are no special distro requirements\nanymore, this ends up being much simpler.\n\nThe lookup order was taken from the openstack-ansible project, and\ncan be extended by copying the family vars file to a more specific\ndistro or versioned file and making necessary the changes, should\nthe need to complicate things ever arise again.\n\nChange-Id: I2a8e2c7f9118912ff4c5c02ad131f5f792f5e750\n'}, {'number': 5, 'created': '2022-11-02 23:29:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/bifrost/commit/166db88cbc44438769fda21043041a0c0ac535e4', 'message': 'Use a more traditional ansible approach to include_vars\n\nMove all these os-default files to vars directory, where the\ninclude_vars expects them to be.\n\nUse a single lookup, given there are no special distro requirements\nanymore, this ends up being much simpler.\n\nThe lookup order was taken from the openstack-ansible project, and\ncan be extended by copying the family vars file to a more specific\ndistro or versioned file and making necessary the changes, should\nthe need to complicate things ever arise again.\n\nChange-Id: I2a8e2c7f9118912ff4c5c02ad131f5f792f5e750\n'}, {'number': 6, 'created': '2022-11-07 21:28:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/bifrost/commit/495c7866382af0801d9c0a2d2234c0058996c75b', 'message': 'Use a more traditional ansible approach to include_vars\n\nMove all these os-default files to vars directory, where the\ninclude_vars expects them to be.\n\nUse a single lookup, given there are no special distro requirements\nanymore, this ends up being much simpler.\n\nThe lookup order was taken from the openstack-ansible project, and\ncan be extended by copying the family vars file to a more specific\ndistro or versioned file and making necessary the changes, should\nthe need to complicate things ever arise again.\n\nChange-Id: I2a8e2c7f9118912ff4c5c02ad131f5f792f5e750\n'}, {'number': 7, 'created': '2023-02-28 09:43:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/bifrost/commit/1e305873305ef70317b47f3455c3422ece80addd', 'message': 'Use a more traditional ansible approach to include_vars\n\nMove all these os-default files to vars directory, where the\ninclude_vars expects them to be.\n\nUse a single lookup, given there are no special distro requirements\nanymore, this ends up being much simpler.\n\nThe lookup order was taken from the openstack-ansible project, and\ncan be extended by copying the family vars file to a more specific\ndistro or versioned file and making necessary the changes, should\nthe need to complicate things ever arise again.\n\nChange-Id: I2a8e2c7f9118912ff4c5c02ad131f5f792f5e750\n'}, {'number': 8, 'created': '2023-03-02 18:53:10.000000000', 'files': ['playbooks/roles/bifrost-ironic-install/vars/debian.yml', 'playbooks/roles/bifrost-ironic-install/vars/redhat.yml', 'playbooks/roles/bifrost-ironic-install/defaults/dummy-defaults.yml', 'playbooks/roles/bifrost-ironic-install/tasks/main.yml'], 'web_link': 'https://opendev.org/openstack/bifrost/commit/645aba57861935f24f22b4d79edf85430647759a', 'message': 'Use a more traditional ansible approach to include_vars\n\nMove all these os-default files to vars directory, where the\ninclude_vars expects them to be.\n\nUse a single lookup, given there are no special distro requirements\nanymore, this ends up being much simpler.\n\nThe lookup order was taken from the openstack-ansible project, and\ncan be extended by copying the family vars file to a more specific\ndistro or versioned file and making necessary the changes, should\nthe need to complicate things ever arise again.\n\nChange-Id: I2a8e2c7f9118912ff4c5c02ad131f5f792f5e750\n'}]",12,855806,645aba57861935f24f22b4d79edf85430647759a,37,5,8,25600,,,0,"Use a more traditional ansible approach to include_vars

Move all these os-default files to vars directory, where the
include_vars expects them to be.

Use a single lookup, given there are no special distro requirements
anymore, this ends up being much simpler.

The lookup order was taken from the openstack-ansible project, and
can be extended by copying the family vars file to a more specific
distro or versioned file and making necessary the changes, should
the need to complicate things ever arise again.

Change-Id: I2a8e2c7f9118912ff4c5c02ad131f5f792f5e750
",git fetch https://review.opendev.org/openstack/bifrost refs/changes/06/855806/1 && git format-patch -1 --stdout FETCH_HEAD,"['playbooks/roles/bifrost-ironic-install/vars/debian.yml', 'playbooks/roles/bifrost-ironic-install/vars/redhat.yml', 'playbooks/roles/bifrost-ironic-install/defaults/dummy-defaults.yml', 'playbooks/roles/bifrost-ironic-install/vars/suse.yml', 'playbooks/roles/bifrost-ironic-install/tasks/main.yml']",5,374f79390620a1c18e17b4b3759484dd6fb89ffc,ironic-week-prio,"- name: Gather variables for each operating system - ""{{ ansible_facts['distribution'] | lower }}-{{ ansible_facts['distribution_version'] | lower }}.yml"" - ""{{ ansible_facts['distribution'] | lower }}-{{ ansible_facts['distribution_major_version'] | lower }}.yml"" - ""{{ ansible_facts['os_family'] | lower }}-{{ ansible_facts['distribution_major_version'] | lower }}.yml"" - ""{{ ansible_facts['distribution'] | lower }}.yml"" - ""{{ ansible_facts['os_family'] | lower }}-{{ ansible_facts['distribution_version'].split('.')[0] }}.yml"" - ""{{ ansible_facts['os_family'] | lower }}.yml""","- name: Include OS family-specific defaults - ""../defaults/required_defaults_{{ ansible_os_family }}_family.yml"" - ""../defaults/dummy-defaults.yml"" - name: Include OS distribution-specific defaults include_vars: ""{{ item }}"" with_first_found: - ""../defaults/required_defaults_{{ ansible_distribution | regex_replace(' ', '_') }}.yml"" - ""../defaults/dummy-defaults.yml"" - name: Include OS version-specific defaults include_vars: ""{{ item }}"" with_first_found: - ""../defaults/required_defaults_{{ ansible_distribution | regex_replace(' ', '_') }}_{{ ansible_distribution_release }}.yml"" - ""../defaults/required_defaults_{{ ansible_distribution | regex_replace(' ', '_') }}_{{ ansible_distribution_version }}.yml"" - ""../defaults/dummy-defaults.yml""",7,19
openstack%2Fcharm-nova-cloud-controller~888181,openstack/charm-nova-cloud-controller,master,I8fcde16f486fccd717e5a592d51658772ee10c00,Add docs key and point at Discourse,ABANDONED,2023-07-11 19:56:43.000000000,2023-07-11 19:59:20.000000000,,[],"[{'number': 1, 'created': '2023-07-11 19:56:43.000000000', 'files': ['metadata.yaml'], 'web_link': 'https://opendev.org/openstack/charm-nova-cloud-controller/commit/decd5e8b76c35c88c3ebe662445d26e4cb6208aa', 'message': ""Add docs key and point at Discourse\n\nAdd the 'docs' key and point it at a Discourse topic\npreviously populated with the charm's README contents.\n\nWhen the new charm revision is released to the Charmhub,\nthis Discourse-based content will be displayed there. In\nthe absense of the this new key, the Charmhub's default\nbehaviour is to display the value of the charm's\n'description' key.\n\nChange-Id: I8fcde16f486fccd717e5a592d51658772ee10c00\n""}]",0,888181,decd5e8b76c35c88c3ebe662445d26e4cb6208aa,2,0,1,31203,,,0,"Add docs key and point at Discourse

Add the 'docs' key and point it at a Discourse topic
previously populated with the charm's README contents.

When the new charm revision is released to the Charmhub,
this Discourse-based content will be displayed there. In
the absense of the this new key, the Charmhub's default
behaviour is to display the value of the charm's
'description' key.

Change-Id: I8fcde16f486fccd717e5a592d51658772ee10c00
",git fetch https://review.opendev.org/openstack/charm-nova-cloud-controller refs/changes/81/888181/1 && git format-patch -1 --stdout FETCH_HEAD,['metadata.yaml'],1,decd5e8b76c35c88c3ebe662445d26e4cb6208aa,charmhub-pop,docs: https://discourse.charmhub.io/t/cinder-docs-index/10549,,1,0
openstack%2Fkeystone~887072,openstack/keystone,stable/wallaby,I90ef05a924718a0c16f57332746ae0511123cf3a,[stable-only] Cap keystone-tempest-plugin version for stable/wallaby,MERGED,2023-06-27 15:26:48.000000000,2023-07-11 18:38:20.000000000,2023-07-11 18:35:58.000000000,"[{'_account_id': 7414}, {'_account_id': 8556}, {'_account_id': 14250}, {'_account_id': 22348}]","[{'number': 1, 'created': '2023-06-27 15:26:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/e872bc1f97d0a750b11b2ae1a7c670a83001d94b', 'message': '[stable-only] Cap keystone-tempest-plugin version for stable/wallaby\n\nWe have capped stable/wallaby testing with Tempest 29.0.0 (see\ndepends-on), so we need to pin the various DVSM jobs to a compatible\nkeystone-tempest-plugin version.\n\nChange-Id: I90ef05a924718a0c16f57332746ae0511123cf3a\nSigned-off-by: Stephen Finucane <sfinucan@redhat.com>\n'}, {'number': 2, 'created': '2023-06-27 15:28:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/a42698b4af08b7d60588c11bb928db75002b3dd7', 'message': '[stable-only] Cap keystone-tempest-plugin version for stable/wallaby\n\nWe have capped stable/wallaby testing with Tempest 29.0.0 (see\ndepends-on), so we need to pin the various DSVM jobs to a compatible\nkeystone-tempest-plugin version.\n\nChange-Id: I90ef05a924718a0c16f57332746ae0511123cf3a\nSigned-off-by: Stephen Finucane <sfinucan@redhat.com>\n'}, {'number': 3, 'created': '2023-06-27 16:09:30.000000000', 'files': ['.zuul.yaml'], 'web_link': 'https://opendev.org/openstack/keystone/commit/e7a70612296f7dce8804bbcdc2ef624f4534e932', 'message': '[stable-only] Cap keystone-tempest-plugin version for stable/wallaby\n\nWe have capped stable/wallaby testing with Tempest 29.0.0 (see\ndepends-on), so we need to pin the various DSVM jobs to a compatible\nkeystone-tempest-plugin version.\n\nChange-Id: I90ef05a924718a0c16f57332746ae0511123cf3a\nDepends-On: https://review.opendev.org/c/openstack/devstack/+/871782\nSigned-off-by: Stephen Finucane <sfinucan@redhat.com>\n'}]",1,887072,e7a70612296f7dce8804bbcdc2ef624f4534e932,13,4,3,15334,,,0,"[stable-only] Cap keystone-tempest-plugin version for stable/wallaby

We have capped stable/wallaby testing with Tempest 29.0.0 (see
depends-on), so we need to pin the various DSVM jobs to a compatible
keystone-tempest-plugin version.

Change-Id: I90ef05a924718a0c16f57332746ae0511123cf3a
Depends-On: https://review.opendev.org/c/openstack/devstack/+/871782
Signed-off-by: Stephen Finucane <sfinucan@redhat.com>
",git fetch https://review.opendev.org/openstack/keystone refs/changes/72/887072/1 && git format-patch -1 --stdout FETCH_HEAD,['.zuul.yaml'],1,e872bc1f97d0a750b11b2ae1a7c670a83001d94b,wallaby-pin-tempest, - name: openstack/keystone-tempest-plugin override-checkout: wallaby-last, - openstack/keystone-tempest-plugin,2,1
openstack%2Fkeystone~887509,openstack/keystone,master,I74e47a9ed986c7c3af19676ac65f4d290bcb4cc0,sql: Remove service_provider.relay_state_prefix default,MERGED,2023-07-03 11:12:31.000000000,2023-07-11 18:37:57.000000000,2023-07-11 18:35:55.000000000,"[{'_account_id': 7414}, {'_account_id': 14250}, {'_account_id': 22348}]","[{'number': 1, 'created': '2023-07-03 11:12:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/4cf57574179fce140c26ab520edad3ad5045bfaa', 'message': ""sql: Remove service_provider.relay_state_prefix default\n\nWe shouldn't specify a server default for a configurable option since it\nmeans our initial database schema is not consistently reproducible.\nInstead, we should specify the default at runtime. It turns out we\nalready do this and the server default was overkill. We can remove it.\n\nChange-Id: I74e47a9ed986c7c3af19676ac65f4d290bcb4cc0\nSigned-off-by: Stephen Finucane <sfinucan@redhat.com>\n""}, {'number': 2, 'created': '2023-07-03 11:33:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/b14aefd6a9a72729547ef201bcdeac7e143e146f', 'message': ""sql: Remove service_provider.relay_state_prefix default\n\nWe shouldn't specify a server default for a configurable option since it\nmeans our initial database schema is not consistently reproducible.\nInstead, we should specify the default at runtime. It turns out we\nalready do this and the server default was overkill. We can remove it.\n\nChange-Id: I74e47a9ed986c7c3af19676ac65f4d290bcb4cc0\nSigned-off-by: Stephen Finucane <sfinucan@redhat.com>\n""}, {'number': 3, 'created': '2023-07-06 09:23:32.000000000', 'files': ['keystone/common/sql/migrations/versions/EXPAND_HEAD', 'keystone/common/sql/migrations/versions/bobcat/expand/11c3b243b4cb_remove_service_provider_relay_state_server_default.py', 'keystone/federation/backends/sql.py', 'keystone/tests/unit/test_sql_banned_operations.py', 'keystone/api/os_federation.py'], 'web_link': 'https://opendev.org/openstack/keystone/commit/845e5b24949bc0cdd021c9e9a0cf88bc74e7b3e8', 'message': ""sql: Remove service_provider.relay_state_prefix default\n\nWe shouldn't specify a server default for a configurable option since it\nmeans our initial database schema is not consistently reproducible.\nInstead, we should specify the default at runtime. It turns out we\nalready do this and the server default was overkill. We can remove it.\n\nChange-Id: I74e47a9ed986c7c3af19676ac65f4d290bcb4cc0\nSigned-off-by: Stephen Finucane <sfinucan@redhat.com>\n""}]",3,887509,845e5b24949bc0cdd021c9e9a0cf88bc74e7b3e8,25,3,3,15334,,,0,"sql: Remove service_provider.relay_state_prefix default

We shouldn't specify a server default for a configurable option since it
means our initial database schema is not consistently reproducible.
Instead, we should specify the default at runtime. It turns out we
already do this and the server default was overkill. We can remove it.

Change-Id: I74e47a9ed986c7c3af19676ac65f4d290bcb4cc0
Signed-off-by: Stephen Finucane <sfinucan@redhat.com>
",git fetch https://review.opendev.org/openstack/keystone refs/changes/09/887509/1 && git format-patch -1 --stdout FETCH_HEAD,"['keystone/common/sql/migrations/versions/bobcat/expand/11c3b243b4cb_remove_service_provider_relay_state_server_default.py', 'keystone/federation/backends/sql.py', 'keystone/api/os_federation.py']",3,4cf57574179fce140c26ab520edad3ad5045bfaa,sqlalchemy-20," sp.setdefault('relay_state_prefix', CONF.saml.relay_state_prefix)"," sp.setdefault('relay_state_prefix', CONF.saml.relay_state_prefix)",36,19
openstack%2Fhorizon~888135,openstack/horizon,master,Ib7158d4c3859576016605fa4e688dbb166156078,Increase explicit wait to avoid timeout error during loading spinner,MERGED,2023-07-11 13:37:41.000000000,2023-07-11 18:03:06.000000000,2023-07-11 18:02:01.000000000,"[{'_account_id': 6914}, {'_account_id': 8648}, {'_account_id': 22348}, {'_account_id': 29313}]","[{'number': 1, 'created': '2023-07-11 13:37:41.000000000', 'files': ['openstack_dashboard/test/integration_tests/horizon.conf'], 'web_link': 'https://opendev.org/openstack/horizon/commit/e6f398715ef1090dc28836cae38e5e7ce2ecf267', 'message': 'Increase explicit wait to avoid timeout error during loading spinner\n\nChange-Id: Ib7158d4c3859576016605fa4e688dbb166156078\n'}]",1,888135,e6f398715ef1090dc28836cae38e5e7ce2ecf267,8,4,1,35133,,,0,"Increase explicit wait to avoid timeout error during loading spinner

Change-Id: Ib7158d4c3859576016605fa4e688dbb166156078
",git fetch https://review.opendev.org/openstack/horizon refs/changes/35/888135/1 && git format-patch -1 --stdout FETCH_HEAD,['openstack_dashboard/test/integration_tests/horizon.conf'],1,e6f398715ef1090dc28836cae38e5e7ce2ecf267,,explicit_wait=180,explicit_wait=90,1,1
openstack%2Fcharm-ironic-conductor~887901,openstack/charm-ironic-conductor,stable/victoria,I97e5d6aecf977e0217665c83c63b69672da0590c,Use service_domain in [service_user] section,MERGED,2023-07-06 20:03:08.000000000,2023-07-11 18:02:54.000000000,2023-07-11 18:02:54.000000000,"[{'_account_id': 8992}, {'_account_id': 20648}, {'_account_id': 20870}, {'_account_id': 22348}]","[{'number': 1, 'created': '2023-07-06 20:03:08.000000000', 'files': ['src/build.lock'], 'web_link': 'https://opendev.org/openstack/charm-ironic-conductor/commit/c71ed343fb3d0be116901fe7f6b2a55b79b7f6be', 'message': 'Use service_domain in [service_user] section\n\nRebuild to update [service_user] config to use the service domain.\nThis was fixed in charm-helpers.\n\nThe keystone charm currently creates two service users, one for the\nservice domain (for v3 authentication), and the other for the default\ndomain (for v2 authentication). The [service_user] config needs to\nuse the service domain.\n\nCloses-Bug: #2026202\nChange-Id: I97e5d6aecf977e0217665c83c63b69672da0590c\n'}]",1,887901,c71ed343fb3d0be116901fe7f6b2a55b79b7f6be,10,4,1,11805,,,0,"Use service_domain in [service_user] section

Rebuild to update [service_user] config to use the service domain.
This was fixed in charm-helpers.

The keystone charm currently creates two service users, one for the
service domain (for v3 authentication), and the other for the default
domain (for v2 authentication). The [service_user] config needs to
use the service domain.

Closes-Bug: #2026202
Change-Id: I97e5d6aecf977e0217665c83c63b69672da0590c
",git fetch https://review.opendev.org/openstack/charm-ironic-conductor refs/changes/01/887901/1 && git format-patch -1 --stdout FETCH_HEAD,['src/build.lock'],1,c71ed343fb3d0be116901fe7f6b2a55b79b7f6be,bug/2026202," ""version"": ""e8c021f99d1a6fdb795ae5a869ef8241ab2b79ba"","," ""version"": ""7d2e709dc443b24177db524eb6b0c44639532479"",",1,1
openstack%2Fglance_store~888155,openstack/glance_store,stable/2023.1,Ia94dd1d12a3d723f6263bdfb0966d416dfbae1af,Do not always import boto3,MERGED,2023-07-11 13:56:56.000000000,2023-07-11 17:16:17.000000000,2023-07-11 17:15:19.000000000,"[{'_account_id': 9303}, {'_account_id': 22348}]","[{'number': 1, 'created': '2023-07-11 13:56:56.000000000', 'files': ['glance_store/_drivers/s3.py'], 'web_link': 'https://opendev.org/openstack/glance_store/commit/d68a84220a64619b431eff093142cf017936679f', 'message': 'Do not always import boto3\n\nCurrently boto3 is not part of requirements but stevedore always tries\nto import it and shows error in case boto3 is missing. This is not\na real error unless users actually enable s3 backends and can be quite\nconfusing.\n\nThis makes the driver code ignore ImportError and actually fail only\nif users try to enable s3 backend without installing boto3.\n\nCloses-Bug: #2007924\nChange-Id: Ia94dd1d12a3d723f6263bdfb0966d416dfbae1af\n(cherry picked from commit 7dc94f7a85e976a9c66f997f944c6ede06d7984a)\n'}]",1,888155,d68a84220a64619b431eff093142cf017936679f,7,2,1,29775,,,0,"Do not always import boto3

Currently boto3 is not part of requirements but stevedore always tries
to import it and shows error in case boto3 is missing. This is not
a real error unless users actually enable s3 backends and can be quite
confusing.

This makes the driver code ignore ImportError and actually fail only
if users try to enable s3 backend without installing boto3.

Closes-Bug: #2007924
Change-Id: Ia94dd1d12a3d723f6263bdfb0966d416dfbae1af
(cherry picked from commit 7dc94f7a85e976a9c66f997f944c6ede06d7984a)
",git fetch https://review.opendev.org/openstack/glance_store refs/changes/55/888155/1 && git format-patch -1 --stdout FETCH_HEAD,['glance_store/_drivers/s3.py'],1,d68a84220a64619b431eff093142cf017936679f,bug/2007924-stable/2023.1,"try: from boto3 import session as boto_session from botocore import client as boto_client from botocore import exceptions as boto_exceptions from botocore import utils as boto_utils except ImportError: boto_session = None boto_client = None boto_exceptions = None boto_utils = None if boto_session is None: reason = _(""boto3 or botocore is not available."") LOG.error(reason) raise exceptions.BadStoreConfiguration(store_name=""s3"", reason=reason) ",from boto3 import session as boto_session from botocore import client as boto_client from botocore import exceptions as boto_exceptions from botocore import utils as boto_utils,17,4
openstack%2Fnova~887943,openstack/nova,stable/train,I83ab667e32bbfa6a2a09760ebcfb4c10beee62f5,DNM: Experimental Fallout,ABANDONED,2023-07-07 11:09:18.000000000,2023-07-11 17:06:58.000000000,,[],"[{'number': 1, 'created': '2023-07-07 11:09:18.000000000', 'files': ['.zuul.yaml'], 'web_link': 'https://opendev.org/openstack/nova/commit/9e705ad986400759b340ae51007ca577f7d5d78f', 'message': ""DNM: Experimental Fallout\n\n... let's see if Zuul warns us that we deleted some job definition that\nother projects are using.\n\nChange-Id: I83ab667e32bbfa6a2a09760ebcfb4c10beee62f5\n""}]",0,887943,9e705ad986400759b340ae51007ca577f7d5d78f,2,0,1,17685,,,0,"DNM: Experimental Fallout

... let's see if Zuul warns us that we deleted some job definition that
other projects are using.

Change-Id: I83ab667e32bbfa6a2a09760ebcfb4c10beee62f5
",git fetch https://review.opendev.org/openstack/nova refs/changes/43/887943/1 && git format-patch -1 --stdout FETCH_HEAD,['.zuul.yaml'],1,9e705ad986400759b340ae51007ca577f7d5d78f,do-not-merge-fallout,- project:,"# See https://docs.openstack.org/infra/manual/drivers.html#naming-with-zuul-v3 # for job naming conventions. - job: name: nova-dsvm-base parent: legacy-dsvm-base description: | The base job definition for nova devstack/tempest jobs. Contains common configuration. timeout: 10800 required-projects: - openstack/devstack-gate - openstack/nova - openstack/tempest irrelevant-files: &dsvm-irrelevant-files - ^api-.*$ - ^(test-|)requirements.txt$ - ^.*\.rst$ - ^.git.*$ - ^doc/.*$ - ^nova/hacking/.*$ - ^nova/locale/.*$ - ^nova/tests/.*$ - ^nova/test.py$ - ^releasenotes/.*$ - ^setup.cfg$ - ^tests-py3.txt$ - ^tools/.*$ - ^tox.ini$ - job: name: nova-dsvm-multinode-base parent: legacy-dsvm-base-multinode description: | Base job for multinode nova devstack/tempest jobs. Will setup firewall rules on all the nodes allowing them to talk to each other. timeout: 10800 required-projects: - openstack/devstack-gate - openstack/nova - openstack/tempest irrelevant-files: *dsvm-irrelevant-files - job: name: nova-tox-functional parent: openstack-tox description: | Run tox-based functional tests for the OpenStack Nova project with Nova specific irrelevant-files list. Uses tox with the ``functional`` environment. This job also provides a parent for other projects to run the nova functional tests on their own changes. required-projects: # including nova here makes this job reusable by other projects - openstack/nova - openstack/placement irrelevant-files: &functional-irrelevant-files - ^.*\.rst$ - ^api-.*$ - ^doc/source/.*$ - ^nova/locale/.*$ - ^releasenotes/.*$ vars: # explicitly stating the work dir makes this job reusable by other # projects zuul_work_dir: src/opendev.org/openstack/nova tox_envlist: functional tox_install_siblings: true timeout: 3600 - job: name: nova-tox-functional-py36 parent: openstack-tox nodeset: ubuntu-bionic description: | Run tox-based functional tests for the OpenStack Nova project under cPython version 3.6 with Nova specific irrelevant-files list. Uses tox with the ``functional-py36`` environment. This job also provides a parent for other projects (notably placement) to run the nova functional tests on their own changes. required-projects: # including nova here makes this job reusable by other projects - openstack/nova - openstack/placement irrelevant-files: *functional-irrelevant-files vars: # explicitly stating the work dir makes this job reusable by other # projects zuul_work_dir: src/opendev.org/openstack/nova tox_envlist: functional-py36 bindep_profile: test py36 timeout: 3600 - job: name: nova-tox-functional-py37 parent: openstack-tox nodeset: ubuntu-bionic description: | Run tox-based functional tests for the OpenStack Nova project under cPython version 3.7 with Nova specific irrelevant-files list. Uses tox with the ``functional-py37`` environment. This job also provides a parent for other projects to run the nova functional tests on their own changes. required-projects: # including nova here makes this job reusable by other projects - openstack/nova - openstack/placement irrelevant-files: *functional-irrelevant-files vars: # explicitly stating the work dir makes this job reusable by other # projects zuul_work_dir: src/opendev.org/openstack/nova tox_envlist: functional-py37 bindep_profile: test py37 python_version: 3.7 timeout: 3600 - job: name: nova-tox-validate-backport parent: openstack-tox description: | Determine whether a backport is ready to be merged by checking whether it has already been merged to master or more recent stable branches. Uses tox with the ``validate-backport`` environment. vars: tox_envlist: validate-backport - job: name: nova-live-migration parent: tempest-multinode-full-py3 description: | Run tempest live migration tests against local qcow2 ephemeral storage and shared LVM/iSCSI cinder volumes. irrelevant-files: *dsvm-irrelevant-files vars: tox_envlist: all tempest_test_regex: (^tempest\.api\.compute\.admin\.(test_live_migration|test_migration)) devstack_local_conf: test-config: $TEMPEST_CONFIG: compute-feature-enabled: volume_backed_live_migration: true block_migration_for_live_migration: true block_migrate_cinder_iscsi: true post-run: playbooks/nova-live-migration/post-run.yaml # TODO(lyarwood): The following jobs need to be written as part of the # migration to zuulv3 before nova-live-migration can be removed: # #- job: # name: nova-multinode-live-migration-ceph # description: | # Run tempest live migration tests against ceph ephemeral storage and # cinder volumes. #- job: # name: nova-multinode-evacuate-ceph # description: | # Verifiy the evacuation of instances with ceph ephemeral disks # from down compute hosts. - job: name: nova-lvm parent: devstack-tempest description: | Run tempest compute API tests using LVM image backend. This only runs against nova/virt/libvirt/* changes. # Copy irrelevant-files from nova-dsvm-base and then exclude anything # that is not in nova/virt/libvirt/* or nova/privsep/*. irrelevant-files: - ^(?!.zuul.yaml)(?!nova/virt/libvirt/)(?!nova/privsep/).*$ - ^api-.*$ - ^(test-|)requirements.txt$ - ^.*\.rst$ - ^.git.*$ - ^doc/.*$ - ^nova/hacking/.*$ - ^nova/locale/.*$ - ^nova/tests/.*$ - ^nova/test.py$ - ^releasenotes/.*$ - ^setup.cfg$ - ^tests-py3.txt$ - ^tools/.*$ - ^tox.ini$ # TODO(mriedem): Make this voting and gating once bug 1771700 is fixed # and we've had enough runs to feel comfortable with this setup. voting: false vars: # We use the ""all"" environment for tempest_test_regex and # tempest_black_regex. tox_envlist: all # Only run compute API tests. tempest_test_regex: ^tempest\.api\.compute # Skip slow tests. tempest_black_regex: .*\[.*\bslow\b.*\] devstack_local_conf: test-config: $TEMPEST_CONFIG: compute-feature-enabled: # NOTE(mriedem): resize of non-volume-backed lvm instances does # not yet work (bug 1831657). resize: false cold_migration: false devstack_localrc: USE_PYTHON3: True NOVA_BACKEND: LVM # Do not waste time clearing volumes. LVM_VOLUME_CLEAR: none # Disable SSH validation in tests to save time. TEMPEST_RUN_VALIDATION: false devstack_services: # Disable non-essential services that we don't need for this job. c-bak: false - job: name: nova-next parent: devstack-tempest description: | This job was added in Newton when placement and cellsv2 were optional. Placement and cellsv2 are required starting in Ocata. In Pike, the service user token functionality was added. This job is also unique in that it runs the post_test_hook from the nova repo, which runs post-test scripts to ensure those scripts are still working, e.g. archive_deleted_rows. In Queens, this job started testing the TLS console proxy code in the libvirt driver. Starting in Stein, the job was changed to run with python 3 and enabled volume multi-attach testing. Starting in Train, the job enabled counting quota usage from placement. Runs all tempest compute API and most scenario tests concurrently. irrelevant-files: *dsvm-irrelevant-files # Run post-tempest tests like for nova-manage commands. post-run: playbooks/nova-next/post.yaml vars: # We use the ""all"" environment for tempest_test_regex and # tempest_black_regex. tox_envlist: all # Run all compute API tests and most scenario tests at the default # concurrency (nproc/2 which is normally 4 in the gate). tempest_test_regex: ^tempest\.(scenario|api\.compute) # The tempest.scenario.test_network* tests are skipped because they # (1) take a long time and (2) are already covered in the # tempest-slow* job. If this regex gets more complicated use # tempest_test_blacklist. tempest_black_regex: ^tempest.scenario.test_network devstack_local_conf: post-config: $NOVA_CPU_CONF: compute: # Switch off the provider association refresh, which should # reduce the number of placement calls in steady state. Added in # Stein. resource_provider_association_refresh: 0 $NOVA_CONF: quota: # Added in Train. count_usage_from_placement: True scheduler: # Added in Train. query_placement_for_image_type_support: True devstack_localrc: # Added in Pike. NOVA_USE_SERVICE_TOKEN: True # Enable TLS between the noVNC proxy & compute nodes; this requires # the tls-proxy service to be enabled. Added in Queens. NOVA_CONSOLE_PROXY_COMPUTE_TLS: True # Added in Stein. USE_PYTHON3: True # Added in Stein. ENABLE_VOLUME_MULTIATTACH: True devstack_services: tls-proxy: true # Disable non-essential services that we don't need for this job. c-bak: false - job: name: nova-tempest-v2-api parent: devstack-tempest branches: - master description: | This job runs the Tempest compute tests against v2.0 endpoint. Former names for this job was: * legacy-tempest-dsvm-nova-v20-api vars: tox_envlist: all tempest_test_regex: api.*compute devstack_localrc: TEMPEST_COMPUTE_TYPE: compute_legacy - job: name: nova-tempest-full-oslo.versionedobjects parent: tempest-full description: | Run test with git version of oslo.versionedobjects to check that changes to nova will work with the next released version of that library. required-projects: - openstack/oslo.versionedobjects - job: name: nova-grenade-multinode parent: grenade-multinode description: | Run a multinode grenade job and run the smoke, cold and live migration tests with the controller upgraded and the compute on the older release. The former names for this job were ""nova-grenade-live-migration"" and ""legacy-grenade-dsvm-neutron-multinode-live-migration"". irrelevant-files: *dsvm-irrelevant-files vars: devstack_local_conf: test-config: $TEMPEST_CONFIG: compute-feature-enabled: live_migration: true volume_backed_live_migration: true block_migration_for_live_migration: true block_migrate_cinder_iscsi: true tox_envlist: all tempest_test_regex: ((tempest\.(api\.compute|scenario)\..*smoke.*)|(^tempest\.api\.compute\.admin\.(test_live_migration|test_migration))) - job: name: nova-multi-cell parent: tempest-multinode-full-py3 description: | Multi-node python3 job which runs with two nodes and two non-cell0 cells. The compute on the controller runs in cell1 and the compute on the subnode runs in cell2. irrelevant-files: *dsvm-irrelevant-files vars: # We use the ""all"" environment for tempest_test_regex and # tempest_test_blacklist. tox_envlist: all # Run compute API and scenario tests. tempest_test_regex: ^tempest\.(scenario|(api\.compute)) tempest_test_blacklist: '{{ ansible_user_dir }}/{{ zuul.projects[""opendev.org/openstack/nova""].src_dir }}/devstack/nova-multi-cell-blacklist.txt' devstack_local_conf: test-config: $TEMPEST_CONFIG: compute-feature-enabled: # TODO(mriedem): Enable cold migration once cross-cell resize is # supported. We cannot enable it until then because this job has # one compute in each cell and with # allow_resize_to_same_host=True cold migrate will try to migrate # on the same host which is not supported by the libvirt driver. cold_migration: false devstack_services: # Disable other non-essential services that we don't need for this job. c-bak: false devstack_localrc: # Setup two non-cell0 cells (cell1 and cell2). NOVA_NUM_CELLS: 2 # Resize to the same host is supported for now since we only have # two computes and they are in different cells. # TODO(mriedem): Disable resize to the same host once cross-cell resize # is supported so all resizes will move across cells. NOVA_ALLOW_MOVE_TO_SAME_HOST: true # We only have two computes and we don't yet support cross-cell live # migration. LIVE_MIGRATION_AVAILABLE: false group-vars: peers: devstack_localrc: NOVA_ALLOW_MOVE_TO_SAME_HOST: true LIVE_MIGRATION_AVAILABLE: false subnode: devstack_localrc: # The subnode compute will get registered with cell2. NOVA_CPU_CELL: 2 devstack_services: # Disable other non-essential services that we don't need for this # job. c-bak: false - job: name: nova-osprofiler-redis parent: tempest-smoke-py3-osprofiler-redis description: | Runs osprofiler with the Redis collector on a subset of compute-specific tempest-full-py3 smoke tests. irrelevant-files: *dsvm-irrelevant-files required-projects: - openstack/nova vars: # We use the ""all"" environment for tempest_test_regex. tox_envlist: all # Run compute API and only the test_server_basic_ops scenario tests. tempest_test_regex: ^tempest\.(scenario\.test_server_basic_ops|(api\.compute)) - project: # Please try to keep the list of job names sorted alphabetically. templates: - integrated-gate-compute - openstack-cover-jobs - openstack-python-jobs - openstack-python3-train-jobs - periodic-stable-jobs - publish-openstack-docs-pti - release-notes-jobs-python3 # We define our own irrelevant-files so we don't run the job # on things like nova docs-only changes. - ironic-tempest-ipa-wholedisk-bios-agent_ipmitool-tinyipa: voting: false irrelevant-files: *dsvm-irrelevant-files - devstack-plugin-ceph-tempest: voting: false irrelevant-files: *dsvm-irrelevant-files - neutron-grenade-multinode: irrelevant-files: *dsvm-irrelevant-files - neutron-tempest-linuxbridge: irrelevant-files: # NOTE(mriedem): This job has its own irrelevant-files section # so that we only run it on changes to networking and libvirt/vif # code; we don't need to run this on all changes, nor do we run # it in the gate. - ^(?!nova/network/.*)(?!nova/virt/libvirt/vif.py).*$ - nova-live-migration - nova-lvm - nova-multi-cell - nova-next - nova-tox-functional - nova-tox-functional-py36 - nova-tox-validate-backport: voting: false - tempest-integrated-compute: irrelevant-files: *dsvm-irrelevant-files - tempest-slow-py3: irrelevant-files: *dsvm-irrelevant-files - nova-grenade-multinode: irrelevant-files: *dsvm-irrelevant-files - tempest-ipv6-only: irrelevant-files: *dsvm-irrelevant-files - nova-live-migration - nova-tox-functional - nova-tox-functional-py36 - nova-multi-cell - nova-next - nova-tox-validate-backport - tempest-integrated-compute: irrelevant-files: *dsvm-irrelevant-files - tempest-slow-py3: irrelevant-files: *dsvm-irrelevant-files - nova-grenade-multinode: irrelevant-files: *dsvm-irrelevant-files - tempest-ipv6-only: irrelevant-files: *dsvm-irrelevant-files experimental: jobs: - ironic-tempest-bfv: irrelevant-files: *dsvm-irrelevant-files - ironic-tempest-ipa-wholedisk-direct-tinyipa-multinode: irrelevant-files: *dsvm-irrelevant-files - barbican-simple-crypto-devstack-tempest: irrelevant-files: *dsvm-irrelevant-files - devstack-plugin-ceph-tempest-py3: irrelevant-files: *dsvm-irrelevant-files - legacy-grenade-dsvm-neutron-multinode-zero-downtime: irrelevant-files: *dsvm-irrelevant-files - devstack-plugin-nfs-tempest-full: irrelevant-files: *dsvm-irrelevant-files - nova-osprofiler-redis - tempest-full-py3-opensuse15: irrelevant-files: *dsvm-irrelevant-files - tempest-pg-full: irrelevant-files: *dsvm-irrelevant-files - nova-tempest-full-oslo.versionedobjects: irrelevant-files: *dsvm-irrelevant-files - legacy-tempest-dsvm-nova-libvirt-kvm-apr: irrelevant-files: *dsvm-irrelevant-files - nova-tempest-v2-api: irrelevant-files: *dsvm-irrelevant-files - neutron-tempest-dvr-ha-multinode-full: irrelevant-files: *dsvm-irrelevant-files - neutron-tempest-iptables_hybrid: irrelevant-files: *dsvm-irrelevant-files - os-vif-ovs: irrelevant-files: *dsvm-irrelevant-files # NOTE(mriedem): Consider moving nova-tox-functional-py37 to the # check and gate queues once it's stable (like openstack-python37-jobs) - nova-tox-functional-py37",0,482
openstack%2Freleases~888128,openstack/releases,master,I5ce388ff43e4ee951e56a2461cc1a959dde64426,Release horizon 23.2.0(bobcat),MERGED,2023-07-11 10:48:30.000000000,2023-07-11 16:56:37.000000000,2023-07-11 16:56:37.000000000,"[{'_account_id': 17685}, {'_account_id': 22348}, {'_account_id': 28522}]","[{'number': 1, 'created': '2023-07-11 10:48:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/releases/commit/2cdbdad73e5eb90f34060cc75d84493c07448e47', 'message': 'Release horizon 23.2.0(bobcat)\n\nThis patch cut the first release of the horizon for the bobcat cycle.\nhorizon recently bumped the upper version of Xstatic-jQuery version from\n1.12.4.1->3.5.1.1[1] but the patch which update the upper bound in the\nopenstack/requirements is failing as of now [2] beacuse horizon 23.1.0\ndepends on XStatic-jQuery<2 and >=1.12.4.1. The main purpose of\nthis release is to fix the above version compatibility  issue.\n\n[1] https://review.opendev.org/c/openstack/horizon/+/887548\n[2] https://review.opendev.org/c/openstack/requirements/+/887933\n\nChange-Id: I5ce388ff43e4ee951e56a2461cc1a959dde64426\n'}, {'number': 2, 'created': '2023-07-11 12:30:18.000000000', 'files': ['deliverables/bobcat/horizon.yaml'], 'web_link': 'https://opendev.org/openstack/releases/commit/6d64693748fb74bf3b4e476fcda84d9d4c382d27', 'message': 'Release horizon 23.2.0(bobcat)\n\nThis patch cut the first release of the horizon for the bobcat cycle.\nhorizon recently bumped the upper version of Xstatic-jQuery version from\n1.12.4.1->3.5.1.1[1] but the patch which update the upper bound in the\nopenstack/requirements is failing as of now [2] beacuse horizon 23.1.0\ndepends on XStatic-jQuery<2 and >=1.12.4.1. The main purpose of\nthis release is to fix the above version compatibility  issue.\n\n[1] https://review.opendev.org/c/openstack/horizon/+/887548\n[2] https://review.opendev.org/c/openstack/requirements/+/887933\n\nChange-Id: I5ce388ff43e4ee951e56a2461cc1a959dde64426\n'}]",1,888128,6d64693748fb74bf3b4e476fcda84d9d4c382d27,11,3,2,29313,,,0,"Release horizon 23.2.0(bobcat)

This patch cut the first release of the horizon for the bobcat cycle.
horizon recently bumped the upper version of Xstatic-jQuery version from
1.12.4.1->3.5.1.1[1] but the patch which update the upper bound in the
openstack/requirements is failing as of now [2] beacuse horizon 23.1.0
depends on XStatic-jQuery<2 and >=1.12.4.1. The main purpose of
this release is to fix the above version compatibility  issue.

[1] https://review.opendev.org/c/openstack/horizon/+/887548
[2] https://review.opendev.org/c/openstack/requirements/+/887933

Change-Id: I5ce388ff43e4ee951e56a2461cc1a959dde64426
",git fetch https://review.opendev.org/openstack/releases refs/changes/28/888128/1 && git format-patch -1 --stdout FETCH_HEAD,['deliverables/bobcat/horizon.yaml'],1,2cdbdad73e5eb90f34060cc75d84493c07448e47,, releases: - version: 23.2.0 projects: - repo: openstack/horizon hash: 480aba9422384348730b2464de1cfe2eafd4aa78,,5,0
openstack%2Fhorizon~887935,openstack/horizon,master,I0c9e76f81c696b36ba3d7c7a06eaf0bbc875625d,[DNM] Pin XStatic-JQuery==2.2.4.1 to make it work with jquery-migrate,ABANDONED,2023-07-07 08:46:33.000000000,2023-07-11 16:12:58.000000000,,[{'_account_id': 22348}],"[{'number': 1, 'created': '2023-07-07 08:46:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/ad9bef317918fddbfa7279b75f5425f6ae8bff8a', 'message': 'Pin XStatic-JQuery==2.2.4.1 to make it work with jquery-migrate\n\nThe jquery-migrate 3 requires newer jquery than we have.\n\nAlso added all the other fixes for integration tests to see if that\nresolves our problems.\n\nThis needs https://review.opendev.org/c/openstack/requirements/+/887607\nmerged first.\n\nChange-Id: I9b8a5e8abe734e7fd99aa0066ede0377e34fbf44\n\nDepends-On: https://review.opendev.org/c/openstack/requirements/+/887933\nChange-Id: I0c9e76f81c696b36ba3d7c7a06eaf0bbc875625d\n'}, {'number': 2, 'created': '2023-07-08 12:45:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/7cb499457e243f21b78a19b7ed1f1d30c0e21c12', 'message': '[DNM] Pin XStatic-JQuery==2.2.4.1 to make it work with jquery-migrate\n\nThe jquery-migrate 3 requires newer jquery than we have.\n\nAlso added all the other fixes for integration tests to see if that\nresolves our problems.\n\nThis needs https://review.opendev.org/c/openstack/requirements/+/887607\nmerged first.\n\nChange-Id: I0c9e76f81c696b36ba3d7c7a06eaf0bbc875625d\n'}, {'number': 3, 'created': '2023-07-09 06:33:41.000000000', 'files': ['requirements.txt', 'openstack_dashboard/test/integration_tests/config.py', 'openstack_dashboard/test/integration_tests/horizon.conf', 'test-upper.txt', 'openstack_dashboard/dashboards/project/static/dashboard/project/workflow/launch-instance/keypair/keypair.html', 'tox.ini'], 'web_link': 'https://opendev.org/openstack/horizon/commit/6b26777833201920d58deef8b0e394b5d679a01b', 'message': '[DNM] Pin XStatic-JQuery==2.2.4.1 to make it work with jquery-migrate\n\nThe jquery-migrate 3 requires newer jquery than we have.\n\nAlso added all the other fixes for integration tests to see if that\nresolves our problems.\n\nChange-Id: I0c9e76f81c696b36ba3d7c7a06eaf0bbc875625d\n'}]",0,887935,6b26777833201920d58deef8b0e394b5d679a01b,9,1,3,29313,,,0,"[DNM] Pin XStatic-JQuery==2.2.4.1 to make it work with jquery-migrate

The jquery-migrate 3 requires newer jquery than we have.

Also added all the other fixes for integration tests to see if that
resolves our problems.

Change-Id: I0c9e76f81c696b36ba3d7c7a06eaf0bbc875625d
",git fetch https://review.opendev.org/openstack/horizon refs/changes/35/887935/1 && git format-patch -1 --stdout FETCH_HEAD,"['requirements.txt', 'openstack_dashboard/test/integration_tests/config.py', 'openstack_dashboard/test/integration_tests/horizon.conf', 'openstack_dashboard/dashboards/project/static/dashboard/project/workflow/launch-instance/keypair/keypair.html']",4,ad9bef317918fddbfa7279b75f5425f6ae8bff8a,887548," <settings-service hz-if-settings=""[&quot;OPENSTACK_HYPERVISOR_FEATURES.can_set_password&quot;]"">"," <settings-service hz-if-settings=""[""OPENSTACK_HYPERVISOR_FEATURES.can_set_password""]"">",10,11
openstack%2Fcharm-masakari~874437,openstack/charm-masakari,stable/ussuri,I0821304b3f0e586e3a868e3c95294a688bae085a,Add section-oslo-rabbitmq to templates,MERGED,2023-02-20 16:00:24.000000000,2023-07-11 15:52:59.000000000,2023-07-11 15:52:59.000000000,"[{'_account_id': 11805}, {'_account_id': 20648}, {'_account_id': 20870}, {'_account_id': 22348}, {'_account_id': 31203}]","[{'number': 1, 'created': '2023-02-20 16:00:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-masakari/commit/550fdfc74cb02e351e180f2bce6c5e44743fc5d2', 'message': 'Add section-oslo-rabbitmq to templates\n\nEnsure the RabbitMQ oslo.messaging section is used in all templates;\nthis configures SSL options when deployed in TLS secured configurations\nwith RabbitMQ.\n\nChange-Id: I0821304b3f0e586e3a868e3c95294a688bae085a\nCloses-Bug: 2007567\n(cherry picked from commit f4a8f7c4dfc5a5ef0244b095b7ea83d1e78e99d0)\n'}, {'number': 2, 'created': '2023-02-20 16:56:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-masakari/commit/bba17ae38ad758c422da67f1c130607d1a23988f', 'message': 'Add section-oslo-rabbitmq to templates\n\nEnsure the RabbitMQ oslo.messaging section is used in all templates;\nthis configures SSL options when deployed in TLS secured configurations\nwith RabbitMQ.\n\nChange-Id: I0821304b3f0e586e3a868e3c95294a688bae085a\nCloses-Bug: 2007567\n(cherry picked from commit f4a8f7c4dfc5a5ef0244b095b7ea83d1e78e99d0)\n'}, {'number': 3, 'created': '2023-06-29 20:49:33.000000000', 'files': ['src/templates/stein/masakari.conf', 'src/templates/masakari.conf'], 'web_link': 'https://opendev.org/openstack/charm-masakari/commit/bb13387061843a184cd486aa97c862852710139c', 'message': 'Add section-oslo-rabbitmq to templates\n\nEnsure the RabbitMQ oslo.messaging section is used in all templates;\nthis configures SSL options when deployed in TLS secured configurations\nwith RabbitMQ.\n\nChange-Id: I0821304b3f0e586e3a868e3c95294a688bae085a\nCloses-Bug: 2007567\n(cherry picked from commit f4a8f7c4dfc5a5ef0244b095b7ea83d1e78e99d0)\n'}]",8,874437,bb13387061843a184cd486aa97c862852710139c,25,5,3,935,,,0,"Add section-oslo-rabbitmq to templates

Ensure the RabbitMQ oslo.messaging section is used in all templates;
this configures SSL options when deployed in TLS secured configurations
with RabbitMQ.

Change-Id: I0821304b3f0e586e3a868e3c95294a688bae085a
Closes-Bug: 2007567
(cherry picked from commit f4a8f7c4dfc5a5ef0244b095b7ea83d1e78e99d0)
",git fetch https://review.opendev.org/openstack/charm-masakari refs/changes/37/874437/1 && git format-patch -1 --stdout FETCH_HEAD,"['src/templates/stein/masakari.conf', 'src/templates/masakari.conf']",2,550fdfc74cb02e351e180f2bce6c5e44743fc5d2,stable/bug2007567-ussuri,"{% include ""parts/section-rabbitmq-oslo"" %} ",,4,0
openstack%2Fswift-bench~866826,openstack/swift-bench,master,Ibb2c3bb17522b6302697e2d2b01df3a6aa62800e,refactor bin/bench into swiftbench/cli for testing,MERGED,2022-12-07 06:59:49.000000000,2023-07-11 15:52:07.000000000,2023-07-11 15:52:07.000000000,"[{'_account_id': 15343}, {'_account_id': 22348}]","[{'number': 1, 'created': '2022-12-07 06:59:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift-bench/commit/1f6a3f8ee0101f727e3ed91cc4259581a7954a5a', 'message': 'refactor bin/bench into swiftbench/cli for testing\n\nThe test infrastructure for swiftbench is pretty bad. In order to start\ncleaning it up this patch starts with some initial scaffolding for\ntest_cli.py. Sd such it refactors the code out of bin/swiftbench and\nputs it into swiftbench/cli/__init__.py. Leaving the cli namespace free\nfor future expansions.\n\nA verybasic tests/test_cli.py has been added which initialises some test\nscaffolding and a first test_default has been added.\n\nThis is at least a start that we can extend.\n\nChange-Id: Ibb2c3bb17522b6302697e2d2b01df3a6aa62800e\n'}, {'number': 2, 'created': '2022-12-08 03:28:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift-bench/commit/4614f846090da2606fd9b539353bde8cab9ffe35', 'message': 'refactor bin/bench into swiftbench/cli for testing\n\nThe test infrastructure for swiftbench is pretty bad. In order to start\ncleaning it up this patch starts with some initial scaffolding for\ntest_cli.py. Sd such it refactors the code out of bin/swiftbench and\nputs it into swiftbench/cli/__init__.py. Leaving the cli namespace free\nfor future expansions.\n\nA verybasic tests/test_cli.py has been added which initialises some test\nscaffolding and a first test_default has been added.\n\nThis is at least a start that we can extend.\n\nChange-Id: Ibb2c3bb17522b6302697e2d2b01df3a6aa62800e\n'}, {'number': 3, 'created': '2023-02-17 21:30:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift-bench/commit/5065c4a559dcdbff0617e9d436402dce41eea330', 'message': 'refactor bin/bench into swiftbench/cli for testing\n\nThe test infrastructure for swiftbench is pretty bad. In order to start\ncleaning it up this patch starts with some initial scaffolding for\ntest_cli.py. Sd such it refactors the code out of bin/swiftbench and\nputs it into swiftbench/cli/__init__.py. Leaving the cli namespace free\nfor future expansions.\n\nA very basic tests/test_cli.py has been added which initialises some test\nscaffolding. Additionally, fix some bugs this uncovered:\n\n- The --delete-concurrency option now actually has an effect.\n- Stop mutating global state on every run.\n\nPartial-Bug: #1263290\nChange-Id: Ibb2c3bb17522b6302697e2d2b01df3a6aa62800e\n'}, {'number': 4, 'created': '2023-02-17 23:46:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift-bench/commit/1c0c75543153a89b31c91c89f08bc1b3a1ff47d4', 'message': 'refactor bin/bench into swiftbench/cli for testing\n\nThe test infrastructure for swiftbench is pretty bad. In order to start\ncleaning it up this patch starts with some initial scaffolding for\ntest_cli.py. Sd such it refactors the code out of bin/swiftbench and\nputs it into swiftbench/cli/__init__.py. Leaving the cli namespace free\nfor future expansions.\n\nA very basic tests/test_cli.py has been added which initialises some test\nscaffolding. Additionally, fix some bugs this uncovered:\n\n- The --delete-concurrency option now actually has an effect.\n- Stop mutating global state on every run.\n\nPartial-Bug: #1263290\nChange-Id: Ibb2c3bb17522b6302697e2d2b01df3a6aa62800e\n'}, {'number': 5, 'created': '2023-07-10 22:42:47.000000000', 'files': ['swiftbench/cli/__init__.py', 'bin/swift-bench', 'tests/test_cli.py'], 'web_link': 'https://opendev.org/openstack/swift-bench/commit/5f803ae8fde7d5511e8b364ae7fd86fac09e48d3', 'message': 'refactor bin/bench into swiftbench/cli for testing\n\nThe test infrastructure for swiftbench is pretty bad. In order to start\ncleaning it up this patch starts with some initial scaffolding for\ntest_cli.py. Sd such it refactors the code out of bin/swiftbench and\nputs it into swiftbench/cli/__init__.py. Leaving the cli namespace free\nfor future expansions.\n\nA very basic tests/test_cli.py has been added which initialises some test\nscaffolding. Additionally, fix some bugs this uncovered:\n\n- The --delete-concurrency option now actually has an effect.\n- Stop mutating global state on every run.\n\nPartial-Bug: #1263290\nChange-Id: Ibb2c3bb17522b6302697e2d2b01df3a6aa62800e\n'}]",12,866826,5f803ae8fde7d5511e8b364ae7fd86fac09e48d3,20,2,5,7233,,,0,"refactor bin/bench into swiftbench/cli for testing

The test infrastructure for swiftbench is pretty bad. In order to start
cleaning it up this patch starts with some initial scaffolding for
test_cli.py. Sd such it refactors the code out of bin/swiftbench and
puts it into swiftbench/cli/__init__.py. Leaving the cli namespace free
for future expansions.

A very basic tests/test_cli.py has been added which initialises some test
scaffolding. Additionally, fix some bugs this uncovered:

- The --delete-concurrency option now actually has an effect.
- Stop mutating global state on every run.

Partial-Bug: #1263290
Change-Id: Ibb2c3bb17522b6302697e2d2b01df3a6aa62800e
",git fetch https://review.opendev.org/openstack/swift-bench refs/changes/26/866826/1 && git format-patch -1 --stdout FETCH_HEAD,"['swiftbench/cli/__init__.py', 'bin/swift-bench', 'tests/test_cli.py']",3,1f6a3f8ee0101f727e3ed91cc4259581a7954a5a,cli_test_base,"# Copyright (c) 2022 NVIDIA # # Licensed under the Apache License, Version 2.0 (the ""License""); # you may not use this file except in compliance with the License. # You may obtain a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or # implied. # See the License for the specific language governing permissions and # limitations under the License. import unittest import mock from swiftbench import cli class TestCli(unittest.TestCase): def setUp(self): self.controller_options = None self.container_options = None self.delete_options = None def fake_create_containers(self, logger, options): self.container_options = options def fake_delete_containers(self, logger, options): self.delete_options = options def run_main(self, args): mock_controller = mock.Mock() with mock.patch('swiftbench.cli.create_containers', self.fake_create_containers), \ mock.patch('swiftbench.cli.delete_containers', self.fake_delete_containers), \ mock.patch('swiftbench.cli.BenchController', mock_controller), \ mock.patch('swiftbench.cli.DistributedBenchController', mock_controller): cli.main(args) return (mock_controller.call_args[0][-1], self.container_options, self.delete_options) def test_defaults(self): controller_opts, container_opts, del_opts = self.run_main([]) self.assertFalse(controller_opts.saio) self.assertEqual(controller_opts.auth, '') self.assertEqual(controller_opts.user, '') self.assertEqual(controller_opts.key, '') self.assertEqual(controller_opts.url, '') self.assertEqual(controller_opts.concurrency, '') self.assertEqual(controller_opts.get_concurrency, '10') self.assertEqual(controller_opts.put_concurrency, '10') self.assertEqual(controller_opts.lower_object_size, '10') self.assertEqual(controller_opts.upper_object_size, '10') self.assertEqual(controller_opts.num_objects, '1000') self.assertEqual(controller_opts.num_gets, '10000') self.assertEqual(controller_opts.num_containers, '20') self.assertTrue(controller_opts.delete) self.assertEqual(controller_opts.auth_version, '1.0') self.assertEqual(controller_opts.delay, '0') self.assertIsNone(controller_opts.policy_name) self.assertTrue(controller_opts.use_proxy) self.assertEqual(controller_opts.del_concurrency, '10') self.assertEqual(controller_opts.object_sources, '') self.assertEqual(controller_opts.account, '') self.assertEqual(controller_opts.container_name, mock.ANY) self.assertEqual(controller_opts.devices, 'sdb1') self.assertEqual(controller_opts.log_level, 'INFO') self.assertEqual(controller_opts.timeout, '10') self.assertTrue(controller_opts.containers) ",,270,174
openstack%2Freleases~881620,openstack/releases,master,Ia8010c1e399166db1485675a4bc1c1ffac569c24,[OpenStackAnsible] Transition Rocky to End of Life,MERGED,2023-04-26 18:17:16.000000000,2023-07-11 15:48:41.000000000,2023-07-11 15:48:41.000000000,"[{'_account_id': 17685}, {'_account_id': 22348}, {'_account_id': 28522}, {'_account_id': 28619}]","[{'number': 1, 'created': '2023-04-26 18:17:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/releases/commit/fb24971bf507f42998d8fe8e62201b61f325be81', 'message': ""[OpenStackAnsible] Transition Rocky to End of Life\n\nAs discussed in the mail thread [1][2], this patch transition the Rocky\nbranch to End of Life. The last patch of the branch will be tagged with\nrocky-eol tag. stable/rocky branch cannot be used anymore and will be\ndeleted if this patch merges.\n\nThis is needed as stable/rocky is not actively maintained in recent\nperiod, thus gates are mostly broken due to job failures. Besides,\nby removing these branches, infra resources will be freed up, too.\n\nPlease try to identify any zuul job, that is defined outside of the\nrepositories in this patch (for example in openstack-zuul-jobs, etc.)\nand won't be used anymore if stable/rocky is deleted. Propose a job\nremoval patch for them.\n\nPlease +1 if the team is ready for us to proceed with this transition,\nor -1 if there are still some activity on the branch and the team wants\nto continue to maintain it.\n\n[1] https://lists.openstack.org/pipermail/openstack-discuss/2023-January/031922.html\n[2] https://lists.openstack.org/pipermail/openstack-discuss/2023-April/033386.html\n\nChange-Id: Ia8010c1e399166db1485675a4bc1c1ffac569c24\n""}, {'number': 2, 'created': '2023-07-11 11:41:34.000000000', 'files': ['deliverables/rocky/openstack-ansible.yaml'], 'web_link': 'https://opendev.org/openstack/releases/commit/07c7880f197a4b69422aa5d7c824e99d3a9dc277', 'message': ""[OpenStackAnsible] Transition Rocky to End of Life\n\nAs discussed in the mail thread [1][2], this patch transition the Rocky\nbranch to End of Life. The last patch of the branch will be tagged with\nrocky-eol tag. stable/rocky branch cannot be used anymore and will be\ndeleted if this patch merges.\n\nThis is needed as stable/rocky is not actively maintained in recent\nperiod, thus gates are mostly broken due to job failures. Besides,\nby removing these branches, infra resources will be freed up, too.\n\nPlease try to identify any zuul job, that is defined outside of the\nrepositories in this patch (for example in openstack-zuul-jobs, etc.)\nand won't be used anymore if stable/rocky is deleted. Propose a job\nremoval patch for them.\n\nPlease +1 if the team is ready for us to proceed with this transition,\nor -1 if there are still some activity on the branch and the team wants\nto continue to maintain it.\n\n[1] https://lists.openstack.org/pipermail/openstack-discuss/2023-January/031922.html\n[2] https://lists.openstack.org/pipermail/openstack-discuss/2023-April/033386.html\n\nChange-Id: Ia8010c1e399166db1485675a4bc1c1ffac569c24\n""}]",4,881620,07c7880f197a4b69422aa5d7c824e99d3a9dc277,13,4,2,17685,,,0,"[OpenStackAnsible] Transition Rocky to End of Life

As discussed in the mail thread [1][2], this patch transition the Rocky
branch to End of Life. The last patch of the branch will be tagged with
rocky-eol tag. stable/rocky branch cannot be used anymore and will be
deleted if this patch merges.

This is needed as stable/rocky is not actively maintained in recent
period, thus gates are mostly broken due to job failures. Besides,
by removing these branches, infra resources will be freed up, too.

Please try to identify any zuul job, that is defined outside of the
repositories in this patch (for example in openstack-zuul-jobs, etc.)
and won't be used anymore if stable/rocky is deleted. Propose a job
removal patch for them.

Please +1 if the team is ready for us to proceed with this transition,
or -1 if there are still some activity on the branch and the team wants
to continue to maintain it.

[1] https://lists.openstack.org/pipermail/openstack-discuss/2023-January/031922.html
[2] https://lists.openstack.org/pipermail/openstack-discuss/2023-April/033386.html

Change-Id: Ia8010c1e399166db1485675a4bc1c1ffac569c24
",git fetch https://review.opendev.org/openstack/releases refs/changes/20/881620/1 && git format-patch -1 --stdout FETCH_HEAD,['deliverables/rocky/openstack-ansible.yaml'],1,fb24971bf507f42998d8fe8e62201b61f325be81,rocky-eol, - version: rocky-eol projects: - repo: openstack/openstack-ansible hash: 24938f3db5175c2c0ed4b3886b54dcd305af37c8,,4,0
openstack%2Fovn-octavia-provider~885433,openstack/ovn-octavia-provider,master,I07c8f3492e62576f66008e8ea1ef9846bed8c6fa,Add support for SOURCE_IP session persistence,MERGED,2023-06-07 09:30:03.000000000,2023-07-11 15:27:42.000000000,2023-07-11 15:26:36.000000000,"[{'_account_id': 6773}, {'_account_id': 11600}, {'_account_id': 11628}, {'_account_id': 22348}, {'_account_id': 23567}, {'_account_id': 34451}]","[{'number': 1, 'created': '2023-06-07 09:30:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ovn-octavia-provider/commit/f8d73b97e06389aa51d49311baf646ad60f2f439', 'message': '[WIP] Add support for SOURCE_IP session persistence\n\nThis patch adds support to configure ovn loadbalancer\naffinity_timeout option based on the pool session persistence\ntimeout.\n\nChange-Id: I07c8f3492e62576f66008e8ea1ef9846bed8c6fa\n'}, {'number': 2, 'created': '2023-06-07 10:13:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ovn-octavia-provider/commit/f15c5e4495fe81c6f98245cb5454b3ea8d7679a7', 'message': '[WIP] Add support for SOURCE_IP session persistence\n\nThis patch adds support to configure ovn loadbalancer\naffinity_timeout option based on the pool session persistence\ntimeout.\n\nChange-Id: I07c8f3492e62576f66008e8ea1ef9846bed8c6fa\n'}, {'number': 3, 'created': '2023-06-07 10:55:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ovn-octavia-provider/commit/441467a442b777c8a1474fcd47a0bf81fc8c75f5', 'message': 'Add support for SOURCE_IP session persistence\n\nThis patch adds support to configure ovn loadbalancer\naffinity_timeout option based on the pool session persistence\ntimeout.\n\nChange-Id: I07c8f3492e62576f66008e8ea1ef9846bed8c6fa\n'}, {'number': 4, 'created': '2023-06-26 12:22:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ovn-octavia-provider/commit/9124fa6bc4511b3a56f387ee1774eb29a33d2233', 'message': 'Add support for SOURCE_IP session persistence\n\nThis patch adds support to configure ovn loadbalancer\naffinity_timeout option based on the pool session persistence\ntimeout.\n\nChange-Id: I07c8f3492e62576f66008e8ea1ef9846bed8c6fa\n'}, {'number': 5, 'created': '2023-06-28 13:01:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ovn-octavia-provider/commit/1e601ec2ee47c2b611f8ca453f4d0d73a0792f33', 'message': 'Add support for SOURCE_IP session persistence\n\nThis patch adds support to configure ovn loadbalancer\naffinity_timeout option based on the pool session persistence\ntimeout.\n\nChange-Id: I07c8f3492e62576f66008e8ea1ef9846bed8c6fa\n'}, {'number': 6, 'created': '2023-06-29 06:27:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ovn-octavia-provider/commit/4f258cfa36ea2d93ef89e8e832d5204226b40f8d', 'message': 'Add support for SOURCE_IP session persistence\n\nThis patch adds support to configure ovn loadbalancer\naffinity_timeout option based on the pool session persistence\ntimeout.\n\nChange-Id: I07c8f3492e62576f66008e8ea1ef9846bed8c6fa\n'}, {'number': 7, 'created': '2023-07-11 09:35:05.000000000', 'files': ['ovn_octavia_provider/common/constants.py', 'ovn_octavia_provider/tests/unit/test_driver.py', 'ovn_octavia_provider/helper.py', 'ovn_octavia_provider/driver.py', 'releasenotes/notes/session-persistence-b409428a8907f542.yaml'], 'web_link': 'https://opendev.org/openstack/ovn-octavia-provider/commit/382ddb0329f93873e25a55be65bf43000332a21a', 'message': 'Add support for SOURCE_IP session persistence\n\nThis patch adds support to configure ovn loadbalancer\naffinity_timeout option based on the pool session persistence\ntimeout.\n\nChange-Id: I07c8f3492e62576f66008e8ea1ef9846bed8c6fa\n'}]",11,885433,382ddb0329f93873e25a55be65bf43000332a21a,26,6,7,23567,,,0,"Add support for SOURCE_IP session persistence

This patch adds support to configure ovn loadbalancer
affinity_timeout option based on the pool session persistence
timeout.

Change-Id: I07c8f3492e62576f66008e8ea1ef9846bed8c6fa
",git fetch https://review.opendev.org/openstack/ovn-octavia-provider refs/changes/33/885433/1 && git format-patch -1 --stdout FETCH_HEAD,"['ovn_octavia_provider/common/constants.py', 'ovn_octavia_provider/helper.py', 'ovn_octavia_provider/driver.py']",3,f8d73b97e06389aa51d49311baf646ad60f2f439,," def _check_for_supported_session_perssitence(self, session): if session.type not in ovn_const.OVN_SESSION_PERSISTENCE: msg = _('OVN provider does not support %s session persistence' ) % session.type raise driver_exceptions.UnsupportedOptionError( user_fault_string=msg, operator_fault_string=msg) if not isinstance( pool.session_persistence, o_datamodels.UnsetType): self._check_for_supported_session_perssitence( pool.session_persistence) request['info']['session_persistence'] = pool.session_persistence",,34,2
openstack%2Fironic~884221,openstack/ironic,stable/yoga,If7cfc319de8cefdb42d4a613e5126c0f0edb0c9e,[ci] [stable-only] Cinder fixed; make BFV job vote,MERGED,2023-05-24 19:36:34.000000000,2023-07-11 15:06:13.000000000,2023-07-11 15:03:54.000000000,"[{'_account_id': 10239}, {'_account_id': 10342}, {'_account_id': 22348}]","[{'number': 1, 'created': '2023-05-24 19:36:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/f00754fee4fd6791796f6332b184426cee4c1c14', 'message': '[ci] [stable-only] Cinder fixed; make BFV job vote\n\nWe need to ensure CI for BFV is enabled if we expect BFV to work.\n\nChange-Id: If7cfc319de8cefdb42d4a613e5126c0f0edb0c9e\n'}, {'number': 2, 'created': '2023-06-05 00:05:06.000000000', 'files': ['zuul.d/project.yaml'], 'web_link': 'https://opendev.org/openstack/ironic/commit/4ec0ee67701c838de5dc3fd96fab00894d2d257f', 'message': '[ci] [stable-only] Cinder fixed; make BFV job vote\n\nWe need to ensure CI for BFV is enabled if we expect BFV to work.\n\nChange-Id: If7cfc319de8cefdb42d4a613e5126c0f0edb0c9e\n'}]",1,884221,4ec0ee67701c838de5dc3fd96fab00894d2d257f,13,3,2,10342,,,0,"[ci] [stable-only] Cinder fixed; make BFV job vote

We need to ensure CI for BFV is enabled if we expect BFV to work.

Change-Id: If7cfc319de8cefdb42d4a613e5126c0f0edb0c9e
",git fetch https://review.opendev.org/openstack/ironic refs/changes/21/884221/1 && git format-patch -1 --stdout FETCH_HEAD,['zuul.d/project.yaml'],1,f00754fee4fd6791796f6332b184426cee4c1c14,, - ironic-tempest-bfv - ironic-tempest-bfv, # NOTE(JayF): This job is failing and is being fixed in master. It # should be re-enabled in stable when it's re-enabled on master. # commented out 2023-05-19 - ironic-tempest-bfv: voting: false # NOTE(JayF): This job is failing and is being fixed in master. It # should be re-enabled in stable when it's re-enabled on master. # commented out 2023-05-19 #- ironic-tempest-bfv,2,9
openstack%2Fironic~886985,openstack/ironic,master,Ida495d59bde977a20590c34e282c884a65ceab43,CI: Change migrations timeout to be >60 seoncds,MERGED,2023-06-26 14:08:38.000000000,2023-07-11 15:06:05.000000000,2023-07-11 15:03:57.000000000,"[{'_account_id': 10342}, {'_account_id': 11655}, {'_account_id': 15519}, {'_account_id': 22348}]","[{'number': 1, 'created': '2023-06-26 14:08:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/d9a0000205d3315a65b59a34398b179eb9870af5', 'message': 'CI: Change migrations timeout to be >60 seoncds\n\nIn local testing, I found the migrations tended to take an\naverage of 70 seconds. Granted, my test machine is old, and slow\nbut the performance is very similar to a busy cloud provider.\n\nAs such, increase the timeout to a larger value so we can enable\nthe double migration test again.\n\nChange-Id: Ida495d59bde977a20590c34e282c884a65ceab43\n'}, {'number': 2, 'created': '2023-06-26 15:57:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/ec891bd8224e93ad83ccafe079326015f0e03fb4', 'message': 'CI: Change migrations timeout to be >60 seoncds\n\nIn local testing, I found the migrations tended to take an\naverage of 70 seconds. Granted, my test machine is old, and slow\nbut the performance is very similar to a busy cloud provider.\n\nAs such, increase the timeout to a larger value so we can enable\nthe double migration test again.\n\nChange-Id: Ida495d59bde977a20590c34e282c884a65ceab43\n'}, {'number': 3, 'created': '2023-06-26 15:58:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/91126f9a4a8b700b15e79ade78662303f4fcb239', 'message': 'CI: Change migrations timeout to be >60 seoncds\n\nIn local testing, I found the migrations tended to take an\naverage of 70 seconds. Granted, my test machine is old, and slow\nbut the performance is very similar to a busy cloud provider.\n\nAs such, increase the timeout to a larger value so we can enable\nthe double migration test again.\n\nChange-Id: Ida495d59bde977a20590c34e282c884a65ceab43\n'}, {'number': 4, 'created': '2023-06-26 15:58:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/fc76d6dbd67d06198c338686a6d8001aeff37a1a', 'message': 'CI: Change migrations timeout to be >60 seconds\n\nIn local testing, I found the migrations tended to take an\naverage of 70 seconds. Granted, my test machine is old, and slow\nbut the performance is very similar to a busy cloud provider.\n\nAs such, increase the timeout to a larger value so we can enable\nthe double migration test again.\n\nChange-Id: Ida495d59bde977a20590c34e282c884a65ceab43\n'}, {'number': 5, 'created': '2023-06-26 16:02:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/5ed9aa3b8ebcbcecdb4d086e6e38ecdbcd9e0d4e', 'message': ""CI: Change migrations timeout to be >60 seoncds\n\nIn local testing, I found the migrations tended to take an\naverage of 70 seconds. Granted, my test machine is old, and slow\nbut the performance is very similar to a busy cloud provider.\n\nAs such, increase the timeout to a larger value so we can enable\nthe double migration test again.\n\nAlso use BASE_TEST_TIMEOUT as time limit for unit tests, failing\nhard if that's passed.\n\nChange-Id: Ida495d59bde977a20590c34e282c884a65ceab43\n""}, {'number': 6, 'created': '2023-06-28 07:31:47.000000000', 'files': ['ironic/tests/base.py', 'tox.ini'], 'web_link': 'https://opendev.org/openstack/ironic/commit/bc7771bf35e879bb4f16ea18a4542b0e4418bc10', 'message': ""CI: Change migrations timeout to be >60 seoncds\n\nIn local testing, I found the migrations tended to take an\naverage of 70 seconds. Granted, my test machine is old, and slow\nbut the performance is very similar to a busy cloud provider.\n\nAs such, increase the timeout to a larger value so we can enable\nthe double migration test again.\n\nAlso use BASE_TEST_TIMEOUT as time limit for unit tests, failing\nhard if that's passed.\n\nChange-Id: Ida495d59bde977a20590c34e282c884a65ceab43\n""}]",16,886985,bc7771bf35e879bb4f16ea18a4542b0e4418bc10,71,4,6,11655,,,0,"CI: Change migrations timeout to be >60 seoncds

In local testing, I found the migrations tended to take an
average of 70 seconds. Granted, my test machine is old, and slow
but the performance is very similar to a busy cloud provider.

As such, increase the timeout to a larger value so we can enable
the double migration test again.

Also use BASE_TEST_TIMEOUT as time limit for unit tests, failing
hard if that's passed.

Change-Id: Ida495d59bde977a20590c34e282c884a65ceab43
",git fetch https://review.opendev.org/openstack/ironic refs/changes/85/886985/1 && git format-patch -1 --stdout FETCH_HEAD,['tox.ini'],1,d9a0000205d3315a65b59a34398b179eb9870af5,, MIGRATIONS_TIMEOUT={env:MIGRATIONS_TIMEOUT:180}, MIGRATIONS_TIMEOUT={env:MIGRATIONS_TIMEOUT:60},1,1
openstack%2Fdevstack-plugin-ceph~887955,openstack/devstack-plugin-ceph,stable/2023.1,I899822fec863f43cd6c58b25cf4688c6a3ac1e9b,"[Partial Backport] Revert ""Temporary pin the ceph jobs nodeset to Focal""",MERGED,2023-07-07 13:30:19.000000000,2023-07-11 14:03:43.000000000,2023-07-11 14:01:51.000000000,"[{'_account_id': 4393}, {'_account_id': 8556}, {'_account_id': 13861}, {'_account_id': 17685}, {'_account_id': 22348}, {'_account_id': 22873}]","[{'number': 1, 'created': '2023-07-07 13:30:19.000000000', 'files': ['.zuul.yaml'], 'web_link': 'https://opendev.org/openstack/devstack-plugin-ceph/commit/2d61c38586bfd25cc6cf858c52c739f44f96c191', 'message': '[Partial Backport] Revert ""Temporary pin the ceph jobs nodeset to Focal""\n\nNote(sean-k-mooney):\nThis is a partail backport of I899822fec863f43cd6c58b25cf4688c6a3ac1e9b\ncontianing only the change to enable validations in the base job\nand the swap/concurrency/mysql changes to account for the high memory\npressure in the job which leads to instablity. All changes outside\nof the .zuul.yaml change are dropped as is the depend on for the\ncinder-tempest-plugin. cinder-tempest-plugin is branchless\nso we do not need to backport it and it is already merged on master\nso the depency is fulfilled.\n\nThis reverts commit 863a01b03286e6595d68ac7f2560c857bcf944c5.\n\nPartial revert only for the pin to focal, leaves the broken other jobs\ncommented out.\n\nUpdate paste-deploy workaround to be used always.\nAdd qemu-block-extra and podman deps to the debs list.\nRunning on the newer ceph and distro causes some quite different\nperformance characteristics that cause tests that used to pass to fail\nmore often. This includes some performance optimizations to help\nreduce the memory footprint, as well as depends on changes to\ntempest tests to improve the reliability of those tests by enabling\nvalidation via SSH.\n\nThis also moves the cephadm job to be the voting/gating job as that\nseems to be the clear consensus about ""the future"" of how we deploy\nceph for testing.\n\nCo-Authored-By: Dan Smith <dms@danplanet.com>\nChange-Id: I899822fec863f43cd6c58b25cf4688c6a3ac1e9b\n(cherry picked from commit 41b6a8c227190a9b52d29a078425321f96240d92)\n'}]",4,887955,2d61c38586bfd25cc6cf858c52c739f44f96c191,11,6,1,11604,,,0,"[Partial Backport] Revert ""Temporary pin the ceph jobs nodeset to Focal""

Note(sean-k-mooney):
This is a partail backport of I899822fec863f43cd6c58b25cf4688c6a3ac1e9b
contianing only the change to enable validations in the base job
and the swap/concurrency/mysql changes to account for the high memory
pressure in the job which leads to instablity. All changes outside
of the .zuul.yaml change are dropped as is the depend on for the
cinder-tempest-plugin. cinder-tempest-plugin is branchless
so we do not need to backport it and it is already merged on master
so the depency is fulfilled.

This reverts commit 863a01b03286e6595d68ac7f2560c857bcf944c5.

Partial revert only for the pin to focal, leaves the broken other jobs
commented out.

Update paste-deploy workaround to be used always.
Add qemu-block-extra and podman deps to the debs list.
Running on the newer ceph and distro causes some quite different
performance characteristics that cause tests that used to pass to fail
more often. This includes some performance optimizations to help
reduce the memory footprint, as well as depends on changes to
tempest tests to improve the reliability of those tests by enabling
validation via SSH.

This also moves the cephadm job to be the voting/gating job as that
seems to be the clear consensus about ""the future"" of how we deploy
ceph for testing.

Co-Authored-By: Dan Smith <dms@danplanet.com>
Change-Id: I899822fec863f43cd6c58b25cf4688c6a3ac1e9b
(cherry picked from commit 41b6a8c227190a9b52d29a078425321f96240d92)
",git fetch https://review.opendev.org/openstack/devstack-plugin-ceph refs/changes/55/887955/1 && git format-patch -1 --stdout FETCH_HEAD,['.zuul.yaml'],1,2d61c38586bfd25cc6cf858c52c739f44f96c191,bug/2025813, configure_swap_size: 8192 tempest_concurrency: 3 TEMPEST_RUN_VALIDATION: True MYSQL_REDUCE_MEMORY: True, TEMPEST_RUN_VALIDATION: false,4,1
openstack%2Fbifrost~874520,openstack/bifrost,master,Ic7006ca0c6a74f0d34c78248b68e8000ecc4c332,remove iniparse system packages requirement,MERGED,2023-02-20 23:05:23.000000000,2023-07-11 13:22:22.000000000,2023-07-11 13:21:18.000000000,"[{'_account_id': 10239}, {'_account_id': 10342}, {'_account_id': 22348}, {'_account_id': 25600}, {'_account_id': 32238}]","[{'number': 1, 'created': '2023-02-20 23:05:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/bifrost/commit/ed59e338101bca1c866148793d1c23ebce739f79', 'message': ""remove iniparse system packages requirement\n\nI don't think this package sees any use. Esp. since it's oddly only\na requirement for RedHat family.\n\nChange-Id: Ic7006ca0c6a74f0d34c78248b68e8000ecc4c332\n""}, {'number': 2, 'created': '2023-04-24 17:01:07.000000000', 'files': ['playbooks/roles/bifrost-keystone-install/defaults/required_defaults_RedHat_family.yml'], 'web_link': 'https://opendev.org/openstack/bifrost/commit/9a19219134f455df2bb76970e4dcc3276ec42f64', 'message': ""remove iniparse system packages requirement\n\nI don't think this package sees any use. Esp. since it's oddly only\na requirement for RedHat family.\n\nChange-Id: Ic7006ca0c6a74f0d34c78248b68e8000ecc4c332\n""}]",4,874520,9a19219134f455df2bb76970e4dcc3276ec42f64,17,5,2,25600,,,0,"remove iniparse system packages requirement

I don't think this package sees any use. Esp. since it's oddly only
a requirement for RedHat family.

Change-Id: Ic7006ca0c6a74f0d34c78248b68e8000ecc4c332
",git fetch https://review.opendev.org/openstack/bifrost refs/changes/20/874520/1 && git format-patch -1 --stdout FETCH_HEAD,['playbooks/roles/bifrost-keystone-install/defaults/required_defaults_RedHat_family.yml'],1,ed59e338101bca1c866148793d1c23ebce739f79,first_found_keystone,, - python3-iniparse,0,1
openstack%2Fneutron~888040,openstack/neutron,master,I8d327aeb4041f005633be12135e296924ceab666,Add 'allowed-address-pairs-atomic' to the extensions disabled by FW,ABANDONED,2023-07-10 14:05:00.000000000,2023-07-11 13:18:24.000000000,,"[{'_account_id': 22348}, {'_account_id': 28056}]","[{'number': 1, 'created': '2023-07-10 14:05:00.000000000', 'files': ['neutron/agent/securitygroups_rpc.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/63b4d299ae83c8286ec641c5a3895ae2c4b4be28', 'message': ""Add 'allowed-address-pairs-atomic' to the extensions disabled by FW\n\nAdded the extension 'allowed-address-pairs-atomic' to the list of\nextensions that should be disabled with the firewall is not configured.\n\nRelated-Bug: #2012332\nChange-Id: I8d327aeb4041f005633be12135e296924ceab666\n""}]",0,888040,63b4d299ae83c8286ec641c5a3895ae2c4b4be28,5,2,1,16688,,,0,"Add 'allowed-address-pairs-atomic' to the extensions disabled by FW

Added the extension 'allowed-address-pairs-atomic' to the list of
extensions that should be disabled with the firewall is not configured.

Related-Bug: #2012332
Change-Id: I8d327aeb4041f005633be12135e296924ceab666
",git fetch https://review.opendev.org/openstack/neutron refs/changes/40/888040/1 && git format-patch -1 --stdout FETCH_HEAD,['neutron/agent/securitygroups_rpc.py'],1,63b4d299ae83c8286ec641c5a3895ae2c4b4be28,bug/2012332,"from neutron_lib.api.definitions import allowedaddresspairs as aap_apidef from neutron_lib.api.definitions import allowedaddresspairs_atomic as \ aap_a_apidef _disable_extension(aap_apidef.ALIAS, aliases) _disable_extension(aap_a_apidef.ALIAS, aliases)"," _disable_extension('allowed-address-pairs', aliases)",5,1
openstack%2Fironic~886995,openstack/ironic,master,I91322bcb77e381605d213a8e17d419c852773bb8,"DNM: Revert ""Remove autocommit, again.""",ABANDONED,2023-06-26 17:12:07.000000000,2023-07-11 13:05:20.000000000,,[{'_account_id': 22348}],"[{'number': 1, 'created': '2023-06-26 17:12:07.000000000', 'files': ['ironic/db/sqlalchemy/__init__.py'], 'web_link': 'https://opendev.org/openstack/ironic/commit/a7871b43736f7867b919441ad6764685d6292336', 'message': 'DNM: Revert ""Remove autocommit, again.""\n\nSeeing if this prevents unit test failures from reproducing.\n\nThis reverts commit c03a5b44ef76018a384e7f2c3f4f247e1dc49e0a.\n\nChange-Id: I91322bcb77e381605d213a8e17d419c852773bb8\n'}]",0,886995,a7871b43736f7867b919441ad6764685d6292336,5,1,1,10342,,,0,"DNM: Revert ""Remove autocommit, again.""

Seeing if this prevents unit test failures from reproducing.

This reverts commit c03a5b44ef76018a384e7f2c3f4f247e1dc49e0a.

Change-Id: I91322bcb77e381605d213a8e17d419c852773bb8
",git fetch https://review.opendev.org/openstack/ironic refs/changes/95/886995/1 && git format-patch -1 --stdout FETCH_HEAD,['ironic/db/sqlalchemy/__init__.py'],1,a7871b43736f7867b919441ad6764685d6292336,,"# FIXME(stephenfin): we need to remove reliance on autocommit semantics ASAP # since it's not compatible with SQLAlchemy 2.0enginefacade.configure(sqlite_fk=True, __autocommit=True)",enginefacade.configure(sqlite_fk=True),3,1
openstack%2Fnetworking-generic-switch~870896,openstack/networking-generic-switch,stable/zed,I6e6b7be42448bdf5ea94ba416440d4b59680b55d,Add ArubaOS-CX switch support,ABANDONED,2023-01-18 09:28:11.000000000,2023-07-11 12:50:59.000000000,,"[{'_account_id': 10342}, {'_account_id': 15519}, {'_account_id': 22348}]","[{'number': 1, 'created': '2023-01-18 09:28:11.000000000', 'files': ['networking_generic_switch/tests/unit/netmiko/test_aruba.py', 'doc/source/supported-devices.rst', 'doc/source/configuration.rst', 'networking_generic_switch/devices/netmiko_devices/aruba.py', 'releasenotes/notes/add-aruba-support-463a90b0b150b9af.yaml', 'setup.cfg'], 'web_link': 'https://opendev.org/openstack/networking-generic-switch/commit/041b442317cdb02f4cfcfc075c7493c473a2ed21', 'message': 'Add ArubaOS-CX switch support\n\nChange-Id: I6e6b7be42448bdf5ea94ba416440d4b59680b55d\n(cherry picked from commit e0417135c23c2fecb7728dec44751f5ca15d18f8)\n'}]",4,870896,041b442317cdb02f4cfcfc075c7493c473a2ed21,7,3,1,31746,,,0,"Add ArubaOS-CX switch support

Change-Id: I6e6b7be42448bdf5ea94ba416440d4b59680b55d
(cherry picked from commit e0417135c23c2fecb7728dec44751f5ca15d18f8)
",git fetch https://review.opendev.org/openstack/networking-generic-switch refs/changes/96/870896/1 && git format-patch -1 --stdout FETCH_HEAD,"['networking_generic_switch/tests/unit/netmiko/test_aruba.py', 'doc/source/supported-devices.rst', 'doc/source/configuration.rst', 'networking_generic_switch/devices/netmiko_devices/aruba.py', 'releasenotes/notes/add-aruba-support-463a90b0b150b9af.yaml', 'setup.cfg']",6,041b442317cdb02f4cfcfc075c7493c473a2ed21,, netmiko_aruba_os = networking_generic_switch.devices.netmiko_devices.aruba:ArubaOSCX,,212,0
openstack%2Fcharm-openstack-dashboard~887672,openstack/charm-openstack-dashboard,stable/ussuri,I6bbf7e5f81a772ffc6ea859c9ab7c05f2eb9fdc5,Make LocalSettingsContext more robust to priority,MERGED,2023-07-05 10:40:41.000000000,2023-07-11 12:40:20.000000000,2023-07-11 12:40:20.000000000,"[{'_account_id': 11805}, {'_account_id': 12549}, {'_account_id': 20648}, {'_account_id': 22348}]","[{'number': 1, 'created': '2023-07-05 10:40:41.000000000', 'files': ['hooks/horizon_contexts.py', 'unit_tests/test_horizon_contexts.py'], 'web_link': 'https://opendev.org/openstack/charm-openstack-dashboard/commit/d0a16797e7fd78e8f2c9a77280a5a7ec1acf7538', 'message': ""Make LocalSettingsContext more robust to priority\n\nThe relation data for for the LocalSettings context could cause the\npriority sorting to break if the priority key wasn't cmpable (e.g. using\n<, > or ==).  This patch fixes the associated bug, by making the sorting\nextra robust and ensuring that un-cmp-able values are 'greater' (e.g.\nfurther down the list) that cmp-able values, and equal to each other.\nE.g. a partially ordered set.\n\nChange-Id: I6bbf7e5f81a772ffc6ea859c9ab7c05f2eb9fdc5\nCloses-bug: #2023404\n(cherry picked from commit e8d0ca39a1e02abb075e283e4438464b90223b91)\n""}]",0,887672,d0a16797e7fd78e8f2c9a77280a5a7ec1acf7538,10,4,1,20870,,,0,"Make LocalSettingsContext more robust to priority

The relation data for for the LocalSettings context could cause the
priority sorting to break if the priority key wasn't cmpable (e.g. using
<, > or ==).  This patch fixes the associated bug, by making the sorting
extra robust and ensuring that un-cmp-able values are 'greater' (e.g.
further down the list) that cmp-able values, and equal to each other.
E.g. a partially ordered set.

Change-Id: I6bbf7e5f81a772ffc6ea859c9ab7c05f2eb9fdc5
Closes-bug: #2023404
(cherry picked from commit e8d0ca39a1e02abb075e283e4438464b90223b91)
",git fetch https://review.opendev.org/openstack/charm-openstack-dashboard refs/changes/72/887672/1 && git format-patch -1 --stdout FETCH_HEAD,"['hooks/horizon_contexts.py', 'unit_tests/test_horizon_contexts.py']",2,d0a16797e7fd78e8f2c9a77280a5a7ec1acf7538,bug/2023404," def test_LocalSettingsContext_unusual_priority(self): # First, left priority missing. self.related_units.side_effect = [['horizon-plugin/0'], ['horizon-plugin-too/0']] self.relation_get.side_effect = [{'local-settings': 'FOO = True'}, {'priority': 60, 'local-settings': 'BAR = False'}] self.assertEqual(horizon_contexts.LocalSettingsContext()(), {'settings': []}) # First, right priority missing. self.related_units.side_effect = [['horizon-plugin/0'], ['horizon-plugin-too/0']] self.relation_get.side_effect = [{'priority': 99, 'local-settings': 'FOO = True'}, {'local-settings': 'BAR = False'}] self.assertEqual(horizon_contexts.LocalSettingsContext()(), {'settings': []}) # Left priority is None. self.relation_ids.return_value = ['plugin:0', 'plugin-too:0'] self.related_units.side_effect = [['horizon-plugin/0'], ['horizon-plugin-too/0']] self.relation_get.side_effect = [{'priority': None, 'local-settings': 'FOO = True'}, {'priority': 60, 'local-settings': 'BAR = False'}] self.assertEqual(horizon_contexts.LocalSettingsContext()(), {'settings': ['# horizon-plugin-too/0\n' 'BAR = False', '# horizon-plugin/0\n' 'FOO = True']}) # Right priority is None. self.relation_ids.return_value = ['plugin:0', 'plugin-too:0'] self.related_units.side_effect = [['horizon-plugin/0'], ['horizon-plugin-too/0']] self.relation_get.side_effect = [{'priority': 99, 'local-settings': 'FOO = True'}, {'priority': None, 'local-settings': 'BAR = False'}] self.assertEqual(horizon_contexts.LocalSettingsContext()(), {'settings': ['# horizon-plugin/0\n' 'FOO = True', '# horizon-plugin-too/0\n' 'BAR = False']}) # Left priority is stringy number. self.relation_ids.return_value = ['plugin:0', 'plugin-too:0'] self.related_units.side_effect = [['horizon-plugin/0'], ['horizon-plugin-too/0']] self.relation_get.side_effect = [{'priority': ""99"", 'local-settings': 'FOO = True'}, {'priority': 60, 'local-settings': 'BAR = False'}] self.assertEqual(horizon_contexts.LocalSettingsContext()(), {'settings': ['# horizon-plugin-too/0\n' 'BAR = False', '# horizon-plugin/0\n' 'FOO = True']}) # Right priority is stringy number. self.relation_ids.return_value = ['plugin:0', 'plugin-too:0'] self.related_units.side_effect = [['horizon-plugin/0'], ['horizon-plugin-too/0']] self.relation_get.side_effect = [{'priority': 99, 'local-settings': 'FOO = True'}, {'priority': ""60"", 'local-settings': 'BAR = False'}] self.assertEqual(horizon_contexts.LocalSettingsContext()(), {'settings': ['# horizon-plugin-too/0\n' 'BAR = False', '# horizon-plugin/0\n' 'FOO = True']}) # Both priorities are strings self.relation_ids.return_value = ['plugin:0', 'plugin-too:0'] self.related_units.side_effect = [['horizon-plugin/0'], ['horizon-plugin-too/0']] self.relation_get.side_effect = [{'priority': ""99"", 'local-settings': 'FOO = True'}, {'priority': ""60"", 'local-settings': 'BAR = False'}] self.assertEqual(horizon_contexts.LocalSettingsContext()(), {'settings': ['# horizon-plugin-too/0\n' 'BAR = False', '# horizon-plugin/0\n' 'FOO = True']}) # Left priority is weired json object self.relation_ids.return_value = ['plugin:0', 'plugin-too:0'] self.related_units.side_effect = [['horizon-plugin/0'], ['horizon-plugin-too/0']] self.relation_get.side_effect = [{'priority': ""{'a': 1}"", 'local-settings': 'FOO = True'}, {'priority': ""60"", 'local-settings': 'BAR = False'}] self.assertEqual(horizon_contexts.LocalSettingsContext()(), {'settings': ['# horizon-plugin-too/0\n' 'BAR = False', '# horizon-plugin/0\n' 'FOO = True']}) # right priority is weired json object self.relation_ids.return_value = ['plugin:0', 'plugin-too:0'] self.related_units.side_effect = [['horizon-plugin/0'], ['horizon-plugin-too/0']] self.relation_get.side_effect = [{'priority': ""99"", 'local-settings': 'FOO = True'}, {'priority': ""[1,2,3]"", 'local-settings': 'BAR = False'}] self.assertEqual(horizon_contexts.LocalSettingsContext()(), {'settings': ['# horizon-plugin/0\n' 'FOO = True', '# horizon-plugin-too/0\n' 'BAR = False']}) ",,180,2
openstack%2Fcharm-openstack-dashboard~887671,openstack/charm-openstack-dashboard,stable/victoria,I6bbf7e5f81a772ffc6ea859c9ab7c05f2eb9fdc5,Make LocalSettingsContext more robust to priority,MERGED,2023-07-05 10:39:44.000000000,2023-07-11 12:38:04.000000000,2023-07-11 12:38:04.000000000,"[{'_account_id': 11805}, {'_account_id': 12549}, {'_account_id': 20648}, {'_account_id': 22348}]","[{'number': 1, 'created': '2023-07-05 10:39:44.000000000', 'files': ['hooks/horizon_contexts.py', 'unit_tests/test_horizon_contexts.py'], 'web_link': 'https://opendev.org/openstack/charm-openstack-dashboard/commit/2a8943e319e21677745d138eabd1b5f9ecf99238', 'message': ""Make LocalSettingsContext more robust to priority\n\nThe relation data for for the LocalSettings context could cause the\npriority sorting to break if the priority key wasn't cmpable (e.g. using\n<, > or ==).  This patch fixes the associated bug, by making the sorting\nextra robust and ensuring that un-cmp-able values are 'greater' (e.g.\nfurther down the list) that cmp-able values, and equal to each other.\nE.g. a partially ordered set.\n\nChange-Id: I6bbf7e5f81a772ffc6ea859c9ab7c05f2eb9fdc5\nCloses-bug: #2023404\n(cherry picked from commit e8d0ca39a1e02abb075e283e4438464b90223b91)\n""}]",0,887671,2a8943e319e21677745d138eabd1b5f9ecf99238,10,4,1,20870,,,0,"Make LocalSettingsContext more robust to priority

The relation data for for the LocalSettings context could cause the
priority sorting to break if the priority key wasn't cmpable (e.g. using
<, > or ==).  This patch fixes the associated bug, by making the sorting
extra robust and ensuring that un-cmp-able values are 'greater' (e.g.
further down the list) that cmp-able values, and equal to each other.
E.g. a partially ordered set.

Change-Id: I6bbf7e5f81a772ffc6ea859c9ab7c05f2eb9fdc5
Closes-bug: #2023404
(cherry picked from commit e8d0ca39a1e02abb075e283e4438464b90223b91)
",git fetch https://review.opendev.org/openstack/charm-openstack-dashboard refs/changes/71/887671/1 && git format-patch -1 --stdout FETCH_HEAD,"['hooks/horizon_contexts.py', 'unit_tests/test_horizon_contexts.py']",2,2a8943e319e21677745d138eabd1b5f9ecf99238,bug/2023404," def test_LocalSettingsContext_unusual_priority(self): # First, left priority missing. self.related_units.side_effect = [['horizon-plugin/0'], ['horizon-plugin-too/0']] self.relation_get.side_effect = [{'local-settings': 'FOO = True'}, {'priority': 60, 'local-settings': 'BAR = False'}] self.assertEqual(horizon_contexts.LocalSettingsContext()(), {'settings': []}) # First, right priority missing. self.related_units.side_effect = [['horizon-plugin/0'], ['horizon-plugin-too/0']] self.relation_get.side_effect = [{'priority': 99, 'local-settings': 'FOO = True'}, {'local-settings': 'BAR = False'}] self.assertEqual(horizon_contexts.LocalSettingsContext()(), {'settings': []}) # Left priority is None. self.relation_ids.return_value = ['plugin:0', 'plugin-too:0'] self.related_units.side_effect = [['horizon-plugin/0'], ['horizon-plugin-too/0']] self.relation_get.side_effect = [{'priority': None, 'local-settings': 'FOO = True'}, {'priority': 60, 'local-settings': 'BAR = False'}] self.assertEqual(horizon_contexts.LocalSettingsContext()(), {'settings': ['# horizon-plugin-too/0\n' 'BAR = False', '# horizon-plugin/0\n' 'FOO = True']}) # Right priority is None. self.relation_ids.return_value = ['plugin:0', 'plugin-too:0'] self.related_units.side_effect = [['horizon-plugin/0'], ['horizon-plugin-too/0']] self.relation_get.side_effect = [{'priority': 99, 'local-settings': 'FOO = True'}, {'priority': None, 'local-settings': 'BAR = False'}] self.assertEqual(horizon_contexts.LocalSettingsContext()(), {'settings': ['# horizon-plugin/0\n' 'FOO = True', '# horizon-plugin-too/0\n' 'BAR = False']}) # Left priority is stringy number. self.relation_ids.return_value = ['plugin:0', 'plugin-too:0'] self.related_units.side_effect = [['horizon-plugin/0'], ['horizon-plugin-too/0']] self.relation_get.side_effect = [{'priority': ""99"", 'local-settings': 'FOO = True'}, {'priority': 60, 'local-settings': 'BAR = False'}] self.assertEqual(horizon_contexts.LocalSettingsContext()(), {'settings': ['# horizon-plugin-too/0\n' 'BAR = False', '# horizon-plugin/0\n' 'FOO = True']}) # Right priority is stringy number. self.relation_ids.return_value = ['plugin:0', 'plugin-too:0'] self.related_units.side_effect = [['horizon-plugin/0'], ['horizon-plugin-too/0']] self.relation_get.side_effect = [{'priority': 99, 'local-settings': 'FOO = True'}, {'priority': ""60"", 'local-settings': 'BAR = False'}] self.assertEqual(horizon_contexts.LocalSettingsContext()(), {'settings': ['# horizon-plugin-too/0\n' 'BAR = False', '# horizon-plugin/0\n' 'FOO = True']}) # Both priorities are strings self.relation_ids.return_value = ['plugin:0', 'plugin-too:0'] self.related_units.side_effect = [['horizon-plugin/0'], ['horizon-plugin-too/0']] self.relation_get.side_effect = [{'priority': ""99"", 'local-settings': 'FOO = True'}, {'priority': ""60"", 'local-settings': 'BAR = False'}] self.assertEqual(horizon_contexts.LocalSettingsContext()(), {'settings': ['# horizon-plugin-too/0\n' 'BAR = False', '# horizon-plugin/0\n' 'FOO = True']}) # Left priority is weired json object self.relation_ids.return_value = ['plugin:0', 'plugin-too:0'] self.related_units.side_effect = [['horizon-plugin/0'], ['horizon-plugin-too/0']] self.relation_get.side_effect = [{'priority': ""{'a': 1}"", 'local-settings': 'FOO = True'}, {'priority': ""60"", 'local-settings': 'BAR = False'}] self.assertEqual(horizon_contexts.LocalSettingsContext()(), {'settings': ['# horizon-plugin-too/0\n' 'BAR = False', '# horizon-plugin/0\n' 'FOO = True']}) # right priority is weired json object self.relation_ids.return_value = ['plugin:0', 'plugin-too:0'] self.related_units.side_effect = [['horizon-plugin/0'], ['horizon-plugin-too/0']] self.relation_get.side_effect = [{'priority': ""99"", 'local-settings': 'FOO = True'}, {'priority': ""[1,2,3]"", 'local-settings': 'BAR = False'}] self.assertEqual(horizon_contexts.LocalSettingsContext()(), {'settings': ['# horizon-plugin/0\n' 'FOO = True', '# horizon-plugin-too/0\n' 'BAR = False']}) ",,180,2
openstack%2Fcharm-openstack-dashboard~887670,openstack/charm-openstack-dashboard,stable/wallaby,I6bbf7e5f81a772ffc6ea859c9ab7c05f2eb9fdc5,Make LocalSettingsContext more robust to priority,MERGED,2023-07-05 10:38:50.000000000,2023-07-11 12:38:03.000000000,2023-07-11 12:38:03.000000000,"[{'_account_id': 11805}, {'_account_id': 12549}, {'_account_id': 20648}, {'_account_id': 22348}]","[{'number': 1, 'created': '2023-07-05 10:38:50.000000000', 'files': ['hooks/horizon_contexts.py', 'unit_tests/test_horizon_contexts.py'], 'web_link': 'https://opendev.org/openstack/charm-openstack-dashboard/commit/13f2ad1d5a4161b9f1bb83bee766e4a4b12c340c', 'message': ""Make LocalSettingsContext more robust to priority\n\nThe relation data for for the LocalSettings context could cause the\npriority sorting to break if the priority key wasn't cmpable (e.g. using\n<, > or ==).  This patch fixes the associated bug, by making the sorting\nextra robust and ensuring that un-cmp-able values are 'greater' (e.g.\nfurther down the list) that cmp-able values, and equal to each other.\nE.g. a partially ordered set.\n\nChange-Id: I6bbf7e5f81a772ffc6ea859c9ab7c05f2eb9fdc5\nCloses-bug: #2023404\n(cherry picked from commit e8d0ca39a1e02abb075e283e4438464b90223b91)\n""}]",0,887670,13f2ad1d5a4161b9f1bb83bee766e4a4b12c340c,10,4,1,20870,,,0,"Make LocalSettingsContext more robust to priority

The relation data for for the LocalSettings context could cause the
priority sorting to break if the priority key wasn't cmpable (e.g. using
<, > or ==).  This patch fixes the associated bug, by making the sorting
extra robust and ensuring that un-cmp-able values are 'greater' (e.g.
further down the list) that cmp-able values, and equal to each other.
E.g. a partially ordered set.

Change-Id: I6bbf7e5f81a772ffc6ea859c9ab7c05f2eb9fdc5
Closes-bug: #2023404
(cherry picked from commit e8d0ca39a1e02abb075e283e4438464b90223b91)
",git fetch https://review.opendev.org/openstack/charm-openstack-dashboard refs/changes/70/887670/1 && git format-patch -1 --stdout FETCH_HEAD,"['hooks/horizon_contexts.py', 'unit_tests/test_horizon_contexts.py']",2,13f2ad1d5a4161b9f1bb83bee766e4a4b12c340c,bug/2023404," def test_LocalSettingsContext_unusual_priority(self): # First, left priority missing. self.related_units.side_effect = [['horizon-plugin/0'], ['horizon-plugin-too/0']] self.relation_get.side_effect = [{'local-settings': 'FOO = True'}, {'priority': 60, 'local-settings': 'BAR = False'}] self.assertEqual(horizon_contexts.LocalSettingsContext()(), {'settings': []}) # First, right priority missing. self.related_units.side_effect = [['horizon-plugin/0'], ['horizon-plugin-too/0']] self.relation_get.side_effect = [{'priority': 99, 'local-settings': 'FOO = True'}, {'local-settings': 'BAR = False'}] self.assertEqual(horizon_contexts.LocalSettingsContext()(), {'settings': []}) # Left priority is None. self.relation_ids.return_value = ['plugin:0', 'plugin-too:0'] self.related_units.side_effect = [['horizon-plugin/0'], ['horizon-plugin-too/0']] self.relation_get.side_effect = [{'priority': None, 'local-settings': 'FOO = True'}, {'priority': 60, 'local-settings': 'BAR = False'}] self.assertEqual(horizon_contexts.LocalSettingsContext()(), {'settings': ['# horizon-plugin-too/0\n' 'BAR = False', '# horizon-plugin/0\n' 'FOO = True']}) # Right priority is None. self.relation_ids.return_value = ['plugin:0', 'plugin-too:0'] self.related_units.side_effect = [['horizon-plugin/0'], ['horizon-plugin-too/0']] self.relation_get.side_effect = [{'priority': 99, 'local-settings': 'FOO = True'}, {'priority': None, 'local-settings': 'BAR = False'}] self.assertEqual(horizon_contexts.LocalSettingsContext()(), {'settings': ['# horizon-plugin/0\n' 'FOO = True', '# horizon-plugin-too/0\n' 'BAR = False']}) # Left priority is stringy number. self.relation_ids.return_value = ['plugin:0', 'plugin-too:0'] self.related_units.side_effect = [['horizon-plugin/0'], ['horizon-plugin-too/0']] self.relation_get.side_effect = [{'priority': ""99"", 'local-settings': 'FOO = True'}, {'priority': 60, 'local-settings': 'BAR = False'}] self.assertEqual(horizon_contexts.LocalSettingsContext()(), {'settings': ['# horizon-plugin-too/0\n' 'BAR = False', '# horizon-plugin/0\n' 'FOO = True']}) # Right priority is stringy number. self.relation_ids.return_value = ['plugin:0', 'plugin-too:0'] self.related_units.side_effect = [['horizon-plugin/0'], ['horizon-plugin-too/0']] self.relation_get.side_effect = [{'priority': 99, 'local-settings': 'FOO = True'}, {'priority': ""60"", 'local-settings': 'BAR = False'}] self.assertEqual(horizon_contexts.LocalSettingsContext()(), {'settings': ['# horizon-plugin-too/0\n' 'BAR = False', '# horizon-plugin/0\n' 'FOO = True']}) # Both priorities are strings self.relation_ids.return_value = ['plugin:0', 'plugin-too:0'] self.related_units.side_effect = [['horizon-plugin/0'], ['horizon-plugin-too/0']] self.relation_get.side_effect = [{'priority': ""99"", 'local-settings': 'FOO = True'}, {'priority': ""60"", 'local-settings': 'BAR = False'}] self.assertEqual(horizon_contexts.LocalSettingsContext()(), {'settings': ['# horizon-plugin-too/0\n' 'BAR = False', '# horizon-plugin/0\n' 'FOO = True']}) # Left priority is weired json object self.relation_ids.return_value = ['plugin:0', 'plugin-too:0'] self.related_units.side_effect = [['horizon-plugin/0'], ['horizon-plugin-too/0']] self.relation_get.side_effect = [{'priority': ""{'a': 1}"", 'local-settings': 'FOO = True'}, {'priority': ""60"", 'local-settings': 'BAR = False'}] self.assertEqual(horizon_contexts.LocalSettingsContext()(), {'settings': ['# horizon-plugin-too/0\n' 'BAR = False', '# horizon-plugin/0\n' 'FOO = True']}) # right priority is weired json object self.relation_ids.return_value = ['plugin:0', 'plugin-too:0'] self.related_units.side_effect = [['horizon-plugin/0'], ['horizon-plugin-too/0']] self.relation_get.side_effect = [{'priority': ""99"", 'local-settings': 'FOO = True'}, {'priority': ""[1,2,3]"", 'local-settings': 'BAR = False'}] self.assertEqual(horizon_contexts.LocalSettingsContext()(), {'settings': ['# horizon-plugin/0\n' 'FOO = True', '# horizon-plugin-too/0\n' 'BAR = False']}) ",,180,2
openstack%2Fcharm-openstack-dashboard~887621,openstack/charm-openstack-dashboard,stable/xena,I6bbf7e5f81a772ffc6ea859c9ab7c05f2eb9fdc5,Make LocalSettingsContext more robust to priority,MERGED,2023-07-04 16:47:24.000000000,2023-07-11 12:35:20.000000000,2023-07-11 12:35:20.000000000,"[{'_account_id': 11805}, {'_account_id': 12549}, {'_account_id': 20648}, {'_account_id': 22348}]","[{'number': 1, 'created': '2023-07-04 16:47:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-openstack-dashboard/commit/0e517767e108d5572f789b69cdade0b9c3c307f6', 'message': ""Make LocalSettingsContext more robust to priority\n\nThe relation data for for the LocalSettings context could cause the\npriority sorting to break if the priority key wasn't cmpable (e.g. using\n<, > or ==).  This patch fixes the associated bug, by making the sorting\nextra robust and ensuring that un-cmp-able values are 'greater' (e.g.\nfurther down the list) that cmp-able values, and equal to each other.\nE.g. a partially ordered set.\n\nChange-Id: I6bbf7e5f81a772ffc6ea859c9ab7c05f2eb9fdc5\nCloses-bug: #2023404\n(cherry picked from commit e8d0ca39a1e02abb075e283e4438464b90223b91)\n""}, {'number': 2, 'created': '2023-07-04 17:24:17.000000000', 'files': ['hooks/horizon_contexts.py', 'unit_tests/test_horizon_contexts.py'], 'web_link': 'https://opendev.org/openstack/charm-openstack-dashboard/commit/291d162489ab2b4f99bba0509f7dc51724ffddd0', 'message': ""Make LocalSettingsContext more robust to priority\n\nThe relation data for for the LocalSettings context could cause the\npriority sorting to break if the priority key wasn't cmpable (e.g. using\n<, > or ==).  This patch fixes the associated bug, by making the sorting\nextra robust and ensuring that un-cmp-able values are 'greater' (e.g.\nfurther down the list) that cmp-able values, and equal to each other.\nE.g. a partially ordered set.\n\nChange-Id: I6bbf7e5f81a772ffc6ea859c9ab7c05f2eb9fdc5\nCloses-bug: #2023404\n(cherry picked from commit e8d0ca39a1e02abb075e283e4438464b90223b91)\n""}]",0,887621,291d162489ab2b4f99bba0509f7dc51724ffddd0,13,4,2,20870,,,0,"Make LocalSettingsContext more robust to priority

The relation data for for the LocalSettings context could cause the
priority sorting to break if the priority key wasn't cmpable (e.g. using
<, > or ==).  This patch fixes the associated bug, by making the sorting
extra robust and ensuring that un-cmp-able values are 'greater' (e.g.
further down the list) that cmp-able values, and equal to each other.
E.g. a partially ordered set.

Change-Id: I6bbf7e5f81a772ffc6ea859c9ab7c05f2eb9fdc5
Closes-bug: #2023404
(cherry picked from commit e8d0ca39a1e02abb075e283e4438464b90223b91)
",git fetch https://review.opendev.org/openstack/charm-openstack-dashboard refs/changes/21/887621/1 && git format-patch -1 --stdout FETCH_HEAD,"['hooks/horizon_contexts.py', 'unit_tests/test_horizon_contexts.py']",2,0e517767e108d5572f789b69cdade0b9c3c307f6,bug/2023404,"<<<<<<< HEAD (0e3903 Pin tox to < 4.0.0) ======= def test_LocalSettingsContextJSON(self): self.relation_ids.return_value = ['plugin:0', 'plugin-too:0'] self.related_units.side_effect = [['horizon-plugin/0'], ['horizon-plugin-too/0']] # One JSON and one raw relation self.relation_get.side_effect = [{'priority': ""99"", 'local-settings': '""FOO = True""'}, {'priority': 60, 'local-settings': 'BAR = False'}] self.assertEqual(horizon_contexts.LocalSettingsContext()(), {'settings': ['# horizon-plugin-too/0\n' 'BAR = False', '# horizon-plugin/0\n' 'FOO = True']}) def test_LocalSettingsContext_unusual_priority(self): # First, left priority missing. self.related_units.side_effect = [['horizon-plugin/0'], ['horizon-plugin-too/0']] self.relation_get.side_effect = [{'local-settings': 'FOO = True'}, {'priority': 60, 'local-settings': 'BAR = False'}] self.assertEqual(horizon_contexts.LocalSettingsContext()(), {'settings': []}) # First, right priority missing. self.related_units.side_effect = [['horizon-plugin/0'], ['horizon-plugin-too/0']] self.relation_get.side_effect = [{'priority': 99, 'local-settings': 'FOO = True'}, {'local-settings': 'BAR = False'}] self.assertEqual(horizon_contexts.LocalSettingsContext()(), {'settings': []}) # Left priority is None. self.relation_ids.return_value = ['plugin:0', 'plugin-too:0'] self.related_units.side_effect = [['horizon-plugin/0'], ['horizon-plugin-too/0']] self.relation_get.side_effect = [{'priority': None, 'local-settings': 'FOO = True'}, {'priority': 60, 'local-settings': 'BAR = False'}] self.assertEqual(horizon_contexts.LocalSettingsContext()(), {'settings': ['# horizon-plugin-too/0\n' 'BAR = False', '# horizon-plugin/0\n' 'FOO = True']}) # Right priority is None. self.relation_ids.return_value = ['plugin:0', 'plugin-too:0'] self.related_units.side_effect = [['horizon-plugin/0'], ['horizon-plugin-too/0']] self.relation_get.side_effect = [{'priority': 99, 'local-settings': 'FOO = True'}, {'priority': None, 'local-settings': 'BAR = False'}] self.assertEqual(horizon_contexts.LocalSettingsContext()(), {'settings': ['# horizon-plugin/0\n' 'FOO = True', '# horizon-plugin-too/0\n' 'BAR = False']}) # Left priority is stringy number. self.relation_ids.return_value = ['plugin:0', 'plugin-too:0'] self.related_units.side_effect = [['horizon-plugin/0'], ['horizon-plugin-too/0']] self.relation_get.side_effect = [{'priority': ""99"", 'local-settings': 'FOO = True'}, {'priority': 60, 'local-settings': 'BAR = False'}] self.assertEqual(horizon_contexts.LocalSettingsContext()(), {'settings': ['# horizon-plugin-too/0\n' 'BAR = False', '# horizon-plugin/0\n' 'FOO = True']}) # Right priority is stringy number. self.relation_ids.return_value = ['plugin:0', 'plugin-too:0'] self.related_units.side_effect = [['horizon-plugin/0'], ['horizon-plugin-too/0']] self.relation_get.side_effect = [{'priority': 99, 'local-settings': 'FOO = True'}, {'priority': ""60"", 'local-settings': 'BAR = False'}] self.assertEqual(horizon_contexts.LocalSettingsContext()(), {'settings': ['# horizon-plugin-too/0\n' 'BAR = False', '# horizon-plugin/0\n' 'FOO = True']}) # Both priorities are strings self.relation_ids.return_value = ['plugin:0', 'plugin-too:0'] self.related_units.side_effect = [['horizon-plugin/0'], ['horizon-plugin-too/0']] self.relation_get.side_effect = [{'priority': ""99"", 'local-settings': 'FOO = True'}, {'priority': ""60"", 'local-settings': 'BAR = False'}] self.assertEqual(horizon_contexts.LocalSettingsContext()(), {'settings': ['# horizon-plugin-too/0\n' 'BAR = False', '# horizon-plugin/0\n' 'FOO = True']}) # Left priority is weired json object self.relation_ids.return_value = ['plugin:0', 'plugin-too:0'] self.related_units.side_effect = [['horizon-plugin/0'], ['horizon-plugin-too/0']] self.relation_get.side_effect = [{'priority': ""{'a': 1}"", 'local-settings': 'FOO = True'}, {'priority': ""60"", 'local-settings': 'BAR = False'}] self.assertEqual(horizon_contexts.LocalSettingsContext()(), {'settings': ['# horizon-plugin-too/0\n' 'BAR = False', '# horizon-plugin/0\n' 'FOO = True']}) # right priority is weired json object self.relation_ids.return_value = ['plugin:0', 'plugin-too:0'] self.related_units.side_effect = [['horizon-plugin/0'], ['horizon-plugin-too/0']] self.relation_get.side_effect = [{'priority': ""99"", 'local-settings': 'FOO = True'}, {'priority': ""[1,2,3]"", 'local-settings': 'BAR = False'}] self.assertEqual(horizon_contexts.LocalSettingsContext()(), {'settings': ['# horizon-plugin/0\n' 'FOO = True', '# horizon-plugin-too/0\n' 'BAR = False']}) >>>>>>> CHANGE (daa378 Make LocalSettingsContext more robust to priority)",,199,2
openstack%2Fcharm-openstack-dashboard~887620,openstack/charm-openstack-dashboard,stable/yoga,I6bbf7e5f81a772ffc6ea859c9ab7c05f2eb9fdc5,Make LocalSettingsContext more robust to priority,MERGED,2023-07-04 16:44:19.000000000,2023-07-11 12:35:17.000000000,2023-07-11 12:35:17.000000000,"[{'_account_id': 11805}, {'_account_id': 12549}, {'_account_id': 20648}, {'_account_id': 22348}]","[{'number': 1, 'created': '2023-07-04 16:44:19.000000000', 'files': ['hooks/horizon_contexts.py', 'unit_tests/test_horizon_contexts.py'], 'web_link': 'https://opendev.org/openstack/charm-openstack-dashboard/commit/daa3783d00385a59ac4c44e1f4e14c4946e3f296', 'message': ""Make LocalSettingsContext more robust to priority\n\nThe relation data for for the LocalSettings context could cause the\npriority sorting to break if the priority key wasn't cmpable (e.g. using\n<, > or ==).  This patch fixes the associated bug, by making the sorting\nextra robust and ensuring that un-cmp-able values are 'greater' (e.g.\nfurther down the list) that cmp-able values, and equal to each other.\nE.g. a partially ordered set.\n\nChange-Id: I6bbf7e5f81a772ffc6ea859c9ab7c05f2eb9fdc5\nCloses-bug: #2023404\n(cherry picked from commit e8d0ca39a1e02abb075e283e4438464b90223b91)\n""}]",0,887620,daa3783d00385a59ac4c44e1f4e14c4946e3f296,12,4,1,20870,,,0,"Make LocalSettingsContext more robust to priority

The relation data for for the LocalSettings context could cause the
priority sorting to break if the priority key wasn't cmpable (e.g. using
<, > or ==).  This patch fixes the associated bug, by making the sorting
extra robust and ensuring that un-cmp-able values are 'greater' (e.g.
further down the list) that cmp-able values, and equal to each other.
E.g. a partially ordered set.

Change-Id: I6bbf7e5f81a772ffc6ea859c9ab7c05f2eb9fdc5
Closes-bug: #2023404
(cherry picked from commit e8d0ca39a1e02abb075e283e4438464b90223b91)
",git fetch https://review.opendev.org/openstack/charm-openstack-dashboard refs/changes/20/887620/1 && git format-patch -1 --stdout FETCH_HEAD,"['hooks/horizon_contexts.py', 'unit_tests/test_horizon_contexts.py']",2,daa3783d00385a59ac4c44e1f4e14c4946e3f296,bug/2023404," def test_LocalSettingsContext_unusual_priority(self): # First, left priority missing. self.related_units.side_effect = [['horizon-plugin/0'], ['horizon-plugin-too/0']] self.relation_get.side_effect = [{'local-settings': 'FOO = True'}, {'priority': 60, 'local-settings': 'BAR = False'}] self.assertEqual(horizon_contexts.LocalSettingsContext()(), {'settings': []}) # First, right priority missing. self.related_units.side_effect = [['horizon-plugin/0'], ['horizon-plugin-too/0']] self.relation_get.side_effect = [{'priority': 99, 'local-settings': 'FOO = True'}, {'local-settings': 'BAR = False'}] self.assertEqual(horizon_contexts.LocalSettingsContext()(), {'settings': []}) # Left priority is None. self.relation_ids.return_value = ['plugin:0', 'plugin-too:0'] self.related_units.side_effect = [['horizon-plugin/0'], ['horizon-plugin-too/0']] self.relation_get.side_effect = [{'priority': None, 'local-settings': 'FOO = True'}, {'priority': 60, 'local-settings': 'BAR = False'}] self.assertEqual(horizon_contexts.LocalSettingsContext()(), {'settings': ['# horizon-plugin-too/0\n' 'BAR = False', '# horizon-plugin/0\n' 'FOO = True']}) # Right priority is None. self.relation_ids.return_value = ['plugin:0', 'plugin-too:0'] self.related_units.side_effect = [['horizon-plugin/0'], ['horizon-plugin-too/0']] self.relation_get.side_effect = [{'priority': 99, 'local-settings': 'FOO = True'}, {'priority': None, 'local-settings': 'BAR = False'}] self.assertEqual(horizon_contexts.LocalSettingsContext()(), {'settings': ['# horizon-plugin/0\n' 'FOO = True', '# horizon-plugin-too/0\n' 'BAR = False']}) # Left priority is stringy number. self.relation_ids.return_value = ['plugin:0', 'plugin-too:0'] self.related_units.side_effect = [['horizon-plugin/0'], ['horizon-plugin-too/0']] self.relation_get.side_effect = [{'priority': ""99"", 'local-settings': 'FOO = True'}, {'priority': 60, 'local-settings': 'BAR = False'}] self.assertEqual(horizon_contexts.LocalSettingsContext()(), {'settings': ['# horizon-plugin-too/0\n' 'BAR = False', '# horizon-plugin/0\n' 'FOO = True']}) # Right priority is stringy number. self.relation_ids.return_value = ['plugin:0', 'plugin-too:0'] self.related_units.side_effect = [['horizon-plugin/0'], ['horizon-plugin-too/0']] self.relation_get.side_effect = [{'priority': 99, 'local-settings': 'FOO = True'}, {'priority': ""60"", 'local-settings': 'BAR = False'}] self.assertEqual(horizon_contexts.LocalSettingsContext()(), {'settings': ['# horizon-plugin-too/0\n' 'BAR = False', '# horizon-plugin/0\n' 'FOO = True']}) # Both priorities are strings self.relation_ids.return_value = ['plugin:0', 'plugin-too:0'] self.related_units.side_effect = [['horizon-plugin/0'], ['horizon-plugin-too/0']] self.relation_get.side_effect = [{'priority': ""99"", 'local-settings': 'FOO = True'}, {'priority': ""60"", 'local-settings': 'BAR = False'}] self.assertEqual(horizon_contexts.LocalSettingsContext()(), {'settings': ['# horizon-plugin-too/0\n' 'BAR = False', '# horizon-plugin/0\n' 'FOO = True']}) # Left priority is weired json object self.relation_ids.return_value = ['plugin:0', 'plugin-too:0'] self.related_units.side_effect = [['horizon-plugin/0'], ['horizon-plugin-too/0']] self.relation_get.side_effect = [{'priority': ""{'a': 1}"", 'local-settings': 'FOO = True'}, {'priority': ""60"", 'local-settings': 'BAR = False'}] self.assertEqual(horizon_contexts.LocalSettingsContext()(), {'settings': ['# horizon-plugin-too/0\n' 'BAR = False', '# horizon-plugin/0\n' 'FOO = True']}) # right priority is weired json object self.relation_ids.return_value = ['plugin:0', 'plugin-too:0'] self.related_units.side_effect = [['horizon-plugin/0'], ['horizon-plugin-too/0']] self.relation_get.side_effect = [{'priority': ""99"", 'local-settings': 'FOO = True'}, {'priority': ""[1,2,3]"", 'local-settings': 'BAR = False'}] self.assertEqual(horizon_contexts.LocalSettingsContext()(), {'settings': ['# horizon-plugin/0\n' 'FOO = True', '# horizon-plugin-too/0\n' 'BAR = False']}) ",,180,2
openstack%2Fironic~887271,openstack/ironic,master,If9d571792a8617dd6ecf17e163dea252cb0f7fae,Fix the HTTP code of the BadRequest exception,MERGED,2023-06-29 12:38:33.000000000,2023-07-11 12:23:02.000000000,2023-07-11 12:21:42.000000000,"[{'_account_id': 11655}, {'_account_id': 22348}, {'_account_id': 23851}, {'_account_id': 32238}]","[{'number': 1, 'created': '2023-06-29 12:38:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/4806361f3aa4ddf08ad13f59236de4c90e1baba8', 'message': 'Fix the HTTP code of the BadRequest exception\n\nWe have both Invalid and BadRequest which result in HTTP 400 and 500\naccordingly. The latter is clearly incorrect.\n\nWe also have NotFound and HTTPNotFound which mean the same thing.\n\nAlias exceptions in both cases with the intention to drop one copy.\n\nChange-Id: If9d571792a8617dd6ecf17e163dea252cb0f7fae\n'}, {'number': 2, 'created': '2023-06-29 12:46:14.000000000', 'files': ['ironic/common/exception.py'], 'web_link': 'https://opendev.org/openstack/ironic/commit/64281162127dd6735791ba6239678adef66b74c3', 'message': 'Fix the HTTP code of the BadRequest exception\n\nWe have both Invalid and BadRequest which result in HTTP 400 and 500\naccordingly. The latter is clearly incorrect.\n\nThen we have NotFound and HTTPNotFound which mean the same thing.\n\nAlias exceptions in both cases with the intention to drop one copy.\n\nFinally, NotAuthorized and Unauthorized result in HTTP 403 and 500\nagain. Fortunately, the latter is not used and can be removed.\n\nChange-Id: If9d571792a8617dd6ecf17e163dea252cb0f7fae\n'}]",9,887271,64281162127dd6735791ba6239678adef66b74c3,42,4,2,10239,,,0,"Fix the HTTP code of the BadRequest exception

We have both Invalid and BadRequest which result in HTTP 400 and 500
accordingly. The latter is clearly incorrect.

Then we have NotFound and HTTPNotFound which mean the same thing.

Alias exceptions in both cases with the intention to drop one copy.

Finally, NotAuthorized and Unauthorized result in HTTP 403 and 500
again. Fortunately, the latter is not used and can be removed.

Change-Id: If9d571792a8617dd6ecf17e163dea252cb0f7fae
",git fetch https://review.opendev.org/openstack/ironic refs/changes/71/887271/1 && git format-patch -1 --stdout FETCH_HEAD,['ironic/common/exception.py'],1,4806361f3aa4ddf08ad13f59236de4c90e1baba8,exc-code,# TODO(dtantsur): leave only one variant BadRequest = Invalid# TODO(dtantsur): leave only one variant HTTPNotFound = NotFound,class BadRequest(IronicException): passclass Unauthorized(IronicException): pass class HTTPNotFound(NotFound): pass,4,8
openstack%2Fcharm-openstack-dashboard~887609,openstack/charm-openstack-dashboard,stable/2023.1,I6bbf7e5f81a772ffc6ea859c9ab7c05f2eb9fdc5,Make LocalSettingsContext more robust to priority,MERGED,2023-07-04 15:05:53.000000000,2023-07-11 12:15:48.000000000,2023-07-11 12:15:48.000000000,"[{'_account_id': 11805}, {'_account_id': 12549}, {'_account_id': 20648}, {'_account_id': 22348}]","[{'number': 1, 'created': '2023-07-04 15:05:53.000000000', 'files': ['hooks/horizon_contexts.py', 'unit_tests/test_horizon_contexts.py'], 'web_link': 'https://opendev.org/openstack/charm-openstack-dashboard/commit/d43e1f9f50455339bed0875a07156c829e3a4da2', 'message': ""Make LocalSettingsContext more robust to priority\n\nThe relation data for for the LocalSettings context could cause the\npriority sorting to break if the priority key wasn't cmpable (e.g. using\n<, > or ==).  This patch fixes the associated bug, by making the sorting\nextra robust and ensuring that un-cmp-able values are 'greater' (e.g.\nfurther down the list) that cmp-able values, and equal to each other.\nE.g. a partially ordered set.\n\nChange-Id: I6bbf7e5f81a772ffc6ea859c9ab7c05f2eb9fdc5\nCloses-bug: #2023404\n(cherry picked from commit e8d0ca39a1e02abb075e283e4438464b90223b91)\n""}]",0,887609,d43e1f9f50455339bed0875a07156c829e3a4da2,10,4,1,8992,,,0,"Make LocalSettingsContext more robust to priority

The relation data for for the LocalSettings context could cause the
priority sorting to break if the priority key wasn't cmpable (e.g. using
<, > or ==).  This patch fixes the associated bug, by making the sorting
extra robust and ensuring that un-cmp-able values are 'greater' (e.g.
further down the list) that cmp-able values, and equal to each other.
E.g. a partially ordered set.

Change-Id: I6bbf7e5f81a772ffc6ea859c9ab7c05f2eb9fdc5
Closes-bug: #2023404
(cherry picked from commit e8d0ca39a1e02abb075e283e4438464b90223b91)
",git fetch https://review.opendev.org/openstack/charm-openstack-dashboard refs/changes/09/887609/1 && git format-patch -1 --stdout FETCH_HEAD,"['hooks/horizon_contexts.py', 'unit_tests/test_horizon_contexts.py']",2,d43e1f9f50455339bed0875a07156c829e3a4da2,bug/2023404," def test_LocalSettingsContext_unusual_priority(self): # First, left priority missing. self.related_units.side_effect = [['horizon-plugin/0'], ['horizon-plugin-too/0']] self.relation_get.side_effect = [{'local-settings': 'FOO = True'}, {'priority': 60, 'local-settings': 'BAR = False'}] self.assertEqual(horizon_contexts.LocalSettingsContext()(), {'settings': []}) # First, right priority missing. self.related_units.side_effect = [['horizon-plugin/0'], ['horizon-plugin-too/0']] self.relation_get.side_effect = [{'priority': 99, 'local-settings': 'FOO = True'}, {'local-settings': 'BAR = False'}] self.assertEqual(horizon_contexts.LocalSettingsContext()(), {'settings': []}) # Left priority is None. self.relation_ids.return_value = ['plugin:0', 'plugin-too:0'] self.related_units.side_effect = [['horizon-plugin/0'], ['horizon-plugin-too/0']] self.relation_get.side_effect = [{'priority': None, 'local-settings': 'FOO = True'}, {'priority': 60, 'local-settings': 'BAR = False'}] self.assertEqual(horizon_contexts.LocalSettingsContext()(), {'settings': ['# horizon-plugin-too/0\n' 'BAR = False', '# horizon-plugin/0\n' 'FOO = True']}) # Right priority is None. self.relation_ids.return_value = ['plugin:0', 'plugin-too:0'] self.related_units.side_effect = [['horizon-plugin/0'], ['horizon-plugin-too/0']] self.relation_get.side_effect = [{'priority': 99, 'local-settings': 'FOO = True'}, {'priority': None, 'local-settings': 'BAR = False'}] self.assertEqual(horizon_contexts.LocalSettingsContext()(), {'settings': ['# horizon-plugin/0\n' 'FOO = True', '# horizon-plugin-too/0\n' 'BAR = False']}) # Left priority is stringy number. self.relation_ids.return_value = ['plugin:0', 'plugin-too:0'] self.related_units.side_effect = [['horizon-plugin/0'], ['horizon-plugin-too/0']] self.relation_get.side_effect = [{'priority': ""99"", 'local-settings': 'FOO = True'}, {'priority': 60, 'local-settings': 'BAR = False'}] self.assertEqual(horizon_contexts.LocalSettingsContext()(), {'settings': ['# horizon-plugin-too/0\n' 'BAR = False', '# horizon-plugin/0\n' 'FOO = True']}) # Right priority is stringy number. self.relation_ids.return_value = ['plugin:0', 'plugin-too:0'] self.related_units.side_effect = [['horizon-plugin/0'], ['horizon-plugin-too/0']] self.relation_get.side_effect = [{'priority': 99, 'local-settings': 'FOO = True'}, {'priority': ""60"", 'local-settings': 'BAR = False'}] self.assertEqual(horizon_contexts.LocalSettingsContext()(), {'settings': ['# horizon-plugin-too/0\n' 'BAR = False', '# horizon-plugin/0\n' 'FOO = True']}) # Both priorities are strings self.relation_ids.return_value = ['plugin:0', 'plugin-too:0'] self.related_units.side_effect = [['horizon-plugin/0'], ['horizon-plugin-too/0']] self.relation_get.side_effect = [{'priority': ""99"", 'local-settings': 'FOO = True'}, {'priority': ""60"", 'local-settings': 'BAR = False'}] self.assertEqual(horizon_contexts.LocalSettingsContext()(), {'settings': ['# horizon-plugin-too/0\n' 'BAR = False', '# horizon-plugin/0\n' 'FOO = True']}) # Left priority is weired json object self.relation_ids.return_value = ['plugin:0', 'plugin-too:0'] self.related_units.side_effect = [['horizon-plugin/0'], ['horizon-plugin-too/0']] self.relation_get.side_effect = [{'priority': ""{'a': 1}"", 'local-settings': 'FOO = True'}, {'priority': ""60"", 'local-settings': 'BAR = False'}] self.assertEqual(horizon_contexts.LocalSettingsContext()(), {'settings': ['# horizon-plugin-too/0\n' 'BAR = False', '# horizon-plugin/0\n' 'FOO = True']}) # right priority is weired json object self.relation_ids.return_value = ['plugin:0', 'plugin-too:0'] self.related_units.side_effect = [['horizon-plugin/0'], ['horizon-plugin-too/0']] self.relation_get.side_effect = [{'priority': ""99"", 'local-settings': 'FOO = True'}, {'priority': ""[1,2,3]"", 'local-settings': 'BAR = False'}] self.assertEqual(horizon_contexts.LocalSettingsContext()(), {'settings': ['# horizon-plugin/0\n' 'FOO = True', '# horizon-plugin-too/0\n' 'BAR = False']}) ",,180,2
openstack%2Fopenstack-ansible-plugins~888154,openstack/openstack-ansible-plugins,stable/yoga,I11b1046ea91cef7de0b2f6433baabbb144e07700,Skip updating service password by default,ABANDONED,2023-07-11 12:07:59.000000000,2023-07-11 12:09:54.000000000,,[],"[{'number': 1, 'created': '2023-07-11 12:07:59.000000000', 'files': ['releasenotes/notes/service_password_update-3bdd2bb5ed3a99b5.yaml', 'roles/service_setup/tasks/main.yml'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-plugins/commit/6015a39a64e5e1d49f9daa744ca8b24eec8eddf1', 'message': 'Skip updating service password by default\n\nAt the moment we always do attempt to reset passwords for the\nkeystone services, which in some cases leads to race conditions in\nservices. Thus, running a role is not idempotent which we fix by\nintroducing a `service_update_password` variable. So whenever password\nneeds to be reseted/updated, the variable should be supplied for that.\n\nChange-Id: I11b1046ea91cef7de0b2f6433baabbb144e07700\nCloses-Bug: #2023370\n(cherry picked from commit f35126af68e17d76be00f1cb70cd42fab15f2f4e)\n'}]",0,888154,6015a39a64e5e1d49f9daa744ca8b24eec8eddf1,2,0,1,28619,,,0,"Skip updating service password by default

At the moment we always do attempt to reset passwords for the
keystone services, which in some cases leads to race conditions in
services. Thus, running a role is not idempotent which we fix by
introducing a `service_update_password` variable. So whenever password
needs to be reseted/updated, the variable should be supplied for that.

Change-Id: I11b1046ea91cef7de0b2f6433baabbb144e07700
Closes-Bug: #2023370
(cherry picked from commit f35126af68e17d76be00f1cb70cd42fab15f2f4e)
",git fetch https://review.opendev.org/openstack/openstack-ansible-plugins refs/changes/54/888154/1 && git format-patch -1 --stdout FETCH_HEAD,"['releasenotes/notes/service_password_update-3bdd2bb5ed3a99b5.yaml', 'roles/service_setup/tasks/main.yml']",2,6015a39a64e5e1d49f9daa744ca8b24eec8eddf1,," update_password: ""{{ (service_update_password | default(False) | bool) | ternary('always', omit) }}""", update_password: always,15,1
openstack%2Fopenstack-ansible-plugins~886458,openstack/openstack-ansible-plugins,master,I11b1046ea91cef7de0b2f6433baabbb144e07700,Skip updating service password by default,MERGED,2023-06-20 11:44:25.000000000,2023-07-11 12:02:20.000000000,2023-07-11 12:01:25.000000000,"[{'_account_id': 22348}, {'_account_id': 25023}, {'_account_id': 28619}, {'_account_id': 32666}]","[{'number': 1, 'created': '2023-06-20 11:44:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-plugins/commit/5ec5678fbbadbe2e4d9e696090e37598197db45e', 'message': 'Skip updating service password by default\n\nAt the moment we always do attempt to reset passwords for the\nkeystone services, which in some cases leads to race conditions in\nservices. Thus, running a role is not idempotent which we fix by\nintroducing a `service_update_password` variable. So whenever password\nneeds to be reseted/updated, the variable should be supplied for that.\n\nChange-Id: I11b1046ea91cef7de0b2f6433baabbb144e07700\nCloses-Bug: #2023370\n'}, {'number': 2, 'created': '2023-06-20 11:57:09.000000000', 'files': ['releasenotes/notes/service_password_update-3bdd2bb5ed3a99b5.yaml', 'roles/service_setup/tasks/main.yml'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-plugins/commit/f35126af68e17d76be00f1cb70cd42fab15f2f4e', 'message': 'Skip updating service password by default\n\nAt the moment we always do attempt to reset passwords for the\nkeystone services, which in some cases leads to race conditions in\nservices. Thus, running a role is not idempotent which we fix by\nintroducing a `service_update_password` variable. So whenever password\nneeds to be reseted/updated, the variable should be supplied for that.\n\nChange-Id: I11b1046ea91cef7de0b2f6433baabbb144e07700\nCloses-Bug: #2023370\n'}]",2,886458,f35126af68e17d76be00f1cb70cd42fab15f2f4e,12,4,2,28619,,,0,"Skip updating service password by default

At the moment we always do attempt to reset passwords for the
keystone services, which in some cases leads to race conditions in
services. Thus, running a role is not idempotent which we fix by
introducing a `service_update_password` variable. So whenever password
needs to be reseted/updated, the variable should be supplied for that.

Change-Id: I11b1046ea91cef7de0b2f6433baabbb144e07700
Closes-Bug: #2023370
",git fetch https://review.opendev.org/openstack/openstack-ansible-plugins refs/changes/58/886458/1 && git format-patch -1 --stdout FETCH_HEAD,"['releasenotes/notes/service_password_update-3bdd2bb5ed3a99b5.yaml', 'roles/service_setup/tasks/main.yml']",2,5ec5678fbbadbe2e4d9e696090e37598197db45e,," update_password: ""{{ (service_update_password | default(False) | bool) | ternary('always', omit) }}""", update_password: always,15,1
openstack%2Fironic~887432,openstack/ironic,master,I9ac9113ff772ec5ca7549733858926ba359de3ec,Fix db migration tests for sqlalchemy 2.0,MERGED,2023-06-30 22:06:03.000000000,2023-07-11 11:13:40.000000000,2023-07-11 11:12:31.000000000,"[{'_account_id': 10239}, {'_account_id': 10342}, {'_account_id': 22348}, {'_account_id': 23851}]","[{'number': 1, 'created': '2023-06-30 22:06:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/75c6da7d306139968aa7532300e7b5210da60c24', 'message': 'Fix db migration test for sqlalchemy 2.0\n\nChange-Id: I9ac9113ff772ec5ca7549733858926ba359de3ec\n'}, {'number': 2, 'created': '2023-07-03 13:27:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/a2b8964f7b31111836ba0741ae152873adf4025d', 'message': 'Fix db migration tests for sqlalchemy 2.0\n\nChange-Id: I9ac9113ff772ec5ca7549733858926ba359de3ec\n'}, {'number': 3, 'created': '2023-07-06 13:26:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/84a60f6e6d41b62f31c28466c036115e847ee4ea', 'message': 'Fix db migration tests for sqlalchemy 2.0\n\nChange-Id: I9ac9113ff772ec5ca7549733858926ba359de3ec\n'}, {'number': 4, 'created': '2023-07-07 18:15:36.000000000', 'files': ['ironic/tests/unit/db/sqlalchemy/test_migrations.py'], 'web_link': 'https://opendev.org/openstack/ironic/commit/cb60b8a956c37742b802664d561ccaeab5a46621', 'message': 'Fix db migration tests for sqlalchemy 2.0\n\nChange-Id: I9ac9113ff772ec5ca7549733858926ba359de3ec\n'}]",2,887432,cb60b8a956c37742b802664d561ccaeab5a46621,26,4,4,11655,,,0,"Fix db migration tests for sqlalchemy 2.0

Change-Id: I9ac9113ff772ec5ca7549733858926ba359de3ec
",git fetch https://review.opendev.org/openstack/ironic refs/changes/32/887432/1 && git format-patch -1 --stdout FETCH_HEAD,['ironic/tests/unit/db/sqlalchemy/test_migrations.py'],1,75c6da7d306139968aa7532300e7b5210da60c24,sqlalchemy-20, new = row.provision_state, new = row['provision_state'],1,1
openstack%2Fcharm-nova-compute~887735,openstack/charm-nova-compute,master,Ia1329a6c53cc4b532436751f0396149139a88172,Use service_domain in [service_user] section,MERGED,2023-07-05 20:00:30.000000000,2023-07-11 11:12:22.000000000,2023-07-11 11:12:22.000000000,"[{'_account_id': 20648}, {'_account_id': 20870}, {'_account_id': 22348}]","[{'number': 1, 'created': '2023-07-05 20:00:30.000000000', 'files': ['hooks/charmhelpers/contrib/hahelpers/cluster.py', 'hooks/charmhelpers/contrib/openstack/templates/section-keystone-authtoken-mitaka', 'hooks/charmhelpers/contrib/openstack/templates/section-keystone-authtoken', 'hooks/charmhelpers/contrib/openstack/templates/wsgi-openstack-metadata.conf', 'hooks/charmhelpers/contrib/openstack/context.py', 'hooks/charmhelpers/fetch/ubuntu.py', 'hooks/charmhelpers/contrib/openstack/templates/section-service-user', 'hooks/charmhelpers/contrib/openstack/cert_utils.py', 'hooks/charmhelpers/contrib/openstack/utils.py', 'hooks/charmhelpers/fetch/ubuntu_apt_pkg.py', 'hooks/charmhelpers/contrib/storage/linux/ceph.py', 'hooks/charmhelpers/contrib/openstack/templates/wsgi-openstack-api.conf'], 'web_link': 'https://opendev.org/openstack/charm-nova-compute/commit/1e4112d1d68741fb479d5012026c7b9940ee8d68', 'message': 'Use service_domain in [service_user] section\n\nSync from charm-helpers to update [service_user] config to use the\nservice domain.\n\nThe keystone charm currently creates two service users, one for the\nservice domain (for v3 authentication), and the other for the default\ndomain (for v2 authentication). The [service_user] config needs to\nuse the service domain.\n\nCloses-Bug: #2026202\nChange-Id: Ia1329a6c53cc4b532436751f0396149139a88172\n'}]",0,887735,1e4112d1d68741fb479d5012026c7b9940ee8d68,8,3,1,11805,,,0,"Use service_domain in [service_user] section

Sync from charm-helpers to update [service_user] config to use the
service domain.

The keystone charm currently creates two service users, one for the
service domain (for v3 authentication), and the other for the default
domain (for v2 authentication). The [service_user] config needs to
use the service domain.

Closes-Bug: #2026202
Change-Id: Ia1329a6c53cc4b532436751f0396149139a88172
",git fetch https://review.opendev.org/openstack/charm-nova-compute refs/changes/35/887735/1 && git format-patch -1 --stdout FETCH_HEAD,"['hooks/charmhelpers/contrib/hahelpers/cluster.py', 'hooks/charmhelpers/contrib/openstack/templates/section-keystone-authtoken-mitaka', 'hooks/charmhelpers/contrib/openstack/templates/section-keystone-authtoken', 'hooks/charmhelpers/contrib/openstack/templates/wsgi-openstack-metadata.conf', 'hooks/charmhelpers/contrib/openstack/context.py', 'hooks/charmhelpers/fetch/ubuntu.py', 'hooks/charmhelpers/contrib/openstack/templates/section-service-user', 'hooks/charmhelpers/contrib/openstack/cert_utils.py', 'hooks/charmhelpers/contrib/openstack/utils.py', 'hooks/charmhelpers/fetch/ubuntu_apt_pkg.py', 'hooks/charmhelpers/contrib/storage/linux/ceph.py', 'hooks/charmhelpers/contrib/openstack/templates/wsgi-openstack-api.conf']",12,1e4112d1d68741fb479d5012026c7b9940ee8d68,bug/2026202,{% if wsgi_rotation -%} WSGISocketRotation On {% else -%} WSGISocketRotation Off {% endif -%} ,,74,31
openstack%2Fcharm-cinder~887736,openstack/charm-cinder,master,Ice5953fb7e926fd8dcf48c895a1dc36210da1dfc,Use service_domain in [service_user] section,MERGED,2023-07-05 20:00:53.000000000,2023-07-11 11:10:15.000000000,2023-07-11 11:10:15.000000000,"[{'_account_id': 20648}, {'_account_id': 20870}, {'_account_id': 22348}]","[{'number': 1, 'created': '2023-07-05 20:00:53.000000000', 'files': ['charmhelpers/contrib/openstack/utils.py', 'charmhelpers/contrib/openstack/templates/section-keystone-authtoken-mitaka', 'charmhelpers/contrib/openstack/templates/section-service-user', 'charmhelpers/contrib/storage/linux/ceph.py', 'charmhelpers/fetch/ubuntu.py', 'charmhelpers/contrib/openstack/cert_utils.py', 'charmhelpers/contrib/openstack/templates/wsgi-openstack-api.conf', 'charmhelpers/contrib/hahelpers/cluster.py', 'charmhelpers/contrib/openstack/templates/wsgi-openstack-metadata.conf', 'charmhelpers/fetch/ubuntu_apt_pkg.py', 'charmhelpers/contrib/openstack/context.py', 'charmhelpers/contrib/openstack/templates/section-keystone-authtoken'], 'web_link': 'https://opendev.org/openstack/charm-cinder/commit/43ff5e66e7ebe90f7d5834bf5b86336dcef58eae', 'message': 'Use service_domain in [service_user] section\n\nSync from charm-helpers to update [service_user] config to use the\nservice domain.\n\nThe keystone charm currently creates two service users, one for the\nservice domain (for v3 authentication), and the other for the default\ndomain (for v2 authentication). The [service_user] config needs to\nuse the service domain.\n\nCloses-Bug: #2026202\nChange-Id: Ice5953fb7e926fd8dcf48c895a1dc36210da1dfc\n'}]",0,887736,43ff5e66e7ebe90f7d5834bf5b86336dcef58eae,8,3,1,11805,,,0,"Use service_domain in [service_user] section

Sync from charm-helpers to update [service_user] config to use the
service domain.

The keystone charm currently creates two service users, one for the
service domain (for v3 authentication), and the other for the default
domain (for v2 authentication). The [service_user] config needs to
use the service domain.

Closes-Bug: #2026202
Change-Id: Ice5953fb7e926fd8dcf48c895a1dc36210da1dfc
",git fetch https://review.opendev.org/openstack/charm-cinder refs/changes/36/887736/1 && git format-patch -1 --stdout FETCH_HEAD,"['charmhelpers/contrib/openstack/utils.py', 'charmhelpers/contrib/openstack/templates/section-keystone-authtoken-mitaka', 'charmhelpers/contrib/openstack/templates/section-service-user', 'charmhelpers/contrib/storage/linux/ceph.py', 'charmhelpers/fetch/ubuntu.py', 'charmhelpers/contrib/openstack/cert_utils.py', 'charmhelpers/contrib/openstack/templates/wsgi-openstack-api.conf', 'charmhelpers/contrib/hahelpers/cluster.py', 'charmhelpers/contrib/openstack/templates/wsgi-openstack-metadata.conf', 'charmhelpers/fetch/ubuntu_apt_pkg.py', 'charmhelpers/contrib/openstack/context.py', 'charmhelpers/contrib/openstack/templates/section-keystone-authtoken']",12,43ff5e66e7ebe90f7d5834bf5b86336dcef58eae,bug/2026202,{% if admin_role -%}{% endif -%},,74,31
openstack%2Fcharm-mysql-router~871370,openstack/charm-mysql-router,stable/jammy,I96e464c3ba52b953d032ad7c5f41414a33bbb683,Pin tox to < 4.0.0,MERGED,2023-01-20 20:11:31.000000000,2023-07-11 11:09:59.000000000,2023-07-11 11:09:59.000000000,"[{'_account_id': 11805}, {'_account_id': 20648}, {'_account_id': 20870}, {'_account_id': 22348}]","[{'number': 1, 'created': '2023-01-20 20:11:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-mysql-router/commit/f134f9885036819517bca36d89a063c24bcceded', 'message': ""Pin tox to < 4.0.0\n\nTox 4.0.0 was recently released and it has several breaking changes.\nWe pin to < 4.0.0 here. We are planning to move forward only on the\nmaster charm branches.\n\nTox is also pinned to < 4.0.0 for stable branches in upstream\nopenstack-zuul-jobs as well as in zosci-config. However, the\nrequires= section in the charm's tox.ini file ends up installing\ntox>4, wiping out the zuul-pinned tox<4 that was already installed\ninstalled. This patch fixes that.\n\nRelated-Bug: #2002788\nChange-Id: I96e464c3ba52b953d032ad7c5f41414a33bbb683\n""}, {'number': 2, 'created': '2023-06-02 16:06:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-mysql-router/commit/aa292c5990dadb4b26b53c83fe4c7c02ae82b7f2', 'message': ""Pin tox to < 4.0.0\n\nTox 4.0.0 was recently released and it has several breaking changes.\nWe pin to < 4.0.0 here. We are planning to move forward only on the\nmaster charm branches.\n\nTox is also pinned to < 4.0.0 for stable branches in upstream\nopenstack-zuul-jobs as well as in zosci-config. However, the\nrequires= section in the charm's tox.ini file ends up installing\ntox>4, wiping out the zuul-pinned tox<4 that was already installed\ninstalled. This patch fixes that.\n\nRelated-Bug: #2002788\nChange-Id: I96e464c3ba52b953d032ad7c5f41414a33bbb683\n""}, {'number': 3, 'created': '2023-06-02 16:16:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-mysql-router/commit/7c7dc775765c77d9635914bff0c7cacc6a4b8b6a', 'message': ""Pin tox to < 4.0.0\n\nTox 4.0.0 was recently released and it has several breaking changes.\nWe pin to < 4.0.0 here. We are planning to move forward only on the\nmaster charm branches.\n\nTox is also pinned to < 4.0.0 for stable branches in upstream\nopenstack-zuul-jobs as well as in zosci-config. However, the\nrequires= section in the charm's tox.ini file ends up installing\ntox>4, wiping out the zuul-pinned tox<4 that was already installed\ninstalled. This patch fixes that.\n\nRelated-Bug: #2002788\nChange-Id: I96e464c3ba52b953d032ad7c5f41414a33bbb683\n""}, {'number': 4, 'created': '2023-06-02 16:25:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-mysql-router/commit/87b8b988c992d84d6067ee9e492d773bd8dfb1f3', 'message': ""Pin tox to < 4.0.0\n\nTox 4.0.0 was recently released and it has several breaking changes.\nWe pin to < 4.0.0 here. We are planning to move forward only on the\nmaster charm branches.\n\nTox is also pinned to < 4.0.0 for stable branches in upstream\nopenstack-zuul-jobs as well as in zosci-config. However, the\nrequires= section in the charm's tox.ini file ends up installing\ntox>4, wiping out the zuul-pinned tox<4 that was already installed\ninstalled. This patch fixes that.\n\nRelated-Bug: #2002788\nChange-Id: I96e464c3ba52b953d032ad7c5f41414a33bbb683\n""}, {'number': 5, 'created': '2023-06-02 16:44:05.000000000', 'files': ['requirements.txt', 'bindep.txt', 'tox.ini'], 'web_link': 'https://opendev.org/openstack/charm-mysql-router/commit/80f211371eda3c734f6c2698aa9bb4711317c612', 'message': ""Pin tox to < 4.0.0\n\nTox 4.0.0 was recently released and it has several breaking changes.\nWe pin to < 4.0.0 here. We are planning to move forward only on the\nmaster charm branches.\n\nTox is also pinned to < 4.0.0 for stable branches in upstream\nopenstack-zuul-jobs as well as in zosci-config. However, the\nrequires= section in the charm's tox.ini file ends up installing\ntox>4, wiping out the zuul-pinned tox<4 that was already installed\ninstalled. This patch fixes that.\n\nRelated-Bug: #2002788\nChange-Id: I96e464c3ba52b953d032ad7c5f41414a33bbb683\n""}]",3,871370,80f211371eda3c734f6c2698aa9bb4711317c612,19,4,5,11805,,,0,"Pin tox to < 4.0.0

Tox 4.0.0 was recently released and it has several breaking changes.
We pin to < 4.0.0 here. We are planning to move forward only on the
master charm branches.

Tox is also pinned to < 4.0.0 for stable branches in upstream
openstack-zuul-jobs as well as in zosci-config. However, the
requires= section in the charm's tox.ini file ends up installing
tox>4, wiping out the zuul-pinned tox<4 that was already installed
installed. This patch fixes that.

Related-Bug: #2002788
Change-Id: I96e464c3ba52b953d032ad7c5f41414a33bbb683
",git fetch https://review.opendev.org/openstack/charm-mysql-router refs/changes/70/871370/1 && git format-patch -1 --stdout FETCH_HEAD,['tox.ini'],1,f134f9885036819517bca36d89a063c24bcceded,logrotate-chmod-stable/jammy, tox < 4.0.0,,1,0
openstack%2Fcharm-ironic-conductor~887801,openstack/charm-ironic-conductor,master,Ic575ac23cc0e7d4d43e26fb979baac61ed27ba6a,Use service_domain in [service_user] section,MERGED,2023-07-06 12:26:48.000000000,2023-07-11 11:01:01.000000000,2023-07-11 11:01:01.000000000,"[{'_account_id': 20648}, {'_account_id': 20870}, {'_account_id': 22348}]","[{'number': 1, 'created': '2023-07-06 12:26:48.000000000', 'files': ['rebuild'], 'web_link': 'https://opendev.org/openstack/charm-ironic-conductor/commit/6241b061bd8131dd0ce899aa65fa7643707403ba', 'message': 'Use service_domain in [service_user] section\n\nRebuild to update [service_user] config to use the service domain.\nThis was fixed in charm-helpers.\n\nThe keystone charm currently creates two service users, one for the\nservice domain (for v3 authentication), and the other for the default\ndomain (for v2 authentication). The [service_user] config needs to\nuse the service domain.\n\nCloses-Bug: #2026202\nChange-Id: Ic575ac23cc0e7d4d43e26fb979baac61ed27ba6a\n'}]",0,887801,6241b061bd8131dd0ce899aa65fa7643707403ba,8,3,1,11805,,,0,"Use service_domain in [service_user] section

Rebuild to update [service_user] config to use the service domain.
This was fixed in charm-helpers.

The keystone charm currently creates two service users, one for the
service domain (for v3 authentication), and the other for the default
domain (for v2 authentication). The [service_user] config needs to
use the service domain.

Closes-Bug: #2026202
Change-Id: Ic575ac23cc0e7d4d43e26fb979baac61ed27ba6a
",git fetch https://review.opendev.org/openstack/charm-ironic-conductor refs/changes/01/887801/1 && git format-patch -1 --stdout FETCH_HEAD,['rebuild'],1,6241b061bd8131dd0ce899aa65fa7643707403ba,bug/2026202,fd27702b-0f8c-4dad-9985-393ac5228cc8,53c50d6c-1178-11ec-aec9-53d92906ceae,1,1
openstack%2Fcharm-nova-cloud-controller~887737,openstack/charm-nova-cloud-controller,master,I3a5f61c39ce1d3f663f5f5c9d9f4ac19d1fc6886,Use service_domain in [service_user] section,MERGED,2023-07-05 20:01:20.000000000,2023-07-11 11:00:28.000000000,2023-07-11 11:00:28.000000000,"[{'_account_id': 20648}, {'_account_id': 20870}, {'_account_id': 22348}]","[{'number': 1, 'created': '2023-07-05 20:01:20.000000000', 'files': ['charmhelpers/contrib/openstack/templates/wsgi-openstack-metadata.conf', 'charmhelpers/fetch/ubuntu_apt_pkg.py', 'charmhelpers/contrib/openstack/templates/section-keystone-authtoken-mitaka', 'charmhelpers/contrib/openstack/templates/section-service-user', 'charmhelpers/contrib/openstack/context.py', 'charmhelpers/contrib/openstack/cert_utils.py', 'charmhelpers/contrib/openstack/templates/wsgi-openstack-api.conf', 'charmhelpers/contrib/openstack/templates/section-keystone-authtoken'], 'web_link': 'https://opendev.org/openstack/charm-nova-cloud-controller/commit/1c1ab7658ee1b8c21e025bdc437844bc91976b3b', 'message': 'Use service_domain in [service_user] section\n\nSync from charm-helpers to update [service_user] config to use the\nservice domain.\n\nThe keystone charm currently creates two service users, one for the\nservice domain (for v3 authentication), and the other for the default\ndomain (for v2 authentication). The [service_user] config needs to\nuse the service domain.\n\nCloses-Bug: #2026202\nChange-Id: I3a5f61c39ce1d3f663f5f5c9d9f4ac19d1fc6886\n'}]",0,887737,1c1ab7658ee1b8c21e025bdc437844bc91976b3b,8,3,1,11805,,,0,"Use service_domain in [service_user] section

Sync from charm-helpers to update [service_user] config to use the
service domain.

The keystone charm currently creates two service users, one for the
service domain (for v3 authentication), and the other for the default
domain (for v2 authentication). The [service_user] config needs to
use the service domain.

Closes-Bug: #2026202
Change-Id: I3a5f61c39ce1d3f663f5f5c9d9f4ac19d1fc6886
",git fetch https://review.opendev.org/openstack/charm-nova-cloud-controller refs/changes/37/887737/1 && git format-patch -1 --stdout FETCH_HEAD,"['charmhelpers/contrib/openstack/templates/wsgi-openstack-metadata.conf', 'charmhelpers/fetch/ubuntu_apt_pkg.py', 'charmhelpers/contrib/openstack/templates/section-keystone-authtoken-mitaka', 'charmhelpers/contrib/openstack/templates/section-service-user', 'charmhelpers/contrib/openstack/context.py', 'charmhelpers/contrib/openstack/cert_utils.py', 'charmhelpers/contrib/openstack/templates/wsgi-openstack-api.conf', 'charmhelpers/contrib/openstack/templates/section-keystone-authtoken']",8,1c1ab7658ee1b8c21e025bdc437844bc91976b3b,bug/2026202,{% if admin_role -%}{% endif -%},,47,24
openstack%2Fcharm-ironic-api~887800,openstack/charm-ironic-api,master,I747859dac5533e5eb579dd9f8e23c306ba6c1388,Use service_domain in [service_user] section,MERGED,2023-07-06 12:26:47.000000000,2023-07-11 10:58:52.000000000,2023-07-11 10:58:52.000000000,"[{'_account_id': 20648}, {'_account_id': 20870}, {'_account_id': 22348}]","[{'number': 1, 'created': '2023-07-06 12:26:47.000000000', 'files': ['rebuild'], 'web_link': 'https://opendev.org/openstack/charm-ironic-api/commit/c71c8b55a7b0060071c3fd02155c11732930f149', 'message': 'Use service_domain in [service_user] section\n\nRebuild to update [service_user] config to use the service domain.\nThis was fixed in charm-helpers.\n\nThe keystone charm currently creates two service users, one for the\nservice domain (for v3 authentication), and the other for the default\ndomain (for v2 authentication). The [service_user] config needs to\nuse the service domain.\n\nCloses-Bug: #2026202\nChange-Id: I747859dac5533e5eb579dd9f8e23c306ba6c1388\n'}]",0,887800,c71c8b55a7b0060071c3fd02155c11732930f149,8,3,1,11805,,,0,"Use service_domain in [service_user] section

Rebuild to update [service_user] config to use the service domain.
This was fixed in charm-helpers.

The keystone charm currently creates two service users, one for the
service domain (for v3 authentication), and the other for the default
domain (for v2 authentication). The [service_user] config needs to
use the service domain.

Closes-Bug: #2026202
Change-Id: I747859dac5533e5eb579dd9f8e23c306ba6c1388
",git fetch https://review.opendev.org/openstack/charm-ironic-api refs/changes/00/887800/1 && git format-patch -1 --stdout FETCH_HEAD,['rebuild'],1,c71c8b55a7b0060071c3fd02155c11732930f149,bug/2026202,fd27702b-0f8c-4dad-9985-393ac5228cc8,059b8736-4fe2-4fee-af25-31d86fdf0dfc,1,1
openstack%2Fopenstack-ansible~888122,openstack/openstack-ansible,stable/rocky,I88f7f33c765933c1cd3698f6417754aab23b053e,Transition Rocky to EOL,MERGED,2023-07-11 09:29:08.000000000,2023-07-11 10:53:16.000000000,2023-07-11 10:53:16.000000000,"[{'_account_id': 22348}, {'_account_id': 25023}, {'_account_id': 32666}]","[{'number': 1, 'created': '2023-07-11 09:29:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/488c89316ff7ff532c52c4e9e5ba65df66e522ca', 'message': 'Transition Rocky to EOL\n\nChange-Id: I88f7f33c765933c1cd3698f6417754aab23b053e\n'}, {'number': 2, 'created': '2023-07-11 09:51:02.000000000', 'files': ['playbooks/defaults/repo_packages/openstack_services.yml', 'doc/source/conf.py', 'deploy-guide/source/conf.py', 'ansible-role-requirements.yml'], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/90d57f2b39dbcd45b100619dc55c4bb3aaa82fd4', 'message': 'Transition Rocky to EOL\n\nChange-Id: I88f7f33c765933c1cd3698f6417754aab23b053e\n'}]",0,888122,90d57f2b39dbcd45b100619dc55c4bb3aaa82fd4,9,3,2,28619,,,0,"Transition Rocky to EOL

Change-Id: I88f7f33c765933c1cd3698f6417754aab23b053e
",git fetch https://review.opendev.org/openstack/openstack-ansible refs/changes/22/888122/1 && git format-patch -1 --stdout FETCH_HEAD,"['playbooks/defaults/repo_packages/openstack_services.yml', 'ansible-role-requirements.yml']",2,488c89316ff7ff532c52c4e9e5ba65df66e522ca,, version: rocky-eol version: rocky-eol version: rocky-eol version: rocky-eol version: rocky-eol version: rocky-eol version: rocky-eol version: rocky-eol version: rocky-eol version: rocky-eol version: rocky-eol version: rocky-eol version: rocky-eol version: rocky-eol version: rocky-eol version: rocky-eol version: rocky-eol version: rocky-eol version: rocky-eol version: rocky-eol version: rocky-eol version: rocky-eol version: rocky-eol version: rocky-eol version: rocky-eol version: rocky-eol version: rocky-eol version: rocky-eol version: rocky-eol version: rocky-eol version: rocky-eol version: rocky-eol version: rocky-eol version: rocky-eol version: rocky-eol version: rocky-eol version: rocky-eol version: rocky-eol version: rocky-eol version: rocky-eol version: rocky-eol version: rocky-eol version: rocky-eol version: rocky-eol version: rocky-eol version: rocky-eol version: rocky-eol, version: stable/rocky version: stable/rocky version: stable/rocky version: stable/rocky version: stable/rocky version: stable/rocky version: stable/rocky version: stable/rocky version: stable/rocky version: stable/rocky version: stable/rocky version: stable/rocky version: stable/rocky version: stable/rocky version: stable/rocky version: stable/rocky version: stable/rocky version: stable/rocky version: stable/rocky version: stable/rocky version: stable/rocky version: stable/rocky version: stable/rocky version: stable/rocky version: stable/rocky version: stable/rocky version: stable/rocky version: stable/rocky version: stable/rocky version: stable/rocky version: stable/rocky version: stable/rocky version: stable/rocky version: stable/rocky version: stable/rocky version: stable/rocky version: stable/rocky version: stable/rocky version: stable/rocky version: stable/rocky version: stable/rocky version: stable/rocky version: stable/rocky version: stable/rocky version: stable/rocky version: stable/rocky version: stable/rocky,84,84
openstack%2Fcinder~852725,openstack/cinder,master,I457ed6140651c8593b3a271370560adca691eb50,Add storage_protocol to FS drivers,NEW,2022-08-10 10:29:30.000000000,2023-07-11 10:10:35.000000000,,"[{'_account_id': 4523}, {'_account_id': 5314}, {'_account_id': 22348}]","[{'number': 1, 'created': '2022-08-10 10:29:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/dbbcea8970576a05ccea4b9ea014311d9379d367', 'message': 'Add storage_protocol to FS drivers\n\nCurrently most of the File System type drivers inherit from\nRemoteFSDriver and use most of the base class methods.\nOne such method is _update_volume_stats which reports driver\ncapabilities to scheduler.\nIn the RemoteFSDriver, driver_volume_type is reported as\nstorage_protocol[1] which is not correct.\ndriver_volume_type is used in attachments to initialize\nconnection and is also reported to os-brick in the connection\ninformation dict.\nOn the other hand, storage_protocol is reported to scheduler\nand is internal to cinder (not reported to any external project).\n\nThis does not have any current impact but we need to differentiate\nbetween both the options to avoid confusion.\nThis patch adds support of storage_protocol in drivers that\ninherit from RemoteFSDriver and also modifies the RemoteFSDriver\nto report storage_protocol, if set in the driver, else fall back\nto reporting driver_volume_type as it used to.\n\n[1] https://opendev.org/openstack/cinder/src/commit/4e02f204ff50ffdf3379c5f71e653c6742be2960/cinder/volume/drivers/remotefs.py#L624\n\nChange-Id: I457ed6140651c8593b3a271370560adca691eb50\n'}, {'number': 2, 'created': '2022-08-10 10:34:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/ac060b8125a06d662da338408071a8881ed5ba09', 'message': 'Add storage_protocol to FS drivers\n\nCurrently most of the File System type drivers inherit from\nRemoteFSDriver and use most of the base class methods.\nOne such method is _update_volume_stats which reports driver\ncapabilities to scheduler.\nIn the RemoteFSDriver, driver_volume_type is reported as\nstorage_protocol[1] which is not correct.\ndriver_volume_type is used in attachments to initialize\nconnection and is also reported to os-brick in the connection\ninformation dict.\nOn the other hand, storage_protocol is reported to scheduler\nand is internal to cinder (not reported to any external project).\n\nThis does not have any current impact but we need to differentiate\nbetween both the options to avoid confusion.\nThis patch adds support of storage_protocol in drivers that\ninherit from RemoteFSDriver and also modifies the RemoteFSDriver\nto report storage_protocol, if set in the driver, else fall back\nto reporting driver_volume_type as it used to.\n\n[1] https://opendev.org/openstack/cinder/src/commit/4e02f204ff50ffdf3379c5f71e653c6742be2960/cinder/volume/drivers/remotefs.py#L624\n\nChange-Id: I457ed6140651c8593b3a271370560adca691eb50\n'}, {'number': 3, 'created': '2022-08-10 10:37:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/2e15704db3940147f0cde9086df130db42d9a421', 'message': 'Add storage_protocol to FS drivers\n\nCurrently most of the File System type drivers inherit from\nRemoteFSDriver and use most of the base class methods.\nOne such method is _update_volume_stats which reports driver\ncapabilities to scheduler.\nIn the RemoteFSDriver, driver_volume_type is reported as\nstorage_protocol[1] which is not correct.\ndriver_volume_type is used in attachments to initialize\nconnection and is also reported to os-brick in the connection\ninformation dict.\nOn the other hand, storage_protocol is reported to scheduler\nand is internal to cinder (not reported to any external project).\n\nThis does not have any current impact but we need to differentiate\nbetween both the options to avoid confusion.\nThis patch adds support of storage_protocol in drivers that\ninherit from RemoteFSDriver and also modifies the RemoteFSDriver\nto report storage_protocol, if set in the driver, else fall back\nto reporting driver_volume_type as it used to.\n\n[1] https://opendev.org/openstack/cinder/src/commit/4e02f204ff50ffdf3379c5f71e653c6742be2960/cinder/volume/drivers/remotefs.py#L624\n\nChange-Id: I457ed6140651c8593b3a271370560adca691eb50\n'}, {'number': 4, 'created': '2022-11-07 16:01:02.000000000', 'files': ['cinder/volume/drivers/windows/smbfs.py', 'cinder/volume/drivers/vzstorage.py', 'cinder/volume/drivers/quobyte.py', 'cinder/volume/drivers/nfs.py', 'cinder/common/constants.py', 'cinder/volume/drivers/remotefs.py'], 'web_link': 'https://opendev.org/openstack/cinder/commit/98afb031736d9082eeb2cbee6ff6464baf8f2738', 'message': 'Add storage_protocol to FS drivers\n\nCurrently most of the File System type drivers inherit from\nRemoteFSDriver and use most of the base class methods.\nOne such method is _update_volume_stats which reports driver\ncapabilities to scheduler.\nIn the RemoteFSDriver, driver_volume_type is reported as\nstorage_protocol[1] which is not correct.\ndriver_volume_type is used in attachments to initialize\nconnection and is also reported to os-brick in the connection\ninformation dict.\nOn the other hand, storage_protocol is reported to scheduler\nand is internal to cinder (not reported to any external project).\n\nThis does not have any current impact but we need to differentiate\nbetween both the options to avoid confusion.\nThis patch adds support of storage_protocol in drivers that\ninherit from RemoteFSDriver and also modifies the RemoteFSDriver\nto report storage_protocol, if set in the driver, else fall back\nto reporting driver_volume_type as it used to.\n\n[1] https://opendev.org/openstack/cinder/src/commit/4e02f204ff50ffdf3379c5f71e653c6742be2960/cinder/volume/drivers/remotefs.py#L624\n\nChange-Id: I457ed6140651c8593b3a271370560adca691eb50\n'}]",9,852725,98afb031736d9082eeb2cbee6ff6464baf8f2738,59,3,4,27615,,,0,"Add storage_protocol to FS drivers

Currently most of the File System type drivers inherit from
RemoteFSDriver and use most of the base class methods.
One such method is _update_volume_stats which reports driver
capabilities to scheduler.
In the RemoteFSDriver, driver_volume_type is reported as
storage_protocol[1] which is not correct.
driver_volume_type is used in attachments to initialize
connection and is also reported to os-brick in the connection
information dict.
On the other hand, storage_protocol is reported to scheduler
and is internal to cinder (not reported to any external project).

This does not have any current impact but we need to differentiate
between both the options to avoid confusion.
This patch adds support of storage_protocol in drivers that
inherit from RemoteFSDriver and also modifies the RemoteFSDriver
to report storage_protocol, if set in the driver, else fall back
to reporting driver_volume_type as it used to.

[1] https://opendev.org/openstack/cinder/src/commit/4e02f204ff50ffdf3379c5f71e653c6742be2960/cinder/volume/drivers/remotefs.py#L624

Change-Id: I457ed6140651c8593b3a271370560adca691eb50
",git fetch https://review.opendev.org/openstack/cinder refs/changes/25/852725/1 && git format-patch -1 --stdout FETCH_HEAD,"['cinder/volume/drivers/windows/smbfs.py', 'cinder/volume/drivers/vzstorage.py', 'cinder/volume/drivers/quobyte.py', 'cinder/volume/drivers/nfs.py', 'cinder/volume/drivers/remotefs.py']",5,dbbcea8970576a05ccea4b9ea014311d9379d367,852725, storage_protocol: Optional[str] = None data['storage_protocol'] = (self.storage_protocol or self.driver_volume_type), data['storage_protocol'] = self.driver_volume_type,11,1
openstack%2Fironic~864802,openstack/ironic,master,I37faecdd95862a58b61e39b1c9368904ad5570ea,Use association_proxy for node chassis_uuid,NEW,2022-11-17 00:11:55.000000000,2023-07-11 09:48:07.000000000,,"[{'_account_id': 22348}, {'_account_id': 24245}]","[{'number': 1, 'created': '2022-11-17 00:11:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/da3cc093df2fccd2f090af58e7ac15d868ae4d1d', 'message': ""Use association_proxy for node chassis_uuid\n\nThis change adds 'chassis_uuid' to:\n  ironic.objects.node.Node\n\n'chassis_uuid' is a relationship using association_proxy\nin models.Node. Using the association_proxy removes the\nneed to do the node lookup to populate chassis uuid for\nnodes in the api controller.\n\nNOTE:\n  On node create a read is added this ensures chassis_uuid\n  is loaded and solves the DetachedInstanceError which is\n  otherwise raised.\n\nBumps Node object version to 1.37\n\nChange-Id: I37faecdd95862a58b61e39b1c9368904ad5570ea\n""}, {'number': 2, 'created': '2022-11-17 18:00:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/d80256c826bdcdf245553e15cd75a172727d05b8', 'message': ""Use association_proxy for node chassis_uuid\n\nThis change adds 'chassis_uuid' to:\n  ironic.objects.node.Node\n\n'chassis_uuid' is a relationship using association_proxy\nin models.Node. Using the association_proxy removes the\nneed to do the node lookup to populate chassis uuid for\nnodes in the api controller.\n\nNOTE:\n  On node create a read is added this ensures chassis_uuid\n  is loaded and solves the DetachedInstanceError which is\n  otherwise raised.\n\nBumps Node object version to 1.37\n\nChange-Id: I37faecdd95862a58b61e39b1c9368904ad5570ea\n""}, {'number': 3, 'created': '2022-11-17 19:13:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/0a7380a3bbd58af9d6456a7e46be7091bec97f60', 'message': ""Use association_proxy for node chassis_uuid\n\nThis change adds 'chassis_uuid' to:\n  ironic.objects.node.Node\n\n'chassis_uuid' is a relationship using association_proxy\nin models.Node. Using the association_proxy removes the\nneed to do the node lookup to populate chassis uuid for\nnodes in the api controller.\n\nNOTE:\n  On node create a read is added this ensures chassis_uuid\n  is loaded and solves the DetachedInstanceError which is\n  otherwise raised.\n\nBumps Node object version to 1.37\n\nChange-Id: I37faecdd95862a58b61e39b1c9368904ad5570ea\n""}, {'number': 4, 'created': '2022-11-17 23:57:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/795687adc689926775db5cda7ca669a2e432ac0e', 'message': ""Use association_proxy for node chassis_uuid\n\nThis change adds 'chassis_uuid' to:\n  ironic.objects.node.Node\n\n'chassis_uuid' is a relationship using association_proxy\nin models.Node. Using the association_proxy removes the\nneed to do the node lookup to populate chassis uuid for\nnodes in the api controller.\n\nNOTE:\n  On node create a read is added this ensures chassis_uuid\n  is loaded and solves the DetachedInstanceError which is\n  otherwise raised.\n\nBumps Node object version to 1.37\n\nChange-Id: I37faecdd95862a58b61e39b1c9368904ad5570ea\n""}, {'number': 5, 'created': '2022-11-29 13:45:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/8b52de51f3910217ff8abcfa66153026f965e58d', 'message': ""Use association_proxy for node chassis_uuid\n\nThis change adds 'chassis_uuid' to:\n  ironic.objects.node.Node\n\n'chassis_uuid' is a relationship using association_proxy\nin models.Node. Using the association_proxy removes the\nneed to do the node lookup to populate chassis uuid for\nnodes in the api controller.\n\nNOTE:\n  On node create a read is added this ensures chassis_uuid\n  is loaded and solves the DetachedInstanceError which is\n  otherwise raised.\n\nBumps Node object version to 1.37\n\nChange-Id: I37faecdd95862a58b61e39b1c9368904ad5570ea\n""}, {'number': 6, 'created': '2022-12-14 08:15:29.000000000', 'files': ['ironic/objects/node.py', 'ironic/tests/unit/db/utils.py', 'ironic/common/release_mappings.py', 'ironic/tests/unit/api/controllers/v1/test_node.py', 'ironic/tests/unit/objects/test_objects.py', 'ironic/db/sqlalchemy/models.py', 'ironic/api/controllers/v1/node.py', 'ironic/tests/unit/objects/test_node.py'], 'web_link': 'https://opendev.org/openstack/ironic/commit/d5c5683d4a547c900e780cdd88a4824714bf7da5', 'message': ""Use association_proxy for node chassis_uuid\n\nThis change adds 'chassis_uuid' to:\n  ironic.objects.node.Node\n\n'chassis_uuid' is a relationship using association_proxy\nin models.Node. Using the association_proxy removes the\nneed to do the node lookup to populate chassis uuid for\nnodes in the api controller.\n\nNOTE:\n  On node create a read is added this ensures chassis_uuid\n  is loaded and solves the DetachedInstanceError which is\n  otherwise raised.\n\nBumps Node object version to 1.37\n\nChange-Id: I37faecdd95862a58b61e39b1c9368904ad5570ea\n""}]",7,864802,d5c5683d4a547c900e780cdd88a4824714bf7da5,38,2,6,24245,,,0,"Use association_proxy for node chassis_uuid

This change adds 'chassis_uuid' to:
  ironic.objects.node.Node

'chassis_uuid' is a relationship using association_proxy
in models.Node. Using the association_proxy removes the
need to do the node lookup to populate chassis uuid for
nodes in the api controller.

NOTE:
  On node create a read is added this ensures chassis_uuid
  is loaded and solves the DetachedInstanceError which is
  otherwise raised.

Bumps Node object version to 1.37

Change-Id: I37faecdd95862a58b61e39b1c9368904ad5570ea
",git fetch https://review.opendev.org/openstack/ironic refs/changes/02/864802/1 && git format-patch -1 --stdout FETCH_HEAD,"['ironic/objects/node.py', 'ironic/tests/unit/db/utils.py', 'ironic/common/release_mappings.py', 'ironic/tests/unit/api/controllers/v1/test_node.py', 'ironic/tests/unit/objects/test_objects.py', 'ironic/db/sqlalchemy/models.py', 'ironic/api/controllers/v1/node.py', 'ironic/tests/unit/objects/test_node.py']",8,da3cc093df2fccd2f090af58e7ac15d868ae4d1d,sql_joins," with mock.patch.object(self.dbapi, 'get_node_by_id', autospec=True) as mock_get_node: test_node = db_utils.get_test_node() mock_create_node.return_value = test_node mock_get_node.return_value = test_node node.create() args, _kwargs = mock_create_node.call_args self.assertEqual(objects.Node.VERSION, args[0]['version']) self.assertEqual(1, mock_create_node.call_count)"," mock_create_node.return_value = db_utils.get_test_node() node.create() args, _kwargs = mock_create_node.call_args self.assertEqual(objects.Node.VERSION, args[0]['version']) self.assertEqual(1, mock_create_node.call_count)",35,64
openstack%2Fcharm-openstack-hypervisor~888116,openstack/charm-openstack-hypervisor,main,I428a4c275203641eaaa7cdb83c8f120503bcfd92,Use identity internal endpoint,MERGED,2023-07-11 08:18:53.000000000,2023-07-11 09:24:51.000000000,2023-07-11 09:10:19.000000000,"[{'_account_id': 12549}, {'_account_id': 22348}]","[{'number': 1, 'created': '2023-07-11 08:18:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-openstack-hypervisor/commit/8f52bce3fa8121162945f2c822f631bcae1ac842', 'message': 'Use identity internal endpoint\n\nThe charm configured the snap with the public endpoint while it should\nbe internal.\n\nChange-Id: I428a4c275203641eaaa7cdb83c8f120503bcfd92\n'}, {'number': 2, 'created': '2023-07-11 08:45:16.000000000', 'files': ['src/charm.py', 'tests/unit/test_charm.py'], 'web_link': 'https://opendev.org/openstack/charm-openstack-hypervisor/commit/6f6f7cdca620bf6a2ec4e8f984d8638c70e2676d', 'message': 'Use identity internal endpoint\n\nThe charm configured the snap with the public endpoint while it should\nbe internal.\n\nChange-Id: I428a4c275203641eaaa7cdb83c8f120503bcfd92\n'}]",1,888116,6f6f7cdca620bf6a2ec4e8f984d8638c70e2676d,9,2,2,35761,,,0,"Use identity internal endpoint

The charm configured the snap with the public endpoint while it should
be internal.

Change-Id: I428a4c275203641eaaa7cdb83c8f120503bcfd92
",git fetch https://review.opendev.org/openstack/charm-openstack-hypervisor refs/changes/16/888116/1 && git format-patch -1 --stdout FETCH_HEAD,['src/charm.py'],1,8f52bce3fa8121162945f2c822f631bcae1ac842,fix/identity-endpoint," ""identity.auth-url"": contexts.identity_credentials.internal_endpoint,"," ""identity.auth-url"": contexts.identity_credentials.public_endpoint,",1,1
openstack%2Fironic~888058,openstack/ironic,master,Iacfd1ab677c612525601afcaeee5e5b067206ff3,CI: Use focal dnsmasq,MERGED,2023-07-10 16:40:31.000000000,2023-07-11 09:10:46.000000000,2023-07-11 09:08:41.000000000,"[{'_account_id': 10239}, {'_account_id': 22348}, {'_account_id': 23851}]","[{'number': 1, 'created': '2023-07-10 16:40:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/c00c5144d7d82c3157fdaa44885d348bdefd3195', 'message': 'CI: Use focal dnsmasq\n\nInvestigation of our standalone test job issues, where jobs would\nfail, hosts not get DHCP updates, and ultimately IPXE would\nfail prior to getting a valid or the expected response,\nrevealed the discovery that dnsmasq was crashing often when\nthe port updates were going through, ultimately preventing\nthe mutli-scenario test jobs from running as the standalone\njobs represent a number of different scenarios which are\nexecuted across a pool of test machines.\n\nIn this case, the path forward appears to be to downgrade\ndnsmasq to stablize our CI and allow us to otherwise upgrade.\n\nThis patch adds the focal updates as a package source,\nand installs the dnsmasq package.\n\nRelated-Bug: #2026757\nChange-Id: Iacfd1ab677c612525601afcaeee5e5b067206ff3\n'}, {'number': 2, 'created': '2023-07-10 17:48:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/5d2267974618639088c60b87055b7439bb9a8eb1', 'message': 'CI: Use focal dnsmasq\n\nInvestigation of our standalone test job issues, where jobs would\nfail, hosts not get DHCP updates, and ultimately IPXE would\nfail prior to getting a valid or the expected response,\nrevealed the discovery that dnsmasq was crashing often when\nthe port updates were going through, ultimately preventing\nthe mutli-scenario test jobs from running as the standalone\njobs represent a number of different scenarios which are\nexecuted across a pool of test machines.\n\nIn this case, the path forward appears to be to downgrade\ndnsmasq to stablize our CI and allow us to otherwise upgrade.\n\nThis patch adds the focal updates as a package source,\nand installs the dnsmasq package.\n\nRelated-Bug: #2026757\nChange-Id: Iacfd1ab677c612525601afcaeee5e5b067206ff3\n'}, {'number': 3, 'created': '2023-07-10 18:05:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/55749c7156984ed4e773ae4e75d30c194972fcff', 'message': 'CI: Use focal dnsmasq\n\nInvestigation of our standalone test job issues, where jobs would\nfail, hosts not get DHCP updates, and ultimately IPXE would\nfail prior to getting a valid or the expected response,\nrevealed the discovery that dnsmasq was crashing often when\nthe port updates were going through, ultimately preventing\nthe mutli-scenario test jobs from running as the standalone\njobs represent a number of different scenarios which are\nexecuted across a pool of test machines.\n\nIn this case, the path forward appears to be to downgrade\ndnsmasq to stablize our CI and allow us to otherwise upgrade.\n\nThis patch adds the focal updates as a package source,\nand installs the dnsmasq package.\n\nRelated-Bug: #2026757\nChange-Id: Iacfd1ab677c612525601afcaeee5e5b067206ff3\n'}, {'number': 4, 'created': '2023-07-10 18:22:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/d3d163e0ea63da8db1c38c442f954ac26106b5a1', 'message': 'CI: Use focal dnsmasq\n\nInvestigation of our standalone test job issues, where jobs would\nfail, hosts not get DHCP updates, and ultimately IPXE would\nfail prior to getting a valid or the expected response,\nrevealed the discovery that dnsmasq was crashing often when\nthe port updates were going through, ultimately preventing\nthe mutli-scenario test jobs from running as the standalone\njobs represent a number of different scenarios which are\nexecuted across a pool of test machines.\n\nIn this case, the path forward appears to be to downgrade\ndnsmasq to stablize our CI and allow us to otherwise upgrade.\n\nThis patch adds the focal updates as a package source,\nand installs the dnsmasq package.\n\nRelated-Bug: #2026757\nChange-Id: Iacfd1ab677c612525601afcaeee5e5b067206ff3\n'}, {'number': 5, 'created': '2023-07-10 18:35:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/50626562917210bce366509e57bfe6955c87936c', 'message': 'CI: Use focal dnsmasq\n\nInvestigation of our standalone test job issues, where jobs would\nfail, hosts not get DHCP updates, and ultimately IPXE would\nfail prior to getting a valid or the expected response,\nrevealed the discovery that dnsmasq was crashing often when\nthe port updates were going through, ultimately preventing\nthe mutli-scenario test jobs from running as the standalone\njobs represent a number of different scenarios which are\nexecuted across a pool of test machines.\n\nIn this case, the path forward appears to be to downgrade\ndnsmasq to stablize our CI and allow us to otherwise upgrade.\n\nThis patch adds the focal updates as a package source,\nand installs the dnsmasq package.\n\nRelated-Bug: #2026757\nChange-Id: Iacfd1ab677c612525601afcaeee5e5b067206ff3\n'}, {'number': 6, 'created': '2023-07-10 19:57:24.000000000', 'files': ['zuul.d/ironic-jobs.yaml', 'devstack/lib/ironic', 'devstack/plugin.sh'], 'web_link': 'https://opendev.org/openstack/ironic/commit/0a11855d3fe86545a749aed03fb937cabc389916', 'message': 'CI: Use focal dnsmasq\n\nInvestigation of our standalone test job issues, where jobs would\nfail, hosts not get DHCP updates, and ultimately IPXE would\nfail prior to getting a valid or the expected response,\nrevealed the discovery that dnsmasq was crashing often when\nthe port updates were going through, ultimately preventing\nthe mutli-scenario test jobs from running as the standalone\njobs represent a number of different scenarios which are\nexecuted across a pool of test machines.\n\nIn this case, the path forward appears to be to downgrade\ndnsmasq to stablize our CI and allow us to otherwise upgrade.\n\nThis patch adds the focal updates as a package source,\nand installs the dnsmasq package.\n\nRelated-Bug: #2026757\nChange-Id: Iacfd1ab677c612525601afcaeee5e5b067206ff3\n'}]",3,888058,0a11855d3fe86545a749aed03fb937cabc389916,33,3,6,11655,,,0,"CI: Use focal dnsmasq

Investigation of our standalone test job issues, where jobs would
fail, hosts not get DHCP updates, and ultimately IPXE would
fail prior to getting a valid or the expected response,
revealed the discovery that dnsmasq was crashing often when
the port updates were going through, ultimately preventing
the mutli-scenario test jobs from running as the standalone
jobs represent a number of different scenarios which are
executed across a pool of test machines.

In this case, the path forward appears to be to downgrade
dnsmasq to stablize our CI and allow us to otherwise upgrade.

This patch adds the focal updates as a package source,
and installs the dnsmasq package.

Related-Bug: #2026757
Change-Id: Iacfd1ab677c612525601afcaeee5e5b067206ff3
",git fetch https://review.opendev.org/openstack/ironic refs/changes/58/888058/1 && git format-patch -1 --stdout FETCH_HEAD,"['zuul.d/ironic-jobs.yaml', 'devstack/lib/ironic', 'devstack/plugin.sh']",3,c00c5144d7d82c3157fdaa44885d348bdefd3195,, downgrade_dnsmasq,,10,2
openstack%2Fneutron~887583,openstack/neutron,stable/wallaby,I1fb6a9ff94376ab5f695d311b6fa8034d73cf556,[OVN] Expose chassis hosting information in LSP,MERGED,2023-07-04 08:42:12.000000000,2023-07-11 08:39:58.000000000,2023-07-11 08:37:34.000000000,"[{'_account_id': 16688}, {'_account_id': 21798}, {'_account_id': 22348}, {'_account_id': 23567}]","[{'number': 1, 'created': '2023-07-04 08:42:12.000000000', 'files': ['neutron/plugins/ml2/drivers/ovn/mech_driver/ovsdb/ovn_client.py', 'neutron/tests/unit/plugins/ml2/drivers/ovn/mech_driver/test_mech_driver.py', 'neutron/common/ovn/constants.py', 'neutron/plugins/ml2/drivers/ovn/mech_driver/mech_driver.py', 'neutron/tests/unit/plugins/ml2/drivers/ovn/mech_driver/ovsdb/test_ovn_client.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/384fe4bb8e436bd5b7598697f2f62c3032d825ec', 'message': '[OVN] Expose chassis hosting information in LSP\n\nExpose chassis hosting information via LSP\'s external_ids. This allows\nfor projects such as ovn-bgp-agent NB driver that only connects to the\nNB database to consume such information (avoiding more connections to\nthe SB database).\n\nAlso stop populating the ""requested-chassis"" options for ports of the\ntype virtual because it\'s ignored by OVN.\n\nSee LP #2020058 for more information.\n\nConflicts:\n  neutron/common/ovn/constants.py\n  neutron/plugins/ml2/drivers/ovn/mech_driver/ovsdb/ovn_client.py\n  neutron/tests/unit/plugins/ml2/drivers/ovn/mech_driver/ovsdb/test_ovn_client.py\n\nCloses-Bug: #2020058\nChange-Id: I1fb6a9ff94376ab5f695d311b6fa8034d73cf556\nSigned-off-by: Lucas Alvares Gomes <lucasagomes@gmail.com>\n(cherry picked from commit 28926957d691c8b0897c71fee59a888783d15974)\n'}]",6,887583,384fe4bb8e436bd5b7598697f2f62c3032d825ec,20,4,1,6773,,,0,"[OVN] Expose chassis hosting information in LSP

Expose chassis hosting information via LSP's external_ids. This allows
for projects such as ovn-bgp-agent NB driver that only connects to the
NB database to consume such information (avoiding more connections to
the SB database).

Also stop populating the ""requested-chassis"" options for ports of the
type virtual because it's ignored by OVN.

See LP #2020058 for more information.

Conflicts:
  neutron/common/ovn/constants.py
  neutron/plugins/ml2/drivers/ovn/mech_driver/ovsdb/ovn_client.py
  neutron/tests/unit/plugins/ml2/drivers/ovn/mech_driver/ovsdb/test_ovn_client.py

Closes-Bug: #2020058
Change-Id: I1fb6a9ff94376ab5f695d311b6fa8034d73cf556
Signed-off-by: Lucas Alvares Gomes <lucasagomes@gmail.com>
(cherry picked from commit 28926957d691c8b0897c71fee59a888783d15974)
",git fetch https://review.opendev.org/openstack/neutron refs/changes/83/887583/1 && git format-patch -1 --stdout FETCH_HEAD,"['neutron/plugins/ml2/drivers/ovn/mech_driver/ovsdb/ovn_client.py', 'neutron/tests/unit/plugins/ml2/drivers/ovn/mech_driver/test_mech_driver.py', 'neutron/common/ovn/constants.py', 'neutron/plugins/ml2/drivers/ovn/mech_driver/mech_driver.py', 'neutron/tests/unit/plugins/ml2/drivers/ovn/mech_driver/ovsdb/test_ovn_client.py']",5,384fe4bb8e436bd5b7598697f2f62c3032d825ec,,"class TestOVNClient(TestOVNClientBase): def setUp(self): super(TestOVNClient, self).setUp() self.get_plugin = mock.patch( 'neutron_lib.plugins.directory.get_plugin').start() def test_update_lsp_host_info_up(self): context = mock.MagicMock() host_id = 'fake-binding-host-id' port_id = 'fake-port-id' db_port = mock.Mock( id=port_id, port_bindings=[mock.Mock(host=host_id)]) self.ovn_client.update_lsp_host_info(context, db_port) self.nb_idl.db_set.assert_called_once_with( 'Logical_Switch_Port', port_id, ('external_ids', {constants.OVN_HOST_ID_EXT_ID_KEY: host_id})) def test_update_lsp_host_info_down(self): context = mock.MagicMock() port_id = 'fake-port-id' db_port = mock.Mock(id=port_id) self.ovn_client.update_lsp_host_info(context, db_port, up=False) self.nb_idl.db_remove.assert_called_once_with( 'Logical_Switch_Port', port_id, 'external_ids', constants.OVN_HOST_ID_EXT_ID_KEY, if_exists=True) ",,81,3
openstack%2Fneutron~887627,openstack/neutron,stable/wallaby,I89db15dd1b629bc963f3b63926391a4a02cbedf7,Ensure traffic is not centralized if DVR is enabled,MERGED,2023-07-05 05:33:19.000000000,2023-07-11 08:38:58.000000000,2023-07-11 08:37:30.000000000,"[{'_account_id': 16688}, {'_account_id': 21798}, {'_account_id': 22348}, {'_account_id': 32029}]","[{'number': 1, 'created': '2023-07-05 05:33:19.000000000', 'files': ['neutron/tests/unit/plugins/ml2/drivers/ovn/mech_driver/test_mech_driver.py', 'releasenotes/notes/dvr-external-mac-934409413e515eb2.yaml', 'neutron/plugins/ml2/drivers/ovn/mech_driver/mech_driver.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/ec94cb4b43f953f381e67c1b1d3fa2101e842945', 'message': 'Ensure traffic is not centralized if DVR is enabled\n\nThere is no need to clear the external_mac if DVR is enabled, not\neven when the port is down. This patch ensures the external_mac is\nonly deleted when DVR is not enabled.\n\nWithout this patch, if a VM with a floating IP gets deleted, and\nDVR is enabled, during some time the traffic gets (wrongly)\ncentralized while it should not. And it is also generating more\nload on the OVN side unnecesarily.\n\nCloses-Bug: #2025264\n\nChange-Id: I89db15dd1b629bc963f3b63926391a4a02cbedf7\n(cherry picked from commit 0090572b93d96348778c724194c26a976a9f8757)\n'}]",8,887627,ec94cb4b43f953f381e67c1b1d3fa2101e842945,31,4,1,23567,,,0,"Ensure traffic is not centralized if DVR is enabled

There is no need to clear the external_mac if DVR is enabled, not
even when the port is down. This patch ensures the external_mac is
only deleted when DVR is not enabled.

Without this patch, if a VM with a floating IP gets deleted, and
DVR is enabled, during some time the traffic gets (wrongly)
centralized while it should not. And it is also generating more
load on the OVN side unnecesarily.

Closes-Bug: #2025264

Change-Id: I89db15dd1b629bc963f3b63926391a4a02cbedf7
(cherry picked from commit 0090572b93d96348778c724194c26a976a9f8757)
",git fetch https://review.opendev.org/openstack/neutron refs/changes/27/887627/1 && git format-patch -1 --stdout FETCH_HEAD,"['neutron/tests/unit/plugins/ml2/drivers/ovn/mech_driver/test_mech_driver.py', 'releasenotes/notes/dvr-external-mac-934409413e515eb2.yaml', 'neutron/plugins/ml2/drivers/ovn/mech_driver/mech_driver.py']",3,ec94cb4b43f953f381e67c1b1d3fa2101e842945,," def _update_dnat_entry_if_needed(self, port_id): if ovn_conf.is_ovn_distributed_floating_ip(): mac = nat['external_ids'].get(ovn_const.OVN_FIP_EXT_MAC_KEY) if mac and nat['external_mac'] != mac: self._update_dnat_entry_if_needed(port_id)"," def _update_dnat_entry_if_needed(self, port_id, up=True): if up and ovn_conf.is_ovn_distributed_floating_ip(): mac = nat['external_ids'][ovn_const.OVN_FIP_EXT_MAC_KEY] if nat['external_mac'] != mac: self._update_dnat_entry_if_needed(port_id, False)",28,15
openstack%2Ftrove~887753,openstack/trove,master,I66408c9e65f07c3c96cabb1f7f55a312f6dc9f36,Prevent docker from manipulating iptables,MERGED,2023-07-06 06:58:36.000000000,2023-07-11 08:37:15.000000000,2023-07-11 08:36:16.000000000,"[{'_account_id': 22348}, {'_account_id': 26285}]","[{'number': 1, 'created': '2023-07-06 06:58:36.000000000', 'files': ['integration/scripts/trovestack', 'devstack/files/debs/trove', 'devstack/files/rpms/trove', 'devstack/plugin.sh'], 'web_link': 'https://opendev.org/openstack/trove/commit/caf06bc4f7e1e06913509c499531ff435f4b807a', 'message': 'Prevent docker from manipulating iptables\n\nby default, Docker sets the policy for the FORWARD chain to DROP.\nthis behavior will block our public network connectivity.\n\nfor more details: https://docs.docker.com/network/packet-filtering-firewalls/#docker-on-a-router\n\nChange-Id: I66408c9e65f07c3c96cabb1f7f55a312f6dc9f36\n'}]",0,887753,caf06bc4f7e1e06913509c499531ff435f4b807a,8,2,1,26285,,,0,"Prevent docker from manipulating iptables

by default, Docker sets the policy for the FORWARD chain to DROP.
this behavior will block our public network connectivity.

for more details: https://docs.docker.com/network/packet-filtering-firewalls/#docker-on-a-router

Change-Id: I66408c9e65f07c3c96cabb1f7f55a312f6dc9f36
",git fetch https://review.opendev.org/openstack/trove refs/changes/53/887753/1 && git format-patch -1 --stdout FETCH_HEAD,"['integration/scripts/trovestack', 'devstack/files/debs/trove', 'devstack/files/rpms/trove', 'devstack/plugin.sh']",4,caf06bc4f7e1e06913509c499531ff435f4b807a,prevent-docker-manipulate-iptables, # install docker on the host. $DEST/trove/integration/scripts/trovestack install-docker,,25,3
openstack%2Ftacker~887747,openstack/tacker,master,Ic107d78a298c6f10932936700a3d7a33887af5e4,Fix cannot get namespace when executing DB Sync,MERGED,2023-07-06 02:38:12.000000000,2023-07-11 08:25:48.000000000,2023-07-11 08:24:22.000000000,"[{'_account_id': 17255}, {'_account_id': 22348}, {'_account_id': 25701}, {'_account_id': 31857}, {'_account_id': 32707}, {'_account_id': 34712}]","[{'number': 1, 'created': '2023-07-06 02:38:12.000000000', 'files': ['tacker/sol_refactored/infra_drivers/kubernetes/kubernetes_common.py'], 'web_link': 'https://opendev.org/openstack/tacker/commit/3416148ca6c569607c7b59aea260d0af0eb03f95', 'message': 'Fix cannot get namespace when executing DB Sync\n\nWhen DB sync is executed, the namespace of the vnf instance must be\nobtained. The current code gets the namespace in the wrong place.\nThis patch fixes the bug to get namespace from correct place.\n\nCloses-Bug: #2025007\nChange-Id: Ic107d78a298c6f10932936700a3d7a33887af5e4\n'}]",1,887747,3416148ca6c569607c7b59aea260d0af0eb03f95,11,6,1,34996,,,0,"Fix cannot get namespace when executing DB Sync

When DB sync is executed, the namespace of the vnf instance must be
obtained. The current code gets the namespace in the wrong place.
This patch fixes the bug to get namespace from correct place.

Closes-Bug: #2025007
Change-Id: Ic107d78a298c6f10932936700a3d7a33887af5e4
",git fetch https://review.opendev.org/openstack/tacker refs/changes/47/887747/1 && git format-patch -1 --stdout FETCH_HEAD,['tacker/sol_refactored/infra_drivers/kubernetes/kubernetes_common.py'],1,3416148ca6c569607c7b59aea260d0af0eb03f95,bug/2025007, namespace = vnf_instance.instantiatedVnfInfo.metadata.get('namespace'), namespace = vnf_instance.metadata.get('namespace'),1,1
openstack%2Fironic~888112,openstack/ironic,master,I256b8637dc54fdd407b9942724d400b664f2f86b,CI: move snmp pxe job to jammy,NEW,2023-07-11 05:49:14.000000000,2023-07-11 07:45:38.000000000,,[{'_account_id': 22348}],"[{'number': 1, 'created': '2023-07-11 05:49:14.000000000', 'files': ['zuul.d/ironic-jobs.yaml'], 'web_link': 'https://opendev.org/openstack/ironic/commit/328cb71a55c38047b04af6fe36f333d4ad173586', 'message': 'CI: move snmp pxe job to jammy\n\nChange-Id: I256b8637dc54fdd407b9942724d400b664f2f86b\n'}]",0,888112,328cb71a55c38047b04af6fe36f333d4ad173586,4,1,1,23851,,,0,"CI: move snmp pxe job to jammy

Change-Id: I256b8637dc54fdd407b9942724d400b664f2f86b
",git fetch https://review.opendev.org/openstack/ironic refs/changes/12/888112/1 && git format-patch -1 --stdout FETCH_HEAD,['zuul.d/ironic-jobs.yaml'],1,328cb71a55c38047b04af6fe36f333d4ad173586,,,# NOTE(rpittau): the snmp job fails on ubuntu jammy so we pin it to # ubuntu focal for the time being. nodeset: openstack-single-node-focal,0,3
openstack%2Fhorizon~887548,openstack/horizon,master,I9b8a5e8abe734e7fd99aa0066ede0377e34fbf44,Bump XStatic-JQuery to make it work with jquery-migrate,MERGED,2023-07-04 06:49:20.000000000,2023-07-11 06:03:32.000000000,2023-07-11 06:01:44.000000000,"[{'_account_id': 8648}, {'_account_id': 22348}, {'_account_id': 29313}]","[{'number': 1, 'created': '2023-07-04 06:49:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/dea2258168e1bfd4ef7730e18d388d73937e4152', 'message': 'Pin XStatic-JQuery-Migrate==1.2.1.2 until we upgrade jquery\n\nThe jquery-migrate 3 requires newer jquery than we have.\n\nChange-Id: I9b8a5e8abe734e7fd99aa0066ede0377e34fbf44\n'}, {'number': 2, 'created': '2023-07-04 06:57:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/8017c4f785eea05888adf77e95d75e9f53d2b1c9', 'message': 'Pin XStatic-JQuery-Migrate==1.2.1.2 until we upgrade jquery\n\nThe jquery-migrate 3 requires newer jquery than we have.\n\nAlso added all the other fixes for integration tests to see if that\nresolves our problems.\n\nChange-Id: I9b8a5e8abe734e7fd99aa0066ede0377e34fbf44\n'}, {'number': 3, 'created': '2023-07-04 08:48:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/879bc966a9af06161b0d4d234b4660a0e87faa29', 'message': 'Pin XStatic-JQuery-Migrate==1.2.1.2 until we upgrade jquery\n\nThe jquery-migrate 3 requires newer jquery than we have.\n\nAlso added all the other fixes for integration tests to see if that\nresolves our problems.\n\nChange-Id: I9b8a5e8abe734e7fd99aa0066ede0377e34fbf44\n'}, {'number': 4, 'created': '2023-07-04 11:28:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/012d1bcfa55cbfaf13f7f0a1b0aec6f7dad2d2d6', 'message': 'Pin XStatic-JQuery==2.2.4.1 to make it work with jquery-migrate\n\nThe jquery-migrate 3 requires newer jquery than we have.\n\nAlso added all the other fixes for integration tests to see if that\nresolves our problems.\n\nChange-Id: I9b8a5e8abe734e7fd99aa0066ede0377e34fbf44\n'}, {'number': 5, 'created': '2023-07-04 14:06:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/ed82bc96c3e56e4c0fa47cd0fb72e5d1a4b15c17', 'message': 'Pin XStatic-JQuery==2.2.4.1 to make it work with jquery-migrate\n\nThe jquery-migrate 3 requires newer jquery than we have.\n\nAlso added all the other fixes for integration tests to see if that\nresolves our problems.\n\nThis needs https://review.opendev.org/c/openstack/requirements/+/887607\nmerged first.\n\nChange-Id: I9b8a5e8abe734e7fd99aa0066ede0377e34fbf44\n'}, {'number': 6, 'created': '2023-07-07 09:15:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/7feacccf960a4a63d226e1dba349d684e60fd126', 'message': 'Pin XStatic-JQuery==2.2.4.1 to make it work with jquery-migrate\n\nThe jquery-migrate 3 requires newer jquery than we have.\n\nAlso added all the other fixes for integration tests to see if that\nresolves our problems.\n\nThis needs https://review.opendev.org/c/openstack/requirements/+/887607\nmerged first.\n\nChange-Id: I9b8a5e8abe734e7fd99aa0066ede0377e34fbf44\n'}, {'number': 7, 'created': '2023-07-07 09:53:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/d10d872b4554092f84e524db1cf7ccf16a3bebdf', 'message': 'Pin XStatic-JQuery==2.2.4.1 to make it work with jquery-migrate\n\nThe jquery-migrate 3 requires newer jquery than we have.\n\nAlso added all the other fixes for integration tests to see if that\nresolves our problems.\n\nThis needs https://review.opendev.org/c/openstack/requirements/+/887607\nmerged first.\n\nChange-Id: I9b8a5e8abe734e7fd99aa0066ede0377e34fbf44\n'}, {'number': 8, 'created': '2023-07-10 07:30:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/af117548620b698e1b3059c58712e59b88f4d293', 'message': 'Bump XStatic-JQuery to make it work with jquery-migrate\n\nThe jquery-migrate 3 requires newer jquery than we have.\nAlso added all the other fixes for integration tests to see\nif that resolves our problems.\n\nThis needs to be merge first so that patch which update the\nupper bump of XStatic-JQuery in openstack/requiremensts [1]\ncan be merged.\n\nNote: This patch also make horizon-integration job to non-voting\nso that we can merge this patch and once openstack/requirements\n[1] patch is merged, we will make horizon-integartion job voting\nagain\n\n[1] https://review.opendev.org/c/openstack/requirements/+/887607 merged\n\nChange-Id: I9b8a5e8abe734e7fd99aa0066ede0377e34fbf44\n'}, {'number': 9, 'created': '2023-07-10 08:31:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/0855d27372caecba7f4e6a60bcd1be63fa07a6ab', 'message': 'Bump XStatic-JQuery to make it work with jquery-migrate\n\nThe jquery-migrate 3 requires newer jquery than we have.\nAlso added all the other fixes for integration tests to see\nif that resolves our problems.\n\nThis needs to be merge first so that patch which update the\nupper bump of XStatic-JQuery in openstack/requiremensts [1]\ncan be merged.\n\nNote: This patch also make horizon-integration job to non-voting\nso that we can merge this patch and once openstack/requirements\n[1] patch is merged, we will make horizon-integartion job voting\nagain\n\n[1] https://review.opendev.org/c/openstack/requirements/+/887607 merged\n\nChange-Id: I9b8a5e8abe734e7fd99aa0066ede0377e34fbf44\n'}, {'number': 10, 'created': '2023-07-10 12:39:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/54aaaa020bdea92c0ded6745243f89e50c1aeb55', 'message': 'Bump XStatic-JQuery to make it work with jquery-migrate\n\nThe jquery-migrate 3 requires newer jquery than we have.\nAlso added all the other fixes for integration tests to see\nif that resolves our problems.\n\nThis needs to be merge first so that patch which update the\nupper bump of XStatic-JQuery in openstack/requiremensts [1]\ncan be merged.\n\nNote: This patch also make horizon-integration job to non-voting\nso that we can merge this patch and once openstack/requirements\n[1] patch is merged, we will make horizon-integartion job voting\nagain\n\n[1] https://review.opendev.org/c/openstack/requirements/+/887933\n\nCo-Author-By: manchandavishal <manchandavishal143@gmail.com>\n\nChange-Id: I9b8a5e8abe734e7fd99aa0066ede0377e34fbf44\n'}, {'number': 11, 'created': '2023-07-10 12:47:32.000000000', 'files': ['requirements.txt', 'openstack_dashboard/test/integration_tests/config.py', 'openstack_dashboard/test/integration_tests/horizon.conf', '.zuul.d/project.yaml', 'openstack_dashboard/dashboards/project/static/dashboard/project/workflow/launch-instance/keypair/keypair.html'], 'web_link': 'https://opendev.org/openstack/horizon/commit/480aba9422384348730b2464de1cfe2eafd4aa78', 'message': 'Bump XStatic-JQuery to make it work with jquery-migrate\n\nThe jquery-migrate 3 requires newer jquery than we have.\nAlso added all the other fixes for integration tests to see\nif that resolves our problems.\n\nThis needs to be merge first so that patch which update the\nupper bump of XStatic-JQuery in openstack/requiremensts [1]\ncan be merged.\n\nNote: This patch also make horizon-integration job to non-voting\nso that we can merge this patch and once openstack/requirements\n[1] patch is merged, we will make horizon-integartion job voting\nagain\n\n[1] https://review.opendev.org/c/openstack/requirements/+/887933\n\nCo-Author-By: manchandavishal <manchandavishal143@gmail.com>\n\nChange-Id: I9b8a5e8abe734e7fd99aa0066ede0377e34fbf44\n'}]",4,887548,480aba9422384348730b2464de1cfe2eafd4aa78,35,3,11,8648,,,0,"Bump XStatic-JQuery to make it work with jquery-migrate

The jquery-migrate 3 requires newer jquery than we have.
Also added all the other fixes for integration tests to see
if that resolves our problems.

This needs to be merge first so that patch which update the
upper bump of XStatic-JQuery in openstack/requiremensts [1]
can be merged.

Note: This patch also make horizon-integration job to non-voting
so that we can merge this patch and once openstack/requirements
[1] patch is merged, we will make horizon-integartion job voting
again

[1] https://review.opendev.org/c/openstack/requirements/+/887933

Co-Author-By: manchandavishal <manchandavishal143@gmail.com>

Change-Id: I9b8a5e8abe734e7fd99aa0066ede0377e34fbf44
",git fetch https://review.opendev.org/openstack/horizon refs/changes/48/887548/1 && git format-patch -1 --stdout FETCH_HEAD,['requirements.txt'],1,dea2258168e1bfd4ef7730e18d388d73937e4152,887548,XStatic-JQuery-Migrate==1.2.1.1 # MIT License,XStatic-JQuery-Migrate>=1.2.1.1 # MIT License,1,1
openstack%2Ftempest~887237,openstack/tempest,master,I1e32e7a07018a05b54515d9e6e6c8bc2fc7fbdff,Run slow tests parallely,MERGED,2023-06-28 23:52:59.000000000,2023-07-11 04:40:58.000000000,2023-07-11 04:38:21.000000000,"[{'_account_id': 8313}, {'_account_id': 8556}, {'_account_id': 22348}, {'_account_id': 22873}, {'_account_id': 32029}]","[{'number': 1, 'created': '2023-06-28 23:52:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/b53713986ca22cd6064f44b9fef2dbdaa8df9cb0', 'message': ""Run slow tests parallely\n\nWe started the slow test run serially to avoid\nany timeout issue in parallel run. But serial run\ntakes lot of time and end up with job timeout.\n\ntempest-slow-parallel job exepriment running the slow\ntests in parallel and its not so bad. Only 1 timeout\nin last 50 run\n- https://zuul.opendev.org/t/openstack/builds?job_name=tempest-slow-parallel&skip=0\n\nLet's try running slow tests in parallel in tempest-slow-py3\njob itself and if it make situation worst then we can revert\nit to run serially.\n\nChange-Id: I1e32e7a07018a05b54515d9e6e6c8bc2fc7fbdff\n""}, {'number': 2, 'created': '2023-06-28 23:56:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/f1b8a398575d4713aaee8884a61dfc5faad1f90b', 'message': ""Run slow tests parallely\n\nWe started the slow test run serially to avoid\nany timeout issue in parallel run. But serial run\ntakes lot of time and end up with job timeout.\n\ntempest-slow-parallel job exepriment running the slow\ntests in parallel and its not so bad. Only 1 timeout\nin last 50 run\n- https://zuul.opendev.org/t/openstack/builds?job_name=tempest-slow-parallel&skip=0\n\nLet's try running slow tests in parallel in tempest-slow-py3\njob itself and if it make situation worst then we can revert\nit to run serially.\n\nChange-Id: I1e32e7a07018a05b54515d9e6e6c8bc2fc7fbdff\n""}, {'number': 3, 'created': '2023-06-29 00:32:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/004f7f5096b62f5c7dd373ce6da4a0884353e5ae', 'message': ""Run slow tests parallely\n\nWe started the slow test run serially to avoid\nany timeout issue in parallel run. But serial run\ntakes lot of time and end up with job timeout.\n\ntempest-slow-parallel job exepriment running the slow\ntests in parallel and its not so bad. Only 1 timeout\nin last 50 run\n- https://zuul.opendev.org/t/openstack/builds?job_name=tempest-slow-parallel&skip=0\n\nLet's try running slow tests in parallel in tempest-slow-py3\njob itself and if it make situation worst then we can revert\nit to run serially.\n\nChange-Id: I1e32e7a07018a05b54515d9e6e6c8bc2fc7fbdff\n""}, {'number': 4, 'created': '2023-07-06 17:39:41.000000000', 'files': ['zuul.d/project.yaml', 'zuul.d/integrated-gate.yaml'], 'web_link': 'https://opendev.org/openstack/tempest/commit/8de4127c0e24d3ef3fab50650e63d1a339b1ada5', 'message': ""Run slow tests parallely\n\nWe started the slow test run serially to avoid\nany timeout issue in parallel run. But serial run\ntakes lot of time and end up with job timeout.\n\ntempest-slow-parallel job exepriment running the slow\ntests in parallel and its not so bad. Only 1 timeout\nin last 50 run\n- https://zuul.opendev.org/t/openstack/builds?job_name=tempest-slow-parallel&skip=0\n\nLet's try running slow tests in parallel in tempest-slow-py3\njob itself and if it make situation worst then we can revert\nit to run serially.\n\nChange-Id: I1e32e7a07018a05b54515d9e6e6c8bc2fc7fbdff\n""}]",26,887237,8de4127c0e24d3ef3fab50650e63d1a339b1ada5,75,5,4,8556,,,0,"Run slow tests parallely

We started the slow test run serially to avoid
any timeout issue in parallel run. But serial run
takes lot of time and end up with job timeout.

tempest-slow-parallel job exepriment running the slow
tests in parallel and its not so bad. Only 1 timeout
in last 50 run
- https://zuul.opendev.org/t/openstack/builds?job_name=tempest-slow-parallel&skip=0

Let's try running slow tests in parallel in tempest-slow-py3
job itself and if it make situation worst then we can revert
it to run serially.

Change-Id: I1e32e7a07018a05b54515d9e6e6c8bc2fc7fbdff
",git fetch https://review.opendev.org/openstack/tempest refs/changes/37/887237/1 && git format-patch -1 --stdout FETCH_HEAD,"['zuul.d/project.yaml', 'zuul.d/integrated-gate.yaml']",2,b53713986ca22cd6064f44b9fef2dbdaa8df9cb0,job-timeout,, - job: name: tempest-slow-parallel parent: tempest-slow-py3 # This job run slow tests in parallel. vars: devstack_localrc: MYSQL_REDUCE_MEMORY: true,0,10
openstack%2Fironic~883062,openstack/ironic,master,Ie1e2a4150d4ee4521290737612780c02506f4a9e,Add DB API for Firmware and Object,MERGED,2023-05-12 12:22:09.000000000,2023-07-11 03:19:20.000000000,2023-07-11 03:17:47.000000000,"[{'_account_id': 10239}, {'_account_id': 10342}, {'_account_id': 11655}, {'_account_id': 22348}, {'_account_id': 23851}]","[{'number': 1, 'created': '2023-05-12 12:22:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/3a5ea05031be16c9dc9285085740101593a8d81e', 'message': 'Add DB API for Firmware\n\nAdds the following methods to DB API:\n\n* create_firmware_component_list\n* update_firmware_component_list\n* delete_firmware_component_list\n* get_firmware_component\n* get_firmware_component_list\n\nAdds three exceptions:\n\n* FirmwareComponentAlreadyExists\n* FirmwareComponentNotFound\n* FirmwareComponentListNotFound\n\nChange-Id: Ie1e2a4150d4ee4521290737612780c02506f4a9e\n'}, {'number': 2, 'created': '2023-05-13 14:23:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/c1b01d03a53e6790dabd144724c06b622a39c5b4', 'message': 'Add DB API for Firmware\n\nAdds the following methods to DB API:\n\n* create_firmware_component_list\n* update_firmware_component_list\n* delete_firmware_component_list\n* get_firmware_component\n* get_firmware_component_list\n\nAdds three exceptions:\n\n* FirmwareComponentAlreadyExists\n* FirmwareComponentNotFound\n* FirmwareComponentListNotFound\n\nStory: 2010659\nTask: 47977\n\nChange-Id: Ie1e2a4150d4ee4521290737612780c02506f4a9e\n'}, {'number': 3, 'created': '2023-05-23 21:41:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/d22a312e38f68cec9d42913da18b26e76599ee29', 'message': 'Add DB API for Firmware\n\nAdds the following methods to DB API:\n\n* create_firmware_component_list\n* update_firmware_component_list\n* delete_firmware_component_list\n* get_firmware_component\n* get_firmware_component_list\n\nAdds three exceptions:\n\n* FirmwareComponentAlreadyExists\n* FirmwareComponentNotFound\n* FirmwareComponentListNotFound\n\nStory: 2010659\nTask: 47977\n\nChange-Id: Ie1e2a4150d4ee4521290737612780c02506f4a9e\n'}, {'number': 4, 'created': '2023-05-25 01:06:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/d0e53a2f956d9dafcfd66bc979a7beb43630ec80', 'message': 'Add DB API for Firmware\n\nAdds the following methods to DB API:\n\n* create_firmware_component_list\n* update_firmware_component_list\n* delete_firmware_component_list\n* get_firmware_component\n* get_firmware_component_list\n\nAdds three exceptions:\n\n* FirmwareComponentAlreadyExists\n* FirmwareComponentNotFound\n* FirmwareComponentListNotFound\n\nStory: 2010659\nTask: 47977\n\nChange-Id: Ie1e2a4150d4ee4521290737612780c02506f4a9e\n'}, {'number': 5, 'created': '2023-05-26 06:24:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/9458bcbe81be57fb904ed8bb01b7b11f11879cf8', 'message': 'Add DB API for Firmware\n\nAdds the following methods to DB API:\n\n* create_firmware_component\n* update_firmware_component\n* get_firmware_component\n* get_firmware_component_list\n\nAdds two exceptions:\n\n* FirmwareComponentAlreadyExists\n* FirmwareComponentNotFound\n\nStory: 2010659\nTask: 47977\n\nChange-Id: Ie1e2a4150d4ee4521290737612780c02506f4a9e\n'}, {'number': 6, 'created': '2023-05-26 13:33:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/f4340b5c925ca78f282b8260a40fa56cf2930506', 'message': 'Add DB API for Firmware\n\nAdds the following methods to DB API:\n\n* create_firmware_component\n* update_firmware_component\n* get_firmware_component\n* get_firmware_component_list\n\nAdds two exceptions:\n\n* FirmwareComponentAlreadyExists\n* FirmwareComponentNotFound\n\nStory: 2010659\nTask: 47977\n\nChange-Id: Ie1e2a4150d4ee4521290737612780c02506f4a9e\n'}, {'number': 7, 'created': '2023-05-31 17:51:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/0e0bf9a4567f7a911ec890cc3a174a5d53c8186f', 'message': 'Add DB API for Firmware and Object\n\nAdds the following methods to DB API:\n\n* create_firmware_component\n* update_firmware_component\n* get_firmware_component\n* get_firmware_component_list\n\nFirmwareComponent\n* create | save | get\n\nFirmwareComponentList\n* get_by_node id\n\nAdds two exceptions:\n\n* FirmwareComponentAlreadyExists\n* FirmwareComponentNotFound\n\nTests for db and objects\n\nChanges were required in models, the class name should match the\nobject name we will create\n\nStory: 2010659\nTask: 47977\n\nChange-Id: Ie1e2a4150d4ee4521290737612780c02506f4a9e\n'}, {'number': 8, 'created': '2023-06-01 14:06:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/dbe5f659dcb8c4069e3b614cc5f2e804791cc48a', 'message': 'Add DB API for Firmware and Object\n\nAdds the following methods to DB API:\n\n* create_firmware_component\n* update_firmware_component\n* get_firmware_component\n* get_firmware_component_list\n\nFirmwareComponent\n* create | save | get\n\nFirmwareComponentList\n* get_by_node id\n\nAdds two exceptions:\n\n* FirmwareComponentAlreadyExists\n* FirmwareComponentNotFound\n\nTests for db and objects\n\nChanges were required in models, the class name should match the\nobject name we will create\n\nStory: 2010659\nTask: 47977\n\nChange-Id: Ie1e2a4150d4ee4521290737612780c02506f4a9e\n'}, {'number': 9, 'created': '2023-06-02 12:30:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/cdb51038557afc61e88c89cee128d13f4d5aff16', 'message': 'Add DB API for Firmware and Object\n\nAdds the following methods to DB API:\n\n* create_firmware_component\n* update_firmware_component\n* get_firmware_component\n* get_firmware_component_list\n\nFirmwareComponent\n* create | save | get\n\nFirmwareComponentList\n* get_by_node id\n\nAdds two exceptions:\n\n* FirmwareComponentAlreadyExists\n* FirmwareComponentNotFound\n\nTests for db and objects\n\nChanges were required in models, the class name should match the\nobject name we will create\n\nStory: 2010659\nTask: 47977\n\nChange-Id: Ie1e2a4150d4ee4521290737612780c02506f4a9e\n'}, {'number': 10, 'created': '2023-06-06 03:24:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/b745b4c29d0275d9ea727f61b831b3ab17e400ec', 'message': 'Add DB API for Firmware and Object\n\nAdds the following methods to DB API:\n\n* create_firmware_component\n* update_firmware_component\n* get_firmware_component\n* get_firmware_component_list\n\nFirmwareComponent\n* create | save | get\n\nFirmwareComponentList\n* get_by_node id | sync_firmware_components\n\nAdds two exceptions:\n\n* FirmwareComponentAlreadyExists\n* FirmwareComponentNotFound\n\nTests for db and objects\n\nChanges were required in models, the class name should match the\nobject name we will create\n\nStory: 2010659\nTask: 47977\n\nChange-Id: Ie1e2a4150d4ee4521290737612780c02506f4a9e\n'}, {'number': 11, 'created': '2023-06-06 03:41:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/f97007efed75a27d38d03d3f74ba6e5db4e78238', 'message': 'Add DB API for Firmware and Object\n\nAdds the following methods to DB API:\n\n* create_firmware_component\n* update_firmware_component\n* get_firmware_component\n* get_firmware_component_list\n\nFirmwareComponent\n* create | save | get\n\nFirmwareComponentList\n* get_by_node id | sync_firmware_components\n\nAdds two exceptions:\n\n* FirmwareComponentAlreadyExists\n* FirmwareComponentNotFound\n\nTests for db and objects\n\nChanges were required in models, the class name should match the\nobject name we will create\n\nStory: 2010659\nTask: 47977\n\nChange-Id: Ie1e2a4150d4ee4521290737612780c02506f4a9e\n'}, {'number': 12, 'created': '2023-06-06 23:50:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/2ea2e636c5627dbb373bd442c16071ba249888af', 'message': 'Add DB API for Firmware and Object\n\nAdds the following methods to DB API:\n\n* create_firmware_component\n* update_firmware_component\n* get_firmware_component\n* get_firmware_component_list\n\nFirmwareComponent\n* create | save | get\n\nFirmwareComponentList\n* get_by_node id | sync_firmware_components\n\nAdds two exceptions:\n\n* FirmwareComponentAlreadyExists\n* FirmwareComponentNotFound\n\nTests for db and objects\n\nChanges were required in models, the class name should match the\nobject name we will create\n\nStory: 2010659\nTask: 47977\n\nDepends-On: https://review.opendev.org/c/openstack/ironic/+/885372\n\nChange-Id: Ie1e2a4150d4ee4521290737612780c02506f4a9e\n'}, {'number': 13, 'created': '2023-06-07 01:54:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/1d97f2a37d8a47e03891664dc179efcc8a1618e9', 'message': 'Add DB API for Firmware and Object\n\nAdds the following methods to DB API:\n\n* create_firmware_component\n* update_firmware_component\n* get_firmware_component\n* get_firmware_component_list\n\nFirmwareComponent\n* create | save | get\n\nFirmwareComponentList\n* get_by_node id | sync_firmware_components\n\nAdds two exceptions:\n\n* FirmwareComponentAlreadyExists\n* FirmwareComponentNotFound\n\nTests for db and objects\n\nChanges were required in models, the class name should match the\nobject name we will create\n\nStory: 2010659\nTask: 47977\n\nChange-Id: Ie1e2a4150d4ee4521290737612780c02506f4a9e\n'}, {'number': 14, 'created': '2023-06-20 11:51:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/94213d470ea547c22b0cc8f0d77fca737d9c5398', 'message': 'Add DB API for Firmware and Object\n\nAdds the following methods to DB API:\n\n* create_firmware_component\n* update_firmware_component\n* get_firmware_component\n* get_firmware_component_list\n\nFirmwareComponent\n* create | save | get\n\nFirmwareComponentList\n* get_by_node id | sync_firmware_components\n\nAdds two exceptions:\n\n* FirmwareComponentAlreadyExists\n* FirmwareComponentNotFound\n\nTests for db and objects\n\nChanges were required in models, the class name should match the\nobject name we will create\n\nStory: 2010659\nTask: 47977\n\nChange-Id: Ie1e2a4150d4ee4521290737612780c02506f4a9e\n'}, {'number': 15, 'created': '2023-06-20 13:50:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/2d22b6a089467f07f341c73c2d48fa3a39c0afba', 'message': 'Add DB API for Firmware and Object\n\nAdds the following methods to DB API:\n\n* create_firmware_component\n* update_firmware_component\n* get_firmware_component\n* get_firmware_component_list\n\nFirmwareComponent\n* create | save | get\n\nFirmwareComponentList\n* get_by_node id | sync_firmware_components\n\nAdds two exceptions:\n\n* FirmwareComponentAlreadyExists\n* FirmwareComponentNotFound\n\nTests for db and objects\n\nChanges were required in models, the class name should match the\nobject name we will create\n\nStory: 2010659\nTask: 47977\n\nChange-Id: Ie1e2a4150d4ee4521290737612780c02506f4a9e\n'}, {'number': 16, 'created': '2023-06-21 17:45:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/b01a285dee0565bbdea25740f6088eb5c192a752', 'message': 'Add DB API for Firmware and Object\n\nAdds the following methods to DB API:\n\n* create_firmware_component\n* update_firmware_component\n* get_firmware_component\n* get_firmware_component_list\n\nFirmwareComponent\n* create | save | get\n\nFirmwareComponentList\n* get_by_node id | sync_firmware_components\n\nAdds two exceptions:\n\n* FirmwareComponentAlreadyExists\n* FirmwareComponentNotFound\n\nTests for db and objects\n\nChanges were required in models, the class name should match the\nobject name we will create\n\nStory: 2010659\nTask: 47977\n\nChange-Id: Ie1e2a4150d4ee4521290737612780c02506f4a9e\n'}, {'number': 17, 'created': '2023-06-28 17:05:30.000000000', 'files': ['ironic/tests/unit/common/test_release_mappings.py', 'ironic/tests/unit/objects/test_firmware.py', 'ironic/common/exception.py', 'ironic/objects/firmware.py', 'ironic/db/sqlalchemy/api.py', 'ironic/tests/unit/db/utils.py', 'ironic/tests/unit/db/test_nodes.py', 'ironic/common/release_mappings.py', 'ironic/tests/unit/db/test_firmware_component.py', 'ironic/tests/unit/objects/test_objects.py', 'ironic/db/sqlalchemy/models.py', 'ironic/tests/unit/db/sqlalchemy/test_migrations.py', 'ironic/db/api.py', 'ironic/objects/__init__.py', 'ironic/tests/unit/objects/test_node.py', 'ironic/tests/unit/objects/utils.py'], 'web_link': 'https://opendev.org/openstack/ironic/commit/dad6724292b57085a5234efba4441c754657e865', 'message': 'Add DB API for Firmware and Object\n\nAdds the following methods to DB API:\n\n* create_firmware_component\n* update_firmware_component\n* get_firmware_component\n* get_firmware_component_list\n\nFirmwareComponent\n* create | save | get\n\nFirmwareComponentList\n* get_by_node id | sync_firmware_components\n\nAdds two exceptions:\n\n* FirmwareComponentAlreadyExists\n* FirmwareComponentNotFound\n\nTests for db and objects\n\nChanges were required in models, the class name should match the\nobject name we will create\n\nStory: 2010659\nTask: 47977\n\nChange-Id: Ie1e2a4150d4ee4521290737612780c02506f4a9e\n'}]",101,883062,dad6724292b57085a5234efba4441c754657e865,161,5,17,15519,,,0,"Add DB API for Firmware and Object

Adds the following methods to DB API:

* create_firmware_component
* update_firmware_component
* get_firmware_component
* get_firmware_component_list

FirmwareComponent
* create | save | get

FirmwareComponentList
* get_by_node id | sync_firmware_components

Adds two exceptions:

* FirmwareComponentAlreadyExists
* FirmwareComponentNotFound

Tests for db and objects

Changes were required in models, the class name should match the
object name we will create

Story: 2010659
Task: 47977

Change-Id: Ie1e2a4150d4ee4521290737612780c02506f4a9e
",git fetch https://review.opendev.org/openstack/ironic refs/changes/62/883062/1 && git format-patch -1 --stdout FETCH_HEAD,"['ironic/common/exception.py', 'ironic/db/sqlalchemy/api.py', 'ironic/tests/unit/db/utils.py', 'ironic/tests/unit/db/test_firmware_component.py', 'ironic/db/api.py']",5,3a5ea05031be16c9dc9285085740101593a8d81e,fw_db_api," @abc.abstractclassmethod def create_firmware_component_list(self, node_id, components, version): """"""Create a list of FirmwareComponent records for a given node. :param node_id: The node id. :param components: A list of Firmware Components to be created. :: [ { 'component': String, 'initial_version': String, 'current_version': String, 'last_version_flashed': String }, ... ] :param version: the version of the object.FirmwareComponent :returns: A list of FirmwareComponent object. :raises: NodeNotFound if the node is not found. :raises: FirmwareComponentAlreadyExists if any of the component records already exists. """""" @abc.abstractclassmethod def update_firmware_component_list(self, node_id, components, version): """"""Update a list of FirmwareComponent records. :param node_id: The node id. :param components: A list of Firmware Components to be created. :: [ { 'component': String, 'initial_version': String, 'current_version': String, 'last_version_flashed': String }, ... ] :param version: the version of the object.FirmwareComponent :returns: A list of FirmwareComponent object. :raises: NodeNotFound if the node is not found. :raises: FirmwareComponentNotFound if any of the components is not found. """""" @abc.abstractclassmethod def delete_firmware_component_list(self, node_id, names): """"""Delete a list of Firmware Component :param node_id: The node id. :param names: List of firmware components names to be deleted. :raises: NodeNotFound if the node is not found. :raises: FirmwareComponentNotFound if any of the components is not found. """""" @abc.abstractmethod def get_firmware_component(self, node_id, name): """"""Retrieve Firmware Component. :param node_id: The node id. :param name: String containing name of Firmware component. :returns: The FirmwareComponent object. :raises: NodeNotFound if the node is not found. :raises: FirmwareComponentNotFound if the BIOS setting is not found. """""" @abc.abstractclassmethod def get_firmware_component_list(self, node_id): """"""TRetrieve Firmware Components of a given node. :param node_id: The node id. :returns: A list of FirmwareComponent objects. :raises: NodeNotFound if the node is not found. """"""",,359,0
openstack%2Fsahara-dashboard~885446,openstack/sahara-dashboard,master,I29227341b9b278d205fc9a27ba0296ed65482f2c,setup.cfg: Replace dashes with underscores,ABANDONED,2023-06-08 12:20:52.000000000,2023-07-11 03:07:37.000000000,,"[{'_account_id': 22348}, {'_account_id': 29313}]","[{'number': 1, 'created': '2023-06-08 12:20:52.000000000', 'files': ['setup.cfg'], 'web_link': 'https://opendev.org/openstack/sahara-dashboard/commit/ff9aeb711d16ab75faa082f1f4825dca89d24a18', 'message': ""setup.cfg: Replace dashes with underscores\n\nSetuptools v54.1.0 introduces a warning that the use of dash-separated\noptions in 'setup.cfg' will not be supported in a future version [1].\nGet ahead of the issue by replacing the dashes with underscores. Without\nthis, we see 'UserWarning' messages like the following on new enough\nversions of setuptools:\n\n  UserWarning: Usage of dash-separated 'description-file' will not be\n  supported in future versions. Please use the underscore name\n  'description_file' instead\n\n[1] https://github.com/pypa/setuptools/commit/a2e9ae4cb\n\nChange-Id: I29227341b9b278d205fc9a27ba0296ed65482f2c\n""}]",1,885446,ff9aeb711d16ab75faa082f1f4825dca89d24a18,4,2,1,29423,,,0,"setup.cfg: Replace dashes with underscores

Setuptools v54.1.0 introduces a warning that the use of dash-separated
options in 'setup.cfg' will not be supported in a future version [1].
Get ahead of the issue by replacing the dashes with underscores. Without
this, we see 'UserWarning' messages like the following on new enough
versions of setuptools:

  UserWarning: Usage of dash-separated 'description-file' will not be
  supported in future versions. Please use the underscore name
  'description_file' instead

[1] https://github.com/pypa/setuptools/commit/a2e9ae4cb

Change-Id: I29227341b9b278d205fc9a27ba0296ed65482f2c
",git fetch https://review.opendev.org/openstack/sahara-dashboard refs/changes/46/885446/1 && git format-patch -1 --stdout FETCH_HEAD,['setup.cfg'],1,ff9aeb711d16ab75faa082f1f4825dca89d24a18,,description_file =author_email = openstack-discuss@lists.openstack.org home_page = https://docs.openstack.org/sahara/latest/ python_requires = >=3.8,description-file =author-email = openstack-discuss@lists.openstack.org home-page = https://docs.openstack.org/sahara/latest/ python-requires = >=3.8,4,4
openstack%2Ftripleo-common~888025,openstack/tripleo-common,stable/wallaby,I1381b4f7f4f7808d29e7f1aa73e7c0cd06acc795,Fix unassigned new_manifest_type variable,MERGED,2023-07-10 08:56:35.000000000,2023-07-11 02:37:15.000000000,2023-07-11 02:35:45.000000000,"[{'_account_id': 7144}, {'_account_id': 9816}, {'_account_id': 11166}, {'_account_id': 22348}]","[{'number': 1, 'created': '2023-07-10 08:56:35.000000000', 'files': ['tripleo_common/image/image_uploader.py'], 'web_link': 'https://opendev.org/openstack/tripleo-common/commit/91f875acb7acc4ed3a94ee515dc685e40f36a943', 'message': 'Fix unassigned new_manifest_type variable\n\nThis fixes the regression caused by the recent change[1], and ensures\nthe new_manifest_type variable is defined in any code paths.\n\n[1] I04f6ac171b10af7a294819d6248eac641090cc49\n\nCloses-Bug: #2026711\nChange-Id: I1381b4f7f4f7808d29e7f1aa73e7c0cd06acc795\n'}]",0,888025,91f875acb7acc4ed3a94ee515dc685e40f36a943,9,4,1,9816,,,0,"Fix unassigned new_manifest_type variable

This fixes the regression caused by the recent change[1], and ensures
the new_manifest_type variable is defined in any code paths.

[1] I04f6ac171b10af7a294819d6248eac641090cc49

Closes-Bug: #2026711
Change-Id: I1381b4f7f4f7808d29e7f1aa73e7c0cd06acc795
",git fetch https://review.opendev.org/openstack/tripleo-common refs/changes/25/888025/1 && git format-patch -1 --stdout FETCH_HEAD,['tripleo_common/image/image_uploader.py'],1,91f875acb7acc4ed3a94ee515dc685e40f36a943,bug/2026711, new_manifest_type = manifest_type,,1,0
openstack%2Fironic~887297,openstack/ironic,master,Iefc044c31ef029e400a7dad294504175a4462638,Unit tests: Isolate mysql test migrations,MERGED,2023-06-29 16:16:17.000000000,2023-07-11 01:15:08.000000000,2023-07-11 01:13:06.000000000,"[{'_account_id': 10342}, {'_account_id': 15519}, {'_account_id': 22348}]","[{'number': 1, 'created': '2023-06-29 16:16:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/cd23265fa8ea4f94e121df7a6e08d0507d20ae4c', 'message': ""Unit tests: Isolate mysql test migrations\n\nAll database migration testing in opestack is done through\nan opportunistic worker model, where if the database is available\nand correctly configured for testing, i.e. openstack-citest user\nand access appropriately granted, then the tests will create and\ntest migrations.\n\nHowever, this has been problematic with mysql as of recent, as we\nhave seen a long standing migration issue boil to the surface often\nwith tests.\n\nAs a result, we're isolating that test down to it's own job so we\ncan limit the blast damage. This also helps us isolate is it all\nof the tests, or is it just soley isolated down to the mysql test\nrun class, which is an additional data point.\n\nBy default, we continue to run Postgres migration tests in the\nmain jobs, as they haven't been impacted by this issue.\n\nChange-Id: Iefc044c31ef029e400a7dad294504175a4462638\n""}, {'number': 2, 'created': '2023-06-29 16:23:40.000000000', 'files': ['zuul.d/ironic-jobs.yaml', 'zuul.d/project.yaml', 'tox.ini'], 'web_link': 'https://opendev.org/openstack/ironic/commit/5cad8ac7736618a875d9e6d6dd29d8db5f81fcd8', 'message': ""Unit tests: Isolate mysql test migrations\n\nAll database migration testing in opestack is done through\nan opportunistic worker model, where if the database is available\nand correctly configured for testing, i.e. openstack-citest user\nand access appropriately granted, then the tests will create and\ntest migrations.\n\nHowever, this has been problematic with mysql as of recent, as we\nhave seen a long standing migration issue boil to the surface often\nwith tests.\n\nAs a result, we're isolating that test down to it's own job so we\ncan limit the blast damage. This also helps us isolate is it all\nof the tests, or is it just soley isolated down to the mysql test\nrun class, which is an additional data point.\n\nBy default, we continue to run Postgres migration tests in the\nmain jobs, as they haven't been impacted by this issue.\n\nChange-Id: Iefc044c31ef029e400a7dad294504175a4462638\n""}]",8,887297,5cad8ac7736618a875d9e6d6dd29d8db5f81fcd8,29,3,2,11655,,,0,"Unit tests: Isolate mysql test migrations

All database migration testing in opestack is done through
an opportunistic worker model, where if the database is available
and correctly configured for testing, i.e. openstack-citest user
and access appropriately granted, then the tests will create and
test migrations.

However, this has been problematic with mysql as of recent, as we
have seen a long standing migration issue boil to the surface often
with tests.

As a result, we're isolating that test down to it's own job so we
can limit the blast damage. This also helps us isolate is it all
of the tests, or is it just soley isolated down to the mysql test
run class, which is an additional data point.

By default, we continue to run Postgres migration tests in the
main jobs, as they haven't been impacted by this issue.

Change-Id: Iefc044c31ef029e400a7dad294504175a4462638
",git fetch https://review.opendev.org/openstack/ironic refs/changes/97/887297/1 && git format-patch -1 --stdout FETCH_HEAD,"['zuul.d/ironic-jobs.yaml', 'zuul.d/project.yaml', 'tox.ini']",3,cd23265fa8ea4f94e121df7a6e08d0507d20ae4c,, stestr run --slowest --parallel-class --exclude-regex TestMigrationsMySQL {posargs}[testenv:mysql-migrations] sitepackages = False commands = stestr run --slowest --parallel-class TestMigrationsMySQL {posargs} , stestr run --slowest --parallel-class {posargs},16,1
openstack%2Fswift-bench~874341,openstack/swift-bench,master,Ie56dc0cdcc56577570e13e48732d7d72c63820e4,Switch from optparse to argparse,NEW,2023-02-17 23:46:49.000000000,2023-07-10 22:51:19.000000000,,[{'_account_id': 22348}],"[{'number': 1, 'created': '2023-02-17 23:46:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift-bench/commit/6bce89964bbb6362009aabb76bf1831152c87cca', 'message': 'Switch from optparse to argparse\n\nChange-Id: Ie56dc0cdcc56577570e13e48732d7d72c63820e4\n'}, {'number': 2, 'created': '2023-07-10 22:42:47.000000000', 'files': ['swiftbench/cli/__init__.py', 'tests/test_utils.py', 'tests/test_cli.py', 'swiftbench/utils.py'], 'web_link': 'https://opendev.org/openstack/swift-bench/commit/a395f374897dd5af72a83fe1f5c92900331d67fb', 'message': 'Switch from optparse to argparse\n\nChange-Id: Ie56dc0cdcc56577570e13e48732d7d72c63820e4\n'}]",0,874341,a395f374897dd5af72a83fe1f5c92900331d67fb,4,1,2,15343,,,0,"Switch from optparse to argparse

Change-Id: Ie56dc0cdcc56577570e13e48732d7d72c63820e4
",git fetch https://review.opendev.org/openstack/swift-bench refs/changes/41/874341/1 && git format-patch -1 --stdout FETCH_HEAD,"['swiftbench/cli/__init__.py', 'tests/test_utils.py', 'tests/test_cli.py', 'swiftbench/utils.py']",4,6bce89964bbb6362009aabb76bf1831152c87cca,," if isinstance(value, int): return value",,119,113
openstack%2Fswift-bench~888069,openstack/swift-bench,master,Iedfb1bc5fd444109f9239eb7aeb57983883acf0f,Fix SyntaxWarning,MERGED,2023-07-10 21:35:46.000000000,2023-07-10 22:22:00.000000000,2023-07-10 22:22:00.000000000,"[{'_account_id': 15343}, {'_account_id': 22348}]","[{'number': 1, 'created': '2023-07-10 21:35:46.000000000', 'files': ['bin/swift-bench'], 'web_link': 'https://opendev.org/openstack/swift-bench/commit/427a16cb085a1b2a5437e0c4a202e0e6070564a6', 'message': 'Fix SyntaxWarning\n\nSyntaxWarning: ""is not"" with a literal. Did you mean ""!=""?\nChange-Id: Iedfb1bc5fd444109f9239eb7aeb57983883acf0f\n'}]",0,888069,427a16cb085a1b2a5437e0c4a202e0e6070564a6,6,2,1,15343,,,0,"Fix SyntaxWarning

SyntaxWarning: ""is not"" with a literal. Did you mean ""!=""?
Change-Id: Iedfb1bc5fd444109f9239eb7aeb57983883acf0f
",git fetch https://review.opendev.org/openstack/swift-bench refs/changes/69/888069/1 && git format-patch -1 --stdout FETCH_HEAD,['bin/swift-bench'],1,427a16cb085a1b2a5437e0c4a202e0e6070564a6,, if options.concurrency != '':, if options.concurrency is not '':,1,1
openstack%2Fswift~885302,openstack/swift,master,I557bd01643375d7ad68c3031430899b85908a54f,Object-server: keep SLO manifest files in page cache.,MERGED,2023-06-05 18:10:24.000000000,2023-07-10 21:45:05.000000000,2023-07-10 19:50:47.000000000,"[{'_account_id': 1179}, {'_account_id': 7847}, {'_account_id': 15343}, {'_account_id': 22348}]","[{'number': 1, 'created': '2023-06-05 18:10:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/dc28ed29a94b99a6834e8381abf4efcae6527967', 'message': 'Object-server: keep SLO manifest files in page cache.\n\nChange-Id: I557bd01643375d7ad68c3031430899b85908a54f\n'}, {'number': 2, 'created': '2023-06-05 23:00:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/fd830fa39492067d8bf3daf7351568e919ff0396', 'message': 'Object-server: keep SLO manifest files in page cache.\n\nChange-Id: I557bd01643375d7ad68c3031430899b85908a54f\n'}, {'number': 3, 'created': '2023-06-06 03:46:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/f3a0efbede8b45d94e8d31a5e535d2855a2cf1c1', 'message': 'Object-server: keep SLO manifest files in page cache.\n\nCurrently, SLO manifest files will be evicted from page cache\nafter reading it, which cause hard drives very busy when user\nrequests a lot of parallel byte range GETs for a particular\nSLO object.\n\nThis patch will try keeping the manifest files in page cache\nby not evicting them after reading. Also CC team members who\nhelped on this issue.\n\nCo-Authored-By: Tim Burke <tim.burke@gmail.com>\nCo-Authored-By: Clay Gerrard <clay.gerrard@gmail.com>\nCo-Authored-By: Alistair Coles <alistairncoles@gmail.com>\nChange-Id: I557bd01643375d7ad68c3031430899b85908a54f\n'}, {'number': 4, 'created': '2023-06-07 05:22:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/0c661b4fe81932a9320a72a9c1519a155e04d712', 'message': 'Object-server: keep SLO manifest files in page cache.\n\nCurrently, SLO manifest files will be evicted from page cache\nafter reading it, which cause hard drives very busy when user\nrequests a lot of parallel byte range GETs for a particular\nSLO object.\n\nThis patch will try keeping the manifest files in page cache\nby not evicting them after reading.\n\nCo-Authored-By: Tim Burke <tim.burke@gmail.com>\nCo-Authored-By: Clay Gerrard <clay.gerrard@gmail.com>\nCo-Authored-By: Alistair Coles <alistairncoles@gmail.com>\nChange-Id: I557bd01643375d7ad68c3031430899b85908a54f\n'}, {'number': 5, 'created': '2023-06-10 21:52:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/8e8a64a653d83e3cb86ab9ec0b5593342ee6dd58', 'message': ""Object-server: keep SLO manifest files in page cache.\n\nCurrently, SLO manifest files will be evicted from page cache\nafter reading it, which cause hard drives very busy when user\nrequests a lot of parallel byte range GETs for a particular\nSLO object.\n\nThis patch will add a new config 'keep_cache_slo_manifest', and\ntry keeping the manifest files in page cache by not evicting them\nafter reading if config settings allow so.\n\nCo-Authored-By: Tim Burke <tim.burke@gmail.com>\nCo-Authored-By: Clay Gerrard <clay.gerrard@gmail.com>\nCo-Authored-By: Alistair Coles <alistairncoles@gmail.com>\nChange-Id: I557bd01643375d7ad68c3031430899b85908a54f\n""}, {'number': 6, 'created': '2023-07-07 19:55:21.000000000', 'files': ['swift/obj/server.py', 'test/unit/obj/test_server.py', 'doc/source/config/object_server_config.rst', 'test/unit/common/test_utils.py', 'etc/object-server.conf-sample'], 'web_link': 'https://opendev.org/openstack/swift/commit/cb1e584e6495b4e35b9b2833f250ac38b76ab0b3', 'message': ""Object-server: keep SLO manifest files in page cache.\n\nCurrently, SLO manifest files will be evicted from page cache\nafter reading it, which cause hard drives very busy when user\nrequests a lot of parallel byte range GETs for a particular\nSLO object.\n\nThis patch will add a new config 'keep_cache_slo_manifest', and\ntry keeping the manifest files in page cache by not evicting them\nafter reading if config settings allow so.\n\nCo-Authored-By: Tim Burke <tim.burke@gmail.com>\nCo-Authored-By: Clay Gerrard <clay.gerrard@gmail.com>\nCo-Authored-By: Alistair Coles <alistairncoles@gmail.com>\nChange-Id: I557bd01643375d7ad68c3031430899b85908a54f\n""}]",40,885302,cb1e584e6495b4e35b9b2833f250ac38b76ab0b3,44,4,6,34930,,,0,"Object-server: keep SLO manifest files in page cache.

Currently, SLO manifest files will be evicted from page cache
after reading it, which cause hard drives very busy when user
requests a lot of parallel byte range GETs for a particular
SLO object.

This patch will add a new config 'keep_cache_slo_manifest', and
try keeping the manifest files in page cache by not evicting them
after reading if config settings allow so.

Co-Authored-By: Tim Burke <tim.burke@gmail.com>
Co-Authored-By: Clay Gerrard <clay.gerrard@gmail.com>
Co-Authored-By: Alistair Coles <alistairncoles@gmail.com>
Change-Id: I557bd01643375d7ad68c3031430899b85908a54f
",git fetch https://review.opendev.org/openstack/swift refs/changes/02/885302/1 && git format-patch -1 --stdout FETCH_HEAD,['swift/obj/server.py'],1,dc28ed29a94b99a6834e8381abf4efcae6527967,slo_manifest_pagecache," keep_cache = ( self.keep_cache_private or ( ""X-Auth-Token"" not in request.headers and ""X-Storage-Token"" not in request.headers ) or ( ""X-Static-Large-Object"" in request.headers and request.headers[""X-Static-Large-Object""].lower() == ""true"" ) )", keep_cache = (self.keep_cache_private or ('X-Auth-Token' not in request.headers and 'X-Storage-Token' not in request.headers)),12,3
openstack%2Fmanila~886748,openstack/manila,master,I58dcd9716cf95d0d696c13a4c831df787726bcda,Fix duplicate entries in share_server_backend_details,MERGED,2023-06-22 13:01:36.000000000,2023-07-10 20:27:21.000000000,2023-07-10 19:06:46.000000000,"[{'_account_id': 16643}, {'_account_id': 18816}, {'_account_id': 22348}, {'_account_id': 29632}, {'_account_id': 31721}, {'_account_id': 33038}]","[{'number': 1, 'created': '2023-06-22 13:01:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/manila/commit/22b10b023019fc1b4b7ecdb77cdc85b438a4b88b', 'message': 'Fix duplicate entries of share_server_backend_details\n\nshare_server_backend_details_set() add entries in table without checking\nexisting entries with given combinaton of share_server_id and key. This\ncauses duplicate records. Fix it by validating presence of key.\n\nCloses-bug: #2024658\nChange-Id: I58dcd9716cf95d0d696c13a4c831df787726bcda\n'}, {'number': 2, 'created': '2023-06-22 15:02:45.000000000', 'files': ['manila/tests/db/sqlalchemy/test_api.py', 'manila/db/sqlalchemy/api.py', 'manila/exception.py', 'releasenotes/notes/bug-2024658-fix-duplicate-entries-of-share-server-backend-details-adf45b417d45b437.yaml'], 'web_link': 'https://opendev.org/openstack/manila/commit/37278df338ab4d2753ca004e556a197f847be0ce', 'message': 'Fix duplicate entries in share_server_backend_details\n\nshare_server_backend_details_set() add entries in db table without\nchecking existing entries with given combinaton of share_server_id\nand key. This causes duplicate records. Fix it by validating presence\nof share server id and key.\n\nCloses-bug: #2024658\nChange-Id: I58dcd9716cf95d0d696c13a4c831df787726bcda\n'}]",3,886748,37278df338ab4d2753ca004e556a197f847be0ce,17,6,2,32919,,,0,"Fix duplicate entries in share_server_backend_details

share_server_backend_details_set() add entries in db table without
checking existing entries with given combinaton of share_server_id
and key. This causes duplicate records. Fix it by validating presence
of share server id and key.

Closes-bug: #2024658
Change-Id: I58dcd9716cf95d0d696c13a4c831df787726bcda
",git fetch https://review.opendev.org/openstack/manila refs/changes/48/886748/1 && git format-patch -1 --stdout FETCH_HEAD,"['manila/tests/db/sqlalchemy/test_api.py', 'manila/db/sqlalchemy/api.py', 'manila/exception.py', 'releasenotes/notes/bug-2024658-fix-duplicate-entries-of-share-server-backend-details-adf45b417d45b437.yaml']",4,22b10b023019fc1b4b7ecdb77cdc85b438a4b88b,bug/2024658,--- fixes: - | Share server backend details sets function adds db records without checking existing entries. This results in duplicate records for the combination of given share server id and key. Fixed it by updating records if already exist else creating new. For more details check `Launchpad bug #2024658<https://bugs.launchpad.net/manila/+bug/2024658>`_ ,,50,6
openstack%2Frequirements~888055,openstack/requirements,master,Iccd7166f0a8091bdf4613186f9c8048864603f29,Raise cap for XStatic-JQuery in ``global-requirements.txt``,MERGED,2023-07-10 15:56:25.000000000,2023-07-10 20:22:07.000000000,2023-07-10 20:21:09.000000000,"[{'_account_id': 14288}, {'_account_id': 22348}]","[{'number': 1, 'created': '2023-07-10 15:56:25.000000000', 'files': ['global-requirements.txt'], 'web_link': 'https://opendev.org/openstack/requirements/commit/df5efbd42bd4bf89f38bee2527b61415927c5823', 'message': 'Raise cap for XStatic-JQuery in ``global-requirements.txt``\n\nThis patch raise the version of XStatic-JQuery <3.6\nin ``global-requirements.txt`` file because horizon\nis already using XStatic-JQuery-Migrate version 3.3.2.1 [1]\nbut XStatic-jQuery old version is not compatiable with\nlatest version of XStatic-JQuery-Migrate version.\nSo horizon is updating XStatic-JQuery to <3.6 and for that\nthis patch needs to be merge first.\n\nNote: ``upper-constraints.txt`` is updated in a seprate patch\n[3].\n\n[1] https://review.opendev.org/c/openstack/requirements/+/883402\n[2] https://review.opendev.org/c/openstack/horizon/+/887548\n[3] https://review.opendev.org/c/openstack/requirements/+/887933\n\nChange-Id: Iccd7166f0a8091bdf4613186f9c8048864603f29\n'}]",0,888055,df5efbd42bd4bf89f38bee2527b61415927c5823,7,2,1,29313,,,0,"Raise cap for XStatic-JQuery in ``global-requirements.txt``

This patch raise the version of XStatic-JQuery <3.6
in ``global-requirements.txt`` file because horizon
is already using XStatic-JQuery-Migrate version 3.3.2.1 [1]
but XStatic-jQuery old version is not compatiable with
latest version of XStatic-JQuery-Migrate version.
So horizon is updating XStatic-JQuery to <3.6 and for that
this patch needs to be merge first.

Note: ``upper-constraints.txt`` is updated in a seprate patch
[3].

[1] https://review.opendev.org/c/openstack/requirements/+/883402
[2] https://review.opendev.org/c/openstack/horizon/+/887548
[3] https://review.opendev.org/c/openstack/requirements/+/887933

Change-Id: Iccd7166f0a8091bdf4613186f9c8048864603f29
",git fetch https://review.opendev.org/openstack/requirements refs/changes/55/888055/1 && git format-patch -1 --stdout FETCH_HEAD,['global-requirements.txt'],1,df5efbd42bd4bf89f38bee2527b61415927c5823,,XStatic-jQuery<3.6 # MIT License,XStatic-jQuery<3 # MIT License,1,1
openstack%2Fopenstack-ansible-haproxy_server~887573,openstack/openstack-ansible-haproxy_server,master,I184021b65d6f3f28526c9fa09bea90a2baef77b2,Fix `regen pem` with `extra_lb_tls_vip_addresses`,MERGED,2023-07-04 08:24:04.000000000,2023-07-10 20:05:07.000000000,2023-07-10 20:04:11.000000000,"[{'_account_id': 22348}, {'_account_id': 25023}, {'_account_id': 28619}]","[{'number': 1, 'created': '2023-07-04 08:24:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-haproxy_server/commit/b2229d8cc6382ecccc9d75d96c1c6aa5bcf37911', 'message': 'Fix `regen pem` when using `extra_lb_tls_vip_addresses`\n\n`extra_lb_tls_vip_addresses` is list of additional internal VIP\naddresses, which gets parsed into `haproxy_tls_vip_binds` without\n`interface` attribute.\n\nChange-Id: I184021b65d6f3f28526c9fa09bea90a2baef77b2\n'}, {'number': 2, 'created': '2023-07-04 08:25:21.000000000', 'files': ['handlers/main.yml'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-haproxy_server/commit/848e316ef5066cc0937ec9a91e215382373ae243', 'message': 'Fix `regen pem` with `extra_lb_tls_vip_addresses`\n\n`extra_lb_tls_vip_addresses` is list of additional internal VIP\naddresses, which gets parsed into `haproxy_tls_vip_binds` without\n`interface` attribute.\n\nChange-Id: I184021b65d6f3f28526c9fa09bea90a2baef77b2\n'}]",5,887573,848e316ef5066cc0937ec9a91e215382373ae243,16,3,2,34653,,,0,"Fix `regen pem` with `extra_lb_tls_vip_addresses`

`extra_lb_tls_vip_addresses` is list of additional internal VIP
addresses, which gets parsed into `haproxy_tls_vip_binds` without
`interface` attribute.

Change-Id: I184021b65d6f3f28526c9fa09bea90a2baef77b2
",git fetch https://review.opendev.org/openstack/openstack-ansible-haproxy_server refs/changes/73/887573/1 && git format-patch -1 --stdout FETCH_HEAD,['handlers/main.yml'],1,b2229d8cc6382ecccc9d75d96c1c6aa5bcf37911,fix_regen_pem_with_extra_lb_tls_vip_addresses," item_interface: ""{{ item['interface'] | default('') }}"""," item_interface: ""{{ item['interface'] }}""",1,1
openstack%2Fcharms.ceph~885933,openstack/charms.ceph,stable/pacific,I07f0b34e80978189ca03ab7bad956e5ce5da4201,Add missing octopus -> pacific upgrade path,MERGED,2023-06-13 04:53:01.000000000,2023-07-10 19:24:48.000000000,2023-07-10 19:24:48.000000000,"[{'_account_id': 8992}, {'_account_id': 15382}, {'_account_id': 21107}, {'_account_id': 22348}, {'_account_id': 33717}, {'_account_id': 34952}]","[{'number': 1, 'created': '2023-06-13 04:53:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charms.ceph/commit/bfcbc3f6fea9c0eec447ef5885f0c91797b2b930', 'message': ""Add missing octopus -> pacific upgrade path\n\nThe octopus -> pacific upgrade path is missing from the stable/pacific\nbranch, which results in an error and failure to upgrade.\n\nInvalid upgrade path from octopus to octopus. Valid paths are: ['firefly\n-> hammer', 'hammer -> jewel', 'jewel -> luminous', 'luminous -> mimic',\n'mimic -> nautilus', 'nautilus -> octopus']\n\nChange-Id: I07f0b34e80978189ca03ab7bad956e5ce5da4201\n""}, {'number': 2, 'created': '2023-06-13 06:59:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charms.ceph/commit/e3c81383c2c06ab991dedb87ad7798ef0476c529', 'message': ""Add missing octopus -> pacific upgrade path\n\nThe octopus -> pacific upgrade path is missing from the stable/pacific\nbranch, which results in an error and failure to upgrade.\n\nInvalid upgrade path from octopus to octopus. Valid paths are: ['firefly\n-> hammer', 'hammer -> jewel', 'jewel -> luminous', 'luminous -> mimic',\n'mimic -> nautilus', 'nautilus -> octopus']\n\nChange-Id: I07f0b34e80978189ca03ab7bad956e5ce5da4201\n""}, {'number': 3, 'created': '2023-06-14 01:58:39.000000000', 'files': ['charms_ceph/utils.py', 'unit_tests/test_utils.py'], 'web_link': 'https://opendev.org/openstack/charms.ceph/commit/2e600bdf71ef302de5d91bb5f9b9b989478e3b1c', 'message': ""Add missing octopus -> pacific upgrade path\n\nThe octopus -> pacific upgrade path is missing from the stable/pacific\nbranch, which results in an error and failure to upgrade.\n\nInvalid upgrade path from octopus to octopus. Valid paths are: ['firefly\n-> hammer', 'hammer -> jewel', 'jewel -> luminous', 'luminous -> mimic',\n'mimic -> nautilus', 'nautilus -> octopus']\n\nChange-Id: I07f0b34e80978189ca03ab7bad956e5ce5da4201\n""}]",17,885933,2e600bdf71ef302de5d91bb5f9b9b989478e3b1c,19,6,3,21107,,,0,"Add missing octopus -> pacific upgrade path

The octopus -> pacific upgrade path is missing from the stable/pacific
branch, which results in an error and failure to upgrade.

Invalid upgrade path from octopus to octopus. Valid paths are: ['firefly
-> hammer', 'hammer -> jewel', 'jewel -> luminous', 'luminous -> mimic',
'mimic -> nautilus', 'nautilus -> octopus']

Change-Id: I07f0b34e80978189ca03ab7bad956e5ce5da4201
",git fetch https://review.opendev.org/openstack/charms.ceph refs/changes/33/885933/1 && git format-patch -1 --stdout FETCH_HEAD,"['charms_ceph/utils.py', 'unit_tests/test_utils.py']",2,bfcbc3f6fea9c0eec447ef5885f0c91797b2b930,," 'octopus -> pacific',",,5,0
openstack%2Fcharms.ceph~886038,openstack/charms.ceph,stable/pacific,I16d01e15438e3d61033863b4c03087d1a0b7a008,Fix linting errors,MERGED,2023-06-14 01:53:22.000000000,2023-07-10 19:13:23.000000000,2023-07-10 19:13:23.000000000,"[{'_account_id': 1131}, {'_account_id': 8992}, {'_account_id': 15382}, {'_account_id': 22348}, {'_account_id': 34952}]","[{'number': 1, 'created': '2023-06-14 01:53:22.000000000', 'files': ['charms_ceph/utils.py', 'unit_tests/test_utils.py'], 'web_link': 'https://opendev.org/openstack/charms.ceph/commit/763495aeb39f1312011b17eedbb84edda351b649', 'message': 'Fix linting errors\n\nChange-Id: I16d01e15438e3d61033863b4c03087d1a0b7a008\n(cherry picked from commit 78bd3fd21ae81f7ae9180d9bd8a271d1d27d7537)\n'}]",1,886038,763495aeb39f1312011b17eedbb84edda351b649,9,5,1,21107,,,0,"Fix linting errors

Change-Id: I16d01e15438e3d61033863b4c03087d1a0b7a008
(cherry picked from commit 78bd3fd21ae81f7ae9180d9bd8a271d1d27d7537)
",git fetch https://review.opendev.org/openstack/charms.ceph refs/changes/38/886038/1 && git format-patch -1 --stdout FETCH_HEAD,"['charms_ceph/utils.py', 'unit_tests/test_utils.py']",2,763495aeb39f1312011b17eedbb84edda351b649,, assert (utils.use_bluestore()), assert(utils.use_bluestore()),3,3
openstack%2Fneutron~887278,openstack/neutron,stable/wallaby,If06c372a9d5cb1dc1ec1af768abb61f52c2c5abd,[OVN] Improve Hash Ring logs,MERGED,2023-06-29 12:57:48.000000000,2023-07-10 19:06:56.000000000,2023-07-10 19:05:56.000000000,"[{'_account_id': 16688}, {'_account_id': 21798}, {'_account_id': 22348}]","[{'number': 1, 'created': '2023-06-29 12:57:48.000000000', 'files': ['neutron/tests/unit/db/test_ovn_hash_ring_db.py', 'neutron/common/ovn/exceptions.py', 'neutron/db/ovn_hash_ring_db.py', 'neutron/common/ovn/hash_ring_manager.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/e28fd4b4a5820f8c9aeaee3b43608e6260883069', 'message': '[OVN] Improve Hash Ring logs\n\nDebugging Hash Ring problems can be difficult challenge given that prior\nto this patch the logs were very limited.\n\nThis patch improves the logging for this feature as follow:\n\n1. Log when a node is added to the ring\n2. Log when nodes are removed from the ring\n3. Keep track the number of offline nodes and log it upon loading the\n   ring\n4. Improve the ""Hash Ring is empty"" exception with the number of offline\n   nodes found (if 0, means the ovn_hash_ring table has no entries)\n\nCloses-Bug: #2023670\nChange-Id: Ic90432b5ddea8cf176de159ec7eaafd5fd7bdd6e\nSigned-off-by: Lucas Alvares Gomes <lucasagomes@gmail.com>\n(cherry picked from commit afa20faec3c37bd06346360cadbad0d69e9925f0)\n\n[OVN] The all() and count() methods should be inside a DB txn\n\nThe ``ovn_hash_ring_db`` methods ``get_active_nodes`` and\n``count_offline_nodes`` are sending SQL requests that should be issued\nfrom inside a READER context.\n\nCloses-Bug: #2024447\nChange-Id: If06c372a9d5cb1dc1ec1af768abb61f52c2c5abd\n(cherry picked from commit 0c66dfaed8e1ec00726c3e484e69174779678abd)\n'}]",7,887278,e28fd4b4a5820f8c9aeaee3b43608e6260883069,25,3,1,6773,,,0,"[OVN] Improve Hash Ring logs

Debugging Hash Ring problems can be difficult challenge given that prior
to this patch the logs were very limited.

This patch improves the logging for this feature as follow:

1. Log when a node is added to the ring
2. Log when nodes are removed from the ring
3. Keep track the number of offline nodes and log it upon loading the
   ring
4. Improve the ""Hash Ring is empty"" exception with the number of offline
   nodes found (if 0, means the ovn_hash_ring table has no entries)

Closes-Bug: #2023670
Change-Id: Ic90432b5ddea8cf176de159ec7eaafd5fd7bdd6e
Signed-off-by: Lucas Alvares Gomes <lucasagomes@gmail.com>
(cherry picked from commit afa20faec3c37bd06346360cadbad0d69e9925f0)

[OVN] The all() and count() methods should be inside a DB txn

The ``ovn_hash_ring_db`` methods ``get_active_nodes`` and
``count_offline_nodes`` are sending SQL requests that should be issued
from inside a READER context.

Closes-Bug: #2024447
Change-Id: If06c372a9d5cb1dc1ec1af768abb61f52c2c5abd
(cherry picked from commit 0c66dfaed8e1ec00726c3e484e69174779678abd)
",git fetch https://review.opendev.org/openstack/neutron refs/changes/78/887278/1 && git format-patch -1 --stdout FETCH_HEAD,"['neutron/tests/unit/db/test_ovn_hash_ring_db.py', 'neutron/common/ovn/exceptions.py', 'neutron/db/ovn_hash_ring_db.py', 'neutron/common/ovn/hash_ring_manager.py']",4,e28fd4b4a5820f8c9aeaee3b43608e6260883069,," self._offline_node_count = 0 self._offline_node_count = db_hash_ring.count_offline_nodes( self.admin_ctx, constants.HASH_RING_NODES_TIMEOUT, self._group) LOG.debug(""Hash Ring loaded. %d active nodes. %d offline nodes"", len(nodes), self._offline_node_count) raise exceptions.HashRingIsEmpty( key=key, node_count=self._offline_node_count)", raise exceptions.HashRingIsEmpty(key=key),72,12
openstack%2Ftripleo-common~888026,openstack/tripleo-common,stable/train,I1381b4f7f4f7808d29e7f1aa73e7c0cd06acc795,Fix unassigned new_manifest_type variable,MERGED,2023-07-10 08:57:01.000000000,2023-07-10 18:45:57.000000000,2023-07-10 18:45:01.000000000,"[{'_account_id': 7144}, {'_account_id': 8449}, {'_account_id': 22348}]","[{'number': 1, 'created': '2023-07-10 08:57:01.000000000', 'files': ['tripleo_common/image/image_uploader.py'], 'web_link': 'https://opendev.org/openstack/tripleo-common/commit/ae83d4b24a6cbbfa711d0bf67f69c717308f1b68', 'message': 'Fix unassigned new_manifest_type variable\n\nThis fixes the regression caused by the recent change[1], and ensures\nthe new_manifest_type variable is defined in any code paths.\n\n[1] I04f6ac171b10af7a294819d6248eac641090cc49\n\nCloses-Bug: #2026711\nChange-Id: I1381b4f7f4f7808d29e7f1aa73e7c0cd06acc795\n'}]",1,888026,ae83d4b24a6cbbfa711d0bf67f69c717308f1b68,9,3,1,9816,,,0,"Fix unassigned new_manifest_type variable

This fixes the regression caused by the recent change[1], and ensures
the new_manifest_type variable is defined in any code paths.

[1] I04f6ac171b10af7a294819d6248eac641090cc49

Closes-Bug: #2026711
Change-Id: I1381b4f7f4f7808d29e7f1aa73e7c0cd06acc795
",git fetch https://review.opendev.org/openstack/tripleo-common refs/changes/26/888026/1 && git format-patch -1 --stdout FETCH_HEAD,['tripleo_common/image/image_uploader.py'],1,ae83d4b24a6cbbfa711d0bf67f69c717308f1b68,bug/2026711, new_manifest_type = manifest_type,,1,0
openstack%2Fneutron~887044,openstack/neutron,stable/wallaby,I15d22e0e2b4bf3e4f882b521bcd6a13f84e4feed,[qos] _validate_create_network_callback return in no network,MERGED,2023-06-27 12:56:50.000000000,2023-07-10 18:22:24.000000000,2023-07-10 18:21:10.000000000,"[{'_account_id': 11975}, {'_account_id': 21798}, {'_account_id': 22348}]","[{'number': 1, 'created': '2023-06-27 12:56:50.000000000', 'files': ['neutron/services/qos/qos_plugin.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/18ab40fcade6a5a0ed8e5bfa6c42b48567157782', 'message': '[qos] _validate_create_network_callback return in no network\n\nIt seems that _validate_create_network_callback notified without\nnetwork_id in payload, to avoid issues in such case return.\n\nChange-Id: I15d22e0e2b4bf3e4f882b521bcd6a13f84e4feed\nCloses-Bug: #2008912\n(cherry picked from commit ec4bfb91f0d3ae4aa4cbe8ba05c20cb00515b00d)\n'}]",8,887044,18ab40fcade6a5a0ed8e5bfa6c42b48567157782,41,3,1,16688,,,0,"[qos] _validate_create_network_callback return in no network

It seems that _validate_create_network_callback notified without
network_id in payload, to avoid issues in such case return.

Change-Id: I15d22e0e2b4bf3e4f882b521bcd6a13f84e4feed
Closes-Bug: #2008912
(cherry picked from commit ec4bfb91f0d3ae4aa4cbe8ba05c20cb00515b00d)
",git fetch https://review.opendev.org/openstack/neutron refs/changes/44/887044/1 && git format-patch -1 --stdout FETCH_HEAD,['neutron/services/qos/qos_plugin.py'],1,18ab40fcade6a5a0ed8e5bfa6c42b48567157782,bug/2008912," if not network or not getattr(network, 'qos_policy_id', None): policy_id = network.qos_policy_id", policy_id = network.qos_policy_id if policy_id is None:,2,2
openstack%2Frequirements~887961,openstack/requirements,master,I6c67cd897adb0cf8a84748aea2c92a998964f990,update constraint for python-glanceclient to new release 4.4.0,MERGED,2023-07-07 14:35:43.000000000,2023-07-10 18:16:38.000000000,2023-07-10 18:15:46.000000000,"[{'_account_id': 11904}, {'_account_id': 14288}, {'_account_id': 22348}]","[{'number': 1, 'created': '2023-07-07 14:35:43.000000000', 'files': ['upper-constraints.txt'], 'web_link': 'https://opendev.org/openstack/requirements/commit/e835b6370d575025c5fdc559b61ff61eac06230e', 'message': 'update constraint for python-glanceclient to new release 4.4.0\n\nmeta: version: 4.4.0\nmeta: diff-start: -\nmeta: series: bobcat\nmeta: branch: master\nmeta: release-type: release\nmeta: pypi: yes\nmeta: first: yes\nmeta: release:Author: Elod Illes <elod.illes@est.tech>\nmeta: release:Commit: Pranali Deore <pdeore@redhat.com>\nmeta: release:Change-Id: I327a1884a1c93ece4fe5d7531d9fe4a6db3bd742\nmeta: release:Code-Review+2: Elod Illes <elod.illes@est.tech>\nmeta: release:Code-Review+2: Hervé Beraud <herveberaud.pro@gmail.com>\nmeta: release:Workflow+1: Hervé Beraud <herveberaud.pro@gmail.com>\nChange-Id: I6c67cd897adb0cf8a84748aea2c92a998964f990\n'}]",1,887961,e835b6370d575025c5fdc559b61ff61eac06230e,9,3,1,11131,,,0,"update constraint for python-glanceclient to new release 4.4.0

meta: version: 4.4.0
meta: diff-start: -
meta: series: bobcat
meta: branch: master
meta: release-type: release
meta: pypi: yes
meta: first: yes
meta: release:Author: Elod Illes <elod.illes@est.tech>
meta: release:Commit: Pranali Deore <pdeore@redhat.com>
meta: release:Change-Id: I327a1884a1c93ece4fe5d7531d9fe4a6db3bd742
meta: release:Code-Review+2: Elod Illes <elod.illes@est.tech>
meta: release:Code-Review+2: Hervé Beraud <herveberaud.pro@gmail.com>
meta: release:Workflow+1: Hervé Beraud <herveberaud.pro@gmail.com>
Change-Id: I6c67cd897adb0cf8a84748aea2c92a998964f990
",git fetch https://review.opendev.org/openstack/requirements refs/changes/61/887961/1 && git format-patch -1 --stdout FETCH_HEAD,['upper-constraints.txt'],1,e835b6370d575025c5fdc559b61ff61eac06230e,new-release,python-glanceclient===4.4.0,python-glanceclient===4.3.0,1,1
openstack%2Fswift~884240,openstack/swift,master,I0ea464bcda16678997865667287aa11ea89cdcde,Encode header in latin-1 with wsgi_to_bytes,MERGED,2023-05-24 15:59:59.000000000,2023-07-10 17:45:39.000000000,2023-07-10 17:44:30.000000000,"[{'_account_id': 597}, {'_account_id': 7847}, {'_account_id': 22348}]","[{'number': 1, 'created': '2023-05-24 15:59:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/52af7ea6857649742c1292d8bc9767043d183cab', 'message': ""Encode header in latin-1 with wsgi_to_bytes\n\nPrevent encoding corruption in client's metadata during ssync\n\nCloses-Bug: #2020667\nChange-Id: I0ea464bcda16678997865667287aa11ea89cdcde\n""}, {'number': 2, 'created': '2023-05-31 11:06:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/cd6e71e62b7b56ff1a2770adfb3f9f4441d874e4', 'message': ""Encode header in latin-1 with wsgi_to_bytes\n\nPrevent encoding corruption in client's metadata during ssync\n\nCloses-Bug: #2020667\nChange-Id: I0ea464bcda16678997865667287aa11ea89cdcde\n""}, {'number': 3, 'created': '2023-05-31 23:07:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/1e167471ea4c4d7e28e6fd1378d7c7d3d058c96f', 'message': ""Encode header in latin-1 with wsgi_to_bytes\n\nPrevent encoding corruption in client's metadata during ssync\n\nCloses-Bug: #2020667\nChange-Id: I0ea464bcda16678997865667287aa11ea89cdcde\n""}, {'number': 4, 'created': '2023-06-01 16:19:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/e6179e98211a9488a5581f50427df9bdd647c783', 'message': ""Encode header in latin-1 with wsgi_to_bytes\n\nPrevent encoding corruption in client's metadata during ssync\n\nCloses-Bug: #2020667\nChange-Id: I0ea464bcda16678997865667287aa11ea89cdcde\n""}, {'number': 5, 'created': '2023-06-23 21:23:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/28172879f193afb96017ebd44a41d1f43cb6e2c2', 'message': ""Encode header in latin-1 with wsgi_to_bytes\n\nPrevent encoding corruption in client's metadata during ssync\n\nCloses-Bug: #2020667\nChange-Id: I0ea464bcda16678997865667287aa11ea89cdcde\n""}, {'number': 6, 'created': '2023-07-10 14:20:39.000000000', 'files': ['swift/obj/server.py', 'test/unit/obj/test_ssync_sender.py', 'test/unit/obj/test_server.py', 'swift/obj/ssync_sender.py', 'swift/obj/ssync_receiver.py', 'test/unit/obj/test_ssync_receiver.py'], 'web_link': 'https://opendev.org/openstack/swift/commit/365c0ef005ca14691f8ba21f1e81d37ae7c0bfc0', 'message': ""Encode header in latin-1 with wsgi_to_bytes\n\nPrevent encoding corruption in client's metadata during ssync\n\nCloses-Bug: #2020667\nChange-Id: I0ea464bcda16678997865667287aa11ea89cdcde\n""}]",25,884240,365c0ef005ca14691f8ba21f1e81d37ae7c0bfc0,34,3,6,28499,,,0,"Encode header in latin-1 with wsgi_to_bytes

Prevent encoding corruption in client's metadata during ssync

Closes-Bug: #2020667
Change-Id: I0ea464bcda16678997865667287aa11ea89cdcde
",git fetch https://review.opendev.org/openstack/swift refs/changes/40/884240/1 && git format-patch -1 --stdout FETCH_HEAD,['swift/obj/ssync_sender.py'],1,52af7ea6857649742c1292d8bc9767043d183cab,bug2020667,"from swift.common.swob import wsgi_to_bytes msg.append(wsgi_to_bytes('%s: %s' % (key, value)))"," if six.PY2: msg.append(b'%s: %s' % (key, value)) else: msg.append(b'%s: %s' % ( key.encode('utf8', 'surrogateescape'), str(value).encode('utf8', 'surrogateescape')))",2,6
openstack%2Ftacker-specs~886944,openstack/tacker-specs,master,I71571607804b5ac1d2cd7a77cf34e89b1ec4af03,"Update Spec of ""Enhance Tacker API Access Control""",MERGED,2023-06-26 04:29:54.000000000,2023-07-10 17:28:54.000000000,2023-07-10 17:28:54.000000000,"[{'_account_id': 17255}, {'_account_id': 22348}, {'_account_id': 25701}, {'_account_id': 31668}, {'_account_id': 31730}, {'_account_id': 31857}, {'_account_id': 32707}]","[{'number': 1, 'created': '2023-06-26 04:29:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tacker-specs/commit/97227437a0201306d4a93117ca1a73f65b01e28d', 'message': 'Update Spec of ""Enhance Tacker API Access Control""\n\nThe spec of ""Enhancement of Tacker API Resource Access Control""\nwill be updated for the following items.\n* The attribute of ""namespace"" and the special roles of ""NAMESPACE"" are\n  changed to ""tenant"" and ""TENANT"" in Antelope\n* Add tenant control for VNF will be supported in Bobcat\n  (Remove the expression of ""CNF only"".)\n\nThis patch fixes these changes in the current spec.\n\nImplements: blueprint enhance-api-policy\nChange-Id: I71571607804b5ac1d2cd7a77cf34e89b1ec4af03\n'}, {'number': 2, 'created': '2023-07-04 23:51:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tacker-specs/commit/f09d5c1a8e791bb3c8444c247fe13f7b8156a539', 'message': 'Update Spec of ""Enhance Tacker API Access Control""\n\nThe spec of ""Enhancement of Tacker API Resource Access Control""\nwill be updated for the following items.\n* The attribute of ""namespace"" and the special roles of ""NAMESPACE"" are\n  changed to ""tenant"" and ""TENANT"" in Antelope\n* Add tenant control for VNF will be supported in Bobcat\n  (Remove the expression of ""CNF only"".)\n\nThis patch fixes these changes in the current spec.\n\nImplements: blueprint enhance-api-policy\nChange-Id: I71571607804b5ac1d2cd7a77cf34e89b1ec4af03\n'}, {'number': 3, 'created': '2023-07-05 00:30:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tacker-specs/commit/f2b80a3fe275b673e76018fd311055d6326aa055', 'message': 'Update Spec of ""Enhance Tacker API Access Control""\n\nThe spec of ""Enhancement of Tacker API Resource Access Control""\nwill be updated for the following items.\n* The attribute of ""namespace"" and the special roles of ""NAMESPACE"" are\n  changed to ""tenant"" and ""TENANT"" in Antelope\n* Add tenant control for VNF will be supported in Bobcat\n  (Remove the expression of ""CNF only"".)\n\nThis patch fixes these changes in the current spec.\n\nImplements: blueprint enhance-api-policy\nChange-Id: I71571607804b5ac1d2cd7a77cf34e89b1ec4af03\n'}, {'number': 4, 'created': '2023-07-10 07:26:28.000000000', 'files': ['specs/2023.1/enhance-tacker-policy.rst'], 'web_link': 'https://opendev.org/openstack/tacker-specs/commit/0b15b736da207c6381928ae0ab4f70dbfa44c89e', 'message': 'Update Spec of ""Enhance Tacker API Access Control""\n\nThe spec of ""Enhancement of Tacker API Resource Access Control""\nwill be updated for the following items.\n* The attribute of ""namespace"" and the special roles of ""NAMESPACE"" are\n  changed to ""tenant"" and ""TENANT"" in Antelope\n* Add tenant control for VNF will be supported in Bobcat\n  (Remove the expression of ""CNF only"".)\n\nThis patch fixes these changes in the current spec.\n\nImplements: blueprint enhance-api-policy\nChange-Id: I71571607804b5ac1d2cd7a77cf34e89b1ec4af03\n'}]",17,886944,0b15b736da207c6381928ae0ab4f70dbfa44c89e,27,7,4,34712,,,0,"Update Spec of ""Enhance Tacker API Access Control""

The spec of ""Enhancement of Tacker API Resource Access Control""
will be updated for the following items.
* The attribute of ""namespace"" and the special roles of ""NAMESPACE"" are
  changed to ""tenant"" and ""TENANT"" in Antelope
* Add tenant control for VNF will be supported in Bobcat
  (Remove the expression of ""CNF only"".)

This patch fixes these changes in the current spec.

Implements: blueprint enhance-api-policy
Change-Id: I71571607804b5ac1d2cd7a77cf34e89b1ec4af03
",git fetch https://review.opendev.org/openstack/tacker-specs refs/changes/44/886944/1 && git format-patch -1 --stdout FETCH_HEAD,['specs/2023.1/enhance-tacker-policy.rst'],1,97227437a0201306d4a93117ca1a73f65b01e28d,fix-enhance-policy," * - tenant - {""tenant"": ""default""} * - tenant - {""tenant"": ""default""} * - TENANT - tenant value - TENANT_default, TENANT_all * - TENANT - tenant value - TENANT_default -> {""tenant"": [""default""]} * - TENANT - tenant value - {""tenant"": ""default""} -> {""tenant"": [""default""]} as area, vendor and tenant. At this time, if the enhanced policy ""vnflcm_attrs_cmp"": ""area:%(area)s and vendor:%(vendor)s and tenant:%(tenant)s""* TENANT_default * TENANT_tenant_A * TENANT_all* TENANT_all* TENANT_all* TENANT_all* TENANT_all* TENANT_all* TENANT_all* TENANT_all"," * - namespace(CNF) - {""namespace"": ""default""} * - namespace(CNF) - {""namespace"": ""default""} * - NAMESPACE - namespace value - NAMESPACE_default, NAMESPACE_all * - NAMESPACE - namespace value - NAMESPACE_default -> {""namespace"": [""default""]} * - NAMESPACE - namespace value - {""namespace"": ""default""} -> {""namespace"": [""default""]} as area, vendor and namespace(CNF). At this time, if the enhanced policy ""vnflcm_attrs_cmp"": ""area:%(area)s and vendor:%(vendor)s and namespace:%(namespace)s""* NAMESPACE_default * NAMESPACE_namespace_A * NAMESPACE_all* NAMESPACE_all* NAMESPACE_all* NAMESPACE_all* NAMESPACE_all* NAMESPACE_all* NAMESPACE_all* NAMESPACE_all",25,26
openstack%2Ftacker-specs~878615,openstack/tacker-specs,master,I72c2c7887ceba4734b367f7e5bc78921eb0ab0a1,Add sphinx plantUML pluging,MERGED,2023-03-27 06:11:00.000000000,2023-07-10 17:25:47.000000000,2023-07-10 17:25:47.000000000,"[{'_account_id': 17255}, {'_account_id': 22348}, {'_account_id': 25701}, {'_account_id': 31857}, {'_account_id': 32102}]","[{'number': 1, 'created': '2023-03-27 06:11:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tacker-specs/commit/c5306c6105a6a27fdaa06dec0a7a9f5d4e6fc590', 'message': '[DNM] Add plantUML\n\nChange-Id: I72c2c7887ceba4734b367f7e5bc78921eb0ab0a1\n'}, {'number': 2, 'created': '2023-03-27 06:47:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tacker-specs/commit/109132688ece06fac9f4e4c3636f83380f2fc2af', 'message': '[DNM] Add plantUML\n\nChange-Id: I72c2c7887ceba4734b367f7e5bc78921eb0ab0a1\n'}, {'number': 3, 'created': '2023-03-27 07:04:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tacker-specs/commit/f8718f3f553c751566f2fb97aa5ea0b3b0780117', 'message': '[DNM] Add plantUML\n\nChange-Id: I72c2c7887ceba4734b367f7e5bc78921eb0ab0a1\n'}, {'number': 4, 'created': '2023-03-27 07:51:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tacker-specs/commit/08b7dce36bf43b6b1441d717088df39301c7b7f8', 'message': '[DNM] Add plantUML\n\nChange-Id: I72c2c7887ceba4734b367f7e5bc78921eb0ab0a1\n'}, {'number': 5, 'created': '2023-03-27 09:08:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tacker-specs/commit/feebd8d7f751e4ca02e194e735ba739f8a80dba0', 'message': '[DNM] Add plantUML\n\nChange-Id: I72c2c7887ceba4734b367f7e5bc78921eb0ab0a1\n'}, {'number': 6, 'created': '2023-03-27 09:30:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tacker-specs/commit/a43812e25da309e024845e1297bdeda544517704', 'message': '[DNM] Add plantUML\n\nChange-Id: I72c2c7887ceba4734b367f7e5bc78921eb0ab0a1\n'}, {'number': 7, 'created': '2023-03-27 10:18:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tacker-specs/commit/8ff398ab5fb6232699b2305dec085313a01a221d', 'message': '[DNM] Add plantUML\n\nChange-Id: I72c2c7887ceba4734b367f7e5bc78921eb0ab0a1\n'}, {'number': 8, 'created': '2023-03-27 10:28:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tacker-specs/commit/5cbb5411972a21c28cde0901ba7f045c99edc979', 'message': '[DNM] Add plantUML\n\nChange-Id: I72c2c7887ceba4734b367f7e5bc78921eb0ab0a1\n'}, {'number': 9, 'created': '2023-03-27 10:38:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tacker-specs/commit/8b9f1e5421f1634aa637ea51c5c59bd0aeb2a547', 'message': '[DNM] Add plantUML\n\nChange-Id: I72c2c7887ceba4734b367f7e5bc78921eb0ab0a1\n'}, {'number': 10, 'created': '2023-03-27 11:12:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tacker-specs/commit/d452852375f5ffa59ace4a63311261eb8ea73ac9', 'message': '[DNM] Add plantUML\n\nChange-Id: I72c2c7887ceba4734b367f7e5bc78921eb0ab0a1\n'}, {'number': 11, 'created': '2023-03-27 11:41:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tacker-specs/commit/c1dafc582038b82b6ead15e5dedbfad08ae1b2e8', 'message': '[DNM] Add plantUML\n\nChange-Id: I72c2c7887ceba4734b367f7e5bc78921eb0ab0a1\n'}, {'number': 12, 'created': '2023-03-27 11:59:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tacker-specs/commit/cb31cd31d4f43daae5585ff28757a1e6c4ba6047', 'message': '[DNM] Add plantUML\n\nChange-Id: I72c2c7887ceba4734b367f7e5bc78921eb0ab0a1\n'}, {'number': 13, 'created': '2023-03-28 03:05:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tacker-specs/commit/fcd56911148c8d6a3645b486b853d5d0b3b31e68', 'message': 'Add sphinx plantUML pluging\n\nThis patch enables the sphinx PlantUML extension. As PlantUML is often\nused in Tacker documents, authors of specs can re-use diagrams when\nthey write user guides with small revising.\n\nTo build plantUML with a sphinx PlantUML extension:\n- Updated conf.py\n- Updated requirements\n- Added plantuml.jar\n\nTo use the sphinx PlantUML extension in Zuul jobs:\n- Added bindep [1][2] to install graphviz\n- Added pre.yaml to install java [3]\n- Updated setup.cfg (this is necessary to place more than two\n  directories at the project root)\n\nOthers:\n- Added examples to 2023.2/placeholder.rst and template.rst\n\n[1] https://github.com/openstack/cinder-specs/blob/master/bindep.txt\n[2] https://docs.opendev.org/opendev/bindep/latest/readme.html\n[3] https://opendev.org/zuul/zuul-jobs/src/branch/master/roles/ensure-java\n\nChange-Id: I72c2c7887ceba4734b367f7e5bc78921eb0ab0a1\n'}, {'number': 14, 'created': '2023-07-09 13:15:05.000000000', 'files': ['tools/plantuml.jar', 'bindep.txt', 'specs/template.rst', 'specs/2023.2/placeholder.rst', 'playbooks/pre.yaml', 'README.rst', '.zuul.yaml', 'doc/source/conf.py', 'doc/requirements.txt', 'setup.cfg'], 'web_link': 'https://opendev.org/openstack/tacker-specs/commit/3779761ee4cfd59798d6ca6c800330d12d0dafa6', 'message': 'Add sphinx plantUML pluging\n\nThis patch enables the sphinx PlantUML extension. As PlantUML is often\nused in Tacker documents, authors of specs can re-use diagrams when\nthey write user guides with small revising.\n\nTo build plantUML with a sphinx PlantUML extension:\n- Updated conf.py\n- Updated requirements\n- Added plantuml.jar\n\nTo use the sphinx PlantUML extension in Zuul jobs:\n- Added bindep [1][2] to install graphviz\n- Added pre.yaml to install java [3]\n- Updated setup.cfg (this is necessary to place more than two\n  directories at the project root)\n\nOthers:\n- Added examples to 2023.2/placeholder.rst and template.rst\n\n[1] https://github.com/openstack/cinder-specs/blob/master/bindep.txt\n[2] https://docs.opendev.org/opendev/bindep/latest/readme.html\n[3] https://opendev.org/zuul/zuul-jobs/src/branch/master/roles/ensure-java\n\nChange-Id: I72c2c7887ceba4734b367f7e5bc78921eb0ab0a1\n'}]",11,878615,3779761ee4cfd59798d6ca6c800330d12d0dafa6,41,5,14,33455,,,0,"Add sphinx plantUML pluging

This patch enables the sphinx PlantUML extension. As PlantUML is often
used in Tacker documents, authors of specs can re-use diagrams when
they write user guides with small revising.

To build plantUML with a sphinx PlantUML extension:
- Updated conf.py
- Updated requirements
- Added plantuml.jar

To use the sphinx PlantUML extension in Zuul jobs:
- Added bindep [1][2] to install graphviz
- Added pre.yaml to install java [3]
- Updated setup.cfg (this is necessary to place more than two
  directories at the project root)

Others:
- Added examples to 2023.2/placeholder.rst and template.rst

[1] https://github.com/openstack/cinder-specs/blob/master/bindep.txt
[2] https://docs.opendev.org/opendev/bindep/latest/readme.html
[3] https://opendev.org/zuul/zuul-jobs/src/branch/master/roles/ensure-java

Change-Id: I72c2c7887ceba4734b367f7e5bc78921eb0ab0a1
",git fetch https://review.opendev.org/openstack/tacker-specs refs/changes/15/878615/1 && git format-patch -1 --stdout FETCH_HEAD,"['specs/ocata/nsd-support.rst', 'specs/xena/test_sol_with_robot_api_tests.rst', 'specs/victoria/support-notification-api-based-on-etsi-nfv-sol.rst', 'specs/wallaby/mgmt-driver-for-k8s-cluster.rst', 'specs/train/tacker-studio.rst', 'specs/2023.1/support-threshold-pm-interface.rst', 'specs/mitaka/tosca-parser-integration.rst', 'specs/2023.1/vnfm-autoheal-and-autoscale.rst', 'specs/ussuri/enhance_vnf_package_support.rst', 'specs/queens/zabbix-plugin.rst', 'specs/victoria/support-vnf-update-api-based-on-etsi-nfv-sol.rst', 'specs/victoria/add-event-alarm-policy.rst', 'specs/zed/db-migration-tool.rst', 'specs/wallaby/support-cnf-scale.rst', 'specs/pike/vnf-cluster-management-by-senlin.rst', 'specs/xena/index.rst', 'specs/yoga/support-heal-scale-in-user_lcm.rst', 'specs/zed/centos-stream-zuul.rst', 'specs/2023.1/enhance_placement_process.rst', 'specs/pike/encryption-with-barbican.rst', 'specs/wallaby/support-fundamental-vnf-lcm-based-on-ETSI-NFV.rst', 'specs/rocky/vdu-affinity-policy.rst', 'specs/xena/support-nfv-solv3-get-information.rst', 'specs/pike/python-openstackclient.rst', 'specs/yoga/prometheus-plugin-heal.rst', 'specs/victoria/add-artifacts.rst', 'specs/wallaby/support-change-external-VNF-connectivity-operation.rst', 'specs/wallaby/support-cnf-heal.rst', 'specs/2023.1/support-multi-conductors-onboarding.rst', 'specs/pike/persistent-block-storage.rst', 'specs/xena/support-nfv-solv3-start-and-terminate-vnf.rst', 'specs/victoria/index.rst', 'specs/2023.2/placeholder.rst', 'specs/zed/enhance_change_current_vnf_package_API.rst', 'specs/mitaka/enhanced-placement.rst', 'specs/2023.1/improving-mgmt-driver-log.rst', 'specs/victoria/enhancement_enhance-vnf-lcm-api-support.rst', 'specs/newton/index.rst', 'specs/xena/k8s-mgmtdriver-kubespray.rst', 'specs/zed/enhancement-container-update.rst', 'specs/pike/vnffg-scaling.rst', 'specs/mitaka/multi-site-feature.rst', 'specs/victoria/use_robot_api_tests.rst', 'specs/zed/support-v2-cnf-rollback.rst', 'specs/ussuri/vnf_parameter_update.rst', 'specs/yoga/add-sample-ansible-mgmt-driver.rst', 'specs/yoga/support-nfv-solv3-error-handling.rst', 'specs/zed/prometheus-plugin-autoheal-and-autoscale.rst', 'specs/ocata/tacker-API-framework.rst', 'specs/liberty/monitor-framework.rst', 'specs/train/vnf-rolling-upgrade.rst', 'specs/yoga/vim-monitor-feature.rst', 'specs/zed/enhance-multi-tenant-policy.rst', 'specs/ocata/tacker-vnfc.rst', 'specs/2023.1/enhance-tacker-policy.rst', 'specs/yoga/enhance-nfv-solv3-lcm-operation.rst', 'specs/ussuri/lcm-operation-with-lcm-operation-user-data.rst', 'specs/zed/individual-vnfc-management.rst', '.zuul.yaml', 'specs/victoria/support-scale-api-based-on-etsi-nfv-sol.rst', 'specs/zed/code-refactoring.rst', 'specs/pike/vnffg-autohealing.rst', 'specs/newton/alarm-based-monitoring-driver.rst', 'doc/source/index.rst', 'specs/yoga/index.rst', 'specs/queens/update-vnffg.rst', 'specs/zed/database-synchronization.rst', 'specs/wallaby/support-error-handling-based-on-ETSI-NFV.rst', 'specs/yoga/container-update.rst', 'specs/wallaby/mgmt-driver-for-k8s-heal.rst', 'specs/zed/enhance-cnf-operations.rst', 'specs/zed/support-v2-cnf-scale.rst', 'specs/2023.1/support-tacker-db-manage-postgresql.rst', 'specs/newton/manual-and-auto-scaling.rst', 'specs/ocata/vnf-inline-template.rst', 'specs/yoga/k8s-namespace.rst', 'specs/zed/enhance-cli-for-paging.rst', 'specs/stein/reservation-vnfm.rst', 'specs/train/index.rst', 'specs/queens/Kubernetes-as-VIM.rst', 'specs/ocata/index.rst', 'specs/ussuri/index.rst', 'specs/stein/index.rst', 'specs/xena/multi-version-api.rst', 'specs/xena/helmchart-k8s-vim.rst', 'specs/zed/faultnotification-autoheal.rst', 'specs/newton/tacker-vnffg.rst', 'specs/wallaby/mgmt-driver-for-k8s-scale.rst', 'specs/newton/event_logging.rst', 'specs/xena/cir-k8s-cluster.rst', 'specs/rocky/shared_vim_for_policy_action.rst', 'specs/victoria/action_driver.rst', 'specs/liberty/index.rst', 'specs/yoga/add-vnf-package-sample-for-practical-use-cases.rst', 'specs/ussuri/etsi-nfv-sol-rest-api-for-VNF-deployment.rst', 'specs/yoga/upgrade-vnf-package.rst', 'specs/wallaby/hardware-aware-pod-affinity.rst', 'specs/train/vnf_package_support.rst', 'specs/zed/index.rst', 'specs/victoria/support-sol003-vnfm-operations.rst', 'specs/queens/kubernetes-type-for-containerized-VNF.rst', 'specs/yoga/multi-tenant-policy.rst', 'specs/wallaby/mgmt-driver-for-ha-k8s.rst', 'specs/mitaka/index.rst', 'specs/yoga/paging-query-result.rst', 'specs/train/multi-interface-container.rst', 'specs/2023.1/add-sample-coordination.rst', 'specs/template.rst', 'specs/pike/index.rst', 'specs/victoria/support-etsi-nfv-based-errorhandling.rst', 'specs/2023.1/srbac-implement-project-personas.rst', 'specs/zed/support_multi_artifact_of_ansible_driver.rst', 'specs/rocky/index.rst', 'specs/rocky/vnffg-ns.rst', 'specs/zed/support-v2-cnf-heal.rst', 'specs/pike/mistral_vim_monitor.rst', 'specs/mitaka/automatic-resource-creation.rst', 'specs/queens/index.rst', 'specs/newton/tacker-networking-sfc.rst', 'doc/source/conf.py', 'specs/stein/vdu-auto-healing.rst', 'doc/source/plantuml.jar', 'specs/pike/mistral_vnf_monitor_policies.rst', 'specs/xena/pv-k8s-cluster.rst', 'specs/wallaby/index.rst', 'specs/zed/support-openid-k8s-vim.rst', 'specs/stein/support-force-delete.rst', 'specs/victoria/container-network-function.rst', 'specs/xena/support-hot-according-to-nfv-sol014.rst', 'specs/2023.1/index.rst', 'doc/requirements.txt', 'specs/liberty/tacker-api-mano.rst']",132,c5306c6105a6a27fdaa06dec0a7a9f5d4e6fc590,plantuml,,".. This work is licensed under a Creative Commons Attribution 3.0 Unported License. http://creativecommons.org/licenses/by/3.0/legalcode ========================================== Implement Tacker API v1 based on NFV MANO ========================================== https://blueprints.launchpad.net/tacker/+spec/tacker-api-mano This spec describes the plan to introduce new Tacker REST API endpoints based on ETSI NFV MANO standards [1]. The current REST API endpoints based on 'servicevm' standards will be retained for backward compatibility and support. Problem description =================== Tacker service currently implements REST API endpoints based on 'servicevm' standards. However, Tacker is built on principles of an NFV orchestrator with in-built VNF Manager as described in the ETSI NFV MANO architecture [1]. Tacker should support and implement CRUD operations on VNF resources. Towards this, REST API endpoints based on VNF has to be introduced which can then be invoked by a user using an independent client or through the python-tackerclient itself. Proposed change =============== The actual task of moving Tacker from 'servicevm' to NFV MANO standards in entirety is complex and will be done in phases. As part of this spec, the task concerning REST API endpoints based on NFV MANO will be introduced and implemented. The proposed changes involve the following action items: * Tacker REST API extension will be moved from 'servicevm' to 'vnfm'. * Add two new REST API end points 'vnf' and 'vnfd' to describe VNF resources. * The exiting resources 'device' and 'device_template' will be moved under the new 'vnfm' extension. * The implementation of 'vnfm' REST API will be a wrapper around existing 'servicevm' implementation. * The 'vnfm' resource attributes will be the same as 'servicevm' resources except for 'services' attribute which is not being used in the project currently. The new 'vnfm' extension will be integrated to Tacker v1 REST API. The current implementation of 'servicevm' extension will be retained for backward compatibility. Alternatives ------------ Other solution is to integrate the Pecan framework in to Tacker. This involves re-factoring the entire project in one phase to update to NFV MANO standards. Currently, tacker is based on stable Kilo release branch and does not support Pecan framework. This solution can only be implemented when Tacker moves to master release for OpenStack services. The high-level tasks include: * Modify plugin and database backend implementation to move from servicevm to NFV MANO standards. * Move out of home grown REST framework and implement the Pecan framework to describe and implement CRUD operations on VNF resources. Data model impact ----------------- None REST API impact --------------- New extension 'vnfm' will be introduced in v1 which will implement REST API end points as described below: **/vnfd** :: +---------------------------------------------------------------------------+ |Attribute |Type |Access |Default |Validation/ |Description | |Name | | |Value |Conversion | | +---------------------------------------------------------------------------+ |id |string |RO, All |generated |N/A |identity | | |(UUID) | | | | | +---------------------------------------------------------------------------+ |name |string |RW, All |'' |string |human+readable | | | | | | |name | +---------------------------------------------------------------------------+ |description |string |RW, All |'' |string |description of | | | | | | |template | +---------------------------------------------------------------------------+ |attributes |dict |RW, All |None |dict |TOSCA YAML file | | | | | | | | +---------------------------------------------------------------------------+ |infra_driver |string |RW, All |heat |string |driver to provision| | | | | | |VNF | +---------------------------------------------------------------------------+ |mgmt_driver |string |RW All |noop |string |driver to configure| | | | | | |VNF | +---------------------------------------------------------------------------+ |service_types |list |RW, All |[] |service_type|NFV service type | | | | | |_list |(VNF, NSD) | +---------------------------------------------------------------------------+ |tenant_id |string |RO, All |N/A |string |project id to | | | | | | |launch VNF | +--------------+-------+--------+----------+--------------------------------+ **/vnf** :: +----------------------------------------------------------------------------+ |Attribute |Type |Access |Default |Validation/ |Description | |Name | | |Value |Conversion | | +----------------------------------------------------------------------------+ |id |string |RO, All |generated |N/A |identity | | |(UUID) | | | | | +----------------------------------------------------------------------------+ |name |string |RW, All |'' |string |human+readable | | | | | | |name | +----------------------------------------------------------------------------+ |description |string |RW, All |'' |string |description of | | | | | | |template | +----------------------------------------------------------------------------+ |attributes |dict |RW, All |None |dict |TOSCA YAML file | | | | | | | | +----------------------------------------------------------------------------+ |instance_id |string |RO, All |generated |string |identity of | | | | | | |VM instance | +----------------------------------------------------------------------------+ |mgmt_url |string |RO, All |None |string |IP address of | | | | | | |VNF management net. | +----------------------------------------------------------------------------+ |tenant_id |string |RW, All |generated |string |project id to | | | | | | |launch VNF | +----------------------------------------------------------------------------+ |template_id |string |RW, All |None |string |VNFD id | | | | | | | | +----------------------------------------------------------------------------+ |status |string |RO, All |generated |string |current state | | | | | | |of VNF | +--------------+-------+--------+----------+---------------------------------+ |service_ |list |RW, All |[] |service_ |VNF role for a given| |contexts | | | |context_list|network | +--------------+-------+--------+----------+---------------------------------+ Security impact --------------- None Notifications impact -------------------- None Other end user impact --------------------- There will be no direct impact on python-tackerclient in the way the user will interact with the client. With the current implementation, VNF resource requests were internally forwarded to 'servicevm' resource requests. However, with the new implementation, python-tackerclient will directly invoke the 'vnfm' REST API for VNF resource requests. Performance Impact ------------------ None Other deployer impact --------------------- None Developer impact ---------------- None Implementation ============== Assignee(s) ----------- Primary assignee: sseetha Other contributors: None Work Items ---------- 1. Add new extension 'vnfm' to tacker v1 and deprecate the existing 'servicevm' extension. 2. The new extension should internally call servicevm plugin base. 3. Modify VNFM API requests from tackerclient to reflect VNF resources in request body and remove the current wrapper implementation around 'servicevm'. 4. Add unit tests for the new extension and contribute to existing API related test cases. 5. Add REST api doc file that will capture the 'vnfm' extension in detail. Dependencies ============ None Testing ======= As of now, there are no tempest tests added to Tacker and will be tracked as a separate activity. Documentation Impact ==================== A documentation page capturing the new REST API VNF v1 resources will be added in Tacker wiki link [2]. References ========== [1] http://www.ietf.org/proceedings/88/slides/slides-88-opsawg-6.pdf [2] https://wiki.openstack.org/wiki/Tacker/API ",22,60557
openstack%2Fneutron~886408,openstack/neutron,master,Iad73856cb86b04f8d2a10b186befa4aa8c6a933d,Return back the test_dvr_router_interface_mtu_update test case,MERGED,2023-06-19 15:16:48.000000000,2023-07-10 17:18:13.000000000,2023-07-10 17:16:57.000000000,"[{'_account_id': 5948}, {'_account_id': 8313}, {'_account_id': 9845}, {'_account_id': 16688}, {'_account_id': 22348}]","[{'number': 1, 'created': '2023-06-19 15:16:48.000000000', 'files': ['neutron/tests/functional/agent/l3/test_dvr_router.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/57e860ca1996d4afa8ede87239b53395ee55ef03', 'message': ""Return back the test_dvr_router_interface_mtu_update test case\n\nThis patch is actually a partial cherry-pick of the commit\nb5dd6efdca0aa6e7405a55d66c7042a49ec72214 by Slawek Kaplonski.\nBy some chance the commit 3a9a17ad8216d039ca3dadce0e8fc160f3ec18ba\nremoves this test case, although it shoudldn't\n\nRelated-Bug: #1933273\nRelated-Bug: #2024381\n\n(partially cherry picked from commit\nb5dd6efdca0aa6e7405a55d66c7042a49ec72214)\n\nChange-Id: Iad73856cb86b04f8d2a10b186befa4aa8c6a933d\n""}]",2,886408,57e860ca1996d4afa8ede87239b53395ee55ef03,12,5,1,28722,,,0,"Return back the test_dvr_router_interface_mtu_update test case

This patch is actually a partial cherry-pick of the commit
b5dd6efdca0aa6e7405a55d66c7042a49ec72214 by Slawek Kaplonski.
By some chance the commit 3a9a17ad8216d039ca3dadce0e8fc160f3ec18ba
removes this test case, although it shoudldn't

Related-Bug: #1933273
Related-Bug: #2024381

(partially cherry picked from commit
b5dd6efdca0aa6e7405a55d66c7042a49ec72214)

Change-Id: Iad73856cb86b04f8d2a10b186befa4aa8c6a933d
",git fetch https://review.opendev.org/openstack/neutron refs/changes/08/886408/1 && git format-patch -1 --stdout FETCH_HEAD,['neutron/tests/functional/agent/l3/test_dvr_router.py'],1,57e860ca1996d4afa8ede87239b53395ee55ef03,bug/2024381," def _test_router_interface_mtu_update(self, ha): original_mtu = 1450 router_info = self.generate_dvr_router_info( enable_ha=ha, enable_snat=True) router_info['_interfaces'][0]['mtu'] = original_mtu router_info['gw_port']['mtu'] = original_mtu router_info[lib_constants.SNAT_ROUTER_INTF_KEY][0]['mtu'] = ( original_mtu) router = self.manage_router(self.agent, router_info) if ha: utils.wait_until_true(lambda: router.ha_state == 'primary') # Keepalived notifies of a state transition when it starts, # not when it ends. Thus, we have to wait until keepalived finishes # configuring everything. We verify this by waiting until the last # device has an IP address. device = router.router[lib_constants.INTERFACE_KEY][-1] device_exists = functools.partial( self.device_exists_with_ips_and_mac, device, router.get_internal_device_name, router.ns_name) utils.wait_until_true(device_exists) interface_name = router.get_internal_device_name( router_info['_interfaces'][0]['id']) gw_interface_name = router.get_external_device_name( router_info['gw_port']['id']) snat_internal_port = router_info[lib_constants.SNAT_ROUTER_INTF_KEY] snat_interface_name = router._get_snat_int_device_name( snat_internal_port[0]['id']) snat_namespace = dvr_snat_ns.SnatNamespace.get_snat_ns_name( router_info['id']) self.assertEqual( original_mtu, ip_lib.IPDevice(interface_name, router.ns_name).link.mtu) self.assertEqual( original_mtu, ip_lib.IPDevice(gw_interface_name, snat_namespace).link.mtu) self.assertEqual( original_mtu, ip_lib.IPDevice(snat_interface_name, snat_namespace).link.mtu) updated_mtu = original_mtu + 1 router_info_copy = copy.deepcopy(router_info) router_info_copy['_interfaces'][0]['mtu'] = updated_mtu router_info_copy['gw_port']['mtu'] = updated_mtu router_info_copy[lib_constants.SNAT_ROUTER_INTF_KEY][0]['mtu'] = ( updated_mtu) self.agent._process_updated_router(router_info_copy) self.assertEqual( updated_mtu, ip_lib.IPDevice(interface_name, router.ns_name).link.mtu) self.assertEqual( updated_mtu, ip_lib.IPDevice(gw_interface_name, snat_namespace).link.mtu) self.assertEqual( updated_mtu, ip_lib.IPDevice(snat_interface_name, snat_namespace).link.mtu) def test_dvr_router_interface_mtu_update(self): self._test_router_interface_mtu_update(ha=False)",,66,0
openstack%2Foctavia-tempest-plugin~885723,openstack/octavia-tempest-plugin,master,Ia8f73e9fa07cbfaea5024047c650dfe5ca747420,Add stable/2023.1 jobs on master gate,MERGED,2023-06-09 07:25:51.000000000,2023-07-10 16:34:35.000000000,2023-07-10 16:32:45.000000000,"[{'_account_id': 22348}, {'_account_id': 29244}, {'_account_id': 34429}]","[{'number': 1, 'created': '2023-06-09 07:25:51.000000000', 'files': ['zuul.d/projects.yaml', 'zuul.d/jobs.yaml'], 'web_link': 'https://opendev.org/openstack/octavia-tempest-plugin/commit/63b5c60964578d2214ab6bcaa6c9bca733239263', 'message': 'Add stable/2023.1 jobs on master gate\n\nAs 2023.1 is released, we should add its job on master\ngate to keep branchless tempest plugins compatible\nto stable branch.\n\nRef: Tempest plugins guide for stable branch testing:\n- https://docs.openstack.org/tempest/latest/stable_branch_testing_policy.html\n\nChange-Id: Ia8f73e9fa07cbfaea5024047c650dfe5ca747420\n'}]",2,885723,63b5c60964578d2214ab6bcaa6c9bca733239263,12,3,1,8556,,,0,"Add stable/2023.1 jobs on master gate

As 2023.1 is released, we should add its job on master
gate to keep branchless tempest plugins compatible
to stable branch.

Ref: Tempest plugins guide for stable branch testing:
- https://docs.openstack.org/tempest/latest/stable_branch_testing_policy.html

Change-Id: Ia8f73e9fa07cbfaea5024047c650dfe5ca747420
",git fetch https://review.opendev.org/openstack/octavia-tempest-plugin refs/changes/23/885723/1 && git format-patch -1 --stdout FETCH_HEAD,"['zuul.d/projects.yaml', 'zuul.d/jobs.yaml']",2,63b5c60964578d2214ab6bcaa6c9bca733239263,2023-1-stable-job, name: octavia-v2-dsvm-noop-api-stable-2023-1 parent: octavia-v2-dsvm-noop-api nodeset: octavia-single-node-ubuntu-jammy override-checkout: stable/2023.1 - job: name: octavia-v2-dsvm-scenario-stable-2023-1 parent: octavia-v2-dsvm-scenario nodeset: octavia-single-node-ubuntu-jammy override-checkout: stable/2023.1 - job: name: octavia-v2-dsvm-scenario-traffic-ops-stable-2023-1 parent: octavia-v2-dsvm-scenario-stable-2023-1 vars: tempest_test_regex: ^octavia_tempest_plugin.tests.scenario.v2.*traffic_ops - job: name: octavia-v2-dsvm-scenario-non-traffic-ops-stable-2023-1 parent: octavia-v2-dsvm-scenario-stable-2023-1 vars: tempest_test_regex: ^octavia_tempest_plugin.tests.scenario.v2.(?!.*traffic_ops) - job: name: octavia-v2-dsvm-tls-barbican-stable-2023-1 parent: octavia-v2-dsvm-tls-barbican nodeset: octavia-single-node-ubuntu-jammy override-checkout: stable/2023-1 - job: name: octavia-v2-act-stdby-dsvm-scenario-stable-2023-1 parent: octavia-v2-act-stdby-dsvm-scenario nodeset: octavia-single-node-ubuntu-jammy override-checkout: stable/2023-1 - job:,,46,0
openstack%2Foctavia-tempest-plugin~865513,openstack/octavia-tempest-plugin,master,Id851d5a5388e290770c617267daa9fdd0a50dae6,Adding jobs for stable/zed,MERGED,2022-11-24 08:33:17.000000000,2023-07-10 16:25:50.000000000,2023-07-10 16:23:54.000000000,"[{'_account_id': 22348}, {'_account_id': 29244}, {'_account_id': 31664}, {'_account_id': 32761}, {'_account_id': 34429}]","[{'number': 1, 'created': '2022-11-24 08:33:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/octavia-tempest-plugin/commit/e0be9a3cc3164cc5445ad4c75f554077339a9019', 'message': 'Adding jobs for stable/zed\n\nChange-Id: Id851d5a5388e290770c617267daa9fdd0a50dae6\n'}, {'number': 2, 'created': '2023-06-09 07:16:50.000000000', 'files': ['zuul.d/projects.yaml', 'zuul.d/jobs.yaml'], 'web_link': 'https://opendev.org/openstack/octavia-tempest-plugin/commit/c45b5546e42f590556d1abbff322def7c16c4f03', 'message': 'Adding jobs for stable/zed\n\nChange-Id: Id851d5a5388e290770c617267daa9fdd0a50dae6\n'}]",8,865513,c45b5546e42f590556d1abbff322def7c16c4f03,28,5,2,29244,,,0,"Adding jobs for stable/zed

Change-Id: Id851d5a5388e290770c617267daa9fdd0a50dae6
",git fetch https://review.opendev.org/openstack/octavia-tempest-plugin refs/changes/13/865513/1 && git format-patch -1 --stdout FETCH_HEAD,"['zuul.d/projects.yaml', 'zuul.d/jobs.yaml']",2,e0be9a3cc3164cc5445ad4c75f554077339a9019,, name: octavia-v2-dsvm-noop-api-stable-zed parent: octavia-v2-dsvm-noop-api nodeset: octavia-single-node-ubuntu-focal override-checkout: stable/zed - job: name: octavia-v2-dsvm-scenario-stable-zed parent: octavia-v2-dsvm-scenario nodeset: octavia-single-node-ubuntu-focal override-checkout: stable/zed - job: name: octavia-v2-dsvm-tls-barbican-stable-zed parent: octavia-v2-dsvm-tls-barbican nodeset: octavia-single-node-ubuntu-focal override-checkout: stable/zed - job: name: octavia-v2-act-stdby-dsvm-scenario-stable-zed parent: octavia-v2-act-stdby-dsvm-scenario nodeset: octavia-single-node-ubuntu-focal override-checkout: stable/zed - job:,,32,0
openstack%2Fmanila-tempest-plugin~868340,openstack/manila-tempest-plugin,master,Ibca3fa93ac6ee382baa3fad256ea438d6596608b,Replication: verify access rules in detail,NEW,2022-12-23 10:01:59.000000000,2023-07-10 15:36:33.000000000,,"[{'_account_id': 16643}, {'_account_id': 22348}, {'_account_id': 29632}]","[{'number': 1, 'created': '2022-12-23 10:01:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/manila-tempest-plugin/commit/d72fa7f0c8915865274991a016b7e3e070dc759a', 'message': 'Replication: verify access rules in detail\n\nRelated-bug: #2000253\nChange-Id: Ibca3fa93ac6ee382baa3fad256ea438d6596608b\n'}, {'number': 2, 'created': '2022-12-23 11:58:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/manila-tempest-plugin/commit/99df094dea774c2b249e7ff63ade66ca8dc29efc', 'message': 'Replication: verify access rules in detail\n\nRelated-bug: #2000253\nDepends-On: Ie7ddd9f631510ba97e92a1eb0eb9a5d944ec1b3b\nChange-Id: Ibca3fa93ac6ee382baa3fad256ea438d6596608b\n'}, {'number': 3, 'created': '2023-01-05 09:42:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/manila-tempest-plugin/commit/a8320a4972049a1b0da7cc878350d0e42df0510b', 'message': 'Replication: verify access rules in detail\n\nRelated-bug: #2000253\nDepends-On: Ie7ddd9f631510ba97e92a1eb0eb9a5d944ec1b3b\nChange-Id: Ibca3fa93ac6ee382baa3fad256ea438d6596608b\n'}, {'number': 4, 'created': '2023-04-13 18:36:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/manila-tempest-plugin/commit/e64324fbfda18b6ce8b842d09fab42294275334e', 'message': 'Replication: verify access rules in detail\n\nRelated-bug: #2000253\nChange-Id: Ibca3fa93ac6ee382baa3fad256ea438d6596608b\n'}, {'number': 5, 'created': '2023-04-13 18:37:50.000000000', 'files': ['manila_tempest_tests/tests/api/test_replication.py'], 'web_link': 'https://opendev.org/openstack/manila-tempest-plugin/commit/0db023abcec7d20b2491d6d770dd6fff69813e6e', 'message': 'Replication: verify access rules in detail\n\nRelated-bug: #2000253\nDepends-On: Ie7ddd9f631510ba97e92a1eb0eb9a5d944ec1b3b\nChange-Id: Ibca3fa93ac6ee382baa3fad256ea438d6596608b\n'}]",9,868340,0db023abcec7d20b2491d6d770dd6fff69813e6e,27,3,5,18816,,,0,"Replication: verify access rules in detail

Related-bug: #2000253
Depends-On: Ie7ddd9f631510ba97e92a1eb0eb9a5d944ec1b3b
Change-Id: Ibca3fa93ac6ee382baa3fad256ea438d6596608b
",git fetch https://review.opendev.org/openstack/manila-tempest-plugin refs/changes/40/868340/1 && git format-patch -1 --stdout FETCH_HEAD,['manila_tempest_tests/tests/api/test_replication.py'],1,d72fa7f0c8915865274991a016b7e3e070dc759a,bug/2000253," access_level = 'ro' access_level=access_level) # verify rule's values rules_list = self.shares_v2_client.list_access_rules( self.shares[0][""id""])['access_list'] self.assertEqual(1, len(rules_list)) self.assertEqual(access_type, rules_list[0][""access_type""]) self.assertEqual(access_to, rules_list[0][""access_to""]) self.assertEqual(access_level, rules_list[0][""access_level""]) self.assertEqual(constants.RULE_STATE_ACTIVE, rules_list[0][""state""]) access_level = 'ro' access_level=access_level) # verify rule's values rules_list = self.shares_v2_client.list_access_rules( self.shares[0][""id""])['access_list'] self.assertEqual(1, len(rules_list)) self.assertEqual(access_type, rules_list[0][""access_type""]) self.assertEqual(access_to, rules_list[0][""access_to""]) self.assertEqual(access_level, rules_list[0][""access_level""]) self.assertEqual(constants.RULE_STATE_ACTIVE, rules_list[0][""state""]) access_level = 'ro' access_level=access_level) self.assertEqual(access_level, rules_list[0][""access_level""]) self.assertEqual(constants.RULE_STATE_ACTIVE, rules_list[0][""state""])"," access_level='ro') access_level='ro') access_level='ro') self.assertEqual('ro', rules_list[0][""access_level""])",26,4
openstack%2Fcloudkitty~887752,openstack/cloudkitty,master,If217a639f9af1e2693e6a132e46033df6bf96415,Fix random unit test failures,MERGED,2023-07-06 06:49:56.000000000,2023-07-10 15:01:56.000000000,2023-07-10 15:00:48.000000000,"[{'_account_id': 22348}, {'_account_id': 25277}, {'_account_id': 28356}]","[{'number': 1, 'created': '2023-07-06 06:49:56.000000000', 'files': ['cloudkitty/tests/storage/v2/test_storage_unit.py'], 'web_link': 'https://opendev.org/openstack/cloudkitty/commit/b460fd937fd2c8cc83979efa1abb7fa82d40a3f7', 'message': ""Fix random unit test failures\n\nAs per https://bugs.debian.org/1029646, Cloudkitty often fails to build\nas it fails its unit tests during the package build. This error happens\nrandomly. Sometimes it fails, sometimes it does not fail, but it's\nclearly a false positive, because we don't really want the test to fail\nin such case.\n\nThis patch makes it a lot less likely (10 times less) to happen by\nincreasing the tolerance.\n\nChange-Id: If217a639f9af1e2693e6a132e46033df6bf96415\n""}]",0,887752,b460fd937fd2c8cc83979efa1abb7fa82d40a3f7,8,3,1,6476,,,0,"Fix random unit test failures

As per https://bugs.debian.org/1029646, Cloudkitty often fails to build
as it fails its unit tests during the package build. This error happens
randomly. Sometimes it fails, sometimes it does not fail, but it's
clearly a false positive, because we don't really want the test to fail
in such case.

This patch makes it a lot less likely (10 times less) to happen by
increasing the tolerance.

Change-Id: If217a639f9af1e2693e6a132e46033df6bf96415
",git fetch https://review.opendev.org/openstack/cloudkitty refs/changes/52/887752/1 && git format-patch -1 --stdout FETCH_HEAD,['cloudkitty/tests/storage/v2/test_storage_unit.py'],1,b460fd937fd2c8cc83979efa1abb7fa82d40a3f7,," abs(expected_total - float(returned_total)), 0.0001) abs(expected_qty - float(returned_qty)), 0.0001) 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001,"," abs(expected_total - float(returned_total)), 0.00001) abs(expected_qty - float(returned_qty)), 0.00001) 0.00001, 0.00001, 0.00001, 0.00001, 0.00001, 0.00001, 0.00001, 0.00001,",10,10
openstack%2Fkeystone~875766,openstack/keystone,master,Ifd4487c4566853244c4b2c90a178b1067c17fbc6,Remove unnecessary removal of pyc files,MERGED,2023-02-28 17:28:53.000000000,2023-07-10 14:43:15.000000000,2023-07-10 14:41:55.000000000,"[{'_account_id': 597}, {'_account_id': 7414}, {'_account_id': 14250}, {'_account_id': 22348}]","[{'number': 1, 'created': '2023-02-28 17:28:53.000000000', 'files': ['tox.ini'], 'web_link': 'https://opendev.org/openstack/keystone/commit/cbe2f7f6f22fbc33cfc3e5a3ffc011258a83dc40', 'message': ""Remove unnecessary removal of pyc files\n\nIn change I8fcd9370a6adbfe8bbb2ce441a6f2efad45d089a, we started setting\nthe 'PYTHONDONTWRITEBYTECODE=1' flag. With this set, Python won't\ngenerate pyc files. As these files aren't generated, there's no need to\nremove them. Remove the 'find' calls that were doing this.\n\nChange-Id: Ifd4487c4566853244c4b2c90a178b1067c17fbc6\nSigned-off-by: Stephen Finucane <sfinucan@redhat.com>\n""}]",0,875766,cbe2f7f6f22fbc33cfc3e5a3ffc011258a83dc40,10,4,1,15334,,,0,"Remove unnecessary removal of pyc files

In change I8fcd9370a6adbfe8bbb2ce441a6f2efad45d089a, we started setting
the 'PYTHONDONTWRITEBYTECODE=1' flag. With this set, Python won't
generate pyc files. As these files aren't generated, there's no need to
remove them. Remove the 'find' calls that were doing this.

Change-Id: Ifd4487c4566853244c4b2c90a178b1067c17fbc6
Signed-off-by: Stephen Finucane <sfinucan@redhat.com>
",git fetch https://review.opendev.org/openstack/keystone refs/changes/66/875766/1 && git format-patch -1 --stdout FETCH_HEAD,['tox.ini'],1,cbe2f7f6f22fbc33cfc3e5a3ffc011258a83dc40,trivial,," find keystone -type f -name ""*.pyc"" -delete find find keystone -type f -name ""*.pyc"" -delete find keystone -type f -name ""*.pyc"" -delete find keystone -type f -name ""*.pyc"" -delete find keystone -type f -name ""*.pyc"" -delete",0,6
openstack%2Ftripleo-upgrade~873251,openstack/tripleo-upgrade,stable/wallaby,Ide4d840ba8e42ef57b7bf748a65307d4ed5cc9a6,workload : generate traffic to the vm.,MERGED,2023-02-09 12:40:43.000000000,2023-07-10 14:23:53.000000000,2023-07-10 14:23:53.000000000,"[{'_account_id': 8297}, {'_account_id': 11166}, {'_account_id': 22348}, {'_account_id': 33080}]","[{'number': 1, 'created': '2023-02-09 12:40:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-upgrade/commit/88486281226956ac3a843f99e56152f84e62d813', 'message': 'workload : generate traffic to the vm.\n\nSome issues on the dataplane are more likely to happen when some\ntraffic have happen on the vm. Furthermore it match more closely what\ncustomer would have (running vm with existing traffic)\n\nThis patch add a run of iperf during 1 minute to simulate that traffic\njust after the vm has been created.\n\nWe only do that for the ""workload"" option.\n\nWe also add:\n - -o pipefail: to make sure errors are caught, note that -e would\n   require major refactoring and thus in not enabled in this review;\n - prepopulate ~/vm_ip.sh so that it doesn\'t have to be re-calculated later.\n\nChange-Id: Ide4d840ba8e42ef57b7bf748a65307d4ed5cc9a6\n'}, {'number': 2, 'created': '2023-02-09 15:42:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-upgrade/commit/6bce5a10bc8a42d166865538c75cc126100098f2', 'message': 'workload : generate traffic to the vm.\n\nSome issues on the dataplane are more likely to happen when some\ntraffic have happen on the vm. Furthermore it match more closely what\ncustomer would have (running vm with existing traffic)\n\nThis patch add a run of iperf during 1 minute to simulate that traffic\njust after the vm has been created.\n\nWe only do that for the ""workload"" option.\n\nWe also add:\n - -o pipefail: to make sure errors are caught, note that -e would\n   require major refactoring and thus in not enabled in this review;\n - prepopulate ~/vm_ip.sh so that it doesn\'t have to be re-calculated later.\n\nChange-Id: Ide4d840ba8e42ef57b7bf748a65307d4ed5cc9a6\n'}, {'number': 3, 'created': '2023-02-09 17:12:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-upgrade/commit/51d23f5cb899e95d95d76fb7986de0e0b0b80af5', 'message': 'workload : generate traffic to the vm.\n\nSome issues on the dataplane are more likely to happen when some\ntraffic have happen on the vm. Furthermore it match more closely what\ncustomer would have (running vm with existing traffic)\n\nThis patch add a run of iperf during 1 minute to simulate that traffic\njust after the vm has been created.\n\nWe only do that for the ""workload"" option.\n\nWe also add:\n - -o pipefail: to make sure errors are caught, note that -e would\n   require major refactoring and thus in not enabled in this review;\n - prepopulate ~/vm_ip.sh so that it doesn\'t have to be re-calculated later.\n\nChange-Id: Ide4d840ba8e42ef57b7bf748a65307d4ed5cc9a6\n'}, {'number': 4, 'created': '2023-02-09 17:26:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-upgrade/commit/9bb794153fd5c1ab475372b0ef33a6dd820ea394', 'message': 'workload : generate traffic to the vm.\n\nSome issues on the dataplane are more likely to happen when some\ntraffic have happen on the vm. Furthermore it match more closely what\ncustomer would have (running vm with existing traffic)\n\nThis patch add a run of iperf during 1 minute to simulate that traffic\njust after the vm has been created.\n\nWe only do that for the ""workload"" option.\n\nWe also add:\n - -o pipefail: to make sure errors are caught, note that -e would\n   require major refactoring and thus in not enabled in this review;\n - prepopulate ~/vm_ip.sh so that it doesn\'t have to be re-calculated later.\n\nNote that a weird templating issue force the ""}"" to be before the else\nthe endif templating clauses in set_vm_ip or else the ""}"" is rendered\nlike this:\n\n    VM_IP=""${INSTANCE_FIP}""}\n\nwhich is a shell syntax error.\n\nChange-Id: Ide4d840ba8e42ef57b7bf748a65307d4ed5cc9a6\n'}, {'number': 5, 'created': '2023-02-15 14:23:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-upgrade/commit/a108d1d536e1052896d87b7ec5dcd556e8ac06df', 'message': 'workload : generate traffic to the vm.\n\nSome issues on the dataplane are more likely to happen when some\ntraffic have happen on the vm. Furthermore it match more closely what\ncustomer would have (running vm with existing traffic)\n\nThis patch add a run of iperf during 1 minute to simulate that traffic\njust after the vm has been created.\n\nWe only do that for the ""workload"" option.\n\nWe also add:\n - -o pipefail: to make sure errors are caught, note that -e would\n   require major refactoring and thus in not enabled in this review;\n - prepopulate ~/vm_ip.sh so that it doesn\'t have to be re-calculated later.\n\nNote that a weird templating issue force the ""}"" to be before the else\nthe endif templating clauses in set_vm_ip or else the ""}"" is rendered\nlike this:\n\n    VM_IP=""${INSTANCE_FIP}""}\n\nwhich is a shell syntax error.\n\nChange-Id: Ide4d840ba8e42ef57b7bf748a65307d4ed5cc9a6\n'}, {'number': 6, 'created': '2023-02-20 13:08:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-upgrade/commit/998bfd8eeb3baeed159274a248c54b173526edb2', 'message': 'workload : generate traffic to the vm.\n\nSome issues on the dataplane are more likely to happen when some\ntraffic have happen on the vm. Furthermore it match more closely what\ncustomer would have (running vm with existing traffic)\n\nThis patch add a run of iperf during 1 minute to simulate that traffic\njust after the vm has been created.\n\nWe only do that for the ""workload"" option.\n\nWe also add:\n - -o pipefail: to make sure errors are caught, note that -e would\n   require major refactoring and thus in not enabled in this review;\n - prepopulate ~/vm_ip.sh so that it doesn\'t have to be re-calculated later.\n\nNote that a weird templating issue force the ""}"" to be before the else\nthe endif templating clauses in set_vm_ip or else the ""}"" is rendered\nlike this:\n\n    VM_IP=""${INSTANCE_FIP}""}\n\nwhich is a shell syntax error.\n\nChange-Id: Ide4d840ba8e42ef57b7bf748a65307d4ed5cc9a6\n'}, {'number': 7, 'created': '2023-02-20 14:51:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-upgrade/commit/bbb0587720716789bdeda09c12ddb42127aa3301', 'message': 'workload : generate traffic to the vm.\n\nSome issues on the dataplane are more likely to happen when some\ntraffic have happen on the vm. Furthermore it match more closely what\ncustomer would have (running vm with existing traffic)\n\nThis patch add a run of iperf during 1 minute to simulate that traffic\njust after the vm has been created.\n\nWe only do that for the ""workload"" option.\n\nWe also add:\n - -o pipefail: to make sure errors are caught, note that -e would\n   require major refactoring and thus in not enabled in this review;\n - prepopulate ~/vm_ip.sh so that it doesn\'t have to be re-calculated later.\n\nNote that a weird templating issue force the ""}"" to be before the else\nthe endif templating clauses in set_vm_ip or else the ""}"" is rendered\nlike this:\n\n    VM_IP=""${INSTANCE_FIP}""}\n\nwhich is a shell syntax error.\n\nChange-Id: Ide4d840ba8e42ef57b7bf748a65307d4ed5cc9a6\n'}, {'number': 8, 'created': '2023-02-21 17:12:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-upgrade/commit/456c088c92d0cc9edaa69d8115a4b867050a2d5d', 'message': 'workload : generate traffic to the vm.\n\nSome issues on the dataplane are more likely to happen when some\ntraffic have happen on the vm. Furthermore it match more closely what\ncustomer would have (running vm with existing traffic)\n\nThis patch add a run of iperf during 1 minute to simulate that traffic\njust after the vm has been created.\n\nWe only do that for the ""workload"" option.\n\nWe also add:\n - -o pipefail: to make sure errors are caught, note that -e would\n   require major refactoring and thus in not enabled in this review;\n - prepopulate ~/vm_ip.sh so that it doesn\'t have to be re-calculated later.\n\nNote that a weird templating issue force the ""}"" to be before the else\nthe endif templating clauses in set_vm_ip or else the ""}"" is rendered\nlike this:\n\n    VM_IP=""${INSTANCE_FIP}""}\n\nwhich is a shell syntax error.\n\nEventually we take into account vm with misconfigured name resolution,\nby temporarily taking the resolv.conf from the undercloud (which\nshould be always working) and use that for getting iperf into the vm.\n\nChange-Id: Ide4d840ba8e42ef57b7bf748a65307d4ed5cc9a6\n'}, {'number': 9, 'created': '2023-06-19 17:29:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-upgrade/commit/4caad16428bf03d5823c5994917af0a5f1f8938e', 'message': 'workload : generate traffic to the vm.\n\nSome issues on the dataplane are more likely to happen when there have\nbeen some traffic to the vm. Furthermore it match more closely what\ncustomer would have (running vms with existing traffic)\n\nThis patch add a run of iperf during 1 minute to simulate that traffic\njust after the vm has been created.\n\nThis is opt-in as the mode needs to be changed to workload_traffic. To\naccess it add `--install-upgrade-workload-traffic` to the infrared\ncommand or set `workload_launch_traffic` to true in other\nenvironments.\n\nWe also take into account vm with misconfigured name resolution, by\ntemporarily taking the resolv.conf from the undercloud (which should\nbe always working) and use that for getting iperf into the vm.\n\nChange-Id: Ide4d840ba8e42ef57b7bf748a65307d4ed5cc9a6\n'}, {'number': 10, 'created': '2023-06-21 16:50:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-upgrade/commit/ea596f9adab6ee87f827e79e8b235220c0c9d8aa', 'message': 'workload : generate traffic to the vm.\n\nSome issues on the dataplane are more likely to happen when there have\nbeen some traffic to the vm. Furthermore it match more closely what\ncustomer would have (running vms with existing traffic)\n\nThis patch add a run of iperf during 1 minute to simulate that traffic\njust after the vm has been created.\n\nThis is opt-in as the mode needs to be changed to workload_traffic. To\naccess it add `--install-upgrade-workload-traffic` to the infrared\ncommand or set `workload_launch_traffic` to true in other\nenvironments.\n\nWe also take into account vm with misconfigured name resolution, by\ntemporarily taking the resolv.conf from the undercloud (which should\nbe always working) and use that for getting iperf into the vm.\n\nChange-Id: Ide4d840ba8e42ef57b7bf748a65307d4ed5cc9a6\n'}, {'number': 11, 'created': '2023-06-26 09:59:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-upgrade/commit/89473540edec342f03aafc787c3e7f80fc33db2c', 'message': 'workload : generate traffic to the vm.\n\nSome issues on the dataplane are more likely to happen when there have\nbeen some traffic to the vm. Furthermore it match more closely what\ncustomer would have (running vms with existing traffic)\n\nThis patch add a run of iperf during 1 minute to simulate that traffic\njust after the vm has been created.\n\nThis is opt-in as the mode needs to be changed to workload_traffic. To\naccess it add `--install-upgrade-workload-traffic` to the infrared\ncommand or set `workload_launch_traffic` to true in other\nenvironments.\n\nWe also take into account vm with misconfigured name resolution, by\ntemporarily taking the resolv.conf from the undercloud (which should\nbe always working) and use that for getting iperf into the vm.\n\nChange-Id: Ide4d840ba8e42ef57b7bf748a65307d4ed5cc9a6\n'}, {'number': 12, 'created': '2023-07-03 08:35:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-upgrade/commit/ce510a8ba6418e9d8ee3993070fcacd03c837dc1', 'message': 'workload : generate traffic to the vm.\n\nSome issues on the dataplane are more likely to happen when there have\nbeen some traffic to the vm. Furthermore it match more closely what\ncustomer would have (running vms with existing traffic)\n\nThis patch add a run of iperf during 1 minute to simulate that traffic\njust after the vm has been created.\n\nThis is opt-in as the mode needs to be changed to workload_traffic. To\naccess it add `--install-upgrade-workload-traffic` to the infrared\ncommand or set `workload_launch_traffic` to true in other\nenvironments.\n\nWe also take into account vm with misconfigured name resolution, by\ntemporarily taking the resolv.conf from the undercloud (which should\nbe always working) and use that for getting iperf into the vm.\n\nChange-Id: Ide4d840ba8e42ef57b7bf748a65307d4ed5cc9a6\n'}, {'number': 13, 'created': '2023-07-03 12:18:52.000000000', 'files': ['tasks/main.yml', 'README.rst', 'infrared_plugin/plugin.spec', 'templates/workload_launch.sh.j2', 'infrared_plugin/main.yml', 'defaults/main.yml'], 'web_link': 'https://opendev.org/openstack/tripleo-upgrade/commit/8f7c90f474678b71e1ce8702052ec811eac17ba8', 'message': 'workload : generate traffic to the vm.\n\nSome issues on the dataplane are more likely to happen when there have\nbeen some traffic to the vm. Furthermore it match more closely what\ncustomer would have (running vms with existing traffic)\n\nThis patch add a run of iperf during 1 minute to simulate that traffic\njust after the vm has been created.\n\nThis is opt-in as the mode needs to be changed to workload_traffic. To\naccess it add `--install-upgrade-workload-traffic` to the infrared\ncommand or set `workload_launch_traffic` to true in other\nenvironments.\n\nWe also take into account vm with misconfigured name resolution, by\ntemporarily taking the resolv.conf from the undercloud (which should\nbe always working) and use that for getting iperf into the vm.\n\nChange-Id: Ide4d840ba8e42ef57b7bf748a65307d4ed5cc9a6\n'}]",21,873251,8f7c90f474678b71e1ce8702052ec811eac17ba8,40,4,13,8297,,,0,"workload : generate traffic to the vm.

Some issues on the dataplane are more likely to happen when there have
been some traffic to the vm. Furthermore it match more closely what
customer would have (running vms with existing traffic)

This patch add a run of iperf during 1 minute to simulate that traffic
just after the vm has been created.

This is opt-in as the mode needs to be changed to workload_traffic. To
access it add `--install-upgrade-workload-traffic` to the infrared
command or set `workload_launch_traffic` to true in other
environments.

We also take into account vm with misconfigured name resolution, by
temporarily taking the resolv.conf from the undercloud (which should
be always working) and use that for getting iperf into the vm.

Change-Id: Ide4d840ba8e42ef57b7bf748a65307d4ed5cc9a6
",git fetch https://review.opendev.org/openstack/tripleo-upgrade refs/changes/51/873251/1 && git format-patch -1 --stdout FETCH_HEAD,['templates/workload_launch.sh.j2'],1,88486281226956ac3a843f99e56152f84e62d813,873251-873251-873255-873255-update-ctl-plane-test,"set -o pipefail IPERF_STATIC_URL=""https://github.com/userdocs/iperf3-static/releases/download/3.12%2B/iperf3-amd64"" SSH=""ssh -q -o StrictHostKeyChecking=no -o UserKnownHostsFile=/dev/null""function set_vm_ip { ## assign floating ip or external ip {% if workload_sriov | bool -%} EXTERNAL_IP=$(openstack port show ${SRIOV_PORT} -f json -c fixed_ips | jq -r -c '.fixed_ips[0][""ip_address""]') VM_IP=${EXTERNAL_IP} {% else -%} INSTANCE_FIP=$(openstack floating ip create ${EXTERNAL_NET_NAME} -f json | jq -r -c '.floating_ip_address' ) echo ""Assign FIP[${INSTANCE_FIP}] to server ${INSTANCE_NAME}"" openstack server add floating ip ${INSTANCE_NAME} ${INSTANCE_FIP} if [ $? -ne 0 ]; then echo ""Network related error detected while attaching FIP to VM. Exiting with non-zero code"" if [[ ""${MODE}"" == ""sanity"" ]]; then sanity_teardown fi exit 1 fi VM_IP=${INSTANCE_FIP} # Newline workaround for endif behaving like endif -%, ie I get VM_IP=...FIP}}"" which fails. {%- endif %} } function generate_traffic { if [ -z ""${VM_IP}"" ]; then set_vm_ip fi if ! ${SSH} cirros@${VM_IP} test -e iperf3-amd64; then ${SSH} cirros@${VM_IP} curl -L -k -O ""${IPERF_STATIC_URL}"" ${SSH} cirros@${VM_IP} chmod +x iperf3-amd64 fi if ! ${SSH} cirros@${VM_IP} ps fauxw | grep -q iperf3-amd64; then ${SSH} -T cirros@${VM_IP} ./iperf3-amd64 -D -s fi if ! openstack security group show ${SECGROUP_NAME} | grep -q 'port_range.*=.5201'; then openstack security group rule create --proto tcp --dst-port 5201 ${SECGROUP_NAME} fi if ! rpm -qa | grep iperf3; then sudo dnf -y install iperf3 fi if [ ! -e iperf3.log ]; then echo -n ""Generating traffic ...."" iperf3 -c ${VM_IP} -t 60 --connect-timeout 3000 --logfile iperf3.log rc=$? if [ ""${rc}"" -ne 0 ]; then echo ""!!"" echo ""Problem generating traffic using iperf: ${rc}"" cat iperf3.log exit 1 fi echo "" done"" fi } set_vm_ip ${SSH} \ echo ""Write VM_IP ${VM_IP} to file ~/${INSTANCE_NAME}"" echo ""export VM_IP=${VM_IP}"" > ~/vm_ip.sh generate_traffic"," ## assign floating ip or external ip {% if workload_sriov | bool -%} EXTERNAL_IP=$(openstack port show ${SRIOV_PORT} -f json -c fixed_ips | jq -r -c '.fixed_ips[0][""ip_address""]') VM_IP=${EXTERNAL_IP} {% else -%} INSTANCE_FIP=$(openstack floating ip create ${EXTERNAL_NET_NAME} -f json | jq -r -c '.floating_ip_address' ) echo ""Assign FIP[${INSTANCE_FIP}] to server ${INSTANCE_NAME}"" openstack server add floating ip ${INSTANCE_NAME} ${INSTANCE_FIP} if [ $? -ne 0 ]; then echo ""Network related error detected while attaching FIP to VM. Exiting with non-zero code"" if [[ ""${MODE}"" == ""sanity"" ]]; then sanity_teardown fi exit 1 fi VM_IP=${INSTANCE_FIP} {%- endif %} ssh -q -o StrictHostKeyChecking=no -o UserKnownHostsFile=/dev/null \ echo ""Write VM_IP ${VM_IP} to file""",63,21
openstack%2Fneutron~888031,openstack/neutron,stable/victoria,Ib52cc6b9c99535b2461a42832c5c8f7603ca7df9,[DNM] Test patch neutron-tempest-plugin/+/888029,ABANDONED,2023-07-10 11:14:34.000000000,2023-07-10 14:12:03.000000000,,[],"[{'number': 1, 'created': '2023-07-10 11:14:34.000000000', 'files': ['neutron/plugins/ml2/drivers/ovn/mech_driver/ovsdb/ovn_client.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/ea68d3bba09e0ce546f55c17947b4d005a913dd4', 'message': '[DNM] Test patch neutron-tempest-plugin/+/888029\n\nDepends-On: https://review.opendev.org/c/openstack/neutron-tempest-plugin/+/888029\nChange-Id: Ib52cc6b9c99535b2461a42832c5c8f7603ca7df9\n'}]",0,888031,ea68d3bba09e0ce546f55c17947b4d005a913dd4,2,0,1,16688,,,0,"[DNM] Test patch neutron-tempest-plugin/+/888029

Depends-On: https://review.opendev.org/c/openstack/neutron-tempest-plugin/+/888029
Change-Id: Ib52cc6b9c99535b2461a42832c5c8f7603ca7df9
",git fetch https://review.opendev.org/openstack/neutron refs/changes/31/888031/1 && git format-patch -1 --stdout FETCH_HEAD,['neutron/plugins/ml2/drivers/ovn/mech_driver/ovsdb/ovn_client.py'],1,ea68d3bba09e0ce546f55c17947b4d005a913dd4,wallaby_vitoria_ovn_21.06,TEST = 'test',,1,0
openstack%2Fneutron~888030,openstack/neutron,stable/wallaby,Ib52cc6b9c99535b2461a42832c5c8f7603ca7df9,[DNM] Test patch neutron-tempest-plugin/+/888029,ABANDONED,2023-07-10 10:33:29.000000000,2023-07-10 14:08:36.000000000,,[{'_account_id': 6773}],"[{'number': 1, 'created': '2023-07-10 10:33:29.000000000', 'files': ['neutron/plugins/ml2/drivers/ovn/mech_driver/ovsdb/ovn_client.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/c661752a5cefcb8f44909d7800b60a5cb9f84cb2', 'message': '[DNM] Test patch neutron-tempest-plugin/+/888029\n\nDepends-On: https://review.opendev.org/c/openstack/neutron-tempest-plugin/+/888029\nChange-Id: Ib52cc6b9c99535b2461a42832c5c8f7603ca7df9\n'}]",0,888030,c661752a5cefcb8f44909d7800b60a5cb9f84cb2,4,1,1,16688,,,0,"[DNM] Test patch neutron-tempest-plugin/+/888029

Depends-On: https://review.opendev.org/c/openstack/neutron-tempest-plugin/+/888029
Change-Id: Ib52cc6b9c99535b2461a42832c5c8f7603ca7df9
",git fetch https://review.opendev.org/openstack/neutron refs/changes/30/888030/1 && git format-patch -1 --stdout FETCH_HEAD,['neutron/plugins/ml2/drivers/ovn/mech_driver/ovsdb/ovn_client.py'],1,c661752a5cefcb8f44909d7800b60a5cb9f84cb2,wallaby_vitoria_ovn_21.06,TEST = 'test',,1,0
openstack%2Fneutron-lib~887659,openstack/neutron-lib,master,I85d8abf76712b069402cce69bf2c049ac51496c1,Remove the dependency of allowedaddresspairs on atomic extensions,NEW,2023-07-05 08:42:07.000000000,2023-07-10 14:05:56.000000000,,"[{'_account_id': 4694}, {'_account_id': 5948}, {'_account_id': 8313}, {'_account_id': 11975}, {'_account_id': 16688}, {'_account_id': 22348}, {'_account_id': 28056}, {'_account_id': 34125}]","[{'number': 1, 'created': '2023-07-05 08:42:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-lib/commit/990b92faaebc9d7533349adbc321dc42ceb9994e', 'message': 'Remove the dependency of allowedaddresspairs on atomic extensions\n\nThe dependency of allowedaddresspairs.ALIAS on atomic extensions\nwill cause the unit tests of neutron to fail.\n\nPartial-Bug: #2012332\nChange-Id: I85d8abf76712b069402cce69bf2c049ac51496c1\n'}, {'number': 2, 'created': '2023-07-05 08:46:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-lib/commit/b00e9e4a3bc62cd627b9a07e588adae26ce9be6b', 'message': 'Remove the dependency of allowedaddresspairs on atomic extensions\n\nThe dependency of allowedaddresspairs.ALIAS on atomic extensions\nwill cause the unit tests of neutron [1] to fail.\n\n[1]https://review.opendev.org/c/openstack/neutron/+/880922\n\nPartial-Bug: #2012332\nChange-Id: I85d8abf76712b069402cce69bf2c049ac51496c1\n'}, {'number': 3, 'created': '2023-07-05 08:49:23.000000000', 'files': ['neutron_lib/api/definitions/allowedaddresspairs_atomic.py'], 'web_link': 'https://opendev.org/openstack/neutron-lib/commit/b8c383e7fb43093850d36cae46336142a247cc1a', 'message': 'Remove the dependency of allowedaddresspairs on atomic extensions\n\nThe dependency of allowedaddresspairs.ALIAS on atomic extensions\nwill cause the unit tests of neutron [1] to fail.\n\n[1]https://review.opendev.org/c/openstack/neutron/+/880922\n\nPartial-Bug: #2012332\nChange-Id: I85d8abf76712b069402cce69bf2c049ac51496c1\n'}]",4,887659,b8c383e7fb43093850d36cae46336142a247cc1a,9,8,3,34125,,,0,"Remove the dependency of allowedaddresspairs on atomic extensions

The dependency of allowedaddresspairs.ALIAS on atomic extensions
will cause the unit tests of neutron [1] to fail.

[1]https://review.opendev.org/c/openstack/neutron/+/880922

Partial-Bug: #2012332
Change-Id: I85d8abf76712b069402cce69bf2c049ac51496c1
",git fetch https://review.opendev.org/openstack/neutron-lib refs/changes/59/887659/1 && git format-patch -1 --stdout FETCH_HEAD,['neutron_lib/api/definitions/allowedaddresspairs_atomic.py'],1,990b92faaebc9d7533349adbc321dc42ceb9994e,bug/2012332,REQUIRED_EXTENSIONS = [],REQUIRED_EXTENSIONS = [allowedaddresspairs.ALIAS],1,1
openstack%2Fkeystone~872667,openstack/keystone,master,Ie5dd375c4922cee895e4dfe25defb70a0b5e21a7,api-ref: Correct app credentials auth response,MERGED,2023-02-03 18:18:55.000000000,2023-07-10 14:01:13.000000000,2023-07-10 13:59:54.000000000,"[{'_account_id': 7414}, {'_account_id': 14250}, {'_account_id': 22348}]","[{'number': 1, 'created': '2023-02-03 18:18:55.000000000', 'files': ['api-ref/source/v3/application-credentials.inc', 'api-ref/source/v3/samples/admin/auth-application-credential-response.json', 'api-ref/source/v3/parameters.yaml'], 'web_link': 'https://opendev.org/openstack/keystone/commit/434dbe1e73ba8cfeed9d43d34ce5d4fdff572975', 'message': ""api-ref: Correct app credentials auth response\n\nIn change I322a40404d8287748fe8c3a8d6dc1256d935d84a we switched from an\n'auth_credential_required' field in the response to an 'auth_credential'\nobject. Correct the api-ref.\n\nWhile we're alphabetize the response parameters.\n\nChange-Id: Ie5dd375c4922cee895e4dfe25defb70a0b5e21a7\nSigned-off-by: Stephen Finucane <sfinucan@redhat.com>\n""}]",0,872667,434dbe1e73ba8cfeed9d43d34ce5d4fdff572975,8,3,1,15334,,,0,"api-ref: Correct app credentials auth response

In change I322a40404d8287748fe8c3a8d6dc1256d935d84a we switched from an
'auth_credential_required' field in the response to an 'auth_credential'
object. Correct the api-ref.

While we're alphabetize the response parameters.

Change-Id: Ie5dd375c4922cee895e4dfe25defb70a0b5e21a7
Signed-off-by: Stephen Finucane <sfinucan@redhat.com>
",git fetch https://review.opendev.org/openstack/keystone refs/changes/67/872667/1 && git format-patch -1 --stdout FETCH_HEAD,"['api-ref/source/v3/application-credentials.inc', 'api-ref/source/v3/samples/admin/auth-application-credential-response.json', 'api-ref/source/v3/parameters.yaml']",3,434dbe1e73ba8cfeed9d43d34ce5d4fdff572975,api-ref,auth_application_credential_body:,auth_application_credential_restricted_body:,41,35
openstack%2Fcharm-neutron-api-plugin-ovn~874922,openstack/charm-neutron-api-plugin-ovn,master,Icc05980b4bc9184ba4e52722c6c11abfcfc0d58c,Enable ovn_emit_need_to_frag,MERGED,2023-02-23 13:42:57.000000000,2023-07-10 13:58:54.000000000,2023-07-10 13:58:54.000000000,"[{'_account_id': 13686}, {'_account_id': 20648}, {'_account_id': 22348}]","[{'number': 1, 'created': '2023-02-23 13:42:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-neutron-api-plugin-ovn/commit/4068345b48f483935336b9a21c25a6f9da377d42', 'message': 'bug#1947391 Added ovn_emit_need_to_frag flag\n\nChange-Id: Icc05980b4bc9184ba4e52722c6c11abfcfc0d58c\n'}, {'number': 2, 'created': '2023-02-24 10:38:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-neutron-api-plugin-ovn/commit/5046e0b097faf2690f2e7479ee693b75bdb11312', 'message': 'Enable ovn_emit_need_to_frag for supported releases\n\nPassing ovn_emit_need_to_frag flag to automatically enable fragmentation\nsupport in OVN. Patching master branch because all recent releases will\nhave a kernel version >= 5.2. This change will be backported to Ussuri,\nwith a kernel version check added only to Ussuri.\n\nCloses-Bug: #1947391\nChange-Id: Icc05980b4bc9184ba4e52722c6c11abfcfc0d58c\n'}, {'number': 3, 'created': '2023-02-24 10:40:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-neutron-api-plugin-ovn/commit/8ba09e3ea35642d75a660aa081407c92cd1f459c', 'message': 'Enable ovn_emit_need_to_frag for supported releases\n\nThe flag requires recent kernel versions (=> 5.2) to be functional.\n\nWe should backport this change only for the following releases:\n\n- kinetic-zed                               5.19\n- jammy-{yoga,zed}                          5.15\n- focal-{ussuri,victoria,wallaby,xena,yoga} 5.4\n\nCloses-Bug: #1947391\nChange-Id: Icc05980b4bc9184ba4e52722c6c11abfcfc0d58c\n'}, {'number': 4, 'created': '2023-02-25 13:15:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-neutron-api-plugin-ovn/commit/0ac9b8ae3008cfafb83309ff3072d1b080ed34fc', 'message': 'Enable ovn_emit_need_to_frag for supported releases\n\nThe flag requires recent kernel versions (=> 5.2) to be functional.\n\nWe should backport this change only for the following releases:\n\n- kinetic-zed                               5.19\n- jammy-{yoga,zed}                          5.15\n- focal-{ussuri,victoria,wallaby,xena,yoga} 5.4\n\nCloses-Bug: #1947391\nChange-Id: Icc05980b4bc9184ba4e52722c6c11abfcfc0d58c\n'}, {'number': 5, 'created': '2023-02-27 11:12:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-neutron-api-plugin-ovn/commit/bdccde40e115d163250cce79b17b9993cabb2997', 'message': 'Enable ovn_emit_need_to_frag for supported releases\n\nThe flag requires recent kernel versions (=> 5.2) to be functional.\n\nWe should backport this change only for the following releases:\n\n- kinetic-zed                               5.19\n- jammy-{yoga,zed}                          5.15\n- focal-{yoga}                              5.4\n\nCloses-Bug: #1947391\nChange-Id: Icc05980b4bc9184ba4e52722c6c11abfcfc0d58c\n'}, {'number': 6, 'created': '2023-02-27 11:16:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-neutron-api-plugin-ovn/commit/777169eb57cb43d8773d255a05bc3976c4578e6a', 'message': 'Enable ovn_emit_need_to_frag\n\nThe flag requires recent kernel versions (=> 5.2) to be functional.\n\nCloses-Bug: #1947391\nChange-Id: Icc05980b4bc9184ba4e52722c6c11abfcfc0d58c\n'}, {'number': 7, 'created': '2023-02-27 11:46:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-neutron-api-plugin-ovn/commit/8f8e46bf1d2408ee6f555473f48f33be5929cc54', 'message': 'Enable ovn_emit_need_to_frag\n\nEnabled by default since this branch only supports jammy where the\nkernel and ovn are new enough to support this flag. This will eliminate\nthe need for a more complex change or the use of a dedicated opt-in\nconfig option.\n\nFor more details, please refer to\nI089f95b40803a6cd5e01990acacd599ced3bbd91\n\nCloses-Bug: #1947391\nChange-Id: Icc05980b4bc9184ba4e52722c6c11abfcfc0d58c\n'}, {'number': 8, 'created': '2023-05-15 07:35:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-neutron-api-plugin-ovn/commit/7e3e494ed28a5e344fa7f9d8ff59469dd84fd90c', 'message': 'Enable ovn_emit_need_to_frag\n\nEnabled by default since this branch only supports jammy where the\nkernel and ovn are new enough to support this flag. This will eliminate\nthe need for a more complex change or the use of a dedicated opt-in\nconfig option.\n\nFor more details, please refer to\nI089f95b40803a6cd5e01990acacd599ced3bbd91\n\nCloses-Bug: #1947391\nChange-Id: Icc05980b4bc9184ba4e52722c6c11abfcfc0d58c\n'}, {'number': 9, 'created': '2023-07-04 10:15:19.000000000', 'files': ['src/reactive/neutron_api_plugin_ovn_handlers.py', 'unit_tests/test_reactive_neutron_api_plugin_ovn_handlers.py'], 'web_link': 'https://opendev.org/openstack/charm-neutron-api-plugin-ovn/commit/c26114ddd8fa859f418e2e3a6ab3db8680e41708', 'message': 'Enable ovn_emit_need_to_frag\n\nEnabled by default since this branch only supports jammy where the\nkernel and ovn are new enough to support this flag. This will eliminate\nthe need for a more complex change or the use of a dedicated opt-in\nconfig option.\n\nFor more details, please refer to\nI089f95b40803a6cd5e01990acacd599ced3bbd91\n\nCloses-Bug: #1947391\nChange-Id: Icc05980b4bc9184ba4e52722c6c11abfcfc0d58c\n'}]",26,874922,c26114ddd8fa859f418e2e3a6ab3db8680e41708,50,3,9,35788,,,0,"Enable ovn_emit_need_to_frag

Enabled by default since this branch only supports jammy where the
kernel and ovn are new enough to support this flag. This will eliminate
the need for a more complex change or the use of a dedicated opt-in
config option.

For more details, please refer to
I089f95b40803a6cd5e01990acacd599ced3bbd91

Closes-Bug: #1947391
Change-Id: Icc05980b4bc9184ba4e52722c6c11abfcfc0d58c
",git fetch https://review.opendev.org/openstack/charm-neutron-api-plugin-ovn refs/changes/22/874922/1 && git format-patch -1 --stdout FETCH_HEAD,"['src/reactive/neutron_api_plugin_ovn_handlers.py', 'unit_tests/test_reactive_neutron_api_plugin_ovn_handlers.py']",2,4068345b48f483935336b9a21c25a6f9da377d42,," ('ovn_emit_need_to_frag', True),",,2,0
openstack%2Fcharm-neutron-api-plugin-ovn~887362,openstack/charm-neutron-api-plugin-ovn,master,I20789f637c9443bd274df5f91522f9e2ce973164,Add 'ovn-source' config option.,MERGED,2023-06-30 08:47:03.000000000,2023-07-10 13:46:49.000000000,2023-07-10 13:46:49.000000000,"[{'_account_id': 13686}, {'_account_id': 20648}, {'_account_id': 22348}]","[{'number': 1, 'created': '2023-06-30 08:47:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-neutron-api-plugin-ovn/commit/47f8642b837592efbb6f5aa90a04582772fb453c', 'message': 'Add \'ovn-source\' config option.\n\nThis option enables configuration of overlay package\nrepository for installation of OVN packages that are\nnot available in default distribution repository.\n\nExpected behavior:\n* New deployments will use default overlay for\n  their series.\n* Setting this option to ""distro"" allows new\n  deployment that does not use overlay repository\n* Existing deployments that are upgraded to this\n  version of the charm won\'t automatically apply\n  repository overlay and will keep using their\n  current defaults.\n\nChange-Id: I20789f637c9443bd274df5f91522f9e2ce973164\n'}, {'number': 2, 'created': '2023-07-03 16:49:48.000000000', 'files': ['src/config.yaml', 'unit_tests/test_lib_charm_openstack_ovn.py', 'src/reactive/neutron_api_plugin_ovn_handlers.py', 'src/lib/charm/openstack/neutron_api_plugin_ovn.py', 'unit_tests/test_reactive_neutron_api_plugin_ovn_handlers.py'], 'web_link': 'https://opendev.org/openstack/charm-neutron-api-plugin-ovn/commit/412885acc9aeb94de910757d1fee5658a8de9a10', 'message': 'Add \'ovn-source\' config option.\n\nThis option enables configuration of overlay package\nrepository for installation of OVN packages that are\nnot available in default distribution repository.\n\nExpected behavior:\n* New deployments will use default overlay for\n  their series.\n* Setting this option to ""distro"" allows new\n  deployment that does not use overlay repository\n* Existing deployments that are upgraded to this\n  version of the charm won\'t automatically apply\n  repository overlay and will keep using their\n  current defaults.\n\nCloses-Bug: #1992770\nChange-Id: I20789f637c9443bd274df5f91522f9e2ce973164\n'}]",59,887362,412885acc9aeb94de910757d1fee5658a8de9a10,17,3,2,32288,,,0,"Add 'ovn-source' config option.

This option enables configuration of overlay package
repository for installation of OVN packages that are
not available in default distribution repository.

Expected behavior:
* New deployments will use default overlay for
  their series.
* Setting this option to ""distro"" allows new
  deployment that does not use overlay repository
* Existing deployments that are upgraded to this
  version of the charm won't automatically apply
  repository overlay and will keep using their
  current defaults.

Closes-Bug: #1992770
Change-Id: I20789f637c9443bd274df5f91522f9e2ce973164
",git fetch https://review.opendev.org/openstack/charm-neutron-api-plugin-ovn refs/changes/62/887362/1 && git format-patch -1 --stdout FETCH_HEAD,"['src/config.yaml', 'unit_tests/test_lib_charm_openstack_ovn.py', 'src/reactive/neutron_api_plugin_ovn_handlers.py', 'src/lib/charm/openstack/neutron_api_plugin_ovn.py', 'unit_tests/test_reactive_neutron_api_plugin_ovn_handlers.py']",5,47f8642b837592efbb6f5aa90a04582772fb453c,," 'ovn_source_changed': ('config.changed.ovn-source',), def test_ovn_source_config_changed(self): """"""Test that changing 'ovn-source' config triggers package upgrade."""""" config = {'ovn-source': 'cloud:focal-ovn-22.03'} handlers.ch_core.hookenv.config.return_value = config handlers.ovn_source_changed() self.charm.upgrade_ovn.assert_called_once_with() def test_ovn_source_config_changed_no_trigger(self): """"""Test no package upgrade is triggered if 'ovn-source' is default. Not triggering OVN package upgrade if value of 'ovn-source' is default empty string ensures that packages are not automatically upgraded on charm upgrade. """""" config = {'ovn-source': ''} handlers.ch_core.hookenv.config.return_value = config handlers.ovn_source_changed() self.charm.upgrade_ovn.assert_not_called()",,316,2
openstack%2Fcharm-magpie~887136,openstack/charm-magpie,master,I0f4b2bc5427533b990f8b216a955565c1faaefd2,Migrate charm to binary,MERGED,2023-06-28 06:13:25.000000000,2023-07-10 13:41:39.000000000,2023-07-10 13:41:39.000000000,"[{'_account_id': 935}, {'_account_id': 20648}, {'_account_id': 22348}, {'_account_id': 34352}]","[{'number': 1, 'created': '2023-06-28 06:13:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-magpie/commit/d7f6dab8a5e2a67bb991159174717157dec07dd7', 'message': 'Migrate charm to binary\n\nThis greatly improve the deployment of Magpie where\nit is actually deployed many times for different\nspaces on an identical underlaying machine\n\nChange-Id: I0f4b2bc5427533b990f8b216a955565c1faaefd2\n'}, {'number': 2, 'created': '2023-06-28 09:45:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-magpie/commit/97c4f87cb6de87d20a5d6a6267909206ddd28277', 'message': 'Migrate charm to binary\n\nThis greatly improve the installation phase of Magpie\nwhere it is common to have the charm deployed\nmultiple times on a same underlaying machine mainly\nfor each network spaces.\nFrom a setup from 3 nodes and 5 network spaces the\ninstallation time required was reduced from 12 to\n1 minute\n\nChange-Id: I0f4b2bc5427533b990f8b216a955565c1faaefd2\n'}, {'number': 3, 'created': '2023-06-28 09:56:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-magpie/commit/4112f94ee55d5fbf21c9a8d1f462f4cd0a0a9596', 'message': 'Migrate charm to binary\n\nThis greatly improve the installation phase of Magpie\nwhere it is common to have the charm deployed\nmultiple times on a same underlaying machine mainly\nfor each network spaces.\nFrom a setup from 3 nodes and 5 network spaces the\ninstallation time required was reduced from 12 to\n1 minute\n\nDrop Kinetic support\n\nChange-Id: I0f4b2bc5427533b990f8b216a955565c1faaefd2\n'}, {'number': 4, 'created': '2023-06-30 08:41:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-magpie/commit/0f3d9947161635c4147cf609450a6c7192e9cec4', 'message': 'Migrate charm to binary\n\nThis greatly improve the installation phase of Magpie\nwhere it is common to have the charm deployed\nmultiple times on a same underlaying machine mainly\nfor each network spaces.\nFrom a setup from 3 nodes and 5 network spaces the\ninstallation time required was reduced from 12 to\n1 minute\n\nDrop Impish and Kinetic support\n\nChange-Id: I0f4b2bc5427533b990f8b216a955565c1faaefd2\n'}, {'number': 5, 'created': '2023-06-30 09:18:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-magpie/commit/490c8012fff88bf2416670473f40c85617abcce4', 'message': 'Migrate charm to binary\n\nThis greatly improve the installation phase of Magpie\nwhere it is common to have the charm deployed\nmultiple times on a same underlaying machine mainly\nfor each network spaces.\nFrom a setup from 3 nodes and 5 network spaces the\ninstallation time required was reduced from 12 to\n1 minute\n\nDrop Impish and Kinetic support\n\nChange-Id: I0f4b2bc5427533b990f8b216a955565c1faaefd2\n'}, {'number': 6, 'created': '2023-06-30 09:39:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-magpie/commit/578bf66c0405f0f63e1f80a416848c9ed6652898', 'message': 'Migrate charm to binary\n\nThis greatly improve the installation phase of Magpie\nwhere it is common to have the charm deployed\nmultiple times on a same underlaying machine mainly\nfor each network spaces.\nFrom a setup from 3 nodes and 5 network spaces the\ninstallation time required was reduced from 12 to\n1 minute\n\nDrop Impish and Kinetic support\n\nChange-Id: I0f4b2bc5427533b990f8b216a955565c1faaefd2\n'}, {'number': 7, 'created': '2023-06-30 09:55:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-magpie/commit/cb45a3daab3175bf456228e58259756fd0958659', 'message': 'Migrate charm to binary\n\nThis greatly improve the installation phase of Magpie\nwhere it is common to have the charm deployed\nmultiple times on a same underlaying machine mainly\nfor each network spaces.\nFrom a setup from 3 nodes and 5 network spaces the\ninstallation time required was reduced from 12 to\n1 minute\n\nDrop Impish and Kinetic support\n\nChange-Id: I0f4b2bc5427533b990f8b216a955565c1faaefd2\n'}, {'number': 8, 'created': '2023-07-04 09:08:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-magpie/commit/116ca15ad04b1877ea203cfe0f8c6a0d3a49ad36', 'message': 'Migrate charm to binary\n\nThis greatly improve the installation phase of Magpie\nwhere it is common to have the charm deployed\nmultiple times on a same underlaying machine mainly\nfor each network spaces.\nFrom a setup from 3 nodes and 5 network spaces the\ninstallation time required was reduced from 12 to\n1 minute\n\nDrop Impish and Kinetic support\n\nChange-Id: I0f4b2bc5427533b990f8b216a955565c1faaefd2\n'}, {'number': 9, 'created': '2023-07-04 10:28:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-magpie/commit/cf76f7725d63846025aec56b7e1a9154402b74bc', 'message': 'Migrate charm to binary\n\nThis greatly improve the installation phase of Magpie\nwhere it is common to have the charm deployed\nmultiple times on a same underlaying machine mainly\nfor each network spaces.\nFrom a setup from 3 nodes and 5 network spaces the\ninstallation time required was reduced from 12 to\n1 minute\n\nDrop Impish and Kinetic support\n\nChange-Id: I0f4b2bc5427533b990f8b216a955565c1faaefd2\n'}, {'number': 10, 'created': '2023-07-04 12:37:48.000000000', 'files': ['src/tests/bundles/kinetic.yaml', 'osci.yaml', 'src/tests/bundles/focal.yaml', 'src/tests/bundles/lunar.yaml', 'rename.sh', 'charmcraft.yaml', 'src/metadata.yaml', 'src/tests/bundles/jammy.yaml', 'src/tests/tests.yaml', 'tox.ini'], 'web_link': 'https://opendev.org/openstack/charm-magpie/commit/cb60a11f572c201268fffc293bf40a530aadc3d7', 'message': 'Migrate charm to binary\n\nThis greatly improve the installation phase of Magpie\nwhere it is common to have the charm deployed\nmultiple times on a same underlaying machine mainly\nfor each network spaces.\nFrom a setup from 3 nodes and 5 network spaces the\ninstallation time required was reduced from 12 to\n1 minute\n\nDrop Impish and Kinetic support\n\nChange-Id: I0f4b2bc5427533b990f8b216a955565c1faaefd2\n'}]",6,887136,cb60a11f572c201268fffc293bf40a530aadc3d7,41,4,10,34232,,,0,"Migrate charm to binary

This greatly improve the installation phase of Magpie
where it is common to have the charm deployed
multiple times on a same underlaying machine mainly
for each network spaces.
From a setup from 3 nodes and 5 network spaces the
installation time required was reduced from 12 to
1 minute

Drop Impish and Kinetic support

Change-Id: I0f4b2bc5427533b990f8b216a955565c1faaefd2
",git fetch https://review.opendev.org/openstack/charm-magpie refs/changes/36/887136/1 && git format-patch -1 --stdout FETCH_HEAD,"['charmcraft.yaml', 'src/metadata.yaml']",2,d7f6dab8a5e2a67bb991159174717157dec07dd7,binary-reactive,,- kinetic,87,10
openstack%2Fcharm-magpie~887135,openstack/charm-magpie,master,I595b39a2ca9853ef0989dd0124c6e02f03dc51ff,Fix iperf errors and results on Focal,MERGED,2023-06-28 06:10:57.000000000,2023-07-10 13:35:10.000000000,2023-07-10 13:35:10.000000000,"[{'_account_id': 935}, {'_account_id': 20648}, {'_account_id': 22348}, {'_account_id': 34352}]","[{'number': 1, 'created': '2023-06-28 06:10:57.000000000', 'files': ['src/lib/charms/layer/magpie_tools.py', 'unit_tests/test_magpie_tools.py'], 'web_link': 'https://opendev.org/openstack/charm-magpie/commit/5bda1a00495e9a22b0f7d8c7b9d644b62924fae6', 'message': 'Fix iperf errors and results on Focal\n\nOn Focal, the value of bandwidth would be doubled\nthan in reality\n\nIt fixes also a silent error when the action fails\nto reach a single node\nIt will return at least the source ip, interface\nand destination used for the test\n\nCloses-Bug: #2025212\nChange-Id: I595b39a2ca9853ef0989dd0124c6e02f03dc51ff\n'}]",1,887135,5bda1a00495e9a22b0f7d8c7b9d644b62924fae6,8,4,1,34232,,,0,"Fix iperf errors and results on Focal

On Focal, the value of bandwidth would be doubled
than in reality

It fixes also a silent error when the action fails
to reach a single node
It will return at least the source ip, interface
and destination used for the test

Closes-Bug: #2025212
Change-Id: I595b39a2ca9853ef0989dd0124c6e02f03dc51ff
",git fetch https://review.opendev.org/openstack/charm-magpie refs/changes/35/887135/1 && git format-patch -1 --stdout FETCH_HEAD,"['src/lib/charms/layer/magpie_tools.py', 'unit_tests/test_magpie_tools.py']",2,5bda1a00495e9a22b0f7d8c7b9d644b62924fae6,focal_error_output," self.maxDiff = None @patch( ""lib.charms.layer.magpie_tools.get_src_ip_from_dest"", lambda _: ""192.168.2.2"" ) ""mynode"", ""192.168.2.1"", ""10"", ""2"" ""iperf -t10 -c 192.168.2.1 --port 5001 -P2 --reportstyle c"" @patch('subprocess.PIPE', None) @patch('subprocess.run') def test_get_src_ip_from_dest(self, mock_subprocess): mock_stdout = MagicMock() mock_stdout.configure_mock( **{ 'stdout.decode.return_value': '[{""dst"":""192.168.12.1"",' '""dev"":""enp5s0"",""prefsrc"":""192.168.12.15"",""flags"":[],' '""uid"":1000,""cache"":[]}]' } ) mock_subprocess.return_value = mock_stdout self.assertEqual( magpie_tools.get_src_ip_from_dest(""192.168.12.1""), '192.168.12.15', )"," ""mynode"", ""192.168.2.2"", ""10"", ""2"" ""iperf -t10 -c 192.168.2.2 --port 5001 -P2 --reportstyle c""",92,32
openstack%2Fneutron-tempest-plugin~888029,openstack/neutron-tempest-plugin,master,I961bfb5b58d34bf6400117c6ea788231db40a5fe,Use OVN v21.06 in Wallaby and Victoria,MERGED,2023-07-10 10:31:21.000000000,2023-07-10 13:20:19.000000000,2023-07-10 13:20:19.000000000,"[{'_account_id': 1131}, {'_account_id': 6773}, {'_account_id': 8313}, {'_account_id': 13861}, {'_account_id': 16688}, {'_account_id': 22348}]","[{'number': 1, 'created': '2023-07-10 10:31:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-tempest-plugin/commit/14e157454f81a7e335c233d76450408511cb986a', 'message': 'Use OVN v21.06 in Wallaby and Victoria\n\nThis patch is a follow-up of [1]. In order to keep using the same OVS\nand OVN versions used before in the stable branched Wallaby and\nVictoria, this patch enforces the OVN version to v21.06\n\n[1]https://review.opendev.org/c/openstack/neutron-tempest-plugin/+/887666\n\nChange-Id: I961bfb5b58d34bf6400117c6ea788231db40a5fe\n'}, {'number': 2, 'created': '2023-07-10 12:42:38.000000000', 'files': ['zuul.d/wallaby_jobs.yaml', 'zuul.d/victoria_jobs.yaml'], 'web_link': 'https://opendev.org/openstack/neutron-tempest-plugin/commit/d5023e1b9914fe93d909ea92b38baba76f2d7869', 'message': 'Use OVN v21.06 in Wallaby and Victoria\n\nThis patch is a follow-up of [1]. In order to keep using the same OVS\nand OVN versions used before in the stable branched Wallaby and\nVictoria, this patch enforces the OVN version to v21.06\n\n[1]https://review.opendev.org/c/openstack/neutron-tempest-plugin/+/887666\n\nChange-Id: I961bfb5b58d34bf6400117c6ea788231db40a5fe\n'}]",6,888029,d5023e1b9914fe93d909ea92b38baba76f2d7869,14,6,2,16688,,,0,"Use OVN v21.06 in Wallaby and Victoria

This patch is a follow-up of [1]. In order to keep using the same OVS
and OVN versions used before in the stable branched Wallaby and
Victoria, this patch enforces the OVN version to v21.06

[1]https://review.opendev.org/c/openstack/neutron-tempest-plugin/+/887666

Change-Id: I961bfb5b58d34bf6400117c6ea788231db40a5fe
",git fetch https://review.opendev.org/openstack/neutron-tempest-plugin refs/changes/29/888029/1 && git format-patch -1 --stdout FETCH_HEAD,"['zuul.d/wallaby_jobs.yaml', 'zuul.d/victoria_jobs.yaml']",2,14e157454f81a7e335c233d76450408511cb986a,wallaby_vitoria_ovn_21.06," OVN_BRANCH: ""v21.06.0"" OVS_BRANCH: ""a4b04276ab5934d087669ff2d191a23931335c87"""," OVN_BRANCH: ""branch-22.03"" OVS_BRANCH: ""branch-3.0""",4,4
openstack%2Fpython-manilaclient~869709,openstack/python-manilaclient,master,I204cd0aeb66dfb7f0b4da29413b80d76a6034aa3,Metadata for Share Network Subnets,MERGED,2023-01-12 11:41:31.000000000,2023-07-10 13:15:40.000000000,2023-07-10 13:14:39.000000000,"[{'_account_id': 16643}, {'_account_id': 22348}, {'_account_id': 29632}, {'_account_id': 32594}, {'_account_id': 33756}, {'_account_id': 34489}]","[{'number': 1, 'created': '2023-01-12 11:41:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-manilaclient/commit/7be34e31a5e77a8fa4943d70ef7ad95b44c7934f', 'message': 'Metadata for Share Network Subnets\n\nExtend these into OSC capabilities where appropriate.\nBumps max microversion to 2.74.\n\nDepends-On: I8d5a03eb127941a84eea5e6e9bdf76b3489f17a8\nImplements: bp/metadata-for-share-resources\nChange-Id: I204cd0aeb66dfb7f0b4da29413b80d76a6034aa3\n'}, {'number': 2, 'created': '2023-03-08 20:54:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-manilaclient/commit/4aa858e8bc9a66d2b94ddc681649a64b16209d0b', 'message': 'Metadata for Share Network Subnets\n\nExtend these into OSC capabilities where appropriate.\nBumps max microversion to 2.78.\n\nDepends-On: I8d5a03eb127941a84eea5e6e9bdf76b3489f17a8\nImplements: bp/metadata-for-share-resources\nChange-Id: I204cd0aeb66dfb7f0b4da29413b80d76a6034aa3\n'}, {'number': 3, 'created': '2023-05-09 01:49:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-manilaclient/commit/a52a4f63e1ec8cef68f3637c7a56b1ddd854e2cd', 'message': 'Metadata for Share Network Subnets\n\nExtend these into OSC capabilities where appropriate.\nBumps max microversion to 2.78.\n\nDepends-On: I8d5a03eb127941a84eea5e6e9bdf76b3489f17a8\nImplements: bp/metadata-for-share-resources\nChange-Id: I204cd0aeb66dfb7f0b4da29413b80d76a6034aa3\n'}, {'number': 4, 'created': '2023-05-10 12:54:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-manilaclient/commit/afe7fa9c62bd71d7f4d87fe2961744ff53182d4c', 'message': 'Metadata for Share Network Subnets\n\nExtend these into OSC capabilities where appropriate.\nBumps max microversion to 2.78.\n\nDepends-On: I8d5a03eb127941a84eea5e6e9bdf76b3489f17a8\nImplements: bp/metadata-for-share-resources\nChange-Id: I204cd0aeb66dfb7f0b4da29413b80d76a6034aa3\n'}, {'number': 5, 'created': '2023-07-07 19:26:09.000000000', 'files': ['manilaclient/tests/unit/v2/test_share_network_subnets.py', 'manilaclient/tests/unit/osc/v2/fakes.py', 'manilaclient/tests/unit/osc/v2/test_share_network_subnets.py', 'manilaclient/osc/v2/share_network_subnets.py', 'manilaclient/osc/v2/share_networks.py', 'releasenotes/notes/add-subnet-metadata-82426986431b0179.yaml', 'setup.cfg', 'manilaclient/v2/share_network_subnets.py', 'manilaclient/api_versions.py'], 'web_link': 'https://opendev.org/openstack/python-manilaclient/commit/e3f01e5c2a134cd0b228bf35c70d6d110187ee36', 'message': 'Metadata for Share Network Subnets\n\nExtend these into OSC capabilities where appropriate.\nBumps max microversion to 2.78.\n\nDepends-On: I8d5a03eb127941a84eea5e6e9bdf76b3489f17a8\nImplements: bp/metadata-for-share-resources\nChange-Id: I204cd0aeb66dfb7f0b4da29413b80d76a6034aa3\n'}]",65,869709,e3f01e5c2a134cd0b228bf35c70d6d110187ee36,35,6,5,31721,,,0,"Metadata for Share Network Subnets

Extend these into OSC capabilities where appropriate.
Bumps max microversion to 2.78.

Depends-On: I8d5a03eb127941a84eea5e6e9bdf76b3489f17a8
Implements: bp/metadata-for-share-resources
Change-Id: I204cd0aeb66dfb7f0b4da29413b80d76a6034aa3
",git fetch https://review.opendev.org/openstack/python-manilaclient refs/changes/09/869709/1 && git format-patch -1 --stdout FETCH_HEAD,"['manilaclient/tests/unit/v2/test_share_network_subnets.py', 'releasenotes/notes/add_subnet_metadata-82426986431b0179.yaml', 'manilaclient/tests/unit/osc/v2/fakes.py', 'manilaclient/v2/shell.py', 'manilaclient/tests/unit/osc/v2/test_share_network_subnets.py', 'manilaclient/osc/v2/share_network_subnets.py', 'setup.cfg', 'manilaclient/v2/share_network_subnets.py', 'manilaclient/api_versions.py']",9,7be34e31a5e77a8fa4943d70ef7ad95b44c7934f,manual_vlan,MAX_VERSION = '2.74',MAX_VERSION = '2.73',350,7
openstack%2Fcharm-ceph-mon~888024,openstack/charm-ceph-mon,master,I9428e93ba6107ba5e2ebcc667995b3d88eb03d27,Set consistent source,MERGED,2023-07-10 07:41:28.000000000,2023-07-10 12:54:25.000000000,2023-07-10 12:54:25.000000000,"[{'_account_id': 20648}, {'_account_id': 22348}, {'_account_id': 33717}, {'_account_id': 34952}]","[{'number': 1, 'created': '2023-07-10 07:41:28.000000000', 'files': ['config.yaml'], 'web_link': 'https://opendev.org/openstack/charm-ceph-mon/commit/ab84214805e130848db3c45884223619904b3734', 'message': 'Set consistent source\n\nAvoid the unintuitive situation where users are deploying from\nchannel=quincy but get an older ceph due to deploying series=focal by\nexplicitly setting source=quincy which is what most users want anyway;\nthose that do not can still explicitly set source.\n\nChange-Id: I9428e93ba6107ba5e2ebcc667995b3d88eb03d27\n'}]",1,888024,ab84214805e130848db3c45884223619904b3734,8,4,1,15382,,,0,"Set consistent source

Avoid the unintuitive situation where users are deploying from
channel=quincy but get an older ceph due to deploying series=focal by
explicitly setting source=quincy which is what most users want anyway;
those that do not can still explicitly set source.

Change-Id: I9428e93ba6107ba5e2ebcc667995b3d88eb03d27
",git fetch https://review.opendev.org/openstack/charm-ceph-mon refs/changes/24/888024/1 && git format-patch -1 --stdout FETCH_HEAD,['config.yaml'],1,ab84214805e130848db3c45884223619904b3734,set-source-default, default: quincy, default: distro,1,1
openstack%2Fcharm-ceph-mon~887881,openstack/charm-ceph-mon,stable/quincy.2,I1ca4316aaf4f0b855a12aa582a8188c88e926fa6,Fix ceph-mon upgrade path,MERGED,2023-07-10 07:53:50.000000000,2023-07-10 12:41:26.000000000,2023-07-10 12:41:26.000000000,"[{'_account_id': 20648}, {'_account_id': 22348}, {'_account_id': 33717}]","[{'number': 1, 'created': '2023-07-10 07:53:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-ceph-mon/commit/356a44a62cc43c9bd92f5c5844fb245ff7b3d132', 'message': 'Fix ceph-mon upgrade path\n\nThis PR makes some small changes in the upgrade path logic by\nproviding a fallback method of fetching the current ceph-mon\nversion and adding additional checks to see if the upgrade can\nbe done in a sane way.\n\nCloses-Bug: #2024253\nChange-Id: I1ca4316aaf4f0b855a12aa582a8188c88e926fa6\n(cherry picked from commit 1a41aa24ce82c411da936ef3f21c61a57c059155)\n'}, {'number': 2, 'created': '2023-07-10 10:20:05.000000000', 'files': ['src/ceph_hooks.py', 'test-requirements.txt', 'unit_tests/test_upgrade.py'], 'web_link': 'https://opendev.org/openstack/charm-ceph-mon/commit/9db193ef9b27074a0a4469dc85b9fa49137370d4', 'message': 'Fix ceph-mon upgrade path\n\nThis PR makes some small changes in the upgrade path logic by\nproviding a fallback method of fetching the current ceph-mon\nversion and adding additional checks to see if the upgrade can\nbe done in a sane way.\n\nCloses-Bug: #2024253\nChange-Id: I1ca4316aaf4f0b855a12aa582a8188c88e926fa6\n(cherry picked from commit 1a41aa24ce82c411da936ef3f21c61a57c059155)\n'}]",1,887881,9db193ef9b27074a0a4469dc85b9fa49137370d4,10,3,2,15382,,,0,"Fix ceph-mon upgrade path

This PR makes some small changes in the upgrade path logic by
providing a fallback method of fetching the current ceph-mon
version and adding additional checks to see if the upgrade can
be done in a sane way.

Closes-Bug: #2024253
Change-Id: I1ca4316aaf4f0b855a12aa582a8188c88e926fa6
(cherry picked from commit 1a41aa24ce82c411da936ef3f21c61a57c059155)
",git fetch https://review.opendev.org/openstack/charm-ceph-mon refs/changes/81/887881/1 && git format-patch -1 --stdout FETCH_HEAD,"['src/ceph_hooks.py', 'unit_tests/test_upgrade.py']",2,356a44a62cc43c9bd92f5c5844fb245ff7b3d132,fix-upgrade-stable/quincy.2,"from charms_ceph.utils import resolve_ceph_version as resolve_ceph_version_orig @patch('ceph_hooks.ceph.resolve_ceph_version') @patch('ceph_hooks.subprocess.check_output') @patch('ceph_hooks.add_source') @patch('ceph_hooks.ceph.is_bootstrapped') @patch('ceph_hooks.hookenv') @patch('ceph_hooks.ceph.roll_monitor_cluster') def test_check_for_upgrade_no_current_version(self, roll_monitor_cluster, hookenv, is_bootstrapped, add_source, check_output, resolve_ceph_version): _resolve_first = True def _resolve_version(arg): nonlocal _resolve_first if _resolve_first: _resolve_first = False return None return resolve_ceph_version_orig(arg) resolve_ceph_version.side_effect = _resolve_version check_output.return_value = b"""""" ceph version 16.2.13 (123) pacific (stable)"""""" is_bootstrapped.return_value = True hookenv.config.side_effect = self.test_config self.test_config.set('source', 'cloud:focal-yoga') check_for_upgrade() roll_monitor_cluster.assert_called() add_source.assert_not_called() @patch('ceph_hooks.ceph.resolve_ceph_version') @patch('ceph_hooks.subprocess.check_output') @patch('ceph_hooks.add_source') @patch('ceph_hooks.ceph.is_bootstrapped') @patch('ceph_hooks.hookenv') @patch('ceph_hooks.ceph.roll_monitor_cluster') def test_check_for_upgrade_no_versions(self, roll_monitor_cluster, hookenv, is_bootstrapped, add_source, check_output, resolve_ceph_version): resolve_ceph_version.return_value = None check_output.return_value = b"""""" ceph version 17.2.5 (456) quincy (stable)"""""" is_bootstrapped.return_value = True hookenv.config.side_effect = self.test_config check_for_upgrade() roll_monitor_cluster.assert_not_called() add_source.assert_not_called()",,77,1
openstack%2Fironic~887971,openstack/ironic,master,I1a85c0c9285359ee92fb676ec56c817cbe350367,Move standalone jobs to focal,MERGED,2023-07-07 15:31:44.000000000,2023-07-10 12:34:00.000000000,2023-07-10 12:31:51.000000000,"[{'_account_id': 10239}, {'_account_id': 22348}, {'_account_id': 23851}]","[{'number': 1, 'created': '2023-07-07 15:31:44.000000000', 'files': ['zuul.d/ironic-jobs.yaml'], 'web_link': 'https://opendev.org/openstack/ironic/commit/6c35a44424ea03a8a147d64cad17cee79777d210', 'message': ""Move standalone jobs to focal\n\nWe are seeing a lot of failures in our standalone jobs\nafter we switched to jammy, see[1].\nLet's pin the jobs to focal and to isolate the problem and\nfix in a separate patch.\n\n[1] https://zuul.opendev.org/t/openstack/builds?job_name=ironic-standalone-redfish&project=openstack%2Fironic&branch=master&skip=0\n\nChange-Id: I1a85c0c9285359ee92fb676ec56c817cbe350367\n""}]",0,887971,6c35a44424ea03a8a147d64cad17cee79777d210,11,3,1,15519,,,0,"Move standalone jobs to focal

We are seeing a lot of failures in our standalone jobs
after we switched to jammy, see[1].
Let's pin the jobs to focal and to isolate the problem and
fix in a separate patch.

[1] https://zuul.opendev.org/t/openstack/builds?job_name=ironic-standalone-redfish&project=openstack%2Fironic&branch=master&skip=0

Change-Id: I1a85c0c9285359ee92fb676ec56c817cbe350367
",git fetch https://review.opendev.org/openstack/ironic refs/changes/71/887971/1 && git format-patch -1 --stdout FETCH_HEAD,['zuul.d/ironic-jobs.yaml'],1,6c35a44424ea03a8a147d64cad17cee79777d210,pin_standalone, nodeset: openstack-single-node-focal nodeset: openstack-single-node-focal,,2,0
openstack%2Ftripleo-common~888035,openstack/tripleo-common,stable/wallaby,Ifacd7b81e2f9e8509ab287d603f38f61fae22902,Use new_manifest_type var,ABANDONED,2023-07-10 12:25:53.000000000,2023-07-10 12:31:15.000000000,,[],"[{'number': 1, 'created': '2023-07-10 12:25:53.000000000', 'files': ['tripleo_common/image/image_uploader.py'], 'web_link': 'https://opendev.org/openstack/tripleo-common/commit/3767578974d52592d56e3e2b0516dd19bf7373e5', 'message': ""Use new_manifest_type var\n\nThis a followup fix for b0962d2ba09fbb4da33daa328e6a50cac5e3ba05.\nThe new_manifest_type var needs to be set since we assume it's has the\nvalue of the manifest type later in the function.\n\nChange-Id: Ifacd7b81e2f9e8509ab287d603f38f61fae22902\nSigned-off-by: James Slagle <jslagle@redhat.com>\n""}]",0,888035,3767578974d52592d56e3e2b0516dd19bf7373e5,2,0,1,7144,,,0,"Use new_manifest_type var

This a followup fix for b0962d2ba09fbb4da33daa328e6a50cac5e3ba05.
The new_manifest_type var needs to be set since we assume it's has the
value of the manifest type later in the function.

Change-Id: Ifacd7b81e2f9e8509ab287d603f38f61fae22902
Signed-off-by: James Slagle <jslagle@redhat.com>
",git fetch https://review.opendev.org/openstack/tripleo-common refs/changes/35/888035/1 && git format-patch -1 --stdout FETCH_HEAD,['tripleo_common/image/image_uploader.py'],1,3767578974d52592d56e3e2b0516dd19bf7373e5,, new_manifest_type = MEDIA_MANIFEST_V1_SIGNED else: new_manifest_type = MEDIA_MANIFEST_V1, manifest_type = MEDIA_MANIFEST_V1_SIGNED else: manifest_type = MEDIA_MANIFEST_V1,2,2
openstack%2Ftripleo-common~888036,openstack/tripleo-common,stable/train,Ifacd7b81e2f9e8509ab287d603f38f61fae22902,Use new_manifest_type var,ABANDONED,2023-07-10 12:26:34.000000000,2023-07-10 12:31:05.000000000,,[],"[{'number': 1, 'created': '2023-07-10 12:26:34.000000000', 'files': ['tripleo_common/image/image_uploader.py'], 'web_link': 'https://opendev.org/openstack/tripleo-common/commit/61ef3793af7bd4fbccf977e8c0ae829e4267822d', 'message': ""Use new_manifest_type var\n\nThis a followup fix for b0962d2ba09fbb4da33daa328e6a50cac5e3ba05.\nThe new_manifest_type var needs to be set since we assume it's has the\nvalue of the manifest type later in the function.\n\nChange-Id: Ifacd7b81e2f9e8509ab287d603f38f61fae22902\nSigned-off-by: James Slagle <jslagle@redhat.com>\n(cherry picked from commit 3767578974d52592d56e3e2b0516dd19bf7373e5)\n""}]",0,888036,61ef3793af7bd4fbccf977e8c0ae829e4267822d,2,0,1,7144,,,0,"Use new_manifest_type var

This a followup fix for b0962d2ba09fbb4da33daa328e6a50cac5e3ba05.
The new_manifest_type var needs to be set since we assume it's has the
value of the manifest type later in the function.

Change-Id: Ifacd7b81e2f9e8509ab287d603f38f61fae22902
Signed-off-by: James Slagle <jslagle@redhat.com>
(cherry picked from commit 3767578974d52592d56e3e2b0516dd19bf7373e5)
",git fetch https://review.opendev.org/openstack/tripleo-common refs/changes/36/888036/1 && git format-patch -1 --stdout FETCH_HEAD,['tripleo_common/image/image_uploader.py'],1,61ef3793af7bd4fbccf977e8c0ae829e4267822d,, new_manifest_type = MEDIA_MANIFEST_V1_SIGNED else: new_manifest_type = MEDIA_MANIFEST_V1, manifest_type = MEDIA_MANIFEST_V1_SIGNED else: manifest_type = MEDIA_MANIFEST_V1,2,2
openstack%2Fopenstack-ansible~887513,openstack/openstack-ansible,stable/2023.1,I87a5c85d42aa757f9789a81974403284c2d32051,Bump SHAs for stable/2023.1,MERGED,2023-07-03 12:59:13.000000000,2023-07-10 11:53:08.000000000,2023-07-10 11:51:51.000000000,"[{'_account_id': 22348}, {'_account_id': 25023}, {'_account_id': 32666}]","[{'number': 1, 'created': '2023-07-03 12:59:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/88a602bde722d38d662ffb4a615d3b1616194661', 'message': 'Bump SHAs for stable/2023.1\n\nCloses-Bug: #2025513\nCloses-Bug: #2024407\nChange-Id: I87a5c85d42aa757f9789a81974403284c2d32051\n'}, {'number': 2, 'created': '2023-07-06 20:22:47.000000000', 'files': ['inventory/group_vars/trove_all/source_git.yml', 'ansible-collection-requirements.yml', 'inventory/group_vars/cinder_all/source_git.yml', 'inventory/group_vars/ironic_all/source_git.yml', 'inventory/group_vars/all/source_git.yml', 'inventory/group_vars/magnum_all/source_git.yml', 'inventory/group_vars/horizon_all/source_git.yml', 'ansible-role-requirements.yml', 'inventory/group_vars/gnocchi_all/source_git.yml', 'inventory/group_vars/designate_all/source_git.yml', 'inventory/group_vars/swift_all/source_git.yml', 'inventory/group_vars/neutron_all/source_git.yml', 'inventory/group_vars/nova_all/source_git.yml', 'inventory/group_vars/octavia_all/source_git.yml'], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/9921c23ea463c8cd16f709198e7602157848e41a', 'message': 'Bump SHAs for stable/2023.1\n\nCloses-Bug: #2025513\nCloses-Bug: #2024407\nChange-Id: I87a5c85d42aa757f9789a81974403284c2d32051\n'}]",1,887513,9921c23ea463c8cd16f709198e7602157848e41a,12,3,2,28619,,,0,"Bump SHAs for stable/2023.1

Closes-Bug: #2025513
Closes-Bug: #2024407
Change-Id: I87a5c85d42aa757f9789a81974403284c2d32051
",git fetch https://review.opendev.org/openstack/openstack-ansible refs/changes/13/887513/1 && git format-patch -1 --stdout FETCH_HEAD,"['inventory/group_vars/trove_all/source_git.yml', 'ansible-collection-requirements.yml', 'inventory/group_vars/cinder_all/source_git.yml', 'inventory/group_vars/ironic_all/source_git.yml', 'inventory/group_vars/all/source_git.yml', 'inventory/group_vars/magnum_all/source_git.yml', 'inventory/group_vars/horizon_all/source_git.yml', 'ansible-role-requirements.yml', 'inventory/group_vars/designate_all/source_git.yml', 'inventory/group_vars/swift_all/source_git.yml', 'inventory/group_vars/neutron_all/source_git.yml', 'inventory/group_vars/nova_all/source_git.yml', 'inventory/group_vars/octavia_all/source_git.yml']",13,88a602bde722d38d662ffb4a615d3b1616194661,bump_osa,### HEAD as of 03.07.2023 ###octavia_git_install_branch: 34d95db1332dea340ec1ca492cca71cdda53d7c2octavia_ovn_octavia_provider_git_install_branch: 217d1ab4317b886ef3544c029819121c91f0709f,### HEAD as of 30.05.2023 ###octavia_git_install_branch: 920dbfa5ad7d529ba0ee6ae2162fb73ddfc8ec13octavia_ovn_octavia_provider_git_install_branch: f6537b1d90a10d4e9bd03e93a2018d312df656bc,43,43
openstack%2Fbifrost~874854,openstack/bifrost,master,Id6279d681faf0c9a1893c00953b0b59d9319e08b,Fix key-order[task] linter warnings,MERGED,2023-02-23 09:19:51.000000000,2023-07-10 11:44:08.000000000,2023-07-10 11:43:10.000000000,"[{'_account_id': 4571}, {'_account_id': 10342}, {'_account_id': 22348}, {'_account_id': 25600}, {'_account_id': 32029}]","[{'number': 1, 'created': '2023-02-23 09:19:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/bifrost/commit/efe3f6de22c43998d1bddeb4b363163fba5dcf41', 'message': 'Fix key-order[task] linter warnings\n\nAlso make indentation consistent, and remove traces of Suse.\n\nChange-Id: Id6279d681faf0c9a1893c00953b0b59d9319e08b\n'}, {'number': 2, 'created': '2023-03-12 22:57:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/bifrost/commit/796e3c8a34da0cefe044dfa2ef011a3fddafe239', 'message': 'Fix key-order[task] linter warnings\n\nIt looks a little jarring at first so see keys ordered this way,\nbut once you get used to it, it reads so much better!\n\nAlso make indentation consistent, clean up epel install\nand remove traces of Suse.\n\nChange-Id: Id6279d681faf0c9a1893c00953b0b59d9319e08b\n'}, {'number': 3, 'created': '2023-05-30 18:01:22.000000000', 'files': ['playbooks/roles/bifrost-ironic-install/ssh_public_key_path.yaml', 'playbooks/roles/bifrost-pip-install/tasks/main.yml', 'playbooks/roles/bifrost-create-vm-nodes/tasks/prepare_libvirt.yml', 'playbooks/test-bifrost.yaml', 'playbooks/roles/bifrost-create-vm-nodes/tasks/create_vm.yml', 'playbooks/roles/bifrost-keystone-install/tasks/bootstrap.yml', 'playbooks/roles/bifrost-keystone-client-config/tasks/validate.yml', 'playbooks/roles/bifrost-download-packages/tasks/main.yml', 'playbooks/roles/bifrost-ironic-install/tasks/create_tftpboot.yml', '.ansible-lint', 'playbooks/roles/bifrost-ironic-install/tasks/bootstrap.yml', 'playbooks/roles/bifrost-ironic-install/tasks/install.yml', 'playbooks/roles/bifrost-deploy-nodes-dynamic/tasks/main.yml'], 'web_link': 'https://opendev.org/openstack/bifrost/commit/db24a0c721477d759bde03a7bbed4f48f6c30c74', 'message': 'Fix key-order[task] linter warnings\n\nIt looks a little jarring at first so see keys ordered this way,\nbut once you get used to it, it reads so much better!\n\nAlso make indentation consistent, clean up epel install\nand remove traces of Suse.\n\nChange-Id: Id6279d681faf0c9a1893c00953b0b59d9319e08b\n'}]",2,874854,db24a0c721477d759bde03a7bbed4f48f6c30c74,23,5,3,25600,,,0,"Fix key-order[task] linter warnings

It looks a little jarring at first so see keys ordered this way,
but once you get used to it, it reads so much better!

Also make indentation consistent, clean up epel install
and remove traces of Suse.

Change-Id: Id6279d681faf0c9a1893c00953b0b59d9319e08b
",git fetch https://review.opendev.org/openstack/bifrost refs/changes/54/874854/1 && git format-patch -1 --stdout FETCH_HEAD,"['playbooks/roles/bifrost-ironic-install/ssh_public_key_path.yaml', 'playbooks/roles/bifrost-pip-install/tasks/main.yml', 'playbooks/roles/bifrost-create-vm-nodes/tasks/prepare_libvirt.yml', 'playbooks/test-bifrost.yaml', 'playbooks/roles/bifrost-create-vm-nodes/tasks/create_vm.yml', 'playbooks/roles/bifrost-keystone-install/tasks/bootstrap.yml', 'playbooks/roles/bifrost-keystone-client-config/tasks/validate.yml', 'playbooks/roles/bifrost-download-packages/tasks/main.yml', 'playbooks/roles/bifrost-ironic-install/tasks/create_tftpboot.yml', 'playbooks/roles/bifrost-ironic-install/tasks/bootstrap.yml', 'playbooks/roles/bifrost-configdrives-dynamic/tasks/ssh_public_key_path.yaml', 'playbooks/roles/bifrost-ironic-install/tasks/install.yml', 'playbooks/roles/bifrost-deploy-nodes-dynamic/tasks/main.yml']",13,efe3f6de22c43998d1bddeb4b363163fba5dcf41,linters, when: instance_info is not defined or instance_info == {} block: when: - deploy_image_checksum is not defined - not deploy_image_source.startswith('file://') block:, block: block: when: - deploy_image_checksum is not defined - not deploy_image_source.startswith('file://') when: instance_info is not defined or instance_info == {} ,193,200
openstack%2Fopenstack-ansible~846228,openstack/openstack-ansible,master,I44cb4e6bb41976c9e5f87958400a7b5c0816553b,Reduce memory consumption in CI,ABANDONED,2022-06-16 21:58:28.000000000,2023-07-10 11:24:15.000000000,,"[{'_account_id': 22348}, {'_account_id': 28619}]","[{'number': 1, 'created': '2022-06-16 21:58:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/5a423850ff617f91b7586b74e339c741f739bc56', 'message': 'Reduce memory consumption in CI\n\nThis patch reduces memory usage of the different OpenStack Python\nservices by tuning glibc.\n\nThe specific tuning consist on disabling the per thread arenas and\ndisabling dynamic thresholds.\n\nRelated-To: https://review.opendev.org/c/openstack/tripleo-common/+/845807\nRelated-To: https://review.opendev.org/c/openstack/devstack/+/845805\nChange-Id: I44cb4e6bb41976c9e5f87958400a7b5c0816553b\n'}, {'number': 2, 'created': '2022-06-17 08:14:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/bd2d25e90f4b8c794cf91910e4f70cbe6fc1b94e', 'message': 'Reduce memory consumption in CI\n\nThis patch reduces memory usage of the different OpenStack Python\nservices by tuning glibc.\n\nThe specific tuning consist on disabling the per thread arenas and\ndisabling dynamic thresholds.\n\nRelated-To: https://review.opendev.org/c/openstack/tripleo-common/+/845807\nRelated-To: https://review.opendev.org/c/openstack/devstack/+/845805\nChange-Id: I44cb4e6bb41976c9e5f87958400a7b5c0816553b\n'}, {'number': 3, 'created': '2022-06-17 08:16:42.000000000', 'files': ['tests/roles/bootstrap-host/templates/user_variables.aio.yml.j2'], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/0e468455e5dcbff2ec58f30340c289ee8dd646af', 'message': 'Reduce memory consumption in CI\n\nThis patch reduces memory usage of the different OpenStack Python\nservices by tuning glibc.\n\nThe specific tuning consist on disabling the per thread arenas and\ndisabling dynamic thresholds.\n\nRelated-To: https://review.opendev.org/c/openstack/tripleo-common/+/845807\nRelated-To: https://review.opendev.org/c/openstack/devstack/+/845805\nChange-Id: I44cb4e6bb41976c9e5f87958400a7b5c0816553b\n'}]",4,846228,0e468455e5dcbff2ec58f30340c289ee8dd646af,10,2,3,28619,,,0,"Reduce memory consumption in CI

This patch reduces memory usage of the different OpenStack Python
services by tuning glibc.

The specific tuning consist on disabling the per thread arenas and
disabling dynamic thresholds.

Related-To: https://review.opendev.org/c/openstack/tripleo-common/+/845807
Related-To: https://review.opendev.org/c/openstack/devstack/+/845805
Change-Id: I44cb4e6bb41976c9e5f87958400a7b5c0816553b
",git fetch https://review.opendev.org/openstack/openstack-ansible refs/changes/28/846228/1 && git format-patch -1 --stdout FETCH_HEAD,"['tests/roles/bootstrap-host/files/user_variables_proxy.yml', 'tests/roles/bootstrap-host/templates/user_variables.aio.yml.j2']",2,5a423850ff617f91b7586b74e339c741f739bc56,846228,global_environment_variables: MALLOC_ARENA_MAX: 2 MALLOC_MMAP_THRESHOLD_: 131072 MALLOC_TRIM_THRESHOLD_: 262144 ,,8,0
openstack%2Fglance~879304,openstack/glance,master,Ic7b93b387ea93a9eec94a92920770e0e361c579d,Fix parameter verification in import_image(),NEW,2023-04-04 06:42:49.000000000,2023-07-10 09:42:12.000000000,,"[{'_account_id': 9303}, {'_account_id': 22348}]","[{'number': 1, 'created': '2023-04-04 06:42:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/5acde251f316649f8ec1fc25a83f697bebe697f0', 'message': 'Fix parameter verification in import_image()\n\nA logic problem occurred in import_image() function,\nfix it.\n\nChange-Id: Ic7b93b387ea93a9eec94a92920770e0e361c579d\n'}, {'number': 2, 'created': '2023-07-10 07:39:08.000000000', 'files': ['glance/api/v2/images.py', 'api-ref/source/v2/images-import.inc', 'glance/tests/unit/v2/test_images_resource.py'], 'web_link': 'https://opendev.org/openstack/glance/commit/ee44dfd571309919063659c6ccbe58c632132ea7', 'message': 'Fix parameter verification in import_image()\n\n1. A logic problem occurred in import_image() function,\nfix it.\n2. Setting all_stores_must_succeed default to False.\n\nChange-Id: Ic7b93b387ea93a9eec94a92920770e0e361c579d\n'}]",5,879304,ee44dfd571309919063659c6ccbe58c632132ea7,14,2,2,30858,,,0,"Fix parameter verification in import_image()

1. A logic problem occurred in import_image() function,
fix it.
2. Setting all_stores_must_succeed default to False.

Change-Id: Ic7b93b387ea93a9eec94a92920770e0e361c579d
",git fetch https://review.opendev.org/openstack/glance refs/changes/04/879304/1 && git format-patch -1 --stdout FETCH_HEAD,['glance/api/v2/images.py'],1,5acde251f316649f8ec1fc25a83f697bebe697f0,, if all_stores_must_succeed and (not CONF.enabled_backends):, if (not all_stores_must_succeed) and (not CONF.enabled_backends):,1,1
openstack%2Foctavia~760065,openstack/octavia,master,Iae9bc44f39ccea406b482f5008d3cb569c41e631,update requirements,ABANDONED,2020-10-28 07:46:31.000000000,2023-07-10 08:37:06.000000000,,[{'_account_id': 22348}],"[{'number': 1, 'created': '2020-10-28 07:46:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/octavia/commit/a63554e8b2d97c6502021ffe17076e8c77d442ed', 'message': 'Bump hacking min version to 3.0.1\n\nhacking 3.0.1 fix the pinning of flake8 to avoid bringing in a new\nversion with new checks.\n\nbumping the min version for hacking so that any older hacking versions\nwhich auto adopt the new checks are not used.\n\nChange-Id: Iae9bc44f39ccea406b482f5008d3cb569c41e631\n'}, {'number': 2, 'created': '2020-10-29 02:08:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/octavia/commit/a151fcc144f5d0ce5fee748f9fbdf06b62f87bb0', 'message': 'update requirements\n\nWe also need to change the lower-constraint requirements to make them\npy3.8 compatible. See https://bugs.launchpad.net/nova/+bug/1886298\n\nMarkupSafe==1.1.1\nparamiko==2.7.1\n\nChange-Id: Iae9bc44f39ccea406b482f5008d3cb569c41e631\n'}, {'number': 3, 'created': '2020-12-27 03:41:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/octavia/commit/85d2667617233ca7a4e837d027b615a4430410a5', 'message': 'update requirements\n\nWe also need to change the lower-constraint requirements to make them\npy3.8 compatible. See https://bugs.launchpad.net/nova/+bug/1886298\n\nMarkupSafe==1.1.1\nparamiko==2.7.1\n\nChange-Id: Iae9bc44f39ccea406b482f5008d3cb569c41e631\n'}, {'number': 4, 'created': '2020-12-27 08:19:24.000000000', 'files': ['test-requirements.txt', 'lower-constraints.txt'], 'web_link': 'https://opendev.org/openstack/octavia/commit/a3ab813a11d91bc74909868d4a8fe8a8e5b070f1', 'message': 'update requirements\n\nWe also need to change the lower-constraint requirements to make them\npy3.8 compatible. See https://bugs.launchpad.net/nova/+bug/1886298\n\nMarkupSafe==1.1.1\nparamiko==2.7.1\n\nChange-Id: Iae9bc44f39ccea406b482f5008d3cb569c41e631\n'}]",0,760065,a3ab813a11d91bc74909868d4a8fe8a8e5b070f1,12,1,4,32029,,,0,"update requirements

We also need to change the lower-constraint requirements to make them
py3.8 compatible. See https://bugs.launchpad.net/nova/+bug/1886298

MarkupSafe==1.1.1
paramiko==2.7.1

Change-Id: Iae9bc44f39ccea406b482f5008d3cb569c41e631
",git fetch https://review.opendev.org/openstack/octavia refs/changes/65/760065/1 && git format-patch -1 --stdout FETCH_HEAD,['test-requirements.txt'],1,a63554e8b2d97c6502021ffe17076e8c77d442ed,hacking-fix,hacking>=3.0.1 # Apache-2.0,hacking>=3.0 # Apache-2.0,1,1
openstack%2Fos-brick~872536,openstack/os-brick,master,I819e32f807bcba4c9d6f928f2ad04c4dd27f22c2,linuxrbd: Remove rados_connect_timeout parameter,MERGED,2023-02-06 20:59:45.000000000,2023-07-10 08:36:56.000000000,2023-07-10 08:35:56.000000000,"[{'_account_id': 5314}, {'_account_id': 20813}, {'_account_id': 22348}, {'_account_id': 27615}, {'_account_id': 35075}]","[{'number': 1, 'created': '2023-02-06 20:59:45.000000000', 'files': ['os_brick/initiator/linuxrbd.py'], 'web_link': 'https://opendev.org/openstack/os-brick/commit/acd0265f8d806341672ede5597441967edd5c5d2', 'message': ""linuxrbd: Remove rados_connect_timeout parameter\n\nThis parameter doesn't do anything, we should skip it here.\n\nhttps://docs.ceph.com/en/latest/rados/api/python/#rados.Rados.connect\nhttps://github.com/ceph/ceph/blob/974339d1f/src/pybind/rados/rados.pyx#L674\n\nChange-Id: I819e32f807bcba4c9d6f928f2ad04c4dd27f22c2\n""}]",4,872536,acd0265f8d806341672ede5597441967edd5c5d2,22,5,1,4523,,,0,"linuxrbd: Remove rados_connect_timeout parameter

This parameter doesn't do anything, we should skip it here.

https://docs.ceph.com/en/latest/rados/api/python/#rados.Rados.connect
https://github.com/ceph/ceph/blob/974339d1f/src/pybind/rados/rados.pyx#L674

Change-Id: I819e32f807bcba4c9d6f928f2ad04c4dd27f22c2
",git fetch https://review.opendev.org/openstack/os-brick refs/changes/36/872536/1 && git format-patch -1 --stdout FETCH_HEAD,['os_brick/initiator/linuxrbd.py'],1,acd0265f8d806341672ede5597441967edd5c5d2,," LOG.debug(""opening connection to ceph cluster"") client.connect()"," self.rados_connect_timeout: int = kwargs.get('rados_connect_timeout', -1) LOG.debug(""opening connection to ceph cluster (timeout=%s)."", self.rados_connect_timeout) if self.rados_connect_timeout >= 0: client.connect( timeout=self.rados_connect_timeout) else: client.connect()",2,9
openstack%2Fpython-zaqarclient~758982,openstack/python-zaqarclient,master,I7ad69220a938d27529b794830c9da3221dd150c7,bump py37 to py38 in tox.ini,ABANDONED,2020-10-21 09:43:34.000000000,2023-07-10 08:36:55.000000000,,"[{'_account_id': 22348}, {'_account_id': 32029}]","[{'number': 1, 'created': '2020-10-21 09:43:34.000000000', 'files': ['setup.cfg', 'tox.ini'], 'web_link': 'https://opendev.org/openstack/python-zaqarclient/commit/09e6cc9261894709b2532d7536a6f2a6c50b9b65', 'message': ""bump py37 to py38 in tox.ini\n\nfrom 'victoria' cycle, we should test py38 by default.\n\n[1] https://governance.openstack.org/tc/reference/runtimes/victoria.html\n\nChange-Id: I7ad69220a938d27529b794830c9da3221dd150c7\n""}]",0,758982,09e6cc9261894709b2532d7536a6f2a6c50b9b65,5,2,1,32029,,,0,"bump py37 to py38 in tox.ini

from 'victoria' cycle, we should test py38 by default.

[1] https://governance.openstack.org/tc/reference/runtimes/victoria.html

Change-Id: I7ad69220a938d27529b794830c9da3221dd150c7
",git fetch https://review.opendev.org/openstack/python-zaqarclient refs/changes/82/758982/1 && git format-patch -1 --stdout FETCH_HEAD,"['setup.cfg', 'tox.ini']",2,09e6cc9261894709b2532d7536a6f2a6c50b9b65,py38,"envlist = py38,pep8","envlist = py37,pep8",2,1
openstack%2Fpython-barbicanclient~844258,openstack/python-barbicanclient,master,I11d75990bcfddd54c4d0346823e972554a216c2c,Drop python3.6/3.7 support in testing runtime,ABANDONED,2022-06-01 08:26:30.000000000,2023-07-10 08:36:07.000000000,,"[{'_account_id': 7973}, {'_account_id': 14250}, {'_account_id': 22348}]","[{'number': 1, 'created': '2022-06-01 08:26:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-barbicanclient/commit/a14579a78dd7b2c4a95dc7e9d120009429c111fb', 'message': 'Drop python3.6/3.7 support in testing runtime\n\nIn Zed cycle testing runtime, we are targetting to drop the\npython 3.6/3.7 support, project started adding python 3.8 as minimum\n\n[1] https://governance.openstack.org/tc/reference/runtimes/zed.html\n\nChange-Id: I11d75990bcfddd54c4d0346823e972554a216c2c\n'}, {'number': 2, 'created': '2023-02-10 11:46:22.000000000', 'files': ['setup.cfg'], 'web_link': 'https://opendev.org/openstack/python-barbicanclient/commit/db45c116c0e11214976816a753fb3556bdff8eeb', 'message': 'Drop python3.6/3.7 support in testing runtime\n\nIn Zed cycle testing runtime, we are targetting to drop the\npython 3.6/3.7 support, project started adding python 3.8 as minimum\n\n[1] https://governance.openstack.org/tc/reference/runtimes/zed.html\n\nChange-Id: I11d75990bcfddd54c4d0346823e972554a216c2c\n'}]",2,844258,db45c116c0e11214976816a753fb3556bdff8eeb,7,3,2,32029,,,0,"Drop python3.6/3.7 support in testing runtime

In Zed cycle testing runtime, we are targetting to drop the
python 3.6/3.7 support, project started adding python 3.8 as minimum

[1] https://governance.openstack.org/tc/reference/runtimes/zed.html

Change-Id: I11d75990bcfddd54c4d0346823e972554a216c2c
",git fetch https://review.opendev.org/openstack/python-barbicanclient refs/changes/58/844258/1 && git format-patch -1 --stdout FETCH_HEAD,['setup.cfg'],1,a14579a78dd7b2c4a95dc7e9d120009429c111fb,setup,, Programming Language :: Python :: 3.6 Programming Language :: Python :: 3.7,0,2
openstack%2Fglance~886754,openstack/glance,master,Ide428268f52527972165ab59ac6e3da0688968f4,Remove the last occurrence of six.add_metaclass,MERGED,2023-06-22 13:50:25.000000000,2023-07-10 08:21:51.000000000,2023-07-10 08:20:27.000000000,"[{'_account_id': 4393}, {'_account_id': 9303}, {'_account_id': 22348}, {'_account_id': 32238}]","[{'number': 1, 'created': '2023-06-22 13:50:25.000000000', 'files': ['glance/async_/flows/_internal_plugins/base_download.py'], 'web_link': 'https://opendev.org/openstack/glance/commit/11061d5b5a11fec0fb2ca6d55b0f116b8c716928', 'message': 'Remove the last occurrence of six.add_metaclass\n\nChange-Id: Ide428268f52527972165ab59ac6e3da0688968f4\n'}]",7,886754,11061d5b5a11fec0fb2ca6d55b0f116b8c716928,55,4,1,8122,,,0,"Remove the last occurrence of six.add_metaclass

Change-Id: Ide428268f52527972165ab59ac6e3da0688968f4
",git fetch https://review.opendev.org/openstack/glance refs/changes/54/886754/1 && git format-patch -1 --stdout FETCH_HEAD,['glance/async_/flows/_internal_plugins/base_download.py'],1,11061d5b5a11fec0fb2ca6d55b0f116b8c716928,remove-six-metaclass,"class BaseDownload(task.Task, metaclass=abc.ABCMeta):",import six@six.add_metaclass(abc.ABCMeta) class BaseDownload(task.Task):,1,3
openstack%2Fdesignate~888005,openstack/designate,master,I7c30db493111107aba79de6c5361ab0726046704,Imported Translations from Zanata,MERGED,2023-07-08 02:53:33.000000000,2023-07-10 08:19:10.000000000,2023-07-10 08:17:33.000000000,"[{'_account_id': 22348}, {'_account_id': 22623}]","[{'number': 1, 'created': '2023-07-08 02:53:33.000000000', 'files': ['releasenotes/source/locale/en_GB/LC_MESSAGES/releasenotes.po'], 'web_link': 'https://opendev.org/openstack/designate/commit/963751f2b403c3e9a73008ac62854ed3d3758247', 'message': 'Imported Translations from Zanata\n\nFor more information about this automatic import see:\nhttps://docs.openstack.org/i18n/latest/reviewing-translation-import.html\n\nChange-Id: I7c30db493111107aba79de6c5361ab0726046704\n'}]",0,888005,963751f2b403c3e9a73008ac62854ed3d3758247,7,2,1,11131,,,0,"Imported Translations from Zanata

For more information about this automatic import see:
https://docs.openstack.org/i18n/latest/reviewing-translation-import.html

Change-Id: I7c30db493111107aba79de6c5361ab0726046704
",git fetch https://review.opendev.org/openstack/designate refs/changes/05/888005/1 && git format-patch -1 --stdout FETCH_HEAD,['releasenotes/source/locale/en_GB/LC_MESSAGES/releasenotes.po'],1,963751f2b403c3e9a73008ac62854ed3d3758247,zanata/translations,"""POT-Creation-Date: 2023-07-05 16:39+0000\n""""PO-Revision-Date: 2023-07-07 09:08+0000\n""msgid ""15.0.0-7"" msgstr ""15.0.0-7""msgid ""16.0.0-45"" msgstr ""16.0.0-45""msgid """" ""Fixed issues with list zones and recordsets when a zone is shared with more "" ""than one project."" msgstr """" ""Fixed issues with list zones and recordsets when a zone is shared with more "" ""than one project."" ","""POT-Creation-Date: 2023-06-08 16:18+0000\n""""PO-Revision-Date: 2023-06-17 02:38+0000\n""msgid ""15.0.0-6"" msgstr ""15.0.0-6""msgid ""16.0.0-41"" msgstr ""16.0.0-41""",13,6
openstack%2Fcharm-ceph-mon~888009,openstack/charm-ceph-mon,master,I07314133118939a9fe24603342282e24057d5b9f,DNM: test merge request,ABANDONED,2023-07-08 19:43:19.000000000,2023-07-10 07:04:47.000000000,,"[{'_account_id': 20648}, {'_account_id': 22348}]","[{'number': 1, 'created': '2023-07-08 19:43:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-ceph-mon/commit/28abe435367428556b4ddf798752b2c797368c60', 'message': 'DNM: test merge request\n\nChange-Id: I07314133118939a9fe24603342282e24057d5b9f\n'}]",0,888009,28abe435367428556b4ddf798752b2c797368c60,4,2,1,15382,,,0,"DNM: test merge request

Change-Id: I07314133118939a9fe24603342282e24057d5b9f
",git fetch https://review.opendev.org/openstack/charm-ceph-mon refs/changes/09/888009/1 && git format-patch -1 --stdout FETCH_HEAD,[],0,28abe435367428556b4ddf798752b2c797368c60,,,,0,0
openstack%2Ftacker-specs~887772,openstack/tacker-specs,master,I20a70c12c565ca3a86ff34f4b9c9007207edf8aa,Fix Pillow version to 9.5.0,MERGED,2023-07-06 08:54:00.000000000,2023-07-10 05:47:28.000000000,2023-07-10 05:46:30.000000000,"[{'_account_id': 17255}, {'_account_id': 22348}, {'_account_id': 25701}, {'_account_id': 31668}, {'_account_id': 31857}, {'_account_id': 32029}, {'_account_id': 33455}, {'_account_id': 34712}, {'_account_id': 35978}]","[{'number': 1, 'created': '2023-07-06 08:54:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tacker-specs/commit/8dcc46659a108ea43463697205ad1ae4c31b337c', 'message': 'Downgrade Pillows version\n\nThis patch is for downgrading the\nPillow version from 10.0 to 9.5.\n\nChange-Id: I20a70c12c565ca3a86ff34f4b9c9007207edf8aa\n'}, {'number': 2, 'created': '2023-07-06 08:55:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tacker-specs/commit/9d44a167e113307c903e05bd193d917d17f37ea9', 'message': 'Downgrade Pillows version\n\nThis patch is for downgrading the\nPillow version from 10.0 to 9.5.\n\nChange-Id: I20a70c12c565ca3a86ff34f4b9c9007207edf8aa\n'}, {'number': 3, 'created': '2023-07-07 00:03:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tacker-specs/commit/9247a42998c0b7e06ff2d54be4290ff65486f1f8', 'message': ""Downgrade Pillows version\n\nThis patch is for downgrading the\nPillow version from 10.0 to 9.5.\n\nIamgeDrew.textsize was removed in version 10 of the Pillows.\nHowever, Sphinx uses ImageDrew.textsize.\nwe need to downgrade until Sphinx supports ImageDrew.\n\nIn addition, the current tacker-spec's tox does not have Pillow version\ncontrol.\nFix tox to use openstack requirements[1].\n\n[1]\nhttps://opendev.org/openstack/requirements/src/branch/master/upper-constraints.txt\n\nChange-Id: I20a70c12c565ca3a86ff34f4b9c9007207edf8aa\n""}, {'number': 4, 'created': '2023-07-07 00:06:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tacker-specs/commit/da8f0582bdcc801113487a8ef818898fd2143c09', 'message': ""Fix tox to upper-constraints\n\nthe current tacker-spec's tox does not have version\ncontrol.\nFix tox to use openstack requirements[1].\n\n[1]\nhttps://opendev.org/openstack/requirements/src/branch/master/upper-constraints.txt\n\nChange-Id: I20a70c12c565ca3a86ff34f4b9c9007207edf8aa\n""}, {'number': 5, 'created': '2023-07-07 00:14:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tacker-specs/commit/1c07cce8e10e9ee12f48ac5498caaf56f37d0f0e', 'message': ""Fix tox to use upper-constraints\n\nthe current tacker-spec's tox does not have version\ncontrol.\nFix tox to use openstack requirements[1].\n\n[1]\nhttps://opendev.org/openstack/requirements/src/branch/master/upper-constraints.txt\n\nChange-Id: I20a70c12c565ca3a86ff34f4b9c9007207edf8aa\n""}, {'number': 6, 'created': '2023-07-07 07:34:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tacker-specs/commit/094c56e84d55f3b714e41c6cb70722a52096b427', 'message': ""Fix tox to use upper-constraints\n\nThe current tacker-spec's tox does not have version\ncontrol.\nFix tox to use openstack requirements[1].\n\nUpper-constraints requirements pillow version 9.5.0.\nThis patch fixed tacker-spec's pillow and shpinx bug[2].\n\n[1]\nhttps://opendev.org/openstack/requirements/src/branch/master/upper-constraints.txt\n[2]\nhttps://bugs.launchpad.net/tacker/+bug/2026345\n\nChange-Id: I20a70c12c565ca3a86ff34f4b9c9007207edf8aa\n""}, {'number': 7, 'created': '2023-07-07 08:16:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tacker-specs/commit/85163078759ad1106504ff0e701540dd43eddeaa', 'message': ""Fix tox to use upper-constraints\n\nThe current tacker-spec's tox does not have version\ncontrol.\nFix tox to use openstack requirements[1].\n\nUpper-constraints requirements pillow version 9.5.0.\nThis patch fixed tacker-spec's pillow and shpinx problem.\n\n[1]\nhttps://opendev.org/openstack/requirements/src/branch/master/upper-constraints.txt\n\nChange-Id: I20a70c12c565ca3a86ff34f4b9c9007207edf8aa\nCloses-Bug: #2026345\n""}, {'number': 8, 'created': '2023-07-09 23:47:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tacker-specs/commit/0f0d3ac9a601be6f639effd147e997818d3a5c49', 'message': ""Fix tox to use upper-constraints\n\nThe current tacker-spec's tox does not have version\ncontrol.\nFix tox to use openstack requirements[1].\n\nUpper-constraints requirements pillow version 9.5.0.\nThis patch fixed tacker-spec's pillow and sphinx's problem.\n\n[1]\nhttps://opendev.org/openstack/requirements/src/branch/master/upper-constraints.txt\n\nChange-Id: I20a70c12c565ca3a86ff34f4b9c9007207edf8aa\nCloses-Bug: #2026345\n""}, {'number': 9, 'created': '2023-07-09 23:56:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tacker-specs/commit/5ca00db94f879c0573df24c67b9f7f637c5e478b', 'message': ""Fix Pillow version to 9.5.0\n\nThe current tacker-spec's tox does not have version\ncontrol.\n\nThis patch fixes the problem of pillow and sphinx's by\nselecting version 9.5.0.\n\n[1]\nhttps://opendev.org/openstack/requirements/src/branch/master/upper-constraints.txt\n\nChange-Id: I20a70c12c565ca3a86ff34f4b9c9007207edf8aa\nCloses-Bug: #2026345\n""}, {'number': 10, 'created': '2023-07-10 02:45:28.000000000', 'files': ['doc/requirements.txt'], 'web_link': 'https://opendev.org/openstack/tacker-specs/commit/66c3a8b7d8b2cde832a0bea2c0d5bc8b8fb158c2', 'message': ""Fix Pillow version to 9.5.0\n\nThis patch fixes the problem of pillow and sphinx's by\nselecting version 9.5.0.\n\n[1]\nhttps://opendev.org/openstack/requirements/src/branch/master/upper-constraints.txt\n\nChange-Id: I20a70c12c565ca3a86ff34f4b9c9007207edf8aa\nCloses-Bug: #2026345\n""}]",26,887772,66c3a8b7d8b2cde832a0bea2c0d5bc8b8fb158c2,40,9,10,32707,,,0,"Fix Pillow version to 9.5.0

This patch fixes the problem of pillow and sphinx's by
selecting version 9.5.0.

[1]
https://opendev.org/openstack/requirements/src/branch/master/upper-constraints.txt

Change-Id: I20a70c12c565ca3a86ff34f4b9c9007207edf8aa
Closes-Bug: #2026345
",git fetch https://review.opendev.org/openstack/tacker-specs refs/changes/72/887772/1 && git format-patch -1 --stdout FETCH_HEAD,['tox.ini'],1,8dcc46659a108ea43463697205ad1ae4c31b337c,bug/2026345,deps = -c{env:TOX_CONSTRAINTS_FILE:https://releases.openstack.org/constraints/upper/master} -r{toxinidir}/doc/requirements.txt ,deps = -r{toxinidir}/doc/requirements.txt,4,1
openstack%2Fmanila-specs~881934,openstack/manila-specs,master,Ib184995f6fce2a9aaa60f8251513d58c5b663112,Access rule visibility and deletion restrictions,MERGED,2023-05-01 23:10:47.000000000,2023-07-10 02:53:22.000000000,2023-07-10 02:52:13.000000000,"[{'_account_id': 4393}, {'_account_id': 11604}, {'_account_id': 16207}, {'_account_id': 22348}, {'_account_id': 29632}, {'_account_id': 30407}]","[{'number': 1, 'created': '2023-05-01 23:10:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/manila-specs/commit/68bdcb2e0c52b4ab057aab04448fcf1e4a9179a8', 'message': 'Access rule visibility and deletion restrictions\n\nDesign of better visibility and manipulation protections\nto access rules of a share.\n\nAPIImpact\nPartially-Implements: bp protect-access-rules\n\nChange-Id: Ib184995f6fce2a9aaa60f8251513d58c5b663112\nSigned-off-by: Goutham Pacha Ravi <gouthampravi@gmail.com>\n'}, {'number': 2, 'created': '2023-06-14 05:50:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/manila-specs/commit/211db932384e197503b1029807a4836cb44aa63c', 'message': 'Access rule visibility and deletion restrictions\n\nDesign of better visibility and manipulation protections\nto access rules of a share.\n\nAPIImpact\nPartially-Implements: bp protect-access-rules\n\nChange-Id: Ib184995f6fce2a9aaa60f8251513d58c5b663112\nSigned-off-by: Goutham Pacha Ravi <gouthampravi@gmail.com>\n'}, {'number': 3, 'created': '2023-07-06 17:23:59.000000000', 'files': ['specs/bobcat/protect-access-rules.rst', 'doc/source/index.rst', 'specs/bobcat/allow-locking-shares-against-deletion.rst'], 'web_link': 'https://opendev.org/openstack/manila-specs/commit/10e4c609fea5838f4b7dd128626568e1f0a5a2f1', 'message': 'Access rule visibility and deletion restrictions\n\nDesign of better visibility and manipulation protections\nto access rules of a share.\n\nAPIImpact\nPartially-Implements: bp protect-access-rules\n\nChange-Id: Ib184995f6fce2a9aaa60f8251513d58c5b663112\nSigned-off-by: Goutham Pacha Ravi <gouthampravi@gmail.com>\n'}]",81,881934,10e4c609fea5838f4b7dd128626568e1f0a5a2f1,28,6,3,16643,,,0,"Access rule visibility and deletion restrictions

Design of better visibility and manipulation protections
to access rules of a share.

APIImpact
Partially-Implements: bp protect-access-rules

Change-Id: Ib184995f6fce2a9aaa60f8251513d58c5b663112
Signed-off-by: Goutham Pacha Ravi <gouthampravi@gmail.com>
",git fetch https://review.opendev.org/openstack/manila-specs refs/changes/34/881934/1 && git format-patch -1 --stdout FETCH_HEAD,"['specs/bobcat/protect-access-rules.rst', 'doc/source/index.rst']",2,68bdcb2e0c52b4ab057aab04448fcf1e4a9179a8,bp/protect-access-rules,2023.2 Bobcat approved specs ============================ .. toctree:: :glob: :maxdepth: 1 specs/bobcat/* 2023.1 Antelope approved specs ==============================,Antelope approved specs =======================,378,2
openstack%2Fneutron~860766,openstack/neutron,master,I758c376f55b71d7159fa3f5d83e47d2b05da3218,Refactor for ovs qos driver meter limit features,MERGED,2022-10-09 01:50:35.000000000,2023-07-10 02:49:31.000000000,2023-07-10 02:48:02.000000000,"[{'_account_id': 8313}, {'_account_id': 9531}, {'_account_id': 9845}, {'_account_id': 11975}, {'_account_id': 22348}]","[{'number': 1, 'created': '2022-10-09 01:50:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/2a36d111e057daff514a944f8b881dc0265a7003', 'message': 'Refactor for ovs qos driver meter limit features\n\nMove common functions create/update/delete_packet_rate_limit\nto the QosOVSAgentDriver, and keep special driver methods in\ntheir own classes.\n\nCloses-Bug: #1964342\nChange-Id: I758c376f55b71d7159fa3f5d83e47d2b05da3218\n'}, {'number': 2, 'created': '2022-10-09 06:57:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/0dc07ac0570ed57a6d5ae3636b6d4e1ff4cae658', 'message': 'Refactor for ovs qos driver meter limit features\n\nMove common functions create/update/delete_packet_rate_limit\nto the QosOVSAgentDriver, and keep special driver methods in\ntheir own classes.\n\nCloses-Bug: #1964342\nChange-Id: I758c376f55b71d7159fa3f5d83e47d2b05da3218\n'}, {'number': 3, 'created': '2022-10-18 03:05:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/3b0a5e493aef282de8af924a9746fca2769fc406', 'message': 'Refactor for ovs qos driver meter limit features\n\nMove common functions create/update/delete_packet_rate_limit\nto the QosOVSAgentDriver, and keep special driver methods in\ntheir own classes.\n\nCloses-Bug: #1964342\nChange-Id: I758c376f55b71d7159fa3f5d83e47d2b05da3218\n'}, {'number': 4, 'created': '2022-10-19 01:44:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/d66cd08f372ea03f568fa1a2a7edf467cb723844', 'message': 'Refactor for ovs qos driver meter limit features\n\nMove common functions create/update/delete_packet_rate_limit\nto the QosOVSAgentDriver, and keep special driver methods in\ntheir own classes.\n\nCloses-Bug: #1964342\nChange-Id: I758c376f55b71d7159fa3f5d83e47d2b05da3218\n'}, {'number': 5, 'created': '2022-11-14 01:40:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/129d08ecbad5697731897cd723d326c3cd1f21b4', 'message': 'Refactor for ovs qos driver meter limit features\n\nMove common functions create/update/delete_packet_rate_limit\nto the QosOVSAgentDriver, and keep special driver methods in\ntheir own classes.\n\nCloses-Bug: #1964342\nChange-Id: I758c376f55b71d7159fa3f5d83e47d2b05da3218\n'}, {'number': 6, 'created': '2022-11-14 03:40:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/1c3c447cfa8dfc85b9a16359478c4e3d4d31ec5d', 'message': 'Refactor for ovs qos driver meter limit features\n\nMove common functions create/update/delete_packet_rate_limit\nto the QosOVSAgentDriver, and keep special driver methods in\ntheir own classes.\n\nCloses-Bug: #1964342\nChange-Id: I758c376f55b71d7159fa3f5d83e47d2b05da3218\n'}, {'number': 7, 'created': '2022-11-14 06:47:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/5ee6434540da04132bc2568036a84bb406281472', 'message': 'Refactor for ovs qos driver meter limit features\n\nMove common functions create/update/delete_packet_rate_limit\nto the QosOVSAgentDriver, and keep special driver methods in\ntheir own classes.\n\nCloses-Bug: #1964342\nChange-Id: I758c376f55b71d7159fa3f5d83e47d2b05da3218\n'}, {'number': 8, 'created': '2022-11-15 02:21:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/beff37583ba5129f334c9989b4dbc5e1289a3d56', 'message': 'Refactor for ovs qos driver meter limit features\n\nMove common functions create/update/delete_packet_rate_limit\nto the QosOVSAgentDriver, and keep special driver methods in\ntheir own classes.\n\nCloses-Bug: #1964342\nChange-Id: I758c376f55b71d7159fa3f5d83e47d2b05da3218\n'}, {'number': 9, 'created': '2022-11-16 01:33:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/15f67175aa97f32bb9925c74183b739f264b98f0', 'message': 'Refactor for ovs qos driver meter limit features\n\nMove common functions create/update/delete_packet_rate_limit\nto the QosOVSAgentDriver, and keep special driver methods in\ntheir own classes.\n\nCloses-Bug: #1964342\nChange-Id: I758c376f55b71d7159fa3f5d83e47d2b05da3218\n'}, {'number': 10, 'created': '2022-12-05 04:18:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/874b3e03f61fcd49070ab05cb2fa205a9503231b', 'message': 'Refactor for ovs qos driver meter limit features\n\nMove common functions create/update/delete_packet_rate_limit\nto the QosOVSAgentDriver, and keep special driver methods in\ntheir own classes.\n\nCloses-Bug: #1964342\nChange-Id: I758c376f55b71d7159fa3f5d83e47d2b05da3218\n'}, {'number': 11, 'created': '2022-12-05 04:20:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/dc3d1dfa29cac770de925549b6094add9ef95e9e', 'message': 'Refactor for ovs qos driver meter limit features\n\nMove common functions create/update/delete_packet_rate_limit\nto the QosOVSAgentDriver, and keep special driver methods in\ntheir own classes.\n\nCloses-Bug: #1964342\nChange-Id: I758c376f55b71d7159fa3f5d83e47d2b05da3218\n'}, {'number': 12, 'created': '2022-12-14 03:07:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/11295e130f135ebc6d65818dc0b7754b02a1b900', 'message': 'Refactor for ovs qos driver meter limit features\n\nMove common functions create/update/delete_packet_rate_limit\nto the QosOVSAgentDriver, and keep special driver methods in\ntheir own classes.\n\nCloses-Bug: #1964342\nChange-Id: I758c376f55b71d7159fa3f5d83e47d2b05da3218\n'}, {'number': 13, 'created': '2022-12-16 00:55:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/334016e0141862c8c409251649578c9a0f9aee54', 'message': 'Refactor for ovs qos driver meter limit features\n\nMove common functions create/update/delete_packet_rate_limit\nto the QosOVSAgentDriver, and keep special driver methods in\ntheir own classes.\n\nCloses-Bug: #1964342\nChange-Id: I758c376f55b71d7159fa3f5d83e47d2b05da3218\n'}, {'number': 14, 'created': '2022-12-21 02:05:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/20b99eb63d0402139bb965bb863e3dc60b68610a', 'message': 'Refactor for ovs qos driver meter limit features\n\nMove common functions create/update/delete_packet_rate_limit\nto the QosOVSAgentDriver, and keep special driver methods in\ntheir own classes.\n\nCloses-Bug: #1964342\nChange-Id: I758c376f55b71d7159fa3f5d83e47d2b05da3218\n'}, {'number': 15, 'created': '2023-03-09 01:34:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/dd886cf8b049a7f62db78cf75095561989f21744', 'message': 'Refactor for ovs qos driver meter limit features\n\nMove common functions create/update/delete_packet_rate_limit\nto the QosOVSAgentDriver, and keep special driver methods in\ntheir own classes.\n\nCloses-Bug: #1964342\nChange-Id: I758c376f55b71d7159fa3f5d83e47d2b05da3218\n'}, {'number': 16, 'created': '2023-04-11 01:52:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/e39145073e3d782f8a02b9771e9c512ed7389577', 'message': 'Refactor for ovs qos driver meter limit features\n\nMove common functions create/update/delete_packet_rate_limit\nto the QosOVSAgentDriver, and keep special driver methods in\ntheir own classes.\n\nCloses-Bug: #1964342\nChange-Id: I758c376f55b71d7159fa3f5d83e47d2b05da3218\n'}, {'number': 17, 'created': '2023-06-01 07:14:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/e839702fea6c29865ac35c7188e61e64161fe7a4', 'message': 'Refactor for ovs qos driver meter limit features\n\nMove common functions create/update/delete_packet_rate_limit\nto the QosOVSAgentDriver, and keep special driver methods in\ntheir own classes.\n\nCloses-Bug: #1964342\nChange-Id: I758c376f55b71d7159fa3f5d83e47d2b05da3218\n'}, {'number': 18, 'created': '2023-07-05 08:52:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/acdaf3c07ce18ce31cf85126df53cff0e60a28b4', 'message': 'Refactor for ovs qos driver meter limit features\n\nMove common functions create/update/delete_packet_rate_limit\nto the QosOVSAgentDriver, and keep special driver methods in\ntheir own classes.\n\nCloses-Bug: #1964342\nChange-Id: I758c376f55b71d7159fa3f5d83e47d2b05da3218\n'}, {'number': 19, 'created': '2023-07-05 09:51:06.000000000', 'files': ['neutron/tests/common/agents/l2_extensions.py', 'neutron/plugins/ml2/drivers/openvswitch/agent/extension_drivers/qos_driver.py', 'neutron/tests/unit/plugins/ml2/drivers/openvswitch/agent/extension_drivers/test_qos_driver.py', 'neutron/tests/unit/plugins/ml2/drivers/openvswitch/agent/openflow/native/test_br_int.py', 'neutron/plugins/ml2/drivers/openvswitch/agent/openflow/native/br_int.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/02b12b09175c8608ac7d2032baa5d6caf01c660b', 'message': 'Refactor for ovs qos driver meter limit features\n\nMove common functions create/update/delete_packet_rate_limit\nto the QosOVSAgentDriver, and keep special driver methods in\ntheir own classes.\n\nCloses-Bug: #1964342\nChange-Id: I758c376f55b71d7159fa3f5d83e47d2b05da3218\n'}]",32,860766,02b12b09175c8608ac7d2032baa5d6caf01c660b,124,5,19,9531,,,0,"Refactor for ovs qos driver meter limit features

Move common functions create/update/delete_packet_rate_limit
to the QosOVSAgentDriver, and keep special driver methods in
their own classes.

Closes-Bug: #1964342
Change-Id: I758c376f55b71d7159fa3f5d83e47d2b05da3218
",git fetch https://review.opendev.org/openstack/neutron refs/changes/66/860766/1 && git format-patch -1 --stdout FETCH_HEAD,"['neutron/plugins/ml2/drivers/openvswitch/agent/extension_drivers/qos_driver.py', 'neutron/tests/unit/plugins/ml2/drivers/openvswitch/agent/extension_drivers/test_qos_driver.py']",2,2a36d111e057daff514a944f8b881dc0265a7003,bug/1964342," self.qos_driver.meter_cache_pps.br_int = self.qos_driver.br_int self.qos_driver.meter_cache_pps.max_meter = 65535 burst=self.rules[2].max_burst_kpps * 1000, type_=comm_consts.METER_FLAG_PPS), burst=self.rules[3].max_burst_kpps * 1000, type_=comm_consts.METER_FLAG_PPS)]) in_port=111, type_=comm_consts.METER_FLAG_PPS), local_vlan=1, type_=comm_consts.METER_FLAG_PPS)]) in_port=111, type_=comm_consts.METER_FLAG_PPS), local_vlan=1, type_=comm_consts.METER_FLAG_PPS)]) burst=self.rules[2].max_burst_kpps * 1000, type_=comm_consts.METER_FLAG_PPS), burst=self.rules[3].max_burst_kpps * 1000, type_=comm_consts.METER_FLAG_PPS)]) in_port=111, type_=comm_consts.METER_FLAG_PPS), local_vlan=1, type_=comm_consts.METER_FLAG_PPS)])"," self.qos_driver.meter_cache.br_int = self.qos_driver.br_int self.qos_driver.meter_cache.max_meter = 65535 burst=self.rules[2].max_burst_kpps * 1000), burst=self.rules[3].max_burst_kpps * 1000)]) in_port=111), local_vlan=1)]) in_port=111), local_vlan=1)]) burst=self.rules[2].max_burst_kpps * 1000), burst=self.rules[3].max_burst_kpps * 1000)]) in_port=111), local_vlan=1)])",132,98
openstack%2Fkeystonemiddleware~886521,openstack/keystonemiddleware,master,I40bc0b3b024d38aef5cfd79bda5bd6603230fa6e,Fix Max retries exceeded with v3 ec2tokens,ABANDONED,2023-06-20 16:31:18.000000000,2023-07-10 02:04:34.000000000,,"[{'_account_id': 597}, {'_account_id': 7414}, {'_account_id': 7973}, {'_account_id': 16465}, {'_account_id': 22348}]","[{'number': 1, 'created': '2023-06-20 16:31:18.000000000', 'files': ['keystonemiddleware/tests/unit/test_ec2_token_middleware.py'], 'web_link': 'https://opendev.org/openstack/keystonemiddleware/commit/3282df1a8f50368f1c91159d0bacd22f0f451c5b', 'message': ""Fix Max retries exceeded with v3 ec2tokens\n\nFixed mocks by cherry-picking [1] to fit recently introduced the timeout\narg and the change of method from request to post. This error is caused\nby the gaps between codes and tests. The ec2_token is recently updated\n[2], but test codes on the master branch haven't been updated.\n\n[1] https://review.opendev.org/c/openstack/keystonemiddleware/+/878544\n[2] https://review.opendev.org/c/openstack/keystonemiddleware/+/877808\n\nCloses-Bug: #2023689\nChange-Id: I40bc0b3b024d38aef5cfd79bda5bd6603230fa6e\n""}]",3,886521,3282df1a8f50368f1c91159d0bacd22f0f451c5b,7,5,1,33455,,,0,"Fix Max retries exceeded with v3 ec2tokens

Fixed mocks by cherry-picking [1] to fit recently introduced the timeout
arg and the change of method from request to post. This error is caused
by the gaps between codes and tests. The ec2_token is recently updated
[2], but test codes on the master branch haven't been updated.

[1] https://review.opendev.org/c/openstack/keystonemiddleware/+/878544
[2] https://review.opendev.org/c/openstack/keystonemiddleware/+/877808

Closes-Bug: #2023689
Change-Id: I40bc0b3b024d38aef5cfd79bda5bd6603230fa6e
",git fetch https://review.opendev.org/openstack/keystonemiddleware refs/changes/21/886521/1 && git format-patch -1 --stdout FETCH_HEAD,['keystonemiddleware/tests/unit/test_ec2_token_middleware.py'],1,3282df1a8f50368f1c91159d0bacd22f0f451c5b,bug/2023689," requests, 'post', 'http://localhost:5000/v3/ec2tokens', verify=True, cert=None, timeout=mock.ANY) requests, 'post', 'http://localhost:5000/v3/ec2tokens', verify=True, cert=None, timeout=mock.ANY) 'post', mock_request.assert_called_with(mock.ANY, verify=mock.ANY, cert=mock.ANY, timeout=mock.ANY) 'post', mock_request.assert_called_with(mock.ANY, verify=mock.ANY, cert=mock.ANY, timeout=mock.ANY)"," requests, 'request', 'POST', 'http://localhost:5000/v3/ec2tokens', verify=True, cert=None) requests, 'request', 'POST', 'http://localhost:5000/v3/ec2tokens', verify=True, cert=None) 'request', mock_request.assert_called_with('POST', mock.ANY, verify=mock.ANY, cert=mock.ANY) 'request', mock_request.assert_called_with('POST', mock.ANY, verify=mock.ANY, cert=mock.ANY)",14,12
openstack%2Ftempest~879510,openstack/tempest,master,I2047e24118be5d0abf4f79ff9a6d79a06ac807e6,Enable file injection tests,NEW,2023-04-04 19:59:21.000000000,2023-07-10 00:40:57.000000000,,"[{'_account_id': 8556}, {'_account_id': 22348}, {'_account_id': 33983}]","[{'number': 1, 'created': '2023-04-04 19:59:21.000000000', 'files': ['zuul.d/integrated-gate.yaml'], 'web_link': 'https://opendev.org/openstack/tempest/commit/7c7349c337a97ff547e2bc75ba8cabc0a5d0eaf0', 'message': ""Enable file injection tests\n\nLet's enable file injection tests as the bug, which was the reason\nbehind disabling them, has been resolved.\n\nRelated-Bug: #1882421\nChange-Id: I2047e24118be5d0abf4f79ff9a6d79a06ac807e6\n""}]",10,879510,7c7349c337a97ff547e2bc75ba8cabc0a5d0eaf0,15,3,1,22873,,,0,"Enable file injection tests

Let's enable file injection tests as the bug, which was the reason
behind disabling them, has been resolved.

Related-Bug: #1882421
Change-Id: I2047e24118be5d0abf4f79ff9a6d79a06ac807e6
",git fetch https://review.opendev.org/openstack/tempest refs/changes/10/879510/1 && git format-patch -1 --stdout FETCH_HEAD,['zuul.d/integrated-gate.yaml'],1,7c7349c337a97ff547e2bc75ba8cabc0a5d0eaf0,, ENABLE_FILE_INJECTION: true ENABLE_FILE_INJECTION: true, # TODO(gmann): Enable File injection tests once nova bug is fixed # https://bugs.launchpad.net/nova/+bug/1882421 # ENABLE_FILE_INJECTION: true # TODO(gmann): Enable File injection tests once nova bug is fixed # https://bugs.launchpad.net/nova/+bug/1882421 # ENABLE_FILE_INJECTION: true,2,6
openstack%2Fmetalsmith~887867,openstack/metalsmith,stable/wallaby,Ied2d16ec33fe71522c3461d3df6e70fbfdd976b2,Allow both 'network' and 'subnet' in NIC,MERGED,2023-07-06 18:06:06.000000000,2023-07-09 23:03:11.000000000,2023-07-09 23:02:17.000000000,"[{'_account_id': 4571}, {'_account_id': 11655}, {'_account_id': 22348}]","[{'number': 1, 'created': '2023-07-06 18:06:06.000000000', 'files': ['releasenotes/notes/allow-both-network-and-subnet-in-nic-info-af8b40a26d55828e.yaml', 'metalsmith/_nics.py'], 'web_link': 'https://opendev.org/openstack/metalsmith/commit/554df57f34352f5e6e7daeca510f049d218874e4', 'message': ""Allow both 'network' and 'subnet' in NIC\n\nFixes and issue where a port cannot be created on\na specific subnet if there are multiple subnets\nwith the same name on different networks.\n\nAllows both 'network' and 'subnet' in NIC information,\nwhen looking up the subnet filter on the network_id when\nboth 'network' and 'subnet' is provided.\n\nConflicts:\n\tmetalsmith/test/test_nics.py\n\n  Unit test for nics was added after wallaby.\n\nStory: 2009732\nTask: 44152\nChange-Id: Ied2d16ec33fe71522c3461d3df6e70fbfdd976b2\n(cherry picked from commit 264836d59ac741424c3fad4d47e51073722c848f)\n""}]",0,887867,554df57f34352f5e6e7daeca510f049d218874e4,8,3,1,24245,,,0,"Allow both 'network' and 'subnet' in NIC

Fixes and issue where a port cannot be created on
a specific subnet if there are multiple subnets
with the same name on different networks.

Allows both 'network' and 'subnet' in NIC information,
when looking up the subnet filter on the network_id when
both 'network' and 'subnet' is provided.

Conflicts:
	metalsmith/test/test_nics.py

  Unit test for nics was added after wallaby.

Story: 2009732
Task: 44152
Change-Id: Ied2d16ec33fe71522c3461d3df6e70fbfdd976b2
(cherry picked from commit 264836d59ac741424c3fad4d47e51073722c848f)
",git fetch https://review.opendev.org/openstack/metalsmith refs/changes/67/887867/1 && git format-patch -1 --stdout FETCH_HEAD,"['releasenotes/notes/allow-both-network-and-subnet-in-nic-info-af8b40a26d55828e.yaml', 'metalsmith/_nics.py']",2,554df57f34352f5e6e7daeca510f049d218874e4,story/2009732," unexpected = set(nic) - {'network', 'fixed_ip', 'subnet'} fixed_ip = {} if nic.get('fixed_ip'): fixed_ip['ip_address'] = nic['fixed_ip'] if nic.get('subnet'): try: subnet = self._connection.network.find_subnet( nic['subnet'], network_id=network.id, ignore_missing=False) except sdk_exc.SDKException as exc: raise exceptions.InvalidNIC( 'Cannot find subnet %(subnet)s on network %(net)s: ' '%(error)s' % {'net': nic['network'], 'subnet': nic['subnet'], 'error': exc}) fixed_ip['subnet_id'] = subnet.id port_args = {'network_id': network.id} if fixed_ip: port_args['fixed_ips'] = [fixed_ip]"," unexpected = set(nic) - {'network', 'fixed_ip'} port_args = {'network_id': network.id} if nic.get('fixed_ip'): port_args['fixed_ips'] = [{'ip_address': nic['fixed_ip']}]",26,3
openstack%2Fglance_store~888004,openstack/glance_store,master,If5c27deb39ce62c5791b8157efeb42cfc728fc67,Imported Translations from Zanata,MERGED,2023-07-08 02:08:40.000000000,2023-07-09 16:06:26.000000000,2023-07-09 16:05:22.000000000,"[{'_account_id': 5314}, {'_account_id': 22348}]","[{'number': 1, 'created': '2023-07-08 02:08:40.000000000', 'files': ['releasenotes/source/locale/en_GB/LC_MESSAGES/releasenotes.po', 'glance_store/locale/en_GB/LC_MESSAGES/glance_store.po'], 'web_link': 'https://opendev.org/openstack/glance_store/commit/0c60291637d1c941dcd8d2e022acb22ba0bed440', 'message': 'Imported Translations from Zanata\n\nFor more information about this automatic import see:\nhttps://docs.openstack.org/i18n/latest/reviewing-translation-import.html\n\nChange-Id: If5c27deb39ce62c5791b8157efeb42cfc728fc67\n'}]",1,888004,0c60291637d1c941dcd8d2e022acb22ba0bed440,9,2,1,11131,,,0,"Imported Translations from Zanata

For more information about this automatic import see:
https://docs.openstack.org/i18n/latest/reviewing-translation-import.html

Change-Id: If5c27deb39ce62c5791b8157efeb42cfc728fc67
",git fetch https://review.opendev.org/openstack/glance_store refs/changes/04/888004/1 && git format-patch -1 --stdout FETCH_HEAD,"['releasenotes/source/locale/en_GB/LC_MESSAGES/releasenotes.po', 'glance_store/locale/en_GB/LC_MESSAGES/glance_store.po']",2,0c60291637d1c941dcd8d2e022acb22ba0bed440,zanata/translations,"# Andi Chandler <andi@gowling.com>, 2023. #zanata""POT-Creation-Date: 2023-06-23 19:07+0000\n""""PO-Revision-Date: 2023-07-07 09:08+0000\n""""This option is used to define a relative weight for this store over\n"" ""any others that are configured. The actual value of the weight is "" ""meaningless\n"" ""and only serves to provide a \""sort order\"" compared to others. Any stores\n"" ""with the same weight will be treated as equivalent.\n"" msgstr """" ""\n"" ""This option is used to define a relative weight for this store over\n"" ""any others that are configured. The actual value of the weight is "" ""meaningless\n"" ""and only serves to provide a \""sort order\"" compared to others. Any stores\n"" ""with the same weight will be treated as equivalent.\n"" msgid """" ""\n""","""POT-Creation-Date: 2020-05-04 16:18+0000\n""""PO-Revision-Date: 2020-05-04 08:05+0000\n""",32,4
openstack%2Fopenstack-helm~887599,openstack/openstack-helm,master,If224d1162a531759fe6ad2d636406be60721f16b,Add ubuntu-jammy based images,MERGED,2023-07-04 13:08:20.000000000,2023-07-09 15:56:32.000000000,2023-07-09 15:54:35.000000000,"[{'_account_id': 3009}, {'_account_id': 22348}]","[{'number': 1, 'created': '2023-07-04 13:08:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm/commit/dde50115db04ef4397b535570e0f5662e17c9863', 'message': 'Add ubuntu-jammy based images\n\nChange-Id: If224d1162a531759fe6ad2d636406be60721f16b\n'}, {'number': 2, 'created': '2023-07-04 16:07:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm/commit/21508269046027203865d44c7efb3da2bf0f9ae7', 'message': 'Add ubuntu-jammy based images\n\nChange-Id: If224d1162a531759fe6ad2d636406be60721f16b\n'}, {'number': 3, 'created': '2023-07-05 00:55:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm/commit/7ebf9623416a18ad3a821ec8c79b15b8a951f4ec', 'message': 'Add ubuntu-jammy based images\n\nChange-Id: If224d1162a531759fe6ad2d636406be60721f16b\n'}, {'number': 4, 'created': '2023-07-08 14:25:54.000000000', 'files': ['zuul.d/jobs-openstack-helm.yaml'], 'web_link': 'https://opendev.org/openstack/openstack-helm/commit/66f2affb8d15a86dd6cc83cb496c4f89ac68a812', 'message': 'Add ubuntu-jammy based images\n\nChange-Id: If224d1162a531759fe6ad2d636406be60721f16b\n'}]",8,887599,66f2affb8d15a86dd6cc83cb496c4f89ac68a812,28,2,4,35691,,,0,"Add ubuntu-jammy based images

Change-Id: If224d1162a531759fe6ad2d636406be60721f16b
",git fetch https://review.opendev.org/openstack/openstack-helm refs/changes/99/887599/1 && git format-patch -1 --stdout FETCH_HEAD,['zuul.d/jobs-openstack-helm.yaml'],1,dde50115db04ef4397b535570e0f5662e17c9863,jammy_jobs, name: openstack-helm-cinder-zed-ubuntu_jammy parent: openstack-helm-cinder vars: osh_params: openstack_release: zed container_distro_name: ubuntu container_distro_version: jammy - job: name: openstack-helm-compute-kit-zed-ubuntu_jammy parent: openstack-helm-compute-kit nodeset: openstack-helm-single-32GB-focal-tmp # TODO: Use jammy nodeset vars: osh_params: openstack_release: zed container_distro_name: ubuntu container_distro_version: jammy - job:,,19,0
openstack%2Fglance~887476,openstack/glance,master,I4fd052503d1980c650234b90cfed71053e22e3b5,Release notes for Bobcat Milestone 2,MERGED,2023-07-03 06:50:58.000000000,2023-07-09 12:13:36.000000000,2023-07-09 12:12:25.000000000,"[{'_account_id': 8122}, {'_account_id': 9303}, {'_account_id': 22348}]","[{'number': 1, 'created': '2023-07-03 06:50:58.000000000', 'files': ['releasenotes/notes/bobcat-milestone-2-releasenotes-085084b03f66d671.yaml'], 'web_link': 'https://opendev.org/openstack/glance/commit/735db034851e7b9c5612435a1ae822e5bc0dbcae', 'message': 'Release notes for Bobcat Milestone 2\n\nChange-Id: I4fd052503d1980c650234b90cfed71053e22e3b5\n'}]",1,887476,735db034851e7b9c5612435a1ae822e5bc0dbcae,12,3,1,19138,,,0,"Release notes for Bobcat Milestone 2

Change-Id: I4fd052503d1980c650234b90cfed71053e22e3b5
",git fetch https://review.opendev.org/openstack/glance refs/changes/76/887476/1 && git format-patch -1 --stdout FETCH_HEAD,['releasenotes/notes/bobcat-milestone-2-releasenotes-085084b03f66d671.yaml'],1,735db034851e7b9c5612435a1ae822e5bc0dbcae,bobcat-milestone-2,--- fixes: - | Bug 1937901_: healthcheck middleware should be deployed as app instead of filter - | Bug 1889664_: Image Import 'web-download' is broken with py37+ .. _1937901: https://code.launchpad.net/bugs/1937901 .. _1889664: https://code.launchpad.net/bugs/1889664 ,,10,0
openstack%2Fneutron-tempest-plugin~888011,openstack/neutron-tempest-plugin,master,I5d41e317fadd8dc9935fc639c67f4eb3f27c7622,add a comment,ABANDONED,2023-07-09 11:17:33.000000000,2023-07-09 11:22:36.000000000,,[],"[{'number': 1, 'created': '2023-07-09 11:17:33.000000000', 'files': ['neutron_tempest_plugin/scenario/test_basic.py'], 'web_link': 'https://opendev.org/openstack/neutron-tempest-plugin/commit/f0bbb9efdefbe003f5d2ce2ba79fdbd62ddf6992', 'message': 'add a comment\n\nChange-Id: I5d41e317fadd8dc9935fc639c67f4eb3f27c7622\n'}]",0,888011,f0bbb9efdefbe003f5d2ce2ba79fdbd62ddf6992,2,0,1,36141,,,0,"add a comment

Change-Id: I5d41e317fadd8dc9935fc639c67f4eb3f27c7622
",git fetch https://review.opendev.org/openstack/neutron-tempest-plugin refs/changes/11/888011/1 && git format-patch -1 --stdout FETCH_HEAD,['neutron_tempest_plugin/scenario/test_basic.py'],1,f0bbb9efdefbe003f5d2ce2ba79fdbd62ddf6992,, # TEST,,2,0
openstack%2Fglance~887475,openstack/glance,master,If22e04649fb9a5c237ca59e3844974756303d127,Refresh Glance example configs for bobcat milestone 2,MERGED,2023-07-03 06:50:58.000000000,2023-07-09 11:11:39.000000000,2023-07-09 11:10:27.000000000,"[{'_account_id': 8122}, {'_account_id': 9303}, {'_account_id': 22348}, {'_account_id': 32238}]","[{'number': 1, 'created': '2023-07-03 06:50:58.000000000', 'files': ['etc/glance-api.conf'], 'web_link': 'https://opendev.org/openstack/glance/commit/d68f99a7384be677836a1309cb3b0f5d9f58277d', 'message': 'Refresh Glance example configs for bobcat milestone 2\n\nChange-Id: If22e04649fb9a5c237ca59e3844974756303d127\n'}]",14,887475,d68f99a7384be677836a1309cb3b0f5d9f58277d,56,4,1,19138,,,0,"Refresh Glance example configs for bobcat milestone 2

Change-Id: If22e04649fb9a5c237ca59e3844974756303d127
",git fetch https://review.opendev.org/openstack/glance refs/changes/75/887475/1 && git format-patch -1 --stdout FETCH_HEAD,['etc/glance-api.conf'],1,d68f99a7384be677836a1309cb3b0f5d9f58277d,bobcat-milestone-2,# How long to wait (in seconds) before reconnecting in response to an AMQP # consumer cancel notification. (floating point value) # Minimum value: 0.0 # Maximum value: 4.5# Deprecated group/name - [oslo_messaging_rabbit]/rabbit_quroum_max_memory_length #rabbit_quorum_max_memory_length = 0# Deprecated group/name - [oslo_messaging_rabbit]/rabbit_quroum_max_memory_bytes #rabbit_quorum_max_memory_bytes = 0,# How long to wait before reconnecting in response to an AMQP consumer cancel # notification. (floating point value)#rabbit_quroum_max_memory_length = 0#rabbit_quroum_max_memory_bytes = 0,8,4
openstack%2Fansible-collections-openstack~885085,openstack/ansible-collections-openstack,master,I3c3b6f59393928d098e9b80c55b87fc6ee1e9912,fix(inventory): bug when using clouds_yaml_path,MERGED,2023-06-01 17:41:36.000000000,2023-07-09 08:28:17.000000000,2023-07-09 08:28:17.000000000,"[{'_account_id': 22348}, {'_account_id': 32962}]","[{'number': 1, 'created': '2023-06-01 17:41:36.000000000', 'files': ['plugins/inventory/openstack.py'], 'web_link': 'https://opendev.org/openstack/ansible-collections-openstack/commit/2808d1c15500b4a5f2d977a0131f58d74abe7679', 'message': 'fix(inventory): bug when using clouds_yaml_path\n\nBefore this fix the current implementation in combination with the most\nrecent openstacksdk (1.2.0) resulted in a list containing the default\nvalues and another list inside this list containing the value of\nclouds_yaml_path. The clouds_yaml_path value gets now added directly to\nthe list only if it was set.\n\nChange-Id: I3c3b6f59393928d098e9b80c55b87fc6ee1e9912\n'}]",1,885085,2808d1c15500b4a5f2d977a0131f58d74abe7679,7,2,1,36071,,,0,"fix(inventory): bug when using clouds_yaml_path

Before this fix the current implementation in combination with the most
recent openstacksdk (1.2.0) resulted in a list containing the default
values and another list inside this list containing the value of
clouds_yaml_path. The clouds_yaml_path value gets now added directly to
the list only if it was set.

Change-Id: I3c3b6f59393928d098e9b80c55b87fc6ee1e9912
",git fetch https://review.opendev.org/openstack/ansible-collections-openstack refs/changes/85/885085/1 && git format-patch -1 --stdout FETCH_HEAD,['plugins/inventory/openstack.py'],1,2808d1c15500b4a5f2d977a0131f58d74abe7679,patch-clouds_yaml_path, config_files = openstack.config.loader.CONFIG_FILES if clouds_yaml_path: config_files += clouds_yaml_path, config_files = ( openstack.config.loader.CONFIG_FILES + ([clouds_yaml_path] if clouds_yaml_path else [])),3,3
openstack%2Fopenstack-helm-infra~887526,openstack/openstack-helm-infra,master,If4ac19942642ae2fa6193d9f3db9e602929cfcb5,Add metrics port,ABANDONED,2023-07-03 16:44:18.000000000,2023-07-09 05:29:02.000000000,,[{'_account_id': 22348}],"[{'number': 1, 'created': '2023-07-03 16:44:18.000000000', 'files': ['rabbitmq/templates/service.yaml', 'rabbitmq/templates/statefulset.yaml'], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/a4387cb3af2cf1f70e46407a3268a7ac26867ebd', 'message': 'Add metrics port\n\nChange-Id: If4ac19942642ae2fa6193d9f3db9e602929cfcb5\n'}]",2,887526,a4387cb3af2cf1f70e46407a3268a7ac26867ebd,5,1,1,35691,,,0,"Add metrics port

Change-Id: If4ac19942642ae2fa6193d9f3db9e602929cfcb5
",git fetch https://review.opendev.org/openstack/openstack-helm-infra refs/changes/26/887526/1 && git format-patch -1 --stdout FETCH_HEAD,"['rabbitmq/templates/service.yaml', 'rabbitmq/templates/statefulset.yaml']",2,a4387cb3af2cf1f70e46407a3268a7ac26867ebd,rabbitmq-metrics, - containerPort: 15692 name: metrics protocol: TCP,,7,0
openstack%2Fopenstack-helm-infra~887525,openstack/openstack-helm-infra,master,I680edbc03167dac3b4656ee7f88bfac02a390aa1,Fix rabbitmq in ipv6 disabled env,MERGED,2023-07-03 16:40:56.000000000,2023-07-09 01:05:29.000000000,2023-07-09 01:04:32.000000000,"[{'_account_id': 1004}, {'_account_id': 3009}, {'_account_id': 22348}]","[{'number': 1, 'created': '2023-07-03 16:40:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/8997f798d568e5adaf05a0d8c7c07ba8d8298a89', 'message': 'Fix rabbitmq in ipv6 disabled env\n\nChange-Id: I680edbc03167dac3b4656ee7f88bfac02a390aa1\n'}, {'number': 2, 'created': '2023-07-04 10:12:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/cf82578d1fe90da8e80c00d54262ae096fcd095a', 'message': 'Fix rabbitmq in ipv6 disabled env\n\nChange-Id: I680edbc03167dac3b4656ee7f88bfac02a390aa1\n'}, {'number': 3, 'created': '2023-07-05 18:04:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/bc712dee79fc68c21587cd8a1d5256e1c7f9756f', 'message': 'Fix rabbitmq in ipv6 disabled env\n\nChange-Id: I680edbc03167dac3b4656ee7f88bfac02a390aa1\n'}, {'number': 4, 'created': '2023-07-05 19:48:14.000000000', 'files': ['releasenotes/notes/rabbitmq.yaml', 'rabbitmq/templates/configmap-etc.yaml', 'rabbitmq/Chart.yaml', 'rabbitmq/values.yaml'], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/1dd1989fff3dede1e20123f3de5c6e82b25de401', 'message': 'Fix rabbitmq in ipv6 disabled env\n\nChange-Id: I680edbc03167dac3b4656ee7f88bfac02a390aa1\n'}]",3,887525,1dd1989fff3dede1e20123f3de5c6e82b25de401,19,3,4,35691,,,0,"Fix rabbitmq in ipv6 disabled env

Change-Id: I680edbc03167dac3b4656ee7f88bfac02a390aa1
",git fetch https://review.opendev.org/openstack/openstack-helm-infra refs/changes/25/887525/1 && git format-patch -1 --stdout FETCH_HEAD,"['rabbitmq/templates/configmap-etc.yaml', 'rabbitmq/values.yaml']",2,8997f798d568e5adaf05a0d8c7c07ba8d8298a89,rabbitmq_ipv6," bind_address: ""::""",,2,1
openstack%2Fopenstack-helm-infra~887963,openstack/openstack-helm-infra,master,I9c22bb692385dbb7bc2816233c83c7472e071dd4,[ceph-osd] Extend the ceph-osd post-apply job PG wait,MERGED,2023-07-07 14:40:54.000000000,2023-07-08 20:41:29.000000000,2023-07-08 20:40:31.000000000,"[{'_account_id': 3009}, {'_account_id': 22348}, {'_account_id': 28372}, {'_account_id': 32433}, {'_account_id': 33330}, {'_account_id': 34821}]","[{'number': 1, 'created': '2023-07-07 14:40:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/9fbf40be9b17484a7547e14fcc008cb705f52b53', 'message': ""[ceph-osd] Extend the ceph-osd post-apply job PG wait\n\nIn some cases, especially for disruptive OSD restarts on upgrade,\nPGs can take longer than the allowed ~30 seconds to get into a\npeering state. In these cases, the post-apply job fails prematurely\ninstead of allowing time for the OSDs and PGs to recover. This\nchange extends that timeout to ~10 minutes instead to allow the PGs\nplenty of recovery time.\n\nThe only negative effect of this change is that a legitimate\nfailure where the PGs can't recover will take 10 minutes to fail\nthe post-apply job instead of 30 seconds.\n\nChange-Id: I9c22bb692385dbb7bc2816233c83c7472e071dd4\n""}, {'number': 2, 'created': '2023-07-07 14:42:36.000000000', 'files': ['ceph-osd/templates/bin/_post-apply.sh.tpl', 'ceph-osd/Chart.yaml', 'releasenotes/notes/ceph-osd.yaml'], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/8d6cc364b7d227013df29d87874bea9ad9cf0b17', 'message': ""[ceph-osd] Extend the ceph-osd post-apply job PG wait\n\nIn some cases, especially for disruptive OSD restarts on upgrade,\nPGs can take longer than the allowed ~30 seconds to get into a\npeering state. In these cases, the post-apply job fails prematurely\ninstead of allowing time for the OSDs and PGs to recover. This\nchange extends that timeout to ~10 minutes instead to allow the PGs\nplenty of recovery time.\n\nThe only negative effect of this change is that a legitimate\nfailure where the PGs can't recover will take 10 minutes to fail\nthe post-apply job instead of 30 seconds.\n\nChange-Id: I9c22bb692385dbb7bc2816233c83c7472e071dd4\n""}]",2,887963,8d6cc364b7d227013df29d87874bea9ad9cf0b17,14,6,2,29974,,,0,"[ceph-osd] Extend the ceph-osd post-apply job PG wait

In some cases, especially for disruptive OSD restarts on upgrade,
PGs can take longer than the allowed ~30 seconds to get into a
peering state. In these cases, the post-apply job fails prematurely
instead of allowing time for the OSDs and PGs to recover. This
change extends that timeout to ~10 minutes instead to allow the PGs
plenty of recovery time.

The only negative effect of this change is that a legitimate
failure where the PGs can't recover will take 10 minutes to fail
the post-apply job instead of 30 seconds.

Change-Id: I9c22bb692385dbb7bc2816233c83c7472e071dd4
",git fetch https://review.opendev.org/openstack/openstack-helm-infra refs/changes/63/887963/1 && git format-patch -1 --stdout FETCH_HEAD,['ceph-osd/templates/bin/_post-apply.sh.tpl'],1,9fbf40be9b17484a7547e14fcc008cb705f52b53,," if [[ $pgs_inactive -gt 200 ]]; then # If inactive PGs aren't peering after ~10 minutes, fail"," if [[ $pgs_inactive -gt 10 ]]; then # If inactive PGs aren't peering, fail",2,2
openstack%2Fironic-python-agent-builder~881299,openstack/ironic-python-agent-builder,master,I5e2d454fb84b76810f3c5ed26a0caeef8ea06675,Extend the DIB_CHECKSUM variable usage,MERGED,2023-04-23 21:47:19.000000000,2023-07-08 20:11:15.000000000,2023-07-08 20:10:22.000000000,"[{'_account_id': 4571}, {'_account_id': 7118}, {'_account_id': 11655}, {'_account_id': 22348}, {'_account_id': 32761}]","[{'number': 1, 'created': '2023-04-23 21:47:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic-python-agent-builder/commit/ac2c388136e6ae57485bec6679e9255730511bbb', 'message': 'Extend the DIB_CHECKSUM variable usage\n\nFollowup on I2dd1c60e3bfd9c823a7382b1390b1d40c52a5c97\n\nDepends-On: I2dd1c60e3bfd9c823a7382b1390b1d40c52a5c97\nChange-Id: I5e2d454fb84b76810f3c5ed26a0caeef8ea06675\nSigned-off-by: Maksim Malchuk <maksim.malchuk@gmail.com>\n'}, {'number': 2, 'created': '2023-04-23 22:01:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic-python-agent-builder/commit/b3cf8d2b3a550580fc27857ed5b40e3e62e5bdd8', 'message': 'Extend the DIB_CHECKSUM variable usage\n\nFollowup on I2dd1c60e3bfd9c823a7382b1390b1d40c52a5c97\n\nDepends-On: I2dd1c60e3bfd9c823a7382b1390b1d40c52a5c97\nChange-Id: I5e2d454fb84b76810f3c5ed26a0caeef8ea06675\nSigned-off-by: Maksim Malchuk <maksim.malchuk@gmail.com>\n'}, {'number': 3, 'created': '2023-04-23 22:19:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic-python-agent-builder/commit/0680f70aff4a40f2ec3c5d8d95e802c93ce81e81', 'message': 'Extend the DIB_CHECKSUM variable usage\n\nFollowup on I2dd1c60e3bfd9c823a7382b1390b1d40c52a5c97\n\nDepends-On: I2dd1c60e3bfd9c823a7382b1390b1d40c52a5c97\nChange-Id: I5e2d454fb84b76810f3c5ed26a0caeef8ea06675\nSigned-off-by: Maksim Malchuk <maksim.malchuk@gmail.com>\n'}, {'number': 4, 'created': '2023-04-23 22:31:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic-python-agent-builder/commit/af7937ec87e982826c150d5c67f9f14928f37992', 'message': 'Extend the DIB_CHECKSUM variable usage\n\nFollowup on I2dd1c60e3bfd9c823a7382b1390b1d40c52a5c97\n\nChange-Id: I5e2d454fb84b76810f3c5ed26a0caeef8ea06675\nSigned-off-by: Maksim Malchuk <maksim.malchuk@gmail.com>\n'}, {'number': 5, 'created': '2023-04-23 22:36:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic-python-agent-builder/commit/380a393d9c517452d3e0a3fd1ef3afc3abb06043', 'message': 'Extend the DIB_CHECKSUM variable usage\n\nFollowup on I2dd1c60e3bfd9c823a7382b1390b1d40c52a5c97\n\nChange-Id: I5e2d454fb84b76810f3c5ed26a0caeef8ea06675\nSigned-off-by: Maksim Malchuk <maksim.malchuk@gmail.com>\n'}, {'number': 6, 'created': '2023-04-25 17:27:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic-python-agent-builder/commit/a51af60b1a3075b2585039caf9ef9fb0b6b4548f', 'message': 'Extend the DIB_CHECKSUM variable usage\n\nFollowup on I2dd1c60e3bfd9c823a7382b1390b1d40c52a5c97\n\nChange-Id: I5e2d454fb84b76810f3c5ed26a0caeef8ea06675\nSigned-off-by: Maksim Malchuk <maksim.malchuk@gmail.com>\n'}, {'number': 7, 'created': '2023-04-26 21:27:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic-python-agent-builder/commit/3b982245582a69bc90225bca6dad36dd7ec40427', 'message': 'Extend the DIB_CHECKSUM variable usage\n\nFollowup on I2dd1c60e3bfd9c823a7382b1390b1d40c52a5c97\n\nChange-Id: I5e2d454fb84b76810f3c5ed26a0caeef8ea06675\nSigned-off-by: Maksim Malchuk <maksim.malchuk@gmail.com>\n'}, {'number': 8, 'created': '2023-05-24 20:44:14.000000000', 'files': ['dib/ironic-ramdisk-base/cleanup.d/99-ramdisk-create'], 'web_link': 'https://opendev.org/openstack/ironic-python-agent-builder/commit/e118104f9838875c56c51cc40ec106994baa72b3', 'message': 'Extend the DIB_CHECKSUM variable usage\n\nFollowup on I2dd1c60e3bfd9c823a7382b1390b1d40c52a5c97\n\nChange-Id: I5e2d454fb84b76810f3c5ed26a0caeef8ea06675\nSigned-off-by: Maksim Malchuk <maksim.malchuk@gmail.com>\n'}]",11,881299,e118104f9838875c56c51cc40ec106994baa72b3,44,5,8,14200,,,0,"Extend the DIB_CHECKSUM variable usage

Followup on I2dd1c60e3bfd9c823a7382b1390b1d40c52a5c97

Change-Id: I5e2d454fb84b76810f3c5ed26a0caeef8ea06675
Signed-off-by: Maksim Malchuk <maksim.malchuk@gmail.com>
",git fetch https://review.opendev.org/openstack/ironic-python-agent-builder refs/changes/99/881299/1 && git format-patch -1 --stdout FETCH_HEAD,['dib/ironic-ramdisk-base/cleanup.d/99-ramdisk-create'],1,ac2c388136e6ae57485bec6679e9255730511bbb,extend-dib-checksum,"if [ -n ""$DIB_CHECKSUM"" ]; then [ ""$DIB_CHECKSUM"" == ""sha256"" ] || md5sum ${IMAGE_NAME}.initramfs ${IMAGE_NAME}.kernel > ${IMAGE_NAME}.md5 [ ""$DIB_CHECKSUM"" == ""md5""] || sha256sum ${IMAGE_NAME}.initramfs ${IMAGE_NAME}.kernel > ${IMAGE_NAME}.sha256","if [ ""$DIB_CHECKSUM"" == ""1"" ]; then md5sum ${IMAGE_NAME}.initramfs ${IMAGE_NAME}.kernel > ${IMAGE_NAME}.md5 sha256sum ${IMAGE_NAME}.initramfs ${IMAGE_NAME}.kernel > ${IMAGE_NAME}.sha256",3,3
openstack%2Fcinder~888008,openstack/cinder,master,I5b41f761b0957d508eedd9f003860b833b14d56f,Imported Translations from Zanata,MERGED,2023-07-08 03:22:18.000000000,2023-07-08 19:54:58.000000000,2023-07-08 19:53:53.000000000,"[{'_account_id': 5314}, {'_account_id': 22348}]","[{'number': 1, 'created': '2023-07-08 03:22:18.000000000', 'files': ['releasenotes/source/locale/en_GB/LC_MESSAGES/releasenotes.po'], 'web_link': 'https://opendev.org/openstack/cinder/commit/7fa5561eb5ac9100f26be5a9c75ed070ecb728ac', 'message': 'Imported Translations from Zanata\n\nFor more information about this automatic import see:\nhttps://docs.openstack.org/i18n/latest/reviewing-translation-import.html\n\nChange-Id: I5b41f761b0957d508eedd9f003860b833b14d56f\n'}]",0,888008,7fa5561eb5ac9100f26be5a9c75ed070ecb728ac,19,2,1,11131,,,0,"Imported Translations from Zanata

For more information about this automatic import see:
https://docs.openstack.org/i18n/latest/reviewing-translation-import.html

Change-Id: I5b41f761b0957d508eedd9f003860b833b14d56f
",git fetch https://review.opendev.org/openstack/cinder refs/changes/08/888008/1 && git format-patch -1 --stdout FETCH_HEAD,['releasenotes/source/locale/en_GB/LC_MESSAGES/releasenotes.po'],1,7fa5561eb5ac9100f26be5a9c75ed070ecb728ac,zanata/translations,"""POT-Creation-Date: 2023-07-03 19:36+0000\n""""PO-Revision-Date: 2023-07-07 09:07+0000\n""msgid ""16.4.2-17"" msgstr ""16.4.2-17""msgid ""20.3.0-2"" msgstr ""20.3.0-2"" msgid ""21.3.0-3"" msgstr ""21.3.0-3""msgid ""22.0.0.0rc1-74"" msgstr ""22.0.0.0rc1-74"" ","""POT-Creation-Date: 2023-06-27 22:25+0000\n""""PO-Revision-Date: 2023-06-20 11:18+0000\n""msgid ""16.4.2-16"" msgstr ""16.4.2-16""msgid ""21.3.0-2"" msgstr ""21.3.0-2""",12,6
openstack%2Fcinder~808137,openstack/cinder,master,I22b767e848529cf98befe07a4a2983479570d0b1,WIP: Add option to disable discard for encrypted volumes,NEW,2021-09-09 21:01:38.000000000,2023-07-08 18:53:33.000000000,,"[{'_account_id': 4523}, {'_account_id': 22348}]","[{'number': 1, 'created': '2021-09-09 21:01:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/ecf93a03eb13fbdd6afb3e948f4efacd9d7357aa', 'message': 'WIP: Add option to disable discard for encrypted volumes\n\nAdd a new option, ""allow_discard_on_encrypted_volumes"".\n\nWhen set to false, Cinder will no longer report that discard\nshould be enabled when a volume is encrypted.  This defaults\nto true to maintain current behavior.\n\nThis is beneficial for deployers/users with particularly strong\nsecurity concerns, because discard/TRIM patterns can reveal some\ninformation about the contents of a volume.\n\nTODO: add releasenote\n\nChange-Id: I22b767e848529cf98befe07a4a2983479570d0b1\n'}, {'number': 2, 'created': '2023-07-06 14:38:06.000000000', 'files': ['cinder/volume/manager.py', 'cinder/tests/unit/volume/test_volume_manager.py'], 'web_link': 'https://opendev.org/openstack/cinder/commit/0c60f998a07b7967b2761561f085f8d654eb94a6', 'message': 'WIP: Add option to disable discard for encrypted volumes\n\nAdd a new option, ""allow_discard_on_encrypted_volumes"".\n\nWhen set to false, Cinder will no longer report that discard\nshould be enabled when a volume is encrypted.  This defaults\nto true to maintain current behavior.\n\nThis is beneficial for deployers/users with particularly strong\nsecurity concerns, because discard/TRIM patterns can reveal some\ninformation about the contents of a volume.\n\nTODO: add releasenote\n\nChange-Id: I22b767e848529cf98befe07a4a2983479570d0b1\n'}]",0,808137,0c60f998a07b7967b2761561f085f8d654eb94a6,37,2,2,4523,,,0,"WIP: Add option to disable discard for encrypted volumes

Add a new option, ""allow_discard_on_encrypted_volumes"".

When set to false, Cinder will no longer report that discard
should be enabled when a volume is encrypted.  This defaults
to true to maintain current behavior.

This is beneficial for deployers/users with particularly strong
security concerns, because discard/TRIM patterns can reveal some
information about the contents of a volume.

TODO: add releasenote

Change-Id: I22b767e848529cf98befe07a4a2983479570d0b1
",git fetch https://review.opendev.org/openstack/cinder refs/changes/37/808137/1 && git format-patch -1 --stdout FETCH_HEAD,"['cinder/volume/manager.py', 'cinder/tests/unit/volume/test_volume_manager.py']",2,ecf93a03eb13fbdd6afb3e948f4efacd9d7357aa,," @mock.patch('cinder.volume.volume_types.get_volume_type_extra_specs') @mock.patch('cinder.volume.volume_types.get_volume_type_qos_specs', return_value={'qos_specs': None}) def test_parse_connection_options_discard(self, mock_get_qos, mock_get_extra_specs): ctxt = mock.Mock() manager = vol_manager.VolumeManager() vol = fake_volume.fake_volume_obj(ctxt) vol.volume_type_id = fake.VOLUME_TYPE_ID # no 'discard' set by driver, should not be reported conn_info = {""data"": {}} manager._parse_connection_options(ctxt, vol, conn_info) self.assertNotIn('discard', conn_info['data']) # driver sets 'discard' False conn_info = {""data"": {""discard"": False}} manager._parse_connection_options(ctxt, vol, conn_info) self.assertIn('discard', conn_info['data']) self.assertIs(conn_info['data']['discard'], False) # driver sets 'discard' True for encrypted vol w/ option on self.override_config('allow_discard_on_encrypted_volumes', True, group='backend_defaults') vol.encryption_key_id = fake.ENCRYPTION_KEY_ID conn_info = {""data"": {""discard"": True}} manager._parse_connection_options(ctxt, vol, conn_info) self.assertIs(conn_info['data']['discard'], True) # driver sets 'discard' True for encrypted vol w/ option off self.override_config('allow_discard_on_encrypted_volumes', False, group='backend_defaults') conn_info = {""data"": {""discard"": True}} manager._parse_connection_options(ctxt, vol, conn_info) self.assertIs(conn_info['data']['discard'], False) # driver sets 'discard' True for unencrypted vol w/ option on self.override_config('allow_discard_on_encrypted_volumes', True, group='backend_defaults') vol.encryption_key_id = None conn_info = {""data"": {""discard"": True}} manager._parse_connection_options(ctxt, vol, conn_info) self.assertIs(conn_info['data']['discard'], True) # driver sets 'discard' True for unencrypted vol w/ option off self.override_config('allow_discard_on_encrypted_volumes', False, group='backend_defaults') vol.encryption_key_id = None conn_info = {""data"": {""discard"": True}} manager._parse_connection_options(ctxt, vol, conn_info) self.assertIs(conn_info['data']['discard'], True)",,65,1
openstack%2Fopenstack-helm-infra~887986,openstack/openstack-helm-infra,master,Icdcfa5684c2a5e610805f6dec9391a4947b213d4,Make sure ovs ctl file exist before chown,MERGED,2023-07-07 18:36:41.000000000,2023-07-08 18:41:05.000000000,2023-07-08 18:40:09.000000000,"[{'_account_id': 1004}, {'_account_id': 3009}, {'_account_id': 22348}, {'_account_id': 28372}, {'_account_id': 29974}, {'_account_id': 32433}, {'_account_id': 34821}]","[{'number': 1, 'created': '2023-07-07 18:36:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/ba2d74aa0a3039a31017387dd6936613d3a45e5b', 'message': 'Make sure ovs ctl file exist before chown\n\nThis propose to make sure the exist of\n`/run/openvswitch/ovs-vswitchd.${PID}.ctl`\nbefore we do chown command with it.\n\nChange-Id: Icdcfa5684c2a5e610805f6dec9391a4947b213d4\n'}, {'number': 2, 'created': '2023-07-08 15:54:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/26376ccea786c959c94978a8e013251563d71295', 'message': 'Make sure ovs ctl file exist before chown\n\nThis propose to make sure the exist of\n`/run/openvswitch/ovs-vswitchd.${PID}.ctl`\nbefore we do chown command with it.\n\nChange-Id: Icdcfa5684c2a5e610805f6dec9391a4947b213d4\n'}, {'number': 3, 'created': '2023-07-08 16:56:03.000000000', 'files': ['releasenotes/notes/openvswitch.yaml', 'openvswitch/Chart.yaml', 'openvswitch/templates/bin/_openvswitch-vswitchd.sh.tpl'], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/ee4d3ac71ce9fca76eceacfd569e44f019064c1e', 'message': 'Make sure ovs ctl file exist before chown\n\nThis propose to make sure the exist of\n`/run/openvswitch/ovs-vswitchd.${PID}.ctl`\nbefore we do chown command with it.\n\nChange-Id: Icdcfa5684c2a5e610805f6dec9391a4947b213d4\n'}]",1,887986,ee4d3ac71ce9fca76eceacfd569e44f019064c1e,12,7,3,12404,,,0,"Make sure ovs ctl file exist before chown

This propose to make sure the exist of
`/run/openvswitch/ovs-vswitchd.${PID}.ctl`
before we do chown command with it.

Change-Id: Icdcfa5684c2a5e610805f6dec9391a4947b213d4
",git fetch https://review.opendev.org/openstack/openstack-helm-infra refs/changes/86/887986/1 && git format-patch -1 --stdout FETCH_HEAD,['openvswitch/templates/bin/_openvswitch-vswitchd.sh.tpl'],1,ba2d74aa0a3039a31017387dd6936613d3a45e5b,fix-ovs," until [ -f $OVS_CTL ] do echo ""Waiting for file $OVS_CTL"" sleep 1 done",,6,0
openstack%2Fopenstack-ansible~887082,openstack/openstack-ansible,master,Iaf81f778ffd9fcf6572e03e8ce73ffef46bd98aa,Use include_role in task to avoid lack of access to vars,MERGED,2023-06-27 16:25:26.000000000,2023-07-08 17:44:03.000000000,2023-07-08 17:42:42.000000000,"[{'_account_id': 22348}, {'_account_id': 25023}, {'_account_id': 28619}]","[{'number': 1, 'created': '2023-06-27 16:25:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/f20904551ee7ad0cf18f1b8865fcf34c142be606', 'message': ""Use include_role in task to avoid lack of access to vars\n\nThis patch updates the security hardening playbook to use include_role\nwithin a task versus using 'roles' directly to fix cases where\napply_security_hardening is set to False. Some change to Ansible\nappears to limit access to vars when the role is skipped, resulting\nin failures. The side effect of this change is the role is skipped\nentirely (when applicable) versus the individual tasks being skipped,\nwhich speeds up deployment times.\n\nChange-Id: Iaf81f778ffd9fcf6572e03e8ce73ffef46bd98aa\n""}, {'number': 2, 'created': '2023-06-30 14:18:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/c5dba6dd5e9d2f36ae59c3ebb545f38f5b857e11', 'message': ""Use include_role in task to avoid lack of access to vars\n\nThis patch updates the security hardening playbook to use include_role\nwithin a task versus using 'roles' directly to fix cases where\napply_security_hardening is set to False. Some change to Ansible\nappears to limit access to vars when the role is skipped, resulting\nin failures. The side effect of this change is the role is skipped\nentirely (when applicable) versus the individual tasks being skipped,\nwhich speeds up deployment times.\n\nChange-Id: Iaf81f778ffd9fcf6572e03e8ce73ffef46bd98aa\n""}, {'number': 3, 'created': '2023-06-30 14:19:19.000000000', 'files': ['playbooks/infra-journal-remote.yml', 'playbooks/security-hardening.yml'], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/9690b34193430d99c201e3ac2e85258e6aba011e', 'message': ""Use include_role in task to avoid lack of access to vars\n\nThis patch updates the security hardening playbook to use include_role\nwithin a task versus using 'roles' directly to fix cases where\napply_security_hardening is set to False. Some change to Ansible\nappears to limit access to vars when the role is skipped, resulting\nin failures. The side effect of this change is the role is skipped\nentirely (when applicable) versus the individual tasks being skipped,\nwhich speeds up deployment times.\n\nChange-Id: Iaf81f778ffd9fcf6572e03e8ce73ffef46bd98aa\n""}]",5,887082,9690b34193430d99c201e3ac2e85258e6aba011e,27,3,3,16011,,,0,"Use include_role in task to avoid lack of access to vars

This patch updates the security hardening playbook to use include_role
within a task versus using 'roles' directly to fix cases where
apply_security_hardening is set to False. Some change to Ansible
appears to limit access to vars when the role is skipped, resulting
in failures. The side effect of this change is the role is skipped
entirely (when applicable) versus the individual tasks being skipped,
which speeds up deployment times.

Change-Id: Iaf81f778ffd9fcf6572e03e8ce73ffef46bd98aa
",git fetch https://review.opendev.org/openstack/openstack-ansible refs/changes/82/887082/1 && git format-patch -1 --stdout FETCH_HEAD,['playbooks/security-hardening.yml'],1,f20904551ee7ad0cf18f1b8865fcf34c142be606,osa/core-2.15," tasks: - name: Include security hardening role include_role: name: ""ansible-hardening"""," roles: - role: ""ansible-hardening""",4,2
openstack%2Fceilometer~888007,openstack/ceilometer,master,Ieb4f08c08efdc95c13b33bae52c28495b051d78e,Imported Translations from Zanata,ABANDONED,2023-07-08 03:15:49.000000000,2023-07-08 16:11:04.000000000,,[{'_account_id': 22348}],"[{'number': 1, 'created': '2023-07-08 03:15:49.000000000', 'files': ['releasenotes/source/locale/en_GB/LC_MESSAGES/releasenotes.po'], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/dc4ced468068fcaff23f83539183c26248129321', 'message': 'Imported Translations from Zanata\n\nFor more information about this automatic import see:\nhttps://docs.openstack.org/i18n/latest/reviewing-translation-import.html\n\nChange-Id: Ieb4f08c08efdc95c13b33bae52c28495b051d78e\n'}]",0,888007,dc4ced468068fcaff23f83539183c26248129321,3,1,1,11131,,,0,"Imported Translations from Zanata

For more information about this automatic import see:
https://docs.openstack.org/i18n/latest/reviewing-translation-import.html

Change-Id: Ieb4f08c08efdc95c13b33bae52c28495b051d78e
",git fetch https://review.opendev.org/openstack/ceilometer refs/changes/07/888007/1 && git format-patch -1 --stdout FETCH_HEAD,['releasenotes/source/locale/en_GB/LC_MESSAGES/releasenotes.po'],1,dc4ced468068fcaff23f83539183c26248129321,zanata/translations,"""POT-Creation-Date: 2023-07-07 08:57+0000\n""""PO-Revision-Date: 2023-07-07 09:07+0000\n""msgid ""20.0.0-13"" msgstr ""20.0.0-13""","""POT-Creation-Date: 2023-06-19 06:37+0000\n""""PO-Revision-Date: 2023-06-20 11:18+0000\n""msgid ""20.0.0-12"" msgstr ""20.0.0-12""",4,4
openstack%2Fproject-config~887570,openstack/project-config,master,I93e6928d30db8a90b45329ca00f066b4ec1b4ae7,Fix unbound setup for debian-bookworm,MERGED,2023-07-04 07:49:19.000000000,2023-07-08 13:29:58.000000000,2023-07-04 09:46:55.000000000,"[{'_account_id': 13252}, {'_account_id': 22348}]","[{'number': 1, 'created': '2023-07-04 07:49:19.000000000', 'files': ['nodepool/elements/nodepool-base/pkg-map'], 'web_link': 'https://opendev.org/openstack/project-config/commit/3df74599243942aa691cda526f607a89c1a7ec7e', 'message': 'Fix unbound setup for debian-bookworm\n\ndns-root-data has been demoted to a ""Recommends"" dependency of unbound,\nwhich we don\'t install. Sadly the default unbound configuration is\nbroken without it.\n\nChange-Id: I93e6928d30db8a90b45329ca00f066b4ec1b4ae7\n'}]",1,887570,3df74599243942aa691cda526f607a89c1a7ec7e,9,2,1,13252,,,0,"Fix unbound setup for debian-bookworm

dns-root-data has been demoted to a ""Recommends"" dependency of unbound,
which we don't install. Sadly the default unbound configuration is
broken without it.

Change-Id: I93e6928d30db8a90b45329ca00f066b4ec1b4ae7
",git fetch https://review.opendev.org/openstack/project-config refs/changes/70/887570/1 && git format-patch -1 --stdout FETCH_HEAD,['nodepool/elements/nodepool-base/pkg-map'],1,3df74599243942aa691cda526f607a89c1a7ec7e,debian-bookworm,"{ ""release"": { ""debian"": { ""bookworm"": { ""unbound"": ""unbound dns-root-data"" } } } } ",,9,0
openstack%2Fneutron~887615,openstack/neutron,stable/zed,I1a3723ae999fefb5dcbe3a60cf1a4902da9f0265,Don't allow deletion of the router ports without IP addresses,MERGED,2023-07-04 14:48:34.000000000,2023-07-08 12:35:57.000000000,2023-07-08 12:34:08.000000000,"[{'_account_id': 16688}, {'_account_id': 21798}, {'_account_id': 22348}]","[{'number': 1, 'created': '2023-07-04 14:48:34.000000000', 'files': ['neutron/db/l3_db.py', 'neutron/tests/unit/db/test_l3_db.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/1fe05c561c27846af5a35e00f8b0e83a978c3c8f', 'message': ""Don't allow deletion of the router ports without IP addresses\n\nThis patch effectively reverts old patch [1]. From now on it will be not\nallowed to directly remove router ports which don't have fixed IPs\nassigned. Such ports will be treated as any other ports connected to the\nrouters.\nOriginally [1] was introduced to allow cleanup of the router ports for\nwhich subnets were deleted. But now it's not needed anymore as we\nprevent deletion of subnet if there are any ports with IP allocated from\nthat subnet.\n\nCloses-bug: #2025056\n\n[1] https://review.opendev.org/c/openstack/neutron/+/20424\n\nChange-Id: I1a3723ae999fefb5dcbe3a60cf1a4902da9f0265\n(cherry picked from commit 32d589f03ed0d2744fe15173ebacafd18fced8a9)\n""}]",2,887615,1fe05c561c27846af5a35e00f8b0e83a978c3c8f,19,3,1,11975,,,0,"Don't allow deletion of the router ports without IP addresses

This patch effectively reverts old patch [1]. From now on it will be not
allowed to directly remove router ports which don't have fixed IPs
assigned. Such ports will be treated as any other ports connected to the
routers.
Originally [1] was introduced to allow cleanup of the router ports for
which subnets were deleted. But now it's not needed anymore as we
prevent deletion of subnet if there are any ports with IP allocated from
that subnet.

Closes-bug: #2025056

[1] https://review.opendev.org/c/openstack/neutron/+/20424

Change-Id: I1a3723ae999fefb5dcbe3a60cf1a4902da9f0265
(cherry picked from commit 32d589f03ed0d2744fe15173ebacafd18fced8a9)
",git fetch https://review.opendev.org/openstack/neutron refs/changes/15/887615/1 && git format-patch -1 --stdout FETCH_HEAD,"['neutron/db/l3_db.py', 'neutron/tests/unit/db/test_l3_db.py']",2,1fe05c561c27846af5a35e00f8b0e83a978c3c8f,bug/2025056-stable/2023.1-stable/zed," 'device_id': '44', 'id': 'f', } with testtools.ExpectedException(n_exc.ServicePortInUse): self.db.prevent_l3_port_deletion(mock.Mock(), None)"," 'id': 'f' } self.db.prevent_l3_port_deletion(None, None)",3,11
openstack%2Fopenstack-helm~887647,openstack/openstack-helm,master,Ie227e7d2dd297b6095a40f6114ef6b0a2f226790,Run tests for older releases periodic-weekly,MERGED,2023-07-05 00:50:08.000000000,2023-07-08 07:39:37.000000000,2023-07-08 07:37:46.000000000,"[{'_account_id': 3009}, {'_account_id': 22348}, {'_account_id': 33330}]","[{'number': 1, 'created': '2023-07-05 00:50:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm/commit/a206f72ac33ca0eb91bc68c296edc92f6dd85b00', 'message': ""Run tests for older releases periodic-weekly\n\nOpenstack releases older than Yoga are now in\nextended maintenance. To reduce the CI\nfootprint we don't run test jobs for older\nrelases as part of the check/gate pipelines.\n\nInstead we are going to run those jobs as\npart of the periodic-weekly pipeline.\n\nSee the detailed description of extended maintenance\nstatus here\nhttps://docs.openstack.org/project-team-guide/stable-branches.html#maintenance-phases\n\nChange-Id: Ie227e7d2dd297b6095a40f6114ef6b0a2f226790\n""}, {'number': 2, 'created': '2023-07-05 00:57:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm/commit/efd9d80f629737acb4e5a6351bbfac50cd3301ec', 'message': ""Run tests for older releases periodic-weekly\n\nOpenstack releases older than Yoga are now in\nextended maintenance. To reduce the CI\nfootprint we don't run test jobs for older\nrelases as part of the check/gate pipelines.\n\nInstead we are going to run those jobs as\npart of the periodic-weekly pipeline.\n\nSee the detailed description of extended maintenance\nstatus here\nhttps://docs.openstack.org/project-team-guide/stable-branches.html#maintenance-phases\n\nChange-Id: Ie227e7d2dd297b6095a40f6114ef6b0a2f226790\n""}, {'number': 3, 'created': '2023-07-07 17:12:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm/commit/a2a1a6dc11516e740363208e2e3ef660eaedfd47', 'message': ""Run tests for older releases periodic-weekly\n\nOpenstack releases older than Yoga are now in\nextended maintenance. To reduce the CI\nfootprint we don't run test jobs for older\nrelases as part of the check/gate pipelines.\n\nInstead we are going to run those jobs as\npart of the periodic-weekly pipeline.\n\nSee the detailed description of extended maintenance\nstatus here\nhttps://docs.openstack.org/project-team-guide/stable-branches.html#maintenance-phases\n\nChange-Id: Ie227e7d2dd297b6095a40f6114ef6b0a2f226790\n""}, {'number': 4, 'created': '2023-07-08 05:10:41.000000000', 'files': ['zuul.d/project.yaml'], 'web_link': 'https://opendev.org/openstack/openstack-helm/commit/1a3b7b5c2579d8062802342ac977dc29118eda28', 'message': ""Run tests for older releases periodic-weekly\n\nOpenstack releases older than Yoga are now in\nextended maintenance. To reduce the CI\nfootprint we don't run test jobs for older\nrelases as part of the check/gate pipelines.\n\nInstead we are going to run those jobs as\npart of the periodic-weekly pipeline.\n\nSee the detailed description of extended maintenance\nstatus here\nhttps://docs.openstack.org/project-team-guide/stable-branches.html#maintenance-phases\n\nChange-Id: Ie227e7d2dd297b6095a40f6114ef6b0a2f226790\n""}]",7,887647,1a3b7b5c2579d8062802342ac977dc29118eda28,26,3,4,3009,,,0,"Run tests for older releases periodic-weekly

Openstack releases older than Yoga are now in
extended maintenance. To reduce the CI
footprint we don't run test jobs for older
relases as part of the check/gate pipelines.

Instead we are going to run those jobs as
part of the periodic-weekly pipeline.

See the detailed description of extended maintenance
status here
https://docs.openstack.org/project-team-guide/stable-branches.html#maintenance-phases

Change-Id: Ie227e7d2dd297b6095a40f6114ef6b0a2f226790
",git fetch https://review.opendev.org/openstack/openstack-helm refs/changes/47/887647/1 && git format-patch -1 --stdout FETCH_HEAD,['zuul.d/project.yaml'],1,a206f72ac33ca0eb91bc68c296edc92f6dd85b00,, - openstack-helm-cinder-2023-1-ubuntu_focal - openstack-helm-compute-kit-2023-1-ubuntu_focal periodic-weekly: jobs: - openstack-helm-cinder-victoria-ubuntu_focal - openstack-helm-cinder-wallaby-ubuntu_focal - openstack-helm-cinder-xena-ubuntu_focal - openstack-helm-compute-kit-victoria-ubuntu_focal - openstack-helm-compute-kit-wallaby-ubuntu_focal - openstack-helm-compute-kit-xena-ubuntu_focal , - openstack-helm-cinder-victoria-ubuntu_focal - openstack-helm-cinder-wallaby-ubuntu_focal - openstack-helm-cinder-xena-ubuntu_focal - openstack-helm-compute-kit-victoria-ubuntu_focal - openstack-helm-compute-kit-wallaby-ubuntu_focal - openstack-helm-compute-kit-xena-ubuntu_focal - openstack-helm-cinder-wallaby-ubuntu_focal - openstack-helm-compute-kit-wallaby-ubuntu_focal,11,8
openstack%2Fpython-swiftclient~887994,openstack/python-swiftclient,master,I757b76e3af5f667a670cdf65687f23ef2b486666,Declare py311 support,MERGED,2023-07-07 19:42:10.000000000,2023-07-08 06:54:06.000000000,2023-07-08 06:52:16.000000000,"[{'_account_id': 15343}, {'_account_id': 22348}]","[{'number': 1, 'created': '2023-07-07 19:42:10.000000000', 'files': ['.zuul.yaml', 'setup.cfg'], 'web_link': 'https://opendev.org/openstack/python-swiftclient/commit/90f565009a2d18d6f4f3660aa57673e99ba638a7', 'message': 'Declare py311 support\n\nAdd a voting job, update trove classifiers.\n\nChange-Id: I757b76e3af5f667a670cdf65687f23ef2b486666\n'}]",1,887994,90f565009a2d18d6f4f3660aa57673e99ba638a7,8,2,1,15343,,,0,"Declare py311 support

Add a voting job, update trove classifiers.

Change-Id: I757b76e3af5f667a670cdf65687f23ef2b486666
",git fetch https://review.opendev.org/openstack/python-swiftclient refs/changes/94/887994/1 && git format-patch -1 --stdout FETCH_HEAD,"['.zuul.yaml', 'setup.cfg']",2,90f565009a2d18d6f4f3660aa57673e99ba638a7,, Programming Language :: Python :: 3.11,,11,0
openstack%2Fopenstack-helm~887999,openstack/openstack-helm,master,I27600cc732039ef82d41cea8d1ef9bba2eb6001b,Run rally tests sequentially in compute-kit jobs,MERGED,2023-07-07 21:31:09.000000000,2023-07-08 04:02:05.000000000,2023-07-08 03:59:07.000000000,"[{'_account_id': 3009}, {'_account_id': 22348}]","[{'number': 1, 'created': '2023-07-07 21:31:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm/commit/6904397e8f97bdec6f28261a0e772fd8f97d4f5f', 'message': 'Run rally tests sequentially in compute-kit jobs\n\nChange-Id: I27600cc732039ef82d41cea8d1ef9bba2eb6001b\n'}, {'number': 2, 'created': '2023-07-08 01:08:32.000000000', 'files': ['zuul.d/jobs-openstack-helm.yaml'], 'web_link': 'https://opendev.org/openstack/openstack-helm/commit/77fe3a0fb2a271630501e8773c7f8e563c570c08', 'message': 'Run rally tests sequentially in compute-kit jobs\n\nChange-Id: I27600cc732039ef82d41cea8d1ef9bba2eb6001b\n'}]",1,887999,77fe3a0fb2a271630501e8773c7f8e563c570c08,9,2,2,3009,,,0,"Run rally tests sequentially in compute-kit jobs

Change-Id: I27600cc732039ef82d41cea8d1ef9bba2eb6001b
",git fetch https://review.opendev.org/openstack/openstack-helm refs/changes/99/887999/1 && git format-patch -1 --stdout FETCH_HEAD,['zuul.d/jobs-openstack-helm.yaml'],1,6904397e8f97bdec6f28261a0e772fd8f97d4f5f,sequential_rally_tests, - export OSH_TEST_TIMEOUT=1200;./tools/deployment/common/run-helm-tests.sh neutron - ./tools/deployment/common/run-helm-tests.sh nova - ./tools/deployment/common/run-helm-tests.sh glance - ./tools/deployment/common/run-helm-tests.sh keystone, - - export OSH_TEST_TIMEOUT=1200;./tools/deployment/common/run-helm-tests.sh neutron - ./tools/deployment/common/run-helm-tests.sh nova; ./tools/deployment/common/run-helm-tests.sh glance; ./tools/deployment/common/run-helm-tests.sh keystone;,4,4
openstack%2Fpython-swiftclient~443110,openstack/python-swiftclient,master,I6ac1c04ba1831b1445fb0554b5e10fe3b1c26d7b,Python 3.4 support is removed,ABANDONED,2017-03-08 12:42:44.000000000,2023-07-08 03:40:06.000000000,,[{'_account_id': 3}],"[{'number': 1, 'created': '2017-03-08 12:42:44.000000000', 'files': ['setup.cfg', 'tox.ini'], 'web_link': 'https://opendev.org/openstack/python-swiftclient/commit/32783a783d56347afd4667bb7ea43e0fb56ad4ff', 'message': 'Python 3.4 support is removed\n\nIn setup.cfg and tox.ini the python 3.4 is removed\nbeacuse python 3.5 is available.\n\nChange-Id: I6ac1c04ba1831b1445fb0554b5e10fe3b1c26d7b\n'}]",0,443110,32783a783d56347afd4667bb7ea43e0fb56ad4ff,3,1,1,25005,,,0,"Python 3.4 support is removed

In setup.cfg and tox.ini the python 3.4 is removed
beacuse python 3.5 is available.

Change-Id: I6ac1c04ba1831b1445fb0554b5e10fe3b1c26d7b
",git fetch https://review.opendev.org/openstack/python-swiftclient refs/changes/10/443110/1 && git format-patch -1 --stdout FETCH_HEAD,"['setup.cfg', 'tox.ini']",2,32783a783d56347afd4667bb7ea43e0fb56ad4ff,pythonversion,"envlist = py27,py35,pypy,pep8","envlist = py27,py34,py35,pypy,pep8",1,2
openstack%2Frequirements~886406,openstack/requirements,master,Ia3d9182cf067d3684e2ab534e436c97a6562682e,update constraint for keystoneauth1 to new release 5.2.1,MERGED,2023-06-19 14:13:35.000000000,2023-07-08 00:16:02.000000000,2023-07-08 00:15:06.000000000,"[{'_account_id': 11904}, {'_account_id': 14288}, {'_account_id': 22348}]","[{'number': 1, 'created': '2023-06-19 14:13:35.000000000', 'files': ['upper-constraints.txt'], 'web_link': 'https://opendev.org/openstack/requirements/commit/24cab47230976257fc4beca351bea66f31c7d5d0', 'message': 'update constraint for keystoneauth1 to new release 5.2.1\n\nmeta: version: 5.2.1\nmeta: diff-start: -\nmeta: series: bobcat\nmeta: release-type: release\nmeta: pypi: yes\nmeta: first: no\nmeta: release:Author: Artem Goncharov <artem.goncharov@gmail.com>\nmeta: release:Commit: Artem Goncharov <artem.goncharov@gmail.com>\nmeta: release:Change-Id: Ifa7288f2cad259c0569979d7744dd944c1165571\nmeta: release:Code-Review+2: Thierry Carrez <thierry@openstack.org>\nmeta: release:Code-Review+1: David Wilde <dwilde@redhat.com>\nmeta: release:Code-Review+2: Hervé Beraud <herveberaud.pro@gmail.com>\nmeta: release:Workflow+1: Thierry Carrez <thierry@openstack.org>\nChange-Id: Ia3d9182cf067d3684e2ab534e436c97a6562682e\n'}]",3,886406,24cab47230976257fc4beca351bea66f31c7d5d0,18,3,1,11131,,,0,"update constraint for keystoneauth1 to new release 5.2.1

meta: version: 5.2.1
meta: diff-start: -
meta: series: bobcat
meta: release-type: release
meta: pypi: yes
meta: first: no
meta: release:Author: Artem Goncharov <artem.goncharov@gmail.com>
meta: release:Commit: Artem Goncharov <artem.goncharov@gmail.com>
meta: release:Change-Id: Ifa7288f2cad259c0569979d7744dd944c1165571
meta: release:Code-Review+2: Thierry Carrez <thierry@openstack.org>
meta: release:Code-Review+1: David Wilde <dwilde@redhat.com>
meta: release:Code-Review+2: Hervé Beraud <herveberaud.pro@gmail.com>
meta: release:Workflow+1: Thierry Carrez <thierry@openstack.org>
Change-Id: Ia3d9182cf067d3684e2ab534e436c97a6562682e
",git fetch https://review.opendev.org/openstack/requirements refs/changes/06/886406/1 && git format-patch -1 --stdout FETCH_HEAD,['upper-constraints.txt'],1,24cab47230976257fc4beca351bea66f31c7d5d0,new-release,keystoneauth1===5.2.1,keystoneauth1===5.2.0,1,1
openstack%2Ftripleo-common~887503,openstack/tripleo-common,stable/wallaby,Ib7c1b83eaba36f7bc7ea6538e73604ca5bc6bf01,Use nova-libvirt image for LibvirtConfig,MERGED,2023-07-03 10:30:07.000000000,2023-07-07 22:43:04.000000000,2023-07-07 22:42:08.000000000,"[{'_account_id': 6926}, {'_account_id': 9816}, {'_account_id': 17216}, {'_account_id': 20733}, {'_account_id': 22348}, {'_account_id': 22954}, {'_account_id': 23811}]","[{'number': 1, 'created': '2023-07-03 10:30:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-common/commit/2d5ae80c34b2d20382324639983bd6d7e88ecd85', 'message': 'Use nova-libvirt image for LibvirtConfig\n\nThis change moves the ContainerNovaLibvirtConfigImage param to use the\nnova-libvirt image instead of the nova-compute image.\n\nResolves: rhbz#2186553\nSigned-off-by: Brendan Shephard <bshephar@redhat.com>\nChange-Id: Ib7c1b83eaba36f7bc7ea6538e73604ca5bc6bf01\n'}, {'number': 2, 'created': '2023-07-04 11:23:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-common/commit/ab2e63579c60293509ed8c3ca62569aeb2de5d8c', 'message': 'Use nova-libvirt image for LibvirtConfig\n\nThis change moves the ContainerNovaLibvirtConfigImage param to use the\nnova-libvirt image instead of the nova-compute image.\n\nResolves: rhbz#2186553\nSigned-off-by: Brendan Shephard <bshephar@redhat.com>\nChange-Id: Ib7c1b83eaba36f7bc7ea6538e73604ca5bc6bf01\n'}, {'number': 3, 'created': '2023-07-05 00:18:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-common/commit/7ac21a8f72e243b86791d2196d1e355d2e973dc7', 'message': 'Use nova-libvirt image for LibvirtConfig\n\nThis change moves the ContainerNovaLibvirtConfigImage param to use the\nnova-libvirt image instead of the nova-compute image.\n\nResolves: rhbz#2186553\nSigned-off-by: Brendan Shephard <bshephar@redhat.com>\nChange-Id: Ib7c1b83eaba36f7bc7ea6538e73604ca5bc6bf01\n'}, {'number': 4, 'created': '2023-07-05 04:12:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-common/commit/941d1e7bc5c38cf434ba942c215c4bd26e293233', 'message': 'Use nova-libvirt image for LibvirtConfig\n\nThis change moves the ContainerNovaLibvirtConfigImage param to use the\nnova-libvirt image instead of the nova-compute image.\n\nResolves: rhbz#2186553\nSigned-off-by: Brendan Shephard <bshephar@redhat.com>\nChange-Id: Ib7c1b83eaba36f7bc7ea6538e73604ca5bc6bf01\n'}, {'number': 5, 'created': '2023-07-05 05:03:26.000000000', 'files': ['container-images/tripleo_containers.yaml.j2', 'tripleo_common/tests/image/test_kolla_builder.py'], 'web_link': 'https://opendev.org/openstack/tripleo-common/commit/4c109097e02ff9a7be217a2e6f053487b06cc950', 'message': 'Use nova-libvirt image for LibvirtConfig\n\nThis change moves the ContainerNovaLibvirtConfigImage param to use the\nnova-libvirt image instead of the nova-compute image.\n\nResolves: rhbz#2186553\nSigned-off-by: Brendan Shephard <bshephar@redhat.com>\nChange-Id: Ib7c1b83eaba36f7bc7ea6538e73604ca5bc6bf01\n'}]",17,887503,4c109097e02ff9a7be217a2e6f053487b06cc950,36,7,5,30073,,,0,"Use nova-libvirt image for LibvirtConfig

This change moves the ContainerNovaLibvirtConfigImage param to use the
nova-libvirt image instead of the nova-compute image.

Resolves: rhbz#2186553
Signed-off-by: Brendan Shephard <bshephar@redhat.com>
Change-Id: Ib7c1b83eaba36f7bc7ea6538e73604ca5bc6bf01
",git fetch https://review.opendev.org/openstack/tripleo-common refs/changes/03/887503/1 && git format-patch -1 --stdout FETCH_HEAD,['container-images/tripleo_containers.yaml.j2'],1,2d5ae80c34b2d20382324639983bd6d7e88ecd85,, - ContainerNovaLibvirtConfigImage, - ContainerNovaLibvirtConfigImage,1,1
openstack%2Fneutron-lib~886589,openstack/neutron-lib,master,Ie74934754598292b125d2be7edb4bbcbb898a230,Removed ``HasProjectPrimaryKeyIndex`` class,MERGED,2023-06-21 10:06:36.000000000,2023-07-07 20:49:17.000000000,2023-07-07 20:48:22.000000000,"[{'_account_id': 1131}, {'_account_id': 5948}, {'_account_id': 8313}, {'_account_id': 11975}, {'_account_id': 16688}, {'_account_id': 22348}]","[{'number': 1, 'created': '2023-06-21 10:06:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-lib/commit/153f15c51627f37ace71cc62234d99063706ae85', 'message': 'Removed ``HasProjectPrimaryKeyIndex`` class\n\nA column that is primary key creates an index by default. There is no\nneed to create another one by passing index=True.\n\nRelated-Bug: #2024044\nChange-Id: Ie74934754598292b125d2be7edb4bbcbb898a230\n'}, {'number': 2, 'created': '2023-07-03 07:45:13.000000000', 'files': ['neutron_lib/db/model_base.py'], 'web_link': 'https://opendev.org/openstack/neutron-lib/commit/673e48a1890c721654ce0de9cd9e0897c791bd6a', 'message': 'Removed ``HasProjectPrimaryKeyIndex`` class\n\nA column that is primary key creates an index by default. There is no\nneed to create another one by passing index=True.\n\nRelated-Bug: #2024044\nChange-Id: Ie74934754598292b125d2be7edb4bbcbb898a230\n'}]",3,886589,673e48a1890c721654ce0de9cd9e0897c791bd6a,16,6,2,16688,,,0,"Removed ``HasProjectPrimaryKeyIndex`` class

A column that is primary key creates an index by default. There is no
need to create another one by passing index=True.

Related-Bug: #2024044
Change-Id: Ie74934754598292b125d2be7edb4bbcbb898a230
",git fetch https://review.opendev.org/openstack/neutron-lib refs/changes/89/886589/1 && git format-patch -1 --stdout FETCH_HEAD,['neutron_lib/db/model_base.py'],1,153f15c51627f37ace71cc62234d99063706ae85,bug/2024044,,"class HasProjectPrimaryKeyIndex(HasProject): """"""Project mixin, add to subclasses that have a user."""""" # NOTE: project_id is just a free form string project_id = sa.Column(sa.String(db_const.PROJECT_ID_FIELD_SIZE), nullable=False, primary_key=True, index=True) ",0,8
openstack%2Fswift~886633,openstack/swift,master,I8ed9b4ca5af90e9a64ec996725e59cba34f796a5,"In the case where we can't stat the device, an error search in the Kernel logs must also be carried out, and the device unmounted if necessary",ABANDONED,2023-06-21 12:37:37.000000000,2023-07-07 20:06:08.000000000,,[{'_account_id': 22348}],"[{'number': 1, 'created': '2023-06-21 12:37:37.000000000', 'files': ['bin/swift-drive-audit'], 'web_link': 'https://opendev.org/openstack/swift/commit/761863ada93b13a9cb1b1055942b7982fb9877c8', 'message': ""In the case where we can't stat the device, an error search in the Kernel logs must also be carried out, and the device unmounted if necessary\n\nChange-Id: I8ed9b4ca5af90e9a64ec996725e59cba34f796a5\n""}]",1,886633,761863ada93b13a9cb1b1055942b7982fb9877c8,4,1,1,36116,,,0,"In the case where we can't stat the device, an error search in the Kernel logs must also be carried out, and the device unmounted if necessary

Change-Id: I8ed9b4ca5af90e9a64ec996725e59cba34f796a5
",git fetch https://review.opendev.org/openstack/swift refs/changes/33/886633/1 && git format-patch -1 --stdout FETCH_HEAD,['bin/swift-drive-audit'],1,761863ada93b13a9cb1b1055942b7982fb9877c8,TOPIC-BRANCH," # In this case, an error search in the Kernel logs must also be carried out, and the device unmounted if necessary devices.append(device)",,2,0
openstack%2Fironic~887991,openstack/ironic,master,I41baf76d8e0f20e5760e0d75af825ab6dd446e92,Make sure there's no stale path_tmp,ABANDONED,2023-07-07 19:14:50.000000000,2023-07-07 20:02:56.000000000,,[],"[{'number': 1, 'created': '2023-07-07 19:14:50.000000000', 'files': ['ironic/drivers/modules/image_cache.py'], 'web_link': 'https://opendev.org/openstack/ironic/commit/691cbedd87d52fd9656cf4072ef194a52e78085f', 'message': ""Make sure there's no stale path_tmp\n\nWe might get a stale .part file that is incomplete and corrupted (ie: full disk\nue to image conversion, server reboots, oom) and this prevents future deployment\nfrom completing successfully.\n\nChange-Id: I41baf76d8e0f20e5760e0d75af825ab6dd446e92\n""}]",0,887991,691cbedd87d52fd9656cf4072ef194a52e78085f,4,0,1,7130,,,0,"Make sure there's no stale path_tmp

We might get a stale .part file that is incomplete and corrupted (ie: full disk
ue to image conversion, server reboots, oom) and this prevents future deployment
from completing successfully.

Change-Id: I41baf76d8e0f20e5760e0d75af825ab6dd446e92
",git fetch https://review.opendev.org/openstack/ironic refs/changes/91/887991/1 && git format-patch -1 --stdout FETCH_HEAD,['ironic/drivers/modules/image_cache.py'],1,691cbedd87d52fd9656cf4072ef194a52e78085f,stale_download," if os.path.exists(path_tmp): LOG.warning(""%s exist, assuming it's stale"" % (path_tmp)) os.remove(path_tmp)",,3,0
openstack%2Fironic~887954,openstack/ironic,stable/train,I53bfd0dcc6289e51316795fbe352c70d608e4f31,Cleanup if images.fetch fails,ABANDONED,2023-07-07 13:17:42.000000000,2023-07-07 19:15:31.000000000,,[{'_account_id': 22348}],"[{'number': 1, 'created': '2023-07-07 13:17:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/77a61d46c2b35c7c44929b76eda70cbccfac24b5', 'message': 'Cleanup if images.fetch fails\n\nCleanup if images.fetch fails as in some cases, we might get a stale\n.part file that is incomplete and corrupted (ie: full disk due to image\nconversion) and this prevents future deployment from working.\n\nChange-Id: I53bfd0dcc6289e51316795fbe352c70d608e4f31\n'}, {'number': 2, 'created': '2023-07-07 17:00:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/bfd35a9b9c2bc67c4fb8b4f88d0c02a7b6001290', 'message': 'Cleanup if images.fetch fails\n\nCleanup if images.fetch fails as in some cases, we might get a stale\n.part file that is incomplete and corrupted (ie: full disk due to image\nconversion) and this prevents future deployment from working.\n\nChange-Id: I53bfd0dcc6289e51316795fbe352c70d608e4f31\n'}, {'number': 3, 'created': '2023-07-07 17:09:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/a8dd65d8a5d03c2caa3b28060151c553ed832470', 'message': 'Cleanup if images.fetch fails\n\nCleanup if images.fetch fails as in some cases, we might get a stale\n.part file that is incomplete and corrupted (ie: full disk due to image\nconversion) and this prevents future deployment from working.\n\nChange-Id: I53bfd0dcc6289e51316795fbe352c70d608e4f31\n'}, {'number': 4, 'created': '2023-07-07 18:31:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/9f32543f04a0ac9ec818898e737de17717e74a2c', 'message': 'Cleanup if images.fetch fails\n\nCleanup if images.fetch fails as in some cases, we might get a stale\n.part file that is incomplete and corrupted (ie: full disk due to image\nconversion) and this prevents future deployment from working.\n\nChange-Id: I53bfd0dcc6289e51316795fbe352c70d608e4f31\n'}, {'number': 5, 'created': '2023-07-07 18:33:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/f187053aaade360874b9865a7535429effc62747', 'message': 'Cleanup if images.fetch fails\n\nCleanup if images.fetch fails as in some cases, we might get a stale\n.part file that is incomplete and corrupted (ie: full disk due to image\nconversion) and this prevents future deployment from working.\n\nChange-Id: I53bfd0dcc6289e51316795fbe352c70d608e4f31\n'}, {'number': 6, 'created': '2023-07-07 18:52:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/52bf94308665c45b60e354e62bf07a42748422d0', 'message': 'Cleanup if images.fetch fails\n\nCleanup if images.fetch fails as in some cases, we might get a stale\n.part file that is incomplete and corrupted (ie: full disk due to image\nconversion) and this prevents future deployment from working.\n\nChange-Id: I53bfd0dcc6289e51316795fbe352c70d608e4f31\n'}, {'number': 7, 'created': '2023-07-07 19:09:40.000000000', 'files': ['ironic/drivers/modules/image_cache.py'], 'web_link': 'https://opendev.org/openstack/ironic/commit/064ec755c32b72c874cf5b7545470cce76f8eb16', 'message': 'Cleanup if images.fetch fails\n\nCleanup if images.fetch fails as in some cases, we might get a stale\n.part file that is incomplete and corrupted (ie: full disk due to image\nconversion) and this prevents future deployment from working.\n\nChange-Id: I53bfd0dcc6289e51316795fbe352c70d608e4f31\n'}]",41,887954,064ec755c32b72c874cf5b7545470cce76f8eb16,17,1,7,7130,,,0,"Cleanup if images.fetch fails

Cleanup if images.fetch fails as in some cases, we might get a stale
.part file that is incomplete and corrupted (ie: full disk due to image
conversion) and this prevents future deployment from working.

Change-Id: I53bfd0dcc6289e51316795fbe352c70d608e4f31
",git fetch https://review.opendev.org/openstack/ironic refs/changes/54/887954/1 && git format-patch -1 --stdout FETCH_HEAD,['ironic/drivers/modules/image_cache.py'],1,77a61d46c2b35c7c44929b76eda70cbccfac24b5,," try: images.fetch(context, image_href, path_tmp, force_raw=False) except: os.remove(path_tmp)"," images.fetch(context, image_href, path_tmp, force_raw=False)",4,1
openstack%2Fos-brick~887390,openstack/os-brick,master,I7cced8b9d8704c1782ac8583ce227efcc21b2847,mypy: Fix failing mypy job,MERGED,2023-06-30 13:00:07.000000000,2023-07-07 19:03:44.000000000,2023-07-07 19:02:47.000000000,"[{'_account_id': 4523}, {'_account_id': 5314}, {'_account_id': 9535}, {'_account_id': 22348}]","[{'number': 1, 'created': '2023-06-30 13:00:07.000000000', 'files': ['os_brick/initiator/connectors/fibre_channel.py'], 'web_link': 'https://opendev.org/openstack/os-brick/commit/4d41c2986c5fc6389e1dc7a3053da03338dbda21', 'message': 'mypy: Fix failing mypy job\n\nCurrently fails w/ ""Unused type: ignore comment"" errors.\n\nChange-Id: I7cced8b9d8704c1782ac8583ce227efcc21b2847\n'}]",1,887390,4d41c2986c5fc6389e1dc7a3053da03338dbda21,18,4,1,4523,,,0,"mypy: Fix failing mypy job

Currently fails w/ ""Unused type: ignore comment"" errors.

Change-Id: I7cced8b9d8704c1782ac8583ce227efcc21b2847
",git fetch https://review.opendev.org/openstack/os-brick refs/changes/90/887390/1 && git format-patch -1 --stdout FETCH_HEAD,['os_brick/initiator/connectors/fibre_channel.py'],1,4d41c2986c5fc6389e1dc7a3053da03338dbda21,, if exc: raise exc, if exc: # type: ignore raise exc # type: ignore,2,2
openstack%2Foctavia~875364,openstack/octavia,master,I2c8b235835d1c00f81302ed881e18040cb2c7c16,[sqlalchemy2] Added missing relationships in models,MERGED,2023-02-27 07:52:40.000000000,2023-07-07 18:22:50.000000000,2023-07-07 18:21:46.000000000,"[{'_account_id': 11628}, {'_account_id': 22348}, {'_account_id': 32238}, {'_account_id': 34429}]","[{'number': 1, 'created': '2023-02-27 07:52:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/octavia/commit/f0c682e8c853dcd42cc32bf4c1db08000a6cbd12', 'message': '[sqlalchemy2] Added missing relationships in models\n\nSome missing relationships triggered issues when creating many objects\nin the same transaction, for instance a FlavorProfile, a Flavor and a\nLoadBalancer. The FlavorProfile was not created before the Flavor,\nviolating the foreign key constraint.\n\nChange-Id: I2c8b235835d1c00f81302ed881e18040cb2c7c16\n'}, {'number': 2, 'created': '2023-03-29 08:44:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/octavia/commit/d62efd2b7e6e52ae8f0395cc7ed8b819d0235740', 'message': '[sqlalchemy2] Added missing relationships in models\n\nSome missing relationships triggered issues when creating many objects\nin the same transaction, for instance a FlavorProfile, a Flavor and a\nLoadBalancer. The FlavorProfile was not created before the Flavor,\nviolating the foreign key constraint.\n\nChange-Id: I2c8b235835d1c00f81302ed881e18040cb2c7c16\n'}, {'number': 3, 'created': '2023-04-24 06:50:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/octavia/commit/43fbdee9dea0ebca15331fb682306fde67b12622', 'message': '[sqlalchemy2] Added missing relationships in models\n\nSome missing relationships triggered issues when creating many objects\nin the same transaction, for instance a FlavorProfile, a Flavor and a\nLoadBalancer. The FlavorProfile was not created before the Flavor,\nviolating the foreign key constraint.\n\nChange-Id: I2c8b235835d1c00f81302ed881e18040cb2c7c16\n'}, {'number': 4, 'created': '2023-05-03 07:07:19.000000000', 'files': ['octavia/db/models.py'], 'web_link': 'https://opendev.org/openstack/octavia/commit/e63e149b752575a6416dfcac61e2467f5d6f2846', 'message': '[sqlalchemy2] Added missing relationships in models\n\nSome missing relationships triggered issues when creating many objects\nin the same transaction, for instance a FlavorProfile, a Flavor and a\nLoadBalancer. The FlavorProfile was not created before the Flavor,\nviolating the foreign key constraint.\n\nChange-Id: I2c8b235835d1c00f81302ed881e18040cb2c7c16\n'}]",6,875364,e63e149b752575a6416dfcac61e2467f5d6f2846,26,4,4,29244,,,0,"[sqlalchemy2] Added missing relationships in models

Some missing relationships triggered issues when creating many objects
in the same transaction, for instance a FlavorProfile, a Flavor and a
LoadBalancer. The FlavorProfile was not created before the Flavor,
violating the foreign key constraint.

Change-Id: I2c8b235835d1c00f81302ed881e18040cb2c7c16
",git fetch https://review.opendev.org/openstack/octavia refs/changes/64/875364/1 && git format-patch -1 --stdout FETCH_HEAD,['octavia/db/models.py'],1,f0c682e8c853dcd42cc32bf4c1db08000a6cbd12,sqlalchemy2," flavor = orm.relationship(""Flavor"") flavor_profile = orm.relationship(""FlavorProfile"") availability_zone_profile = orm.relationship(""AvailabilityZoneProfile"")",,3,0
openstack%2Foctavia~861315,openstack/octavia,master,I4507d79bd49a325dae825088db22f49a93ddd6f3,[sqlalchemy2] Removal of cascade backrefs,MERGED,2022-10-14 06:19:17.000000000,2023-07-07 17:54:55.000000000,2023-07-07 17:53:52.000000000,"[{'_account_id': 11628}, {'_account_id': 22348}, {'_account_id': 32238}, {'_account_id': 34429}]","[{'number': 1, 'created': '2022-10-14 06:19:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/octavia/commit/a92bb724b4a1407fdbc0e73c5e5244c2db17c3da', 'message': 'WIP [sqlalchemy2] Prepare the removal of cascade backrefs\n\n[0] https://docs.sqlalchemy.org/en/14/errors.html#\\\n    object-is-being-merged-into-a-session-along-the-backref-cascade\n\nChange-Id: I4507d79bd49a325dae825088db22f49a93ddd6f3\n'}, {'number': 2, 'created': '2023-02-27 07:52:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/octavia/commit/b91b391135cee0068175c1f9c2c80dd90a751ad6', 'message': '[sqlalchemy2] Removal of cascade backrefs\n\n[0] https://docs.sqlalchemy.org/en/14/errors.html#\\\n    object-is-being-merged-into-a-session-along-the-backref-cascade\n\nChange-Id: I4507d79bd49a325dae825088db22f49a93ddd6f3\n'}, {'number': 3, 'created': '2023-03-29 08:44:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/octavia/commit/fb5c6ebd07854d635a46b64ae49a05141a80400b', 'message': '[sqlalchemy2] Removal of cascade backrefs\n\n[0] https://docs.sqlalchemy.org/en/14/errors.html#\\\n    object-is-being-merged-into-a-session-along-the-backref-cascade\n\nChange-Id: I4507d79bd49a325dae825088db22f49a93ddd6f3\n'}, {'number': 4, 'created': '2023-04-24 06:50:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/octavia/commit/f24e744858db889603ef8645af06e917a852e3c7', 'message': '[sqlalchemy2] Removal of cascade backrefs\n\n[0] https://docs.sqlalchemy.org/en/14/errors.html#\\\n    object-is-being-merged-into-a-session-along-the-backref-cascade\n\nChange-Id: I4507d79bd49a325dae825088db22f49a93ddd6f3\n'}, {'number': 5, 'created': '2023-05-03 07:07:19.000000000', 'files': ['octavia/tests/fixtures.py', 'octavia/db/models.py'], 'web_link': 'https://opendev.org/openstack/octavia/commit/022b407784ca199150833bdb5f94dca35d5591ac', 'message': '[sqlalchemy2] Removal of cascade backrefs\n\n[0] https://docs.sqlalchemy.org/en/14/errors.html#\\\n    object-is-being-merged-into-a-session-along-the-backref-cascade\n\nChange-Id: I4507d79bd49a325dae825088db22f49a93ddd6f3\n'}]",8,861315,022b407784ca199150833bdb5f94dca35d5591ac,29,4,5,29244,,,0,"[sqlalchemy2] Removal of cascade backrefs

[0] https://docs.sqlalchemy.org/en/14/errors.html#\
    object-is-being-merged-into-a-session-along-the-backref-cascade

Change-Id: I4507d79bd49a325dae825088db22f49a93ddd6f3
",git fetch https://review.opendev.org/openstack/octavia refs/changes/15/861315/1 && git format-patch -1 --stdout FETCH_HEAD,"['octavia/tests/fixtures.py', 'octavia/db/models.py']",2,a92bb724b4a1407fdbc0e73c5e5244c2db17c3da,sqlalchemy2," back_populates=""default_pool"", cascade_backrefs=False) back_populates=""_default_listeners"", cascade_backrefs=False)"," back_populates=""default_pool"") back_populates=""_default_listeners"")",4,7
openstack%2Fopenstacksdk~883461,openstack/openstacksdk,master,Ib877d292f8adbf2fa0c51065f2917b3f1e263483,Bump the chunk_size to use CPU more efficiently,MERGED,2023-05-18 02:32:10.000000000,2023-07-07 17:43:42.000000000,2023-07-07 17:42:44.000000000,"[{'_account_id': 10239}, {'_account_id': 22348}, {'_account_id': 27900}]","[{'number': 1, 'created': '2023-05-18 02:32:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstacksdk/commit/be1c2ed5db0d0b36fe0f0635c2455d99df738f0d', 'message': 'Bump the chunk_size to use CPU more efficiently\n\nThe chunk_size used for downloading images was 1KiB for some time. That\nis okay for relatively small images but the client side of CPU can be a\nbottleneck especially for large images. Bump the default chunk_size from\n1KiB to 1MiB so we can use the client side CPU more efficiently.\n\n[1KiB chunk_size - current]\n\n$ time openstack image save IMAGE_689MB --file /dev/null\n\nreal    0m16.633s\nuser    0m12.633s\nsys     0m1.365s\n\n-> ~331 Mbps\n\n[1MiB chunk_size - patched]\n\n$ time openstack image save IMAGE_689MB --file /dev/null\n\nreal    0m4.896s\nuser    0m3.361s\nsys     0m0.724s\n\n-> ~1,125 Mbps\n\nStory: 2010759\nTask: 48044\nChange-Id: Ib877d292f8adbf2fa0c51065f2917b3f1e263483\n'}, {'number': 2, 'created': '2023-05-18 02:53:01.000000000', 'files': ['openstack/image/v1/_proxy.py', 'openstack/image/_download.py', 'examples/image/download.py', 'openstack/image/v2/_proxy.py', 'openstack/cloud/_image.py'], 'web_link': 'https://opendev.org/openstack/openstacksdk/commit/a72d46a9554ba50a36539dd046a6fdbf73de2808', 'message': 'Bump the chunk_size to use CPU more efficiently\n\nThe chunk_size used for downloading images was 1KiB for some time. That\nis okay for relatively small images but the client side of CPU can be a\nbottleneck especially for large images. Bump the default chunk_size from\n1KiB to 1MiB so we can use the client side CPU more efficiently.\n\n[1KiB chunk_size - current]\n\n$ time openstack image save IMAGE_689MB --file /dev/null\n\nreal    0m16.633s\nuser    0m12.633s\nsys     0m1.365s\n\n-> ~331 Mbps\n\n[1MiB chunk_size - patched]\n\n$ time openstack image save IMAGE_689MB --file /dev/null\n\nreal    0m4.896s\nuser    0m3.361s\nsys     0m0.724s\n\n-> ~1,125 Mbps\n\nStory: 2010759\nTask: 48044\nChange-Id: Ib877d292f8adbf2fa0c51065f2917b3f1e263483\n'}]",1,883461,a72d46a9554ba50a36539dd046a6fdbf73de2808,10,3,2,8108,,,0,"Bump the chunk_size to use CPU more efficiently

The chunk_size used for downloading images was 1KiB for some time. That
is okay for relatively small images but the client side of CPU can be a
bottleneck especially for large images. Bump the default chunk_size from
1KiB to 1MiB so we can use the client side CPU more efficiently.

[1KiB chunk_size - current]

$ time openstack image save IMAGE_689MB --file /dev/null

real    0m16.633s
user    0m12.633s
sys     0m1.365s

-> ~331 Mbps

[1MiB chunk_size - patched]

$ time openstack image save IMAGE_689MB --file /dev/null

real    0m4.896s
user    0m3.361s
sys     0m0.724s

-> ~1,125 Mbps

Story: 2010759
Task: 48044
Change-Id: Ib877d292f8adbf2fa0c51065f2917b3f1e263483
",git fetch https://review.opendev.org/openstack/openstacksdk refs/changes/61/883461/1 && git format-patch -1 --stdout FETCH_HEAD,"['openstack/image/v1/_proxy.py', 'openstack/image/_download.py', 'examples/image/download.py', 'openstack/image/v2/_proxy.py', 'openstack/cloud/_image.py']",5,be1c2ed5db0d0b36fe0f0635c2455d99df738f0d,chunk_size_1MiB," chunk_size=1024 * 1024, at one time. Defaults to 1 MiB"," chunk_size=1024, at one time. Defaults to 1024",9,7
openstack%2Fopenstack-tempest-skiplist~887880,openstack/openstack-tempest-skiplist,master,I5c96971efcb0e95b207ae514c376714ddbd193a9,"Revert ""Add fs020-rbac to skiplist - BZ2211604""",MERGED,2023-07-07 16:11:51.000000000,2023-07-07 17:16:50.000000000,2023-07-07 17:15:52.000000000,"[{'_account_id': 8367}, {'_account_id': 9976}, {'_account_id': 22348}]","[{'number': 1, 'created': '2023-07-07 16:11:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-tempest-skiplist/commit/51955a19ac9954ba09decb24adcdaa0afb94a667', 'message': 'Revert ""Add fs020-rbac to skiplist - BZ2211604""\n\nThis reverts commit 30b34879ce3d2b90cdc30bf914dcbca10ea6aaf2.\n\nReason for revert: ovn22.12-22.12.0-94.el9fdp with the fix is in the latest compose\n\nChange-Id: I5c96971efcb0e95b207ae514c376714ddbd193a9\n'}, {'number': 2, 'created': '2023-07-07 16:21:45.000000000', 'files': ['roles/validate-tempest/vars/tempest_skip.yml'], 'web_link': 'https://opendev.org/openstack/openstack-tempest-skiplist/commit/ec349ebef6942b2343be4584f734559f33eae241', 'message': 'Revert ""Add fs020-rbac to skiplist - BZ2211604""\n\nThis reverts commit 30b34879ce3d2b90cdc30bf914dcbca10ea6aaf2.\n\nReason for revert: ovn22.12-22.12.0-94.el9fdp with the fix is in the latest compose\n\nChange-Id: I5c96971efcb0e95b207ae514c376714ddbd193a9\n'}]",0,887880,ec349ebef6942b2343be4584f734559f33eae241,11,3,2,1955,,,0,"Revert ""Add fs020-rbac to skiplist - BZ2211604""

This reverts commit 30b34879ce3d2b90cdc30bf914dcbca10ea6aaf2.

Reason for revert: ovn22.12-22.12.0-94.el9fdp with the fix is in the latest compose

Change-Id: I5c96971efcb0e95b207ae514c376714ddbd193a9
",git fetch https://review.opendev.org/openstack/openstack-tempest-skiplist refs/changes/80/887880/1 && git format-patch -1 --stdout FETCH_HEAD,['roles/validate-tempest/vars/tempest_skip.yml'],1,51955a19ac9954ba09decb24adcdaa0afb94a667,fs020-rbac,, - periodic-tripleo-ci-rhel-9-ovb-1ctlr_2comp-featureset020-rbac-internal-rhos-17.1 - periodic-tripleo-ci-rhel-9-ovb-1ctlr_2comp-featureset020-rbac-internal-rhos-17.1,0,2
openstack%2Fswift~887910,openstack/swift,master,I035ef2dcc0d0e09337bd2e742baeff1fb62bf018,Object-server: backfill unit test coverage for keep_cache_private,MERGED,2023-07-07 05:39:56.000000000,2023-07-07 17:05:41.000000000,2023-07-07 17:04:37.000000000,"[{'_account_id': 15343}, {'_account_id': 22348}]","[{'number': 1, 'created': '2023-07-07 05:39:56.000000000', 'files': ['test/unit/obj/test_server.py'], 'web_link': 'https://opendev.org/openstack/swift/commit/1b7cf29476a2f77ceab1a082100b0c7e7cb8dc93', 'message': 'Object-server: backfill unit test coverage for keep_cache_private\n\nChange-Id: I035ef2dcc0d0e09337bd2e742baeff1fb62bf018\n'}]",1,887910,1b7cf29476a2f77ceab1a082100b0c7e7cb8dc93,8,2,1,34930,,,0,"Object-server: backfill unit test coverage for keep_cache_private

Change-Id: I035ef2dcc0d0e09337bd2e742baeff1fb62bf018
",git fetch https://review.opendev.org/openstack/swift refs/changes/10/887910/1 && git format-patch -1 --stdout FETCH_HEAD,['test/unit/obj/test_server.py'],1,1b7cf29476a2f77ceab1a082100b0c7e7cb8dc93,keep_cache_tests," def test_GET_keep_cache_private_config_true(self): # Test swift.obj.server.ObjectController.GET that, when # 'keep_cache_private' is configured True, then # disk_file.reader will be called with keep_cache=True. # Set up a new ObjectController with customized configurations. conf = {'devices': self.testdir, 'mount_check': 'false', 'container_update_timeout': 0.0, 'keep_cache_private': 'True'} obj_controller = object_server.ObjectController( conf, logger=self.logger) obj_controller.bytes_per_sync = 1 timestamp = normalize_timestamp(time()) req = Request.blank('/sda1/p/a/c/o', environ={'REQUEST_METHOD': 'PUT'}, headers={'X-Timestamp': timestamp, 'Content-Type': 'application/x-test'}) req.body = b'VERIFY' resp = req.get_response(obj_controller) self.assertEqual(resp.status_int, 201) # Request headers have neither 'X-Auth-Token' nor 'X-Storage-Token'. req = Request.blank('/sda1/p/a/c/o', headers={'Content-Type': 'application/x-test'}) reader_mock = mock.Mock(keep_cache=False) with mock.patch('swift.obj.diskfile.BaseDiskFile.reader', reader_mock): resp = req.get_response(obj_controller) reader_mock.assert_called_with(keep_cache=True) self.assertEqual(resp.status_int, 200) etag = '""%s""' % md5(b'VERIFY', usedforsecurity=False).hexdigest() self.assertEqual(dict(resp.headers), { 'Content-Type': 'application/x-test', 'Content-Length': '6', 'Etag': etag, 'X-Backend-Timestamp': timestamp, 'X-Timestamp': timestamp, 'X-Backend-Data-Timestamp': timestamp, 'X-Backend-Durable-Timestamp': timestamp, 'Last-Modified': strftime( '%a, %d %b %Y %H:%M:%S GMT', gmtime(math.ceil(float(timestamp)))), }) # Request headers have 'X-Auth-Token'. req = Request.blank('/sda1/p/a/c/o', headers={'Content-Type': 'application/x-test', 'X-Auth-Token': '2340lsdfhhjl02lxfjj'}) reader_mock = mock.Mock(keep_cache=False) with mock.patch('swift.obj.diskfile.BaseDiskFile.reader', reader_mock): resp = req.get_response(obj_controller) reader_mock.assert_called_with(keep_cache=True) self.assertEqual(resp.status_int, 200) # Request headers have 'X-Storage-Token'. req = Request.blank('/sda1/p/a/c/o', headers={'Content-Type': 'application/x-test', 'X-Storage-Token': '2340lsdfhhjl02lxfjj'}) reader_mock = mock.Mock(keep_cache=False) with mock.patch('swift.obj.diskfile.BaseDiskFile.reader', reader_mock): resp = req.get_response(obj_controller) reader_mock.assert_called_with(keep_cache=True) self.assertEqual(resp.status_int, 200) # Request headers have both 'X-Auth-Token' and 'X-Storage-Token'. req = Request.blank('/sda1/p/a/c/o', headers={'Content-Type': 'application/x-test', 'X-Auth-Token': '2340lsdfhhjl02lxfjj', 'X-Storage-Token': '2340lsdfhhjl02lxfjj'}) reader_mock = mock.Mock(keep_cache=False) with mock.patch('swift.obj.diskfile.BaseDiskFile.reader', reader_mock): resp = req.get_response(obj_controller) reader_mock.assert_called_with(keep_cache=True) self.assertEqual(resp.status_int, 200) def test_GET_keep_cache_private_config_false(self): # Test swift.obj.server.ObjectController.GET that, when # 'keep_cache_private' is configured false, then # disk_file.reader will be called with correct 'keep_cache'. # Set up a new ObjectController with customized configurations. conf = {'devices': self.testdir, 'mount_check': 'false', 'container_update_timeout': 0.0, 'keep_cache_private': 'false'} obj_controller = object_server.ObjectController( conf, logger=self.logger) obj_controller.bytes_per_sync = 1 timestamp = normalize_timestamp(time()) req = Request.blank('/sda1/p/a/c/o', environ={'REQUEST_METHOD': 'PUT'}, headers={'X-Timestamp': timestamp, 'Content-Type': 'application/x-test'}) req.body = b'VERIFY' resp = req.get_response(obj_controller) self.assertEqual(resp.status_int, 201) # Request headers have neither 'X-Auth-Token' nor 'X-Storage-Token'. req = Request.blank('/sda1/p/a/c/o', headers={'Content-Type': 'application/x-test'}) reader_mock = mock.Mock(keep_cache=False) with mock.patch('swift.obj.diskfile.BaseDiskFile.reader', reader_mock): resp = req.get_response(obj_controller) reader_mock.assert_called_with(keep_cache=True) self.assertEqual(resp.status_int, 200) etag = '""%s""' % md5(b'VERIFY', usedforsecurity=False).hexdigest() self.assertEqual(dict(resp.headers), { 'Content-Type': 'application/x-test', 'Content-Length': '6', 'Etag': etag, 'X-Backend-Timestamp': timestamp, 'X-Timestamp': timestamp, 'X-Backend-Data-Timestamp': timestamp, 'X-Backend-Durable-Timestamp': timestamp, 'Last-Modified': strftime( '%a, %d %b %Y %H:%M:%S GMT', gmtime(math.ceil(float(timestamp)))), }) # Request headers have 'X-Auth-Token'. req = Request.blank('/sda1/p/a/c/o', headers={'Content-Type': 'application/x-test', 'X-Auth-Token': '2340lsdfhhjl02lxfjj'}) reader_mock = mock.Mock(keep_cache=False) with mock.patch('swift.obj.diskfile.BaseDiskFile.reader', reader_mock): resp = req.get_response(obj_controller) reader_mock.assert_called_with(keep_cache=False) self.assertEqual(resp.status_int, 200) # Request headers have 'X-Storage-Token'. req = Request.blank('/sda1/p/a/c/o', headers={'Content-Type': 'application/x-test', 'X-Storage-Token': '2340lsdfhhjl02lxfjj'}) reader_mock = mock.Mock(keep_cache=False) with mock.patch('swift.obj.diskfile.BaseDiskFile.reader', reader_mock): resp = req.get_response(obj_controller) reader_mock.assert_called_with(keep_cache=False) self.assertEqual(resp.status_int, 200) # Request headers have both 'X-Auth-Token' and 'X-Storage-Token'. req = Request.blank('/sda1/p/a/c/o', headers={'Content-Type': 'application/x-test', 'X-Auth-Token': '2340lsdfhhjl02lxfjj', 'X-Storage-Token': '2340lsdfhhjl02lxfjj'}) reader_mock = mock.Mock(keep_cache=False) with mock.patch('swift.obj.diskfile.BaseDiskFile.reader', reader_mock): resp = req.get_response(obj_controller) reader_mock.assert_called_with(keep_cache=False) self.assertEqual(resp.status_int, 200) ",,144,0
openstack%2Fneutron~887761,openstack/neutron,stable/zed,Ie09d9d3e5efa8a57ad11655c2eb31d2604bab326,Set result when lswitch port exist,MERGED,2023-07-06 07:49:13.000000000,2023-07-07 16:43:22.000000000,2023-07-07 16:41:55.000000000,"[{'_account_id': 1131}, {'_account_id': 21798}, {'_account_id': 22348}]","[{'number': 1, 'created': '2023-07-06 07:49:13.000000000', 'files': ['neutron/tests/unit/plugins/ml2/drivers/ovn/mech_driver/ovsdb/test_commands.py', 'neutron/tests/functional/plugins/ml2/drivers/ovn/mech_driver/ovsdb/test_ovn_client.py', 'neutron/plugins/ml2/drivers/ovn/mech_driver/ovsdb/commands.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/bfdc1bf25a98c3601a8aeb1f80ccf7c74739ce06', 'message': 'Set result when lswitch port exist\n\nA TypeError was thrown during a synchronization\ncommand(neutron-ovn-db-sync-util) execution. From the code[1][2], it\ncan be seen. The result of the AddLSwitchPortCommand command will be\npassed as a parameter to the UpdateLSwitchPortQosOptionsCommand. But\nif the logical switch port exists, the result will not be set. Therefore,\nwhen the UpdateLSwitchPortQosOptionsCommand is executed, the port_id\nwill not be obtained, thereby throwing an exception TypeError.\nThis patch sets the result when the logical switch port exists.\n\n[1] https://opendev.org/openstack/neutron/src/commit/b71f7ceb3e97e021cb9aeda757a7ffdeeff80e8e/neutron/plugins/ml2/drivers/ovn/mech_driver/ovsdb/ovn_client.py#L488\n[2] https://opendev.org/openstack/neutron/src/commit/b71f7ceb3e97e021cb9aeda757a7ffdeeff80e8e/neutron/plugins/ml2/drivers/ovn/mech_driver/ovsdb/ovn_client.py#L505\n\nCloses-Bug: #2025202\n\nChange-Id: Ie09d9d3e5efa8a57ad11655c2eb31d2604bab326\n(cherry picked from commit 65bbbcee76fc2a7501d4c28e3cc716f1f9a6f763)\n'}]",0,887761,bfdc1bf25a98c3601a8aeb1f80ccf7c74739ce06,9,3,1,16688,,,0,"Set result when lswitch port exist

A TypeError was thrown during a synchronization
command(neutron-ovn-db-sync-util) execution. From the code[1][2], it
can be seen. The result of the AddLSwitchPortCommand command will be
passed as a parameter to the UpdateLSwitchPortQosOptionsCommand. But
if the logical switch port exists, the result will not be set. Therefore,
when the UpdateLSwitchPortQosOptionsCommand is executed, the port_id
will not be obtained, thereby throwing an exception TypeError.
This patch sets the result when the logical switch port exists.

[1] https://opendev.org/openstack/neutron/src/commit/b71f7ceb3e97e021cb9aeda757a7ffdeeff80e8e/neutron/plugins/ml2/drivers/ovn/mech_driver/ovsdb/ovn_client.py#L488
[2] https://opendev.org/openstack/neutron/src/commit/b71f7ceb3e97e021cb9aeda757a7ffdeeff80e8e/neutron/plugins/ml2/drivers/ovn/mech_driver/ovsdb/ovn_client.py#L505

Closes-Bug: #2025202

Change-Id: Ie09d9d3e5efa8a57ad11655c2eb31d2604bab326
(cherry picked from commit 65bbbcee76fc2a7501d4c28e3cc716f1f9a6f763)
",git fetch https://review.opendev.org/openstack/neutron refs/changes/61/887761/1 && git format-patch -1 --stdout FETCH_HEAD,"['neutron/tests/unit/plugins/ml2/drivers/ovn/mech_driver/ovsdb/test_commands.py', 'neutron/tests/functional/plugins/ml2/drivers/ovn/mech_driver/ovsdb/test_ovn_client.py', 'neutron/plugins/ml2/drivers/ovn/mech_driver/ovsdb/commands.py']",3,bfdc1bf25a98c3601a8aeb1f80ccf7c74739ce06,bug/2025202, self.result = port.uuid,,20,1
openstack%2Fneutron~887764,openstack/neutron,stable/xena,Ie09d9d3e5efa8a57ad11655c2eb31d2604bab326,Set result when lswitch port exist,MERGED,2023-07-06 07:49:37.000000000,2023-07-07 16:43:11.000000000,2023-07-07 16:42:03.000000000,"[{'_account_id': 1131}, {'_account_id': 21798}, {'_account_id': 22348}]","[{'number': 1, 'created': '2023-07-06 07:49:37.000000000', 'files': ['neutron/tests/unit/plugins/ml2/drivers/ovn/mech_driver/ovsdb/test_commands.py', 'neutron/tests/functional/plugins/ml2/drivers/ovn/mech_driver/ovsdb/test_ovn_client.py', 'neutron/plugins/ml2/drivers/ovn/mech_driver/ovsdb/commands.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/ecd968a1b5c29f5ef5bbe378e925b3b3e8e7442d', 'message': 'Set result when lswitch port exist\n\nA TypeError was thrown during a synchronization\ncommand(neutron-ovn-db-sync-util) execution. From the code[1][2], it\ncan be seen. The result of the AddLSwitchPortCommand command will be\npassed as a parameter to the UpdateLSwitchPortQosOptionsCommand. But\nif the logical switch port exists, the result will not be set. Therefore,\nwhen the UpdateLSwitchPortQosOptionsCommand is executed, the port_id\nwill not be obtained, thereby throwing an exception TypeError.\nThis patch sets the result when the logical switch port exists.\n\n[1] https://opendev.org/openstack/neutron/src/commit/b71f7ceb3e97e021cb9aeda757a7ffdeeff80e8e/neutron/plugins/ml2/drivers/ovn/mech_driver/ovsdb/ovn_client.py#L488\n[2] https://opendev.org/openstack/neutron/src/commit/b71f7ceb3e97e021cb9aeda757a7ffdeeff80e8e/neutron/plugins/ml2/drivers/ovn/mech_driver/ovsdb/ovn_client.py#L505\n\nCloses-Bug: #2025202\n\nChange-Id: Ie09d9d3e5efa8a57ad11655c2eb31d2604bab326\n(cherry picked from commit 65bbbcee76fc2a7501d4c28e3cc716f1f9a6f763)\n'}]",0,887764,ecd968a1b5c29f5ef5bbe378e925b3b3e8e7442d,9,3,1,16688,,,0,"Set result when lswitch port exist

A TypeError was thrown during a synchronization
command(neutron-ovn-db-sync-util) execution. From the code[1][2], it
can be seen. The result of the AddLSwitchPortCommand command will be
passed as a parameter to the UpdateLSwitchPortQosOptionsCommand. But
if the logical switch port exists, the result will not be set. Therefore,
when the UpdateLSwitchPortQosOptionsCommand is executed, the port_id
will not be obtained, thereby throwing an exception TypeError.
This patch sets the result when the logical switch port exists.

[1] https://opendev.org/openstack/neutron/src/commit/b71f7ceb3e97e021cb9aeda757a7ffdeeff80e8e/neutron/plugins/ml2/drivers/ovn/mech_driver/ovsdb/ovn_client.py#L488
[2] https://opendev.org/openstack/neutron/src/commit/b71f7ceb3e97e021cb9aeda757a7ffdeeff80e8e/neutron/plugins/ml2/drivers/ovn/mech_driver/ovsdb/ovn_client.py#L505

Closes-Bug: #2025202

Change-Id: Ie09d9d3e5efa8a57ad11655c2eb31d2604bab326
(cherry picked from commit 65bbbcee76fc2a7501d4c28e3cc716f1f9a6f763)
",git fetch https://review.opendev.org/openstack/neutron refs/changes/64/887764/1 && git format-patch -1 --stdout FETCH_HEAD,"['neutron/tests/unit/plugins/ml2/drivers/ovn/mech_driver/ovsdb/test_commands.py', 'neutron/tests/functional/plugins/ml2/drivers/ovn/mech_driver/ovsdb/test_ovn_client.py', 'neutron/plugins/ml2/drivers/ovn/mech_driver/ovsdb/commands.py']",3,ecd968a1b5c29f5ef5bbe378e925b3b3e8e7442d,bug/2025202, self.result = port.uuid,,20,1
openstack%2Fneutron~887762,openstack/neutron,stable/yoga,Ie09d9d3e5efa8a57ad11655c2eb31d2604bab326,Set result when lswitch port exist,MERGED,2023-07-06 07:49:24.000000000,2023-07-07 16:43:06.000000000,2023-07-07 16:41:59.000000000,"[{'_account_id': 1131}, {'_account_id': 21798}, {'_account_id': 22348}]","[{'number': 1, 'created': '2023-07-06 07:49:24.000000000', 'files': ['neutron/tests/unit/plugins/ml2/drivers/ovn/mech_driver/ovsdb/test_commands.py', 'neutron/tests/functional/plugins/ml2/drivers/ovn/mech_driver/ovsdb/test_ovn_client.py', 'neutron/plugins/ml2/drivers/ovn/mech_driver/ovsdb/commands.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/6af9f70e0b07715c6908a23e7bdd8b2549fac397', 'message': 'Set result when lswitch port exist\n\nA TypeError was thrown during a synchronization\ncommand(neutron-ovn-db-sync-util) execution. From the code[1][2], it\ncan be seen. The result of the AddLSwitchPortCommand command will be\npassed as a parameter to the UpdateLSwitchPortQosOptionsCommand. But\nif the logical switch port exists, the result will not be set. Therefore,\nwhen the UpdateLSwitchPortQosOptionsCommand is executed, the port_id\nwill not be obtained, thereby throwing an exception TypeError.\nThis patch sets the result when the logical switch port exists.\n\n[1] https://opendev.org/openstack/neutron/src/commit/b71f7ceb3e97e021cb9aeda757a7ffdeeff80e8e/neutron/plugins/ml2/drivers/ovn/mech_driver/ovsdb/ovn_client.py#L488\n[2] https://opendev.org/openstack/neutron/src/commit/b71f7ceb3e97e021cb9aeda757a7ffdeeff80e8e/neutron/plugins/ml2/drivers/ovn/mech_driver/ovsdb/ovn_client.py#L505\n\nCloses-Bug: #2025202\n\nChange-Id: Ie09d9d3e5efa8a57ad11655c2eb31d2604bab326\n(cherry picked from commit 65bbbcee76fc2a7501d4c28e3cc716f1f9a6f763)\n'}]",0,887762,6af9f70e0b07715c6908a23e7bdd8b2549fac397,9,3,1,16688,,,0,"Set result when lswitch port exist

A TypeError was thrown during a synchronization
command(neutron-ovn-db-sync-util) execution. From the code[1][2], it
can be seen. The result of the AddLSwitchPortCommand command will be
passed as a parameter to the UpdateLSwitchPortQosOptionsCommand. But
if the logical switch port exists, the result will not be set. Therefore,
when the UpdateLSwitchPortQosOptionsCommand is executed, the port_id
will not be obtained, thereby throwing an exception TypeError.
This patch sets the result when the logical switch port exists.

[1] https://opendev.org/openstack/neutron/src/commit/b71f7ceb3e97e021cb9aeda757a7ffdeeff80e8e/neutron/plugins/ml2/drivers/ovn/mech_driver/ovsdb/ovn_client.py#L488
[2] https://opendev.org/openstack/neutron/src/commit/b71f7ceb3e97e021cb9aeda757a7ffdeeff80e8e/neutron/plugins/ml2/drivers/ovn/mech_driver/ovsdb/ovn_client.py#L505

Closes-Bug: #2025202

Change-Id: Ie09d9d3e5efa8a57ad11655c2eb31d2604bab326
(cherry picked from commit 65bbbcee76fc2a7501d4c28e3cc716f1f9a6f763)
",git fetch https://review.opendev.org/openstack/neutron refs/changes/62/887762/1 && git format-patch -1 --stdout FETCH_HEAD,"['neutron/tests/unit/plugins/ml2/drivers/ovn/mech_driver/ovsdb/test_commands.py', 'neutron/tests/functional/plugins/ml2/drivers/ovn/mech_driver/ovsdb/test_ovn_client.py', 'neutron/plugins/ml2/drivers/ovn/mech_driver/ovsdb/commands.py']",3,6af9f70e0b07715c6908a23e7bdd8b2549fac397,bug/2025202, self.result = port.uuid,,20,1
openstack%2Fneutron~887760,openstack/neutron,stable/2023.1,Ie09d9d3e5efa8a57ad11655c2eb31d2604bab326,Set result when lswitch port exist,MERGED,2023-07-06 07:48:59.000000000,2023-07-07 16:43:04.000000000,2023-07-07 16:41:52.000000000,"[{'_account_id': 1131}, {'_account_id': 21798}, {'_account_id': 22348}]","[{'number': 1, 'created': '2023-07-06 07:48:59.000000000', 'files': ['neutron/tests/unit/plugins/ml2/drivers/ovn/mech_driver/ovsdb/test_commands.py', 'neutron/tests/functional/plugins/ml2/drivers/ovn/mech_driver/ovsdb/test_ovn_client.py', 'neutron/plugins/ml2/drivers/ovn/mech_driver/ovsdb/commands.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/d9eb4ff47ca7b4f8b21d10fb5afc80dbe13d8424', 'message': 'Set result when lswitch port exist\n\nA TypeError was thrown during a synchronization\ncommand(neutron-ovn-db-sync-util) execution. From the code[1][2], it\ncan be seen. The result of the AddLSwitchPortCommand command will be\npassed as a parameter to the UpdateLSwitchPortQosOptionsCommand. But\nif the logical switch port exists, the result will not be set. Therefore,\nwhen the UpdateLSwitchPortQosOptionsCommand is executed, the port_id\nwill not be obtained, thereby throwing an exception TypeError.\nThis patch sets the result when the logical switch port exists.\n\n[1] https://opendev.org/openstack/neutron/src/commit/b71f7ceb3e97e021cb9aeda757a7ffdeeff80e8e/neutron/plugins/ml2/drivers/ovn/mech_driver/ovsdb/ovn_client.py#L488\n[2] https://opendev.org/openstack/neutron/src/commit/b71f7ceb3e97e021cb9aeda757a7ffdeeff80e8e/neutron/plugins/ml2/drivers/ovn/mech_driver/ovsdb/ovn_client.py#L505\n\nCloses-Bug: #2025202\n\nChange-Id: Ie09d9d3e5efa8a57ad11655c2eb31d2604bab326\n(cherry picked from commit 65bbbcee76fc2a7501d4c28e3cc716f1f9a6f763)\n'}]",1,887760,d9eb4ff47ca7b4f8b21d10fb5afc80dbe13d8424,9,3,1,16688,,,0,"Set result when lswitch port exist

A TypeError was thrown during a synchronization
command(neutron-ovn-db-sync-util) execution. From the code[1][2], it
can be seen. The result of the AddLSwitchPortCommand command will be
passed as a parameter to the UpdateLSwitchPortQosOptionsCommand. But
if the logical switch port exists, the result will not be set. Therefore,
when the UpdateLSwitchPortQosOptionsCommand is executed, the port_id
will not be obtained, thereby throwing an exception TypeError.
This patch sets the result when the logical switch port exists.

[1] https://opendev.org/openstack/neutron/src/commit/b71f7ceb3e97e021cb9aeda757a7ffdeeff80e8e/neutron/plugins/ml2/drivers/ovn/mech_driver/ovsdb/ovn_client.py#L488
[2] https://opendev.org/openstack/neutron/src/commit/b71f7ceb3e97e021cb9aeda757a7ffdeeff80e8e/neutron/plugins/ml2/drivers/ovn/mech_driver/ovsdb/ovn_client.py#L505

Closes-Bug: #2025202

Change-Id: Ie09d9d3e5efa8a57ad11655c2eb31d2604bab326
(cherry picked from commit 65bbbcee76fc2a7501d4c28e3cc716f1f9a6f763)
",git fetch https://review.opendev.org/openstack/neutron refs/changes/60/887760/1 && git format-patch -1 --stdout FETCH_HEAD,"['neutron/tests/unit/plugins/ml2/drivers/ovn/mech_driver/ovsdb/test_commands.py', 'neutron/tests/functional/plugins/ml2/drivers/ovn/mech_driver/ovsdb/test_ovn_client.py', 'neutron/plugins/ml2/drivers/ovn/mech_driver/ovsdb/commands.py']",3,d9eb4ff47ca7b4f8b21d10fb5afc80dbe13d8424,bug/2025202, self.result = port.uuid,,20,1
openstack%2Fneutron~887633,openstack/neutron,stable/2023.1,Ia3741abe5fa0c8ff65cf36d1ec31c089a1759f05,[FT] Move ``BaseOVSTestCase`` class to concurrency 1 executor,MERGED,2023-07-04 15:57:39.000000000,2023-07-07 16:33:46.000000000,2023-07-07 16:31:37.000000000,"[{'_account_id': 8313}, {'_account_id': 21798}, {'_account_id': 22348}]","[{'number': 1, 'created': '2023-07-04 15:57:39.000000000', 'files': ['tox.ini'], 'web_link': 'https://opendev.org/openstack/neutron/commit/88d00e698f4c631c1db7eb7b32297e1c92e5524f', 'message': '[FT] Move ``BaseOVSTestCase`` class to concurrency 1 executor\n\nMove the ``BaseOVSTestCase`` class tests to the stestr executor with\nconcurrency=1. That will prevent that the minimum bandwidth tests\ninterfere among them.\n\nConflicts:\n    tox.ini\n\nCloses-Bug: #2025740\nChange-Id: Ia3741abe5fa0c8ff65cf36d1ec31c089a1759f05\n(cherry picked from commit 26a2266cf4e2395b0146902de2eb0a6966a037ec)\n'}]",1,887633,88d00e698f4c631c1db7eb7b32297e1c92e5524f,9,3,1,16688,,,0,"[FT] Move ``BaseOVSTestCase`` class to concurrency 1 executor

Move the ``BaseOVSTestCase`` class tests to the stestr executor with
concurrency=1. That will prevent that the minimum bandwidth tests
interfere among them.

Conflicts:
    tox.ini

Closes-Bug: #2025740
Change-Id: Ia3741abe5fa0c8ff65cf36d1ec31c089a1759f05
(cherry picked from commit 26a2266cf4e2395b0146902de2eb0a6966a037ec)
",git fetch https://review.opendev.org/openstack/neutron refs/changes/33/887633/1 && git format-patch -1 --stdout FETCH_HEAD,['tox.ini'],1,88d00e698f4c631c1db7eb7b32297e1c92e5524f,bug/2025740, stestr run --exclude-regex (.*MySQL\.|.*PostgreSQL\.|.*test_get_all_devices|.*BaseOVSTestCase\.) {posargs} stestr run --combine --concurrency 1 (.*MySQL\.|.*PostgreSQL\.|.*test_get_all_devices|.*BaseOVSTestCase\.) {posargs}, stestr run --exclude-regex (.*MySQL\.|.*PostgreSQL\.|.*test_get_all_devices) {posargs} stestr run --combine --concurrency 1 (.*MySQL\.|.*PostgreSQL\.|.*test_get_all_devices) {posargs},2,2
openstack%2Fneutron~887582,openstack/neutron,stable/xena,I1fb6a9ff94376ab5f695d311b6fa8034d73cf556,[OVN] Expose chassis hosting information in LSP,MERGED,2023-07-04 08:42:03.000000000,2023-07-07 16:32:54.000000000,2023-07-07 16:31:33.000000000,"[{'_account_id': 16688}, {'_account_id': 21798}, {'_account_id': 22348}, {'_account_id': 23567}]","[{'number': 1, 'created': '2023-07-04 08:42:03.000000000', 'files': ['neutron/plugins/ml2/drivers/ovn/mech_driver/ovsdb/ovn_client.py', 'neutron/tests/unit/plugins/ml2/drivers/ovn/mech_driver/test_mech_driver.py', 'neutron/common/ovn/constants.py', 'neutron/plugins/ml2/drivers/ovn/mech_driver/mech_driver.py', 'neutron/tests/unit/plugins/ml2/drivers/ovn/mech_driver/ovsdb/test_ovn_client.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/819339472ae9b6d20a299ed4e2e61856def70654', 'message': '[OVN] Expose chassis hosting information in LSP\n\nExpose chassis hosting information via LSP\'s external_ids. This allows\nfor projects such as ovn-bgp-agent NB driver that only connects to the\nNB database to consume such information (avoiding more connections to\nthe SB database).\n\nAlso stop populating the ""requested-chassis"" options for ports of the\ntype virtual because it\'s ignored by OVN.\n\nSee LP #2020058 for more information.\n\nConflicts:\n  neutron/common/ovn/constants.py\n  neutron/plugins/ml2/drivers/ovn/mech_driver/ovsdb/ovn_client.py\n  neutron/tests/unit/plugins/ml2/drivers/ovn/mech_driver/ovsdb/test_ovn_client.py\n\nCloses-Bug: #2020058\nChange-Id: I1fb6a9ff94376ab5f695d311b6fa8034d73cf556\nSigned-off-by: Lucas Alvares Gomes <lucasagomes@gmail.com>\n(cherry picked from commit 28926957d691c8b0897c71fee59a888783d15974)\n'}]",1,887582,819339472ae9b6d20a299ed4e2e61856def70654,10,4,1,6773,,,0,"[OVN] Expose chassis hosting information in LSP

Expose chassis hosting information via LSP's external_ids. This allows
for projects such as ovn-bgp-agent NB driver that only connects to the
NB database to consume such information (avoiding more connections to
the SB database).

Also stop populating the ""requested-chassis"" options for ports of the
type virtual because it's ignored by OVN.

See LP #2020058 for more information.

Conflicts:
  neutron/common/ovn/constants.py
  neutron/plugins/ml2/drivers/ovn/mech_driver/ovsdb/ovn_client.py
  neutron/tests/unit/plugins/ml2/drivers/ovn/mech_driver/ovsdb/test_ovn_client.py

Closes-Bug: #2020058
Change-Id: I1fb6a9ff94376ab5f695d311b6fa8034d73cf556
Signed-off-by: Lucas Alvares Gomes <lucasagomes@gmail.com>
(cherry picked from commit 28926957d691c8b0897c71fee59a888783d15974)
",git fetch https://review.opendev.org/openstack/neutron refs/changes/82/887582/1 && git format-patch -1 --stdout FETCH_HEAD,"['neutron/plugins/ml2/drivers/ovn/mech_driver/ovsdb/ovn_client.py', 'neutron/tests/unit/plugins/ml2/drivers/ovn/mech_driver/test_mech_driver.py', 'neutron/common/ovn/constants.py', 'neutron/plugins/ml2/drivers/ovn/mech_driver/mech_driver.py', 'neutron/tests/unit/plugins/ml2/drivers/ovn/mech_driver/ovsdb/test_ovn_client.py']",5,819339472ae9b6d20a299ed4e2e61856def70654,,"class TestOVNClient(TestOVNClientBase): def setUp(self): super(TestOVNClient, self).setUp() self.get_plugin = mock.patch( 'neutron_lib.plugins.directory.get_plugin').start() def test_update_lsp_host_info_up(self): context = mock.MagicMock() host_id = 'fake-binding-host-id' port_id = 'fake-port-id' db_port = mock.Mock( id=port_id, port_bindings=[mock.Mock(host=host_id)]) self.ovn_client.update_lsp_host_info(context, db_port) self.nb_idl.db_set.assert_called_once_with( 'Logical_Switch_Port', port_id, ('external_ids', {constants.OVN_HOST_ID_EXT_ID_KEY: host_id})) def test_update_lsp_host_info_down(self): context = mock.MagicMock() port_id = 'fake-port-id' db_port = mock.Mock(id=port_id) self.ovn_client.update_lsp_host_info(context, db_port, up=False) self.nb_idl.db_remove.assert_called_once_with( 'Logical_Switch_Port', port_id, 'external_ids', constants.OVN_HOST_ID_EXT_ID_KEY, if_exists=True) ",,81,3
openstack%2Fneutron~887581,openstack/neutron,stable/yoga,I1fb6a9ff94376ab5f695d311b6fa8034d73cf556,[OVN] Expose chassis hosting information in LSP,MERGED,2023-07-04 08:41:55.000000000,2023-07-07 16:32:49.000000000,2023-07-07 16:31:30.000000000,"[{'_account_id': 16688}, {'_account_id': 21798}, {'_account_id': 22348}, {'_account_id': 23567}]","[{'number': 1, 'created': '2023-07-04 08:41:55.000000000', 'files': ['neutron/plugins/ml2/drivers/ovn/mech_driver/ovsdb/ovn_client.py', 'neutron/tests/unit/plugins/ml2/drivers/ovn/mech_driver/test_mech_driver.py', 'neutron/common/ovn/constants.py', 'neutron/plugins/ml2/drivers/ovn/mech_driver/mech_driver.py', 'neutron/tests/unit/plugins/ml2/drivers/ovn/mech_driver/ovsdb/test_ovn_client.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/3e6b2b77b2aa84260864c53bf7bcdd7611a848ef', 'message': '[OVN] Expose chassis hosting information in LSP\n\nExpose chassis hosting information via LSP\'s external_ids. This allows\nfor projects such as ovn-bgp-agent NB driver that only connects to the\nNB database to consume such information (avoiding more connections to\nthe SB database).\n\nAlso stop populating the ""requested-chassis"" options for ports of the\ntype virtual because it\'s ignored by OVN.\n\nSee LP #2020058 for more information.\n\nConflicts:\n  neutron/plugins/ml2/drivers/ovn/mech_driver/ovsdb/ovn_client.py\n\nCloses-Bug: #2020058\nChange-Id: I1fb6a9ff94376ab5f695d311b6fa8034d73cf556\nSigned-off-by: Lucas Alvares Gomes <lucasagomes@gmail.com>\n(cherry picked from commit 28926957d691c8b0897c71fee59a888783d15974)\n'}]",0,887581,3e6b2b77b2aa84260864c53bf7bcdd7611a848ef,10,4,1,6773,,,0,"[OVN] Expose chassis hosting information in LSP

Expose chassis hosting information via LSP's external_ids. This allows
for projects such as ovn-bgp-agent NB driver that only connects to the
NB database to consume such information (avoiding more connections to
the SB database).

Also stop populating the ""requested-chassis"" options for ports of the
type virtual because it's ignored by OVN.

See LP #2020058 for more information.

Conflicts:
  neutron/plugins/ml2/drivers/ovn/mech_driver/ovsdb/ovn_client.py

Closes-Bug: #2020058
Change-Id: I1fb6a9ff94376ab5f695d311b6fa8034d73cf556
Signed-off-by: Lucas Alvares Gomes <lucasagomes@gmail.com>
(cherry picked from commit 28926957d691c8b0897c71fee59a888783d15974)
",git fetch https://review.opendev.org/openstack/neutron refs/changes/81/887581/1 && git format-patch -1 --stdout FETCH_HEAD,"['neutron/plugins/ml2/drivers/ovn/mech_driver/ovsdb/ovn_client.py', 'neutron/tests/unit/plugins/ml2/drivers/ovn/mech_driver/test_mech_driver.py', 'neutron/common/ovn/constants.py', 'neutron/plugins/ml2/drivers/ovn/mech_driver/mech_driver.py', 'neutron/tests/unit/plugins/ml2/drivers/ovn/mech_driver/ovsdb/test_ovn_client.py']",5,3e6b2b77b2aa84260864c53bf7bcdd7611a848ef,," def test_update_lsp_host_info_up(self): context = mock.MagicMock() host_id = 'fake-binding-host-id' port_id = 'fake-port-id' db_port = mock.Mock( id=port_id, port_bindings=[mock.Mock(host=host_id)]) self.ovn_client.update_lsp_host_info(context, db_port) self.nb_idl.db_set.assert_called_once_with( 'Logical_Switch_Port', port_id, ('external_ids', {constants.OVN_HOST_ID_EXT_ID_KEY: host_id})) def test_update_lsp_host_info_down(self): context = mock.MagicMock() port_id = 'fake-port-id' db_port = mock.Mock(id=port_id) self.ovn_client.update_lsp_host_info(context, db_port, up=False) self.nb_idl.db_remove.assert_called_once_with( 'Logical_Switch_Port', port_id, 'external_ids', constants.OVN_HOST_ID_EXT_ID_KEY, if_exists=True) ",,76,3
openstack%2Fneutron~887580,openstack/neutron,stable/zed,I1fb6a9ff94376ab5f695d311b6fa8034d73cf556,[OVN] Expose chassis hosting information in LSP,MERGED,2023-07-04 08:41:45.000000000,2023-07-07 16:32:46.000000000,2023-07-07 16:31:26.000000000,"[{'_account_id': 16688}, {'_account_id': 21798}, {'_account_id': 22348}, {'_account_id': 23567}]","[{'number': 1, 'created': '2023-07-04 08:41:45.000000000', 'files': ['neutron/plugins/ml2/drivers/ovn/mech_driver/ovsdb/ovn_client.py', 'neutron/tests/unit/plugins/ml2/drivers/ovn/mech_driver/test_mech_driver.py', 'neutron/common/ovn/constants.py', 'neutron/plugins/ml2/drivers/ovn/mech_driver/mech_driver.py', 'neutron/tests/unit/plugins/ml2/drivers/ovn/mech_driver/ovsdb/test_ovn_client.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/984193b0dccd6cd080d60473de51f04bad704285', 'message': '[OVN] Expose chassis hosting information in LSP\n\nExpose chassis hosting information via LSP\'s external_ids. This allows\nfor projects such as ovn-bgp-agent NB driver that only connects to the\nNB database to consume such information (avoiding more connections to\nthe SB database).\n\nAlso stop populating the ""requested-chassis"" options for ports of the\ntype virtual because it\'s ignored by OVN.\n\nSee LP #2020058 for more information.\n\nConflicts:\n  neutron/plugins/ml2/drivers/ovn/mech_driver/ovsdb/ovn_client.py\n\nCloses-Bug: #2020058\nChange-Id: I1fb6a9ff94376ab5f695d311b6fa8034d73cf556\nSigned-off-by: Lucas Alvares Gomes <lucasagomes@gmail.com>\n(cherry picked from commit 28926957d691c8b0897c71fee59a888783d15974)\n'}]",0,887580,984193b0dccd6cd080d60473de51f04bad704285,10,4,1,6773,,,0,"[OVN] Expose chassis hosting information in LSP

Expose chassis hosting information via LSP's external_ids. This allows
for projects such as ovn-bgp-agent NB driver that only connects to the
NB database to consume such information (avoiding more connections to
the SB database).

Also stop populating the ""requested-chassis"" options for ports of the
type virtual because it's ignored by OVN.

See LP #2020058 for more information.

Conflicts:
  neutron/plugins/ml2/drivers/ovn/mech_driver/ovsdb/ovn_client.py

Closes-Bug: #2020058
Change-Id: I1fb6a9ff94376ab5f695d311b6fa8034d73cf556
Signed-off-by: Lucas Alvares Gomes <lucasagomes@gmail.com>
(cherry picked from commit 28926957d691c8b0897c71fee59a888783d15974)
",git fetch https://review.opendev.org/openstack/neutron refs/changes/80/887580/1 && git format-patch -1 --stdout FETCH_HEAD,"['neutron/plugins/ml2/drivers/ovn/mech_driver/ovsdb/ovn_client.py', 'neutron/tests/unit/plugins/ml2/drivers/ovn/mech_driver/test_mech_driver.py', 'neutron/common/ovn/constants.py', 'neutron/plugins/ml2/drivers/ovn/mech_driver/mech_driver.py', 'neutron/tests/unit/plugins/ml2/drivers/ovn/mech_driver/ovsdb/test_ovn_client.py']",5,984193b0dccd6cd080d60473de51f04bad704285,," def test_update_lsp_host_info_up(self): context = mock.MagicMock() host_id = 'fake-binding-host-id' port_id = 'fake-port-id' db_port = mock.Mock( id=port_id, port_bindings=[mock.Mock(host=host_id)]) self.ovn_client.update_lsp_host_info(context, db_port) self.nb_idl.db_set.assert_called_once_with( 'Logical_Switch_Port', port_id, ('external_ids', {constants.OVN_HOST_ID_EXT_ID_KEY: host_id})) def test_update_lsp_host_info_down(self): context = mock.MagicMock() port_id = 'fake-port-id' db_port = mock.Mock(id=port_id) self.ovn_client.update_lsp_host_info(context, db_port, up=False) self.nb_idl.db_remove.assert_called_once_with( 'Logical_Switch_Port', port_id, 'external_ids', constants.OVN_HOST_ID_EXT_ID_KEY, if_exists=True) ",,76,3
openstack%2Fneutron~887579,openstack/neutron,stable/2023.1,I1fb6a9ff94376ab5f695d311b6fa8034d73cf556,[OVN] Expose chassis hosting information in LSP,MERGED,2023-07-04 08:41:30.000000000,2023-07-07 16:32:44.000000000,2023-07-07 16:31:22.000000000,"[{'_account_id': 16688}, {'_account_id': 21798}, {'_account_id': 22348}, {'_account_id': 23567}]","[{'number': 1, 'created': '2023-07-04 08:41:30.000000000', 'files': ['neutron/plugins/ml2/drivers/ovn/mech_driver/ovsdb/ovn_client.py', 'neutron/tests/unit/plugins/ml2/drivers/ovn/mech_driver/test_mech_driver.py', 'neutron/common/ovn/constants.py', 'neutron/plugins/ml2/drivers/ovn/mech_driver/mech_driver.py', 'neutron/tests/unit/plugins/ml2/drivers/ovn/mech_driver/ovsdb/test_ovn_client.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/82e94208bc45f9ef85c042ad85f6ff51da2f2548', 'message': '[OVN] Expose chassis hosting information in LSP\n\nExpose chassis hosting information via LSP\'s external_ids. This allows\nfor projects such as ovn-bgp-agent NB driver that only connects to the\nNB database to consume such information (avoiding more connections to\nthe SB database).\n\nAlso stop populating the ""requested-chassis"" options for ports of the\ntype virtual because it\'s ignored by OVN.\n\nSee LP #2020058 for more information.\n\nConflicts:\n  neutron/plugins/ml2/drivers/ovn/mech_driver/ovsdb/ovn_client.py\n\nCloses-Bug: #2020058\nChange-Id: I1fb6a9ff94376ab5f695d311b6fa8034d73cf556\nSigned-off-by: Lucas Alvares Gomes <lucasagomes@gmail.com>\n(cherry picked from commit 28926957d691c8b0897c71fee59a888783d15974)\n'}]",2,887579,82e94208bc45f9ef85c042ad85f6ff51da2f2548,13,4,1,6773,,,0,"[OVN] Expose chassis hosting information in LSP

Expose chassis hosting information via LSP's external_ids. This allows
for projects such as ovn-bgp-agent NB driver that only connects to the
NB database to consume such information (avoiding more connections to
the SB database).

Also stop populating the ""requested-chassis"" options for ports of the
type virtual because it's ignored by OVN.

See LP #2020058 for more information.

Conflicts:
  neutron/plugins/ml2/drivers/ovn/mech_driver/ovsdb/ovn_client.py

Closes-Bug: #2020058
Change-Id: I1fb6a9ff94376ab5f695d311b6fa8034d73cf556
Signed-off-by: Lucas Alvares Gomes <lucasagomes@gmail.com>
(cherry picked from commit 28926957d691c8b0897c71fee59a888783d15974)
",git fetch https://review.opendev.org/openstack/neutron refs/changes/79/887579/1 && git format-patch -1 --stdout FETCH_HEAD,"['neutron/plugins/ml2/drivers/ovn/mech_driver/ovsdb/ovn_client.py', 'neutron/tests/unit/plugins/ml2/drivers/ovn/mech_driver/test_mech_driver.py', 'neutron/common/ovn/constants.py', 'neutron/plugins/ml2/drivers/ovn/mech_driver/mech_driver.py', 'neutron/tests/unit/plugins/ml2/drivers/ovn/mech_driver/ovsdb/test_ovn_client.py']",5,82e94208bc45f9ef85c042ad85f6ff51da2f2548,," def test_update_lsp_host_info_up(self): context = mock.MagicMock() host_id = 'fake-binding-host-id' port_id = 'fake-port-id' db_port = mock.Mock( id=port_id, port_bindings=[mock.Mock(host=host_id)]) self.ovn_client.update_lsp_host_info(context, db_port) self.nb_idl.db_set.assert_called_once_with( 'Logical_Switch_Port', port_id, ('external_ids', {constants.OVN_HOST_ID_EXT_ID_KEY: host_id})) def test_update_lsp_host_info_down(self): context = mock.MagicMock() port_id = 'fake-port-id' db_port = mock.Mock(id=port_id) self.ovn_client.update_lsp_host_info(context, db_port, up=False) self.nb_idl.db_remove.assert_called_once_with( 'Logical_Switch_Port', port_id, 'external_ids', constants.OVN_HOST_ID_EXT_ID_KEY, if_exists=True) ",,76,3
openstack%2Ftripleo-common~887748,openstack/tripleo-common,stable/wallaby,Id384780e8394b40a91761e7fbbc0f8e44263d681,Disable pam_loguinuid for crond,MERGED,2023-07-06 05:30:16.000000000,2023-07-07 16:27:01.000000000,2023-07-07 16:26:04.000000000,"[{'_account_id': 7144}, {'_account_id': 7414}, {'_account_id': 9816}, {'_account_id': 22348}, {'_account_id': 30073}]","[{'number': 1, 'created': '2023-07-06 05:30:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-common/commit/7b58d68b482b0af90f31ff1d69fa36e4b0c613bb', 'message': 'Disable pan_loguinuid for crond\n\nCurrently we run some crond processes with -n option but the cron jobs\nfails because of pam errors. According to man page we have to remove\npam_loginuid.so in case we run crond in the foreground.\n\n~~~\n       -n     Tells the daemon to run in the foreground.  This can be\n              useful when starting it out of init. With this option is\n              needed to change pam setting.  /etc/pam.d/crond must not\n              enable pam_loginuid.so module.\n~~~\n\nThis was not a problem in CentOS8/RHEL8 likely because old podman added\nAUDIT_CONTROL by default but it is no longer enabled in the newer\npodman version we have in CentOS9/RHEL9.\n\nResolves: rhbz#2219765\nChange-Id: Id384780e8394b40a91761e7fbbc0f8e44263d681\n'}, {'number': 2, 'created': '2023-07-06 05:35:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-common/commit/d64c182c1598b8a4171102e2ea374ce123ca1b38', 'message': 'Disable pan_loguinuid for crond\n\nCurrently we run some crond processes with -n option but the cron jobs\nfails because of pam errors. According to man page we have to remove\npam_loginuid.so in case we run crond in the foreground.\n\n~~~\n       -n     Tells the daemon to run in the foreground.  This can be\n              useful when starting it out of init. With this option is\n              needed to change pam setting.  /etc/pam.d/crond must not\n              enable pam_loginuid.so module.\n~~~\n\nResolves: rhbz#2219765\nChange-Id: Id384780e8394b40a91761e7fbbc0f8e44263d681\n'}, {'number': 3, 'created': '2023-07-06 08:13:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-common/commit/27948542404739c34161df85eee3f7d7194a4a78', 'message': 'Disable pam_loguinuid for crond\n\nCurrently we run some crond processes with -n option but the cron jobs\nfails because of pam errors. According to man page we have to remove\npam_loginuid.so in case we run crond in the foreground.\n\n~~~\n       -n     Tells the daemon to run in the foreground.  This can be\n              useful when starting it out of init. With this option is\n              needed to change pam setting.  /etc/pam.d/crond must not\n              enable pam_loginuid.so module.\n~~~\n\nResolves: rhbz#2219765\nChange-Id: Id384780e8394b40a91761e7fbbc0f8e44263d681\n'}, {'number': 4, 'created': '2023-07-06 08:16:25.000000000', 'files': ['container-images/tcib/base/os/os.yaml', 'container-images/tcib/base/cron/cron.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-common/commit/dfd9325672f24ed4954b248815eef2776f2605c4', 'message': 'Disable pam_loguinuid for crond\n\nCurrently we run some crond processes with -n option but the cron jobs\nfails because of pam errors. According to man page we have to remove\npam_loginuid.so in case we run crond in the foreground.\n\n~~~\n       -n     Tells the daemon to run in the foreground.  This can be\n              useful when starting it out of init. With this option is\n              needed to change pam setting.  /etc/pam.d/crond must not\n              enable pam_loginuid.so module.\n~~~\n\nResolves: rhbz#2219765\nChange-Id: Id384780e8394b40a91761e7fbbc0f8e44263d681\n'}]",1,887748,dfd9325672f24ed4954b248815eef2776f2605c4,18,5,4,9816,,,0,"Disable pam_loguinuid for crond

Currently we run some crond processes with -n option but the cron jobs
fails because of pam errors. According to man page we have to remove
pam_loginuid.so in case we run crond in the foreground.

~~~
       -n     Tells the daemon to run in the foreground.  This can be
              useful when starting it out of init. With this option is
              needed to change pam setting.  /etc/pam.d/crond must not
              enable pam_loginuid.so module.
~~~

Resolves: rhbz#2219765
Change-Id: Id384780e8394b40a91761e7fbbc0f8e44263d681
",git fetch https://review.opendev.org/openstack/tripleo-common refs/changes/48/887748/1 && git format-patch -1 --stdout FETCH_HEAD,['container-images/tcib/base/base.yaml'],1,7b58d68b482b0af90f31ff1d69fa36e4b0c613bb,rhbz2219765,- run: sed -ri '/^session(\s)+required(\s+)pam_loginuid.so$/d' /etc/pam.d/crond sed -ri '/^-session(\s+)optional(\s+)pam_systemd.so$/d' /etc/pam.d/system-auth &&, sed -ri '/-session(\s+)optional(\s+)pam_systemd.so/d' /etc/pam.d/system-auth &&,2,1
openstack%2Fdesignate~887728,openstack/designate,stable/2023.1,I98c341b8f7138681e35d84707062f8d0e807c533,Fix list zones if shared with multiple projects,MERGED,2023-07-05 16:45:14.000000000,2023-07-07 16:26:11.000000000,2023-07-07 16:25:07.000000000,"[{'_account_id': 11628}, {'_account_id': 22348}, {'_account_id': 22623}]","[{'number': 1, 'created': '2023-07-05 16:45:14.000000000', 'files': ['releasenotes/notes/Fix-zone-list-when-zone-shared-more-than-once-288b57cafeba82df.yaml', 'designate/tests/test_storage/__init__.py', 'designate/storage/impl_sqlalchemy/__init__.py'], 'web_link': 'https://opendev.org/openstack/designate/commit/efeff8e8be0e73d461ac7206e4bf1350c5c684f6', 'message': 'Fix list zones if shared with multiple projects\n\nThis patch fixes a bug when listing zones or updating recordsets in\nzones that are shared with more than one project.\n\nCloses-Bug: #2025295\n(cherry picked from commit 011ebe2e7cd0df0c7f0869f0c7abbce79434821a)\nChange-Id: I98c341b8f7138681e35d84707062f8d0e807c533\n'}]",2,887728,efeff8e8be0e73d461ac7206e4bf1350c5c684f6,10,3,1,11628,,,0,"Fix list zones if shared with multiple projects

This patch fixes a bug when listing zones or updating recordsets in
zones that are shared with more than one project.

Closes-Bug: #2025295
(cherry picked from commit 011ebe2e7cd0df0c7f0869f0c7abbce79434821a)
Change-Id: I98c341b8f7138681e35d84707062f8d0e807c533
",git fetch https://review.opendev.org/openstack/designate refs/changes/28/887728/1 && git format-patch -1 --stdout FETCH_HEAD,"['releasenotes/notes/Fix-zone-list-when-zone-shared-more-than-once-288b57cafeba82df.yaml', 'designate/tests/test_storage/__init__.py', 'designate/storage/impl_sqlalchemy/__init__.py']",3,efeff8e8be0e73d461ac7206e4bf1350c5c684f6,bug/2025295," [tables.zones, shared_case]).outerjoin(tables.shared_zones).distinct()"," [tables.zones, shared_case]).outerjoin(tables.shared_zones)",24,1
openstack%2Fgovernance~887974,openstack/governance,master,I986570ec33354a2e7544fec8ea0fe07242f349e0,Create TOC for 2023 resolutions,ABANDONED,2023-07-07 16:03:49.000000000,2023-07-07 16:18:13.000000000,,[{'_account_id': 22348}],"[{'number': 1, 'created': '2023-07-07 16:03:49.000000000', 'files': ['resolutions/index.rst'], 'web_link': 'https://opendev.org/openstack/governance/commit/07fcbde9bb49b2242ae3b3663be0df79f3ffe6dd', 'message': 'Create TOC for 2023 resolutions\n\nChange-Id: I986570ec33354a2e7544fec8ea0fe07242f349e0\n'}]",0,887974,07fcbde9bb49b2242ae3b3663be0df79f3ffe6dd,3,1,1,16465,,,0,"Create TOC for 2023 resolutions

Change-Id: I986570ec33354a2e7544fec8ea0fe07242f349e0
",git fetch https://review.opendev.org/openstack/governance refs/changes/74/887974/1 && git format-patch -1 --stdout FETCH_HEAD,['resolutions/index.rst'],1,07fcbde9bb49b2242ae3b3663be0df79f3ffe6dd,code-change,2023 ==== .. toctree:: :maxdepth: 1 :glob: :reversed: 2023* ,,10,0
openstack%2Fopenstack-tempest-skiplist~885102,openstack/openstack-tempest-skiplist,master,I0f465f5dd32df6e5cc72f3a5edbce1e19a83f10f,Add fs020-rbac to skiplist - BZ2211604,MERGED,2023-06-02 00:52:05.000000000,2023-07-07 16:11:51.000000000,2023-06-02 01:11:13.000000000,"[{'_account_id': 9976}, {'_account_id': 22348}]","[{'number': 1, 'created': '2023-06-02 00:52:05.000000000', 'files': ['roles/validate-tempest/vars/tempest_skip.yml'], 'web_link': 'https://opendev.org/openstack/openstack-tempest-skiplist/commit/30b34879ce3d2b90cdc30bf914dcbca10ea6aaf2', 'message': 'Add fs020-rbac to skiplist - BZ2211604\n\nRelated-Bug: #BZ2211604\nChange-Id: I0f465f5dd32df6e5cc72f3a5edbce1e19a83f10f\n'}]",0,885102,30b34879ce3d2b90cdc30bf914dcbca10ea6aaf2,8,2,1,9976,,,0,"Add fs020-rbac to skiplist - BZ2211604

Related-Bug: #BZ2211604
Change-Id: I0f465f5dd32df6e5cc72f3a5edbce1e19a83f10f
",git fetch https://review.opendev.org/openstack/openstack-tempest-skiplist refs/changes/02/885102/1 && git format-patch -1 --stdout FETCH_HEAD,['roles/validate-tempest/vars/tempest_skip.yml'],1,30b34879ce3d2b90cdc30bf914dcbca10ea6aaf2,fs020-rbac, - periodic-tripleo-ci-rhel-9-ovb-1ctlr_2comp-featureset020-rbac-internal-rhos-17.1 - periodic-tripleo-ci-rhel-9-ovb-1ctlr_2comp-featureset020-rbac-internal-rhos-17.1,,2,0
openstack%2Fkeystonemiddleware~887189,openstack/keystonemiddleware,stable/2023.1,I3b8263afbf0ccee88ceaac2040d5ad274f22d74a,Make tox.ini tox 4.0.0 compatible/fix gate,MERGED,2023-06-30 19:25:12.000000000,2023-07-07 15:58:58.000000000,2023-07-07 15:57:55.000000000,"[{'_account_id': 7414}, {'_account_id': 7973}, {'_account_id': 15334}, {'_account_id': 22348}]","[{'number': 1, 'created': '2023-06-30 19:25:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystonemiddleware/commit/6ad1c2ab199ac0dcd5464e3a0348fdeca8e183ae', 'message': ""Make tox.ini tox 4.0.0 compatible/fix gate\n\n* Removed skipsdist=True to make sure placement available in the virtual\n  env. Without this, our entrypoints are not available.\n\n* Removed basepython = python3 as we assume all developer switched to\n  python3 in their env already\n\n* Removed ignore_basepython_conflict = True as without the basepython\n  definition generative targets now work without conflict\n\nSee [1] for a similar change made to placement.\n\nIt is also necessary to fix issues with the gate. For reasons that I\nhave yet to grok, a mock of 'requests.request' used in some test is no\nlonger functioning as expected. My guess is that something is now\nimporting requests before us and interfering with the mock but never\nmind - we can easily bypass the issue by mocking 'requests.post'\ninstead.\n\n[1] https://review.opendev.org/c/openstack/placement/+/868418/\n\nChange-Id: I3b8263afbf0ccee88ceaac2040d5ad274f22d74a\nSigned-off-by: Stephen Finucane <stephenfin@redhat.com>\n(cherry picked from commit 626df3a5e9e9d4fbea2649a9cfa0048083bdb88b)\n""}, {'number': 2, 'created': '2023-07-03 11:31:26.000000000', 'files': ['test-requirements.txt', 'tox.ini'], 'web_link': 'https://opendev.org/openstack/keystonemiddleware/commit/ce29fcfb4cc76d890856d96def2e888ffee26fc2', 'message': ""Make tox.ini tox 4.0.0 compatible/fix gate\n\n* Removed skipsdist=True to make sure placement available in the virtual\n  env. Without this, our entrypoints are not available.\n\n* Removed basepython = python3 as we assume all developer switched to\n  python3 in their env already\n\n* Removed ignore_basepython_conflict = True as without the basepython\n  definition generative targets now work without conflict\n\nSee [1] for a similar change made to placement.\n\nIt is also necessary to fix issues with the gate. For reasons that I\nhave yet to grok, a mock of 'requests.request' used in some test is no\nlonger functioning as expected. My guess is that something is now\nimporting requests before us and interfering with the mock but never\nmind - we can easily bypass the issue by mocking 'requests.post'\ninstead.\n\nChanges:\n  keystonemiddleware/tests/unit/test_ec2_token_middleware.py\n  test-requirements.txt\n\nNOTE(stephenfin): It is necessary to revert the test changes since they\ndon't apply to this branch. It is also necessary to cap bandit since we\ncan't fix the timeout errors it is warning about without a feature\nbackport.\n\n[1] https://review.opendev.org/c/openstack/placement/+/868418/\n\nChange-Id: I3b8263afbf0ccee88ceaac2040d5ad274f22d74a\nSigned-off-by: Stephen Finucane <stephenfin@redhat.com>\n(cherry picked from commit 626df3a5e9e9d4fbea2649a9cfa0048083bdb88b)\n""}]",0,887189,ce29fcfb4cc76d890856d96def2e888ffee26fc2,10,4,2,7414,,,0,"Make tox.ini tox 4.0.0 compatible/fix gate

* Removed skipsdist=True to make sure placement available in the virtual
  env. Without this, our entrypoints are not available.

* Removed basepython = python3 as we assume all developer switched to
  python3 in their env already

* Removed ignore_basepython_conflict = True as without the basepython
  definition generative targets now work without conflict

See [1] for a similar change made to placement.

It is also necessary to fix issues with the gate. For reasons that I
have yet to grok, a mock of 'requests.request' used in some test is no
longer functioning as expected. My guess is that something is now
importing requests before us and interfering with the mock but never
mind - we can easily bypass the issue by mocking 'requests.post'
instead.

Changes:
  keystonemiddleware/tests/unit/test_ec2_token_middleware.py
  test-requirements.txt

NOTE(stephenfin): It is necessary to revert the test changes since they
don't apply to this branch. It is also necessary to cap bandit since we
can't fix the timeout errors it is warning about without a feature
backport.

[1] https://review.opendev.org/c/openstack/placement/+/868418/

Change-Id: I3b8263afbf0ccee88ceaac2040d5ad274f22d74a
Signed-off-by: Stephen Finucane <stephenfin@redhat.com>
(cherry picked from commit 626df3a5e9e9d4fbea2649a9cfa0048083bdb88b)
",git fetch https://review.opendev.org/openstack/keystonemiddleware refs/changes/89/887189/1 && git format-patch -1 --stdout FETCH_HEAD,"['keystonemiddleware/tests/unit/test_ec2_token_middleware.py', 'tox.ini']",2,6ad1c2ab199ac0dcd5464e3a0348fdeca8e183ae,tox-4-stable/2023.1,"minversion = 4.2.0 envlist = py3,pep8,releasenotescommands = stestr run {posargs}","minversion = 3.18.0 skipsdist = True envlist = py37,pep8,releasenotes ignore_basepython_conflict = Truecommands = stestr run {posargs} basepython = python3",24,24
openstack%2Fdevstack-plugin-ceph~887879,openstack/devstack-plugin-ceph,stable/2023.1,I076527536e19f7fa2c0cd177bebb1df22db51a0a,Enable validation and disable block-migration,NEW,2023-07-07 12:44:38.000000000,2023-07-07 15:48:36.000000000,,"[{'_account_id': 13861}, {'_account_id': 22348}]","[{'number': 1, 'created': '2023-07-07 12:44:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack-plugin-ceph/commit/c46e478e3745aba10735e81bb28a877141215eda', 'message': 'Enable validation and disable block-migration\n\nOn the multinode job we need to enable validation like the base job\nand also disable block migration for live migration that we get from\nour parent job.\n\nChange-Id: I076527536e19f7fa2c0cd177bebb1df22db51a0a\n(cherry picked from commit bf4598d923bebe9ba31e6651a07596017208b37e)\n'}, {'number': 2, 'created': '2023-07-07 13:42:19.000000000', 'files': ['.zuul.yaml'], 'web_link': 'https://opendev.org/openstack/devstack-plugin-ceph/commit/a9a5910e5ded91471496580d0a7d757073b7f9cc', 'message': 'Enable validation and disable block-migration\n\nOn the multinode job we need to enable validation like the base job\nand also disable block migration for live migration that we get from\nour parent job.\n\nChange-Id: I076527536e19f7fa2c0cd177bebb1df22db51a0a\n(cherry picked from commit bf4598d923bebe9ba31e6651a07596017208b37e)\n'}]",3,887879,a9a5910e5ded91471496580d0a7d757073b7f9cc,10,2,2,11604,,,0,"Enable validation and disable block-migration

On the multinode job we need to enable validation like the base job
and also disable block migration for live migration that we get from
our parent job.

Change-Id: I076527536e19f7fa2c0cd177bebb1df22db51a0a
(cherry picked from commit bf4598d923bebe9ba31e6651a07596017208b37e)
",git fetch https://review.opendev.org/openstack/devstack-plugin-ceph refs/changes/79/887879/1 && git format-patch -1 --stdout FETCH_HEAD,['.zuul.yaml'],1,c46e478e3745aba10735e81bb28a877141215eda,bug/2025813, TEMPEST_RUN_VALIDATION: true USE_BLOCK_MIGRATION_FOR_LIVE_MIGRATION: false, TEMPEST_RUN_VALIDATION: false,2,1
openstack%2Fnova-specs~859290,openstack/nova-specs,master,I2df34bbf4031384e008cbc642ca15291501dfe53,Add support for Napatech LinkVirt SmartNICs,MERGED,2022-09-26 12:41:48.000000000,2023-07-07 15:14:55.000000000,2023-07-07 15:13:46.000000000,"[{'_account_id': 7166}, {'_account_id': 7730}, {'_account_id': 11604}, {'_account_id': 16688}, {'_account_id': 22348}]","[{'number': 1, 'created': '2022-09-26 12:41:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/6bfa49d228524e07c722aff46d069cf9fa226b3a', 'message': 'Add support for Napatech LinkVirt SmartNICs\n\nNapatech LinkVirtualization SmartNICs offload network traffic switching, QoS, and tunnel encapsulation/decapsulation functions from the OVS running on the hypervisor to the on-board silicon. This patch updates the Nova source code to include support for a new VIF type corresponding to the virtual devices exposed by the LinkVirtualization SmartNIC.\n\nChange-Id: I2df34bbf4031384e008cbc642ca15291501dfe53\n'}, {'number': 2, 'created': '2022-09-26 12:57:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/42df37278c73ec7d12d14620cf08aa8df9f3429d', 'message': 'Add support for Napatech LinkVirt SmartNICs\n\nNapatech LinkVirtualization SmartNICs offload network traffic switching, QoS, and tunnel encapsulation/decapsulation functions from the OVS running on the hypervisor to the on-board silicon. This patch updates the Nova source code to include support for a new VIF type corresponding to the virtual devices exposed by the LinkVirtualization SmartNIC.\n\nChange-Id: I2df34bbf4031384e008cbc642ca15291501dfe53\n'}, {'number': 3, 'created': '2022-09-26 13:12:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/6d7c36b6f2e00900274f7d0ce64d9a144f6e6f98', 'message': 'Add support for Napatech LinkVirt SmartNICs\n\nNapatech LinkVirtualization SmartNICs offload network traffic switching, QoS, and tunnel encapsulation/decapsulation functions from the OVS running on the hypervisor to the on-board silicon. This patch updates the Nova source code to include support for a new VIF type corresponding to the virtual devices exposed by the LinkVirtualization SmartNIC.\n\nChange-Id: I2df34bbf4031384e008cbc642ca15291501dfe53\n'}, {'number': 4, 'created': '2022-09-28 13:17:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/679d5f2b2f0a9faaa6689462442cd903ebb779dc', 'message': 'Add support for Napatech LinkVirt SmartNICs\n\nNapatech LinkVirtualization SmartNICs offload network traffic switching, QoS, and tunnel encapsulation/decapsulation functions from the OVS running on the hypervisor to the on-board silicon. This patch updates the Nova source code to include support for a new VIF type corresponding to the virtual devices exposed by the LinkVirtualization SmartNIC.\n\nChange-Id: I2df34bbf4031384e008cbc642ca15291501dfe53\n'}, {'number': 5, 'created': '2023-01-10 09:59:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/dc09be840df59ccc803f036172772fc1e705f6d7', 'message': 'Add support for Napatech LinkVirt SmartNICs\n\nNapatech LinkVirtualization SmartNICs offload network traffic switching, QoS, and tunnel encapsulation/decapsulation functions from the OVS running on the hypervisor to the on-board silicon. This patch updates the Nova source code to include support for a new VIF type corresponding to the virtual devices exposed by the LinkVirtualization SmartNIC.\n\nChange-Id: I2df34bbf4031384e008cbc642ca15291501dfe53\n'}, {'number': 6, 'created': '2023-03-07 08:58:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/efa921b99b9a4a1fac42bef6f1b12866effa0ecb', 'message': 'Add support for Napatech LinkVirt SmartNICs\n\nNapatech LinkVirtualization SmartNICs offload network traffic switching, QoS, and tunnel encapsulation/decapsulation functions from the OVS running on the hypervisor to the on-board silicon. This patch updates the Nova source code to include support for a new VIF type corresponding to the virtual devices exposed by the LinkVirtualization SmartNIC.\n\nChange-Id: I2df34bbf4031384e008cbc642ca15291501dfe53\n'}, {'number': 7, 'created': '2023-03-15 12:00:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/63910f42b9b6e61c145511842ae4febf2a9595a6', 'message': 'Add support for Napatech LinkVirt SmartNICs\n\nNapatech LinkVirtualization SmartNICs offload network traffic switching, QoS, and tunnel encapsulation/decapsulation functions from the OVS running on the hypervisor to the on-board silicon. This patch updates the Nova source code to include support for a new VIF type corresponding to the virtual devices exposed by the LinkVirtualization SmartNIC.\n\nChange-Id: I2df34bbf4031384e008cbc642ca15291501dfe53\n'}, {'number': 8, 'created': '2023-03-15 12:10:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/1ce288e9c590a481b6282c940853cdc903bcec24', 'message': 'Add support for Napatech LinkVirt SmartNICs\n\nNapatech LinkVirtualization SmartNICs offload network traffic switching, QoS, and tunnel encapsulation/decapsulation functions from the OVS running on the hypervisor to the on-board silicon. This patch updates the Nova source code to include support for a new VIF type corresponding to the virtual devices exposed by the LinkVirtualization SmartNIC.\n\nChange-Id: I2df34bbf4031384e008cbc642ca15291501dfe53\n'}, {'number': 9, 'created': '2023-04-11 13:49:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/63e83725eb06ddf7d019f9cb209b4c1081cf90ec', 'message': 'Add support for Napatech LinkVirt SmartNICs\n\nNapatech LinkVirtualization SmartNICs offload network traffic switching, QoS, and tunnel encapsulation/decapsulation functions from the OVS running on the hypervisor to the on-board silicon. This patch updates the Nova source code to include support for a new VIF type corresponding to the virtual devices exposed by the LinkVirtualization SmartNIC.\n\nChange-Id: I2df34bbf4031384e008cbc642ca15291501dfe53\n'}, {'number': 10, 'created': '2023-05-05 08:27:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/a95069d093d29e12379368120c1037d484d3eb63', 'message': 'Add support for Napatech LinkVirt SmartNICs\n\nNapatech LinkVirtualization SmartNICs offload network traffic switching, QoS, and tunnel encapsulation/decapsulation functions from the OVS running on the hypervisor to the on-board silicon. This patch updates the Nova source code to include support for a new VIF type corresponding to the virtual devices exposed by the LinkVirtualization SmartNIC.\n\nChange-Id: I2df34bbf4031384e008cbc642ca15291501dfe53\n'}, {'number': 11, 'created': '2023-05-08 14:10:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/5760ff2b9537f7d39e703cd612ce2d0b0844aa9a', 'message': 'Add support for Napatech LinkVirt SmartNICs\n\nNapatech LinkVirtualization SmartNICs offload network traffic switching, QoS, and tunnel encapsulation/decapsulation functions from the OVS running on the hypervisor to the on-board silicon. This patch updates the Nova source code to include support for a new VIF type corresponding to the virtual devices exposed by the LinkVirtualization SmartNIC.\n\nChange-Id: I2df34bbf4031384e008cbc642ca15291501dfe53\n'}, {'number': 12, 'created': '2023-05-19 13:16:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/cd23fb4acde300f3940e184f89e20c64468b44b2', 'message': 'Add support for Napatech LinkVirt SmartNICs\n\nNapatech LinkVirtualization SmartNICs offload network traffic switching, QoS, and tunnel encapsulation/decapsulation functions from the OVS running on the hypervisor to the on-board silicon. This patch updates the Nova source code to include support for a new VIF type corresponding to the virtual devices exposed by the LinkVirtualization SmartNIC.\n\nChange-Id: I2df34bbf4031384e008cbc642ca15291501dfe53\n'}, {'number': 13, 'created': '2023-05-19 13:41:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/50bafb989c9e64fc7ae1691fb38589758ec6663f', 'message': 'Add support for Napatech LinkVirt SmartNICs\n\nNapatech LinkVirtualization SmartNICs offload network traffic switching, QoS, and tunnel encapsulation/decapsulation functions from the OVS running on the hypervisor to the on-board silicon. This patch updates the Nova source code to include support for a new VIF type corresponding to the virtual devices exposed by the LinkVirtualization SmartNIC.\n\nChange-Id: I2df34bbf4031384e008cbc642ca15291501dfe53\n'}, {'number': 14, 'created': '2023-05-19 13:43:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/3f842fc98c4af3908d99a24b10d594b159f89930', 'message': 'Add support for Napatech LinkVirt SmartNICs\n\nNapatech LinkVirtualization SmartNICs offload network traffic switching, QoS, and tunnel encapsulation/decapsulation functions from the OVS running on the hypervisor to the on-board silicon. This patch updates the Nova source code to include support for a new VIF type corresponding to the virtual devices exposed by the LinkVirtualization SmartNIC.\n\nChange-Id: I2df34bbf4031384e008cbc642ca15291501dfe53\n'}, {'number': 15, 'created': '2023-05-29 09:23:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/882db8abab1b9b4b2b677a89a077cf5a7a10973f', 'message': 'Add support for Napatech LinkVirt SmartNICs\n\nNapatech LinkVirtualization SmartNICs offload network traffic switching, QoS, and tunnel encapsulation/decapsulation functions from the OVS running on the hypervisor to the on-board silicon. This patch updates the Nova source code to include support for a new VIF type corresponding to the virtual devices exposed by the LinkVirtualization SmartNIC.\n\nChange-Id: I2df34bbf4031384e008cbc642ca15291501dfe53\n'}, {'number': 16, 'created': '2023-06-01 14:30:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/75d84a974271ca190d58ef593c336c64a7943c7d', 'message': 'Add support for Napatech LinkVirt SmartNICs\n\nNapatech LinkVirtualization SmartNICs offload network traffic switching, QoS, and tunnel encapsulation/decapsulation functions from the OVS running on the hypervisor to the on-board silicon. This patch updates the Nova source code to include support for a new VIF type corresponding to the virtual devices exposed by the LinkVirtualization SmartNIC.\n\nChange-Id: I2df34bbf4031384e008cbc642ca15291501dfe53\n'}, {'number': 17, 'created': '2023-06-01 14:53:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/f319a61f9c609de76f340521534ef8931db4a76a', 'message': 'Add support for Napatech LinkVirt SmartNICs\n\nNapatech LinkVirtualization SmartNICs offload network traffic switching, QoS, and tunnel encapsulation/decapsulation functions from the OVS running on the hypervisor to the on-board silicon. This patch updates the Nova source code to include support for a new VIF type corresponding to the virtual devices exposed by the LinkVirtualization SmartNIC.\n\nChange-Id: I2df34bbf4031384e008cbc642ca15291501dfe53\n'}, {'number': 18, 'created': '2023-06-01 15:13:23.000000000', 'files': ['specs/2023.2/approved/support-napatech-linkvirtualization-smartnic.rst'], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/f62bcfe652dc31e0047fc045b3f25be06bbe8d6a', 'message': 'Add support for Napatech LinkVirt SmartNICs\n\nNapatech LinkVirtualization SmartNICs offload network traffic switching, QoS, and tunnel encapsulation/decapsulation functions from the OVS running on the hypervisor to the on-board silicon. This patch updates the Nova source code to include support for a new VIF type corresponding to the virtual devices exposed by the LinkVirtualization SmartNIC.\n\nChange-Id: I2df34bbf4031384e008cbc642ca15291501dfe53\n'}]",87,859290,f62bcfe652dc31e0047fc045b3f25be06bbe8d6a,76,5,18,35239,,,0,"Add support for Napatech LinkVirt SmartNICs

Napatech LinkVirtualization SmartNICs offload network traffic switching, QoS, and tunnel encapsulation/decapsulation functions from the OVS running on the hypervisor to the on-board silicon. This patch updates the Nova source code to include support for a new VIF type corresponding to the virtual devices exposed by the LinkVirtualization SmartNIC.

Change-Id: I2df34bbf4031384e008cbc642ca15291501dfe53
",git fetch https://review.opendev.org/openstack/nova-specs refs/changes/90/859290/1 && git format-patch -1 --stdout FETCH_HEAD,['specs/2023.1/approved/napatech-linkvirtualization-smartnic-support.rst'],1,6bfa49d228524e07c722aff46d069cf9fa226b3a,bug/2013540,".. This work is licensed under a Creative Commons Attribution 3.0 Unported License. http://creativecommons.org/licenses/by/3.0/legalcode ========================================== Support Napatech LinkVirtualization SmartNICs ========================================== https://blueprints.launchpad.net/nova/+spec/example Napatech LinkVirtualization SmartNICs offload network traffic switching, QoS, and tunnel encapsulation/decapsulation functions from the OVS running on the hypervisor to the on-board silicon. This patch updates the Nova source code to include support for a new VIF type corresponding to the virtual devices exposed by the LinkVirtualization SmartNIC. Problem description =================== Napatech SmartNICs can offload several computational resource intensive tasks from the hypervisor, such as packet switching, QoS enforcement, and V(x)LAN tunnel encapsulation/decapsulation. This patch includes changes to Nova and Os-vif codebases to support Napatech SmartNICs out-of-the-box. This change proposal does not add any new vnic types. The only vnic type supported by Napatech LinkVirtualization is `virtio-forwarder`. Use Cases --------- * An end user of Napatech SmartNIC should be able to run VMs over the hardware-offloaded switch fabric without having to patch OpenStack source code. Proposed change =============== * We propose to add a new VIF type `VIF_TYPE_LV_OVS` and the related VIF handling code to a function `nova_to_osvif_vif()`. * We propose to add a new os-vif `network` property called `network_type`. It is used by the LinkVirtualization ML2 driver. Driver code is open-source and is available online in Github. * We propose unit-tests pertinent to the proposed changes. Alternatives ------------ An alternative is not to support LinkVirtualization adapters and require users to patch OpenStack source code. Data model impact ----------------- None REST API impact --------------- None Security impact --------------- None Notifications impact -------------------- None Other end user impact --------------------- None Performance Impact ------------------ Users will see a significant network performance increase when running over the hardware offloaded data-plane. Other deployer impact --------------------- In line with other SmartNIC offerings, the deployer will have to configure OVS-DPDK following the SmartNIC producer guidelines and update the PCI whitelist configuration. Developer impact ---------------- Noen Upgrade impact -------------- Os-vif change includes code to handle differences object version 1.1 and 1.2 ( addition of `network_type` key.) Implementation ============== Assignee(s) ----------- TBD Feature Liaison --------------- TBD Work Items ---------- * Nova change proposal: https://review.opendev.org/c/openstack/nova/+/XXXXXX * Os-vif change proposal: https://review.opendev.org/c/openstack/os-vif/+/XXXXXX * Neutron-lib change proposal: https://review.opendev.org/c/openstack/neutron-lib/+/XXXXXX Dependencies ============ * This blueprint is a prerequisite to update code in Neutron to support LinkVirtualization SmartNICs. This is in-line with support of other SmartNICs. Links to changes of all four components are given in the Work Items section. Testing ======= Code changes include unit-tests. Documentation Impact ==================== We are not introducing any new VNIC type, so there should be no impact on documentation. References ========== * Napatech LinkVirtualization: https://www.napatech.com/products/link-virtualization-software/ * Napatech OpenStack drivers: https://github.com/napatech/linkvirt-ovs-openstack-plugin History ======= .. list-table:: Revisions :header-rows: 1 * - Release Name - Description * - 2023.1 Antelope - Introduced",,169,0
openstack%2Fironic~887023,openstack/ironic,master,Ia045e10564dba5ad6d2f90ab75dc4d289c90cf68,Remove python 3.6 mock hack,MERGED,2023-06-27 08:40:05.000000000,2023-07-07 14:42:32.000000000,2023-07-07 14:41:12.000000000,"[{'_account_id': 4571}, {'_account_id': 10239}, {'_account_id': 10342}, {'_account_id': 22348}]","[{'number': 1, 'created': '2023-06-27 08:40:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/31355b140ca2791f828be3355b44398171f53481', 'message': ""Remove python 3.6 mock hack\n\nWe don't support Python 3.6 anymore and the function is not\nused anywhere.\n\nChange-Id: Ia045e10564dba5ad6d2f90ab75dc4d289c90cf68\n""}, {'number': 2, 'created': '2023-07-03 09:30:36.000000000', 'files': ['ironic/tests/base.py'], 'web_link': 'https://opendev.org/openstack/ironic/commit/e8d6a890f1956844b2ddfbb5d60d2ffa388062da', 'message': ""Remove python 3.6 mock hack\n\nWe don't support Python 3.6 anymore and the function is not\nused anywhere.\n\nChange-Id: Ia045e10564dba5ad6d2f90ab75dc4d289c90cf68\n""}]",5,887023,e8d6a890f1956844b2ddfbb5d60d2ffa388062da,32,4,2,23851,,,0,"Remove python 3.6 mock hack

We don't support Python 3.6 anymore and the function is not
used anywhere.

Change-Id: Ia045e10564dba5ad6d2f90ab75dc4d289c90cf68
",git fetch https://review.opendev.org/openstack/ironic refs/changes/23/887023/1 && git format-patch -1 --stdout FETCH_HEAD,['ironic/tests/base.py'],1,31355b140ca2791f828be3355b44398171f53481,remove-py36hack,,"from unittest import mock# NOTE(rpittau) this function allows autospec for classmethods and # staticmethods in Python 3.6, while no issue occurs in Python 3.7.4 # and later. # For more info please see: http://bugs.python.org/issue23078 def _patch_mock_callable(obj): if isinstance(obj, type): return True if getattr(obj, '__call__', None) is not None: return True if (isinstance(obj, (staticmethod, classmethod)) and mock._callable(obj.__func__)): return True return False ",0,16
openstack%2Freleases~887483,openstack/releases,master,I0bee8a1e7285d971dc7c6ca5d09f25271848d993,Bobcat-2 release for keystonemiddleware,MERGED,2023-07-03 09:31:29.000000000,2023-07-07 14:33:13.000000000,2023-07-07 14:33:13.000000000,"[{'_account_id': 7414}, {'_account_id': 16465}, {'_account_id': 17685}, {'_account_id': 22348}, {'_account_id': 28522}]","[{'number': 1, 'created': '2023-07-03 09:31:29.000000000', 'files': ['deliverables/bobcat/keystonemiddleware.yaml'], 'web_link': 'https://opendev.org/openstack/releases/commit/bc54b2946e61cb7265fba73d78bb82d82ec6b269', 'message': 'Bobcat-2 release for keystonemiddleware\n\nThis is the Bobcat-2 milestone release for keystonemiddleware.\nClients and libraries following the cycle-with-intermediary release\nmodel are encouraged to release each milestone to make sure updates\nare made available.\n\nIf the team is happy with the current release hash, please +1 this\npatch and we will process the release. If you need to get some\nimportant changes merged first, leave a -1 and update the patch with\na new commit hash to use once it is ready.\n\nIf a release is definitely not wanted at this time, please -1 and\nleave a comment explaining that and we can abandon the patch.\n\nAny patches with no response will be assumed to be OK and will be\nprocessed after July 6th.\n\nChange-Id: I0bee8a1e7285d971dc7c6ca5d09f25271848d993\nSigned-off-by: Elod Illes <elod.illes@est.tech>\n'}]",2,887483,bc54b2946e61cb7265fba73d78bb82d82ec6b269,8,5,1,17685,,,0,"Bobcat-2 release for keystonemiddleware

This is the Bobcat-2 milestone release for keystonemiddleware.
Clients and libraries following the cycle-with-intermediary release
model are encouraged to release each milestone to make sure updates
are made available.

If the team is happy with the current release hash, please +1 this
patch and we will process the release. If you need to get some
important changes merged first, leave a -1 and update the patch with
a new commit hash to use once it is ready.

If a release is definitely not wanted at this time, please -1 and
leave a comment explaining that and we can abandon the patch.

Any patches with no response will be assumed to be OK and will be
processed after July 6th.

Change-Id: I0bee8a1e7285d971dc7c6ca5d09f25271848d993
Signed-off-by: Elod Illes <elod.illes@est.tech>
",git fetch https://review.opendev.org/openstack/releases refs/changes/83/887483/1 && git format-patch -1 --stdout FETCH_HEAD,['deliverables/bobcat/keystonemiddleware.yaml'],1,bc54b2946e61cb7265fba73d78bb82d82ec6b269,bobcat-milestone-2, - version: 10.4.0 projects: - repo: openstack/keystonemiddleware hash: 22408f8da0e8a14a1a24dc9237448e78a5673cf9,,4,0
openstack%2Freleases~887486,openstack/releases,master,I15a4e9c8d036d2942daf2d749bd430643d0d0dcc,Bobcat-2 release for os-vif,MERGED,2023-07-03 09:38:02.000000000,2023-07-07 14:24:54.000000000,2023-07-07 14:24:54.000000000,"[{'_account_id': 7166}, {'_account_id': 11604}, {'_account_id': 16207}, {'_account_id': 17685}, {'_account_id': 22348}, {'_account_id': 28522}, {'_account_id': 34860}]","[{'number': 1, 'created': '2023-07-03 09:38:02.000000000', 'files': ['deliverables/bobcat/os-vif.yaml'], 'web_link': 'https://opendev.org/openstack/releases/commit/541bbfccaa8af4bffb15c7a82598bf9010d97f9d', 'message': 'Bobcat-2 release for os-vif\n\nThis is the Bobcat-2 milestone release for os-vif.\nClients and libraries following the cycle-with-intermediary release\nmodel are encouraged to release each milestone to make sure updates\nare made available.\n\nIf the team is happy with the current release hash, please +1 this\npatch and we will process the release. If you need to get some\nimportant changes merged first, leave a -1 and update the patch with\na new commit hash to use once it is ready.\n\nIf a release is definitely not wanted at this time, please -1 and\nleave a comment explaining that and we can abandon the patch.\n\nAny patches with no response will be assumed to be OK and will be\nprocessed after July 6th.\n\nChange-Id: I15a4e9c8d036d2942daf2d749bd430643d0d0dcc\nSigned-off-by: Elod Illes <elod.illes@est.tech>\n'}]",6,887486,541bbfccaa8af4bffb15c7a82598bf9010d97f9d,12,7,1,17685,,,0,"Bobcat-2 release for os-vif

This is the Bobcat-2 milestone release for os-vif.
Clients and libraries following the cycle-with-intermediary release
model are encouraged to release each milestone to make sure updates
are made available.

If the team is happy with the current release hash, please +1 this
patch and we will process the release. If you need to get some
important changes merged first, leave a -1 and update the patch with
a new commit hash to use once it is ready.

If a release is definitely not wanted at this time, please -1 and
leave a comment explaining that and we can abandon the patch.

Any patches with no response will be assumed to be OK and will be
processed after July 6th.

Change-Id: I15a4e9c8d036d2942daf2d749bd430643d0d0dcc
Signed-off-by: Elod Illes <elod.illes@est.tech>
",git fetch https://review.opendev.org/openstack/releases refs/changes/86/887486/1 && git format-patch -1 --stdout FETCH_HEAD,['deliverables/bobcat/os-vif.yaml'],1,541bbfccaa8af4bffb15c7a82598bf9010d97f9d,bobcat-milestone-2,releases: - version: 3.2.0 projects: - repo: openstack/os-vif hash: da742a849a1b8b2f3ca9485b38c5bb54c1bb6c75,,5,0
openstack%2Freleases~887496,openstack/releases,master,I327a1884a1c93ece4fe5d7531d9fe4a6db3bd742,Bobcat-2 release for python-glanceclient,MERGED,2023-07-03 10:02:26.000000000,2023-07-07 14:24:52.000000000,2023-07-07 14:24:52.000000000,"[{'_account_id': 17685}, {'_account_id': 19138}, {'_account_id': 22348}, {'_account_id': 28522}]","[{'number': 1, 'created': '2023-07-03 10:02:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/releases/commit/b711f17752f682fb63e52866429a4593f3577d1d', 'message': 'Bobcat-2 release for python-glanceclient\n\nThis is the Bobcat-2 milestone release for python-glanceclient.\nClients and libraries following the cycle-with-intermediary release\nmodel are encouraged to release each milestone to make sure updates\nare made available.\n\nIf the team is happy with the current release hash, please +1 this\npatch and we will process the release. If you need to get some\nimportant changes merged first, leave a -1 and update the patch with\na new commit hash to use once it is ready.\n\nIf a release is definitely not wanted at this time, please -1 and\nleave a comment explaining that and we can abandon the patch.\n\nAny patches with no response will be assumed to be OK and will be\nprocessed after July 6th.\n\nChange-Id: I327a1884a1c93ece4fe5d7531d9fe4a6db3bd742\nSigned-off-by: Elod Illes <elod.illes@est.tech>\n'}, {'number': 2, 'created': '2023-07-06 10:51:53.000000000', 'files': ['deliverables/bobcat/python-glanceclient.yaml'], 'web_link': 'https://opendev.org/openstack/releases/commit/8d8f40a75fec9e22e81be71b84a93f7ccf9cd901', 'message': 'Bobcat-2 release for python-glanceclient\n\nThis is the Bobcat-2 milestone release for python-glanceclient.\nClients and libraries following the cycle-with-intermediary release\nmodel are encouraged to release each milestone to make sure updates\nare made available.\n\nIf the team is happy with the current release hash, please +1 this\npatch and we will process the release. If you need to get some\nimportant changes merged first, leave a -1 and update the patch with\na new commit hash to use once it is ready.\n\nIf a release is definitely not wanted at this time, please -1 and\nleave a comment explaining that and we can abandon the patch.\n\nAny patches with no response will be assumed to be OK and will be\nprocessed after July 6th.\n\nChange-Id: I327a1884a1c93ece4fe5d7531d9fe4a6db3bd742\nSigned-off-by: Elod Illes <elod.illes@est.tech>\n'}]",3,887496,8d8f40a75fec9e22e81be71b84a93f7ccf9cd901,12,4,2,17685,,,0,"Bobcat-2 release for python-glanceclient

This is the Bobcat-2 milestone release for python-glanceclient.
Clients and libraries following the cycle-with-intermediary release
model are encouraged to release each milestone to make sure updates
are made available.

If the team is happy with the current release hash, please +1 this
patch and we will process the release. If you need to get some
important changes merged first, leave a -1 and update the patch with
a new commit hash to use once it is ready.

If a release is definitely not wanted at this time, please -1 and
leave a comment explaining that and we can abandon the patch.

Any patches with no response will be assumed to be OK and will be
processed after July 6th.

Change-Id: I327a1884a1c93ece4fe5d7531d9fe4a6db3bd742
Signed-off-by: Elod Illes <elod.illes@est.tech>
",git fetch https://review.opendev.org/openstack/releases refs/changes/96/887496/1 && git format-patch -1 --stdout FETCH_HEAD,['deliverables/bobcat/python-glanceclient.yaml'],1,b711f17752f682fb63e52866429a4593f3577d1d,bobcat-milestone-2,releases: - version: 4.4.0 projects: - repo: openstack/python-glanceclient hash: f53d6714fda94b22517489dfeb72bc2874386ebb,,5,0
openstack%2Fbarbican~869387,openstack/barbican,master,I984ca060e7c65e8b9374eaaf192afc0023fa9262,Add support for Vault KV path,NEW,2023-01-05 16:22:41.000000000,2023-07-07 14:23:01.000000000,,"[{'_account_id': 7973}, {'_account_id': 10342}, {'_account_id': 14250}, {'_account_id': 15334}, {'_account_id': 22348}, {'_account_id': 29543}]","[{'number': 1, 'created': '2023-01-05 16:22:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/barbican/commit/5843c5bc2b5cffc5b5d5f41546631267ac1d1e63', 'message': 'Add support for Vault KV path\n\nThis commit adds support for a Vault path that is relative to\nthe root of the Vault KV store. This configuration is optional\nand will be a noop for existing deployments.\n\nDepends-On: If34c38c8f0a2f13ea90f564bfe5e933e5e748da4\nChange-Id: I984ca060e7c65e8b9374eaaf192afc0023fa9262\n'}, {'number': 2, 'created': '2023-01-06 12:08:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/barbican/commit/74aaa37c7ff8e9d7d14cbbb419b315ef757b9634', 'message': 'Add support for Vault KV path\n\nThis commit adds support for a Vault path that is relative to\nthe root of the Vault KV store. This configuration is optional\nand will be a noop for existing deployments.\n\nDepends-On: If34c38c8f0a2f13ea90f564bfe5e933e5e748da4\nChange-Id: I984ca060e7c65e8b9374eaaf192afc0023fa9262\n'}, {'number': 3, 'created': '2023-01-16 22:38:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/barbican/commit/636a99e3a055fb00e1bb905fa895d80414312f03', 'message': 'Add support for Vault KV path\n\nThis commit adds support for a Vault path that is relative to\nthe root of the Vault KV store. This configuration is optional\nand will be a noop for existing deployments.\n\nDepends-On: If34c38c8f0a2f13ea90f564bfe5e933e5e748da4\nChange-Id: I984ca060e7c65e8b9374eaaf192afc0023fa9262\n'}, {'number': 4, 'created': '2023-01-17 18:40:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/barbican/commit/1ac52c15946fc14c5c570ce561037d717d606088', 'message': 'Add support for Vault KV path\n\nThis commit adds support for a Vault path that is relative to\nthe root of the Vault KV store. This configuration is optional\nand will be a noop for existing deployments.\n\nDepends-On: https://review.opendev.org/c/openstack/castellan/+/869386\nChange-Id: I984ca060e7c65e8b9374eaaf192afc0023fa9262\n'}, {'number': 5, 'created': '2023-06-30 15:51:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/barbican/commit/004079cce9cc9c68fcfc8949ada24799355a4dc1', 'message': 'Add support for Vault KV path\n\nThis commit adds support for a Vault path that is relative to\nthe root of the Vault KV store. This configuration is optional\nand will be a noop for existing deployments.\n\nChange-Id: I984ca060e7c65e8b9374eaaf192afc0023fa9262\n'}, {'number': 6, 'created': '2023-06-30 15:51:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/barbican/commit/f2a389c4b65ed0aff28c98ce12fac08323e57edb', 'message': 'Add support for Vault KV path\n\nThis commit adds support for a Vault path that is relative to\nthe root of the Vault KV store. This configuration is optional\nand will be a noop for existing deployments.\n\nChange-Id: I984ca060e7c65e8b9374eaaf192afc0023fa9262\n'}, {'number': 7, 'created': '2023-07-01 03:46:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/barbican/commit/836622951283ef04463f2452db35a534022db8c7', 'message': 'Add support for Vault KV path\n\nThis commit adds support for a Vault path that is relative to\nthe root of the Vault KV store. This configuration is optional\nand will be a noop for existing deployments.\n\nChange-Id: I984ca060e7c65e8b9374eaaf192afc0023fa9262\nDepends-On: https://review.opendev.org/c/openstack/barbican/+/887439\n'}, {'number': 8, 'created': '2023-07-01 04:51:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/barbican/commit/821998720757dde276e6a8b4e0fc2041c876d1f7', 'message': 'Add support for Vault KV path\n\nThis commit adds support for a Vault path that is relative to\nthe root of the Vault KV store. This configuration is optional\nand will be a noop for existing deployments.\n\nRaises required version of castellan to 4.2.0, which added vault\nkv support.\n\nChange-Id: I984ca060e7c65e8b9374eaaf192afc0023fa9262\n'}, {'number': 9, 'created': '2023-07-01 14:38:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/barbican/commit/9bd36d04ad7d7f50eee9d4b23bcc5706bad9dfe1', 'message': 'Add support for Vault KV path\n\nThis commit adds support for a Vault path that is relative to\nthe root of the Vault KV store. This configuration is optional\nand will be a noop for existing deployments.\n\nRaises required version of castellan to 4.2.0, which added vault\nkv support.\n\nChange-Id: I984ca060e7c65e8b9374eaaf192afc0023fa9262\n'}, {'number': 10, 'created': '2023-07-01 16:27:44.000000000', 'files': ['requirements.txt', 'barbican/plugin/vault_secret_store.py'], 'web_link': 'https://opendev.org/openstack/barbican/commit/3bd86424cc20fd0605148a8e95531af3a47aa1da', 'message': 'Add support for Vault KV path\n\nThis commit adds support for a Vault path that is relative to\nthe root of the Vault KV store. This configuration is optional\nand will be a noop for existing deployments.\n\nRaises required version of castellan to 4.2.0, which added vault\nkv support.\n\nDepends-On: https://review.opendev.org/c/openstack/requirements/+/887446\nChange-Id: I984ca060e7c65e8b9374eaaf192afc0023fa9262\n'}]",10,869387,3bd86424cc20fd0605148a8e95531af3a47aa1da,34,6,10,29543,,,0,"Add support for Vault KV path

This commit adds support for a Vault path that is relative to
the root of the Vault KV store. This configuration is optional
and will be a noop for existing deployments.

Raises required version of castellan to 4.2.0, which added vault
kv support.

Depends-On: https://review.opendev.org/c/openstack/requirements/+/887446
Change-Id: I984ca060e7c65e8b9374eaaf192afc0023fa9262
",git fetch https://review.opendev.org/openstack/barbican refs/changes/87/869387/1 && git format-patch -1 --stdout FETCH_HEAD,['barbican/plugin/vault_secret_store.py'],1,5843c5bc2b5cffc5b5d5f41546631267ac1d1e63,hash-vault-kv-path," cfg.StrOpt('kv_path', help='Path relative to root of KV store in Vault to use.') vault_kv_path=conf.vault_plugin.kv_path,",,3,0
openstack%2Freleases~887504,openstack/releases,master,I6341099f2493590008bbb9a14d4e5a858dc4aa27,Remove networking-odl from Bobcat release,MERGED,2023-07-03 10:42:58.000000000,2023-07-07 14:11:46.000000000,2023-07-07 14:11:46.000000000,"[{'_account_id': 11975}, {'_account_id': 16688}, {'_account_id': 17685}, {'_account_id': 22348}, {'_account_id': 28522}]","[{'number': 1, 'created': '2023-07-03 10:42:58.000000000', 'files': ['deliverables/bobcat/networking-odl.yaml'], 'web_link': 'https://opendev.org/openstack/releases/commit/4bf493a7f2c75cb6376986f06c90aaff46c405de', 'message': 'Remove networking-odl from Bobcat release\n\nnetworking-odl was deprecated May 2023, and should not be included in\nthe 2023.1 Bobcat final release.\n\nChange-Id: I6341099f2493590008bbb9a14d4e5a858dc4aa27\n'}]",1,887504,4bf493a7f2c75cb6376986f06c90aaff46c405de,8,5,1,308,,,0,"Remove networking-odl from Bobcat release

networking-odl was deprecated May 2023, and should not be included in
the 2023.1 Bobcat final release.

Change-Id: I6341099f2493590008bbb9a14d4e5a858dc4aa27
",git fetch https://review.opendev.org/openstack/releases refs/changes/04/887504/1 && git format-patch -1 --stdout FETCH_HEAD,['deliverables/bobcat/networking-odl.yaml'],1,4bf493a7f2c75cb6376986f06c90aaff46c405de,remove-networking-odl,,--- launchpad: networking-odl team: neutron type: other release-model: cycle-with-rc release-type: neutron include-pypi-link: true repository-settings: openstack/networking-odl: {} ,0,9
openstack%2Fneutron~887614,openstack/neutron,stable/2023.1,I1a3723ae999fefb5dcbe3a60cf1a4902da9f0265,Don't allow deletion of the router ports without IP addresses,MERGED,2023-07-04 14:48:08.000000000,2023-07-07 14:03:47.000000000,2023-07-07 14:02:32.000000000,"[{'_account_id': 16688}, {'_account_id': 21798}, {'_account_id': 22348}]","[{'number': 1, 'created': '2023-07-04 14:48:08.000000000', 'files': ['neutron/db/l3_db.py', 'neutron/tests/unit/db/test_l3_db.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/854613167419984f227855b8a7a0589747ea6764', 'message': ""Don't allow deletion of the router ports without IP addresses\n\nThis patch effectively reverts old patch [1]. From now on it will be not\nallowed to directly remove router ports which don't have fixed IPs\nassigned. Such ports will be treated as any other ports connected to the\nrouters.\nOriginally [1] was introduced to allow cleanup of the router ports for\nwhich subnets were deleted. But now it's not needed anymore as we\nprevent deletion of subnet if there are any ports with IP allocated from\nthat subnet.\n\nCloses-bug: #2025056\n\n[1] https://review.opendev.org/c/openstack/neutron/+/20424\n\nChange-Id: I1a3723ae999fefb5dcbe3a60cf1a4902da9f0265\n(cherry picked from commit 32d589f03ed0d2744fe15173ebacafd18fced8a9)\n""}]",4,887614,854613167419984f227855b8a7a0589747ea6764,18,3,1,11975,,,0,"Don't allow deletion of the router ports without IP addresses

This patch effectively reverts old patch [1]. From now on it will be not
allowed to directly remove router ports which don't have fixed IPs
assigned. Such ports will be treated as any other ports connected to the
routers.
Originally [1] was introduced to allow cleanup of the router ports for
which subnets were deleted. But now it's not needed anymore as we
prevent deletion of subnet if there are any ports with IP allocated from
that subnet.

Closes-bug: #2025056

[1] https://review.opendev.org/c/openstack/neutron/+/20424

Change-Id: I1a3723ae999fefb5dcbe3a60cf1a4902da9f0265
(cherry picked from commit 32d589f03ed0d2744fe15173ebacafd18fced8a9)
",git fetch https://review.opendev.org/openstack/neutron refs/changes/14/887614/1 && git format-patch -1 --stdout FETCH_HEAD,"['neutron/db/l3_db.py', 'neutron/tests/unit/db/test_l3_db.py']",2,854613167419984f227855b8a7a0589747ea6764,bug/2025056-stable/2023.1," 'device_id': '44', 'id': 'f', } with testtools.ExpectedException(n_exc.ServicePortInUse): self.db.prevent_l3_port_deletion(mock.Mock(), None)"," 'id': 'f' } self.db.prevent_l3_port_deletion(None, None)",3,11
openstack%2Freleases~887946,openstack/releases,master,I92e9df123756a849c0f37f50717d51be580afe44,[oslo] Transition Rocky to End of Life,MERGED,2023-07-07 12:06:24.000000000,2023-07-07 13:31:29.000000000,2023-07-07 13:31:29.000000000,"[{'_account_id': 17685}, {'_account_id': 22348}, {'_account_id': 28522}, {'_account_id': 31245}]","[{'number': 1, 'created': '2023-07-07 12:06:24.000000000', 'files': ['deliverables/rocky/devstack-plugin-kafka.yaml', 'deliverables/rocky/devstack-plugin-amqp1.yaml'], 'web_link': 'https://opendev.org/openstack/releases/commit/3d32a7f22c90199965c0538cc88a5e57f869e196', 'message': ""[oslo] Transition Rocky to End of Life\n\nAs discussed in the mail thread [1][2], this patch transition the Rocky\nbranch to End of Life. The last patch of the branch will be tagged with\nrocky-eol tag. stable/rocky branch cannot be used anymore and will be\ndeleted if this patch merges.\n\nThis is needed as stable/rocky is not actively maintained in recent\nperiod, thus gates are mostly broken due to job failures. Besides,\nby removing these branches, infra resources will be freed up, too.\n\nPlease try to identify any zuul job, that is defined outside of the\nrepositories in this patch (for example in openstack-zuul-jobs, etc.)\nand won't be used anymore if stable/rocky is deleted. Propose a job\nremoval patch for them.\n\nPlease +1 if the team is ready for us to proceed with this transition,\nor -1 if there are still some activity on the branch and the team wants\nto continue to maintain it.\n\n[1] https://lists.openstack.org/pipermail/openstack-discuss/2023-January/031922.html\n[2] https://lists.openstack.org/pipermail/openstack-discuss/2023-April/033386.html\n\nChange-Id: I92e9df123756a849c0f37f50717d51be580afe44\n""}]",1,887946,3d32a7f22c90199965c0538cc88a5e57f869e196,8,4,1,17685,,,0,"[oslo] Transition Rocky to End of Life

As discussed in the mail thread [1][2], this patch transition the Rocky
branch to End of Life. The last patch of the branch will be tagged with
rocky-eol tag. stable/rocky branch cannot be used anymore and will be
deleted if this patch merges.

This is needed as stable/rocky is not actively maintained in recent
period, thus gates are mostly broken due to job failures. Besides,
by removing these branches, infra resources will be freed up, too.

Please try to identify any zuul job, that is defined outside of the
repositories in this patch (for example in openstack-zuul-jobs, etc.)
and won't be used anymore if stable/rocky is deleted. Propose a job
removal patch for them.

Please +1 if the team is ready for us to proceed with this transition,
or -1 if there are still some activity on the branch and the team wants
to continue to maintain it.

[1] https://lists.openstack.org/pipermail/openstack-discuss/2023-January/031922.html
[2] https://lists.openstack.org/pipermail/openstack-discuss/2023-April/033386.html

Change-Id: I92e9df123756a849c0f37f50717d51be580afe44
",git fetch https://review.opendev.org/openstack/releases refs/changes/46/887946/1 && git format-patch -1 --stdout FETCH_HEAD,"['deliverables/rocky/devstack-plugin-kafka.yaml', 'deliverables/rocky/devstack-plugin-amqp1.yaml']",2,3d32a7f22c90199965c0538cc88a5e57f869e196,rocky-eol,releases: - version: rocky-eol projects: - repo: openstack/devstack-plugin-amqp1 hash: cf07f5f9c54e60fc49ca05057e3dee4ca6e76581,,10,0
openstack%2Freleases~887945,openstack/releases,master,I2b2a9c82d68d65dbb0fb270887ace4ff0a66febd,[Packaging-rpm] Transition Rocky to End of Life,MERGED,2023-07-07 12:06:15.000000000,2023-07-07 13:17:55.000000000,2023-07-07 13:17:55.000000000,"[{'_account_id': 17685}, {'_account_id': 22348}, {'_account_id': 28522}]","[{'number': 1, 'created': '2023-07-07 12:06:15.000000000', 'files': ['deliverables/rocky/rpm-packaging.yaml'], 'web_link': 'https://opendev.org/openstack/releases/commit/907ead1c5c38d269ea57ce4706013a8756c26ba5', 'message': ""[Packaging-rpm] Transition Rocky to End of Life\n\nAs discussed in the mail thread [1][2], this patch transition the Rocky\nbranch to End of Life. The last patch of the branch will be tagged with\nrocky-eol tag. stable/rocky branch cannot be used anymore and will be\ndeleted if this patch merges.\n\nThis is needed as stable/rocky is not actively maintained in recent\nperiod, thus gates are mostly broken due to job failures. Besides,\nby removing these branches, infra resources will be freed up, too.\n\nPlease try to identify any zuul job, that is defined outside of the\nrepositories in this patch (for example in openstack-zuul-jobs, etc.)\nand won't be used anymore if stable/rocky is deleted. Propose a job\nremoval patch for them.\n\nPlease +1 if the team is ready for us to proceed with this transition,\nor -1 if there are still some activity on the branch and the team wants\nto continue to maintain it.\n\n[1] https://lists.openstack.org/pipermail/openstack-discuss/2023-January/031922.html\n[2] https://lists.openstack.org/pipermail/openstack-discuss/2023-April/033386.html\n\nChange-Id: I2b2a9c82d68d65dbb0fb270887ace4ff0a66febd\n""}]",1,887945,907ead1c5c38d269ea57ce4706013a8756c26ba5,7,3,1,17685,,,0,"[Packaging-rpm] Transition Rocky to End of Life

As discussed in the mail thread [1][2], this patch transition the Rocky
branch to End of Life. The last patch of the branch will be tagged with
rocky-eol tag. stable/rocky branch cannot be used anymore and will be
deleted if this patch merges.

This is needed as stable/rocky is not actively maintained in recent
period, thus gates are mostly broken due to job failures. Besides,
by removing these branches, infra resources will be freed up, too.

Please try to identify any zuul job, that is defined outside of the
repositories in this patch (for example in openstack-zuul-jobs, etc.)
and won't be used anymore if stable/rocky is deleted. Propose a job
removal patch for them.

Please +1 if the team is ready for us to proceed with this transition,
or -1 if there are still some activity on the branch and the team wants
to continue to maintain it.

[1] https://lists.openstack.org/pipermail/openstack-discuss/2023-January/031922.html
[2] https://lists.openstack.org/pipermail/openstack-discuss/2023-April/033386.html

Change-Id: I2b2a9c82d68d65dbb0fb270887ace4ff0a66febd
",git fetch https://review.opendev.org/openstack/releases refs/changes/45/887945/1 && git format-patch -1 --stdout FETCH_HEAD,['deliverables/rocky/rpm-packaging.yaml'],1,907ead1c5c38d269ea57ce4706013a8756c26ba5,rocky-eol,team: Packaging-rpmreleases: - version: rocky-eol projects: - repo: openstack/rpm-packaging hash: 2a488d9bd16c98665573e55a72b04ffe12dd99da,team: 'Packaging-rpm',6,1
openstack%2Fovn-octavia-provider~887686,openstack/ovn-octavia-provider,stable/zed,Ie4b44c9f15fc9e33a68f9aacd766590b974c63fd,Ensure DVR is restablished on member on cascade deletion,MERGED,2023-07-06 10:56:26.000000000,2023-07-07 13:08:14.000000000,2023-07-07 13:07:16.000000000,"[{'_account_id': 6773}, {'_account_id': 21798}, {'_account_id': 22348}, {'_account_id': 34451}]","[{'number': 1, 'created': '2023-07-06 10:56:26.000000000', 'files': ['ovn_octavia_provider/tests/unit/test_driver.py', 'ovn_octavia_provider/helper.py', 'ovn_octavia_provider/driver.py', 'ovn_octavia_provider/tests/unit/test_helper.py'], 'web_link': 'https://opendev.org/openstack/ovn-octavia-provider/commit/d7040c43703f0b49ae78d2ecfd904dd54bbc7152', 'message': 'Ensure DVR is restablished on member on cascade deletion\n\nTraffic to member, if they have FIPs gets centralized when they\nare part of a loadbalancer. However, when the loadbalancer gets\ndeleted, the traffic should be distributed again (if DVR was\nenabled). To do that this patch also considers the cascade deletion\n\nCloses-Bug: #2025637\nChange-Id: Ie4b44c9f15fc9e33a68f9aacd766590b974c63fd\n(cherry picked from commit 20997b185f21aac8959d7517b4ffb7bc44c1b76a)\n'}]",3,887686,d7040c43703f0b49ae78d2ecfd904dd54bbc7152,17,4,1,23567,,,0,"Ensure DVR is restablished on member on cascade deletion

Traffic to member, if they have FIPs gets centralized when they
are part of a loadbalancer. However, when the loadbalancer gets
deleted, the traffic should be distributed again (if DVR was
enabled). To do that this patch also considers the cascade deletion

Closes-Bug: #2025637
Change-Id: Ie4b44c9f15fc9e33a68f9aacd766590b974c63fd
(cherry picked from commit 20997b185f21aac8959d7517b4ffb7bc44c1b76a)
",git fetch https://review.opendev.org/openstack/ovn-octavia-provider refs/changes/86/887686/1 && git format-patch -1 --stdout FETCH_HEAD,"['ovn_octavia_provider/tests/unit/test_driver.py', 'ovn_octavia_provider/helper.py', 'ovn_octavia_provider/driver.py', 'ovn_octavia_provider/tests/unit/test_helper.py']",4,d7040c43703f0b49ae78d2ecfd904dd54bbc7152,," @mock.patch('ovn_octavia_provider.common.clients.get_neutron_client') def test_lb_delete_port_exception(self, del_port, net_cli):"," def test_lb_delete_port_exception(self, del_port):",37,4
openstack%2Fdesignate~887450,openstack/designate,stable/2023.1,I04c104cfc9ee2f03d0c5adca3c80bbfff20afb70,Fix TsigKeyring issues with dnspython 2.x,MERGED,2023-07-01 07:34:06.000000000,2023-07-07 13:07:56.000000000,2023-07-07 13:06:48.000000000,"[{'_account_id': 11628}, {'_account_id': 13252}, {'_account_id': 22348}]","[{'number': 1, 'created': '2023-07-01 07:34:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/designate/commit/aab7a1e61c58d341b5c816aedc58972b11e6a607', 'message': 'Fix TsigKeyring issues with dnspython 2.x\n\n- Fixed issues in TsigKeyring.\n- Fixed tsgi issues in mdns handler.\n- Fixed invalid secret used in tests.\n- Added additional test coverage.\n- Re-enabled previously broken test.\n\nCloses-Bug: #1982252\nChange-Id: I04c104cfc9ee2f03d0c5adca3c80bbfff20afb70\n(cherry picked from commit 38c591eaa1109e7ea4600563e505dbdbe8a59b37)\n'}, {'number': 2, 'created': '2023-07-01 16:05:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/designate/commit/158130bd713a31cc82f633a937b97acd3e3fd749', 'message': 'Fix TsigKeyring issues with dnspython 2.x\n\n- Fixed issues in TsigKeyring.\n- Fixed tsgi issues in mdns handler.\n- Fixed invalid secret used in tests.\n- Added additional test coverage.\n- Re-enabled previously broken test.\n\nCloses-Bug: #1982252\nChange-Id: I04c104cfc9ee2f03d0c5adca3c80bbfff20afb70\n(cherry picked from commit 38c591eaa1109e7ea4600563e505dbdbe8a59b37)\n'}, {'number': 3, 'created': '2023-07-02 09:49:09.000000000', 'files': ['designate/tests/__init__.py', 'designate/mdns/handler.py', 'designate/dnsutils.py', 'designate/tests/test_dnsutils.py', 'designate/tests/test_mdns/test_handler.py'], 'web_link': 'https://opendev.org/openstack/designate/commit/bc87a7daac78f973d945aef6fee6a55ac46c5ce4', 'message': 'Fix TsigKeyring issues with dnspython 2.x\n\n- Fixed issues in TsigKeyring.\n- Fixed tsgi issues in mdns handler.\n- Fixed invalid secret used in tests.\n- Added additional test coverage.\n- Re-enabled previously broken test.\n\nAdditionally modified unit test to provide a storage provider,\nas this does not exist in the next release.\n\nCloses-Bug: #1982252\nChange-Id: I04c104cfc9ee2f03d0c5adca3c80bbfff20afb70\n(cherry picked from commit 38c591eaa1109e7ea4600563e505dbdbe8a59b37)\n'}]",5,887450,bc87a7daac78f973d945aef6fee6a55ac46c5ce4,20,3,3,13252,,,0,"Fix TsigKeyring issues with dnspython 2.x

- Fixed issues in TsigKeyring.
- Fixed tsgi issues in mdns handler.
- Fixed invalid secret used in tests.
- Added additional test coverage.
- Re-enabled previously broken test.

Additionally modified unit test to provide a storage provider,
as this does not exist in the next release.

Closes-Bug: #1982252
Change-Id: I04c104cfc9ee2f03d0c5adca3c80bbfff20afb70
(cherry picked from commit 38c591eaa1109e7ea4600563e505dbdbe8a59b37)
",git fetch https://review.opendev.org/openstack/designate refs/changes/50/887450/1 && git format-patch -1 --stdout FETCH_HEAD,"['designate/tests/__init__.py', 'designate/mdns/handler.py', 'designate/dnsutils.py', 'designate/tests/test_dnsutils.py', 'designate/tests/test_mdns/test_handler.py']",5,aab7a1e61c58d341b5c816aedc58972b11e6a607,,"import dns.tsigkeyring request.use_tsig(dns.tsigkeyring.from_text( {'test-key-two': 'AnotherSecretKey'}) ) args = [request.keyname, request.keyring.secret, 300, request.id, request.tsig_error, b'', request.mac, request.keyalgorithm]","from unittest import expectedFailure @expectedFailure request.keyring = {request.keyname: ''} request.had_tsig = True args = [request.keyname, request.keyring[request.keyname], request.fudge, request.original_id, request.tsig_error, request.other_data, request.mac, request.keyalgorithm]",99,16
openstack%2Foctavia~878816,openstack/octavia,master,I59f1ed85383c078f505c654b1acf3e2a22d11faa,Fix octavia-status with amphorav2,MERGED,2023-03-29 08:13:34.000000000,2023-07-07 11:55:26.000000000,2023-07-07 11:53:26.000000000,"[{'_account_id': 11628}, {'_account_id': 22348}, {'_account_id': 29244}, {'_account_id': 32238}, {'_account_id': 34429}]","[{'number': 1, 'created': '2023-03-29 08:13:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/octavia/commit/cfe19cd9f52c64cd180360360ca66acfc9a82873', 'message': 'Fix octavia-status with amphorav2\n\nChange-Id: I59f1ed85383c078f505c654b1acf3e2a22d11faa\n'}, {'number': 2, 'created': '2023-04-05 15:04:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/octavia/commit/bfd743324daea3b8d071d42b8afff67ad136c1fe', 'message': 'Fix octavia-status with amphorav2\n\nChange-Id: I59f1ed85383c078f505c654b1acf3e2a22d11faa\n'}, {'number': 3, 'created': '2023-04-07 08:30:00.000000000', 'files': ['octavia/cmd/status.py', 'octavia/tests/unit/cmd/test_status.py', 'releasenotes/notes/fix-octavia-status-amphorav2-038fe77a2189b99f.yaml'], 'web_link': 'https://opendev.org/openstack/octavia/commit/1771f6acf9255e0ba80a8e5e68a8d1865daaae30', 'message': 'Fix octavia-status with amphorav2\n\nChange-Id: I59f1ed85383c078f505c654b1acf3e2a22d11faa\n'}]",4,878816,1771f6acf9255e0ba80a8e5e68a8d1865daaae30,23,5,3,29244,,,0,"Fix octavia-status with amphorav2

Change-Id: I59f1ed85383c078f505c654b1acf3e2a22d11faa
",git fetch https://review.opendev.org/openstack/octavia refs/changes/16/878816/1 && git format-patch -1 --stdout FETCH_HEAD,"['octavia/cmd/status.py', 'octavia/tests/unit/cmd/test_status.py', 'releasenotes/notes/fix-octavia-status-amphorav2-038fe77a2189b99f.yaml']",3,cfe19cd9f52c64cd180360360ca66acfc9a82873,amphorav1-removal,--- fixes: - | Fixed a bug in octavia-status which reported an incorrect status for the *amphorav2* driver when using the default *amphora* alias. ,,8,4
openstack%2Foctavia~876480,openstack/octavia,master,I16430fa52db02e7445203994220673c1037d764c,Fix upgrade check not working,MERGED,2023-03-05 22:18:44.000000000,2023-07-07 11:24:45.000000000,2023-07-07 11:23:37.000000000,"[{'_account_id': 22348}, {'_account_id': 29244}, {'_account_id': 32238}, {'_account_id': 34429}]","[{'number': 1, 'created': '2023-03-05 22:18:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/octavia/commit/c27e90136203579e6e8c956e06780ce40d1a7ad1', 'message': ""Fix upgrade check not working\n\nThe octavia-status upgrade check command fails because\nthe initialization of Policy() requires oslo_config to\nbe initialized already which it isn't.\n\nThis can be reproduced in master by running:\n\n  tox -e venv -- octavia-status upgrade check\n\nI can observe this issue multiple relases back which\nprobably means this has been broken for a long time.\n\nWe shouldn't need to init Policy() because it just\nloads policy rules which is not checked in upgrade\ncheck anyway.\n\nChange-Id: I16430fa52db02e7445203994220673c1037d764c\n""}, {'number': 2, 'created': '2023-03-06 15:30:25.000000000', 'files': ['octavia/cmd/status.py'], 'web_link': 'https://opendev.org/openstack/octavia/commit/47de8fa3444cc7b1b68d486ad8c06d294a9ef9de', 'message': ""Fix upgrade check not working\n\nThe octavia-status upgrade check command fails because\nthe initialization of Policy() requires oslo_config to\nbe initialized already which it isn't.\n\nThis can be reproduced in master by running:\n\n  tox -e venv -- octavia-status upgrade check\n\nI can observe this issue multiple relases back which\nprobably means this has been broken for a long time.\n\nWe shouldn't need to init Policy() because it just\nloads policy rules which is not checked in upgrade\ncheck anyway.\n\nChange-Id: I16430fa52db02e7445203994220673c1037d764c\n""}]",7,876480,47de8fa3444cc7b1b68d486ad8c06d294a9ef9de,24,4,2,16137,,,0,"Fix upgrade check not working

The octavia-status upgrade check command fails because
the initialization of Policy() requires oslo_config to
be initialized already which it isn't.

This can be reproduced in master by running:

  tox -e venv -- octavia-status upgrade check

I can observe this issue multiple relases back which
probably means this has been broken for a long time.

We shouldn't need to init Policy() because it just
loads policy rules which is not checked in upgrade
check anyway.

Change-Id: I16430fa52db02e7445203994220673c1037d764c
",git fetch https://review.opendev.org/openstack/octavia refs/changes/80/876480/1 && git format-patch -1 --stdout FETCH_HEAD,['octavia/cmd/status.py'],1,c27e90136203579e6e8c956e06780ce40d1a7ad1,,, policy.Policy(),0,1
openstack%2Fovn-octavia-provider~887688,openstack/ovn-octavia-provider,stable/xena,Ie4b44c9f15fc9e33a68f9aacd766590b974c63fd,Ensure DVR is restablished on member on cascade deletion,MERGED,2023-07-06 10:56:55.000000000,2023-07-07 10:26:56.000000000,2023-07-07 10:25:50.000000000,"[{'_account_id': 6773}, {'_account_id': 21798}, {'_account_id': 22348}, {'_account_id': 34451}]","[{'number': 1, 'created': '2023-07-06 10:56:55.000000000', 'files': ['ovn_octavia_provider/tests/unit/test_driver.py', 'ovn_octavia_provider/helper.py', 'ovn_octavia_provider/driver.py', 'ovn_octavia_provider/tests/unit/test_helper.py'], 'web_link': 'https://opendev.org/openstack/ovn-octavia-provider/commit/cf17c25aa63a37fc9add2b96a5b778e3190018c7', 'message': 'Ensure DVR is restablished on member on cascade deletion\n\nTraffic to member, if they have FIPs gets centralized when they\nare part of a loadbalancer. However, when the loadbalancer gets\ndeleted, the traffic should be distributed again (if DVR was\nenabled). To do that this patch also considers the cascade deletion\n\nCloses-Bug: #2025637\nChange-Id: Ie4b44c9f15fc9e33a68f9aacd766590b974c63fd\n(cherry picked from commit 20997b185f21aac8959d7517b4ffb7bc44c1b76a)\n'}]",0,887688,cf17c25aa63a37fc9add2b96a5b778e3190018c7,9,4,1,23567,,,0,"Ensure DVR is restablished on member on cascade deletion

Traffic to member, if they have FIPs gets centralized when they
are part of a loadbalancer. However, when the loadbalancer gets
deleted, the traffic should be distributed again (if DVR was
enabled). To do that this patch also considers the cascade deletion

Closes-Bug: #2025637
Change-Id: Ie4b44c9f15fc9e33a68f9aacd766590b974c63fd
(cherry picked from commit 20997b185f21aac8959d7517b4ffb7bc44c1b76a)
",git fetch https://review.opendev.org/openstack/ovn-octavia-provider refs/changes/88/887688/1 && git format-patch -1 --stdout FETCH_HEAD,"['ovn_octavia_provider/tests/unit/test_driver.py', 'ovn_octavia_provider/helper.py', 'ovn_octavia_provider/driver.py', 'ovn_octavia_provider/tests/unit/test_helper.py']",4,cf17c25aa63a37fc9add2b96a5b778e3190018c7,," @mock.patch('ovn_octavia_provider.common.clients.get_neutron_client') def test_lb_delete_port_exception(self, del_port, net_cli):"," def test_lb_delete_port_exception(self, del_port):",37,4
openstack%2Fovn-octavia-provider~887689,openstack/ovn-octavia-provider,stable/wallaby,Ie4b44c9f15fc9e33a68f9aacd766590b974c63fd,Ensure DVR is restablished on member on cascade deletion,MERGED,2023-07-06 10:57:11.000000000,2023-07-07 10:23:46.000000000,2023-07-07 10:22:35.000000000,"[{'_account_id': 6773}, {'_account_id': 21798}, {'_account_id': 22348}, {'_account_id': 34451}]","[{'number': 1, 'created': '2023-07-06 10:57:11.000000000', 'files': ['ovn_octavia_provider/tests/unit/test_driver.py', 'ovn_octavia_provider/helper.py', 'ovn_octavia_provider/driver.py', 'ovn_octavia_provider/tests/unit/test_helper.py'], 'web_link': 'https://opendev.org/openstack/ovn-octavia-provider/commit/3fa41be337aa19ec3affff20cded74810c63a17e', 'message': 'Ensure DVR is restablished on member on cascade deletion\n\nTraffic to member, if they have FIPs gets centralized when they\nare part of a loadbalancer. However, when the loadbalancer gets\ndeleted, the traffic should be distributed again (if DVR was\nenabled). To do that this patch also considers the cascade deletion\n\nCloses-Bug: #2025637\nChange-Id: Ie4b44c9f15fc9e33a68f9aacd766590b974c63fd\n(cherry picked from commit 20997b185f21aac8959d7517b4ffb7bc44c1b76a)\n'}]",0,887689,3fa41be337aa19ec3affff20cded74810c63a17e,9,4,1,23567,,,0,"Ensure DVR is restablished on member on cascade deletion

Traffic to member, if they have FIPs gets centralized when they
are part of a loadbalancer. However, when the loadbalancer gets
deleted, the traffic should be distributed again (if DVR was
enabled). To do that this patch also considers the cascade deletion

Closes-Bug: #2025637
Change-Id: Ie4b44c9f15fc9e33a68f9aacd766590b974c63fd
(cherry picked from commit 20997b185f21aac8959d7517b4ffb7bc44c1b76a)
",git fetch https://review.opendev.org/openstack/ovn-octavia-provider refs/changes/89/887689/1 && git format-patch -1 --stdout FETCH_HEAD,"['ovn_octavia_provider/tests/unit/test_driver.py', 'ovn_octavia_provider/helper.py', 'ovn_octavia_provider/driver.py', 'ovn_octavia_provider/tests/unit/test_helper.py']",4,3fa41be337aa19ec3affff20cded74810c63a17e,," @mock.patch('ovn_octavia_provider.common.clients.get_neutron_client') def test_lb_delete_port_exception(self, del_port, net_cli):"," def test_lb_delete_port_exception(self, del_port):",37,4
openstack%2Fovn-octavia-provider~887687,openstack/ovn-octavia-provider,stable/yoga,Ie4b44c9f15fc9e33a68f9aacd766590b974c63fd,Ensure DVR is restablished on member on cascade deletion,MERGED,2023-07-06 10:56:37.000000000,2023-07-07 10:23:44.000000000,2023-07-07 10:22:33.000000000,"[{'_account_id': 6773}, {'_account_id': 21798}, {'_account_id': 22348}, {'_account_id': 34451}]","[{'number': 1, 'created': '2023-07-06 10:56:37.000000000', 'files': ['ovn_octavia_provider/tests/unit/test_driver.py', 'ovn_octavia_provider/helper.py', 'ovn_octavia_provider/driver.py', 'ovn_octavia_provider/tests/unit/test_helper.py'], 'web_link': 'https://opendev.org/openstack/ovn-octavia-provider/commit/72cd160214d211710f2b512a0ac96dd35c798c9f', 'message': 'Ensure DVR is restablished on member on cascade deletion\n\nTraffic to member, if they have FIPs gets centralized when they\nare part of a loadbalancer. However, when the loadbalancer gets\ndeleted, the traffic should be distributed again (if DVR was\nenabled). To do that this patch also considers the cascade deletion\n\nCloses-Bug: #2025637\nChange-Id: Ie4b44c9f15fc9e33a68f9aacd766590b974c63fd\n(cherry picked from commit 20997b185f21aac8959d7517b4ffb7bc44c1b76a)\n'}]",0,887687,72cd160214d211710f2b512a0ac96dd35c798c9f,9,4,1,23567,,,0,"Ensure DVR is restablished on member on cascade deletion

Traffic to member, if they have FIPs gets centralized when they
are part of a loadbalancer. However, when the loadbalancer gets
deleted, the traffic should be distributed again (if DVR was
enabled). To do that this patch also considers the cascade deletion

Closes-Bug: #2025637
Change-Id: Ie4b44c9f15fc9e33a68f9aacd766590b974c63fd
(cherry picked from commit 20997b185f21aac8959d7517b4ffb7bc44c1b76a)
",git fetch https://review.opendev.org/openstack/ovn-octavia-provider refs/changes/87/887687/1 && git format-patch -1 --stdout FETCH_HEAD,"['ovn_octavia_provider/tests/unit/test_driver.py', 'ovn_octavia_provider/helper.py', 'ovn_octavia_provider/driver.py', 'ovn_octavia_provider/tests/unit/test_helper.py']",4,72cd160214d211710f2b512a0ac96dd35c798c9f,," @mock.patch('ovn_octavia_provider.common.clients.get_neutron_client') def test_lb_delete_port_exception(self, del_port, net_cli):"," def test_lb_delete_port_exception(self, del_port):",37,4
openstack%2Fneutron~887854,openstack/neutron,stable/2023.1,I1fef7e225d631d581cb9f25982ba2e09b6f35fa8,[2023.1 Only] Switch to 2023.1 neutron-tempest-plugin jobs,MERGED,2023-07-06 14:20:19.000000000,2023-07-07 10:04:53.000000000,2023-07-07 10:02:37.000000000,"[{'_account_id': 8313}, {'_account_id': 16688}, {'_account_id': 22348}]","[{'number': 1, 'created': '2023-07-06 14:20:19.000000000', 'files': ['zuul.d/project.yaml'], 'web_link': 'https://opendev.org/openstack/neutron/commit/e0c387f4e088b1c61943074fc7d161e3f883d38a', 'message': '[2023.1 Only] Switch to 2023.1 neutron-tempest-plugin jobs\n\nChange-Id: I1fef7e225d631d581cb9f25982ba2e09b6f35fa8\n'}]",0,887854,e0c387f4e088b1c61943074fc7d161e3f883d38a,8,3,1,13861,,,0,"[2023.1 Only] Switch to 2023.1 neutron-tempest-plugin jobs

Change-Id: I1fef7e225d631d581cb9f25982ba2e09b6f35fa8
",git fetch https://review.opendev.org/openstack/neutron refs/changes/54/887854/1 && git format-patch -1 --stdout FETCH_HEAD,['zuul.d/project.yaml'],1,e0c387f4e088b1c61943074fc7d161e3f883d38a,antelope_release, - neutron-tempest-plugin-jobs-2023-1, - neutron-tempest-plugin-jobs,1,1
openstack%2Fovn-octavia-provider~887685,openstack/ovn-octavia-provider,stable/2023.1,Ie4b44c9f15fc9e33a68f9aacd766590b974c63fd,Ensure DVR is restablished on member on cascade deletion,MERGED,2023-07-06 10:56:02.000000000,2023-07-07 09:58:55.000000000,2023-07-07 09:57:59.000000000,"[{'_account_id': 6773}, {'_account_id': 21798}, {'_account_id': 22348}, {'_account_id': 34451}]","[{'number': 1, 'created': '2023-07-06 10:56:02.000000000', 'files': ['ovn_octavia_provider/tests/unit/test_driver.py', 'ovn_octavia_provider/helper.py', 'ovn_octavia_provider/driver.py', 'ovn_octavia_provider/tests/unit/test_helper.py'], 'web_link': 'https://opendev.org/openstack/ovn-octavia-provider/commit/b423ff94260828389b020700148a0096c6fb52c4', 'message': 'Ensure DVR is restablished on member on cascade deletion\n\nTraffic to member, if they have FIPs gets centralized when they\nare part of a loadbalancer. However, when the loadbalancer gets\ndeleted, the traffic should be distributed again (if DVR was\nenabled). To do that this patch also considers the cascade deletion\n\nCloses-Bug: #2025637\nChange-Id: Ie4b44c9f15fc9e33a68f9aacd766590b974c63fd\n(cherry picked from commit 20997b185f21aac8959d7517b4ffb7bc44c1b76a)\n'}]",1,887685,b423ff94260828389b020700148a0096c6fb52c4,9,4,1,23567,,,0,"Ensure DVR is restablished on member on cascade deletion

Traffic to member, if they have FIPs gets centralized when they
are part of a loadbalancer. However, when the loadbalancer gets
deleted, the traffic should be distributed again (if DVR was
enabled). To do that this patch also considers the cascade deletion

Closes-Bug: #2025637
Change-Id: Ie4b44c9f15fc9e33a68f9aacd766590b974c63fd
(cherry picked from commit 20997b185f21aac8959d7517b4ffb7bc44c1b76a)
",git fetch https://review.opendev.org/openstack/ovn-octavia-provider refs/changes/85/887685/1 && git format-patch -1 --stdout FETCH_HEAD,"['ovn_octavia_provider/tests/unit/test_driver.py', 'ovn_octavia_provider/helper.py', 'ovn_octavia_provider/driver.py', 'ovn_octavia_provider/tests/unit/test_helper.py']",4,b423ff94260828389b020700148a0096c6fb52c4,," @mock.patch('ovn_octavia_provider.common.clients.get_neutron_client') def test_lb_delete_port_exception(self, del_port, net_cli):"," def test_lb_delete_port_exception(self, del_port):",37,4
openstack%2Fkolla-ansible~874280,openstack/kolla-ansible,master,I01b0afc0d32d1d3aed4e6d9fe6a1849a5ba6541e,[CI]Fix designate scenario,ABANDONED,2023-02-17 16:57:57.000000000,2023-07-07 09:01:24.000000000,,[{'_account_id': 22348}],"[{'number': 1, 'created': '2023-02-17 16:57:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/d358d26e6ba15827ab4d8342f3eb9c66b49b8b46', 'message': '[CI]Fix designate scenario\n\nChange-Id: I01b0afc0d32d1d3aed4e6d9fe6a1849a5ba6541e\n'}, {'number': 2, 'created': '2023-02-19 09:48:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/78381dc60aac7a93331d353b0b3374210cf3bb94', 'message': '[CI]Fix designate scenario\n\nChange-Id: I01b0afc0d32d1d3aed4e6d9fe6a1849a5ba6541e\n'}, {'number': 3, 'created': '2023-02-19 15:51:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/bddd7b864c923bf484fc6859eef74c7d7946d5ce', 'message': '[CI]Fix designate scenario\n\nChange-Id: I01b0afc0d32d1d3aed4e6d9fe6a1849a5ba6541e\n'}, {'number': 4, 'created': '2023-02-20 13:12:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/f9726eb28c7eaff38df84e9321c8e03d767ca210', 'message': '[CI]Fix designate scenario\n\nChange-Id: I01b0afc0d32d1d3aed4e6d9fe6a1849a5ba6541e\n'}, {'number': 5, 'created': '2023-02-20 14:11:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/35380880a26725a48e759fb210fd7fec3f5c97ce', 'message': '[CI]Fix designate scenario\n\nChange-Id: I01b0afc0d32d1d3aed4e6d9fe6a1849a5ba6541e\n'}, {'number': 6, 'created': '2023-02-21 01:31:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/4b336ef4fe89cb95577c38d07b71e289c92c18ef', 'message': '[CI]Fix designate scenario\n\nChange-Id: I01b0afc0d32d1d3aed4e6d9fe6a1849a5ba6541e\n'}, {'number': 7, 'created': '2023-02-21 04:40:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/aba51e92c902158b2e4308624e5e350eafba571b', 'message': '[CI]Fix designate scenario\n\nChange-Id: I01b0afc0d32d1d3aed4e6d9fe6a1849a5ba6541e\n'}, {'number': 8, 'created': '2023-02-21 09:13:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/c99e741b726d53b5146752d77ba53f0dc0db5cf5', 'message': '[CI]Fix designate scenario\n\nChange-Id: I01b0afc0d32d1d3aed4e6d9fe6a1849a5ba6541e\n'}, {'number': 9, 'created': '2023-02-21 12:56:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/c203d681db9b1f0e4f0ae0f3c8274b5a7d63e049', 'message': '[CI]Fix designate scenario\n\nChange-Id: I01b0afc0d32d1d3aed4e6d9fe6a1849a5ba6541e\n'}, {'number': 10, 'created': '2023-02-22 15:07:11.000000000', 'files': ['tests/templates/globals-default.j2'], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/f57d6bf98c57e94aad2e36e102a66934f9599a7f', 'message': '[CI]Fix designate scenario\n\nChange-Id: I01b0afc0d32d1d3aed4e6d9fe6a1849a5ba6541e\n'}]",0,874280,f57d6bf98c57e94aad2e36e102a66934f9599a7f,26,1,10,26285,,,0,"[CI]Fix designate scenario

Change-Id: I01b0afc0d32d1d3aed4e6d9fe6a1849a5ba6541e
",git fetch https://review.opendev.org/openstack/kolla-ansible refs/changes/80/874280/1 && git format-patch -1 --stdout FETCH_HEAD,"['tests/test-magnum.sh', 'zuul.d/project.yaml']",2,d358d26e6ba15827ab4d8342f3eb9c66b49b8b46,designate-ci, # - kolla-ansible-centos9s # - kolla-ansible-debian # - kolla-ansible-openeuler # - kolla-ansible-rocky9 # - kolla-ansible-ubuntu # - kolla-ansible-rocky9-kvm # - kolla-ansible-ubuntu-kvm # - kolla-ansible-rocky9-multinode-ipv6 # - kolla-ansible-ubuntu-multinode-ipv6 # - kolla-ansible-rocky9-bifrost # - kolla-ansible-ubuntu-bifrost # - kolla-ansible-rocky9-zun # - kolla-ansible-debian-zun # - kolla-ansible-ubuntu-zun # - kolla-ansible-rocky9-swift # - kolla-ansible-ubuntu-swift # - kolla-ansible-rocky9-scenario-nfv # - kolla-ansible-rocky9-octavia # - kolla-ansible-ubuntu-octavia # - kolla-ansible-rocky9-masakari # - kolla-ansible-ubuntu-masakari # - kolla-ansible-rocky9-ironic # - kolla-ansible-debian-ironic # - kolla-ansible-ubuntu-ironic # - kolla-ansible-rocky9-upgrade # - kolla-ansible-debian-upgrade # - kolla-ansible-ubuntu-upgrade # - kolla-ansible-ubuntu-binary-upgrade # - kolla-ansible-ubuntu-cells # - kolla-ansible-rocky9-cells # - kolla-ansible-rocky9-mariadb # - kolla-ansible-ubuntu-mariadb # - kolla-ansible-rocky9-ovn # - kolla-ansible-ubuntu-ovn # - kolla-ansible-rocky9-upgrade-ovn # - kolla-ansible-ubuntu-upgrade-ovn # - kolla-ansible-rocky9-prometheus-opensearch # - kolla-ansible-ubuntu-prometheus-opensearch # - kolla-ansible-rocky9-prometheus-opensearch-upgrade # - kolla-ansible-ubuntu-prometheus-opensearch-upgrade # - kolla-ansible-rocky9-venus # - kolla-ansible-ubuntu-venus # - kolla-ansible-rocky9-cephadm # - kolla-ansible-ubuntu-cephadm # - kolla-ansible-rocky9-upgrade-cephadm # - kolla-ansible-ubuntu-upgrade-cephadm # - kolla-ansible-rocky9-hashi-vault, - kolla-ansible-centos9s - kolla-ansible-debian - kolla-ansible-openeuler - kolla-ansible-rocky9 - kolla-ansible-ubuntu - kolla-ansible-rocky9-kvm - kolla-ansible-ubuntu-kvm - kolla-ansible-rocky9-multinode-ipv6 - kolla-ansible-ubuntu-multinode-ipv6 - kolla-ansible-rocky9-bifrost - kolla-ansible-ubuntu-bifrost - kolla-ansible-rocky9-zun - kolla-ansible-debian-zun - kolla-ansible-ubuntu-zun - kolla-ansible-rocky9-swift - kolla-ansible-ubuntu-swift - kolla-ansible-rocky9-scenario-nfv - kolla-ansible-rocky9-octavia - kolla-ansible-ubuntu-octavia - kolla-ansible-rocky9-masakari - kolla-ansible-ubuntu-masakari - kolla-ansible-rocky9-ironic - kolla-ansible-debian-ironic - kolla-ansible-ubuntu-ironic - kolla-ansible-rocky9-upgrade - kolla-ansible-debian-upgrade - kolla-ansible-ubuntu-upgrade - kolla-ansible-ubuntu-binary-upgrade - kolla-ansible-ubuntu-cells - kolla-ansible-rocky9-cells - kolla-ansible-rocky9-mariadb - kolla-ansible-ubuntu-mariadb - kolla-ansible-rocky9-ovn - kolla-ansible-ubuntu-ovn - kolla-ansible-rocky9-upgrade-ovn - kolla-ansible-ubuntu-upgrade-ovn - kolla-ansible-rocky9-prometheus-opensearch - kolla-ansible-ubuntu-prometheus-opensearch - kolla-ansible-rocky9-prometheus-opensearch-upgrade - kolla-ansible-ubuntu-prometheus-opensearch-upgrade - kolla-ansible-rocky9-venus - kolla-ansible-ubuntu-venus - kolla-ansible-rocky9-cephadm - kolla-ansible-ubuntu-cephadm - kolla-ansible-rocky9-upgrade-cephadm - kolla-ansible-ubuntu-upgrade-cephadm - kolla-ansible-rocky9-hashi-vault,49,47
openstack%2Fproject-config~887909,openstack/project-config,master,Idd8e0b269738e771995bf4744f44dcd187c8d46e,Normalize projects.yaml,MERGED,2023-07-07 02:51:20.000000000,2023-07-07 08:56:06.000000000,2023-07-07 08:50:36.000000000,"[{'_account_id': 6547}, {'_account_id': 22348}]","[{'number': 1, 'created': '2023-07-07 02:51:20.000000000', 'files': ['gerrit/projects.yaml'], 'web_link': 'https://opendev.org/openstack/project-config/commit/39d0b03ce6cbc0f4ee188b339322bd0b893e028e', 'message': 'Normalize projects.yaml\n\nChange-Id: Idd8e0b269738e771995bf4744f44dcd187c8d46e\n'}]",1,887909,39d0b03ce6cbc0f4ee188b339322bd0b893e028e,7,2,1,11131,,,0,"Normalize projects.yaml

Change-Id: Idd8e0b269738e771995bf4744f44dcd187c8d46e
",git fetch https://review.opendev.org/openstack/project-config refs/changes/09/887909/1 && git format-patch -1 --stdout FETCH_HEAD,['gerrit/projects.yaml'],1,39d0b03ce6cbc0f4ee188b339322bd0b893e028e,project-yaml-normalization,, upstream: https://github.com/openstack-charmers/charm-barbican-k8s.git upstream: https://github.com/freyes/charm-heat-k8s.git,0,2
openstack%2Fceilometer~886560,openstack/ceilometer,master,I0cfb559ca95f9457c48a9173331f2ccb7660d25c,Imported Translations from Zanata,MERGED,2023-06-21 03:32:08.000000000,2023-07-07 08:43:09.000000000,2023-07-07 08:42:05.000000000,"[{'_account_id': 4264}, {'_account_id': 22348}]","[{'number': 1, 'created': '2023-06-21 03:32:08.000000000', 'files': ['releasenotes/source/locale/en_GB/LC_MESSAGES/releasenotes.po'], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/cb7244148df3a2cf205a102da030c7d3f96a0152', 'message': 'Imported Translations from Zanata\n\nFor more information about this automatic import see:\nhttps://docs.openstack.org/i18n/latest/reviewing-translation-import.html\n\nChange-Id: I0cfb559ca95f9457c48a9173331f2ccb7660d25c\n'}]",0,886560,cb7244148df3a2cf205a102da030c7d3f96a0152,7,2,1,11131,,,0,"Imported Translations from Zanata

For more information about this automatic import see:
https://docs.openstack.org/i18n/latest/reviewing-translation-import.html

Change-Id: I0cfb559ca95f9457c48a9173331f2ccb7660d25c
",git fetch https://review.opendev.org/openstack/ceilometer refs/changes/60/886560/1 && git format-patch -1 --stdout FETCH_HEAD,['releasenotes/source/locale/en_GB/LC_MESSAGES/releasenotes.po'],1,cb7244148df3a2cf205a102da030c7d3f96a0152,zanata/translations,"""POT-Creation-Date: 2023-06-19 06:37+0000\n""""PO-Revision-Date: 2023-06-20 11:18+0000\n""msgid ""20.0.0-12"" msgstr ""20.0.0-12""","""POT-Creation-Date: 2023-06-15 19:40+0000\n""""PO-Revision-Date: 2023-06-17 02:35+0000\n""msgid ""20.0.0-11"" msgstr ""20.0.0-11""",4,4
openstack%2Fironic~881492,openstack/ironic,master,I145af7d2d1172bc6e4b6b826b633b6b61cbb3384,[DNM] Test new inspection code path,ABANDONED,2023-04-25 16:20:41.000000000,2023-07-07 08:32:54.000000000,,[{'_account_id': 22348}],"[{'number': 1, 'created': '2023-04-25 16:20:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/0da87ad487dc8285a5f97ba4e20ee3a332d0eb04', 'message': '[DNM] Test new inspection code path\n\nChange-Id: I145af7d2d1172bc6e4b6b826b633b6b61cbb3384\n'}, {'number': 2, 'created': '2023-05-03 17:19:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/86697305f79b7950f74ee0b3c80fc7dcea06312a', 'message': '[DNM] Test new inspection code path\n\nChange-Id: I145af7d2d1172bc6e4b6b826b633b6b61cbb3384\n'}, {'number': 3, 'created': '2023-05-05 15:10:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/7d7a93c6ed2bb672e35124d0d065a932edc2f1ee', 'message': '[DNM] Test new inspection code path\n\nChange-Id: I145af7d2d1172bc6e4b6b826b633b6b61cbb3384\n'}, {'number': 4, 'created': '2023-05-26 15:19:28.000000000', 'files': ['ironic/drivers/modules/inspector/interface.py'], 'web_link': 'https://opendev.org/openstack/ironic/commit/4395040813a2cc55cb647105dbfe7e68413f60b2', 'message': '[DNM] Test new inspection code path\n\nChange-Id: I145af7d2d1172bc6e4b6b826b633b6b61cbb3384\n'}]",4,881492,4395040813a2cc55cb647105dbfe7e68413f60b2,16,1,4,10239,,,0,"[DNM] Test new inspection code path

Change-Id: I145af7d2d1172bc6e4b6b826b633b6b61cbb3384
",git fetch https://review.opendev.org/openstack/ironic refs/changes/92/881492/1 && git format-patch -1 --stdout FETCH_HEAD,['ironic/drivers/modules/inspector/interface.py'],1,0da87ad487dc8285a5f97ba4e20ee3a332d0eb04,inspector," # FIXME(dtantsur): do not merge this, only for testing!!! endpoint = deploy_utils.get_ironic_api_url() + ""/v1/continue_inspection"" # end of FIXME",,4,0
openstack%2Fglance~887932,openstack/glance,master,I10904e8f2f524306181080365bf17251dedcb336,Sort locations based on store weight,ABANDONED,2023-07-07 08:22:38.000000000,2023-07-07 08:25:08.000000000,,[],"[{'number': 1, 'created': '2023-07-07 08:22:38.000000000', 'files': ['glance/tests/unit/common/test_utils.py', 'glance/common/utils.py', 'glance/tests/functional/v2/test_images.py', 'releasenotes/notes/store-weight-3ed3ee612579bc25.yaml', 'glance/api/v2/images.py', 'glance/db/__init__.py'], 'web_link': 'https://opendev.org/openstack/glance/commit/6ab2640f66a00275525b1bb0b2b96158162e968a', 'message': 'Sort locations based on store weight\n\nRelated to blueprint store-weight\nChange-Id: I2383a476cb7e79c7efecdf33203cff0b50ef3bbb\n\nChange-Id: I10904e8f2f524306181080365bf17251dedcb336\n'}]",0,887932,6ab2640f66a00275525b1bb0b2b96158162e968a,2,0,1,9303,,,0,"Sort locations based on store weight

Related to blueprint store-weight
Change-Id: I2383a476cb7e79c7efecdf33203cff0b50ef3bbb

Change-Id: I10904e8f2f524306181080365bf17251dedcb336
",git fetch https://review.opendev.org/openstack/glance refs/changes/32/887932/1 && git format-patch -1 --stdout FETCH_HEAD,"['glance/tests/unit/common/test_utils.py', 'glance/common/utils.py', 'glance/tests/functional/v2/test_images.py', 'releasenotes/notes/store-weight-3ed3ee612579bc25.yaml', 'glance/api/v2/images.py', 'glance/db/__init__.py']",6,6ab2640f66a00275525b1bb0b2b96158162e968a,bp/store-weight,"from glance.common import utils as common_utils locations=common_utils.sort_image_locations(locations),","from glance.common import location_strategy locations=location_strategy.get_ordered_locations(locations),",164,4
openstack%2Fcharm-ceph-mon~887733,openstack/charm-ceph-mon,master,I1ca4316aaf4f0b855a12aa582a8188c88e926fa6,Fix ceph-mon upgrade path,MERGED,2023-07-05 19:28:00.000000000,2023-07-07 08:19:47.000000000,2023-07-07 08:19:47.000000000,"[{'_account_id': 15382}, {'_account_id': 20648}, {'_account_id': 22348}]","[{'number': 1, 'created': '2023-07-05 19:28:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-ceph-mon/commit/6bd661f222f58013e9de71f838ab72d7fb3284b9', 'message': 'Fix ceph-mon upgrade path\n\nThis PR makes some small changes in the upgrade path logic by\nproviding a fallback method of fetching the current ceph-mon\nversion and adding additional checks to see if the upgrade can\nbe done in a sane way.\n\nCloses-Bug: #2024253\nChange-Id: I1ca4316aaf4f0b855a12aa582a8188c88e926fa6\n'}, {'number': 2, 'created': '2023-07-06 19:59:45.000000000', 'files': ['src/ceph_hooks.py', 'unit_tests/test_upgrade.py'], 'web_link': 'https://opendev.org/openstack/charm-ceph-mon/commit/1a41aa24ce82c411da936ef3f21c61a57c059155', 'message': 'Fix ceph-mon upgrade path\n\nThis PR makes some small changes in the upgrade path logic by\nproviding a fallback method of fetching the current ceph-mon\nversion and adding additional checks to see if the upgrade can\nbe done in a sane way.\n\nCloses-Bug: #2024253\nChange-Id: I1ca4316aaf4f0b855a12aa582a8188c88e926fa6\n'}]",10,887733,1a41aa24ce82c411da936ef3f21c61a57c059155,12,3,2,33717,,,0,"Fix ceph-mon upgrade path

This PR makes some small changes in the upgrade path logic by
providing a fallback method of fetching the current ceph-mon
version and adding additional checks to see if the upgrade can
be done in a sane way.

Closes-Bug: #2024253
Change-Id: I1ca4316aaf4f0b855a12aa582a8188c88e926fa6
",git fetch https://review.opendev.org/openstack/charm-ceph-mon refs/changes/33/887733/1 && git format-patch -1 --stdout FETCH_HEAD,"['src/ceph_hooks.py', 'unit_tests/test_upgrade.py']",2,6bd661f222f58013e9de71f838ab72d7fb3284b9,fix-upgrade,"from charms_ceph.utils import resolve_ceph_version as resolve_ceph_version_orig @patch('ceph_hooks.ceph.resolve_ceph_version') @patch('ceph_hooks.subprocess.check_output') @patch('ceph_hooks.add_source') @patch('ceph_hooks.ceph.is_bootstrapped') @patch('ceph_hooks.hookenv') @patch('ceph_hooks.ceph.roll_monitor_cluster') def test_check_for_upgrade_no_current_version(self, roll_monitor_cluster, hookenv, is_bootstrapped, add_source, check_output, resolve_ceph_version): _resolve_first = True def _resolve_version(arg): nonlocal _resolve_first if _resolve_first: _resolve_first = False return None return resolve_ceph_version_orig(arg) resolve_ceph_version.side_effect = _resolve_version check_output.return_value = b"""""" ceph version 16.2.13 (123) pacific (stable)"""""" is_bootstrapped.return_value = True hookenv.config.side_effect = self.test_config self.test_config.set('source', 'cloud:focal-yoga') check_for_upgrade() roll_monitor_cluster.assert_called() add_source.assert_not_called() @patch('ceph_hooks.ceph.resolve_ceph_version') @patch('ceph_hooks.subprocess.check_output') @patch('ceph_hooks.add_source') @patch('ceph_hooks.ceph.is_bootstrapped') @patch('ceph_hooks.hookenv') @patch('ceph_hooks.ceph.roll_monitor_cluster') def test_check_for_upgrade_no_versions(self, roll_monitor_cluster, hookenv, is_bootstrapped, add_source, check_output, resolve_ceph_version): resolve_ceph_version.return_value = None check_output.return_value = b"""""" ceph version 17.2.5 (456) quincy (stable)"""""" is_bootstrapped.return_value = True hookenv.config.side_effect = self.test_config check_for_upgrade() roll_monitor_cluster.assert_not_called() add_source.assert_not_called()",,74,0
openstack%2Frequirements~887720,openstack/requirements,master,I186780a029c15de15764f1491f43737de8066b12,Bump XStatic-jQuery upper bound,MERGED,2023-07-05 15:26:03.000000000,2023-07-07 08:10:30.000000000,2023-07-07 08:09:39.000000000,"[{'_account_id': 6914}, {'_account_id': 8648}, {'_account_id': 11904}, {'_account_id': 13252}, {'_account_id': 14288}, {'_account_id': 22348}, {'_account_id': 28522}]","[{'number': 1, 'created': '2023-07-05 15:26:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/requirements/commit/a47d4ce03c692716a08ba84388e0f85b5518b336', 'message': '[DNM] Upgrade XStatic-jQuery to 3.3.2.1 for Horizon\n\nChange-Id: I186780a029c15de15764f1491f43737de8066b12\n'}, {'number': 2, 'created': '2023-07-05 15:32:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/requirements/commit/7f254dd56b8f3b685e8f461636c86cd9cf41b760', 'message': '[DNM] Upgrade XStatic-jQuery to 3.3.2.1 for Horizon\n\nChange-Id: I186780a029c15de15764f1491f43737de8066b12\n'}, {'number': 3, 'created': '2023-07-05 15:34:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/requirements/commit/891dbf8959004064fe867023a4f3a46035669a7f', 'message': '[DNM] Upgrade XStatic-jQuery to 3.3.2.1 for Horizon\n\nChange-Id: I186780a029c15de15764f1491f43737de8066b12\n'}, {'number': 4, 'created': '2023-07-05 18:41:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/requirements/commit/7abf5f00aeabf20bf36f043aeda30b926342e4e4', 'message': ""Upgrade XStatic-jQuery to 3.3.2.1 for Horizon\n\nSince we upgraded XStatic-JQuery-Migrate to 3.3.2.1 in patch\nhttps://review.opendev.org/c/openstack/requirements/+/883402 we now\nneed newer jquery, because that version of jquery-migrate won't\nwork with jquery 1.2.\n\nChange-Id: I186780a029c15de15764f1491f43737de8066b12\n""}, {'number': 5, 'created': '2023-07-06 13:39:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/requirements/commit/6568c974a06294c9d9f38c8b69cbc38f1a285e7b', 'message': ""Bump XStatic-jQuery upper bound\n\nThis commit bumps the upper bound of XStatic-jQuery to <3.4.\nSince we upgraded XStatic-JQuery-Migrate to 3.3.2.1 in patch\nhttps://review.opendev.org/c/openstack/requirements/+/883402 we now\nneed newer jquery, because that version of jquery-migrate won't\nwork with jquery 1.2.\n\nNote: upper-constraints.txt will be updated in a seprate patch.\n\nChange-Id: I186780a029c15de15764f1491f43737de8066b12\n""}, {'number': 6, 'created': '2023-07-06 16:13:41.000000000', 'files': ['global-requirements.txt'], 'web_link': 'https://opendev.org/openstack/requirements/commit/5881dcaff7dcea00b6954e9cf540467370185f55', 'message': ""Bump XStatic-jQuery upper bound\n\nThis commit bumps the upper bound of XStatic-jQuery to <3.\nSince we upgraded XStatic-JQuery-Migrate to 3.3.2.1 in patch\nhttps://review.opendev.org/c/openstack/requirements/+/883402 we now\nneed newer jquery, because that version of jquery-migrate won't\nwork with jquery 1.2.\n\nNote: upper-constraints.txt will be updated in a seprate patch.\n\nChange-Id: I186780a029c15de15764f1491f43737de8066b12\n""}]",3,887720,5881dcaff7dcea00b6954e9cf540467370185f55,22,7,6,29313,,,0,"Bump XStatic-jQuery upper bound

This commit bumps the upper bound of XStatic-jQuery to <3.
Since we upgraded XStatic-JQuery-Migrate to 3.3.2.1 in patch
https://review.opendev.org/c/openstack/requirements/+/883402 we now
need newer jquery, because that version of jquery-migrate won't
work with jquery 1.2.

Note: upper-constraints.txt will be updated in a seprate patch.

Change-Id: I186780a029c15de15764f1491f43737de8066b12
",git fetch https://review.opendev.org/openstack/requirements refs/changes/20/887720/1 && git format-patch -1 --stdout FETCH_HEAD,"['global-requirements.txt', 'upper-constraints.txt']",2,a47d4ce03c692716a08ba84388e0f85b5518b336,,XStatic-jQuery===3.3.2.1,XStatic-jQuery===1.12.4.1,2,2
openstack%2Fopenstack-ansible~884645,openstack/openstack-ansible,master,Ief8759e19d935aec9d8cfa855b1b0ba2b0c83424,Enable S3 API by default,MERGED,2023-05-29 22:11:40.000000000,2023-07-07 06:58:35.000000000,2023-07-07 06:56:28.000000000,"[{'_account_id': 22348}, {'_account_id': 25023}, {'_account_id': 28619}]","[{'number': 1, 'created': '2023-05-29 22:11:40.000000000', 'files': ['releasenotes/notes/s3-api-enabled-by-default-53e6602aeb4d9ff1.yaml', 'inventory/group_vars/ceph-rgw.yml'], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/e00689d50fb6b311988afc2e8a3459ce3af15d47', 'message': ""Enable S3 API by default\n\nWhen only 'swift' is specified in `rgw_enable_apis`, sending a http\nrequest to the base RadosGW API URL('/') returns '405 Method Not\nAllowed'.\nIt causes an important issue, because when any change is made to RadosGW\nconfiguration via ceph-ansible, the 'restart ceph rgws' handler is\ntriggered that use restart_rgw_daemon.sh[1] script to restart radosgw\nservice.\nBoth curl and wget used by this script return non-zero return code on\n'405 Method Not Allowed' response, causing ceph-ansible playbook to fail.\n\nAs a solution 's3' api can be enabled by default. With S3 API enabled,\nbase RadosGW API URL('/') returns 200 instead of 405 RC.\nThis change affects only environments using integrated ceph-ansible.\n\n[1] https://github.com/ceph/ceph-ansible/blob/stable-7.0/roles/ceph-handler/templates/restart_rgw_daemon.sh.j2#L68\n\nChange-Id: Ief8759e19d935aec9d8cfa855b1b0ba2b0c83424\n""}]",0,884645,e00689d50fb6b311988afc2e8a3459ce3af15d47,8,3,1,32666,,,0,"Enable S3 API by default

When only 'swift' is specified in `rgw_enable_apis`, sending a http
request to the base RadosGW API URL('/') returns '405 Method Not
Allowed'.
It causes an important issue, because when any change is made to RadosGW
configuration via ceph-ansible, the 'restart ceph rgws' handler is
triggered that use restart_rgw_daemon.sh[1] script to restart radosgw
service.
Both curl and wget used by this script return non-zero return code on
'405 Method Not Allowed' response, causing ceph-ansible playbook to fail.

As a solution 's3' api can be enabled by default. With S3 API enabled,
base RadosGW API URL('/') returns 200 instead of 405 RC.
This change affects only environments using integrated ceph-ansible.

[1] https://github.com/ceph/ceph-ansible/blob/stable-7.0/roles/ceph-handler/templates/restart_rgw_daemon.sh.j2#L68

Change-Id: Ief8759e19d935aec9d8cfa855b1b0ba2b0c83424
",git fetch https://review.opendev.org/openstack/openstack-ansible refs/changes/45/884645/1 && git format-patch -1 --stdout FETCH_HEAD,"['releasenotes/notes/s3-api-enabled-by-default-53e6602aeb4d9ff1.yaml', 'inventory/group_vars/ceph-rgw.yml']",2,e00689d50fb6b311988afc2e8a3459ce3af15d47,tls-backend," rgw_enable_apis: 'swift, s3' rgw_s3_auth_use_keystone: 'true'"," rgw_enable_apis: swift # For S3 support, update/add below rows # rgw_enable_apis: 'swift, s3' # rgw_s3_auth_use_keystone: 'true'",6,4
openstack%2Fopenstack-ansible~887862,openstack/openstack-ansible,master,If451b4bc12bb0b0bfe3fe20494e99a07b59ab798,Return PIP_OPTS for load_nodepool_pip_opts,MERGED,2023-07-06 16:36:33.000000000,2023-07-07 06:57:37.000000000,2023-07-07 06:56:26.000000000,"[{'_account_id': 22348}, {'_account_id': 25023}, {'_account_id': 32666}]","[{'number': 1, 'created': '2023-07-06 16:36:33.000000000', 'files': ['scripts/scripts-library.sh'], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/d458b1f46a8279e74e93ee2ba25b68921de302e5', 'message': ""Return PIP_OPTS for load_nodepool_pip_opts\n\nAt the moment for some scenarios, like linters, where ansible bootstrap\nis skipped, PIP_OPTS are undefined and linters fail due to that.\n\nWith patch we define PIP_OPTS to an empty value if\nwe're not in CI.\n\nAlternatively we can patch scenarios independently\nnot to rely on existance of PIP_OPTS or export default in\ngate-check-commit instead.\n\nChange-Id: If451b4bc12bb0b0bfe3fe20494e99a07b59ab798\n""}]",0,887862,d458b1f46a8279e74e93ee2ba25b68921de302e5,8,3,1,28619,,,0,"Return PIP_OPTS for load_nodepool_pip_opts

At the moment for some scenarios, like linters, where ansible bootstrap
is skipped, PIP_OPTS are undefined and linters fail due to that.

With patch we define PIP_OPTS to an empty value if
we're not in CI.

Alternatively we can patch scenarios independently
not to rely on existance of PIP_OPTS or export default in
gate-check-commit instead.

Change-Id: If451b4bc12bb0b0bfe3fe20494e99a07b59ab798
",git fetch https://review.opendev.org/openstack/openstack-ansible refs/changes/62/887862/1 && git format-patch -1 --stdout FETCH_HEAD,['scripts/scripts-library.sh'],1,d458b1f46a8279e74e93ee2ba25b68921de302e5,," else export PIP_OPTS=${PIP_OPTS:-""""}",,2,0
openstack%2Fopenstack-ansible~887785,openstack/openstack-ansible,master,I1553ba549ba36ab23f999cb256e731520cbb5d09,Adjust default value for *_backend_ssl,MERGED,2023-07-06 09:55:39.000000000,2023-07-07 06:55:46.000000000,2023-07-07 06:53:38.000000000,"[{'_account_id': 22348}, {'_account_id': 25023}, {'_account_id': 28619}]","[{'number': 1, 'created': '2023-07-06 09:55:39.000000000', 'files': ['inventory/group_vars/horizon_all/haproxy_service.yml', 'inventory/group_vars/blazar_all/haproxy_service.yml'], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/e88bf6b19c1c03f2d56d2be26180547b2fe8b5de', 'message': 'Adjust default value for *_backend_ssl\n\nI forgot to set a proper(openstack_service_backend_ssl) default value\nfor *_backend_ssl variables in a few places.\nThis patch fixes my mistake.\n\nChange-Id: I1553ba549ba36ab23f999cb256e731520cbb5d09\n'}]",0,887785,e88bf6b19c1c03f2d56d2be26180547b2fe8b5de,8,3,1,32666,,,0,"Adjust default value for *_backend_ssl

I forgot to set a proper(openstack_service_backend_ssl) default value
for *_backend_ssl variables in a few places.
This patch fixes my mistake.

Change-Id: I1553ba549ba36ab23f999cb256e731520cbb5d09
",git fetch https://review.opendev.org/openstack/openstack-ansible refs/changes/85/887785/1 && git format-patch -1 --stdout FETCH_HEAD,"['inventory/group_vars/horizon_all/haproxy_service.yml', 'inventory/group_vars/blazar_all/haproxy_service.yml']",2,e88bf6b19c1c03f2d56d2be26180547b2fe8b5de,tls-backend," haproxy_backend_ssl: ""{{ blazar_backend_ssl | default(openstack_service_backend_ssl) }}"""," haproxy_backend_ssl: ""{{ blazar_backend_ssl | default(False) }}""",2,2
openstack%2Fopenstack-ansible~884633,openstack/openstack-ansible,master,I276ccd7e49db7e7ffe4f6f6c22ab1a82edc34688,Add TLS support to ceph-rgw backends,MERGED,2023-05-29 15:30:53.000000000,2023-07-07 06:54:47.000000000,2023-07-07 06:53:33.000000000,"[{'_account_id': 22348}, {'_account_id': 25023}, {'_account_id': 28619}]","[{'number': 1, 'created': '2023-05-29 15:30:53.000000000', 'files': ['playbooks/ceph-rgw-install.yml', 'inventory/group_vars/haproxy/haproxy.yml', 'inventory/group_vars/ceph-rgw.yml'], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/14f69fbb5d78f655ac55e2dc780f412b28c0ee9d', 'message': 'Add TLS support to ceph-rgw backends\n\nBy overriding the variable `ceph_rgw_backend_ssl: True` HTTPS will\nbe enabled, disabling HTTP support on the ceph-rgw backend api.\n\nThe ansible-role-pki is used to generate the required TLS\ncertificates if this functionality is enabled.\n\nChange-Id: I276ccd7e49db7e7ffe4f6f6c22ab1a82edc34688\n'}]",3,884633,14f69fbb5d78f655ac55e2dc780f412b28c0ee9d,11,3,1,32666,,,0,"Add TLS support to ceph-rgw backends

By overriding the variable `ceph_rgw_backend_ssl: True` HTTPS will
be enabled, disabling HTTP support on the ceph-rgw backend api.

The ansible-role-pki is used to generate the required TLS
certificates if this functionality is enabled.

Change-Id: I276ccd7e49db7e7ffe4f6f6c22ab1a82edc34688
",git fetch https://review.opendev.org/openstack/openstack-ansible refs/changes/33/884633/1 && git format-patch -1 --stdout FETCH_HEAD,"['playbooks/ceph-rgw-install.yml', 'inventory/group_vars/haproxy/haproxy.yml', 'inventory/group_vars/ceph-rgw.yml']",3,14f69fbb5d78f655ac55e2dc780f412b28c0ee9d,tls-backend,"### ### Backend TLS ### # Ceph configuration options to enable TLS on ceph-rgw radosgw_frontend_ssl_certificate: ""{{ ceph_rgw_backend_ssl is truthy | ternary(ceph_rgw_ssl_cert, '') }}"" # Ceph-ansible requires to include private key in `radosgw_frontend_ssl_certificate` # which is not possible with ansible-role-pki. # That is why `ssl_private_key` is defined in `radosgw_frontend_options`. radosgw_frontend_options: ""{{ ceph_rgw_backend_ssl is truthy | ternary('ssl_private_key=' + ceph_rgw_ssl_key, '') }}"" # Define if communication between haproxy and service backends should be # encrypted with TLS. ceph_rgw_backend_ssl: ""{{ openstack_service_backend_ssl | default(False) }}"" # Storage location for SSL certificate authority ceph_rgw_pki_dir: ""{{ openstack_pki_dir | default('/etc/openstack_deploy/pki') }}"" # Delegated host for operating the certificate authority ceph_rgw_pki_setup_host: ""{{ openstack_pki_setup_host | default('localhost') }}"" # ceph_rgw server certificate ceph_rgw_pki_keys_path: ""{{ ceph_rgw_pki_dir ~ '/certs/private/' }}"" ceph_rgw_pki_certs_path: ""{{ ceph_rgw_pki_dir ~ '/certs/certs/' }}"" ceph_rgw_pki_intermediate_cert_name: ""{{ openstack_pki_service_intermediate_cert_name | default('ExampleCorpIntermediate') }}"" ceph_rgw_pki_regen_cert: '' ceph_rgw_pki_san: ""{{ openstack_pki_san | default('DNS:' ~ ansible_facts['hostname'] ~ ',IP:' ~ management_address) }}"" ceph_rgw_pki_certificates: - name: ""ceph_rgw_{{ ansible_facts['hostname'] }}"" provider: ownca cn: ""{{ ansible_facts['hostname'] }}"" san: ""{{ ceph_rgw_pki_san }}"" signed_by: ""{{ ceph_rgw_pki_intermediate_cert_name }}"" # ceph_rgw destination files for SSL certificates ceph_rgw_ssl_cert: /etc/ceph/ceph-rgw.pem ceph_rgw_ssl_key: /etc/ceph/ceph-rgw.key # Installation details for SSL certificates ceph_rgw_pki_install_certificates: - src: ""{{ ceph_rgw_user_ssl_cert | default(ceph_rgw_pki_certs_path ~ 'ceph_rgw_' ~ ansible_facts['hostname'] ~ '-chain.crt') }}"" dest: ""{{ ceph_rgw_ssl_cert }}"" owner: ""ceph"" group: ""ceph"" mode: ""0644"" - src: ""{{ ceph_rgw_user_ssl_key | default(ceph_rgw_pki_keys_path ~ 'ceph_rgw_' ~ ansible_facts['hostname'] ~ '.key.pem') }}"" dest: ""{{ ceph_rgw_ssl_key }}"" owner: ""ceph"" group: ""ceph"" mode: ""0600"" # Define user-provided SSL certificates #ceph_rgw_user_ssl_cert: <path to cert on ansible deployment host> #ceph_rgw_user_ssl_key: <path to cert on ansible deployment host>",,78,0
openstack%2Fopenstack-ansible~884662,openstack/openstack-ansible,master,I92953a14dd311a60b169165c5a8e61dd98466033,Restore an ability for HAProxy to bind on interal IP,MERGED,2023-05-30 08:53:11.000000000,2023-07-07 06:53:36.000000000,2023-07-07 06:53:36.000000000,"[{'_account_id': 22348}, {'_account_id': 25023}, {'_account_id': 28619}]","[{'number': 1, 'created': '2023-05-30 08:53:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/d29055c8b80b119979e5991c6743d59dc9bc530a', 'message': 'Allow using domain name as internal_lb_vip_address\n\nChange-Id: I92953a14dd311a60b169165c5a8e61dd98466033\n'}, {'number': 2, 'created': '2023-06-30 10:20:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/d23e61572ebe41742c809852edcf57364406c04f', 'message': 'Allow using domain name as internal_lb_vip_address\n\nChange-Id: I92953a14dd311a60b169165c5a8e61dd98466033\n'}, {'number': 3, 'created': '2023-07-03 14:31:53.000000000', 'files': ['inventory/group_vars/repo_all.yml', 'inventory/group_vars/galera_all.yml', 'inventory/group_vars/nova_all/haproxy_service.yml', 'inventory/group_vars/neutron_all/haproxy_service.yml', 'inventory/group_vars/rabbitmq_all.yml'], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/64054e4cada6aacb87f7b3feee88fece95c5127a', 'message': 'Restore an ability for HAProxy to bind on interal IP\n\nAccording to the docs [1], there is an ability for HAProxy to bind\nspecifically on IP-address, ""while preserving the names for TLS-\ncertificates and endpoint URIs"".\n\nFor internal endpoint this supposed to be done by setting\n`internal_lb_vip_address` and `haproxy_bind_internal_lb_vip_address`\nbut was broken due to the fact that for:\n* `haproxy_galera_service`\n* `haproxy_opendaylight_neutron_service`\n* `haproxy_opendaylight_websocket_service`\n* `haproxy_nova_api_metadata_service`\n* `haproxy_rabbitmq_service`\n* `haproxy_repo_service`\n`haproxy_bind` was explicitly set to `[internal_lb_vip_address]` and\noverriding `haproxy_bind_internal_lb_vip_address` would result in\nwrong certificate paths (with FQDN in names, which does not exist)\nfor these frontends.\n\n[1] https://docs.openstack.org/openstack-ansible-haproxy_server/latest/configure-haproxy.html#overriding-the-address-haproxy-will-bind-to\n\nChange-Id: I92953a14dd311a60b169165c5a8e61dd98466033\n'}]",7,884662,64054e4cada6aacb87f7b3feee88fece95c5127a,20,3,3,34653,,,0,"Restore an ability for HAProxy to bind on interal IP

According to the docs [1], there is an ability for HAProxy to bind
specifically on IP-address, ""while preserving the names for TLS-
certificates and endpoint URIs"".

For internal endpoint this supposed to be done by setting
`internal_lb_vip_address` and `haproxy_bind_internal_lb_vip_address`
but was broken due to the fact that for:
* `haproxy_galera_service`
* `haproxy_opendaylight_neutron_service`
* `haproxy_opendaylight_websocket_service`
* `haproxy_nova_api_metadata_service`
* `haproxy_rabbitmq_service`
* `haproxy_repo_service`
`haproxy_bind` was explicitly set to `[internal_lb_vip_address]` and
overriding `haproxy_bind_internal_lb_vip_address` would result in
wrong certificate paths (with FQDN in names, which does not exist)
for these frontends.

[1] https://docs.openstack.org/openstack-ansible-haproxy_server/latest/configure-haproxy.html#overriding-the-address-haproxy-will-bind-to

Change-Id: I92953a14dd311a60b169165c5a8e61dd98466033
",git fetch https://review.opendev.org/openstack/openstack-ansible refs/changes/62/884662/1 && git format-patch -1 --stdout FETCH_HEAD,"['inventory/group_vars/repo_all.yml', 'inventory/group_vars/galera_all.yml', 'inventory/group_vars/nova_all/haproxy_service.yml', 'inventory/group_vars/neutron_all/haproxy_service.yml', 'inventory/group_vars/rabbitmq_all.yml']",5,d29055c8b80b119979e5991c6743d59dc9bc530a,multiceph," haproxy_bind: ""{{ [haproxy_bind_internal_lb_vip_address] }}"""," haproxy_bind: ""{{ [internal_lb_vip_address] }}""",6,6
openstack%2Fopenstack-ansible-galera_server~887861,openstack/openstack-ansible-galera_server,master,Id5ae73222a1109ad13b0b70ba3d02063d931ff90,Remove warn argument for command/shell,MERGED,2023-07-06 16:18:58.000000000,2023-07-07 06:50:45.000000000,2023-07-07 06:49:52.000000000,"[{'_account_id': 22348}, {'_account_id': 25023}, {'_account_id': 32666}]","[{'number': 1, 'created': '2023-07-06 16:18:58.000000000', 'files': ['tasks/galera_server_post_install.yml'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-galera_server/commit/cef3aa94f6a39b62f8a3fc337d6b00b4dacb7226', 'message': ""Remove warn argument for command/shell\n\nSince ansible-core 2.14 you can't use warn as module argument.\n\nChange-Id: Id5ae73222a1109ad13b0b70ba3d02063d931ff90\n""}]",1,887861,cef3aa94f6a39b62f8a3fc337d6b00b4dacb7226,10,3,1,28619,,,0,"Remove warn argument for command/shell

Since ansible-core 2.14 you can't use warn as module argument.

Change-Id: Id5ae73222a1109ad13b0b70ba3d02063d931ff90
",git fetch https://review.opendev.org/openstack/openstack-ansible-galera_server refs/changes/61/887861/1 && git format-patch -1 --stdout FETCH_HEAD,['tasks/galera_server_post_install.yml'],1,cef3aa94f6a39b62f8a3fc337d6b00b4dacb7226,osa/core-2.15,, warn: no,0,1
openstack%2Fopenstack-ansible-rabbitmq_server~887779,openstack/openstack-ansible-rabbitmq_server,master,Ie2e783d065f32b906ee1554abaf5dc3b24236ca8,Adjust wildcard definition,MERGED,2023-07-06 09:21:17.000000000,2023-07-07 06:29:06.000000000,2023-07-07 06:28:08.000000000,"[{'_account_id': 22348}, {'_account_id': 25023}, {'_account_id': 32666}]","[{'number': 1, 'created': '2023-07-06 09:21:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-rabbitmq_server/commit/00fbf1f61c0f4507a948e833776a92d5db2818da', 'message': ""Adjust wildcard definition\n\nThere was no reason to adjust rabbitmq_package_version previously, as\nreplaced by the wildcard part is never changed, so patching that doesn't\nhave any practical sense. We also return `-1` to erlang spec, so that\nwildcard would match only the part we expect to change.\n\nThis partially reverts I99683a031f935b579d38ae457c484c9a150344c6\n\nChange-Id: Ie2e783d065f32b906ee1554abaf5dc3b24236ca8\n""}, {'number': 2, 'created': '2023-07-06 09:39:35.000000000', 'files': ['vars/redhat.yml', 'vars/debian.yml'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-rabbitmq_server/commit/2fc53a3a03889dc742892b83a1c9d4f30d258e0d', 'message': ""Adjust wildcard definition\n\nThere was no reason to adjust rabbitmq_package_version previously, as\nreplaced by the wildcard part is never changed, so patching that doesn't\nhave any practical sense. We also return `-1` to erlang spec, so that\nwildcard would match only the part we expect to change.\n\nThis partially reverts I99683a031f935b579d38ae457c484c9a150344c6\n\nChange-Id: Ie2e783d065f32b906ee1554abaf5dc3b24236ca8\n""}]",1,887779,2fc53a3a03889dc742892b83a1c9d4f30d258e0d,11,3,2,28619,,,0,"Adjust wildcard definition

There was no reason to adjust rabbitmq_package_version previously, as
replaced by the wildcard part is never changed, so patching that doesn't
have any practical sense. We also return `-1` to erlang spec, so that
wildcard would match only the part we expect to change.

This partially reverts I99683a031f935b579d38ae457c484c9a150344c6

Change-Id: Ie2e783d065f32b906ee1554abaf5dc3b24236ca8
",git fetch https://review.opendev.org/openstack/openstack-ansible-rabbitmq_server refs/changes/79/887779/1 && git format-patch -1 --stdout FETCH_HEAD,"['vars/redhat.yml', 'vars/debian.yml']",2,00fbf1f61c0f4507a948e833776a92d5db2818da,,"_rabbitmq_package_version: ""3.11.17-1""_rabbitmq_erlang_version_spec: ""{{ (rabbitmq_install_method == 'external_repo') | ternary('1:25.3.2*-1', '1:22.*') }}""","_rabbitmq_package_version: ""3.11.17*""_rabbitmq_erlang_version_spec: ""{{ (rabbitmq_install_method == 'external_repo') | ternary('1:25.3.2*', '1:22.*') }}""",4,4
openstack%2Fbifrost~877494,openstack/bifrost,stable/2023.1,I54ab52bbaec98ab94314698bc13083760d090206,chore: allow ironic-inspector to work with IPv6 disabled,MERGED,2023-03-15 15:14:30.000000000,2023-07-07 06:09:07.000000000,2023-07-07 06:08:03.000000000,"[{'_account_id': 4571}, {'_account_id': 10342}, {'_account_id': 14760}, {'_account_id': 22348}]","[{'number': 1, 'created': '2023-03-15 15:14:30.000000000', 'files': ['playbooks/roles/bifrost-ironic-install/templates/ironic-inspector.conf.j2'], 'web_link': 'https://opendev.org/openstack/bifrost/commit/867a4c466cef639df1939ccc52f154c98fae5c22', 'message': 'chore: allow ironic-inspector to work with IPv6 disabled\n\nIf IPv6 is disabled then ironic-inspector would fail to start. Update\nthe template to have ironic-inspector listen on the `internal_ip` of\nthe system.\n\nChange-Id: I54ab52bbaec98ab94314698bc13083760d090206\n(cherry picked from commit 83d56c72bb9af1ab60c08e7438f7b74ed5394b4d)\n'}]",1,877494,867a4c466cef639df1939ccc52f154c98fae5c22,12,4,1,10239,,,0,"chore: allow ironic-inspector to work with IPv6 disabled

If IPv6 is disabled then ironic-inspector would fail to start. Update
the template to have ironic-inspector listen on the `internal_ip` of
the system.

Change-Id: I54ab52bbaec98ab94314698bc13083760d090206
(cherry picked from commit 83d56c72bb9af1ab60c08e7438f7b74ed5394b4d)
",git fetch https://review.opendev.org/openstack/bifrost refs/changes/94/877494/1 && git format-patch -1 --stdout FETCH_HEAD,['playbooks/roles/bifrost-ironic-install/templates/ironic-inspector.conf.j2'],1,867a4c466cef639df1939ccc52f154c98fae5c22,jlvillal/ipv4-stable/2023.1,{% else %} listen_address = {{ internal_ip }},,2,0
openstack%2Fnova~867077,openstack/nova,master,I04ce2b00903c0ad884bbe844ff45b7db62338072,libvirt: retry libvirt connection on live_migration_monitor,NEW,2022-12-09 06:03:03.000000000,2023-07-07 04:55:42.000000000,,"[{'_account_id': 7730}, {'_account_id': 11604}, {'_account_id': 22348}]","[{'number': 1, 'created': '2022-12-09 06:03:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/3d7c59e15f6189aaec801993ddfe15716f0b1532', 'message': 'libvirt: retry libvirt connection on live_migration_monitor\n\nWhen libvirtd is restarted, libvirtd aborts live migrations and\ndisconnect client connection. In this case, current nova fails to\ncontinue live_migration_monitor and fails with unclean state.\n\nBy this commit, at least for the cases that the domain is still on the\nsource host, nova can know that the live migration is cancelled and thus\ncan roll back cleanly.\n\nSigned-off-by: Hiroki Narukawa <hnarukaw@yahoo-corp.jp>\nChange-Id: I04ce2b00903c0ad884bbe844ff45b7db62338072\n'}, {'number': 2, 'created': '2022-12-15 08:00:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/1680b139050aded74b11e7e3719fef87534777dd', 'message': 'libvirt: retry libvirt connection on live_migration_monitor\n\nWhen libvirtd is restarted, libvirtd aborts live migrations and\ndisconnect client connection. In this case, current nova fails to\ncontinue live_migration_monitor and fails with unclean state.\n\nBy this commit, at least for the cases that the domain is still on the\nsource host, nova can know that the live migration is cancelled and thus\ncan roll back cleanly.\n\nSigned-off-by: Hiroki Narukawa <hnarukaw@yahoo-corp.jp>\nCloses-Bug: #1999607\nChange-Id: I04ce2b00903c0ad884bbe844ff45b7db62338072\n'}, {'number': 3, 'created': '2023-01-20 09:10:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/51d888c053aa38d94937d850fb4c8afc3fddbaaf', 'message': 'libvirt: retry libvirt connection on live_migration_monitor\n\nWhen libvirtd is restarted, libvirtd aborts live migrations and\ndisconnect client connection. In this case, current nova fails to\ncontinue live_migration_monitor and fails with unclean state.\n\nBy this commit, at least for the cases that the domain is still on the\nsource host, nova can know that the live migration is cancelled and thus\ncan roll back cleanly.\n\nSigned-off-by: Hiroki Narukawa <hnarukaw@yahoo-corp.jp>\nCloses-Bug: #1999607\nChange-Id: I04ce2b00903c0ad884bbe844ff45b7db62338072\n'}, {'number': 4, 'created': '2023-02-16 03:44:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/fe2fea741def7bdaf0e8cde85dd703144cf02313', 'message': 'libvirt: retry libvirt connection on live_migration_monitor\n\nWhen libvirtd is restarted, libvirtd aborts live migrations and\ndisconnect client connection. In this case, current nova fails to\ncontinue live_migration_monitor and fails with unclean state.\n\nBy this commit, at least for the cases that the domain is still on the\nsource host, nova can know that the live migration is cancelled and thus\ncan roll back cleanly.\n\nSigned-off-by: Hiroki Narukawa <hnarukaw@yahoo-corp.jp>\nCloses-Bug: #1999607\nChange-Id: I04ce2b00903c0ad884bbe844ff45b7db62338072\n'}, {'number': 5, 'created': '2023-03-14 10:57:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/9fbc3cf3c1db3c774148997786331593a8c93c85', 'message': 'libvirt: retry libvirt connection on live_migration_monitor\n\nWhen libvirtd is restarted, libvirtd aborts live migrations and\ndisconnect client connection. In this case, current nova fails to\ncontinue live_migration_monitor and fails with unclean state.\n\nBy this commit, at least for the cases that the domain is still on the\nsource host, nova can know that the live migration is cancelled and thus\ncan roll back cleanly.\n\nThis commit changes the behavior of\ntest_live_migration_monitor_job_stats_internal_error, because by this\ncommit libvirt driver will now retry after single LibvirtException.\nTherefore this commit also changes the test case, as this is expected\nchange.\n\nSigned-off-by: Hiroki Narukawa <hnarukaw@yahoo-corp.jp>\nCloses-Bug: #1999607\nChange-Id: I04ce2b00903c0ad884bbe844ff45b7db62338072\n'}, {'number': 6, 'created': '2023-03-16 06:07:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/a5b7a452b23971b1c24e8a3616fc9a7c6d51bb1b', 'message': 'libvirt: retry libvirt connection on live_migration_monitor\n\nWhen libvirtd is restarted, libvirtd aborts live migrations and\ndisconnect client connection. In this case, current nova fails to\ncontinue live_migration_monitor and fails with unclean state.\n\nBy this commit, at least for the cases that the domain is still on the\nsource host, nova can know that the live migration is cancelled and thus\ncan roll back cleanly.\n\nThis commit changes the behavior of\ntest_live_migration_monitor_job_stats_internal_error, because by this\ncommit libvirt driver will now retry after single LibvirtException.\nTherefore this commit also changes the test case, as this is expected\nchange.\n\nSigned-off-by: Hiroki Narukawa <hnarukaw@yahoo-corp.jp>\nCloses-Bug: #1999607\nChange-Id: I04ce2b00903c0ad884bbe844ff45b7db62338072\n'}, {'number': 7, 'created': '2023-03-16 06:39:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/9a7a5af44e1f5bddf26bf00cee734f2b3251efe4', 'message': 'libvirt: retry libvirt connection on live_migration_monitor\n\nWhen libvirtd is restarted, libvirtd aborts live migrations and\ndisconnect client connection. In this case, current nova fails to\ncontinue live_migration_monitor and fails with unclean state.\n\nBy this commit, at least for the cases that the domain is still on the\nsource host, nova can know that the live migration is cancelled and thus\ncan roll back cleanly.\n\nThis commit changes the behavior of\ntest_live_migration_monitor_job_stats_internal_error, because by this\ncommit libvirt driver will now retry after single LibvirtException.\nTherefore this commit also changes the test case, as this is expected\nchange.\n\nSigned-off-by: Hiroki Narukawa <hnarukaw@yahoo-corp.jp>\nCloses-Bug: #1999607\nChange-Id: I04ce2b00903c0ad884bbe844ff45b7db62338072\n'}, {'number': 8, 'created': '2023-03-16 07:22:06.000000000', 'files': ['nova/virt/libvirt/driver.py', 'nova/tests/functional/regressions/test_bug_1999607.py', 'releasenotes/notes/bug_1999607-libvirtd-restart-while-live-migration-a3c7d8a2c982f342.yaml', 'nova/tests/unit/virt/libvirt/test_driver.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/e6457fa581142458772bbf1fe0fef9e6240c73d5', 'message': 'libvirt: retry libvirt connection on live_migration_monitor\n\nWhen libvirtd is restarted, libvirtd aborts live migrations and\ndisconnect client connection. In this case, current nova fails to\ncontinue live_migration_monitor and fails with unclean state.\n\nBy this commit, at least for the cases that the domain is still on the\nsource host, nova can know that the live migration is cancelled and thus\ncan roll back cleanly.\n\nThis commit changes the behavior of\ntest_live_migration_monitor_job_stats_internal_error, because by this\ncommit libvirt driver will now retry after single LibvirtException.\nTherefore this commit also changes the test case, as this is expected\nchange.\n\nSigned-off-by: Hiroki Narukawa <hnarukaw@yahoo-corp.jp>\nCloses-Bug: #1999607\nChange-Id: I04ce2b00903c0ad884bbe844ff45b7db62338072\n'}]",20,867077,e6457fa581142458772bbf1fe0fef9e6240c73d5,58,3,8,35587,,,0,"libvirt: retry libvirt connection on live_migration_monitor

When libvirtd is restarted, libvirtd aborts live migrations and
disconnect client connection. In this case, current nova fails to
continue live_migration_monitor and fails with unclean state.

By this commit, at least for the cases that the domain is still on the
source host, nova can know that the live migration is cancelled and thus
can roll back cleanly.

This commit changes the behavior of
test_live_migration_monitor_job_stats_internal_error, because by this
commit libvirt driver will now retry after single LibvirtException.
Therefore this commit also changes the test case, as this is expected
change.

Signed-off-by: Hiroki Narukawa <hnarukaw@yahoo-corp.jp>
Closes-Bug: #1999607
Change-Id: I04ce2b00903c0ad884bbe844ff45b7db62338072
",git fetch https://review.opendev.org/openstack/nova refs/changes/77/867077/1 && git format-patch -1 --stdout FETCH_HEAD,['nova/virt/libvirt/driver.py'],1,3d7c59e15f6189aaec801993ddfe15716f0b1532,bug/1999607," monitor_interval_sec = 0.5 while True: retries = 120 for i in range(retries): try: if i > 0: # libvirt connection was lost on previous iteration. # @guest is tied to libvirt connection, so the # instance should be renewed. guest = self._host.get_guest(instance) info = guest.get_job_info() break except libvirt.libvirtError: if i == retries - 1: # Giving up with the result that nova cannot determine # on which hypervisor the virtual machine is running. LOG.exception(""Cannot connect to libvirt, and cannot "" ""know the result of migration job. "" ""Giving up."", instance=instance) raise LOG.info(""Cannot connect to libvirt, but live migration "" ""should be ongoing. Retry %(current)d / %(max)d"", {'current': i + 1, 'max': retries}, instance=instance) time.sleep(monitor_interval_sec) time.sleep(monitor_interval_sec)", while True: info = guest.get_job_info() time.sleep(0.5),25,2
openstack%2Ffuturist~866553,openstack/futurist,master,Idb13271f5ea698cd382986d9cdd9c378516ac2ad,GreenThreadPoolExecutor to accept multiple shutdown()s,NEW,2022-12-05 08:49:37.000000000,2023-07-07 04:55:28.000000000,,[{'_account_id': 22348}],"[{'number': 1, 'created': '2022-12-05 08:49:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/futurist/commit/8637cc49a02d38ba34ceb136aa636d8c5023b50a', 'message': 'GreenThreadPoolExecutor to accept multiple shutdown()s\n\nCurrent GreenThreadPoolExecutor does nothing on shutdown() if it is not\nthe first time.\n\nIf wait=False was given on the first time, then even if\nshutdown(wait=True) was called after that, jobs are not guaranteed not\nto be running.\n\nCurrent document says this function is safe to call several times, so\nthe second call should also succeed.\nhttps://docs.openstack.org/futurist/latest/reference/index.html#executors\n\nBy this commit, fix the behavior of GreenThreadPoolExecutor and add a\ntest.\n\nfuturist.ProcessPoolExecutor also did not pass this test, but testing by\nthe original concurrent.futures.ProcessPoolExecutor raised on\nshutdown(wait=False), so did not change the behavior on this commit.\n\nSigned-off-by: Hiroki Narukawa <hnarukaw@yahoo-corp.jp>\nChange-Id: Idb13271f5ea698cd382986d9cdd9c378516ac2ad\n'}, {'number': 2, 'created': '2022-12-13 05:29:36.000000000', 'files': ['futurist/_futures.py', 'futurist/tests/test_executors.py'], 'web_link': 'https://opendev.org/openstack/futurist/commit/8167b857ca60a7707e9368e11af0b15edae91b8c', 'message': 'GreenThreadPoolExecutor to accept multiple shutdown()s\n\nCurrent GreenThreadPoolExecutor does nothing on shutdown() if it is not\nthe first time.\n\nIf wait=False was given on the first time, then even if\nshutdown(wait=True) was called after that, jobs are not guaranteed not\nto be running.\n\nCurrent document says this function is safe to call several times, so\nthe second call should also succeed.\nhttps://docs.openstack.org/futurist/latest/reference/index.html#executors\n\nBy this commit, fix the behavior of GreenThreadPoolExecutor and add a\ntest.\n\nfuturist.ProcessPoolExecutor also did not pass this test, but testing by\nthe original concurrent.futures.ProcessPoolExecutor raised on\nshutdown(wait=False), so did not change the behavior on this commit.\n\nSigned-off-by: Hiroki Narukawa <hnarukaw@yahoo-corp.jp>\nChange-Id: Idb13271f5ea698cd382986d9cdd9c378516ac2ad\n'}]",6,866553,8167b857ca60a7707e9368e11af0b15edae91b8c,8,1,2,35587,,,0,"GreenThreadPoolExecutor to accept multiple shutdown()s

Current GreenThreadPoolExecutor does nothing on shutdown() if it is not
the first time.

If wait=False was given on the first time, then even if
shutdown(wait=True) was called after that, jobs are not guaranteed not
to be running.

Current document says this function is safe to call several times, so
the second call should also succeed.
https://docs.openstack.org/futurist/latest/reference/index.html#executors

By this commit, fix the behavior of GreenThreadPoolExecutor and add a
test.

futurist.ProcessPoolExecutor also did not pass this test, but testing by
the original concurrent.futures.ProcessPoolExecutor raised on
shutdown(wait=False), so did not change the behavior on this commit.

Signed-off-by: Hiroki Narukawa <hnarukaw@yahoo-corp.jp>
Change-Id: Idb13271f5ea698cd382986d9cdd9c378516ac2ad
",git fetch https://review.opendev.org/openstack/futurist refs/changes/53/866553/1 && git format-patch -1 --stdout FETCH_HEAD,"['futurist/_futures.py', 'futurist/tests/test_executors.py']",2,8637cc49a02d38ba34ceb136aa636d8c5023b50a,feature/green-threadpool-executor-shutdown-again," def test_shutdown_again(self): if isinstance(self.executor, futurist.ProcessPoolExecutor): # Skipping this behavior as intended behavior, # because concurrent.futures.ProcessPoolExecutor raises # on shutdown(wait=False) return self.executor.submit(delayed, 0.2) self.executor.shutdown(wait=False) self.executor.shutdown(wait=True) self.assertEqual(1, self.executor.statistics.executed) self.executor.shutdown(wait=True) self.executor.shutdown(wait=False) ",,16,4
openstack%2Fnova~866672,openstack/nova,master,Ic63d8c51bd0a6c7845ae9eb44cf33fc3c341bf9e,libvirt: add sftp driver,NEW,2022-12-06 08:32:50.000000000,2023-07-07 04:54:18.000000000,,"[{'_account_id': 7730}, {'_account_id': 22348}]","[{'number': 1, 'created': '2022-12-06 08:32:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/57c5d94da85afe4c8e37a3fb5345497559d97b75', 'message': 'libvirt: add sftp driver\n\nsshd can be configured to accept only sftp access by force-command\noption. Both ssh driver and rsync driver cannot use with internal-sftp\nrestriction. Also, ChrootDirectory option is combined well with\ninternal-sftp command. This commit supports the situation that the ssh\nserver is configured with ChrootDirectory and still have enough\nprivilege to access the necessary directories.\n\nSigned-off-by: Hiroki Narukawa <hnarukaw@yahoo-corp.jp>\nChange-Id: Ic63d8c51bd0a6c7845ae9eb44cf33fc3c341bf9e\n'}, {'number': 2, 'created': '2022-12-07 04:57:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/9abc100c98facff11233fd894a41cc84a5aefad6', 'message': 'libvirt: add sftp driver\n\nsshd can be configured to accept only sftp access by force-command\noption. Both ssh driver and rsync driver cannot use with internal-sftp\nrestriction. Also, ChrootDirectory option is combined well with\ninternal-sftp command. This commit supports the situation that the ssh\nserver is configured with ChrootDirectory and still have enough\nprivilege to access the necessary directories.\n\nSigned-off-by: Hiroki Narukawa <hnarukaw@yahoo-corp.jp>\nChange-Id: Ic63d8c51bd0a6c7845ae9eb44cf33fc3c341bf9e\n'}, {'number': 3, 'created': '2022-12-07 07:24:11.000000000', 'files': ['nova/conf/libvirt.py', 'nova/virt/libvirt/volume/remotefs.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/8a26e653640b2af37a71157dbb32829283f17e6f', 'message': 'libvirt: add sftp driver\n\nsshd can be configured to accept only sftp access by force-command\noption. Both ssh driver and rsync driver cannot use with internal-sftp\nrestriction. Also, ChrootDirectory option is combined well with\ninternal-sftp command. This commit supports the situation that the ssh\nserver is configured with ChrootDirectory and still have enough\nprivilege to access the necessary directories.\n\nSigned-off-by: Hiroki Narukawa <hnarukaw@yahoo-corp.jp>\nChange-Id: Ic63d8c51bd0a6c7845ae9eb44cf33fc3c341bf9e\n'}]",13,866672,8a26e653640b2af37a71157dbb32829283f17e6f,33,2,3,35587,,,0,"libvirt: add sftp driver

sshd can be configured to accept only sftp access by force-command
option. Both ssh driver and rsync driver cannot use with internal-sftp
restriction. Also, ChrootDirectory option is combined well with
internal-sftp command. This commit supports the situation that the ssh
server is configured with ChrootDirectory and still have enough
privilege to access the necessary directories.

Signed-off-by: Hiroki Narukawa <hnarukaw@yahoo-corp.jp>
Change-Id: Ic63d8c51bd0a6c7845ae9eb44cf33fc3c341bf9e
",git fetch https://review.opendev.org/openstack/nova refs/changes/72/866672/1 && git format-patch -1 --stdout FETCH_HEAD,"['nova/conf/libvirt.py', 'nova/virt/libvirt/volume/remotefs.py']",2,57c5d94da85afe4c8e37a3fb5345497559d97b75,feature/sftp-driver,"from nova import exception # Behavior slightly differs on each implementation # Not idempotent # When /a/a.txt exists but /a/b does not exist, # after copying /c/b inside into /a/b, /a/b/a.txt exists. # Idempotent # When /a/a.txt exists but /a/b does not exist, # after copying /c/b inside into /a/b, /a/b/b/a.txt exists. class SftpDriver(RemoteFilesystemDriver): def create_file(self, host, dst_path, on_execute, on_completion): with utils.tempdir() as tempdir: dir_path = os.path.dirname(os.path.normpath(dst_path)) # Create target dir inside temporary directory local_tmp_dir = os.path.join(tempdir, dir_path.strip(os.path.sep)) processutils.execute('mkdir', '-p', local_tmp_dir, on_execute=on_execute, on_completion=on_completion) # Create file in directory file_name = os.path.basename(os.path.normpath(dst_path)) local_tmp_file = os.path.join(local_tmp_dir, file_name) processutils.execute('touch', local_tmp_file) self.copy_file(local_tmp_file, host + ':' + dst_path, on_execute=on_execute, on_completion=on_completion, compression=False) def remove_file(self, host, dst, on_execute, on_completion): args = ['sftp', '-b', '-', host] cmd = '@rm ' + self._remote_path(dst) processutils.execute( *args, process_input=cmd, on_execute=on_execute, on_completion=on_completion) def create_dir(self, host, dst_path, on_execute, on_completion): if host is None: try: os.mkdir(dst_path) except FileExistsError: pass return try: args = ['sftp', '-b', '-', host] cmd = '@mkdir ' + self._remote_path(dst_path) processutils.execute( *args, process_input=cmd, on_execute=on_execute, on_completion=on_completion) except processutils.ProcessExecutionError: # sftp has no command equivalent to mkdir -p is_dir = self._is_dir(host, dst_path) if not is_dir: raise exception.NovaException('%s exists, but not a directory' % dst_path) def remove_dir(self, host, dst, on_execute, on_completion): (dirs, files) = self._list_files(host, dst) for d in dirs: self.remove_dir(host, os.path.join(dst, d), on_execute=None, on_completion=None) for f in files: self.remove_file(host, os.path.join(dst, f), on_execute=None, on_completion=None) args = ['sftp', '-b', '-', host] cmd = '@rmdir ' + self._remote_path(dst) processutils.execute( *args, process_input=cmd, on_execute=on_execute, on_completion=on_completion) # Not idempotent # When /a/a.txt exists but /a/b does not exist, # after copying /c/b inside into /a/b, /a/b/a.txt exists. def copy_file(self, src, dst, on_execute, on_completion, compression): if ':' in src: src_host = src.split(':')[0] src_path = src.split(':')[1] else: src_host = None src_path = src if ':' in dst: dst_host = dst.split(':')[0] dst_path = dst.split(':')[1] else: dst_host = None dst_path = dst if src_host is None and dst_host is None: # simple local copy args = ['cp', '-rf', src_path, dst_path] processutils.execute( *args, on_execute=on_execute, on_completion=on_completion) return if src_host is not None and dst_host is not None: with utils.tempdir() as tempdir: self.copy_file(src, tempdir, None, None, compression) self.copy_file(os.path.join(tempdir, os.path.basename(src_path)), dst, on_execute, on_completion, compression) return # After here, exactly one of src and dst is remote if self._is_dir(src_host, src_path): self.create_dir(dst_host, os.path.join(dst_path, os.path.basename(src)), None, None) # As far as ploop disks are in fact directories we add '-r' argument if src_host is not None: host = src_host sftp_cmd = '@get -r ' + self._remote_path(src_path) + ' ' + dst_path else: host = dst_host sftp_cmd = '@put -r ' + src_path + ' ' + self._remote_path(dst_path) args = ['sftp', '-b', '-', host] if compression: args.append('-C') processutils.execute( *args, process_input=sftp_cmd, on_execute=on_execute, on_completion=on_completion) def _list_files(self, host, dst_path): if host is None: dirs = [] files = [] for f in os.listdir(dst_path): if os.path.isdir(f): dirs.append(f) if os.path.isfile(f): files.append(f) return (dirs, files) args = ['sftp', '-b', '-', host] # Only basename is displayed when executed with -l sftp_cmd = '@ls -1al ' + self._remote_path(dst_path) ls_out = processutils.execute(*args, process_input=sftp_cmd)[0] dirs = [] files = [] for line in ls_out.split(""\n""): if line == '': continue line_split = line.split(' ') is_dir = line_split[0][0] == 'd' name = line_split[-1] if name == ('.') or name == ('..'): continue if is_dir: dirs.append(name) else: files.append(name) return (dirs, files) def _is_dir(self, host, dst_path): if host is None: if not os.path.exists(dst_path): raise exception.NovaException('Path not found: %s' % dst_path) return os.path.isdir(dst_path) args = ['sftp', '-b', '-', host] # Full path is displayed when executed without -l sftp_cmd = '@ls -1a ' + self._remote_path(dst_path) ls_out = processutils.execute(*args, process_input=sftp_cmd)[0] for name in ls_out.split(""\n""): if name == os.path.join(self._remote_path(dst_path), '.'): return True return False def _remote_path(self, path): sftp_remote_chroot = CONF.libvirt.sftp_remote_chroot if sftp_remote_chroot is None: return path chroot_canonical_path = os.path.abspath(sftp_remote_chroot) target_canonical_path = os.path.abspath(path) if os.path.commonpath([chroot_canonical_path, target_canonical_path]) != chroot_canonical_path: raise exception.NovaException('Trying to access outside the chroot: accessing %(path)s, ' 'chroot %(chroot)s' % {'path': path, 'chroot': sftp_remote_chroot}) return path[len(chroot_canonical_path):]",,207,2
openstack%2Fironic~879060,openstack/ironic,master,I34f58f4e77e7757b89247fd64f5fcde26f679453,Add hold steps,MERGED,2023-03-30 16:18:46.000000000,2023-07-07 04:31:22.000000000,2023-07-07 04:28:36.000000000,"[{'_account_id': 4571}, {'_account_id': 10239}, {'_account_id': 10342}, {'_account_id': 11655}, {'_account_id': 22348}]","[{'number': 1, 'created': '2023-03-30 16:18:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/7313809ca3fb312ea3d375d97b11179b70099771', 'message': 'WIP: Add hold steps\n\nChange-Id: I34f58f4e77e7757b89247fd64f5fcde26f679453\n'}, {'number': 2, 'created': '2023-03-30 22:07:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/691e1939a3b1ee13425e23771cd22d628e500704', 'message': 'WIP: Add hold steps\n\nChange-Id: I34f58f4e77e7757b89247fd64f5fcde26f679453\n'}, {'number': 3, 'created': '2023-04-05 21:26:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/6a1e638ef5e307e9044dae6939bfe56018740cd5', 'message': 'WIP: Add hold steps\n\nChange-Id: I34f58f4e77e7757b89247fd64f5fcde26f679453\n'}, {'number': 4, 'created': '2023-04-05 21:59:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/03c850d5f65f79d3cc1ea005ac65c1f056f263a9', 'message': 'WIP: Add hold steps\n\nChange-Id: I34f58f4e77e7757b89247fd64f5fcde26f679453\n'}, {'number': 5, 'created': '2023-05-05 00:24:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/b5b0a9686b5a174198f9df459070ecc77d26ca62', 'message': 'WIP: Add hold steps\n\nChange-Id: I34f58f4e77e7757b89247fd64f5fcde26f679453\n'}, {'number': 6, 'created': '2023-05-05 00:45:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/77e2103e4ab2b45a2dd6915ea41ef7bf25ca1e19', 'message': 'WIP: Add hold steps\n\nChange-Id: I34f58f4e77e7757b89247fd64f5fcde26f679453\n'}, {'number': 7, 'created': '2023-05-05 00:49:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/fc70efce352fbba97a579a0d84a21050c3d4f252', 'message': 'WIP: Add hold steps\n\nChange-Id: I34f58f4e77e7757b89247fd64f5fcde26f679453\n'}, {'number': 8, 'created': '2023-05-19 18:19:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/9ad890d2312efad9d02fa95c6abcd5e9cf047e97', 'message': ""Add hold steps\n\n* Updates API version to 1.84 to permit an ``unhold`` verb\n* Adds the ``deploy hold`` and ``clean hold`` provision states\n  to the internal state machine.\n* Adds on documentation on steps to help provide greater clarity\n  to Ironic's users on how to utilize steps. It should be noted\n  this documentation also includes the power state reserved step\n  names from the DPU functionality patch.\n* Fixes the state machine diagram. Changes type to PNG as SVG\n  rendering is broken due to python libraries utilized for SVG\n  generation which do not work on more recent Python versions.\n\nChange-Id: I34f58f4e77e7757b89247fd64f5fcde26f679453\n""}, {'number': 9, 'created': '2023-05-24 15:10:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/3c76788c71fc49e3800e24b955d225188de1c35a', 'message': ""Add hold steps\n\n* Updates API version to 1.84 to permit an ``unhold`` verb\n* Adds the ``deploy hold`` and ``clean hold`` provision states\n  to the internal state machine.\n* Adds on documentation on steps to help provide greater clarity\n  to Ironic's users on how to utilize steps. It should be noted\n  this documentation also includes the power state reserved step\n  names from the DPU functionality patch.\n* Fixes the state machine diagram. Changes type to PNG as SVG\n  rendering is broken due to python libraries utilized for SVG\n  generation which do not work on more recent Python versions.\n\nChange-Id: I34f58f4e77e7757b89247fd64f5fcde26f679453\n""}, {'number': 10, 'created': '2023-05-24 21:37:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/c91bfb90672b9cd4c74407c19fe8d59a3658a722', 'message': ""Add hold steps\n\n* Updates API version to 1.84 to permit an ``unhold`` verb\n* Adds the ``deploy hold`` and ``clean hold`` provision states\n  to the internal state machine.\n* Adds on documentation on steps to help provide greater clarity\n  to Ironic's users on how to utilize steps. It should be noted\n  this documentation also includes the power state reserved step\n  names from the DPU functionality patch.\n* Fixes the state machine diagram. Changes type to PNG as SVG\n  rendering is broken due to python libraries utilized for SVG\n  generation which do not work on more recent Python versions.\n\nChange-Id: I34f58f4e77e7757b89247fd64f5fcde26f679453\n""}, {'number': 11, 'created': '2023-05-24 23:18:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/23045403719a99d46fe429497fd164bbf779977c', 'message': ""Add hold steps\n\n* Updates API version to 1.84 to permit an ``unhold`` verb\n* Adds the ``deploy hold`` and ``clean hold`` provision states\n  to the internal state machine.\n* Adds on documentation on steps to help provide greater clarity\n  to Ironic's users on how to utilize steps. It should be noted\n  this documentation also includes the power state reserved step\n  names from the DPU functionality patch.\n* Fixes the state machine diagram. Changes type to PNG as SVG\n  rendering is broken due to python libraries utilized for SVG\n  generation which do not work on more recent Python versions.\n\nChange-Id: I34f58f4e77e7757b89247fd64f5fcde26f679453\n""}, {'number': 12, 'created': '2023-05-25 14:27:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/637d294cb15ebd19dea3a5b830bc839d67027d15', 'message': ""Add hold steps\n\n* Updates API version to 1.84 to permit an ``unhold`` verb\n* Adds the ``deploy hold`` and ``clean hold`` provision states\n  to the internal state machine.\n* Adds on documentation on steps to help provide greater clarity\n  to Ironic's users on how to utilize steps. It should be noted\n  this documentation also includes the power state reserved step\n  names from the DPU functionality patch.\n* Fixes the state machine diagram. Changes type to PNG as SVG\n  rendering is broken due to python libraries utilized for SVG\n  generation which do not work on more recent Python versions.\n\nChange-Id: I34f58f4e77e7757b89247fd64f5fcde26f679453\n""}, {'number': 13, 'created': '2023-06-24 16:06:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/0d7aa19a545954fb4a58f3d0e9377e6d4bba2771', 'message': ""WIP Add hold steps\n\n* Updates API version to 1.84 to permit an ``unhold`` verb\n* Adds the ``deploy hold`` and ``clean hold`` provision states\n  to the internal state machine.\n* Adds on documentation on steps to help provide greater clarity\n  to Ironic's users on how to utilize steps. It should be noted\n  this documentation also includes the power state reserved step\n  names from the DPU functionality patch.\n* Fixes the state machine diagram. Changes type to PNG as SVG\n  rendering is broken due to python libraries utilized for SVG\n  generation which do not work on more recent Python versions.\n\nChange-Id: I34f58f4e77e7757b89247fd64f5fcde26f679453\n""}, {'number': 14, 'created': '2023-06-30 16:21:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/a8c158d2661c4ea976b2b1ad4795c8c53413b812', 'message': ""Add hold steps\n\n* Updates API version to 1.85 to permit an ``unhold`` verb\n* Adds the ``deploy hold`` and ``clean hold`` provision states\n  to the internal state machine.\n* Adds on documentation on steps to help provide greater clarity\n  to Ironic's users on how to utilize steps. It should be noted\n  this documentation also includes the power state reserved step\n  names from the DPU functionality patch.\n* Fixes the state machine diagram. Changes type to PNG as SVG\n  rendering is broken due to python libraries utilized for SVG\n  generation which do not work on more recent Python versions.\n\nChange-Id: I34f58f4e77e7757b89247fd64f5fcde26f679453\n""}, {'number': 15, 'created': '2023-06-30 16:37:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/4aa66f53509d6ac57315ad776439c595ca538ee6', 'message': ""Add hold steps\n\n* Updates API version to 1.85 to permit an ``unhold`` verb\n* Adds the ``deploy hold`` and ``clean hold`` provision states\n  to the internal state machine.\n* Adds on documentation on steps to help provide greater clarity\n  to Ironic's users on how to utilize steps. It should be noted\n  this documentation also includes the power state reserved step\n  names from the DPU functionality patch.\n* Fixes the state machine diagram. Changes type to PNG as SVG\n  rendering is broken due to python libraries utilized for SVG\n  generation which do not work on more recent Python versions.\n\nChange-Id: I34f58f4e77e7757b89247fd64f5fcde26f679453\n""}, {'number': 16, 'created': '2023-06-30 21:36:03.000000000', 'files': ['doc/source/admin/index.rst', 'ironic/tests/unit/conductor/test_manager.py', 'ironic/tests/unit/conductor/test_cleaning.py', 'ironic/conductor/steps.py', 'ironic/api/controllers/v1/utils.py', 'ironic/common/release_mappings.py', 'ironic/common/states.py', 'doc/source/admin/steps.rst', 'releasenotes/notes/add-hold-states-7be5804d6f3a119a.yaml', 'tools/states_to_dot.py', 'ironic/tests/unit/drivers/modules/test_agent_base.py', 'ironic/tests/unit/api/controllers/v1/test_node.py', 'ironic/conductor/cleaning.py', 'doc/source/contributor/webapi-version-history.rst', 'ironic/conductor/manager.py', 'doc/source/user/states.rst', 'ironic/api/controllers/v1/versions.py', 'ironic/drivers/modules/agent_base.py', 'ironic/tests/unit/conductor/test_deployments.py', 'doc/source/images/states.svg', 'ironic/conductor/deployments.py', 'tox.ini', 'doc/source/images/states.png', 'ironic/api/controllers/v1/node.py'], 'web_link': 'https://opendev.org/openstack/ironic/commit/c4e3100d5c99f276aba2d2ed3d55dd9e6650c276', 'message': ""Add hold steps\n\n* Updates API version to 1.85 to permit an ``unhold`` verb\n* Adds the ``deploy hold`` and ``clean hold`` provision states\n  to the internal state machine.\n* Adds on documentation on steps to help provide greater clarity\n  to Ironic's users on how to utilize steps. It should be noted\n  this documentation also includes the power state reserved step\n  names from the DPU functionality patch.\n* Fixes the state machine diagram. Changes type to PNG as SVG\n  rendering is broken due to python libraries utilized for SVG\n  generation which do not work on more recent Python versions.\n\nChange-Id: I34f58f4e77e7757b89247fd64f5fcde26f679453\n""}]",44,879060,c4e3100d5c99f276aba2d2ed3d55dd9e6650c276,61,5,16,11655,,,0,"Add hold steps

* Updates API version to 1.85 to permit an ``unhold`` verb
* Adds the ``deploy hold`` and ``clean hold`` provision states
  to the internal state machine.
* Adds on documentation on steps to help provide greater clarity
  to Ironic's users on how to utilize steps. It should be noted
  this documentation also includes the power state reserved step
  names from the DPU functionality patch.
* Fixes the state machine diagram. Changes type to PNG as SVG
  rendering is broken due to python libraries utilized for SVG
  generation which do not work on more recent Python versions.

Change-Id: I34f58f4e77e7757b89247fd64f5fcde26f679453
",git fetch https://review.opendev.org/openstack/ironic refs/changes/60/879060/1 && git format-patch -1 --stdout FETCH_HEAD,"['doc/source/admin/index.rst', 'ironic/tests/unit/drivers/modules/test_agent_base.py', 'ironic/tests/unit/conductor/test_manager.py', 'doc/source/admin/reserved-functional-steps.rst', 'ironic/tests/unit/conductor/test_cleaning.py', 'ironic/conductor/cleaning.py', 'ironic/conductor/manager.py', 'ironic/drivers/modules/agent_base.py', 'ironic/conductor/steps.py', 'ironic/tests/unit/conductor/test_deployments.py', 'ironic/common/states.py', 'ironic/conductor/deployments.py']",12,7313809ca3fb312ea3d375d97b11179b70099771,sleep_step," if conductor_steps.reserved_step_name_handler(task, step): return",,193,8
openstack%2Foctavia~886699,openstack/octavia,master,I9ca1b2e5c222a9d7dca21c943f375cc07043fe72,Imported Translations from Zanata,MERGED,2023-06-22 04:12:39.000000000,2023-07-07 04:07:21.000000000,2023-07-07 04:06:06.000000000,"[{'_account_id': 11628}, {'_account_id': 22348}, {'_account_id': 26285}, {'_account_id': 34429}]","[{'number': 1, 'created': '2023-06-22 04:12:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/octavia/commit/28810bdcf1d11bab047af30e95fdb34b0590ed82', 'message': 'Imported Translations from Zanata\n\nFor more information about this automatic import see:\nhttps://docs.openstack.org/i18n/latest/reviewing-translation-import.html\n\nChange-Id: I9ca1b2e5c222a9d7dca21c943f375cc07043fe72\n'}, {'number': 2, 'created': '2023-06-23 03:59:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/octavia/commit/2f10afcdcdc4877d79a3667b8961aa809c4158a7', 'message': 'Imported Translations from Zanata\n\nFor more information about this automatic import see:\nhttps://docs.openstack.org/i18n/latest/reviewing-translation-import.html\n\nChange-Id: I9ca1b2e5c222a9d7dca21c943f375cc07043fe72\n'}, {'number': 3, 'created': '2023-07-04 02:58:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/octavia/commit/aff5a184d589bb1477ee5ebcdb45bd160d9b8314', 'message': 'Imported Translations from Zanata\n\nFor more information about this automatic import see:\nhttps://docs.openstack.org/i18n/latest/reviewing-translation-import.html\n\nChange-Id: I9ca1b2e5c222a9d7dca21c943f375cc07043fe72\n'}, {'number': 4, 'created': '2023-07-07 03:00:47.000000000', 'files': ['releasenotes/source/locale/en_GB/LC_MESSAGES/releasenotes.po'], 'web_link': 'https://opendev.org/openstack/octavia/commit/a9359ab7b3a094968cc128d8c22eacc86a93d2e6', 'message': 'Imported Translations from Zanata\n\nFor more information about this automatic import see:\nhttps://docs.openstack.org/i18n/latest/reviewing-translation-import.html\n\nChange-Id: I9ca1b2e5c222a9d7dca21c943f375cc07043fe72\n'}]",1,886699,a9359ab7b3a094968cc128d8c22eacc86a93d2e6,15,4,4,11131,,,0,"Imported Translations from Zanata

For more information about this automatic import see:
https://docs.openstack.org/i18n/latest/reviewing-translation-import.html

Change-Id: I9ca1b2e5c222a9d7dca21c943f375cc07043fe72
",git fetch https://review.opendev.org/openstack/octavia refs/changes/99/886699/1 && git format-patch -1 --stdout FETCH_HEAD,['releasenotes/source/locale/en_GB/LC_MESSAGES/releasenotes.po'],1,28810bdcf1d11bab047af30e95fdb34b0590ed82,zanata/translations,"""POT-Creation-Date: 2023-06-21 17:35+0000\n""""PO-Revision-Date: 2023-06-21 09:03+0000\n""msgid ""10.0.0-59"" msgstr ""10.0.0-59"" msgid ""11.0.0-18"" msgstr ""11.0.0-18"" msgid ""12.0.0-8"" msgstr ""12.0.0-8"" msgid ""12.0.0.0rc1-34"" msgstr ""12.0.0.0rc1-34"" msgid ""2023.1 Series Release Notes"" msgstr ""2023.1 Series Release Notes"" msgid ""5.1.2-37"" msgstr ""5.1.2-37""msgid ""7.1.2-35"" msgstr ""7.1.2-35""msgid ""8.0.1-67"" msgstr ""8.0.1-67""msgid ""9.1.0-17"" msgstr ""9.1.0-17""msgid ""Zed Series Release Notes"" msgstr ""Zed Series Release Notes"" ","""POT-Creation-Date: 2023-05-16 18:42+0000\n""""PO-Revision-Date: 2023-05-08 11:50+0000\n""msgid ""5.1.2-36"" msgstr ""5.1.2-36""msgid ""7.1.2-34"" msgstr ""7.1.2-34""msgid ""8.0.1-66"" msgstr ""8.0.1-66""msgid ""9.1.0-16"" msgstr ""9.1.0-16""",28,10
openstack%2Fneutron~887616,openstack/neutron,stable/yoga,I1a3723ae999fefb5dcbe3a60cf1a4902da9f0265,Don't allow deletion of the router ports without IP addresses,MERGED,2023-07-04 14:49:17.000000000,2023-07-07 02:41:30.000000000,2023-07-07 02:39:38.000000000,"[{'_account_id': 16688}, {'_account_id': 21798}, {'_account_id': 22348}]","[{'number': 1, 'created': '2023-07-04 14:49:17.000000000', 'files': ['neutron/db/l3_db.py', 'neutron/tests/unit/db/test_l3_db.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/4f043fb7ad672d3aa71674ec820b3be5f9aaad9f', 'message': ""Don't allow deletion of the router ports without IP addresses\n\nThis patch effectively reverts old patch [1]. From now on it will be not\nallowed to directly remove router ports which don't have fixed IPs\nassigned. Such ports will be treated as any other ports connected to the\nrouters.\nOriginally [1] was introduced to allow cleanup of the router ports for\nwhich subnets were deleted. But now it's not needed anymore as we\nprevent deletion of subnet if there are any ports with IP allocated from\nthat subnet.\n\nCloses-bug: #2025056\n\n[1] https://review.opendev.org/c/openstack/neutron/+/20424\n\nChange-Id: I1a3723ae999fefb5dcbe3a60cf1a4902da9f0265\n(cherry picked from commit 32d589f03ed0d2744fe15173ebacafd18fced8a9)\n""}]",2,887616,4f043fb7ad672d3aa71674ec820b3be5f9aaad9f,17,3,1,11975,,,0,"Don't allow deletion of the router ports without IP addresses

This patch effectively reverts old patch [1]. From now on it will be not
allowed to directly remove router ports which don't have fixed IPs
assigned. Such ports will be treated as any other ports connected to the
routers.
Originally [1] was introduced to allow cleanup of the router ports for
which subnets were deleted. But now it's not needed anymore as we
prevent deletion of subnet if there are any ports with IP allocated from
that subnet.

Closes-bug: #2025056

[1] https://review.opendev.org/c/openstack/neutron/+/20424

Change-Id: I1a3723ae999fefb5dcbe3a60cf1a4902da9f0265
(cherry picked from commit 32d589f03ed0d2744fe15173ebacafd18fced8a9)
",git fetch https://review.opendev.org/openstack/neutron refs/changes/16/887616/1 && git format-patch -1 --stdout FETCH_HEAD,"['neutron/db/l3_db.py', 'neutron/tests/unit/db/test_l3_db.py']",2,4f043fb7ad672d3aa71674ec820b3be5f9aaad9f,bug/2025056-stable/2023.1-stable/zed-stable/yoga," 'device_id': '44', 'id': 'f', } with testtools.ExpectedException(n_exc.ServicePortInUse): self.db.prevent_l3_port_deletion(mock.Mock(), None)"," 'id': 'f' } self.db.prevent_l3_port_deletion(None, None)",3,11
openstack%2Fneutron~887600,openstack/neutron,stable/2023.1,I8cfa7e67524a42224cbb4b3c3cec3cfa49b795fd,[OVN] Prevent Trunk creation/deletion with parent port bound,MERGED,2023-07-04 13:27:43.000000000,2023-07-07 01:27:50.000000000,2023-07-07 01:26:31.000000000,"[{'_account_id': 8313}, {'_account_id': 11975}, {'_account_id': 21798}, {'_account_id': 22348}]","[{'number': 1, 'created': '2023-07-04 13:27:43.000000000', 'files': ['neutron/tests/unit/db/test_l3_dvr_db.py', 'neutron/tests/unit/services/trunk/test_plugin.py', 'neutron/db/l3_dvr_db.py', 'releasenotes/notes/ovn-trunk-check-parent-port-eeca2eceaca9d158.yaml', 'neutron/services/trunk/drivers/ovn/trunk_driver.py', 'neutron/common/utils.py', 'neutron/services/trunk/plugin.py', 'neutron/tests/functional/services/trunk/drivers/ovn/test_trunk_driver.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/2f48c24d412ee07d7cc609cf8379de83380324e3', 'message': '[OVN] Prevent Trunk creation/deletion with parent port bound\n\nThis patch imitates the ML2/OVS Trunk driver behaviour. When the\ntrunk parent port is bound:\n* A new trunk cannot be created using this parent port.\n* If the port is assigned as parent port of a trunk, this\n  trunk cannot be deleted.\n\nConflicts:\n    neutron/common/utils.py\n\nCloses-Bug: #2022059\nChange-Id: I8cfa7e67524a42224cbb4b3c3cec3cfa49b795fd\n(cherry picked from commit 833a6d82cd705548130cdac73a88d388f52c7824)\n'}]",3,887600,2f48c24d412ee07d7cc609cf8379de83380324e3,10,4,1,16688,,,0,"[OVN] Prevent Trunk creation/deletion with parent port bound

This patch imitates the ML2/OVS Trunk driver behaviour. When the
trunk parent port is bound:
* A new trunk cannot be created using this parent port.
* If the port is assigned as parent port of a trunk, this
  trunk cannot be deleted.

Conflicts:
    neutron/common/utils.py

Closes-Bug: #2022059
Change-Id: I8cfa7e67524a42224cbb4b3c3cec3cfa49b795fd
(cherry picked from commit 833a6d82cd705548130cdac73a88d388f52c7824)
",git fetch https://review.opendev.org/openstack/neutron refs/changes/00/887600/1 && git format-patch -1 --stdout FETCH_HEAD,"['neutron/tests/unit/db/test_l3_dvr_db.py', 'neutron/tests/unit/services/trunk/test_plugin.py', 'neutron/db/l3_dvr_db.py', 'releasenotes/notes/ovn-trunk-check-parent-port-eeca2eceaca9d158.yaml', 'neutron/services/trunk/drivers/ovn/trunk_driver.py', 'neutron/common/utils.py', 'neutron/services/trunk/plugin.py', 'neutron/tests/functional/services/trunk/drivers/ovn/test_trunk_driver.py']",8,2f48c24d412ee07d7cc609cf8379de83380324e3,bug/2022059,"from neutron_lib.callbacks import exceptions as n_exc def test_trunk_create_parent_port_bound(self): with self.network() as network: with self.subnet(network=network) as subnet: with self.port(subnet=subnet) as parent_port: pb = port_obj.PortBinding.get_objects( self.context, port_id=parent_port['port']['id']) port_obj.PortBinding.update_object( self.context, {'vif_type': portbindings.VIF_TYPE_OVS}, port_id=pb[0].port_id, host=pb[0].host) tenant_id = uuidutils.generate_uuid() trunk = {'trunk': { 'port_id': parent_port['port']['id'], 'tenant_id': tenant_id, 'project_id': tenant_id, 'admin_state_up': True, 'name': 'trunk', 'sub_ports': []}} self.assertRaises(n_exc.CallbackFailure, self.trunk_plugin.create_trunk, self.context, trunk) def test_trunk_delete_parent_port_bound(self): with self.trunk() as trunk: bp = port_obj.PortBinding.get_objects( self.context, port_id=trunk['port_id']) port_obj.PortBinding.update_object( self.context, {'vif_type': portbindings.VIF_TYPE_OVS}, port_id=bp[0].port_id, host=bp[0].host) self.assertRaises(n_exc.CallbackFailure, self.trunk_plugin.delete_trunk, self.context, trunk['id'])",,79,19
openstack%2Fneutron~887601,openstack/neutron,stable/zed,I8cfa7e67524a42224cbb4b3c3cec3cfa49b795fd,[OVN] Prevent Trunk creation/deletion with parent port bound,MERGED,2023-07-04 13:29:47.000000000,2023-07-07 01:27:49.000000000,2023-07-07 01:26:35.000000000,"[{'_account_id': 8313}, {'_account_id': 11975}, {'_account_id': 21798}, {'_account_id': 22348}]","[{'number': 1, 'created': '2023-07-04 13:29:47.000000000', 'files': ['neutron/tests/unit/db/test_l3_dvr_db.py', 'neutron/tests/unit/services/trunk/test_plugin.py', 'neutron/db/l3_dvr_db.py', 'releasenotes/notes/ovn-trunk-check-parent-port-eeca2eceaca9d158.yaml', 'neutron/services/trunk/drivers/ovn/trunk_driver.py', 'neutron/common/utils.py', 'neutron/services/trunk/plugin.py', 'neutron/tests/functional/services/trunk/drivers/ovn/test_trunk_driver.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/0d499808f1f3ec6cf40bb87eb32789c463401338', 'message': '[OVN] Prevent Trunk creation/deletion with parent port bound\n\nThis patch imitates the ML2/OVS Trunk driver behaviour. When the\ntrunk parent port is bound:\n* A new trunk cannot be created using this parent port.\n* If the port is assigned as parent port of a trunk, this\n  trunk cannot be deleted.\n\nConflicts:\n    neutron/common/utils.py\n\nCloses-Bug: #2022059\nChange-Id: I8cfa7e67524a42224cbb4b3c3cec3cfa49b795fd\n(cherry picked from commit 833a6d82cd705548130cdac73a88d388f52c7824)\n(cherry picked from commit 2f48c24d412ee07d7cc609cf8379de83380324e3)\n'}]",1,887601,0d499808f1f3ec6cf40bb87eb32789c463401338,9,4,1,16688,,,0,"[OVN] Prevent Trunk creation/deletion with parent port bound

This patch imitates the ML2/OVS Trunk driver behaviour. When the
trunk parent port is bound:
* A new trunk cannot be created using this parent port.
* If the port is assigned as parent port of a trunk, this
  trunk cannot be deleted.

Conflicts:
    neutron/common/utils.py

Closes-Bug: #2022059
Change-Id: I8cfa7e67524a42224cbb4b3c3cec3cfa49b795fd
(cherry picked from commit 833a6d82cd705548130cdac73a88d388f52c7824)
(cherry picked from commit 2f48c24d412ee07d7cc609cf8379de83380324e3)
",git fetch https://review.opendev.org/openstack/neutron refs/changes/01/887601/1 && git format-patch -1 --stdout FETCH_HEAD,"['neutron/tests/unit/db/test_l3_dvr_db.py', 'neutron/tests/unit/services/trunk/test_plugin.py', 'neutron/db/l3_dvr_db.py', 'releasenotes/notes/ovn-trunk-check-parent-port-eeca2eceaca9d158.yaml', 'neutron/services/trunk/drivers/ovn/trunk_driver.py', 'neutron/common/utils.py', 'neutron/services/trunk/plugin.py', 'neutron/tests/functional/services/trunk/drivers/ovn/test_trunk_driver.py']",8,0d499808f1f3ec6cf40bb87eb32789c463401338,bug/2022059,"from neutron_lib.callbacks import exceptions as n_exc def test_trunk_create_parent_port_bound(self): with self.network() as network: with self.subnet(network=network) as subnet: with self.port(subnet=subnet) as parent_port: pb = port_obj.PortBinding.get_objects( self.context, port_id=parent_port['port']['id']) port_obj.PortBinding.update_object( self.context, {'vif_type': portbindings.VIF_TYPE_OVS}, port_id=pb[0].port_id, host=pb[0].host) tenant_id = uuidutils.generate_uuid() trunk = {'trunk': { 'port_id': parent_port['port']['id'], 'tenant_id': tenant_id, 'project_id': tenant_id, 'admin_state_up': True, 'name': 'trunk', 'sub_ports': []}} self.assertRaises(n_exc.CallbackFailure, self.trunk_plugin.create_trunk, self.context, trunk) def test_trunk_delete_parent_port_bound(self): with self.trunk() as trunk: bp = port_obj.PortBinding.get_objects( self.context, port_id=trunk['port_id']) port_obj.PortBinding.update_object( self.context, {'vif_type': portbindings.VIF_TYPE_OVS}, port_id=bp[0].port_id, host=bp[0].host) self.assertRaises(n_exc.CallbackFailure, self.trunk_plugin.delete_trunk, self.context, trunk['id'])",,79,19
openstack%2Fansible-role-python_venv_build~887384,openstack/ansible-role-python_venv_build,master,I4ceeee4bf6c1020851824450ec7b30f6d14573f3,Remove warn argument for command/shell,MERGED,2023-06-30 14:56:07.000000000,2023-07-07 00:12:56.000000000,2023-07-07 00:12:02.000000000,"[{'_account_id': 22348}, {'_account_id': 25023}, {'_account_id': 32666}]","[{'number': 1, 'created': '2023-06-30 14:56:07.000000000', 'files': ['tasks/python_venv_install_symlink.yml'], 'web_link': 'https://opendev.org/openstack/ansible-role-python_venv_build/commit/0e1abb285872c2f677e3e382f9e7fd13abc76ed9', 'message': ""Remove warn argument for command/shell\n\nSince ansible-core 2.14 you can't use warn as module argument.\n\nInstead, a tag is used to instruct ansible-lint to\nsupress alerts.\n\nChange-Id: I4ceeee4bf6c1020851824450ec7b30f6d14573f3\n""}]",1,887384,0e1abb285872c2f677e3e382f9e7fd13abc76ed9,10,3,1,28619,,,0,"Remove warn argument for command/shell

Since ansible-core 2.14 you can't use warn as module argument.

Instead, a tag is used to instruct ansible-lint to
supress alerts.

Change-Id: I4ceeee4bf6c1020851824450ec7b30f6d14573f3
",git fetch https://review.opendev.org/openstack/ansible-role-python_venv_build refs/changes/84/887384/1 && git format-patch -1 --stdout FETCH_HEAD,['tasks/python_venv_install_symlink.yml'],1,0e1abb285872c2f677e3e382f9e7fd13abc76ed9,osa/core-2.15, tags: - skip_ansible_lint, args: warn: no,2,2
openstack%2Fansible-role-systemd_mount~887378,openstack/ansible-role-systemd_mount,master,I7287d449b8fd0ad970e37aa63b5cb25f88197858,Remove warn argument for command/shell,MERGED,2023-06-30 13:28:43.000000000,2023-07-07 00:05:50.000000000,2023-07-07 00:04:57.000000000,"[{'_account_id': 22348}, {'_account_id': 25023}, {'_account_id': 32666}]","[{'number': 1, 'created': '2023-06-30 13:28:43.000000000', 'files': ['tasks/systemd_mounts.yml'], 'web_link': 'https://opendev.org/openstack/ansible-role-systemd_mount/commit/34b6061ab56857976447e50104f585340dde0b05', 'message': ""Remove warn argument for command/shell\n\nSince ansible-core 2.14 you can't use warn as module argument.\n\nIt's being removed to avoid module failure.\n\nChange-Id: I7287d449b8fd0ad970e37aa63b5cb25f88197858\n""}]",0,887378,34b6061ab56857976447e50104f585340dde0b05,8,3,1,28619,,,0,"Remove warn argument for command/shell

Since ansible-core 2.14 you can't use warn as module argument.

It's being removed to avoid module failure.

Change-Id: I7287d449b8fd0ad970e37aa63b5cb25f88197858
",git fetch https://review.opendev.org/openstack/ansible-role-systemd_mount refs/changes/78/887378/1 && git format-patch -1 --stdout FETCH_HEAD,['tasks/systemd_mounts.yml'],1,34b6061ab56857976447e50104f585340dde0b05,osa/core-2.15,, args: warn: no,0,2
openstack%2Fansible-role-pki~887374,openstack/ansible-role-pki,master,I453d2db4eeefb78735db54cf9e6fa8fa5f89b069,Convert loop labels to strings,MERGED,2023-06-30 12:50:02.000000000,2023-07-06 23:38:10.000000000,2023-07-06 23:37:19.000000000,"[{'_account_id': 22348}, {'_account_id': 25023}, {'_account_id': 32666}]","[{'number': 1, 'created': '2023-06-30 12:50:02.000000000', 'files': ['tasks/main_certs.yml', 'tasks/standalone/install_ca.yml'], 'web_link': 'https://opendev.org/openstack/ansible-role-pki/commit/1139b8a18f17b1c0755e579e23cc68b6f9be5aaf', 'message': ""Convert loop labels to strings\n\nSince ansible-core 2.15 it's a requirement to have loop\nlabels as strings. In order to remain code readable, we move\ndefinition of label to vars and convert them to json string for\noutput.\n\nChange-Id: I453d2db4eeefb78735db54cf9e6fa8fa5f89b069\n""}]",0,887374,1139b8a18f17b1c0755e579e23cc68b6f9be5aaf,9,3,1,28619,,,0,"Convert loop labels to strings

Since ansible-core 2.15 it's a requirement to have loop
labels as strings. In order to remain code readable, we move
definition of label to vars and convert them to json string for
output.

Change-Id: I453d2db4eeefb78735db54cf9e6fa8fa5f89b069
",git fetch https://review.opendev.org/openstack/ansible-role-pki refs/changes/74/887374/1 && git format-patch -1 --stdout FETCH_HEAD,"['tasks/main_certs.yml', 'tasks/standalone/install_ca.yml']",2,1139b8a18f17b1c0755e579e23cc68b6f9be5aaf,osa/core-2.15," label: ""{{ loop_label | to_json }}"" vars: loop_label:", label:,9,3
openstack%2Frequirements~887781,openstack/requirements,master,I37fe5174dbd7deadb350aa9956581a944202ffbc,Bump oslo.db to 12.3.2,MERGED,2023-07-06 09:41:58.000000000,2023-07-06 22:44:39.000000000,2023-07-06 22:42:52.000000000,"[{'_account_id': 14288}, {'_account_id': 22348}, {'_account_id': 28522}]","[{'number': 1, 'created': '2023-07-06 09:41:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/requirements/commit/ed8e05b925d137ef4a51b1930f4aa8cf4de6c2d5', 'message': ""Bump oslo.db to 12.3.2\n\nWe are currently blocked from upgrading to oslo.db 13.x since that\nremoves support for things like sqlalchemy-migrate, which unfortunately\nare still being used by a few projects. However, there's an annoying bug\nthat is causing spurious warning messages during test runs in various\nprojects. This has been fixed on the most recent stable branch [1], so\nwe can at least bump our upper constraint to drag this in while waiting\nfor a chance to use 13.x.\n\nChange-Id: I37fe5174dbd7deadb350aa9956581a944202ffbc\nSigned-off-by: Stephen Finucane <stephenfin@redhat.com>\n""}, {'number': 2, 'created': '2023-07-06 09:44:12.000000000', 'files': ['upper-constraints.txt'], 'web_link': 'https://opendev.org/openstack/requirements/commit/95075f38c1a083b268dd3f5177ad30dc71a170d1', 'message': ""Bump oslo.db to 12.3.2\n\nWe are currently blocked from upgrading to oslo.db 13.x since that\nremoves support for things like sqlalchemy-migrate, which unfortunately\nare still being used by a few projects. However, there's an annoying bug\nthat is causing spurious warning messages during test runs in various\nprojects. This has been fixed on the most recent stable branch [1], so\nwe can at least bump our upper constraint to drag this in while waiting\nfor a chance to use 13.x.\n\n[1] https://review.opendev.org/c/openstack/oslo.db/+/880617\n\nChange-Id: I37fe5174dbd7deadb350aa9956581a944202ffbc\nSigned-off-by: Stephen Finucane <stephenfin@redhat.com>\n""}]",0,887781,95075f38c1a083b268dd3f5177ad30dc71a170d1,9,3,2,15334,,,0,"Bump oslo.db to 12.3.2

We are currently blocked from upgrading to oslo.db 13.x since that
removes support for things like sqlalchemy-migrate, which unfortunately
are still being used by a few projects. However, there's an annoying bug
that is causing spurious warning messages during test runs in various
projects. This has been fixed on the most recent stable branch [1], so
we can at least bump our upper constraint to drag this in while waiting
for a chance to use 13.x.

[1] https://review.opendev.org/c/openstack/oslo.db/+/880617

Change-Id: I37fe5174dbd7deadb350aa9956581a944202ffbc
Signed-off-by: Stephen Finucane <stephenfin@redhat.com>
",git fetch https://review.opendev.org/openstack/requirements refs/changes/81/887781/1 && git format-patch -1 --stdout FETCH_HEAD,['upper-constraints.txt'],1,ed8e05b925d137ef4a51b1930f4aa8cf4de6c2d5,oslo.db,oslo.db===12.3.2,oslo.db===12.3.1,1,1
openstack%2Frequirements~887777,openstack/requirements,master,Ia1946f42a187c69872744211fef719bc963b81dc,update constraint for python-ironicclient to new release 5.3.0,MERGED,2023-07-06 09:04:18.000000000,2023-07-06 22:43:45.000000000,2023-07-06 22:42:49.000000000,"[{'_account_id': 14288}, {'_account_id': 22348}, {'_account_id': 28522}]","[{'number': 1, 'created': '2023-07-06 09:04:18.000000000', 'files': ['upper-constraints.txt'], 'web_link': 'https://opendev.org/openstack/requirements/commit/84bce05233e74771e9c18436cbcb91c0bc01a35b', 'message': 'update constraint for python-ironicclient to new release 5.3.0\n\nmeta: version: 5.3.0\nmeta: diff-start: -\nmeta: series: bobcat\nmeta: branch: master\nmeta: release-type: release\nmeta: pypi: yes\nmeta: first: no\nmeta: release:Author: Elod Illes <elod.illes@est.tech>\nmeta: release:Commit: Jay Faulkner <jay@jvf.cc>\nmeta: release:Change-Id: I49a0d84f09177dfba153bd1ec62c698c77bae4ea\nmeta: release:Code-Review+1: Jay Faulkner <jay@jvf.cc>\nmeta: release:Code-Review+2: Thierry Carrez <thierry@openstack.org>\nmeta: release:Code-Review+1: Iury Gregory Melo Ferreira <iurygregory@gmail.com>\nmeta: release:Workflow+1: Thierry Carrez <thierry@openstack.org>\nmeta: release:Code-Review+2: Hervé Beraud <herveberaud.pro@gmail.com>\nChange-Id: Ia1946f42a187c69872744211fef719bc963b81dc\n'}]",0,887777,84bce05233e74771e9c18436cbcb91c0bc01a35b,8,3,1,11131,,,0,"update constraint for python-ironicclient to new release 5.3.0

meta: version: 5.3.0
meta: diff-start: -
meta: series: bobcat
meta: branch: master
meta: release-type: release
meta: pypi: yes
meta: first: no
meta: release:Author: Elod Illes <elod.illes@est.tech>
meta: release:Commit: Jay Faulkner <jay@jvf.cc>
meta: release:Change-Id: I49a0d84f09177dfba153bd1ec62c698c77bae4ea
meta: release:Code-Review+1: Jay Faulkner <jay@jvf.cc>
meta: release:Code-Review+2: Thierry Carrez <thierry@openstack.org>
meta: release:Code-Review+1: Iury Gregory Melo Ferreira <iurygregory@gmail.com>
meta: release:Workflow+1: Thierry Carrez <thierry@openstack.org>
meta: release:Code-Review+2: Hervé Beraud <herveberaud.pro@gmail.com>
Change-Id: Ia1946f42a187c69872744211fef719bc963b81dc
",git fetch https://review.opendev.org/openstack/requirements refs/changes/77/887777/1 && git format-patch -1 --stdout FETCH_HEAD,['upper-constraints.txt'],1,84bce05233e74771e9c18436cbcb91c0bc01a35b,new-release,python-ironicclient===5.3.0,python-ironicclient===5.2.0,1,1
openstack%2Frequirements~887787,openstack/requirements,stable/zed,Ib78698d66a261704afe4ae5c43a39218305dcc87,update constraint for oslo.messaging to new release 14.0.1,MERGED,2023-07-06 10:13:23.000000000,2023-07-06 22:42:57.000000000,2023-07-06 22:42:57.000000000,"[{'_account_id': 14288}, {'_account_id': 22348}, {'_account_id': 28522}]","[{'number': 1, 'created': '2023-07-06 10:13:23.000000000', 'files': ['upper-constraints.txt'], 'web_link': 'https://opendev.org/openstack/requirements/commit/ce23ac59f84228b1747c22311992169cf827cff9', 'message': 'update constraint for oslo.messaging to new release 14.0.1\n\nmeta: version: 14.0.1\nmeta: diff-start: -\nmeta: series: zed\nmeta: branch: stable/zed\nmeta: release-type: release\nmeta: pypi: yes\nmeta: first: no\nmeta: release:Author: Hervé Beraud <hberaud@redhat.com>\nmeta: release:Commit: Hervé Beraud <hberaud@redhat.com>\nmeta: release:Change-Id: If65debbef4ae6527f7a811ace99cf69e4b0d5339\nmeta: release:Code-Review+2: Thierry Carrez <thierry@openstack.org>\nmeta: release:Workflow+1: Elod Illes <elod.illes@est.tech>\nmeta: release:Code-Review+2: Elod Illes <elod.illes@est.tech>\nChange-Id: Ib78698d66a261704afe4ae5c43a39218305dcc87\n'}]",0,887787,ce23ac59f84228b1747c22311992169cf827cff9,8,3,1,11131,,,0,"update constraint for oslo.messaging to new release 14.0.1

meta: version: 14.0.1
meta: diff-start: -
meta: series: zed
meta: branch: stable/zed
meta: release-type: release
meta: pypi: yes
meta: first: no
meta: release:Author: Hervé Beraud <hberaud@redhat.com>
meta: release:Commit: Hervé Beraud <hberaud@redhat.com>
meta: release:Change-Id: If65debbef4ae6527f7a811ace99cf69e4b0d5339
meta: release:Code-Review+2: Thierry Carrez <thierry@openstack.org>
meta: release:Workflow+1: Elod Illes <elod.illes@est.tech>
meta: release:Code-Review+2: Elod Illes <elod.illes@est.tech>
Change-Id: Ib78698d66a261704afe4ae5c43a39218305dcc87
",git fetch https://review.opendev.org/openstack/requirements refs/changes/87/887787/1 && git format-patch -1 --stdout FETCH_HEAD,['upper-constraints.txt'],1,ce23ac59f84228b1747c22311992169cf827cff9,new-release,oslo.messaging===14.0.1,oslo.messaging===14.0.0,1,1
openstack%2Frequirements~887786,openstack/requirements,stable/yoga,I40e4712dabbf4bc4034d28c9b7ab8de6d88b5fbc,update constraint for oslo.messaging to new release 12.13.1,MERGED,2023-07-06 10:01:50.000000000,2023-07-06 22:42:54.000000000,2023-07-06 22:42:54.000000000,"[{'_account_id': 14288}, {'_account_id': 22348}, {'_account_id': 28522}]","[{'number': 1, 'created': '2023-07-06 10:01:50.000000000', 'files': ['upper-constraints.txt'], 'web_link': 'https://opendev.org/openstack/requirements/commit/fb131ba4a3bd11ff87094d96805c925c08b3dfdc', 'message': 'update constraint for oslo.messaging to new release 12.13.1\n\nmeta: version: 12.13.1\nmeta: diff-start: -\nmeta: series: yoga\nmeta: branch: stable/yoga\nmeta: release-type: release\nmeta: pypi: yes\nmeta: first: no\nmeta: release:Author: Hervé Beraud <hberaud@redhat.com>\nmeta: release:Commit: Hervé Beraud <hberaud@redhat.com>\nmeta: release:Change-Id: Ice1fa6e981ca88240f6bdc7ce47f823854d1da40\nmeta: release:Code-Review+2: Thierry Carrez <thierry@openstack.org>\nmeta: release:Workflow+1: Elod Illes <elod.illes@est.tech>\nmeta: release:Code-Review+2: Elod Illes <elod.illes@est.tech>\nChange-Id: I40e4712dabbf4bc4034d28c9b7ab8de6d88b5fbc\n'}]",0,887786,fb131ba4a3bd11ff87094d96805c925c08b3dfdc,8,3,1,11131,,,0,"update constraint for oslo.messaging to new release 12.13.1

meta: version: 12.13.1
meta: diff-start: -
meta: series: yoga
meta: branch: stable/yoga
meta: release-type: release
meta: pypi: yes
meta: first: no
meta: release:Author: Hervé Beraud <hberaud@redhat.com>
meta: release:Commit: Hervé Beraud <hberaud@redhat.com>
meta: release:Change-Id: Ice1fa6e981ca88240f6bdc7ce47f823854d1da40
meta: release:Code-Review+2: Thierry Carrez <thierry@openstack.org>
meta: release:Workflow+1: Elod Illes <elod.illes@est.tech>
meta: release:Code-Review+2: Elod Illes <elod.illes@est.tech>
Change-Id: I40e4712dabbf4bc4034d28c9b7ab8de6d88b5fbc
",git fetch https://review.opendev.org/openstack/requirements refs/changes/86/887786/1 && git format-patch -1 --stdout FETCH_HEAD,['upper-constraints.txt'],1,fb131ba4a3bd11ff87094d96805c925c08b3dfdc,new-release,oslo.messaging===12.13.1,oslo.messaging===12.13.0,1,1
openstack%2Fansible-hardening~887376,openstack/ansible-hardening,master,Ie448fa182db8c1c9f64744ea72f27f285aa64366,Remove warn argument for command/shell,MERGED,2023-06-30 13:05:56.000000000,2023-07-06 22:34:31.000000000,2023-07-06 22:33:35.000000000,"[{'_account_id': 22348}, {'_account_id': 25023}, {'_account_id': 32666}]","[{'number': 1, 'created': '2023-06-30 13:05:56.000000000', 'files': ['tasks/rhel7stig/dnf.yml', 'handlers/main.yml', 'tasks/rhel7stig/file_perms.yml', 'tasks/rhel7stig/async_tasks.yml'], 'web_link': 'https://opendev.org/openstack/ansible-hardening/commit/2c7889852c7e8c6e8ecd14e4ce5304f01792cc01', 'message': ""Remove warn argument for command/shell\n\nSince ansible-core 2.14 you can't use warn as module argument.\n\nInstead, noqa should be used to instruct ansible-lint to\nsupress alerts.\n\nChange-Id: Ie448fa182db8c1c9f64744ea72f27f285aa64366\n""}]",0,887376,2c7889852c7e8c6e8ecd14e4ce5304f01792cc01,8,3,1,28619,,,0,"Remove warn argument for command/shell

Since ansible-core 2.14 you can't use warn as module argument.

Instead, noqa should be used to instruct ansible-lint to
supress alerts.

Change-Id: Ie448fa182db8c1c9f64744ea72f27f285aa64366
",git fetch https://review.opendev.org/openstack/ansible-hardening refs/changes/76/887376/1 && git format-patch -1 --stdout FETCH_HEAD,"['tasks/rhel7stig/dnf.yml', 'handlers/main.yml', 'tasks/rhel7stig/file_perms.yml', 'tasks/rhel7stig/async_tasks.yml']",4,2c7889852c7e8c6e8ecd14e4ce5304f01792cc01,osa/core-2.15," shell: ""rpm -Va > {{ temp_dir }}/rpmverify.txt"" # noqa: command-instead-of-module"," shell: ""rpm -Va > {{ temp_dir }}/rpmverify.txt"" args: warn: no",6,20
openstack%2Frequirements~887773,openstack/requirements,master,I7732bbfa8b5bda15df9499042253a14271c3bd86,update constraint for ovsdbapp to new release 2.4.0,MERGED,2023-07-06 08:57:34.000000000,2023-07-06 22:34:18.000000000,2023-07-06 22:32:27.000000000,"[{'_account_id': 14288}, {'_account_id': 22348}, {'_account_id': 28522}]","[{'number': 1, 'created': '2023-07-06 08:57:34.000000000', 'files': ['upper-constraints.txt'], 'web_link': 'https://opendev.org/openstack/requirements/commit/b2163742523f5753660e997cef981fe537a8fe9d', 'message': 'update constraint for ovsdbapp to new release 2.4.0\n\nmeta: version: 2.4.0\nmeta: diff-start: -\nmeta: series: bobcat\nmeta: branch: master\nmeta: release-type: release\nmeta: pypi: no\nmeta: first: no\nmeta: release:Author: Elod Illes <elod.illes@est.tech>\nmeta: release:Commit: Elod Illes <elod.illes@est.tech>\nmeta: release:Change-Id: I42f7f568e413cb42d22ea7158d87d27dd20e2fb6\nmeta: release:Code-Review+1: likui <likui@yovole.com>\nmeta: release:Code-Review+1: Rodolfo Alonso <ralonsoh@redhat.com>\nmeta: release:Code-Review+2: Elod Illes <elod.illes@est.tech>\nmeta: release:Code-Review+1: Slawek Kaplonski <skaplons@redhat.com>\nmeta: release:Code-Review+1: Lajos Katona <katonalala@gmail.com>\nmeta: release:Workflow+1: Hervé Beraud <herveberaud.pro@gmail.com>\nmeta: release:Code-Review+1: Lucas Alvares Gomes <lucasagomes@gmail.com>\nmeta: release:Code-Review+2: Hervé Beraud <herveberaud.pro@gmail.com>\nChange-Id: I7732bbfa8b5bda15df9499042253a14271c3bd86\n'}]",0,887773,b2163742523f5753660e997cef981fe537a8fe9d,8,3,1,11131,,,0,"update constraint for ovsdbapp to new release 2.4.0

meta: version: 2.4.0
meta: diff-start: -
meta: series: bobcat
meta: branch: master
meta: release-type: release
meta: pypi: no
meta: first: no
meta: release:Author: Elod Illes <elod.illes@est.tech>
meta: release:Commit: Elod Illes <elod.illes@est.tech>
meta: release:Change-Id: I42f7f568e413cb42d22ea7158d87d27dd20e2fb6
meta: release:Code-Review+1: likui <likui@yovole.com>
meta: release:Code-Review+1: Rodolfo Alonso <ralonsoh@redhat.com>
meta: release:Code-Review+2: Elod Illes <elod.illes@est.tech>
meta: release:Code-Review+1: Slawek Kaplonski <skaplons@redhat.com>
meta: release:Code-Review+1: Lajos Katona <katonalala@gmail.com>
meta: release:Workflow+1: Hervé Beraud <herveberaud.pro@gmail.com>
meta: release:Code-Review+1: Lucas Alvares Gomes <lucasagomes@gmail.com>
meta: release:Code-Review+2: Hervé Beraud <herveberaud.pro@gmail.com>
Change-Id: I7732bbfa8b5bda15df9499042253a14271c3bd86
",git fetch https://review.opendev.org/openstack/requirements refs/changes/73/887773/1 && git format-patch -1 --stdout FETCH_HEAD,['upper-constraints.txt'],1,b2163742523f5753660e997cef981fe537a8fe9d,new-release,ovsdbapp===2.4.0,ovsdbapp===2.3.0,1,1
openstack%2Frequirements~887769,openstack/requirements,master,I1cf5cb92825b90cc894117c54ec24cd718a3ba71,update constraint for python-troveclient to new release 8.2.0,MERGED,2023-07-06 08:40:26.000000000,2023-07-06 22:33:33.000000000,2023-07-06 22:32:21.000000000,"[{'_account_id': 14288}, {'_account_id': 22348}, {'_account_id': 28522}]","[{'number': 1, 'created': '2023-07-06 08:40:26.000000000', 'files': ['upper-constraints.txt'], 'web_link': 'https://opendev.org/openstack/requirements/commit/18333c0360d4054c00a4171a6f7ee996507418a7', 'message': 'update constraint for python-troveclient to new release 8.2.0\n\nmeta: version: 8.2.0\nmeta: diff-start: -\nmeta: series: bobcat\nmeta: branch: master\nmeta: release-type: release\nmeta: pypi: yes\nmeta: first: yes\nmeta: release:Author: Elod Illes <elod.illes@est.tech>\nmeta: release:Commit: Elod Illes <elod.illes@est.tech>\nmeta: release:Change-Id: I65447a5b4897567c9524e28a049919a2b73ff635\nmeta: release:Code-Review+2: Hervé Beraud <herveberaud.pro@gmail.com>\nmeta: release:Code-Review+1: wu.chunyang <wchy1001@gmail.com>\nmeta: release:Code-Review+2: Elod Illes <elod.illes@est.tech>\nmeta: release:Workflow+1: Hervé Beraud <herveberaud.pro@gmail.com>\nChange-Id: I1cf5cb92825b90cc894117c54ec24cd718a3ba71\n'}]",0,887769,18333c0360d4054c00a4171a6f7ee996507418a7,8,3,1,11131,,,0,"update constraint for python-troveclient to new release 8.2.0

meta: version: 8.2.0
meta: diff-start: -
meta: series: bobcat
meta: branch: master
meta: release-type: release
meta: pypi: yes
meta: first: yes
meta: release:Author: Elod Illes <elod.illes@est.tech>
meta: release:Commit: Elod Illes <elod.illes@est.tech>
meta: release:Change-Id: I65447a5b4897567c9524e28a049919a2b73ff635
meta: release:Code-Review+2: Hervé Beraud <herveberaud.pro@gmail.com>
meta: release:Code-Review+1: wu.chunyang <wchy1001@gmail.com>
meta: release:Code-Review+2: Elod Illes <elod.illes@est.tech>
meta: release:Workflow+1: Hervé Beraud <herveberaud.pro@gmail.com>
Change-Id: I1cf5cb92825b90cc894117c54ec24cd718a3ba71
",git fetch https://review.opendev.org/openstack/requirements refs/changes/69/887769/1 && git format-patch -1 --stdout FETCH_HEAD,['upper-constraints.txt'],1,18333c0360d4054c00a4171a6f7ee996507418a7,new-release,python-troveclient===8.2.0,python-troveclient===8.1.0,1,1
openstack%2Frequirements~887770,openstack/requirements,master,I9ed31162f7db71ac6135e069fe035cb3abe86b7d,update constraint for octavia-lib to new release 3.3.0,MERGED,2023-07-06 08:41:52.000000000,2023-07-06 22:32:24.000000000,2023-07-06 22:32:24.000000000,"[{'_account_id': 14288}, {'_account_id': 22348}, {'_account_id': 28522}]","[{'number': 1, 'created': '2023-07-06 08:41:52.000000000', 'files': ['upper-constraints.txt'], 'web_link': 'https://opendev.org/openstack/requirements/commit/d6b4fead39a2b1f1c71ceebf3c1c2996c1d131f8', 'message': 'update constraint for octavia-lib to new release 3.3.0\n\nmeta: version: 3.3.0\nmeta: diff-start: -\nmeta: series: bobcat\nmeta: branch: master\nmeta: release-type: release\nmeta: pypi: yes\nmeta: first: yes\nmeta: release:Author: Elod Illes <elod.illes@est.tech>\nmeta: release:Commit: Elod Illes <elod.illes@est.tech>\nmeta: release:Change-Id: I82779805f32939fb4fdf404875a41361501d2a78\nmeta: release:Code-Review+2: Hervé Beraud <herveberaud.pro@gmail.com>\nmeta: release:Code-Review+1: Gregory Thiemonge <gthiemon@redhat.com>\nmeta: release:Code-Review+2: Elod Illes <elod.illes@est.tech>\nmeta: release:Workflow+1: Hervé Beraud <herveberaud.pro@gmail.com>\nChange-Id: I9ed31162f7db71ac6135e069fe035cb3abe86b7d\n'}]",0,887770,d6b4fead39a2b1f1c71ceebf3c1c2996c1d131f8,7,3,1,11131,,,0,"update constraint for octavia-lib to new release 3.3.0

meta: version: 3.3.0
meta: diff-start: -
meta: series: bobcat
meta: branch: master
meta: release-type: release
meta: pypi: yes
meta: first: yes
meta: release:Author: Elod Illes <elod.illes@est.tech>
meta: release:Commit: Elod Illes <elod.illes@est.tech>
meta: release:Change-Id: I82779805f32939fb4fdf404875a41361501d2a78
meta: release:Code-Review+2: Hervé Beraud <herveberaud.pro@gmail.com>
meta: release:Code-Review+1: Gregory Thiemonge <gthiemon@redhat.com>
meta: release:Code-Review+2: Elod Illes <elod.illes@est.tech>
meta: release:Workflow+1: Hervé Beraud <herveberaud.pro@gmail.com>
Change-Id: I9ed31162f7db71ac6135e069fe035cb3abe86b7d
",git fetch https://review.opendev.org/openstack/requirements refs/changes/70/887770/1 && git format-patch -1 --stdout FETCH_HEAD,['upper-constraints.txt'],1,d6b4fead39a2b1f1c71ceebf3c1c2996c1d131f8,new-release,octavia-lib===3.3.0,octavia-lib===3.2.0,1,1
openstack%2Frequirements~887768,openstack/requirements,master,Ib82d11ba5d8fc4e5224089634096d7929dd17c97,update constraint for python-cyborgclient to new release 2.2.0,MERGED,2023-07-06 08:38:20.000000000,2023-07-06 21:49:57.000000000,2023-07-06 21:49:01.000000000,"[{'_account_id': 14288}, {'_account_id': 22348}, {'_account_id': 28522}]","[{'number': 1, 'created': '2023-07-06 08:38:20.000000000', 'files': ['upper-constraints.txt'], 'web_link': 'https://opendev.org/openstack/requirements/commit/bc407bd0d2c732b679ce40621890ff6fd51e1ac0', 'message': 'update constraint for python-cyborgclient to new release 2.2.0\n\nmeta: version: 2.2.0\nmeta: diff-start: -\nmeta: series: bobcat\nmeta: branch: master\nmeta: release-type: release\nmeta: pypi: yes\nmeta: first: yes\nmeta: release:Author: Elod Illes <elod.illes@est.tech>\nmeta: release:Commit: Elod Illes <elod.illes@est.tech>\nmeta: release:Change-Id: If82d7a0224afbdd5542ac5149479e7dd89f56036\nmeta: release:Workflow+1: Hervé Beraud <herveberaud.pro@gmail.com>\nmeta: release:Code-Review+2: Elod Illes <elod.illes@est.tech>\nmeta: release:Code-Review+1: Wenping Song <songwenping@inspur.com>\nmeta: release:Code-Review+2: Hervé Beraud <herveberaud.pro@gmail.com>\nChange-Id: Ib82d11ba5d8fc4e5224089634096d7929dd17c97\n'}]",0,887768,bc407bd0d2c732b679ce40621890ff6fd51e1ac0,8,3,1,11131,,,0,"update constraint for python-cyborgclient to new release 2.2.0

meta: version: 2.2.0
meta: diff-start: -
meta: series: bobcat
meta: branch: master
meta: release-type: release
meta: pypi: yes
meta: first: yes
meta: release:Author: Elod Illes <elod.illes@est.tech>
meta: release:Commit: Elod Illes <elod.illes@est.tech>
meta: release:Change-Id: If82d7a0224afbdd5542ac5149479e7dd89f56036
meta: release:Workflow+1: Hervé Beraud <herveberaud.pro@gmail.com>
meta: release:Code-Review+2: Elod Illes <elod.illes@est.tech>
meta: release:Code-Review+1: Wenping Song <songwenping@inspur.com>
meta: release:Code-Review+2: Hervé Beraud <herveberaud.pro@gmail.com>
Change-Id: Ib82d11ba5d8fc4e5224089634096d7929dd17c97
",git fetch https://review.opendev.org/openstack/requirements refs/changes/68/887768/1 && git format-patch -1 --stdout FETCH_HEAD,['upper-constraints.txt'],1,bc407bd0d2c732b679ce40621890ff6fd51e1ac0,new-release,python-cyborgclient===2.2.0,python-cyborgclient===2.1.0,1,1
openstack%2Foctavia~887751,openstack/octavia,master,I90ddebabcd90f30fccc6e1751f7c188b35ef16c4,Fix test_driver_agent tests with newer octavia-lib,MERGED,2023-07-06 06:49:35.000000000,2023-07-06 20:18:32.000000000,2023-07-06 20:17:00.000000000,"[{'_account_id': 11628}, {'_account_id': 22348}, {'_account_id': 29244}]","[{'number': 1, 'created': '2023-07-06 06:49:35.000000000', 'files': ['octavia/tests/functional/api/drivers/driver_agent/test_driver_agent.py'], 'web_link': 'https://opendev.org/openstack/octavia/commit/133e74787d544fe27b699d40bf655838d4554c32', 'message': 'Fix test_driver_agent tests with newer octavia-lib\n\nThe tests in test_driver_agent compare recursively the dicts defined in\noctavia with the dicts returned by octavia-lib. But when a new attribute\nis added to octavia-lib, it breaks the tests in the -tips job until the\nnew attribute is included in octavia.\n\nTo mitigate this issue, the tests in octavia should only compare the\ndicts by using the keys that are known by octavia.\n\nChange-Id: I90ddebabcd90f30fccc6e1751f7c188b35ef16c4\n'}]",2,887751,133e74787d544fe27b699d40bf655838d4554c32,8,3,1,29244,,,0,"Fix test_driver_agent tests with newer octavia-lib

The tests in test_driver_agent compare recursively the dicts defined in
octavia with the dicts returned by octavia-lib. But when a new attribute
is added to octavia-lib, it breaks the tests in the -tips job until the
new attribute is included in octavia.

To mitigate this issue, the tests in octavia should only compare the
dicts by using the keys that are known by octavia.

Change-Id: I90ddebabcd90f30fccc6e1751f7c188b35ef16c4
",git fetch https://review.opendev.org/openstack/octavia refs/changes/51/887751/1 && git format-patch -1 --stdout FETCH_HEAD,['octavia/tests/functional/api/drivers/driver_agent/test_driver_agent.py'],1,133e74787d544fe27b699d40bf655838d4554c32,," def _compare_load_balancer_dicts(self, provider_lb_dict, result_dict): for key in (lib_consts.LOADBALANCER_ID, lib_consts.NAME, lib_consts.DESCRIPTION, lib_consts.PROJECT_ID, lib_consts.ADMIN_STATE_UP, lib_consts.VIP_ADDRESS, lib_consts.VIP_NETWORK_ID, lib_consts.VIP_SUBNET_ID, lib_consts.VIP_PORT_ID, lib_consts.VIP_QOS_POLICY_ID, lib_consts.FLAVOR, lib_consts.AVAILABILITY_ZONE, lib_consts.ADDITIONAL_VIPS): self.assertEqual(provider_lb_dict.get(key), result_dict.get(key)) provider_listener_dicts = provider_lb_dict[lib_consts.LISTENERS] result_listener_dicts = result_dict[lib_consts.LISTENERS] self.assertEqual(len(provider_listener_dicts), len(result_listener_dicts)) for listener_dicts in zip(provider_listener_dicts, result_listener_dicts): provider_listener_dict = listener_dicts[0] result_listener_dict = listener_dicts[1] self._compare_listener_dicts(provider_listener_dict, result_listener_dict) self.assertEqual(len(provider_lb_dict[lib_consts.POOLS]), len(result_dict[lib_consts.POOLS])) for pool_dicts in zip(provider_lb_dict[lib_consts.POOLS], result_dict[lib_consts.POOLS]): provider_pool_dict = pool_dicts[0] result_pool_dict = pool_dicts[1] self._compare_pool_dicts(provider_pool_dict, result_pool_dict) def _compare_listener_dicts(self, provider_listener_dict, result_listener_dict): for key in (lib_consts.LISTENER_ID, lib_consts.LOADBALANCER_ID, lib_consts.NAME, lib_consts.DESCRIPTION, lib_consts.PROJECT_ID, lib_consts.ADMIN_STATE_UP, lib_consts.PROTOCOL, lib_consts.PROTOCOL_PORT, lib_consts.CONNECTION_LIMIT, lib_consts.DEFAULT_POOL_ID, lib_consts.TIMEOUT_CLIENT_DATA, lib_consts.TIMEOUT_MEMBER_CONNECT, lib_consts.TIMEOUT_MEMBER_DATA, lib_consts.TIMEOUT_TCP_INSPECT, lib_consts.INSERT_HEADERS, lib_consts.ALLOWED_CIDRS, lib_consts.DEFAULT_TLS_CONTAINER_REF, lib_consts.DEFAULT_TLS_CONTAINER_DATA, lib_consts.SNI_CONTAINER_REFS, lib_consts.SNI_CONTAINER_DATA, lib_consts.CLIENT_CA_TLS_CONTAINER_REF, lib_consts.CLIENT_CA_TLS_CONTAINER_DATA, lib_consts.CLIENT_AUTHENTICATION, lib_consts.CLIENT_CRL_CONTAINER_REF, lib_consts.CLIENT_CRL_CONTAINER_DATA, lib_consts.TLS_CIPHERS, lib_consts.TLS_VERSIONS): self.assertEqual(provider_listener_dict.get(key), result_listener_dict.get(key)) provider_l7policy_dicts = provider_listener_dict.get( lib_consts.L7POLICIES) result_l7policy_dicts = result_listener_dict.get( lib_consts.L7POLICIES) self.assertEqual(len(provider_l7policy_dicts), len(result_l7policy_dicts)) for l7policy_dicts in zip(provider_l7policy_dicts, result_l7policy_dicts): provider_l7policy_dict = l7policy_dicts[0] result_l7policy_dict = l7policy_dicts[1] self._compare_l7policy_dicts(provider_l7policy_dict, result_l7policy_dict) def _compare_l7policy_dicts(self, provider_l7policy_dict, result_l7policy_dict): for key in (lib_consts.L7POLICY_ID, lib_consts.LISTENER_ID, lib_consts.NAME, lib_consts.DESCRIPTION, lib_consts.PROJECT_ID, lib_consts.ADMIN_STATE_UP, lib_consts.ACTION, lib_consts.POSITION, lib_consts.REDIRECT_POOL_ID, lib_consts.REDIRECT_URL, lib_consts.REDIRECT_PREFIX, lib_consts.REDIRECT_HTTP_CODE): self.assertEqual(provider_l7policy_dict.get(key), result_l7policy_dict.get(key)) provider_l7rule_dicts = provider_l7policy_dict.get(lib_consts.L7RULES) result_l7rule_dicts = result_l7policy_dict.get(lib_consts.L7RULES) if provider_l7rule_dicts or result_l7rule_dicts: self.assertIsNotNone(provider_l7rule_dicts) self.assertIsNotNone(result_l7rule_dicts) self.assertEqual(len(provider_l7rule_dicts), len(result_l7rule_dicts)) for l7rule_dicts in zip(provider_l7rule_dicts, result_l7rule_dicts): provider_l7rule_dict = l7rule_dicts[0] result_l7rule_dict = l7rule_dicts[1] self._compare_l7rule_dicts(provider_l7rule_dict, result_l7rule_dict) def _compare_l7rule_dicts(self, provider_l7rule_dict, result_l7rule_dict): for key in (lib_consts.L7RULE_ID, lib_consts.L7POLICY_ID, lib_consts.LISTENER_ID, lib_consts.NAME, lib_consts.DESCRIPTION, lib_consts.PROJECT_ID, lib_consts.ADMIN_STATE_UP, lib_consts.TYPE, lib_consts.COMPARE_TYPE, lib_consts.KEY, lib_consts.VALUE, lib_consts.INVERT): self.assertEqual(provider_l7rule_dict.get(key), result_l7rule_dict.get(key)) def _compare_pool_dicts(self, provider_pool_dict, result_pool_dict): for key in (lib_consts.POOL_ID, lib_consts.NAME, lib_consts.DESCRIPTION, lib_consts.PROJECT_ID, lib_consts.ADMIN_STATE_UP, lib_consts.LB_ALGORITHM, lib_consts.LOADBALANCER_ID, lib_consts.PROTOCOL, lib_consts.SESSION_PERSISTENCE, lib_consts.TLS_ENABLED, lib_consts.TLS_CONTAINER_REF, lib_consts.TLS_CONTAINER_DATA, lib_consts.CA_TLS_CONTAINER_REF, lib_consts.CA_TLS_CONTAINER_DATA, lib_consts.CRL_CONTAINER_REF, lib_consts.CRL_CONTAINER_DATA, lib_consts.TLS_CIPHERS, lib_consts.TLS_VERSIONS, lib_consts.ALPN_PROTOCOLS): self.assertEqual(provider_pool_dict.get(key), result_pool_dict.get(key)) provider_hm_dict = provider_pool_dict.get( lib_consts.HEALTHMONITOR) result_hm_dict = result_pool_dict.get( lib_consts.HEALTHMONITOR) if provider_hm_dict or result_hm_dict: self._compare_hm_dicts(provider_hm_dict, result_hm_dict) provider_member_dicts = provider_pool_dict.get( lib_consts.MEMBERS) result_member_dicts = result_pool_dict.get( lib_consts.MEMBERS) self.assertEqual(len(provider_member_dicts), len(result_member_dicts)) for member_dicts in zip(provider_member_dicts, result_member_dicts): provider_member_dict = member_dicts[0] result_member_dict = member_dicts[1] self._compare_member_dicts(provider_member_dict, result_member_dict) def _compare_hm_dicts(self, provider_hm_dict, result_hm_dict): for key in (lib_consts.HEALTHMONITOR_ID, lib_consts.POOL_ID, lib_consts.NAME, lib_consts.DESCRIPTION, lib_consts.PROJECT_ID, lib_consts.ADMIN_STATE_UP, lib_consts.TYPE, lib_consts.DELAY, lib_consts.TIMEOUT, lib_consts.MAX_RETRIES, lib_consts.MAX_RETRIES_DOWN, lib_consts.DOMAIN_NAME, lib_consts.EXPECTED_CODES, lib_consts.HTTP_METHOD, lib_consts.HTTP_VERSION, lib_consts.URL_PATH): self.assertEqual(provider_hm_dict.get(key), result_hm_dict.get(key)) def _compare_member_dicts(self, provider_member_dict, result_member_dict): for key in (lib_consts.MEMBER_ID, lib_consts.POOL_ID, lib_consts.NAME, lib_consts.DESCRIPTION, lib_consts.PROJECT_ID, lib_consts.ADMIN_STATE_UP, lib_consts.ADDRESS, lib_consts.PROTOCOL_PORT, lib_consts.MONITOR_ADDRESS, lib_consts.MONITOR_PORT, lib_consts.SUBNET_ID, lib_consts.WEIGHT, lib_consts.BACKUP): self.assertEqual(provider_member_dict.get(key), result_member_dict.get(key)) result_dict = result.to_dict(render_unsets=True, recurse=True) self._compare_load_balancer_dicts(self.provider_lb_dict, result_dict) result_dict = result.to_dict(render_unsets=True, recurse=True) self._compare_listener_dicts(self.provider_listener_dict, result_dict) result_dict = result.to_dict(render_unsets=True, recurse=True) self._compare_pool_dicts(self.provider_pool_dict, result_dict) result_dict = result.to_dict(render_unsets=True) self._compare_member_dicts(self.sample_data.provider_member1_dict, result_dict) result_dict = result.to_dict(render_unsets=True) self._compare_hm_dicts(self.sample_data.provider_hm1_dict, result_dict) result_dict = result.to_dict(render_unsets=True, recurse=True) self._compare_l7policy_dicts( self.sample_data.provider_l7policy1_dict, result_dict) result_dict = result.to_dict(render_unsets=True) self._compare_l7rule_dicts( self.sample_data.provider_l7rule1_dict, result_dict)"," self.assertEqual(self.provider_lb_dict, result.to_dict(render_unsets=True, recurse=True)) # We need to recurse here to pick up the SNI data self.assertEqual(self.provider_listener_dict, result.to_dict(render_unsets=True, recurse=True)) self.assertEqual(self.provider_pool_dict, result.to_dict(render_unsets=True, recurse=True)) self.assertEqual(self.sample_data.provider_member1_dict, result.to_dict(render_unsets=True)) self.assertEqual(self.sample_data.provider_hm1_dict, result.to_dict(render_unsets=True)) self.assertEqual(self.sample_data.provider_l7policy1_dict, result.to_dict(render_unsets=True, recurse=True)) self.assertEqual(self.sample_data.provider_l7rule1_dict, result.to_dict(render_unsets=True))",254,15
openstack%2Fswift~886541,openstack/swift,master,I0e928bcb3810e391297300f4949024db3cf87d05,CI: test under py311,MERGED,2023-06-20 23:42:55.000000000,2023-07-06 20:01:15.000000000,2023-07-04 01:29:04.000000000,"[{'_account_id': 1179}, {'_account_id': 7233}, {'_account_id': 22348}]","[{'number': 1, 'created': '2023-06-20 23:42:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/68cc42cebff62bc55440a03efb4d56354f4c8fde', 'message': 'CI: test under py311\n\nChange-Id: I0e928bcb3810e391297300f4949024db3cf87d05\n'}, {'number': 2, 'created': '2023-06-21 01:16:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/a36f8cb9b3b878246f47f1d81ed15a5a38d928f0', 'message': 'CI: test under py311\n\nChange-Id: I0e928bcb3810e391297300f4949024db3cf87d05\n'}, {'number': 3, 'created': '2023-06-21 16:21:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/f1cf79aa1e2a8a543afa4b0250015fe3fc43adc4', 'message': 'CI: test under py311\n\nJammy only offers a py311 RC, so include the __slots__ hack to avoid\nthe segfault from https://github.com/python/cpython/issues/99886.\n\nFix up a test to work with the slotted connection.\n\nChange-Id: I0e928bcb3810e391297300f4949024db3cf87d05\n'}, {'number': 4, 'created': '2023-06-23 00:28:27.000000000', 'files': ['swift/common/db.py', '.zuul.yaml', 'test/unit/account/test_backend.py'], 'web_link': 'https://opendev.org/openstack/swift/commit/f955e81043b1d04fe7c54c03eaec405c99968ae1', 'message': 'CI: test under py311\n\nJammy only offers a py311 RC, so include the __slots__ hack to avoid\nthe segfault from https://github.com/python/cpython/issues/99886.\n\nFix up a test to work with the slotted connection.\n\nChange-Id: I0e928bcb3810e391297300f4949024db3cf87d05\n'}]",4,886541,f955e81043b1d04fe7c54c03eaec405c99968ae1,22,3,4,15343,,,0,"CI: test under py311

Jammy only offers a py311 RC, so include the __slots__ hack to avoid
the segfault from https://github.com/python/cpython/issues/99886.

Fix up a test to work with the slotted connection.

Change-Id: I0e928bcb3810e391297300f4949024db3cf87d05
",git fetch https://review.opendev.org/openstack/swift refs/changes/41/886541/1 && git format-patch -1 --stdout FETCH_HEAD,"['swift/common/db.py', '.zuul.yaml']",2,68cc42cebff62bc55440a03efb4d56354f4c8fde,py311-support, name: swift-tox-py311 parent: swift-tox-base nodeset: ubuntu-jammy description: | Run unit-tests for swift under cPython version 3.11. Uses tox with the ``py311`` environment. It sets TMPDIR to an XFS mount point created via tools/test-setup.sh. vars: tox_envlist: py311 bindep_profile: test py311 python_version: '3.11' post-run: tools/playbooks/common/cover-post.yaml - job: - swift-tox-py311: irrelevant-files: *unittest-irrelevant-files - swift-tox-py311,,22,0
openstack%2Fneutron~882588,openstack/neutron,master,I1943e6e0d7d8e255e95f93881cc3caec16ab67fe,[OVN] Prevent binding a virtual type port,MERGED,2023-05-08 16:09:21.000000000,2023-07-06 19:43:01.000000000,2023-07-06 19:41:38.000000000,"[{'_account_id': 1131}, {'_account_id': 4694}, {'_account_id': 5948}, {'_account_id': 8313}, {'_account_id': 9845}, {'_account_id': 11975}, {'_account_id': 16688}, {'_account_id': 22348}, {'_account_id': 32586}, {'_account_id': 34271}, {'_account_id': 34451}]","[{'number': 1, 'created': '2023-05-08 16:09:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/87b7f2a7703a7815f229c3253529acc6319afc4d', 'message': '[WIP] == [OVN] Prevent binding a virtual type port\n\nA LSP is type=virtual when its IP address is used by other ports\nas allowed address. If a LSP is type=virtual, this port cannot be\nbound (that means cannot be used as a port for a virtual machine).\n\nCloses-Bug: #2018529\nChange-Id: I1943e6e0d7d8e255e95f93881cc3caec16ab67fe\n'}, {'number': 2, 'created': '2023-05-09 09:43:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/3938ef30fa4460e61230d8abe46ab6ac5e1acd4b', 'message': '[WIP] == [OVN] Prevent binding a virtual type port\n\nA LSP is type=virtual when its IP address is used by other ports\nas allowed address. If a LSP is type=virtual, this port cannot be\nbound (that means cannot be used as a port for a virtual machine).\n\nCloses-Bug: #2018529\nChange-Id: I1943e6e0d7d8e255e95f93881cc3caec16ab67fe\n'}, {'number': 3, 'created': '2023-05-11 17:20:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/7de7bc036d6fe2b33d2fdc9e4bb9a13e36a1aa39', 'message': '[WIP] == [OVN] Prevent binding a virtual type port\n\nTODO: testing\n      reno\n      docuemntation\n\nA LSP is type=virtual when its IP address is used by other ports\nas allowed address. If a LSP is type=virtual, this port cannot be\nbound (that means cannot be used as a port for a virtual machine).\n\nCloses-Bug: #2018529\nChange-Id: I1943e6e0d7d8e255e95f93881cc3caec16ab67fe\n'}, {'number': 4, 'created': '2023-05-30 10:59:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/6d95bf2df3b31b4e0317225df4ea2b44beb5717d', 'message': '[OVN] Prevent binding a virtual type port\n\nA LSP is type=virtual when its IP address is used by other ports\nas allowed address. If a LSP is type=virtual, this port cannot be\nbound (that means cannot be used as a port for a virtual machine).\n\nCloses-Bug: #2018529\nChange-Id: I1943e6e0d7d8e255e95f93881cc3caec16ab67fe\n'}, {'number': 5, 'created': '2023-05-31 16:30:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/342fd5d7ef535c1e6e2b5f1265b82dbc15676f22', 'message': '[OVN] Prevent binding a virtual type port\n\nA LSP is type=virtual when its IP address is used by other ports\nas allowed address. If a LSP is type=virtual, this port cannot be\nbound (that means cannot be used as a port for a virtual machine).\n\nCloses-Bug: #2018529\nChange-Id: I1943e6e0d7d8e255e95f93881cc3caec16ab67fe\n'}, {'number': 6, 'created': '2023-06-02 15:48:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/e71c7fd1a3d056fdf6dfafea51ddbfcb114c4016', 'message': '[OVN] Prevent binding a virtual type port\n\nA LSP is type=virtual when its IP address is used by other ports\nas allowed address. If a LSP is type=virtual, this port cannot be\nbound (that means cannot be used as a port for a virtual machine).\n\nCloses-Bug: #2018529\nChange-Id: I1943e6e0d7d8e255e95f93881cc3caec16ab67fe\n'}, {'number': 7, 'created': '2023-07-03 08:15:11.000000000', 'files': ['neutron/common/ovn/utils.py', 'neutron/tests/unit/plugins/ml2/drivers/ovn/mech_driver/test_mech_driver.py', 'releasenotes/notes/ovn-virtual-port-prevent-binding-50efba5521e8a28e.yaml', 'neutron/plugins/ml2/drivers/ovn/mech_driver/mech_driver.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/68ecae5ff9a364e41126cb338902f1a36fc9413f', 'message': '[OVN] Prevent binding a virtual type port\n\nA LSP is type=virtual when its IP address is used by other ports\nas allowed address. If a LSP is type=virtual, this port cannot be\nbound (that means cannot be used as a port for a virtual machine).\n\nCloses-Bug: #2018529\nChange-Id: I1943e6e0d7d8e255e95f93881cc3caec16ab67fe\n'}]",28,882588,68ecae5ff9a364e41126cb338902f1a36fc9413f,69,11,7,16688,,,0,"[OVN] Prevent binding a virtual type port

A LSP is type=virtual when its IP address is used by other ports
as allowed address. If a LSP is type=virtual, this port cannot be
bound (that means cannot be used as a port for a virtual machine).

Closes-Bug: #2018529
Change-Id: I1943e6e0d7d8e255e95f93881cc3caec16ab67fe
",git fetch https://review.opendev.org/openstack/neutron refs/changes/88/882588/1 && git format-patch -1 --stdout FETCH_HEAD,"['neutron/common/ovn/utils.py', 'neutron/plugins/ml2/drivers/ovn/mech_driver/mech_driver.py']",2,87b7f2a7703a7815f229c3253529acc6319afc4d,bug/2018529, ovn_utils,,21,0
openstack%2Fdesignate~887451,openstack/designate,stable/zed,I04c104cfc9ee2f03d0c5adca3c80bbfff20afb70,Fix TsigKeyring issues with dnspython 2.x,MERGED,2023-07-01 07:34:36.000000000,2023-07-06 19:41:40.000000000,2023-07-06 19:40:32.000000000,"[{'_account_id': 11628}, {'_account_id': 13252}, {'_account_id': 22348}]","[{'number': 1, 'created': '2023-07-01 07:34:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/designate/commit/0b624558a42bdc158ff09b5a1b27c0fa2dbb485b', 'message': 'Fix TsigKeyring issues with dnspython 2.x\n\n- Fixed issues in TsigKeyring.\n- Fixed tsgi issues in mdns handler.\n- Fixed invalid secret used in tests.\n- Added additional test coverage.\n- Re-enabled previously broken test.\n\nCloses-Bug: #1982252\nChange-Id: I04c104cfc9ee2f03d0c5adca3c80bbfff20afb70\n(cherry picked from commit 38c591eaa1109e7ea4600563e505dbdbe8a59b37)\n'}, {'number': 2, 'created': '2023-07-01 16:04:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/designate/commit/0b6816711f5320e738c48c202761f40656c74fd4', 'message': 'Fix TsigKeyring issues with dnspython 2.x\n\n- Fixed issues in TsigKeyring.\n- Fixed tsgi issues in mdns handler.\n- Fixed invalid secret used in tests.\n- Added additional test coverage.\n- Re-enabled previously broken test.\n\nCloses-Bug: #1982252\nChange-Id: I04c104cfc9ee2f03d0c5adca3c80bbfff20afb70\n(cherry picked from commit 38c591eaa1109e7ea4600563e505dbdbe8a59b37)\n'}, {'number': 3, 'created': '2023-07-02 09:49:29.000000000', 'files': ['designate/tests/__init__.py', 'designate/mdns/handler.py', 'designate/dnsutils.py', 'designate/tests/test_dnsutils.py', 'designate/tests/test_mdns/test_handler.py'], 'web_link': 'https://opendev.org/openstack/designate/commit/a99367cff117268ec265a12d1f46fdf0376b40cc', 'message': 'Fix TsigKeyring issues with dnspython 2.x\n\n- Fixed issues in TsigKeyring.\n- Fixed tsgi issues in mdns handler.\n- Fixed invalid secret used in tests.\n- Added additional test coverage.\n- Re-enabled previously broken test.\n\nAdditionally modified unit test to provide a storage provider,\nas this does not exist in the next release.\n\nCloses-Bug: #1982252\nChange-Id: I04c104cfc9ee2f03d0c5adca3c80bbfff20afb70\n(cherry picked from commit 38c591eaa1109e7ea4600563e505dbdbe8a59b37)\n'}]",2,887451,a99367cff117268ec265a12d1f46fdf0376b40cc,14,3,3,13252,,,0,"Fix TsigKeyring issues with dnspython 2.x

- Fixed issues in TsigKeyring.
- Fixed tsgi issues in mdns handler.
- Fixed invalid secret used in tests.
- Added additional test coverage.
- Re-enabled previously broken test.

Additionally modified unit test to provide a storage provider,
as this does not exist in the next release.

Closes-Bug: #1982252
Change-Id: I04c104cfc9ee2f03d0c5adca3c80bbfff20afb70
(cherry picked from commit 38c591eaa1109e7ea4600563e505dbdbe8a59b37)
",git fetch https://review.opendev.org/openstack/designate refs/changes/51/887451/1 && git format-patch -1 --stdout FETCH_HEAD,"['designate/tests/__init__.py', 'designate/mdns/handler.py', 'designate/dnsutils.py', 'designate/tests/test_dnsutils.py', 'designate/tests/test_mdns/test_handler.py']",5,0b624558a42bdc158ff09b5a1b27c0fa2dbb485b,,"import dns.tsigkeyring request.use_tsig(dns.tsigkeyring.from_text( {'test-key-two': 'AnotherSecretKey'}) ) args = [request.keyname, request.keyring.secret, 300, request.id, request.tsig_error, b'', request.mac, request.keyalgorithm]","from unittest import expectedFailure @expectedFailure request.keyring = {request.keyname: ''} request.had_tsig = True args = [request.keyname, request.keyring[request.keyname], request.fudge, request.original_id, request.tsig_error, request.other_data, request.mac, request.keyalgorithm]",99,16
openstack%2Fneutron~887617,openstack/neutron,stable/xena,I1a3723ae999fefb5dcbe3a60cf1a4902da9f0265,Don't allow deletion of the router ports without IP addresses,MERGED,2023-07-04 14:49:38.000000000,2023-07-06 19:37:44.000000000,2023-07-06 19:36:22.000000000,"[{'_account_id': 16688}, {'_account_id': 21798}, {'_account_id': 22348}]","[{'number': 1, 'created': '2023-07-04 14:49:38.000000000', 'files': ['neutron/db/l3_db.py', 'neutron/tests/unit/db/test_l3_db.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/2417b76aad624003488c22781143ec55f7cd1a62', 'message': ""Don't allow deletion of the router ports without IP addresses\n\nThis patch effectively reverts old patch [1]. From now on it will be not\nallowed to directly remove router ports which don't have fixed IPs\nassigned. Such ports will be treated as any other ports connected to the\nrouters.\nOriginally [1] was introduced to allow cleanup of the router ports for\nwhich subnets were deleted. But now it's not needed anymore as we\nprevent deletion of subnet if there are any ports with IP allocated from\nthat subnet.\n\nCloses-bug: #2025056\n\n[1] https://review.opendev.org/c/openstack/neutron/+/20424\n\nChange-Id: I1a3723ae999fefb5dcbe3a60cf1a4902da9f0265\n(cherry picked from commit 32d589f03ed0d2744fe15173ebacafd18fced8a9)\n""}]",0,887617,2417b76aad624003488c22781143ec55f7cd1a62,9,3,1,11975,,,0,"Don't allow deletion of the router ports without IP addresses

This patch effectively reverts old patch [1]. From now on it will be not
allowed to directly remove router ports which don't have fixed IPs
assigned. Such ports will be treated as any other ports connected to the
routers.
Originally [1] was introduced to allow cleanup of the router ports for
which subnets were deleted. But now it's not needed anymore as we
prevent deletion of subnet if there are any ports with IP allocated from
that subnet.

Closes-bug: #2025056

[1] https://review.opendev.org/c/openstack/neutron/+/20424

Change-Id: I1a3723ae999fefb5dcbe3a60cf1a4902da9f0265
(cherry picked from commit 32d589f03ed0d2744fe15173ebacafd18fced8a9)
",git fetch https://review.opendev.org/openstack/neutron refs/changes/17/887617/1 && git format-patch -1 --stdout FETCH_HEAD,"['neutron/db/l3_db.py', 'neutron/tests/unit/db/test_l3_db.py']",2,2417b76aad624003488c22781143ec55f7cd1a62,bug/2025056-stable/2023.1-stable/zed-stable/yoga-stable/xena," 'device_id': '44', 'id': 'f', } with testtools.ExpectedException(n_exc.ServicePortInUse): self.db.prevent_l3_port_deletion(mock.Mock(), None)"," 'id': 'f' } self.db.prevent_l3_port_deletion(None, None)",3,11
openstack%2Fpython-openstackclient~887812,openstack/python-openstackclient,stable/2023.1,I716f6a1496fc552b32809c7eb744283f3a3cd5a4,Fix pep issue in the network service provider,MERGED,2023-07-06 15:46:02.000000000,2023-07-06 19:37:36.000000000,2023-07-06 19:36:26.000000000,"[{'_account_id': 15334}, {'_account_id': 22348}]","[{'number': 1, 'created': '2023-07-06 15:46:02.000000000', 'files': ['openstackclient/network/v2/network_service_provider.py'], 'web_link': 'https://opendev.org/openstack/python-openstackclient/commit/07c5a26fe56a6374fcbcfaa61f9c340f9c0fdc10', 'message': 'Fix pep issue in the network service provider\n\npep gods started complaining (correctfully) about spacing in the old\ncommand. Apply `black -l 79` on the file to make it looking nice and\npassing checks.\n\nChange-Id: I716f6a1496fc552b32809c7eb744283f3a3cd5a4\n(cherry picked from commit a675c61e469067e556a39e89cb1b06484122004d)\n'}]",1,887812,07c5a26fe56a6374fcbcfaa61f9c340f9c0fdc10,7,2,1,7973,,,0,"Fix pep issue in the network service provider

pep gods started complaining (correctfully) about spacing in the old
command. Apply `black -l 79` on the file to make it looking nice and
passing checks.

Change-Id: I716f6a1496fc552b32809c7eb744283f3a3cd5a4
(cherry picked from commit a675c61e469067e556a39e89cb1b06484122004d)
",git fetch https://review.opendev.org/openstack/python-openstackclient refs/changes/12/887812/1 && git format-patch -1 --stdout FETCH_HEAD,['openstackclient/network/v2/network_service_provider.py'],1,07c5a26fe56a6374fcbcfaa61f9c340f9c0fdc10,," ""service_type"", ""name"", ""is_default"", ""Service Type"", ""Name"", ""Default"", return ( column_headers, ( utils.get_item_properties( s, columns, ) for s in data ), )"," 'service_type', 'name', 'is_default', 'Service Type', 'Name', 'Default', return(column_headers, (utils.get_item_properties( s, columns, ) for s in data))",16,10
openstack%2Fproject-config~887726,openstack/project-config,master,I7fc9c9bebb7385143c2f281d9a5df702777d79b2,"Migrate ""os-ken"" project to Launchpad",MERGED,2023-07-05 16:39:45.000000000,2023-07-06 19:24:44.000000000,2023-07-05 17:00:49.000000000,"[{'_account_id': 4694}, {'_account_id': 5263}, {'_account_id': 5948}, {'_account_id': 8313}, {'_account_id': 11975}, {'_account_id': 22348}]","[{'number': 1, 'created': '2023-07-05 16:39:45.000000000', 'files': ['gerrit/projects.yaml'], 'web_link': 'https://opendev.org/openstack/project-config/commit/37ad65c16fe4206552febe62ac76fa7c327587f8', 'message': 'Migrate ""os-ken"" project to Launchpad\n\nThe project ""os-ken"" will report bugs in the Neutron Launchpad project\nsite [1], with the title prexif ""[os-ken]"" and using the tag ""os-ken"".\nThat decission was taken in the last Neutron team meeting [2].\n\n[1]https://bugs.launchpad.net/neutron/\n[2]https://meetings.opendev.org/meetings/networking/2023/networking.2023-07-04-14.00.log.html#l-85\n\nChange-Id: I7fc9c9bebb7385143c2f281d9a5df702777d79b2\n'}]",0,887726,37ad65c16fe4206552febe62ac76fa7c327587f8,8,6,1,16688,,,0,"Migrate ""os-ken"" project to Launchpad

The project ""os-ken"" will report bugs in the Neutron Launchpad project
site [1], with the title prexif ""[os-ken]"" and using the tag ""os-ken"".
That decission was taken in the last Neutron team meeting [2].

[1]https://bugs.launchpad.net/neutron/
[2]https://meetings.opendev.org/meetings/networking/2023/networking.2023-07-04-14.00.log.html#l-85

Change-Id: I7fc9c9bebb7385143c2f281d9a5df702777d79b2
",git fetch https://review.opendev.org/openstack/project-config refs/changes/26/887726/1 && git format-patch -1 --stdout FETCH_HEAD,['gerrit/projects.yaml'],1,37ad65c16fe4206552febe62ac76fa7c327587f8,os-ken_launchpad,, use-storyboard: true,0,1
openstack%2Fcharm-manila~886048,openstack/charm-manila,stable/yoga,I557d02dcbbde91f3f12b243f43be3a062c5180ad,DNM - test to see if stable/yoga gate is working,ABANDONED,2023-06-14 08:57:35.000000000,2023-07-06 19:22:56.000000000,,"[{'_account_id': 20648}, {'_account_id': 22348}]","[{'number': 1, 'created': '2023-06-14 08:57:35.000000000', 'files': ['rebuild'], 'web_link': 'https://opendev.org/openstack/charm-manila/commit/17c3dc7c252c1de0c509626f3f5da25074c1243c', 'message': 'DNM - test to see if stable/yoga gate is working\n\nChange-Id: I557d02dcbbde91f3f12b243f43be3a062c5180ad\n'}]",0,886048,17c3dc7c252c1de0c509626f3f5da25074c1243c,5,2,1,20870,,,0,"DNM - test to see if stable/yoga gate is working

Change-Id: I557d02dcbbde91f3f12b243f43be3a062c5180ad
",git fetch https://review.opendev.org/openstack/charm-manila refs/changes/48/886048/1 && git format-patch -1 --stdout FETCH_HEAD,['rebuild'],1,17c3dc7c252c1de0c509626f3f5da25074c1243c,test-gate,260008f3-f00f-4def-8196-6c86cec8786c,fdb2c6cd-5f92-40c2-9af1-fecff8a72d87,1,1
openstack%2Fcharm-manila~886047,openstack/charm-manila,stable/zed,I92b34b68b8ea73deda6bdc67c3d5ccd1358a62ad,DNM - Test to see if gate is working,ABANDONED,2023-06-14 08:56:25.000000000,2023-07-06 19:22:43.000000000,,"[{'_account_id': 20648}, {'_account_id': 22348}]","[{'number': 1, 'created': '2023-06-14 08:56:25.000000000', 'files': ['rebuild'], 'web_link': 'https://opendev.org/openstack/charm-manila/commit/d91b551caa2eef528ac66aea8144541a9a86c14e', 'message': 'DNM - Test to see if gate is working\n\nChange-Id: I92b34b68b8ea73deda6bdc67c3d5ccd1358a62ad\n'}]",0,886047,d91b551caa2eef528ac66aea8144541a9a86c14e,5,2,1,20870,,,0,"DNM - Test to see if gate is working

Change-Id: I92b34b68b8ea73deda6bdc67c3d5ccd1358a62ad
",git fetch https://review.opendev.org/openstack/charm-manila refs/changes/47/886047/1 && git format-patch -1 --stdout FETCH_HEAD,['rebuild'],1,d91b551caa2eef528ac66aea8144541a9a86c14e,test-gate,fa7fb5fd-c940-4bb0-87b8-9d85869aa57c,53cf1d5c-1178-11ec-8ac2-bb3a2551099e,1,1
openstack%2Fironic-python-agent-builder~886379,openstack/ironic-python-agent-builder,master,I430ba8f86883b233b975f615e0e50b01e22c66e6,Remove outdated install pyyaml with pip2,MERGED,2023-06-19 08:48:59.000000000,2023-07-06 19:22:04.000000000,2023-07-06 19:21:05.000000000,"[{'_account_id': 11655}, {'_account_id': 22348}, {'_account_id': 24828}, {'_account_id': 32761}]","[{'number': 1, 'created': '2023-06-19 08:48:59.000000000', 'files': ['roles/ipa-build-dib-image/tasks/install.yaml'], 'web_link': 'https://opendev.org/openstack/ironic-python-agent-builder/commit/241d14cd2406a96fd83256e408b5106cf612d3b6', 'message': ""Remove outdated install pyyaml with pip2\n\nWe don't support python2 since a while\n\nChange-Id: I430ba8f86883b233b975f615e0e50b01e22c66e6\n""}]",0,886379,241d14cd2406a96fd83256e408b5106cf612d3b6,10,4,1,23851,,,0,"Remove outdated install pyyaml with pip2

We don't support python2 since a while

Change-Id: I430ba8f86883b233b975f615e0e50b01e22c66e6
",git fetch https://review.opendev.org/openstack/ironic-python-agent-builder refs/changes/79/886379/1 && git format-patch -1 --stdout FETCH_HEAD,['roles/ipa-build-dib-image/tasks/install.yaml'],1,241d14cd2406a96fd83256e408b5106cf612d3b6,remove-pip2-command,,"# NOTE(dtantsur): work around the issue in older DIB versions when some # elements try to use the default Python instead of the one DIB is using, # failing with ""No module named yaml"" - name: Install PyYAML in Python 2 pip: name: PyYAML extra_args: -c ""{{ ansible_user_dir }}/{{ zuul.projects['opendev.org/openstack/requirements'].src_dir }}/upper-constraints.txt"" executable: pip2 become: true ignore_errors: true",0,10
openstack%2Fswift~887740,openstack/swift,master,Ic1962975e5ff7025a86e18fc02f5de01c91aff73,updater: Redirect to root on client errors,NEW,2023-07-05 20:07:46.000000000,2023-07-06 19:17:55.000000000,,[{'_account_id': 22348}],"[{'number': 1, 'created': '2023-07-05 20:07:46.000000000', 'files': ['swift/obj/updater.py', 'test/unit/obj/test_updater.py'], 'web_link': 'https://opendev.org/openstack/swift/commit/2ac7d9dfcdf440f3b6120341002c65beb895cb8c', 'message': ""updater: Redirect to root on client errors\n\nWe've seen (rather old) updates get stuck because they're pointed at a\nshard whose DBs have been unlinked. This was likely done manually, as\npart of some overlapping-shard-ranges cleanup. Since there's no deleted\nDB to point us toward the new shard, the update hangs around retrying\nfor a full reclaim_age.\n\nNow, treat all 4xx errors as a (soft) redirect to the root. If we got\nany explicit redirects, trust those more -- but if all we've got are\n404s, we should really be going back to the root.\n\nChange-Id: Ic1962975e5ff7025a86e18fc02f5de01c91aff73\n""}]",3,887740,2ac7d9dfcdf440f3b6120341002c65beb895cb8c,5,1,1,15343,,,0,"updater: Redirect to root on client errors

We've seen (rather old) updates get stuck because they're pointed at a
shard whose DBs have been unlinked. This was likely done manually, as
part of some overlapping-shard-ranges cleanup. Since there's no deleted
DB to point us toward the new shard, the update hangs around retrying
for a full reclaim_age.

Now, treat all 4xx errors as a (soft) redirect to the root. If we got
any explicit redirects, trust those more -- but if all we've got are
404s, we should really be going back to the root.

Change-Id: Ic1962975e5ff7025a86e18fc02f5de01c91aff73
",git fetch https://review.opendev.org/openstack/swift refs/changes/40/887740/1 && git format-patch -1 --stdout FETCH_HEAD,"['swift/obj/updater.py', 'test/unit/obj/test_updater.py']",2,2ac7d9dfcdf440f3b6120341002c65beb895cb8c,," def test_obj_put_async_404_redirects_to_root(self): policies = list(POLICIES) random.shuffle(policies) # setup updater conf = { 'devices': self.devices_dir, 'mount_check': 'false', 'swift_dir': self.testdir, } daemon = object_updater.ObjectUpdater(conf, logger=self.logger) async_dir = os.path.join(self.sda1, get_async_dir(policies[0])) os.mkdir(async_dir) dfmanager = DiskFileManager(conf, daemon.logger) ts_obj = next(self.ts_iter) self._write_async_update(dfmanager, ts_obj, policies[0], container_path='shard/container') orig_async_path, orig_async_data = self._check_async_file(async_dir) # run once fake_responses = [ # only round of update attempts; going back to the root rewrites # the pickle (404, {}), (404, {}), (404, {}), ] fake_status_codes, fake_headers = zip(*fake_responses) with mocked_http_conn( *fake_status_codes, headers=fake_headers) as conn: with mock.patch('swift.obj.updater.dump_recon_cache'): daemon.run_once() self._check_update_requests(conn.requests[:3], ts_obj, policies[0]) self._check_update_requests(conn.requests[3:], ts_obj, policies[0]) self.assertEqual(['/sda1/0/shard/container/o'] * 3, [req['path'] for req in conn.requests]) self.assertEqual( {'redirects': 1, 'async_pendings': 1}, daemon.logger.get_increment_counts()) # async file now points to root async_path, async_data = self._check_async_file(async_dir) self.assertEqual(orig_async_path, async_path) expected = dict(orig_async_data, container_path=None, redirect_history=[]) self.assertEqual(expected, async_data) ",,68,5
openstack%2Fnova-specs~887014,openstack/nova-specs,master,I66a17b0840be4a9340a41022001420884d9f59eb,Propose tooling and docs for unified limits,MERGED,2023-06-27 01:52:06.000000000,2023-07-06 18:41:55.000000000,2023-07-06 18:40:17.000000000,"[{'_account_id': 7166}, {'_account_id': 11604}, {'_account_id': 22348}]","[{'number': 1, 'created': '2023-06-27 01:52:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/c1b640532f5934b107654d3c8e46919a02216ea0', 'message': 'Propose tooling and docs for unified limits\n\nRelated to blueprint unified-limits-nova-tool-and-docs\n\nChange-Id: I66a17b0840be4a9340a41022001420884d9f59eb\n'}, {'number': 2, 'created': '2023-06-27 22:23:50.000000000', 'files': ['specs/2023.2/approved/unified-limits-nova-tool-and-docs.rst'], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/15e09863f15271d485d05ab919f83dbfc6952db0', 'message': 'Propose tooling and docs for unified limits\n\nRelated to blueprint unified-limits-nova-tool-and-docs\n\nChange-Id: I66a17b0840be4a9340a41022001420884d9f59eb\n'}]",23,887014,15e09863f15271d485d05ab919f83dbfc6952db0,14,3,2,4690,,,0,"Propose tooling and docs for unified limits

Related to blueprint unified-limits-nova-tool-and-docs

Change-Id: I66a17b0840be4a9340a41022001420884d9f59eb
",git fetch https://review.opendev.org/openstack/nova-specs refs/changes/14/887014/1 && git format-patch -1 --stdout FETCH_HEAD,['specs/2023.2/approved/unified-limits-nova-tool-and-docs.rst'],1,c1b640532f5934b107654d3c8e46919a02216ea0,bp/unified-limits-nova-tool-and-docs,".. This work is licensed under a Creative Commons Attribution 3.0 Unported License. http://creativecommons.org/licenses/by/3.0/legalcode =================================== Tooling and Docs for Unified Limits =================================== https://blueprints.launchpad.net/nova/+spec/unified-limits-nova-tool-and-docs In the Yoga release support for Unified Limits was added in Nova as an experimental feature to get early feedback and fix issues that were found by operators trying it out. Now that a few releases have passed, we want to go ahead and formalize the unified limits quota driver by creating a tool to help operators copy their existing legacy quota limits from Nova to unified limits in Keystone, publish official documentation in the Nova quota documentation, and removing the note on the ``[quota]driver=nova.quota.UnifiedLimitsDriver`` config option indicating its experimental status. Problem description =================== Currently there is no documentation in the Nova docs about unified limits and there isn't any automated tool for generating unified limits in Keystone from existing Nova legacy quota limits. Use Cases --------- * As an operator, I would like to use a tool to automatically copy my existing legacy quota limits from Nova to unified limits in Keystone. * As an operator, I would like formal documentation for unified limits quotas to be available. Proposed change =============== We propose to create an automated tool, for example maybe ``nova-manage limits migrate_to_unified_limits`` that will read existing legacy quota limits from the Nova database and config options and create equivalent unified limits for them in Keystone using the Keystone REST API. It will be able to migrate both default limits and project-scoped limits. It will not migrate user-scoped limits as they are not supported by unified limits. We will add formal docs about unified limits to the Nova docs and remove the note on the ``[quota]driver`` config option about the ``nova.quota.UnifiedLimitsDriver`` being in a development state. Alternatives ------------ Operators can create unified limits using the ``openstack limit`` openstack client commands without a provided tool. Data model impact ----------------- None REST API impact --------------- None Security impact --------------- None Notifications impact -------------------- None Other end user impact --------------------- End users will be able to read documentation about how quotas work with unified limits. Performance Impact ------------------ None Other deployer impact --------------------- Deployers will have the option of using the quota limit migration tool to copy existing legacy Nova quota limits into Keystone unified limits instead of using openstackclient commands or otherwise calling the Keystone REST API manually. Developer impact ---------------- None Upgrade impact -------------- None Implementation ============== Assignee(s) ----------- Primary assignee: melwitt Other contributors: None Feature Liaison --------------- Feature liaison: melwitt Work Items ---------- * Develop a ``nova-manage limits`` command to copy existing legacy Nova quota limits from the Nova database and config options to unified limits by calling the Keystone REST API * Write documentation for unified limits in Nova * Remove note from ``[quota]driver=nova.quota.UnifiedLimitsDriver`` about the driver being in a development state * Collaborate with Keystone team to remove the docs warning in https://docs.openstack.org/keystone/latest/admin/unified-limits.html about the unified limits API labeled as experimental Dependencies ============ * https://specs.openstack.org/openstack/nova-specs/specs/yoga/implemented/unified-limits-nova.html Testing ======= Unit and/or functional testing for the quota limit migrate tool wil be added. We can also test the quota limit migrate tool alongside the existing nova/tools/hooks/post_test_hook.sh unified limits coverage in the nova-next CI job. Documentation Impact ==================== Operators will be most affected by the addition of Nova unified limits documentation. The following docs will need to be updated: * https://docs.openstack.org/nova/latest/user/quotas.html * https://docs.openstack.org/nova/latest/admin/quotas.html * https://docs.openstack.org/nova/latest/cli/nova-manage.html References ========== * https://etherpad.opendev.org/p/nova-bobcat-ptg#L415 * https://docs.openstack.org/keystone/latest/admin/unified-limits.html History ======= .. list-table:: Revisions :header-rows: 1 * - Release Name - Description * - 2023.2 Bobcat - Introduced ",,182,0
openstack%2Fbifrost~885874,openstack/bifrost,master,I208182e65884d63548d78c68f676b899c562a2dc,CI: Update cached cirros image to 0.5.3,MERGED,2023-06-12 12:57:47.000000000,2023-07-06 18:39:18.000000000,2023-07-06 18:38:23.000000000,"[{'_account_id': 10239}, {'_account_id': 22348}]","[{'number': 1, 'created': '2023-06-12 12:57:47.000000000', 'files': ['playbooks/test-bifrost.yaml'], 'web_link': 'https://opendev.org/openstack/bifrost/commit/5ee710cafb3d4ba772a134c95f936223c157d80f', 'message': ""CI: Update cached cirros image to 0.5.3\n\nBifrost CI is currently failing to fetch the cirros image from cache:\n\n    No such file or directory: '/opt/cache/files/cirros-0.5.1-x86_64-disk.img'\n\nThis may be caused by the removal of cirros-0.5.1 images from cache in\nchange Ibada405e0c1183559f428c749d0e54d0a45a2223.\n\nSwitch to cirros version 0.5.3 image instead.\n\nChange-Id: I208182e65884d63548d78c68f676b899c562a2dc\n""}]",0,885874,5ee710cafb3d4ba772a134c95f936223c157d80f,10,2,1,15197,,,0,"CI: Update cached cirros image to 0.5.3

Bifrost CI is currently failing to fetch the cirros image from cache:

    No such file or directory: '/opt/cache/files/cirros-0.5.1-x86_64-disk.img'

This may be caused by the removal of cirros-0.5.1 images from cache in
change Ibada405e0c1183559f428c749d0e54d0a45a2223.

Switch to cirros version 0.5.3 image instead.

Change-Id: I208182e65884d63548d78c68f676b899c562a2dc
",git fetch https://review.opendev.org/openstack/bifrost refs/changes/74/885874/1 && git format-patch -1 --stdout FETCH_HEAD,['playbooks/test-bifrost.yaml'],1,5ee710cafb3d4ba772a134c95f936223c157d80f,, cirros_deploy_image_upstream_url: file:///opt/cache/files/cirros-0.5.3-x86_64-disk.img, cirros_deploy_image_upstream_url: file:///opt/cache/files/cirros-0.5.1-x86_64-disk.img,1,1
openstack%2Ftripleo-docs~887631,openstack/tripleo-docs,master,I935982424e4b3ceaa614db585475e3e1aabccb69,Move the crush hierarchy example close to the option definition,MERGED,2023-07-04 15:12:46.000000000,2023-07-06 18:27:18.000000000,2023-07-06 18:25:52.000000000,"[{'_account_id': 18002}, {'_account_id': 22348}, {'_account_id': 25402}, {'_account_id': 34598}]","[{'number': 1, 'created': '2023-07-04 15:12:46.000000000', 'files': ['deploy-guide/source/features/deployed_ceph.rst'], 'web_link': 'https://opendev.org/openstack/tripleo-docs/commit/a8151e9563ccf158a90e72308cd6048d076a6f2f', 'message': 'Move the crush hierarchy example close to the option definition\n\nThe TLD section was added between the definition and the example\nof the same option, so fix the order.\n\nChange-Id: I935982424e4b3ceaa614db585475e3e1aabccb69\n'}]",1,887631,a8151e9563ccf158a90e72308cd6048d076a6f2f,10,4,1,10459,,,0,"Move the crush hierarchy example close to the option definition

The TLD section was added between the definition and the example
of the same option, so fix the order.

Change-Id: I935982424e4b3ceaa614db585475e3e1aabccb69
",git fetch https://review.opendev.org/openstack/tripleo-docs refs/changes/31/887631/1 && git format-patch -1 --stdout FETCH_HEAD,['deploy-guide/source/features/deployed_ceph.rst'],1,a8151e9563ccf158a90e72308cd6048d076a6f2f,fix-crush-hierarchy,"TLD option ---------- During ceph spec generation, if ``--tld`` is passed to `ceph_spec_bootstrap`_ ansible module, generated spec will have the hostnames appended with tld. This ``--tld`` option is available in `openstack overcloud ceph deploy` and `openstack overcloud ceph spec` commands. for example:: openstack overcloud ceph deploy \ --tld ""redhat.local"" During `openstack overcloud ceph deploy` , even the hostnames of all overcloud nodes are appended with ``--tld`` option, which makes it a Fully qualified Domain name (canonical name) suitable for TLS-e configuration. ","TLD option ---------- During ceph spec generation, if ``--tld`` is passed to `ceph_spec_bootstrap`_ ansible module, generated spec will have the hostnames appended with tld. This ``--tld`` option is available in `openstack overcloud ceph deploy` and `openstack overcloud ceph spec` commands. for example:: openstack overcloud ceph deploy \ --tld ""redhat.local"" During `openstack overcloud ceph deploy` , even the hostnames of all overcloud nodes are appended with ``--tld`` option, which makes it a Fully qualified Domain name (canonical name) suitable for TLS-e configuration. ",17,17
openstack%2Fneutron~887626,openstack/neutron,stable/xena,I89db15dd1b629bc963f3b63926391a4a02cbedf7,Ensure traffic is not centralized if DVR is enabled,MERGED,2023-07-05 05:32:57.000000000,2023-07-06 18:04:31.000000000,2023-07-06 18:03:02.000000000,"[{'_account_id': 16688}, {'_account_id': 21798}, {'_account_id': 22348}]","[{'number': 1, 'created': '2023-07-05 05:32:57.000000000', 'files': ['neutron/tests/unit/plugins/ml2/drivers/ovn/mech_driver/test_mech_driver.py', 'releasenotes/notes/dvr-external-mac-934409413e515eb2.yaml', 'neutron/plugins/ml2/drivers/ovn/mech_driver/mech_driver.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/ba7768d7ec399b1fd6bd3c806ea2ad20ce5c8fe7', 'message': 'Ensure traffic is not centralized if DVR is enabled\n\nThere is no need to clear the external_mac if DVR is enabled, not\neven when the port is down. This patch ensures the external_mac is\nonly deleted when DVR is not enabled.\n\nWithout this patch, if a VM with a floating IP gets deleted, and\nDVR is enabled, during some time the traffic gets (wrongly)\ncentralized while it should not. And it is also generating more\nload on the OVN side unnecesarily.\n\nCloses-Bug: #2025264\n\nChange-Id: I89db15dd1b629bc963f3b63926391a4a02cbedf7\n(cherry picked from commit 0090572b93d96348778c724194c26a976a9f8757)\n'}]",2,887626,ba7768d7ec399b1fd6bd3c806ea2ad20ce5c8fe7,15,3,1,23567,,,0,"Ensure traffic is not centralized if DVR is enabled

There is no need to clear the external_mac if DVR is enabled, not
even when the port is down. This patch ensures the external_mac is
only deleted when DVR is not enabled.

Without this patch, if a VM with a floating IP gets deleted, and
DVR is enabled, during some time the traffic gets (wrongly)
centralized while it should not. And it is also generating more
load on the OVN side unnecesarily.

Closes-Bug: #2025264

Change-Id: I89db15dd1b629bc963f3b63926391a4a02cbedf7
(cherry picked from commit 0090572b93d96348778c724194c26a976a9f8757)
",git fetch https://review.opendev.org/openstack/neutron refs/changes/26/887626/1 && git format-patch -1 --stdout FETCH_HEAD,"['neutron/tests/unit/plugins/ml2/drivers/ovn/mech_driver/test_mech_driver.py', 'releasenotes/notes/dvr-external-mac-934409413e515eb2.yaml', 'neutron/plugins/ml2/drivers/ovn/mech_driver/mech_driver.py']",3,ba7768d7ec399b1fd6bd3c806ea2ad20ce5c8fe7,," def _update_dnat_entry_if_needed(self, port_id): if ovn_conf.is_ovn_distributed_floating_ip(): mac = nat['external_ids'].get(ovn_const.OVN_FIP_EXT_MAC_KEY) if mac and nat['external_mac'] != mac: self._update_dnat_entry_if_needed(port_id)"," def _update_dnat_entry_if_needed(self, port_id, up=True): if up and ovn_conf.is_ovn_distributed_floating_ip(): mac = nat['external_ids'][ovn_const.OVN_FIP_EXT_MAC_KEY] if nat['external_mac'] != mac: self._update_dnat_entry_if_needed(port_id, False)",28,15
openstack%2Fneutron~887625,openstack/neutron,stable/yoga,I89db15dd1b629bc963f3b63926391a4a02cbedf7,Ensure traffic is not centralized if DVR is enabled,MERGED,2023-07-05 05:32:40.000000000,2023-07-06 18:04:29.000000000,2023-07-06 18:02:58.000000000,"[{'_account_id': 16688}, {'_account_id': 21798}, {'_account_id': 22348}]","[{'number': 1, 'created': '2023-07-05 05:32:40.000000000', 'files': ['neutron/tests/unit/plugins/ml2/drivers/ovn/mech_driver/test_mech_driver.py', 'releasenotes/notes/dvr-external-mac-934409413e515eb2.yaml', 'neutron/plugins/ml2/drivers/ovn/mech_driver/mech_driver.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/61d9e5972d30318650faf8f0ff88756000bdef6a', 'message': 'Ensure traffic is not centralized if DVR is enabled\n\nThere is no need to clear the external_mac if DVR is enabled, not\neven when the port is down. This patch ensures the external_mac is\nonly deleted when DVR is not enabled.\n\nWithout this patch, if a VM with a floating IP gets deleted, and\nDVR is enabled, during some time the traffic gets (wrongly)\ncentralized while it should not. And it is also generating more\nload on the OVN side unnecesarily.\n\nCloses-Bug: #2025264\n\nChange-Id: I89db15dd1b629bc963f3b63926391a4a02cbedf7\n(cherry picked from commit 0090572b93d96348778c724194c26a976a9f8757)\n'}]",1,887625,61d9e5972d30318650faf8f0ff88756000bdef6a,12,3,1,23567,,,0,"Ensure traffic is not centralized if DVR is enabled

There is no need to clear the external_mac if DVR is enabled, not
even when the port is down. This patch ensures the external_mac is
only deleted when DVR is not enabled.

Without this patch, if a VM with a floating IP gets deleted, and
DVR is enabled, during some time the traffic gets (wrongly)
centralized while it should not. And it is also generating more
load on the OVN side unnecesarily.

Closes-Bug: #2025264

Change-Id: I89db15dd1b629bc963f3b63926391a4a02cbedf7
(cherry picked from commit 0090572b93d96348778c724194c26a976a9f8757)
",git fetch https://review.opendev.org/openstack/neutron refs/changes/25/887625/1 && git format-patch -1 --stdout FETCH_HEAD,"['neutron/tests/unit/plugins/ml2/drivers/ovn/mech_driver/test_mech_driver.py', 'releasenotes/notes/dvr-external-mac-934409413e515eb2.yaml', 'neutron/plugins/ml2/drivers/ovn/mech_driver/mech_driver.py']",3,61d9e5972d30318650faf8f0ff88756000bdef6a,," def _update_dnat_entry_if_needed(self, port_id): if ovn_conf.is_ovn_distributed_floating_ip(): mac = nat['external_ids'].get(ovn_const.OVN_FIP_EXT_MAC_KEY) if mac and nat['external_mac'] != mac: self._update_dnat_entry_if_needed(port_id)"," def _update_dnat_entry_if_needed(self, port_id, up=True): if up and ovn_conf.is_ovn_distributed_floating_ip(): mac = nat['external_ids'][ovn_const.OVN_FIP_EXT_MAC_KEY] if nat['external_mac'] != mac: self._update_dnat_entry_if_needed(port_id, False)",28,15
openstack%2Fneutron~887624,openstack/neutron,stable/zed,I89db15dd1b629bc963f3b63926391a4a02cbedf7,Ensure traffic is not centralized if DVR is enabled,MERGED,2023-07-05 05:32:25.000000000,2023-07-06 18:04:21.000000000,2023-07-06 18:02:54.000000000,"[{'_account_id': 16688}, {'_account_id': 21798}, {'_account_id': 22348}]","[{'number': 1, 'created': '2023-07-05 05:32:25.000000000', 'files': ['neutron/tests/unit/plugins/ml2/drivers/ovn/mech_driver/test_mech_driver.py', 'releasenotes/notes/dvr-external-mac-934409413e515eb2.yaml', 'neutron/plugins/ml2/drivers/ovn/mech_driver/mech_driver.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/b9b819d7665ee72fd3fd86b1e08f2121451e6c94', 'message': 'Ensure traffic is not centralized if DVR is enabled\n\nThere is no need to clear the external_mac if DVR is enabled, not\neven when the port is down. This patch ensures the external_mac is\nonly deleted when DVR is not enabled.\n\nWithout this patch, if a VM with a floating IP gets deleted, and\nDVR is enabled, during some time the traffic gets (wrongly)\ncentralized while it should not. And it is also generating more\nload on the OVN side unnecesarily.\n\nCloses-Bug: #2025264\n\nChange-Id: I89db15dd1b629bc963f3b63926391a4a02cbedf7\n(cherry picked from commit 0090572b93d96348778c724194c26a976a9f8757)\n'}]",1,887624,b9b819d7665ee72fd3fd86b1e08f2121451e6c94,12,3,1,23567,,,0,"Ensure traffic is not centralized if DVR is enabled

There is no need to clear the external_mac if DVR is enabled, not
even when the port is down. This patch ensures the external_mac is
only deleted when DVR is not enabled.

Without this patch, if a VM with a floating IP gets deleted, and
DVR is enabled, during some time the traffic gets (wrongly)
centralized while it should not. And it is also generating more
load on the OVN side unnecesarily.

Closes-Bug: #2025264

Change-Id: I89db15dd1b629bc963f3b63926391a4a02cbedf7
(cherry picked from commit 0090572b93d96348778c724194c26a976a9f8757)
",git fetch https://review.opendev.org/openstack/neutron refs/changes/24/887624/1 && git format-patch -1 --stdout FETCH_HEAD,"['neutron/tests/unit/plugins/ml2/drivers/ovn/mech_driver/test_mech_driver.py', 'releasenotes/notes/dvr-external-mac-934409413e515eb2.yaml', 'neutron/plugins/ml2/drivers/ovn/mech_driver/mech_driver.py']",3,b9b819d7665ee72fd3fd86b1e08f2121451e6c94,," def _update_dnat_entry_if_needed(self, port_id): if ovn_conf.is_ovn_distributed_floating_ip(): mac = nat['external_ids'].get(ovn_const.OVN_FIP_EXT_MAC_KEY) if mac and nat['external_mac'] != mac: self._update_dnat_entry_if_needed(port_id)"," def _update_dnat_entry_if_needed(self, port_id, up=True): if up and ovn_conf.is_ovn_distributed_floating_ip(): mac = nat['external_ids'][ovn_const.OVN_FIP_EXT_MAC_KEY] if nat['external_mac'] != mac: self._update_dnat_entry_if_needed(port_id, False)",28,15
openstack%2Fneutron~887623,openstack/neutron,stable/2023.1,I89db15dd1b629bc963f3b63926391a4a02cbedf7,Ensure traffic is not centralized if DVR is enabled,MERGED,2023-07-05 05:31:35.000000000,2023-07-06 18:04:05.000000000,2023-07-06 18:02:50.000000000,"[{'_account_id': 16688}, {'_account_id': 21798}, {'_account_id': 22348}]","[{'number': 1, 'created': '2023-07-05 05:31:35.000000000', 'files': ['neutron/tests/unit/plugins/ml2/drivers/ovn/mech_driver/test_mech_driver.py', 'releasenotes/notes/dvr-external-mac-934409413e515eb2.yaml', 'neutron/plugins/ml2/drivers/ovn/mech_driver/mech_driver.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/fc29d622675ac4a7672416e735230a5759a49f41', 'message': 'Ensure traffic is not centralized if DVR is enabled\n\nThere is no need to clear the external_mac if DVR is enabled, not\neven when the port is down. This patch ensures the external_mac is\nonly deleted when DVR is not enabled.\n\nWithout this patch, if a VM with a floating IP gets deleted, and\nDVR is enabled, during some time the traffic gets (wrongly)\ncentralized while it should not. And it is also generating more\nload on the OVN side unnecesarily.\n\nCloses-Bug: #2025264\n\nChange-Id: I89db15dd1b629bc963f3b63926391a4a02cbedf7\n(cherry picked from commit 0090572b93d96348778c724194c26a976a9f8757)\n'}]",3,887623,fc29d622675ac4a7672416e735230a5759a49f41,15,3,1,23567,,,0,"Ensure traffic is not centralized if DVR is enabled

There is no need to clear the external_mac if DVR is enabled, not
even when the port is down. This patch ensures the external_mac is
only deleted when DVR is not enabled.

Without this patch, if a VM with a floating IP gets deleted, and
DVR is enabled, during some time the traffic gets (wrongly)
centralized while it should not. And it is also generating more
load on the OVN side unnecesarily.

Closes-Bug: #2025264

Change-Id: I89db15dd1b629bc963f3b63926391a4a02cbedf7
(cherry picked from commit 0090572b93d96348778c724194c26a976a9f8757)
",git fetch https://review.opendev.org/openstack/neutron refs/changes/23/887623/1 && git format-patch -1 --stdout FETCH_HEAD,"['neutron/tests/unit/plugins/ml2/drivers/ovn/mech_driver/test_mech_driver.py', 'releasenotes/notes/dvr-external-mac-934409413e515eb2.yaml', 'neutron/plugins/ml2/drivers/ovn/mech_driver/mech_driver.py']",3,fc29d622675ac4a7672416e735230a5759a49f41,," def _update_dnat_entry_if_needed(self, port_id): if ovn_conf.is_ovn_distributed_floating_ip(): mac = nat['external_ids'].get(ovn_const.OVN_FIP_EXT_MAC_KEY) if mac and nat['external_mac'] != mac: self._update_dnat_entry_if_needed(port_id)"," def _update_dnat_entry_if_needed(self, port_id, up=True): if up and ovn_conf.is_ovn_distributed_floating_ip(): mac = nat['external_ids'][ovn_const.OVN_FIP_EXT_MAC_KEY] if nat['external_mac'] != mac: self._update_dnat_entry_if_needed(port_id, False)",28,15
openstack%2Fopenstacksdk~885132,openstack/openstacksdk,master,I69522bf820e5cf4546ccf99da2c7373218785d9c,volume: Add missing attributes to Extension,MERGED,2023-06-02 13:35:16.000000000,2023-07-06 18:03:59.000000000,2023-07-06 18:02:47.000000000,"[{'_account_id': 15334}, {'_account_id': 22348}, {'_account_id': 27900}]","[{'number': 1, 'created': '2023-06-02 13:35:16.000000000', 'files': ['openstack/block_storage/v3/extension.py', 'openstack/tests/functional/block_storage/v3/test_extension.py', 'openstack/tests/unit/block_storage/v3/test_extension.py'], 'web_link': 'https://opendev.org/openstack/openstacksdk/commit/0adf8f5601001b3b768d62d787b730f8fd531202', 'message': ""volume: Add missing attributes to Extension\n\nWe also rename 'updated' to 'updated_at' to match the 'Extension'\nobjects provided by other services.\n\nChange-Id: I69522bf820e5cf4546ccf99da2c7373218785d9c\n""}]",2,885132,0adf8f5601001b3b768d62d787b730f8fd531202,14,3,1,15334,,,0,"volume: Add missing attributes to Extension

We also rename 'updated' to 'updated_at' to match the 'Extension'
objects provided by other services.

Change-Id: I69522bf820e5cf4546ccf99da2c7373218785d9c
",git fetch https://review.opendev.org/openstack/openstacksdk refs/changes/32/885132/1 && git format-patch -1 --stdout FETCH_HEAD,"['openstack/block_storage/v3/extension.py', 'openstack/tests/functional/block_storage/v3/test_extension.py', 'openstack/tests/unit/block_storage/v3/test_extension.py']",3,0adf8f5601001b3b768d62d787b730f8fd531202,volume-gaps," self.assertEqual(EXTENSION['links'], extension_resource.links) self.assertEqual(EXTENSION['name'], extension_resource.name) self.assertEqual(EXTENSION['updated'], extension_resource.updated_at)"," self.assertEqual(EXTENSION['updated'], extension_resource.updated)",9,5
openstack%2Fopenstack-ansible-os_nova~885337,openstack/openstack-ansible-os_nova,master,I56aee80180804b8a3e3316cffc6fa8115513b8f1,Apply always tag to nova_virt_detect.yml,MERGED,2023-06-06 05:35:49.000000000,2023-07-06 17:46:42.000000000,2023-07-06 17:45:36.000000000,"[{'_account_id': 22348}, {'_account_id': 25023}, {'_account_id': 28619}]","[{'number': 1, 'created': '2023-06-06 05:35:49.000000000', 'files': ['tasks/main.yml'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_nova/commit/c90a5c2b927b955aaa82d78e65548423b24f2ecc', 'message': ""Apply always tag to nova_virt_detect.yml\n\nRunning nova playbook with tag limit may lead to an error:\n\nThe conditional check 'nova_virt_type != 'ironic'' failed. The error\nwas: error while evaluating conditional (nova_virt_type != 'ironic'):\n'nova_virt_type' is undefined\\n\\nThe error appears to be in\n'/etc/ansible/roles/os_nova/tasks/main.yml': line 289, column 3, but\nmay be elsewhere in the file depending on the exact syntax problem.\n\nIt can be easily fixed by applying always tag to tasks from\nnova_virt_detect.yml\n\nChange-Id: I56aee80180804b8a3e3316cffc6fa8115513b8f1\n""}]",0,885337,c90a5c2b927b955aaa82d78e65548423b24f2ecc,8,3,1,32666,,,0,"Apply always tag to nova_virt_detect.yml

Running nova playbook with tag limit may lead to an error:

The conditional check 'nova_virt_type != 'ironic'' failed. The error
was: error while evaluating conditional (nova_virt_type != 'ironic'):
'nova_virt_type' is undefined\n\nThe error appears to be in
'/etc/ansible/roles/os_nova/tasks/main.yml': line 289, column 3, but
may be elsewhere in the file depending on the exact syntax problem.

It can be easily fixed by applying always tag to tasks from
nova_virt_detect.yml

Change-Id: I56aee80180804b8a3e3316cffc6fa8115513b8f1
",git fetch https://review.opendev.org/openstack/openstack-ansible-os_nova refs/changes/37/885337/1 && git format-patch -1 --stdout FETCH_HEAD,['tasks/main.yml'],1,c90a5c2b927b955aaa82d78e65548423b24f2ecc,tls-backend, args: apply: tags: - always,,4,0
openstack%2Fironic~887848,openstack/ironic,master,Ie0a5075451742736ceb71f7e446118e5a2d7284e,SQLAlchemy: LOG the connection event action,ABANDONED,2023-07-06 13:39:37.000000000,2023-07-06 17:44:03.000000000,,[{'_account_id': 22348}],"[{'number': 1, 'created': '2023-07-06 13:39:37.000000000', 'files': ['ironic/db/sqlalchemy/__init__.py'], 'web_link': 'https://opendev.org/openstack/ironic/commit/e48b8ec6c597c1c8d03e3ab66b5947ffd7422afa', 'message': 'SQLAlchemy: LOG the connection event action\n\nChange-Id: Ie0a5075451742736ceb71f7e446118e5a2d7284e\n'}]",0,887848,e48b8ec6c597c1c8d03e3ab66b5947ffd7422afa,5,1,1,11655,,,0,"SQLAlchemy: LOG the connection event action

Change-Id: Ie0a5075451742736ceb71f7e446118e5a2d7284e
",git fetch https://review.opendev.org/openstack/ironic refs/changes/48/887848/1 && git format-patch -1 --stdout FETCH_HEAD,['ironic/db/sqlalchemy/__init__.py'],1,e48b8ec6c597c1c8d03e3ab66b5947ffd7422afa,,from oslo_log import logLOG = log.getLogger(__name__) LOG.debug('Initializing SQLite connection to utilize the write-ahead' 'journal mode of operationl.'),,5,0
openstack%2Fnova-specs~878757,openstack/nova-specs,master,Ic7a456ecb59dd4498444f953a6bcb7f63ee3c902,Adds cleanup to remove dangling volumes,MERGED,2023-03-28 10:21:28.000000000,2023-07-06 15:33:49.000000000,2023-07-06 15:32:33.000000000,"[{'_account_id': 4393}, {'_account_id': 4690}, {'_account_id': 7166}, {'_account_id': 9535}, {'_account_id': 9708}, {'_account_id': 11604}, {'_account_id': 11655}, {'_account_id': 16207}, {'_account_id': 22348}]","[{'number': 1, 'created': '2023-03-28 10:21:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/aa9691f34752ca6f25879f0513efbdc1823ea796', 'message': 'Add cleanup flag spec to remove dangling volumes\n\nChange-Id: Ic7a456ecb59dd4498444f953a6bcb7f63ee3c902\n'}, {'number': 2, 'created': '2023-03-28 10:45:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/5195e23c43fa781847dff06b294ffb4f2e27b820', 'message': 'Add cleanup flag spec to remove dangling volumes\n\nChange-Id: Ic7a456ecb59dd4498444f953a6bcb7f63ee3c902\n'}, {'number': 3, 'created': '2023-03-29 06:38:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/c117b9c579185f154bf2a84f14a5b2220e0c78cf', 'message': 'Add cleanup flag to remove dangling volumes\n\nChange-Id: Ic7a456ecb59dd4498444f953a6bcb7f63ee3c902\n'}, {'number': 4, 'created': '2023-03-29 06:52:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/ca3bc5e30e8a29e2fe327f67345fc91c8e1df9dd', 'message': 'Add cleanup flag to remove dangling volumes\n\nChange-Id: Ic7a456ecb59dd4498444f953a6bcb7f63ee3c902\n'}, {'number': 5, 'created': '2023-03-29 06:55:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/d6eb12da3104a40afc6fc5ad17028dbf6bba37e2', 'message': 'Add cleanup flag to remove dangling volumes\n\nChange-Id: Ic7a456ecb59dd4498444f953a6bcb7f63ee3c902\n'}, {'number': 6, 'created': '2023-03-31 10:55:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/f39b630c356135e619562205ebcd3dc1118fa3cb', 'message': 'Add cleanup flag to remove dangling volumes\n\nBlueprint: https://blueprints.launchpad.net/nova/+spec/nova-manage-cleanup-dangling-volume-attachments\n\nChange-Id: Ic7a456ecb59dd4498444f953a6bcb7f63ee3c902\n'}, {'number': 7, 'created': '2023-03-31 11:39:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/d446e080a4199c3105ba39f764998993b98e0644', 'message': 'Add cleanup flag to remove dangling volumes\n\nBlueprint: https://blueprints.launchpad.net/nova/+spec/nova-manage-cleanup-dangling-volume-attachments\n\nChange-Id: Ic7a456ecb59dd4498444f953a6bcb7f63ee3c902\n'}, {'number': 8, 'created': '2023-03-31 13:08:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/377947a6c998a366c57d8d6fc132d210a63e69cb', 'message': 'Add cleanup flag to remove dangling volumes\n\nBlueprint: https://blueprints.launchpad.net/nova/+spec/nova-manage-cleanup-dangling-volume-attachments\n\nChange-Id: Ic7a456ecb59dd4498444f953a6bcb7f63ee3c902\n'}, {'number': 9, 'created': '2023-04-03 06:20:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/cc020388757c6b6a09fd723520b6b8cef051461b', 'message': 'Add cleanup flag to remove dangling volumes\n\nBlueprint: https://blueprints.launchpad.net/nova/+spec/nova-manage-cleanup-dangling-volume-attachments\n\nChange-Id: Ic7a456ecb59dd4498444f953a6bcb7f63ee3c902\n'}, {'number': 10, 'created': '2023-04-10 06:37:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/228f40f2fa188f94c5e43b2fccda623c42eea74d', 'message': 'Add cleanup flag to remove dangling volumes\n\nBlueprint: https://blueprints.launchpad.net/nova/+spec/nova-manage-cleanup-dangling-volume-attachments\n\nChange-Id: Ic7a456ecb59dd4498444f953a6bcb7f63ee3c902\n'}, {'number': 11, 'created': '2023-05-15 11:18:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/2e1c161885a91de6eeb3eaadece591794a540d55', 'message': 'Adds cleanup to remove dangling volumes\n\nChange-Id: Ic7a456ecb59dd4498444f953a6bcb7f63ee3c902\n'}, {'number': 12, 'created': '2023-05-16 09:27:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/befeb2b945cd58663433afb9b0cf50ba54c64c30', 'message': 'Adds cleanup to remove dangling volumes\n\nChange-Id: Ic7a456ecb59dd4498444f953a6bcb7f63ee3c902\n'}, {'number': 13, 'created': '2023-06-07 08:14:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/a50d1a21b081a7abfa719a34567902747d053fcd', 'message': 'Adds cleanup to remove dangling volumes\n\nChange-Id: Ic7a456ecb59dd4498444f953a6bcb7f63ee3c902\n'}, {'number': 14, 'created': '2023-06-21 11:37:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/1e1a3a926291df99de93cc7f73e6c8a3f4a583d3', 'message': 'Adds cleanup to remove dangling volumes\n\nChange-Id: Ic7a456ecb59dd4498444f953a6bcb7f63ee3c902\n'}, {'number': 15, 'created': '2023-06-30 09:45:31.000000000', 'files': ['specs/2023.2/approved/cleanup-dangling-volume-attachments.rst'], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/871aa3e4779be7deca9cde9d2a9bf40a5c56d010', 'message': 'Adds cleanup to remove dangling volumes\n\nChange-Id: Ic7a456ecb59dd4498444f953a6bcb7f63ee3c902\n'}]",99,878757,871aa3e4779be7deca9cde9d2a9bf40a5c56d010,63,9,15,34860,,,0,"Adds cleanup to remove dangling volumes

Change-Id: Ic7a456ecb59dd4498444f953a6bcb7f63ee3c902
",git fetch https://review.opendev.org/openstack/nova-specs refs/changes/57/878757/1 && git format-patch -1 --stdout FETCH_HEAD,['specs/2023.2/approved/nova-manage-cleanup-dangling-volume-attachments.rst'],1,aa9691f34752ca6f25879f0513efbdc1823ea796,dangling-volumes,".. This work is licensed under a Creative Commons Attribution 3.0 Unported License. http://creativecommons.org/licenses/by/3.0/legalcode =================================================== Clean Up dangling volumes using nova-manage command =================================================== Launchpad blueprint: https://blueprints.launchpad.net/nova/+spec/nova-manage-cleanup-dangling-volume-attachments Find out if there is any dangling/unattached volume in nova database and remove it from nova database. Problem description =================== In case after some volume operation, volume get deattached from instance but nova did not get notified and thinks volume is still attached to instance. This can lead to different issues which required volume details from block device mapping table, such as live miration and resizing of instance. Delete volume attachment-id using cinder 1 - There is a volume attached to an instance 2 - Delete volume attachement 3 - Verify using cinder api volume is not attached to instance 4 - Verify from nova api volume would be listed as attached to instance 5 - Verify in nova block device mapping table volume would be listed as attached to instance Use Cases --------- - As a operator, I want to remove all dangling volumes safely my instance had. So this can not affect other volume related operations. Proposed change =============== Soft delete block device mapping. Verify using nova.cinder.API.check_attached, if volume is not attached at cinder side, soft delete at nova side. Check attach volume raises, an InvalidVolume exception if volume is not in ""in-use"" status. if exception get caught perform soft-delete by calling bdm.destroy, this will update bdm table as deleted=ID. We already have a nova-mange utility with volume refresh option, add a new flag --clean-orphans to find all dangling volumes and then remove them from nova block device mapping table. .. code-block:: shell nova-manage volume_attachment refresh --clean-orphans pre-requisite: server should be shut-off, else later no other volume will be attached to it and same volume can not be attached to other instance. Problem if we use current refresh functionality user need to pass volume-id as well. So, we can have a new functionality, cleanup volumes in same class VolumeAttachmentCommands. Might be issue: .. code-block:: shell if we cleanup the volume and then later we attached same again now in bdm there are 2 entries. one deleted and another not deleted. | ec891162-8b65-4726-a16a-3eecf6257435 | 1ce5fc3a-0c28-4c0a-94c0-26cd0746e7f9 | ccb720ea-5d64-465c-9b15-b2b7a3b55cac | volume | volume | 097e3bf7-9697-40e6-8fdc-f2eca291e16e | NULL | 19 | | 0bcdfef7-6af5-44ee-bf21-4955607f5239 | 1ce5fc3a-0c28-4c0a-94c0-26cd0746e7f9 | ccb720ea-5d64-465c-9b15-b2b7a3b55cac | volume | volume | 68ef99d4-859b-4dca-b6e4-d2e59db532f0 | NULL | 0 | is this Okay ? Alternatives ------------ 1 - For each instance in bdm table, check if volume exists is attached if not remove it. In this solution instance uuid is not required, so we can have this as a cron job as well. Data model impact ----------------- nova block device mapping table will get updated on every operation, but no model changes. REST API impact --------------- N/A Security impact --------------- N/A Notifications impact -------------------- N/A Other end user impact --------------------- N/A Performance Impact ------------------ N/A Other deployer impact --------------------- N/A Developer impact ---------------- N/A Upgrade impact -------------- N/A Implementation ============== Assignee(s) ----------- Primary assignee: auniyal Feature Liaison --------------- Feature liaison: auniyal Work Items ---------- - Create a flag for nova-manage volume_attachment refresh functionality. - List all volumes instance instance block device mapping has. - Check volume status from cinder api, for volumes where source and destination type is volume. - if such volumes status is not in-use in cinder volume DB, update nova block device mapping DB to remove attachment from instance. Dependencies ============ N/A Testing ======= - Delete volume without deattaching from server - Delete server volume attachment-id when server is not shut-off, and run cleanup of dangling volumes. Documentation Impact ==================== Documentation will be updated References ========== N/A History ======= .. list-table:: Revisions :header-rows: 1 * - Release Name - Description * - 2023.2 Bobcat - Introduced ",,202,0
openstack%2Fneutron~887789,openstack/neutron,stable/victoria,I99fc9c3fcbf39c4f7a79d5ca936f16605dace1dd,"[stable-only] Disable ""neutron-tempest-plugin-scenario-ovn-wallaby""",ABANDONED,2023-07-06 10:17:09.000000000,2023-07-06 15:32:45.000000000,,"[{'_account_id': 16688}, {'_account_id': 22348}]","[{'number': 1, 'created': '2023-07-06 10:17:09.000000000', 'files': ['zuul.d/project.yaml'], 'web_link': 'https://opendev.org/openstack/neutron/commit/f8d8bae419e4d8736623995cc8a20d567fd91e79', 'message': '[stable-only] Disable ""neutron-tempest-plugin-scenario-ovn-wallaby""\n\nUntil the git clone issue is fixed (solved in newer versions in\ndevstack project), this CI job must be disabled.\n\nRelated-Bug: #2025486\nChange-Id: I99fc9c3fcbf39c4f7a79d5ca936f16605dace1dd\n'}]",0,887789,f8d8bae419e4d8736623995cc8a20d567fd91e79,4,2,1,16688,,,0,"[stable-only] Disable ""neutron-tempest-plugin-scenario-ovn-wallaby""

Until the git clone issue is fixed (solved in newer versions in
devstack project), this CI job must be disabled.

Related-Bug: #2025486
Change-Id: I99fc9c3fcbf39c4f7a79d5ca936f16605dace1dd
",git fetch https://review.opendev.org/openstack/neutron refs/changes/89/887789/1 && git format-patch -1 --stdout FETCH_HEAD,['zuul.d/project.yaml'],1,f8d8bae419e4d8736623995cc8a20d567fd91e79,bug/2025486, - neutron-tempest-plugin-api-victoria - neutron-tempest-plugin-scenario-linuxbridge-victoria - neutron-tempest-plugin-scenario-openvswitch-victoria - neutron-tempest-plugin-scenario-openvswitch-iptables_hybrid-victoria # NOTE(ralonsoh): disabled until LP#2025486 is fixed. #- neutron-tempest-plugin-scenario-ovn-victoria - neutron-tempest-plugin-designate-scenario-victoria - neutron-tempest-plugin-api-victoria, - neutron-tempest-plugin-jobs-victoria,8,1
openstack%2Fneutron~887788,openstack/neutron,stable/wallaby,I61451d483d72001c1aac8ab7b0af1d5b07bc1a3d,"[stable-only] Disable ""neutron-tempest-plugin-scenario-ovn-wallaby""",ABANDONED,2023-07-06 10:14:56.000000000,2023-07-06 15:32:43.000000000,,"[{'_account_id': 16688}, {'_account_id': 22348}]","[{'number': 1, 'created': '2023-07-06 10:14:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/1422c112b43d73e8a0ad02116ad5078ac54a9ea2', 'message': '[stable-only] Disable ""neutron-tempest-plugin-scenario-ovn-wallaby""\n\nUntil the git clone issue is fixed (solved in newer versions in\ndevstack project), this CI job must be disabled.\n\nRelated-Bug: #2025486\nChange-Id: I61451d483d72001c1aac8ab7b0af1d5b07bc1a3d\n'}, {'number': 2, 'created': '2023-07-06 10:16:03.000000000', 'files': ['zuul.d/project.yaml'], 'web_link': 'https://opendev.org/openstack/neutron/commit/290b00e0f0e5e4aff9f21ae8c6c335baec52bc64', 'message': '[stable-only] Disable ""neutron-tempest-plugin-scenario-ovn-wallaby""\n\nUntil the git clone issue is fixed (solved in newer versions in\ndevstack project), this CI job must be disabled.\n\nRelated-Bug: #2025486\nChange-Id: I61451d483d72001c1aac8ab7b0af1d5b07bc1a3d\n'}]",0,887788,290b00e0f0e5e4aff9f21ae8c6c335baec52bc64,5,2,2,16688,,,0,"[stable-only] Disable ""neutron-tempest-plugin-scenario-ovn-wallaby""

Until the git clone issue is fixed (solved in newer versions in
devstack project), this CI job must be disabled.

Related-Bug: #2025486
Change-Id: I61451d483d72001c1aac8ab7b0af1d5b07bc1a3d
",git fetch https://review.opendev.org/openstack/neutron refs/changes/88/887788/1 && git format-patch -1 --stdout FETCH_HEAD,['zuul.d/project.yaml'],1,1422c112b43d73e8a0ad02116ad5078ac54a9ea2,bug/2025486, - neutron-tempest-plugin-api-wallaby - neutron-tempest-plugin-scenario-linuxbridge-wallaby - neutron-tempest-plugin-scenario-openvswitch-wallaby - neutron-tempest-plugin-scenario-openvswitch-iptables_hybrid-wallaby # NOTE(ralonsoh): disables until LP#2025486 is fixed. #- neutron-tempest-plugin-scenario-ovn-wallaby - neutron-tempest-plugin-designate-scenario-wallaby - neutron-tempest-plugin-api-wallaby, - neutron-tempest-plugin-jobs-wallaby,8,1
openstack%2Fneutron~887791,openstack/neutron,stable/wallaby,If3487f1a9522438e2b6f3ebb30036a9360a2cb05,[DNM] wallaby ovn job fix,ABANDONED,2023-07-06 10:45:06.000000000,2023-07-06 14:21:13.000000000,,[{'_account_id': 22348}],"[{'number': 1, 'created': '2023-07-06 10:45:06.000000000', 'files': ['zuul.d/project.yaml'], 'web_link': 'https://opendev.org/openstack/neutron/commit/3ddb55e9fb8268f85c6375693f462223a9f16101', 'message': '[DNM] wallaby ovn job fix\n\nDepends-On: https://review.opendev.org/c/openstack/devstack/+/887790\nChange-Id: If3487f1a9522438e2b6f3ebb30036a9360a2cb05\n'}]",0,887791,3ddb55e9fb8268f85c6375693f462223a9f16101,3,1,1,13861,,,0,"[DNM] wallaby ovn job fix

Depends-On: https://review.opendev.org/c/openstack/devstack/+/887790
Change-Id: If3487f1a9522438e2b6f3ebb30036a9360a2cb05
",git fetch https://review.opendev.org/openstack/neutron refs/changes/91/887791/1 && git format-patch -1 --stdout FETCH_HEAD,['zuul.d/project.yaml'],1,3ddb55e9fb8268f85c6375693f462223a9f16101,bug/1987832, - neutron-tempest-plugin-scenario-ovn-wallaby, templates: - neutron-tempest-plugin-jobs-wallaby - openstack-cover-jobs - openstack-python3-wallaby-jobs - openstack-python3-wallaby-jobs-arm64 - publish-openstack-docs-pti - periodic-stable-jobs - check-requirements - release-notes-jobs-python3 - neutron-experimental-jobs - neutron-periodic-jobs - neutron-tox-override-jobs - neutron-functional-with-uwsgi - neutron-fullstack-with-uwsgi - neutron-rally-task - neutron-grenade-multinode - neutron-grenade-dvr-multinode: # TODO(slaweq): make that job voting when bug # https://bugs.launchpad.net/neutron/+bug/1920778 # will be fixed voting: false - neutron-tempest-multinode-full-py3 - neutron-tempest-dvr-ha-multinode-full - neutron-tempest-slow-py3 - neutron-tempest-ipv6-only - neutron-ovn-tempest-ovs-release - neutron-ovn-tempest-ovs-release-ipv6-only # TODO(slaweq): add this job again to the check queue when it will be # working fine on python 3 #- networking-midonet-tempest-aio-ml2-centos-7: # voting: false - neutron-ovn-rally-task: voting: false - neutron-ovn-tempest-slow gate: jobs: - neutron-functional-with-uwsgi - neutron-fullstack-with-uwsgi - neutron-tempest-multinode-full-py3 - neutron-grenade-multinode # TODO(slaweq): make that job gating when bug # https://bugs.launchpad.net/neutron/+bug/1920778 # will be fixed # - neutron-grenade-dvr-multinode - neutron-tempest-slow-py3 - neutron-tempest-ipv6-only - neutron-ovn-tempest-ovs-release - neutron-ovn-tempest-ovs-release-ipv6-only - neutron-ovn-tempest-slow #- neutron-ovn-rally-task #- neutron-ovn-tripleo-ci-centos-8-containers-multinode,1,51
openstack%2Fkeystone~879734,openstack/keystone,master,I906cb8f7b76833c880a40c1aa0584fe7ab93cb7a,sql: Fix incorrect columns,MERGED,2023-04-06 10:48:29.000000000,2023-07-06 14:16:15.000000000,2023-07-06 14:14:19.000000000,"[{'_account_id': 7414}, {'_account_id': 14250}, {'_account_id': 15334}, {'_account_id': 22348}]","[{'number': 1, 'created': '2023-04-06 10:48:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/20908ff4f5ff8f7fc92f911d2b9b24202fb6b7b6', 'message': 'sql: Fix incorrect columns\n\nIn these instances, we take the migrations to be the ""official"" version\n- since they\'re stricter in almost all cases - updating the models to\nsuit.\n\nChange-Id: I906cb8f7b76833c880a40c1aa0584fe7ab93cb7a\nSigned-off-by: Stephen Finucane <sfinucan@redhat.com>\n'}, {'number': 2, 'created': '2023-06-27 09:58:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/3219cc1632808ac5af3bfc85f5b73fe66b0899ec', 'message': 'sql: Fix incorrect columns\n\nIn these instances, we take the migrations to be the ""official"" version\n- since they\'re stricter in almost all cases - updating the models to\nsuit.\n\nChange-Id: I906cb8f7b76833c880a40c1aa0584fe7ab93cb7a\nSigned-off-by: Stephen Finucane <sfinucan@redhat.com>\n'}, {'number': 3, 'created': '2023-07-03 11:12:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/e05e3929d162182aaaa99c11fcf36f179ec6ffe2', 'message': 'sql: Fix incorrect columns\n\nIn these instances, we take the migrations to be the ""official"" version\n- since they\'re stricter in almost all cases - updating the models to\nsuit.\n\nThis change highlights a slight issue in our use of a config option in\nour database schema, which we shouldn\'t really do. A TODO is left to\naddress this later. We can also remove a now-unnecessary TODO from our\ninitial migration related to the same issue: we have our own tooling for\nmigrations that *does* load and register config options so there is no\nlonger an issue here.\n\nChange-Id: I906cb8f7b76833c880a40c1aa0584fe7ab93cb7a\nSigned-off-by: Stephen Finucane <sfinucan@redhat.com>\n'}, {'number': 4, 'created': '2023-07-03 11:33:09.000000000', 'files': ['keystone/common/sql/migrations/env.py', 'keystone/common/sql/migrations/versions/27e647c0fad4_initial_version.py', 'keystone/credential/backends/sql.py', 'keystone/identity/backends/sql_model.py', 'keystone/federation/backends/sql.py'], 'web_link': 'https://opendev.org/openstack/keystone/commit/2bf70a10a2a7e0ef31f790c21d9cb6b2643c186d', 'message': 'sql: Fix incorrect columns\n\nIn these instances, we take the migrations to be the ""official"" version\n- since they\'re stricter in almost all cases - updating the models to\nsuit.\n\nThis change highlights a slight issue in our use of a config option in\nour database schema, which we shouldn\'t really do. A TODO is left to\naddress this later. We can also remove a now-unnecessary TODO from our\ninitial migration related to the same issue: we have our own tooling for\nmigrations that *does* load and register config options so there is no\nlonger an issue here.\n\nChange-Id: I906cb8f7b76833c880a40c1aa0584fe7ab93cb7a\nSigned-off-by: Stephen Finucane <sfinucan@redhat.com>\n'}]",1,879734,2bf70a10a2a7e0ef31f790c21d9cb6b2643c186d,18,4,4,15334,,,0,"sql: Fix incorrect columns

In these instances, we take the migrations to be the ""official"" version
- since they're stricter in almost all cases - updating the models to
suit.

This change highlights a slight issue in our use of a config option in
our database schema, which we shouldn't really do. A TODO is left to
address this later. We can also remove a now-unnecessary TODO from our
initial migration related to the same issue: we have our own tooling for
migrations that *does* load and register config options so there is no
longer an issue here.

Change-Id: I906cb8f7b76833c880a40c1aa0584fe7ab93cb7a
Signed-off-by: Stephen Finucane <sfinucan@redhat.com>
",git fetch https://review.opendev.org/openstack/keystone refs/changes/34/879734/1 && git format-patch -1 --stdout FETCH_HEAD,"['keystone/common/sql/migrations/env.py', 'keystone/credential/backends/sql.py', 'keystone/identity/backends/sql_model.py', 'keystone/federation/backends/sql.py']",4,20908ff4f5ff8f7fc92f911d2b9b24202fb6b7b6,sqlalchemy-20,"import keystone.confCONF = keystone.conf.CONF relay_state_prefix = sql.Column( sql.String(256), nullable=False, server_default=CONF.saml.relay_state_prefix, )"," relay_state_prefix = sql.Column(sql.String(256), nullable=False)",38,28
openstack%2Fneutron~887610,openstack/neutron,stable/2023.1,I04f120d3ccd11b18ae08cb10b19a7cb5a0e8983d,Disable pool recycle in tests,MERGED,2023-07-04 12:54:49.000000000,2023-07-06 13:58:54.000000000,2023-07-06 13:56:22.000000000,"[{'_account_id': 16688}, {'_account_id': 21798}, {'_account_id': 22348}]","[{'number': 1, 'created': '2023-07-04 12:54:49.000000000', 'files': ['neutron/tests/base.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/cd8035306f3195aab541d52bfd453223d35d9172', 'message': ""Disable pool recycle in tests\n\nThe default for connection_recycle_time is\none hour. If any test using StaticSqlFixture\nruns after 1 hour it fails as connection get's\nrecycled.\n\nWith sqlite memory db if there is a connection\ndisconnect or reconnect db get's wiped off.\nThis patch disables the pool recycle so tests\ncan run fine even in slow environments.\n\nCloses-Bug: #2024674\nChange-Id: I04f120d3ccd11b18ae08cb10b19a7cb5a0e8983d\n(cherry picked from commit 576c468b711a94a1e6a7d5c65841b6a042dab855)\n""}]",1,887610,cd8035306f3195aab541d52bfd453223d35d9172,9,3,1,13861,,,0,"Disable pool recycle in tests

The default for connection_recycle_time is
one hour. If any test using StaticSqlFixture
runs after 1 hour it fails as connection get's
recycled.

With sqlite memory db if there is a connection
disconnect or reconnect db get's wiped off.
This patch disables the pool recycle so tests
can run fine even in slow environments.

Closes-Bug: #2024674
Change-Id: I04f120d3ccd11b18ae08cb10b19a7cb5a0e8983d
(cherry picked from commit 576c468b711a94a1e6a7d5c65841b6a042dab855)
",git fetch https://review.opendev.org/openstack/neutron refs/changes/10/887610/1 && git format-patch -1 --stdout FETCH_HEAD,['neutron/tests/base.py'],1,cd8035306f3195aab541d52bfd453223d35d9172,bug/2024674-stable/2023.1," # NOTE(ykarel): Disable pool recycle as tables are dropped with sqlite # memory db with connection close or reconnect cfg.CONF.set_override('connection_recycle_time', -1, group='database') ",,4,0
openstack%2Fneutron~887611,openstack/neutron,stable/zed,I04f120d3ccd11b18ae08cb10b19a7cb5a0e8983d,Disable pool recycle in tests,MERGED,2023-07-04 12:55:19.000000000,2023-07-06 13:58:45.000000000,2023-07-06 13:56:26.000000000,"[{'_account_id': 16688}, {'_account_id': 21798}, {'_account_id': 22348}]","[{'number': 1, 'created': '2023-07-04 12:55:19.000000000', 'files': ['neutron/tests/base.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/a03a60e89deefc12153c31229e00a77a58525f45', 'message': ""Disable pool recycle in tests\n\nThe default for connection_recycle_time is\none hour. If any test using StaticSqlFixture\nruns after 1 hour it fails as connection get's\nrecycled.\n\nWith sqlite memory db if there is a connection\ndisconnect or reconnect db get's wiped off.\nThis patch disables the pool recycle so tests\ncan run fine even in slow environments.\n\nCloses-Bug: #2024674\nChange-Id: I04f120d3ccd11b18ae08cb10b19a7cb5a0e8983d\n(cherry picked from commit 576c468b711a94a1e6a7d5c65841b6a042dab855)\n""}]",0,887611,a03a60e89deefc12153c31229e00a77a58525f45,9,3,1,13861,,,0,"Disable pool recycle in tests

The default for connection_recycle_time is
one hour. If any test using StaticSqlFixture
runs after 1 hour it fails as connection get's
recycled.

With sqlite memory db if there is a connection
disconnect or reconnect db get's wiped off.
This patch disables the pool recycle so tests
can run fine even in slow environments.

Closes-Bug: #2024674
Change-Id: I04f120d3ccd11b18ae08cb10b19a7cb5a0e8983d
(cherry picked from commit 576c468b711a94a1e6a7d5c65841b6a042dab855)
",git fetch https://review.opendev.org/openstack/neutron refs/changes/11/887611/1 && git format-patch -1 --stdout FETCH_HEAD,['neutron/tests/base.py'],1,a03a60e89deefc12153c31229e00a77a58525f45,bug/2024674-stable/2023.1-stable/zed," # NOTE(ykarel): Disable pool recycle as tables are dropped with sqlite # memory db with connection close or reconnect cfg.CONF.set_override('connection_recycle_time', -1, group='database') ",,4,0
openstack%2Fcinder-tempest-plugin~887294,openstack/cinder-tempest-plugin,master,Ic999af2e2f0c2429363f611f4bb113581b83bacf,Add test for create volume from backup,NEW,2023-06-29 15:14:20.000000000,2023-07-06 13:58:18.000000000,,"[{'_account_id': 20813}, {'_account_id': 22348}]","[{'number': 1, 'created': '2023-06-29 15:14:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder-tempest-plugin/commit/38c062811318638ac4669f5604eb97ba30056b37', 'message': 'Add test for create volume from backup\n\nRelated-Bug: #2025277\nChange-Id: Ic999af2e2f0c2429363f611f4bb113581b83bacf\n'}, {'number': 2, 'created': '2023-06-29 18:06:45.000000000', 'files': ['cinder_tempest_plugin/api/volume/test_volume_backup.py'], 'web_link': 'https://opendev.org/openstack/cinder-tempest-plugin/commit/bf94b3eb62f5e8430ab1543b61905017bad462f5', 'message': 'Add test for create volume from backup\n\nRelated-Bug: #2025277\nChange-Id: Ic999af2e2f0c2429363f611f4bb113581b83bacf\n'}]",2,887294,bf94b3eb62f5e8430ab1543b61905017bad462f5,5,2,2,4523,,,0,"Add test for create volume from backup

Related-Bug: #2025277
Change-Id: Ic999af2e2f0c2429363f611f4bb113581b83bacf
",git fetch https://review.opendev.org/openstack/cinder-tempest-plugin refs/changes/94/887294/1 && git format-patch -1 --stdout FETCH_HEAD,['cinder_tempest_plugin/api/volume/test_volume_backup.py'],1,38c062811318638ac4669f5604eb97ba30056b37,," class VolumesBackupsTest347(VolumesBackupTest): min_microversion = '3.47' @decorators.idempotent_id('a685788f-caa9-4d7d-b109-243d835d921a') def test_backup_create_and_create_volume_from_it(self): """"""Test backup create and create vol from backup."""""" src_vol = self.create_volume() backup = self.create_backup(volume_id=src_vol['id']) dest_vol = self.create_volume(backup_id=backup['id']) waiters.wait_for_volume_resource_status( self.volumes_client, dest_vol['id'], 'available')",,17,0
openstack%2Fneutron~887467,openstack/neutron,stable/xena,I9e8ddfa26c5402fefd573b0e2ea5f3a57983ca35,Delete sg rule which remote is the deleted sg,MERGED,2023-07-04 12:26:18.000000000,2023-07-06 13:57:50.000000000,2023-07-06 13:56:17.000000000,"[{'_account_id': 16688}, {'_account_id': 21798}, {'_account_id': 22348}]","[{'number': 1, 'created': '2023-07-04 12:26:18.000000000', 'files': ['neutron/tests/unit/api/rpc/handlers/test_securitygroups_rpc.py', 'neutron/api/rpc/handlers/securitygroups_rpc.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/a8b8902b11bc7843c4950f88b549f00048d95b4f', 'message': 'Delete sg rule which remote is the deleted sg\n\nBased on bug #2008712 if we have a security-group which\nis the remote group of a 2nd security-group, the backend\nnever deletes the rule of the 2nd group which\nremote_group_id is the original security-group.\nBy AFTER_DELETE event for each rule that has the\nsecurity_group_id as remote_group_id, we can make the\nmech drivers do their work and delete these rules in the\nbackend.\n\nOne version of this fix was merged:\nhttps://review.opendev.org/q/I207ecf7954b06507e03cb16b502ceb6e2807e0e7\nand reverted due to #2019449:\nhttps://review.opendev.org/q/I077fe87435f61bd29d5c1efc979c2adebca26181\n\nThis patch is based on\nhttps://review.opendev.org/c/openstack/neutron/+/876716/1\n\nCloses-Bug: #2008712\nRelated-Bug: #2019449\nChange-Id: I9e8ddfa26c5402fefd573b0e2ea5f3a57983ca35\n(cherry picked from commit 67a0b0728788207cee27adb586880fabb8da6f25)\n'}]",0,887467,a8b8902b11bc7843c4950f88b549f00048d95b4f,9,3,1,8313,,,0,"Delete sg rule which remote is the deleted sg

Based on bug #2008712 if we have a security-group which
is the remote group of a 2nd security-group, the backend
never deletes the rule of the 2nd group which
remote_group_id is the original security-group.
By AFTER_DELETE event for each rule that has the
security_group_id as remote_group_id, we can make the
mech drivers do their work and delete these rules in the
backend.

One version of this fix was merged:
https://review.opendev.org/q/I207ecf7954b06507e03cb16b502ceb6e2807e0e7
and reverted due to #2019449:
https://review.opendev.org/q/I077fe87435f61bd29d5c1efc979c2adebca26181

This patch is based on
https://review.opendev.org/c/openstack/neutron/+/876716/1

Closes-Bug: #2008712
Related-Bug: #2019449
Change-Id: I9e8ddfa26c5402fefd573b0e2ea5f3a57983ca35
(cherry picked from commit 67a0b0728788207cee27adb586880fabb8da6f25)
",git fetch https://review.opendev.org/openstack/neutron refs/changes/67/887467/1 && git format-patch -1 --stdout FETCH_HEAD,"['neutron/tests/unit/api/rpc/handlers/test_securitygroups_rpc.py', 'neutron/api/rpc/handlers/securitygroups_rpc.py']",2,a8b8902b11bc7843c4950f88b549f00048d95b4f,bug/2008712-stable/2023.1-stable/zed-stable/yoga-stable/xena," # If there's a rule which remote is the deleted sg, remove that also. rules = self.rcache.match_resources_with_func( 'SecurityGroupRule', lambda sg_rule: sg_rule.remote_group_id == existing.id) for rule in rules: self.rcache.record_resource_delete(context, 'SecurityGroupRule', rule.id)",,56,1
openstack%2Fneutron~887466,openstack/neutron,stable/yoga,I9e8ddfa26c5402fefd573b0e2ea5f3a57983ca35,Delete sg rule which remote is the deleted sg,MERGED,2023-07-04 12:25:21.000000000,2023-07-06 13:57:49.000000000,2023-07-06 13:56:13.000000000,"[{'_account_id': 16688}, {'_account_id': 21798}, {'_account_id': 22348}]","[{'number': 1, 'created': '2023-07-04 12:25:21.000000000', 'files': ['neutron/tests/unit/api/rpc/handlers/test_securitygroups_rpc.py', 'neutron/api/rpc/handlers/securitygroups_rpc.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/78b7cf82dd84ea19c6a147c8715961f7c37ce448', 'message': 'Delete sg rule which remote is the deleted sg\n\nBased on bug #2008712 if we have a security-group which\nis the remote group of a 2nd security-group, the backend\nnever deletes the rule of the 2nd group which\nremote_group_id is the original security-group.\nBy AFTER_DELETE event for each rule that has the\nsecurity_group_id as remote_group_id, we can make the\nmech drivers do their work and delete these rules in the\nbackend.\n\nOne version of this fix was merged:\nhttps://review.opendev.org/q/I207ecf7954b06507e03cb16b502ceb6e2807e0e7\nand reverted due to #2019449:\nhttps://review.opendev.org/q/I077fe87435f61bd29d5c1efc979c2adebca26181\n\nThis patch is based on\nhttps://review.opendev.org/c/openstack/neutron/+/876716/1\n\nCloses-Bug: #2008712\nRelated-Bug: #2019449\nChange-Id: I9e8ddfa26c5402fefd573b0e2ea5f3a57983ca35\n(cherry picked from commit 67a0b0728788207cee27adb586880fabb8da6f25)\n'}]",0,887466,78b7cf82dd84ea19c6a147c8715961f7c37ce448,9,3,1,8313,,,0,"Delete sg rule which remote is the deleted sg

Based on bug #2008712 if we have a security-group which
is the remote group of a 2nd security-group, the backend
never deletes the rule of the 2nd group which
remote_group_id is the original security-group.
By AFTER_DELETE event for each rule that has the
security_group_id as remote_group_id, we can make the
mech drivers do their work and delete these rules in the
backend.

One version of this fix was merged:
https://review.opendev.org/q/I207ecf7954b06507e03cb16b502ceb6e2807e0e7
and reverted due to #2019449:
https://review.opendev.org/q/I077fe87435f61bd29d5c1efc979c2adebca26181

This patch is based on
https://review.opendev.org/c/openstack/neutron/+/876716/1

Closes-Bug: #2008712
Related-Bug: #2019449
Change-Id: I9e8ddfa26c5402fefd573b0e2ea5f3a57983ca35
(cherry picked from commit 67a0b0728788207cee27adb586880fabb8da6f25)
",git fetch https://review.opendev.org/openstack/neutron refs/changes/66/887466/1 && git format-patch -1 --stdout FETCH_HEAD,"['neutron/tests/unit/api/rpc/handlers/test_securitygroups_rpc.py', 'neutron/api/rpc/handlers/securitygroups_rpc.py']",2,78b7cf82dd84ea19c6a147c8715961f7c37ce448,bug/2008712-stable/2023.1-stable/zed-stable/yoga," # If there's a rule which remote is the deleted sg, remove that also. rules = self.rcache.match_resources_with_func( 'SecurityGroupRule', lambda sg_rule: sg_rule.remote_group_id == existing.id) for rule in rules: self.rcache.record_resource_delete(context, 'SecurityGroupRule', rule.id)",,56,1
openstack%2Fneutron~887465,openstack/neutron,stable/zed,I9e8ddfa26c5402fefd573b0e2ea5f3a57983ca35,Delete sg rule which remote is the deleted sg,MERGED,2023-07-04 12:25:00.000000000,2023-07-06 13:57:47.000000000,2023-07-06 13:56:09.000000000,"[{'_account_id': 16688}, {'_account_id': 21798}, {'_account_id': 22348}]","[{'number': 1, 'created': '2023-07-04 12:25:00.000000000', 'files': ['neutron/tests/unit/api/rpc/handlers/test_securitygroups_rpc.py', 'neutron/api/rpc/handlers/securitygroups_rpc.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/4d09a6f7de00fe0db11af860d0da32719c8dd168', 'message': 'Delete sg rule which remote is the deleted sg\n\nBased on bug #2008712 if we have a security-group which\nis the remote group of a 2nd security-group, the backend\nnever deletes the rule of the 2nd group which\nremote_group_id is the original security-group.\nBy AFTER_DELETE event for each rule that has the\nsecurity_group_id as remote_group_id, we can make the\nmech drivers do their work and delete these rules in the\nbackend.\n\nOne version of this fix was merged:\nhttps://review.opendev.org/q/I207ecf7954b06507e03cb16b502ceb6e2807e0e7\nand reverted due to #2019449:\nhttps://review.opendev.org/q/I077fe87435f61bd29d5c1efc979c2adebca26181\n\nThis patch is based on\nhttps://review.opendev.org/c/openstack/neutron/+/876716/1\n\nCloses-Bug: #2008712\nRelated-Bug: #2019449\nChange-Id: I9e8ddfa26c5402fefd573b0e2ea5f3a57983ca35\n(cherry picked from commit 67a0b0728788207cee27adb586880fabb8da6f25)\n'}]",1,887465,4d09a6f7de00fe0db11af860d0da32719c8dd168,11,3,1,8313,,,0,"Delete sg rule which remote is the deleted sg

Based on bug #2008712 if we have a security-group which
is the remote group of a 2nd security-group, the backend
never deletes the rule of the 2nd group which
remote_group_id is the original security-group.
By AFTER_DELETE event for each rule that has the
security_group_id as remote_group_id, we can make the
mech drivers do their work and delete these rules in the
backend.

One version of this fix was merged:
https://review.opendev.org/q/I207ecf7954b06507e03cb16b502ceb6e2807e0e7
and reverted due to #2019449:
https://review.opendev.org/q/I077fe87435f61bd29d5c1efc979c2adebca26181

This patch is based on
https://review.opendev.org/c/openstack/neutron/+/876716/1

Closes-Bug: #2008712
Related-Bug: #2019449
Change-Id: I9e8ddfa26c5402fefd573b0e2ea5f3a57983ca35
(cherry picked from commit 67a0b0728788207cee27adb586880fabb8da6f25)
",git fetch https://review.opendev.org/openstack/neutron refs/changes/65/887465/1 && git format-patch -1 --stdout FETCH_HEAD,"['neutron/tests/unit/api/rpc/handlers/test_securitygroups_rpc.py', 'neutron/api/rpc/handlers/securitygroups_rpc.py']",2,4d09a6f7de00fe0db11af860d0da32719c8dd168,bug/2008712-stable/2023.1-stable/zed," # If there's a rule which remote is the deleted sg, remove that also. rules = self.rcache.match_resources_with_func( 'SecurityGroupRule', lambda sg_rule: sg_rule.remote_group_id == existing.id) for rule in rules: self.rcache.record_resource_delete(context, 'SecurityGroupRule', rule.id)",,56,1
openstack%2Fneutron~887464,openstack/neutron,stable/2023.1,I9e8ddfa26c5402fefd573b0e2ea5f3a57983ca35,Delete sg rule which remote is the deleted sg,MERGED,2023-07-04 12:23:36.000000000,2023-07-06 13:57:47.000000000,2023-07-06 13:56:05.000000000,"[{'_account_id': 16688}, {'_account_id': 21798}, {'_account_id': 22348}]","[{'number': 1, 'created': '2023-07-04 12:23:36.000000000', 'files': ['neutron/tests/unit/api/rpc/handlers/test_securitygroups_rpc.py', 'neutron/api/rpc/handlers/securitygroups_rpc.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/287f4231a0b4b0e7b3fdaa0fcd415d6a4aeb2930', 'message': 'Delete sg rule which remote is the deleted sg\n\nBased on bug #2008712 if we have a security-group which\nis the remote group of a 2nd security-group, the backend\nnever deletes the rule of the 2nd group which\nremote_group_id is the original security-group.\nBy AFTER_DELETE event for each rule that has the\nsecurity_group_id as remote_group_id, we can make the\nmech drivers do their work and delete these rules in the\nbackend.\n\nOne version of this fix was merged:\nhttps://review.opendev.org/q/I207ecf7954b06507e03cb16b502ceb6e2807e0e7\nand reverted due to #2019449:\nhttps://review.opendev.org/q/I077fe87435f61bd29d5c1efc979c2adebca26181\n\nThis patch is based on\nhttps://review.opendev.org/c/openstack/neutron/+/876716/1\n\nCloses-Bug: #2008712\nRelated-Bug: #2019449\nChange-Id: I9e8ddfa26c5402fefd573b0e2ea5f3a57983ca35\n(cherry picked from commit 67a0b0728788207cee27adb586880fabb8da6f25)\n'}]",1,887464,287f4231a0b4b0e7b3fdaa0fcd415d6a4aeb2930,9,3,1,8313,,,0,"Delete sg rule which remote is the deleted sg

Based on bug #2008712 if we have a security-group which
is the remote group of a 2nd security-group, the backend
never deletes the rule of the 2nd group which
remote_group_id is the original security-group.
By AFTER_DELETE event for each rule that has the
security_group_id as remote_group_id, we can make the
mech drivers do their work and delete these rules in the
backend.

One version of this fix was merged:
https://review.opendev.org/q/I207ecf7954b06507e03cb16b502ceb6e2807e0e7
and reverted due to #2019449:
https://review.opendev.org/q/I077fe87435f61bd29d5c1efc979c2adebca26181

This patch is based on
https://review.opendev.org/c/openstack/neutron/+/876716/1

Closes-Bug: #2008712
Related-Bug: #2019449
Change-Id: I9e8ddfa26c5402fefd573b0e2ea5f3a57983ca35
(cherry picked from commit 67a0b0728788207cee27adb586880fabb8da6f25)
",git fetch https://review.opendev.org/openstack/neutron refs/changes/64/887464/1 && git format-patch -1 --stdout FETCH_HEAD,"['neutron/tests/unit/api/rpc/handlers/test_securitygroups_rpc.py', 'neutron/api/rpc/handlers/securitygroups_rpc.py']",2,287f4231a0b4b0e7b3fdaa0fcd415d6a4aeb2930,bug/2008712-stable/2023.1," # If there's a rule which remote is the deleted sg, remove that also. rules = self.rcache.match_resources_with_func( 'SecurityGroupRule', lambda sg_rule: sg_rule.remote_group_id == existing.id) for rule in rules: self.rcache.record_resource_delete(context, 'SecurityGroupRule', rule.id)",,56,1
openstack%2Fmanila-specs~881894,openstack/manila-specs,master,Icdc909c43459730c8e35a677779d842e36dc7b1b,Allow locking shares against deletion,MERGED,2023-04-29 01:58:47.000000000,2023-07-06 13:41:14.000000000,2023-07-06 13:40:12.000000000,"[{'_account_id': 11604}, {'_account_id': 16207}, {'_account_id': 22348}, {'_account_id': 29632}, {'_account_id': 30407}, {'_account_id': 35677}]","[{'number': 1, 'created': '2023-04-29 01:58:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/manila-specs/commit/d469d5e4e2242618435add2e01ed7bd91b5a6f7e', 'message': 'Allow locking shares against deletion\n\nA proposal to introduce ""resource locks"" that\ncan be placed by project users against project\nresources and specific resource actions that\nthey intend to prevent. In the 2023.2 Bobcat\ncycle, the share deletion resource locks will\nbe implemented.\n\nPartially-Implements: bp allow-locking-shares-against-deletion\nAPIImpact\n\nChange-Id: Icdc909c43459730c8e35a677779d842e36dc7b1b\nSigned-off-by: Goutham Pacha Ravi <gouthampravi@gmail.com>\n'}, {'number': 2, 'created': '2023-06-14 08:34:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/manila-specs/commit/db6ae3f55811a8a338d974077a36a1b5bfa8dab3', 'message': 'Allow locking shares against deletion\n\nA proposal to introduce ""resource locks"" that\ncan be placed by project users against project\nresources and specific resource actions that\nthey intend to prevent. In the 2023.2 Bobcat\ncycle, the share deletion resource locks will\nbe implemented.\n\nPartially-Implements: bp allow-locking-shares-against-deletion\nAPIImpact\n\nChange-Id: Icdc909c43459730c8e35a677779d842e36dc7b1b\nSigned-off-by: Goutham Pacha Ravi <gouthampravi@gmail.com>\n'}, {'number': 3, 'created': '2023-06-30 07:12:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/manila-specs/commit/415e52dacbcf6ee4bc3e5332f0fbbf000605acec', 'message': 'Allow locking shares against deletion\n\nA proposal to introduce ""resource locks"" that\ncan be placed by project users against project\nresources and specific resource actions that\nthey intend to prevent. In the 2023.2 Bobcat\ncycle, the share deletion resource locks will\nbe implemented.\n\nPartially-Implements: bp allow-locking-shares-against-deletion\nAPIImpact\n\nChange-Id: Icdc909c43459730c8e35a677779d842e36dc7b1b\nSigned-off-by: Goutham Pacha Ravi <gouthampravi@gmail.com>\n'}, {'number': 4, 'created': '2023-07-05 14:45:17.000000000', 'files': ['doc/source/index.rst', 'specs/bobcat/allow-locking-shares-against-deletion.rst'], 'web_link': 'https://opendev.org/openstack/manila-specs/commit/194021de433f609fb3e0867ca72ef84cf521b8f2', 'message': 'Allow locking shares against deletion\n\nA proposal to introduce ""resource locks"" that\ncan be placed by project users against project\nresources and specific resource actions that\nthey intend to prevent. In the 2023.2 Bobcat\ncycle, the share deletion resource locks will\nbe implemented.\n\nPartially-Implements: bp allow-locking-shares-against-deletion\nAPIImpact\n\nChange-Id: Icdc909c43459730c8e35a677779d842e36dc7b1b\nSigned-off-by: Goutham Pacha Ravi <gouthampravi@gmail.com>\n'}]",80,881894,194021de433f609fb3e0867ca72ef84cf521b8f2,33,6,4,16643,,,0,"Allow locking shares against deletion

A proposal to introduce ""resource locks"" that
can be placed by project users against project
resources and specific resource actions that
they intend to prevent. In the 2023.2 Bobcat
cycle, the share deletion resource locks will
be implemented.

Partially-Implements: bp allow-locking-shares-against-deletion
APIImpact

Change-Id: Icdc909c43459730c8e35a677779d842e36dc7b1b
Signed-off-by: Goutham Pacha Ravi <gouthampravi@gmail.com>
",git fetch https://review.opendev.org/openstack/manila-specs refs/changes/94/881894/1 && git format-patch -1 --stdout FETCH_HEAD,"['doc/source/index.rst', 'specs/bobcat/allow-locking-shares-against-deletion.rst']",2,d469d5e4e2242618435add2e01ed7bd91b5a6f7e,bp/allow-locking-shares-against-deletion,".. This work is licensed under a Creative Commons Attribution 3.0 Unported License. http://creativecommons.org/licenses/by/3.0/legalcode ===================================== Allow locking shares against deletion ===================================== Include the URL of your launchpad blueprint: https://blueprints.launchpad.net/manila/+spec/allow-locking-shares-against-deletion The default RBAC permits a non-reader project user to create and delete shares under the project's namespace. Deletion of shares can be dangerous, and we expect that users exercise caution before initiating the action. The Shared File Systems (Manila) API ensures that some pre-conditions are met prior to proceeding with the deletion. A desirable pre-condition would be to check if the share is actively being used by a client workload. Such a check however is not straight forward to perform as it cannot reliably be implemented in a consistent manner across all Network Attached Storage (NAS) protocols or storage system back ends that Manila supports. In other words, Manila does not know who and how many clients have mounted a share, or if data is actively being read or written into the share. So there is a need for a safety mechanism to prevent unintentional consequences. This specification proposes a new pre-condition, one that allows any non-reader project user to create a deletion lock against a share in the project's namespace. The deletion lock can be removed by the same user, or by a privileged user. Problem description =================== A shared file system is served by a network file server and it allows several simultaneous clients to connect, read and write to it. In OpenStack, Manila shares are collectively owned by the project users that the share belongs to. A user in the project can delete a share that some other user is actively using, and Manila API provides no way to indicate or coordinate communication prior to this deletion. Further, as part of the protocol, NAS clients are hardened to survive minor network interruptions and server side failures within a degree of tolerance. If the server goes unresponsive for a while, the client can wait, filling up its write cache or retrying its reads until they succeed, or until the tolerance expires. In the most common scenario, the client can be instructed to wait indefinitely (""hard mounts""). So, an extended server failure can be catastrophic to the client. If a file system that is mounted is deleted on the server, the client typically exercises the same waiting behavior and can go unresponsive in the process. Use Cases ========= The most recent use case is with the OpenStack Compute feature that allows users to mount their shares to virtual machines via VirtIOFS `[1]`_. With this feature, a compute host can plumb a mounted network filesystem to one or more guests. If the share is deleted while it is mounted, the compute host would be compromised. This would disable all virtual machines on the host, not just the virtual machine that was using the share via VirtIOFS. So while the Compute service orchestrates the mount, a user's action of deleting the backing share can bring down the shared infrastructure. Proposed change =============== Users will have the ability to lock any share in the project. Multiple locks can be placed on the share. A share cannot be deleted unless all locks have been removed. Only the user that placed the lock, or the administrator user can remove a given lock. If a user attempts to lock a share that is previously locked by them, the API will not present an error. The lock record can be updated with a new lock reason or a different lock action. The implementation of this feature will include generalizations for future extensibility. The lock API will accept a resource ID, resource type, and a resource action that must be locked. In the 2023.2 Bobcat release cycle, we will only be implementing deletion locks for shares. Alternatives ------------ Shares could have an ""in-use"" state that could prevent adverse manipulation. The presence of access rules can allow a share to transition to this ""in-use"" status. The problem with this approach is that users could drain access rules prior to deleting the share. This provides a two-step deletion ensuring that the action is deliberate. However, in the use case above, it wouldn't protect OpenStack Compute service resources from losing the share gracelessly. Data model impact ----------------- A new table will be introduced:: +-----------------+---------------+----------+----------+ | Field | Type | Nullable | Default | +-----------------+---------------+----------+----------+ | ID | varchar(36) | NO | NULL | | USER_ID | varchar(36) | YES | NULL | | PROJECT_ID | varchar(36) | YES | NULL | | RESOURCE_ACTION | varchar(255) | YES | 'delete' | | RESOURCE_TYPE | varchar(255) | YES | NULL | | RESOURCE_ID | varchar(36) | NO | NULL | | LOCK_REASON | varchar(1023) | YES | NULL | | DELETED | tinyint(1) | YES | NULL | | CREATED_AT | datetime(6) | YES | NULL | | DELETED_AT | datetime(6) | YES | NULL | | UPDATED_AT | datetime(6) | YES | NULL | +-----------------+---------------+----------+----------+ The table will assist storing lock records and will be manipulated as locks are created, updated and removed. A database migration will create this table with no initial data. REST API impact --------------- The APIs using resource lock endpoints and methods will only be available in a new API micro version. However, if resource locks exist, they cannot be circumvented by using an older API micro version to perform the action that they are preventing. **Create a resource lock on a particular action**:: POST /v2/resource-locks Normal http response code(s): - 204 - Lock created successfully Expected http error code(s): - 401 - Unauthorized; user has not authenticated - 400 - Bad Request - 400 - Unrecognized action on resource - 400 - Unrecognized resource (no such resource in project namespace) - 403 - Forbidden; user is forbidden by policy - 404 - API does not exist in micro version - 406 - API version not supported Request example:: { 'resource_lock': { 'resource_action': 'delete', 'resource_type': 'share', 'resource_id': 'a448e0d2-7501-4b99-a447-1b89e3961e39', 'lock_reason': 'share is used by audit team' } } Response example:: { 'resource_lock': { 'id': 'be0871e8-742e-4c19-8567-7016fa0e2235', 'user_id': 'cec1dd3e297b45348228f4fc3f5dba38', 'project_id': '2e47ac4e2cf04a5b8b8509de8177d65d', 'resource_action': 'delete', 'resource_type': 'share', 'resource_id': 'a448e0d2-7501-4b99-a447-1b89e3961e39', 'lock_reason': 'share is used by audit team', 'created_at': '2023-04-28T09:49:58-05:00', 'updated_at': None } } **Update a resource lock**:: PUT /v2/resource-locks/{id} Updatable fields include ""resource_action"" and ""lock_reason"". ""lock_reason"" can be nullified on update. Only the user that created the lock or a user with ""admin"" role will be allowed to update a lock per default RBAC policy. Normal http response code(s): - 200 - Lock updated successfully Expected http error code(s): - 401 - Unauthorized; user has not authenticated - 400 - Bad Request - 400 - Unrecognized action on resource - 400 - Unrecognized resource (no such resource in project namespace) - 403 - Forbidden; user is forbidden by policy - 404 - API does not exist in micro version - 404 - lock does not exist in project namespace - 406 - API version not supported Request example:: { 'resource_lock': { 'id': 'be0871e8-742e-4c19-8567-7016fa0e2235', 'lock_reason': 'share will be used by audit team until 2024' } } Response example:: { 'resource_lock': { 'id': 'be0871e8-742e-4c19-8567-7016fa0e2235', 'user_id': 'cec1dd3e297b45348228f4fc3f5dba38', 'project_id': '2e47ac4e2cf04a5b8b8509de8177d65d', 'resource_action': 'delete', 'resource_type': 'share', 'resource_id': 'a448e0d2-7501-4b99-a447-1b89e3961e39', 'lock_reason': 'share will be used by audit team until 2024', 'created_at': '2023-04-28T09:49:58.231919', 'updated_at': '2023-04-28T20:01:13.12106' } } **Delete a resource lock for a particular action**:: DELETE /v2/resource-locks/{id} Only the user that created the lock or a user with ""admin"" role will be allowed to delete a lock per default RBAC policy. Normal http response code(s): - 204 - Lock deleted successfully Expected http error code(s): - 401 - Unauthorized; user has not authenticated - 400 - Bad Request - 403 - Forbidden; user is forbidden by policy - 404 - API does not exist in microversion - 404 - lock does not exist in project namespace - 406 - API version not supported Request and response do not contain any data **List resource locks**:: GET /v2/resource-locks?{queries} Queries will allow filtering with exact and inexact (""created_since"", ""created_before"") attributes. Querying with ""project_id"" or ""all_projects"" will only be allowed for a user with ""admin"" role per default RBAC policy. Normal http response code(s): - 200 - List of locks in project namespace Expected http error code(s): - 401 - Unauthorized; user has not authenticated - 403 - Forbidden; user is forbidden by policy - 404 - API does not exist in microversion - 406 - API version not supported Response example:: { 'resource_locks': [ { 'id': 'be0871e8-742e-4c19-8567-7016fa0e2235', 'user_id': 'cec1dd3e297b45348228f4fc3f5dba38', 'project_id': '2e47ac4e2cf04a5b8b8509de8177d65d', 'resource_action': 'delete', 'resource_type': 'share', 'resource_id': 'a448e0d2-7501-4b99-a447-1b89e3961e39', 'lock_reason': 'share will be used by audit team until 2024' }, { 'id': '4945b04e-cdda-4308-9cfd-1483e7f9dd8c', 'user_id': '80b789450540431db23575b333059ca8', 'project_id': '2e47ac4e2cf04a5b8b8509de8177d65d', 'resource_action': 'shrink', 'resource_type': 'share', 'resource_id': '4227fbd2-7f55-4ff4-9239-2cfc700d9fdf', 'lock_reason': 'space is reserved for in place snapshots' } ] } **Show lock**:: GET /v2/resource-locks/{id} Normal http response code(s): - 200 - Details of a lock in the project namespace Expected http error code(s): - 401 - Unauthorized; user has not authenticated - 403 - Forbidden; user is forbidden by policy - 404 - API does not exist in micro version - 404 - lock does not exist in project namespace - 406 - API version not supported Response example:: { 'resource_lock': { 'id': 'be0871e8-742e-4c19-8567-7016fa0e2235', 'user_id': 'cec1dd3e297b45348228f4fc3f5dba38', 'project_id': '2e47ac4e2cf04a5b8b8509de8177d65d', 'resource_action': 'delete', 'resource_type': 'share', 'resource_id': 'a448e0d2-7501-4b99-a447-1b89e3961e39', 'lock_reason': 'share will be used by audit team until 2024', 'created_at': '2023-04-28T09:49:58.231919', 'updated_at': '2023-04-28T20:01:13.12106' } } **Deleting a share that has locks**:: DELETE /v2/shares/{id} Normal http response code(s): - 202 - No locks exist and all other pre-conditions allow, accepted Expected http error code(s): - 401 - Unauthorized; user has not authenticated - 403 - Forbidden; user is forbidden by policy - 404 - API does not exist in microversion - 404 - share does not exist in project namespace - 409 - share deletion precondition failed, perhaps there's a lock - 406 - API version not supported **New RBAC policies will be introduced:** .. code-block:: python """"""Policy defaults that are used in specific policies below:"""""" RULE_ADMIN = ""role:admin"" PROJECT_MEMBER = ""rule:project-member"" PROJECT_READER = ""rule:project-reader"" PROJECT_OWNER_USER = ""rule:project-owner-user"" ADMIN_OR_PROJECT_MEMBER = f'({RULE_ADMIN}) or ({PROJECT_MEMBER})' ADMIN_OR_PROJECT_READER = f'({RULE_ADMIN}) or ({PROJECT_READER})' ADMIN_OR_PROJECT_OWNER_USER = f'({RULE_ADMIN}) or ({PROJECT_OWNER_USER})' rules = [ policy.RuleDefault( name='project-member', check_str='role:member and ' 'project_id:%(project_id)s', description='Project scoped Member', scope_types=['project']), policy.RuleDefault( name='project-reader', check_str='role:reader and ' 'project_id:%(project_id)s', description='Project scoped Reader', scope_types=['project']), policy.RuleDefault( name='project-owner-user', check_str='role:member and ' 'project_id:%(project_id)s and ' 'user_id:%(user_id)s', description='Project scoped Member who owns a resource', scope_types=['project']), ] * Create a lock .. code-block:: python policy.DocumentedRuleDefault( name= 'resource_locks:create', check_str=ADMIN_OR_PROJECT_MEMBER, scope_types=['project'], description=""Create a resource lock."", operations=[ { 'method': 'POST', 'path': '/resource-locks', }, ], ) * Update a lock .. code-block:: python policy.DocumentedRuleDefault( name= 'resource_locks:update', check_str=ADMIN_OR_PROJECT_OWNER_USER, scope_types=['project'], description=""Update a resource lock."", operations=[ { 'method': 'PUT', 'path': '/resource-locks/{id}', }, ], ) * Delete a lock .. code-block:: python policy.DocumentedRuleDefault( name= 'resource_locks:delete', check_str=ADMIN_OR_PROJECT_OWNER_USER, scope_types=['project'], description=""Delete a resource lock."", operations=[ { 'method': 'DELETE', 'path': '/resource-locks/{id}', }, ], ) * List locks .. code-block:: python policy.DocumentedRuleDefault( name= 'resource_locks:index', check_str=ADMIN_OR_PROJECT_READER, scope_types=['project'], description=""List all resource locks."", operations=[ { 'method': 'GET', 'path': '/resource-locks?{queries}', }, ], ) * List locks with project queries .. code-block:: python policy.DocumentedRuleDefault( name= 'resource_locks:get_all_projects', check_str=ADMIN, scope_types=['project'], description=""Create a resource lock."", operations=[ { 'method': 'GET', 'path': '/resource-locks?all_projects=1&project_id={project_id}', }, ], ) * Get lock .. code-block:: python policy.DocumentedRuleDefault( name= 'resource_locks:get', check_str=ADMIN_OR_PROJECT_READER, scope_types=['project'], description=""Get details about a resource lock."", operations=[ { 'method': 'GET', 'path': '/resource-locks/{id}', }, ], ) Driver impact ------------- None. This is an API only feature. Security impact --------------- Default RBAC policies will allow users with ""admin"" role to create, view or delete user locks. The ""admin"" role is presumed to be given to the operator user. If a lock must be created on behalf of the user by a service or an application, it is advised that the service or application is configured with a user that has the ""service"" role and not ""admin"". No further security impact, positive or negative is noted. Notifications impact -------------------- ""lock.create"" and ""lock.delete"" notification events will be emitted for the respective actions. Other end user impact --------------------- User Interface improvements will be introduced in OpenStackClient (``python-manilaclient`` plugin) and the OpenStack Dashboard (``manila-ui`` plugin). The OpenStackClient addition will be accompanied by ``manilaclient`` and ``openstacksdk`` interfaces: * Create a resource lock: .. code-block:: bash openstack share lock create <resource_id> <resource_action> \ [--resource-type <resource_type>] \ [--reason <lock_reason>}] * Update a resource lock: .. code-block:: bash openstack share lock update <id> \ [--resource-action <resource_action>] \ [--reason <lock_reason>}] * Delete a resource lock: .. code-block:: bash openstack share lock delete <id> * List resource locks: .. code-block:: bash openstack share lock list * Show a resource lock: .. code-block:: bash openstack share lock show <id> Performance Impact ------------------ As we're introducing a new pre-condition on share deletion, the share delete API will suffer performance degradation due to the additional lookup. It's not possible to avoid this lookup even when locks are not used in the environment. We'll optimize the query by using appropriate indices. In the future, as more resources and resource actions use this approach, we will be impacting the existing performance of these APIs. It's a trade-off for the feature functionality. Other deployer impact --------------------- None. Developer impact ---------------- Consider allowing locks via this interface when defining or manipulating actions. Implementation ============== Assignee(s) ----------- Primary assignee: gouthamr Work Items ---------- - Manila API changes - support in manilaclient, openstackclient, manila UI - support in openstacksdk - e2e tests with manila-tempest-plugin - API Reference, user and administrator documentation Dependencies ============ * This feature doesn't depend on work elsewhere, but, the VirtIOFS integration effort in Nova requires this feature. Testing ======= New tests will be added to create locks, list locks, show locks, delete locks. Test cases will cover use of multiple locks and involve validation of request and response schema and codes. RBAC policies will also be tested via tempest. Documentation Impact ==================== API Reference will be updated alongside the API changes. User and administrator documentation will follow alongside the UX changes in respective repositories. References ========== _`[1]` `VirtIOFS Specification <https://specs.openstack .org/openstack/nova-specs/specs/2023.2/approved/libvirt-virtiofs-attach-manila-shares.html>`_ [2] `2023.2 Bobcat PTG Discussion <https://etherpad.opendev .org/p/nova-bobcat-ptg#72>`_ ",,633,2
openstack%2Fcharm-vault~880858,openstack/charm-vault,master,I240ebb4bd14932a6bf95f41da3f2cd7776742266,Improve snap channel refresh mechanism,MERGED,2023-04-19 15:12:51.000000000,2023-07-06 13:08:24.000000000,2023-07-06 13:08:24.000000000,"[{'_account_id': 20648}, {'_account_id': 20870}, {'_account_id': 22348}]","[{'number': 1, 'created': '2023-04-19 15:12:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-vault/commit/883c241a5350622be13d01629fb8905027019abb', 'message': 'Blocked unit if vault snap channel changed\n\n- blocked unit, when snap channel changed\n- add refresh-snap-channel action to proceed snap refresh\n\nChange-Id: I240ebb4bd14932a6bf95f41da3f2cd7776742266\n'}, {'number': 2, 'created': '2023-04-20 07:50:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-vault/commit/449acc644a2752f6f0491dce8d6d48558a9798b4', 'message': 'Blocked unit if vault snap channel changed\n\n- blocked unit, when snap channel changed\n- add refresh-snap-channel action to proceed snap refresh\n\nRelated-Bug: 2007587\nChange-Id: I240ebb4bd14932a6bf95f41da3f2cd7776742266\n'}, {'number': 3, 'created': '2023-06-14 11:00:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-vault/commit/556c11fe40c5e3366c4c7924eb77add00f3711b0', 'message': 'Improve snap channel refresh mechanism\n\n- stop vault.service before refresing it\n- added a warning note that changing the channel config option will\n  cause the vault to be sealed\n\nRelated-Bug: 2007587\nChange-Id: I240ebb4bd14932a6bf95f41da3f2cd7776742266\n'}, {'number': 4, 'created': '2023-06-22 15:13:43.000000000', 'files': ['src/config.yaml', 'unit_tests/test_reactive_vault_handlers.py', 'src/reactive/vault_handlers.py'], 'web_link': 'https://opendev.org/openstack/charm-vault/commit/9e927889d0e29de919816c315b2c6f5643f53049', 'message': 'Improve snap channel refresh mechanism\n\n- stop vault.service before refresing it\n- added a warning note that changing the channel config option will\n  cause the vault to be sealed\n\nRelated-Bug: 2007587\nChange-Id: I240ebb4bd14932a6bf95f41da3f2cd7776742266\n'}]",12,880858,9e927889d0e29de919816c315b2c6f5643f53049,24,3,4,32363,,,0,"Improve snap channel refresh mechanism

- stop vault.service before refresing it
- added a warning note that changing the channel config option will
  cause the vault to be sealed

Related-Bug: 2007587
Change-Id: I240ebb4bd14932a6bf95f41da3f2cd7776742266
",git fetch https://review.opendev.org/openstack/charm-vault refs/changes/58/880858/1 && git format-patch -1 --stdout FETCH_HEAD,"['src/README.md', 'src/config.yaml', 'unit_tests/test_reactive_vault_handlers.py', 'src/actions.yaml', 'src/actions/refresh-snap-channel', 'src/actions/actions.py', 'src/reactive/vault_handlers.py']",7,883c241a5350622be13d01629fb8905027019abb,lp2007587," if snap.get_installed_channel(""vault"") != channel: set_flag(""snap.channel.refresh"") if is_flag_set(""snap.channel.refresh""): status_set( ""blocked"", ""The snap channel must be refreshed manually to {} channel with "" ""the refresh-snap-channel action."".format(config(""channel"")), ) return"," service_restart, snap.refresh('vault', channel=channel) if vault.can_restart(): log(""Restarting vault"", level=DEBUG) service_restart('vault') if config('totally-unsecure-auto-unlock'): vault.prepare_vault()",56,26
openstack%2Fcinder~887578,openstack/cinder,master,I06fb186ce14121d00f82da456ca381f9cbc9484a,Tatlin unified driver - rename tatlin_api object,ABANDONED,2023-07-04 08:35:06.000000000,2023-07-06 13:00:07.000000000,,[],"[{'number': 1, 'created': '2023-07-04 08:35:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/ebed875f4f0926d55e2d35df2849f168975595ba', 'message': 'Tatlin unified driver - rename tatlin_api object\n\nIn Tatlin Unified driver client object is incorrectly called\ntatlin_api. TatlinAPI is a different type and does not have\nTatlin*Client methods. Renamed to tatlin_client.\n\nPartially Implements: blueprint yadro-tatlin-unified-refactoring\nChange-Id: I10135877889a17c6ae6274f8be1b992294bf65d3\n\nChange-Id: I06fb186ce14121d00f82da456ca381f9cbc9484a\n'}, {'number': 2, 'created': '2023-07-04 08:50:16.000000000', 'files': ['cinder/volume/drivers/yadro/tatlin_iscsi.py', 'cinder/tests/unit/volume/drivers/yadro/test_tatlin_common.py', 'cinder/volume/drivers/yadro/tatlin_common.py'], 'web_link': 'https://opendev.org/openstack/cinder/commit/253bb25a37a5e306089fe2aa426f610ebf8c81b6', 'message': 'Tatlin unified driver - rename tatlin_api object\n\nIn Tatlin Unified driver client object is incorrectly called\ntatlin_api. TatlinAPI is a different type and does not have\nTatlin*Client methods. Renamed to tatlin_client.\n\nPartially Implements: blueprint yadro-tatlin-unified-refactoring\nChange-Id: I10135877889a17c6ae6274f8be1b992294bf65d3\n\nChange-Id: I06fb186ce14121d00f82da456ca381f9cbc9484a\n'}]",0,887578,253bb25a37a5e306089fe2aa426f610ebf8c81b6,11,0,2,13671,,,0,"Tatlin unified driver - rename tatlin_api object

In Tatlin Unified driver client object is incorrectly called
tatlin_api. TatlinAPI is a different type and does not have
Tatlin*Client methods. Renamed to tatlin_client.

Partially Implements: blueprint yadro-tatlin-unified-refactoring
Change-Id: I10135877889a17c6ae6274f8be1b992294bf65d3

Change-Id: I06fb186ce14121d00f82da456ca381f9cbc9484a
",git fetch https://review.opendev.org/openstack/cinder refs/changes/78/887578/1 && git format-patch -1 --stdout FETCH_HEAD,"['cinder/volume/drivers/yadro/tatlin_iscsi.py', 'cinder/tests/unit/volume/drivers/yadro/test_tatlin_common.py', 'cinder/volume/drivers/yadro/tatlin_common.py']",3,ebed875f4f0926d55e2d35df2849f168975595ba,," self.tatlin_client = self._get_tatlin_client() self.tatlin_client.get_resource_count(self.pool_id) LOG.debug('Current pool %(pool)s has %(pool_res)s resourses. ' if pool_res_count >= self._max_pool_resource_count: message = _('Create volume failed. ' 'Too many resources per pool: ' % pool_res_count) if cluster_res_count >= self.MAX_ALLOWED_RESOURCES: message = _('Create volume failed. ' 'Too many resources per cluster: ' % cluster_res_count) self.tatlin_client.create_volume(volume.name_id, name, size, self.pool_id, lbaFormat=self._lba_format) if self.tatlin_client.is_volume_ready(volume.name_id): if (self.tatlin_client.get_volume_status(volume.name_id) == 'online'): if not self.tatlin_client.is_volume_exists(volume.name_id): self.tatlin_client.delete_volume(volume.name_id) if not self.tatlin_client.is_volume_exists(volume.name_id): if self.tatlin_client.is_volume_exists(volume.name_id): self.tatlin_client.extend_volume(volume.name_id, size) self.tatlin_client.update_qos( pool_stat = self.tatlin_client.get_pool_detail(self.pool_id) sys_stat = self.tatlin_client.get_sys_statistic() self.tatlin_client.get_resource_count(self.pool_id) result = self.tatlin_client.get_volume_info(source_name) result = self.tatlin_client.get_volume_info(source_name) self.tatlin_client.add_vol_to_host(volume.name_id, host_id) self.tatlin_client.remove_vol_from_host(volume.name_id, host_id) cur_ports = self.tatlin_client.get_resource_ports_array(volume_id) result = self.tatlin_client.get_resource_mapping() self.tatlin_client.export_volume(volume.name_id, ports) self._pool_id = self.tatlin_client.get_pool_id_by_name("," self.tatlin_api = self._get_tatlin_client() self.tatlin_api.get_resource_count(self.pool_id) LOG.debug('Current pool %(pool)s has %(pool_res)s res.' if pool_res_count > 255: message = _('TatlinVolumeDriver create volume failed. ' 'Too many resources per pool created') if cluster_res_count + 1 > self.MAX_ALLOWED_RESOURCES: message = _('TatlinVolumeDriver create volume failed. ' 'Too many resources per cluster created') self.tatlin_api.create_volume(volume.name_id, name, size, self.pool_id, lbaFormat=self._lba_format) if self.tatlin_api.is_volume_ready(volume.name_id): if self.tatlin_api.get_volume_status(volume.name_id) == 'online': if not self.tatlin_api.is_volume_exists(volume.name_id): self.tatlin_api.delete_volume(volume.name_id) if not self.tatlin_api.is_volume_exists(volume.name_id): if self.tatlin_api.is_volume_exists(volume.name_id): self.tatlin_api.extend_volume(volume.name_id, size) self.tatlin_api.update_qos( pool_stat = self.tatlin_api.get_pool_detail(self.pool_id) sys_stat = self.tatlin_api.get_sys_statistic() self.tatlin_api.get_resource_count(self.pool_id) result = self.tatlin_api.get_volume_info(source_name) result = self.tatlin_api.get_volume_info(source_name) self.tatlin_api.add_vol_to_host(volume.name_id, host_id) self.tatlin_api.remove_vol_from_host(volume.name_id, host_id) cur_ports = self.tatlin_api.get_resource_ports_array(volume_id) result = self.tatlin_api.get_resource_mapping() self.tatlin_api.export_volume(volume.name_id, ports) self._pool_id = self.tatlin_api.get_pool_id_by_name(",47,46
openstack%2Fbifrost~887783,openstack/bifrost,stable/2023.1,I208182e65884d63548d78c68f676b899c562a2dc,CI: Update cached cirros image to 0.5.3,MERGED,2023-07-06 09:49:34.000000000,2023-07-06 12:52:17.000000000,2023-07-06 12:51:15.000000000,"[{'_account_id': 22348}, {'_account_id': 23851}]","[{'number': 1, 'created': '2023-07-06 09:49:34.000000000', 'files': ['playbooks/test-bifrost.yaml'], 'web_link': 'https://opendev.org/openstack/bifrost/commit/eef2efb704985c86d313591024890f205ebda2d6', 'message': ""CI: Update cached cirros image to 0.5.3\n\nBifrost CI is currently failing to fetch the cirros image from cache:\n\n    No such file or directory: '/opt/cache/files/cirros-0.5.1-x86_64-disk.img'\n\nThis may be caused by the removal of cirros-0.5.1 images from cache in\nchange Ibada405e0c1183559f428c749d0e54d0a45a2223.\n\nSwitch to cirros version 0.5.3 image instead.\n\nChange-Id: I208182e65884d63548d78c68f676b899c562a2dc\n""}]",0,887783,eef2efb704985c86d313591024890f205ebda2d6,7,2,1,10239,,,0,"CI: Update cached cirros image to 0.5.3

Bifrost CI is currently failing to fetch the cirros image from cache:

    No such file or directory: '/opt/cache/files/cirros-0.5.1-x86_64-disk.img'

This may be caused by the removal of cirros-0.5.1 images from cache in
change Ibada405e0c1183559f428c749d0e54d0a45a2223.

Switch to cirros version 0.5.3 image instead.

Change-Id: I208182e65884d63548d78c68f676b899c562a2dc
",git fetch https://review.opendev.org/openstack/bifrost refs/changes/83/887783/1 && git format-patch -1 --stdout FETCH_HEAD,['playbooks/test-bifrost.yaml'],1,eef2efb704985c86d313591024890f205ebda2d6,, cirros_deploy_image_upstream_url: file:///opt/cache/files/cirros-0.5.3-x86_64-disk.img, cirros_deploy_image_upstream_url: file:///opt/cache/files/cirros-0.5.1-x86_64-disk.img,1,1
openstack%2Fnetworking-odl~887076,openstack/networking-odl,stable/ussuri,I5a099d5934872b29274944f4941c8348f7d90160,[stable-only] Remove the periodic stable jobs,ABANDONED,2023-06-27 15:53:56.000000000,2023-07-06 12:45:26.000000000,,[{'_account_id': 22348}],"[{'number': 1, 'created': '2023-06-27 15:53:56.000000000', 'files': ['.zuul.d/project.yaml'], 'web_link': 'https://opendev.org/openstack/networking-odl/commit/df20889a8126d50d17ae6fd41fcf02154550f4fb', 'message': '[stable-only] Remove the periodic stable jobs\n\nThis project has been deprecated and there is no need to consume\nCI resources periodically.\n\nChange-Id: I5a099d5934872b29274944f4941c8348f7d90160\n'}]",2,887076,df20889a8126d50d17ae6fd41fcf02154550f4fb,5,1,1,16688,,,0,"[stable-only] Remove the periodic stable jobs

This project has been deprecated and there is no need to consume
CI resources periodically.

Change-Id: I5a099d5934872b29274944f4941c8348f7d90160
",git fetch https://review.opendev.org/openstack/networking-odl refs/changes/76/887076/1 && git format-patch -1 --stdout FETCH_HEAD,['.zuul.d/project.yaml'],1,df20889a8126d50d17ae6fd41fcf02154550f4fb,remove_periodic_jobs,, - periodic-stable-jobs-neutron,0,1
openstack%2Fnova-specs~887011,openstack/nova-specs,master,Ie796abd247a9231d1e126a589f03a81696960b26,Re-propose spec for ephemeral storage encryption,MERGED,2023-06-26 23:00:10.000000000,2023-07-06 12:41:09.000000000,2023-07-06 12:39:56.000000000,"[{'_account_id': 7166}, {'_account_id': 11604}, {'_account_id': 22348}]","[{'number': 1, 'created': '2023-06-26 23:00:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/b2a3c3495a3a188b79f17c8173ea1b24d5ef7bdd', 'message': 'Re-propose spec for ephemeral storage encryption\n\nPreviously-approved: 2023.1, Zed, Yoga, Xena, Wallaby\n\nThe spec has been updated to reflect a change needed in the\nimplementation to support snapshot and shelve for ephemeral encrypted\ninstances. The encryption secret is needed in order to boot a new\ninstance from a snapshot of an ephemeral encrypted instance and to\nunshelve an ephemeral encrypted instance. So, the spec is updated to\npropose an additional flavor extra spec or image property to keep the\nencryption secret UUID from the key manager.\n\nRelated to blueprint ephemeral-storage-encryption\n\nChange-Id: Ie796abd247a9231d1e126a589f03a81696960b26\n'}, {'number': 2, 'created': '2023-06-27 09:15:29.000000000', 'files': ['specs/2023.2/approved/ephemeral-storage-encryption.rst'], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/ea0cf9579f16c93d23c4e7210a6bc3d8ec87792d', 'message': 'Re-propose spec for ephemeral storage encryption\n\nPreviously-approved: 2023.1, Zed, Yoga, Xena, Wallaby\n\nThe spec has been updated to reflect a change needed in the\nimplementation to support snapshot and shelve for ephemeral encrypted\ninstances. The encryption secret is needed in order to boot a new\ninstance from a snapshot of an ephemeral encrypted instance and to\nunshelve an ephemeral encrypted instance. So, the spec is updated to\npropose an additional flavor extra spec or image property to keep the\nencryption secret UUID from the key manager.\n\nRelated to blueprint ephemeral-storage-encryption\n\n\nChange-Id: Ie796abd247a9231d1e126a589f03a81696960b26\n'}]",10,887011,ea0cf9579f16c93d23c4e7210a6bc3d8ec87792d,16,3,2,4690,,,0,"Re-propose spec for ephemeral storage encryption

Previously-approved: 2023.1, Zed, Yoga, Xena, Wallaby

The spec has been updated to reflect a change needed in the
implementation to support snapshot and shelve for ephemeral encrypted
instances. The encryption secret is needed in order to boot a new
instance from a snapshot of an ephemeral encrypted instance and to
unshelve an ephemeral encrypted instance. So, the spec is updated to
propose an additional flavor extra spec or image property to keep the
encryption secret UUID from the key manager.

Related to blueprint ephemeral-storage-encryption


Change-Id: Ie796abd247a9231d1e126a589f03a81696960b26
",git fetch https://review.opendev.org/openstack/nova-specs refs/changes/11/887011/1 && git format-patch -1 --stdout FETCH_HEAD,['specs/2023.2/approved/ephemeral-storage-encryption.rst'],1,b2a3c3495a3a188b79f17c8173ea1b24d5ef7bdd,bp/ephemeral-storage-encryption,".. This work is licensed under a Creative Commons Attribution 3.0 Unported License. http://creativecommons.org/licenses/by/3.0/legalcode ====================================================== Flavour and Image defined ephemeral storage encryption ====================================================== https://blueprints.launchpad.net/nova/+spec/ephemeral-storage-encryption This spec outlines a new approach to ephemeral storage encryption in Nova allowing users to select how their ephemeral storage is encrypted at rest through the use of flavors with specific extra specs or images with specific properties. The aim being to bring the ephemeral storage encryption experience within Nova in line with the block storage encryption implementation provided by Cinder where user selectable `encrypted volume types`_ are available. .. note:: This spec will only cover the high level changes to the API and compute layers, implementation within specific virt drivers is left for separate specs. Problem description =================== At present the only in-tree ephemeral storage encryption support is provided by the libvirt virt driver when using the lvm imagebackend. The current implementation provides basic operator controlled and configured host specific support for ephemeral disk encryption at rest where all instances on a given compute are forced to use encrypted ephemeral storage using the dm-crypt ``PLAIN`` encryption format. This is not ideal and makes ephemeral storage encryption completely opaque to the end user as opposed to the block storage encryption support provided by Cinder where users are able to opt-in to using admin defined encrypted volume types to ensure their storage is encrypted at rest. Additionally the current implementation uses a single symmetric key to encrypt all ephemeral storage associated with the instance. As the ``PLAIN`` encryption format is used there is no way to rotate this key in-place. Use Cases --------- * As a user I want to request that all of my ephemeral storage is encrypted at rest through the selection of a specific flavor or image. * As a user I want to be able to pick how my ephemeral storage is encrypted at rest through the selection of a specific flavor or image. * As an admin/operator I want to either enforce ephemeral encryption per flavor or per image. * As an admin/operator I want to provide sane choices to my end users regarding how their ephemeral storage is encrypted at rest. * As a virt driver maintainer/developer I want to indicate that my driver supports ephemeral storage encryption using a specific encryption format. * As a virt driver maintainer/developer I want to provide sane default encryption format and options for users looking to encrypt their ephemeral storage at rest. I want these associated with the encrypted storage until it is deleted. Proposed change =============== To enable this new flavor extra specs, image properties and host configurables will be introduced. These will control when and how ephemeral storage encryption at rest is enabled for an instance. .. note:: The following ``hw_ephemeral_encryption`` image properties do not relate to if an image is encrypted at rest within the Glance service. They only relate to how ephemeral storage will be encrypted at rest when used by a provisioned instance within Nova. Separate image properties have been documented in the `Glance image encryption`_ and `Cinder image encryption`_ specs to cover how images can be encrypted at rest within Glance. Allow ephemeral encryption to be configured by flavor, image or config ---------------------------------------------------------------------- To enable ephemeral encryption per instance the following boolean based flavor extra spec and image property will be introduced: * ``hw:ephemeral_encryption`` * ``hw_ephemeral_encryption`` The above will enable ephemeral storage encryption for an instance but does not control the encryption format used or the associated options. For this the following flavor extra specs, image properties and configurables will be introduced. The encryption format used will be controlled by the following flavor extra specs and image properties: * ``hw:ephemeral_encryption_format`` * ``hw_ephemeral_encryption_format`` When neither of the above are provided but ephemeral encryption is still requested an additional host configurable will be used to provide a default format per compute, this will initially default to ``luks``: * ``[ephemeral_storage_encryption]/default_format`` This could lead to requests against different clouds resulting in a different ephemeral encryption format being used but as this is transparent to the end user from within the instance it shouldn't have any real impact. The format will be provided as a string that maps to a ``BlockDeviceEncryptionFormatTypeField`` oslo.versionedobjects field value: * ``plain`` for the plain dm-crypt format * ``luks`` for the LUKSv1 format To enable snapshot and shelve of instances using ephemeral encryption, the UUID of the encryption security stored in the key manager for the resultant image will be kept with the image as a flavor extra spec or image property: * ``hw:ephemeral_encryption_secret_uuid`` * ``hw_ephemeral_encryption_secret_uuid`` The secret UUID is needed when creating an instance from an ephemeral encrypted snapshot or when unshelving an ephemeral encrypted instance. BlockDeviceMapping changes -------------------------- The ``BlockDeviceMapping`` object will be extended to include the following fields encapsulating some of the above information per ephemeral disk within the instance: ``encrypted`` A simple boolean to indicate if the block device is encrypted. This will initially only be populated when ephemeral encryption is used but could easily be used for encrypted volumes as well in the future. ``encryption_secret_uuid`` As the name suggests this will contain the UUID of the associated encryption secret for the disk. The type of secret used here will be specific to the encryption format and virt driver used, it should not be assumed that this will always been an symmetric key as is currently the case with all encrypted volumes provided by Cinder. For example, for ``luks`` based ephemeral storage this secret will be a ``passphrase``. ``encryption_format`` A new ``BlockDeviceEncryptionFormatType`` enum and associated ``BlockDeviceEncryptionFormatTypeField`` field listing the encryption format. The available options being kept in line with the constants currently provided by os-brick and potentially merged in the future if both can share these types and fields somehow. ``encryption_options`` A simple unversioned dict of strings containing encryption options specific to the virt driver implementation, underlying hypervisor and format being used. .. note:: The ``encryption_options`` field will be unused and not exposed to end users initially because of the security and upgrade implications around it. For the first pass, sensible defaults for the cipher algorithm, cipher mode, and initialization vector generator algorithm will be hard-coded instead. Encryption options could be exposed to end users in the future when a proper design which addresses security and handles all upgrade scenarios is developed. Populate ephemeral encryption BlockDeviceMapping attributes during build ------------------------------------------------------------------------ When launching an instance with ephemeral encryption requested via either the image or flavor the ``BlockDeviceMapping.encrypted`` attribute will be set to ``True`` for each ``BlockDeviceMapping`` record with a ``destination_type`` value of ``local``. This will happen after the original API BDM dicts have been transformed into objects within the Compute API but before scheduling the instance(s). The ``encryption_format`` attribute will also take its' value from the image or flavor if provided. Any differences or conflicts between the image and flavor for this will raise a ``409 Conflict`` error being raised by the API. Use ``COMPUTE_EPHEMERAL_ENCRYPTION`` compatibility traits --------------------------------------------------------- A ``COMPUTE_EPHEMERAL_ENCRYPTION`` compute compatibility trait was introduced during `Wallaby`__ and will be reported by virt drivers to indicate overall support for ephemeral storage encryption using this new approach. This trait will always be used by pre-filter outlined in the following section when ephemeral encryption has been requested, regardless of any format being specified in the request, allowing the compute that eventually handles the request to select a format it supports using the ``[ephemeral_storage_encryption]/default_format`` configurable. .. __: https://review.opendev.org/c/openstack/os-traits/+/759878 ``COMPUTE_EPHEMERAL_ENCRYPTION_$FORMAT`` compute compatibility traits were also added to os-traits during Wallaby and will be reported by virt drivers to indicate support for specific ephemeral storage encryption formats. For example: * ``COMPUTE_EPHEMERAL_ENCRYPTION_LUKS`` * ``COMPUTE_EPHEMERAL_ENCRYPTION_LUKSV2`` * ``COMPUTE_EPHEMERAL_ENCRYPTION_PLAIN`` These traits will only be used alongside the ``COMPUTE_EPHEMERAL_ENCRYPTION`` trait when the ``hw_ephemeral_encryption_format`` image property or ``hw:ephemeral_encryption_format`` extra spec have been provided in the initial request. Introduce an ephemeral encryption request pre-filter ---------------------------------------------------- A new pre-filter will be introduced that adds the above traits as required to the request spec when the aforementioned image properties or flavor extra specs are provided. As outlined above this will always include the ``COMPUTE_EPHEMERAL_ENCRYPTION`` trait when ephemeral encryption has been requested and may optionally include one of the format specific traits if a format is included in the request. Expose ephemeral encryption attributes via block_device_info ------------------------------------------------------------ Once the ``BlockDeviceMapping`` objects have been updated and the instance scheduled to a compute the objects are transformed once again into a ``block_device_info`` dict understood by the virt layer that at present contains the following: ``root_device_name`` The root device path used by the instance. ``ephemerals`` A list of ``DriverEphemeralBlockDevice`` dict objects detailing the ephemeral disks attached to the instance. Note this does not include the initial image based disk used by the instance that is classified as an ephemeral disk in terms of the ephemeral encryption feature. ``block_device_mapping`` A list of ``DriverVol*BlockDevice`` dict objects detailing the volume based disks attached to the instance. ``swap`` An optional ``DriverSwapBlockDevice`` dict object detailing the swap device. For example: .. code-block:: json { ""root_device_name"": ""/dev/vda"", ""ephemerals"": [ { ""guest_format"": null, ""device_name"": ""/dev/vdb"", ""device_type"": ""disk"", ""size"": 1, ""disk_bus"": ""virtio"" } ], ""block_device_mapping"": [], ""swap"": { ""swap_size"": 1, ""device_name"": ""/dev/vdc"", ""disk_bus"": ""virtio"" } } As noted above ``block_device_info`` does not provide a complete overview of the storage associated with an instance. In order for it to be useful in the context of ephemeral storage encryption we would need to extend the dict to always include information relating to local image based disks. As such a new ``DriverImageBlockDevice`` dict class will be introduced covering image based block devices and provided to the virt layer via an additional ``image`` key within the ``block_device_info`` dict when the instance uses such a disk. As with the other ``Driver*BlockDevice`` dict classes this will proxy access to the underlying ``BlockDeviceMapping`` object allowing the virt layer to lookup the previously listed ``encrypted`` and ``encryption_*`` attributes. While outside the scope of this spec the above highlights a huge amount of complexity and technical debt still residing in the codebase around how storage configurations are handled between the different layers. In the long term we should plan to remove ``block_device_info`` and replace it with direct access to ``BlockDeviceMapping`` based objects ensuring the entire configuration is always exposed to the virt layer. Report that a disk is encrypted at rest through the metadata API ---------------------------------------------------------------- Extend the metadata API so that users can confirm that their ephemeral storage is encrypted at rest through the metadata API, accessible from within their instance. .. code-block:: json { ""devices"": [ { ""type"": ""nic"", ""bus"": ""pci"", ""address"": ""0000:00:02.0"", ""mac"": ""00:11:22:33:44:55"", ""tags"": [""trusted""] }, { ""type"": ""disk"", ""bus"": ""virtio"", ""address"": ""0:0"", ""serial"": ""12352423"", ""path"": ""/dev/vda"", ""encrypted"": ""True"" }, { ""type"": ""disk"", ""bus"": ""ide"", ""address"": ""0:0"", ""serial"": ""disk-vol-2352423"", ""path"": ""/dev/sda"", ""tags"": [""baz""] } ] } This should also be extended to cover disks provided by encrypted volumes but this is obviously out of scope for this implementation. Block resize between flavors with different hw:ephemeral_encryption settings ---------------------------------------------------------------------------- Ephemeral data is expected to persist through a resize and as such any resize between flavors that differed in their configuration of ephemeral encryption (one enabled, another disabled or formats etc) would cause us to convert this data in place. This isn't trivial and so for this initial implementation resizing between flavors that differ will be blocked. Provide a migration path from the legacy implementation ------------------------------------------------------- New ``nova-manage`` and ``nova-status`` commands will be introduced to migrate any instances using the legacy libvirt virt driver implementation ahead of the removal of this in a future release. The ``nova-manage`` command will ensure that any existing instances with ``ephemeral_key_uuid`` set will have their associated ``BlockDeviceMapping`` records updated to reference said secret key, the ``plain`` encryption format and configured options on the host before clearing ``ephemeral_key_uuid``. Additionally the libvirt virt driver will also attempt to migrate instances with ``ephemeral_key_uuid`` set during spawn. This should allow at least some of the instances to be moved during the W release ahead of X. The ``nova-status`` command will simply report on the existence of any instances with ``ephemeral_key_uuid`` set that do not have the corresponding ``BlockDeviceMapping`` attributes enabled etc. Deprecate the now legacy implementation --------------------------------------- The legacy implementation within the libvirt virt driver will be deprecated for removal in a future release once the ability to migrate is in place. Alternatives ------------ Continue to use the transparent host configurables and expand support to other encryption formats such as ``LUKS``. Data model impact ----------------- See above for the various flavor extra spec, image property, ``BlockDeviceMapping`` and ``DriverBlockDevice`` object changes. REST API impact --------------- * Flavor extra specs and image property validation will be introduced for the any ephemeral encryption provided options. * Attempts to resize between flavors that differ in their ephemeral encryption options will be rejected. * Attempts to rebuild between images that differ in their ephemeral encryption options will be allowed. * The metadata API will be changed to allow users to determine if their ephemeral storage is encrypted as discussed above. Security impact --------------- This should hopefully be positive given the unique secret per disk and user visible choice regarding how their ephemeral storage is encrypted at rest. Additionally this should allow additional virt drivers to support ephemeral storage encryption while also allowing the libvirt virt driver to increase coverage of the feature across more imagebackends such as qcow2 and rbd. .. note:: Internal base images stored locally in Nova will not be encrypted at rest. Notifications impact -------------------- N/A Other end user impact --------------------- Users will now need to opt-in to ephemeral storage encryption being used by their instances through their choice of image or flavors. Performance Impact ------------------ The additional pre-filter will add a small amount of overhead when scheduling instances but this should fail fast if ephemeral encryption is not requested through the image or flavor. The performance impact of increased use of ephemeral storage encryption by instances is left to be discussed in the virt driver specific specs as this will vary between hypervisors. Other deployer impact --------------------- N/A Developer impact ---------------- Virt driver developers will be able to indicate support for specific ephemeral storage encryption formats using the newly introduced compute compatibility traits. Upgrade impact -------------- The compute traits should ensure that requests to schedule instances using ephemeral storage encryption with mixed computes (N-1 and N) will work during a rolling upgrade. As discussed earlier in the spec future upgrades will need to provide a path for existing ephemeral storage encryption users to migrate from the legacy implementation. This should be trivial but may require an additional grenade based job in CI during the W cycle to prove out the migration path. Implementation ============== Assignee(s) ----------- Primary assignee: melwitt Other contributors: lyarwood Feature Liaison --------------- Feature liaison: melwitt Work Items ---------- * Introduce ``hw_ephemeral_encryption*`` image properties and ``hw:ephemeral_encryption`` flavor extra specs. * Introduce a new ``encrypted``. ``encryption_secret_uuid``, ``encryption_format`` and ``encryption_options`` attributes to the BlockDeviceMapping Object. * Wire up the new ``BlockDeviceMapping`` object attributes through the ``Driver*BlockDevice`` layer and ``block_device_info`` dict. * Report ephemeral storage encryption through the metadata API. * Introduce new ``nova-manage`` and ``nova-status`` commands to allow existing users to migrate to this new implementation. This should however be blocked outside of testing until a virt driver implementation is landed. * Validate all of the above in functional tests ahead of any virt driver implementation landing. Dependencies ============ None Testing ======= At present without a virt driver implementation this will be tested entirely within our unit and functional test suites. Once a virt driver implementation is available additional integration tests in Tempest and whitebox tests can be written. Testing of the migration path from the legacy implementation will require an additional grenade job but this will require the libvirt virt driver implementation to be completed first. Documentation Impact ==================== * The new host configurables, flavor extra specs and image properties should be documented. * New user documentation should be written covering the overall use of the feature from a Nova point of view. * Reference documentation around `BlockDeviceMapping` objects etc should be updated to make note of the new encryption attributes. References ========== .. _`Glance image encryption`: https://specs.openstack.org/openstack/glance-specs/specs/victoria/approved/glance/image-encryption.html .. _`Cinder image encryption`: https://specs.openstack.org/openstack/cinder-specs/specs/wallaby/image-encryption.html .. _`encrypted volume types`: https://docs.openstack.org/cinder/latest/configuration/block-storage/volume-encryption.html#create-an-encrypted-volume-type .. _`libvirt virt driver`: https://libvirt.org/formatstorageencryption.html#StorageEncryptionLuks History ======= Optional section intended to be used each time the spec is updated to describe new design, API or any database schema updated. Useful to let reader understand what's happened along the time. .. list-table:: Revisions :header-rows: 1 * - Release Name - Description * - Wallaby - Introduced * - Xena - Reproposed * - Yoga - Reproposed * - Zed - Reproposed * - 2023.1 Antelope - Reproposed * - 2023.2 Bobcat - Reproposed ",,560,0
openstack%2Fneutron~886277,openstack/neutron,stable/wallaby,Iab77c64c03fd0d44ff7a3fc1c556d85a8c480bb9,Return 409 Conflict to tenant user deleting port attached to FIP,MERGED,2023-06-16 15:07:58.000000000,2023-07-06 12:38:38.000000000,2023-07-06 12:37:18.000000000,"[{'_account_id': 8313}, {'_account_id': 21798}, {'_account_id': 22348}]","[{'number': 1, 'created': '2023-06-16 15:07:58.000000000', 'files': ['neutron/db/l3_db.py', 'neutron/tests/unit/db/test_l3_db.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/0180d797e26415ac112610692f42b2dc9dc6dcb6', 'message': 'Return 409 Conflict to tenant user deleting port attached to FIP\n\nWhen a tenant user try to delete a port that has attached a FIP by\nan admin user is getting a 500 ServerError.\n\nThis patch improves the error to 409 Conflict doing some additionals\nchecks on the delete_port method.\n\nNew exception has been included locally, but will be removed as soon\nneutron-lib bumps to a newer release.\n\nConflicts:\n      neutron/db/l3_db.py\n\nCloses-Bug: 2017680\nChange-Id: Iab77c64c03fd0d44ff7a3fc1c556d85a8c480bb9\n(cherry picked from commit 9f6f6d5082b4341529144e992d5293675146ae88)\n'}]",1,886277,0180d797e26415ac112610692f42b2dc9dc6dcb6,9,3,1,34451,,,0,"Return 409 Conflict to tenant user deleting port attached to FIP

When a tenant user try to delete a port that has attached a FIP by
an admin user is getting a 500 ServerError.

This patch improves the error to 409 Conflict doing some additionals
checks on the delete_port method.

New exception has been included locally, but will be removed as soon
neutron-lib bumps to a newer release.

Conflicts:
      neutron/db/l3_db.py

Closes-Bug: 2017680
Change-Id: Iab77c64c03fd0d44ff7a3fc1c556d85a8c480bb9
(cherry picked from commit 9f6f6d5082b4341529144e992d5293675146ae88)
",git fetch https://review.opendev.org/openstack/neutron refs/changes/77/886277/1 && git format-patch -1 --stdout FETCH_HEAD,"['neutron/db/l3_db.py', 'neutron/tests/unit/db/test_l3_db.py']",2,0180d797e26415ac112610692f42b2dc9dc6dcb6,wallaby," @mock.patch.object(l3_obj.FloatingIP, 'objects_exist') @mock.patch.object(l3_obj.FloatingIP, 'get_objects') def test_disassociate_floatingips_conflict_by_fip_attached(self, get_objects, objects_exist): context_tenant = context.Context('tenant', 'tenant', is_admin=False) objects_exist.return_value = True get_objects.side_effect = [ [], [{'id': 'floating_ip1', 'port_id': 'port_id'}]] self.assertRaises(l3_db.FipAssociated, self.db.disassociate_floatingips, context_tenant, 'port_id') objects_exist.assert_called_once_with( mock.ANY, fixed_port_id='port_id') expected_calls = [ mock.call(context_tenant, fixed_port_id='port_id'), mock.call(mock.ANY, fixed_port_id='port_id')] get_objects.assert_has_calls(expected_calls) ",,47,0
openstack%2Fneutron~886273,openstack/neutron,stable/xena,Iab77c64c03fd0d44ff7a3fc1c556d85a8c480bb9,Return 409 Conflict to tenant user deleting port attached to FIP,MERGED,2023-06-16 15:05:54.000000000,2023-07-06 12:38:33.000000000,2023-07-06 12:37:14.000000000,"[{'_account_id': 8313}, {'_account_id': 21798}, {'_account_id': 22348}]","[{'number': 1, 'created': '2023-06-16 15:05:54.000000000', 'files': ['neutron/db/l3_db.py', 'neutron/tests/unit/db/test_l3_db.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/3e8716e7f5db0955807daadc1c31f6957ae429a6', 'message': 'Return 409 Conflict to tenant user deleting port attached to FIP\n\nWhen a tenant user try to delete a port that has attached a FIP by\nan admin user is getting a 500 ServerError.\n\nThis patch improves the error to 409 Conflict doing some additionals\nchecks on the delete_port method.\n\nNew exception has been included locally, but will be removed as soon\nneutron-lib bumps to a newer release.\n\nCloses-Bug: 2017680\nChange-Id: Iab77c64c03fd0d44ff7a3fc1c556d85a8c480bb9\n(cherry picked from commit 9f6f6d5082b4341529144e992d5293675146ae88)\n'}]",2,886273,3e8716e7f5db0955807daadc1c31f6957ae429a6,12,3,1,34451,,,0,"Return 409 Conflict to tenant user deleting port attached to FIP

When a tenant user try to delete a port that has attached a FIP by
an admin user is getting a 500 ServerError.

This patch improves the error to 409 Conflict doing some additionals
checks on the delete_port method.

New exception has been included locally, but will be removed as soon
neutron-lib bumps to a newer release.

Closes-Bug: 2017680
Change-Id: Iab77c64c03fd0d44ff7a3fc1c556d85a8c480bb9
(cherry picked from commit 9f6f6d5082b4341529144e992d5293675146ae88)
",git fetch https://review.opendev.org/openstack/neutron refs/changes/73/886273/1 && git format-patch -1 --stdout FETCH_HEAD,"['neutron/db/l3_db.py', 'neutron/tests/unit/db/test_l3_db.py']",2,3e8716e7f5db0955807daadc1c31f6957ae429a6,xena," @mock.patch.object(l3_obj.FloatingIP, 'objects_exist') @mock.patch.object(l3_obj.FloatingIP, 'get_objects') def test_disassociate_floatingips_conflict_by_fip_attached(self, get_objects, objects_exist): context_tenant = context.Context('tenant', 'tenant', is_admin=False) objects_exist.return_value = True get_objects.side_effect = [ [], [{'id': 'floating_ip1', 'port_id': 'port_id'}]] self.assertRaises(l3_db.FipAssociated, self.db.disassociate_floatingips, context_tenant, 'port_id') objects_exist.assert_called_once_with( mock.ANY, fixed_port_id='port_id') expected_calls = [ mock.call(context_tenant, fixed_port_id='port_id'), mock.call(mock.ANY, fixed_port_id='port_id')] get_objects.assert_has_calls(expected_calls) ",,44,1
openstack%2Fproject-config~887602,openstack/project-config,master,Ia2c1d54dc9eec429a6b20b5f6cbdcadec46435c2,Add OpenStack K8S charms,MERGED,2023-07-04 13:31:42.000000000,2023-07-06 12:30:54.000000000,2023-07-06 12:19:08.000000000,"[{'_account_id': 935}, {'_account_id': 5263}, {'_account_id': 22348}]","[{'number': 1, 'created': '2023-07-04 13:31:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/project-config/commit/329278e98498fbf4d582650581d782e201437665', 'message': 'Add OpenStack K8S charms\n\nSetup and import OpenStack K8S Charms for deployment of\nheat and barbican hosted in Kubernetes.\n\nRequired-By:\nChange-Id: Ia2c1d54dc9eec429a6b20b5f6cbdcadec46435c2\n'}, {'number': 2, 'created': '2023-07-04 13:32:33.000000000', 'files': ['gerrit/projects.yaml', 'zuul/main.yaml'], 'web_link': 'https://opendev.org/openstack/project-config/commit/766bda25d0e56613d8950ee59c7e635ead8d1a5f', 'message': 'Add OpenStack K8S charms\n\nSetup and import OpenStack K8S Charms for deployment of\nheat and barbican hosted in Kubernetes.\n\nRequired-By: I218144cbe0fef51f3e28cb902c81783138f60905\nChange-Id: Ia2c1d54dc9eec429a6b20b5f6cbdcadec46435c2\n'}]",1,887602,766bda25d0e56613d8950ee59c7e635ead8d1a5f,10,3,2,12549,,,0,"Add OpenStack K8S charms

Setup and import OpenStack K8S Charms for deployment of
heat and barbican hosted in Kubernetes.

Required-By: I218144cbe0fef51f3e28cb902c81783138f60905
Change-Id: Ia2c1d54dc9eec429a6b20b5f6cbdcadec46435c2
",git fetch https://review.opendev.org/openstack/project-config refs/changes/02/887602/1 && git format-patch -1 --stdout FETCH_HEAD,"['gerrit/projects.yaml', 'zuul/main.yaml']",2,329278e98498fbf4d582650581d782e201437665,sunbeam-heat-barbican, - openstack/charm-barbican-k8s - openstack/charm-heat-k8s,,16,0
openstack%2Fneutron~886974,openstack/neutron,master,Ib9ec45d643c6162c526cd5a02db270094b575e34,[OVN][L3] Optimize FIP update operation,MERGED,2023-06-26 10:05:40.000000000,2023-07-06 12:29:31.000000000,2023-07-06 12:28:05.000000000,"[{'_account_id': 1131}, {'_account_id': 5948}, {'_account_id': 6773}, {'_account_id': 9845}, {'_account_id': 11975}, {'_account_id': 15554}, {'_account_id': 22348}, {'_account_id': 32029}]","[{'number': 1, 'created': '2023-06-26 10:05:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/897b09d64113e21862593c524b7205efdf749912', 'message': '[DNM][WIP] == [OVN][FIP] Optimize FIP update\n\nChange-Id: Ib9ec45d643c6162c526cd5a02db270094b575e34\n'}, {'number': 2, 'created': '2023-06-26 10:06:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/01936332479e9dc0b796610649dd4b518cab9f54', 'message': '[DNM][WIP] == [OVN][FIP] Optimize FIP update\n\nChange-Id: Ib9ec45d643c6162c526cd5a02db270094b575e34\n'}, {'number': 3, 'created': '2023-06-27 13:30:31.000000000', 'files': ['neutron/plugins/ml2/drivers/ovn/mech_driver/ovsdb/ovn_client.py', 'neutron/services/ovn_l3/plugin.py', 'neutron/tests/unit/services/ovn_l3/test_plugin.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/7b85f9c244cde25d2dad81f51a0c96a429ddc488', 'message': '[OVN][L3] Optimize FIP update operation\n\nIf the floating IP updates only the QoS policy, the method now\nskips the OVN NAT rules update and updates only the QoS policy.\nThat avoids the OVN NAT rules deletion and creation and the\n``FIPAddDeleteEvent`` event that deletes the MAC binding entries\nfor an active floating IP, causing a disruption.\n\nCloses-Bug: #2025144\n\nChange-Id: Ib9ec45d643c6162c526cd5a02db270094b575e34\n'}]",1,886974,7b85f9c244cde25d2dad81f51a0c96a429ddc488,21,8,3,16688,,,0,"[OVN][L3] Optimize FIP update operation

If the floating IP updates only the QoS policy, the method now
skips the OVN NAT rules update and updates only the QoS policy.
That avoids the OVN NAT rules deletion and creation and the
``FIPAddDeleteEvent`` event that deletes the MAC binding entries
for an active floating IP, causing a disruption.

Closes-Bug: #2025144

Change-Id: Ib9ec45d643c6162c526cd5a02db270094b575e34
",git fetch https://review.opendev.org/openstack/neutron refs/changes/74/886974/1 && git format-patch -1 --stdout FETCH_HEAD,"['neutron/plugins/ml2/drivers/ovn/mech_driver/ovsdb/ovn_client.py', 'neutron/services/ovn_l3/plugin.py']",2,897b09d64113e21862593c524b7205efdf749912,bug/2025144," self._ovn_client.update_floatingip(context, fip, floatingip)"," self._ovn_client.update_floatingip(context, fip)",16,11
openstack%2Fnova-specs~881880,openstack/nova-specs,master,Iea9c017a4f104370e75a3f1e5070c8efa01e30b6,"Re-propose ""Policy service role spec""",MERGED,2023-04-28 18:26:47.000000000,2023-07-06 12:13:54.000000000,2023-07-06 12:12:16.000000000,"[{'_account_id': 7166}, {'_account_id': 11604}, {'_account_id': 22348}, {'_account_id': 32761}]","[{'number': 1, 'created': '2023-04-28 18:26:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/278b0eff1e3cd3052be57729a3c2523bfa133163', 'message': 'Re-propose ""Policy service role spec""\n\nThis spec is to add service role to nova service-to-service\nAPIs policies.\n\nPartial implement blueprint policy-service-role-default\n\nAPIImpact\n\nChange-Id: Iea9c017a4f104370e75a3f1e5070c8efa01e30b6\n'}, {'number': 2, 'created': '2023-06-27 04:33:23.000000000', 'files': ['specs/2023.2/approved/policy-service-role-default.rst'], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/9036a12bc64ac9a369906e9cb461d0267411aee3', 'message': 'Re-propose ""Policy service role spec""\n\nThis spec is to add service role to nova service-to-service\nAPIs policies.\n\nPartial implement blueprint policy-service-role-default\n\nAPIImpact\n\nChange-Id: Iea9c017a4f104370e75a3f1e5070c8efa01e30b6\n'}]",2,881880,9036a12bc64ac9a369906e9cb461d0267411aee3,12,4,2,8556,,,0,"Re-propose ""Policy service role spec""

This spec is to add service role to nova service-to-service
APIs policies.

Partial implement blueprint policy-service-role-default

APIImpact

Change-Id: Iea9c017a4f104370e75a3f1e5070c8efa01e30b6
",git fetch https://review.opendev.org/openstack/nova-specs refs/changes/80/881880/1 && git format-patch -1 --stdout FETCH_HEAD,['specs/2023.2/approved/policy-service-role-default.rst'],1,278b0eff1e3cd3052be57729a3c2523bfa133163,bp/policy-service-role-default,".. This work is licensed under a Creative Commons Attribution 3.0 Unported License. http://creativecommons.org/licenses/by/3.0/legalcode =========================== Policy Service Role Default =========================== https://blueprints.launchpad.net/nova/+spec/policy-service-role-default Ideally all internal service-to-service APIs should not be accessible by admin or end user by default. From policy defaults it should be clear which APIs are supposed to be used by admin or end user and which is for internal service-to-service APIs communication. Problem description =================== Currently, internal service-to-service communication APIs have their default policy as either admin or project roles which means operators need to assign the admin or project roles to their service users. That service user having admin or project role access is poor security practice as they can perform admin or project level operations. Another problem is that APIs which are meant to only be used by internal services are able to be called by regular users and human admins. Requiring (and allowing only) a service role for these APIs help avoid intentional and accidental abuse. Use Cases --------- As an operator I want to keep ``service`` role user to access service-to-service APIs with least privilege. Proposed change =============== We need to make sure all the policy rules for internal service-to-service APIs are default to ``service`` role only. Example: .. code-block:: python policy.DocumentedRuleDefault( name='os_compute_api:os-server-external-events:create', check_str='role:service', scope_types=['project'] ) Keystone's ``service`` role is kept outside of the existing role hierarchy that includes ``admin``, ``member``, and ``reader``. Keeping the ``service`` role outside the current hierarchy ensures we're following the principle of least privilege for service accounts. We need to make all the service-to-service APIs which are *only* suitable for services default to ``service`` role only. But we might have some cases where APIs are both intended for service usage, as well as admin (any other user role) usage. For such policy rules we need to default them to ``service`` as well as ``admin`` (or any other user role) role. For example, 'role:admin or role:service' As Nova have dropped the system scope implementation, service-to-service communication with ``service`` role will be done with project scope token (which is currently done in devstack setup). Below APIs policy will be default to ``service`` role: * os_compute_api:os-assisted-volume-snapshots:create * os_compute_api:os-assisted-volume-snapshots:delete * os_compute_api:os-volumes-attachments:swap * os_compute_api:os-server-external-events:create Alternatives ------------ Keep the service-to-service APIs default same as it is and expect operators to take care of the ``service`` role users access permissions by overriding it in the policy.yaml. Data model impact ----------------- None REST API impact --------------- Below APIs policy will be default to ``service`` role: * os_compute_api:os-assisted-volume-snapshots:create * os_compute_api:os-assisted-volume-snapshots:delete * os_compute_api:os-volumes-attachments:swap * os_compute_api:os-server-external-events:create Security impact --------------- Easier to understand service-to-service APIs policy and restricting them to least privilege. Notifications impact -------------------- None Other end user impact --------------------- None Performance Impact ------------------ None Other deployer impact --------------------- If service-to-service APIs are used by the admin or end user then make sure to override the required permission in policy.yaml because by default they will be accessed by the ``service`` role user only. Developer impact ---------------- New APIs must add policies that follow the new pattern. Upgrade impact -------------- If service-to-service APIs are used by the admin or end user then make sure to override the required permission in policy.yaml because by default they will be accessed by the ``service`` role user only. If deployment overrides these policies then, they need to start considering the new default policy rules. Implementation ============== Assignee(s) ----------- Primary assignee: gmann Feature Liaison --------------- Feature liaison: dansmith Work Items ---------- * Modify the service-to-service APIs defaults * Modify policy rule unit tests Dependencies ============ None Testing ======= Modify or add the policy unit tests. Add a job enabling the new defaults and run the tempest tests to make sure existing service-service APIs communication work fine. If needed modify the token used by services as per the new defaults. Documentation Impact ==================== API Reference should be updated to add all the service-service APIs under separate section and mention about ``service`` role as their default. References ========== History ======= .. list-table:: Revisions :header-rows: 1 * - Release Name - Description * - 2023.1 - Introduced * - 2023.2 - Re-proposed ",,195,0
openstack%2Freleases~887385,openstack/releases,master,Id489e2567b8c38d1defc9229087e1d25ccb59a59,[neutron] Release the 1.0.0.0b1 version of ovn-bgp-agent,MERGED,2023-06-30 14:58:16.000000000,2023-07-06 11:16:30.000000000,2023-07-06 08:50:48.000000000,"[{'_account_id': 308}, {'_account_id': 6773}, {'_account_id': 11975}, {'_account_id': 16688}, {'_account_id': 17685}, {'_account_id': 22348}, {'_account_id': 23567}]","[{'number': 1, 'created': '2023-06-30 14:58:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/releases/commit/0f3550cdb2b63c7dab6ac25f982540b2730c9fb1', 'message': '[neutron] Release the first version of ovn-bgp-agent\n\nThis is the first release of the project ""ovn-bgp-agent"".\n\nChange-Id: Id489e2567b8c38d1defc9229087e1d25ccb59a59\n'}, {'number': 2, 'created': '2023-06-30 15:03:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/releases/commit/3c47fe29eaef8b0c108f0f431586ed99c74b8305', 'message': '[neutron] Release the 0.5.0 version of ovn-bgp-agent\n\nThis is the first release of the project ""ovn-bgp-agent"" in the\nOpenStack community. However the project had four previous releases\nthat are documented in [1].\n\n[1]https://pypi.org/project/ovn-bgp-agent/\n\nChange-Id: Id489e2567b8c38d1defc9229087e1d25ccb59a59\n'}, {'number': 3, 'created': '2023-06-30 15:41:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/releases/commit/1c3f4961004b3d3cdc257d1e047ae39b55aaec73', 'message': '[neutron] Release the 1.0.0.0rc1 version of ovn-bgp-agent\n\nThis is the first release of the project ""ovn-bgp-agent"" in the\nOpenStack community. However the project had four previous releases\nthat are documented in [1].\n\n[1]https://pypi.org/project/ovn-bgp-agent/\n\nChange-Id: Id489e2567b8c38d1defc9229087e1d25ccb59a59\n'}, {'number': 4, 'created': '2023-06-30 16:31:04.000000000', 'files': ['deliverables/bobcat/ovn-bgp-agent.yaml'], 'web_link': 'https://opendev.org/openstack/releases/commit/1f7d482c13e6fec4f0de674a0123c5a43029d105', 'message': '[neutron] Release the 1.0.0.0b1 version of ovn-bgp-agent\n\nThis is the first release of the project ""ovn-bgp-agent"" in the\nOpenStack community. However the project had four previous releases\nthat are documented in [1].\n\n[1]https://pypi.org/project/ovn-bgp-agent/\n\nChange-Id: Id489e2567b8c38d1defc9229087e1d25ccb59a59\n'}]",14,887385,1f7d482c13e6fec4f0de674a0123c5a43029d105,35,7,4,16688,,,0,"[neutron] Release the 1.0.0.0b1 version of ovn-bgp-agent

This is the first release of the project ""ovn-bgp-agent"" in the
OpenStack community. However the project had four previous releases
that are documented in [1].

[1]https://pypi.org/project/ovn-bgp-agent/

Change-Id: Id489e2567b8c38d1defc9229087e1d25ccb59a59
",git fetch https://review.opendev.org/openstack/releases refs/changes/85/887385/1 && git format-patch -1 --stdout FETCH_HEAD,['deliverables/bobcat/ovn-bgp-agent.yaml'],1,0f3550cdb2b63c7dab6ac25f982540b2730c9fb1,ovn-bgp-agent_0.5.0,--- launchpad: ovn-bgp-agent team: neutron type: other release-model: cycle-with-rc repository-settings: openstack/ovn-bgp-agent: {} releases: - version: 0.1.0 projects: - repo: openstack/ovn-bgp-agent hash: c930d525635d70fa3a675de7f7a36f9171aaaf77 ,,12,0
openstack%2Fdevstack~886250,openstack/devstack,master,I6aacac94f9697088338b3d2f99d8eaa22c2be67b,Add 10 second buffer for uwsgi service stop,MERGED,2023-06-16 09:01:37.000000000,2023-07-06 11:15:43.000000000,2023-07-06 11:14:43.000000000,"[{'_account_id': 8556}, {'_account_id': 13252}, {'_account_id': 22348}, {'_account_id': 22873}]","[{'number': 1, 'created': '2023-06-16 09:01:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack/commit/758eff0a858866cac41f38201411df33c09f2fae', 'message': 'Add 10 second buffer for uwsgi service stop\n\nDefault for systemd TimeoutStopSec is 90 seconds\nand that is same for graceful shutdown of uwsgi\nservice(WORKER_TIMEOUT).\n\nDue to the Related-Bug graceful stop attempt\nfails and there is no room for force shutdown.\nThis patch adds 10 seconds buffer so service\nstop is successful.\n\nCloses-Bug: #2020643\nRelated-Bug: #2015065\nChange-Id: I6aacac94f9697088338b3d2f99d8eaa22c2be67b\n'}, {'number': 2, 'created': '2023-06-21 12:47:37.000000000', 'files': ['stackrc'], 'web_link': 'https://opendev.org/openstack/devstack/commit/7288df34f8513caf6f3985c75855feb572f6b004', 'message': 'Add 10 second buffer for uwsgi service stop\n\nDefault for systemd TimeoutStopSec is 90 seconds\nand that is same for default graceful shutdown of\nuwsgi service(WORKER_TIMEOUT).\n\nDue to the Related-Bug graceful stop attempt\nfails and there is no room for force shutdown.\nThis patch reduces default for WORKER_TIMEOUT by\n10 seconds so there is a buffer to force stop the\nservice.\n\nCloses-Bug: #2020643\nRelated-Bug: #2015065\nChange-Id: I6aacac94f9697088338b3d2f99d8eaa22c2be67b\n'}]",13,886250,7288df34f8513caf6f3985c75855feb572f6b004,37,4,2,13861,,,0,"Add 10 second buffer for uwsgi service stop

Default for systemd TimeoutStopSec is 90 seconds
and that is same for default graceful shutdown of
uwsgi service(WORKER_TIMEOUT).

Due to the Related-Bug graceful stop attempt
fails and there is no room for force shutdown.
This patch reduces default for WORKER_TIMEOUT by
10 seconds so there is a buffer to force stop the
service.

Closes-Bug: #2020643
Related-Bug: #2015065
Change-Id: I6aacac94f9697088338b3d2f99d8eaa22c2be67b
",git fetch https://review.opendev.org/openstack/devstack refs/changes/50/886250/1 && git format-patch -1 --stdout FETCH_HEAD,['functions-common'],1,758eff0a858866cac41f38201411df33c09f2fae,bug/2020643," iniset -sudo $unitfile ""Service"" ""TimeoutStopSec"" ""$((${WORKER_TIMEOUT} + 10))""",,1,0
openstack%2Freleases~887490,openstack/releases,master,I8261f08aaf2432c8bdd3406eb29bf498b41874e7,Bobcat-2 release for oslo.middleware,ABANDONED,2023-07-03 09:48:22.000000000,2023-07-06 11:09:06.000000000,,"[{'_account_id': 22348}, {'_account_id': 28522}, {'_account_id': 31245}]","[{'number': 1, 'created': '2023-07-03 09:48:22.000000000', 'files': ['deliverables/bobcat/oslo.middleware.yaml'], 'web_link': 'https://opendev.org/openstack/releases/commit/e4aa509a28df81c32959b68d7a5f54e660c90fe4', 'message': 'Bobcat-2 release for oslo.middleware\n\nThis is the Bobcat-2 milestone release for oslo.middleware.\nClients and libraries following the cycle-with-intermediary release\nmodel are encouraged to release each milestone to make sure updates\nare made available.\n\nIf the team is happy with the current release hash, please +1 this\npatch and we will process the release. If you need to get some\nimportant changes merged first, leave a -1 and update the patch with\na new commit hash to use once it is ready.\n\nIf a release is definitely not wanted at this time, please -1 and\nleave a comment explaining that and we can abandon the patch.\n\nAny patches with no response will be assumed to be OK and will be\nprocessed after July 6th.\n\nChange-Id: I8261f08aaf2432c8bdd3406eb29bf498b41874e7\nSigned-off-by: Elod Illes <elod.illes@est.tech>\n'}]",2,887490,e4aa509a28df81c32959b68d7a5f54e660c90fe4,5,3,1,17685,,,0,"Bobcat-2 release for oslo.middleware

This is the Bobcat-2 milestone release for oslo.middleware.
Clients and libraries following the cycle-with-intermediary release
model are encouraged to release each milestone to make sure updates
are made available.

If the team is happy with the current release hash, please +1 this
patch and we will process the release. If you need to get some
important changes merged first, leave a -1 and update the patch with
a new commit hash to use once it is ready.

If a release is definitely not wanted at this time, please -1 and
leave a comment explaining that and we can abandon the patch.

Any patches with no response will be assumed to be OK and will be
processed after July 6th.

Change-Id: I8261f08aaf2432c8bdd3406eb29bf498b41874e7
Signed-off-by: Elod Illes <elod.illes@est.tech>
",git fetch https://review.opendev.org/openstack/releases refs/changes/90/887490/1 && git format-patch -1 --stdout FETCH_HEAD,['deliverables/bobcat/oslo.middleware.yaml'],1,e4aa509a28df81c32959b68d7a5f54e660c90fe4,bobcat-milestone-2,releases: - version: 5.2.0 projects: - repo: openstack/oslo.middleware hash: 17531fe654805542364090cf9b66784dab1318ac,,5,0
openstack%2Freleases~887489,openstack/releases,master,Ic6c386303901da633b7f62e2ab807db6910d50a6,Bobcat-2 release for oslo.metrics,ABANDONED,2023-07-03 09:47:40.000000000,2023-07-06 11:07:12.000000000,,"[{'_account_id': 22348}, {'_account_id': 28522}, {'_account_id': 31245}]","[{'number': 1, 'created': '2023-07-03 09:47:40.000000000', 'files': ['deliverables/bobcat/oslo.metrics.yaml'], 'web_link': 'https://opendev.org/openstack/releases/commit/132aba5fae9d82fd0c1ab63be89710574fd453b8', 'message': 'Bobcat-2 release for oslo.metrics\n\nThis is the Bobcat-2 milestone release for oslo.metrics.\nClients and libraries following the cycle-with-intermediary release\nmodel are encouraged to release each milestone to make sure updates\nare made available.\n\nIf the team is happy with the current release hash, please +1 this\npatch and we will process the release. If you need to get some\nimportant changes merged first, leave a -1 and update the patch with\na new commit hash to use once it is ready.\n\nIf a release is definitely not wanted at this time, please -1 and\nleave a comment explaining that and we can abandon the patch.\n\nAny patches with no response will be assumed to be OK and will be\nprocessed after July 6th.\n\nChange-Id: Ic6c386303901da633b7f62e2ab807db6910d50a6\nSigned-off-by: Elod Illes <elod.illes@est.tech>\n'}]",2,887489,132aba5fae9d82fd0c1ab63be89710574fd453b8,5,3,1,17685,,,0,"Bobcat-2 release for oslo.metrics

This is the Bobcat-2 milestone release for oslo.metrics.
Clients and libraries following the cycle-with-intermediary release
model are encouraged to release each milestone to make sure updates
are made available.

If the team is happy with the current release hash, please +1 this
patch and we will process the release. If you need to get some
important changes merged first, leave a -1 and update the patch with
a new commit hash to use once it is ready.

If a release is definitely not wanted at this time, please -1 and
leave a comment explaining that and we can abandon the patch.

Any patches with no response will be assumed to be OK and will be
processed after July 6th.

Change-Id: Ic6c386303901da633b7f62e2ab807db6910d50a6
Signed-off-by: Elod Illes <elod.illes@est.tech>
",git fetch https://review.opendev.org/openstack/releases refs/changes/89/887489/1 && git format-patch -1 --stdout FETCH_HEAD,['deliverables/bobcat/oslo.metrics.yaml'],1,132aba5fae9d82fd0c1ab63be89710574fd453b8,bobcat-milestone-2,releases: - version: 0.7.0 projects: - repo: openstack/oslo.metrics hash: 5b478403278e69ca9fd822cb117c3e2aa49a6cda,,5,0
openstack%2Freleases~887488,openstack/releases,master,Ifc70061c5ad8199d4f57fe033a3b1a626532cfed,Bobcat-2 release for oslo.config,ABANDONED,2023-07-03 09:44:22.000000000,2023-07-06 11:04:02.000000000,,"[{'_account_id': 22348}, {'_account_id': 28522}, {'_account_id': 31245}]","[{'number': 1, 'created': '2023-07-03 09:44:22.000000000', 'files': ['deliverables/bobcat/oslo.config.yaml'], 'web_link': 'https://opendev.org/openstack/releases/commit/47b9e374a561e0d027b7ca96543d9b3ac9037192', 'message': 'Bobcat-2 release for oslo.config\n\nThis is the Bobcat-2 milestone release for oslo.config.\nClients and libraries following the cycle-with-intermediary release\nmodel are encouraged to release each milestone to make sure updates\nare made available.\n\nIf the team is happy with the current release hash, please +1 this\npatch and we will process the release. If you need to get some\nimportant changes merged first, leave a -1 and update the patch with\na new commit hash to use once it is ready.\n\nIf a release is definitely not wanted at this time, please -1 and\nleave a comment explaining that and we can abandon the patch.\n\nAny patches with no response will be assumed to be OK and will be\nprocessed after July 6th.\n\nChange-Id: Ifc70061c5ad8199d4f57fe033a3b1a626532cfed\nSigned-off-by: Elod Illes <elod.illes@est.tech>\n'}]",2,887488,47b9e374a561e0d027b7ca96543d9b3ac9037192,5,3,1,17685,,,0,"Bobcat-2 release for oslo.config

This is the Bobcat-2 milestone release for oslo.config.
Clients and libraries following the cycle-with-intermediary release
model are encouraged to release each milestone to make sure updates
are made available.

If the team is happy with the current release hash, please +1 this
patch and we will process the release. If you need to get some
important changes merged first, leave a -1 and update the patch with
a new commit hash to use once it is ready.

If a release is definitely not wanted at this time, please -1 and
leave a comment explaining that and we can abandon the patch.

Any patches with no response will be assumed to be OK and will be
processed after July 6th.

Change-Id: Ifc70061c5ad8199d4f57fe033a3b1a626532cfed
Signed-off-by: Elod Illes <elod.illes@est.tech>
",git fetch https://review.opendev.org/openstack/releases refs/changes/88/887488/1 && git format-patch -1 --stdout FETCH_HEAD,['deliverables/bobcat/oslo.config.yaml'],1,47b9e374a561e0d027b7ca96543d9b3ac9037192,bobcat-milestone-2,releases: - version: 9.2.0 projects: - repo: openstack/oslo.config hash: 28187da6d7b8eae39208e7cefbbc7da32ec3d3be,,5,0
openstack%2Fpython-glanceclient~887784,openstack/python-glanceclient,master,I96283b493c60de69f4598fb4470fba5fb117d749,Release notes for 4.4.0,MERGED,2023-07-06 09:51:08.000000000,2023-07-06 10:45:42.000000000,2023-07-06 10:44:37.000000000,"[{'_account_id': 8122}, {'_account_id': 9303}, {'_account_id': 22348}]","[{'number': 1, 'created': '2023-07-06 09:51:08.000000000', 'files': ['releasenotes/notes/4.4.0_Release-a3c89184f345e5a2.yaml'], 'web_link': 'https://opendev.org/openstack/python-glanceclient/commit/62e6fc8270a3e76e6b21cf2e6385f3c4bfe56cad', 'message': 'Release notes for 4.4.0\n\nChange-Id: I96283b493c60de69f4598fb4470fba5fb117d749\n'}]",0,887784,62e6fc8270a3e76e6b21cf2e6385f3c4bfe56cad,7,3,1,19138,,,0,"Release notes for 4.4.0

Change-Id: I96283b493c60de69f4598fb4470fba5fb117d749
",git fetch https://review.opendev.org/openstack/python-glanceclient refs/changes/84/887784/1 && git format-patch -1 --stdout FETCH_HEAD,['releasenotes/notes/4.4.0_Release-a3c89184f345e5a2.yaml'],1,62e6fc8270a3e76e6b21cf2e6385f3c4bfe56cad,4.4.0-reno,--- fixes: - | Bug 2012442_: import image with glance-download return 400 - | Bug 1934626_: glanceclient has no support to add type while creating md-property for namespace .. _2012442: https://code.launchpad.net/bugs/2012442 .. _1934626: https://code.launchpad.net/bugs/1934626 ,,9,0
openstack%2Fneutron-tempest-plugin~887684,openstack/neutron-tempest-plugin,master,I16182fde9c4be47beacb09c5e23eb91ea909146f,"Revert ""Fix wallaby/victoria neutron-tempest-plugin-ovn job""",ABANDONED,2023-07-06 10:05:00.000000000,2023-07-06 10:32:49.000000000,,"[{'_account_id': 6773}, {'_account_id': 8313}, {'_account_id': 11975}, {'_account_id': 13861}, {'_account_id': 22348}]","[{'number': 1, 'created': '2023-07-06 10:05:00.000000000', 'files': ['zuul.d/wallaby_jobs.yaml', 'zuul.d/victoria_jobs.yaml'], 'web_link': 'https://opendev.org/openstack/neutron-tempest-plugin/commit/5fea42635c1a74a015c2853a3dabdbb2072b2366', 'message': 'Revert ""Fix wallaby/victoria neutron-tempest-plugin-ovn job""\n\nThis reverts commit 24b5edd88c8eb889e05dfccd72ccba136661dcb9.\n\nReason for revert: Wallaby CI is pinned to 1.8.0 and Victoria\nto 1.6.0. Because we can\'t update these versions (the CI is\nnot taking this patch), we should find another way to solve the\ngit clone issue.\n\nChange-Id: I16182fde9c4be47beacb09c5e23eb91ea909146f\n'}]",2,887684,5fea42635c1a74a015c2853a3dabdbb2072b2366,5,5,1,16688,,,0,"Revert ""Fix wallaby/victoria neutron-tempest-plugin-ovn job""

This reverts commit 24b5edd88c8eb889e05dfccd72ccba136661dcb9.

Reason for revert: Wallaby CI is pinned to 1.8.0 and Victoria
to 1.6.0. Because we can't update these versions (the CI is
not taking this patch), we should find another way to solve the
git clone issue.

Change-Id: I16182fde9c4be47beacb09c5e23eb91ea909146f
",git fetch https://review.opendev.org/openstack/neutron-tempest-plugin refs/changes/84/887684/1 && git format-patch -1 --stdout FETCH_HEAD,"['zuul.d/wallaby_jobs.yaml', 'zuul.d/victoria_jobs.yaml']",2,5fea42635c1a74a015c2853a3dabdbb2072b2366,fix-wallaby,," # TODO(lucasagomes): Remove the OVN_BRANCH and OVS_BRANCH config # once https://review.opendev.org/c/openstack/devstack/+/887185 # is merged OVN_BRANCH: ""branch-22.03"" OVS_BRANCH: ""branch-3.0""",0,10
openstack%2Fovn-octavia-provider~886611,openstack/ovn-octavia-provider,master,Ie4b44c9f15fc9e33a68f9aacd766590b974c63fd,Ensure DVR is restablished on member on cascade deletion,MERGED,2023-06-23 16:24:13.000000000,2023-07-06 10:18:50.000000000,2023-07-06 10:17:39.000000000,"[{'_account_id': 6773}, {'_account_id': 22348}, {'_account_id': 23567}, {'_account_id': 34451}]","[{'number': 1, 'created': '2023-06-23 16:24:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ovn-octavia-provider/commit/ec8c49bdf5f4ab7d647779ef5cc777afffa56b2a', 'message': '[WIP] Ensure DVR is restablished on member on cascade deletion\n\nTraffic to member, if they have FIPs gets centralized when they\nare part of a loadbalancer. However, when the loadbalancer gets\ndeleted, the traffic should be distributed again (if DVR was\nenabled). To do that this patch also considers the cascade deletion\n\nChange-Id: Ie4b44c9f15fc9e33a68f9aacd766590b974c63fd\n'}, {'number': 2, 'created': '2023-06-26 09:54:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ovn-octavia-provider/commit/c350ed9ed458544038e4cbb230cf5b29b386b3ac', 'message': '[WIP] Ensure DVR is restablished on member on cascade deletion\n\nTraffic to member, if they have FIPs gets centralized when they\nare part of a loadbalancer. However, when the loadbalancer gets\ndeleted, the traffic should be distributed again (if DVR was\nenabled). To do that this patch also considers the cascade deletion\n\nChange-Id: Ie4b44c9f15fc9e33a68f9aacd766590b974c63fd\n'}, {'number': 3, 'created': '2023-06-30 17:09:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ovn-octavia-provider/commit/abffcc728ca9a4ca446b73b6a132aa15ffc1c249', 'message': 'Ensure DVR is restablished on member on cascade deletion\n\nTraffic to member, if they have FIPs gets centralized when they\nare part of a loadbalancer. However, when the loadbalancer gets\ndeleted, the traffic should be distributed again (if DVR was\nenabled). To do that this patch also considers the cascade deletion\n\nChange-Id: Ie4b44c9f15fc9e33a68f9aacd766590b974c63fd\n'}, {'number': 4, 'created': '2023-07-03 10:18:53.000000000', 'files': ['ovn_octavia_provider/tests/unit/test_driver.py', 'ovn_octavia_provider/helper.py', 'ovn_octavia_provider/driver.py', 'ovn_octavia_provider/tests/unit/test_helper.py'], 'web_link': 'https://opendev.org/openstack/ovn-octavia-provider/commit/20997b185f21aac8959d7517b4ffb7bc44c1b76a', 'message': 'Ensure DVR is restablished on member on cascade deletion\n\nTraffic to member, if they have FIPs gets centralized when they\nare part of a loadbalancer. However, when the loadbalancer gets\ndeleted, the traffic should be distributed again (if DVR was\nenabled). To do that this patch also considers the cascade deletion\n\nCloses-Bug: #2025637\nChange-Id: Ie4b44c9f15fc9e33a68f9aacd766590b974c63fd\n'}]",4,886611,20997b185f21aac8959d7517b4ffb7bc44c1b76a,19,4,4,23567,,,0,"Ensure DVR is restablished on member on cascade deletion

Traffic to member, if they have FIPs gets centralized when they
are part of a loadbalancer. However, when the loadbalancer gets
deleted, the traffic should be distributed again (if DVR was
enabled). To do that this patch also considers the cascade deletion

Closes-Bug: #2025637
Change-Id: Ie4b44c9f15fc9e33a68f9aacd766590b974c63fd
",git fetch https://review.opendev.org/openstack/ovn-octavia-provider refs/changes/11/886611/1 && git format-patch -1 --stdout FETCH_HEAD,['ovn_octavia_provider/helper.py'],1,ec8c49bdf5f4ab7d647779ef5cc777afffa56b2a,," member_ip = mem_info.split('_')[2].split("":"")[0] member_info = { 'id': mem_info.split('_')[1], 'address': member_ip, 'pool_id': pool_id, 'subnet_id': mem_info.split('_')[3], 'action': ovn_const.REQ_INFO_MEMBER_DELETED} self.handle_member_dvr(member_info) ",,9,0
openstack%2Fneutron~887511,openstack/neutron,stable/wallaby,I41ffffeca433faab2244ff3d1876ca078ce5ebfb,Load FIP information during initialize not init,MERGED,2023-07-03 11:29:54.000000000,2023-07-06 10:16:36.000000000,2023-07-06 10:14:59.000000000,"[{'_account_id': 1131}, {'_account_id': 8313}, {'_account_id': 11975}, {'_account_id': 21798}, {'_account_id': 22348}]","[{'number': 1, 'created': '2023-07-03 11:29:54.000000000', 'files': ['neutron/agent/l3/dvr_local_router.py', 'neutron/tests/unit/agent/l3/test_dvr_local_router.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/5d3da0fd318b523aeccbf3b9572659cefcba05bb', 'message': ""Load FIP information during initialize not init\n\nDvrLocalRouter._load_used_fip_information() is called during the class\ninit however in some cases it tries to access a network namespace which\nhasn't yet been created. This results in NetworkNamespaceNotFound.\n\nThis change ensures that we instead create any FIP priority rules after\nthe network namespace has been created by calling\n_load_used_fip_information() from the initialize function rather than\nin the class instantiation.\n\nCloses-Bug: #2025129\nChange-Id: I41ffffeca433faab2244ff3d1876ca078ce5ebfb\n(cherry picked from commit c8c74f12e048e7858eee332883dbe7c1dc1d0f0c)\n""}]",0,887511,5d3da0fd318b523aeccbf3b9572659cefcba05bb,9,5,1,16688,,,0,"Load FIP information during initialize not init

DvrLocalRouter._load_used_fip_information() is called during the class
init however in some cases it tries to access a network namespace which
hasn't yet been created. This results in NetworkNamespaceNotFound.

This change ensures that we instead create any FIP priority rules after
the network namespace has been created by calling
_load_used_fip_information() from the initialize function rather than
in the class instantiation.

Closes-Bug: #2025129
Change-Id: I41ffffeca433faab2244ff3d1876ca078ce5ebfb
(cherry picked from commit c8c74f12e048e7858eee332883dbe7c1dc1d0f0c)
",git fetch https://review.opendev.org/openstack/neutron refs/changes/11/887511/1 && git format-patch -1 --stdout FETCH_HEAD,"['neutron/agent/l3/dvr_local_router.py', 'neutron/tests/unit/agent/l3/test_dvr_local_router.py']",2,5d3da0fd318b523aeccbf3b9572659cefcba05bb,bug/2025129," @mock.patch.object(router_info.RouterInfo, 'initialize') def test_initialize_dvr_local_router(self, super_initialize): ri = self._create_router() self.mock_load_fip.assert_not_called() ri.initialize(self.process_monitor) super_initialize.assert_called_once_with(self.process_monitor) self.mock_load_fip.assert_called_once() ",,12,0
openstack%2Fnova~882718,openstack/nova,master,Iab294811172c7d3d723f716f154f0b57e9760223,WIP: Added api for healthcheck,ABANDONED,2023-05-09 13:51:28.000000000,2023-07-06 10:09:28.000000000,,[{'_account_id': 22348}],"[{'number': 1, 'created': '2023-05-09 13:51:28.000000000', 'files': ['nova/api/openstack/compute/routes.py', 'nova/api/openstack/compute/health.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/05ab03585ce00df47a3878fcad72a71c8fd170c7', 'message': 'WIP: Added api for healthcheck\n\nChange-Id: Iab294811172c7d3d723f716f154f0b57e9760223\n'}]",0,882718,05ab03585ce00df47a3878fcad72a71c8fd170c7,7,1,1,34860,,,0,"WIP: Added api for healthcheck

Change-Id: Iab294811172c7d3d723f716f154f0b57e9760223
",git fetch https://review.opendev.org/openstack/nova refs/changes/18/882718/1 && git format-patch -1 --stdout FETCH_HEAD,"['nova/api/openstack/compute/routes.py', 'nova/api/openstack/compute/health.py']",2,05ab03585ce00df47a3878fcad72a71c8fd170c7,nova-healthcheck-rfe,"from oslo_log import log as logging from nova.api.openstack import wsgi from nova.api.openstack.compute import services from nova.compute import api as compute from nova import servicegroup LOG = logging.getLogger(__name__) class HealthController(wsgi.Controller): def __init__(self): super(HealthController, self).__init__() self.host_api = compute.HostAPI() self.servicegroup_api = servicegroup.API() def _get_service_detail(self, svc, additional_fields, req, cell_down_support=False): alive = self.servicegroup_api.service_is_up(svc) state = (alive and ""pass"") or ""fail"" service_detail = {'binary': svc['binary'], 'host': svc['host'], 'state': state, } return service_detail def _get_services(self, context): services = [ s for s in self.host_api.service_get_all(context, set_zones=True, all_cells=True, cell_down_support=True) if s.topic ] service_detail = {} for svc in services: alive = self.servicegroup_api.service_is_up(svc) state = (alive and ""pass"") or ""fail"" service_detail.update({ svc['uuid']:{ 'binary': svc['binary'], 'host': svc['host'], 'state': state, } }) return service_detail @wsgi.expected_errors(()) def index(self, req): """"""Return a list of all running services. Filter by host & service name """""" context = req.environ['nova.context'] LOG.info(""~~~""*100) services = self._get_services(context) LOG.info(""~~~""*100) return services",,75,0
openstack%2Fneutron-tempest-plugin~887666,openstack/neutron-tempest-plugin,master,I18c81ae4a9b5a50e2db25302ab99883248b473a1,Fix wallaby/victoria neutron-tempest-plugin-ovn job,MERGED,2023-07-05 10:35:04.000000000,2023-07-06 10:05:00.000000000,2023-07-05 14:42:22.000000000,"[{'_account_id': 8313}, {'_account_id': 11975}, {'_account_id': 13861}, {'_account_id': 16688}, {'_account_id': 22348}]","[{'number': 1, 'created': '2023-07-05 10:35:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-tempest-plugin/commit/5a52177c5e87a55aba138835ec0574b1ddd61d6e', 'message': ""Fix wallaby neutron-tempest-plugin-ovn job\n\nThis could be fixed by merging\nhttps://review.opendev.org/c/openstack/devstack/+/887184 but, talking to\ndevstack maintainers upstream this patch does introduce a regression:\n\n<frickler> the problem with that patch is that it introduces a regression\nbecause GIT_DEPTH no longer works and until we have a fix for that,\nI'm hesitating to do more backports of it\n\nSo, I think we could workaround this by using the name of the branches\nwith those commits included instead of the commit hash, that would work\nwith the git clone function from devstack.\n\nChange-Id: I18c81ae4a9b5a50e2db25302ab99883248b473a1\nSigned-off-by: Lucas Alvares Gomes <lucasagomes@gmail.com>\n""}, {'number': 2, 'created': '2023-07-05 10:35:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-tempest-plugin/commit/09e94103286c76576980f4041a1a748aa46dc887', 'message': ""Fix wallaby neutron-tempest-plugin-ovn job\n\nThis could be fixed by merging\nhttps://review.opendev.org/c/openstack/devstack/+/887184 but, talking to\ndevstack maintainers upstream this patch does introduce a regression:\n\n<frickler> the problem with that patch is that it introduces a regression\nbecause GIT_DEPTH no longer works and until we have a fix for that,\nI'm hesitating to do more backports of it\n\nSo, I think we could workaround this by using the name of the branches\nwith those commits included instead of the commit hash, that would work\nwith the git clone function from devstack.\n\nChange-Id: I18c81ae4a9b5a50e2db25302ab99883248b473a1\nSigned-off-by: Lucas Alvares Gomes <lucasagomes@gmail.com>\n""}, {'number': 3, 'created': '2023-07-05 11:10:47.000000000', 'files': ['zuul.d/wallaby_jobs.yaml', 'zuul.d/victoria_jobs.yaml'], 'web_link': 'https://opendev.org/openstack/neutron-tempest-plugin/commit/24b5edd88c8eb889e05dfccd72ccba136661dcb9', 'message': ""Fix wallaby/victoria neutron-tempest-plugin-ovn job\n\nThis could be fixed by merging\nhttps://review.opendev.org/c/openstack/devstack/+/887184 and\nhttps://review.opendev.org/c/openstack/devstack/+/887185 but, talking\nto devstack maintainers upstream this patch does introduce a regression:\n\n<frickler> the problem with that patch is that it introduces a regression\nbecause GIT_DEPTH no longer works and until we have a fix for that,\nI'm hesitating to do more backports of it\n\nSo, I think we could workaround this by using the name of the branches\nwith those commits included instead of the commit hash, that would work\nwith the git clone function from devstack.\n\nChange-Id: I18c81ae4a9b5a50e2db25302ab99883248b473a1\nSigned-off-by: Lucas Alvares Gomes <lucasagomes@gmail.com>\n""}]",8,887666,24b5edd88c8eb889e05dfccd72ccba136661dcb9,18,5,3,6773,,,0,"Fix wallaby/victoria neutron-tempest-plugin-ovn job

This could be fixed by merging
https://review.opendev.org/c/openstack/devstack/+/887184 and
https://review.opendev.org/c/openstack/devstack/+/887185 but, talking
to devstack maintainers upstream this patch does introduce a regression:

<frickler> the problem with that patch is that it introduces a regression
because GIT_DEPTH no longer works and until we have a fix for that,
I'm hesitating to do more backports of it

So, I think we could workaround this by using the name of the branches
with those commits included instead of the commit hash, that would work
with the git clone function from devstack.

Change-Id: I18c81ae4a9b5a50e2db25302ab99883248b473a1
Signed-off-by: Lucas Alvares Gomes <lucasagomes@gmail.com>
",git fetch https://review.opendev.org/openstack/neutron-tempest-plugin refs/changes/66/887666/1 && git format-patch -1 --stdout FETCH_HEAD,['zuul.d/wallaby_jobs.yaml'],1,5a52177c5e87a55aba138835ec0574b1ddd61d6e,fix-wallaby," devstack_localrc: # TODO(lucasagomes): Remove the OVN_BRANCH and OVS_BRANCH config # once https://review.opendev.org/c/openstack/devstack/+/887184 # is merged OVN_BRANCH: ""branch-22.03"" OVS_BRANCH: ""branch-3.0""",,6,0
openstack%2Fneutron~887510,openstack/neutron,stable/xena,I41ffffeca433faab2244ff3d1876ca078ce5ebfb,Load FIP information during initialize not init,MERGED,2023-07-03 11:29:42.000000000,2023-07-06 10:00:11.000000000,2023-07-06 09:58:47.000000000,"[{'_account_id': 1131}, {'_account_id': 8313}, {'_account_id': 11975}, {'_account_id': 21798}, {'_account_id': 22348}]","[{'number': 1, 'created': '2023-07-03 11:29:42.000000000', 'files': ['neutron/agent/l3/dvr_local_router.py', 'neutron/tests/unit/agent/l3/test_dvr_local_router.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/7d595ded10790c9a3694019eba73a8e886f12071', 'message': ""Load FIP information during initialize not init\n\nDvrLocalRouter._load_used_fip_information() is called during the class\ninit however in some cases it tries to access a network namespace which\nhasn't yet been created. This results in NetworkNamespaceNotFound.\n\nThis change ensures that we instead create any FIP priority rules after\nthe network namespace has been created by calling\n_load_used_fip_information() from the initialize function rather than\nin the class instantiation.\n\nCloses-Bug: #2025129\nChange-Id: I41ffffeca433faab2244ff3d1876ca078ce5ebfb\n(cherry picked from commit c8c74f12e048e7858eee332883dbe7c1dc1d0f0c)\n""}]",3,887510,7d595ded10790c9a3694019eba73a8e886f12071,18,5,1,16688,,,0,"Load FIP information during initialize not init

DvrLocalRouter._load_used_fip_information() is called during the class
init however in some cases it tries to access a network namespace which
hasn't yet been created. This results in NetworkNamespaceNotFound.

This change ensures that we instead create any FIP priority rules after
the network namespace has been created by calling
_load_used_fip_information() from the initialize function rather than
in the class instantiation.

Closes-Bug: #2025129
Change-Id: I41ffffeca433faab2244ff3d1876ca078ce5ebfb
(cherry picked from commit c8c74f12e048e7858eee332883dbe7c1dc1d0f0c)
",git fetch https://review.opendev.org/openstack/neutron refs/changes/10/887510/1 && git format-patch -1 --stdout FETCH_HEAD,"['neutron/agent/l3/dvr_local_router.py', 'neutron/tests/unit/agent/l3/test_dvr_local_router.py']",2,7d595ded10790c9a3694019eba73a8e886f12071,bug/2025129," @mock.patch.object(router_info.RouterInfo, 'initialize') def test_initialize_dvr_local_router(self, super_initialize): ri = self._create_router() self.mock_load_fip.assert_not_called() ri.initialize(self.process_monitor) super_initialize.assert_called_once_with(self.process_monitor) self.mock_load_fip.assert_called_once() ",,12,0
openstack%2Freleases~887767,openstack/releases,master,If65debbef4ae6527f7a811ace99cf69e4b0d5339,[zed] release oslo.messaging 14.0.1,MERGED,2023-07-06 07:55:13.000000000,2023-07-06 09:54:09.000000000,2023-07-06 09:54:09.000000000,"[{'_account_id': 308}, {'_account_id': 17685}, {'_account_id': 22348}]","[{'number': 1, 'created': '2023-07-06 07:55:13.000000000', 'files': ['deliverables/zed/oslo.messaging.yaml'], 'web_link': 'https://opendev.org/openstack/releases/commit/2f95c4d58da64f789975566dab4e90f88677aeed', 'message': '[zed] release oslo.messaging 14.0.1\n\nChange-Id: If65debbef4ae6527f7a811ace99cf69e4b0d5339\n'}]",2,887767,2f95c4d58da64f789975566dab4e90f88677aeed,8,3,1,28522,,,0,"[zed] release oslo.messaging 14.0.1

Change-Id: If65debbef4ae6527f7a811ace99cf69e4b0d5339
",git fetch https://review.opendev.org/openstack/releases refs/changes/67/887767/1 && git format-patch -1 --stdout FETCH_HEAD,['deliverables/zed/oslo.messaging.yaml'],1,2f95c4d58da64f789975566dab4e90f88677aeed,oslo-zed, - version: 14.0.1 projects: - repo: openstack/oslo.messaging hash: fa3195a3459cae3f4e9be43f114ee2d5eb7a60f1,,4,0
openstack%2Ftempest~886496,openstack/tempest,master,I01b6a8eb5b0e319205834d0d36b21e3c15e8c9d6,"Mark ""test_live_migration_with_trunk"" as unstable",MERGED,2023-06-20 13:56:03.000000000,2023-07-06 09:40:54.000000000,2023-06-22 01:25:20.000000000,"[{'_account_id': 7166}, {'_account_id': 8313}, {'_account_id': 8556}, {'_account_id': 9708}, {'_account_id': 22348}]","[{'number': 1, 'created': '2023-06-20 13:56:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/b974a086b2c6c606d9885d41ce165a73886d8518', 'message': 'Mark ""test_live_migration_with_trunk"" as unstable\n\nMost probably due to a new OVN version, the subports status of a trunk\nport  are always DOWN. We are investigating this issue right now. In\norder to unblock the Nova CI, this test is marked as unstable\ntemporarily.\n\nRelated-Bug: #2024160\nChange-Id: I01b6a8eb5b0e319205834d0d36b21e3c15e8c9d6\n'}, {'number': 2, 'created': '2023-06-20 19:05:22.000000000', 'files': ['tempest/api/compute/admin/test_live_migration.py'], 'web_link': 'https://opendev.org/openstack/tempest/commit/0c953a7c100a8eced9158402106eec99f64a5378', 'message': 'Mark ""test_live_migration_with_trunk"" as unstable\n\nMost probably due to a new OVN version, the subports status of a trunk\nport  are always DOWN. We are investigating this issue right now. In\norder to unblock the Nova CI, this test is marked as unstable\ntemporarily.\n\nRelated-Bug: #2024160\nChange-Id: I01b6a8eb5b0e319205834d0d36b21e3c15e8c9d6\n'}]",9,886496,0c953a7c100a8eced9158402106eec99f64a5378,25,5,2,16688,,,0,"Mark ""test_live_migration_with_trunk"" as unstable

Most probably due to a new OVN version, the subports status of a trunk
port  are always DOWN. We are investigating this issue right now. In
order to unblock the Nova CI, this test is marked as unstable
temporarily.

Related-Bug: #2024160
Change-Id: I01b6a8eb5b0e319205834d0d36b21e3c15e8c9d6
",git fetch https://review.opendev.org/openstack/tempest refs/changes/96/886496/1 && git format-patch -1 --stdout FETCH_HEAD,['tempest/api/compute/admin/test_live_migration.py'],1,b974a086b2c6c606d9885d41ce165a73886d8518,bug/2024160, @decorators.unstable_test('bug 2024160'),,1,0
openstack%2Freleases~887766,openstack/releases,master,Ice1fa6e981ca88240f6bdc7ce47f823854d1da40,[yoga] release oslo.messaging 12.13.1,MERGED,2023-07-06 07:53:18.000000000,2023-07-06 09:38:59.000000000,2023-07-06 09:38:59.000000000,"[{'_account_id': 308}, {'_account_id': 17685}, {'_account_id': 22348}]","[{'number': 1, 'created': '2023-07-06 07:53:18.000000000', 'files': ['deliverables/yoga/oslo.messaging.yaml'], 'web_link': 'https://opendev.org/openstack/releases/commit/e183654753d3af4efe61e159c022fe8a02472e29', 'message': '[yoga] release oslo.messaging 12.13.1\n\nChange-Id: Ice1fa6e981ca88240f6bdc7ce47f823854d1da40\n'}]",2,887766,e183654753d3af4efe61e159c022fe8a02472e29,8,3,1,28522,,,0,"[yoga] release oslo.messaging 12.13.1

Change-Id: Ice1fa6e981ca88240f6bdc7ce47f823854d1da40
",git fetch https://review.opendev.org/openstack/releases refs/changes/66/887766/1 && git format-patch -1 --stdout FETCH_HEAD,['deliverables/yoga/oslo.messaging.yaml'],1,e183654753d3af4efe61e159c022fe8a02472e29,oslo-yoga, - version: 12.13.1 projects: - repo: openstack/oslo.messaging hash: f20a905ea6f41399c1723f8f1cbd0bc1097b8672,,4,0
openstack%2Fmonasca-api~887775,openstack/monasca-api,master,I0658e32038501c845e0186b54e776723fdd0e918,DNM: dummy change to test gate health Change-Id: I0658e32038501c845e0186b54e776723fdd0e918,NEW,2023-07-06 09:01:06.000000000,2023-07-06 09:38:44.000000000,,[{'_account_id': 22348}],"[{'number': 1, 'created': '2023-07-06 09:01:06.000000000', 'files': ['docker/health_check.py'], 'web_link': 'https://opendev.org/openstack/monasca-api/commit/dab1e8535f7d631a041f2442898a6e95444cdcbb', 'message': 'DNM: dummy change to test gate health\nChange-Id: I0658e32038501c845e0186b54e776723fdd0e918\n'}]",0,887775,dab1e8535f7d631a041f2442898a6e95444cdcbb,3,1,1,35988,,,0,"DNM: dummy change to test gate health
Change-Id: I0658e32038501c845e0186b54e776723fdd0e918
",git fetch https://review.opendev.org/openstack/monasca-api refs/changes/75/887775/1 && git format-patch -1 --stdout FETCH_HEAD,['docker/health_check.py'],1,dab1e8535f7d631a041f2442898a6e95444cdcbb,, # dummy test change,,2,0
openstack%2Fmasakari~887264,openstack/masakari,master,I44b1db763d3a0ed9eb4c007278c8f131db9b57dd,log when set host on maintenance,MERGED,2023-06-29 10:55:22.000000000,2023-07-06 09:19:36.000000000,2023-07-06 09:18:38.000000000,"[{'_account_id': 22348}, {'_account_id': 30623}]","[{'number': 1, 'created': '2023-06-29 10:55:22.000000000', 'files': ['masakari/engine/manager.py'], 'web_link': 'https://opendev.org/openstack/masakari/commit/bad1f2fe6e5b4cc1f04c8723d9aba8c4cfffb164', 'message': 'log when set host on maintenance\n\nChange-Id: I44b1db763d3a0ed9eb4c007278c8f131db9b57dd\n'}]",0,887264,bad1f2fe6e5b4cc1f04c8723d9aba8c4cfffb164,7,2,1,30623,,,0,"log when set host on maintenance

Change-Id: I44b1db763d3a0ed9eb4c007278c8f131db9b57dd
",git fetch https://review.opendev.org/openstack/masakari refs/changes/64/887264/1 && git format-patch -1 --stdout FETCH_HEAD,['masakari/engine/manager.py'],1,bad1f2fe6e5b4cc1f04c8723d9aba8c4cfffb164,," LOG.info(""Set host %s on maintenance."", host_name)",,1,0
openstack%2Fopenstack-ansible-rabbitmq_server~887592,openstack/openstack-ansible-rabbitmq_server,master,I99683a031f935b579d38ae457c484c9a150344c6,Use wildcards to specify rabbit/erlang versions,MERGED,2023-07-04 10:58:44.000000000,2023-07-06 09:15:42.000000000,2023-07-05 17:21:27.000000000,"[{'_account_id': 16011}, {'_account_id': 22348}, {'_account_id': 25023}, {'_account_id': 28619}, {'_account_id': 32666}]","[{'number': 1, 'created': '2023-07-04 10:58:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-rabbitmq_server/commit/dc5eba187a11681e22c183574571d9b54f953754', 'message': 'Use wildcards to specify rabbit/erlang versions\n\nFor a long time we were struggling with disappearing packages on\npackagecloud/cloudsmith repos.\nWe were told to use {ppa1,yum1}.novemberain.com because packages should\nnot disappear from there[1].\nUnfortunately it just happened causing Rocky jobs to fail with error\nmessage: ""No package erlang-25.3.2-1.el9.x86_64 available.""\n\nBecause we had this issue for a long time and we have not found any\nproper solution so far, I think the best we can do is to use wildcards\nin a version definitions.\n\nAdditionally, I don\'t think that pinning to specific patch version\n(number afer second dot) is really needed because according to [2],\nrabbitmq 3.11.X should always work with erlang 25.3.Y.\nBased on that information, it is enough to pin:\nrabbitmq-server==3.11.* and erlang==25.3.*\n\n[1] https://github.com/rabbitmq/rabbitmq-server/discussions/8386#discussioncomment-6022021\n[2] https://www.rabbitmq.com/which-erlang.html#compatibility-matrix\n\nRequired-By: https://review.opendev.org/c/openstack/openstack-ansible-os_rally/+/887528\nChange-Id: I99683a031f935b579d38ae457c484c9a150344c6\n'}, {'number': 2, 'created': '2023-07-04 16:13:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-rabbitmq_server/commit/710b1ffb4f93a6a3599c6a73e271c7828e223fe4', 'message': 'Use wildcards to specify rabbit/erlang versions\n\nFor a long time we were struggling with disappearing packages on\npackagecloud/cloudsmith repos.\nWe were told to use {ppa1,yum1}.novemberain.com because packages should\nnot disappear from there[1].\nUnfortunately it just happened causing Rocky jobs to fail with error\nmessage: ""No package erlang-25.3.2-1.el9.x86_64 available.""\n\nBecause we had this issue for a long time and we have not found any\nproper solution so far, I think the best we can do is to use wildcards for\nversion definitions.\nWildcards are used only for build numbers(number after 3th dot) if they are\npresent. It should minimize a chance to install incompatible erlang and rabbitmq\nversions.\n\n[1] https://github.com/rabbitmq/rabbitmq-server/discussions/8386#discussioncomment-6022021\n\nRequired-By: https://review.opendev.org/c/openstack/openstack-ansible-os_rally/+/887528\nChange-Id: I99683a031f935b579d38ae457c484c9a150344c6\n'}, {'number': 3, 'created': '2023-07-04 16:47:31.000000000', 'files': ['vars/redhat.yml', 'vars/debian.yml'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-rabbitmq_server/commit/953ceccb0b374f15e055abc4830d5de2e9a2c2aa', 'message': 'Use wildcards to specify rabbit/erlang versions\n\nFor a long time we were struggling with disappearing packages on\npackagecloud/cloudsmith repos.\nWe were told to use {ppa1,yum1}.novemberain.com because packages should\nnot disappear from there[1].\nUnfortunately it just happened causing Rocky jobs to fail with error\nmessage: ""No package erlang-25.3.2-1.el9.x86_64 available.""\n\nBecause we had this issue for a long time and we have not found any\nproper solution so far, I think the best we can do is to use wildcards\nfor version definitions.\nWildcards are used only for build numbers(number after 3th dot) if they\nare present. It should minimize a chance to install incompatible erlang\nand rabbitmq versions.\n\n[1] https://github.com/rabbitmq/rabbitmq-server/discussions/8386#discussioncomment-6022021\n\nRequired-By: https://review.opendev.org/c/openstack/openstack-ansible-os_rally/+/887528\nChange-Id: I99683a031f935b579d38ae457c484c9a150344c6\n'}]",4,887592,953ceccb0b374f15e055abc4830d5de2e9a2c2aa,17,5,3,32666,,,0,"Use wildcards to specify rabbit/erlang versions

For a long time we were struggling with disappearing packages on
packagecloud/cloudsmith repos.
We were told to use {ppa1,yum1}.novemberain.com because packages should
not disappear from there[1].
Unfortunately it just happened causing Rocky jobs to fail with error
message: ""No package erlang-25.3.2-1.el9.x86_64 available.""

Because we had this issue for a long time and we have not found any
proper solution so far, I think the best we can do is to use wildcards
for version definitions.
Wildcards are used only for build numbers(number after 3th dot) if they
are present. It should minimize a chance to install incompatible erlang
and rabbitmq versions.

[1] https://github.com/rabbitmq/rabbitmq-server/discussions/8386#discussioncomment-6022021

Required-By: https://review.opendev.org/c/openstack/openstack-ansible-os_rally/+/887528
Change-Id: I99683a031f935b579d38ae457c484c9a150344c6
",git fetch https://review.opendev.org/openstack/openstack-ansible-rabbitmq_server refs/changes/92/887592/1 && git format-patch -1 --stdout FETCH_HEAD,"['vars/redhat.yml', 'vars/debian.yml']",2,dc5eba187a11681e22c183574571d9b54f953754,,"_rabbitmq_package_version: ""3.11.*""_rabbitmq_erlang_version_spec: ""{{ (rabbitmq_install_method == 'external_repo') | ternary('1:25.3.*', '1:22.*') }}""","_rabbitmq_package_version: ""3.11.17-1""_rabbitmq_erlang_version_spec: ""{{ (rabbitmq_install_method == 'external_repo') | ternary('1:25.3.2.1-1', '1:22.*') }}""",4,4
openstack%2Fovn-bgp-agent~883187,openstack/ovn-bgp-agent,master,I9abf987004370d0c3ec6a152bb28ab450a9af2c2,Fix issue with virtual ports not being exposed on time,MERGED,2023-05-19 05:43:45.000000000,2023-07-06 09:14:50.000000000,2023-07-06 09:13:49.000000000,"[{'_account_id': 6773}, {'_account_id': 22348}, {'_account_id': 23567}]","[{'number': 1, 'created': '2023-05-19 05:43:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ovn-bgp-agent/commit/b7361f9238c9021223f4500bc15a09f0a2c5cd60', 'message': 'Fix issue with virtual ports not being exposed on time\n\nThe requested-chassis information is only added by neutron\nfor """" port types. The virtual ports chassis is decided by OVN\nnot by neutron, and neutron only update that information in the\nperiodic maintenance task.\n\nAs part of [1] information about the virtual port chassis is being\nadded to the external_ids. This patch is adapting the NB DB driver\nto consume this new source of information and being able to expose\nthose ports when OVN associates them to a node.\n\nDepends-On: https://review.opendev.org/c/openstack/neutron/+/882705\n\nCloses-Bug: #2020157\n\n[1] https://review.opendev.org/c/openstack/neutron/+/882705\n\nChange-Id: I9abf987004370d0c3ec6a152bb28ab450a9af2c2\n'}, {'number': 2, 'created': '2023-05-19 07:19:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ovn-bgp-agent/commit/011b4669ea6584ad414db1f9fcae2a6b9f76ffc6', 'message': 'Fix issue with virtual ports not being exposed on time\n\nThe requested-chassis information is only added by neutron\nfor """" port types. The virtual ports chassis is decided by OVN\nnot by neutron, and neutron only update that information in the\nperiodic maintenance task.\n\nAs part of [1] information about the virtual port chassis is being\nadded to the external_ids. This patch is adapting the NB DB driver\nto consume this new source of information and being able to expose\nthose ports when OVN associates them to a node.\n\nDepends-On: https://review.opendev.org/c/openstack/neutron/+/882705\n\nCloses-Bug: #2020157\n\n[1] https://review.opendev.org/c/openstack/neutron/+/882705\n\nChange-Id: I9abf987004370d0c3ec6a152bb28ab450a9af2c2\n'}, {'number': 3, 'created': '2023-05-19 07:24:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ovn-bgp-agent/commit/78a6e6a9909e58d9c5aaee630c709d6c43c08d25', 'message': 'Fix issue with virtual ports not being exposed on time\n\nThe requested-chassis information is only added by neutron\nfor """" port types. The virtual ports chassis is decided by OVN\nnot by neutron, and neutron only update that information in the\nperiodic maintenance task.\n\nAs part of [1] information about the virtual port chassis is being\nadded to the external_ids. This patch is adapting the NB DB driver\nto consume this new source of information and being able to expose\nthose ports when OVN associates them to a node.\n\nDepends-On: https://review.opendev.org/c/openstack/neutron/+/882705\n\nCloses-Bug: #2020157\n\n[1] https://review.opendev.org/c/openstack/neutron/+/882705\n\nChange-Id: I9abf987004370d0c3ec6a152bb28ab450a9af2c2\n'}, {'number': 4, 'created': '2023-07-05 08:16:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ovn-bgp-agent/commit/d8e734a4223e7113e73d58320a8aa0f092c10dfc', 'message': 'Fix issue with virtual ports not being exposed on time\n\nThe requested-chassis information is only added by neutron\nfor """" port types. The virtual ports chassis is decided by OVN\nnot by neutron, and neutron only update that information in the\nperiodic maintenance task.\n\nAs part of [1] information about the virtual port chassis is being\nadded to the external_ids. This patch is adapting the NB DB driver\nto consume this new source of information and being able to expose\nthose ports when OVN associates them to a node.\n\nDepends-On: https://review.opendev.org/c/openstack/neutron/+/882705\n\nCloses-Bug: #2020157\n\n[1] https://review.opendev.org/c/openstack/neutron/+/882705\n\nChange-Id: I9abf987004370d0c3ec6a152bb28ab450a9af2c2\n'}, {'number': 5, 'created': '2023-07-05 10:41:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ovn-bgp-agent/commit/c4bca172233eafec68458acdf86343df27906597', 'message': 'Fix issue with virtual ports not being exposed on time\n\nThe requested-chassis information is only added by neutron\nfor """" port types. The virtual ports chassis is decided by OVN\nnot by neutron, and neutron only update that information in the\nperiodic maintenance task.\n\nAs part of [1] information about the virtual port chassis is being\nadded to the external_ids. This patch is adapting the NB DB driver\nto consume this new source of information and being able to expose\nthose ports when OVN associates them to a node.\n\nDepends-On: https://review.opendev.org/c/openstack/neutron/+/882705\n\nCloses-Bug: #2020157\n\n[1] https://review.opendev.org/c/openstack/neutron/+/882705\n\nChange-Id: I9abf987004370d0c3ec6a152bb28ab450a9af2c2\n'}, {'number': 6, 'created': '2023-07-05 11:56:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ovn-bgp-agent/commit/315732c7e385d0f6ca28c3fbb1e159052f0d4b98', 'message': 'Fix issue with virtual ports not being exposed on time\n\nThe requested-chassis information is only added by neutron\nfor """" port types. The virtual ports chassis is decided by OVN\nnot by neutron, and neutron only update that information in the\nperiodic maintenance task.\n\nAs part of [1] information about the virtual port chassis is being\nadded to the external_ids, as well as for """" ports. This patch is\nadapting the NB DB driver to consume this new source of information\nand being able to expose those ports when OVN associates them to a\nnode.\n\nDepends-On: https://review.opendev.org/c/openstack/neutron/+/882705\n\nCloses-Bug: #2020157\n\n[1] https://review.opendev.org/c/openstack/neutron/+/882705\n\nChange-Id: I9abf987004370d0c3ec6a152bb28ab450a9af2c2\n'}, {'number': 7, 'created': '2023-07-05 13:59:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ovn-bgp-agent/commit/f38a327794c3e065a171f6f6bdbfa1eec15a8fb4', 'message': 'Fix issue with virtual ports not being exposed on time\n\nThe requested-chassis information is only added by neutron\nfor """" port types. The virtual ports chassis is decided by OVN\nnot by neutron, and neutron only update that information in the\nperiodic maintenance task.\n\nAs part of [1] information about the virtual port chassis is being\nadded to the external_ids, as well as for """" ports. This patch is\nadapting the NB DB driver to consume this new source of information\nand being able to expose those ports when OVN associates them to a\nnode.\n\nDepends-On: https://review.opendev.org/c/openstack/neutron/+/882705\n\nCloses-Bug: #2020157\n\n[1] https://review.opendev.org/c/openstack/neutron/+/882705\n\nChange-Id: I9abf987004370d0c3ec6a152bb28ab450a9af2c2\n'}, {'number': 8, 'created': '2023-07-05 14:25:09.000000000', 'files': ['ovn_bgp_agent/drivers/openstack/utils/ovn.py', 'ovn_bgp_agent/drivers/openstack/watchers/base_watcher.py', 'ovn_bgp_agent/tests/unit/drivers/openstack/watchers/test_nb_bgp_watcher.py', 'ovn_bgp_agent/tests/unit/drivers/openstack/utils/test_ovn.py', 'ovn_bgp_agent/constants.py', 'ovn_bgp_agent/drivers/openstack/watchers/nb_bgp_watcher.py'], 'web_link': 'https://opendev.org/openstack/ovn-bgp-agent/commit/eaf217d89da5184ff660accda76a8fe1de5a16d4', 'message': 'Fix issue with virtual ports not being exposed on time\n\nThe requested-chassis information is only added by neutron\nfor """" port types. The virtual ports chassis is decided by OVN\nnot by neutron, and neutron only update that information in the\nperiodic maintenance task.\n\nAs part of [1] information about the virtual port chassis is being\nadded to the external_ids, as well as for """" ports. This patch is\nadapting the NB DB driver to consume this new source of information\nand being able to expose those ports when OVN associates them to a\nnode.\n\nDepends-On: https://review.opendev.org/c/openstack/neutron/+/882705\n\nCloses-Bug: #2020157\n\n[1] https://review.opendev.org/c/openstack/neutron/+/882705\n\nChange-Id: I9abf987004370d0c3ec6a152bb28ab450a9af2c2\n'}]",4,883187,eaf217d89da5184ff660accda76a8fe1de5a16d4,26,3,8,23567,,,0,"Fix issue with virtual ports not being exposed on time

The requested-chassis information is only added by neutron
for """" port types. The virtual ports chassis is decided by OVN
not by neutron, and neutron only update that information in the
periodic maintenance task.

As part of [1] information about the virtual port chassis is being
added to the external_ids, as well as for """" ports. This patch is
adapting the NB DB driver to consume this new source of information
and being able to expose those ports when OVN associates them to a
node.

Depends-On: https://review.opendev.org/c/openstack/neutron/+/882705

Closes-Bug: #2020157

[1] https://review.opendev.org/c/openstack/neutron/+/882705

Change-Id: I9abf987004370d0c3ec6a152bb28ab450a9af2c2
",git fetch https://review.opendev.org/openstack/ovn-bgp-agent refs/changes/87/883187/1 && git format-patch -1 --stdout FETCH_HEAD,"['ovn_bgp_agent/drivers/openstack/utils/ovn.py', 'ovn_bgp_agent/drivers/openstack/watchers/base_watcher.py', 'ovn_bgp_agent/constants.py', 'ovn_bgp_agent/drivers/openstack/watchers/nb_bgp_watcher.py']",4,b7361f9238c9021223f4500bc15a09f0a2c5cd60,," current_chassis = self._get_chassis(row) old_chassis = self._get_chassis(old) current_chassis = self._get_chassis(row) if event == self.ROW_DELETE: return current_chassis == self.agent.chassis and row.up if hasattr(old, 'options') or hasattr(old, 'external_ids'): # check chassis change old_chassis = self._get_chassis(old) if old_chassis != self.agent.chassis: return False if not current_chassis or current_chassis != old_chassis: return True current_chassis = self._get_chassis(row) if row.type == constants.OVN_VM_VIF_PORT_TYPE: if hasattr(old, 'options'): # check chassis change old_chassis = self._get_chassis(old) if not old_chassis or current_chassis != old_chassis: return True if hasattr(old, 'external_ids'): # check fips addition old_port_fip = old.external_ids.get( constants.OVN_FIP_EXT_ID_KEY) if not old_port_fip or current_port_fip != old_port_fip: return True elif row.type == constants.OVN_VIRTUAL_VIF_PORT_TYPE: if hasattr(old, 'external_ids'): old_chassis = self._get_chassis(old) old_port_fip = old.external_ids.get( constants.OVN_FIP_EXT_ID_KEY) if (current_chassis != old_chassis or current_port_fip != old_port_fip): return True current_chassis = self._get_chassis(row) if row.type == constants.OVN_VM_VIF_PORT_TYPE: if hasattr(old, 'options'): # check chassis change old_chassis = self._get_chassis(old) if (not old_chassis or old_chassis != self.agent.chassis): return False if current_chassis != old_chassis and current_port_fip: return True # There was no change in chassis, so only progress if the # chassis matches if current_chassis != self.agent.chassis: return False if hasattr(old, 'external_ids'): # check fips deletion old_port_fip = old.external_ids.get( constants.OVN_FIP_EXT_ID_KEY) if not old_port_fip: return False if old_port_fip != current_port_fip: return True elif row.type == constants.OVN_VIRTUAL_VIF_PORT_TYPE: if hasattr(old, 'external_ids'): # check chassis change old_chassis = self._get_chassis(old) if (not old_chassis or old_chassis != self.agent.chassis): return False if current_chassis != old_chassis and current_port_fip: return True # check fips deletion old_port_fip = old.external_ids.get( constants.OVN_FIP_EXT_ID_KEY) if not old_port_fip: return False if old_port_fip != current_port_fip: return True"," current_chassis = row.options.get(constants.OVN_REQUESTED_CHASSIS) old_chassis = old.options.get(constants.OVN_REQUESTED_CHASSIS) current_chassis = row.options.get(constants.OVN_REQUESTED_CHASSIS) if event == self.ROW_DELETE: return current_chassis == self.agent.chassis if hasattr(old, 'options'): # check chassis change old_chassis = old.options.get(constants.OVN_REQUESTED_CHASSIS) if old_chassis != self.agent.chassis: return False if not current_chassis or current_chassis != old_chassis: return True current_chassis = row.options.get(constants.OVN_REQUESTED_CHASSIS) if hasattr(old, 'options'): # check chassis change old_chassis = old.options.get(constants.OVN_REQUESTED_CHASSIS) if not old_chassis or current_chassis != old_chassis: return True if hasattr(old, 'external_ids'): # check fips addition old_port_fip = old.external_ids.get( constants.OVN_FIP_EXT_ID_KEY) if not old_port_fip or current_port_fip != old_port_fip: return True current_chassis = row.options.get(constants.OVN_REQUESTED_CHASSIS) if hasattr(old, 'options'): # check chassis change old_chassis = old.options.get(constants.OVN_REQUESTED_CHASSIS) if (not old_chassis or old_chassis != self.agent.chassis): return False if current_chassis != old_chassis and current_port_fip: return True # There was no change in chassis, so only progress if the # chassis matches if current_chassis != self.agent.chassis: return False if hasattr(old, 'external_ids'): # check fips deletion old_port_fip = old.external_ids.get( constants.OVN_FIP_EXT_ID_KEY) if not old_port_fip: return False if old_port_fip != current_port_fip: return True",86,45
openstack%2Fkeystone~846368,openstack/keystone,master,I98a68caa5493839f8dea007308bd031693115848,WIP sql: Don't rely on globals to configure enginefacades,ABANDONED,2022-06-17 13:38:33.000000000,2023-07-06 09:05:58.000000000,,[{'_account_id': 22348}],"[{'number': 1, 'created': '2022-06-17 13:38:33.000000000', 'files': ['keystone/common/sql/core.py', 'keystone/cmd/cli.py', 'keystone/common/sql/upgrades.py', 'keystone/tests/unit/identity/backends/test_sql.py', 'keystone/tests/unit/test_sql_banned_operations.py', 'keystone/tests/unit/ksfixtures/database.py', 'keystone/tests/unit/test_sql_upgrade.py'], 'web_link': 'https://opendev.org/openstack/keystone/commit/9033ab3ae915ae110d81b3275a31fcce457d4678', 'message': ""WIP sql: Don't rely on globals to configure enginefacades\n\nI can't figure out what test is causing a conflict with the update\nmigration tests in the alembic migration series but the root cause is\nthe use of global enginefacades. We can't remove the global enginefacade\nsince those things are supposed to be global, but we can rely on monkey\npatching rather than a single enginefacade that we need to patch.\n\nWIP because I've clearly missed something as we're seeing Foreign Key\nConstraint failures when creating projects. I would assume this is\nbecause the parent project isn't being created.\n\nChange-Id: I98a68caa5493839f8dea007308bd031693115848\nSigned-off-by: Stephen Finucane <sfinucan@redhat.com>\n""}]",1,846368,9033ab3ae915ae110d81b3275a31fcce457d4678,4,1,1,15334,,,0,"WIP sql: Don't rely on globals to configure enginefacades

I can't figure out what test is causing a conflict with the update
migration tests in the alembic migration series but the root cause is
the use of global enginefacades. We can't remove the global enginefacade
since those things are supposed to be global, but we can rely on monkey
patching rather than a single enginefacade that we need to patch.

WIP because I've clearly missed something as we're seeing Foreign Key
Constraint failures when creating projects. I would assume this is
because the parent project isn't being created.

Change-Id: I98a68caa5493839f8dea007308bd031693115848
Signed-off-by: Stephen Finucane <sfinucan@redhat.com>
",git fetch https://review.opendev.org/openstack/keystone refs/changes/68/846368/1 && git format-patch -1 --stdout FETCH_HEAD,"['keystone/common/sql/core.py', 'keystone/cmd/cli.py', 'keystone/common/sql/upgrades.py', 'keystone/tests/unit/identity/backends/test_sql.py', 'keystone/tests/unit/test_sql_banned_operations.py', 'keystone/tests/unit/ksfixtures/database.py', 'keystone/tests/unit/test_sql_upgrade.py']",7,9033ab3ae915ae110d81b3275a31fcce457d4678,remove-sqlalchemy-migrate," self.engine = engine self.engine, self.repo_path, self.min_version, self.engine, self.repo_name, target_repo_version=version, database.initialize_sql_session( self.engine.url, enforce_sqlite_fks=False, ) upgrades.get_db_version(self.engine, 'expand'), upgrades.get_db_version(self.engine, 'data_migration'), upgrades.get_db_version(self.engine, 'contract'), status = checker.check_db_sync_status(self.engine) status = checker.check_db_sync_status(self.engine) status = checker.check_db_sync_status(self.engine) status = checker.check_db_sync_status(self.engine) status = checker.check_db_sync_status(self.engine)"," engine, self.repo_path, self.min_version, self.repo_name, target_repo_version=version, self.sessionmaker = enginefacade.writer.get_sessionmaker() database.initialize_sql_session(self.engine.url, enforce_sqlite_fks=False) # Override keystone's context manager to be oslo.db's global context # manager. sql.core._TESTING_USE_GLOBAL_CONTEXT_MANAGER = True self.addCleanup(setattr, sql.core, '_TESTING_USE_GLOBAL_CONTEXT_MANAGER', False) self.addCleanup(sql.cleanup) upgrades.get_db_version('expand'), upgrades.get_db_version('data_migration'), upgrades.get_db_version('contract'), status = checker.check_db_sync_status() status = checker.check_db_sync_status() status = checker.check_db_sync_status() status = checker.check_db_sync_status() status = checker.check_db_sync_status()",103,127
openstack%2Freleases~887138,openstack/releases,master,I2ce9460d630d9af0aed04588d33e666ad4f30a75,Release neutron 21.1.2 and 22.0.2,MERGED,2023-06-28 06:30:21.000000000,2023-07-06 08:50:51.000000000,2023-07-06 08:50:51.000000000,"[{'_account_id': 308}, {'_account_id': 8313}, {'_account_id': 11975}, {'_account_id': 16688}, {'_account_id': 17685}, {'_account_id': 21798}, {'_account_id': 22348}, {'_account_id': 28522}]","[{'number': 1, 'created': '2023-06-28 06:30:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/releases/commit/a8308bca43cd686f812434287fd802d0a2c0d462', 'message': 'Release neutron 21.2.0 with important bug fix\n\nThis is required for fix release for bug/886680\n(https://review.opendev.org/c/openstack/neutron/+/886680)\n\nChange-Id: I2ce9460d630d9af0aed04588d33e666ad4f30a75\n'}, {'number': 2, 'created': '2023-06-28 06:59:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/releases/commit/d1f6bd6d2e886a4a16c6c8e384bb5993b4a38c93', 'message': 'Release neutron 21.2.0 and 22.1.0\n\nThis is required for fix release for bug/886680\n(https://review.opendev.org/c/openstack/neutron/+/886680)\n\nChange-Id: I2ce9460d630d9af0aed04588d33e666ad4f30a75\n'}, {'number': 3, 'created': '2023-06-28 14:31:42.000000000', 'files': ['deliverables/zed/neutron.yaml', 'deliverables/antelope/neutron.yaml'], 'web_link': 'https://opendev.org/openstack/releases/commit/3d35def94b658a5fecade412398ae9caf8a1c7bd', 'message': 'Release neutron 21.1.2 and 22.0.2\n\nThis is required for fix release for bug/886680\n(https://review.opendev.org/c/openstack/neutron/+/886680)\n\nChange-Id: I2ce9460d630d9af0aed04588d33e666ad4f30a75\n'}]",7,887138,3d35def94b658a5fecade412398ae9caf8a1c7bd,20,8,3,12404,,,0,"Release neutron 21.1.2 and 22.0.2

This is required for fix release for bug/886680
(https://review.opendev.org/c/openstack/neutron/+/886680)

Change-Id: I2ce9460d630d9af0aed04588d33e666ad4f30a75
",git fetch https://review.opendev.org/openstack/releases refs/changes/38/887138/1 && git format-patch -1 --stdout FETCH_HEAD,['deliverables/zed/neutron.yaml'],1,a8308bca43cd686f812434287fd802d0a2c0d462,release-neutron, - version: 21.2.0 projects: - repo: openstack/neutron hash: d539460ab59e13e7ac9eced80e871b5055912dc3,,4,0
openstack%2Freleases~887491,openstack/releases,master,I62874663f891d0536042af7411048e0205ae635b,Bobcat-2 release for oslo.utils,MERGED,2023-07-03 09:55:08.000000000,2023-07-06 08:50:46.000000000,2023-07-06 08:50:46.000000000,"[{'_account_id': 308}, {'_account_id': 1131}, {'_account_id': 22348}, {'_account_id': 28522}, {'_account_id': 31245}]","[{'number': 1, 'created': '2023-07-03 09:55:08.000000000', 'files': ['deliverables/bobcat/oslo.utils.yaml'], 'web_link': 'https://opendev.org/openstack/releases/commit/c16a9595cae7bc8a321cdbc173e2e8324eebe081', 'message': 'Bobcat-2 release for oslo.utils\n\nThis is the Bobcat-2 milestone release for oslo.utils.\nClients and libraries following the cycle-with-intermediary release\nmodel are encouraged to release each milestone to make sure updates\nare made available.\n\nIf the team is happy with the current release hash, please +1 this\npatch and we will process the release. If you need to get some\nimportant changes merged first, leave a -1 and update the patch with\na new commit hash to use once it is ready.\n\nIf a release is definitely not wanted at this time, please -1 and\nleave a comment explaining that and we can abandon the patch.\n\nAny patches with no response will be assumed to be OK and will be\nprocessed after July 6th.\n\nChange-Id: I62874663f891d0536042af7411048e0205ae635b\nSigned-off-by: Elod Illes <elod.illes@est.tech>\n'}]",0,887491,c16a9595cae7bc8a321cdbc173e2e8324eebe081,9,5,1,17685,,,0,"Bobcat-2 release for oslo.utils

This is the Bobcat-2 milestone release for oslo.utils.
Clients and libraries following the cycle-with-intermediary release
model are encouraged to release each milestone to make sure updates
are made available.

If the team is happy with the current release hash, please +1 this
patch and we will process the release. If you need to get some
important changes merged first, leave a -1 and update the patch with
a new commit hash to use once it is ready.

If a release is definitely not wanted at this time, please -1 and
leave a comment explaining that and we can abandon the patch.

Any patches with no response will be assumed to be OK and will be
processed after July 6th.

Change-Id: I62874663f891d0536042af7411048e0205ae635b
Signed-off-by: Elod Illes <elod.illes@est.tech>
",git fetch https://review.opendev.org/openstack/releases refs/changes/91/887491/1 && git format-patch -1 --stdout FETCH_HEAD,['deliverables/bobcat/oslo.utils.yaml'],1,c16a9595cae7bc8a321cdbc173e2e8324eebe081,bobcat-milestone-2,releases: - version: 6.2.0 projects: - repo: openstack/oslo.utils hash: 8115085dac49b005b623a74339eddc2bd9e096ce,,5,0
openstack%2Freleases~887501,openstack/releases,master,I45bcf5d20445972177e1df7dca3eb53a64b7f932,Bobcat-2 release for tosca-parser,MERGED,2023-07-03 10:20:05.000000000,2023-07-06 08:50:44.000000000,2023-07-06 08:50:44.000000000,"[{'_account_id': 308}, {'_account_id': 22348}, {'_account_id': 25701}, {'_account_id': 28522}]","[{'number': 1, 'created': '2023-07-03 10:20:05.000000000', 'files': ['deliverables/bobcat/tosca-parser.yaml'], 'web_link': 'https://opendev.org/openstack/releases/commit/3edc18f15a3e53b12c3680d831df7a981585bb1b', 'message': 'Bobcat-2 release for tosca-parser\n\nThis is the Bobcat-2 milestone release for tosca-parser.\nClients and libraries following the cycle-with-intermediary release\nmodel are encouraged to release each milestone to make sure updates\nare made available.\n\nIf the team is happy with the current release hash, please +1 this\npatch and we will process the release. If you need to get some\nimportant changes merged first, leave a -1 and update the patch with\na new commit hash to use once it is ready.\n\nIf a release is definitely not wanted at this time, please -1 and\nleave a comment explaining that and we can abandon the patch.\n\nAny patches with no response will be assumed to be OK and will be\nprocessed after July 6th.\n\nChange-Id: I45bcf5d20445972177e1df7dca3eb53a64b7f932\nSigned-off-by: Elod Illes <elod.illes@est.tech>\n'}]",0,887501,3edc18f15a3e53b12c3680d831df7a981585bb1b,9,4,1,17685,,,0,"Bobcat-2 release for tosca-parser

This is the Bobcat-2 milestone release for tosca-parser.
Clients and libraries following the cycle-with-intermediary release
model are encouraged to release each milestone to make sure updates
are made available.

If the team is happy with the current release hash, please +1 this
patch and we will process the release. If you need to get some
important changes merged first, leave a -1 and update the patch with
a new commit hash to use once it is ready.

If a release is definitely not wanted at this time, please -1 and
leave a comment explaining that and we can abandon the patch.

Any patches with no response will be assumed to be OK and will be
processed after July 6th.

Change-Id: I45bcf5d20445972177e1df7dca3eb53a64b7f932
Signed-off-by: Elod Illes <elod.illes@est.tech>
",git fetch https://review.opendev.org/openstack/releases refs/changes/01/887501/1 && git format-patch -1 --stdout FETCH_HEAD,['deliverables/bobcat/tosca-parser.yaml'],1,3edc18f15a3e53b12c3680d831df7a981585bb1b,bobcat-milestone-2,releases: - version: 2.9.0 projects: - repo: openstack/tosca-parser hash: 6c919b777ddb1d1ffa0758bc25d60d57eedb5d59,,5,0
openstack%2Freleases~887497,openstack/releases,master,I49a0d84f09177dfba153bd1ec62c698c77bae4ea,Bobcat-2 release for python-ironicclient,MERGED,2023-07-03 10:03:55.000000000,2023-07-06 08:50:42.000000000,2023-07-06 08:50:42.000000000,"[{'_account_id': 308}, {'_account_id': 10342}, {'_account_id': 15519}, {'_account_id': 22348}, {'_account_id': 23851}, {'_account_id': 28522}]","[{'number': 1, 'created': '2023-07-03 10:03:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/releases/commit/ba8ab05b24da13c34977373c3846b7f874bce126', 'message': 'Bobcat-2 release for python-ironicclient\n\nThis is the Bobcat-2 milestone release for python-ironicclient.\nClients and libraries following the cycle-with-intermediary release\nmodel are encouraged to release each milestone to make sure updates\nare made available.\n\nIf the team is happy with the current release hash, please +1 this\npatch and we will process the release. If you need to get some\nimportant changes merged first, leave a -1 and update the patch with\na new commit hash to use once it is ready.\n\nIf a release is definitely not wanted at this time, please -1 and\nleave a comment explaining that and we can abandon the patch.\n\nAny patches with no response will be assumed to be OK and will be\nprocessed after July 6th.\n\nChange-Id: I49a0d84f09177dfba153bd1ec62c698c77bae4ea\nSigned-off-by: Elod Illes <elod.illes@est.tech>\n'}, {'number': 2, 'created': '2023-07-05 17:37:01.000000000', 'files': ['deliverables/bobcat/python-ironicclient.yaml'], 'web_link': 'https://opendev.org/openstack/releases/commit/c10ebeefebbb59c7c0ad65cdbbf303057d930fab', 'message': 'Bobcat-2 release for python-ironicclient\n\nThis is the Bobcat-2 milestone release for python-ironicclient.\nClients and libraries following the cycle-with-intermediary release\nmodel are encouraged to release each milestone to make sure updates\nare made available.\n\nIf the team is happy with the current release hash, please +1 this\npatch and we will process the release. If you need to get some\nimportant changes merged first, leave a -1 and update the patch with\na new commit hash to use once it is ready.\n\nIf a release is definitely not wanted at this time, please -1 and\nleave a comment explaining that and we can abandon the patch.\n\nAny patches with no response will be assumed to be OK and will be\nprocessed after July 6th.\n\nChange-Id: I49a0d84f09177dfba153bd1ec62c698c77bae4ea\nSigned-off-by: Elod Illes <elod.illes@est.tech>\n'}]",2,887497,c10ebeefebbb59c7c0ad65cdbbf303057d930fab,14,6,2,17685,,,0,"Bobcat-2 release for python-ironicclient

This is the Bobcat-2 milestone release for python-ironicclient.
Clients and libraries following the cycle-with-intermediary release
model are encouraged to release each milestone to make sure updates
are made available.

If the team is happy with the current release hash, please +1 this
patch and we will process the release. If you need to get some
important changes merged first, leave a -1 and update the patch with
a new commit hash to use once it is ready.

If a release is definitely not wanted at this time, please -1 and
leave a comment explaining that and we can abandon the patch.

Any patches with no response will be assumed to be OK and will be
processed after July 6th.

Change-Id: I49a0d84f09177dfba153bd1ec62c698c77bae4ea
Signed-off-by: Elod Illes <elod.illes@est.tech>
",git fetch https://review.opendev.org/openstack/releases refs/changes/97/887497/1 && git format-patch -1 --stdout FETCH_HEAD,['deliverables/bobcat/python-ironicclient.yaml'],1,ba8ab05b24da13c34977373c3846b7f874bce126,bobcat-milestone-2, - version: 5.3.0 projects: - repo: openstack/python-ironicclient hash: dd8e146a4cec8d0f2d2ab3fc40a19e5d3384edcb,,4,0
openstack%2Ftripleo-common~887676,openstack/tripleo-common,stable/train,I04f6ac171b10af7a294819d6248eac641090cc49,Only modify the container manifest if the mediaType has changed.,MERGED,2023-07-05 16:42:45.000000000,2023-07-06 08:50:41.000000000,2023-07-06 08:49:44.000000000,"[{'_account_id': 9816}, {'_account_id': 22348}]","[{'number': 1, 'created': '2023-07-05 16:42:45.000000000', 'files': ['tripleo_common/image/image_uploader.py'], 'web_link': 'https://opendev.org/openstack/tripleo-common/commit/464aad0ab84ef8f795905d7a10349593931703ed', 'message': 'Only modify the container manifest if the mediaType has changed.\n\nOnly modify the manifest if the mediaType has actually changed.  This is a\npartial fix for https://bugzilla.redhat.com/show_bug.cgi?id=2213672 where the\njson pretty print with indent=3 causes the SHA256 of the manifest to change\nsince the manifest is not pretty printed the same way in the source registry.\n\nWhen the SHA256 changes, the above bug is triggered since the code does\nnot account for the fact that the httpd type-map file also needs to be\nupdated to use the changed SHA256.\n\nThis will need to be backported to stable/train as well.\n\nChange-Id: I04f6ac171b10af7a294819d6248eac641090cc49\nSigned-off-by: James Slagle <jslagle@redhat.com>\n(cherry picked from commit b0962d2ba09fbb4da33daa328e6a50cac5e3ba05)\n'}]",0,887676,464aad0ab84ef8f795905d7a10349593931703ed,7,2,1,7144,,,0,"Only modify the container manifest if the mediaType has changed.

Only modify the manifest if the mediaType has actually changed.  This is a
partial fix for https://bugzilla.redhat.com/show_bug.cgi?id=2213672 where the
json pretty print with indent=3 causes the SHA256 of the manifest to change
since the manifest is not pretty printed the same way in the source registry.

When the SHA256 changes, the above bug is triggered since the code does
not account for the fact that the httpd type-map file also needs to be
updated to use the changed SHA256.

This will need to be backported to stable/train as well.

Change-Id: I04f6ac171b10af7a294819d6248eac641090cc49
Signed-off-by: James Slagle <jslagle@redhat.com>
(cherry picked from commit b0962d2ba09fbb4da33daa328e6a50cac5e3ba05)
",git fetch https://review.opendev.org/openstack/tripleo-common refs/changes/76/887676/1 && git format-patch -1 --stdout FETCH_HEAD,['tripleo_common/image/image_uploader.py'],1,464aad0ab84ef8f795905d7a10349593931703ed,," new_manifest_type = manifest_type set_config_MediaType = False new_layers = [] new_manifest_type = MEDIA_MANIFEST_V2 set_config_MediaType = True new_manifest_type = MEDIA_MANIFEST_V2 elif manifest_type == MEDIA_OCI_INDEX_V1: new_manifest_type = MEDIA_MANIFEST_V2_LIST # Only modify the manifest if the mediaType has actually changed. # This is a partial fix for # https://bugzilla.redhat.com/show_bug.cgi?id=2213672 # where the json pretty print with indent=3 causes the SHA256 of # the manifest to change since the manifest is not pretty printed # the same way in the source registry. if (manifest_type != new_manifest_type or set_config_MediaType or new_layers): manifest['mediaType'] = new_manifest_type manifest_str = json.dumps(manifest, indent=3) new_manifest_type, (image, new_manifest_type, manifest_url)) 'Content-Type': new_manifest_type"," manifest_type = MEDIA_MANIFEST_V2 new_layers = [] manifest_type = MEDIA_MANIFEST_V2 elif manifest_type == MEDIA_OCI_INDEX_V1: manifest_type = MEDIA_MANIFEST_V2_LIST manifest['mediaType'] = manifest_type manifest_str = json.dumps(manifest, indent=3) manifest_type, (image, manifest_type, manifest_url)) 'Content-Type': manifest_type",22,9
openstack%2Freleases~887499,openstack/releases,master,Iedc29697b241eaf003d1a20db1d88c1b6f8075d2,Bobcat-2 release for python-neutronclient,MERGED,2023-07-03 10:11:33.000000000,2023-07-06 08:30:16.000000000,2023-07-06 08:30:16.000000000,"[{'_account_id': 11975}, {'_account_id': 16688}, {'_account_id': 17685}, {'_account_id': 22348}, {'_account_id': 28522}, {'_account_id': 32029}]","[{'number': 1, 'created': '2023-07-03 10:11:33.000000000', 'files': ['deliverables/bobcat/python-neutronclient.yaml'], 'web_link': 'https://opendev.org/openstack/releases/commit/b3e3e3bc3ecf2c726f6f6153498a4872f95e4540', 'message': 'Bobcat-2 release for python-neutronclient\n\nThis is the Bobcat-2 milestone release for python-neutronclient.\nClients and libraries following the cycle-with-intermediary release\nmodel are encouraged to release each milestone to make sure updates\nare made available.\n\nIf the team is happy with the current release hash, please +1 this\npatch and we will process the release. If you need to get some\nimportant changes merged first, leave a -1 and update the patch with\na new commit hash to use once it is ready.\n\nIf a release is definitely not wanted at this time, please -1 and\nleave a comment explaining that and we can abandon the patch.\n\nAny patches with no response will be assumed to be OK and will be\nprocessed after July 6th.\n\nChange-Id: Iedc29697b241eaf003d1a20db1d88c1b6f8075d2\nSigned-off-by: Elod Illes <elod.illes@est.tech>\n'}]",1,887499,b3e3e3bc3ecf2c726f6f6153498a4872f95e4540,11,6,1,17685,,,0,"Bobcat-2 release for python-neutronclient

This is the Bobcat-2 milestone release for python-neutronclient.
Clients and libraries following the cycle-with-intermediary release
model are encouraged to release each milestone to make sure updates
are made available.

If the team is happy with the current release hash, please +1 this
patch and we will process the release. If you need to get some
important changes merged first, leave a -1 and update the patch with
a new commit hash to use once it is ready.

If a release is definitely not wanted at this time, please -1 and
leave a comment explaining that and we can abandon the patch.

Any patches with no response will be assumed to be OK and will be
processed after July 6th.

Change-Id: Iedc29697b241eaf003d1a20db1d88c1b6f8075d2
Signed-off-by: Elod Illes <elod.illes@est.tech>
",git fetch https://review.opendev.org/openstack/releases refs/changes/99/887499/1 && git format-patch -1 --stdout FETCH_HEAD,['deliverables/bobcat/python-neutronclient.yaml'],1,b3e3e3bc3ecf2c726f6f6153498a4872f95e4540,bobcat-milestone-2, - version: 11.0.0 projects: - repo: openstack/python-neutronclient hash: d4976152401907b94d50a1ec3ad473fbe7c32dad,,4,0
openstack%2Freleases~887492,openstack/releases,master,I42f7f568e413cb42d22ea7158d87d27dd20e2fb6,Bobcat-2 release for ovsdbapp,MERGED,2023-07-03 09:56:49.000000000,2023-07-06 08:30:14.000000000,2023-07-06 08:30:14.000000000,"[{'_account_id': 5756}, {'_account_id': 6773}, {'_account_id': 8313}, {'_account_id': 11975}, {'_account_id': 16688}, {'_account_id': 17685}, {'_account_id': 22348}, {'_account_id': 28522}, {'_account_id': 32029}]","[{'number': 1, 'created': '2023-07-03 09:56:49.000000000', 'files': ['deliverables/bobcat/ovsdbapp.yaml'], 'web_link': 'https://opendev.org/openstack/releases/commit/50685947088b37849f6021ab3f2b086db4bec228', 'message': 'Bobcat-2 release for ovsdbapp\n\nThis is the Bobcat-2 milestone release for ovsdbapp.\nClients and libraries following the cycle-with-intermediary release\nmodel are encouraged to release each milestone to make sure updates\nare made available.\n\nIf the team is happy with the current release hash, please +1 this\npatch and we will process the release. If you need to get some\nimportant changes merged first, leave a -1 and update the patch with\na new commit hash to use once it is ready.\n\nIf a release is definitely not wanted at this time, please -1 and\nleave a comment explaining that and we can abandon the patch.\n\nAny patches with no response will be assumed to be OK and will be\nprocessed after July 6th.\n\nChange-Id: I42f7f568e413cb42d22ea7158d87d27dd20e2fb6\nSigned-off-by: Elod Illes <elod.illes@est.tech>\n'}]",1,887492,50685947088b37849f6021ab3f2b086db4bec228,13,9,1,17685,,,0,"Bobcat-2 release for ovsdbapp

This is the Bobcat-2 milestone release for ovsdbapp.
Clients and libraries following the cycle-with-intermediary release
model are encouraged to release each milestone to make sure updates
are made available.

If the team is happy with the current release hash, please +1 this
patch and we will process the release. If you need to get some
important changes merged first, leave a -1 and update the patch with
a new commit hash to use once it is ready.

If a release is definitely not wanted at this time, please -1 and
leave a comment explaining that and we can abandon the patch.

Any patches with no response will be assumed to be OK and will be
processed after July 6th.

Change-Id: I42f7f568e413cb42d22ea7158d87d27dd20e2fb6
Signed-off-by: Elod Illes <elod.illes@est.tech>
",git fetch https://review.opendev.org/openstack/releases refs/changes/92/887492/1 && git format-patch -1 --stdout FETCH_HEAD,['deliverables/bobcat/ovsdbapp.yaml'],1,50685947088b37849f6021ab3f2b086db4bec228,bobcat-milestone-2, - version: 2.4.0 projects: - repo: openstack/ovsdbapp hash: d542e5cee1c41703c0edb3e206c36c1392a57028,,4,0
openstack%2Freleases~887500,openstack/releases,master,I65447a5b4897567c9524e28a049919a2b73ff635,Bobcat-2 release for python-troveclient,MERGED,2023-07-03 10:14:18.000000000,2023-07-06 08:30:11.000000000,2023-07-06 08:30:11.000000000,"[{'_account_id': 6732}, {'_account_id': 17685}, {'_account_id': 22348}, {'_account_id': 26285}, {'_account_id': 28522}]","[{'number': 1, 'created': '2023-07-03 10:14:18.000000000', 'files': ['deliverables/bobcat/python-troveclient.yaml'], 'web_link': 'https://opendev.org/openstack/releases/commit/caf258893c187ba266760c213d0f1be5a53945f3', 'message': 'Bobcat-2 release for python-troveclient\n\nThis is the Bobcat-2 milestone release for python-troveclient.\nClients and libraries following the cycle-with-intermediary release\nmodel are encouraged to release each milestone to make sure updates\nare made available.\n\nIf the team is happy with the current release hash, please +1 this\npatch and we will process the release. If you need to get some\nimportant changes merged first, leave a -1 and update the patch with\na new commit hash to use once it is ready.\n\nIf a release is definitely not wanted at this time, please -1 and\nleave a comment explaining that and we can abandon the patch.\n\nAny patches with no response will be assumed to be OK and will be\nprocessed after July 6th.\n\nChange-Id: I65447a5b4897567c9524e28a049919a2b73ff635\nSigned-off-by: Elod Illes <elod.illes@est.tech>\n'}]",1,887500,caf258893c187ba266760c213d0f1be5a53945f3,9,5,1,17685,,,0,"Bobcat-2 release for python-troveclient

This is the Bobcat-2 milestone release for python-troveclient.
Clients and libraries following the cycle-with-intermediary release
model are encouraged to release each milestone to make sure updates
are made available.

If the team is happy with the current release hash, please +1 this
patch and we will process the release. If you need to get some
important changes merged first, leave a -1 and update the patch with
a new commit hash to use once it is ready.

If a release is definitely not wanted at this time, please -1 and
leave a comment explaining that and we can abandon the patch.

Any patches with no response will be assumed to be OK and will be
processed after July 6th.

Change-Id: I65447a5b4897567c9524e28a049919a2b73ff635
Signed-off-by: Elod Illes <elod.illes@est.tech>
",git fetch https://review.opendev.org/openstack/releases refs/changes/00/887500/1 && git format-patch -1 --stdout FETCH_HEAD,['deliverables/bobcat/python-troveclient.yaml'],1,caf258893c187ba266760c213d0f1be5a53945f3,bobcat-milestone-2,releases: - version: 8.2.0 projects: - repo: openstack/python-troveclient hash: b739fe40ad3720c00dc290ef5c2354169bb54865,,5,0
openstack%2Freleases~887485,openstack/releases,master,I82779805f32939fb4fdf404875a41361501d2a78,Bobcat-2 release for octavia-lib,MERGED,2023-07-03 09:36:15.000000000,2023-07-06 08:30:09.000000000,2023-07-06 08:30:09.000000000,"[{'_account_id': 6469}, {'_account_id': 11628}, {'_account_id': 17685}, {'_account_id': 22348}, {'_account_id': 28522}, {'_account_id': 29244}]","[{'number': 1, 'created': '2023-07-03 09:36:15.000000000', 'files': ['deliverables/bobcat/octavia-lib.yaml'], 'web_link': 'https://opendev.org/openstack/releases/commit/c3799f79dcc13a45683ee59768392c7c563c178c', 'message': 'Bobcat-2 release for octavia-lib\n\nThis is the Bobcat-2 milestone release for octavia-lib.\nClients and libraries following the cycle-with-intermediary release\nmodel are encouraged to release each milestone to make sure updates\nare made available.\n\nIf the team is happy with the current release hash, please +1 this\npatch and we will process the release. If you need to get some\nimportant changes merged first, leave a -1 and update the patch with\na new commit hash to use once it is ready.\n\nIf a release is definitely not wanted at this time, please -1 and\nleave a comment explaining that and we can abandon the patch.\n\nAny patches with no response will be assumed to be OK and will be\nprocessed after July 6th.\n\nChange-Id: I82779805f32939fb4fdf404875a41361501d2a78\nSigned-off-by: Elod Illes <elod.illes@est.tech>\n'}]",3,887485,c3799f79dcc13a45683ee59768392c7c563c178c,9,6,1,17685,,,0,"Bobcat-2 release for octavia-lib

This is the Bobcat-2 milestone release for octavia-lib.
Clients and libraries following the cycle-with-intermediary release
model are encouraged to release each milestone to make sure updates
are made available.

If the team is happy with the current release hash, please +1 this
patch and we will process the release. If you need to get some
important changes merged first, leave a -1 and update the patch with
a new commit hash to use once it is ready.

If a release is definitely not wanted at this time, please -1 and
leave a comment explaining that and we can abandon the patch.

Any patches with no response will be assumed to be OK and will be
processed after July 6th.

Change-Id: I82779805f32939fb4fdf404875a41361501d2a78
Signed-off-by: Elod Illes <elod.illes@est.tech>
",git fetch https://review.opendev.org/openstack/releases refs/changes/85/887485/1 && git format-patch -1 --stdout FETCH_HEAD,['deliverables/bobcat/octavia-lib.yaml'],1,c3799f79dcc13a45683ee59768392c7c563c178c,bobcat-milestone-2,releases: - version: 3.3.0 projects: - repo: openstack/octavia-lib hash: bad19004b09dd6daf1b6db0a6f96545790a08336,,5,0
openstack%2Freleases~887494,openstack/releases,master,If82d7a0224afbdd5542ac5149479e7dd89f56036,Bobcat-2 release for python-cyborgclient,MERGED,2023-07-03 10:00:32.000000000,2023-07-06 08:28:13.000000000,2023-07-06 08:28:13.000000000,"[{'_account_id': 13629}, {'_account_id': 17685}, {'_account_id': 22348}, {'_account_id': 26458}, {'_account_id': 28522}, {'_account_id': 31412}]","[{'number': 1, 'created': '2023-07-03 10:00:32.000000000', 'files': ['deliverables/bobcat/python-cyborgclient.yaml'], 'web_link': 'https://opendev.org/openstack/releases/commit/49acd2f24bfa1db189cd5ed119b04edee1441019', 'message': 'Bobcat-2 release for python-cyborgclient\n\nThis is the Bobcat-2 milestone release for python-cyborgclient.\nClients and libraries following the cycle-with-intermediary release\nmodel are encouraged to release each milestone to make sure updates\nare made available.\n\nIf the team is happy with the current release hash, please +1 this\npatch and we will process the release. If you need to get some\nimportant changes merged first, leave a -1 and update the patch with\na new commit hash to use once it is ready.\n\nIf a release is definitely not wanted at this time, please -1 and\nleave a comment explaining that and we can abandon the patch.\n\nAny patches with no response will be assumed to be OK and will be\nprocessed after July 6th.\n\nChange-Id: If82d7a0224afbdd5542ac5149479e7dd89f56036\nSigned-off-by: Elod Illes <elod.illes@est.tech>\n'}]",1,887494,49acd2f24bfa1db189cd5ed119b04edee1441019,9,6,1,17685,,,0,"Bobcat-2 release for python-cyborgclient

This is the Bobcat-2 milestone release for python-cyborgclient.
Clients and libraries following the cycle-with-intermediary release
model are encouraged to release each milestone to make sure updates
are made available.

If the team is happy with the current release hash, please +1 this
patch and we will process the release. If you need to get some
important changes merged first, leave a -1 and update the patch with
a new commit hash to use once it is ready.

If a release is definitely not wanted at this time, please -1 and
leave a comment explaining that and we can abandon the patch.

Any patches with no response will be assumed to be OK and will be
processed after July 6th.

Change-Id: If82d7a0224afbdd5542ac5149479e7dd89f56036
Signed-off-by: Elod Illes <elod.illes@est.tech>
",git fetch https://review.opendev.org/openstack/releases refs/changes/94/887494/1 && git format-patch -1 --stdout FETCH_HEAD,['deliverables/bobcat/python-cyborgclient.yaml'],1,49acd2f24bfa1db189cd5ed119b04edee1441019,bobcat-milestone-2,releases: - version: 2.2.0 projects: - repo: openstack/python-cyborgclient hash: 8a1428b88ad66caa0c5e3fed8e008ff297cd83c9,,5,0
openstack%2Freleases~887763,openstack/releases,master,Id20e2a481e7bc408e74d4ca98a96be0aedb3895a,release oslo.utils 6.2.0,ABANDONED,2023-07-06 07:49:26.000000000,2023-07-06 08:05:46.000000000,,[{'_account_id': 22348}],"[{'number': 1, 'created': '2023-07-06 07:49:26.000000000', 'files': ['deliverables/bobcat/oslo.utils.yaml'], 'web_link': 'https://opendev.org/openstack/releases/commit/847e3bac362557385531f572216d80fb283ae762', 'message': 'release oslo.utils 6.2.0\n\nChange-Id: Id20e2a481e7bc408e74d4ca98a96be0aedb3895a\n'}]",0,887763,847e3bac362557385531f572216d80fb283ae762,4,1,1,28522,,,0,"release oslo.utils 6.2.0

Change-Id: Id20e2a481e7bc408e74d4ca98a96be0aedb3895a
",git fetch https://review.opendev.org/openstack/releases refs/changes/63/887763/1 && git format-patch -1 --stdout FETCH_HEAD,['deliverables/bobcat/oslo.utils.yaml'],1,847e3bac362557385531f572216d80fb283ae762,oslo-bobcat,releases: - version: 6.2.0 projects: - repo: openstack/oslo.utils hash: 8115085dac49b005b623a74339eddc2bd9e096ce,,5,0
openstack%2Fcharms.openstack~876455,openstack/charms.openstack,stable/21.10,I491ca9f482a00b7ca3fa44aa8c26ef73559c178f,Use unittest.mock instead of mock,ABANDONED,2023-03-04 05:41:43.000000000,2023-07-06 07:20:02.000000000,,[{'_account_id': 22348}],"[{'number': 1, 'created': '2023-03-04 05:41:43.000000000', 'files': ['unit_tests/charms_openstack/plugins/test_adapters.py', 'test-requirements.txt', 'charms_openstack/test_mocks.py', 'unit_tests/charms_openstack/charm/test_core.py', 'unit_tests/__init__.py', 'unit_tests/charms_openstack/charm/test_defaults.py', 'unit_tests/charms_openstack/charm/utils.py', 'unit_tests/utils.py', 'unit_tests/test_charms_openstack_bus.py', 'unit_tests/test_charms_openstack_devices_pci.py', 'unit_tests/charms_openstack/plugins/test_classes.py', 'unit_tests/test_charms_openstack_adapters.py', 'charms_openstack/test_utils.py', 'unit_tests/charms_openstack/charm/test_classes.py'], 'web_link': 'https://opendev.org/openstack/charms.openstack/commit/5e3300338ae6e4450432794709041f11f460ad32', 'message': 'Use unittest.mock instead of mock\n\nThe mock third party library was needed for mock support in py2\nruntimes. Since we now only support py36 and later, we can use the\nstandard lib unittest.mock module instead.\n\nChange-Id: I491ca9f482a00b7ca3fa44aa8c26ef73559c178f\n(cherry picked from commit 2812f9f6649d809e80bc66bee4a12509fef6bb0d)\n'}]",0,876455,5e3300338ae6e4450432794709041f11f460ad32,3,1,1,5112,,,0,"Use unittest.mock instead of mock

The mock third party library was needed for mock support in py2
runtimes. Since we now only support py36 and later, we can use the
standard lib unittest.mock module instead.

Change-Id: I491ca9f482a00b7ca3fa44aa8c26ef73559c178f
(cherry picked from commit 2812f9f6649d809e80bc66bee4a12509fef6bb0d)
",git fetch https://review.opendev.org/openstack/charms.openstack refs/changes/55/876455/1 && git format-patch -1 --stdout FETCH_HEAD,"['unit_tests/charms_openstack/plugins/test_adapters.py', 'test-requirements.txt', 'charms_openstack/test_mocks.py', 'unit_tests/charms_openstack/charm/test_core.py', 'unit_tests/__init__.py', 'unit_tests/charms_openstack/charm/test_defaults.py', 'unit_tests/charms_openstack/charm/utils.py', 'unit_tests/utils.py', 'unit_tests/test_charms_openstack_bus.py', 'unit_tests/test_charms_openstack_devices_pci.py', 'unit_tests/charms_openstack/plugins/test_classes.py', 'unit_tests/test_charms_openstack_adapters.py', 'charms_openstack/test_utils.py', 'unit_tests/charms_openstack/charm/test_classes.py']",14,5e3300338ae6e4450432794709041f11f460ad32,drop_mock-stable/21.10,from unittest import mock,import mock,13,14
openstack%2Fcinder~866106,openstack/cinder,master,Ida8b41850bc6dfa8b000f72b71001badb3bb36ea,Volume State Update Failed After Backup Completed,NEW,2022-11-30 07:55:48.000000000,2023-07-06 06:00:07.000000000,,"[{'_account_id': 22348}, {'_account_id': 30615}]","[{'number': 1, 'created': '2022-11-30 07:55:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/40694eb9729d8b0ccddebf920f8150fdfcb2547a', 'message': ""Generally, after the backup is created, the state of the volume will be reset to the state before the backup. However, if we create a backup of a volume with status 'in-use'(attached to an instance). When backup creating, the instance get deleted, status will be set to in-use by error, but not reset to available.\n\nWhen an instance is deleted, the volume will be detached, and the volume status will be set to available. After that, the volume backup is completed, and the status of the volume is reset to in-use. The bug is caused by this.\n\nThis patch fix this by rechecking attachment status before resetting volume status.\nCloses-Bug: #1996039\n\nChange-Id: Ida8b41850bc6dfa8b000f72b71001badb3bb36ea\n""}, {'number': 2, 'created': '2022-11-30 07:58:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/228fca2c0d6d6d905ffc20f6b415f272c8319fee', 'message': ""Volume State Update Failed After Backup Completed\n\nGenerally, after the backup is created, the state of the volume will be reset to the state before the backup. However, if we create a backup of a volume with status 'in-use'(attached to an instance). When backup creating, the instance get deleted, status will be set to in-use by error, but not reset to available.\n\nWhen an instance is deleted, the volume will be detached, and the volume status will be set to available. After that, the volume backup is completed, and the status of the volume is reset to in-use. The bug is caused by this.\n\nThis patch fix this by rechecking attachment status before resetting volume status.\nCloses-Bug: #1996039\n\nChange-Id: Ida8b41850bc6dfa8b000f72b71001badb3bb36ea\n""}, {'number': 3, 'created': '2022-11-30 08:49:33.000000000', 'files': ['cinder/backup/manager.py', 'cinder/tests/unit/backup/test_backup.py', 'cinder/db/sqlalchemy/api.py'], 'web_link': 'https://opendev.org/openstack/cinder/commit/2acbb9286b913a1225f28fe3d877515d5ae60e63', 'message': ""Volume State Update Failed After Backup Completed\n\nGenerally, after the backup is created, the state of the volume will be reset to the state before the backup. However, if we create a backup of a volume with status 'in-use'(attached to an instance). When backup creating, the instance get deleted, status will be set to in-use by error, but not reset to available.\n\nWhen an instance is deleted, the volume will be detached, and the volume status will be set to available. After that, the volume backup is completed, and the status of the volume is reset to in-use. The bug is caused by this.\n\nThis patch fix this by rechecking attachment status before resetting volume status.\nCloses-Bug: #1996039\n\nChange-Id: Ida8b41850bc6dfa8b000f72b71001badb3bb36ea\n""}]",1,866106,2acbb9286b913a1225f28fe3d877515d5ae60e63,28,2,3,35495,,,0,"Volume State Update Failed After Backup Completed

Generally, after the backup is created, the state of the volume will be reset to the state before the backup. However, if we create a backup of a volume with status 'in-use'(attached to an instance). When backup creating, the instance get deleted, status will be set to in-use by error, but not reset to available.

When an instance is deleted, the volume will be detached, and the volume status will be set to available. After that, the volume backup is completed, and the status of the volume is reset to in-use. The bug is caused by this.

This patch fix this by rechecking attachment status before resetting volume status.
Closes-Bug: #1996039

Change-Id: Ida8b41850bc6dfa8b000f72b71001badb3bb36ea
",git fetch https://review.opendev.org/openstack/cinder refs/changes/06/866106/1 && git format-patch -1 --stdout FETCH_HEAD,"['cinder/backup/manager.py', 'cinder/db/sqlalchemy/api.py']",2,40694eb9729d8b0ccddebf920f8150fdfcb2547a,," # Hide volume status update to available on volume migration or upload # or backup, as status is updated later on those flows. or volume.status == 'backing-up'"," # Hide volume status update to available on volume migration or upload, # as status is updated later on those flows.",7,2
openstack%2Fdiskimage-builder~880567,openstack/diskimage-builder,master,I105d5440ee138ad3b751d8b5b7ed4a22863de9a9,Create a wildcard InfiniBand connection profile for IB interfaces,ABANDONED,2023-04-16 11:20:07.000000000,2023-07-06 05:46:08.000000000,,"[{'_account_id': 4571}, {'_account_id': 7118}, {'_account_id': 11655}, {'_account_id': 12171}, {'_account_id': 22348}, {'_account_id': 24245}, {'_account_id': 35001}]","[{'number': 1, 'created': '2023-04-16 11:20:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/diskimage-builder/commit/37d98a71f763fb4ecd2ac7f9f0c2edff2157b38c', 'message': ""Create a wildcard InfiniBand connection profile for IB interfaces\n\nCurrently, NetworkManager can't automatically create default\nconnection profiles for InfiniBand interfaces.\n\nSo, as a workaround, we are installing\nNetworkManager-system-connections-infiniband.nmconnection\nto NetworkManager to create a wildcard InfiniBand connection profile.\n\nThe content of NetworkManager-system-connections-infiniband.nmconnection\nis generated by running this command:\n`nmcli --offline connection add type infiniband connection.multi-connect multiple`\n\nChange-Id: I105d5440ee138ad3b751d8b5b7ed4a22863de9a9\n""}, {'number': 2, 'created': '2023-04-19 07:51:50.000000000', 'files': ['diskimage_builder/elements/dhcp-all-interfaces/README.rst', 'releasenotes/notes/bug-2016965-be1dafbe1ee03647.yaml', 'diskimage_builder/elements/dhcp-all-interfaces/install.d/NetworkManager-system-connections-infiniband.nmconnection', 'diskimage_builder/elements/dhcp-all-interfaces/install.d/50-dhcp-all-interfaces'], 'web_link': 'https://opendev.org/openstack/diskimage-builder/commit/0720af0bd645ea4082942bb576741b2eff59e69a', 'message': ""Create a wildcard InfiniBand connection profile for IB interfaces\n\nCurrently, NetworkManager can't automatically create default\nconnection profiles for InfiniBand interfaces.\n\nSo, as a workaround, we are installing\nNetworkManager-system-connections-infiniband.nmconnection\nto NetworkManager to create a wildcard InfiniBand connection profile.\n\nThe content of NetworkManager-system-connections-infiniband.nmconnection\nis generated by running this command:\n`nmcli --offline connection add type infiniband connection.multi-connect multiple`\n\nCloses-Bug: #2016965\nChange-Id: I105d5440ee138ad3b751d8b5b7ed4a22863de9a9\n""}]",6,880567,0720af0bd645ea4082942bb576741b2eff59e69a,20,7,2,25241,,,0,"Create a wildcard InfiniBand connection profile for IB interfaces

Currently, NetworkManager can't automatically create default
connection profiles for InfiniBand interfaces.

So, as a workaround, we are installing
NetworkManager-system-connections-infiniband.nmconnection
to NetworkManager to create a wildcard InfiniBand connection profile.

The content of NetworkManager-system-connections-infiniband.nmconnection
is generated by running this command:
`nmcli --offline connection add type infiniband connection.multi-connect multiple`

Closes-Bug: #2016965
Change-Id: I105d5440ee138ad3b751d8b5b7ed4a22863de9a9
",git fetch https://review.opendev.org/openstack/diskimage-builder refs/changes/67/880567/1 && git format-patch -1 --stdout FETCH_HEAD,"['diskimage_builder/elements/dhcp-all-interfaces/install.d/NetworkManager-system-connections-infiniband.nmconnection', 'diskimage_builder/elements/dhcp-all-interfaces/install.d/50-dhcp-all-interfaces']",2,37d98a71f763fb4ecd2ac7f9f0c2edff2157b38c,," # Because NetworkManager can't automatically create default connection # profiles for InfiniBand interfaces, we are installing # NetworkManager-system-connections-infiniband.nmconnection to # NetworkManager to create a wildcard InfiniBand connection profile install -D -g root -o root -m 0600 ${SCRIPTDIR}/NetworkManager-system-connections-infiniband.nmconnection /etc/NetworkManager/system-connections/infiniband.nmconnection ",,24,0
openstack%2Fcharm-cinder-k8s~887705,openstack/charm-cinder-k8s,stable/2023.1.1,I562374a15eb607090ee35b47819190a9aedee482,2023.1.1 release updates,MERGED,2023-07-05 14:43:42.000000000,2023-07-06 02:34:33.000000000,2023-07-06 02:08:18.000000000,"[{'_account_id': 10366}, {'_account_id': 22348}]","[{'number': 1, 'created': '2023-07-05 14:43:42.000000000', 'files': ['osci.yaml', '.gitreview', 'tests/bundles/smoke.yaml'], 'web_link': 'https://opendev.org/openstack/charm-cinder-k8s/commit/7b12bb3c49ca63394e43d7d96543bcf3d52e61db', 'message': '2023.1.1 release updates\n\nUpdate publishing target to push to candidate channel.\n\nRefresh bundles to deploy from candidate channel for testing.\n\nUpdate .gitreview default branch.\n\nChange-Id: I562374a15eb607090ee35b47819190a9aedee482\n'}]",0,887705,7b12bb3c49ca63394e43d7d96543bcf3d52e61db,7,2,1,935,,,0,"2023.1.1 release updates

Update publishing target to push to candidate channel.

Refresh bundles to deploy from candidate channel for testing.

Update .gitreview default branch.

Change-Id: I562374a15eb607090ee35b47819190a9aedee482
",git fetch https://review.opendev.org/openstack/charm-cinder-k8s refs/changes/05/887705/1 && git format-patch -1 --stdout FETCH_HEAD,"['osci.yaml', '.gitreview', 'tests/bundles/smoke.yaml']",3,7b12bb3c49ca63394e43d7d96543bcf3d52e61db,release/2023.1.1, channel: 3.9/candidate channel: 2023.1/candidate, channel: 3.9/edge channel: 2023.1/edge,4,4
openstack%2Fcharm-nova-k8s~887717,openstack/charm-nova-k8s,stable/2023.1.1,I1c79a4d74ad88425c40ea72e3dd9d2b14f51365f,2023.1.1 release updates,MERGED,2023-07-05 14:58:04.000000000,2023-07-06 02:32:25.000000000,2023-07-06 02:08:17.000000000,"[{'_account_id': 10366}, {'_account_id': 22348}]","[{'number': 1, 'created': '2023-07-05 14:58:04.000000000', 'files': ['osci.yaml', '.gitreview', 'tests/bundles/smoke.yaml'], 'web_link': 'https://opendev.org/openstack/charm-nova-k8s/commit/40e880c203eab4da5594c4f1fd8c800f1e7dd738', 'message': '2023.1.1 release updates\n\nUpdate publishing target to push to candidate channel.\n\nRefresh bundles to deploy from candidate channel for testing.\n\nUpdate .gitreview default branch.\n\nChange-Id: I1c79a4d74ad88425c40ea72e3dd9d2b14f51365f\n'}]",0,887717,40e880c203eab4da5594c4f1fd8c800f1e7dd738,7,2,1,935,,,0,"2023.1.1 release updates

Update publishing target to push to candidate channel.

Refresh bundles to deploy from candidate channel for testing.

Update .gitreview default branch.

Change-Id: I1c79a4d74ad88425c40ea72e3dd9d2b14f51365f
",git fetch https://review.opendev.org/openstack/charm-nova-k8s refs/changes/17/887717/1 && git format-patch -1 --stdout FETCH_HEAD,"['osci.yaml', '.gitreview', 'tests/bundles/smoke.yaml']",3,40e880c203eab4da5594c4f1fd8c800f1e7dd738,release/2023.1.1, channel: 3.9/candidate channel: 2023.1/candidate channel: 2023.1/candidate, channel: 3.9/edge channel: 2023.1/edge channel: 2023.1/edge,5,5
openstack%2Fcharm-cinder-ceph-k8s~887703,openstack/charm-cinder-ceph-k8s,stable/2023.1.1,I6398606791dd11863f5f33e9f018d76e3ed0402e,2023.1.1 release updates,MERGED,2023-07-05 14:40:29.000000000,2023-07-06 02:29:29.000000000,2023-07-06 02:08:19.000000000,"[{'_account_id': 10366}, {'_account_id': 20648}, {'_account_id': 22348}]","[{'number': 1, 'created': '2023-07-05 14:40:29.000000000', 'files': ['osci.yaml', '.gitreview', 'tests/bundles/smoke.yaml'], 'web_link': 'https://opendev.org/openstack/charm-cinder-ceph-k8s/commit/a4eec1921bfc5f2a3166c165a55643ac0296ff21', 'message': '2023.1.1 release updates\n\nUpdate publishing target to push to candidate channel.\n\nRefresh bundles to deploy from candidate channel for testing.\n\nUpdate .gitreview default branch.\n\nChange-Id: I6398606791dd11863f5f33e9f018d76e3ed0402e\n'}]",0,887703,a4eec1921bfc5f2a3166c165a55643ac0296ff21,8,3,1,935,,,0,"2023.1.1 release updates

Update publishing target to push to candidate channel.

Refresh bundles to deploy from candidate channel for testing.

Update .gitreview default branch.

Change-Id: I6398606791dd11863f5f33e9f018d76e3ed0402e
",git fetch https://review.opendev.org/openstack/charm-cinder-ceph-k8s refs/changes/03/887703/1 && git format-patch -1 --stdout FETCH_HEAD,"['osci.yaml', '.gitreview', 'tests/bundles/smoke.yaml']",3,a4eec1921bfc5f2a3166c165a55643ac0296ff21,release/2023.1.1, channel: 3.9/candidate channel: 2023.1/candidate channel: 2023.1/candidate, channel: 3.9/edge channel: 2023.1/edge channel: 2023.1/edge,5,5
openstack%2Fcharm-placement-k8s~887718,openstack/charm-placement-k8s,stable/2023.1.1,I806b1f0401f978394231861dd0d390801d8aa7e7,2023.1.1 release updates,MERGED,2023-07-05 14:59:53.000000000,2023-07-06 02:27:15.000000000,2023-07-06 02:10:42.000000000,"[{'_account_id': 10366}, {'_account_id': 22348}]","[{'number': 1, 'created': '2023-07-05 14:59:53.000000000', 'files': ['osci.yaml', '.gitreview', 'tests/bundles/smoke.yaml'], 'web_link': 'https://opendev.org/openstack/charm-placement-k8s/commit/e3f2d453d5c31a58657bfa2907478c0b0479bea1', 'message': '2023.1.1 release updates\n\nUpdate publishing target to push to candidate channel.\n\nRefresh bundles to deploy from candidate channel for testing.\n\nUpdate .gitreview default branch.\n\nChange-Id: I806b1f0401f978394231861dd0d390801d8aa7e7\n'}]",0,887718,e3f2d453d5c31a58657bfa2907478c0b0479bea1,7,2,1,935,,,0,"2023.1.1 release updates

Update publishing target to push to candidate channel.

Refresh bundles to deploy from candidate channel for testing.

Update .gitreview default branch.

Change-Id: I806b1f0401f978394231861dd0d390801d8aa7e7
",git fetch https://review.opendev.org/openstack/charm-placement-k8s refs/changes/18/887718/1 && git format-patch -1 --stdout FETCH_HEAD,"['osci.yaml', '.gitreview', 'tests/bundles/smoke.yaml']",3,e3f2d453d5c31a58657bfa2907478c0b0479bea1,release/2023.1.1, channel: 8.0/stable channel: 3.9/candidate channel: 2023.1/candidate channel: 2023.1/candidate, channel: edge channel: 3.9/edge channel: 2023.1/edge channel: 2023.1/edge,6,6
openstack%2Fcharm-keystone-k8s~887708,openstack/charm-keystone-k8s,stable/2023.1.1,Ia39724a6579841f7ef8282766990446ae466c1c8,2023.1.1 release updates,MERGED,2023-07-05 14:48:44.000000000,2023-07-06 02:24:53.000000000,2023-07-06 01:57:57.000000000,"[{'_account_id': 10366}, {'_account_id': 22348}]","[{'number': 1, 'created': '2023-07-05 14:48:44.000000000', 'files': ['osci.yaml', '.gitreview', 'tests/bundles/smoke.yaml'], 'web_link': 'https://opendev.org/openstack/charm-keystone-k8s/commit/d5ff9362c041e8d9e910be4edd2aeb98bb89f816', 'message': '2023.1.1 release updates\n\nUpdate publishing target to push to candidate channel.\n\nRefresh bundles to deploy from candidate channel for testing.\n\nUpdate .gitreview default branch.\n\nChange-Id: Ia39724a6579841f7ef8282766990446ae466c1c8\n'}]",0,887708,d5ff9362c041e8d9e910be4edd2aeb98bb89f816,7,2,1,935,,,0,"2023.1.1 release updates

Update publishing target to push to candidate channel.

Refresh bundles to deploy from candidate channel for testing.

Update .gitreview default branch.

Change-Id: Ia39724a6579841f7ef8282766990446ae466c1c8
",git fetch https://review.opendev.org/openstack/charm-keystone-k8s refs/changes/08/887708/1 && git format-patch -1 --stdout FETCH_HEAD,"['osci.yaml', '.gitreview', 'tests/bundles/smoke.yaml']",3,d5ff9362c041e8d9e910be4edd2aeb98bb89f816,release/2023.1.1, channel: 3.9/candidate channel: 2023.1/candidate, channel: 3.9/edge channel: 2023.1/edge,4,4
openstack%2Fcharm-neutron-k8s~887709,openstack/charm-neutron-k8s,stable/2023.1.1,Iaa6e08331ab95b0391518aa7d5971b5ee84af8d1,2023.1.1 release updates,MERGED,2023-07-05 14:50:24.000000000,2023-07-06 02:20:36.000000000,2023-07-06 02:06:52.000000000,"[{'_account_id': 10366}, {'_account_id': 22348}]","[{'number': 1, 'created': '2023-07-05 14:50:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-neutron-k8s/commit/e91cb5b04114441a3b2912c01d64d9c5ba491298', 'message': '2023.1.1 release updates\n\nUpdate publishing target to push to candidate channel.\n\nRefresh bundles to deploy from candidate channel for testing.\n\nUpdate .gitreview default branch.\n\nChange-Id: Iaa6e08331ab95b0391518aa7d5971b5ee84af8d1\n'}, {'number': 2, 'created': '2023-07-05 15:09:25.000000000', 'files': ['osci.yaml', '.gitreview', 'tests/bundles/smoke.yaml'], 'web_link': 'https://opendev.org/openstack/charm-neutron-k8s/commit/138f434d1d2753bb2e602146d10b4273f79a435c', 'message': '2023.1.1 release updates\n\nUpdate publishing target to push to candidate channel.\n\nRefresh bundles to deploy from candidate channel for testing.\n\nUpdate .gitreview default branch.\n\nChange-Id: Iaa6e08331ab95b0391518aa7d5971b5ee84af8d1\n'}]",0,887709,138f434d1d2753bb2e602146d10b4273f79a435c,9,2,2,935,,,0,"2023.1.1 release updates

Update publishing target to push to candidate channel.

Refresh bundles to deploy from candidate channel for testing.

Update .gitreview default branch.

Change-Id: Iaa6e08331ab95b0391518aa7d5971b5ee84af8d1
",git fetch https://review.opendev.org/openstack/charm-neutron-k8s refs/changes/09/887709/1 && git format-patch -1 --stdout FETCH_HEAD,"['osci.yaml', '.gitreview', 'tests/bundles/smoke.yaml']",3,e91cb5b04114441a3b2912c01d64d9c5ba491298,release/2023.1.1, channel: 3.9/candidate channel: yoga/candidate channel: 23.03/candidate channel: candidate, channel: 3.9/edge channel: yoga/edge channel: 23.03/edge channel: edge,6,6
openstack%2Fcharm-horizon-k8s~887707,openstack/charm-horizon-k8s,stable/2023.1.1,I8f4bceb4481143e4ecbb6bac3ebef1e88f5793cd,2023.1.1 release updates,MERGED,2023-07-05 14:46:50.000000000,2023-07-06 02:19:22.000000000,2023-07-06 02:03:28.000000000,"[{'_account_id': 10366}, {'_account_id': 20648}, {'_account_id': 22348}]","[{'number': 1, 'created': '2023-07-05 14:46:50.000000000', 'files': ['osci.yaml', '.gitreview'], 'web_link': 'https://opendev.org/openstack/charm-horizon-k8s/commit/6d979cda095e0786b06d77187c4b6ee7369580c2', 'message': '2023.1.1 release updates\n\nUpdate publishing target to push to candidate channel.\n\nUpdate .gitreview default branch.\n\nChange-Id: I8f4bceb4481143e4ecbb6bac3ebef1e88f5793cd\n'}]",0,887707,6d979cda095e0786b06d77187c4b6ee7369580c2,8,3,1,935,,,0,"2023.1.1 release updates

Update publishing target to push to candidate channel.

Update .gitreview default branch.

Change-Id: I8f4bceb4481143e4ecbb6bac3ebef1e88f5793cd
",git fetch https://review.opendev.org/openstack/charm-horizon-k8s refs/changes/07/887707/1 && git format-patch -1 --stdout FETCH_HEAD,"['osci.yaml', '.gitreview']",2,6d979cda095e0786b06d77187c4b6ee7369580c2,release/2023.1.1,defaultbranch=stable/2023.1.1,defaultbranch=main,2,2
openstack%2Fcharm-glance-k8s~887706,openstack/charm-glance-k8s,stable/2023.1.1,I35198159c8e6ba40a6e83261c83e0d0b147967fa,2023.1.1 release updates,MERGED,2023-07-05 14:45:04.000000000,2023-07-06 02:17:55.000000000,2023-07-06 01:58:12.000000000,"[{'_account_id': 10366}, {'_account_id': 22348}]","[{'number': 1, 'created': '2023-07-05 14:45:04.000000000', 'files': ['osci.yaml', '.gitreview', 'tests/bundles/smoke.yaml'], 'web_link': 'https://opendev.org/openstack/charm-glance-k8s/commit/2fd7c868b6c432b9648e42fe521842fef19dacd5', 'message': '2023.1.1 release updates\n\nUpdate publishing target to push to candidate channel.\n\nRefresh bundles to deploy from candidate channel for testing.\n\nUpdate .gitreview default branch.\n\nChange-Id: I35198159c8e6ba40a6e83261c83e0d0b147967fa\n'}]",0,887706,2fd7c868b6c432b9648e42fe521842fef19dacd5,7,2,1,935,,,0,"2023.1.1 release updates

Update publishing target to push to candidate channel.

Refresh bundles to deploy from candidate channel for testing.

Update .gitreview default branch.

Change-Id: I35198159c8e6ba40a6e83261c83e0d0b147967fa
",git fetch https://review.opendev.org/openstack/charm-glance-k8s refs/changes/06/887706/1 && git format-patch -1 --stdout FETCH_HEAD,"['osci.yaml', '.gitreview', 'tests/bundles/smoke.yaml']",3,2fd7c868b6c432b9648e42fe521842fef19dacd5,release/2023.1.1, channel: 3.9/candidate channel: 2023.1/candidate, channel: 3.9/edge channel: 2023.1/edge,4,4
openstack%2Fnova-specs~878753,openstack/nova-specs,master,Idcfa51a9854202a0c627c3cfd370d29c4357cbd9,"Re-propose ""Add maxphysaddr support for Libvirt"" for 2023.2 Bobcat",MERGED,2023-03-28 09:54:52.000000000,2023-07-06 01:43:17.000000000,2023-07-06 01:42:10.000000000,"[{'_account_id': 7166}, {'_account_id': 9708}, {'_account_id': 11604}, {'_account_id': 22348}]","[{'number': 1, 'created': '2023-03-28 09:54:52.000000000', 'files': ['specs/2023.2/approved/libvirt-maxphysaddr-support.rst'], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/518e3357c28759e20a92add1175de721e1571241', 'message': 'Re-propose ""Add maxphysaddr support for Libvirt"" for 2023.2 Bobcat\n\nblueprint: libvirt-maxphysaddr-support\nSigned-off-by: Nobuhiro MIKI <nmiki@yahoo-corp.jp>\nChange-Id: Idcfa51a9854202a0c627c3cfd370d29c4357cbd9\n'}]",4,878753,518e3357c28759e20a92add1175de721e1571241,13,4,1,31652,,,0,"Re-propose ""Add maxphysaddr support for Libvirt"" for 2023.2 Bobcat

blueprint: libvirt-maxphysaddr-support
Signed-off-by: Nobuhiro MIKI <nmiki@yahoo-corp.jp>
Change-Id: Idcfa51a9854202a0c627c3cfd370d29c4357cbd9
",git fetch https://review.opendev.org/openstack/nova-specs refs/changes/53/878753/1 && git format-patch -1 --stdout FETCH_HEAD,['specs/2023.2/approved/libvirt-maxphysaddr-support.rst'],1,518e3357c28759e20a92add1175de721e1571241,bp/libvirt-maxphysaddr-support,".. This work is licensed under a Creative Commons Attribution 3.0 Unported License. http://creativecommons.org/licenses/by/3.0/legalcode ========================================== Add maxphysaddr support for Libvirt ========================================== https://blueprints.launchpad.net/nova/+spec/libvirt-maxphysaddr-support This blueprint propose new flavor extra_specs to control the physical address bits of vCPUs in Libvirt guests. Problem description =================== When booting a guest with 1TB+ RAM, the default physical address bits are too small and the boot fails [1]_. So a knob is needed to specify the appropriate physical address bits. Use Cases --------- Booting a guest with large RAM. Proposed change =============== In Libvirt v8.7.0+ and QEMU v2.7.0+, physical address bits can be specified with following XML elements [2]_ [3]_. The former means to adopt any physical address bits, the latter means to adopt the physical address bits of the host CPU. - ``<maxphysaddr mode='emulate' bits='42'/>`` - ``<maxphysaddr mode='passthrough'/>`` Flavor extra_specs ----------------------------------------------- Here I suggest the following two flavor extra_specs. Of course, if these are omitted, the behavior is the same as before. - ``hw:maxphysaddr_mode`` can be either ``emulate`` or ``passthrough``. - ``hw:maxphysaddr_bits`` takes a positive integer value. Only meaningful and must be specified if ``hw:maxphysaddr_mode=emulate``. Nova scheduler changes ---------------------- Nova scheduler also needs to be modified to take these two properties into account. There can be a mix of supported and unsupported hosts depending on Libvirt and QEMU versions. So add new traits ``COMPUTE_ADDRESS_SPACE_PASSTHROUGH`` and ``COMPUTE_ADDRESS_SPACE_EMULATED`` to check the scheduled host supports this feature. ``trait:COMPUTE_ADDRESS_SPACE_PASSTHROUGH=required`` is automatically added if ``hw:maxphysaddr_mode=passthrough`` is specified in flavor extra_specs. And same for ``hw:maxphysaddr_mode=emulate``. Passthrough and emulate modes have different properties. So let's consider the two separately. The case of ``hw:maxphysaddr_mode=passthrough``. In this case, ``cpu_mode=host-passthrough`` is a requirement, which is already taken into account in nova scheduling, and no additional modifications are required in this proposal. It is not guaranteed whether the instance can be migrated by nova. So the admin needs to make sure that targets of cold and live migration have similar hardware and software. This restriction is similar for ``cpu_mode=host-passthrough``. The case of ``hw:maxphysaddr_mode=emulate``. In nova scheduling, it is necessary to check that the hypervisor supports at least ``hw:maxphysaddr_bits``. The maximum number of bits supported by hypervisor can be obtained by using libvirt capabilities [4]_. Therefore, ``ComputeCapabilitiesFilter`` can be used to compare the number of bits in scheduling. For example, this can be accomplished by adding ``capabilities:cpu_info:maxphysaddr:bits>=42`` automatically. Cold migration and live migration can also be realized with this filter and ``COMPUTE_ADDRESS_SPACE_EMULATED`` trait. So the overall flavor extra_specs look like the following:: openstack flavor set <flavor> \ --property hw:maxphysaddr_mode=emulate \ --property hw:maxphysaddr_bits=42 .. note:: Since ComputeCapabilitiesFilter only supports flavor extra_specs and not image properties [5]_, this proposal is out of scope for image properties. Alternatives ------------ Before the ``maxphysaddr`` option was introduced into Libvirt, it was specified as a workaround with the QEMU comanndline parameter. But this alternative is not allowed in nova. Also, some Linux distributions may have machine types with ``host-phys-bits=true`` [6]_. For example, ``pc-i440fx-bionic-hpb`` and ``pc-q35-bionic-hpb``. However, this alternative has following two issues and cannot be adopted for general-purpose use cases. - Ubuntu package maintainers are applying a patch to QEMU [7]_. It means this is not included in vanilla QEMU and is not available in other distributions. - This is only the case for ``hw:maxphysaddr_mode=passthrough`` and does not include ``hw:maxphysaddr_mode=emulate``. Since ``hw:maxphysaddr_mode=passthrough`` requires ``cpu_mode=host-passthrough`` to be used [8]_, this alternative cannot be used with ``cpu_mode=custom`` or ``cpu_mode=host-model``. So, this alternative is not sufficient for a cloud with many different CPU models. As for scheduling, placement does not currently support numeric traits, so the maximum number of bits supported by hypervisor cannot be checked by this mechanism. Data model impact ----------------- None REST API impact --------------- None Security impact --------------- None Notifications impact -------------------- None Other end user impact --------------------- None Performance Impact ------------------ None Other deployer impact --------------------- Operators should specify appropriate flavor extra_specs as needed. Developer impact ---------------- None Upgrade impact -------------- As described earlier, the new traits ``COMPUTE_ADDRESS_SPACE_PASSTHROUGH`` and ``COMPUTE_ADDRESS_SPACE_EMULATED`` signal if the upgraded compute nodes support this feature. Implementation ============== Assignee(s) ----------- Primary assignee: nmiki Other contributors: None Feature Liaison --------------- Feature liaison: Liaison Needed Work Items ---------- * Add new guest configs * Add new fileds in nova/api/validation/extra_specs/hw.py * Add new fields in LibvirtConfigCPU in nova/virt/livbirt/config.py * Add new traits to check Libvirt and QEMU versions * Add new field ``maxphysaddr`` to ``cpu_info`` in nova/virt/libvirt/driver.py * Add docs and release notes for new flavor extra_specs Dependencies ============ Libivrt v8.7.0+. QEMU v2.7.0+. Testing ======= Add the following unit tests: - check that proposed flavor extra_specs are properly validated - check that intended XML elements are output - check that traits are properly added and used - check that new field in ``ComputeCapabilitiesFilter`` is property added and used Documentation Impact ==================== For operators, the documentation describes what proposed flavor extra_specs mean and how they should be set. References ========== .. [1] https://bugs.launchpad.net/ubuntu/+source/libvirt/+bug/1769053 .. [2] https://libvirt.org/news.html#v8-7-0-2022-09-01 .. [3] https://github.com/libvirt/libvirt/commit/1c1a7cdd4096c59fb0c374529e1e5aea8d43ee9c .. [4] https://libvirt.org/formatcaps.html#examples .. [5] https://docs.openstack.org/nova/latest/admin/scheduling.html#computecapabilitiesfilter .. [6] https://cpaelzer.github.io/blogs/005-guests-bigger-than-1tb/ .. [7] https://git.launchpad.net/~paelzer/ubuntu/+source/qemu/commit/?id=6ba8b5c843d405e1b067dc8b98ecb8545af78a2b .. [8] https://github.com/libvirt/libvirt/blob/v8.7.0/src/qemu/qemu_validate.c#L346-L351 History ======= .. list-table:: Revisions :header-rows: 1 * - Release Name - Description * - 2023.1 Antelope - Introduced * - 2023.2 Bobcat - Reproposed ",,239,0
openstack%2Fnova-specs~887661,openstack/nova-specs,master,I345570605eb3ed5f2e08f7e3660d9f5d91f4734b,Fix build failures caused by changes in Pillow v10.0.0,ABANDONED,2023-07-05 09:44:48.000000000,2023-07-06 01:25:59.000000000,,"[{'_account_id': 7166}, {'_account_id': 22348}]","[{'number': 1, 'created': '2023-07-05 09:44:48.000000000', 'files': ['doc/requirements.txt'], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/649f44213e62ad5659b6dde9f04e6ecb0682914a', 'message': 'Fix build failures caused by changes in Pillow v10.0.0\n\nThis is due to the removal of the ImageDraw.textsize() method from\nversion 10.0.0 or later [1] in Pillow package on which nova-specs\nbuilds depend. This was expected and is not a problem in itself.\n\nWhen building nova-specs, we use Pillow package via blockdiag\npackage. A patch to fix this has already been proposed for blockdiag [2],\nbut there is no indication that it will be merged. Fixing blockdiag\npackage is the legitimate way to go, but I have not found an active\nmaintainer, so this patch fix it.\n\n[1]: https://pillow.readthedocs.io/en/stable/deprecations.html#font-size-and-offset-methods\n[2]: https://github.com/blockdiag/blockdiag/pull/171\n\nSigned-off-by: Nobuhiro MIKI <nmiki@yahoo-corp.jp>\nChange-Id: I345570605eb3ed5f2e08f7e3660d9f5d91f4734b\n'}]",4,887661,649f44213e62ad5659b6dde9f04e6ecb0682914a,8,2,1,31652,,,0,"Fix build failures caused by changes in Pillow v10.0.0

This is due to the removal of the ImageDraw.textsize() method from
version 10.0.0 or later [1] in Pillow package on which nova-specs
builds depend. This was expected and is not a problem in itself.

When building nova-specs, we use Pillow package via blockdiag
package. A patch to fix this has already been proposed for blockdiag [2],
but there is no indication that it will be merged. Fixing blockdiag
package is the legitimate way to go, but I have not found an active
maintainer, so this patch fix it.

[1]: https://pillow.readthedocs.io/en/stable/deprecations.html#font-size-and-offset-methods
[2]: https://github.com/blockdiag/blockdiag/pull/171

Signed-off-by: Nobuhiro MIKI <nmiki@yahoo-corp.jp>
Change-Id: I345570605eb3ed5f2e08f7e3660d9f5d91f4734b
",git fetch https://review.opendev.org/openstack/nova-specs refs/changes/61/887661/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/requirements.txt'],1,649f44213e62ad5659b6dde9f04e6ecb0682914a,add_ver_constraint_pillow,Pillow<=9.5.0,,1,0
openstack%2Ftrove~887653,openstack/trove,master,Ide59528d9526fdf1c741f0749ca2263721374c65,update requirements,ABANDONED,2023-07-05 07:07:56.000000000,2023-07-06 01:18:52.000000000,,[{'_account_id': 22348}],"[{'number': 1, 'created': '2023-07-05 07:07:56.000000000', 'files': ['requirements.txt'], 'web_link': 'https://opendev.org/openstack/trove/commit/44de13cc61eab48e474a336e7862c3e975f2d2f9', 'message': 'update requirements\n\nAdd flask and pyroute2 module in requirements\n\nChange-Id: Ide59528d9526fdf1c741f0749ca2263721374c65\n'}]",0,887653,44de13cc61eab48e474a336e7862c3e975f2d2f9,4,1,1,26285,,,0,"update requirements

Add flask and pyroute2 module in requirements

Change-Id: Ide59528d9526fdf1c741f0749ca2263721374c65
",git fetch https://review.opendev.org/openstack/trove refs/changes/53/887653/1 && git format-patch -1 --stdout FETCH_HEAD,['requirements.txt'],1,44de13cc61eab48e474a336e7862c3e975f2d2f9,, # for trove network driver Flask>=2.2.3 # BSD pyroute2>=0.7.7;sys_platform!='win32' # Apache-2.0 (+ dual licensed GPL2),,4,0
openstack%2Fpython-novaclient~887268,openstack/python-novaclient,master,I47d3b572247cc63e696c3feb0062fff8a633a55c,Do exact-matching when finding one instance by name,ABANDONED,2023-06-29 11:50:03.000000000,2023-07-06 01:18:03.000000000,,"[{'_account_id': 679}, {'_account_id': 22348}, {'_account_id': 34564}]","[{'number': 1, 'created': '2023-06-29 11:50:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-novaclient/commit/4d3fc0066169d0744c922c1fa68ace0571667357', 'message': 'Do exact-matching when finding one instance by name\n\nWhen we search an instance by its display_name, Nova API considered\nthe display_name as a regular expression.\n\nhttps://docs.openstack.org/api-ref/compute/?expanded=list-servers-detail\n> name (Optional)\n> query\n> string\n> Filters the response by a server name, as a string. You can use regular expressions in the query.\n\nHowever, in the current implementation, nova cli filter the\nresponse of the Nova API by exact-matching, not regular expression\nmatching. Because of this inconsistency, we cannot find instances whose\ndisplay_name contains special characters which has special meanings in\nregular expression, such as (){}[]?*, etc.\n\nThis change escapes these special characters before calling the Nova\nAPI. By this change, we can find instances by its display_name even if\nit contains these special characters.\n\nCloses-Bug: #2025358\nChange-Id: I47d3b572247cc63e696c3feb0062fff8a633a55c\n'}, {'number': 2, 'created': '2023-06-30 08:13:50.000000000', 'files': ['novaclient/base.py', 'novaclient/v2/servers.py', 'novaclient/tests/unit/v2/test_shell.py'], 'web_link': 'https://opendev.org/openstack/python-novaclient/commit/2b601b4fa834d79948e14a2e36beddca06c56b0c', 'message': 'Do exact-matching when finding one instance by name\n\nWhen we search an instance by its display_name, Nova API considered\nthe display_name as a regular expression.\n\nhttps://docs.openstack.org/api-ref/compute/?expanded=list-servers-detail\n> name (Optional)\n> query\n> string\n> Filters the response by a server name, as a string. You can use regular expressions in the query.\n\nHowever, in the current implementation, nova cli filter the\nresponse of the Nova API by exact-matching, not regular expression\nmatching. Because of this inconsistency, we cannot find instances whose\ndisplay_name contains special characters which has special meanings in\nregular expression, such as (){}[]?*, etc.\n\nThis change escapes these special characters before calling the Nova\nAPI. By this change, we can find instances by its display_name even if\nit contains these special characters.\n\nCloses-Bug: #2025358\nChange-Id: I47d3b572247cc63e696c3feb0062fff8a633a55c\n'}]",0,887268,2b601b4fa834d79948e14a2e36beddca06c56b0c,6,3,2,34564,,,0,"Do exact-matching when finding one instance by name

When we search an instance by its display_name, Nova API considered
the display_name as a regular expression.

https://docs.openstack.org/api-ref/compute/?expanded=list-servers-detail
> name (Optional)
> query
> string
> Filters the response by a server name, as a string. You can use regular expressions in the query.

However, in the current implementation, nova cli filter the
response of the Nova API by exact-matching, not regular expression
matching. Because of this inconsistency, we cannot find instances whose
display_name contains special characters which has special meanings in
regular expression, such as (){}[]?*, etc.

This change escapes these special characters before calling the Nova
API. By this change, we can find instances by its display_name even if
it contains these special characters.

Closes-Bug: #2025358
Change-Id: I47d3b572247cc63e696c3feb0062fff8a633a55c
",git fetch https://review.opendev.org/openstack/python-novaclient refs/changes/68/887268/1 && git format-patch -1 --stdout FETCH_HEAD,"['novaclient/base.py', 'novaclient/v2/servers.py', 'novaclient/tests/unit/v2/test_shell.py']",3,4d3fc0066169d0744c922c1fa68ace0571667357,bug/2025358," self.assert_called('GET', '/servers?name=sample%5C-server', pos=0) self.assert_called('GET', '/servers?name=sample%5C-server', pos=0) self.assert_called('GET', '/servers?name=sample%5C-server', pos=0) self.assert_called('GET', '/servers?name=sample%5C-server', pos=0) self.assert_called('GET', '/servers?name=sample%5C-server', pos=0) self.assert_called('GET', '/servers?name=sample%5C-server', pos=0) self.assert_called('GET', '/servers?name=sample%5C-server', pos=0) self.assert_called('GET', '/servers?name=sample%5C-server', pos=0) self.assert_called('GET', '/servers?name=sample%5C-server', pos=0) self.assert_called('GET', '/servers?name=sample%5C-server', pos=0) self.assert_called('GET', '/servers?name=sample%5C-server', pos=0) self.assert_called('GET', '/servers?name=sample%5C-server', pos=0) self.assert_called('GET', '/servers?name=sample%5C-server', pos=0) self.assert_called('GET', '/servers?name=sample%5C-server', pos=0) self.assert_called('GET', '/servers?name=sample%5C-server', pos=0) self.assert_called('GET', '/servers?name=sample%5C-server', pos=0) self.assert_called('GET', '/servers?name=sample%5C-server', pos=0) '/servers?all_tenants=1&name=sample%5C-server', pos=0) '/servers?all_tenants=1&name=sample%5C-server', pos=0) '/servers?deleted=True&name=sample%5C-server', pos=0) '/servers?name=sample%5C-server', pos=-6) '/servers?name=sample%5C-server2', '/servers?all_tenants=1&name=sample%5C-server', pos=0) '/servers?all_tenants=1&name=sample%5C-server2', '/servers?all_tenants=1&name=sample%5C-server', pos=0)"," self.assert_called('GET', '/servers?name=sample-server', pos=0) self.assert_called('GET', '/servers?name=sample-server', pos=0) self.assert_called('GET', '/servers?name=sample-server', pos=0) self.assert_called('GET', '/servers?name=sample-server', pos=0) self.assert_called('GET', '/servers?name=sample-server', pos=0) self.assert_called('GET', '/servers?name=sample-server', pos=0) self.assert_called('GET', '/servers?name=sample-server', pos=0) self.assert_called('GET', '/servers?name=sample-server', pos=0) self.assert_called('GET', '/servers?name=sample-server', pos=0) self.assert_called('GET', '/servers?name=sample-server', pos=0) self.assert_called('GET', '/servers?name=sample-server', pos=0) self.assert_called('GET', '/servers?name=sample-server', pos=0) self.assert_called('GET', '/servers?name=sample-server', pos=0) self.assert_called('GET', '/servers?name=sample-server', pos=0) self.assert_called('GET', '/servers?name=sample-server', pos=0) self.assert_called('GET', '/servers?name=sample-server', pos=0) self.assert_called('GET', '/servers?name=sample-server', pos=0) '/servers?all_tenants=1&name=sample-server', pos=0) '/servers?all_tenants=1&name=sample-server', pos=0) '/servers?deleted=True&name=sample-server', pos=0) '/servers?name=sample-server', pos=-6) '/servers?name=sample-server2', '/servers?all_tenants=1&name=sample-server', pos=0) '/servers?all_tenants=1&name=sample-server2', '/servers?all_tenants=1&name=sample-server', pos=0)",45,25
openstack%2Fopenstacksdk~887127,openstack/openstacksdk,master,I9c83f044e6ff36138b0788207912fe5d5a518980,Do exact-matching when finding one instance by name,ABANDONED,2023-06-28 02:43:31.000000000,2023-07-06 01:18:01.000000000,,"[{'_account_id': 22348}, {'_account_id': 34564}]","[{'number': 1, 'created': '2023-06-28 02:43:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstacksdk/commit/8e60a65cf0d8963b93027b9d49de602f3851334f', 'message': 'Do exact-matching when finding one instance by name\n\nWhen we search an instance by its display_name, Nova API considered\nthe display_name as a regular expression.\n\nhttps://docs.openstack.org/api-ref/compute/?expanded=list-servers-detail\n> name (Optional)\n> query\n> string\n> Filters the response by a server name, as a string. You can use regular expressions in the query.\n\nHowever, in the current implementation, openstack cli filter the\nresponse of the Nova API by exact-matching, not regular expression\nmatching. Because of this inconsistency, we cannot find instances whose\ndisplay_name contains special characters which has special meanings in\nregular expression, such as (){}[]?*, etc.\n\nThis change escapes these special characters before calling the Nova\nAPI. By this change, we can find instances by its display_name even if\nit contains these special characters.\n\nCloses-Bug: #2025143\nChange-Id: I9c83f044e6ff36138b0788207912fe5d5a518980\n'}, {'number': 2, 'created': '2023-06-28 09:07:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstacksdk/commit/e07230ffda41391b4687ab0c8e55ad37a67b2314', 'message': 'Do exact-matching when finding one instance by name\n\nWhen we search an instance by its display_name, Nova API considered\nthe display_name as a regular expression.\n\nhttps://docs.openstack.org/api-ref/compute/?expanded=list-servers-detail\n> name (Optional)\n> query\n> string\n> Filters the response by a server name, as a string. You can use regular expressions in the query.\n\nHowever, in the current implementation, openstack cli filter the\nresponse of the Nova API by exact-matching, not regular expression\nmatching. Because of this inconsistency, we cannot find instances whose\ndisplay_name contains special characters which has special meanings in\nregular expression, such as (){}[]?*, etc.\n\nThis change escapes these special characters before calling the Nova\nAPI. By this change, we can find instances by its display_name even if\nit contains these special characters.\n\nCloses-Bug: #2025143\nChange-Id: I9c83f044e6ff36138b0788207912fe5d5a518980\n'}, {'number': 3, 'created': '2023-06-29 10:36:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstacksdk/commit/f03c6005b90d0a1fa11eaf0d7570bec73f46ad8d', 'message': 'Do exact-matching when finding one instance by name\n\nWhen we search an instance by its display_name, Nova API considered\nthe display_name as a regular expression.\n\nhttps://docs.openstack.org/api-ref/compute/?expanded=list-servers-detail\n> name (Optional)\n> query\n> string\n> Filters the response by a server name, as a string. You can use regular expressions in the query.\n\nHowever, in the current implementation, openstack cli filter the\nresponse of the Nova API by exact-matching, not regular expression\nmatching. Because of this inconsistency, we cannot find instances whose\ndisplay_name contains special characters which has special meanings in\nregular expression, such as (){}[]?*, etc.\n\nThis change escapes these special characters before calling the Nova\nAPI. By this change, we can find instances by its display_name even if\nit contains these special characters.\n\nStory: 2010809\nTask: 48311\nChange-Id: I9c83f044e6ff36138b0788207912fe5d5a518980\n'}, {'number': 4, 'created': '2023-06-29 12:26:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstacksdk/commit/458b9322abe77924fb69834cb696241757df4d09', 'message': 'Do exact-matching when finding one instance by name\n\nWhen we search an instance by its display_name, Nova API considered\nthe display_name as a regular expression.\n\nhttps://docs.openstack.org/api-ref/compute/?expanded=list-servers-detail\n> name (Optional)\n> query\n> string\n> Filters the response by a server name, as a string. You can use regular expressions in the query.\n\nHowever, in the current implementation, compute.find_server filters the\nresponse of the Nova API by exact-matching, not regular expression\nmatching. Because of this inconsistency, we cannot find instances whose\ndisplay_name contains special characters which has special meanings in\nregular expression, such as (){}[]?*, etc.\n\nThis change escapes these special characters before calling the Nova\nAPI. By this change, we can find instances by its display_name even if\nit contains these special characters.\n\nStory: 2010809\nTask: 48311\nChange-Id: I9c83f044e6ff36138b0788207912fe5d5a518980\n'}, {'number': 5, 'created': '2023-06-29 12:30:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstacksdk/commit/61f1090dbab92581648c9ea704c0d789beb1ad58', 'message': 'Do exact-matching when finding one instance by name\n\nWhen we search an instance by its display_name, Nova API considered\nthe display_name as a regular expression.\n\nhttps://docs.openstack.org/api-ref/compute/?expanded=list-servers-detail\n> name (Optional)\n> query\n> string\n> Filters the response by a server name, as a string. You can use regular expressions in the query.\n\nHowever, in the current implementation, compute.find_server filters the\nresponse of the Nova API by exact-matching, not regular expression\nmatching. Because of this inconsistency, we cannot find instances whose\ndisplay_name contains special characters which has special meanings in\nregular expression, such as (){}[]?*, etc.\n\nThis change escapes these special characters before calling the Nova\nAPI. By this change, we can find instances by its display_name even if\nit contains these special characters.\n\nStory: 2010809\nTask: 48311\nChange-Id: I9c83f044e6ff36138b0788207912fe5d5a518980\n'}, {'number': 6, 'created': '2023-06-30 08:13:49.000000000', 'files': ['openstack/tests/unit/cloud/test_update_server.py', 'openstack/compute/v2/server.py', 'openstack/resource.py'], 'web_link': 'https://opendev.org/openstack/openstacksdk/commit/dde0eca51b012d1bbf58c325341a4c156896fd0f', 'message': 'Do exact-matching when finding one instance by name\n\nWhen we search an instance by its display_name, Nova API considered\nthe display_name as a regular expression.\n\nhttps://docs.openstack.org/api-ref/compute/?expanded=list-servers-detail\n> name (Optional)\n> query\n> string\n> Filters the response by a server name, as a string. You can use regular expressions in the query.\n\nHowever, in the current implementation, compute.find_server filters the\nresponse of the Nova API by exact-matching, not regular expression\nmatching. Because of this inconsistency, we cannot find instances whose\ndisplay_name contains special characters which has special meanings in\nregular expression, such as (){}[]?*, etc.\n\nThis change escapes these special characters before calling the Nova\nAPI. By this change, we can find instances by its display_name even if\nit contains these special characters.\n\nStory: 2010809\nTask: 48311\nChange-Id: I9c83f044e6ff36138b0788207912fe5d5a518980\n'}]",1,887127,dde0eca51b012d1bbf58c325341a4c156896fd0f,12,2,6,34564,,,0,"Do exact-matching when finding one instance by name

When we search an instance by its display_name, Nova API considered
the display_name as a regular expression.

https://docs.openstack.org/api-ref/compute/?expanded=list-servers-detail
> name (Optional)
> query
> string
> Filters the response by a server name, as a string. You can use regular expressions in the query.

However, in the current implementation, compute.find_server filters the
response of the Nova API by exact-matching, not regular expression
matching. Because of this inconsistency, we cannot find instances whose
display_name contains special characters which has special meanings in
regular expression, such as (){}[]?*, etc.

This change escapes these special characters before calling the Nova
API. By this change, we can find instances by its display_name even if
it contains these special characters.

Story: 2010809
Task: 48311
Change-Id: I9c83f044e6ff36138b0788207912fe5d5a518980
",git fetch https://review.opendev.org/openstack/openstacksdk refs/changes/27/887127/1 && git format-patch -1 --stdout FETCH_HEAD,['openstack/compute/v2/server.py'],1,8e60a65cf0d8963b93027b9d49de602f3851334f,bug/2025143,"import re @classmethod def find( cls, session, name_or_id, ignore_missing=True, list_base_path=None, *, microversion=None, all_projects=None, **params, ): session = cls._get_session(session) # Try to short-circuit by looking directly for a matching ID. try: match = cls.existing( id=name_or_id, connection=session._get_connection(), **params, ) return match.fetch(session, microversion=microversion, **params) except ( exceptions.NotFoundException, exceptions.BadRequestException, exceptions.ForbiddenException, ): # NOTE(gtema): There are few places around openstack that return # 400 if we try to GET resource and it doesn't exist. pass if list_base_path: params['base_path'] = list_base_path # all_projects is a special case that is used by multiple services. We # handle it here since it doesn't make sense to pass it to the .fetch # call above if all_projects is not None: params['all_projects'] = all_projects if ( 'name' in cls._query_mapping._mapping.keys() and 'name' not in params ): params['name'] = re.escape(name_or_id) data = cls.list(session, **params) result = cls._get_one_match(name_or_id, data) if result is not None: return result if ignore_missing: return None raise exceptions.ResourceNotFound( ""No %s found for %s"" % (cls.__name__, name_or_id) ) ",,61,0
openstack%2Fkeystone~879733,openstack/keystone,master,Iea594efe528318cfc168a06ed8c00eaf6d9483d1,sql: Delay importing SQL modules,MERGED,2023-04-06 10:48:29.000000000,2023-07-06 00:24:16.000000000,2023-07-06 00:23:01.000000000,"[{'_account_id': 7414}, {'_account_id': 14250}, {'_account_id': 22348}]","[{'number': 1, 'created': '2023-04-06 10:48:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/4eb0ff0e0b6fcce0c710fcd8dba530d57300a136', 'message': 'sql: Delay importing SQL modules\n\nThese need access to CONF variables. We need to delay importing until\nafter the singleton is configured.\n\nChange-Id: Iea594efe528318cfc168a06ed8c00eaf6d9483d1\nSigned-off-by: Stephen Finucane <sfinucan@redhat.com>\n'}, {'number': 2, 'created': '2023-06-27 09:58:52.000000000', 'files': ['keystone/common/sql/migrations/manage.py'], 'web_link': 'https://opendev.org/openstack/keystone/commit/a5544ea3377fc0abc285c24b4007322a68c46771', 'message': 'sql: Delay importing SQL modules\n\nThese need access to CONF variables. We need to delay importing until\nafter the singleton is configured.\n\nChange-Id: Iea594efe528318cfc168a06ed8c00eaf6d9483d1\nSigned-off-by: Stephen Finucane <sfinucan@redhat.com>\n'}]",2,879733,a5544ea3377fc0abc285c24b4007322a68c46771,19,3,2,15334,,,0,"sql: Delay importing SQL modules

These need access to CONF variables. We need to delay importing until
after the singleton is configured.

Change-Id: Iea594efe528318cfc168a06ed8c00eaf6d9483d1
Signed-off-by: Stephen Finucane <sfinucan@redhat.com>
",git fetch https://review.opendev.org/openstack/keystone refs/changes/33/879733/1 && git format-patch -1 --stdout FETCH_HEAD,['keystone/common/sql/migrations/manage.py'],1,4eb0ff0e0b6fcce0c710fcd8dba530d57300a136,sqlalchemy-20,"import sysdef import_sql_modules(): # We need to import all of these so the tables are registered. It would be # easier if these were all in a central location :( import keystone.application_credential.backends.sql # noqa: F401 import keystone.assignment.backends.sql # noqa: F401 import keystone.assignment.role_backends.sql_model # noqa: F401 import keystone.catalog.backends.sql # noqa: F401 import keystone.credential.backends.sql # noqa: F401 import keystone.endpoint_policy.backends.sql # noqa: F401 import keystone.federation.backends.sql # noqa: F401 import keystone.identity.backends.sql_model # noqa: F401 import keystone.identity.mapping_backends.sql # noqa: F401 import keystone.limit.backends.sql # noqa: F401 import keystone.oauth1.backends.sql # noqa: F401 import keystone.policy.backends.sql # noqa: F401 import keystone.resource.backends.sql_model # noqa: F401 import keystone.resource.config_backends.sql # noqa: F401 import keystone.revoke.backends.sql # noqa: F401 import keystone.trust.backends.sql # noqa: F401 def main(argv): keystone.conf.set_default_for_default_log_levels() user_supplied_config_file = False if argv: for argument in argv: if argument == '--config-file': user_supplied_config_file = True if not CONF.default_config_files and not user_supplied_config_file: LOG.warning('Config file not found, using default configs.') import_sql_modules() main(sys.argv)",# We need to import all of these so the tables are registered. It would be # easier if these were all in a central location :( import keystone.application_credential.backends.sql # noqa: F401 import keystone.assignment.backends.sql # noqa: F401 import keystone.assignment.role_backends.sql_model # noqa: F401 import keystone.catalog.backends.sql # noqa: F401 import keystone.credential.backends.sql # noqa: F401 import keystone.endpoint_policy.backends.sql # noqa: F401 import keystone.federation.backends.sql # noqa: F401 import keystone.identity.backends.sql_model # noqa: F401 import keystone.identity.mapping_backends.sql # noqa: F401 import keystone.limit.backends.sql # noqa: F401 import keystone.oauth1.backends.sql # noqa: F401 import keystone.policy.backends.sql # noqa: F401 import keystone.resource.backends.sql_model # noqa: F401 import keystone.resource.config_backends.sql # noqa: F401 import keystone.revoke.backends.sql # noqa: F401 import keystone.trust.backends.sql # noqa: F401 def main(): main(),37,21
openstack%2Fmagnum~887745,openstack/magnum,stable/2023.1,Ibc5090ac5d30534f278da3b1a694b796dbdfd937,Upgrade system monitoring to use kube-prometheus-stack helm chart,NEW,2023-07-05 23:45:24.000000000,2023-07-06 00:23:00.000000000,,[{'_account_id': 22348}],"[{'number': 1, 'created': '2023-07-05 23:45:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/magnum/commit/e524accce7c50c4cc210a457d5b95306c80e5b3e', 'message': '[catalystcloud] Upgrade system monitoring to use kube-prometheus-stack helm chart\n\n* Add variables to specify kube-prometheus-stack chart tag version\n* Additional variables to specify dependency versions\n* Add fragment to include kube-prometheus-stack chart in\n  heat-config-deploy script\n* Change conditional to make make kube-prometheus-stack and\n  prometheus-operator charts mutually exclusive of one another.\n  Prometheus-operator helm chart should run only if kube-prometheus-stack\n  chart tag is not defined.\n\nChange-Id: Ibc5090ac5d30534f278da3b1a694b796dbdfd937\n'}, {'number': 2, 'created': '2023-07-05 23:47:38.000000000', 'files': ['doc/source/user/index.rst', 'magnum/tests/unit/drivers/test_template_definition.py', 'doc/source/user/monitoring.rst', 'magnum/drivers/k8s_fedora_coreos_v1/templates/kubecluster.yaml', 'magnum/drivers/k8s_fedora_coreos_v1/templates/kubemaster.yaml', 'magnum/drivers/common/templates/kubernetes/fragments/write-heat-params-master.sh', 'magnum/tests/unit/conductor/handlers/test_k8s_cluster_conductor.py', 'magnum/drivers/heat/k8s_template_def.py', 'magnum/drivers/common/templates/kubernetes/helm/prometheus-operator.sh', 'magnum/drivers/heat/k8s_fedora_template_def.py', 'magnum/drivers/common/templates/kubernetes/helm/kube-prometheus-stack.sh', 'magnum/drivers/common/templates/kubernetes/helm/prometheus-adapter.sh'], 'web_link': 'https://opendev.org/openstack/magnum/commit/7bb3a171a938b538f04bd8229fc837367e5300be', 'message': 'Upgrade system monitoring to use kube-prometheus-stack helm chart\n\n* Add variables to specify kube-prometheus-stack chart tag version\n* Additional variables to specify dependency versions\n* Add fragment to include kube-prometheus-stack chart in\n  heat-config-deploy script\n* Change conditional to make make kube-prometheus-stack and\n  prometheus-operator charts mutually exclusive of one another.\n  Prometheus-operator helm chart should run only if kube-prometheus-stack\n  chart tag is not defined.\n\nChange-Id: Ibc5090ac5d30534f278da3b1a694b796dbdfd937\n'}]",0,887745,7bb3a171a938b538f04bd8229fc837367e5300be,3,1,2,35921,,,0,"Upgrade system monitoring to use kube-prometheus-stack helm chart

* Add variables to specify kube-prometheus-stack chart tag version
* Additional variables to specify dependency versions
* Add fragment to include kube-prometheus-stack chart in
  heat-config-deploy script
* Change conditional to make make kube-prometheus-stack and
  prometheus-operator charts mutually exclusive of one another.
  Prometheus-operator helm chart should run only if kube-prometheus-stack
  chart tag is not defined.

Change-Id: Ibc5090ac5d30534f278da3b1a694b796dbdfd937
",git fetch https://review.opendev.org/openstack/magnum refs/changes/45/887745/1 && git format-patch -1 --stdout FETCH_HEAD,"['doc/source/user/index.rst', 'magnum/tests/unit/drivers/test_template_definition.py', 'doc/source/user/monitoring.rst', 'magnum/drivers/k8s_fedora_coreos_v1/templates/kubecluster.yaml', 'magnum/drivers/k8s_fedora_coreos_v1/templates/kubemaster.yaml', 'magnum/drivers/common/templates/kubernetes/fragments/write-heat-params-master.sh', 'magnum/tests/unit/conductor/handlers/test_k8s_cluster_conductor.py', 'magnum/drivers/heat/k8s_template_def.py', 'magnum/drivers/common/templates/kubernetes/helm/prometheus-operator.sh', 'magnum/drivers/heat/k8s_fedora_template_def.py', 'magnum/drivers/common/templates/kubernetes/helm/kube-prometheus-stack.sh', 'magnum/drivers/common/templates/kubernetes/helm/prometheus-adapter.sh']",12,e524accce7c50c4cc210a457d5b95306c80e5b3e,upgrade-kube-prometheus-stack, repository: ${CONTAINER_INFRA_PREFIX:-k8s.gcr.io/prometheus-adapter/}prometheus-adapter-${ARCH} tag: ${PROMETHEUS_ADAPTER_TAG:-v0.10.0}, repository: ${CONTAINER_INFRA_PREFIX:-docker.io/directxman12/}k8s-prometheus-adapter-${ARCH},1279,5
openstack%2Fbifrost~887699,openstack/bifrost,stable/zed,I208182e65884d63548d78c68f676b899c562a2dc,CI: Update cached cirros image to 0.5.3,MERGED,2023-07-05 14:05:36.000000000,2023-07-05 23:16:18.000000000,2023-07-05 23:15:24.000000000,"[{'_account_id': 15519}, {'_account_id': 22348}, {'_account_id': 23851}]","[{'number': 1, 'created': '2023-07-05 14:05:36.000000000', 'files': ['playbooks/test-bifrost.yaml'], 'web_link': 'https://opendev.org/openstack/bifrost/commit/f38f1d8e01314e408c7d882d9c5cab381969c404', 'message': ""CI: Update cached cirros image to 0.5.3\n\nBifrost CI is currently failing to fetch the cirros image from cache:\n\n    No such file or directory: '/opt/cache/files/cirros-0.5.1-x86_64-disk.img'\n\nThis may be caused by the removal of cirros-0.5.1 images from cache in\nchange Ibada405e0c1183559f428c749d0e54d0a45a2223.\n\nSwitch to cirros version 0.5.3 image instead.\n\nChange-Id: I208182e65884d63548d78c68f676b899c562a2dc\n""}]",1,887699,f38f1d8e01314e408c7d882d9c5cab381969c404,10,3,1,10239,,,0,"CI: Update cached cirros image to 0.5.3

Bifrost CI is currently failing to fetch the cirros image from cache:

    No such file or directory: '/opt/cache/files/cirros-0.5.1-x86_64-disk.img'

This may be caused by the removal of cirros-0.5.1 images from cache in
change Ibada405e0c1183559f428c749d0e54d0a45a2223.

Switch to cirros version 0.5.3 image instead.

Change-Id: I208182e65884d63548d78c68f676b899c562a2dc
",git fetch https://review.opendev.org/openstack/bifrost refs/changes/99/887699/1 && git format-patch -1 --stdout FETCH_HEAD,['playbooks/test-bifrost.yaml'],1,f38f1d8e01314e408c7d882d9c5cab381969c404,, cirros_deploy_image_upstream_url: file:///opt/cache/files/cirros-0.5.3-x86_64-disk.img, cirros_deploy_image_upstream_url: file:///opt/cache/files/cirros-0.5.1-x86_64-disk.img,1,1
openstack%2Fswift~884444,openstack/swift,master,I6fc9eaf0903bdbe4ccb82c4e7647478a1eef9785,"docs: Format metrics in fixed-width font, not italics",MERGED,2023-05-25 20:59:25.000000000,2023-07-05 22:50:12.000000000,2023-07-05 22:48:46.000000000,"[{'_account_id': 1179}, {'_account_id': 15343}, {'_account_id': 22348}]","[{'number': 1, 'created': '2023-05-25 20:59:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/ffbe64f9339e85eaaa74a5ed54867636eabab7f0', 'message': 'docs: Format metrics in fixed-width font, not italics\n\nChange-Id: I6fc9eaf0903bdbe4ccb82c4e7647478a1eef9785\n'}, {'number': 2, 'created': '2023-05-30 18:40:07.000000000', 'files': ['doc/source/metrics/object_server.rst', 'doc/source/metrics/container_sync.rst', 'doc/source/metrics/container_server.rst', 'doc/source/metrics/container_auditor.rst', 'doc/source/metrics/container_updater.rst', 'doc/source/metrics/object_replicator.rst', 'doc/source/metrics/object_updater.rst', 'doc/source/metrics/proxy_server.rst', 'doc/source/metrics/account_auditor.rst', 'doc/source/metrics/account_reaper.rst', 'doc/source/metrics/account_replicator.rst', 'doc/source/metrics/object_reconstructor.rst', 'doc/source/metrics/object_expirer.rst', 'doc/source/metrics/container_replicator.rst', 'doc/source/metrics/object_auditor.rst', 'doc/source/metrics/account_server.rst'], 'web_link': 'https://opendev.org/openstack/swift/commit/1f298714aff931b8041bbfeb2d87e9547dcaefee', 'message': 'docs: Format metrics in fixed-width font, not italics\n\nChange-Id: I6fc9eaf0903bdbe4ccb82c4e7647478a1eef9785\n'}]",2,884444,1f298714aff931b8041bbfeb2d87e9547dcaefee,10,3,2,15343,,,0,"docs: Format metrics in fixed-width font, not italics

Change-Id: I6fc9eaf0903bdbe4ccb82c4e7647478a1eef9785
",git fetch https://review.opendev.org/openstack/swift refs/changes/44/884444/1 && git format-patch -1 --stdout FETCH_HEAD,"['doc/source/metrics/object_server.rst', 'doc/source/metrics/container_sync.rst', 'doc/source/metrics/container_server.rst', 'doc/source/metrics/container_auditor.rst', 'doc/source/metrics/container_updater.rst', 'doc/source/metrics/object_replicator.rst', 'doc/source/metrics/object_updater.rst', 'doc/source/metrics/proxy_server.rst', 'doc/source/metrics/account_auditor.rst', 'doc/source/metrics/account_reaper.rst', 'doc/source/metrics/account_replicator.rst', 'doc/source/metrics/object_reconstructor.rst', 'doc/source/metrics/object_expirer.rst', 'doc/source/metrics/container_replicator.rst', 'doc/source/metrics/object_auditor.rst', 'doc/source/metrics/account_server.rst']",16,ffbe64f9339e85eaaa74a5ed54867636eabab7f0,," which increment ``errors`` are not included in the timing data. ========================================== ======================================================= Metric Name Description ------------------------------------------ ------------------------------------------------------- ``account-server.DELETE.errors.timing`` Timing data for each DELETE request resulting in an error: bad request, not mounted, missing timestamp. ``account-server.DELETE.timing`` Timing data for each DELETE request not resulting in an error. ``account-server.PUT.errors.timing`` Timing data for each PUT request resulting in an error: bad request, not mounted, conflict, recently-deleted. ``account-server.PUT.timing`` Timing data for each PUT request not resulting in an error. ``account-server.HEAD.errors.timing`` Timing data for each HEAD request resulting in an error: bad request, not mounted. ``account-server.HEAD.timing`` Timing data for each HEAD request not resulting in an error. ``account-server.GET.errors.timing`` Timing data for each GET request resulting in an error: bad request, not mounted, bad delimiter, account listing limit too high, bad accept header. ``account-server.GET.timing`` Timing data for each GET request not resulting in an error. ``account-server.REPLICATE.errors.timing`` Timing data for each REPLICATE request resulting in an error: bad request, not mounted. ``account-server.REPLICATE.timing`` Timing data for each REPLICATE request not resulting in an error. ``account-server.POST.errors.timing`` Timing data for each POST request resulting in an error: bad request, bad or missing timestamp, not mounted. ``account-server.POST.timing`` Timing data for each POST request not resulting in an error. ========================================== ======================================================="," which increment `errors` are not included in the timing data. ======================================== ======================================================= Metric Name Description ---------------------------------------- ------------------------------------------------------- `account-server.DELETE.errors.timing` Timing data for each DELETE request resulting in an error: bad request, not mounted, missing timestamp. `account-server.DELETE.timing` Timing data for each DELETE request not resulting in an error. `account-server.PUT.errors.timing` Timing data for each PUT request resulting in an error: bad request, not mounted, conflict, recently-deleted. `account-server.PUT.timing` Timing data for each PUT request not resulting in an error. `account-server.HEAD.errors.timing` Timing data for each HEAD request resulting in an error: bad request, not mounted. `account-server.HEAD.timing` Timing data for each HEAD request not resulting in an error. `account-server.GET.errors.timing` Timing data for each GET request resulting in an error: bad request, not mounted, bad delimiter, account listing limit too high, bad accept header. `account-server.GET.timing` Timing data for each GET request not resulting in an error. `account-server.REPLICATE.errors.timing` Timing data for each REPLICATE request resulting in an error: bad request, not mounted. `account-server.REPLICATE.timing` Timing data for each REPLICATE request not resulting in an error. `account-server.POST.errors.timing` Timing data for each POST request resulting in an error: bad request, bad or missing timestamp, not mounted. `account-server.POST.timing` Timing data for each POST request not resulting in an error. ======================================== =======================================================",368,368
openstack%2Fswift~877146,openstack/swift,master,Ia386736b9b283858931794690538871b6e1ad9c8,Fix handling of non-ASCII accounts,MERGED,2023-03-11 00:49:12.000000000,2023-07-05 22:49:22.000000000,2023-07-05 22:48:12.000000000,"[{'_account_id': 1179}, {'_account_id': 15343}, {'_account_id': 22348}, {'_account_id': 32761}]","[{'number': 1, 'created': '2023-03-11 00:49:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/870615cb81875598b7b9f8af05533606ccfa1f50', 'message': 'Fix handling of non-ASCII accounts\n\nRelated-Change: I4ecfae2bca6ffa08ad15e584579ebce707f4628d\nRelated-Change: I1e244c231753b8f4b6f1cf95cb0ae4c3c959ae0f\nChange-Id: Ia386736b9b283858931794690538871b6e1ad9c8\n'}, {'number': 2, 'created': '2023-06-13 22:28:50.000000000', 'files': ['test/functional/test_dlo.py', 'test/unit/common/middleware/test_tempauth.py', 'test/unit/proxy/test_server.py', 'swift/common/middleware/tempauth.py', 'test/functional/test_slo.py', 'test/functional/test_object_versioning.py', 'test/functional/test_domain_remap.py', 'swift/proxy/controllers/container.py', 'swift/proxy/controllers/base.py'], 'web_link': 'https://opendev.org/openstack/swift/commit/b46b735a3e7b1f5b515edde6046e0c53dc3923ae', 'message': 'Fix handling of non-ASCII accounts\n\nRelated-Change: I4ecfae2bca6ffa08ad15e584579ebce707f4628d\nRelated-Change: I1e244c231753b8f4b6f1cf95cb0ae4c3c959ae0f\nChange-Id: Ia386736b9b283858931794690538871b6e1ad9c8\n'}]",23,877146,b46b735a3e7b1f5b515edde6046e0c53dc3923ae,27,4,2,15343,,,0,"Fix handling of non-ASCII accounts

Related-Change: I4ecfae2bca6ffa08ad15e584579ebce707f4628d
Related-Change: I1e244c231753b8f4b6f1cf95cb0ae4c3c959ae0f
Change-Id: Ia386736b9b283858931794690538871b6e1ad9c8
",git fetch https://review.opendev.org/openstack/swift refs/changes/46/877146/1 && git format-patch -1 --stdout FETCH_HEAD,"['test/functional/test_dlo.py', 'test/unit/common/middleware/test_tempauth.py', 'swift/common/middleware/tempauth.py', 'test/functional/test_slo.py', 'test/functional/test_object_versioning.py', 'test/functional/test_domain_remap.py', 'swift/proxy/controllers/container.py', 'swift/proxy/controllers/base.py']",8,870615cb81875598b7b9f8af05533606ccfa1f50,," resp = self.make_requests(Request.blank(str_to_wsgi('/v1' + path)),"," resp = self.make_requests(Request.blank('/v1' + path),",41,23
openstack%2Fswift~887267,openstack/swift,master,I4976b3ee24e4ec498c66359f391813261d42c495,s3api: emit metrics for error responses,MERGED,2023-06-29 11:28:18.000000000,2023-07-05 22:48:43.000000000,2023-07-05 22:48:43.000000000,"[{'_account_id': 7233}, {'_account_id': 15343}, {'_account_id': 22348}]","[{'number': 1, 'created': '2023-06-29 11:28:18.000000000', 'files': ['test/unit/common/middleware/s3api/__init__.py', 'swift/common/middleware/s3api/s3request.py', 'swift/common/middleware/s3api/s3response.py', 'swift/common/middleware/s3api/s3api.py', 'test/unit/common/middleware/s3api/test_s3api.py'], 'web_link': 'https://opendev.org/openstack/swift/commit/f9af0b70b7ce22014e5756d3bdf863f929f6c71b', 'message': 's3api: emit metrics for error responses\n\nUsers sometimes ask why their request received a 403\nresponse. Sometimes s3api will include a reason in the response body,\nbut client code may not make this visible to the user. To provide some\nother insights, this patch adds statsd metrics when error responses,\nsuch as 403, are returned from the s3api middleware.\n\nThe new metrics have the form:\n\n  s3api.<status_int>.<error_class>[.reason]\n\nFor example:\n\ns3api.403.SignatureDoesNotMatch\ns3api.403.RequestTimeTooSkewed\ns3api.403.AccessDenied.invalid_date\ns3api.400.InvalidBucketName\n\nChange-Id: I4976b3ee24e4ec498c66359f391813261d42c495\n'}]",7,887267,f9af0b70b7ce22014e5756d3bdf863f929f6c71b,12,3,1,7847,,,0,"s3api: emit metrics for error responses

Users sometimes ask why their request received a 403
response. Sometimes s3api will include a reason in the response body,
but client code may not make this visible to the user. To provide some
other insights, this patch adds statsd metrics when error responses,
such as 403, are returned from the s3api middleware.

The new metrics have the form:

  s3api.<status_int>.<error_class>[.reason]

For example:

s3api.403.SignatureDoesNotMatch
s3api.403.RequestTimeTooSkewed
s3api.403.AccessDenied.invalid_date
s3api.400.InvalidBucketName

Change-Id: I4976b3ee24e4ec498c66359f391813261d42c495
",git fetch https://review.opendev.org/openstack/swift refs/changes/67/887267/1 && git format-patch -1 --stdout FETCH_HEAD,"['test/unit/common/middleware/s3api/__init__.py', 'swift/common/middleware/s3api/s3request.py', 'swift/common/middleware/s3api/s3response.py', 'swift/common/middleware/s3api/s3api.py', 'test/unit/common/middleware/s3api/test_s3api.py']",5,f9af0b70b7ce22014e5756d3bdf863f929f6c71b,p-s3api-metrics,"from swift.common.middleware.s3api.s3response import ErrorResponse, \ AccessDenied self.assertEqual({'403.AccessDenied.invalid_header_auth': 1}, self.s3api.logger.logger.get_increment_counts()) self.assertEqual({'405.MethodNotAllowed': 1}, self.s3api.logger.logger.get_increment_counts()) self.assertEqual({'405.MethodNotAllowed': 1}, self.s3api.logger.logger.get_increment_counts()) self.assertEqual({'403.AccessDenied.expired': 1}, self.s3api.logger.logger.get_increment_counts()) self.assertEqual({'403.AccessDenied.invalid_expires': 1}, self.s3api.logger.logger.get_increment_counts()) self.assertEqual({'403.AccessDenied.invalid_query_auth': 1}, self.s3api.logger.logger.get_increment_counts()) self.assertEqual({'403.AccessDenied.invalid_query_auth': 1}, self.s3api.logger.logger.get_increment_counts()) self.s3api.logger.logger.clear() self.assertEqual({'400.AuthorizationQueryParametersError': 1}, self.s3api.logger.logger.get_increment_counts()) self.assertEqual({'403.AccessDenied.invalid_date': 1}, self.s3api.logger.logger.get_increment_counts()) self.assertEqual({'400.InvalidArgument': 1}, self.s3api.logger.logger.get_increment_counts()) self.assertEqual({'400.AuthorizationHeaderMalformed': 1}, self.s3api.logger.logger.get_increment_counts()) self.assertEqual({'403.AccessDenied.invalid_credential': 1}, self.s3api.logger.logger.get_increment_counts()) self.assertEqual({'403.AccessDenied.invalid_query_auth': 1}, self.s3api.logger.logger.get_increment_counts()) self.assertEqual({'400.InvalidURI': 1}, self.s3api.logger.logger.get_increment_counts()) self.assertEqual({'400.InvalidDigest': 1}, self.s3api.logger.logger.get_increment_counts()) self.assertEqual({'400.InvalidDigest': 1}, self.s3api.logger.logger.get_increment_counts()) self.assertEqual({'400.InvalidDigest': 1}, self.s3api.logger.logger.get_increment_counts()) self.assertEqual({'400.InvalidDigest': 1}, self.s3api.logger.logger.get_increment_counts()) self.assertEqual({'400.InvalidArgument': 1}, self.s3api.logger.logger.get_increment_counts()) self.assertEqual({'400.InvalidStorageClass': 1}, self.s3api.logger.logger.get_increment_counts()) self.assertEqual({'400.InvalidArgument': 1}, self.s3api.logger.logger.get_increment_counts()) self.s3api.logger.logger.clear() self.assertEqual({'501.NotImplemented': 1}, self.s3api.logger.logger.get_increment_counts()) self.assertEqual({'501.NotImplemented': 1}, self.s3api.logger.logger.get_increment_counts()) self.assertEqual({}, self.s3api.logger.logger.get_increment_counts()) self.s3api.logger.logger.clear() self.assertEqual({'501.NotImplemented': 1}, self.s3api.logger.logger.get_increment_counts()) self.s3api.logger.logger.clear() self.assertEqual({'501.NotImplemented': 1}, self.s3api.logger.logger.get_increment_counts()) self.assertEqual({'405.MethodNotAllowed': 1}, self.s3api.logger.logger.get_increment_counts()) self.assertEqual({'403.AccessDenied.invalid_date': 1}, self.s3api.logger.logger.get_increment_counts()) self.assertEqual({'400.InvalidRequest': 1}, self.s3api.logger.logger.get_increment_counts()) def test(auth_str, error, msg, metric, extra=b''): self.s3api.logger.logger.clear() self.assertEqual({metric: 1}, self.s3api.logger.logger.get_increment_counts()) test(auth_str, 'AccessDenied', 'Access Denied.', '403.AccessDenied.invalid_credential') 'and Signature.', '400.AuthorizationHeaderMalformed') '400.AuthorizationHeaderMalformed', b'<Region>us-east-1</Region>') 'incorrect service ""not-s3"". This endpoint belongs to ""s3"".', '400.AuthorizationHeaderMalformed') 'This endpoint uses ""aws4_request"".', '400.AuthorizationHeaderMalformed') test(auth_str, 'AccessDenied', 'Access Denied.', '403.AccessDenied.invalid_header_auth') self.assertEqual({'403.AccessDenied.invalid_expires': 1}, self.s3api.logger.logger.get_increment_counts()) self.s3api.logger.logger.clear() self.assertEqual({'403.AccessDenied.invalid_expires': 1}, self.s3api.logger.logger.get_increment_counts()) self.assertEqual( {'403.SignatureDoesNotMatch': 1}, self.s3api.logger.logger.get_increment_counts()) def test_s3api_with_time_skew(self): def do_test(skew): req = Request.blank( '/object', environ={'HTTP_HOST': 'bucket.localhost:80', 'REQUEST_METHOD': 'GET', 'HTTP_AUTHORIZATION': 'AWS test:tester:hmac'}, headers={'Date': self.get_date_header(skew=skew)}) self.s3api.logger.logger.clear() return self.call_s3api(req) status, _, body = do_test(800) self.assertEqual('200 OK', status) self.assertFalse(self.s3api.logger.logger.get_increment_counts()) status, _, body = do_test(-800) self.assertEqual('200 OK', status) self.assertFalse(self.s3api.logger.logger.get_increment_counts()) status, _, body = do_test(1000) self.assertEqual('403 Forbidden', status) self.assertEqual(self._get_error_code(body), 'RequestTimeTooSkewed') self.assertEqual({'403.RequestTimeTooSkewed': 1}, self.s3api.logger.logger.get_increment_counts()) status, _, body = do_test(-1000) self.assertEqual('403 Forbidden', status) self.assertEqual(self._get_error_code(body), 'RequestTimeTooSkewed') self.assertEqual({'403.RequestTimeTooSkewed': 1}, self.s3api.logger.logger.get_increment_counts()) self.s3api.conf.allowable_clock_skew = 100 status, _, body = do_test(800) self.assertEqual('403 Forbidden', status) self.assertEqual(self._get_error_code(body), 'RequestTimeTooSkewed') self.assertEqual({'403.RequestTimeTooSkewed': 1}, self.s3api.logger.logger.get_increment_counts()) def test_s3api_error_metric(self): class KaboomResponse(ErrorResponse): _code = 'ka boom' def do_test(err_response): req = Request.blank( '/object', environ={'HTTP_HOST': 'bucket.localhost:80', 'REQUEST_METHOD': 'GET', 'HTTP_AUTHORIZATION': 'AWS test:tester:hmac'}, headers={'Date': self.get_date_header()}) self.s3api.logger.logger.clear() with mock.patch.object( self.s3api, 'handle_request', side_effect=err_response): self.call_s3api(req) do_test(ErrorResponse(status=403, msg='not good', reason='bad')) self.assertEqual({'403.ErrorResponse.bad': 1}, self.s3api.logger.logger.get_increment_counts()) do_test(AccessDenied(msg='no entry', reason='invalid_date')) self.assertEqual({'403.AccessDenied.invalid_date': 1}, self.s3api.logger.logger.get_increment_counts()) # check whitespace replaced with underscore do_test(KaboomResponse(status=400, msg='boom', reason='boom boom')) self.assertEqual({'400.ka_boom.boom_boom': 1}, self.s3api.logger.logger.get_increment_counts()) "," def test(auth_str, error, msg, extra=b''): test(auth_str, 'AccessDenied', 'Access Denied.') 'and Signature.') b'<Region>us-east-1</Region>') 'incorrect service ""not-s3"". This endpoint belongs to ""s3"".') 'This endpoint uses ""aws4_request"".') test(auth_str, 'AccessDenied', 'Access Denied.')",197,31
openstack%2Fswift~887226,openstack/swift,master,Iadc54111e79910dd1809e21facba81153ca61822,tests: Stop requiring <1ms test runtime,MERGED,2023-06-28 19:57:22.000000000,2023-07-05 22:48:15.000000000,2023-07-05 22:48:15.000000000,"[{'_account_id': 597}, {'_account_id': 15343}, {'_account_id': 22348}]","[{'number': 1, 'created': '2023-06-28 19:57:22.000000000', 'files': ['test/unit/obj/test_replicator.py'], 'web_link': 'https://opendev.org/openstack/swift/commit/82b5335fd5420a09c1495217b68afb6eb044af15', 'message': 'tests: Stop requiring <1ms test runtime\n\nChange-Id: Iadc54111e79910dd1809e21facba81153ca61822\n'}]",0,887226,82b5335fd5420a09c1495217b68afb6eb044af15,8,3,1,15343,,,0,"tests: Stop requiring <1ms test runtime

Change-Id: Iadc54111e79910dd1809e21facba81153ca61822
",git fetch https://review.opendev.org/openstack/swift refs/changes/26/887226/1 && git format-patch -1 --stdout FETCH_HEAD,['test/unit/obj/test_replicator.py'],1,82b5335fd5420a09c1495217b68afb6eb044af15,," with mock.patch( 'swift.obj.replicator.subprocess.Popen') as mock_popen, \ mock.patch('time.time', side_effect=[123.4, 123.5]): '192.168.50.30::object/d8/objects/241 (0.100)']) with mock.patch( 'swift.obj.replicator.subprocess.Popen') as mock_popen, \ mock.patch('time.time', side_effect=[123.4, 123.5]): '192.168.50.30::object/d8/objects/241 (0.100)'])", with mock.patch('swift.obj.replicator.subprocess.Popen') as mock_popen: '192.168.50.30::object/d8/objects/241 (0.000)']) with mock.patch('swift.obj.replicator.subprocess.Popen') as mock_popen: '192.168.50.30::object/d8/objects/241 (0.000)']),8,4
openstack%2Fcharm-ironic-api~887421,openstack/charm-ironic-api,stable/ussuri,Ic84e4706b93c38916e89b91dfc30bf32396e5213,Add support for using service tokens,MERGED,2023-06-30 17:22:51.000000000,2023-07-05 22:39:41.000000000,2023-07-05 22:39:41.000000000,"[{'_account_id': 935}, {'_account_id': 20648}, {'_account_id': 20870}, {'_account_id': 22348}, {'_account_id': 32029}]","[{'number': 1, 'created': '2023-06-30 17:22:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-ironic-api/commit/780a7c0e2661a9a5b0f195d0d51fc5c1288906ce', 'message': 'Add support for using service tokens\n\nThis patch configures ironic-api to send a service token along with the\nreceived user token on requests to other services. This allow those\nother services to accept the request even if the user token has been\ninvalidated since received by Ironic. Also with this patch Ironic will\naccept request from other services with invalid user tokens but valid\nservice tokens.\n\nUpdate src/build.lock to get backported patches into\ncharm-helpers@stable/yoga\n\nCloses-Bug: #1992840\nChange-Id: Ic84e4706b93c38916e89b91dfc30bf32396e5213\n(cherry picked from commit 02b7180a6b9cd9c22c4b672ae8510ea14af5e0df)\n(cherry picked from commit fca337274407d8c145c33fe5ce4805497878eb04)\n'}, {'number': 2, 'created': '2023-06-30 17:23:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-ironic-api/commit/14ea4ee0753d86124a6e06abd0c985a6f6d466db', 'message': 'Add support for using service tokens\n\nThis patch configures ironic-api to send a service token along with the\nreceived user token on requests to other services. This allow those\nother services to accept the request even if the user token has been\ninvalidated since received by Ironic. Also with this patch Ironic will\naccept request from other services with invalid user tokens but valid\nservice tokens.\n\nUpdate src/build.lock to get backported patches into\ncharm-helpers@stable/ussuri\n\nCloses-Bug: #1992840\nChange-Id: Ic84e4706b93c38916e89b91dfc30bf32396e5213\n(cherry picked from commit 02b7180a6b9cd9c22c4b672ae8510ea14af5e0df)\n(cherry picked from commit fca337274407d8c145c33fe5ce4805497878eb04)\n'}, {'number': 3, 'created': '2023-07-03 13:02:04.000000000', 'files': ['src/templates/train/ironic.conf', 'src/templates/parts/keystone-authtoken', 'src/build.lock'], 'web_link': 'https://opendev.org/openstack/charm-ironic-api/commit/b9bee8cee23aa2cf22401b393de7639b81893431', 'message': 'Add support for using service tokens\n\nThis patch configures ironic-api to send a service token along with the\nreceived user token on requests to other services. This allow those\nother services to accept the request even if the user token has been\ninvalidated since received by Ironic. Also with this patch Ironic will\naccept request from other services with invalid user tokens but valid\nservice tokens.\n\nUpdate src/build.lock to get backported patches into\ncharm-helpers@stable/ussuri\n\nCloses-Bug: #1992840\nDepends-On: https://review.opendev.org/c/openstack/charm-ironic-api/+/887514\nChange-Id: Ic84e4706b93c38916e89b91dfc30bf32396e5213\n(cherry picked from commit 02b7180a6b9cd9c22c4b672ae8510ea14af5e0df)\n(cherry picked from commit fca337274407d8c145c33fe5ce4805497878eb04)\n'}]",0,887421,b9bee8cee23aa2cf22401b393de7639b81893431,13,5,3,11805,,,0,"Add support for using service tokens

This patch configures ironic-api to send a service token along with the
received user token on requests to other services. This allow those
other services to accept the request even if the user token has been
invalidated since received by Ironic. Also with this patch Ironic will
accept request from other services with invalid user tokens but valid
service tokens.

Update src/build.lock to get backported patches into
charm-helpers@stable/ussuri

Closes-Bug: #1992840
Depends-On: https://review.opendev.org/c/openstack/charm-ironic-api/+/887514
Change-Id: Ic84e4706b93c38916e89b91dfc30bf32396e5213
(cherry picked from commit 02b7180a6b9cd9c22c4b672ae8510ea14af5e0df)
(cherry picked from commit fca337274407d8c145c33fe5ce4805497878eb04)
",git fetch https://review.opendev.org/openstack/charm-ironic-api refs/changes/21/887421/1 && git format-patch -1 --stdout FETCH_HEAD,"['src/templates/train/ironic.conf', 'src/templates/parts/keystone-authtoken', 'src/build.lock']",3,780a7c0e2661a9a5b0f195d0d51fc5c1288906ce,bug/1992840," ""version"": ""87f9a8df625ce6cd0c2a04da2d718ab7f9c1aad3"",} "," ""version"": ""a99a667d343ab3c11074d8bc8c6d8b5d638f73b7"",}",6,2
openstack%2Fcharm-ironic-api~887514,openstack/charm-ironic-api,stable/ussuri,I8f1cd484ceeb79f57276cd69e14a5d47a2f7073d,Install libpq-dev bindep for py36,MERGED,2023-07-03 13:00:32.000000000,2023-07-05 22:39:40.000000000,2023-07-05 22:39:40.000000000,"[{'_account_id': 8992}, {'_account_id': 20648}, {'_account_id': 20870}, {'_account_id': 22348}]","[{'number': 1, 'created': '2023-07-03 13:00:32.000000000', 'files': ['bindep.txt'], 'web_link': 'https://opendev.org/openstack/charm-ironic-api/commit/417b0b619193380e911c3122b2c0c69f0b66e8db', 'message': 'Install libpq-dev bindep for py36\n\nWithout this py36 tests are failing with:\n""Error: pg_config executable not found""\n\nChange-Id: I8f1cd484ceeb79f57276cd69e14a5d47a2f7073d\n'}]",1,887514,417b0b619193380e911c3122b2c0c69f0b66e8db,10,4,1,11805,,,0,"Install libpq-dev bindep for py36

Without this py36 tests are failing with:
""Error: pg_config executable not found""

Change-Id: I8f1cd484ceeb79f57276cd69e14a5d47a2f7073d
",git fetch https://review.opendev.org/openstack/charm-ironic-api refs/changes/14/887514/1 && git format-patch -1 --stdout FETCH_HEAD,['bindep.txt'],1,417b0b619193380e911c3122b2c0c69f0b66e8db,,libpq-dev [platform:dpkg] ,,1,0
openstack%2Fcharm-ironic-conductor~887417,openstack/charm-ironic-conductor,stable/ussuri,Ie94b5ce9ba9d015a31a78bb71ce7ca786377d6d9,Add support for using service tokens,MERGED,2023-06-30 17:17:42.000000000,2023-07-05 22:39:18.000000000,2023-07-05 22:39:18.000000000,"[{'_account_id': 935}, {'_account_id': 20648}, {'_account_id': 20870}, {'_account_id': 22348}]","[{'number': 1, 'created': '2023-06-30 17:17:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-ironic-conductor/commit/a2d21c8d8a90ad0154e946845090cb7370e7db87', 'message': 'Add support for using service tokens\n\nThis patch configures ironic-conductor to send a service token along\nwith the received user token on requests to other services. This allow\nthose other services to accept the request even if the user token has\nbeen invalidated since received by Ironic. Also with this patch Ironic\nwill accept request from other services with invalid user tokens but\nvalid service tokens.\n\nUpdate src/build.lock to get backported patches into\ncharm-helpers@stable/zed\n\nCloses-Bug: #1992840\nChange-Id: Ie94b5ce9ba9d015a31a78bb71ce7ca786377d6d9\n(cherry picked from commit c7dda3f3a8c4b3e5445c727590eb44e4a6482cc3)\n(cherry picked from commit aa73b57b9c4bffd376ca65869df964bc205accef)\n'}, {'number': 2, 'created': '2023-06-30 17:24:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-ironic-conductor/commit/7bd595fb9e6c101ef0a0e2e8185e8283ff3e71c8', 'message': 'Add support for using service tokens\n\nThis patch configures ironic-conductor to send a service token along\nwith the received user token on requests to other services. This allow\nthose other services to accept the request even if the user token has\nbeen invalidated since received by Ironic. Also with this patch Ironic\nwill accept request from other services with invalid user tokens but\nvalid service tokens.\n\nUpdate src/build.lock to get backported patches into\ncharm-helpers@stable/ussuri\n\nCloses-Bug: #1992840\nChange-Id: Ie94b5ce9ba9d015a31a78bb71ce7ca786377d6d9\n(cherry picked from commit c7dda3f3a8c4b3e5445c727590eb44e4a6482cc3)\n(cherry picked from commit aa73b57b9c4bffd376ca65869df964bc205accef)\n'}, {'number': 3, 'created': '2023-07-03 13:01:17.000000000', 'files': ['src/templates/train/ironic.conf', 'src/templates/parts/keystone-authtoken', 'src/build.lock'], 'web_link': 'https://opendev.org/openstack/charm-ironic-conductor/commit/0f0d5692aeadad01785f01c487902ccb272c2b24', 'message': 'Add support for using service tokens\n\nThis patch configures ironic-conductor to send a service token along\nwith the received user token on requests to other services. This allow\nthose other services to accept the request even if the user token has\nbeen invalidated since received by Ironic. Also with this patch Ironic\nwill accept request from other services with invalid user tokens but\nvalid service tokens.\n\nUpdate src/build.lock to get backported patches into\ncharm-helpers@stable/ussuri\n\nCloses-Bug: #1992840\nDepends-On: https://review.opendev.org/c/openstack/charm-ironic-conductor/+/887512\nChange-Id: Ie94b5ce9ba9d015a31a78bb71ce7ca786377d6d9\n(cherry picked from commit c7dda3f3a8c4b3e5445c727590eb44e4a6482cc3)\n(cherry picked from commit aa73b57b9c4bffd376ca65869df964bc205accef)\n'}]",0,887417,0f0d5692aeadad01785f01c487902ccb272c2b24,12,4,3,11805,,,0,"Add support for using service tokens

This patch configures ironic-conductor to send a service token along
with the received user token on requests to other services. This allow
those other services to accept the request even if the user token has
been invalidated since received by Ironic. Also with this patch Ironic
will accept request from other services with invalid user tokens but
valid service tokens.

Update src/build.lock to get backported patches into
charm-helpers@stable/ussuri

Closes-Bug: #1992840
Depends-On: https://review.opendev.org/c/openstack/charm-ironic-conductor/+/887512
Change-Id: Ie94b5ce9ba9d015a31a78bb71ce7ca786377d6d9
(cherry picked from commit c7dda3f3a8c4b3e5445c727590eb44e4a6482cc3)
(cherry picked from commit aa73b57b9c4bffd376ca65869df964bc205accef)
",git fetch https://review.opendev.org/openstack/charm-ironic-conductor refs/changes/17/887417/1 && git format-patch -1 --stdout FETCH_HEAD,"['src/templates/train/ironic.conf', 'src/templates/parts/keystone-authtoken', 'src/build.lock']",3,a2d21c8d8a90ad0154e946845090cb7370e7db87,bug/1992840," ""version"": ""87f9a8df625ce6cd0c2a04da2d718ab7f9c1aad3"",} "," ""version"": ""a99a667d343ab3c11074d8bc8c6d8b5d638f73b7"",}",6,2
openstack%2Fcharm-ironic-conductor~887512,openstack/charm-ironic-conductor,stable/ussuri,Ia02517f071dd0b512527dd92bf8a1f918b8ae6a0,Install libpq-dev bindep for py36,MERGED,2023-07-03 12:58:33.000000000,2023-07-05 22:36:28.000000000,2023-07-05 22:36:28.000000000,"[{'_account_id': 8992}, {'_account_id': 20648}, {'_account_id': 20870}, {'_account_id': 22348}]","[{'number': 1, 'created': '2023-07-03 12:58:33.000000000', 'files': ['bindep.txt'], 'web_link': 'https://opendev.org/openstack/charm-ironic-conductor/commit/15ed6c342765d3c91ed541e1f7f57e37e581e7f4', 'message': 'Install libpq-dev bindep for py36\n\nWithout this py36 tests are failing with:\n""Error: pg_config executable not found""\n\nChange-Id: Ia02517f071dd0b512527dd92bf8a1f918b8ae6a0\n'}]",0,887512,15ed6c342765d3c91ed541e1f7f57e37e581e7f4,8,4,1,11805,,,0,"Install libpq-dev bindep for py36

Without this py36 tests are failing with:
""Error: pg_config executable not found""

Change-Id: Ia02517f071dd0b512527dd92bf8a1f918b8ae6a0
",git fetch https://review.opendev.org/openstack/charm-ironic-conductor refs/changes/12/887512/1 && git format-patch -1 --stdout FETCH_HEAD,['bindep.txt'],1,15ed6c342765d3c91ed541e1f7f57e37e581e7f4,,libpq-dev [platform:dpkg] ,,1,0
openstack%2Fcinder~847620,openstack/cinder,master,Id0f57cc855cd7470a7b1ca299c87c079a2e48d1e,Add benji-backup.me driver to cinder,NEW,2022-06-24 21:42:47.000000000,2023-07-05 21:58:16.000000000,,[{'_account_id': 22348}],"[{'number': 1, 'created': '2022-06-24 21:42:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/f302d7bcfbbf7869e0aa2891aa38e96936233a57', 'message': 'Add benji-backup.me driver to ceph and other backends\n\nSigned-off-by: Jesper Schmtiz Mouridsen <jesper@schmitz.computer>\nChange-Id: Id0f57cc855cd7470a7b1ca299c87c079a2e48d1e\n'}, {'number': 2, 'created': '2022-06-25 15:15:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/1640140c31d9f1a82b9d0c75c94a805073560421', 'message': 'Add benji-backup.me driver to ceph and other backends\n\nSigned-off-by: Jesper Schmtiz Mouridsen <jesper@schmitz.computer>\nChange-Id: Id0f57cc855cd7470a7b1ca299c87c079a2e48d1e\n'}, {'number': 3, 'created': '2023-06-24 17:54:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/fb601c9c8f678dde77f4afa3705198688aac25c8', 'message': 'Add benji-backup.me driver to ceph and other backends\n\nSigned-off-by: Jesper Schmtiz Mouridsen <jesper@schmitz.computer>\nChange-Id: Id0f57cc855cd7470a7b1ca299c87c079a2e48d1e\n'}, {'number': 4, 'created': '2023-06-25 17:34:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/51e94d30d214b2f3fdf789882d3f526c32e97eab', 'message': 'Add benji-backup.me driver to ceph and other backends\n\nSigned-off-by: Jesper Schmtiz Mouridsen <jesper@schmitz.computer>\nChange-Id: Id0f57cc855cd7470a7b1ca299c87c079a2e48d1e\n'}, {'number': 5, 'created': '2023-06-25 19:57:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/0d7e5d430cf67f1133abfc733c1e0ecbde12f750', 'message': 'Add benji-backup.me driver to cinder\n\n The backup driver supports\n ceph and other cinder volume backends\n\nSigned-off-by: Jesper Schmtiz Mouridsen <jesper@schmitz.computer>\nChange-Id: Id0f57cc855cd7470a7b1ca299c87c079a2e48d1e\n'}, {'number': 6, 'created': '2023-07-02 16:41:33.000000000', 'files': ['cinder/opts.py', 'tools/install-requirements-wrapper.sh', 'cinder/backup/drivers/benjidriver.py', 'benji-requirements.txt', 'mypy-files.txt', 'tox.ini'], 'web_link': 'https://opendev.org/openstack/cinder/commit/0614457b804b42a63546090f423dd3c78268e433', 'message': 'Add benji-backup.me driver to cinder\n\n The backup driver supports\n ceph and other cinder volume backends\n\nSigned-off-by: Jesper Schmtiz Mouridsen <jesper@schmitz.computer>\nChange-Id: Id0f57cc855cd7470a7b1ca299c87c079a2e48d1e\n'}]",4,847620,0614457b804b42a63546090f423dd3c78268e433,96,1,6,29260,,,0,"Add benji-backup.me driver to cinder

 The backup driver supports
 ceph and other cinder volume backends

Signed-off-by: Jesper Schmtiz Mouridsen <jesper@schmitz.computer>
Change-Id: Id0f57cc855cd7470a7b1ca299c87c079a2e48d1e
",git fetch https://review.opendev.org/openstack/cinder refs/changes/20/847620/1 && git format-patch -1 --stdout FETCH_HEAD,['cinder/backup/drivers/benjidriver.py'],1,f302d7bcfbbf7869e0aa2891aa38e96936233a57,,"# Copyright 2022 Jesper Schmitz Mouridsen. # All Rights Reserved. # # Licensed under the Apache License, Version 2.0 (the ""License""); you may # not use this file except in compliance with the License. You may obtain # a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT # WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the # License for the specific language governing permissions and limitations # under the License. from datetime import datetime from typing import Optional, Tuple # noqa: H301 from benji.benji import Benji from benji.benji import VersionUid import benji.config as benji_config from benji.io.factory import IOFactory from benji.storage.factory import StorageFactory import eventlet from os_brick.remotefs import remotefs as remotefs_brick from oslo_config import cfg from oslo_log import log as logging import rados import rbd from cinder.backup import driver from cinder import exception from cinder import utils import cinder.volume.drivers.rbd as rbd_driver def setup_logging(): extra_log_level_defaults = [ 'dogpile=INFO', 'routes=INFO', 'benji=INFO' ] logging.set_defaults( default_log_levels=logging.get_default_log_levels() + extra_log_level_defaults) logging.setup(CONF, ""cinder-backup"") service_opts = [ cfg.StrOpt('benji_storage_name', default=None, help='Name of benji storage from benji.yaml to use'), cfg.StrOpt('benji_nfs_share_path', default=None, help='NFS share in hostname:path, ipv4addr:path, ' 'or ""[ipv6addr]:path"" format.'), cfg.StrOpt('benji_backup_mount_point_base', default='$state_path/benji_backup_mount', help='Base dir containing mount point for NFS share.'), cfg.StrOpt('benji_io_scheme_ceph', default='cinder-volumes', help='Benji io scheme for ceph sources to backup'), cfg.StrOpt('benji_io_scheme_file', default='file', help='Benji io scheme for file sources to backup'), cfg.StrOpt('benji_snapshot_prefix', default='benjibackup-', help='prefix for rbd snaphots'), cfg.StrOpt('benji_premade_snapshot_prefix', default='benjibackup_premade-', help='prefix for premade rbd snaphots'), ] CONF = cfg.CONF CONF.register_opts(service_opts) setup_logging() LOG = logging.getLogger(__name__) class BenjiBackupDriver(driver.BackupDriver): """"""Provides backup, restore and delete using benji-backup system."""""" def __init__(self, context, db=None): super().__init__(context) self.rados = rados self.rbd = rbd self.diff_list = [] if CONF.benji_nfs_share_path is not None: self.nfs_mount_path = self._mount_nfs() bconfig = benji_config.Config() if CONF.benji_storage_name is None: self.storage_name = bconfig.get(""defaultStorage"") else: self.storage_name = CONF.benji_storage_name self.storages = bconfig.get(""storages"") IOFactory.initialize(bconfig) StorageFactory.initialize(bconfig) self.b_backup = Benji(bconfig) self.ios = bconfig.get(""ios"") def check_for_setup_error(self): rbdmodules = [iomodule for iomodule in self.ios if iomodule[""module""] == ""rbd""] config_modules = [iomodule for iomodule in rbdmodules if iomodule[""name""] == CONF.benji_io_scheme_ceph] if rbdmodules and not config_modules: raise exception.BackupDriverException( reason=""No ios module rbd named %(name)s in benji.yaml"" % {'name': CONF.benji_io_scheme_ceph}) storage = [storage for storage in self.storages if storage[""name""] == self.storage_name] LOG.debug(storage) if CONF.benji_nfs_share_path is None: return if not storage: raise exception.BackupDriverException( reason=""storage name '%(storage_name)s"" ""' not found in /etc/benji.yaml"" % {'storage_name': self.storage_name}) if storage[0][""configuration""][""path""] != self.nfs_mount_path: raise exception.BackupDriverException( reason=""mount point '%(mount_point)s' not found in "" ""/etc/benji.yaml in "" ""storage '%(storage_name)s' configuration path"" % {'mount_point': self.nfs_mount_path, 'storage_name': self.storage_name}) def _mount_nfs(self): remotefsclient = remotefs_brick.RemoteFsClient( 'nfs', utils.get_root_helper(), nfs_mount_point_base=CONF.benji_backup_mount_point_base, nfs_mount_options="""") remotefsclient.mount(CONF.benji_nfs_share_path) nfs_share_path = CONF.benji_nfs_share_path mount_point = remotefsclient.get_mount_point(nfs_share_path) LOG.info(""Usinng '%(mount_point)s'"", {'mount_point': mount_point}) return mount_point def iterate_cb(self, offset, length, exists): self.diff_list.append((offset, length, exists)) def _connect_to_rados(self, pool: Optional[str] = None) -> Tuple['rados.Rados', 'rados.Ioctx']: """"""Establish connection to the Ceph cluster."""""" client = eventlet.tpool.Proxy(rados.Rados( rados_id=self.ceph_user, conffile=self.ceph_conf )) try: client.connect() pool_to_open = pool or self.pool ioctx = client.open_ioctx(pool_to_open) return client, ioctx except rados.Error: # shutdown cannot raise an exception client.shutdown() raise @staticmethod def _disconnect_from_rados(client: 'rados.Rados', ioctx: 'rados.Ioctx') -> None: """"""Terminate connection with the Ceph cluster."""""" # closing an ioctx cannot raise an exception LOG.debug(""disconnect"") ioctx.close() client.shutdown() def _rename_snap(self, source_rbd, premade_snap, snapshot): LOG.info(""renaming '%(premade_snap)s' to '%(snap)s'"", { 'premade_snap': premade_snap, 'snap': snapshot}) source_rbd.rename_snap(premade_snap, snapshot) def _get_snap_list(self, source_rbd: rbd.Image, snap_prefix): snapshotlist = source_rbd.list_snaps() benji_snaps = [ snapshot[""name""] for snapshot in snapshotlist if snapshot[""name""].startswith(snap_prefix) ] return benji_snaps def _get_snap_path(self, volume_id, snapshot, include_io_scheme=False): image_name = CONF.volume_name_template % volume_id if include_io_scheme: return ""{0}:{1}/{2}@{3}"".format(self.io_scheme, self.pool, image_name, snapshot) else: return '{0}/{1}@{2}'.format(self.pool, image_name, snapshot) def get_metadata(self, volume_id): return self.backup_meta_api.get(volume_id) def put_metadata(self, volume_id, json_metadata): self.backup_meta_api.put(volume_id, json_metadata) def _parse_backend(self, volume_id): # Using DEFAULT section to configure drivers # is not supported since Ocata. if len(CONF.enabled_backends) > 1: src_volume = self.db.volume_get(self.context, volume_id) backend = [b.value for b in src_volume.volume_type.extra_specs if b.key == ""volume_backend_name""] LOG.debug(src_volume.volume_type.extra_specs) LOG.debug(""'%(backend)s'"", {'backend': backend}) else: backend = CONF.enabled_backends return backend def _backup_rbd_differential(self, backup): with eventlet.tpool.Proxy(rbd_driver.RADOSClient( self, self.pool)) as client: with eventlet.tpool.Proxy(self.rbd.Image( client.ioctx, CONF.volume_name_template % backup.volume_id, read_only=False)) as source_rbd: benji_snaps_unsorted = self._get_snap_list( source_rbd, CONF.benji_snapshot_prefix) # sort the list by name without the prefix, i.e by date. benji_snaps = sorted(benji_snaps_unsorted, key=lambda x: x.split( CONF.benji_snapshot_prefix)[1]) LOG.debug(benji_snaps) for delete_snapname in benji_snaps[:-1]: source_rbd.remove_snap(delete_snapname) last_snapshot = benji_snaps[-1] versions = self.b_backup.find_versions_with_filter( f'volume == ""{backup.volume_id}""\ and snapshot == ""{last_snapshot}""\ and status == ""valid""') if len(versions) == 0: raise exception.BackupDriverException( reason = 'latest snapshot is not in ' + 'benji db please fallback to full backup') LOG.debug(versions[0].uid) now = datetime.utcnow() snapshot = now.strftime(CONF.benji_snapshot_prefix + '%Y-%m-%dT%H:%M:%SZ') premade_snaps = self._get_snap_list( source_rbd, CONF.benji_premade_snapshot_prefix) LOG.debug(premade_snaps) if len(premade_snaps) > 0: self._rename_snap(source_rbd, premade_snaps[-1], snapshot) else: source_rbd.create_snap(snapshot) with eventlet.tpool.Proxy( self.rbd.Image( client.ioctx, CONF.volume_name_template % backup.volume_id, snapshot=snapshot, read_only=False)) as source_rbd_snap: self.diff_list = [] source_rbd_snap.diff_iterate( 0, source_rbd_snap.size(), last_snapshot, self.iterate_cb, whole_object=True) source_rbd.remove_snap(last_snapshot) self.b_backup.backup(version_uid=backup.id, base_version_uid=versions[0].uid, volume=backup.volume_id, snapshot=snapshot, storage_name=self.storage_name, source=self._get_snap_path( backup.volume_id, snapshot, include_io_scheme=True), hints=self.diff_list) self._add_labels(backup) source_rbd_snap.close() source_rbd.close() return def _backup_rbd_initial(self, backup): with eventlet.tpool.Proxy(rbd_driver.RADOSClient( self, self.pool)) as client: with eventlet.tpool.Proxy(self.rbd.Image( client.ioctx, CONF.volume_name_template % backup.volume_id, read_only=False)) as source_rbd: now = datetime.utcnow() snapshot = now.strftime(CONF.benji_snapshot_prefix + '%Y-%m-%dT%H:%M:%SZ') premade_snaps = self._get_snap_list( source_rbd, CONF.benji_premade_snapshot_prefix) LOG.debug(premade_snaps) if len(premade_snaps) > 0: self._rename_snap(source_rbd, premade_snaps[-1], snapshot) else: LOG.debug(source_rbd.get_name()) LOG.debug(source_rbd.create_snap(snapshot)) with eventlet.tpool.Proxy(self.rbd.Image( client.ioctx, CONF.volume_name_template % backup.volume_id, snapshot=snapshot, read_only=False)) as source_rbd_snap: self.diff_list = [] source_rbd_snap.diff_iterate(0, source_rbd.size(), None, self.iterate_cb, whole_object=True) self.b_backup.backup(version_uid=backup.id, volume=backup.volume_id, snapshot=snapshot, storage_name=self.storage_name, source=self._get_snap_path( backup.volume_id, snapshot, include_io_scheme=True), hints=self.diff_list) self._add_labels(backup) LOG.debug(""done"") source_rbd_snap.close() source_rbd.close() return def _add_labels(self, backup): Benji.add_label(version_uid=backup.id, key='openstack-project-id', value=backup.project_id) Benji.add_label(version_uid=backup.id, key='openstack-user-id', value=backup.user_id) def _backup_file(self, backup, volume_file): source = f'{self.io_scheme}:{volume_file._obj.name}' self.b_backup.backup(version_uid=backup.id, source=source, snapshot="""", storage_name=self.storage_name, volume=backup.volume_id) self._add_labels(backup) def backup(self, backup, volume_file, backup_metadata=False): """"""Start a backup of a specified volume. Some I/O operations may block greenthreads, so in order to prevent starvation parameter volume_file will be a proxy that will execute all methods in native threads, so the method implementation doesn't need to worry about that.. """""" backend = self._parse_backend(backup.volume_id) if hasattr(volume_file, 'rbd_image'): self.io_scheme = CONF.benji_io_scheme_ceph CONF.register_opts(rbd_driver.RBD_OPTS, group=backend[0]) LOG.debug(CONF[backend[0]].rbd_pool) self.pool = CONF[backend[0]].rbd_pool LOG.debug(self.pool) self.ceph_user = CONF[backend[0]].rbd_user self.ceph_conf = CONF[backend[0]].rbd_ceph_conf else: self.io_scheme = CONF.benji_io_scheme_file if backup[""snapshot_id""] is not None: if hasattr(volume_file, 'rbd_image'): ceph_name = volume_file.rbd_image.image.get_name() source = f'{self.io_scheme}:{self.pool}/{ceph_name}' else: dev_file = volume_file._obj.name source = f'{CONF.benji_io_scheme_file}:{dev_file}' self.b_backup.backup(version_uid=backup.id, source=source, storage_name=self.storage_name, snapshot="""", volume=backup.volume_id) self._add_labels(backup) elif backup['parent_id'] is None: if self.io_scheme == CONF.benji_io_scheme_ceph: self._backup_rbd_initial(backup) elif self.io_scheme == CONF.benji_io_scheme_file: self._backup_file(backup, volume_file) elif backup['parent_id'] is not None: if self.io_scheme == CONF.benji_io_scheme_ceph: self._backup_rbd_differential(backup) elif self.io_scheme == CONF.benji_io_scheme_file: self._backup_file(backup, volume_file) def restore(self, backup, volume_id, volume_file): """"""Restore a saved backup. Some I/O operations may block greenthreads, so in order to prevent G starvation parameter volume_file will be a proxy that will execute all methods in native threads, so the method implementation doesn't need to worry about that.. May raise BackupRestoreCancel to indicate that the restoration of a volume has been aborted by changing the backup status. """""" backend = self._parse_backend(volume_id) force = True sparse = False if hasattr(volume_file, 'rbd_image'): image_name = volume_file.rbd_image.image.get_name() CONF.register_opts(rbd_driver.RBD_OPTS, group=backend[0]) pool = CONF[backend[0]].rbd_pool target = f'{CONF.benji_io_scheme_ceph}:{pool}/{image_name}' sparse = True else: target = f'{CONF.benji_io_scheme_file}:{volume_file._obj.name}' LOG.debug(self.b_backup.restore(version_uid=backup.id, target=target, sparse=sparse, force=force)) return def delete_backup(self, backup): """"""Delete a saved backup."""""" try: self.b_backup.rm(VersionUid(backup.id), force=True) except KeyError: LOG.warning(""'%(version_uid)s' not found in benji database"", {'version_uid': backup.id}) return def export_record(self, backup): """"""Export driver specific backup record information. If backup backend needs additional driver specific information to import backup record back into the system it must overwrite this method and return it here as a dictionary so it can be serialized into a string. Default backup driver implementation has no extra information. :param backup: backup object to export :returns: driver_info - dictionary with extra information """""" return {} def import_record(self, backup, driver_info): """"""Import driver specific backup record information. If backup backend needs additional driver specific information to import backup record back into the system it must overwrite this method since it will be called with the extra information that was provided by export_record when exporting the backup. Default backup driver implementation does nothing since it didn't export any specific data in export_record. :param backup: backup object to export :param driver_info: dictionary with driver specific backup record information :returns: nothing """""" return ",,455,0
openstack%2Fdevstack-plugin-ceph~887111,openstack/devstack-plugin-ceph,master,I5b852797dc05f1de55a2b294289938b9962c38e1,Unskip rebuild_volume_backed_server test,MERGED,2023-06-27 19:19:23.000000000,2023-07-05 20:47:24.000000000,2023-07-05 20:46:33.000000000,"[{'_account_id': 8556}, {'_account_id': 16643}, {'_account_id': 22348}]","[{'number': 1, 'created': '2023-06-27 19:19:23.000000000', 'files': ['tempest_skiplist.txt'], 'web_link': 'https://opendev.org/openstack/devstack-plugin-ceph/commit/c4d753d37a7b431ef91ab44c8abeb0bcc4a39334', 'message': 'Unskip rebuild_volume_backed_server test\n\nThis was actually due to a too-strict-for-AIO-machines default timeout,\nwhich is bumped in the dependent patch.\n\nCloses-Bug: #2025096\nDepends-On: https://review.opendev.org/c/openstack/devstack/+/887110\nChange-Id: I5b852797dc05f1de55a2b294289938b9962c38e1\n'}]",7,887111,c4d753d37a7b431ef91ab44c8abeb0bcc4a39334,24,3,1,4393,,,0,"Unskip rebuild_volume_backed_server test

This was actually due to a too-strict-for-AIO-machines default timeout,
which is bumped in the dependent patch.

Closes-Bug: #2025096
Depends-On: https://review.opendev.org/c/openstack/devstack/+/887110
Change-Id: I5b852797dc05f1de55a2b294289938b9962c38e1
",git fetch https://review.opendev.org/openstack/devstack-plugin-ceph refs/changes/11/887111/1 && git format-patch -1 --stdout FETCH_HEAD,['tempest_skiplist.txt'],1,c4d753d37a7b431ef91ab44c8abeb0bcc4a39334,reimage-timeout,," # TODO: Due to password injection issue during rebuild, this test fail on ceph job 100%. # Remve this test from this file once bug: https://bugs.launchpad.net/tempest/+bug/2025096 # is fixed. tempest.api.compute.servers.test_server_actions.ServerActionsV293TestJSON.test_rebuild_volume_backed_server",0,5
openstack%2Fkeystone~886509,openstack/keystone,master,Id92d74d368356d67d5a9be6d3eada44cd190a35d,Add job to test with SQLAlchemy master (2.x),MERGED,2023-06-20 15:33:40.000000000,2023-07-05 20:43:03.000000000,2023-07-05 20:40:42.000000000,"[{'_account_id': 7414}, {'_account_id': 14250}, {'_account_id': 22348}]","[{'number': 1, 'created': '2023-06-20 15:33:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/2fd52713bb64b6c68c670a98cc4e90cc106ce9be', 'message': 'Add job to test with SQLAlchemy master (2.x)\n\nChange-Id: Id92d74d368356d67d5a9be6d3eada44cd190a35d\nSigned-off-by: Stephen Finucane <sfinucan@redhat.com>\n'}, {'number': 2, 'created': '2023-06-27 09:58:52.000000000', 'files': ['.zuul.yaml'], 'web_link': 'https://opendev.org/openstack/keystone/commit/b2d638e902b0164b1a9531aa1d12a56f103206ec', 'message': 'Add job to test with SQLAlchemy master (2.x)\n\nChange-Id: Id92d74d368356d67d5a9be6d3eada44cd190a35d\nSigned-off-by: Stephen Finucane <sfinucan@redhat.com>\n'}]",0,886509,b2d638e902b0164b1a9531aa1d12a56f103206ec,12,3,2,15334,,,0,"Add job to test with SQLAlchemy master (2.x)

Change-Id: Id92d74d368356d67d5a9be6d3eada44cd190a35d
Signed-off-by: Stephen Finucane <sfinucan@redhat.com>
",git fetch https://review.opendev.org/openstack/keystone refs/changes/09/886509/1 && git format-patch -1 --stdout FETCH_HEAD,['.zuul.yaml'],1,2fd52713bb64b6c68c670a98cc4e90cc106ce9be,sqlalchemy-20,"# Temporary job until SQLAlchemy 2.0 is no longer blocked by upper-requirements - job: name: keystone-tox-py310-with-sqlalchemy-2x parent: openstack-tox-py310 description: | Run unit tests with main branch of SQLAlchemy, alembic and oslo.db. Takes advantage of the base tox job's install-siblings feature. # The job only tests the latest and shouldn't be run on the stable branches branches: ^(?!stable) required-projects: - name: github.com/sqlalchemy/sqlalchemy override-checkout: main - name: github.com/sqlalchemy/alembic override-checkout: main - name: openstack/oslo.db - keystone-tox-py310-with-sqlalchemy-2x - keystone-tox-py310-with-sqlalchemy-2x",,18,0
openstack%2Fmanila~808131,openstack/manila,master,I0db507db5dc848d124a4fb59c7feccae6fac07f8,Follow up SVM Migrate change,NEW,2021-09-09 19:57:03.000000000,2023-07-05 20:28:47.000000000,,"[{'_account_id': 16643}, {'_account_id': 22348}, {'_account_id': 30002}, {'_account_id': 30998}, {'_account_id': 31721}]","[{'number': 1, 'created': '2021-09-09 19:57:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/manila/commit/59e280b7f5f48f4897d389863351e5b3b7ad3a3b', 'message': 'Follow up SVM Migrate change\n\nAddresses few comments that were open points in the SVM migrate\nchange merged during the Xena release.\n\nChange-Id: I0db507db5dc848d124a4fb59c7feccae6fac07f8\n'}, {'number': 2, 'created': '2021-10-26 12:13:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/manila/commit/89912dac56892d3fe9c9c9529e96c6db6b5bbcb2', 'message': 'Follow up SVM Migrate change\n\nAddresses few comments that were open points in the SVM migrate\nchange merged during the Xena release.\n\nChange-Id: I0db507db5dc848d124a4fb59c7feccae6fac07f8\n'}, {'number': 3, 'created': '2022-07-08 21:38:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/manila/commit/6d40b24ecd57321115c42366466e6485f597e430', 'message': 'Follow up SVM Migrate change\n\nAddresses few comments that were open points in the SVM migrate\nchange merged during the Xena release.\n\nChange-Id: I0db507db5dc848d124a4fb59c7feccae6fac07f8\n'}, {'number': 4, 'created': '2023-07-05 13:28:42.000000000', 'files': ['manila/share/drivers/netapp/dataontap/cluster_mode/lib_multi_svm.py', 'manila/share/drivers/netapp/dataontap/client/api.py', 'manila/tests/share/drivers/netapp/dataontap/client/test_api.py'], 'web_link': 'https://opendev.org/openstack/manila/commit/63ccba9fba9f9ea052aff22604dace59fa37fdd9', 'message': 'Follow up SVM Migrate change\n\nAddresses few comments that were open points in the SVM migrate\nchange merged during the Xena release.\n\nChange-Id: I0db507db5dc848d124a4fb59c7feccae6fac07f8\n'}]",14,808131,63ccba9fba9f9ea052aff22604dace59fa37fdd9,54,5,4,29632,,,0,"Follow up SVM Migrate change

Addresses few comments that were open points in the SVM migrate
change merged during the Xena release.

Change-Id: I0db507db5dc848d124a4fb59c7feccae6fac07f8
",git fetch https://review.opendev.org/openstack/manila refs/changes/31/808131/1 && git format-patch -1 --stdout FETCH_HEAD,"['manila/share/drivers/netapp/dataontap/cluster_mode/lib_multi_svm.py', 'manila/share/drivers/netapp/dataontap/client/api.py', 'manila/tests/share/drivers/netapp/dataontap/client/test_api.py']",3,59e280b7f5f48f4897d389863351e5b3b7ad3a3b,,"import six from lxml import etreeclass NetAppApiBaseClientTests(test.TestCase): """"""Test case for NetApp API server methods"""""" def setUp(self): self.root = api.BaseClient('127.0.0.1', style=api.STYLE_LOGIN_PASSWORD) super(NetAppApiBaseClientTests, self).setUp() @ddt.data(api.STYLE_LOGIN_PASSWORD, api.STYLE_CERTIFICATE) def test_get_style(self, expected_style): self.root._auth_style = expected_style style = self.root.get_style() self.assertEqual(expected_style, style) @ddt.data(api.STYLE_LOGIN_PASSWORD, api.STYLE_CERTIFICATE) def test_set_style(self, expected_style): self.root.set_style(expected_style) self.assertIs(True, hasattr(self.root, '_auth_style')) self.assertEqual(expected_style, self.root._auth_style) def test_set_style_error(self): self.assertRaises( ValueError, self.root.set_transport_type, 'invalid_transport_type' ) @ddt.data(api.TRANSPORT_TYPE_HTTP, api.TRANSPORT_TYPE_HTTPS) def test_get_transport_type(self, expected_type): self.root._protocol = expected_type type = self.root.get_transport_type() self.assertEqual(expected_type, type) @ddt.data(api.TRANSPORT_TYPE_HTTP, api.TRANSPORT_TYPE_HTTPS) def test_set_transport_type(self, expected_type): self.root.set_transport_type(expected_type) expected_type = expected_type.lower() self.assertIs(True, hasattr(self.root, '_protocol')) self.assertEqual(expected_type, self.root._protocol) def test_set_transport_type_error(self): self.assertRaises( ValueError, self.root.set_transport_type, 'invalid_style' ) @ddt.data(api.ZapiClient.SERVER_TYPE_FILER, api.ZapiClient.SERVER_TYPE_DFM) def test_get_server_type(self, expected_type): self.root._server_type = expected_type type = self.root.get_server_type() self.assertEqual(expected_type, type) def test_set_server_type(self): self.assertRaises( NotImplementedError, self.root.set_server_type, 'invalid_type' ) def test_set_api_version_error(self): self.mock_object(six, 'text_type', mock.Mock(side_effect=ValueError())) self.assertRaises( ValueError, self.root.set_api_version, '1', '15' ) @ddt.data(True, False) def test_get_api_version(self, has_api_version): expected_api_version = None if has_api_version: self.root._api_version = '1.15' self.root._api_major_version = 1 self.root._api_minor_version = 15 expected_api_version = (1, 15) api_version = self.root.get_api_version() self.assertEqual(expected_api_version, api_version) def test_set_port_value_error(self): self.assertRaises( ValueError, self.root.set_port, 'not_an_integer' ) def test_get_port(self): expected_port = 80 self.root._port = expected_port port = self.root.get_port() self.assertEqual(expected_port, port) def test_get_timeout(self): expected_timeout = 30 self.root._timeout = expected_timeout timeout = self.root.get_timeout() self.assertEqual(timeout, expected_timeout) def test_set_timeout(self): expected_timeout = 30 self.root.set_timeout(expected_timeout) self.assertIs(True, hasattr(self.root, '_timeout')) self.assertEqual(self.root._timeout, expected_timeout) def test_set_username(self): username = 'admin' self.root.set_username(username) self.assertIs(True, hasattr(self.root, '_username')) self.assertEqual(username, self.root._username) def test_set_password(self): password = '12345' self.root.set_password(password) self.assertIs(True, hasattr(self.root, '_password')) self.assertEqual(password, self.root._password) @ddt.data(api.STYLE_LOGIN_PASSWORD, api.STYLE_CERTIFICATE) def test__build_session(self, auth_style): self.root._auth_style = auth_style mock_basic_auth_handler = mock.Mock() mock_cert_auth_handler = mock.Mock() mock_build_headers = mock.Mock() mock_session = fake.FAKE_HTTP_SESSION expected_auth_handler = ( mock_basic_auth_handler if auth_style == api.STYLE_LOGIN_PASSWORD else mock_cert_auth_handler) self.mock_object(self.root, '_create_basic_auth_handler', mock.Mock(return_value=mock_basic_auth_handler)) self.mock_object(self.root, '_create_certificate_auth_handler', mock.Mock(return_value=mock_cert_auth_handler)) self.mock_object(requests, 'Session', mock.Mock(return_value=mock_session)) self.mock_object(self.root, '_build_headers', mock.Mock(return_value=mock_build_headers)) self.root._build_session() self.assertEqual(self.root._session, mock_session) self.assertEqual(self.root._session.auth, expected_auth_handler) self.assertEqual(self.root._session.verify, True) self.assertEqual(self.root._session.headers, mock_build_headers) def test__build_headers(self): self.assertRaises( NotImplementedError, self.root._build_headers ) def test__create_basic_auth_handler(self): mock_basic_auth = mock.Mock() self.root._password = '12345' self.root._username = 'admin' self.mock_object(requests.auth, 'HTTPBasicAuth', mock.Mock(return_value=mock_basic_auth)) basic_auth = self.root._create_basic_auth_handler() self.assertEqual(basic_auth, mock_basic_auth) @ddt.ddt @ddt.data( (api.TRANSPORT_TYPE_HTTP, api.ZapiClient.SERVER_TYPE_FILER, 80), (api.TRANSPORT_TYPE_HTTP, api.ZapiClient.SERVER_TYPE_DFM, 8088), (api.TRANSPORT_TYPE_HTTPS, api.ZapiClient.SERVER_TYPE_FILER, 443), (api.TRANSPORT_TYPE_HTTPS, api.ZapiClient.SERVER_TYPE_DFM, 8488)) @ddt.unpack def test__set_port(self, protocol, server_type, expected_port): self.root._protocol = protocol self.root._server_type = server_type self.root._set_port() self.assertEqual(self.root._port, str(expected_port)) @ddt.data( (api.ZapiClient.SERVER_TYPE_FILER, api.ZapiClient.URL_FILER), (api.ZapiClient.SERVER_TYPE_DFM, api.ZapiClient.URL_DFM)) @ddt.unpack def test_set_server_type(self, server_type, expected_url): self.root.set_server_type(server_type) self.assertIs(True, hasattr(self.root, '_server_type')) self.assertEqual(self.root._server_type, server_type) self.assertIs(True, hasattr(self.root, '_url')) self.assertEqual(self.root._url, expected_url) @ddt.data(fake.FAKE_XML_STR) 'trace_pattern': '(.*)', 'log': False, 'timeout': 10}, 'trace_pattern': '(?!(volume)).*', 'log': False, 'timeout': None}, 'trace_pattern': '(.*)', 'log': True, 'timeout': None}, 'trace_pattern': '^volume-(info|get-iter)$', 'log': True, 'timeout': None}) def test_invoke_elem_valid(self, trace_enabled, trace_pattern, log, timeout): if timeout: self.root._timeout = timeout @ddt.data(fake.FAKE_RESULT_API_ERRNO_VALID, fake.FAKE_RESULT_API_ERRNO_INVALID) def test_invoke_successfully_error(self, errored_na_element): na_elem = api.NaElement('netapp') self.mock_object( self.root, 'invoke_elem', mock.Mock(return_value=errored_na_element)) self.assertRaises( api.NaApiError, self.root.invoke_successfully, na_elem ) self.root.invoke_elem.assert_called_once_with( na_elem, enable_tunneling=False) def test_invoke_successfully(self): na_elem = api.NaElement('netapp') api.NaElement.translate_struct = mock.Mock() api_args = { 'source-volume': fake.SHARE_NAME, 'vserver': fake.VSERVER_NAME, } expected_result = fake.FAKE_RESULT_SUCCESS self.mock_object(self.root, 'invoke_elem', mock.Mock(return_value=expected_result)) result = self.root.invoke_successfully( na_elem, api_args=api_args) self.assertEqual(expected_result, result) api.NaElement.translate_struct.assert_called_once_with( api_args) self.root.invoke_elem.assert_called_once_with( na_elem, enable_tunneling=False) def test__create_request(self): na_elem = api.NaElement('netapp') na_element = api.NaElement('vserver-get-iter') self.root._api_version = '1.20' self.root._ns = self.root.NETAPP_NS expected_result = na_elem expected_result.add_attr('xmlns', self.root.NETAPP_NS) expected_result.add_attr('version', '1.20') expected_result.add_child_elem(na_element) api.NaElement.add_child_elem = mock.Mock() self.mock_object(api, 'NaElement', mock.Mock(return_value=na_elem)) self.mock_object(self.root, '_enable_tunnel_request') result = self.root._create_request(na_element, enable_tunneling=True) self.assertEqual(expected_result, result) self.root._enable_tunnel_request.assert_called_once_with( na_elem) @ddt.data( {'vfiler': fake.VSERVER_NAME, 'vserver': None}, {'vfiler': None, 'vserver': fake.VSERVER_NAME}, ) @ddt.unpack def test__enable_tunnel_request_no_api_version(self, vfiler, vserver): request_elem = api.NaElement('root') if vfiler: self.root._vfiler = vfiler if vserver: self.root._vserver = vserver self.assertRaises( ValueError, self.root._enable_tunnel_request, request_elem ) @ddt.data( {'vfiler': fake.VSERVER_NAME, 'vserver': None}, {'vfiler': None, 'vserver': fake.VSERVER_NAME}, ) @ddt.unpack def test__enable_tunnel_request(self, vfiler, vserver): request_elem = api.NaElement('root') if vfiler: self.root._vfiler = vfiler self.root._api_major_version = 1 self.root._api_minor_version = 7 if vserver: self.root._vserver = vserver self.root._api_major_version = 1 self.root._api_minor_version = 15 self.root._enable_tunnel_request(request_elem) if vfiler: self.assertEqual(request_elem.get_attr('vfiler'), vfiler) if vserver: self.assertEqual(request_elem.get_attr('vfiler'), vserver) def test__parse_response(self): response_string = ( api.NaElement(fake.VSERVER_GET_ITER_RESPONSE).to_string()) response_xml = etree.XML(response_string) self.mock_object(etree, 'XML', mock.Mock(return_value=response_xml)) result = self.root._parse_response(response_string) self.assertEqual(response_string, result.to_string()) def test__get_result(self): expected_result = fake.FAKE_RESULT_SUCCESS.get_child_by_name('results') self.mock_object(self.root, '_parse_response', mock.Mock(return_value=fake.FAKE_RESULT_SUCCESS)) result = self.root._get_result(fake.VSERVER_GET_ITER_RESPONSE) self.assertEqual(expected_result, result) @ddt.data('2001:db8:3333:4444:5555:6666:7777:8888', '10.20.30.40') def test__get_url(self, host): self.root._host = host self.root._protocol = protocol = 'http' self.root._port = port = '80' self.root._url = url = 'fakeurl/' if ':' in host: host = '[%s]' % host expected_url = ('%s://%s:%s/%s' % ( protocol, host, port, url)) result = self.root._get_url() self.assertEqual(expected_url, result) def test__build_headers(self): expected_headers = {'Content-Type': 'text/xml'} result = self.root._build_headers() self.assertEqual(expected_headers, result) 'body': fake.FAKE_HTTP_BODY, 'timeout': 10, 'body': fake.FAKE_HTTP_BODY, 'timeout': None, 'body': fake.FAKE_HTTP_BODY, 'timeout': None, 'body': fake.FAKE_HTTP_BODY, 'timeout': None, body, timeout): expected_post_params = {} if timeout: self.root._timeout = timeout expected_post_params['timeout'] = timeout expected_url, data=body, **expected_post_params) def test_invoke_sucessfully(self): body = fake.FAKE_HTTP_BODY query = fake.FAKE_HTTP_QUERY api_args = { ""body"": body, ""query"": query } self.mock_object(self.root, 'invoke_elem', mock.Mock(return_value=fake.FAKE_JOB_SUCCESS_STATE)) result = self.root.invoke_successfully(fake.FAKE_NA_ELEMENT, api_args) self.assertEqual(result, fake.FAKE_JOB_SUCCESS_STATE) self.root.invoke_elem.assert_called_once_with( fake.FAKE_NA_ELEMENT, api_args=api_args) @ddt.data(api.ESIS_CLONE_NOT_LICENSED, None) def test_invoke_sucessfuly_error(self, error_code): body = fake.FAKE_HTTP_BODY query = fake.FAKE_HTTP_QUERY api_args = { ""body"": body, ""query"": query } fake_job_error_state = fake.FAKE_JOB_SUCCESS_STATE fake_job_error_state['state'] = 'error' fake_job_error_state['error'] = { 'error': { 'code': error_code, 'message': 'error reason' }, } self.mock_object(self.root, 'invoke_elem', mock.Mock(return_value=fake_job_error_state)) self.assertRaises( api.NaApiError, self.root.invoke_successfully, fake.FAKE_NA_ELEMENT, api_args) self.root.invoke_elem.assert_called_once_with( fake.FAKE_NA_ELEMENT, api_args=api_args) def test__build_headers(self): expected_headers = { ""Accept"": ""application/json"", ""Content-Type"": ""application/json"" } headers = self.root._build_headers() self.assertEqual(expected_headers, headers) @ddt.ddt class NaServerTestCase(test.TestCase): """"""Test case for NetApp API Rest server methods"""""" def setUp(self): self.root = api.NaServer('127.0.0.1') super(NaServerTestCase, self).setUp() def _mock_setter(self, attribute_to_mock): self.mock_object(self.root.zapi_client, attribute_to_mock) self.mock_object(self.root.rest_client, attribute_to_mock) def test_get_transport_type(self): use_zapi = False self.mock_object(self.root, 'get_client', mock.Mock(return_value=self.root.zapi_client)) self.mock_object(self.root.zapi_client, 'get_transport_type') self.root.get_transport_type(use_zapi_client=use_zapi) self.root.get_client.assert_called_once_with(use_zapi=use_zapi) self.root.zapi_client.get_transport_type.assert_called_once() def test_set_transport_type(self): self._mock_setter('set_transport_type') transport_type = api.TRANSPORT_TYPE_HTTP self.root.set_transport_type(transport_type) for client in [self.root.zapi_client, self.root.rest_client]: client.set_transport_type.assert_called_once_with(transport_type) def test_get_style(self): use_zapi = False self.mock_object(self.root, 'get_client', mock.Mock(return_value=self.root.zapi_client)) self.mock_object(self.root.zapi_client, 'get_style') self.root.get_style(use_zapi_client=use_zapi) self.root.get_client.assert_called_once_with(use_zapi=use_zapi) self.root.zapi_client.get_style.assert_called_once() def test_set_style(self): self._mock_setter('set_style') style = api.STYLE_LOGIN_PASSWORD self.root.set_style(style) for client in [self.root.zapi_client, self.root.rest_client]: client.set_style.assert_called_once_with(style) def test_get_server_type(self): use_zapi = False self.mock_object(self.root, 'get_client', mock.Mock(return_value=self.root.zapi_client)) self.mock_object(self.root.zapi_client, 'get_server_type') self.root.get_server_type(use_zapi_client=use_zapi) self.root.get_client.assert_called_once_with(use_zapi=use_zapi) self.root.zapi_client.get_server_type.assert_called_once() def test_set_server_type(self): self._mock_setter('set_server_type') server_type = api.ZapiClient.SERVER_TYPE_FILER self.root.set_server_type(server_type) for client in [self.root.zapi_client]: client.set_server_type.assert_called_once_with(server_type) def test_get_api_version(self): use_zapi = False self.mock_object(self.root, 'get_client', mock.Mock(return_value=self.root.zapi_client)) self.mock_object(self.root.zapi_client, 'get_api_version') self.root.get_api_version(use_zapi_client=use_zapi) self.root.get_client.assert_called_once_with(use_zapi=use_zapi) self.root.zapi_client.get_api_version.assert_called_once() def test_set_port(self): self._mock_setter('set_port') port = 80 self.root.set_port(port) for client in [self.root.zapi_client, self.root.rest_client]: client.set_port.assert_called_once_with(port) def test_get_port(self): use_zapi = False self.mock_object(self.root, 'get_client', mock.Mock(return_value=self.root.zapi_client)) self.mock_object(self.root.zapi_client, 'get_port') self.root.get_port(use_zapi_client=use_zapi) self.root.get_client.assert_called_once_with(use_zapi=use_zapi) self.root.zapi_client.get_port.assert_called_once() def test_set_timeout(self): self._mock_setter('set_timeout') timeout = 10 self.root.set_timeout(timeout) for client in [self.root.zapi_client, self.root.rest_client]: client.set_timeout.assert_called_once_with(timeout) def test_get_timeout(self): use_zapi = False self.mock_object(self.root, 'get_client', mock.Mock(return_value=self.root.zapi_client)) self.mock_object(self.root.zapi_client, 'get_timeout') self.root.get_timeout(use_zapi_client=use_zapi) self.root.get_client.assert_called_once_with(use_zapi=use_zapi) self.root.zapi_client.get_timeout.assert_called_once() def test_get_vfiler(self): self.mock_object(self.root, 'get_client', mock.Mock(return_value=self.root.zapi_client)) self.mock_object(self.root.zapi_client, 'get_vfiler') self.root.get_vfiler() self.root.zapi_client.get_vfiler.assert_called_once() def test_get_vserver(self): self.mock_object(self.root, 'get_client', mock.Mock(return_value=self.root.zapi_client)) self.mock_object(self.root.zapi_client, 'get_vserver') self.root.get_vserver() self.root.get_client.assert_called_once() self.root.zapi_client.get_vserver.assert_called_once() def test_set_username(self): self._mock_setter('set_username') username = 'admin' self.root.set_username(username) for client in [self.root.zapi_client, self.root.rest_client]: client.set_username.assert_called_once_with(username) def test_set_password(self): self._mock_setter('set_password') username = '12345' self.root.set_password(username) for client in [self.root.zapi_client, self.root.rest_client]: client.set_password.assert_called_once_with(username) @ddt.data(True, False) def test_get_client(self, use_zapi): expected_client = ( self.root.zapi_client if use_zapi else self.root.rest_client) result_client = self.root.get_client(use_zapi=use_zapi) self.assertEqual(result_client, expected_client)"," @ddt.data(None, fake.FAKE_XML_STR) 'trace_pattern': '(.*)', 'log': False}, 'trace_pattern': '(?!(volume)).*', 'log': False}, 'trace_pattern': '(.*)', 'log': True}, 'trace_pattern': '^volume-(info|get-iter)$', 'log': True}) def test_invoke_elem_valid(self, trace_enabled, trace_pattern, log): 'body': fake.FAKE_HTTP_BODY 'body': fake.FAKE_HTTP_BODY 'body': fake.FAKE_HTTP_BODY 'body': fake.FAKE_HTTP_BODY body): expected_url, data=body)",608,17
openstack%2Fopenstack-ansible-os_heat~887731,openstack/openstack-ansible-os_heat,master,I956138b85392394da3eed73b2adadefa68460e8e,DNM - test heat deployment,NEW,2023-07-05 17:48:06.000000000,2023-07-05 19:51:15.000000000,,[{'_account_id': 22348}],"[{'number': 1, 'created': '2023-07-05 17:48:06.000000000', 'files': ['test'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_heat/commit/e97975ac454f4ff112ee5dc426f4b08493bf11d8', 'message': 'DNM - test heat deployment\n\nChange-Id: I956138b85392394da3eed73b2adadefa68460e8e\n'}]",0,887731,e97975ac454f4ff112ee5dc426f4b08493bf11d8,2,1,1,25023,,,0,"DNM - test heat deployment

Change-Id: I956138b85392394da3eed73b2adadefa68460e8e
",git fetch https://review.opendev.org/openstack/openstack-ansible-os_heat refs/changes/31/887731/1 && git format-patch -1 --stdout FETCH_HEAD,['test'],1,e97975ac454f4ff112ee5dc426f4b08493bf11d8,,,,0,0
openstack%2Fneutron~843245,openstack/neutron,master,Ie4e807b1490d59390316ec20b499b7676acfe410,Switch fullstack/functional fips jobs to 9-stream,MERGED,2022-05-25 07:53:09.000000000,2023-07-05 19:42:15.000000000,2023-07-05 19:40:10.000000000,"[{'_account_id': 9845}, {'_account_id': 11975}, {'_account_id': 16688}, {'_account_id': 21798}, {'_account_id': 22348}]","[{'number': 1, 'created': '2022-05-25 07:53:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/994668e707f92c1b73aec64ed956a94ff01e0d5d', 'message': ""[WIP] Switch fullstack/functional fips jobs to 9-stream\n\nMaster no longer support py3.6, so let's switch\nthese jobs to CentOS 9-stream which includes py3.9.\n\nAlso dbcounter[1] is not installable on CentOS 8-stream\nand hence these jobs are currently broken.\n\nOther fips jobs already switched with[2].\n\n[1] https://review.opendev.org/c/openstack/devstack/+/839820\n[2] https://review.opendev.org/c/openstack/neutron/+/833173\n\nChange-Id: Ie4e807b1490d59390316ec20b499b7676acfe410\n""}, {'number': 2, 'created': '2022-05-26 05:23:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/8a499499b14342e9bdb83f9b5ee518acf0f435d0', 'message': ""[WIP] Switch fullstack/functional fips jobs to 9-stream\n\nMaster no longer support py3.6, so let's switch\nthese jobs to CentOS 9-stream which includes py3.9.\n\nAlso dbcounter[1] is not installable on CentOS 8-stream\nand hence these jobs are currently broken.\n\nOther fips jobs already switched with[2].\n\n[1] https://review.opendev.org/c/openstack/devstack/+/839820\n[2] https://review.opendev.org/c/openstack/neutron/+/833173\n\nChange-Id: Ie4e807b1490d59390316ec20b499b7676acfe410\n""}, {'number': 3, 'created': '2022-05-27 07:34:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/4421279cbbcdce4004a190976b4594f59b537e49', 'message': ""[WIP] Switch fullstack/functional fips jobs to 9-stream\n\nMaster no longer support py3.6, so let's switch\nthese jobs to CentOS 9-stream which includes py3.9.\n\nAlso dbcounter[1] is not installable on CentOS 8-stream\nand hence these jobs are currently broken.\n\nOther fips jobs already switched with[2].\n\n[1] https://review.opendev.org/c/openstack/devstack/+/839820\n[2] https://review.opendev.org/c/openstack/neutron/+/833173\n\nChange-Id: Ie4e807b1490d59390316ec20b499b7676acfe410\n""}, {'number': 4, 'created': '2022-05-27 07:53:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/c2ebb8b8818de9c578637820dc79dd22dbaf02e4', 'message': ""[WIP] Switch fullstack/functional fips jobs to 9-stream\n\nMaster no longer support py3.6, so let's switch\nthese jobs to CentOS 9-stream which includes py3.9.\n\nAlso dbcounter[1] is not installable on CentOS 8-stream\nand hence these jobs are currently broken.\n\nOther fips jobs already switched with[2].\n\n[1] https://review.opendev.org/c/openstack/devstack/+/839820\n[2] https://review.opendev.org/c/openstack/neutron/+/833173\n\nChange-Id: Ie4e807b1490d59390316ec20b499b7676acfe410\n""}, {'number': 5, 'created': '2022-05-27 13:07:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/c23a3603579348ee5e997a817f30055f8ccabb74', 'message': ""[WIP] Switch fullstack/functional fips jobs to 9-stream\n\nMaster no longer support py3.6, so let's switch\nthese jobs to CentOS 9-stream which includes py3.9.\n\nAlso dbcounter[1] is not installable on CentOS 8-stream\nand hence these jobs are currently broken.\n\nOther fips jobs already switched with[2].\n\n[1] https://review.opendev.org/c/openstack/devstack/+/839820\n[2] https://review.opendev.org/c/openstack/neutron/+/833173\n\nChange-Id: Ie4e807b1490d59390316ec20b499b7676acfe410\n""}, {'number': 6, 'created': '2022-05-27 14:12:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/a129258d4ed17215dd98f5ac6ffd8b1e90d70b71', 'message': ""[WIP] Switch fullstack/functional fips jobs to 9-stream\n\nMaster no longer support py3.6, so let's switch\nthese jobs to CentOS 9-stream which includes py3.9.\n\nAlso dbcounter[1] is not installable on CentOS 8-stream\nand hence these jobs are currently broken.\n\nOther fips jobs already switched with[2].\n\n[1] https://review.opendev.org/c/openstack/devstack/+/839820\n[2] https://review.opendev.org/c/openstack/neutron/+/833173\n\nChange-Id: Ie4e807b1490d59390316ec20b499b7676acfe410\n""}, {'number': 7, 'created': '2022-06-03 13:30:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/bdb23b2951c4ebdf3659eef8d89f4dd490a87fa6', 'message': ""[WIP] Switch fullstack/functional fips jobs to 9-stream\n\nMaster no longer support py3.6, so let's switch\nthese jobs to CentOS 9-stream which includes py3.9.\n\nAlso dbcounter[1] is not installable on CentOS 8-stream\nand hence these jobs are currently broken.\n\nOther fips jobs already switched with[2].\n\n[1] https://review.opendev.org/c/openstack/devstack/+/839820\n[2] https://review.opendev.org/c/openstack/neutron/+/833173\n\nChange-Id: Ie4e807b1490d59390316ec20b499b7676acfe410\n""}, {'number': 8, 'created': '2022-06-03 14:17:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/e2c03f163777647ddff131ae89fcee3a871617fe', 'message': ""[WIP] Switch fullstack/functional fips jobs to 9-stream\n\nMaster no longer support py3.6, so let's switch\nthese jobs to CentOS 9-stream which includes py3.9.\n\nAlso dbcounter[1] is not installable on CentOS 8-stream\nand hence these jobs are currently broken.\n\nOther fips jobs already switched with[2].\n\n[1] https://review.opendev.org/c/openstack/devstack/+/839820\n[2] https://review.opendev.org/c/openstack/neutron/+/833173\n\nChange-Id: Ie4e807b1490d59390316ec20b499b7676acfe410\n""}, {'number': 9, 'created': '2022-07-27 18:50:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/d0c0655e552b2cf692cff5d00064958b21df7e03', 'message': ""[WIP] Switch fullstack/functional fips jobs to 9-stream\n\nMaster no longer support py3.6, so let's switch\nthese jobs to CentOS 9-stream which includes py3.9.\n\nAlso dbcounter[1] is not installable on CentOS 8-stream\nand hence these jobs are currently broken.\n\nOther fips jobs already switched with[2].\n\n[1] https://review.opendev.org/c/openstack/devstack/+/839820\n[2] https://review.opendev.org/c/openstack/neutron/+/833173\n\nChange-Id: Ie4e807b1490d59390316ec20b499b7676acfe410\n""}, {'number': 10, 'created': '2022-07-28 12:09:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/2857226a51568e6780f85b67fe81d9bd35eae0eb', 'message': ""[WIP] Switch fullstack/functional fips jobs to 9-stream\n\nMaster no longer support py3.6, so let's switch\nthese jobs to CentOS 9-stream which includes py3.9.\n\nAlso dbcounter[1] is not installable on CentOS 8-stream\nand hence these jobs are currently broken.\n\nOther fips jobs already switched with[2].\n\n[1] https://review.opendev.org/c/openstack/devstack/+/839820\n[2] https://review.opendev.org/c/openstack/neutron/+/833173\n\nChange-Id: Ie4e807b1490d59390316ec20b499b7676acfe410\n""}, {'number': 11, 'created': '2022-08-23 04:12:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/2b793873503190460063f689b0fadf2f5935f8d4', 'message': ""[WIP] Switch fullstack/functional fips jobs to 9-stream\n\nMaster no longer support py3.6, so let's switch\nthese jobs to CentOS 9-stream which includes py3.9.\n\nAlso dbcounter[1] is not installable on CentOS 8-stream\nand hence these jobs are currently broken.\n\nOther fips jobs already switched with[2].\n\n[1] https://review.opendev.org/c/openstack/devstack/+/839820\n[2] https://review.opendev.org/c/openstack/neutron/+/833173\n\nCloses-Bug: #1976323\nChange-Id: Ie4e807b1490d59390316ec20b499b7676acfe410\n""}, {'number': 12, 'created': '2022-10-19 09:58:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/b263399b2b2dadb00b86c8f229242065bb54b9ff', 'message': ""[WIP] Switch fullstack/functional fips jobs to 9-stream\n\nMaster no longer support py3.6, so let's switch\nthese jobs to CentOS 9-stream which includes py3.9.\n\nAlso dbcounter[1] is not installable on CentOS 8-stream\nand hence these jobs are currently broken.\n\nOther fips jobs already switched with[2].\n\n[1] https://review.opendev.org/c/openstack/devstack/+/839820\n[2] https://review.opendev.org/c/openstack/neutron/+/833173\n\nCloses-Bug: #1976323\nChange-Id: Ie4e807b1490d59390316ec20b499b7676acfe410\n""}, {'number': 13, 'created': '2023-03-31 14:10:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/c119aa3ebd7d8dd50422dc9ba66e8c657f61c342', 'message': ""[WIP] Switch fullstack/functional fips jobs to 9-stream\n\nMaster no longer support py3.6, so let's switch\nthese jobs to CentOS 9-stream which includes py3.9.\n\nAlso dbcounter[1] is not installable on CentOS 8-stream\nand hence these jobs are currently broken.\n\nOther fips jobs already switched with[2].\n\n[1] https://review.opendev.org/c/openstack/devstack/+/839820\n[2] https://review.opendev.org/c/openstack/neutron/+/833173\n\nCloses-Bug: #1976323\nChange-Id: Ie4e807b1490d59390316ec20b499b7676acfe410\n""}, {'number': 14, 'created': '2023-03-31 14:13:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/26f793261652da8b1eab3a7049e7072b4beb009d', 'message': ""[WIP] Switch fullstack/functional fips jobs to 9-stream\n\nMaster no longer support py3.6, so let's switch\nthese jobs to CentOS 9-stream which includes py3.9.\n\nAlso dbcounter[1] is not installable on CentOS 8-stream\nand hence these jobs are currently broken.\n\nOther fips jobs already switched with[2].\n\n[1] https://review.opendev.org/c/openstack/devstack/+/839820\n[2] https://review.opendev.org/c/openstack/neutron/+/833173\n\nCloses-Bug: #1976323\nChange-Id: Ie4e807b1490d59390316ec20b499b7676acfe410\n""}, {'number': 15, 'created': '2023-04-10 05:52:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/9c6ded360b05b811dc91407145493efd8367345f', 'message': ""[WIP] Switch fullstack/functional fips jobs to 9-stream\n\nMaster no longer support py3.6, so let's switch\nthese jobs to CentOS 9-stream which includes py3.9.\n\nAlso dbcounter[1] is not installable on CentOS 8-stream\nand hence these jobs are currently broken.\n\nOther fips jobs already switched with[2].\n\n[1] https://review.opendev.org/c/openstack/devstack/+/839820\n[2] https://review.opendev.org/c/openstack/neutron/+/833173\n\nCloses-Bug: #1976323\nChange-Id: Ie4e807b1490d59390316ec20b499b7676acfe410\n""}, {'number': 16, 'created': '2023-04-11 12:59:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/e773914e412173188f5db48cd7c746b5fe358582', 'message': ""[WIP] Switch fullstack/functional fips jobs to 9-stream\n\nMaster no longer support py3.6, so let's switch\nthese jobs to CentOS 9-stream which includes py3.9.\n\nAlso dbcounter[1] is not installable on CentOS 8-stream\nand hence these jobs are currently broken.\n\nOther fips jobs already switched with[2].\n\n[1] https://review.opendev.org/c/openstack/devstack/+/839820\n[2] https://review.opendev.org/c/openstack/neutron/+/833173\n\nCloses-Bug: #1976323\nChange-Id: Ie4e807b1490d59390316ec20b499b7676acfe410\n""}, {'number': 17, 'created': '2023-06-30 12:32:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/4056842951fadc7aa6a4db72e273c569a2e1e31e', 'message': ""Switch fullstack/functional fips jobs to 9-stream\n\nMaster no longer support py3.6, so let's switch\nthese jobs to CentOS 9-stream which includes py3.9.\n\nAlso dbcounter[1] is not installable on CentOS 8-stream\nand hence these jobs are currently broken.\n\nOther fips jobs already switched with[2].\n\n[1] https://review.opendev.org/c/openstack/devstack/+/839820\n[2] https://review.opendev.org/c/openstack/neutron/+/833173\n\nCloses-Bug: #1976323\nChange-Id: Ie4e807b1490d59390316ec20b499b7676acfe410\n""}, {'number': 18, 'created': '2023-06-30 13:00:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/ebcf5add5233d6c095a3ba31d6bebe414d0c65ab', 'message': ""Switch fullstack/functional fips jobs to 9-stream\n\nMaster no longer support py3.6, so let's switch\nthese jobs to CentOS 9-stream which includes py3.9.\n\nAlso dbcounter[1] is not installable on CentOS 8-stream\nand hence these jobs are currently broken.\n\nOther fips jobs already switched with[2].\n\n[1] https://review.opendev.org/c/openstack/devstack/+/839820\n[2] https://review.opendev.org/c/openstack/neutron/+/833173\n\nCloses-Bug: #1976323\nChange-Id: Ie4e807b1490d59390316ec20b499b7676acfe410\n""}, {'number': 19, 'created': '2023-07-03 07:46:20.000000000', 'files': ['neutron/tests/fullstack/test_local_ip.py', 'zuul.d/base.yaml', 'roles/configure_functional_tests/tasks/main.yaml', 'neutron/tests/fullstack/test_l3_agent.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/42ae9448701b7925b736f5706140d414b53d9012', 'message': ""Switch fullstack/functional fips jobs to 9-stream\n\nMaster no longer support py3.6, so let's switch\nthese jobs to CentOS 9-stream which includes py3.9.\n\nAlso dbcounter[1] is not installable on CentOS 8-stream\nand hence these jobs are currently broken.\n\nOther fips jobs already switched with[2].\n\n[1] https://review.opendev.org/c/openstack/devstack/+/839820\n[2] https://review.opendev.org/c/openstack/neutron/+/833173\n\nCloses-Bug: #1976323\nChange-Id: Ie4e807b1490d59390316ec20b499b7676acfe410\n""}]",15,843245,42ae9448701b7925b736f5706140d414b53d9012,88,5,19,13861,,,0,"Switch fullstack/functional fips jobs to 9-stream

Master no longer support py3.6, so let's switch
these jobs to CentOS 9-stream which includes py3.9.

Also dbcounter[1] is not installable on CentOS 8-stream
and hence these jobs are currently broken.

Other fips jobs already switched with[2].

[1] https://review.opendev.org/c/openstack/devstack/+/839820
[2] https://review.opendev.org/c/openstack/neutron/+/833173

Closes-Bug: #1976323
Change-Id: Ie4e807b1490d59390316ec20b499b7676acfe410
",git fetch https://review.opendev.org/openstack/neutron refs/changes/45/843245/1 && git format-patch -1 --stdout FETCH_HEAD,"['zuul.d/base.yaml', 'zuul.d/project.yaml', 'roles/configure_functional_tests/tasks/main.yaml']",3,994668e707f92c1b73aec64ed956a94ff01e0d5d,bug/1976323," OPENSTACK_RELEASE=victoria # For CentOS 9-Stream need to setup yoga repos if [[ $os_VENDOR == ""CentOSStream"" && $os_RELEASE -gt 8 ]]; then OPENSTACK_RELEASE=yoga fi install_package centos-release-openstack-${OPENSTACK_RELEASE}", install_package centos-release-openstack-victoria,12,27
openstack%2Fopenstack-ansible-os_rally~887528,openstack/openstack-ansible-os_rally,master,I016e457c0e4b7819d6d65af3bc35e06061f92d1c,Include proper commit in rally_upper_constraints_url,MERGED,2023-07-03 17:01:36.000000000,2023-07-05 19:16:18.000000000,2023-07-05 19:15:19.000000000,"[{'_account_id': 16011}, {'_account_id': 22348}, {'_account_id': 25023}, {'_account_id': 32666}]","[{'number': 1, 'created': '2023-07-03 17:01:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_rally/commit/bb9c8cae2a18489813edb4962135c039d7c1c7d3', 'message': 'Include proper commit in rally_upper_constraints_url\n\nCurrently, rally_upper_constraints_url always points to master branch.\nIt is not a valid behavior because u-c from master may not work for\nstable branches.\nThis change fixes rally_upper_constraints_url.\n\nChange-Id: I016e457c0e4b7819d6d65af3bc35e06061f92d1c\n'}, {'number': 2, 'created': '2023-07-04 10:59:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_rally/commit/7a37c8b8ae2956325e28815d2c8fc039b13d0d7d', 'message': 'Include proper commit in rally_upper_constraints_url\n\nCurrently, rally_upper_constraints_url always points to master branch.\nIt is not a valid behavior because u-c from master may not work for\nstable branches.\nThis change fixes rally_upper_constraints_url.\n\nDepends-On: https://review.opendev.org/c/openstack/openstack-ansible-rabbitmq_server/+/887592\n\nChange-Id: I016e457c0e4b7819d6d65af3bc35e06061f92d1c\n'}, {'number': 3, 'created': '2023-07-04 17:01:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_rally/commit/412e290c349ef7d6eb3314de532e57d56d489072', 'message': 'Include proper commit in rally_upper_constraints_url\n\nCurrently, rally_upper_constraints_url always points to master branch.\nIt is not a valid behavior because u-c from master may not work for\nstable branches.\nThis change fixes rally_upper_constraints_url.\n\nChange-Id: I016e457c0e4b7819d6d65af3bc35e06061f92d1c\n'}, {'number': 4, 'created': '2023-07-04 17:04:36.000000000', 'files': ['defaults/main.yml'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_rally/commit/c65b91b4900292fb5c4a07dd4473fcf4554b111e', 'message': 'Include proper commit in rally_upper_constraints_url\n\nCurrently, rally_upper_constraints_url always points to master branch.\nIt is not a valid behavior because u-c from master may not work for\nstable branches.\nThis change fixes rally_upper_constraints_url.\n\nDepends-On: https://review.opendev.org/c/openstack/openstack-ansible-rabbitmq_server/+/887592\n\nChange-Id: I016e457c0e4b7819d6d65af3bc35e06061f92d1c\n'}]",2,887528,c65b91b4900292fb5c4a07dd4473fcf4554b111e,16,4,4,32666,,,0,"Include proper commit in rally_upper_constraints_url

Currently, rally_upper_constraints_url always points to master branch.
It is not a valid behavior because u-c from master may not work for
stable branches.
This change fixes rally_upper_constraints_url.

Depends-On: https://review.opendev.org/c/openstack/openstack-ansible-rabbitmq_server/+/887592

Change-Id: I016e457c0e4b7819d6d65af3bc35e06061f92d1c
",git fetch https://review.opendev.org/openstack/openstack-ansible-os_rally refs/changes/28/887528/1 && git format-patch -1 --stdout FETCH_HEAD,['defaults/main.yml'],1,bb9c8cae2a18489813edb4962135c039d7c1c7d3,,"rally_upper_constraints_url: ""{{ rally_openstack_git_repo }}/raw/{{ (rally_openstack_git_install_branch == 'master') | ternary('branch','commit') }}/{{ rally_openstack_git_install_branch }}/upper-constraints.txt""","rally_upper_constraints_url: ""{{ rally_openstack_git_repo }}/raw/branch/master/upper-constraints.txt""",1,1
openstack%2Fcinder~869259,openstack/cinder,master,I04d3df9f21052e3088ad44a62f98f601c88be8d7,mypy: Annotate cinder/compute/nova.py,NEW,2023-01-04 20:23:37.000000000,2023-07-05 19:00:07.000000000,,"[{'_account_id': 22348}, {'_account_id': 30615}]","[{'number': 1, 'created': '2023-01-04 20:23:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/10d4fdd4d6a6ef48a868e6c2d018e87113354148', 'message': 'mypy: Annotate cinder/compute/nova.py\n\nChange-Id: I04d3df9f21052e3088ad44a62f98f601c88be8d7\n'}, {'number': 2, 'created': '2023-04-10 15:43:08.000000000', 'files': ['cinder/compute/nova.py', 'mypy-files.txt'], 'web_link': 'https://opendev.org/openstack/cinder/commit/e16027b8b3c372eeeeb0e5de1832bd374e6d86b0', 'message': 'mypy: Annotate cinder/compute/nova.py\n\nChange-Id: I04d3df9f21052e3088ad44a62f98f601c88be8d7\n'}]",1,869259,e16027b8b3c372eeeeb0e5de1832bd374e6d86b0,35,2,2,4523,,,0,"mypy: Annotate cinder/compute/nova.py

Change-Id: I04d3df9f21052e3088ad44a62f98f601c88be8d7
",git fetch https://review.opendev.org/openstack/cinder refs/changes/59/869259/1 && git format-patch -1 --stdout FETCH_HEAD,"['cinder/compute/nova.py', 'mypy-files.txt']",2,10d4fdd4d6a6ef48a868e6c2d018e87113354148,,cinder/compute/__init__.py cinder/compute/nova.py,,51,13
openstack%2Fkeystone~887028,openstack/keystone,master,I95fc21e1d0993de94a4eb61b2b51ada7ed81044b,db: Don't rely on branched connections,MERGED,2023-06-27 09:58:52.000000000,2023-07-05 18:14:41.000000000,2023-07-05 18:13:30.000000000,"[{'_account_id': 7414}, {'_account_id': 14250}, {'_account_id': 22348}]","[{'number': 1, 'created': '2023-06-27 09:58:52.000000000', 'files': ['keystone/common/sql/migrations/env.py'], 'web_link': 'https://opendev.org/openstack/keystone/commit/f477307bd8e71f0d9c37e67e79738fa36359dfbc', 'message': 'db: Don\'t rely on branched connections\n\nWe were previously calling \'connect()\' on the \'connectable\' object in\n\'run_migrations_online\', regardless of whether it was an \'Engine\' or\n\'Connection\' object. This worked because, as noted in an inline comment,\n""when connectable is already a Connection object, calling \'connect()\'\ngives us a *branched connection*."" This is no longer the case. From the\nSQLAlchemy docs [1]:\n\n  The Connection object does not support ""branching"", which was a\n  pattern by which a sub ""connection"" would be used that refers to this\n  connection as a parent.\n\nUpdate our code to reflect this change, using the newly updated example\nfrom the SQLAlchemy cookbook doc [2] as inspiration.\n\n[1] https://docs.sqlalchemy.org/en/14/core/future.html#sqlalchemy.future.Connection\n[2] https://alembic.sqlalchemy.org/en/latest/cookbook.html#connection-sharing\n\nChange-Id: I95fc21e1d0993de94a4eb61b2b51ada7ed81044b\nSigned-off-by: Stephen Finucane <sfinucan@redhat.com>\n'}]",4,887028,f477307bd8e71f0d9c37e67e79738fa36359dfbc,19,3,1,15334,,,0,"db: Don't rely on branched connections

We were previously calling 'connect()' on the 'connectable' object in
'run_migrations_online', regardless of whether it was an 'Engine' or
'Connection' object. This worked because, as noted in an inline comment,
""when connectable is already a Connection object, calling 'connect()'
gives us a *branched connection*."" This is no longer the case. From the
SQLAlchemy docs [1]:

  The Connection object does not support ""branching"", which was a
  pattern by which a sub ""connection"" would be used that refers to this
  connection as a parent.

Update our code to reflect this change, using the newly updated example
from the SQLAlchemy cookbook doc [2] as inspiration.

[1] https://docs.sqlalchemy.org/en/14/core/future.html#sqlalchemy.future.Connection
[2] https://alembic.sqlalchemy.org/en/latest/cookbook.html#connection-sharing

Change-Id: I95fc21e1d0993de94a4eb61b2b51ada7ed81044b
Signed-off-by: Stephen Finucane <sfinucan@redhat.com>
",git fetch https://review.opendev.org/openstack/keystone refs/changes/28/887028/1 && git format-patch -1 --stdout FETCH_HEAD,['keystone/common/sql/migrations/env.py'],1,f477307bd8e71f0d9c37e67e79738fa36359dfbc,sqlalchemy-20," with connectable.connect() as connection: context.configure( connection=connection, target_metadata=target_metadata, render_as_batch=True, include_name=include_name, include_object=include_object, process_revision_directives=autogen.process_revision_directives, # noqa: E501 ) with context.begin_transaction(): context.run_migrations() else: connection=connectable,"," # when connectable is already a Connection object, calling connect() gives # us a *branched connection*. with connectable.connect() as connection: connection=connection,",13,5
openstack%2Fneutron~881771,openstack/neutron,master,Ie09d9d3e5efa8a57ad11655c2eb31d2604bab326,Set result when lswitch port exist,MERGED,2023-04-28 02:01:46.000000000,2023-07-05 17:58:08.000000000,2023-07-05 17:57:07.000000000,"[{'_account_id': 1131}, {'_account_id': 9845}, {'_account_id': 16688}, {'_account_id': 22348}]","[{'number': 1, 'created': '2023-04-28 02:01:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/80fd33ec917c4f0480cf1852ebe1147e80549988', 'message': 'Set result when lswitch port exist\n\nChange-Id: Ie09d9d3e5efa8a57ad11655c2eb31d2604bab326\n'}, {'number': 2, 'created': '2023-05-24 06:40:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/c67723b8f84e8dd9c433e199dec0c091c3dfa033', 'message': 'Set result when lswitch port exist\n\nChange-Id: Ie09d9d3e5efa8a57ad11655c2eb31d2604bab326\n'}, {'number': 3, 'created': '2023-05-24 07:03:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/5e142641ad83b7fc56b23ca7a4fae1d8f7a2c0c0', 'message': 'Set result when lswitch port exist\n\nChange-Id: Ie09d9d3e5efa8a57ad11655c2eb31d2604bab326\n'}, {'number': 4, 'created': '2023-06-28 03:05:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/3d9c57b59e595259c3edc2e6a0779a38713134ff', 'message': 'Set result when lswitch port exist\n\nCloses-Bug: #2025202\n\nChange-Id: Ie09d9d3e5efa8a57ad11655c2eb31d2604bab326\n'}, {'number': 5, 'created': '2023-06-28 06:16:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/56d644f5c6728dc2d68ee59a3fa23850e5b38900', 'message': 'Set result when lswitch port exist\n\nA TypeError was thrown during a synchronization\ncommand(neutron-ovn-db-sync-util) execution. From the code[1][2], it\ncan be seen. The result of the AddLSwitchPortCommand command will be\npassed as a parameter to the UpdateLSwitchQosOptionsCommand. But if\nthe logical switch port exists, the result will not be set. Therefore,\nwhen the UpdateLSwitchQosOptionsCommand is executed, the port_id will\nnot be obtained, thereby throwing an exception TypeError.\nThis patch sets the result when the logical switch port exists.\n\n[1] https://opendev.org/openstack/neutron/src/commit/b71f7ceb3e97e021cb9aeda757a7ffdeeff80e8e/neutron/plugins/ml2/drivers/ovn/mech_driver/ovsdb/ovn_client.py#L488\n[2] https://opendev.org/openstack/neutron/src/commit/b71f7ceb3e97e021cb9aeda757a7ffdeeff80e8e/neutron/plugins/ml2/drivers/ovn/mech_driver/ovsdb/ovn_client.py#L505\n\nCloses-Bug: #2025202\n\nChange-Id: Ie09d9d3e5efa8a57ad11655c2eb31d2604bab326\n'}, {'number': 6, 'created': '2023-07-04 06:15:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/c4018af4bba11f7f33d3d48a09dc2e8f48fe7b5a', 'message': 'Set result when lswitch port exist\n\nA TypeError was thrown during a synchronization\ncommand(neutron-ovn-db-sync-util) execution. From the code[1][2], it\ncan be seen. The result of the AddLSwitchPortCommand command will be\npassed as a parameter to the UpdateLSwitchPortQosOptionsCommand. But\nif the logical switch port exists, the result will not be set. Therefore,\nwhen the UpdateLSwitchPortQosOptionsCommand is executed, the port_id\nwill not be obtained, thereby throwing an exception TypeError.\nThis patch sets the result when the logical switch port exists.\n\n[1] https://opendev.org/openstack/neutron/src/commit/b71f7ceb3e97e021cb9aeda757a7ffdeeff80e8e/neutron/plugins/ml2/drivers/ovn/mech_driver/ovsdb/ovn_client.py#L488\n[2] https://opendev.org/openstack/neutron/src/commit/b71f7ceb3e97e021cb9aeda757a7ffdeeff80e8e/neutron/plugins/ml2/drivers/ovn/mech_driver/ovsdb/ovn_client.py#L505\n\nCloses-Bug: #2025202\n\nChange-Id: Ie09d9d3e5efa8a57ad11655c2eb31d2604bab326\n'}, {'number': 7, 'created': '2023-07-04 07:25:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/c4f583048c61d16ebbefc3a2f8734c1247136381', 'message': 'Set result when lswitch port exist\n\nA TypeError was thrown during a synchronization\ncommand(neutron-ovn-db-sync-util) execution. From the code[1][2], it\ncan be seen. The result of the AddLSwitchPortCommand command will be\npassed as a parameter to the UpdateLSwitchPortQosOptionsCommand. But\nif the logical switch port exists, the result will not be set. Therefore,\nwhen the UpdateLSwitchPortQosOptionsCommand is executed, the port_id\nwill not be obtained, thereby throwing an exception TypeError.\nThis patch sets the result when the logical switch port exists.\n\n[1] https://opendev.org/openstack/neutron/src/commit/b71f7ceb3e97e021cb9aeda757a7ffdeeff80e8e/neutron/plugins/ml2/drivers/ovn/mech_driver/ovsdb/ovn_client.py#L488\n[2] https://opendev.org/openstack/neutron/src/commit/b71f7ceb3e97e021cb9aeda757a7ffdeeff80e8e/neutron/plugins/ml2/drivers/ovn/mech_driver/ovsdb/ovn_client.py#L505\n\nCloses-Bug: #2025202\n\nChange-Id: Ie09d9d3e5efa8a57ad11655c2eb31d2604bab326\n'}, {'number': 8, 'created': '2023-07-04 11:24:58.000000000', 'files': ['neutron/tests/unit/plugins/ml2/drivers/ovn/mech_driver/ovsdb/test_commands.py', 'neutron/tests/functional/plugins/ml2/drivers/ovn/mech_driver/ovsdb/test_ovn_client.py', 'neutron/plugins/ml2/drivers/ovn/mech_driver/ovsdb/commands.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/65bbbcee76fc2a7501d4c28e3cc716f1f9a6f763', 'message': 'Set result when lswitch port exist\n\nA TypeError was thrown during a synchronization\ncommand(neutron-ovn-db-sync-util) execution. From the code[1][2], it\ncan be seen. The result of the AddLSwitchPortCommand command will be\npassed as a parameter to the UpdateLSwitchPortQosOptionsCommand. But\nif the logical switch port exists, the result will not be set. Therefore,\nwhen the UpdateLSwitchPortQosOptionsCommand is executed, the port_id\nwill not be obtained, thereby throwing an exception TypeError.\nThis patch sets the result when the logical switch port exists.\n\n[1] https://opendev.org/openstack/neutron/src/commit/b71f7ceb3e97e021cb9aeda757a7ffdeeff80e8e/neutron/plugins/ml2/drivers/ovn/mech_driver/ovsdb/ovn_client.py#L488\n[2] https://opendev.org/openstack/neutron/src/commit/b71f7ceb3e97e021cb9aeda757a7ffdeeff80e8e/neutron/plugins/ml2/drivers/ovn/mech_driver/ovsdb/ovn_client.py#L505\n\nCloses-Bug: #2025202\n\nChange-Id: Ie09d9d3e5efa8a57ad11655c2eb31d2604bab326\n'}]",14,881771,65bbbcee76fc2a7501d4c28e3cc716f1f9a6f763,49,4,8,30380,,,0,"Set result when lswitch port exist

A TypeError was thrown during a synchronization
command(neutron-ovn-db-sync-util) execution. From the code[1][2], it
can be seen. The result of the AddLSwitchPortCommand command will be
passed as a parameter to the UpdateLSwitchPortQosOptionsCommand. But
if the logical switch port exists, the result will not be set. Therefore,
when the UpdateLSwitchPortQosOptionsCommand is executed, the port_id
will not be obtained, thereby throwing an exception TypeError.
This patch sets the result when the logical switch port exists.

[1] https://opendev.org/openstack/neutron/src/commit/b71f7ceb3e97e021cb9aeda757a7ffdeeff80e8e/neutron/plugins/ml2/drivers/ovn/mech_driver/ovsdb/ovn_client.py#L488
[2] https://opendev.org/openstack/neutron/src/commit/b71f7ceb3e97e021cb9aeda757a7ffdeeff80e8e/neutron/plugins/ml2/drivers/ovn/mech_driver/ovsdb/ovn_client.py#L505

Closes-Bug: #2025202

Change-Id: Ie09d9d3e5efa8a57ad11655c2eb31d2604bab326
",git fetch https://review.opendev.org/openstack/neutron refs/changes/71/881771/1 && git format-patch -1 --stdout FETCH_HEAD,['neutron/plugins/ml2/drivers/ovn/mech_driver/ovsdb/commands.py'],1,80fd33ec917c4f0480cf1852ebe1147e80549988,bug/2025202, self.result = port.uuid,,1,0
openstack%2Fneutron~885456,openstack/neutron,master,I8236ec1f685a3ae7c503d3ff8148138a875d702a,Drop redundant index on ports table,MERGED,2023-06-07 11:02:23.000000000,2023-07-05 17:47:37.000000000,2023-07-05 17:46:26.000000000,"[{'_account_id': 1131}, {'_account_id': 8313}, {'_account_id': 9845}, {'_account_id': 16688}, {'_account_id': 21798}, {'_account_id': 22348}]","[{'number': 1, 'created': '2023-06-07 11:02:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/670f0daac171d274ee2349ab76778317122b7b6a', 'message': ' db: Drop redundant index on ports table\n\n * There already exists a unique constraint on the same columns, making\n   an additional index redundant.\n\nCloses-Bug: #1988421\nChange-Id: I8236ec1f685a3ae7c503d3ff8148138a875d702a\n'}, {'number': 2, 'created': '2023-06-07 12:32:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/39f7ed45e42d3e8087200a28f2fc012cbd07c814', 'message': ' db: Drop redundant index on ports table\n\n * There already exists a unique constraint on the same columns, making\n   an additional index redundant.\n\nCloses-Bug: #1988421\nChange-Id: I8236ec1f685a3ae7c503d3ff8148138a875d702a\n'}, {'number': 3, 'created': '2023-06-12 08:16:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/5194528a15c8925c86632bef3381926756a99ac7', 'message': ' db: Drop redundant index on ports table\n\n * There already exists a unique constraint on the same columns, making\n   an additional index redundant.\n\nCloses-Bug: #1988421\nChange-Id: I8236ec1f685a3ae7c503d3ff8148138a875d702a\n'}, {'number': 4, 'created': '2023-06-16 09:02:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/406465ed8ebb504a75173b7294acfb7d0ab02b07', 'message': 'Drop redundant index on ports table\n\nThere already exists a unique constraint on the same columns, making\nan additional index redundant.\n\nCloses-Bug: #1988421\nChange-Id: I8236ec1f685a3ae7c503d3ff8148138a875d702a\n'}, {'number': 5, 'created': '2023-06-16 13:15:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/749f9533217059c576585c84be79a5e51e7a6065', 'message': 'Drop redundant index on ports table\n\nThere already exists a unique constraint on the same columns, making\nan additional index redundant.\n\nCloses-Bug: #1988421\nChange-Id: I8236ec1f685a3ae7c503d3ff8148138a875d702a\n'}, {'number': 6, 'created': '2023-06-30 09:10:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/8e2d305d9e3f8311ccf745916ebec4917d2f017e', 'message': 'Drop redundant index on ports table\n\nThere already exists a unique constraint on the same columns, making\nan additional index redundant.\n\nCloses-Bug: #1988421\nChange-Id: I8236ec1f685a3ae7c503d3ff8148138a875d702a\n'}, {'number': 7, 'created': '2023-06-30 15:04:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/a6e0743cfdde87da3029593cc3d75961d364142e', 'message': 'Drop redundant index on ports table\n\nThere already exists a unique constraint on the same columns, making\nan additional index redundant.\n\nCloses-Bug: #1988421\nChange-Id: I8236ec1f685a3ae7c503d3ff8148138a875d702a\n'}, {'number': 8, 'created': '2023-06-30 15:10:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/612f484af735bf3763626bb4e7fc6bfddd4c7274', 'message': 'Drop redundant index on ports table\n\nThere already exists a unique constraint on the same columns, making\nan additional index redundant.\n\nCloses-Bug: #1988421\nChange-Id: I8236ec1f685a3ae7c503d3ff8148138a875d702a\n'}, {'number': 9, 'created': '2023-07-03 07:51:46.000000000', 'files': ['neutron/db/migration/alembic_migrations/versions/2023.2/expand/b1199a3adbef_de_duplicate_indices_for_ports.py', 'neutron/db/migration/alembic_migrations/versions/EXPAND_HEAD', 'neutron/db/models_v2.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/b4eb5d71ab8594a24369d15e4dc6580a4c1cf705', 'message': 'Drop redundant index on ports table\n\nThere already exists a unique constraint on the same columns, making\nan additional index redundant.\n\nCloses-Bug: #1988421\nChange-Id: I8236ec1f685a3ae7c503d3ff8148138a875d702a\n'}]",22,885456,b4eb5d71ab8594a24369d15e4dc6580a4c1cf705,48,6,9,32755,,,0,"Drop redundant index on ports table

There already exists a unique constraint on the same columns, making
an additional index redundant.

Closes-Bug: #1988421
Change-Id: I8236ec1f685a3ae7c503d3ff8148138a875d702a
",git fetch https://review.opendev.org/openstack/neutron refs/changes/56/885456/1 && git format-patch -1 --stdout FETCH_HEAD,['neutron/db/models_v2.py'],1,670f0daac171d274ee2349ab76778317122b7b6a,bug/1988421,," 'ix_ports_network_id_mac_address', 'network_id', 'mac_address'), sa.Index(",0,2
openstack%2Fneutron~887477,openstack/neutron,master,I54b3dbf64ad313f6e3c34a2c774975f6327843c4,doc: fix typo in metering-agent.rst,MERGED,2023-07-03 07:22:10.000000000,2023-07-05 17:27:24.000000000,2023-07-05 17:25:59.000000000,"[{'_account_id': 1131}, {'_account_id': 8313}, {'_account_id': 22348}]","[{'number': 1, 'created': '2023-07-03 07:22:10.000000000', 'files': ['doc/source/configuration/metering-agent.rst'], 'web_link': 'https://opendev.org/openstack/neutron/commit/f2dd2d3cac4a3cf2602425cc3266b54993454f35', 'message': 'doc: fix typo in metering-agent.rst\n\nSigned-off-by: Sahid Orentino Ferdjaoui <sahid.ferdjaoui@industrialdiscipline.com>\nChange-Id: I54b3dbf64ad313f6e3c34a2c774975f6327843c4\n'}]",2,887477,f2dd2d3cac4a3cf2602425cc3266b54993454f35,9,3,1,7730,,,0,"doc: fix typo in metering-agent.rst

Signed-off-by: Sahid Orentino Ferdjaoui <sahid.ferdjaoui@industrialdiscipline.com>
Change-Id: I54b3dbf64ad313f6e3c34a2c774975f6327843c4
",git fetch https://review.opendev.org/openstack/neutron refs/changes/77/887477/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/source/configuration/metering-agent.rst'],1,f2dd2d3cac4a3cf2602425cc3266b54993454f35,fixtypo,* ``report_interval``: the interval in seconds used to generated the report,* ``report_interval``: the interval in secodns used to generated the report,1,1
openstack%2Fneutron~887457,openstack/neutron,stable/yoga,I41ffffeca433faab2244ff3d1876ca078ce5ebfb,Load FIP information during initialize not init,MERGED,2023-07-03 09:18:59.000000000,2023-07-05 17:27:15.000000000,2023-07-05 17:25:55.000000000,"[{'_account_id': 1131}, {'_account_id': 8313}, {'_account_id': 11975}, {'_account_id': 16688}, {'_account_id': 21798}, {'_account_id': 22348}]","[{'number': 1, 'created': '2023-07-03 09:18:59.000000000', 'files': ['neutron/agent/l3/dvr_local_router.py', 'neutron/tests/unit/agent/l3/test_dvr_local_router.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/226e29af1ad39f0b9f9a773fcc1116e7f02f8184', 'message': ""Load FIP information during initialize not init\n\nDvrLocalRouter._load_used_fip_information() is called during the class\ninit however in some cases it tries to access a network namespace which\nhasn't yet been created. This results in NetworkNamespaceNotFound.\n\nThis change ensures that we instead create any FIP priority rules after\nthe network namespace has been created by calling\n_load_used_fip_information() from the initialize function rather than\nin the class instantiation.\n\nCloses-Bug: #2025129\nChange-Id: I41ffffeca433faab2244ff3d1876ca078ce5ebfb\n(cherry picked from commit c8c74f12e048e7858eee332883dbe7c1dc1d0f0c)\n""}]",1,887457,226e29af1ad39f0b9f9a773fcc1116e7f02f8184,12,6,1,35825,,,0,"Load FIP information during initialize not init

DvrLocalRouter._load_used_fip_information() is called during the class
init however in some cases it tries to access a network namespace which
hasn't yet been created. This results in NetworkNamespaceNotFound.

This change ensures that we instead create any FIP priority rules after
the network namespace has been created by calling
_load_used_fip_information() from the initialize function rather than
in the class instantiation.

Closes-Bug: #2025129
Change-Id: I41ffffeca433faab2244ff3d1876ca078ce5ebfb
(cherry picked from commit c8c74f12e048e7858eee332883dbe7c1dc1d0f0c)
",git fetch https://review.opendev.org/openstack/neutron refs/changes/57/887457/1 && git format-patch -1 --stdout FETCH_HEAD,"['neutron/agent/l3/dvr_local_router.py', 'neutron/tests/unit/agent/l3/test_dvr_local_router.py']",2,226e29af1ad39f0b9f9a773fcc1116e7f02f8184,fix_dvr_net_ns_bug-stable/yoga," @mock.patch.object(router_info.RouterInfo, 'initialize') def test_initialize_dvr_local_router(self, super_initialize): ri = self._create_router() self.mock_load_fip.assert_not_called() ri.initialize(self.process_monitor) super_initialize.assert_called_once_with(self.process_monitor) self.mock_load_fip.assert_called_once() ",,12,0
openstack%2Fneutron~887456,openstack/neutron,stable/zed,I41ffffeca433faab2244ff3d1876ca078ce5ebfb,Load FIP information during initialize not init,MERGED,2023-07-03 09:18:35.000000000,2023-07-05 17:27:07.000000000,2023-07-05 17:25:51.000000000,"[{'_account_id': 1131}, {'_account_id': 8313}, {'_account_id': 11975}, {'_account_id': 16688}, {'_account_id': 21798}, {'_account_id': 22348}]","[{'number': 1, 'created': '2023-07-03 09:18:35.000000000', 'files': ['neutron/agent/l3/dvr_local_router.py', 'neutron/tests/unit/agent/l3/test_dvr_local_router.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/7972c1e2245fcafc207a32e116516d63e6cd0d0a', 'message': ""Load FIP information during initialize not init\n\nDvrLocalRouter._load_used_fip_information() is called during the class\ninit however in some cases it tries to access a network namespace which\nhasn't yet been created. This results in NetworkNamespaceNotFound.\n\nThis change ensures that we instead create any FIP priority rules after\nthe network namespace has been created by calling\n_load_used_fip_information() from the initialize function rather than\nin the class instantiation.\n\nCloses-Bug: #2025129\nChange-Id: I41ffffeca433faab2244ff3d1876ca078ce5ebfb\n(cherry picked from commit c8c74f12e048e7858eee332883dbe7c1dc1d0f0c)\n""}]",0,887456,7972c1e2245fcafc207a32e116516d63e6cd0d0a,9,6,1,35825,,,0,"Load FIP information during initialize not init

DvrLocalRouter._load_used_fip_information() is called during the class
init however in some cases it tries to access a network namespace which
hasn't yet been created. This results in NetworkNamespaceNotFound.

This change ensures that we instead create any FIP priority rules after
the network namespace has been created by calling
_load_used_fip_information() from the initialize function rather than
in the class instantiation.

Closes-Bug: #2025129
Change-Id: I41ffffeca433faab2244ff3d1876ca078ce5ebfb
(cherry picked from commit c8c74f12e048e7858eee332883dbe7c1dc1d0f0c)
",git fetch https://review.opendev.org/openstack/neutron refs/changes/56/887456/1 && git format-patch -1 --stdout FETCH_HEAD,"['neutron/agent/l3/dvr_local_router.py', 'neutron/tests/unit/agent/l3/test_dvr_local_router.py']",2,7972c1e2245fcafc207a32e116516d63e6cd0d0a,fix_dvr_net_ns_bug-stable/zed," @mock.patch.object(router_info.RouterInfo, 'initialize') def test_initialize_dvr_local_router(self, super_initialize): ri = self._create_router() self.mock_load_fip.assert_not_called() ri.initialize(self.process_monitor) super_initialize.assert_called_once_with(self.process_monitor) self.mock_load_fip.assert_called_once() ",,12,0
openstack%2Fneutron~887455,openstack/neutron,stable/2023.1,I41ffffeca433faab2244ff3d1876ca078ce5ebfb,Load FIP information during initialize not init,MERGED,2023-07-03 09:18:14.000000000,2023-07-05 17:27:04.000000000,2023-07-05 17:25:46.000000000,"[{'_account_id': 1131}, {'_account_id': 8313}, {'_account_id': 11975}, {'_account_id': 16688}, {'_account_id': 21798}, {'_account_id': 22348}]","[{'number': 1, 'created': '2023-07-03 09:18:14.000000000', 'files': ['neutron/agent/l3/dvr_local_router.py', 'neutron/tests/unit/agent/l3/test_dvr_local_router.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/06694e336e8fe8540849ad771bb782c8ab4caa35', 'message': ""Load FIP information during initialize not init\n\nDvrLocalRouter._load_used_fip_information() is called during the class\ninit however in some cases it tries to access a network namespace which\nhasn't yet been created. This results in NetworkNamespaceNotFound.\n\nThis change ensures that we instead create any FIP priority rules after\nthe network namespace has been created by calling\n_load_used_fip_information() from the initialize function rather than\nin the class instantiation.\n\nCloses-Bug: #2025129\nChange-Id: I41ffffeca433faab2244ff3d1876ca078ce5ebfb\n(cherry picked from commit c8c74f12e048e7858eee332883dbe7c1dc1d0f0c)\n""}]",0,887455,06694e336e8fe8540849ad771bb782c8ab4caa35,9,6,1,35825,,,0,"Load FIP information during initialize not init

DvrLocalRouter._load_used_fip_information() is called during the class
init however in some cases it tries to access a network namespace which
hasn't yet been created. This results in NetworkNamespaceNotFound.

This change ensures that we instead create any FIP priority rules after
the network namespace has been created by calling
_load_used_fip_information() from the initialize function rather than
in the class instantiation.

Closes-Bug: #2025129
Change-Id: I41ffffeca433faab2244ff3d1876ca078ce5ebfb
(cherry picked from commit c8c74f12e048e7858eee332883dbe7c1dc1d0f0c)
",git fetch https://review.opendev.org/openstack/neutron refs/changes/55/887455/1 && git format-patch -1 --stdout FETCH_HEAD,"['neutron/agent/l3/dvr_local_router.py', 'neutron/tests/unit/agent/l3/test_dvr_local_router.py']",2,06694e336e8fe8540849ad771bb782c8ab4caa35,fix_dvr_net_ns_bug-stable/2023.1," @mock.patch.object(router_info.RouterInfo, 'initialize') def test_initialize_dvr_local_router(self, super_initialize): ri = self._create_router() self.mock_load_fip.assert_not_called() ri.initialize(self.process_monitor) super_initialize.assert_called_once_with(self.process_monitor) self.mock_load_fip.assert_called_once() ",,12,0
openstack%2Fdesignate~887675,openstack/designate,stable/2023.1,I8af9b5cf8c1473bbf7db71a1fb848fb64509db84,Fix list zones if shared with multiple projects,ABANDONED,2023-07-05 16:33:40.000000000,2023-07-05 16:35:14.000000000,,[],"[{'number': 1, 'created': '2023-07-05 16:33:40.000000000', 'files': ['designate/storage/sqlalchemy/__init__.py', 'releasenotes/notes/Fix-zone-list-when-zone-shared-more-than-once-288b57cafeba82df.yaml', 'designate/tests/test_storage/test_storage.py'], 'web_link': 'https://opendev.org/openstack/designate/commit/0b56ffe1b95748e1bb51f74b8ae47d550178ff55', 'message': 'Fix list zones if shared with multiple projects\n\nThis patch fixes a bug when listing zones or updating recordsets in\nzones that are shared with more than one project.\n\nCloses-Bug: #2025295\nChange-Id: I8af9b5cf8c1473bbf7db71a1fb848fb64509db84\n(cherry picked from commit 011ebe2e7cd0df0c7f0869f0c7abbce79434821a)\n'}]",0,887675,0b56ffe1b95748e1bb51f74b8ae47d550178ff55,2,0,1,11628,,,0,"Fix list zones if shared with multiple projects

This patch fixes a bug when listing zones or updating recordsets in
zones that are shared with more than one project.

Closes-Bug: #2025295
Change-Id: I8af9b5cf8c1473bbf7db71a1fb848fb64509db84
(cherry picked from commit 011ebe2e7cd0df0c7f0869f0c7abbce79434821a)
",git fetch https://review.opendev.org/openstack/designate refs/changes/75/887675/1 && git format-patch -1 --stdout FETCH_HEAD,"['designate/storage/sqlalchemy/__init__.py', 'releasenotes/notes/Fix-zone-list-when-zone-shared-more-than-once-288b57cafeba82df.yaml', 'designate/tests/test_storage/test_storage.py']",3,0b56ffe1b95748e1bb51f74b8ae47d550178ff55,,"<<<<<<< HEAD (e74285 Re-enable test jobs) ======= # Copyright 2012 Managed I.T. # # Author: Kiall Mac Innes <kiall@managedit.ie> # # Licensed under the Apache License, Version 2.0 (the ""License""); you may # not use this file except in compliance with the License. You may obtain # a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT # WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the # License for the specific language governing permissions and limitations # under the License. import math from sqlalchemy import text from unittest import mock from oslo_config import cfg from oslo_log import log as logging from oslo_messaging.rpc import dispatcher as rpc_dispatcher from designate.conf.mdns import DEFAULT_MDNS_PORT from designate import exceptions from designate import objects from designate import storage from designate.storage import sql from designate.tests import TestCase from designate.utils import generate_uuid LOG = logging.getLogger(__name__) class SqlalchemyStorageTest(TestCase): def setUp(self): super(SqlalchemyStorageTest, self).setUp() self.storage = storage.get_storage() # TODO(kiall): Someone, Somewhere, could probably make use of a # assertNestedDictContainsSubset(), cleanup and put somewhere # better. def assertNestedDictContainsSubset(self, expected, actual): for key, value in expected.items(): if isinstance(value, dict): self.assertNestedDictContainsSubset(value, actual.get(key, {})) elif isinstance(value, list): self.assertEqual(len(value), len(actual[key])) for index, item in enumerate(value): self.assertNestedDictContainsSubset( item, actual[key][index]) else: self.assertEqual(value, actual[key]) def create_quota(self, **kwargs): """""" This create method has been kept in the StorageTestCase class as quotas are treated differently to other resources in Central. """""" context = kwargs.pop('context', self.admin_context) fixture = kwargs.pop('fixture', 0) values = self.get_quota_fixture(fixture=fixture, values=kwargs) if 'tenant_id' not in values: values['tenant_id'] = context.project_id return self.storage.create_quota(context, values) def create_pool_nameserver(self, pool, **kwargs): # NOTE(kiall): We add this method here, rather than in the base test # case, as the base methods expect to make a central API # call. If a central API method is exposed for this, we # should remove this and add to the base. context = kwargs.pop('context', self.admin_context) fixture = kwargs.pop('fixture', 0) values = self.get_pool_nameserver_fixture( fixture=fixture, values=kwargs) if 'pool_id' not in values: values['pool_id'] = pool.id return self.storage.create_pool_nameserver( context, pool.id, objects.PoolNameserver.from_dict(values)) def create_pool_target(self, pool, **kwargs): # NOTE(kiall): We add this method here, rather than in the base test # case, as the base methods expect to make a central API # call. If a central API method is exposed for this, we # should remove this and add to the base. context = kwargs.pop('context', self.admin_context) fixture = kwargs.pop('fixture', 0) values = self.get_pool_target_fixture( fixture=fixture, values=kwargs) if 'pool_id' not in values: values['pool_id'] = pool.id return self.storage.create_pool_target( context, pool.id, objects.PoolTarget.from_dict(values)) def create_pool_also_notify(self, pool, **kwargs): # NOTE(kiall): We add this method here, rather than in the base test # case, as the base methods expect to make a central API # call. If a central API method is exposed for this, we # should remove this and add to the base. context = kwargs.pop('context', self.admin_context) fixture = kwargs.pop('fixture', 0) values = self.get_pool_also_notify_fixture( fixture=fixture, values=kwargs) if 'pool_id' not in values: values['pool_id'] = pool.id return self.storage.create_pool_also_notify( context, pool.id, objects.PoolAlsoNotify.from_dict(values)) # Paging Tests def _ensure_paging(self, data, method, criterion=None): """""" Given an array of created items we iterate through them making sure they match up to things returned by paged results. """""" results = None item_number = 0 criterion = criterion or {} for current_page in range(0, int(math.ceil(float(len(data)) / 2))): LOG.critical('Validating results on page %d', current_page) if results is not None: results = method( self.admin_context, limit=2, marker=results[-1]['id'], criterion=criterion ) else: results = method(self.admin_context, limit=2, criterion=criterion) LOG.critical('Results: %d', len(results)) for result_number, result in enumerate(results): LOG.critical('Validating result %d on page %d', result_number, current_page) self.assertEqual( data[item_number]['id'], results[result_number]['id']) item_number += 1 def test_paging_marker_not_found(self): self.assertRaisesRegex( exceptions.MarkerNotFound, 'Marker None could not be found', self.storage.find_pool_attributes, self.admin_context, marker=generate_uuid(), limit=5 ) def test_paging_marker_invalid(self): self.assertRaises( exceptions.InvalidMarker, self.storage.find_pool_attributes, self.admin_context, marker='4' ) def test_paging_limit_invalid(self): self.assertRaisesRegex( exceptions.ValueError, r'invalid literal for int\(\) with base 10: \'z\'', self.storage.find_pool_attributes, self.admin_context, limit='z' ) def test_paging_sort_dir_invalid(self): self.assertRaisesRegex( exceptions.ValueError, r'Unknown sort direction, must be \'desc\' or \'asc\'', self.storage.find_pool_attributes, self.admin_context, sort_dir='invalid_sort_dir' ) def test_paging_sort_key_invalid(self): self.assertRaisesRegex( exceptions.InvalidSortKey, 'Sort key supplied is invalid: None', self.storage.find_pool_attributes, self.admin_context, sort_key='invalid_sort_key' ) # Quota Tests def test_create_quota(self): values = self.get_quota_fixture() values['tenant_id'] = self.admin_context.project_id result = self.storage.create_quota(self.admin_context, values) self.assertIsNotNone(result['id']) self.assertIsNotNone(result['created_at']) self.assertIsNone(result['updated_at']) self.assertEqual(self.admin_context.project_id, result['tenant_id']) self.assertEqual(values['resource'], result['resource']) self.assertEqual(values['hard_limit'], result['hard_limit']) def test_create_quota_duplicate(self): # Create the initial quota self.create_quota() self.assertRaisesRegex( exceptions.DuplicateQuota, 'Duplicate Quota', self.create_quota ) def test_find_quotas(self): actual = self.storage.find_quotas(self.admin_context) self.assertEqual(0, len(actual)) # Create a single quota quota_one = self.create_quota() actual = self.storage.find_quotas(self.admin_context) self.assertEqual(1, len(actual)) self.assertEqual(quota_one['tenant_id'], actual[0]['tenant_id']) self.assertEqual(quota_one['resource'], actual[0]['resource']) self.assertEqual(quota_one['hard_limit'], actual[0]['hard_limit']) # Create a second quota quota_two = self.create_quota(fixture=1) actual = self.storage.find_quotas(self.admin_context) self.assertEqual(2, len(actual)) self.assertEqual(quota_two['tenant_id'], actual[1]['tenant_id']) self.assertEqual(quota_two['resource'], actual[1]['resource']) self.assertEqual(quota_two['hard_limit'], actual[1]['hard_limit']) def test_find_quotas_criterion(self): quota_one = self.create_quota() quota_two = self.create_quota(fixture=1) criterion = dict( tenant_id=quota_one['tenant_id'], resource=quota_one['resource'] ) results = self.storage.find_quotas(self.admin_context, criterion) self.assertEqual(1, len(results)) self.assertEqual(quota_one['tenant_id'], results[0]['tenant_id']) self.assertEqual(quota_one['resource'], results[0]['resource']) self.assertEqual(quota_one['hard_limit'], results[0]['hard_limit']) criterion = dict( tenant_id=quota_two['tenant_id'], resource=quota_two['resource'] ) results = self.storage.find_quotas(self.admin_context, criterion) self.assertEqual(1, len(results)) self.assertEqual(quota_two['tenant_id'], results[0]['tenant_id']) self.assertEqual(quota_two['resource'], results[0]['resource']) self.assertEqual(quota_two['hard_limit'], results[0]['hard_limit']) def test_get_quota(self): # Create a quota expected = self.create_quota() actual = self.storage.get_quota(self.admin_context, expected['id']) self.assertEqual(expected['tenant_id'], actual['tenant_id']) self.assertEqual(expected['resource'], actual['resource']) self.assertEqual(expected['hard_limit'], actual['hard_limit']) def test_get_quota_missing(self): uuid = 'caf771fc-6b05-4891-bee1-c2a48621f57b' self.assertRaisesRegex( exceptions.QuotaNotFound, 'Could not find Quota', self.storage.get_quota, self.admin_context, uuid ) def test_find_quota_criterion(self): quota_one = self.create_quota() quota_two = self.create_quota(fixture=1) criterion = dict( tenant_id=quota_one['tenant_id'], resource=quota_one['resource'] ) result = self.storage.find_quota(self.admin_context, criterion) self.assertEqual(quota_one['tenant_id'], result['tenant_id']) self.assertEqual(quota_one['resource'], result['resource']) self.assertEqual(quota_one['hard_limit'], result['hard_limit']) criterion = dict( tenant_id=quota_two['tenant_id'], resource=quota_two['resource'] ) result = self.storage.find_quota(self.admin_context, criterion) self.assertEqual(quota_two['tenant_id'], result['tenant_id']) self.assertEqual(quota_two['resource'], result['resource']) self.assertEqual(quota_two['hard_limit'], result['hard_limit']) def test_find_quota_criterion_missing(self): expected = self.create_quota() criterion = dict( tenant_id=expected['tenant_id'] + 'NOT FOUND' ) self.assertRaisesRegex( exceptions.QuotaNotFound, 'Could not find Quota', self.storage.find_quota, self.admin_context, criterion ) def test_update_quota(self): # Create a quota quota = self.create_quota(fixture=1) # Update the Object quota.hard_limit = 5000 # Perform the update quota = self.storage.update_quota(self.admin_context, quota) # Ensure the new value took self.assertEqual(5000, quota.hard_limit) # Ensure the version column was incremented self.assertEqual(2, quota.version) def test_update_quota_duplicate(self): # Create two quotas quota_one = self.create_quota(fixture=0) quota_two = self.create_quota(fixture=1) # Update the Q2 object to be a duplicate of Q1 quota_two.resource = quota_one.resource self.assertRaisesRegex( exceptions.DuplicateQuota, 'Duplicate Quota', self.storage.update_quota, self.admin_context, quota_two ) def test_update_quota_missing(self): quota = objects.Quota( id='caf771fc-6b05-4891-bee1-c2a48621f57b' ) self.assertRaisesRegex( exceptions.QuotaNotFound, 'Could not find Quota', self.storage.update_quota, self.admin_context, quota ) def test_delete_quota(self): quota = self.create_quota() self.storage.delete_quota(self.admin_context, quota['id']) self.assertRaisesRegex( exceptions.QuotaNotFound, 'Could not find Quota', self.storage.get_quota, self.admin_context, quota['id'] ) def test_delete_quota_missing(self): uuid = 'caf771fc-6b05-4891-bee1-c2a48621f57b' self.assertRaisesRegex( exceptions.QuotaNotFound, 'Could not find Quota', self.storage.delete_quota, self.admin_context, uuid ) # TSIG Key Tests def test_create_tsigkey(self): values = self.get_tsigkey_fixture() result = self.storage.create_tsigkey( self.admin_context, tsigkey=objects.TsigKey.from_dict(values)) self.assertIsNotNone(result['id']) self.assertIsNotNone(result['created_at']) self.assertIsNone(result['updated_at']) self.assertEqual(values['name'], result['name']) self.assertEqual(values['algorithm'], result['algorithm']) self.assertEqual(values['secret'], result['secret']) self.assertEqual(values['scope'], result['scope']) def test_create_tsigkey_duplicate(self): # Create the Initial TsigKey tsigkey_one = self.create_tsigkey() values = self.get_tsigkey_fixture(1) values['name'] = tsigkey_one['name'] exc = self.assertRaises(rpc_dispatcher.ExpectedException, self.create_tsigkey, **values) self.assertEqual(exceptions.DuplicateTsigKey, exc.exc_info[0]) def test_find_tsigkeys(self): actual = self.storage.find_tsigkeys(self.admin_context) self.assertEqual(0, len(actual)) # Create a single tsigkey tsig = self.create_tsigkey() actual = self.storage.find_tsigkeys(self.admin_context) self.assertEqual(1, len(actual)) self.assertEqual(tsig['name'], actual[0]['name']) self.assertEqual(tsig['algorithm'], actual[0]['algorithm']) self.assertEqual(tsig['secret'], actual[0]['secret']) self.assertEqual(tsig['scope'], actual[0]['scope']) def test_find_tsigkey(self): # Create a single tsigkey tsig = self.create_tsigkey() actual = self.storage.find_tsigkeys(self.admin_context) self.assertEqual(1, len(actual)) name = actual[0].name actual = self.storage.find_tsigkey(self.admin_context, {'name': name}) self.assertEqual(tsig['name'], actual['name']) self.assertEqual(tsig['algorithm'], actual['algorithm']) self.assertEqual(tsig['secret'], actual['secret']) self.assertEqual(tsig['scope'], actual['scope']) def test_find_tsigkeys_paging(self): # Create 10 TSIG Keys created = [self.create_tsigkey(name='tsig-%s' % i) for i in range(10)] # Ensure we can page through the results. self._ensure_paging(created, self.storage.find_tsigkeys) def test_find_tsigkeys_criterion(self): tsigkey_one = self.create_tsigkey(fixture=0) tsigkey_two = self.create_tsigkey(fixture=1) criterion = dict( name=tsigkey_one['name'] ) results = self.storage.find_tsigkeys(self.admin_context, criterion) self.assertEqual(1, len(results)) self.assertEqual(tsigkey_one['name'], results[0]['name']) criterion = dict( name=tsigkey_two['name'] ) results = self.storage.find_tsigkeys(self.admin_context, criterion) self.assertEqual(1, len(results)) self.assertEqual(tsigkey_two['name'], results[0]['name']) def test_get_tsigkey(self): # Create a tsigkey expected = self.create_tsigkey() actual = self.storage.get_tsigkey(self.admin_context, expected['id']) self.assertEqual(expected['name'], actual['name']) self.assertEqual(expected['algorithm'], actual['algorithm']) self.assertEqual(expected['secret'], actual['secret']) self.assertEqual(expected['scope'], actual['scope']) def test_get_tsigkey_missing(self): uuid = 'caf771fc-6b05-4891-bee1-c2a48621f57b' self.assertRaisesRegex( exceptions.TsigKeyNotFound, 'Could not find TsigKey', self.storage.get_tsigkey, self.admin_context, uuid ) def test_update_tsigkey(self): # Create a tsigkey tsigkey = self.create_tsigkey(name='test-key') # Update the Object tsigkey.name = 'test-key-updated' # Perform the update tsigkey = self.storage.update_tsigkey(self.admin_context, tsigkey) # Ensure the new value took self.assertEqual('test-key-updated', tsigkey.name) # Ensure the version column was incremented self.assertEqual(2, tsigkey.version) def test_update_tsigkey_duplicate(self): # Create two tsigkeys tsigkey_one = self.create_tsigkey(fixture=0) tsigkey_two = self.create_tsigkey(fixture=1) # Update the T2 object to be a duplicate of T1 tsigkey_two.name = tsigkey_one.name self.assertRaisesRegex( exceptions.DuplicateTsigKey, 'Duplicate TsigKey', self.storage.update_tsigkey, self.admin_context, tsigkey_two ) def test_update_tsigkey_missing(self): tsigkey = objects.TsigKey( id='caf771fc-6b05-4891-bee1-c2a48621f57b' ) self.assertRaisesRegex( exceptions.TsigKeyNotFound, 'Could not find TsigKey', self.storage.update_tsigkey, self.admin_context, tsigkey ) def test_delete_tsigkey(self): tsigkey = self.create_tsigkey() self.storage.delete_tsigkey(self.admin_context, tsigkey['id']) self.assertRaisesRegex( exceptions.TsigKeyNotFound, 'Could not find TsigKey', self.storage.get_tsigkey, self.admin_context, tsigkey['id'] ) def test_delete_tsigkey_missing(self): uuid = 'caf771fc-6b05-4891-bee1-c2a48621f57b' self.assertRaisesRegex( exceptions.TsigKeyNotFound, 'Could not find TsigKey', self.storage.delete_tsigkey, self.admin_context, uuid ) # Tenant Tests def test_find_tenants(self): context = self.get_admin_context() one_context = context one_context.project_id = 'One' two_context = context two_context.project_id = 'Two' context.all_tenants = True # create 3 zones in 2 tenants self.create_zone(fixture=0, context=one_context, tenant_id='One') zone = self.create_zone(fixture=1, context=one_context, tenant_id='One') self.create_zone(fixture=2, context=two_context, tenant_id='Two') # Delete one of the zones. self.storage.delete_zone(context, zone['id']) # Ensure we get accurate results result = self.storage.find_tenants(context) result_dict = [dict(t) for t in result] expected = [{ 'id': 'One', 'zone_count': 1, }, { 'id': 'Two', 'zone_count': 1, }] self.assertEqual(expected, result_dict) def test_get_tenant(self): context = self.get_admin_context() one_context = context one_context.project_id = 1 context.all_tenants = True # create 2 zones in a tenant zone_1 = self.create_zone(fixture=0, context=one_context) zone_2 = self.create_zone(fixture=1, context=one_context) zone_3 = self.create_zone(fixture=2, context=one_context) # Delete one of the zones. self.storage.delete_zone(context, zone_3['id']) result = self.storage.get_tenant(context, 1) self.assertEqual(1, result['id']) self.assertEqual(2, result['zone_count']) self.assertEqual([zone_1['name'], zone_2['name']], sorted(result['zones'])) def test_count_tenants(self): context = self.get_admin_context() one_context = context one_context.project_id = 1 two_context = context two_context.project_id = 2 context.all_tenants = True # in the beginning, there should be nothing tenants = self.storage.count_tenants(context) self.assertEqual(0, tenants) # create 2 zones with 2 tenants self.create_zone(fixture=0, context=one_context, tenant_id=1) self.create_zone(fixture=1, context=two_context, tenant_id=2) zone = self.create_zone(fixture=2, context=two_context, tenant_id=2) # Delete one of the zones. self.storage.delete_zone(context, zone['id']) tenants = self.storage.count_tenants(context) self.assertEqual(2, tenants) def test_count_tenants_no_results(self): tenants = self.storage.count_tenants(self.admin_context) self.assertEqual(0, tenants) @mock.patch('designate.storage.sql.get_read_session') def test_count_tenants_none_result(self, mock_read_session): mock_sql_execute = mock.Mock() mock_sql_fetchone = mock.Mock() mock_read_session().__enter__.return_value = mock_sql_execute mock_sql_execute.execute.return_value = mock_sql_fetchone mock_sql_fetchone.fetchone.return_value = None tenants = self.storage.count_tenants(self.admin_context) mock_read_session.assert_called() self.assertEqual(0, tenants) # Zone Tests def test_create_zone(self): pool_id = cfg.CONF['service:central'].default_pool_id values = { 'tenant_id': self.admin_context.project_id, 'name': 'example.net.', 'email': 'example@example.net', 'pool_id': pool_id } result = self.storage.create_zone( self.admin_context, zone=objects.Zone.from_dict(values)) self.assertIsNotNone(result['id']) self.assertIsNotNone(result['created_at']) self.assertIsNone(result['updated_at']) self.assertEqual(self.admin_context.project_id, result['tenant_id']) self.assertEqual(values['name'], result['name']) self.assertEqual(values['email'], result['email']) self.assertEqual(pool_id, result['pool_id']) self.assertIn('status', result) def test_create_zone_duplicate(self): # Create the Initial Zone self.create_zone() exc = self.assertRaises(rpc_dispatcher.ExpectedException, self.create_zone) self.assertEqual(exceptions.DuplicateZone, exc.exc_info[0]) def test_find_zones(self): self.config(quota_zones=20) actual = self.storage.find_zones(self.admin_context) self.assertEqual(0, len(actual)) # Create a single zone zone = self.create_zone() actual = self.storage.find_zones(self.admin_context) self.assertEqual(1, len(actual)) self.assertEqual(zone['name'], actual[0]['name']) self.assertEqual(zone['email'], actual[0]['email']) def test_find_zones_paging(self): # Create 10 zones created = [self.create_zone(name='example-%d.org.' % i) for i in range(10)] # Ensure we can page through the results. self._ensure_paging(created, self.storage.find_zones) def test_find_zones_criterion(self): zone_one = self.create_zone() zone_two = self.create_zone(fixture=1) criterion = dict( name=zone_one['name'] ) results = self.storage.find_zones(self.admin_context, criterion) self.assertEqual(1, len(results)) self.assertEqual(zone_one['name'], results[0]['name']) self.assertEqual(zone_one['email'], results[0]['email']) self.assertIn('status', zone_one) criterion = dict( name=zone_two['name'] ) results = self.storage.find_zones(self.admin_context, criterion) self.assertEqual(len(results), 1) self.assertEqual(zone_two['name'], results[0]['name']) self.assertEqual(zone_two['email'], results[0]['email']) self.assertIn('status', zone_two) def test_find_zones_all_tenants(self): # Create two contexts with different tenant_id's one_context = self.get_admin_context() one_context.project_id = 1 two_context = self.get_admin_context() two_context.project_id = 2 # Create normal and all_tenants context objects nm_context = self.get_admin_context() at_context = self.get_admin_context() at_context.all_tenants = True # Create two zones in different tenants self.create_zone(fixture=0, context=one_context) self.create_zone(fixture=1, context=two_context) # Ensure the all_tenants context see's two zones results = self.storage.find_zones(at_context) self.assertEqual(2, len(results)) # Ensure the normal context see's no zones results = self.storage.find_zones(nm_context) self.assertEqual(0, len(results)) # Ensure the tenant 1 context see's 1 zone results = self.storage.find_zones(one_context) self.assertEqual(1, len(results)) # Ensure the tenant 2 context see's 1 zone results = self.storage.find_zones(two_context) self.assertEqual(1, len(results)) def test_find_zones_shared(self): # Create an admin context admin_context = self.get_admin_context() # Create a zone in the admin context zone = self.create_zone(context=admin_context) # Share the zone with two other projects self.share_zone( zone_id=zone['id'], target_project_id=1, context=admin_context) self.share_zone( zone_id=zone['id'], target_project_id=2, context=admin_context) # Ensure that one zone record is returned from find_zones (LP 2025295) results = self.storage.find_zones(admin_context) self.assertEqual(1, len(results)) def test_get_zone(self): # Create a zone expected = self.create_zone() actual = self.storage.get_zone(self.admin_context, expected['id']) self.assertEqual(expected['name'], actual['name']) self.assertEqual(expected['email'], actual['email']) self.assertIn('status', actual) def test_get_zone_missing(self): uuid = 'caf771fc-6b05-4891-bee1-c2a48621f57b' self.assertRaisesRegex( exceptions.ZoneNotFound, 'Could not find Zone', self.storage.get_zone, self.admin_context, uuid ) def test_get_deleted_zone(self): context = self.get_admin_context() context.show_deleted = True zone = self.create_zone(context=context) self.storage.delete_zone(context, zone['id']) self.storage.get_zone(context, zone['id']) def test_find_zone_criterion(self): zone_one = self.create_zone() zone_two = self.create_zone(fixture=1) criterion = dict( name=zone_one['name'] ) result = self.storage.find_zone(self.admin_context, criterion) self.assertEqual(zone_one['name'], result['name']) self.assertEqual(zone_one['email'], result['email']) self.assertIn('status', zone_one) criterion = dict( name=zone_two['name'] ) result = self.storage.find_zone(self.admin_context, criterion) self.assertEqual(zone_two['name'], result['name']) self.assertEqual(zone_two['email'], result['email']) self.assertIn('status', zone_one) self.assertIn('status', zone_two) def test_find_zone_criterion_missing(self): expected = self.create_zone() criterion = dict( name=expected['name'] + 'NOT FOUND' ) self.assertRaisesRegex( exceptions.ZoneNotFound, 'Could not find Zone', self.storage.find_zone, self.admin_context, criterion ) def test_find_zone_criterion_lessthan(self): zone = self.create_zone() # Test Finding No Results (serial is not < serial) criterion = dict( name=zone['name'], serial='<%s' % zone['serial'], ) self.assertRaisesRegex( exceptions.ZoneNotFound, 'Could not find Zone', self.storage.find_zone, self.admin_context, criterion ) # Test Finding 1 Result (serial is < serial + 1) criterion = dict( name=zone['name'], serial='<%s' % (zone['serial'] + 1), ) result = self.storage.find_zone(self.admin_context, criterion) self.assertEqual(zone['name'], result['name']) def test_find_zone_criterion_greaterthan(self): zone = self.create_zone() # Test Finding No Results (serial is not > serial) criterion = dict( name=zone['name'], serial='>%s' % zone['serial'], ) self.assertRaisesRegex( exceptions.ZoneNotFound, 'Could not find Zone', self.storage.find_zone, self.admin_context, criterion ) # Test Finding 1 Result (serial is > serial - 1) criterion = dict( name=zone['name'], serial='>%s' % (zone['serial'] - 1), ) result = self.storage.find_zone(self.admin_context, criterion) self.assertEqual(zone['name'], result['name']) def test_update_zone(self): # Create a zone zone = self.create_zone(name='example.org.') # Update the Object zone.name = 'example.net.' zone.recordsets = objects.RecordSetList(objects=[]) zone.attributes = objects.ZoneAttributeList( objects=[objects.ZoneAttribute(key='foo', value='bar')] ) zone.masters = objects.ZoneMasterList( objects=[objects.ZoneMaster(host='127.0.0.1', port=80)] ) # Perform the update zone = self.storage.update_zone(self.admin_context, zone) # Ensure the new valie took self.assertEqual('example.net.', zone.name) # Ensure the version column was incremented self.assertEqual(2, zone.version) def test_update_zone_secondary(self): # Create a zone fixture = self.get_zone_fixture('SECONDARY', 1) fixture['email'] = 'root@example.com' zone = self.create_zone(**fixture) # Update the Object zone.name = 'example.net.' zone.recordsets = objects.RecordSetList() # Perform the update zone = self.storage.update_zone(self.admin_context, zone) # Ensure the new valie took self.assertEqual('example.net.', zone.name) # Ensure the version column was incremented self.assertEqual(2, zone.version) def test_update_zone_new_recordset_with_existing(self): zone = self.create_zone(name='example.org.') recordset1 = self.create_recordset(zone) recordset2 = objects.RecordSet( name='www.example.org.', type='A', records=objects.RecordList(objects=[ objects.Record(data='192.0.2.1'), ]) ) zone.name = 'example.net.' zone.recordsets = objects.RecordSetList( objects=[recordset1, recordset2] ) # Perform the update self.storage.update_zone(self.admin_context, zone) recordsets = self.storage.find_recordsets( self.admin_context, {'zone_id': zone['id']} ) self.assertEqual(4, len(recordsets)) def test_update_zone_new_recordset(self): zone = self.create_zone(name='example.org.') recordset = objects.RecordSet( name='www.example.org.', type='A', records=objects.RecordList(objects=[ objects.Record(data='192.0.2.1'), ]) ) zone.name = 'example.net.' zone.recordsets = objects.RecordSetList(objects=[recordset]) # Perform the update self.storage.update_zone(self.admin_context, zone) recordsets = self.storage.find_recordsets( self.admin_context, {'zone_id': zone['id']} ) self.assertEqual(3, len(recordsets)) def test_update_zone_duplicate(self): # Create two zones zone_one = self.create_zone(fixture=0) zone_two = self.create_zone(fixture=1) # Update the D2 object to be a duplicate of D1 zone_two.name = zone_one.name self.assertRaisesRegex( exceptions.DuplicateZone, 'Duplicate Zone', self.storage.update_zone, self.admin_context, zone_two ) def test_update_zone_missing(self): zone = objects.Zone( id='caf771fc-6b05-4891-bee1-c2a48621f57b' ) self.assertRaisesRegex( exceptions.ZoneNotFound, 'Could not find Zone', self.storage.update_zone, self.admin_context, zone ) def test_delete_zone(self): zone = self.create_zone() self.storage.delete_zone(self.admin_context, zone['id']) self.assertRaisesRegex( exceptions.ZoneNotFound, 'Could not find Zone', self.storage.get_zone, self.admin_context, zone['id'] ) def test_delete_zone_missing(self): uuid = 'caf771fc-6b05-4891-bee1-c2a48621f57b' self.assertRaisesRegex( exceptions.ZoneNotFound, 'Could not find Zone', self.storage.delete_zone, self.admin_context, uuid ) def test_count_zones(self): # in the beginning, there should be nothing zones = self.storage.count_zones(self.admin_context) self.assertEqual(0, zones) # Create a single zone self.create_zone() # count 'em up zones = self.storage.count_zones(self.admin_context) # well, did we get 1? self.assertEqual(1, zones) @mock.patch('designate.storage.sql.get_read_session') def test_count_zones_none_result(self, mock_read_session): mock_sql_execute = mock.Mock() mock_sql_fetchone = mock.Mock() mock_read_session().__enter__.return_value = mock_sql_execute mock_sql_execute.execute.return_value = mock_sql_fetchone mock_sql_fetchone.fetchone.return_value = None zones = self.storage.count_zones(self.admin_context) mock_read_session.assert_called() self.assertEqual(0, zones) def test_create_recordset(self): zone = self.create_zone() values = { 'name': 'www.%s' % zone['name'], 'type': 'A' } result = self.storage.create_recordset( self.admin_context, zone['id'], recordset=objects.RecordSet.from_dict(values)) self.assertIsNotNone(result['id']) self.assertIsNotNone(result['created_at']) self.assertIsNone(result['updated_at']) self.assertEqual(values['name'], result['name']) self.assertEqual(values['type'], result['type']) def test_create_recordset_duplicate(self): zone = self.create_zone() # Create the First RecordSet self.create_recordset(zone) exc = self.assertRaises(rpc_dispatcher.ExpectedException, self.create_recordset, zone) self.assertEqual(exceptions.DuplicateRecordSet, exc.exc_info[0]) def test_create_recordset_with_records(self): zone = self.create_zone() recordset = objects.RecordSet( name='www.%s' % zone['name'], type='A', records=objects.RecordList(objects=[ objects.Record(data='192.0.2.1'), objects.Record(data='192.0.2.2'), ]) ) recordset = self.storage.create_recordset( self.admin_context, zone['id'], recordset) # Ensure recordset.records is a RecordList instance self.assertIsInstance(recordset.records, objects.RecordList) # Ensure two Records are attached to the RecordSet correctly self.assertEqual(2, len(recordset.records)) self.assertIsInstance(recordset.records[0], objects.Record) self.assertIsInstance(recordset.records[1], objects.Record) # Ensure the Records have been saved by checking they have an ID self.assertIsNotNone(recordset.records[0].id) self.assertIsNotNone(recordset.records[1].id) def test_find_recordsets_axfr(self): zone = self.create_zone() self.create_recordset(zone) result = self.storage.find_recordsets_axfr( self.admin_context, {'zone_id': zone['id']} ) self.assertEqual(3, len(result)) def test_find_recordsets(self): zone = self.create_zone() criterion = {'zone_id': zone['id']} actual = self.storage.find_recordsets(self.admin_context, criterion) self.assertEqual(2, len(actual)) # Create a single recordset recordset_one = self.create_recordset(zone) actual = self.storage.find_recordsets(self.admin_context, criterion) self.assertEqual(3, len(actual)) self.assertEqual(recordset_one['name'], actual[2]['name']) self.assertEqual(recordset_one['type'], actual[2]['type']) def test_find_recordsets_paging(self): zone = self.create_zone(name='example.org.') # Create 10 RecordSets created = [self.create_recordset(zone, name='r-%d.example.org.' % i) for i in range(10)] # Add in the SOA and NS recordsets that are automatically created soa = self.storage.find_recordset(self.admin_context, criterion={'zone_id': zone['id'], 'type': 'SOA'}) ns = self.storage.find_recordset(self.admin_context, criterion={'zone_id': zone['id'], 'type': 'NS'}) created.insert(0, ns) created.insert(0, soa) # Ensure we can page through the results. self._ensure_paging(created, self.storage.find_recordsets) def test_find_recordsets_criterion(self): zone = self.create_zone() recordset_one = self.create_recordset(zone, type='A', fixture=0) self.create_recordset(zone, fixture=1) criterion = dict( zone_id=zone['id'], name=recordset_one['name'], ) results = self.storage.find_recordsets(self.admin_context, criterion) self.assertEqual(1, len(results)) criterion = dict( zone_id=zone['id'], type='A', ) results = self.storage.find_recordsets(self.admin_context, criterion) self.assertEqual(2, len(results)) def test_find_recordsets_criterion_wildcard(self): zone = self.create_zone() values = {'name': 'one.%s' % zone['name']} self.create_recordset(zone, **values) criterion = dict( zone_id=zone['id'], name='%%%(name)s' % {'name': zone['name']}, ) results = self.storage.find_recordsets(self.admin_context, criterion) # Should be 3, as SOA and NS recordsets are automiatcally created self.assertEqual(3, len(results)) def test_find_recordsets_with_records(self): zone = self.create_zone() records = [ objects.Record.from_dict({'data': '192.0.2.1'}), objects.Record.from_dict({'data': '192.0.2.2'}), objects.Record.from_dict({'data': '192.0.2.3'}) ] recordset = self.create_recordset(zone, records=records) criterion = dict( id=recordset.id, ) # Find the RecordSet results = self.storage.find_recordsets(self.admin_context, criterion) # Ensure we only have one result self.assertEqual(1, len(results)) recordset = results[0] # Ensure recordset.records is a RecordList instance self.assertIsInstance(recordset.records, objects.RecordList) # Ensure two Records are attached to the RecordSet correctly self.assertEqual(3, len(recordset.records)) records = [] for record in recordset.records: self.assertIsInstance(record, objects.Record) self.assertNotIn(record, records) records.append(record) def test_find_recordset_criterion(self): zone = self.create_zone() expected = self.create_recordset(zone) criterion = dict( zone_id=zone['id'], name=expected['name'], ) actual = self.storage.find_recordset(self.admin_context, criterion) self.assertEqual(expected['name'], actual['name']) self.assertEqual(expected['type'], actual['type']) def test_find_recordset_criterion_missing(self): zone = self.create_zone() expected = self.create_recordset(zone) criterion = dict( name=expected['name'] + 'NOT FOUND' ) self.assertRaisesRegex( exceptions.RecordSetNotFound, 'Could not find RecordSet', self.storage.find_recordset, self.admin_context, criterion ) def test_find_recordset_criterion_with_records(self): zone = self.create_zone() records = [ objects.Record.from_dict(self.get_record_fixture('A', fixture=0)), objects.Record.from_dict(self.get_record_fixture('A', fixture=1)) ] recordset = self.create_recordset(zone, records=records) criterion = dict( id=recordset.id, ) # Fetch the RecordSet again recordset = self.storage.find_recordset(self.admin_context, criterion) # Ensure recordset.records is a RecordList instance self.assertIsInstance(recordset.records, objects.RecordList) # Ensure two Records are attached to the RecordSet correctly self.assertEqual(2, len(recordset.records)) self.assertIsInstance(recordset.records[0], objects.Record) self.assertIsInstance(recordset.records[1], objects.Record) def test_update_recordset(self): zone = self.create_zone() # Create a recordset recordset = self.create_recordset(zone) # Update the Object recordset.ttl = 1800 # Change records as well recordset.records.append(objects.Record(data='192.0.2.2')) # Perform the update recordset = self.storage.update_recordset(self.admin_context, recordset) # Ensure the new value took self.assertEqual(1800, recordset.ttl) # Ensure the version column was incremented self.assertEqual(2, recordset.version) def test_update_recordset_duplicate(self): zone = self.create_zone() # Create two recordsets recordset_one = self.create_recordset(zone, type='A') recordset_two = self.create_recordset(zone, type='A', fixture=1) # Update the R2 object to be a duplicate of R1 recordset_two.name = recordset_one.name self.assertRaisesRegex( exceptions.DuplicateRecordSet, 'Duplicate RecordSet', self.storage.update_recordset, self.admin_context, recordset_two ) def test_update_recordset_missing(self): recordset = objects.RecordSet( id='caf771fc-6b05-4891-bee1-c2a48621f57b' ) self.assertRaisesRegex( exceptions.RecordSetNotFound, 'Could not find RecordSet', self.storage.update_recordset, self.admin_context, recordset ) def test_update_recordset_with_record_create(self): zone = self.create_zone() # Create a RecordSet recordset = self.create_recordset(zone, 'A', records=[]) # Append two new Records recordset.records.append(objects.Record(data='192.0.2.1')) recordset.records.append(objects.Record(data='192.0.2.2')) # Perform the update self.storage.update_recordset(self.admin_context, recordset) # Fetch the RecordSet again recordset = self.storage.find_recordset(self.admin_context, {'id': recordset.id}) # Ensure two Records are attached to the RecordSet correctly self.assertEqual(2, len(recordset.records)) self.assertIsInstance(recordset.records[0], objects.Record) self.assertIsInstance(recordset.records[1], objects.Record) # Ensure the Records have been saved by checking they have an ID self.assertIsNotNone(recordset.records[0].id) self.assertIsNotNone(recordset.records[1].id) def test_update_recordset_with_record_delete(self): zone = self.create_zone() # Create a RecordSet and two Records records = [ objects.Record.from_dict(self.get_record_fixture('A', fixture=0)), objects.Record.from_dict(self.get_record_fixture('A', fixture=1)) ] recordset = self.create_recordset(zone, records=records) # Fetch the RecordSet again recordset = self.storage.find_recordset(self.admin_context, {'id': recordset.id}) # Remove one of the Records recordset.records.pop(0) # Ensure only one Record is attached to the RecordSet self.assertEqual(1, len(recordset.records)) # Perform the update self.storage.update_recordset(self.admin_context, recordset) # Fetch the RecordSet again recordset = self.storage.find_recordset(self.admin_context, {'id': recordset.id}) # Ensure only one Record is attached to the RecordSet self.assertEqual(1, len(recordset.records)) self.assertIsInstance(recordset.records[0], objects.Record) def test_update_recordset_with_record_update(self): zone = self.create_zone() # Create a RecordSet and two Records records = [ objects.Record.from_dict(self.get_record_fixture('A', fixture=0)), objects.Record.from_dict(self.get_record_fixture('A', fixture=1)) ] recordset = self.create_recordset(zone, records=records) # Fetch the RecordSet again recordset = self.storage.find_recordset(self.admin_context, {'id': recordset.id}) # Update one of the Records updated_record_id = recordset.records[0].id recordset.records[0].data = '192.0.2.255' # Perform the update self.storage.update_recordset(self.admin_context, recordset) # Fetch the RecordSet again recordset = self.storage.find_recordset(self.admin_context, {'id': recordset.id}) # Ensure the Record has been updated for record in recordset.records: if record.id != updated_record_id: continue self.assertEqual('192.0.2.255', record.data) return # Exits this test early as we succeeded raise Exception('Updated record not found') def test_delete_recordset(self): zone = self.create_zone() # Create a recordset recordset = self.create_recordset(zone) self.storage.delete_recordset(self.admin_context, recordset['id']) self.assertRaisesRegex( exceptions.RecordSetNotFound, 'Could not find RecordSet', self.storage.find_recordset, self.admin_context, criterion={'id': recordset['id']} ) def test_delete_recordset_missing(self): uuid = 'caf771fc-6b05-4891-bee1-c2a48621f57b' self.assertRaisesRegex( exceptions.RecordSetNotFound, 'Could not find RecordSet', self.storage.delete_recordset, self.admin_context, uuid ) def test_count_recordsets(self): # in the beginning, there should be nothing recordsets = self.storage.count_recordsets(self.admin_context) self.assertEqual(0, recordsets) # Create a single zone & recordset zone = self.create_zone() self.create_recordset(zone) # we should have 3 recordsets now, including SOA & NS recordsets = self.storage.count_recordsets(self.admin_context) self.assertEqual(3, recordsets) # Delete the zone, we should be back to 0 recordsets self.storage.delete_zone(self.admin_context, zone.id) recordsets = self.storage.count_recordsets(self.admin_context) self.assertEqual(0, recordsets) @mock.patch('designate.storage.sql.get_read_session') def test_count_recordsets_none_result(self, mock_read_session): mock_sql_execute = mock.Mock() mock_sql_fetchone = mock.Mock() mock_read_session().__enter__.return_value = mock_sql_execute mock_sql_execute.execute.return_value = mock_sql_fetchone mock_sql_fetchone.fetchone.return_value = None recordsets = self.storage.count_recordsets(self.admin_context) mock_read_session.assert_called() self.assertEqual(0, recordsets) def test_find_records(self): zone = self.create_zone() recordset = self.create_recordset(zone, records=[]) criterion = { 'zone_id': zone['id'], 'recordset_id': recordset['id'] } actual = self.storage.find_records(self.admin_context, criterion) self.assertEqual(0, len(actual)) # Create a single record records = [ objects.Record.from_dict(self.get_record_fixture('A', fixture=0)), ] recordset.records = records self.central_service.update_recordset(self.admin_context, recordset) recordset = self.central_service.get_recordset( self.admin_context, zone['id'], recordset['id'] ) record = recordset.records[0] actual = self.storage.find_records(self.admin_context, criterion) self.assertEqual(1, len(actual)) self.assertEqual(record['data'], actual[0]['data']) def test_find_records_paging(self): zone = self.create_zone() records = [] for i in range(10): records.append( objects.Record.from_dict(({'data': '192.0.2.%d' % i})) ) self.create_recordset(zone, type='A', records=records) # Add in the SOA and NS records that are automatically created soa = self.storage.find_recordset(self.admin_context, criterion={'zone_id': zone['id'], 'type': 'SOA'}) ns = self.storage.find_recordset(self.admin_context, criterion={'zone_id': zone['id'], 'type': 'NS'}) for r in ns['records']: records.insert(0, r) records.insert(0, soa['records'][0]) # Ensure we can page through the results. self._ensure_paging(records, self.storage.find_records) def test_find_records_criterion(self): zone = self.create_zone() record_one = objects.Record.from_dict( self.get_record_fixture('A', fixture=0) ) records = [ record_one, objects.Record.from_dict(self.get_record_fixture('A', fixture=1)) ] recordset = self.create_recordset(zone, records=records) criterion = dict( data=record_one['data'], zone_id=zone['id'], recordset_id=recordset['id'], ) results = self.storage.find_records(self.admin_context, criterion) self.assertEqual(1, len(results)) criterion = dict( zone_id=zone['id'], recordset_id=recordset['id'], ) results = self.storage.find_records(self.admin_context, criterion) self.assertEqual(2, len(results)) def test_find_records_criterion_wildcard(self): zone = self.create_zone() records = [objects.Record.from_dict({'data': '127.0.0.1'})] recordset = self.create_recordset(zone, type='A', records=records) criterion = dict( zone_id=zone['id'], recordset_id=recordset['id'], data='%.0.0.1', ) results = self.storage.find_records(self.admin_context, criterion) self.assertEqual(1, len(results)) def test_get_record(self): zone = self.create_zone() recordset = self.create_recordset(zone) expected = recordset.records[0] actual = self.storage.get_record(self.admin_context, expected['id']) self.assertEqual(expected['data'], actual['data']) self.assertIn('status', actual) def test_get_record_missing(self): uuid = 'caf771fc-6b05-4891-bee1-c2a48621f57b' self.assertRaisesRegex( exceptions.RecordNotFound, 'Could not find Record', self.storage.get_record, self.admin_context, uuid ) def test_find_record_criterion(self): zone = self.create_zone() recordset = self.create_recordset(zone) expected = recordset.records[0] criterion = dict( zone_id=zone['id'], recordset_id=recordset['id'], data=expected['data'], ) actual = self.storage.find_record(self.admin_context, criterion) self.assertEqual(expected['data'], actual['data']) self.assertIn('status', actual) def test_find_record_criterion_missing(self): zone = self.create_zone() recordset = self.create_recordset(zone) expected = recordset.records[0] criterion = dict( zone_id=zone['id'], data=expected['data'] + 'NOT FOUND', ) self.assertRaisesRegex( exceptions.RecordNotFound, 'Could not find Record', self.storage.find_record, self.admin_context, criterion ) def test_update_record(self): zone = self.create_zone() recordset = self.create_recordset(zone, type='A') record = recordset.records[0] # Update the Object record.data = '192.0.2.255' # Perform the update record = self.storage.update_record(self.admin_context, record) # Ensure the new value took self.assertEqual('192.0.2.255', record.data) # Ensure the version column was incremented self.assertEqual(2, record.version) def test_update_record_duplicate(self): zone = self.create_zone() record_one = objects.Record.from_dict( self.get_record_fixture('A', fixture=0) ) record_two = objects.Record.from_dict( self.get_record_fixture('A', fixture=1) ) records = [ record_one, record_two ] self.create_recordset(zone, records=records) # Update the R2 object to be a duplicate of R1 record_two.data = record_one.data self.assertRaisesRegex( exceptions.DuplicateRecord, 'Duplicate Record', self.storage.update_record, self.admin_context, record_two ) def test_update_record_missing(self): record = objects.Record( id='caf771fc-6b05-4891-bee1-c2a48621f57b' ) self.assertRaisesRegex( exceptions.RecordNotFound, 'Could not find Record', self.storage.update_record, self.admin_context, record ) def test_delete_record(self): zone = self.create_zone() recordset = self.create_recordset(zone) record = recordset.records[0] self.storage.delete_record(self.admin_context, record['id']) self.assertRaisesRegex( exceptions.RecordNotFound, 'Could not find Record', self.storage.get_record, self.admin_context, record['id'] ) def test_delete_record_missing(self): uuid = 'caf771fc-6b05-4891-bee1-c2a48621f57b' self.assertRaisesRegex( exceptions.RecordNotFound, 'Could not find Record', self.storage.delete_record, self.admin_context, uuid ) def test_count_records(self): # in the beginning, there should be nothing records = self.storage.count_records(self.admin_context) self.assertEqual(0, records) # Create a single zone & record zone = self.create_zone() self.create_recordset(zone) # we should have 3 records now, including NS and SOA records = self.storage.count_records(self.admin_context) self.assertEqual(3, records) # Delete the zone, we should be back to 0 records self.storage.delete_zone(self.admin_context, zone.id) records = self.storage.count_records(self.admin_context) self.assertEqual(0, records) @mock.patch('designate.storage.sql.get_read_session') def test_count_records_none_result(self, mock_read_session): mock_sql_execute = mock.Mock() mock_sql_fetchone = mock.Mock() mock_read_session().__enter__.return_value = mock_sql_execute mock_sql_execute.execute.return_value = mock_sql_fetchone mock_sql_fetchone.fetchone.return_value = None records = self.storage.count_records(self.admin_context) mock_read_session.assert_called() self.assertEqual(0, records) # TLD Tests def test_create_tld(self): values = { 'name': 'com', 'description': 'This is a comment.' } result = self.storage.create_tld( self.admin_context, objects.Tld.from_dict(values)) self.assertIsNotNone(result['id']) self.assertIsNotNone(result['created_at']) self.assertIsNone(result['updated_at']) self.assertIsNotNone(result['version']) self.assertEqual(values['name'], result['name']) self.assertEqual(values['description'], result['description']) def test_create_tld_with_duplicate(self): # Create the First Tld self.create_tld(fixture=0) exc = self.assertRaises(rpc_dispatcher.ExpectedException, self.create_tld, fixture=0) self.assertEqual(exceptions.DuplicateTld, exc.exc_info[0]) def test_find_tlds(self): actual = self.storage.find_tlds(self.admin_context) self.assertEqual(0, len(actual)) # Create a single Tld tld = self.create_tld(fixture=0) actual = self.storage.find_tlds(self.admin_context) self.assertEqual(1, len(actual)) self.assertEqual(tld['name'], actual[0]['name']) self.assertEqual(tld['description'], actual[0]['description']) def test_find_tlds_paging(self): # Create 10 Tlds created = [self.create_tld(name='org%d' % i) for i in range(10)] # Ensure we can page through the results. self._ensure_paging(created, self.storage.find_tlds) def test_find_tlds_with_criterion(self): tld_one = self.create_tld(fixture=0) tld_two = self.create_tld(fixture=1) criterion_one = dict(name=tld_one['name']) results = self.storage.find_tlds(self.admin_context, criterion_one) self.assertEqual(1, len(results)) self.assertEqual(tld_one['name'], results[0]['name']) criterion_two = dict(name=tld_two['name']) results = self.storage.find_tlds(self.admin_context, criterion_two) self.assertEqual(len(results), 1) self.assertEqual(tld_two['name'], results[0]['name']) def test_get_tld(self): # Create a tld expected = self.create_tld() actual = self.storage.get_tld(self.admin_context, expected['id']) self.assertEqual(expected['name'], actual['name']) def test_get_tld_missing(self): uuid = '4c8e7f82-3519-4bf7-8940-a66a4480f223' self.assertRaisesRegex( exceptions.TldNotFound, 'Could not find Tld', self.storage.get_tld, self.admin_context, uuid ) def test_find_tld_criterion(self): # Create two tlds tld_one = self.create_tld(fixture=0) tld_two = self.create_tld(fixture=1) criterion = dict(name=tld_one['name']) # Find tld_one using its name as criterion result = self.storage.find_tld(self.admin_context, criterion) # Assert names match self.assertEqual(tld_one['name'], result['name']) # Repeat with tld_two criterion = dict(name=tld_two['name']) result = self.storage.find_tld(self.admin_context, criterion) self.assertEqual(tld_two['name'], result['name']) def test_find_tld_criterion_missing(self): expected = self.create_tld() criterion = dict(name=expected['name'] + 'NOT FOUND') self.assertRaisesRegex( exceptions.TldNotFound, 'Could not find Tld', self.storage.find_tld, self.admin_context, criterion ) def test_update_tld(self): # Create a tld tld = self.create_tld(name='net') # Update the tld tld.name = 'org' # Update storage tld = self.storage.update_tld(self.admin_context, tld) # Verify the new value self.assertEqual('org', tld.name) # Ensure the version column was incremented self.assertEqual(2, tld.version) def test_update_tld_duplicate(self): # Create two tlds tld_one = self.create_tld(fixture=0) tld_two = self.create_tld(fixture=1) # Update tld_two to be a duplicate of tld_ond tld_two.name = tld_one.name self.assertRaisesRegex( exceptions.DuplicateTld, 'Duplicate Tld', self.storage.update_tld, self.admin_context, tld_two ) def test_update_tld_missing(self): tld = objects.Tld( id='486f9cbe-b8b6-4d8c-8275-1a6e47b13e00' ) self.assertRaisesRegex( exceptions.TldNotFound, 'Could not find Tld', self.storage.update_tld, self.admin_context, tld ) def test_delete_tld(self): # Create a tld tld = self.create_tld() # Delete the tld self.storage.delete_tld(self.admin_context, tld['id']) # Verify that it's deleted self.assertRaisesRegex( exceptions.TldNotFound, 'Could not find Tld', self.storage.get_tld, self.admin_context, tld['id'] ) def test_delete_tld_missing(self): uuid = 'cac1fc02-79b2-4e62-a1a4-427b6790bbe6' self.assertRaisesRegex( exceptions.TldNotFound, 'Could not find Tld', self.storage.delete_tld, self.admin_context, uuid ) # Blacklist tests def test_create_blacklist(self): values = { 'pattern': '^([A-Za-z0-9_\\-]+\\.)*example\\.com\\.$', 'description': 'This is a comment.' } result = self.storage.create_blacklist( self.admin_context, objects.Blacklist.from_dict(values)) self.assertIsNotNone(result['id']) self.assertIsNotNone(result['created_at']) self.assertIsNotNone(result['version']) self.assertIsNone(result['updated_at']) self.assertEqual(values['pattern'], result['pattern']) self.assertEqual(values['description'], result['description']) def test_create_blacklist_duplicate(self): # Create the initial Blacklist self.create_blacklist(fixture=0) exc = self.assertRaises(rpc_dispatcher.ExpectedException, self.create_blacklist, fixture=0) self.assertEqual(exceptions.DuplicateBlacklist, exc.exc_info[0]) def test_find_blacklists(self): # Verify that there are no blacklists created actual = self.storage.find_blacklists(self.admin_context) self.assertEqual(0, len(actual)) # Create a Blacklist blacklist = self.create_blacklist(fixture=0) actual = self.storage.find_blacklists(self.admin_context) self.assertEqual(1, len(actual)) self.assertEqual(blacklist['pattern'], actual[0]['pattern']) def test_find_blacklists_paging(self): # Create 10 Blacklists created = [self.create_blacklist(pattern='^example-%d.org.' % i) for i in range(10)] # Ensure we can page through the results. self._ensure_paging(created, self.storage.find_blacklists) def test_find_blacklists_with_criterion(self): # Create two blacklists blacklist_one = self.create_blacklist(fixture=0) blacklist_two = self.create_blacklist(fixture=1) # Verify blacklist_one criterion = dict(pattern=blacklist_one['pattern']) results = self.storage.find_blacklists(self.admin_context, criterion) self.assertEqual(1, len(results)) self.assertEqual(blacklist_one['pattern'], results[0]['pattern']) # Verify blacklist_two criterion = dict(pattern=blacklist_two['pattern']) results = self.storage.find_blacklists(self.admin_context, criterion) self.assertEqual(1, len(results)) self.assertEqual(blacklist_two['pattern'], results[0]['pattern']) def test_get_blacklist(self): expected = self.create_blacklist(fixture=0) actual = self.storage.get_blacklist(self.admin_context, expected['id']) self.assertEqual(expected['pattern'], actual['pattern']) def test_get_blacklist_missing(self): uuid = '2c102ffd-7146-4b4e-ad62-b530ee0873fb' self.assertRaisesRegex( exceptions.BlacklistNotFound, 'Could not find Blacklist', self.storage.get_blacklist, self.admin_context, uuid ) def test_find_blacklist_criterion(self): blacklist_one = self.create_blacklist(fixture=0) blacklist_two = self.create_blacklist(fixture=1) criterion = dict(pattern=blacklist_one['pattern']) result = self.storage.find_blacklist(self.admin_context, criterion) self.assertEqual(blacklist_one['pattern'], result['pattern']) criterion = dict(pattern=blacklist_two['pattern']) result = self.storage.find_blacklist(self.admin_context, criterion) self.assertEqual(blacklist_two['pattern'], result['pattern']) def test_find_blacklist_criterion_missing(self): expected = self.create_blacklist(fixture=0) criterion = dict(pattern=expected['pattern'] + 'NOT FOUND') self.assertRaisesRegex( exceptions.BlacklistNotFound, 'Could not find Blacklist', self.storage.find_blacklist, self.admin_context, criterion ) def test_update_blacklist(self): blacklist = self.create_blacklist(pattern='^example.uk.') # Update the blacklist blacklist.pattern = '^example.uk.co.' blacklist = self.storage.update_blacklist(self.admin_context, blacklist) # Verify the new values self.assertEqual('^example.uk.co.', blacklist.pattern) # Ensure the version column was incremented self.assertEqual(2, blacklist.version) def test_update_blacklist_duplicate(self): # Create two blacklists blacklist_one = self.create_blacklist(fixture=0) blacklist_two = self.create_blacklist(fixture=1) # Update the second one to be a duplicate of the first blacklist_two.pattern = blacklist_one.pattern self.assertRaisesRegex( exceptions.DuplicateBlacklist, 'Duplicate Blacklist', self.storage.update_blacklist, self.admin_context, blacklist_two ) def test_update_blacklist_missing(self): blacklist = objects.Blacklist( id='e8cee063-3a26-42d6-b181-bdbdc2c99d08' ) self.assertRaisesRegex( exceptions.BlacklistNotFound, 'Could not find Blacklist', self.storage.update_blacklist, self.admin_context, blacklist ) def test_delete_blacklist(self): blacklist = self.create_blacklist(fixture=0) self.storage.delete_blacklist(self.admin_context, blacklist['id']) self.assertRaisesRegex( exceptions.BlacklistNotFound, 'Could not find Blacklist', self.storage.get_blacklist, self.admin_context, blacklist['id'] ) def test_delete_blacklist_missing(self): uuid = '97f57960-f41b-4e93-8e22-8fd6c7e2c183' self.assertRaisesRegex( exceptions.BlacklistNotFound, 'Could not find Blacklist', self.storage.delete_blacklist, self.admin_context, uuid ) # Pool Tests def test_create_pool(self): values = { 'name': 'test1', 'tenant_id': self.admin_context.project_id, 'provisioner': 'UNMANAGED' } result = self.storage.create_pool( self.admin_context, objects.Pool.from_dict(values)) self.assertIsNotNone(result['id']) self.assertIsNotNone(result['created_at']) self.assertIsNone(result['updated_at']) self.assertEqual(values['name'], result['name']) self.assertEqual(values['tenant_id'], result['tenant_id']) self.assertEqual(values['provisioner'], result['provisioner']) def test_create_pool_with_all_relations(self): values = { 'name': 'Pool', 'description': 'Pool description', 'attributes': [{'key': 'scope', 'value': 'public'}], 'ns_records': [{'priority': 1, 'hostname': 'ns1.example.org.'}], 'nameservers': [{'host': '192.0.2.1', 'port': 53}], 'targets': [{ 'type': 'fake', 'description': 'FooBar', 'masters': [{'host': '192.0.2.2', 'port': DEFAULT_MDNS_PORT}], 'options': [{'key': 'fake_option', 'value': 'fake_value'}], }], 'also_notifies': [{'host': '192.0.2.3', 'port': 53}] } # Create the Pool, and check all values are OK result = self.storage.create_pool( self.admin_context, objects.Pool.from_dict(values)) self.assertNestedDictContainsSubset(values, result.to_dict()) # Re-Fetch the pool, and check everything is still OK result = self.storage.get_pool(self.admin_context, result.id) self.assertNestedDictContainsSubset(values, result.to_dict()) def test_create_pool_duplicate(self): # Create the first pool self.create_pool(fixture=0) # Create the second pool and should get exception exc = self.assertRaises(rpc_dispatcher.ExpectedException, self.create_pool, fixture=0) self.assertEqual(exceptions.DuplicatePool, exc.exc_info[0]) def test_find_pools(self): # Verify that there are no pools, except for default pool actual = self.storage.find_pools(self.admin_context) self.assertEqual(1, len(actual)) # Create a Pool pool = self.create_pool(fixture=0) actual = self.storage.find_pools(self.admin_context) self.assertEqual(2, len(actual)) # Test against the second pool, since the first is the default pool self.assertEqual(pool['name'], actual[1]['name']) def test_find_pools_paging(self): # Get any pools that are already created, including default pools = self.storage.find_pools(self.admin_context) # Create 10 Pools created = [self.create_pool(name='test%d' % i) for i in range(10)] # Add in the existing pools for p in pools: created.insert(0, p) # Ensure we can page through the results self._ensure_paging(created, self.storage.find_pools) def test_find_pools_criterion(self): # Create two pools pool_one = self.create_pool(fixture=0) pool_two = self.create_pool(fixture=1) # Verify pool_one criterion = dict(name=pool_one['name']) results = self.storage.find_pools(self.admin_context, criterion) self.assertEqual(1, len(results)) self.assertEqual(pool_one['name'], results[0]['name']) self.assertEqual(pool_one['provisioner'], results[0]['provisioner']) criterion = dict(name=pool_two['name']) results = self.storage.find_pools(self.admin_context, criterion) self.assertEqual(1, len(results)) self.assertEqual(pool_two['name'], results[0]['name']) self.assertEqual(pool_two['provisioner'], results[0]['provisioner']) def test_get_pool(self): # Create a pool expected = self.create_pool() actual = self.storage.get_pool(self.admin_context, expected['id']) self.assertEqual(expected['name'], actual['name']) self.assertEqual(expected['provisioner'], actual['provisioner']) def test_get_pool_missing(self): uuid = 'c28893e3-eb87-4562-aa29-1f0e835d749b' self.assertRaisesRegex( exceptions.PoolNotFound, 'Could not find Pool', self.storage.get_pool, self.admin_context, uuid ) def test_find_pool_criterion(self): pool_one = self.create_pool(fixture=0) pool_two = self.create_pool(fixture=1) criterion = dict(name=pool_one['name']) result = self.storage.find_pool(self.admin_context, criterion) self.assertEqual(pool_one['name'], result['name']) self.assertEqual(pool_one['provisioner'], result['provisioner']) criterion = dict(name=pool_two['name']) result = self.storage.find_pool(self.admin_context, criterion) self.assertEqual(pool_two['name'], result['name']) self.assertEqual(pool_two['provisioner'], result['provisioner']) def test_find_pool_criterion_missing(self): expected = self.create_pool() criterion = dict(name=expected['name'] + 'NOT FOUND') self.assertRaisesRegex( exceptions.PoolNotFound, 'Could not find Pool', self.storage.find_pool, self.admin_context, criterion ) def test_update_pool(self): # Create a pool pool = self.create_pool(name='test1') # Update the Pool pool.name = 'test3' # Perform the update pool = self.storage.update_pool(self.admin_context, pool) # Verify the new value is there self.assertEqual('test3', pool.name) def test_update_pool_duplicate(self): # Create two pools pool_one = self.create_pool(fixture=0) pool_two = self.create_pool(fixture=1) # Update pool_two to be a duplicate of pool_one pool_two.name = pool_one.name self.assertRaisesRegex( exceptions.DuplicatePool, 'Duplicate Pool', self.storage.update_pool, self.admin_context, pool_two ) def test_update_pool_missing(self): pool = objects.Pool( id='8806f871-5140-43f4-badd-2bbc5715b013' ) self.assertRaisesRegex( exceptions.PoolNotFound, 'Could not find Pool', self.storage.update_pool, self.admin_context, pool ) def test_update_pool_with_all_relations(self): values = { 'name': 'Pool-A', 'description': 'Pool-A description', 'attributes': [{'key': 'scope', 'value': 'public'}], 'ns_records': [{'priority': 1, 'hostname': 'ns1.example.org.'}], 'nameservers': [{'host': '192.0.2.1', 'port': 53}], 'targets': [{ 'type': 'fake', 'description': 'FooBar', 'masters': [{'host': '192.0.2.2', 'port': DEFAULT_MDNS_PORT}], 'options': [{'key': 'fake_option', 'value': 'fake_value'}], }], 'also_notifies': [{'host': '192.0.2.3', 'port': 53}] } # Create the Pool result = self.storage.create_pool( self.admin_context, objects.Pool.from_dict(values)) created_pool_id = result.id # Prepare a new set of data for the Pool, copying over the ID so # we trigger an update rather than a create. values = { 'id': created_pool_id, 'name': 'Pool-B', 'description': 'Pool-B description', 'attributes': [{'key': 'scope', 'value': 'private'}], 'ns_records': [{'priority': 1, 'hostname': 'ns2.example.org.'}], 'nameservers': [{'host': '192.0.2.5', 'port': 53}], 'targets': [{ 'type': 'fake', 'description': 'NewFooBar', 'masters': [{'host': '192.0.2.2', 'port': DEFAULT_MDNS_PORT}], 'options': [{'key': 'fake_option', 'value': 'fake_value'}], }, { 'type': 'fake', 'description': 'FooBar2', 'masters': [{'host': '192.0.2.7', 'port': 5355}], 'options': [{'key': 'fake_option', 'value': 'new_fake_value'}], }], 'also_notifies': [] } # Update the pool, and check everything is OK result = self.storage.update_pool( self.admin_context, objects.Pool.from_dict(values)) self.assertNestedDictContainsSubset(values, result.to_dict()) # Re-Fetch the pool, and check everything is still OK result = self.storage.get_pool(self.admin_context, created_pool_id) self.assertNestedDictContainsSubset(values, result.to_dict()) def test_delete_pool(self): pool = self.create_pool() self.storage.delete_pool(self.admin_context, pool['id']) self.assertRaisesRegex( exceptions.PoolNotFound, 'Could not find Pool', self.storage.delete_pool, self.admin_context, pool['id'] ) def test_delete_pool_missing(self): uuid = '203ca44f-c7e7-4337-9a02-0d735833e6aa' self.assertRaisesRegex( exceptions.PoolNotFound, 'Could not find Pool', self.storage.delete_pool, self.admin_context, uuid ) def test_create_pool_ns_record_duplicate(self): # Create a pool pool = self.create_pool(name='test1') ns = objects.PoolNsRecord(priority=1, hostname='ns.example.io.') self.storage.create_pool_ns_record( self.admin_context, pool.id, ns) ns2 = objects.PoolNsRecord(priority=2, hostname='ns.example.io.') self.assertRaisesRegex( exceptions.DuplicatePoolNsRecord, 'Duplicate PoolNsRecord', self.storage.create_pool_ns_record, self.admin_context, pool.id, ns2 ) def test_update_pool_ns_record_duplicate(self): # Create a pool pool = self.create_pool(name='test1') ns1 = objects.PoolNsRecord(priority=1, hostname='ns1.example.io.') self.storage.create_pool_ns_record( self.admin_context, pool.id, ns1) ns2 = objects.PoolNsRecord(priority=2, hostname='ns2.example.io.') self.storage.create_pool_ns_record( self.admin_context, pool.id, ns2) ns2.hostname = ns1.hostname self.assertRaisesRegex( exceptions.DuplicatePoolNsRecord, 'Duplicate PoolNsRecord', self.storage.update_pool_ns_record, self.admin_context, ns2 ) # PoolAttribute tests def test_create_pool_attribute(self): values = { 'pool_id': 'd5d10661-0312-4ae1-8664-31188a4310b7', 'key': 'test-attribute', 'value': 'test-value' } result = self.storage.create_pool_attribute( self.admin_context, values['pool_id'], objects.PoolAttribute.from_dict(values)) self.assertIsNotNone(result['id']) self.assertIsNotNone(result['created_at']) self.assertIsNotNone(result['version']) self.assertIsNone(result['updated_at']) self.assertEqual(values['pool_id'], result['pool_id']) self.assertEqual(values['key'], result['key']) self.assertEqual(values['value'], result['value']) def test_find_pool_attribute(self): # Verify that there are no Pool Attributes created actual = self.storage.find_pool_attributes(self.admin_context) self.assertEqual(0, len(actual)) # Create a Pool Attribute pool_attribute = self.create_pool_attribute(fixture=0) actual = self.storage.find_pool_attributes(self.admin_context) self.assertEqual(1, len(actual)) self.assertEqual(pool_attribute['pool_id'], actual[0]['pool_id']) self.assertEqual(pool_attribute['key'], actual[0]['key']) self.assertEqual(pool_attribute['value'], actual[0]['value']) def test_find_pool_attributes_paging(self): # Create 10 Pool Attributes created = [self.create_pool_attribute(value='^ns%d.example.com.' % i) for i in range(10)] # Ensure we can page through the results. self._ensure_paging(created, self.storage.find_pool_attributes) def test_find_pool_attributes_with_criterion(self): # Create two pool attributes pool_attribute_one = self.create_pool_attribute(fixture=0) pool_attribute_two = self.create_pool_attribute(fixture=1) # Verify pool_attribute_one criterion = dict(key=pool_attribute_one['key']) results = self.storage.find_pool_attributes(self.admin_context, criterion) self.assertEqual(1, len(results)) self.assertEqual(pool_attribute_one['pool_id'], results[0]['pool_id']) self.assertEqual(pool_attribute_one['key'], results[0]['key']) self.assertEqual(pool_attribute_one['value'], results[0]['value']) # Verify pool_attribute_two criterion = dict(key=pool_attribute_two['key']) LOG.debug('Criterion is %r ' % criterion) results = self.storage.find_pool_attributes(self.admin_context, criterion) self.assertEqual(1, len(results)) self.assertEqual(pool_attribute_two['pool_id'], results[0]['pool_id']) self.assertEqual(pool_attribute_two['key'], results[0]['key']) self.assertEqual(pool_attribute_two['value'], results[0]['value']) def test_get_pool_attribute(self): expected = self.create_pool_attribute(fixture=0) actual = self.storage.get_pool_attribute(self.admin_context, expected['id']) self.assertEqual(expected['pool_id'], actual['pool_id']) self.assertEqual(expected['key'], actual['key']) self.assertEqual(expected['value'], actual['value']) def test_get_pool_attribute_missing(self): uuid = '2c102ffd-7146-4b4e-ad62-b530ee0873fb' self.assertRaisesRegex( exceptions.PoolAttributeNotFound, 'Could not find PoolAttribute', self.storage.get_pool_attribute, self.admin_context, uuid ) def test_find_pool_attribute_criterion(self): pool_attribute_one = self.create_pool_attribute(fixture=0) pool_attribute_two = self.create_pool_attribute(fixture=1) criterion = dict(key=pool_attribute_one['key']) result = self.storage.find_pool_attribute(self.admin_context, criterion) self.assertEqual(pool_attribute_one['pool_id'], result['pool_id']) self.assertEqual(pool_attribute_one['key'], result['key']) self.assertEqual(pool_attribute_one['value'], result['value']) criterion = dict(key=pool_attribute_two['key']) result = self.storage.find_pool_attribute(self.admin_context, criterion) self.assertEqual(pool_attribute_two['pool_id'], result['pool_id']) self.assertEqual(pool_attribute_two['key'], result['key']) self.assertEqual(pool_attribute_two['value'], result['value']) def test_find_pool_attribute_criterion_missing(self): expected = self.create_pool_attribute(fixture=0) criterion = dict(key=expected['key'] + 'NOT FOUND') self.assertRaisesRegex( exceptions.PoolAttributeNotFound, 'Could not find PoolAttribute', self.storage.find_pool_attribute, self.admin_context, criterion ) def test_update_pool_attribute(self): pool_attribute = self.create_pool_attribute(value='ns1.example.org') # Update the Pool Attribute pool_attribute.value = 'ns5.example.org' pool_attribute = self.storage.update_pool_attribute(self.admin_context, pool_attribute) # Verify the new values self.assertEqual('ns5.example.org', pool_attribute.value) # Ensure the version column was incremented self.assertEqual(2, pool_attribute.version) def test_update_pool_attribute_missing(self): pool_attribute = objects.PoolAttribute( id='728a329a-83b1-4573-82dc-45dceab435d4' ) self.assertRaisesRegex( exceptions.PoolAttributeNotFound, 'Could not find PoolAttribute', self.storage.update_pool_attribute, self.admin_context, pool_attribute ) def test_update_pool_attribute_duplicate(self): # Create two PoolAttributes pool_attribute_one = self.create_pool_attribute(fixture=0) pool_attribute_two = self.create_pool_attribute(fixture=1) # Update the second one to be a duplicate of the first pool_attribute_two.pool_id = pool_attribute_one.pool_id pool_attribute_two.key = pool_attribute_one.key pool_attribute_two.value = pool_attribute_one.value self.assertRaisesRegex( exceptions.DuplicatePoolAttribute, 'Duplicate PoolAttribute', self.storage.update_pool_attribute, self.admin_context, pool_attribute_two ) def test_delete_pool_attribute(self): pool_attribute = self.create_pool_attribute(fixture=0) self.storage.delete_pool_attribute(self.admin_context, pool_attribute['id']) self.assertRaisesRegex( exceptions.PoolAttributeNotFound, 'Could not find PoolAttribute', self.storage.get_pool_attribute, self.admin_context, pool_attribute['id'] ) def test_delete_oool_attribute_missing(self): uuid = '464e9250-4fe0-4267-9993-da639390bb04' self.assertRaisesRegex( exceptions.PoolAttributeNotFound, 'Could not find PoolAttribute', self.storage.delete_pool_attribute, self.admin_context, uuid ) def test_create_pool_attribute_duplicate(self): # Create the initial PoolAttribute self.create_pool_attribute(fixture=0) self.assertRaisesRegex( exceptions.DuplicatePoolAttribute, 'Duplicate PoolAttribute', self.create_pool_attribute, fixture=0 ) # PoolNameserver tests def test_create_pool_nameserver(self): pool = self.create_pool(fixture=0) values = { 'pool_id': pool.id, 'host': '192.0.2.1', 'port': 53 } result = self.storage.create_pool_nameserver( self.admin_context, pool.id, objects.PoolNameserver.from_dict(values)) self.assertIsNotNone(result['id']) self.assertIsNotNone(result['created_at']) self.assertIsNotNone(result['version']) self.assertIsNone(result['updated_at']) self.assertEqual(values['pool_id'], result['pool_id']) self.assertEqual(values['host'], result['host']) self.assertEqual(values['port'], result['port']) def test_create_pool_nameserver_duplicate(self): pool = self.create_pool(fixture=0) # Create the initial PoolNameserver self.create_pool_nameserver(pool, fixture=0) self.assertRaisesRegex( exceptions.DuplicatePoolNameserver, 'Duplicate PoolNameserver', self.create_pool_nameserver, pool, fixture=0 ) def test_find_pool_nameservers(self): pool = self.create_pool(fixture=0) # Verify that there are no pool_nameservers created actual = self.storage.find_pool_nameservers(self.admin_context) self.assertEqual(0, len(actual)) # Create a PoolNameserver pool_nameserver = self.create_pool_nameserver(pool, fixture=0) # Fetch the PoolNameservers and ensure only 1 exists actual = self.storage.find_pool_nameservers(self.admin_context) self.assertEqual(1, len(actual)) self.assertEqual(pool_nameserver['pool_id'], actual[0]['pool_id']) self.assertEqual(pool_nameserver['host'], actual[0]['host']) self.assertEqual(pool_nameserver['port'], actual[0]['port']) def test_find_pool_nameservers_paging(self): pool = self.create_pool(fixture=0) # Create 10 PoolNameservers created = [self.create_pool_nameserver(pool, host='192.0.2.%d' % i) for i in range(10)] # Ensure we can page through the results. self._ensure_paging(created, self.storage.find_pool_nameservers) def test_find_pool_nameservers_with_criterion(self): pool = self.create_pool(fixture=0) # Create two pool_nameservers pool_nameserver_one = self.create_pool_nameserver(pool, fixture=0) pool_nameserver_two = self.create_pool_nameserver(pool, fixture=1) # Verify pool_nameserver_one criterion = dict(host=pool_nameserver_one['host']) results = self.storage.find_pool_nameservers( self.admin_context, criterion) self.assertEqual(1, len(results)) self.assertEqual(pool_nameserver_one['host'], results[0]['host']) # Verify pool_nameserver_two criterion = dict(host=pool_nameserver_two['host']) results = self.storage.find_pool_nameservers(self.admin_context, criterion) self.assertEqual(1, len(results)) self.assertEqual(pool_nameserver_two['host'], results[0]['host']) def test_get_pool_nameserver(self): pool = self.create_pool(fixture=0) expected = self.create_pool_nameserver(pool, fixture=0) actual = self.storage.get_pool_nameserver( self.admin_context, expected['id']) self.assertEqual(expected['host'], actual['host']) def test_get_pool_nameserver_missing(self): uuid = '2c102ffd-7146-4b4e-ad62-b530ee0873fb' self.assertRaisesRegex( exceptions.PoolNameserverNotFound, 'Could not find PoolNameserver', self.storage.get_pool_nameserver, self.admin_context, uuid ) def test_find_pool_nameserver_criterion(self): pool = self.create_pool(fixture=0) # Create two pool_nameservers pool_nameserver_one = self.create_pool_nameserver(pool, fixture=0) pool_nameserver_two = self.create_pool_nameserver(pool, fixture=1) # Verify pool_nameserver_one criterion = dict(host=pool_nameserver_one['host']) result = self.storage.find_pool_nameserver( self.admin_context, criterion) self.assertEqual(pool_nameserver_one['host'], result['host']) # Verify pool_nameserver_two criterion = dict(host=pool_nameserver_two['host']) result = self.storage.find_pool_nameserver( self.admin_context, criterion) self.assertEqual(pool_nameserver_two['host'], result['host']) def test_find_pool_nameserver_criterion_missing(self): pool = self.create_pool(fixture=0) expected = self.create_pool_nameserver(pool, fixture=0) criterion = dict(host=expected['host'] + 'NOT FOUND') self.assertRaisesRegex( exceptions.PoolNameserverNotFound, 'Could not find PoolNameserver', self.storage.find_pool_nameserver, self.admin_context, criterion ) def test_update_pool_nameserver(self): pool = self.create_pool(fixture=0) pool_nameserver = self.create_pool_nameserver(pool, host='192.0.2.1') # Update the pool_nameserver pool_nameserver.host = '192.0.2.2' pool_nameserver = self.storage.update_pool_nameserver( self.admin_context, pool_nameserver) # Verify the new values self.assertEqual('192.0.2.2', pool_nameserver.host) # Ensure the version column was incremented self.assertEqual(2, pool_nameserver.version) def test_update_pool_nameserver_duplicate(self): pool = self.create_pool(fixture=0) # Create two pool_nameservers pool_nameserver_one = self.create_pool_nameserver( pool, fixture=0, host='192.0.2.1') pool_nameserver_two = self.create_pool_nameserver( pool, fixture=0, host='192.0.2.2') # Update the second one to be a duplicate of the first pool_nameserver_two.host = pool_nameserver_one.host self.assertRaisesRegex( exceptions.DuplicatePoolNameserver, 'Duplicate PoolNameserver', self.storage.update_pool_nameserver, self.admin_context, pool_nameserver_two ) def test_update_pool_nameserver_missing(self): pool_nameserver = objects.PoolNameserver( id='e8cee063-3a26-42d6-b181-bdbdc2c99d08' ) self.assertRaisesRegex( exceptions.PoolNameserverNotFound, 'Could not find PoolNameserver', self.storage.update_pool_nameserver, self.admin_context, pool_nameserver ) def test_delete_pool_nameserver(self): pool = self.create_pool(fixture=0) pool_nameserver = self.create_pool_nameserver(pool, fixture=0) self.storage.delete_pool_nameserver( self.admin_context, pool_nameserver['id']) self.assertRaisesRegex( exceptions.PoolNameserverNotFound, 'Could not find PoolNameserver', self.storage.get_pool_nameserver, self.admin_context, pool_nameserver['id'] ) def test_delete_pool_nameserver_missing(self): uuid = '97f57960-f41b-4e93-8e22-8fd6c7e2c183' self.assertRaisesRegex( exceptions.PoolNameserverNotFound, 'Could not find PoolNameserver', self.storage.delete_pool_nameserver, self.admin_context, uuid ) # PoolTarget tests def test_create_pool_target(self): pool = self.create_pool(fixture=0) values = { 'pool_id': pool.id, 'type': 'fake' } result = self.storage.create_pool_target( self.admin_context, pool.id, objects.PoolTarget.from_dict(values)) self.assertIsNotNone(result['id']) self.assertIsNotNone(result['created_at']) self.assertIsNotNone(result['version']) self.assertIsNone(result['updated_at']) self.assertEqual(values['pool_id'], result['pool_id']) self.assertEqual(values['type'], result['type']) def test_find_pool_targets(self): pool = self.create_pool(fixture=0) # Verify that there are no new pool_targets created actual = self.storage.find_pool_targets( self.admin_context, criterion={'pool_id': pool.id}) self.assertEqual(0, len(actual)) # Create a PoolTarget pool_target = self.create_pool_target(pool, fixture=0) # Fetch the PoolTargets and ensure only 2 exist actual = self.storage.find_pool_targets( self.admin_context, criterion={'pool_id': pool.id}) self.assertEqual(1, len(actual)) self.assertEqual(pool_target['pool_id'], actual[0]['pool_id']) self.assertEqual(pool_target['type'], actual[0]['type']) def test_find_pool_targets_paging(self): pool = self.create_pool(fixture=0) # Create 10 PoolTargets created = [self.create_pool_target(pool, description='Target %d' % i) for i in range(10)] # Ensure we can page through the results. self._ensure_paging(created, self.storage.find_pool_targets, criterion={'pool_id': pool.id}) def test_find_pool_targets_with_criterion(self): pool = self.create_pool(fixture=0) # Create two pool_targets pool_target_one = self.create_pool_target( pool, fixture=0, description='One') pool_target_two = self.create_pool_target( pool, fixture=1, description='Two') # Verify pool_target_one criterion = dict(description=pool_target_one['description']) results = self.storage.find_pool_targets( self.admin_context, criterion) self.assertEqual(1, len(results)) self.assertEqual( pool_target_one['description'], results[0]['description']) # Verify pool_target_two criterion = dict(description=pool_target_two['description']) results = self.storage.find_pool_targets(self.admin_context, criterion) self.assertEqual(1, len(results)) self.assertEqual( pool_target_two['description'], results[0]['description']) def test_get_pool_target(self): pool = self.create_pool(fixture=0) expected = self.create_pool_target(pool, fixture=0) actual = self.storage.get_pool_target( self.admin_context, expected['id']) self.assertEqual(expected['type'], actual['type']) def test_get_pool_target_missing(self): uuid = '2c102ffd-7146-4b4e-ad62-b530ee0873fb' self.assertRaisesRegex( exceptions.PoolTargetNotFound, 'Could not find PoolTarget', self.storage.get_pool_target, self.admin_context, uuid ) def test_find_pool_target_criterion(self): pool = self.create_pool(fixture=0) # Create two pool_targets pool_target_one = self.create_pool_target( pool, fixture=0, description='One') pool_target_two = self.create_pool_target( pool, fixture=1, description='Two') # Verify pool_target_one criterion = dict(description=pool_target_one['description']) result = self.storage.find_pool_target( self.admin_context, criterion) self.assertEqual(pool_target_one['description'], result['description']) # Verify pool_target_two criterion = dict(description=pool_target_two['description']) result = self.storage.find_pool_target( self.admin_context, criterion) self.assertEqual(pool_target_two['description'], result['description']) def test_find_pool_target_criterion_missing(self): pool = self.create_pool(fixture=0) expected = self.create_pool_target(pool, fixture=0) criterion = dict(description=expected['description'] + 'NOT FOUND') self.assertRaisesRegex( exceptions.PoolTargetNotFound, 'Could not find PoolTarget', self.storage.find_pool_target, self.admin_context, criterion ) def test_update_pool_target(self): pool = self.create_pool(fixture=0) pool_target = self.create_pool_target(pool, description='One') # Update the pool_target pool_target.description = 'Two' pool_target.masters = objects.PoolTargetMasterList( objects=[objects.PoolTargetMaster(host='127.0.0.1', port=80)] ) pool_target.options = objects.PoolTargetOptionList( objects=[objects.PoolTargetOption(key='foo', value='bar')] ) pool_target = self.storage.update_pool_target( self.admin_context, pool_target) # Verify the new values self.assertEqual('Two', pool_target.description) # Ensure the version column was incremented self.assertEqual(2, pool_target.version) def test_update_pool_target_missing(self): pool_target = objects.PoolTarget( id='e8cee063-3a26-42d6-b181-bdbdc2c99d08' ) self.assertRaisesRegex( exceptions.PoolTargetNotFound, 'Could not find PoolTarget', self.storage.update_pool_target, self.admin_context, pool_target ) def test_delete_pool_target(self): pool = self.create_pool(fixture=0) pool_target = self.create_pool_target(pool, fixture=0) self.storage.delete_pool_target( self.admin_context, pool_target['id']) self.assertRaisesRegex( exceptions.PoolTargetNotFound, 'Could not find PoolTarget', self.storage.get_pool_target, self.admin_context, pool_target['id'] ) def test_delete_pool_target_missing(self): uuid = '97f57960-f41b-4e93-8e22-8fd6c7e2c183' self.assertRaisesRegex( exceptions.PoolTargetNotFound, 'Could not find PoolTarget', self.storage.delete_pool_target, self.admin_context, uuid ) def test_create_pool_target_option(self): pool = self.create_pool(fixture=0) pool_target = self.create_pool_target(pool, fixture=0) target = self.storage.create_pool_target_option( self.admin_context, pool_target['id'], objects.PoolTargetOption(key='foo', value='bar') ) result = self.storage._find_pool_target_options( self.admin_context, {'id': target['id']} ) self.assertEqual(1, len(result)) def test_update_pool_target_option(self): pool = self.create_pool(fixture=0) pool_target = self.create_pool_target(pool, fixture=0) target = self.storage.create_pool_target_option( self.admin_context, pool_target['id'], objects.PoolTargetOption(key='foo', value='bar') ) target.value = 'baz' self.storage.update_pool_target_option(self.admin_context, target) result = self.storage._find_pool_target_options( self.admin_context, {'id': target['id']} ) self.assertEqual('baz', result[0].value) def test_delete_pool_target_option(self): pool = self.create_pool(fixture=0) pool_target = self.create_pool_target(pool, fixture=0) target = self.storage.create_pool_target_option( self.admin_context, pool_target['id'], objects.PoolTargetOption(key='foo', value='bar') ) self.storage.delete_pool_target_option( self.admin_context, target['id'] ) result = self.storage._find_pool_target_options( self.admin_context, {'id': target['id']} ) self.assertEqual(0, len(result)) def test_create_pool_target_master(self): pool = self.create_pool(fixture=0) pool_target = self.create_pool_target(pool, fixture=0) target = self.storage.create_pool_target_master( self.admin_context, pool_target['id'], objects.PoolTargetMaster(host='127.0.0.1', port=80) ) result = self.storage._find_pool_target_masters( self.admin_context, {'id': target['id']} ) self.assertEqual(1, len(result)) def test_update_pool_target_master(self): pool = self.create_pool(fixture=0) pool_target = self.create_pool_target(pool, fixture=0) target = self.storage.create_pool_target_master( self.admin_context, pool_target['id'], objects.PoolTargetMaster(host='127.0.0.1', port=80) ) target.port = 443 self.storage.update_pool_target_master(self.admin_context, target) result = self.storage._find_pool_target_masters( self.admin_context, {'id': target['id']} ) self.assertEqual(443, result[0].port) def test_delete_pool_target_master(self): pool = self.create_pool(fixture=0) pool_target = self.create_pool_target(pool, fixture=0) target = self.storage.create_pool_target_master( self.admin_context, pool_target['id'], objects.PoolTargetMaster(host='127.0.0.1', port=80) ) self.storage.delete_pool_target_master( self.admin_context, target['id'] ) result = self.storage._find_pool_target_masters( self.admin_context, {'id': target['id']} ) self.assertEqual(0, len(result)) def test_create_zone_attribute(self): zone = self.create_zone() zone_attribute = self.storage.create_zone_attribute( self.admin_context, zone['id'], objects.ZoneAttribute(key='foo', value='bar') ) result = self.storage.find_zone_attributes( self.admin_context, {'id': zone_attribute['id']} ) self.assertEqual(1, len(result)) def test_update_zone_attribute(self): zone = self.create_zone() zone_attribute = self.storage.create_zone_attribute( self.admin_context, zone['id'], objects.ZoneAttribute(key='foo', value='bar') ) zone_attribute.value = 'baz' self.storage.update_zone_attribute( self.admin_context, zone_attribute ) result = self.storage.get_zone_attributes( self.admin_context, zone_attribute['id'] ) self.assertEqual('baz', result.value) def test_delete_zone_attribute(self): zone = self.create_zone() zone_attribute = self.storage.create_zone_attribute( self.admin_context, zone['id'], objects.ZoneAttribute(key='foo', value='bar') ) self.storage.delete_zone_attribute( self.admin_context, zone_attribute['id'] ) result = self.storage.find_zone_attributes( self.admin_context, {'id': zone_attribute['id']} ) self.assertEqual(0, len(result)) def test_create_zone_master(self): zone = self.create_zone() zone_master = self.storage.create_zone_master( self.admin_context, zone['id'], objects.ZoneMaster(host='127.0.0.1', port='80') ) result = self.storage._find_zone_masters( self.admin_context, {'id': zone_master['id']} ) self.assertEqual(1, len(result)) def test_update_zone_master(self): zone = self.create_zone() zone_master = self.storage.create_zone_master( self.admin_context, zone['id'], objects.ZoneMaster(host='127.0.0.1', port='80') ) zone_master.port = 443 self.storage.update_zone_master( self.admin_context, zone_master ) result = self.storage._find_zone_masters( self.admin_context, {'id': zone_master['id']} ) self.assertEqual(443, result[0].port) def test_delete_zone_master(self): zone = self.create_zone() zone_master = self.storage.create_zone_master( self.admin_context, zone['id'], objects.ZoneMaster(host='127.0.0.1', port='80') ) self.storage.delete_zone_master( self.admin_context, zone_master['id'] ) result = self.storage._find_zone_masters( self.admin_context, {'id': zone_master['id']} ) self.assertEqual(0, len(result)) def test_create_zone_export(self): zone_export = self.storage.create_zone_export( self.admin_context, objects.ZoneExport(status='ACTIVE', task_type='EXPORT') ) result = self.storage.find_zone_exports( self.admin_context, {'id': zone_export['id']} ) self.assertEqual(1, len(result)) def test_find_zone_exports_with_no_criterion(self): self.storage.create_zone_export( self.admin_context, objects.ZoneExport(status='ACTIVE', task_type='EXPORT') ) result = self.storage._find_zone_exports( self.admin_context, None ) self.assertEqual(1, len(result)) def test_update_zone_export(self): zone_export = self.storage.create_zone_export( self.admin_context, objects.ZoneExport(status='ACTIVE', task_type='EXPORT') ) zone_export.message = 'foo' self.storage.update_zone_export( self.admin_context, zone_export ) result = self.storage.find_zone_export( self.admin_context, {'id': zone_export['id']} ) self.assertEqual('foo', result.message) def test_delete_zone_export(self): zone_export = self.storage.create_zone_export( self.admin_context, objects.ZoneExport(status='ACTIVE', task_type='EXPORT') ) self.storage.delete_zone_export( self.admin_context, zone_export['id'] ) result = self.storage.find_zone_exports( self.admin_context, {'id': zone_export['id']} ) self.assertEqual(0, len(result)) # PoolAlsoNotify tests def test_create_pool_also_notify(self): pool = self.create_pool(fixture=0) values = { 'pool_id': pool.id, 'host': '192.0.2.1', 'port': 53 } result = self.storage.create_pool_also_notify( self.admin_context, pool.id, objects.PoolAlsoNotify.from_dict(values)) self.assertIsNotNone(result['id']) self.assertIsNotNone(result['created_at']) self.assertIsNotNone(result['version']) self.assertIsNone(result['updated_at']) self.assertEqual(values['pool_id'], result['pool_id']) self.assertEqual(values['host'], result['host']) self.assertEqual(values['port'], result['port']) def test_create_pool_also_notify_duplicate(self): pool = self.create_pool(fixture=0) # Create the initial PoolAlsoNotify self.create_pool_also_notify(pool, fixture=0) self.assertRaisesRegex( exceptions.DuplicatePoolAlsoNotify, 'Duplicate PoolAlsoNotify', self.create_pool_also_notify, pool, fixture=0 ) def test_find_pool_also_notifies(self): pool = self.create_pool(fixture=0) # Verify that there are no pool_also_notifies created actual = self.storage.find_pool_also_notifies(self.admin_context) self.assertEqual(0, len(actual)) # Create a PoolAlsoNotify pool_also_notify = self.create_pool_also_notify(pool, fixture=0) # Fetch the PoolAlsoNotifies and ensure only 1 exists actual = self.storage.find_pool_also_notifies(self.admin_context) self.assertEqual(1, len(actual)) self.assertEqual(pool_also_notify['pool_id'], actual[0]['pool_id']) self.assertEqual(pool_also_notify['host'], actual[0]['host']) self.assertEqual(pool_also_notify['port'], actual[0]['port']) def test_find_pool_also_notifies_paging(self): pool = self.create_pool(fixture=0) # Create 10 PoolAlsoNotifies created = [self.create_pool_also_notify(pool, host='192.0.2.%d' % i) for i in range(10)] # Ensure we can page through the results. self._ensure_paging(created, self.storage.find_pool_also_notifies) def test_find_pool_also_notifies_with_criterion(self): pool = self.create_pool(fixture=0) # Create two pool_also_notifies pool_also_notify_one = self.create_pool_also_notify(pool, fixture=0) pool_also_notify_two = self.create_pool_also_notify(pool, fixture=1) # Verify pool_also_notify_one criterion = dict(host=pool_also_notify_one['host']) results = self.storage.find_pool_also_notifies( self.admin_context, criterion) self.assertEqual(1, len(results)) self.assertEqual(pool_also_notify_one['host'], results[0]['host']) # Verify pool_also_notify_two criterion = dict(host=pool_also_notify_two['host']) results = self.storage.find_pool_also_notifies(self.admin_context, criterion) self.assertEqual(1, len(results)) self.assertEqual(pool_also_notify_two['host'], results[0]['host']) def test_get_pool_also_notify(self): pool = self.create_pool(fixture=0) expected = self.create_pool_also_notify(pool, fixture=0) actual = self.storage.get_pool_also_notify( self.admin_context, expected['id']) self.assertEqual(expected['host'], actual['host']) def test_get_pool_also_notify_missing(self): uuid = '2c102ffd-7146-4b4e-ad62-b530ee0873fb' self.assertRaisesRegex( exceptions.PoolAlsoNotifyNotFound, 'Could not find PoolAlsoNotify', self.storage.get_pool_also_notify, self.admin_context, uuid ) def test_find_pool_also_notify_criterion(self): pool = self.create_pool(fixture=0) # Create two pool_also_notifies pool_also_notify_one = self.create_pool_also_notify(pool, fixture=0) pool_also_notify_two = self.create_pool_also_notify(pool, fixture=1) # Verify pool_also_notify_one criterion = dict(host=pool_also_notify_one['host']) result = self.storage.find_pool_also_notify( self.admin_context, criterion) self.assertEqual(pool_also_notify_one['host'], result['host']) # Verify pool_also_notify_two criterion = dict(host=pool_also_notify_two['host']) result = self.storage.find_pool_also_notify( self.admin_context, criterion) self.assertEqual(pool_also_notify_two['host'], result['host']) def test_find_pool_also_notify_criterion_missing(self): pool = self.create_pool(fixture=0) expected = self.create_pool_also_notify(pool, fixture=0) criterion = dict(host=expected['host'] + 'NOT FOUND') self.assertRaisesRegex( exceptions.PoolAlsoNotifyNotFound, 'Could not find PoolAlsoNotify', self.storage.find_pool_also_notify, self.admin_context, criterion ) def test_update_pool_also_notify(self): pool = self.create_pool(fixture=0) pool_also_notify = self.create_pool_also_notify(pool, host='192.0.2.1') # Update the pool_also_notify pool_also_notify.host = '192.0.2.2' pool_also_notify = self.storage.update_pool_also_notify( self.admin_context, pool_also_notify) # Verify the new values self.assertEqual('192.0.2.2', pool_also_notify.host) # Ensure the version column was incremented self.assertEqual(2, pool_also_notify.version) def test_update_pool_also_notify_duplicate(self): pool = self.create_pool(fixture=0) # Create two pool_also_notifies pool_also_notify_one = self.create_pool_also_notify( pool, fixture=0, host='192.0.2.1') pool_also_notify_two = self.create_pool_also_notify( pool, fixture=0, host='192.0.2.2') # Update the second one to be a duplicate of the first pool_also_notify_two.host = pool_also_notify_one.host self.assertRaisesRegex( exceptions.DuplicatePoolAlsoNotify, 'Duplicate PoolAlsoNotify', self.storage.update_pool_also_notify, self.admin_context, pool_also_notify_two ) def test_update_pool_also_notify_missing(self): pool_also_notify = objects.PoolAlsoNotify( id='e8cee063-3a26-42d6-b181-bdbdc2c99d08' ) self.assertRaisesRegex( exceptions.PoolAlsoNotifyNotFound, 'Could not find PoolAlsoNotify', self.storage.update_pool_also_notify, self.admin_context, pool_also_notify ) def test_delete_pool_also_notify(self): pool = self.create_pool(fixture=0) pool_also_notify = self.create_pool_also_notify(pool, fixture=0) self.storage.delete_pool_also_notify( self.admin_context, pool_also_notify['id']) self.assertRaisesRegex( exceptions.PoolAlsoNotifyNotFound, 'Could not find PoolAlsoNotify', self.storage.get_pool_also_notify, self.admin_context, pool_also_notify['id'] ) def test_delete_pool_also_notify_missing(self): uuid = '97f57960-f41b-4e93-8e22-8fd6c7e2c183' self.assertRaisesRegex( exceptions.PoolAlsoNotifyNotFound, 'Could not find PoolAlsoNotify', self.storage.delete_pool_also_notify, self.admin_context, uuid ) def test_create_service_status_duplicate(self): values = self.get_service_status_fixture(fixture=0) self.storage.create_service_status( self.admin_context, objects.ServiceStatus.from_dict(values)) self.assertRaisesRegex( exceptions.DuplicateServiceStatus, 'Duplicate ServiceStatus', self.storage.create_service_status, self.admin_context, objects.ServiceStatus.from_dict(values) ) # Zone Transfer Accept tests def test_create_zone_transfer_request(self): zone = self.create_zone() values = { 'tenant_id': self.admin_context.project_id, 'zone_id': zone.id, 'key': 'qwertyuiop' } result = self.storage.create_zone_transfer_request( self.admin_context, objects.ZoneTransferRequest.from_dict(values)) self.assertEqual(self.admin_context.project_id, result['tenant_id']) self.assertIn('status', result) def test_create_zone_transfer_request_scoped(self): zone = self.create_zone() tenant_2_context = self.get_context(project_id='2') tenant_3_context = self.get_context(project_id='3') values = { 'tenant_id': self.admin_context.project_id, 'zone_id': zone.id, 'key': 'qwertyuiop', 'target_tenant_id': tenant_2_context.project_id, } result = self.storage.create_zone_transfer_request( self.admin_context, objects.ZoneTransferRequest.from_dict(values)) self.assertIsNotNone(result['id']) self.assertIsNotNone(result['created_at']) self.assertIsNone(result['updated_at']) self.assertEqual(self.admin_context.project_id, result['tenant_id']) self.assertEqual( tenant_2_context.project_id, result['target_tenant_id'] ) self.assertIn('status', result) stored_ztr = self.storage.get_zone_transfer_request( tenant_2_context, result.id) self.assertEqual( self.admin_context.project_id, stored_ztr['tenant_id'] ) self.assertEqual(stored_ztr['id'], result['id']) self.assertRaisesRegex( exceptions.ZoneTransferRequestNotFound, 'Could not find ZoneTransferRequest', self.storage.get_zone_transfer_request, tenant_3_context, result.id ) def test_find_zone_transfer_requests(self): zone = self.create_zone() values = { 'tenant_id': self.admin_context.project_id, 'zone_id': zone.id, 'key': 'qwertyuiop' } self.storage.create_zone_transfer_request( self.admin_context, objects.ZoneTransferRequest.from_dict(values)) requests = self.storage.find_zone_transfer_requests( self.admin_context, {'tenant_id': self.admin_context.project_id}) self.assertEqual(1, len(requests)) def test_delete_zone_transfer_request(self): zone = self.create_zone() zt_request = self.create_zone_transfer_request(zone) self.storage.delete_zone_transfer_request( self.admin_context, zt_request.id) self.assertRaisesRegex( exceptions.ZoneTransferRequestNotFound, 'Could not find ZoneTransferRequest', self.storage.get_zone_transfer_request, self.admin_context, zt_request.id ) def test_update_zone_transfer_request(self): zone = self.create_zone() zt_request = self.create_zone_transfer_request(zone) zt_request.description = 'New description' result = self.storage.update_zone_transfer_request( self.admin_context, zt_request) self.assertEqual('New description', result.description) def test_get_zone_transfer_request(self): zone = self.create_zone() zt_request = self.create_zone_transfer_request(zone) result = self.storage.get_zone_transfer_request( self.admin_context, zt_request.id) self.assertEqual(zt_request.id, result.id) self.assertEqual(zt_request.zone_id, result.zone_id) def test_get_zone_transfer_request_no_project_id(self): context1 = self.get_context(project_id='1', roles=['member', 'reader']) context2 = self.get_context(roles=['member', 'reader']) zone = self.create_zone(context=context1) zt_request = self.create_zone_transfer_request(zone, context=context1) result = self.storage.get_zone_transfer_request(context2, zt_request.id) self.assertEqual(objects.ZoneTransferRequest(), result) def test_find_zone_transfer_requests_no_project_id(self): context1 = self.get_context(project_id='1', roles=['member', 'reader']) context2 = self.get_context(roles=['member', 'reader']) zone = self.create_zone(context=context1) zt_request = self.create_zone_transfer_request(zone, context=context1) result = self.storage.find_zone_transfer_requests(context2, zt_request.id) self.assertEqual(objects.ZoneTransferRequestList(), result) self.assertEqual(0, len(result)) # Zone Transfer Accept tests def test_create_zone_transfer_accept(self): zone = self.create_zone() zt_request = self.create_zone_transfer_request(zone) values = { 'tenant_id': self.admin_context.project_id, 'zone_transfer_request_id': zt_request.id, 'zone_id': zone.id, 'key': zt_request.key } result = self.storage.create_zone_transfer_accept( self.admin_context, objects.ZoneTransferAccept.from_dict(values)) self.assertIsNotNone(result['id']) self.assertIsNotNone(result['created_at']) self.assertIsNone(result['updated_at']) self.assertEqual(self.admin_context.project_id, result['tenant_id']) self.assertIn('status', result) def test_find_zone_transfer_accepts(self): zone = self.create_zone() zt_request = self.create_zone_transfer_request(zone) values = { 'tenant_id': self.admin_context.project_id, 'zone_transfer_request_id': zt_request.id, 'zone_id': zone.id, 'key': zt_request.key } self.storage.create_zone_transfer_accept( self.admin_context, objects.ZoneTransferAccept.from_dict(values)) accepts = self.storage.find_zone_transfer_accepts( self.admin_context, {'tenant_id': self.admin_context.project_id}) self.assertEqual(1, len(accepts)) def test_find_zone_transfer_accept(self): zone = self.create_zone() zt_request = self.create_zone_transfer_request(zone) values = { 'tenant_id': self.admin_context.project_id, 'zone_transfer_request_id': zt_request.id, 'zone_id': zone.id, 'key': zt_request.key } result = self.storage.create_zone_transfer_accept( self.admin_context, objects.ZoneTransferAccept.from_dict(values)) accept = self.storage.find_zone_transfer_accept( self.admin_context, {'id': result.id}) self.assertEqual(result.id, accept.id) def test_transfer_zone_ownership(self): tenant_1_context = self.get_context(project_id='1', roles=['member', 'reader']) tenant_2_context = self.get_context(project_id='2', roles=['member', 'reader']) admin_context = self.get_admin_context() admin_context.all_tenants = True zone = self.create_zone(context=tenant_1_context) recordset = self.create_recordset(zone, context=tenant_1_context) record = recordset.records[0] updated_zone = zone updated_zone.tenant_id = tenant_2_context.project_id self.storage.update_zone( admin_context, updated_zone) saved_zone = self.storage.get_zone( admin_context, zone.id) saved_recordset = self.storage.find_recordset( admin_context, criterion={'id': recordset.id}) saved_record = self.storage.get_record( admin_context, record.id) self.assertEqual(tenant_2_context.project_id, saved_zone.tenant_id) self.assertEqual( tenant_2_context.project_id, saved_recordset.tenant_id ) self.assertEqual(tenant_2_context.project_id, saved_record.tenant_id) def test_delete_zone_transfer_accept(self): zone = self.create_zone() zt_request = self.create_zone_transfer_request(zone) zt_accept = self.create_zone_transfer_accept(zt_request) self.storage.delete_zone_transfer_accept( self.admin_context, zt_accept.id) self.assertRaisesRegex( exceptions.ZoneTransferAcceptNotFound, 'Could not find ZoneTransferAccept', self.storage.get_zone_transfer_accept, self.admin_context, zt_accept.id ) def test_update_zone_transfer_accept(self): zone = self.create_zone() zt_request = self.create_zone_transfer_request(zone) zt_accept = self.create_zone_transfer_accept(zt_request) zt_accept.status = 'COMPLETE' result = self.storage.update_zone_transfer_accept( self.admin_context, zt_accept) self.assertEqual('COMPLETE', result.status) def test_get_zone_transfer_accept(self): zone = self.create_zone() zt_request = self.create_zone_transfer_request(zone) zt_accept = self.create_zone_transfer_accept(zt_request) result = self.storage.get_zone_transfer_accept( self.admin_context, zt_accept.id) self.assertEqual(zt_accept.id, result.id) self.assertEqual(zt_accept.zone_id, result.zone_id) def test_count_zone_tasks(self): # in the beginning, there should be nothing zones = self.storage.count_zone_tasks(self.admin_context) self.assertEqual(0, zones) values = { 'status': 'PENDING', 'task_type': 'IMPORT' } self.storage.create_zone_import( self.admin_context, objects.ZoneImport.from_dict(values)) # count imported zones zones = self.storage.count_zone_tasks(self.admin_context) # well, did we get 1? self.assertEqual(1, zones) @mock.patch('designate.storage.sql.get_read_session') def test_count_zone_tasks_none_result(self, mock_read_session): mock_sql_execute = mock.Mock() mock_sql_fetchone = mock.Mock() mock_read_session().__enter__.return_value = mock_sql_execute mock_sql_execute.execute.return_value = mock_sql_fetchone mock_sql_fetchone.fetchone.return_value = None zone_tasks = self.storage.count_zone_tasks(self.admin_context) mock_read_session.assert_called() self.assertEqual(0, zone_tasks) @mock.patch('designate.storage.sql.get_read_session') def test_count_zone_transfer_accept_none_result(self, mock_read_session): mock_sql_execute = mock.Mock() mock_sql_fetchone = mock.Mock() mock_read_session().__enter__.return_value = mock_sql_execute mock_sql_execute.execute.return_value = mock_sql_fetchone mock_sql_fetchone.fetchone.return_value = None zone_transfer_accepts = self.storage.count_zone_transfer_accept( self.admin_context ) mock_read_session.assert_called() self.assertEqual(0, zone_transfer_accepts) # Zone Import Tests def test_create_zone_import(self): values = { 'status': 'PENDING', 'task_type': 'IMPORT' } result = self.storage.create_zone_import( self.admin_context, objects.ZoneImport.from_dict(values)) self.assertIsNotNone(result['id']) self.assertIsNotNone(result['created_at']) self.assertIsNone(result['updated_at']) self.assertIsNotNone(result['version']) self.assertEqual(values['status'], result['status']) self.assertIsNone(result['zone_id']) self.assertIsNone(result['message']) def test_find_zone_imports(self): actual = self.storage.find_zone_imports(self.admin_context) self.assertEqual(0, len(actual)) # Create a single ZoneImport zone_import = self.create_zone_import(fixture=0) actual = self.storage.find_zone_imports(self.admin_context) self.assertEqual(1, len(actual)) self.assertEqual(zone_import['status'], actual[0]['status']) self.assertEqual(zone_import['message'], actual[0]['message']) self.assertEqual(zone_import['zone_id'], actual[0]['zone_id']) def test_find_zone_imports_paging(self): # Create 10 ZoneImports created = [self.create_zone_import() for i in range(10)] # Ensure we can page through the results. self._ensure_paging(created, self.storage.find_zone_imports) def test_find_zone_imports_with_criterion(self): zone_import_one = self.create_zone_import(fixture=0) zone_import_two = self.create_zone_import(fixture=1) criterion_one = dict(status=zone_import_one['status']) results = self.storage.find_zone_imports(self.admin_context, criterion_one) self.assertEqual(1, len(results)) self.assertEqual(zone_import_one['status'], results[0]['status']) criterion_two = dict(status=zone_import_two['status']) results = self.storage.find_zone_imports(self.admin_context, criterion_two) self.assertEqual(1, len(results)) self.assertEqual(zone_import_two['status'], results[0]['status']) def test_get_zone_import(self): # Create a zone_import expected = self.create_zone_import() actual = self.storage.get_zone_import(self.admin_context, expected['id']) self.assertEqual(expected['status'], actual['status']) def test_get_zone_import_missing(self): uuid = '4c8e7f82-3519-4bf7-8940-a66a4480f223' self.assertRaisesRegex( exceptions.ZoneImportNotFound, 'Could not find ZoneImport', self.storage.get_zone_import, self.admin_context, uuid ) def test_find_zone_import_criterion_missing(self): expected = self.create_zone_import() criterion = dict(status=expected['status'] + 'NOT FOUND') self.assertRaisesRegex( exceptions.ZoneImportNotFound, 'Could not find ZoneImport', self.storage.find_zone_import, self.admin_context, criterion ) def test_update_zone_import(self): # Create a zone_import zone_import = self.create_zone_import(status='PENDING', task_type='IMPORT') # Update the zone_import zone_import.status = 'COMPLETE' # Update storage zone_import = self.storage.update_zone_import(self.admin_context, zone_import) # Verify the new value self.assertEqual('COMPLETE', zone_import.status) # Ensure the version column was incremented self.assertEqual(2, zone_import.version) def test_update_zone_import_missing(self): zone_import = objects.ZoneImport( id='486f9cbe-b8b6-4d8c-8275-1a6e47b13e00' ) self.assertRaisesRegex( exceptions.ZoneImportNotFound, 'Could not find ZoneImport', self.storage.update_zone_import, self.admin_context, zone_import ) def test_delete_zone_import(self): # Create a zone_import zone_import = self.create_zone_import() # Delete the zone_import self.storage.delete_zone_import(self.admin_context, zone_import['id']) # Verify that it's deleted self.assertRaisesRegex( exceptions.ZoneImportNotFound, 'Could not find ZoneImport', self.storage.get_zone_import, self.admin_context, zone_import['id'] ) def test_delete_zone_import_missing(self): uuid = 'cac1fc02-79b2-4e62-a1a4-427b6790bbe6' self.assertRaisesRegex( exceptions.ZoneImportNotFound, 'Could not find ZoneImport', self.storage.delete_zone_import, self.admin_context, uuid ) def test_schema_table_names(self): table_names = [ 'blacklists', 'pool_also_notifies', 'pool_attributes', 'pool_nameservers', 'pool_ns_records', 'pool_target_masters', 'pool_target_options', 'pool_targets', 'pools', 'quotas', 'records', 'recordsets', 'service_statuses', 'shared_zones', 'tlds', 'tsigkeys', 'zone_attributes', 'zone_masters', 'zone_tasks', 'zone_transfer_accepts', 'zone_transfer_requests', 'zones' ] inspector = self.storage.get_inspector() actual_table_names = inspector.get_table_names() # We have transitioned database schema migration tools. # They use different tracking tables. Accomidate that one or both # may exist in this test. migration_table_found = False if ('migrate_version' in actual_table_names or 'alembic_version' in actual_table_names): migration_table_found = True self.assertTrue( migration_table_found, 'A DB migration table was not found.' ) try: actual_table_names.remove('migrate_version') except ValueError: pass try: actual_table_names.remove('alembic_version') except ValueError: pass self.assertEqual(table_names, actual_table_names) def test_schema_table_indexes(self): with sql.get_read_session() as session: indexes_t = session.execute( text(""SELECT * FROM sqlite_master WHERE type = 'index';"")) indexes = {} # table name -> index names -> cmd for _, index_name, table_name, num, cmd in indexes_t: if index_name.startswith(""sqlite_""): continue # ignore sqlite-specific indexes if table_name not in indexes: indexes[table_name] = {} indexes[table_name][index_name] = cmd expected = { ""records"": { ""record_created_at"": ""CREATE INDEX record_created_at ON records (created_at)"", # noqa ""records_tenant"": ""CREATE INDEX records_tenant ON records (tenant_id)"", # noqa ""update_status_index"": ""CREATE INDEX update_status_index ON records (status, zone_id, tenant_id, created_at, serial)"", # noqa }, ""recordsets"": { ""recordset_created_at"": ""CREATE INDEX recordset_created_at ON recordsets (created_at)"", # noqa ""recordset_type_name"": ""CREATE INDEX recordset_type_name ON recordsets (type, name)"", # noqa ""reverse_name_dom_id"": ""CREATE INDEX reverse_name_dom_id ON recordsets (reverse_name, zone_id)"", # noqa ""rrset_type_domainid"": ""CREATE INDEX rrset_type_domainid ON recordsets (type, zone_id)"", # noqa ""rrset_updated_at"": ""CREATE INDEX rrset_updated_at ON recordsets (updated_at)"", # noqa ""rrset_zoneid"": ""CREATE INDEX rrset_zoneid ON recordsets (zone_id)"", # noqa ""rrset_type"": ""CREATE INDEX rrset_type ON recordsets (type)"", # noqa ""rrset_ttl"": ""CREATE INDEX rrset_ttl ON recordsets (ttl)"", # noqa ""rrset_tenant_id"": ""CREATE INDEX rrset_tenant_id ON recordsets (tenant_id)"", # noqa }, ""zones"": { ""delayed_notify"": ""CREATE INDEX delayed_notify ON zones (delayed_notify)"", # noqa ""increment_serial"": ""CREATE INDEX increment_serial ON zones (increment_serial)"", # noqa ""reverse_name_deleted"": ""CREATE INDEX reverse_name_deleted ON zones (reverse_name, deleted)"", # noqa ""zone_created_at"": ""CREATE INDEX zone_created_at ON zones (created_at)"", # noqa ""zone_deleted"": ""CREATE INDEX zone_deleted ON zones (deleted)"", ""zone_tenant_deleted"": ""CREATE INDEX zone_tenant_deleted ON zones (tenant_id, deleted)"", # noqa } } self.assertDictEqual(expected, indexes) >>>>>>> CHANGE (011ebe Fix list zones if shared with multiple projects) ",,6377,0
openstack%2Fdesignate~887425,openstack/designate,master,I8af9b5cf8c1473bbf7db71a1fb848fb64509db84,Fix list zones if shared with multiple projects,MERGED,2023-06-30 18:53:42.000000000,2023-07-05 16:34:01.000000000,2023-07-05 16:32:53.000000000,"[{'_account_id': 11628}, {'_account_id': 22348}, {'_account_id': 22623}]","[{'number': 1, 'created': '2023-06-30 18:53:42.000000000', 'files': ['designate/storage/sqlalchemy/__init__.py', 'releasenotes/notes/Fix-zone-list-when-zone-shared-more-than-once-288b57cafeba82df.yaml', 'designate/tests/test_storage/test_storage.py'], 'web_link': 'https://opendev.org/openstack/designate/commit/011ebe2e7cd0df0c7f0869f0c7abbce79434821a', 'message': 'Fix list zones if shared with multiple projects\n\nThis patch fixes a bug when listing zones or updating recordsets in\nzones that are shared with more than one project.\n\nCloses-Bug: #2025295\nChange-Id: I8af9b5cf8c1473bbf7db71a1fb848fb64509db84\n'}]",1,887425,011ebe2e7cd0df0c7f0869f0c7abbce79434821a,8,3,1,11628,,,0,"Fix list zones if shared with multiple projects

This patch fixes a bug when listing zones or updating recordsets in
zones that are shared with more than one project.

Closes-Bug: #2025295
Change-Id: I8af9b5cf8c1473bbf7db71a1fb848fb64509db84
",git fetch https://review.opendev.org/openstack/designate refs/changes/25/887425/1 && git format-patch -1 --stdout FETCH_HEAD,"['designate/storage/sqlalchemy/__init__.py', 'releasenotes/notes/Fix-zone-list-when-zone-shared-more-than-once-288b57cafeba82df.yaml', 'designate/tests/test_storage/test_storage.py']",3,011ebe2e7cd0df0c7f0869f0c7abbce79434821a,," def test_find_zones_shared(self): # Create an admin context admin_context = self.get_admin_context() # Create a zone in the admin context zone = self.create_zone(context=admin_context) # Share the zone with two other projects self.share_zone( zone_id=zone['id'], target_project_id=1, context=admin_context) self.share_zone( zone_id=zone['id'], target_project_id=2, context=admin_context) # Ensure that one zone record is returned from find_zones (LP 2025295) results = self.storage.find_zones(admin_context) self.assertEqual(1, len(results)) ",,24,1
openstack%2Ftripleo-common~886179,openstack/tripleo-common,stable/wallaby,I04f6ac171b10af7a294819d6248eac641090cc49,Only modify the container manifest if the mediaType has changed.,MERGED,2023-06-15 13:46:01.000000000,2023-07-05 16:23:41.000000000,2023-07-05 16:22:36.000000000,"[{'_account_id': 8833}, {'_account_id': 9816}, {'_account_id': 22348}]","[{'number': 1, 'created': '2023-06-15 13:46:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-common/commit/b9b97350150c13eef3a2b13e01fa2f703be131d6', 'message': 'Only modify the container manifest if the mediaType has changed.\n\nOnly modify the manifest if the mediaType has actually changed.  This is a\npartial fix for https://bugzilla.redhat.com/show_bug.cgi?id=2213672 where the\njson pretty print with indent=3 causes the SHA256 of the manifest to change\nsince the manifest is not pretty printed the same way in the source registry.\n\nWhen the SHA256 changes, the above bug is triggered since the code does\nnot account for the fact that the httpd type-map file also needs to be\nupdated to use the changed SHA256.\n\nChange-Id: I04f6ac171b10af7a294819d6248eac641090cc49\nSigned-off-by: James Slagle <jslagle@redhat.com>\n'}, {'number': 2, 'created': '2023-06-15 13:46:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-common/commit/95dbdbe260dbab5ef0d9deeb48ce44e055343cef', 'message': 'Only modify the container manifest if the mediaType has changed.\n\nOnly modify the manifest if the mediaType has actually changed.  This is a\npartial fix for https://bugzilla.redhat.com/show_bug.cgi?id=2213672 where the\njson pretty print with indent=3 causes the SHA256 of the manifest to change\nsince the manifest is not pretty printed the same way in the source registry.\n\nWhen the SHA256 changes, the above bug is triggered since the code does\nnot account for the fact that the httpd type-map file also needs to be\nupdated to use the changed SHA256.\n\nThis will need to be backported to stable/train as well.\n\nChange-Id: I04f6ac171b10af7a294819d6248eac641090cc49\nSigned-off-by: James Slagle <jslagle@redhat.com>\n'}, {'number': 3, 'created': '2023-06-15 17:11:54.000000000', 'files': ['tripleo_common/image/image_uploader.py'], 'web_link': 'https://opendev.org/openstack/tripleo-common/commit/b0962d2ba09fbb4da33daa328e6a50cac5e3ba05', 'message': 'Only modify the container manifest if the mediaType has changed.\n\nOnly modify the manifest if the mediaType has actually changed.  This is a\npartial fix for https://bugzilla.redhat.com/show_bug.cgi?id=2213672 where the\njson pretty print with indent=3 causes the SHA256 of the manifest to change\nsince the manifest is not pretty printed the same way in the source registry.\n\nWhen the SHA256 changes, the above bug is triggered since the code does\nnot account for the fact that the httpd type-map file also needs to be\nupdated to use the changed SHA256.\n\nThis will need to be backported to stable/train as well.\n\nChange-Id: I04f6ac171b10af7a294819d6248eac641090cc49\nSigned-off-by: James Slagle <jslagle@redhat.com>\n'}]",1,886179,b0962d2ba09fbb4da33daa328e6a50cac5e3ba05,13,3,3,7144,,,0,"Only modify the container manifest if the mediaType has changed.

Only modify the manifest if the mediaType has actually changed.  This is a
partial fix for https://bugzilla.redhat.com/show_bug.cgi?id=2213672 where the
json pretty print with indent=3 causes the SHA256 of the manifest to change
since the manifest is not pretty printed the same way in the source registry.

When the SHA256 changes, the above bug is triggered since the code does
not account for the fact that the httpd type-map file also needs to be
updated to use the changed SHA256.

This will need to be backported to stable/train as well.

Change-Id: I04f6ac171b10af7a294819d6248eac641090cc49
Signed-off-by: James Slagle <jslagle@redhat.com>
",git fetch https://review.opendev.org/openstack/tripleo-common refs/changes/79/886179/1 && git format-patch -1 --stdout FETCH_HEAD,['tripleo_common/image/image_uploader.py'],1,b9b97350150c13eef3a2b13e01fa2f703be131d6,," new_manifest_type = manifest_type new_manifest_type = MEDIA_MANIFEST_V2 new_manifest_type = MEDIA_MANIFEST_V2 elif manifest_type == MEDIA_OCI_INDEX_V1: new_manifest_type = MEDIA_MANIFEST_V2_LIST # Only modify the manifest if the mediaType has actually changed. # This is a partial fix for # https://bugzilla.redhat.com/show_bug.cgi?id=2213672 # where the json pretty print with indent=3 causes the SHA256 of # the manifest to change since the manifest is not pretty printed # the same way in the source registry. if manifest_type != new_manifest_type: manifest['mediaType'] = manifest_type manifest_str = json.dumps(manifest, indent=3)"," manifest_type = MEDIA_MANIFEST_V2 manifest_type = MEDIA_MANIFEST_V2 elif manifest_type == MEDIA_OCI_INDEX_V1: manifest_type = MEDIA_MANIFEST_V2_LIST manifest['mediaType'] = manifest_type manifest_str = json.dumps(manifest, indent=3)",13,5
openstack%2Fnova-specs~887702,openstack/nova-specs,master,Ie3f89730128fdb8beca8bb02312d11516affcbbc,Remove sphinxcontrib.seqdiag,MERGED,2023-07-05 14:24:47.000000000,2023-07-05 15:57:32.000000000,2023-07-05 15:56:26.000000000,"[{'_account_id': 7166}, {'_account_id': 11604}, {'_account_id': 22348}]","[{'number': 1, 'created': '2023-07-05 14:24:47.000000000', 'files': ['doc/source/_media/stein/reshape-provider-tree.seqdiag', 'doc/source/_media/rocky/reshape-provider-tree.svg', 'doc/source/_media/stein/reshape-provider-tree.svg', 'doc/source/_media/train/nova-cyborg-interaction.svg', 'specs/rocky/approved/reshape-provider-tree.rst', 'doc/source/conf.py', 'specs/train/approved/nova-cyborg-interaction.rst', 'doc/source/_media/rocky/reshape-provider-tree.seqdiag', 'doc/source/_media/ussuri/nova-cyborg-interaction.seqdiag', 'doc/source/_media/ussuri/nova-cyborg-interaction.svg', 'specs/stein/approved/reshape-provider-tree.rst', 'doc/source/_media/train/nova-cyborg-interaction.seqdiag', 'doc/requirements.txt', 'specs/ussuri/implemented/nova-cyborg-interaction.rst'], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/00347ca9b7ea4e52b1833340c08869b72eedbb61', 'message': 'Remove sphinxcontrib.seqdiag\n\nThis was a great tool but it seems it is no longer maintained, with no\ncommits since late 2021 [1]. Remove it, capturing static copies of the\nSVGs it was generating so we don\'t lose information. The original\n""source"" is retained in case we ever want to revive our use of the tool\nbut that seems unlikely at this point.\n\n[1] https://github.com/blockdiag/blockdiag\n\nChange-Id: Ie3f89730128fdb8beca8bb02312d11516affcbbc\nSigned-off-by: Stephen Finucane <stephenfin@redhat.com>\n'}]",0,887702,00347ca9b7ea4e52b1833340c08869b72eedbb61,8,3,1,15334,,,0,"Remove sphinxcontrib.seqdiag

This was a great tool but it seems it is no longer maintained, with no
commits since late 2021 [1]. Remove it, capturing static copies of the
SVGs it was generating so we don't lose information. The original
""source"" is retained in case we ever want to revive our use of the tool
but that seems unlikely at this point.

[1] https://github.com/blockdiag/blockdiag

Change-Id: Ie3f89730128fdb8beca8bb02312d11516affcbbc
Signed-off-by: Stephen Finucane <stephenfin@redhat.com>
",git fetch https://review.opendev.org/openstack/nova-specs refs/changes/02/887702/1 && git format-patch -1 --stdout FETCH_HEAD,"['doc/source/_media/stein/reshape-provider-tree.seqdiag', 'doc/source/_media/rocky/reshape-provider-tree.svg', 'doc/source/_media/stein/reshape-provider-tree.svg', 'doc/source/_media/train/nova-cyborg-interaction.svg', 'specs/rocky/approved/reshape-provider-tree.rst', 'doc/source/conf.py', 'specs/train/approved/nova-cyborg-interaction.rst', 'doc/source/_media/rocky/reshape-provider-tree.seqdiag', 'doc/source/_media/ussuri/nova-cyborg-interaction.seqdiag', 'doc/source/_media/ussuri/nova-cyborg-interaction.svg', 'specs/stein/approved/reshape-provider-tree.rst', 'doc/source/_media/train/nova-cyborg-interaction.seqdiag', 'doc/requirements.txt', 'specs/ussuri/implemented/nova-cyborg-interaction.rst']",14,00347ca9b7ea4e52b1833340c08869b72eedbb61,remove-seqdiag,.. image:: /_media/ussuri/nova-cyborg-interaction.svg,".. seqdiag:: seqdiag { edge_length = 200; span_height = 15; activation = none; default_note_color = white; 'Nova Controller'; 'Placement'; 'Cyborg'; 'Nova Compute'; 'Nova Controller' -> 'Cyborg' [label = ""GET /v2/device_profiles?name=mydp""]; 'Nova Controller' <- 'Cyborg' [label = '{""device_profiles"": $device_profile}']; 'Nova Controller' -> 'Nova Controller' [label= 'Merge request groups into request_spec']; 'Nova Controller' -> 'Placement' [label= 'Get /allocation_candidates']; 'Nova Controller' <- 'Placement' [label= 'allocation candidates with nested RPs']; 'Nova Controller' -> 'Nova Controller' [label= 'Select a candidate']; 'Nova Controller' -> 'Nova Compute' [label= 'build_and_run_instances()']; 'Nova Compute' -> 'Cyborg' [label= 'POST /v2/accelerator_requests']; 'Nova Compute' <- 'Cyborg' [label= '{""arqs"": [$arq, ...]']; 'Nova Compute' -> 'Cyborg' [label= 'PATCH /v2/accelerator_requests']; 'Nova Compute' <- 'Cyborg' [label= '{""arqs"": [$arq, ...]']; 'Cyborg' -> 'Nova Controller' [label= 'POST /os-server-external-events']; 'Nova Compute' -> 'Nova Compute' [label= 'Wait for notification from Cyborg']; 'Nova Compute' -> 'Cyborg' [label= 'GET /v2/accelerator_requests? instance=$uuid&bind_state=resolved']; 'Nova Compute' <- 'Cyborg' [label= '{""arqs"": [$arq, ....]}']; } ",538,172
openstack%2Fmistral~887119,openstack/mistral,master,I415bb3fbefa91da0e7aaca9fe5d3714989ffda69,Fix test not waiting for action to be created,MERGED,2023-06-27 21:30:52.000000000,2023-07-05 15:40:50.000000000,2023-07-05 15:39:49.000000000,"[{'_account_id': 8731}, {'_account_id': 11583}, {'_account_id': 15895}, {'_account_id': 19134}, {'_account_id': 21970}, {'_account_id': 22348}, {'_account_id': 29124}, {'_account_id': 35600}]","[{'number': 1, 'created': '2023-06-27 21:30:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/mistral/commit/b20213fdb35bf08cabd04fada1fd4a67e1a2fca0', 'message': 'Fix test not waiting for action to be created\n\nSigned-off-by: Oleg Ovcharuk <vgvoleg@gmail.com>\nChange-Id: I415bb3fbefa91da0e7aaca9fe5d3714989ffda69\n'}, {'number': 2, 'created': '2023-06-27 23:50:28.000000000', 'files': ['mistral/tests/unit/engine/base.py', 'mistral/tests/unit/engine/test_task_cancel.py'], 'web_link': 'https://opendev.org/openstack/mistral/commit/5cb9cb74e535bec21bda766fd6d34098a5b1e496', 'message': 'Fix test not waiting for action to be created\n\nChange-Id: I415bb3fbefa91da0e7aaca9fe5d3714989ffda69\nSigned-off-by: Oleg Ovcharuk <vgvoleg@gmail.com>\n'}]",4,887119,5cb9cb74e535bec21bda766fd6d34098a5b1e496,17,8,2,29124,,,0,"Fix test not waiting for action to be created

Change-Id: I415bb3fbefa91da0e7aaca9fe5d3714989ffda69
Signed-off-by: Oleg Ovcharuk <vgvoleg@gmail.com>
",git fetch https://review.opendev.org/openstack/mistral refs/changes/19/887119/1 && git format-patch -1 --stdout FETCH_HEAD,"['mistral/tests/unit/engine/base.py', 'mistral/tests/unit/engine/test_task_cancel.py']",2,b20213fdb35bf08cabd04fada1fd4a67e1a2fca0,fix/tests_stabilization, self.await_task_creates_action(task_1_ex.id),,14,0
openstack%2Ftripleo-upgrade~887721,openstack/tripleo-upgrade,stable/wallaby,Ia3051418f4cddcf5bfc7692d1b46c3eabc6a5442,[collect log] Fix wrong permission when collecting vm information.,ABANDONED,2023-07-05 15:28:59.000000000,2023-07-05 15:33:13.000000000,,[],"[{'number': 1, 'created': '2023-07-05 15:28:59.000000000', 'files': ['templates/collect_logs.yaml.j2'], 'web_link': 'https://opendev.org/openstack/tripleo-upgrade/commit/4ac4d2fd0841228746811d39bf4b293d4cee97dd', 'message': ""[collect log] Fix wrong permission when collecting vm information.\n\nWe must become root to be able to write in `/var/log/extra`.\n\n'/etc/openstack/clouds.yaml' is correctly populated in upstream and\ndownstream jobs meaning that we can use the `openstack --os-cloud`\ncommand with the root user.\n\nChange-Id: Ia3051418f4cddcf5bfc7692d1b46c3eabc6a5442\n""}]",0,887721,4ac4d2fd0841228746811d39bf4b293d4cee97dd,2,0,1,8297,,,0,"[collect log] Fix wrong permission when collecting vm information.

We must become root to be able to write in `/var/log/extra`.

'/etc/openstack/clouds.yaml' is correctly populated in upstream and
downstream jobs meaning that we can use the `openstack --os-cloud`
command with the root user.

Change-Id: Ia3051418f4cddcf5bfc7692d1b46c3eabc6a5442
",git fetch https://review.opendev.org/openstack/tripleo-upgrade refs/changes/21/887721/1 && git format-patch -1 --stdout FETCH_HEAD,['templates/collect_logs.yaml.j2'],1,4ac4d2fd0841228746811d39bf4b293d4cee97dd,, openstack --os-cloud {{ overcloud_stack_name }} server show $i -f shell > /var/log/extra/oc-server-$i-{% raw %}{{ current_stage }}{% endraw %}.txt;, openstack --os-cloud {{ overcloud_stack_name }} server show $i > /var/log/extra/oc-server-$i-{% raw %}{{ current_stage }}{% endraw %}.txt;,1,1
openstack%2Fcinder~862491,openstack/cinder,master,I9ee8bb76e5b97b0493fc4647d2655ec74765097e,Tatlin Unified driver - simplify code,NEW,2022-10-24 12:32:07.000000000,2023-07-05 15:00:07.000000000,,"[{'_account_id': 9236}, {'_account_id': 22348}, {'_account_id': 27615}, {'_account_id': 30615}, {'_account_id': 32029}, {'_account_id': 32238}, {'_account_id': 32761}]","[{'number': 1, 'created': '2022-10-24 12:32:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/ff372ff10660a9bac041ad0ad01895d3fa1056e6', 'message': 'Tatlin Unified driver - simplify code\n\nImplements: blueprint yadro-tatlin-unified-refactoring\nChange-Id: I9ee8bb76e5b97b0493fc4647d2655ec74765097e\n'}, {'number': 2, 'created': '2023-01-31 12:23:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/2a55ff4e8c5b91a5098c1be7a8b8b96b989e6083', 'message': 'Tatlin Unified driver - simplify code\n\nImplements: blueprint yadro-tatlin-unified-refactoring\nChange-Id: I9ee8bb76e5b97b0493fc4647d2655ec74765097e\n'}, {'number': 3, 'created': '2023-02-15 15:21:12.000000000', 'files': ['cinder/volume/drivers/yadro/tatlin_common.py', 'cinder/tests/unit/volume/drivers/yadro/test_tatlin_client.py', 'cinder/volume/drivers/yadro/tatlin_client.py'], 'web_link': 'https://opendev.org/openstack/cinder/commit/90478c726e3a476e69031b79a58ec63b94da5634', 'message': 'Tatlin Unified driver - simplify code\n\nImplements: blueprint yadro-tatlin-unified-refactoring\nChange-Id: I9ee8bb76e5b97b0493fc4647d2655ec74765097e\n'}]",4,862491,90478c726e3a476e69031b79a58ec63b94da5634,83,7,3,13671,,,0,"Tatlin Unified driver - simplify code

Implements: blueprint yadro-tatlin-unified-refactoring
Change-Id: I9ee8bb76e5b97b0493fc4647d2655ec74765097e
",git fetch https://review.opendev.org/openstack/cinder refs/changes/91/862491/1 && git format-patch -1 --stdout FETCH_HEAD,"['cinder/volume/drivers/yadro/tatlin_common.py', 'cinder/tests/unit/volume/drivers/yadro/test_tatlin_client.py', 'cinder/volume/drivers/yadro/tatlin_client.py']",3,ff372ff10660a9bac041ad0ad01895d3fa1056e6,tatlin-unified-simplify," raise exception.VolumeBackendAPIException(message=message) if not ports: result = [p['port'] for p in ports] LOG.debug('Volume %s port list %s', volume_id, result) return result"," if not self.is_volume_exists(vol_id): message = _('Unable to get volume info %s' % vol_id) LOG.error(message) return {} return {} if ports == {}: res = [] for p in ports: res.append(p['port']) LOG.debug('Volume %s port list %s', volume_id, res) return res",60,38
openstack%2Frequirements~887607,openstack/requirements,master,Ic5c748d60e902b55a4af9587c951a4520f5977db,Upgrade XStatic-jQuery to 2.2.4.1 for Horizon,ABANDONED,2023-07-04 14:02:45.000000000,2023-07-05 14:51:55.000000000,,"[{'_account_id': 6914}, {'_account_id': 22348}]","[{'number': 1, 'created': '2023-07-04 14:02:45.000000000', 'files': ['global-requirements.txt', 'upper-constraints.txt'], 'web_link': 'https://opendev.org/openstack/requirements/commit/82b4da69cd80c7053d3662f488dcbd733283a444', 'message': ""Upgrade XStatic-jQuery to 2.2.4.1 for Horizon\n\nSince we upgraded XStatic-JQuery-Migrate to 3.3.2.1 in patch\nhttps://review.opendev.org/c/openstack/requirements/+/883402 we now\nneed newer jquery, because that version of jquery-migrate won't\nwork with jquery 1.2.\n\nChange-Id: Ic5c748d60e902b55a4af9587c951a4520f5977db\n""}]",0,887607,82b4da69cd80c7053d3662f488dcbd733283a444,4,2,1,8648,,,0,"Upgrade XStatic-jQuery to 2.2.4.1 for Horizon

Since we upgraded XStatic-JQuery-Migrate to 3.3.2.1 in patch
https://review.opendev.org/c/openstack/requirements/+/883402 we now
need newer jquery, because that version of jquery-migrate won't
work with jquery 1.2.

Change-Id: Ic5c748d60e902b55a4af9587c951a4520f5977db
",git fetch https://review.opendev.org/openstack/requirements refs/changes/07/887607/1 && git format-patch -1 --stdout FETCH_HEAD,"['global-requirements.txt', 'upper-constraints.txt']",2,82b4da69cd80c7053d3662f488dcbd733283a444,,XStatic-jQuery===2.2.4.1,XStatic-jQuery===1.12.4.1,2,2
openstack%2Fcharm-ceph-dashboard~887654,openstack/charm-ceph-dashboard,stable/quincy.2,Iec2f200963c3ed1e4d9bff86d62b49ddc91d0578,Adds skip logic to non-leader units,MERGED,2023-07-05 07:50:29.000000000,2023-07-05 14:45:20.000000000,2023-07-05 14:45:20.000000000,"[{'_account_id': 20648}, {'_account_id': 22348}, {'_account_id': 33717}, {'_account_id': 34952}]","[{'number': 1, 'created': '2023-07-05 07:50:29.000000000', 'files': ['tests/bundles/kinetic-zed.yaml', 'tests/bundles/lunar-antelope.yaml', 'tests/bundles/focal-yoga.yaml', 'tests/bundles/focal.yaml', 'tests/bundles/jammy-antelope.yaml', 'src/charm.py', 'tests/bundles/jammy-yoga.yaml', 'tests/bundles/jammy-zed.yaml'], 'web_link': 'https://opendev.org/openstack/charm-ceph-dashboard/commit/28a0ce89e81d803e832144d711b518f245c76fa3', 'message': 'Adds skip logic to non-leader units\n\nNon leader units will skip the event handling if Ceph dashboard\nis not enabled by the leader yet.\n\nSome test bundle fixes.\n\nPartial-Bug: #1952282\ncherry-pick from I743e50663ee85c91af4962d7d100e2fd48efa48c\n\nChange-Id: Iec2f200963c3ed1e4d9bff86d62b49ddc91d0578\n'}]",1,887654,28a0ce89e81d803e832144d711b518f245c76fa3,8,4,1,15382,,,0,"Adds skip logic to non-leader units

Non leader units will skip the event handling if Ceph dashboard
is not enabled by the leader yet.

Some test bundle fixes.

Partial-Bug: #1952282
cherry-pick from I743e50663ee85c91af4962d7d100e2fd48efa48c

Change-Id: Iec2f200963c3ed1e4d9bff86d62b49ddc91d0578
",git fetch https://review.opendev.org/openstack/charm-ceph-dashboard refs/changes/54/887654/1 && git format-patch -1 --stdout FETCH_HEAD,"['tests/bundles/kinetic-zed.yaml', 'tests/bundles/lunar-antelope.yaml', 'tests/bundles/focal-yoga.yaml', 'tests/bundles/focal.yaml', 'tests/bundles/jammy-antelope.yaml', 'src/charm.py', 'tests/bundles/jammy-yoga.yaml', 'tests/bundles/jammy-zed.yaml']",8,28a0ce89e81d803e832144d711b518f245c76fa3,," osd-devices: 'cinder,10G,2' channel: 8.0/edge"," osd-devices: 'cinder,10G' channel: latest/edge",27,22
openstack%2Fcharm-vault~887701,openstack/charm-vault,master,Ide581e82f53710d1d9f1e6e4a5232260a7ccabed,Add support for lunar,ABANDONED,2023-07-05 14:14:36.000000000,2023-07-05 14:15:30.000000000,,[],"[{'number': 1, 'created': '2023-07-05 14:14:36.000000000', 'files': ['osci.yaml', 'src/tests/bundles/lunar-mysql8.yaml', 'src/wheelhouse.txt', 'src/tests/bundles/lunar-raft.yaml', 'src/tests/tests.yaml', 'src/tests/bundles/lunar-raft-cluster.yaml'], 'web_link': 'https://opendev.org/openstack/charm-vault/commit/c36555576d12cc4ce49cc32cc13e3b189bb722a6', 'message': 'Add support for lunar\n\nAs lunar introduces python3.11, psycopg2 version needs to be at least\nversion 2.9.5 to support it.\nModify the tests to run on Lunar and remove the Kinetic ones.\n\nCloses-Bug: #2025983\n\nChange-Id: Ide581e82f53710d1d9f1e6e4a5232260a7ccabed\nSigned-off-by: David Negreira <david.negreira@canonical.com>\n'}]",0,887701,c36555576d12cc4ce49cc32cc13e3b189bb722a6,2,0,1,32371,,,0,"Add support for lunar

As lunar introduces python3.11, psycopg2 version needs to be at least
version 2.9.5 to support it.
Modify the tests to run on Lunar and remove the Kinetic ones.

Closes-Bug: #2025983

Change-Id: Ide581e82f53710d1d9f1e6e4a5232260a7ccabed
Signed-off-by: David Negreira <david.negreira@canonical.com>
",git fetch https://review.opendev.org/openstack/charm-vault refs/changes/01/887701/1 && git format-patch -1 --stdout FETCH_HEAD,"['osci.yaml', 'src/tests/bundles/lunar-mysql8.yaml', 'src/wheelhouse.txt', 'src/tests/bundles/lunar-raft.yaml', 'src/tests/tests.yaml', 'src/tests/bundles/lunar-raft-cluster.yaml']",6,c36555576d12cc4ce49cc32cc13e3b189bb722a6,lp2025983,series: lunar,series: kinetic,21,19
openstack%2Fcharm-vault~887700,openstack/charm-vault,master,I57047d140cf1bc0e9c503db1c82fe46d05bb9a0b,Add support for lunar,ABANDONED,2023-07-05 14:11:55.000000000,2023-07-05 14:12:20.000000000,,[],"[{'number': 1, 'created': '2023-07-05 14:11:55.000000000', 'files': ['osci.yaml', 'src/tests/bundles/lunar-mysql8.yaml', 'src/wheelhouse.txt', 'src/tests/bundles/lunar-raft.yaml', 'src/tests/tests.yaml', 'src/tests/bundles/lunar-raft-cluster.yaml'], 'web_link': 'https://opendev.org/openstack/charm-vault/commit/09b5ea787c0ba0c950c0508c8f90d4d0bce58542', 'message': 'Add support for lunar\n\nAs lunar introduces python3.11, psycopg2 version needs to be at least\nversion 2.9.5 to support it.\nModify the tests to run on Lunar and remove the Kinetic ones.\n\nCloses-Bug: #2025983\n\nChange-Id: I57047d140cf1bc0e9c503db1c82fe46d05bb9a0b\nSigned-off-by: David Negreira <david.negreira@canonical.com>\n'}]",0,887700,09b5ea787c0ba0c950c0508c8f90d4d0bce58542,2,0,1,32371,,,0,"Add support for lunar

As lunar introduces python3.11, psycopg2 version needs to be at least
version 2.9.5 to support it.
Modify the tests to run on Lunar and remove the Kinetic ones.

Closes-Bug: #2025983

Change-Id: I57047d140cf1bc0e9c503db1c82fe46d05bb9a0b
Signed-off-by: David Negreira <david.negreira@canonical.com>
",git fetch https://review.opendev.org/openstack/charm-vault refs/changes/00/887700/1 && git format-patch -1 --stdout FETCH_HEAD,"['osci.yaml', 'src/tests/bundles/lunar-mysql8.yaml', 'src/wheelhouse.txt', 'src/tests/bundles/lunar-raft.yaml', 'src/tests/tests.yaml', 'src/tests/bundles/lunar-raft-cluster.yaml']",6,09b5ea787c0ba0c950c0508c8f90d4d0bce58542,,series: lunar,series: kinetic,21,19
openstack%2Fbifrost~887656,openstack/bifrost,stable/yoga,I208182e65884d63548d78c68f676b899c562a2dc,CI: Update cached cirros image to 0.5.3,MERGED,2023-07-05 08:07:24.000000000,2023-07-05 14:05:40.000000000,2023-07-05 14:04:43.000000000,"[{'_account_id': 22348}, {'_account_id': 23851}]","[{'number': 1, 'created': '2023-07-05 08:07:24.000000000', 'files': ['playbooks/test-bifrost.yaml'], 'web_link': 'https://opendev.org/openstack/bifrost/commit/835bd27861ed22fd011ae8a933897432f202c919', 'message': ""CI: Update cached cirros image to 0.5.3\n\nBifrost CI is currently failing to fetch the cirros image from cache:\n\n    No such file or directory: '/opt/cache/files/cirros-0.5.1-x86_64-disk.img'\n\nThis may be caused by the removal of cirros-0.5.1 images from cache in\nchange Ibada405e0c1183559f428c749d0e54d0a45a2223.\n\nSwitch to cirros version 0.5.3 image instead.\n\nChange-Id: I208182e65884d63548d78c68f676b899c562a2dc\n""}]",1,887656,835bd27861ed22fd011ae8a933897432f202c919,11,2,1,10239,,,0,"CI: Update cached cirros image to 0.5.3

Bifrost CI is currently failing to fetch the cirros image from cache:

    No such file or directory: '/opt/cache/files/cirros-0.5.1-x86_64-disk.img'

This may be caused by the removal of cirros-0.5.1 images from cache in
change Ibada405e0c1183559f428c749d0e54d0a45a2223.

Switch to cirros version 0.5.3 image instead.

Change-Id: I208182e65884d63548d78c68f676b899c562a2dc
",git fetch https://review.opendev.org/openstack/bifrost refs/changes/56/887656/1 && git format-patch -1 --stdout FETCH_HEAD,['playbooks/test-bifrost.yaml'],1,835bd27861ed22fd011ae8a933897432f202c919,, cirros_deploy_image_upstream_url: file:///opt/cache/files/cirros-0.5.3-x86_64-disk.img, cirros_deploy_image_upstream_url: file:///opt/cache/files/cirros-0.5.1-x86_64-disk.img,1,1
openstack%2Fcharm-vault~887698,openstack/charm-vault,master,I3185f26e243bf02e8a0dcdd8ad5c7abd1a5729a1,Add support for lunar,ABANDONED,2023-07-05 14:04:14.000000000,2023-07-05 14:04:55.000000000,,[],"[{'number': 1, 'created': '2023-07-05 14:04:14.000000000', 'files': ['osci.yaml', 'src/tests/bundles/kinetic-raft-cluster.yaml', 'src/wheelhouse.txt', 'src/tests/bundles/kinetic-mysql8.yaml', 'src/tests/tests.yaml', 'src/tests/bundles/kinetic-raft.yaml'], 'web_link': 'https://opendev.org/openstack/charm-vault/commit/cedf9e84017764ff366d929a629ad13622ed08d1', 'message': 'Add support for lunar\n\nAs lunar introduces python3.11, psycopg2 version needs to be at least\nversion 2.9.5 to support it.\nModify the tests to run on Lunar and remove the Kinetic ones.\n\nCloses-Bug: #2025983\n\nChange-Id: I3185f26e243bf02e8a0dcdd8ad5c7abd1a5729a1\nSigned-off-by: David Negreira <david.negreira@canonical.com>\n'}]",0,887698,cedf9e84017764ff366d929a629ad13622ed08d1,2,0,1,32371,,,0,"Add support for lunar

As lunar introduces python3.11, psycopg2 version needs to be at least
version 2.9.5 to support it.
Modify the tests to run on Lunar and remove the Kinetic ones.

Closes-Bug: #2025983

Change-Id: I3185f26e243bf02e8a0dcdd8ad5c7abd1a5729a1
Signed-off-by: David Negreira <david.negreira@canonical.com>
",git fetch https://review.opendev.org/openstack/charm-vault refs/changes/98/887698/1 && git format-patch -1 --stdout FETCH_HEAD,"['osci.yaml', 'src/tests/bundles/kinetic-raft-cluster.yaml', 'src/wheelhouse.txt', 'src/tests/bundles/kinetic-mysql8.yaml', 'src/tests/tests.yaml', 'src/tests/bundles/kinetic-raft.yaml']",6,cedf9e84017764ff366d929a629ad13622ed08d1,lp2025983,,"variables: openstack-origin: &openstack-origin distro local_overlay_enabled: False series: kinetic comment: - 'machines section to decide order of deployment. database sooner = faster' machines: '0': constraints: mem=3072M '1': constraints: mem=3072M '2': constraints: mem=3072M '3': '4': '5': '6': '7': '8': '9': '10': applications: keystone-mysql-router: charm: ch:mysql-router channel: latest/edge mysql-innodb-cluster: charm: ch:mysql-innodb-cluster num_units: 3 options: source: *openstack-origin to: - '0' - '1' - '2' channel: latest/edge vault: num_units: 1 charm: ../../../vault.charm to: - '3' keystone: charm: ch:keystone num_units: 1 options: admin-password: openstack openstack-origin: *openstack-origin to: - '4' channel: latest/edge ceph-mon: charm: ch:ceph-mon num_units: 3 options: source: *openstack-origin to: - '5' - '6' - '7' channel: latest/edge ceph-osd: charm: ch:ceph-osd num_units: 3 options: osd-encrypt: true osd-encrypt-keymanager: vault source: *openstack-origin storage: osd-devices: 10G,2 to: - '8' - '9' - '10' channel: latest/edge relations: - - 'keystone:shared-db' - 'keystone-mysql-router:shared-db' - - 'keystone-mysql-router:db-router' - 'mysql-innodb-cluster:db-router' - - 'vault:certificates' - 'keystone:certificates' - - 'vault:secrets' - 'ceph-osd:secrets-storage' - - 'ceph-mon:osd' - 'ceph-osd:mon' ",18,323
openstack%2Fcharm-vault~887697,openstack/charm-vault,master,I651d3d5018eb1e79f01578e668aa5beb25726c52,Add support for lunar,ABANDONED,2023-07-05 13:57:53.000000000,2023-07-05 13:58:11.000000000,,[],"[{'number': 1, 'created': '2023-07-05 13:57:53.000000000', 'files': ['osci.yaml', 'src/tests/bundles/lunar-mysql8.yaml', 'src/wheelhouse.txt', 'src/tests/bundles/lunar-raft.yaml', 'src/tests/tests.yaml', 'src/tests/bundles/lunar-raft-cluster.yaml'], 'web_link': 'https://opendev.org/openstack/charm-vault/commit/cfda53cab70198b4bf5eba9fe9bbbdf2b62fcd5c', 'message': 'Add support for lunar\n\nAs lunar introduces python3.11, psycopg2 version needs to be at least\nversion 2.9.5 to support it.\nModify the tests to run on Lunar and remove the Kinetic ones.\n\nCloses-Bug: #2025983\n\nChange-Id: I651d3d5018eb1e79f01578e668aa5beb25726c52\nSigned-off-by: David Negreira <david.negreira@canonical.com>\n'}]",0,887697,cfda53cab70198b4bf5eba9fe9bbbdf2b62fcd5c,2,0,1,32371,,,0,"Add support for lunar

As lunar introduces python3.11, psycopg2 version needs to be at least
version 2.9.5 to support it.
Modify the tests to run on Lunar and remove the Kinetic ones.

Closes-Bug: #2025983

Change-Id: I651d3d5018eb1e79f01578e668aa5beb25726c52
Signed-off-by: David Negreira <david.negreira@canonical.com>
",git fetch https://review.opendev.org/openstack/charm-vault refs/changes/97/887697/1 && git format-patch -1 --stdout FETCH_HEAD,"['osci.yaml', 'src/tests/bundles/lunar-mysql8.yaml', 'src/wheelhouse.txt', 'src/tests/bundles/lunar-raft.yaml', 'src/tests/tests.yaml', 'src/tests/bundles/lunar-raft-cluster.yaml']",6,cfda53cab70198b4bf5eba9fe9bbbdf2b62fcd5c,lp2025983,series: lunar,series: kinetic,21,19
openstack%2Fcharm-vault~887696,openstack/charm-vault,master,Ia8acfd5d1cdf627e085a42291e38742d93f90b96,Add support for lunar,ABANDONED,2023-07-05 13:44:29.000000000,2023-07-05 13:45:23.000000000,,[],"[{'number': 1, 'created': '2023-07-05 13:44:29.000000000', 'files': ['osci.yaml', 'src/tests/bundles/lunar-mysql8.yaml', 'src/wheelhouse.txt', 'src/tests/bundles/lunar-raft.yaml', 'src/tests/tests.yaml', 'src/tests/bundles/lunar-raft-cluster.yaml'], 'web_link': 'https://opendev.org/openstack/charm-vault/commit/9238cebd644b33d9e54c181a653a26f00478cf83', 'message': 'Add support for lunar\n\nAs lunar introduces python3.11, psycopg2 version needs to be at least\nversion 2.9.5 to support it.\nModify the tests to run on Lunar and remove the Kinetic ones.\n\nCloses-Bug: #2025983\n\nChange-Id: Ia8acfd5d1cdf627e085a42291e38742d93f90b96\nSigned-off-by: David Negreira <david.negreira@canonical.com>\n'}]",0,887696,9238cebd644b33d9e54c181a653a26f00478cf83,2,0,1,32371,,,0,"Add support for lunar

As lunar introduces python3.11, psycopg2 version needs to be at least
version 2.9.5 to support it.
Modify the tests to run on Lunar and remove the Kinetic ones.

Closes-Bug: #2025983

Change-Id: Ia8acfd5d1cdf627e085a42291e38742d93f90b96
Signed-off-by: David Negreira <david.negreira@canonical.com>
",git fetch https://review.opendev.org/openstack/charm-vault refs/changes/96/887696/1 && git format-patch -1 --stdout FETCH_HEAD,"['osci.yaml', 'src/tests/bundles/lunar-mysql8.yaml', 'src/wheelhouse.txt', 'src/tests/bundles/lunar-raft.yaml', 'src/tests/tests.yaml', 'src/tests/bundles/lunar-raft-cluster.yaml']",6,9238cebd644b33d9e54c181a653a26f00478cf83,lp2025983,series: lunar,series: kinetic,21,19
openstack%2Fnova~887632,openstack/nova,master,Ia198f712e2ad277743aed08e27e480208f463ac7,enable validations in nova-lvm,MERGED,2023-07-04 15:44:14.000000000,2023-07-05 13:02:13.000000000,2023-07-05 13:00:20.000000000,"[{'_account_id': 7166}, {'_account_id': 9708}, {'_account_id': 17685}, {'_account_id': 22348}]","[{'number': 1, 'created': '2023-07-04 15:44:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/a27e0394e1a6d61bc1cf3e40ef80810c61c84d39', 'message': 'enable validations in nova-lvm\n\nAs of I8ca059a4702471d4d30ea5a06079859eba3f5a81 validations\nare now requried for test_rebuild_volume_backed_server.\nValidations are also required for any volume attach/detach based test\nin general due to know qemu issues.\n\nThis patch just turns them back on to unblock the gate.\n\nChange-Id: Ia198f712e2ad277743aed08e27e480208f463ac7\n'}, {'number': 2, 'created': '2023-07-04 15:49:11.000000000', 'files': ['.zuul.yaml'], 'web_link': 'https://opendev.org/openstack/nova/commit/6f56c5c9fd60ee1d53376a9100a9580cb2b38dc3', 'message': 'enable validations in nova-lvm\n\nAs of I8ca059a4702471d4d30ea5a06079859eba3f5a81 validations\nare now requried for test_rebuild_volume_backed_server.\nValidations are also required for any volume attach/detach based test\nin general due to know qemu issues.\n\nThis patch just turns them back on to unblock the gate.\n\nCloses-Bug: #2025813\nChange-Id: Ia198f712e2ad277743aed08e27e480208f463ac7\n'}]",3,887632,6f56c5c9fd60ee1d53376a9100a9580cb2b38dc3,19,4,2,11604,,,0,"enable validations in nova-lvm

As of I8ca059a4702471d4d30ea5a06079859eba3f5a81 validations
are now requried for test_rebuild_volume_backed_server.
Validations are also required for any volume attach/detach based test
in general due to know qemu issues.

This patch just turns them back on to unblock the gate.

Closes-Bug: #2025813
Change-Id: Ia198f712e2ad277743aed08e27e480208f463ac7
",git fetch https://review.opendev.org/openstack/nova refs/changes/32/887632/1 && git format-patch -1 --stdout FETCH_HEAD,['.zuul.yaml'],1,a27e0394e1a6d61bc1cf3e40ef80810c61c84d39,bug/2025813,, # Disable SSH validation in tests to save time. TEMPEST_RUN_VALIDATION: false,0,2
